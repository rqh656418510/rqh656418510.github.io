<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Clay 的技术空间</title>
  
  <subtitle>用进废退 | 艺不压身</subtitle>
  <link href="https://www.techgrow.cn/atom.xml" rel="self"/>
  
  <link href="https://www.techgrow.cn/"/>
  <updated>2023-12-04T13:55:33.000Z</updated>
  <id>https://www.techgrow.cn/</id>
  
  <author>
    <name>Clay</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Qt 各版本官方下载地址</title>
    <link href="https://www.techgrow.cn/posts/5bd27ea.html"/>
    <id>https://www.techgrow.cn/posts/5bd27ea.html</id>
    <published>2023-12-04T13:55:33.000Z</published>
    <updated>2023-12-04T13:55:33.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>从 Qt <code>5.15</code> 开始，Qt 的开源版本只支持在线安装，不再提供离线安装包。使用在线安装器可以安装 Qt <code>5.9</code> 之后 Qt <code>5</code> 和 Qt <code>6</code> 的各个子版本。</p><div class="admonition note"><p class="admonition-title">Qt 的长期技术支持版本</p><ul><li>Qt 6 发布后，Qt 5 仍然在更新，Qt 5 系列的最后一个长期技术支持版本是 <code>5.15</code>。</li><li>Qt 6 系列的第一个长期技术支持版本是 <code>6.2</code>，包含了 Qt 框架中的所有模块。</li></ul></div><h2 id="官方下载地址"><a href="#官方下载地址" class="headerlink" title="官方下载地址"></a>官方下载地址</h2><ul><li><a href="http://download.qt.io/">Qt 相关下载大全</a></li><li><a href="https://download.qt.io/archive/online_installers/">在线安装器的下载地址</a></li><li><a href="http://download.qt.io/archive/qtcreator/">Qt Creator 各个版本的下载地址</a></li><li><a href="http://download.qt.io/archive/vsaddin/">Qt VS 开发插件各个版本的下载地址</a></li></ul><span id="more"></span><h2 id="Qt-官方下载（较慢）"><a href="#Qt-官方下载（较慢）" class="headerlink" title="Qt 官方下载（较慢）"></a>Qt 官方下载（较慢）</h2><blockquote><p>Qt 官方有一个专门的资源下载网站，所有的开发环境和相关工具都可以从这里下载，具体地址是：<code>http://download.qt.io/</code></p></blockquote><p><img data-src="../../../asset/2023/12/qt-download-1.png"></p><table><thead><tr><th>目录</th><th>说明</th></tr></thead><tbody><tr><td> archive</td><td> 各种 Qt 开发工具安装包，新旧都有（可以下载 Qt 开发环境和源代码）。</td></tr><tr><td>community_releases</td><td> 社区定制的 Qt 库，Tizen 版 Qt 以及 Qt 附加源码包。</td></tr><tr><td>development_releases</td><td> 开发版，有新的和旧的不稳定版本，在 Qt 开发过程中的非正式版本。</td></tr><tr><td>learning</td><td> 有学习 Qt 的文档教程和示范视频。</td></tr><tr><td>ministro</td><td> 迷你版，目前是针对 Android 的版本。</td></tr><tr><td>official_releases</td><td> 正式发布版，即最新稳定版的 Qt 库和开发工具（可以下载 Qt 开发环境和源代码）。</td></tr><tr><td>online</td><td>Qt 在线资源。</td></tr><tr><td>snapshots</td><td> 预览版，最新的开发测试中的 Qt 库和开发工具。</td></tr></tbody></table><blockquote><p><code>archive</code> 和 <code>official_releases</code> 两个目录都有最新的 Qt 开发环境安装包，这里以 <code>archive</code> 目录里的内容为例来说明。点击进入 <code>archive</code> 目录，会看到多个子目录：</p></blockquote><p><img data-src="../../../asset/2023/12/qt-download-2.png"></p><table><thead><tr><th>目录</th><th>说明</th></tr></thead><tbody><tr><td> vsaddin</td><td>Qt 针对 Visual Studio 集成的插件。</td></tr><tr><td>qtcreator</td><td>Qt 官方的集成开发工具。</td></tr><tr><td>qt</td><td>Qt 开发环境的下载目录。</td></tr><tr><td>online_installers</td><td> 在线安装器，国内用户的下载速度较慢。</td></tr><tr><td>additional_libraries</td><td>QT 框架的一些附加模块。</td></tr></tbody></table><blockquote><p>再进入 <code>qt</code> 子目录 ，会看到所有的 Qt 版本，从 <code>1.0</code> 到目前的 <code>6.6</code></p></blockquote><p><img data-src="../../../asset/2023/12/qt-download-3.png"></p><blockquote><p>进入 <code>6.6</code> 目录，会看到各种子版本</p></blockquote><p><img data-src="../../../asset/2023/12/qt-download-4.png"></p><blockquote><p>进入 <code>6.6.1</code> 子版本，会看到多个目录</p></blockquote><p><img data-src="../../../asset/2023/12/qt-download-5.png"></p><table><thead><tr><th>目录</th><th>说明</th></tr></thead><tbody><tr><td> submodules</td><td>Qt 各个子模块的源码包</td></tr><tr><td> single</td><td>Qt 完整的源码包</td></tr></tbody></table><div class="admonition note"><p class="admonition-title">Qt 版本号的命名规则</p><p>这里解释一下 Qt 的版本号，比如 <code>6.5.3</code> 是完整的 Qt 版本号，第一个数字 6 是大版本号（major），第二个数字 5 是小版本号（minor），第三个数字 3 是补丁号（patch）。只要前面两个数字相同，Qt 的特性就是一致的，最后的数字是对该版本的补丁更新。</p></div><h2 id="Qt-国内镜像网站下载（较快）"><a href="#Qt-国内镜像网站下载（较快）" class="headerlink" title="Qt 国内镜像网站下载（较快）"></a>Qt 国内镜像网站下载（较快）</h2><p>在国内，Qt 的官方下载速度较慢，建议使用国内镜像网站下载。这里推荐几个国内著名的 Qt 镜像网站，主要是各个高校的：</p><table><thead><tr><th>镜像网站名称</th><th>下载地址</th></tr></thead><tbody><tr><td>中国科学技术大学 </td><td><a href="http://mirrors.ustc.edu.cn/qtproject/">http://mirrors.ustc.edu.cn/qtproject/</a></td></tr><tr><td> 清华大学 </td><td><a href="https://mirrors.tuna.tsinghua.edu.cn/qt/">https://mirrors.tuna.tsinghua.edu.cn/qt/</a></td></tr><tr><td> 北京理工大学 </td><td><a href="http://mirror.bit.edu.cn/qtproject/">http://mirror.bit.edu.cn/qtproject/</a></td></tr><tr><td> 中国互联网络信息中心 </td><td><a href="https://mirrors.cnnic.cn/qt/">https://mirrors.cnnic.cn/qt/</a></td></tr></tbody></table><blockquote><p>值得一提的是，国内镜像网站的资源目录结构和 Qt 官网是类似的，这里不再赘述。</p></blockquote><h2 id="Qt-在线安装案例"><a href="#Qt-在线安装案例" class="headerlink" title="Qt 在线安装案例"></a>Qt 在线安装案例</h2><blockquote><p>在 <a href="https://download.qt.io/archive/online_installers/">Qt 官网</a> 下载在线安装器，如 <code>qt-unified-windows-x86-4.2.0-online.exe</code></p></blockquote><p><img data-src="../../../asset/2023/12/qt-download-6.png"></p><blockquote><p>双击在线安装器的 <code>EXE</code> 文件，开始安装 Qt，然后根据自己实际需求安装所需的组件</p></blockquote><p><img data-src="../../../asset/2023/12/qt-download-7.png"></p><div class="admonition note"><p class="admonition-title">提示</p><ul><li>Qt 的安装一般需要 20G 以上的磁盘空间，请确保磁盘有足够的空间。</li><li>由于笔者在本地安装了 Visual Studio 2019，因此在上述图中选择了 <code>MSVC 2019 64-bit</code> 开发套件，若不需要，可以选择不安装该组件。</li><li>笔者选择安装 Qt 的长期技术支持版本，分别是 Qt <code>5.15</code> 与 Qt <code>6.2</code>，若不需要使用 Qt 5，可以选择不安装上述图中 Qt <code>5.15.2</code> 相关的组件，只安装 Qt 6 相关的组件。</li></ul></div><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://c.biancheng.net/view/3851.html">Qt 下载（多种下载通道 + 所有版本）</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 Qt 各版本的官方下载地址，包括 Qt 的安装教程、镜像网站下载加速等内容。</summary>
    
    
    
    
    <category term="开发工具" scheme="https://www.techgrow.cn/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
    <category term="C++" scheme="https://www.techgrow.cn/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>分库分表可能真的要退出历史舞台</title>
    <link href="https://www.techgrow.cn/posts/8c661fac.html"/>
    <id>https://www.techgrow.cn/posts/8c661fac.html</id>
    <published>2023-11-26T14:45:21.000Z</published>
    <updated>2023-11-26T14:45:21.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一开始，开箱即用的 MySQL，一定是企业的首选。不仅仅因为用的人多，更重要的是生态成熟。随着业务的飞速发展（虽然现在这种机会比较少了），对于 MySQL 来说，很快就会遇到各种性能问题。这个时候，就需要由单机 MySQL 向分布式发展了。</p><h2 id="传统数据库的瓶颈"><a href="#传统数据库的瓶颈" class="headerlink" title="传统数据库的瓶颈"></a>传统数据库的瓶颈</h2><p>单机 MySQL 面临很多问题：</p><ul><li>单表太大，比如超过 500w，查询就非常吃力</li><li>单库太大，各种资源告急</li><li>读请求太高，严重影响写请求</li></ul><span id="more"></span><h2 id="传统数据库解决方案"><a href="#传统数据库解决方案" class="headerlink" title="传统数据库解决方案"></a>传统数据库解决方案</h2><p>很长时间以来，国内互联网的做法普遍是采用加入一个中间件的方式来解决，但随着分布式数据库的技术越来越成熟，这些魔法逐渐下沉到它本应该解决的层面 – 数据库实现层。留给分库分表技术的时间已经不多，它的存量市场越来越少了。分库分表技术，退出历史舞台，也是迟早的事情了。解决上面三个单机 MySQL 问题，有很多种切入层面，常见的有框架层、驱动层、代理层。</p><h3 id="第一种（框架层）"><a href="#第一种（框架层）" class="headerlink" title="第一种（框架层）"></a>第一种（框架层）</h3><p>简单地在 MyBatis 或者 JPA 之上使用 AOP 或者拦截器封装一层，也可以实现，这也是最傻的方式。</p><h3 id="第二种（驱动层）"><a href="#第二种（驱动层）" class="headerlink" title="第二种（驱动层）"></a>第二种（驱动层）</h3><p>再进一步，就可以在 JDBC 之上的驱动层来实现，把分库分表的路由维护在内存里，通过重写的 DataSource、Connection、Statment、ResultSet 等，对业务进行无侵入的改进。但可惜的是，这类方案还必须要维护与逻辑表相对应的物理表，而且功能也是阉割的，不确定性依然不小。更要命的是，JDBC 只支持 Java，对于某些公司来说，就非常的不适用。</p><h3 id="第三种（代理层）"><a href="#第三种（代理层）" class="headerlink" title="第三种（代理层）"></a>第三种（代理层）</h3><p>再就是采用中间件的传统模式，引入 Proxy 中间件，即把自己伪装成一个 MySQL Server，接受 Client 的请求。至于它后面怎么去操作真实的数据库，开发者都不需要知道。但 Proxy 本身也是一套服务，需要保证高可用，且有运维成本在里面，同时功能依然是阉割的。</p><h2 id="新型数据库解决方案"><a href="#新型数据库解决方案" class="headerlink" title="新型数据库解决方案"></a>新型数据库解决方案</h2><p>框架层、驱动层、代理层，在过去很长一段时间里，有无数的互联网公司前赴后继的试水，从 TDDL、Cobar，到 MyCat、ShardingSphere，各种层面的中间件也是层出不穷。但最近几年，这种争相斗艳的场面逐渐不再，到最后剩下来的，也就 ShardingSphere 这一枝独秀了。是问题不存在了么？不，正好相反，问题越来越严重。并不是问题消失了，而是它被转化成其他解决方式了。</p><h3 id="分布式数据库的前景"><a href="#分布式数据库的前景" class="headerlink" title="分布式数据库的前景"></a>分布式数据库的前景</h3><p>抛开关系型数据库不说，很久之前，类似于 ElasticSearch、Cassandra 这样的 NoSQL 存储，分片和副本的概念，就已经非常成熟了，而且它们是内置的，并不需要 DBA 去人工维护它们的物理位置。对于关系型数据库来说，走向分布式也终将成为必然。随着 Raft 等协议应用越来越广泛，分布式数据库的可靠性也逐渐得到了保证。如果以前因为事务问题而拒绝采用某些 NoSQL 产品，那么如今完全兼容 MySQL 的分布式数据库，没有理由再拒绝。</p><h3 id="分布式数据库的选择"><a href="#分布式数据库的选择" class="headerlink" title="分布式数据库的选择"></a>分布式数据库的选择</h3><p>云厂商，直接提供了像 Aurora、PolarDB 之类的 MySQL 增强，更有类似 TiDB、OceanBase 这样纯粹的分布式数据库，越来越多的业务走向了这个终途。当团队加班加点验证着分库分表中间件的时候，却发现其实换个兼容的存储就能玩得转，你会怎么选，简直不用再多说。当然，一旦选用了分布式数据库，以前的 DBA 经验可能就不管用了，比如说索引及其二级索引。开发团队不得不学习新的知识，来应对分布式环境。但这些都是阵痛，<strong>长远看来，分布式数据库是趋势，而分库分表中间件只能吃存量业务。</strong></p><h2 id="如何选择解决方案"><a href="#如何选择解决方案" class="headerlink" title="如何选择解决方案"></a>如何选择解决方案</h2><ul><li>如果业务拥有常年累积的大量复杂数据，建议采用复杂的分库分表组件。</li><li>如果业务比较新，在可预见的未来会有大量数据，那选择分布式数据库是最合适的。</li></ul><h2 id="最后总结"><a href="#最后总结" class="headerlink" title="最后总结"></a>最后总结</h2><p><strong>分库分表中间件并不是消失了。它摇身一变，变成了分布式数据库的一部分。</strong>你可能会听到很多切到分布式数据库，又从分布式数据库切回到 MySQL 的案例，这属于想吃螃蟹但并没有吃到。目前来看，分布式数据库越来越稳定，生态建设也越来越好。而分库分表，则适用于存量业务，终将会退出历史的舞台。</p>]]></content>
    
    
    <summary type="html">分库分表可能真的要退出历史舞台。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="数据库" scheme="https://www.techgrow.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Cisdem PDF Converter OCR 转换器破解安装</title>
    <link href="https://www.techgrow.cn/posts/3ac58081.html"/>
    <id>https://www.techgrow.cn/posts/3ac58081.html</id>
    <published>2023-11-22T13:18:36.000Z</published>
    <updated>2023-11-22T13:18:36.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>PDF 可以在任何屏幕上完美地显示内容，并且可以轻松阅读、存档或分发文件，而 Office 格式是文档创建和编辑的必备格式，因此 PDF 转换对于进一步编辑或重复使用变得很常见。Cisdem PDF Converter OCR 支持快速无缝地将 PDF 转换为多种文档格式。</p><h2 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h2><p>支持 Windows 7、Windows 8、Windows 10、Windows 11 的 64 位操作系统。</p><h2 id="软件简介"><a href="#软件简介" class="headerlink" title="软件简介"></a>软件简介</h2><p>Cisdem PDF Converter OCR 是一款 PDF 格式转换软件，可以轻松地将正常和可扫描的 PDF 文档转换为可编辑文本格式的文件，比如转换为可编辑和可搜索的 PDF、Word、Excel、PPT、ePub、HTML、TXT、Rtfd、图片 (JPEG，BMP，PNG，GIF，TIFF) 等格式，支持 OCR 技术，同时保持原始布局和文件质量。</p><h2 id="软件特点"><a href="#软件特点" class="headerlink" title="软件特点"></a>软件特点</h2><p>Cisdem PDF Converter OCR 将尽力保留文本、图像、表格元素，并尽可能准确地保持原始格式、布局。例如，它可以在 Word 文档中保留复杂 PDF 文件的原始外观和感觉，将表格数据放入 Excel 电子表格中的正确单元格中，并在 PowerPoint 中保留布局，您无需花费数小时调整输出文件。OCR (光学字符识别) 用于根据形状和外观识别文本字符，它可以帮助从扫描的 PDF 或图像文件中提取文本内容，是归档和重新扫描 PDF 的必备功能。Cisdem PDF Converter OCR 不仅可以通过启用 OCR 功能快速批量处理扫描的 PDF 和图像文件，还可以通过手动标记文本、图像和表格来微调 OCR 应用区域，以实现更准确的识别。Cisdem PDF Converter OCR 可以识别 200 多种语言，包括英语、中文、西班牙语、阿拉伯语、法语、俄语、葡萄牙语、德语、日语、韩语等。</p><span id="more"></span><h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h2><h3 id="软件下载"><a href="#软件下载" class="headerlink" title="软件下载"></a>软件下载</h3><ul><li>百度网盘链接: <code>https://pan.baidu.com/s/1jls5BTI_kinz5e70wbbQHg</code></li><li>百度网盘提取码: <code>7exm</code></li></ul><h3 id="破解安装"><a href="#破解安装" class="headerlink" title="破解安装"></a>破解安装</h3><ol><li>在软件下载并解压后，将获得 <code>Setup.exe</code> 和 <code>Crack</code> 等文件，双击 <code>Setup.exe</code> 文件开始安装</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-1.png"></p><ol start="2"><li>默认选择创建桌面快捷方式，然后点击 <code>next</code> 按钮</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-2.png"></p><ol start="3"><li>点击 <code>install</code> 按钮开始安装软件</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-3.png"></p><ol start="4"><li>去掉勾选，先不要运行软件，等待安装破解补丁</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-4.png"></p><ol start="5"><li>在安装破解补丁前，首先打开软件的安装目录。如果忘记软件的安装目录，请返回到系统桌面，找到软件的桌面快捷图标，并右键点击图标，出现弹窗后选择 <code>打开文件位置</code> 即可获得软件的安装目录</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-5.png"></p><ol start="6"><li>打开解压后的 <code>Crack</code> 文件夹，将里面的破解补丁文件复制到软件安装目录中替换</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-6.png"></p><ol start="7"><li>选择替换目标中的文件</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-7.png"></p><ol start="8"><li>双击桌面的快捷方式运行软件，点击顶部菜单栏里的 <code>About</code> 选项，查看是否激活成功</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-8.png"></p><h2 id="软件使用"><a href="#软件使用" class="headerlink" title="软件使用"></a>软件使用</h2><ol><li>将需要转换的 PDF 文件拖拽到软件的主界面中，此时会提示在线下载并安装 OCR 模块，点击 <code>OK</code> 按钮开始下载。如果下载失败，可以关闭并重启软件，拖拽 PDF 文件到主界面，然后重新安装 OCR 模块</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-9.png"></p><ol start="2"><li>等待 OCR 模块下载完成</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-10.png"></p><ol start="3"><li> OCR 模块下载完成后，根据提示进行安装</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-11.png"></p><ol start="4"><li>若需要将扫描版的 PDF 文件转换为可编辑的 PDF 文件，可以选择 <code>OCR PDF</code>，并点击 <code>齿轮</code> 图标，选择语言为 <code>Chinese（Simplified）</code> 和 <code>English</code>，然后点击 <code>OK</code> 按钮</li></ol><p><img data-src="../../../asset/2023/10/pdf-converter-12.png"></p><ol start="5"><li>最后选择 PDF 文件转换后的输出目录，然后点击 <code>Convert</code> 按钮开始转换 PDF 文件</li></ol><p><img data-src="../../../asset/2023/10/pdf-convert-13.png"></p>]]></content>
    
    
    <summary type="html">本文主要记录 Cisdem PDF Converter OCR 转换器的破解安装教程，包括如何将 PDF 转换为其他格式的文件。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="开发工具" scheme="https://www.techgrow.cn/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 云原生解决方案介绍</title>
    <link href="https://www.techgrow.cn/posts/16a97c36.html"/>
    <id>https://www.techgrow.cn/posts/16a97c36.html</id>
    <published>2023-11-15T14:13:45.000Z</published>
    <updated>2023-11-15T14:13:45.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文主要介绍 Kafka 在生产实践中存在的问题，如运维操作、负载均衡、故障恢复等各方面，并简单介绍字节跳动、小红书是如何使用消息队列的云原生化来解决这些问题的。</p><h2 id="Kafka-实践遇到的问题"><a href="#Kafka-实践遇到的问题" class="headerlink" title="Kafka 实践遇到的问题"></a>Kafka 实践遇到的问题</h2><p>随着业务快速增长，经典消息队列 Kafka 的劣势开始逐渐暴露，在弹性、规模、成本及运维方面都无法满足业务需求。在本中，将介绍 Kafka 在生产实践中存在的问题，如运维操作、负载均衡、故障恢复等各方面。</p><span id="more"></span><h3 id="运维操作"><a href="#运维操作" class="headerlink" title="运维操作"></a>运维操作</h3><p>Kafka 的重启、扩缩容、分区迁移，这些运维操作都比较复杂。</p><p><img data-src="../../../asset/2023/10/kafka-note-1.png"></p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p><img data-src="../../../asset/2023/10/kafka-note-2.png"></p><h3 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h3><p>Kafka 自身支持处理单机故障，但对多机故障却无能为力。</p><p><img data-src="../../../asset/2023/10/kafka-note-3.png"></p><h3 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h3><p><img data-src="../../../asset/2023/10/kafka-note-4.png"></p><h3 id="存算一体架构"><a href="#存算一体架构" class="headerlink" title="存算一体架构"></a>存算一体架构</h3><p><img data-src="../../../asset/2023/10/kafka-note-5.png"></p><h2 id="字节跳动云原生消息队列方案"><a href="#字节跳动云原生消息队列方案" class="headerlink" title="字节跳动云原生消息队列方案"></a>字节跳动云原生消息队列方案</h2><p>BMQ 是字节跳动自研的一款消息队列，基于 C++ 开发，兼容 Kafka 协议，采用 HDFS 分布式存储来存放消息数据。</p><h3 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h3><p><img data-src="../../../asset/2023/10/kafka-note-6.png"></p><h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><p><img data-src="../../../asset/2023/10/kafka-note-7.png"></p><h3 id="Broker-运行机制"><a href="#Broker-运行机制" class="headerlink" title="Broker 运行机制"></a>Broker 运行机制</h3><p><img data-src="../../../asset/2023/10/kafka-note-8.png"></p><p><img data-src="../../../asset/2023/10/kafka-note-9.png"></p><p><img data-src="../../../asset/2023/10/kafka-note-10.png"></p><h3 id="Proxy-运行机制"><a href="#Proxy-运行机制" class="headerlink" title="Proxy 运行机制"></a>Proxy 运行机制</h3><p><img data-src="../../../asset/2023/10/kafka-note-11.png"></p><p><img data-src="../../../asset/2023/10/kafka-note-12.png"></p><h3 id="容灾容错-HDFS"><a href="#容灾容错-HDFS" class="headerlink" title="容灾容错 HDFS"></a>容灾容错 HDFS</h3><p><img data-src="../../../asset/2023/10/kafka-note-13.png"></p><p><img data-src="../../../asset/2023/10/kafka-note-14.png"></p><h3 id="线上业务使用场景"><a href="#线上业务使用场景" class="headerlink" title="线上业务使用场景"></a>线上业务使用场景</h3><p><img data-src="../../../asset/2023/10/kafka-note-15.png"></p><h2 id="小红书-Kafka-云原生最佳实践"><a href="#小红书-Kafka-云原生最佳实践" class="headerlink" title="小红书 Kafka 云原生最佳实践"></a>小红书 Kafka 云原生最佳实践</h2><p>小红书在 Kafka 原有的基础上，引入了分层存储、弹性扩容、消费隔离等特性。</p><h3 id="核心手段"><a href="#核心手段" class="headerlink" title="核心手段"></a>核心手段</h3><p><img data-src="../../../asset/2023/10/kafka-note-16.png"></p><h3 id="系统架构-1"><a href="#系统架构-1" class="headerlink" title="系统架构"></a>系统架构</h3><p><img data-src="../../../asset/2023/10/kafka-note-17.png"></p><h3 id="架构优势"><a href="#架构优势" class="headerlink" title="架构优势"></a>架构优势</h3><p><img data-src="../../../asset/2023/10/kafka-note-18.png"></p><h3 id="成本优化"><a href="#成本优化" class="headerlink" title="成本优化"></a>成本优化</h3><p><img data-src="../../../asset/2023/10/kafka-note-19.png"></p><h3 id="消费隔离"><a href="#消费隔离" class="headerlink" title="消费隔离"></a>消费隔离</h3><p><img data-src="../../../asset/2023/10/kafka-note-20.png"></p><h3 id="智能缓存"><a href="#智能缓存" class="headerlink" title="智能缓存"></a>智能缓存</h3><p><img data-src="../../../asset/2023/10/kafka-note-21.png"></p><h3 id="弹性扩容"><a href="#弹性扩容" class="headerlink" title="弹性扩容"></a>弹性扩容</h3><p><img data-src="../../../asset/2023/10/kafka-note-22.png"></p><p><img data-src="../../../asset/2023/10/kafka-note-23.png"></p><h3 id="容器化"><a href="#容器化" class="headerlink" title="容器化"></a>容器化</h3><p><img data-src="../../../asset/2023/10/kafka-note-24.png"></p><p><img data-src="../../../asset/2023/10/kafka-note-25.png"></p><p><img data-src="../../../asset/2023/10/kafka-note-26.png"></p><h3 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h3><h4 id="升级现有架构"><a href="#升级现有架构" class="headerlink" title="升级现有架构"></a>升级现有架构</h4><p><img data-src="../../../asset/2023/10/kafka-note-27.png"></p><h4 id="引入存算分离架构"><a href="#引入存算分离架构" class="headerlink" title="引入存算分离架构"></a>引入存算分离架构</h4><p><img data-src="../../../asset/2023/10/kafka-note-28.png"></p><h2 id="AutoMQ-云原生消息队列方案"><a href="#AutoMQ-云原生消息队列方案" class="headerlink" title="AutoMQ 云原生消息队列方案"></a>AutoMQ 云原生消息队列方案</h2><h3 id="AutoMQ-for-Kafka"><a href="#AutoMQ-for-Kafka" class="headerlink" title="AutoMQ for Kafka"></a>AutoMQ for Kafka</h3><p>由 <a href="https://www.automq.com/">AutoMQ</a> 开源的新一代消息流存储平台，面向开发者提供低成本、无状态、 100% 兼容 Apache Kafka 的消息服务。目前有两种版本，分别是商业版与开源版本。</p><ul><li><a href="https://docs.automq.com/zh/docs/automq-s3kafka/YUzOwI7AgiNIgDk1GJAcu6Uanog">官方中文文档</a></li><li><a href="https://github.com/AutoMQ/automq-for-kafka">GitHub 开源项目</a></li></ul><h3 id="AutoMQ-for-RocketMQ"><a href="#AutoMQ-for-RocketMQ" class="headerlink" title="AutoMQ for RocketMQ"></a>AutoMQ for RocketMQ</h3><p>由 <a href="https://www.automq.com/">AutoMQ</a> 基于 Apache RocketMQ 5.0 的云原生开源实现。目前有两种版本，分别是商业版与开源版本。</p><ul><li><a href="https://github.com/AutoMQ/automq-for-rocketmq">GitHub 开源项目</a></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://juejin.cn/post/7199550396213542973">消息队列 | 青训营笔记</a></li><li><a href="https://www.bilibili.com/video/BV1Cc411R7kt">字节跳动云原生消息队列实践 - 视频</a></li><li><a href="https://www.bilibili.com/video/BV1dw411s7g8">小红书 Kafka 云原生化最佳实践 - 视频</a></li><li><a href="https://www.bilibili.com/video/BV1hM411S7PP">如何实现 Apache Kafka 十倍的降本增效 - 视频</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 Kafka 云原生解决方案。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="分布式" scheme="https://www.techgrow.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="微服务" scheme="https://www.techgrow.cn/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    <category term="消息队列" scheme="https://www.techgrow.cn/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Linux 的 Xinetd 服务介绍</title>
    <link href="https://www.techgrow.cn/posts/7f134f1e.html"/>
    <id>https://www.techgrow.cn/posts/7f134f1e.html</id>
    <published>2023-11-14T13:48:23.000Z</published>
    <updated>2023-11-14T13:48:23.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="Xinetd-简介"><a href="#Xinetd-简介" class="headerlink" title="Xinetd 简介"></a>Xinetd 简介</h2><p>Xinetd 是新一代的网络守护进程服务程序，又叫超级 Internet 服务器，经常用来管理保护多种轻量级 Internet 服务。它在 Linux 的安全中有着举足轻重的地位，它管理的服务都是一些不是很常用，但是系统中偶尔也会用到的小服务或者该服务没什么好的安全机制，比如：Ftp、Rsync、Telnet、SSH 等。它并不是一真正意义上的服务，Xinetd 相当于 Rync、SSH 等服务的代理人，比如代理了 <code>sshd</code>，那就可以关闭 SSH 服务，22 端口就由 Xinetd 服务代理了。它的作用大致可以分为以下几个：访问控制、防止 DOS 攻击、服务转发、用户交互式体验等。</p><h3 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h3><ul><li><code>超级守护进程</code>：多个服务统一由一个进程管理，该进程可以管理多个服务。</li><li><code>独立启动的守护进程</code>：每个特定服务都有单独的守护进程（stand-alone），这个保证单一服务始终存活的进程就是独立启动的守护进程。</li></ul><span id="more"></span><h3 id="优点介绍"><a href="#优点介绍" class="headerlink" title="优点介绍"></a>优点介绍</h3><ul><li><p>强大的存取控制功能</p><ul><li>设置特定的连接时间；</li><li>内置对恶意用户和善意用户的差别待遇设定；</li><li>使用 <code>libwrap</code> 支持，其效能更甚于 <code>tcpd</code>；</li><li>可以限制连接的等级，基于主机的连接数和基于服务的连接数；</li><li>将某个服务设置到特定的主机以提供服务。</li></ul></li><li><p>有效防止 DoS 攻击</p><ul><li>可以限制连接的等级；</li><li>可以限制一个主机的最大连接数，从而防止某个主机独占某个服务；</li><li>可以限制日志文件的大小，防止磁盘空间被填满。</li></ul></li><li><p>强大的日志功能</p><ul><li>可以为每一个服务 <code>syslog</code> 设定日志等级；</li><li>如果不使用 <code>syslog</code>，也可以为每个服务建立日志文件；</li><li>可以记录请求的起止时间以决定对方的访问时间；</li><li>可以记录试图非法访问的请求。</li></ul></li><li><p>转向功能</p><ul><li>可以将客户端的请求转发到另一台主机去处理。</li></ul></li><li><p>支持 IPv6</p><ul><li>Xinetd 从 <code>2.1.8.8 pre*</code> 版本开始就支持 IPv6，另外 IPv4 仍然被支持。</li></ul></li><li><p>与客户端的交互功能</p><ul><li>无论客户端请求是否成功，Xinetd 都会有提示告知连接状态。</li></ul></li></ul><h3 id="缺点介绍"><a href="#缺点介绍" class="headerlink" title="缺点介绍"></a>缺点介绍</h3><p>Xinetd 当前最大的缺点是对 RPC 支持的不稳定，但是可以启用 <code>protmap</code>，使它与 Xinetd 共存来解决这个问题。</p><h2 id="Xinetd-使用"><a href="#Xinetd-使用" class="headerlink" title="Xinetd 使用"></a>Xinetd 使用</h2><p>原则上任何系统服务都可以使用 Xinetd，然而最适合的应该是那些常见的网络服务，并且这些服务的请求数目和频繁程度不会太高。像 DNS 和 Apache 就不适合采用 Xinetd 进行管理，而像 FTP、Telnet、SSH 等就适合使用 Xinetd 进行管理。</p><ul><li>系统默认使用 Xinetd 的服务可以分为如下几类<ul><li>① 标准 Internet 服务：telnet、ftp。</li><li>② 信息服务：finger、netstat、systat。</li><li>③ 邮件服务：imap、imaps、pop2、pop3、pops。</li><li>④ RPC 服务：rquotad、rstatd、rusersd、sprayd、walld。</li><li>⑤ BSD 服务：comsat、exec、login、ntalk、shell、talk。</li><li>⑥ 内部服务：chargen、daytime、echo、servers、services、time。</li><li>⑦ 安全服务：irc。</li><li>⑧ 其他服务：name、tftp、uucp。</li></ul></li></ul><p>具体可以使用 Xinetd 进行管理的服务都在 <code>/etc/services</code> 配置文件中定义，该配置文件记录了网络服务名和它们对应使用的端口号及协议。文件中的每一行对应一种服务，它由 4 个字段组成，中间用 Tab 键或空格键分隔，分别表示 <code>服务名称</code>、<code>使用端口</code>、<code>协议名称</code> 及 <code>别名</code>。在一般情况下，不要修改该配置文件的内容，因为这些设置都是 Internet 标准的设置。一旦修改，可能会造成系统冲突，使用户无法正常访问资源。Linux 系统的端口号范围为 0 ~ 65535，不同范围的端口号有不同的意义：</p><ul><li><code>0</code>：不使用。</li><li><code>1 ~ 1023</code>：系统保留，只能由 <code>root</code> 用户使用。</li><li><code>1024 ~ 4999</code>：由客户端程序自由分配。</li><li><code>5000 ~ 65535</code>：由服务器程序自由分配。</li></ul><h2 id="Xinetd-配置"><a href="#Xinetd-配置" class="headerlink" title="Xinetd 配置"></a>Xinetd 配置</h2><p> Xinetd 的配置文件是 <code>/etc/xinetd.conf</code>，但是它只包括默认值，并包含 <code>/etc/xinetd.d</code> 目录中的配置文件。如果要启用或禁用某项 Xinetd 服务，可以编辑位于 <code>/etc/xinetd.d</code> 目录中的配置文件。例如，<code>disable</code> 属性被设为 <code>yes</code>，表示该项服务已禁用；<code>disable</code> 属性被设为 <code>no</code>，表示该项服务已启用。参数和值之间的操作符可以是 <code>=</code>、<code>+=</code> 或 <code>-=</code>。所有属性可以使用 <code>=</code>，其作用是分配一个或多个值。某些属性可以使用 <code>+=</code> 或 <code>-=</code>，其作用分别是将其值增加到某个现存的值表中，或将其值从现存值表中删除。详细的配置参数说明如下：</p><table><thead><tr><th>配置参数</th><th>说明</th></tr></thead><tbody><tr><td> enabled</td><td> 是否启用该服务或服务列表</td></tr><tr><td> disabled</td><td> 是否停用该服务或服务列表</td></tr><tr><td> server</td><td> 启动脚本的位置</td></tr><tr><td> server_args</td><td></td></tr><tr><td>socket_type</td><td> 服务的数据包类型</td></tr><tr><td> log_type</td><td> 包括：日志类型、路径、报警最大容量、停止服务的最大容量</td></tr><tr><td> log_on_success</td><td> 成功后要将哪些值记录到日志中</td></tr><tr><td> log_on_failure</td><td> 失败后要将哪些值记录到日志中</td></tr><tr><td> only_from</td><td> 只有指定 IP 可以访问</td></tr><tr><td> no_access</td><td> 指定 IP 不可以访问</td></tr><tr><td> access_times</td><td> 允许连接的时间</td></tr><tr><td> user</td><td> 运行此服务进程的用户</td></tr><tr><td> wait</td><td> 服务将以多线程的方式运行</td></tr><tr><td> max_load</td><td> 系统最大负载系数</td></tr><tr><td> cps m n</td><td> 限制每秒 m 个入站连接，如果超过 m，则等待 n 秒，主要用于对付服务攻击</td></tr><tr><td> port</td><td> 连接的端口</td></tr><tr><td> nice</td><td></td></tr><tr><td>protocol</td><td> 连接使用的协议</td></tr><tr><td> instances</td><td> 最大连接进程数</td></tr><tr><td> per_source</td><td> 限制每个主机的最大连接数</td></tr><tr><td> bind</td><td></td></tr><tr><td>mdns</td><td></td></tr><tr><td>v6only</td><td></td></tr><tr><td>passenv</td><td></td></tr><tr><td>groups</td><td></td></tr><tr><td>umask</td><td></td></tr><tr><td>banner</td><td></td></tr><tr><td>banner_fail</td><td></td></tr><tr><td>banner_success</td><td></td></tr><tr><td>rlimit_as</td><td> 最多可用内存</td></tr><tr><td> rlimit_cpu</td><td>CPU 每秒最多处理的进程数</td></tr></tbody></table><h2 id="Xinetd-安装"><a href="#Xinetd-安装" class="headerlink" title="Xinetd 安装"></a>Xinetd 安装</h2><ul><li>CentOS 安装 Xinetd</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">sudo yum -y install xinetd</span><br></pre></td></tr></tbody></table></figure><ul><li>Xinetd 服务管理 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">sudo service xinetd start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止</span></span><br><span class="line">sudo service xinetd stop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启</span></span><br><span class="line">sudo service xinetd restart</span><br></pre></td></tr></tbody></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.csdn.net/weixin_43869703/article/details/133879164">Xinetd 服务介绍</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 Xinetd 服务的使用。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="Linux" scheme="https://www.techgrow.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Debian 12 设置时区与同步时间</title>
    <link href="https://www.techgrow.cn/posts/6a0cde5a.html"/>
    <id>https://www.techgrow.cn/posts/6a0cde5a.html</id>
    <published>2023-11-11T12:13:32.000Z</published>
    <updated>2023-11-11T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文主要介绍如何在 Debian 系统上设置时区与同步时间，适用于 Debian 11 Bullseye、Debian 12 Bookworm 发行版。</p><h2 id="设置时区"><a href="#设置时区" class="headerlink" title="设置时区"></a>设置时区</h2><p>一般全自动安装好的 Debian 是 UTC 时间，与北京时间差 8 小时，所以最好将时区设置为常用的时区，这样方便使用与阅读。<code>timedatectl</code> 是一个新工具，它作为 <code>systemd</code> 系统和服务管理器的一部分，代替旧的传统的用在基于 Linux 分布式系统的 <code>sysvinit</code> 守护进程的 <code>date</code> 命令。<code>timedatectl</code> 命令可以查询和更改系统时钟和设置，可以使用此命令来设置或更改当前的日期、时间和时区，或实现与远程 NTP 服务器的自动系统时钟同步。</p><ul><li>查看所有可用的时区 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl list-timezones</span><br></pre></td></tr></tbody></table></figure><ul><li>设置当前系统的时区为上海 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo timedatectl set-timezone <span class="string">"Asia/Shanghai"</span></span><br></pre></td></tr></tbody></table></figure><ul><li>查看当前系统的时区 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl status</span><br></pre></td></tr></tbody></table></figure><span id="more"></span><h2 id="同步时间"><a href="#同步时间" class="headerlink" title="同步时间"></a>同步时间</h2><p>一般重新设置系统时区后，现实时间会与系统时间之间会有误差，这时候建议使用 <code>systemd-timesyncd</code> 相关工具来解决时间差异的问题。<strong>特别注意：<code>timedatectl</code> 并不兼容 <code>ntpd</code> 等组件，请不要安装 <code>ntpd</code> 等组件，以免时间同步失效。</strong></p><ul><li>安装 <code>systemd-timesyncd</code> 服务 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install systemd-timesyncd</span><br></pre></td></tr></tbody></table></figure><ul><li>更改配置文件，添加 NTP 服务器（添加一行 NTP 服务器地址）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/systemd/timesyncd.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Time]</span><br><span class="line">NTP=pool.ntp.org 0.asia.pool.ntp.org 1.asia.pool.ntp.org 2.asia.pool.ntp.org</span><br><span class="line">#RootDistanceMaxSec=5</span><br><span class="line">#PollIntervalMinSec=32</span><br><span class="line">#PollIntervalMaxSec=2048</span><br></pre></td></tr></tbody></table></figure><ul><li>重启 <code>systemd-timesyncd</code> 服务 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart systemd-timesyncd</span><br></pre></td></tr></tbody></table></figure><ul><li>查看 <code>systemd-timesyncd</code> 服务的运行状态 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status systemd-timesyncd</span><br></pre></td></tr></tbody></table></figure><ul><li>启用时间自动同步 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo timedatectl set-ntp <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure><ul><li>查看时间同步状态 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">timedatectl status</span><br><span class="line"></span><br><span class="line">timedatectl timesync-status</span><br><span class="line"></span><br><span class="line">timedatectl show-timesync --all</span><br></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <summary type="html">本文主要介绍如何在 Debian 12 设置时区与同步时间。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="Debian" scheme="https://www.techgrow.cn/tags/Debian/"/>
    
  </entry>
  
  <entry>
    <title>Debian 12 编译安装 Erlang 23.2</title>
    <link href="https://www.techgrow.cn/posts/a6c59612.html"/>
    <id>https://www.techgrow.cn/posts/a6c59612.html</id>
    <published>2023-11-03T12:13:32.000Z</published>
    <updated>2023-11-03T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><table><thead><tr><th>软件</th><th>版本</th></tr></thead><tbody><tr><td> Debian</td><td><code>12</code></td></tr><tr><td>autoconf</td><td><code>2.6.9</code></td></tr><tr><td>OpenSSL</td><td><code>1.1.1</code></td></tr><tr><td>Erlang</td><td><code>23.2</code></td></tr></tbody></table><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y build-essential perl unzip flex bison fop xsltproc unixodbc libssl-dev unixodbc-dev libncurses5-dev libgl1-mesa-dev libglu1-mesa-dev libxml2-utils</span><br></pre></td></tr></tbody></table></figure><h3 id="安装-autoconf"><a href="#安装-autoconf" class="headerlink" title="安装 autoconf"></a>安装 autoconf</h3><div class="admonition warning"><p class="admonition-title">特别注意</p><p>这里必须安装 <code>2.69</code> 版本的 <code>autoconf</code>，否则 Erlang <code>23.2</code> 在编译前的配置操作会执行失败。</p></div><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卸载已安装的版本</span></span><br><span class="line">sudo apt-get remove --purge autoconf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载</span></span><br><span class="line">curl -O http://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar zxvf autoconf-2.69.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入解压目录</span></span><br><span class="line"><span class="built_in">cd</span> autoconf-2.69</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line">./configure</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line">make -j4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">sudo make install</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看版本</span></span><br><span class="line">autoconf -V</span><br></pre></td></tr></tbody></table></figure><span id="more"></span><h3 id="安装-OpenSSL"><a href="#安装-OpenSSL" class="headerlink" title="安装 OpenSSL"></a>安装 OpenSSL</h3><div class="admonition warning"><p class="admonition-title">特别注意</p><p>这里必须安装 <code>1.1.1</code> 版本的 OpenSSL，否则 Erlang <code>23.2</code> 会编译失败。</p></div><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget https://github.com/openssl/openssl/archive/refs/heads/OpenSSL_1_1_1-stable.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">unzip OpenSSL_1_1_1-stable.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入解压目录</span></span><br><span class="line"><span class="built_in">cd</span> openssl-OpenSSL_1_1_1-stable</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line">./config --prefix=/usr/<span class="built_in">local</span>/openssl-1.1.1 --openssldir=/usr/<span class="built_in">local</span>/openssl-1.1.1 shared</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line">make -j4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">sudo make install</span><br></pre></td></tr></tbody></table></figure><h3 id="安装-Erlang"><a href="#安装-Erlang" class="headerlink" title="安装 Erlang"></a>安装 Erlang</h3><div class="admonition note"><p class="admonition-title">提示</p><ul><li>若在 Erlang 的安装过程中，出现 <code>wxWidgets</code> 没有安装的警告信息，可以忽略该警告。</li><li>由于暂时不需要使用到 <code>wxWidegts</code> 组件（GUI），因此下面使用了 <code>--without-wx</code> 命令行参数进行配置。</li><li>若需要使用到 <code>wxWidegts</code> 组件（GUI），则需要安装 <code>libwxgtk3.0-gtk3-dev</code>、<code>libwxgtk-webview3.0-gtk3-dev</code> 软件包，目前 Debian 12 的软件仓库里并没有这两个软件包，可能需要使用源码进行编译安装。</li></ul></div><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建安装目录</span></span><br><span class="line">sudo mkdir -p /usr/<span class="built_in">local</span>/erlang-23.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget https://erlang.org/download/otp_src_23.2.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -xvf otp_src_23.2.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入解压目录</span></span><br><span class="line"><span class="built_in">cd</span> otp_src_23.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line">./otp_build autoconf</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/erlang-23.2 -with-ssl=/usr/<span class="built_in">local</span>/openssl-1.1.1 --without-javac --without-wx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line">make -j4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">sudo make install</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> ERLANG_HOME=/usr/<span class="built_in">local</span>/erlang-23.2</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ERLANG_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使环境变量生效</span></span><br><span class="line">sudo <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></tbody></table></figure><h3 id="卸载-OpenJDK"><a href="#卸载-OpenJDK" class="headerlink" title="卸载 OpenJDK"></a>卸载 OpenJDK</h3><p>Erlang 在安装过程中使用 <code>fop</code> 来生成 PDF 文档，而 <code>fop</code> 依赖了 OpenJDK，因此在上面安装依赖的步骤里，默认已经安装了最新版本的 OpenJDK。若希望在 Erlang 编译安装成功后卸载 OpenDJK，可以使用以下命令：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看已安装的OpenJDK版本</span></span><br><span class="line">sudo apt list --installed | grep openjdk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载OpenJDK（请自行更改版本号）</span></span><br><span class="line">sudo apt-get autoremove openjdk-17-jre-headless</span><br></pre></td></tr></tbody></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://github.com/asdf-vm/asdf-erlang/issues/257">Ubuntu 22 erlang 23 build error</a></li><li><a href="https://github.com/asdf-vm/asdf-erlang/issues/195">Cannot find required auxiliary files: install-sh config.guess config.sub</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍如何在 Debian 12 安装 Erlang 23.2。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="Debian" scheme="https://www.techgrow.cn/tags/Debian/"/>
    
  </entry>
  
  <entry>
    <title>Debian 11 生产环境部署 PXC 8.0 集群</title>
    <link href="https://www.techgrow.cn/posts/ff0f2d6.html"/>
    <id>https://www.techgrow.cn/posts/ff0f2d6.html</id>
    <published>2023-10-30T12:13:32.000Z</published>
    <updated>2023-11-12T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文主要介绍 Deian 11 如何安装 Percona XtraDB Cluster 8.0 集群（三个物理节点），并基于 Haproxy + Keepalived （两个物理节点）实现双机热备方案。</p><h3 id="系列教程"><a href="#系列教程" class="headerlink" title="系列教程"></a>系列教程</h3><ul><li><a href="/posts/aba17375.html">Docker 部署 PXC 5.7 单机集群</a></li><li><a href="/posts/8dc5e7ed.html">Docker 部署 PXC 8.0 单机集群</a></li><li><a href="/posts/ff0f2d6.html">Debian 11 生产环境部署 PXC 8.0 集群</a></li></ul><span id="more"></span><h3 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a>官方文档</h3><ul><li><a href="https://docs.percona.com/percona-xtradb-cluster/8.0/apt.html">Percona XtraDB Cluster 8.0 官方文档</a></li></ul><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="部署架构"><a href="#部署架构" class="headerlink" title="部署架构"></a>部署架构</h3><p><img data-src="../../../asset/2023/10/mysql-pxc8-6.png"></p><h3 id="部署规划"><a href="#部署规划" class="headerlink" title="部署规划"></a>部署规划</h3><ul><li>软件版本说明</li></ul><table><thead><tr><th>软件</th><th>版本</th><th>描述</th></tr></thead><tbody><tr><td> Haproxy</td><td>1.5.18</td><td></td></tr><tr><td>Keepalived</td><td>1.3.5</td><td></td></tr><tr><td>Percona XtraDB Cluster (PXC)</td><td>8.0</td><td></td></tr></tbody></table><ul><li> 节点部署规划</li></ul><table><thead><tr><th>节点名称</th><th>主机名</th><th> IP</th><th> 系统</th><th>说明</th></tr></thead><tbody><tr><td> PXC 节点一</td><td> pxc-node-1</td><td>192.168.1.188</td><td>Debian 11 (Bullseye)</td><td>Percona XtraDB Cluster (PXC)</td></tr><tr><td>PXC 节点二</td><td> pxc-node-2</td><td>192.168.1.193</td><td>Debian 11 (Bullseye)</td><td>Percona XtraDB Cluster (PXC)</td></tr><tr><td>PXC 节点三</td><td> pxc-node-3</td><td>192.168.1.223</td><td>Debian 11 (Bullseye)</td><td>Percona XtraDB Cluster (PXC)</td></tr><tr><td>Haproxy 节点一</td><td> haproxy-node-1</td><td>192.168.1.235</td><td>Debian 11 (Bullseye)</td><td>Haproxy + Keepalived</td></tr><tr><td>Haproxy 节点二</td><td> haproxy-node-2</td><td>192.168.1.239</td><td>Debian 11 (Bullseye)</td><td>Haproxy + Keepalived</td></tr></tbody></table><div class="admonition note"><p class="admonition-title">提示</p><ul><li>Percona XtraDB Cluster 要求最小的集群大小是 3 个节点。</li><li>建议尽可能地控制 PXC 集群的规模，节点越多，数据同步速度越慢。</li><li>PXC 存在硬件配置短板限制，即整个集群的写吞吐量受最弱节点的限制。因此所有 PXC 节点的硬件配置要一致，否则如果一个节点变慢，整个集群会跟着变慢。</li></ul></div><h2 id="系统初始化"><a href="#系统初始化" class="headerlink" title="系统初始化"></a>系统初始化</h2><h3 id="配置-Host"><a href="#配置-Host" class="headerlink" title="配置 Host"></a>配置 Host</h3><p>在每个节点服务器上编辑 <code>/etc/hosts</code> 文件，加入以下内容：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.188    pxc-node-1</span><br><span class="line">192.168.1.193    pxc-node-2</span><br><span class="line">192.168.1.223    pxc-node-3</span><br><span class="line">192.168.1.235    haproxy-node-1</span><br><span class="line">192.168.1.239    haproxy-node-2</span><br></pre></td></tr></tbody></table></figure><h3 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h3><p>在每个节点服务器上设置主机名。若由于其他限制导致不允许更改主机名，则可以跳过以下步骤。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看主机名</span></span><br><span class="line">$ hostnamectl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久更改主机名</span></span><br><span class="line">$ sudo hostnamectl set-hostname xx-xxxx</span><br></pre></td></tr></tbody></table></figure><h3 id="配置防火墙"><a href="#配置防火墙" class="headerlink" title="配置防火墙"></a>配置防火墙</h3><p>在配置系统防火墙之前，在每个服务器上分别安装 UFW 防火墙工具。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装ufw</span></span><br><span class="line">sudo apt install ufw</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开放SSH端口</span></span><br><span class="line">sudo ufw allow OpenSSH</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用ufw</span></span><br><span class="line">sudo ufw <span class="built_in">enable</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ufw的运行状态</span></span><br><span class="line">sudo ufw status</span><br></pre></td></tr></tbody></table></figure><h4 id="PXC-集群的防火墙"><a href="#PXC-集群的防火墙" class="headerlink" title="PXC 集群的防火墙"></a>PXC 集群的防火墙</h4><p>在本节中，将在每个 PXC 集群节点服务器上使用 UFW 配置防火墙，使 PXC 集群节点之间可以互相通信。</p><ul><li><p>PXC 集群默认会使用到以下端口</p><ul><li><code>3306</code></li><li><code>4444</code></li><li><code>4567</code></li><li><code>4568</code></li></ul></li><li><p>基于 UFW 配置防火墙</p></li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开放 PXC 端口，192.168.1.0/24 是所有 PXC 集群节点的子网地址</span></span><br><span class="line">sudo ufw allow from 192.168.1.0/24 proto tcp to any port 3306</span><br><span class="line">sudo ufw allow from 192.168.1.0/24 proto tcp to any port 4444</span><br><span class="line">sudo ufw allow from 192.168.1.0/24 proto tcp to any port 4567</span><br><span class="line">sudo ufw allow from 192.168.1.0/24 proto tcp to any port 4568</span><br></pre></td></tr></tbody></table></figure><ul><li>查看 UFW 的运行状态 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看ufw的运行状态</span></span><br><span class="line">sudo ufw status</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Status: active</span><br><span class="line"></span><br><span class="line">To                         Action      From</span><br><span class="line">--                         ------      ----</span><br><span class="line">OpenSSH                    ALLOW       Anywhere                  </span><br><span class="line">3306/tcp                   ALLOW       192.168.1.0/24            </span><br><span class="line">4444/tcp                   ALLOW       192.168.1.0/24            </span><br><span class="line">4567/tcp                   ALLOW       192.168.1.0/24            </span><br><span class="line">4568/tcp                   ALLOW       192.168.1.0/24            </span><br><span class="line">OpenSSH (v6)               ALLOW       Anywhere (v6)     </span><br></pre></td></tr></tbody></table></figure><h4 id="Haproxy-的防火墙"><a href="#Haproxy-的防火墙" class="headerlink" title="Haproxy 的防火墙"></a>Haproxy 的防火墙</h4><p>在本节中，将在每个 Haproxy 节点服务器上使用 UFW 配置防火墙，使外部可以正常访问 Haproxy。</p><ul><li><p>Haproxy 默认会使用到以下端口</p><ul><li><code>3306</code>：Haproxy 代理 MySQL 的端口</li><li><code>8888</code>：Haproxy 监控页面的 Web 端口</li></ul></li><li><p>基于 UFW 配置防火墙</p></li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开放 Haproxy 端口，192.168.1.0/24 是所有 Haproxy 节点的子网地址</span></span><br><span class="line">sudo ufw allow from 192.168.1.0/24 proto tcp to any port 3306</span><br><span class="line">sudo ufw allow from 192.168.1.0/24 proto tcp to any port 8888</span><br></pre></td></tr></tbody></table></figure><ul><li>查看 UFW 的运行状态 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看ufw的运行状态</span></span><br><span class="line">sudo ufw status</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Status: active</span><br><span class="line"></span><br><span class="line">To                         Action      From</span><br><span class="line">--                         ------      ----</span><br><span class="line">OpenSSH                    ALLOW       Anywhere                  </span><br><span class="line">3306/tcp                   ALLOW       192.168.1.0/24            </span><br><span class="line">8888/tcp                   ALLOW       192.168.1.0/24            </span><br><span class="line">OpenSSH (v6)               ALLOW       Anywhere (v6)   </span><br></pre></td></tr></tbody></table></figure><h4 id="Keepalived-的防火墙"><a href="#Keepalived-的防火墙" class="headerlink" title="Keepalived 的防火墙"></a>Keepalived 的防火墙</h4><p>在本节中，将在每个 Keepalived 节点服务器上使用 UFW 配置防火墙，使 Keepalived 节点之间可以互相进行心跳通信。</p><ul><li><p>Keepalived 心跳通信</p><ul><li>Keepalived 使用 VRRP 协议进行通信（协议号码为 <code>112</code>）</li><li>Keepalived 用于心跳通信的默认 VRRP 广播地址是 <code>224.0.0.18</code></li><li>如果 Keepalived 节点之间不能正常进行心跳通信，就会发生脑裂现象，即多个 Keepalived 节点会同时抢占到虚拟 IP</li></ul></li><li><p> 基于 UFW 配置防火墙</p></li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开放 VRRP 广播地址，enp0s3 是网卡接口，192.168.1.0/24 是所有 Keepalived 节点的子网地址</span></span><br><span class="line">ufw allow <span class="keyword">in</span> on enp0s3 from 192.168.1.0/24 to 224.0.0.18;</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Status: active</span><br><span class="line"></span><br><span class="line">To                         Action      From</span><br><span class="line">--                         ------      ----</span><br><span class="line">OpenSSH                    ALLOW       Anywhere                  </span><br><span class="line">3306/tcp                   ALLOW       192.168.1.0/24            </span><br><span class="line">8888/tcp                   ALLOW       192.168.1.0/24            </span><br><span class="line">224.0.0.18 on enp0s3       ALLOW       192.168.1.0/24            </span><br><span class="line">OpenSSH (v6)               ALLOW       Anywhere (v6)   </span><br></pre></td></tr></tbody></table></figure><h3 id="关闭-SeLinux"><a href="#关闭-SeLinux" class="headerlink" title="关闭 SeLinux"></a>关闭 SeLinux</h3><p>在本节中，将在每个节点服务器上永久关闭 SeLinux，保证 PXC 集群节点可以互相通信。值得一提的是，如果系统没有安装 SeLinux，则可以跳过以下步骤。</p><ul><li>编辑 SeLinux 的配置文件 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑配置文件</span></span><br><span class="line">sudo vi /etc/selinux/config</span><br></pre></td></tr></tbody></table></figure><ul><li>将 <code>SELINUX</code> 的值设置为 <code>disabled</code></li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># This file controls the state of SELinux on the system.</span><br><span class="line"># SELINUX= can take one of these three values:</span><br><span class="line">#     enforcing - SELinux security policy is enforced.</span><br><span class="line">#     permissive - SELinux prints warnings instead of enforcing.</span><br><span class="line">#     disabled - No SELinux policy is loaded.</span><br><span class="line">SELINUX=disabled</span><br><span class="line"># SELINUXTYPE= can take one of three two values:</span><br><span class="line">#     targeted - Targeted processes are protected,</span><br><span class="line">#     minimum - Modification of targeted policy. Only selected processes are protected.</span><br><span class="line">#     mls - Multi Level Security protection.</span><br><span class="line">SELINUXTYPE=targeted</span><br></pre></td></tr></tbody></table></figure><h3 id="系统性能优化"><a href="#系统性能优化" class="headerlink" title="系统性能优化"></a>系统性能优化</h3><p>在本节中，将在每个节点服务器上更改系统的最大打开文件描述符数，且更改永久生效。</p><div class="admonition note"><p class="admonition-title">提示</p><ul><li>关于更改最大打开文件描述符数的详细教程，可以看 <a href="/posts/88a10b.html">这里</a>。</li><li>PXC 集群无需配置 Percona Server 数据库的最大打开文件描述符数，因为在 Percona Server 服务的配置文件 <code>/lib/systemd/system/mysql.service</code> 和 <code>/lib/systemd/system/mysql@.service</code> 中，默认都已经配置了 <code>LimitNOFILE=16364</code>。</li></ul></div><ul><li>查看限制 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ulimit</span> -n</span><br></pre></td></tr></tbody></table></figure><ul><li>更改配置 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一步</span></span><br><span class="line">sudo vim /etc/security/limits.conf</span><br><span class="line"></span><br><span class="line">* soft nofile 1048576</span><br><span class="line">* hard nofile 1048576</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步</span></span><br><span class="line">sudo vim /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">fs.file-max = 1048576</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三步（重启系统）</span></span><br><span class="line">sudo reboot</span><br></pre></td></tr></tbody></table></figure><ul><li>验证生效 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ulimit</span> -n</span><br><span class="line"></span><br><span class="line">sudo sysctl fs.file-max</span><br></pre></td></tr></tbody></table></figure><h3 id="卸载已安装软件"><a href="#卸载已安装软件" class="headerlink" title="卸载已安装软件"></a>卸载已安装软件</h3><p>检查每个节点服务器上的 Debian 系统是否已经安装过 MySQL、MariaDB、Percona Server 数据库，如果安装过请先卸载掉，然后再安装 PXC 集群。</p><h3 id="检查交换分区的大小"><a href="#检查交换分区的大小" class="headerlink" title="检查交换分区的大小"></a>检查交换分区的大小</h3><p>检查每个节点服务器上的交换分区大小，如果 Debian 系统没有交换分区，则建议手动创建并挂载，详细教程请看 <a href="/posts/9301e8fd.html">这里</a>。</p><ul><li>交换分区大小配置规则<ul><li>如果 RAM 介于 2 GB 和 8 GB 之间，则 SWAP 为 RAM 大小的 2 倍。</li><li>如果 RAM 在 8 GB 到 32 GB 之间，则 SWAP 为 RAM 大小的 1.5 倍。</li><li>如果 RAM 大于 32 GB，则 SWAP 为 32 GB。</li></ul></li></ul><h2 id="PXC-集群安装"><a href="#PXC-集群安装" class="headerlink" title="PXC 集群安装"></a>PXC 集群安装</h2><p>在本节中，将在每个节点服务器上，基于 Debian 11 添加并设置 Percona XtraDB Cluster 存储库，然后安装 Percona XtraDB Cluster 软件包。此外，在安装过程中，系统会提示设置 MySQL 的 <code>root</code> 账号的密码，并为 Percona XtraDB Cluster 设置默认身份验证插件。最后，将通过配置的 <code>root</code> 用户和密码登录数据库，验证 Percona XtraDB Cluster 的安装。值得一提的，PXC 集群的部署规划如下表所示：</p><table><thead><tr><th>节点名称</th><th>主机名</th><th> IP</th><th> 系统</th><th>说明</th></tr></thead><tbody><tr><td> PXC 节点一</td><td> pxc-node-1</td><td>192.168.1.188</td><td>Debian 11 (Bullseye)</td><td>Percona XtraDB Cluster (PXC)</td></tr><tr><td>PXC 节点二</td><td> pxc-node-2</td><td>192.168.1.193</td><td>Debian 11 (Bullseye)</td><td>Percona XtraDB Cluster (PXC)</td></tr><tr><td>PXC 节点三</td><td> pxc-node-3</td><td>192.168.1.223</td><td>Debian 11 (Bullseye)</td><td>Percona XtraDB Cluster (PXC)</td></tr></tbody></table><h3 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h3><ul><li>安装基础依赖 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">sudo apt install -y wget gnupg2 lsb-release curl</span><br></pre></td></tr></tbody></table></figure><ul><li>安装 Percona XtraDB Cluster 的存储库包 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载存储库包</span></span><br><span class="line">wget -q https://repo.percona.com/apt/percona-release_latest.generic_all.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装存储库包</span></span><br><span class="line">sudo dpkg -i percona-release_latest.generic_all.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新包索引信息</span></span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></tbody></table></figure><ul><li>启用 Percona XtraDB Cluster 8.0 （相当于 MySQL 8.0）的存储库 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo percona-release setup pxc80</span><br></pre></td></tr></tbody></table></figure><ul><li>安装 Percona XtraDB Cluster 软件包 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装PXC软件包</span></span><br><span class="line">sudo apt install -y percona-xtradb-cluster</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者使用代理，如果网络很卡导致安装失败，建议使用代理进行安装</span></span><br><span class="line">sudo apt install -y -o Acquire::http::proxy=<span class="string">"socks5h://127.0.0.1:1080/"</span> percona-xtradb-cluster</span><br></pre></td></tr></tbody></table></figure><ul><li>选择默认的认证插件（建议选择强加密）</li></ul><p><img data-src="../../../asset/2023/10/mysql-pxc8-7.png"></p><ul><li>根据提示输入 <code>root</code> 账号的密码（强）</li></ul><p><img data-src="../../../asset/2023/10/mysql-pxc8-1.png"></p><ul><li>根据提示确认 <code>root</code> 账号的密码（强）</li></ul><p><img data-src="../../../asset/2023/10/mysql-pxc8-2.png"></p><ul><li>启动 MySQL 服务 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">sudo systemctl start mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看服务状态</span></span><br><span class="line">sudo systemctl status mysql</span><br></pre></td></tr></tbody></table></figure><h3 id="安装测试"><a href="#安装测试" class="headerlink" title="安装测试"></a>安装测试</h3><p>在每个节点服务器上执行以下命令，然后输入 <code>root</code> 账号的密码，若能成功登录 MySQL，则说明数据库正常运行。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录MySQL</span></span><br><span class="line">sudo mysql -h localhost -u root -p</span><br></pre></td></tr></tbody></table></figure><h2 id="PXC-集群配置"><a href="#PXC-集群配置" class="headerlink" title="PXC 集群配置"></a>PXC 集群配置</h2><p><strong>特别注意，在开始配置 Percona XtraDB Cluster 集群之前，必须确保所有节点上的 MySQL 服务器都已停止运行。</strong></p><ul><li>关闭第一个节点（负责集群初始化）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭服务</span></span><br><span class="line">sudo systemctl stop mysql@bootstrap.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看服务状态</span></span><br><span class="line">sudo systemctl status mysql@bootstrap.service</span><br></pre></td></tr></tbody></table></figure><ul><li>关闭其他节点 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭服务</span></span><br><span class="line">sudo systemctl stop mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看服务状态</span></span><br><span class="line">sudo systemctl status mysql</span><br></pre></td></tr></tbody></table></figure><h3 id="拷贝-SSL-TLS-证书"><a href="#拷贝-SSL-TLS-证书" class="headerlink" title="拷贝 SSL/TLS 证书"></a>拷贝 SSL/TLS 证书</h3><p>Percona XtraDB Cluster 有两种流量加密：客户端 / 服务器连接和复制流量。在最新的 Percona XtraDB Cluster 8.0 上，默认情况下会启用所有复制流量的加密以增强安全性。因此在创建和设置 Percona XtraDB Cluster 时，所有服务器都必须具有相同的 CA 和 Server 证书，即必须将默认的 CA 和 Server 证书从 <code>pxc-node-1</code> 节点拷贝到 <code>pxc-node-2</code> 节点和 <code>pxc-node-3</code> 节点。</p><ul><li>在 PXC 集群安装的过程中，SSL/TLS 证书已经在数据目录 <code>/var/lib/mysql</code> 下自动生成了，包括 Client、Server、CA 三种类型的证书 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看SSL/TLC证书列表</span></span><br><span class="line">ls /var/lib/mysql/*.pem</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/var/lib/mysql/ca.pem</span><br><span class="line">/var/lib/mysql/ca-key.pem</span><br><span class="line">/var/lib/mysql/public_key.pem</span><br><span class="line">/var/lib/mysql/private_key.pem</span><br><span class="line">/var/lib/mysql/client-key.pem</span><br><span class="line">/var/lib/mysql/client-cert.pem</span><br><span class="line">/var/lib/mysql/server-key.pem</span><br><span class="line">/var/lib/mysql/server-cert.pem</span><br></pre></td></tr></tbody></table></figure><ul><li>在 <code>pxc-node-1</code> 节点上，拷贝 CA 和 Server 证书到 <code>pxc-node-2</code> 节点和 <code>pxc-node-3</code> 节点。</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入证书目录</span></span><br><span class="line"><span class="built_in">cd</span> /var/lib/mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝证书</span></span><br><span class="line">scp server-key.pem server-cert.pem ca.pem root@pxc-node-2:/var/lib/mysql</span><br><span class="line">scp server-key.pem server-cert.pem ca.pem root@pxc-node-3:/var/lib/mysql</span><br></pre></td></tr></tbody></table></figure><h3 id="在第一个节点上初始化集群"><a href="#在第一个节点上初始化集群" class="headerlink" title="在第一个节点上初始化集群"></a>在第一个节点上初始化集群</h3><p>在本节中，将在第一个节点服务器 <code>pxc-node-1</code> 上初始化 Percona XtraDB Cluster 集群（即引导 PXC 集群启动）。<strong>请确保以下步骤都是在节点一服务器上执行。</strong></p><ul><li>编辑节点一的 MySQL 配置文件，添加以下配置内容 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份配置文件</span></span><br><span class="line">sudo cp /etc/mysql/mysql.conf.d/mysqld.cnf /etc/mysql/mysql.conf.d/mysqld.cnf.bak</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑配置文件</span></span><br><span class="line">sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[client]</span><br><span class="line">socket=/var/run/mysqld/mysqld.sock</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">server-id=1</span><br><span class="line">datadir=/var/lib/mysql</span><br><span class="line">socket=/var/run/mysqld/mysqld.sock</span><br><span class="line">log-error=/var/log/mysql/error.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line"></span><br><span class="line">######## wsrep ###############</span><br><span class="line"></span><br><span class="line"># Path to Galera library</span><br><span class="line">wsrep_provider=/usr/lib/libgalera_smm.so</span><br><span class="line"></span><br><span class="line"># Cluster connection URL contains the IPs of pxc01, pxc02, and pxc03</span><br><span class="line">wsrep_cluster_address=gcomm://192.168.1.188,192.168.1.193,192.168.1.223</span><br><span class="line"></span><br><span class="line"># In order for Galera to work correctly binlog format should be ROW</span><br><span class="line">binlog_format=ROW</span><br><span class="line"></span><br><span class="line"># Slave thread to use</span><br><span class="line">wsrep_slave_threads=4</span><br><span class="line"></span><br><span class="line"># Using the MyISAM storage engine is not recommended.</span><br><span class="line">default_storage_engine=InnoDB</span><br><span class="line"></span><br><span class="line"># This InnoDB autoincrement locking mode is a requirement for Galera</span><br><span class="line">innodb_autoinc_lock_mode=2</span><br><span class="line"></span><br><span class="line"># Node 1 address</span><br><span class="line">wsrep_node_address=192.168.1.188</span><br><span class="line"></span><br><span class="line"># SST method</span><br><span class="line">wsrep_sst_method=xtrabackup-v2</span><br><span class="line"></span><br><span class="line"># Cluster name</span><br><span class="line">wsrep_cluster_name=pxc_cluster</span><br><span class="line"></span><br><span class="line"># If is not specified, then system hostname will be used</span><br><span class="line">wsrep_node_name=pxc-cluster-node-1</span><br><span class="line"></span><br><span class="line"># PXC Strict Mode allowed values: DISABLED,PERMISSIVE,ENFORCING,MASTER</span><br><span class="line">pxc_strict_mode=ENFORCING</span><br><span class="line"></span><br><span class="line">wsrep_provider_options="socket.ssl_key=server-key.pem;socket.ssl_cert=server-cert.pem;socket.ssl_ca=ca.pem"</span><br><span class="line"></span><br><span class="line">[sst]</span><br><span class="line">encrypt=4</span><br><span class="line">ssl-key=server-key.pem</span><br><span class="line">ssl-ca=ca.pem</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">核心参数说明：</span><br><span class="line">    - `wsrep_cluster_name`：集群的名称</span><br><span class="line">    - `server-id`：MySQL 实例的唯一标识符（每个节点都不一样）</span><br><span class="line">    - `wsrep_node_name`：当前节点服务器的名称（每个节点都不一样），如果不指定默认使用主机名</span><br><span class="line">    - `wsrep_node_address`：当前节点服务器的 IP 地址（每个节点都不一样）</span><br><span class="line">    - `wsrep_cluster_address`：所有节点服务器的 IP 地址</span><br><span class="line"></span><br><span class="line">其他参数说明：</span><br><span class="line">    - `default_storage_engine=InnoDB`：指定默认的存储引擎为 InnoDB</span><br><span class="line">    - `innodb_autoinc_lock_mode=2`：该模式下所有 INSERT SQL 都不会有表级 AUTO-INC 锁，即多个语句可以同时执行</span><br><span class="line">    - `pxc_strict_mode=ENFORCING`：严厉模式，`ENFORCING` 表示会阻止用户执行 Percona XtraDB Cluster 所不支持的功能</span><br></pre></td></tr></tbody></table></figure><ul><li>初始化集群 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动节点一的MySQL服务（初始化集群）</span></span><br><span class="line">systemctl start mysql@bootstrap.service</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><code>mysql@bootstrap</code> 是一个用于运行 Percona XtraDB Cluster 的 Systemd 服务，这与普通的 <code>mysql</code> 服务有本质的区别，主要用于 PXC 集群的初始化（即引导 PXC 集群启动）。</li><li>使用 Percona XtraDB Cluster 构建 MySQL 服务器时，第一个节点必须使用 <code>mysql@bootstrap</code> 服务进行管理，包括启动、关闭、重启、查看状态等操作（如下所示），而其他节点则可以直接使用普通的 <code>mysql</code> 服务进行管理。</li><li>启动第一个节点服务器：<code>systemctl start mysql@bootstrap.service</code>。</li><li>关闭第一个节点服务器：<code>systemctl stop mysql@bootstrap.service</code>。</li><li>重启第一个节点服务器：<code>systemctl restart mysql@bootstrap.service</code>。</li><li>查看第一个节点服务器的状态：<code>systemctl status mysql@bootstrap.service</code>。</li></ul></div><ul><li>验证集群的初始化是否成功 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录MySQL</span></span><br><span class="line">sudo mysql -h localhost -u root -p</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看集群状态</span></span><br><span class="line">show status like <span class="string">'wsrep%'</span>;</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>当 PXC 集群初始化成功后，应该可以看到下述的状态信息。<code>wsrep_cluster_size</code> 的值是 <code>1</code>，这意味着 Percona XtraDB Cluster 是用一台服务器初始化的。<code>wsrep_incoming_address</code> 的值是节点一服务器的 IP 地址。最后，节点处于 <code>Synced</code> 状态，这意味着它已完全连接并准备好进行写集复制。</p></div><p><img data-src="../../../asset/2023/10/mysql-pxc8-3.png"></p><h3 id="将第二个节点添加到集群中"><a href="#将第二个节点添加到集群中" class="headerlink" title="将第二个节点添加到集群中"></a>将第二个节点添加到集群中</h3><ul><li>编辑节点二的 MySQL 配置文件，添加以下内容 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份配置文件</span></span><br><span class="line">sudo cp /etc/mysql/mysql.conf.d/mysqld.cnf /etc/mysql/mysql.conf.d/mysqld.cnf.bak</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑配置文件</span></span><br><span class="line">sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[client]</span><br><span class="line">socket=/var/run/mysqld/mysqld.sock</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">server-id=2</span><br><span class="line">datadir=/var/lib/mysql</span><br><span class="line">socket=/var/run/mysqld/mysqld.sock</span><br><span class="line">log-error=/var/log/mysql/error.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line"></span><br><span class="line">######## wsrep ###############</span><br><span class="line"></span><br><span class="line"># Path to Galera library</span><br><span class="line">wsrep_provider=/usr/lib/libgalera_smm.so</span><br><span class="line"></span><br><span class="line"># Cluster connection URL contains the IPs of pxc01, pxc02, and pxc03</span><br><span class="line">wsrep_cluster_address=gcomm://192.168.1.188,192.168.1.193,192.168.1.223</span><br><span class="line"></span><br><span class="line"># In order for Galera to work correctly binlog format should be ROW</span><br><span class="line">binlog_format=ROW</span><br><span class="line"></span><br><span class="line"># Slave thread to use</span><br><span class="line">wsrep_slave_threads=4</span><br><span class="line"></span><br><span class="line"># Using the MyISAM storage engine is not recommended.</span><br><span class="line">default_storage_engine=InnoDB</span><br><span class="line"></span><br><span class="line"># This InnoDB autoincrement locking mode is a requirement for Galera</span><br><span class="line">innodb_autoinc_lock_mode=2</span><br><span class="line"></span><br><span class="line"># Node 2 address</span><br><span class="line">wsrep_node_address=192.168.1.193</span><br><span class="line"></span><br><span class="line"># SST method</span><br><span class="line">wsrep_sst_method=xtrabackup-v2</span><br><span class="line"></span><br><span class="line"># Cluster name</span><br><span class="line">wsrep_cluster_name=pxc_cluster</span><br><span class="line"></span><br><span class="line"># If is not specified, then system hostname will be used</span><br><span class="line">wsrep_node_name=pxc-cluster-node-2</span><br><span class="line"></span><br><span class="line"># PXC Strict Mode allowed values: DISABLED,PERMISSIVE,ENFORCING,MASTER</span><br><span class="line">pxc_strict_mode=ENFORCING</span><br><span class="line"></span><br><span class="line">wsrep_provider_options="socket.ssl_key=server-key.pem;socket.ssl_cert=server-cert.pem;socket.ssl_ca=ca.pem"</span><br><span class="line"></span><br><span class="line">[sst]</span><br><span class="line">encrypt=4</span><br><span class="line">ssl-key=server-key.pem</span><br><span class="line">ssl-ca=ca.pem</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p><code>server-id</code>、<code>wsrep_node_address</code>、<code>wsrep_node_name</code> 这三个参数必须跟其他节点一、节点三不一样。</p></div><ul><li>验证节点二是否成功添加到集群，在节点二服务器上执行以下命令 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动MySQL服务</span></span><br><span class="line">sudo systemctl start mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看MySQL服务的状态</span></span><br><span class="line">sudo systemctl status mysql</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录MySQL</span></span><br><span class="line">sudo mysql -h localhost -u root -p</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看集群状态</span></span><br><span class="line">show status like <span class="string">'wsrep%'</span>;</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/10/mysql-pxc8-4.png"></p><h3 id="将第三个节点添加到集群中"><a href="#将第三个节点添加到集群中" class="headerlink" title="将第三个节点添加到集群中"></a>将第三个节点添加到集群中</h3><ul><li>编辑节点三的 MySQL 配置文件，添加以下内容 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份配置文件</span></span><br><span class="line">sudo cp /etc/mysql/mysql.conf.d/mysqld.cnf /etc/mysql/mysql.conf.d/mysqld.cnf.bak</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑配置文件</span></span><br><span class="line">sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[client]</span><br><span class="line">socket=/var/run/mysqld/mysqld.sock</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">server-id=3</span><br><span class="line">datadir=/var/lib/mysql</span><br><span class="line">socket=/var/run/mysqld/mysqld.sock</span><br><span class="line">log-error=/var/log/mysql/error.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line"></span><br><span class="line">######## wsrep ###############</span><br><span class="line"></span><br><span class="line"># Path to Galera library</span><br><span class="line">wsrep_provider=/usr/lib/libgalera_smm.so</span><br><span class="line"></span><br><span class="line"># Cluster connection URL contains the IPs of pxc01, pxc02, and pxc03</span><br><span class="line">wsrep_cluster_address=gcomm://192.168.1.188,192.168.1.193,192.168.1.223</span><br><span class="line"></span><br><span class="line"># In order for Galera to work correctly binlog format should be ROW</span><br><span class="line">binlog_format=ROW</span><br><span class="line"></span><br><span class="line"># Slave thread to use</span><br><span class="line">wsrep_slave_threads=4</span><br><span class="line"></span><br><span class="line"># Using the MyISAM storage engine is not recommended.</span><br><span class="line">default_storage_engine=InnoDB</span><br><span class="line"></span><br><span class="line"># This InnoDB autoincrement locking mode is a requirement for Galera</span><br><span class="line">innodb_autoinc_lock_mode=2</span><br><span class="line"></span><br><span class="line"># Node 3 address</span><br><span class="line">wsrep_node_address=192.168.1.223</span><br><span class="line"></span><br><span class="line"># SST method</span><br><span class="line">wsrep_sst_method=xtrabackup-v2</span><br><span class="line"></span><br><span class="line"># Cluster name</span><br><span class="line">wsrep_cluster_name=pxc_cluster</span><br><span class="line"></span><br><span class="line"># If is not specified, then system hostname will be used</span><br><span class="line">wsrep_node_name=pxc-cluster-node-3</span><br><span class="line"></span><br><span class="line"># PXC Strict Mode allowed values: DISABLED,PERMISSIVE,ENFORCING,MASTER</span><br><span class="line">pxc_strict_mode=ENFORCING</span><br><span class="line"></span><br><span class="line">wsrep_provider_options="socket.ssl_key=server-key.pem;socket.ssl_cert=server-cert.pem;socket.ssl_ca=ca.pem"</span><br><span class="line"></span><br><span class="line">[sst]</span><br><span class="line">encrypt=4</span><br><span class="line">ssl-key=server-key.pem</span><br><span class="line">ssl-ca=ca.pem</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p><code>server-id</code>、<code>wsrep_node_address</code>、<code>wsrep_node_name</code> 这三个参数必须跟其他节点一、节点二不一样。</p></div><ul><li>验证节点三是否成功添加到集群，在节点三服务器上执行以下命令 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动MySQL服务</span></span><br><span class="line">sudo systemctl start mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看MySQL服务的状态</span></span><br><span class="line">sudo systemctl status mysql</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录MySQL</span></span><br><span class="line">sudo mysql -h localhost -u root -p</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看集群状态</span></span><br><span class="line">show status like <span class="string">'wsrep%'</span>;</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/10/mysql-pxc8-5.png"></p><h2 id="PXC-集群测试"><a href="#PXC-集群测试" class="headerlink" title="PXC 集群测试"></a>PXC 集群测试</h2><p>在本节中，将对 PXC 集群的复制进行测试，包括创建数据库和表、插入数据。</p><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><ul><li>登录节点二的 MySQL 服务器，创建 <code>percona</code> 数据库 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建数据库</span></span><br><span class="line">CREATE DATABASE `percona` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;</span><br></pre></td></tr></tbody></table></figure><ul><li>登录节点一或者节点三的 MySQL 服务器，观察是否同步创建了相同的数据库 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据库列表</span></span><br><span class="line">SHOW DATABASES;</span><br></pre></td></tr></tbody></table></figure><h3 id="创建数据库表"><a href="#创建数据库表" class="headerlink" title="创建数据库表"></a>创建数据库表</h3><ul><li>登录节点三的 MySQL 服务器，创建 <code>example</code> 数据库表 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换数据库</span></span><br><span class="line">USE `percona`;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据库表</span></span><br><span class="line">CREATE TABLE example (node_id INT PRIMARY KEY, node_name VARCHAR(30));</span><br></pre></td></tr></tbody></table></figure><ul><li>登录节点一的 MySQL 服务器，往 <code>example</code> 数据库表插入数据 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换数据库</span></span><br><span class="line">USE `percona`;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插入数据</span></span><br><span class="line">INSERT INTO percona.example VALUES (1, <span class="string">'pxc01'</span>);</span><br><span class="line">INSERT INTO percona.example VALUES (2, <span class="string">'pxc02'</span>);</span><br><span class="line">INSERT INTO percona.example VALUES (3, <span class="string">'pxc03'</span>);</span><br></pre></td></tr></tbody></table></figure><ul><li>登录节点二的 MySQL 服务器，查询 <code>example</code> 表的数据 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换数据库</span></span><br><span class="line">USE `percona`;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询数据</span></span><br><span class="line">SELECT * FROM percona.example;</span><br></pre></td></tr></tbody></table></figure><h2 id="PXC-集群管理"><a href="#PXC-集群管理" class="headerlink" title="PXC 集群管理"></a>PXC 集群管理</h2><h3 id="创建用户操作"><a href="#创建用户操作" class="headerlink" title="创建用户操作"></a>创建用户操作</h3><p>登录任意一个 PXC 集群节点的数据库，执行以下命令创建新用户，并授权用户可以远程访问指定的数据库。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录MySQL</span></span><br><span class="line">sudo mysql -h localhost -u root -p</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用户</span></span><br><span class="line">CREATE USER <span class="string">'uatOption'</span>@<span class="string">'%'</span> IDENTIFIED WITH mysql_native_password BY <span class="string">'Pxc_User_123@456'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 授权远程访问指定的数据库</span></span><br><span class="line">GRANT ALL PRIVILEGES ON percona.* TO <span class="string">'uatOption'</span>@<span class="string">'%'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新权限信息</span></span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看用户列表</span></span><br><span class="line">SELECT host, user, plugin, authentication_string FROM mysql.user;</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>这里为了兼容 MySQL 5 的认证方式，建议在创建数据库用户时，指定加密规则为 <code>mysql_native_password</code>。值得一提的是，MySQL 8 默认使用的加密规则是 <code>caching_sha2_password</code>。</p></div><h3 id="集群各指标检查"><a href="#集群各指标检查" class="headerlink" title="集群各指标检查"></a>集群各指标检查</h3><p>在检测 PXC 集群各指标之前，先登录任意一个 PXC 集群节点的数据库，然后再执行其他操作。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录MySQL</span></span><br><span class="line">sudo mysql -h localhost -u root -p</span><br></pre></td></tr></tbody></table></figure><h4 id="集群完整性检查"><a href="#集群完整性检查" class="headerlink" title="集群完整性检查"></a>集群完整性检查</h4><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show global status <span class="built_in">where</span> variable_name <span class="keyword">in</span> (<span class="string">'wsrep_cluster_state_uuid'</span>,<span class="string">'wsrep_cluster_conf_id'</span>,<span class="string">'wsrep_cluster_size'</span>,<span class="string">'wsrep_cluster_status'</span>);</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+--------------------------+--------------------------------------+</span><br><span class="line">| Variable_name            | Value                                |</span><br><span class="line">+--------------------------+--------------------------------------+</span><br><span class="line">| wsrep_cluster_conf_id    | 7                                    |</span><br><span class="line">| wsrep_cluster_size       | 3                                    |</span><br><span class="line">| wsrep_cluster_state_uuid | e4bb8bf0-73d5-11ee-b279-3a5ebcc11ef7 |</span><br><span class="line">| wsrep_cluster_status     | Primary                              |</span><br><span class="line">+--------------------------+--------------------------------------+</span><br><span class="line">4 rows in set (0.00 sec)</span><br></pre></td></tr></tbody></table></figure><p>特别注意，在正常情况下以下指标值，在所有节点应该都是一致的。</p><table><thead><tr><th>指标</th><th>说明</th></tr></thead><tbody><tr><td><code>wsrep_cluster_state_uuid</code></td><td>在集群所有节点中该值应该是相同的，若有不同值，说明该节点没有连入集群。</td></tr><tr><td><code>wsrep_cluster_conf_id</code></td><td>在集群所有节点中该值应该是相同的，若有不同值，说明该节点被临时 <code>分区</code> 了，当节点之间网络连接恢复后，该值应该恢复成一致。</td></tr><tr><td><code>wsrep_cluster_size</code></td><td>如果与集群中的节点数一致，说明所有节点已经连接。</td></tr><tr><td><code>wsrep_cluster_status</code></td><td>集群状态，若不为 <code>Primary</code>，说明出现 <code>分区</code> 或是 <code>split-brain</code> 状况。</td></tr></tbody></table><h4 id="集群节点状态检查"><a href="#集群节点状态检查" class="headerlink" title="集群节点状态检查"></a>集群节点状态检查</h4><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show global status <span class="built_in">where</span> variable_name <span class="keyword">in</span> (<span class="string">'wsrep_ready'</span>,<span class="string">'wsrep_connected'</span>,<span class="string">'wsrep_local_state_comment'</span>);</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+---------------------------+--------+</span><br><span class="line">| Variable_name             | Value  |</span><br><span class="line">+---------------------------+--------+</span><br><span class="line">| wsrep_connected           | ON     |</span><br><span class="line">| wsrep_local_state_comment | Synced |</span><br><span class="line">| wsrep_ready               | ON     |</span><br><span class="line">+---------------------------+--------+</span><br></pre></td></tr></tbody></table></figure><p>特别注意，在正常情况下以下指标值，在所有节点应该都是一致的。</p><table><thead><tr><th>指标</th><th>说明</th></tr></thead><tbody><tr><td><code>wsrep_ready</code></td><td>该值为 <code>ON</code>，则说明可以接受 SQL 负载；如果为 <code>OFF</code>，则需要检查 <code>wsrep_connected</code>。</td></tr><tr><td><code>wsrep_connected</code></td><td>如果该值为 <code>OFF</code>，且 <code>wsrep_ready</code> 的值也为 <code>OFF</code>，则说明该节点没有连入集群，可能是 <code>wsrep_cluster_address</code> 或 <code>wsrep_cluster_name</code> 等配置错误造成的，具体需要排查 MySQL 的错误日志。</td></tr><tr><td><code>wsrep_local_state_comment</code></td><td>若 <code>wsrep_connected</code> 为 <code>ON</code>，但 <code>wsrep_ready</code> 为 <code>OFF</code>，则可以从该项查找错误原因。</td></tr></tbody></table><h4 id="集群健康信息检查"><a href="#集群健康信息检查" class="headerlink" title="集群健康信息检查"></a>集群健康信息检查</h4><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show global status <span class="built_in">where</span> variable_name <span class="keyword">in</span> (<span class="string">'wsrep_flow_control_paused'</span>,<span class="string">'wsrep_cert_deps_distance'</span>,<span class="string">'wsrep_flow_control_sent'</span>,<span class="string">'wsrep_local_recv_queue_avg'</span>);</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+----------------------------+-------+</span><br><span class="line">| Variable_name              | Value |</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">| wsrep_cert_deps_distance   | 1     |</span><br><span class="line">| wsrep_flow_control_paused  | 0     |</span><br><span class="line">| wsrep_flow_control_sent    | 0     |</span><br><span class="line">| wsrep_local_recv_queue_avg | 0     |</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">4 rows in set (0.00 sec)</span><br></pre></td></tr></tbody></table></figure><table><thead><tr><th>指标</th><th>说明</th></tr></thead><tbody><tr><td><code>wsrep_flow_control_paused</code></td><td>表示数据复制停止了多长时间（即因 Slave 延迟而慢的程度，取值范围为 0 ~ 1，越靠近 0 越好，值为 1 表示数据复制完全停止（停止广播），可优化 <code>wsrep_slave_threads</code> 的值来改善）。</td></tr><tr><td><code>wsrep_cert_deps_distance</code></td><td>表示有多少事务可以并行应用处理，<code>wsrep_slave_threads</code> 设置的值不应该高出该值太多。</td></tr><tr><td><code>wsrep_flow_control_sent</code></td><td>表示该节点已经停止复制了多少次。</td></tr><tr><td><code>wsrep_local_recv_queue_avg</code></td><td>表示 Slave 事务队列的平均长度，可作为 Slave 瓶颈的预兆。</td></tr></tbody></table><h2 id="Haproxy-Keepalived-双机热备"><a href="#Haproxy-Keepalived-双机热备" class="headerlink" title="Haproxy + Keepalived 双机热备"></a>Haproxy + Keepalived 双机热备</h2><p>在本节中，将使用 Haproxy + Keepalived 实现双机热备方案，其中 Haproxy 负责将请求转发给 PXC 集群各个节点。值得一提的，Haproxy 与 Keepalived 的部署规划如下表所示：</p><table><thead><tr><th>节点名称</th><th>主机名</th><th> IP</th><th> 系统</th><th>说明</th></tr></thead><tbody><tr><td> Haproxy 节点一</td><td> haproxy-node-1</td><td>192.168.1.235</td><td>Debian 11 (Bullseye)</td><td>Haproxy + Keepalived</td></tr><tr><td>Haproxy 节点二</td><td> haproxy-node-2</td><td>192.168.1.239</td><td>Debian 11 (Bullseye)</td><td>Haproxy + Keepalived</td></tr></tbody></table><h3 id="双机热备架构"><a href="#双机热备架构" class="headerlink" title="双机热备架构"></a>双机热备架构</h3><p><img data-src="../../../asset/2023/10/mysql-pxc8-6.png"></p><h3 id="创建数据库用户"><a href="#创建数据库用户" class="headerlink" title="创建数据库用户"></a>创建数据库用户</h3><p>在本节中，将创建 MySQL 用户，Haproxy 后续会使用这个用户对 PXC 集群节点进行心跳检测。</p><ul><li>登录任意一个 PXC 集群节点的数据库 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录MySQL</span></span><br><span class="line">sudo mysql -h localhost -u root -p</span><br></pre></td></tr></tbody></table></figure><ul><li>创建数据库用户 <code>haproxy</code>，不指定密码和权限，只允许远程访问 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用户</span></span><br><span class="line">CREATE USER <span class="string">'haproxy'</span>@<span class="string">'%'</span> IDENTIFIED WITH mysql_native_password;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新权限信息</span></span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看用户列表</span></span><br><span class="line">SELECT host, user, plugin, authentication_string FROM mysql.user;</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>MySQL 8.0 默认使用的加密规则是 <code>caching_sha2_password</code>，为了让 Haproxy 可以对 PXC 集群节点进行心跳检测，在创建数据库用户时，必须指定加密规则为 <code>mysql_native_password</code>，否则 Haproxy 无法正常检测 PXC 集群节点的运行状态。</p></div><h3 id="Haproxy-安装"><a href="#Haproxy-安装" class="headerlink" title="Haproxy 安装"></a>Haproxy 安装</h3><p>在本节中，将在两个单独的服务器节点上分别安装 Haproxy 服务（两个节点的安装步骤和配置内容基本一致），实现对 PXC 集群的负载均衡。</p><ul><li>安装 Haproxy</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">sudo apt-get install -y haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> haproxy</span><br></pre></td></tr></tbody></table></figure><ul><li>配置 Haproxy</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份Haproxy的配置文件</span></span><br><span class="line">sudo cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑Haproxy的配置文件，添加以下内容</span></span><br><span class="line">sudo vim /etc/haproxy/haproxy.cfg</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">    # 工作目录</span><br><span class="line">    # chroot /usr/local/etc/haproxy</span><br><span class="line">    # 日志文件，使用rsyslog服务中local5日志设备（/var/log/local5），等级info</span><br><span class="line">    log 127.0.0.1 local5 info</span><br><span class="line">    # 以守护进程运行</span><br><span class="line">    daemon</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    log    global</span><br><span class="line">    mode    http</span><br><span class="line">    # 日志格式</span><br><span class="line">    option    httplog</span><br><span class="line">    # 日志中不记录负载均衡的心跳检测记录</span><br><span class="line">    option    dontlognull</span><br><span class="line">    # 连接超时（毫秒）</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    # 客户端超时（毫秒）</span><br><span class="line">    timeout client  50000</span><br><span class="line">    # 服务器超时（毫秒）</span><br><span class="line">    timeout server  50000</span><br><span class="line"></span><br><span class="line"># 监控界面    </span><br><span class="line">listen  admin_stats</span><br><span class="line">    # 监控界面的访问的IP和端口</span><br><span class="line">    bind  0.0.0.0:8888</span><br><span class="line">    # 访问协议</span><br><span class="line">    mode        http</span><br><span class="line">    # URI相对地址</span><br><span class="line">    stats uri   /dbs</span><br><span class="line">    # 统计报告格式</span><br><span class="line">    stats realm     Global\ statistics</span><br><span class="line">    # 登陆账户信息</span><br><span class="line">    stats auth  admin:admin</span><br><span class="line"># 数据库负载均衡</span><br><span class="line">listen  proxy-pxc</span><br><span class="line">    # 访问的IP和端口</span><br><span class="line">    bind  0.0.0.0:3306</span><br><span class="line">    # 网络协议</span><br><span class="line">    mode  tcp</span><br><span class="line">    # 负载均衡算法（轮询算法）</span><br><span class="line">    # 轮询算法：roundrobin</span><br><span class="line">    # 权重算法：static-rr</span><br><span class="line">    # 最少连接算法：leastconn</span><br><span class="line">    # 请求源IP算法：source </span><br><span class="line">    balance  roundrobin</span><br><span class="line">    # 日志格式</span><br><span class="line">    option  tcplog</span><br><span class="line">    # Haproxy使用MySQL的haproxy账户对数据库进行心跳检测</span><br><span class="line">    option  mysql-check user haproxy</span><br><span class="line">    server  PXC_Node_1 192.168.1.188:3306 check weight 1 maxconn 2000  </span><br><span class="line">    server  PXC_Node_2 192.168.1.193:3306 check weight 1 maxconn 2000  </span><br><span class="line">    server  PXC_Node_3 192.168.1.223:3306 check weight 1 maxconn 2000 </span><br><span class="line">    # 使用Keepalived检测死链</span><br><span class="line">    option  tcpka</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">Haproxy 配置说明</p><ul><li><code>bind  0.0.0.0:8888</code>： <code>8888</code> 端口用于 Haproxy 提供监控界面的 Web 服务。</li><li><code>bind  0.0.0.0:3306</code>： <code>3306</code> 端口用于 Haproxy 转发请求给 PXC 集群节点。</li><li><code>option  mysql-check user haproxy</code>： 指定 Haproxy 使用 MySQL 的 <code>haproxy</code> 账户对 PXC 集群节点进行心跳检测。</li></ul></div><ul><li>重启 Haproxy</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启</span></span><br><span class="line">sudo systemctl restart haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行状态</span></span><br><span class="line">sudo systemctl status haproxy</span><br></pre></td></tr></tbody></table></figure><ul><li>测试 Haproxy</li></ul><p>使用浏览器访问不同节点的 Haproxy 监控页面（如下图所示），登录用户名是 <code>admin</code>，登录密码是 <code>admin</code>。如果可以正常访问 Haproxy 的监控界面，则说明 Haproxy 成功部署。</p><ul><li>Haproxy 节点一的监控页面： <code>http://192.168.1.235:8888/dbs</code></li><li>Haproxy 节点二的监控页面： <code>http://192.168.1.239:8888/dbs</code></li></ul><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-6.png"></p><h3 id="Keepalived-安装"><a href="#Keepalived-安装" class="headerlink" title="Keepalived 安装"></a>Keepalived 安装</h3><p>在本节中，将在两个单独的 Haproxy 服务器节点上分别安装 Keepalived 服务，实现 Haproxy + Keepalived 的双机热备方案。</p><div class="admonition note"><p class="admonition-title">提示</p><p>Keepalived 安装完成后，默认会将配置模板文件存放在 <code>/usr/share/doc/keepalived/samples/</code> 目录下。</p></div><h4 id="Haproxy-节点一安装-Keepalived"><a href="#Haproxy-节点一安装-Keepalived" class="headerlink" title="Haproxy 节点一安装 Keepalived"></a>Haproxy 节点一安装 Keepalived</h4><ul><li>安装 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">sudo apt-get install -y keepalived</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> keepalived</span><br></pre></td></tr></tbody></table></figure><ul><li>配置 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建或编辑Keepalived的配置文件，写入以下配置内容（请自行更改网卡设备参数）</span></span><br><span class="line">sudo vim /etc/keepalived/keepalived.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance  VI_1 {</span><br><span class="line">    state  MASTER           # 必填，Keepalived 的身份（MASTER 是主服务器，BACKUP 是备服务器）</span><br><span class="line">    interface  enp0s3       # 必填，系统的网卡设备，虚拟 IP 所在</span><br><span class="line">    virtual_router_id  51   # 必填，虚拟路由标识，取值在0-255之间，用来区分多个Instance的VRRP组播，同一网段内ID不能重复，主备机器的该值必须为一样</span><br><span class="line">    priority  100           # 必填，用来选举Master的，MASTER 权重要高于 BACKUP，数字越大优先级越高，该项取值范围是1-255（在此范围之外会被识别成默认值100）</span><br><span class="line">    advert_int  1           # 必填，MASTER 和 BACKUP 节点同步检查的时间间隔（单位为秒），主备之间必须一致，可以认为是健康检查的时间间隔</span><br><span class="line">    authentication {        # 必填，主备服务器的验证方式，主备之间必须使用相同的密码才能正常通信</span><br><span class="line">        auth_type  PASS     # 必填，主备服务器的认证方式，其中有两种方式PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位），主备之间必须使用相同的密码才能正常通信</span><br><span class="line">        auth_pass  123456</span><br><span class="line">    }</span><br><span class="line">    virtual_ipaddress {     # 必填，虚拟 IP，可以设置多个虚拟 IP 地址，每行一个</span><br><span class="line">        192.168.1.173</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>启动 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">sudo systemctl start keepalived</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行状态</span></span><br><span class="line">sudo systemctl status keepalived</span><br></pre></td></tr></tbody></table></figure><h4 id="Haproxy-节点二安装-Keepalived"><a href="#Haproxy-节点二安装-Keepalived" class="headerlink" title="Haproxy 节点二安装 Keepalived"></a>Haproxy 节点二安装 Keepalived</h4><ul><li>安装 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">sudo apt-get install -y keepalived</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> keepalived</span><br></pre></td></tr></tbody></table></figure><ul><li>配置 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建或编辑Keepalived的配置文件，写入以下配置内容（请自行更改网卡设备参数）</span></span><br><span class="line">sudo vim /etc/keepalived/keepalived.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance  VI_1 {</span><br><span class="line">    state  BACKUP           # 必填，Keepalived 的身份（MASTER 是主服务器，BACKUP 是备服务器）</span><br><span class="line">    interface  enp0s3       # 必填，系统的网卡设备，虚拟 IP 所在</span><br><span class="line">    virtual_router_id  51   # 必填，虚拟路由标识，取值在0-255之间，用来区分多个Instance的VRRP组播，同一网段内ID不能重复，主备机器的该值必须为一样</span><br><span class="line">    priority  90            # 必填，用来选举Master的，MASTER 权重要高于 BACKUP，数字越大优先级越高，该项取值范围是1-255（在此范围之外会被识别成默认值100）</span><br><span class="line">    advert_int  1           # 必填，MASTER 和 BACKUP 节点同步检查的时间间隔（单位为秒），主备之间必须一致，可以认为是健康检查的时间间隔</span><br><span class="line">    authentication {        # 必填，主备服务器的验证方式，主备之间必须使用相同的密码才能正常通信</span><br><span class="line">        auth_type  PASS     # 必填，主备服务器的认证方式，其中有两种方式PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位），主备之间必须使用相同的密码才能正常通信</span><br><span class="line">        auth_pass  123456</span><br><span class="line">    }</span><br><span class="line">    virtual_ipaddress {     # 必填，虚拟 IP，可以设置多个虚拟 IP 地址，每行一个</span><br><span class="line">        192.168.1.173</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>启动 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">sudo systemctl start keepalived</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行状态</span></span><br><span class="line">sudo systemctl status keepalived</span><br></pre></td></tr></tbody></table></figure><h3 id="双机热备方案测试"><a href="#双机热备方案测试" class="headerlink" title="双机热备方案测试"></a>双机热备方案测试</h3><ul><li>在其他电脑上，如果可以通过虚拟 IP <code>192.168.1.173</code> 正常访问 Haproxy 的 <code>8888</code> 与 <code>3306</code> 端口，则说明 PXC + Haproxy + Keepalived 的高可用集群搭建成功。</li></ul><table><thead><tr><th>测试内容</th><th>虚拟 IP</th><th> 端口</th><th>测试命令</th></tr></thead><tbody><tr><td> Haproxy 的监控页面</td><td> 192.168.1.173</td><td>8888</td><td><code>curl -basic -u admin:admin -I http://192.168.1.173:8888/dbs</code></td></tr><tr><td>Haproxy 的 MySQL 负载均衡</td><td> 192.168.1.173</td><td>3306</td><td><code>mysql -h 192.168.1.173 -u uatOption -P 3306 -p</code></td></tr></tbody></table><ul><li>通过 SSH 分别登录进两台 Haproxy 服务器，检查两个 Keepalived 节点之间是否可以正常进行心跳通信。如果不能进行心跳通信，则会发生脑裂现象（即两个 Keepalived 节点会同时抢占到虚拟 IP）。</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看IP地址</span></span><br><span class="line">ip addr</span><br></pre></td></tr></tbody></table></figure><ul><li>关闭 Haproxy 节点一服务器上的 Keepalived 服务，然后在其他电脑上，打开浏览器访问 <code>http://192.168.1.173:8888/dbs</code>。如果可以正常访问 Haproxy 的监控页面，则说明 Haproxy + Keepalived 的双机热备方案生效了。</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭Keepalived服务</span></span><br><span class="line">sudo systemctl stop keepalived</span><br></pre></td></tr></tbody></table></figure><ul><li>在 Haproxy 节点一服务器上的 Keepalived 服务关闭之后，通过 SSH 登录进 Haproxy 节点二服务器，使用 <code>ip addr</code> 命令查看 IP 地址，可以观察到 Haproxy 节点二服务器已经抢占到虚拟 IP。</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看IP地址</span></span><br><span class="line">ip addr</span><br></pre></td></tr></tbody></table></figure><h3 id="双机热备方案完善"><a href="#双机热备方案完善" class="headerlink" title="双机热备方案完善"></a>双机热备方案完善</h3><p>第一个问题：上述两个 Haproxy 服务器内的 Keepalived 服务，彼此仅仅是基于心跳检测来实现双机热备（故障切换）。如果第一个 Haproxy 服务器内的 Keepalived 服务（Master）正常运行，而 Haproxy 自身运行异常，那么将会出现 Haproxy 负载均衡服务失效，无法切换到备用的 Haproxy 负载均衡器上，最终导致后端的 Web 服务无法收到响应。所以，<strong>应该是要基于 Shell 脚本每隔一段时间检测 Haproxy 服务是否正常运行，而不是仅仅依靠 Keepalived 主备节点之间的心跳检测。</strong>比如，当检测到 Haproxy 服务不是正常运行，首先尝试启动 Haproxy 服务；若 Haproxy 服务重启失败，就应该关闭掉该节点上的 Keepalived 服务，并发送报警邮件，这样才能自动切换到 Keepalived 服务的 Backup 节点上。详细的解决方案建议参考 <a href="/posts/503c34e4.html#Keepalived-%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE">这里</a> 的教程。</p><hr><div class="admonition note"><p class="admonition-title">扩展阅读</p><ul><li><a href="https://www.cnblogs.com/f-ck-need-u/p/9370579.html">Haproxy 代理 MySQL 要考虑的问题</a></li></ul></div><p>第二个问题：Haproxy 代理 MySQL 的时候，事务持久性的问题必须解决。这个事务持久性不是 ACID 的 D（持久性，Durability），而是 Transaction Persistent，这里简单描述一下此处的事务持久性。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">start transaction</span><br><span class="line">update1...</span><br><span class="line">update2...</span><br><span class="line">insert3...</span><br><span class="line">commit</span><br></pre></td></tr></tbody></table></figure><p>当客户端显式开启一个事务，然后执行上述几个数据库操作，然后提交或回滚。如果使用代理软件（如 Haproxy）对 MySQL 进行代理，必须要保证这 5 个语句全都路由到同一个 MySQL 节点上，即使后端的 MySQL 采用的是多主模型（MGR、Galera 都提供多主模型），否则事务中各语句分散，轻则返回失败，重则数据不一致、提交混乱。这就是 Transaction Persistent 的概念，即让同一个事务路由到同一个后端节点。Haproxy 如何保证事务持久性呢？对于非 MySQL 协议感知的代理（LVS、Nginx、Haproxy 等），要保证事务持久性，只能通过间接的方法实现，比较通用的方法是在代理软件上监听不同的端口（实现读写分离）。具体的思路如下：</p><ul><li>1）在 Haproxy 上监听不同端口，例如 <code>3307</code> 端口的请求作为写端口，<code>3306</code> 端口的请求作为读端口。</li><li>2）从后端 MySQL 节点中选一个节点 (只能是一个) 作为逻辑写节点，Haproxy 将 <code>3307</code> 端口的请求全都路由给这个节点。</li><li>3）可以在 Haproxy 上配置多个备用写节点 (Backup)，但 <code>3307</code> 端口在某一时刻，路由到的必须只能有一个写节点。</li></ul><p>这样能保证事务的持久性，也能解决一些乐观锁问题。但是，如果后端是多主模型的 MGR（组复制）或 Galera，这样的代理方式将强制变为单主模型，虽然是逻辑上的强制。当然，这并非什么问题，至少到目前为止的开源技术，都建议采用单主模型。Haproxy 保证事务持久性的配置示例如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">listen  haproxy_3306_read_multi</span><br><span class="line">        bind *:3306</span><br><span class="line">        mode tcp</span><br><span class="line">        timeout client  10800s</span><br><span class="line">        timeout server  10800s</span><br><span class="line">        balance leastconn</span><br><span class="line">        option httpchk</span><br><span class="line">        option allbackups</span><br><span class="line">        default-server port 9200 inter 2s downinter 5s rise 3 fall 2 slowstart 60s maxconn 64 maxqueue 128 weight 100</span><br><span class="line">        server galera1 192.168.55.111:3306 check</span><br><span class="line">        server galera2 192.168.55.112:3306 check</span><br><span class="line">        server galera3 192.168.55.113:3306 check</span><br><span class="line"> </span><br><span class="line">listen  haproxy_3307_write_single</span><br><span class="line">        bind *:3307</span><br><span class="line">        mode tcp</span><br><span class="line">        timeout client  10800s</span><br><span class="line">        timeout server  10800s</span><br><span class="line">        balance leastconn</span><br><span class="line">        option httpchk</span><br><span class="line">        option allbackups</span><br><span class="line">        default-server port 9200 inter 2s downinter 5s rise 3 fall 2 slowstart 60s maxconn 64 maxqueue 128 weight 100</span><br><span class="line">        server galera1 192.168.55.111:3306 check</span><br><span class="line">        server galera2 192.168.55.112:3306 check backup</span><br><span class="line">        server galera3 192.168.55.113:3306 check backup</span><br></pre></td></tr></tbody></table></figure><p>上面的配置通过 <code>3306</code> 端口和 <code>3307</code> 端口进行读写分离，并且在负责写的 <code>3307</code> 端口中只有一个节点可写，其余两个节点作为 Backup 节点。对于 MySQL 的负载来说，更建议采用 MySQL 协议感知的程序来实现，例如 MySQL Router、ProxySql，MaxScale、MyCat 等数据库中间件。</p><h2 id="PXC-集群运维"><a href="#PXC-集群运维" class="headerlink" title="PXC 集群运维"></a>PXC 集群运维</h2><h3 id="查看错误日志"><a href="#查看错误日志" class="headerlink" title="查看错误日志"></a>查看错误日志</h3><p>PXC 集群使用的是 Percona Server 数据库，它是 MySQL 的衍生版本，因此 PXC 集群节点的很多操作跟 MySQL 一样，其错误日志信息存放在每个节点的 <code>/var/log/mysql/error.log</code> 文件里面。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看错误日志文件</span></span><br><span class="line">sudo vi /var/<span class="built_in">log</span>/mysql/error.log</span><br></pre></td></tr></tbody></table></figure><h3 id="正确关闭集群"><a href="#正确关闭集群" class="headerlink" title="正确关闭集群"></a>正确关闭集群</h3><p>如果第一个节点（负责集群初始化）不是最后一个离开集群的，那么它在一般情况下就不能再以第一个节点的形式启动了。这是因为从这个节点引导集群启动可能是不安全的，即这个节点可能不包含所有更新的数据。<strong>综上所述，PXC 集群节点的正确关闭顺序，应该与它们的启动顺序相反（类似栈结构 - 先进后出），即最先启动的节点应该最后关闭。</strong></p><ul><li>启动集群 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动第一个节点</span></span><br><span class="line">sudo systemctl start mysql@bootstrap.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动第二个节点（必须等待第一个节点启动完成再启动）</span></span><br><span class="line">sudo systemctl start mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动第三个节点（必须等待第一个节点启动完成再启动）</span></span><br><span class="line">sudo systemctl start mysql</span><br></pre></td></tr></tbody></table></figure><ul><li>关闭集群 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭第三个节点</span></span><br><span class="line">sudo systemctl stop mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭第二个节点</span></span><br><span class="line">sudo systemctl stop mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭第一个节点</span></span><br><span class="line">sudo systemctl stop mysql@bootstrap.service</span><br></pre></td></tr></tbody></table></figure><h3 id="节点动态下线"><a href="#节点动态下线" class="headerlink" title="节点动态下线"></a>节点动态下线</h3><p>PXC 集群允许动态下线节点，但需要注意的是节点的启动命令和关闭命令必须一致；比如使用 <code>mysql@bootstrap.service</code> 服务启动的第一个节点服务器（负责集群初始化），在它关闭时也必须使用 <code>mysql@bootstrap.service</code> 服务来操作（<strong>该结论有待验证</strong>）。</p><ul><li>第一个节点上下线 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一个节点下线</span></span><br><span class="line">sudo systemctl stop mysql@bootstrap.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个节点上线</span></span><br><span class="line">sudo systemctl start mysql@bootstrap.service</span><br></pre></td></tr></tbody></table></figure><ul><li>其他节点上下线 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 其他节点下线</span></span><br><span class="line">sudo service stop mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他节点上线</span></span><br><span class="line">sudo service start mysql</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>由于 PXC 集群的所有节点都是对等的，所以下线第一个节点和下线其他节点在效果上都是相同的。</p></div><h3 id="单节点的操作系统重启"><a href="#单节点的操作系统重启" class="headerlink" title="单节点的操作系统重启"></a>单节点的操作系统重启</h3><p><strong>特别注意，当 PXC 集群中某个节点所在的 Debian 系统重启后，PXC 会自动将该节点的 MySQL 服务从集群中剔除（因为节点不可用了），以此保证高可用，但该节点的 MySQL 服务后续是不会自动启动的。</strong>也就是说，等 Debian 系统重启完成后，必须手动启动该节点上的 MySQL 服务。此时只要确保 PXC 集群中至少有一个节点存活着，那么就不需要再重新初始化 PXC 集群（引导 PXC 集群启动），因此无论等待重启的节点是第一个节点（负责集群初始化），还是其他节点，都可以直接使用 <code>mysql</code> 服务进行启动。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启意外关闭的节点</span></span><br><span class="line">sudo service start mysql</span><br></pre></td></tr></tbody></table></figure><h3 id="集群断电重启，第一个节点启动失败"><a href="#集群断电重启，第一个节点启动失败" class="headerlink" title="集群断电重启，第一个节点启动失败"></a>集群断电重启，第一个节点启动失败</h3><ul><li>PXC 集群的三台节点服务器都突然断电重启了（即所有集群节点几乎都在同一时刻意外关闭），等服务器上的 Debian 系统相继重新启动完成后，无法使用以下命令正常启动第一个节点服务器（负责集群初始化）上的 MySQL 服务 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动第一个节点</span></span><br><span class="line">sudo systemctl start mysql@bootstrap.service</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一个节点启动的错误信息</span></span><br><span class="line">systemctl start mysql@bootstrap.service Job <span class="keyword">for</span> mysql@bootstrap.service failed because the control process exited with error code. See <span class="string">"systemctl status mysql@bootstrap.service"</span> and <span class="string">"journalctl -xe"</span> <span class="keyword">for</span> details.</span><br></pre></td></tr></tbody></table></figure><ul><li>首先使用以下几种方式，查看 MySQL 的日志信息 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看系统日志信息</span></span><br><span class="line">journalctl -xe</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看MySQL的错误日志文件</span></span><br><span class="line">sudo vi /var/<span class="built_in">log</span>/mysql/error.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看MySQL的运行状态信息</span></span><br><span class="line">sudo systemctl status mysql@bootstrap.service</span><br></pre></td></tr></tbody></table></figure><ul><li>进一步在 MySQL 的错误日志文件中，发现了以下错误内容（留意 ERROR 部分）</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2023-10-26T22:13:35.822653Z 0 [Note] [MY-000000] [Galera] ####### Assign initial position for certification: e4bb8bf0-73d5-11ee-b279-3a5ebcc11ef7:29, protocol version: -1</span><br><span class="line">2023-10-26T22:13:35.822752Z 0 [Note] [MY-000000] [WSREP] Starting replication</span><br><span class="line">2023-10-26T22:13:35.822790Z 0 [Note] [MY-000000] [Galera] Connecting with bootstrap option: 1</span><br><span class="line">2023-10-26T22:13:35.822809Z 0 [Note] [MY-000000] [Galera] Setting GCS initial position to e4bb8bf0-73d5-11ee-b279-3a5ebcc11ef7:29</span><br><span class="line">2023-10-26T22:13:35.822823Z 0 [ERROR] [MY-000000] [Galera] It may not be safe to bootstrap the cluster from this node. It was not the last one to leave the cluster and may not contain all the updates. To force cluster bootstrap with this node, edit the grastate.dat file manually and set safe_to_bootstrap to 1 .</span><br><span class="line">2023-10-26T22:13:35.822844Z 0 [ERROR] [MY-000000] [WSREP] Provider/Node (gcomm://192.168.1.188,192.168.1.193,192.168.1.223) failed to establish connection with cluster (reason: 7)</span><br><span class="line">2023-10-26T22:13:35.822855Z 0 [ERROR] [MY-010119] [Server] Aborting</span><br><span class="line">2023-10-26T22:13:35.823148Z 0 [System] [MY-010910] [Server] /usr/sbin/mysqld: Shutdown complete (mysqld 8.0.33-25.1)  Percona XtraDB Cluster (GPL), Release rel25, Revision 0c56202, WSREP version 26.1.4.3.</span><br><span class="line">2023-10-26T22:13:35.824298Z 0 [ERROR] [MY-010065] [Server] Failed to shutdown components infrastructure.</span><br></pre></td></tr></tbody></table></figure><p>意思是从这个节点引导集群启动可能是不安全。由于该节点不是最后一个离开集群的节点（最后停掉的节点），可能不包含所有更新的数据。要强制使用该节点进行集群引导，请手动编辑该节点的 <code>grastate.dat</code> 文件，并将 <code>safe_to_bootstrap</code> 参数设置为 <code>1</code>。当然了，一般情况下不需要强制从该节点启动，可以逐一排查每个节点下的 <code>grastate.dat</code> 文件，找到 <code>safe_to_bootstrap=1</code> 的节点，然后在该节点上引导 PXC 集群启动即可。如果所有节点的 <code>safe_to_bootstrap</code> 都为 <code>0</code>，那么只能任意选择一个节点，更改该节点下的 <code>grastate.dat</code> 文件，将 <code>safe_to_bootstrap</code> 设置为 <code>1</code>，然后在该节点上引导 PXC 集群启动。<strong>特别注意，引导 PXC 集群启动（第一个节点）使用的是 <code>sudo systemctl start mysql@bootstrap.service</code> 命令，而启动其他节点使用的则是 <code>sudo systemctl start mysql</code> 命令。必须等待第一个节点启动成功，也就是 PXC 集群初始化完成之后，才能接着启动其他节点，最后再检查集群的数据是否可以正常同步。</strong></p><div class="admonition note"><p class="admonition-title">提示</p><ul><li><code>grastate.dat</code> 文件的完整路径是 <code>/var/lib/mysql/grastate.dat</code>。</li><li>在第一个节点服务器上引导 PXC 集群启动（即集群初始化）的命令是 <code>sudo systemctl start mysql@bootstrap.service</code>，其他节点的 MySQL 服务启动命令则是 <code>sudo systemctl start mysql</code>。</li></ul></div><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://www.jiangguo.net/c/mog/1w2.html">CentOS 搭建 PXC 5.7 集群</a></li><li><a href="https://www.cnblogs.com/f-ck-need-u/p/9370579.html">Haproxy 代理 MySQL 要考虑的问题</a></li><li><a href="https://docs.morpheusdata.com/en/5.5.1/getting_started/installation/distributed/full/perconaTls-ubuntu.html">Debian/Ubuntu Percona XtraDB Cluster with TLS</a></li><li><a href="https://www.howtoforge.com/how-to-install-percona-xtradb-cluster-on-debian-11/">How to Install Percona XtraDB Cluster on Debian 11</a></li><li><a href="http://blog.itpub.net/30310891/viewspace-2772587/">基于 Centos 7 部署 Percona Xtradb Cluster 5.7 高可用架构</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍如何在生产环境的 Debian 11 系统上部署 MySQL 的 PXC 8.0 集群，并基于 Haproxy + Keepalived 实现双机热备方案。</summary>
    
    
    
    
    <category term="Debian" scheme="https://www.techgrow.cn/tags/Debian/"/>
    
  </entry>
  
  <entry>
    <title>Docker 部署 PXC 8.0 单机集群</title>
    <link href="https://www.techgrow.cn/posts/8dc5e7ed.html"/>
    <id>https://www.techgrow.cn/posts/8dc5e7ed.html</id>
    <published>2023-10-26T12:13:32.000Z</published>
    <updated>2023-10-26T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文主要介绍如何使用 Docker 部署 Percona XtraDB Cluster 8.0 集群（单机三个节点），并详细介绍集群可用性的验证。</p><h3 id="系列教程"><a href="#系列教程" class="headerlink" title="系列教程"></a>系列教程</h3><ul><li><a href="/posts/aba17375.html">Docker 部署 PXC 5.7 单机集群</a></li><li><a href="/posts/8dc5e7ed.html">Docker 部署 PXC 8.0 单机集群</a></li><li><a href="/posts/ff0f2d6.html">Debian 11 生产环境部署 PXC 8.0 集群</a></li></ul><h3 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a>官方文档</h3><ul><li><a href="https://docs.percona.com/percona-xtradb-cluster/8.0/">Percona Xtradb Cluster 8.0 官方文档</a></li></ul><h2 id="PXC-集群介绍"><a href="#PXC-集群介绍" class="headerlink" title="PXC 集群介绍"></a>PXC 集群介绍</h2><div class="admonition note"><p class="admonition-title">提示</p><p>Percona Xtradb Cluster (PXC) 的详细介绍请看 <a href="/posts/cc846db2.html#Percona-XtraDB-Cluster">这里</a> 的教程。</p></div><span id="more"></span><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.cnblogs.com/wanglei957/p/11819547.html">Docker 部署 MySQL 集群</a></li><li><a href="https://cloud.tencent.com/developer/article/1929627">CentOS 7 部署 PXC 集群 【Docker + 单机多节点】</a></li><li><a href="https://www.cnblogs.com/ll409546297/p/17129532.html">MySQL 之 PXC 集群模式（Docker + MySQL + PXC 实现）</a></li><li><a href="https://www.cnblogs.com/nhdlb/p/14032657.html">Docker 部署 PXC 5.7 集群 - 搭建负载均衡实现双机热部署方案</a></li><li><a href="https://www.cnblogs.com/pengboke/p/15012571.html#node3">Docker 部署 PXC 集群 (Haproxy 负载均衡、Keepalived 高可用、XtraBackup 数据备份)</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍如何基于 Docker 部署 MySQL 的 PXC 8.0 单机集群。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="容器化" scheme="https://www.techgrow.cn/tags/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Docker 部署 PXC 5.7 单机集群</title>
    <link href="https://www.techgrow.cn/posts/aba17375.html"/>
    <id>https://www.techgrow.cn/posts/aba17375.html</id>
    <published>2023-10-24T12:13:32.000Z</published>
    <updated>2023-11-12T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文主要介绍如何使用 Docker 部署 Percona XtraDB Cluster 5.7 集群（单机三个节点），并基于 Haproxy + Keepalived 实现双机热备方案。</p><h3 id="系列教程"><a href="#系列教程" class="headerlink" title="系列教程"></a>系列教程</h3><ul><li><a href="/posts/aba17375.html">Docker 部署 PXC 5.7 单机集群</a></li><li><a href="/posts/8dc5e7ed.html">Docker 部署 PXC 8.0 单机集群</a></li><li><a href="/posts/ff0f2d6.html">Debian 11 生产环境部署 PXC 8.0 集群</a></li></ul><h3 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a>官方文档</h3><ul><li><a href="https://docs.percona.com/percona-xtradb-cluster/5.7/">Percona Xtradb Cluster 5.7 官方文档</a></li></ul><h2 id="部署准备"><a href="#部署准备" class="headerlink" title="部署准备"></a>部署准备</h2><h3 id="整体部署架构"><a href="#整体部署架构" class="headerlink" title="整体部署架构"></a>整体部署架构</h3><div class="admonition note"><p class="admonition-title">提示</p><p>PXC + Haproxy + Keepalived 双机热备架构的介绍可以阅读 <a href="/posts/aba17375.html#%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84">这里</a> 的内容。</p></div><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-12.png"></p><h3 id="整体部署规划"><a href="#整体部署规划" class="headerlink" title="整体部署规划"></a>整体部署规划</h3><ul><li>软件版本说明</li></ul><table><thead><tr><th>软件</th><th>版本</th><th>描述</th></tr></thead><tbody><tr><td> PXC 镜像</td><td> 5.7.43</td><td></td></tr><tr><td>Haproxy 镜像</td><td> 2.8.3</td><td></td></tr><tr><td>Keepalived 服务</td><td> 1.3.5</td><td></td></tr></tbody></table><ul><li>Docker 部署 PXC 集群（三个节点）+ Haproxy（两个节点 - 主备）</li></ul><table><thead><tr><th>节点名称</th><th>容器名称</th><th>容器 IP</th><th> 容器数据卷</th><th>容器数据卷目录</th><th>操作系统</th></tr></thead><tbody><tr><td> PXC 节点一</td><td> pxc-node1</td><td>172.30.0.2</td><td>pxc-v1</td><td><code>/var/lib/docker/volumes/pxc-v1/_data/</code></td><td>Debian 11</td></tr><tr><td>PXC 节点二</td><td> pxc-node2</td><td>172.30.0.3</td><td>pxc-v2</td><td><code>/var/lib/docker/volumes/pxc-v2/_data/</code></td><td>Debian 11</td></tr><tr><td>PXC 节点三</td><td> pxc-node3</td><td>172.30.0.4</td><td>pxc-v3</td><td><code>/var/lib/docker/volumes/pxc-v3/_data/</code></td><td>Debian 11</td></tr><tr><td>Haproxy 节点一</td><td> haproxy-node1</td><td>172.30.0.5</td><td>haproxy-v1</td><td><code>/var/lib/docker/volumes/haproxy-v1/_data/</code></td><td>Debian 11</td></tr><tr><td>Haproxy 节点二</td><td> haproxy-node2</td><td>172.30.0.6</td><td>haproxy-v2</td><td><code>/var/lib/docker/volumes/haproxy-v2/_data/</code></td><td>Debian 11</td></tr></tbody></table><ul><li>Keepalived 服务器安装</li></ul><table><thead><tr><th>服务器名称</th><th>服务器角色</th><th>虚拟 IP</th><th> 说明</th><th>操作系统</th></tr></thead><tbody><tr><td> Keepalived 服务器一</td><td>主服务器（MASTER）</td><td>172.30.0.7</td><td> 安装在 Haproxy 节点一的容器内（<code>haproxy-node1</code>）</td><td>Debian 11</td></tr><tr><td>Keepalived 服务器二</td><td>备服务器（BACKUP）</td><td>172.30.0.7</td><td> 安装在 Haproxy 节点二的容器内（<code>haproxy-node2</code>）</td><td>Debian 11</td></tr><tr><td>Keepalived 服务器三</td><td></td><td> 192.168.1.160</td><td> 安装在宿主机内，为了实现外网可以正常访问 Docker 容器内的虚拟 IP</td><td>Centos 7</td></tr></tbody></table><h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><h3 id="虚拟-IP-概念介绍"><a href="#虚拟-IP-概念介绍" class="headerlink" title="虚拟 IP 概念介绍"></a>虚拟 IP 概念介绍</h3><p>Linux 系统支持在一个网卡中定义多个 IP 地址，并将这些地址分配给多个应用程序，这些地址就是虚拟 IP，基于 Haproxy + Keepalived 的双机热备方案最关键的技术就是虚拟 IP。</p><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-10.png"></p><p>Keepalived 利用了上述 Linux 系统的特性，让多台服务器去获取同一个虚拟 IP，获取到的服务器将虚拟 IP 绑定到自身的网卡，然后接受外部流量；没有抢占到虚拟 IP 的则作为备用服务器，并进行心跳检测，一旦检测到主服务器宕机，则立刻抢占虚拟 IP。</p><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-11.png"></p><h3 id="负载均衡中间件选型"><a href="#负载均衡中间件选型" class="headerlink" title="负载均衡中间件选型"></a>负载均衡中间件选型</h3><p>PXC 集群有三个节点，如果每次都是第一个节点处理请求，那么就存在负载高、性能差、其他节点利用率不高等问题，所以更优的方案是对不同的节点都进行请求。这就需要有负载均衡中间件负责请求转发，主流的中间件有 Nginx、Haproxy 等，两者都支持 TCP/IP 协议，Nginx 额外支持插件，Haproxy 属于是老牌的中间件。在数据库集群的负载均衡领域，Haproxy 会使用的要多一些。不同中间件的对比如下图所示：</p><p><img data-src="../../../asset/2023/10/mysql-docker-pxc-proxy.png"></p><h3 id="Нaproxy-双机热备方案介绍"><a href="#Нaproxy-双机热备方案介绍" class="headerlink" title="Нaproxy 双机热备方案介绍"></a>Нaproxy 双机热备方案介绍</h3><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-12.png"></p><ul><li>Docker 创建两个 Haproxy 容器，每个容器中都单独安装 Keepalived 服务器</li><li>两个 Keepalived 服务器会争抢 Docker 容器内的虚拟 IP，一个抢到后，另一个没抢到就会等待，抢到的作为主服务器，没抢到的作为备用服务器</li><li>两个 Keepalived 服务器之间会进行心跳检测，如果备用服务器没有接收到主服务器的心跳响应，则说明主服务器发生故障，那么备用服务器就可以抢占虚拟 IP，继续工作</li><li>客户端向虚拟 IP 发送数据库请求，当其中一个 Haproxy 节点宕机后，还有另一个 Haproxy 节点可以接替工作</li><li>由于 Docker 容器内的虚拟 IP 不能被外网直接访问，所以需要借助宿主机里的 Keepalived 服务映射成外网可以访问的虚拟 IP</li></ul><span id="more"></span><h2 id="PXC-集群搭建"><a href="#PXC-集群搭建" class="headerlink" title="PXC 集群搭建"></a>PXC 集群搭建</h2><p>在本节中，将通过 Docker 部署 PXC 5.7 集群，其中包含三个集群节点。</p><div class="admonition note"><p class="admonition-title">提示</p><p>Percona Xtradb Cluster (PXC) 的详细介绍请看 <a href="/posts/cc846db2.html#Percona-XtraDB-Cluster">这里</a> 的教程。</p></div><h3 id="部署规划"><a href="#部署规划" class="headerlink" title="部署规划"></a>部署规划</h3><table><thead><tr><th>节点名称</th><th>容器名称</th><th>容器 IP</th><th> 容器数据卷</th><th>容器数据卷目录</th><th>操作系统</th></tr></thead><tbody><tr><td> PXC 节点一</td><td> pxc-node1</td><td>172.30.0.2</td><td>pxc-v1</td><td><code>/var/lib/docker/volumes/pxc-v1/_data/</code></td><td>Debian 11</td></tr><tr><td>PXC 节点二</td><td> pxc-node2</td><td>172.30.0.3</td><td>pxc-v2</td><td><code>/var/lib/docker/volumes/pxc-v2/_data/</code></td><td>Debian 11</td></tr><tr><td>PXC 节点三</td><td> pxc-node3</td><td>172.30.0.4</td><td>pxc-v3</td><td><code>/var/lib/docker/volumes/pxc-v3/_data/</code></td><td>Debian 11</td></tr></tbody></table><div class="admonition note"><p class="admonition-title">提示</p><ul><li>Percona XtraDB Cluster 要求最小的集群大小是 3 个节点。</li><li>建议尽可能地控制 PXC 集群的规模，节点越多，数据同步速度越慢。</li><li>PXC 存在硬件配置短板限制，即整个集群的写吞吐量受最弱节点的限制。因此所有 PXC 节点的硬件配置要一致，否则如果一个节点变慢，整个集群会跟着变慢。</li></ul></div><h3 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h3><ul><li>拉取镜像，官方文档详见 <a href="https://hub.docker.com/r/percona/percona-xtradb-cluster">Docker Hub</a>，镜像的各个版本号可以从 <a href="../../../asset/2023/10/docker-mysql-pxc-1.png">这里</a> 查看 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取镜像</span></span><br><span class="line">sudo docker pull percona/percona-xtradb-cluster:5.7.43</span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像打上标签</span></span><br><span class="line">sudo docker tag percona/percona-xtradb-cluster:5.7.43 pxc</span><br></pre></td></tr></tbody></table></figure><ul><li>创建数据卷，存储路径为 <code>/var/lib/docker/volumes/</code></li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建数据卷</span></span><br><span class="line">sudo docker volume create --name pxc-v1</span><br><span class="line">sudo docker volume create --name pxc-v2</span><br><span class="line">sudo docker volume create --name pxc-v3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有数据卷</span></span><br><span class="line">sudo docker volume ls</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据卷的详细信息</span></span><br><span class="line">sudo docker volume inspect pxc-v1</span><br></pre></td></tr></tbody></table></figure><ul><li>创建网络（专用网段）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建网络</span></span><br><span class="line">sudo docker network create --subnet=172.30.0.0/24 pxc-network</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有网络</span></span><br><span class="line">sudo docker network ls</span><br></pre></td></tr></tbody></table></figure><ul><li>创建容器，<code>XTRABACKUP_PASSWORD</code> 是 XtraBackup 工具备份数据库数据的密码 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建第一个节点</span></span><br><span class="line">sudo docker create -p 13306:3306 -v pxc-v1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_NAME=pxc --name=pxc-node1 --net=pxc-network --ip 172.30.0.2 pxc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建第二个节点（增加了CLUSTER_JOIN参数）</span></span><br><span class="line">sudo docker create -p 13307:3306 -v pxc-v2:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_NAME=pxc -e CLUSTER_JOIN=pxc-node1 --name=pxc-node2 --net=pxc-network --ip 172.30.0.3 pxc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建第三个节点（增加了CLUSTER_JOIN参数）</span></span><br><span class="line">sudo docker create -p 13308:3306 -v pxc-v3:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_NAME=pxc -e CLUSTER_JOIN=pxc-node1 --name=pxc-node3 --net=pxc-network --ip 172.30.0.4 pxc</span><br></pre></td></tr></tbody></table></figure><ul><li>启动节点一的容器（必须先启动节点一，等待 PXC 集群初始化操作执行完成后，再启动节点二和节点三的容器）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动节点一</span></span><br><span class="line">sudo docker start pxc-node1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看节点一的日志信息</span></span><br><span class="line">sudo docker logs -f pxc-node1</span><br></pre></td></tr></tbody></table></figure><ul><li>启动节点二的容器（必须等待节点一启动成功后再启动）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动节点二</span></span><br><span class="line">sudo docker start pxc-node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看节点二的日志信息</span></span><br><span class="line">sudo docker logs -f pxc-node2</span><br></pre></td></tr></tbody></table></figure><ul><li>启动节点三的容器（必须等待节点一启动成功后再启动）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动节点三</span></span><br><span class="line">sudo docker start pxc-node3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看节点三的日志信息</span></span><br><span class="line">sudo docker logs -f pxc-node3</span><br></pre></td></tr></tbody></table></figure><h3 id="集群验证"><a href="#集群验证" class="headerlink" title="集群验证"></a>集群验证</h3><h4 id="登录-MySQL"><a href="#登录-MySQL" class="headerlink" title="登录 MySQL"></a>登录 MySQL</h4><ul><li>登录 MySQL 数据库，可以是 PXC 集群中的任意一个节点 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker <span class="built_in">exec</span> -it pxc-node1 /usr/bin/mysql -uroot -p123456</span><br></pre></td></tr></tbody></table></figure><h4 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h4><ul><li>在 PXC 集群的任意一个节点上，执行以下 SQL 语句来查看集群状态 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> status <span class="keyword">like</span> <span class="string">'wsrep_cluster%'</span>;</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-2.png"></p><h4 id="创建数据库表"><a href="#创建数据库表" class="headerlink" title="创建数据库表"></a>创建数据库表</h4><ul><li>在 PXC 集群的任意一个节点上，执行以下 SQL 语句，然后观察其他节点是否同步创建了数据库和表。</li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建数据库</span></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE `percona` <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_unicode_ci;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 切换数据库</span></span><br><span class="line">USE `percona`;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建用户表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `acl_user` (</span><br><span class="line">  `id` <span class="type">char</span>(<span class="number">19</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">'会员id'</span>,</span><br><span class="line">  `username` <span class="type">varchar</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">''</span> COMMENT <span class="string">'微信openid'</span>,</span><br><span class="line">  `password` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">''</span> COMMENT <span class="string">'密码'</span>,</span><br><span class="line">  `nick_name` <span class="type">varchar</span>(<span class="number">50</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">'昵称'</span>,</span><br><span class="line">  `salt` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">'用户头像'</span>,</span><br><span class="line">  `token` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">'用户签名'</span>,</span><br><span class="line">  `is_deleted` tinyint(<span class="number">1</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">'0'</span> COMMENT <span class="string">'逻辑删除 1（true）已删除， 0（false）未删除'</span>,</span><br><span class="line">  `gmt_create` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">'创建时间'</span>,</span><br><span class="line">  `gmt_modified` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">'更新时间'</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  <span class="keyword">UNIQUE</span> KEY `uk_username` (`username`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">'用户表'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 插入用户数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `acl_user` <span class="keyword">VALUES</span> (<span class="string">'1'</span>,<span class="string">'admin'</span>,<span class="string">'96e79218965eb72c92a549dd5a330112'</span>,<span class="string">'admin'</span>,<span class="string">''</span>,<span class="keyword">NULL</span>,<span class="number">0</span>,<span class="string">'2018-05-01 10:39:47'</span>,<span class="string">'2018-05-01 10:39:47'</span>);</span><br></pre></td></tr></tbody></table></figure><h2 id="Haproxy-负载均衡"><a href="#Haproxy-负载均衡" class="headerlink" title="Haproxy 负载均衡"></a>Haproxy 负载均衡</h2><p>在本节中，将介绍如何使用 Haproxy 作为负载均衡服务器，将请求转发给 PXC 集群中的各个节点。<strong>特别注意，在执行以下操作之前，请先启动 PXC 集群，并确保集群可以正常运行。</strong></p><h3 id="部署规划-1"><a href="#部署规划-1" class="headerlink" title="部署规划"></a>部署规划</h3><table><thead><tr><th>节点名称</th><th>容器名称</th><th>容器 IP</th><th> 容器数据卷</th><th>容器数据卷目录</th><th>操作系统</th></tr></thead><tbody><tr><td> Haproxy 节点一</td><td> haproxy-node1</td><td>172.30.0.5</td><td>haproxy-v1</td><td><code>/var/lib/docker/volumes/haproxy-v1/_data/</code></td><td>Debian 11</td></tr></tbody></table><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p>当使用 PXC 集群的单个节点处理所有请求时，存在负载高、性能差、其他节点利用率不高等问题。</p><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-4.png"></p><p>使用 Haproxy 做负载均衡，将请求均匀地分配给 PXC 集群中的每一个节点，单节点负载低、性能高，且所有节点都能利用起来。</p><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-5.png"></p><h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><p>在本节中，将创建 MySQL 用户，Haproxy 后续会使用这个用户对 PXC 集群节点进行心跳检测。</p><ul><li>登录 MySQL 数据库，可以是 PXC 集群中的任意一个节点 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker <span class="built_in">exec</span> -it pxc-node1 /usr/bin/mysql -uroot -p123456</span><br></pre></td></tr></tbody></table></figure><ul><li>创建数据库用户 <code>haproxy</code>，不指定密码和权限，只允许远程访问 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用户</span></span><br><span class="line">CREATE USER <span class="string">'haproxy'</span>@<span class="string">'%'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新权限信息</span></span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看用户列表</span></span><br><span class="line">SELECT user, host FROM mysql.user;</span><br></pre></td></tr></tbody></table></figure><h3 id="应用部署"><a href="#应用部署" class="headerlink" title="应用部署"></a>应用部署</h3><ul><li>拉取镜像，官方文档详见 <a href="https://hub.docker.com/_/haproxy">Docker Hub</a></li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取镜像</span></span><br><span class="line">sudo docker pull haproxy:2.8.3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像打上标签</span></span><br><span class="line">sudo docker tag haproxy:2.8.3 haproxy</span><br></pre></td></tr></tbody></table></figure><ul><li>创建数据卷，存储路径为 <code>/var/lib/docker/volumes/</code></li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建数据卷</span></span><br><span class="line">sudo docker volume create --name haproxy-v1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有数据卷</span></span><br><span class="line">sudo docker volume ls</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据卷的详细信息</span></span><br><span class="line">sudo docker volume inspect haproxy-v1</span><br></pre></td></tr></tbody></table></figure><ul><li>创建 Haproxy 的配置文件 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在数据卷目录下创建Haproxy的配置文件</span></span><br><span class="line">sudo touch /var/lib/docker/volumes/haproxy-v1/_data/haproxy.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑Haproxy的配置文件，添加以下内容</span></span><br><span class="line">sudo vi /var/lib/docker/volumes/haproxy-v1/_data/haproxy.cfg</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">    # 工作目录</span><br><span class="line">    # chroot /usr/local/etc/haproxy</span><br><span class="line">    # 日志文件，使用rsyslog服务中local5日志设备（/var/log/local5），等级info</span><br><span class="line">    log 127.0.0.1 local5 info</span><br><span class="line">    # 以守护进程运行</span><br><span class="line">    daemon</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    log    global</span><br><span class="line">    mode    http</span><br><span class="line">    # 日志格式</span><br><span class="line">    option    httplog</span><br><span class="line">    # 日志中不记录负载均衡的心跳检测记录</span><br><span class="line">    option    dontlognull</span><br><span class="line">    # 连接超时（毫秒）</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    # 客户端超时（毫秒）</span><br><span class="line">    timeout client  50000</span><br><span class="line">    # 服务器超时（毫秒）</span><br><span class="line">    timeout server  50000</span><br><span class="line"></span><br><span class="line"># 监控界面    </span><br><span class="line">listen  admin_stats</span><br><span class="line">    # 监控界面的访问的IP和端口</span><br><span class="line">    bind  0.0.0.0:8888</span><br><span class="line">    # 访问协议</span><br><span class="line">    mode        http</span><br><span class="line">    # URI相对地址</span><br><span class="line">    stats uri   /dbs</span><br><span class="line">    # 统计报告格式</span><br><span class="line">    stats realm     Global\ statistics</span><br><span class="line">    # 登陆账户信息</span><br><span class="line">    stats auth  admin:admin</span><br><span class="line"># 数据库负载均衡</span><br><span class="line">listen  proxy-pxc</span><br><span class="line">    # 访问的IP和端口</span><br><span class="line">    bind  0.0.0.0:3306  </span><br><span class="line">    # 网络协议</span><br><span class="line">    mode  tcp</span><br><span class="line">    # 负载均衡算法（轮询算法）</span><br><span class="line">    # 轮询算法：roundrobin</span><br><span class="line">    # 权重算法：static-rr</span><br><span class="line">    # 最少连接算法：leastconn</span><br><span class="line">    # 请求源IP算法：source </span><br><span class="line">    balance  roundrobin</span><br><span class="line">    # 日志格式</span><br><span class="line">    option  tcplog</span><br><span class="line">    # Haproxy使用MySQL的haproxy账户对数据库进行心跳检测</span><br><span class="line">    option  mysql-check user haproxy</span><br><span class="line">    server  PXC_Node_1 172.30.0.2:3306 check weight 1 maxconn 2000  </span><br><span class="line">    server  PXC_Node_2 172.30.0.3:3306 check weight 1 maxconn 2000  </span><br><span class="line">    server  PXC_Node_3 172.30.0.4:3306 check weight 1 maxconn 2000 </span><br><span class="line">    # 使用Keepalived检测死链</span><br><span class="line">    option  tcpka</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>在上述 Haproxy 的配置文件中，不能启用 <code>chroot /usr/local/etc/haproxy</code>，否则 Haproxy 容器会启动失败（日志信息如下），暂时不清楚其原因。</p></div><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[NOTICE]   (1) : New worker (8) forked</span><br><span class="line">[NOTICE]   (1) : Loading success.</span><br><span class="line">[NOTICE]   (8) : haproxy version is 2.8.3-86e043a</span><br><span class="line">[NOTICE]   (8) : path to executable is /usr/local/sbin/haproxy</span><br><span class="line">[ALERT]    (8) : [haproxy.main()] Cannot chroot(/usr/local/etc/haproxy).</span><br><span class="line">[NOTICE]   (1) : haproxy version is 2.8.3-86e043a</span><br><span class="line">[NOTICE]   (1) : path to executable is /usr/local/sbin/haproxy</span><br><span class="line">[WARNING]  (1) : Current worker (8) exited with code 1 (Exit)</span><br><span class="line">[ALERT]    (1) : exit-on-failure: killing every processes with SIGTERM</span><br><span class="line">[WARNING]  (1) : All workers exited. Exiting... (1)</span><br></pre></td></tr></tbody></table></figure><ul><li>创建并运行 Haproxy 容器，其中的 <code>8888</code> 是 Haproxy 监听的 HTTP 端口（用于提供监控界面的 Web 服务），<code>3306</code> 是 Haproxy 监听的 MySQL 端口（用于转发请求给 PXC 集群节点）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建并运行容器</span></span><br><span class="line">sudo docker run -it -p 4001:8888 -p 4002:3306 -v /var/lib/docker/volumes/haproxy-v1/_data/:/usr/<span class="built_in">local</span>/etc/haproxy --privileged --name=haproxy-node1 --net=pxc-network --ip 172.30.0.5 -d haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看日志信息</span></span><br><span class="line">sudo docker logs -f haproxy-node1</span><br></pre></td></tr></tbody></table></figure><h3 id="部署验证"><a href="#部署验证" class="headerlink" title="部署验证"></a>部署验证</h3><h4 id="访问监控界面"><a href="#访问监控界面" class="headerlink" title="访问监控界面"></a>访问监控界面</h4><p>在宿主机内使用浏览器访问 <code>http://192.168.1.221:4001/dbs</code>，打开 Haproxy 的监控界面（如下图所示），登录用户名是 <code>admin</code>，登录密码是 <code>admin</code>。如果可以正常访问 Haproxy 的监控界面，则说明 Haproxy 成功部署。</p><div class="admonition note"><p class="admonition-title">提示</p><p>值得一提的是，上述的 <code>192.168.1.221</code> 是宿主机的 IP 地址，<code>4001</code> 是 Haproxy 容器映射的 HTTP 端口。</p></div><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-6.png"></p><h4 id="连接-PXC-集群"><a href="#连接-PXC-集群" class="headerlink" title="连接 PXC 集群"></a>连接 PXC 集群</h4><p>通过 Haproxy 容器映射的数据库代理端口 <code>4402</code> 登录 PXC 集群的 MySQL 节点。如果可以正常登录，则说明 Haproxy 成功将请求转发给 PXC 集群。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h 192.168.1.221 -u root -P 4002 -p123456</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>值得一提的是，上述的 <code>192.168.1.221</code> 是宿主机的 IP 地址，<code>4002</code> 是 Haproxy 容器映射的 MySQL 端口。</p></div><h4 id="集群节点心跳检测"><a href="#集群节点心跳检测" class="headerlink" title="集群节点心跳检测"></a>集群节点心跳检测</h4><p>Haproxy 每隔一段时间会对 PXC 集群的节点进行心跳检测，当某个集群节点下线后，在 Haproxy 的监控界面可以观察到（如下图所示）。</p><div class="admonition note"><p class="admonition-title">提示</p><p>当 Haproxy 检测到有 PXC 集群节点处于不可用状态时，它会将该节点从负载均衡的服务器列表中剔除掉，直到该节点重新恢复到可用状态后。因此 Haproxy 可以做到一定程度的高可用，它的负载均衡跟 Nginx 有比较大的区别，后者默认不会剔除不用的服务器节点，而是会直接转发请求给故障节点。</p></div><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭节点二</span></span><br><span class="line">sudo docker stop pxc-node2</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-7.png"></p><h2 id="Haproxy-Keepalived-双机热备部署"><a href="#Haproxy-Keepalived-双机热备部署" class="headerlink" title="Haproxy + Keepalived 双机热备部署"></a>Haproxy + Keepalived 双机热备部署</h2><p>在本节中，将会创建多一个 Haproxy 容器（最终 Haproxy 会有两个容器），并在宿主机和每个 Haproxy 容器内单独安装 Keepalived 服务器，以此实现 Haproxy + Keepalived 双机热备方案。<strong>特别注意，在执行以下操作之前，请先启动 PXC 集群，并确保集群可以正常运行。</strong></p><h3 id="双机热备部署规划"><a href="#双机热备部署规划" class="headerlink" title="双机热备部署规划"></a>双机热备部署规划</h3><ul><li>Docker 部署 Haproxy（两个节点 - 主备）</li></ul><table><thead><tr><th>节点名称</th><th>容器名称</th><th>容器 IP</th><th> 容器数据卷</th><th>容器数据卷目录</th><th>操作系统</th></tr></thead><tbody><tr><td> Haproxy 节点一</td><td> haproxy-node1</td><td>172.30.0.5</td><td>haproxy-v1</td><td><code>/var/lib/docker/volumes/haproxy-v1/_data/</code></td><td>Debian 11</td></tr><tr><td>Haproxy 节点二</td><td> haproxy-node2</td><td>172.30.0.6</td><td>haproxy-v2</td><td><code>/var/lib/docker/volumes/haproxy-v2/_data/</code></td><td>Debian 11</td></tr></tbody></table><ul><li>Keepalived 服务器安装</li></ul><table><thead><tr><th>服务器名称</th><th>服务器角色</th><th>虚拟 IP</th><th> 说明</th><th>操作系统</th></tr></thead><tbody><tr><td> Keepalived 服务器一</td><td>主服务器（MASTER）</td><td>172.30.0.7</td><td> 安装在 Haproxy 节点一的容器内（<code>haproxy-node1</code>）</td><td>Debian 11</td></tr><tr><td>Keepalived 服务器二</td><td>备服务器（BACKUP）</td><td>172.30.0.7</td><td> 安装在 Haproxy 节点二的容器内（<code>haproxy-node2</code>）</td><td>Debian 11</td></tr><tr><td>Keepalived 服务器三</td><td></td><td> 192.168.1.160</td><td> 安装在宿主机内，为了实现外网可以正常访问 Docker 容器内的虚拟 IP</td><td>Centos 7</td></tr></tbody></table><h3 id="双机热备整体架构"><a href="#双机热备整体架构" class="headerlink" title="双机热备整体架构"></a>双机热备整体架构</h3><p>单节点的 Haproxy 不具备真正的高可用性，必须要有冗余设计，否则 Haproxy 宕机后，会造成整个集群不可用，如下图所示：</p><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-9.png"></p><p>对 Haproxy 进行集群部署（两个节点），并使用 Keepalived 实现双机热备架构，当其中一个 Haproxy 节点宕机后，另一个 Haproxy 节点可以顶上，保证整个集群的可用性，如下图所示：</p><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-12.png"></p><ul><li>Docker 创建两个 Haproxy 容器，每个容器中都单独安装 Keepalived 服务器</li><li>两个 Keepalived 服务器会争抢 Docker 容器内的虚拟 IP，一个抢到后，另一个没抢到就会等待，抢到的作为主服务器，没抢到的作为备用服务器</li><li>两个 Keepalived 服务器之间会进行心跳检测，如果备用服务器没有接收到主服务器的心跳响应，则说明主服务器发生故障，那么备用服务器就可以抢占虚拟 IP，继续工作</li><li>客户端向虚拟 IP 发送数据库请求，当其中一个 Haproxy 节点宕机后，还有另一个 Haproxy 节点可以接替工作</li><li>由于 Docker 容器内的虚拟 IP 不能被外网直接访问，所以需要借助宿主机里的 Keepalived 服务映射成外网可以访问的虚拟 IP</li></ul><h3 id="安装第一个-Keepalive-服务"><a href="#安装第一个-Keepalive-服务" class="headerlink" title="安装第一个 Keepalive 服务"></a>安装第一个 Keepalive 服务</h3><p>在本节中，将在上面创建第一个的 Haproxy 容器内，安装 Keepalived 服务器。</p><ul><li>使用 root 权限连接第一个 Haproxy 容器 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连接Haproxy容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -u 0 -it haproxy-node1 /bin/bash</span><br></pre></td></tr></tbody></table></figure><ul><li>在第一个 Haproxy 容器内安装 Keepalived 服务器 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新包索引</span></span><br><span class="line">apt-get update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装软件</span></span><br><span class="line">apt-get install -y vim keepalived</span><br></pre></td></tr></tbody></table></figure><ul><li>在第一个 Haproxy 容器内配置 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建Keepalived的配置文件</span></span><br><span class="line">touch /etc/keepalived/keepalived.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑Keepalived的配置文件，写入以下配置内容（请自行更改网卡设备参数）</span></span><br><span class="line">vim /etc/keepalived/keepalived.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance  VI_1 {</span><br><span class="line">    state  MASTER           # 必填，Keepalived 的身份（MASTER 是主服务器，BACKUP 是备服务器）</span><br><span class="line">    interface  eth0         # 必填，Docker 的网卡设备，虚拟 IP 所在</span><br><span class="line">    virtual_router_id  51   # 必填，虚拟路由标识，取值在0-255之间，用来区分多个Instance的VRRP组播，同一网段内ID不能重复，主备机器的该值必须为一样</span><br><span class="line">    priority  100           # 必填，用来选举Master的，MASTER 权重要高于 BACKUP，数字越大优先级越高，该项取值范围是1-255（在此范围之外会被识别成默认值100）</span><br><span class="line">    advert_int  1           # 必填，MASTER 和 BACKUP 节点同步检查的时间间隔（单位为秒），主备之间必须一致，可以认为是健康检查的时间间隔</span><br><span class="line">    authentication {        # 必填，主备服务器的验证方式，主备之间必须使用相同的密码才能正常通信</span><br><span class="line">        auth_type  PASS     # 必填，主备服务器的认证方式，其中有两种方式PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位），主备之间必须使用相同的密码才能正常通信</span><br><span class="line">        auth_pass  123456</span><br><span class="line">    }</span><br><span class="line">    virtual_ipaddress {     # 必填，虚拟 IP，可以设置多个虚拟 IP 地址，每行一个</span><br><span class="line">        172.30.0.7</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>在第一个 Haproxy 容器内启动 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service keepalived start</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机内查看第一个 Haproxy 容器内的进程列表，验证 Keepalived 服务是否正常运行 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker top haproxy-node1</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机内 Ping 虚拟 IP，验证虚拟 IP 是否可用 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping 172.30.0.7</span><br></pre></td></tr></tbody></table></figure><h3 id="安装第二个-Keepalived-服务"><a href="#安装第二个-Keepalived-服务" class="headerlink" title="安装第二个 Keepalived 服务"></a>安装第二个 Keepalived 服务</h3><p>在本节中，将另外多部署一个 Haproxy 容器，并在容器内安装 Keepalived 服务器。</p><h4 id="部署第二个-Haproxy-容器"><a href="#部署第二个-Haproxy-容器" class="headerlink" title="部署第二个 Haproxy 容器"></a>部署第二个 Haproxy 容器</h4><ul><li>创建数据卷，存储路径为 <code>/var/lib/docker/volumes/</code></li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建数据卷</span></span><br><span class="line">sudo docker volume create --name haproxy-v2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有数据卷</span></span><br><span class="line">sudo docker volume ls</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据卷的详细信息</span></span><br><span class="line">sudo docker volume inspect haproxy-v2</span><br></pre></td></tr></tbody></table></figure><ul><li>创建 Haproxy 的配置文件 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在数据卷目录下创建Haproxy的配置文件</span></span><br><span class="line">sudo touch /var/lib/docker/volumes/haproxy-v2/_data/haproxy.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑Haproxy的配置文件，添加以下内容</span></span><br><span class="line">sudo vi /var/lib/docker/volumes/haproxy-v2/_data/haproxy.cfg</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">    # 工作目录</span><br><span class="line">    # chroot /usr/local/etc/haproxy</span><br><span class="line">    # 日志文件，使用rsyslog服务中local5日志设备（/var/log/local5），等级info</span><br><span class="line">    log 127.0.0.1 local5 info</span><br><span class="line">    # 以守护进程运行</span><br><span class="line">    daemon</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    log    global</span><br><span class="line">    mode    http</span><br><span class="line">    # 日志格式</span><br><span class="line">    option    httplog</span><br><span class="line">    # 日志中不记录负载均衡的心跳检测记录</span><br><span class="line">    option    dontlognull</span><br><span class="line">    # 连接超时（毫秒）</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    # 客户端超时（毫秒）</span><br><span class="line">    timeout client  50000</span><br><span class="line">    # 服务器超时（毫秒）</span><br><span class="line">    timeout server  50000</span><br><span class="line"></span><br><span class="line"># 监控界面    </span><br><span class="line">listen  admin_stats</span><br><span class="line">    # 监控界面的访问的IP和端口</span><br><span class="line">    bind  0.0.0.0:8888</span><br><span class="line">    # 访问协议</span><br><span class="line">    mode        http</span><br><span class="line">    # URI相对地址</span><br><span class="line">    stats uri   /dbs</span><br><span class="line">    # 统计报告格式</span><br><span class="line">    stats realm     Global\ statistics</span><br><span class="line">    # 登陆账户信息</span><br><span class="line">    stats auth  admin:admin</span><br><span class="line"># 数据库负载均衡</span><br><span class="line">listen  proxy-pxc</span><br><span class="line">    # 访问的IP和端口</span><br><span class="line">    bind  0.0.0.0:3306  </span><br><span class="line">    # 网络协议</span><br><span class="line">    mode  tcp</span><br><span class="line">    # 负载均衡算法（轮询算法）</span><br><span class="line">    # 轮询算法：roundrobin</span><br><span class="line">    # 权重算法：static-rr</span><br><span class="line">    # 最少连接算法：leastconn</span><br><span class="line">    # 请求源IP算法：source </span><br><span class="line">    balance  roundrobin</span><br><span class="line">    # 日志格式</span><br><span class="line">    option  tcplog</span><br><span class="line">    # Haproxy使用MySQL的haproxy账户对数据库进行心跳检测</span><br><span class="line">    option  mysql-check user haproxy</span><br><span class="line">    server  PXC_Node_1 172.30.0.2:3306 check weight 1 maxconn 2000  </span><br><span class="line">    server  PXC_Node_2 172.30.0.3:3306 check weight 1 maxconn 2000  </span><br><span class="line">    server  PXC_Node_3 172.30.0.4:3306 check weight 1 maxconn 2000 </span><br><span class="line">    # 使用Keepalived检测死链</span><br><span class="line">    option  tcpka</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>在上述 Haproxy 的配置文件中，不能启用 <code>chroot /usr/local/etc/haproxy</code>，否则 Haproxy 容器会启动失败（日志信息如下），暂时不清楚其原因。</p></div><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[NOTICE]   (1) : New worker (8) forked</span><br><span class="line">[NOTICE]   (1) : Loading success.</span><br><span class="line">[NOTICE]   (8) : haproxy version is 2.8.3-86e043a</span><br><span class="line">[NOTICE]   (8) : path to executable is /usr/local/sbin/haproxy</span><br><span class="line">[ALERT]    (8) : [haproxy.main()] Cannot chroot(/usr/local/etc/haproxy).</span><br><span class="line">[NOTICE]   (1) : haproxy version is 2.8.3-86e043a</span><br><span class="line">[NOTICE]   (1) : path to executable is /usr/local/sbin/haproxy</span><br><span class="line">[WARNING]  (1) : Current worker (8) exited with code 1 (Exit)</span><br><span class="line">[ALERT]    (1) : exit-on-failure: killing every processes with SIGTERM</span><br><span class="line">[WARNING]  (1) : All workers exited. Exiting... (1)</span><br></pre></td></tr></tbody></table></figure><ul><li>创建并运行 Haproxy 容器，其中的 <code>8888</code> 是 Haproxy 监听的 HTTP 端口（用于提供监控界面的 Web 服务），<code>3306</code> 是 Haproxy 监听的 MySQL 端口（用于转发请求给 PXC 集群节点）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建并运行容器</span></span><br><span class="line">sudo docker run -it -p 4003:8888 -p 4004:3306 -v /var/lib/docker/volumes/haproxy-v2/_data/:/usr/<span class="built_in">local</span>/etc/haproxy --privileged --name=haproxy-node2 --net=pxc-network --ip 172.30.0.6 -d haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看日志信息</span></span><br><span class="line">sudo docker logs -f haproxy-node2</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机内使用浏览器访问 <code>http://192.168.1.221:4003/dbs</code>，打开 Haproxy 的监控界面（如下图所示），登录用户名是 <code>admin</code>，登录密码是 <code>admin</code>。如果可以正常访问 Haproxy 的监控界面，则说明 Haproxy 成功部署。</li></ul><div class="admonition note"><p class="admonition-title">提示</p><p>值得一提的是，上述的 <code>192.168.1.221</code> 是宿主机的 IP 地址，<code>4003</code> 是 Haproxy 容器映射的 HTTP 端口。</p></div><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-6.png"></p><h4 id="安装第二个-Keepalive-服务"><a href="#安装第二个-Keepalive-服务" class="headerlink" title="安装第二个 Keepalive 服务"></a>安装第二个 Keepalive 服务</h4><ul><li>使用 root 权限连接第二个 Haproxy 容器 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连接Haproxy容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -u 0 -it haproxy-node2 /bin/bash</span><br></pre></td></tr></tbody></table></figure><ul><li>在第二个 Haproxy 容器内安装 Keepalived 服务器 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新包索引</span></span><br><span class="line">apt-get update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装软件</span></span><br><span class="line">apt-get install -y vim keepalived</span><br></pre></td></tr></tbody></table></figure><ul><li>在第二个 Haproxy 容器内配置 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建Keepalived的配置文件</span></span><br><span class="line">touch /etc/keepalived/keepalived.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑Keepalived的配置文件，写入以下配置内容（请自行更改网卡设备参数）</span></span><br><span class="line">vim /etc/keepalived/keepalived.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance  VI_1 {</span><br><span class="line">    state  BACKUP           # 必填，Keepalived 的身份（MASTER 是主服务器，BACKUP 是备服务器）</span><br><span class="line">    interface  eth0         # 必填，Docker 的网卡设备，虚拟 IP 所在</span><br><span class="line">    virtual_router_id  51   # 必填，虚拟路由标识，取值在0-255之间，用来区分多个Instance的VRRP组播，同一网段内ID不能重复，主备机器的该值必须为一样</span><br><span class="line">    priority  90            # 必填，用来选举Master的，MASTER 权重要高于 BACKUP，数字越大优先级越高，该项取值范围是1-255（在此范围之外会被识别成默认值100）</span><br><span class="line">    advert_int  1           # 必填，MASTER 和 BACKUP 节点同步检查的时间间隔（单位为秒），主备之间必须一致，可以认为是健康检查的时间间隔</span><br><span class="line">    authentication {        # 必填，主备服务器的验证方式，主备之间必须使用相同的密码才能正常通信</span><br><span class="line">        auth_type  PASS     # 必填，主备服务器的认证方式，其中有两种方式PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位），主备之间必须使用相同的密码才能正常通信</span><br><span class="line">        auth_pass  123456</span><br><span class="line">    }</span><br><span class="line">    virtual_ipaddress {     # 必填，虚拟 IP，可以设置多个虚拟 IP 地址，每行一个</span><br><span class="line">        172.30.0.7</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>在第二个 Haproxy 容器内启动 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service keepalived start</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机内查看第二个 Haproxy 容器内的进程列表，验证 Keepalived 服务是否正常运行 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker top haproxy-node2</span><br></pre></td></tr></tbody></table></figure><h3 id="安装第三个-Keepalive-服务"><a href="#安装第三个-Keepalive-服务" class="headerlink" title="安装第三个 Keepalive 服务"></a>安装第三个 Keepalive 服务</h3><p>在本节中，将在宿主机内安装第三个 Keepalive 服务器，目的是为了实现外网可以正常访问 Docker 内的虚拟 IP。<strong>特别注意，Docker 内的虚拟 IP 默认是不能被外网访问的，所以需要借助宿主机的 Keepalived 映射成外网可以正常访问的虚拟 IP。</strong></p><ul><li>配置宿主机的防火墙，对外开放 <code>8888</code> 和 <code>3306</code> 端口 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看防火墙运行状态</span></span><br><span class="line">sudo systemctl status firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用防火墙</span></span><br><span class="line">sudo systemctl start firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置防火墙永久开放8888和3306端口</span></span><br><span class="line">sudo firewall-cmd --zone=public --permanent --add-port=8888/tcp</span><br><span class="line">sudo firewall-cmd --zone=public --permanent --add-port=3306/tcp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重载防火墙配置</span></span><br><span class="line">sudo firewall-cmd --reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看防火墙已开放的端口</span></span><br><span class="line">sudo firewall-cmd --list-ports</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机内查看当前局域网的 IP 分配情况 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装nmap</span></span><br><span class="line">sudo yum install -y nmap </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前网段所有分配的IP</span></span><br><span class="line">nmap -sP 192.168.1.0/24</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机内安装 Keepalive</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装Keepalive</span></span><br><span class="line">sudo yum install -y keepalived</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动Keepalived</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> keepalived</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机内配置 Keepalive</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份Keepalived的配置文件</span></span><br><span class="line">sudo cp /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑Keepalived的配置文件，覆盖写入以下配置内容（请自行更改网卡设备参数）</span></span><br><span class="line">sudo vim /etc/keepalived/keepalived.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance VI_1 {</span><br><span class="line">    state MASTER</span><br><span class="line">    # 这里指定是宿主机的网卡，可以通过 "ip a" 命令查看当前系统上使用的网卡是哪个</span><br><span class="line">    interface enp0s3</span><br><span class="line">    virtual_router_id 100</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication {</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    }</span><br><span class="line">    virtual_ipaddress {</span><br><span class="line">           # 这里是指定宿主机上的一个虚拟IP，一定要和宿主机网卡在同一个网段，例如宿主机网卡的IP是192.168.1.221，那么指定的虚拟IP可以是192.168.1.160</span><br><span class="line">           192.168.1.160</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"># 接收HTTP数据，用于访问Haproxy的Web监控页面</span><br><span class="line">virtual_server 192.168.1.160 8888 {</span><br><span class="line">    delay_loop 3</span><br><span class="line">    lb_algo rr </span><br><span class="line">    lb_kind NAT</span><br><span class="line">    persistence_timeout 50</span><br><span class="line">    protocol TCP</span><br><span class="line">    # 将宿主机接收到的数据，转发给Haproxy容器内的虚拟IP和HTTP端口</span><br><span class="line">    real_server 172.30.0.7 8888 {</span><br><span class="line">        weight 1</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"># 接收数据库请求，用于访问Haproxy代理的MySQL端口</span><br><span class="line">virtual_server 192.168.1.160 3306 {</span><br><span class="line">    delay_loop 3</span><br><span class="line">    lb_algo rr </span><br><span class="line">    lb_kind NAT</span><br><span class="line">    persistence_timeout 50</span><br><span class="line">    protocol TCP</span><br><span class="line">    # 将宿主机接收到的数据，转发给Haproxy容器内的虚拟IP和MySQL端口</span><br><span class="line">    real_server 172.30.0.7 3306 {</span><br><span class="line">        weight 1</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机内启动 Keepalived</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">sudo systemctl start keepalived</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行状态</span></span><br><span class="line">sudo systemctl status keepalived</span><br></pre></td></tr></tbody></table></figure><h3 id="双机热备方案部署验证"><a href="#双机热备方案部署验证" class="headerlink" title="双机热备方案部署验证"></a>双机热备方案部署验证</h3><ul><li>在其他电脑上，如果可以通过宿主机的虚拟 IP <code>192.168.1.160</code> 正常访问宿主机 Haproxy 容器中的虚拟 IP <code>172.30.0.7</code> 及相应端口，则说明 PXC + Haproxy + Keepalived 的高可用集群搭建成功。</li></ul><table><thead><tr><th>验证内容</th><th>宿主机的虚拟 IP</th><th> 宿主机的端口</th><th>验证命令</th></tr></thead><tbody><tr><td> Haproxy 的监控页面</td><td> 192.168.1.160</td><td>8888</td><td><code>curl -basic -u admin:admin -I http://192.168.1.160:8888/dbs</code></td></tr><tr><td>Haproxy 的 MySQL 负载均衡</td><td> 192.168.1.160</td><td>3306</td><td><code>mysql -h 192.168.1.160 -u root -P 3306 -p123456</code></td></tr></tbody></table><ul><li>检查两个 Keepalived 节点之间是否可以正常进行心跳通信，如果不能进行心跳通信，则会发生脑裂现象（即两个 Keepalived 节点会同时抢占到虚拟 IP）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用root权限连接Haproxy容器一</span></span><br><span class="line">docker <span class="built_in">exec</span> -u 0 -it haproxy-node1 /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看IP地址</span></span><br><span class="line">ip addr</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用root权限连接Haproxy容器二</span></span><br><span class="line">docker <span class="built_in">exec</span> -u 0 -it haproxy-node2 /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看IP地址</span></span><br><span class="line">ip addr</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机上面关闭 Haproxy 节点一的容器，然后在其他电脑上，打开浏览器访问 <code>http://192.168.1.160:8888/dbs</code>，如果可以正常访问 Haproxy 监控页面，则说明 Haproxy + Keepalived 的双机热备方案生效了。</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭Haproxy节点一的容器</span></span><br><span class="line">sudo docker stop haproxy-node1</span><br></pre></td></tr></tbody></table></figure><ul><li>在宿主机上面关闭 Haproxy 节点一的容器之后，连接进 Haproxy 节点二的容器内部，使用 <code>ip addr</code> 命令查看 IP 地址，可以看见已经抢占到的虚拟 IP</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用root权限连接容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -u 0 -it haproxy-node2 /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看IP地址</span></span><br><span class="line">ip addr</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/10/docker-mysql-pxc-13.png"></p><h2 id="Haproxy-Keepalived-双机热备完善"><a href="#Haproxy-Keepalived-双机热备完善" class="headerlink" title="Haproxy + Keepalived 双机热备完善"></a>Haproxy + Keepalived 双机热备完善</h2><p>在本节中，将介绍上述操作完成之后，Haproxy + Keepalived 双机热备方案仍需要改进的地方。</p><h3 id="Keepalived-服务自启动"><a href="#Keepalived-服务自启动" class="headerlink" title="Keepalived 服务自启动"></a>Keepalived 服务自启动</h3><p>目前集群里有两个 Keepalived 服务分别安装在不同的 Haproxy 容器内，但它们默认都没有配置自启动，也就是说 Keepalived 没有随 Haproxy 容器启动而启动。为了日后方便维护集群，建议将 Haproxy 容器内的 Keepalived 服务统一配置成自启动。可以尝试通过 Dockerfile 自主构建包含有 Haproxy + Keepalived 的 Docker 镜像。由于篇幅有限，这里不再累述。</p><h3 id="Haproxy-保证事务持久性"><a href="#Haproxy-保证事务持久性" class="headerlink" title="Haproxy 保证事务持久性"></a>Haproxy 保证事务持久性</h3><div class="admonition note"><p class="admonition-title">扩展阅读</p><ul><li><a href="https://www.cnblogs.com/f-ck-need-u/p/9370579.html">Haproxy 代理 MySQL 要考虑的问题</a></li></ul></div><p>Haproxy 代理 MySQL 的时候，事务持久性的问题必须解决。这个事务持久性不是 ACID 的 D（持久性，Durability），而是 Transaction Persistent，这里简单描述一下此处的事务持久性。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">start transaction</span><br><span class="line">update1...</span><br><span class="line">update2...</span><br><span class="line">insert3...</span><br><span class="line">commit</span><br></pre></td></tr></tbody></table></figure><p>当客户端显式开启一个事务，然后执行上述几个数据库操作，然后提交或回滚。如果使用代理软件（如 Haproxy）对 MySQL 进行代理，必须要保证这 5 个语句全都路由到同一个 MySQL 节点上，即使后端的 MySQL 采用的是多主模型（MGR、Galera 都提供多主模型），否则事务中各语句分散，轻则返回失败，重则数据不一致、提交混乱。这就是 Transaction Persistent 的概念，即让同一个事务路由到同一个后端节点。Haproxy 如何保证事务持久性呢？对于非 MySQL 协议感知的代理（LVS、Nginx、Haproxy 等），要保证事务持久性，只能通过间接的方法实现，比较通用的方法是在代理软件上监听不同的端口（实现读写分离）。具体的思路如下：</p><ul><li>1）在 Haproxy 上监听不同端口，例如 <code>3307</code> 端口的请求作为写端口，<code>3306</code> 端口的请求作为读端口。</li><li>2）从后端 MySQL 节点中选一个节点 (只能是一个) 作为逻辑写节点，Haproxy 将 <code>3307</code> 端口的请求全都路由给这个节点。</li><li>3）可以在 Haproxy 上配置多个备用写节点 (Backup)，但 <code>3307</code> 端口在某一时刻，路由到的必须只能有一个写节点。</li></ul><p>这样能保证事务的持久性，也能解决一些乐观锁问题。但是，如果后端是多主模型的 MGR（组复制）或 Galera，这样的代理方式将强制变为单主模型，虽然是逻辑上的强制。当然，这并非什么问题，至少到目前为止的开源技术，都建议采用单主模型。Haproxy 保证事务持久性的配置示例如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">listen  haproxy_3306_read_multi</span><br><span class="line">        bind *:3306</span><br><span class="line">        mode tcp</span><br><span class="line">        timeout client  10800s</span><br><span class="line">        timeout server  10800s</span><br><span class="line">        balance leastconn</span><br><span class="line">        option httpchk</span><br><span class="line">        option allbackups</span><br><span class="line">        default-server port 9200 inter 2s downinter 5s rise 3 fall 2 slowstart 60s maxconn 64 maxqueue 128 weight 100</span><br><span class="line">        server galera1 192.168.55.111:3306 check</span><br><span class="line">        server galera2 192.168.55.112:3306 check</span><br><span class="line">        server galera3 192.168.55.113:3306 check</span><br><span class="line"> </span><br><span class="line">listen  haproxy_3307_write_single</span><br><span class="line">        bind *:3307</span><br><span class="line">        mode tcp</span><br><span class="line">        timeout client  10800s</span><br><span class="line">        timeout server  10800s</span><br><span class="line">        balance leastconn</span><br><span class="line">        option httpchk</span><br><span class="line">        option allbackups</span><br><span class="line">        default-server port 9200 inter 2s downinter 5s rise 3 fall 2 slowstart 60s maxconn 64 maxqueue 128 weight 100</span><br><span class="line">        server galera1 192.168.55.111:3306 check</span><br><span class="line">        server galera2 192.168.55.112:3306 check backup</span><br><span class="line">        server galera3 192.168.55.113:3306 check backup</span><br></pre></td></tr></tbody></table></figure><p>上面的配置通过 <code>3306</code> 端口和 <code>3307</code> 端口进行读写分离，并且在负责写的 <code>3307</code> 端口中只有一个节点可写，其余两个节点作为 Backup 节点。对于 MySQL 的负载来说，更建议采用 MySQL 协议感知的程序来实现，例如 MySQL Router、ProxySql，MaxScale、MyCat 等数据库中间件。</p><h3 id="Keepalived-监控-Haproxy-运行状态"><a href="#Keepalived-监控-Haproxy-运行状态" class="headerlink" title="Keepalived 监控 Haproxy 运行状态"></a>Keepalived 监控 Haproxy 运行状态</h3><p>上述两个 Haproxy 容器内的 Keepalived 服务，彼此仅仅是基于心跳检测来实现双机热备（故障切换）。如果第一个 Haproxy 容器内的 Keepalived 服务（Master）正常运行，而 Haproxy 自身运行异常，那么将会出现 Haproxy 负载均衡服务失效，无法切换到备用的 Haproxy 负载均衡器上，最终导致后端的 Web 服务无法收到响应。所以，<strong>应该是要基于 Shell 脚本每隔一段时间检测 Haproxy 服务是否正常运行，而不是仅仅依靠 Keepalived 主备节点之间的心跳检测。</strong>比如，当检测到 Haproxy 服务不是正常运行，首先尝试启动 Haproxy 服务；若 Haproxy 服务重启失败，就应该关闭掉该节点上的 Keepalived 服务，并发送报警邮件，这样才能自动切换到 Keepalived 服务的 Backup 节点上。详细的解决方案建议参考 <a href="/posts/503c34e4.html#Keepalived-%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE">这里</a> 的教程。</p><h2 id="PXC-集群数据备份"><a href="#PXC-集群数据备份" class="headerlink" title="PXC 集群数据备份"></a>PXC 集群数据备份</h2><h3 id="数据库备份方案"><a href="#数据库备份方案" class="headerlink" title="数据库备份方案"></a>数据库备份方案</h3><ul><li><p>冷备份</p><ul><li>冷备份是关闭数据库时候的备份方式，通常做法是拷贝数据文件。</li><li>是简单安全的一种备份方式，但不能在数据库运行时进行备份。</li><li>大型网站无法做到关闭业务备份数据，所以冷备份不是最佳选择。</li></ul></li><li><p>热备份</p><ul><li>热备份是在数据库运行状态下备份数据，MySQL 常见的热备份有 <code>LVM</code> 和 <code>XtraBackup</code> 两种方案。</li><li><code>LVM</code> 热备份方案<ul><li> Linux 的分区备份命令，可以备份任何数据库。</li><li>会对数据库加锁，备份期间只能读取数据库，而且命令复杂。</li></ul></li><li><code>XtraBackup</code> 热备份方案<ul><li>基于 InnoDB 的在线热备工具，开源免费</li><li>备份过程中不锁表，快速可靠</li><li>备份过程中不会打断正在执行地事务</li><li>备份数据经过压缩，占用磁盘空间小</li><li>能够非常快速地备份与恢复 MySQL 数据库</li></ul></li></ul></li><li><p>全量备份与增量备份</p><ul><li><code>全量备份</code>：备份全部数据。备份过程时间长，占用空间大。第一次备份要使用全量备份。</li><li><code>增量备份</code>： 只备份变化的那部分数据。备份的时间短，占用空间小。第二次以后可以使用增量备份</li></ul></li></ul><h3 id="PXC-全量备份（暂未验证）"><a href="#PXC-全量备份（暂未验证）" class="headerlink" title="PXC 全量备份（暂未验证）"></a>PXC 全量备份（暂未验证）</h3><ul><li>备份操作要在某个 PXC 集群节点的 Docker 容器内执行，但应该把备份数据保存到宿主机内，因此先创建用于存储备份数据的数据卷 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建数据卷，用于存储备份数据</span></span><br><span class="line">sudo docker volume create backup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有数据卷</span></span><br><span class="line">sudo docker volume ls</span><br></pre></td></tr></tbody></table></figure><ul><li>挑选第二个 PXC 集群节点 <code>pxc-node2</code>，将其容器关闭并删除掉，然后重新创建一个挂载了 <code>backup</code> 数据卷的 <code>pxc-node2</code> 容器 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭容器</span></span><br><span class="line">sudo docker stop pxc-node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除容器，由于数据库的数据存放在数据卷 "pxc-v2" 中，所以数据不会丢失</span></span><br><span class="line">sudo docker rm pxc-node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建容器（增加挂载"backup"数据卷）</span></span><br><span class="line">sudo docker create -p 13307:3306 -v pxc-v2:/var/lib/mysql -v backup:/data -e MYSQL_ROOT_PASSWORD=123456 -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_NAME=pxc -e CLUSTER_JOIN=pxc-node1 --name=pxc-node2 --net=pxc-network --ip 172.30.0.3 pxc</span><br></pre></td></tr></tbody></table></figure><ul><li>在新创建的 <code>pxc-node2</code> 容器中安装 <code>xtrabackup</code> 工具 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动容器</span></span><br><span class="line">sudo docker start pxc-node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用root权限连容器</span></span><br><span class="line">sudo docker <span class="built_in">exec</span> -u 0 -it pxc-node2 /bin/bash</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装存储库包</span></span><br><span class="line">yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用存储库</span></span><br><span class="line">percona-release enable-only tools release</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装XtraBackup工具</span></span><br><span class="line">yum install -y percona-xtrabackup-80</span><br></pre></td></tr></tbody></table></figure><ul><li>使用 XtraBackup 全量备份数据库数据 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建存放备份数据的目录</span></span><br><span class="line">mkdir -p /data/backup/full</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全量备份数据库数据</span></span><br><span class="line">xtrabackup --backup -uroot -p123456 --target-dir=/data/backup/full</span><br></pre></td></tr></tbody></table></figure><h3 id="PXC-全量还原（暂未验证）"><a href="#PXC-全量还原（暂未验证）" class="headerlink" title="PXC 全量还原（暂未验证）"></a>PXC 全量还原（暂未验证）</h3><p>数据库可以热备份，但是不能热还原，否则会造成业务数据和还原数据的冲突。针对 PXC 集群，为了避免在还原过程中可能出现各节点数据同步冲突的问题，需要先解散原来的集群（删除所有集群节点），然后重新创建空白数据库节点，再执行数据库冷还原操作，最后再创建其他集群节点。还原前还要将热备份保存的未提交的事务回滚，还原之后重启 MySQL 服务器。</p><ul><li>关闭并删除所有 PXC 集群节点 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭容器</span></span><br><span class="line">sudo docker stop pxc-node1 pxc-node2 pxc-node3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除容器</span></span><br><span class="line">sudo docker rm pxc-node1 pxc-node2 pxc-node3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除数据卷（强烈建议在删除之前备份所有数据卷文件）</span></span><br><span class="line">sudo docker volume rm pxc-v1 pxc-v2 pxc-v3</span><br></pre></td></tr></tbody></table></figure><ul><li>按照之前的步骤重新创建第一个节点的容器 <code>pxc-node1</code>，并进入容器内，执行冷还原操作 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建第一个节点的数据卷</span></span><br><span class="line">docker volume create pxc-v1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建第一个节点的容器（增加挂载"backup"数据卷）</span></span><br><span class="line">sudo docker create -p 13306:3306 -v pxc-v1:/var/lib/mysql -v backup:/data -e MYSQL_ROOT_PASSWORD=123456 -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_NAME=pxc --name=pxc-node1 --net=pxc-network --ip 172.30.0.2 pxc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动第一个节点的容器</span></span><br><span class="line">sudo docker start pxc-node1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用root权限连第一个节点的容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it -uroot pxc-node1 /bin/bash</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 准备还原</span></span><br><span class="line">xtrabackup --prepare --target-dir=/data/backup/full/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始冷还原</span></span><br><span class="line">xtrabackup --copy-back --target-dir=/data/backup/full/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改还原后的数据库文件属主</span></span><br><span class="line">chown -R mysql:mysql /var/lib/mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 断开容器连接</span></span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭第一个节点的容器</span></span><br><span class="line">docker stop pxc-node1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启第一个节点的容器</span></span><br><span class="line">docker start pxc-node1</span><br></pre></td></tr></tbody></table></figure><ul><li>创建第二个与第三个节点的容器 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建第二个节点的数据卷</span></span><br><span class="line">sudo docker volume create --name pxc-v2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建第三个节点的数据卷</span></span><br><span class="line">sudo docker volume create --name pxc-v3</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建第二个节点（增加了CLUSTER_JOIN参数）</span></span><br><span class="line">sudo docker create -p 13307:3306 -v pxc-v2:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_NAME=pxc -e CLUSTER_JOIN=pxc-node1 --name=pxc-node2 --net=pxc-network --ip 172.30.0.3 pxc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建第三个节点（增加了CLUSTER_JOIN参数）</span></span><br><span class="line">sudo docker create -p 13308:3306 -v pxc-v3:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_NAME=pxc -e CLUSTER_JOIN=pxc-node1 --name=pxc-node3 --net=pxc-network --ip 172.30.0.4 pxc</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动第二节点（首次启动比较耗时间，因为需要同步第一个节点的数据）</span></span><br><span class="line">sudo docker start pxc-node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动第三节点（首次启动比较耗时间，因为需要同步第一个节点的的数据）</span></span><br><span class="line">sudo docker start pxc-node3</span><br></pre></td></tr></tbody></table></figure><h2 id="PXC-集群日常维护"><a href="#PXC-集群日常维护" class="headerlink" title="PXC 集群日常维护"></a>PXC 集群日常维护</h2><div class="admonition warning"><p class="admonition-title">特别注意</p><p>对于 PXC 集群节点的启动、关闭等操作，区分第一个节点（负责集群初始化）和其他节点，两者的操作步骤是不同的。</p></div><h3 id="正确关闭集群"><a href="#正确关闭集群" class="headerlink" title="正确关闭集群"></a>正确关闭集群</h3><p>如果第一个节点（负责集群初始化）不是最后一个离开集群的，那么它在一般情况下就不能再以第一个节点的形式启动了。这是因为从这个节点引导集群启动可能是不安全的，即这个节点可能不包含所有更新的数据。<strong>综上所述，PXC 集群节点的正确关闭顺序，应该与它们的启动顺序相反（类似栈结构 - 先进后出），即最先启动的节点应该最后关闭。</strong></p><ul><li>PXC 集群节点容器的正确关闭顺序 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭节点三</span></span><br><span class="line">sudo docker stop pxc-node3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭节点二</span></span><br><span class="line">sudo docker stop pxc-node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭节点一</span></span><br><span class="line">sudo docker stop pxc-node1</span><br></pre></td></tr></tbody></table></figure><ul><li>PXC 集群节点容器的正确启动顺序 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动节点一</span></span><br><span class="line">sudo docker start pxc-node1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动节点二</span></span><br><span class="line">sudo docker start pxc-node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动节点三</span></span><br><span class="line">sudo docker start pxc-node3</span><br></pre></td></tr></tbody></table></figure><h3 id="正确关闭与启动节点"><a href="#正确关闭与启动节点" class="headerlink" title="正确关闭与启动节点"></a>正确关闭与启动节点</h3><p>如果是希望 PXC 集群关闭某个节点（非第一个节点），正确的步骤如下：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭节点</span></span><br><span class="line">sudo docker stop pxc-node2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">sudo docker ps -a</span><br></pre></td></tr></tbody></table></figure><p>某个节点（非第一个节点）关闭之后，其他维护工作也完成了，若希望将该节点重新加入 PXC 集群，可以执行以下命令：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动节点</span></span><br><span class="line">sudo docker start pxc-node2</span><br></pre></td></tr></tbody></table></figure><h3 id="第一个节点不是最后一个离开集群"><a href="#第一个节点不是最后一个离开集群" class="headerlink" title="第一个节点不是最后一个离开集群"></a>第一个节点不是最后一个离开集群</h3><p><strong>如果第一个节点（负责集群初始化）不是最后一个离开集群的，不能再以第一个节点的形式启动了。</strong></p><ul><li>第一个节点（负责集群初始化）关闭后，希望重新加入 PXC 集群，此时运行 <code>sudo docker start pxc-node1</code> 命令，会发现第一个节点的容器没有正常启动</li><li>启动失败的原因往往是：此时从第一个节点引导集群启动可能是不安全。由于该节点不是最后一个离开集群的节点（最后停掉的节点），可能没有包含所有更新的数据</li><li>如果此时所有集群节点都处于关闭状态<ul><li>首先逐一排查每个节点的数据卷目录，查看数据卷目录下是否存在 <code>grastate.dat</code> 文件，并找到 <code>safe_to_bootstrap=1</code> 的节点<ul><li>如果找到 <code>safe_to_bootstrap=1</code> 的节点，且它不是第一个节点（负责集群初始化）<ul><li>此时为了方便操作，建议先将所有节点容器关闭并删除掉，在删除所有节点容器之前，必须确保数据卷目录的数据不被误删，否则会丢失所有数据库数据</li><li>然后再按照 <a href="/posts/aba17375.html#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2">上面的步骤</a>，重新创建并启动每一个 PXC 集群节点容器</li><li>最后再检查集群的数据是否可以正常同步</li></ul></li><li>如果找到 <code>safe_to_bootstrap=1</code> 的节点，且它是第一个节点（负责集群初始化），或者根本找不到 <code>safe_to_bootstrap=1</code> 的节点<ul><li>这时，需要通过 <code>sudo docker volume inspect pxc-v1</code> 得到第一个节点的数据卷目录路径，找到数据卷目录下的 <code>grastate.dat</code> 文件</li><li>打开第一个节点下的 <code>grastate.dat</code> 文件，将 <code>safe_to_bootstrap</code> 设置为 <code>1</code></li><li>然后直接使用 <code>sudo docker start pxc-node1</code> 命令强制从第一个节点启动</li><li>等第一个节点正常启动后，再接着启动其他节点</li><li>最后再检查集群的数据是否可以正常同步</li></ul></li></ul></li></ul></li><li>如果此时集群里还至少有一个节点存活（例如节点三存活着）<ul><li>首先删除第一个节点的容器，<code>sudo docker stop pxc-node1</code>、<code>sudo docker rm pxc-node1</code></li><li>重新创建一个新节点的容器，<code>sudo docker create -p 13306:3306 -v pxc-v1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_NAME=pxc -e CLUSTER_JOIN=pxc-node3 --name=pxc-node1 --net=pxc-network --ip 172.30.0.2 pxc</code></li><li>在创建新节点的容器时，是以普通节点形式（非第一个节点的形式）加入集群的，注意创建新节点容器的命令行参数是包含 <code>-e CLUSTER_JOIN=pxc-node3</code>，这里的 <code>pxc-node3</code> 是集群中存活着的节点三</li><li>然后启动新节点的容器，<code>sudo docker start pxc-node1</code></li><li>最后再检查集群的数据是否可以正常同步</li></ul></li></ul><h3 id="系统重启之后，PXC-集群启动失败"><a href="#系统重启之后，PXC-集群启动失败" class="headerlink" title="系统重启之后，PXC 集群启动失败"></a>系统重启之后，PXC 集群启动失败</h3><p>Docker 所在的 Windows/Linux 操作系统重启后，导致所有 PXC 集群节点都意外关闭了，此时选择 PXC 集群中的第一个节点容器进行重启，出现以下的错误信息：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] WSREP: It may not be safe to bootstrap the cluster from this node. It was not the last one to leave the cluster and may not contain all the updates. To force cluster bootstrap with this node, edit the grastate.dat file manually and set safe_to_bootstrap to 1 .</span><br></pre></td></tr></tbody></table></figure><ul><li>意思是从这个节点引导集群启动可能是不安全。由于该节点不是最后一个离开集群的节点（最后停掉的节点），可能没有包含所有更新的数据，强制从该节点启动，需要手工编辑该节点的 <code>grastate.dat</code> 文件，设置 <code>safe_to_bootstrap=1</code>。</li><li>当然了，一般情况下不需要强制从该节点启动，可以逐一排查每个节点下的 <code>grastate.dat</code> 文件，找到 <code>safe_to_bootstrap=1</code> 的节点。</li><li>如果 <code>safe_to_bootstrap=1</code> 的节点是第一个节点，那么可以直接在该节点上引导 PXC 集群启动，然后再启动其他节点。</li><li>如果 <code>safe_to_bootstrap=1</code> 的节点不是第一个节点，此时为了方便操作，建议先将所有节点容器关闭并删除掉，然后再按照 <a href="/posts/aba17375.html#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2">上面的步骤</a>，重新创建并启动每一个 PXC 集群节点容器。</li><li>如果所有节点的 <code>safe_to_bootstrap</code> 都为 <code>0</code>，那么只能任意选择一个节点，更改该节点下的 <code>grastate.dat</code> 文件，将 <code>safe_to_bootstrap</code> 设置为 <code>1</code>，然后在该节点上引导 PXC 集群启动，最后再启动其他节点。</li><li><strong>无论是上述哪种情况，都必须等待第一个节点启动成功，也就是 PXC 集群初始化完成之后，才能接着启动其他节点，最后再检查集群的数据是否可以正常同步。</strong></li></ul><div class="admonition note"><p class="admonition-title">提示</p><ul><li><code>grastate.dat</code> 文件的路径是 <code>/var/lib/docker/volumes/xxxx/_data/grastate.dat</code>，其中的 <code>xxx</code> 是容器数据卷的目录名称。</li></ul></div><h3 id="最坏情况，所有节点容器重新创建"><a href="#最坏情况，所有节点容器重新创建" class="headerlink" title="最坏情况，所有节点容器重新创建"></a>最坏情况，所有节点容器重新创建</h3><p>假设由于各种原因导致整个 PXC 集群无法正常启动，此时可以将所有节点容器关闭并删除掉（<strong>必须确保数据卷目录的数据不被误删，否则会丢失所有数据库数据</strong>），然后再按照 <a href="/posts/aba17375.html#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2">上面的步骤</a>，重新创建并启动每一个 PXC 集群节点容器。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.cnblogs.com/wanglei957/p/11819547.html">Docker 部署 MySQL 集群</a></li><li><a href="https://www.cnblogs.com/f-ck-need-u/p/9370579.html">Haproxy 代理 MySQL 要考虑的问题</a></li><li><a href="https://cloud.tencent.com/developer/article/1929627">CentOS 7 部署 PXC 集群 【Docker + 单机多节点】</a></li><li><a href="https://www.cnblogs.com/ll409546297/p/17129532.html">MySQL 之 PXC 集群模式（Docker + MySQL + PXC 实现）</a></li><li><a href="https://www.cnblogs.com/nhdlb/p/14032657.html">Docker 部署 PXC 5.7 集群 - 搭建负载均衡实现双机热部署方案</a></li><li><a href="https://www.cnblogs.com/pengboke/p/15012571.html#node3">Docker 部署 PXC 集群 (Haproxy 负载均衡、Keepalived 高可用、XtraBackup 数据备份)</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍如何基于 Docker 部署 MySQL 的 PXC 5.7 单机集群，包括使用 Haproxy + Keepalived 实现双机热备方案。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="容器化" scheme="https://www.techgrow.cn/tags/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 高可用基础教程之四数据可靠性方案介绍</title>
    <link href="https://www.techgrow.cn/posts/56993278.html"/>
    <id>https://www.techgrow.cn/posts/56993278.html</id>
    <published>2023-10-22T12:13:32.000Z</published>
    <updated>2023-10-22T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/2f77f23a.html">MySQL 高可用基础教程之一主从复制方案介绍</a></li><li><a href="/posts/d6058b93.html">MySQL 高可用基础教程之二高可用架构方案介绍</a></li><li><a href="/posts/cc846db2.html">MySQL 高可用基础教程之三高可用架构方案介绍</a></li><li><a href="/posts/56993278.html">MySQL 高可用基础教程之四数据可靠性方案介绍</a></li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="数据可靠性方案分类"><a href="#数据可靠性方案分类" class="headerlink" title="数据可靠性方案分类"></a>数据可靠性方案分类</h3><table><thead><tr><th>数据可靠性方案</th><th>说明</th></tr></thead><tbody><tr><td> RAID 10</td><td> 适用于对数据冗余性和性能要求较高的应用场景，如数据库服务器、虚拟化环境和高性能计算等。</td></tr><tr><td>SAN 存储网络</td><td>除了价格贵，没有太多缺点。</td></tr><tr><td>DRBD 磁盘复制</td><td> Linux 内核模块实现的磁盘块级别的同步复制技术。</td></tr></tbody></table><span id="more"></span><h2 id="RAID-10"><a href="#RAID-10" class="headerlink" title="RAID 10"></a>RAID 10</h2><p>RAID 10（Redundant Array of Independent Disks 10）是一种存储方案，它结合了 RAID 1（镜像）和 RAID 0（条带化）的特性。RAID 10 通过将多个磁盘组合在一起，提供了数据冗余和性能增强的优势。在 RAID 10 中，磁盘被分为两组，每组至少有两个磁盘。其中一组磁盘使用 RAID 1（镜像）技术，即数据被同时写入两个磁盘，提供了数据的冗余备份。另一组磁盘使用 RAID 0（条带化）技术，即数据被分块地写入多个磁盘，提供了更好的读写性能。</p><div class="admonition note"><p class="admonition-title">提示</p><ul><li>RAID 10 数据可靠性方案在金融、银行领域使用的比较多。</li><li>RAID 10 适用于对数据冗余性和性能要求较高的应用场景，如数据库服务器、虚拟化环境和高性能计算等。</li><li>RAID 10 的容量利用率较低，如果容量是一个关键因素，可能需要考虑其他 RAID 级别。在选择 RAID 级别时，需要根据具体的需求和预算来权衡各种因素。</li></ul></div><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/10/mysql-ha-17.png"></p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li><p>优点</p><ul><li><code>数据冗余</code>：RAID 10 通过镜像技术提供了数据的冗余备份。如果一个磁盘发生故障，数据仍然可以从镜像磁盘中恢复，保证了数据的可靠性和可用性。</li><li><code>高性能</code>：RAID 10 通过条带化技术提供了更好的读写性能。数据可以同时从多个磁盘读取或写入，提高了数据访问的速度和吞吐量。</li><li><code>故障容忍</code>：由于 RAID 10 具有数据冗余性，当一个磁盘发生故障时，系统可以继续正常运行，并且可以在更换故障磁盘后进行数据恢复，减少了系统停机时间。</li></ul></li><li><p>缺点</p><ul><li><code>成本较高</code>：由于 RAID 10 需要使用多个磁盘进行数据镜像和条带化，所以成本较高。相比其他 RAID 级别，RAID 10 需要更多的磁盘。</li><li><code>容量利用率较低</code>：RAID 10 的容量利用率较低，因为数据被同时写入两个磁盘。例如，如果有 4 个 1TB 的磁盘组成 RAID 10，实际可用的存储容量只有 2TB。</li></ul></li></ul><h2 id="SAN-存储网络"><a href="#SAN-存储网络" class="headerlink" title="SAN 存储网络"></a>SAN 存储网络</h2><p>SAN（Storage Area Network）是一种专门用于存储数据的高速网络架构。它将存储设备（如磁盘阵列、磁带库等）与服务器连接起来，提供高性能、高可用性和可扩展性的共享存储解决方案。</p><div class="admonition note"><p class="admonition-title">提示</p><ul><li>SAN 存储网络适用于对存储性能、可用性和扩展性要求较高的应用场景，如大型企业、数据中心、虚拟化环境等。</li><li>在选择和部署 SAN 存储网络时，需要根据具体的需求和预算来权衡各种因素，并确保与服务器和应用程序的兼容性。</li></ul></div><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li><p>优点</p><ul><li><code>存储共享</code>：SAN 允许多台服务器共享存储设备，使得数据可以在不同的服务器之间共享和访问。这样可以提高数据的灵活性和共享性，减少存储资源的浪费。</li><li><code>高性能</code>：SAN 使用高速的网络连接（如光纤通道、以太网等），提供了高带宽和低延迟的数据传输。这使得存储设备可以提供更高的读写性能，满足对存储性能要求较高的应用场景。</li><li><code>可扩展性</code>：SAN 具有良好的可扩展性，可以根据需求灵活地扩展存储容量和性能。通过添加新的存储设备或扩展现有设备的容量，可以满足不断增长的存储需求。</li><li><code>管理简便</code>：SAN 提供了集中管理和监控的功能，使得存储资源的配置、监控和管理变得更加简便和高效。管理员可以通过集中的管理界面对存储设备进行配置和管理，提高了管理效率。</li><li><code>数据强一致性</code>：可以很好地保证数据的强一致性，不会因为 MySQL 的逻辑错误发生数据不一致的情况。</li><li><code>部署简单</code>：部署两节点即可，不依赖数据库实现，保障数据安全。</li></ul></li><li><p>缺点</p><ul><li><code>不具备故障转移</code>：需要考虑共享存储的高可用性。</li><li><code>成本较高</code>：相比于其他存储解决方案，SAN 的成本较高。它需要专用的硬件设备和高速网络连接，这增加了部署和维护的成本。</li><li><code>配置复杂性</code>：SAN 的配置和管理相对复杂，需要专业的知识和技能。对于不熟悉 SAN 的用户来说，配置和管理可能是一项具有挑战性的任务。</li></ul></li></ul><h2 id="DRBD-磁盘复制"><a href="#DRBD-磁盘复制" class="headerlink" title="DRBD 磁盘复制"></a>DRBD 磁盘复制</h2><p>DRBD（Distrubuted Replicated Block Device）是一种构建高可用分布式网络存储解决方案的专业工具（由 Linux 内核提供），可用于对服务器之间的磁盘、分区、逻辑卷等进行数据同步。当用户将数据写入本地磁盘时，会将数据发送到网络中另一台主机的磁盘上，这样的本地主机（主节点）与远程主机（备节点）的数据就可以保证实时同步。DRBD 主要用于数据传输、复制和同步，可以在网络存储节点之间实现可靠性更高的数据备份，也常用于构建高可用的存储节点及其他组件，如集群、负载均衡和存储服务器等。</p><div class="admonition note"><p class="admonition-title">DRBD 结合 MySQL 使用</p><p>DRBD 与 MySQL 结合使用可以实现高可用性的数据库方案。通过将 MySQL 数据库的数据目录配置为 DRBD 设备，加上额外的配置和管理工具（如 Pacemaker），可以为数据库提供实时复制和故障转移的能力，从而提高数据库的可靠性和可用性。当主节点发生故障时，系统可以自动切换到备节点，减少数据库服务的中断时间。<strong>DRBD 经典架构的组合是 MySQL + DRBD + Heartbeat。</strong></p></div><h3 id="整体架构-1"><a href="#整体架构-1" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/10/mysql-ha-16.png"></p><p>在 MySQL 与 DRBD 方案中，通常会有两个节点：一个主节点和一个备节点。主节点负责处理所有的读写操作，并将数据实时复制到备节点上。备节点会持续地从主节点复制数据，以保持数据的一致性。当主节点发生故障时，备节点可以接管主节点的角色，成为新的主节点，继续提供数据库服务。这种故障转移过程是自动的，可以通过配置和管理工具（如 Pacemaker）来实现。需要注意的是，配置和管理 MySQL 与 DRBD 方案需要一定的技术知识和经验。此外，对网络的稳定性和带宽要求较高，以确保数据的实时复制和同步。因此，在实施该方案之前，建议进行充分的规划和测试，以确保系统的稳定性和可靠性。</p><h3 id="优缺点-2"><a href="#优缺点-2" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li><p>优点</p><ul><li>两节点即可，部署简单，切换逻辑简单。</li><li>相比于 SAN 储存网络，价格低廉。</li><li>保证数据的强一致性。</li></ul></li><li><p>缺点</p><ul><li>从库不提供读服务。</li><li>对 IO 性能的影响较大。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 MySQL 的数据可靠性方案，包括 RAID 10、SAN 存储网络、DRBD 磁盘复制等。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="数据库" scheme="https://www.techgrow.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 高可用基础教程之三高可用架构方案介绍</title>
    <link href="https://www.techgrow.cn/posts/cc846db2.html"/>
    <id>https://www.techgrow.cn/posts/cc846db2.html</id>
    <published>2023-10-21T12:13:32.000Z</published>
    <updated>2023-10-21T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/2f77f23a.html">MySQL 高可用基础教程之一主从复制方案介绍</a></li><li><a href="/posts/d6058b93.html">MySQL 高可用基础教程之二高可用架构方案介绍</a></li><li><a href="/posts/cc846db2.html">MySQL 高可用基础教程之三高可用架构方案介绍</a></li><li><a href="/posts/56993278.html">MySQL 高可用基础教程之四数据可靠性方案介绍</a></li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="高可用架构方案分类"><a href="#高可用架构方案分类" class="headerlink" title="高可用架构方案分类"></a>高可用架构方案分类</h3><table><thead><tr><th>高可用方案</th><th>保证数据强一致性</th><th>使用说明</th><th>描述</th></tr></thead><tbody><tr><td>主从复制</td><td>否</td><td>支持单主</td><td>只适用于对可用性和数据一致性要求较低的业务场景。</td></tr><tr><td>MMM</td><td> 否</td><td>支持单主</td><td>基本淘汰了，在一致性和高并发稳定性等方面有些问题。</td></tr><tr><td>MHA</td><td> 否</td><td>支持单主</td><td>有少数开发者还在用，但也有些问题，也是趋于淘汰的 MySQL 主从高可用方案。</td></tr><tr><td>MGR</td><td> 是</td><td>支持单主 / 多主</td><td>基于 MySQL 官方从 <code>5.7.17</code> 版本开始引入的组复制技术。</td></tr><tr><td>MySQL Cluster</td><td> 是</td><td>支持多主</td><td> MySQL 官方提供的一种分布式数据库解决方案，只支持 NDB 引擎。</td></tr><tr><td>Galera Cluster</td><td> 是</td><td>支持多主</td><td>引领时代的主从复制高可用技术。</td></tr><tr><td>Galera Cluster for MySQL</td><td> 是</td><td>支持多主</td><td> MySQL 对 Galera Cluster 的实现。</td></tr><tr><td>MariaDB Galera Cluster (MGC)</td><td> 是</td><td>支持多主</td><td> MariaDB 对 Galera Cluster 的实现。</td></tr><tr><td>Percona XtraDB Cluster (PXC)</td><td> 是</td><td>支持多主</td><td> Percona 对 Galera Cluster 的实现，目前业界使用 PXC 的会多一些。</td></tr><tr><td>MySQL InnoDB Cluster</td><td> 是</td><td>支持单主 / 多主</td><td> MySQL 官方推出的一套完整高可用性解决方案。</td></tr></tbody></table><span id="more"></span><h2 id="Galera-Cluster"><a href="#Galera-Cluster" class="headerlink" title="Galera Cluster"></a>Galera Cluster</h2><p><a href="https://galeracluster.com/">Galera Cluster</a> 是由 Codership 开源的一套基于同步多主复制的 MySQL 集群解决方案。目前 Galera Cluster 有三种版本（实现方案），分别是 Galera Cluster for MySQL、MariaDB Galera Cluster (MGC) 及 Percona Xtradb Cluster (PXC)。Galera Cluster 使用 Galera Replication 插件，通过在多个 MySQL 节点之间同步数据来实现高可用性和负载均衡。其本身具有 Multi-Master (多主) 特性，支持多点写入（<strong>所有节点都可以同时读写数据库</strong>），Galera Cluster 中每个实例都是对等的，互为主从。当客户端读写数据的时候，可以选择任一 MySQL 实例，对于读操作，每个实例读取到的数据都是相同的。对于写操作，当数据写入某一节点后，集群会将其同步到其它节点。这种架构不共享任何数据，是一种高冗余架构。</p><div class="admonition note"><p class="admonition-title">如何选择版本？</p><p>建议采用 Percona XtraDB Cluster，因为技术比较成熟，而且国内很多企业在生产线上用的更多一些。</p></div><h3 id="版本区别"><a href="#版本区别" class="headerlink" title="版本区别"></a>版本区别</h3><p>Galera Cluster for MySQL、MariaDB Galera Cluster (MGC) 与 Percona Xtradb Cluster (PXC) 三者的区别如下：</p><ul><li><p><code>版本不同</code></p><ul><li>三者使用的 Galera Cluster 版本不同，因此在功能和性能上存在一些的差异。</li></ul></li><li><p><code>发行版不同</code>：</p><ul><li>MariaDB Galera Cluster 是由 MariaDB 基金会开发的，支持 MariaDB 数据库。</li><li>Percona XtraDB Cluster 是由 Percona 公司开发的，支持 Percona Server 数据库。</li><li>Galera Cluster for MySQL 是由 Codership 公司开发的，支持 MySQL 和 Percona Server 数据库。</li></ul></li><li><p><code>功能不同</code>：</p><ul><li>Percona XtraDB Cluster 提供了一些额外的功能，例如在线扩容、在线更改节点角色等。</li><li>MariaDB Galera Cluster 支持 Galera Cluster for MySQL 的所有功能，包括多主写入、并行复制、自动故障检测和恢复等。</li></ul></li><li><p><code>许可证不同</code>：</p><ul><li>MariaDB Galera Cluster 使用 LGPLv2.1 许可证。</li><li>Galera Cluster for MySQL 和 Percona XtraDB Cluster 都使用 GPLv2 许可证。</li></ul></li></ul><div class="admonition note"><p class="admonition-title">MariaDB 与 Percona Server 的关系</p><p>MariaDB 数据库是由原 MySQL 创始人开发，Percona Server 数据库由 Percona 公司开发（使用 XtraDB 存储引擎），两者都是从 MySQL 衍生出来的数据库分支。</p></div><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/10/mysql-ha-9.png"></p><ul><li>Galera Cluster 的核心组件<ul><li><code>Galera Replication 插件</code>：Galera Replication 是一个基于同步复制的插件，用于实现数据的多主复制和一致性。它使用了多主复制协议，确保在集群中的所有节点之间的数据同步和一致性。</li><li><code>Primary Component</code>：Primary Component 是 Galera Cluster 中的主组件，负责处理所有的写操作和读操作。Primary Component 接收来自应用程序的写请求，并将数据复制到其他节点（Secondary Component）上。</li><li><code>Secondary Component</code>：Secondary Component 是 Galera Cluster 中的从组件，负责复制 Primary Component 上的数据。Secondary Component 通过与 Primary Component 进行通信，接收并应用 Primary Component 上的写操作，以保持数据的一致性。</li></ul></li></ul><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><h4 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h4><ul><li><code>初始化集群</code>：在 Galera Cluster 中，首先需要配置和启动一个节点作为初始 Primary Component，并将其配置为 Galera Replication 插件的成员。然后，其他节点可以加入到集群中，并通过与 Primary Component 进行通信，获取数据并成为 Secondary Component。</li><li><code>数据同步和复制</code>：一旦集群初始化完成，Primary Component 开始接收来自应用程序的写请求，并将数据复制到其他节点上。Secondary Component 通过与 Primary Component 进行通信，接收并应用 Primary Component 上的写操作，以保持数据的一致性。</li><li><code>自动故障切换</code>：如果 Primary Component 发生故障，Galera Cluster 会自动选择一个 Secondary Component 作为新的 Primary Component，并将其他节点重新配置为新的 Secondary Component。这个过程是自动的，无需人工干预。</li></ul><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li>优点<ul><li><code>高可用性</code>：Galera Cluster 通过数据的多主复制和自动故障切换，支持自动添加和剔除节点，实现了高可用性。即使某个节点发生故障，集群仍然可以继续提供服务。</li><li><code>数据强一致性</code>：Galera Cluster 使用多主复制协议，确保在集群中的所有节点之间的数据同步和一致性。在写操作提交之前，集群中的成员会达成一致，确保数据在所有节点上的复制是一致的。</li><li><code>简化配置和管理</code>：Galera Cluster 提供了简单易用的配置选项和管理工具，使得集群的配置和管理变得更加简单和方便。</li><li><code>可扩展性</code>：Galera Cluster 支持水平扩展，可以通过增加节点来扩展存储容量和处理能力。同时，由于数据的多主复制和负载均衡，可以实现更好的性能和吞吐量。</li><li><code>拥有成熟的社区</code>：Galera Cluster 拥有成熟的社区，国内有互联网公司在大规模使用。</li><li><code>使用体验一致</code>：用户可以直接连接 Galera Cluster 集群，使用感受上与 MySQL 完全一致。</li><li><code>同步复制</code>：Galera Cluster 使用了同步复制，且支持真正的并行复制（行级）。</li></ul></li><li>缺点<ul><li><code>网络稳定性</code>：Galera Cluster 对网络的稳定性要求较高，因为节点之间需要进行频繁的通信和数据同步。如果网络不稳定，可能会导致数据同步延迟或节点之间的通信故障。</li><li><code>写冲突</code>：由于 Galera Cluster 支持多主复制，如果应用程序在不同的节点上同时进行写操作，可能会导致写冲突和一致性问题。因此，需要在应用程序层面进行合理的设计和处理。</li><li><code>配置复杂性</code>：尽管 Galera Cluster 提供了简化的配置选项和管理工具，但对于不熟悉 Galera Cluster 的用户来说，配置可能是一项具有挑战性的任务。</li><li><code>需要安装补丁</code>：使用 Galera Cluster 时，需要提前为原生 MySQL 节点安装 Wsrep 补丁。</li><li><code>节点数需求</code>：搭建 Galera Cluster 时，要求至少有三个服务器节点，且多节点写入开销大。</li><li><code>使用限制</code><ul><li>不支持 GTID（全局事务标识符）。</li><li>不支持异步复制，所有节点必须同步复制。</li><li>不支持全局临时表，因为它们不能被复制。</li><li>不支持使用外键，因为这会导致复制延迟和性能问题。</li><li>不支持 DDL 语句的自动化复制，需要手动在每个节点上执行。</li><li>不支持非确定性函数，因为它们在不同节点上的结果可能不同。</li><li>不支持存储过程和函数的自动化复制，需要手动在每个节点上创建。</li><li>只支持使用 InnoDB 存储引擎，不支持 MyISAM、NDB 存储引擎。</li></ul></li></ul></li></ul><div class="admonition note"><p class="admonition-title">提示</p><p>在使用 Galera Cluster 之前，建议进行充分的测试和评估，以确保它能够满足系统的可用性、性能和扩展性要求，并根据具体的应用场景和需求进行适当的配置和调整。</p></div><h2 id="Percona-XtraDB-Cluster"><a href="#Percona-XtraDB-Cluster" class="headerlink" title="Percona XtraDB Cluster"></a>Percona XtraDB Cluster</h2><p>Percona XtraDB Cluster（PXC）由 <a href="https://www.percona.com/">Percona</a> 公司开发，是一个基于 <a href="/posts/cc846db2.html#Galera-Cluster">Galera Cluster</a> 实现的高可用性和高性能的 MySQL 集群解决方案。它是由 Percona 开发的，建立在 Galera Replication 插件之上，提供了多主复制和数据同步的功能。</p><h3 id="PXC-的兼容性"><a href="#PXC-的兼容性" class="headerlink" title="PXC 的兼容性"></a>PXC 的兼容性</h3><ul><li>最小化的迁移（可以非常方便地从现有系统迁移到 PXC）。</li><li>快速地回退版本（无锁化、非常容易地恢复到非 PXC 系统）。</li><li>完全兼容已有的系统（InnoDB 存储引擎，优化器执行计划，完全相同的优化思路）。</li></ul><h3 id="PXC-的使用限制"><a href="#PXC-的使用限制" class="headerlink" title="PXC 的使用限制"></a>PXC 的使用限制</h3><ul><li>仅支持 InnoDB 存储引擎，而 MySQL 自带的系统库（如 <code>mysql</code>）里面有些表是使用 MyISAM 存储引擎，因此不能直接对系统库的表进行 DML 操作，比如 <code>INSERT INTO mysql.user</code>，但使用 <code>CREATE USER</code> 是没有问题的，它也是正确的使用方式。</li><li>不允许大事务的产生（否则的话后果很严重），允许的最大事务大小由 <code>wsrep_max_ws_rows</code> 和 <code>wsrep_max_ws_size</code> 变量定义，<code>LOAD DATA INFILE</code> 方式处理每 10000 行提交一次，对于大的事务将被分解众多小型事务。</li><li>对于写密集型应用需要控制单个节点的大小，单个节点的数据越大，新加节点如果采用自动添加，则可能会产生很大抖动（添加节点建议提前使用备份或者备份 + Binlog 进行数据同步，尽量减少抖动）。</li><li>集群高负载时应避免执行 <code>ALTER TABLE</code>、<code>IMPORT</code>、<code>EXPORT</code> 等操作，因为如果这些操作未在所有节点上同步执行，可能会导致节点不一致。</li><li>在多主模式中不支持 <code>LOCK TABLES</code> 以及 <code>UNLOCK TABLES</code> 锁定功能，如 <code>GET_LOCK ()</code>，<code>RELEASE_LOCK ()</code> 等也不被支持。</li><li>硬件配置短板限制，即整个集群的写吞吐量受最弱节点的限制，因此所有 PXC 节点的硬件配置要一致。如果一个节点变慢，整个集群会跟着变慢。</li><li>需要尽可能地控制 PXC 集群的规模，节点越多，数据同步速度越慢。</li><li>查询日志不能定向到表，即如果启用查询日志记录，则必须将日志转发到文件，而不能转发到表。</li><li><code>enforce_storage_engine=InnoDB</code> 与 <code>wsrep_replicate_myisam=OFF（默认）</code> 不兼容。</li><li><code>binlog_rows_query_log_events</code> 变量不受支持。</li><li>由于可能的提交回滚，XA 事务不受支持。</li><li>InnoDB 的虚假更改功能不受支持。</li><li>最小的集群大小是 3 个节点。</li><li>不能解决热点更新问题。</li></ul><h3 id="Replication-与-PXC-对比"><a href="#Replication-与-PXC-对比" class="headerlink" title="Replication 与 PXC 对比"></a>Replication 与 PXC 对比</h3><h4 id="方案介绍"><a href="#方案介绍" class="headerlink" title="方案介绍"></a>方案介绍</h4><p><img data-src="../../../asset/2023/10/mysql-ha-20.png"></p><ul><li>Replication 方案（主从复制）<ul><li>速度快，但仅能保证弱一致性，适用于保存价值不高的数据，比如日志、帖子、新闻等。</li><li>采用 Master-Slave 架构，在 Master 写入会同步到 Slave，能从 Slave 读出，但在 Slave 写入无法同步到 Master。</li><li>采用异步复制，Master 写入成功就向客户端返回成功，但是同步 Slave 可能失败，会造成无法从 Slave 读出的结果。</li></ul></li></ul><p><img data-src="../../../asset/2023/10/mysql-ha-21.png"></p><ul><li>Percona XtraDB Cluster（PXC）方案<ul><li>速度慢，但能保证强一致性，适用于保存价值较高的数据，比如订单、客户、支付数据等。</li><li>数据同步是双向的，在任一节点写入数据，都会同步到其他所有节点，在任何节点上都能同时读写。</li><li>采用同步复制，向任一节点写入数据，只有所有节点都同步成功后，才会向客户端返回成功。事务在所有节点要么同时提交，要么不提交。</li></ul></li></ul><h4 id="对比说明"><a href="#对比说明" class="headerlink" title="对比说明"></a>对比说明</h4><p><img data-src="../../../asset/2023/10/mysql-ha-10.png"></p><p><img data-src="../../../asset/2023/10/mysql-ha-11.png"></p><h4 id="对比总结"><a href="#对比总结" class="headerlink" title="对比总结"></a>对比总结</h4><ul><li><p>数据一致性对比</p><ul><li>Replication 一般采用异步复制，无法保证数据的强一致性。</li><li>PXC 采用同步复制，事务在所有集群节点要么都提交，要么都不提交，可以保证数据的强一致性。</li></ul></li><li><p>写入性能对比</p><ul><li>Replication 写入速度快，但是不能保证数据的强一致性。</li><li>PXC 可以保证数据的强一致性，但写入速度慢（所有节点都可以同时读写）。</li><li>PXC 和 Replication 都只实现了数据的同步，并没有提供数据切分（分片）的的功能。</li></ul></li><li><p>两者的区别总结</p><ul><li>PXC 集群的所有节点都是可读可写，但 Replication 的从节点不能写入，因为主从同步是单向的，无法从 Slave 节点向 Master 节点同步。</li><li>PXC 的同步机制是同步进行的，这也是它能保证数据强一致性的根本原因，Replication 的同步机制是异步进行的，如果从节点停止同步，依然可以向主节点插入数据，且正确返回给客户端，造成主从节点的数据不一致。</li><li>PXC 是牺牲性能来保证数据的一致性，Replication 在性能上是高于 PXC 的，所以两者的使用场景是不一样的。<ul><li>Replication 适用于存储普通数据，能够容忍数据丢失，例如：购物车、用户行为日志等。</li><li>PXC 适用于存储重要数据，要求保证数据的强一致性，例如：订单信息、支付信息、用户信息等。</li></ul></li></ul></li></ul><h3 id="PXC-高性能高可用部署方案"><a href="#PXC-高性能高可用部署方案" class="headerlink" title="PXC 高性能高可用部署方案"></a>PXC 高性能高可用部署方案</h3><h4 id="PXC-集群高可用架构部署"><a href="#PXC-集群高可用架构部署" class="headerlink" title="PXC 集群高可用架构部署"></a>PXC 集群高可用架构部署</h4><p><img data-src="../../../asset/2023/10/mysql-ha-14.png"></p><p><img data-src="../../../asset/2023/10/mysql-ha-13.png"></p><h4 id="PXC-集群高性能架构部署"><a href="#PXC-集群高性能架构部署" class="headerlink" title="PXC 集群高性能架构部署"></a>PXC 集群高性能架构部署</h4><p><img data-src="../../../asset/2023/10/mysql-ha-12.png"></p><h4 id="PXC-集群混合架构部署"><a href="#PXC-集群混合架构部署" class="headerlink" title="PXC 集群混合架构部署"></a>PXC 集群混合架构部署</h4><p><img data-src="../../../asset/2023/10/mysql-ha-15.png"></p><h2 id="MySQL-InnoDB-Cluster"><a href="#MySQL-InnoDB-Cluster" class="headerlink" title="MySQL InnoDB Cluster"></a>MySQL InnoDB Cluster</h2><p>MySQL InnoDB Cluster 是 MySQL 官方推出的一套完整高可用性解决方案。</p><h3 id="整体架构-1"><a href="#整体架构-1" class="headerlink" title="整体架构"></a>整体架构</h3><ul><li>MySQL InnoDB Cluster 的核心组件<ul><li><code>MySQL Group Replication</code>：简称 MGR，是 MySQL 的主从同步高可用方案，包括数据同步及角色选举。</li><li><code>MySQL Router</code>：业务流量的统一入口，支持对 MGR 的主从角色判断，可以配置不同的端口分别对外提供读写服务，实现读写分离等功能。</li><li><code>MySQL Shell</code>：MySQL InnoDB Cluster 的管理工具，用来创建和管理集群。</li></ul></li></ul><p><img data-src="../../../asset/2023/10/mysql-ha-18.png"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.51cto.com/u_16099257/7022269">MySQL 高可用方案推荐</a></li><li><a href="https://bigdata.it168.com/a2016/0822/2871/000002871893.shtml">链家 MySQL 高可用架构设计</a></li><li><a href="https://mt.sohu.com/20170323/n484341088.shtml">10 款常见 MySQL 高可用方案选型解读</a></li><li><a href="https://www.php.cn/faq/554468.html">MySQL 中常见的高可用架构部署方案有哪些</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzI4NjE4NTUwNQ==&amp;mid=2247495043&amp;idx=8&amp;sn=85a4c8aa143ac9e11e1fea11ab134a1e">MySQL 高可用架构 - MMM、MHA、MGR、PXC</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 MySQL 的高可用架构方案，包括 Galera Cluster、Percona XtraDB Cluster 等。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="数据库" scheme="https://www.techgrow.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 高可用基础教程之二高可用架构方案介绍</title>
    <link href="https://www.techgrow.cn/posts/d6058b93.html"/>
    <id>https://www.techgrow.cn/posts/d6058b93.html</id>
    <published>2023-10-18T12:13:32.000Z</published>
    <updated>2023-10-18T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/2f77f23a.html">MySQL 高可用基础教程之一主从复制方案介绍</a></li><li><a href="/posts/d6058b93.html">MySQL 高可用基础教程之二高可用架构方案介绍</a></li><li><a href="/posts/cc846db2.html">MySQL 高可用基础教程之三高可用架构方案介绍</a></li><li><a href="/posts/56993278.html">MySQL 高可用基础教程之四数据可靠性方案介绍</a></li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="高可用架构方案分类"><a href="#高可用架构方案分类" class="headerlink" title="高可用架构方案分类"></a>高可用架构方案分类</h3><table><thead><tr><th>高可用方案</th><th>保证数据强一致性</th><th>使用说明</th><th>描述</th></tr></thead><tbody><tr><td>主从复制</td><td>否</td><td>支持单主</td><td>只适用于对可用性和数据一致性要求较低的业务场景。</td></tr><tr><td>MMM</td><td> 否</td><td>支持单主</td><td>基本淘汰了，在一致性和高并发稳定性等方面有些问题。</td></tr><tr><td>MHA</td><td> 否</td><td>支持单主</td><td>有少数开发者还在用，但也有些问题，也是趋于淘汰的 MySQL 主从高可用方案。</td></tr><tr><td>MGR</td><td> 是</td><td>支持单主 / 多主</td><td>基于 MySQL 官方从 <code>5.7.17</code> 版本开始引入的组复制技术。</td></tr><tr><td>MySQL Cluster</td><td> 是</td><td>支持多主</td><td> MySQL 官方提供的一种分布式数据库解决方案，只支持 NDB 引擎。</td></tr><tr><td>Galera Cluster</td><td> 是</td><td>支持多主</td><td>引领时代的主从复制高可用技术。</td></tr><tr><td>Galera Cluster for MySQL</td><td> 是</td><td>支持多主</td><td> MySQL 对 Galera Cluster 的实现。</td></tr><tr><td>MariaDB Galera Cluster (MGC)</td><td> 是</td><td>支持多主</td><td> MariaDB 对 Galera Cluster 的实现。</td></tr><tr><td>Percona XtraDB Cluster (PXC)</td><td> 是</td><td>支持多主</td><td> Percona 对 Galera Cluster 的实现，目前业界使用 PXC 的会多一些。</td></tr><tr><td>MySQL InnoDB Cluster</td><td> 是</td><td>支持单主 / 多主</td><td> MySQL 官方推出的一套完整高可用性解决方案。</td></tr></tbody></table><span id="more"></span><h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>主从之间一般使用异步复制，这意味无法保证数据的一致性，对于数据一致性要求比较高的业务场景是不适用的（如金融、银行业务）。</p><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/10/mysql-ha-19.png"></p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li><p>优点</p><ul><li>架构简单，维护起来比较方便。</li></ul></li><li><p>缺点</p><ul><li>无法保证数据的一致性。</li><li>主库宕机后，整个系统都无法写入数据。</li><li>Proxy 存在单点问题，建议使用 Keepalived + HAProxy 实现数据库中间件的负载均衡。</li></ul></li></ul><h2 id="MMM"><a href="#MMM" class="headerlink" title="MMM"></a>MMM</h2><p>MMM（Master-Master Replication Manager）是一套支持 MySQL 双主故障切换和双主日常管理的脚本程序，可以实现 MySQL 数据库的高可用性和负载均衡。MMM 基于 Perl 语言开发，主要用于监控和管理 MySQL Master-Master（双主） 复制，可以说是 MySQL 主主复制的管理器。<strong>虽然叫做双主复制，但在业务上同一时刻只能有一个主库进行数据的写入，另一台主备库会提供部分读服务，以加速在主主切换时主备库的预热。另外，主备库会在主库失效时，进行主备切换和故障转移</strong>。可以说 MMM 这套脚本程序一方面实现了主备切换的功能，另一方面其内部附加的工具脚本也可以实现多个 Slave 节点的读负载均衡。<strong>简而言之，MMM 是一套基于 MySQL 主从复制的高可用性解决方案，通过使用双主复制架构、自动故障检测与切换机制、故障恢复机制，实现了 MySQL 数据库的高可用性和数据同步。</strong></p><div class="admonition warning"><p class="admonition-title">注意</p><p>MMM 方案基本淘汰了，在生产环境中不建议使用。</p></div><h3 id="整体架构-1"><a href="#整体架构-1" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/10/mysql-ha-3.png"></p><ul><li>MMM 架构包括三大组件：监控器（Monitor）、代理（Agent）和 MySQL 实例。</li><li>在 MMM 中是通过一个 VIP（虚拟 IP）的机制来保证集群的高可用。在整个 MySQL 集群中，在主节点会提供一个 VIP 地址来提供数据读写服务，当出现故障的时候，VIP 就会从原来的主节点切换到其他节点，由其他节点提供服务。</li><li>VIP（虚拟 IP）是基于 ARP 协议，因此所有节点必须处于同一局域网。</li></ul><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><ul><li><code>工作原理</code>：MMM 采用了一种双主复制架构，其中有两个 MySQL 主服务器（Master1 和 Master2），它们之间通过 MySQL 的复制功能进行数据同步。在这种架构中，应用程序可以同时连接到 Master1 和 Master2，从而实现读写负载的分担和高可用性。</li><li><code>主从复制</code>：MMM 利用 MySQL 的主从复制机制，将一个 MySQL 主服务器（Master1）作为主节点，另一个 MySQL 主服务器（Master2）作为从节点。主节点接收写操作并将其复制到从节点，从而保持数据的同步。当主节点发生故障时，从节点可以自动接管主节点的角色，确保数据库的高可用性。</li><li><code>自动故障检测与切换</code>：MMM 具有自动检测主节点故障的能力。它通过监控主节点的心跳以及与从节点的复制延迟来确定主节点是否正常工作。如果主节点发生故障或延迟过高，MMM 会自动将从节点切换为主节点，并将所有写操作重定向到新的主节点。</li><li><code>故障恢复</code>：当主节点恢复正常工作后，MMM 可以自动将其重新加入复制拓扑，并将其配置为从节点。这样，当前的主节点（之前的从节点）会将数据同步到恢复的主节点，以确保数据的一致性。</li></ul><div class="admonition warning"><p class="admonition-title">特别注意</p><p>使用 MMM 可以有效地提高 MySQL 数据库的可用性和性能。特别注意的是，MMM 并不能解决所有的高可用问题，例如网络分区和数据一致性等问题。</p></div><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li><p>优点</p><ul><li><code>高可用性</code>：MMM 通过自动故障检测和故障转移机制，可以快速将一个从节点提升为新的主节点，从而实现数据库的高可用性，减少系统的停机时间。</li><li><code>负载均衡</code>：MMM 可以根据节点的负载情况，将读操作分发到不同的节点上，从而实现负载均衡，提高系统的整体性能。</li><li><code>简单易用</code>：MMM 提供了一些管理工具，可以方便地进行节点的添加、删除和配置修改等操作，使得系统的管理和维护变得简单易用。</li><li><code>VIP 支持</code>：默认提供了读写 VIP（虚拟 IP）的支持。</li></ul></li><li><p>缺点：</p><ul><li><code>无法完全保证数据一致性</code>：由于 MMM 默认采用了 MySQL 的异步复制机制，主节点和从节点之间的同步存在一定的延迟，可能会导致数据的不一致。在某些场景下，需要额外的措施来确保数据的一致性。</li><li><code>单点故障</code>：虽然 MMM 可以自动进行故障转移，但在故障转移过程中，可能会存在一段时间的数据库不可用。如果 MMM 本身发生故障，可能会导致整个系统的不可用。</li><li><code>配置复杂性</code>：MMM 的配置相对复杂，需要对 MySQL 的复制机制和 MMM 的工作原理有一定的了解。在配置过程中，需要注意各个节点的配置一致性和正确性。</li><li><code>故障切换会丢事务</code>：出现故障切换时，容易丢失事务，建议主从库采用半同步复制方式解决，减少出问题的概率。</li><li><code>不支持 GTID</code>：MMM 不支持基于 GTID 的复制，只支持基于日志点的复制。</li><li><code>社区不活跃</code>：目前 MMM 开源社区已经缺少维护者。</li></ul></li></ul><h2 id="MHA"><a href="#MHA" class="headerlink" title="MHA"></a>MHA</h2><p>MHA（Master High Availability）是一种用于 MySQL 数据库的高可用性架构。它的设计目标是确保在主数据库发生故障时，能够快速自动地将备库（Slave）提升为新的主库，以保证系统的连续性和可用性。MHA 专门用于监控主库的状态，当发现 Master 节点发生故障的时候，会自动提升其中拥有最新数据的 Slave 节点成为新的 Master 节点；在此期间，MHA 会通过其他从节点获取额外的信息来避免数据一致性问题。MHA 还提供了一种在线切换 Master-Slave 节点的功能，可以根据需要进行切换。MHA 可在 30 秒内实现故障转移，同时最大程度确保数据一致性。</p><div class="admonition warning"><p class="admonition-title">注意</p><ul><li>MHA 方案比较适合旧版本的 MySQL，即小于 <code>5.7.17</code> 的版本，如 <code>5.5</code>、<code>5.6</code> 等。</li><li>MySQL 官方从 <code>5.7.17</code> 版本开始提供了组复制技术，因此版本号大于 <code>5.7.17</code> 的 MySQL，建议采用 MGR（MySQL Group Replication）或者其他高可用方案。</li></ul></div><h3 id="整体架构-2"><a href="#整体架构-2" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/10/mysql-ha-4.png"></p><ul><li>MHA 由两部分组成，分别是 MHA Manager（管理节点）和 MHA Node（数据节点）。</li><li>MHA Manager 可以单独部署在一台独立的机器上管理单个或多个 Master-Slave 集群，也可以部署在一台 Slave 节点上。MHA Node 运行在每台 MySQL 服务器上。</li><li>Slave 节点是 MySQL 数据库的备库，负责同步主库的数据。MHA 会通过与 Slave 节点建立 SSH 连接，实时监测备库的状态。</li><li>Master 节点是 MySQL 数据库的主库，负责处理所有的写操作和读操作。MHA 会通过与 Master 节点建立 SSH 连接，实时监测主库的状态。</li><li>Manager 节点是 MHA 的核心组件，负责监控主库的状态并自动执行故障切换操作。它通过与 MySQL 主库和备库建立 SSH 连接，实时监测集群中的 Master 节点；<strong>当 Master 节点出现故障时，它可以自动将拥有最新数据的 Slave 节点提升为新的 Master 节点，然后将所有其他的 Slave 节点重新指向新的 Master 节点。</strong></li></ul><blockquote><p>MHA 可以扩展为多主多从的集群架构，如下图所示</p></blockquote><p><img data-src="../../../asset/2023/10/mysql-ha-5.png"></p><h3 id="工作原理-1"><a href="#工作原理-1" class="headerlink" title="工作原理"></a>工作原理</h3><p>目前 MHA 主要支持一主多从的架构，要搭建 MHA，则必须保证在一个 MySQL 复制集群中最少有三台数据库服务器，一主二从，即一台 Master 节点，一台充当备用 Master 节点，另外一台充当 Slave 节点，因为至少需要三台服务器。</p><h4 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h4><p>MHA 架构的工作流程如下：</p><ul><li>从宕机崩溃的 Master 中保存二进制日志事件（binlog events）</li><li>识别最新更新的 Slave 节点</li><li>应用差异的中继日志（relay log）到其他 Slave 节点</li><li>应用从 Master 保存的二进制日志事件（binlog events）</li><li>提升其中一个 Slave 节点为新 Master 节点</li><li>让其他的 Slave 节点连接新的 Master 节点进行复制</li></ul><h4 id="自动故障切换"><a href="#自动故障切换" class="headerlink" title="自动故障切换"></a>自动故障切换</h4><p>在 MHA 自动故障切换的过程中，MHA 会尝试从宕机的主服务器上最大限度的保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，主服务器硬件故障或无法通过 SSH 访问，导致 MHA 无法保存二进制日志，只进行故障转移而丢失了最新的数据。使用从 MySQL 5.5 开始支持的半同步复制，可以大大降低数据丢失的风险。<strong>值得一提的是，MHA 很适合与半同步复制机制结合起来使用。</strong>如果只有一个 Slave 节点已经接收到了最新的二进制日志，MHA 可以将最新的二进制日志应用于其他所有的 Slave 节点上，因此可以保证所有节点的数据一致性。</p><h3 id="优缺点-2"><a href="#优缺点-2" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li><p>优点：</p><ul><li><code>自动故障切换</code>：MHA 能够自动检测主库的故障，并快速将备库提升为新的主库，减少了手动干预的需要，提高了系统的可用性。</li><li><code>实时监测</code>：MHA 通过与 Master 节点和 Slave 节点建立 SSH 连接，实时监测它们的状态，能够及时发现故障并采取相应的措施。</li><li><code>简化配置</code>：MHA 提供了简单易用的配置文件，可以轻松地配置主库和备库的信息，减少了配置的复杂性。</li><li><code>高可扩展性</code>：MHA 支持多个备库，可以根据需求灵活地扩展系统的容量和性能。</li><li><code>支持 GTID 与日志点</code>：支持基于 GTID 的复制模式，在进行故障转移时更不易产生数据丢失，同时还支持基于日志点的复制。</li><li><code>支持监控多个集群</code>：同一个监控节点可以监控多个集群。</li></ul></li><li><p>缺点：</p><ul><li><code>配置复杂性</code>：尽管 MHA 提供了简化的配置文件，但对于不熟悉 MHA 的用户来说，配置仍然可能是一项复杂的任务。特别是在涉及多个主库和备库的复杂环境中，配置可能变得更加困难。</li><li><code>依赖 SSH 连接</code>：MHA 通过 SSH 连接与主库和备库进行通信和监控。这意味着在配置和使用 MHA 时，必须确保 SSH 连接的可用性和稳定性，否则可能会导致 MHA 无法正常工作。由于需要基于 SSH 免认证配置，存在一定的安全隐患。</li><li><code>故障切换过程中的数据同步延迟</code>：在故障切换期间，MHA 需要将备库提升为新的主库，并重新配置其他备库作为新的从库。这个过程可能需要一些时间，导致在切换期间存在一定的数据同步延迟，这可能会对某些应用程序的数据一致性产生影响。</li><li><code>依赖 MySQL 复制功能</code>：MHA 依赖 MySQL 的半同步复制方式来实现数据的同步和复制。如果 MySQL 的复制功能出现问题，可能会导致 MHA 无法正常工作或数据同步不完整。</li><li><code>需要额外的硬件资源</code>：为了实现高可用性，MHA 需要至少一个备库来作为冗余备份。这意味着需要额外的硬件资源来支持备库的运行和数据复制，增加了系统的成本和复杂性。</li><li><code>只监控 Master 节点</code>：MHA 启动后只会对主数据库进行监控，并不关注 Slave 节点的运行状态，这可能会导致 Master 节点挂掉后切换到无效的 Slave 节点，从而导致系统崩溃。</li><li><code>需要配置 VIP</code>：MHA 需要编写脚本或利用第三方工具来实现 VIP（虚拟 IP）的配置。</li><li><code>存在脑裂的问题</code>：可能会因网络分区导致脑裂问题的发生。</li></ul></li></ul><div class="admonition warning"><p class="admonition-title">特别注意</p><p>MHA 并不是万能的解决方案，它适用于大多数的 MySQL 数据库场景，但在特定的情况下可能需要根据实际需求进行定制化的配置和调整。此外，为了确保 MHA 的正常运行，还需要进行定期的监控和维护工作，以保证系统的稳定性和可靠性。</p></div><h2 id="MGR"><a href="#MGR" class="headerlink" title="MGR"></a>MGR</h2><p>MGR（MySQL Group Replication）是 MySQL 官方在 <code>5.7.17</code> 版本引进的一个数据库高可用解决方案，以插件形式提供，用于实现 MySQL 数据库的主从复制和自动故障切换。MGR 基于 MySQL 的 InnoDB 存储引擎和 Group Replication 插件实现，引入组复制主要是为了解决传统异步复制和半同步复制可能产生数据不一致的问题。<strong>值得一提的是，MGR 支持单主模式与多主模式，多主模式支持多点写入，MySQL 官方推荐使用单主模式。</strong></p><ul><li><p>MGR 架构的核心组件</p><ul><li><code>Group Replication 组件</code>：Group Replication 是 MySQL 官方提供的插件，用于实现多主复制和自动故障切换。它基于 Paxos 协议，通过在集群中的成员之间进行通信和协调，实现数据的同步和一致性。</li><li><code>Primary 节点</code>：Primary 节点是 MGR 集群中的主节点，负责处理所有的写操作和读操作。Primary 节点接收来自应用程序的写请求，并将数据复制到其他节点（Secondary 节点）上。</li><li><code>Secondary 节点</code>：Secondary 节点是 MGR 集群中的从节点，负责复制 Primary 节点上的数据。Secondary 节点通过与 Primary 节点进行通信，接收并应用 Primary 节点上的写操作，以保持数据的一致性。</li></ul></li><li><p>MGR 架构的工作流程</p><ul><li><code>初始化集群</code>：在 MGR 架构中，首先需要选择一个节点作为初始 Primary 节点，并将其配置为 Group Replication 组件的成员。然后，其他节点可以加入到集群中，并通过与 Primary 节点进行通信，获取数据并成为 Secondary 节点。</li><li><code>数据同步</code>：一旦集群初始化完成，Primary 节点开始接收来自应用程序的写请求，并将数据复制到其他节点上。Secondary 节点通过与 Primary 节点进行通信，接收并应用 Primary 节点上的写操作，以保持数据的一致性。</li><li><code>自动故障切换</code>：如果 Primary 节点发生故障，Group Replication 组件会自动选择一个 Secondary 节点作为新的 Primary 节点，并将其他节点重新配置为新的 Secondary 节点。这个过程是自动的，无需人工干预。</li></ul></li></ul><h3 id="整体架构-3"><a href="#整体架构-3" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/10/mysql-ha-6.png"></p><h3 id="工作原理-2"><a href="#工作原理-2" class="headerlink" title="工作原理"></a>工作原理</h3><ul><li>MGR 由若干个节点共同组成一个复制组，一个事务的提交，必须经过组内大多数节点（N / 2 + 1）决议并通过，才能得以提交。</li><li>MGR 基于分布式 Paxos 协议，实现组复制，保证数据的强一致性，自带故障检测和自动选主功能。</li><li>MGR 基于 ROW 格式的二进制日志文件和 GTID 特性。</li></ul><h3 id="优缺点-3"><a href="#优缺点-3" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li><p>优点</p><ul><li><code>自动故障切换</code>：MGR 能够自动检测 Primary 节点的故障，并快速将一个 Secondary 节点提升为新的 Primary 节点，实现自动故障切换，提高了系统的可用性。只要有 N / 2 + 1 节点可用，集群就可用。</li><li><code>保证数据的强一致性</code>：MGR 使用 Paxos 协议来保证数据的强一致性。在写操作提交之前，集群中的成员会达成一致，确保数据在所有节点上的复制是一致的。</li><li><code>简化配置和管理</code>：MGR 提供了简单易用的配置选项和管理工具，使得集群的配置和管理变得更加简单和方便。</li><li><code>高可扩展性</code>：MGR 支持多主复制，可以根据需求灵活地扩展系统的容量和性能。</li><li><code>支持多主模式，但目前该技术还不是很成熟</code><ul><li>多主模式下，客户端可以随机向 MySQL 节点写入数据。</li><li>单主模式下，MGR 集群会选出 Primary 节点负责写请求，Primary 和 Secondary 节点都可以进行读请求的处理。</li></ul></li></ul></li><li><p>缺点</p><ul><li><code>网络稳定性</code>：MGR 对网络的稳定性要求较高，因为节点之间需要进行频繁的通信和数据同步。如果网络不稳定，可能会导致数据同步延迟或节点之间的通信故障。</li><li><code>数据冲突</code>：由于 MGR 支持多主复制，如果应用程序在不同的节点上同时进行写操作，可能会导致数据冲突和一致性问题。因此，需要在应用程序层面进行合理的设计和处理。</li><li><code>配置复杂性</code>：尽管 MGR 提供了简化的配置选项和管理工具，但对于不熟悉 MGR 的用户来说，配置仍然可能是一项复杂的任务。特别是在涉及多个节点和复杂环境中，配置可能变得更加困难。</li><li><code>存在较多限制</code>：<ul><li>仅支持 Innodb 储存引擎，且储存引擎的版本必须一致。</li><li>所有节点的 MySQL 版本必须一致，否则无法添加到 MGR 中。</li><li>不支持异构的 MySQL 节点，也就是说，所有 MySQL 节点的操作系统和版本必须一致。</li><li>只能在 GTID 模式下使用。</li><li>Binlog 的日志格式必须为 ROW 格式。</li><li>每个表都必须有主键，在进行事务冲突检测时需要利用主键值进行对比。</li><li>RP 和普通复制 Binlog 校验不能共存，需设置 <code>--binlog-checksum=none</code>。</li><li>不支持 <code>gap lock（间隙锁）</code>，隔离级别需设置为 <code>read_committed</code>。</li><li>不支持对表进行锁操作（如 <code>lock table</code>、<code>unlock table</code>）。</li><li>不支持在不同的 MGR 节点上，对同一个表分别执行 DML 和 DDL，可能会造成数据丢失或节点报错退出。</li><li>DDL 语句不支持原子性，不能检测冲突，执行后需自行校验是否一致。</li><li>多主模式下不支持使用外键，但单主模式下支持使用外键。</li><li>不支持 <code>serializable（串行）</code> 隔离级别。</li><li>不支持复制过滤（Replication Filters）设置。</li><li>最多支持 9 个节点，超过 9 个节点无法加入组。</li></ul></li></ul></li><li><p>适用场景</p><ul><li>要求数据强一致性的业务场景</li><li>希望对数据库的写服务提供高可用保障，但又不想安装第三方软件</li></ul></li></ul><div class="admonition note"><p class="admonition-title">提示</p><p>在使用 MGR 之前，建议进行充分的测试和评估，以确保它能够满足系统的可用性和性能要求，并根据具体的应用场景和需求进行适当的配置和调整。</p></div><h2 id="MySQL-Cluster"><a href="#MySQL-Cluster" class="headerlink" title="MySQL Cluster"></a>MySQL Cluster</h2><p>MySQL Cluster （又叫 MySQL NDB Cluster）是 MySQL 官方开源的一种分布式数据库解决方案，旨在提供高可用性、可扩展性和实时性能。它基于 NDB（Network DataBase）存储引擎，使用多台服务器组成一个集群，提供数据的分片和复制，以实现高可用性和自动的读写负载均衡。值得一的是，MySQL Cluster 兼容 ACID 事务，不存在单点故障，支持自动水平扩容，可以保证数据的强一致性。</p><div class="admonition warning"><p class="admonition-title">注意</p><p>由于 MySQL Cluster 的使用和配置都比较复杂，该方案在国内并没有被大规模使用。</p></div><h3 id="整体架构-4"><a href="#整体架构-4" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/10/mysql-ha-8.png"></p><ul><li>MySQL Cluster 架构的核心组件<ul><li><code>Management 节点</code>：Management 节点是 MySQL Cluster 的控制节点，负责集群的管理和配置。它负责监控集群中的各个节点，并协调数据的分片和复制。</li><li><code>Data 节点</code>：Data 节点是 MySQL Cluster 的数据节点，负责存储和处理数据。每个 Data 节点都运行 NDB 存储引擎，数据被分片存储在不同的 Data 节点上，以实现数据的分布和负载均衡。</li><li><code>SQL 节点</code>：SQL 节点是 MySQL Cluster 的查询节点，负责处理应用程序的查询请求。SQL 节点接收来自应用程序的 SQL 查询，并将查询分发到适当的 Data 节点上进行处理。</li></ul></li></ul><h3 id="工作原理-3"><a href="#工作原理-3" class="headerlink" title="工作原理"></a>工作原理</h3><h4 id="工作流程-1"><a href="#工作流程-1" class="headerlink" title="工作流程"></a>工作流程</h4><p>MySQL Cluster 架构的工作流程如下：</p><ul><li><code>集群初始化</code>：在 MySQL Cluster 中，首先需要配置和启动 Management 节点，然后配置和启动 Data 节点和 SQL 节点。Management 节点负责监控和管理集群中的各个节点。</li><li><code>数据分片和复制</code>：一旦集群初始化完成，Management 节点会根据配置的规则将数据分片存储在不同的 Data 节点上。数据的复制和同步由 MySQL Cluster 自动处理，以保证数据的一致性和可用性。</li><li><code>查询处理</code>：当应用程序发送查询请求时，SQL 节点接收并解析查询，并将查询分发到适当的 Data 节点上进行处理。Data 节点返回查询结果给 SQL 节点，然后 SQL 节点将结果返回给应用程序。</li></ul><h3 id="优缺点-4"><a href="#优缺点-4" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li><p>优点</p><ul><li><code>高可用性</code>：MySQL Cluster 通过数据的分片和复制，以及自动故障检测和恢复机制，实现了高可用性。即使某个节点发生故障，集群仍然可以继续提供服务。</li><li><code>可扩展性</code>：MySQL Cluster 支持水平扩展，可以通过增加 Data 节点来扩展存储容量和处理能力。同时，由于数据的分片和负载均衡，可以实现更好的性能和吞吐量。</li><li><code>实时性能</code>：MySQL Cluster 的设计目标之一是提供实时性能。通过将数据存储在内存中，并使用并行处理和分布式计算，可以实现较低的延迟和更高的吞吐量。</li><li><code>数据的强一致性</code>：MySQL Cluster 使用多副本复制和同步机制，以保证数据的强一致性。即使在节点故障或网络分区的情况下，数据仍然可以保持一致。</li></ul></li><li><p>缺点：</p><ul><li><code>配置复杂性</code>：MySQL Cluster 的配置相对复杂，需要考虑数据分片、复制和负载均衡等因素。对于不熟悉 MySQL Cluster 的用户来说，配置可能是一项具有挑战性的任务。</li><li><code>内存需求</code>：由于 MySQL Cluster 将数据存储在内存中，因此对内存的需求较高，需要根据数据量和性能需求来配置足够的内存资源。</li><li><code>存储引擎需求</code>：MySQL Cluster 需要使用 NDB 存储引擎，与 MySQL 常用引擎（如 Innodb 引擎）存在一定的差异。</li><li><code>网络稳定性</code>：MySQL Cluster 对网络的稳定性要求较高，因为节点之间需要进行频繁的通信和数据同步。如果网络不稳定，可能会导致数据同步延迟或节点之间的通信故障。</li><li><code>重启时间长</code>：重启的时候，数据节点将数据加载到内存需要很长时间。</li><li><code>备份和恢复</code>：MySQL Cluster 对数据备份和恢复并不友好。</li><li><code>节点数需求</code>：搭建 MySQL Cluster 时，要求至少有三个服务器节点。</li><li><code>存在较多限制</code>：如不支持外键，数据行不能超过 8K（不包括 BLOB 和 TEXT 中的数据）等。</li></ul></li></ul><div class="admonition note"><p class="admonition-title">提示</p><p>在使用 MySQL Cluster 之前，建议进行充分的测试和评估，以确保它能够满足系统的可用性、性能和扩展性要求，并根据具体的应用场景和需求进行适当的配置和调整。</p></div><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.51cto.com/u_16099257/7022269">MySQL 高可用方案推荐</a></li><li><a href="https://bigdata.it168.com/a2016/0822/2871/000002871893.shtml">链家 MySQL 高可用架构设计</a></li><li><a href="https://mt.sohu.com/20170323/n484341088.shtml">10 款常见 MySQL 高可用方案选型解读</a></li><li><a href="https://www.php.cn/faq/554468.html">MySQL 中常见的高可用架构部署方案有哪些</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzI4NjE4NTUwNQ==&amp;mid=2247495043&amp;idx=8&amp;sn=85a4c8aa143ac9e11e1fea11ab134a1e">MySQL 高可用架构 - MMM、MHA、MGR、PXC</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 MySQL 的高可用架构方案，包括 MMM、MHA、MGR、MySQL Cluster。</summary>
    
    
    
    
    <category term="数据库" scheme="https://www.techgrow.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 高可用基础教程之一主从复制方案介绍</title>
    <link href="https://www.techgrow.cn/posts/2f77f23a.html"/>
    <id>https://www.techgrow.cn/posts/2f77f23a.html</id>
    <published>2023-10-15T12:13:32.000Z</published>
    <updated>2023-10-15T12:13:32.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/2f77f23a.html">MySQL 高可用基础教程之一主从复制方案介绍</a></li><li><a href="/posts/d6058b93.html">MySQL 高可用基础教程之二高可用架构方案介绍</a></li><li><a href="/posts/cc846db2.html">MySQL 高可用基础教程之三高可用架构方案介绍</a></li><li><a href="/posts/56993278.html">MySQL 高可用基础教程之四数据可靠性方案介绍</a></li></ul><h2 id="主从复制概述"><a href="#主从复制概述" class="headerlink" title="主从复制概述"></a>主从复制概述</h2><h3 id="主从复制用途"><a href="#主从复制用途" class="headerlink" title="主从复制用途"></a>主从复制用途</h3><ul><li><code>实时灾备</code>：用于故障切换（高可用）</li><li><code>读写分离</code>：提供查询服务（读扩展）</li><li><code>数据备份</code>：避免影响业务（高可用）</li></ul><span id="more"></span><h3 id="主从复制原理"><a href="#主从复制原理" class="headerlink" title="主从复制原理"></a>主从复制原理</h3><ul><li>主从复制的原理<ul><li> (1) Master 节点将数据的改变都记录到二进制 Binlog 日志中，只要 Master 上的数据发生改变，则将其改变写入二进制日志。</li><li>(2) Salve 节点会在一定时间间隔内对 Master 二进制日志进行探测，判断其是否发生改变，如果发生改变，则启动一个 I/O 线程请求 Master 二进制事件。</li><li>(3) 同时 Master 节点会为每个 I/O 线程启动一个 Binlog Dump 线程，用于向其发送二进制事件，让 Slave 节点保存至本地的 Relay-Log （中继日志）中。</li><li>(4) Slave 节点启动 SQL 线程从 Relay-Log （中继日志）中读取二进制日志，并在本地重放，使得其数据和 Master 节点的保持一致。</li><li>(5) 最后 Slave 节点的 I/O 线程 和 SQL 线程将进入睡眠状态，等待下一次被唤醒。</li></ul></li></ul><p><img data-src="../../../asset/2023/10/mysql-replication-5.png"></p><ul><li>主从复制的重点<ul><li> (1) Slave 节点会启动两个线程，分别是 I/O 线程和 SQL 线程。</li><li>(2) Slave 节点的 I/O 线程会去请求 Master 节点的 Binlog，并将得到的 Binlog 写入本地的 Relay-Log（中继日志）文件中。</li><li>(3) Master 节点会启动一个 Binlog Dump 线程，用来给 Slave 节点的 I/O 线程传 Binlog。</li><li>(4) Slave 节点的 SQL 线程会读取本地 Relay-Log（中继日志）文件中的日志，并解析成 SQL 语句逐一执行。</li></ul></li></ul><h3 id="主从复制方式"><a href="#主从复制方式" class="headerlink" title="主从复制方式"></a>主从复制方式</h3><ul><li><code>基于语句的复制</code>: 在主服务器执行的 SQL 语句，在从服务器也执行同样语句，这是 MySQL 默认采用的复制方式。</li><li><code>基于行的复制</code>: 将改变的数据复制给从服务器，而不是让 SQL 语句在从服务器上执行一遍，从 MySQL <code>5.0</code> 版本开始支持。</li><li><code>混合类型的复制</code>: 默认采用基于 SQL 语句的复制（效率较高），一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。</li></ul><h2 id="主从复制类型"><a href="#主从复制类型" class="headerlink" title="主从复制类型"></a>主从复制类型</h2><h3 id="异步复制"><a href="#异步复制" class="headerlink" title="异步复制"></a>异步复制</h3><p>异步复制是 MySQL 默认使用的复制类型。</p><div class="admonition warning"><p class="admonition-title">特别注意</p><p>异步复制不能保证 Slave 节点一定能接收到 Binlog 日志，即无法保证数据的一致性，但执行效率是最高的。</p></div><h4 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h4><p><img data-src="../../../asset/2023/10/mysql-replication-1.png"></p><h3 id="半同步复制"><a href="#半同步复制" class="headerlink" title="半同步复制"></a>半同步复制</h3><p>从 MySQL <code>5.5</code> 版本开始，MySQL 可以让 Master 节点在某一个时间点等待 Slave 节点的 ACK 消息，接收到 ACK 消息后才进行事务提交，这就是半同步复制。半同步复制可以保证至少有一个 Slave 节点的 Relay Log（中继日志）是完整的数据，即对数据一致性有一定的保障，但执行效率较慢。</p><ul><li>半同步复制在提交过程中增加了一个延迟，即在提交事务时，在客户端接收到查询结束反馈前必须保证二进制日志已经传输到一台 Slave 节点上。</li><li>半同步不会阻塞 Master 节点上的事务提交，只有通知客户端被延迟了。</li><li>Slave 节点在接收到事务后发送 ACK 消息，而不是完成事务后再发送。</li><li><strong>如果 Slave 节点一直没有回应，会超时自动切换为异步复制模式。</strong></li></ul><h4 id="整体流程-1"><a href="#整体流程-1" class="headerlink" title="整体流程"></a>整体流程</h4><p><img data-src="../../../asset/2023/10/mysql-replication-2.png"></p><h4 id="半同步复制插件"><a href="#半同步复制插件" class="headerlink" title="半同步复制插件"></a>半同步复制插件</h4><p>MySQL 的半同步复制是以插件的形式提供的，因此在使用之前需要安装对应的插件，如下所示：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主库安装半同步复制插件</span></span><br><span class="line">mysql&gt; install plugin rpl_semi_sync_master soname <span class="string">'semisync_master.so'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从库安装半同步复制插件</span></span><br><span class="line">mysql&gt; install plugin rpl_semi_sync_slave soname <span class="string">'semisync_slave.so'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看已安装的插件</span></span><br><span class="line">mysql&gt; show plugins;</span><br></pre></td></tr></tbody></table></figure><h4 id="半同步复制大坑"><a href="#半同步复制大坑" class="headerlink" title="半同步复制大坑"></a>半同步复制大坑</h4><p>在极端情况下，半同步复制也无法保证数据的一致性（至少有一个 Slave 节点的数据是完整的），如下图所示：</p><p><img data-src="../../../asset/2023/10/mysql-replication-3.png"></p><p>为了避免出现上述图中数据不一致的问题，强烈建议使用 <code>SET rpl_semi_sync_master_wait_point=AFTER_SYNC</code> 开启了 MySQL 的增强半同步，从 <code>5.7</code> 版本开始默认就是开启的。<strong>特别注意，MySQL <code>5.7</code> 之前的旧版本默认是使用 <code>AFTER_COMMIT</code>（传统半同步）。</strong></p><div class="admonition note"><p class="admonition-title">MHA 与半同步复制是绝配</p><p>MHA 高可用架构非常适合搭配半同步复制一起使用，详细介绍请看 <a href="/posts/d6058b93.html#MHA-%E6%96%B9%E6%A1%88">这里</a> 的教程。</p></div><h3 id="全同步复制"><a href="#全同步复制" class="headerlink" title="全同步复制"></a>全同步复制</h3><p>全同步复制属于主从强一致方案，对 Binlog 有一定的要求，且执行效率最慢。MySQL <code>5.7.17</code> 版本开始引入了组复制技术，因此全同步复制可以配合 <a href="/posts/d6058b93.html#MGR-%E6%96%B9%E6%A1%88">MGR 高可用架构</a> 一起使用。MGR 中的组复制协议如下图所示：</p><p><img data-src="../../../asset/2023/10/mysql-replication-4.png"></p><h2 id="主从复制进阶"><a href="#主从复制进阶" class="headerlink" title="主从复制进阶"></a>主从复制进阶</h2><h3 id="并行复制"><a href="#并行复制" class="headerlink" title="并行复制"></a>并行复制</h3><p>MySQL 从 <code>5.6</code> 版本开始引入了并行复制功能，用于改善复制延迟的问题。这是因为 Slave 节点只有一个 SQL 线程，当主库写压力大时，复制很可能会延迟。</p><h4 id="5-6-版本并行复制"><a href="#5-6-版本并行复制" class="headerlink" title="5.6 版本并行复制"></a>5.6 版本并行复制</h4><p>MySQL <code>5.6</code> 版本仅支持基于库的并行复制，也就是多个线程分别执行不同库的复制操作，互不干扰。值得一提的是，单库多表的复制效率并没有提升。</p><p><img data-src="../../../asset/2023/10/mysql-replication-6.png"></p><h4 id="5-7-版本并行复制"><a href="#5-7-版本并行复制" class="headerlink" title="5.7 版本并行复制"></a>5.7 版本并行复制</h4><p>MySQL <code>5.7</code> 版本支持基于组提交的并行复制，不再有库的并行复制限制（即支持单库多表的并行复制）。当事务提交时，通过在主库上的二进制日志中添加组提交信息，并将在单个操作中写入到二进制日志中。如果多个事务能同时提交成功，那么它们意味着没有冲突，因此可以在 Slave 节点上并行执行。InnoDB 事务提交采用的是两阶段提交模式。一个阶段是 Prepare，另一个阶段是 Commit。MySQL <code>5.7</code> 版本的并行复制基于一个前提，即所有已经处于 Prepare 阶段的事务，都是可以并行提交的。在 MySQL <code>5.7</code> 版本中，其设计方式是将组提交的信息存放在 GTID 中。为了避免用户没有开启 GTID 功能，MySQL <code>5.7</code> 又引入了称之为 <code>Anonymous_Gtid</code> 的二进制日志 Event 类型，即日志中具有相同的 <code>last_committed</code>，表示这些事务都在一组内。</p><h4 id="8-0-版本并行复制"><a href="#8-0-版本并行复制" class="headerlink" title="8.0 版本并行复制"></a>8.0 版本并行复制</h4><p>MySQL <code>8.0</code> 版本支持基于 <code>write-set</code> 的并行复制。有一个集合变量来存储事务修改的记录信息（主键哈希值），所有已经提交的事务所修改的主键值经过 Hash 后都会与那个变量的集合进行对比，来判断改行是否与其冲突，并以此来确定依赖关系，没有冲突即可并行，Row 级别的粒度，类似于之前的表锁行锁差异，效率会更高。</p><h3 id="日志点与-GTID"><a href="#日志点与-GTID" class="headerlink" title="日志点与 GTID"></a>日志点与 GTID</h3><p>MySQL 的主从复制，支持基于日志点或者 GTID 进行复制。</p><ul><li><p>基于日志点复制</p><ul><li>Slave 节点请求 Master 节点的增量日志依赖于日志偏移量。</li><li>配置主从复制链路时需要指定参数。</li><li>支持 MMM 和 MHA。</li></ul></li><li><p>基于 GTID 复制</p><ul><li>GTID（全局事务唯一 ID），其构成是 <code>GTID = source_id:transaction_id</code>。</li><li>Slave 节点增量同步 Master 节点的数据依赖于其未同步的全局事务 ID。</li><li>配置主从复制链路时，Slave 节点会根据已经同步的事务 ID 继续自动同步。</li><li>支持 MHA。</li></ul></li></ul><div class="admonition note"><p class="admonition-title">复制方式选择</p><p>如何是为了兼容旧版本的 MySQL 和 MMM，建议选择基于日志点复制，其他业务场景可以选择基于 GTID 复制。</p></div><h3 id="主从复制架构"><a href="#主从复制架构" class="headerlink" title="主从复制架构"></a>主从复制架构</h3><p>MySQL 常见的主从复制架构如下：</p><p><img data-src="../../../asset/2023/10/mysql-replication0-7.png"></p><h2 id="主从复制常见问题"><a href="#主从复制常见问题" class="headerlink" title="主从复制常见问题"></a>主从复制常见问题</h2><h3 id="主从复制高延迟"><a href="#主从复制高延迟" class="headerlink" title="主从复制高延迟"></a>主从复制高延迟</h3><p>造成 MySQL 主从复制高延迟的常见原因如下：</p><ul><li><code>网络</code>：如主库或者从库的带宽打满，或者主从之间的网络延迟很大，导致主库上的 Binlog 没有全量传输到从库，造成了延迟。</li><li><code>机器性能</code>：从库的硬件性能较差，比如主库使用 SSD 硬盘，而从库使用 SATA 硬盘。</li><li><code>从库高负载</code>：有很多业务会在从库上做统计，把从库服务器搞成高负载，从而造成从库延迟很大的情况。</li><li><code>大事务</code>：比如在 RBR 模式下，执行带有大量的 Delete 操作，这种通过查看 <code>processlist</code> 相关信息以及使用 <code>mysqlbinlog</code> 查看 Binlog 中的 SQL 就能快速进行排查。</li><li><code>锁</code>: 锁冲突问题也可能导致从库的 SQL 线程执行慢，比如从库上有一些 <code>select ... for update</code> 的 SQL，或者使用了 MyISAM 存储引擎等。</li></ul><p>MySQL 主从复制高延迟硬件方面的优化方案如下：</p><ul><li>采用性能更高的服务器，比如 4U 比 2U 性能明显要更好。</li><li>数据库存储使用 SSD 硬盘、磁盘阵列或者 SAN 存储网络，提升随机写的性能。</li><li>主从库之间保证处在同一个交换机下面，并且是万兆环境。</li></ul><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ul><li>全同步复制相对于半同步复制来说，数据的一致性更高，但性能代价也更高。具体选择哪种复制，取决于对数据一致性和性能的需求权衡。</li><li>在关键业务场景下（对数据一致性的要求较高），可以更倾向于选择全同步复制，而在某些读写分离的场景下，可以考虑半同步复制。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/383463007">MySQL 集群架构</a></li><li><a href="https://www.cnblogs.com/junjun511/p/11412313.html">MySQL 主从复制原理</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 MySQL 的主从复制方案，包括异步复制、半同步复制、全同步复制、并行复制等内容。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="数据库" scheme="https://www.techgrow.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>JavaScript 模块化入门教程</title>
    <link href="https://www.techgrow.cn/posts/1ce314e0.html"/>
    <id>https://www.techgrow.cn/posts/1ce314e0.html</id>
    <published>2023-10-09T12:23:35.000Z</published>
    <updated>2023-10-09T12:23:35.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="模块化介绍"><a href="#模块化介绍" class="headerlink" title="模块化介绍"></a>模块化介绍</h2><h3 id="模块化的概念"><a href="#模块化的概念" class="headerlink" title="模块化的概念"></a>模块化的概念</h3><p>模块化的本质是将一个复杂的程序依据一定的规则 (规范) 封装成几个块 (文件)，并进行组合在一起，块 (文件) 的内部数据和操作实现是私有的，只是对外部暴露一些接口 (方法) 与外部其它模块通信。</p><span id="more"></span><h3 id="模块化的进化史"><a href="#模块化的进化史" class="headerlink" title="模块化的进化史"></a>模块化的进化史</h3><blockquote><p>一、将不同的功能封装成不同的全局函数（全局函数模式）</p></blockquote><ul><li>缺点：Global 被污染，很容易引起命名冲突</li></ul><p><img data-src="../../../asset/2023/10/javascript-modular-1.png"></p><blockquote><p>二、简单对象封装（命名模式）</p></blockquote><ul><li>优点：减少 Global 上的变量数目</li><li>缺点：本质是对象，一点都不安全</li></ul><p><img data-src="../../../asset/2023/10/javascript-modular-2.png"></p><blockquote><p>三、匿名函数自调用【闭包】（IIFE 模式）</p></blockquote><ul><li>优点：函数是 JavaScript 唯一的 Local Scope</li><li> 缺点：如果当前这个模块依赖另一个模块怎么办？</li></ul><p><img data-src="../../../asset/2023/10/javascript-modular-3.png"></p><blockquote><p>四、引入依赖（IIFE 模式增强），<strong>这是现代模块化实现的基石</strong></p></blockquote><p><img data-src="../../../asset/2023/10/javascript-modular-4.png"></p><h3 id="为什么要模块化"><a href="#为什么要模块化" class="headerlink" title="为什么要模块化"></a>为什么要模块化</h3><h4 id="前端开发的现状"><a href="#前端开发的现状" class="headerlink" title="前端开发的现状"></a>前端开发的现状</h4><p>前端开发的现状往往是在页面中引入加载大量的 JavaScript 文件（如下图），这会导致页面请求过多、依赖模糊、代码难以维护等问题。值得一提的是，这些问题可以通过现代模块化编码和项目构建来解决。</p><p><img data-src="../../../asset/2023/10/javascript-modular-5.png"></p><h4 id="模块化的需求"><a href="#模块化的需求" class="headerlink" title="模块化的需求"></a>模块化的需求</h4><ul><li>Web sites are turning into Web apps（网站正转变为网络应用程序）</li><li>Code complexity grows as the site gets bigger（代码复杂度随着站点变大而变复杂）</li><li>Assembly gets harder（组装变得更难）</li><li>Developer wants discrete JS files/modules（开发者想分离 JS 文件 / 模块）</li><li>Deployment wants optimized code in just one or a few HTTP calls（网站部署者想通过使用一个或者很少 HTTP 请求来优化代码）</li></ul><h4 id="模块化的优点"><a href="#模块化的优点" class="headerlink" title="模块化的优点"></a>模块化的优点</h4><ul><li>避免命名冲突（减少命名空间污染）</li><li>更好的分离，按需加载</li><li>更高的复用性</li><li>更高的可维护性</li></ul><h2 id="模块化规范"><a href="#模块化规范" class="headerlink" title="模块化规范"></a>模块化规范</h2><p>JavaScript 的模块化规范分为四大类，分别是 CommonJS、ES 6、AMD、CMD。</p><h3 id="CommonJS"><a href="#CommonJS" class="headerlink" title="CommonJS"></a>CommonJS</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>每个 JavaScript 文件都可以当一个模块，并具有以下特性：</p><ul><li><code>在服务器端</code>：模块的加载是在运行时同步加载的</li><li><code>在浏览器端</code>：模块需要提前编译打包处理</li></ul><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><ul><li><p>服务端的实现</p><ul><li><a href="https://nodejs.cn/">Node.js</a></li></ul></li><li><p> 浏览器端的实现</p><ul><li><a href="https://browserify.org/">Browserify</a>，它也称为 CommonJS 的浏览器端的打包工具</li></ul></li></ul><div class="admonition note"><p class="admonition-title">Node.js 与 Browserify 的区别</p><p>Node.js 是在运行时动态加载模块（同步），而 Browserify 是在转译（编译）时就会加载并打包 （合并） <code>require</code> 的模块。</p></div><h4 id="基础语法"><a href="#基础语法" class="headerlink" title="基础语法"></a>基础语法</h4><ul><li><p>暴露模块</p><ul><li><code>module.exports = value</code></li><li><code>exports.xxx = value</code></li></ul></li><li><p>引入模块</p><ul><li><code>require(xxx)</code><ul><li>内置模块： <code>xxx</code> 为模块名</li><li>第三方模块： <code>xxx</code> 为模块名</li><li>自定义模块： <code>xxx</code> 为模块文件的路径</li></ul></li></ul></li></ul><h4 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h4><ul><li>创建项目结构 </li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">05</span><br><span class="line">├── app.js</span><br><span class="line">├── modules</span><br><span class="line">│   ├── module1.js</span><br><span class="line">│   ├── module2.js</span><br><span class="line">│   └── module3.js</span><br><span class="line">└── package.json</span><br></pre></td></tr></tbody></table></figure><ul><li>Node 安装第三方模块 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install uniq --save</span><br></pre></td></tr></tbody></table></figure><ul><li>模块化编码 - module1.js</li></ul><figure class="highlight js"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// module.exports = value 暴露一个对象</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">module</span>.exports = {</span><br><span class="line">    <span class="attr">msg</span> : <span class="string">'module1 msg'</span>,</span><br><span class="line">    <span class="function"><span class="title">foo</span>(<span class="params"></span>)</span> {</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'module1 foo()'</span>);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>模块化编码 - module2.js</li></ul><figure class="highlight js"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// module.exports = value 暴露一个函数</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">module</span>.exports = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>{</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'module2()'</span>);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>模块化编码 - module3.js</li></ul><figure class="highlight js"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// exports.xxx = value 暴露多个目标</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exports</span>.foo = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>{</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'module3 foo()'</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="built_in">exports</span>.bar = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>{</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'module3 bar()'</span>)</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>模块化编码 - app.js</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 引入内置模块</span></span><br><span class="line"><span class="keyword">const</span> fs = require(<span class="string">'fs'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 引入第三方模块</span></span><br><span class="line"><span class="keyword">const</span> uniq = require(<span class="string">'uniq'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 引入自定义模块</span></span><br><span class="line"><span class="keyword">const</span> module1 = require(<span class="string">'./modules/module1'</span>);</span><br><span class="line"><span class="keyword">const</span> module2 = require(<span class="string">'./modules/module2'</span>);</span><br><span class="line"><span class="keyword">const</span> module3 = require(<span class="string">'./modules/module3'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用模块</span></span><br><span class="line">fs.readFile(<span class="string">'app.js'</span>, function(error, data) {</span><br><span class="line">    console.log(data.toString());</span><br><span class="line">})</span><br><span class="line"></span><br><span class="line">let arr = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>];</span><br><span class="line">console.log(uniq(arr));</span><br><span class="line"></span><br><span class="line">module1.foo();</span><br><span class="line">module2();</span><br><span class="line">module3.foo();</span><br><span class="line">module3.bar();</span><br></pre></td></tr></tbody></table></figure><ul><li>通过 Node 运行 app.js</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node app.js</span><br></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <summary type="html">本文主要介绍 JavaScript 模块化的入门教程，包括 CommonJS、ES 6、AMD、CMD 的模块化使用。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="前端" scheme="https://www.techgrow.cn/tags/%E5%89%8D%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 使用自带的事件调度器定时执行 SQL</title>
    <link href="https://www.techgrow.cn/posts/15d17038.html"/>
    <id>https://www.techgrow.cn/posts/15d17038.html</id>
    <published>2023-09-07T12:48:23.000Z</published>
    <updated>2023-09-07T12:48:23.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在开发过程中经常会遇到这样一个问题，每天或者每月必须定时去执行一条 SQL 语句，下面这篇文章主要给大家介绍如何使用 MySQL 自带的事件调度器定时执行 SQL 语句。</p><h2 id="启用事件调度器"><a href="#启用事件调度器" class="headerlink" title="启用事件调度器"></a>启用事件调度器</h2><p>查看事件调度器的运行状态</p><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">'%sche%'</span>;</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/09/mysql-event-1.png"></p><span id="more"></span><p>如果 <code>event_scheduler</code> 的值为 <code>OFF</code>，则需要启用事件调度器（下述方式属于临时启用）</p><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> event_scheduler<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></tbody></table></figure><p>或者更改 MySQL 的配置文件（如 <code>my.conf</code>），在 <code>[mysqld]</code> 标记下添加以下内容，然后重启 MySQL 服务器（下述方式属于永久启用）</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">event_scheduler = ON</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">为什么建议在 MySQL 的配置文件中启用事件调度器</p><p>这是为了防止在操作系统断电重启后，导致数据库的事件调度器又变回默认关闭的状态 <code>OFF</code>，这样定时事件就不再自动执行了。通过更改 MySQL 的配置文件，将它设置成默认开启状态 <code>ON</code>，这使得在断电重启后 MySQL 依旧会自动正常执行定时事件。</p></div><h2 id="管理定时事件"><a href="#管理定时事件" class="headerlink" title="管理定时事件"></a>管理定时事件</h2><h3 id="创建定时事件"><a href="#创建定时事件" class="headerlink" title="创建定时事件"></a>创建定时事件</h3><p>创建定时事件，<code>DO</code> 后面的内容是需要定时执行的 SQL 语句，也可以使用 <code>CALL</code> 指令调用存储过程</p><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 每天0点执行</span></span><br><span class="line"><span class="keyword">CREATE</span> EVENT clear_logging_event_property</span><br><span class="line"><span class="keyword">ON</span> SCHEDULE <span class="keyword">EVERY</span> <span class="number">1</span> <span class="keyword">DAY</span> STARTS <span class="type">DATE</span>(<span class="built_in">CURRENT_DATE</span> <span class="operator">+</span> <span class="number">1</span>) </span><br><span class="line">DO <span class="keyword">truncate</span> <span class="keyword">table</span> logging_event_property;</span><br></pre></td></tr></tbody></table></figure><p><code>on schedule at</code> 表示在特定时间执行，<code>on schedule every</code> 表示重复执行</p><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--- 特定的日期特定的时间点执行定时任务</span></span><br><span class="line"><span class="keyword">ON</span> SCHEDULE <span class="keyword">at</span> <span class="string">'2023-10-05 19:14:10'</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--- 每五分钟执行一次定时任务</span></span><br><span class="line"><span class="keyword">ON</span> SCHEDULE <span class="keyword">EVERY</span> <span class="number">5</span> <span class="keyword">MINUTE</span> STARTS CURDATE()</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--- 每小时执行一次定时任务</span></span><br><span class="line"><span class="keyword">ON</span> SCHEDULE <span class="keyword">EVERY</span> <span class="number">1</span> <span class="keyword">HOUR</span> STARTS CURDATE()</span><br></pre></td></tr></tbody></table></figure><h3 id="查看定时事件"><a href="#查看定时事件" class="headerlink" title="查看定时事件"></a>查看定时事件</h3><ul><li>查看所有定时事件，将显示事件的详细信息，包括事件名称、定时器时间、事件状态和执行操作等 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> events;</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/09/mysql-event-2.png"></p><ul><li>查看所有定时事件的执行历史记录，将显示事件的详细信息，包括事件名称、定时器时间、事件状态、执行操作、最后一次执行的时间等 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> information_schema.events;</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/09/mysql-event-3.png"></p><h3 id="开启定时事件"><a href="#开启定时事件" class="headerlink" title="开启定时事件"></a>开启定时事件</h3><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--- 开启某个定时事件</span></span><br><span class="line"><span class="keyword">alter</span> event user_event <span class="keyword">on</span> completion preserve enable;</span><br></pre></td></tr></tbody></table></figure><h3 id="关闭定时事件"><a href="#关闭定时事件" class="headerlink" title="关闭定时事件"></a>关闭定时事件</h3><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--- 关闭某个定时事件</span></span><br><span class="line"><span class="keyword">alter</span> event user_event <span class="keyword">on</span> completion preserve disable;</span><br></pre></td></tr></tbody></table></figure><h3 id="删除定时事件"><a href="#删除定时事件" class="headerlink" title="删除定时事件"></a>删除定时事件</h3><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--- 删除某个定时事件</span></span><br><span class="line"><span class="keyword">drop</span> event user_event;</span><br></pre></td></tr></tbody></table></figure><h2 id="常用定时事件案例"><a href="#常用定时事件案例" class="headerlink" title="常用定时事件案例"></a>常用定时事件案例</h2><h3 id="一次性执行"><a href="#一次性执行" class="headerlink" title="一次性执行"></a>一次性执行</h3><blockquote><p>满足指定条件时，只会执行一次定时事件，然后定时事件结束执行</p></blockquote><ul><li>在未来指定时间点执行一次 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;</span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line">    <span class="keyword">ON</span> SCHEDULE <span class="keyword">AT</span> <span class="type">TIMESTAMP</span> <span class="string">'2023-09-24 18:26:00'</span></span><br><span class="line">    <span class="keyword">ON</span> COMPLETION <span class="keyword">NOT</span> PRESERVE</span><br><span class="line">DO <span class="keyword">call</span> user_procedure();</span><br></pre></td></tr></tbody></table></figure><ul><li>从现在开始 1 小时后执行一次 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;</span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line">    <span class="keyword">ON</span> SCHEDULE <span class="keyword">AT</span> <span class="built_in">CURRENT_TIMESTAMP</span> <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">HOUR</span></span><br><span class="line">    <span class="keyword">ON</span> COMPLETION <span class="keyword">NOT</span> PRESERVE</span><br><span class="line">DO <span class="keyword">call</span> user_procedure();</span><br></pre></td></tr></tbody></table></figure><h3 id="周期性一直执行"><a href="#周期性一直执行" class="headerlink" title="周期性一直执行"></a>周期性一直执行</h3><blockquote><p>定时事件一直周期性地执行</p></blockquote><ul><li>从现在开始每隔 N 天执行一次 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;    </span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line"><span class="keyword">ON</span> SCHEDULE <span class="keyword">EVERY</span> <span class="number">9</span> <span class="keyword">DAY</span> STARTS NOW()</span><br><span class="line">DO <span class="keyword">call</span> user_procedure();</span><br></pre></td></tr></tbody></table></figure><ul><li>每天凌晨 1 点执行 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;    </span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line"><span class="keyword">on</span> schedule <span class="keyword">EVERY</span> <span class="number">1</span> <span class="keyword">DAY</span> STARTS date_add(<span class="type">date</span>( ADDDATE(curdate(),<span class="number">1</span>)),<span class="type">interval</span> <span class="number">1</span> <span class="keyword">hour</span>)  </span><br><span class="line">DO <span class="keyword">call</span> user_procedure();  </span><br></pre></td></tr></tbody></table></figure><ul><li>每个月的一号凌晨 1 点执行 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;</span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line"><span class="keyword">ON</span> schedule <span class="keyword">every</span> <span class="number">1</span> <span class="keyword">month</span> starts date_add(date_add(date_sub(curdate(),<span class="type">interval</span> <span class="keyword">day</span>(curdate())<span class="number">-1</span> <span class="keyword">day</span>),<span class="type">interval</span> <span class="number">1</span> <span class="keyword">month</span>),<span class="type">interval</span> <span class="number">1</span> <span class="keyword">hour</span>)</span><br><span class="line">DO <span class="keyword">call</span> user_procedure();  </span><br></pre></td></tr></tbody></table></figure><ul><li>每个季度一号的凌晨 1 点执行 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;</span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line"><span class="keyword">ON</span> schedule <span class="keyword">every</span> <span class="number">1</span> quarter starts date_add(date_add(<span class="type">date</span>(concat(<span class="keyword">year</span>(curdate()),<span class="string">'-'</span>,elt(quarter(curdate()),<span class="number">1</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">10</span>),<span class="string">'-'</span>,<span class="number">1</span>)),<span class="type">interval</span> <span class="number">1</span> quarter),<span class="type">interval</span> <span class="number">1</span> <span class="keyword">hour</span>)</span><br><span class="line">DO <span class="keyword">call</span> user_procedure(); </span><br></pre></td></tr></tbody></table></figure><ul><li>每年 1 月 1 号凌晨 1 点执行 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;</span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line"><span class="keyword">ON</span> schedule <span class="keyword">every</span> <span class="number">1</span> quarter starts date_add(date_add(<span class="type">date</span>(concat(<span class="keyword">year</span>(curdate()),<span class="string">'-'</span>,elt(quarter(curdate()),<span class="number">1</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">10</span>),<span class="string">'-'</span>,<span class="number">1</span>)),<span class="type">interval</span> <span class="number">1</span> quarter),<span class="type">interval</span> <span class="number">1</span> <span class="keyword">hour</span>)</span><br><span class="line">DO <span class="keyword">call</span> user_procedure();  </span><br></pre></td></tr></tbody></table></figure><h3 id="周期性多次执行"><a href="#周期性多次执行" class="headerlink" title="周期性多次执行"></a>周期性多次执行</h3><blockquote><p>定时事件执行多次后，在满足某个条件时，定时事件结束执行</p></blockquote><ul><li>从现在开始每天执行一次，5 天后停止执行 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;</span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line">    <span class="keyword">ON</span> SCHEDULE <span class="keyword">EVERY</span> <span class="number">1</span> <span class="keyword">DAY</span></span><br><span class="line">    ENDS <span class="built_in">CURRENT_TIMESTAMP</span> <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">5</span> <span class="keyword">DAY</span></span><br><span class="line">DO <span class="keyword">call</span> user_procedure();</span><br></pre></td></tr></tbody></table></figure><ul><li>从现在开始 5 天后开始执行，一个月后停止执行 </li></ul><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> EVENT IF <span class="keyword">EXISTS</span> user_event;</span><br><span class="line"><span class="keyword">CREATE</span> EVENT user_event</span><br><span class="line">    <span class="keyword">ON</span> SCHEDULE <span class="keyword">EVERY</span> <span class="number">1</span> <span class="keyword">DAY</span></span><br><span class="line">    STARTS <span class="built_in">CURRENT_TIMESTAMP</span> <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">5</span> <span class="keyword">DAY</span></span><br><span class="line">    ENDS <span class="built_in">CURRENT_TIMESTAMP</span> <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">MONTH</span></span><br><span class="line">DO <span class="keyword">call</span> user_procedure();</span><br></pre></td></tr></tbody></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.jb51.net/article/276735.htm">如何用 MySQL 自带的定时器定时执行 SQL</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 MySQL 使用自带的事件调度器定时执行 SQL 语句。</summary>
    
    
    
    
    <category term="数据库" scheme="https://www.techgrow.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Linux 挂载 NTFS 硬盘分区出错</title>
    <link href="https://www.techgrow.cn/posts/3ea887f5.html"/>
    <id>https://www.techgrow.cn/posts/3ea887f5.html</id>
    <published>2023-09-06T14:32:44.000Z</published>
    <updated>2023-09-06T14:32:44.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="错误信息"><a href="#错误信息" class="headerlink" title="错误信息"></a>错误信息</h2><p>Linux 系统突然断电重启后，再次挂载 NTFS 格式的硬盘分区时，出现以下错误信息：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mount -t ntfs-3g /dev/sdb1 /mnt/share</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$MFTMirr does not match $MFT (record 0).</span><br><span class="line">Failed to mount '/dev/sdb1': Input/output error</span><br><span class="line">NTFS is either inconsistent, or there is a hardware fault, or it's a</span><br><span class="line">SoftRAID/FakeRAID hardware. In the first case run chkdsk /f on Windows</span><br><span class="line">then reboot into Windows twice. The usage of the /f parameter is very</span><br><span class="line">important! If the device is a SoftRAID/FakeRAID then first activate</span><br><span class="line">it and mount a different device under the /dev/mapper/ directory, (e.g.</span><br><span class="line">/dev/mapper/nvidia_eahaabcc1). Please see the 'dmraid' documentation</span><br><span class="line">for more details.</span><br></pre></td></tr></tbody></table></figure><span id="more"></span><h2 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h2><p>在删除、拷贝或者移动硬盘文件时，如果硬盘突然断电或者掉落（断掉、接口松动），那么再次挂载硬盘时，可能会提示硬盘分区的 <code>$MFT</code> 文件出现了问题。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>在 Linux 系统下使用 <code>ntfsfix</code> 命令进行修复，而在 Windows 系统下可以使用 <code>chkdsk</code> 命令进行修复。</p><ul><li>安装 ntfsprogs 工具 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install ntfsprogs</span></span><br></pre></td></tr></tbody></table></figure><ul><li>使用 <code>ntfsfix</code> 命令进行修复 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ntfsfix /dev/sdb1</span></span><br><span class="line"></span><br><span class="line">Mounting volume... <span class="variable">$MFTMirr</span> does not match <span class="variable">$MFT</span> (record 0).</span><br><span class="line">FAILED</span><br><span class="line">Attempting to correct errors... </span><br><span class="line">Processing <span class="variable">$MFT</span> and <span class="variable">$MFTMirr</span>...</span><br><span class="line">Reading <span class="variable">$MFT</span>... OK</span><br><span class="line">Reading <span class="variable">$MFTMirr</span>... OK</span><br><span class="line">Comparing <span class="variable">$MFTMirr</span> to <span class="variable">$MFT</span>... FAILED</span><br><span class="line">Correcting differences <span class="keyword">in</span> <span class="variable">$MFTMirr</span> record 0...OK</span><br><span class="line">Processing of <span class="variable">$MFT</span> and <span class="variable">$MFTMirr</span> completed successfully.</span><br><span class="line">Setting required flags on partition... OK</span><br><span class="line">Going to empty the journal (<span class="variable">$LogFile</span>)... OK</span><br><span class="line">Checking the alternate boot sector... OK</span><br><span class="line">NTFS volume version is 3.1.</span><br><span class="line">NTFS partition /dev/sdb1 was processed successfully.</span><br></pre></td></tr></tbody></table></figure><p>重新挂载 NTFS 硬盘分区</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mount -t ntfs-3g /dev/sdb1 /mnt/share</span></span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>笔者的硬盘分区路径是 <code>/dev/sdb1</code>，您需要根据实际情况指定自己的硬盘分区路径。值得一提的是，可以使用 <code>fdisk -l</code> 命令来查看硬盘分区的详细信息。</p></div>]]></content>
    
    
    <summary type="html">本文主要介绍如何解决 Linux 挂载 NTFS 硬盘分区出错的问题。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="Linux" scheme="https://www.techgrow.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Centos 7 开机启动失败问题解决</title>
    <link href="https://www.techgrow.cn/posts/2032e2a7.html"/>
    <id>https://www.techgrow.cn/posts/2032e2a7.html</id>
    <published>2023-09-02T12:10:21.000Z</published>
    <updated>2023-09-02T12:10:21.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="Centos-7-开机启动失败"><a href="#Centos-7-开机启动失败" class="headerlink" title="Centos 7 开机启动失败"></a>Centos 7 开机启动失败</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>Centos 7 系统突然断电重启后，无法正常启动。</p><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>在 Centos 7 启用了 SeLinux 的情况下，系统突然断电重启之后，由于未知原因导致 SeLinux 未自动对文件系统（包括系统磁盘和挂载的数据磁盘的文件系统）重新标记，最终导致系统启动失败。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul><li>第一步：进入 Centos 7 的救援模式，使用 <code>journalctl</code> 命令查看系统启动的错误日志 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl -xb -p err</span><br></pre></td></tr></tbody></table></figure><ul><li>第二步：永久禁用 SeLinux，可以更改系统的 SeLinux 配置文件，将 <code>SELINUX</code> 的值设置为 <code>disabled</code>。</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑配置文件，禁用SeLinux</span></span><br><span class="line">sudo vim /etc/selinux/config</span><br><span class="line"></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></tbody></table></figure><ul><li>第三步：重启 Centos 7 系统</li></ul><span id="more"></span><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://www.cnblogs.com/nf01/articles/14005379.html">Centos 7 进入救援模式</a></li><li><a href="https://blog.51cto.com/jschu/1706020">Centos 7 进入救援模式重置密码</a></li><li><a href="https://www.freesion.com/article/8855704390/">Centos 7.X 重新启用 SeLinux，系统无法启动</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 Centos7 如何解决开机启动失败的问题。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="Centos" scheme="https://www.techgrow.cn/tags/Centos/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot 3 进阶教程之二 GraalVM 与 AOT</title>
    <link href="https://www.techgrow.cn/posts/885fde15.html"/>
    <id>https://www.techgrow.cn/posts/885fde15.html</id>
    <published>2023-08-26T15:12:43.000Z</published>
    <updated>2023-08-30T15:12:43.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/1b2af7f9.html">SpringBoot 3 进阶教程之一整合 Prometheus</a></li><li><a href="/posts/885fde15.html">SpringBoot 3 进阶教程之二 GraalVM 与 AOT</a></li><li><a href="/posts/2cc2991f.html">SpringBoot 3 进阶教程之三整合 Spring Security</a></li><li><a href="/posts/308cedc0.html">SpringBoot 3 进阶教程之四自定义 Starter</a></li></ul><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文主要介绍 SpringBoot 3 如何使用 AOT 技术，包括在 Windows、Linux 平台使用 GraalVM 将 SpringBoot 应用编译成原生镜像（二进制可执行文件）。</p><h2 id="AOT-与-JIT"><a href="#AOT-与-JIT" class="headerlink" title="AOT 与 JIT"></a>AOT 与 JIT</h2><ul><li><code>AOT</code>：Ahead of Time（提前编译），程序执行前，全部被编译成机器码</li><li><code>JIT</code>：Just in Time（即时编译），程序边编译边运行</li></ul><h3 id="编译器与解释器"><a href="#编译器与解释器" class="headerlink" title="编译器与解释器"></a>编译器与解释器</h3><div class="admonition note"><p class="admonition-title">编程语言的分类</p><ul><li>编译型语言：依赖编译器 (Complier)，如 C、C++</li><li> 解释型语言：依赖解释器 (Interpreter)，如 JavaScrpt、Python</li></ul></div><span id="more"></span><p><img data-src="../../../asset/2023/08/spring-boot3-study-52.png"></p><table><thead><tr><th> 对比项目</th><th>编译器 (Complier)</th><th> 解释器 (Interpreter)</th></tr></thead><tbody><tr><td> 机器执行速度</td><td>快，因为源代码只需被转换一次</td><td>慢，因为每行代码都需要被解释执行</td></tr><tr><td>开发效率</td><td>慢，因为需要耗费大量时间编译</td><td>快，无需花费时间生成目标代码，更快的开发和测试</td></tr><tr><td>调试</td><td>难以调试编译器生成的目标代码</td><td>容易调试源代码，因为解释器一行一行地执行</td></tr><tr><td>可移植性（跨平台）</td><td>不同平台需要重新编译目标平台代码</td><td>同一份源码可以跨平台执行，因为每个平台会开发对应的解释器</td></tr><tr><td>学习难度</td><td>相对较高，需要了解源代码、编译器以及目标机器的知识</td><td>相对较低，无需了解机器的细节</td></tr><tr><td>错误检查</td><td>编译器可以在编译代码时检查错误</td><td>解释器只能在执行代码时检查错误</td></tr><tr><td>运行时增强</td><td>无</td><td>可以动态增强</td></tr></tbody></table><h3 id="AOT-与-JIT-对比"><a href="#AOT-与-JIT-对比" class="headerlink" title="AOT 与 JIT 对比"></a>AOT 与 JIT 对比</h3><p><img data-src="../../../asset/2023/08/spring-boot3-study-53.png"></p><blockquote><p>在 OpenJDK 的官方 Wiki 上，介绍了 HotSpot 虚拟机一个相对比较全面的、即时编译器（JIT）中采用的 <a href="https://wiki.openjdk.org/display/HotSpot/PerformanceTacticIndex">优化技术列表</a>。Java 应用可以使用 JVM 参数 <code>-XX:+PrintCompilation</code> 打印 JIT 编译信息。</p></blockquote><h2 id="JVM-编译原理"><a href="#JVM-编译原理" class="headerlink" title="JVM 编译原理"></a>JVM 编译原理</h2><h3 id="JVM-整体架构"><a href="#JVM-整体架构" class="headerlink" title="JVM 整体架构"></a>JVM 整体架构</h3><p><img data-src="../../../asset/2023/08/spring-boot3-study-54.png"></p><blockquote><p>JVM 既有解释器，又有编译器，因此可以说 Java 是半编译半解释的编程语言。</p></blockquote><h3 id="Java-执行流程"><a href="#Java-执行流程" class="headerlink" title="Java 执行流程"></a>Java 执行流程</h3><div class="admonition note"><p class="admonition-title">建议阅读</p><ul><li>OpenJDK 官方文档：<a href="https://wiki.openjdk.org/display/HotSpot/Compiler">https://wiki.openjdk.org/display/HotSpot/Compiler</a></li><li> 美团技术团队的博客：<a href="https://tech.meituan.com/2020/10/22/java-jit-practice-in-meituan.html">https://tech.meituan.com/2020/10/22/java-jit-practice-in-meituan.html</a></li></ul></div><h4 id="流程概要"><a href="#流程概要" class="headerlink" title="流程概要"></a>流程概要</h4><p><img data-src="../../../asset/2023/08/spring-boot3-study-55.png"></p><h4 id="详细流程"><a href="#详细流程" class="headerlink" title="详细流程"></a>详细流程</h4><p><img data-src="../../../asset/2023/08/spring-boot3-study-56.png"></p><h3 id="JVM-编译器"><a href="#JVM-编译器" class="headerlink" title="JVM 编译器"></a>JVM 编译器</h3><ul><li><p>JVM 中集成了两种编译器，分别是 Client Compiler 和 Server Compiler</p><ul><li><code>Client Compiler</code>：注重启动速度和局部的优化</li><li><code>Server Compiler</code>：更加关注全局优化，性能更好，但由于会进行更多的全局分析，所以启动速度会慢</li></ul></li><li><p> Client Compiler</p><ul><li>HotSpot 虚拟机带有一个 Client Compiler C1 编译器</li><li>这种编译器启动速度快，但是性能比较 Server Compiler 来说会差一些</li><li>编译后的机器码执行效率没有 C2 的高</li></ul></li><li><p> Server Compiler</p><ul><li>Hotspot 虚拟机中使用的 Server Compiler 有两种： C2 和 Graal</li><li> 在 Hotspot 虚拟机中，默认的 Server Compiler 是 C2 编译器</li></ul></li></ul><h3 id="分层编译"><a href="#分层编译" class="headerlink" title="分层编译"></a>分层编译</h3><p>在 Java 7 以前，需要研发人员根据服务的性质去选择编译器。对于需要快速启动的，或者一些不会长期运行的服务，可以采用编译效率较高的 C1，对应参数 <code>-client</code>。长期运行的服务，或者对峰值性能有要求的后台服务，可以采用峰值性能更好的 C2，对应参数 <code>-server</code>。Java 7 开始引入了分层编译的概念，它结合了 C1 和 C2 的优势，追求启动速度和峰值性能的一个平衡。分层编译将 JVM 的执行状态分为了五个层次。五个层级分别是：</p><ul><li>解释执行</li><li>执行不带 <code>profiling</code> 的 C1 代码</li><li>执行仅带方法调用次数以及循环回边执行次数 <code>profiling</code> 的 C1 代码。</li><li>执行带所有 <code>profiling</code> 的 C1 代码</li><li>执行 C2 代码</li></ul><p><img data-src="../../../asset/2023/08/spring-boot3-study-57.png"></p><ul><li>图中第 ① 条路径，代表编译的一般情况，热点方法从解释执行到被 3 层的 C1 编译，最后被 4 层的 C2 编译。</li><li>如果方法比较小（比如 Java 服务中常见的 <code>getter</code> 与 <code>setter</code> 方法），3 层的 <code>profiling</code> 没有收集到有价值的数据，JVM 就会断定该方法对于 C1 代码和 C2 代码的执行效率相同，就会执行图中第 ② 条路径。在这种情况下，JVM 会在 3 层编译之后，放弃进入 C2 编译，直接选择用 1 层的 C1 编译运行。</li><li>在 C1 忙碌的情况下，执行图中第 ③ 条路径，在解释执行过程中对程序进行 <code>profiling</code> ，根据信息直接由第 4 层的 C2 编译。</li><li>由于 C1 中的执行效率是 1 层 &gt; 2 层 &gt; 3 层，第 3 层一般要比第 2 层慢 35% 以上，所以在 C2 忙碌的情况下，执行图中第 ④ 条路径。这时方法会被 2 层的 C1 编译，然后再被 3 层的 C1 编译，以减少方法在 3 层的执行时间。</li><li>如果编译器做了一些比较激进的优化，比如分支预测，在实际运行时发现预测出错，这时就会进行反优化，重新进入解释执行，图中第 ⑤ 条执行路径代表的就是反优化。</li></ul><blockquote><p>总的来说，C1 的编译速度更快，C2 的编译质量更高，分层编译的不同编译路径，也就是 JVM 根据当前服务的运行情况来寻找当前服务的最佳平衡点的一个过程。从 JDK 8 开始，JVM 默认开启分层编译。</p></blockquote><h2 id="云原生介绍"><a href="#云原生介绍" class="headerlink" title="云原生介绍"></a>云原生介绍</h2><p>在云原生 (Cloud Native) 的背景下，Java 应用的运行条件发生了变化。</p><ul><li><p>存在的问题</p><ul><li>Java 应用如果用 Jar 启动，解释执行后热点代码才被编译成机器码，会导致初始启动速度慢，初始处理请求数量少。</li><li>大型云平台，要求每一种应用都必须秒级启动，每个应用都要求高效率。</li></ul></li><li><p>希望的效果</p><ul><li>Java 应用也能提前被编译成机器码，随时急速启动，一启动就急速运行，追求最高性能</li><li>编译成机器码的优点<ul><li>服务器不需要安装 Java 运行环境</li><li>应用编译成机器码后，可以在 Windows x64 等平台直接运行</li></ul></li></ul></li></ul><div class="admonition note"><p class="admonition-title">原生镜像是什么？</p><ul><li>原生镜像 (Native Image)：机器码、本地镜像</li><li>把应用打包成能适配本机平台的可执行文件（机器码、本地镜像）</li></ul></div><h2 id="GraalVM-介绍"><a href="#GraalVM-介绍" class="headerlink" title="GraalVM 介绍"></a>GraalVM 介绍</h2><p><a href="https://www.graalvm.org/">GraalVM</a> 是一个高性能的 JDK，旨在加速用 Java 和其他 JVM 语言编写的应用程序的执行，同时还提供 JavaScript、Python 和许多其他流行语言的运行时。GraalVM 提供了两种运行 Java 应用程序的方式：</p><ul><li><code>第一种运行方式</code>：在 HotSpot JVM 上使用 Graal 即时编译器（JIT）</li><li><code>第二种运行方式</code>：作为预先编译（AOT）的本机可执行文件运行（原生镜像）</li></ul><blockquote><p>值得一提的是，GraalVM 的多语言能力使得在单个应用程序中混合多种编程语言成为可能，同时消除了外部语言调用的成本。</p></blockquote><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p><img data-src="../../../asset/2023/08/spring-boot3-study-58.png"></p><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>GraalVM 跨平台提供原生镜像的原理如下图所示：</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-59.png"></p><h3 id="特别说明"><a href="#特别说明" class="headerlink" title="特别说明"></a>特别说明</h3><p>目前并不是所有 Java 代码都支持直接使用 GraalVm 编译成原生镜像（二进制可执行文件），具体存在的兼容问题如下：</p><ul><li><p>动态能力损失：</p><ul><li>问题描述：GraalVM 不支持直接编译反射代码，包括动态获取构造器、反射创建对象、反射调用等</li><li>解决方案：额外使用 SpringBoot 提供的一些注解，提前告知 GraalVm 反射会用到哪些构造器、方法等</li></ul></li><li><p>配置文件损失：</p><ul><li>问题描述：以二进制可执行文件的方式运行 Java 应用，项目内原有的配置文件会失效</li><li>解决方案：额外处理（如使用配置中心、使用配置文件的相对路径等），提前告知 GraalVM 配置文件怎么处理</li></ul></li></ul><blockquote><p>值得一提的是，SpringBoot 可以保证 Spring 应用都能在使用 AOT 特性的时候，提前告知 GraalVm 怎么处理，但并不是所有框架都适配了 AOT 特性，尤其是第三方框架。</p></blockquote><h2 id="Linux-平台-编译原生镜像"><a href="#Linux-平台-编译原生镜像" class="headerlink" title="Linux 平台 编译原生镜像"></a>Linux 平台 编译原生镜像</h2><p>在 Linux 平台，使用 GraalVM 编译原生镜像，需要提前安装 GCC 和 GraalVM。</p><h3 id="GCC-安装"><a href="#GCC-安装" class="headerlink" title="GCC 安装"></a>GCC 安装</h3><p>安装 GCC/G++ 的目的是为了可以编译 C/C++ 代码。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gcc gcc-c++ glibc-devel kernel-devel zlib-devel</span><br></pre></td></tr></tbody></table></figure><h3 id="Graalvm-安装"><a href="#Graalvm-安装" class="headerlink" title="Graalvm 安装"></a>Graalvm 安装</h3><h4 id="下载软件"><a href="#下载软件" class="headerlink" title="下载软件"></a>下载软件</h4><p>根据开发平台和 JDK 版本，在 <a href="https://github.com/graalvm/graalvm-ce-builds/releases/">GraalVM GitHub Releases</a> 页面上下载 GraalVM 与 Native Image 的软件包（如下图）。值得一提的是，GraalVM 有两种版本，分别是社区版和商业版，开发环境一般使用社区版即可。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-70.png"></p><p><img data-src="../../../asset/2023/08/spring-boot3-study-71.png"></p><h4 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h4><p>解压 GraalVM 的软件包（如 <code>graalvm-ce-java17-linux-amd64-22.3.3.tar.gz</code>），然后添加或更改系统环境变量 <code>JAVA_HOME</code> 与 <code>Path</code>，其中 <code>JAVA_HOME</code> 指向 GraalVM 的解压目录，<code>PATH</code> 则指向 GraalVM 的 <code>bin</code> 目录路径。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line">tar -zxvf graalvm-ce-java17-linux-amd64-22.3.2.tar.gz -C /opt/java/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/java/graalvm-ce-java17-22.3.2</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使环境变量生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></tbody></table></figure><p>在命令行终端输入 <code>java -version</code> 命令，验证 JDK 环境是否为 GraalVM 提供的。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-72.png"></p><div class="admonition note"><p class="admonition-title">提示</p><p>上述配置 GraalVM 环境变量的方式，与平时配置 OpenJDK 或者 Oracle JDK 的环境变量并没有任何区别。</p></div><h4 id="安装工具"><a href="#安装工具" class="headerlink" title="安装工具"></a>安装工具</h4><p>安装 Native Image 工具，用于编译生成原生镜像，安装方式分为在线安装和离线安装两种，如下所示：</p><ul><li>网络环境好，可以选择在线安装 Native Image</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gu install native-image</span><br></pre></td></tr></tbody></table></figure><ul><li>网络环境不好，可以使用上面下载好的 Native Image Jar 包（如 <code>native-image-installable-xxxx.jar</code>）进行离线安装 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gu install --file native-image-installable-svm-java17-linux-amd64-22.3.3.jar</span><br></pre></td></tr></tbody></table></figure><ul><li>验证工具的安装结果 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">native-image --<span class="built_in">help</span></span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>更多关于 Native Image 的安装说明，可以参考 <a href="https://www.graalvm.org/latest/reference-manual/native-image/">GraalVM 官方文档</a>。</p></div><h3 id="编译原生镜像"><a href="#编译原生镜像" class="headerlink" title="编译原生镜像"></a>编译原生镜像</h3><p>本章节完整的案例代码可以直接从 <a href="https://github.com/rqh656418510/spring-cloud-share/tree/main/spring-boot-3/spring-boot-3-study">GitHub</a> 下载对应章节 <code>spring-boot3-18</code>。</p><h4 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h4><p>创建普通 Maven 项目，编写 <code>Main</code> 主类</p><ul><li>使用 <code>mvn clean package</code> 命令进行打包</li><li>使用 <code>java -jar xxx.jar</code> 命令确认 Jar 包是否可以执行</li><li>若 Jar 包不能正常执行，则需要通过 Maven 插件指定主类的全类名，如下所示：</li></ul><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-jar-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.clay.MainApplication<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h4 id="编译镜像"><a href="#编译镜像" class="headerlink" title="编译镜像"></a>编译镜像</h4><p>在命令行终端使用 <code>native-image</code> 工具编译原生镜像（二进制可执行文件），如下所示：</p><ul><li>第一种编译方式 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只编译某个类，该类必须有 main 方法，否则无法编译（下面的 classes 目录一般是在 Maven 项目编译生成的 target 目录下）</span></span><br><span class="line">native-image -cp classes com.clay.boot.MainApplication -o graalvm-demo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行生成的原生镜像（二进制可执行文件）</span></span><br><span class="line">./graalvm-demo</span><br></pre></td></tr></tbody></table></figure><ul><li>第二种编译方式 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从主类开始，编译整个 Jar 包（下面的 Jar 包一般是在 Maven 项目编译生成的 target 目录下）</span></span><br><span class="line">native-image -cp spring-boot3-18-1.0.jar com.clay.boot.MainApplication -o spring-boot3-18</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行生成的原生镜像（二进制可执行文件）</span></span><br><span class="line">./spring-boot3-18</span><br></pre></td></tr></tbody></table></figure><h2 id="Windows-平台-编译原生镜像"><a href="#Windows-平台-编译原生镜像" class="headerlink" title="Windows 平台 编译原生镜像"></a>Windows 平台 编译原生镜像</h2><p>在 Windows 平台，使用 GraalVM 编译原生镜像，需要提前安装 GraalVM 和 Visual Studio。</p><h3 id="GraalVM-安装"><a href="#GraalVM-安装" class="headerlink" title="GraalVM 安装"></a>GraalVM 安装</h3><h4 id="下载软件-1"><a href="#下载软件-1" class="headerlink" title="下载软件"></a>下载软件</h4><p>根据开发平台和 JDK 版本，在 <a href="https://github.com/graalvm/graalvm-ce-builds/releases/">GraalVM GitHub Releases</a> 页面上下载 GraalVM 与 Native Image 的软件包（如下图）。值得一提的是，GraalVM 有两种版本，分别是社区版和商业版，开发环境一般使用社区版即可。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-65.png"></p><p><img data-src="../../../asset/2023/08/spring-boot3-study-64.png"></p><h4 id="配置环境-1"><a href="#配置环境-1" class="headerlink" title="配置环境"></a>配置环境</h4><p>解压 GraalVM 的软件包（如 <code>graalvm-ce-java17-windows-amd64-22.3.3.zip</code>），然后添加或更改系统环境变量 <code>JAVA_HOME</code> 与 <code>Path</code>，其中 <code>JAVA_HOME</code> 指向 GraalVM 的解压目录，<code>PATH</code> 则指向 GraalVM 的 <code>bin</code> 目录路径。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-68.png"></p><p><img data-src="../../../asset/2023/08/spring-boot3-study-69.png"></p><p>在 CMD 窗口输入 <code>java -version</code> 命令，验证 JDK 环境是否为 GraalVM 提供的。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-66.png"></p><div class="admonition note"><p class="admonition-title">提示</p><p>上述配置 GraalVM 环境变量的方式，与平时配置 OpenJDK 或者 Oracle JDK 的环境变量并没有任何区别。</p></div><h4 id="安装工具-1"><a href="#安装工具-1" class="headerlink" title="安装工具"></a>安装工具</h4><p>安装 Native Image 工具，用于编译生成原生镜像，安装方式分为在线安装和离线安装两种，如下所示：</p><ul><li>网络环境好，可以选择在线安装 Native Image</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gu install native-image</span><br></pre></td></tr></tbody></table></figure><ul><li>网络环境不好，可以使用上面下载好的 Native Image Jar 包（如 <code>native-image-installable-xxxx.jar</code>）进行离线安装 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gu install --file native-image-installable-svm-java17-windows-amd64-22.3.3.jar</span><br></pre></td></tr></tbody></table></figure><ul><li>验证工具的安装结果 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">native-image --<span class="built_in">help</span></span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>更多关于 Native Image 的安装说明，可以参考 <a href="https://www.graalvm.org/latest/reference-manual/native-image/">GraalVM 官方文档</a>。</p></div><h3 id="Visual-Studio-安装"><a href="#Visual-Studio-安装" class="headerlink" title="Visual Studio 安装"></a>Visual Studio 安装</h3><p>安装 Visual Studio 的目的是为了使用 VS 提供的工具链编译 C/C++ 代码。值得一提的是，可以使用 MinGW、Cygwin 等编译工具替代 Visual Studio。</p><h4 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h4><div class="admonition note"><p class="admonition-title">Visual Studio 安装教程</p><ul><li>Visual Studio <a href="/posts/71979ec9.html">在线安装教程</a></li><li> Visual Studio <a href="/posts/f201bf82.html">离线安装教程</a></li></ul></div><p>在 Visual Studio 安装时，一般选择安装 <code>Microsoft.VisualStudio.Workload.NativeDesktop</code>、<code>Microsoft.VisualStudio.Workload.Universal</code> 这两大组件即可，分别对应下图红框内的组件。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-60.png"></p><p>语言包必须选择 <code>英语</code>，不能选择中文，否则在 GraalVM 编译原生镜像时，可能会出现各种莫名奇妙的问题。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-61.png"></p><p>安装步骤完成后，如果使用管理员身份可以正常运行 <code>x64 Native Tools Command Prompt for VS 20xx</code> 工具，则说明 Visual Studio 安装成功。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-62.png"></p><h3 id="编译原生镜像-1"><a href="#编译原生镜像-1" class="headerlink" title="编译原生镜像"></a>编译原生镜像</h3><p>本章节完整的案例代码可以直接从 <a href="https://github.com/rqh656418510/spring-cloud-share/tree/main/spring-boot-3/spring-boot-3-study">GitHub</a> 下载对应章节 <code>spring-boot3-18</code>。</p><h4 id="创建项目-1"><a href="#创建项目-1" class="headerlink" title="创建项目"></a>创建项目</h4><p>创建普通 Maven 项目，编写 <code>Main</code> 主类</p><ul><li>使用 <code>mvn clean package</code> 命令进行打包</li><li>使用 <code>java -jar xxx.jar</code> 命令确认 Jar 包是否可以执行</li><li>若 Jar 包不能正常执行，则需要通过 Maven 插件指定主类的全类名，如下所示：</li></ul><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-jar-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.clay.MainApplication<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h4 id="编译镜像-1"><a href="#编译镜像-1" class="headerlink" title="编译镜像"></a>编译镜像</h4><p>运行 Visual Studio 的 <code>x64 Native Tools Command Prompt for VS 20xx</code> 工具，使用 <code>native-image</code> 工具编译原生镜像（二进制可执行文件），如下所示：</p><ul><li>第一种编译方式 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只编译某个类，该类必须有 main 方法，否则无法编译（下面的 classes 目录一般是在 Maven 项目编译生成的 target 目录下）</span></span><br><span class="line">native-image -cp classes com.clay.boot.MainApplication -o graalvm-demo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行生成的原生镜像（二进制可执行文件）</span></span><br><span class="line">./graalvm-demo.exe</span><br></pre></td></tr></tbody></table></figure><ul><li>第二种编译方式 </li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从主类开始，编译整个 Jar 包（下面的 Jar 包一般是在 Maven 项目编译生成的 target 目录下）</span></span><br><span class="line">native-image -cp spring-boot3-18-1.0.jar com.clay.boot.MainApplication -o spring-boot3-18</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行生成的原生镜像（二进制可执行文件）</span></span><br><span class="line">./spring-boot3-18.exe</span><br></pre></td></tr></tbody></table></figure><h2 id="SpringBoot-编译原生镜像"><a href="#SpringBoot-编译原生镜像" class="headerlink" title="SpringBoot 编译原生镜像"></a>SpringBoot 编译原生镜像</h2><p>这里将演示 SpringBoot 项目如何使用 GraaVM 编译生成原生镜像，本章节完整的案例代码可以直接从 <a href="https://github.com/rqh656418510/spring-cloud-share/tree/main/spring-boot-3/spring-boot-3-study">GitHub</a> 下载对应章节 <code>spring-boot3-19</code>。</p><div class="admonition warning"><p class="admonition-title">特别注意</p><p>在执行以下步骤之前，必须确保在 Windows/Linux 平台配置好了 GraalVM 编译所需要的环境，包括 GraalVM 安装、Visual Studio 安装或者 GCC 安装等。</p></div><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><ul><li>添加 GraalVM 编译插件和 SpringBoot 打包插件的依赖 </li></ul><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.graalvm.buildtools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>native-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h3 id="编译镜像-2"><a href="#编译镜像-2" class="headerlink" title="编译镜像"></a>编译镜像</h3><ul><li>第一步：运行 Maven 的打包命令 <code>mvn clean package</code></li></ul><p><img data-src="../../../asset/2023/08/spring-boot3-study-77.png"></p><ul><li>第二步：运行 AOT 的提前处理命令 <code>mvn spring-boot:process-aot</code></li></ul><p><img data-src="../../../asset/2023/08/spring-boot3-study-75.png"></p><ul><li>第三步：运行 Native Image 的编译命令 <code>mvn -Pnative native:build</code>，其中的 <code>-Pnative</code> 表示激活 <code>native</code> 环境的 Profile 配置文件，建议都带上这参数进行编译</li></ul><p><img data-src="../../../asset/2023/08/spring-boot3-study-76.png"></p><h3 id="启动镜像"><a href="#启动镜像" class="headerlink" title="启动镜像"></a>启动镜像</h3><p>SpringBoot 应用成功编译原生镜像后，在项目的 <code>target</code> 目录下，可以看到编译生成的原生镜像（二进制可执行文件）。</p><p><img data-src="../../../asset/2023/08/spring-boot3-study-78.png"></p><p>在项目的 <code>target</code> 目录下，直接运行 <code>./spring-boot3-19.exe</code> 就可以快速启动镜像，观察可以发现应用的整个启动过程仅仅耗费 0.137 秒。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">  .   ____          _            __ _ _</span><br><span class="line"> /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \</span><br><span class="line">( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \</span><br><span class="line"> \\/  ___)| |_)| | | | | || (_| |  ) ) ) )</span><br><span class="line">  '  |____| .__|_| |_|_| |_\__, | / / / /</span><br><span class="line"> =========|_|==============|___/=/_/_/_/</span><br><span class="line"> :: Spring Boot ::                (v3.0.5)</span><br><span class="line"></span><br><span class="line">2023-08-30T22:03:53.297+08:00  INFO 41976 --- [           main] com.clay.boot.MainApplication            : Starting AOT-processed MainApplication using Java 17.0.8 with PID 41976</span><br><span class="line">2023-08-30T22:03:53.298+08:00  INFO 41976 --- [           main] com.clay.boot.MainApplication            : No active profile set, falling back to 1 default profile: "default"</span><br><span class="line">2023-08-30T22:03:53.339+08:00  INFO 41976 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)</span><br><span class="line">2023-08-30T22:03:53.342+08:00  INFO 41976 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]</span><br><span class="line">2023-08-30T22:03:53.342+08:00  INFO 41976 --- [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.7]</span><br><span class="line">2023-08-30T22:03:53.357+08:00  INFO 41976 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext</span><br><span class="line">2023-08-30T22:03:53.357+08:00  INFO 41976 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 59 ms</span><br><span class="line">2023-08-30T22:03:53.400+08:00  INFO 41976 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''</span><br><span class="line">2023-08-30T22:03:53.401+08:00  INFO 41976 --- [           main] com.clay.boot.MainApplication            : Started MainApplication in 0.137 seconds (process running for 0.15)</span><br></pre></td></tr></tbody></table></figure><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="Windows-平台"><a href="#Windows-平台" class="headerlink" title="Windows 平台"></a>Windows 平台</h3><h4 id="编译原生镜像失败"><a href="#编译原生镜像失败" class="headerlink" title="编译原生镜像失败"></a>编译原生镜像失败</h4><blockquote><p>问题描述：GraalVM 编译生成原生镜像时，可能出现如下各种错误</p></blockquote><ul><li>出现乱码</li><li>出现 <code>cl.exe</code> 找不到错误</li><li>提示 <code>no include path set</code></li><li>提示 <code>fatal error LNK1104: cannot open file 'LIBCMT.lib'</code></li><li>提示 <code>LINK : fatal error LNK1104: cannot open file 'kernel32.lib'</code></li><li>提示各种其他找不到的内容</li></ul><blockquote><p>解决方案：修改三个环境变量：<code>Path</code>、<code>INCLUDE</code>、<code>lib</code>，<strong>请自行根据 Visual Studio 的实际安装路径来更改环境变量的值</strong></p></blockquote><ul><li><code>PATH</code> 环境变量添加如下值：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.33.31629\bin\Hostx64\x64</span><br></pre></td></tr></tbody></table></figure><ul><li>新建 <code>INCLUDE</code> 环境变量，值为：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.33.31629\include;C:\Program Files (x86)\Windows Kits\10\Include\10.0.19041.0\shared;C:\Program Files (x86)\Windows Kits\10\Include\10.0.19041.0\ucrt;C:\Program Files (x86)\Windows Kits\10\Include\10.0.19041.0\um;C:\Program Files (x86)\Windows Kits\10\Include\10.0.19041.0\winrt</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/08/spring-boot3-study-74.png"></p><ul><li>新建 <code>lib</code> 环境变量，值为：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.33.31629\lib\x64;C:\Program Files (x86)\Windows Kits\10\Lib\10.0.19041.0\um\x64;C:\Program Files (x86)\Windows Kits\10\Lib\10.0.19041.0\ucrt\x64</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/08/spring-boot3-study-73.png"></p>]]></content>
    
    
    <summary type="html">本文主要介绍 SpringBoot 3 如何使用 AOT 技术，包括 Windows 和 Linux 平台使用 GraalVM 编译原生镜像。</summary>
    
    
    
    
    <category term="微服务" scheme="https://www.techgrow.cn/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Git &amp; GitHub 开发随笔</title>
    <link href="https://www.techgrow.cn/posts/d09e2a40.html"/>
    <id>https://www.techgrow.cn/posts/d09e2a40.html</id>
    <published>2023-08-22T15:12:43.000Z</published>
    <updated>2023-08-22T15:12:43.000Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="Emoji"><a href="#Emoji" class="headerlink" title="Emoji"></a>Emoji</h2><h3 id="Emoji-使用说明"><a href="#Emoji-使用说明" class="headerlink" title="Emoji 使用说明"></a>Emoji 使用说明</h3><p>不经意发现在大神的 GitHub 项目上，Git 的提交信息竟然有 Emoji 前缀，相当鹤立鸡群、别具一格，感觉挺有趣的。个人认为这样做有三点好处，后两点尤为重要：</p><ul><li>Emoji 比较呆萌，能美化提交记录和 GitHub 页面；</li><li>Emoji 作为标签，能很好的对提交记录分门别类，方便整理；</li><li>Emoji 蕴含的丰富语义和情绪，能提高提交信息的可读性、可理解性，增强提交历史的阅读体验；</li></ul><span id="more"></span><p><img data-src="../../../asset/2023/08/git-notes-1.png"></p><p>Emoji 的用法很简单，在 <code>git commit</code> 时如下书写提交信息，用 <code>:smile:</code> 即可插入一个笑脸 Emoji：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -am <span class="string">':smile: 重构代码'</span></span><br></pre></td></tr></tbody></table></figure><p>Emoji 除了可以在 Git 提交时使用，还可以在 README.md 、GitHub Issues 和 GitHub Wiki 中直接使用 Emoji。这里整理出常用的 Emoji 列表：</p><p><img data-src="../../../asset/2023/08/git-emoji.png"></p><h3 id="Emoji-资源整理"><a href="#Emoji-资源整理" class="headerlink" title="Emoji 资源整理"></a>Emoji 资源整理</h3><ul><li><a href="https://gitmoji.dev/">Git Emoji 指南</a></li><li><a href="https://www.cnblogs.com/trigger-cn/p/16976232.html">Git Emoji 表情合集</a></li></ul>]]></content>
    
    
    <summary type="html">本文主要介绍 Git、GitHub 日常使用的笔记。</summary>
    
    
    
    <category term="hide" scheme="https://www.techgrow.cn/categories/hide/"/>
    
    
    <category term="版本控制" scheme="https://www.techgrow.cn/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"/>
    
    <category term="开发随笔" scheme="https://www.techgrow.cn/tags/%E5%BC%80%E5%8F%91%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
</feed>
