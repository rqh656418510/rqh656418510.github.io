<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CRoboto+Slab:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic&amp;display=swap&amp;subset=latin,latin-ext"><link rel="stylesheet" href="/lib/@fortawesome/fontawesome-free/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/animate.css/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/pace-js/themes/blue/pace-theme-minimal.css"><script src="/lib/pace-js/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.techgrow.cn","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script><meta name="description" content="本文主要介绍 Kafka 的使用教程。"><meta property="og:type" content="article"><meta property="og:title" content="Kafka 入门教程之七"><meta property="og:url" content="https://www.techgrow.cn/posts/50c7d080.html"><meta property="og:site_name" content="Clay 的技术空间"><meta property="og:description" content="本文主要介绍 Kafka 的使用教程。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-kraft-1.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-code-1.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-code-2.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-code-3.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-code-4.png"><meta property="article:published_time" content="2022-09-23T14:13:45.000Z"><meta property="article:modified_time" content="2022-09-23T14:13:45.000Z"><meta property="article:author" content="Clay"><meta property="article:tag" content="微服务"><meta property="article:tag" content="分布式"><meta property="article:tag" content="消息队列"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.techgrow.cn/asset/2024/12/kafka-kraft-1.png"><link rel="canonical" href="https://www.techgrow.cn/posts/50c7d080.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.techgrow.cn/posts/50c7d080.html","path":"posts/50c7d080.html","title":"Kafka 入门教程之七"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Kafka 入门教程之七 | Clay 的技术空间</title><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-135294383-1"></script><script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-135294383-1","only_pageview":false,"measure_protocol_api_secret":null}</script><script src="/js/third-party/analytics/google-analytics.js"></script><script class="next-config" data-name="baidu_analytics" type="application/json">"84c09b30349a65573c5c642ff336969b"</script><script src="/js/third-party/analytics/baidu-analytics.js"></script><link rel="dns-prefetch" href="https://waline.techgrow.cn"><link rel="stylesheet" type="text/css" href="/css/injector/main.css"><link rel="preload" as="style" href="/css/injector/light.css"><link rel="preload" as="style" href="/css/injector/dark.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><style>.admonition{margin:1.5625em 0;padding:.6rem;overflow:hidden;font-size:.64rem;page-break-inside:avoid;border-left:.3rem solid #42b983;border-radius:.3rem;box-shadow:0 .1rem .4rem rgba(0,0,0,.05),0 0 .05rem rgba(0,0,0,.1);background-color:#fafafa}p.admonition-title{position:relative;margin:-.6rem -.6rem .8em -.6rem!important;padding:.4rem .6rem .4rem 2.5rem;font-weight:700;background-color:rgba(66,185,131,.1)}.admonition-title::before{position:absolute;top:.9rem;left:1rem;width:12px;height:12px;background-color:#42b983;border-radius:50%;content:' '}.info>.admonition-title,.todo>.admonition-title{background-color:rgba(0,184,212,.1)}.attention>.admonition-title,.caution>.admonition-title,.warning>.admonition-title{background-color:rgba(255,145,0,.1)}.error>.admonition-title,.fail>.admonition-title,.failure>.admonition-title,.missing>.admonition-title{background-color:rgba(255,82,82,.1)}.admonition.info,.admonition.todo{border-color:#00b8d4}.admonition.attention,.admonition.caution,.admonition.warning{border-color:#ff9100}.admonition.error,.admonition.fail,.admonition.failure,.admonition.missing{border-color:#ff5252}.info>.admonition-title::before,.todo>.admonition-title::before{background-color:#00b8d4;border-radius:50%}.attention>.admonition-title::before,.caution>.admonition-title::before,.warning>.admonition-title::before{background-color:#ff9100;border-radius:50%}.error>.admonition-title::before,.fail>.admonition-title::before,.failure>.admonition-title::before,.missing>.admonition-title::before{background-color:#ff5252;border-radius:50%}.admonition>:last-child{margin-bottom:0!important}</style><link rel="alternate" href="/atom.xml" title="Clay 的技术空间" type="application/atom+xml"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope="" itemtype="http://schema.org/WebPage" class="use-motion"><script src="/lib/jquery/dist/jquery.min.js"></script><script data-pjax="">!function(){var t=window.location.host;if(-1==t.indexOf("127.0.0.1")&&-1==t.indexOf("localhost")){var o=document.createElement("script"),e=window.location.protocol.split(":")[0];o.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(o,n)}}()</script><link rel="stylesheet" href="/lib/aplayer/dist/APlayer.min.css"><div id="aplayer" style="display:none"></div><script src="/lib/aplayer/dist/APlayer.min.js"></script><script src="/lib/aplayer/dist/color-thief.js"></script><script src="/lib/aplayer-init.js"></script><script src="https://res.wx.qq.com/open/js/jweixin-1.4.0.js"></script><script>function getTitle(){var t=jQuery("meta[property='og:title']");return t?t.attr("content"):""}function getDesc(){var t=jQuery("meta[property='og:description']");return t?t.attr("content"):""}function randomString(t){for(var e="ABCDEFGHJKMNPQRSTWXYZabcdefhijkmnprstwxyz2345678",n=e.length,i="",r=0;r<t;++r)i+=e.charAt(Math.floor(Math.random()*n));return i}function initWx(t){wx.config({debug:!1,appId:t.appId,nonceStr:t.nonceStr,signature:t.signature,timestamp:t.timestamp,jsApiList:["checkJsApi","onMenuShareTimeline","onMenuShareAppMessage","onMenuShareQQ"]}),wx.ready(function(){wx.onMenuShareTimeline({title:t.title,link:t.link,imgUrl:t.imgUrl,success:function(){}}),wx.onMenuShareAppMessage({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,type:"link",dataUrl:"",success:function(){}}),wx.onMenuShareQQ({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,success:function(){},cancel:function(){}})}),wx.error(function(t){})}jQuery(function(){var e=getDesc(),n=getTitle(),i=randomString(16),r=(new Date).getTime(),a=window.location.href,t="https://open.techgrow.cn/app/api/wechat/js/signature?url="+a+"&noncestr="+i+"&timestamp="+r;jQuery.getJSON(t,function(t){initWx({desc:e,title:n,link:a,nonceStr:i,timestamp:r,signature:t.data,appId:"wx1fcf69355af43d41",imgUrl:"https://www.techgrow.cn/img/wx_share.jpg"})})})</script><div style="display:none"><img src="https://www.techgrow.cn/img/wx_share.jpg" alt=""></div><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">Clay 的技术空间</p><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">用进废退 | 艺不压身</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-search"><a href="/search" rel="section"><i class="fa fa-search fa-fw"></i>搜索</a></li><li class="menu-item menu-item-links"><a href="/links" rel="section"><i class="fas fa-link fa-fw"></i>友链</a></li><li class="menu-item menu-item-readingnotes"><a href="https://www.techgrow.cn/reading/" rel="section"><i class="fa fa-book-open-reader fa-fw"></i>读书笔记</a></li><li class="menu-item menu-item-commentmanage"><a href="https://waline.techgrow.cn/" rel="external nofollow" target="_blank"><i class="fa fa-comment fa-fw"></i>评论管理</a></li></ul></nav></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E7%BA%B2"><span class="nav-text">大纲</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-text">前言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90"><span class="nav-text">学习资源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-KRaft-%E6%A8%A1%E5%BC%8F"><span class="nav-text">Kafka-KRaft 模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#KRaft-%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="nav-text">KRaft 模式的概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KRaft-%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-text">KRaft 模式的优势</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E9%80%89%E4%B8%BE%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">Kafka 选举的概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ZooKeeper-%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E9%80%89%E4%B8%BE"><span class="nav-text">ZooKeeper 模式下的选举</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KRaft-%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E9%80%89%E4%B8%BE"><span class="nav-text">KRaft 模式下的选举</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E5%BA%95%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-text">Kafka 底层源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-text">生产者源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">生产者的工作原理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="nav-text">发送消息的流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Main-%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-text">Main 线程的初始化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Sender-%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-text">Sender 线程的初始化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%88%B0%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="nav-text">发送数据到缓冲区</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-text">生产者的源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Main-%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96-1"><span class="nav-text">Main 线程的初始化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Sender-%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96-1"><span class="nav-text">Sender 线程的初始化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%88%B0%E7%BC%93%E5%86%B2%E5%8C%BA-1"><span class="nav-text">发送数据到缓冲区</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="nav-text">发送总体流程</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%9A%84%E9%80%89%E6%8B%A9"><span class="nav-text">分区的选择</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope="" itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="Clay" src="/img/head.jpg"></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"> <span class="site-state-item-count">615</span> <span class="site-state-item-name">文章</span></div><div class="site-state-item site-state-tags"> <span class="site-state-item-count">52</span> <span class="site-state-item-name">标签</span></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/rqh656418510" title="GitHub → https://github.com/rqh656418510" rel="external nofollow" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:rong656418510@gmail.com" title="E-Mail → mailto:rong656418510@gmail.com" rel="external nofollow" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="/atom.xml" title="RSS → /atom.xml" rel="noopener me"><i class="fa fa-rss fa-fw"></i> RSS</a></span><span class="links-of-author-item"><a href="/sitemap.xml" title="SiteMap → /sitemap.xml" rel="noopener me"><i class="fa fa-sitemap fa-fw"></i> SiteMap</a></span></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope="" itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.techgrow.cn/posts/50c7d080.html"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="image" content="/img/head.jpg"><meta itemprop="name" content="Clay"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Clay 的技术空间"><meta itemprop="description" content="专注于 Java 后端、分布式、微服务、云原生、数据库、系统架构、大数据、云计算、虚拟化、人工智能学习的技术博客。"></span><span hidden="" itemprop="post" itemscope="" itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Kafka 入门教程之七 | Clay 的技术空间"><meta itemprop="description" content="本文主要介绍 Kafka 的使用教程。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Kafka 入门教程之七</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-09-23 22:13:45" itemprop="dateCreated datePublished" datetime="2022-09-23T22:13:45+08:00">2022-09-23</time></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i></span> <span class="post-meta-item-text">评论数：</span><a title="waline" href="/posts/50c7d080.html#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/50c7d080.html" itemprop="commentCount"></span></a></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>3k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 ≈</span> <span>3 分钟</span></span></div></div></header><div class="post-body post-container" itemprop="articleBody" id="readmore-container"><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/b6be8183.html">Kafka 入门教程之一</a>、<a href="/posts/60ddcede.html">Kafka 入门教程之二</a>、<a href="/posts/228158d3.html">Kafka 入门教程之三</a></li><li><a href="/posts/c61757ff.html">Kafka 入门教程之四</a>、<a href="/posts/ed9d5bd.html">Kafka 入门教程之五</a>、<a href="/posts/e73bffc6.html">Kafka 入门教程之六</a></li><li><a href="/posts/50c7d080.html">Kafka 入门教程之七</a></li></ul><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h3><ul><li><a target="_blank" rel="external nofollow" href="https://kafka.apache.org/documentation/">Kafka 官方文档</a></li><li><a href="/posts/ac64f898.html">Kafka 学习路线</a></li></ul><span id="more"></span><h2 id="Kafka-KRaft-模式"><a href="#Kafka-KRaft-模式" class="headerlink" title="Kafka-KRaft 模式"></a>Kafka-KRaft 模式</h2><h3 id="KRaft-模式的概述"><a href="#KRaft-模式的概述" class="headerlink" title="KRaft 模式的概述"></a>KRaft 模式的概述</h3><p><img data-src="../../../asset/2024/12/kafka-kraft-1.png"></p><ul><li>左图为 Kafka 的 ZooKeeer 模式架构，元数据存储在 Zookeeper 中，运行时会动态选举一个 Broker 节点作为 Controller（唯一），由 Controller 进行 Kafka 集群管理。</li><li>左图为 Kafka 的 KRaft 模式架构，不再依赖 Zookeeper 集群，而是使用多个 Controller 节点来代替 Zookeeper，元数据保存在 Controller 中，由 Controller 直接管理 Kafka 集群。</li></ul><table><thead><tr><th>特性</th><th> ZooKeeper 模式</th><th> KRaft 模式</th></tr></thead><tbody><tr><td> Leader 选举依赖性</td><td>需要 ZooKeeper 提供元数据存储和通知机制</td><td>不依赖 ZooKeeper，完全有 Kafka 自己自行实现</td></tr><tr><td>元数据管理</td><td>由 ZooKeeper 管理</td><td>由 Kafka 自己的 Raft 集群管理</td></tr><tr><td>一致性保障</td><td> ZooKeeper 提供一致性</td><td> Raft 协议保障一致性</td></tr><tr><td>引入版本</td><td> Kafka 早期版本（默认是 ZooKeeper 模式）</td><td>Kafka <code>2.8.0+</code>（KRaft 模式）</td></tr></tbody></table><div class="admonition note"><p class="admonition-title">版本说明</p><p>从 Kafka <code>2.8.0</code> 版本开始，Kafka 自身实现了 Raft 分布式一致性机制，这意味着 Kafka 集群可以脱离 ZooKeeper 独立运行。</p></div><h3 id="KRaft-模式的优势"><a href="#KRaft-模式的优势" class="headerlink" title="KRaft 模式的优势"></a>KRaft 模式的优势</h3><ul><li>Kafka 不再依赖外部服务，而是能够独立运行。</li><li>Controller 管理集群时，不再需要从 Zookeeper 中先读取数据，提高了集群性能。</li><li>由于不依赖 Zookeeper，因此 Kafka 集群扩展时不再受到 Zookeeper 读写能力的限制。</li><li>Controller 节点不再是通过动态选举来决定，而是由配置文件指定，这样开发者可以有针对性地加强。</li><li>Controller 节点支持通过配置来指定，而不是像以前一样对随机 Controller 节点的高负载束手无策。</li></ul><h2 id="Kafka-选举的概念"><a href="#Kafka-选举的概念" class="headerlink" title="Kafka 选举的概念"></a>Kafka 选举的概念</h2><h3 id="ZooKeeper-模式下的选举"><a href="#ZooKeeper-模式下的选举" class="headerlink" title="ZooKeeper 模式下的选举"></a>ZooKeeper 模式下的选举</h3><div class="admonition note"><p class="admonition-title">在 ZooKeeper 模式下，Controller 的责职</p><ul><li>Controller 负责管理和分发 Kafka 集群的元数据信息，例如 Topic、分区和副本的状态。</li><li>Controller 负责管理集群 Broker 的上下线，包括所有 Topic 的分区副本分配和分区副本 Leader 选举等工作。</li><li>当分区的 Leader 副本失效时，Controller 负责触发分区副本的 Leader 选举，并将新的 Leader 信息更新到 ZooKeeper 和其他 Broker。</li></ul></div><ul><li><p>Controller 的选举</p><ul><li>选举机制<ul><li> Kafka 集群的 Controller 是通过 ZooKeeper 进行选举的。</li><li>在 Broker 启动时，每个 Broker 都会尝试在 ZooKeeper 的 <code>/controller</code> 节点上创建一个临时节点。</li><li>成功创建该节点的 Broker 就成为 Controller，其它 Broker 则成为普通 Broker。</li></ul></li><li>触发条件<ul><li>如果当前的 Controller 因故障宕机（例如网络中断），ZooKeeper 会删除该 Controller 所在 Broker 的临时节点，然后触发新的 Controller 选举。</li></ul></li></ul></li><li><p>分区副本的 Leader 选举</p><ul><li>选举机制<ul><li>由 Controller 从 ZooKeeper 获取 ISR 列表，选出新的分区副本 Leader 并更新元数据。</li><li>优先从 ISR 列表中选择健康的副本作为 Leader。</li></ul></li><li>触发条件<ul><li>当分区的 Leader 副本失效（如 Broker 宕机）。</li><li>Controller 检测到 ISR（同步副本列表）发生变化。</li></ul></li><li>更新通知<ul><li>选举完成后，元数据更新至所有 Broker，客户端根据新 Leader 继续读写操作。</li></ul></li></ul></li><li><p>两种选举的区别</p><ul><li>Controller 的选举：由 ZooKeeper 决定，目的是选出集群的管理者。</li><li>分区副本的 Leader 选举：由 Controller 负责发起，目的是为每个分区在 ISR 列表中选出一个新的 Leader 副本。</li></ul></li></ul><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li>在 ZooKeeper 模式下，Kafka 集群中的 Controller 是通过 ZooKeeper 选举产生的，集群中同一时刻只能有一个活跃的 Controller（唯一）。其他 Broker 则处于非 Controller 状态，只处理分区的读写请求。</li><li>在 ZooKeeper 模式下，Kafka 集群中同一时刻只能有一个活跃的 Controller（唯一），这种单点的设计简化了管理，但也增加了 Controller 故障时的切换开销和延迟。</li><li>在 KRaft 模式下，Kafka 使用 Raft 协议来支持运行多个 Quorum Controller 节点，从而提高了可用性和一致性。</li></ul></div><h3 id="KRaft-模式下的选举"><a href="#KRaft-模式下的选举" class="headerlink" title="KRaft 模式下的选举"></a>KRaft 模式下的选举</h3><div class="admonition note"><p class="admonition-title">在 KRaft 模式下，Controller 的责职</p><ul><li>Controller 是负责管理元数据的专用节点。</li><li>Quorum Controller 是一个逻辑角色，可以分布在多个 Kafka Broker 上。</li><li>Quorum Controller 集群是通过 Raft 共识协议来保证元数据的一致性和高可用性的。</li></ul></div><ul><li><p>Controller 的选举</p><ul><li>在 KRaft 模式下，Controller 的选举是通过 Raft 共识算法完成的，而不再依赖 ZooKeeper。</li><li>在多个 Controller 节点中，会有一个被选举为 Leader Controller，负责处理元数据更新和变更请求。</li><li>其他 Controller 节点（Follower Controller）则通过 Raft 协议复制 Leader Controller 的元数据日志。</li></ul></li><li><p>分区副本的 Leader 选举</p><ul><li>Controller 使用 Raft 协议直接管理元数据并选举副本 Leader，无需依赖 ZooKeeper。</li><li>Controller 根据副本状态（如 ISR 列表）决定新的副本 Leader。</li><li>元数据变更后，通过 Raft 协议同步到所有 Quorum Controller 节点，无需依赖 ZooKeeper。</li></ul></li></ul><h2 id="Kafka-底层源码分析"><a href="#Kafka-底层源码分析" class="headerlink" title="Kafka 底层源码分析"></a>Kafka 底层源码分析</h2><div class="admonition note"><p class="admonition-title">提示</p><ul><li>在阅读和调试 Kafka 的源码之前，必须先搭建 Kafka 源码的阅读环境，详细教程请看 <a href="/posts/a2880619.html">这里</a>。</li><li>验证 Kafka 源码阅读成果的两个标志：第一个是能够自行调试源码，第二个是能够在源码上独立开发高阶功能。</li></ul></div><h3 id="生产者源码分析"><a href="#生产者源码分析" class="headerlink" title="生产者源码分析"></a>生产者源码分析</h3><h4 id="生产者的工作原理"><a href="#生产者的工作原理" class="headerlink" title="生产者的工作原理"></a>生产者的工作原理</h4><h5 id="发送消息的流程"><a href="#发送消息的流程" class="headerlink" title="发送消息的流程"></a>发送消息的流程</h5><p><img data-src="../../../asset/2024/12/kafka-code-1.png"></p><h5 id="Main-线程的初始化"><a href="#Main-线程的初始化" class="headerlink" title="Main 线程的初始化"></a>Main 线程的初始化</h5><p><img data-src="../../../asset/2024/12/kafka-code-2.png"></p><h5 id="Sender-线程的初始化"><a href="#Sender-线程的初始化" class="headerlink" title="Sender 线程的初始化"></a>Sender 线程的初始化</h5><p><img data-src="../../../asset/2024/12/kafka-code-3.png"></p><h5 id="发送数据到缓冲区"><a href="#发送数据到缓冲区" class="headerlink" title="发送数据到缓冲区"></a>发送数据到缓冲区</h5><p><img data-src="../../../asset/2024/12/kafka-code-4.png"></p><h4 id="生产者的源码分析"><a href="#生产者的源码分析" class="headerlink" title="生产者的源码分析"></a>生产者的源码分析</h4><h5 id="Main-线程的初始化-1"><a href="#Main-线程的初始化-1" class="headerlink" title="Main 线程的初始化"></a>Main 线程的初始化</h5><p>这里的核心类是 <code>clients</code> 模块下的 <code>org.apache.kafka.clients.producer.KafkaProducer</code> 类，最核心的是 <code>KafkaProducer()</code> 构造方法，如下所示：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line">KafkaProducer(ProducerConfig config,</span><br><span class="line">                Serializer&lt;K&gt; keySerializer,</span><br><span class="line">                Serializer&lt;V&gt; valueSerializer,</span><br><span class="line">                ProducerMetadata metadata,</span><br><span class="line">                KafkaClient kafkaClient,</span><br><span class="line">                ProducerInterceptors&lt;K, V&gt; interceptors,</span><br><span class="line">                Time time) {</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="keyword">this</span>.producerConfig = config;</span><br><span class="line">        <span class="keyword">this</span>.time = time;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取事务 ID</span></span><br><span class="line">        String transactionalId = config.getString(ProducerConfig.TRANSACTIONAL_ID_CONFIG);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取客户端 ID</span></span><br><span class="line">        <span class="keyword">this</span>.clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG);</span><br><span class="line"></span><br><span class="line">        LogContext logContext;</span><br><span class="line">        <span class="keyword">if</span> (transactionalId == <span class="keyword">null</span>)</span><br><span class="line">            logContext = <span class="keyword">new</span> LogContext(String.format(<span class="string">"[Producer clientId=%s] "</span>, clientId));</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            logContext = <span class="keyword">new</span> LogContext(String.format(<span class="string">"[Producer clientId=%s, transactionalId=%s] "</span>, clientId, transactionalId));</span><br><span class="line">        log = logContext.logger(KafkaProducer.class);</span><br><span class="line">        log.trace(<span class="string">"Starting the Kafka producer"</span>);</span><br><span class="line"></span><br><span class="line">        Map&lt;String, String&gt; metricTags = Collections.singletonMap(<span class="string">"client-id"</span>, clientId);</span><br><span class="line">        MetricConfig metricConfig = <span class="keyword">new</span> MetricConfig().samples(config.getInt(ProducerConfig.METRICS_NUM_SAMPLES_CONFIG))</span><br><span class="line">                .timeWindow(config.getLong(ProducerConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG), TimeUnit.MILLISECONDS)</span><br><span class="line">                .recordLevel(Sensor.RecordingLevel.forName(config.getString(ProducerConfig.METRICS_RECORDING_LEVEL_CONFIG)))</span><br><span class="line">                .tags(metricTags);</span><br><span class="line">        List&lt;MetricsReporter&gt; reporters = config.getConfiguredInstances(ProducerConfig.METRIC_REPORTER_CLASSES_CONFIG,</span><br><span class="line">                MetricsReporter.class,</span><br><span class="line">                Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// JMX 监控相关的配置</span></span><br><span class="line">        JmxReporter jmxReporter = <span class="keyword">new</span> JmxReporter();</span><br><span class="line">        jmxReporter.configure(config.originals(Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId)));</span><br><span class="line">        reporters.add(jmxReporter);</span><br><span class="line">        MetricsContext metricsContext = <span class="keyword">new</span> KafkaMetricsContext(JMX_PREFIX,</span><br><span class="line">                config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT_PREFIX));</span><br><span class="line">        <span class="keyword">this</span>.metrics = <span class="keyword">new</span> Metrics(metricConfig, reporters, time, metricsContext);</span><br><span class="line">        <span class="comment">// 分区器的配置</span></span><br><span class="line">        <span class="keyword">this</span>.partitioner = config.getConfiguredInstance(</span><br><span class="line">                ProducerConfig.PARTITIONER_CLASS_CONFIG,</span><br><span class="line">                Partitioner.class,</span><br><span class="line">                Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId));</span><br><span class="line">        <span class="comment">// 重试时间间隔的配置，默认值是 100ms</span></span><br><span class="line">        <span class="keyword">long</span> retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);</span><br><span class="line">        <span class="comment">// 序列化的配置</span></span><br><span class="line">        <span class="keyword">if</span> (keySerializer == <span class="keyword">null</span>) {</span><br><span class="line">            <span class="keyword">this</span>.keySerializer = config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,</span><br><span class="line">                                                                                        Serializer.class);</span><br><span class="line">            <span class="keyword">this</span>.keySerializer.configure(config.originals(Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId)), <span class="keyword">true</span>);</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);</span><br><span class="line">            <span class="keyword">this</span>.keySerializer = keySerializer;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span> (valueSerializer == <span class="keyword">null</span>) {</span><br><span class="line">            <span class="keyword">this</span>.valueSerializer = config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,</span><br><span class="line">                                                                                        Serializer.class);</span><br><span class="line">            <span class="keyword">this</span>.valueSerializer.configure(config.originals(Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId)), <span class="keyword">false</span>);</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);</span><br><span class="line">            <span class="keyword">this</span>.valueSerializer = valueSerializer;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 拦截器的配置</span></span><br><span class="line">        List&lt;ProducerInterceptor&lt;K, V&gt;&gt; interceptorList = (List) config.getConfiguredInstances(</span><br><span class="line">                ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,</span><br><span class="line">                ProducerInterceptor.class,</span><br><span class="line">                Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId));</span><br><span class="line">        <span class="keyword">if</span> (interceptors != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">this</span>.interceptors = interceptors;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">this</span>.interceptors = <span class="keyword">new</span> ProducerInterceptors&lt;&gt;(interceptorList);</span><br><span class="line">        ClusterResourceListeners clusterResourceListeners = configureClusterResourceListeners(keySerializer,</span><br><span class="line">                valueSerializer, interceptorList, reporters);</span><br><span class="line">        <span class="comment">// 生产者发送给 Kafka 的单条消息的最大大小，默认值是 1m</span></span><br><span class="line">        <span class="keyword">this</span>.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);</span><br><span class="line">        <span class="comment">// 缓冲区大小，默认值是 32m</span></span><br><span class="line">        <span class="keyword">this</span>.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG);</span><br><span class="line">        <span class="keyword">this</span>.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.maxBlockTimeMs = config.getLong(ProducerConfig.MAX_BLOCK_MS_CONFIG);</span><br><span class="line">        <span class="keyword">int</span> deliveryTimeoutMs = configureDeliveryTimeout(config, log);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.apiVersions = <span class="keyword">new</span> ApiVersions();</span><br><span class="line">        <span class="keyword">this</span>.transactionManager = configureTransactionState(config, logContext);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 初始化 RecordAccumulator 缓冲区</span></span><br><span class="line">        <span class="comment">// batch.size，默认值是 16k</span></span><br><span class="line">        <span class="comment">// compression.type，默认值是 none</span></span><br><span class="line">        <span class="comment">// linger.ms，默认值是 0</span></span><br><span class="line">        <span class="comment">// retry.backoff.ms，默认值是 100ms</span></span><br><span class="line">        <span class="comment">// delivery.timeout.ms，默认值是 2 分钟</span></span><br><span class="line">        <span class="comment">// request.timeout.ms，默认值是 30s</span></span><br><span class="line">        <span class="keyword">this</span>.accumulator = <span class="keyword">new</span> RecordAccumulator(logContext,</span><br><span class="line">                config.getInt(ProducerConfig.BATCH_SIZE_CONFIG),</span><br><span class="line">                <span class="keyword">this</span>.compressionType,</span><br><span class="line">                lingerMs(config),</span><br><span class="line">                retryBackoffMs,</span><br><span class="line">                deliveryTimeoutMs,</span><br><span class="line">                metrics,</span><br><span class="line">                PRODUCER_METRIC_GROUP_NAME,</span><br><span class="line">                time,</span><br><span class="line">                apiVersions,</span><br><span class="line">                transactionManager,</span><br><span class="line">                <span class="keyword">new</span> BufferPool(<span class="keyword">this</span>.totalMemorySize, config.getInt(ProducerConfig.BATCH_SIZE_CONFIG), metrics, time, PRODUCER_METRIC_GROUP_NAME));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ZooKeeper 集群地址</span></span><br><span class="line">        List&lt;InetSocketAddress&gt; addresses = ClientUtils.parseAndValidateAddresses(</span><br><span class="line">                config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG),</span><br><span class="line">                config.getString(ProducerConfig.CLIENT_DNS_LOOKUP_CONFIG));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 获取元数据</span></span><br><span class="line">        <span class="keyword">if</span> (metadata != <span class="keyword">null</span>) {</span><br><span class="line">            <span class="keyword">this</span>.metadata = metadata;</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="keyword">this</span>.metadata = <span class="keyword">new</span> ProducerMetadata(retryBackoffMs,</span><br><span class="line">                    <span class="comment">// metadata.max.age.ms，生产者每隔多久需要更新一次元数据，默认值是 5 分钟</span></span><br><span class="line">                    config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG),</span><br><span class="line">                    <span class="comment">// metadata.max.idle.ms，网络最大空闲时间设置，超过该阈值，就关闭该网络，默认值是 5 分钟</span></span><br><span class="line">                    config.getLong(ProducerConfig.METADATA_MAX_IDLE_CONFIG),</span><br><span class="line">                    logContext,</span><br><span class="line">                    clusterResourceListeners,</span><br><span class="line">                    Time.SYSTEM);</span><br><span class="line">            <span class="keyword">this</span>.metadata.bootstrap(addresses);</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">this</span>.errors = <span class="keyword">this</span>.metrics.sensor(<span class="string">"errors"</span>);</span><br><span class="line">        <span class="comment">// 初始化 Sender 线程</span></span><br><span class="line">        <span class="keyword">this</span>.sender = newSender(logContext, kafkaClient, <span class="keyword">this</span>.metadata);</span><br><span class="line">        String ioThreadName = NETWORK_THREAD_PREFIX + <span class="string">" | "</span> + clientId;</span><br><span class="line">        <span class="keyword">this</span>.ioThread = <span class="keyword">new</span> KafkaThread(ioThreadName, <span class="keyword">this</span>.sender, <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// 启动 Sender 线程</span></span><br><span class="line">        <span class="keyword">this</span>.ioThread.start();</span><br><span class="line">        config.logUnused();</span><br><span class="line">        AppInfoParser.registerAppInfo(JMX_PREFIX, clientId, metrics, time.milliseconds());</span><br><span class="line">        log.debug(<span class="string">"Kafka producer started"</span>);</span><br><span class="line">    } <span class="keyword">catch</span> (Throwable t) {</span><br><span class="line">        <span class="comment">// call close methods if internal objects are already constructed this is to prevent resource leak. see KAFKA-2121</span></span><br><span class="line">        close(Duration.ofMillis(<span class="number">0</span>), <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// now propagate the exception</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Failed to construct kafka producer"</span>, t);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h5 id="Sender-线程的初始化-1"><a href="#Sender-线程的初始化-1" class="headerlink" title="Sender 线程的初始化"></a>Sender 线程的初始化</h5><p>这里的核心类是 <code>clients</code> 模块下的 <code>org.apache.kafka.clients.producer.KafkaProducer</code> 类，最核心的是 <code>newSender()</code> 方法，如下所示：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Sender <span class="title">newSender</span><span class="params">(LogContext logContext, KafkaClient kafkaClient, ProducerMetadata metadata)</span> </span>{</span><br><span class="line">    <span class="comment">// maxInflightRequests 没有返回 ACK 的请求的最大数量，默认值是 5</span></span><br><span class="line">    <span class="keyword">int</span> maxInflightRequests = configureInflightRequests(producerConfig);</span><br><span class="line">    <span class="comment">// request.timeout.ms，默认值是 30s</span></span><br><span class="line">    <span class="keyword">int</span> requestTimeoutMs = producerConfig.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);</span><br><span class="line">    ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(producerConfig, time, logContext);</span><br><span class="line">    ProducerMetrics metricsRegistry = <span class="keyword">new</span> ProducerMetrics(<span class="keyword">this</span>.metrics);</span><br><span class="line">    Sensor throttleTimeSensor = Sender.throttleTimeSensor(metricsRegistry.senderMetrics);</span><br><span class="line"></span><br><span class="line">    KafkaClient client = kafkaClient != <span class="keyword">null</span> ? kafkaClient : <span class="keyword">new</span> NetworkClient(</span><br><span class="line">            <span class="keyword">new</span> Selector(producerConfig.getLong(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG),</span><br><span class="line">                    <span class="keyword">this</span>.metrics, time, <span class="string">"producer"</span>, channelBuilder, logContext),</span><br><span class="line">            metadata,</span><br><span class="line">            clientId,</span><br><span class="line">            <span class="comment">// maxInflightRequests 没有返回 ACK 的请求的最大数量，默认值是 5</span></span><br><span class="line">            <span class="comment">// reconnect.backoff.ms 重连时间间隔，默认值是 50ms</span></span><br><span class="line">            <span class="comment">// reconnect.backoff.max.ms 重连的总时间。每次重连失败时，呈指数增加重连时间，直至达到此最大值，默认值是 1000ms</span></span><br><span class="line">            <span class="comment">// send.buffer.bytes Socket 发送数据的缓冲区大小，默认值是 128k</span></span><br><span class="line">            <span class="comment">// receive.buffer.bytes Socket 接收数据的缓冲区大小，默认值是 32k</span></span><br><span class="line">            <span class="comment">// request.timeout.ms，默认值是 30s</span></span><br><span class="line">            <span class="comment">// socket.connection.setup.timeout.ms 生产者和服务器通信连接建立的时间。如果在超时之前没有建立连接，将关闭通信，默认值是 10s</span></span><br><span class="line">            <span class="comment">// socket.connection.setup.timeout.max.ms 生产者和服务器通信，每次连续连接失败时，连接建立超时将呈指数增加，直至达到此最大值，默认值是 30s</span></span><br><span class="line">            maxInflightRequests,</span><br><span class="line">            producerConfig.getLong(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG),</span><br><span class="line">            producerConfig.getLong(ProducerConfig.RECONNECT_BACKOFF_MAX_MS_CONFIG),</span><br><span class="line">            producerConfig.getInt(ProducerConfig.SEND_BUFFER_CONFIG),</span><br><span class="line">            producerConfig.getInt(ProducerConfig.RECEIVE_BUFFER_CONFIG),</span><br><span class="line">            requestTimeoutMs,</span><br><span class="line">            producerConfig.getLong(ProducerConfig.SOCKET_CONNECTION_SETUP_TIMEOUT_MS_CONFIG),</span><br><span class="line">            producerConfig.getLong(ProducerConfig.SOCKET_CONNECTION_SETUP_TIMEOUT_MAX_MS_CONFIG),</span><br><span class="line">            time,</span><br><span class="line">            <span class="keyword">true</span>,</span><br><span class="line">            apiVersions,</span><br><span class="line">            throttleTimeSensor,</span><br><span class="line">            logContext);</span><br><span class="line">    <span class="comment">// acks，默认值是 -1</span></span><br><span class="line">    <span class="comment">// acks=0，生产者发送给 Kafka 服务器后，不需要等待应答</span></span><br><span class="line">    <span class="comment">// acks=1，生产者发送给 Kafka 服务器后，需要等待 Leader 接收后应答</span></span><br><span class="line">    <span class="comment">// acks=-1(all)，生产者发送给 Kafka 服务器后，需要等待 Leader 和 ISR 队列中的所有 Follower 接收后应答</span></span><br><span class="line">    <span class="keyword">short</span> acks = configureAcks(producerConfig, log);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Sender(logContext,</span><br><span class="line">            client,</span><br><span class="line">            metadata,</span><br><span class="line">            <span class="keyword">this</span>.accumulator,</span><br><span class="line">            maxInflightRequests == <span class="number">1</span>,</span><br><span class="line">            <span class="comment">// 生产者发送给 Kafka 的单条消息的最大大小，默认值是 1m</span></span><br><span class="line">            producerConfig.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG),</span><br><span class="line">            acks,</span><br><span class="line">            <span class="comment">// retries 失败重试次数，默认值是 Int 的最大值</span></span><br><span class="line">            producerConfig.getInt(ProducerConfig.RETRIES_CONFIG),</span><br><span class="line">            metricsRegistry.senderMetrics,</span><br><span class="line">            time,</span><br><span class="line">            requestTimeoutMs,</span><br><span class="line">            <span class="comment">// retry.backoff.ms 失败重试的时间间隔，默认值 100ms</span></span><br><span class="line">            producerConfig.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG),</span><br><span class="line">            <span class="keyword">this</span>.transactionManager,</span><br><span class="line">            apiVersions);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>Sendler 类实现了 Runnable 接口，Main 线程会将 Sender 对象放到一个线程（KafkaThread 类）中启动。Sender 类的 <code>run()</code> 方法如下所示：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>{</span><br><span class="line">    log.debug(<span class="string">"Starting Kafka producer I/O thread."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// main loop, runs until close is called</span></span><br><span class="line">    <span class="keyword">while</span> (running) {</span><br><span class="line">        <span class="keyword">try</span> {</span><br><span class="line">            <span class="comment">// Sender 线程从缓冲区拉取数据，然后将数据发送给 Kafka，刚启动时会拉取不到数据</span></span><br><span class="line">            runOnce();</span><br><span class="line">        } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">            log.error(<span class="string">"Uncaught error in kafka producer I/O thread: "</span>, e);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Beginning shutdown of Kafka producer I/O thread, sending remaining records."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// okay we stopped accepting requests but there may still be</span></span><br><span class="line">    <span class="comment">// requests in the transaction manager, accumulator or waiting for acknowledgment,</span></span><br><span class="line">    <span class="comment">// wait until these are completed.</span></span><br><span class="line">    <span class="keyword">while</span> (!forceClose &amp;&amp; ((<span class="keyword">this</span>.accumulator.hasUndrained() || <span class="keyword">this</span>.client.inFlightRequestCount() &gt; <span class="number">0</span>) || hasPendingTransactionalRequests())) {</span><br><span class="line">        <span class="keyword">try</span> {</span><br><span class="line">            runOnce();</span><br><span class="line">        } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">            log.error(<span class="string">"Uncaught error in kafka producer I/O thread: "</span>, e);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Abort the transaction if any commit or abort didn't go through the transaction manager's queue</span></span><br><span class="line">    <span class="keyword">while</span> (!forceClose &amp;&amp; transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.hasOngoingTransaction()) {</span><br><span class="line">        <span class="keyword">if</span> (!transactionManager.isCompleting()) {</span><br><span class="line">            log.info(<span class="string">"Aborting incomplete transaction due to shutdown"</span>);</span><br><span class="line">            transactionManager.beginAbort();</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">try</span> {</span><br><span class="line">            runOnce();</span><br><span class="line">        } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">            log.error(<span class="string">"Uncaught error in kafka producer I/O thread: "</span>, e);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (forceClose) {</span><br><span class="line">        <span class="comment">// We need to fail all the incomplete transactional requests and batches and wake up the threads waiting on</span></span><br><span class="line">        <span class="comment">// the futures.</span></span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>) {</span><br><span class="line">            log.debug(<span class="string">"Aborting incomplete transactional requests due to forced shutdown"</span>);</span><br><span class="line">            transactionManager.close();</span><br><span class="line">        }</span><br><span class="line">        log.debug(<span class="string">"Aborting incomplete batches due to forced shutdown"</span>);</span><br><span class="line">        <span class="keyword">this</span>.accumulator.abortIncompleteBatches();</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="keyword">this</span>.client.close();</span><br><span class="line">    } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">        log.error(<span class="string">"Failed to close network client"</span>, e);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Shutdown of Kafka producer I/O thread has completed."</span>);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h5 id="发送数据到缓冲区-1"><a href="#发送数据到缓冲区-1" class="headerlink" title="发送数据到缓冲区"></a>发送数据到缓冲区</h5><h6 id="发送总体流程"><a href="#发送总体流程" class="headerlink" title="发送总体流程"></a>发送总体流程</h6><p>这里的核心类是 <code>clients</code> 模块下的 <code>org.apache.kafka.clients.producer.KafkaProducer</code> 类，最核心的是 <code>send()</code> 方法，如下所示：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>{</span><br><span class="line">    <span class="comment">// 拦截器处理待发送的数据</span></span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="keyword">this</span>.interceptors.onSend(record);</span><br><span class="line">    <span class="comment">// 发送数据给 Kafka</span></span><br><span class="line">    <span class="keyword">return</span> doSend(interceptedRecord, callback);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><code>send()</code> 会调用 <code>onSend()</code> 方法让拦截器处理待发送的数据，如下所示：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ProducerRecord&lt;K, V&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span> </span>{</span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptRecord = record;</span><br><span class="line">    <span class="keyword">for</span> (ProducerInterceptor&lt;K, V&gt; interceptor : <span class="keyword">this</span>.interceptors) {</span><br><span class="line">        <span class="keyword">try</span> {</span><br><span class="line">            <span class="comment">// 拦截器处理</span></span><br><span class="line">            interceptRecord = interceptor.onSend(interceptRecord);</span><br><span class="line">        } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">            <span class="comment">// do not propagate interceptor exception, log and continue calling other interceptors</span></span><br><span class="line">            <span class="comment">// be careful not to throw exception from here</span></span><br><span class="line">            <span class="keyword">if</span> (record != <span class="keyword">null</span>)</span><br><span class="line">                log.warn(<span class="string">"Error executing interceptor onSend callback for topic: {}, partition: {}"</span>, record.topic(), record.partition(), e);</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                log.warn(<span class="string">"Error executing interceptor onSend callback"</span>, e);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> interceptRecord;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><code>send()</code> 会调用 <code>doSend()</code> 方法将数据发送给 Kafka，如下所示：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>{</span><br><span class="line">    TopicPartition tp = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        throwIfProducerClosed();</span><br><span class="line">        <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">        <span class="keyword">long</span> nowMs = time.milliseconds();</span><br><span class="line">        ClusterAndWaitTime clusterAndWaitTime;</span><br><span class="line">        <span class="keyword">try</span> {</span><br><span class="line">            <span class="comment">// 拉取元数据，maxBlockTimeMs 表示最多能等待多长时间</span></span><br><span class="line">            clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), nowMs, maxBlockTimeMs);</span><br><span class="line">        } <span class="keyword">catch</span> (KafkaException e) {</span><br><span class="line">            <span class="keyword">if</span> (metadata.isClosed())</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>, e);</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        }</span><br><span class="line">        nowMs += clusterAndWaitTime.waitedOnMetadataMs;</span><br><span class="line">        <span class="comment">// 剩余等待时间 = 最多能等待的时间 - 用了多少时间</span></span><br><span class="line">        <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">        <span class="comment">// 更新集群的元数据</span></span><br><span class="line">        Cluster cluster = clusterAndWaitTime.cluster;</span><br><span class="line">        <span class="keyword">byte</span>[] serializedKey;</span><br><span class="line">        <span class="keyword">try</span> {</span><br><span class="line">            serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">        } <span class="keyword">catch</span> (ClassCastException cce) {</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert key of class "</span> + record.key().getClass().getName() +</span><br><span class="line">                    <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                    <span class="string">" specified in key.serializer"</span>, cce);</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 序列化操作</span></span><br><span class="line">        <span class="keyword">byte</span>[] serializedValue;</span><br><span class="line">        <span class="keyword">try</span> {</span><br><span class="line">            serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">        } <span class="keyword">catch</span> (ClassCastException cce) {</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert value of class "</span> + record.value().getClass().getName() +</span><br><span class="line">                    <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                    <span class="string">" specified in value.serializer"</span>, cce);</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 分区操作（根据集群的元数据）</span></span><br><span class="line">        <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">        tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line"></span><br><span class="line">        setReadOnly(record.headers());</span><br><span class="line">        Header[] headers = record.headers().toArray();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(),</span><br><span class="line">                compressionType, serializedKey, serializedValue, headers);</span><br><span class="line">        <span class="comment">// 校验发送消息的大小是否超过最大值，默认的最大值是 1m</span></span><br><span class="line">        ensureValidRecordSize(serializedSize);</span><br><span class="line">        <span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? nowMs : record.timestamp();</span><br><span class="line">        <span class="keyword">if</span> (log.isTraceEnabled()) {</span><br><span class="line">            log.trace(<span class="string">"Attempting to append record {} with callback {} to topic {} partition {}"</span>, record, callback, record.topic(), partition);</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 消息发送的回调</span></span><br><span class="line">        <span class="comment">// producer callback will make sure to call both 'callback' and interceptor callback</span></span><br><span class="line">        Callback interceptCallback = <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional()) {</span><br><span class="line">            transactionManager.failIfNotReadyForSend();</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 缓冲区（默认大小是 32m），里面是默认 16k 一个批次</span></span><br><span class="line">        RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                serializedValue, headers, interceptCallback, remainingWaitMs, <span class="keyword">true</span>, nowMs);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (result.abortForNewBatch) {</span><br><span class="line">            <span class="keyword">int</span> prevPartition = partition;</span><br><span class="line">            partitioner.onNewBatch(record.topic(), cluster, prevPartition);</span><br><span class="line">            partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">            tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line">            <span class="keyword">if</span> (log.isTraceEnabled()) {</span><br><span class="line">                log.trace(<span class="string">"Retrying append due to new batch creation for topic {} partition {}. The old partition was {}"</span>, record.topic(), partition, prevPartition);</span><br><span class="line">            }</span><br><span class="line">            <span class="comment">// producer callback will make sure to call both 'callback' and interceptor callback</span></span><br><span class="line">            interceptCallback = <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br><span class="line"></span><br><span class="line">            result = accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                serializedValue, headers, interceptCallback, remainingWaitMs, <span class="keyword">false</span>, nowMs);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional())</span><br><span class="line">            transactionManager.maybeAddPartitionToTransaction(tp);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 当批次满了或者创建了一个新的批次，则唤醒 Sender 线程发送数据给 Kafka</span></span><br><span class="line">        <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) {</span><br><span class="line">            log.trace(<span class="string">"Waking up the sender since topic {} partition {} is either full or getting a new batch"</span>, record.topic(), partition);</span><br><span class="line">            <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">return</span> result.future;</span><br><span class="line">        <span class="comment">// handling exceptions and record the errors;</span></span><br><span class="line">        <span class="comment">// for API exceptions return them in the future,</span></span><br><span class="line">        <span class="comment">// for other exceptions throw directly</span></span><br><span class="line">    } <span class="keyword">catch</span> (ApiException e) {</span><br><span class="line">        log.debug(<span class="string">"Exception occurred during message send:"</span>, e);</span><br><span class="line">        <span class="keyword">if</span> (callback != <span class="keyword">null</span>)</span><br><span class="line">            callback.onCompletion(<span class="keyword">null</span>, e);</span><br><span class="line">        <span class="keyword">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> FutureFailure(e);</span><br><span class="line">    } <span class="keyword">catch</span> (InterruptedException e) {</span><br><span class="line">        <span class="keyword">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> InterruptException(e);</span><br><span class="line">    } <span class="keyword">catch</span> (KafkaException e) {</span><br><span class="line">        <span class="keyword">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">        <span class="comment">// we notify interceptor about all exceptions, since onSend is called before anything else in this method</span></span><br><span class="line">        <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h6 id="分区的选择"><a href="#分区的选择" class="headerlink" title="分区的选择"></a>分区的选择</h6><div id="readmore-expansion" class="pjax"></div><link rel="stylesheet" type="text/css" href="https://qiniu.techgrow.cn/readmore/dist/hexo.css"><script data-pjax="" src="https://qiniu.techgrow.cn/readmore/dist/readmore.js" type="text/javascript"></script><script data-pjax="">var isMobile=navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i),allowMobile=!1;if(!isMobile||isMobile&&allowMobile)try{var plugin=new ReadmorePlugin;plugin.init({type:"hexo",id:"readmore-container",name:"全栈技术驿站",blogId:"96641-5333172926158-056",qrcode:"https://www.techgrow.cn/img/wx_mp_qr.png",keyword:"Tech",random:"1",height:"auto",expires:"365",lockToc:"yes",interval:"30",baseUrl:"",execute:"yes",tocSelector:""})}catch(e){console.warn("readmore plugin occurred error: "+e.name+" | "+e.message)}</script></div><footer class="post-footer"><div class="reward-container"><div>支持一根棒棒糖！</div> <button> 赞赏</button><div class="post-reward"><div> <img src="/img/pay_wx.png" alt="Clay 微信"> <span>微信</span></div><div> <img src="/img/pay_zfb.png" alt="Clay 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"> <strong>本文作者：</strong> Clay</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.techgrow.cn/posts/50c7d080.html" title="Kafka 入门教程之七">https://www.techgrow.cn/posts/50c7d080.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="contactme"><div class="social-list"><div class="social-item"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">欢迎添加博主微信，请备注 "博客"，届时会邀请您加入百人微信群</span><br> <img src="/img/wx_account_qr.png"></div></div></div><div class="post-tags"><a href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" rel="tag"><i class="fa fa-tag"></i> 微服务</a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag"><i class="fa fa-tag"></i> 分布式</a><a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag"><i class="fa fa-tag"></i> 消息队列</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/b9ff615e.html" rel="prev" title="Vagrant 快速创建 VirtualBox 虚拟机"><i class="fa fa-angle-left"></i> Vagrant 快速创建 VirtualBox 虚拟机</a></div><div class="post-nav-item"> <a href="/posts/bc19d204.html" rel="next" title="VuePress 渲染 Mermaid 绘图">VuePress 渲染 Mermaid 绘图<i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments" id="waline"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> Copyright © 2018 – <span itemprop="copyrightYear">2024</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Clay</span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i></span> <span>站点总字数：</span> <span title="站点总字数">1.5m</span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span>站点阅读时长 ≈</span> <span title="站点阅读时长">22:57</span></span></div><div id="site-runtime"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span><span id="runtime"></span></div><script language="javascript">function isPC(){for(var e=navigator.userAgent,t=["Android","iPhone","SymbianOS","Windows Phone","iPad","iPod"],n=0;n<t.length;n++)if(0<e.indexOf(t[n]))return!1;return!0}function siteTime(e,t){window.setTimeout("siteTime(openOnPC, start)",1e3);var n=36e5,o=24*n;t=new Date("2018-12-27 08:00:00");var i=new Date,r=(i.getFullYear(),i.getMonth(),i.getDate(),i.getHours(),i.getMinutes(),i.getSeconds(),i-t),a=Math.floor(r/31536e6),s=Math.floor(r/o-365*a),d=Math.floor((r-(365*a+s)*o)/n),l=Math.floor((r-(365*a+s)*o-d*n)/6e4),u=Math.floor((r-(365*a+s)*o-d*n-6e4*l)/1e3);document.getElementById("runtime").innerHTML="Powered by Hexo & Docker | "+a+" 年 "+s+" 日 "+d+" 小时 "+l+" 分钟 "+u+" 秒 "}var showOnMobile=!1,openOnPC=isPC(),start=new Date;siteTime(openOnPC,start),openOnPC||showOnMobile||(document.getElementById("site-runtime").style.display="none")</script><div class="beian"> <span><img src="/img/gonganbeian.png" alt=""></span> <span><a href="https://beian.miit.gov.cn/" rel="external nofollow" target="_blank">粤 ICP 备 19024664 号</a></span> <span>|&nbsp;</span> <span><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44011302004035" rel="external nofollow" target="_blank">粤公网安备 44011302004035 号</a></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div><div class="sidebar-dimmer"></div> <a href="https://github.com/rqh656418510" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="external nofollow" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="200" alpha="0.5" zindex="-1" src="/lib/ribbon.js/dist/ribbon.min.js"></script><script src="/lib/animejs/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="/lib/@next-theme/pjax/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script><script src="/lib/medium-zoom/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script><script src="/lib/lozad/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script><script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"/lib/pdfobject/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script><script src="/js/third-party/tags/pdf.js"></script><script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"/lib/mermaid/dist/mermaid.min.js","integrity":"sha256-stuqcu2FrjYCXDOytWFA5SoUE/r3nkp6gTglzNSlavU="}}</script><script src="/js/third-party/tags/mermaid.js"></script><script src="/js/third-party/pace.js"></script><script data-pjax="" async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://www.techgrow.cn/lib/darkmode/darkmode@1.5.7.min.js"></script><script>
var options = {
  bottom: '64px',
  right: '30px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#282828',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script><script src="https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js"></script><script>
    var qiniu_domain = "https://oss.techgrow.cn";
    var qiniu_token_url = "https://open.techgrow.cn/app/api/qiniu/token/upload";
    var qiniu_debug = "true" === "false";

    // date format
    Date.prototype.format = function (fmt) {
      var o = {
        "M+": this.getMonth() + 1,
        "d+": this.getDate(),
        "h+": this.getHours(),
        "m+": this.getMinutes(),
        "s+": this.getSeconds(),
        "q+": Math.floor((this.getMonth() + 3) / 3),
        "S": this.getMilliseconds()
      };
      if (/(y+)/.test(fmt)) {
        fmt = fmt.replace(RegExp.$1, (this.getFullYear() + "").substr(4 - RegExp.$1.length));
      }
      for (var k in o) {
        if (new RegExp("(" + k + ")").test(fmt)) {
          fmt = fmt.replace(
            RegExp.$1,
            (RegExp.$1.length == 1)
              ? (o[k])
              : (("00" + o[k]).substr(("" + o[k]).length))
          );
        }
      }
      return fmt;
    }

    // generate uuid
    function uuid() {
      var s = [];
      var hexDigits = "0123456789abcdef";
      for (var i = 0; i < 36; i++) {
        s[i] = hexDigits.substr(Math.floor(Math.random() * 0x10), 1);
      }
      s[14] = "4";
      s[19] = hexDigits.substr((s[19] & 0x3) | 0x8, 1);
      s[8] = s[13] = s[18] = s[23] = "-";
      var uuid = s.join("");
      return uuid;
    }

    // sync get request
    function syncGet(url) {
      var xhr = null;
      if (window.XMLHttpRequest) {
        xhr = new XMLHttpRequest();
      } else {
        xhr = new ActiveXObject("Microsoft.XMLHTTP");
      }
      xhr.open('GET', url, false);
      xhr.send();
      return xhr;
    }

    // get upload file path
    function getUploadFilePath() {
      var now = new Date();
      var name = uuid().replace(/-/g, "");
      var nowStr = now.format("/yyyy/MM/dd/");
      return "uploads" + nowStr + name;
    }

    // get qiniu upload token
    function getUploadToken() {
      try {
        var xhr = syncGet(qiniu_token_url);
        var responseStatus = xhr.status;
        var responseJson = JSON.parse(xhr.responseText);
        if (responseStatus === 200) {
          return responseJson.data;
        } else if (responseStatus === 403) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，非法请求来源！");
        } else if (responseStatus === 429) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，上传过于频繁！");
        } else if (responseStatus === 500) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，系统内部出错！");
        } else {
          alert("图片上传失败，无法获取UploadToken，未知Http响应状态码！");
        }
      } catch (err) {
        if (qiniu_debug) {
          console.error(err);
        }
        alert("图片上传失败，无法获取UploadToken，未知错误！");
      }
      return null;
    }

    // qiniu upload image
    async function qiniuUploadImage(file) {
      var image_path = null;
      await uploadImage(file).then(function onFulfilled(res) {
        image_path = res;
      }).catch(function onRejected(err) {
        if (qiniu_debug) {
          console.error(err);
        }
      });
      return image_path;
    }

    // upload image
    function uploadImage(file) {
      return new Promise((resolve, reject) => {
        var config = null;
        var putExtra = null;
        var token = getUploadToken();
        var key = getUploadFilePath();
        // upload init
        var observable = qiniu.upload(file, key, token, putExtra, config);
        // upload start
        observable.subscribe({
          next(res) {
            // upload progress
          },
          error(err) {
            // upload falied
            reject("falied to upload image for qiniu: " + err.name);
          },
          complete(res) {
            // upload successed
            resolve(qiniu_domain + "/" + key);
          }
        });
      });
    }
  </script><script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://waline.techgrow.cn","cssUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css","commentCount":true,"pageview":false,"copyright":false,"allowUploadImage":true,"libUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.js","locale":{"placeholder":"支持匿名评论啦，若希望及时收到博主的反馈，建议登录评论或者在上方的邮箱输入框留下邮箱地址哦 (๑•̀ㅂ•́)و✧"},"dark":"body.darkmode--activated","emoji":["https://www.techgrow.cn/lib/@waline/emojis/1.0.1/weibo"],"meta":["nick","mail","link"],"login":"enable","pageSize":10,"qiniuDebug":false,"qiniuDomain":"https://oss.techgrow.cn","qiniuTokenUrl":"https://open.techgrow.cn/app/api/qiniu/token/upload","qiniuLibUrl":"https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js","el":"#waline","comment":true,"path":"/posts/50c7d080.html"}</script><link rel="stylesheet" href="https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css"><script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.waline.allowUploadImage) {
    CONFIG.waline.imageUploader = false;
  }
  else if (CONFIG.waline.qiniuDomain && CONFIG.waline.qiniuTokenUrl) {
    CONFIG.waline.imageUploader = qiniuUploadImage;
  } else {
   CONFIG.waline.imageUploader = true;
  }
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script><div class="moon-menu"><div class="moon-menu-items"><div id="moon-menu-item-back2bottom" class="moon-menu-item"><i class="fas fa-chevron-down"></i></div><div id="moon-menu-item-back2top" class="moon-menu-item"><i class="fas fa-chevron-up"></i></div></div><div class="moon-menu-button"><svg class="moon-menu-bg"><circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle><circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle></svg><div class="moon-menu-content"><div class="moon-menu-icon"><i class="fas fa-ellipsis-v"></i></div><div class="moon-menu-text"></div></div></div></div><script src="/js/injector.js"></script><div class="comments" id="waline-comments" style="display:none"></div><script>function isMobile(){var i=navigator.userAgent.toLowerCase(),e="ipad"==i.match(/ipad/i),a="iphone os"==i.match(/iphone os/i),o="midp"==i.match(/midp/i),n="rv:1.2.3.4"==i.match(/rv:1.2.3.4/i),r="ucweb"==i.match(/ucweb/i),c="android"==i.match(/android/i),l="windows ce"==i.match(/windows ce/i),d="windows mobile"==i.match(/windows mobile/i);return!!(e||a||o||n||r||c||l||d)}var openOnMobile=isMobile(),showOnMobile=!1,aplayerEnable=!0;jQuery(document).ready(function(){aplayerEnable&&(openOnMobile&&!showOnMobile||jQuery("#aplayer").css("display","block"))}),jQuery(window).on("load",function(){aplayerEnable&&jQuery(".aplayer\\-icon.aplayer\\-icon\\-lrc").trigger("click")})</script></body></html>