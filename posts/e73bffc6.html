<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CRoboto+Slab:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic&amp;display=swap&amp;subset=latin,latin-ext"><link rel="stylesheet" href="/lib/@fortawesome/fontawesome-free/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/animate.css/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/pace-js/themes/blue/pace-theme-minimal.css"><script src="/lib/pace-js/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.techgrow.cn","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script><meta name="description" content="本文主要介绍 Kafka 的使用教程。"><meta property="og:type" content="article"><meta property="og:title" content="Kafka 入门教程之六"><meta property="og:url" content="https://www.techgrow.cn/posts/e73bffc6.html"><meta property="og:site_name" content="Clay 的技术空间"><meta property="og:description" content="本文主要介绍 Kafka 的使用教程。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-flume-4.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-flume-1.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-flume-2.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-flume-3.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/12/kafka-flink-1.png"><meta property="article:published_time" content="2022-09-16T14:13:45.000Z"><meta property="article:modified_time" content="2022-09-16T14:13:45.000Z"><meta property="article:author" content="Clay"><meta property="article:tag" content="分布式"><meta property="article:tag" content="消息队列"><meta property="article:tag" content="大数据"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.techgrow.cn/asset/2024/12/kafka-flume-4.png"><link rel="canonical" href="https://www.techgrow.cn/posts/e73bffc6.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.techgrow.cn/posts/e73bffc6.html","path":"posts/e73bffc6.html","title":"Kafka 入门教程之六"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Kafka 入门教程之六 | Clay 的技术空间</title><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-135294383-1"></script><script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-135294383-1","only_pageview":false,"measure_protocol_api_secret":null}</script><script src="/js/third-party/analytics/google-analytics.js"></script><script class="next-config" data-name="baidu_analytics" type="application/json">"84c09b30349a65573c5c642ff336969b"</script><script src="/js/third-party/analytics/baidu-analytics.js"></script><link rel="dns-prefetch" href="https://waline.techgrow.cn"><link rel="stylesheet" type="text/css" href="/css/injector/main.css"><link rel="preload" as="style" href="/css/injector/light.css"><link rel="preload" as="style" href="/css/injector/dark.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><style>.admonition{margin:1.5625em 0;padding:.6rem;overflow:hidden;font-size:.64rem;page-break-inside:avoid;border-left:.3rem solid #42b983;border-radius:.3rem;box-shadow:0 .1rem .4rem rgba(0,0,0,.05),0 0 .05rem rgba(0,0,0,.1);background-color:#fafafa}p.admonition-title{position:relative;margin:-.6rem -.6rem .8em -.6rem!important;padding:.4rem .6rem .4rem 2.5rem;font-weight:700;background-color:rgba(66,185,131,.1)}.admonition-title::before{position:absolute;top:.9rem;left:1rem;width:12px;height:12px;background-color:#42b983;border-radius:50%;content:' '}.info>.admonition-title,.todo>.admonition-title{background-color:rgba(0,184,212,.1)}.attention>.admonition-title,.caution>.admonition-title,.warning>.admonition-title{background-color:rgba(255,145,0,.1)}.error>.admonition-title,.fail>.admonition-title,.failure>.admonition-title,.missing>.admonition-title{background-color:rgba(255,82,82,.1)}.admonition.info,.admonition.todo{border-color:#00b8d4}.admonition.attention,.admonition.caution,.admonition.warning{border-color:#ff9100}.admonition.error,.admonition.fail,.admonition.failure,.admonition.missing{border-color:#ff5252}.info>.admonition-title::before,.todo>.admonition-title::before{background-color:#00b8d4;border-radius:50%}.attention>.admonition-title::before,.caution>.admonition-title::before,.warning>.admonition-title::before{background-color:#ff9100;border-radius:50%}.error>.admonition-title::before,.fail>.admonition-title::before,.failure>.admonition-title::before,.missing>.admonition-title::before{background-color:#ff5252;border-radius:50%}.admonition>:last-child{margin-bottom:0!important}</style><link rel="alternate" href="/atom.xml" title="Clay 的技术空间" type="application/atom+xml"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope="" itemtype="http://schema.org/WebPage" class="use-motion"><script src="/lib/jquery/dist/jquery.min.js"></script><script data-pjax="">!function(){var t=window.location.host;if(-1==t.indexOf("127.0.0.1")&&-1==t.indexOf("localhost")){var o=document.createElement("script"),e=window.location.protocol.split(":")[0];o.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(o,n)}}()</script><link rel="stylesheet" href="/lib/aplayer/dist/APlayer.min.css"><div id="aplayer" style="display:none"></div><script src="/lib/aplayer/dist/APlayer.min.js"></script><script src="/lib/aplayer/dist/color-thief.js"></script><script src="/lib/aplayer-init.js"></script><script src="https://res.wx.qq.com/open/js/jweixin-1.4.0.js"></script><script>function getTitle(){var t=jQuery("meta[property='og:title']");return t?t.attr("content"):""}function getDesc(){var t=jQuery("meta[property='og:description']");return t?t.attr("content"):""}function randomString(t){for(var e="ABCDEFGHJKMNPQRSTWXYZabcdefhijkmnprstwxyz2345678",n=e.length,i="",r=0;r<t;++r)i+=e.charAt(Math.floor(Math.random()*n));return i}function initWx(t){wx.config({debug:!1,appId:t.appId,nonceStr:t.nonceStr,signature:t.signature,timestamp:t.timestamp,jsApiList:["checkJsApi","onMenuShareTimeline","onMenuShareAppMessage","onMenuShareQQ"]}),wx.ready(function(){wx.onMenuShareTimeline({title:t.title,link:t.link,imgUrl:t.imgUrl,success:function(){}}),wx.onMenuShareAppMessage({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,type:"link",dataUrl:"",success:function(){}}),wx.onMenuShareQQ({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,success:function(){},cancel:function(){}})}),wx.error(function(t){})}jQuery(function(){var e=getDesc(),n=getTitle(),i=randomString(16),r=(new Date).getTime(),a=window.location.href,t="https://open.techgrow.cn/api/wechat/js/signature?url="+a+"&noncestr="+i+"&timestamp="+r;jQuery.getJSON(t,function(t){initWx({desc:e,title:n,link:a,nonceStr:i,timestamp:r,signature:t.data,appId:"wx1fcf69355af43d41",imgUrl:"https://www.techgrow.cn/img/wx_share.jpg"})})})</script><div style="display:none"><img src="https://www.techgrow.cn/img/wx_share.jpg" alt=""></div><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">Clay 的技术空间</p><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">用进废退 | 艺不压身</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-search"><a href="/search" rel="section"><i class="fa fa-search fa-fw"></i>搜索</a></li><li class="menu-item menu-item-links"><a href="/links" rel="section"><i class="fas fa-link fa-fw"></i>友链</a></li><li class="menu-item menu-item-readingnotes"><a href="https://www.techgrow.cn/reading/" rel="section"><i class="fa fa-book-open-reader fa-fw"></i>读书笔记</a></li><li class="menu-item menu-item-commentmanage"><a href="https://waline.techgrow.cn/" rel="external nofollow" target="_blank"><i class="fa fa-comment fa-fw"></i>评论管理</a></li></ul></nav></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E7%BA%B2"><span class="nav-text">大纲</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-text">前言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90"><span class="nav-text">学习资源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E9%9B%86%E6%88%90-Flume"><span class="nav-text">Kafka 集成 Flume</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Flume-%E7%AE%80%E4%BB%8B"><span class="nav-text">Flume 简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Flume-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-text">Flume 的优缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flume-%E7%9A%84%E6%A0%B8%E5%BF%83%E7%89%B9%E7%82%B9"><span class="nav-text">Flume 的核心特点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flume-%E7%9A%84%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="nav-text">Flume 的核心组件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flume-%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">Flume 的工作原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flume-%E7%9A%84%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-text">Flume 的适用场景</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flume-%E9%9B%86%E6%88%90"><span class="nav-text">Flume 集成</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Flume-%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE"><span class="nav-text">Flume 的安装与配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flume-%E4%BD%9C%E4%B8%BA-Kafka-%E7%9A%84%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-text">Flume 作为 Kafka 的生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E6%88%90-Kafka-%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="nav-text">集成 Kafka 的配置</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E6%88%90-Kafka-%E7%9A%84%E6%B5%8B%E8%AF%95"><span class="nav-text">集成 Kafka 的测试</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E6%88%90-Kafka-%E7%9A%84%E4%BC%98%E5%8C%96"><span class="nav-text">集成 Kafka 的优化</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flume-%E4%BD%9C%E4%B8%BA-Kafka-%E7%9A%84%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-text">Flume 作为 Kafka 的消费者</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E6%88%90-Kafka-%E7%9A%84%E9%85%8D%E7%BD%AE-1"><span class="nav-text">集成 Kafka 的配置</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E6%88%90-Kafka-%E7%9A%84%E6%B5%8B%E8%AF%95-1"><span class="nav-text">集成 Kafka 的测试</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E9%9B%86%E6%88%90-Flink"><span class="nav-text">Kafka 集成 Flink</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Flink-%E7%AE%80%E4%BB%8B"><span class="nav-text">Flink 简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Flink-%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-text">Flink 的优势</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flink-%E7%9A%84%E6%A0%B8%E5%BF%83%E7%89%B9%E7%82%B9"><span class="nav-text">Flink 的核心特点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flink-%E7%9A%84%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="nav-text">Flink 的核心组件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flink-%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-text">Flink 的应用场景</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flink-%E9%9B%86%E6%88%90"><span class="nav-text">Flink 集成</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%95%E5%85%A5%E4%BE%9D%E8%B5%96"><span class="nav-text">引入依赖</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flink-%E4%BD%9C%E4%B8%BA-Kafka-%E7%9A%84%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-text">Flink 作为 Kafka 的生产者</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flink-%E4%BD%9C%E4%B8%BA-Kafka-%E7%9A%84%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-text">Flink 作为 Kafka 的消费者</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E9%9B%86%E6%88%90-SpringBoot"><span class="nav-text">Kafka 集成 SpringBoot</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E9%9B%86%E6%88%90-SpringCloud"><span class="nav-text">Kafka 集成 SpringCloud</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope="" itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="Clay" src="/img/head.jpg"></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"> <span class="site-state-item-count">758</span> <span class="site-state-item-name">文章</span></div><div class="site-state-item site-state-tags"> <span class="site-state-item-count">54</span> <span class="site-state-item-name">标签</span></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/rqh656418510" title="GitHub → https://github.com/rqh656418510" rel="external nofollow" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:rong656418510@gmail.com" title="E-Mail → mailto:rong656418510@gmail.com" rel="external nofollow" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="/atom.xml" title="RSS → /atom.xml" rel="noopener me"><i class="fa fa-rss fa-fw"></i> RSS</a></span><span class="links-of-author-item"><a href="/sitemap.xml" title="SiteMap → /sitemap.xml" rel="noopener me"><i class="fa fa-sitemap fa-fw"></i> SiteMap</a></span></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope="" itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.techgrow.cn/posts/e73bffc6.html"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="image" content="/img/head.jpg"><meta itemprop="name" content="Clay"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Clay 的技术空间"><meta itemprop="description" content="专注于 Java 后端、分布式、微服务、云原生、数据库、系统架构、大数据、云计算、虚拟化、人工智能学习的技术博客。"></span><span hidden="" itemprop="post" itemscope="" itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Kafka 入门教程之六 | Clay 的技术空间"><meta itemprop="description" content="本文主要介绍 Kafka 的使用教程。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Kafka 入门教程之六</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-09-16 22:13:45" itemprop="dateCreated datePublished" datetime="2022-09-16T22:13:45+08:00">2022-09-16</time></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i></span> <span class="post-meta-item-text">评论数：</span><a title="waline" href="/posts/e73bffc6.html#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/e73bffc6.html" itemprop="commentCount"></span></a></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>5.2k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 ≈</span> <span>5 分钟</span></span></div></div></header><div class="post-body post-container" itemprop="articleBody" id="readmore-container"><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/b6be8183.html">Kafka 入门教程之一</a>、<a href="/posts/60ddcede.html">Kafka 入门教程之二</a>、<a href="/posts/228158d3.html">Kafka 入门教程之三</a></li><li><a href="/posts/c61757ff.html">Kafka 入门教程之四</a>、<a href="/posts/ed9d5bd.html">Kafka 入门教程之五</a>、<a href="/posts/e73bffc6.html">Kafka 入门教程之六</a></li><li><a href="/posts/50c7d080.html">Kafka 入门教程之七</a></li></ul><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h3><ul><li><a target="_blank" rel="external nofollow" href="https://nightlies.apache.org/flink/flink-docs-master/">Flink 官方文档</a></li><li><a target="_blank" rel="external nofollow" href="https://flume.apache.org/documentation.html">Flume 官方文档</a></li></ul><span id="more"></span><h2 id="Kafka-集成-Flume"><a href="#Kafka-集成-Flume" class="headerlink" title="Kafka 集成 Flume"></a>Kafka 集成 Flume</h2><h3 id="Flume-简介"><a href="#Flume-简介" class="headerlink" title="Flume 简介"></a>Flume 简介</h3><p><a target="_blank" rel="external nofollow" href="https://github.com/apache/logging-flume">Flume</a> 是一个分布式、可靠且高可用的日志收集和传输系统，主要用于大数据环境中的海量数据采集，功能类似于 ELK 中的 LogStash。它最初由 Cloudera 提出，是 Apache 软件基金会的顶级项目之一，主要用于将日志数据从不同的来源（如服务器日志文件、事件流等）采集、聚合并传输到大数据处理系统（如 HDFS 或 HBase）。<strong>请注意，Flume 项目已于 2024 年 10 月 10 日被标记为休眠状态，停止维护，官方建议迁移到其他替代方案。</strong></p><p><img data-src="../../../asset/2024/12/kafka-flume-4.png"></p><div class="admonition note"><p class="admonition-title">其他日志采集技术</p><p>在大数据和日志收集领域，还有许多类似的技术，比如 Kafka、Logstash、Filebeat、Fluentd、Graylog、Splunk Forwarder、Apache NiFi、Heka 等。</p></div><h4 id="Flume-的优缺点"><a href="#Flume-的优缺点" class="headerlink" title="Flume 的优缺点"></a>Flume 的优缺点</h4><ul><li>优点：<ul><li>易于集成 Hadoop 生态系统。</li><li>配置简单，使用灵活。</li><li>支持多种数据源和目标。</li><li>高可用和可靠性强。</li></ul></li><li>缺点：<ul><li>对实时性要求特别高的场景可能不适用。</li><li>配置灵活但复杂度高，可能需要较多调优。</li></ul></li></ul><h4 id="Flume-的核心特点"><a href="#Flume-的核心特点" class="headerlink" title="Flume 的核心特点"></a>Flume 的核心特点</h4><ul><li>分布式架构：<ul><li>支持分布式部署，可以跨多个节点扩展采集和传输能力。</li></ul></li><li>高可靠性：<ul><li>提供可靠的事件传输机制，确保数据不会丢失。</li></ul></li><li>灵活性：<ul><li>通过配置文件，可以灵活地定义数据来源、数据处理逻辑和数据目标。</li></ul></li><li>可扩展性：<ul><li>提供插件机制，可以轻松扩展以支持自定义的数据来源和目标。</li></ul></li><li>数据传输效率高：<ul><li>支持批量传输和数据压缩，提升传输效率。</li></ul></li></ul><h4 id="Flume-的核心组件"><a href="#Flume-的核心组件" class="headerlink" title="Flume 的核心组件"></a>Flume 的核心组件</h4><ul><li><p>Source（数据源）：</p><ul><li>数据输入端，负责从外部数据源中获取数据。例如，可以从日志文件、网络端口或自定义数据源读取数据。</li><li>常见的 Source 类型：<ul><li>Avro Source</li><li>Spooling Directory Source</li><li>Syslog Source</li><li>HTTP Source</li></ul></li></ul></li><li><p>Channel（通道）：</p><ul><li>数据的中转站，临时存储数据以确保数据的可靠性，同时可以解耦 Source 和 Sink 的处理速度。</li><li>常见的 Channel 类型：<ul><li>Memory Channel：速度快，但数据可能丢失（断电或程序崩溃），适用于非关键性数据。</li><li>File Channel：速度较慢，但数据安全性高，适合需要保证数据可靠性的场景。</li><li>Kafka Channel: 将 Kafka 作为 Channel，适合分布式和高可靠性场景。</li><li>JDBC Channel：，将数据库作为 Channel，速度较慢，但数据可靠性高，适合要求高可靠性、需要持久化存储的场景。</li></ul></li></ul></li><li><p>Sink（数据目的地）：</p><ul><li>数据的输出端，负责将数据发送到目标存储或处理系统。</li><li>常见的 Sink 类型：<ul><li>HDFS Sink</li><li>HBase Sink</li><li>Kafka Sink</li></ul></li></ul></li><li><p>Agent（代理）：</p><ul><li>Flume 的运行实例，一个 Agent 包括一个或多个 Source、Channel 和 Sink。</li></ul></li><li><p>Interceptors（拦截器）：</p><ul><li>用于在数据流动过程中，对数据进行过滤、修改或增强。</li></ul></li></ul><h4 id="Flume-的工作原理"><a href="#Flume-的工作原理" class="headerlink" title="Flume 的工作原理"></a>Flume 的工作原理</h4><ul><li>数据采集：<ul><li>Source 从指定数据源获取数据，并将数据封装成 Event（事件）。</li></ul></li><li>数据传输：<ul><li>Event 被传递到 Channel，并存储在 Channel 中。</li></ul></li><li>数据写入：<ul><li>Sink 从 Channel 中读取 Event，并将其写入指定的目标存储或处理系统。</li></ul></li></ul><h4 id="Flume-的适用场景"><a href="#Flume-的适用场景" class="headerlink" title="Flume 的适用场景"></a>Flume 的适用场景</h4><ul><li>日志采集：<ul><li>将分布式系统中的应用日志采集并传输到 HDFS 或 Kafka 进行分析。</li></ul></li><li>实时数据流处理：<ul><li>配合 Kafka 等流处理系统，传输实时事件流数据。</li></ul></li><li>海量数据传输：<ul><li>在分布式环境下高效、稳定地传输大规模数据。</li></ul></li><li>数据备份：<ul><li>将日志或事件数据备份到分布式存储系统中。</li></ul></li></ul><div class="admonition note"><p class="admonition-title">为什么要同时使用 Flume 和 Kafka，而不是单独使用 Kafka 采集日志信息？</p><ul><li>数据采集能力：Flume 支持多种数据源（如文件、HTTP、Syslog），采集灵活，而 Kafka 更适合作为高性能消息队列。</li><li>缓存与流控：Flume 的 Channel 提供可靠的缓冲和容错能力，可应对下游系统压力或故障。</li><li>数据预处理：Flume 支持通过拦截器进行数据过滤、格式化和增强，简化了日志预处理。</li><li>与 HDFS/HBase 的无缝集成：Flume 内置对 Hadoop 生态的支持，可直接将数据写入 HDFS 或 HBase。</li><li>兼容现有系统：许多项目中 Flume 已经存在，引入 Kafka 可以重用配置，降低改造成本。</li><li>灵活架构：Flume 负责采集日志，Kafka 负责分发数据，实现采集与分发的解耦。</li></ul></div><h3 id="Flume-集成"><a href="#Flume-集成" class="headerlink" title="Flume 集成"></a>Flume 集成</h3><p>在大数据和日志收集领域，Flume 可以作为 Kafka 的生产者，也可以作为 Kafka 的消费者，如下图所示：</p><p><img data-src="../../../asset/2024/12/kafka-flume-1.png"></p><h4 id="Flume-的安装与配置"><a href="#Flume-的安装与配置" class="headerlink" title="Flume 的安装与配置"></a>Flume 的安装与配置</h4><ul><li>在 <a target="_blank" rel="external nofollow" href="http://archive.apache.org/dist/flume/">官网</a> 下载 Flume 的二进制压缩包并解压</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载文件</span></span><br><span class="line">$ wget http://archive.apache.org/dist/flume/1.11.0/apache-flume-1.11.0-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line">$ tar -xvf apache-flume-1.11.0-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名目录</span></span><br><span class="line">$ mv apache-flume-1.11.0-bin flume</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移动目录</span></span><br><span class="line">$ sudo mv flume /opt/flume</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件授权</span></span><br><span class="line">$ sudo chmod -R 777 /opt/flume</span><br><span class="line"></span><br><span class="line"><span class="comment"># 脚本授权执行</span></span><br><span class="line">$ sudo chmod +x /opt/flume/bin/flume-ng</span><br></pre></td></tr></tbody></table></figure><ul><li>更改 Flume 的日志目录路径</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入 Flume 的配置目录</span></span><br><span class="line">$ <span class="built_in">cd</span> /opt/flume/conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑日志配置文件，更改以下内容（建议使用绝对路径）</span></span><br><span class="line">$ vi conf/log4j2.xml</span><br></pre></td></tr></tbody></table></figure><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Properties</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">"LOG_DIR"</span>&gt;</span>/opt/flume/logs<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Properties</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><ul><li>调整 Flume 的堆内存大小（在生产环境中，建议设置堆内存为 4G 或以上）</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入 Flume 的配置目录</span></span><br><span class="line">$ <span class="built_in">cd</span> /opt/flume/conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝运行环境脚本文件</span></span><br><span class="line">$ cp flume-env.sh.template flume-env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑运行环境脚本文件（更改以下内容）</span></span><br><span class="line">$ vi flume-env.sh</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_OPTS=<span class="string">"-Xms4096m -Xmx4096m -Dcom.sun.management.jmxremote"</span></span><br></pre></td></tr></tbody></table></figure><ul><li>添加环境变量</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更改系统配置文件，添加环境变量</span></span><br><span class="line">$ sudo vi /etc/profile</span><br><span class="line"><span class="built_in">export</span> KE_HOME=/opt/flume</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KE_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使系统配置文件的更改生效</span></span><br><span class="line">$ sudo <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></tbody></table></figure><h4 id="Flume-作为-Kafka-的生产者"><a href="#Flume-作为-Kafka-的生产者" class="headerlink" title="Flume 作为 Kafka 的生产者"></a>Flume 作为 Kafka 的生产者</h4><p>本节将演示 Flume 通过 Source 组件读取磁盘里的日志文件，并将日志信息写入到 Channel（基于内存）组件里面，然后通过 Sink 组件从 Channel 中读取日志信息并写入 Kafka，最后由 Kafka 消费者消费日志信息（如下图所示）。</p><p><img data-src="../../../asset/2024/12/kafka-flume-2.png"></p><h5 id="集成-Kafka-的配置"><a href="#集成-Kafka-的配置" class="headerlink" title="集成 Kafka 的配置"></a>集成 Kafka 的配置</h5><ul><li>创建用于测试的日志文件</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建日志目录</span></span><br><span class="line">$ sudo mkdir /opt/applog</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建日志文件</span></span><br><span class="line">$ sudo touch /opt/applog/app.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志文件授权</span></span><br><span class="line">$ sudo chmod 666 /opt/applog/app.log</span><br></pre></td></tr></tbody></table></figure><ul><li>创建 Position 文件</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 Position 目录</span></span><br><span class="line">$ mkdir /opt/flume/positions</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Position 文件</span></span><br><span class="line">$ touch /opt/flume/positions/taildir_position.json</span><br></pre></td></tr></tbody></table></figure><ul><li>创建 Job 文件</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 Job 目录</span></span><br><span class="line">$ mkdir /opt/flume/<span class="built_in">jobs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Job 文件</span></span><br><span class="line">$ touch /opt/flume/<span class="built_in">jobs</span>/file_to_kafka.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑 Job 文件（添加以下内容）</span></span><br><span class="line">$ vi /opt/flume/<span class="built_in">jobs</span>/file_to_kafka.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 组件定义</span></span><br><span class="line"><span class="meta">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="meta">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="meta">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置 source</span></span><br><span class="line"><span class="meta">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="meta">a1.sources.r1.filegroups</span> = <span class="string">f1</span></span><br><span class="line"><span class="meta">a1.sources.r1.filegroups.f1</span> = <span class="string">/opt/applog/app.*</span></span><br><span class="line"><span class="meta">a1.sources.r1.positionFile</span> = <span class="string">/opt/flume/positions/taildir_position.json</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置 channel</span></span><br><span class="line"><span class="meta">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="meta">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="meta">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置 sink</span></span><br><span class="line"><span class="meta">a1.sinks.k1.type</span> = <span class="string">org.apache.flume.sink.kafka.KafkaSink</span></span><br><span class="line"><span class="meta">a1.sinks.k1.kafka.bootstrap.servers</span> = <span class="string">127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094</span></span><br><span class="line"><span class="meta">a1.sinks.k1.kafka.topic</span> = <span class="string">first</span></span><br><span class="line"><span class="meta">a1.sinks.k1.kafka.flumeBatchSize</span> = <span class="string">20</span></span><br><span class="line"><span class="meta">a1.sinks.k1.kafka.producer.acks</span> = <span class="string">1</span></span><br><span class="line"><span class="meta">a1.sinks.k1.kafka.producer.linger.ms</span> = <span class="string">1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 拼接组件</span></span><br><span class="line"><span class="meta">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="meta">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">官方文档说明</p><ul><li><a target="_blank" rel="external nofollow" href="https://flume.apache.org/releases/content/1.11.0/FlumeUserGuide.html#kafka-sink">Kafka Sink 的配置说明</a></li><li><a target="_blank" rel="external nofollow" href="https://flume.apache.org/releases/content/1.11.0/FlumeUserGuide.html#taildir-source">Taildir Source 的配置说明</a></li><li><a target="_blank" rel="external nofollow" href="https://flume.apache.org/releases/content/1.11.0/FlumeUserGuide.html#memory-channel">Memory Channel 的配置说明</a></li></ul></div><div class="admonition warning"><p class="admonition-title">重要参数说明</p><ul><li><code>a1.sources.r1.filegroups.f1</code>：需要传输日志数据到 Kafka 的日志文件</li><li><code>a1.channels.c1.capacity</code>：Channel 的总容量</li><li><code>a1.channels.c1.transactionCapacity</code>：Channel 在每次事务中处理的最大事件数量</li><li><code>a1.sinks.k1.kafka.bootstrap.servers</code>：Kafka 集群的节点列表</li><li><code>a1.sinks.k1.kafka.topic</code>：Kafka 的 Topic</li><li><code>a1.sinks.k1.kafka.flumeBatchSize</code>：控制 Sink 每次从 Channel 中批量读取的最大事件数量</li><li><code>a1.sinks.k1.kafka.producer.linger.ms</code>：底层 Kafka 客户端的参数，用于控制 Producer 在每次批量发送数据前的等待时间</li></ul></div><h5 id="集成-Kafka-的测试"><a href="#集成-Kafka-的测试" class="headerlink" title="集成 Kafka 的测试"></a>集成 Kafka 的测试</h5><ul><li>启动 Kafka 控制台消费者</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first</span><br></pre></td></tr></tbody></table></figure><ul><li>启动 Flume</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入 Flume 的安装目录</span></span><br><span class="line">$ <span class="built_in">cd</span> /opt/flume/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后台启动 Flume（如果希望前台启动，可以去掉尾部的 &amp; 符号）</span></span><br><span class="line">$ bin/flume-ng agent -c conf/ -n a1 -f <span class="built_in">jobs</span>/file_to_kafka.conf &amp;</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">查看 Flume 是否启动成功</p><ul><li>查看进程信息：<code>ps -aux|grep flume</code></li><li>查看启动日志：<code>vi /opt/flume/logs/flume.log</code></li></ul></div><ul><li>往日志文件追加数据，查看 Kafka 控制台消费者的消费情况</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 追加写入日志文件</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"hello kafka"</span> &gt;&gt; /opt/applog/app.log</span><br></pre></td></tr></tbody></table></figure><h5 id="集成-Kafka-的优化"><a href="#集成-Kafka-的优化" class="headerlink" title="集成 Kafka 的优化"></a>集成 Kafka 的优化</h5><p>为了进一步优化 Flume 采集日志的效率，还可以采用 Kafka Channel（相当于 Kafka 作为 Channel），将日志信息直接写入 Kafka，从而省去了 Sink 的处理，提高整体的处理效率。Flume 完整的 Job 配置示例如下：</p><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 组件定义</span></span><br><span class="line"><span class="meta">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="meta">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置 source</span></span><br><span class="line"><span class="meta">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="meta">a1.sources.r1.filegroups</span> = <span class="string">f1</span></span><br><span class="line"><span class="meta">a1.sources.r1.filegroups.f1</span> = <span class="string">/opt/applog/app.*</span></span><br><span class="line"><span class="meta">a1.sources.r1.positionFile</span> = <span class="string">/opt/flume/positions/taildir_position.json</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置 channel</span></span><br><span class="line"><span class="meta">a1.channels.c1.type</span> = <span class="string">org.apache.flume.channel.kafka.KafkaChannel</span></span><br><span class="line"><span class="meta">a1.channels.c1.kafka.bootstrap.servers</span> = <span class="string">127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094</span></span><br><span class="line"><span class="meta">a1.channels.c1.kafka.topic</span> = <span class="string">first</span></span><br><span class="line"><span class="meta">a1.channels.c1.parseAsFlumeEvent</span> = <span class="string">false</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 拼接组件</span></span><br><span class="line"><span class="meta">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">官方文档说明</p><ul><li><a target="_blank" rel="external nofollow" href="https://flume.apache.org/releases/content/1.11.0/FlumeUserGuide.html#taildir-source">Taildir Source 的配置说明</a></li><li><a target="_blank" rel="external nofollow" href="https://flume.apache.org/releases/content/1.11.0/FlumeUserGuide.html#kafka-channel">Kafka Channel 的配置说明</a></li></ul></div><div class="admonition warning"><p class="admonition-title">重要参数说明</p><ul><li><code>a1.sources.r1.filegroups.f1</code>：需要传输日志数据到 Kafka 的日志文件</li><li><code>a1.channels.c1.kafka.bootstrap.servers</code>：Kafka 集群的节点列表</li><li><code>a1.channels.c1.kafka.topic</code>：Kafka 的 Topic</li></ul></div><h4 id="Flume-作为-Kafka-的消费者"><a href="#Flume-作为-Kafka-的消费者" class="headerlink" title="Flume 作为 Kafka 的消费者"></a>Flume 作为 Kafka 的消费者</h4><p>本节将演示 Flume 通过 Source 组件消费 Kafka 中的消息，并将消息写入到 Channel（基于内存）组件里面，然后通过 Sink 组件将消息打印到控制台和记录到日志文件中（如下所示）。</p><p><img data-src="../../../asset/2024/12/kafka-flume-3.png"></p><h5 id="集成-Kafka-的配置-1"><a href="#集成-Kafka-的配置-1" class="headerlink" title="集成 Kafka 的配置"></a>集成 Kafka 的配置</h5><ul><li>创建 Job 文件</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 Job 目录</span></span><br><span class="line">$ mkdir /opt/flume/<span class="built_in">jobs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Job 文件</span></span><br><span class="line">$ touch /opt/flume/<span class="built_in">jobs</span>/kafka_to_log.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑 Job 文件（添加以下内容）</span></span><br><span class="line">$ vi /opt/flume/<span class="built_in">jobs</span>/kafka_to_log.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 组件定义</span></span><br><span class="line"><span class="meta">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="meta">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="meta">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置 source</span></span><br><span class="line"><span class="meta">a1.sources.r1.type</span> = <span class="string">org.apache.flume.source.kafka.KafkaSource</span></span><br><span class="line"><span class="meta">a1.sources.r1.batchSize</span> = <span class="string">100</span></span><br><span class="line"><span class="meta">a1.sources.r1.batchDurationMillis</span> = <span class="string">200</span></span><br><span class="line"><span class="meta">a1.sources.r1.kafka.bootstrap.servers</span> = <span class="string">127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094</span></span><br><span class="line"><span class="meta">a1.sources.r1.kafka.topics</span> = <span class="string">first</span></span><br><span class="line"><span class="meta">a1.sources.r1.kafka.consumer.group.id</span> = <span class="string">flume_group</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置 channel</span></span><br><span class="line"><span class="meta">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="meta">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="meta">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置 sink</span></span><br><span class="line"><span class="meta">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 拼接组件</span></span><br><span class="line"><span class="meta">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="meta">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">官方文档说明</p><ul><li><a target="_blank" rel="external nofollow" href="https://flume.apache.org/releases/content/1.11.0/FlumeUserGuide.html#kafka-source">Kafka Source 的配置说明</a></li><li><a target="_blank" rel="external nofollow" href="https://flume.apache.org/releases/content/1.11.0/FlumeUserGuide.html#memory-channel">Memory Channel 的配置说明</a></li></ul></div><div class="admonition warning"><p class="admonition-title">重要参数说明</p><ul><li><code>a1.sources.r1.batchSize</code>：Source 每次批量写入 Channel 的最大事件数量</li><li><code>a1.sources.r1.batchDurationMillis</code>：Souce 将事件批量写入到 Channel 的最大时间间隔</li><li><code>a1.sources.r1.kafka.bootstrap.servers</code>：Kafka 集群的节点列表</li><li><code>a1.sources.r1.kafka.topics</code>：Kafka 的 Topic</li><li><code>a1.sources.r1.kafka.consumer.group.id</code>：Kafka 的消费者组 ID</li></ul></div><h5 id="集成-Kafka-的测试-1"><a href="#集成-Kafka-的测试-1" class="headerlink" title="集成 Kafka 的测试"></a>集成 Kafka 的测试</h5><ul><li>启动 Flume</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入 Flume 的安装目录</span></span><br><span class="line">$ <span class="built_in">cd</span> /opt/flume/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后台启动 Flume（如果希望前台启动，可以去掉尾部的 &amp; 符号）</span></span><br><span class="line">$ bin/flume-ng agent -c conf/ -n a1 -f <span class="built_in">jobs</span>/kafka_to_log.conf -Dflume.root.logger=INFO,console &amp;</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">查看 Flume 是否启动成功</p><ul><li>查看进程信息：<code>ps -aux|grep flume</code></li><li>查看启动日志：<code>vi /opt/flume/logs/flume.log</code></li></ul></div><ul><li>启动 Kafka 控制台生产者，并手动发送消息</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic first</span><br></pre></td></tr></tbody></table></figure><ul><li>查看 Flume 的日志文件，观察是否可以记录 Kafka 控制台生产者发送的消息</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tail -f /opt/flume/logs/flume.log</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.LoggerSink.process:95)  - Event: { headers:{topic=first, partition=1, offset=6045, timestamp=1733839351854} body: 68 65 6C 6C 6F      hello }</span><br><span class="line">INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.LoggerSink.process:95)  - Event: { headers:{topic=first, partition=0, offset=5656, timestamp=1733839231348} body: 6B 61 66 6B 61      kafka }</span><br><span class="line">INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.LoggerSink.process:95)  - Event: { headers:{topic=first, partition=2, offset=4103, timestamp=1733839428791} body: 66 6C 75 6D 65      flume }</span><br></pre></td></tr></tbody></table></figure><h2 id="Kafka-集成-Flink"><a href="#Kafka-集成-Flink" class="headerlink" title="Kafka 集成 Flink"></a>Kafka 集成 Flink</h2><p><a target="_blank" rel="external nofollow" href="https://github.com/apache/flink">Flink</a> 是一个分布式数据处理框架和计算引擎，它最初由德国柏林工业大学开发，后来开源并成为 Apache 软件基金会的顶级项目。Flink 被广泛用于处理大规模数据流，特别是在实时数据处理和批处理场景中表现出色。</p><h3 id="Flink-简介"><a href="#Flink-简介" class="headerlink" title="Flink 简介"></a>Flink 简介</h3><h4 id="Flink-的优势"><a href="#Flink-的优势" class="headerlink" title="Flink 的优势"></a>Flink 的优势</h4><ul><li>低延迟和高吞吐：通过流优先的设计，保证了实时处理性能。</li><li>灵活性和扩展性：支持多种数据源和目标，支持无缝扩展。</li><li>强大的生态系统：支持 HDFS、Kafka、Elasticsearch、Cassandra 等多种流行的大数据组件。</li></ul><div class="admonition note"><p class="admonition-title">与其他大数据技术的比较</p><ul><li>与 Spark 相比：Flink 更专注于实时流处理，而 Spark 在批处理领域更强。</li><li>与 Kafka Streams 相比：Flink 功能更全面，支持复杂的流处理逻辑和状态管理。</li></ul></div><h4 id="Flink-的核心特点"><a href="#Flink-的核心特点" class="headerlink" title="Flink 的核心特点"></a>Flink 的核心特点</h4><ul><li><p>实时流处理（Stream Processing）：</p><ul><li>Flink 是流处理优先的框架，支持以事件为单位处理数据流。</li><li>可以实现低延迟、高吞吐量的数据处理，适用于实时监控、在线分析等场景。</li></ul></li><li><p>批处理能力（Batch Processing）：</p><ul><li>虽然主要面向流处理，但 Flink 也支持批处理，利用流处理 API 实现批数据的高效处理。</li></ul></li><li><p>事件时间支持（Event Time Support）：</p><ul><li>Flink 通过支持事件时间和水位线（Watermark），可以处理乱序数据流，适用于复杂的实时分析场景。</li></ul></li><li><p>状态管理（State Management）：</p><ul><li>Flink 提供强大的状态管理功能，可以在流处理中存储和管理状态。</li><li>支持状态的容错（通过检查点 Checkpoint 和保存点 Savepoint）。</li></ul></li><li><p>分布式架构：</p><ul><li>Flink 的分布式架构设计支持横向扩展，能够高效处理 PB 级别的数据。</li></ul></li><li><p>容错机制（Fault Tolerance）：</p><ul><li>Flink 提供了基于一致性检查点的强大容错机制，确保数据处理不会因为系统故障而丢失或重复。</li></ul></li></ul><h4 id="Flink-的核心组件"><a href="#Flink-的核心组件" class="headerlink" title="Flink 的核心组件"></a>Flink 的核心组件</h4><ul><li><p>JobManager 和 TaskManager：</p><ul><li>JobManager 负责任务的协调和调度。</li><li>TaskManager 是工作节点，执行实际的计算任务。</li></ul></li><li><p>DataStream API：</p><ul><li>用于流处理任务，支持事件时间、窗口操作、状态管理等。</li></ul></li><li><p>DataSet API：</p><ul><li>用于批处理任务，支持丰富的转换操作。</li></ul></li><li><p>Table API 和 SQL：</p><ul><li>提供 SQL 风格的查询接口，支持更高层次的抽象。</li></ul></li></ul><h4 id="Flink-的应用场景"><a href="#Flink-的应用场景" class="headerlink" title="Flink 的应用场景"></a>Flink 的应用场景</h4><ul><li><p>实时数据分析：</p><ul><li>监控系统的日志分析、实时流量监控、用户行为分析等。</li></ul></li><li><p>数据处理和转换：</p><ul><li>数据清洗、数据聚合、实时数据增强。</li></ul></li><li><p>复杂事件处理（CEP）：</p><ul><li>检测金融欺诈、网络安全威胁、物联网（IoT）中的事件模式。</li></ul></li><li><p>机器学习：</p><ul><li>实时预测、模型更新。</li></ul></li><li><p>ETL（Extract，Transform，Load）：</p><ul><li>从数据源提取数据，进行转换处理，然后加载到目标数据仓库或系统。</li></ul></li></ul><h3 id="Flink-集成"><a href="#Flink-集成" class="headerlink" title="Flink 集成"></a>Flink 集成</h3><p>Flink 可以作为 Kafka 的生产者，也可以作为 Kafka 的消费者（如下图所示）。</p><p><img data-src="../../../asset/2024/12/kafka-flink-1.png"></p><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-18</code>。</p></div><h4 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h4><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">kafka.version</span>&gt;</span>3.6.0<span class="tag">&lt;/<span class="name">kafka.version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.17.0<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>${kafka.version}<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>${flink.version}<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>${flink.version}<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>${flink.version}<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>${flink.version}<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h4 id="Flink-作为-Kafka-的生产者"><a href="#Flink-作为-Kafka-的生产者" class="headerlink" title="Flink 作为 Kafka 的生产者"></a>Flink 作为 Kafka 的生产者</h4><div class="admonition note"><p class="admonition-title">案例目标</p><p>本节将集成 Kafka 与 Flink，并使用 Flink 作为 Kafka 生产者，实现向 Kafka 发送消息。</p></div><ul><li>第一种写法：基于 KafkaSink 类</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlinkKafkaProducerTest1</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">        <span class="comment">// 初始化 Flink 执行环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 模拟源数据</span></span><br><span class="line">        List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        list.add(<span class="string">"hello"</span>);</span><br><span class="line">        list.add(<span class="string">"flink"</span>);</span><br><span class="line">        DataStream&lt;String&gt; dataStream = env.fromCollection(list);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置 KafkaSink（相当于 Kafka 生产者）</span></span><br><span class="line">        KafkaSink&lt;String&gt; kafkaSink = KafkaSink.&lt;String&gt;builder()</span><br><span class="line">            .setBootstrapServers(<span class="string">"127.0.0.1:9092"</span>)</span><br><span class="line">            .setRecordSerializer(</span><br><span class="line">                KafkaRecordSerializationSchema.builder()</span><br><span class="line">                    .setTopic(<span class="string">"first"</span>)</span><br><span class="line">                    .setKeySerializationSchema(<span class="keyword">new</span> SimpleStringSchema())</span><br><span class="line">                    .setValueSerializationSchema(<span class="keyword">new</span> SimpleStringSchema())</span><br><span class="line">                    .build()</span><br><span class="line">            )</span><br><span class="line">            .setDeliveryGuarantee(DeliveryGuarantee.AT_LEAST_ONCE)</span><br><span class="line">            .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Flink 流关联 KafkaSink</span></span><br><span class="line">        dataStream.sinkTo(kafkaSink);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>第二种写法：基于 FlinkKafkaProducer 类（官方已标记为过时）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlinkKafkaProducerTest2</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">        <span class="comment">// 初始化 Flink 执行环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 模拟源数据</span></span><br><span class="line">        List&lt;String&gt; worldsList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        worldsList.add(<span class="string">"hello"</span>);</span><br><span class="line">        worldsList.add(<span class="string">"flink"</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; stream = env.fromCollection(worldsList);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Kafka 生产者的配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建 Kafka 生产者</span></span><br><span class="line">        FlinkKafkaProducer&lt;String&gt; kafkaProducer = <span class="keyword">new</span> FlinkKafkaProducer(<span class="string">"first"</span>, <span class="keyword">new</span> SimpleStringSchema(), properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Flink 流关联 Kafka 生产者</span></span><br><span class="line">        stream.addSink(kafkaProducer);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="Flink-作为-Kafka-的消费者"><a href="#Flink-作为-Kafka-的消费者" class="headerlink" title="Flink 作为 Kafka 的消费者"></a>Flink 作为 Kafka 的消费者</h4><div class="admonition note"><p class="admonition-title">案例目标</p><p>本节将集成 Kafka 与 Flink，并使用 Flink 作为 Kafka 消费者，实现从 Kafka 消费消息。</p></div><ul><li>第一种写法：基于 KafkaSource 类</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlinkKafkaConsumerTest1</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">        <span class="comment">// 初始化 Flink 执行环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置 KafkaSource（相当于 Kafka 消费者）</span></span><br><span class="line">        KafkaSource&lt;String&gt; kafkaSource = KafkaSource.&lt;String&gt;builder()</span><br><span class="line">            .setBootstrapServers(<span class="string">"127.0.0.1:9092"</span>)</span><br><span class="line">            .setTopics(<span class="string">"first"</span>)</span><br><span class="line">            .setGroupId(<span class="string">"flink1"</span>)</span><br><span class="line">            .setStartingOffsets(OffsetsInitializer.latest())</span><br><span class="line">            .setValueOnlyDeserializer(<span class="keyword">new</span> SimpleStringSchema())</span><br><span class="line">            .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Flink 流关联 KafkaSource</span></span><br><span class="line">        DataStreamSource&lt;String&gt; stream = env.fromSource(kafkaSource, WatermarkStrategy.noWatermarks(), <span class="string">"kafka-source"</span>);</span><br><span class="line">        stream.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>第二种写法：基于 FlinkKafkaConsumer 类（官方已标记为过时）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlinkKafkaConsumerTest2</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">        <span class="comment">// 初始化 Flink 执行环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Kafka 消费者的配置信息</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"flink2"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建 Kafka 消费者</span></span><br><span class="line">        FlinkKafkaConsumer&lt;String&gt; kafkaConsumer = <span class="keyword">new</span> FlinkKafkaConsumer(<span class="string">"first"</span>, <span class="keyword">new</span> SimpleStringSchema(), properties);</span><br><span class="line">        kafkaConsumer.setStartFromLatest();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Flink 流关联 Kafka 消费者</span></span><br><span class="line">        DataStream&lt;String&gt; dataStream = env.addSource(kafkaConsumer);</span><br><span class="line">        dataStream.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="Kafka-集成-SpringBoot"><a href="#Kafka-集成-SpringBoot" class="headerlink" title="Kafka 集成 SpringBoot"></a>Kafka 集成 SpringBoot</h2><ul><li><a href="/posts/3db00pa3.html">SpringBoot 与 SpringCloud 整合 Kafka</a></li></ul><h2 id="Kafka-集成-SpringCloud"><a href="#Kafka-集成-SpringCloud" class="headerlink" title="Kafka 集成 SpringCloud"></a>Kafka 集成 SpringCloud</h2><ul><li><a href="/posts/8a5bf4c8.html">SpringBoot 与 SpringCloud 整合 Kafka</a></li></ul><div id="readmore-expansion" class="pjax"></div><link rel="stylesheet" type="text/css" href="https://qiniu.techgrow.cn/readmore/dist/hexo.css"><script data-pjax="" src="https://qiniu.techgrow.cn/readmore/dist/readmore.js" type="text/javascript"></script><script data-pjax="">var isMobile=navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i),allowMobile=!1;if(!isMobile||isMobile&&allowMobile)try{var plugin=new ReadmorePlugin;plugin.init({type:"hexo",id:"readmore-container",name:"全栈技术驿站",blogId:"96641-5333172926158-056",qrcode:"https://www.techgrow.cn/img/wx_mp_qr.png",keyword:"Tech",random:"1",height:"auto",expires:"365",lockToc:"yes",interval:"30",baseUrl:"",execute:"yes",tocSelector:""})}catch(e){console.warn("readmore plugin occurred error: "+e.name+" | "+e.message)}</script></div><footer class="post-footer"><div class="reward-container"><div>支持一根棒棒糖！</div> <button> 赞赏</button><div class="post-reward"><div> <img src="/img/pay_wx.png" alt="Clay 微信"> <span>微信</span></div><div> <img src="/img/pay_zfb.png" alt="Clay 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"> <strong>本文作者：</strong> Clay</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.techgrow.cn/posts/e73bffc6.html" title="Kafka 入门教程之六">https://www.techgrow.cn/posts/e73bffc6.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="contactme"><div class="social-list"><div class="social-item"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">欢迎添加博主微信，请备注 "博客"，届时会邀请您加入百人微信群</span><br> <img src="/img/wx_account_qr.png"></div></div></div><div class="post-tags"><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag"><i class="fa fa-tag"></i> 分布式</a><a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag"><i class="fa fa-tag"></i> 消息队列</a><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"><i class="fa fa-tag"></i> 大数据</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/e33a339c.html" rel="prev" title="Docker 安装 Oracle 11g 数据库"><i class="fa fa-angle-left"></i> Docker 安装 Oracle 11g 数据库</a></div><div class="post-nav-item"> <a href="/posts/b9ff615e.html" rel="next" title="Vagrant 快速创建 VirtualBox 虚拟机">Vagrant 快速创建 VirtualBox 虚拟机<i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments" id="waline"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> Copyright © 2018 – <span itemprop="copyrightYear">2025</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Clay</span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i></span> <span>站点总字数：</span> <span title="站点总字数">2.2m</span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span>站点阅读时长 ≈</span> <span title="站点阅读时长">33:23</span></span></div><div id="site-runtime"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span><span id="runtime"></span></div><script language="javascript">function isPC(){for(var e=navigator.userAgent,t=["Android","iPhone","SymbianOS","Windows Phone","iPad","iPod"],n=0;n<t.length;n++)if(0<e.indexOf(t[n]))return!1;return!0}function siteTime(e,t){window.setTimeout("siteTime(openOnPC, start)",1e3);var n=36e5,o=24*n;t=new Date("2018-12-27 08:00:00");var i=new Date,r=(i.getFullYear(),i.getMonth(),i.getDate(),i.getHours(),i.getMinutes(),i.getSeconds(),i-t),a=Math.floor(r/31536e6),s=Math.floor(r/o-365*a),d=Math.floor((r-(365*a+s)*o)/n),l=Math.floor((r-(365*a+s)*o-d*n)/6e4),u=Math.floor((r-(365*a+s)*o-d*n-6e4*l)/1e3);document.getElementById("runtime").innerHTML="Powered by Hexo & Docker | "+a+" 年 "+s+" 日 "+d+" 小时 "+l+" 分钟 "+u+" 秒 "}var showOnMobile=!1,openOnPC=isPC(),start=new Date;siteTime(openOnPC,start),openOnPC||showOnMobile||(document.getElementById("site-runtime").style.display="none")</script><div class="beian"> <span><img src="/img/gonganbeian.png" alt=""></span> <span><a href="https://beian.miit.gov.cn/" rel="external nofollow" target="_blank">粤ICP备 19024664号-1</a></span> <span>|&nbsp;</span> <span><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44011302004035" rel="external nofollow" target="_blank">粤公网安备 44011302004035号</a></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div><div class="sidebar-dimmer"></div> <a href="https://github.com/rqh656418510" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="external nofollow" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="200" alpha="0.5" zindex="-1" src="/lib/ribbon.js/dist/ribbon.min.js"></script><script src="/lib/animejs/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="/lib/@next-theme/pjax/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script><script src="/lib/medium-zoom/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script><script src="/lib/lozad/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script><script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"/lib/pdfobject/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script><script src="/js/third-party/tags/pdf.js"></script><script src="/js/third-party/pace.js"></script><script data-pjax="" async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://www.techgrow.cn/lib/darkmode/darkmode@1.5.7.min.js"></script><script>
var options = {
  bottom: '64px',
  right: '30px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#282828',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script><script src="https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js"></script><script>
    var qiniu_domain = "https://oss.techgrow.cn";
    var qiniu_token_url = "https://open.techgrow.cn/api/oss/qiniu/token/upload";
    var qiniu_debug = "true" === "false";

    // date format
    Date.prototype.format = function (fmt) {
      var o = {
        "M+": this.getMonth() + 1,
        "d+": this.getDate(),
        "h+": this.getHours(),
        "m+": this.getMinutes(),
        "s+": this.getSeconds(),
        "q+": Math.floor((this.getMonth() + 3) / 3),
        "S": this.getMilliseconds()
      };
      if (/(y+)/.test(fmt)) {
        fmt = fmt.replace(RegExp.$1, (this.getFullYear() + "").substr(4 - RegExp.$1.length));
      }
      for (var k in o) {
        if (new RegExp("(" + k + ")").test(fmt)) {
          fmt = fmt.replace(
            RegExp.$1,
            (RegExp.$1.length == 1)
              ? (o[k])
              : (("00" + o[k]).substr(("" + o[k]).length))
          );
        }
      }
      return fmt;
    }

    // generate uuid
    function uuid() {
      var s = [];
      var hexDigits = "0123456789abcdef";
      for (var i = 0; i < 36; i++) {
        s[i] = hexDigits.substr(Math.floor(Math.random() * 0x10), 1);
      }
      s[14] = "4";
      s[19] = hexDigits.substr((s[19] & 0x3) | 0x8, 1);
      s[8] = s[13] = s[18] = s[23] = "-";
      var uuid = s.join("");
      return uuid;
    }

    // sync get request
    function syncGet(url) {
      var xhr = null;
      if (window.XMLHttpRequest) {
        xhr = new XMLHttpRequest();
      } else {
        xhr = new ActiveXObject("Microsoft.XMLHTTP");
      }
      xhr.open('GET', url, false);
      xhr.send();
      return xhr;
    }

    // get upload file path
    function getUploadFilePath() {
      var now = new Date();
      var name = uuid().replace(/-/g, "");
      var nowStr = now.format("/yyyy/MM/dd/");
      return "uploads" + nowStr + name;
    }

    // get qiniu upload token
    function getUploadToken() {
      try {
        var xhr = syncGet(qiniu_token_url);
        var responseStatus = xhr.status;
        var responseJson = JSON.parse(xhr.responseText);
        if (responseStatus === 200) {
          return responseJson.data;
        } else if (responseStatus === 403) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，非法请求来源！");
        } else if (responseStatus === 429) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，上传过于频繁！");
        } else if (responseStatus === 500) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，系统内部出错！");
        } else {
          alert("图片上传失败，无法获取UploadToken，未知Http响应状态码！");
        }
      } catch (err) {
        if (qiniu_debug) {
          console.error(err);
        }
        alert("图片上传失败，无法获取UploadToken，未知错误！");
      }
      return null;
    }

    // qiniu upload image
    async function qiniuUploadImage(file) {
      var image_path = null;
      await uploadImage(file).then(function onFulfilled(res) {
        image_path = res;
      }).catch(function onRejected(err) {
        if (qiniu_debug) {
          console.error(err);
        }
      });
      return image_path;
    }

    // upload image
    function uploadImage(file) {
      return new Promise((resolve, reject) => {
        var config = null;
        var putExtra = null;
        var token = getUploadToken();
        var key = getUploadFilePath();
        // upload init
        var observable = qiniu.upload(file, key, token, putExtra, config);
        // upload start
        observable.subscribe({
          next(res) {
            // upload progress
          },
          error(err) {
            // upload falied
            reject("falied to upload image for qiniu: " + err.name);
          },
          complete(res) {
            // upload successed
            resolve(qiniu_domain + "/" + key);
          }
        });
      });
    }
  </script><script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://waline.techgrow.cn","cssUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css","commentCount":true,"pageview":false,"copyright":false,"allowUploadImage":true,"libUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.js","locale":{"placeholder":"支持匿名评论啦，若希望及时收到博主的反馈，建议登录评论或者在上方的邮箱输入框留下邮箱地址哦 (๑•̀ㅂ•́)و✧"},"dark":"body.darkmode--activated","emoji":["https://www.techgrow.cn/lib/@waline/emojis/1.0.1/weibo"],"meta":["nick","mail","link"],"login":"enable","pageSize":10,"qiniuDebug":false,"qiniuDomain":"https://oss.techgrow.cn","qiniuTokenUrl":"https://open.techgrow.cn/api/oss/qiniu/token/upload","qiniuLibUrl":"https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js","el":"#waline","comment":true,"path":"/posts/e73bffc6.html"}</script><link rel="stylesheet" href="https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css"><script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.waline.allowUploadImage) {
    CONFIG.waline.imageUploader = false;
  }
  else if (CONFIG.waline.qiniuDomain && CONFIG.waline.qiniuTokenUrl) {
    CONFIG.waline.imageUploader = qiniuUploadImage;
  } else {
   CONFIG.waline.imageUploader = true;
  }
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script><div class="moon-menu"><div class="moon-menu-items"><div id="moon-menu-item-back2bottom" class="moon-menu-item"><i class="fas fa-chevron-down"></i></div><div id="moon-menu-item-back2top" class="moon-menu-item"><i class="fas fa-chevron-up"></i></div></div><div class="moon-menu-button"><svg class="moon-menu-bg"><circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle><circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle></svg><div class="moon-menu-content"><div class="moon-menu-icon"><i class="fas fa-ellipsis-v"></i></div><div class="moon-menu-text"></div></div></div></div><script src="/js/injector.js"></script><div class="comments" id="waline-comments" style="display:none"></div><script>function isMobile(){var i=navigator.userAgent.toLowerCase(),e="ipad"==i.match(/ipad/i),a="iphone os"==i.match(/iphone os/i),o="midp"==i.match(/midp/i),n="rv:1.2.3.4"==i.match(/rv:1.2.3.4/i),r="ucweb"==i.match(/ucweb/i),c="android"==i.match(/android/i),l="windows ce"==i.match(/windows ce/i),d="windows mobile"==i.match(/windows mobile/i);return!!(e||a||o||n||r||c||l||d)}var openOnMobile=isMobile(),showOnMobile=!1,aplayerEnable=!0;jQuery(document).ready(function(){aplayerEnable&&(openOnMobile&&!showOnMobile||jQuery("#aplayer").css("display","block"))}),jQuery(window).on("load",function(){aplayerEnable&&jQuery(".aplayer\\-icon.aplayer\\-icon\\-lrc").trigger("click")})</script></body></html>