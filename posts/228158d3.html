<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CRoboto+Slab:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic&amp;display=swap&amp;subset=latin,latin-ext"><link rel="stylesheet" href="/lib/@fortawesome/fontawesome-free/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/animate.css/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/pace-js/themes/blue/pace-theme-minimal.css"><script src="/lib/pace-js/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.techgrow.cn","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script><meta name="description" content="本文主要介绍 Kafka 的使用教程。"><meta property="og:type" content="article"><meta property="og:title" content="Kafka 入门教程之三"><meta property="og:url" content="https://www.techgrow.cn/posts/228158d3.html"><meta property="og:site_name" content="Clay 的技术空间"><meta property="og:description" content="本文主要介绍 Kafka 的使用教程。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-10.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-11.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-12.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-file-store.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-file-store-2.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-file-store-3.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-file-store-6.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-15.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-18.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-19.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/01/kafka-partition-1.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-17.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-16.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-leader-partition-balancer-1.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-leader-partition-balancer-2.png"><meta property="article:published_time" content="2022-08-21T14:13:45.000Z"><meta property="article:modified_time" content="2022-08-21T14:13:45.000Z"><meta property="article:author" content="Clay"><meta property="article:tag" content="分布式"><meta property="article:tag" content="消息队列"><meta property="article:tag" content="大数据"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.techgrow.cn/asset/2023/12/kafka-producer-10.png"><link rel="canonical" href="https://www.techgrow.cn/posts/228158d3.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.techgrow.cn/posts/228158d3.html","path":"posts/228158d3.html","title":"Kafka 入门教程之三"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Kafka 入门教程之三 | Clay 的技术空间</title><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-135294383-1"></script><script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-135294383-1","only_pageview":false,"measure_protocol_api_secret":null}</script><script src="/js/third-party/analytics/google-analytics.js"></script><script class="next-config" data-name="baidu_analytics" type="application/json">"84c09b30349a65573c5c642ff336969b"</script><script src="/js/third-party/analytics/baidu-analytics.js"></script><link rel="dns-prefetch" href="https://waline.techgrow.cn"><link rel="stylesheet" type="text/css" href="/css/injector/main.css"><link rel="preload" as="style" href="/css/injector/light.css"><link rel="preload" as="style" href="/css/injector/dark.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><style>.admonition{margin:1.5625em 0;padding:.6rem;overflow:hidden;font-size:.64rem;page-break-inside:avoid;border-left:.3rem solid #42b983;border-radius:.3rem;box-shadow:0 .1rem .4rem rgba(0,0,0,.05),0 0 .05rem rgba(0,0,0,.1);background-color:#fafafa}p.admonition-title{position:relative;margin:-.6rem -.6rem .8em -.6rem!important;padding:.4rem .6rem .4rem 2.5rem;font-weight:700;background-color:rgba(66,185,131,.1)}.admonition-title::before{position:absolute;top:.9rem;left:1rem;width:12px;height:12px;background-color:#42b983;border-radius:50%;content:' '}.info>.admonition-title,.todo>.admonition-title{background-color:rgba(0,184,212,.1)}.attention>.admonition-title,.caution>.admonition-title,.warning>.admonition-title{background-color:rgba(255,145,0,.1)}.error>.admonition-title,.fail>.admonition-title,.failure>.admonition-title,.missing>.admonition-title{background-color:rgba(255,82,82,.1)}.admonition.info,.admonition.todo{border-color:#00b8d4}.admonition.attention,.admonition.caution,.admonition.warning{border-color:#ff9100}.admonition.error,.admonition.fail,.admonition.failure,.admonition.missing{border-color:#ff5252}.info>.admonition-title::before,.todo>.admonition-title::before{background-color:#00b8d4;border-radius:50%}.attention>.admonition-title::before,.caution>.admonition-title::before,.warning>.admonition-title::before{background-color:#ff9100;border-radius:50%}.error>.admonition-title::before,.fail>.admonition-title::before,.failure>.admonition-title::before,.missing>.admonition-title::before{background-color:#ff5252;border-radius:50%}.admonition>:last-child{margin-bottom:0!important}</style><link rel="alternate" href="/atom.xml" title="Clay 的技术空间" type="application/atom+xml"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope="" itemtype="http://schema.org/WebPage" class="use-motion"><script src="/lib/jquery/dist/jquery.min.js"></script><script data-pjax="">!function(){var t=window.location.host;if(-1==t.indexOf("127.0.0.1")&&-1==t.indexOf("localhost")){var o=document.createElement("script"),e=window.location.protocol.split(":")[0];o.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(o,n)}}()</script><link rel="stylesheet" href="/lib/aplayer/dist/APlayer.min.css"><div id="aplayer" style="display:none"></div><script src="/lib/aplayer/dist/APlayer.min.js"></script><script src="/lib/aplayer/dist/color-thief.js"></script><script src="/lib/aplayer-init.js"></script><script src="https://res.wx.qq.com/open/js/jweixin-1.4.0.js"></script><script>function getTitle(){var t=jQuery("meta[property='og:title']");return t?t.attr("content"):""}function getDesc(){var t=jQuery("meta[property='og:description']");return t?t.attr("content"):""}function randomString(t){for(var e="ABCDEFGHJKMNPQRSTWXYZabcdefhijkmnprstwxyz2345678",n=e.length,i="",r=0;r<t;++r)i+=e.charAt(Math.floor(Math.random()*n));return i}function initWx(t){wx.config({debug:!1,appId:t.appId,nonceStr:t.nonceStr,signature:t.signature,timestamp:t.timestamp,jsApiList:["checkJsApi","onMenuShareTimeline","onMenuShareAppMessage","onMenuShareQQ"]}),wx.ready(function(){wx.onMenuShareTimeline({title:t.title,link:t.link,imgUrl:t.imgUrl,success:function(){}}),wx.onMenuShareAppMessage({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,type:"link",dataUrl:"",success:function(){}}),wx.onMenuShareQQ({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,success:function(){},cancel:function(){}})}),wx.error(function(t){})}jQuery(function(){var e=getDesc(),n=getTitle(),i=randomString(16),r=(new Date).getTime(),a=window.location.href,t="https://open.techgrow.cn/app/api/wechat/js/signature?url="+a+"&noncestr="+i+"&timestamp="+r;jQuery.getJSON(t,function(t){initWx({desc:e,title:n,link:a,nonceStr:i,timestamp:r,signature:t.data,appId:"wx1fcf69355af43d41",imgUrl:"https://www.techgrow.cn/img/wx_share.jpg"})})})</script><div style="display:none"><img src="https://www.techgrow.cn/img/wx_share.jpg" alt=""></div><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">Clay 的技术空间</p><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">用进废退 | 艺不压身</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-search"><a href="/search" rel="section"><i class="fa fa-search fa-fw"></i>搜索</a></li><li class="menu-item menu-item-links"><a href="/links" rel="section"><i class="fas fa-link fa-fw"></i>友链</a></li><li class="menu-item menu-item-readingnotes"><a href="https://www.techgrow.cn/reading/" rel="section"><i class="fa fa-book-open-reader fa-fw"></i>读书笔记</a></li><li class="menu-item menu-item-commentmanage"><a href="https://waline.techgrow.cn/" rel="external nofollow" target="_blank"><i class="fa fa-comment fa-fw"></i>评论管理</a></li></ul></nav></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E7%BA%B2"><span class="nav-text">大纲</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-text">前言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90"><span class="nav-text">学习资源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-Broker"><span class="nav-text">Kafka Broker</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Zookeeper-%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84"><span class="nav-text">Zookeeper 存储结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B4%E4%BD%93%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="nav-text">整体的工作流程图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Broker-%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0"><span class="nav-text">Broker 的核心参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Broker-%E7%9A%84%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="nav-text">Broker 的文件存储</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="nav-text">文件存储机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE"><span class="nav-text">文件存储位置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E8%AF%A6%E8%A7%A3"><span class="nav-text">文件内容详解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E6%B8%85%E9%99%A4%E7%AD%96%E7%95%A5"><span class="nav-text">文件清除策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99"><span class="nav-text">文件高效读写</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E6%8B%9F-Broker-%E4%B8%8A%E4%B8%8B%E7%BA%BF"><span class="nav-text">模拟 Broker 上下线</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E5%89%AF%E6%9C%AC"><span class="nav-text">Kafka 副本</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">副本的概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E7%9A%84%E9%80%89%E4%B8%BE"><span class="nav-text">副本的选举</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E7%9A%84-Leader-%E9%80%89%E4%B8%BE%E6%B5%81%E7%A8%8B"><span class="nav-text">副本的 Leader 选举流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E6%8B%9F%E5%89%AF%E6%9C%AC%E7%9A%84-Leader-%E9%80%89%E4%B8%BE"><span class="nav-text">模拟副本的 Leader 选举</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E7%9A%84%E5%88%86%E9%85%8D"><span class="nav-text">副本的分配</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E6%8B%9F%E5%89%AF%E6%9C%AC%E5%88%86%E9%85%8D"><span class="nav-text">模拟副本分配</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E8%B0%83%E6%95%B4%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8"><span class="nav-text">手动调整副本存储</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E7%9A%84%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="nav-text">副本的故障处理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E7%9A%84-Leader-%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="nav-text">副本的 Leader 故障处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E7%9A%84-Follower-%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="nav-text">副本的 Follower 故障处理</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-Broker-%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="nav-text">Kafka Broker 的最佳实践</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%8D%E5%BD%B9%E6%96%B0%E8%8A%82%E7%82%B9"><span class="nav-text">服役新节点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%96%B0%E8%8A%82%E7%82%B9"><span class="nav-text">创建新节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB"><span class="nav-text">执行数据迁移</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%80%E5%BD%B9%E6%97%A7%E8%8A%82%E7%82%B9"><span class="nav-text">退役旧节点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB-1"><span class="nav-text">执行数据迁移</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E9%97%AD%E6%97%A7%E8%8A%82%E7%82%B9"><span class="nav-text">关闭旧节点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A2%9E%E5%8A%A0%E5%88%86%E5%8C%BA%E6%95%B0%E9%87%8F"><span class="nav-text">增加分区数量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BA%E4%B8%BB%E9%A2%98"><span class="nav-text">自动创建主题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E5%89%AF%E6%9C%AC%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="nav-text">Kafka 副本的最佳实践</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E5%A2%9E%E5%8A%A0%E5%89%AF%E6%9C%AC%E7%9A%84%E6%95%B0%E9%87%8F"><span class="nav-text">动态增加副本的数量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Leader-Partition-%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1"><span class="nav-text">Leader Partition 负载平衡</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope="" itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="Clay" src="/img/head.jpg"></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"> <span class="site-state-item-count">662</span> <span class="site-state-item-name">文章</span></div><div class="site-state-item site-state-tags"> <span class="site-state-item-count">55</span> <span class="site-state-item-name">标签</span></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/rqh656418510" title="GitHub → https://github.com/rqh656418510" rel="external nofollow" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:rong656418510@gmail.com" title="E-Mail → mailto:rong656418510@gmail.com" rel="external nofollow" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="/atom.xml" title="RSS → /atom.xml" rel="noopener me"><i class="fa fa-rss fa-fw"></i> RSS</a></span><span class="links-of-author-item"><a href="/sitemap.xml" title="SiteMap → /sitemap.xml" rel="noopener me"><i class="fa fa-sitemap fa-fw"></i> SiteMap</a></span></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope="" itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.techgrow.cn/posts/228158d3.html"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="image" content="/img/head.jpg"><meta itemprop="name" content="Clay"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Clay 的技术空间"><meta itemprop="description" content="专注于 Java 后端、分布式、微服务、云原生、数据库、系统架构、大数据、云计算、虚拟化、人工智能学习的技术博客。"></span><span hidden="" itemprop="post" itemscope="" itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Kafka 入门教程之三 | Clay 的技术空间"><meta itemprop="description" content="本文主要介绍 Kafka 的使用教程。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Kafka 入门教程之三</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-08-21 22:13:45" itemprop="dateCreated datePublished" datetime="2022-08-21T22:13:45+08:00">2022-08-21</time></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i></span> <span class="post-meta-item-text">评论数：</span><a title="waline" href="/posts/228158d3.html#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/228158d3.html" itemprop="commentCount"></span></a></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>8.2k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 ≈</span> <span>7 分钟</span></span></div></div></header><div class="post-body post-container" itemprop="articleBody" id="readmore-container"><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/b6be8183.html">Kafka 入门教程之一</a>、<a href="/posts/60ddcede.html">Kafka 入门教程之二</a>、<a href="/posts/228158d3.html">Kafka 入门教程之三</a></li><li><a href="/posts/c61757ff.html">Kafka 入门教程之四</a>、<a href="/posts/ed9d5bd.html">Kafka 入门教程之五</a>、<a href="/posts/e73bffc6.html">Kafka 入门教程之六</a></li><li><a href="/posts/50c7d080.html">Kafka 入门教程之七</a></li></ul><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h3><ul><li><a target="_blank" rel="external nofollow" href="https://kafka.apache.org/documentation/">Kafka 官方文档</a></li><li><a href="/posts/ac64f898.html">Kafka 学习路线</a></li></ul><span id="more"></span><h2 id="Kafka-Broker"><a href="#Kafka-Broker" class="headerlink" title="Kafka Broker"></a>Kafka Broker</h2><h3 id="Zookeeper-存储结构"><a href="#Zookeeper-存储结构" class="headerlink" title="Zookeeper 存储结构"></a>Zookeeper 存储结构</h3><div class="admonition note"><p class="admonition-title">提示</p><p>在 Kafka 的 ZooKeeper 模式架构中，会在集群中选举一个 Broker 作为唯一的 Controller，该 Controller 负责管理集群 Broker 的上下线，包括所有 Topic 的分区副本分配和分区副本 Leader 选举等工作。另外，Controller 的信息同步工作是依赖于 Zookeeper 的，其中 Kafka 在 Zookeeper 中的存储结构如下图所示：</p></div><p><img data-src="../../../asset/2023/12/kafka-producer-10.png"></p><h3 id="整体的工作流程图"><a href="#整体的工作流程图" class="headerlink" title="整体的工作流程图"></a>整体的工作流程图</h3><p><img data-src="../../../asset/2023/12/kafka-producer-11.png"></p><h3 id="Broker-的核心参数"><a href="#Broker-的核心参数" class="headerlink" title="Broker 的核心参数"></a>Broker 的核心参数</h3><p><img data-src="../../../asset/2023/12/kafka-producer-12.png"></p><h3 id="Broker-的文件存储"><a href="#Broker-的文件存储" class="headerlink" title="Broker 的文件存储"></a>Broker 的文件存储</h3><h4 id="文件存储机制"><a href="#文件存储机制" class="headerlink" title="文件存储机制"></a>文件存储机制</h4><p>在 Kafka 中，Topic 是逻辑上的概念，而 Partition 是物理上的概念，每个 Partition 对应于一个 Log 文件，该 Log 文件中存储的就是 Producer 生产的数据。Producer 生产的数据会被不断追加到该 Log 文件末端，为防止 Log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制，将每个 Partition 分为多个 Segment。每个 Segment 都包含了 <code>.log</code> 文件、<code>.index</code> 文件和 <code>.timeindex</code> 等文件。这些文件位于同一个文件夹下，该文件夹的命名规则为 <code>Topic 名称 + 分区序号</code>，比如 <code>first-0</code>。</p><p><img data-src="../../../asset/2024/11/kafka-file-store.png"></p><h4 id="文件存储位置"><a href="#文件存储位置" class="headerlink" title="文件存储位置"></a>文件存储位置</h4><div class="admonition note"><p class="admonition-title">思考问题</p><p>当生产者发送消息到 Kafka 后，Topic 数据（消息数据）到底存储在什么位置？</p></div><p>(1) 启动生产者，并发送消息</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node01 kafka]$ bin/kafka-console-producer.sh --bootstrap-server node01:9092 --topic first</span><br></pre></td></tr></tbody></table></figure><p>(2) 查看 node01（或者 node02、node03）的 <code>kafka/datas/first-0（或者 first-1、first-2）</code> 路径上的文件列表</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[centos@node01 kafka]$ ls ./datas/first-0</span><br><span class="line"></span><br><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000000000.timeindex</span><br><span class="line">leader-epoch-checkpoint</span><br><span class="line">partition.metadata</span><br></pre></td></tr></tbody></table></figure><p>(3) 直接查看 <code>.log</code> 文件的内容，发现是乱码</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node01 first-0]$ cat 00000000000000000000.log</span><br></pre></td></tr></tbody></table></figure><p>(4) 通过工具查看 <code>.log</code> 文件的内容，输出字段的介绍请看 <a href="../../../asset/2024/12/kafka-log-data.png">这里</a></p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node01 kafka]$ bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files ./datas/first-0/00000000000000000000.log --print-data-log</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Dumping ../datas/first-0/00000000000000000000.log</span><br><span class="line">Log starting offset: 0</span><br><span class="line">baseOffset: 18 lastOffset: 18 count: 1 baseSequence: 2 lastSequence: 2 producerId: 1001 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 4040 CreateTime: 1734184179506 size: 68 magic: 2 compresscodec: none crc: 799683847 isvalid: true</span><br><span class="line">| offset: 18 CreateTime: 1734184179506 keySize: -1 valueSize: 0 sequence: 2 headerKeys: [] payload: java</span><br><span class="line">baseOffset: 19 lastOffset: 19 count: 1 baseSequence: 3 lastSequence: 3 producerId: 1001 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 4108 CreateTime: 1734184184516 size: 69 magic: 2 compresscodec: none crc: 769781493 isvalid: true</span><br><span class="line">| offset: 19 CreateTime: 1734184184516 keySize: -1 valueSize: 1 sequence: 3 headerKeys: [] payload: python</span><br><span class="line">baseOffset: 20 lastOffset: 20 count: 1 baseSequence: 0 lastSequence: 0 producerId: 2000 producerEpoch: 0 partitionLeaderEpoch: 4 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 4177 CreateTime: 1734414249682 size: 73 magic: 2 compresscodec: none crc: 3581754326 isvalid: true</span><br><span class="line">| offset: 20 CreateTime: 1734414249682 keySize: -1 valueSize: 5 sequence: 0 headerKeys: [] payload: golang</span><br></pre></td></tr></tbody></table></figure><p>(5) 通过工具查看 <code>.index</code> 文件的内容</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node01 kafka]$ bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files ./datas/first-0/00000000000000000000.index</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Dumping ../datas/first-0/00000000000000000000.index</span><br><span class="line">offset: 0 position: 0</span><br></pre></td></tr></tbody></table></figure><h4 id="文件内容详解"><a href="#文件内容详解" class="headerlink" title="文件内容详解"></a>文件内容详解</h4><blockquote><p>Kafka 通过 offset 定位 Log 文件中的数据的流程如下：</p></blockquote><p><img data-src="../../../asset/2024/11/kafka-file-store-2.png"></p><blockquote><p>Kafka 日志存储的配置参数如下：</p></blockquote><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td><code>log.segment.bytes</code></td><td>Kafka 中 Log 日志是分成一块块存储的，此配置是指 Log 日志划分成块的大小，<code>默认值是 1G</code>。</td></tr><tr><td><code>log.index.interval.bytes</code></td><td><code>默认值是 4kb</code>，表示在 Kafka 里面每当写入了 4kb 大小的日志（<code>.log</code>）， 然后就会往 <code>.index</code> 文件里面记录一个索引（稀疏索引）。</td></tr></tbody></table><h4 id="文件清除策略"><a href="#文件清除策略" class="headerlink" title="文件清除策略"></a>文件清除策略</h4><p>Kafka 中默认的日志（即消息数据）保存时间为 7 天，可以通过调整如下参数来修改保存时间。</p><ul><li><code>log.retention.hours</code>：小时（最低优先级），默认 7 天。</li><li><code>log.retention.minutes</code>：分钟。</li><li><code>log.retention.ms</code>：毫秒（最高优先级）。</li><li><code>log.retention.check.interval.ms</code>：日志检查周期，默认 5 分钟。</li></ul><blockquote><p>思考：Kafka 中的日志一旦超过了设置的保存时间，那么日志会被怎么处理呢？</p></blockquote><p>Kafka 中提供的日志清理策略有两种：<code>delete</code> 和 <code>compact</code>。</p><ul><li><strong>delete（日志删除）</strong><ul><li>会将过期的日志文件删除掉</li><li><code>log.cleanup.policy=delete</code>：该配置参数表示所有日志数据都启用删除策略<ul><li>基于时间删除：默认开启。以 Segment 中所有记录中的最大时间戳作为该文件时间戳。</li><li>基于大小删除：默认关闭。当超过设置的所有日志总大小，就删除最早的 Segment。配置参数是 <code>log.retention.bytes</code>，默认值是 <code>-1</code>，表示无穷大。</li></ul></li></ul></li></ul><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li>如果一个 Segment 中有一部分数据过期，但一部分数据没有过期（<a href="../../../asset/2024/11/kafka-file-store-4.png">如果所示</a>），那 Kafka 会怎么处理？</li><li>由于 Kafka 默认是基于时间删除日志数据的，因此会以一个 Segment 中所有记录中的最大时间戳作为该文件时间戳，只有该时间戳过期了，才会删除该 Segment 中的所有记录。简而言之，只有等该 Segment 中的数据全部过期了，Kafka 才会删除数据。</li></ul></div><ul><li><strong>compact（日志压缩）</strong><ul><li>针对相同 key 的不同 value 值，只保留最后一个版本（如下图所示）。</li><li><code>log.cleanup.policy=compact</code>：该配置参数表示所有日志数据都启用压缩策略。</li><li><img data-src="../../../asset/2024/11/kafka-file-store-3.png"></li><li>日志压缩后的 offset 可能是不连续的，比如上图中没有数据 6。当从这些 offset 消费消息时，将会拿到比这个 offset 大的 offset 对应的消息，比如实际上会拿到 offset 为 7 的消息，并从这个位置开始消费。</li></ul></li></ul><div class="admonition warning"><p class="admonition-title">特别注意</p><p>日志压缩策略在生产环境中用得极少，只适合特殊场景。比如，消息的 key 是用户 ID，而 value 则是用户的资料；通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。</p></div><h4 id="文件高效读写"><a href="#文件高效读写" class="headerlink" title="文件高效读写"></a>文件高效读写</h4><p>Kafka 读写文件（如 <code>.log</code> 文件）非常高效，其主要原因有以下几个：</p><ul><li>(1) Kafka 本身支持分布式集群，可以采用分区技术，并行度较高。</li><li>(2) Kafka 读取数据采用了稀疏索引，可以快速定位需要消费的数据。</li><li>(3) Kafka 是顺序写磁盘，写效率较高。<ul><li>Kafka 的 Producer 生产数据，要写入到 Log 文件时，写的过程是一直追加到文件末端，也就是顺序写。</li><li>Kafka 官网有数据表明，同样的磁盘，顺序写能到 600M/s， 而随机写只有 100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间，<a href="../../../asset/2024/11/kafka-file-store-5.png">如图所示</a>。</li></ul></li><li>(4) Kafka 使用了页缓存 + 零拷贝技术<ul><li>页缓存<ul><li> Kafka 重度依赖底层操作系统提供的页缓存（PageCache）功能。实际上，PageCache 是将尽可能多的空闲内存都当做了磁盘缓存来使用。</li><li>当上层有写操作时，操作系统只是将数据写入 PageCache；当读操作发生时，先从 PageCache 中查找，如果找不到，再去磁盘中读取。</li></ul></li><li>零拷贝技术<ul><li>零拷贝技术主要用在 Kafka 的 Broker 中，尤其是在 Broker 将数据从磁盘读取并发送给消费者的过程中。</li><li>首先，数据从磁盘读取后被拷贝到内核空间，也就是操作系统内核的页缓存（Page Cache）。然后，Kafka 通过操作系统的 <code>sendfile</code> 系统调用，将数据直接从页缓存发送到网络缓冲区，避免了用户空间的拷贝操作（如下图所示），从而提升了数据传输性能和资源利用效率。</li><li><img data-src="../../../asset/2024/11/kafka-file-store-6.png"></li></ul></li></ul></li></ul><blockquote><p>思考：Kafka 重度依赖底层操作系统提供的页缓存（PageCache）功能，那么在写入数据时，如果 PageCache 没来得及落盘（刷写到磁盘），系统就宕机了（如断电），这是否有可能丢失数据呢？</p></blockquote><p>在写入数据时，如果 PageCache 还没来得及将数据刷写到磁盘，并且在此期间发生了系统故障（如断电或崩溃），确实可能会导致数据丢失。不过，Kafka 通过以下机制尽量降低这种风险：</p><ul><li><p><strong>Kafka 主动刷盘（fsync）</strong>：</p><ul><li>Kafka 允许使用配置参数 <code>log.flush.interval.messages</code> 和 <code>log.flush.interval.ms</code>，可以控制写入日志的消息数量或时间间隔后强制调用 <code>fsync</code>，确保 PageCache 中的数据被同步到磁盘。</li></ul></li><li><p><strong>操作系统的刷盘机制</strong>：</p><ul><li>操作系统会定期将 PageCache 中的数据刷写到磁盘（例如 Linux 的 <code>dirty_writeback_interval</code> 配置），但这不是实时的，因此仍可能有短时间窗口导致数据未落盘。</li></ul></li><li><p><strong>数据副本机制</strong>：</p><ul><li>Kafka 的 <strong>ISR（In-Sync Replica）机制</strong> 会在多个副本中同步数据，只有数据被至少一个副本确认后，生产者才会收到 ACK。这意味着，即使 PageCache 中的数据未落盘，但副本中的数据可以作为备份。</li></ul></li></ul><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td><code>log.flush.interval.messages</code></td><td>每个分区在写入指定数量的消息后触发一次刷盘操作（将数据从页缓存刷入磁盘），默认值是 <code>Long</code> 的最大值 9223372036854775807，表示不会基于消息数量自动触发刷盘。一般不建议修改，交给系统自己管理。</td></tr><tr><td><code>log.flush.interval.ms</code></td><td>每隔多长时间，触发一次刷盘操作（将数据从页缓存刷入磁盘），默认值是 <code>null</code>。一般不建议修改，交给系统自己管理。</td></tr></tbody></table><div class="admonition note"><p class="admonition-title">总结</p><p>尽管 PageCache 提供了性能优化，但 Kafka 的可靠性主要依赖副本机制。如果系统故障发生在数据落盘之前，单个节点上的数据可能会丢失，但 Kafka 通过多副本机制保证了整体的数据可靠性。</p></div><h3 id="模拟-Broker-上下线"><a href="#模拟-Broker-上下线" class="headerlink" title="模拟 Broker 上下线"></a>模拟 Broker 上下线</h3><blockquote><p>假设 Kafka 集群有三个节点（Broker），这里模拟 Kafka 上下线，然后观察 Zookeeper 中的数据变化。</p></blockquote><p>(1) 查看 <code>/kafka/brokers/ids</code> 路径上的节点。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] ls /kafka/brokers/ids</span><br><span class="line"></span><br><span class="line">[0, 1, 2]</span><br></pre></td></tr></tbody></table></figure><p>(2) 查看 <code>/kafka/controller</code> 路径上的数据。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] get /kafka/controller</span><br><span class="line"></span><br><span class="line">{"version":1,"brokerid":0,"timestamp":"1637292471777"}</span><br></pre></td></tr></tbody></table></figure><p>(3) 查看 <code>/kafka/brokers/topics/first/partitions/0/state</code> 路径上的数据。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] get /kafka/brokers/topics/first/partitions/0/state</span><br><span class="line"></span><br><span class="line">{"controller_epoch":24,"leader":0,"version":1,"leader_epoch":18,"isr":[0,1,2]}</span><br></pre></td></tr></tbody></table></figure><p>(4) 关闭 node03 节点上的 Kafka。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node03 kafka]$ bin/kafka-server-stop.sh</span><br></pre></td></tr></tbody></table></figure><p>(5) 再次查看 <code>/kafka/brokers/ids</code> 路径上的节点。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] ls /kafka/brokers/ids</span><br><span class="line"></span><br><span class="line">[0, 1]</span><br></pre></td></tr></tbody></table></figure><p>(6) 再次查看 <code>/kafka/controller</code> 路径上的数据。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] get /kafka/controller</span><br><span class="line"></span><br><span class="line">{"version":1,"brokerid":0,"timestamp":"1637292471777"}</span><br></pre></td></tr></tbody></table></figure><p>(7) 再次查看 <code>/kafka/brokers/topics/first/partitions/0/state</code> 路径上的数据。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] get /kafka/brokers/topics/first/partitions/0/state</span><br><span class="line"></span><br><span class="line">{"controller_epoch":24,"leader":0,"version":1,"leader_epoch":18,"isr":[0,1]}</span><br></pre></td></tr></tbody></table></figure><p>(8) 启动 node03 节点上的 Kafka。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node03 kafka]$ bin/kafka-server-start.sh -daemon ./config/server.properties</span><br></pre></td></tr></tbody></table></figure><p>(9) 再次观察 (1)、(2)、(3) 步骤中的内容。</p><h2 id="Kafka-副本"><a href="#Kafka-副本" class="headerlink" title="Kafka 副本"></a>Kafka 副本</h2><h3 id="副本的概念"><a href="#副本的概念" class="headerlink" title="副本的概念"></a>副本的概念</h3><ul><li>Kafka 副本的作用是提高数据可靠性。</li><li>Kafka 默认的副本数量为 1 个，生产环境一般配置为 2 个，这可以保证数据可靠性；但太多副本会增加磁盘存储空间，增加网络上的数据传输，降低运行效率。</li><li>Kafka 中副本分为 Leader 副本和 Follower 副本。Kafka 生产者只会将数据发往 Leader 副本，然后 Follower 副本会从 Leader 副本那里进行数据同步。</li><li>Kafka 分区中的所有副本统称为 AR（Assigned Repllicas）。<ul><li>AR = ISR + OSR</li><li><code>ISR</code>：表示和 Leader 保持同步的 Follower + Leader 集合，简称 <code>同步副本集合</code>。如果 Follower 长时间未向 Leader 发送通信请求或者同步数据，则该 Follower 将被踢出 ISR。该时间阈值由 <code>replica.lag.time.max.ms</code> 配置参数设定，默认 <code>30秒</code>。当 Leader 发生故障之后，就会从 ISR 中选举新的 Leader。</li><li><code>OSR</code>：表示 Follower 与 Leader 同步数据时，数据同步延迟过高的副本。</li></ul></li></ul><h3 id="副本的选举"><a href="#副本的选举" class="headerlink" title="副本的选举"></a>副本的选举</h3><h4 id="副本的-Leader-选举流程"><a href="#副本的-Leader-选举流程" class="headerlink" title="副本的 Leader 选举流程"></a>副本的 Leader 选举流程</h4><p>Kafka 集群中每一个 Broker 都含有一个 Controller，其中有一个 Broker 的 Controller 会被选举为 Controller Leader，负责管理集群 Broker 的上下线，包括所有 Topic 的分区副本分配和分区副本 Leader 选举等工作。另外，Controller 的信息同步工作是依赖于 Zookeeper 的。</p><p><img data-src="../../../asset/2023/12/kafka-producer-15.png"></p><h4 id="模拟副本的-Leader-选举"><a href="#模拟副本的-Leader-选举" class="headerlink" title="模拟副本的 Leader 选举"></a>模拟副本的 Leader 选举</h4><blockquote><p>这里假设 Kafka 集群有 4 个节点（Broker），分别是 broker0、broker1、broker2、broker3。</p></blockquote><p>(1) 创建一个新的 Topic，且拥有 4 个分区和 4 个副本</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --create --topic first --partitions 4 --replication-factor 4</span><br></pre></td></tr></tbody></table></figure><p>(2) 查看 Leader 的分布情况，其中的 <code>Replicas</code> 就是 AR（Assigned Repllicas）</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --describe --topic first</span><br><span class="line"></span><br><span class="line">Topic: first TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4</span><br><span class="line">Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first Partition: 0 Leader: 3 Replicas: 3,0,2,1 Isr: 3,0,2,1</span><br><span class="line">Topic: first Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,2,3,0</span><br><span class="line">Topic: first Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,3,1,2</span><br><span class="line">Topic: first Partition: 3 Leader: 2 Replicas: 2,1,0,3 Isr: 2,1,0,3</span><br></pre></td></tr></tbody></table></figure><p>(3) 关闭掉 node04 节点（<code>broker3</code>）上的 Kafka 进程</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node04 kafka]$ bin/kafka-server-stop.sh</span><br></pre></td></tr></tbody></table></figure><p>(4) 查看 Leader 的分布情况，可以发现分区 0 的 Leader 从 <code>broker3</code> 更换为 <code>broker0</code></p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --describe --topic first</span><br><span class="line"></span><br><span class="line">Topic: first TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4</span><br><span class="line">Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first Partition: 0 Leader: 0 Replicas: 3,0,2,1 Isr: 0,2,1</span><br><span class="line">Topic: first Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,2,0</span><br><span class="line">Topic: first Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,1,2</span><br><span class="line">Topic: first Partition: 3 Leader: 2 Replicas: 2,1,0,3 Isr: 2,1,0</span><br></pre></td></tr></tbody></table></figure><h3 id="副本的分配"><a href="#副本的分配" class="headerlink" title="副本的分配"></a>副本的分配</h3><h4 id="模拟副本分配"><a href="#模拟副本分配" class="headerlink" title="模拟副本分配"></a>模拟副本分配</h4><blockquote><p>假设 Kafka 集群有 4 个节点（Broker），分别是 broker0、broker1、broker2、broker3，当设置 Kafka 的分区数大于节点数时，Kafka 底层是如何分配存储副本呢？</p></blockquote><p>(1) 创建一个新的 Topic，且拥有 16 分区与 3 个副本</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --create --partitions 16 --replication-factor 3 --topic first</span><br></pre></td></tr></tbody></table></figure><p>(2) 查看分区和副本情况</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --describe --topic first</span><br></pre></td></tr></tbody></table></figure><p><img data-src="../../../asset/2023/12/kafka-producer-18.png"></p><p><img data-src="../../../asset/2023/12/kafka-producer-19.png"></p><h4 id="手动调整副本存储"><a href="#手动调整副本存储" class="headerlink" title="手动调整副本存储"></a>手动调整副本存储</h4><div class="admonition note"><p class="admonition-title">提示</p><p>在生产环境中，每台服务器的硬件配置和性能不一致，但是 Kafka 只会根据自己的代码规则创建对应的副本，就会导致个别服务器存储压力较大，所以往往需要手动调整副本的存储。</p></div><blockquote><p>假设 Kafka 集群有 4 个节点（Broker），分别是 broker0、broker1、broker2、broker3，在这基础上创建一个新的 Topic，名称为 <code>first</code>，拥有 4 个分区，2 个副本。最终需要将该 Topic 的所有副本都存储到 broker0 和 broker1 两台服务器上（如下图所示）。</p></blockquote><p><img data-src="../../../asset/2024/01/kafka-partition-1.png"></p><p>(1) 创建一个新的 Topic，名称为 <code>first</code>，拥有 4 个分区，2 个副本</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --create --topic first --partitions 4 --replication-factor 2</span><br></pre></td></tr></tbody></table></figure><p>(2) 查看副本的存储情况</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --describe --topic first</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Topic: first	TopicId: TCI_nvlpST28lUqUMDiaHw	PartitionCount: 4	ReplicationFactor: 2	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first	Partition: 0	Leader: 0	Replicas: 0,1	Isr: 0,1</span><br><span class="line">Topic: first	Partition: 1	Leader: 2	Replicas: 2,0	Isr: 2,0</span><br><span class="line">Topic: first	Partition: 2	Leader: 3	Replicas: 3,2	Isr: 3,2</span><br><span class="line">Topic: first	Partition: 3	Leader: 1	Replicas: 1,3	Isr: 1,3</span><br></pre></td></tr></tbody></table></figure><p>(3) 创建副本存储计划，将所有副本都存储在 broker0、broker1 中</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ vim increase-replication-factor.json</span><br><span class="line"></span><br><span class="line">{</span><br><span class="line">     <span class="string">"version"</span>: 1,</span><br><span class="line">     <span class="string">"partitions"</span>: [</span><br><span class="line">          {</span><br><span class="line">               <span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">               <span class="string">"partition"</span>: 0,</span><br><span class="line">               <span class="string">"replicas"</span>: [0, 1]</span><br><span class="line">          },</span><br><span class="line">          {</span><br><span class="line">               <span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">               <span class="string">"partition"</span>: 1,</span><br><span class="line">               <span class="string">"replicas"</span>: [0, 1]</span><br><span class="line">          },</span><br><span class="line">          {</span><br><span class="line">               <span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">               <span class="string">"partition"</span>: 2,</span><br><span class="line">               <span class="string">"replicas"</span>: [0, 1]</span><br><span class="line">          },</span><br><span class="line">          {</span><br><span class="line">               <span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">               <span class="string">"partition"</span>: 3,</span><br><span class="line">               <span class="string">"replicas"</span>: [0, 1]</span><br><span class="line">          }</span><br><span class="line">     ]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li>在上述 JSON 配置文件中，<code>replicas</code> 是指分区副本所在的 Broker ID。</li><li>比如，<code>"replicas": [0, 1]</code> 表示该分区的副本分别存储在 Broker 0 和 Broker 1 上。</li></ul></div><p>(4) 执行副本存储计划</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br></pre></td></tr></tbody></table></figure><p>(5) 验证副本存储计划的执行</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br></pre></td></tr></tbody></table></figure><p>(6) 查看副本的存储情况</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --describe --topic first</span><br></pre></td></tr></tbody></table></figure><p>可以发现所有副本都存储到 broker0 和 broker1 两台服务器上</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Topic: first	TopicId: TCI_nvlpST28lUqUMDiaHw	PartitionCount: 4	ReplicationFactor: 2	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first	Partition: 0	Leader: 0	Replicas: 0,1	Isr: 0,1</span><br><span class="line">Topic: first	Partition: 1	Leader: 0	Replicas: 0,1	Isr: 0,1</span><br><span class="line">Topic: first	Partition: 2	Leader: 1	Replicas: 1,0	Isr: 0,1</span><br><span class="line">Topic: first	Partition: 3	Leader: 1	Replicas: 1,0	Isr: 1,0</span><br></pre></td></tr></tbody></table></figure><h3 id="副本的故障处理"><a href="#副本的故障处理" class="headerlink" title="副本的故障处理"></a>副本的故障处理</h3><h4 id="副本的-Leader-故障处理"><a href="#副本的-Leader-故障处理" class="headerlink" title="副本的 Leader 故障处理"></a>副本的 Leader 故障处理</h4><p><img data-src="../../../asset/2023/12/kafka-producer-17.png"></p><h4 id="副本的-Follower-故障处理"><a href="#副本的-Follower-故障处理" class="headerlink" title="副本的 Follower 故障处理"></a>副本的 Follower 故障处理</h4><p><img data-src="../../../asset/2023/12/kafka-producer-16.png"></p><h2 id="Kafka-Broker-的最佳实践"><a href="#Kafka-Broker-的最佳实践" class="headerlink" title="Kafka Broker 的最佳实践"></a>Kafka Broker 的最佳实践</h2><h3 id="服役新节点"><a href="#服役新节点" class="headerlink" title="服役新节点"></a>服役新节点</h3><p>服役新节点指的是往 Kafka 集群中动态添加新的节点（Broker）。</p><div class="admonition warning"><p class="admonition-title">特别注意</p><p>将新节点（Broker）加入到 Kafka 集群后，需要手动将分区、副本的数据迁移到新节点上，否则新节点形同虚设。</p></div><h4 id="创建新节点"><a href="#创建新节点" class="headerlink" title="创建新节点"></a>创建新节点</h4><p>创建新的 Kafka 节点（Broker），并将其加入到已有的 Kafka 集群中，具体操作步骤这里不再累述。</p><h4 id="执行数据迁移"><a href="#执行数据迁移" class="headerlink" title="执行数据迁移"></a>执行数据迁移</h4><blockquote><p>这里假设 Kafka 集群原本有 3 个节点（broker0、broker1、broker2），然后新增了一个节点（<code>broker3</code>）。</p></blockquote><p>(1) 创建一个配置文件，指定要迁移数据的 Topic</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ vim topics-to-move.json</span><br><span class="line"></span><br><span class="line">{</span><br><span class="line">     <span class="string">"topics"</span>: [</span><br><span class="line">          {</span><br><span class="line">               <span class="string">"topic"</span>: <span class="string">"first"</span></span><br><span class="line">          }</span><br><span class="line">     ],</span><br><span class="line">     <span class="string">"version"</span>: 1</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>(2) 生成一个数据迁移计划，其中 <code>--broker-list "0,1,2,3"</code> 用于指定 Kafka 集群节点的 ID 列表，也就是说要将数据迁移到这几个节点上</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --topics-to-move-json-file topics-to-move.json --broker-list <span class="string">"0,1,2,3"</span> --generate</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Current partition replica assignment</span><br><span class="line">{"version":1,"partitions":[{"topic":"first","partition":0,"replicas":[0,2,1],"log_dirs":["any","any","any"]},{"topic":"first","partition":1,"replicas":[2,1,0],"log_dirs":["any","any","any"]},{"topic":"first","partition":2,"replicas":[1,0,2],"log_dirs":["any"," any","any"]}]}</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">{"version":1,"partitions":[{"topic":"first","partition":0,"replicas":[2,3,0],"log_dirs":["any","any","any"]},{"topic":"first","partition":1,"replicas":[3,0,1],"log_dirs":["any","any","any"]},{"topic":"first","partition":2,"replicas":[0,1,2],"log_dirs":["any"," any","any"]}]}</span><br></pre></td></tr></tbody></table></figure><p>(3) 拷贝步骤 <code>(2)</code> 生成的数据迁移计划，以此创建副本存储计划（所有副本存储在 broker0、broker1、broker2、broker3 中）</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ vim increase-replication-factor.json</span><br><span class="line"></span><br><span class="line">{</span><br><span class="line">	<span class="string">"version"</span>: 1,</span><br><span class="line">	<span class="string">"partitions"</span>: [{</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 0,</span><br><span class="line">		<span class="string">"replicas"</span>: [2, 3, 0],</span><br><span class="line">		<span class="string">"log_dirs"</span>: [<span class="string">"any"</span>, <span class="string">"any"</span>, <span class="string">"any"</span>]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 1,</span><br><span class="line">		<span class="string">"replicas"</span>: [3, 0, 1],</span><br><span class="line">		<span class="string">"log_dirs"</span>: [<span class="string">"any"</span>, <span class="string">"any"</span>, <span class="string">"any"</span>]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 2,</span><br><span class="line">		<span class="string">"replicas"</span>: [0, 1, 2],</span><br><span class="line">		<span class="string">"log_dirs"</span>: [<span class="string">"any"</span>, <span class="string">" any"</span>, <span class="string">"any"</span>]</span><br><span class="line">	}]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li>在上述 JSON 配置文件中，<code>replicas</code> 是指分区副本所在的 Broker ID。</li><li>比如，<code>"replicas": [0, 1, 2]</code> 表示该分区的副本分别存储在 Broker 0、Broker 1 和 Broker 2 上。</li></ul></div><p>(4) 执行副本存储计划</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br></pre></td></tr></tbody></table></figure><p>(5) 验证副本存储计划的执行</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition first-0 is complete.</span><br><span class="line">Reassignment of partition first-1 is complete.</span><br><span class="line">Reassignment of partition first-2 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 0,1,2,3</span><br><span class="line">Clearing topic-level throttles on topic first</span><br></pre></td></tr></tbody></table></figure><p>(6) 查看主题的详细信息，可以发现各个分区的副本数据会存储在新的 Kafka 节点（broker3）上</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --topic first --describe</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Topic: first     TopicId: _h3inqW0T5ye8kif1P1c3A PartitionCount: 3       ReplicationFactor: 3    Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first     Partition: 0    Leader: 0       Replicas: 0,3,1 Isr: 0,1,3</span><br><span class="line">Topic: first     Partition: 1    Leader: 1       Replicas: 1,0,2 Isr: 2,0,1</span><br><span class="line">Topic: first     Partition: 2    Leader: 2       Replicas: 2,1,3 Isr: 1,2,3</span><br></pre></td></tr></tbody></table></figure><h3 id="退役旧节点"><a href="#退役旧节点" class="headerlink" title="退役旧节点"></a>退役旧节点</h3><p>退役旧节点指的是从 Kafka 集群移除某个正在运行的节点（Broker）。</p><div class="admonition warning"><p class="admonition-title">特别注意</p><p>在移除某个正在运行的节点（Broker）之前，需要手动对分区、副本的数据进行迁移，否则可能会影响 Kafka 集群的正常运行。</p></div><h4 id="执行数据迁移-1"><a href="#执行数据迁移-1" class="headerlink" title="执行数据迁移"></a>执行数据迁移</h4><blockquote><p>这里假设 Kafka 集群原本有 4 个节点（broker0、broker1、broker2、broker3），先按照退役一台节点（如 <code>broker3</code>）来生成执行计划，然后按照节点服役时的操作流程来执行数据迁移操作。</p></blockquote><p>(1) 创建一个配置文件，指定要迁移数据的主题</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ vim topics-to-move.json</span><br><span class="line"></span><br><span class="line">{</span><br><span class="line">	<span class="string">"topics"</span>: [{</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"first"</span></span><br><span class="line">	}],</span><br><span class="line">	<span class="string">"version"</span>: 1</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>(2) 生成一个数据迁移计划，其中 <code>--broker-list "0,1,2"</code> 用于指定 Kafka 集群节点的 ID 列表（因为要退役 broker3，所以列表里只有 <code>0,1,2</code> 这三个节点），也就是说要将数据迁移到这几个节点上</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --topics-to-move-json-file topics-to-move.json --broker-list <span class="string">"0,1,2"</span> --generate</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Current partition replica assignment</span><br><span class="line">{"version":1,"partitions":[{"topic":"first","partition":0,"replicas":[2,0,1],"log_dirs":["any","any","any"]},{"topic":"first","partition":1,"replicas":[3,1,2],"log_dirs":["any","any","any"]},{"topic":"first","partition":2,"replicas":[0,2,3],"log_dirs":["any"," any","any"]}]}</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">{"version":1,"partitions":[{"topic":"first","partition":0,"replicas":[2,0,1],"log_dirs":["any","any","any"]},{"topic":"first","partition":1,"replicas":[0,1,2],"log_dirs":["any","any","any"]},{"topic":"first","partition":2,"replicas":[1,2,0],"log_dirs":["any"," any","any"]}]}</span><br></pre></td></tr></tbody></table></figure><p>(3) 拷贝步骤 <code>(2)</code> 生成的数据迁移计划，以此创建副本存储计划（所有副本存储在 broker0、broker1、broker2 中）</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ vim increase-replication-factor.json</span><br><span class="line"></span><br><span class="line">{</span><br><span class="line">	<span class="string">"version"</span>: 1,</span><br><span class="line">	<span class="string">"partitions"</span>: [{</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 0,</span><br><span class="line">		<span class="string">"replicas"</span>: [2, 0, 1],</span><br><span class="line">		<span class="string">"log_dirs"</span>: [<span class="string">"any"</span>, <span class="string">"any"</span>, <span class="string">"any"</span>]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 1,</span><br><span class="line">		<span class="string">"replicas"</span>: [0, 1, 2],</span><br><span class="line">		<span class="string">"log_dirs"</span>: [<span class="string">"any"</span>, <span class="string">"any"</span>, <span class="string">"any"</span>]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"first"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 2,</span><br><span class="line">		<span class="string">"replicas"</span>: [1, 2, 0],</span><br><span class="line">		<span class="string">"log_dirs"</span>: [<span class="string">"any"</span>, <span class="string">" any"</span>, <span class="string">"any"</span>]</span><br><span class="line">	}]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li>在上述 JSON 配置文件中，<code>replicas</code> 是指分区副本所在的 Broker ID。</li><li>比如，<code>"replicas": [0, 1, 2]</code> 表示该分区的副本分别存储在 Broker 0、Broker 1 和 Broker 2 上。</li></ul></div><p>(4) 执行副本存储计划</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br></pre></td></tr></tbody></table></figure><p>(5) 验证副本存储计划的执行</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br></pre></td></tr></tbody></table></figure><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition first-0 is complete.</span><br><span class="line">Reassignment of partition first-1 is complete.</span><br><span class="line">Reassignment of partition first-2 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 0,1,2,3</span><br><span class="line">Clearing topic-level throttles on topic first</span><br></pre></td></tr></tbody></table></figure><p>(6) 查看主题的详细信息，可以发现各个分区的副本数据不会再存储在需要退役的 Kafka 节点（broker3）上</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --topic first --describe</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Topic: first     TopicId: _h3inqW0T5ye8kif1P1c3A PartitionCount: 3       ReplicationFactor: 3    Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first     Partition: 0    Leader: 0       Replicas: 1,2,0 Isr: 0,1,2</span><br><span class="line">Topic: first     Partition: 1    Leader: 1       Replicas: 2,0,1 Isr: 2,0,1</span><br><span class="line">Topic: first     Partition: 2    Leader: 2       Replicas: 0,1,2 Isr: 1,2,0</span><br></pre></td></tr></tbody></table></figure><h4 id="关闭旧节点"><a href="#关闭旧节点" class="headerlink" title="关闭旧节点"></a>关闭旧节点</h4><p>在需要退役的节点上执行关闭命令，最终 Kafka 集群只剩下 3 个节点（broker0、broker1、broker2）</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node04 kafka]$ bin/kafka-server-stop.sh</span><br></pre></td></tr></tbody></table></figure><h3 id="增加分区数量"><a href="#增加分区数量" class="headerlink" title="增加分区数量"></a>增加分区数量</h3><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --alter --topic first --partitions 3</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>Kafka 的分区数量只能增加，不能减少。值得一提的是，Kafka 同样不支持减少已创建的主题的副本数量，但是可以通过 <code>kafka-reassign-partitions.sh</code> 脚本重新分配副本的方式来实现。</p></div><h3 id="自动创建主题"><a href="#自动创建主题" class="headerlink" title="自动创建主题"></a>自动创建主题</h3><ul><li><p>如果将 Broker 端的配置参数 <code>auto.create.topics.enable</code> 设置为 <code>true</code>（默认值是 <code>true</code>），那么当生产者向一个未创建的主题发送消息时，Broker 会自动创建一个分区数为 <code>num.partitions</code>（默认值为 1）、副本因子为 <code>default.replication.factor</code>（默认值为 1）的主题。</p></li><li><p>除此之外，当一个消费者开始从未知主题中读取消息时，或者当任意一个客户端向未知主题发送元数据请求时，都会自动创建一个相应的主题。这种创建主题的方式是非预期的，增加了主题管理和维护的难度。在生产环境下，强烈建议将 <code>auto.create.topics.enable</code> 设置为 <code>false</code>。</p></li></ul><h2 id="Kafka-副本的最佳实践"><a href="#Kafka-副本的最佳实践" class="headerlink" title="Kafka 副本的最佳实践"></a>Kafka 副本的最佳实践</h2><h3 id="动态增加副本的数量"><a href="#动态增加副本的数量" class="headerlink" title="动态增加副本的数量"></a>动态增加副本的数量</h3><div class="admonition note"><p class="admonition-title">提示</p><p>在生产环境中，由于某个 Topic 的重要等级需要提升，此时可以考虑增加该 Topic 的副本数（也叫增加副本因子）。值得一提的是，副本数的增加需要先制定存储计划，然后根据存储计划执行。</p></div><blockquote><p>这里假设 Kafka 集群有 3 个节点（Broker），分别是 broker0、broker1、broker2。</p></blockquote><p>(1) 创建一个新的 Topic，名称为 <code>four</code>，拥有 3 个分区，1 个副本</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --create --partitions 3 --replication-factor 1 --topic four</span><br></pre></td></tr></tbody></table></figure><p>(2) 查看副本的存储情况</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --describe --topic four</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Topic: four	TopicId: G3To2JZmTfWk7w1pki8Rmw	PartitionCount: 3	ReplicationFactor: 1	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: four	Partition: 0	Leader: 1	Replicas: 1	Isr: 1</span><br><span class="line">Topic: four	Partition: 1	Leader: 0	Replicas: 0	Isr: 0</span><br><span class="line">Topic: four	Partition: 2	Leader: 2	Replicas: 2	Isr: 2</span><br></pre></td></tr></tbody></table></figure><p>(3) 创建副本存储计划，将每个分区的副本数量增加到 3 个（所有副本都指定存储在 broker0、broker1、broker2 中）</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ vim increase-replication-factor.json</span><br><span class="line"></span><br><span class="line">{</span><br><span class="line">	<span class="string">"version"</span>: 1,</span><br><span class="line">	<span class="string">"partitions"</span>: [{</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"four"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 0,</span><br><span class="line">		<span class="string">"replicas"</span>: [0, 1, 2]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"four"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 1,</span><br><span class="line">		<span class="string">"replicas"</span>: [0, 1, 2]</span><br><span class="line">	}, {</span><br><span class="line">		<span class="string">"topic"</span>: <span class="string">"four"</span>,</span><br><span class="line">		<span class="string">"partition"</span>: 2,</span><br><span class="line">		<span class="string">"replicas"</span>: [0, 1, 2]</span><br><span class="line">	}]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li>在上述 JSON 配置文件中，<code>replicas</code> 是指分区副本所在的 Broker ID。</li><li>比如，<code>"replicas": [0, 1, 2]</code> 表示该分区的副本分别存储在 Broker 0、Broker 1 和 Broker 2 上。</li></ul></div><p>(4) 执行副本存储计划</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br></pre></td></tr></tbody></table></figure><p>(5) 验证副本存储计划的执行</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server node02:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br></pre></td></tr></tbody></table></figure><p>(6) 查看副本的存储情况</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server node02:9092 --describe --topic four</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Topic: four	TopicId: G3To2JZmTfWk7w1pki8Rmw	PartitionCount: 3	ReplicationFactor: 3	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: four	Partition: 0	Leader: 1	Replicas: 0,1,2	Isr: 1,2,0</span><br><span class="line">Topic: four	Partition: 1	Leader: 0	Replicas: 0,1,2	Isr: 0,1,2</span><br><span class="line">Topic: four	Partition: 2	Leader: 2	Replicas: 0,1,2	Isr: 2,1,0</span><br></pre></td></tr></tbody></table></figure><h3 id="Leader-Partition-负载平衡"><a href="#Leader-Partition-负载平衡" class="headerlink" title="Leader Partition 负载平衡"></a>Leader Partition 负载平衡</h3><p>在正常情况下，Kafka 本身会自动将 Leader Partition（即 Leader 副本）均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是，如果某些 Broker 宕机，会导致 Leader Partition 过于集中在其他少部分几台 Broker 上，这会导致少数几台 Broker 的读写请求压力过高；当其他宕机的 Broker 恢复之后都是 Follower Partition，读写请求压力都很低，这就会造成集群负载不均衡。</p><p><img data-src="../../../asset/2024/11/kafka-leader-partition-balancer-1.png"></p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td><code>auto.leader.rebalance.enable</code></td><td>是否启用 Leader Partition 自动平衡，默认值是 <code>true</code>。<strong>在生产环境中，Leader 重新选举的代价比较大，可能会带来性能影响，建议设置为 <code>false</code>。</strong></td></tr><tr><td><code>leader.imbalance.per.broker.percentage</code></td><td>每个 Broker 允许的不平衡的 Leader 的比率，默认值是 <code>10%</code>。如果每个 Broker 超过了这个值，控制器（Controller）会触发 Leader 的负载平衡。</td></tr><tr><td><code>leader.imbalance.check.interval.seconds</code></td><td>检查 Leader 负载是否平衡的间隔时间（秒），默认值是 <code>300</code>。</td></tr></tbody></table><blockquote><p>下面拿一个 Topic 举例说明，假设 Kafka 集群（4 个节点、4 个分区、每个分区有 4 个副本）只有一个主题，如下图所示：</p></blockquote><p><img data-src="../../../asset/2024/11/kafka-leader-partition-balancer-2.png"></p><p>针对 broker0 节点，分区 2 的 AR 优先副本是 broker0 节点，但是 broker0 节点却不是 Leader 节点，所以 broker0 节点的不平衡数加 1。因为 AR 副本总数是 4，所以 broker0 节点不平衡率为 1/4 &gt; 10%，需要再平衡。另外，broker2 节点和 broker3 节点和 broker0 节点的不平衡率一样，因此也需要再平衡；broker1 的不平衡数为 0，不需要再平衡。</p><div id="readmore-expansion" class="pjax"></div><link rel="stylesheet" type="text/css" href="https://qiniu.techgrow.cn/readmore/dist/hexo.css"><script data-pjax="" src="https://qiniu.techgrow.cn/readmore/dist/readmore.js" type="text/javascript"></script><script data-pjax="">var isMobile=navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i),allowMobile=!1;if(!isMobile||isMobile&&allowMobile)try{var plugin=new ReadmorePlugin;plugin.init({type:"hexo",id:"readmore-container",name:"全栈技术驿站",blogId:"96641-5333172926158-056",qrcode:"https://www.techgrow.cn/img/wx_mp_qr.png",keyword:"Tech",random:"1",height:"auto",expires:"365",lockToc:"yes",interval:"30",baseUrl:"",execute:"yes",tocSelector:""})}catch(e){console.warn("readmore plugin occurred error: "+e.name+" | "+e.message)}</script></div><footer class="post-footer"><div class="reward-container"><div>支持一根棒棒糖！</div> <button> 赞赏</button><div class="post-reward"><div> <img src="/img/pay_wx.png" alt="Clay 微信"> <span>微信</span></div><div> <img src="/img/pay_zfb.png" alt="Clay 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"> <strong>本文作者：</strong> Clay</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.techgrow.cn/posts/228158d3.html" title="Kafka 入门教程之三">https://www.techgrow.cn/posts/228158d3.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="contactme"><div class="social-list"><div class="social-item"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">欢迎添加博主微信，请备注 "博客"，届时会邀请您加入百人微信群</span><br> <img src="/img/wx_account_qr.png"></div></div></div><div class="post-tags"><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag"><i class="fa fa-tag"></i> 分布式</a><a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag"><i class="fa fa-tag"></i> 消息队列</a><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"><i class="fa fa-tag"></i> 大数据</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/60ddcede.html" rel="prev" title="Kafka 入门教程之二"><i class="fa fa-angle-left"></i> Kafka 入门教程之二</a></div><div class="post-nav-item"> <a href="/posts/874687ce.html" rel="next" title="Debian 11 开机启动执行自定义脚本">Debian 11 开机启动执行自定义脚本<i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments" id="waline"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> Copyright © 2018 – <span itemprop="copyrightYear">2025</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Clay</span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i></span> <span>站点总字数：</span> <span title="站点总字数">1.6m</span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span>站点阅读时长 ≈</span> <span title="站点阅读时长">24:59</span></span></div><div id="site-runtime"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span><span id="runtime"></span></div><script language="javascript">function isPC(){for(var e=navigator.userAgent,t=["Android","iPhone","SymbianOS","Windows Phone","iPad","iPod"],n=0;n<t.length;n++)if(0<e.indexOf(t[n]))return!1;return!0}function siteTime(e,t){window.setTimeout("siteTime(openOnPC, start)",1e3);var n=36e5,o=24*n;t=new Date("2018-12-27 08:00:00");var i=new Date,r=(i.getFullYear(),i.getMonth(),i.getDate(),i.getHours(),i.getMinutes(),i.getSeconds(),i-t),a=Math.floor(r/31536e6),s=Math.floor(r/o-365*a),d=Math.floor((r-(365*a+s)*o)/n),l=Math.floor((r-(365*a+s)*o-d*n)/6e4),u=Math.floor((r-(365*a+s)*o-d*n-6e4*l)/1e3);document.getElementById("runtime").innerHTML="Powered by Hexo & Docker | "+a+" 年 "+s+" 日 "+d+" 小时 "+l+" 分钟 "+u+" 秒 "}var showOnMobile=!1,openOnPC=isPC(),start=new Date;siteTime(openOnPC,start),openOnPC||showOnMobile||(document.getElementById("site-runtime").style.display="none")</script><div class="beian"> <span><img src="/img/gonganbeian.png" alt=""></span> <span><a href="https://beian.miit.gov.cn/" rel="external nofollow" target="_blank">粤 ICP 备 19024664 号</a></span> <span>|&nbsp;</span> <span><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44011302004035" rel="external nofollow" target="_blank">粤公网安备 44011302004035 号</a></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div><div class="sidebar-dimmer"></div> <a href="https://github.com/rqh656418510" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="external nofollow" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="200" alpha="0.5" zindex="-1" src="/lib/ribbon.js/dist/ribbon.min.js"></script><script src="/lib/animejs/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="/lib/@next-theme/pjax/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script><script src="/lib/medium-zoom/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script><script src="/lib/lozad/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script><script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"/lib/pdfobject/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script><script src="/js/third-party/tags/pdf.js"></script><script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"/lib/mermaid/dist/mermaid.min.js","integrity":"sha256-stuqcu2FrjYCXDOytWFA5SoUE/r3nkp6gTglzNSlavU="}}</script><script src="/js/third-party/tags/mermaid.js"></script><script src="/js/third-party/pace.js"></script><script data-pjax="" async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://www.techgrow.cn/lib/darkmode/darkmode@1.5.7.min.js"></script><script>
var options = {
  bottom: '64px',
  right: '30px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#282828',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script><script src="https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js"></script><script>
    var qiniu_domain = "https://oss.techgrow.cn";
    var qiniu_token_url = "https://open.techgrow.cn/app/api/qiniu/token/upload";
    var qiniu_debug = "true" === "false";

    // date format
    Date.prototype.format = function (fmt) {
      var o = {
        "M+": this.getMonth() + 1,
        "d+": this.getDate(),
        "h+": this.getHours(),
        "m+": this.getMinutes(),
        "s+": this.getSeconds(),
        "q+": Math.floor((this.getMonth() + 3) / 3),
        "S": this.getMilliseconds()
      };
      if (/(y+)/.test(fmt)) {
        fmt = fmt.replace(RegExp.$1, (this.getFullYear() + "").substr(4 - RegExp.$1.length));
      }
      for (var k in o) {
        if (new RegExp("(" + k + ")").test(fmt)) {
          fmt = fmt.replace(
            RegExp.$1,
            (RegExp.$1.length == 1)
              ? (o[k])
              : (("00" + o[k]).substr(("" + o[k]).length))
          );
        }
      }
      return fmt;
    }

    // generate uuid
    function uuid() {
      var s = [];
      var hexDigits = "0123456789abcdef";
      for (var i = 0; i < 36; i++) {
        s[i] = hexDigits.substr(Math.floor(Math.random() * 0x10), 1);
      }
      s[14] = "4";
      s[19] = hexDigits.substr((s[19] & 0x3) | 0x8, 1);
      s[8] = s[13] = s[18] = s[23] = "-";
      var uuid = s.join("");
      return uuid;
    }

    // sync get request
    function syncGet(url) {
      var xhr = null;
      if (window.XMLHttpRequest) {
        xhr = new XMLHttpRequest();
      } else {
        xhr = new ActiveXObject("Microsoft.XMLHTTP");
      }
      xhr.open('GET', url, false);
      xhr.send();
      return xhr;
    }

    // get upload file path
    function getUploadFilePath() {
      var now = new Date();
      var name = uuid().replace(/-/g, "");
      var nowStr = now.format("/yyyy/MM/dd/");
      return "uploads" + nowStr + name;
    }

    // get qiniu upload token
    function getUploadToken() {
      try {
        var xhr = syncGet(qiniu_token_url);
        var responseStatus = xhr.status;
        var responseJson = JSON.parse(xhr.responseText);
        if (responseStatus === 200) {
          return responseJson.data;
        } else if (responseStatus === 403) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，非法请求来源！");
        } else if (responseStatus === 429) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，上传过于频繁！");
        } else if (responseStatus === 500) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，系统内部出错！");
        } else {
          alert("图片上传失败，无法获取UploadToken，未知Http响应状态码！");
        }
      } catch (err) {
        if (qiniu_debug) {
          console.error(err);
        }
        alert("图片上传失败，无法获取UploadToken，未知错误！");
      }
      return null;
    }

    // qiniu upload image
    async function qiniuUploadImage(file) {
      var image_path = null;
      await uploadImage(file).then(function onFulfilled(res) {
        image_path = res;
      }).catch(function onRejected(err) {
        if (qiniu_debug) {
          console.error(err);
        }
      });
      return image_path;
    }

    // upload image
    function uploadImage(file) {
      return new Promise((resolve, reject) => {
        var config = null;
        var putExtra = null;
        var token = getUploadToken();
        var key = getUploadFilePath();
        // upload init
        var observable = qiniu.upload(file, key, token, putExtra, config);
        // upload start
        observable.subscribe({
          next(res) {
            // upload progress
          },
          error(err) {
            // upload falied
            reject("falied to upload image for qiniu: " + err.name);
          },
          complete(res) {
            // upload successed
            resolve(qiniu_domain + "/" + key);
          }
        });
      });
    }
  </script><script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://waline.techgrow.cn","cssUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css","commentCount":true,"pageview":false,"copyright":false,"allowUploadImage":true,"libUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.js","locale":{"placeholder":"支持匿名评论啦，若希望及时收到博主的反馈，建议登录评论或者在上方的邮箱输入框留下邮箱地址哦 (๑•̀ㅂ•́)و✧"},"dark":"body.darkmode--activated","emoji":["https://www.techgrow.cn/lib/@waline/emojis/1.0.1/weibo"],"meta":["nick","mail","link"],"login":"enable","pageSize":10,"qiniuDebug":false,"qiniuDomain":"https://oss.techgrow.cn","qiniuTokenUrl":"https://open.techgrow.cn/app/api/qiniu/token/upload","qiniuLibUrl":"https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js","el":"#waline","comment":true,"path":"/posts/228158d3.html"}</script><link rel="stylesheet" href="https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css"><script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.waline.allowUploadImage) {
    CONFIG.waline.imageUploader = false;
  }
  else if (CONFIG.waline.qiniuDomain && CONFIG.waline.qiniuTokenUrl) {
    CONFIG.waline.imageUploader = qiniuUploadImage;
  } else {
   CONFIG.waline.imageUploader = true;
  }
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script><div class="moon-menu"><div class="moon-menu-items"><div id="moon-menu-item-back2bottom" class="moon-menu-item"><i class="fas fa-chevron-down"></i></div><div id="moon-menu-item-back2top" class="moon-menu-item"><i class="fas fa-chevron-up"></i></div></div><div class="moon-menu-button"><svg class="moon-menu-bg"><circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle><circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle></svg><div class="moon-menu-content"><div class="moon-menu-icon"><i class="fas fa-ellipsis-v"></i></div><div class="moon-menu-text"></div></div></div></div><script src="/js/injector.js"></script><div class="comments" id="waline-comments" style="display:none"></div><script>function isMobile(){var i=navigator.userAgent.toLowerCase(),e="ipad"==i.match(/ipad/i),a="iphone os"==i.match(/iphone os/i),o="midp"==i.match(/midp/i),n="rv:1.2.3.4"==i.match(/rv:1.2.3.4/i),r="ucweb"==i.match(/ucweb/i),c="android"==i.match(/android/i),l="windows ce"==i.match(/windows ce/i),d="windows mobile"==i.match(/windows mobile/i);return!!(e||a||o||n||r||c||l||d)}var openOnMobile=isMobile(),showOnMobile=!1,aplayerEnable=!0;jQuery(document).ready(function(){aplayerEnable&&(openOnMobile&&!showOnMobile||jQuery("#aplayer").css("display","block"))}),jQuery(window).on("load",function(){aplayerEnable&&jQuery(".aplayer\\-icon.aplayer\\-icon\\-lrc").trigger("click")})</script></body></html>