<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CRoboto+Slab:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic&amp;display=swap&amp;subset=latin,latin-ext"><link rel="stylesheet" href="/lib/@fortawesome/fontawesome-free/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/animate.css/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/pace-js/themes/blue/pace-theme-minimal.css"><script src="/lib/pace-js/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.techgrow.cn","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script><meta name="description" content="本文主要介绍如何搭建 Kubernetes 高可用集群。"><meta property="og:type" content="article"><meta property="og:title" content="基于二进制包方式搭建 Kubernetes 多 Master 高可用集群"><meta property="og:url" content="https://www.techgrow.cn/posts/fb1a55bb.html"><meta property="og:site_name" content="Clay 的技术空间"><meta property="og:description" content="本文主要介绍如何搭建 Kubernetes 高可用集群。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.techgrow.cn/asset/2025/11/k8s-ha-cluster.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2025/11/k8s-ha-cluster-2.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2025/11/k8s-ha-cluster-3.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2025/07/k8s-nginx.png"><meta property="article:published_time" content="2021-03-23T13:42:52.000Z"><meta property="article:modified_time" content="2025-11-06T14:34:29.000Z"><meta property="article:author" content="Clay"><meta property="article:tag" content="容器化"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.techgrow.cn/asset/2025/11/k8s-ha-cluster.png"><link rel="canonical" href="https://www.techgrow.cn/posts/fb1a55bb.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.techgrow.cn/posts/fb1a55bb.html","path":"posts/fb1a55bb.html","title":"基于二进制包方式搭建 Kubernetes 多 Master 高可用集群"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>基于二进制包方式搭建 Kubernetes 多 Master 高可用集群 | Clay 的技术空间</title><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-135294383-1"></script><script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-135294383-1","only_pageview":false,"measure_protocol_api_secret":null}</script><script src="/js/third-party/analytics/google-analytics.js"></script><script class="next-config" data-name="baidu_analytics" type="application/json">"84c09b30349a65573c5c642ff336969b"</script><script src="/js/third-party/analytics/baidu-analytics.js"></script><link rel="dns-prefetch" href="https://waline.techgrow.cn"><link rel="stylesheet" type="text/css" href="/css/injector/main.css"><link rel="preload" as="style" href="/css/injector/light.css"><link rel="preload" as="style" href="/css/injector/dark.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><style>.admonition{margin:1.5625em 0;padding:.6rem;overflow:hidden;font-size:.64rem;page-break-inside:avoid;border-left:.3rem solid #42b983;border-radius:.3rem;box-shadow:0 .1rem .4rem rgba(0,0,0,.05),0 0 .05rem rgba(0,0,0,.1);background-color:#fafafa}p.admonition-title{position:relative;margin:-.6rem -.6rem .8em -.6rem!important;padding:.4rem .6rem .4rem 2.5rem;font-weight:700;background-color:rgba(66,185,131,.1)}.admonition-title::before{position:absolute;top:.9rem;left:1rem;width:12px;height:12px;background-color:#42b983;border-radius:50%;content:' '}.info>.admonition-title,.todo>.admonition-title{background-color:rgba(0,184,212,.1)}.attention>.admonition-title,.caution>.admonition-title,.warning>.admonition-title{background-color:rgba(255,145,0,.1)}.error>.admonition-title,.fail>.admonition-title,.failure>.admonition-title,.missing>.admonition-title{background-color:rgba(255,82,82,.1)}.admonition.info,.admonition.todo{border-color:#00b8d4}.admonition.attention,.admonition.caution,.admonition.warning{border-color:#ff9100}.admonition.error,.admonition.fail,.admonition.failure,.admonition.missing{border-color:#ff5252}.info>.admonition-title::before,.todo>.admonition-title::before{background-color:#00b8d4;border-radius:50%}.attention>.admonition-title::before,.caution>.admonition-title::before,.warning>.admonition-title::before{background-color:#ff9100;border-radius:50%}.error>.admonition-title::before,.fail>.admonition-title::before,.failure>.admonition-title::before,.missing>.admonition-title::before{background-color:#ff5252;border-radius:50%}.admonition>:last-child{margin-bottom:0!important}</style><link rel="alternate" href="/atom.xml" title="Clay 的技术空间" type="application/atom+xml"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope="" itemtype="http://schema.org/WebPage" class="use-motion"><script src="/lib/jquery/dist/jquery.min.js"></script><script data-pjax="">!function(){var t=window.location.host;if(-1==t.indexOf("127.0.0.1")&&-1==t.indexOf("localhost")){var o=document.createElement("script"),e=window.location.protocol.split(":")[0];o.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(o,n)}}()</script><link rel="stylesheet" href="/lib/aplayer/dist/APlayer.min.css"><div id="aplayer" style="display:none"></div><script src="/lib/aplayer/dist/APlayer.min.js"></script><script src="/lib/aplayer/dist/color-thief.js"></script><script src="/lib/aplayer-init.js"></script><script>
  (function () {

  // 防止 Pjax 重复绑定事件
  if (window.__moonMenuCodeExpandBound) {
    return;
  }
  window.__moonMenuCodeExpandBound = true;

  const STORAGE_KEY = 'moon_menu_code_fold';

  /* ===============================
   * 1. 设置 moon-menu 按钮的 title
   * =============================== */
  (function bindMoonMenuTitles() {
    const items = [
      { selector: '#moon-menu-item-code',        title: '展开 / 折叠代码块' },
      { selector: '#moon-menu-item-back2top',    title: '回到页面顶部' },
      { selector: '#moon-menu-item-back2bottom', title: '回到页面底部' }
    ];

    let allReady = true;

    items.forEach(item => {
      const el = document.querySelector(item.selector);
      if (!el) {
        allReady = false;
        return;
      }
      el.setAttribute('title', item.title);
    });

    if (!allReady) {
      setTimeout(bindMoonMenuTitles, 100);
    }
  })();

  /* =================================
   * 2. 页面首次加载：代码块恢复展开或折叠状态
   * ================================= */
  function applyStoredCodeState() {
    const containers = document.querySelectorAll('.code-container');
    if (!containers.length) {
      return;
    }

    const state = localStorage.getItem(STORAGE_KEY);
    if (!state) {
      return;
    }

    containers.forEach(container => {
      if (state === 'expanded') {
        // 展开代码块
        container.classList.remove('highlight-fold');
      } else if (state === 'folded') {
        // 折叠代码块
        container.classList.add('highlight-fold');
      }
    });
  }

  // 等代码块出现后，再恢复展开或折叠状态
  function waitAndApplyState() {
    const containers = document.querySelectorAll('.code-container');

    if (!containers.length) {
      setTimeout(waitAndApplyState, 100);
      return;
    }

    applyStoredCodeState();
  }

  // 页面首次加载时恢复状态
  waitAndApplyState();
  
  // Pjax 切换页面后，必须重新恢复状态
  document.addEventListener('pjax:complete', function () {
    waitAndApplyState();
  });

  /* ===============================
   * 3. 点击按钮：切换状态并保存
   * =============================== */
  document.addEventListener('click', function (e) {
    const codeMenu = e.target.closest('#moon-menu-item-code');
    if (!codeMenu) {
      return;
    }

    toggleAllCodeBlocks();
  });

  // 展开或折叠代码块
  function toggleAllCodeBlocks() {
    const containers = document.querySelectorAll('.code-container');
    if (!containers.length) {
      return;
    }

    // 只要存在折叠的代码块，就认为当前是折叠状态
    const hasFolded = Array.from(containers).some(c => {
      return c.classList.contains('highlight-fold');
    });

    containers.forEach(container => {
      if (hasFolded) {
        // 展开代码块
        container.classList.remove('highlight-fold');
      } else {
        // 折叠代码块
        container.classList.add('highlight-fold');
      }
    });

    // 记录展开或折叠状态
    localStorage.setItem(
      STORAGE_KEY,
      hasFolded ? 'expanded' : 'folded'
    );
  }

})();
</script><script src="https://res.wx.qq.com/open/js/jweixin-1.4.0.js"></script><script>function getTitle(){var t=jQuery("meta[property='og:title']");return t?t.attr("content"):""}function getDesc(){var t=jQuery("meta[property='og:description']");return t?t.attr("content"):""}function randomString(t){for(var e="ABCDEFGHJKMNPQRSTWXYZabcdefhijkmnprstwxyz2345678",n=e.length,i="",r=0;r<t;++r)i+=e.charAt(Math.floor(Math.random()*n));return i}function initWx(t){wx.config({debug:!1,appId:t.appId,nonceStr:t.nonceStr,signature:t.signature,timestamp:t.timestamp,jsApiList:["checkJsApi","onMenuShareTimeline","onMenuShareAppMessage","onMenuShareQQ"]}),wx.ready(function(){wx.onMenuShareTimeline({title:t.title,link:t.link,imgUrl:t.imgUrl,success:function(){}}),wx.onMenuShareAppMessage({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,type:"link",dataUrl:"",success:function(){}}),wx.onMenuShareQQ({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,success:function(){},cancel:function(){}})}),wx.error(function(t){})}jQuery(function(){var e=getDesc(),n=getTitle(),i=randomString(16),r=(new Date).getTime(),a=window.location.href,t="https://open.techgrow.cn/api/wechat/js/signature?url="+a+"&noncestr="+i+"&timestamp="+r;jQuery.getJSON(t,function(t){initWx({desc:e,title:n,link:a,nonceStr:i,timestamp:r,signature:t.data,appId:"wx1fcf69355af43d41",imgUrl:"https://www.techgrow.cn/img/wx_share.jpg"})})})</script><div style="display:none"><img src="https://www.techgrow.cn/img/wx_share.jpg" alt=""></div><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">Clay 的技术空间</p><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">用进废退 | 艺不压身</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-search"><a href="/search" rel="section"><i class="fa fa-search fa-fw"></i>搜索</a></li><li class="menu-item menu-item-links"><a href="/links" rel="section"><i class="fas fa-link fa-fw"></i>友链</a></li><li class="menu-item menu-item-readingnotes"><a href="https://www.techgrow.cn/reading/" rel="section"><i class="fa fa-book-open-reader fa-fw"></i>读书笔记</a></li><li class="menu-item menu-item-commentmanage"><a href="https://waline.techgrow.cn/" rel="external nofollow" target="_blank"><i class="fa fa-comment fa-fw"></i>评论管理</a></li></ul></nav></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E7%BA%B2"><span class="nav-text">大纲</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="nav-text">高可用集群的介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA%E5%A4%9A-Master-%E9%9B%86%E7%BE%A4"><span class="nav-text">搭建多 Master 集群</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%88%E6%9C%AC%E4%B8%8E%E7%A1%AC%E4%BB%B6"><span class="nav-text">版本与硬件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A7%84%E5%88%92"><span class="nav-text">服务器规划</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-text">操作系统初始化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85-CFSSL-%E5%B7%A5%E5%85%B7"><span class="nav-text">安装 CFSSL 工具</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85-Docker-%E6%9C%8D%E5%8A%A1"><span class="nav-text">安装 Docker 服务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA-Etcd-%E9%9B%86%E7%BE%A4"><span class="nav-text">搭建 Etcd 集群</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E6%88%90-Etcd-%E8%AF%81%E4%B9%A6"><span class="nav-text">生成 Etcd 证书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Etcd-%E9%9B%86%E7%BE%A4"><span class="nav-text">部署 Etcd 集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8-Etcd-%E9%9B%86%E7%BE%A4"><span class="nav-text">启动 Etcd 集群</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA-Kubernetes-%E9%9B%86%E7%BE%A4"><span class="nav-text">搭建 Kubernetes 集群</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E9%9B%86%E7%BE%A4%E8%AF%81%E4%B9%A6"><span class="nav-text">生成集群证书</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%9F%E6%88%90-CA-%E6%A0%B9%E8%AF%81%E4%B9%A6"><span class="nav-text">生成 CA 根证书</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%9F%E6%88%90-API-Server-%E8%AF%81%E4%B9%A6"><span class="nav-text">生成 API Server 证书</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%9F%E6%88%90-Controller-Manager-%E8%AF%81%E4%B9%A6"><span class="nav-text">生成 Controller Manager 证书</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%9F%E6%88%90-Scheduler-%E8%AF%81%E4%B9%A6"><span class="nav-text">生成 Scheduler 证书</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%9F%E6%88%90-Kube-Proxy-%E8%AF%81%E4%B9%A6"><span class="nav-text">生成 Kube-Proxy 证书</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%95%E7%8B%AC%E9%83%A8%E7%BD%B2-Master-%E8%8A%82%E7%82%B9"><span class="nav-text">单独部署 Master 节点</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6"><span class="nav-text">下载二进制文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-API-Server"><span class="nav-text">部署 API Server</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-HaProxy"><span class="nav-text">部署 HaProxy</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Keepalived"><span class="nav-text">部署 Keepalived</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Controller-Manager"><span class="nav-text">部署 Controller Manager</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Scheduler"><span class="nav-text">部署 Scheduler</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Master-%E4%B8%8E-Node-%E8%8A%82%E7%82%B9"><span class="nav-text">部署 Master 与 Node 节点</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6-1"><span class="nav-text">下载二进制文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Kubelet"><span class="nav-text">部署 Kubelet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Kube-Proxy"><span class="nav-text">部署 Kube-Proxy</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-CNI-%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6"><span class="nav-text">部署 CNI 网络插件</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="nav-text">所有节点的操作</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Master-%E8%8A%82%E7%82%B9%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="nav-text">Master 节点的操作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4%E6%95%B4%E4%BD%93%E5%8A%9F%E8%83%BD"><span class="nav-text">测试集群整体功能</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-CoreDNS%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89"><span class="nav-text">部署 CoreDNS（可选）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A-Master-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E9%97%AE%E9%A2%98"><span class="nav-text">多 Master 集群搭建问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98"><span class="nav-text">集群启动顺序问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E8%A7%A3%E5%86%B3%E5%90%AF%E5%8A%A8%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98"><span class="nav-text">手动解决启动顺序问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BD%BB%E5%BA%95%E8%A7%A3%E5%86%B3%E5%90%AF%E5%8A%A8%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98"><span class="nav-text">彻底解决启动顺序问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Etcd-%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8"><span class="nav-text">Etcd 无法正常启动</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9E%E6%8E%A5-API-Server-%E5%A4%B1%E8%B4%A5"><span class="nav-text">连接 API Server 失败</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kubelet-%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8"><span class="nav-text">Kubelet 无法正常启动</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kubelet-%E5%8F%91%E9%80%81-CSR-%E8%AF%B7%E6%B1%82%E5%A4%B1%E8%B4%A5"><span class="nav-text">Kubelet 发送 CSR 请求失败</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNI-%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E9%83%A8%E7%BD%B2"><span class="nav-text">CNI 网络插件无法正常部署</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-text">参考资料</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope="" itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="Clay" src="/img/head.jpg"></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"> <span class="site-state-item-count">795</span> <span class="site-state-item-name">文章</span></div><div class="site-state-item site-state-tags"> <span class="site-state-item-count">56</span> <span class="site-state-item-name">标签</span></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/rqh656418510" title="GitHub → https://github.com/rqh656418510" rel="external nofollow" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:rong656418510@gmail.com" title="E-Mail → mailto:rong656418510@gmail.com" rel="external nofollow" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="/atom.xml" title="RSS → /atom.xml" rel="noopener me"><i class="fa fa-rss fa-fw"></i> RSS</a></span><span class="links-of-author-item"><a href="/sitemap.xml" title="SiteMap → /sitemap.xml" rel="noopener me"><i class="fa fa-sitemap fa-fw"></i> SiteMap</a></span></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope="" itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.techgrow.cn/posts/fb1a55bb.html"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="image" content="/img/head.jpg"><meta itemprop="name" content="Clay"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Clay 的技术空间"><meta itemprop="description" content="专注于 Java 后端、分布式、微服务、云原生、数据库、系统架构、大数据、云计算、虚拟化、人工智能学习的技术博客。"></span><span hidden="" itemprop="post" itemscope="" itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="基于二进制包方式搭建 Kubernetes 多 Master 高可用集群 | Clay 的技术空间"><meta itemprop="description" content="本文主要介绍如何搭建 Kubernetes 高可用集群。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 基于二进制包方式搭建 Kubernetes 多 Master 高可用集群</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-03-23 21:42:52" itemprop="dateCreated datePublished" datetime="2021-03-23T21:42:52+08:00">2021-03-23</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2025-11-06 22:34:29" itemprop="dateModified" datetime="2025-11-06T22:34:29+08:00">2025-11-06</time></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i></span> <span class="post-meta-item-text">评论数：</span><a title="waline" href="/posts/fb1a55bb.html#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/fb1a55bb.html" itemprop="commentCount"></span></a></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>30k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 ≈</span> <span>27 分钟</span></span></div></div></header><div class="post-body post-container" itemprop="articleBody" id="readmore-container"><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/ccd6f2d4.html">基于二进制包方式搭建 Kubernetes 单 Master 集群</a></li><li><a href="/posts/b728042a.html">基于 Kubeadm 方式搭建 Kubernetes 单 Master 集群</a></li><li><a href="/posts/fb1a55bb.html">基于二进制包方式搭建 Kubernetes 多 Master 高可用集群</a></li><li><a href="/posts/8e0e80f.html">基于 Kubeadm 方式搭建 Kubernetes 多 Master 高可用集群</a></li></ul><span id="more"></span><h2 id="高可用集群的介绍"><a href="#高可用集群的介绍" class="headerlink" title="高可用集群的介绍"></a>高可用集群的介绍</h2><p>Kubernetes 作为容器集群系统，通过健康检查与重启策略实现了 Pod 的故障自我修复能力，通过调度算法将 Pod 分布式部署，并持续监控其预期副本数。当节点发生故障时，系统能够自动在正常节点上重新启动 Pod，从而实现应用层的高可用性。<strong>在 Kubernetes 集群环境中，高可用性还需考虑以下两个层面：Etcd 存储库的高可用性，以及 Kubernetes Master 节点的高可用性。</strong>Etcd 可以部署 3 集群个节点来保证高可用性。Kubernetes Master 节点承担总控中心角色，通过持续与工作节点（Worker）上的 Kubelet 和 Kube-Proxy 进行通信，维护整个集群的健康工作状态。一旦 Master 节点发生故障，将无法使用 <code>kubectl</code> 工具或 API 进行集群管理。<strong>Kubernetes Master 节点主要包含三个核心服务：API Server、Controller Manager 和 Scheduler。其中，Controller Manager 和 Scheduler 组件自身已通过内置的 Leader 选举机制实现了高可用。因此，Kubernetes Master 节点的高可用主要是针对 API Server 组件，该组件以 HTTP API 形式提供服务，其高可用实现方式与 Web 服务器类似，可以通过负载均衡器（比如 HaProxy / Nginx）对其多个实例进行负载均衡，使其支持水平扩展，并可以使用 Keepalived 来保证负载均衡器自身的高可用性。</strong></p><div class="admonition note"><p class="admonition-title">Kubernetes 高可用集群的两种搭建方式</p><p>Kubernetes 高可用集群通常有两种部署方式：二进制手动部署 和 Kubeadm 自动化部署。在生产环境中，更推荐使用二进制部署方式，因为可控性高、组件版本可精细管理，便于根据业务需求进行深度定制。而在开发或测试环境，则可以使用 Kubeadm 快速搭建高可用集群，部署流程简单、效率更高。 值得一提的是，如果之前是 <a href="/posts/ccd6f2d4.html">基于二进制包方式搭建 Kubernetes 单 Master 集群</a> 的，那么可以在此基础上对 Master 节点进行扩容，无需从零开始搭建 Kubernetes 多 Master 集群；此时，最关键的步骤是重新生成 Kubernetes 集群所需的证书，并部署 HaProxy 与 Keepalived，最后配置 Controller Manager、Scheduler、Kubelet、Kube-Proxy 这些组件使用 Keepalived 的 VIP 与 HaProxy 的反向代理端口去连接 API Server。</p></div><p>Kubernetes 多 Master 集群的整体架构如下，多个 Master 节点之间通过 HaProxy 实现反向代理和负载均衡，而 HaProxy 通过 Keepalived 来保证自身的高可用性（即双机主备，也叫双机热备）。</p><p><img data-src="../../../asset/2025/11/k8s-ha-cluster.png"></p><h2 id="搭建多-Master-集群"><a href="#搭建多-Master-集群" class="headerlink" title="搭建多 Master 集群"></a>搭建多 Master 集群</h2><p>本节将基于二进制包方式搭建多 Master 的 Kubernetes 集群，核心目标如下：</p><ul><li>为 Etcd 、Kubernetes 核心组件自签证书</li><li>部署 Etcd 集群（3 个节点）</li><li>部署 Kubernetes 集群的 2 个 Master 节点</li><li>部署 Kubernetes 集群的 3 个 Node 节点</li><li>部署 Kubernetes 集群的 CNI 网络插件（Flannel）</li><li>部署 Kubernetes 集群的 DNS 组件（CoreDNS）</li><li>部署 HaProxy、Keepalived，保证 API Server 的高可用性</li></ul><div class="admonition warning"><p class="admonition-title">术语说明</p><p>为了方便描述，本文使用 <code>Node 节点</code> 来替代 Kubernetes 的 <code>Worker Node</code>，使用 <code>Master 节点</code> 来替代 <code>Master Node</code>。</p></div><h3 id="版本与硬件"><a href="#版本与硬件" class="headerlink" title="版本与硬件"></a>版本与硬件</h3><blockquote><p>搭建 Kubernetes 高可用集群所使用的软件版本如下：</p></blockquote><table><thead><tr><th>软件</th><th>版本</th><th>安装方式</th></tr></thead><tbody><tr><td> CentOS</td><td><code>7.9</code></td><td>多个独立虚拟机</td></tr><tr><td> Docker</td><td><code>19.03.9</code></td><td>二进制安装包</td></tr><tr><td> Kubernetes</td><td><code>1.19.10</code></td><td>二进制安装包</td></tr><tr><td> Etcd</td><td><code>3.4.9</code></td><td>二进制安装包</td></tr><tr><td> HaProxy</td><td><code>2.8.5</code></td><td>源码编译安装</td></tr><tr><td> Keepalived</td><td><code>2.2.8</code></td><td>源码编译安装</td></tr></tbody></table><blockquote><p>搭建 Kubernetes 高可用集群所使用的硬件需要满足以下几个条件</p></blockquote><ul><li>多台机器或虚拟机，建议操作系统 CentOS 7（64 位）</li><li>集群中所有机器之间的网络可以互通</li><li>系统内可以访问外网，需要拉取镜像</li><li>系统禁用 Swap 分区（必须）</li><li>Master 节点的硬件配置要求<ul><li>当 Master 节点只运行运行控制平面组件（如 API Server、Controller Manager 和 Scheduler）<ul><li>2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 20GB 或更多</li></ul></li><li>当 Master 节点运行控制平面组件，且承载用户 Pod 的调度和运行任务<ul><li> 6GB 或更多 RAM，6 个 CPU 或更多 CPU，硬盘 60GB 或更多</li></ul></li></ul></li><li> Node 节点的硬件配置要求<ul><li> 4GB 或更多 RAM，4 个 CPU 或更多 CPU，硬盘 40GB 或更多</li></ul></li></ul><h3 id="服务器规划"><a href="#服务器规划" class="headerlink" title="服务器规划"></a>服务器规划</h3><blockquote><p>本文所使用的 Kubernetes 集群服务器规划如下表所示。为了节省资源，Etcd 集群部署在与 Kubernetes 集群相同的服务器上。需要注意的是，在生产环境中，强烈建议将 Etcd 集群部署在独立的服务器上，以提升系统的性能和高可用性。</p></blockquote><table><thead><tr><th>Host 名称</th><th>角色</th><th> IP</th><th>CPU 核数</th><th>内存</th><th>磁盘</th><th>安装的组件</th><th>备注</th></tr></thead><tbody><tr><td> k8s-master1</td><td>master</td><td>192.168.2.191</td><td>&gt;= 6C</td><td>&gt;=6G</td><td>&gt;=60G</td><td>kube-apiserver，kube-controller-manager，kube-scheduler，kubelet，kube-proxy，cni plugin, docker，etcd，haproxy，keepalived</td><td> 部署 Etcd、HaProxy、Keepalived</td></tr><tr><td>k8s-node1</td><td>node（worker）</td><td>192.168.2.112</td><td>&gt;= 4C</td><td>&gt;=4G</td><td>&gt;=40G</td><td>kubelet，kube-proxy，cni plugin, docker，etcd</td><td> 部署 Etcd</td></tr><tr><td>k8s-node2</td><td>node（worker）</td><td>192.168.2.131</td><td>&gt;= 4C</td><td>&gt;=4G</td><td>&gt;=40G</td><td>kubelet，kube-proxy，cni plugin, docker，etcd</td><td> 部署 Etcd</td></tr><tr><td>k8s-node3</td><td>node（worker）</td><td>192.168.2.236</td><td>&gt;= 4C</td><td>&gt;=4G</td><td>&gt;=40G</td><td>kubelet，kube-proxy，cni plugin, docker</td><td> 不部署 Etcd</td></tr><tr><td>k8s-master2</td><td>master</td><td>192.168.2.148</td><td>&gt;= 6C</td><td>&gt;=6G</td><td>&gt;=60G</td><td>kube-apiserver，kube-controller-manager，kube-scheduler，kubelet，kube-proxy，cni plugin, docker，haproxy，keepalived</td><td> 不部署 Etcd，部署 HaProxy、Keepalived</td></tr></tbody></table><blockquote><p>如果希望 Master 节点仅用于运行控制平面组件（如 API Server、Controller Manager 和 Scheduler），不承载用户 Pod 的调度和运行任务，则 Master 节点可以不部署 Kubelet、Kube-Proxy 和 Docker（容器运行时），如下表所示：</p></blockquote><table><thead><tr><th>Host 名称</th><th>角色</th><th> IP</th><th>CPU 核数</th><th>内存</th><th>磁盘</th><th>安装的组件</th><th>备注</th></tr></thead><tbody><tr><td> k8s-master1</td><td>master</td><td>192.168.2.191</td><td>&gt;= 2C</td><td>&gt;=2G</td><td>&gt;=20G</td><td>kube-apiserver，kube-controller-manager，kube-scheduler，cni plugin，etcd，haproxy，keepalived</td><td> 部署 Etcd、HaProxy、Keepalived，不部署 Kubelet、Kube-Proxy、Docker</td></tr><tr><td>k8s-node1</td><td>node（worker）</td><td>192.168.2.112</td><td>&gt;= 4C</td><td>&gt;=4G</td><td>&gt;=40G</td><td>kubelet，kube-proxy，cni plugin, docker，etcd</td><td> 部署 Etcd</td></tr><tr><td>k8s-node2</td><td>node（worker）</td><td>192.168.2.131</td><td>&gt;= 4C</td><td>&gt;=4G</td><td>&gt;=40G</td><td>kubelet，kube-proxy，cni plugin, docker，etcd</td><td> 部署 Etcd</td></tr><tr><td>k8s-node3</td><td>node（worker）</td><td>192.168.2.236</td><td>&gt;= 4C</td><td>&gt;=4G</td><td>&gt;=40G</td><td>kubelet，kube-proxy，cni plugin, docker</td><td> 不部署 Etcd</td></tr><tr><td>k8s-master2</td><td>master</td><td>192.168.2.148</td><td>&gt;= 2C</td><td>&gt;=2G</td><td>&gt;=20G</td><td>kube-apiserver，kube-controller-manager，kube-scheduler，kubelet，kube-proxy，cni plugin, haproxy，keepalived</td><td> 不部署 Etcd、Kubelet、Kube-Proxy、Docker，部署 HaProxy、Keepalived</td></tr></tbody></table><div class="admonition note"><p class="admonition-title">虚拟 IP（VIP）的说明</p><ul><li>虚拟 IP（VIP）由 Keepalived 提供。</li><li>在配置 Keepalived 的 <code>virtual_ipaddress</code> 参数时，所指定的 VIP 地址必须与 HaProxy 所在节点处于同一网段。</li><li>例如，如果两个 HaProxy 节点的网段为 <code>192.168.2.0/24</code>，则 VIP 也应设置为该网段内的地址（如 <code>192.168.2.x</code>）。</li></ul></div><h3 id="操作系统初始化"><a href="#操作系统初始化" class="headerlink" title="操作系统初始化"></a>操作系统初始化</h3><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><strong>在 Kubernetes 集群的所有节点（包括 Master 和 Node 节点）上，分别执行以下系统初始化操作</strong>。</li></ul></div><p>关闭防火墙</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时关闭</span></span><br><span class="line"><span class="keyword"># systemctl</span> stop firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">disable</span> firewalld</span><br></pre></td></tr></tbody></table></figure><p>关闭 selinux</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时关闭</span></span><br><span class="line"><span class="keyword"># setenforce</span> 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line"><span class="keyword"># sed</span><span class="params"> -i</span> <span class="string">'s/enforcing/disabled/'</span> /etc/selinux/config</span><br></pre></td></tr></tbody></table></figure><p>关闭 swap 分区</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时关闭</span></span><br><span class="line"><span class="keyword">$ swapoff</span><span class="params"> -a</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line"><span class="keyword"># sed</span><span class="params"> -i</span> <span class="string">'s/.*swap.*/#&amp;/'</span> /etc/fstab</span><br></pre></td></tr></tbody></table></figure><p>系统时间同步（强烈建议使用 chrony 而不是 ntpdate）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卸载ntpdate服务</span></span><br><span class="line"><span class="keyword"># yum</span> remove<span class="params"> -y</span> ntpdate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装chrony服务</span></span><br><span class="line"><span class="keyword"># yum</span> install<span class="params"> -y</span> chrony</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动chrony服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> chronyd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动chrony服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> start chronyd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置NTP源，添加国内公共的NTP服务器</span></span><br><span class="line"><span class="keyword"># vim</span> /etc/chrony.conf</span><br><span class="line">server ntp.aliyun.com iburst</span><br><span class="line">server ntp1.tencent.com iburst</span><br><span class="line">server cn.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启chrony服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart chronyd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查chrony服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status chronyd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看chrony服务的时间同步状态</span></span><br><span class="line"><span class="keyword"># chronyc</span> tracking</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强制同步一次时间（只在刚部署、时间差很多的时候用）</span></span><br><span class="line"><span class="keyword"># chronyc</span> makestep</span><br></pre></td></tr></tbody></table></figure><hr><p>设置主机名（比如 <code>k8s-master1</code>、<code>k8s-master2</code>、<code>k8s-node1</code>、<code>k8s-node2</code>、<code>k8s-node3</code>）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># hostnamectl</span> <span class="built_in">set</span>-hostname &lt;hostname&gt;</span><br></pre></td></tr></tbody></table></figure><p>添加 hosts 配置信息</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加hosts</span></span><br><span class="line"><span class="keyword"># vim</span> /etc/hosts</span><br><span class="line">192.168.2.191 k8s-master1</span><br><span class="line">192.168.2.148 k8s-master2</span><br><span class="line">192.168.2.112 k8s-node1</span><br><span class="line">192.168.2.131 k8s-node2</span><br><span class="line">192.168.2.236 k8s-node3</span><br></pre></td></tr></tbody></table></figure><p>将桥接的 IPv4 流量传递到 iptables 的链</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件，添加相应的路由规则</span></span><br><span class="line"><span class="keyword"># vim</span> /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置生效</span></span><br><span class="line"><span class="keyword"># sysctl</span><span class="params"> --system</span></span><br></pre></td></tr></tbody></table></figure><h3 id="安装-CFSSL-工具"><a href="#安装-CFSSL-工具" class="headerlink" title="安装 CFSSL 工具"></a>安装 CFSSL 工具</h3><div class="admonition warning"><p class="admonition-title">特别注意</p><p><strong>以下所有操作都是仅在 Kubernetes 集群的任意一个 Master 节点上（比如 <code>k8s-master1</code>）执行</strong>。CFSSL 是 CloudFlare 开源的一款 PKI/TLS 工具，包含一个命令行工具和一个用于签名、验证并且捆绑 TLS 证书的 HTTP API 服务，使用 Go 语言编写。</p></div><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二进制方式安装CFSSL工具</span></span><br><span class="line"><span class="keyword"># curl</span><span class="params"> -L</span> https://pkg.cfssl.org/R1.2/cfssl_linux-amd64<span class="params"> -o</span> /usr/<span class="built_in">local</span>/bin/cfssl</span><br><span class="line"><span class="keyword"># curl</span><span class="params"> -L</span> https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64<span class="params"> -o</span> /usr/<span class="built_in">local</span>/bin/cfssljson</span><br><span class="line"><span class="keyword"># curl</span><span class="params"> -L</span> https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64<span class="params"> -o</span> /usr/<span class="built_in">local</span>/bin/cfssl-certinfo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件授权</span></span><br><span class="line"><span class="keyword"># chmod</span> +x /usr/<span class="built_in">local</span>/bin/cfssl*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line"><span class="keyword"># export</span> PATH=/usr/<span class="built_in">local</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></tbody></table></figure><h3 id="安装-Docker-服务"><a href="#安装-Docker-服务" class="headerlink" title="安装 Docker 服务"></a>安装 Docker 服务</h3><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><strong>在 Kubernetes 集群的所有节点（包括 Master 和 Node 节点）上分别安装 Docker，这里采用二进制安装方式，CentOS 上还可以通过 YUM 安装</strong>。</li><li><strong>如果 Master 节点仅用于运行控制平面组件（如 API Server、Controller Manager 和 Scheduler），不承载用户 Pod 的调度和运行任务，则 Master 节点可以不安装 Docker 服务。</strong></li></ul></div><p>下载并解压 Docker 的二进制包</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载Docker的二进制包</span></span><br><span class="line"><span class="keyword"># wget</span> https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line"><span class="keyword"># tar</span><span class="params"> -xvf</span> docker-19.03.9.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移动文件</span></span><br><span class="line"><span class="keyword"># mv</span> docker/* /usr/bin</span><br></pre></td></tr></tbody></table></figure><p>创建 Docker 的配置文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建Docker的配置目录</span></span><br><span class="line"><span class="keyword"># mkdir</span> /etc/docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置阿里的Docker镜像加速（请更换自己的镜像地址，或者使用国内公共的镜像地址）</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /etc/docker/daemon.json &lt;&lt; EOF</span><br><span class="line">{</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [</span><br><span class="line">     <span class="string">"https://b9pmyelo.mirror.aliyuncs.com"</span>,</span><br><span class="line">     <span class="string">"https://ustc-edu-cn.mirror.aliyuncs.com"</span>,</span><br><span class="line">     <span class="string">"https://mirror.iscas.ac.cn"</span>,</span><br><span class="line">     <span class="string">"https://docker.nju.edu.cn"</span>,</span><br><span class="line">     <span class="string">"https://docker.m.daocloud.io"</span>,</span><br><span class="line">     <span class="string">"https://ccr.ccs.tencentyun.com"</span>,</span><br><span class="line">     <span class="string">"https://dockerhub.timeweb.cloud"</span></span><br><span class="line">    ]</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>配置 Systemd 管理 Docker</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/docker.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">After=network-online.target</span><br><span class="line">After=firewalld.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/bin/dockerd</span><br><span class="line">ExecReload=/bin/<span class="built_in">kill</span><span class="params"> -s</span> HUP <span class="variable">$MAINPID</span></span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=on-failure</span><br><span class="line">StartLimitBurst=3</span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>启动并设置开机自启动 Docker 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动Docker</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动Docker</span></span><br><span class="line"><span class="keyword"># systemctl</span> start docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Docker的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Docker的版本</span></span><br><span class="line"><span class="keyword"># docker</span><span class="params"> --version</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Docker的安装信息</span></span><br><span class="line"><span class="keyword"># docker</span> info</span><br></pre></td></tr></tbody></table></figure><h3 id="搭建-Etcd-集群"><a href="#搭建-Etcd-集群" class="headerlink" title="搭建 Etcd 集群"></a>搭建 Etcd 集群</h3><p>Etcd 是一个分布式键值存储系统，Kubernetes 使用 Etcd 进行数据存储，所以先准备一个 Etcd 系统。为解决 Etcd 单点故障，建议采用集群方式部署，这里使用 3 台机器组建 Etcd 集群，可容忍 1 台机器故障。当然，也可以使用 5 台机器组建 Etcd 集群，可容忍 2 台机器故障。为了节省机器，这里复用 Kubernetes 节点的机器，也可以独立于 Kubernetes 集群之外部署，只要 Kubernetes 的 API Server 能够连接上就行。</p><h4 id="生成-Etcd-证书"><a href="#生成-Etcd-证书" class="headerlink" title="生成 Etcd 证书"></a>生成 Etcd 证书</h4><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><strong>以下所有操作都是仅在 Kubernetes 集群的任意一个节点上（比如，第一个 Master 节点）执行，千万不要在每个 Etcd 集群节点上单独生成证书，否则 Etcd 集群里的节点可能会因证书不一致而导致集群启动失败</strong>。</li><li><strong>以后向 Etcd 集群中添加新节点时，只要将对应的证书拷贝到新节点上即可，通过 CFSSL 工具生成证书的详细使用教程请看 <a href="/posts/58887565.html">这里</a>。</strong></li><li>这里生成的 Etcd 证书，主要是提供给 API Server 使用的，目的是为了 API Server 与 Etcd 集群之间使用 CA 证书进行加密和身份验证。</li></ul></div><table><thead><tr><th>组件</th><th>使用的证书</th></tr></thead><tbody><tr><td> Etcd</td><td><code>ca.pem</code>、<code>server-key.pem</code>、<code>server.pem</code></td></tr></tbody></table><p>创建存放 Etcd 证书的目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建证书目录</span></span><br><span class="line">mkdir<span class="params"> -p</span> ~/tls/etcd/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入证书目录</span></span><br><span class="line"><span class="built_in">cd</span> ~/tls/etcd/</span><br></pre></td></tr></tbody></table></figure><p>创建 CA 证书的配置文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &lt;&lt; EOF | tee ca-config.json</span><br><span class="line">{</span><br><span class="line">  <span class="string">"signing"</span>: {</span><br><span class="line">    <span class="string">"default"</span>: {</span><br><span class="line">      <span class="string">"expiry"</span>: <span class="string">"87600h"</span></span><br><span class="line">    },</span><br><span class="line">    <span class="string">"profiles"</span>: {</span><br><span class="line">      <span class="string">"www"</span>: {</span><br><span class="line">         <span class="string">"expiry"</span>: <span class="string">"87600h"</span>,</span><br><span class="line">         <span class="string">"usages"</span>: [</span><br><span class="line">            <span class="string">"signing"</span>,</span><br><span class="line">            <span class="string">"key encipherment"</span>,</span><br><span class="line">            <span class="string">"server auth"</span>,</span><br><span class="line">            <span class="string">"client auth"</span></span><br><span class="line">        ]</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>创建 CA 证书签名的配置文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &lt;&lt; EOF | tee ca-csr.json</span><br><span class="line">{</span><br><span class="line">  <span class="string">"CN"</span>: <span class="string">"etcd ca"</span>,</span><br><span class="line">  <span class="string">"key"</span>: {</span><br><span class="line">    <span class="string">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="string">"size"</span>: 2048</span><br><span class="line">  },</span><br><span class="line">  <span class="string">"names"</span>: [</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="string">"ST"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="string">"L"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="string">"O"</span>: <span class="string">"k8s"</span>,</span><br><span class="line">      <span class="string">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">    }</span><br><span class="line">  ],</span><br><span class="line">    <span class="string">"ca"</span>: {</span><br><span class="line">       <span class="string">"expiry"</span>: <span class="string">"87600h"</span></span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>创建用于生成 Etcd 证书的配置文件，如果 <code>hosts</code> 字段不为空，则需要指定授权使用该证书的 IP 或域名列表。由于该证书后续会被 Etcd 集群使用到，因此通常指定为 Etcd 集群所有节点的 IP 集合。因为本文的 Etcd 集群节点和 Kubernetes 的集群节点共同安装在不同虚拟机内（即服务器复用），所以 IP 列表就是 Kubernetes 集群所有节点的 IP 集合。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &lt;&lt; EOF | tee server-csr.json</span><br><span class="line">{</span><br><span class="line">    <span class="string">"CN"</span>: <span class="string">"etcd"</span>,</span><br><span class="line">    <span class="string">"hosts"</span>: [</span><br><span class="line">      <span class="string">"192.168.2.191"</span>,</span><br><span class="line">      <span class="string">"192.168.2.148"</span>,</span><br><span class="line">      <span class="string">"192.168.2.112"</span>,</span><br><span class="line">      <span class="string">"192.168.2.131"</span>,</span><br><span class="line">      <span class="string">"192.168.2.236"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"key"</span>: {</span><br><span class="line">        <span class="string">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">        <span class="string">"size"</span>: 2048</span><br><span class="line">    },</span><br><span class="line">    <span class="string">"names"</span>: [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">            <span class="string">"ST"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">            <span class="string">"L"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">            <span class="string">"O"</span>: <span class="string">"k8s"</span>,</span><br><span class="line">            <span class="string">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">        }</span><br><span class="line">    ]</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>生成 CA 证书，并使用自签 CA 签发 Etcd 证书</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前目录下的文件</span></span><br><span class="line"><span class="keyword"># ls</span></span><br><span class="line">ca-config.json  ca-csr.json  server-csr.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成CA证书</span></span><br><span class="line"><span class="keyword"># cfssl</span> gencert<span class="params"> -initca</span> ca-csr.json | cfssljson<span class="params"> -bare</span> ca -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的CA证书</span></span><br><span class="line"><span class="keyword"># ls</span> ca*.pem</span><br><span class="line">ca-key.pem  ca.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自签 CA 证书签发 Etcd 的证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致</span></span><br><span class="line"><span class="keyword"># cfssl</span> gencert<span class="params"> -ca</span>=ca.pem<span class="params"> -ca</span>-key=ca-key.pem<span class="params"> -config</span>=ca-config.json<span class="params"> -profile</span>=www server-csr.json | cfssljson<span class="params"> -bare</span> server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的 Etcd 证书</span></span><br><span class="line"><span class="keyword"># ls</span> server*.pem</span><br><span class="line">server-key.pem  server.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证生成的 Etcd 证书</span></span><br><span class="line"><span class="keyword"># cfssl</span>-certinfo<span class="params"> -cert</span> server.pem</span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params">  -noout</span><span class="params"> -text</span><span class="params"> -in</span>  server.pem</span><br></pre></td></tr></tbody></table></figure><p>拷贝上面生成的 CA 证书和 Etcd 证书到本地目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建存放证书的本地目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /opt/etcd/ssl/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝 CA 证书和 Etcd 证书到本地目录</span></span><br><span class="line"><span class="keyword"># cp</span> ~/tls/etcd/*.pem /opt/etcd/ssl/</span><br></pre></td></tr></tbody></table></figure><p>拷贝上面生成的 CA 证书和 Etcd 证书到其他 Master 节点里面（提供给 API Server 使用）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在其他 Master 节点上分别创建存放证书的目录</span></span><br><span class="line"><span class="keyword"># ssh</span> root@k8s-master2 <span class="string">"mkdir -p /opt/etcd/ssl/"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝 CA 证书和 Etcd 证书到其他 Master 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/etcd/*.pem root@k8s-master2:/opt/etcd/ssl/</span><br></pre></td></tr></tbody></table></figure><h4 id="部署-Etcd-集群"><a href="#部署-Etcd-集群" class="headerlink" title="部署 Etcd 集群"></a>部署 Etcd 集群</h4><p>在第一个 Master 节点（<code>k8s-master1</code>）里面安装 Etcd</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载二进制包</span></span><br><span class="line"><span class="keyword"># wget</span> https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /opt/etcd/{bin,cfg,ssl}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line"><span class="keyword"># tar</span> zxvf etcd-v3.4.9-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移动文件</span></span><br><span class="line"><span class="keyword"># mv</span> etcd-v3.4.9-linux-amd64/{etcd,etcdctl} /opt/etcd/bin/</span><br></pre></td></tr></tbody></table></figure><p>在第一个 Master 节点（<code>k8s-master1</code>）里面创建 Etcd 的配置文件，<strong>这里必须根据实际情况更改 Etcd 节点的 IP、名称，切勿直接拷贝以下配置内容</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建Etcd的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOF</span><br><span class="line"><span class="comment">#[Member]</span></span><br><span class="line">ETCD_NAME=<span class="string">"etcd-1"</span></span><br><span class="line">ETCD_DATA_DIR=<span class="string">"/var/lib/etcd/default.etcd"</span></span><br><span class="line">ETCD_LISTEN_PEER_URLS=<span class="string">"https://192.168.2.191:2380"</span></span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=<span class="string">"https://192.168.2.191:2379"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#[Cluster]</span></span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=<span class="string">"https://192.168.2.191:2380"</span></span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=<span class="string">"https://192.168.2.191:2379"</span></span><br><span class="line">ETCD_INITIAL_CLUSTER=<span class="string">"etcd-1=https://192.168.2.191:2380,etcd-2=https://192.168.2.112:2380,etcd-3=https://192.168.2.131:2380"</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN=<span class="string">"etcd-cluster"</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=<span class="string">"new"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 配置说明：</span><br><span class="line">ETCD_NAME：节点名称，集群中唯一</span><br><span class="line">ETCDDATADIR：数据目录路径</span><br><span class="line">ETCD_LISTEN_PEER_URLS：集群通信监听地址</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址</span><br><span class="line">ETCD_INITIAL_CLUSTER：集群节点地址</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN：集群 Token</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new 是新集群，existing 表示加入已有集群</span><br></pre></td></tr></tbody></table></figure><p>在第一个 Master 节点（<code>k8s-master1</code>）里面使用 Systemd 管理 Etcd 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建Etcd服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=/opt/etcd/cfg/etcd.conf</span><br><span class="line">ExecStart=/opt/etcd/bin/etcd \<span class="params"></span></span><br><span class="line"><span class="params">--cert</span>-file=/opt/etcd/ssl/server.pem \<span class="params"></span></span><br><span class="line"><span class="params">--key</span>-file=/opt/etcd/ssl/server-key.pem \<span class="params"></span></span><br><span class="line"><span class="params">--peer</span>-cert-file=/opt/etcd/ssl/server.pem \<span class="params"></span></span><br><span class="line"><span class="params">--peer</span>-key-file=/opt/etcd/ssl/server-key.pem \<span class="params"></span></span><br><span class="line"><span class="params">--trusted</span>-ca-file=/opt/etcd/ssl/ca.pem \<span class="params"></span></span><br><span class="line"><span class="params">--peer</span>-trusted-ca-file=/opt/etcd/ssl/ca.pem \<span class="params"></span></span><br><span class="line"><span class="params">--logger</span>=zap</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动Etcd服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> etcd</span><br></pre></td></tr></tbody></table></figure><hr><p>在第一个 Master 节点（<code>k8s-master1</code>）里面拷贝所有 Etcd 文件到其他 2 个 Node 节点，并在这 2 个 Node 节点里分别更改 Etcd 的配置文件和设置 Etcd 服务开机自启动，最终 Etcd 集群会有 3 个节点</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝Etcd的所有文件到各个Node节点</span></span><br><span class="line"><span class="keyword"># scp</span><span class="params"> -r</span> /opt/etcd/ root@k8s-node1:/opt/</span><br><span class="line"><span class="keyword"># scp</span><span class="params"> -r</span> /opt/etcd/ root@k8s-node2:/opt/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝Etcd服务管理的配置文件到各个Node节点</span></span><br><span class="line"><span class="keyword"># scp</span> /usr/lib/systemd/system/etcd.service root@k8s-node1:/usr/lib/systemd/system/</span><br><span class="line"><span class="keyword"># scp</span> /usr/lib/systemd/system/etcd.service root@k8s-node2:/usr/lib/systemd/system/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在其他2个Node节点里分别编辑Etcd的配置文件，包括更改当前节点的名称（"ETCD_NAME"）和IP，注意除了 "ETCD_INITIAL_CLUSTER" 配置项里的IP不需要更改，其他IP都需要更改为当前节点的IP</span></span><br><span class="line"><span class="keyword"># vim</span> /opt/etcd/cfg/etcd.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在其他2个Node节点里分别设置Etcd服务开机自启动</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> etcd</span><br></pre></td></tr></tbody></table></figure><p>比如，Etcd 集群第 2 个节点的配置文件（<code>etcd.conf</code>）内容如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ETCD_NAME="etcd-2"</span><br><span class="line">ETCD_DATA_DIR="/var/lib/etcd/default.etcd"</span><br><span class="line">ETCD_LISTEN_PEER_URLS="https://192.168.2.112:2380"</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS="https://192.168.2.112:2379"</span><br><span class="line"></span><br><span class="line">#[Cluster]</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.2.112:2380"</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS="https://192.168.2.112:2379"</span><br><span class="line">ETCD_INITIAL_CLUSTER="etcd-1=https://192.168.2.191:2380,etcd-2=https://192.168.2.112:2380,etcd-3=https://192.168.2.131:2380"</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE="new"</span><br></pre></td></tr></tbody></table></figure><p>比如，Etcd 集群第 3 个节点的配置文件（<code>etcd.conf</code>）内容如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ETCD_NAME="etcd-3"</span><br><span class="line">ETCD_DATA_DIR="/var/lib/etcd/default.etcd"</span><br><span class="line">ETCD_LISTEN_PEER_URLS="https://192.168.2.131:2380"</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS="https://192.168.2.131:2379"</span><br><span class="line"></span><br><span class="line">#[Cluster]</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.2.131:2380"</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS="https://192.168.2.131:2379"</span><br><span class="line">ETCD_INITIAL_CLUSTER="etcd-1=https://192.168.2.191:2380,etcd-2=https://192.168.2.112:2380,etcd-3=https://192.168.2.131:2380"</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE="new"</span><br></pre></td></tr></tbody></table></figure><h4 id="启动-Etcd-集群"><a href="#启动-Etcd-集群" class="headerlink" title="启动 Etcd 集群"></a>启动 Etcd 集群</h4><p>在 Etcd 集群的所有节点上分别执行以下命令来启动 Etcd，<strong>值得一提的是，必须在多个 Etcd 节点里同时执行 <code>systemctl start etcd</code> 命令来启动 Etcd 集群，否则单个 Etcd 节点是无法正常启动的</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Etcd服务（多个节点必须同时启动）</span></span><br><span class="line"><span class="keyword"># systemctl</span> start etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Etcd服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Etcd服务的启动日志（可用于排查启动问题）</span></span><br><span class="line"><span class="keyword"># journalctl</span><span class="params"> -u</span> etcd.service</span><br></pre></td></tr></tbody></table></figure><p>若 Etcd 集群启动成功，可以在任意一个 Etcd 节点里执行以下命令来查看集群的运行状态，比如 Leader 选举结果（<strong>请自行更改 Etcd 集群节点的 IP 和端口，切勿直接拷贝执行以下命令</strong>）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看Etcd集群的运行状态</span></span><br><span class="line"><span class="comment"># /opt/etcd/bin/etcdctl --endpoints=https://192.168.2.191:2379,https://192.168.2.112:2379,https://192.168.2.131:2379 --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem endpoint status --write-out=table</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| https://192.168.2.191:2379 |   9a8c44f9310511 |   3.4.9 |  442 kB |      true |      false |         2 |        519 |                519 |        |</span><br><span class="line">| https://192.168.2.112:2379 | a00042f5519886e3 |   3.4.9 |  451 kB |     false |      false |         2 |        519 |                519 |        |</span><br><span class="line">| https://192.168.2.131:2379 | 9cb4eb07d38510b5 |   3.4.9 |  446 kB |     false |      false |         2 |        519 |                519 |        |</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></tbody></table></figure><p>若 Etcd 集群启动失败，可以在所有的 Etcd 节点里分别执行以下操作来解决</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭Etcd服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> stop etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除Etcd服务的数据目录</span></span><br><span class="line"><span class="keyword"># rm</span><span class="params"> -rf</span> /var/lib/etcd/default.etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启Etcd服务（多个Etcd节点必须同时重启）</span></span><br><span class="line"><span class="keyword"># systemctl</span> start etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Etcd服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status etcd</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>Etcd 集群使用了 Raft 协议，很多操作要依赖时间戳和进行超时判断，因此必须安装类似 <code>chrony</code> 这样的工具来同步操作系统的时间，否则可能会影响 Etcd 集群的正常工作。</p></div><h3 id="搭建-Kubernetes-集群"><a href="#搭建-Kubernetes-集群" class="headerlink" title="搭建 Kubernetes 集群"></a>搭建 Kubernetes 集群</h3><h4 id="生成集群证书"><a href="#生成集群证书" class="headerlink" title="生成集群证书"></a>生成集群证书</h4><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><strong>以下所有操作都是仅在 Kubernetes 集群的任意一个 Master 节点（比如 <code>k8s-master1</code>）上执行，千万不要在每个 Kubernetes 集群节点上单独生成 API Server 或者 Kube-Proxy 等证书，否则可能会因证书不一致而导致 Kubernetes 集群启动失败</strong>。</li><li><strong>简而言之，所有证书（包括 API Server、Kube-Proxy 等证书）都是在任意一个 Master 节点上面生成，其他 Kubernetes 集群节点不参与生成证书。以后向 Kubernetes 集群中添加任何新节点时，只要将对应的证书拷贝到新节点上即可</strong>。</li><li>值得一提的是，通过 CFSSL 工具生成证书的详细使用教程请看 <a href="/posts/58887565.html">这里</a>。</li></ul></div><table><thead><tr><th>组件</th><th>使用的证书</th></tr></thead><tbody><tr><td> CA 根证书</td><td><code>ca.pem</code>、<code>ca-key.pem</code></td></tr><tr><td>API Server</td><td><code>ca.pem</code>、<code>kube-apiserver-key.pem</code>、<code>kube-apiserver.pem</code></td></tr><tr><td>Controller Manager</td><td><code>ca.pem</code>、<code>kube-controller-manager-key.pem</code>、<code>kube-controller-manager.pem</code></td></tr><tr><td>Scheduler</td><td><code>ca.pem</code>、<code>kube-scheduler-key.pem</code>、<code>kube-scheduler.pem</code></td></tr><tr><td>Kubelet</td><td><code>ca.pem</code></td></tr><tr><td>Kube-Proxy</td><td><code>ca.pem</code>、<code>kube-proxy-key.pem</code>、<code>kube-proxy.pem</code></td></tr></tbody></table><h5 id="生成-CA-根证书"><a href="#生成-CA-根证书" class="headerlink" title="生成 CA 根证书"></a>生成 CA 根证书</h5><p>创建存放证书的目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里为了避免与上面生成的 Etcd 证书混淆，创建一个新的证书目录，然后在该目录下存放 Kubernetes 集群所需的证书</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> ~/tls/k8s/</span><br></pre></td></tr></tbody></table></figure><p>进入存放证书的目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入证书目录</span></span><br><span class="line"><span class="keyword"># cd</span> ~/tls/k8s/</span><br></pre></td></tr></tbody></table></figure><p>创建 CA 证书的配置文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; ca-config.json &lt;&lt; EOF</span><br><span class="line">{</span><br><span class="line">    <span class="string">"signing"</span>: {</span><br><span class="line">        <span class="string">"default"</span>: {</span><br><span class="line">            <span class="string">"expiry"</span>: <span class="string">"87600h"</span></span><br><span class="line">        }, </span><br><span class="line">        <span class="string">"profiles"</span>: {</span><br><span class="line">            <span class="string">"kubernetes"</span>: {</span><br><span class="line">                <span class="string">"expiry"</span>: <span class="string">"87600h"</span>, </span><br><span class="line">                <span class="string">"usages"</span>: [</span><br><span class="line">                    <span class="string">"signing"</span>, </span><br><span class="line">                    <span class="string">"key encipherment"</span>, </span><br><span class="line">                    <span class="string">"server auth"</span>, </span><br><span class="line">                    <span class="string">"client auth"</span></span><br><span class="line">                ]</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>创建 CA 证书签名的配置文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; ca-csr.json &lt;&lt; EOF</span><br><span class="line">{</span><br><span class="line">    <span class="string">"CN"</span>: <span class="string">"kubernetes"</span>, </span><br><span class="line">    <span class="string">"key"</span>: {</span><br><span class="line">        <span class="string">"algo"</span>: <span class="string">"rsa"</span>, </span><br><span class="line">        <span class="string">"size"</span>: 2048</span><br><span class="line">    }, </span><br><span class="line">    <span class="string">"names"</span>: [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"C"</span>: <span class="string">"CN"</span>, </span><br><span class="line">            <span class="string">"L"</span>: <span class="string">"Beijing"</span>, </span><br><span class="line">            <span class="string">"ST"</span>: <span class="string">"Beijing"</span>, </span><br><span class="line">            <span class="string">"O"</span>: <span class="string">"k8s"</span>, </span><br><span class="line">            <span class="string">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">        }</span><br><span class="line">    ]</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>生成 CA 证书</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成CA证书</span></span><br><span class="line"><span class="keyword"># cfssl</span> gencert<span class="params"> -initca</span> ca-csr.json | cfssljson<span class="params"> -bare</span> ca -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的CA证书</span></span><br><span class="line"><span class="keyword"># ls</span> ca*.pem</span><br><span class="line">ca-key.pem  ca.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证生成的CA证书</span></span><br><span class="line"><span class="keyword"># cfssl</span>-certinfo<span class="params"> -cert</span> ca.pem</span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params">  -noout</span><span class="params"> -text</span><span class="params"> -in</span>  ca.pem</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 CA 证书拷贝到本地目录里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建存放证书的本地目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /opt/kubernetes/ssl/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝 CA 证书到本地目录</span></span><br><span class="line"><span class="keyword"># cp</span> ~/tls/k8s/ca*.pem /opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 CA 证书拷贝到其他 Master 节点里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在其他 Master 节点上分别创建存放证书的目录</span></span><br><span class="line"><span class="keyword"># ssh</span> root@k8s-master2 <span class="string">"mkdir -p /opt/kubernetes/ssl/"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝 CA 证书到其他 Master 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/ca*.pem root@k8s-master2:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 CA 证书拷贝到所有 Node 节点里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在所有 Node 节点上分别创建存放证书的目录</span></span><br><span class="line"><span class="keyword"># ssh</span> root@k8s-node1 <span class="string">"mkdir -p /opt/kubernetes/ssl/"</span></span><br><span class="line"><span class="keyword"># ssh</span> root@k8s-node2 <span class="string">"mkdir -p /opt/kubernetes/ssl/"</span></span><br><span class="line"><span class="keyword"># ssh</span> root@k8s-node3 <span class="string">"mkdir -p /opt/kubernetes/ssl/"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝 CA 证书到所有 Node 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/ca*.pem root@k8s-node1:/opt/kubernetes/ssl/</span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/ca*.pem root@k8s-node2:/opt/kubernetes/ssl/</span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/ca*.pem root@k8s-node3:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><h5 id="生成-API-Server-证书"><a href="#生成-API-Server-证书" class="headerlink" title="生成 API Server 证书"></a>生成 API Server 证书</h5><p>进入存放证书的目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入证书目录</span></span><br><span class="line"><span class="keyword"># cd</span> ~/tls/k8s/</span><br></pre></td></tr></tbody></table></figure><p>创建用于生成 API Server 证书的配置文件，如果 <code>hosts</code> 字段不为空，需要指定授权使用该证书的 IP 或域名列表。由于该证书会被 Kubernetes 集群使用到，通常需要包含 Kubernetes 集群所有节点的 IP，以及 Kubernetes 服务的 Cluster IP（即 <code>kube-apiserver.conf</code> 配置文件中指定的 <code>--service-cluster-ip-range</code> 网段的第一个可用 IP，例如 <code>10.0.0.1</code>，具体取决于 Kubernetes 集群的 Service 网段配置），<strong>最后还要加上 Keepalived 的虚拟 IP 地址（比如 <code>192.168.2.100</code>）</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &lt;&lt; EOF | tee kube-apiserver-csr.json</span><br><span class="line">{</span><br><span class="line">    <span class="string">"CN"</span>: <span class="string">"kubernetes"</span>, </span><br><span class="line">    <span class="string">"hosts"</span>: [</span><br><span class="line">        <span class="string">"10.0.0.1"</span>,</span><br><span class="line">        <span class="string">"127.0.0.1"</span>,</span><br><span class="line">        <span class="string">"192.168.2.191"</span>,</span><br><span class="line">        <span class="string">"192.168.2.148"</span>,</span><br><span class="line">        <span class="string">"192.168.2.112"</span>,</span><br><span class="line">        <span class="string">"192.168.2.131"</span>,</span><br><span class="line">        <span class="string">"192.168.2.236"</span>,</span><br><span class="line">        <span class="string">"192.168.2.100"</span>,</span><br><span class="line">        <span class="string">"kubernetes"</span>, </span><br><span class="line">        <span class="string">"kubernetes.default"</span>, </span><br><span class="line">        <span class="string">"kubernetes.default.svc"</span>, </span><br><span class="line">        <span class="string">"kubernetes.default.svc.cluster"</span>, </span><br><span class="line">        <span class="string">"kubernetes.default.svc.cluster.local"</span></span><br><span class="line">    ], </span><br><span class="line">    <span class="string">"key"</span>: {</span><br><span class="line">        <span class="string">"algo"</span>: <span class="string">"rsa"</span>, </span><br><span class="line">        <span class="string">"size"</span>: 2048</span><br><span class="line">    }, </span><br><span class="line">    <span class="string">"names"</span>: [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"C"</span>: <span class="string">"CN"</span>, </span><br><span class="line">            <span class="string">"ST"</span>: <span class="string">"BeiJing"</span>, </span><br><span class="line">            <span class="string">"L"</span>: <span class="string">"BeiJing"</span>, </span><br><span class="line">            <span class="string">"O"</span>: <span class="string">"k8s"</span>, </span><br><span class="line">            <span class="string">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">        }</span><br><span class="line">    ]</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>使用自签 CA 签发 API Server 证书</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前目录下的文件</span></span><br><span class="line"><span class="keyword"># ls</span></span><br><span class="line">ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem  kube-apiserver-csr.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自签 CA 证书签发 API Server 的 HTTPS 证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致</span></span><br><span class="line"><span class="keyword"># cfssl</span> gencert<span class="params"> -ca</span>=ca.pem<span class="params"> -ca</span>-key=ca-key.pem<span class="params"> -config</span>=ca-config.json<span class="params"> -profile</span>=kubernetes kube-apiserver-csr.json | cfssljson<span class="params"> -bare</span> kube-apiserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的 API Server 证书</span></span><br><span class="line"><span class="keyword"># ls</span> kube-apiserver*.pem</span><br><span class="line">kube-apiserver-key.pem  kube-apiserver.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证生成的 API Server 证书</span></span><br><span class="line"><span class="keyword"># cfssl</span>-certinfo<span class="params"> -cert</span> kube-apiserver.pem</span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params">  -noout</span><span class="params"> -text</span><span class="params"> -in</span>  kube-apiserver.pem</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 API Server 证书拷贝到本地目录里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 API Server 证书到本地目录</span></span><br><span class="line"><span class="keyword"># cp</span> ~/tls/k8s/kube-apiserver*.pem /opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 API Server 证书拷贝到其他 Master 节点里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 API Server 证书到其他 Master 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/kube-apiserver*.pem root@k8s-master2:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><h5 id="生成-Controller-Manager-证书"><a href="#生成-Controller-Manager-证书" class="headerlink" title="生成 Controller Manager 证书"></a>生成 Controller Manager 证书</h5><p>进入存放证书的目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入证书目录</span></span><br><span class="line"><span class="keyword"># cd</span> ~/tls/k8s/</span><br></pre></td></tr></tbody></table></figure><p>创建用于生成 Controller Manager 证书的配置文件，<code>hosts</code> 必须包含 <code>127.0.0.1</code>、所有 Master 节点的 IP、Keepalived 的虚拟 IP 地址（比如 <code>192.168.2.100</code>），<strong>请自行更改，切勿直接拷贝使用以下配置</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; kube-controller-manager-csr.json &lt;&lt; EOF</span><br><span class="line">{</span><br><span class="line">  <span class="string">"CN"</span>: <span class="string">"system:kube-controller-manager"</span>,</span><br><span class="line">  <span class="string">"hosts"</span>: [</span><br><span class="line">    <span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="string">"192.168.2.191"</span>,</span><br><span class="line">    <span class="string">"192.168.2.148"</span>,</span><br><span class="line">    <span class="string">"192.168.2.100"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"key"</span>: {</span><br><span class="line">    <span class="string">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="string">"size"</span>: 2048</span><br><span class="line">  },</span><br><span class="line">  <span class="string">"names"</span>: [</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="string">"ST"</span>: <span class="string">"Beijing"</span>,</span><br><span class="line">      <span class="string">"L"</span>: <span class="string">"Beijing"</span>,</span><br><span class="line">      <span class="string">"O"</span>: <span class="string">"system:kube-controller-manager"</span>,</span><br><span class="line">      <span class="string">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">    }</span><br><span class="line">  ]</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>使用自签 CA 签发 Controller Manager 证书</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前目录下的文件</span></span><br><span class="line"><span class="keyword"># ls</span></span><br><span class="line">ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem  kube-apiserver.csr  kube-apiserver-csr.json  kube-apiserver-key.pem  kube-apiserver.pem  kube-controller-manager-csr.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自签 CA 证书签发 Controller Manager 证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致</span></span><br><span class="line"><span class="keyword"># cfssl</span> gencert<span class="params"> -ca</span>=ca.pem<span class="params"> -ca</span>-key=ca-key.pem<span class="params"> -config</span>=ca-config.json<span class="params"> -profile</span>=kubernetes kube-controller-manager-csr.json | cfssljson<span class="params"> -bare</span> kube-controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的 Controller Manager 证书</span></span><br><span class="line"><span class="keyword"># ls</span> kube-controller-manager*.pem</span><br><span class="line">kube-controller-manager-key.pem  kube-controller-manager.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证生成的 Controller Manager 证书</span></span><br><span class="line"><span class="keyword"># cfssl</span>-certinfo<span class="params"> -cert</span> kube-controller-manager.pem</span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params">  -noout</span><span class="params"> -text</span><span class="params"> -in</span>  kube-controller-manager.pem</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 Controller Manager 证书拷贝到本地目录里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Controller Manager 证书到本地目录</span></span><br><span class="line"><span class="keyword"># cp</span> ~/tls/k8s/kube-controller-manager*.pem /opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 Controller Manager 证书拷贝到其他 Master 节点里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Controller Manager 证书到其他 Master 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/kube-controller-manager*.pem root@k8s-master2:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><h5 id="生成-Scheduler-证书"><a href="#生成-Scheduler-证书" class="headerlink" title="生成 Scheduler 证书"></a>生成 Scheduler 证书</h5><p>进入存放证书的目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入证书目录</span></span><br><span class="line"><span class="keyword"># cd</span> ~/tls/k8s/</span><br></pre></td></tr></tbody></table></figure><p>创建用于生成 Scheduler 证书的配置文件，<code>hosts</code> 必须包含 <code>127.0.0.1</code>、所有 Master 节点的 IP、Keepalived 的虚拟 IP 地址（比如 <code>192.168.2.100</code>），<strong>请自行更改，切勿直接拷贝使用以下配置</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; kube-scheduler-csr.json &lt;&lt; EOF</span><br><span class="line">{</span><br><span class="line">  <span class="string">"CN"</span>: <span class="string">"system:kube-scheduler"</span>,</span><br><span class="line">  <span class="string">"hosts"</span>: [</span><br><span class="line">    <span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="string">"192.168.2.191"</span>,</span><br><span class="line">    <span class="string">"192.168.2.148"</span>,</span><br><span class="line">    <span class="string">"192.168.2.100"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"key"</span>: {</span><br><span class="line">    <span class="string">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="string">"size"</span>: 2048</span><br><span class="line">  },</span><br><span class="line">  <span class="string">"names"</span>: [</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="string">"ST"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="string">"L"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="string">"O"</span>: <span class="string">"system:kube-scheduler"</span>,</span><br><span class="line">      <span class="string">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">    }</span><br><span class="line">  ]</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>使用自签 CA 签发 Scheduler 证书</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前目录下的文件</span></span><br><span class="line"><span class="keyword"># ls</span></span><br><span class="line">ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem  kube-apiserver.csr  kube-apiserver-csr.json  kube-apiserver-key.pem  kube-apiserver.pem  kube-controller-manager.csr  kube-controller-manager-csr.json  kube-controller-manager-key.pem  kube-controller-manager.pem  kube-scheduler-csr.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自签 CA 证书签发 Scheduler 证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致</span></span><br><span class="line"><span class="keyword"># cfssl</span> gencert<span class="params"> -ca</span>=ca.pem<span class="params"> -ca</span>-key=ca-key.pem<span class="params"> -config</span>=ca-config.json<span class="params"> -profile</span>=kubernetes kube-scheduler-csr.json | cfssljson<span class="params"> -bare</span> kube-scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的 Scheduler 证书</span></span><br><span class="line"><span class="keyword"># ls</span> kube-scheduler*.pem</span><br><span class="line">kube-scheduler-key.pem  kube-scheduler.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证生成的 Scheduler 证书</span></span><br><span class="line"><span class="keyword"># cfssl</span>-certinfo<span class="params"> -cert</span> kube-scheduler.pem</span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params">  -noout</span><span class="params"> -text</span><span class="params"> -in</span> kube-scheduler.pem</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 Scheduler 证书拷贝到本地目录里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Scheduler 证书到本地目录</span></span><br><span class="line"><span class="keyword"># cp</span> ~/tls/k8s/kube-scheduler*.pem /opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 Scheduler 证书拷贝到其他 Master 节点里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Scheduler 证书到其他 Master 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/kube-scheduler*.pem root@k8s-master2:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><h5 id="生成-Kube-Proxy-证书"><a href="#生成-Kube-Proxy-证书" class="headerlink" title="生成 Kube-Proxy 证书"></a>生成 Kube-Proxy 证书</h5><p>进入存放证书的目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入证书目录</span></span><br><span class="line"><span class="keyword"># cd</span> ~/tls/k8s/</span><br></pre></td></tr></tbody></table></figure><p>创建用于生成 Kube-Proxy 证书的配置文件，<code>hosts</code> 配置项的值可以为空，因为 Kube-Proxy 不直接被访问</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; kube-proxy-csr.json &lt;&lt; EOF</span><br><span class="line">{</span><br><span class="line">  <span class="string">"CN"</span>: <span class="string">"system:kube-proxy"</span>,</span><br><span class="line">  <span class="string">"hosts"</span>: [],</span><br><span class="line">  <span class="string">"key"</span>: {</span><br><span class="line">    <span class="string">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="string">"size"</span>: 2048</span><br><span class="line">  },</span><br><span class="line">  <span class="string">"names"</span>: [</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="string">"L"</span>: <span class="string">"Beijing"</span>,</span><br><span class="line">      <span class="string">"ST"</span>: <span class="string">"Beijing"</span>,</span><br><span class="line">      <span class="string">"O"</span>: <span class="string">"system:node-proxier"</span>,</span><br><span class="line">      <span class="string">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">    }</span><br><span class="line">  ]</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>使用自签 CA 签发 Kube-Proxy 证书</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前目录下的文件</span></span><br><span class="line"><span class="keyword"># ls</span></span><br><span class="line">ca-config.json  ca-csr.json  ca.pem              kube-apiserver-csr.json  kube-apiserver.pem           kube-controller-manager-csr.json  kube-controller-manager.pem  kube-scheduler.csr       kube-scheduler-key.pem</span><br><span class="line">ca.csr          ca-key.pem   kube-apiserver.csr  kube-apiserver-key.pem   kube-controller-manager.csr  kube-controller-manager-key.pem   kube-proxy-csr.json          kube-scheduler-csr.json  kube-scheduler.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自签 CA 证书签发 Kube-Proxy 证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致</span></span><br><span class="line"><span class="keyword"># cfssl</span> gencert<span class="params"> -ca</span>=ca.pem<span class="params"> -ca</span>-key=ca-key.pem<span class="params"> -config</span>=ca-config.json<span class="params"> -profile</span>=kubernetes kube-proxy-csr.json | cfssljson<span class="params"> -bare</span> kube-proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的 Kube-Proxy 证书</span></span><br><span class="line"><span class="keyword"># ls</span> kube-proxy*.pem</span><br><span class="line">kube-proxy-key.pem  kube-proxy.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证生成的 Kube-Proxy 证书</span></span><br><span class="line"><span class="keyword"># cfssl</span>-certinfo<span class="params"> -cert</span> kube-proxy.pem</span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params">  -noout</span><span class="params"> -text</span><span class="params"> -in</span>  kube-proxy.pem</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 Kube-Proxy 证书拷贝到本地目录里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Kube-Proxy 证书到本地目录</span></span><br><span class="line"><span class="keyword"># cp</span> ~/tls/k8s/kube-proxy*.pem /opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 Kube-Proxy 证书拷贝到其他 Master 节点里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Kube-Proxy 证书到其他 Master 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/kube-proxy*.pem root@k8s-master2:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><p>将上面生成的 Kube-Proxy 证书拷贝到所有 Node 节点里面</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Kube-Proxy 证书到所有 Node 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/kube-proxy*.pem root@k8s-node1:/opt/kubernetes/ssl/</span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/kube-proxy*.pem root@k8s-node2:/opt/kubernetes/ssl/</span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/kube-proxy*.pem root@k8s-node3:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><h4 id="单独部署-Master-节点"><a href="#单独部署-Master-节点" class="headerlink" title="单独部署 Master 节点"></a>单独部署 Master 节点</h4><div class="admonition warning"><p class="admonition-title">特别注意</p><p><strong>以下所有操作都是仅在 Kubernetes 集群的两台 Master 节点上执行，也就是分别在两台 Master 节点上部署 API Server、Controller Manager、Scheduler、HaProxy、Keepalived</strong>。</p></div><h5 id="下载二进制文件"><a href="#下载二进制文件" class="headerlink" title="下载二进制文件"></a>下载二进制文件</h5><div class="admonition note"><p class="admonition-title">下载地址</p><ul><li>Kubernetes 相关的二进制包可以从 <a target="_blank" rel="external nofollow" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md#v11910">GitHub</a> 下载得到，这里下载的版本是 <code>v1.19.10</code>。</li><li>当打开 <a target="_blank" rel="external nofollow" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md#v11910">GitHub</a> 链接后，会发现里面有很多二进制包，只需要下载一个 <a target="_blank" rel="external nofollow" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md#server-binaries-6">Server</a> 二进制包就够了，里面包含了 Master 节点相关的二进制包。</li></ul></div><p>下载并解压二进制包</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载二进制包（耗时较长）</span></span><br><span class="line"><span class="keyword"># wget</span> https://dl.k8s.io/v1.19.10/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /opt/kubernetes/{bin,cfg,ssl,logs}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line"><span class="keyword"># tar</span> zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入解压目录</span></span><br><span class="line"><span class="keyword"># cd</span> kubernetes/server/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝文件</span></span><br><span class="line"><span class="keyword"># cp</span> kube-apiserver kube-scheduler kube-controller-manager /opt/kubernetes/bin/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝文件</span></span><br><span class="line"><span class="keyword"># cp</span> kubectl /usr/bin/</span><br></pre></td></tr></tbody></table></figure><h5 id="部署-API-Server"><a href="#部署-API-Server" class="headerlink" title="部署 API Server"></a>部署 API Server</h5><p>创建 API Server 的配置文件，使用转义符 <code>\\</code> 是为了使 EOF 保留换行符。<strong>请自行更改 <code>--bind-address</code> 与 <code>--advertise-address</code> 的值为当前 Master 节点的 IP 地址（比如 <code>192.168.2.191</code>），而 <code>--etcd-servers</code> 需要改为 Etcd 所有集群节点的 IP 地址，其他配置可以不更改，切勿直接拷贝以下配置内容</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kube-apiserver.conf &lt;&lt; EOF</span><br><span class="line">KUBE_APISERVER_OPTS=<span class="string">"--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--etcd-servers=https://192.168.2.191:2379,https://192.168.2.112:2379,https://192.168.2.131:2379 \\</span></span><br><span class="line"><span class="string">--bind-address=&lt;当前节点的IP地址&gt; \\</span></span><br><span class="line"><span class="string">--secure-port=6443 \\</span></span><br><span class="line"><span class="string">--advertise-address=&lt;当前节点的IP地址&gt; \\</span></span><br><span class="line"><span class="string">--allow-privileged=true \\</span></span><br><span class="line"><span class="string">--service-cluster-ip-range=10.0.0.0/24 \\</span></span><br><span class="line"><span class="string">--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \\</span></span><br><span class="line"><span class="string">--authorization-mode=RBAC,Node \\</span></span><br><span class="line"><span class="string">--enable-bootstrap-token-auth=true \\</span></span><br><span class="line"><span class="string">--token-auth-file=/opt/kubernetes/cfg/token.csv \\</span></span><br><span class="line"><span class="string">--service-node-port-range=30000-32767 \\</span></span><br><span class="line"><span class="string">--kubelet-client-certificate=/opt/kubernetes/ssl/kube-apiserver.pem \\</span></span><br><span class="line"><span class="string">--kubelet-client-key=/opt/kubernetes/ssl/kube-apiserver-key.pem \\</span></span><br><span class="line"><span class="string">--tls-cert-file=/opt/kubernetes/ssl/kube-apiserver.pem \\</span></span><br><span class="line"><span class="string">--tls-private-key-file=/opt/kubernetes/ssl/kube-apiserver-key.pem \\</span></span><br><span class="line"><span class="string">--client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--etcd-cafile=/opt/etcd/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--etcd-certfile=/opt/etcd/ssl/server.pem \\</span></span><br><span class="line"><span class="string">--etcd-keyfile=/opt/etcd/ssl/server-key.pem \\</span></span><br><span class="line"><span class="string">--audit-log-maxage=30 \\</span></span><br><span class="line"><span class="string">--audit-log-maxbackup=3 \\</span></span><br><span class="line"><span class="string">--audit-log-maxsize=100 \\</span></span><br><span class="line"><span class="string">--audit-log-path=/opt/kubernetes/logs/k8s-audit.log"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>配置参数说明</p><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td><code>--logtostderr</code></td><td>启用将日志输出到 stderr（通常设为 <code>false</code> 以输出到指定目录）。</td></tr><tr><td><code>--v</code></td><td>日志详细级别（verbosity level），数值越大输出越详细。</td></tr><tr><td><code>--log-dir</code></td><td>日志文件输出目录。</td></tr><tr><td><code>--etcd-servers</code></td><td>Etcd 集群地址列表（用逗号分隔，支持 HTTPS）。</td></tr><tr><td><code>--bind-address</code></td><td>Kube-ApiServer 监听的 IP 地址，通常是 Master 节点的 IP 地址。</td></tr><tr><td><code>--secure-port</code></td><td>HTTPS 安全端口（默认 <code>6443</code>）。</td></tr><tr><td><code>--advertise-address</code></td><td>集群中对外通告的地址（其他组件访问时使用），通常是 Master 节点的 IP 地址。</td></tr><tr><td><code>--allow-privileged</code></td><td>是否允许特权容器（启用授权相关特性）。</td></tr><tr><td><code>--service-cluster-ip-range</code></td><td>Service 虚拟 IP 地址段，用于分配 Cluster IP。</td></tr><tr><td><code>--enable-admission-plugins</code></td><td>启用的准入控制插件列表（例如 NamespaceLifecycle, LimitRanger 等）。</td></tr><tr><td><code>--authorization-mode</code></td><td>认证 / 授权模式（如 <code>RBAC,Node</code> 表示启用 RBAC 和节点自管理）。</td></tr><tr><td><code>--enable-bootstrap-token-auth</code></td><td>启用基于 Bootstrap Token 的 TLS 引导认证。</td></tr><tr><td><code>--token-auth-file</code></td><td>Bootstrap Token 的静态文件路径（比如 <code>token.csv</code>）。</td></tr><tr><td><code>--service-node-port-range</code></td><td>NodePort 类型 Service 默认分配的端口范围（如 <code>30000-32767</code>）。</td></tr><tr><td><code>--kubelet-client-certificate</code></td><td>Kube-ApiServer 访问 kubelet 时使用的客户端证书路径。</td></tr><tr><td><code>--kubelet-client-key</code></td><td>Kube-ApiServer 访问 kubelet 时使用的客户端私钥路径。</td></tr><tr><td><code>--tls-cert-file</code></td><td>Kube-ApiServer HTTPS 使用的证书文件。</td></tr><tr><td><code>--tls-private-key-file</code></td><td>Kube-ApiServer HTTPS 使用的私钥文件。</td></tr><tr><td><code>--client-ca-file</code></td><td>用于验证客户端证书（如 kubelet/client）的 CA 证书。</td></tr><tr><td><code>--service-account-key-file</code></td><td>用于签名 Service Account Token 的私钥文件。</td></tr><tr><td><code>--etcd-cafile</code></td><td>连接 Etcd 时验证其证书的 CA 证书路径。</td></tr><tr><td><code>--etcd-certfile</code></td><td>Kube-ApiServer 连接 Etcd 时使用的客户端证书。</td></tr><tr><td><code>--etcd-keyfile</code></td><td>Kube-ApiServer 连接 Etcd 时使用的客户端私钥。</td></tr><tr><td><code>--audit-log-maxage</code></td><td>审计日志保留的最大天数。</td></tr><tr><td><code>--audit-log-maxbackup</code></td><td>审计日志保留的备份数量。</td></tr><tr><td><code>--audit-log-maxsize</code></td><td>单个审计日志文件的最大大小（MB）。</td></tr><tr><td><code>--audit-log-path</code></td><td>审计日志输出路径。</td></tr></tbody></table><div class="admonition note"><p class="admonition-title">TLS Bootstraping 机制介绍</p><p>在 Master 节点中，API Server 启用 TLS 认证后，Node 节点上的 kubelet 和 kube-proxy 必须使用由 CA 签发的有效客户端证书才能与 kube-apiserver 通信。当 Node 节点数量较多时，手动颁发这些客户端证书的工作量大，且会增加集群扩展的复杂度。为简化这一流程，Kubernetes 引入了 TLS Bootstrapping 机制：kubelet 会以低权限用户身份向 API Server 自动申请客户端证书，并由 API Server 动态签发，从而实现证书的自动化管理。TLS Bootstrapping 机制的工作流程<a href="../../../asset/2025/07/k8s-tls-1.png">如图所示</a>。</p></div><p>创建在 API Server 配置文件（<code>kube-apiserver.conf</code>）中通过 <code>--token-auth-file</code> 指定的 Token 文件，用于配置 TLS Bootstrapping 机制</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建Token文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/token.csv &lt;&lt; EOF</span><br><span class="line">c47ffb939f5ca36231d9e3121a252940,kubelet-bootstrap,10001,<span class="string">"system:node-bootstrapper"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>Token 文件的数据格式是 <code>Token,用户名,UID,用户组</code>，其中 UID 仅作标识使用，可以是任意唯一值；用户组 <code>system:node-bootstrapper</code> 是 Kubelet TLS Bootstrap 必需的组；Token 可以使用以下命令自行生成并替换掉</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成Token</span></span><br><span class="line"><span class="keyword"># head</span><span class="params"> -c</span> 16 /dev/urandom | od<span class="params"> -An</span><span class="params"> -t</span> x | tr<span class="params"> -d</span> <span class="string">' '</span></span><br></pre></td></tr></tbody></table></figure><hr><p>配置 Systemd 管理 API Server 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 API Server 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.conf</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-apiserver \<span class="variable">$KUBE_APISERVER_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>启动并设置开机自启动 API Server 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动 API Server 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> kube-apiserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 API Server 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> start kube-apiserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 API Server 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-apiserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 API Server 服务的启动日志（可用于排查启动问题）</span></span><br><span class="line"><span class="keyword"># journalctl</span><span class="params"> -u</span> kube-apiserver.service</span><br></pre></td></tr></tbody></table></figure><p>授权 <code>kubelet-bootstrap</code> 用户允许请求（申请）证书，<strong>请注意，无论有多少个 Master 节点，都只需执行一次授权，重复执行授权会提示失败</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># kubectl</span> create clusterrolebinding kubelet-bootstrap<span class="params"> --clusterrole</span>=system:node-bootstrapper<span class="params"> --user</span>=kubelet-bootstrap</span><br></pre></td></tr></tbody></table></figure><h5 id="部署-HaProxy"><a href="#部署-HaProxy" class="headerlink" title="部署 HaProxy"></a>部署 HaProxy</h5><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><strong>在两台 Master 节点上，分别安装 HaProxy，两台 Master 节点上的 HaProxy 配置文件都是一样的</strong>。</li><li><strong>生产级 Kubernetes 高可用集群通常采用 HAProxy + Keepalived 实现 API Server 的负载均衡（高性能四层负载均衡），而不是使用 Nginx + Keepalived 替代（可选）。同时，会结合使用 Nginx Ingress 处理应用流量负载，两者分层清晰、运维简单</strong>。</li></ul></div><blockquote><p><strong>1. 安装概述</strong></p></blockquote><p>HAProxy 是一款广泛使用的反向代理与负载均衡软件，可以采用其四层（TCP）模式对 Kubernetes API Server 进行负载均衡，从而实现多 Master 节点的高可用访问。通过 HAProxy 构建 API Server 的高可用架构，其整体设计如下图所示：</p><p><img data-src="../../../asset/2025/11/k8s-ha-cluster-2.png"></p><table><thead><tr><th>安装说明</th><th>路径</th></tr></thead><tbody><tr><td> HaProxy 的安装路径</td><td><code>/usr/local/sbin/haproxy</code></td></tr><tr><td>HaProxy 的配置文件</td><td><code>/etc/haproxy/haproxy.cfg</code></td></tr><tr><td>HaProxy 的 PID 文件</td><td><code>/var/lib/haproxy/haproxy.pid</code></td></tr><tr><td>HaProxy 的 Socket 文件</td><td><code>/var/lib/haproxy/stats</code></td></tr><tr><td>HaProxy 的 Systemd 服务配置文件</td><td><code>/usr/lib/systemd/system/haproxy.service</code></td></tr></tbody></table><blockquote><p><strong>2. 安装步骤</strong></p></blockquote><p>安装依赖软件包</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装软件包</span></span><br><span class="line"><span class="keyword"># yum</span> install<span class="params"> -y</span> gcc make pcre-devel openssl openssl-devel systemd-devel wget</span><br></pre></td></tr></tbody></table></figure><p>下载 HaProxy 源码包（<a target="_blank" rel="external nofollow" href="https://www.haproxy.org/download">官网下载地址</a>）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载源码包</span></span><br><span class="line"><span class="keyword"># wget</span> https://www.haproxy.org/download/2.8/src/haproxy-2.8.5.tar.gz</span><br></pre></td></tr></tbody></table></figure><p>下载 HaProxy 源码包</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压源码包</span></span><br><span class="line"><span class="keyword"># tar</span><span class="params"> -xvf</span> haproxy-2.8.5.tar.gz</span><br></pre></td></tr></tbody></table></figure><p>编译源码与安装</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入源码包的解压目录</span></span><br><span class="line"><span class="keyword"># cd</span> haproxy-2.8.5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译源码</span></span><br><span class="line"><span class="keyword"># make</span> TARGET=linux-glibc \</span><br><span class="line">     USE_OPENSSL=1 \</span><br><span class="line">     USE_PCRE=1 \</span><br><span class="line">     USE_SYSTEMD=1 \</span><br><span class="line">     USE_ZLIB=1 \<span class="params"></span></span><br><span class="line"><span class="params">     -j</span>$(nproc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line"><span class="keyword"># make</span> install</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>3. 创建用户</strong></p></blockquote><p>创建 HaProxy 用户与用户组</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用户组</span></span><br><span class="line"><span class="keyword"># groupadd</span><span class="params"> --system</span> haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建用户（禁止登录）</span></span><br><span class="line"><span class="keyword"># useradd</span><span class="params"> --system</span><span class="params"> --no</span>-create-home<span class="params"> --shell</span> /sbin/nologin<span class="params"> --gid</span> haproxy haproxy</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>4. 配置服务</strong></p></blockquote><p>配置 Systemd 管理 HaProxy 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建系统配置文件，添加以下配置内容</span></span><br><span class="line"><span class="keyword"># vim</span> /usr/lib/systemd/system/haproxy.service</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=HAProxy Load Balancer</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=haproxy</span><br><span class="line">Group=haproxy</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">Environment="CONFIG=/etc/haproxy/haproxy.cfg" "PIDFILE=/var/lib/haproxy/haproxy.pid"</span><br><span class="line">ExecStartPre=/usr/local/sbin/haproxy -f $CONFIG -c -q</span><br><span class="line">ExecStart=/usr/local/sbin/haproxy -Ws -f $CONFIG -p $PIDFILE</span><br><span class="line">ExecReload=/bin/kill -USR2 $MAINPID</span><br><span class="line">KillMode=mixed</span><br><span class="line">Type=notify</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></tbody></table></figure><hr><p>创建 HaProxy 的运行目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建运行目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /var/lib/haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改运行目录的所有者</span></span><br><span class="line"><span class="keyword"># chown</span><span class="params"> -R</span> haproxy:haproxy /var/lib/haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置运行目录的权限</span></span><br><span class="line"><span class="keyword"># chmod</span> 750 /var/lib/haproxy</span><br></pre></td></tr></tbody></table></figure><p>创建 HaProxy 的配置目录</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /etc/haproxy</span><br></pre></td></tr></tbody></table></figure><p>创建 HaProxy 的配置文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件，添加以下配置内容</span></span><br><span class="line"><span class="keyword"># vim</span> /etc/haproxy/haproxy.cfg</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># Global settings</span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line">global</span><br><span class="line">    # to have these messages end up in /var/log/haproxy.log you will</span><br><span class="line">    # need to:</span><br><span class="line">    # 1) configure syslog to accept network log events.  This is done</span><br><span class="line">    #    by adding the '-r' option to the SYSLOGD_OPTIONS in</span><br><span class="line">    #    /etc/sysconfig/syslog</span><br><span class="line">    # 2) configure local2 events to go to the /var/log/haproxy.log</span><br><span class="line">    #   file. A line like the following can be added to</span><br><span class="line">    #   /etc/sysconfig/syslog</span><br><span class="line">    #</span><br><span class="line">    #    local2.*                       /var/log/haproxy.log</span><br><span class="line">    #</span><br><span class="line">    log         127.0.0.1 local2</span><br><span class="line">    </span><br><span class="line">    # chroot      /var/lib/haproxy</span><br><span class="line">    # pidfile     /var/run/haproxy.pid</span><br><span class="line">    # user        haproxy</span><br><span class="line">    # group       haproxy</span><br><span class="line">    maxconn     4000</span><br><span class="line">    nbthread    4</span><br><span class="line">    # nbproc    1</span><br><span class="line">    # daemon</span><br><span class="line">       </span><br><span class="line">    # turn on stats unix socket</span><br><span class="line">    stats socket /var/lib/haproxy/stats</span><br><span class="line"></span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># common defaults that all the 'listen' and 'backend' sections will</span><br><span class="line"># use if not designated in their block</span><br><span class="line">#---------------------------------------------------------------------  </span><br><span class="line">defaults</span><br><span class="line">    mode                    http</span><br><span class="line">    log                     global</span><br><span class="line">    option                  httplog</span><br><span class="line">    option                  dontlognull</span><br><span class="line">    option http-server-close</span><br><span class="line">    option                  redispatch</span><br><span class="line">    retries                 3</span><br><span class="line">    timeout http-request    10s</span><br><span class="line">    timeout queue           1m</span><br><span class="line">    timeout connect         10s</span><br><span class="line">    timeout client          1m</span><br><span class="line">    timeout server          1m</span><br><span class="line">    timeout http-keep-alive 10s</span><br><span class="line">    timeout check           10s</span><br><span class="line">    maxconn                 3000</span><br><span class="line"></span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># kubernetes apiserver frontend which proxys to the backends</span><br><span class="line">#--------------------------------------------------------------------- </span><br><span class="line">frontend kubernetes-apiserver</span><br><span class="line">    mode                 tcp</span><br><span class="line">    bind                 *:16443</span><br><span class="line">    option               tcplog</span><br><span class="line">    default_backend      kubernetes-apiserver    </span><br><span class="line"></span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># round robin balancing between the various backends</span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line">backend kubernetes-apiserver</span><br><span class="line">    mode        tcp</span><br><span class="line">    balance     roundrobin</span><br><span class="line">    server      master01.k8s.io   192.168.2.191:6443 check</span><br><span class="line">    server      master02.k8s.io   192.168.2.148:6443 check</span><br><span class="line"></span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># collection haproxy statistics message</span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line">listen stats</span><br><span class="line">    bind                 *:1080</span><br><span class="line">    stats auth           admin:admin</span><br><span class="line">    stats refresh        5s</span><br><span class="line">    stats realm          HAProxy\ Statistics</span><br><span class="line">    stats uri            /admin?stats</span><br></pre></td></tr></tbody></table></figure><p>HaProxy 配置文件的使用说明</p><table><thead><tr><th>配置项</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>maxconn</code></td><td>全局 / 前端 / 后端</td><td><code>2000</code></td><td>最大连接数，控制 HAProxy 可以同时处理的并发连接数。</td></tr><tr><td><code>nbthread</code></td><td>全局</td><td><code>1</code></td><td>指定每个进程使用的线程数。多线程模式可提高单进程并发性能。</td></tr><tr><td><code>nbproc</code></td><td>全局</td><td><code>1</code></td><td>指定 HAProxy 启动的进程数。多进程模式用于多核优化，但 Systemd 下不推荐与 <code>daemon</code> 配合使用。</td></tr><tr><td><code>daemon</code></td><td>全局</td><td>禁用</td><td>是否后台运行。Systemd 管理 HaProxy 时通常禁用，HAProxy 由 Systemd 控制前后台。</td></tr><tr><td><code>mode</code></td><td>defaults/frontend/backend</td><td><code>http</code></td><td>连接模式，可选 <code>http</code> 或 <code>tcp</code>。可以使用 <code>tcp</code> 来实现 Kubernetes API Server 代理。</td></tr><tr><td><code>balance</code></td><td>backend</td><td><code>roundrobin</code></td><td>负载均衡算法，可选 <code>roundrobin</code>、<code>leastconn</code>、<code>source</code> 等。</td></tr><tr><td><code>stats auth</code></td><td>listen</td><td></td><td> 设置统计页面认证用户名和密码，例如 <code>admin:admin</code>。</td></tr><tr><td><code>stats refresh</code></td><td>listen</td><td><code>10s</code></td><td>统计页面刷新时间，单位秒。</td></tr><tr><td><code>stats realm</code></td><td>listen</td><td></td><td>HTTP Basic Auth 的 <code>realm</code> 名称，显示在认证弹窗中。</td></tr><tr><td><code>stats uri</code></td><td>listen</td><td><code>/</code></td><td>HaProxy 统计页面访问 URI，例如 <code>/admin?stats</code>。</td></tr></tbody></table><div class="admonition note"><p class="admonition-title">Haproxy 的配置建议</p><ul><li><code>maxconn</code> + <code>nbthread</code> 可以提升单进程并发性能。</li><li><code>mode tcp</code> 是代理 Kubernetes API Server 的标准配置，因为 API Server 是 HTTPS / TCP 流量。</li><li>当使用 Systemd 管理 HaProxy 时，建议配置 <strong><code>nbproc = 1</code> + <code>nbthread &gt; 1</code> + 不启用 daemon</strong>，这是最稳定和高效的配置方式。</li></ul></div><blockquote><p><strong>5. 启动服务</strong></p></blockquote><p>设置开机自启动 HaProxy 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动HaProxy</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> haproxy</span><br></pre></td></tr></tbody></table></figure><p>立刻启动 HaProxy 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动HaProxy</span></span><br><span class="line"><span class="keyword"># systemctl</span> start haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看HaProxy的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status haproxy</span><br></pre></td></tr></tbody></table></figure><p>当 HaProxy 的配置文件发生变更后，可以执行热加载（也叫平滑重载，不会中断现有连接），让配置文件生效</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 热加载HaProxy配置文件</span></span><br><span class="line"><span class="keyword"># systemctl</span> reload haproxy</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>6. 验证服务</strong></p></blockquote><p>通过 HaProxy 的 <code>16443</code> 反向代理端口（可自定义），验证 HaProxy 的反向代理功能是否可以工作，正常情况下 API Server 的健康检测接口会返回字符串 <code>ok</code></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证 HaProxy 的反向代理功能（注意，这里即使测试通过，只能说明网络连通性没问题，不能说明其他组件一定可以跟 API Server 通过 HTTPS 协议进行加密通信，尤其是涉及到证书问题时）</span></span><br><span class="line"><span class="keyword"># curl</span><span class="params"> --cacert</span> /opt/kubernetes/ssl/ca.pem https://127.0.0.1:16443/healthz</span><br></pre></td></tr></tbody></table></figure><p>浏览器通过 <code>http://&lt;master-ip&gt;:1080/admin?stats</code> 访问 HaProxy 的统计页面，默认的登录用户名和密码是 <code>admin / admin</code>；如果可以正常访问（如下图所示），则说明 HaProxy 可以正常运行</p><p><img data-src="../../../asset/2025/11/k8s-ha-cluster-3.png"></p><h5 id="部署-Keepalived"><a href="#部署-Keepalived" class="headerlink" title="部署 Keepalived"></a>部署 Keepalived</h5><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><strong>在两台 Master 节点上，分别安装 Keepalived，两台 Master 节点上的 Keepalived 配置文件是不一样的</strong>。</li></ul></div><blockquote><p><strong>1. 安装概述</strong></p></blockquote><ul><li>Keepalived 是一个高可用软件，基于 VIP 绑定实现服务器双机主备（也叫双机热备），在上述拓扑中，Keepalived 主要根据 HaProxy 的运行状态判断是否需要故障转移（VIP 切换）。</li><li>例如，当 HaProxy 主节点挂掉，VIP 会自动绑定在 HaProxy 备节点，从而保证 VIP 一直可用，实现 HaProxy 高可用。</li></ul><table><thead><tr><th>安装说明</th><th>路径</th></tr></thead><tbody><tr><td> Keepalived 的安装路径</td><td><code>/usr/local/keepalived</code></td></tr><tr><td>Keepalived 的配置文件</td><td><code>/usr/local/keepalived/etc/keepalived/keepalived.conf</code></td></tr><tr><td>Keepalived 的 Systemd 服务配置文件（自动生成）</td><td><code>/usr/lib/systemd/system/keepalived.service</code></td></tr><tr><td>Keepalived 检测 HaProxy 是否可用的 Shell 脚本</td><td><code>/usr/local/keepalived/etc/keepalived/scripts/haproxy_check.sh</code></td></tr></tbody></table><blockquote><p><strong>2. 安装步骤</strong></p></blockquote><p>安装依赖软件包</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖包</span></span><br><span class="line"><span class="keyword"># yum</span> install<span class="params"> -y</span> gcc gcc-c++ make openssl-devel libnl libnl-devel net-snmp-devel popt-devel</span><br></pre></td></tr></tbody></table></figure><p>下载 Keepalived 源码包（<a target="_blank" rel="external nofollow" href="https://www.keepalived.org/download.html">官网下载地址</a>）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载源码包</span></span><br><span class="line"><span class="keyword"># wget</span> https://www.keepalived.org/software/keepalived-2.2.8.tar.gz</span><br></pre></td></tr></tbody></table></figure><p>解压 Keepalived 源码包</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压源码包</span></span><br><span class="line"><span class="keyword"># tar</span><span class="params"> -xvf</span> keepalived-2.2.8.tar.gz</span><br></pre></td></tr></tbody></table></figure><p>编译源码与安装</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入源码包的解压目录</span></span><br><span class="line"><span class="keyword"># cd</span> keepalived-2.2.8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成构建文件（Makefile）</span></span><br><span class="line"><span class="comment"># ./configure --prefix=/usr/local/keepalived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译源码</span></span><br><span class="line"><span class="keyword"># make</span><span class="params"> -j</span>$(nproc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line"><span class="keyword"># make</span> install</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>3. 创建脚本</strong></p></blockquote><p>创建用于 Keepalived 检测 HaProxy 服务是否可用的 Shell 脚本（比如 <code>haproxy_check.sh</code>）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建存放检测脚本的目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /usr/<span class="built_in">local</span>/keepalived/etc/keepalived/scripts/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建检测脚本，并写入以下脚本内容</span></span><br><span class="line"><span class="keyword"># vim</span> /usr/<span class="built_in">local</span>/keepalived/etc/keepalived/scripts/haproxy_check.sh</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取HaProxy进程数量</span></span><br><span class="line">HAPROXY_COUNT=$(pgrep<span class="params"> -x</span> haproxy | wc<span class="params"> -l</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果没有HaProxy进程，则返回非 0，Keepalived 会认为节点失效</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$HAPROXY_COUNT</span>"</span><span class="params"> -eq</span> 0 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="comment"># 这里可以考虑发送告警邮件</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"HAProxy not running"</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"HAProxy running"</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></tbody></table></figure><p>授予 HaProxy 检测脚本可执行权限</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 脚本授权</span></span><br><span class="line"><span class="keyword"># chmod</span> +x /usr/<span class="built_in">local</span>/keepalived/etc/keepalived/scripts/haproxy_check.sh</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>4. 配置服务</strong></p></blockquote><p>Keepalived 配置文件的使用说明</p><table><thead><tr><th>配置项</th><th>示例值</th><th>说明</th></tr></thead><tbody><tr><td><code>router_id</code></td><td><code>k8s</code></td><td>本节点唯一标识，用于日志区分（不同节点可不同）。</td></tr><tr><td><code>script</code></td><td><code>"killall -0 haproxy"</code></td><td>检测 HAProxy 服务是否可用，可以是 Shell 命令，还可以是 Shell 脚本的绝对路径。Keepalived 会根据脚本的返回状态码（0 表示正常，非 0 表示不正常）判断是否调节点整权重或触发 VIP 切换。</td></tr><tr><td><code>interval</code></td><td><code>2</code></td><td>检测脚本执行间隔（秒），指定 Keepalived 多久执行一次健康检查脚本。</td></tr><tr><td><code>weight</code></td><td><code>-100</code></td><td>节点权重变化值，检测脚本失败时降低优先级或成功时增加优先级。负值表示降低权重，正值表示增加权重。</td></tr><tr><td><code>fall</code></td><td><code>3</code></td><td>连续失败次数阈值，当检测脚本连续失败次数达到 <code>fall</code> 时，节点会认为服务不可用，并扣减权重或触发 VIP 切换。</td></tr><tr><td><code>rise</code></td><td><code>2</code></td><td>连续成功次数阈值，当检测脚本连续成功次数达到 <code>rise</code> 时，节点会认为服务恢复，并恢复权重初始值。</td></tr><tr><td><code>state</code></td><td><code>MASTER</code></td><td>节点初始角色（<code>MASTER</code> 或 <code>BACKUP</code>），最终由优先级决定。</td></tr><tr><td><code>interface</code></td><td><code>enp0s3</code></td><td>VRRP 使用的网络接口名称，可通过 <code>ifconfig</code> 命令得知。</td></tr><tr><td><code>virtual_router_id</code></td><td><code>51</code></td><td>VRRP 组 ID，多个节点必须一致。</td></tr><tr><td><code>priority</code></td><td><code>200</code></td><td>节点优先级（权重），数值越大优先级越高。</td></tr><tr><td><code>advert_int</code></td><td><code>1</code></td><td>VRRP 心跳间隔（秒），默认 1 秒。</td></tr><tr><td><code>auth_type</code></td><td><code>PASS</code></td><td>VRRP 认证方式（<code>PASS</code> 或 <code>AH</code>）。</td></tr><tr><td><code>auth_pass</code></td><td><code>ceb1b3ec013d66163d6ab</code></td><td>VRRP 认证密码，多个节点必须一致。</td></tr><tr><td><code>virtual_ipaddress</code></td><td><code>192.168.2.100</code></td><td>Keepalived 提供的 VIP（虚拟 IP），由 <code>MASTER</code> 持有。</td></tr><tr><td><code>track_script</code></td><td><code>check_haproxy</code></td><td>指定用于健康检查的脚本，检测失败时会调节点整权重或触发 VIP 切换。</td></tr></tbody></table><div class="admonition warning"><p class="admonition-title">Keepalived 什么时候触发 VIP 切换</p><ul><li>Keepalived 的 VIP 切换依赖节点权重变化，只有当 <code>MASTER</code> 节点的实时权重下降到低于 <code>BACKUP</code> 节点时，VIP 才会切换到权重更高的节点。</li><li>在 Keepalived 配置文件中，<code>vrrp_script</code> 可以通过 <code>weight</code> 动态调整节点权重：正值会增加节点权重，负值会降低节点权重。</li><li>当 Keepalived 脚本检测失败时，节点权重会根据 <code>weight</code> 设置下降，如果下降后 <code>MASTER</code> 节点的权重低于 <code>BACKUP</code> 节点，VIP 就会切换。</li><li>当 Keepalived 脚本检测成功时，且连续检测成功的次数达到 <code>rise</code> 次后，节点权重会恢复为初始值，原 <code>MASTER</code> 节点可能会重新成为 <code>MASTER</code>。</li><li><strong>Keepalived 的 <code>weight</code> 必须设置足够大，否则即使 Keepalived 脚本检测失败，<code>MASTER</code> 节点的权重仍可能比 <code>BACKUP</code> 节点高，从而导致不会触发 VIP 切换。</strong></li></ul></div><div class="admonition warning"><p class="admonition-title">Keepalived 调整节点权重的细节</p><ul><li>Keepalived 不会因为检测脚本持续失败而反复扣减节点权重，只有当检测脚本的检测结果从 "成功" 变为 "失败" 时，才会触发一次节点权重扣减。</li><li>也就是说，第一次检测被判定为失败，会执行一次 <code>weight</code> 扣减；当后续检测脚本继续失败时，由于节点已经处于失败状态，不会再重复扣减节点权重。</li><li>当检测脚本恢复成功后，Keepalived 会依据 <code>rise</code> 参数进行节点权重恢复。当检测脚本连续成功达到 <code>rise</code> 次后，节点权重会恢复到初始值。</li><li><strong>简而言之，Keepalived 的节点权重扣减是一次性的，直到检测脚本恢复成功，才再次生效</strong>。同样的，在节点处于健康状态期间，检测脚本即便持续成功，也不会重复增加节点权重。</li></ul></div><hr><p>在<strong>第一个 Master 节点</strong>（比如 <code>k8s-master</code>）中，创建 Keepalived 的配置文件，<strong>请自行更改 <code>interface</code>（网卡接口名称）与 <code>virtual_ipaddress</code>（虚拟 IP）配置项</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件，写入以下配置内容</span></span><br><span class="line"><span class="keyword"># vim</span> /usr/<span class="built_in">local</span>/keepalived/etc/keepalived/keepalived.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs {</span><br><span class="line">    router_id k8s</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">vrrp_script check_haproxy {</span><br><span class="line">    script "/usr/local/keepalived/etc/keepalived/scripts/haproxy_check.sh"</span><br><span class="line">    interval 2</span><br><span class="line">    weight -100</span><br><span class="line">    fall 3</span><br><span class="line">    rise 2</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 {</span><br><span class="line">    state MASTER</span><br><span class="line">    interface enp0s3</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 250</span><br><span class="line">    advert_int 1</span><br><span class="line"></span><br><span class="line">    authentication {</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass ceb1b3ec013d66163d6ab</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    virtual_ipaddress {</span><br><span class="line">        192.168.2.100</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    track_script {</span><br><span class="line">        check_haproxy</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>在<strong>第二个 Master 节点</strong>（比如 <code>k8s-master2</code>）中，创建 Keepalived 的配置文件，<strong>请自行更改 <code>interface</code>（网卡接口名称）与 <code>virtual_ipaddress</code>（虚拟 IP）配置项</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件，写入以下配置内容</span></span><br><span class="line"><span class="keyword"># vim</span> /usr/<span class="built_in">local</span>/keepalived/etc/keepalived/keepalived.conf</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs {</span><br><span class="line">    router_id k8s</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">vrrp_script check_haproxy {</span><br><span class="line">    script "/usr/local/keepalived/etc/keepalived/scripts/haproxy_check.sh"</span><br><span class="line">    interval 2</span><br><span class="line">    weight -100</span><br><span class="line">    fall 3</span><br><span class="line">    rise 2</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 {</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface enp0s3</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 200</span><br><span class="line">    advert_int 1</span><br><span class="line"></span><br><span class="line">    authentication {</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass ceb1b3ec013d66163d6ab</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    virtual_ipaddress {</span><br><span class="line">        192.168.2.100</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    track_script {</span><br><span class="line">        check_haproxy</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>5. 启动服务</strong></p></blockquote><p>设置开机自启动 Keepalived 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动Keepalived</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> keepalived</span><br></pre></td></tr></tbody></table></figure><p>立刻启动 Keepalived 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Keepalived</span></span><br><span class="line"><span class="keyword"># systemctl</span> start keepalived</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Keepalived的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status keepalived</span><br></pre></td></tr></tbody></table></figure><p>当 Keepalived 的配置文件发生变更后，可以重启服务让其生效</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启Keepalived</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart keepalived</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>6. 验证服务</strong></p></blockquote><p>通过 Keepalived 的 VIP（比如 <code>192.168.2.100</code>） + HaProxy 的 <code>16443</code> 反向代理端口（可自定义），验证 Keepalived 的 VIP 和 HaProxy 的反向代理功能是否可以正常工作，正常情况下 API Server 的健康检测接口会返回字符串 <code>ok</code>，<strong>请自行更改 VIP 的地址</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证 Keepalived 的 VIP 与 HaProxy 的反向代理功能（注意，这里即使测试通过，只能说明网络连通性没问题，不能说明其他组件一定可以跟 API Server 通过 HTTPS 协议进行加密通信，尤其是涉及到证书问题时）</span></span><br><span class="line"><span class="keyword"># curl</span><span class="params"> --cacert</span> /opt/kubernetes/ssl/ca.pem https://192.168.2.100:16443/healthz</span><br></pre></td></tr></tbody></table></figure><blockquote><p><strong>7. 验证高可用性</strong></p></blockquote><div class="admonition note"><p class="admonition-title">验证目标</p><p>本节旨在验证 HaProxy + Keepalived 是否能够实现双机主备（即双机热备）高可用机制。具体而言，当第一个 Master 节点上的 HaProxy 发生宕机时，Keepalived 能够将虚拟 IP（VIP）自动切换到第二个 Master 节点上。当第一个 Master 节点上的 HaProxy 恢复运行时，虚拟 IP（VIP）会自动切换回第一个 Master 节点上。这样，在 Kubernetes 集群内部仍可通过 VIP 访问 API Server，从而保障 Kubernetes 集群整体服务的高可用性。</p></div><ul><li>(1) 在第一个 Master 节点（比如 <code>k8s-master</code>）中，查看指定网卡（比如 <code>enp0s3</code>）的详细 IP 地址与状态信息，<strong>请自行更改网卡接口名称</strong></li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看网卡的详细信息</span></span><br><span class="line"><span class="keyword"># ip</span> a s enp0s3</span><br></pre></td></tr></tbody></table></figure><p>输出示例如下，可以看到 VIP（虚拟 IP）地址 <code>192.168.2.100</code> 绑定了网卡接口 <code>enp0s3</code></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 08:00:27:de:6f:6b brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.2.191/24 brd 192.168.2.255 scope global noprefixroute dynamic enp0s3</span><br><span class="line">       valid_lft 42617sec preferred_lft 42617sec</span><br><span class="line">    inet 192.168.2.100/32 scope global enp0s3</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::8b9e:77d3:4d79:eab9/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::6c1a:25c4:bdbd:dad3/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::8dee:f54a:fcd2:369b/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></tbody></table></figure><ul><li>(2) 在第一个 Master 节点（比如 <code>k8s-master</code>）中，关闭 HaProxy 服务，并查看 Keepalived 的运行状态</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭Haproxy</span></span><br><span class="line"><span class="keyword"># systemctl</span> stop haproxy</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看Keepalived的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status keepalived</span><br></pre></td></tr></tbody></table></figure><p>输出示例如下，可以看到 Keepalived 扣减了当前节点的权重（计算公式：<code>250 - 100 = 150</code>），同时 VIP 也被移除了</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">11月 08 14:14:40 k8s-master Keepalived_vrrp[30483]: Sending gratuitous ARP on enp0s3 for 192.168.2.100</span><br><span class="line">11月 08 14:14:40 k8s-master Keepalived_vrrp[30483]: Sending gratuitous ARP on enp0s3 for 192.168.2.100</span><br><span class="line">11月 08 14:18:02 k8s-master Keepalived_vrrp[30483]: Script `check_haproxy` now returning 1</span><br><span class="line">11月 08 14:18:06 k8s-master Keepalived_vrrp[30483]: VRRP_Script(check_haproxy) failed (exited with status 1)</span><br><span class="line">11月 08 14:18:06 k8s-master Keepalived_vrrp[30483]: (VI_1) Changing effective priority from 250 to 150</span><br><span class="line">11月 08 14:18:09 k8s-master Keepalived_vrrp[30483]: (VI_1) Master received advert from 192.168.2.148 with higher priority 200, ours 150</span><br><span class="line">11月 08 14:18:09 k8s-master Keepalived_vrrp[30483]: (VI_1) Entering BACKUP STATE</span><br><span class="line">11月 08 14:18:09 k8s-master Keepalived_vrrp[30483]: (VI_1) removing VIPs.</span><br></pre></td></tr></tbody></table></figure><ul><li>(3) 在第二个 Master 节点（比如 <code>k8s-master2</code>）中，查看指定网卡（比如 <code>enp0s3</code>）的详细 IP 地址与状态信息，<strong>请自行更改网卡接口名称</strong></li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看网卡的详细信息</span></span><br><span class="line"><span class="keyword"># ip</span> a s enp0s3</span><br></pre></td></tr></tbody></table></figure><p>输出示例如下，可以看到 VIP（虚拟 IP）地址 <code>192.168.2.100</code> 绑定了网卡接口 <code>enp0s3</code>，也就是 VIP 成功切换到 <code>BACKUP</code> 节点</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 08:00:27:78:05:48 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.2.148/24 brd 192.168.2.255 scope global noprefixroute dynamic enp0s3</span><br><span class="line">       valid_lft 41406sec preferred_lft 41406sec</span><br><span class="line">    inet 192.168.2.100/32 scope global enp0s3</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::8b9e:77d3:4d79:eab9/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::6c1a:25c4:bdbd:dad3/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::8dee:f54a:fcd2:369b/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></tbody></table></figure><ul><li>(4) 在第一个 Master 节点（比如 <code>k8s-master</code>）中，重新启动 HaProxy 服务，并查看指定网卡（比如 <code>enp0s3</code>）的详细 IP 地址与状态信息，<strong>请自行更改网卡接口名称</strong></li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Haproxy</span></span><br><span class="line"><span class="keyword"># systemctl</span> start haproxy</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看网卡的详细信息</span></span><br><span class="line"><span class="keyword"># ip</span> a s enp0s3</span><br></pre></td></tr></tbody></table></figure><p>输出示例如下，可以看到 VIP（虚拟 IP）地址 <code>192.168.2.100</code> 又绑定了网卡接口 <code>enp0s3</code>，也就是 VIP 再次切换回 <code>MASTER</code> 节点</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 08:00:27:de:6f:6b brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.2.191/24 brd 192.168.2.255 scope global noprefixroute dynamic enp0s3</span><br><span class="line">       valid_lft 42617sec preferred_lft 42617sec</span><br><span class="line">    inet 192.168.2.100/32 scope global enp0s3</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::8b9e:77d3:4d79:eab9/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::6c1a:25c4:bdbd:dad3/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::8dee:f54a:fcd2:369b/64 scope link tentative noprefixroute dadfailed </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></tbody></table></figure><p>此时，若再次在第一个 Master 节点（比如 <code>k8s-master</code>）中查看 Keepalived 的运行状态，可以看到 Keepalived 将当前节点的权重恢复为初始值，输出示例如下</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">11月 08 14:23:49 k8s-master Keepalived_vrrp[30483]: VRRP_Script(check_haproxy) succeeded</span><br><span class="line">11月 08 14:23:49 k8s-master Keepalived_vrrp[30483]: (VI_1) Changing effective priority from 150 to 250</span><br><span class="line">11月 08 14:23:52 k8s-master Keepalived_vrrp[30483]: Sending gratuitous ARP on enp0s3 for 192.168.2.100</span><br><span class="line">11月 08 14:23:52 k8s-master Keepalived_vrrp[30483]: Sending gratuitous ARP on enp0s3 for 192.168.2.100</span><br><span class="line">11月 08 14:23:52 k8s-master Keepalived_vrrp[30483]: Sending gratuitous ARP on enp0s3 for 192.168.2.100</span><br></pre></td></tr></tbody></table></figure><h5 id="部署-Controller-Manager"><a href="#部署-Controller-Manager" class="headerlink" title="部署 Controller Manager"></a>部署 Controller Manager</h5><p>创建 Controller Manager 的配置文件，使用转义符 <code>\\</code> 是为了使 EOF 保留换行符。一般情况下，以下配置内容可以直接拷贝使用</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kube-controller-manager.conf &lt;&lt; EOF</span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=<span class="string">"--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--leader-elect=true \\</span></span><br><span class="line"><span class="string">--bind-address=127.0.0.1 \\</span></span><br><span class="line"><span class="string">--allocate-node-cidrs=true \\</span></span><br><span class="line"><span class="string">--cluster-cidr=10.244.0.0/16 \\</span></span><br><span class="line"><span class="string">--service-cluster-ip-range=10.0.0.0/24 \\</span></span><br><span class="line"><span class="string">--secure-port=10257 \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span></span><br><span class="line"><span class="string">--authentication-kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span></span><br><span class="line"><span class="string">--authorization-kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span></span><br><span class="line"><span class="string">--client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--use-service-account-credentials=true \\</span></span><br><span class="line"><span class="string">--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--tls-cert-file=/opt/kubernetes/ssl/kube-controller-manager.pem \\</span></span><br><span class="line"><span class="string">--tls-private-key-file=/opt/kubernetes/ssl/kube-controller-manager-key.pem \\</span></span><br><span class="line"><span class="string">--root-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--controllers=*,bootstrapsigner,tokencleaner \\</span></span><br><span class="line"><span class="string">--deployment-controller-sync-period=10s \\</span></span><br><span class="line"><span class="string">--enable-garbage-collector=true \\</span></span><br><span class="line"><span class="string">--terminated-pod-gc-threshold=50 \\</span></span><br><span class="line"><span class="string">--node-monitor-period=5s \\</span></span><br><span class="line"><span class="string">--node-monitor-grace-period=20s \\</span></span><br><span class="line"><span class="string">--pod-eviction-timeout=2m0s \\</span></span><br><span class="line"><span class="string">--cluster-signing-duration=87600h0m0s"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>配置参数说明</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>--logtostderr</code></td><td>是否将日志输出到标准错误，<code>false</code> 时输出到文件</td></tr><tr><td><code>--v</code></td><td>日志级别（Verbose），数字越大日志越详细</td></tr><tr><td><code>--log-dir</code></td><td>日志文件存放目录</td></tr><tr><td><code>--leader-elect</code></td><td>启用 Leader 选举以保证高可用</td></tr><tr><td><code>--bind-address</code></td><td>Controller Manager 监听的本地 IP 地址</td></tr><tr><td><code>--allocate-node-cidrs</code></td><td>自动为 Node 分配 Pod CIDR</td></tr><tr><td><code>--cluster-cidr</code></td><td>Pod 网络 CIDR，用于分配 Pod IP</td></tr><tr><td><code>--service-cluster-ip-range</code></td><td>Service 虚拟 IP 地址段</td></tr><tr><td><code>--secure-port</code></td><td>Controller Manager HTTPS 端口</td></tr><tr><td><code>--kubeconfig</code></td><td>用于访问 API Server 的 kubeconfig 文件</td></tr><tr><td><code>--authentication-kubeconfig</code></td><td>Controller Manager 身份认证 kubeconfig</td></tr><tr><td><code>--authorization-kubeconfig</code></td><td>Controller Manager 权限认证 kubeconfig</td></tr><tr><td><code>--client-ca-file</code></td><td>验证客户端证书的 CA 文件</td></tr><tr><td><code>--use-service-account-credentials</code></td><td>使用 ServiceAccount Token 调用 API Server</td></tr><tr><td><code>--service-account-private-key-file</code></td><td>用于生成 ServiceAccount Token 的私钥</td></tr><tr><td><code>--cluster-signing-cert-file</code></td><td>集群证书签名 CA 文件</td></tr><tr><td><code>--cluster-signing-key-file</code></td><td>集群证书签名私钥</td></tr><tr><td><code>--requestheader-client-ca-file</code></td><td>用于验证 API Server 聚合层（Aggregation Layer）客户端请求头证书的 CA 文件</td></tr><tr><td><code>--tls-cert-file</code></td><td>Controller Manager TLS 证书</td></tr><tr><td><code>--tls-private-key-file</code></td><td>Controller Manager TLS 私钥</td></tr><tr><td><code>--root-ca-file</code></td><td>根 CA 文件，用于客户端和服务端通信验证</td></tr><tr><td><code>--controllers</code></td><td>启用的 Controller 类型列表</td></tr><tr><td><code>--deployment-controller-sync-period</code></td><td>Deployment Controller 同步周期</td></tr><tr><td><code>--enable-garbage-collector</code></td><td>启用垃圾回收机制，删除无用资源</td></tr><tr><td><code>--terminated-pod-gc-threshold</code></td><td>触发终止 Pod 垃圾回收的阈值</td></tr><tr><td><code>--node-monitor-period</code></td><td>节点状态检测周期</td></tr><tr><td><code>--node-monitor-grace-period</code></td><td>节点不可达后等待时间</td></tr><tr><td><code>--pod-eviction-timeout</code></td><td>Pod 被逐出前等待的超时时间</td></tr><tr><td><code>--cluster-signing-duration</code></td><td>集群签发证书的有效期（示例：87600h0m0s 表示 10 年）</td></tr></tbody></table><p>生成 <code>kube-controller-manager.kubeconfig</code> 配置文件，<strong>请自行修改这里环境变量中的 API Server 地址，且指定为 Keepalived 的虚拟 IP 地址（比如 <code>192.168.2.100</code>） + HaProxy 反向代理的端口（比如 <code>16443</code>），切勿直接拷贝环境变量的值</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时添加环境变量</span></span><br><span class="line">KUBE_APISERVER=<span class="string">"https://192.168.2.100:16443"</span>        <span class="comment"># API Server 的地址，搭建 K8s 高可用集群时，需要使用 Keepalived 的虚拟 IP 地址 + HaProxy 反向代理的端口</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置集群信息</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-cluster kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">  --certificate</span>-authority=/opt/kubernetes/ssl/ca.pem \<span class="params"></span></span><br><span class="line"><span class="params">  --embed</span>-certs=<span class="literal">true</span> \<span class="params"></span></span><br><span class="line"><span class="params">  --server</span>=<span class="variable">${KUBE_APISERVER}</span> \<span class="params"></span></span><br><span class="line"><span class="params">  --kubeconfig</span>=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证信息</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-credentials system:kube-controller-manager \<span class="params"></span></span><br><span class="line"><span class="params">  --client</span>-certificate=/opt/kubernetes/ssl/kube-controller-manager.pem \<span class="params"></span></span><br><span class="line"><span class="params">  --client</span>-key=/opt/kubernetes/ssl/kube-controller-manager-key.pem \<span class="params"></span></span><br><span class="line"><span class="params">  --embed</span>-certs=<span class="literal">true</span> \<span class="params"></span></span><br><span class="line"><span class="params">  --kubeconfig</span>=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-context system:kube-controller-manager@kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">  --cluster</span>=kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">  --user</span>=system:kube-controller-manager \<span class="params"></span></span><br><span class="line"><span class="params">  --kubeconfig</span>=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换上下文</span></span><br><span class="line"><span class="keyword"># kubectl</span> config use-context system:kube-controller-manager@kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">  --kubeconfig</span>=kube-controller-manager.kubeconfig</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 移动生成的配置文件</span></span><br><span class="line"><span class="keyword"># mv</span> kube-controller-manager.kubeconfig /opt/kubernetes/cfg</span><br></pre></td></tr></tbody></table></figure><p>配置 Systemd 管理 Controller Manager 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 Controller Manager 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.conf</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-controller-manager \<span class="variable">$KUBE_CONTROLLER_MANAGER_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>启动并设置开机自启动 Controller Manager 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动 Controller Manager 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> kube-controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 Controller Manager 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> start kube-controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Controller Manager 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Controller Manager 服务的启动日志（可用于排查启动问题）</span></span><br><span class="line"><span class="keyword"># journalctl</span><span class="params"> -u</span> kube-controller-manager.service</span><br></pre></td></tr></tbody></table></figure><p>当 Controller Manager 启动后，在查看运行状态时，可能会看到以下警告 / 错误信息。如果 K8s 集群是裸机或本地环境（没有 AWS / Azure 等云提供商），这两个报错可以忽略，它们不会影响 K8s 集群的核心功能</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">11月 11 18:58:54 k8s-master1 kube-controller-manager[15484]: E1111 18:58:54.496737   15484 core.go:90] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail</span><br><span class="line">11月 11 18:59:07 k8s-master1 kube-controller-manager[15484]: E1111 18:59:07.629134   15484 core.go:230] failed to start cloud node lifecycle controller: no cloud provider provided</span><br></pre></td></tr></tbody></table></figure><h5 id="部署-Scheduler"><a href="#部署-Scheduler" class="headerlink" title="部署 Scheduler"></a>部署 Scheduler</h5><p>创建 Scheduler 配置文件，使用转义符 <code>\\</code> 是为了使 EOF 保留换行符。一般情况下，以下配置内容可以直接拷贝使用</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kube-scheduler.conf &lt;&lt; EOF</span><br><span class="line">KUBE_SCHEDULER_OPTS=<span class="string">"--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--leader-elect=true \\</span></span><br><span class="line"><span class="string">--bind-address=127.0.0.1 \\</span></span><br><span class="line"><span class="string">--secure-port=10259 \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kube-scheduler.kubeconfig \\</span></span><br><span class="line"><span class="string">--authentication-kubeconfig=/opt/kubernetes/cfg/kube-scheduler.kubeconfig \\</span></span><br><span class="line"><span class="string">--authorization-kubeconfig=/opt/kubernetes/cfg/kube-scheduler.kubeconfig \\</span></span><br><span class="line"><span class="string">--client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--tls-cert-file=/opt/kubernetes/ssl/kube-scheduler.pem \\</span></span><br><span class="line"><span class="string">--tls-private-key-file=/opt/kubernetes/ssl/kube-scheduler-key.pem"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>配置参数说明</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>--logtostderr</code></td><td>是否将日志输出到标准错误（<code>false</code> 表示输出到文件，需要配合 <code>--log-dir</code> 使用）。</td></tr><tr><td><code>--v</code></td><td>日志级别，数值越大日志越详细。一般设置为 <code>2</code>。</td></tr><tr><td><code>--log-dir</code></td><td>日志文件输出目录（当 <code>logtostderr=false</code> 时有效）。</td></tr><tr><td><code>--leader-elect</code></td><td>启用 Leader 选举，用于多个 Scheduler 实例保证高可用。</td></tr><tr><td><code>--bind-address</code></td><td>Scheduler 监听地址，<code>127.0.0.1</code> 表示仅允许本机访问。</td></tr><tr><td><code>--secure-port</code></td><td>Scheduler HTTPS 服务监听端口，默认是 <code>10259</code>。</td></tr><tr><td><code>--kubeconfig</code></td><td>Scheduler 访问 API Server 的凭证文件。</td></tr><tr><td><code>--authentication-kubeconfig</code></td><td>API Server 调用 Scheduler 的认证配置。</td></tr><tr><td><code>--authorization-kubeconfig</code></td><td>API Server 调用 Scheduler 的授权配置。</td></tr><tr><td><code>--client-ca-file</code></td><td>用于验证 API Server 证书的 CA 文件。</td></tr><tr><td><code>--requestheader-client-ca-file</code></td><td>用于验证 API Server 聚合层（Aggregation Layer）客户端请求头证书的 CA 文件。</td></tr><tr><td><code>--tls-cert-file</code></td><td>Scheduler 作为 HTTPS 服务端的证书。</td></tr><tr><td><code>--tls-private-key-file</code></td><td>Scheduler 服务证书对应的私钥。</td></tr></tbody></table><p>生成 <code>kube-scheduler.kubeconfig</code> 配置文件，<strong>请自行修改这里环境变量中的 API Server 地址，且指定为 Keepalived 的虚拟 IP 地址（比如 <code>192.168.2.100</code>） + HaProxy 反向代理的端口（比如 <code>16443</code>），切勿直接拷贝环境变量的值</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时添加环境变量</span></span><br><span class="line">KUBE_APISERVER=<span class="string">"https://192.168.2.100:16443"</span>        <span class="comment"># API Server 的地址，搭建 K8s 高可用集群时，需要使用 Keepalived 的虚拟 IP 地址 + HaProxy 反向代理的端口</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置集群信息</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-cluster kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">  --certificate</span>-authority=/opt/kubernetes/ssl/ca.pem \<span class="params"></span></span><br><span class="line"><span class="params">  --embed</span>-certs=<span class="literal">true</span> \<span class="params"></span></span><br><span class="line"><span class="params">  --server</span>=<span class="variable">${KUBE_APISERVER}</span> \<span class="params"></span></span><br><span class="line"><span class="params">  --kubeconfig</span>=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证信息</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-credentials system:kube-scheduler \<span class="params"></span></span><br><span class="line"><span class="params">  --client</span>-certificate=/opt/kubernetes/ssl/kube-scheduler.pem \<span class="params"></span></span><br><span class="line"><span class="params">  --client</span>-key=/opt/kubernetes/ssl/kube-scheduler-key.pem \<span class="params"></span></span><br><span class="line"><span class="params">  --embed</span>-certs=<span class="literal">true</span> \<span class="params"></span></span><br><span class="line"><span class="params">  --kubeconfig</span>=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-context system:kube-scheduler@kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">  --cluster</span>=kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">  --user</span>=system:kube-scheduler \<span class="params"></span></span><br><span class="line"><span class="params">  --kubeconfig</span>=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换上下文</span></span><br><span class="line"><span class="keyword"># kubectl</span> config use-context system:kube-scheduler@kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">  --kubeconfig</span>=kube-scheduler.kubeconfig</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 移动生成的配置文件</span></span><br><span class="line"><span class="keyword"># mv</span> kube-scheduler.kubeconfig /opt/kubernetes/cfg</span><br></pre></td></tr></tbody></table></figure><p>配置 Systemd 管理 Scheduler 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 Scheduler 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.conf</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-scheduler \<span class="variable">$KUBE_SCHEDULER_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>启动并设置开机自启动 Scheduler 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动 Scheduler 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> kube-scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 Scheduler 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> start kube-scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Scheduler 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Scheduler 服务的启动日志（可用于排查启动问题）</span></span><br><span class="line"><span class="keyword"># journalctl</span><span class="params"> -u</span> kube-scheduler.service</span><br></pre></td></tr></tbody></table></figure><p>当 API Server、Controller Manager、Scheduler 组件都成功启动后，可以通过 <code>kubectl</code> 工具查看当前 Kubernetes 集群组件（不包括 API Server）的运行状态</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看核心组件的运行状态（不包括 API Server）</span></span><br><span class="line"><span class="keyword"># kubectl</span> get cs</span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">scheduler            Healthy   ok                  </span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">etcd-0               Healthy   {<span class="string">"health"</span>:<span class="string">"true"</span>}   </span><br><span class="line">etcd-1               Healthy   {<span class="string">"health"</span>:<span class="string">"true"</span>}  </span><br><span class="line">etcd-2               Healthy   {<span class="string">"health"</span>:<span class="string">"true"</span>}   </span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>这里的 <code>kubectl get cs</code> 命令只会显示部分组件的运行状态（主要是 Etcd、Controller Manager、Scheduler），不包括 API Server；因为 API Server 是 Kubernetes 的核心服务，一般需要通过其它方式进行监控。</p></div><h4 id="部署-Master-与-Node-节点"><a href="#部署-Master-与-Node-节点" class="headerlink" title="部署 Master 与 Node 节点"></a>部署 Master 与 Node 节点</h4><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><strong>在 Kubernetes 集群的所有节点（包括 Master 和 Node 节点）上分别执行以下操作，除了特别说明之外（比如，只在 Master 节点批准 Kubelet 的证书签名请求）。简而言之，Master 和 Node 节点都需要安装 Kubelet、Kube-Proxy、CNI 网络插件。</strong></li><li><strong>如果 Master 节点仅用于运行控制平面组件（如 API Server、Controller Manager 和 Scheduler），不承载用户 Pod 的调度和运行任务，则 Master 节点可以不部署 Kubelet 和 Kube-Proxy，但还是必须安装 CNI 网络插件。。</strong></li></ul></div><h5 id="下载二进制文件-1"><a href="#下载二进制文件-1" class="headerlink" title="下载二进制文件"></a>下载二进制文件</h5><div class="admonition note"><p class="admonition-title">下载地址</p><ul><li>Kubernetes 相关的二进制包可以从 <a target="_blank" rel="external nofollow" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md#v11910">GitHub</a> 下载得到，这里下载的版本是 <code>v1.19.10</code>。</li><li>当打开 <a target="_blank" rel="external nofollow" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md#v11910">GitHub</a> 链接后，会发现里面有很多二进制包，只需要下载一个 <a target="_blank" rel="external nofollow" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md#server-binaries-6">Server</a> 二进制包就够了，里面包含了 Master 节点相关的二进制包。</li></ul></div><p>由于上面单独部署 Maser 节点时，已经下载并解压过 Kubernetes 的二进制包文件，因此这里只需要在所有 Node 节点上下载二进制包文件即可</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载二进制包（耗时较长）</span></span><br><span class="line"><span class="keyword"># wget</span> https://dl.k8s.io/v1.19.10/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line"><span class="keyword"># tar</span> zxvf kubernetes-server-linux-amd64.tar.gz</span><br></pre></td></tr></tbody></table></figure><p>在所有节点（包括 Master 和 Node 节点）上，分别执行以下命令拷贝对应的可执行文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入解压目录</span></span><br><span class="line"><span class="keyword"># cd</span> kubernetes/server/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /opt/kubernetes/{bin,cfg,ssl,logs}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝文件</span></span><br><span class="line"><span class="keyword"># cp</span> kubelet kube-proxy /opt/kubernetes/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝文件</span></span><br><span class="line"><span class="keyword"># cp</span><span class="params"> -n</span> kubectl /usr/bin/</span><br></pre></td></tr></tbody></table></figure><h5 id="部署-Kubelet"><a href="#部署-Kubelet" class="headerlink" title="部署 Kubelet"></a>部署 Kubelet</h5><p>创建 Kubelet 的配置文件，使用转义符 <code>\\</code> 是为了使 EOF 保留换行符，<strong>请自行更改 <code>--hostname-override</code> 的值为当前节点的主机名（比如 <code>k8s-node1</code>），切勿直接拷贝以下配置内容</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kubelet.conf &lt;&lt; EOF</span><br><span class="line">KUBELET_OPTS=<span class="string">"--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--hostname-override=&lt;当前节点的主机名&gt; \\</span></span><br><span class="line"><span class="string">--network-plugin=cni \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\</span></span><br><span class="line"><span class="string">--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\</span></span><br><span class="line"><span class="string">--config=/opt/kubernetes/cfg/kubelet-config.yml \\</span></span><br><span class="line"><span class="string">--cert-dir=/opt/kubernetes/ssl \\</span></span><br><span class="line"><span class="string">--pod-infra-container-image=lizhenliang/pause-amd64:3.0"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>配置参数说明</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>--logtostderr</code></td><td>是否将日志输出到标准错误（<code>false</code> 表示写入日志目录）</td></tr><tr><td><code>--v</code></td><td>日志详细级别，值越大日志越详细（2 为常用调试级别）</td></tr><tr><td><code>--log-dir</code></td><td>日志存放目录</td></tr><tr><td><code>--hostname-override</code></td><td>覆盖节点的主机名，在集群中显示为指定名称，通常填写当前节点的主机名</td></tr><tr><td><code>--network-plugin</code></td><td>使用的网络插件类型（比如 CNI）</td></tr><tr><td><code>--kubeconfig</code></td><td>kubelet 连接 API Server 的 kubeconfig 配置文件路径</td></tr><tr><td><code>--bootstrap-kubeconfig</code></td><td>kubelet 首次启动时用于申请证书的引导配置文件路径</td></tr><tr><td><code>--config</code></td><td>kubelet 主配置文件路径</td></tr><tr><td><code>--cert-dir</code></td><td>存放 kubelet TLS 证书的目录</td></tr><tr><td><code>--pod-infra-container-image</code></td><td>Pod 基础容器（Pause 容器）镜像，用于提供网络命名空间</td></tr></tbody></table><p>创建 Kubelet 的配置参数文件，一般情况下，以下配置内容可以直接拷贝使用</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置参数文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kubelet-config.yml &lt;&lt; EOF</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">clusterDNS:</span><br><span class="line">  - 10.0.0.2</span><br><span class="line">clusterDomain: cluster.<span class="built_in">local</span></span><br><span class="line">failSwapOn: <span class="literal">false</span></span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: <span class="literal">false</span></span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /opt/kubernetes/ssl/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>配置参数说明</p><table><thead><tr><th>参数</th><th>说明</th><th>备注</th></tr></thead><tbody><tr><td><code>kind</code></td><td>资源类型</td><td>固定为 <code>KubeletConfiguration</code></td></tr><tr><td><code>apiVersion</code></td><td>配置 API 版本</td><td>当前常用版本为 <code>kubelet.config.k8s.io/v1beta1</code></td></tr><tr><td><code>address</code></td><td>Kubelet 监听的 IP 地址</td><td><code>0.0.0.0</code> 表示监听所有网卡地址</td></tr><tr><td><code>port</code></td><td>Kubelet 的主要服务端口</td><td>默认值为 <code>10250</code>，用于 API Server 与 Kubelet 通信（带认证）</td></tr><tr><td><code>readOnlyPort</code></td><td>只读端口</td><td>默认值为 <code>10255</code>（不建议对外开放），提供只读状态信息</td></tr><tr><td><code>cgroupDriver</code></td><td>cgroup 驱动类型</td><td>与容器运行时（如 Docker、Containerd）保持一致，常见值：<code>systemd</code> 或 <code>cgroupfs</code></td></tr><tr><td><code>clusterDNS</code></td><td>集群内 DNS 服务 IP 地址</td><td>通常设置为 Kube-DNS 或 CoreDNS 的 ClusterIP，如 <code>10.0.0.2</code></td></tr><tr><td><code>clusterDomain</code></td><td>集群内部 DNS 域名后缀</td><td>默认值为 <code>cluster.local</code></td></tr><tr><td><code>failSwapOn</code></td><td>是否在系统启用 Swap 分区时拒绝启动</td><td>建议 <code>false</code>（否则 Swap 分区未关闭时 Kubelet 会报错）</td></tr><tr><td><code>authentication.anonymous.enabled</code></td><td>是否允许匿名访问</td><td>建议设为 <code>false</code>，禁止匿名访问，提高安全性</td></tr><tr><td><code>authentication.webhook.enabled</code></td><td>是否启用 Webhook 认证</td><td>启用后可通过 API Server 的 Token 校验机制认证</td></tr><tr><td><code>authentication.webhook.cacheTTL</code></td><td>Webhook 认证缓存时间</td><td>如 <code>2m0s</code> 表示缓存 2 分钟</td></tr><tr><td><code>authentication.x509.clientCAFile</code></td><td>客户端证书 CA 文件路径</td><td>指向集群 CA 证书文件</td></tr><tr><td><code>authorization.mode</code></td><td>授权模式</td><td>常用值为 <code>Webhook</code>，即由 API Server 进行鉴权</td></tr><tr><td><code>authorization.webhook.cacheAuthorizedTTL</code></td><td>授权缓存时间（通过）</td><td>配置示例：<code>5m0s</code></td></tr><tr><td><code>authorization.webhook.cacheUnauthorizedTTL</code></td><td>授权缓存时间（未通过）</td><td>配置示例：<code>30s</code></td></tr><tr><td><code>evictionHard.imagefs.available</code></td><td>镜像文件系统最小可用空间阈值</td><td>低于该值会触发 Pod 驱逐，例如 <code>15%</code></td></tr><tr><td><code>evictionHard.memory.available</code></td><td>节点可用内存阈值</td><td>低于 <code>100Mi</code> 时触发 Pod 驱逐</td></tr><tr><td><code>evictionHard.nodefs.available</code></td><td>节点文件系统最小可用空间阈值</td><td>低于 <code>10%</code> 时触发 Pod 驱逐</td></tr><tr><td><code>evictionHard.nodefs.inodesFree</code></td><td>节点可用 inode 阈值</td><td>低于 <code>5%</code> 时触发 Pod 驱逐</td></tr><tr><td><code>maxOpenFiles</code></td><td>Kubelet 允许打开的最大文件数</td><td>默认值较小，建议设置为 <code>1000000</code></td></tr><tr><td><code>maxPods</code></td><td>每个节点允许运行的最大 Pod 数</td><td>默认值为 <code>110</code>，可根据节点的硬件性能调整</td></tr></tbody></table><p>生成 <code>bootstrap.kubeconfig</code> 配置文件，<strong>请自行修改这里环境变量中的 API Server 地址，且指定为 Keepalived 的虚拟 IP 地址（比如 <code>192.168.2.100</code>） + HaProxy 反向代理的端口（比如 <code>16443</code>），切勿直接拷贝环境变量的值</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时添加环境变量</span></span><br><span class="line">KUBE_APISERVER=<span class="string">"https://192.168.2.100:16443"</span>        <span class="comment"># API Server 的地址，搭建 K8s 高可用集群时，需要使用 Keepalived 的虚拟 IP 地址 + HaProxy 反向代理的端口</span></span><br><span class="line">TOKEN=<span class="string">"c47ffb939f5ca36231d9e3121a252940"</span>            <span class="comment"># 必须与 token.csv 文件里的 token 保持一致</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置集群信息</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-cluster kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">--certificate</span>-authority=/opt/kubernetes/ssl/ca.pem \<span class="params"></span></span><br><span class="line"><span class="params">--embed</span>-certs=<span class="literal">true</span> \<span class="params"></span></span><br><span class="line"><span class="params">--server</span>=<span class="variable">${KUBE_APISERVER}</span> \<span class="params"></span></span><br><span class="line"><span class="params">--kubeconfig</span>=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证信息</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-credentials <span class="string">"kubelet-bootstrap"</span> \<span class="params"></span></span><br><span class="line"><span class="params">--token</span>=<span class="variable">${TOKEN}</span> \<span class="params"></span></span><br><span class="line"><span class="params">--kubeconfig</span>=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-context default \<span class="params"></span></span><br><span class="line"><span class="params">--cluster</span>=kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">--user</span>=<span class="string">"kubelet-bootstrap"</span> \<span class="params"></span></span><br><span class="line"><span class="params">--kubeconfig</span>=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换上下文</span></span><br><span class="line"><span class="keyword"># kubectl</span> config use-context default<span class="params"> --kubeconfig</span>=bootstrap.kubeconfig</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 移动生成的配置文件</span></span><br><span class="line"><span class="keyword"># mv</span> bootstrap.kubeconfig /opt/kubernetes/cfg</span><br></pre></td></tr></tbody></table></figure><p>提前手动拉取 Pause 镜像（Pod 的基础镜像，用于 Pod 网络命名空间），避免后面部署 CNI 网络插件时，Kubelet 出现自动拉取 Pause 镜像失败的问题（该镜像的名称和版本在 <code>kubelet.conf</code> 配置文件中通过 <code>--pod-infra-container-image</code> 指定）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提前拉取Pause镜像（可选操作）</span></span><br><span class="line"><span class="keyword"># docker</span> pull lizhenliang/pause-amd64:3.0</span><br></pre></td></tr></tbody></table></figure><p>配置 Systemd 管理 Kubelet 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 Kubelet 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line">After=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kubelet.conf</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kubelet \<span class="variable">$KUBELET_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>启动并设置开机自启动 Kubelet 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动 Kubelet 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 Kubelet 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> start kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Kubelet 服务的运行状态（若有网络错误信息，可暂时忽略）</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Kubelet 服务的启动日志（可用于排查启动问题）</span></span><br><span class="line"><span class="keyword"># journalctl</span><span class="params"> -u</span> kubelet.service</span><br></pre></td></tr></tbody></table></figure><p>在查看 Kubelet 服务的运行状态时，可能会看到以下错误信息。这是因为目前还没有安装 CNI 网络插件，因此该错误可以暂时忽略掉</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">11月 11 21:15:55 k8s-master1 kubelet[7509]: E1112 11:15:55.312188    7509 kubelet.go:2134] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br><span class="line">11月 11 21:16:00 k8s-master1 kubelet[7509]: E1112 11:16:00.329434    7509 kubelet.go:2134] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br><span class="line">11月 11 21:16:05 k8s-master1 kubelet[7509]: E1112 11:16:05.347068    7509 kubelet.go:2134] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>当 Kubelet 服务正常启动后，会自动向 API Server 发起 CSR（证书签名请求）。一旦该 CSR 请求被批准，Kubelet 就会获得客户端证书，并开始与 API Server 通信，从而将它所在的 Node 节点加入到 Kubernetes 集群中，所以无需使用 <code>kubeadm join</code> 命令手动将当前节点加入 Kubernetes 集群，也无需像 Kube-Proxy 一样使用自签 CA 签发证书。</p></div><p><strong>在任意一个 Master 节点上执行以下命令</strong>，批准 Kubelet 证书签名请求并允许 Node 节点加入 Kubernetes 集群</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 Kubernetes 集群中的所有证书签名请求</span></span><br><span class="line"><span class="keyword"># kubectl</span> get csr</span><br><span class="line">NAME                                                   AGE   SIGNERNAME                                    REQUESTOR           CONDITION</span><br><span class="line">node-csr-B91KCv7T_4A4RCfvfEBfFOP3V5zCYKK5NQkVLDmyly4   86s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line">node-csr-F4zdBAJxxKnDLsWJbYHVi_XKF8Uwh1MMarXNJiHAUy0   85s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line">node-csr-GYbsPLYySA0LiUkuhbpXlApj-JC-TDnA7SVRPHWU2mI   88s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line">node-csr-bLUS_w2or-Rq9c5JgCzaf5e6QYHND6PTEqQFTvDsY5g   96s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line">node-csr-ndBBynU94khVf6ADv4pdmtrlsxDOXAnyxu18e_VnhBU   87s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批准证书签名请求（请根据上面输出的证书签名请求名称，自行更改命令行参数）</span></span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-B91KCv7T_4A4RCfvfEBfFOP3V5zCYKK5NQkVLDmyly4</span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-F4zdBAJxxKnDLsWJbYHVi_XKF8Uwh1MMarXNJiHAUy0</span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-GYbsPLYySA0LiUkuhbpXlApj-JC-TDnA7SVRPHWU2mI</span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-bLUS_w2or-Rq9c5JgCzaf5e6QYHND6PTEqQFTvDsY5g</span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-ndBBynU94khVf6ADv4pdmtrlsxDOXAnyxu18e_VnhBU</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看集群中所有节点的状态（由于 CNI 网络插件还没有部署，因此节点会处于没有准备就绪状态 - NotReady）</span></span><br><span class="line"><span class="keyword"># kubectl</span> get node</span><br><span class="line">NAME          STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master1   NotReady   &lt;none&gt;   10m   v1.19.10</span><br><span class="line">k8s-master2   NotReady   &lt;none&gt;   18s   v1.19.10</span><br><span class="line">k8s-node1     NotReady   &lt;none&gt;   29s   v1.19.10</span><br><span class="line">k8s-node2     NotReady   &lt;none&gt;   22s   v1.19.10</span><br><span class="line">k8s-node3     NotReady   &lt;none&gt;   25s   v1.19.10</span><br></pre></td></tr></tbody></table></figure><h5 id="部署-Kube-Proxy"><a href="#部署-Kube-Proxy" class="headerlink" title="部署 Kube-Proxy"></a>部署 Kube-Proxy</h5><p>创建 Kube-Proxy 的配置文件，使用转义符 <code>\\</code> 是为了使 EOF 保留换行符，以下配置内容可以直接拷贝使用</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kube-proxy.conf &lt;&lt; EOF</span><br><span class="line">KUBE_PROXY_OPTS=<span class="string">"--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--config=/opt/kubernetes/cfg/kube-proxy-config.yml"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>配置参数说明</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>--logtostderr=false</code></td><td>日志输出到文件而不是标准错误输出（<code>stderr</code>）</td></tr><tr><td><code>--v=2</code></td><td>设置日志详细级别为 2（数值越大日志越详细）</td></tr><tr><td><code>--log-dir=/opt/kubernetes/logs</code></td><td>指定日志文件存放目录</td></tr><tr><td><code>--config=/opt/kubernetes/cfg/kube-proxy-config.yml</code></td><td>指定 kube-proxy 的配置参数文件路径</td></tr></tbody></table><p>创建 Kube-Proxy 的配置参数文件，<strong>请自行更改 <code>hostnameOverride</code> 的值为当前节点的主机名（比如 <code>k8s-node1</code>），其中的 <code>clusterCIDR</code> 要与 <code>kube-apiserver.conf</code> 配置文件中的 <code>--service-cluster-ip-range</code> 一致，切勿直接拷贝以下配置内容</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置参数文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kube-proxy-config.yml &lt;&lt; EOF</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">metricsBindAddress: 0.0.0.0:10249</span><br><span class="line">clientConnection:</span><br><span class="line">  kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfig</span><br><span class="line">hostnameOverride: &lt;当前节点的主机名&gt;</span><br><span class="line">clusterCIDR: 10.0.0.0/24</span><br><span class="line">mode: <span class="string">"iptables"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>配置参数说明</p><table><thead><tr><th>参数</th><th>说明</th><th>备注</th></tr></thead><tbody><tr><td><code>kind</code></td><td>资源类型，固定为 <code>KubeProxyConfiguration</code></td><td>必填</td></tr><tr><td><code>apiVersion</code></td><td>配置文件的 API 版本，当前主流为 <code>kubeproxy.config.k8s.io/v1alpha1</code></td><td>必填</td></tr><tr><td><code>bindAddress</code></td><td>Kube-Proxy 监听的地址，用于服务代理流量</td><td>一般使用 <code>0.0.0.0</code> 监听所有网卡</td></tr><tr><td><code>metricsBindAddress</code></td><td>暴露 Prometheus 指标的监听地址</td><td>默认端口 <code>10249</code>，可用于监控</td></tr><tr><td><code>clientConnection.kubeconfig</code></td><td>Kube-Proxy 访问 API Server 的 kubeconfig 文件路径</td><td>必填，包含 <code>system:kube-proxy</code> 证书信息</td></tr><tr><td><code>hostnameOverride</code></td><td>当前节点的主机名，注册到集群时的 Node 名称</td><td>建议与系统主机名一致</td></tr><tr><td><code>clusterCIDR</code></td><td>Pod 网段，需与 Controller Manager 的 <code>--cluster-cidr</code> 一致</td><td>必填，否则可能导致 Service 转发异常</td></tr><tr><td><code>mode</code></td><td>Kube-Proxy 的工作模式，可选值 <code>iptables</code> 或 <code>ipvs</code></td><td>默认 <code>iptables</code>，兼容性最好；<code>ipvs</code> 性能更好，但要求节点的操作系统内核支持 <code>ip_vs</code> 模块</td></tr></tbody></table><p>生成 <code>kube-proxy.kubeconfig</code> 文件，<strong>请自行修改这里环境变量中的 API Server 地址，且指定为 Keepalived 的虚拟 IP 地址（比如 <code>192.168.2.100</code>） + HaProxy 反向代理的端口（比如 <code>16443</code>），切勿直接拷贝环境变量的值</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时添加环境变量</span></span><br><span class="line">KUBE_APISERVER=<span class="string">"https://192.168.2.100:16443"</span>         <span class="comment"># API Server 的地址，搭建 K8s 高可用集群时，需要使用 Keepalived 的虚拟 IP 地址 + HaProxy 反向代理的端口</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置集群信息</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-cluster kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">--certificate</span>-authority=/opt/kubernetes/ssl/ca.pem \<span class="params"></span></span><br><span class="line"><span class="params">--embed</span>-certs=<span class="literal">true</span> \<span class="params"></span></span><br><span class="line"><span class="params">--server</span>=<span class="variable">${KUBE_APISERVER}</span> \<span class="params"></span></span><br><span class="line"><span class="params">--kubeconfig</span>=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证信息</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-credentials kube-proxy \<span class="params"></span></span><br><span class="line"><span class="params">--client</span>-certificate=/opt/kubernetes/ssl/kube-proxy.pem \<span class="params"></span></span><br><span class="line"><span class="params">--client</span>-key=/opt/kubernetes/ssl/kube-proxy-key.pem \<span class="params"></span></span><br><span class="line"><span class="params">--embed</span>-certs=<span class="literal">true</span> \<span class="params"></span></span><br><span class="line"><span class="params">--kubeconfig</span>=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文</span></span><br><span class="line"><span class="keyword"># kubectl</span> config <span class="built_in">set</span>-context default \<span class="params"></span></span><br><span class="line"><span class="params">--cluster</span>=kubernetes \<span class="params"></span></span><br><span class="line"><span class="params">--user</span>=kube-proxy \<span class="params"></span></span><br><span class="line"><span class="params">--kubeconfig</span>=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换上下文</span></span><br><span class="line"><span class="keyword"># kubectl</span> config use-context default<span class="params"> --kubeconfig</span>=kube-proxy.kubeconfig</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 移动生成的配置文件</span></span><br><span class="line"><span class="keyword"># mv</span> kube-proxy.kubeconfig /opt/kubernetes/cfg</span><br></pre></td></tr></tbody></table></figure><p>配置 Systemd 管理 Kube-Proxy 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 Kube-Proxy 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line">After=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.conf</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-proxy \<span class="variable">$KUBE_PROXY_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>启动并设置开机自启动 Kube-Proxy 服务</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机自启动 Kube-Proxy 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> <span class="built_in">enable</span> kube-proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 Kube-Proxy 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> start kube-proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Kube-Proxy 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Kube-Proxy 服务的启动日志（可用于排查启动问题）</span></span><br><span class="line"><span class="keyword"># journalctl</span><span class="params"> -u</span> kube-proxy.service</span><br></pre></td></tr></tbody></table></figure><h5 id="部署-CNI-网络插件"><a href="#部署-CNI-网络插件" class="headerlink" title="部署 CNI 网络插件"></a>部署 CNI 网络插件</h5><h6 id="所有节点的操作"><a href="#所有节点的操作" class="headerlink" title="所有节点的操作"></a>所有节点的操作</h6><div class="admonition warning"><p class="admonition-title">特别注意</p><p><strong>在 Kubernetes 集群的所有节点（包括 Master 和 Node 节点）上面，分别下载并解压 CNI 网络插件的二进制包</strong>。</p></div><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载二进制文件</span></span><br><span class="line"><span class="keyword"># wget</span> https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /opt/cni/bin</span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /etc/cni/net.d/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line"><span class="keyword"># tar</span> zxvf cni-plugins-linux-amd64-v0.8.6.tgz<span class="params"> -C</span> /opt/cni/bin</span><br></pre></td></tr></tbody></table></figure><h6 id="Master-节点的操作"><a href="#Master-节点的操作" class="headerlink" title="Master 节点的操作"></a>Master 节点的操作</h6><div class="admonition warning"><p class="admonition-title">特别注意</p><p><strong>在任意一个 Master 节点上面部署 CNI 网络插件（Flannel），不需要在所有的 Master 节点和 Node 节点中重复执行。简而言之，以下操作仅需要在任意一个 Master 节点上执行</strong>。</p></div><p>下载 CNI 网络插件（Flannel）的 YAML 配置文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载配置文件</span></span><br><span class="line"><span class="keyword"># wget</span><span class="params"> -P</span> /opt/kubernetes/cfg/ https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></tbody></table></figure><p>在 Kubernetes 集群中部署 CNI 网络插件（Flannel）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 部署 CNI 网络插件（Flannel），成功后所有节点会自动下载相应的 Docker 镜像（如果本地不存在）</span></span><br><span class="line"><span class="keyword"># kubectl</span> apply<span class="params"> -f</span> /opt/kubernetes/cfg/kube-flannel.yml</span><br></pre></td></tr></tbody></table></figure><p>查看 CNI 网络插件的所有 Pod</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有 Pod</span></span><br><span class="line"><span class="keyword"># kubectl</span> get pods<span class="params"> -n</span> kube-flannel</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NAME                        READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/kube-flannel-ds-29gvn   1/1     Running   0          5m14s</span><br><span class="line">pod/kube-flannel-ds-99gvw   1/1     Running   0          5m14s</span><br><span class="line">pod/kube-flannel-ds-ntsf5   1/1     Running   0          5m14s</span><br><span class="line">pod/kube-flannel-ds-xqrnd   1/1     Running   0          5m14s</span><br><span class="line">pod/kube-flannel-ds-xwr2h   1/1     Running   0          5m14s</span><br></pre></td></tr></tbody></table></figure><p>查看 CNI 网络插件的所有 DaemonSet</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有 DaemonSet</span></span><br><span class="line"><span class="keyword"># kubectl</span> get ds<span class="params"> -n</span> kube-flannel</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">kube-flannel-ds   5         5         5       5            5           &lt;none&gt;          6m59s</span><br></pre></td></tr></tbody></table></figure><p>查看 Kubernetes 集群中所有节点的运行状态</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看集群中所有节点的运行状态（当 CNI 网络插件部署完成后，所有节点都会自动切换到准备就绪状态 - Ready）</span></span><br><span class="line"><span class="keyword"># kubectl</span> get node</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NAME          STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8s-master1   Ready    &lt;none&gt;   5h28m   v1.19.10</span><br><span class="line">k8s-master2   Ready    &lt;none&gt;   5h17m   v1.19.10</span><br><span class="line">k8s-node1     Ready    &lt;none&gt;   5h17m   v1.19.10</span><br><span class="line">k8s-node2     Ready    &lt;none&gt;   5h17m   v1.19.10</span><br><span class="line">k8s-node3     Ready    &lt;none&gt;   5h17m   v1.19.10</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">CNI 网络插件的安装细节</p><p>这个 <code>kubectl apply</code> 命令会创建一个 DaemonSet 类型的资源，而 DaemonSet 的特性是：会在 Kubernetes 集群中所有「可调度」的 Node 节点上运行一个 Pod 副本。换言之，在任意一个 Master 节点上，通过 <code>kubectl apply</code> 命令安装 CNI 网络插件后，默认会将 CNI 网络插件部署到整个 Kubernetes 集群的所有节点（包括 Master 和 Node），无需手动在每个节点上重复执行 <code>kubectl apply</code> 命令来安装 CNI 网络插件。</p></div><p>创建用于授权 API Server 访问 Kubelet 的配置文件</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/apiserver-to-kubelet-rbac.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: <span class="string">"true"</span></span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - <span class="string">""</span></span><br><span class="line">    resources:</span><br><span class="line">      - nodes/proxy</span><br><span class="line">      - nodes/stats</span><br><span class="line">      - nodes/<span class="built_in">log</span></span><br><span class="line">      - nodes/spec</span><br><span class="line">      - nodes/metrics</span><br><span class="line">      - pods/<span class="built_in">log</span></span><br><span class="line">    verbs:</span><br><span class="line">      - <span class="string">"*"</span></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:kube-apiserver</span><br><span class="line">  namespace: <span class="string">""</span></span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">subjects:</span><br><span class="line">  - apiGroup: rbac.authorization.k8s.io</span><br><span class="line">    kind: User</span><br><span class="line">    name: kubernetes</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>授权 API Server 访问 Kubelet</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 授权访问</span></span><br><span class="line"><span class="keyword"># kubectl</span> apply<span class="params"> -f</span> /opt/kubernetes/cfg/apiserver-to-kubelet-rbac.yaml</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">为什么必须安装 CNI 网络插件</p><ul><li>Kubernetes 本身不包含网络实现，但它要求集群中的所有 Pod 能够彼此通信（无论位于哪个节点），这是 Kubernetes 网络模型的基本要求。</li><li>通过 Kubeadm 搭建 Kubernetes 集群时，使用 <code>kubeadm init</code> 初始化 Master 节点后，默认只有控制平面功能，没有网络功能。</li><li>当没有安装 CNI 网络插件时，Pod 会卡在 <code>ContainerCreating</code> 状态，因为找不到网络（CNI）配置。</li><li>当安装 CNI 网络插件（如 Flannel）后，多个节点之间的 Pod 才能通信和正常运行。</li></ul></div><h4 id="测试集群整体功能"><a href="#测试集群整体功能" class="headerlink" title="测试集群整体功能"></a>测试集群整体功能</h4><p>在任意一个 Master 节点中执行以下命令，查看集群中所有节点的运行状态，当节点的运行状态都变更为 <code>Ready</code> 时，则表示 Kubernetes 集群已经成功搭建起来了</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有节点的运行状态</span></span><br><span class="line"><span class="keyword"># kubectl</span> get nodes</span><br><span class="line">NAME          STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8s-master1   Ready    &lt;none&gt;   5h32m   v1.19.10</span><br><span class="line">k8s-master2   Ready    &lt;none&gt;   5h21m   v1.19.10</span><br><span class="line">k8s-node1     Ready    &lt;none&gt;   5h22m   v1.19.10</span><br><span class="line">k8s-node2     Ready    &lt;none&gt;   5h22m   v1.19.10</span><br><span class="line">k8s-node3     Ready    &lt;none&gt;   5h22m   v1.19.10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看核心组件的运行状态（不包括 API Server）</span></span><br><span class="line"><span class="keyword"># kubectl</span> get cs</span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">scheduler            Healthy   ok                  </span><br><span class="line">etcd-2               Healthy   {<span class="string">"health"</span>:<span class="string">"true"</span>}   </span><br><span class="line">etcd-0               Healthy   {<span class="string">"health"</span>:<span class="string">"true"</span>}   </span><br><span class="line">etcd-1               Healthy   {<span class="string">"health"</span>:<span class="string">"true"</span>}   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看集群版本</span></span><br><span class="line"><span class="keyword"># kubectl</span> version<span class="params"> --short</span></span><br><span class="line">Client Version: v1.19.10</span><br><span class="line">Server Version: v1.19.10</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>在使用二进制方式完成 Kubernetes 集群的搭建时，执行 <code>kubectl get pods -n kube-system</code> 命令可能无法看到任何 Pod 的运行状态。这是因为 Kubernetes 中的 Pod 是由 Kubelet 负责向 API Server 注册并创建的，仅仅启动 API Server、Controller Manager、Scheduler、Kubelet、Kube-Proxy 等二进制组件，并不会自动生成或运行这些系统组件对应的 Pod。系统核心组件如 CoreDNS、Metrics Server 等都需要用户手动部署相关的 YAML 资源文件，Kubelet 才会拉取镜像并创建对应的 Pod。因此，若未部署这些资源，<code>kube-system</code> 命名空间中将不会显示任何 Pod。</p></div><p>在任意一个 Master 节点中执行以下命令，目的是在 Kubernetes 集群里创建一个 Nginx 的 Deployment，验证 Kubernetes 集群是否正常运行</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建Nginx</span></span><br><span class="line"><span class="keyword"># kubectl</span> create deployment nginx<span class="params"> --image</span>=nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴露Nginx的端口</span></span><br><span class="line"><span class="keyword"># kubectl</span> expose deployment nginx<span class="params"> --port</span>=80<span class="params"> --type</span>=NodePort<span class="params"> --target</span>-port=80</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod列表</span></span><br><span class="line"><span class="keyword"># kubectl</span> get pods<span class="params"> -o</span> wide</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-6799fc88d8-w8g9b   1/1     Running   0          64s   10.244.2.2   k8s-node3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Service列表</span></span><br><span class="line"><span class="keyword"># kubectl</span> get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">kubernetes   ClusterIP   10.0.0.1     &lt;none&gt;        443/TCP        6h42m</span><br><span class="line">nginx        NodePort    10.0.0.38    &lt;none&gt;        80:31603/TCP   64s</span><br></pre></td></tr></tbody></table></figure><p>在 Kubernetes 集群外部，通过浏览器访问 <code>http://192.168.2.191:31603</code>，其中 IP 可以是任意集群节点的 IP 地址，端口由 <code>kubectl get svc</code> 命令可得知。若 Ngninx 容器在 Kubernetes 集群中创建并启动成功，则浏览器可以正常访问 Nginx 的首页（如下图所示），如下图所示：</p><p><img data-src="../../../asset/2025/07/k8s-nginx.png"></p><p>若希望删除刚在 Kubernetes 集群创建的 Nginx 容器，可以在任意一个 Master 节点上执行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除Service</span></span><br><span class="line"><span class="keyword"># kubectl</span> delete service nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除Deployment</span></span><br><span class="line"><span class="keyword"># kubectl</span> delete deployment nginx</span><br></pre></td></tr></tbody></table></figure><h4 id="部署-CoreDNS（可选）"><a href="#部署-CoreDNS（可选）" class="headerlink" title="部署 CoreDNS（可选）"></a>部署 CoreDNS（可选）</h4><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li><strong>以下所有操作仅在任意一个 Master 节点上执行，不需要在所有的 Master 节点和 Node 节点中重复执行，请保证在部署 CoreDNS 之前，Kubernetes 集群是可以正常运行的。</strong></li><li>CodreDNS 的作用是：在 Kubernetes 集群内，可以通过 Service 的 DNS 名称（域名）对 Pod 进行访问，比如：<code>http://&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local:&lt;port&gt;</code>，具体使用案例请看 <a href="/posts/6bf07963.html#%E7%BD%91%E7%BB%9C%E6%B5%8B%E8%AF%95">这里</a>。</li></ul></div><blockquote><p>CoreDNS 的部署说明</p></blockquote><ul><li>由于上面搭建的 Kubernetes 集群已经具备运行 Pod 的完整容器化环境，这种情况下 CoreDNS 最合适的部署方式就是容器化部署，即通过 Kubernetes 自己来管理 CoreDNS 的 Pod。CoreDNS 也可以通过二进制包进行部署的，两种部署方式的区别如下：</li></ul><table><thead><tr><th>部署方式</th><th>适合场景</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>容器化部署 CoreDNS</td><td> 集群支持运行 Pod，且至少 kube-system 命名空间可用</td><td>符合 Kubernetes 生态，自动扩缩容、自动重启，便于管理</td><td>需要容器运行环境</td></tr><tr><td>二进制部署 CoreDNS</td><td> 极简集群、节点无容器环境，或仅测试 DNS</td><td> 不依赖容器，部署简单</td><td>无法通过 Kubernetes 管理，需手动维护、高可用难度大</td></tr></tbody></table><ul><li>容器化部署 CoreDNS 的几个关键优势如下：</li></ul><table><thead><tr><th>优势</th><th>说明</th></tr></thead><tbody><tr><td>符合 Kubernetes 官方架构</td><td> CoreDNS 本身就是官方默认的集群 DNS 方案，部署成 Pod 完全符合设计思路。</td></tr><tr><td>自动高可用</td><td>可通过 <code>Replica Set</code> 或 <code>Deployment</code> 管理多个副本，某个 Pod 异常退出会被自动重建。</td></tr><tr><td>易扩容 / 升级</td><td>直接通过 <code>kubectl scale</code> 或 <code>kubectl apply</code> 即可扩容、升级。</td></tr><tr><td>与 kube-proxy、kubelet 无缝配合</td><td> kubelet 会自动配置 Pod 的 DNS 指向 CoreDNS 的 ClusterIP。</td></tr><tr><td>支持弹性伸缩</td><td>可配合 Pod 横向自动扩容（Horizontal Pod Autoscaler，简称 HPA）实现负载自动扩缩容。</td></tr></tbody></table><blockquote><p>CoreDNS 的部署步骤</p></blockquote><ul><li>从 CoreDNS 官方仓库下载最新的 YAML 配置文件模板，并生成新的配置文件</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载配置文件模板</span></span><br><span class="line"><span class="keyword"># wget</span> https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed<span class="params"> -O</span> coredns.yaml.sed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换配置文件模板中的占位符，生成新的配置文件</span></span><br><span class="line"><span class="keyword"># sed</span><span class="params"> -e</span> <span class="string">"s/CLUSTER_DOMAIN/cluster.local/g"</span> \<span class="params"></span></span><br><span class="line"><span class="params">    -e</span> <span class="string">"s/REVERSE_CIDRS/in-addr.arpa ip6.arpa/g"</span> \<span class="params"></span></span><br><span class="line"><span class="params">    -e</span> <span class="string">"s/UPSTREAMNAMESERVER/8.8.8.8/g"</span> \<span class="params"></span></span><br><span class="line"><span class="params">    -e</span> <span class="string">"s/}STUBDOMAINS/}/"</span> \</span><br><span class="line">    coredns.yaml.sed &gt; coredns.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移动生成的配置文件</span></span><br><span class="line"><span class="keyword"># mv</span> coredns.yaml /opt/kubernetes/cfg/</span><br></pre></td></tr></tbody></table></figure><ul><li>检查 Kubelet 的 YAML 配置文件（<code>kubelet-config.yml</code>），确保包含以下配置信息（注意，Kubernetes 默认的 DNS Service IP 是 <code>10.0.0.10</code>，也可以指定为实际规划的 Pod 网段内的 IP，本文使用自定义的 IP）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑 Kubelet 的 YAML 配置文件，确保包含以下配置信息</span></span><br><span class="line"><span class="keyword"># vim</span> /opt/kubernetes/cfg/kubelet-config.yml</span><br></pre></td></tr></tbody></table></figure><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">clusterDNS:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.2</span>                    <span class="comment"># 指向 CoreDNS Service 的 ClusterIP</span></span><br><span class="line"><span class="attr">clusterDomain:</span> <span class="string">cluster.local</span>    <span class="comment"># 默认域名后缀</span></span><br></pre></td></tr></tbody></table></figure><ul><li>修改 CoreDNS 的 YAML 配置文件（<code>coredns.yaml</code>），只需要修改 <code>spec.replicas</code> 和 <code>spec.clusterIP</code> 这两个配置</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑 CoreDNS 的 YAML 配置文件，更改以下两个配置项</span></span><br><span class="line"><span class="keyword"># vim</span> /opt/kubernetes/cfg/coredns.yaml</span><br></pre></td></tr></tbody></table></figure><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">......</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">coredns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kube-dns</span></span><br><span class="line">    <span class="attr">kubernetes.io/name:</span> <span class="string">"CoreDNS"</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">coredns</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span>       <span class="comment"># 指定 CoreDNS 的副本数量</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="string">......</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">......</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-dns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">prometheus.io/port:</span> <span class="string">"9153"</span></span><br><span class="line">    <span class="attr">prometheus.io/scrape:</span> <span class="string">"true"</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kube-dns</span></span><br><span class="line">    <span class="attr">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="attr">kubernetes.io/name:</span> <span class="string">"CoreDNS"</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">coredns</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kube-dns</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">coredns</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.2</span>       <span class="comment"># 指定 CoreDNS Service 的 ClusterIP</span></span><br><span class="line"></span><br><span class="line"><span class="string">......</span></span><br></pre></td></tr></tbody></table></figure><ul><li>应用 CoreDNS 的 YAML 配置文件</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># kubectl</span> apply<span class="params"> -f</span> /opt/kubernetes/cfg/coredns.yaml</span><br></pre></td></tr></tbody></table></figure><ul><li>验证 CoreDNS 的 Pod 是否启动成功</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># kubectl</span> get pods<span class="params"> -n</span> kube-system<span class="params"> -l</span> k8s-app=kube-dns</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-6b9bb479b9-gpvvw   1/1     Running   0          21s</span><br><span class="line">coredns-6b9bb479b9-l7z5b   1/1     Running   0          21s</span><br><span class="line">coredns-6b9bb479b9-nzm5c   1/1     Running   0          21s</span><br></pre></td></tr></tbody></table></figure><ul><li>若 CoreDNS 的 Pod 启动失败，可以通过查看日志信息来定位问题</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># kubectl</span> logs coredns-6b9bb479b9-lfd7j<span class="params"> -n</span> kube-system</span><br></pre></td></tr></tbody></table></figure><ul><li>若希望删除 CoreDNS 的所有资源（包括 Pod、Controller、Service 等），可以执行以下命令</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># kubectl</span> delete<span class="params"> -f</span> /opt/kubernetes/cfg/coredns.yaml</span><br></pre></td></tr></tbody></table></figure><h2 id="多-Master-集群搭建问题"><a href="#多-Master-集群搭建问题" class="headerlink" title="多 Master 集群搭建问题"></a>多 Master 集群搭建问题</h2><h3 id="集群启动顺序问题"><a href="#集群启动顺序问题" class="headerlink" title="集群启动顺序问题"></a>集群启动顺序问题</h3><p>Kubernetes 集群包含多个组件，这些组件之间存在依赖关系。例如，大多数组件都依赖 API Server，因此 API Server 通常需要优先启动，而 API Server 本身又依赖 Etcd 集群先行启动。建议按以下顺序启动各个组件，否则有可能导致某些组件无法正常启动（<strong>尤其各个组件都是通过 Systemd 管理服务，并且集群的所有服务器都发生断电重启的情况下</strong>）：</p><ul><li>1、Etcd 集群（所有集群节点的 Etcd）</li><li>2、Master 节点组件：<ul><li>(1) API Server</li><li>(2) Controller Manager</li><li>(3) Scheduler</li></ul></li><li>3、Node 节点组件：<ul><li>(1) Kubelet</li><li>(2) Kube-Proxy</li></ul></li><li>4、网络插件（如 Flannel、Calico、Cilium 等）</li><li>5、其他附加组件（如 CoreDNS、Ingress Controller、Dashboard 等）</li></ul><div class="admonition note"><p class="admonition-title">Kubernetes 集群各个组件之间的依赖关系</p><ul><li>Etcd 集群：Kubernetes 的数据存储后端，保存 API Server 的所有配置信息和资源对象；若未启动，API Server 无法连接存储并会报错退出。</li><li>API Server（Master 节点）：集群核心入口，Controller Manager、Scheduler、<code>kubectl</code> 等都通过它访问集群状态；必须先启动才能让其他组件连接工作。</li><li>Controller Manager（Master 节点）：通过 API Server 访问和修改集群状态（如创建 Pod、更新节点信息）；若 API Server 未启动，则会不断重试连接而启动失败。</li><li>Scheduler（Master 节点）：通过 API Server 获取未调度的 Pod 列表并为其分配合适的 Node；依赖 API Server 正常运行。</li></ul></div><h4 id="手动解决启动顺序问题"><a href="#手动解决启动顺序问题" class="headerlink" title="手动解决启动顺序问题"></a>手动解决启动顺序问题</h4><div class="admonition warning"><p class="admonition-title">特别注意</p><p>当所有 Kubernetes 集群服务器重启后（比如断电重启），部分 Kubernetes 组件可能无法正确启动，因为每个组件之间存在一定的依赖关系，这时候就需要人工介入处理。</p></div><blockquote><p><strong>管理 Master 节点的组件启动，以下所有操作都是仅在 Kubernetes 集群的所有 Master 节点上执行</strong></p></blockquote><ul><li>查看 Master 节点组件的运行状态</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># systemctl</span> status kube-apiserver</span><br><span class="line"><span class="keyword"># systemctl</span> status kube-controller-manager</span><br><span class="line"><span class="keyword"># systemctl</span> status kube-scheduler</span><br><span class="line"><span class="keyword"># systemctl</span> status kubelet</span><br><span class="line"><span class="keyword"># systemctl</span> status kube-proxy</span><br></pre></td></tr></tbody></table></figure><ul><li>若在 Master 节点组件的运行状态中，发现有不可忽略的致命错误提示信息，则严格按以下顺序重启各个组件</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># systemctl</span> restart kube-apiserver</span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-controller-manager</span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-scheduler</span><br><span class="line"><span class="keyword"># systemctl</span> restart kubelet</span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-proxy</span><br></pre></td></tr></tbody></table></figure><ul><li>再次查看 Master 节点组件的运行状态</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># systemctl</span> status kube-apiserver</span><br><span class="line"><span class="keyword"># systemctl</span> status kube-controller-manager</span><br><span class="line"><span class="keyword"># systemctl</span> status kube-scheduler</span><br><span class="line"><span class="keyword"># systemctl</span> status kubelet</span><br><span class="line"><span class="keyword"># systemctl</span> status kube-proxy</span><br></pre></td></tr></tbody></table></figure><hr><blockquote><p><strong>管理 Node 节点的组件启动，以下所有操作分别在 Kubernetes 集群的所有 Node 节点上执行</strong></p></blockquote><ul><li>查看 Node 节点组件的运行状态</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># systemctl</span> status kubelet</span><br><span class="line"><span class="keyword"># systemctl</span> status kube-proxy</span><br></pre></td></tr></tbody></table></figure><ul><li>若在 Node 节点组件的运行状态中，发现有不可忽略的致命错误提示信息，则严格按以下顺序重启各个组件</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># systemctl</span> restart kubelet</span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-proxy</span><br></pre></td></tr></tbody></table></figure><ul><li>再次查看 Node 节点组件的运行状态</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># systemctl</span> status kubelet</span><br><span class="line"><span class="keyword"># systemctl</span> status kube-proxy</span><br></pre></td></tr></tbody></table></figure><h4 id="彻底解决启动顺序问题"><a href="#彻底解决启动顺序问题" class="headerlink" title="彻底解决启动顺序问题"></a>彻底解决启动顺序问题</h4><div class="admonition warning"><p class="admonition-title">特别注意</p><p>若每次在所有 Kubernetes 集群服务器重启后（比如断电重启），都需要手动按顺序重启每个 Kubernetes 组件，这将非常繁琐。为了彻底解决这个问题，可以使用 Systemd 的 <code>Requires</code>、<code>After</code>、<code>ExecStartPre</code> 特性来控制多个服务之间的启动顺序。</p></div><blockquote><p><strong>生成 Health-Check 的证书，用于检测 API Server 的健康状态，以下所有操作都是仅在 Kubernetes 集群的任意一个 Master 节点上执行</strong></p></blockquote><ul><li>在任意一个 Master 节点中，进入证书目录</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入证书目录</span></span><br><span class="line"><span class="built_in">cd</span> ~/tls/k8s/</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，创建用于生成 Health-Check 证书的配置文件</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; health-check-csr.json &lt;&lt; EOF</span><br><span class="line">{</span><br><span class="line">  <span class="string">"CN"</span>: <span class="string">"health-check"</span>,</span><br><span class="line">  <span class="string">"hosts"</span>: [],</span><br><span class="line">  <span class="string">"key"</span>: {</span><br><span class="line">    <span class="string">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="string">"size"</span>: 2048</span><br><span class="line">  },</span><br><span class="line">  <span class="string">"names"</span>: [</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"O"</span>: <span class="string">"system:health-checkers"</span></span><br><span class="line">    }</span><br><span class="line">  ]</span><br><span class="line">}</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，使用自签 CA 签发 Health-Check 证书</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前目录下的文件</span></span><br><span class="line"><span class="keyword"># ls</span></span><br><span class="line">ca-config.json  ca.pem                   kube-apiserver-key.pem            kube-controller-manager-key.pem  kube-proxy-key.pem       kube-scheduler-key.pem</span><br><span class="line">ca.csr          health-check-csr.json    kube-apiserver.pem                kube-controller-manager.pem      kube-proxy.pem           kube-scheduler.pem</span><br><span class="line">ca-csr.json     kube-apiserver.csr       kube-controller-manager.csr       kube-proxy.csr                   kube-scheduler.csr</span><br><span class="line">ca-key.pem      kube-apiserver-csr.json  kube-controller-manager-csr.json  kube-proxy-csr.json              kube-scheduler-csr.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自签 CA 证书签发 Health-Check 证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致</span></span><br><span class="line"><span class="keyword"># cfssl</span> gencert<span class="params"> -ca</span>=ca.pem<span class="params"> -ca</span>-key=ca-key.pem<span class="params"> -config</span>=ca-config.json<span class="params"> -profile</span>=kubernetes health-check-csr.json | cfssljson<span class="params"> -bare</span> health-check</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的 Health-Check 证书</span></span><br><span class="line"><span class="keyword"># ls</span> health-check*.pem</span><br><span class="line">health-check-key.pem  health-check.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证生成的 Health-Check 证书</span></span><br><span class="line"><span class="keyword"># cfssl</span>-certinfo<span class="params"> -cert</span> health-check.pem</span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params">  -noout</span><span class="params"> -text</span><span class="params"> -in</span>  health-check.pem</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，将上面生成的 Health-Check 证书拷贝到本地目录里面</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将 Health-Check 证书拷贝到本地目录里面</span></span><br><span class="line"><span class="keyword"># cp</span> ~/tls/k8s/health*.pem /opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，将上面生成的 Health-Check 证书拷贝到其他 Master 节点里面</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Health-Check 证书到其他 Master 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/health-check*.pem root@k8s-master2:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，将上面生成的 Health-Check 证书拷贝到所有 Node 节点里面</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝 Health-Check 证书到所有 Node 节点里面</span></span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/health-check*.pem root@k8s-node1:/opt/kubernetes/ssl/</span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/health-check*.pem root@k8s-node2:/opt/kubernetes/ssl/</span><br><span class="line"><span class="keyword"># scp</span> ~/tls/k8s/health-check*.pem root@k8s-node3:/opt/kubernetes/ssl/</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，创建 ClusterRole 的配置文件（仅授予只读的健康检测权限）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/health-check-role.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: health-check-role</span><br><span class="line">rules:</span><br><span class="line">  - nonResourceURLs:</span><br><span class="line">      - /healthz</span><br><span class="line">      - /livez</span><br><span class="line">      - /readyz</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，创建绑定用户到 ClusterRole 的配置文件</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/health-check-binding.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: health-check-binding</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: health-check-role</span><br><span class="line">subjects:</span><br><span class="line">  - kind: User</span><br><span class="line">    name: health-check</span><br><span class="line">    apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，应用 YAML 配置文件</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 应用 ClusterRole（仅授予只读的健康检测权限）</span></span><br><span class="line"><span class="keyword"># kubectl</span> apply<span class="params"> -f</span> /opt/kubernetes/cfg/health-check-role.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用 ClusterRoleBinding（将用户绑定到指定的集群角色）</span></span><br><span class="line"><span class="keyword"># kubectl</span> apply<span class="params"> -f</span> /opt/kubernetes/cfg/health-check-binding.yaml</span><br></pre></td></tr></tbody></table></figure><ul><li>在所有节点（包括 Master 和 Node）中，分别验证 API Server 健康检测接口的调用（<strong>请自行更改 API Server 的地址，需要使用 Keepalived 的 VIP 和 HaProxy 的反向代理端口，切勿直接拷贝执行以下命令</strong>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 若接口可以正常调用，则会返回 ok 字符串</span></span><br><span class="line"><span class="keyword"># curl</span><span class="params"> --silent</span><span class="params"> --fail</span><span class="params"> --cacert</span> /opt/kubernetes/ssl/ca.pem<span class="params"> --cert</span> /opt/kubernetes/ssl/health-check.pem<span class="params"> --key</span> /opt/kubernetes/ssl/health-check-key.pem https://192.168.2.100:16443/readyz</span><br></pre></td></tr></tbody></table></figure><hr><blockquote><p><strong>管理 Master 节点的组件启动，以下所有操作都是仅在 Kubernetes 集群的所有 Master 节点上执行</strong></p></blockquote><ul><li>在所有 Master 节点中，下载 Etcd 的 <code>etcdctl</code> 可执行文件（如果本地不存在，才需要下载可执行文件）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看是否存在etcdctl可执行文件（如果存在，则不需要再下载）</span></span><br><span class="line"><span class="keyword"># ls</span> /opt/etcd/bin/etcdctl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载二进制包</span></span><br><span class="line"><span class="keyword"># wget</span> https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line"><span class="keyword"># mkdir</span><span class="params"> -p</span> /opt/etcd/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line"><span class="keyword"># tar</span> zxvf etcd-v3.4.9-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移动文件</span></span><br><span class="line"><span class="keyword"># mv</span> etcd-v3.4.9-linux-amd64/etcdctl /opt/etcd/bin/</span><br></pre></td></tr></tbody></table></figure><ul><li>在所有 Master 节点中，重写（覆盖）API Server 服务的 Systemd 配置文件（<strong>请自行更改 Etcd 集群节点的 IP 和端口，切勿直接拷贝执行以下命令</strong>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重写 API Server 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.conf</span><br><span class="line">ExecStartPre=/bin/bash<span class="params"> -c</span> <span class="string">'until ETCDCTL_API=3 /opt/etcd/bin/etcdctl --endpoints=https://192.168.2.191:2379,https://192.168.2.112:2379,https://192.168.2.131:2379 --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem endpoint status --write-out=table | grep -v "^+" | grep -q " true "; do echo "Waiting for Etcd cluster to be ready..."; sleep 2; done &amp;&amp; echo "Etcd cluster is now ready."'</span></span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-apiserver \<span class="variable">$KUBE_APISERVER_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 API Server 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-apiserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 API Server 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-apiserver</span><br></pre></td></tr></tbody></table></figure><ul><li>在所有 Master 节点中，重写（覆盖）Controller Manager 服务的 Systemd 配置文件（<strong>请自行更改 API Server 的地址，需要使用 Keepalived 的 VIP 和 HaProxy 的反向代理端口，切勿直接拷贝执行以下命令</strong>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重写 Controller Manager 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.conf</span><br><span class="line">ExecStartPre=/bin/bash<span class="params"> -c</span> <span class="string">'until curl --silent --fail --cacert /opt/kubernetes/ssl/ca.pem --cert /opt/kubernetes/ssl/health-check.pem --key /opt/kubernetes/ssl/health-check-key.pem https://192.168.2.100:16443/readyz &gt; /dev/null 2&gt;&amp;1; do echo "Waiting for API Server to be ready..."; sleep 2; done &amp;&amp; echo "API Server is now ready."'</span></span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-controller-manager \<span class="variable">$KUBE_CONTROLLER_MANAGER_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 Controller Manager 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Controller Manager 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-controller-manager</span><br></pre></td></tr></tbody></table></figure><ul><li>在所有 Master 节点中，重写（覆盖）Scheduler 服务的 Systemd 配置文件（<strong>请自行更改 API Server 的地址，需要使用 Keepalived 的 VIP 和 HaProxy 的反向代理端口，切勿直接拷贝执行以下命令</strong>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重写 Scheduler 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.conf</span><br><span class="line">ExecStartPre=/bin/bash<span class="params"> -c</span> <span class="string">'until curl --silent --fail --cacert /opt/kubernetes/ssl/ca.pem --cert /opt/kubernetes/ssl/health-check.pem --key /opt/kubernetes/ssl/health-check-key.pem https://192.168.2.100:16443/readyz &gt; /dev/null 2&gt;&amp;1; do echo "Waiting for API Server to be ready..."; sleep 2; done &amp;&amp; echo "API Server is now ready."'</span></span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-scheduler \<span class="variable">$KUBE_SCHEDULER_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 Scheduler 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Scheduler 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-scheduler</span><br></pre></td></tr></tbody></table></figure><ul><li>在所有 Master 节点中，重写（覆盖）Kubelet 服务的 Systemd 配置文件（<strong>请自行更改 API Server 的地址，需要使用 Keepalived 的 VIP 和 HaProxy 的反向代理端口，切勿直接拷贝执行以下命令</strong>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重写 Kubelet 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line">After=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kubelet.conf</span><br><span class="line">ExecStartPre=/bin/bash<span class="params"> -c</span> <span class="string">'until curl --silent --fail --cacert /opt/kubernetes/ssl/ca.pem --cert /opt/kubernetes/ssl/health-check.pem --key /opt/kubernetes/ssl/health-check-key.pem https://192.168.2.100:16443/readyz &gt; /dev/null 2&gt;&amp;1; do echo "Waiting for API Server to be ready..."; sleep 2; done &amp;&amp; echo "API Server is now ready."'</span></span><br><span class="line">ExecStart=/opt/kubernetes/bin/kubelet \<span class="variable">$KUBELET_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 Kubelet 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Kubelet 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kubelet</span><br></pre></td></tr></tbody></table></figure><ul><li>在所有 Master 节点中，重写（覆盖）Kube-Proxy 服务的 Systemd 配置文件（<strong>请自行更改 API Server 的地址，需要使用 Keepalived 的 VIP 和 HaProxy 的反向代理端口，切勿直接拷贝执行以下命令</strong>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重写 Kube-Proxy 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line">After=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.conf</span><br><span class="line">ExecStartPre=/bin/bash<span class="params"> -c</span> <span class="string">'until curl --silent --fail --cacert /opt/kubernetes/ssl/ca.pem --cert /opt/kubernetes/ssl/health-check.pem --key /opt/kubernetes/ssl/health-check-key.pem https://192.168.2.100:16443/readyz &gt; /dev/null 2&gt;&amp;1; do echo "Waiting for API Server to be ready..."; sleep 2; done &amp;&amp; echo "API Server is now ready."'</span></span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-proxy \<span class="variable">$KUBE_PROXY_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 Kube-Proxy 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Kube-Proxy 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-proxy</span><br></pre></td></tr></tbody></table></figure><hr><blockquote><p><strong>管理 Node 节点的组件启动，以下所有操作分别在 Kubernetes 集群的所有 Node 节点上执行</strong></p></blockquote><ul><li>在所有 Node 节点中，重写（覆盖）Kubelet 服务的 Systemd 配置文件（<strong>请自行更改 API Server 的地址，需要使用 Keepalived 的 VIP 和 HaProxy 的反向代理端口，切勿直接拷贝执行以下命令</strong>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重写 Kubelet 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line">After=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kubelet.conf</span><br><span class="line">ExecStartPre=/bin/bash<span class="params"> -c</span> <span class="string">'until curl --silent --fail --cacert /opt/kubernetes/ssl/ca.pem --cert /opt/kubernetes/ssl/health-check.pem --key /opt/kubernetes/ssl/health-check-key.pem https://192.168.2.100:16443/readyz &gt; /dev/null 2&gt;&amp;1; do echo "Waiting for API Server to be ready..."; sleep 2; done &amp;&amp; echo "API Server is now ready."'</span></span><br><span class="line">ExecStart=/opt/kubernetes/bin/kubelet \<span class="variable">$KUBELET_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 Kubelet 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Kubelet 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kubelet</span><br></pre></td></tr></tbody></table></figure><ul><li>在所有 Node 节点中，重写（覆盖）Kube-Proxy 服务的 Systemd 配置文件（<strong>请自行更改 API Server 的地址，需要使用 Keepalived 的 VIP 和 HaProxy 的反向代理端口，切勿直接拷贝执行以下命令</strong>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重写 Kube-Proxy 服务管理的配置文件</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network-online.target</span><br><span class="line">After=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.conf</span><br><span class="line">ExecStartPre=/bin/bash<span class="params"> -c</span> <span class="string">'until curl --silent --fail --cacert /opt/kubernetes/ssl/ca.pem --cert /opt/kubernetes/ssl/health-check.pem --key /opt/kubernetes/ssl/health-check-key.pem https://192.168.2.100:16443/readyz &gt; /dev/null 2&gt;&amp;1; do echo "Waiting for API Server to be ready..."; sleep 2; done &amp;&amp; echo "API Server is now ready."'</span></span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-proxy \<span class="variable">$KUBE_PROXY_OPTS</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启 Kube-Proxy 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Kube-Proxy 服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-proxy</span><br></pre></td></tr></tbody></table></figure><h3 id="Etcd-无法正常启动"><a href="#Etcd-无法正常启动" class="headerlink" title="Etcd 无法正常启动"></a>Etcd 无法正常启动</h3><ul><li>Etcd 集群断电重启后，通过 <code>systemctl status etcd</code> 命令查看 Etcd 节点（比如：节点名称是 <code>etcd-3</code>，IP 是 <code>192.168.2.131</code>）的运行状态时，提示 Raft 同步失败（如下）。最有可能的原因是这个 Etcd 节点的数据目录损坏或不一致导致，解决方案如下：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">8月 07 09:43:32 k8s-node2 etcd[6043]: {"level":"info","ts":"2025-08-07T09:43:32.007+0800","caller":"rafthttp/stream.go:425","msg":"established TCP streaming connection with remote peer","stream-reader-type":"stream MsgApp v2","local-member-id":"9cb4eb07d38510b5","remote-peer-id":"a00042f5519886e3"}</span><br><span class="line">8月 07 09:43:32 k8s-node2 etcd[6043]: {"level":"info","ts":"2025-08-07T09:43:32.026+0800","caller":"etcdserver/server.go:715","msg":"initialized peer connections; fast-forwarding election ticks","local-member-id":"9cb4eb07d38510b5","forward-ticks":8,"forward-duration":"800ms","election-ticks":10,"election-timeout...</span><br><span class="line">8月 07 09:43:38 k8s-node2 etcd[6043]: {"level":"warn","ts":"2025-08-07T09:43:38.988+0800","caller":"etcdserver/server.go:2065","msg":"failed to publish local member to cluster through raft","local-member-id":"9cb4eb07d38510b5","local-member-attributes":"{Name:etcd-3 ClientURLs:[https://192.168.2.131:2379]}","requ...</span><br><span class="line">8月 07 09:43:45 k8s-node2 etcd[6043]: {"level":"warn","ts":"2025-08-07T09:43:45.988+0800","caller":"etcdserver/server.go:2065","msg":"failed to publish local member to cluster through raft","local-member-id":"9cb4eb07d38510b5","local-member-attributes":"{Name:etcd-3 ClientURLs:[https://192.168.2.131:2379]}","requ...</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full.</span><br></pre></td></tr></tbody></table></figure><ul><li>在其他健康的 Etcd 节点上，查看 Etcd 集群的运行状态，可以发现缺少了 <code>etcd-3</code> 节点</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看集群的运行状态</span></span><br><span class="line"><span class="comment"># /opt/etcd/bin/etcdctl --endpoints=https://192.168.2.191:2379,https://192.168.2.112:2379,https://192.168.2.131:2379 --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem endpoint status --write-out=table</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| https://192.168.2.191:2379 |   9a8c44f9310511 |   3.4.9 |  5.0 MB |     false |      false |       369 |     314583 |             314583 |        |</span><br><span class="line">| https://192.168.2.112:2379 | a00042f5519886e3 |   3.4.9 |  5.0 MB |      true |      false |       369 |     314583 |             314583 |        |</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></tbody></table></figure><ul><li>通过其他健康的 Etcd 节点，查看 Etcd 集群的成员列表，虽然 <code>etcd-3</code> 节点无法正常启动，但依旧可以看到 <code>etcd-3</code> 节点</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看集群的成员列表</span></span><br><span class="line"><span class="comment"># /opt/etcd/bin/etcdctl --endpoints=https://192.168.2.191:2379 --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem member list</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">9a8c44f9310511, started, etcd-1, https://192.168.2.191:2380, https://192.168.2.191:2379, false</span><br><span class="line">5e5716f1d7eba042, started, etcd-3, https://192.168.2.131:2380, https://192.168.2.131:2379, false</span><br><span class="line">a00042f5519886e3, started, etcd-2, https://192.168.2.112:2380, https://192.168.2.112:2379, false</span><br></pre></td></tr></tbody></table></figure><ul><li>在其他健康的 Etcd 节点上，将无法正常启动的 <code>etcd-3</code> 节点移除出集群</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将节点移除出集群</span></span><br><span class="line"><span class="comment"># /opt/etcd/bin/etcdctl --endpoints=https://192.168.2.191:2379 --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem member remove 5e5716f1d7eba042</span></span><br></pre></td></tr></tbody></table></figure><ul><li>在无法正常启动的 <code>etcd-3</code> 节点上，删除本地的 Etcd 数据目录</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭Etcd服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> stop etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除Etcd服务的数据目录</span></span><br><span class="line"><span class="keyword"># rm</span><span class="params"> -rf</span> /var/lib/etcd/default.etcd</span><br></pre></td></tr></tbody></table></figure><ul><li>通过其他健康的 Etcd 节点，将无法正常启动的 <code>etcd-3</code> 节点重新加入 Etcd 集群</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将节点重新加入集群</span></span><br><span class="line"><span class="comment"># /opt/etcd/bin/etcdctl --endpoints=https://192.168.2.112:2379 --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem member add etcd-3 --peer-urls=https://192.168.2.131:2380</span></span><br></pre></td></tr></tbody></table></figure><ul><li>执行命令将 <code>etcd-3</code> 节点重新加入 Etcd 集群后，会输出以下内容</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ETCD_NAME="etcd-3"</span><br><span class="line">ETCD_INITIAL_CLUSTER="etcd-1=https://192.168.2.191:2380,etcd-3=https://192.168.2.131:2380,etcd-2=https://192.168.2.112:2380"</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.2.131:2380"</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE="existing"</span><br></pre></td></tr></tbody></table></figure><ul><li>在无法正常启动的 <code>etcd-3</code> 节点上，更改本地的 Etcd 配置文件，将 <code>ETCD_INITIAL_CLUSTER_STATE</code> 改为 <code>existing</code>，并重启 Etcd 服务（如果上面的操作都生效了，那么这时候 Etcd 服务应该就可以正常启动了）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更改Etcd的配置文件</span></span><br><span class="line"><span class="keyword"># sed</span><span class="params"> -i</span> <span class="string">'s/^ETCD_INITIAL_CLUSTER_STATE="new"/ETCD_INITIAL_CLUSTER_STATE="existing"/'</span> /opt/etcd/cfg/etcd.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启Etcd服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Etcd服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status etcd</span><br></pre></td></tr></tbody></table></figure><ul><li>在之前无法正常启动的 <code>etcd-3</code> 节点上，还原本地的 Etcd 配置文件，将 <code>ETCD_INITIAL_CLUSTER_STATE</code> 改为 <code>new</code>，并重启 Etcd 服务</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更改Etcd的配置文件</span></span><br><span class="line"><span class="keyword"># sed</span><span class="params"> -i</span> <span class="string">'s/^ETCD_INITIAL_CLUSTER_STATE="existing"/ETCD_INITIAL_CLUSTER_STATE="new"/'</span> /opt/etcd/cfg/etcd.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启Etcd服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Etcd服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status etcd</span><br></pre></td></tr></tbody></table></figure><ul><li>在其他健康的 Etcd 节点上，再次查看 Etcd 集群的运行状态，可以发现 <code>etcd-3</code> 节点（会获得新的节点 ID）正常运行</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看集群的运行状态</span></span><br><span class="line"><span class="comment"># /opt/etcd/bin/etcdctl --endpoints=https://192.168.2.191:2379,https://192.168.2.112:2379,https://192.168.2.131:2379 --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem endpoint status --write-out=table</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| https://192.168.2.191:2379 |   9a8c44f9310511 |   3.4.9 |  5.0 MB |     false |      false |       369 |     323848 |             323848 |        |</span><br><span class="line">| https://192.168.2.112:2379 | a00042f5519886e3 |   3.4.9 |  5.0 MB |      true |      false |       369 |     323848 |             323848 |        |</span><br><span class="line">| https://192.168.2.131:2379 | d282ba1f56161393 |   3.4.9 |  5.0 MB |     false |      false |       369 |     323848 |             323848 |        |</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">问题分析与总结</p><p><code>ETCD_INITIAL_CLUSTER_STATE="new"</code> 表示 Etcd 节点将以 "全新集群" 的方式启动，此时它会根据 <code>ETCD_INITIAL_CLUSTER</code> 中的成员列表初始化集群，并假设 Raft 日志为空。如果该节点此前已经加入过集群，当再次使用 <code>new</code> 启动时，就会导致与现有集群中的成员 ID 冲突，触发 Raft 同步失败。而 <code>ETCD_INITIAL_CLUSTER_STATE="existing"</code> 则用于已存在的集群节点，表示该节点将从其他成员处拉取 Raft 日志进行同步。因此，当 <code>etcd-3</code> 节点已经出现在 Etcd 集群的成员列表中时，配置 <code>ETCD_INITIAL_CLUSTER_STATE="new"</code> 是错误的，应该改为 <code>existing</code>，否则该节点在重启时会错误地尝试初始化一个新的集群，导致 Raft 冲突和无法加入集群。简而言之，在初次搭建 Etcd 集群时，<code>ETCD_INITIAL_CLUSTER_STATE="new"</code> 是正确的，但在 Etcd 节点重启或者重新加入集群时，如果这个值仍然是 <code>new</code>，那就可能会引发严重的问题。</p></div><h3 id="连接-API-Server-失败"><a href="#连接-API-Server-失败" class="headerlink" title="连接 API Server 失败"></a>连接 API Server 失败</h3><p>Kubernetes 部分组件（比如 Controller Manager）在启动后，无法与 API Server 通过 HTTPS 协议进行加密通信，出现以下错误信息：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">11月 11 11:56:48 k8s-master1 kube-controller-manager[7582]: I1111 11:56:48.590181    7582 leaderelection.go:243] attempting to acquire leader lease  kube-system/kube-controller-manager...</span><br><span class="line">11月 11 11:56:48 k8s-master1 kube-controller-manager[7582]: E1111 11:56:48.591986    7582 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: the server rejected our request for an unknown reason (get endpoints kube-controller-manager)</span><br><span class="line">11月 11 11:56:51 k8s-master1 kube-controller-manager[7582]: E1111 11:56:51.722757    7582 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: the server rejected our request for an unknown reason (get endpoints kube-controller-manager)</span><br><span class="line">11月 11 11:56:54 k8s-master1 kube-controller-manager[7582]: E1111 11:56:54.201575    7582 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: the server rejected our request for an unknown reason (get endpoints kube-controller-manager)</span><br><span class="line">11月 11 11:56:57 k8s-master1 kube-controller-manager[7582]: E1111 11:56:57.184837    7582 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: the server rejected our request for an unknown reason (get endpoints kube-controller-manager)</span><br><span class="line">11月 11 11:56:59 k8s-master1 kube-controller-manager[7582]: E1111 11:56:59.859566    7582 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: the server rejected our request for an unknown reason (get endpoints kube-controller-manager)</span><br></pre></td></tr></tbody></table></figure><p>这通常是 Kubernetes 组件与 API Server 通信时，所有使用的 CA 证书不匹配导致（或者缺少 CA 证书配置），这里以 Controller Manager 组件为例，给出解决方法</p><hr><p>更改 Controller Manager 的配置文件，使其启动后打印详细的日志信息</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更改配置文件，将 --logtostderr 配置项的值改为 true，打印详细的日志信息</span></span><br><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kube-controller-manager.conf &lt;&lt; EOF</span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=<span class="string">"--logtostderr=true \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--leader-elect=true \\</span></span><br><span class="line"><span class="string">--master=192.168.2.100:16443 \\</span></span><br><span class="line"><span class="string">--bind-address=127.0.0.1 \\</span></span><br><span class="line"><span class="string">--allocate-node-cidrs=true \\</span></span><br><span class="line"><span class="string">--cluster-cidr=10.244.0.0/16 \\</span></span><br><span class="line"><span class="string">--service-cluster-ip-range=10.0.0.0/24 \\</span></span><br><span class="line"><span class="string">--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--root-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--use-service-account-credentials=true \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span></span><br><span class="line"><span class="string">--cluster-signing-duration=87600h0m0s"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><p>重启 Controller Manager 服务，查看输出的详细日志信息，以此定位问题</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新系统配置</span></span><br><span class="line"><span class="keyword"># systemctl</span> daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status kube-controller-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看日志信息</span></span><br><span class="line"><span class="keyword"># journalctl</span><span class="params"> -u</span> kube-controller-manager<span class="params"> -f</span></span><br></pre></td></tr></tbody></table></figure><p>手动测试与 API Server 的连接和认证</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 Controller Manager 的 kubeconfig 测试连接</span></span><br><span class="line"><span class="keyword"># kubectl</span><span class="params"> --kubeconfig</span>=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig get componentstatuses</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果测试连接失败，可以尝试直接使用 Controller Manager 的证书进行测试</span></span><br><span class="line"><span class="keyword"># curl</span><span class="params"> -k</span> \<span class="params"></span></span><br><span class="line"><span class="params">  --cert</span> /opt/kubernetes/ssl/controller-manager.pem \<span class="params"></span></span><br><span class="line"><span class="params">  --key</span> /opt/kubernetes/ssl/controller-manager-key.pem \<span class="params"></span></span><br><span class="line"><span class="params">  --cacert</span> /opt/kubernetes/ssl/ca.pem \</span><br><span class="line">  https://192.168.2.100:16443/version</span><br></pre></td></tr></tbody></table></figure><p>检查 API Server 的证书，必须包含 Keepalived 的虚拟 IP 地址（比如 <code>192.168.2.100</code>）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查 API Server 证书的 SAN</span></span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params"> -in</span> /opt/kubernetes/ssl/server.pem<span class="params"> -text</span><span class="params"> -noout</span> | grep<span class="params"> -A</span> 5 <span class="string">"X509v3 Subject Alternative Name"</span></span><br></pre></td></tr></tbody></table></figure><p>检查 Controller Manager 证书中的 Subject 和 SAN</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查证书的 Subject 和 SAN</span></span><br><span class="line"><span class="keyword"># openssl</span> x509<span class="params"> -in</span> /opt/kubernetes/ssl/controller-manager.pem<span class="params"> -text</span><span class="params"> -noout</span> | grep<span class="params"> -A</span> 10 <span class="string">"Subject:"</span></span><br></pre></td></tr></tbody></table></figure><p>检查 HaProxy 与 Keepalived 是否可以正常工作</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证 Keepalived 的 VIP 与 HaProxy 的反向代理功能（注意，这里即使测试通过，只能说明网络连通性没问题，不能说明其他组件一定可以 API Server 通过 HTTPS 协议进行加密通信，尤其是涉及到证书问题时）</span></span><br><span class="line"><span class="keyword"># curl</span><span class="params"> --cacert</span> /opt/kubernetes/ssl/ca.pem https://192.168.2.100:16443/healthz</span><br></pre></td></tr></tbody></table></figure><p>经检查，发现 Controller Manager 缺少了以下配置项，<strong>尤其是缺少 <code>--requestheader-client-ca-file</code> 配置项</strong>，导致无法与 API Server 通过 HTTPS 协议进行加密通信（使用 CA 证书）</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--authentication-kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span><br><span class="line">--authorization-kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span><br><span class="line">--client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span><br><span class="line">--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span><br><span class="line">--tls-cert-file=/opt/kubernetes/ssl/controller-manager.pem \\</span><br><span class="line">--tls-private-key-file=/opt/kubernetes/ssl/controller-manager-key.pem \\</span><br></pre></td></tr></tbody></table></figure><p>最终，Controller Manager 使用以下配置信息后，可以与 API Server 通过 HTTPS 协议进行加密通信（使用 CA 证书）</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># cat</span> &gt; /opt/kubernetes/cfg/kube-controller-manager.conf &lt;&lt; EOF</span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=<span class="string">"--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--leader-elect=true \\</span></span><br><span class="line"><span class="string">--bind-address=127.0.0.1 \\</span></span><br><span class="line"><span class="string">--allocate-node-cidrs=true \\</span></span><br><span class="line"><span class="string">--cluster-cidr=10.244.0.0/16 \\</span></span><br><span class="line"><span class="string">--service-cluster-ip-range=10.0.0.0/24 \\</span></span><br><span class="line"><span class="string">--secure-port=10257 \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span></span><br><span class="line"><span class="string">--authentication-kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span></span><br><span class="line"><span class="string">--authorization-kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span></span><br><span class="line"><span class="string">--client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--use-service-account-credentials=true \\</span></span><br><span class="line"><span class="string">--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--tls-cert-file=/opt/kubernetes/ssl/kube-controller-manager.pem \\</span></span><br><span class="line"><span class="string">--tls-private-key-file=/opt/kubernetes/ssl/kube-controller-manager-key.pem \\</span></span><br><span class="line"><span class="string">--root-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--controllers=*,bootstrapsigner,tokencleaner \\</span></span><br><span class="line"><span class="string">--deployment-controller-sync-period=10s \\</span></span><br><span class="line"><span class="string">--enable-garbage-collector=true \\</span></span><br><span class="line"><span class="string">--terminated-pod-gc-threshold=50 \\</span></span><br><span class="line"><span class="string">--node-monitor-period=5s \\</span></span><br><span class="line"><span class="string">--node-monitor-grace-period=20s \\</span></span><br><span class="line"><span class="string">--pod-eviction-timeout=2m0s \\</span></span><br><span class="line"><span class="string">--cluster-signing-duration=87600h0m0s"</span></span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>配置项 <code>--requestheader-client-ca-file</code> 用于验证 API Server 聚合层（Aggregation Layer）客户端请求头证书的 CA 文件，Controller Manager 在与启用了聚合层的 API Server 通信时，会使用该 CA 验证代理请求来源的合法性，可以与 <code>--requestheader-allowed-names</code>、<code>--requestheader-extra-headers-prefix</code>、<code>--requestheader-group-headers</code>、<code>--requestheader-username-headers</code> 等参数配合使用。</p></div><h3 id="Kubelet-无法正常启动"><a href="#Kubelet-无法正常启动" class="headerlink" title="Kubelet 无法正常启动"></a>Kubelet 无法正常启动</h3><p>Kubelet 服务断电重启后，通过 <code>systemctl status kubelet</code> 命令查看运行状态时，服务没有处于 <code>active (running)</code> 状态，并且有各种错误信息，尝试多种方法依旧无法正常重启。解决方案如下：</p><ul><li>在 Etcd 集群的所有节点上，分别删除 Etcd 的数据目录（<strong>切记谨慎操作，Etcd 数据删除后，已有的容器都可能无法正常启动，并且整个 Kubernetes 集群都可能需要重建</strong>），并重启 Etcd 服务</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭Etcd服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> stop etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除Etcd服务的数据目录</span></span><br><span class="line"><span class="keyword"># rm</span><span class="params"> -rf</span> /var/lib/etcd/default.etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动Etcd服务（多个Etcd节点必须同时启动）</span></span><br><span class="line"><span class="keyword"># systemctl</span> start etcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Etcd服务的运行状态</span></span><br><span class="line"><span class="keyword"># systemctl</span> status etcd</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，按顺序重启以下服务</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># systemctl</span> restart kube-apiserver</span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-controller-manager</span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-scheduler</span><br><span class="line"><span class="keyword"># systemctl</span> restart kubelet</span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-proxy</span><br></pre></td></tr></tbody></table></figure><ul><li>在所有 Node 节点中，按顺序重启以下服务</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword"># systemctl</span> restart kubelet</span><br><span class="line"><span class="keyword"># systemctl</span> restart kube-proxy</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点中，批准 Kubelet 证书签名请求并允许 Node 节点加入 Kubernetes 集群</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 Kubernetes 集群中的所有证书签名请求</span></span><br><span class="line"><span class="keyword"># kubectl</span> get csr</span><br><span class="line">NAME                                                   AGE   SIGNERNAME                                    REQUESTOR           CONDITION</span><br><span class="line">node-csr-B91KCv7T_4A4RCfvfEBfFOP3V5zCYKK5NQkVLDmyly4   86s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line">node-csr-F4zdBAJxxKnDLsWJbYHVi_XKF8Uwh1MMarXNJiHAUy0   85s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line">node-csr-GYbsPLYySA0LiUkuhbpXlApj-JC-TDnA7SVRPHWU2mI   88s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line">node-csr-bLUS_w2or-Rq9c5JgCzaf5e6QYHND6PTEqQFTvDsY5g   96s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line">node-csr-ndBBynU94khVf6ADv4pdmtrlsxDOXAnyxu18e_VnhBU   87s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批准证书签名请求（请根据上面输出的证书签名请求名称，自行更改命令行参数）</span></span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-B91KCv7T_4A4RCfvfEBfFOP3V5zCYKK5NQkVLDmyly4</span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-F4zdBAJxxKnDLsWJbYHVi_XKF8Uwh1MMarXNJiHAUy0</span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-GYbsPLYySA0LiUkuhbpXlApj-JC-TDnA7SVRPHWU2mI</span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-bLUS_w2or-Rq9c5JgCzaf5e6QYHND6PTEqQFTvDsY5g</span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-ndBBynU94khVf6ADv4pdmtrlsxDOXAnyxu18e_VnhBU</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看集群中所有节点的状态（当 CNI 网络插件部署完成后，所有节点都会自动切换到准备就绪状态 - Ready）</span></span><br><span class="line"><span class="keyword"># kubectl</span> get node</span><br><span class="line">NAME          STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master1   NotReady   &lt;none&gt;   10m   v1.19.10</span><br><span class="line">k8s-master2   NotReady   &lt;none&gt;   18s   v1.19.10</span><br><span class="line">k8s-node1     NotReady   &lt;none&gt;   29s   v1.19.10</span><br><span class="line">k8s-node2     NotReady   &lt;none&gt;   22s   v1.19.10</span><br><span class="line">k8s-node3     NotReady   &lt;none&gt;   25s   v1.19.10</span><br></pre></td></tr></tbody></table></figure><h3 id="Kubelet-发送-CSR-请求失败"><a href="#Kubelet-发送-CSR-请求失败" class="headerlink" title="Kubelet 发送 CSR 请求失败"></a>Kubelet 发送 CSR 请求失败</h3><p>Kubelet 服务启动后，无法正常向 API Server 发起 CSR（证书签名请求），解决方案如下：</p><ul><li>在当前节点上，清理 Kubelet 运行时产生的文件，并重启 Kubelet 服务</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭 Kubelet 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> stop kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除 Kubelet 运行时残留的文件</span></span><br><span class="line"><span class="keyword"># rm</span><span class="params"> -rf</span> /opt/kubernetes/ssl/kubelet*</span><br><span class="line"><span class="keyword"># rm</span><span class="params"> -rf</span> /opt/kubernetes/cfg/kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 Kubelet 是否有可用的 CA 证书</span></span><br><span class="line"><span class="keyword"># ls</span> /opt/kubernetes/ssl/ca*.pem</span><br><span class="line">/opt/kubernetes/ssl/ca-key.pem  /opt/kubernetes/ssl/ca.pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 Kubelet 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> start kubelet</span><br></pre></td></tr></tbody></table></figure><ul><li>在任意一个 Master 节点上，执行以下命令，批准 Kubelet 证书签名请求并允许 Node 节点加入 Kubernetes 集群</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 Kubernetes 集群中的所有证书签名请求</span></span><br><span class="line"><span class="keyword"># kubectl</span> get csr</span><br><span class="line">NAME                                                   AGE   SIGNERNAME                                    REQUESTOR           CONDITION</span><br><span class="line">node-csr-B91KCv7T_4A4RCfvfEBfFOP3V5zCYKK5NQkVLDmyly4   95s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批准证书签名请求（请根据上面输出的证书签名请求名称，自行更改命令行参数）</span></span><br><span class="line"><span class="keyword"># kubectl</span> certificate approve node-csr-B91KCv7T_4A4RCfvfEBfFOP3V5zCYKK5NQkVLDmyly4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看集群中所有节点的状态（当 CNI 网络插件部署完成后，所有节点都会自动切换到准备就绪状态 - Ready）</span></span><br><span class="line"><span class="keyword"># kubectl</span> get node</span><br><span class="line">NAME          STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master1   NotReady   &lt;none&gt;   10m   v1.19.10</span><br><span class="line">k8s-master2   NotReady   &lt;none&gt;   18s   v1.19.10</span><br><span class="line">k8s-node1     NotReady   &lt;none&gt;   29s   v1.19.10</span><br><span class="line">k8s-node2     NotReady   &lt;none&gt;   22s   v1.19.10</span><br><span class="line">k8s-node3     NotReady   &lt;none&gt;   25s   v1.19.10</span><br></pre></td></tr></tbody></table></figure><h3 id="CNI-网络插件无法正常部署"><a href="#CNI-网络插件无法正常部署" class="headerlink" title="CNI 网络插件无法正常部署"></a>CNI 网络插件无法正常部署</h3><ul><li>在 Kubernetes 集群中部署 CNI 网络插件（Flannel）后，通过 <code>systemctl status kubelet</code> 命令查看 Kubelet 的运行状态时，出现以下镜像错误信息，导致 CNI 网络插件（Flannel）无法正常部署</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">k8s-node1 kubelet[30963]: E0805 19:42:19.257544   30963 kuberuntime_sandbox.go:69] CreatePodSandbox for pod "kube-flannel-ds-g5q5l_kube-flannel(0c854c29-c158-45ca-a6c4-5d9ee7d9879b)" failed: rpc error: code = Unknown desc = failed pulling image "lizhenliang/pause-amd64:3.0": Error response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</span><br><span class="line">k8s-node1 kubelet[14733]: E0805 21:34:10.987901   14733 kubelet.go:2134] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br><span class="line">k8s-node1 kubelet[14733]: E0805 21:34:15.991080   14733 kubelet.go:2134] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br><span class="line">k8s-node1 kubelet[14733]: E0805 21:34:21.015325   14733 kubelet.go:2134] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br></pre></td></tr></tbody></table></figure><ul><li>这是因为 Kubelet 会根据 <code>kubelet.conf</code> 配置文件，从 Docker Hub 拉取 <code>lizhenliang/pause-amd64:3.0</code> 镜像；若网络访问超时，就会出现上述错误信息。解决方案有这几种：手动拉取镜像、配置 Docker 代理、更换 Docker 镜像源，最后重启 Kubelet 服务</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭 Kubelet 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> stop kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动拉取 Pause 镜像（用于 Pod 网络命名空间）</span></span><br><span class="line"><span class="keyword"># docker</span> pull lizhenliang/pause-amd64:3.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 Kubelet 服务</span></span><br><span class="line"><span class="keyword"># systemctl</span> start kubelet</span><br></pre></td></tr></tbody></table></figure><ul><li>当 Kubelet 服务成功启动，且 CNI 网络插件（Flannel）成功部署后，可以发现当前节点会有以下 Docker 镜像（缺一不可）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看镜像列表</span></span><br><span class="line"><span class="keyword"># docker</span> images</span><br><span class="line">REPOSITORY                              TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">ghcr.io/flannel-io/flannel              v0.27.4             e83704a17731        5 weeks ago         91.4MB</span><br><span class="line">ghcr.io/flannel-io/flannel-cni-plugin   v1.8.0-flannel1     bb28ded63816        5 weeks ago         10.8MB</span><br><span class="line">lizhenliang/pause-amd64                 3.0                 99e59f495ffa        9 years ago         747kB</span><br></pre></td></tr></tbody></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a target="_blank" rel="external nofollow" href="https://cloud.tencent.com/developer/article/2236281">Kubernetes 集群之 Scheduler 部署</a></li><li><a target="_blank" rel="external nofollow" href="https://www.cnblogs.com/tchua/p/10762725.html">Kubernetes 集群之 Controller Manager 部署</a></li><li><a href="/posts/503c34e4.html">Nginx + Keepalived 实现双机主备高可用</a></li><li><a href="/posts/c93e2d9.html">HaProxy 与 Keepalived 实现双机热备高可用</a></li></ul><div id="readmore-expansion" class="pjax"></div><link rel="stylesheet" type="text/css" href="https://qiniu.techgrow.cn/readmore/dist/hexo.css"><script data-pjax="" src="https://qiniu.techgrow.cn/readmore/dist/readmore.js" type="text/javascript"></script><script data-pjax="">var isMobile=navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i),allowMobile=!1;if(!isMobile||isMobile&&allowMobile)try{var plugin=new ReadmorePlugin;plugin.init({type:"hexo",id:"readmore-container",name:"全栈技术驿站",blogId:"96641-5333172926158-056",qrcode:"https://www.techgrow.cn/img/wx_mp_qr.png",keyword:"Tech",random:"1",height:"auto",expires:"365",lockToc:"yes",interval:"30",baseUrl:"",execute:"yes",tocSelector:""})}catch(e){console.warn("readmore plugin occurred error: "+e.name+" | "+e.message)}</script></div><footer class="post-footer"><div class="reward-container"><div>支持一根棒棒糖！</div> <button> 赞赏</button><div class="post-reward"><div> <img src="/img/pay_wx.png" alt="Clay 微信"> <span>微信</span></div><div> <img src="/img/pay_zfb.png" alt="Clay 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"> <strong>本文作者：</strong> Clay</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.techgrow.cn/posts/fb1a55bb.html" title="基于二进制包方式搭建 Kubernetes 多 Master 高可用集群">https://www.techgrow.cn/posts/fb1a55bb.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="contactme"><div class="social-list"><div class="social-item"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">欢迎添加博主微信，请备注 "博客"，届时会邀请您加入百人微信群</span><br> <img src="/img/wx_account_qr.png"></div></div></div><div class="post-tags"><a href="/tags/%E5%AE%B9%E5%99%A8%E5%8C%96/" rel="tag"><i class="fa fa-tag"></i> 容器化</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/4a5f9755.html" rel="prev" title="Centos7 升级 GCC 版本"><i class="fa fa-angle-left"></i> Centos7 升级 GCC 版本</a></div><div class="post-nav-item"> <a href="/posts/bdfaacc7.html" rel="next" title="Java 基于 LinkedHashMap 实现 LRU 缓存">Java 基于 LinkedHashMap 实现 LRU 缓存<i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments" id="waline"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> Copyright © 2018 – <span itemprop="copyrightYear">2026</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Clay</span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i></span> <span>站点总字数：</span> <span title="站点总字数">2.3m</span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span>站点阅读时长 ≈</span> <span title="站点阅读时长">35:35</span></span></div><div id="site-runtime"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span><span id="runtime"></span></div><script language="javascript">function isPC(){for(var e=navigator.userAgent,t=["Android","iPhone","SymbianOS","Windows Phone","iPad","iPod"],n=0;n<t.length;n++)if(0<e.indexOf(t[n]))return!1;return!0}function siteTime(e,t){window.setTimeout("siteTime(openOnPC, start)",1e3);var n=36e5,o=24*n;t=new Date("2018-12-27 08:00:00");var i=new Date,r=(i.getFullYear(),i.getMonth(),i.getDate(),i.getHours(),i.getMinutes(),i.getSeconds(),i-t),a=Math.floor(r/31536e6),s=Math.floor(r/o-365*a),d=Math.floor((r-(365*a+s)*o)/n),l=Math.floor((r-(365*a+s)*o-d*n)/6e4),u=Math.floor((r-(365*a+s)*o-d*n-6e4*l)/1e3);document.getElementById("runtime").innerHTML="Powered by Hexo & Docker | "+a+" 年 "+s+" 日 "+d+" 小时 "+l+" 分钟 "+u+" 秒 "}var showOnMobile=!1,openOnPC=isPC(),start=new Date;siteTime(openOnPC,start),openOnPC||showOnMobile||(document.getElementById("site-runtime").style.display="none")</script><div class="beian"> <span><img src="/img/gonganbeian.png" alt=""></span> <span><a href="https://beian.miit.gov.cn/" rel="external nofollow" target="_blank">粤ICP备 19024664号-1</a></span> <span>|&nbsp;</span> <span><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44011302004035" rel="external nofollow" target="_blank">粤公网安备 44011302004035号</a></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div><div class="sidebar-dimmer"></div> <a href="https://github.com/rqh656418510" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="external nofollow" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="200" alpha="0.5" zindex="-1" src="/lib/ribbon.js/dist/ribbon.min.js"></script><script src="/lib/animejs/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="/lib/@next-theme/pjax/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script><script src="/lib/medium-zoom/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script><script src="/lib/lozad/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script><script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"/lib/pdfobject/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script><script src="/js/third-party/tags/pdf.js"></script><script src="/js/third-party/pace.js"></script><script data-pjax="" async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"/lib/mathjax/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><script src="https://www.techgrow.cn/lib/darkmode/darkmode@1.5.7.min.js"></script><script>
var options = {
  bottom: '64px',
  right: '30px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#282828',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script><script src="https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js"></script><script>
    var qiniu_domain = "https://oss.techgrow.cn";
    var qiniu_token_url = "https://open.techgrow.cn/api/oss/qiniu/token/upload";
    var qiniu_debug = "true" === "false";

    // date format
    Date.prototype.format = function (fmt) {
      var o = {
        "M+": this.getMonth() + 1,
        "d+": this.getDate(),
        "h+": this.getHours(),
        "m+": this.getMinutes(),
        "s+": this.getSeconds(),
        "q+": Math.floor((this.getMonth() + 3) / 3),
        "S": this.getMilliseconds()
      };
      if (/(y+)/.test(fmt)) {
        fmt = fmt.replace(RegExp.$1, (this.getFullYear() + "").substr(4 - RegExp.$1.length));
      }
      for (var k in o) {
        if (new RegExp("(" + k + ")").test(fmt)) {
          fmt = fmt.replace(
            RegExp.$1,
            (RegExp.$1.length == 1)
              ? (o[k])
              : (("00" + o[k]).substr(("" + o[k]).length))
          );
        }
      }
      return fmt;
    }

    // generate uuid
    function uuid() {
      var s = [];
      var hexDigits = "0123456789abcdef";
      for (var i = 0; i < 36; i++) {
        s[i] = hexDigits.substr(Math.floor(Math.random() * 0x10), 1);
      }
      s[14] = "4";
      s[19] = hexDigits.substr((s[19] & 0x3) | 0x8, 1);
      s[8] = s[13] = s[18] = s[23] = "-";
      var uuid = s.join("");
      return uuid;
    }

    // sync get request
    function syncGet(url) {
      var xhr = null;
      if (window.XMLHttpRequest) {
        xhr = new XMLHttpRequest();
      } else {
        xhr = new ActiveXObject("Microsoft.XMLHTTP");
      }
      xhr.open('GET', url, false);
      xhr.send();
      return xhr;
    }

    // get upload file path
    function getUploadFilePath() {
      var now = new Date();
      var name = uuid().replace(/-/g, "");
      var nowStr = now.format("/yyyy/MM/dd/");
      return "uploads" + nowStr + name;
    }

    // get qiniu upload token
    function getUploadToken() {
      try {
        var xhr = syncGet(qiniu_token_url);
        var responseStatus = xhr.status;
        var responseJson = JSON.parse(xhr.responseText);
        if (responseStatus === 200) {
          return responseJson.data;
        } else if (responseStatus === 403) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，非法请求来源！");
        } else if (responseStatus === 429) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，上传过于频繁！");
        } else if (responseStatus === 500) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，系统内部出错！");
        } else {
          alert("图片上传失败，无法获取UploadToken，未知Http响应状态码！");
        }
      } catch (err) {
        if (qiniu_debug) {
          console.error(err);
        }
        alert("图片上传失败，无法获取UploadToken，未知错误！");
      }
      return null;
    }

    // qiniu upload image
    async function qiniuUploadImage(file) {
      var image_path = null;
      await uploadImage(file).then(function onFulfilled(res) {
        image_path = res;
      }).catch(function onRejected(err) {
        if (qiniu_debug) {
          console.error(err);
        }
      });
      return image_path;
    }

    // upload image
    function uploadImage(file) {
      return new Promise((resolve, reject) => {
        var config = null;
        var putExtra = null;
        var token = getUploadToken();
        var key = getUploadFilePath();
        // upload init
        var observable = qiniu.upload(file, key, token, putExtra, config);
        // upload start
        observable.subscribe({
          next(res) {
            // upload progress
          },
          error(err) {
            // upload falied
            reject("falied to upload image for qiniu: " + err.name);
          },
          complete(res) {
            // upload successed
            resolve(qiniu_domain + "/" + key);
          }
        });
      });
    }
  </script><script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://waline.techgrow.cn","cssUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css","commentCount":true,"pageview":false,"copyright":false,"allowUploadImage":true,"libUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.js","locale":{"placeholder":"支持匿名评论啦，若希望及时收到博主的反馈，建议登录评论或者在上方的邮箱输入框留下邮箱地址哦 (๑•̀ㅂ•́)و✧"},"dark":"body.darkmode--activated","emoji":["https://www.techgrow.cn/lib/@waline/emojis/1.0.1/weibo"],"meta":["nick","mail","link"],"login":"enable","pageSize":10,"qiniuDebug":false,"qiniuDomain":"https://oss.techgrow.cn","qiniuTokenUrl":"https://open.techgrow.cn/api/oss/qiniu/token/upload","qiniuLibUrl":"https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js","el":"#waline","comment":true,"path":"/posts/fb1a55bb.html"}</script><link rel="stylesheet" href="https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css"><script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.waline.allowUploadImage) {
    CONFIG.waline.imageUploader = false;
  }
  else if (CONFIG.waline.qiniuDomain && CONFIG.waline.qiniuTokenUrl) {
    CONFIG.waline.imageUploader = qiniuUploadImage;
  } else {
   CONFIG.waline.imageUploader = true;
  }
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script><div class="moon-menu"><div class="moon-menu-items"><div id="moon-menu-item-back2bottom" class="moon-menu-item"><i class="fas fa-chevron-down"></i></div><div id="moon-menu-item-back2top" class="moon-menu-item"><i class="fas fa-chevron-up"></i></div><div id="moon-menu-item-code" class="moon-menu-item"><i class="fa-solid fa-code"></i></div></div><div class="moon-menu-button"><svg class="moon-menu-bg"><circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle><circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle></svg><div class="moon-menu-content"><div class="moon-menu-icon"><i class="fas fa-ellipsis-v"></i></div><div class="moon-menu-text"></div></div></div></div><script src="/js/injector.js"></script><div class="comments" id="waline-comments" style="display:none"></div><script>function isMobile(){var i=navigator.userAgent.toLowerCase(),e="ipad"==i.match(/ipad/i),a="iphone os"==i.match(/iphone os/i),o="midp"==i.match(/midp/i),n="rv:1.2.3.4"==i.match(/rv:1.2.3.4/i),r="ucweb"==i.match(/ucweb/i),c="android"==i.match(/android/i),l="windows ce"==i.match(/windows ce/i),d="windows mobile"==i.match(/windows mobile/i);return!!(e||a||o||n||r||c||l||d)}var openOnMobile=isMobile(),showOnMobile=!1,aplayerEnable=!0;jQuery(document).ready(function(){aplayerEnable&&(openOnMobile&&!showOnMobile||jQuery("#aplayer").css("display","block"))}),jQuery(window).on("load",function(){aplayerEnable&&jQuery(".aplayer\\-icon.aplayer\\-icon\\-lrc").trigger("click")})</script></body></html>