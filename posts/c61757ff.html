<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CRoboto+Slab:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic&amp;display=swap&amp;subset=latin,latin-ext"><link rel="stylesheet" href="/lib/@fortawesome/fontawesome-free/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/animate.css/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="/lib/pace-js/themes/blue/pace-theme-minimal.css"><script src="/lib/pace-js/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.techgrow.cn","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script><meta name="description" content="本文主要介绍 Kafka 的使用教程。"><meta property="og:type" content="article"><meta property="og:title" content="Kafka 入门教程之四"><meta property="og:url" content="https://www.techgrow.cn/posts/c61757ff.html"><meta property="og:site_name" content="Clay 的技术空间"><meta property="og:description" content="本文主要介绍 Kafka 的使用教程。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-1.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-2.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-3.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-4.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-5.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-6.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-7.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-8.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-9.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-5.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-10.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-11.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-12.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-13.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-14.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-15.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-16.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-17.png"><meta property="og:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-18.png"><meta property="article:published_time" content="2022-09-02T14:13:45.000Z"><meta property="article:modified_time" content="2022-09-02T14:13:45.000Z"><meta property="article:author" content="Clay"><meta property="article:tag" content="分布式"><meta property="article:tag" content="消息队列"><meta property="article:tag" content="大数据"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.techgrow.cn/asset/2024/11/kafka-consumer-1.png"><link rel="canonical" href="https://www.techgrow.cn/posts/c61757ff.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.techgrow.cn/posts/c61757ff.html","path":"posts/c61757ff.html","title":"Kafka 入门教程之四"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Kafka 入门教程之四 | Clay 的技术空间</title><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-135294383-1"></script><script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-135294383-1","only_pageview":false,"measure_protocol_api_secret":null}</script><script src="/js/third-party/analytics/google-analytics.js"></script><script class="next-config" data-name="baidu_analytics" type="application/json">"84c09b30349a65573c5c642ff336969b"</script><script src="/js/third-party/analytics/baidu-analytics.js"></script><link rel="dns-prefetch" href="https://waline.techgrow.cn"><link rel="stylesheet" type="text/css" href="/css/injector/main.css"><link rel="preload" as="style" href="/css/injector/light.css"><link rel="preload" as="style" href="/css/injector/dark.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><style>.admonition{margin:1.5625em 0;padding:.6rem;overflow:hidden;font-size:.64rem;page-break-inside:avoid;border-left:.3rem solid #42b983;border-radius:.3rem;box-shadow:0 .1rem .4rem rgba(0,0,0,.05),0 0 .05rem rgba(0,0,0,.1);background-color:#fafafa}p.admonition-title{position:relative;margin:-.6rem -.6rem .8em -.6rem!important;padding:.4rem .6rem .4rem 2.5rem;font-weight:700;background-color:rgba(66,185,131,.1)}.admonition-title::before{position:absolute;top:.9rem;left:1rem;width:12px;height:12px;background-color:#42b983;border-radius:50%;content:' '}.info>.admonition-title,.todo>.admonition-title{background-color:rgba(0,184,212,.1)}.attention>.admonition-title,.caution>.admonition-title,.warning>.admonition-title{background-color:rgba(255,145,0,.1)}.error>.admonition-title,.fail>.admonition-title,.failure>.admonition-title,.missing>.admonition-title{background-color:rgba(255,82,82,.1)}.admonition.info,.admonition.todo{border-color:#00b8d4}.admonition.attention,.admonition.caution,.admonition.warning{border-color:#ff9100}.admonition.error,.admonition.fail,.admonition.failure,.admonition.missing{border-color:#ff5252}.info>.admonition-title::before,.todo>.admonition-title::before{background-color:#00b8d4;border-radius:50%}.attention>.admonition-title::before,.caution>.admonition-title::before,.warning>.admonition-title::before{background-color:#ff9100;border-radius:50%}.error>.admonition-title::before,.fail>.admonition-title::before,.failure>.admonition-title::before,.missing>.admonition-title::before{background-color:#ff5252;border-radius:50%}.admonition>:last-child{margin-bottom:0!important}</style><link rel="alternate" href="/atom.xml" title="Clay 的技术空间" type="application/atom+xml"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope="" itemtype="http://schema.org/WebPage" class="use-motion"><script src="/lib/jquery/dist/jquery.min.js"></script><script data-pjax="">!function(){var t=window.location.host;if(-1==t.indexOf("127.0.0.1")&&-1==t.indexOf("localhost")){var o=document.createElement("script"),e=window.location.protocol.split(":")[0];o.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(o,n)}}()</script><link rel="stylesheet" href="/lib/aplayer/dist/APlayer.min.css"><div id="aplayer" style="display:none"></div><script src="/lib/aplayer/dist/APlayer.min.js"></script><script src="/lib/aplayer/dist/color-thief.js"></script><script src="/lib/aplayer-init.js"></script><script src="https://res.wx.qq.com/open/js/jweixin-1.4.0.js"></script><script>function getTitle(){var t=jQuery("meta[property='og:title']");return t?t.attr("content"):""}function getDesc(){var t=jQuery("meta[property='og:description']");return t?t.attr("content"):""}function randomString(t){for(var e="ABCDEFGHJKMNPQRSTWXYZabcdefhijkmnprstwxyz2345678",n=e.length,i="",r=0;r<t;++r)i+=e.charAt(Math.floor(Math.random()*n));return i}function initWx(t){wx.config({debug:!1,appId:t.appId,nonceStr:t.nonceStr,signature:t.signature,timestamp:t.timestamp,jsApiList:["checkJsApi","onMenuShareTimeline","onMenuShareAppMessage","onMenuShareQQ"]}),wx.ready(function(){wx.onMenuShareTimeline({title:t.title,link:t.link,imgUrl:t.imgUrl,success:function(){}}),wx.onMenuShareAppMessage({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,type:"link",dataUrl:"",success:function(){}}),wx.onMenuShareQQ({title:t.title,desc:t.desc,link:t.link,imgUrl:t.imgUrl,success:function(){},cancel:function(){}})}),wx.error(function(t){})}jQuery(function(){var e=getDesc(),n=getTitle(),i=randomString(16),r=(new Date).getTime(),a=window.location.href,t="https://open.techgrow.cn/api/wechat/js/signature?url="+a+"&noncestr="+i+"&timestamp="+r;jQuery.getJSON(t,function(t){initWx({desc:e,title:n,link:a,nonceStr:i,timestamp:r,signature:t.data,appId:"wx1fcf69355af43d41",imgUrl:"https://www.techgrow.cn/img/wx_share.jpg"})})})</script><div style="display:none"><img src="https://www.techgrow.cn/img/wx_share.jpg" alt=""></div><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">Clay 的技术空间</p><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">用进废退 | 艺不压身</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-search"><a href="/search" rel="section"><i class="fa fa-search fa-fw"></i>搜索</a></li><li class="menu-item menu-item-links"><a href="/links" rel="section"><i class="fas fa-link fa-fw"></i>友链</a></li><li class="menu-item menu-item-readingnotes"><a href="https://www.techgrow.cn/reading/" rel="section"><i class="fa fa-book-open-reader fa-fw"></i>读书笔记</a></li><li class="menu-item menu-item-commentmanage"><a href="https://waline.techgrow.cn/" rel="external nofollow" target="_blank"><i class="fa fa-comment fa-fw"></i>评论管理</a></li></ul></nav></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E7%BA%B2"><span class="nav-text">大纲</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-text">前言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90"><span class="nav-text">学习资源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">Kafka 消费者的概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E6%B6%88%E8%B4%B9%E6%96%B9%E5%BC%8F"><span class="nav-text">消费者的消费方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-text">消费者的工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">消费者组的工作原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="nav-text">消费者组的概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B"><span class="nav-text">消费者组的初始化流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E5%AE%8C%E6%95%B4%E6%B6%88%E8%B4%B9%E6%B5%81%E7%A8%8B"><span class="nav-text">消费者组的完整消费流程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0"><span class="nav-text">消费者的核心配置参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">Kafka 消费者的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E4%B8%80%E4%B8%AA%E4%B8%BB%E9%A2%98"><span class="nav-text">消费一个主题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E4%B8%80%E4%B8%AA%E5%88%86%E5%8C%BA"><span class="nav-text">消费一个分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%B6%88%E8%B4%B9%E5%A4%9A%E4%B8%AA%E5%88%86%E5%8C%BA"><span class="nav-text">消费者组消费多个分区</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">Kafka 消费者组的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-text">分区再平衡的概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E5%A4%A7%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-text">四大分区分配策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Range-%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-text">Range 分区分配策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Range-%E7%AD%96%E7%95%A5%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="nav-text">Range 策略的概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Range-%E7%AD%96%E7%95%A5%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">Range 策略的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Range-%E7%AD%96%E7%95%A5%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">Range 策略的案例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Range-%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">Range 分区再平衡的案例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RoundRobin-%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-text">RoundRobin 分区分配策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RoundRobin-%E7%AD%96%E7%95%A5%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="nav-text">RoundRobin 策略的概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RoundRobin-%E7%AD%96%E7%95%A5%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">RoundRobin 策略的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#RoundRobin-%E7%AD%96%E7%95%A5%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">RoundRobin 策略的案例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RoundRobin-%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">RoundRobin 分区再平衡的案例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sticky-%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-text">Sticky 分区分配策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sticky-%E7%AD%96%E7%95%A5%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="nav-text">Sticky 策略的概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sticky-%E7%AD%96%E7%95%A5%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">Sticky 策略的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Sticky-%E7%AD%96%E7%95%A5%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">Sticky 策略的案例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Sticky-%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">Sticky 分区再平衡的案例</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafaka-%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84-offset"><span class="nav-text">Kafaka 消费者的 offset</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#offset-%E7%9A%84%E9%BB%98%E8%AE%A4%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE"><span class="nav-text">offset 的默认存储位置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9-offset-%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">消费 offset 的案例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4-offset"><span class="nav-text">自动提交 offset</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4-offset-%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="nav-text">自动提交 offset 的概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4-offset-%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">自动提交 offset 的案例</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4-offset"><span class="nav-text">手动提交 offset</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4-offset-%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="nav-text">手动提交 offset 的概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4-offset-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">手动提交 offset 的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E6%8F%90%E4%BA%A4-offset-%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">同步提交 offset 的案例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4-offset-%E7%9A%84%E6%A1%88%E4%BE%8B"><span class="nav-text">异步提交 offset 的案例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%8C%87%E5%AE%9A-offset-%E6%B6%88%E8%B4%B9"><span class="nav-text">消费者指定 offset 消费</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%8C%89%E7%85%A7%E6%97%B6%E9%97%B4%E6%B6%88%E8%B4%B9"><span class="nav-text">消费者按照时间消费</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="nav-text">Kafka 消费者的最佳实践</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E4%B8%8E%E6%BC%8F%E6%B6%88%E8%B4%B9%E9%97%AE%E9%A2%98"><span class="nav-text">Kafka 重复消费与漏消费问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">Kafka 消费者事务的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F"><span class="nav-text">Kafka 消费者提高吞吐量</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope="" itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="Clay" src="/img/head.jpg"></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"> <span class="site-state-item-count">684</span> <span class="site-state-item-name">文章</span></div><div class="site-state-item site-state-tags"> <span class="site-state-item-count">53</span> <span class="site-state-item-name">标签</span></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/rqh656418510" title="GitHub → https://github.com/rqh656418510" rel="external nofollow" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:rong656418510@gmail.com" title="E-Mail → mailto:rong656418510@gmail.com" rel="external nofollow" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="/atom.xml" title="RSS → /atom.xml" rel="noopener me"><i class="fa fa-rss fa-fw"></i> RSS</a></span><span class="links-of-author-item"><a href="/sitemap.xml" title="SiteMap → /sitemap.xml" rel="noopener me"><i class="fa fa-sitemap fa-fw"></i> SiteMap</a></span></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope="" itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.techgrow.cn/posts/c61757ff.html"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="image" content="/img/head.jpg"><meta itemprop="name" content="Clay"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Clay 的技术空间"><meta itemprop="description" content="专注于 Java 后端、分布式、微服务、云原生、数据库、系统架构、大数据、云计算、虚拟化、人工智能学习的技术博客。"></span><span hidden="" itemprop="post" itemscope="" itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Kafka 入门教程之四 | Clay 的技术空间"><meta itemprop="description" content="本文主要介绍 Kafka 的使用教程。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Kafka 入门教程之四</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-09-02 22:13:45" itemprop="dateCreated datePublished" datetime="2022-09-02T22:13:45+08:00">2022-09-02</time></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i></span> <span class="post-meta-item-text">评论数：</span><a title="waline" href="/posts/c61757ff.html#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/c61757ff.html" itemprop="commentCount"></span></a></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>13k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 ≈</span> <span>12 分钟</span></span></div></div></header><div class="post-body post-container" itemprop="articleBody" id="readmore-container"><h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><ul><li><a href="/posts/b6be8183.html">Kafka 入门教程之一</a>、<a href="/posts/60ddcede.html">Kafka 入门教程之二</a>、<a href="/posts/228158d3.html">Kafka 入门教程之三</a></li><li><a href="/posts/c61757ff.html">Kafka 入门教程之四</a>、<a href="/posts/ed9d5bd.html">Kafka 入门教程之五</a>、<a href="/posts/e73bffc6.html">Kafka 入门教程之六</a></li><li><a href="/posts/50c7d080.html">Kafka 入门教程之七</a></li></ul><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h3><ul><li><a target="_blank" rel="external nofollow" href="https://kafka.apache.org/documentation/">Kafka 官方文档</a></li><li><a href="/posts/ac64f898.html">Kafka 学习路线</a></li></ul><span id="more"></span><h2 id="Kafka-消费者的概念"><a href="#Kafka-消费者的概念" class="headerlink" title="Kafka 消费者的概念"></a>Kafka 消费者的概念</h2><h3 id="消费者的消费方式"><a href="#消费者的消费方式" class="headerlink" title="消费者的消费方式"></a>消费者的消费方式</h3><p>消息队列通常有以下两种消费模式：</p><ul><li><p>Push（推）模式 :</p><ul><li>概述：MQ 服务器主动推送数据给消费者。</li><li>优点：低延迟，消息实时推送，适合高吞吐场景。</li><li>缺点：消费者可能因自身处理能力不足被压垮（消息速率不可控）。</li></ul></li><li><p>Pull（拉）模式 :</p><ul><li>概述：消费者从 MQ 服务器中主动拉取数据。</li><li>优点：消费者主动拉取，消费速率可控，适合消费处理能力不均衡的场景。</li><li>缺点：消息的消费可能会有延迟（需要消费者轮询）。如果 MQ 服务器没有数据，消费者可能会陷入循环中，因为 MQ 服务器一直返回空数据。</li></ul></li></ul><p><strong>Kafka 并没有采用 Push（推）这种消费模式，而是采用 Pull（拉）的消费模式。</strong>因为由 Broker 决定消息发送速率，将很难适应所有消费者的消费速度。比如，当推送的速度是 50m/s，那么 Consumer1、Consumer2 就可能来不及处理消息（如下图所示）。</p><p><img data-src="../../../asset/2024/11/kafka-consumer-1.png"></p><h3 id="消费者的工作流程"><a href="#消费者的工作流程" class="headerlink" title="消费者的工作流程"></a>消费者的工作流程</h3><p><img data-src="../../../asset/2024/11/kafka-consumer-2.png"></p><div class="admonition note"><p class="admonition-title">提示</p><ul><li>Kafka 在 <code>0.9</code> 版本之前，Consumer 默认将 <code>offset</code> 存储在 Zookeeper 中。</li><li>Kafka 从 <code>0.9</code> 版本开始，Consumer 默认将 <code>offset</code> 保存在 Kafka 一个内置的 Topic 中，该 Topic 为 <code>__consumer_offsets</code>，且默认拥有 50 个分区。</li></ul></div><h3 id="消费者组的工作原理"><a href="#消费者组的工作原理" class="headerlink" title="消费者组的工作原理"></a>消费者组的工作原理</h3><h4 id="消费者组的概述"><a href="#消费者组的概述" class="headerlink" title="消费者组的概述"></a>消费者组的概述</h4><p>Consumer Group（CG）: 消费者组，由多个消费者组成。Kafka 形成一个消费者组的条件，是所有消费者的 <code>groupid</code> 相同。值得一提的是，在使用 Kafka 的命令行消费者时，即使只有一个消费者，也会形成一个消费者组；之所以不用专门为该消费者设置 <code>groupid</code>，这是因为 Kafka 默认给该消费者设置了一个随机的 <code>groupid</code>。</p><ul><li>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费，如下图所示：</li></ul><p><img data-src="../../../asset/2024/11/kafka-consumer-3.png"></p><ul><li>向消费组中添加更多的消费者时，如果消费者数量超过了主题分区数量，则有一部分消费者会闲置（即不会接收任何消息），如下图所示：</li><li>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者（消费者），如下图所示：</li></ul><p><img data-src="../../../asset/2024/11/kafka-consumer-4.png"></p><h4 id="消费者组的初始化流程"><a href="#消费者组的初始化流程" class="headerlink" title="消费者组的初始化流程"></a>消费者组的初始化流程</h4><p><img data-src="../../../asset/2024/11/kafka-consumer-5.png"></p><ul><li>coordinator 节点的作用<ul><li>辅助实现消费者组的初始化和分区的分配。</li></ul></li><li>coordinator 节点的选择<ul><li>节点选择算法：<code>groupid 的哈希值 % 50</code>，这里的 <code>50</code> 是 Kafka 内置主题 <code>__consumer_offsets</code> 的默认分区数量，可以通过 Kafka 的 <code>offsets.topic.num.partitions</code> 参数进行配置。</li><li>例如，<code>groupid 的哈希值 = 1; 1 % 50 = 1;</code>，那么就选择 <code>__consumer_offsets</code> 主题的 1 号分区；该分区在哪个 Broker 上，就选择这个 Brokder 的 <code>coordinator</code> 作为这个消费者组的老大（负责消费者组的初始化和分区的分配）。在该消费者组下的所有消费者提交 offset 的时候，就往这个分区去提交 offset。</li></ul></li><li>coordinator 相关的配置参数</li></ul><table><thead><tr><th>参数名称</th><th>参数描述</th></tr></thead><tbody><tr><td><code>heartbeat.interval.ms</code></td><td>消费者向 Broker（Coordinator）发送心跳的时间间隔，该参数的值必须小于 <code>session.timeout.ms</code>，也不应该高于 <code>session.timeout.ms</code> 的 1/3，默认值为 <code>3秒</code></td></tr><tr><td><code>session.timeout.ms</code></td><td>消费者与 Broker（Coordinator）之间心跳超时的阈值，如果消费者在该时间内未向 Broker（Coordinator） 发送心跳，则会被认为消费者已失效，其分区会被重新分配给组内的其他消费者（即触发分区再平衡），默认值为 <code>45秒</code></td></tr><tr><td><code>max.poll.interval.ms</code></td><td>消费者处理消息的最长时间，如果消费者在该时间内未处理完消息（即未调用 <code>poll()</code> 方法），则会被认为消费者已失效，其分区会被重新分配给组内的其他消费者（即触发分区再平衡），默认值为 <code>5分钟</code></td></tr></tbody></table><h4 id="消费者组的完整消费流程"><a href="#消费者组的完整消费流程" class="headerlink" title="消费者组的完整消费流程"></a>消费者组的完整消费流程</h4><p><img data-src="../../../asset/2024/11/kafka-consumer-6.png"></p><h3 id="消费者的核心配置参数"><a href="#消费者的核心配置参数" class="headerlink" title="消费者的核心配置参数"></a>消费者的核心配置参数</h3><p>Kafka 消费者的核心配置参数如下表所示，或者查看 <a href="../../../asset/2024/12/kafka-consumer-optimize-3.png">这里</a> 整理的参数表格。</p><table><thead><tr><th>参数名称</th><th>参数描述</th></tr></thead><tbody><tr><td><code>bootstrap.servers</code></td><td>向 Kafka 集群建立初始连接用到的 <code>host:port</code> 列表。</td></tr><tr><td><code>key.deserializer</code></td><td>指定接收消息的 key 的反序列化器。</td></tr><tr><td><code>value.deserializer</code></td><td>指定接收消息的 value 的反序列化器。</td></tr><tr><td><code>group.id</code></td><td>消费者组 ID，用于标记消费者所属的消费者组。</td></tr><tr><td><code>enable.auto.commit</code></td><td>指定消费者是否自动周期性地向服务器提交 offset，默认值为 <code>true</code>。</td></tr><tr><td><code>auto.commit.interval.ms</code></td><td>如果设置了 <code>enable.auto.commit</code> 的值为 <code>true</code>，则该参数定义了消费者自动提交 offset 的时间间隔（频率），默认值是 <code>5 秒</code>。</td></tr><tr><td><code>auto.offset.reset</code></td><td>当 Kafka 中没有初始 offset 或当前 offset 在服务器中不存在时（比如，数据被删除了），该如何处理？<br> - <code>earliest</code>：自动重置 offset 到最早的 offset。<br> - <code>latest</code>：自动重置 offset 为最晚的 offset，这是默认值。<br> - <code>none</code>：如果消费组原来的 offset 不存在，则向消费者抛出异常。<br> - <code>anything</code>：向消费者抛异常。</td></tr><tr><td><code>offsets.topic.num.partitions</code></td><td>Kafka 内置主题 <code>__consumer_offsets</code> 的分区数数量，默认值为 <code>50</code>。</td></tr><tr><td><code>heartbeat.interval.ms</code></td><td>消费者向 Broker（Coordinator）发送心跳的时间间隔，该参数的值必须小于 <code>session.timeout.ms</code>，也不应该高于 <code>session.timeout.ms</code> 的 1/3，默认值为 <code>3秒</code>。</td></tr><tr><td><code>session.timeout.ms</code></td><td>消费者与 Broker（Coordinator）之间心跳超时的阈值，如果消费者在该时间内未向 Broker（Coordinator） 发送心跳，则会被认为消费者已失效，其分区会被重新分配给组内的其他消费者（即触发分区再平衡），默认值为 <code>45秒</code>。</td></tr><tr><td><code>max.poll.interval.ms</code></td><td>消费者处理消息的最长时间，如果消费者在该时间内未处理完消息（即未调用 <code>poll()</code> 方法），则会被认为消费者已失效，其分区会被重新分配给组内的其他消费者（即触发分区再平衡），默认值为 <code>5分钟</code>。</td></tr><tr><td><code>fetch.min.bytes</code></td><td>消费者获取服务器端一批消息的最小字节数，默认值为 <code>1字节</code>。</td></tr><tr><td><code>fetch.max.wait.ms</code></td><td>如果消费者没有从服务器端获取到一批消息的最小字节数，等过了该参数指定的等待时间，仍然会去服务器端拉取消息，默认值为 <code>500 毫秒</code>。</td></tr><tr><td><code>fetch.max.bytes</code></td><td>消费者获取服务器端一批消息的最大字节数，默认值为 <code>50M</code>。如果服务器端一批次的消息大于该值，仍然可以将这批消息拉取回来，所以这不是一个绝对最大值。消费者拉取一批次消息的大小受 <code>message.max.bytes</code>（Broker 配置）或者 <code>max.message.bytes</code>（Topic 配置）影响。</td></tr><tr><td><code>max.poll.records</code></td><td>消费者每次调用 <code>poll()</code> 方法时，最多能拉取的消息数量，默认值为 <code>500</code>。</td></tr></tbody></table><h2 id="Kafka-消费者的使用"><a href="#Kafka-消费者的使用" class="headerlink" title="Kafka 消费者的使用"></a>Kafka 消费者的使用</h2><h3 id="消费一个主题"><a href="#消费一个主题" class="headerlink" title="消费一个主题"></a>消费一个主题</h3><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-08</code>。</p></div><ul><li>案例目标：创建一个独立消费者，消费 <code>first</code> 主题中数据</li></ul><p><img data-src="../../../asset/2024/11/kafka-consumer-7.png"></p><ul><li> Java 代码（消费者）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题（可以订阅消费多个主题）</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>测试代码</li></ul><p>第一步：启动 Kafa 的命令行生产者，并手动往 <code>first</code> 主题发送消息</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./kafka-console-producer.sh --topic first --broker-list 127.0.0.1:9092</span><br></pre></td></tr></tbody></table></figure><p>第二步：在 IDE 工具中执行消费者的代码，观察控制台中是否打印接收到的消息，如下所示：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 11, CreateTime = 1732780407396, serialized key size = -1, serialized value size = 12, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hello kafka1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 12, CreateTime = 1732780413888, serialized key size = -1, serialized value size = 12, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hello kafka2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 13, CreateTime = 1732780417120, serialized key size = -1, serialized value size = 12, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hello kafka3)</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><p>在消费者 API 代码中必须配置消费者组 ID，即使只有一个消费者存在。在使用命令行启动消费者时，之所以不用专门为该消费者设置 <code>groupid</code>，这是因为 Kafka 默认给该消费者设置了一个随机的 <code>groupid</code>。</p></div><h3 id="消费一个分区"><a href="#消费一个分区" class="headerlink" title="消费一个分区"></a>消费一个分区</h3><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-09</code>。</p></div><ul><li>案例目标：创建一个独立消费者，消费 <code>first</code> 主题 <code>0</code> 号分区的数据</li></ul><p><img data-src="../../../asset/2024/11/kafka-consumer-8.png"></p><ul><li> Java 代码（消费者）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 消费某个主题的某个分区数据</span></span><br><span class="line">        List&lt;TopicPartition&gt; topicPartitions = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topicPartitions.add(<span class="keyword">new</span> TopicPartition(<span class="string">"first"</span>, <span class="number">0</span>));</span><br><span class="line">        consumer.assign(topicPartitions);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>测试代码</li></ul><p>第一步：执行以下的生产者代码，创建一个生产者往 <code>first</code> 主题的 <code>0</code> 号分区发送消息</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerProducer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定序列化器（必须）</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) {</span><br><span class="line">            <span class="comment">// 往某个主题的某个分区异步发送消息</span></span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"first"</span>, <span class="number">0</span>, <span class="string">""</span>, <span class="string">"hello kafka "</span> + i));</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 关闭资源</span></span><br><span class="line">        producer.close();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>第二步：在 IDE 工具中执行消费者的代码，观察控制台中是否打印接收到的消息，如下所示：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 14, CreateTime = 1732779753896, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 15, CreateTime = 1732779753922, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 16, CreateTime = 1732779753922, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br></pre></td></tr></tbody></table></figure><h3 id="消费者组消费多个分区"><a href="#消费者组消费多个分区" class="headerlink" title="消费者组消费多个分区"></a>消费者组消费多个分区</h3><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-10</code>。</p></div><ul><li>案例目标：消费者组内每个消费者负责消费 <code>first</code> 主题的不同分区的数据，一个分区只能由一个组内消费者消费</li></ul><p><img data-src="../../../asset/2024/11/kafka-consumer-9.png"></p><ul><li><code>first</code> 主题的分区信息</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Topic: first	TopicId: bvg8QtrBR6yX6kO_pmbp2A	PartitionCount: 2	ReplicationFactor: 2	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first	Partition: 0	Leader: 1    Replicas: 1,0    Isr: 1,0</span><br><span class="line">Topic: first	Partition: 1	Leader: 0    Replicas: 0,2    Isr: 0,2</span><br></pre></td></tr></tbody></table></figure><ul><li>Java 代码（消费者一）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer1</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>Java 代码（消费者二）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer1</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>测试代码</li></ul><p>第一步：在 IDE 工具中执行上面的消费者代码，分别启动同一个消费者组中的两个消费者</p><p>第一步：执行以下的生产者代码，创建一个生产者往 <code>first</code> 主题的两个分区发送消息</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerProducer2</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定序列化器（必须）</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200</span>; i++) {</span><br><span class="line">            <span class="comment">// 分区号（假设只有两个分区）</span></span><br><span class="line">            <span class="keyword">int</span> partition = i % <span class="number">2</span>;</span><br><span class="line">            <span class="comment">// 异步发送消息（带回调函数）</span></span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"first"</span>, partition, <span class="string">""</span>, <span class="string">"hello kafka "</span> + i), <span class="keyword">new</span> Callback() {</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception exception)</span> </span>{</span><br><span class="line">                    <span class="keyword">if</span> (exception != <span class="keyword">null</span>) {</span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    } <span class="keyword">else</span> {</span><br><span class="line">                        System.out.println(<span class="string">"topic: "</span> + recordMetadata.topic() + <span class="string">", partition: "</span> + recordMetadata.partition());</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            });</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 关闭资源</span></span><br><span class="line">        producer.close();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>第三步：在 IDE 工具控制台中，会输出以下日志信息，可以看到两个消费者各自消费不同分区的消息，也就是说同一个分区不会被组内两个消费者同时消费</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 100, CreateTime = 1732797538636, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 101, CreateTime = 1732797538664, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 102, CreateTime = 1732797538665, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 0, offset = 100, CreateTime = 1732797538663, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 0, offset = 101, CreateTime = 1732797538664, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 0, offset = 102, CreateTime = 1732797538665, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br></pre></td></tr></tbody></table></figure><h2 id="Kafka-消费者组的使用"><a href="#Kafka-消费者组的使用" class="headerlink" title="Kafka 消费者组的使用"></a>Kafka 消费者组的使用</h2><h3 id="分区再平衡的概念"><a href="#分区再平衡的概念" class="headerlink" title="分区再平衡的概念"></a>分区再平衡的概念</h3><blockquote><p>分区再平衡的介绍</p></blockquote><p>Kafka 消费者的分区再平衡（Partition Rebalancing）是指当消费者组中的成员发生变更时（如消费者加入、退出或故障），Kafka 自动调整分区与消费者之间的映射关系，以确保所有分区都会被消费者组中的成员消费。分区再平衡的关键点如下：</p><ul><li><p>触发条件：</p><ul><li>新消费者加入消费者组。</li><li>消费者退出消费者组（主动离开或因宕机）。</li><li>订阅的主题数量或分区数量发生变化。</li></ul></li><li><p>再平衡过程：</p><ul><li>Kafka 的消费者组协调器（Group Coordinator）负责管理消费者组。</li><li>当组成员发生变动时，协调器会触发再平衡过程，停止当前消费者对分区的消费。</li><li>再平衡完成后，分区会重新分配给消费者组中的成员，消费恢复。</li></ul></li><li><p>分区分配策略：</p><ul><li>Kafka 默认提供了四大分区分配策略：<ul><li>Range 分配策略：将分区按主题划分范围，尽量连续分配给消费者，可能导致分区分配不均。</li><li>RoundRobin 分配策略：以轮询方式将分区均匀分配给消费者，适合分区数量与消费者数量差距较大的场景。</li><li>Sticky 分配策略：在尽量保持当前分配不变的前提下均衡分区，减少分区切换，降低再平衡开销。</li><li>CooperativeSticky 分配策略：在减少分区重新分配的基础上，通过渐进式再平衡机制最小化消费中断，只调整必要的分区分配。</li></ul></li><li>可通过配置 <code>partition.assignment.strategy</code> 参数来自定义分配策略。</li></ul></li><li><p>优缺点</p><ul><li>优点：<ul><li>动态调整分区分配，支持弹性扩展。</li><li>确保分区始终被有效消费。</li></ul></li><li>缺点：<ul><li>短暂中断：再平衡期间会暂停消费，导致短时间内消息未被处理。</li><li>分区切换开销：消费者需要重新建立分区的连接和状态。</li></ul></li></ul></li><li><p>优化措施：</p><ul><li>使用静态成员 ID（<code>group.instance.id</code>），减少分区再平衡的频率。</li><li>控制心跳和会话超时（<code>heartbeat.interval.ms</code> 和 <code>session.timeout.ms</code>），避免误触发分区再平衡。</li><li>通过配置参数 <code>partition.assignment.strategy</code> 来调整分区分配策略，以适应具体场景需求。</li></ul></li></ul><blockquote><p>消费者组的初始化流程</p></blockquote><p><img data-src="../../../asset/2024/11/kafka-consumer-5.png"></p><blockquote><p>分区再平衡相关的配置参数</p></blockquote><table><thead><tr><th>参数名称</th><th>参数描述</th></tr></thead><tbody><tr><td><code>heartbeat.interval.ms</code></td><td>消费者向 Broker（Coordinator）发送心跳的时间间隔，该参数的值必须小于 <code>session.timeout.ms</code>，也不应该高于 <code>session.timeout.ms</code> 的 1/3，默认值为 <code>3秒</code></td></tr><tr><td><code>session.timeout.ms</code></td><td>消费者与 Broker（Coordinator）之间心跳超时的阈值，如果消费者在该时间内未向 Broker（Coordinator） 发送心跳，则会被认为消费者已失效，其分区会被重新分配给组内的其他消费者（即触发分区再平衡），默认值为 <code>45秒</code></td></tr><tr><td><code>max.poll.interval.ms</code></td><td>消费者处理消息的最长时间，如果消费者在该时间内未处理完消息（即未调用 <code>poll()</code> 方法），则会被认为消费者已失效，其分区会被重新分配给组内的其他消费者（即触发分区再平衡），默认值为 <code>5分钟</code></td></tr><tr><td><code>partition.assignment.strategy</code></td><td>消费者的分区分配策略，默认策略是 <code>Range</code> + <code>CooperativeSticky</code>。Kafka 支持同时使用多个分区分配策略，可以选择的策略包括：<code>Range</code>、<code>RoundRobin</code>、<code>Sticky</code>、<code>CooperativeSticky</code></td></tr></tbody></table><h3 id="四大分区分配策略"><a href="#四大分区分配策略" class="headerlink" title="四大分区分配策略"></a>四大分区分配策略</h3><ul><li><p>一个消费者组由多个 Consumer 组成，一个 Topic 由多个 Partition 组成。现在的问题是，到底由哪个 Consumer 来消费哪个 Partition 的数据呢？</p></li><li><p>Kafka 提供了四种主流的分区分配策略：</p><ul><li>Kafka 的四种分区分配策略分别是：<ul><li><strong>Range</strong>：<code>org.apache.kafka.clients.consumer.RangeAssignor</code></li><li><strong>RoundRobin</strong>：<code>org.apache.kafka.clients.consumer.RoundRobinAssignor</code></li><li><strong>Sticky</strong>：<code>org.apache.kafka.clients.consumer.StickyAssignor</code></li><li><strong>CooperativeSticky</strong>：<code>org.apache.kafka.clients.consumer.CooperativeStickyAssignor</code></li></ul></li><li>Kafka 可以通过配置参数 <code>partition.assignment.strategy</code> 来修改分区的分配策略。</li><li>Kafka 默认的分区分配策略是 <code>Range</code> + <code>CooperativeSticky</code>。</li><li>Kafka 支持同时使用多个分区分配策略。</li></ul></li></ul><h3 id="Range-分区分配策略"><a href="#Range-分区分配策略" class="headerlink" title="Range 分区分配策略"></a>Range 分区分配策略</h3><h4 id="Range-策略的概述"><a href="#Range-策略的概述" class="headerlink" title="Range 策略的概述"></a>Range 策略的概述</h4><p><img data-src="../../../asset/2024/11/kafka-consumer-10.png"></p><ul><li>Range 分区分配策略是针对每个 Topic 而言的。</li><li>首先对同一个 Topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。</li><li>假如现在有 7 个分区，3 个消费者，排序后的分区将会是 <code>0,1,2,3,4,5,6</code>，消费者排序之后将会是 <code>C0,C1,C2</code>。</li><li>通过 <code>Partitions 数量 / Consumer 数量</code> 来决定每个消费者应该消费几个分区。如果除不尽，那么最前面的几个消费者将会多消费 1 个分区。</li><li>例如，<code>7 / 3 = 2</code>，余 1，除不尽，那么消费者 C0 将会多消费 1 个分区。<code>8 / 3 = 2</code>，余 2，除不尽，那么 C0 和 C1 将会分别多消费一个分区。</li><li>特别注意：如果只是针对 1 个 Topic 而言，C0 消费者多消费 1 个分区的影响并不是很大。但是，如果有 N 个 Topic，那么针对每个 Topic，消费者 C0 都将多消费 1 个分区；随着 Topic 增多，C0 消费的分区会比其他消费者多消费 N 个分区，这导致容易产生数据倾斜。</li></ul><h4 id="Range-策略的使用"><a href="#Range-策略的使用" class="headerlink" title="Range 策略的使用"></a>Range 策略的使用</h4><p>本节将创建主题 <code>first</code>，拥有 7 个分区和 3 个副本。准备 3 个消费者（同一消费组）和 1 个 生产者，采用 Range 分区分配策略并进行消费，观察分区的消费分配情况。然后，再停止其中一个消费者，再次观察分区的消费分配情况。</p><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-11</code>。</p></div><h5 id="Range-策略的案例"><a href="#Range-策略的案例" class="headerlink" title="Range 策略的案例"></a>Range 策略的案例</h5><ul><li>创建 <code>first</code> 主题，包含 7 个分区和 3 个副本</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建主题</span></span><br><span class="line">$ ./kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --topic first --partitions 7 --replication-factor 3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看主题信息</span></span><br><span class="line">$ ./kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic first</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Topic: first	TopicId: s4_N3GKgQAul_LtfVc_AoQ	PartitionCount: 7	ReplicationFactor: 3	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first	Partition: 0	Leader: 2    Replicas: 2,0,1    Isr: 2,0,1</span><br><span class="line">Topic: first	Partition: 1	Leader: 1    Replicas: 1,2,0    Isr: 1,2,0</span><br><span class="line">Topic: first	Partition: 2	Leader: 0    Replicas: 0,1,2    Isr: 0,1,2</span><br><span class="line">Topic: first	Partition: 3	Leader: 2    Replicas: 2,1,0    Isr: 2,1,0</span><br><span class="line">Topic: first	Partition: 4	Leader: 1    Replicas: 1,0,2    Isr: 1,0,2</span><br><span class="line">Topic: first	Partition: 5	Leader: 0    Replicas: 0,2,1    Isr: 0,2,1</span><br><span class="line">Topic: first	Partition: 6	Leader: 2    Replicas: 2,0,1    Isr: 2,0,1</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者一）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer1</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者二）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer2</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者三）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer3</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><div class="admonition note"><p class="admonition-title">提示</p><p>由于 Kafka 默认的分区分配策略就是 <code>Range</code> + <code>CooperativeSticky</code>，所以在消费者的代码中不需要指定分区分配策略。</p></div><ul><li>测试代码</li></ul><p>第一步：在 IDE 工具中执行上面的消费者代码，分别启动同一个消费者组中的三个消费者</p><p>第二步：执行以下的生产者代码，创建一个生产者往 <code>first</code> 主题的 7 个分区发送消息</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerProducer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定序列化器（必须）</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">7</span>; i++) {</span><br><span class="line">            <span class="comment">// 异步发送消息（带回调函数）</span></span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"first"</span>, i, <span class="string">""</span>, <span class="string">"hello kafka "</span> + i), <span class="keyword">new</span> Callback() {</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception exception)</span> </span>{</span><br><span class="line">                    <span class="keyword">if</span> (exception != <span class="keyword">null</span>) {</span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    } <span class="keyword">else</span> {</span><br><span class="line">                        System.out.println(<span class="string">"topic: "</span> + recordMetadata.topic() + <span class="string">", partition: "</span> + recordMetadata.partition());</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            });</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 关闭资源</span></span><br><span class="line">        producer.close();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>第三步：在 IDE 工具控制台中，会输出以下日志信息，可以看到三个消费者各自消费不同分区（两个）的消息，而且其中一个消费者（Leader） 会多消费一个分区，如下所示：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 2, CreateTime = 1732855355141, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 0, offset = 2, CreateTime = 1732855355164, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 0, offset = 2, CreateTime = 1732855355165, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 0, offset = 2, CreateTime = 1732855355165, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 0, offset = 2, CreateTime = 1732855355165, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 0, offset = 2, CreateTime = 1732855355165, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 0, offset = 2, CreateTime = 1732855355165, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><h5 id="Range-分区再平衡的案例"><a href="#Range-分区再平衡的案例" class="headerlink" title="Range 分区再平衡的案例"></a>Range 分区再平衡的案例</h5><ul><li>第一步：执行完上述案例代码的测试步骤后，首先停止消费者一的运行，然后快速（必须是 45 秒内，因为此时消费者一还没有被踢出消费者组）再次执行生产者的代码往 7 个分区发送消息；等待 45 秒后，会发现原本由消费者一负责消费的分区，会<strong>整体重新分配</strong>给消费者二或者消费者三继续消费（如下所示）。</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 4, CreateTime = 1732856785264, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 0, offset = 4, CreateTime = 1732856785285, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 0, offset = 4, CreateTime = 1732856785285, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 0, offset = 4, CreateTime = 1732856785286, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 0, offset = 4, CreateTime = 1732856785286, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 0, offset = 4, CreateTime = 1732856785286, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 0, offset = 4, CreateTime = 1732856785286, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><ul><li>第二步：从上面输出的日志信息可以看到，消费者一挂掉后，消费者组需要根据心跳超时时间（45 秒）来判断消费者一是否退出，所以需要等待一段时间；等时间到了 45 秒后，判断消费者一真的退出了，就会将原本由消费者一负责消费的分区<strong>整体重新分配</strong>给组内的某个消费者来消费。</li></ul><hr><ul><li>第三步：等时间过了 45 秒后，再次执行生产者的代码往 7 个分区发送消息；由于消费者一已经被踢出消费者组，即消费者组内只剩下两个消费者了，此时分区会重新按照 Range 分配策略分配给组内剩下的两个消费者，如下所示：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 0, offset = 5, CreateTime = 1732858089294, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 0, offset = 5, CreateTime = 1732858089317, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 0, offset = 5, CreateTime = 1732858089318, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 0, offset = 5, CreateTime = 1732858089318, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 0, offset = 5, CreateTime = 1732858089319, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 0, offset = 5, CreateTime = 1732858089319, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 0, offset = 5, CreateTime = 1732858089320, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><h3 id="RoundRobin-分区分配策略"><a href="#RoundRobin-分区分配策略" class="headerlink" title="RoundRobin 分区分配策略"></a>RoundRobin 分区分配策略</h3><h4 id="RoundRobin-策略的概述"><a href="#RoundRobin-策略的概述" class="headerlink" title="RoundRobin 策略的概述"></a>RoundRobin 策略的概述</h4><p><img data-src="../../../asset/2024/11/kafka-consumer-11.png"></p><ul><li>RoundRobin 分区分配策略是针对集群中所有 Topic 而言。</li><li>RoundRobin 轮询分区策略，是将所有的 Partition 和所有的 Consumer 都列出来，然后按照对应的 HashCode 进行排序，最后通过轮询算法来将 Partition 分配给各个 Consumer。</li></ul><h4 id="RoundRobin-策略的使用"><a href="#RoundRobin-策略的使用" class="headerlink" title="RoundRobin 策略的使用"></a>RoundRobin 策略的使用</h4><p>本节将创建主题 <code>first</code>，拥有 7 个分区和 3 个副本。准备 3 个消费者（同一消费组）和 1 个 生产者，采用 RoundRobin 分区分配策略并进行消费，观察分区的消费分配情况。然后，再停止其中一个消费者，再次观察分区的消费分配情况。</p><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-12</code>。</p></div><h5 id="RoundRobin-策略的案例"><a href="#RoundRobin-策略的案例" class="headerlink" title="RoundRobin 策略的案例"></a>RoundRobin 策略的案例</h5><ul><li>创建 <code>first</code> 主题，包含 7 个分区和 3 个副本</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建主题</span></span><br><span class="line">$ ./kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --topic first --partitions 7 --replication-factor 3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看主题信息</span></span><br><span class="line">$ ./kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic first</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Topic: first	TopicId: s4_N3GKgQAul_LtfVc_AoQ	PartitionCount: 7	ReplicationFactor: 3	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first	Partition: 0	Leader: 2    Replicas: 2,0,1    Isr: 2,0,1</span><br><span class="line">Topic: first	Partition: 1	Leader: 1    Replicas: 1,2,0    Isr: 1,2,0</span><br><span class="line">Topic: first	Partition: 2	Leader: 0    Replicas: 0,1,2    Isr: 0,1,2</span><br><span class="line">Topic: first	Partition: 3	Leader: 2    Replicas: 2,1,0    Isr: 2,1,0</span><br><span class="line">Topic: first	Partition: 4	Leader: 1    Replicas: 1,0,2    Isr: 1,0,2</span><br><span class="line">Topic: first	Partition: 5	Leader: 0    Replicas: 0,2,1    Isr: 0,2,1</span><br><span class="line">Topic: first	Partition: 6	Leader: 2    Replicas: 2,0,1    Isr: 2,0,1</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者一）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer1</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test2"</span>);</span><br><span class="line">        <span class="comment">// 指定消费者组的分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">"org.apache.kafka.clients.consumer.RoundRobinAssignor"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者二）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer2</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test2"</span>);</span><br><span class="line">        <span class="comment">// 指定消费者组的分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">"org.apache.kafka.clients.consumer.RoundRobinAssignor"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者三）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer3</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test2"</span>);</span><br><span class="line">        <span class="comment">// 指定消费者组的分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">"org.apache.kafka.clients.consumer.RoundRobinAssignor"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>测试代码</li></ul><p>第一步：在 IDE 工具中执行上面的消费者代码，分别启动同一个消费者组中的三个消费者</p><p>第二步：执行以下的生产者代码，创建一个生产者往 <code>first</code> 主题的 7 个分区发送消息</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerProducer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定序列化器（必须）</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">7</span>; i++) {</span><br><span class="line">            <span class="comment">// 异步发送消息（带回调函数）</span></span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"first"</span>, i, <span class="string">""</span>, <span class="string">"hello kafka "</span> + i), <span class="keyword">new</span> Callback() {</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception exception)</span> </span>{</span><br><span class="line">                    <span class="keyword">if</span> (exception != <span class="keyword">null</span>) {</span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    } <span class="keyword">else</span> {</span><br><span class="line">                        System.out.println(<span class="string">"topic: "</span> + recordMetadata.topic() + <span class="string">", partition: "</span> + recordMetadata.partition());</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            });</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 关闭资源</span></span><br><span class="line">        producer.close();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>第三步：在 IDE 工具控制台中，会输出以下日志信息，可以看到三个消费者各自消费不同分区的消息，如下所示：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 8, offset = 9, CreateTime = 1732934991668, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 8, offset = 9, CreateTime = 1732934991689, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 8, offset = 9, CreateTime = 1732934991690, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 6, offset = 9, CreateTime = 1732934991689, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 6, offset = 9, CreateTime = 1732934991690, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 6, offset = 9, CreateTime = 1732934991689, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 6, offset = 9, CreateTime = 1732934991690, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br></pre></td></tr></tbody></table></figure><h5 id="RoundRobin-分区再平衡的案例"><a href="#RoundRobin-分区再平衡的案例" class="headerlink" title="RoundRobin 分区再平衡的案例"></a>RoundRobin 分区再平衡的案例</h5><ul><li>第一步：执行完上述案例代码的测试步骤后，首先停止消费者一的运行，然后快速（必须是 45 秒内，因为此时消费者一还没有被踢出消费者组）再次执行生产者的代码往 7 个分区发送消息；等待 45 秒后，发现原本由消费者一负责消费的分区，会按照 <strong>RoundRobin 轮询</strong>的方式，将分区轮询分成 0 、6 和 3 号分区，然后分配给消费者二和消费者三继续消费。</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 6, offset = 12, CreateTime = 1732936140359, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 6, offset = 12, CreateTime = 1732936140360, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 8, offset = 12, CreateTime = 1732936140337, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 8, offset = 12, CreateTime = 1732936140360, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 6, offset = 12, CreateTime = 1732936140359, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 6, offset = 12, CreateTime = 1732936140360, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 8, offset = 12, CreateTime = 1732936140360, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br></pre></td></tr></tbody></table></figure><ul><li>第二步：从上面输出的日志信息可以看到，消费者一挂掉后，消费者组需要根据心跳超时时间（45 秒）来判断消费者一是否退出，所以需要等待一段时间；等时间到了 45 秒后，判断消费者一真的退出了，就会将原本由消费者一负责消费的分区按照 <strong>RoundRobin 轮询</strong>的方式重新分配给组内的所有消费者继续消费。</li></ul><hr><ul><li>第三步：等时间过了 45 秒后，再次执行生产者的代码往 7 个分区发送消息；由于消费者一已经被踢出消费者组，即消费者组内只剩下两个消费者了，此时分区会重新按照 RoundRobin 分配策略分配给组内剩下的两个消费者，如下所示：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 8, offset = 13, CreateTime = 1732936983383, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 6, offset = 13, CreateTime = 1732936983406, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 6, offset = 13, CreateTime = 1732936983407, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 8, offset = 13, CreateTime = 1732936983407, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 6, offset = 13, CreateTime = 1732936983405, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 8, offset = 13, CreateTime = 1732936983406, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 6, offset = 13, CreateTime = 1732936983407, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br></pre></td></tr></tbody></table></figure><h3 id="Sticky-分区分配策略"><a href="#Sticky-分区分配策略" class="headerlink" title="Sticky 分区分配策略"></a>Sticky 分区分配策略</h3><h4 id="Sticky-策略的概述"><a href="#Sticky-策略的概述" class="headerlink" title="Sticky 策略的概述"></a>Sticky 策略的概述</h4><ul><li>粘性分区定义：可以理解为分区分配的结果带有 “粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽可能少地调整分区分配的变动，这样可以节省大量的开销。</li><li>Kafka 从 <code>0.11.x</code> 版本开始引入 Sticky 分区分配策略，首先会尽可能均衡地随机分配分区给消费者；在同一消费者组内，当消费者出现宕机并被踢出消费者组的时候，会尽量保持原有分配的分区不变动。</li><li><strong>值得注意的是，采用 Sticky 分区分配策略后，在执行第一次分区分配（之前没有执行过分区分配）时，默认是随机分配分区的。</strong></li></ul><h4 id="Sticky-策略的使用"><a href="#Sticky-策略的使用" class="headerlink" title="Sticky 策略的使用"></a>Sticky 策略的使用</h4><p>本节将创建主题 <code>first</code>，拥有 7 个分区和 3 个副本。准备 3 个消费者（同一消费组）和 1 个 生产者，采用 Sticky 分区分配策略并进行消费，观察分区的消费分配情况。然后，再停止其中一个消费者，再次观察分区的消费分配情况。</p><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-13</code>。</p></div><h5 id="Sticky-策略的案例"><a href="#Sticky-策略的案例" class="headerlink" title="Sticky 策略的案例"></a>Sticky 策略的案例</h5><ul><li>创建 <code>first</code> 主题，包含 7 个分区和 3 个副本</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建主题</span></span><br><span class="line">$ ./kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --topic first --partitions 7 --replication-factor 3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看主题信息</span></span><br><span class="line">$ ./kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic first</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Topic: first	TopicId: s4_N3GKgQAul_LtfVc_AoQ	PartitionCount: 7	ReplicationFactor: 3	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first	Partition: 0	Leader: 2    Replicas: 2,0,1    Isr: 2,0,1</span><br><span class="line">Topic: first	Partition: 1	Leader: 1    Replicas: 1,2,0    Isr: 1,2,0</span><br><span class="line">Topic: first	Partition: 2	Leader: 0    Replicas: 0,1,2    Isr: 0,1,2</span><br><span class="line">Topic: first	Partition: 3	Leader: 2    Replicas: 2,1,0    Isr: 2,1,0</span><br><span class="line">Topic: first	Partition: 4	Leader: 1    Replicas: 1,0,2    Isr: 1,0,2</span><br><span class="line">Topic: first	Partition: 5	Leader: 0    Replicas: 0,2,1    Isr: 0,2,1</span><br><span class="line">Topic: first	Partition: 6	Leader: 2    Replicas: 2,0,1    Isr: 2,0,1</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者一）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer1</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test3"</span>);</span><br><span class="line">        <span class="comment">// 指定消费者组的分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">"org.apache.kafka.clients.consumer.StickyAssignor"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者二）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer2</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test3"</span>);</span><br><span class="line">        <span class="comment">// 指定消费者组的分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">"org.apache.kafka.clients.consumer.StickyAssignor"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>Java（消费者三）</li></ul><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer3</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test3"</span>);</span><br><span class="line">        <span class="comment">// 指定消费者组的分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">"org.apache.kafka.clients.consumer.StickyAssignor"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ul><li>测试代码</li></ul><p>第一步：在 IDE 工具中执行上面的消费者代码，分别启动同一个消费者组中的三个消费者</p><p>第二步：执行以下的生产者代码，创建一个生产者往 <code>first</code> 主题的 7 个分区发送消息</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerProducer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定序列化器（必须）</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">7</span>; i++) {</span><br><span class="line">            <span class="comment">// 异步发送消息（带回调函数）</span></span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"first"</span>, i, <span class="string">""</span>, <span class="string">"hello kafka "</span> + i), <span class="keyword">new</span> Callback() {</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception exception)</span> </span>{</span><br><span class="line">                    <span class="keyword">if</span> (exception != <span class="keyword">null</span>) {</span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    } <span class="keyword">else</span> {</span><br><span class="line">                        System.out.println(<span class="string">"topic: "</span> + recordMetadata.topic() + <span class="string">", partition: "</span> + recordMetadata.partition());</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            });</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 关闭资源</span></span><br><span class="line">        producer.close();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>第三步：在 IDE 工具控制台中，会输出以下日志信息，可以看到三个消费者各自消费不同分区的消息，如下所示：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 8, offset = 16, CreateTime = 1732939292544, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 8, offset = 16, CreateTime = 1732939292570, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 8, offset = 16, CreateTime = 1732939292571, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 6, offset = 16, CreateTime = 1732939292569, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 6, offset = 16, CreateTime = 1732939292570, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 6, offset = 16, CreateTime = 1732939292570, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 6, offset = 16, CreateTime = 1732939292571, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br></pre></td></tr></tbody></table></figure><h5 id="Sticky-分区再平衡的案例"><a href="#Sticky-分区再平衡的案例" class="headerlink" title="Sticky 分区再平衡的案例"></a>Sticky 分区再平衡的案例</h5><ul><li>第一步：执行完上述案例代码的测试步骤后，首先停止消费者一的运行，然后快速（必须是 45 秒内，因为此时消费者一还没有被踢出消费者组）再次执行生产者的代码往 7 个分区发送消息；等待 45 秒后，发现原本由消费者一负责消费的分区，会尽可能均衡地随机分成 0、3、6 号分区，然后<strong>随机</strong>分配给消费者二和消费者三继续消费。</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 6, offset = 17, CreateTime = 1732940272374, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 6, offset = 17, CreateTime = 1732940272375, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 8, offset = 17, CreateTime = 1732940272351, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 8, offset = 17, CreateTime = 1732940272381, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 6, offset = 17, CreateTime = 1732940272375, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 6, offset = 17, CreateTime = 1732940272375, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 8, offset = 17, CreateTime = 1732940272375, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br></pre></td></tr></tbody></table></figure><ul><li>第二步：从上面输出的日志信息可以看到，消费者一挂掉后，消费者组需要根据心跳超时时间（45 秒）来判断消费者一是否退出，所以需要等待一段时间；等时间到了 45 秒后，判断消费者一真的退出了，就会将原本由消费者一负责消费的分区尽可能均衡地<strong>随机</strong>重新分配给组内的所有消费者继续消费。</li></ul><hr><ul><li>第三步：等时间过了 45 秒后，再次执行生产者的代码往 7 个分区发送消息；由于消费者一已经被踢出消费者组，即消费者组内只剩下两个消费者了，此时分区会重新按照 Sticky 分配策略分配给组内剩下的两个消费者，如下所示：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 8, offset = 18, CreateTime = 1732940641037, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 6, offset = 18, CreateTime = 1732940641059, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 4, leaderEpoch = 6, offset = 18, CreateTime = 1732940641060, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 4)</span><br><span class="line">ConsumerRecord(topic = first, partition = 6, leaderEpoch = 8, offset = 18, CreateTime = 1732940641061, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 6)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 2, leaderEpoch = 6, offset = 18, CreateTime = 1732940641060, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 3, leaderEpoch = 8, offset = 18, CreateTime = 1732940641060, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 5, leaderEpoch = 6, offset = 18, CreateTime = 1732940641060, serialized key size = 0, serialized value size = 13, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hello kafka 5)</span><br></pre></td></tr></tbody></table></figure><h2 id="Kafaka-消费者的-offset"><a href="#Kafaka-消费者的-offset" class="headerlink" title="Kafaka 消费者的 offset"></a>Kafaka 消费者的 offset</h2><h3 id="offset-的默认存储位置"><a href="#offset-的默认存储位置" class="headerlink" title="offset 的默认存储位置"></a>offset 的默认存储位置</h3><p><img data-src="../../../asset/2024/11/kafka-consumer-12.png"></p><p>值得注意的是，在 Kafka 的不同版本中，存储消费者的 offset 的地方是不一样的：</p><ul><li><p>Kafka 旧版本（<code>0.9.0</code> 及以前）</p><ul><li>存储方式：<ul><li>消费者的 offset 信息存储在 Zookeeper 中。</li></ul></li><li>存储特点：<ul><li>每个消费者组都会在 Zookeeper 中维护其消费的 offset 信息。</li><li>Zookeeper 主要负责集群的元数据管理，频繁地写入 offset 数据会导致 Zookeeper 的性能问题，尤其是在高吞吐量场景下。</li><li>存储偏移时，Zookeeper 会受到延迟和负载的影响，扩展性较差。</li></ul></li></ul></li><li><p>Kafka 新版本（<code>0.10.0</code> 及以后）</p><ul><li>存储方式：<ul><li>消费者的 offset 信息存储在 Kafka 的内置主题 <code>__consumer_offsets</code> 中，该主题默认拥有 50 个分区。</li></ul></li><li>存储特点：<ul><li>在 Kafka 内置主题 <code>__consumer_offsets</code> 里面，采用键值对的方式存储数据。其中 Key 是 <code>GroupId + Topic + 分区号</code>，而 Value 就是当前 <code>offset</code> 的值。每隔一段时间，Kafka 内部会对这个内置 Topic 进行压缩（Compact），也就是针对每个 <code>GroupId + Topic + 分区号</code> 只保留最新的数据。</li><li>Kafka 内置的 <code>__consumer_offsets</code> 是一个特殊的主题，用于存储消费者组的 offset 信息。这个主题支持分区和副本，提供了更高的可靠性和扩展性。</li><li>Kafka 的 Broker 可以高效地管理 offset 的存储和读取，减轻了 Zookeeper 的压力。</li><li>支持更细粒度的控制，例如自动提交（<code>auto.commit</code>）或手动提交 offset。</li><li>提高了整体性能，尤其是在高吞吐场景下，消费者提交 offset 的操作不会影响整个集群的性能。</li></ul></li></ul></li></ul><blockquote><p>在 Kafka 中，offset 相关的参数如下：</p></blockquote><table><thead><tr><th>参数名称</th><th>参数描述</th></tr></thead><tbody><tr><td><code>enable.auto.commit</code></td><td>是否开启自动提交 offset 功能，默认值是 <code>true</code>。开启后，消费者会自动周期性地向 Kafka 服务器提交 offset。</td></tr><tr><td><code>auto.commit.interval.ms</code></td><td>如果设置了 <code>enable.auto.commit</code> 的值为 <code>true</code>，则该参数定义了消费者自动提交 offset 的时间间隔（频率），默认值是 <code>5 秒</code>。</td></tr><tr><td><code>offsets.retention.minutes</code></td><td>Kafka 中内置主题 <code>__consumer_offsets</code> 存储 offset 的保留时间，默认值是 <code>24 小时</code>。具体来说，当一个消费者组的 offset 变为无效（例如消费者组停止消费或从未重新平衡中恢复），Kafka 会在超过这个时间后清理该组的 offset。</td></tr></tbody></table><h3 id="消费-offset-的案例"><a href="#消费-offset-的案例" class="headerlink" title="消费 offset 的案例"></a>消费 offset 的案例</h3><div class="admonition note"><p class="admonition-title">提示</p><p>因为 <code>__consumer_offsets</code> 是 Kafka 的内置主题，所以可以通过消费者对该主题进行消费。</p></div><ul><li>(1) 在 Kafka 的配置文件 <code>config/consumer.properties</code> 中添加配置参数 <code>exclude.internal.topics</code>，默认值是 <code>true</code>，即表示不能消费 Kafka 的内置主题。为了查看该内置主题的数据，需要将该参数修改为 <code>false</code>。</li></ul><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">exclude.internal.topics</span>=<span class="string">false</span></span><br></pre></td></tr></tbody></table></figure><ul><li>(2) 采用命令行的方式，创建新主题 <code>test</code></li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --create --topic <span class="built_in">test</span> --partitions 3 --replication-factor 3</span><br></pre></td></tr></tbody></table></figure><ul><li>(3) 启动命令行生产者往 <code>test</code> 主题发送多条消息</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic <span class="built_in">test</span></span><br></pre></td></tr></tbody></table></figure><ul><li>(4) 启动命令行消费者消费 <code>test</code> 主题，同时指定消费者组的 ID，这是为了可以更好地观察 offset 的存储状况</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic <span class="built_in">test</span> --group mygroup</span><br></pre></td></tr></tbody></table></figure><ul><li>(5) 启动命令行消费者消费内置主题 <code>__consumer_offsets</code>，这样就可以查看内置主题 <code>__consumer_offsets</code> 的数据</li></ul><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@node02 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --consumer.config ../config/consumer.properties --formatter <span class="string">"kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter"</span> --topic __consumer_offsets --from-beginning</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[mygroup,test,1]::OffsetAndMetadata(offset=1, leaderEpoch=Optional[0], metadata=, commitTimestamp=1732965368784, expireTimestamp=None)</span><br><span class="line">[mygroup,test,0]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1732965368784, expireTimestamp=None)</span><br><span class="line">[mygroup,test,2]::OffsetAndMetadata(offset=1, leaderEpoch=Optional[0], metadata=, commitTimestamp=1732965368784, expireTimestamp=None)</span><br></pre></td></tr></tbody></table></figure><p>其中的 <code>[mygroup,test,2]</code> 是 Key，分别对应 <code>GroupId + Topic + 分区号</code>。</p><h3 id="自动提交-offset"><a href="#自动提交-offset" class="headerlink" title="自动提交 offset"></a>自动提交 offset</h3><h4 id="自动提交-offset-的概述"><a href="#自动提交-offset-的概述" class="headerlink" title="自动提交 offset 的概述"></a>自动提交 offset 的概述</h4><p>为了让开发者能够专注于业务逻辑的开发，Kafka 提供了消费者自动提交 offset 的功能，如下图所示：</p><p><img data-src="../../../asset/2024/11/kafka-consumer-13.png"></p><p>消费者自动提交 offset 的相关参数如下：</p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td><code>enable.auto.commit</code></td><td>是否开启自动提交 offset 功能，默认值是 <code>true</code>。开启后，消费者会自动周期性地向 Kafka 服务器提交 offset。</td></tr><tr><td><code>auto.commit.interval.ms</code></td><td>如果设置了 <code>enable.auto.commit</code> 的值为 <code>true</code>，则该参数定义了消费者自动提交 offset 的时间间隔（频率），默认值是 <code>5 秒</code>。</td></tr></tbody></table><h4 id="自动提交-offset-的案例"><a href="#自动提交-offset-的案例" class="headerlink" title="自动提交 offset 的案例"></a>自动提交 offset 的案例</h4><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-14</code>。</p></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line">        <span class="comment">// 是否自动提交 offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// 指定自动提交 offset 的时间间隔，默认值是 5 秒</span></span><br><span class="line">        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="手动提交-offset"><a href="#手动提交-offset" class="headerlink" title="手动提交 offset"></a>手动提交 offset</h3><h4 id="手动提交-offset-的概述"><a href="#手动提交-offset-的概述" class="headerlink" title="手动提交 offset 的概述"></a>手动提交 offset 的概述</h4><p><img data-src="../../../asset/2024/11/kafka-consumer-14.png"></p><ul><li>虽然自动提交 offset 十分简单便利，但由于其是基于时间提交的，开发人员难以把握 offset 提交的时机。因此，Kafka 还提供了手动提交 offset 的 API。</li><li>Kafka 手动提交 offset 有以下两种方式：<ul><li><code>commitSync（同步提交）</code>：必须阻塞等待 offset 提交完毕，再去消费下一批数据。</li><li><code>commitAsync（异步提交）</code>：发送完提交 offset 的请求后，就可以立刻消费下一批数据了。</li><li>两者的相同点是，都会将本次提交的一批数据的最高偏移量（offset）提交。</li><li>两者的不同点是，同步提交会阻塞当前线程，直到提交成功为止，并且会自动失败重试（由于诸多不可控因素导致，也可能会出现提交失败的情况）； 而异步提交则没有失败重试机制，因此有可能提交失败。</li></ul></li></ul><h4 id="手动提交-offset-的使用"><a href="#手动提交-offset-的使用" class="headerlink" title="手动提交 offset 的使用"></a>手动提交 offset 的使用</h4><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-15</code>。</p></div><h5 id="同步提交-offset-的案例"><a href="#同步提交-offset-的案例" class="headerlink" title="同步提交 offset 的案例"></a>同步提交 offset 的案例</h5><p>由于同步提交 offset 有失败重试机制，因此更加可靠；但是，需要一直阻塞等待提交的结果，这也导致了提交效率比较低。以下为同步提交 offset 的案例：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line">        <span class="comment">// 关闭自动提交 offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">            <span class="comment">// 同步提交 offset（会阻塞当前线程，并且有失败重试机制）</span></span><br><span class="line">            consumer.commitSync();</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h5 id="异步提交-offset-的案例"><a href="#异步提交-offset-的案例" class="headerlink" title="异步提交 offset 的案例"></a>异步提交 offset 的案例</h5><p>虽然同步提交 offset 有失败重试机制，更可靠一些，但是由于其会阻塞当前线程，直到 offset 提交成功。因此，吞吐量会受到很大的影响。在通常的情况下，更多会选用异步提交 offset 的方式。</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test"</span>);</span><br><span class="line">        <span class="comment">// 关闭自动提交 offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">            <span class="comment">// 异步提交 offset（不会阻塞当前线程，没有失败重试机制）</span></span><br><span class="line">            consumer.commitAsync();</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="消费者指定-offset-消费"><a href="#消费者指定-offset-消费" class="headerlink" title="消费者指定 offset 消费"></a>消费者指定 offset 消费</h3><blockquote><p>消费者指定 offset 消费的概述</p></blockquote><p>当 Kafka 中没有初始偏移量（消费者组第一次消费）或者服务器上不再存在当前偏移量时（例如该数据已被删除），该怎么办呢？Kafka 为此提供了 <code>auto.offset.reset</code> 配置参数，该参数的值有三种类型：</p><ul><li>(1) <code>earliest</code>：自动将偏移量重置为最早的偏移量，相当于 <code>--from-beginning</code>。</li><li>(2) <code>latest</code>：自动将偏移量重置为最新（最晚）的偏移量，这是默认值。</li><li>(3) <code>none</code>：如果未找到消费者组的先前偏移量，则向消费者抛出异常。</li></ul><p><img data-src="../../../asset/2024/11/kafka-consumer-15.png"></p><table><thead><tr><th>参数名称</th><th>参数描述</th></tr></thead><tbody><tr><td><code>auto.offset.reset</code></td><td>指定在消费者找不到有效偏移量时的处理策略，该参数的值有三种类型：<code>earliest</code>、<code>latest</code>、<code>none</code>，默认值是 <code>latest</code>。<strong>特别注意，该参数仅在首次消费或偏移量丢失时生效，平时消费者会按已提交的偏移量消费。</strong></td></tr></tbody></table><blockquote><p>消费者指定 offset 消费的案例</p></blockquote><p>本节将让消费者从任意指定的 offset 位置开始消费数据。</p><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-16</code>。</p></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test2"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取消费者的分区分配信息（有了分区分配信息才能开始消费）</span></span><br><span class="line">        Set&lt;TopicPartition&gt; assignment = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) {</span><br><span class="line">            <span class="comment">// 确保分区分配完成</span></span><br><span class="line">            consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 获取消费者的分区分配信息</span></span><br><span class="line">            assignment = consumer.assignment();</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历每个分区，对每个分区指定从哪个 offset 开始消费</span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) {</span><br><span class="line">            consumer.seek(topicPartition, <span class="number">23</span>);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><div class="admonition warning"><p class="admonition-title">特别注意</p><ul><li>上述代码每次执行完后，如果希望再次执行，那么就需要更改消费者组的 ID，否则消费者会消费不到数据。</li><li>这是因为 Kafka 的 offset 是按消费者组来存储的，如果更换了消费者组，新组没有之前的 offset 记录，就会从手动指定的 offset 开始消费消息，又或者根据 <code>auto.offset.reset</code> 配置来重新消费消息。</li><li>值得一提的是，如果消费者组 ID 不变，Kafka 会记录该组上一次提交的 offset，即使开发者手动指定了 <code>seek</code> 偏移量，也可能会出现偏移冲突，导致消费者会消费不到数据。</li></ul></div><h3 id="消费者按照时间消费"><a href="#消费者按照时间消费" class="headerlink" title="消费者按照时间消费"></a>消费者按照时间消费</h3><p>在生产环境中，会遇到最近消费的几个小时存在数据异常，想按照时间对消息进行重新消费。例如，要求按照时间重新消费前一天的数据，那么应该怎么处实现呢？</p><div class="admonition note"><p class="admonition-title">提示</p><p>本节所需的案例代码，可以直接从 <a target="_blank" rel="external nofollow" href="https://github.com/rqh656418510/spring-cloud-share/tree/main/kafka/kafka-study">GitHub</a> 下载对应章节 <code>kafka-lesson-17</code>。</p></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerConsumer</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 指定Kafka的连接信息（若是Kafka集群，多个节点之间使用逗号分隔）</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"127.0.0.1:9092"</span>);</span><br><span class="line">        <span class="comment">// 指定反序列化器（必须）</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 指定消费者组 ID（必须，可以任意定义）</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"test2"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题</span></span><br><span class="line">        List&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">"first"</span>);</span><br><span class="line">        consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取消费者的分区分配信息（有了分区分配信息才能开始消费）</span></span><br><span class="line">        Set&lt;TopicPartition&gt; assignment = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) {</span><br><span class="line">            <span class="comment">// 确保分区分配完成</span></span><br><span class="line">            consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 获取消费者的分区分配信息</span></span><br><span class="line">            assignment = consumer.assignment();</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 封装集合存储，每个分区对应一天前的数据</span></span><br><span class="line">        Map&lt;TopicPartition, Long&gt; timestampToSearch = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) {</span><br><span class="line">            timestampToSearch.put(topicPartition, System.currentTimeMillis() - <span class="number">1</span> * <span class="number">24</span> * <span class="number">3600</span> * <span class="number">1000</span>);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取从 1 天前开始消费的每个分区的 offset</span></span><br><span class="line">        Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = consumer.offsetsForTimes(timestampToSearch);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历每个分区，对每个分区指定从哪个时间开始消费</span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) {</span><br><span class="line">            <span class="comment">// 获取分区的 offset 和时间信息</span></span><br><span class="line">            OffsetAndTimestamp offsetAndTimestamp = offsets.get(topicPartition);</span><br><span class="line">            <span class="comment">// 根据时间指定从哪个位置开始消费</span></span><br><span class="line">            <span class="keyword">if</span> (offsetAndTimestamp != <span class="keyword">null</span>) {</span><br><span class="line">                consumer.seek(topicPartition, offsetAndTimestamp.offset());</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">            <span class="comment">// 设置每隔 1 秒消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="Kafka-消费者的最佳实践"><a href="#Kafka-消费者的最佳实践" class="headerlink" title="Kafka 消费者的最佳实践"></a>Kafka 消费者的最佳实践</h2><h3 id="Kafka-重复消费与漏消费问题"><a href="#Kafka-重复消费与漏消费问题" class="headerlink" title="Kafka 重复消费与漏消费问题"></a>Kafka 重复消费与漏消费问题</h3><ul><li><p><strong>重复消费</strong></p><ul><li>已经消费了数据，但是 offset 没有提交。</li><li><strong>重复消费通常是由于 Kafka 消费者启用自动提交 offset 引起的。</strong></li><li>比如：设置了 offset 为自动提交，当消费者将消息数据处理完（写库），还没等到 offset 提交，此时刚好消费者线程被 kill 掉，等消费者再次启动后，则会从上一次提交的 offset 位置继续消费，最终导致消息重复消费。</li></ul></li><li><p><strong>漏消费</strong></p><ul><li>先提交 offset 再消费，有可能会造成消息的漏消费。</li><li>比如：设置了 offset 为手动提交，当 offset 被提交时，消息数据还在内存中未处理，此时刚好消费者线程被 Kill 掉，导致内存中的消息数据丢失；由于 offset 已经提交，但是消息数据未处理，最终导致消息漏消费。</li></ul></li></ul><div class="admonition note"><p class="admonition-title">思考</p><p>Kafka 消费者如何才能做到既不漏消费，也不重复消费呢？详见下面介绍的消费者事务。</p></div><p><img data-src="../../../asset/2024/11/kafka-consumer-16.png"></p><h3 id="Kafka-消费者事务的实现"><a href="#Kafka-消费者事务的实现" class="headerlink" title="Kafka 消费者事务的实现"></a>Kafka 消费者事务的实现</h3><p>如果希望实现消费者端的精准一次性消费，那么需要 Kafka 消费端将消费过程和提交 offset 过程做原子绑定。此时，开发者需要将 Kafka 的 offset 存储到支持事务的自定义介质中（比如 MySQL）。</p><p><img data-src="../../../asset/2024/11/kafka-consumer-17.png"></p><h3 id="Kafka-消费者提高吞吐量"><a href="#Kafka-消费者提高吞吐量" class="headerlink" title="Kafka 消费者提高吞吐量"></a>Kafka 消费者提高吞吐量</h3><p>Kafka 如何提高消费者的消费速度呢？</p><ul><li><p>(1) 如果是 Kafka 消费能力不足，则可以考虑增加 Topic 的分区数量，并且同时增加消费组的消费者数量，这两个条件缺一不可，即 <code>消费组的消费者数量 = Topic 的分区数量</code>。</p></li><li><p>(2) 如果是下游的数据处理不及时（有较大延迟），则可以提高消费者每批次拉取消息的数量（默认每批次拉取 500 条消息）。每批次拉取数据过少（拉取的数据量 / 数据处理时间 &lt; 生产速度），会使消费者处理数据的速度小于生产者生产数据的速度，从而可能导致消息积压。</p></li></ul><p><img data-src="../../../asset/2024/11/kafka-consumer-18.png"></p><ul><li>(3) 消费者提高吞吐量的相关配置参数</li></ul><table><thead><tr><th>参数名称</th><th>参数描述</th></tr></thead><tbody><tr><td><code>fetch.max.bytes</code></td><td>消费者获取服务器端一批消息的最大字节数，默认值为 <code>50M</code>。如果服务器端一批次的消息大于该值，仍然可以将这批消息拉取回来，所以这不是一个绝对最大值。消费者拉取一批次消息的大小受 <code>message.max.bytes</code>（Broker 配置）或者 <code>max.message.bytes</code>（Topic 配置）影响。</td></tr><tr><td><code>max.poll.records</code></td><td>消费者每次调用 <code>poll()</code> 方法时，最多能拉取的消息数量，默认值为 <code>500</code>。</td></tr></tbody></table><div id="readmore-expansion" class="pjax"></div><link rel="stylesheet" type="text/css" href="https://qiniu.techgrow.cn/readmore/dist/hexo.css"><script data-pjax="" src="https://qiniu.techgrow.cn/readmore/dist/readmore.js" type="text/javascript"></script><script data-pjax="">var isMobile=navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i),allowMobile=!1;if(!isMobile||isMobile&&allowMobile)try{var plugin=new ReadmorePlugin;plugin.init({type:"hexo",id:"readmore-container",name:"全栈技术驿站",blogId:"96641-5333172926158-056",qrcode:"https://www.techgrow.cn/img/wx_mp_qr.png",keyword:"Tech",random:"1",height:"auto",expires:"365",lockToc:"yes",interval:"30",baseUrl:"",execute:"yes",tocSelector:""})}catch(e){console.warn("readmore plugin occurred error: "+e.name+" | "+e.message)}</script></div><footer class="post-footer"><div class="reward-container"><div>支持一根棒棒糖！</div> <button> 赞赏</button><div class="post-reward"><div> <img src="/img/pay_wx.png" alt="Clay 微信"> <span>微信</span></div><div> <img src="/img/pay_zfb.png" alt="Clay 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"> <strong>本文作者：</strong> Clay</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.techgrow.cn/posts/c61757ff.html" title="Kafka 入门教程之四">https://www.techgrow.cn/posts/c61757ff.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="contactme"><div class="social-list"><div class="social-item"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">欢迎添加博主微信，请备注 "博客"，届时会邀请您加入百人微信群</span><br> <img src="/img/wx_account_qr.png"></div></div></div><div class="post-tags"><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag"><i class="fa fa-tag"></i> 分布式</a><a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag"><i class="fa fa-tag"></i> 消息队列</a><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"><i class="fa fa-tag"></i> 大数据</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/f5674448.html" rel="prev" title="C++ 进阶基础之十一"><i class="fa fa-angle-left"></i> C++ 进阶基础之十一</a></div><div class="post-nav-item"> <a href="/posts/ed9d5bd.html" rel="next" title="Kafka 入门教程之五">Kafka 入门教程之五<i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments" id="waline"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> Copyright © 2018 – <span itemprop="copyrightYear">2025</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Clay</span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i></span> <span>站点总字数：</span> <span title="站点总字数">1.7m</span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span>站点阅读时长 ≈</span> <span title="站点阅读时长">26:11</span></span></div><div id="site-runtime"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span><span id="runtime"></span></div><script language="javascript">function isPC(){for(var e=navigator.userAgent,t=["Android","iPhone","SymbianOS","Windows Phone","iPad","iPod"],n=0;n<t.length;n++)if(0<e.indexOf(t[n]))return!1;return!0}function siteTime(e,t){window.setTimeout("siteTime(openOnPC, start)",1e3);var n=36e5,o=24*n;t=new Date("2018-12-27 08:00:00");var i=new Date,r=(i.getFullYear(),i.getMonth(),i.getDate(),i.getHours(),i.getMinutes(),i.getSeconds(),i-t),a=Math.floor(r/31536e6),s=Math.floor(r/o-365*a),d=Math.floor((r-(365*a+s)*o)/n),l=Math.floor((r-(365*a+s)*o-d*n)/6e4),u=Math.floor((r-(365*a+s)*o-d*n-6e4*l)/1e3);document.getElementById("runtime").innerHTML="Powered by Hexo & Docker | "+a+" 年 "+s+" 日 "+d+" 小时 "+l+" 分钟 "+u+" 秒 "}var showOnMobile=!1,openOnPC=isPC(),start=new Date;siteTime(openOnPC,start),openOnPC||showOnMobile||(document.getElementById("site-runtime").style.display="none")</script><div class="beian"> <span><img src="/img/gonganbeian.png" alt=""></span> <span><a href="https://beian.miit.gov.cn/" rel="external nofollow" target="_blank">粤ICP备 19024664号-1</a></span> <span>|&nbsp;</span> <span><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44011302004035" rel="external nofollow" target="_blank">粤公网安备 44011302004035号</a></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div><div class="sidebar-dimmer"></div> <a href="https://github.com/rqh656418510" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="external nofollow" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="200" alpha="0.5" zindex="-1" src="/lib/ribbon.js/dist/ribbon.min.js"></script><script src="/lib/animejs/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="/lib/@next-theme/pjax/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script><script src="/lib/medium-zoom/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script><script src="/lib/lozad/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script><script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"/lib/pdfobject/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script><script src="/js/third-party/tags/pdf.js"></script><script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"/lib/mermaid/dist/mermaid.min.js","integrity":"sha256-stuqcu2FrjYCXDOytWFA5SoUE/r3nkp6gTglzNSlavU="}}</script><script src="/js/third-party/tags/mermaid.js"></script><script src="/js/third-party/pace.js"></script><script data-pjax="" async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://www.techgrow.cn/lib/darkmode/darkmode@1.5.7.min.js"></script><script>
var options = {
  bottom: '64px',
  right: '30px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#282828',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script><script src="https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js"></script><script>
    var qiniu_domain = "https://oss.techgrow.cn";
    var qiniu_token_url = "https://open.techgrow.cn/api/oss/qiniu/token/upload";
    var qiniu_debug = "true" === "false";

    // date format
    Date.prototype.format = function (fmt) {
      var o = {
        "M+": this.getMonth() + 1,
        "d+": this.getDate(),
        "h+": this.getHours(),
        "m+": this.getMinutes(),
        "s+": this.getSeconds(),
        "q+": Math.floor((this.getMonth() + 3) / 3),
        "S": this.getMilliseconds()
      };
      if (/(y+)/.test(fmt)) {
        fmt = fmt.replace(RegExp.$1, (this.getFullYear() + "").substr(4 - RegExp.$1.length));
      }
      for (var k in o) {
        if (new RegExp("(" + k + ")").test(fmt)) {
          fmt = fmt.replace(
            RegExp.$1,
            (RegExp.$1.length == 1)
              ? (o[k])
              : (("00" + o[k]).substr(("" + o[k]).length))
          );
        }
      }
      return fmt;
    }

    // generate uuid
    function uuid() {
      var s = [];
      var hexDigits = "0123456789abcdef";
      for (var i = 0; i < 36; i++) {
        s[i] = hexDigits.substr(Math.floor(Math.random() * 0x10), 1);
      }
      s[14] = "4";
      s[19] = hexDigits.substr((s[19] & 0x3) | 0x8, 1);
      s[8] = s[13] = s[18] = s[23] = "-";
      var uuid = s.join("");
      return uuid;
    }

    // sync get request
    function syncGet(url) {
      var xhr = null;
      if (window.XMLHttpRequest) {
        xhr = new XMLHttpRequest();
      } else {
        xhr = new ActiveXObject("Microsoft.XMLHTTP");
      }
      xhr.open('GET', url, false);
      xhr.send();
      return xhr;
    }

    // get upload file path
    function getUploadFilePath() {
      var now = new Date();
      var name = uuid().replace(/-/g, "");
      var nowStr = now.format("/yyyy/MM/dd/");
      return "uploads" + nowStr + name;
    }

    // get qiniu upload token
    function getUploadToken() {
      try {
        var xhr = syncGet(qiniu_token_url);
        var responseStatus = xhr.status;
        var responseJson = JSON.parse(xhr.responseText);
        if (responseStatus === 200) {
          return responseJson.data;
        } else if (responseStatus === 403) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，非法请求来源！");
        } else if (responseStatus === 429) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，上传过于频繁！");
        } else if (responseStatus === 500) {
          alert(responseJson.msg || "图片上传失败，无法获取UploadToken，系统内部出错！");
        } else {
          alert("图片上传失败，无法获取UploadToken，未知Http响应状态码！");
        }
      } catch (err) {
        if (qiniu_debug) {
          console.error(err);
        }
        alert("图片上传失败，无法获取UploadToken，未知错误！");
      }
      return null;
    }

    // qiniu upload image
    async function qiniuUploadImage(file) {
      var image_path = null;
      await uploadImage(file).then(function onFulfilled(res) {
        image_path = res;
      }).catch(function onRejected(err) {
        if (qiniu_debug) {
          console.error(err);
        }
      });
      return image_path;
    }

    // upload image
    function uploadImage(file) {
      return new Promise((resolve, reject) => {
        var config = null;
        var putExtra = null;
        var token = getUploadToken();
        var key = getUploadFilePath();
        // upload init
        var observable = qiniu.upload(file, key, token, putExtra, config);
        // upload start
        observable.subscribe({
          next(res) {
            // upload progress
          },
          error(err) {
            // upload falied
            reject("falied to upload image for qiniu: " + err.name);
          },
          complete(res) {
            // upload successed
            resolve(qiniu_domain + "/" + key);
          }
        });
      });
    }
  </script><script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://waline.techgrow.cn","cssUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css","commentCount":true,"pageview":false,"copyright":false,"allowUploadImage":true,"libUrl":"https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.js","locale":{"placeholder":"支持匿名评论啦，若希望及时收到博主的反馈，建议登录评论或者在上方的邮箱输入框留下邮箱地址哦 (๑•̀ㅂ•́)و✧"},"dark":"body.darkmode--activated","emoji":["https://www.techgrow.cn/lib/@waline/emojis/1.0.1/weibo"],"meta":["nick","mail","link"],"login":"enable","pageSize":10,"qiniuDebug":false,"qiniuDomain":"https://oss.techgrow.cn","qiniuTokenUrl":"https://open.techgrow.cn/api/oss/qiniu/token/upload","qiniuLibUrl":"https://www.techgrow.cn/lib/qiniu/qiniu@3.3.1.min.js","el":"#waline","comment":true,"path":"/posts/c61757ff.html"}</script><link rel="stylesheet" href="https://www.techgrow.cn/lib/@waline/client/client@2.5.1.min.css"><script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.waline.allowUploadImage) {
    CONFIG.waline.imageUploader = false;
  }
  else if (CONFIG.waline.qiniuDomain && CONFIG.waline.qiniuTokenUrl) {
    CONFIG.waline.imageUploader = qiniuUploadImage;
  } else {
   CONFIG.waline.imageUploader = true;
  }
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script><div class="moon-menu"><div class="moon-menu-items"><div id="moon-menu-item-back2bottom" class="moon-menu-item"><i class="fas fa-chevron-down"></i></div><div id="moon-menu-item-back2top" class="moon-menu-item"><i class="fas fa-chevron-up"></i></div></div><div class="moon-menu-button"><svg class="moon-menu-bg"><circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle><circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle></svg><div class="moon-menu-content"><div class="moon-menu-icon"><i class="fas fa-ellipsis-v"></i></div><div class="moon-menu-text"></div></div></div></div><script src="/js/injector.js"></script><div class="comments" id="waline-comments" style="display:none"></div><script>function isMobile(){var i=navigator.userAgent.toLowerCase(),e="ipad"==i.match(/ipad/i),a="iphone os"==i.match(/iphone os/i),o="midp"==i.match(/midp/i),n="rv:1.2.3.4"==i.match(/rv:1.2.3.4/i),r="ucweb"==i.match(/ucweb/i),c="android"==i.match(/android/i),l="windows ce"==i.match(/windows ce/i),d="windows mobile"==i.match(/windows mobile/i);return!!(e||a||o||n||r||c||l||d)}var openOnMobile=isMobile(),showOnMobile=!1,aplayerEnable=!0;jQuery(document).ready(function(){aplayerEnable&&(openOnMobile&&!showOnMobile||jQuery("#aplayer").css("display","block"))}),jQuery(window).on("load",function(){aplayerEnable&&jQuery(".aplayer\\-icon.aplayer\\-icon\\-lrc").trigger("click")})</script></body></html>