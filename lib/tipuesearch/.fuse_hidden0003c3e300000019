var tipuesearch = {"pages":[{"title":"Hexo 主题兼容 Pjax","url":"/posts/637e7b8f.html","text":"什么是 Pjax​Pjax​​​ 通过 Ajax 从服务器获取 HTML 内容，然后用加载到的 HTML 替换页面上容器元素的内容。Pjax 使用 pushState 更新浏览器中的当前 URL，即 ​​pjax = pushState + ajax​​ 。最早的时候，​​Pjax​​​ 是一个基于 ​​jQuery​​ 的插件，后来推出了完全独立的版本，适用更广泛的应用场景。值得一提的是，Pjax 最大的优势在于，可以在网站本身无刷新的情况下，局部刷新页面内容，同时在现代浏览器中支持前进和后退，由于局部加载的数据量极小，加载速度极快，因此可以最大程度地提升用户体验。Pjax 的天生劣势在于，默认配置对 ​​SEO​​ 并不友好，同时非常依赖页面布局的一致性，需要大量改造来优化。 Hexo 引入 Pjax很多较早使用 ​​Pjax​​ 的 Hexo 主题，都使用了基于 jQuery 的版本。因此如果是新引入，可以使用最新独立版本的 ​​Pjax​​。 1&lt;script src=\"https://cdn.jsdelivr.net/npm/pjax@VERSION/pjax.min.js\"&gt;&lt;/script&gt; 为什么引入 Pjax由于想在 Hexo 博客中整合 Aplayer 音乐播放器，但是如果不进行改造，跳转页面肯定会引起音乐播放的中断，于是就想到利用 ​​Pjax​​ 的特性，局部加载核心内容，从而不影响音乐播放器，整体效果类似网易云音乐的 PC 端。 兼容处理首先独立版的 Pjax 工作方式其实特别好理解。例如初始化： 123456789101112131415document.addEventListener('DOMContentLoaded', function () { pjax = new Pjax({ elements: 'a[href]:not([href^=\"#\"]):not([href=\"javascript:void(0)\"]):not([pjax-fancybox]):not([notallow=\"return false;\"]):not([notallow=\"return!1\"]):not([target=\"_blank\"]):not([target=\"view_window\"]):not([href$=\".xml\"])', selectors: [ \"head title\", // 标题 \"head meta[name=keywords]\", // 关键词 \"head meta[name=description]\", // 描述 \".pjax\", \"pjax\", // &lt;pjax&gt;&lt;/pjax&gt; 标签 \"script[data-pjax], .pjax-reload script\" // script 标签添加 data-pjax 或 script 标签外层添加 .pjax-reload 的 script 代码段重载 ], cacheBust: &lt;%= theme.plugins.pjax.cacheBust %&gt;, // url 地址追加时间戳，用以避免浏览器缓存 timeout: &lt;%= theme.plugins.pjax.timeout %&gt;, });}); 然后是标签部分，主要是用在以下场景： 12345678&lt;div class=\"pjax\"&gt;我是将被 Pjax 重载的内容&lt;/div&gt;&lt;script data-pjax&gt;我是将被 Pjax 重载的内容&lt;/script&gt;&lt;div class=\"pjax-reload\"&gt; &lt;div&gt; &lt;div&gt;我不是将被 Pjax 重载的内容&lt;/div&gt; &lt;script&gt;我是将被 Pjax 重载的内容&lt;/script&gt; &lt;/div&gt;&lt;/div&gt; 常见问题Pjax 触发重载这个是最严重的问题，独立版的 ​​Pjax​​ 会自动检测页面布局变化，如果变化过大，则会直接重载整个页面。实际测试就发现 Hexo 非常容易触发重载，尤其是 ​​page​​​ 和 ​​post​​ ，因为这两种页面原本的处理就完全不同。测试了一下，如果完全相同，则不会触发重载。 自定义 JS 代码不加载启用 Pjax 以后，可能会出现一些 JavaScript 代码加载不出来的情况。解决方案很简单，只要在原有的 &lt;script&gt;&lt;/script&gt; 标签中添加 data-pjax 属性就行。 123&lt;script data-pjax type=\"text/javascript\"&gt; // Some code here&lt;/script&gt; 参考资料 网站访问速度优化之 Pjax Butterfly 的 Pjax 适配方案 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"Vue 项目中禁用浏览器缓存配置","url":"/posts/b044ec3b.html","text":"前言前端项目发布新版本时，会经常遇到需要清理缓存的问题，以下是 Vue 项目禁用缓存的方法。 HTML 内容在 HTML 页面（如 index.html）的 &lt;head&gt; 标签中添加 meta 配置。 123&lt;meta http-equiv=\"pragram\" content=\"no-cache\" /&gt;&lt;meta http-equiv=\"cache-control\" content=\"no-cache, no-store, must-revalidate\" /&gt;&lt;meta http-equiv=\"expires\" content=\"0\" /&gt; Vue Cli 构建针对 Vue3 以下版本，在 vue.config.js 新增配置内容，将时间戳作为打包编译后的文件名称的一部分。 123456789101112131415const Timestamp = new Date().getTime()module.exports = { configureWebpack: { output: { // 输出重构，打包编译后的文件名称 【模块名称.版本号(可选).时间戳】 filename: `[name].${Timestamp}.js`, chunkFilename: `[name].${Timestamp}.js` }, }, css: { extract: { // 打包后css文件名称添加时间戳 filename: `css/[name].${Timestamp}.css`, chunkFilename: `css/[name].${Timestamp}.css` } },} Nginx 配置禁用掉 Nginx 缓存，让浏览器每次到服务器去请求文件，而不是在浏览器中读取缓存文件。值得一提的是，以下配置只对 HTML 文件有效。 123location ~ .*\\.(?:htm|html)$ { add_header Cache-Control \"private, no-store, no-cache, must-revalidate, proxy-revalidate\";} 参考资料 Nginx 缓存设置 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"VuePress v1 图片居中插件不生效","url":"/posts/d23a0b2b.html","text":"问题说明无论是 VuePress 官方主题，还是第三方主题，使用官方内置的插件 @vuepress/plugin-medium-zoom 都无法实现图片居中并点击放大的效果，配置示例如下。 默认主题 1234567module.exports = { plugins: { '@vuepress/medium-zoom': { selector: '.theme-default-content img' } }} 第三方主题 1234567module.exports = { plugins: { '@vuepress/medium-zoom': { selector: '.theme-reco-content img' } }} 问题解决安装官方的另一款插件 vuepress-plugin-medium-zoom 来替代。 1npm install -D vuepress-plugin-medium-zoom 默认主题 1234567module.exports = { plugins: { 'vuepress-plugin-medium-zoom': { selector: '.theme-default-content img' } }} 第三方主题 1234567module.exports = { plugins: { 'vuepress-plugin-medium-zoom': { selector: '.theme-reco-content img' } }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"推送镜像到 DockerHub","url":"/posts/2ba32056.html","text":"注册账号在 DockerHub 官网注册账号，该账号是免费注册的。 创建个人仓库登录 DockerHub 的官网，创建新的镜像仓库。 手动推送镜像构建镜像在本地使用 Dockerfile 的方式构建镜像。通过 docker build 命令构建新的镜像，-t 参数可以指定新镜像的名称，. 表示在当前目录下。 构建本地镜像 1docker build -t clay/dingtalk-webhook . 查看本地镜像 1docker images 给镜像打标签，更改标签的语法： docker tag IMAGEID REPOSITORY:TAG 12345# 指定版本号docker tag 2657f9dbbd15 clay/dingtalk-webhook:1.0.3# 不指定版本号（默认为 latest）docker tag 2657f9dbbd15 clay/dingtalk-webhook 特别注意 每次都要 Push 不带版本号的镜像，否则镜像将没有 latest 版本，导致其他人拉取镜像的时候必须要指定 tag，这样会非常不方便。 推送镜像12345678# 登录 DockerHubdocker login# 推送指定版本号的镜像docker push clay/dingtalk-webhook:1.0.3# 推送不带版本号的镜像（默认为 latest）docker push clay/dingtalk-webhook 搜索镜像镜像推送成功后，可以在 DockerHub 仓库中观察是否可以搜索到，若能搜索到则说明镜像推送成功。 1docker search dingtalk-webhook 推送加速推送镜像到 DockerHub 时，往往会因网络延迟而超时。这种情况下，可以配置 Docker Push 使用代理，加快镜像推送的速度。 提示 由于不可描述的原因，Docker 的 Pull 或 Push 都很慢。Docker Pull 镜像时，可以更改 /etc/docker/daemon.json 配置文件，加入国内镜像源的方式来加速。但 Docker Push 不支持这种方式，传统的 export http_proxy=xxxx 设置 HTTP 代理变量的方式对 Docker 也无效，因此需要采用下面的方式设置 HTTP 代理来解决。 123456789101112131415161718# 创建配置目录mkdir -p /etc/systemd/system/docker.service.d# 创建配置文件vim /etc/systemd/system/docker.service.d/http-proxy.conf# 写入配置文件(指定代理服务的地址)[Service]Environment=\"HTTP_PROXY=http://127.0.0.1:1080/\"# 刷新更改systemctl daemon-reload &amp;&amp; systemctl restart docker# 验证是否生效systemctl show --property=Environment docker# 重新Push镜像docker push clay/dingtalk-webhook 自动推送镜像这里将介绍如何利用 GitHub Actions 自动构建并推送 Docker 镜像到 DockerHub。 创建 GitHub 仓库登录 GitHub 官网，首先手动创建代码仓库，然后将本地的代码 Push 到代码仓库。 配置 DockerHub 账号由于希望通过 GitHub Actions 自动推送镜像到 DockerHub，因此必须要有 DockerHub 的认证配置，即需要在 GitHub 仓库中添加 DockerHub 登录的用户名和密码（AcessToken）。 选择 Action 工作流模板选择 GitHub Actions 的工作流模板，这里可以任意选择一个，后续可以手动更改模板文件的内容。值得一提的是，模板文件创建成功后，默认会保存在 GitHub 仓库的 .github/workflows/ 目录下。 更改 Workflow 配置文件编辑 GitHub 仓库 .github/workflows/ 目录下的 Workflow 配置文件，覆盖并添加下述内容。 提示 GitHub Actions 的中文文档 GitHub 从 Git 引用和 GitHub 事件中提取元数据（tags、labels）的配置方法，详细教程可以参考 这里。 Action 本质就是由一系列的 step 组成，GitHub Actions 官方所有可用的 Action 可以从 这里 查找到。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# This workflow will build a package using Maven and then publish it to GitHub packages when a release is created# For more information see: https://github.com/actions/setup-java/blob/main/docs/advanced-usage.md#apache-maven-with-a-settings-pathname: DockerHub Image Publishon: push: branches: - 'main' tags: - '*' pull_request: branches: - 'main'env: IMAGE_NAME: clay/dingtalk-webhookjobs: build: runs-on: ubuntu-latest steps: - name: Checkout the repo uses: actions/checkout@v3 - name: Set up JDK 11 uses: actions/setup-java@v3 with: java-version: '11' distribution: 'temurin' cache: maven - name: Build with Maven run: mvn -B package --file pom.xml - name: Build the Docker image run: docker build . --file Dockerfile --tag ${{ env.IMAGE_NAME }} - name: Login to DockerHub if: github.event_name != 'pull_request' uses: docker/login-action@v2 with: username: ${{ secrets.DOCKERHUB_USERNAME }} password: ${{ secrets.DOCKERHUB_TOKEN }} - name: Extract Docker metadata id: meta uses: docker/metadata-action@v4 with: images: ${{ env.IMAGE_NAME }} - name: Build and push Docker image uses: docker/build-push-action@v3 with: context: . push: ${{ github.event_name != 'pull_request' }} tags: ${{ steps.meta.outputs.tags }} labels: ${{ steps.meta.outputs.labels }} 步骤的名称 步骤的描述 Checkout the repo 检出仓库代码 Set up JDK 11 安装 JDK 11 Build with Maven Maven 编译代码 Build the Docker image 构建 Docker 镜像 Login to DockerHub 登录 DockerHub Extract Docker metadata 提取 Docker 的元数据 Build and push Docker image 推送 Docker 镜像 自动推送镜像到 DockerHubWorkflow 文件配置完成之后，将所有内容更改推送至 Github 仓库。按照本例中的配置，只要 main 分支有新的 Push 事件或者 tag 有更新，就会触发 Github Actions 自动构建镜像并推送至 DockerHub。上述配置的 Extract Docker metadata 步骤，目的是更改镜像的名称，镜像的 tag 会自动抽取（规则如下表所示）。默认情况下，如果是分支的 Push 事件，那么镜像的 tag 则为分支的名称，如果是 tag 的 Push 事件，则会推送 tag 和 latest 这两个版本的镜像到 DockerHub，具体配置规则参见 这里 。 Eent Ref Docker Tags pull_request refs/pull/2/merge pr-2 push refs/heads/main main push refs/heads/releases/1 releases-1 push tag refs/tags/1.2.3 1.2.3, latest push tag refs/tags/2.0.8-beta.67 2.0.8-beta.67, latest workflow_dispatch refs/heads/main main Git 创建并推送 tag 的命令 12345678# 创建标签git tag 1.0.2# 推送标签git push origin 1.0.2# 查看所有标签列表git tag --list 当 Push 新的 tag 到 GitHub 仓库后，等待 GitHub Actions 的自动构建操作完成，最后登录 DockerHub 的官网，可以看到已经有相应的 Docker 镜像被创建。 查看自动构建的结果 参考资料 Git 之 Tag 标签的使用 使用 GitHub Actions 自动构建 DockerHub 镜像 巧用 Github Actions 自动推送 DockerHub 镜像 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化"},{"title":"SpringBoot 整合 MyBatis-Plus 与 H2 教程","url":"/posts/afd4ab85.html","text":"大纲 H2 数据库基础使用教程 SpringBoot 整合 MyBatis-Plus 与 H2 教程 前言 H2 官方文档 H2 GitHub 项目 项目介绍版本说明 框架 版本 描述 Spring Boot 2.7.11 MyBatis-Plus 3.5.3.1 H2 2.1.214 项目结构 代码下载本文所需的案例代码，可以直接从 GitHub 下载对应章节 h2-springboot-mybatis-plus。 项目文件Maven 配置文件 pom.xml 的核心配置内容如下 1234567891011121314151617181920212223242526272829303132333435363738&lt;properties&gt; &lt;spring-boot.version&gt;2.7.11&lt;/spring-boot.version&gt; &lt;mybatis-plus.version&gt;3.5.3.1&lt;/mybatis-plus.version&gt; &lt;h2.version&gt;2.1.214&lt;/h2.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mybatis-plus --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis-plus.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- h2 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;${h2.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- spring-boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; SQL 映射文件 UserMapper.xml，MyBatis 的 SQL 映射文件 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.clay.h2.mapper.UserMapper\"&gt; &lt;update id=\"clear\"&gt; truncate table `t_user` &lt;/update&gt;&lt;/mapper&gt; SQL 初始化脚本文件 schema.sql，用于初始化数据库的表结构 1234567create table if not exists `t_user` ( `id` int primary key auto_increment not null, `username` char (50) not null, `pwd` char(50) not null, `create_time` datetime not null, `update_time` datetime); data.sql，用于初始化数据库的表数据 1insert into t_user(id, username, pwd, create_time, update_time) values (0, 'zhhangsan', '1222', {ts '2022-07-27 18:47:52.69'}, {ts '2022-07-27 18:47:52.69'}); SpringBoot 配置文件提示 H2 数据库支持多种连接方式和连接设置，连接数据库的 JDBC URL 对大小写不敏感。 关于 H2 的更多 JDBC URL 格式和使用示例，请看 这里 的详细介绍。 配置完整案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051server: port: 8080spring: application: name: h2-springboot-mybatis-plus # 数据源配置 datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource # mem 表示 H2 使用内存数据库（应用重启会丢失数据） url: jdbc:h2:mem:shopDb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;AUTO_RECONNECT=TRUE username: root password: 123456 # 数据库初始化 sql: init: separator: ; encoding: UTF-8 platform: h2 mode: always continue-on-error: false schema-locations: - classpath:db/schema.sql data-locations: - classpath:db/data.sql # H2 的 Web 控制台 h2: console: enabled: true settings: path: /h2-console trace: true web-allow-others: false# Mybatis-Plusmybatis-plus: mapper-locations: classpath*:/mapper/**/*.xml typeAliasesPackage: com.clay.*.entity # MyBatis-Plus 配置 global-config: db-config: id-type: AUTO banner: false # MyBatis 原生配置 configuration: map-underscore-to-camel-case: true call-setters-on-nulls: true jdbc-type-for-null: 'null' # 打印 SQL 语句 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl H2 内存数据库 若希望 H2 将数据库表的数据存储在内存中（应用重启后会丢失数据），可以使用以下的数据源配置信息。 1234567spring: datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource url: jdbc:h2:mem:shopDb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;AUTO_RECONNECT=TRUE username: root password: 123456 H2 持久化数据 若希望 H2 持久化数据，可以使用以下的数据源配置信息（必须指定数据库的文件路径）。 1234567spring: datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource url: jdbc:h2:file:/var/database/h2/shopDb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;AUTO_RECONNECT=TRUE username: root password: 123456 H2 兼容 MySQL 若希望 H2 兼容 MySQL，可以使用连接参数 MODE 来实现。 H2 兼容多种数据库，MODE 参数的值可以为：DB2、Derby、HSQLDB、MSSQLServer、MySQL、Oracle、PostgreSQL。 1234567spring: datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource url: jdbc:h2:file:/var/database/h2/shopDb;MODE=MYSQL;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;AUTO_RECONNECT=TRUE username: root password: 123456 H2 使用混合模式 若希望 H2 使用混合模式，可以使用以下的数据源配置信息（必须指定数据库的文件路径）。 值得一提的是，在默认情况下，H2 数据库同一时刻只允许一个客户端访问；设置 AUTO_SERVER=TRUE 表示启用混合模式，允许多个客户端同时连接同一个 H2 数据库，该参数不支持在内存中运行的 H2 数据库。 1234567spring: datasource: driver-class-name: org.h2.Driver type: com.zaxxer.hikari.HikariDataSource url: jdbc:h2:/var/database/h2/shopDb;AUTO_SERVER=TRUE;DB_CLOSE_DELAY=-1;AUTO_RECONNECT=TRUE username: root password: 123456 SpringBoot 不同版本之间的配置差异 使用 SpringBoot 低版本时（如 2.3.5 版本），若希望应用在启动的时候初始化数据库，则需要使用以下的配置信息。 123456789spring: datasource: continue-on-error: false # 初始化模式 initialization-mode: always # 初始化表 schema: classpath:db/schema.sql # 初始化数据 data: classpath:db/data.sql 数据库初始化参数 说明 spring.datasource.schema DDL 表初始化语句，用于在应用程序启动时创建数据库表结构，默认加载 schema.sql 文件 spring.datasource.data DML 数据插入语句，它用于在应用程序启动时向数据库表中插入一些初始化数据，默认加载 data.sql 文件 spring.datasource.continue-on-error 指定在初始化数据库时，是否遇到错误后继续执行初始化操作。默认情况下，该属性值为 false，即遇到错误时会停止初始化操作。特别注意，如果遇到错误后继续执行，可能会导致数据库结构不完整或数据不一致，因此请谨慎使用此属性。 spring.datasource.initialization-mode 数据库的初始化模式，never 表示从不初始化，embedded 表示仅初始化嵌入式的数据库，always 表示始终初始化数据库，默认值是 embedded。特别注意，如果数据库已经存在相应的表，always 模式下也会重新执行 SQL 初始化脚本，请谨慎使用此模式，否则可能会丢失数据。 配置参数说明 数据源配置参数 说明 spring.datasource.url 连接数据库的 URL spring.datasource.username 数据库的用户名 spring.datasource.password 数据库的密码 spring.datasource.driver-class-name 驱动类的全限定名 spring.datasource.type 数据源类型（连接池）的全限定名 数据库初始化参数 说明 spring.sql.init.separator 指定 SQL 语句的断句分隔符，默认为分号 ;。如果 SQL 语句中包含存储过程或游标等语句，则需要将该属性更改为适当的分隔符，例如 $$ spring.sql.init.encoding 指定 SQL 文件的编码方式，默认为 UTF-8 spring.sql.init.platform 指定 SQL 方言，默认为所有方言通用 spring.sql.init.mode 数据库的初始化模式，never 表示从不初始化，embedded 表示仅初始化嵌入式的数据库，always 表示始终初始化数据库，默认值是 embedded。特别注意，如果数据库已经存在相应的表，always 模式下也会重新执行 SQL 初始化脚本，请谨慎使用此模式，否则可能会丢失数据。 spring.sql.init.schema-locations DDL 表初始化语句，用于在应用程序启动时创建数据库表结构，默认加载 schema.sql 文件 spring.sql.init.data-locations DML 数据插入语句，它用于在应用程序启动时向数据库表中插入一些初始化数据，默认加载 data.sql 文件 spring.sql.init.continue-on-error 指定在初始化数据库时，是否遇到错误后继续执行初始化操作。默认情况下，该属性值为 false，即遇到错误时会停止初始化操作。特别注意，如果遇到错误后继续执行，可能会导致数据库结构不完整或数据不一致，因此请谨慎使用此属性。 H2 数据库连接参数 说明 AUTO_SERVER=TRUE 启用混合模式，允许多个客户端同时连接同一个 H2 数据库，该参数不支持在内存中运行的 H2 数据库 MODE=MYSQL 兼容 MySQL 数据库，该参数值可以为：DB2、Derby、HSQLDB、MSSQLServer、MySQL、Oracle、PostgreSQL DB_CLOSE_ON_EXIT=FALSE 当虚拟机退出时，并不关闭数据库 DB_CLOSE_DELAY=-1 默认情况下，当最后一个连接关闭后，H2 数据库会自动关闭。为了提高数据库的性能，可以控制延迟一定的秒数后再关闭数据库。当值设置为 10，表示延迟 10 秒 再关闭数据库，当设置为 -1，表示禁用数据库自动关闭的功能。 AUTO_RECONNECT=TRUE 连接丢失后自动重新连接 TRACE_LEVEL_SYSTEM_OUT=1 输出跟踪日志到控制台的日志级别，取值 0 为 OFF，1 为 ERROR（默认值），2 为 INFO，3 为 DEBUG TRACE_LEVEL_FILE=1 输出跟踪日志到文件的日志级别，取值 0 为 OFF，1 为 ERROR（默认值），2 为 INFO，3 为 DEBUG H2 的 Web 控制台参数 说明 spring.h2.console.enabled 启用 H2 的 Web 控制台 spring.h2.console.settings.path 指定 H2 的 Web 控制台的访问路径 spring.h2.console.settings.trace 开启 H2 的 Web 控制台的日志跟踪，方便开发调试 spring.h2.console.settings.web-allow-others 允许 H2 的 Web 控制台的远程访问 项目代码Util 类代码12345678910111213141516@Data@NoArgsConstructor@AllArgsConstructorpublic class Result&lt;T&gt; { private Integer code = 0; private String msg; private T data; public Result(T data) { this.data = data; }} Entity 类代码1234567891011121314151617181920212223242526272829303132333435@Data@ToString@TableName(\"t_user\")public class User implements Serializable { /** * 用户主键 */ @TableId(value = \"id\", type = IdType.AUTO) private Integer id; /** * 用户名称 */ @TableField(\"username\") private String username; /** * 密码 */ private String pwd; /** * 创建时间 */ @JsonFormat(timezone = \"GMT+8\", pattern = \"yyyy-MM-dd HH:mm:ss\") private Date createTime; /** * 修改时间 */ @JsonFormat(timezone = \"GMT+8\", pattern = \"yyyy-MM-dd HH:mm:ss\") private Date updateTime;} Mapper 类代码12345678public interface UserMapper extends BaseMapper&lt;User&gt; { /** * 清空表 */ void clear();} Service 类代码12345678910111213141516171819202122public interface UserService extends IService&lt;User&gt; { /** * 分页查询 * @return */ Result getByPage(); /** * 新增记录 * @param user * @return */ Result add(User user); /** * 清空数据 * @return */ Result clear();} 123456789101112131415161718192021222324252627@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService { @Override public Result getByPage() { Page&lt;User&gt; page = new Page&lt;&gt;(1, 10); QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(\"username\", \"zhhangsan\"); this.page(page, wrapper); return new Result(page.getRecords()); } @Override @Transactional(rollbackFor = Exception.class) public Result add(User user) { user.setCreateTime(new Date()); return new Result(this.save(user)); } @Override @Transactional(rollbackFor = Exception.class) public Result clear() { this.baseMapper.clear(); return new Result(); }} Controller 类代码1234567891011121314151617181920212223@RestController@RequestMapping(\"/user\")public class UserController { @Autowired private UserService userService; @GetMapping(\"/page\") public Result getByPage() { return userService.getByPage(); } @PostMapping(\"/add\") public Result add(@RequestBody User user) { return userService.add(user); } @DeleteMapping(\"/clear\") public Result clear() { return userService.clear(); }} MyBatis-Plus 配置类代码123456789101112131415@Configuration@MapperScan(\"com.clay.h2.mapper\")public class MyBatisPlusConfig { /** * 分页插件 */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.H2)); return interceptor; }} 项目测试访问 H2 的 Web 控制台启动 SpringBoot 项目后，打开浏览器访问 http://127.0.0.1:8080/h2-console，若 H2 的 Web 控制台能正常访问，且连接 H2 数据库后能看到已创建的数据库表（如下图），则说明内嵌的 H2 数据库启动成功。 H2 数据库连接 在浏览器页面连接 H2 数据库时，使用的账号、密码与 JDBC URL 都是在 SpringBoot 的配置文件 application.yml 中指定的。 API 接口调用启动 SpringBoot 项目后，使用 PostMan 等工具测试以下接口，若能得到正常的响应结果，则说明 MyBatis-Plus 成功连接并操作 H2 数据库。 API 名称 API 地址 请求方法 新增用户 http://127.0.0.1:8080/user/add/ POST 分页查询用户 http://127.0.0.1:8080/user/page/ GET 删除所有用户 http://127.0.0.1:8080/user/clear/ DELETE 常见问题版本兼容问题当访问一个别人创建好的本地 H2 数据库文件，此时很有可能默认的 H2 版本不兼容导致 SpringBoot 应用启动报错（如下） 1org.h2.jdbc.JdbcSQLNonTransientException: General error: \"java.lang.IllegalStateException: Unable to read the page at position 70368748811782 [1.4.200/6]\" [50000-200] 解决方法是弄清楚对方本地的数据库文件是 H2 哪个版本创建的，然后手动指定 Maven 配置文件中的 H2 版本号即可（如下） 12345&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;2.1.214&lt;/version&gt;&lt;/dependency&gt; 参考资料 H2 兼容 MySQL 内存数据库－H2 简介与实践 SpringBoot 启动时自动创建数据库表 SpringBoot 集成 MybatisPlus、H2 纯内存数据库实战 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 数据库"},{"title":"H2 数据库基础使用教程","url":"/posts/dfc4cb86.html","text":"大纲 H2 数据库基础使用教程 SpringBoot 整合 MyBatis-Plus 与 H2 教程 前言在开发或学习时，有时候想编写一个数据库操作的小 Demo，但又不想利用 MySQL、Oracle 等数据库进行建库建表操作，因为只想写个小案例，感觉没必要弄个很大很麻烦的数据库。而且这个案例中的数据用完之后就不再需要了，所以也不需要进行数据的持久化操作。那有没有什么方案可以满足这个需求呢？答案是肯定的，H2 是一款内存数据库，适合在学习阶段、开发阶段调试代码使用，并不适用于生产阶段，可以满足学习与调试代码的需求。 H2 基础使用H2 的介绍H2 简介H2 数据库是一个用 Java 开发的内嵌式 (内存级别) 关系型数据库，它本身只是一个类库，也就是只有一个 Jar 文件，可以直接嵌入到 Java 项目中。H2 数据库又被称为内存数据库，因为它支持在内存中创建数据库和表。所以如果使用 H2 数据库的内存模式，那么创建的数据库和表都只是保存在内存中，一旦服务器重启，那么内存中的数据库和表将不存在了。 H2 优点 纯 Java 编写，不受平台的限制； 只有一个 Jar 文件，适合作为嵌入式数据库使用； H2 提供了一个十分方便的 Web 控制台用于操作和管理数据库； 功能完整，支持标准 SQL 和 JDBC，麻雀虽小五脏俱全； 支持内嵌模式、服务器模式和集群； H2 用途H2 主要有如下三个用途： 最常使用的用途就在于可以同应用程序一起打包发布，可以非常方便地存储少量的结构化数据； 可以用于单元测试，H2 启动速度快，而且可以关闭持久化功能，每一个用例执行完随即还原到初始状态； 可以作为缓存，即当内存数据库使用，作为 NoSQL 的一个补充。当某些场景下数据模型必须为关系型，可以拿它充当 Memcached 使用，作为后端 MySQL/Oracle 的一个缓冲层，缓存一些不经常变化但需要频繁访问的数据，比如字典表、权限表等。 H2 与其他数据库对比提示 完整的数据库对比图表请点击 这里 查看。 H2 的 3 种运行模式内嵌模式 (Embedded Mode)使用 JDBC 的本地连接。在内嵌模式下，应用程序和 H2 数据库处在同一个 JVM 中，应用程序通过 JDBC 连接数据库。内嵌模式可以实现持久化，但同一时刻只能有一个客户端连接数据库。内嵌模式是最快也是最容易的连接方式，性能也比较好。缺点是数据库无论什么时候，都只能在一个虚拟机（和类加载器）中打开。内嵌模式与所有模式一样，支持持久化和内存数据库。对并发打开数据库的数量或者打开连接的数量没有限制。 服务器模式 (Server Mode)使用 JDBC 或 ODBC 在 TCP/IP 基础上的远程连接。使用服务器模式和内嵌模式一样，只不过它可以跑在另一个进程里。服务器模式比内嵌模式慢，因为所有数据都通过 TCP/IP 协议传输。与所有模式一样，支持持久化和内存数据库。对每个数据库服务器并发打开的数据库数量或者打开连接的数量没有限制。 混合模式 (Mixed Mode)混合模式是内嵌模式和服务器模式的组合。混合模式集合了内嵌模式和服务模式的优点，使得数据库的性能和内嵌模式一样高，同时又支持多个应用同时连接同一个数据库。第一个应用通过内嵌模式与数据库建立连接，同时也作为一个独立的服务器启动，而其他的应用 (运行在不同的进程或是虚拟机上) 可以同时访问同样的数据库。第一个应用程序的本地连接与内嵌模式的连接性能一样快，而其它应用的连接性能理论上会差一点。H2 服务器可以从应用程序内（使用 H2 服务器的 API）启动或停止，或自动（自动混合模式）。当使用自动混合模式时，所有想要连接到数据库的客户端（无论是本地连接还是远程连接）都可以使用完全相同的数据库 URL 来实现连接。值得注意的是，H2 在混合模式下不支持内存数据库，即数据库必须持久化。 H2 的 3 种连接方式 第一种连接方式，以内嵌模式 (内存) 连接 H2 数据库。H2 支持在内存中创建数据库和表。特别注意，如果使用 H2 数据库的内存模式，那么创建的数据库和表都只是保存在内存中，一旦服务器重启，那么内存中的数据库和表就不存在了。 连接语法 连接示例 说明 jdbc:h2:mem:&lt;databaseName&gt; jdbc:h2:mem:testDb 数据库的数据只存在内存中 第二种连接方式，以内嵌模式 (本地文件) 连接 H2 数据库。这种连接方式在默认情况下，同一时刻只允许有一个客户端连接到 H2 数据库。当有客户端连接到 H2 数据库之后，此时数据库文件就会被锁定，那么其他客户端就无法再建立连接。 连接语法 连接示例 说明 jdbc:h2:[file:][&lt;path&gt;]&lt;databaseName&gt; jdbc:h2:~/testDb，连接位于当前用户目录下的 testDb 数据库 jdbc:h2:file:./testDb，连接位于当前程序所在目录下的 testDb 数据库 jdbc:h2:file:/h2/data/testDb，适用于 Linux 系统 jdbc:h2:file:E:/h2/data/testDb，适用于 Windows 系统 会将数据库的数据持久化到文件中 jdbc:h2:[file:][&lt;path&gt;]&lt;databaseName&gt;;AUTO_SERVER=TRUE jdbc:h2:~/testDb;AUTO_SERVER=TRUE jdbc:h2:file:./testDb;AUTO_SERVER=TRUE jdbc:h2:file:/h2/data/testDb;AUTO_SERVER=TRUE jdbc:h2:file:E:/h2/data/testDb;AUTO_SERVER=TRUE 启用混合模式，允许多个客户端同时连接同一个 H2 数据库，该参数不支持在内存中运行的 H2 数据库 第三种连接方式，使用支持 TCP/IP 的服务器模式 (远程连接) 连接 H2 数据库。这种连接方式和其他数据库的连接方式类似，是基于 Service 的形式进行连接的，因此允许多个客户端同时连接到 H2 数据库。 连接语法 连接示例 说明 jdbc:h2:tcp://&lt;server&gt;[:&lt;port&gt;]/[&lt;path&gt;]&lt;databaseName&gt; jdbc:h2:tcp://localhost/~/testDb jdbc:h2:ssl://&lt;server&gt;[:&lt;port&gt;]/[&lt;path&gt;]&lt;databaseName&gt; jdbc:h2:ssl://localhost/~/testDb 支持 SSL 连接 安装 H2 的 Web 控制台H2 的 Web 控制台是一个基于浏览器的 GUI 数据库管理工具，可以很方便地管理 H2 数据库。它的作用就相当于 PhpMyAdmin，一般情况下可以在开发环境启动 H2 的 Web 控制台。 H2 数据库下载地址可以在官网上选择一个版本进行下载，可以下载安装器或者直接下载软件包。这里建议选择 All Platforms 版本，因为解压文件后，既可用于 Windows 平台，也可用于 Linux 平台 (如下图所示)。 下载地址 http://www.h2database.com/html/main.html http://www.h2database.com/html/download.html http://www.h2database.com/html/download-archive.html H2 软件包目录结构1234567891011h2 |---bin | |---h2-2.1.214.jar //H2数据库的Jar包（驱动也在里面） | |---h2.bat //Windows控制台启动脚本 | |---h2.sh //Linux控制台启动脚本 | |---h2w.bat //Windows控制台启动脚本（不带黑屏窗口） |---docs //H2数据库的帮助文档（内有H2数据库的使用手册） |---service //通过Wrapper包装成服务 |---src //H2数据库的源代码 |---build.bat //Windows构建脚本 |---build.sh //Linux构建脚本 启动 H2 的 Web 控制台Linux 平台启动在 Linux 环境下，首先用 unzip 命令解压下载到的文件，然后在 bin 目录下，执行 h2.sh 来启动 H2 的 Web 控制台。值得一提的是，一般不建议这样直接启动，因为最好是带一些命令参数来启动 Web 控制台。 命令参数 说明 org.h2.tools.Shell 以终端方式启动 H2 的 Web 控制台，需要根据提示输入 DRIVER CLASS、URL、USER NAME、PASSWORD 等连接信息。以终端方式启动后，可以执行数据库的备份、还原、SQL 导出，SQL 导入等操作，详细教程请看 这里 org.h2.tools.Console 启动 H2 的 Web 控制台 org.h2.tools.Server 以服务器模式启动 H2 的 Web 控制台 -tcpAllowOthers 允许远程机器通过 TCP 方式访问数据库 -webAllowOthers 允许远程机器访问 H2 的 Web 控制台 -webPort 8082 指定 Web 控制台的访问端口，默认是 8082 -webSSL 启用 SSL 加密连接 在 bin 目录下创建新的启动脚本（如 h2_server.sh），内容如下（三种启动方式可以任意选择一种） 123#!/bin/shdir=$(dirname \"$0\")java -cp \"$dir/h2-2.1.214.jar:$H2DRIVERS:$CLASSPATH\" org.h2.tools.Shell \"$@\" 123#!/bin/shdir=$(dirname \"$0\")java -cp \"$dir/h2-2.1.214.jar:$H2DRIVERS:$CLASSPATH\" org.h2.tools.Console -webAllowOthers -webPort 8082 \"$@\" 123#!/bin/shdir=$(dirname \"$0\")java -cp \"$dir/h2-2.1.214.jar:$H2DRIVERS:$CLASSPATH\" org.h2.tools.Server -tcpAllowOthers -webAllowOthers -webPort 8082 \"$@\" 启动数据库服务 12345678# 新的启动脚本授权$ chmod +x h2_server.sh# 前台运行新的启动脚本$ bash h2_server.sh# 或者后台运行新的启动脚本$ nohup h2_server.sh &amp; 正常启动 Web 控制台（服务器模式）后，终端输出的日志信息如下 123Web Console server running at http://192.168.1.106:8082 (others can connect)TCP server running at tcp://192.168.1.106:9092 (others can connect)PG server running at pg://192.168.1.106:5435 (only local connections) Windows 平台启动进入到 H2 解压后的 bin 目录下，点击 h2.bat 或者 h2w.bat，直接运行软件。值得一提的是，点击 h2w.bat 后，此方式会在后台静默运行 H2 的 Web 控制台。 访问 H2 的 Web 控制台使用浏览器访问 H2 的 Web 控制台，URL 是 http://127.0.0.1:8082，也可以使用本机的 IP 地址（例如 http://192.168.1.106:8082） 使用 H2 的数据库创建 H2 数据库H2 成功启动后，在系统桌面底部的状态栏右下角会有一个黄色小图标（如下图红色箭头所指的位置） 可以在桌面状态栏右下角的黄色小图标处，右键点击 H2 控制台的图标，选择 Create a new database...，即可以创建一个新的数据库 出现如下窗口后，填写数据库文件的存放路径（例如 ~/demo，支持使用相对路径或者绝对路径）、访问数据库的用户名和密码，点击 Create 按钮，则会在用户目录下创建对应的数据库文件（例如 demo.mv.db） 提示 H2 数据库创建后，可能还会看到一个 demo.trace.db 文件，它是 H2 数据库的错误日志文件。 H2 数据库的文件名称 demo.mv.db，之所以里面有 mv，这是因为高版本的 H2 存储引擎默认为 mvStore。 连接 H2 数据库提示 H2 数据库连接成功后，会自动在用户目录下创建 .h2.server.properties 配置文件，用于保存数据库的历史连接信息。 用鼠标左键点击在桌面状态栏右下角的黄色小图标，此时会在浏览器打开 H2 的 Web 控制台界面（默认地址是 http://127.0.0.1:8082），填写 JDBC URL、用户名和密码后，点击 Connect 按钮就可以连接 H2 数据库 H2 数据库成功连接后，就会自动进入数据库的管理界面 输入 show databases; 和 show tables; SQL 语句，可以显示 H2 默认的数据库和表名 使用 H2 的 Web 控制台设置超级管理员密码H2 数据库连接成功后，会自动在用户目录下创建 .h2.server.properties 配置文件（如下），用于保存数据库的历史连接信息。因此，可以手动编辑 .h2.server.properties 配置文件，然后添加 webAdminPassword 参数来指定 H2 的超级管理员密码。 参数 说明 webAllowOthers 允许远程机器访问 H2 的 Web 控制台 webPort 指定 Web 控制台的访问端口，默认是 8082 webSSL 启用 SSL 加密连接 webAdminPassword 指定超级管理员密码 1234567891011121314151617181920212223242526webSSL=falsewebAdminPassword=adminwebAllowOthers=truewebPort=808210=Generic DB2|com.ibm.db2.jcc.DB2Driver|jdbc\\:db2\\://localhost/test|11=Generic Oracle|oracle.jdbc.driver.OracleDriver|jdbc\\:oracle\\:thin\\:@localhost\\:1521\\:XE|sa12=Generic MS SQL Server 2000|com.microsoft.jdbc.sqlserver.SQLServerDriver|jdbc\\:microsoft\\:sqlserver\\://localhost\\:1433;DatabaseName\\=sqlexpress|sa13=Generic MS SQL Server 2005|com.microsoft.sqlserver.jdbc.SQLServerDriver|jdbc\\:sqlserver\\://localhost;DatabaseName\\=test|sa14=Generic PostgreSQL|org.postgresql.Driver|jdbc\\:postgresql\\:test|15=Generic MySQL|com.mysql.cj.jdbc.Driver|jdbc\\:mysql\\://localhost\\:3306/test|16=Generic MariaDB|org.mariadb.jdbc.Driver|jdbc\\:mariadb\\://localhost\\:3306/test|17=Generic HSQLDB|org.hsqldb.jdbcDriver|jdbc\\:hsqldb\\:test;hsqldb.default_table_type\\=cached|sa18=Generic Derby (Server)|org.apache.derby.client.ClientAutoloadedDriver|jdbc\\:derby\\://localhost\\:1527/test;create\\=true|sa19=Generic Derby (Embedded)|org.apache.derby.iapi.jdbc.AutoloadedDriver|jdbc\\:derby\\:test;create\\=true|sa0=Generic JNDI Data Source|javax.naming.InitialContext|java\\:comp/env/jdbc/Test|sa1=Generic Teradata|com.teradata.jdbc.TeraDriver|jdbc\\:teradata\\://whomooz/|2=Generic Snowflake|com.snowflake.client.jdbc.SnowflakeDriver|jdbc\\:snowflake\\://accountName.snowflakecomputing.com|3=Generic Redshift|com.amazon.redshift.jdbc42.Driver|jdbc\\:redshift\\://endpoint\\:5439/database|4=Generic Impala|org.cloudera.impala.jdbc41.Driver|jdbc\\:impala\\://clustername\\:21050/default|5=Generic Hive 2|org.apache.hive.jdbc.HiveDriver|jdbc\\:hive2\\://clustername\\:10000/default|6=Generic Hive|org.apache.hadoop.hive.jdbc.HiveDriver|jdbc\\:hive\\://clustername\\:10000/default|7=Generic Azure SQL|com.microsoft.sqlserver.jdbc.SQLServerDriver|jdbc\\:sqlserver\\://name.database.windows.net\\:1433|8=Generic Firebird Server|org.firebirdsql.jdbc.FBDriver|jdbc\\:firebirdsql\\:localhost\\:c\\:/temp/firebird/test|sysdba9=Generic SQLite|org.sqlite.JDBC|jdbc\\:sqlite\\:test|sa20=Generic H2 (Server)|org.h2.Driver|jdbc\\:h2\\:tcp\\://localhost/~/test|sa21=Generic H2 (Embedded)|org.h2.Driver|jdbc\\:h2\\:~/demo|root 提示 若没有找到 .h2.server.properties 文件，以 Web-Server 方式首次启动 H2 后，浏览器打开 Web 控制台，点击 Save 按钮后就会自动创建对应的配置文件。 使用 H2 的配置界面使用浏览器访问 H2 的 Web 控制台，然后点击 Preferences，填写超级管理员密码后，就可以进入 H2 的配置界面 进入到 H2 的配置界面后，可以设置远程访问、端口号等信息 使用 H2 的工具界面使用浏览器访问 H2 的 Web 控制台，然后点击 Tools，填写超级管理员密码后，就可以进入 H2 的工具界面 进入 H2 的工具界面后，可以对 H2 数据库进行备份、还原、恢复、集群、运行脚本、删除文件等操作 H2 进阶使用第三方软件连接 H2 数据库H2 除了可以使用自身的 Web 控制台管理数据库之外，还可以使用 Navicat、DBeaver 这样的数据库软件来管理。这里以开源的 DBeaver 数据库管理软件举例，介绍如何使用第三方软件连接 H2 数据库。 在 DBeaver 的主界面新建数据库连接，数据库类型选择 H2 Embedded V.2，即使用内嵌模式连接 H2 数据库 特别注意 内嵌模式只允许有一个客户端连接 H2 数据库，可以简单理解为只允许有一个应用访问数据库文件。 如果 H2 数据库已经以服务器模式启动了，那么 DBeaver 的数据库类型可以选择 H2 Server，服务器模式支持多个客户端同时连接 H2 数据库。 填写 JDBC URL、用户名和密码，然后点击 测试连接 按钮或者 完成 按钮即可 成功连接 H2 数据库后，就可以看到之前创建的数据库表 附录以下表格是 H2 数据库在不同模式下的 URL 连接字串，参考自：H2 数据库使用简介 参考资料 H2 使用指南 H2 数据库使用简介 H2 内存数据库使用教程详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 数据库"},{"title":"Spring 注解驱动开发随笔","url":"/posts/542a9813.html","text":"var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 开发随笔"},{"title":"XXL-JOB 入门教程之二","url":"/posts/972c1f90.html","text":"大纲 XXL-JOB 入门教程之一 XXL-JOB 入门教程之二 前言 XXL 官方开源社区 XXL-JOB 官方文档 XXL-JOB 官方项目 体系架构XXL-JOB 框架中包含了两个核心模块：调度中心和执行器，其中调度中心（服务端）主要负责任务的调度，而执行器（客户端）负责任务的执行。v2.1.0 版本的架构图如下： 术语解释 术语 描述 执行器 真正执行调度任务的应用（客户端） 路由策略 路由的选择方式，即调度任务的分配规则，使用分片广播时，需要结合代码使用 Cron 定时任务的触发时间规则 运行模式 - Bean：执行器要执行指定的 Bean 对象的方式 - GLUE (Java)：以源码的方式来维护调度中心，相当于就是将调度中心变成一个执行器，每次调用运行指定的脚本 JobHandler 执行器执行的业务逻辑（调度任务） 子任务 ID 当前任务执行完之后，下一个所要执行任务的 ID（支持多个子任务） 任务超时时间 当执行任务的时间大于规定时间时，就算任务超时 阻塞处理策略 任务调度过于密集，执行器来不及处理时的处理策略，一共有三种阻塞处理策略- 单机串行：按顺序一个一个地执行完任务 - 丢弃后续调度：执行前一个任务，后面的调度任务全部丢弃，直到前一个任务执行完成 - 覆盖之前调度：后一个任务去覆盖前一个任务，前一个任务不再执行 代码下载本文的案例代码都可以在 这里 下载得到，直接作为 Maven 项目导入到 IDEA 或者 Eclipse 即可。 XXL-JOB 介绍调度中心的核心模块 模块名称 说明 定时模块 Scheduled 定时去获取任务调度的数据，数据存储在数据库中 路由模块 Route 一定的路由规则，负责计算出要指定的执行器 远程调用 RPC 通过远程调用执行执行器，将远程调用的信息发给执行器，信息包括哪个执行器，哪个任务 提示：执行器（客户端）中也有一个 RPC 用于通信，负责接收任务。 调度中心的执行流程 1、启动服务，将执行器注册到调度中心（注意每 30s 重新注册到调度中心） 2、在数据库中存储着执行器的数据，也可以手动地去录入执行器 3、配置调度中心、定时调度、配置路由规则 4、远程调用指定的执行器实例，找到对应的任务进行调用 调度中心的设计思想 将调度行为抽象形成 “调度中心” 公共平台，而平台自身并不承担业务逻辑，” 调度中心” 负责发起调度请求。 将任务抽象成分散的 JobHandler，交由 “执行器” 统一管理，” 执行器” 负责接收调度请求并执行对应的 JobHandler 中业务逻辑。因此，” 调度” 和 “任务” 两部分可以相互解耦，提高系统整体稳定性和扩展性。 调度模块（调度中心）：负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码。调度系统与任务解耦，提高了系统可用性和稳定性，同时调度系统性能不再受限于任务模块。 支持可视化、简单且动态的管理调度信息，包括任务新建、更新、删除、GLUE 开发和任务报警等，所有上述操作都会实时生效，同时支持监控调度结果以及执行日志，支持执行器 Failover。 执行模块（执行器）：负责接收调度请求并执行任务逻辑，任务模块专注于任务的执行等操作，开发和维护更简单和高效；接收 “调度中心” 的执行请求、终止请求和日志请求等。 提示：调度中心大体的架构设计图可查看 这里。 快速入门案例创建 POM 模块为了后续方便管理多个子模块，这里先创建 Maven 的 POM 模块 xxl-job-study，XML 配置文件的内容如下： 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.clay&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-study&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;modules&gt; &lt;module&gt;xxl-job-executor-spring&lt;/module&gt; &lt;module&gt;xxl-job-executor-springboot&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 基于 Spring 开发框架版本说明 框架 版本 Spring 5.3.23 XXL-JOB 2.4.0 项目目录结构 创建 Maven 子模块在 Maven 的 POM 模块中创建子模块 xxl-job-executor-spring，XML 配置文件的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.clay&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-study&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;xxl-job-executor-spring&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!-- xxl-job-core --&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring-mvc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.3.23&lt;/version&gt; &lt;/dependency&gt; &lt;!-- logback --&gt; &lt;dependency&gt; &lt;groupId&gt;org.logback-extensions&lt;/groupId&gt; &lt;artifactId&gt;logback-ext-spring&lt;/artifactId&gt; &lt;version&gt;0.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt; &lt;configuration&gt; &lt;archiveClasses&gt;false&lt;/archiveClasses&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建项目的配置文件创建执行器的配置文件在子模块的 /src/main/resources 目录下创建 xxl-job-executor.properties 配置文件。 123456789101112131415161718### 调度中心部署根地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行\"执行器心跳注册\"和\"任务结果回调\"；为空则关闭自动注册；xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin### 执行器通讯TOKENxxl.job.accessToken=default_token### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册xxl.job.executor.appname=xxl-job-executor-spring### 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。xxl.job.executor.address=### 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；地址信息用于 \"执行器注册\" 和 \"调度中心请求并触发任务\"；xxl.job.executor.ip=### 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；xxl.job.executor.port=9999### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler### 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；xxl.job.executor.logretentiondays=30 参数名称 参数说明 xxl.job.executor.appname 执行器的名称，建议使用 Maven 模块的名称 xxl.job.executor.address 执行器的注册地址，使用新版本（如 v2.4.0）时，必须带 HTTP/HTTPS 协议头，例如 http://127.0.0.1:9999 xxl.job.accessToken XXL-JOB 的访问令牌，只有调度中心和执行器双方的 AccessToken 互相匹配才允许通讯 特别注意 XXL-JOB 从 v.2.3.1 版本开始，调度通讯默认启用 AccessToken，且默认的 AccessToken 是 default_token。 创建 Spring 的配置文件在子模块的 /src/main/resources 目录下创建 applicationcontext-xxl-job.xml 配置文件，这里主要需要指定 JobHandler 的扫描路径。 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 读取执行器的配置信息 --&gt; &lt;bean id=\"propertyConfigurer\" class=\"org.springframework.context.support.PropertySourcesPlaceholderConfigurer\"&gt; &lt;property name=\"fileEncoding\" value=\"utf-8\"/&gt; &lt;property name=\"locations\"&gt; &lt;list&gt; &lt;value&gt;classpath*:xxl-job-executor.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置01、JobHandler 扫描路径 --&gt; &lt;context:component-scan base-package=\"com.clay.job.executor\"/&gt; &lt;!-- 配置02、执行器 --&gt; &lt;bean id=\"xxlJobSpringExecutor\" class=\"com.xxl.job.core.executor.impl.XxlJobSpringExecutor\"&gt; &lt;!-- 执行器注册中心地址[选填]，为空则关闭自动注册 --&gt; &lt;property name=\"adminAddresses\" value=\"${xxl.job.admin.addresses}\"/&gt; &lt;!-- 访问令牌[选填]，非空则进行匹配校验 --&gt; &lt;property name=\"accessToken\" value=\"${xxl.job.accessToken}\"/&gt; &lt;!-- 执行器AppName[选填]，为空则关闭自动注册 --&gt; &lt;property name=\"appname\" value=\"${xxl.job.executor.appname}\"/&gt; &lt;!-- 注册地址[选填]，优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址 --&gt; &lt;property name=\"address\" value=\"${xxl.job.executor.address}\"/&gt; &lt;!-- 执行器IP[选填]，为空则自动获取 --&gt; &lt;property name=\"ip\" value=\"${xxl.job.executor.ip}\"/&gt; &lt;!-- 执行器端口号[选填]，小于等于0则自动获取 --&gt; &lt;property name=\"port\" value=\"${xxl.job.executor.port}\"/&gt; &lt;!-- 执行器日志路径[选填]，为空则使用默认路径 --&gt; &lt;property name=\"logPath\" value=\"${xxl.job.executor.logpath}\"/&gt; &lt;!-- 日志保存天数[选填]，值大于3时生效 --&gt; &lt;property name=\"logRetentionDays\" value=\"${xxl.job.executor.logretentiondays}\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 创建 Logback 的配置文件在子模块的 /src/main/resources 目录下创建 logback.xml 配置文件。 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration debug=\"false\" scan=\"true\" scanPeriod=\"1 seconds\"&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;property name=\"log.path\" value=\"/data/applogs/xxl-job/xxl-job-executor-spring.log\"/&gt; &lt;appender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;${log.path}&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;${log.path}.%d{yyyy-MM-dd}.zip&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date %level [%thread] %logger{36} [%file : %line] %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"console\"/&gt; &lt;appender-ref ref=\"file\"/&gt; &lt;/root&gt;&lt;/configuration&gt; 创建 Web 容器的配置文件在子模块的 /src/main/webapp/WEB-INF 目录下创建 web.xml 配置文件。 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:web=\"http://java.sun.com/xml/ns/javaee\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" id=\"WebApp_ID\" version=\"2.5\"&gt; &lt;display-name&gt;xxl-job-executor-spring&lt;/display-name&gt; &lt;context-param&gt; &lt;param-name&gt;webAppRootKey&lt;/param-name&gt; &lt;param-value&gt;xxl-job-executor-spring&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- spring --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:applicationcontext-*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- logback --&gt; &lt;context-param&gt; &lt;param-name&gt;logbackConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:logback.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;ch.qos.logback.ext.spring.web.LogbackConfigListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;/web-app&gt; 创建自定义的执行器类123456789101112131415161718192021222324252627282930313233343536373839404142package com.clay.job.executor;import com.xxl.job.core.context.XxlJobHelper;import com.xxl.job.core.handler.annotation.XxlJob;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import java.util.concurrent.TimeUnit;/** * * XxlJob 执行器开发示例（Bean模式） * * 开发步骤： * 1、任务开发：在Spring Bean实例中，开发Job方法； * 2、注解配置：为Job方法添加注解 \"@XxlJob(value=\"自定义jobhandler名称\", init = \"JobHandler初始化方法\", destroy = \"JobHandler销毁方法\")\"，注解value值对应的是调度中心新建任务的JobHandler属性的值。 * 3、执行日志：需要通过 \"XxlJobHelper.log\" 打印执行日志； * 4、任务结果：默认任务结果为 \"成功\" 状态，不需要主动设置；如有诉求，比如设置任务结果为失败，可以通过 \"XxlJobHelper.handleFail/handleSuccess\" 自主设置任务结果； * * @author clay */@Componentpublic class CustomJobExecutor { private static final Logger logger = LoggerFactory.getLogger(CustomJobExecutor.class); /** * 简单任务示例（Bean模式） */ @XxlJob(value = \"sampleJobHandler\") public void sampleJobHandler() throws Exception { XxlJobHelper.log(\"XXL-JOB, Hello World.\"); for (int i = 0; i &lt; 5; i++) { XxlJobHelper.log(\"beat at:\" + i); TimeUnit.SECONDS.sleep(2); } XxlJobHelper.handleSuccess(); }} 部署应用到 Tomcat 服务器 测试任务调度代码启动调度中心服务 IDEA 运行 XXL-JOB 调度中心 Docker 安装 XXL-JOB 调度中心 调度中心添加执行器登录 XXL-JOB 调度中心的管理页面，添加自定义的执行器信息，这里的 AppName 是在 xxl-job-executor.properties 配置文件中使用 xxl.job.executor.appname 参数指定的。 确定执行器自动注册成功 ，添加执行器后一般需要等待 10 秒左右。 特别注意 XXL-JOB 使用新版本（如 v2.4.0）时，如果添加执行器选择的是手动录入模式，那么此时填写的机器地址必须是带 HTTP/HTTPS 协议头（例如 http://127.0.0.1:9999），否则后续添加的调度任务无法正常执行。 调度中心添加调度任务这里的 JobHandler 配置内容，是在自定义的执行器类里使用 @XxlJob 注解的 value 属性指定。 调度中心启动调度任务 查看任务调度日志信息 基于 SpringBoot 开发框架版本说明 框架 版本 Spring Boot 2.7.9 XXL-JOB 2.4.0 项目目录结构 创建 Maven 子模块在 Maven 的 POM 模块中创建子模块 xxl-job-executor-springboot，XML 配置文件的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.clay&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-study&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;xxl-job-executor-springboot&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;xxl-job.version&gt;2.4.0&lt;/xxl-job.version&gt; &lt;spring-boot.version&gt;2.7.9&lt;/spring-boot.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- xxl-job-core --&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt; &lt;version&gt;${xxl-job.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring-webmvc + tomcat --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 编写 Java 项目代码创建应用的主启动类12345678910111213141516package com.clay.job.executor;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @author clay */@SpringBootApplicationpublic class XxlJobExecutorApplication { public static void main(String[] args) { SpringApplication.run(XxlJobExecutorApplication.class, args); }} 创建 XXL-JOB 的配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.clay.job.executor.config;import com.xxl.job.core.executor.impl.XxlJobSpringExecutor;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author clay */@Configurationpublic class XxlJobConfig { private static final Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(\"${xxl.job.admin.addresses}\") private String adminAddresses; @Value(\"${xxl.job.accessToken}\") private String accessToken; @Value(\"${xxl.job.executor.appname}\") private String appname; @Value(\"${xxl.job.executor.address}\") private String address; @Value(\"${xxl.job.executor.ip}\") private String ip; @Value(\"${xxl.job.executor.port}\") private int port; @Value(\"${xxl.job.executor.logpath}\") private String logPath; @Value(\"${xxl.job.executor.logretentiondays}\") private int logRetentionDays; @Bean public XxlJobSpringExecutor xxlJobExecutor() { logger.info(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.\"); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppname(appname); xxlJobSpringExecutor.setAddress(address); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } /** * 针对多网卡、容器内部署等情况，可借助 \"spring-cloud-commons\" 提供的 \"InetUtils\" 组件灵活定制注册IP； * * 1、引入依赖： * &lt;dependency&gt; * &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; * &lt;artifactId&gt;spring-cloud-commons&lt;/artifactId&gt; * &lt;version&gt;${version}&lt;/version&gt; * &lt;/dependency&gt; * * 2、配置文件，或者容器启动变量 * spring.cloud.inetutils.preferred-networks: 'xxx.xxx.xxx.' * * 3、获取IP * String ip_ = inetUtils.findFirstNonLoopbackHostInfo().getIpAddress(); */} 创建 XXL-JOB 的执行器类123456789101112131415161718192021222324252627282930313233343536373839404142package com.clay.job.executor.jobhandler;import com.xxl.job.core.context.XxlJobHelper;import com.xxl.job.core.handler.annotation.XxlJob;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import java.util.concurrent.TimeUnit;/** * * XxlJob 执行器开发示例（Bean模式） * * 开发步骤： * 1、任务开发：在Spring Bean实例中，开发Job方法； * 2、注解配置：为Job方法添加注解 \"@XxlJob(value=\"自定义jobhandler名称\", init = \"JobHandler初始化方法\", destroy = \"JobHandler销毁方法\")\"，注解value值对应的是调度中心新建任务的JobHandler属性的值。 * 3、执行日志：需要通过 \"XxlJobHelper.log\" 打印执行日志； * 4、任务结果：默认任务结果为 \"成功\" 状态，不需要主动设置；如有诉求，比如设置任务结果为失败，可以通过 \"XxlJobHelper.handleFail/handleSuccess\" 自主设置任务结果； * * @author clay */@Componentpublic class CustomJobExecutor { private static final Logger logger = LoggerFactory.getLogger(CustomJobExecutor.class); /** * 简单任务示例（Bean模式） */ @XxlJob(value = \"sampleJobHandler\") public void sampleJobHandler() throws Exception { XxlJobHelper.log(\"XXL-JOB, Hello World.\"); for (int i = 0; i &lt; 5; i++) { XxlJobHelper.log(\"beat at:\" + i); TimeUnit.SECONDS.sleep(2); } XxlJobHelper.handleSuccess(); }} 创建项目配置文件创建日志配置文件1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration debug=\"false\" scan=\"true\" scanPeriod=\"1 seconds\"&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;property name=\"log.path\" value=\"/data/applogs/xxl-job/xxl-job-executor-springboot.log\"/&gt; &lt;appender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;${log.path}&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;${log.path}.%d{yyyy-MM-dd}.zip&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date %level [%thread] %logger{36} [%file : %line] %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"console\"/&gt; &lt;appender-ref ref=\"file\"/&gt; &lt;/root&gt;&lt;/configuration&gt; 创建 SpringBoot 配置文件123456789101112131415161718192021222324# 端口server.port=8089# 日志配置logging.config=classpath:logback.xml### 调度中心部署根地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行\"执行器心跳注册\"和\"任务结果回调\"；为空则关闭自动注册；xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin### 执行器通讯TOKENxxl.job.accessToken=default_token### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册xxl.job.executor.appname=xxl-job-executor-springboot### 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。xxl.job.executor.address=### 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；地址信息用于 \"执行器注册\" 和 \"调度中心请求并触发任务\"；xxl.job.executor.ip=### 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；xxl.job.executor.port=9999### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler### 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；xxl.job.executor.logretentiondays=30 参数名称 参数说明 xxl.job.executor.appname 执行器的名称，建议使用 Maven 模块的名称 xxl.job.executor.address 执行器的注册地址，使用新版本（如 v2.4.0）时，必须带 HTTP/HTTPS 协议头，例如 http://127.0.0.1:9999 xxl.job.accessToken XXL-JOB 的访问令牌，只有调度中心和执行器双方的 AccessToken 互相匹配才允许通讯 特别注意 XXL-JOB 从 v.2.3.1 版本开始，调度通讯默认启用 AccessToken，且默认的 AccessToken 是 default_token。 测试任务调度代码启动调度中心服务 IDEA 运行 XXL-JOB 调度中心 Docker 安装 XXL-JOB 调度中心 调度中心添加执行器登录 XXL-JOB 调度中心的管理页面，添加自定义的执行器信息，这里的 AppName 是在 application.properties 配置文件中使用 xxl.job.executor.appname 参数指定的。 确定执行器自动注册成功 ，添加执行器后一般需要等待 10 秒左右。 特别注意 XXL-JOB 使用新版本（如 v2.4.0）时，如果添加执行器选择的是手动录入模式，那么此时填写的机器地址必须是带 HTTP/HTTPS 协议头（例如 http://127.0.0.1:9999），否则后续添加的调度任务无法正常执行。 调度中心添加调度任务这里的 JobHandler 配置内容，是在自定义的执行器类里使用 @XxlJob 注解的 value 属性指定。 调度中心启动调度任务 查看任务调度日志信息 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"分布式"},{"title":"Docker 安装 XXL-JOB","url":"/posts/b7f83596.html","text":"前言 XXL 官方开源社区 XXL-JOB 官方文档 XXL-JOB 官方项目 初始化数据库在 MySQL 执行 XXL-JOB GitHub 仓库中的 SQL 初始化脚本，初始化完成后一共有 8 张表。 表名称 描述 xxl_job_group 执行器信息表，用于维护任务执行器的信息 xxl_job_info 调度扩展信息表，用于存储调度任务的扩展信息，比如任务分组、任务名、机器的地址等 xxl_job_lock 任务调度锁表 xxl_job_log 日志表，用于存储任务调度的历史信息，例如调度结果、执行结果、调度入参等 xxl_job_log_report 日志报表，用于存储任务调度的日志报表，会在调度中心里的报表功能里使用到 xxl_job_logglue 任务的 GLUE 日志，用于存储 GLUE 日志的更新历史变化，支持 GLUE 版本的回溯功能 xxl_job_registry 执行器的注册表，用在维护在线的执行器与调度中心的地址信息 xxl_job_user 系统的用户表，可以用表中默认的用户名与密码进行登录 XXL-JOB 安装拉取镜像12345# 最新版本$ docker pull xuxueli/xxl-job-admin# 或者指定版本号（推荐）$ docker pull xuxueli/xxl-job-admin:2.3.1 启动容器监听端口XXL-JOB 启动后默认会监听 8080 端口，用于 Admin 的 HTTP 服务。 自定义参数 GitHub 仓库中的配置项参考文件：/xxl-job/xxl-job-admin/src/main/resources/application.properties 如需自定义 JVM 内存参数等配置，可通过 Docker 的 -e JAVA_OPTS 指定，参数格式 -e JAVA_OPTS=\"-Xmx512m\" 如需自定义 MySQL 等配置，可通过 Docker 的 -e PARAMS 指定，参数格式 -e PARAMS=\"--key=value --key2=value2\" Docker 启动12345docker run -e PARAMS=\"--server.port=8080 --spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?characterEncoding=UTF-8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=root --xxl.job.accessToken=default_token\" \\-p 8080:8080 \\-v /tmp/logs:/data/applogs \\--name xxl-job-admin \\-d xuxueli/xxl-job-admin:2.3.1 请自行更改 MySQL 数据库的连接信息，例如 IP、用户名和密码。 Docker-Compose 启动12345678910111213version: '3.5'services: xxl-job: image: xuxueli/xxl-job-admin:2.3.1 container_name: xxl-job-admin restart: always volumes: - /tmp/logs:/data/applogs environment: - \"PARAMS=--server.port=8080 --spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?characterEncoding=UTF-8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=root --xxl.job.accessToken=default_token\" ports: - 8080:8080 请自行更改 MySQL 数据库的连接信息，例如 IP、用户名和密码。 登录控制台浏览器访问 http://127.0.0.1:8080/xxl-job-admin，默认登录的账号密码是 admin / 123456。 访问令牌配置为了提升系统的安全性，可要求任务调度中心和执行器进行安全性校验，双方的 AccessToken 匹配才允许通讯。任务调度中心和执行器，均可通过配置项 xxl.job.accessToken 进行 AccessToken 的设置。 启动 Docker 容器时，可以通过 -e PARAMS 指定 AccessToken 12345docker run -e PARAMS=\"--server.port=8080 --spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?characterEncoding=UTF-8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=root --xxl.job.accessToken=default_token\" \\-p 8080:8080 \\-v /tmp/logs:/data/applogs \\--name xxl-job-admin \\-d xuxueli/xxl-job-admin:2.3.1 在 SpringBoot 项目中，可以使用以下内容配置执行器的 AccessToken 12345xxl: job: accessToken: default_token admin: addresses: http://127.0.0.1:8080/xxl-job-admin 提示，如果任务调度中心和执行器要实现正常通讯，只有两种设置 第一种：任务调度中心和执行器，设置了相同的 AccessToken。 第二种：任务调度中心和执行器，均不设置 AccessToken，即关闭安全性校验。 特别注意：XXL-JOB 从 v.2.3.1 版本开始，调度通讯默认启用 AccessToken，且默认的 AccessToken 是 default_token。 更改登录密码XXL-JOB 的用户密码采用 MD5 算法 32 位小写加密。由于 MD5 是摘要算法，不可逆向的，每次登录时需要将密码通过相同的 MD5 算法加密后对比数据库是否一致，所以想修改密码只能修改数据库表的字段值。使用下述 Java 代码将新密码通过 MD5 算法加密，然后更改到数据库的 xxl_job_user 表即可。 特别注意 如果修改的新密码在加密前长度超过 18 位，仍然会登录失败，原因是 XXL-JOB 的前端页面对输入框输入的密码做了截取，只保留了 18 位字符并传到后端，因此会导致输入正确的密码后仍然登录失败，因此新密码的最大长度只支持 18 位。 12345678910import org.springframework.util.DigestUtils;public class PasswordEncoderUtil { public static void main(String[] args) { String password = DigestUtils.md5DigestAsHex(\"newPassword\".getBytes()); System.out.println(password); }} 参考博客 XXL-JOB 的 Docker 部署与接入教程 XXL-JOB 访问令牌（AccessToken）设置 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化"},{"title":"XXL-JOB 入门教程之一","url":"/posts/acac3139.html","text":"大纲 XXL-JOB 入门教程之一 XXL-JOB 入门教程之二 前言 XXL 官方开源社区 XXL-JOB 官方文档 XXL-JOB 官方项目 什么是任务调度任务调度就是我们常说的定时任务，定时任务是指在指定时间、指定的频率去执行任务（业务代码）。任务调度是日常开发中非常常见的一个业务场景，我们经常需要去运行一些的周期性、指定时间点等方式自动触发的异步业务逻辑。 集中式任务调度集中式任务是与分布式任务恰好相反的概念，集中式任务就是单机任务，一个项目，一台机器，也就是我们常说的单体应用。对于集中式任务，也就是我们 Java 开发中常见的定时任务。 集中式任务调度的问题如果采用集中式的任务调度方式，在分布式集群部署的模式下会带来一些问题，比如： 多台机器集群部署的定时任务如何保证不被重复执行？ 如何动态地调整定时任务的执行时间（不重启服务的情况下）？ 部署定时任务的机器发生故障时，如何实现故障转移？ 如何对定时任务的执行情况进行监控？ 业务量较大，单机遭遇性能瓶颈问题，任务调度如何扩展？ 集中式任务调度的缺点 不支持分片任务：处理有序数据时，多机器分片执行任务处理不同数据。 不支持生命周期统一管理：不重启服务的情况下关闭、启动任务。 不支持集群：存在任务重复执行的问题。 不支持失败重试：出现异常后任务终结，不能根据执行状态控制任务重新执行。 不支持动态调整：在不重启服务的情况下，动态修改任务参数。 不支持报警机制：在任务执行失败之后，没有报警机制。 不支持任务数据统计：在任务数据量大时，对于任务执行情况无法高效地统计执行情况。 Java 实现集中式任务调度的方式 实现方式 说明 while (true) + Thread.sleep 轮询 + 线程休眠的方式实现定时任务（最古老的方法） java.util.Timer + java.util.TimerTask Timer 是一种定时器工具，用来在一个后台线程按计划执行指定任务，它可以按计划执行一个任务一次或反复多次。TimerTask 是一个抽象类，它的子类代表一个可以被 Timer 计划的任务。 ScheduledExecutorService 从 JDK 1.5 开始，ScheduledExecutorService 做为并发工具类被引入，是最理想的定时任务实现方式 Quartz Quartz 是一个开源的定时任务调度框架，由 Java 编写而成，用于 Java 生态下的定时任务调度，是一个灵活方便、使用简单的定时任务调度框架，可以和 Spring 整合使用 Spring Task Spring 框架从 3.0 版本开始提供的轻量级的定时任务调用工具，使用起来很方便 Spring Boot 注解 @EnableScheduling + @Scheduled 底层依然是采用 Spring Task 来实现任务调度 分布式任务调度分布式任务调度的优点 高可用。在集群架构下，有节点出现异常，不影响任务的执行。 动态配置。对任务的执行周期，以及其他跟任务相关的属性不停机修改。 生命周期管理。可以在不停机的情况下，对任务单次执行启动任务，关闭任务的管理。 失败机制。在任务执行过程中出现执行失败时，支持报警、任务重试并快速查阅执行日志。 数据统计。在定时任务数比较多的情况下，支持统计一共有多少任务，哪些任务执行失败过，哪些任务执行成功。 分片执行。对于批量处理的数据，让多台机器执行该任务，对数据进行分片处理。 分布式任务调度解决方案由于集中式的定时任务调度需要解决一系列问题，所以在技术演进的过程中产生一些解决办法： 使用数据库唯一约束 使用配置文件、Redis、MySQL 作为任务调度的开关 使用分布式锁实现任务调度的并发控制 使用开源的分布式任务调度平台 TBSchedule、Elastic-Job、Saturn、XXL-JOB 等 自研分布式任务调度平台 分布式任务调度开源框架XXL-JOBXXL-JOB 是美团开源的轻量级分布式任务调度平台，其核心设计目标是轻量级、易扩展、开发迅速、开箱即用，已有多家公司线上产品线采用了 XXL-JOB。 Elastic-JobElastic-Job 是当当网推出的分布式任务调度框架，现在已经被纳入到 Apache 基金会下，很多公司的产品都在使用该分布式任务调度框架。 PowerJobPowerJob 是新一代分布式任务调度与计算框架，支持 CRON、API、固定频率、固定延迟等调度策略，提供工作流来编排任务解决依赖关系，使用简单，功能强大。 SaturnSaturn 唯品会推出的开源分布式任务调度平台，它是基于 Elastic-Job 而开发的，新增了一些特性，唯品会内部及一些互联网公司都在使用，但目前项目处于停止维护的状态。 IDEA 运行 XXL-JOB 调度中心XXL-JOB 由调度中心（服务端）和执行器（客户端）两个核心模块组成，因此一般需要先运行调度中心的服务，然后再开发执行器（客户端）的业务代码。 下载源码项目12345# GitHub$ git clone https://github.com/xuxueli/xxl-job.git# Gitee$ git clone https://github.com/xuxueli/xxl-job.git 导入源码项目将源码项目导入到 IDEA 中，方便快速启动 XXL-JOB 的调度中心和阅读底层源码。 初始化数据库为了初始化调度中心的数据库，需要在数据库里执行源码项目中的 SQL 脚本，文件路径是 /xxl-job/doc/db/tables_xxl_job.sql。值得一提的是，数据库初始化完成之后，一共有 8 张表。 表名称 描述 xxl_job_group 执行器信息表，用于维护任务执行器的信息 xxl_job_info 调度扩展信息表，用于存储调度任务的扩展信息，比如任务分组、任务名、机器的地址等 xxl_job_lock 任务调度锁表 xxl_job_log 日志表，用于存储任务调度的历史信息，例如调度结果、执行结果、调度入参等 xxl_job_log_report 日志报表，用于存储任务调度的日志报表，会在调度中心里的报表功能里使用到 xxl_job_logglue 任务的 GLUE 日志，用于存储 GLUE 日志的更新历史变化，支持 GLUE 版本的回溯功能 xxl_job_registry 执行器的注册表，用在维护在线的执行器与调度中心的地址信息 xxl_job_user 系统的用户表，可以用表中默认的用户名与密码进行登录 更改配置信息打开 xxl-job-admin 模块下的 application.properties 配置文件，更改数据库的连接信息。 12345### xxl-job, datasourcespring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=Asia/Shanghaispring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver 启动调度中心打开 xxl-job-admin 模块下的 XxlJobAdminApplication 主启动类，在 IDEA 内直接启动调度中心的服务。 登录调度中心浏览器访问 http://127.0.0.1:8080/xxl-job-admin，默认登录的账号密码是 admin / 123456。 提示 若浏览器能正常访问调度中心的管理页面，则说明 XXL-JOB 的调度中心启动成功。 XXL-JOB 调度中心的前端页面使用了 AdminLTE 框架，它是一个基于 Bootstrap 框架和 jQuery 插件的开源的管理模板工具，提供了一系列响应迅速的、可重复使用的组件，并设置了许多模板页面。 Docker 运行 XXL-JOB 调度中心 Docker 安装 XXL-JOB var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"分布式"},{"title":"Maven 激活 SpringBoot 配置文件","url":"/posts/82a430bf.html","text":"前言为了实现不同环境构建的不同需求，这里使用到了 Maven 的 Profile 特性。因为 Profile 能够在构建时修改 POM 的一个子集，或者添加额外的配置元素。接下来将介绍 Maven 中对 Profile 的配置和激活。 Maven 配置1234567891011121314151617181920212223242526272829303132333435363738394041&lt;build&gt; &lt;finalName&gt;${project.name}&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt;&lt;project&gt; &lt;!--多环境配置--&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;!-- 环境标识，需要与配置文件的名称相对应 --&gt; &lt;profiles.active&gt;dev&lt;/profiles.active&gt; &lt;nacos.username&gt;nacos&lt;/nacos.username&gt; &lt;nacos.password&gt;nacos&lt;/nacos.password&gt; &lt;/properties&gt; &lt;activation&gt; &lt;!-- 是否为默认环境 --&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;!-- 环境标识，需要与配置文件的名称相对应 --&gt; &lt;profiles.active&gt;prod&lt;/profiles.active&gt; &lt;nacos.username&gt;admin&lt;/nacos.username&gt; &lt;nacos.password&gt;admin&lt;/nacos.password&gt; &lt;/properties&gt; &lt;activation&gt; &lt;!-- 是否为默认环境 --&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt; SpringBoot 配置在 SpringBoot 项目的 application.yml 配置文件中，可以通过 @属性名@ 的格式获取在 &lt;profile&gt; 标签中定义的属性值，同时还可以通过 @profiles.active@ 的格式来获取当前被激活的 Profile 的 Id 属性。 配置案例一123spring: profiles: active: @profiles.active@ 配置案例二在下述的例子中，使用 Nacos 作为配置中心，当 Maven 激活不同的 Profile 时，Nacos 的客户端会从配置中心拉取 Profile 对应的配置信息。 1234567891011121314151617181920server: port: 9091spring: application: name: @artifactId@ cloud: nacos: username: @nacos.username@ password: @nacos.password@ discovery: server-addr: ${NACOS_HOST:shop-register}:${NACOS_PORT:8848} config: server-addr: ${spring.cloud.nacos.discovery.server-addr} extension-configs[0]: data-id: shop-application-@profiles.active@.yml refresh: true extension-configs[1]: data-id: @artifactId@-@profiles.active@.yml refresh: true 无法解析 @ 符号若使用了上述的 SpringBoot 配置内容后，在 IDEA 内启动项目时，提示 @...@ 的内容无法解析，可以按照以下步骤解决。 第一步：在 POM 里添加 Maven 插件 12345678910111213141516171819202122232425262728&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;configuration&gt; &lt;delimiters&gt;@&lt;/delimiters&gt; &lt;useDefaultDelimiters&gt;false&lt;/useDefaultDelimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/build&gt; 第二步：先执行 Maven 的编译命令，再让 IDEA 启动项目 1$ mvn clean install Maven 激活配置 当打包项目时，可以在 Maven 的命令行中添加参数 -P，指定要激活的 Profile 的 Id，这样就可以激活不同的环境配置。 1$ mvn clean package -Pdev 如果一次要激活多个 Profile，可以用逗号分开一起激活 1$ mvn clean package -Pdev,test 若希望查看当前默认激活的是哪个 Profile，可以使用以下命令 1$ mvn help:active-profiles Maven 读取系统环境变量在 Linux 系统环境中，Maven 可以使用 ${env.xxxx} 的格式读取到系统的环境变量，使用示例如下： 12345678910111213141516171819202122232425262728293031&lt;project&gt; &lt;!--多环境配置--&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;!-- 环境标识，需要与配置文件的名称相对应 --&gt; &lt;profiles.active&gt;dev&lt;/profiles.active&gt; &lt;nacos.username&gt;nacos&lt;/nacos.username&gt; &lt;nacos.password&gt;nacos&lt;/nacos.password&gt; &lt;/properties&gt; &lt;activation&gt; &lt;!-- 是否为默认环境 --&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;!-- 环境标识，需要与配置文件的名称相对应 --&gt; &lt;profiles.active&gt;prod&lt;/profiles.active&gt; &lt;nacos.username&gt;${env.NACOS_USERNAME}&lt;/nacos.username&gt; &lt;nacos.password&gt;${env.NACOS_PASSWORD}&lt;/nacos.password&gt; &lt;/properties&gt; &lt;activation&gt; &lt;!-- 是否为默认环境 --&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt; 参考资料 Maven 构建配置和激活 SpringBoot 配置文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java"},{"title":"Nacos 开发随笔","url":"/posts/85aa5d65.html","text":"配置内存大小配置参数 JVM 参数 说明 JVM_XMS=512m -Xms - JVM 启动时分配的内存大小 JVM_XMX=512m -Xmx - JVM 运行过程中分配的最大内存大小 JVM_XMN=256m -Xmn - JVM 堆内存中新生代的大小 配置方式 第一种方式，启动 Docker 容器时指定 JVM 参数 1docker run --name nacos-standalone -e MODE=standalone -e JVM_XMS=512m -e JVM_XMX=512m -e JVM_XMN=256m -p 8848:8848 -d nacos/nacos-server:latest 第二种方式，在 Nacos 的 Env 配置文件中添加 JVM 参数 123456PREFER_HOST_MODE=hostnameMODE=standaloneSPRING_DATASOURCE_PLATFORM=mysqlJVM_XMS=512mJVM_XMX=512mJVM_XMN=256m 更改登录密码 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 通过 BCryptPasswordEncoder 类生成新的密码，注意盐值是随机的，所以生成的密码每次都可能不一样，请不要担心 12345678910import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;public class PasswordEncoderUtil { public static void main(String[] args) { // 每次生成的密码都可能不一样 System.out.println(new BCryptPasswordEncoder().encode(\"newPassword\")); }} 更改 Nacos 的 users 表，指定新的密码 若是添加新的 Nacos 用户，可以参考以下 SQL 语句 12INSERT INTO users (username, password, enabled) VALUES ('admin', '$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu', TRUE);INSERT INTO roles (username, role) VALUES ('admin', 'ROLE_ADMIN'); var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 开发随笔"},{"title":"快乐 8 购买攻略","url":"/posts/b99b3e39.html","text":"var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"彩票竞猜"},{"title":"双色球购买攻略","url":"/posts/6be8d9e3.html","text":"开奖日期 开奖时间： 21:15 开奖日期： 每周二、四、日 截止停售时间： 开奖日期的 20:00 购买规则双色球 每注投注号码由 6 个红色球号码和 1 个蓝色球号码组成。红色球号码从 1 ~ 33 中选择，蓝色球号码从 1 ~ 16 中选择。每注基本投注金额人民币为 2 元。 购彩攻略 1、增加购买彩票的数量：这会提高中奖的机会，但同时也会增加投入的成本。 2、避免常见的号码组合：比如选择连号、同尾数、同奇偶等常见组合，因为这些号码容易被别人选择，中奖的概率也会降低。 3、购买多种号码组合：通过购买多种号码组合，可以增加中奖的机会。但是，这也会增加成本。 4、参与合买：加入合买团队可以增加中奖的概率，但是奖金也需要与其他参与者分享。 5、选择冷门号码：通常人们会倾向于选择热门号码，也就是经常出现的号码，但这样的号码也会有很多人选择，导致最终的奖金分配比较平均。选择一些较为冷门的号码，虽然中奖的概率较低，但是如果中奖的话，奖金可能会更高。 请注意，彩票是一种纯粹的随机游戏，没有任何策略可以保证中奖。所以，玩彩票应该理性看待，量力而行。 中奖规则 中奖概率 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"彩票竞猜"},{"title":"超级大乐透购买攻略","url":"/posts/2ad61463.html","text":"开奖日期 开奖时间： 21:25 开奖日期： 每周一、三、六 截止停售时间： 开奖日期的 21:00 购买规则超级大乐透 基本投注是指从前区号码中任选 5 个号码，并从后区号码中任选 2 个号码的组合进行投注。其中，前区号码由 1 ~ 35 号码组成，后区号码由 1 ~ 12 号码组成。每注基本投注金额人民币为 2 元。 购买攻略 1、购买更多的彩票：这会增加中奖的机会，但是也意味着需要投入更多的资金。 2、选择冷门号码：冷门号码是指在过去的开奖中出现频率较低的号码，虽然中奖概率较低，但如果中奖可以获得较高的奖金。 3、使用统计学方法：通过分析历史开奖数据，利用统计学方法预测下一期的中奖号码，例如数学公式、遗漏数据、走势图等。 4、参加合买：合买是指多人共同购买彩票，增加了中奖的机会，但中奖奖金需要分配给所有参与者。 5、选择热门号码：热门号码是指在过去的开奖中出现频率较高的号码，可以通过分析历史开奖数据来选择热门号码，但这样的号码也会有很多人选择，导致最终的奖金分配比较平均。 请注意，彩票是一种纯粹的随机游戏，没有任何策略可以保证中奖。所以，玩彩票应该理性看待，量力而行。 中奖规则 中奖概率 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"彩票竞猜"},{"title":"ChatGPT 资源汇总","url":"/posts/78bfedfa.html","text":"网站资源 名称 网址 描述 GPT-3 Demo https://gpt3demo.com/ ChatGPT, AI and GPT-3 Apps and use cases var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"ai"},{"title":"JMeter 压测教程之二 JVM 调优","url":"/posts/e0671e6d.html","text":"大纲 JMeter 压测教程之一基础使用 JMeter 压测教程之二 JVM 调优 JVM 简单介绍JVM 内存结构JVM 内存结构主要有三大块：栈、堆内存、方法区。堆内存是 JVM 中最大的一块。方法区存储类信息、静态变量、常量、常量池等数据，是线程共享的区域，为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。栈又分为 Java 虚拟机栈和本地方法栈，主要用于方法的执行。 JVM 堆内存所有的对象实例以及数组都要在堆内存上分配，堆内存是垃圾收集器管理的主要区域，也被称为 GC 堆。堆内存由新生代和老年代组成，不包括永久代（方法区）；而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间，默认情况下新生代按照 8:1:1 的比例来分配。 提示 从 Java 8 开始，HotSpot 已经完全将永久代（Permanent Generation）移除，取而代之的是一个新的区域 — 元空间（MetaSpace）。 JVM 性能监控为了方便监控 JVM 的性能，JDK 提供了 jconsole、jvisualvm 工具，两者都可以通过命令行直接启动，支持监控本地和远程应用。值得一提的是，推荐使用 jvisualvm，因为它可以看作是升级版的 jconsole。 Jconsole 监控启动监控 启动命令 1$ jconsole 运行界面 Jvisualvm 监控jvisualvm 可以监控内存泄露、跟踪垃圾回收、执行时内存分析、CPU 分析、线程分析等。 启动监控 启动命令 1$ jvisualvm 运行界面 安装插件为了方便查看 GC 的情况，jvisualvm 需要提前安装指定的插件。 第一步：查看 JDK 版本 1$ java -version 第二步：浏览器打开 官方插件中心 的页面，根据 JDK 版本找到 Java VisualVM 的更新链接，例如 https://visualvm.github.io/archive/uc/8u40/updates.xml.gz 第三步：菜单栏导航到 工具 -&gt; 插件 -&gt; 设置，点击 编辑 按钮，将 URL 更改为上面找到的 Java VisualVM 更新链接 第四步：菜单栏导航到 工具 -&gt; 插件 -&gt; 可用插件，点击 检查最新版本 按钮，等插件列表更新成功后，勾选 Visual GC 项，最后点击 安装 按钮即可。 第六步：重启 jvisualvm 后，选择要监控的应用，若在标签页中看到 Visual GC 页面，则说明 GC 插件安装成功。 性能监控指标中间件指标常用的中间件（如 Tomcat、Weblogic）监控指标，主要包括 JVM、ThreadPool、JDBC 等，具体如下： 当前正在运行的线程数不能超过设定的最大值。一般情况下系统性能较好的情况下，线程数最小值设置为 50 和最大值设置为 200 比较合适。 当前运行的 JDBC 连接数不能超过设定的最大值。一般情况下系统性能较好的情况下，JDBC 最小值设置为 50 和最大值设置为 200 比较合适。 GC 频率不能频繁，特别是 FULL GC 更不能频繁，一般情况下系统性能较好的情况下，JVM 最小堆大小和最大堆大小分别设置 1024M 比较合适。 数据库指标常用的数据库（如 MySQL）监控指标，主要包括 SQL 性能、吞吐量、缓存命中率、锁、连接数等，具体如下： SQL 执行耗时越小越好，一般情况下微秒级别。 缓存命中率越高越好，一般情况下不能低于 95%。 锁等待次数越低越好，等待时间越短越好。 中间件压测案例以简单的电商商城项目为例，各中间件的压测结果如下： 总结 中间件越多，性能损失越大，大多都损失在网络交互上。 业务优化方向：数据库、模板页面的渲染速度、静态资源。 JVM 分析 &amp; 调优JVM 调优，调的是稳定，并不能让性能得到大幅提升。服务稳定的重要性就不用多说了，保证服务的稳定，GC 永远会是 JAVA 程序员需要考虑的不稳定因素之一。复杂和高并发下的服务，必须保证每次 GC 不会出现性能下降，各种性能指标不会出现波动，GC 回收规律而且干净，找到合适的 JVM 设置。FULL GC 最会影响性能，根据代码问题，避免 FULL GC 频率。可以适当调大年轻代的容量，让大对象可以在年轻代触发 YONG GC，调整大对象在年轻代的回收频次，尽可能保证大对象在年轻代回收，减小老年代缩短回收时间。 提示 Oracle 官方的 JVM 调优文档 常用工具 工具 说明 jstack 查看 JVM 线程运行状态，是否有死锁现象等信息 jinfo 可以输出并修改运行时的 Java 进程的 opts jps 与 Unix 上的 ps 命令类似，用来显示本地的 Java 进程，可以查看本地运行着几个 Java 程序，并显示它们的进程号 jstat 一个极强的监视 VM 内存工具。可以用来监视 VM 内存内的各种堆和非堆的大小及其内存使用量 jmap 打印出某个 Java 进程（使用 pid）内存内的所有 对象 的情况（如：产生哪些对象及其数量） 工具使用在使用下述工具前，建议先用 jps 命令获取当前的每个 JVM 进程号，然后选择要查看的 JVM。 jstat 使用jstat 工具特别强大，参数有众多的可选项，可详细地查看堆内各个部分的使用量，以及类加载的数量。使用时，需加上应用的进程 id 和所选参数。 命令 说明 jstat -class pid 显示加载 Class 的数量，及所占空间等信息 jstat -compiler pid 显示 VM 实时编译的数量等信息 jstat -gc pid 显示 GC 的信息，查看 GC 的次数与时间 jstat -gccapacity pid 堆内存统计，包括堆内存的使用和占用大小 jstat -gcnew pid 新生代垃圾回收统计 jstat -gcnewcapacity pid 新生代内存统计 jstat -gcold pid 老年代垃圾回收统计 jstat -gcutil pid 堆内存（包括新生代、老年代）的垃圾回收统计 除了以上 pid 参数外，还可以同时加上两个数字，示例如下： jstat -gcutil pid 1000 100: 每 1000 毫秒统计一次 GC 情况，一共统计 100 次 jstat -printcompilation pid 250 6： 表示每 250 毫秒打印一次，一共打印 6 次，还可以加上 -h3 参数使每三行显示一次标题 jinfo 使用jinfo 是 JDK 自带的命令，可以用来查看正在运行的 Java 应用程序的扩展参数，包括 Java System 属性和 JVM 命令行参数；也可以动态地修改正在运行的 JVM 一些参数。当系统崩溃时，jinfo 可以从 core 文件里面知道崩溃的 Java 应用程序的配置信息。 命令 说明 jinfo pid 输出当前 JVM 进程的全部参数和系统属性 jinfo -flag name pid 查看指定的 JVM 参数的值，打印结果： - 无此参数，`+ 有此参数 jinfo -flag [+/-]name pid 开启或者关闭对应名称的参数（无需重启虚拟机） jinfo -flag name=value pid 修改指定参数的值 jinfo -flags pid 输出全部的参数 jinfo -sysprops pid 输出当前 JVM 进行的全部的系统属性 jmap 使用jmap 命令可以生成堆内存的 Dump 文件，也可以查看堆内对象分析内存信息等，如果不使用这个命令，还可以使用 -XX:+HeapDumpOnOutOfMemoryError 参数来让虚拟机在出现 OOM 的时候自动生成 Dump 文件。 命令 说明 jmap -dump:live,format=b,file=product.dump pid Dump 堆内存到指定的文件，format 指定输出格式，live 指明是活着的对象，file 指定文件名。Eclipse 可以直接打开这个文件 jmap -heap pid 打印堆内存的概要信息，包括 GC 使用的算法、堆内存的配置和使用情况，可以用此来判断目前内存的使用情况以及垃圾回收情况 jmap -finalizerinfo pid 打印等待回收的对象信息 jmap -histo:live pid 打印堆的对象统计，包括对象数、内存大小等。特别注意，这个命令执行，JVM 会先触发一次 GC，然后再统计信息 jmap -clstats pid 打印 Java 类加载器的智能统计信息，对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印 -F 参数表示强制模式。如果指定的 pid 没有响应，请使用 jmap -dump 或 jmap -histo 选项。此模式下，不支持 live 子选项。使用示例：jmap -F -histo pid。 jstack 使用jstack 是 JDK 自带的线程堆栈分析工具，使用该命令可以查看或导出 Java 应用程序中的线程堆栈信息。 命令 说明 jstack pid 输出当前 JVM 进程的线程堆栈信息 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 软件测试"},{"title":"JMeter 压测教程之一基础使用","url":"/posts/7e51ed02.html","text":"大纲 JMeter 压测教程之一基础使用 JMeter 压测教程之二 JVM 调优 前言 JMeter 官方网站 JMeter GitHub 仓库 性能指标 RT (Response Time)：用户从客户端发起一个请求开始，到客户端接收到从服务器端返回的响应结束，整个过程所耗费的时间。 HPS (Hits Per Second)：每秒点击的次数，单位是次 / 秒。 TPS (Transaction per Second)：系统每秒处理交易 (事务) 的笔数，单位是笔 / 秒。 QPS (Query per Second)：系统每秒处理查询的次数，单位是次 / 秒。 对于互联网业务，如果某些业务有且仅有一个请求连接，那么 TPS=QPS=HPS。一般情况下用 TPS 来衡量整个业务流程，用 QPS 来衡量接口查询次数，用 HPS 来表示对服务器的单击请求。 最大响应时间 (Max Response Time)：指用户发出请求或者指令到系统做出反应 (响应) 的最大时间。 最少响应时间 (Mininum Response Time)：指用户发出请求或者指令到系统做出反应 (响应) 的最少时间。 90% 响应时间 (90% Response Time)：指将所有用户的响应时间进行排序，第 90% 的响应时间。 无论 TPS、QPS、HPS，此指标是衡量系统处理能力非常重要的指标，越大越好，根据经验，一般情况下: 金融行业：1000TPS~50000TPS，不包括互联网化的活动 保险行业：100TPS~100000TPS，不包括互联网化的活动 制造行业：10TPS~5000TPS 互联网电子商务：10000TPS~1000000TPS 互联网中型网站：1000TPS~50000TPS 互联网小型网站：500TPS~10000TPS 从外部看，性能测试主要关注如下三个指标： 吞吐量：每秒钟系统能够处理的请求数、任务数。 响应时间：服务处理一个请求或一个任务的耗时。 错误率：一批请求中结果出错的请求所占比例。 JMeter 安装在 JMeter 官网 下载安装包，然后解压文件。进入解压后的 bin 目录，Windows 系统运行 jmeter.bat，而 Linux 系统运行 jmeter.sh 即可启动 JMeter。 提示 本文使用的 JMeter 版本是 5.5 JMeter 3.2 以上版本需要安装 JDK 1.8 以上版本才能使用。 JMeter 默认支持国际化，因此可以很方便地支持中文显示，切换语言的步骤如下： JMeter 压测案例添加线程组选中 测试计划 并右击，在弹出的菜单中选择 添加 -&gt; 线程 (用户) -&gt; 线程组 线程组参数详解: 线程数：虚拟用户数。一个虚拟用户占用一个进程或线程，在这里设置多少个虚拟用户，也就表示设置多少个线程。 Ramp-Up 时间 (秒)：准备时长，即设置的线程数需要在多长时间内全部启动完成。如果线程数为 10， 准备时长为 2， 那么需要 2 秒钟启动 10 个线程，也就是每秒启动 5 个线程。 循环次数：每个线程发送请求的次数。如果线程数为 10，循环次数为 100，那么每个线程发送 100 次请求，即总请求数为 10*100=1000。如果勾选了 永远 选项，那么所有线程会一直发送请求，直到选择停止运行脚本为止。 延迟创建线程直到需要：直到需要时延迟线程的创建。 持续时间 (秒)：测试持续时间，会覆盖结束时间。 启动延迟 (秒)：测试延迟启动时间，会覆盖启动时间。 启动时间：测试启动时间，启动延迟会覆盖它。当启动时间已过，手动只需测试时当前时间也会覆盖它。 结束时间：测试结束时间，持续时间会覆盖它。 添加 HTTP 请求选中已创建的线程组并右击，在弹出的菜单中选择 添加 -&gt; 取样器 -&gt; HTTP 请求 添加监听器选中已创建的线程组并右击，在弹出的菜单中选择 添加 -&gt; 监听器 -&gt; 汇总报告 、聚合报告 启动压测脚本GUI 启动压测特别注意 JMeter 官方要求在一般情况下，要使用命令行启动压测，而不是使用 GUI 的方式。 命令行启动压测保存压测脚本将所有操作保存为压测脚本，文件的后缀是 jmx。 命令行执行压测进入 JMeter 的 bin 目录，执行压测脚本。 1jmeter -n -t /tmp/jmeter/product-up.jmx -l /tmp/jmeter/result.jtl 参数 说明 -n 命令行模式 -t JMX 脚本的路径 -l JTL 结果文件的存放路径 分析命令行压测结果使用命令行执行压测后，输出的日志信息如下： 12345678910Creating summariser &lt;summary&gt;Created the tree successfully using product-up.jmxStarting standalone test @ 2023 Jan 10 13:38:23 CST (1673329103194)Waiting for possible Shutdown/StopTestNow/HeapDump/ThreadDump message on port 4445Warning: Nashorn engine is planned to be removed from a future JDK releasesummary + 16585 in 00:00:06 = 2582.9/s Avg: 70 Min: 7 Max: 314 Err: 0 (0.00%) Active: 200 Started: 200 Finished: 0summary + 3415 in 00:00:01 = 3162.0/s Avg: 53 Min: 4 Max: 99 Err: 0 (0.00%) Active: 0 Started: 200 Finished: 200summary = 20000 in 00:00:08 = 2666.0/s Avg: 67 Min: 4 Max: 314 Err: 0 (0.00%)Tidying up ... @ 2023 Jan 10 13:38:31 CST (1673329111081)... end of run +：表示过去 30 秒的执行情况 =：表示脚本从开始到现在的运行情况 在 JMeter 的 /bin/jmeter.properties 配置文件中，可以修改 summariser.interval 参数来指定控制台取样的时间间隔，默认值是 30 JMeter 查看压测结果在 JMeter 的界面内打开压测脚本（后缀是 jmx 的文件），找到希望查看的监听器（例如 聚合报告、汇总报告），然后点击 浏览 按钮，选中上面生成 JTL 文件后，即可查看对应的压测结果。 命令行生成 HTML 压测报表JMeter 支持根据 JTL 结果文件生成 HTML 压测报表，具体的使用步骤如下： 进入 JMeter 的 bin 目录，修改 reportgenerator.properties 配置文件，将 jmeter.reportgenerator.overall_granularity 的参数值更改为 1000（设置报表中数据展示间隔 1 秒，默认值为 60 秒） 创建一个存放数据报表的文件夹 (例如 report) 执行下述命令，根据 JTL 结果文件生成 HTML 报表 1jmeter -g /tmp/jmeter/result.jtl -o /tmp/jmeter/report 参数 说明 -g 指定 JTL 文件的路径 -o 指定 HTML 报表生成到哪个文件夹下 浏览器打开生成的 index.html 文件，就可以很直观地查看压测结果 压测结果分析 若有错误率则需同开发人员确认，确定是否允许错误的发生或者错误率允许在多大的范围内。 若吞吐量 (每秒请求的数) 大于并发数，则可以慢慢的往上面增加并发数；若在压测的机器性能很好的情况下，出现吞吐量小于并发数，说明并发数不能再增加了，可以慢慢的往下减，找到最佳的并发数。 压测结束，登陆相应的 Linux/Windows 服务器查看 CPU 与内存占用等性能指标，然后进行数据分析。 最大的 TPS：不断的增加并发数，加到 TPS 达到一定值开始出现下降，那么那个值就是最大的 TPS。 最大的并发数：最大的并发数和最大的 TPS 是不同的，一般不断增加并发数，达到一个值后，服务器出现请求超时，则可认为该值为最大的并发数。 压测过程出现性能瓶颈，若在压力机的任务管理器查看到 CPU、网络和内存占用都正常，即均未达到 90% 以上，则可以说明 Linux/Windows 服务器有问题，而压力机没有问题。 提示 影响性能的考虑点包括：数据库、应用程序、中间件 (Tomcat、Nginx)、网络和操作系统等方面，优先考虑运行的应用程序属于 CPU 密集型还是 IO 密集型。 常见错误解决错误一错误信息 1JMeter Address Already in use 错误分析 这是 Windows 系统本身提供的端口访问机制导致的。Windows 提供给 TCP/IP 连接的端口为 1024 ~ 5000，并且要每隔四分钟来循环回收它们，因此就导致在短时间内跑大量的请求时将端口占满了。 解决方法 在 CMD 窗口中，使用 regedit 命令打开注册表编辑器 在 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters 下 右击 Parameters，添加一个新的 DWORD，名字为 MaxUserPort，然后双击 MaxUserPort，输入数值数据为 65534，基数选择十进制 右击 Parameters，添加一个新的 DWORD，名字为 TCPTimedWaitDelay，然后双击 TCPTimedWaitDelay，输入数值数据为 30，基数选择十进制 退出注册表编辑器，重启 Wnidows 操作系统，让新增的配置内容生效 若是分布式执行压测的话，控制机器和负载机器都需要这样操作 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 软件测试"},{"title":"近期开发计划","url":"/posts/29d74d90.html","text":"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 请 输 入 阅 读 密 码.","tags":"加密博客"},{"title":"近期学习计划","url":"/posts/860c6c02.html","text":"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 请 输 入 阅 读 密 码.","tags":"加密博客"},{"title":"国产互联网产品汇总","url":"/posts/3ccf5667.html","text":"国内数据库云厂商数据库 数据库 云厂商 TDSQL 腾讯云 GaussDB 华为云 AnalyticDB 阿里云 国产商用数据库 数据库 公司 武汉达梦 - 人大金仓 - 神州通用 - GBase 南大通用 PolarDB 阿里云 国产开源数据库 数据库 公司 TiDB PingCAP openGauss 华为 OceanBase 阿里 国产 Linux 系统 Linux 系统 公司 HarmonyOs 华为 统信 UOS - 银河麒麟 - openEuler 华为 Deepin - 优麒麟 - table { width: fit-content; border-collapse: unset; } th, td { padding-left: 30px; padding-right: 30px; font-weight: normal; border-bottom: 1px solid #ddd; } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"数据库"},{"title":"ElasticSearch 开发随笔","url":"/posts/26ba10c4.html","text":"ElasticSearch 客户端选择第一种基于 TCP 协议（ES 的 9300 端口，用于集群通信），依赖 spring-data-elasticsearch:transport-api.jar，此方式的缺点如下： SpringBoot 版本不同， 依赖的 transport-api.jar 版本也就不同，不能适配不同版本的 ES 从 ES 7.x 版本开始，官方已经不建议使用 9300 端口来操作，而且 ES 8.x 以后就要移除该操作方式 第二种基于 HTTP 协议（ES 的 9200 端口，用于 RESTful API），可选的客户端如下： RestTemplate、HttpClient、OkHttp：直接发送 HTTP 请求，ES 的很多操作需要自己封装，使用起来比较麻烦 Elasticsearch-Rest-Client：官方的 Rest 客户端，分为 Java Low Level REST Client 和 Java High Level REST Client，API 层次分明，上手简单 客户端对比 客户端 优点 缺点 说明 Java Low Level Rest Client 与 ES 版本之间没有关系，适用于作为所有版本 ES 的客户端 可以看做是低级的 HTTP 客户端，没有封装过多的 ES 操作 Java High Level Rest Client 使用最多 使用时必须与 ES 版本保持一致 基于 Low Level Rest Client，但在 ES 7.15.0 版本之后被弃用 TransportClient 使用 Transport 端口 (9300) 进行通信，能够使用 ES 集群中的一些特性，性能最好 JAR 包版本必须与 ES 集群版本一致，ES 集群升级，客户端也要跟着升级到相同版本 已过时，官方从 ES 7 版本开始不建议使用，ES 8 版本之后被移除 Elasticsearch Java API Client 最新的 ES 客户端 文档较少 提示 关于更多的 Elasticsearch 客户端说明，建议阅读 官方文档。 ElasticSearch 客户端使用案例下面将简单介绍 SpringBoot 项目如何引入 Java High Level Rest Client，由于 SpringBoot Starter 默认依赖了某版本的 Elasticsearch，因此需要在 pom.xml 配置文件中使用 &lt;elasticsearch.version&gt; 来指定（覆盖） Elasticsearch 的实际版本号，否则会出现兼容性问题。 引入 Maven 坐标123456789101112131415161718&lt;properties&gt; &lt;elasticsearch.version&gt;7.4.2&lt;/elasticsearch.version&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;${elasticsearch.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Java 配置类123456789101112131415161718192021222324252627282930313233343536import org.apache.http.HttpHost;import org.elasticsearch.client.RequestOptions;import org.elasticsearch.client.RestClient;import org.elasticsearch.client.RestClientBuilder;import org.elasticsearch.client.RestHighLevelClient;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class ElasticSearchConfig { public static final RequestOptions COMMON_OPTIONS; static { // 基础配置信息 String token = \"\"; RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder(); // builder.addHeader(\"Authorization\", \"Bearer \" + token); // builder.setHttpAsyncResponseConsumerFactory( // new HttpAsyncResponseConsumerFactory.HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024)); COMMON_OPTIONS = builder.build(); } /** * 定义 ES 客户端 * * @return ES 客户端 */ @Bean public RestHighLevelClient restHighLevelClient() { // 指定ES的连接地址 RestClientBuilder builder = RestClient.builder(new HttpHost(\"127.0.0.1\", 9200, \"http\")); return new RestHighLevelClient(builder); } } Java 测试代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889import com.alibaba.fastjson2.JSON;import com.clay.gulimall.search.config.ElasticSearchConfig;import lombok.extern.slf4j.Slf4j;import org.elasticsearch.action.index.IndexRequest;import org.elasticsearch.action.index.IndexResponse;import org.elasticsearch.action.search.SearchRequest;import org.elasticsearch.action.search.SearchResponse;import org.elasticsearch.client.RestHighLevelClient;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.SearchHit;import org.elasticsearch.search.SearchHits;import org.elasticsearch.search.aggregations.AggregationBuilders;import org.elasticsearch.search.aggregations.Aggregations;import org.elasticsearch.search.aggregations.bucket.terms.Terms;import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;import org.elasticsearch.search.aggregations.metrics.Avg;import org.elasticsearch.search.aggregations.metrics.AvgAggregationBuilder;import org.elasticsearch.search.builder.SearchSourceBuilder;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.util.Date;@Slf4j@SpringBootTestpublic class ElasticSearchApiTest { @Autowired private RestHighLevelClient esClient; /** * 创建索引数据 */ @Test public void indexData() throws Exception { IndexRequest request = new IndexRequest(\"posts\").id(\"1\") .source(\"user\", \"Jim\", \"postDate\", new Date(), \"message\", \"trying out ElasticSearch\"); IndexResponse indexResponse = esClient.index(request, ElasticSearchConfig.COMMON_OPTIONS); log.info(JSON.toJSONString(indexResponse)); } /** * 聚合查询 * &lt;p&gt; 查询 address 中包含 mill 的所有人的年龄分布以及平均薪资 */ @Test public void searchData() throws Exception { SearchRequest searchRequest = new SearchRequest(); // 指定索引 searchRequest.indices(\"bank\"); // 检索条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchQuery(\"address\", \"mill\")); // 按照年龄的分布进行聚合 TermsAggregationBuilder ageAgg = AggregationBuilders.terms(\"group_by_age\").field(\"age\").size(100); searchSourceBuilder.aggregation(ageAgg); // 计算所有人的平均薪资 AvgAggregationBuilder avgBalance = AggregationBuilders.avg(\"avgBalance\").field(\"balance\"); searchSourceBuilder.aggregation(avgBalance); // 执行检索 searchRequest.source(searchSourceBuilder); SearchResponse searchResponse = esClient.search(searchRequest, ElasticSearchConfig.COMMON_OPTIONS); // 获取搜索结果 SearchHits searchHits = searchResponse.getHits(); SearchHit[] hitArray = searchHits.getHits(); for (SearchHit hit : hitArray) { String recored = hit.getSourceAsString(); log.info(\"id: {}, data: {}\", hit.getId(), recored); } // 获取聚合结果 - 年龄的分布 Aggregations aggregations = searchResponse.getAggregations(); Terms terms = aggregations.get(\"group_by_age\"); for (Terms.Bucket bucket : terms.getBuckets()) { log.info(\"age: {}, total: {}\", bucket.getKeyAsString(), bucket.getDocCount()); } // 获取聚合结果 - 平均薪资 Avg avg = aggregations.get(\"avgBalance\"); log.info(\"avg balance: {}\", avg.getValue()); log.info(\"search params: {}\\n\", searchSourceBuilder.toString()); log.info(\"search result: {}\\n\", JSON.toJSONString(searchResponse)); } } 上述的聚合查询代码，最终发出 HTTP 请求体内容如下： 123456789101112131415161718192021GET /bank/_search{ \"query\": { \"match\": { \"address\": \"mill\" } }, \"aggs\": { \"group_by_age\": { \"terms\": { \"field\": \"age\", \"size\": 100 } }, \"avgBalance\": { \"avg\": { \"field\": \"balance\" } } }} ElasticSearch 日志分析技术栈大型项目的日志分析一般有以下两种技术栈： Kafka + ElasticSearch + Kibana Logstash + ElasticSearch + Kibana var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 开发随笔"},{"title":"Java 的五种代理实现方式","url":"/posts/aa402c78.html","text":"前言本文主要介绍 Java 的五种代理实现方式，包括 Cglib、ASM、Javassist、Byte Buddy、JDK 代理，点击 下载完整的案例代码。 准备工作先定义出一个接口和相应的实现类，方便后续使用代理类在方法中添加日志信息。 接口 12345public interface IUserApi { String queryUserInfo(); } 实现类 12345678public class UserApi implements IUserApi { @Override public String queryUserInfo() { return \"Hello Proxy!\"; } } 反射调用 1234567891011121314import java.lang.reflect.Method;import org.junit.Test;public class ReflectTest { @Test public void reflect() throws Exception { Class&lt;UserApi&gt; clazz = UserApi.class; Method queryUserInfo = clazz.getMethod(\"queryUserInfo\"); Object invoke = queryUserInfo.invoke(clazz.newInstance()); System.out.println(invoke); } } 有代理地方几乎就会有反射，它们是一套互相配合使用的功能类。在反射中可以调用方法、获取属性、拿到注解等相关内容。这些都可以与接下来的类代理组合使用，满足各种框架所面临的技术场景。 执行结果 1Hello Proxy! JDK 代理JDK 代理用于对接口的动态代理，会动态产生一个实现指定接口的类。特别注意，JDK 动态代理有个约束：目标对象一定是要有接口的，没有接口就不能实现动态代理，只能为接口创建动态代理实例，而不能对类创建动态代理实例。值得一提的是，JDK 动态代理主要依赖 java.lang.reflect 包中的 InvocationHandler、Proxy 类来实现。 使用案例 JDK 代理类 123456789101112131415161718192021import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class JDKProxy implements InvocationHandler { Object originalObj; public Object getProxy(Object originalObj) { this.originalObj = originalObj; // JDK 动态代理只能为接口创建代理实例 return Proxy.newProxyInstance(originalObj.getClass().getClassLoader(), originalObj.getClass().getInterfaces(), this); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(method.getName() + \"() 被 JDKProxy 代理了\"); return method.invoke(originalObj, args); } } JDK 代理类调用 12345678910111213import com.clay.proxy.jdk.JDKProxy;import org.junit.Test;public class JDKProxyTest { @Test public void jdkProxy() { IUserApi userApi = (IUserApi) new JDKProxy().getProxy(new UserApi()); String invoke = userApi.queryUserInfo(); System.out.println(\"运行结果: \" + invoke); } } 执行结果 12queryUserInfo() 被 JDKProxy 代理了运行结果: Hello Proxy! 使用总结 使用场景：中间件开发、设计模式中代理模式和装饰器模式的应用 使用点评：JDK 动态代理是非常常用的一种，也是非常简单的一种。基本会在一些中间件代码里看到，例如：数据库路由组件、Redis 组件等，同时也可以将这样的方式应用到设计模式中。 Cglib 代理Cglib 是 Code Generation Library 的缩写，属于动态代理方式中的一种。Cglib 用于对类的代理，不强制要求被代理的对象具有接口，其原理是把被代理对象类的 Class 文件加载进来，修改其字节码生成一个继承了被代理类的子类。由于 Cglib 采用了类的继承方式，所以不能对 final 修饰的类进行代理。Cglib 相对于 JDK 动态代理生成了大量的字节码文件，这是一种空间换时间的策略，在生成字节码的时候效率低于 JDK 动态代理。相比于反射机制，CGLIB 用到了 FastClass 机制，通过索引取调用方法，调用效率要高于 JDK 动态代理。值得一提的是，由于修改了字节码，所以 Cglib 需要依赖 ASM（Java 字节码操作类库），使用 Cglib 可以弥补 JDK 动态代理的不足。 使用案例 Maven 坐标 12345&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; Cglib 代理类 12345678910111213import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;public class CglibProxy implements MethodInterceptor { @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(method.getName() + \"() 被 CglibProxy 代理了\"); return methodProxy.invokeSuper(o, objects); } } Cglib 代理类调用 1234567891011121314151617181920import com.clay.proxy.cglib.CglibProxy;import net.sf.cglib.proxy.Enhancer;import org.junit.Test;public class CglibProxyTest { @Test public void cglibProxy() { Enhancer enhancer = new Enhancer(); // 设置父类（这里指定的是类，而不是接口） enhancer.setSuperclass(UserApi.class); // 设置拦截器 enhancer.setCallback(new CglibProxy()); // 生成动态代理类 IUserApi userApi = (UserApi) enhancer.create(); // 调用类方法 System.out.println(\"运行结果: \" + userApi.queryUserInfo()); } } 执行结果 12queryUserInfo() 被 CglibProxy 代理了运行结果: Hello Proxy! 使用总结 使用场景：Spring AOP 切面、鉴权服务、中间件开发、RPC 框架等 使用点评：Cglib 不同于 JDK 代理，它的底层使用 ASM 字节码框架在类中修改指令码来实现代理，所以这种代理方式也就不需要像 JDK 代理那样需要接口才能代理。同时得益于字节码框架的使用，所以这种代理方式也会比使用 JDK 代理的方式快 1.5~2.0 倍。 ASM 代理ASM 是一个 Java 字节码操作的类库。它能够以二进制形式修改已有类或者动态生成类。ASM 可以直接产生二进制 Class 文件，也可以在类被加载入 Java 虚拟机之前动态改变类行为。ASM 从类文件中读入信息后，能够改变类行为，分析类信息，甚至能够根据用户要求生成新类。特别注意，ASM 在创建 Class 字节码的过程中，操纵的级别是底层 JVM 的汇编指令级别，这要求 ASM 使用者要对 Class 组织结构和 JVM 汇编指令有一定的了解。 使用案例 Maven 坐标 12345&lt;dependency&gt; &lt;groupId&gt;org.ow2.asm&lt;/groupId&gt; &lt;artifactId&gt;asm&lt;/artifactId&gt; &lt;version&gt;7.1&lt;/version&gt;&lt;/dependency&gt; 类加载器 1234567891011121314151617181920212223242526272829303132333435import org.objectweb.asm.ClassWriter;import org.objectweb.asm.MethodVisitor;import org.objectweb.asm.Opcodes;public class AsmClassLoader extends ClassLoader { public Class&lt;?&gt; defineClass(String name, byte[] bytes) { return super.defineClass(name, bytes, 0, bytes.length); } public byte[] generateClassBytes() { ClassWriter cw = new ClassWriter(0); // 定义对象头：版本号、修饰符、全类名、签名、父类、实现的接口 cw.visit(Opcodes.V1_8, Opcodes.ACC_PUBLIC, \"com/proxy/asm/HelloWorld\", null, \"java/lang/Object\", null); // 添加方法：修饰符、方法名、描述符、签名、抛出的异常 MethodVisitor mv = cw.visitMethod(Opcodes.ACC_PUBLIC + Opcodes.ACC_STATIC, \"main\", \"([Ljava/lang/String;)V\", null, null); // 执行指令：获取静态属性 mv.visitFieldInsn(Opcodes.GETSTATIC, \"java/lang/System\", \"out\", \"Ljava/io/PrintStream;\"); // 加载常量 mv.visitLdcInsn(\"Hello ASM!\"); // 调用方法 mv.visitMethodInsn(Opcodes.INVOKEVIRTUAL, \"java/io/PrintStream\", \"println\", \"(Ljava/lang/String;)V\", false); // 返回值 mv.visitInsn(Opcodes.RETURN); // 设置栈大小和局部变量表大小 mv.visitMaxs(2, 1); // 方法结束 mv.visitEnd(); // 类定义完成 cw.visitEnd(); // 生成字节数组 return cw.toByteArray(); } } 类加载器调用 1234567891011121314151617181920import com.clay.proxy.asm.AsmClassLoader;import java.lang.reflect.Method;import org.junit.Test;public class AsmProxyTest { @Test public void amsProxyTest() throws Exception { AsmClassLoader classLoader = new AsmClassLoader(); // 生成二进制字节码 byte[] bytes = classLoader.generateClassBytes(); // 加载生成的 HelloWorld 类 Class&lt;?&gt; clazz = classLoader.defineClass(\"com.proxy.asm.HelloWorld\", bytes); // 反射获取 main 方法 Method main = clazz.getMethod(\"main\", String[].class); // 调用 main 方法 main.invoke(null, new Object[] {new String[] {}}); }} 执行结果 1Hello ASM! 使用总结 使用场景：全链路监控、破解工具包、Cglib、Byte Buddy 使用点评：ASM 代理使用了字节码编程的方式进行处理，它的实现方式相对复杂，而且需要了解 Java 虚拟机规范相关的知识。因为开发人员的每一步代理操作，都是在操作字节码指令，例如：Opcodes.GETSTATIC、Opcodes.INVOKEVIRTUAL，除了这些还有约 200 个常用的指令。但 ASM 这种最接近底层的方式，也是效率最快的方式，所以在一些使用字节码插装的全链路监控中，会非常常见。 Javassist 代理Javassist 是一个开源的 Java 字节码操作类库。由东京工业大学的数学和计算机科学系的 Shigeru Chiba 创建。它已加入了开放源代码 JBoss 应用服务器项目，通过使用 Javassist 对字节码操作为 JBoss 实现动态 AOP 框架。其功能与 JDK 自带的反射功能类似，但比反射功能更强大，可以用来检查、动态修改以及创建 Java 类。 使用案例 Maven 坐标 12345&lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.29.2-GA&lt;/version&gt;&lt;/dependency&gt; Javassist 代理类 1234567891011121314151617181920import javassist.ClassPool;import javassist.CtClass;import javassist.CtMethod;public class JavassistProxy extends ClassLoader { public static &lt;T&gt; T getProxy(Class clazz) throws Exception { ClassPool pool = ClassPool.getDefault(); // 获取类 CtClass ctClass = pool.get(clazz.getName()); // 获取方法 CtMethod ctMethod = ctClass.getDeclaredMethod(\"queryUserInfo\"); // 方法前加强 ctMethod.insertBefore(\"{System.out.println(\\\"\" + ctMethod.getName() + \"() 被 JavassistProxy 代理了\\\");}\"); // 获取字节码 byte[] bytes = ctClass.toBytecode(); return (T) new JavassistProxy().defineClass(clazz.getName(), bytes, 0, bytes.length).newInstance(); } } Javassist 代理类调用 12345678910111213import com.clay.proxy.javassist.JavassistProxy;import org.junit.Test;public class JavassistProxyTest { @Test public void javassistProxy() throws Exception { IUserApi userApi = JavassistProxy.getProxy(UserApi.class); String invoke = userApi.queryUserInfo(); System.out.println(\"运行结果: \" + invoke); } } 执行结果 12queryUserInfo() 被 JavassistProxy 代理了运行结果: Hello Proxy! 使用总结 使用场景：全链路监控、类代理、AOP 使用点评：Javassist 是一个使用非常广的字节码插装框架，几乎一大部分非入侵式的全链路监控都是会选择使用这个框架。因为它不想像 ASM 那样操作字节码导致风险，同时它的功能也非常齐全。另外，这个框架即可使用它所提供的方式直接编写插装代码，也可以使用字节码指令进行控制生成代码，所以综合来看也是一个非常不错的字节码框架。 Byte Buddy 代理Byte Buddy 是一个字节码生成和操作类库，用于在 Java 应用程序运行时创建和修改 Java 类，而无需编译器的帮助。除了 Java 类库附带的代码生成实用程序外，Byte Buddy 还允许创建任意类，并且不限于实现用于创建运行时代理的接口。此外，Byte Buddy 提供了一种方便的 API，可以使用 Java 代理或在构建过程中手动更改类；无需理解字节码指令，即可使用简单的 API 就能很容易操作字节码，控制类和方法。值得一提的是，Byte Buddy 跟 Cglib 一样，底层都是依赖 ASM 实现的。2015 年 10 月，Byte Buddy 被 Oracle 授予了 Duke’s Choice 大奖。该奖项对 Byte Buddy 的 “Java 技术方面的巨大创新” 表示赞赏。 使用案例 Maven 坐标 12345&lt;dependency&gt; &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt; &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt; &lt;version&gt;1.12.19&lt;/version&gt;&lt;/dependency&gt; Byte Buddy 拦截器类 12345678910111213141516import net.bytebuddy.implementation.bind.annotation.AllArguments;import net.bytebuddy.implementation.bind.annotation.Origin;import net.bytebuddy.implementation.bind.annotation.RuntimeType;import net.bytebuddy.implementation.bind.annotation.SuperCall;import java.lang.reflect.Method;import java.util.concurrent.Callable;public class InvocationInterceptor { @RuntimeType public static Object intercept(@Origin Method method, @AllArguments Object[] args, @SuperCall Callable&lt;?&gt; callable) throws Exception { System.out.println(method.getName() + \"() 被 ByteBuddyProxy 代理了\"); return callable.call(); } } Byte Buddy 代理类 1234567891011121314151617import net.bytebuddy.ByteBuddy;import net.bytebuddy.description.method.MethodDescription;import net.bytebuddy.dynamic.DynamicType;import net.bytebuddy.implementation.MethodDelegation;import net.bytebuddy.matcher.ElementMatchers;public class ByteBuddyProxy { public static &lt;T&gt; T getProxy(Class clazz) throws Exception { DynamicType.Unloaded&lt;?&gt; dynamicType = new ByteBuddy().subclass(clazz) .method(ElementMatchers.&lt;MethodDescription&gt;any()) .intercept(MethodDelegation.to(InvocationInterceptor.class)).make(); return (T) dynamicType.load(Thread.currentThread().getContextClassLoader()).getLoaded().newInstance(); } } Byte Buddy 代理类调用 12345678910111213import com.clay.proxy.buddy.ByteBuddyProxy;import org.junit.Test;public class ByteBuddyProxyTest { @Test public void byteBuddyProxy() throws Exception { IUserApi userApi = ByteBuddyProxy.getProxy(UserApi.class); String invoke = userApi.queryUserInfo(); System.out.println(invoke); } } 执行结果 12queryUserInfo() 被 ByteBuddyProxy 代理了Hello Proxy! 使用总结 使用场景：AOP 切面、类代理、组件、监控、日志 使用点评：Byte Buddy 也是一个字节码操作的类库，但 Byte Buddy 的使用方式更加简单。比起 JDK 动态代理、Cglib、Javassist 的实现，Byte Buddy 在性能上具有一定的优势。 最后总结代理的实际目的就是通过一些技术手段，替换掉原有的实现类或者给原有的实现类注入新的字节码指令；而这些技术往往会被应用到一些框架、中间件开发以及类似非入侵式的全链路监控中。几种代理方式相比较，在性能上 Javassist 高于反射，但低于 ASM，因为 Javassist 增加了一层抽象。在实现成本上 Javassist 和反射都很低，而 ASM 由于直接操作字节码，相比 Javassist 源码级别的 API 实现，ASM 的实现成本要高很多。 参考资料 ASM 官方文档 Byte Buddy 官方文档 Java 字节码编程系列知识 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java"},{"title":"如何估算 Java 线程池的大小与队列数","url":"/posts/dc8f1477.html","text":"估算算法第一种估算算法先来一个天真的估算算法：假设要求一个系统的 TPS（Transaction Per Second 或者 Task Per Second）至少为 20，然后假设每个 Transaction 由一个线程完成，继续假设平均每个线程处理一个 Transaction 的时间为 4s。那么问题可以转化为：如何设计线程池大小，使得可以在 1s 内处理完 20 个 Transaction？这里计算过程可以很简单，每个线程的处理能力为 0.25TPS，那么要达到 20TPS，显然需要 20/0.25=80 个线程。 很显然这个估算算法很天真，因为它没有考虑到 CPU 数目。一般服务器的 CPU 核数为 16 或者 32，如果有 80 个线程，那么肯定会带来太多不必要的线程上下文切换开销。 第二种估算算法第二种估算算法比较简单，但不知是否可行（N 为 CPU 总核数）： 如果是 CPU 密集型应用，则线程池大小设置为 N+1 如果是 IO 密集型应用，则线程池大小设置为 2N+1 如果一台服务器上只部署这一个应用并且只有一个线程池，那么这种估算或许合理，具体还需自行测试验证。 第三种估算算法第三种方法是在服务器性能 IO 优化中发现的一个估算公式： 最佳线程数目 = （（线程等待时间 + 线程 CPU 时间）/ 线程 CPU 时间 ）* CPU 数目 比如平均每个线程 CPU 运行时间为 0.5s，而线程等待时间（非 CPU 运行时间，比如 IO）为 1.5s，CPU 核心数为 8，那么根据上面这个公式估算得到：((0.5+1.5)/0.5)*8=32。这个公式可以进一步转化为： 最佳线程数目 = （线程等待时间与线程 CPU 时间之比 + 1）* CPU 数目 这里可以得出一个结论（第二种估算算法也可以和这个结论相结合）： 线程 CPU 时间所占比例越高，需要越少线程 线程等待时间所占比例越高，需要越多线程 估算算法总结一个系统最快的部分是 CPU，所以决定一个系统吞吐量上限的是 CPU。增强 CPU 处理能力，可以提高系统吞吐量上限。但根据短板效应，真实的系统吞吐量并不能单纯根据 CPU 来计算。那要提高系统吞吐量，就需要从 系统短板（比如网络延迟、磁盘 IO）着手： 尽量提高短板操作的并行化比率，比如多线程下载技术 增强短板能力，比如用 NIO 替代 IO 第一条可以联系到 Amdahl 定律，这条定律定义了串行系统并行化后的加速比计算公式（如下），加速比越大，表明系统并行化的优化效果越好： 加速比 = 优化前系统耗时 / 优化后系统耗时 Addahl 定律还给出了系统并行度、CPU 数目和加速比的关系（如下），加速比为 Speedup，系统串行化比率（指串行执行代码所占比率）为 F，CPU 数目为 N： Speedup &lt;= 1 / (F + (1-F)/N) 当 N 足够大时，串行化比率 F 越小，加速比 Speedup 越大。 问答 使用线程池后，是不是就一定比使用单线程高效呢？ 答案是否定的，比如 Redis 就是单线程的，但它却非常高效，基本操作都能达到十万量级 /s。从线程这个角度来看，部分原因在于多线程带来线程上下文切换开销，单线程就没有这种开销。当然 Redis 速度快的本质原因在于：Redis 基本都是内存操作，这种情况下单线程可以很高效地利用 CPU。而多线程适用场景一般是：存在相当比例的 IO 和网络操作。 所以即使有上面的估算算法，也许看似合理，但实际上也未必合理，都需要结合系统真实情况（比如是 IO 密集型或者是 CPU 密集型或者是纯内存操作）和硬件环境（CPU、内存、硬盘读写速度、网络状况等）来不断尝试达到一个符合实际的合理估算值。 估算代码为了方便估算 Java 线程池的大小与队列数，可以使用下述的两个 Java 类进行多次测试，这样可以得出最终的估算结果。 PoolSizeCalculator 类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198package threadpool;import java.math.BigDecimal;import java.math.RoundingMode;import java.util.Timer;import java.util.TimerTask;import java.util.concurrent.BlockingQueue;/** * A class that calculates the optimal thread pool boundaries. It takes the * desired target utilization and the desired work queue memory consumption as * input and retuns thread count and work queue capacity. * * @author Niklas Schlimm */public abstract class PoolSizeCalculator { /** * The sample queue size to calculate the size of a single {@link Runnable} * element. */ private static final int SAMPLE_QUEUE_SIZE = 1000; /** * Accuracy of test run. It must finish within 20ms of the testTime * otherwise we retry the test. This could be configurable. */ private static final int EPSYLON = 20; /** * Control variable for the CPU time investigation. */ private volatile boolean expired; /** * Time (millis) of the test run in the CPU time calculation. */ private final long elapsed = 3000; /** * Calculates the boundaries of a thread pool for a given {@link Runnable}. * * @param targetUtilization the desired utilization of the CPUs (0 &lt;= targetUtilization &lt;= 1) * @param targetQueueSizeBytes the desired maximum work queue size of the thread pool (bytes) */ void calculateBoundaries(BigDecimal targetUtilization, BigDecimal targetQueueSizeBytes) { calculateOptimalCapacity(targetQueueSizeBytes); Runnable task = createTask(); start(task); start(task); // warm up phase long cputime = getCurrentThreadCPUTime(); start(task); // test interval cputime = getCurrentThreadCPUTime() - cputime; long waitTime = (elapsed * 1000000) - cputime; calculateOptimalThreadCount(cputime, waitTime, targetUtilization); } private void calculateOptimalCapacity(BigDecimal targetQueueSizeBytes) { long mem = calculateMemoryUsage(); BigDecimal queueCapacity = targetQueueSizeBytes.divide(new BigDecimal(mem), RoundingMode.HALF_UP); System.out.println(\"Target queue memory usage (bytes): \" + targetQueueSizeBytes); System.out.println(\"createTask() produced \" + createTask().getClass().getName() + \" which took \" + mem + \" bytes in a queue\"); System.out.println(\"Formula: \" + targetQueueSizeBytes + \" / \" + mem); System.out.println(\"* Recommended queue capacity (bytes): \" + queueCapacity); } /** * Brian Goetz' optimal thread count formula, see 'Java Concurrency in * * Practice' (chapter 8.2) * * * @param cpu * * cpu time consumed by considered task * * @param wait * * wait time of considered task * * @param targetUtilization * * target utilization of the system */ private void calculateOptimalThreadCount(long cpu, long wait, BigDecimal targetUtilization) { BigDecimal computeTime = new BigDecimal(cpu); BigDecimal waitTime = new BigDecimal(wait); BigDecimal numberOfCPU = new BigDecimal(Runtime.getRuntime() .availableProcessors()); BigDecimal optimalthreadcount = numberOfCPU.multiply(targetUtilization) .multiply(new BigDecimal(1).add(waitTime.divide(computeTime, RoundingMode.HALF_UP))); System.out.println(\"Number of CPU: \" + numberOfCPU); System.out.println(\"Target utilization: \" + targetUtilization); System.out.println(\"Elapsed time (nanos): \" + (elapsed * 1000000)); System.out.println(\"Compute time (nanos): \" + cpu); System.out.println(\"Wait time (nanos): \" + wait); System.out.println(\"Formula: \" + numberOfCPU + \" * \" + targetUtilization + \" * (1 + \" + waitTime + \" / \" + computeTime + \")\"); System.out.println(\"* Optimal thread count: \" + optimalthreadcount); } /** * * Runs the {@link Runnable} over a period defined in {@link #elapsed}. * * Based on Heinz Kabbutz' ideas * * (http://www.javaspecialists.eu/archive/Issue124.html). * * * * @param task * * the runnable under investigation */ public void start(Runnable task) { long start = 0; int runs = 0; do { if (++runs &gt; 10) { throw new IllegalStateException(\"Test not accurate\"); } expired = false; start = System.currentTimeMillis(); Timer timer = new Timer(); timer.schedule(new TimerTask() { public void run() { expired = true; } }, elapsed); while (!expired) { task.run(); } start = System.currentTimeMillis() - start; timer.cancel(); } while (Math.abs(start - elapsed) &gt; EPSYLON); collectGarbage(3); } private void collectGarbage(int times) { for (int i = 0; i &lt; times; i++) { System.gc(); try { Thread.sleep(10); } catch (InterruptedException e) { Thread.currentThread().interrupt(); break; } } } /** * Calculates the memory usage of a single element in a work queue. Based on * Heinz Kabbutz' ideas * (http://www.javaspecialists.eu/archive/Issue029.html). * * @return memory usage of a single {@link Runnable} element in the thread * pools work queue */ private long calculateMemoryUsage() { BlockingQueue&lt;Runnable&gt; queue = createWorkQueue(SAMPLE_QUEUE_SIZE); for (int i = 0; i &lt; SAMPLE_QUEUE_SIZE; i++) { queue.add(createTask()); } long mem0 = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory(); long mem1 = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory(); queue = null; collectGarbage(15); mem0 = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory(); queue = createWorkQueue(SAMPLE_QUEUE_SIZE); for (int i = 0; i &lt; SAMPLE_QUEUE_SIZE; i++) { queue.add(createTask()); } collectGarbage(15); mem1 = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory(); return (mem1 - mem0) / SAMPLE_QUEUE_SIZE; } /** * Create your runnable task here. * * @return an instance of your runnable task under investigation */ protected abstract Runnable createTask(); /** * Return an instance of the queue used in the thread pool. * * @return queue instance */ protected abstract BlockingQueue&lt;Runnable&gt; createWorkQueue(int capacity); /** * Calculate current cpu time. Various frameworks may be used here, * depending on the operating system in use. (e.g. * http://www.hyperic.com/products/sigar). The more accurate the CPU time * measurement, the more accurate the results for thread count boundaries. * * @return current cpu time of current thread */ protected abstract long getCurrentThreadCPUTime();} SimplePoolSizeCaculator 类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package threadpool;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.lang.management.ManagementFactory;import java.math.BigDecimal;import java.net.HttpURLConnection;import java.net.URL;import java.util.concurrent.BlockingQueue;import java.util.concurrent.LinkedBlockingQueue;public class SimplePoolSizeCaculator extends PoolSizeCalculator { @Override protected Runnable createTask() { return new AsyncIOTask(); } @Override protected BlockingQueue&lt;Runnable&gt; createWorkQueue(int capacity) { return new LinkedBlockingQueue&lt;Runnable&gt;(capacity); } @Override protected long getCurrentThreadCPUTime() { //the total CPU time for the current thread in nanoseconds return ManagementFactory.getThreadMXBean().getCurrentThreadCpuTime(); } public static void main(String[] args) { PoolSizeCalculator poolSizeCalculator = new SimplePoolSizeCaculator(); poolSizeCalculator.calculateBoundaries(new BigDecimal(1.0), new BigDecimal(100000)); }}/** * 自定义的异步IO任务 * @author Will * */class AsyncIOTask implements Runnable { @Override public void run() { HttpURLConnection connection = null; BufferedReader reader = null; try { URL url = new URL(\"http://baidu.com\"); connection = (HttpURLConnection) url.openConnection(); connection.connect(); reader = new BufferedReader(new InputStreamReader( connection.getInputStream())); String line; StringBuilder stringBuilder; while ((line = reader.readLine()) != null) { stringBuilder = new StringBuilder(); stringBuilder.append(line); } } catch (IOException e) { } finally { if(reader != null) { try { reader.close(); } catch(Exception e) { } } if (connection != null) connection.disconnect(); } }} 源码剖析PoolSizeCalculator 类 calculateBoundaries()：计算线程池大小和队列数，接收两个方法参数，分别是 CPU 负载和队列总内存的大小（bytes） calculateMemoryUsage()：计算单个任务的内存大小，计算方法如下： 1234561. 手动 GC2. 计算可用内存大小 m03. 创建一个队列，并往里面放 1000 个任务4. 再次 GC5. 计算可用内存大小 m16. (m1 - m0) / 1000 即每个任务的大小 calculateOptimalCapacity()：计算队列数 计算公式：队列总内存 / 单个任务的内存 接收一个参数，即队列总内存的大小 calculateOptimalThreadCount()：计算线程池大小 计算公式：CPU 核数 *（1 + 线程等待时间 / 线程 CPU 时间） collectGarbage()：循环手动执行 GC 操作 start()：计算执行 3 秒的任务所消耗 CPU 的实际使用时间 SimplePoolSizeCaculator 类 SimplePoolSizeCaculator 类：PoolSizeCalculator 抽象类的一个实现，用于计算 CPU 负载 ，包括队列总内存的大小为 100k 左右的 IO 密集型的线程池大小和队列数 AsyncIOTask 类：IO 密集型应用的一个简单例子 估算代码的运行结果1234567891011Target queue memory usage (bytes): 100000createTask () produced threadpool.AsyncIOTask which took 40 bytes in a queueFormula: 100000 / 40* Recommended queue capacity (bytes): 2500Number of CPU: 4Target utilization: 1Elapsed time (nanos): 3000000000Compute time (nanos): 125000000Wait time (nanos): 2875000000Formula: 4 * 1 * (1 + 2875000000 / 125000000)* Optimal thread count: 96 如果不修改队列内存大小和任务，队列数可能都是 2500 参考资料 合理估算 Java 的线程池大小与队列数 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java"},{"title":"在线下载 Google Play 的 APK 应用","url":"/posts/f5fd80cf.html","text":"前言请确保有科学上网的条件，否则本文的教程内容不适用。 第一步 在 Gooble Play 官网 搜索希望下载的 APK 应用，然后记录下网页地址（URL），如下所示： 1https://play.google.com/store/apps/details?id=org.videolan.vlc&amp;hl=en 第二步 打开 apk.support 网站，粘贴上面记录下的 APK 网页地址（URL），然后点击界面上 分析 按钮，选中 Google Server，接着点击 APK 的下载连接 开始下载应用。 第三步 为了校验下载到的 APK 应用是否安全（包含恶意代码），可以打开 Virustotal 官网，粘贴上面记录下的 APK 网页地址（URL），然后开始分析 APK 应用文件。 若 Virustotal 显示所有安全检测指标都通过（绿色勾图标），则说明 APK 应用是安全的，可以放心安装使用。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Java 代码规范检测与格式化（超详细）","url":"/posts/eb1b1f3.html","text":"前言本文主要介绍如何检测 Java 代码规范与格式化 Java 代码，包括 IDEA 插件与 Maven 插件的使用。 代码规范检测插件IDEA 代码规范检测插件IDEA 可以使用 CheckStyle-IDEA 插件来检测 Java 代码的规范，它可以保证每位提交者的代码规范都保持一致。值得一提的是，CheckStyle-IDEA 插件只能检测代码的规范，并不能格式化代码。 创建规则文件在项目中创建 checkstyle.xml 规则文件，例如路径为 config/checkstyle/checkstyle.xml。 提示 1、CheckStyle 的版本与 checkstyle.xml 规则文件的内容必须互相匹配，否则会影响代码规范检测插件 CheckStyle-IDEA 的正常运行。 2、Alibaba Nacos 项目的 CheckStyle 规则文件可以从 GitHub 获取，详细的使用说明请看 官方文档。 3、Google 的 CheckStyle 规则文件可以从 GitHub 获取。 4、Spring 的 CheckStyle 规则文件可以从 GitHub 获取。 Alibaba Nacos 的 CheckStyle 规则文件如下，要求 CheckStyle 的版本至少为 8.30 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220&lt;?xml version=\"1.0\"?&gt;&lt;!-- ~ Copyright 1999-2018 Alibaba Group Holding Ltd. ~ ~ Licensed under the Apache License, Version 2.0 (the \"License\"); ~ you may not use this file except in compliance with the License. ~ You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 ~ ~ Unless required by applicable law or agreed to in writing, software ~ distributed under the License is distributed on an \"AS IS\" BASIS, ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the License for the specific language governing permissions and ~ limitations under the License. --&gt;&lt;!DOCTYPE module PUBLIC \"-//Checkstyle//DTD Checkstyle Configuration 1.3//EN\" \"https://checkstyle.org/dtds/configuration_1_3.dtd\"&gt;&lt;module name=\"Checker\"&gt; &lt;property name=\"charset\" value=\"UTF-8\"/&gt; &lt;property name=\"severity\" value=\"error\"/&gt; &lt;property name=\"fileExtensions\" value=\"java, properties, xml\"/&gt; &lt;module name=\"FileTabCharacter\"&gt; &lt;property name=\"eachLine\" value=\"true\"/&gt; &lt;/module&gt; &lt;module name=\"LineLength\"&gt; &lt;property name=\"fileExtensions\" value=\"java\"/&gt; &lt;property name=\"max\" value=\"150\"/&gt; &lt;property name=\"ignorePattern\" value=\"^implements.*|^extends.*|^package.*|^import.*|a href|href|http://|https://|ftp://\"/&gt; &lt;/module&gt; &lt;module name=\"SuppressWarningsFilter\"/&gt; &lt;module name=\"TreeWalker\"&gt; &lt;module name=\"SuppressionCommentFilter\"/&gt; &lt;module name=\"SuppressWarningsHolder\" /&gt; &lt;!-- Name Checker --&gt; &lt;module name=\"OuterTypeFilename\"/&gt; &lt;module name=\"PackageName\"&gt; &lt;property name=\"format\" value=\"^[a-z]+(\\.[a-z][a-z0-9]*)*$\"/&gt; &lt;message key=\"name.invalidPattern\" value=\"Package name ''{0}'' must match pattern ''{1}''.\"/&gt; &lt;/module&gt; &lt;module name=\"TypeName\"/&gt; &lt;module name=\"MemberName\"/&gt; &lt;module name=\"ParameterName\"/&gt; &lt;module name=\"LambdaParameterName\"/&gt; &lt;module name=\"CatchParameterName\"/&gt; &lt;module name=\"LocalVariableName\"/&gt; &lt;module name=\"ClassTypeParameterName\"/&gt; &lt;module name=\"MethodTypeParameterName\"/&gt; &lt;module name=\"InterfaceTypeParameterName\"/&gt; &lt;module name=\"MethodName\"/&gt; &lt;module name=\"ConstantName\"/&gt; &lt;module name=\"StaticVariableName\"/&gt; &lt;module name=\"AbbreviationAsWordInName\"&gt; &lt;property name=\"ignoreFinal\" value=\"false\"/&gt; &lt;property name=\"allowedAbbreviationLength\" value=\"1\"/&gt; &lt;property name=\"allowedAbbreviations\" value=\"VO\"/&gt; &lt;/module&gt; &lt;!-- Import Checker --&gt; &lt;module name=\"AvoidStarImport\"/&gt; &lt;module name=\"UnusedImports\"/&gt; &lt;module name=\"RedundantImport\"/&gt; &lt;!-- Block Checker --&gt; &lt;module name=\"EmptyBlock\"&gt; &lt;property name=\"option\" value=\"TEXT\"/&gt; &lt;property name=\"tokens\" value=\"LITERAL_TRY, LITERAL_FINALLY, LITERAL_IF, LITERAL_ELSE, LITERAL_SWITCH\"/&gt; &lt;/module&gt; &lt;module name=\"EmptyCatchBlock\"&gt; &lt;property name=\"exceptionVariableName\" value=\"expected|ignore(d)?\"/&gt; &lt;/module&gt; &lt;module name=\"LeftCurly\"/&gt; &lt;module name=\"RightCurly\"/&gt; &lt;module name=\"NeedBraces\"/&gt; &lt;!-- Javadoc Checker --&gt; &lt;module name=\"JavadocMethod\"&gt; &lt;property name=\"scope\" value=\"public\"/&gt; &lt;property name=\"allowMissingParamTags\" value=\"true\"/&gt; &lt;property name=\"allowMissingReturnTag\" value=\"true\"/&gt; &lt;property name=\"allowedAnnotations\" value=\"Override, Test, Before, After, BeforeClass, AfterClass, Parameterized, Parameters, Bean\"/&gt; &lt;property name=\"tokens\" value=\"METHOD_DEF, CTOR_DEF, ANNOTATION_FIELD_DEF\"/&gt; &lt;/module&gt; &lt;module name=\"MissingJavadocMethod\"&gt; &lt;property name=\"scope\" value=\"public\"/&gt; &lt;property name=\"minLineCount\" value=\"2\"/&gt; &lt;property name=\"allowedAnnotations\" value=\"Override, Test, Before, After, BeforeClass, AfterClass, Parameterized, Parameters, Bean\"/&gt; &lt;property name=\"ignoreMethodNamesRegex\" value=\"^set[A-Z].*|^get[A-Z].*|main\"/&gt; &lt;property name=\"tokens\" value=\"METHOD_DEF, ANNOTATION_FIELD_DEF\"/&gt; &lt;/module&gt; &lt;module name=\"SingleLineJavadoc\"&gt; &lt;property name=\"ignoreInlineTags\" value=\"false\"/&gt; &lt;/module&gt; &lt;module name=\"InvalidJavadocPosition\"/&gt; &lt;module name=\"SummaryJavadoc\"&gt; &lt;property name=\"forbiddenSummaryFragments\" value=\"^@return the *|^This method returns |^A [{]@code [a-zA-Z0-9]+[}]( is a )\"/&gt; &lt;/module&gt; &lt;module name=\"JavadocParagraph\"/&gt; &lt;module name=\"NonEmptyAtclauseDescription\"/&gt; &lt;!-- Coding Checker --&gt; &lt;module name=\"IllegalTokenText\"&gt; &lt;property name=\"tokens\" value=\"STRING_LITERAL, CHAR_LITERAL\"/&gt; &lt;property name=\"format\" value=\"\\\\u00(09|0(a|A)|0(c|C)|0(d|D)|22|27|5(C|c))|\\\\(0(10|11|12|14|15|42|47)|134)\"/&gt; &lt;property name=\"message\" value=\"Consider using special escape sequence instead of octal value or Unicode escaped value.\"/&gt; &lt;/module&gt; &lt;module name=\"OneStatementPerLine\"/&gt; &lt;module name=\"MultipleVariableDeclarations\"/&gt; &lt;module name=\"MissingSwitchDefault\"/&gt; &lt;module name=\"FallThrough\"/&gt; &lt;module name=\"NoFinalizer\"/&gt; &lt;module name=\"OverloadMethodsDeclarationOrder\"/&gt; &lt;module name=\"VariableDeclarationUsageDistance\"/&gt; &lt;module name=\"AtclauseOrder\"&gt; &lt;property name=\"tagOrder\" value=\"@param, @return, @throws, @deprecated\"/&gt; &lt;/module&gt; &lt;!-- Miscellaneous Checker --&gt; &lt;module name=\"AvoidEscapedUnicodeCharacters\"&gt; &lt;property name=\"allowEscapesForControlCharacters\" value=\"true\"/&gt; &lt;property name=\"allowByTailComment\" value=\"true\"/&gt; &lt;property name=\"allowNonPrintableEscapes\" value=\"true\"/&gt; &lt;/module&gt; &lt;module name=\"Indentation\"&gt; &lt;property name=\"arrayInitIndent\" value=\"8\"/&gt; &lt;property name=\"lineWrappingIndentation\" value=\"8\"/&gt; &lt;/module&gt; &lt;module name=\"CommentsIndentation\"&gt; &lt;property name=\"tokens\" value=\"SINGLE_LINE_COMMENT, BLOCK_COMMENT_BEGIN\"/&gt; &lt;/module&gt; &lt;module name=\"ArrayTypeStyle\"/&gt; &lt;module name=\"UpperEll\"/&gt; &lt;!-- Design Checker --&gt; &lt;module name=\"OneTopLevelClass\"/&gt; &lt;!-- Whitespace --&gt; &lt;module name=\"NoLineWrap\"/&gt; &lt;module name=\"WhitespaceAfter\"/&gt; &lt;module name=\"WhitespaceAround\"&gt; &lt;property name=\"allowEmptyConstructors\" value=\"true\"/&gt; &lt;/module&gt; &lt;module name=\"EmptyLineSeparator\"&gt; &lt;property name=\"allowMultipleEmptyLines\" value=\"false\"/&gt; &lt;property name=\"allowMultipleEmptyLinesInsideClassMembers\" value=\"false\"/&gt; &lt;/module&gt; &lt;module name=\"SeparatorWrap\"&gt; &lt;property name=\"id\" value=\"SeparatorWrapDot\"/&gt; &lt;property name=\"tokens\" value=\"DOT\"/&gt; &lt;property name=\"option\" value=\"nl\"/&gt; &lt;/module&gt; &lt;module name=\"SeparatorWrap\"&gt; &lt;property name=\"id\" value=\"SeparatorWrapComma\"/&gt; &lt;property name=\"tokens\" value=\"COMMA\"/&gt; &lt;property name=\"option\" value=\"EOL\"/&gt; &lt;/module&gt; &lt;module name=\"SeparatorWrap\"&gt; &lt;property name=\"id\" value=\"SeparatorWrapEllipsis\"/&gt; &lt;property name=\"tokens\" value=\"ELLIPSIS\"/&gt; &lt;property name=\"option\" value=\"EOL\"/&gt; &lt;/module&gt; &lt;module name=\"SeparatorWrap\"&gt; &lt;property name=\"id\" value=\"SeparatorWrapArrayDeclarator\"/&gt; &lt;property name=\"tokens\" value=\"ARRAY_DECLARATOR\"/&gt; &lt;property name=\"option\" value=\"EOL\"/&gt; &lt;/module&gt; &lt;module name=\"SeparatorWrap\"&gt; &lt;property name=\"id\" value=\"SeparatorWrapMethodRef\"/&gt; &lt;property name=\"tokens\" value=\"METHOD_REF\"/&gt; &lt;property name=\"option\" value=\"nl\"/&gt; &lt;/module&gt; &lt;module name=\"GenericWhitespace\"&gt; &lt;message key=\"ws.followed\" value=\"GenericWhitespace ''{0}'' is followed by whitespace.\"/&gt; &lt;message key=\"ws.preceded\" value=\"GenericWhitespace ''{0}'' is preceded with whitespace.\"/&gt; &lt;message key=\"ws.illegalFollow\" value=\"GenericWhitespace ''{0}'' should followed by whitespace.\"/&gt; &lt;message key=\"ws.notPreceded\" value=\"GenericWhitespace ''{0}'' is not preceded with whitespace.\"/&gt; &lt;/module&gt; &lt;module name=\"MethodParamPad\"/&gt; &lt;module name=\"NoWhitespaceBefore\"/&gt; &lt;module name=\"ParenPad\"/&gt; &lt;module name=\"OperatorWrap\"&gt; &lt;property name=\"option\" value=\"NL\"/&gt; &lt;property name=\"tokens\" value=\"BAND, BOR, BSR, BXOR, DIV, EQUAL, GE, GT, LAND, LE, LITERAL_INSTANCEOF, LOR, LT, MINUS, MOD, NOT_EQUAL, PLUS, QUESTION, SL, SR, STAR, METHOD_REF \"/&gt; &lt;/module&gt; &lt;!-- Modifier Checker --&gt; &lt;module name=\"ModifierOrder\"/&gt; &lt;!-- Annotation Checker --&gt; &lt;module name=\"AnnotationLocation\"&gt; &lt;property name=\"id\" value=\"AnnotationLocationMostCases\"/&gt; &lt;property name=\"tokens\" value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, METHOD_DEF, CTOR_DEF\"/&gt; &lt;/module&gt; &lt;module name=\"AnnotationLocation\"&gt; &lt;property name=\"id\" value=\"AnnotationLocationVariables\"/&gt; &lt;property name=\"tokens\" value=\"VARIABLE_DEF\"/&gt; &lt;property name=\"allowSamelineMultipleAnnotations\" value=\"true\"/&gt; &lt;/module&gt; &lt;/module&gt;&lt;/module&gt; 插件安装 1、打开 IDEA 插件市场的界面 2、搜索 CheckStyle-IDEA，点击安装即可 插件配置导入规则文件 1、打开 CheckStyle 的配置界面（File –&gt; Settings –&gt; Tools –&gt; Checkstyle） 2、选择 Checkstyle 的版本为 8.39，这里的版本号必须与 checkstyle.xml 规则文件的内容相互匹配 3、选择 Scan Scope 扫描范围，若 checkstyle.xml 规则文件支持检测不同类型的文件（.java、.xml 等）的代码规范，则可以选择 All sources (including tests) 4、在界面上点击配置文件的添加按钮，配置描述可随便填写（例如 Custom Checks），然后选中项目里的 checkstyle.xml 规则文件，点击下一步和完成 5、在界面上勾选刚刚添加的配置文件 配置编辑器的代码检测规范 1、打开 IDEA 编辑器的配置界面（File –&gt; Settings –&gt; Editor –&gt; Code Style –&gt; Schema –&gt; Import Schema –&gt; CheckStyle Configuration） 2、导入项目中的 checkstyle.xml 规则文件，如下图所示： 配置编辑器的代码实时检测 1、打开 IDEA 编辑器的配置界面（File –&gt; Settings –&gt; Editor –&gt; Inspections） 2、勾选 Checkstyle real-time scan 选项，如下图所示： 配置编辑器提示信息的颜色在 IDEA 的编辑器内，默认的 CheckStyle 提示样式跟 IDEA 默认的差不多，两者并不好区分。若希望更改 CheckStyle 提示信息的颜色，可以按照以下步骤操作： 1、打开 CheckStyle 的颜色设置窗口（File –&gt; Settings –&gt; Editor –&gt; Inspections –&gt; CheckStyle –&gt; Severity –&gt; Edit severities） 2、更改不同类型的提示信息的颜色 插件使用 1、在 IDEA 界面内打开任意一个 Java 源文件 2、打开 IDEA 界面底部的 CheckStyle 操作面板，点击左侧的 绿色三角形 按钮，这样就可以检查单个 Java 源文件的代码规范 提示 CheckStyle 除了可以检测单个 Java 源文件的代码规范，还支持检测整个 Maven 模块（Check Module）或者整个项目（Check Project）的 Java 代码规范。 Maven 代码规范检测插件Maven Checkstyle Plugin 插件可用于检测 Java 代码规范，更详细的使用教程可看 官方文档。 创建规则文件在项目中创建 checkstyle.xml 规则文件，例如路径为 config/checkstyle/checkstyle.xml。Checkstyle 8.39 版本可使用的规则文件请参考 这里。 提示 1、Maven Checkstyle Plugin 与 Checkstyle 的版本对应关系请看 官方文档。 2、若不指定 checkstyle.xml 规则文件的路径，Maven Checkstyle Plugin 默认会从项目的根目录下搜索规则文件。 3、当 Maven Checkstyle Plugin 找不到对应的 checkstyle.xml 规则文件时，默认会使用内置的 sun_checks.xml 或者 google_checks.xml 规则文件。 配置插件Maven Checkstyle Plugin 3.2.0 默认使用的 Checkstyle 版本是 9.3，由于 Checkstyle 的版本必须与 checkstyle.xml 规则文件的内容互相匹配，因此需要引入 checkstyle 来指定 Checkstyle 的版本号，这样就可以很方便地兼容不同的规则文件了。 12345678910111213141516171819202122232425262728293031323334353637&lt;properties&gt; &lt;!-- 指定项目中自定义的 CheckStyle 规则文件 --&gt; &lt;checkstyle.config.location&gt;config/checkstyle/checkstyle.xml&lt;/checkstyle.config.location&gt;&lt;/properties&gt;&lt;build&gt; &lt;plugins&gt; &lt;!-- 代码规范检测插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;8.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;configuration&gt; &lt;consoleOutput&gt;true&lt;/consoleOutput&gt; &lt;failsOnError&gt;true&lt;/failsOnError&gt; &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 现在切换到项目所在的目录下，就可以使用 mvn checkstyle:check 命令执行代码规范检测了，或者直接执行 mvn compile 命令。Maven Checkstyle Plugin 插件除了会在控制台打印代码规范的检测结果，还会将检测结果输出到项目的 target/checkstyle-result.xml 文件中。 123456789 &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt;&lt;/executions&gt; 上述的 id 可以随意填写，phase 表示将插件绑定到 Maven Lifecycle 的 phase 中的哪个命令上。指定 phase 为 validate 后，当执行 mvn compile 命令时会执行 Maven CheckStyle Plugin 插件。若指定 phase 为 install，则表示绑定到 install 命令上，即当执行 maven install 命令的时候才会执行插件。 生成报告若希望 Maven Checkstyle Plugin 将代码规范的检测结果生成 HTML 报告，可以参考以下写法，详情可参考 官方文档。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;project&gt; &lt;properties&gt; &lt;!-- 指定项目中自定义的 CheckStyle 规则文件 --&gt; &lt;checkstyle.config.location&gt;config/checkstyle/checkstyle.xml&lt;/checkstyle.config.location&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 站点生成插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;version&gt;3.12.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 代码规范检测插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;8.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;configuration&gt; &lt;consoleOutput&gt;true&lt;/consoleOutput&gt; &lt;failsOnError&gt;true&lt;/failsOnError&gt; &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 生成的报告 --&gt; &lt;reporting&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt;&lt;/project&gt; 现在切换到项目所在的目录下，就可以使用 mvn checkstyle:checkstyle 命令生成代码规范检测结果的 HTML 报告了，或者使用 mvn site 命令（速度较慢，会生成多种类型的站点报告），默认会将检测报告输出到项目的 target/site/checkstyle.html 文件中。 错误级别在 checkstyle.xml 规则文件中，有以下的配置内容，表示当扫描到代码有不符合规范的地方时，指定错误级别为 error 1&lt;property name=\"severity\" value=\"error\"/&gt; Maven CheckStyle Plugin 有以下的配置内容，表示如果在扫描代码时遇到 error 级别的错误，就直接中断命令的执行；否则，只会生成检测结果文件，但不会中断命令的执行。 1&lt;failsOnError&gt;true&lt;/failsOnError&gt; CheckStyle 允许的错误级别有 error、warning、info，只有指定错误级别为 error，并配置了 failsOnError 才会中断命令的执行。命令中断执行后，会在对应的模块下生成 target/checkstyle-result.xml 检测结果文件。 多模块配置在企业开发中，一般会把项目的逻辑按照模块拆分出来，这样便于分离和解耦，项目脉络也更加清晰。在这种情况下，要为每个 Maven 模块创建 CheckStyle 任务，也就是需要放到 Parent 的 pom.xml 配置文件里。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;project&gt; &lt;properties&gt; &lt;!-- 指定项目中自定义的 CheckStyle 规则文件 --&gt; &lt;checkstyle.config.location&gt;config/checkstyle/checkstyle.xml&lt;/checkstyle.config.location&gt; &lt;/properties&gt; &lt;build&gt; &lt;!-- 公共的 CheckStyle 插件标准配置，可以在子模块中覆盖，并修改自定义选项 --&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 站点生成 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;version&gt;3.12.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 代码检测 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;8.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;configuration&gt; &lt;consoleOutput&gt;true&lt;/consoleOutput&gt; &lt;failsOnError&gt;true&lt;/failsOnError&gt; &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 所有子模块都要执行的插件 --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;reporting&gt; &lt;plugins&gt; &lt;!-- 所有子模块都要生成的报告 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt;&lt;/project&gt; 常见问题汇总无法打印检测结果首先，执行 Maven 代码规范检测插件的常用命令有两种： mvn checkstyle:check mvn checkstyle:checkstyle 特别注意的是，上述两个命令的执行效果是不一样的： 执行 mvn checkstyle:check 命令，控制台会显示 BUILD FAILURE，会打印详细的代码规范检测结果（警告或错误信息），同时还会将检测结果记录在 target/checkstyle-result.xml 文件里，不会生成 HTML 检测报告 执行 mvn checkstyle:checkstyle 命令，控制台会显示 BUILD SUCCESS，不会打印详细的代码规范检测结果（警告或错误信息），但会将检测结果记录在 target/checkstyle-result.xml 文件里，会生成 HTML 检测报告 提示 值得一提的是，mvn checkstyle:check 命令默认会绑定到 validate 阶段（phase），它将在编译代码之前检测代码的规范，详细说明请看 官方文档。 无法定位 XRef 资源若执行 mvn checkstyle:check 命令后，Maven 打印 Unable to locate Source XRef to link 这样的警告信息，可以在 pom.xml 配置文件中加入以下内容来解决： 123456789&lt;reporting&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jxr-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/reporting&gt; 忽略检测指定的子模块若不希望 Maven 的 CheckStyle 插件检测某些指定子模块的代码规范，可以在子模块下的 pom.xml 配置文件中，加入以下内容。 123&lt;properties&gt; &lt;checkstyle.skip&gt;true&lt;/checkstyle.skip&gt;&lt;/properties&gt; 代码格式化插件Maven 代码格式化插件Spring Java Format 插件集提供了一款格式化 Java 代码的 Maven 插件，默认使用 Spring 的代码规范，插件的运行依赖于 JDK 11+。在项目里配置好代码格式化的 Maven 插件后，可直接运行命令格式化项目代码： mvn spring-javaformat:apply 或者 ./mvnw spring-javaformat:apply。 基础配置在项目中的 pom.xml 配置文件中添加以下内容： 123456789&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.0.35&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 现在切换到项目所在的目录下，就可以使用 mvn spring-javaformat:apply 或者 ./mvnw spring-javaformat:apply 命令批量格式化 Java 代码了。 强制格式化若希望强制所有代码都符合所需的规范，可以使用以下的插件配置内容： 123456789101112131415161718&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.0.35&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;goals&gt; &lt;goal&gt;validate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 提示 配置强制格式化代码后，如果 Maven 在编译项目时发现有代码的风格不符合 Spring 规范，会自动终止编译，直至所有代码的风格都符合 Spring 规范才会让项目正常编译。 强制检测特定的代码规范若希望在 Maven 编译之前，强制检测特定的代码规范，则可以在上述配置内容的基础上（如果只是想让 Maven 插件检测特定的代码规范，而不需要执行代码格式化，则可以不引入上述的配置内容），额外引入 CheckStyle 的 Maven 插件，并包含 spring-javaformat-checkstyle 依赖，然后指定 CheckStyle 的规则文件即可，具体的配置内容如下： 特别注意 1、配置了强制检测特定的代码规范之后，如果 Maven 在编译项目时发现有代码的风格不符合特定的代码规范，会自动终止编译，直至所有代码的风格都符合特定的代码规范才会让项目正常编译。 2、在下述的 Maven 配置内容中，checkstyle 依赖的版本必须与指定的 checkstyle.xml 规则文件的内容互相匹配，否则会影响 Maven 代码规范检测插件的运行。 3、下述的 Maven 配置内容，只是让 Maven 插件在编译代码之前强制检测特定的代码规范，而不是让 Maven 插件按照 CheckStyle 的规则文件来格式化代码，也就是说 Maven 插件最终还是会使用 Spring 的代码规范来进行格式化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;properties&gt; &lt;!-- 指定项目中自定义的 CheckStyle 规则文件 --&gt; &lt;checkstyle.config.location&gt;config/checkstyle/checkstyle.xml&lt;/checkstyle.config.location&gt;&lt;/properties&gt;&lt;build&gt; &lt;plugins&gt; &lt;!-- 代码格式化插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.0.35&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;goals&gt; &lt;goal&gt;validate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- 代码规范检测插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;8.39&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-checkstyle&lt;/artifactId&gt; &lt;version&gt;0.0.35&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;checkstyle-validation&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;configuration&gt; &lt;consoleOutput&gt;true&lt;/consoleOutput&gt; &lt;failsOnError&gt;true&lt;/failsOnError&gt; &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;check&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 现在切换到项目所在的目录下，就可以使用 mvn checkstyle:check 命令执行代码规范检测了，或者直接执行 mvn compile 命令。 配合 CheckStyle-IDEA 插件使用在 IDEA 里配置 CheckStyle-IDEA 代码规范检测插件，让 CheckStyle 默认使用 Spring 的代码规范来检测。 创建规则文件在项目中创建 checkstyle.xml 规则文件，并写入如下内容： 12345678&lt;?xml version=\"1.0\"?&gt;&lt;!DOCTYPE module PUBLIC \"-//Checkstyle//DTD Checkstyle Configuration 1.3//EN\" \"https://checkstyle.org/dtds/configuration_1_3.dtd\"&gt;&lt;module name=\"com.puppycrawl.tools.checkstyle.Checker\"&gt; &lt;module name=\"io.spring.javaformat.checkstyle.SpringChecks\" /&gt;&lt;/module&gt; 配置 CheckStyle-IDEA 插件 1、打开 CheckStyle 的配置界面（File –&gt; Settings –&gt; Tools –&gt; Checkstyle） 2、选择 Checkstyle 的版本，例如 8.39 3、在界面上点击配置文件的添加按钮，配置描述可随便填写（例如 Custom Checks），然后选中项目里的 checkstyle.xml 规则文件，点击下一步和完成 4、在界面上勾选刚刚添加的配置文件 5、下载 spring-javaformat-checkstyle-0.0.35.jar 与 spring-javaformat-config-0.0.35.jar 文件，并将它们添加到 Third-Party Checks IDEA 代码格式化插件IDEA 内置的格式化工具IDEA 可以使用内置工具格式化 Java 代码，格式化代码的快捷键是 CTRL + ALT + L。 代码风格配置若希望让 IDEA 默认使用特定的代码风格来格式化代码，可以参考以下配置步骤： 1、从 Nacos GitHub 下载 IDEA 的代码风格 XML 文件，这里使用 Alibaba Nacos 的代码风格（附上官方教程），也可以选择 Google GitHub 的代码风格 2、打开 IDEA 编辑器的配置界面（File –&gt; Settings –&gt; Editor –&gt; Code Style –&gt; Schema –&gt; Import Schema –&gt; IntelliJ IDEA code style XML） 3、导入 IDEA 的代码风格 XML 文件 单个格式化打开任意一个 Java 源文件，使用快捷键 CTRL + ALT + L 即可按照特定的代码风格来格式化单个源文件了。 批量格式化IDEA 支持代码批量格式化的功能，这样就不用手动使用快捷键格式化每个 Java 源文件了，而且基于上面 IDEA 代码格式化风格的配置，可以让 IDEA 按照特定的代码风格批量格式化，具体的操作步骤如下： 打开 IDEA 批量格式化代码的界面（右键项目 / 模块 –&gt; Reformat Code） 配置批量格式化的参数（如下图所示） 最后点击 Run 按钮 Spring Java Format 格式化插件Spring Java Format 提供了一款可以格式化 Java 代码的 IDEA 插件，可以从 Maven Central 下载，详细的使用教程请看官方文档。 最佳实践在企业项目开发中，推荐使用以下的技术组合来约束项目的代码风格。 推荐方案一 使用 IDEA 内置的代码格式化工具，基于 Google 或 Nacos 的 代码风格文件 使用 IDEA 的代码规范检测插件，基于 Google 或 Nacos 的 CheckStyle 规则文件 使用 Maven 的代码规范检测插件，基于 Google 或 Nacos 的 CheckStyle 规则文件 推荐方案二 Spring Java Format 的 IDEA 代码格式化插件 Spring Java Format 的 Maven 代码格式化插件 使用 IDEA 的代码规范检测插件，基于 Spring 的 CheckStyle 规则文件 使用 Maven 的代码规范检测插件，基于 Spring 的 CheckStyle 规则文件 资源文件CheckStyle 规则文件 Nacos CheckStyle Google CheckStyle Spring CheckStyle IDEA 代码风格 XML 文件 Nacos Java Code Style For IDEA Google Java Code Style For IDEA 参考资料 Google All Style Guide Google Java Style Guide 使用 CheckStyle 来规范你的项目 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 开发工具"},{"title":"VuePress 渲染 Mermaid 绘图","url":"/posts/bc19d204.html","text":"前言本文将介绍 VuePress 如何渲染 Mermaid 绘图，适用于 VuePress 1.x 与 VuePress 2.x。 VuePress 1.xVuePress 1.x 可以直接安装第三方插件 vuepress-plugin-mermaidjs 来渲染 Mermaid 绘图，插件的详细文档可看 这里。 安装插件安装插件时必须指定具体的版本号，否则默认会安装最新版本的插件，最新版本不兼容 VuePres 1.x。 1$ npm install vuepress-plugin-mermaidjs@1.9.1 -D 配置插件编辑 VuePress 1.x 的 .vuepress/config.js 配置文件，新增 mermaidjs 插件，如下所示： 12345module.exports = { plugins: [ 'vuepress-plugin-mermaidjs' ]} Markdown 渲染语法说明 第二种写法：使用代码块（推荐） 第二种写法：使用 &lt;mermaid&gt; 标签 使用示例1234567&lt;mermaid&gt;sequenceDiagramAlice-&gt;John: Hello John, how are you?loop every minute John--&gt;Alice: Great!end&lt;/mermaid&gt; VuePress 2.x由于第三方插件 vuepress-plugin-mermaidjs 并没有适配最新版的 VuePress 2.x，因此需要手动配置 VuePress 2.x 来渲染 Mermaid 绘图。 安装依赖 让 VuePress 2.x 支持 Mermaid 1$ npm install mermaid -D 让 VuePress 2.x 支持自定义组件 1$ npm install @vuepress/plugin-register-components@next -D 配置 VuePress 2编辑 VuePress 2.x 的 .vuepress/config.ts 配置文件，指定自定义组件所在的目录，该目录下的 Vue 文件会被自动注册为 Vue 组件，详细介绍可以看 这里。 第一种配置方式 1234567891011import { registerComponentsPlugin } from '@vuepress/plugin-register-components'import { getDirname, path } from '@vuepress/utils'const __dirname = getDirname(import.meta.url)export default { plugins: [ registerComponentsPlugin({ componentsDir: path.resolve(__dirname, './components'), }) ]} 第二种配置方式 1$ npm install app-root-path -D 1234567891011121314151617import path from 'path'import appRoot from 'app-root-path';import { registerComponentsPlugin } from '@vuepress/plugin-register-components'// 获取 \".vupress\" 目录的绝对路径const __dirname = appRoot.resolve('./.vuepress/');// 如果文档项目存放在工程的子目录中，比如在 \"/docs\" 文件夹，则写法如下// const __dirname = appRoot.resolve('./docs/.vuepress/');export default { plugins: [ registerComponentsPlugin({ componentsDir: path.resolve(__dirname, './components'), }) ]} 提示 上述的两种方式，都可以指定 VuePress 2.x 的自定义组件目录为 ./components，该目录默认存放在 .vuepress 目录下，即完整的自定义组件目录的路径是 .vuepress/components/。 自定义 Mermaid 组件在上面的自定义组件目录下，创建 mermaid.vue 源文件，例如源文件路径为 .vuepress/components/mermaid.vue，文件的内容如下： 1234567891011121314151617181920212223242526&lt;template&gt; &lt;div class=\"mermaid\"&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { mounted() { import(\"mermaid/dist/mermaid\").then((m) =&gt; { m.initialize({ startOnLoad: true, }); m.init(); }); }, updated() { import(\"mermaid/dist/mermaid\").then((m) =&gt; { m.initialize({ startOnLoad: true, }); m.init(); }); }};&lt;/script&gt; Markdown 渲染语法说明在 MarkDown 文件内添加 &lt;mermaid&gt; 标签，Mermaid 的内容需要使用 {{ 包裹住，并写在 &lt;mermaid&gt; 标签内（如下所示）。特别注意，&lt;mermaid&gt; 标签内不允许存在空行。 12345&lt;mermaid&gt;{{` ......（Mermaid 的内容）`}}&lt;/mermaid&gt; 使用示例流程图1234567891011&lt;mermaid&gt;{{`graph TB id1(圆角矩形)--普通线--&gt;id2[矩形]; subgraph 子图 id2==粗线==&gt;id3{菱形} id3-.虚线.-&gt;id4&gt;右向旗帜] id3--无箭头---id5((圆形)) end`}}&lt;/mermaid&gt; 时序图12345678910111213&lt;mermaid&gt;{{`sequenceDiagramAlice-&gt;&gt;John: Hello John, how are you?loop Healthcheck John-&gt;&gt;John: Fight against hypochondriaendNote right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob : How about you? Bob--&gt;&gt;John : Jolly good!`}}&lt;/mermaid&gt; 饼图12345678910&lt;mermaid&gt;{{`pie title Key elements in Product X \"Calcium\" : 42.96 \"Potassium\" : 50.05 \"Magnesium\" : 10.01 \"Iron\" : 5`}}&lt;/mermaid&gt; 类别图12345678910111213141516171819202122232425&lt;mermaid&gt;{{`classDiagram Animal &lt;|-- Duck Animal &lt;|-- Fish Animal &lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() }`}}&lt;/mermaid&gt; 甘特图123456789101112&lt;mermaid&gt;{{`ganttsection Section Completed: done, des1, 2014-01-06, 2014-01-08 Active : active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d`}}&lt;/mermaid&gt; 状态图12345678910111213141516171819&lt;mermaid&gt;{{`stateDiagram [*]--&gt;Active state Active { [*]--&gt;NumLockOff NumLockOff--&gt;NumLockOn : EvNumLockPressed NumLockOn--&gt;NumLockOff : EvNumLockPressed -- [*]--&gt;CapsLockOff CapsLockOff--&gt;CapsLockOn : EvCapsLockPressed CapsLockOn--&gt;CapsLockOff : EvCapsLockPressed -- [*]--&gt;ScrollLockOff ScrollLockOff--&gt;ScrollLockOn : EvCapsLockPressed ScrollLockOn--&gt;ScrollLockOff : EvCapsLockPressed }`}}&lt;/mermaid&gt; 实体关系图12345678&lt;mermaid&gt;{{`erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses`}}&lt;/mermaid&gt; 参考博客 Mermaid Docs Mermaid Support VuePress v2 How to use mermaid on Vuepress Has anyone gotten mermaid working ? var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"Rust 编程之道","url":"/posts/35ea9077.html","text":"","tags":"在线电子书"},{"title":"Vagrant 快速创建 VirtualBox 虚拟机","url":"/posts/b9ff615e.html","text":"前言本文将介绍如何使用 Vagrant 在 VirtualBox 中快速创建 Linux 虚拟机，请提前在 Linux/Windows 本地操作系统里安装好 VirtualBox 虚拟机软件。 Vagrant 介绍Vagrant 简介Vagrant 是一个基于 Ruby 的开源工具，用于创建和部署虚拟化开发环境。Vagrant 可与 Hyper-V、VirtualBox、VMWare、Parallels 和 Libvirt 等虚拟化软件配合使用，致力于提供一种简易的方法来创建、配置和复制状态已知的虚拟机。它可以很方便地将预配置的虚拟机或设备从 Vagrant Cloud（镜像仓库）获取，并初始化后在系统上运行。简而言之，Vagrant 可以通过命令行快速创建 VirtualBox、VMWare 等虚拟机，主要用途类似 Docker（本质上的实现原理不一样）。 Vagrant 站点资源 Vagrant 官网 Vargrant 镜像仓库 Vargrant 官方文档 Vagrant GitHub 项目 Vagrant 安装Linux 系统Linux 系统执行以下命令安装 Vagrant 后，在终端输入命令 vagrant，若出现相关命令提示，则说明 Vagrant 安装成功。 特别注意 Linux 系统环境下，Vagrant 的虚拟机镜像下载目录是 ~/.vagrant.d，为了方便日后有足够的磁盘空间安装更多的虚拟机镜像，建议通过软链接的方式更改镜像存放的默认目录，例如： ln -sf /your_new_path ~/.vagrant.d Fedora123$ sudo dnf install -y dnf-plugins-core$ sudo dnf config-manager --add-repo https://rpm.releases.hashicorp.com/fedora/hashicorp.repo$ sudo dnf -y install vagrant CentOS/RHEL123$ sudo yum install -y yum-utils$ sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo$ sudo yum -y install vagrant Debian/Ubuntu123$ wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg$ echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list$ sudo apt update &amp;&amp; sudo apt install vagrant Windows 系统Vagrant 官网 下载 EXE 安装包，然后直接安装即可。Vagrant 安装完成后，打开 CMD 窗口，输入命令 vagrant，若出现相关命令提示，则说明安装成功。 Vagrant 常用命令 命令 描述 vagrant box add 添加 box 的操作 vagrant box list 查看本地的 box 列表 vagrant box remove 删除本地的 box vagrant init 初始化 box 的操作，会生成 Vagrant 的配置文件 Vagrantfile vagrant up 启动本地虚拟机 vagrant ssh 通过 SSH 登录本地虚拟机 vagrant suspend 暂停本地虚拟机 vagrant resume 恢复本地虚拟机 vagrant package 将当前本地虚拟机打包成 box vagrant status 查看当前虚拟机的状态 vagrant global-status 显示当前用户下 Vagrant 所有虚拟机的状态 vagrant reload 更改了 Vagrantfile 后，使之生效（相当于先 halt，再 up） Vagrant 创建虚拟机创建 VirtualBox 虚拟机执行以下 init 命令，即可快速初始化一个 VirtualBox 虚拟机。值得一提的是，虚拟机初始化完成后，Vagrant 会在执行命令的当前目录下创建一个 Vagrantfile 文件。 1vagrant init centos/7 命令行中的 centos/7 代表需要初始化 CentOS 7 的虚拟机，如果需要初始化其他虚拟机直接替换它就可以，注意 / 符不能省略掉，例如初始化 Ubuntu 虚拟机的命令如下： 1vagrant init ubuntu/trusty64 提示 Vagrant 支持的虚拟机列表可以在右边这个网站查找到：https://app.vagrantup.com/boxes/search 启动 VirtualBox 虚拟机执行以下 up 命令，即可快速启动上面初始化好的 VirtualBox 虚拟机 1vagrant up Vagrant 首次启动 VirtualBox 虚拟机时，会从 Vagrant Cloud（镜像仓库）下载对应的镜像，CentOS 7 虚拟机完整的启动日志信息如下： 123456789101112131415161718192021222324252627282930313233343536373839404142Bringing machine 'default' up with 'virtualbox' provider...==&gt; default: Box 'centos/7' could not be found. Attempting to find and install... default: Box Provider: virtualbox default: Box Version: &gt;= 0==&gt; default: Loading metadata for box 'centos/7' default: URL: https://vagrantcloud.com/centos/7==&gt; default: Adding box 'centos/7' (v2004.01) for provider: virtualbox default: Downloading: https://vagrantcloud.com/centos/boxes/7/versions/2004.01/providers/virtualbox.boxDownload redirected to host: cloud.centos.org default: Calculating and comparing box checksum...==&gt; default: Successfully added box 'centos/7' (v2004.01) for 'virtualbox'!==&gt; default: Importing base box 'centos/7'...==&gt; default: Matching MAC address for NAT networking...==&gt; default: Checking if box 'centos/7' version '2004.01' is up to date...==&gt; default: Setting the name of the VM: Vagrant_default_1663582821802_96925==&gt; default: Clearing any previously set network interfaces...==&gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat==&gt; default: Forwarding ports... default: 22 (guest) =&gt; 2222 (host) (adapter 1)==&gt; default: Booting VM...==&gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key default: default: Vagrant insecure key detected. Vagrant will automatically replace default: this with a newly generated keypair for better security. default: default: Inserting generated public key within guest... default: Removing insecure key from the guest if it's present... default: Key inserted! Disconnecting and reconnecting using new SSH key...==&gt; default: Machine booted and ready!==&gt; default: Checking for guest additions in VM... default: No guest additions were detected on the base box for this VM! Guest default: additions are required for forwarded ports, shared folders, host only default: networking, and more. If SSH fails on this machine, please install default: the guest additions and repackage the box to continue. default: default: This is not an error message; everything may continue to work properly, default: in which case you may ignore this message.==&gt; default: Rsyncing folder: /home/centos/vagrant/ =&gt; /vagrant SSH 连接 VirtualBox 虚拟机VirtualBox 虚拟机系统启动后，Vagrant 会为我们自动创建 SSH 连接，因此我们不仅可以直接通过 VirtualBox 操作虚拟机系统，也可以通过 SSH 连接来操作。Vagrant 默认的 SSH 账号名称是 vagrant，登录密码是 vagrant，所以可以通过这种连接方式以 Vagrant 的账号连接虚拟机系统，命令如下： 1vagrant ssh 使用 SSH 连接到 VirtualBox 虚拟机系统后，若希望切换到 root 用户，可以在终端输入下命令，root 用户的默认密码是 vagrant 1$ su root VirtualBox 虚拟机网络配置默认情况下，Vagrant 创建虚拟机后，使用的是网络地址转换和端口转发的方式来解决本地系统和虚拟机网络地址映射的问题，如下图所示。在实际使用过程中，网络地址转换和端口转发的方式可能不太方便。举个例子，在虚拟机中装了很多软件服务，比如 MySQL 数据库，Redis 等等，在虚拟机内部使用是没有问题的。MySQL 数据库的端口默认是 3306，但在本地系统中，虚拟机给我们映射出来的端口可能就不是 3306 了，这对于在本地系统上进行测试是及其不方便的。因此，若不希望使用这种默认的方式，可以设置一个私有的 IP 实现本地系统和虚拟机系统之间的互通。 在本地系统（宿主机）内执行以下命令，找到 VirtualBox 的虚拟网卡地址，例如 192.168.56.2 1$ ip addr 或者 1$ ifconfig -a 编辑 Vagrantfile 文件，找到如下的一行内容，去掉注释并更改 IP 地址，例如 192.168.56.10。特别注意，其中的网段 192.168.56 是固定的，而 10 可以换成其他的，最大不要超过 255 就可以 1config.vm.network \"private_network\", ip: \"192.168.56.10\" 重新加载 Vagrantfile 配置文件，Vagrant 会自动重启虚拟机系统 1vagrant reload 虚拟机系统重启完成后，在本地系统和虚拟机之间互相执行 Ping 操作，如果互相能 Ping 得通，说明网络配置成功，操作步骤如下： 在虚拟机中 Ping 本地系统的 IP 地址 1ping 192.168.56.2 在本地系统中 Ping 虚拟机的 IP 1ping 192.168.56.10 VirtualBox 虚拟机硬件资源配置由于 Vagrant 创建 VirtualBox 虚拟机时，默认只会分配较少的处理器（CPU）和内存资源，因此需要在 VirtualBox 的用户界面里手动更改虚拟机的硬件资源配置，如下图所示： VirtualBox 虚拟机启用账号密码登录Vagrant 创建的 VirtualBox 虚拟机默认只支持 SSH 登录方式，为了后续操作方便，比如上传文件或者 SSH 远程连接，可以配置允许使用账号密码登录，步骤如下： 编辑 sshd 服务的配置文件 1$ sudo vi /etc/ssh/sshd_config 将 PasswordAuthentication 改为 yes 1PasswordAuthentication yes 重启 sshd 服务 1$ sudo service sshd restart Vagrant 打包 Box为了方便将本地的虚拟机备份或者分发到互联网上，可以将让 Vagrant 将虚拟机打包成 Box 文件。 特别注意 在执行打包命令之前，建议将 Vagrantfile 配置文件中的虚拟网络配置注释掉，否则以后通过添加 Box 的方式恢复虚拟机时，虚拟机可能会无法正常启动 例如，在执行打包命令之前，注释掉 Vagrantfile 配置文件中的 config.vm.network \"private_network\", ip: \"192.168.56.10\" 打包命令 命令格式：vagrant package --base {packagename} --output {/path/packagename.box} 命令参数：--base：当前本地要打包的虚拟机，--output：打包导出的文件的路径，{packagename}：Box 的包名（唯一标识） 打包示例 查看虚拟机列表 1vboxmanage list vms 虚拟机列表如下 12\"php-centos7\" {4b663e7c-ba60-4026-9330-64c2e6d6d1c4}\"java-centos7\" {7b1cf3a0-72e0-4d47-9a93-6aae4c701390} 打包虚拟机 1vagrant package --base php-centos7 --output ./php-centos7.box Vagrant 添加 Box从互联网上下载或者本地虚拟机打包得到的 Box 文件，可以通过 Vagrant 命令将 Box 添加到本地，然后就可以创建并启动对应的虚拟机，这类似 备份 --&gt; 恢复。 添加命令 命令格式：vagrant box add {packagename} {/path/packagename.box} 命令参数：{packagename}：Box 的包名（唯一标识），{/path/packagename.box}：Box 文件的本地路径 添加示例12345678# 添加本地的 Boxvagrant box add php-server-centos7 ./php-centos7.box# 创建虚拟机vagrant init php-server-centos7# 启动虚拟机vagrant up 提示 1、vagrant box add 命令除了可以指定 Box 文件的本地路径之外，还可以指定 Box 文件的网络地址（镜像源 URL），借此就可以加快镜像的下载速度 2、若是 Vagrant 添加的是本地虚拟机导出的 Box 文件，那么创建虚拟机后，一般还需要在 VirtualBox 的界面上手动更改虚拟机的 Mac 地址，否则虚拟机启动后会存在 Mac 地址冲突的问题 Vagrant 设置第三方镜像源为了提高 Vagrant 镜像的下载速度，可以在 这里 找到自己想要的镜像源（URL），然后使用指定的镜像源来添加 Box，最后再创建并启动虚拟机。 12345678# 使用指定的镜像源（URL）来添加 Boxvagrant box add {packagename} {url}# 创建虚拟机vagrant init {packagename}# 启动虚拟机vagrant up CentOS 7 虚拟机系统配置若安装的是 CentOS 7 虚拟机，可以执行以下操作来配置虚拟机操作系统（可选操作）。值得一提的是，以下操作都需要以 root 用户身份执行。 更换 YUM 源1234567891011# 备份原YUM源# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak# 使用阿里云的YUM源# curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 清理数据# yum clean all# 生成缓存# yum makecache 安装 EPEL 源1# yum install -y epel-release 安装软件1# yum install -y vim tree htop tmux net-tools telnet wget curl 时间同步1234567891011121314# 由于Centos7默认使用chronyd来同步时间，如果需要安装其他时间同步服务（ntpd），则需要禁用chronyd# systemctl disable chronyd# 安装ntp服务# yum install -y ntp# 开机启动ntp服务# systemctl enable ntpd# 启动ntp服务# systemctl start ntpd# 查看ntp服务的运行状态# systemctl status ntpd 1234567891011# 使用ntp手动同步时间# ntpdate pool.ntp.org# 设置亚洲时区# timedatectl set-timezone Asia/Shanghai# 启用ntp同步# timedatectl set-ntp yes# 查看当前系统时间、时间同步状态# timedatectl status 安装 Docker Docker 安装 123456789101112131415161718192021# 卸载旧版本的Docker# yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine# 添加YUM仓库# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo# 安装Docker# yum install -y docker-ce docker-ce-cli containerd.io# 启动Docker# systemctl start docker# 开机启动Docker# systemctl enable docker Docker 镜像加速 针对 Docker 客户端版本大于 1.10.0 的用户，可以通过修改 daemon 的配置文件 /etc/docker/daemon.json 来使用阿里云的镜像加速。值得一提的是，使用镜像加速之前，需要在阿里云平台注册账号，并开通容器镜像服务。 12345# 创建配置文件的目录# mkdir -p /etc/docker# 创建配置文件，并写入以下JSON内容# vi /etc/docker/daemon.json 123{ \"registry-mirrors\": [\"https://82m9ar63.mirror.aliyuncs.com\"]} 12345# 重载配置文件# systemctl daemon-reload# 重启Docker# systemctl restart docker 常见问题打包虚拟机后无法恢复运行问题描述 打包虚拟机后，通过添加 Box 的方式让虚拟机恢复运行，但虚拟机在启动时一直卡在 SSH auth method 阶段 1234567891011121314Bringing machine 'default' up with 'virtualbox' provider...==&gt; default: Importing base box 'Vagrant-Gulimall-CentOS7'...==&gt; default: Matching MAC address for NAT networking...==&gt; default: Setting the name of the VM: centos7==&gt; default: Clearing any previously set network interfaces...==&gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat==&gt; default: Forwarding ports... default: 22 (guest) =&gt; 2222 (host) (adapter 1)==&gt; default: Booting VM...==&gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key 解决方案 第一种方案：在执行打包命令之前，将 Vagrantfile 配置文件中的虚拟网络配置注释掉（如下），然后再执行打包命令 1# config.vm.network \"private_network\", ip: \"192.168.56.10\" 第二种方案：虚拟机恢复运行失败后，往 Vagrantfile 配置文件添加以下配置内容，然后重新启动虚拟机 123config.ssh.username = \"root\"config.ssh.password = \"vagrant\"config.ssh.insert_key = \"true\" 第三种方案：将要打包的虚拟机所在目录下的 private_key 秘钥文件（路径如下）复制一份，并拷贝覆盖到要恢复运行的虚拟机所在目录下，然后重新启动虚拟机 1/xxxx/.vagrant/machines/default/virtualbox/private_key 第四种方案：如果虚拟机还是无法正常启动，可以使用 --debug 参数来获取详细的启动日志信息 1$ vagrant up --debug 相关资料 Vagrant 导出的 Box 不能启动 Fix Vagrant ssh authentication failure after packaging vagrant box 虚拟机挂载共享目录失败问题描述 虚拟机启动时，提示无法挂载 VirtualBox 的共享目录 123456789101112Vagrant was unable to mount VirtualBox shared folders. This is usuallybecause the filesystem \"vboxsf\" is not available. This filesystem ismade available via the VirtualBox Guest Additions and kernel module.Please verify that these guest additions are properly installed in theguest. This is not a bug in Vagrant and is usually caused by a faultyVagrant box. For context, the command attempted was:mount -t vboxsf -o uid=0,gid=0,_netdev vagrant /vagrantThe error output from the command was:mount: unknown filesystem type 'vboxsf' 解决方案 先将 VirtualBox 虚拟机关闭掉 1$ vagrant halt 执行以下命令安装 vagrant-vbguest 插件 1$ vagrant plugin install vagrant-vbguest 1234Installing the 'vagrant-vbguest' plugin. This can take a few minutes...Fetching micromachine-3.0.0.gemFetching vagrant-vbguest-0.31.0.gemInstalled the plugin 'vagrant-vbguest (0.31.0)'! 插件安装完成后，重新启动虚拟机 1$ vagrant up 虚拟机正常启动后，建议执行以下命令卸载插件（可选操作） 1$ vagrant plugin uninstall vagrant-vbguest 在卸载插件时，可以忽略 Vagrant 输出的错误信息，然后使用以下命令查看插件是否成功卸载 1$ vagrant plugin list 相关资料 Vagrant was unable to mount VirtualBox shared folders 参考博客 超详细的 Vagrant 上手指南 Linux VirtualBox Vagrant 安装使用教程 VirtualBox + Vagrant 安装 VirtualBox 虚拟机 VirtualBox + Vagrant + Centos7，安装 Docker var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化 开发工具"},{"title":"Docker 安装 Oracle 11g 数据库","url":"/posts/e33a339c.html","text":"前言Docker 镜像本文直接使用 DockerHub 平台上的 Oracle 11g 镜像，基于 Ubuntu 18.04 LTS 系统，数据库版本是 Oracle Express Edition 11g Release 2（11.2.0.2.0）。 Oracle 版本列表在 Oracle 数据库的发展中，数据库一直处于不断升级状态，一共有以下几个版本： Oracle 8i：Oracle 8i 表示 Oracle 正式向 Internet 上发展，其中 i 表示就是 internet。 Oracle 9i：Oracle 8i 是一个过渡版本，Oracle 9i 是一个更加完善的数据库版本。 Oracle 10g：g 表示 grid，代表网格的意思，即这种数据库采用网格计算的方式进行操作。 Oracle 11g：是 Oracle 10g 的稳定版本，Oracle 11g 是目前使用最广泛的版本。 Oracle 12c：是 Oracle 2013 年推出的数据库版本，c 代表 Cloud，代表云计算的意思，同时 Oracle 12c 支持大数据的处理能力。 Oracle 18c、Oracle 19c 是对 12c 版本的完善和发展。 快速开始拉取镜像1# docker pull quay.io/maksymbilenko/oracle-12c 启动容器 启动容器 1# docker run -d -p 1521:1521 --name oracle-11g oracleinanutshell/oracle-xe-11g 允许远程连接 1# docker run -d -p 1521:1521 --name oracle-11g -e ORACLE_ALLOW_REMOTE=true oracleinanutshell/oracle-xe-11g 出于性能考虑，启动容器时可能需要禁用磁盘异步 IO 1# docker run -d -p 1521:1521 --name oracle-11g -e ORACLE_DISABLE_ASYNCH_IO=true oracleinanutshell/oracle-xe-11g 使用默认密码启用 XDB 用户（xdb） 1# docker run -d -p 1521:1521 --name oracle-11g -e ORACLE_ENABLE_XDB=true oracleinanutshell/oracle-xe-11g 启动 APEX 用户 1# docker run -d -p 1521:1521 --name oracle-11g -p 8080:8080 oracleinanutshell/oracle-xe-11g 123# 登录 http://localhost:8080/apex/apex_admin 并使用以下账号username: ADMINpassword: admin 对于最新的 APEX（18.1）用户，请先拉取 oracleinanutshell/oracle-xe-11g:18.04-apex 镜像 1# docker run -d -p 1521:1521 --name oracle-11g -p 8080:8080 oracleinanutshell/oracle-xe-11g:18.04-apex 123# 登录 http://localhost:8080/apex/apex_admin 并使用以下账号username: ADMINpassword: Oracle_11g Oracle 连接密码默认情况下，密码验证是禁用的（密码永不过期），可以使用以下配置信息连接 Oracle 数据库 12345hostname: localhostport: 1521sid: xeusername: systempassword: oracle 提示 SYS 和 SYSTEM 用户的默认密码都是 oracle。 Oracle 连接测试 连接 Docker 容器 1# docker exec -it oracle-11g /bin/bash 切换到 sqlplus 操作 1# sqlplus /nolog 连接 Oracle 11g 数据库 12345# 连接Oracle数据库SQL&gt; conn system/oracle# 查看Oracle的版本信息SQL&gt; SELECT BANNER FROM V$VERSION; Docker-Compose 使用12345678version: '3'services: oracle-db: image: oracleinanutshell/oracle-xe-11g:latest ports: - 1521:1521 - 8080:8080 Java 连接 Oracel 数据库下载 Oracle 驱动包由于 Oracle 授权的问题，无法从 Maven 中央仓库下载 Oracle 的数据库驱动包，Oracle 11g 的数据库驱动包可以 点击这里 下载得到。 Maven 引入 Oracle 驱动包将 Oralce 数据库驱动包存放到项目中的 lib 目录下，然后使用以下方式让 Maven 引入驱动包依赖。当然也可以使用其他方式引入，例如直接使用 Maven 命令 mvn install 将驱动包安装到本地仓库，接着按照平时的方式直接引入驱动包依赖即可，这里不再累述。 1234567&lt;dependency&gt; &lt;groupId&gt;oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt; &lt;version&gt;11.2.0.2.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/lib/ojdbc6.jar&lt;/systemPath&gt;&lt;/dependency&gt; 配置 Oracle 的 JDBC 连接信息1234driver-class-name=oracle.jdbc.OracleDriverurl=jdbc:oracle:thin:@localhost:1521:xeusername=systempassword=oracle 提示 更多关于 Java 连接 Oracle 数据库的教程内容，可以查看教程 《MyBatis-Plus 中 如何生成 Oralce 的主键》。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"数据库 容器化"},{"title":"IDEA 一键启动多个服务并配置占用内存的大小","url":"/posts/9577b09a.html","text":"配置一键启动多个服务 第一步： 选中项目，然后点击工具栏的 Edit Configurations 进入配置界面 第二步： 在弹出的配置界面中，点击左上角加号 +，选中 Compound 第三步： 选中创建出来的 Compound，点击右侧的加号 +，将需要一键启动的服务都加进去，然后更改名称 第四步骤： 选中已创建的 Compound，然后点击工具栏的绿色三角按钮，即可一键启动多个服务 配置服务占用内存的大小 第一步： 选中项目，然后点击工具栏的 Edit Configurations 进入配置界面 第二步： 选中需要配置内存大小的服务，然后点击右侧的 Environment 项，指定 VM options 的内容为 -Xmx512m JVM 参数 参数说明 -Xms JVM 启动时分配的内存大小 -Xmx JVM 运行过程中分配的最大内存大小 -Xmn JVM 堆内存中新生代的大小 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Kafka 入门教程之二","url":"/posts/60ddcede.html","text":"Kafka 生产者生产者消息发送流程生产者消息发送原理Kafka 的 Producer 发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程 — main 线程和 Sender 线程。在 main 线程中，会创建一个双端队列 RecordAccumulator。值得一提的是，main 线程将消息发送给 RecordAccumulator 时，Sender 线程会不断从 RecordAccumulator 中拉取消息并发送到 Kafka Broker。 生产者重要参数列表 生产者异步发送 API普通的异步发送提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 kafka-lesson-01。 Maven 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt;&lt;/dependency&gt; Java 代码 123456789101112131415161718192021public class CustomerProducer { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"127.0.0.1:9092,127.0.0.1:9093\"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 异步发送消息 producer.send(new ProducerRecord&lt;&gt;(\"test\", \"hello kafka \" + i)); } // 关闭资源 producer.close(); }} 测试代码 第一步：启动 Kafka 的控制台消费者： 1# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test 第二步：在 IDE 工具中执行代码，观察控制台消费者中是否接收到消息，如下所示： 12345hello kafka 0hello kafka 1hello kafka 2hello kafka 3hello kafka 4 带回调函数的异步发送回调方法会在 Producer 收到 ack 时调用，且为异步调用；该方法有两个参数，分别是元数据信息（RecordMetadata）和异常信息（Exception）。如果 Exception 为 null，则说明消息发送成功，如果 Exception 不为 null，则说明消息发送失败。值得一提的是，消息发送失败会自动重试发送，不需要在回调函数中手动重试发送。 Java 代码 12345678910111213141516171819202122232425262728public class CustomerProducer2 { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"127.0.0.1:9092,127.0.0.1:9093\"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 异步发送消息（带回调函数） producer.send(new ProducerRecord&lt;&gt;(\"test\", \"hello kafka \" + i), new Callback() { @Override public void onCompletion(RecordMetadata recordMetadata, Exception exception) { if (exception == null) { System.out.println(\"topic: \" + recordMetadata.topic() + \", partition: \" + recordMetadata.partition()); } } }); } // 关闭资源 producer.close(); }} 测试代码 除了在 Kafka 的控制台消费者中接收到消息之外，还可以在 IDE 的控制台看到如下的输出信息： 12345topic: test, partition: 0topic: test, partition: 0topic: test, partition: 0topic: test, partition: 0topic: test, partition: 0 生产者同步发送 API提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 kafka-lesson-02。 普通的同步发送同步发送的意思就是，当一条消息发送之后，会阻塞当前线程，直至收到 ack 应答。由于 send() 方法返回的是一个 Future 对象，根据 Futrue 对象的特点，只需调用 Future 对象的 get() 方法即可实现同步发送。 Maven 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt;&lt;/dependency&gt; Java 代码 12345678910111213141516171819202122232425public class CustomerProducer { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"127.0.0.1:9092,127.0.0.1:9093\"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 同步发送消息 try { producer.send(new ProducerRecord&lt;&gt;(\"test\", \"hello kafka \" + i)).get(); } catch (Exception e) { e.printStackTrace(); } } // 关闭资源 producer.close(); }} 测试代码 第一步：启动 Kafka 的控制台消费者： 1# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test 第二步：在 IDE 工具中执行代码，观察控制台消费者中是否接收到消息，如下所示： 12345hello kafka 0hello kafka 1hello kafka 2hello kafka 3hello kafka 4 带回调函数的同步发送1234567891011121314151617181920212223242526272829303132public class CustomerProducer2 { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"127.0.0.1:9092,127.0.0.1:9093\"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 同步发送消息（带回调函数） try { producer.send(new ProducerRecord&lt;&gt;(\"test\", \"hello kafka \" + i), new Callback() { @Override public void onCompletion(RecordMetadata recordMetadata, Exception exception) { if (exception == null) { System.out.println(\"topic: \" + recordMetadata.topic() + \", partition: \" + recordMetadata.partition()); } } }).get(); } catch (Exception e) { e.printStackTrace(); } } // 关闭资源 producer.close(); }} 测试代码 除了在 Kafka 的控制台消费者中接收到消息之外，还可以在 IDE 的控制台看到如下的输出信息： 12345topic: test, partition: 0topic: test, partition: 2topic: test, partition: 0topic: test, partition: 1topic: test, partition: 2 生产者分区生产者分区分区的优点 提高并行度，生产者可以以分区为单位发送数据，消费者可以以分区为单位消费数据 便于合理使用存储资源，每个 Partition 在一个 Broker 上存储，可以把海量的数据按照分区切割成一块一块的数据并存储在多台 Broker 上。合理控制分区的任务，可以实现负载均衡的效果 生产者发送消息的分区策略默认的分区器类是 DefaultPartitioner，部分源码如下： 123456789101112131415/** * The default partitioning strategy: * &lt;ul&gt; * &lt;li&gt;If a partition is specified in the record, use it * &lt;li&gt;If no partition is specified but a key is present choose a partition based on a hash of the key * &lt;li&gt;If no partition or key is present choose the sticky partition that changes when the batch is full. * * See KIP-480 for details about sticky partitioning. */public class DefaultPartitioner implements Partitioner { ......} 通过 KafkaProducer 类的 send() 方法发送消息时，需要指定 ProducerRecord 对象作为参数，ProducerRecord 类的构造方法如下： 12345678910111213141516171819202122232425public class ProducerRecord&lt;K, V&gt; { public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value, Iterable&lt;Header&gt; headers) { ...... } public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value) { ...... } public ProducerRecord(String topic, Integer partition, K key, V value, Iterable&lt;Header&gt; headers) { ...... } public ProducerRecord(String topic, Integer partition, K key, V value) { ...... } public ProducerRecord(String topic, K key, V value) { ...... } public ProducerRecord(String topic, V value) { ...... } 调用 ProducerRecord 类不同的构造方法时，有以下几种分区策略： 在指明 partition 的情况下，直接将指明的值作为 partition 值。例如：partition=0，那么数据会被写入分区 0。 在没有指明 partition 值，但有指定 key 的情况下，将 key 的 Hash 值与 topic 的 partition 数进行取余来得到 partition 值。例如：key 的 Hash 值是 5，topic 的 partition 数是 2，那么 key 对应的 value 会被写入 1 号分区。 在既没有指明 partition 值，又没有指定 key 的情况下，Kafka 会采用 Sticky Partition 黏性分区器，也就是会随机选择一个分区，并尽可能一直使用该分区，等该分区的 batch 已满或者已完成，Kafka 再随机一个分区进行使用（和上一次选的分区不同）。例如：第一次随机选择 0 号分区，等 0 号分区当前批次满了（默认 16K 大小）或者 linger.ms 设置的时间到了，Kafka 会再随机选择一个分区进行使用（如果还是 0 分区会继续随机选择一个分区）。 自定义生产者的分区器开发人员可以根据业务需求自定义分区器，只需要实现 Partitioner 接口即可。 提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 kafka-lesson-03。 自定义分区器类，实现 Partitioner 接口，并重写 partition() 方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 自定义分区器 */public class CustomPartitioner implements Partitioner { /** * 返回消息对应的分区 * * @param topic 主题 * @param key 消息的 key * @param keyBytes 消息的 key 序列化后的字节数组 * @param value 消息的 value * @param valueBytes 消息的 value 序列化后的字节数组 * @param cluster 集群元数据可以查看分区信息 * @return */ @Override public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { // 获取消息内容 String msgValue = value.toString(); // 定义分区号 int partition; if (msgValue.contains(\"order\")) { partition = 0; } else { partition = 1; } // 返回分区号 return partition; } /** * 关闭资源 */ @Override public void close() { } /** * 配置信息 * * @param configs */ @Override public void configure(Map&lt;String, ?&gt; configs) { }} 在生产者的配置中添加分区器参数，以此来指定自定义分区器 12345678910111213141516171819202122232425262728293031/** * 异步发送 */public class CustomerProducer { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"127.0.0.1:9092,127.0.0.1:9093\"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 指定自定义分区器 properties.setProperty(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartitioner.class.getName()); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 异步发送消息 producer.send(new ProducerRecord&lt;&gt;(\"test\", \"hello kafka \" + i), new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { System.out.println(\"Partition : \" + metadata.partition()); } }); } // 关闭资源 producer.close(); }} 生产者最佳实践生产者如何提高吞吐量参数优化为了让生产者提高吞吐量（发送消息的效率），可以优化以下几个参数： batch.size：批次大小，默认 16k linger.ms：等待时间，默认 0ms，修改为 5-100ms compression.type：压缩方式，默认是 none，修改过为 snappy RecordAccumulator：缓冲区（双端队列）大小，默认是 32m，修改为 64m 参数说明 示例代码提示 本节所需的案例代码，可以直接从 GitHub 下载对应章节 kafka-lesson-04。 123456789101112131415161718192021222324252627282930public class CustomerProducer { public static void main(String[] args) { Properties properties = new Properties(); // 指定Kafka集群的连接信息 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"127.0.0.1:9092,127.0.0.1:9093\"); // 指定序列化器（必需） properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 等待时间（默认0ms） properties.put(ProducerConfig.LINGER_MS_CONFIG, 5); // 批次大小（默认16K） properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16 * 1024); // 压缩方式（默认none） properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, \"snappy\"); // 缓冲区大小（默认32M） properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 64 * 1024 * 1024); // 创建生产者对象 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(properties); for (int i = 0; i &lt; 5; i++) { // 异步发送消息 producer.send(new ProducerRecord&lt;&gt;(\"test\", \"hello kafka \" + i)); } // 关闭资源 producer.close(); }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"分布式"},{"title":"Kafka 入门教程之一","url":"/posts/b6be8183.html","text":"消息队列目前企业中比较常见的消息队列产品主要有 Kafka、ActiveMQ、RabbitMQ、RocketMQ 等。在大数据场景主要采用 Kafka 作为消息队列，而在 JavaEE 开发中主要采用 ActiveMQ、RabbitMQ、RocketMQ。 消息队列的优势 解耦 - 允许独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束 缓冲 - 有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况 消峰 - 在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源并随时待命，这无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃 异步通信 - 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们 可恢复性 - 系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理 消息队列的两种模式点对点模式点对点模式 就是一对一，消费者主动拉取数据，消息收到后消息会被清除。消息生产者将消息发送到 Queue 中，然后消息消费者从 Queue 中取出并消费消息。消息被消费以后，Queue 中不再存储它，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。 发布 / 订阅模式发布/订阅模式 就是一对多，消息产生后主动推送给订阅者，消费者消费消息之后不会清除消息。消息生产者（发布）将消息发布到 topic 主题（如浏览、点赞、收藏、评论等）中，同时有多个消息消费者（订阅）消费该消息。这和点对点模式不同，每个消费者互相独立，发布到 topic 的消息会被所有订阅者消费。 Kafka 详细介绍在流式计算中，Kafka 一般用于缓存数据，Storm 通过消费 Kafka 的数据来进行计算。 Apache Kafka 是一个开源的分布式消息队列系统，由 Scala 语言编写。 Kafka 最初由 LinkedIn 公司开发，并于 2011 年初开源。2012 年 10 月从 Apache Incubator 毕业，该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。 Kafka 集群由多个 Kafka 实例（broker）组成，无论是 Kafka 集群，还是 Consumer 都依赖于 Zookeeper 集群保存一些 meta 信息，以此来保证系统的高可用性。 Kafka 概述 传统定义：Kafka 是一个分布式的基于发布 / 订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 最新定义：Kafka 是一个开源的分布式事件流平台（EventStreaming Platform），被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用。 Kafka 学习路线 Kafka 学习路线 Kafka 基础架构 Producer：消息生产者，就是向 Kafka Broker 发消息的客户端。 Consumer：消息消费者，就是向 Kafka Broker 取消息的客户端。 Consumer Group (CG)：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费，消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 Broker：一台 Kafka 服务器就是一个 broker。一个 Kafka 集群由多个 broker 组成。一个 broker 可以容纳多个 topic。 Topic：主题，可以理解为一个队列，生产者和消费者面向的都是一个 topic。 Partition：分区，为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即 Kafka 服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。 Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且让 Kafka 仍然能够继续工作，Kafka 为此提供了副本机制。一个 topic 的每个分区都有若干个副本，包括一个 leader 和若干个 follower。 Leader：每个分区多个副本的 主，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。 Follower：每个分区多个副本的 从，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader。 Kafka 企业案例 Kafka 集群搭建单机搭建 Kafka 集群 Linux 单机搭建 Kafka 集群 生产环境搭建 Kafka 集群 Linux 生产环境搭建 Kafka 集群 Kafka 常用命令Topic 命令命令参数 使用案例 创建主题：创建名称为 test、分区数量为 1 和 分区副本数量为 3 的主题 1# ./kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --topic test --partitions 1 --replication-factor 3 查看主题列表 1# ./kafka-topics.sh --list --bootstrap-server 127.0.0.1:9092 查看主题详情：查看 test 主题的详细信息（例如分区数量、分区副本数量等） 1# ./kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic test 更改主题的分区数量：更改 test 主题的分区数量为 3 1# ./kafka-topics.sh --alter --bootstrap-server 127.0.0.1:9092 --topic test --partitions 3 特别注意 Kafka 不支持更改主题的分区副本数量 更改主题的分区数量时，只能增加，不能减少 删除主题：删除 test 主题 1# ./kafka-topics.sh --delete --bootstrap-server 127.0.0.1:9092 --topic test Consumer 命令命令参数 使用案例 消费 test 主题中的数据（增量消费） 1# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test 消费 test 主题中的所有数据（包括历史数据） 1# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test --from-beginning Producer 命令命令参数 使用案例 生产消息：往 test 主题发送消息 1# ./kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic test var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"分布式"},{"title":"Linux 生产环境搭建 Kafka 集群","url":"/posts/6dceb9c9.html","text":"前言本文适用于在 Centos/Debian/Ubuntu 等 Linux 发行版系统上，使用多台物理机器（至少三台）搭建 Kafka 集群。 Zookeeper 集群搭建本文的 Kafka 集群搭建依赖于 Zookeeper，因此生产环境需要将 Zookeeper 集群提前搭建起来。值得一提的是，从 Kafka 2.8.0 版本开始，Kafka 自身实现了 Raft 分布式一致性机制，这意味着 Kafka 是可以脱离 ZooKeeper 独立运行的。 集群规划 节点 IP 地址 端口 版本号 Zookeeper 节点 1 192.168.1.1 2181 3.4.10 Zookeeper 节点 2 192.168.1.2 2181 3.4.10 Zookeeper 节点 3 192.168.1.3 2181 3.4.10 集群部署由于篇幅有限，Linux 生产环境搭建 Zookeeper 集群的内容这里不再累述，详细教程可看 这里。 Kafka 集群搭建集群规划 节点 IP 地址 端口 版本号 Kafka 节点 1 192.168.1.1 9092 2.13-3.2.1 Kafka 节点 2 192.168.1.2 9092 2.13-3.2.1 Kafka 节点 3 192.168.1.3 9092 2.13-3.2.1 集群搭建 Kafka 下载 Kafka 的安装包可以从 官网 下载。 以下载得到的压缩文件 kafka_2.13-3.2.1.tgz 为例，2.11 是 Scala 的版本号，3.2.1 是 Kafka 的版本号。 Kafka 安装 1234567891011121314151617# 创建安装目录# mkdir -p /usr/local/kafka-cluster# 进入安装目录# cd /usr/local/kafka-cluster# 下载文件# wget https://downloads.apache.org/kafka/3.2.1/kafka_2.13-3.2.1.tgz# 解压文件# tar -xvf kafka_2.13-3.2.1.tgz# 重命名目录# mv kafka_2.13-3.2.1 kafka-node1# 删除文件# rm -rf kafka_2.13-3.2.1.tgz Kafka 基础配置 12345678# 进入安装目录# cd /usr/local/kafka-cluster/kafka-node1# 创建日志目录（数据存储目录）# mkdir logs# 编辑配置文件（指定以下内容即可）# vim config/server.properties 最关键的配置内容是 broker.id、log.dirs、zookeeper.connect，其中的 zookeeper.connect 是 Zookeeper 连接地址，建议使用 /kafka 作为后缀，这样方便日后在 Zookeeper 里统一管理 Kafka 的数据。 12345678910111213141516171819202122232425262728# broker 的全局唯一编号,不能重复broker.id=1# 处理网络请求的线程数量num.network.threads=3# 用来处理磁盘 IO 的现成数量num.io.threads=8# 发送套接字的缓冲区大小socket.send.buffer.bytes=102400# 接收套接字的缓冲区大小socket.receive.buffer.bytes=102400# 请求套接字的缓冲区大小socket.request.max.bytes=104857600# 运行日志存放的路径log.dirs=/usr/local/kafka-cluster/kafka-node1/logs# topic 在当前 broker 上的分区个数num.partitions=1# 用来恢复和清理 data 下数据的线程数量num.recovery.threads.per.data.dir=1# 每个 topic 创建时的副本数,默认时 1 个副本offsets.topic.replication.factor=1# 每个 segment 文件保留的最长时间,超时将被删除log.retention.hours=168# 每个 segment 文件的大小,默认最大 1Glog.segment.bytes=1073741824# 检查过期数据的时间,默认 5 分钟检查一次是否数据过期log.retention.check.interval.ms=300000# 配置连接 Zookeeper 集群地址zookeeper.connect=192.168.1.1:2181,192.168.1.2:2181,192.168.1.3:2181/kafka Kafka 创建多个节点 复制两份上面已经配置好的 Kafka 安装目录到其他服务器节点上，以此作为集群中另外两个节点的安装文件，例如 kafka-node2、kafka-node3。安装目录复制完成后，还需要更改每个新节点里的 server.properties 配置文件的 broker.id、log.dirs。节点二和节点三的最终配置如下： 123# 节点二的配置broker.id=2log.dirs=/usr/local/kafka-cluster/kafka-node2/logs 123# 节点三的配置broker.id=3log.dirs=/usr/local/kafka-cluster/kafka-node3/logs 集群管理 集群启动 注意 启动 Kafka 集群之前，必须确保 Zookeeper 集群已经启动成功，这是因为本文搭建的 Kafka 集群依赖于 Zookeeper 集群。 123456789# 后台启动# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node1/config/server.properties# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node2/config/server.properties# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node3/config/server.properties# 或者前台启动（可直接查看启动时输出的日志信息）# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node1/config/server.properties# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node2/config/server.properties# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node3/config/server.properties 查看状态 集群启动后，可以使用以下命令查看集群的运行状态。如果发现集群启动失败，则可以使用前台的方式再次启动集群，然后根据终端输出的错误日志信息来定位问题。 12345678910# 查看端口占用情况# netstat -nplt | grep 9092# netstat -nplt | grep 9093# netstat -nplt | grep 9094# 查看Kafka进程# ps -aux | grep kafka# 查看Java进程# jps -l 集群关闭 注意 关闭 Kafka 集群时，一定要等 Kafka 所有节点进程全部关闭后再关闭 Zookeeper 集群。因为 Zookeeper 集群当中记录着 Kafka 集群的相关信息，Zookeeper 集群一旦先关闭，Kafka 集群就没有办法再获取关闭进程的信息，此时只能手动强制杀死 Kafka 进程。 123# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-stop.sh stop# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-stop.sh stop# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-stop.sh stop 清空数据 若希望清空 Kafka 集群的数据，则可以按照以下步骤操作。清空数据的操作不可恢复，生产环境下慎用。 第一步：关闭 Kafka 集群第二步：连接 Zookeeper 集群，然后删除 /kafka 目录第三步：删除 Kafka 各个集群节点的安装目录下的 logs 目录（文件夹）第四步：重启 Kafka 集群 集群测试 进入任意节点的安装目录下的 bin 目录 12# 进入安装目录# cd /usr/local/kafka-cluster/kafka-node1/bin 创建主题 12# 创建主题# ./kafka-topics.sh --create --bootstrap-server 192.168.1.1:9092 --replication-factor 3 --partitions 1 --topic test 查看主题列表 12# 查看主题列表# ./kafka-topics.sh --list --bootstrap-server 192.168.1.1:9092 查看主题详细信息 12# 查看主题详细信息# ./kafka-topics.sh --bootstrap-server 192.168.1.1:9092 --topic test --describe 启动控制台消费者 12# 启动消费者# ./kafka-console-consumer.sh --bootstrap-server 192.168.1.1:9092 --topic test --from-beginning 启动控制台生产者 12# 启动生产者# ./kafka-console-producer.sh --broker-list 192.168.1.1:9092 --topic test 生产者正常启动后，在生产者的控制台手动输入 hello kafka，消费者的控制台就可以消费到生产者的消息，并输出 hello kafka，这表示消费者成功消费了生产者发送的消息！ Kafka 更改端口（可选）若希望更改 Kafka 的默认端口（9092），可以按照以下步骤更改 Kafka 安装目录下 config 子目录里的各个配置文件。例如可以将 Kafka 的默认端口更改为 9090，如下所示： 1234# vim config/server.properties# 默认端口号listeners=PLAINTEXT://:9090 1234# vim config/connect-standalone.properties# 单机环境的端口号bootstrap.servers=localhost:9090 1234# vim config/connect-distributed.properties# 集群环境的端口号bootstrap.servers=localhost:9090 1234# vim config/producer.properties# 发布端的端口号bootstrap.servers=localhost:9090 1234# vim config/consumer.properties# 消费端的端口号bootstrap.servers=localhost:9090 参考博客 Kafka 集群搭建超详细教程 Linux 单机搭建 Kafka 集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux"},{"title":"Linux 单机搭建 Kafka 集群","url":"/posts/124a5015.html","text":"前言本文适用于在 Centos/Debian/Ubuntu 等 Linux 发行版系统上，使用单机搭建 Kafka 集群。 Zookeeper 集群搭建本文的 Kafka 集群搭建依赖于 Zookeeper，因此需要将 Zookeeper 单机集群提前搭建起来。值得一提的是，从 Kafka 2.8.0 版本开始，Kafka 自身实现了 Raft 分布式一致性机制，这意味着 Kafka 是可以脱离 ZooKeeper 独立运行的。 集群规划 节点 IP 地址 端口 版本号 Zookeeper 节点 1 127.0.0.1 2181 3.4.10 Zookeeper 节点 2 127.0.0.1 2182 3.4.10 Zookeeper 节点 3 127.0.0.1 2183 3.4.10 集群搭建由于篇幅有限，Linux 单机搭建 Zookeeper 集群的内容这里不再累述，详细教程可看 这里。 Kafka 集群搭建集群规划 节点 IP 地址 端口 版本号 Kafka 节点 1 127.0.0.1 9092 2.13-3.2.1 Kafka 节点 2 127.0.0.1 9093 2.13-3.2.1 Kafka 节点 3 127.0.0.1 9094 2.13-3.2.1 集群搭建 Kafka 下载 Kafka 的安装包可以从 官网 下载。 以下载得到的压缩文件 kafka_2.13-3.2.1.tgz 为例，2.11 是 Scala 的版本号，3.2.1 是 Kafka 的版本号。 Kafka 安装 1234567891011121314151617# 创建安装目录# mkdir -p /usr/local/kafka-cluster# 进入安装目录# cd /usr/local/kafka-cluster# 下载文件# wget https://downloads.apache.org/kafka/3.2.1/kafka_2.13-3.2.1.tgz# 解压文件# tar -xvf kafka_2.13-3.2.1.tgz# 重命名目录# mv kafka_2.13-3.2.1 kafka-node1# 删除文件# rm -rf kafka_2.13-3.2.1.tgz Kafka 基础配置 12345678# 进入安装目录# cd /usr/local/kafka-cluster/kafka-node1# 创建日志目录（数据存储目录）# mkdir logs# 编辑配置文件（指定以下内容即可）# vim config/server.properties 最关键的配置内容是 broker.id、log.dirs、zookeeper.connect，其中的 zookeeper.connect 是 Zookeeper 连接地址，建议使用 /kafka 作为后缀，这样方便日后在 Zookeeper 里统一管理 Kafka 的数据。在项目的开发测试阶段，其他配置内容暂时可以使用默认值。 12345678910111213141516171819202122232425262728# broker 的全局唯一编号,不能重复broker.id=1# 处理网络请求的线程数量num.network.threads=3# 用来处理磁盘 IO 的现成数量num.io.threads=8# 发送套接字的缓冲区大小socket.send.buffer.bytes=102400# 接收套接字的缓冲区大小socket.receive.buffer.bytes=102400# 请求套接字的缓冲区大小socket.request.max.bytes=104857600# 运行日志存放的路径log.dirs=/usr/local/kafka-cluster/kafka-node1/logs# topic 在当前 broker 上的分区个数num.partitions=1# 用来恢复和清理 data 下数据的线程数量num.recovery.threads.per.data.dir=1# 每个 topic 创建时的副本数,默认时 1 个副本offsets.topic.replication.factor=1# 每个 segment 文件保留的最长时间,超时将被删除log.retention.hours=168# 每个 segment 文件的大小,默认最大 1Glog.segment.bytes=1073741824# 检查过期数据的时间,默认 5 分钟检查一次是否数据过期log.retention.check.interval.ms=300000# 配置连接 Zookeeper 集群地址zookeeper.connect=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183/kafka Kafka 端口配置 单机搭建 Kafka 集群时，为了解决端口冲突的问题，还需要指定 Kafka 监听的端口，必须将下述各个配置文件里的端口都更改掉。 1234# vim config/server.properties# 默认端口号listeners=PLAINTEXT://:9092 1234# vim config/connect-standalone.properties# 单机环境的端口号bootstrap.servers=localhost:9092 1234# vim config/connect-distributed.properties# 集群环境的端口号bootstrap.servers=localhost:9092 1234# vim config/producer.properties# 发布端的端口号bootstrap.servers=localhost:9092 1234# vim config/consumer.properties# 消费端的端口号bootstrap.servers=localhost:9092 Kafka 创建多个节点 复制两份上面已经配置好的 Kafka 安装目录，以此作为集群中另外两个节点的安装文件，例如 kafka-node2、kafka-node3。安装目录复制完成后，还需要为每个新节点按照以下步骤更改对应的内容： 第一步：更改 server.properties 配置文件里的 broker.id、log.dirs第二步：更改 Kafka 监听的端口，包括更改上述的 server.properties、connect-standalone.properties、connect-distributed.properties、producer.properties、consumer.properties 配置文件 上述两个步骤完成后，节点二和节点三的最终配置如下： 123456# 节点二的配置broker.id=2listeners=PLAINTEXT://:9093log.dirs=/usr/local/kafka-cluster/kafka-node2/logsbootstrap.servers=localhost:9093 123456# 节点三的配置broker.id=3listeners=PLAINTEXT://:9094log.dirs=/usr/local/kafka-cluster/kafka-node3/logsbootstrap.servers=localhost:9094 集群管理 集群启动 注意 启动 Kafka 集群之前，必须确保 Zookeeper 集群已经启动成功，这是因为本文搭建的 Kafka 集群依赖于 Zookeeper 集群。 123456789# 后台启动# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node1/config/server.properties# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node2/config/server.properties# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-start.sh -daemon /usr/local/kafka-cluster/kafka-node3/config/server.properties# 或者前台启动（可直接查看启动时输出的日志信息）# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node1/config/server.properties# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node2/config/server.properties# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-start.sh /usr/local/kafka-cluster/kafka-node3/config/server.properties 查看状态 集群启动后，可以使用以下命令查看集群的运行状态。如果发现集群启动失败，则可以使用前台的方式再次启动集群，然后根据终端输出的错误日志信息来定位问题。 12345678910# 查看端口占用情况# netstat -nplt | grep 9092# netstat -nplt | grep 9093# netstat -nplt | grep 9094# 查看Kafka进程# ps -aux | grep kafka# 查看Java进程# jps -l 集群关闭 注意 关闭 Kafka 集群时，一定要等 Kafka 所有节点进程全部关闭后再关闭 Zookeeper 集群。因为 Zookeeper 集群当中记录着 Kafka 集群的相关信息，Zookeeper 集群一旦先关闭，Kafka 集群就没有办法再获取关闭进程的信息，此时只能手动强制杀死 Kafka 进程。 123# /usr/local/kafka-cluster/kafka-node1/bin/kafka-server-stop.sh stop# /usr/local/kafka-cluster/kafka-node2/bin/kafka-server-stop.sh stop# /usr/local/kafka-cluster/kafka-node3/bin/kafka-server-stop.sh stop 清空数据 若希望清空 Kafka 集群的数据，则可以按照以下步骤操作。清空数据的操作不可恢复，生产环境下慎用。 第一步：关闭 Kafka 集群第二步：连接 Zookeeper 集群，然后删除 /kafka 目录第三步：删除 Kafka 各个集群节点的安装目录下的 logs 目录（文件夹）第四步：重启 Kafka 集群 集群测试 进入任意节点的安装目录下的 bin 目录 12# 进入安装目录# cd /usr/local/kafka-cluster/kafka-node1/bin 创建主题 12# 创建主题# ./kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 3 --partitions 1 --topic test 查看主题列表 12# 查看主题列表# ./kafka-topics.sh --list --bootstrap-server 127.0.0.1:9092 查看主题详细信息 12# 查看主题详细信息# ./kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --topic test --describe 启动控制台消费者 12# 启动消费者# ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test --from-beginning 启动控制台生产者 12# 启动生产者# ./kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic test 生产者正常启动后，在生产者的控制台手动输入 hello kafka，消费者的控制台就可以消费到生产者的消息，并输出 hello kafka，这表示消费者成功消费了生产者发送的消息！ 参考博客 Kafka 集群搭建超详细教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux"},{"title":"Java 微信支付开发入门教程","url":"/posts/ba04f364.html","text":"前言 微信支付 - 官网 微信支付 - 官方开发文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 在线支付"},{"title":"Java 自动生成数据库文档","url":"/posts/28df7196.html","text":"前言在企业级开发中，我们经常会有编写数据库文档的时间付出，关于数据库文档的状态：要么没有、要么有但都是手写、后期运维开发都需要手动对文档进行维护，很是繁琐。如果忘记一次维护就会给以后的工作造成很多困扰，这无形中留了很多坑给自己和后人。screw 是一款简洁好用的数据库文档生成工具，专为解决这一开发痛点而生。 screw 介绍特色功能 灵活扩展 支持自定义模板 支持多种数据库 支持多种格式的文档 简洁、轻量、设计良好 数据库支持 MySQL MariaDB TIDB Oracle SqlServer PostgreSQL Cache DB（2016） 文档类型支持 Html Word Markdown screw 使用基于 Java 代码第一种使用方式是基于 Java 代码，自动生成数据库文档。 Maven 依赖12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.31&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.smallbun.screw&lt;/groupId&gt; &lt;artifactId&gt;screw-core&lt;/artifactId&gt; &lt;version&gt;1.0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.20&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Java 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import cn.smallbun.screw.core.Configuration;import cn.smallbun.screw.core.engine.EngineConfig;import cn.smallbun.screw.core.engine.EngineFileType;import cn.smallbun.screw.core.engine.EngineTemplateType;import cn.smallbun.screw.core.execute.DocumentationExecute;import cn.smallbun.screw.core.process.ProcessConfig;import com.zaxxer.hikari.HikariConfig;import com.zaxxer.hikari.HikariDataSource;import javax.sql.DataSource;import java.util.ArrayList;/** * 生成数据库文档 */public class ScrewTest { public static final String fileOutputDir = \"D:/database/docs\"; public static void main(String[] args) { documentGeneration(); } /** * 文档生成 */ public static void documentGeneration() { //数据源 HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDriverClassName(\"com.mysql.cj.jdbc.Driver\"); hikariConfig.setJdbcUrl(\"jdbc:mysql://127.0.0.1:3306/database\"); hikariConfig.setUsername(\"root\"); hikariConfig.setPassword(\"123456\"); //设置可以获取tables remarks信息 hikariConfig.addDataSourceProperty(\"useInformationSchema\", \"true\"); hikariConfig.setMinimumIdle(2); hikariConfig.setMaximumPoolSize(5); DataSource dataSource = new HikariDataSource(hikariConfig); //生成配置 EngineConfig engineConfig = EngineConfig.builder() //生成文件路径 .fileOutputDir(fileOutputDir) //打开目录 .openOutputDir(true) //文件类型 .fileType(EngineFileType.HTML) //生成模板实现 .produceType(EngineTemplateType.freemarker) //自定义文件名称 .fileName(\"自定义文件名称\").build(); //忽略表 ArrayList&lt;String&gt; ignoreTableName = new ArrayList&lt;&gt;(); //忽略表前缀 ArrayList&lt;String&gt; ignorePrefix = new ArrayList&lt;&gt;(); //忽略表后缀 ArrayList&lt;String&gt; ignoreSuffix = new ArrayList&lt;&gt;(); ProcessConfig processConfig = ProcessConfig.builder() //指定生成逻辑、当存在指定表、指定表前缀、指定表后缀时，将生成指定表，其余表不生成、并跳过忽略表配置 //根据名称指定表生成 .designatedTableName(new ArrayList&lt;&gt;()) //根据表前缀生成 .designatedTablePrefix(new ArrayList&lt;&gt;()) //根据表后缀生成 .designatedTableSuffix(new ArrayList&lt;&gt;()) //忽略表名 .ignoreTableName(ignoreTableName) //忽略表前缀 .ignoreTablePrefix(ignorePrefix) //忽略表后缀 .ignoreTableSuffix(ignoreSuffix).build(); //配置 Configuration config = Configuration.builder() //版本 .version(\"1.0.0\") //描述 .description(\"数据库设计文档生成\") //数据源 .dataSource(dataSource) //生成配置 .engineConfig(engineConfig) //生成配置 .produceConfig(processConfig) .build(); //执行生成 new DocumentationExecute(config).execute(); }} 基于 Maven 插件第二种使用方式是基于 Maven 插件，自动生成数据库文档。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;cn.smallbun.screw&lt;/groupId&gt; &lt;artifactId&gt;screw-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${lastVersion}&lt;/version&gt; &lt;dependencies&gt; &lt;!-- HikariCP --&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql driver--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.20&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;!--username--&gt; &lt;username&gt;root&lt;/username&gt; &lt;!--password--&gt; &lt;password&gt;123456&lt;/password&gt; &lt;!--driver--&gt; &lt;driverClassName&gt;com.mysql.cj.jdbc.Driver&lt;/driverClassName&gt; &lt;!--jdbc url--&gt; &lt;jdbcUrl&gt;jdbc:mysql://127.0.0.1:3306/database&lt;/jdbcUrl&gt; &lt;!--生成文件类型--&gt; &lt;fileType&gt;HTML&lt;/fileType&gt; &lt;!--打开文件输出目录--&gt; &lt;openOutputDir&gt;false&lt;/openOutputDir&gt; &lt;!--生成模板--&gt; &lt;produceType&gt;freemarker&lt;/produceType&gt; &lt;!--文档名称 为空时:将采用[数据库名称-描述-版本号]作为文档名称--&gt; &lt;fileName&gt;测试文档名称&lt;/fileName&gt; &lt;!--描述--&gt; &lt;description&gt;数据库文档生成&lt;/description&gt; &lt;!--版本--&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;!--标题--&gt; &lt;title&gt;数据库文档&lt;/title&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 扩展模块在日常的开发中，经过需求分析、建模之后，往往会先在数据库中建表，其次再进行代码的开发。使用 POJO 生成功能可以直接根据数据库表生成对应的 Java POJO 对象，这可以帮助开发人员节省一些重复劳动。screw 支持 POJO 生成功能，目前处于初步开发的状态，且仅支持 MySQL 数据库。 POJO 生成模块12345&lt;dependency&gt; &lt;groupId&gt;cn.smallbun.screw&lt;/groupId&gt; &lt;artifactId&gt;screw-extension&lt;/artifactId&gt; &lt;version&gt;${lastVersion}&lt;/version&gt; &lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * POJO 生成 */void pojoGeneration() { //数据源 HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDriverClassName(\"com.mysql.cj.jdbc.Driver\"); hikariConfig.setJdbcUrl(\"jdbc:mysql://127.0.0.1:3306/database\"); hikariConfig.setUsername(\"root\"); hikariConfig.setPassword(\"123456\"); //设置可以获取tables remarks信息 hikariConfig.addDataSourceProperty(\"useInformationSchema\", \"true\"); hikariConfig.setMinimumIdle(2); hikariConfig.setMaximumPoolSize(5); DataSource dataSource = new HikariDataSource(hikariConfig); ProcessConfig processConfig = ProcessConfig.builder() //指定生成逻辑、当存在指定表、指定表前缀、指定表后缀时，将生成指定表，其余表不生成、并跳过忽略表配置 //根据名称指定表生成 .designatedTableName(new ArrayList&lt;&gt;()) //根据表前缀生成 .designatedTablePrefix(new ArrayList&lt;&gt;()) //根据表后缀生成 .designatedTableSuffix(new ArrayList&lt;&gt;()).build(); //设置生成pojo相关配置 PojoConfiguration config = new PojoConfiguration(); //设置文件存放路径 config.setPath(\"/cn/smallbun/screw/\"); //设置包名 config.setPackageName(\"cn.smallbun.screw\"); //设置是否使用lombok config.setUseLombok(false); //设置数据源 config.setDataSource(dataSource); //设置命名策略 config.setNameStrategy(new HumpNameStrategy()); //设置表过滤逻辑 config.setProcessConfig(processConfig); //执行生成 new PojoExecute(config).execute();} 常见问题问题一 生成的数据库文档出现乱码？ 在连接 MySQL 的 URL 中加入 characterEncoding=UTF-8 即可 问题二 MySQL 数据库表和列字段有注释，但生成的数据库文档却没有注释？ 在连接 MySQL 的 URL 中加入 useInformationSchema=true 即可 问题三 运行抛出异常： Caused by: java.lang.NoSuchFieldError: VERSION_2_3_30 检查项目中 freemarker 的依赖版本，这是由于版本过低造成的，升级版本为 2.3.30 即可 问题四 运行抛出异常： java.lang.AbstractMethodError: com.mysql.jdbc.JDBC4Connection.getSchema()Ljava/lang/String; 这是因为 MySQL 驱动的版本过低造成的，升级 MySQL 驱动的版本为最新即可 问题五 运行抛出异常： java.lang.AbstractMethodError: oracle.jdbc.driver.T4CConnection.getSchema()Ljava/lang/String; 这是因为 Oracle 驱动版本过低造成的，删除或屏蔽当前的驱动版本，并将驱动升级为以下版本： 12345678910&lt;dependency&gt; &lt;groupId&gt;com.oracle.ojdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc8&lt;/artifactId&gt; &lt;version&gt;19.3.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;cn.easyproject&lt;/groupId&gt; &lt;artifactId&gt;orai18n&lt;/artifactId&gt; &lt;version&gt;12.1.0.2.0&lt;/version&gt;&lt;/dependency&gt; 文档生成截图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 数据库"},{"title":"Golang 入门教程之一","url":"/posts/42f8c3d7.html","text":"","tags":"golang"},{"title":"C++ 进阶基础之八","url":"/posts/8b87f2be.html","text":"大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 stack 容器stack 容器的概念stack 是一种先进后出（First In Last Out，FILO）的数据结构，它只有一个出口。stack 容器允许新增元素、移除元素、取得栈顶元素，但是除了最顶端的元素外，没有任何其他方法可以存取 stack 中的其他元素。stack 没有迭代器，容器中所有元素的进出都必须符合 “先进后出” 的规则，只有 stack 最顶端的元素，才有机会被外界取用。换言之，stack 不提供遍历功能，也不提供迭代器。deque 是双向开口的数据结构，若以 deque 为底部结构并封闭其头端开口，便轻而易举地形成一个 stack。因此，SGI STL 便以 deque 作为缺省情况下的 stack 底部结构。由于 stack 以底部容器完成其所有工作，而具有这种 “修改某物接口，形成另一种风貌” 的性质者，称为 adapter（配接器），因此，STL stack 往往不被归类为 container（容器），而被归类为 container adapter（容器配接器）。 stack 容器的使用12345678910111213141516171819202122232425262728293031323334#include&lt;iostream&gt;#include&lt;stack&gt;using namespace std;void printStack(stack&lt;int&gt; &amp;s) { // 判断容器是否为空 while (!s.empty()) { // 获取栈顶元素 cout &lt;&lt; s.top() &lt;&lt; \" \"; // 弹出栈顶元素（弹栈） s.pop(); } cout &lt;&lt; endl;}int main() { // 默认构造函数 stack&lt;int&gt; s1; // 向栈顶添加元素（压栈） s1.push(5); s1.push(12); s1.push(24); s1.push(35); s1.push(46); printStack(s1); // 拷贝构造函数 stack&lt;int&gt; s2 = s1; return 0;} 程序运行输出的结果如下： 146 35 24 12 5 queue 容器queue 容器的概念queue 是一种先进先出（First In First Out，FIFO）的数据结构，它有两个出口。queue 容器允许从一端新增元素，从另一端移除元素。queue 所有元素的进出都必须符合 ” 先进先出” 的规则，只有 queue 的顶端元素，才有机会被外界取用。queue 不提供遍历功能，也不提供迭代器。由于 queue 以底部容器完成其所有工作，因此，STL queue 往往也不被归类为 container（容器），而被归类为 container adapter（容器配接器）。 queue 容器的使用1234567891011121314151617181920212223242526272829303132333435363738394041424344#include&lt;iostream&gt;#include&lt;queue&gt;using namespace std;void printQueue(queue&lt;int&gt; &amp;q) { // 判断队列是否为空 while (!q.empty()) { cout &lt;&lt; \"大小: \" &lt;&lt; q.size() &lt;&lt; endl; cout &lt;&lt; \"队头: \" &lt;&lt; q.front() &lt;&lt; endl; cout &lt;&lt; \"队尾: \" &lt;&lt; q.back() &lt;&lt; endl; // 弹出（删除）队头元素 q.pop(); }}int main() { // 默认构造函数 queue&lt;int&gt; q1; // 往队尾添加元素 q1.push(1); q1.push(3); q1.push(5); q1.push(7); q1.push(9); // 返回队列的大小 cout &lt;&lt; \"size = \" &lt;&lt; q1.size() &lt;&lt; endl; // 返回第一个元素 cout &lt;&lt; \"first = \" &lt;&lt; q1.front() &lt;&lt; endl; // 返回最后一个元素 cout &lt;&lt; \"last = \" &lt;&lt; q1.back() &lt;&lt; endl; printQueue(q1); // 拷贝构造函数 queue&lt;int&gt; q2 = q1; return 0;} 程序运行输出的结果如下： 123456789101112131415161718size = 5first = 1last = 9大小: 5队头: 1队尾: 9大小: 4队头: 3队尾: 9大小: 3队头: 5队尾: 9大小: 2队头: 7队尾: 9大小: 1队头: 9队尾: 9 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 进阶基础之七","url":"/posts/9e89901e.html","text":"大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 vector 容器vector 容器的概念vector 的数据存储以及操作方式，与 Array 非常相似，两者的唯一差别在于空间运用的灵活性。Array 是静态空间，一旦配置了就不能改变，要换大一点或者小一点的空间，可以，一切琐碎的细节得由自己来实现；首先配置一块新的空间，然后将旧空间的数据搬往新空间，再释放原来的空间。Vector 是动态空间，随着元素的加入，它的内部机制会自动扩充空间以容纳新元素。因此 vector 的运用对于内存的合理利用与运用的灵活性有很大的帮助，我们再也不必害怕空间不足而一开始就初始化一个大的 Array 了。Vector 的实现技术，关键在于其对大小的控制以及重新配置时的数据移动效率，一旦 vector 旧空间满了，如果客户每新增一个元素 vector 内部只是扩充一个元素的空间，实为不智，因为所谓的扩充空间（不论多大），一如刚所说，是 “配置新空间 - 数据移动 - 释放旧空间” 的大工程，时间成本很高，应该加入某种未雨绸缪的考虑。 vector 容器的数据结构 vector 所采用的数据结构是线性连续空间（单向开口的连续内存空间），它以两个迭代器（_Myfirst 和 _Mylast）分别指向配置得来的连续空间中目前已被使用的范围，并以迭代器 _Myend 指向整块连续内存空间的尾端。vector 往尾部添加或移除元素的效率非常高，但是往头部或者中部插入元素或移除元素则比较费时。为了降低空间配置时的速度成本，vector 实际配置的大小可能比客户端需求大一些，以应付将来可能的扩充，这里是容量的概念。换句话说，一个 vector 的容量永远大于或等于其大小，一旦容量等于大小，便是满载，下次再需要新增元素时，整个 vector 容器就得另觅居所。值得一提的是，所谓动态增加大小，并不是在原空间之后续接新空间（因为无法保证原空间之后尚有可配置的空间），而是申请一块更大的内存空间，然后将原数据拷贝到新空间，并释放原空间。因此，对 vector 的任何操作，一旦引起空间的重新配置，指向原 vector 的所有迭代器就都失效了，这是程序容易出错的地方，务必小心。 vector 容器的迭代器vector 维护了一个线性空间，所以不论元素的类型是什么，普通指针都可以作为 vector 的迭代器，因为 vector 迭代器所需要的操作行为，如 operaroe*, operator-&gt;, operator++, operator--, operator+, operator-, operator+=, operator-= 都是普通指针天生具备的。vector 支持随机存取，而普通指针正有着这样的能力，所以 vector 提供的是随机访问迭代器（Random Access Iterators），支持随机存取元素。根据前面的描述，可以写如下的代码： 123456789101112131415161718192021222324#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main() { // 声明容器 vector&lt;int&gt; v1; // 插入容器数据 for (int i = 0; i &lt; 10; i++) { v1.push_back(i); cout &lt;&lt; i &lt;&lt; \" \"; } cout &lt;&lt; endl; // vector 的迭代器是随机访问迭代器，支持跳跃式访问（随机存取元素） vector&lt;int&gt;::iterator itBegin = v1.begin(); itBegin = itBegin + 2; cout &lt;&lt; *itBegin &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 120 1 2 3 4 5 6 7 8 9 2 vector 容器的使用vector 的构造与赋值1234vector&lt;T&gt; v; // 默认构造函数，采用模板实现类实现vector(v.begin(), v.end()); // 有参构造函数，将 v[begin(), end()] 区间中的元素拷贝给本身vector(n, elem); // 有参构造函数，将 n 个 elem 元素拷贝给本身vector(const vector &amp;vec); // 拷贝构造函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;iostream&gt;#include&lt;vector&gt;using namespace std;void printVector(vector&lt;int&gt; &amp;v) { // 遍历容器 for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; } cout &lt;&lt; endl;}int main() { int arr[] = {1, 2, 3, 4, 5}; cout &lt;&lt; \"------ vector 构造函数 ------\" &lt;&lt; endl; // 默认构造函数 vector&lt;int&gt; v1; // 有参构造函数，将 v[begin(), end()] 区间中的元素拷贝给本身 vector&lt;int&gt; v2(arr, arr + sizeof(arr) / sizeof(int)); printVector(v2); // 有参构造函数，将 v[begin(), end()] 区间中的元素拷贝给本身 vector&lt;int&gt; v3(v2.begin(), v2.end()); printVector(v3); // 有参构造函数，将 n 个 elem 元素拷贝给本身 vector&lt;int&gt; v4(5, 10); printVector(v4); // 拷贝构造函数 vector&lt;int&gt; v5 = v4; printVector(v5); cout &lt;&lt; \"------ vector 赋值操作 ------\" &lt;&lt; endl; // 赋值操作，将 v[begin(), end()] 区间中的元素拷贝给本身 vector&lt;int&gt; v6; v6.assign(v5.begin(), v5.end()); printVector(v6); // 赋值操作，将 n 个 elem 元素拷贝给本身 vector&lt;int&gt; v7; v7.assign(5, 8); printVector(v7); // 赋值操作，重载等号操作符 vector&lt;int&gt; v8; v8 = v6; printVector(v8); // 赋值操作，将其他容器与本身的元素互换，利用 swap() 可以收缩空间 v8.swap(v7); printVector(v8); return 0;} 程序运行输出的结果如下： 12345678910------ vector 构造函数 ------1 2 3 4 5 1 2 3 4 5 10 10 10 10 10 10 10 10 10 10 ------ vector 赋值操作 ------10 10 10 10 10 8 8 8 8 8 10 10 10 10 10 8 8 8 8 8 vector 的常用操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void printVector(vector&lt;int&gt; &amp;v) { // 遍历vector for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; } cout &lt;&lt; endl;}int main() { vector&lt;int&gt; v1; v1.assign(5, 10); cout &lt;&lt; \"------ vector 大小、容量操作 ------\" &lt;&lt; endl; // 获取容器中元素的个数 size_t size = v1.size(); cout &lt;&lt; \"size = \" &lt;&lt; size &lt;&lt; endl; // 判断容器是否为空 bool empty = v1.empty(); cout &lt;&lt; (empty == 0 ? \"true\" : \"false\") &lt;&lt; endl; // 重新指定容器的大小为 num，若容器变大，则以默认值（0）填充新位置。如果容器变小，则末尾超出容器大小的元素会被删除 v1.resize(7); printVector(v1); // 重新指定容器的大小为 num，若容器变大，则以指定值填充新位置。如果容器变小，则末尾超出容器大小的元素会被删除 v1.resize(10, 8); printVector(v1); // 获取容器的容量 size_t capacity = v1.capacity(); cout &lt;&lt; \"capacity = \" &lt;&lt; capacity &lt;&lt; endl; cout &lt;&lt; \"------ vector 数据读取操作 ------\" &lt;&lt; endl; vector&lt;int&gt; v2; v2.push_back(3); v2.push_back(6); v2.push_back(9); v2.push_back(12); v2.push_back(15); // 返回索引所指向的数据，如果索引越界，抛出 out_of_range 异常 int num1 = v2.at(1); cout &lt;&lt; \"num1 = \" &lt;&lt; num1 &lt;&lt; endl; // 返回索引所指向的数据，如果索引越界，程序终止运行 int num2 = v2[3]; cout &lt;&lt; \"num2 = \" &lt;&lt; num2 &lt;&lt; endl; // 返回容器中第一个数据元素 int font = v2.front(); cout &lt;&lt; \"font = \" &lt;&lt; font &lt;&lt; endl; // 返回容器中最后一个数据元素 int back = v2.back(); cout &lt;&lt; \"back = \" &lt;&lt; back &lt;&lt; endl; cout &lt;&lt; \"------ vector 插入和删除操作 ------\" &lt;&lt; endl; // 往迭代器指向的位置插入 n 个指定的元素，其中元素个数可以省略 vector&lt;int&gt; v3(5, 8); v3.insert(v3.begin(), 2, 10); printVector(v3); // 往容器的尾部插入元素 v3.push_back(11); printVector(v3); // 删除最后一个元素 v3.pop_back(); printVector(v3); // 删除迭代器指向的元素，迭代器就是指针 v3.erase(v3.begin()); printVector(v3); // 删除迭代器从 start 到 end 之间的元素 v3.erase(v3.begin(), v3.end()); if (v3.empty()) { cout &lt;&lt; \"vector is empty\" &lt;&lt; endl; } // 删除容器中的所有元素 v3.clear(); return 0;} 程序运行输出的结果如下： 1234567891011121314151617------ vector 大小、容量操作 ------size = 5true10 10 10 10 10 0 0 10 10 10 10 10 0 0 8 8 8 capacity = 10------ vector 数据存取操作 ------num1 = 6num2 = 12font = 3back = 15------ vector 插入和删除操作 ------10 10 8 8 8 8 8 10 10 8 8 8 8 8 11 10 10 8 8 8 8 8 10 8 8 8 8 8 vector is empty vector 逆序遍历容器迭代器的类型： iterator：普通迭代器 const_iterator：只读迭代器 reverse_iterator：逆序迭代器 1234567891011121314151617181920212223242526272829303132#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main() { vector&lt;int&gt; v1; for (int i = 0; i &lt; 10; i++) { v1.push_back(i); } // 顺序遍历容器 for (vector&lt;int&gt;::iterator it = v1.begin(); it != v1.end(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; } cout &lt;&lt; endl; // 逆序遍历容器（使用逆序迭代器） for (vector&lt;int&gt;::reverse_iterator it = v1.rbegin(); it != v1.rend(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; } cout &lt;&lt; endl; // vector 的迭代器是随机访问迭代器，支持跳跃式访问 vector&lt;int&gt;::iterator itBegin = v1.begin(); itBegin = itBegin + 2; cout &lt;&lt; *itBegin &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1230 1 2 3 4 5 6 7 8 9 9 8 7 6 5 4 3 2 1 0 2 vector 收缩空间结合 C++ 的匿名对象和 vector 容器的 swap() 函数，可以实现收缩 vector 容器的空间。 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main() { vector&lt;int&gt; v1; // 插入容器数据 for (int i = 0; i &lt; 100000; i++) { v1.push_back(i); } cout &lt;&lt; \"size = \" &lt;&lt; v1.size() &lt;&lt; endl; cout &lt;&lt; \"capacity = \" &lt;&lt; v1.capacity() &lt;&lt; endl; // 重新指定容器的大小，此时容器的容量不会改变 v1.resize(5); cout &lt;&lt; \"size = \" &lt;&lt; v1.size() &lt;&lt; endl; cout &lt;&lt; \"capacity = \" &lt;&lt; v1.capacity() &lt;&lt; endl; // 巧用匿名对象和 swap() 函数收缩 vector 容器的空间 vector&lt;int&gt;(v1).swap(v1); cout &lt;&lt; \"size = \" &lt;&lt; v1.size() &lt;&lt; endl; cout &lt;&lt; \"capacity = \" &lt;&lt; v1.capacity() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123456size = 100000capacity = 131072size = 5capacity = 131072size = 5capacity = 5 vector 预留空间reserve() 函数可以让 vector 容器预留指定的空间，尤其在大数据量插入的情况下，这可以减少 vector 容器频繁扩充容量带来的额外性能开销，从而提升程序的运行效率。 123456789101112131415161718192021222324252627282930313233343536#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void initData(vector&lt;int&gt; &amp;v, size_t size, bool reserve) { // 预留空间 if (reserve) { v.reserve(size); } int count = 0; int *pStart = NULL; for (int i = 0; i &lt; size; i++) { // 插入容器数据 v.push_back(i); // 统计容器改变容量的次数 if (pStart != &amp;v[0]) { pStart = &amp;v[0]; count++; } } cout &lt;&lt; \"count : \" &lt;&lt; count &lt;&lt; endl;}int main() { // 不申请预览空间 vector&lt;int&gt; v1; initData(v1, 100000, false); // 申请预览空间 vector&lt;int&gt; v2; initData(v2, 100000, true); return 0;} 程序运行输出的结果如下： 12count : 18count : 1 deque 容器deque 容器的概念vector 是单向开口的连续线性空间，而 deque 则是一种双向开口的连续线性空间。所谓双向开口，意思是可以在头尾两端分别进行元素的插入和移除操作。虽然 vector 也可以在头尾两端进行操作，但是其头部操作的效率非常低，无法被接受。deque 和 vector 的最大差异，一在于 deque 允许于常数项时间内对头端进行元素的插入或移除操作，二在于 deque 没有所谓容量 capacity 的观念，因为它是动态地以分段连续空间组合而成，随时可以增加一段新的空间并链接起来。换句话说，像 vector 那样因旧空间不足而重新配置一块更大的空间，然后拷贝元素，再释放旧空间这样的事情不会发生在 deque 身上，也因此 deque 没有必要提供所谓的空间保留（reserve）功能。虽然 deque 也提供了随机迭代器（Random Access Iterator），但是它的迭代器并不是普通的指针，其复杂度和 vector 不是一个量级，这会影响各个层面的运算效率。因此，除非有必要，应该尽可能的使用 vector，而不是 deque。对 deque 进行的排序操作，为了提高效率，可将 deque 先完整的复制到一个 vector 中，然后对 vector 容器进行排序，再复制回 deque。 deque 容器的实现原理deque 本质由一段一段的定量连续空间（分段连续内存空间）构造而成，一旦有必要在 deque 的头端或尾端增加新空间，便会配置一段新的定量连续空间，然后串接在整个 deque 的头端或尾端。deque 最大的工作就是维护这些分段连续的内存空间的整体性的假象，并提供随机存取的接口；这避开了重新配置空间、复制数据、释放空间的轮回，代价就是复杂的迭代器架构。既然 deque 使用的是分段连续内存空间，那么就必须有中央控制器，维持其整体连续的假象，这样也导致了数据结构的设计及迭代器的前进后退操作颇为繁琐，deque 底层实现的代码远比 vector 或 list 都多得多。 deque 内部的中控器维护的是每个缓冲区的地址，而缓冲区则存放着真实的数据，目的是让 deque 使用起来像是一片连续的内存空间。deque 采取一块所谓的 map（注意，不是 STL 的 map 容器）作为主控，这里所谓的 map 是一小块连续的内存空间，其中每一个元素（节点）都是一个指针，指向另一段连续性内存空间，称作缓冲区，缓冲区才是 deque 的存储空间的主体。 deque 与 vector 的区别 vector 对于头部的插入效率极低，数据量越大，效率越低 deque 相对而言，对头部的元素插入、删除速度会比 vector 快 vector 访问元素时的速度会比 deque 快，这和两者的内部实现有关 deque 容器的使用deque 的构造和赋值123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;deque&gt;using namespace std;void printDeque(const deque&lt;int&gt; &amp;d) { // 遍历容器 for (deque&lt;int&gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; } cout &lt;&lt; endl;}int main() { cout &lt;&lt; \"------ deque 构造函数 ------\" &lt;&lt; endl; // 默认构造函数 deque&lt;int&gt; d1; // 有参构造函数，将 n 个 elem 元素拷贝给本身 deque&lt;int&gt; d2(5, 10); printDeque(d2); // 有参构造函数，将 d[begin(), end()] 区间中的元素拷贝给本身 deque&lt;int&gt; d3(d2.begin(), d2.end()); printDeque(d3); // 拷贝构造函 deque&lt;int&gt; d4 = d3; printDeque(d4); cout &lt;&lt; \"------ deque 赋值操作 ------\" &lt;&lt; endl; // 赋值操作，重载等号操作符 deque&lt;int&gt; d5; d5 = d4; printDeque(d5); // 赋值操作，将 d[begin(), end()] 区间中的元素拷贝给本身 deque&lt;int&gt; d6; d6.assign(d5.begin(), d5.end()); printDeque(d6); // 赋值操作，将 n 个 elem 元素拷贝给本身 deque&lt;int&gt; d7; d7.assign(5, 8); printDeque(d7); // 赋值操作，将其他容器与本身的元素互换 d7.swap(d6); printDeque(d7); return 0;} 程序运行输出的结果如下： 123456789------ deque 构造函数 ------10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 ------ deque 赋值操作 ------10 10 10 10 10 10 10 10 10 10 8 8 8 8 8 10 10 10 10 10 deque 的常用操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include &lt;iostream&gt;#include &lt;deque&gt;using namespace std;void printDeque(const deque&lt;int&gt; &amp;d) { // 遍历容器 for (deque&lt;int&gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; } cout &lt;&lt; endl;}int main() { cout &lt;&lt; \"------ deque 大小操作 ------\" &lt;&lt; endl; deque&lt;int&gt; d1; d1.assign(5, 10); printDeque(d1); // 判断容器是否为空 bool empty = d1.empty(); cout &lt;&lt; (empty ? \"yes\" : \"no\") &lt;&lt; endl; // 获取容器中元素的个数 size_t size = d1.size(); cout &lt;&lt; size &lt;&lt; endl; // 重新指定容器的大小为 num，若容器变大，则以默认值（0）填充新位置。如果容器变小，则末尾超出容器大小的元素会被删除 d1.resize(7); printDeque(d1); // 重新指定容器的大小为 num，若容器变大，则以指定值填充新位置。如果容器变小，则末尾超出容器大小的元素会被删除 d1.resize(10, 8); printDeque(d1); cout &lt;&lt; \"------ deque 读取操作 ------\" &lt;&lt; endl; deque&lt;int&gt; d2; d2.push_back(1); d2.push_back(2); d2.push_back(3); d2.push_back(4); d2.push_back(5); // 返回索引所指向的数据，如果索引越界，抛出 out_of_range 异常 int num1 = d2.at(2); cout &lt;&lt; \"num1 = \" &lt;&lt; num1 &lt;&lt; endl; // 返回索引所指向的数据，如果索引越界，程序终止运行 int num2 = d2[3]; cout &lt;&lt; \"num2 = \" &lt;&lt; num2 &lt;&lt; endl; // 返回容器中第一个数据元素 int font = d2.front(); cout &lt;&lt; \"font = \" &lt;&lt; font &lt;&lt; endl; // 返回容器中最后一个数据元素 int back = d2.back(); cout &lt;&lt; \"back = \" &lt;&lt; back &lt;&lt; endl; cout &lt;&lt; \"------ deque 插入操作 ------\" &lt;&lt; endl; deque&lt;int&gt; d3(3, 8); printDeque(d3); // 往迭代器指向的位置插入指定的元素 d3.insert(d3.begin(), 10); printDeque(d3); // 往迭代器指向的位置插入 n 个指定的元素 d3.insert(d3.begin(), 2, 11); printDeque(d3); // 往迭代器指向的位置插入 [begin, end) 区间的数据 deque&lt;int&gt; d4(2, 12); d3.insert(d3.begin(), d4.begin(), d4.end()); printDeque(d3); // 在容器头部插入一个数据 d4.push_front(13); printDeque(d4); // 在容器尾部添加一个数据 d4.push_back(11); printDeque(d4); cout &lt;&lt; \"------ deque 删除操作 ------\" &lt;&lt; endl; deque&lt;int&gt; d5; d5.push_back(1); d5.push_back(2); d5.push_back(3); d5.push_back(4); d5.push_back(5); d5.push_back(6); // 删除指定位置的数据，会返回下一个数据的位置 d5.erase(d5.begin()); printDeque(d5); // 删除容器第一个数据 d5.pop_front(); printDeque(d5); // 删除容器最后一个数据 d5.pop_back(); printDeque(d5); // 清空容器的所有数据 d5.clear(); return 0;} 程序运行输出的结果如下： 12345678910111213141516171819202122------ deque 大小操作 ------10 10 10 10 10 no510 10 10 10 10 0 0 10 10 10 10 10 0 0 8 8 8 ------ deque 读取操作 ------num1 = 3num2 = 4font = 1back = 5------ deque 插入操作 ------8 8 8 10 8 8 8 11 11 10 8 8 8 12 12 11 11 10 8 8 8 13 12 12 13 12 12 11 ------ deque 删除操作 ------2 3 4 5 6 3 4 5 6 3 4 5 deque 的排序操作利用算法可以对 deque 容器进行排序，但需要引入头文件 algorithm。对于支持随机访问的迭代器的容器，都可以利用 sort() 排序，vector 容器也可以用 sort() 排序。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;iostream&gt;#include &lt;deque&gt;#include &lt;algorithm&gt;using namespace std;void printDeque(const deque&lt;int&gt; &amp;d) { // 遍历容器 for (deque&lt;int&gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; } cout &lt;&lt; endl;}bool descCompare(const int a, const int b) { return a &gt; b;}void asc() { deque&lt;int&gt; d1; d1.push_back(3); d1.push_back(11); d1.push_back(8); d1.push_back(6); d1.push_back(21); cout &lt;&lt; \"升序排序前：\" &lt;&lt; endl; printDeque(d1); // 升序排序，默认从小到大排序 sort(d1.begin(), d1.end()); cout &lt;&lt; \"升序排序后：\" &lt;&lt; endl; printDeque(d1);}void desc() { deque&lt;int&gt; d1; d1.push_back(3); d1.push_back(11); d1.push_back(8); d1.push_back(6); d1.push_back(21); cout &lt;&lt; \"降序排序前：\" &lt;&lt; endl; printDeque(d1); // 降序排序，默认从大到小排序 sort(d1.begin(), d1.end(), descCompare); cout &lt;&lt; \"降序排序后：\" &lt;&lt; endl; printDeque(d1);}int main() { asc(); // 升序排序 cout &lt;&lt; endl; desc(); // 降序排序后 return 0;} 程序运行输出的结果如下： 123456789升序排序前：3 11 8 6 21 升序排序后：3 6 8 11 21 降序排序前：3 11 8 6 21 降序排序后：21 11 8 6 3 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"JavaScript 常用代码块","url":"/posts/b69c820e.html","text":"一、日期处理1. 时间格式化该方法可以用于将时间转化为 hour:minutes:seconds 的格式： 12345const timeFromDate = date =&gt; date.toTimeString().slice(0, 8);timeFromDate(new Date(2021, 11, 2, 12, 30, 0)); // 12:30:00timeFromDate(new Date()); // 返回当前时间 09:00:00复制代码 2. 检察日期是否有效该方法用于检测给出的日期是否有效： 1234const isDateValid = (...val) =&gt; !Number.isNaN(new Date(...val).valueOf());isDateValid(\"December 17, 1995 03:24:00\"); // true复制代码 3. 计算两个日期之间的间隔该方法用于计算两个日期之间的间隔时间： 1234const dayDif = (date1, date2) =&gt; Math.ceil(Math.abs(date1.getTime() - date2.getTime()) / 86400000)dayDif(new Date(\"2021-11-3\"), new Date(\"2022-2-1\")) // 90复制代码 距离过年还有 90 天～ 4. 查找日期位于一年中的第几天该方法用于检测给出的日期位于今年的第几天： 1234const dayOfYear = (date) =&gt; Math.floor((date - new Date(date.getFullYear(), 0, 0)) / 1000 / 60 / 60 / 24);dayOfYear(new Date()); // 307复制代码 2021 年已经过去 300 多天了～ 二、字符串处理1. 字符串首字母大写该方法用于将英文字符串的首字母大写处理： 1234const capitalize = str =&gt; str.charAt(0).toUpperCase() + str.slice(1)capitalize(\"hello world\") // Hello world复制代码 2. 翻转字符串该方法用于将一个字符串进行翻转操作，返回翻转后的字符串： 1234const reverse = str =&gt; str.split('').reverse().join('');reverse('hello world'); // 'dlrow olleh'复制代码 3. 随机字符串该方法用于生成一个随机的字符串： 1234const randomString = () =&gt; Math.random().toString(36).slice(2);randomString();复制代码 4. 截断字符串该方法可以从指定长度处截断字符串: 1234const truncateString = (string, length) =&gt; string.length &lt; length ? string : `${string.slice(0, length - 3)}...`;truncateString('Hi, I should be truncated because I am too loooong!', 36) // 'Hi, I should be truncated because...'复制代码 5. 去除字符串中的 HTML该方法用于去除字符串中的 HTML 元素： 12const stripHtml = html =&gt; (new DOMParser().parseFromString(html, 'text/html')).body.textContent || '';复制代码 三、数组处理1. 从数组中移除重复项该方法用于移除数组中的重复项： 1234const removeDuplicates = (arr) =&gt; [...new Set(arr)];console.log(removeDuplicates([1, 2, 2, 3, 3, 4, 4, 5, 5, 6]));复制代码 2. 判断数组是否为空该方法用于判断一个数组是否为空数组，它将返回一个布尔值： 1234const isNotEmpty = arr =&gt; Array.isArray(arr) &amp;&amp; arr.length &gt; 0;isNotEmpty([1, 2, 3]); // true复制代码 3. 合并两个数组可以使用下面两个方法来合并两个数组： 1234const merge = (a, b) =&gt; a.concat(b);const merge = (a, b) =&gt; [...a, ...b];复制代码 四、数字操作1. 判断一个数是奇数还是偶数该方法用于判断一个数字是奇数还是偶数： 1234const isEven = num =&gt; num % 2 === 0;isEven(996);复制代码 2. 获得一组数的平均值1234const average = (...args) =&gt; args.reduce((a, b) =&gt; a + b) / args.length;average(1, 2, 3, 4, 5); // 3复制代码 3. 获取两个整数之间的随机整数该方法用于获取两个整数之间的随机整数 1234const random = (min, max) =&gt; Math.floor(Math.random() * (max - min + 1) + min);random(1, 50);复制代码 4. 指定位数四舍五入该方法用于将一个数字按照指定位进行四舍五入： 12345const round = (n, d) =&gt; Number(Math.round(n + \"e\" + d) + \"e-\" + d)round(1.005, 2) //1.01round(1.555, 2) //1.56复制代码 五、颜色操作1. 将 RGB 转化为十六机制该方法可以将一个 RGB 的颜色值转化为 16 进制值： 1234const rgbToHex = (r, g, b) =&gt; \"#\" + ((1 &lt;&lt; 24) + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).slice(1);rgbToHex(255, 255, 255); // '#ffffff'复制代码 2. 获取随机十六进制颜色该方法用于获取一个随机的十六进制颜色值： 1234const randomHex = () =&gt; `#${Math.floor(Math.random() * 0xffffff).toString(16).padEnd(6, \"0\")}`;randomHex();复制代码 六、浏览器操作1. 复制内容到剪切板该方法使用 navigator.clipboard.writeText 来实现将文本复制到剪贴板： 1234const copyToClipboard = (text) =&gt; navigator.clipboard.writeText(text);copyToClipboard(\"Hello World\");复制代码 2. 清除所有 cookie该方法可以通过使用 document.cookie 来访问 cookie 并清除存储在网页中的所有 cookie： 12const clearCookies = document.cookie.split(';').forEach(cookie =&gt; document.cookie = cookie.replace(/^ +/, '').replace(/=.*/, `=;expires=${new Date(0).toUTCString()};path=/`));复制代码 3. 获取选中的文本该方法通过内置的 getSelection 属性获取用户选择的文本： 1234const getSelectedText = () =&gt; window.getSelection().toString();getSelectedText();复制代码 4. 检测是否是黑暗模式该方法用于检测当前的环境是否是黑暗模式，它是一个布尔值： 1234const isDarkMode = window.matchMedia &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matchesconsole.log(isDarkMode)复制代码 5. 滚动到页面顶部该方法用于在页面中返回顶部： 1234const goToTop = () =&gt; window.scrollTo(0, 0);goToTop();复制代码 6. 判断当前标签页是否激活该方法用于检测当前标签页是否已经激活： 12const isTabInView = () =&gt; !document.hidden;复制代码 7. 判断当前是否是苹果设备该方法用于检测当前的设备是否是苹果的设备： 1234const isAppleDevice = () =&gt; /Mac|iPod|iPhone|iPad/.test(navigator.platform);isAppleDevice();复制代码 8. 是否滚动到页面底部该方法用于判断页面是否已经底部： 12const scrolledToBottom = () =&gt; document.documentElement.clientHeight + window.scrollY &gt;= document.documentElement.scrollHeight;复制代码 9. 重定向到一个 URL该方法用于重定向到一个新的 URL： 1234const redirect = url =&gt; location.href = urlredirect(\"https://www.google.com/\")复制代码 10. 打开浏览器打印框该方法用于打开浏览器的打印框： 12const showPrintDialog = () =&gt; window.print()复制代码 七、其他操作1. 随机布尔值该方法可以返回一个随机的布尔值，使用 Math.random () 可以获得 0-1 的随机数，与 0.5 进行比较，就有一半的概率获得真值或者假值。 1234const randomBoolean = () =&gt; Math.random() &gt;= 0.5;randomBoolean();复制代码 2. 变量交换可以使用以下形式在不适用第三个变量的情况下，交换两个变量的值： 12[foo, bar] = [bar, foo];复制代码 3. 获取变量的类型该方法用于获取一个变量的类型： 1234567891011const trueTypeOf = (obj) =&gt; Object.prototype.toString.call(obj).slice(8, -1).toLowerCase();trueTypeOf(''); // stringtrueTypeOf(0); // numbertrueTypeOf(); // undefinedtrueTypeOf(null); // nulltrueTypeOf({}); // objecttrueTypeOf([]); // arraytrueTypeOf(0); // numbertrueTypeOf(() =&gt; {}); // function复制代码 4. 华氏度和摄氏度之间的转化该方法用于摄氏度和华氏度之间的转化： 123456789const celsiusToFahrenheit = (celsius) =&gt; celsius * 9/5 + 32;const fahrenheitToCelsius = (fahrenheit) =&gt; (fahrenheit - 32) * 5/9;celsiusToFahrenheit(15); // 59celsiusToFahrenheit(0); // 32celsiusToFahrenheit(-20); // -4fahrenheitToCelsius(59); // 15fahrenheitToCelsius(32); // 0复制代码 5. 检测对象是否为空该方法用于检测一个 JavaScript 对象是否为空： 12const isEmpty = obj =&gt; Reflect.ownKeys(obj).length === 0 &amp;&amp; obj.constructor === Object;复制代码 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"VuePress 整合百度统计","url":"/posts/b23e0b9c.html","text":"前言本文主要介绍 VuePress 如何整合百度统计，适用于 VuePress 1.x 和 VuePress 2.x 版本。 VuePress v1.x安装插件1$ npm install -D vuepress-plugin-baidu-seo 配置插件12345678module.exports = { plugins: [ ['vuepress-plugin-baidu-seo', { hm: 'xxxxxxxx', ignoreLocal: true }] ]} 配置参数 参数 类型 必填 默认值 描述 hm String 是 已申请的百度统计 Key ignoreLocal Boolean 否 false 忽略本地的访问记录，例如 127.0.0.1 或者 localhost VuePress v2.x安装插件兼容性说明 以 SEO 插件版本号 2.0.0-beta.61.x 举例，其中的 2.0.0-beta.61 代表该 SEO 插件所兼容的 VuePress 2 版本，而 x 则代表 SEO 插件自身的修订版本号。若 VuePress 2 与 SEO 插件的版本不兼容，很可能会导致编译出错或者 SEO 插件无法生效。 查看插件的所有版本 12# 查看版本信息$ npm view vuepress-plugin-baidu-seo-next versions 安装插件到本地博客 12345# 安装最新版本$ npm install -D vuepress-plugin-baidu-seo-next# # 安装指定版本（推荐）$ npm install -D vuepress-plugin-baidu-seo-next@2.0.0-beta.61.1 配置插件12345678910import { baiduSeoPlugin } from 'vuepress-plugin-baidu-seo-next'module.exports = { plugins: [ baiduSeoPlugin({ hm: 'xxxxxxxx', ignoreLocal: true }) ]} 配置参数 参数 类型 必填 默认值 描述 hm String 是 已申请的百度统计 Key ignoreLocal Boolean 否 false 忽略本地的访问记录，例如 127.0.0.1 或者 localhost var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"VsCode 编程开发插件汇总","url":"/posts/7d927a64.html","text":"基础开发 Path Intellisense - 提供文件路径自动补全功能 Docker - 提供与 Docker 相关的功能，使得在容器中开发和调试应用程序变得更加容易 Chinese (Simplified) Language Pack for Visual Studio Code - 中文语言包 Code Runner - 提供一种便捷的方式来运行代码片段和脚本文件，支持多种编程语言和操作系统 GitLens - 对 Git 版本控制系统的全面支持，包括代码历史记录、代码比较、代码注释、代码作者等功能 Material Icon Theme - 提供一套漂亮的图标主题，可以为 VS Code 中的文件和文件夹添加彩色图标，使得文件结构更加清晰和易于理解 前端开发基础插件 Prettier - 自动格式化代码 EsLint - 语法检查和风格检查 HTML Snippets - HTML 代码快速自动补全 Auto Close Tag - 自动闭合 HTML/XML 标签 Auto Rename Tag - 自动完成另一侧标签的同步修改 HTML CSS Support - 在 HTML 标签上写 class 时，智能提示当前项目所支持的样式 Open in browser - 浏览器快速打开 Live Server - 以内嵌服务器方式实时预览和调试网页应用程序 Thunder Client - 轻量级 Rest API 客户端，可替代 PostMan REST Client - 提供一种便捷方式来测试和调试 RESTful API 接口，支持 HTTP 和 HTTPS 协议 JavaScript Debugger - 用于在 VS Code 中调试 JavaScript 代码，支持多种调试方式，如单步调试、断点调试、条件断点调试等 JavaScript (ES6) code snippets - ES6 语法智能提示以及快速输入，除 JS 外还支持 .ts、.jsx、.tsx、.html、.vue Vue 插件 Vue 3 Snippets - Vue2、Vue3 代码片段快速生成 Vetur - 对 Vue 项目的全面支持，包括语法高亮、智能提示、代码片段、错误检查、格式化等 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"个人在线支付接入方案介绍","url":"/posts/4d9ccdf3.html","text":"前言移动支付大势所趋，互联网购物或者线上服务都需要用到支付，那作为开发者和商家，必须要跟第三方支付公司签约合作，开通商户我们才有能调用支付功能，大家最熟悉的是微信和支付宝，你要在里面实现在线购物支付功能，需要有一个微信商户号或者支付宝商户号，然后将商户号接入到网页、公众号、app、小程序中。当消费者支付时，我们通过接口把支付信息传给微信或者支付宝的服务器进行支付，它们收到款会把结果回调到我们的服务器进行订单处理，然后服务器实时响应到客户端上提示完成交易。以上，就是整个商户支付的流程。首先，整个支付流程的本质是公司对个人的，也就是我们常说的 B2C 模式。其次，线上支付是需要签约的。每个商户都是对应一个公司，微信商户号和支付宝商户号的开通都需要以公司的名义开通，而开通的时候，需要签约盖章审核等等各种手续。至于微信和支付宝为什么不给个人开通支付通道呢？笔者也想过，其实这是国家政策要求的，你想想，如果个人支付开通后，国家怎么管控税收、怎么管理网络安全？所以，微信和支付宝这么做，其实是不想大家钻了偷税漏税的空子。 个人免签的三种支付模式 1、使用个人收款码，通过手机 App 软件监测收款（不合法） 2、代收款，然后手动提现（存在二清，不合法，会跑路） 3、代签约，走官方的渠道（合法，直接到账，不存在二清） 推荐第三种模式，前两种模式不合法，平台说不定哪天就会关闭。选择第三方支付平台时，应尽量考虑平台费率最低的、开户费最低的、开户操作最便捷的。 App 软件监测收款模式市面上有不少通过安装特定收款监听 App 实现收款回调功能的平台，比如玎玎支付、PaysApi、收小钱等；这些虽然是零资质，而且收费也不是特别高，但是有几个弊端： 收款金额上限额度小，上限金额为固定收款二维码每日的限额，额度较小 手机需要安装特定的收款监听 App，并且需要一直处于开机和网络良好状态，或者需要使用模拟器来运行 App 用户在扫描支付二维码后发现是跳转转账页面，而不是调起微信支付或支付宝支付，心中会有所怀疑，导致部分潜在付费用户流失，这是最致命的弊端 如果改动价格，需要上传多张收款二维码，操作繁琐，尽管有些平台通过安装 VirtualXposed，生成任意收款金额的二维码免去此操作，但是手机需要停留在微信或者支付宝界面、而且还要保持屏幕常亮状态 回调存在不稳定因素，由于收款回调是在安装了收款监听 App 的手机在接收到收款的通知栏通知后上报金额到该平台服务器，再通过该平台回调到设置好的回调地址，所以其中有些环节如果出问题，比如收款监听的手机断网了，或者该平台的服务器宕机，都会导致没有收到收款回调 个人第三方支付平台推荐由于没有公司账号，开发者在微信和支付宝是接入不了支付的，因此只能选第三方支付平台，payjs 官方做了很详细的 对比图表。 7-pay，仅支持支付宝 Payjs，仅支持微信支付 麻瓜宝数字货币支付，仅支持数字货币 参考博客 微信支付宝，个人支付收款接口现状剖析 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"在线支付"},{"title":"解决 GitHub DNS 被污染的问题","url":"/posts/b7c0261d.html","text":"第一步访问 IP 查询网站，查询以下域名对应的 IP： 1234github.comraw.githubusercontent.comcamo.githubusercontent.comgithub.global.ssl.fastly.net 第二步Linux 系统编辑系统配置文件 /etc/hosts，新增以下内容（请自行更改查询到的 IP）： 1234140.82.112.4 github.com185.199.108.133 raw.githubusercontent.com185.199.108.133 camo.githubusercontent.com199.232.69.194 github.global.ssl.fastly.net Windows 系统编辑系统配置文件 c:\\windows\\system32\\drivers\\etc\\hosts，新增以下内容（请自行更改查询到的 IP）： 1234140.82.112.4 github.com185.199.108.133 raw.githubusercontent.com185.199.108.133 camo.githubusercontent.com199.232.69.194 github.global.ssl.fastly.net 执行以下命令刷新 DNS 解析的缓存： 1&gt; ipconfig /flushdns var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发随笔"},{"title":"Nacos 架构与原理","url":"/posts/ab99a12c.html","text":"","tags":"在线电子书"},{"title":"Vuepress v1 博客导流微信公众号","url":"/posts/92228e7b.html","text":"前言Vuepress v1 博客建议安装 vuepress-plugin-readmore-popular 插件，将 TechGrow 的免费微信公众号导流工具整合到博客中，用户扫码关注微信公众号后可以解锁全站文章，让微信公众号的粉丝数躺着增长。 提示 TechGrow 开放平台的 官方文档 vuepress-plugin-readmore-popular 插件只支持 Vuepress v1，不支持 Vuepress v2 若使用的是 Vuepress v2 静态博客，建议直接安装 vuepress-plugin-readmore-popular-next 插件，详细教程可点击这里 特色功能 支持随机为博客添加导流功能 支持关闭某篇文章的导流功能 支持查询用户解锁文章的历史记录 支持自定义或者动态计算文章内容的预览高度 支持自定义 CSS 样式，轻松适配不同风格的博客 注册博客浏览器访问 TechGrow 的官网 ，注册并登录账号后，进入博客的后台管理页面。首先点击左侧的菜单 博客注册，然后点击 新增 按钮，添加自己博客的信息。博客注册成功后，记录下 博客 ID，后面的步骤会使用到 设置公众号在微信公众号的后台管理页面，菜单栏里选择 自动回复 - 关键词回复，启用 自动回复，然后点击 添加回复 按钮： 填写 规则名称、关键词（当初你在 TechGrow 中设置的）、回复内容 选择 文字，然后 回复文字 的内容填写获取博客解锁验证码的链接，如下所示（请自行更改 xxxxx-xxxxxxxxx-xxx 为你申请到的博客 ID） 1&lt;a href=\"https://open.techgrow.cn/#/readmore/captcha/generate?blogId=xxxxx-xxxxxxxxx-xxx\"&gt;点击链接，获取博客解锁验证码&lt;/a&gt; 此时，当读者关注你的微信公众号，并输入关键词后（比如我设置的关键词就是 tech），那么读者就会自动接收到获取博客解锁验证码的链接 安装插件 运行 npm install 命令安装插件到本地博客 1$ npm install -D vuepress-plugin-readmore-popular 配置 VuePress编辑 VuePress 的主配置文件（例如 .vuepress/config.js），新增插件的配置信息（请自行更改博客相关的信息），如下所示： 1234567891011121314151617181920212223242526272829303132module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { // 已申请的博客 ID blogId: '18762-1609305354821-257', // 已申请的微信公众号名称 name: '全栈技术驿站', // 已申请的微信公众号回复关键词 keyword: 'Tech', // 已申请的微信公众号二维码图片 qrcode: 'https://www.techgrow.cn/img/wx_mp_qr.png', // 文章内容的 JS 选择器，若使用的不是官方默认主题，则需要根据第三方的主题来设置 selector: 'div.theme-default-content', // 自定义的 JS 资源链接，可用于 CDN 加速 libUrl: 'https://qiniu.techgrow.cn/readmore/dist/readmore.js', // 自定义的 CSS 资源链接，可用于适配不同风格的博客 cssUrl: 'https://qiniu.techgrow.cn/readmore/dist/vuepress.css', // 文章排除添加引流工具的 URL 规则，支持使用路径、通配符、正则表达式的匹配规则 excludes: { strExp: [], regExp: [] }, // 是否反转 URL 排除规则的配置，即只有符合排除规则的文章才会添加引流工具 reverse: false, // 文章内容的预览高度 height: 'auto', // 文章解锁后凭证的有效天数 expires: 365, // 定时校验凭证有效性的时间间隔（秒） interval: 60, // 每篇文章随机添加引流工具的概率，有效范围在 0.1 ~ 1 之间，1 则表示所有文章默认都自动添加引流工具 random: 1 }] ]} 插件参数说明 参数 类型 必填 默认值 说明 blogId String 是 无 - name String 是 无 - keyword String 是 无 - qrcode String 是 无 - selector String 否 div.theme-default-content - libUrl String 否 https://qiniu.techgrow.cn/readmore/dist/readmore.js - cssUrl String 否 https://qiniu.techgrow.cn/readmore/dist/vuepress.css - excludes Json Object 否 { strExp: [ ], regExp: [ ] } - reverse Boolean 否 false - height String / Number 否 auto - expires Number 否 365 - interval Number 否 60 - random Number 否 1 - selector 参数的作用是指定 JS 选择器来获取文章的主体内容，若 VuePress 使用了第三方主题，则一般需要根据第三方主题来配置该参数，否则可能会导致引流工具无法生效。其中 VuePress 不同主题的配置示例如下： 主题 插件配置 备注 @vuepress/theme-vue selector: 'div.theme-default-content' 官方默认主题 vuepress-theme-reco selector: 'div.theme-reco-content' 第三方主题 vuepress-theme-hope selector: 'div.theme-hope-content' 第三方主题 vuepress-theme-vdoing selector: 'div.theme-vdoing-content' 第三方主题 提示 若不清楚如何指定 JS 选择器，则可以打开博客的任意一篇文章，利用 Chrome 等浏览器的元素审查功能，找到文章页面中文章主体的 div 标签，最后定位得到 div 标签的 CSS 类即可（例如 theme-default-content），点击查看详细的操作图解。 验证插件效果打开文章页面，若文章自动隐藏了部分内容，并且出现了 阅读全文 按钮，则说明导流插件正常运行，如下图所示： 点击 阅读全文 按钮，会弹出微信公众号的二维码窗口，如下图所示： 取消阅读限制若希望关闭部分文章的微信公众号导流功能，可以使用插件的 excludes 参数来实现。值得一提的是，excludes 的参数值是一个 JSON 对象，其中的 strExp 属性是路径和通配符规则的字符串数组，而 regExp 属性是正则表达式的字符串数组。 根据 URL 路径，关闭某篇文章的导流功能 12345678module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { // 排除 URL 为 `/fontend/webpack` 的文章 excludes: { strExp: ['/fontend/webpack'] }, }] ]} 根据 URL 通配符，关闭某个目录下的所有文章的导流功能 123456789module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { // 排除 URL 以 `/fontend` 开头的文章 // 排除 URL 为 `/backend/python/io` 的文章 excludes: { strExp: ['/fontend/*', '/backend/*/io'] }, }] ]} 根据 URL 正则表达式，关闭符合规则的所有文章的导流功能 12345678module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { // 排除 URL 不以 `/fontend` 开头的文章 excludes: { regExp: ['^(?!\\/fontend).*'] }, }] ]} 混合使用 1234567module.exports = { plugins: [ ['vuepress-plugin-readmore-popular', { excludes: { strExp: ['/webpack', '/fontend/*', '/backend/*/io'], regExp: ['^(?!\\/php).*'] }, }] ]} 提示 文章 URL 优先匹配 strExp 规则，然后再匹配 regExp 规则 文章 URL 一旦满足 strExp 规则，则不会再匹配 regExp 规则 如果希望符合 URL 排除规则的文章才添加导流工具，则可以使用 reverse : true 配置参数实现 自定义样式插件默认使用了定义在 vuepress.css 的 CSS 样式，你可以使用以下两种方式自定义自己的样式： 第一种方式：更改博客主题的 CSS 源码文件，将自定义的那部分 CSS 样式添加到里面 第二种方式：根据 vuepress.css 创建自己的 CSS 文件（完整的），并将其存放在自己的博客里，同时通过插件的 cssUrl 配置参数来指定其访问的 URL 路径 提示：为了方便日后维护，强烈建议使用第二种方式来添加自定义样式 常见问题问题一 VuePress 安装插件后，引流工具无法生效。 若引流工具无法生效，此时需要留意 VuePress 使用的是不是第三方主题。在使用第三方主题的情况下，一般需要根据第三方主题来配置插件的 selector 参数，该参数的作用是指定 JS 选择器来获取文章的主体内容，详细说明请看这里。 值得一提的是，若由于 selector 参数配置不正确导致引流工具无效，那么引流工具会在浏览器的控制台输出如下的警告信息： 问题二 VuePress 安装插件后，浏览器的控制台输出警告或者错误信息，且引流工具无法生效 浏览器访问 VuePress 博客后，按下 F12 快捷键调出调试工具，然后切换到 控制台，最后将警告或者错误信息截图，并发送到 官方微信群，建议留言备注 VuePress 与 VuePress 主题的版本号。 问题三 VuePress 安装插件后，移动端的引流工具无法生效，而 PC 端却生效 考虑到用户体验的问题，在移动端默认是关闭引流功能的，请知悉。 在线演示 官方 Demo 官方微信群","tags":"静态博客"},{"title":"VuePress 插件开发","url":"/posts/2f4cff19.html","text":"前言博主已开发的插件 vuepress-plugin-baidu-seo | VuePress v1 百度 SEO 插件 vuepress-plugin-baidu-seo-next | VuePress v2 百度 SEO 插件 vuepress-plugin-readmore-popular | VuePress v1 公众号引流插件 vuepress-plugin-readmore-popular-next | VuePress v2 公众号引流插件 VuePress 官方插件VuePress v1.x VuePress v1.x 官方中文文档 VuePress v1.x 官方插件的代码仓库 VuePress v2.x VuePress v2.x 官方中文文档 VuePress v2.x 官方插件的代码仓库 VuePress v1 插件开发Vue 组件引入内部 JS 文件第一步：在项目内定义 JS 文件，例如这里定义 loadResources.js 文件，同时通过 export 暴露 JS 函数： 123456789101112131415161718192021222324252627282930313233343536// 引入Qconst Q = require('q');/** * 异步加载js文件 * * @param url 导入js的url地址 * @param id script标签的id（必须唯一） * @returns {*} export此函数方便全局调用 */export function asyncLoadJs(url, id) { return Q.Promise((resovle, reject) =&gt; { let srcArr = document.getElementsByTagName('script'); let hasLoaded = false; for (let i = 0; i &lt; srcArr.length; i++) { hasLoaded = srcArr[i].id === id; if (hasLoaded) { document.getElementById(id).remove(); } } let script = document.createElement('script'); script.type = 'text/javascript'; script.src = url; script.id = id; document.body.appendChild(script); script.onload = () =&gt; { resovle(); }; script.onerror = () =&gt; { reject(); } })} 第二步：在项目里定义 Vue 组件，例如这里定义 example.vue，同时通过 import 引入上面定义的 JS 文件即可： 12345678910111213141516171819&lt;template&gt; &lt;div&gt;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;import { asyncLoadJs } from \"../js/loadResources.js\";export default { name: \"example\", data() { return {}; }, mounted() { asyncLoadJs(\"https://www.example/js/example.js\", \"example\"); },};&lt;/script&gt;&lt;style lang=\"scss\" scoped&gt;&lt;/style&gt; 参考资料 从零实现一个 VuePress 插件 VuePress 博客优化之拓展 Markdown 语法 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客 前端"},{"title":"VirtualBox 常见使用问题解决","url":"/posts/729d1230.html","text":"Win10 虚拟机无法识别 USB 设备根据 VirtualBox 的版本号，在 VirtualBox 官网 下载对应版本的一个叫 Oracle_VM_VirtualBox_Extension_Pack 的扩展，扩展包的版本号必须与 VirtualBox 的版本号一致 然后使用以下 Linux 命令将扩展包安装到 VirtualBox 中，这里需要提前将以前安装过的扩展包手动删除掉，否则会提示扩展包安装失败 1$ sudo VBoxManage extpack install Oracle_VM_VirtualBox_Extension_Pack-6.1.38-153438.vbox-extpack 安装完后可以在 VirtualBox 的全局设定界面看到对应的扩展包 打开 VirtualBox 的 Win10 虚拟机设置界面，开启 USB 3.0 Controller 最后插入 USB 设备，等宿主机挂载 USB 设备后启动 Win10 虚拟机，接着在虚拟机菜单栏中的 Devices -&gt; USB 中勾选对应的 USB 设备，即可让 Win10 虚拟机识别到 USB 设备了 参考博客 VirtualBox 虚拟机读取 U 盘 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"SpringCloud 开发随笔","url":"/posts/b9ecd4c2.html","text":"配置中心Nacos 配置中心Maven 引入 Nacos Config 不生效错误日志信息Spring Cloud 项目引入 Nacos Config 的 Maven 依赖后，使用 @Value 注解无法读取 Nacos 配置中心的内容，抛出的异常信息如下 1Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'common.name' in value \"${common.name}\" 第一种错误原因Spring Cloud 无法读取项目中的 bootstrap.yml 配置文件，此时需要额外引入 spring-cloud-starter-bootstrap 依赖来解决 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 第二种错误原因项目中 bootstrap.yml 配置文件的内容有误，导致 Nacos Config Spring Cloud 无法通过正确的 dataId 去 Nacos 配置中心获取对应的配置信息，正确的配置示例如下所示： 123456789101112131415server: port: 8080spring: application: name: seamall-coupon profiles: active: dev cloud: nacos: config: server-addr: 127.0.0.1:8848 # 配置中心的地址 namespace: 73975db4-5c7f-4fef-9ea9-36492bd59f45 # 命名空间 group: TEST_GROUP # 配置分组 file-extension: yaml # 由于当前环境对应的 profile 为 dev，因此这里完整的 dataId 就是 seamall-coupon-dev.yaml 上述 bootstrap.yml 配置文件对应的 Nacos Config 配置内容如下图所示 上述 bootstrap.yml 配置文件的详细说明如下 在 bootstrap.yaml 配置文件中，需要配置 spring.application.name，因为它是构成 Nacos Config 配置管理 dataId 字段的一部分。值得一提的是，在 Nacos Config Spring Cloud 中，dataId 的完整格式如下： 1${prefix}-${spring.profiles.active}.${file-extension} prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置 file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置，目前只支持 properties 和 yaml 类型 spring.profiles.active 即为当前环境对应的 profile。特别注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式会变成 ${prefix}.${file-extension} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 开发随笔"},{"title":"Spring Boot 集成 Alibaba OSS","url":"/posts/e4db4080.html","text":"前言本文主要介绍 Spring Boot 项目如何集成 Alibaba 的 OSS 服务（对象存储），教程内容同样适用于 Spring Cloud 项目。 提示 1、Spring Cloud 项目不建议继续使用 spring-cloud-starter-alicloud-oss 组件，尤其是较新版本的 Spring Cloud（例如 2021.0.1 版本），毕竟 Alibaba OSS 的官方文档也移除了该组件的使用说明。 2、Alibaba OSS 更多的使用教程请查看 官方文档。 版本说明 Spring Boot Spring Boot Alibaba 2.6.3 1.0.0 Maven 依赖1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;aliyun-oss-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;aliyun-spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; YAML 配置内容在 Spring Boot 的 application.yml 文件中配置 Alibaba OSS 的 accessKeyId、secretAccessKey、endpoint 123456alibaba: cloud: access-key: *** secret-key: *** oss: endpoint: *** Java 测试代码运行下述代码之前，记得将 BUCKET_NAME 更改为你自己的存储桶的名称。 1234567891011121314151617181920212223242526272829303132333435import com.aliyun.oss.OSSClient;import org.junit.jupiter.api.Test;import org.springframework.boot.test.context.SpringBootTest;import javax.annotation.Resource;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.InputStream;@SpringBootTestpublic class OssTest { /** * Bucket */ private static final String BUCKET_NAME = \"your-bucket\"; @Resource private OSSClient ossClient; /** * 上传文件 */ @Test public void uploadFile() throws FileNotFoundException { // 文件名称 String objectName = \"upload.jpg\"; // 文件路径 String filePath = \"/tmp/images/upload.jpg\"; // 文件上传 InputStream inputStream = new FileInputStream(filePath); ossClient.putObject(BUCKET_NAME, objectName, inputStream); } } var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Spring Cache 使用教程之二","url":"/posts/a843c693.html","text":"大纲 Spring Cache 使用教程之一 Spring Cache 使用教程之二 前言官方文档 Spring Cache 官方文档 使用 @Cacheable 注解@Cacheable 可以将方法运行的结果进行缓存，在缓存时效内再次调用该方法时不会调用方法本身，而是直接从缓存获取结果并返回给调用方。 属性介绍 属性名 描述 value / cacheNames 指定缓存的名称，Spring Cache 使用 CacheManage 管理多个缓存组件 Cache，这里的 Cache 组件就是根据该名称进行区分的，它负责对缓存执行真正的 CRUD 操作 key 缓存数据时 Key 的值，默认是使用方法参数的值，可以使用 SpEL 表达式计算 Key 的值 keyGenerator 缓存 Key 的生成策略，它和 key 属性互斥使用（只能二选一） cacheManager 指定缓存管理器（如 ConcurrentHashMap、Redis 等） cacheResolver 作用和 cacheManager 属性一样，两者只能二选一 condition 指定缓存的条件（满足什么条件才缓存），可用 SpELl 表达式（如 #id&gt;0，表示当入参 id 大于 0 时才缓存） unless 否定缓存，即满足 unless 指定的条件时，方法的结果不进行缓存，使用 unless 时可以在调用的方法获取到结果之后再进行判断（如 #result == null，表示如果结果为 null 时不缓存） sync 是否使用异步模式进行缓存，默认值是 false 在一个多线程的环境中，某些操作可能会被相同的参数并发地调用，同一个 value 值可能被多次计算（或多次访问数据库），这样就达不到缓存的目的。针对这些可能高并发的操作，可以使用 sync 属性来告诉底层的缓存提供者将缓存的入口锁住，这样在同一时刻就只能有一个线程计算操作的结果值，而其它线程则需要等待。当 sync 的值为 true 时，相当于同步操作，可以有效地避免出现缓存击穿的问题，关于缓存击穿的介绍可以点击 这里。 特别注意 1、即满足 condition 又满足 unless 条件的情况下，不会缓存数据 2、使用异步模式（sync=true）进行缓存时，unless 条件将不会生效 3、condition 不指定相当于 true，而 unless 不指定相当于 false 4、condition 属性使用的 SpEL 表达式只有 #root 和获取方法参数类的 SpEL 表达式，不能使用带返回结果的表达式（如 #result），因此 condition = \"#result != null\" 会导致所有对象都不写入缓存，每次都要查询数据库。 使用案例1234@Cacheable(value=\"users\", key=\"#id\")public User find(Integer id) { return null;} 指定 Key@Cacheable 注解有一个属性 key 可以用于直接定义缓存 Key，该属性不是必填项。如果为空，则会使用默认的 Key 生成器进行生成。默认的 Key 生成器要求方法参数具有有效的 hashCode() 和 equals() 方法实现。值得一提的是，key 属性的值支持使用 SpEL 表达式。使用方法参数作为 Key 时，可以直接使用 #参数名 或者 #p参数索引 的 SpEL 表达式来引用，以下的写法都是合法的。 12345678910111213141516171819@Cacheable(value=\"users\", key=\"#id\")public User find(Integer id) { return null;}@Cacheable(value=\"users\", key=\"#p0\")public User find(Integer id) { return null;}@Cacheable(value=\"users\", key=\"#user.id\")public User find(User user) { return null;}@Cacheable(value=\"users\", key=\"#p0.id\")public User find(User user) { return null;} 使用 @CachePut 注解与 @Cacheable 注解不同的是使用 @CachePut 注解标注的方法，在执行前不会去检查缓存中是否存在之前执行过的结果，而是每次都会执行该方法，并将执行结果以键值对的形式写入指定的缓存中。@CachePut 注解一般用于更新缓存数据，相当于缓存使用的是写模式中的双写模式。 属性介绍@CachePut 注解所具有的属性与 @Cacheable 注解相同，这里不再累述。 使用案例12345@CachePut(value = \"users\", key=\"#user.id\")public User updateUser(User user) { userMapper.updateUser(user); return user;} 使用 @CacheEvict 注解标注了 @CacheEvict 注解的方法在被调用时，会从缓存中移除已存储的数据。@CacheEvict 注解一般用于删除缓存数据，相当于缓存使用的是写模式中的失效模式。 属性介绍 属性名 描述 value / cacheNames 缓存的名称 key 缓存的键 allEntries 是否根据缓存名称清空所有缓存数据，默认值为 false，当值指定为 true 时，Spring Cache 将忽略注解上指定的 key 属性 beforeInvocation 是否在方法执行之前就清空缓存，默认值为 false 清除缓存的操作默认是在对应方法成功执行之后才触发的，即方法的执行如果因为抛出异常而未能成功返回时也不会触发清除操作。使用 beforeInvocation 属性可以改变触发清除操作执行的时机，当指定该属性的值为 true 时，Spring 会在调用该方法之前清除缓存中的数据。值得一提的是，在方法调用之前还是之后清除缓存的区别在于方法调用时是否会出现异常，若不出现异常，这两者之间没有区别，若出现异常，设置为在方法调用之后清除缓存将不起作用，因为方法调用失败了。 使用案例1234@CacheEvict(value = \"users\", key = \"#id\")public void deleteUserById(Long id) { userMapper.deleteUserById(id);} 使用 @Caching 注解@Caching 注解用于在一个方法或者类上，同时指定多个 Spring Cache 相关的注解。 属性介绍 属性名 描述 cacheable 用于指定 @Cacheable 注解 put 用于指定 @CachePut 注解 evict 用于指定 @@CacheEvict 注解 使用案例12345678@Caching(cacheable = {@Cacheable(value = \"stu\", key = \"#userName\")}, put = { @CachePut(value = \"stu\", key = \"#result.id\"), @CachePut(value = \"stu\", key = \"#result.age\")})public Student getStuByUserName(String userName) { StudentExample studentExample = new StudentExample(); studentExample.createCriteria().andUserNameEqualTo(userName); List&lt;Student&gt; students = studentMapper.selectByExample(studentExample); return Optional.ofNullable(students).orElse(null).get(0);} 使用 @CacheConfig 注解@CacheConfig 注解标注在类上，用于抽取 Spring Cache 相关注解的公共配置，可抽取的公共配置包括缓存名称、主键生成器、缓存管理器。比如，在每个 Spring Cache 缓存注解中，往往都指定了缓存名称（value = \"stu\" 或者 cacheNames = \"stu\"）。此时 @CacheConfig 注解可以将它抽离出来，并在整个类上添加 @CacheConfig(value = \"stu\") 注解之后，每个方法默认都会使用指定的缓存名称 stu。 属性介绍 属性名 描述 value / cacheNames 指定缓存的名称，Spring Cache 使用 CacheManage 管理多个缓存组件 Cache，这里的 Cache 组件就是根据该名称进行区分的，它负责对缓存执行真正的 CRUD 操作 cacheManager 缓存管理器 keyGenerator 主键生成器 使用案例123456789101112131415161718192021@Service@CacheConfig(value = \"stu\")public class StudentServiceImpl implements StudentService { @Resource private StudentMapper studentMapper; @Override @CachePut(key = \"#result.id\") public Student updateStu(Student student){ studentMapper.updateByPrimaryKey(student); return student; } @Override @CacheEvict(key = \"#id\") public void delSut(Integer id) { studentMapper.deleteByPrimaryKey(id); }} 使用 SpEL 表达式SpEL 表达式的语法 Spring Cache 也提供了 root 对象，可以在 SpEL 表达式中直接使用 名称 位置 描述 示例 methodName 根对象 要调用的方法的名称 #root.methodName method 根对象 正在调用的方法 #root.method.name target 根对象 正在调用的目标对象 #root.target targetClass 根对象 要调用的目标的类 #root.targetClass args 根对象 用于调用目标的参数（作为数组） #root.args[0] caches 根对象 正在调用的方法使用的缓存列表（如 @Cacheable(value={\"cache1\", \"cache2\"}))，则有两个缓存） #root.caches[0].name argument name 评估背景 方法参数名，可以直接使用 #参数名，也可以使用 #p0 或 #a0 的形式，0 代表参数的索引 #iban、#a0、#p0 result 评估背景 方法执行后的返回值，仅当方法执行之后的判断有效，如 unless、cache put、cache evict (当 beforeInvocation = false) 的表达式 #result SpEL 表达式的使用案例123456789@Cacheable(value=\"users\", key=\"#p0.id\")public User find(User user) { return null;}@Cacheable(value=\"users\", key=\"#root.method.name\")public User find(User user) { return null;} 当需要使用 root 对象的属性作为 Key 时，还可以将 #root 省略掉，因为 Spring Cache 默认使用的就是 root 对象的属性 1234@Cacheable(value={\"users\", \"members\"}, key=\"caches[0].name\")public User find(User user) { return null;} 当需要调用目前类里的方法动态生成 Key 时，在 SpEL 表达式内拼接字符串时，必须使用单引号将字符串包裹起来 123456789101112@Cacheable(value=\"users\", key=\"#root.target.getDictTableName() + '_' + #root.target.getFieldName()\")public User find(User user) { return null;}public String getDictTableName(){ return \"\";}public String getFieldName(){ return \"\";} 自定义缓存配置防止缓存穿透为了避免出现缓存穿透，建议让 Spring Cache 将空值也写入缓存，关于缓存穿透的介绍可以点击 这里。 123456spring: cache: type: redis redis: # 是否缓存空值，防止缓存穿透 cache-null-values: true 指定有效时间指定缓存数据的有效时间，这样可以让缓存数据过期被删除后，触发主动更新（基于缓存的读模式）。 123456spring: cache: type: redis redis: # 有效时间，单位为毫秒 time-to-live: 3600000 提示 Spring Cache 的注解不支持给缓存单独设置不同的有效时间，若希望像 Redis 一样设置缓存的有效时间，可以参考这篇 博客。 指定 Key 前缀在不指定 Key 前缀时，Spring Cache 默认会使用缓存的名称作为 Key 前缀。 12345678spring: cache: type: redis redis: # Key 的前缀，建议不配置，让它默认使用缓存的名称作为前缀 key-prefix: CACHE_ # 是否使用前缀 use-key-prefix: true 指定 Key 生成器缓存的本质就是键值对存储模式，每一次方法的调用都需要生成相应的 Key，这样才能操作缓存。若没有给 Spring Cache 的注解（如 @Cacheable）设置属性 key，缓存抽象默认会使用 SimpleKeyGenerator 来自动生成 Key，具体源码如下： 如果没有方法参数，则直接返回 SimpleKey.EMPTY 如果只有一个方法参数，则直接返回该方法参数 若有多个方法参数，则返回包含多个方法参数的 SimpleKey 对象 Spring Cache 也考虑到需要自定义 Key 的生成方式，只需要实现 org.springframework.cache.interceptor.KeyGenerator 接口，然后通过 @Cacheable 注解的 keyGenerator 属性指定 Key 生成器即可。值得一提的是，默认的 Key 生成器要求方法参数具有有效的 hashCode() 和 equals() 方法实现。 123456789101112/*** 自定义 Key 生成器*/@Componentpublic class CustomKeyGenerator implements KeyGenerator { public Object generate(Object target, Method method, Object... params) { String key = target.toString() + \":\" + method.getName() + \":\" + Arrays.toString(params); return key; }} 1234567/*** 指定自定义的 Key 生成器*/@Cacheable(value=\"users\", keyGenerator=\"customKeyGenerator\")public User find(User user) { return null;} 指定序列化机制默认情况下，Spring Cache 会使用 JDK 的序列化机制将缓存数据写入 Redis，这样存储在 Redis 里面的就是二进制数据。若希望 Spring Cache 将数据序列化成 JSON 数据再写入 Redis，可以使用以下的配置类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.springframework.boot.autoconfigure.cache.CacheProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializationContext;import org.springframework.data.redis.serializer.StringRedisSerializer;import java.time.Duration;@Configuration@EnableCaching@EnableConfigurationProperties(CacheProperties.class)public class SpringCacheConfig extends CachingConfigurerSupport { /** * Spring Cache 的 Redis 配置 */ @Bean public RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) { // 默认配置 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig(); // 设置随机的有效时间，若不设置，默认是永久有效 // Random random = new Random(); // config = config.entryTtl(Duration.ofHours(random.nextInt(24))); // Key的序列化机制 config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())); // Value的序列化机制 config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())); // 加载配置文件的内容 CacheProperties.Redis redisProperties = cacheProperties.getRedis(); if (redisProperties.getTimeToLive() != null) { config = config.entryTtl(redisProperties.getTimeToLive()); } if (redisProperties.getKeyPrefix() != null) { config = config.prefixCacheNameWith(redisProperties.getKeyPrefix()); } if (!redisProperties.isCacheNullValues()) { config = config.disableCachingNullValues(); } if (!redisProperties.isUseKeyPrefix()) { config = config.disableKeyPrefix(); } return config; }} Spring Cache 加载 Redis 缓存配置的流程 CacheAutoConfiguration --&gt; RedisCacheConfiguration --&gt; 自动配置了 RedisCacheManager --&gt; 初始化所有缓存 --&gt; 每个缓存决定使用什么配置内容 --&gt; 如果 RedisCacheConfiguration 有就用已经有的，没有就用默认的 Redis 配置 所以如果想自定义 Redis 缓存配置，只需要在 Spring 容器中放一个 RedisCacheConfiguration，它就会应用到当前 RedisCacheManager 管理的所有缓存分区中 常见问题总结缓存不生效在有些情形下，Spring Cache 注解式缓存是不起作用的。比如在同一个 Bean 里的内部方法调用，又或者是子类调用父类中有缓存注解的方法等。后者不起作用是因为缓存切面必须走代理才有效，这时候可以手动使用 CacheManager 来获得缓存效果。 Spring Cache 的不足 读模式 读模式下，可能会出现缓存失效的问题，Spring Cache 的解决方案如下 缓存穿透：查询一个不存在的数据（Null），解决方案是缓存空数据，配置内容是 cache-null-values: true 缓存雪崩：大量缓存同时过期，解决方案是给缓存设置过期时间（或者是随机的过期时间），配置内容是 time-to-live: 3600000 缓存击穿：大量并发请求进来同时查询一个正好过期的数据，解决方案是使用 @Cacheable(sync = true) 来实现同步模式的缓存写入，底层是基于 JDK 的 synchronized 写模式 双写模式或者失效模式下，可能会出现缓存数据一致性问题（读取到脏数据），Spring Cache 暂时没办法解决，其他的解决方案如下 加分布式锁（读写锁），只适用于读多写少的业务场景 直接查询数据库，不再从缓存获取数据，只适用于读多写多的业务场景 使用 Canal 中间件，实时将数据库的数据更新到缓存，会增加系统的复杂性 总结 常规数据（读多写少、即时性与一致性要求不高的数据）完全可以使用 Spring Cache，至于写模式下缓存数据一致性问题的解决，只要缓存数据有设置过期时间就足够了 特殊数据（读多写多、即时性与一致性要求非常高的数据），不能使用 Spring Cache，建议考虑特殊的设计（例如使用 Cancal 中间件等） 提示 更多关于缓存写模式、缓存失效、缓存数据一致性、分布式锁的介绍，请点击 这里。 参考博客 Spring Cache 详解 Spring Cache 基础使用 JSR-107 与 Spring Boot 缓存 Spring Boot 中 Cache 缓存的介绍和使用 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 缓存"},{"title":"Spring Cache 使用教程之一","url":"/posts/e792e01b.html","text":"大纲 Spring Cache 使用教程之一 Spring Cache 使用教程之二 前言官方文档 Spring Cache 官方文档 简单介绍Spring Cache 是 Spring 提供的一个缓存框架，从 Spring 3.1 版本开始支持将缓存添加到现有的 Spring 应用程序中，从 Spring 在 4.1 版本开始，缓存已支持 JSR-107 注释和更多自定义的选项。Spring Cache 利用了 AOP，实现了基于注解的缓存功能，并且进行了合理的抽象，业务代码不用关心底层是使用了什么缓存框架，只需要简单地加一个注解就能实现缓存功能，做到了较小的代码侵入性。由于市面上的缓存工具实在太多，Spring Cache 框架还提供了 CacheManager 接口，可以实现降低对各种缓存框架的耦合；它不是具体的缓存实现，只是提供一整套的接口和代码规范、配置、注解等，用于整合各种缓存方案，比如 Ehcache、Caffeine、Hazelcast、Couchbase 等。 JSR-107 规范JSR 是 Java Specification Requests（Java 规范请求）的缩写。JSR-107 是关于如何使用缓存的规范，是 Java 提供的一个接口规范，类似 JDBC 规范，没有具体的实现。Java Caching（JSR-107）定义了 5 个核心接口，分别是 CachingProvider、CacheManager、Cache、Entry 、Expiry。 CachingProvider（缓存提供者）：用于创建、配置、获取、管理和控制多个 CacheManager。 CacheManager（缓存管理器）：用于创建、配置、获取、管理和控制多个唯一命名的 Cache，一个 CacheManager 仅对应一个 CachingProvider。 Cache（缓存）：存在于 CacheManager 的上下文中，是一个类似 Map 的数据结构，并临时存储以 Key 为索引的值。一个 Cache 仅被一个 CacheManager 所拥有，由 CacheManager 管理其生命周期。 Entry（缓存键值对）：是一个存储在 Cache 中的键值对。 Expiry（缓存时效）：每一个存储在 Cache 中的条目都有一个定义的有效期。一旦超过这个时间，条目就自动过期，过期后条目将不可以执行访问、更新和删除操作。缓存有效期可以通过 ExpiryPolicy 设置。 Spring Cache 概念大致原理在 Spring Cache 官网中，有一个缓存抽象的概念，其核心就是将缓存应用于 Java 方法中，从而减少基于缓存中可用信息的执行次数。换句话来说，就是每次调用目标方法前，Spring Cache 都会先检查该方法是否正对给定参数执行，如果已经执行过，就直接返回缓存的结果。通俗的讲，就是查看缓存里面是否有对应的数据，如果有就返回缓存数据，而无需执行实际方法；如果该方法尚未执行，则执行该方法（缓存中没有对应的数据就执行方法来获取对应的数据），并缓存结果后返回给用户。这样就不用多次去执行数据库操作，减少 CPU 和 IO 的消耗。 使用 Spring 缓存抽象时，应该需要关注以下两点 1、确定方法需要被缓存以及它们的缓存策略 2、从缓存中读取之前缓存存储的数据 核心接口 org.springframework.cache.Cache：为缓存组件定义规范，包含缓存的各种操作集合。在 Cache 接口下，Spring 提供了各种 xxxCache 的实现，如 RedisCache、EhCacheCache、ConcurrentMapCache 等。 org.springframework.cache.CacheManager：缓存管理器，管理各种缓存（Cache）组件，如 RedisCacheManager，使用 Redis 作为缓存。 核心注解 注解 说明 @Cacheable 主要针对方法配置，能够根据方法的请求参数对其执行结果进行缓存，相当于缓存使用的是读模式 @CacheEvict 将一条或多条数据从缓存中删除，相当于缓存使用的是写模式中的失效模式 @CachePut 保证方法被调用，又希望结果被缓存，相当于缓存使用的是写模式中的双写模式 @EnableCaching 开启基于注解的缓存功能 @CacheConfig 标注在类上，用于抽取 Spring Cache 相关注解的公共配置，可抽取的公共配置包括缓存名称、主键生成器、缓存管理器 @Caching 用于在一个方法或者类上，同时指定多个 Spring Cache 相关的注解 keyGenerator 缓存数据时 Key 的生成策略 serialize 缓存数据时 Value 的序列化策略 在上面常用的三个注解 @Cacheable、@CachePut、CacheEvict 中，主要有以下的参数，可用于对要缓存的数据进行过滤和配置。 提示 1、@Cacheable 标注在方法上，表示方法的结果需要被缓存起来，缓存的键由 keyGenerator 的策略决定，缓存的值的形式则由 serialize 序列化策略决定（JDK 还是 Json 序列化机制）；标注上该注解之后，在缓存时效内再次调用该方法时不会调用方法本身，而是直接从缓存获取结果。 2、@CachePut 也标注在方法上，它和 @Cacheable 相似也会将方法的返回值缓存起来，不同的是标注 @CachePut 的方法每次都会被调用，而且每次都会将结果缓存起来，适用于对象的更新。 Spring Cache 整合下面将介绍 Spring Boot 项目如何整合 Spring Cache，并使用 Redis 存储缓存数据。 引入依赖123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt; 配置信息在 application.yml 配置文件里，指定 Spring Cache 使用 Redis 存储缓存数据，并配置 Redis 的连接信息。 123456789spring: redis: host: 127.0.0.1 port: 6379 password: 123456 database: 0 timeout: 5000 cache: type: redis 启用缓存在应用的主启动类上添加 @EnableCaching 注解，启用 Spring Cache 的缓存功能。 12345@EnableCaching@SpringBootApplicationpublic class ProductApplication { } 配置序列化默认情况下，Spring Cache 会使用 JDK 的序列化机制将缓存数据写入 Redis，这样存储在 Redis 里面的就是二进制数据。若希望 Spring Cache 将数据序列化成 JSON 数据再写入 Redis，可以使用以下的配置类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import org.springframework.boot.autoconfigure.cache.CacheProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializationContext;import org.springframework.data.redis.serializer.StringRedisSerializer;import java.time.Duration;@Configuration@EnableConfigurationProperties(CacheProperties.class)public class SpringCacheConfig extends CachingConfigurerSupport { /** * Spring Cache 的 Redis 配置 */ @Bean public RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) { // 默认配置 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig(); // 设置随机的有效时间，若不设置，默认是永久有效 // Random random = new Random(); // config = config.entryTtl(Duration.ofHours(random.nextInt(24))); // Key的序列化机制 config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())); // Value的序列化机制 config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())); // 加载配置文件的内容 CacheProperties.Redis redisProperties = cacheProperties.getRedis(); if (redisProperties.getTimeToLive() != null) { config = config.entryTtl(redisProperties.getTimeToLive()); } if (redisProperties.getKeyPrefix() != null) { config = config.prefixCacheNameWith(redisProperties.getKeyPrefix()); } if (!redisProperties.isCacheNullValues()) { config = config.disableCachingNullValues(); } if (!redisProperties.isUseKeyPrefix()) { config = config.disableKeyPrefix(); } return config; }} 添加缓存注解在需要使用缓存的方法上添加 @Cacheable 注解，其中的 value 参数代表缓存的名称，必须指定至少一个。标注上该注解之后，会将方法运行的结果进行缓存，在缓存时效内再次调用该方法时不会调用方法本身，而是直接从缓存获取结果并返回给调用方。 123456789101112@Service(\"categoryService\")public class CategoryServiceImpl implements CategoryService { @Override @Cacheable(value = \"categoryTree\") public List&lt;CategoryEntity&gt; listWithTree() { // TODO 查询数据库 System.out.println(\"查询数据库\"); return Collections.emptyList(); }} 至此，Spring Boot 项目整合 Spring Cache 的步骤就完成了。当重复调用标记了 @Cacheable 注解的方法时，可以发现该方法只会被调用一次，此时说明 Redis 的缓存生效了。 参考博客 Spring Cache 详解 Spring Cache 基础使用 JSR-107 与 Spring Boot 缓存 Spring Boot 中 Cache 缓存的介绍和使用 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 缓存"},{"title":"Centos7 使用 Rsync 同步文件","url":"/posts/a8ab361e.html","text":"前言Rsync 是一个增量备份工具，可压缩数据传输，速度快且增量备份，占用流量少。 准备工作创建用户12345# 创建用户组# groupadd www# 创建用户# useradd -g www www -s /bin/false 创建配置文件12# 创建Rsync服务器信息提示文件# echo \"Welcome To Access\" &gt; /etc/rsyncd.motd 123456# 创建Rsync服务器密码文件，其中 RsyncUser 是用户名，123456 是密码# echo \"RsyncUser:123456\" &gt; /etc/rsyncd.secrets# Rsync服务器密码文件授权，所属的用户和用户组必须都是 root，同时权限必须为 600# chown root:root /etc/rsyncd.secrets# chmod 600 /etc/rsyncd.secrets 安装 Rsync安装 Rsync 服务12345# 安装#&nbsp;yum install rsync# 开机自启动# systemctl enable rsyncd 注意 这里还需要更改 systemd 的配置文件，加入以下内容，否则 Rsync 服务开机无法正常自启动。 12345678# 更改systemd的配置文件，加入以下内容# vim /usr/lib/systemd/system/rsyncd.service[Unit]...After=network.target# 让配置文件生效# systemctl daemon-reload 配置 Rsync 服务12345# 备份默认的配置文件# cp /etc/rsyncd.conf /etc/rsyncd.conf.bak# 编辑配置文件，添加以下内容（请自行根据实际情况更改对应的配置内容）# vim /etc/rsyncd.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 设置服务器信息提示文件名称，在该文件中编写提示信息motd file = /etc/rsyncd.motd# 开启Rsync数据传输日志功能transfer logging = yes# 设置日志文件名称，可以通过log format参数设置日志格式log file =/var/log/rsyncd.log# 设置Rsync进程号保存文件名称pid file =/var/run/rsyncd.pid# 设置锁文件名称lock file =/var/run/rsync.lock# 设置服务器监听的端口号，默认为873 port = 873# 设置服务器所监听网卡接口的IP地址（内网IP）address = 172.0.25.18# 设置进行数据传输时所使用的账户名称或ID号，默认使用nobody uid = www# 设置进行数据传输时所使用的组名称或GID号，默认使用nobody gid = www# 设置user chroot为yes后，rsync会首先进行chroot设置，将根映射到path参数路径下，对客户端而言，系统的根就是path参数所指定的路径。但这样做需要root权限，并且在同步符号连接资料时仅会同步名称，而内容将不会同步。 use chroot = no# 是否允许客户端上传数据，这里设置不为只读。 read only = no# 设置并发连接数，0代表无限制。超出并发数后，如果依然有客户端连接请求，则将会收到稍后重试的提示消息 max connections = 10# 模块，Rsync通过模块定义同步的目录，模块以[name]的形式定义，这与Samba定义共享目录是一样的效果，在Rsync中也可以定义多个模块[blog]# comment定义注释说明字串 comment = rsync blog files# 同步目录的真实路径通过path指定 path = /home/www/blog# 忽略一些IO错误 ignore errors# exclude可以指定例外的目录，即将common目录下的某个目录设置为不同步数据 # exclude = test/ # 设置允许连接服务器的账户，账户可以是系统中不存在的用户 auth users = RsyncUser# 设置密码文件名称，注意该文件的权限要求为只读，建议权限为600，仅在设置auth users参数后有效 secrets file = /etc/rsyncd.secrets# 设置允许哪些主机可以同步数据，可以是单个IP，也可以是网段，多个IP与网段之间使用空格分隔 hosts allow = *# 设置拒绝所有（除hosts allow定义的主机外） # hosts deny = *# 客户端请求显示模块列表时，本模块名称是否显示，默认为true list = true 启动 Rsync 服务12345# 启动服务# systemctl start rsyncd# 查看服务的运行状态# systemctl status rsyncd 值得一提的是，还可以使用以下命令管理 Rsync 服务： 12345# 关闭服务# systemctl stop rsyncd# 重启服务# systemctl restart rsyncd 配置系统防火墙12345678# 开放Rsync监听的端口（默认端口是873）# firewall-cmd --permanent --add-port=873/tcp# 让防火墙规则生效# firewall-cmd --reload# 查看所有开放的端口# firewall-cmd --list-ports 测试文件同步服务提示 在下述的案例里，各命令参数的说明如下： 183.242.11.186：服务器的 IP 地址 blog：在 /etc/rsyncd.conf 配置文件中定义的模块名称 RsyncUser：在 /etc/rsyncd.secrets 配置文件中定义的用户名 --delete：表示同步文件时，删除目标目录比源目录多余的文件 同步目录授权在服务器上，确保用户拥有在 /etc/rsyncd.conf 配置文件中定义的 path 同步目录的访问权限。 12# 同步目录授权# chown -R www:www /home/www/blog 客户端同步服务器文件到本地12345# 客户端同步服务器的某个文件到本地$ rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./# 客户端同步服务器的某个目录到本地$ rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/posts/ ./posts/ 客户端同步本地文件到服务器12345678# 客户端同步本地的某个文件到服务器$ rsync -rlptDv index.html RsyncUser@183.242.11.186::blog/# 客户端同步本地的某个目录到服务器（本地的目录路径必须不以'/'结尾）$ rsync -avzP --delete ./posts RsyncUser@183.242.11.186::blog/# 客户端同步本地某个目录下的所有文件到服务器（本地的目录路径必须以'/'结尾）$ rsync -avzP --delete ./posts/ RsyncUser@183.242.11.186::blog/ 设置同步时不手动输入密码在客户端同步文件时指定密码文件，这样可以避免每次都手动输入密码。 123456# 在本地创建密码文件，其中 123456 是密码，这里不需要指定用户名# echo \"123456\" &gt; /etc/rsyncd.password# 密码文件授权，所属的用户和用户组必须都是 root，同时权限必须为 600# chown root:root /etc/rsyncd.password# chmod 600 /etc/rsyncd.password 12# 客户端同步服务器的某个文件到本地（指定密码文件）# rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./ --password-file=/etc/rsyncd.password 提示 除了上述的方法之外，还可通过设置环境变量的方式，避免每次都手动输入密码。 12345# 通过环境变量设置密码# export RSYNC_PASSWORD=\"123456\"# 客户端同步服务器的某个文件到本地# rsync -vzrtopg --progress RsyncUser@183.242.11.186::blog/index.html ./ 不同步文件的所有者和用户组信息在 rsync -a dir/ remote:/dir/ 命令中，-a 相当于 -rlptgoD，各参数选项的说明如下： 123456789-o, --owner preserve owner (super-user only)-g, --group preserve group-r, --recursive recurse into directories-l, --links copy symlinks as symlinks-p, --perms preserve permissions-t, --times preserve modification times-D same as --devices --specials --devices preserve device files (super-user only) --specials preserve special files 若希望不同步文件的所有者和用户组信息，那么可以通过移除 -o 和 -g 参数选项来实现，示例命令如下： 1$ rsync -a --no-o --no-g dir/ remote:/dir/ 用参数控制 Rsync 同步时的比较算法Rsync 默认只会比较文件大小和最后修改时间，只要这两者一样，Rsync 就认为文件相同；此时如果其它属性（包括文件内容）的不同，并不会让 Rsync 同步该文件。所以，如果本地文件与远程文件大小一样，修改时间也一样，那么默认情况下，即使文件内容不一样的文件也不同被同步。通过设置合适的参数，可以控制 Rsync 的比较算法，其中 Rsync 使用以下三个步骤来比较文件： a) 比较文件大小 b) 比较文件最后修改日期 c) 比较文件内容，通过 checksum，例如使用 md5sum 可以用参数来控制 Rsync 执行上面的哪些步骤： 默认的比较算法只执行 a 和 b 参数 --size-only 只检查 a ，即只要文件大小一样，即使修改日期不一样，就认为文件一样，更不会去检查文件内容 参数 --ignore-times 是忽略所有检查，直接认为文件都不一样，然后总是复制文件 参数 --checksum 是在 a 的基础上执行 c ，比较文件内容。如果文件大小不一样，可以确保内容不一样。如果文件大小一样，那么直接比较文件内容，不会执行 b 中的比较最后修改时间。该方法最安全，但需要读取两边的文件内容，某些情况下要慢很多（尤其是最后比较出来的文件内容一样的情况） 命令参数的使用示例如下： 1$ rsync -avzP --delete --checksum dir/ remote:/dir/ 常见问题delete 参数不生效 Rsync –delete option doesn’t delete files in target directory var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"centos"},{"title":"IDEA 开发随笔","url":"/posts/6c257231.html","text":"IDEA 常用插件推荐 推荐 插件名称 插件说明 官方地址 √ Key Promoter X 快捷键提示 https://plugins.jetbrains.com/plugin/9792?pr=idea JRebel Plugin（收费） 热部署 https://plugins.jetbrains.com/plugin/4441?pr=idea √ CodeGlance 代码编辑区缩略图 https://plugins.jetbrains.com/plugin/7275?pr=idea √ Lombok 代码注解支持 https://plugins.jetbrains.com/plugin/6317?pr=idea GsonFormat JSON 转领域对象工具 https://plugins.jetbrains.com/plugin/7654?pr=idea √ Alibaba Java Coding Guidelines 阿里巴巴代码规约检测 https://plugins.jetbrains.com/plugin/10046?pr=idea Mybatis Log Plugin MyBatis SQL 日志格式化 https://plugins.jetbrains.com/plugin/10065?pr=idea √ MyBatisX 自动生成代码，支持在 Mapper 接口和 XML 映射文件之间跳转 https://plugins.jetbrains.com/plugin/10119-mybatisx MyBatisCodeHelperPro 自动生成代码，支持在 Mapper 接口和 XML 映射文件之间跳转 https://plugins.jetbrains.com/plugin/9837-mybatiscodehelperpro Free MyBatis plugin 自动生成代码，支持在 Mapper 接口和 XML 映射文件之间跳转 https://plugins.jetbrains.com/plugin/8321?pr=idea √ Maven Helper Maven 依赖分析 https://plugins.jetbrains.com/plugin/7179?pr=idea Gradle Dependencies Helper Gradle 依赖提示 https://plugins.jetbrains.com/plugin/7299?pr=idea Gradle Dependencies Formatter 将 Maven 依赖转换为 Gradle 依赖 https://plugins.jetbrains.com/plugin/7937?pr=idea √ Rainbow Brackets 彩色的括号 https://plugins.jetbrains.com/plugin/10080?pr=idea √ Grep Console 控制日志颜色 https://plugins.jetbrains.com/plugin/7125?pr=idea √ .ignore Git 忽略文件 https://plugins.jetbrains.com/plugin/7495?pr=idea Translation 中英文翻译 https://plugins.jetbrains.com/plugin/8579?pr=idea CodeMaker 代码生成 https://plugins.jetbrains.com/plugin/9486?pr=idea codehelper.generator 代码生成 https://plugins.jetbrains.com/plugin/8640?pr=idea MyBatisCodeHelperPro（收费） MyBatis 代码生成 https://plugins.jetbrains.com/plugin/9837?pr=idea GenerateAllSetter 生成 Get、Set 方法 https://plugins.jetbrains.com/plugin/9360?pr=idea JUnitGenerator 生成 Junit 代码 https://plugins.jetbrains.com/plugin/3064?pr=idea CamelCase 驼峰式命名和下划线命名交替切换 https://plugins.jetbrains.com/plugin/7160?pr=idea Statistic 代码统计 https://plugins.jetbrains.com/plugin/4509?pr=idea √ CheckStyle-IDEA 代码规范和风格的检查 https://plugins.jetbrains.com/plugin/1065?pr=idea √ FindBugs-IDEA 代码 Bug 检查 https://plugins.jetbrains.com/plugin/3847?pr=idea SonarLint 代码 Bug 检查、代码质量优化 https://plugins.jetbrains.com/plugin/7973?pr=idea Eclipse Code Formatter 使用 Eclipse 的代码格式化风格 https://plugins.jetbrains.com/plugin/6546?pr=idea Spring Initializr 网络连接超时使用 Spring Initializr 工具初始化 SpringBoot 项目时，出现网络连接超时的异常。 方案一使用阿里云版的 Spring Initializr 来替代，在 IDEA 内搜索 Alibaba Cloud Toolkit 插件，安装插件后重启 IDEA。 方案二（推荐）配置阿里云的 Spring Initializr URL，可以在 Spring Initializr 的界面中指定服务器 URL 为 https://start.aliyun.com/ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Spring 与 SpringBoot 配置跨域的几种方式","url":"/posts/3a3d508.html","text":"前言跨域介绍 什么是跨域：浏览器从一个域名的网页去请求另一个域名的资源时，域名、端口、协议任一项不同，都属于跨域 造成的原因：由于浏览器的同源策略，即 A 网站只能访问 A 网站的内容，不能访问 B 网站的内容 特别注意：跨域问题只存在于浏览器，也就是说当前端页面访问后端的接口时，返回值是有的，只是服务器没有在请求头指定跨域的信息，所以浏览器自动把返回值给” 屏蔽了” 解决跨域：经过上面的了解，可以得出几个解决跨域的方法（这里暂不考虑前端的实现方案），一是服务端指定跨域信息，二是在 Web 页面与后端服务之间加一层服务来指定跨域信息，比如代理服务 Nginx 提示 更多关于跨域的详细介绍内容，可以看 这里。 跨域解决方案方案一使用 Nginx 等代理服务器，将不同的应用部署为同一域。 方案二添加 HTTP 响应头，配置当次请求允许跨域。 Access-Control-Allow-Origin：支持哪些来源的请求跨域 Access-Control-Allow-Methods：支持哪些方法跨域 Access-Control-Allow-Credentials：跨域请求默认不包含 Cookie，设置为 true 则可以包含 Cookie Access-Control-Max-Age：表明该响应的有效时间为多少秒。在有效时间内，浏览器无须为同一请求再次发起预检请求。请注意，浏览器自身维护了一个最大有效时间，如果该字段的值超过了最大有效时间，将不会生效 Access-Control-Expose-Headers：跨域请求暴露的字段。发出跨域请求时，XMLHttpRequest 对象的 getResponseHeader () 方法默认只能拿到 6 个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在 Access-Control-Expose-Headers 里面指定 Spring 配置跨域使用注解实现跨域 特别注意：Spring 的版本要在 4.2 或以上版本才支持使用 @CrossOrigin 注解来控制跨域，使用注解的方式优势在于比较容易细粒度（局部）地实现跨域控制 在 Controller 类中配置跨域，可以使用注解 @CrossOrigin，该注解支持写在类或者方法上，示例代码如下： 1234567891011@RestController@RequestMapping(\"/account\")public class AccountController { @CrossOrigin @GetMapping(\"/{id}\") public Account retrieve(@PathVariable Long id) { }} 或者 1234567891011121314import org.springframework.web.bind.annotation.*;import static org.springframework.web.bind.annotation.RequestMethod.*;@RestController@RequestMapping(\"/account\")@CrossOrigin(origins = {\"http://example.com\"}, maxAge = 3600, allowedHeaders = {\"Origin\", \"X-Requested-With\", \"Content-Type\", \"Accept\", \"token\"}, methods = {GET, POST, PUT, OPTIONS, DELETE, PATCH})public class AccountController { @GetMapping(\"/{id}\") public Account retrieve(@PathVariable Long id) { }} @CrossOrigin 注解中的参数说明如下： origins：允许来源域名的列表，不设置确切值时默认支持所有域名跨域访问 methods: 跨域请求中支持的 HTTP 请求的类型（GET、POST、DELETE …），不指定确切值时默认与 Controller 方法中的 methods 字段保持一致 maxAge：跨域预检请求的有效期（单位为秒），目的是减少浏览器预检 / 响应的请求数量，默认值是 1800秒；设置了该值后，浏览器将在设置值的时间段内对该跨域请求不再发起预检请求 exposedHeaders：跨域请求的请求头中允许携带除 Cache-Controller、Content-Language、Content-Type、Expires、Last-Modified、Pragma 这六个基本字段之外的其他字段信息 allowedHeaders：允许的请求头中的字段类型，不设置确切值时默认支持所有的 Header 字段（Cache-Controller、Content-Language、Content-Type、Expires、Last-Modified、Pragma）跨域访问 allowCredentials：浏览器是否将本域名下的 Cookie 信息携带至跨域服务器中，若设置为携带 Cookie 至跨域服务器中，要实现 Cookie 共享还需要前端在 AJAX 请求中打开 withCredentials 属性 SpringMVC 还支持同时使用类和方法级别的跨域配置，此时 SpringMVC 会合并两个注解属性以创建合并后的跨域配置 123456789101112@RestController@RequestMapping(\"/account\")@CrossOrigin(maxAge = 3600)public class AccountController { @CrossOrigin(origins = {\"http://example.com\"}) @GetMapping(\"/{id}\") public Account retrieve(@PathVariable Long id) { }} 如果在 Spring 项目里使用了 Spring Security，请确保 Spring Security 在安全级别启用 CORS，并允许它利用 Spring MVC 级别的配置定义 123456789@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.cors().and()... }} 使用拦截器实现跨域123456789101112131415161718192021222324252627282930313233343536373839import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Configurationpublic class WebMvcConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new HandlerInterceptor() { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { response.addHeader(\"Access-Control-Allow-Origin\", \"*\"); response.setHeader(\"Access-Control-Allow-Credentials\", \"true\"); response.addHeader(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, OPTIONS\"); response.addHeader(\"Access-Control-Allow-Headers\", \"Content-Type,X-Requested-With,Accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,token\"); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } }); }} 由于请求头中自定义的字段是不允许跨域的，所以需要指定允许跨域的自定义 Header，上述的代码段如下： 1response.addHeader(\"Access-Control-Allow-Headers\", \"Content-Type,X-Requested-With,Accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,token\"); 使用过滤器实现跨域123456789101112131415161718192021222324252627282930313233343536373839404142434445import org.springframework.stereotype.Component;import javax.servlet.*;import javax.servlet.annotation.WebFilter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;import java.io.IOException;@Component@WebFilter(urlPatterns = {\"/*\"}, filterName = \"corsFilter\")public class CorsFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse rep = (HttpServletResponse) response; HttpSession session = req.getSession(); // 设置允许跨域的来源域名 rep.setHeader(\"Access-Control-Allow-Origin\", \"*\"); // 设置允许跨域请求中支持的HTTP请求类型 rep.setHeader(\"Access-Control-Allow-Methods\", \"POST, GET, PUT, OPTIONS, DELETE, PATCH\"); // 设置跨域预检请求的有效期（秒） rep.setHeader(\"Access-Control-Max-Age\", \"3600\"); // 设置允许跨域的请求头字段 rep.setHeader(\"Access-Control-Allow-Headers\", \"token, Origin, X-Requested-With, Content-Type, Accept\"); // 设置允许将本站域名下的Cookie信息携带至跨域服务器 rep.setHeader(\"Access-Control-Allow-Credentials\", \"true\"); // 将获取到的SessionId通过Cookie返回给前端 // rep.addCookie(new Cookie(\"JSSESIONID\", session.getId())); chain.doFilter(req, rep); } @Override public void init(FilterConfig arg0) throws ServletException { } @Override public void destroy() { }} SpringBoot 配置跨域 特别注意：上述介绍的 Spring 使用注解、拦截器、过滤器控制跨域的方式，同样适用于 SpringBoot 项目 SpringBoot 1.5 版本在 SpringBoot 1.5 版本里，可以继承 WebMvcConfigurerAdapter 类并实现 addCorsMappings() 抽象方法 1234567891011@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\"/**\").allowedHeaders(\"*\") .allowedMethods(\"*\") .allowedOrigins(\"*\") .allowCredentials(true); }} SpringBoot 2.0 版本在 SpringBoot 2.0 版本里，可以实现 WebMvcConfigurer 接口并实现 addCorsMappings() 方法 1234567891011121314151617import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@Configurationpublic class WebMvcConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\"/**\") .allowedHeaders(\"Content-Type\", \"X-Requested-With\", \"Accept,Origin\", \"Access-Control-Request-Method\", \"Access-Control-Request-Headers\", \"token\") .allowedMethods(\"*\") .allowedOrigins(\"*\") .allowCredentials(true); }} Gateway 配置跨域由于 Spring Cloud Gateway 是基于 WebFlux 开发的，因此上述配置跨域的方式都不适用于 Gateway，具体可参考以下配置类： 12345678910111213141516171819202122232425import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.reactive.CorsWebFilter;import org.springframework.web.cors.reactive.UrlBasedCorsConfigurationSource;@Configurationpublic class CorsConfig { @Bean public CorsWebFilter corsWebFilter() { UrlBasedCorsConfigurationSource corsSource = new UrlBasedCorsConfigurationSource(); // 配置跨域 CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.addAllowedOrigin(\"http://127.0.0.1:8080\"); corsConfiguration.addAllowedHeader(\"*\"); corsConfiguration.addAllowedMethod(\"*\"); corsConfiguration.setAllowCredentials(true); corsSource.registerCorsConfiguration(\"/**\", corsConfiguration); return new CorsWebFilter(corsSource); }} 提示 1、如果 AllowCredentials 设置为 false，则 AllowedOrigin 可以指定为 *，表示所有来源的请求都允许跨域 2、如果 AllowCredentials 设置为 true，则 AllowedOrigin 不能指定为 *，必须明确指定哪些来源的请求允许跨域 扩展说明Nginx 配置跨域 Nginx 配置跨域 Access-Control-Max-Age 参数浏览器的同源策略，就是出于安全考虑，浏览器会限制从脚本发起的跨域 HTTP 请求（比如异步请求 GET、POST、PUT、DELETE、OPTIONS 等等），所以浏览器会向所请求的服务器发起两次请求；第一次是浏览器使用 OPTIONS 方法发起一个预检请求，第二次才是真正的请求；第一次的预检请求获知服务器是否允许该跨域请求：如果允许，才发起第二次真实的请求；如果不允许，则拦截第二次请求。Access-Control-Max-Age:3600（单位为秒，有效期为 1 小时）表示该预检请求在客户端 1 小时后过期，即 1 小时内发送普通请求就不会再伴随着发送预检请求，这样可以减少对服务器的压力，但是时间也不宜设置太大，尤其是项目频繁发布版本的阶段，同时又修改了 Cors 配置的场景。 resp.addHeader(\"Access-Control-Max-Age\", \"0\")：表示每次请求都发起预检请求，也就是说每次都发送两次请求 resp.addHeader(\"Access-Control-Max-Age\", \"1800\")：表示每隔 30 分钟才发起一次预检请求 Access-Control-Allow-Credentials 参数如果服务器端设置了 Access-Control-Allow-Credentials: true，同时服务器端还设置了 Access-Control-Allow-Origin: *，那就意味将 Cookie 暴露给了所有的网站。举个例子，假设当前是 A 网站，并且在 Cookie 里写入了身份凭证，用户同时打开了 B 网站，那么 B 网站给 A 网站的服务器发的所有请求都是以 A 用户的身份进行的，这将导致 CSRF 系统安全问题。 常见问题@CrossOrigin 注解不生效 1.Spring 的版本要在 4.2 或以上版本才支持 @CrossOrigin 注解 2. 并非 @CrossOrigin 没有解决跨域的问题，而是不正确的请求导致无法得到预期的响应，最终使浏览器端提示跨域错误，此时建议检查 HTTP 请求的响应状态码 3. 在 Controller 类上方添加 @CrossOrigin 注解后，仍然出现跨域问题，解决方案之一就是在方法上的 @RequestMapping 注解中指定 GET、POST 等方式，示例代码如下： 123456789@CrossOrigin@RestControllerpublic class AccountController { @RequestMapping(method = RequestMethod.GET) public String add() { }} 注解方式与过滤器方式的适用场景过滤器 / 拦截器方式适合于大范围的跨域控制，比如某个 Controller 类的所有方法全部支持某个或几个具体的域名跨域访问的场景。而注解方式的优势在于细粒度的跨域控制，比如一个 Controller 类中 methodA 支持域名 originA 跨域访问，methodB 支持域名 originB 跨域访问的情况，当然过滤器 / 拦截器方式也能实现，但使用注解的方式能轻松很多，尤其是上述情况比较多的场景。值得一提的是，@CrossOrigin 注解的底层代码并不是基于拦截器或者过滤器来实现的。 参考博客 Spring 官方文档 @CrossOrigin 注解解决跨域问题 CORS 与 @CrossOrigin 注解底层实现详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Centos7 安装 Edge 浏览器","url":"/posts/350db602.html","text":"下载在 Edge 的 官网，手动下载最新版的 RPM 安装包，或者使用以下命令进行下载： 1$ wget https://packages.microsoft.com/yumrepos/edge/microsoft-edge-dev-101.0.1193.0-1.x86_64.rpm 安装依赖1# yum install libatomic 提示 若不提前安装 libatomic 库，则安装 Edge 时会出现以下错误信息。 123错误：依赖检测失败： libatomic.so.1()(64bit) 被 microsoft-edge-dev-101.0.1193.0-1.x86_64 需要 libatomic.so.1(LIBATOMIC_1.0)(64bit) 被 microsoft-edge-dev-101.0.1193.0-1.x86_64 需要 安装 Edge 浏览器1# rpm -ivh microsoft-edge-dev-101.0.1193.0-1.x86_64.rpm var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"centos"},{"title":"Hexo 博客导流微信公众号","url":"/posts/c86372a2.html","text":"前言Hexo 博客建议安装 hexo-readmore 插件，将 TechGrow 的免费微信公众号导流工具整合到博客中，用户扫码关注微信公众号后可以解锁全站文章，让微信公众号的粉丝数躺着增长。 提示 TechGrow 开放平台的 官方文档 特色功能 兼容主流的 Hexo 主题 支持随机为博客添加引流功能 支持关闭某篇文章的引流功能 支持查询用户解锁文章的历史记录 支持自定义或者动态计算文章内容的预览高度 支持自定义 CSS 样式，轻松适配不同风格的博客 支持开放 API，灵活接入第三方私有化部署的应用服务 注册博客浏览器访问 TechGrow 的官网 ，注册并登录账号后，进入博客的后台管理页面。首先点击左侧的菜单 博客注册，然后点击 新增 按钮，添加自己博客的信息。博客注册成功后，记录下 博客 ID，后面的步骤会使用到 设置公众号在微信公众号的后台管理页面，菜单栏里选择 自动回复 - 关键词回复，启用 自动回复，然后点击 添加回复 按钮： 填写 规则名称、关键词（当初你在 TechGrow 中设置的）、回复内容 选择 文字，然后 回复文字 的内容填写获取博客解锁验证码的链接，如下所示（请自行更改 xxxxx-xxxxxxxxx-xxx 为你申请到的博客 ID） 1&lt;a href=\"https://open.techgrow.cn/#/readmore/captcha/generate?blogId=xxxxx-xxxxxxxxx-xxx\"&gt;点击链接，获取博客解锁验证码&lt;/a&gt; 此时，当读者关注你的微信公众号，并输入关键词后（比如我设置的关键词就是 tech），那么读者就会自动接收到获取博客解锁验证码的链接 安装插件 运行 npm install 命令安装插件到本地项目 1$ npm install hexo-readmore --save 配置 Hexo编辑 Hexo 自身的 _config.yml 配置文件，新增插件的配置信息（请自行更改博客相关的信息），如下所示： 123456789101112131415161718192021222324252627readmore: # 是否启用 enable: true # 已申请的博客 ID blogId: '18762-1609305354821-257' # 已申请的微信公众号名称 name: '全栈技术驿站' # 已申请的微信公众号回复关键词 keyword: 'tech' # 已申请的微信公众号二维码图片 qrcode: 'https://www.techgrow.cn/img/wx_mp_qr.png' # 自定义的 JS 资源链接，可用于 CDN 加速 libUrl: 'https://qiniu.techgrow.cn/readmore/dist/readmore.js' # 自定义的 CSS 资源链接，可用于适配不同风格的博客 cssUrl: 'https://qiniu.techgrow.cn/readmore/dist/hexo.css' # 文章内容的预览高度（例如 300） height: 'auto' # 文章解锁后凭证的有效天数 expires: 365 # 定时校验凭证有效性的时间间隔（秒） interval: 60 # 移动端的页面是否添加微信公众号引流工具 allowMobile: false # Pjax 支持重载的 Css 类（例如 'pjax'），在博客启用了 Pjax 的情况下才需要根据不同的主题进行配置 pjaxCssClass: '' # 每篇文章随机添加微信公众号引流工具的概率，有效范围在 0.1 ~ 1 之间，1 则表示所有文章默认都自动添加引流工具 random: 1 或者打开 TechGrow 的博客后台管理页面，点击博客列表中右侧的 使用 链接，将窗口里的 YAML 配置内容复制到 Hexo 自身的 _config.yml 配置文件即可 参数说明 参数 类型 必填 默认值 说明 enable Boolean 是 false - blogId String 是 - name String 是 - keyword String 是 - qrcode String 是 - libUrl String 否 https://qiniu.techgrow.cn/readmore/dist/readmore.js - cssUrl String 否 https://qiniu.techgrow.cn/readmore/dist/hexo.css - height String / Number 否 auto - expires Number 否 365 - interval Number 否 60 - allowMobile Boolean 否 false - pjaxCssClass String 否 - random Number 否 1 - 构建 Hexo 运行 hexo clean 命令清理本地博客 1$ hexo clean 运行 hexo generate 命令构建本地博客 1$ hexo generate 运行 hexo server 命令启动本地博客服务 1$ hexo server 验证插件效果打开文章页面，若文章自动隐藏了部分内容，并且出现了 阅读全文 按钮，则说明导流插件正常运行，如下图所示： 点击 阅读全文 按钮，会弹出微信公众号的二维码窗口，如下图所示： 取消阅读限制若希望关闭某篇文章的微信公众号导流功能，可以在文章的头模板中使用 readmore: false 配置属性（优先级最高），如下所示： 12345678---title: Hexo版本升级教程tags: [Hexo]readmore: falsekeywords: [Hexo, 版本升级]date: 2022-01-12 22:25:49updated: 2022-01-12 22:25:49--- Pjax 的支持如果博客启用了 Pjax，那么 Hexo 引流插件需要配置 pjaxCssClass 参数，否则在站点内通过链接访问文章页面时，引流插件不会生效，除非是手动刷新一次页面。值得一提的是，pjaxCssClass 参数的作用是让 Pjax 重载引流插件的代码段，它需要根据不同的 Hexo 主题来配置，其中不同主题的配置示例如下： 主题 插件配置 备注 NexT pjaxCssClass: 'pjax' Butterfly pjaxCssClass: 'js-pjax' 自定义样式插件默认使用了定义在 hexo.css 的 CSS 样式，你可以使用以下两种方式自定义自己的样式： 第一种方式：更改博客主题的 CSS 源码文件，将自定义的那部分 CSS 样式添加到里面 第二种方式：根据 hexo.css 创建自己的 CSS 文件（完整的），并将其存放在自己的博客里，同时通过插件的 cssUrl 配置参数来指定其访问的 URL 路径 开放 API若不希望依赖 TechGrow 官方提供的系统服务，可以选择使用开放 API 的方式，让引流插件直接使用私有化部署的后端应用服务，详细介绍请看 这里。 已兼容的主题 主题 GitHub 仓库 NexT https://github.com/next-theme/hexo-theme-next Yilia https://github.com/litten/hexo-theme-yilia Icarus https://github.com/ppoffice/hexo-theme-icarus Matery https://github.com/blinkfox/hexo-theme-matery Fluid https://github.com/fluid-dev/hexo-theme-fluid Stun https://github.com/liuyib/hexo-theme-stun Butterfly https://github.com/jerryc127/hexo-theme-butterfly 在线演示 官方博客 官方微信群","tags":"静态博客"},{"title":"博客导流微信公众号","url":"/posts/48b470db.html","text":"前言博客将流量导向微信公众号很简单，可以使用 TechGrow 的免费导流工具实现，用户扫码关注微信公众号后可以解锁全站文章，让微信公众号的粉丝数躺着增长。整个过程只需六步就可以搞定，适用于各类主流的博客，本文以 Hexo 的 NexT 主题博客举例。 提示 TechGrow 开放平台的 官方文档 若使用的是 Hexo 静态博客，建议直接安装 hexo-readmore 插件，详细教程可点击这里 若使用的是 VuePress v1 静态博客，建议直接安装 vuepress-plugin-readmore-popular 插件，详细教程可点击这里 若使用的是 VuePress v2 静态博客，建议直接安装 vuepress-plugin-readmore-popular-next 插件，详细教程可点击这里 特色功能 兼容主流的博客框架 支持随机为博客添加引流功能 支持查询用户解锁文章的历史记录 支持自定义或者动态计算文章内容的预览高度 支持自定义 CSS 样式，轻松适配不同风格的博客 支持开放 API，灵活接入第三方私有化部署的应用服务 第一步：注册博客浏览器访问 TechGrow 的官网 ，注册并登录账号后，进入博客的后台管理页面。首先点击左侧的菜单 博客注册，然后点击 新增 按钮，添加自己博客的信息。博客注册成功后，记录下 博客 ID，后面的步骤会使用到 第二步：设置公众号在微信公众号的后台管理页面，菜单栏里选择 自动回复 - 关键词回复，启用 自动回复，然后点击 添加回复 按钮： 填写 规则名称、关键词（当初你在 TechGrow 中设置的）、回复内容 选择 文字，然后 回复文字 的内容填写获取博客解锁验证码的链接，如下所示（请自行更改 xxxxx-xxxxxxxxx-xxx 为你申请到的博客 ID） 1&lt;a href=\"https://open.techgrow.cn/#/readmore/captcha/generate?blogId=xxxxx-xxxxxxxxx-xxx\"&gt;点击链接，获取博客解锁验证码&lt;/a&gt; 此时，当读者关注你的微信公众号，并输入关键词后（比如我设置的关键词就是 tech），那么读者就会自动接收到获取博客解锁验证码的链接 第三步：定位文章主体的标签元素在 Hexo 博客的 themes 目录下，找到你正在使用的主题目录，比如：next 等，具体根据你选择的主题来判断。进入主题源码的 layout 目录，找到 _macro/post.njk 模板文件，若这里有一大段与文章主体内容相关的 HTML 代码，那就说明文章主体标签元素的模板定义就在这里，示例模板代码如下： 123456789101112131415161718&lt;div class=\"post-block\"&gt; {# Gallery support #} {{ post_gallery(post.photos) }} &lt;!-- 文章主体的标签元素 --&gt; &lt;article itemscope itemtype=\"http://schema.org/Article\" class=\"post-content\" lang=\"{{ post.lang }}\"&gt; &lt;link itemprop=\"mainEntityOfPage\" href=\"{{ post.permalink }}\"&gt; &lt;span hidden itemprop=\"author\" itemscope itemtype=\"http://schema.org/Person\"&gt; &lt;meta itemprop=\"image\" content=\"{{ url_for(theme.avatar.url or theme.images + '/avatar.gif') }}\"&gt; &lt;meta itemprop=\"name\" content=\"{{ author }}\"&gt; &lt;meta itemprop=\"description\" content=\"{{ description }}\"&gt; &lt;/span&gt; ...（省略） &lt;/article&gt;&lt;/div&gt; 另一种定位方式是打开你博客的任意一篇文章，利用 Chrome 等浏览器的元素审查功能，找到文章页面中文章主体的标签元素，比如下图中的 article 就是文章主体的标签元素： 第四步：新增文章内容 DIV 标签在文章模板文件中找到文章主体的标签元素之后，在其上面包一层 div 标签，并将 div 标签的 id 属性值设置为 readmore-container，即添加的完整 HTML 标签为 &lt;div id=\"readmore-container\"&gt;&lt;/div&gt;，示例模板代码如下： 1234567891011121314151617181920&lt;div class=\"post-block\"&gt; {# Gallery support #} {{ post_gallery(post.photos) }} &lt;!-- 新增的DIV标签 --&gt; &lt;div id=\"readmore-container\"&gt; &lt;article itemscope itemtype=\"http://schema.org/Article\" class=\"post-content\" lang=\"{{ post.lang }}\"&gt; &lt;link itemprop=\"mainEntityOfPage\" href=\"{{ post.permalink }}\"&gt; &lt;span hidden itemprop=\"author\" itemscope itemtype=\"http://schema.org/Person\"&gt; &lt;meta itemprop=\"image\" content=\"{{ url_for(theme.avatar.url or theme.images + '/avatar.gif') }}\"&gt; &lt;meta itemprop=\"name\" content=\"{{ author }}\"&gt; &lt;meta itemprop=\"description\" content=\"{{ description }}\"&gt; &lt;/span&gt; ...（省略） &lt;/article&gt; &lt;/div&gt;&lt;/div&gt; 第五步：新增导流工具的 HTML 代码打开 TechGrow 的博客后台管理页面，点击博客列表中右侧的 使用 链接，将窗口里的 HTML 代码复制到第三步中找到的文章模板文件的末尾，也可以添加到主题的 footer 模板文件中，示例 HTML 代码如下图所示： 参数 必填 默认值 描述 id 是 DIV 标签的 ID blogId 是 已申请的博客 ID name 是 已申请的微信公众号名称 qrcode 是 已申请的微信公众号二维码图片 keyword 是 已申请的微信公众号回复关键词 height 否 auto 文章内容的预览高度（例如 300） expires 否 365 文章解锁后凭证的有效天数 interval 否 60 定时校验凭证有效性的时间间隔（秒） type 否 other 博客类型，包括：hexo、vuepress、vuepress2、hugo、gatsby、jekyll、docsify、typecho、wordpress、website random 否 1 每篇文章随机添加微信公众号引流工具的概率，有效范围在 0.1 ~ 1 之间，1 则表示所有文章默认都自动添加引流工具 第六步：验证导流工具是否整合成功重新构建并运行博客服务后，打开文章页面，若文章自动隐藏了部分内容，并且出现了 阅读全文 按钮，则说明导流工具整合成功，如下图所示： 点击 阅读全文 按钮，会弹出微信公众号的二维码窗口，如下图所示： 使用总结 博客整合引流工具，其本质原理就是先在博客的主题源码里，找到文章的主体内容，然后在其外面包裹一层 DIV 标签（&lt;div id=\"readmore-container\"&gt;&lt;/div&gt;），最后再将引流工具的 HTML 代码添加到博客文章的末尾即可。 自定义样式引流工具默认使用了定义在 readmore.css 的 CSS 样式，你可以使用以下两种方式自定义自己的样式： 第一种方式：更改博客主题的 CSS 源码文件，将自定义的那部分 CSS 样式添加到里面 第二种方式：根据 readmore.css 创建自己的 CSS 文件（完整的），并将其存放在自己的博客里，同时通过引流工具的 cssUrl 配置参数来指定其访问的 URL 路径 开放 API若不希望依赖 TechGrow 官方提供的系统服务，可以选择使用开放 API 的方式，让引流插件直接使用私有化部署的后端应用服务，详细介绍请看 这里。 常见问题问题一 博客整合引流工具后，浏览器的控制台输出警告或者错误信息，且引流工具无法生效 浏览器访问博客后，按下 F12 快捷键调出调试工具，然后切换到 控制台，最后将警告或者错误信息截图，并发送到 官方微信群 或者 656418510@qq.com 邮箱，建议留言备注博客与博客主题的类型。 问题二 博客整合引流工具后，移动端的引流工具无法生效，而 PC 端却生效 考虑到用户体验的问题，在移动端默认是关闭引流功能的，请知悉。 在线演示 官方博客 官方微信群","tags":"静态博客"},{"title":"Vue 页面高亮显示代码块","url":"/posts/5cf75f16.html","text":"前言Vue 页面可以基于 vue-prism-editor 实现高亮显示代码块，支持 Vue 2.x 和 Vue 3.x。 提示 vue-prism-editor 要求 Vue 的版本高于 2.6.11 若 Vue 的版本为 3.x，则需要使用 vue-prism-editor 的 feature/next 分支代码 安装模块1$ npm install vue-prism-editor --save 由于 vue-prism-editor 依赖了 prismjs，所以还需要安装 prismjs 1$ npm install prismjs --save Vue 代码在 Vue 页面中引入 vue-prism-editor 组件，完整的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;template&gt; &lt;prism-editor class=\"my-editor height-300\" v-model=\"code\" :highlight=\"highlighter\" readonly line-numbers&gt;&lt;/prism-editor&gt;&lt;/template&gt;&lt;script&gt; // import Prism Editor import { PrismEditor } from 'vue-prism-editor' import 'vue-prism-editor/dist/prismeditor.min.css' // import highlighting library import { highlight, languages } from 'prismjs/components/prism-core' import 'prismjs/components/prism-clike' import 'prismjs/components/prism-javascript' import 'prismjs/themes/prism-tomorrow.css' export default { components: { PrismEditor }, data: () =&gt; ({ code: 'console.log(\"Hello World\")' }), methods: { highlighter (code) { return highlight(code, languages.js) } } }&lt;/script&gt;&lt;style&gt; /* required class */ .my-editor { /* we dont use `language-` classes anymore so thats why we need to add background and text color manually */ background: #2d2d2d; color: #ccc; /* you must provide font-family font-size line-height. Example: */ font-family: Fira code, Fira Mono, Consolas, Menlo, Courier, monospace; font-size: 14px; line-height: 1.5; padding: 5px; } /* optional class for removing the outline */ .prism-editor__textarea:focus { outline: none; } /* not required: */ .height-300 { height: 300px; }&lt;/style&gt; 提示 highlighter：定义在 methods 中的一个方法，用于将代码高亮显示 readonly：代码块是否只读（不可编辑） code：需要高亮显示的代码内容 lineNumbers：是否显示行号 演示效果 常见问题问题一如果安装 NPM 模块失败，且错误信息中有提示升级 vue@^2.6.11 版本，则根据提示升级 Vue 的版本即可： 1$ npm install vue@^2.6.11 问题二vue 与 vue-template-compiler 的版本不一致，导致 Vue 项目编译失败 首先卸载低版本的 vue-template-compiler 1$ npm uninstall vue-template-compiler 然后安装跟 vue 相同版本的 vue-template-compiler 1$ npm install vue-template-compiler@2.6.11 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"Vue 页面读取并展示 Markdown 文件","url":"/posts/df920f01.html","text":"前言如何在 Vue 中读取项目本地的 MarkDown 文件并展示在网页上呢？查阅资料后发现，一般的方案是在 Vue 页面中引入 Markdown 编辑器，然后利用编辑器的预览功能来展示 MarkDown 文件的内容。推荐使用开源的 MarkDown 编辑器 mavonEditor 或者 vue-meditor。 vue-meditor 介绍简介提示 vue-meditor 官方文档 vue-meditor Github 仓库 vue-markdown 是一款使用 marked 和 highlight.js 开发的一款 MarkDown 编辑器，主要包括三个部分： 简单版编辑器，左侧文本输入框使用 textarea 实现 专业版编辑器，左侧输入框使用 codemirror 实现 MarkDown 预览组件，可单独使用 显示效果图 vue-meditor 使用使用 NPM 安装1$ npm i -S vue-meditor 在项目中引入组件在 Vue 页面中引入 vue-meditor 的预览组件 MarkdownPreview，完整示例代码如下，编辑器的完整基本属性可查阅 官方文档 1234567891011121314151617181920212223242526272829303132333435&lt;template&gt; &lt;div class=\"markdown\"&gt; &lt;MarkdownPreview v-model=\"content\" :height=\"1024\" :isPreview=true :bordered=false :copyCode=true theme=\"oneDark\" /&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import MarkdownPreview from 'vue-meditor' export default { name: 'markdown', data () { return { content: '' } }, components: { MarkdownPreview }, created () { // 读取本地的Markdown文件 this.$http.get('/static/guide/start.md').then((response) =&gt; { if (response.data) { this.content = response.data } }) } }&lt;/script&gt; 值得一提的是，/static/guide/start.md 是 Vue 项目根目录下 MarkDown 文件的路径，上面的代码通过 HTTP 请求去读取 Markdown 文件，这样的优势是可以实时预览 MarDown 文件的内容。 最终实现的效果图 参考资料 Vue 使用 MarkDown Vue 读取本地 MarkDown 文件 Vue 读取展示 MarkDown 文件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"CTP 开发随笔","url":"/posts/790d6d80.html","text":"API 版本升级提示 CTP API 版本说明 CTP API 各版本官方下载 下面将以 v6.3.15 版本升级到 v6.6.1_P1 版本举例，同样适用于将 v6.3.19_P1 版本升级到 v6.6.1_P1 第一步从官网下载 v6.6.1_P1_20210406 版本的 API，然后解压并将 .h 头文件和 .DLL 文件拷贝到 C/C++ 项目里；也就是说，将原有的 API 文件替换掉即可。 第二步v6.6.1_P1 相比 v6.3.15，其中一个不同的地方，就是函数里的结构体名称更改了。因此需要在 IDE 里全局将 CThostFtdcQueryMaxOrderVolumeField 替换为 CThostFtdcQryMaxOrderVolumeField，同时将 ReqQueryMaxOrderVolume 替换为 ReqQryMaxOrderVolume。 第三步由于 v6.6.1_P1 版本新增了一些函数，若项目的代码是基于官方的 Demo 进行二次开发的，那么则需要在下述的 C++ 源文件末尾追加以下代码： traderApi.h 1234567891011///请求查询分类合约virtual int ReqQryClassifiedInstrument(CThostFtdcQryClassifiedInstrumentField *pQryClassifiedInstrument, int nRequestID);///请求组合优惠比例virtual int ReqQryCombPromotionParam(CThostFtdcQryCombPromotionParamField *pQryCombPromotionParam, int nRequestID);///投资者风险结算持仓查询virtual int ReqQryRiskSettleInvstPosition(CThostFtdcQryRiskSettleInvstPositionField *pQryRiskSettleInvstPosition, int nRequestID);///风险结算产品查询virtual int ReqQryRiskSettleProductStatus(CThostFtdcQryRiskSettleProductStatusField *pQryRiskSettleProductStatus, int nRequestID); traderApi.cpp 123456789101112131415int CTraderApi::ReqQryClassifiedInstrument(CThostFtdcQryClassifiedInstrumentField *pQryClassifiedInstrument, int nRequestID) {};int CTraderApi::ReqQryCombPromotionParam(CThostFtdcQryCombPromotionParamField *pQryCombPromotionParam, int nRequestID) {};int CTraderApi::ReqQryRiskSettleInvstPosition(CThostFtdcQryRiskSettleInvstPositionField *pQryRiskSettleInvstPosition, int nRequestID) {};int CTraderApi::ReqQryRiskSettleProductStatus(CThostFtdcQryRiskSettleProductStatusField *pQryRiskSettleProductStatus, int nRequestID) {}; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发随笔 量化交易"},{"title":"初探最流行的前端低代码平台","url":"/posts/65ee20c1.html","text":"前言在 2022 年，“低代码” 成了热门的话题，各大云厂商都在这个领域发力。那么作为普通的企业，是否也可以深度定制一套自己的 “低代码” 平台呢？ 云厂商的低代码平台阿里云阿里云推出了易搭，通过简单的拖拽、配置，即可完成业务应用的搭建。旨在为广大中小企业提供一套低成本的企业应用搭建解决方案。应用无缝植入钉钉企业工作台，随时随地、高效协同。 腾讯云腾讯云则是推出了微搭，通过行业化模板、拖放式组件和可视化配置快速构建多端应用（小程序、H5 应用、Web 应用等），打通了小程序、云函数。 开源的低代码平台基础平台amis提示 amis GitHub 仓库 amis 官方中文文档 amis 是一个低代码前端框架，它使用 JSON 配置来生成页面，可以减少页面开发工作量，极大提升效率，由百度团队开源。 用 JSON 写页面的好处 为了实现用最简单方式来生成大部分页面，amis 的解决方案是基于 JSON 来配置，它的独特好处是： 不需要懂前端：在百度内部，大部分 amis 用户之前从来没写过前端页面，也不会 JavaScript，却能做出专业且复杂的后台界面，这是所有其他前端 UI 库都无法做到的； 不受前端技术更新的影响：百度内部最老的 amis 页面是 6 年多前创建的，至今还在使用，而当年的 Angular/Vue/React 版本现在都废弃了，当年流行的 Gulp 也被 Webpack 取代了，如果这些页面不是用 amis，现在的维护成本会很高； 享受 amis 的不断升级：amis 一直在提升细节交互体验，比如表格首行冻结、下拉框大数据下不卡顿等，之前的 JSON 配置完全不需要修改； 可以完全使用 可视化页面编辑器 来制作页面；一般前端可视化编辑器只能用来做静态原型，而 amis 可视化编辑器做出的页面是可以直接上线的。 amis 的其它亮点 提供完整的界面解决方案：其它 UI 框架必须使用 JavaScript 来组装业务逻辑，而 amis 只需 JSON 配置就能完成完整功能开发，包括数据获取、表单提交及验证等功能，做出来的页面不需要经过二次开发就能直接上线； 大量内置组件（120+），一站式解决：其它 UI 框架大部分都只有最通用的组件，如果遇到一些稍微不常用的组件就得自己找第三方，而这些第三方组件往往在展现和交互上不一致，整合起来效果不好，而 amis 则内置大量组件，包括了富文本编辑器、代码编辑器、diff、条件组合、实时日志等业务组件，绝大部分中后台页面开发只需要了解 amis 就足够了； 支持扩展：除了低代码模式，还可以通过 自定义组件 来扩充组件，实际上 amis 可以当成普通 UI 库来使用，实现 90% 低代码，10% 代码开发的混合模式，既提升了效率，又不失灵活性； 容器支持无限级嵌套：可以通过嵌套来满足各种布局及展现需求； 经历了长时间的实战考验：amis 在百度内部得到了广泛使用，在 6 年多的时间里创建了 5 万页面，从内容审核到机器管理，从数据分析到模型训练，amis 满足了各种各样的页面需求，最复杂的页面有超过 1 万行 JSON 配置。 amis 不适合做什么 使用 JSON 有优点但也有明显缺点，在以下场合并不适合 amis： 大量定制 UI：JSON 配置使得 amis 更适合做有大量常见 UI 组件的页面，但对于面向普通客户（toC）的页面，往往追求个性化的视觉效果，这种情况下用 amis 就不合适，实际上绝大部分前端 UI 组件库也都不适合，只能定制开发。 极为复杂或特殊的交互： 有些复杂的前端功能，比如 可视化编辑器，其中有大量定制的拖拽操作，这种需要依赖原生 DOM 实现的功能无法使用 amis。 但对于某些交互固定的领域，比如图连线，amis 后续会有专门的组件来实现。 mometa提示 mometa GitHub 仓库 mometa 是一款面向研发的低代码元编程，代码可视编辑，辅助编码工具。 背景 mometa 不是传统主流的低代码平台（如 amis / 云凤蝶），mometa 是面向研发的、代码可视设计编辑平台，它更像是 dreamweaver、gui 可视编辑之于程序员。 特性 面向研发的代码可视化编辑，直接作用于源码 响应式布局、路由模拟、物料预览 反向定位（视图定位源码） 拖拽插入物料 拖拽移动 上下移动 删除 替换 层级选择 接入友好，Webpack&gt;=4 插件化接入 开发友好，物料库支持热更新，不破坏已有开发模式 开放物料生态，可定制团队内物料库，见 mometa-mat 多语言、多生态支持，目前暂只支持 React，后续有计划支持 Vue 解决的问题 对低代码平台不形成依赖，二次开发可以无缝进入代码开发模式 同时支持所见即所得的可视编辑，用于提效，提升开发体验 提供物料生态，可自定义物料，提升物料使用体验，提升复用率 mometa 定位更多是基于程序员本地开发的模式，新增了可视化编码的能力（修改的也是本地的代码文件本身）。它更像是辅助编码工具，而不是 No-Code (amis / 云凤蝶) 的平台方案。 Sortable提示 Sortable GitHub 仓库 Sortable 是一个用于可重新排序的拖放列表的 JavaScript 库，可实现适用于现代浏览器和触摸设备的可重新排序的拖放列表，不需要依赖 jQuery 或框架。 H5 开发H5-Dooring提示 H5-Dooring GitHub 仓库 H5-Dooring 官方 Wiki H5-Dooring 是一款功能强大，专业可靠的 H5 可视化页面配置解决方案，致力于提供一套简单方便、专业可靠、无限可能的 H5 落地页最佳实践。技术栈以 React 和 Typescript 为主， 后台采用 Nodejs 开发，正在探索 h5-lowcode 解决方案。 luban-h5提示 luban-h5 GitHub 仓库 luban-h5 官方中文文档 luban-h5 在线 Demo 演示 鲁班 H5 是基于 Vue2.0 开发，通过拖拽快速生成页面的平台，类似 易企秀、Maka、百度 H5 等平台。 quark-h5提示 quark-h5 GitHub 仓库 quark-h5 是一款基于 Vue2 + Koa2 的 H5 页面可视化制作工具，让不会写代码的人也能轻松快速上手制作 H5 页面。类似易企秀、百度 H5 等 H5 制作、建站工具。 其他开源项目 h5-factory：H5 页面制作，移动端专题活动页面可视化编辑 lz-h5-edit：随心秀（React 版 H5 微场景编辑器)，一款类似易企秀、兔展的 H5 微场景编辑器 vite-vue3-lowcode：移动端低代码平台，实现了可视化拖拽、可视化编辑器，类似易企秀的 H5 制作、建站工具、可视化搭建工具； 参考博客 云凤蝶低代码之路 搭建自己的低代码平台 云凤蝶可视化搭建的推导与实现 Vue + Koa 从零打造一个 H5 页面可视化编辑器 - quark-h5 基于 Koa2 打造属于自己的 MVC 框架，仿 Egg 的简易版本 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"Markdown 转换微信公众号文章内容","url":"/posts/1c073f45.html","text":"前言使用微信公众号编辑器有一个十分头疼的问题 —— 粘贴出来的代码，格式错乱，而且特别丑。markdown-weixin 是一款让 Markdown 转微信公众号内容的神器，能让 Markdown 内容，无需作任何调整就能一键复制到微信公众号使用，而且特别针对代码展示做了优化。 项目构建1234567891011121314# 拉取源代码$ git clone https://github.com/rqh656418510/markdown-weixin.git# 进入源代码目录$ cd markdown-weixin# 安装依赖$ npm install# 构建项目$ npm run build# 查看构建生成的文件（docs目录可直接部署到Web服务器）$ ls -al docs 演示效果 使用 Docker12345# 构建镜像# docker build -f Dockerfile -t clay/markdown-weixin:latest .# 启动容器# docker run -d -p 8080:80 clay/markdown-weixin:latest Docker 容器运行起来之后，打开浏览器访问 http://127.0.0.1:8080 即可，完整的 Dockerfile（基于 Debian 9 + Tengine） 如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879FROM node:14-stretchMAINTAINER clay&lt;clay@gmail.com&gt;# 创建用户RUN groupadd tengine &amp;&amp; useradd -g tengine tengine# 更换软件源RUN cp /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo \"deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib\" &gt; /etc/apt/sources.list &amp;&amp; \\ echo \"deb http://mirrors.aliyun.com/debian-security stretch/updates main\" &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ echo \"deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ echo \"deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.list# 安装依赖RUN apt-get -y update &amp;&amp; apt-get -y upgrade &amp;&amp; \\ apt-get -y install vim tree htop apt-utils net-tools telnet wget curl &amp;&amp; \\ apt-get -y install autoconf git build-essential libpcre3 libpcre3-dev zlib1g zlib1g.dev openssl libssl-dev &amp;&amp; \\ apt-get -y autoclean &amp;&amp; apt-get -y autoremove# 定义Tengine的版本号ENV VERSION 2.2.3# 下载并解压文件RUN mkdir -p /usr/local/src/ADD http://tengine.taobao.org/download/tengine-$VERSION.tar.gz /usr/local/srcRUN tar -xvf /usr/local/src/tengine-$VERSION.tar.gz -C /usr/local/src/# 创建安装目录ENV TENGINE_HOME /usr/local/tengineRUN mkdir -p $TENGINE_HOME# 进入解压目录WORKDIR /usr/local/src/tengine-$VERSION# 编译安装RUN ./configure \\ --user=tengine \\ --group=tengine \\ --prefix=$TENGINE_HOME \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_concat_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_upstream_consistent_hash_module \\ &amp;&amp; make \\ &amp;&amp; make install# 设置环境变量ENV PATH $PATH:$TENGINE_HOME/sbin# 定义APP目录ENV APP_HOME $TENGINE_HOME/html# 编译APP项目RUN mkdir -p /tmp/markdown-weixin \\ &amp;&amp; git clone https://github.com/rqh656418510/markdown-weixin /tmp/markdown-weixin \\ &amp;&amp; cd /tmp/markdown-weixin \\ &amp;&amp; npm config set registry https://registry.npm.taobao.org \\ &amp;&amp; npm install \\ &amp;&amp; npm run build# 拷贝APP项目编译后的文件RUN mkdir -p $APP_HOME \\ &amp;&amp; rm -rf $APP_HOME/* \\ &amp;&amp; cp -R -rf /tmp/markdown-weixin/docs/* $APP_HOME# 清理文件RUN rm -rf /usr/local/src &amp;&amp; rm -rf /tmp/markdown-weixin# 设置默认工作目录WORKDIR $APP_HOME# 暴露端口EXPOSE 80EXPOSE 443CMD $TENGINE_HOME/sbin/nginx -g 'daemon off;' -c $TENGINE_HOME/conf/nginx.conf var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客 前端"},{"title":"Docker 构建 Frp 镜像","url":"/posts/8285186a.html","text":"前言 Frp 官方文档 Frp GitHub 项目 Frp Docker GitHub 项目 构建 Frps 镜像 Dockerfile 编写 123456789101112131415161718FROM amd64/alpine:3.10LABEL maintainer=\"snowdream &lt;sn0wdr1am@icloud.com&gt;\"ENV FRP_VERSION 0.38.0RUN cd /root \\ &amp;&amp; wget --no-check-certificate -c https://github.com/fatedier/frp/releases/download/v${FRP_VERSION}/frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; tar zxvf frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; cd frp_${FRP_VERSION}_linux_amd64/ \\ &amp;&amp; cp frps /usr/bin/ \\ &amp;&amp; mkdir -p /etc/frp \\ &amp;&amp; cp frps.ini /etc/frp \\ &amp;&amp; cd /root \\ &amp;&amp; rm frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; rm -rf frp_${FRP_VERSION}_linux_amd64/ ENTRYPOINT /usr/bin/frps -c /etc/frp/frps.ini 构建镜像 1# docker build -f Dockerfile -t clay/frps:0.38.0 . 启动镜像 1# docker run --restart=always --network host -d -v /etc/frp/frps.ini:/etc/frp/frps.ini --name frps clay/frps 查看日志信息 1# docker logs -f --tail 20 frps 构建 Frpc 镜像 Dockerfile 编写 123456789101112131415161718FROM amd64/alpine:3.10LABEL maintainer=\"snowdream &lt;sn0wdr1am@icloud.com&gt;\"ENV FRP_VERSION 0.38.0RUN cd /root \\ &amp;&amp; wget --no-check-certificate -c https://github.com/fatedier/frp/releases/download/v${FRP_VERSION}/frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; tar zxvf frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; cd frp_${FRP_VERSION}_linux_amd64/ \\ &amp;&amp; cp frpc /usr/bin/ \\ &amp;&amp; mkdir -p /etc/frp \\ &amp;&amp; cp frpc.ini /etc/frp \\ &amp;&amp; cd /root \\ &amp;&amp; rm frp_${FRP_VERSION}_linux_amd64.tar.gz \\ &amp;&amp; rm -rf frp_${FRP_VERSION}_linux_amd64/ ENTRYPOINT /usr/bin/frpc -c /etc/frp/frpc.ini 构建镜像 1# docker build -f Dockerfile -t clay/frpc:0.38.0 . 启动镜像 1# docker run --restart=always --network host -d -v /etc/frp/frpc.ini:/etc/frp/frpc.ini --name frpc clay/frpc 查看日志信息 1# docker logs -f --tail 20 frpc var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化"},{"title":"CMake 入门教程之三单元测试","url":"/posts/52f22f9b.html","text":"前言CMake 是一个跨平台的 C/C++ 项目组织管理工具，虽然许多 IDE 都有私有的项目管理工具，但是在现在各大 IDE 基本都支持使用 CMake 管理项目，所以如果有跨平台的需求，使用 CMake 管理是最方便的。值得一提的是，CMake 支持 gtest、cppunit 等单元测试框架，当然也可以使用断言自定义单元测试。 创建简单的带单元测试的项目创建项目工程下载代码 点击下载 完整的案例代码，项目的目录结构如下： 12345678910111213minder-test├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp└── test ├── CMakeLists.txt ├── include │ └── strUtil.h └── src └── main.cpp 编写项目代码 include/datetime.h 1234567891011121314151617181920#pragma once#include &lt;iostream&gt;#include &lt;sstream&gt;using namespace std;// 日期工具类class DateUtil {public: static string formatCurrentTime(); static string formatCurrentTime(string format); static int dayOfWeek(const string &amp;date); static bool isWeekendDays(const string &amp;date);}; src/datetime.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include \"datetime.h\"// 格式化当前时间// 默认格式是: 2020-06-07 23:46:53string DateUtil::formatCurrentTime() { time_t rawtime; struct tm *info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, \"%Y-%m-%d %H:%M:%S\", info); string str(buffer); return str;}// 格式化当前时间// format: 格式字符串，例如 %Y-%m-%d %H:%M:%Sstring DateUtil::formatCurrentTime(string format) { time_t rawtime; struct tm *info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, format.c_str(), info); string str(buffer); return str;}// 根据给定的日期，计算它是星期几// date: 日期字符串，格式是: 2021-12-01// 返回值：1, 2, 3, 4, 5, 6, 0, 其中 0 表示星期日int DateUtil::dayOfWeek(const string &amp;date) { char c; int y, m, d; stringstream(date) &gt;&gt; y &gt;&gt; c &gt;&gt; m &gt;&gt; c &gt;&gt; d; tm t = {0, 0, 0, d, m - 1, y - 1900}; mktime(&amp;t); return t.tm_wday;}// 根据给定的日期，判断是否为周末// date: 日期字符串，格式是: 2021-12-01bool DateUtil::isWeekendDays(const string &amp;date) { int wday = dayOfWeek(date); if (wday == 6 || wday == 0) { return true; } return false;} src/main.cpp 12345678910#include &lt;iostream&gt;#include \"datetime.h\"using namespace std;int main() { cout &lt;&lt; DateUtil::formatCurrentTime() &lt;&lt; endl; cout &lt;&lt; DateUtil::formatCurrentTime(\"%Y-%m-%d\") &lt;&lt; endl; return 0;} test/include/strUtil.h 1234567891011121314#pragma once#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(\" \")); str.erase(str.find_last_not_of(\" \") + 1);} test/src/main.cpp 1234567891011121314151617#include &lt;iostream&gt;#include \"strUtil.h\"#include \"datetime.h\"using namespace std;int main() { // 去除字符串两边的空格 string str = \" Hello World ! \"; trim(str); cout &lt;&lt; str &lt;&lt; endl; // 根据给定的日期，计算它是星期几 cout &lt;&lt; \"wday = \" &lt;&lt; DateUtil::dayOfWeek(\"2022-01-11\") &lt;&lt; \", \"; cout &lt;&lt; \"isWeekendDays = \" &lt;&lt; (DateUtil::isWeekendDays(\"2022-01-11\") ? \"true\" : \"false\") &lt;&lt; endl; return 0;} 其中 test 目录可以视作为子项目，和主目录分开编译。为了模拟更真实的企业项目开发场景，这里的 test/src/main.cpp 同时引入了 datetime.h 和 strUtil.h 头文件。 CMake 配置文件 主目录的 CMakeLists.txt 12345678910111213141516171819202122232425262728293031323334cmake_minimum_required(VERSION 3.15)# 项目信息project(minder)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 输出调试信息set(CMAKE_CXX_FLAGS \"-g\")# 开启所有警告set(CMAKE_CXX_FLAGS \"-Wall\")# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 引入主项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索主项目的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src MAIN_SOURCES)# 指定可执行文件的名称和主项目的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES})# 启用项目测试enable_testing()# 添加子目录（测试项目）add_subdirectory(test)# 添加测试项目的可执行文件add_test(minder_test ${PROJECT_SOURCE_DIR}/test/build/minder_test) 特别说明： set(CMAKE_CXX_FLAGS \"-xxx\")：指定编译参数，细化的还有 CMAKE_CXX_FLAGS_DEBUG 和 CMAKE_CXX_FLAGS_RELEASE add_subdirectory(xxx)：添加子目录（子项目），要求子目录里必须有单独的 CMakeLists.txt，该文件包含了子目录的编译配置信息 add_test(xxx ${PROJECT_SOURCE_DIR}/test/build/xxx)：第一个参数是某个单元测试的名称，第二个参数是该单元测试的可执行文件的路径 test 目录的 CMakeLists.txt 12345678910111213141516171819202122232425262728cmake_minimum_required(VERSION 3.15)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX \"main.cpp\")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES}) 这里的 test 作为子项目，主要要生成单元测试的可执行文件。 命令行编译项目 编译 test 子项目 1234567891011121314151617# 进入子项目的目录$ cd minder-test/test# 创建子项目的构建目录$ mkdir build# 进入子项目的构建目录$ cd build# 构建子项目$ cmake ..# 编译子项目$ make# 运行可执行文件$ ./minder_test 编译主项目 1234567891011121314151617181920# 进入主项目的目录$ cd minder-test# 创建主项目的构建目录$ mkdir build# 进入主项目的构建目录$ cd build# 构建主项目$ cmake ..# 编译主项目$ make# 执行项目测试$ make test# 运行可执行文件$ ./minder CMake 使用 GoogleTest 测试框架相关站点 GoogleTest 官方文档 GoogleTest GitHub 仓库 GoogleTest 官方下载页面 GoogleTest 的安装GoogleTest 编译安装注意事项 GoogleTest 最新版（1.11.0）要求使用 GCC 5.0+ 和 Clang 5.0+，若 GCC 的版本比较低，建议安装 GoogleTest 1.10.0 或者 1.8.1 版本 实测 GCC 4.8.5 可以正常使用 GoogleTest 的 1.10.0 版本，不兼容 1.11.0 版本 1234567891011121314151617181920212223# 下载文件$ wget https://github.com/google/googletest/archive/refs/tags/release-1.11.0.tar.gz# 解压文件$ tar -xvf release-1.11.0.tar.gz# 进入解压目录$ cd googletest-release-1.11.0# 创建构建目录$ mkdir build# 进入构建目录$ cd build# 生成makefile，如果需要构建得到动态链接库，则必须添加参数 \"-DBUILD_SHARED_LIBS=ON\"，否则默认只会得到静态库（.a）$ cmake -DBUILD_SHARED_LIBS=ON -Dgtest_build_samples=ON ..# 编译$ make -j4# 安装$ make install 值得一提的是，安装命令执行完成后，会自动将 libgmock_main.so 、libgmock.so、libgtest_main.so、libgtest.so 库文件拷贝到 /usr/local/lib64/ 目录下。GoogleTest 的头文件则会安装在 /usr/local/include/gmock 和 /usr/local/include/gtest/ 目录。 GoogleTest 验证安装 创建 C++ 源文件 test.cpp 123456789101112131415#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;gtest/gtest.h&gt;TEST( COutputPopLimitStrategyTest, PositiveNos ){ EXPECT_EQ(true, true);}int main( int argc, char *argv[] ){ ::testing::InitGoogleTest( &amp;argc, argv ); return(RUN_ALL_TESTS() );} 使用 G++ 命令编译 C++ 源文件 12345678910111213141516# 编译源文件$ g++ -std=c++11 test.cpp -lpthread /usr/local/lib64/libgtest.so -o test# 运行可执行文件，若输出以下的日志信息，则说明GoogleTest安装成功$ ./test[==========] Running 1 test from 1 test suite.[----------] Global test environment set-up.[----------] 1 test from COutputPopLimitStrategyTest[ RUN ] COutputPopLimitStrategyTest.PositiveNos[ OK ] COutputPopLimitStrategyTest.PositiveNos (0 ms)[----------] 1 test from COutputPopLimitStrategyTest (1 ms total)[----------] Global test environment tear-down[==========] 1 test from 1 test suite ran. (1 ms total)[ PASSED ] 1 test. G++ 编译参数说明： -std=c++11：指定 C++ 的版本 /usr/local/lib64/libgtest.so：链接 GoogleTest 的动态链接库 -lpthread：由于 GoogleTest 的内部使用了多线程，因此需要链接 pthread 库 Google Test 的使用案例创建项目工程下载代码 点击下载 完整的案例代码，项目的目录结构如下： 12345678910111213minder-gtest├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp└── test ├── CMakeLists.txt ├── include │ └── strUtil.h └── src └── main.cpp 编写项目代码下载代码 这里的 C++ 代码，除了 main.cpp 的代码不一样之外，其他代码与上面的案例代码完全一致，不再累述。 1234567891011121314151617181920212223#include &lt;iostream&gt;#include \"strUtil.h\"#include \"datetime.h\"#include &lt;gtest/gtest.h&gt;using namespace std;// 去除字符串两边的空格TEST(TestCase, test1) { string str = \" Hello World ! \"; trim(str); ASSERT_EQ(\"Hello World !\", str);}// 根据给定的日期，计算它是星期几TEST(TestCase, test2) { ASSERT_EQ(true, DateUtil::isWeekendDays(\"2022-01-09\"));}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} CMake 配置文件 主目录的 CMakeLists.txt，这里的配置内容与上面的案例没有任何区别 12345678910111213141516171819202122232425262728293031323334cmake_minimum_required(VERSION 3.15)# 项目信息project(minder)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 输出调试信息set(CMAKE_CXX_FLAGS \"-g\")# 开启所有警告set(CMAKE_CXX_FLAGS \"-Wall\")# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 引入主项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索主项目的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src MAIN_SOURCES)# 指定可执行文件的名称和主项目的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES})# 启用单元测试enable_testing()# 添加子目录（子项目）add_subdirectory(test)# 添加单元测试的可执行文件add_test(minder_test ${PROJECT_SOURCE_DIR}/test/build/minder_test) test 目录的 CMakeLists.txt，这里的配置内容新增了 GoogleTest 库 1234567891011121314151617181920212223242526272829303132333435363738394041cmake_minimum_required(VERSION 3.15)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 查找 GoogleTest 库find_package(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS \"GTEST_INCLUDE_DIRS : \" ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS \"GTEST_BOTH_LIBRARIES : \" ${GTEST_BOTH_LIBRARIES})# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX \"main.cpp\")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 引入 GoogleTest 的头文件include_directories(${GTEST_INCLUDE_DIRS})# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES})# 链接 GoogleTest 与 pthread 库（请特别注意声明的顺序）target_link_libraries(${PROJECT_NAME} ${GTEST_BOTH_LIBRARIES} pthread) 命令行编译项目 编译 test 子项目 1234567891011121314151617# 进入子项目的目录$ cd minder-gtest/test# 创建子项目的构建目录$ mkdir build# 进入子项目的构建目录$ cd build# 构建子项目$ cmake ..# 编译子项目$ make# 运行可执行文件$ ./minder_test 运行可执行文件后，输出的日志信息如下： 123456789101112[==========] Running 2 tests from 1 test suite.[----------] Global test environment set-up.[----------] 2 tests from TestCase[ RUN ] TestCase.test1[ OK ] TestCase.test1 (0 ms)[ RUN ] TestCase.test2[ OK ] TestCase.test2 (0 ms)[----------] 2 tests from TestCase (0 ms total)[----------] Global test environment tear-down[==========] 2 tests from 1 test suite ran. (2 ms total)[ PASSED ] 2 tests. 编译主项目 1234567891011121314151617181920# 进入主项目的目录$ cd minder-gtest# 创建主项目的构建目录$ mkdir build# 进入主项目的构建目录$ cd build# 构建主项目$ cmake ..# 编译主项目$ make# 执行项目测试$ make test# 运行可执行文件$ ./minder GoogleTest 使用扩展说明在上面的案例中，GoogleTest 是使用源码编译的方式安装到 Linux 系统上的，这在迁移操作系统的时候，需要重复执行同样的安装步骤。此时为了方便日后迁移操作系统，可以将 GoogleTest 的头文件、动态链接都复制一份到项目中，这样就可以不依赖外部的系统环境了。 提示 点击下载 完整的案例代码，项目的目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778minder-gtest-plus├── CMakeLists.txt├── include│ └── datetime.h├── src│ ├── datetime.cpp│ └── main.cpp├── test│ ├── CMakeLists.txt│ ├── include│ │ └── strUtil.h│ └── src│ └── main.cpp└── thirdparty └── googletest ├── gmock │ ├── include │ │ └── gmock │ │ ├── gmock-actions.h │ │ ├── gmock-cardinalities.h │ │ ├── gmock-function-mocker.h │ │ ├── gmock-generated-actions.h │ │ ├── gmock-generated-actions.h.pump │ │ ├── gmock-generated-function-mockers.h │ │ ├── gmock-generated-function-mockers.h.pump │ │ ├── gmock-generated-matchers.h │ │ ├── gmock-generated-matchers.h.pump │ │ ├── gmock.h │ │ ├── gmock-matchers.h │ │ ├── gmock-more-actions.h │ │ ├── gmock-more-matchers.h │ │ ├── gmock-nice-strict.h │ │ ├── gmock-spec-builders.h │ │ └── internal │ │ ├── custom │ │ │ ├── gmock-generated-actions.h │ │ │ ├── gmock-generated-actions.h.pump │ │ │ ├── gmock-matchers.h │ │ │ ├── gmock-port.h │ │ │ └── README.md │ │ ├── gmock-internal-utils.h │ │ ├── gmock-port.h │ │ └── gmock-pp.h │ └── lib │ ├── libgmock_main.so │ └── libgmock.so └── gtest ├── include │ └── gtest │ ├── gtest-death-test.h │ ├── gtest.h │ ├── gtest-matchers.h │ ├── gtest-message.h │ ├── gtest-param-test.h │ ├── gtest_pred_impl.h │ ├── gtest-printers.h │ ├── gtest_prod.h │ ├── gtest-spi.h │ ├── gtest-test-part.h │ ├── gtest-typed-test.h │ └── internal │ ├── custom │ │ ├── gtest.h │ │ ├── gtest-port.h │ │ ├── gtest-printers.h │ │ └── README.md │ ├── gtest-death-test-internal.h │ ├── gtest-filepath.h │ ├── gtest-internal.h │ ├── gtest-param-util.h │ ├── gtest-port-arch.h │ ├── gtest-port.h │ ├── gtest-string.h │ ├── gtest-type-util.h │ └── gtest-type-util.h.pump └── lib ├── libgtest_main.so └── libgtest.so test 目录的 CMakeLists.txt，这里的配置内容使用了项目里的 GoogleTest 库 1234567891011121314151617181920212223242526272829303132333435363738394041cmake_minimum_required(VERSION 3.15)# 定义 GoogleTest 库的目录路径set(PATH_TO_GOOGLE_TEST ../thirdparty/googletest/gtest)set(PATH_TO_GOOGLE_MOCK ../thirdparty/googletest/gmock)# 项目信息project(minder_test)# 定义C++的版本set(CMAKE_CXX_STANDARD 11)# 搜索父目录（父项目）的头文件include_directories(../include)# 搜索父目录（父项目）的源文件aux_source_directory(../src MAIN_SOURCES)# 排除父目录（父项目）的入口源文件list(FILTER MAIN_SOURCES EXCLUDE REGEX \"main.cpp\")# 引入子项目的头文件include_directories(${PROJECT_SOURCE_DIR}/include)# 搜索子项目里的源文件aux_source_directory(${PROJECT_SOURCE_DIR}/src TEST_SOURCES)# 引入 GoogleTest 库的头文件include_directories(${PATH_TO_GOOGLE_TEST}/include ${PATH_TO_GOOGLE_MOCK}/include)# 指定 GoogleTest 动态链接库所在的目录link_directories(${PATH_TO_GOOGLE_TEST}/lib ${PATH_TO_GOOGLE_MOCK}/lib)# 指定构建输出的目录set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的名称和单元测试的所有源文件add_executable(${PROJECT_NAME} ${MAIN_SOURCES} ${TEST_SOURCES})# 链接 GoogleTest 与 pthread 库（请特别注意声明的顺序）target_link_libraries(${PROJECT_NAME} gtest_main.so gtest.so gmock_main.so gmock.so pthread) main.cpp 的 C++ 代码，与上面的案例代码完全一致 1234567891011121314151617181920212223#include &lt;iostream&gt;#include \"strUtil.h\"#include \"datetime.h\"#include &lt;gtest/gtest.h&gt;using namespace std;// 去除字符串两边的空格TEST(TestCase, test1) { string str = \" Hello World ! \"; trim(str); ASSERT_EQ(\"Hello World !\", str);}// 根据给定的日期，计算它是星期几TEST(TestCase, test2) { ASSERT_EQ(true, DateUtil::isWeekendDays(\"2022-01-09\"));}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} 参考博客 建立简单的带单元测试的 CMake 项目 CMake + GoogleTest 之一入门 CMake 使用 GoogleTest 进行单元测试 Centos7 C++ 安装使用 GoogleTest 进行单元测试 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ c语言 linux系统编程"},{"title":"Debian 安装 GCC、G++、GDB","url":"/posts/7df04100.html","text":"提示 GCC 4.8.1，这是该编译器由 C 语言实现转向 C++ 实现（4.8 版本）后的首次升级，也是第一个实现 C++ 11 所有语言特性的编译器。 Debian 8 Jessie 更改仓库源 123456# 备份配置文件# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 更改仓库源# echo \"deb http://ftp.us.debian.org/debian/ jessie main contrib non-free\" &gt;&gt; /etc/apt/sources.list# echo \"deb-src http://ftp.us.debian.org/debian/ jessie main contrib non-free\" &gt;&gt; /etc/apt/sources.list 安装 GCC、G++、GDB 123456# 安装软件（最后得到的版本是4.8.4）# apt-get install -y gcc-4.8 g++-4.8 gdb# 建立软链接（可选）# ln -s /usr/bin/gcc-4.8 /usr/bin/gcc# ln -s /usr/bin/g++-4.8 /usr/bin/g++ Debian 9 Stretch提示 build-essential 指的是编译程序必需的软件包，包含了 GCC、G++、Make 等工具 在 Debian 9 Stretch 上安装 build-essential 后，得到的 GCC、G++ 的版本是 6.3.0 若希望在 Debian 9 Stretch 上安装低版本的 GCC/G++（例如 4.8），那么可以将上面 Debian 8 Jessie 的仓库源地址添加到 Debian 9 Stretch 系统里，然后使用同样的方法分别单独安装 GCC/G++ 更改仓库源 123456789101112# 备份配置文件# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 更改仓库源# echo \"deb http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt; /etc/apt/sources.list# echo \"deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list# echo \"deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.list# echo \"deb-src http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt;&gt; /etc/apt/sources.list# echo \"deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list# echo \"deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.list# echo \"deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list# echo \"deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list 安装 GCC、G++、GDB 1# apt-get install -y build-essential gdb 参考博客 Debian 9 安装 gcc-4.8 如何在 Debian Stretch 上安装 gcc-4.8 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"debian"},{"title":"Docker 开发随笔","url":"/posts/abd1f0ff.html","text":"Docker 删除所有 none 镜像1# docker rmi `docker images | grep '&lt;none&gt;' | awk '{print $3}'` Docker 构建镜像时忽略错误信息根据 Dockerfile 构建镜像，当构建失败时，往往会出现以下错误： 12automake: error: no 'Makefile.am' found for any configure outputError build: The command [/bin/sh -c aclocal &amp;&amp; autoconf &amp;&amp; automake -a] returned a non-zero code: 1 在很多企业的应用场景里，上面的错误信息实际上是无害的，可以忽略不处理。但一旦出现此类错误 Docker 就会停止构建，此时如果需要让 Docker 忽略类似的错误信息，可以使用 exit 0 1RUN make 当 Dockerfile 里包含了上面类似的指令，则可以改写为以下的内容，这将始终返回 0（成功）退出代码，此时 Docker 不会意外终止构建过程 1RUN make; exit 0 不同网段之间的容器实现互相通信Docker 命令行的使用提示 假设存在两个容器，分别是 Redis 容器（172.89.0.2）和 Nginx 容器（172.89.0.5），两者具体的 docker-compose.yml 配置信息如下： Redis 容器 123456789101112131415161718192021222324252627version: '3.5'services: redis: image: redis:5.0.4-stretch container_name: redis restart: always privileged: false environment: TZ: 'Asia/Shanghai' ports: - 6379:6379 networks: redis-network: ipv4_address: 172.89.0.2 volumes: - '/usr/local/redis/data:/data' - '/usr/local/redis/redis.conf:/usr/local/etc/redis/redis.conf' command: redis-server /usr/local/etc/redis/redis.confnetworks: redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Nginx 容器 1234567891011121314151617181920212223242526version: '3.5'services: nginx: image: nginx:1.20 container_name: nginx restart: always privileged: false environment: TZ: 'Asia/Shanghai' networks: nginx-network: ipv4_address: 172.64.0.5 ports: - 80:80 - 443:443 volumes: - '/usr/local/nginx/conf/nginx.conf:/usr/local/nginx/conf/nginx.conf'networks: nginx-network: name: nginx-network driver: bridge ipam: config: - subnet: 172.64.0.0/24 上述的 Redis 和 Nginx 容器分别处于不同的网段中，两者之间的网络无法直接 Ping 得通；若希望在 Redis 内可以 Ping 通 Nginx 容器，那么可以将 Nginx 容器添加到 Redis 容器所在网络里，命令示例如下： 12345678# 将Nginx容器添加到Redis容器所在网络里# docker network connect redis-network nginx# 查看Nginx容器在Redis容器所在网络里的IP# docker network inspect redis-network# 在Redis容器内直接Ping通Nginx容器（这里的IP是Nginx容器在新网络里的IP地址）# ping 172.89.0.3 警告 使用 docker network connect redis-network nginx 命令，将 Nginx 容器添加到 Redis 容器所在网络后，Nginx 在新网络里的 IP 地址是不固定的，例如 Docker 服务重启后 IP 地址会变更，这一点必须注意！ 将 Nginx 容器从 Redis 容器所在网络里移除掉，可以使用以下命令： 1# docker network disconnect redis-network nginx 提示 Docker 默认网络的名称是 bridge，默认情况下创建的所有容器都会在 bridge 网络内。 12345# 查看Docker的所有网络# docker network ls# 查看某网络下所有容器的信息（包括各个容器的IP）# docker network inspect redis-network Docker-Compose 的使用在 Docker-Compose 中，支持将 Nginx 容器添加到 Redis 容器所在网络里，配置示例如下所示。 提示 值得一提的是，这里通过 docker-compose.yml 配置文件，将 Nginx 容器添加到 Redis 容器所在网络后，Nginx 在新网络里的 IP 地址是固定的。 Redis 容器，配置内容和上面的案例一致 123456789101112131415161718192021222324252627version: '3.5'services: redis: image: redis:5.0.4-stretch container_name: redis restart: always privileged: false environment: TZ: 'Asia/Shanghai' ports: - 6379:6379 networks: redis-network: ipv4_address: 172.89.0.2 volumes: - '/usr/local/redis/data:/data' - '/usr/local/redis/redis.conf:/usr/local/etc/redis/redis.conf' command: redis-server /usr/local/etc/redis/redis.confnetworks: redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Nginx 容器，配置了多个网络，同时指定了容器在不同网络下的 IP 地址 12345678910111213141516171819202122232425262728293031323334version: '3.5'services: nginx: image: nginx:1.20 container_name: nginx restart: always privileged: false environment: TZ: 'Asia/Shanghai' networks: nginx-network: ipv4_address: 172.64.0.5 redis-network: ipv4_address: 172.89.0.3 ports: - 80:80 - 443:443 volumes: - '/usr/local/nginx/conf/nginx.conf:/usr/local/nginx/conf/nginx.conf'networks: nginx-network: name: nginx-network driver: bridge ipam: config: - subnet: 172.64.0.0/24 redis-network: name: redis-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 查看 Docker 的网络状况 12345# 查看Nginx容器在Redis容器所在网络里的IP# docker network inspect redis-network# 在Redis容器内直接Ping通Nginx容器# ping 172.89.0.3 Docker 升级版本后无法启动Docker 升级版本后无法正常启动，使用命令 journalctl -u docker 查看系统日志信息，得到的错误信息如下： 1[graphdriver] prior storage driver devicemapper is deprecated and will be removed in a future release; update the the daemon configuration and explicitly choose this storage driver to continue using it; 创建或编辑 /etc/docker/daemon.json 配置文件，然后在配置文件内添加以下内容： 123{ \"storage-driver\": \"devicemapper\"} 再次重启 Docker 服务 1systemctl restart docker 参考资料 Docker storage drivers Use the Device Mapper storage driver Docker 查看容器的资源占用情况使用以下命令，可以查看 Docker 容器的 CPU、内存、网络资源占用情况。 12345# 查看所有容器# docker stats# 查看特定的容器# docker stats mysql Docker 容器添加自定义 Hosts为了向容器的 /etc/hosts 配置文件中添加一些记录，可以使用以下任意一种方式来实现。 Docker 启动容器时，添加 Hosts 1docker run --add-host=myhostname:10.180.8.1 --name test -it debian Docker-Compose 通过配置参数 extra_hosts 实现 1234567891011121314151617181920212223version: \"3.5\"services: pms: image: idoop/zentao:latest container_name: pms privileged: true ports: - 8080:80 - 3386:3306 environment: - ADMINER_USER=root - ADMINER_PASSWD=123456 - BIND_ADDRESS=false - SET_CONTAINER_TIMEZONE=true - CONTAINER_TIMEZONE=Asia/Shanghai volumes: - /etc/localtime:/etc/localtime:ro - /data/pms/:/opt/zbox/ restart: always extra_hosts: - \"github.com:140.82.112.4\" - \"smtp.exmail.qq.com:113.96.208.92\" Docker-Compose 的另一种写法，可能需要高版本的 Compose 才支持（例如 1.3 版本） 1234567891011121314151617181920212223version: \"3.5\"services: pms: image: idoop/zentao:latest container_name: pms privileged: true ports: - 8080:80 - 3386:3306 environment: - ADMINER_USER=root - ADMINER_PASSWD=123456 - BIND_ADDRESS=false - SET_CONTAINER_TIMEZONE=true - CONTAINER_TIMEZONE=Asia/Shanghai volumes: - /etc/localtime:/etc/localtime:ro - /data/pms/:/opt/zbox/ restart: always extra_hosts: - github.com: 140.82.112.4 - smtp.exmail.qq.com: 113.96.208.92 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化 开发随笔"},{"title":"Centos7 升级 OpenSSL","url":"/posts/4ffdb5e1.html","text":"系统环境1Linux clay 3.10.0-1160.49.1.el7.x86_64 #1 SMP Tue Nov 30 15:51:32 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 升级 OpenSSL 查看 OpenSSL 的版本 12# openssl versionOpenSSL 1.0.2k-fips 26 Jan 2017 备份旧版的 OpenSSL 12# mv /usr/bin/openssl /usr/bin/openssl.bak# mv /usr/include/openssl /usr/include/openssl-bak 安装依赖 1# yum install -y perl perl-devel perl-Test-Simple gcc gcc-c++ make 编译安装 注意事项 建议从 OpenSSL 官网 下载源码包，最新的稳定版本是 1.1.1 系列 ./config 命令必须加上 shared 参数，否则生成的 lib 目录里面只有 .a 静态库文件， 没有 .so 动态链接库文件 123456789101112131415161718192021222324252627# 下载文件# wget https://www.openssl.org/source/openssl-1.1.1m.tar.gz# 解压文件# tar -xvf openssl-1.1.1m.tar.gz# 进入解压目录# cd openssl-1.1.1m# 构建配置# ./config shared zlib --prefix=/usr/local/openssl# 编译# make -j4# 安装# make install# 添加动态链接库的路径到系统配置文件# echo \"/usr/local/openssl/lib\" &gt;&gt; /etc/ld.so.conf# 使配置生效# ldconfig -v# 链接文件# ln -sf /usr/local/openssl/bin/openssl /usr/bin/openssl# ln -sf /usr/local/openssl/include/openssl /usr/include/openssl 验证是否升级成功 12# openssl versionOpenSSL 1.1.1m 14 Dec 2021 升级后的维护更新 OpenSSL 后，需要排查系统的第三方服务是否以静态编译方式使用了 OpenSSL；如果第三方服务是静态编译的，则需要指定新的 OpenSSL 库重新进行编译，否则会影响服务的正常运行或者容易让其受到安全攻击。 提示 一般以静态编译方式使用了 OpenSSL 的第三方服务有：OpenSSH、Nginx、Apache，尤其当 Web 服务器支持 HTTPS 协议的时候 参考博客 Ubuntu16.04.4 升级 OpenSSL Centos8 OpenSSL 升级版本到最新 CentOS 如何升级 OpenSSL 到最新版本 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"centos"},{"title":"Linux 实现 Windows 的 Event 事件机制","url":"/posts/c847598e.html","text":"前言 Linux 中没有 Windows 系统中的 CreateEvent()、WaitEvent()、SetEvent()、ResetEvent() 等函数，本文将介绍如何使用 pevents 替代 Linux 缺失的函数。 pevents 介绍 pevents 的简介pevents 是一个跨平台的轻量级 C++ 库，旨在为 POSIX 系统提供 WIN32 事件的实现。pevents 提供了 Windows 平台手动和自动重置事件的大部分功能，最显著的是支持同时等待多个事件（WaitForMultipleObjects），而且支持 Windows、FreeBSD、Linux、macOS、iOS、Android 等平台。 pevents 的 APIAPI 函数pevents 的 API 是根据 Windows 的 CreateEvent（）、WaitEvent（） 和 WaitForMultipleObjects（） 函数编写的，熟悉 WIN32 事件的开发人员应该可以将代码库切换到 pevents API。虚假唤醒是 Linux 下系统编程的正常部分，也是来自 Windows 世界的开发人员的常见陷阱，pevents 可以保证不存在虚假唤醒和等待返回的数据的正确性，其提供了如下的 API： 12345678910int SetEvent(neosmart_event_t event);int ResetEvent(neosmart_event_t event);int PulseEvent(neosmart_event_t event);int DestroyEvent(neosmart_event_t event);neosmart_event_t CreateEvent(bool manualReset, bool initialState);int WaitForEvent(neosmart_event_t event, uint64_t milliseconds);int WaitForMultipleEvents(neosmart_event_t *events, int count, bool waitAll, uint64_t milliseconds);int WaitForMultipleEvents(neosmart_event_t *events, int count, bool waitAll, uint64_t milliseconds, int &amp;index); 事件状态的类型 CreateEvent() 函数 1234567neosmart_event_t CreateEvent( // true：表示手动，在 WaitEvent 后需要手动调用 ResetEvent 清除事件信号。false：表示自动，在 WaitEvent 后，系统会自动清除事件信号 bool manualReset, // 初始状态，false 为无信号，true 为有信号 bool initialState); WaitForEvent() 函数 123456int WaitForEvent( // 句柄对象 neosmart_event_t event, // 等待的时间（毫秒） uint64_t milliseconds); 事件状态的类型 WAIT_TIMEOUT：等待超时 WAIT_OBJECT_0：句柄对象处于有信号状态 WAIT_FAILED：出现错误，可通过 GetLastError() 函数得到错误码 WAIT_ABANDONED：说明句柄代表的对象是个互斥对象，并且正在被其它线程占用 注意 在 Linux 平台，pevents 的事件状态只支持使用 WAIT_TIMEOUT，且有信号的时候 WaitEvent() 函数的返回值是 0，而在 Windows 平台则支持上述四种事件状态 pevents 的项目结构 核心代码在 src/ 目录 单元测试代码（通过 Meson 构建）在 test/ 目录 在 examples/ 目录中可以找到演示 pevents 用法的跨平台应用示例程序 pevents 的编译构建pevents 使用的构建工具是 Meson，目前这仅用于支持 pevents 核心代码及其单元测试的自动化构建 / 测试。值得一提的是，开发人员不需要担心构建工具的差异性，pevents 是特意基于 C/C++ 标准编写的，避免了复杂的配置或依赖于平台的构建指令的需要。 pevents 的编译参数通过编译参数 -DWFMO 与 -DPULSE，可以在编译时让 pevents 启用不同的功能： WFMO：启用 WFMO 功能，如果需要使用 WaitForMultipleEvents() 函数，建议仅使用 WFMO 进行编译，因为它会为所有事件对象增加开销（较小）。 PULSE：启用 PulseEvent 功能，PulseEvent() 在 Windows 平台从根本上被破坏了，一般不应该被使用，当你调用它时，它几乎永远不会做你认为你正在做的事情。pevents 包含这个函数只是为了让现有的（有缺陷的）代码从 WIN32 移植到 Unix/Linux 平台更容易，并且这个函数默认没有编译到 pevents 中。 Meson 指定编译参数在 Meson 中，可以通过 meson_options.txt 配置文件指定编译参数，让 pevents 启用不同的功能 1234option('wfmo', type: 'boolean', value: true, description: 'Enable WFMO events')option('pulse', type: 'boolean', value: false, description: 'Enable PulseEvent() function') CMake 指定编译参数在 CMake 中，可以通过 CMakeLists.txt 配置文件指定编译参数，让 pevents 启用不同的功能 1set(CMAKE_CXX_FLAGS \"-std=c++11 -lpthread -DWFMO\") pevents 运行示例代码提示 值得一提的是，pevents 的核心 C++ 源文件是 pevents.h、pevents.cpp 1234567891011121314151617# 拉取代码$ git clone git@github.com:clay-world/pevents.git# 进入源码目录$ cd pevents# 生成构建的输出目录$ meson build# 进入构建的输出目录$ cd build# 编译代码$ ninja# 运行示例程序$ ./sample pevents 的实战案例编译说明下面给出的案例使用了 pthread，由于 pthread 不是 Linux 系统默认的库，因此链接时需要使用静态库 libpthread.a。简而言之，在使用 pthread_create() 创建线程，以及调用 pthread_atfork() 函数建立 fork 处理程序时，需要通过 -lpthread 参数链接该库，同时还需要在 C++ 源文件里添加头文件 pthread.h。 提示 为了可以正常编译使用了 pthread 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lpthread 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS \"-std=c++11 -lpthread -DWFMO\")add_executable(main main.cpp) 实战案例一CreateEvent(true, true) - 手动清除事件信号，初始状态为有信号，点击下载 基于 CMake 构建的完整案例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include \"pevents.h\"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf(\"%s pid %u tid %u (0x%x)\\n\", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds(\"thread-1\"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; \"thread-1 is working...\" &lt;&lt; endl; } return ((void *) 0);}void *procFunc2(void *args) { printIds(\"thread-2\"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; \"thread-2 is working...\" &lt;&lt; endl; } return ((void *) 0);}int main() { // 手动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(true, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);} 程序运行的结果如下： 1234thread-1 pid 62705 tid 2336241408 (0x8b403700)thread-1 is working...thread-2 pid 62705 tid 2327848704 (0x8ac02700)thread-2 is working... 提示 可以看到线程 1 和线程 2 都完整执行了，这是因为创建的事件是需手动 Reset 才会变为无信号的，所以执行完线程 1 后事件仍处于有信号的状态，所以线程 2 的逻辑才会被继续执行。 实战案例二CreateEvent(false, true) - 自动清除事件信号，且初始状态为有信号，点击下载 基于 CMake 构建的完整案例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include \"pevents.h\"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf(\"%s pid %u tid %u (0x%x)\\n\", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds(\"thread-1\"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; \"thread-1 is working...\" &lt;&lt; endl; } return ((void *) 0);}void *procFunc2(void *args) { printIds(\"thread-2\"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; \"thread-2 is working...\" &lt;&lt; endl; } return ((void *) 0);}int main() { // 自动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(false, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);} 程序运行的结果如下： 123thread-1 pid 59685 tid 2245932800 (0x85de3700)thread-1 is working...thread-2 pid 59685 tid 2237540096 (0x855e2700) 提示 可以看到只有线程 1 完整执行了，这是由于事件在执行完线程 1 后被系统自动重置为无信号，所以线程 2 中的逻辑没有被执行。 实战案例三CreateEvent(true, false) - 手动清除事件信号，初始状态为无信号，包括 SetEvent（） 与 ResetEvent() 的使用，点击下载 基于 CMake 构建的完整案例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include \"pevents.h\"using namespace std;using namespace neosmart;neosmart_event_t g_hEvent = NULL;void printIds(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf(\"%s pid %u tid %u (0x%x)\\n\", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *procFunc1(void *args) { printIds(\"thread-1\"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; \"thread-1 is working...\" &lt;&lt; endl; } // 重置事件为无信号 ResetEvent(g_hEvent); return ((void *) 0);}void *procFunc2(void *args) { printIds(\"thread-2\"); if (WaitForEvent(g_hEvent, 1) == 0) { cout &lt;&lt; \"thread-2 is working...\" &lt;&lt; endl; } return ((void *) 0);}void func1() { // 手动清除事件信号，初始状态为有信号 g_hEvent = CreateEvent(true, true); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5);}int main() { // 手动清除事件信号，初始状态为无信号 g_hEvent = CreateEvent(true, false); // 设置事件为有信号 SetEvent(g_hEvent); pthread_t ntid1; pthread_create(&amp;ntid1, NULL, procFunc1, NULL); sleep(1); pthread_t ntid2; pthread_create(&amp;ntid2, NULL, procFunc2, NULL); sleep(5); return 0;} 程序运行的结果如下： 123thread-1 pid 70368 tid 2745513728 (0xa3a53700)thread-1 is working...thread-2 pid 70368 tid 2737121024 (0xa3252700) 提示 可以看到只有线程 1 完整执行了，这是因为线程 1 在执行之前事件是有信号的，执行完成后事件被手动重置为无信号，所以线程 2 中的逻辑没有被执行。 参考资料 C++ 的 CreateEvent () WaitForSingleObject 和 WaitForMultipleObject 事件 SetEvent、ResetEvent、WaitForSingleObject 与 CreateEvent 详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ linux系统编程"},{"title":"Linux 移植 Windows 的 C++ 代码","url":"/posts/15f45d12.html","text":"conio.h 头文件移植简述conio.h 不是 C 标准库中的头文件，在 ISO 和 POSIX 标准中均没有定义。conio 是 Console Input/Output（控制台输入输出）的简写，其中定义了通过控制台进行数据输入和数据输出的函数，主要是一些用户通过按键盘产生的对应操作，比如 getch() 函数等等。大部分 DOS、Windows、Phar Lap、DOSX，OS/2 等平台上的 C 编译器提供了此头文件，UNIX 和 Linux 平台的 C 编译器本身通常不包含此头文件。另外在项目开发中，平时主要是使用 conio.h 这个头文件中的 getch() 函数，即读取键盘字符但是不显示出来（without echo)，但是含有 conio.h 的代码在 Linux 下无法直接编译通过，因为 Linux 没有这个头文件。但 Linux 平台下完全可以使用 ncurses 替代 conio.h 头文件，ncurses 支持的 API 可以阅读 官方文档。值得一提的是，ncurses 在 Linux 平台实现了 getch()、scanw()、getstr() 等函数。 安装依赖提示 由于 ncurses 不是 Linux 系统默认的库，因此需要安装后才能使用，不同平台的安装命令如下： CentOS/Fedora 1# yum install -y ncurses ncurses-devel Debian/Ubuntu 1# apt-get install -y libncurses5-dev libncursesw5-dev 案例代码提示 ncurses.h 与 curses.h 这两个头文件是等价的 12345678910#include &lt;iostream&gt;#include &lt;ncurses.h&gt;using namespace std;int main() { cout &lt;&lt; (\"Hello Wolrd!\") &lt;&lt; endl; getch(); return 0;} 编译说明由于 ncurses 不是 Linux 系统默认的库，因此编译时需要链接到该库，同时还需要在 C++ 的源文件里添加头文件 ncurses.h，否则编译会失败。 提示 为了可以正常编译使用了 ncurses 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lncurses 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS \"-std=c++11 -lncurses\")add_executable(main main.cpp) itoa () 函数移植简述在 Window 平台里，itoa() 函数可以将整数转换为字符串，其函数的原型如下。Linux 平台中只有 atoi() 函数，并没有对应的 itoa() 函数，但可以使用 sprintf() 或者 snprintf() 函数替代，建议使用更安全的 snprintf()。 itoa () 函数 函数原型：char *itoa( int value, char *string,int radix) 函数功能：将整数 value 转换成字符串存入 string 指向的内存空间，radix 为转换时所用基数 (保存到字符串中的数据的进制基数) 函数的参数：value：转换的数据，string：目标字符串的地址，radix：转换后的进制数，可以是 10 进制、16 进制等，范围必须在 2-36 之间 snprintf () 函数 头文件：#include &lt;stdio.h&gt; 函数原型：int snprintf(char *str, size_t size, const char *format, ...) 函数功能：将可变参数 ... 按照 format 格式化成字符串，然后将其复制到 str 中 函数参数：str：目标字符串，size：拷贝字节数（Bytes），format：格式化字符串，... 可变参数 案例代码1234567891011#include &lt;iostream&gt;using namespace std;int main() { int num = 12; char str[4]; int size = snprintf(str, 4, \"%d\", num); cout &lt;&lt; \"str = \" &lt;&lt; str &lt;&lt; \", size = \" &lt;&lt; size &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1str = 12, size = 2 strcpy_s () 函数相关站点 Safe C Library 的下载页面 Safe C Library 的官方文档 Safe C Library 的 GitHub 项目 移植简述在 Window 平台上，strcpy_s() 函数存在于 #include &lt;cstring&gt; 头文件中。Linux 平台没有该函数，但可以使用 Safe C Library 替代实现。Safe C Library 这个库是在 libc 的基础之上实现了安全的 C11 Annex K 函数，这些函数是它们所缺少的，可以帮助缓解不断增加的安全攻击，特别是缓冲区溢出。 安装依赖提示 由于 Safe C Library 不是 Linux 系统默认的库，因此需要安装后才能使用，其默认的安装目录如下 /usr/local/lib/：包含静态库和动态链接库文件 /usr/local/include/libsafec：包所有含头文件 1234567891011121314151617# 下载文件（这里下载的不是源码压缩包）# wget https://github.com/rurban/safeclib/releases/download/v02092020/libsafec-02092020.tar.gz# 解压文件# tar -xvf libsafec-02092020.tar.gz# 进入解压目录# cd libsafec-02092020.0-g6d921f# 配置# ./configure# 编译# make -j4# 安装# make install 值得一提的是，Safe C Library 编译后会单独生成静态库文件 /usr/local/lib/libsafec-3.6.0.a 和动态链接库文件 /usr/local/lib/libsafec-3.6.0.so.3.0.6，其中的 3.6.0 是指版本号。 案例代码提示 strcpy_s() 函数在 Safe C Library 里的 safe_str_lib.h 头文件中声明 123456789101112#include &lt;iostream&gt;#include &lt;libsafec/safe_str_lib.h&gt;using namespace std;int main() { char *str = new char[5]; strcpy_s(str, 5, \"abcd\"); cout &lt;&lt; str &lt;&lt; endl; delete[] str; return 0;} 编译说明由于 Safe C Library 不是 Linux 系统默认的库，因此编译时需要链接到该库，同时还需要在 C++ 的源文件里添加头文件 &lt;libsafec/safe_str_lib.h&gt;，否则编译会失败。 提示 为了可以正常编译使用了 Safe C Library 的项目代码，不同构建工具的使用说明如下所示 可以将上面构建生成的 libsafec-3.6.0.a 静态库文件和 .h 头文件都拷贝到项目里，这样就可以方便在不同的 Linux 系统编译和运行项目，不用每次切换系统时都要重新安装 Safe C Library 若使用 G++ 编译 C++ 项目，则编译命令的示例如下，请自行更改库文件的版本号： 12345# 编译代码$ g++ main.cpp -o main -L/usr/local/lib/ -l:libsafec-3.6.0.a# \"-L\" 参数指定了库文件的目录路径# \"-l:\" 参数指定了库文件的文件名 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下，请自行更改库文件的版本号： 123link_libraries(/usr/local/lib/libsafec-3.6.0.a)add_executable(windows_to_linux main.cpp) 函数可变参数宏移植简述在 Windows 平台与 Linux 平台，函数可变参数宏定义的语法是不一样的。 案例代码 Windows 平台的函数可变参数宏定义的写法如下，使用的是 __VA_ARGS__ 12FILE* logfile = fopen(\"syslog.txt\", \"w\");#define LOG(format, ...) fprintf(logfile, format, __VA_ARGS__); printf(format, __VA_ARGS__); fflush(logfile); Linux 平台的函数可变参数宏定义写法如下，使用的是 ##__VA_ARGS__ 12FILE* logfile = fopen(\"syslog.txt\", \"w\");#define LOG(format, ...) fprintf(logfile, format, ##__VA_ARGS__); printf(format, ##__VA_ARGS__); fflush(logfile); var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ linux系统编程"},{"title":"C++ 进阶基础之六","url":"/posts/62e4578b.html","text":"大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 string 容器string 容器的概念string 是 STL 的字符串类型，通常用来表示字符串。而在使用 string 之前，字符串通常是用 char* 表示的。string 与 char* 都可以用来表示字符串，两者的区别如下： string 是一个类，char* 是一个指向字符的指针 string 封装了 char* 来管理字符串，本质是一个 char* 类型的容器 string 不用考虑内存释放和越界的问题 string 负责管理 char* 所分配的内存。每一次 string 的复制，取值都由 string 类负责维护，不用担心复制越界和取值越界等问题 string 提供了一系列的字符串操作函数，例如：查找（find）、拷贝（copy）、删除（erase）、替换（replace）、插入（insert） stirng 容器的 API构造函数 默认构造函数：string(); 带参数的构造函数： string(const char *s);，用字符串 s 初始化 string(int n, char c);，用 n 个字符 c 初始化 拷贝构造函数：string(const string &amp;str); string 的长度 size_t size() const，返回当前字符串的长度，这里的长度不包括字符串的结尾的 \\0 字符 size_t length() const;，返回当前字符串的长度，这里的长度不包括字符串的结尾的 \\0 字符 bool empty() const;，判断当前字符串是否为空 值得一提的是，sizeof() 返回的是对象所占用空间的字节数，strlen() 返回的是字符数组中第一个 \\0 前的字节数，string 的成员函数 size() 和 length() 没有任何区别。 string 的赋值 string &amp;operator=(const string &amp;s);，把字符串 s 赋给当前的字符串 string &amp;assign(const char *s);，把字符串 s 赋给当前的字符串 string &amp;assign(const char *s, int n);，把字符串 s 的前 n 个字符赋给当前的字符串 string &amp;assign(const string &amp;s);，把字符串 s 赋给当前字符串 string &amp;assign(int n, char c);，用 n 个字符 c 赋值给当前字符串 string &amp;assign(const string &amp;s, int start, int n);，把字符串 s 中从 start 开始的 n 个字符赋值给当前字符串 string 的子串 string substr(int pos=0, int n=npos) const;，返回由 pos 位置开始的 n 个字符组成的子字符串 string 的查找 int find(char c, int pos=0) const;，从 pos 位置开始查找字符 c 在当前字符串第一次出现的位置 int find(const char *s, int pos=0) const;，从 pos 位置开始查找字符串 s 在当前字符串第一次出现的位置 int find(const string &amp;s, int pos=0) const;，从 pos 位置开始查找字符串 s 在当前字符串第一次出现的位置 int rfind(char c, int pos=npos) const;，从 pos 位置开始查找字符 c 在当前字符串中最后一次出现的位置 int rfind(const char *s, int pos=npos) const;，从 pos 位置开始查找字符串 s 在当前字符串中最后一次出现的位置 int rfind(const string &amp;s, int pos=npos) const;，从 pos 位置开始查找字符串 s 在当前字符串中最后一次出现的位置 值得一提的是，当 find() 与 rfind() 函数查找不到时，都会返回 -1；两者不同的是 find() 是正向查找，而 rfind() 是逆向查找，但是最终两个函数返回的位置均是字符 / 字符串出现的正向位置；若有重复字符 / 字符串时，则 rfind() 返回的是逆向查找到的字符 / 字符串在正向的位置（即最后一次出现的正向位置）。 string 的替换 string &amp;replace(int pos, int n, const char *s);，删除从 pos 位置开始的 n 个字符，然后在 pos 位置插入字符串 s string &amp;replace(int pos, int n, const string &amp;s);，删除从 pos 位置开始的 n 个字符，然后在 pos 位置插入字符串 s void swap(string &amp;s2);，交换当前字符串与字符串 s2 的值 string 的比较 int compare(const string &amp;s) const;，与字符串 s 比较 int compare(const char *s) const;，与字符串 s 比较 compare() 函数的结果在 &gt; 时返回 1，&lt; 时返回 -1，= 时返回 0。字符串比较区分大小写，比较时参考字典顺序，排越前面的越小。大写的 A（65） 比小写的 a（97） 小。 string 的字符存储 char &amp;at(int n); char &amp;operator[] (int n); operator[] 和 at() 均返回当前字符串中的第 n 个字符，但二者是有区别的 at() 在越界时会抛出异常，[] 在刚好越界时会返回 (char)0，再继续越界时，程序异常终止 如果程序希望可以通过 try catch 捕获异常，则建议采用 at() string 的区间插入 string &amp;insert(int pos, const char *s);，在 pos 位置插入字符串 s，返回修改后的字符串 string &amp;insert(int pos, const string &amp;s);，在 pos 位置插入字符串 s，返回修改后的字符串 string &amp;insert(int pos, int n, char c);，在 pos 位置插入 n 个字符 c，返回修改后的字符串 string 的区间删除 string &amp;erase(int pos=0, int n=npos);，删除从 pos 位置开始的 n 个字符，返回修改后的字符串 string 的字符串拼接 string &amp;operator+=(const string &amp;s);，把字符串 s 连接到当前字符串的结尾 string &amp;operator+=(const char *s);，把字符串 s 连接到当前字符串的结尾 string &amp;append(const char *s); ，把字符串 s 连接到当前字符串的结尾 string &amp;append(const char *s, int n);，把字符串 s 的前 n 个字符连接到当前字符串的结尾 string &amp;append(const string &amp;s); ，把字符串 s 连接到当前字符串的结尾 string &amp;append(const string &amp;s, int pos, int n);，把字符串 s 中从 pos 位置开始的 n 个字符连接到当前字符串的结尾 string &amp;append(int n, char c); ，在当前字符串的结尾添加 n 个字符 c 从 string 取得 char* const char *c_str() const;，返回一个以 \\0 结尾的字符串的首地址 值得一提的是，char * 可以隐式转换为 string 类型，反过来则不可以，例如右边这种写法是合法的： char *p = \"abc\"; string str = p; 将 string 拷贝到 char* 指向的内存空间 int copy(char *s, int n, int pos=0) const; 将当前串中以 pos 位置开始的 n 个字符拷贝到以 s 为起始位置的字符数组中，返回实际拷贝的字符数量。特别注意，要保证指针 s 所指向的内存空间足以容纳当前的字符串，不然可能会发生越界。 string 容器的常用操作 string 容器的构造与赋值 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;int main() { // 默认构造函数 string str1; // 拷贝构造函数 string str2 = str1; // 有参构造函数 string str3(\"abced\"); string str4(5, 'f'); // 基本赋值 str1 = \"123456\"; str2 = str3; str3.assign(\"mnopq\", 3); str4.assign(\"45678\", 1, 3); // 从0开始索引，1表示第2个字符 cout &lt;&lt; \"str1 = \" &lt;&lt; str1 &lt;&lt; endl; cout &lt;&lt; \"str2 = \" &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; \"str3 = \" &lt;&lt; str3 &lt;&lt; endl; cout &lt;&lt; \"str4 = \" &lt;&lt; str4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234str1 = 123456str2 = abcedstr3 = mnostr4 = 567 string 容器的 API 调用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;iostream&gt;using namespace std;int main() { // 存储字符 string str1 = \"abcde\"; for (int i = 0; i &lt; str1.size(); i++) { // 第一种方式 cout &lt;&lt; str1[i] &lt;&lt; \" \"; // 第二种方式 // cout &lt;&lt; str1.at(i) &lt;&lt; \" \"; } cout &lt;&lt; endl; // 字符串拼接 string str2 = \"hello \"; string str3 = \"world \"; str2 += str3; str3.append(\"where\"); cout &lt;&lt; \"str2 = \" &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; \"str3 = \" &lt;&lt; str3 &lt;&lt; endl; // 字符串查找 string str4 = \"My name is Peter\"; int index1 = str4.find(\"name\"); cout &lt;&lt; \"index1 = \" &lt;&lt; index1 &lt;&lt; endl; int index2 = str4.rfind(\"e\"); cout &lt;&lt; \"index2 = \" &lt;&lt; index2 &lt;&lt; endl; // 字符串替换 string str5 = \"abc123\"; str5.replace(3, 3, \"def\"); cout &lt;&lt; \"str5 = \" &lt;&lt; str5 &lt;&lt; endl; string str6 = \"123456\"; string str7 = \"654321\"; str6.swap(str7); cout &lt;&lt; \"str6 = \" &lt;&lt; str6 &lt;&lt; endl; // 字符串比较 string str8 = \"ABC\"; string str9 = \"abc\"; int result = str8.compare(str9); // 返回值小于等于-1 cout &lt;&lt; \"result = \" &lt;&lt; result &lt;&lt; endl; // 截取子字符串 string str10 = \"124abc\"; string str11 = str10.substr(1, 3); cout &lt;&lt; \"str11 = \" &lt;&lt; str11 &lt;&lt; endl; // 字符串的区间插入 string str12 = \"abcdef\"; str12.insert(2, \"123\"); cout &lt;&lt; \"str12 = \" &lt;&lt; str12 &lt;&lt; endl; // 字符串的区间删除 string str13 = \"123456\"; str13.erase(2, 2); cout &lt;&lt; \"str13 = \" &lt;&lt; str13 &lt;&lt; endl; // 从字符串取得 char * string str14 = \"hijkl\"; const char *p1 = str14.c_str(); cout &lt;&lt; \"p1 = \" &lt;&lt; p1 &lt;&lt; endl; // char * 隐式类型转换为 string char *p2 = \"abc123\"; string str15 = p2; cout &lt;&lt; \"str15 = \" &lt;&lt; str15 &lt;&lt; endl; // 将 string 拷贝到 char* 指向的内存空间 char *p3 = new char[3]; string str16 = \"hello jim\"; int number = str16.copy(p3, 3, 2); cout &lt;&lt; \"number = \" &lt;&lt; number &lt;&lt; endl; cout &lt;&lt; \"p3 = \" &lt;&lt; p3 &lt;&lt; endl; delete[] p3; return 0;} 程序运行输出的结果如下： 123456789101112131415a b c d e str2 = hello world str3 = world whereindex1 = 3index2 = 14str5 = abcdefstr6 = 654321result = -32str11 = 24astr12 = ab123cdefstr13 = 1256p1 = hijklstr15 = abc123number = 3p3 = llo map 容器map 容器的概念map 是 STL 的一个关联式容器，它提供一对一（其中第一个称为关键字，每个关键字只能在 map 中出现一次，第二个称为该关键字的值）的数据处理能力。map 容器存储的都是 pair 对象，也就是用 pair 类模板创建的键值对。其中，各个键值对的键和值可以是任意数据类型，包括 C++ 基本数据类型（int、double 等）、使用结构体或类自定义的类型。通常情况下，map 容器中存储的各个键值对都选用 string 字符串作为键的类型。map 内部自建了一颗红黑树 (一种非严格意义上的平衡二叉树)，这颗树具有对数据自动排序的功能，所以在 map 内部所有的数据都是有序的。map 的特点是增加和删除节点对迭代器的影响很小，除了那个被操作的节点，对其他的节点都没有什么影响。值得一提的是，使用 map 容器存储的各个键值对，键的值既不能重复也不能被修改。map 可以根据 key 值快速查找记录，复杂度在 log(n) 级别，如果有 1000 条记录，最多查找 10 次，如果有 1000000 条记录，最多查找 20 次。 map 容器的常用操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;iostream&gt;#include &lt;map&gt;using namespace std;int main() { // 定义Map集合变量 map&lt;int, int&gt; m; // 第一种数据插入方式 m.insert(pair&lt;int, int&gt;(1, 2)); // 第二种数据插入方式（推荐） m.insert(make_pair(3, 4)); // 第三种数据插入方式 m.insert(map&lt;int, int&gt;::value_type(5, 6)); // 第四种数据插入方式 m[7] = 8; // 第一种方式遍历Map集合 for (map&lt;int, int&gt;::iterator it = m.begin(); it != m.end(); it++) { cout &lt;&lt; \"key = \" &lt;&lt; it-&gt;first &lt;&lt; \" , \" &lt;&lt; it-&gt;second &lt;&lt; endl; } cout &lt;&lt; endl; // 第二种方式遍历Map集合 for (auto it = m.begin(); it != m.end(); it++) { cout &lt;&lt; \"key = \" &lt;&lt; it-&gt;first &lt;&lt; \" , value = \" &lt;&lt; it-&gt;second &lt;&lt; endl; } cout &lt;&lt; endl; // 获取指定的Key map&lt;int, int&gt;::iterator item = m.find(5); cout &lt;&lt; \"key = \" &lt;&lt; item-&gt;first &lt;&lt; \" , value = \" &lt;&lt; item-&gt;second &lt;&lt; endl; cout &lt;&lt; endl; // 第一种方式判断Key是否存在 // 如果Key存在，find()函数会返回Key对应的迭代器，如果Key不存在，find()函数会返回尾后迭代器end() if (m.find(100) == m.end()) { cout &lt;&lt; \"key \" &lt;&lt; 100 &lt;&lt; \" not exist\" &lt;&lt; endl; } cout &lt;&lt; endl; // 第二种方式判断Key是否存在 // count()函数用于统计Key值在Map中出现的次数，Map的Key是不允许重复的，因此如果Key存在会返回1，不存在会返回0 if (m.count(5) == 1) { cout &lt;&lt; \"key \" &lt;&lt; 5 &lt;&lt; \" existed\" &lt;&lt; endl; } cout &lt;&lt; endl; // 删除指定的Key m.erase(7); for (auto it = m.begin(); it != m.end(); it++) { cout &lt;&lt; \"key = \" &lt;&lt; it-&gt;first &lt;&lt; \" , value = \" &lt;&lt; it-&gt;second &lt;&lt; endl; }} 程序运行输出的结果如下： 12345678910111213141516171819key = 1 , 2key = 3 , 4key = 5 , 6key = 7 , 8key = 1 , value = 2key = 3 , value = 4key = 5 , value = 6key = 7 , value = 8key = 5 , value = 6key 100 not existkey 5 existedkey = 1 , value = 2key = 3 , value = 4key = 5 , value = 6 参考资料 C++ 中 string 成员函数 length ()、size () 与 strlen () 的区别 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 进阶基础之五","url":"/posts/64fd9f88.html","text":"大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 基本概念模板的基本概念模板是实现代码重用机制的一种重要工具，其本质是类型参数化，即把类型定义为参数。C++ 提供了类模板和函数模板，详细的使用可参考教程：C++ 进阶基础之二 类模板的简介 类模板的本质就是建立一个通用类，其成员变量的类型、成员函数的返回类型和参数类型都可以不具体指定，而用虚拟的类型来替代 当使用类模板建立对象时，编译器会根据实参的类型取代类模板中的虚拟类型，从而实现不同类的功能 函数模板的简介 函数模板就是建立一个通用的函数，其函数返回类型和形参类型不具体指定，而是用虚拟的类型来替代 凡是函数体相同的函数都可以用函数模板来代替，不必定义多个函数，只需在模板中定义一次即可 在调用函数时，编译器会根据实参的类型来取代模板中的虚拟类型，从而实现不同函数的功能 STL 的基本概念STL 的简介STL（Standard Template Library，标准模板库）是惠普实验室开发的一系列软件的统称。现然主要出现在 C++ 中，但在被引入 C++ 之前该技术就已经存在了很长的一段时间。STL 的从广义上讲分为三类：Algorithm（算法）、Container（容器）和 Iterator（迭代器），容器和算法通过迭代器可以进行无缝地连接。几乎所有的 STL 代码都采用了类模板和函数模板的方式编写，这相比于传统的由类和函数组成的库来说提供了更好的代码重用机会。从逻辑层次来看，在 STL 中体现了泛型化程序设计的思想（Generic Programming），在这种思想里，大部分的基本算法被抽象和被泛化，独立于与之对应的数据结构，用于以相同或相近的方式处理各种不同情形。从实现层次看，整个 STL 是以一种类型参数化（Type Parameterized）的方式实现的，本质是基于模板（Template）。在 C++ 标准中，STL 被组织为下面的 13 个头文件：&lt;algorithm&gt;、&lt;deque&gt;、&lt;functional&gt;、&lt;iterator&gt;、&lt;vector&gt;、&lt;list&gt;、&lt;map&gt;、&lt;memory&gt;、&lt;numeric&gt;、&lt;queue&gt;、&lt;set&gt;、&lt;stack&gt; 、&lt;utility&gt;。 STL 的优势 STL 是 C++ 的一部分，因此不用额外安装什么就可以直接使用，因为它被内建在编译器之内 STL 的一个重要特点是数据结构和算法的分离，尽管这是个简单的概念，但是这种分离使 STL 变得非常通用 开发人员一般可以不用思考 STL 具体的实现过程，只要能够熟练使用 STL 就可以了，这样可以把精力放在程序开发的其他方面 STL 具有高可重用性、高性能、高移植性、跨平台的优点 高移植性：如在项目 A 上使用 STL 编写的模块，可以直接移植到项目 B 上 跨平台：如用 Windows 的 Visual Studio 编写的代码，可以在 Mac OS 的 XCode 上直接编译 高性能：如 map 可以高效地从十万条记录里面查找出指定的记录，因为 map 是采用红黑树的变体实现的（红黑树是平横二叉树的一种） 高可重用性：STL 中几乎所有的代码都采用了类模板和函数模板的方式实现，这相比于传统的由函数和类组成的库来说提供了更好的代码重用机会 STL 的六大组件 容器（Containers）：各种数据结构，如 vector、list、deque、set、map 用来存放数据，STL 容器是一种类模板。 算法（Algorithms）：各种常用算法如 sort、search、copy、erase，从实现的角度来看，STL 算法是一种函数模板。 迭代器（Iterators）：扮演容器与算法之间的胶合剂，是所谓的 泛型指针，共有五种类型，以及其它衍生变体。从实现的角度来看，迭代器是一种将 Operators*、Operator-&gt;、Operator++、Operator-- 等相关操作予以重载的类模板。所有 STL 容器都附带有自己专属的迭代器，原生指针（Native pointer）也是一种迭代器。 仿函数（Functors）： 行为类似函数，可作为算法的某种策略（Policy），从实现的角度来看，仿函数是一种重载了 Operator() 的类或者类模板。一般函数指针可视为狭义的仿函数。 适配器（Adapters）：一种用来修饰容器（Containers）或仿函数（Functors）或迭代器（Iterators）接口的东西，例如：STL 提供的 Queue 和 Stack，虽然看似容器，但只能算是一种容器适配器，因为它们的底层完全借助 Deque，所有操作都由底层的 Deque 提供。改变 Functor 接口者，称为 Function Adapter；改变 Container 接口者，称为 Container Adapter；改变 Iterator 接口者，称为 Iterator Adapter。适配器的实现技术很难一言蔽之，必须逐一分析。 空间配置器（Allocators）：负责空间配置与管理，从实现的角度来看，配置器是一个实现了动态空间配置、空间管理、空间释放的类模板。 容器的基本概念在实际的开发过程中，数据结构本身的重要性不会逊于操作数据结构的算法的重要性，当程序中存在着对执行效率要求很高的部分时，数据结构的选择就显得更加重要。经典的数据结构数量有限，但是常常重复着一些为了实现向量、链表等结构而编写的代码，这些代码都十分相似，只是为了适应不同数据的变化而在细节上有所不同。STL 容器为此提供了这样的方便，它允许重复利用已有的实现构造自己的特定类型下的数据结构，通过设置一些模板，STL 容器对最常用的数据结构提供了支持，这些模板的参数允许指定容器中元素的数据类型，可以将许多重复而乏味的工作简化。容器部分主要由头文件 &lt;vector&gt;、&lt;list&gt;、&lt;deque&gt;、&lt;set&gt;、&lt;map&gt;、&lt;stack&gt;、&lt;queue&gt; 组成。对于常用的一些容器和容器适配器（可以看作由其它容器实现的容器），可以通过下表总结不同容器与相应头文件的对应关系。 容器 描述 实现头文件 向量 (vector) 连续内存的元素 &lt;vector&gt; 列表 (list) 由节点组成的双向链表，每个结点包含着一个元素 &lt;list&gt; 双队列 (deque) 连续内存的指向不同元素的指针所组成的数组 &lt;deque&gt; 集合 (set) 由节点组成的红黑树，每个节点都包含着一个元素，节点之间以某种作用于元素对的谓词排列，没有两个不同的元素能够拥有相同的次序 &lt;set&gt; 多重集合 (multiset) 允许存在两个次序相等的元素的集合 &lt;set&gt; 栈 (stack) 先进后出的值的排列 &lt;stack&gt; 队列 (queue) 先进先出的执的排列 &lt;queue&gt; 优先队列 (priority_queue) 元素的次序是由作用于所内存的值对上的某种谓词决定的一种队列 &lt;queue&gt; 映射 (map) 由 {键，值} 对组成的集合，以某种作用于键对上的谓词排列 &lt;map&gt; 多重映射 (multimap) 允许键对有相等的次序的映射 &lt;map&gt; 容器的简介容器可以用来管理一组元素，如下图所示： 容器的分类 序列式容器（Sequence Containers）：每个元素都有固定的位置，取决于插入时机和地点，与元素的值无关，如 vector、deque、list 关联式容器（Associated Containers）：元素位置取决于特定的排序规则，与插入的顺序无关，如 set、multiset、map、multimap 算法的基本概念算法的简介函数库对数据类型的选择对其可重用性起着至关重要的作用。举例来说，一个求方根的函数，在使用浮点数作为其参数类型的情况下的可重用性肯定比使用整型作为它的参数类性要高。而 C++ 通过模板的机制允许推迟对某些类型的选择，直到真正想使用模板或者说对模板进行特化的时候，STL 就利用了这一点提供了相当多的算法。它是在一个有效的框架中完成这些算法的 —— 可以将所有的类型划分为少数的几类，然后就可以在模板的参数中使用一种类型替换掉同一种类中的其他类型。 算法的头文件STL 提供了大约 100 个实现算法的函数模板，比如算法 for_each 将为指定序列中的每一个元素调用指定的函数，stable_sort 以调用者所指定的规则对序列进行稳定性排序等等。这样一来，只要熟悉了 STL 之后，许多代码可以被大大地简化，只需要通过调用一两个算法模板，就可以完成所需要的功能。算法主要由头文件 &lt;algorithm&gt;、&lt;numeric&gt;、&lt;functional&gt; 组成。&lt;algorithm&gt; 是所有 STL 头文件中最大的一个，它是由一大堆函数模板组成的，可以认为每个函数在很大程度上都是独立的，其中常用到的功能范围涉及到比较、交换、查找、遍历、复制、修改、移除、反转、排序、合并操作等。&lt;numeric&gt; 的体积很小，只包括几个在序列上面进行简单数学运算的函数模板，包括加法和乘法在序列上的一些操作。&lt;functional&gt; 中则定义了一些类模板，用来声明函数对象。 迭代器的基本概念迭代器从作用上来说是最基本的部分。软件设计有一个基本原则，所有的问题都可以通过引进一个间接层来简化，这种简化在 STL 中就是用迭代器来完成的。概括来说，迭代器在 STL 中用来将算法和容器联系起来，起着一种黏和剂的作用。几乎 STL 提供的所有算法都是通过迭代器存取元素序列进行工作的，每一个容器都定义了其本身所专有的迭代器，用以存取容器中的元素。迭代器主要由头文件 &lt;utility&gt;、&lt;iterator&gt;、&lt;memory&gt; 组成。其中 &lt;utility&gt; 是一个很小的头文件，它包括了贯穿使用在 STL 中的几个模板的声明，&lt;iterator&gt; 中提供了迭代器 使用的许多方法，而对于 &lt;memory&gt; 描述起来则十分的困难，它以不同寻常的方式为容器中的元素分配内存空间，同时也为某些算法在执行期间产生的临时对象提供管理机制，&lt;memory&gt; 中最主要的是类模板 allocator，它负责产生所有容器的默认空间配置器（分配器）。 初识容器的使用指针是一种迭代器1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { int array[5] = {1, 2, 3, 4, 5}; int length = sizeof(array) / sizeof(int); int *p = array; for (int i = 0; i &lt; length; i++) { cout &lt;&lt; *(p++) &lt;&lt; \" \"; } return 0;} 程序运行输出的结果如下： 11 2 3 4 5 容器存放基础数据类型12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;void m_print(const int num) { cout &lt;&lt; num &lt;&lt; \" \";}int main() { // 定义容器 vector&lt;int&gt; v; // 插入数据 v.push_back(11); v.push_back(12); v.push_back(13); v.push_back(14); v.push_back(15); // 第一种方式：遍历容器 vector&lt;int&gt;::iterator itBegin = v.begin(); vector&lt;int&gt;::iterator itEnd = v.end(); while (itBegin != itEnd) { cout &lt;&lt; *(itBegin++) &lt;&lt; \" \"; } cout &lt;&lt; endl; // 第二种方式：遍历容器 for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; } cout &lt;&lt; endl; // 第三种方式：遍历容器 for_each(v.begin(), v.end(), m_print); return 0;} 程序运行输出的结果如下： 12311 12 13 14 15 11 12 13 14 15 11 12 13 14 15 容器存放自定义数据类型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class Person {public: Person(int age, string name) { this-&gt;age = age; this-&gt;name = name; } int getAge() { return this-&gt;age; } string getName() { return this-&gt;name; }private: int age; string name;};int main() { Person p1(23, \"Jim\"); Person p2(26, \"Tom\"); Person p3(29, \"Peter\"); // 定义容器 vector&lt;Person&gt; v; // 插入数据 v.push_back(p1); v.push_back(p2); v.push_back(p3); // 遍历容器 for (vector&lt;Person&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; \"age = \" &lt;&lt; it-&gt;getAge() &lt;&lt; \", name = \" &lt;&lt; it-&gt;getName() &lt;&lt; endl; // 或者 // cout &lt;&lt; \"age = \" &lt;&lt; (*it).getAge() &lt;&lt; \", name = \" &lt;&lt; (*it).getName() &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 123age = 23, name = Jimage = 26, name = Tomage = 29, name = Peter 容器存放自定义数据类型的指针1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class Person {public: Person(int age, string name) { this-&gt;age = age; this-&gt;name = name; } int getAge() { return this-&gt;age; } string getName() { return this-&gt;name; }private: int age; string name;};int main() { // 定义容器 vector&lt;Person *&gt; v; // 插入数据 v.push_back(new Person(23, \"Jim\")); v.push_back(new Person(26, \"Tom\")); v.push_back(new Person(29, \"Peter\")); // 遍历容器 for (vector&lt;Person *&gt;::iterator it = v.begin(); it != v.end(); it++) { cout &lt;&lt; \"age = \" &lt;&lt; (*it)-&gt;getAge() &lt;&lt; \", name = \" &lt;&lt; (*it)-&gt;getName() &lt;&lt; endl; // 或者 // cout &lt;&lt; \"age = \" &lt;&lt; (**it).getAge() &lt;&lt; \", name = \" &lt;&lt; (**it).getName() &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 123age = 23, name = Jimage = 26, name = Tomage = 29, name = Peter 容器之间的嵌套使用12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() { // 定义容器 vector&lt;int&gt; v1; vector&lt;int&gt; v2; vector&lt;int&gt; v3; vector&lt;vector&lt;int&gt;&gt; v; // 插入数据 for (int i = 0; i &lt; 5; i++) { v1.push_back(i + 1); v2.push_back(i + 6); v3.push_back(i + 11); } v.push_back(v1); v.push_back(v2); v.push_back(v3); // 遍历容器 for (vector&lt;vector&lt;int&gt;&gt;::iterator it1 = v.begin(); it1 != v.end(); it1++) { for (vector&lt;int&gt;::iterator it2 = (*it1).begin(); it2 != (*it1).end(); it2++) { cout &lt;&lt; *it2 &lt;&lt; \" \"; } cout &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1231 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"Linux 屏幕截图和剪贴板命令行工具","url":"/posts/9eb6789a.html","text":"前言版本说明 xclip：0.13 gnome-screenshot：3.26.0 截图工具gnome-screenshot 是一款 GNOME 命令行工具，它是一款用来对整个屏幕、一个特定的窗口或者用户所定义一些其他区域进行捕获的工具。该工具提供了几个其他的功能，包括对所捕获的截图的边界进行美化的功能。值得一提的是，gnome-screenshot 不适用于 KDE、Xfce 等 Linux 桌面环境。 截图工具的使用1234567891011121314# 捕捉整个屏幕$ gnome-screenshot# 捕捉当前Shell窗口$ gnome-screenshot -w# 捕捉指定区域$ gnome-screenshot -a# 延迟捕捉屏幕$ gnome-screenshot -d 5# 捕捉当前Shell窗口，并去除窗口的边框$ gnome-screenshot -w -b 12345# 区域截图，并将截图复制到剪贴板$ gnome-screenshot -acbp# 区域截图，并将截图输出到指定的文件$ gnome-screenshot -abpf screenshot.png 截图工具的参数说明123456789101112-c, --clipboard 将截图直接发送到剪贴板-w, --window 截取窗口，而不是整个屏幕-a, --area 截取屏幕的一个区域，而不是整个屏幕-b, --include-border 在截图中包含窗口边框-B, --remove-border 去除屏幕截图的窗口边框-p, --include-pointer 在截图中包含鼠标指针-d, --delay=秒 在指定延迟后截图[以秒计]-e, --border-effect=特效 添加到边框的特效（阴影、边框、老照片或无特效）-i, --interactive 交互设置选项-f, --file=文件名 将截图直接保存为该文件--version 打印版本信息并退出--display=显示 要使用的 X 显示 xclip 的安装功能说明xclip 是一个剪贴板的命令行实用工具，它可以从标准文件或文件中读取数据（文本、图片）并将其放置在剪贴板里，也可以将剪贴板里的数据（文本、图片）输出到标准文件或文件中。xclip 详细的功能说明如下，适用于 Debian/Ubuntu/CentOS/Arch 等主流的 Linux 发行版。 Accesses the cut-buffers Prints contents of selection to standard out Waits for selection requests in the background Supports the INCR mechanism for large transfers Reads data piped to standard in or files given as arguments Accesses the XA_PRIMARY, XA_SECONDARY or XA_CLIPBOARD selection Connects to the X display in $DISPLAY, or specified with -display host:0 依赖安装CentOS/Fedora 1# yum install -y libXmu libXmu-devel Debian/Ubuntu 1# apt-get install -y libx11-dev libxmu-headers libxt-dev libxmu-dev 编译安装12345678910111213141516# 克隆代码# git clone https://github.com/astrand/xclip.git# 进入源码目录# cd xclip# 预配置# autoreconf# ./configure# 编译# make# 安装# make install# make install.man 验证安装12345678# 查看版本号$ xclip -versionxclip version 0.13Copyright (C) 2001-2008 Kim Saunders et al.Distributed under the terms of the GNU GPL# 查看命令手册$ man xclip xclip 的使用示例图片的使用示例 将图片复制到剪贴板 12345# 第一步：区域截图，将截图输出到指定的文件$ gnome-screenshot -abpf screenshot.png# 第二步：将指定的图片复制到剪贴板$ xclip -selection clipboard -t image/png -i screenshot.png 将剪贴板的图片输出到指定的文件 12345# 第一步：区域截图，并将截图复制到剪贴板$ gnome-screenshot -acbp# 第二步：将剪贴板的图片输出到指定的文件$ xclip -selection clipboard -t image/png -o &gt; clipboard.png 完整的使用示例12345678910111213141516171819## Copy your uptime into the selection for pasting:$ uptime | xclip## Copy your password file for pasting:$ xclip /etc/passwd## Save some text you have Edit | Copied in a web browser:$ xclip -o -sel clip &gt; webpage.txt## Open a URL selected in an email client$ mozilla `xclip -o`## Copy XA_PRIMARY to XA_CLIPBOARD$ xclip -o | xclip -sel clip## In command mode in vim, select some lines of text, then press shift-:## for an ex prompt, and use this command to copy the selected lines of## text to the primary X selection:$ !xclip -f 值得一提的是，xclip 自身还提供了 xclip-copyfile、xclip-pastefile、xclip-cutfile 命令行工具，支持在不同的目录和机器之间拷贝和移动文件，详见：官方文档 VS Code 使用说明在 Linux 系统下，VS Code 的 MarkDown 粘贴插件，例如 Markdown Paste 底层使用了 xclip，且版本必须大于等于 0.13.0，否则这类插件无法正常将剪贴板里的图片粘贴到 MarkDown 文件里。 参考资料 Copy image from clipboard to file GNOME Screenshot can’t copy to clipboard in Ubuntu 18.04 How to copy image to clipboard, to paste to another application How to copy an image to the clipboard from a file using command line var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux"},{"title":"C++ 开发常用代码块之一","url":"/posts/b84a96ac.html","text":"日期处理获取时间戳1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;chrono&gt;using namespace std;// 获取时间戳（秒数）// dateTime: 日期时间字符串，格式：2021-01-08 21:27:00long getTimestamp(const string &amp;dateTime) { tm tm = {}; strptime(dateTime.c_str(), \"%Y-%m-%d %H:%M:%S\", &amp;tm); chrono::system_clock::time_point tp = chrono::system_clock::from_time_t(mktime(&amp;tm)); long milliseconds = chrono::duration_cast&lt;chrono::milliseconds&gt;(tp.time_since_epoch()).count(); return milliseconds / 1000;}int main() { long timestamp = getTimestamp(\"2021-01-08 21:27:00\"); cout &lt;&lt; \"timestamp = \" &lt;&lt; timestamp &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1timestamp = 1610112420 格式化当前时间12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;time.h&gt;using namespace std;// 格式化当前时间// 默认格式是: 2020-06-07 23:46:53string formatCurrentTime() { time_t rawtime; struct tm* info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, \"%Y-%m-%d %H:%M:%S\", info); string str(buffer); return str;}// 格式化当前时间// format: 格式字符串，例如 %Y-%m-%d %H:%M:%Sstring formatCurrentTime(string format) { time_t rawtime; struct tm* info; char buffer[80]; time(&amp;rawtime); info = localtime(&amp;rawtime); strftime(buffer, 80, format.c_str(), info); string str(buffer); return str;}int main() { cout &lt;&lt; formatCurrentTime() &lt;&lt; endl; cout &lt;&lt; formatCurrentTime(\"%Y-%m-%d\") &lt;&lt; endl;} 程序运行输出的结果如下： 122021-11-22 22:52:432021-11-22 计算指定的日期是星期几12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;sstream&gt;using namespace std;// 根据给定的日期，计算它是星期几// date: 日期字符串，格式是: 2021-12-01// 返回值：1, 2, 3, 4, 5, 6, 0, 其中 0 表示星期日int dayOfWeek(const string &amp;date) { char c; int y, m, d; stringstream(date) &gt;&gt; y &gt;&gt; c &gt;&gt; m &gt;&gt; c &gt;&gt; d; tm t = {0, 0, 0, d, m - 1, y - 1900}; mktime(&amp;t); return t.tm_wday;}// 根据给定的日期，判断是否为周末// date: 日期字符串，格式是: 2021-12-01bool isWeekendDays(const string &amp;date) { int wday = dayOfWeek(date); if (wday == 6 || wday == 0) { return true; } return false;}int main() { cout &lt;&lt; dayOfWeek(\"2022-01-07\") &lt;&lt; endl; cout &lt;&lt; dayOfWeek(\"2022-01-08\") &lt;&lt; endl; cout &lt;&lt; dayOfWeek(\"2022-01-09\") &lt;&lt; endl; cout &lt;&lt; dayOfWeek(\"2022-01-10\") &lt;&lt; endl; cout &lt;&lt; (isWeekendDays(\"2022-01-09\") ? \"true\" : \"false\") &lt;&lt; endl;} 程序运行输出的结果如下： 123455601true 计算两个日期之间的天数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#include &lt;iostream&gt;using namespace std;// 判断一个年份是否为闰年bool isLeap(int year) { return (year % 4 == 0 || year % 400 == 0) &amp;&amp; (year % 100 != 0);}// 计算特定年份的天数int daysOfYear(int year) { return isLeap(year) ? 366 : 365;}// 根据给定的日期，计算它在该年的第几天int dayOfYear(int year, int month, int day) { int DAY[12] = { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 }; if (isLeap(year)) { DAY[1] = 29; } for (int i = 0; i &lt; month - 1; ++i) { day += DAY[i]; } return day;}// 判断日期字符串是否合法，并分别取出日期中的年月日// date: 日期字符串，格式是: 20211201bool stringToDate(string date, int&amp; year, int&amp; month, int&amp; day) { year = atoi(date.substr(0, 4).c_str()); month = atoi(date.substr(4, 2).c_str()); day = atoi(date.substr(6, 2).c_str()); int DAY[12] = { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 }; if (isLeap(year)) { DAY[1] = 29; } return year &gt;= 0 &amp;&amp; month &lt;= 12 &amp;&amp; month &gt; 0 &amp;&amp; day &lt;= DAY[month - 1] &amp;&amp; day &gt; 0;}// 计算两个日期之间的天数// date1: 日期字符串，格式是: 20211201// date2: 日期字符串，格式是: 20211201// 当返回值为 -1 时，说明日期的格式不正确int daysBetween2Date(string date1, string date2) { int year1, month1, day1; int year2, month2, day2; if (!stringToDate(date1, year1, month1, day1) || !stringToDate(date2, year2, month2, day2)) { cout &lt;&lt; \"输入的日期格式不正确\"; return -1; } if (year1 == year2 &amp;&amp; month1 == month2) { return day1 &gt; day2 ? day1 - day2 : day2 - day1; } else if (year1 == year2) { int d1, d2; d1 = dayOfYear(year1, month1, day1); d2 = dayOfYear(year2, month2, day2); return d1 &gt; d2 ? d1 - d2 : d2 - d1; } else { // 确保year1年份比year2早 if (year1 &gt; year2) { swap(year1, year2); swap(month1, month2); swap(day1, day2); } // 计算第一个日期在该年还剩多少天 int d1, d2, d3; if (isLeap(year1)) { d1 = 366 - dayOfYear(year1, month1, day1); } else { d1 = 365 - dayOfYear(year1, month1, day1); } // 计算第二日期在当年中的第几天 d2 = dayOfYear(year2, month2, day2); // 计算两个年份相隔的天数 d3 = 0; for (int year = year1 + 1; year &lt; year2; year++) { if (isLeap(year)) d3 += 366; else d3 += 365; } return d1 + d2 + d3; }}int main() { int days = daysBetween2Date(\"20101111\", \"20111111\"); cout &lt;&lt; \"相差 \" &lt;&lt; days &lt;&lt; \" 天\" &lt;&lt; endl; int days2 = daysBetween2Date(\"20200202\", \"20200131\"); cout &lt;&lt; \"相差 \" &lt;&lt; days2 &lt;&lt; \" 天\" &lt;&lt; endl; int days3 = daysBetween2Date(\"20230712\", \"20050619\"); cout &lt;&lt; \"相差 \" &lt;&lt; days3 &lt;&lt; \" 天\" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123相差 365 天相差 2 天相差 6597 天 加载动态库加载动态库（.so）提示 下述示例代码，适用于 Linux 系统的 C++ 开发。 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;stdio.h&gt;#include &lt;dlfcn.h&gt;#include &lt;stdlib.h&gt;#include &lt;iostream&gt;using namespace std;int main(){ int a = 0; // 加载动态库 void *handle = dlopen(\"./libadd_c.so\", RTLD_LAZY); if(!handle) { printf(\"open lib error\\n\"); cout&lt;&lt;dlerror()&lt;&lt;endl; return -1; } // 定义函数指针类型 typedef int (*add_t)(int a, int b); // 调用动态库 add_t add = (add_t) dlsym(handle, \"add\"); if(!add) { cout&lt;&lt;dlerror()&lt;&lt;endl; dlclose(handle); return -1; } a = add(3, 4); printf(\"a = %d\\n\",a); // 释放动态库 dlclose(handle); return 0;} 加载动态链接库（.dll）提示 下述示例代码，适用于 Windows 系统的 C++ 开发。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;windows.h&gt;using namespace std;int main() { HINSTANCE hInstance; // 加载动态链接库 hInstance = LoadLibrary(\"./socketclient.dll\"); if (hInstance == NULL) { printf(\"LoadLibrary() 调用失败, ErrorCode: %d\", GetLastError()); return -1; } // 定义函数类型指针 typedef int (*CltSocketInit)(void** handle); // 调用动态链接库 CltSocketInit cltSocketInit = (CltSocketInit)GetProcAddress(hInstance, \"cltSocketInit\"); if (cltSocketInit != NULL) { void* handle = NULL; int result = cltSocketInit(&amp;handle); printf(\"result = %d\", result); } // 释放动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} 任务调度定时器提示 基于 C++ 11 实现等价于 Javascript 的 setTimeout() 和 setInterval() 函数。 timer.h 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;chrono&gt;#include &lt;atomic&gt;using namespace std;class Timer {public: typedef void(TimerFunction)();public: void setTimeout(TimerFunction, long delay); void setInterval(TimerFunction, long interval); void stop();private: atomic&lt;bool&gt; active{ true };};void Timer::setTimeout(TimerFunction function, long delay) { active = true; thread t([=]() { if (!active.load()) return; this_thread::sleep_for(chrono::milliseconds(delay)); if (!active.load()) return; function(); }); t.detach();}void Timer::setInterval(TimerFunction function, long interval) { active = true; thread t([=]() { while (active.load()) { this_thread::sleep_for(chrono::milliseconds(interval)); if (!active.load()) return; function(); } }); t.detach();}void Timer::stop() { active = false;} main.cpp 12345678910111213141516171819#include &lt;conio.h&gt;#include &lt;iostream&gt;#include \"timer.h\"using namespace std;void refreshConfig() { cout &lt;&lt; \"execute refresh config ...\" &lt;&lt; endl;}int main() { // 使用智能指针 unique_ptr&lt;Timer&gt; timer(new Timer()); Timer::TimerFunction* refreshFunc = refreshConfig; timer-&gt;setInterval(refreshConfig, 3000); timer-&gt;setTimeout(refreshConfig, 5000); _getch(); return 0;} 程序运行输出的结果如下： 12345execute refresh config ...execute refresh config ...execute refresh config ...execute refresh config ...execute refresh config ... 线程休眠sleep() 函数的功能是让程序的执行挂起一段时间，也就是等待一段时间再继续往下执行。 不同平台和不同编译器的区别 sleep() 函数在 Linux 平台的头文件是 unistd.h sleep() 函数在 Windows 平台的头文件是 windows.h sleep() 函数的名称是区分大小写的，有的编译器是大写，有的是小写 sleep() 函数休眠的时间，在 Windows 平台下是以 毫秒 为单位，而在 Linux 平台是以 秒 为单位 123456789101112131415// Windows平台的写法#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;windows.h&gt;int main(){ int a = 1; while (a) { printf(\"Welcome to songjiahao's blog\\n\"); Sleep(1000); } system(\"pause\"); return 0;} 文件处理创建文件夹提示 下述 C++ 代码兼容 Linux 与 Windows 平台，用于创建文件夹以及子文件夹 fileutil.h 123456789101112131415161718192021222324#pragma once#ifdef WIN32#include &lt;io.h&gt;#include &lt;direct.h&gt;#else#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#endif#ifdef WIN32#define ACCESS(fileName, accessMode) _access(fileName, accessMode)#define MKDIR(path) _mkdir(path)#else#define ACCESS(fileName, accessMode) access(fileName, accessMode)#define MKDIR(path) mkdir(path, S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH)#endif#include &lt;iostream&gt;#define MAX_PATH_LEN 256using namespace std;int32_t createDirectory(const string &amp;dirPath); fileutil.cpp 123456789101112131415161718192021222324#include \"fileutil.h\"// 根据目录路径，从左到右依次判断目录是否存在，不存在则创建// 注意：最后一个如果是目录的话，则必须加上 '\\\\' 或者 '/'// 示例: /usr/local/scripts/int32_t createDirectory(const string &amp;dirPath) { uint32_t dirPathLen = dirPath.length(); if (dirPathLen &gt; MAX_PATH_LEN) { return -1; } char tmpDirPath[MAX_PATH_LEN] = {0}; for (uint32_t i = 0; i &lt; dirPathLen; ++i) { tmpDirPath[i] = dirPath[i]; if (tmpDirPath[i] == '\\\\' || tmpDirPath[i] == '/') { if (ACCESS(tmpDirPath, 0) != 0) { int32_t ret = MKDIR(tmpDirPath); if (ret != 0) { return ret; } } } } return 0;} 字符串处理分割字符串1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;// 分割字符串// str: 要分割的字符串// delim: 分割字符vector&lt;string&gt; split(const string &amp;str, const char &amp;delim = ' ') { vector&lt;string&gt; tokens; size_t lastPos = str.find_first_not_of(delim, 0); size_t pos = str.find(delim, lastPos); while (lastPos != string::npos) { tokens.emplace_back(str.substr(lastPos, pos - lastPos)); lastPos = str.find_first_not_of(delim, pos); pos = str.find(delim, lastPos); } return tokens;}int main() { vector&lt;string&gt; strResult = split(\"Hello,World,!\", ','); for (auto it = strResult.begin(); it != strResult.end(); it++) { cout &lt;&lt; *it &lt;&lt; \" \"; }} 程序运行输出的结果如下： 1Hello World ! 去除字符串两边的空格1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(\" \")); str.erase(str.find_last_not_of(\" \") + 1);}int main() { string str = \" hello \"; trim(str); cout &lt;&lt; \"str=\" &lt;&lt; str &lt;&lt; endl; string str2 = str + \"world\"; cout &lt;&lt; \"str2=\" &lt;&lt; str2 &lt;&lt; endl;} 程序运行输出的结果如下： 12str=hellostr2=helloworld 判断字符串是否为空串12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;using namespace std;// 去除字符串两边的空格void trim(string &amp;str) { if (str.empty()) { return; } str.erase(0, str.find_first_not_of(\" \")); str.erase(str.find_last_not_of(\" \") + 1);}// 判断字符串是否为空串// \"\" -&gt; true// \" \" -&gt; true// \"a\" -&gt; false// \" a \" -&gt; falsebool empty(const string &amp;str) { if (str.empty()) { return true; } string strTemp = str; trim(strTemp); return strTemp.length() == 0;}int main() { string str1 = \"\"; string str2 = \" \"; string str3 = \"a\"; string str4 = \" a \"; cout &lt;&lt; (empty(str1) ? \"true\" : \"false\") &lt;&lt; endl; cout &lt;&lt; (empty(str2) ? \"true\" : \"false\") &lt;&lt; endl; cout &lt;&lt; (empty(str3) ? \"true\" : \"false\") &lt;&lt; endl; cout &lt;&lt; (empty(str4) ? \"true\" : \"false\") &lt;&lt; endl;} 程序运行输出的结果如下： 1234truetruefalsefalse 转换字符集编码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 // Gb2312 转换 Utf8 编码// iInLen的长度不包括'\\0'字符，应该用strlen()，返回值是处理后的sOut长度int Gb2312ToUtf8(char *sOut, int iMaxOutLen, const char *sIn, int iInLen) { char *pIn = (char *) sIn; char *pOut = sOut; size_t ret; size_t iLeftLen = iMaxOutLen; iconv_t cd; cd = iconv_open(\"utf-8\", \"gb2312\"); if (cd == (iconv_t) -1) { return -1; } size_t iSrcLen = iInLen; ret = iconv(cd, &amp;pIn, &amp;iSrcLen, &amp;pOut, &amp;iLeftLen); if (ret == (size_t) -1) { iconv_close(cd); return -1; } iconv_close(cd); return (iMaxOutLen - iLeftLen);}// Utf8 转换 Gb2312 编码// iInLen的长度不包括'\\0'字符，应该用strlen()，返回值是处理后的sOut长度int Utf8ToGb2312(char *sOut, int iMaxOutLen, const char *sIn, int iInLen) { char *pIn = (char *) sIn; char *pOut = sOut; size_t ret; size_t iLeftLen = iMaxOutLen; iconv_t cd; cd = iconv_open(\"gb2312\", \"utf-8\"); if (cd == (iconv_t) -1) { return -1; } size_t iSrcLen = iInLen; ret = iconv(cd, &amp;pIn, &amp;iSrcLen, &amp;pOut, &amp;iLeftLen); if (ret == (size_t) -1) { iconv_close(cd); return -1; } iconv_close(cd); return (iMaxOutLen - iLeftLen);} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ 代码块"},{"title":"C++ 进阶基础之四","url":"/posts/791ffdcd.html","text":"大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 标准 I/O 流的介绍I/O 流的概念程序的输入指的是从输入文件将数据传送给程序，程序的输出指的是从程序将数据传送给输出文件。C++ 的输入输出包含以下三个方面的内容： 对系统指定的标准设备的输入和输出：即从键盘输入数据，输出到显示器屏幕。这种输入输出称为标准的输入输出，简称 标准 I/O。 以外存磁盘文件为对象进行输入和输出：即从磁盘文件输入数据，数据输出到磁盘文件。以外存文件为对象的输入输出称为文件的输入输出，简称 文件 I/O。 对内存中指定的空间进行输入和输出：通常指定一个字符数组作为存储空间（实际上可以利用该内存空间存储任何信息）。这种输入和输出称为字符串输入输出，简称 串 I/O。 I/O 流类库的结构在 C 语言中，用 printf 和 scanf 进行输入输出，往往不能保证所输入输出的数据是可靠的安全的。在 C++ 的输入输出中，编译系统对数据类型进行严格的检查，凡是类型不正确的数据都不可能通过编译。因此 C++ 的 I/O 操作是类型安全（Type Safe）的。C++ 的 I/O 操作是可扩展的，不仅可以用来输入输出标准类型的数据，也可以用于用户自定义类型的数据。C++ 通过 I/O 类库来实现丰富的 I/O 功能。这样使 C++ 的输人输出明显地优于 C 语言中的 printf 和 scanf，但是也为之付出了代价，C++ 的 I/O 系统因此变得比较复杂，要掌握许多使用细节。C++ 编译系统提供了用于输入输出的 iostream 类库。iostream 这个单词是由 3 个部分组成的，即 i-o-stream，意为输入输出流。在 iostream 类库中包含许多用于输入输出的类，如下图所示： ios 是抽象基类，由它派生出 istream 类和 ostream 类，两个类名中第 1 个字母 i 和 o 分别代表输入（input）和输出（output）。istream 类支持输入操作，ostream 类支持输出操作，iostream 类支持输入输出操作。iostream 类是从 istream 类和 ostream 类通过多重继承而派生的类，其继承层次如下图所示： iostream 类库中不同的类的声明被放在不同的头文件中，用户在自己的程序中用 #include 命令包含了有关的头文件，这就相当于在本程序中声明了所需要用到的类。可以换 — 种说法：头文件是程序与类库的接口。iostream 类库的接口分别由不同的头文件来实现，常用的头文件如下： strstream：用于字符串流 I/O fstream：用于实现文件的 I/O 操作 iomanip：在使用格式化 I/O 时，应包含此头文件 iostream：包含了对输入输出流进行操作所需的基本信息 stdiostream：用于混合使用 C 语言和 C++ 的 I/O 机制，例如希望将 C 语言程序转变为 C++ 程序 在 iostream 头文件中定义的类有 ios，istream，ostream，iostream，istream_withassign，ostream_withassign，iostream_withassign 等。在 iostream 头文件中不仅定义了相关的类，还定义了 4 种标准 I/O 对象，如下所示： &lt;&lt; 和 &gt;&gt; 本来在 C++ 中是被定义为左位移运算符和右位移运算符的，由于在 iostream 头文件中对它们进行了重载，使它们能用作标准类型数据的输入和输出运算符。所以，在使用到它们的程序中必须用 #include &lt;iostream&gt; 命令将其包含到程序中。在 iostream 中只对 &lt;&lt; 和 &gt;&gt; 运算符用于标准类型数据的输入输出进行了重载，但未对用户声明的类型数据的输入输出进行重载。如果用户声明了新的类型，并希望用 &lt;&lt; 和 &gt;&gt; 运算符对其进行输入输出，则需要按照 C++ 的运算符重载规则来做。 标准 I/O 流的使用标准输入流的简单使用标准输入流对象 cin 的常用函数如下： cin.get()，一次只能读取一个字符 cin.get(一个参数)，读一个字符 cin.get(多个参数)，可以读字符串 cin.getline()，读取整行字符串，包括读取空格字符 cin.ignore()，用于忽略或清除输入缓冲区中的一个或多个字符 cin.putback()，将数据放回缓冲区 cin.peek()，返回值是一个 char 型的字符，即指针指向的当前字符，但它只是观测指针停留在当前的位置并不后移；如果要访问的字符是文件结束符，则函数的返回值是 EOF 或者 -1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;iostream&gt;using namespace std;void input1() { int number; cout &lt;&lt; \"请输入一个数字: \"; cin &gt;&gt; number; cout &lt;&lt; \"输入的数字是: \" &lt;&lt; number &lt;&lt; endl;}void input2() { char buf[1024]; cout &lt;&lt; \"请输入字符串: \"; cin &gt;&gt; buf; // 当遇到空格符时，会停止接收数据输入 cout &lt;&lt; \"输入的字符串: \"; cout &lt;&lt; buf &lt;&lt; endl;}void input3() { char ch; cout &lt;&lt; \"请输入字符串: \"; while ((ch = cin.get()) != EOF) // 如果缓冲区没有数据，则程序会阻塞 { cout &lt;&lt; ch &lt;&lt; \" \"; }}void input4() { char a, b, c; cout &lt;&lt; \"请输入字符串: \"; cin.get(a); // 如果缓冲区没有数据，则程序会阻塞 cin.get(b); cin.get(c); cout &lt;&lt; a &lt;&lt; b &lt;&lt; c;}void input5() { char buf[256]; cout &lt;&lt; \"请输入字符串: \"; cin.getline(buf, 256); // 当遇到空格符时，不会停止接收数据输入 cout &lt;&lt; buf &lt;&lt; endl;}void input6() { char buf1[256]; char buf2[256]; cout &lt;&lt; \"请输入字符串:\"; // 例如输入：abc efghi cin &gt;&gt; buf1; cin.ignore(2); // 忽略缓冲区的数据 cin.getline(buf2, 256); cout &lt;&lt; buf1 &lt;&lt; endl; cout &lt;&lt; buf2 &lt;&lt; endl;}void input7() { char buf1[256]; char buf2[256]; cout &lt;&lt; \"请输入字符串:\"; // 例如输入：abc efghi cin &gt;&gt; buf1; cin.ignore(2); int num = cin.peek(); // 查看缓冲区是否有数据 cout &lt;&lt; num &lt;&lt; endl; cin.getline(buf2, 256); cout &lt;&lt; buf1 &lt;&lt; endl; cout &lt;&lt; buf2 &lt;&lt; endl;}void input8() { // 分开处理输入的整数和字符 cout &lt;&lt; \"Please, enter a number or a word: \"; char c = std::cin.get(); if ((c &gt;= '0') &amp;&amp; (c &lt;= '9')) { int n; cin.putback(c); // 将数据放回缓冲区 cin &gt;&gt; n; cout &lt;&lt; \"You entered a number: \" &lt;&lt; n &lt;&lt; '\\n'; } else { char ch; cin.putback(c); // 将数据放回缓冲区 cin.get(ch); cout &lt;&lt; \"You entered a character: \" &lt;&lt; ch &lt;&lt; '\\n'; }} 标准输出流的简单使用标准输出流对象 cout 的常用函数如下： cout.flush() cout.put() cout.write() cout.width() cout.fill() cout.setf() 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;iomanip&gt;using namespace std;void output1() { cout.put('h').put('e').put('l').put('l').put('o').put('\\n');}void output2() { char* str = \"hello world\\n\"; cout.write(str, strlen(str));}void output3() { // 第一种方式：使用流对象的成员函数 cout &lt;&lt; \"&lt;Start&gt;\"; cout.width(30); cout.fill('*'); cout.setf(ios::showbase); cout.setf(ios::internal); cout &lt;&lt; hex &lt;&lt; 123 &lt;&lt; \"&lt;End&gt;\\n\";}void output4() { // 第二种方式：使用控制符 cout &lt;&lt; \"&lt;Start&gt;\" &lt;&lt; setw(30) &lt;&lt; setfill('*') &lt;&lt; setiosflags(ios::showbase) &lt;&lt; setiosflags(ios::internal) &lt;&lt; hex &lt;&lt; 123 &lt;&lt; \"&lt;End&gt;\\n\";}int main() { output1(); output2(); output3(); output4(); return 0;} 程序运行输出的结果如下： 1234hellohello world&lt;Start&gt;0x**************************7b&lt;End&gt;&lt;Start&gt;0x**************************7b&lt;End&gt; 文件 I/O 流的简单使用以普通的方式读写文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include \"fstream\"using namespace std;void writeFile() { // 打开文件 char* fname = \"D:/file.txt\"; ofstream fout(fname); if (fout) { fout &lt;&lt; \"Hello World\" &lt;&lt; endl; fout.flush(); fout.close(); }}void readFile() { // 读取文件 char ch; char* fname = \"D:/file.txt\"; ifstream fin(fname); if (fin) { while (fin.get(ch)) { cout &lt;&lt; ch; } fin.close(); }}void writeFileApp() { // 以追加的方式打开文件 char* fname = \"D:/file.txt\"; ofstream fout(fname, ios::app); if (fout) { fout &lt;&lt; \"What\" &lt;&lt; endl; fout.flush(); fout.close(); }}int main() { writeFile(); readFile(); writeFileApp(); readFile(); return 0;} 程序运行输出的结果如下： 123Hello WorldHello WorldWhat 以二进制的方式读写文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;iostream&gt;#include \"fstream\"using namespace std;class Teacher {public: Teacher() { age = 33; strcpy(name, \"\"); } Teacher(int _age, char* _name) { age = _age; strcpy(name, _name); } void print() { cout &lt;&lt; \"age:\" &lt;&lt; age &lt;&lt; \", name:\" &lt;&lt; name &lt;&lt; endl; }private: int age; char name[32];};int main() { char* fname = \"D:/file.dat\"; ofstream fout(fname, ios::binary); if (!fout) { cout &lt;&lt; \"打开文件失败\" &lt;&lt; endl; return 0; } // 将类对象写入二进制文件（序列化） Teacher t1(23, \"Jim\"); Teacher t2(26, \"Tom\"); fout.write((char*)&amp;t1, sizeof(Teacher)); fout.write((char*)&amp;t2, sizeof(Teacher)); fout.flush(); fout.close(); ifstream fin(fname); if (!fin) { cout &lt;&lt; \"打开文件失败\" &lt;&lt; endl; return 0; } // 从二进制文件读取类对象（反序列化） Teacher tmp; fin.read((char*)&amp;tmp, sizeof(Teacher)); tmp.print(); fin.read((char*)&amp;tmp, sizeof(Teacher)); tmp.print(); fin.close(); return 0;} 程序运行输出的结果如下： 12age:23, name:Jimage:23, name:Jim var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 进阶基础之三","url":"/posts/35cd91d3.html","text":"大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 类型转换类型转换的语法 C 语言风格的强制类型转换（Type Cast）很简单，不管什么类型的转换，语法都是：TYPE b = (TYPE) a C++ 风格的类型转换，提供了 4 种类型转换操作符来应对不同场合的应用 const_cast：去除变量的 const 只读属性 reinterpreter_cast：重新解释类型（强制类型转换） static_cast：静态类型转换，如 int 转换成 char dynamic_cast：动态类型转换，如父类和子类之间的多态类型转换 C++ 4 种类型转换的语法：TYPE B = static_cast&lt;TYPE&gt; (a) 类型转换的一般性介绍一般性介绍： a) const_cast&lt;&gt;()：去除变量的 const 只读属性 b) reinterpret_cast&lt;&gt;()：重新解释类型，不同类型之间会进行强制类型转换 c) dynamic_cast&lt;&gt;()：动态类型转换，安全的基类和派生类之间转换，运行时会做类型检查 d) static_cast&lt;&gt;()：静态类型转换，编译的时候 C++ 编译器会做类型检查，基本类型都能转换，但是不能转换指针类型（多态除外） 一般性结论： a) 在 C 语言中，不能隐式类型转换的，在 C++ 中可以用 reinterpret_cast&lt;&gt;() 进行强行类型解释 b) 在 C 语言中，能隐式类型转换的，在 C++ 中可用 static_cast&lt;&gt;() 进行类型转换，因为 C++ 编译器在编译的时候，一般都可以顺利通过类型检查 c) static_cast&lt;&gt;() 和 reinterpret_cast&lt;&gt;() 基本上把 C 语言中的强制类型转换功能给覆盖了，但 reinterpret_cast&lt;&gt;() 很难保证代码的移植性 类型转换的简单使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#include &lt;iostream&gt;using namespace std;class Tree {};class Animal {public: virtual void cry() = 0;};class Dog : public Animal {public: void cry() override { cout &lt;&lt; \"dog cry ...\" &lt;&lt; endl; } void watchHome() { cout &lt;&lt; \"dog watch home\" &lt;&lt; endl; }};class Cat : public Animal {public: void cry() override { cout &lt;&lt; \"cat cry ...\" &lt;&lt; endl; } void playBall() { cout &lt;&lt; \"cat play ball ...\" &lt;&lt; endl; }};void playAnimal(Animal *animal) { animal-&gt;cry(); // 动态类型转换，将父类转换为子类，运行时会做类型检查 Dog *dog = dynamic_cast&lt;Dog *&gt;(animal); if (dog != NULL) { dog-&gt;watchHome(); } Cat *cat = dynamic_cast&lt;Cat *&gt;(animal); if (cat != NULL) { cat-&gt;playBall(); }}void printBuf(const char *buf) { // const_cast 去除变量的 const 只读属性 char *m_buf = const_cast&lt;char *&gt;(buf); m_buf[0] = 'b'; cout &lt;&lt; buf &lt;&lt; endl; cout &lt;&lt; m_buf &lt;&lt; endl;}void printBuf2() { // 定义指针指向一个常量，这里的常量的内存空间不可以更改 char* buf = \"aaaaa\"; // const_cast 去除变量的 const 只读属性 char* m_buf = const_cast&lt;char*&gt;(buf); // 此时若更改指针所指向的内存空间，会带来灾难性的后果 m_buf[0] = 'b'; cout &lt;&lt; buf &lt;&lt; endl; cout &lt;&lt; m_buf &lt;&lt; endl;}int main() { char *p1 = \"hello\"; double pi = 3.1415926; // 静态类型转换，编译的时候 C++ 编译器会做类型检查 int num1 = static_cast&lt;int&gt;(pi); cout &lt;&lt; \"num1 = \" &lt;&lt; num1 &lt;&lt; endl; // 静态类型转换，基本类型都能转换，但是不能转换指针类型（多态除外） // int* p2 = static_cast&lt;int*&gt;(p1); // 错误写法，C++ 编译器编译失败 // 重新解释类型，不同类型之间会进行强制类型转换，包括转换指针类型 int *p2 = reinterpret_cast&lt;int *&gt;(p1); cout &lt;&lt; \"p2 = \" &lt;&lt; p2 &lt;&lt; endl; // 去除变量的 const 只读属性 char buf[] = \"aaaaa\"; printBuf(buf); // printBuf2(); // 动态类型转换，基类和派生类之间转换，运行时会做类型检查 Dog dog; Cat cat; playAnimal(&amp;dog); playAnimal(&amp;cat); // 多态的其他使用场景 Animal *pAnimal = NULL; pAnimal = &amp;dog; pAnimal = static_cast&lt;Animal *&gt;(&amp;dog); // 编译通过 pAnimal-&gt;cry(); pAnimal = reinterpret_cast&lt;Animal *&gt;(&amp;dog); // 编译通过 pAnimal-&gt;cry(); Tree tree; // pAnimal = static_cast&lt;Animal*&gt;(&amp;tree); // 错误写法，C++ 编译器编译失败 pAnimal = reinterpret_cast&lt;Animal *&gt;(&amp;tree); // 编译通过 return 0;} 程序运行输出的结果如下： 12345678910num1 = 3p2 = 005661B8baaaabaaaadog cry ...dog watch homecat cry ...cat play ball ...dog cry ...dog cry ... 使用总结： 一般情况下，不建议进行类型转换，应该避免进行类型转换 要清楚地知道：要转换的变量，类型转换前是什么类型，类型转换后是什么类型，转换后有什么后果 异常处理机制 异常的介绍： 异常是一种程序控制机制，与函数机制独立和互补 函数是一种以栈结构展开的上下函数衔接的程序控制系统，而异常是另一种控制结构，它依附于栈结构，却可以同时设置多个异常类型作为捕获条件，从而实现以类型匹配在栈机制中跳跃回馈 异常设计目的： 栈机制是一种高度节律性的控制机制，面向对象编程却要求对象之间有方向、有目的的控制传动，从一开始，异常就是冲着改变程序控制结构，以适应面向对象程序更有效地工作这个主题，而不是仅为了进行错误处理 异常设计出来之后，却发现在错误处理方面获得了最大的好处 异常处理的基本思想传统错误处理机制传统的程序错误处理机制，是通过函数返回值来处理错误。 异常处理的基本思想 异常跨越了函数，并超脱于函数机制，决定了其对函数的跨越式回跳 C++ 的异常处理机制使得异常的引发和异常的处理不必在同一个函数中，这样底层的函数可以着重解决具体问题，而不必过多的考虑异常的处理，上层调用者可以在适当的位置设计对不同类型异常的处理 异常是专门针对抽象编程中的一系列错误进行处理的，C++ 中不能借助函数机制，因为栈结构的本质是先进后出，依次访问，无法进行跳跃，但错误处理的特征却是遇到错误信息就想要转到若干级之上进行重新尝试，如图所示： C++ 异常的基础使用异常的基本语法 a) 若有异常则通过 throw 操作创建一个异常对象并抛掷 b) 将可能抛出异常的程序段嵌在 try 块之中，控制通过正常的顺序执行到达 try 语句，然后执行 try 代码块内的保护段 c) 如果在保护段执行期间没有引起异常，那么跟在 try 代码块后的 catch 子句就不会执行，程序从 try 代码块后跟随的最后一个 catch 子句后面的语句将继续执行下去 d) catch 子句按其在 try 代码块后出现的顺序被检查，匹配到的 catch 子句将捕获并处理异常（或继续抛掷异常） e) 如果匹配的异常处理器未被找到，则函数 terminate() 将被自动调用，其缺省功能是调用函数 abort() 终止程序的运行 f) 处理不了的异常，可以在 catch 子句的最后一个分支，使用 throw 语法，向上抛掷异常 异常的简单使用案例一123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;int divide(int x, int y) { if (0 == y) { throw y; // 抛出 int 类型的异常 } return x / y;}int main() { try { int result = divide(5, 0); cout &lt;&lt; \"result = \" &lt;&lt; result &lt;&lt; endl; } catch (int e) { cout &lt;&lt; e &lt;&lt; \", 被除数不能为零\" &lt;&lt; endl; } // 会捕获所有未被捕获的异常，必须最后出现 catch (...) { throw \"发生未知的异常 ...\"; } cout &lt;&lt; \"程序正常结束运行\" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 120, 被除数不能为零程序正常结束运行 异常的简单使用案例二异常机制与函数机制互不干涉，但捕捉的方式是基于类型匹配。异常捕捉相当于函数返回类型的匹配，而不是函数参数的匹配，所以异常捕捉不用考虑一个抛掷中的多种数据类型匹配问题。异常捕捉是严格按照类型匹配的，它的类型匹配之苛刻程度可以和模板的类型匹配相媲美。它不允许相容类型的隐式转换，比如，抛掷 char 类型的异常，用 int 类型就捕捉不到对应的异常。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;class A {};class B {};int main() { try { int a; int i = 0; double d = 2.3; char str[20] = \"Hello\"; cout &lt;&lt; \"Please input a exception number: \"; cin &gt;&gt; a; switch (a) { case 1: throw i; case 2: throw d; case 3: throw str; case 4: throw A(); case 5: throw B(); default: cout &lt;&lt; \"No exception throws here.\\n\"; } } catch (int) { cout &lt;&lt; \"int exception.\\n\"; } catch (double) { cout &lt;&lt; \"double exception.\\n\"; } catch (char*) { cout &lt;&lt; \"char* exception.\\n\"; } catch (A) { cout &lt;&lt; \"class A exception.\\n\"; } catch (B) { cout &lt;&lt; \"class B exception.\\n\"; } cout &lt;&lt; \"That's ok.\\n\"; return 0;} 程序运行输出的结果如下： 123Please input a exception number: 3char* exception.That's ok. 异常在继承中的使用案例 MyException.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#pragma once#include &lt;iostream&gt;using namespace std;// 异常抽象类class SizeException {public: // 纯虚函数 virtual void printErr() = 0;public: int getSize() { return this-&gt;size; }protected: int size = 0;};class NegativeException : public SizeException {public: NegativeException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; \"数组大小不能小于零, 当前大小为 \" &lt;&lt; this-&gt;size &lt;&lt; endl; }};class TooBigException : public SizeException {public: TooBigException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; \"数组大小太大, 当前大小为 \" &lt;&lt; this-&gt;size &lt;&lt; endl; }};class ZeroException : public SizeException {public: ZeroException(int size) { this-&gt;size = size; } void printErr() { cout &lt;&lt; \"数组大小不允许为零\" &lt;&lt; endl; }}; MyArray.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#pragma once#include &lt;iostream&gt;#include \"MyException.h\"using namespace std;class MyArray {public: // 构造函数 MyArray(int size) { // 数组初始化大小检查，大小不合法则抛出异常 if (size &lt; 0) { throw NegativeException(size); } else if (size == 0) { throw ZeroException(size); } else if (size &gt; this-&gt;m_max_size) { throw TooBigException(size); } this-&gt;m_size = size; this-&gt;m_space = new int[size]; } // 拷贝构造函数 MyArray(const MyArray&amp; obj) { // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new int[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } } // 析构函数 ~MyArray() { if (this-&gt;m_space) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_size = 0; } }public: // 使用类成员函数，重载运算符 \"[]\" int&amp; operator[](int index) { return this-&gt;m_space[index]; } // 使用类成员函数，重载运算符 \"=\" MyArray&amp; operator=(const MyArray&amp; obj) { // 释放原本的内存空间 if (this-&gt;m_space) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_size = 0; } // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new int[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } return *this; } // 使用友元函数，重载运算符 \"&lt;&lt;\" friend ostream&amp; operator&lt;&lt;(ostream&amp; out, const MyArray&amp; obj);public: int getsize() { return m_size; }private: int* m_space; int m_size; int m_max_size = 1000;};// 使用友元函数，重载运算符 \"&lt;&lt;\"ostream&amp; operator&lt;&lt;(ostream&amp; out, const MyArray&amp; obj) { for (int i = 0; i &lt; obj.m_size; i++) { out &lt;&lt; obj.m_space[i] &lt;&lt; \", \"; } return out;} main.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142#include \"MyArray.h\"int main() { try { // 调用构造函数 MyArray array1(-6); // MyArray array1(5); // MyArray array1(0); // MyArray array1(2000); // 重载运算符 \"[]\" for (int i = 0; i &lt; array1.getsize(); i++) { array1[i] = 20 + i; } // 重载运算符 \"&lt;&lt;\" cout &lt;&lt; array1 &lt;&lt; endl; // 调用拷贝构造函数 MyArray array2 = array1; cout &lt;&lt; array2 &lt;&lt; endl; MyArray array3(3); array3[0] = 43; array3[1] = 56; array3[2] = 79; cout &lt;&lt; array3 &lt;&lt; endl; // 重载运算符 \"=\" array3 = array2; cout &lt;&lt; array3 &lt;&lt; endl; } // 使用引用捕获异常（多态） catch (SizeException&amp; e) { e.printErr(); } catch (...) { cout &lt;&lt; \"发生未知异常\" &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1数组大小不能小于零, 当前大小为 -6 C++ 异常的进阶使用栈解旋异常被抛出后，从进入 try 代码块起，到异常被抛掷前，这期间在栈上构造的所有对象，都会被自动析构，析构的顺序与构造的顺序相反。这一过程称为 栈解旋（unwinding）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;class Test {public: Test(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; \"构造函数被调用\" &lt;&lt; endl; } ~Test() { cout &lt;&lt; \"析构函数被调用\" &lt;&lt; endl; }private: int a; int b;};int divide(int x, int y) { Test t1(3, 4), t2(5, 6); if (0 == y) { throw y; // 抛出 int 类型的异常 } return x / y;}int main() { // divide(5, 0); 如果 divide() 函数的调用写在 try 代码块之外，那么 Test 类的析构函数不会自动被调用 try { int result = divide(5, 0); cout &lt;&lt; \"result = \" &lt;&lt; result &lt;&lt; endl; } catch (int e) { cout &lt;&lt; e &lt;&lt; \", 被除数不能为零\" &lt;&lt; endl; } catch (...) { cout &lt;&lt; \"发生未知的异常\"; } return 0;} 程序运行输出的结果如下： 12345构造函数被调用构造函数被调用析构函数被调用析构函数被调用0, 被除数不能为零 异常接口的声明 a) 为了加强程序的可读性，可以在函数声明中列出可能抛出的所有异常类型，例如：void func() throw (A, B, C , D) {}，这个函数 func（） 能够且只能抛出类型 A、B、C、D 及其子类型的异常 b) 如果一个函数抛出了它的异常接口声明所不允许抛出的异常，unexpected() 函数会被调用，该函数的默认行为是调用 terminate() 函数中止程序 c) 如果在函数声明中没有包含异常接口声明，则此函数可以抛掷任何类型的异常，例如：void func() {} d) 一个不抛掷任何类型异常的函数，可以声明为：void func() throw() {} 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;class A {};class B {};class C {};class D {};class F {};// 能够且只能抛出类型 A、B、C、D 及其子类型的异常void funcA() throw (A, B, C, D) { throw A();}// 不能抛出任何类型的异常void funcB() throw() {}// 可以抛出任何类型的异常void funcC() { throw B();}int main() { try { funcA(); } catch (...) { cout &lt;&lt; \"发生异常 ...\" &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1发生异常 ... 默认的异常处理器terminate () 函数在 C++ 中，异常是不可以忽略的，当异常找不到匹配的 catch 子句时，会调用系统的库函数 terminate()（在头文件中）；默认情况下，terminate（） 函数会调用标准 C 库函数 abort（） 使程序终止而退出。当调用 abort() 函数时，程序不会调用正常的终止函数，也就是说，全局对象和静态对象的析构函数不会执行，这就可能会导致内存泄漏。值得一提的是，在多线程程序中，各个 terminate() 函数是互相独立的，每个线程都有自己的 terminate() 函数。 set_terminate () 函数在 C++ 中，通过使用标准的 set_terminate() 函数，可以设置自己的 terminate（) 函数。自定义的 terminate() 函数不能有参数，而且返回值类型必须为 void。另外，terminate() 函数不能抛出异常，它必须终止程序。如果 terminate() 函数被调用，这就意味着问题已经无法解决了。 设置默认的异常处理器1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;using namespace std;// 自定义 terminate() 函数void myTerminate() { cout &lt;&lt; \"函数 myTerminate() 被 terminate() 调用!\" &lt;&lt; endl; exit(-1);}int divide(int x, int y) { return x / y;}int main() { // 设置默认的异常处理器 set_terminate(myTerminate); int x = 10, y = 0, result; try { if (y == 0) { throw \"被除数为零!\"; //抛出异常，由 terminate() 函数捕获 } else { result = x / y; } } // 不会被整型异常捕获 catch (int e) { cout &lt;&lt; \"捕获到整型异常!\" &lt;&lt; endl; } cout &lt;&lt; \"程序正常结束运行!\" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1函数 myTerminate() 被 terminate() 调用! C++ 提供的标准异常库标准异常库的介绍 标准异常库的使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;class Teacher {public: Teacher(int age) { if (age &gt; 100) { // 抛出标准库内的异常 throw out_of_range(\"年龄太大\"); } this-&gt;age = age; }private: int age;};// 继承标准库内的异常class MyException : public exception {public: MyException(const char *p) { this-&gt;m_p = p; } virtual const char *what() { cout &lt;&lt; \"MyException 类型的异常 : \" &lt;&lt; m_p &lt;&lt; endl; return m_p; }private: const char *m_p;};int main() { try { // Teacher teacher(105); throw MyException(\"发生自定义异常!\"); } catch (out_of_range e) { cout &lt;&lt; \"out_of_range 类型的异常 : \" &lt;&lt; e.what() &lt;&lt; endl; } catch (MyException &amp;e) { e.what(); } catch (...) { cout &lt;&lt; \"发生未知类型的异常!\" &lt;&lt; endl; } return 0;} 程序运行输出的结果如下： 1MyException 类型的异常 : 发生自定义异常! 异常类型和异常变量的生命周期 throw 异常是有类型的，可以使用数字、字符串、类对象，catch 严格按照类型进行匹配 throw 类对象类型的异常时： 如果捕获异常的时候，使用一个异常变量，则拷贝构造该异常变量 如果捕获异常的时候，使用了引用，则会使用 throw 时候的那个对象 捕获异常的时候，指针可以和引用 / 元素同时出现，但是引用与元素不能同时出现 结论：如果抛出的是类对象类型的异常，则使用引用进行异常捕获比较合适 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#include &lt;iostream&gt;using namespace std;class BadSrcType {};class BadDestType {};class BadProcessType {public: BadProcessType() { cout &lt;&lt; \"BadProcessType的构造函数被调用\" &lt;&lt; endl; } BadProcessType(const BadProcessType&amp; obj) { cout &lt;&lt; \"BadProcessType的拷贝构造函数被调用\" &lt;&lt; endl; } ~BadProcessType() { cout &lt;&lt; \"BadProcessType的析构函数被调用\" &lt;&lt; endl; }};void myStrcpy(char* to, char* from) { if (to == NULL) { throw BadDestType(); } if (from == NULL) { throw BadSrcType(); } if (*from == 'a') { throw BadProcessType(); } if (*from == 'b') { // 不建议使用这种写法 throw&amp; (BadProcessType()); } if (*from == 'c') { throw new BadProcessType; } while (*from != '\\0') { *to = *from; to++; from++; } *to = '\\0';}int main() { int ret = 0; char buf1[] = \"cbbcdefg\"; char buf2[1024] = { 0 }; try { myStrcpy(buf2, buf1); } catch (BadSrcType e) { cout &lt;&lt; \" BadSrcType 类型异常\" &lt;&lt; endl; } catch (BadDestType e) { cout &lt;&lt; \" BadDestType 类型异常\" &lt;&lt; endl; } /* // 结论1: 如果接收异常的时候，使用一个异常变量，则拷贝构造该异常变量 catch (BadProcessType e) { cout &lt;&lt; \" BadProcessType 类型异常\" &lt;&lt; endl; } // 结论2: 如果接收异常的时候，使用了引用，则会使用throw时候的那个对象 catch (BadProcessType&amp; e) { cout &lt;&lt; \" BadProcessType 类型异常\" &lt;&lt; endl; } // 结论3: 接收异常的时候，指针可以和引用/元素同时出现，但是引用与元素不能同时出现 catch (BadProcessType* e) { cout &lt;&lt; \" BadProcessType 类型异常\" &lt;&lt; endl; delete e; } // 结论4: 如果抛出的是类对象类型的异常，则使用引用进行异常捕获比较合适 */ catch (...) { cout &lt;&lt; \"未知 类型异常\" &lt;&lt; endl; } return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 进阶基础之二","url":"/posts/779107de.html","text":"大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 函数模板和类模板C++ 提供了函数模板（function template）。所谓函数模板，实际上是建立一个通用函数，其函数类型和形参类型不具体指定，用一个虚拟的类型来代表，这个通用函数就称为函数模板。凡是函数体相同的函数都可以用这个模板来代替，不必定义多个函数，只需在模板中定义一次即可。在调用函数时，系统会根据实参的类型来取代模板中的虚拟类型，从而实现不同函数的功能。 C++ 提供两种模板机制：函数模板、类模板 模板又称之为 泛型编程 模板把函数或类要处理的数据类型参数化，表现为参数的多态性，称为类属 模板用于表达逻辑结构相同，但具有数据元素类型不同的数据对象的通用行为 类属 —— 类型参数化，又称参数模板，使得程序（算法）可以从逻辑功能上抽象，把被处理的对象（数据）类型作为参数传递 函数模板函数模板的定义 模板声明的语法为：template &lt; 类型形式参数表 &gt;，例如 template &lt;typename T&gt; 类型形式参数表的语法为：typename T1 , typename T2 , …… , typename Tn 或者 class T1 , class T2 , …… , class Tn 函数模板的调用 myswap(a, b);：自动数据类型推导 myswap&lt;float&gt;(a, b);：显示类型调用（推荐） 函数模板的简单使用 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 函数定义void myswap(T &amp;a, T &amp;b) { T temp; temp = a; a = b; b = temp;}int main() { // 自动数据类型推导 int x = 1, y = 2; myswap(x, y); printf(\"x = %d, y = %d\\n\", x, y); // 自动数据类型推导 double n = 0.5, m = 0.8; myswap(n, m); printf(\"n = %f, m = %f\\n\", n, m); // 显示类型调用（推荐） char i = 'h', j = 'e'; myswap&lt;char&gt;(i, j); printf(\"n = %c, m = %c\\n\", i, j); return 0;} 程序运行输出的结果如下： 123x = 2, y = 1n = 0.800000, m = 0.500000n = e, m = h 函数模板做函数参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;iostream&gt;using namespace std;// 使用函数模板，实现数组排序template &lt;typename T1&gt;void arraySort(T1* array, int size, bool asc = true) { if (array == NULL || size == 0) { return; } T1 tmp; for (int i = 0; i &lt; size; i++) { for (int j = i + 1; j &lt; size; j++) { // 升序排序（从小到大） if (asc) { if (array[i] &gt; array[j]) { tmp = array[i]; array[i] = array[j]; array[j] = tmp; } } // 降序排序（从大到小） else { if (array[i] &lt; array[j]) { tmp = array[i]; array[i] = array[j]; array[j] = tmp; } } } }}// 使用函数模板，打印数组template &lt;typename T2&gt;void printArray(T2* array, int size) { for (int i = 0; i &lt; size; i++) { cout &lt;&lt; array[i] &lt;&lt; \" \"; } cout &lt;&lt; endl;}int main() { int array[] = { 32, 16, 29, 9, 43, 53, 23 }; int size = sizeof(array) / sizeof(*array); cout &lt;&lt; \"排序之前: \"; printArray&lt;int&gt;(array, size); arraySort&lt;int&gt;(array, size, false); cout &lt;&lt; \"排序之后: \"; printArray&lt;int&gt;(array, size); cout &lt;&lt; \"------------------------------\" &lt;&lt; endl; char array2[] = { 'c', 'z', 'h', 'i', 'q', 'm' }; int size2 = sizeof(array2) / sizeof(*array2); cout &lt;&lt; \"排序之前: \"; printArray&lt;char&gt;(array2, size2); arraySort&lt;char&gt;(array2, size2); cout &lt;&lt; \"排序之后: \"; printArray&lt;char&gt;(array2, size2); return 0;} 程序运行输出的结果如下： 12345排序之前: 32 16 29 9 43 53 23排序之后: 53 43 32 29 23 16 9------------------------------排序之前: c z h i q m排序之后: c h i m q z 函数模板与普通函数函数模板和普通函数的区别： a) 函数模板不允许自动类型转化 b) 普通函数能够进行自动类型转换 函数模板和普通函数的调用规则： a) C++ 编译器优先考虑使用普通函数 b) 如果函数模板可以产生一个更好的匹配，那么编译器会选择函数模板 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;void myswap(T&amp; a, T&amp; b) { T tmp; tmp = a; a = b; b = tmp; cout &lt;&lt; \"模板函数被调用\" &lt;&lt; endl;}void myswap(int a, char b) { cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; \", b = \" &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; \"普通函数被调用\" &lt;&lt; endl;}int main() { int a = 10; char c = 'z'; myswap(a, c); // 调用普通函数 myswap(c, a); // 调用普通函数，会进行隐式的类型转换 myswap(a, a); // 调用函数模板（本质是类型参数化），将严格地按照类型进行匹配，不会进行隐式的类型转换 return 0;} 程序运行输出的结果如下： 123456a = 10, b = z普通函数被调用a = 122, b =普通函数被调用模板函数被调用 函数模板与函数重载 a) 函数模板可以像普通函数一样被重载 b) 通过空模板实参列表的语法，可以限制编译器只使用函数模板匹配 c) 如果函数模板可以产生一个更好的匹配，那么编译器会选择函数模板 123456789101112131415161718192021222324252627282930313233343536#include \"iostream\"using namespace std;int Max(int a, int b){ cout &lt;&lt; \"int Max(int a, int b)\" &lt;&lt; endl; return a &gt; b ? a : b;}template &lt;typename T&gt;T Max(T a, T b){ cout &lt;&lt; \"T Max(T a, T b)\" &lt;&lt; endl; return a &gt; b ? a : b;}// 函数模板重载template &lt;typename T&gt;T Max(T a, T b, T c){ cout &lt;&lt; \"T Max(T a, T b, T c)\" &lt;&lt; endl; return Max(Max(a, b), c);}void main(){ int a = 1; int b = 2; cout &lt;&lt; Max(a, b) &lt;&lt; endl; // 当函数模板和普通函数都符合调用时,优先选择普通函数 cout &lt;&lt; Max&lt;&gt;(a, b) &lt;&lt; endl; // 通过空模板实参列表的语法，可以限制编译器只使用函数模板匹配 cout &lt;&lt; Max(3.0, 4.0) &lt;&lt; endl; // 如果函数模板产生更好的匹配 使用函数模板 cout &lt;&lt; Max(5.0, 6.0, 7.0) &lt;&lt; endl; // 函数模板的重载 cout &lt;&lt; Max('a', 100) &lt;&lt; endl; // 调用普通函数，可以进行隐式类型转换 return;} 程序运行输出的结果如下： 123456789101112int Max(int a, int b)2T Max(T a, T b)2T Max(T a, T b)4T Max(T a, T b, T c)T Max(T a, T b)T Max(T a, T b)7int Max(int a, int b)100 函数模板底层原理剖析 编译器并不是根据函数模板，产生能够处理任意参数的函数 编译器本质上是根据具体的调用类型，从函数模板产生不同的函数 编译器会对函数模板进行两次编译，在声明的地方对函数模板代码本身进行第一次编译，在调用的地方对参数替换后的函数模板代码进行第二次编译 类模板类模板与函数模板的定义和使用类似，在实际项目开发中，经常有两个或多个类，其功能是相同的，仅仅是数据类型不同，为了不重复定义功能相同的类，可以使用类模板来解决这类问题。 类模板的定义 类模板用于实现类所需数据的类型参数化 类模板在表示如数组、表、图等数据结构显得特别重要，这些数据结构的表示和算法不受所包含的元素类型的影响 在下述的所有代码中，template &lt;typename T&gt; 等价于 template &lt;class T&gt; 类模板的简单使用值得一提的是，在类模板中如果使用了构造函数，则必须遵守 C++ 类的构造函数的调用规则 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T t) { this-&gt;t = t; } T&amp; getT() { return this-&gt;t; }private: T t;};// 类模板做函数参数void printA(A&lt;int&gt;&amp; a) { cout &lt;&lt; a.getT() &lt;&lt; endl;}int main() { A&lt;int&gt; a(100); // 模板类是抽象的，需要声明具体的类型（模板参数列表），这里的 &lt;int&gt; 不能省略 cout &lt;&lt; a.getT() &lt;&lt; endl; A&lt;int&gt; a2(50); printA(a2); return 0;} 程序运行输出的结果如下： 1210050 类模板与派生类的使用普通类继承类模板在 C++ 中，类模板可以被普通类继承，普通类继承类模板时，需要声明父类具体的数据类型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T a) { this-&gt;a = a; } T&amp; getA() { return this-&gt;a; }public: T a;};// 普通类继承类模板，需要声明具体的类型（模板参数列表），这里的 &lt;int&gt; 不能省略class B : public A&lt;int&gt; {public: B(int a, int b) : A&lt;int&gt;(a) { this-&gt;b = b; } void printB() { cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; \", b = \" &lt;&lt; b &lt;&lt; endl; }public: int b;};int main() { A&lt;int&gt; a(100); cout &lt;&lt; a.getA() &lt;&lt; endl; B b(1, 3); b.printB(); return 0;} 程序运行输出的结果如下： 12100a = 1, b = 3 类模板继承类模板12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;using namespace std;// 模板声明template &lt;typename T&gt;// 类定义class A {public: A(T a) { this-&gt;a = a; } T&amp; getA() { return this-&gt;a; }public: T a;};// 模板声明template &lt;typename T&gt;// 类模板继承类模板class B : public A&lt;T&gt; {public: B(T a, T b) : A(a) { this-&gt;b = b; } T&amp; getB() { return this-&gt;b; }private: T b;};int main() { A&lt;int&gt; a(3); cout &lt;&lt; a.getA() &lt;&lt; endl; B&lt;double&gt; b(3.2, 4.5); cout &lt;&lt; b.getA() &lt;&lt; endl; cout &lt;&lt; b.getB() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12333.24.5 类模板函数的三种写法值得一提的是，企业项目开发中，建议使用第一种或者第三种方式，STL 库一般都采用第一种方式。 所有的类模板函数写在类的内部（第一种）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Complex {public: // 构造函数 Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b; } // 类成员函数 void print() { cout &lt;&lt; \"a = \" &lt;&lt; this-&gt;a &lt;&lt; \", b = \" &lt;&lt; this-&gt;b &lt;&lt; endl; } // 类成员函数，重载运算符 \"+\" Complex operator+(Complex&amp; c2) { Complex tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp; } // 友元函数，重载运算符 \"&lt;&lt;\" friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1) { cout &lt;&lt; \"a = \" &lt;&lt; c1.a &lt;&lt; \", b = \" &lt;&lt; c1.b; return out; } // 友元函数 friend Complex sub(Complex&amp; c1, Complex&amp; c2) { Complex tmp(c1.a - c2.a, c1.b - c2.b); return tmp; }private: T a; T b;};int main() { Complex&lt;int&gt; c1(1, 4); Complex&lt;int&gt; c2(3, 6); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; Complex&lt;int&gt; c4 = sub(c1, c2); cout &lt;&lt; c4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234a = 1, b = 4a = 3, b = 6a = 4, b = 10a = -2, b = -2 所有的类模板函数写在类的外部（第二种）所有的类模板函数写在类的外部（写在同一个 .cpp 文件），当使用友元函数重载了 &lt;&lt;、&gt;&gt; 运算符时，需要特别注意声明友元函数的写法 friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);。特别注意，除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，其他运算符的重载尽量都使用类成员函数。千万不要滥用友元函数，尤其类模板与友元函数一起使用的时候，这是因为需要使用怪异的语法来解决 C++ 编译器出现的错误，且不同的 C++ 编译器表现行为不一定一致。假设在类模板中滥用了友元函数，解决 C++ 编译问题的语法详见 图解分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;using namespace std;/********** START 解决类模板与友元函数滥用（非重载左移与右移运算符）时出现的编译问题 *********/template &lt;typename T&gt; class Complex;template &lt;typename T&gt; Complex&lt;T&gt; sub(Complex&lt;T&gt;&amp; c1, Complex&lt;T&gt;&amp; c2);/********** END 解决类模板与友元函数滥用（非重载左移与右移运算符）时出现的编译问题 *********/template &lt;typename T&gt;class Complex {public: // 构造函数 Complex(T a, T b); // 类成员函数 void print(); // 类成员函数，重载运算符 \"+\" Complex operator+(Complex&amp; c2); // 友元函数（滥用友元函数） friend Complex sub&lt;T&gt;(Complex&amp; c1, Complex&amp; c2); // 友元函数，重载运算符 \"&lt;&lt;\" friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);private: T a; T b;};// 构造函数template &lt;typename T&gt;Complex&lt;T&gt;::Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b;}// 类成员函数template &lt;typename T&gt;void Complex&lt;T&gt;::print() { cout &lt;&lt; \"a = \" &lt;&lt; this-&gt;a &lt;&lt; \", b = \" &lt;&lt; this-&gt;b &lt;&lt; endl;}// 类成员函数，重载运算符 \"+\"template &lt;typename T&gt;Complex&lt;T&gt; Complex&lt;T&gt;::operator+(Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp;}// 友元函数，重载运算符 \"&lt;&lt;\"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&lt;T&gt;&amp; c1) { cout &lt;&lt; \"a = \" &lt;&lt; c1.a &lt;&lt; \", b = \" &lt;&lt; c1.b; return out;}// 友元函数（滥用友元函数）template &lt;typename T&gt;Complex&lt;T&gt; sub(Complex&lt;T&gt;&amp; c1, Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(c1.a - c2.a, c1.b - c2.b); return tmp;}int main() { Complex&lt;int&gt; c1(3, 8); Complex&lt;int&gt; c2(9, 5); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; Complex&lt;int&gt; c4 = sub(c1, c2); cout &lt;&lt; c4 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234a = 3, b = 8a = 9, b = 5a = 12, b = 13a = -6, b = 3 所有的类模板函数写在类的外部（第三种）所有的类模板函数写在类的外部（分开写在 .h 和 .cpp 中），这里除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，千万不要滥用友元函数；因为 C++ 编译器会出现编译错误，且没有很好的解决方法。 complex.h 123456789101112131415161718192021#pragma once#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Complex {public: Complex(T a, T b); void print(); Complex operator+(Complex&amp; c2); friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, Complex&amp; c1);private: T a; T b;}; complex.hpp，这里的 .hpp 文件与 .cpp 文件本质上没有区别，为了方便区分意图，只是文件的后缀不一样而已 12345678910111213141516171819202122232425262728#include \"complex.h\"// 构造函数template &lt;typename T&gt;Complex&lt;T&gt;::Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b;}// 类成员函数template &lt;typename T&gt;void Complex&lt;T&gt;::print() { cout &lt;&lt; \"a = \" &lt;&lt; this-&gt;a &lt;&lt; \", b = \" &lt;&lt; this-&gt;b &lt;&lt; endl;}// 类成员函数，重载运算符 \"+\"template &lt;typename T&gt;Complex&lt;T&gt; Complex&lt;T&gt;::operator+(Complex&lt;T&gt;&amp; c2) { Complex&lt;T&gt; tmp(this-&gt;a + c2.a, this-&gt;b + c2.b); return tmp;}// 友元函数，重载运算符 \"&lt;&lt;\"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&lt;T&gt;&amp; c1) { cout &lt;&lt; \"a = \" &lt;&lt; c1.a &lt;&lt; \", b = \" &lt;&lt; c1.b; return out;} main.cpp，特别注意，这里引入的是 .hpp 或者 .cpp 文件，而不是 .h 头文件，否则 C++ 编译器会编译失败 12345678910111213#include \"complex.hpp\"int main() { Complex&lt;int&gt; c1(6, 13); Complex&lt;int&gt; c2(23, 34); c1.print(); c2.print(); Complex&lt;int&gt; c3 = c1 + c2; cout &lt;&lt; c3 &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123a = 6, b = 13a = 23, b = 34a = 29, b = 47 类模板中的 static 关键字 从类模板实例化的每种数据类型模板类都有自己的类模板数据成员，该数据类型的模板类的所有对象共享同一个 static 数据成员 和非模板类的 static 数据成员一样，模板类的 static 数据成员也应该在源文件范围内定义和初始化 每种数据类型的模板类都有自己单独一份的类模板的 static 数据成员副本，详见 图解分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;iostream&gt;using namespace std;const double pi = 3.14;template &lt;typename T&gt; class Circle {public: Circle(T radius = 0) { this-&gt;m_radius = radius; this-&gt;m_total++; } void setRadius(T radius) { this-&gt;m_radius = radius; } T getRadius() { return this-&gt;m_radius; } double getGirth() { return 2 * pi * this-&gt;m_radius; } double getArea() { return pi * this-&gt;m_radius * this-&gt;m_radius; } // 类模板的静态成员函数 static int getTotal() { return m_total; }private: T m_radius; // 类模板的静态数据成员 static int m_total;};// 初始化类模板的静态数据成员template &lt;typename T&gt; int Circle&lt;T&gt;::m_total = 0;int main() { // 每种数据类型的模板类都有自己单独一份的类模板的 static 数据成员副本 Circle&lt;int&gt; c1(4), c2(6); cout &lt;&lt; \"m_total = \" &lt;&lt; Circle&lt;int&gt;::getTotal() &lt;&lt; endl; cout &lt;&lt; \"radius = \" &lt;&lt; c1.getRadius() &lt;&lt; \", girth = \" &lt;&lt; c1.getGirth() &lt;&lt; \", area = \" &lt;&lt; c1.getArea() &lt;&lt; endl; cout &lt;&lt; \"radius = \" &lt;&lt; c2.getRadius() &lt;&lt; \", girth = \" &lt;&lt; c2.getGirth() &lt;&lt; \", area = \" &lt;&lt; c2.getArea() &lt;&lt; endl; Circle&lt;float&gt; c3(3.2), c4(4.3), c5(6.2); cout &lt;&lt; \"m_total = \" &lt;&lt; Circle&lt;float&gt;::getTotal() &lt;&lt; endl; cout &lt;&lt; \"radius = \" &lt;&lt; c3.getRadius() &lt;&lt; \", girth = \" &lt;&lt; c3.getGirth() &lt;&lt; \", area = \" &lt;&lt; c3.getArea() &lt;&lt; endl; cout &lt;&lt; \"radius = \" &lt;&lt; c4.getRadius() &lt;&lt; \", girth = \" &lt;&lt; c4.getGirth() &lt;&lt; \", area = \" &lt;&lt; c4.getArea() &lt;&lt; endl; cout &lt;&lt; \"radius = \" &lt;&lt; c5.getRadius() &lt;&lt; \", girth = \" &lt;&lt; c5.getGirth() &lt;&lt; \", area = \" &lt;&lt; c5.getArea() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234567m_total = 2radius = 4, girth = 25.12, area = 50.24radius = 6, girth = 37.68, area = 113.04m_total = 3radius = 3.2, girth = 20.096, area = 32.1536radius = 4.3, girth = 27.004, area = 58.0586radius = 6.2, girth = 38.936, area = 120.702 数组模板类的实战案例下面将编写数组模板类，模拟 STL 容器的实现，同时贯穿上面所讲的 C++ 模板知识点。 ★点击显示完整的案例代码★ MyVector.h 123456789101112131415161718192021222324252627#pragma once#include &lt;iostream&gt;using namespace std;template &lt;class T&gt;class MyVector {public: MyVector(int size = 0); ~MyVector(); MyVector(const MyVector&amp; obj);public: int getSize();public: T&amp; operator[](int index); MyVector&amp; operator=(const MyVector&amp; obj); friend ostream&amp; operator&lt;&lt; &lt;T&gt;(ostream&amp; out, MyVector&amp; obj);private: T* m_space; // 指向数组的指针 int m_size;}; MyVector.hpp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include \"MyVector.h\"// 构造函数template &lt;typename T&gt;MyVector&lt;T&gt;::MyVector(int size) { this-&gt;m_size = size; // 分配内存空间 this-&gt;m_space = new T[size];}// 析构函数template &lt;typename T&gt;MyVector&lt;T&gt;::~MyVector() { if (this-&gt;m_space) { // 释放内存空间 delete[] this-&gt;m_space; this-&gt;m_size = 0; this-&gt;m_space = NULL; }}// 拷贝构造函数template &lt;typename T&gt;MyVector&lt;T&gt;::MyVector(const MyVector&lt;T&gt;&amp; obj) { // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new T[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; }}// 普通类成员函数template &lt;typename T&gt;int MyVector&lt;T&gt;::getSize() { return this-&gt;m_size;}// 使用类成员函数，重载运算符 \"[]\"template &lt;typename T&gt;T&amp; MyVector&lt;T&gt;::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数，重载运算符 \"=\"template &lt;typename T&gt;MyVector&lt;T&gt;&amp; MyVector&lt;T&gt;::operator=(const MyVector&lt;T&gt;&amp; obj) { if (this-&gt;m_space) { // 释放原本的内存空间 delete[] this-&gt;m_space; this-&gt;m_size = 0; this-&gt;m_space = NULL; } // 深拷贝 this-&gt;m_size = obj.m_size; this-&gt;m_space = new T[obj.m_size]; for (int i = 0; i &lt; obj.m_size; i++) { this-&gt;m_space[i] = obj.m_space[i]; } return *this;};// 使用友元函数，重载运算符 \"&lt;&lt;\"template &lt;typename T&gt;ostream&amp; operator&lt;&lt;(ostream&amp; out, MyVector&lt;T&gt;&amp; obj) { for (int i = 0; i &lt; obj.m_size; i++) { cout &lt;&lt; obj.m_space[i] &lt;&lt; \", \"; } return out;} Teacher.h 12345678910111213141516171819202122232425262728#pragma once#include &lt;iostream&gt;using namespace std;class Teacher {public: Teacher(); Teacher(int age, const char* name); Teacher(const Teacher&amp; obj); ~Teacher();public: Teacher&amp; operator=(const Teacher&amp; obj); friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Teacher&amp; obj);public: int getAge(); char* getName(); void setAge(int age); void setName(const char* name);private: int m_age; char* m_name;}; Teacher.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include \"Teacher.h\"// 构造函数Teacher::Teacher() { this-&gt;m_age = 0; this-&gt;m_name = (char*)malloc(1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, \"\"); }}// 构造函数Teacher::Teacher(int age, const char* name) { this-&gt;m_age = age; this-&gt;m_name = (char*)malloc(strlen(name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, name); }}// 拷贝构造函数Teacher::Teacher(const Teacher&amp; obj) { // 深拷贝 this-&gt;m_age = obj.m_age; this-&gt;m_name = (char*)malloc(strlen(obj.m_name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, obj.m_name); }}// 析构函数Teacher::~Teacher() { if (this-&gt;m_name) { free(this-&gt;m_name); }}// 使用类成员函数，重载运算符 \"=\"Teacher&amp; Teacher::operator=(const Teacher&amp; obj) { // 释放原本的内存空间 if (this-&gt;m_name) { free(this-&gt;m_name); this-&gt;m_name = NULL; } // 深拷贝 this-&gt;m_age = obj.m_age; this-&gt;m_name = (char*)malloc(strlen(obj.m_name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, obj.m_name); } return *this;}// 使用友元函数，重载运算符 \"&lt;&lt;\"ostream&amp; operator&lt;&lt;(ostream&amp; out, Teacher&amp; obj) { cout &lt;&lt; \"age = \" &lt;&lt; obj.m_age &lt;&lt; \" name = \" &lt;&lt; obj.m_name; return out;}int Teacher::getAge() { return this-&gt;m_age;}char* Teacher::getName() { return this-&gt;m_name;}void Teacher::setAge(int age) { this-&gt;m_age = age;}void Teacher::setName(const char* name) { // 释放原本的内存空间 if (this-&gt;m_name) { free(this-&gt;m_name); this-&gt;m_name = NULL; } // 深拷贝 this-&gt;m_name = (char*)malloc(strlen(name) + 1); if (this-&gt;m_name) { strcpy(this-&gt;m_name, name); }} main.cpp，值得一提的是，这里需要引入 Teacher.cpp 和 MyVector.hpp，而不是 Teacher.h 和 MyVector.h 头文件，否则 C++ 编译器会编译失败，本质原因是由于 C++ 编译器会对模板进行两次编译导致的，详见 C++ 模板的编译错误分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include \"Teacher.cpp\"#include \"MyVector.hpp\"int main() { // 自动调用构造函数 MyVector&lt;int&gt; v(5); // 重载运算符 \"[]\" for (int i = 0; i &lt; v.getSize(); i++) { v[i] = i + 1; } // 重载运算符 \"&lt;&lt;\" cout &lt;&lt; v &lt;&lt; endl; // 自动调用拷贝构造函数 MyVector&lt;int&gt; v2 = v; cout &lt;&lt; v2 &lt;&lt; endl; // 重载运算符 \"=\" MyVector&lt;int&gt; v3(2); v3 = v2; cout &lt;&lt; v3 &lt;&lt; endl; // 容器存放类对象 MyVector&lt;Teacher&gt; teachers(3); for (int i = 0; i &lt; teachers.getSize(); i++) { Teacher t(i + 20, \"Jim\"); teachers[i] = t; } cout &lt;&lt; teachers &lt;&lt; endl; // 容器存放指针 MyVector&lt;Teacher*&gt; points(4); for (int i = 0; i &lt; points.getSize(); i++) { points[i] = new Teacher(25 + i, \"Tom\"); } for (int i = 0; i &lt; points.getSize(); i++) { Teacher* obj = points[i]; cout &lt;&lt; \"age = \" &lt;&lt; obj-&gt;getAge() &lt;&lt; \" name = \" &lt;&lt; obj-&gt;getName() &lt;&lt; \", \"; } return 0;} 程序运行输出的结果如下： 123451, 2, 3, 4, 5,1, 2, 3, 4, 5,1, 2, 3, 4, 5,age = 20 name = Jim, age = 21 name = Jim, age = 22 name = Jim,age = 25 name = Tom, age = 26 name = Tom, age = 27 name = Tom, age = 28 name = Tom, 函数模板与类模板的使用总结 模板是 C++ 类型参数化的多态工具，C++ 为此提供了函数模板和类模板 模板定义以模板声明开始，类属参数必须在模板定义中至少出现一次 同一个类属参数可以用于多个模板 类属参数可用于函数的参数类型、返回值类型和声明函数中的变量 模板由编译器根据实际的数据类型进行实例化，生成可执行代码 模板中的函数称为模板函数，实例化的类模板称为模板类 类模板可以在类层次中使用（即可以被继承） 函数模板可以使用多种方式重载 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 进阶基础之一","url":"/posts/dbff2af9.html","text":"大纲 C++ 进阶基础之一、C++ 进阶基础之二、C++ 进阶基础之三 C++ 进阶基础之四、C++ 进阶基础之五、C++ 进阶基础之六 C++ 进阶基础之七、C++ 进阶基础之八 智能指针智能指针的入门案例unique_ptr 对象的介绍unique_ptr 是 C++ 11 提供的用于防止内存泄漏的智能指针中的一种实现，独享被管理对象指针所有权的智能指针。unique_ptr 对象包装了一个原始指针，并负责其生命周期。当该对象被销毁时，会在其析构函数中删除关联的原始指针。unique_ptr 实现了 -&gt; 和 * 运算符的重载，因此它可以像普通指针一样使用。 unique_ptr 对象的简单使用123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;class Task {public: Task(int id) { this-&gt;id = id; cout &lt;&lt; \"构造函数被调用\" &lt;&lt; endl; } ~Task() { cout &lt;&lt; \"析构函数被调用\" &lt;&lt; endl; } int getId() { return this-&gt;id; }private: int id;};int main() { unique_ptr&lt;Task&gt; taskPtr(new Task(23)); cout &lt;&lt; \"id = \" &lt;&lt; taskPtr-&gt;getId() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123构造函数被调用id = 23析构函数被调用 unique_ptr&lt;Task&gt; 对象 taskPtr 接受原始指针作为参数。当 main 函数退出时，该对象超出作用范围就会自动调用自身的析构函数。在 unique_ptr&lt;Task&gt; 对象 taskPtr 的析构函数中，会删除关联的原始指针，这样就不用专门执行 Task 对象的 delete 操作了。以后不管函数正常退出还是异常退出（由于某些异常），也会始终调用 taskPtr 对象的析构函数。因此，原始指针将始终被删除并防止内存泄漏。 unique_ptr 对象独享所有权unique_ptr 对象始终是关联的原始指针的唯一所有者，因此开发者无法通过拷贝构造函数或赋值运算符复制 unique_ptr 对象的副本，只能移动它。由于每个 unique_ptr 对象都是原始指针的唯一所有者，因此在其析构函数中，它可以直接删除关联的指针，不需要任何参考计数。 智能指针的基础操作获取被管理对象的原始指针在 unique_ptr 对象上调用 get() 函数，可以获取管理对象的原始指针 1Task *p1 = taskPtr.get(); 检查 unique_ptr 对象是否为空有两种方法创建一个空的 unique_ptr 对象，因为没有与之关联的原始指针，所以它是空的 1unique_ptr&lt;int&gt; ptr; 1unique_ptr&lt;int&gt; ptr = nullptr; 有两种方法可以检查 unique_ptr 对象是否为空或者是否有与之关联的原始指针 123if (!ptr) { cout&lt;&lt;\"ptr is empty\"&lt;&lt;endl;} 123if (ptr == nullptr){ cout&lt;&lt;\"ptr is empty\"&lt;&lt;endl;} 使用原始指针创建 unique_ptr 对象要创建非空的 unique_ptr 对象，需要在创建对象时在其构造函数中传递原始指针 1unique_ptr&lt;Task&gt; taskPtr(new Task(22)); 或者 1unique_ptr&lt;Task&gt; taskPtr(new unique_ptr&lt;Task&gt;::element_type(23)); 不能通过赋值的方法创建 unique_ptr 对象 1unique_ptr&lt;Task&gt; taskPtr = new Task(); // 错误写法，编译失败 智能指针的进阶操作重置 unique_ptr 对象在 unique_ptr 对象上调用 reset() 函数可以重置它，即它会 delete 已关联的原始指针，并将 unique_ptr 对象设置为空 1taskPtr.reset(); unique_ptr 对象不允许复制由于 unique_ptr 不可复制，只能移动。因此，无法通过拷贝构造函数或赋值运算符创建 unique_ptr 对象的副本 123456unique_ptr&lt;Task&gt; taskPtr1(new Task(22));unique_ptr&lt;Task&gt; taskPtr2(new Task(35));unique_ptr&lt;Task&gt; taskPtr4 = taskPtr1; // 错误写法，编译失败taskPtr2 = taskPtr1; // 错误写法，编译失败 转移 unique_ptr 对象的所有权不允许复制 unique_ptr 对象，但可以转移它们。这意味着 unique_ptr 对象可以将自身关联的原始指针的所有权转移给另一个 unique_ptr 对象 1234567891011121314151617// 通过原始指针创建taskPtr1unique_ptr&lt;Task&gt; taskPtr1(new Task(55));// 把taskPtr1中关联指针的所有权转移给taskPtr2unique_ptr&lt;Task&gt; taskPtr2 = move(taskPtr1);// taskPtr1关联指针的所有权现在转移到了taskPtr2中，此时taskPtr1关联的指针为空if (taskPtr1 == nullptr) { cout &lt;&lt; \"taskPtr1 is empty\" &lt;&lt; endl;}// taskPtr1关联指针的所有权现在转移到了taskPtr2中，此时taskPtr2关联的指针不为空if (taskPtr2 != nullptr) { cout &lt;&lt; \"taskPtr2 is not empty\" &lt;&lt; endl;}cout &lt;&lt; taskPtr2-&gt;getId() &lt;&lt; endl; 程序运行输出的结果如下： 123taskPtr1 is emptytaskPtr2 is not empty55 释放 unique_ptr 对象关联的原始指针在 unique_ptr 对象上调用 release() 函数，将释放其关联的原始指针的所有权，并返回原始指针，同时设置 unique_ptr 对象为空。特别注意，这里是释放其关联的原始指针的所有权，并没有 delete 原始指针，而调用 reset() 函数则会 delete 原始指针 1234567891011121314unique_ptr&lt;Task&gt; taskPtr1(new Task(55));if (taskPtr1 != nullptr) { cout &lt;&lt; \"taskPtr1 is not empty\" &lt;&lt; endl;}// 释放关联指针的所有权Task* ptr = taskPtr1.release();if (taskPtr1 == nullptr) { cout &lt;&lt; \"taskPtr1 is empty\" &lt;&lt; endl;}cout &lt;&lt; \"id = \" &lt;&lt; ptr-&gt;getId() &lt;&lt; endl; 程序运行输出的结果如下： 123taskPtr1 is not emptytaskPtr1 is emptyid = 55 C++ 14 使用原始指针创建 unique_ptr 对象C++ 引入了新的语法，可以使用 make_unique 来创建 unique_ptr 对象，省去了 new 关键字的使用 1unique_ptr&lt;Task&gt; taskPtr = make_unique&lt;Task&gt;(34); 原子操作的使用原子操作简介所谓的原子操作，取的就是 “原子是最小的、不可分割的最小个体” 的意义，它表示在多个线程访问同一个全局资源的时候，能够确保在同一时刻只有唯一的线程对这个资源进行访问。这有点类似互斥对象对共享资源的访问的保护，但是原子操作更加接近底层，因而效率更高。在以往的 C++ 标准中并没有对原子操作进行规定，开发人员往往是使用汇编语言，或者是借助第三方的线程库，例如 Intel 的 pthread 来实现。在新标准 C++ 11 中，引入了原子操作的概念，并通过这个新的头文件提供了多种原子操作数据类型，例如 atomic_bool、atomic_int 等等。如果在多个线程中对这些类型的共享资源进行操作，编译器将保证这些操作都是原子性的，也就是说，确保任意时刻只有一个线程对这个资源进行访问；这样就可以保证多个线程访问这个共享资源的正确性，从而避免了锁的使用，提高了效率。在新标准 C++ 11 中，atomic 对 int、char、bool 等基础数据结构进行了原子性封装，在多线程环境中，对 atomic 对象的访问不会造成资源竞争，利用 atomic 可实现数据结构的无锁设计。 atomic 的简介在新标准 C++ 11 中，新增了 atomic 关键字，可以使用它定义一个原子类型，详见 C++ 参考手册一、C++ 参考手册二。 成员函数 成员函数 说明 store 原子地以非原子对象替换原子对象的值 load 原子地获得原子对象的值 operator= 存储值于原子对象 is_lock_free 检查原子对象是否免锁 operator T 从原子对象加载值 exchange 原子地替换原子对象的值，并获得它先前持有的值 compare_exchange_weak、compare_exchange_strong 原子地比较原子对象与非原子参数的值，若相等则进行交换，若不相等则进行加载 特化成员函数 特化成员函数 说明 fetch_add 原子地将参数加到存储于原子对象的值，并返回先前保有的值 fetch_sub 原子地从存储于原子对象的值减去参数，并获得先前保有的值 fetch_and 原子地进行参数和原子对象的值的逐位与，并获得先前保有的值 fetch_or 原子地进行参数和原子对象的值的逐位或，并获得先前保有的值 fetch_xor 原子地进行参数和原子对象的值的逐位异或，并获得先前保有的值 operator++、operator++(int)、operator--、operator--(int) 令原子值增加或者减少一 operator+=、operator-=、operator&amp;=、operator^= 加、减，或者与原子值进行逐位与、异或 值得一提的是，所谓特化函数，也就是 atomic 自身提供的，可以进行原子操作的函数。使用这些函数进行的操作，都是原子的。 atomic 的使用案例加锁不使用 atomic123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;ctime&gt;#include &lt;mutex&gt;#include &lt;vector&gt;#include &lt;thread&gt;using namespace std;mutex mtx;size_t total = 0;void threadFun(){ for (int i = 0; i &lt; 1000000; i++) { // 加锁防止多个线程同时访问同一资源 unique_lock&lt;mutex&gt; lock(mtx); total++; }}int main(void){ clock_t start_time = clock(); // 启动多个线程 vector&lt;thread&gt; threads; for (int i = 0; i &lt; 10; i++) { threads.push_back(thread(threadFun)); } for (auto&amp; thad : threads) { thad.join(); } // 检测total是否正确 10000*10 = 100000 cout &lt;&lt; \"total number:\" &lt;&lt; total &lt;&lt; endl; clock_t end_time = clock(); cout &lt;&lt; \"耗时：\" &lt;&lt; end_time - start_time &lt;&lt; \"ms\" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12total number:10000000耗时：615ms 不加锁使用 atomic与加锁相比，使用原子操作（atomic）能大大地提高程序的运行效率。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;ctime&gt;#include &lt;mutex&gt;#include &lt;vector&gt;#include &lt;thread&gt;using namespace std;atomic&lt;size_t&gt; total(0);void threadFun(){ for (int i = 0; i &lt; 1000000; i++) { total++; }}int main(void){ clock_t start_time = clock(); // 启动多个线程 vector&lt;thread&gt; threads; for (int i = 0; i &lt; 10; i++) { threads.push_back(thread(threadFun)); } for (auto&amp; thad : threads) { thad.join(); } // 检测total是否正确 10000*10 = 100000 cout &lt;&lt; \"total number:\" &lt;&lt; total &lt;&lt; endl; clock_t end_time = clock(); cout &lt;&lt; \"耗时：\" &lt;&lt; end_time - start_time &lt;&lt; \"ms\" &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12total number:10000000耗时：321ms 为什么要定义一个原子类型举个例子，int64_t 类型，在 32 位机器上为非原子操作。更新时该类型的值时，需要进行两步操作（高 32 位、低 32 位）。如果多线程操作该类型的变量，且在操作时未加锁，可能会出现读脏数据的情况。解决该问题的话，可以使用加锁，或者提供一种定义原子类型的方法。 定义原子类型 12// 定义一个\"int64_t\"的原子类型std::atomic&lt;int64_t&gt; value; 自加操作（原子） 12// atomic提供的特化成员函数，已经重载了++运算符value++ 读取变量值（原子） 12// 此处的原子操作，指的是读取value的值这一步，而不是将value的值赋给xint64_t x = value.load(std::memory_order_relaxed); 更新变量（原子） 12int64_t x = 10;value.store(x, std::memory_order_relaxed) atomic 不能与 string 一起使用特别注意，atomic 关键字不能与 string 类型一起使用，因为 string 不是可简单复制的类型（TriviallyCopyable），详见 C++ 参考文档： The primary std::atomic template may be instantiated with any TriviallyCopyable type T satisfying both CopyConstructible and CopyAssignable. 123456#include &lt;iostream&gt;int main() { std::atomic&lt;std::string&gt; str{ \"Hello\" }; return 0;} 上述代码编译后，C++ 编译器会出现编译错误，如下所示： 1error C2338: atomic&lt;T&gt; requires T to be trivially copyable, copy constructible, move constructible, copy assignable, and move assignable. 关于 C++ 编译器为什么会对 std::atomic&lt;std::string&gt; 给出简单的可复制错误，在 Stack Overflow 上找到了一个类似的问题可供参考。 参考博客 C++11 新特性之 atomic C++ 智能指针 unique_ptr 详解与示例 为何优先选用 unique_ptr 而不是裸指针？ var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 使用 API 连接 MySQL 数据库","url":"/posts/c942e1de.html","text":"前言本文将介绍 C++ 如何使用 MySQL Connector/C++ 的 API 连接 MySQL 数据库，适用于 Windows 系统。 版本说明 软件 版本 默认安装路径 MySQL Connector/C++ 1.1.13 C:\\Program Files\\MySQL\\MySQL Connector C++ 1.1.13 OpenSSL v1.1.1L C:\\Program Files\\OpenSSL-Win64 boost 1_77_0 C:\\Program Files\\boost_1_77_0 MySQL Server 5.7.33 C++ 11 Visual Studio 2019 Windows System Win 10 MySQL Connector/C++ 介绍简介 MySQL Connector/C++ 是一个 MySQL 数据库连接器，包含了 C++ 连接 MySQL 服务器所需的头文件和库文件，可用于开发基于 JDBC 的 C++ 应用程序。 开发优势 与 MySQL 客户端库提供的 C 语言 API 相比，MySQL Connector/C++ 为 C++ 用户提供以下好处： 纯 C++ 开发的便利 支持基于 JDBC 4.0 的 API 支持面向对象的编程范式 减少项目的开发时间 可根据要求获得商业许可证 根据 GPL 获得许可，但 FLOSS 许可除外 分发方式 MySQL Connector/C++ 有二进制文件和源代码分发版，并以特定于平台的打包格式提供： 二进制分发版可用于 Windows、Linux、Unix 和类 Unix 平台 源代码分发版可作为压缩的 tar 文件或 zip 文件提供，并可在任何受支持的平台上使用 源代码存储库使用 Git 存储，可在 GitHub 上获得 与 JDBC 的兼容性 MySQL Connector/C++ 与 JDBC 4.0 API 兼容，没有实现整个 JDBC 4.0 API，但具有以下类：Connection、DatabaseMetaData、Driver、PreparedStatement、ResultSet、ResultSetMetaData、Savepoint、Statement。JDBC 4.0 API 为刚才提到的类定义了大约 450 个方法，MySQL Connector/C++ 实现了其中的大约 80%。 支持的平台和先决条件 对于 MySQL Connector/C++ 1.1.11 及更高版本，商业和社区发行版需要依赖 Visual C++ Redistributable for Visual Studio 2015 才能在 Windows 平台上运行。从 MySQL Connector/C++ 1.1.10 开始，社区（非商业）发行版需要依赖适用于 Visual Studio 2013 的 Visual C++ Redistributable。可在 Microsoft 下载中心获取 Redistributable 的安装包，并在安装 MySQL Connector/C++ 之前安装它。 要运行带 MySQL Connector/C++ 的应用程序，需要 MySQL 5.6 或更高版本的数据库服务器 要构建带 MySQL Connector/C++ 的应用程序 在 Windows 系统上，需要 Microsoft Visual Studio 2015 要从源代码构建 MySQL Connector/C++ 自身 在 Windows 系统上，需要 Microsoft Visual Studio 2015 Building Connector/C++ 需要 MySQL 5.7（5.7.9 或更高版本）或 MySQL 8.0（8.0.11 或更高版本）的客户端库 准备工作OpenSSL 安装安装 OpenSSL在 OpenSSL 官网 下载 Win64 OpenSSL v1.1.1L 版本的安装包，下载完成后直接安装，每一步安装步骤选择默认选项即可。OpenSSL 默认的安装路径是 C:\\Program Files\\OpenSSL-Win64。 VS 项目添加 OpenSSL 的 库文件OpenSSL 安装完成之后，将其安装目录下的 bin 文件夹中的 libssl-1_1-x64.dll 和 libcrypto-1_1-x64.dll 库文件拷贝到 VS 项目的目录中，如下图所示： VS 项目引入 OpenSSL 的 头文件右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 OpenSSL 头文件所在的目录路径（如 C:\\Program Files\\OpenSSL-Win64\\include），如下图所示： MySQL Connector/C++ 安装安装 MySQL Connector/C++在 MySQL 官网 上下载 1.1.13 版本的 MySQL Connector/C++，下载完成后直接安装即可。若已经本地已经安装过 MySQL Server，则不再需要手动安装 MySQL Connector/C++，因为默认已经安装过了，但需要留意 MySQL Connector/C++ 与 MySQL 的版本是否匹配 。值得一提的是，MySQL Connector/C++ 支持多个版本共存（同时安装不同的版本），其默认的安装路径为 C:\\Program Files\\MySQL\\Connector.C++ 1.x。 VS 项目添加 MySQL Connector/C++ 的 库文件MySQL Connector/C++ 安装完成后，将其安装目录下 lib/opt 文件夹中的 mysqlcppconn.dll 与 mysqlcppconn.lib 库文件拷贝到 VS 项目的目录中，如下图所示： VS 项目引入 MySQL Connector/C++ 的头文件右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 MySQL Connector/C++ 头文件所在的目录路径（如 C:\\Program Files\\MySQL\\MySQL Connector C++ 1.1.13\\include），如下图所示： C++ 连接 MySQL 的实战案例MySQL 数据库初始化123456789101112131415161718192021222324252627282930-- ------------------------------ 创建数据库-- ----------------------------DROP DATABASE IF EXISTS `t_shop`;CREATE DATABASE `t_shop` DEFAULT CHARACTER SET UTF8;-- ------------------------------ 切换数据库-- ----------------------------USE `t_shop`;-- ------------------------------ 创建数据库表-- ----------------------------DROP TABLE IF EXISTS `properties`;CREATE TABLE `properties` ( `ID` int(11) NOT NULL AUTO_INCREMENT, `KEY` varchar(200) DEFAULT NULL, `VALUE` varchar(200) DEFAULT NULL, `REMARK` varchar(200) DEFAULT NULL, PRIMARY KEY (`ID`) USING BTREE, UNIQUE KEY `key_unique_index` (`KEY`)) ENGINE=InnoDB AUTO_INCREMENT=27 DEFAULT CHARSET=UTF8 ROW_FORMAT=DYNAMIC;-- ------------------------------ 往数据库表插入数据-- ----------------------------INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES ('test_limit_price', '30.5', '限制价格');INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES ('test_limit_number', '430', '限制数量');INSERT INTO `properties` (`KEY`, `VALUE`, `REMARK`) VALUES ('test_limit_balance', '929.32', '限制余额'); C++ 连接 MySQL 的代码 mysqldb.h 12345678910111213141516171819202122232425262728293031323334#pragma once#include &lt;vector&gt;#include &lt;iostream&gt;#include &lt;mysql_connection.h&gt;#include &lt;cppconn/driver.h&gt;#include &lt;cppconn/exception.h&gt;#include &lt;cppconn/resultset.h&gt;#include &lt;cppconn/statement.h&gt;#include &lt;cppconn/prepared_statement.h&gt;using namespace std;using namespace sql;// MySQL数据库操作类class MysqlDB {public: MysqlDB(const string host, const string username, const string password, const string database); ~MysqlDB();public: bool Execute(const char* sql); int ExecuteUpdate(const char* sql); unique_ptr&lt;ResultSet&gt; Query(const char* query, const vector&lt;string&gt; parameters);private: string host; string username; string password; string database; Driver* driver; unique_ptr&lt;Connection&gt; connection; // 智能指针}; mysqldb.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#include \"mysqldb.h\"// 构造函数MysqlDB::MysqlDB(const string host, const string username, const string password, const string database) { // 初始化MySQL的连接信息 this-&gt;host = host; this-&gt;username = username; this-&gt;password = password; this-&gt;database = database; try { // 加载MySQL驱动 this-&gt;driver = get_driver_instance(); if (!this-&gt;driver) { throw \"failed to load mysql driver\"; } // 连接MySQL实例 this-&gt;connection.reset(driver-&gt;connect(this-&gt;host.c_str(), this-&gt;username.c_str(), this-&gt;password.c_str())); if (!this-&gt;connection) { throw \"failed to connect mysql server\"; } else { // 设置默认数据库 this-&gt;connection-&gt;setSchema(this-&gt;database.c_str()); } } catch (SQLException&amp; e) { cout &lt;&lt; \"# ERR: SQLException in \" &lt;&lt; __FILE__ &lt;&lt; \"(\" &lt;&lt; __FUNCTION__ &lt;&lt; \") on line \" &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; \"# ERR: \" &lt;&lt; e.what() &lt;&lt; endl; };}// 析构函数MysqlDB::~MysqlDB() {}// 用于执行任何 SQL 语句，返回一个 bool 值，表明执行该 SQL 语句是否返回了 ResultSet// 如果执行后第一个结果是 ResultSet，则返回 true，否则返回 falsebool MysqlDB::Execute(const char* sql) { try { if (this-&gt;connection) { unique_ptr&lt;Statement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;createStatement()); if (statement) { return statement-&gt;execute(sql); } } } catch (SQLException&amp; e) { cout &lt;&lt; \"# ERR: SQLException in \" &lt;&lt; __FILE__ &lt;&lt; \"(\" &lt;&lt; __FUNCTION__ &lt;&lt; \") on line \" &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; \"# ERR: \" &lt;&lt; e.what() &lt;&lt; endl; } return false;}// 用于执行 INSERT、UPDATE 或 DELETE 语句以及 SQL DDL（数据定义语言）语句，例如 CREATE TABLE 和 DROP TABLE// 函数的返回值是一个整数，指示受影响的行数，对于 CREATE TABLE 或 DROP TABLE 等不操作行的语句，返回值总为零int MysqlDB::ExecuteUpdate(const char* sql) { try { if (this-&gt;connection) { unique_ptr&lt;Statement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;createStatement()); if (statement) { return statement-&gt;executeUpdate(sql); } } } catch (SQLException&amp; e) { cout &lt;&lt; \"# ERR: SQLException in \" &lt;&lt; __FILE__ &lt;&lt; \"(\" &lt;&lt; __FUNCTION__ &lt;&lt; \") on line \" &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; \"# ERR: \" &lt;&lt; e.what() &lt;&lt; endl; } return 0;}// 基于 SQL 的预编译机制，执行查询单个结果集（ResultSet）的 SQL 语句，例如 SELECT 语句unique_ptr&lt;ResultSet&gt; MysqlDB::Query(const char* sql, const vector&lt;string&gt; parameters) { unique_ptr&lt;ResultSet&gt; resultSet = nullptr; try { if (this-&gt;connection) { int index = 0; unique_ptr&lt;PreparedStatement&gt; statement = nullptr; statement.reset(this-&gt;connection-&gt;prepareStatement(sql)); if (statement) { for (auto iterator = parameters.cbegin(); iterator != parameters.cend(); iterator++) { index++; statement-&gt;setString(index, (*iterator).c_str()); } resultSet.reset(statement-&gt;executeQuery()); } } } catch (SQLException&amp; e) { cout &lt;&lt; \"# ERR: SQLException in \" &lt;&lt; __FILE__ &lt;&lt; \"(\" &lt;&lt; __FUNCTION__ &lt;&lt; \") on line \" &lt;&lt; __LINE__ &lt;&lt; endl; cout &lt;&lt; \"# ERR: \" &lt;&lt; e.what() &lt;&lt; endl; } return resultSet;} main.cpp 12345678910111213141516171819202122#include &lt;iostream&gt;#include \"mysqldb.h\"using namespace std;int main() { unique_ptr&lt;MysqlDB&gt; db(new MysqlDB(\"tcp://127.0.0.1:3306\", \"root\", \"123456\", \"t_shop\")); string querySql = \"select * from properties where `KEY` = ?\"; unique_ptr&lt;ResultSet&gt; result = db-&gt;Query(querySql.c_str(), { \"test_limit_price\" }); if (result) { cout &lt;&lt; \"Query: \" &lt;&lt; querySql &lt;&lt; endl; while (result-&gt;next()) { cout &lt;&lt; result-&gt;getInt(\"ID\") &lt;&lt; \" | \"; cout &lt;&lt; result-&gt;getString(\"KEY\").c_str() &lt;&lt; \" | \"; cout &lt;&lt; result-&gt;getString(\"VALUE\").c_str() &lt;&lt; \" | \"; cout &lt;&lt; result-&gt;getString(\"REMARK\").c_str() &lt;&lt; \" | \"; cout &lt;&lt; endl; } } return 0;} 程序运行输出的结果如下： 12Query: select * from properties where `KEY` = ?27 | test_limit_price | 30.5 | 限制价格 | 常见问题缺失 Boost 库错误信息： 项目执行编译操作后，VS 出现下述错误信息，这是本地缺失 boost 库导致的。1fatal error C1083: 无法打开包括文件: “boost/shared_ptr.hpp”: No such file or directory 解决方法： a) 在 Boost 官网 下载最新版本的 Boost，并解压到本地磁盘，例如解压路径为：C:\\Program Files\\boost_1_77_0 b) 右键项目，选择 属性，导航到 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录，添加 Boost 的安装路径（如 C:\\Program Files\\boost_1_77_0），如下图所示 c) 重新执行项目的编译操作 缺失 libssl-1_1-64.dll 文件错误信息： 项目运行后，系统弹窗提示以下错误信息。1由于找不到 libssl-1_1-64.dll，无法继续执行代码。重新安装程序可能会解决此问题。 解决方法： 安装 OpenSSL，并拷贝 libssl-1_1-64.dll 库文件到 VS 项目的目录中，具体步骤可参考上面的 OpenSSL - 安装 教程。 缺失 libcrypto-1_1-x64.dll 文件错误信息： 项目运行后，系统弹窗提示以下错误信息。1由于找不到 libcrypto-1_1-x64.dll，无法继续执行代码。重新安装程序可能会解决此问题。 解决方法： 安装 OpenSSL，并拷贝 libcrypto-1_1-x64.dll 库文件到 VS 项目的目录中，具体步骤可参考上面的 OpenSSL - 安装 教程。 参考文档 mysql-connector-demo MySQL Connector/C++ 官方文档 MySQL Connector/C++ Github 仓库 MySQL Connector/C++ 官方 API 使用教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 入门基础之九","url":"/posts/f1a16291.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 多态的原理多态的实现原理 当类中声明了虚函数时，编译器会在类中生成一个虚函数表 虚函数表是一个存储类成员函数指针的数据结构 虚函数表是由编译器自动生成和维护的 虚函数（virtual）会被编译器放入虚函数表中 当存在虚函数时，每个对象中都有一个指向虚函数表的指针（C++ 编译器给父类对象、子类对象提前设置了 VPTR 虚函数表指针，因此 C++ 编译器不需要区分子类对象或者父类对象，只需要在 base 指针中，找 VPTR 指针即可） VPTR 虚函数表指针一般作为类对象的第一个成员 多态的实现原理图解 a) 多态实现原理的图解 如图 所示 b) 通过 VPTR 虚函数表指针调用重写函数的过程是在程序运行时进行的，因此需要通过寻址操作才能确定真正应该调用的函数，而普通成员函数是在编译时就确定了调用的函数 c) 在效率上，虚函数的效率要低很多，因此出于效率考虑，没有必要将所有成员函数都声明为虚函数，即使 C++ 编译器允许这么做 d) 由于有了虚函数表，C++ 编译器不再需要知道是子类对象还是父类对象，这往往会给我们造成一种假象：C++ 编译器能识别子类对象或者父类对象 证明 VPTR 指针的存在12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Parent1 {public: Parent1(int a) { this-&gt;a = a; } // 不声明虚函数 void print() { cout &lt;&lt; \"I'm parent1\" &lt;&lt; endl; }private: int a;};class Parent2 {public: Parent2(int a) { this-&gt;a = a; } // 声明虚函数 virtual void print() { cout &lt;&lt; \"I'm parent2\" &lt;&lt; endl; }private: int a;};int main() { // 由于指针也是一种数据类型，由于在Parent2类中声明了虚函数，若Parent2类里存在VPTR指针，那么下面两个类的大小应该是不一样的 cout &lt;&lt; \"sizeof(Parent1): \" &lt;&lt; sizeof(Parent1) &lt;&lt; endl; cout &lt;&lt; \"sizeof(Parent2): \" &lt;&lt; sizeof(Parent2) &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12sizeof(Parent1): 4sizeof(Parent2): 8 父类指针和子类指针的步长可能是不一样的 a) 指针也只一种数据类型，对 C++ 类对象的指针执行 ++、-- 运算符仍然是合法的 b) \"多态是用父类的指针指向子类的对象\" 和 \"父类指针步长的自加（++）\" 是两个完全不同的概念 c) 当子类继承父类后，没有添加任何自己的成员变量和成员函数，那么此时父类指针和子类指针的步长才是一样的 d) 指针运算是按照指针所指的类型进行的，父类指针和子类指针的步长可能是不一样的，不要用父类指针自加（++）、自减（--）的方式来操作子类的对象数组 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;using namespace std;class Parent{public: Parent(int a = 0) { this-&gt;a = a; } virtual void print() { cout &lt;&lt; \"I'm parent\" &lt;&lt; endl; }private: int a;};class Child : public Parent{public: Child(int b, int c) :Parent(0) { this-&gt;b = b; this-&gt;c = c; } virtual void print() { cout &lt;&lt; \"I'm child\" &lt;&lt; endl; }private: int b; int c;};int main(){ Parent* parent = NULL; Child* child = NULL; Child array[] = { Child(1, 2), Child(3,4), Child(5, 6) }; parent = array; child = array; // 指针自加运算后运行可能会出错，这里父类指针和子类指针的步长是不一样的，不要用父类指针自加（`++`）、自减（`--`）的方式来操作子类的对象数组 parent++; child++; parent++; child++; return 0;} 在父类的构造函数中调用虚函数，不能实现多态子类的 VPTR 指针是分步完成初始化的，当执行父类的构造函数时，子类 的 VPTR 指针指向父类的虚函数表，当父类的构造函数执行完毕后，才会把子类的 VPTR 指针指向子类的虚函数表。因此，在父类的构造函数中调用虚函数，不能实现多态。 a) 分析图解 如图 所示 b) 对象在创建的时，由编译器对 VPTR 指针进行初始化 c) 只有当对象的构造全部完成后，VPTR 指针的指向才能最终确定 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; // 在父类的构造函数中调用虚函数 print(); } virtual void print() { cout &lt;&lt; \"I'm parent, a = \" &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int a, int c) : Parent(a) { this-&gt;c = c; } virtual void print() { cout &lt;&lt; \"I'm child, c = \" &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Child child(5, 8); return 0;} 程序运行的输出结果如下： 1I'm parent, a = 5 纯虚函数和抽象类纯虚函数和抽象类的基本概念基本概念： a) 纯虚函数是一个在基类中说明的虚函数，且在基类中没有被定义，要求任何派生类都定义自己的版本 b) 纯虚函数为各派生类提供一个公共界面，可以实现接口的封装和设计、软件的模块功能划分 c) 纯虚函数的声明形式： virtual 类型 函数名 ( 参数表 ) = 0; d) 一个具有纯虚函数的基类称为抽象类 使用限制： a) 可以声明抽象类的指针和引用 b) 抽象类不能创建对象（实例化） c) 抽象类不能作为函数的参数类型和返回值类型 纯虚函数和抽象类的应用案例定义一个图形抽象类 Figure，并声明了负责计算图形面积的纯虚函数 getArea()，然后再定义 Circle、Triangle、Squre 派生类，并各自实现了纯虚函数 getArea() 来计算不同图形的面积。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;iostream&gt;using namespace std;// 抽象类class Figure {public: // 声明纯虚函数，计算面积 virtual double getArea() = 0;};class Circle : public Figure {public: Circle(double r) { this-&gt;r = r; } // 计算圆的面积 virtual double getArea() { double area = 3.14 * r * r; cout &lt;&lt; \"圆的面积: \" &lt;&lt; area &lt;&lt; endl; return area; }private: double r;};class Triangle : public Figure {public: Triangle(double a, double b) { this-&gt;a = a; this-&gt;b = b; } // 计算三角形的面积 virtual double getArea() { double area = a * b / 2; cout &lt;&lt; \"三角形的面积: \" &lt;&lt; area &lt;&lt; endl; return area; }private: double a; double b;};class Square : public Figure {public: Square(double a, double b) { this-&gt;a = a; this-&gt;b = b; } // 计算四边形的面积 virtual double getArea() { double area = a * b; cout &lt;&lt; \"四边形的面积: \" &lt;&lt; area &lt;&lt; endl; return area; }private: double a; double b;};void printArea(Figure* base) { base-&gt;getArea();}int main() { // Figure f; // 错误写法，抽象类不能实例化 Triangle Triangle(20, 30); Circle circle(6.8); Square square(50, 60); // 可以声明抽象类的指针 Figure* pBase = new Circle(5.3); pBase-&gt;getArea(); // 可以声明抽象类的引用 Figure&amp; base = square; base.getArea(); printArea(&amp;Triangle); return 0;} 程序运行的输出结果如下： 123圆的面积: 88.2026四边形的面积: 3000三角形的面积: 300 纯虚函数和抽象类在多继承中的应用案例C++ 中没有 Java 中的接口概念，但可以使用抽象类和纯虚函数模拟 Java 中的接口（代码如下）。值得一提的是，C++ 中的接口类只有函数原型定义，没有任何数据的定义，同时继承多个接口类不会带来二义性和复杂性等问题。C++ 面向抽象类编程（Java 面向接口编程）是项目开发中重要技能之一。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;iostream&gt;using namespace std;// 定义接口类一class Interface1 {public: virtual int add(int a, int b) = 0; virtual void print() = 0;};// 定义接口类二class Interface2 {public: virtual int mult(int a, int b) = 0; virtual void print() = 0;};// 定义父类class Parent {public: Parent() { this-&gt;a = 8; } virtual ~Parent() { } virtual int getA() { return a; }private: int a;};// 定义子类，首先继承父类，然后继承多个接口类class Child : public Parent, public Interface1, public Interface2 {public: int add(int a, int b) { return a + b; } int mult(int a, int b) { return a * b; } void print() { cout &lt;&lt; \"Child::print() 函数被执行\" &lt;&lt; endl; }};int main() { Child child; child.print(); Parent* parent = &amp;child; cout &lt;&lt; \"a = \" &lt;&lt; parent-&gt;getA() &lt;&lt; endl; Interface1* interface1 = &amp;child; int result1 = interface1-&gt;add(2, 5); cout &lt;&lt; \"2 + 5 = \" &lt;&lt; result1 &lt;&lt; endl; Interface2* interface2 = &amp;child; int result2 = interface2-&gt;mult(3, 6); cout &lt;&lt; \"3 * 6 = \" &lt;&lt; result2 &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 123a = 82 + 5 = 73 * 6 = 18 纯虚函数和抽象类在多继承中的使用总结C++ 中没有 Java 中的接口概念： 绝大多数面向对象语言都不支持多继承 绝大多数面向对象语言都支持接口的概念 C++ 中没有 Java 中的接口概念，但可以使用抽象类和纯虚函数模拟 Java 中的接口 C++ 中的接口类只有函数原型定义，没有任何数据的定义（代码如下） ★点击显示示例代码★ 1234567class Interface { public: virtual void func1() = 0; virtual void func2(int i) = 0; virtual void func3(int i) = 0; }; 工程上多继承的使用说明： a) 多继承已经被实际开发经验所抛弃 b) 工程开发中真正意义上的多继承是几乎不被使用的 c) 多继承带来的代码复杂性远多于其带来的便利 d) 多继承对代码维护性上的影响是灾难性的 e) 在设计方法上，任何多继承都可以使用单继承代替 f) 在多继承中，使用虚继承不能完全解决二义性的问题 虚继承的使用与适用场景介绍 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇），如右图所示 对于 V 字形的多继承场景，虚继承是没办法解决二义性问题的，如右图所示 工程上继承多个接口类的使用说明： a) 继承多个接口类不会带来二义性和复杂性等问题 b) 多继承可以通过精心设计的单继承和接口类来代替 c) 接口类只是一个功能说明，而不是功能实现，子类需要根据功能说明定义功能实现 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 入门基础之八","url":"/posts/4c2ae4c0.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 多继承多继承概念 a) 一个类有多个直接基类（父类）的继承关系称为多继承 b) 类 C 可以根据访问控制同时继承类 A 和类 B 的成员，并添加自己的成员 c) 多继承声明语法 1234class 派生类名 : 访问控制 基类名1 , 访问控制 基类名2 , … , 访问控制 基类名n{ 数据成员和成员函数声明}; 多继承的简单应用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;using namespace std;class Base1 {public: Base1(int a) { this-&gt;a = a; } void printA() { cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl; }private: int a;};class Base2 {public: Base2(int b) { this-&gt;b = b; } void printB() { cout &lt;&lt; \"b = \" &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : public Base1, public Base2 {public: Base3(int a, int b, int c) : Base1(a), Base2(b) { this-&gt;c = c; } void printC() { cout &lt;&lt; \"c = \" &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Base3 base(1, 2, 3); base.printA(); base.printB(); base.printC(); return 0;} 程序运行的输出结果如下： 123a = 1b = 2c = 3 派生类的构造函数和成员访问在多继承的派生类中，其构造函数和成员访问的特性如下： 拥有多个基类的派生类的构造函数，可以用初始化列表调用基类构造函数来初始化数据成员。 执行顺序与单继承构造函数情况类似，多个直接基类构造函数执行顺序取决于定义派生类时指定的各个继承基类的顺序。 一个派生类对象拥有多个直接或间接基类的成员。不同名成员访问不会出现二义性，如果不同的基类有同名成员，那么派生类对象访问时应该加以识别。 虚继承虚继承的概念 总结： 如果一个派生类从多个基类继承，而这些基类又有一个共同的基类（公共基类），则在对该基类中声明的成员进行访问时，可能会产生二义性。 如果在多条继承路径上有一个公共的基类，那么在继承路径的某处汇合点，这个公共基类就会在派生类的对象中产生多个基类子对象 要使这个公共基类在派生类中只产生一个子对象，必须对这个基类声明为虚继承，使这个基类成为 虚基类。 虚继承声明需要使用关键字：virtual 虚继承的简单应用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;using namespace std;class Base {public: Base(int x) { this-&gt;x = x; cout &lt;&lt; \"Base 类的构造函数被调用\" &lt;&lt; endl; } void printX() { cout &lt;&lt; \"x = \" &lt;&lt; x &lt;&lt; endl; }private: int x;};// 声明虚继承class Base1 : virtual public Base {public: Base1(int a, int x) : Base(x) { this-&gt;a = a; } void printA() { cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl; }private: int a;};// 声明虚继承class Base2 : virtual public Base {public: Base2(int b, int x) : Base(x) { this-&gt;b = b; } void printB() { cout &lt;&lt; \"b = \" &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : public Base1, public Base2 {public: // 由于父类和虚基类没有默认的无参构造函数，所以这里的派生类需要在初始化列表中，显式调用父类、虚基类的有参构造函数 Base3(int a, int b, int c, int x) : Base1(a, x), Base2(b, x), Base(x) { this-&gt;c = c; } void printC() { cout &lt;&lt; \"c = \" &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Base3 base(1, 2, 3, 4); // 虚基类Base的构造函数只会被调用一次 base.printA(); base.printB(); base.printC(); base.printX(); // 当不声明虚继承的时候，此写法会产生二义性，C++编译器会出现编译错误 return 0;} 程序运行的输出结果如下： 12345Base 类的构造函数被调用a = 1b = 2c = 3x = 4 值得一提的是，如果虚基类声明了非默认形式的（即带参数的）构造函数，并且没有声明默认形式的（无参）构造函数，此时在整个继承关系中，直接或者间接继承虚基类的所有派生类，都必须在构造函数的成员初始化列表中列出对虚基类的初始化。因为涉及到多重继承和虚继承，为避免派生类因调用多个父类的构造函数后多次构造更上层虚基类，所以需要派生类自己显示调用继承而来的虚基类的构造函数，而继承链上其它所有对虚基类的构造函数调用将被忽略。简单一句话概况：父类不会帮子类调用虚基类的构造函数，子类在构造时必须自己初始化所有虚基类。 虚继承的适用场景 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇），如右图所示 对于 V 字形的多继承场景（代码如下），虚继承是没办法解决二义性问题的，如右图所示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;using namespace std;class Base1 {public: Base1(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl; }private: int a;};class Base2 {public: Base2(int b) { this-&gt;b = b; } void print() { cout &lt;&lt; \"b = \" &lt;&lt; b &lt;&lt; endl; }private: int b;};class Base3 : virtual public Base1, virtual public Base2 {public: Base3(int a, int b) : Base1(a), Base2(b) { }};int main() { Base3 base(1, 2); // 虚继承只适用于有共同基类（公共基类）的多继承场景（钻石菱形 ◇） // 即使上面声明了虚继承，但此写法仍然会产生二义性，C++编译器会出现编译错误 // base.print(); base.Base1::print(); base.Base2::print(); return 0;} 程序运行的输出结果如下： 12a = 1b = 2 多态多态是面向对象的三大概念（如下）之一，按字面的意思就是多种形态。当类之间存在层次结构，并且类之间是通过继承关联时，就会使用到多态。C++ 的多态意味着调用成员函数时，会根据调用函数的对象的类型来执行不同的函数。值得一提的是，多态是设计模式的基础，同时也是框架的基石。 封装：突破了 C 语言函数的概念。 继承：提高了代码的可重用性。 多态：多态是指在不同继承关系的类对象中，去调同一函数，产生了不同的行为。多态的一般使用方式，是使用一个父类的指针或引用去调用子类中被重写的方法。 函数重写函数重写的概念 函数重写是指在子类中定义与父类中原型相同的函数 父类中被重写的函数依然会继承给子类 默认情况下，在子类中重写的函数将隐藏父类中的函数 通过作用域分辨符 :: 可以访问到父类中被隐藏的函数 函数重写只发生在父类与子类之间，而函数重载只发生在同一个类中 函数重写的应用12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; \"I'm parent, a = \" &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int a, int c) : Parent(a) { this-&gt;c = c; } // 子类重写父类中的函数 void print() { cout &lt;&lt; \"I'm child, c = \" &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Child child(3, 7); // 执行子类的函数，默认情况下子类中重写的函数将隐藏父类中的函数 child.print(); // 执行父类的函数，通过作用域分辨符\"::\"可以访问到父类中被隐藏的函数 child.Parent::print(); return 0;} 程序运行的输出结果如下： 12I'm child, c = 7I'm parent, a = 3 函数重写与函数重载的区别 函数重载 必须在同一个类中进行 子类无法重载父类的函数，父类同名函数将被子类的覆盖 重载是在编译期间根据参数类型、个数和顺序决定函数的调用 函数重写 必须发生于父类与子类之间 父类与子类中的函数必须有完全相同的原型 使用 virtual 关键字声明之后，能够产生多态（如果不使用 virtual 关键字声明，那叫重定义） 虚函数类型兼容原则遇上函数重写当 类型兼容原则 遇上函数重写时，执行以下代码后会出现意外的现象，即被调用的永远是父类的函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } void print() { cout &lt;&lt; \"I'm parent, a = \" &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int c) : Parent(c) { this-&gt;c = c; } // 子类重写父类中的函数 void print() { cout &lt;&lt; \"I'm child, c = \" &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Parent* p = NULL; Parent parent(6); Child child(5); // 执行父类的函数 p = &amp;parent; p-&gt;print(); // 执行父类的函数 p = &amp;child; p-&gt;print(); return 0;} 程序运行的输出结果如下： 12I'm parent, a = 6I'm parent, a = 5 C/C++ 是静态编译型语言，在执行编译时，编译器会自动根据指针的类型判断指向的是一个什么样的对象。但在编译 print() 函数的时候，编译器不可能知道指针 p 究竟指向了什么对象，因为程序还没有运行。同时编译译器没有理由报错，于是编译器认为最安全的做法是编译到父类的 print() 函数，因为父类和子类肯定都有相同的 print() 函数。这就是所谓的 静态多态 或 静态联编，函数调用在程序执行之前就已经准备好了；有时候这也被称为 早绑定，因为 print() 函数在程序编译期间就已经设置好了。这就引出了面向对象新的需求，希望根据实际的对象类型来判断重写函数的调用；如果父类指针指向的是父类对象则调用父类中定义的函数，如果父类指针指向的是子类对象则调用子类中定义的重写函数，如图所示。 虚函数的应用C++ 中通过 virtual 关键字对多态进行支持，使用 virtual 关键字声明的函数被重写后即可展现多态特性，一般称之为 虚函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a) { this-&gt;a = a; } // 使用 \"virtual\" 关键字声明父类的函数 virtual void print() { cout &lt;&lt; \"I'm parent, a = \" &lt;&lt; a &lt;&lt; endl; }private: int a;};class Child : public Parent {public: Child(int c) : Parent(c) { this-&gt;c = c; } // 使用 \"virtual\" 关键字声明重写父类中的函数 // 只要父类中的函数有 \"virtual\" 关键字的声明，那么子类的 \"virtual\" 声明可写可不写，一般建议都写上 virtual void print() { cout &lt;&lt; \"I'm child, c = \" &lt;&lt; c &lt;&lt; endl; }private: int c;};int main() { Parent* p = NULL; Parent parent(6); Child child(5); // 执行父类的函数 p = &amp;parent; p-&gt;print(); // 执行子类的函数 p = &amp;child; p-&gt;print(); return 0;} 程序运行的输出结果如下： 12I'm parent, a = 6I'm child, c = 5 此时，编译器看的是指针的内容，而不是它的类型。因此，由于 Parent 和 Child 类的对象的地址存储在 *p 中，所以会调用各自的 print() 函数。正如所看到的，父类 Parent 的每个子类都有一个 print() 函数的独立实现。这就是多态的一般使用方式，即使用一个父类的指针或引用去调用子类中被重写的方法。有了多态就可以有多个不同的实现类，它们都带有同一个名称但具有不同实现的函数，函数的参数甚至可以是相同的。 虚析构函数虚析构函数的作用：为了避免内存泄漏，通过父类的指针，可以将所有子类对象的析构函数都执行一遍（释放所有的子类资源）。即虚析构函数使得在删除指向子类对象的父类指针时，可以调用子类的析构函数来实现释放子类中堆内存的目的，从而防止内存泄漏。 析构函数可以是虚的，虚析构函数用于指引 delete 运算符正确析构动态对象 构造函数不能是虚函数，因为建立一个派生类对象时，必须从类层次的根开始，沿着继承路径逐个调用基类的构造函数 虚析构函数的简单应用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;using namespace std;class A {public: A() { this-&gt;p = new char[20]; strcpy(p, \"Hello A\"); cout &lt;&lt; \"A 类的构造函数被调用\" &lt;&lt; endl; } virtual ~A() { delete[] this-&gt;p; cout &lt;&lt; \"A 类的析构函数被调用\" &lt;&lt; endl; }private: char* p;};class B : public A {public: B() { this-&gt;p = new char[20]; strcpy(p, \"Hello B\"); cout &lt;&lt; \"B 类的构造函数被调用\" &lt;&lt; endl; } ~B() { delete[] this-&gt;p; cout &lt;&lt; \"B 类的析构函数被调用\" &lt;&lt; endl; }private: char* p;};int main() { // 此写法，如果上面不使用 \"virtual\" 修饰A类（基类）的析构函数，派生类与所有基类的析构函数依然都会被自动调用一次 B* b = new B(); delete b; cout &lt;&lt; endl; // 此写法，如果上面不使用 \"virtual\" 修饰A类（基类）的析构函数，那么只有A类（基类）的析构函数会被调用一次，B类（派生类）的析构函数不会被调用，这样就会造成内存泄漏 // 虚析构函数的作用是，通过父类的指针，可以将所有子类对象的析构函数都执行一遍（释放所有的子类资源）。 A* a = new B(); delete a; return 0;} 程序运行的输出结果如下： 123456789A 类的构造函数被调用B 类的构造函数被调用B 类的析构函数被调用A 类的析构函数被调用A 类的构造函数被调用B 类的构造函数被调用B 类的析构函数被调用A 类的析构函数被调用 虚析构函数的作用总结 a) 如果基类的析构函数不加 virtual 关键字修饰，那么就是普通析构函数 当基类中的析构函数没有声明为虚析构函数时，派生类开始从基类继承，基类的指针指向派生类的对象时，delete 基类的指针时，只会调用基类的析构函数，不会调用派生类的析构函数 b) 如果基类的析构函数加 virtual 关键字修饰，那么就是虚析构函数 当基类中的析构函数声明为虚析构函数时，派生类开始从基类继承，基类的指针指向派生类的对象时，delete 基类的指针时，先调用派生类的析构函数，再调用基类中的析构函数 多态的理论基础 联编：是指一个程序模块、代码之间互相关联的过程 静态联编：是程序的匹配、连接在编译阶段实现，也称为早期联编（早绑定） 函数重载属于静态联编 动态联编：是指程序联编推迟到运行时进行，所以又称为晚期联编（迟绑定） 虚函数、switch 语句和 if 语句属于动态联编 多态理论联系实际应用（代码示例）： C++ 与 C 相同，是静态编译型语言 在编译时，编译器会自动根据指针的类型判断指向的是一个什么样的对象，所以编译器认为父类指针指向的是父类对象 由于程序没有运行，所以不可能知道父类指针指向的具体是父类对象还是子类对象 从程序安全的角度，编译器假设父类指针只指向父类对象，因此编译的结果为调用父类的成员函数，这种特性就是 静态联编 多态成立的三个必要条件 a) 要有继承 b) 要有虚函数重写 c) 父类指针或引用指向子类对象 C++ 11 的 override 和 finaloverride 关键字：用来检查函数是否重写，在子类中的函数声明里加上该关键字 virtual void fun() override {}，编译器就会自动检查对应的函数是否重写了父类中的函数final 关键字：在类的声明中加上该关键字 class A final {};，目的是为了不让这个类被继承。或者，在一个函数后加上该关键字，表示这个函数不能被重写 void fun() final {} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"Vue 开发随笔","url":"/posts/d786f74a.html","text":"Vue 版本升级若项目需要升级 Vue 的版本，一般主要是升级 vue 和 vue-template-compiler 组件，而且两者的版本号必须一致，升级步骤如下： a) 删除项目里的 node_modules 文件夹 和 package-lock.json 文件 b) 执行 npm view vue versions 命令查看 Vue 的所有版本号 c) 更改项目里的 package.json 文件，为 vue 和 vue-template-compiler 组件指定新的版本号 d) 在项目里执行 npm install 命令 e) 重新编译构建项目，观察项目代码是否可以正常编译 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端 开发随笔"},{"title":"C++ 入门基础之七","url":"/posts/e4826e2c.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 继承概念面向对象程序设计有 4 个主要特点：抽象、封装、继承和多态性。面向对象程序设计的两个重要特征一数据抽象与封装，两者已经能够设计出基于对象的程序，这是面向对象程序设计的基础。要较好地进行面向对象程序设计，还必须了解面向对象程序设计另外两个重要特征 —— 继承性和多态性。继承性是面向对象程序设计最重要的特征，可以说，如果没有掌握继承性，就等于没有掌握类和对象的精华，就是没有掌握面向对象程序设计的真谛。 类之间的关系类之间一般有三种关系：has-A、uses-A 和 is-A： has-A：包含关系，用以描述一个类由多个 “部件类” 构成。实现 has-A 关系可以用类成员表示，即一个类中的数据成员是另一种已经定义的类。 uses-A：一个类部分地使用另一个类。类之间成员函数的联系，可以通过定义友元或者对象参数传递来实现。 is-A：机制称为 “继承” 。关系具有传递性，不具有对称性。 继承关系举例 继承相关概念 派生类的定义 值得一提的是，C++ 中的继承方式（public、private、protected）会影响子类的对外访问属性。 继承重要说明 a) 子类拥有父类的所有成员变量和成员函数 b) 子类可以拥有父类没有的方法和属性 c) 子类就是一种特殊的父类 d) 子类对象可以当作父类对象使用 继承使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;// 定义父类（基类）（父类）class Parent {public: Parent(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; \"a=\" &lt;&lt; this-&gt;a &lt;&lt; \", b=\" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: int a; int b;};// 定义派生类（子类）class Child : public Parent {public: Child(int a = 0, int b = 0, int c = 0) { // 直接访问父类（基类）（父类）的成员变量 this-&gt;a = a; this-&gt;b = b; this-&gt;c = c; } void echo() { cout &lt;&lt; \"a=\" &lt;&lt; this-&gt;a &lt;&lt; \", b=\" &lt;&lt; this-&gt;b &lt;&lt; \", c=\" &lt;&lt; this-&gt;c &lt;&lt; endl; }private: int c;};int main() { Child child(1, 2, 3); child.print(); // 直接调用父类（基类）（父类）的成员函数 child.echo(); // 直接调用派生类（子类）的成员函数 return 0;} 程序运行的输出结果如下： 12a=1, b=2a=1, b=2, c=3 派生类的访问控制派生类（子类）继承了基类（父类）的全部成员变量和成员函数（除了构造函数和析构函数之外的成员函数），但是这些成员的访问属性，在派生过程中是可以调整的。 单个类的访问控制在 C++ 中，类成员变量和类成员函数的访问级别为 public、private、protected private：修饰的成员变量和成员函数，只能在类的内部被访问 public：修饰的成员变量和成员函数，可以在类的内部和类的外部被访问 protected：修饰的成员变量和成员函数，可以在派生类的内部访问，不能在派生类的外部被访问 特别注意：若在类中没有声明访问控制级别的成员变量和成员函数，默认都是 private 访问级别的 继承成员的访问控制在 C++ 中，不同的继承方式（public、private、protected）会改变继承成员的访问属性： public 继承：父类成员在子类中保持原有的访问级别 private 继承：父类成员在子类中都变为 private 成员 protected 继承：父类中 public 成员会变成 protected，父类中 private 成员仍然为 private，父类中 protected 成员仍然为 protected 特别注意：private 成员在子类中依然存在，但是无法访问到的，即不论使用哪种方式继承父类，子类都不能直接使用父类的私有成员 继承成员访问控制的 “三看” 原则在 C++ 中，不同的继承方式（public、private、protected）会改变继承成员的访问属性，最终可总结为以下三个原则（判断某一句话，是否可以被访问）： a) 看调用语句是写在子类的内部还是外部 b) 看子类如何从父类继承（public、private、protected） c) 看父类中的访问级别（public、private、protected） 派生类成员访问级别控制的原则对于派生类自身的成员，访问级别控制的原则如下： a) 需要被外界访问的成员直接设置为 public b) 只能在当前类中访问的成员设置为 private c) 只能在当前类和子类中访问的成员设置为 protected 继承中的构造和析构类型兼容原则类型兼容规则是指在需要基类对象的任何地方，都可以使用公有派生类（公有继承）的对象来替代。通过公有继承，派生类得到了基类中除构造函数、析构函数之外的所有成员。这样，公有派生类实际就具备了基类的所有功能，凡是基类能解决的问题，公有派生类都可以解决。值得一提的是，在替代之后，派生类对象就可以作为基类的对象使用，但是只能使用从基类继承得到的成员，类型兼容规则是多态性的重要基础之一。类型兼容规则中所指的替代包括以下情况： 子类对象可以当作父类对象使用 子类对象可以直接赋值给父类对象 子类对象可以直接初始化父类对象 父类指针可以直接指向子类对象 父类引用可以直接引用子类对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;using namespace std;// 父类class Parent {public: void printParent() { cout &lt;&lt; \"I'm parent\" &lt;&lt; endl; }private: int a;};// 子类（公有继承）class Child : public Parent {public: void printChild() { cout &lt;&lt; \"I'm child\" &lt;&lt; endl; }private: int c;};void howToPrint(Parent* p) { p-&gt;printParent();}void howToPrint(Parent&amp; p) { p.printParent();}int main() { Parent p1; p1.printParent(); Child c1; c1.printChild(); c1.printParent(); // 1-1 父类指针可以直接指向子类对象 cout &lt;&lt; \"1-1\" &lt;&lt; endl; Parent* p2 = NULL; p2 = &amp;c1; p2-&gt;printParent(); // 1-2 父类指针可以直接指向子类对象，指针做函数参数 cout &lt;&lt; \"1-2\" &lt;&lt; endl; howToPrint(&amp;p1); howToPrint(&amp;c1); // 2-1 父类引用可以直接引用子类对象 cout &lt;&lt; \"2-1\" &lt;&lt; endl; Parent&amp; p3 = c1; p3.printParent(); // 2-2 父类引用可以直接引用子类对象，引用做函数参数 cout &lt;&lt; \"2-2\" &lt;&lt; endl; howToPrint(p1); howToPrint(c1); // 3-1 子类对象可以直接初始化父类对象，会自动调用父类的拷贝构造函数 cout &lt;&lt; \"3-1\" &lt;&lt; endl; Parent p4 = c1; p4.printParent(); // 4-1 子类对象可以直接赋值给父类对象 cout &lt;&lt; \"4-1\" &lt;&lt; endl; Parent p5; p5 = c1; p5.printParent(); return 0;} 程序运行输出的结果如下： 1234567891011121314151617I'm parentI'm childI'm parent1-1I'm parent1-2I'm parentI'm parent2-1I'm parent2-2I'm parentI'm parent3-1I'm parent4-1I'm parent 继承中的对象模型类在 C++ 编译器的内部可以理解为结构体，子类是由父类成员叠加子类新成员得到的。 父类与子类的构造函数、析构函数的关系如下： 在子类对象构造时，需要调用父类构造函数对其继承得来的成员进行初始化 在子类对象析构时，需要调用父类析构函数对其继承得来的成员进行清理 继承中的构造与析构的调用原则 a) 子类对象在创建时，会首先调用父类的构造函数 b) 父类构造函数执行结束后，再执行子类的构造函数 c) 当父类只存在有参构造函数时，必须在子类的初始化列表中显示调用父类的构造函数 d) 析构函数调用的先后顺序与构造函数相反，即先调用子类的析构函数，再调用父类的析构函数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; \"父类的构造函数被调用\" &lt;&lt; endl; } ~Parent() { cout &lt;&lt; \"父类的析构函数被调用\" &lt;&lt; endl; } void printParent() { cout &lt;&lt; \"I'm parent, a = \" &lt;&lt; this-&gt;a &lt;&lt; \", b = \" &lt;&lt; this-&gt;b &lt;&lt; endl; }private: int a; int b;};class Child : public Parent {public: // 当父类只存在有参构造函数时，必须在子类的初始化列表中显示调用 Child(int a, int b, int c) : Parent(a, b) { this-&gt;c = c; cout &lt;&lt; \"子类的构造函数被调用\" &lt;&lt; endl; } ~Child() { cout &lt;&lt; \"子类的析构函数被调用\" &lt;&lt; endl; } void printChild() { cout &lt;&lt; \"I'm child, c = \" &lt;&lt; this-&gt;c &lt;&lt; endl; }private: int c;};int main() { Child c1(1, 2, 3); c1.printParent(); c1.printChild(); return 0;} 程序运行的输出结果如下： 123456父类的构造函数被调用子类的构造函数被调用I'm parent, a = 1, b = 2I'm child, c = 3子类的析构函数被调用父类的析构函数被调用 继承与组合混搭情况下，构造和析构的调用原则继承与组合对象混搭使用的情况下，构造函数与析构函数的调用原则如下： 构造函数的调用：先构造父类，再构造成员变量，最后构造自身 析构函数的调用：先析构自身，再析构成员变量，最后析构父类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;iostream&gt;using namespace std;class Object {public: Object(int a, int b) { this-&gt;a = a; this-&gt;b = b; cout &lt;&lt; \"Object类的构造函数被调用\" &lt;&lt; endl; } ~Object() { cout &lt;&lt; \"Object类的析构函数被调用\" &lt;&lt; endl; } void printObject() { cout &lt;&lt; \"I'm object, a = \" &lt;&lt; this-&gt;a &lt;&lt; \", b = \" &lt;&lt; this-&gt;b &lt;&lt; endl; }protected: int a; int b;};class Parent : public Object {public: // 通过初始化列表，调用父类的构造函数 Parent(char* p) : Object(1, 2) { this-&gt;p = p; cout &lt;&lt; \"Parent类的构造函数被调用\" &lt;&lt; endl; } ~Parent() { cout &lt;&lt; \"Parent类的析构函数被调用\" &lt;&lt; endl; } void printParent() { cout &lt;&lt; \"I'm parent, p = \" &lt;&lt; p &lt;&lt; endl; }protected: char* p;};class Child : public Parent {public: // 通过初始化列表，调用组合对象与父类的构造函数 Child(char* c) : obj1(3, 4), obj2(5, 6), Parent(c) { this-&gt;c = c; cout &lt;&lt; \"Child类的构造函数被调用\" &lt;&lt; endl; } ~Child() { cout &lt;&lt; \"Child类的析构函数被调用\" &lt;&lt; endl; } void printChild() { cout &lt;&lt; \"I'm child, p = \" &lt;&lt; p &lt;&lt; endl; }protected: char* c; // 组合对象 Object obj1; Object obj2;};int main() { char* str = new char[3]; str[0] = 'J'; str[1] = 'i'; str[2] = 'm'; Child c1(str); c1.printChild(); c1.printParent(); c1.printObject(); return 0;} 程序运行的输出结果如下： 12345678910111213Object类的构造函数被调用Parent类的构造函数被调用Object类的构造函数被调用Object类的构造函数被调用Child类的构造函数被调用I'm child, p = JimI'm parent, p = JimI'm object, a = 1, b = 2Child类的析构函数被调用Object类的析构函数被调用Object类的析构函数被调用Parent类的析构函数被调用Object类的析构函数被调用 继承中的同名成员的处理方式 当子类成员与父类成员同名时，子类依然可以从父类继承同名成员 在子类中通过作用域分辨符 :: 进行同名成员的区分（在子类中使用父类的同名成员，需要显式地使用类名限定符），其作用类似 Java 中的 super 关键字 同名成员存储在内存中的不同位置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;class Parent {public: Parent(int a, int b) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; \"I'm parent, a = \" &lt;&lt; a &lt;&lt; \", b = \" &lt;&lt; b &lt;&lt; endl; }public: int a; int b;};class Child : public Parent {public: Child(int a, int b) : Parent(a, b) { this-&gt;a = a + 5; this-&gt;b = b + 5; } void print() { cout &lt;&lt; \"I'm child, a = \" &lt;&lt; a &lt;&lt; \", b = \" &lt;&lt; b &lt;&lt; endl; }public: int a; int b;};int main() { Child child(1, 2); // 子类访问自身的同名成员函数 child.print(); // 子类访问自身的同名成员变量 cout &lt;&lt; \"child's a = \" &lt;&lt; child.a &lt;&lt; endl; cout &lt;&lt; \"child's b = \" &lt;&lt; child.b &lt;&lt; endl; // 子类访问父类的同名成员函数 child.Parent::print(); // 子类访问父类的同名成员变量 cout &lt;&lt; \"parent's a = \" &lt;&lt; child.Parent::a &lt;&lt; endl; cout &lt;&lt; \"parent's b = \" &lt;&lt; child.Parent::b &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 123456I'm child, a = 6, b = 7child's a = 6child's b = 7I'm parent, a = 1, b = 2parent's a = 1parent's b = 2 派生类中的 static 关键字使用在 C++ 的普通类中，static 关键字的使用可以看 这里，而派生类中 static 关键字的使用说明如下： 基类定义的静态成员，将被所有派生类共享 根据静态成员自身的访问特性和派生类的继承方式，在类层次体系中具有不同的访问性质（遵守派生类成员访问级别控制的原则） 在派生类中访问基类的静态成员，需要显式说明，对应的语法是：类名 :: 成员 或者通过对象访问：对象名 . 成员 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;using namespace std;class Parent {public: // 声明公有的静态成员函数 static void print() { cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; \", b = \" &lt;&lt; b &lt;&lt; endl; }public: // 声明公有的静态成员变量 static int a;private: // 声明私有的静态成员变量 static int b;};// 定义私有的静态成员变量int Parent::b = 50;// 定义公有的静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存, 否则在派生类中用到该变量就会报错int Parent::a = 30;class Child : public Parent {public: int getA() { // 访问从基类继承得到的静态成员变量 return this-&gt;a; } int getA2() { // 访问基类的静态成员变量 return Parent::a; } int getB() { // return b; 错误写法，基类中静态成员自身的访问特性遵守派生类的访问级别控制原则，因此这里不能访问基类中私有的静态成员变量b return 0; } // 调用从基类继承得到的静态成员函数 void print2() { this-&gt;print(); } // 调用基类的静态成员函数 void print1() { Parent::print(); }};int main() { // 在类外访问基类的静态成员变量和静态成员函数 Parent::a++; Parent::print(); cout &lt;&lt; endl; // 在类外访问派生类的静态成员变量和静态成员函数 cout &lt;&lt; \"a = \" &lt;&lt; Child::a &lt;&lt; endl; Child::print(); cout &lt;&lt; endl; Child c1; cout &lt;&lt; \"a = \" &lt;&lt; c1.getA() &lt;&lt; endl; cout &lt;&lt; \"a = \" &lt;&lt; c1.getA2() &lt;&lt; endl; cout &lt;&lt; \"a = \" &lt;&lt; c1.Parent::a &lt;&lt; endl; cout &lt;&lt; endl; c1.print1(); c1.print2(); c1.Parent::print(); return 0;} 程序运行的输出结果如下： 123456789101112a = 31, b = 50a = 31a = 31, b = 50a = 31a = 31a = 31a = 31, b = 50a = 31, b = 50a = 31, b = 50 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"CMake 入门教程之二常用命令","url":"/posts/881a3bba.html","text":"查找文件查找源文件12345678# 查找 src 目录下的所有源文件，并保存到 SOURCE_FILES 变量aux_source_directory(src SOURCE_FILES)# 查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB SOURCE_FILES \"src/*.cpp\")# 递归查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB_RECURSE SOURCE_FILES \"src/*.cpp\") 排除指定的文件12345# 查找 src 目录下所有以 .cpp 开头的文件，并保存到 SOURCE_FILES 变量file(GLOB SOURCE_FILES \"src/*.cpp\")# 排除 example.cpp 源文件list(FILTER SOURCE_FILES EXCLUDE REGEX \"example.cpp\") 输出目录指定输出目录12345# 指定构建输出的目录（build 目录）set(PROJECT_BINARY_DIR ${PROJECT_SOURCE_DIR}/build)# 指定可执行文件的输出目录（bin 目录）set(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/bin) 编译代码设置编译参数1234567set(CMAKE_CXX_COMPILER \"clang++\") # 指定使用的 C++ 编译器set(CMAKE_CXX_FLAGS \"-std=c++11\") # 指定使用的 C++ 的版本set(CMAKE_CXX_FLAGS \"-g\") # 输出调试信息set(CMAKE_CXX_FLAGS \"-Wall\") # 开启所有警告set(CMAKE_CXX_FLAGS_DEBUG \"-O0\") # 调试包不优化set(CMAKE_CXX_FLAGS_RELEASE \"-O2 -DNDEBUG\") # 发布包优化set(CMAKE_CXX_FLAGS \"-lpthread\") # 链接 pthread 库 设置预处理指令1234567891011121314#include &lt;iostream&gt;using namespace std;int main() {#ifdef TARGET cout &lt;&lt; \"Hello!\" &lt;&lt; endl;#else cout &lt;&lt; \"World!\" &lt;&lt; endl;#endif return 0;} CMake 指定编译参数 1set(CMAKE_CXX_FLAGS \"-DTARGET\") 调试信息打印日志信息提示 使用 MESSAGE() 指令可以输出指定的日志信息，例如打印 CMake 变量的值 123456# 查找 GoogleTest 库FIND_PACKAGE(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS \"GTEST_INCLUDE_DIRS : \" ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS \"GTEST_BOTH_LIBRARIES : \" ${GTEST_BOTH_LIBRARIES}) 链接第三方库查找并链接系统的第三方库这里以第三方库 GoogleTest 为例子，其中 GoogleTest 是手动安装到 Linux 系统上的（编译安装或者通过包管理器安装）。 123456789# 查找 GoogleTest 库find_package(GTest REQUIRED)# 显示 GoogleTest 库的路径MESSAGE(STATUS \"GTEST_INCLUDE_DIRS : \" ${GTEST_INCLUDE_DIRS})MESSAGE(STATUS \"GTEST_BOTH_LIBRARIES : \" ${GTEST_BOTH_LIBRARIES})# 链接 GoogleTest 库target_link_libraries(${PROJECT_NAME} ${GTEST_BOTH_LIBRARIES}) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ c语言 linux系统编程"},{"title":"CTP 程序化交易基础之一","url":"/posts/d35e15f1.html","text":"CTP 介绍CTP 简介综合交易平台（Comprehensive Transaction Platform，CTP）是专门为期货公司开发的一套期货经纪业务管理系统，由交易、风险控制和结算三大系统组成。其中，交易系统主要负责订单处理、行情转发及银期转账业务，结算系统负责交易管理、帐户管理、经纪人管理、资金管理、费率设置、日终结算、信息查询以及报表管理等，风控系统则主要在盘中进行高速的实时试算，以及时揭示并控制风险。系统能够同时连通国内四家期货交易所，支持国内商品期货和股指期货的交易结算业务，并能自动生成、报送保证金监控文件和反洗钱监控文件。 CTP 架构综合交易平台是基于全内存的交易系统，采用创新的完全精确重演的分布式体系架构，支持 7x24 小时连续交易，运维人员不必每日启停系统，可以做到 “一键运维”，该特性使得综合交易平台新增交易中心以扩展业务规模时不用增加运维人力的成本。支持 FENS 机制的 “一键切换” 多活交易中心也是目前市场上只有 CTP 系统实现了的特性。该机制使得交易系统可在某个交易中心宕机的情况下立即切换到另一个备用交易中心，得以实现真真正正的连续交易。综合交易平台公开并对外开放交易系统接口，使用该接口可以接收交易所的行情数据和执行交易指令。该接口采用开放接口（API）的方式接入，早已在期货界已经形成事实上的行业标准。 CTP API从 CTP 官网（非交易时段禁止访问）可以了解到，CTP API 从 v6.3.15 版开始引入强制看穿式认证规则，CTP 不再兼容之前的 API 版本。目前，CTP API 最新版是 v6.6.1，与 v6.3.15 相比较最大的改动是，InstrumentID 由最长 30 个字节增加到 80 个字节。CTP 生产系统兼容 v6.3.15 及以上版本。但是，大部分期货公司做看穿式认证的仿真系统要求使用新版 API 才能接入。所以，新用户做看穿式认证时首先要确认 API 的版本号。 CTP 仿真系统SimNow 仿真系统SimNow 是上期技术为广大投资者打造的一个最接近真实市场环境的仿真平台，主要面向期货经纪公司和投资者服务，提供整套期货交易的信息化技术平台。SimNow 官网（非交易时段禁止访问），交易者注册 SimNow 仿真账户后，可以使用从 CTP 官网下载 API 接入这套仿真交易系统。开发、测试完成之后，只需要更换用户名、密码、前置地址等信息就可以接入期货公司生产系统进行实盘交易。SimNow 要求 CTP API 的版本是 v6.3.15 及以上才能够接入。 认证信息123BrokerID = \"9999\"AppID = \"SimNow_client_test\"AuthCode = \"0000000000000000\" 值得一提的是，默认的 BrokerID 为 9999，AppID 为 SimNow_client_test，AuthCode 为 0000000000000000（16个0），默认不会开终端认证，程序化用户可以选择不开终端认证接入。 生产仿真环境以下的前置地址，交易时段与真实生产环境（实盘）一致。 电信 12FrontAddr=tcp://180.168.146.187:10201FrontMdAddr=tcp://180.168.146.187:10211 电信 12FrontAddr=tcp://180.168.146.187:10202FrontMdAddr=tcp://180.168.146.187:10212 移动 12FrontAddr=tcp://218.202.237.33:10203FrontMdAddr=tcp://218.202.237.33:10213 测试仿真环境 支持全天交易（7x24），不间断轮播某天行情 SimNow 新注册用户，需要等到第三个交易日才能使用 交易时段：交易日 16：00 ～ 次日 09：00；非交易日 16：00 ～ 次日 15：00 仅服务于 CTP API 开发爱好者，仅为用户提供 CTP API 测试需求，不提供结算等其它服务 12FrontAddr=tcp://180.168.146.187:10130FrontMdAddr=tcp://180.168.146.187:10131 仿真成交规则 期货交易按照交易所公布的买一卖一价对价成交 买入时：如果委托价大于等于卖一价，则成交，成交价为委托价、卖一价、最新价三价取中，如果委托价小于卖一价，不能成交，等待更优的行情才能成交 卖出时：如果委托价小于等于买一价，则成交，成交价为委托价、买一价、最新价三价取中，如果委托价大于买一价，不能成交，等待更优的行情才能成交 仿真交易时间 NSight 仿真系统交易者在 NSight 官网 注册仿真账户后，可以使用从 CTP 官网下载的 API v6.3.15 接入这套仿真交易系统。开发、测试完成之后，只需要更换用户名、密码、前置地址等信息就可以接入期货公司生产系统进行实盘交易。 认证信息123BrokerID = \"10010\"AppID = \"\"AuthCode = \"\" 值得一提的是，默认的 BrokerID 为 10010，AppID 与 AuthCode 均为空字符串。 生产仿真环境以下的前置地址，交易时段与真实生产环境（实盘）一致。 12FrontAddr=tcp://210.14.72.12:4600FrontMdAddr=tcp://210.14.72.12:4602 期货交易终端市面上主流的期货交易终端可以在 SimNow 官网（非交易时段禁止访问）下载。 快期期货交易终端对于量化交易者，在没有自主开发监控客户端之前，快期是一个很不错的选择。这里以 快期 v2 版本举例，若使用快期登录 SimNow 的模拟账户，则只需要在快期的登录界面选择服务器 上期技术-xx 即可，下拉列表里不同的服务器分别使用了不同的前置地址，而 用户代码 直接填写 InvestorID。 CTP 开放平台 CTP 开放平台 CTP 开放平台运行环境监控 CTP 接口兼容模拟交易平台介绍 - 类似 SimNow 参考博客 CTP API 版本说明 CTP API 各版本官方下载 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"量化交易"},{"title":"C++ 入门基础之六","url":"/posts/a54941f5.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 友元函数类的友元函数是定义在类的外部，但有权访问类的所有私有（private）成员和保护（protected）成员。尽管友元函数的原型在类的声明中出现过，但是友元函数并不是类的成员函数，而是普通函数（全局函数）。如果要声明函数为一个类的友元，需要在类定义中该函数原型前使用关键字 friend。 友元函数的规则为什么要引入友元函数： C++ 利用 friend 修饰符，可以让一些设定的函数能够对一些保护数据进行访问，避免把类的成员全部设置成 public，最大限度的保护数据成员的安全。同时友元函数可以实现类之间的数据共享，减少系统开销，提高效率。由于友元函数破环了封装机制，因此推荐尽量使用成员函数，除非不得已的情况下才使用友元函数。 什么时候使用友元函数： 多个类要共享数据的时候 运算符重载的某些场合需要使用友元函数 友元函数的参数： 因为友元函数没有 this 指针，所以参数会有三种情况： a) 要访问非 static 成员时，需要对象做参数 b) 要访问 static 成员或全局变量时，则不需要对象做参数 c) 如果做参数的对象是全局对象，则不需要对象做参数 友元函数的位置： 因为友元函数是类外的函数（普通函数），所以它的声明可以放在类的私有段（private）或公有段（public），两者都是没有区别的 一个函数可以是多个类的友元函数，只需要在各个类中分别声明即可 友元函数的调用： 可以直接调用友元函数，不需要通过对象或指针 友元函数的调用与普通函数（全局函数）的调用方式和原理一致 友元函数的使用123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class A {public: A(int a) { this-&gt;a = a; } int getA() { return this-&gt;a; } // 声明友元函数 friend void update2(A* p);private: int a;};void update1(A* p) { // p-&gt;a = 30; // 错误写法，在普通函数（全局函数）内，私有数据成员不能在类外被访问}void update2(A* p) { p-&gt;a = 30; // 在友元函数内，可以通过对象参数访问私有数据成员}int main() { A* a = new A(10); update2(a); // 调用友元函数 cout &lt;&lt; \"a = \" &lt;&lt; a-&gt;getA() &lt;&lt; endl; delete a; return 0;} 程序运行的输出结果如下： 1a = 30 友元类友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的私有（private）成员和保护（protected）成员。当希望一个类可以访问另一个类的保护数据时，可以将该类声明为另一类的友元类。定义友元类的语法格式为 friend class 类名;，其中类名必须是程序中的一个已定义过的类。值得一提的是，友元类通常设计为一种对数据操作或类之间传递消息的辅助类。 友元类的规则 友元关系不能被继承 友元关系是单向的，不具有交换性。若类 B 是类 A 的友元，则类 A 不一定是类 B 的友元，要看在类 B 中是否有相应的声明 友元关系不具有传递性，若类 B 是类 A 的友元，类 C 是 类 B 的友元，则类 C 不一定是类 A 的友元，要看类 A 中是否有相应的声明 友元类的使用1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;using namespace std;class A {public: // 声明友元类 B friend class B; void print() { cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl; }private: int a;};class B {public: void setValue(int a) { aObj.a = a; // 类 B 是类 A 的友元类，因此 B 类的所有成员函数都可以访问 A 类的私有成员或者保护成员 } void print() { aObj.print(); }private: A aObj;};int main() { B b; b.setValue(100); b.print(); return 0;} 程序运行的输出结果如下： 1a = 100 运算符重载基础所谓重载，就是重新赋予新的含义。函数重载就是对一个已有的函数赋予新的含义，使之实现新功能，因此，一个函数名就可以用来代表不同功能的函数，也就是 一名多用。运算符也可以重载，实际上，开发者已经在不知不觉之中使用了运算符重载。例如，大家都已习惯于用加法运算符 + 对整数、单精度数和双精度数进行加法运算，如 5 + 8，5.8 + 3.67 等，其实计算机对整数、单精度数和双精度数的加法操作过程是很不相同的，但由于 C++ 已经对运算符 + 进行了重载，所以就能适用于 int、float、doUble 类型的运算。又如 &lt;&lt; 是 C++ 的位运算中的位移运算符（左移），但在输出操作中又是与流对象 cout 配合使用的流插入运算符。&gt;&gt; 也是位移运算符 (右移），但在输入操作中又是与流对象 cin 配合使用的流提取运算符。这就是运算符重载 (Operator Overloading)。C++ 系统对 &lt;&lt; 和 &gt;&gt; 进行了重载，用户在不同的场合下使用它们时，作用是不同的。对 &lt;&lt; 和 &gt;&gt; 的重载处理是放在头文件 stream 中的。因此，如果要在程序中用 &lt;&lt; 和 &gt;&gt; 作流插入运算符和流提取运算符，必须在本文件模块中包含头文件 stream，当然还应当包括命名空间的使用声明 using namespace std。 运算符重载的语法 例如： 使用类成员函数完成 \"-\" 运算符重载的语法：Complex operator-(Complex &amp;c2) 使用友元函数完成 \"+\" 运算符重载的语法：Complex operator+(Complex &amp;c1, Complex &amp;c2) 运算符重载的限制 运算符重载的两种方式 前置与后置运算符重载规则在 C++ 中是通过一个占位参数（int）来区分前置运算符和后置运算符的重载，例如 ++a、a++、--b、b--。 运算符重载的简单使用案例二元运算符重载在下述的案例中，演示了如何使用类成员函数和友元函数实现二元运算符的重载。值得一提的是，除了使用友元函数外，还可以使用全局函数（普通函数）来实现运算符的重载，不同的是使用友元函数更方便，可以直接访问类的所有私有（private）成员和保护（protected）成员。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; \"a=\" &lt;&lt; this-&gt;a &lt;&lt; \", b=\" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: // 使用类成员函数完成 \"-\" 运算符的重载 Complex operator-(Complex&amp; c2) { Complex c3(this-&gt;a - c2.a, this-&gt;b - c2.b); return c3; } // 声明用于 \"+\" 运算符重载的友元函数 friend Complex operator+(Complex&amp; c1, Complex&amp; c2);};// 定义友元函数完成 \"+\" 运算符的重载Complex operator+(Complex&amp; c1, Complex&amp; c2) { Complex c3(c1.a + c2.a, c1.b + c2.b); return c3;}int main() { Complex c1(1, 2), c2(3, 4); // 直接调用友元函数 Complex c3 = operator+(c1, c2); c3.print(); // 使用友元函数完成 \"+\" 运算符的重载 Complex c4 = c1 + c2; c4.print(); // 直接调用类成员函数 Complex c5 = c1.operator-(c2); c5.print(); // 使用类成员函数完成 \"-\" 运算符的重载 Complex c6 = c1 - c2; c6.print(); return 0;} 程序运行的输出结果如下： 1234a=4, b=6a=4, b=6a=-2, b=-2a=-2, b=-2 一元运算符重载在下述的案例中，演示了如何使用类成员函数和友元函数实现一元运算符的重载。值得一提的是，除了使用友元函数外，还可以使用全局函数（普通函数）来实现运算符的重载，不同的是使用友元函数更方便，可以直接访问类的所有私有（private）成员和保护（protected）成员。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } void print() { cout &lt;&lt; \"a=\" &lt;&lt; this-&gt;a &lt;&lt; \", b=\" &lt;&lt; this-&gt;b &lt;&lt; endl; }public: // 使用类成员函数完成 \"前置--\" 运算符的重载 Complex&amp; operator--() { this-&gt;a--; this-&gt;b--; return *this; } // 使用类成员函数完成 \"后置--\" 运算符的重载 // 使用占位参数进行函数重载，是为了解决与 \"前置--\" 类成员函数冲突的问题 Complex operator--(int) { Complex tmp(this-&gt;a, this-&gt;b); this-&gt;a--; this-&gt;b--; return tmp; } // 声明用于 \"前置++\" 运算符重载的友元函数 friend Complex&amp; operator++(Complex&amp; c1); // 声明用于 \"后置++\" 运算符重载的友元函数 // 使用占位参数进行函数重载，是为了解决与 \"前置++\" 友元函数冲突的问题 friend Complex operator++(Complex&amp; c1, int);};// 定义友元函数完成 \"前置++\" 运算符的重载Complex&amp; operator++(Complex&amp; c1){ c1.a++; c1.b++; return c1;}// 定义友元函数完成 \"后置++\" 运算符的重载Complex operator++(Complex&amp; c1, int) { Complex tmp(c1.a, c1.b); c1.a++; c1.b++; return tmp;}int main() { Complex c1(1, 2), c2(8, 9), c3(15, 16), c4(24, 25); // 使用友元函数完成 \"前置++\" 运算符的重载 ++c1; c1.print(); // 使用类成员函数完成 \"前置--\" 运算符的重载 --c2; c2.print(); // 使用友元函数完成 \"后置++\" 运算符的重载 Complex c5 = c3++; c3.print(); c5.print(); // 使用类成员函数完成 \"后置--\" 运算符的重载 Complex c6 = c4--; c4.print(); c6.print(); return 0;} 程序运行的输出结果如下： 123456a=2, b=3a=7, b=8a=16, b=17a=15, b=16a=23, b=24a=24, b=25 左移运算符的重载值得一提的是，&lt;&lt; 左移运算符和 &gt;&gt; 右移运算符的重载，只能使用友元函数或者全局函数，不能使用类成员函数，这也是友元函数的重要作用之一。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class Complex {private: int a; int b;public: Complex(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; }public: // 声明友元函数实现 \"&lt;&lt;\" 左移运算符的重载 friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1);};// 定义友元函数实现 \"&lt;&lt;\" 左移运算符的重载ostream&amp; operator&lt;&lt;(ostream&amp; out, Complex&amp; c1) { out &lt;&lt; \"a=\" &lt;&lt; c1.a &lt;&lt; \", b=\" &lt;&lt; c1.b &lt;&lt; endl; return out;}int main() { Complex c1(1, 2), c2(6, 9); cout &lt;&lt; c1 &lt;&lt; c2; return 0;} 程序运行的输出结果如下： 12a=1, b=2a=6, b=9 等号运算符的重载 = 运算符的结合性是从右到左 = 运算符的重载用于对象数据的复制 必须通过类成员函数重载 = 运算符，不能使用友元函数 = 运算符重载的函数原型为：类型 &amp; 类名 :: operator= ( const 类名 &amp; ) ; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;#include \"string.h\"using namespace std;class Name {private: char* p; int len;public: Name(const char* name) { cout &lt;&lt; \"有参构造函数被调用了\" &lt;&lt; endl; len = strlen(name); p = new char[len + 1]; strcpy(p, name); } // 深拷贝的实现 Name(const Name&amp; name) { cout &lt;&lt; \"拷贝构造函数被调用了\" &lt;&lt; endl; len = name.getLen(); p = new char[len + 1]; strcpy(p, name.getP()); } ~Name() { cout &lt;&lt; \"析构函数被调用了\" &lt;&lt; endl; if (p != NULL) { delete[] p; p = NULL; len = 0; } } char* getP() const { return p; } int getLen() const { return len; }public: // 使用类成员函数实现 \"=\" 运算符的重载 Name&amp; operator=(const Name&amp; n) { // 释放内存空间 if (p != NULL) { delete[] p; p = NULL; len = 0; } // 重新分配内存空间 len = n.getLen(); p = new char[len + 1]; strcpy(p, n.getP()); return *this; }};int main() { Name obj1(\"Peter\"); Name obj2(\"Tom\"); Name obj4(\"Tim\"); // 会自动调用拷贝构造函数（属于深拷贝） Name obj3 = obj1; cout &lt;&lt; \"obj3.name: \" &lt;&lt; obj3.getP() &lt;&lt; \", obj3.len: \" &lt;&lt; obj3.getLen() &lt;&lt; endl; // 不会自动调用拷贝构造函数（属于浅拷贝） // 默认情况下，若这里不对 \"=\" 运算符进行重载，最终程序会异常终止运行（由于同一块内存空间被释放两次导致） obj4 = obj1; cout &lt;&lt; \"obj4.name: \" &lt;&lt; obj4.getP() &lt;&lt; \", obj4.len: \" &lt;&lt; obj4.getLen() &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12345678910有参构造函数被调用了有参构造函数被调用了有参构造函数被调用了拷贝构造函数被调用了obj3.name: Peter, obj3.len: 5obj4.name: Peter, obj4.len: 5析构函数被调用了析构函数被调用了析构函数被调用了析构函数被调用了 函数运算符的重载在下述的案例中，演示了如何使用类成员函数重载函数运算符 ()，值得一提的是，不能用友元函数重载函数运算符 ()。 12345678910111213141516#include &lt;iostream&gt;using namespace std;class Test {public: int operator()(int a, int b) { return a + b; }};int main() { Test test; cout &lt;&lt; test(3, 4) &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 17 运算符重载进阶为什么不要重载 &amp;&amp; 和 || 操作符 a) &amp;&amp; 和 || 是 C++ 中非常特殊的操作符 b) &amp;&amp; 和 || 内置实现了短路规则 c) 操作符重载是靠函数重载来完成的 d) 操作数作为函数参数传递 e) C++ 的函数参数都会被求值，无法实现短路规则 不同函数实现运算符重载的应用场景友元函数和类成员函数的选择方法： a) =、[]、() 和 -&gt; 运算符，只能通过类成员函数进行重载 b) 当无法修改左操作数的类时，只能通过友元函数进行重载，例如 &lt;&lt; 与 &gt;&gt; 运算符 友元函数重载 &lt;&lt; 与 &gt;&gt; 运算符： istream 和 ostream 是 C++ 的预定义流类 cin 是 istream 的对象，cout 是 ostream 的对象 运算符 &lt;&lt; 由 ostream 重载为插入操作，用于输出基本类型数据 运算符 &gt;&gt; 由 istream 重载为提取操作，用于输入基本类型数据 只能使用友元函数或者全局函数重载 &lt;&lt; 和 &gt;&gt; 运算符，输出和输入用户自定义的数据类型 类成员函数与友元函数实现运算符重载的步骤： a) 要承认运算符重载是一个函数，写出函数名称，如 operator +() b) 根据操作数，写出函数参数 c) 根据业务，完善函数的返回值（看函数是返回引用、指针还是元素），及实现函数业务；例如当函数的返回值充当左值时，需要返回一个引用 使用友元函数重载运算符的注意事项 a) 友元函数重载运算符常用于运算符的左右操作数类型不相同的场景 b) 在函数的第一个参数需要隐式转换的情形下，使用友元函数重载运算符是正确的选择 c) 友元函数没有 this 指针，所需操作数都必须在函数的参数表中显式声明，很容易实现类型的隐式转换 d) 在 C++ 中不能用友元函数重载的运算符分别有：=、[]、() 和 -&gt; e) 在 C++ 中不要重载 &amp;&amp; 和 || 运算符 f) C++ 的运算符重载遵循函数重载的规则 g) 除了重载运算符 &lt;&lt;、&gt;&gt; 必须使用友元函数之外，其他运算符的重载尽量都使用类成员函数，千万不要滥用友元函数，尤其类模板与友元函数一起使用的时候 运算符重载的综合使用案例重载自定义数组类的各种运算符在本案例中，自定义了数组类 Array，并使用类成员函数分别对 Array 类的 []、=、==、!= 运算符进行重载。 ★点击显示完整的案例代码★ Array.h 12345678910111213141516171819202122232425262728293031323334#pragma once#include &lt;iostream&gt;using namespace std;class Array {public: Array(int length); Array(const Array&amp; array); ~Array();public: int length();public: // 使用类成员函数重载 \"[]\" 数组下标运算符，用于数组元素的赋值和取值 int&amp; operator[](int index); // 使用类成员函数重载 \"=\" 运算符，用于数组之间的赋值 Array&amp; operator=(const Array&amp; array); // 使用类成员函数重载 \"==\" 运算符，判断两个数组是否相同 bool operator==(const Array &amp; array); // 使用类成员函数重载 \"!=\" 运算符，判断两个数组是否不相同 bool operator!=(const Array&amp; array);private: int m_length; int* m_space;}; Array.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include \"Array.h\"Array::Array(int length) { cout &lt;&lt; \"有参构造函数被调用\" &lt;&lt; endl; if (length &lt; 0) { length = 0; } this-&gt;m_length = length; this-&gt;m_space = new int[length];}Array::Array(const Array&amp; array) { cout &lt;&lt; \"拷贝构造函数被调用\" &lt;&lt; endl; // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; }}Array::~Array() { cout &lt;&lt; \"析构函数被调用\" &lt;&lt; endl; if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}// 使用类成员函数重载 \"[]\" 数组下标运算符，用于数组元素的赋值和取值int&amp; Array::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数重载 \"=\" 运算符，用于数组之间的赋值Array&amp; Array::operator=(const Array&amp; array) { if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; } return *this;}// 使用类成员函数重载 \"==\" 运算符，判断两个数组是否相同bool Array::operator==(const Array&amp; array) { if (this-&gt;m_length != array.m_length) { return false; } for (int i = 0; i &lt; this-&gt;m_length; i++) { if (this-&gt;m_space[i] != array.m_space[i]) { return false; } } return true;}// 使用类成员函数重载 \"!=\" 运算符，判断两个数组是否不相同bool Array::operator!=(const Array&amp; array) { return !(*this == array);}int Array::length() { return this-&gt;m_length;} main.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include \"Array.h\"using namespace std;int main() { // 自动调用构造函数 Array array1(5); for (int i = 0; i &lt; array1.length(); i++) { array1[i] = i; } for (int i = 0; i &lt; array1.length(); i++) { cout &lt;&lt; \"array1[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; array1[i] &lt;&lt; endl; } // 自动调用拷贝构造函数（属于深拷贝） Array array2 = array1; for (int i = 0; i &lt; array2.length(); i++) { cout &lt;&lt; \"array2[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; array2[i] &lt;&lt; endl; } // 自动调用拷贝构造函数（属于深拷贝） Array array3 = array1; // 不会自动调用拷贝构造函数（属于浅拷贝） // 默认情况下，若这里不对 \"=\" 运算符进行重载，最终程序会异常终止运行（由于同一块内存空间被释放两次导致） array3 = array2; for (int i = 0; i &lt; array3.length(); i++) { cout &lt;&lt; \"array3[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; array3[i] &lt;&lt; endl; } // 判断两个数组是否相同 bool result1 = array1 == array2; string strResult1 = result1 ? \"=\" : \"!=\"; cout &lt;&lt; \"array1 \" &lt;&lt; strResult1 &lt;&lt; \" array2 \" &lt;&lt; endl; // 判断两个数组是否不相同 bool result2 = array1 != array2; string strResult2 = result2 ? \"!=\" : \"=\"; cout &lt;&lt; \"array1 \" &lt;&lt; strResult2 &lt;&lt; \" array2 \" &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1234567891011121314151617181920212223有参构造函数被调用array1[0] = 0array1[1] = 1array1[2] = 2array1[3] = 3array1[4] = 4拷贝构造函数被调用array2[0] = 0array2[1] = 1array2[2] = 2array2[3] = 3array2[4] = 4拷贝构造函数被调用array3[0] = 0array3[1] = 1array3[2] = 2array3[3] = 3array3[4] = 4array1 = array2array1 = array2析构函数被调用析构函数被调用析构函数被调用 重载自定义字符串类的各种运算符在本案例中，自定义了字符串类 MyString，并使用类成员函数和友元函数分别对 MyString 类的 []、=、==、!=、&gt;、&lt;、&gt;&gt;、&lt;&lt; 运算符进行重载。 ★点击显示完整的案例代码★ MyString.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#pragma once#include &lt;iostream&gt;#include \"string.h\"using namespace std;class MyString {public: MyString(); MyString(int len); MyString(const char* p); MyString(const MyString&amp; str);public: ~MyString();public: // 使用类成员函数重载 \"[]\" 运算符 char&amp; operator[](int index); // 使用类成员函数重载 \"=\" 运算符 MyString&amp; operator=(const char* p); MyString&amp; operator=(const MyString&amp; str); // 使用类成员函数重载 \"==\" 运算符 bool operator==(const char* p) const; bool operator==(const MyString str) const; // 使用类成员函数重载 \"!=\" 运算符 bool operator!=(const char* p) const; bool operator!=(const MyString str) const; // 使用类成员函数重载 \"&gt;\" 运算符 bool operator&gt;(const char* p) const; bool operator&gt;(const MyString str) const; // 使用类成员函数重载 \"&lt;\" 运算符 bool operator&lt;(const char* p) const; bool operator&lt;(const MyString str) const; // 使用友元函数重载 \"&lt;&lt;\" 运算符 friend ostream&amp; operator&lt;&lt;(ostream&amp; out, MyString&amp; str); // 使用友元函数重载 \"&gt;&gt;\" 运算符 friend iostream&amp; operator&gt;&gt;(iostream&amp; in, MyString&amp; str);public: int length(); char* c_str();private: int m_length; char* m_space;}; MyString.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166#include \"MyString.h\"// 无参构造函数MyString::MyString() { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, \"\");}// 有参构造函数MyString::MyString(int len) { if (len &lt; 0) { len = 0; } // 初始化为空字符串 this-&gt;m_length = len; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, \"\");}// 有参构造函数MyString::MyString(const char* p) { if (p == NULL) { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, \"\"); } else { this-&gt;m_length = strlen(p); this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, p); }}// 拷贝构造函数MyString::MyString(const MyString&amp; str) { // 深拷贝，重新分配内存空间 this-&gt;m_length = str.m_length; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, str.m_space);}// 析构函数MyString::~MyString() { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}// 使用类成员函数重载 \"[]\" 运算符char&amp; MyString::operator[](int index) { return this-&gt;m_space[index];}// 使用类成员函数重载 \"=\" 运算符MyString&amp; MyString::operator=(const char* p) { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，重新分配内存空间 if (p == NULL) { // 初始化为空字符串 this-&gt;m_length = 0; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, \"\"); } else { this-&gt;m_length = strlen(p); this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, p); } return *this;}// 使用类成员函数重载 \"=\" 运算符MyString&amp; MyString::operator=(const MyString&amp; str) { // 释放内存空间 if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; } // 深拷贝，重新分配内存空间 this-&gt;m_length = str.m_length; this-&gt;m_space = new char[this-&gt;m_length + 1]; strcpy(this-&gt;m_space, str.m_space); return *this;}// 使用类成员函数重载 \"==\" 运算符bool MyString::operator==(const char* p) const { if (p == NULL) { if (this-&gt;m_length == 0) { return true; } return false; } if (this-&gt;m_length != strlen(p)) { return false; } return !strcmp(this-&gt;m_space, p);}bool MyString::operator==(const MyString str) const { if (this-&gt;m_length != str.m_length) { return false; } return !strcmp(this-&gt;m_space, str.m_space);}// 使用类成员函数重载 \"!=\" 运算符bool MyString::operator!=(const char* p) const { return !(*this == p);}bool MyString::operator!=(const MyString str) const { return !(*this == str);}// 使用类成员函数重载 \"&gt;\" 运算符bool MyString::operator&gt;(const char* p) const { return strcmp(p, this-&gt;m_space) &lt; 0;}bool MyString::operator&gt;(const MyString str) const { return strcmp(str.m_space, this-&gt;m_space) &lt; 0;}// 使用类成员函数重载 \"&lt;\" 运算符bool MyString::operator&lt;(const char* p) const { return strcmp(this-&gt;m_space, p) &lt; 0;}bool MyString::operator&lt;(const MyString str) const { return strcmp(this-&gt;m_space, str.m_space) &lt; 0;}// 使用友元函数重载 \"&lt;&lt;\" 运算符ostream&amp; operator&lt;&lt;(ostream&amp; out, MyString&amp; str) { out &lt;&lt; str.m_space; return out;}// 使用友元函数重载 \"&gt;&gt;\" 运算符iostream&amp; operator&gt;&gt;(iostream&amp; in, MyString&amp; str){ in &gt;&gt; str.m_space; return in;}int MyString::length(){ return this-&gt;m_length;}char* MyString::c_str() { return this-&gt;m_space;} main.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include \"MyString.h\"int main() { // 自动调用有参构造函数 MyString str1(\"Tom\"); MyString str2(NULL); MyString str3(\"Peter\"); // 自动调用拷贝构造函数 MyString str4 = str1; // 重载 \"&lt;&lt;\" 运算符 cout &lt;&lt; \"str2 = \" &lt;&lt; str2 &lt;&lt; endl; cout &lt;&lt; \"str4 = \" &lt;&lt; str4 &lt;&lt; endl; cout &lt;&lt; endl; // 不会自动调用拷贝构造函数（属于浅拷贝） // 重载 \"=\" 运算符，实现深拷贝 str4 = str3; cout &lt;&lt; \"str4 = \" &lt;&lt; str4 &lt;&lt; endl; str4 = \"Jim\"; cout &lt;&lt; \"str4 = \" &lt;&lt; str4 &lt;&lt; endl; str4 = NULL; cout &lt;&lt; \"str4 = \" &lt;&lt; str4 &lt;&lt; endl; cout &lt;&lt; endl; // 重载 \"[]\" 运算符 MyString str5(\"David\"); str5[0] = 'F'; cout &lt;&lt; \"str5[0] = \" &lt;&lt; str5[0] &lt;&lt; endl; cout &lt;&lt; \"str5 = \" &lt;&lt; str5 &lt;&lt; endl; cout &lt;&lt; endl; // 重载 \"==\" 运算符 MyString str6(\"Aaron\"); MyString str7 = str6; cout &lt;&lt; str6 &lt;&lt; (str6 == str7 ? \" = \" : \" != \") &lt;&lt; str7 &lt;&lt; endl; // 重载 \"!=\" 运算符 cout &lt;&lt; str6 &lt;&lt; (str6 != NULL ? \" != \" : \" = \") &lt;&lt; \" NULL\" &lt;&lt; endl; cout &lt;&lt; endl; // 重载 \"&lt;\" 运算符 MyString str8(\"AAAA\"); MyString str9(\"BBBB\"); cout &lt;&lt; str8 &lt;&lt; (str8 &lt; str9 ? \" &lt; \" : \" &gt; \") &lt;&lt; str9 &lt;&lt; endl; cout &lt;&lt; str8 &lt;&lt; (str8 &lt; \"CCCC\" ? \" &lt; \" : \" &gt; \") &lt;&lt; \"CCCC\" &lt;&lt; endl; // 重载 \"&gt;\" 运算符 cout &lt;&lt; str9 &lt;&lt; (str9 &gt; str8 ? \" &gt; \" : \" &lt; \") &lt;&lt; str8 &lt;&lt; endl; cout &lt;&lt; str9 &lt;&lt; (str9 &gt; \"DDDD\" ? \" &gt; \" : \" &lt; \") &lt;&lt; \"DDDD\" &lt;&lt; endl; cout &lt;&lt; endl; // 重载 \"&gt;&gt;\" 运算符 MyString str11(5); cout &lt;&lt; \"请输入长度为 5 的字符串：\" &lt;&lt; endl; cin &gt;&gt; str11.c_str(); cout &lt;&lt; \"str11 = \" &lt;&lt; str11 &lt;&lt; endl; // MyString str4 = NULL; 此写法，会自动调用有参构造函数 `MyString(const char* p);` // MyString str1(\"AB\"); // MyString str2 = str1; // str2 = NULL: 此写法，会自动调用 \"=\" 运算符重载的函数 `bool operator==(const char* p) const;` return 0;} 程序运行的输出结果如下： 123456789101112131415161718192021str2 =str4 = Tomstr4 = Peterstr4 = Jimstr4 =str5[0] = Fstr5 = FavidAaron = AaronAaron != NULLAAAA &lt; BBBBAAAA &lt; CCCCBBBB &gt; AAAABBBB &lt; DDDD请输入长度为 5 的字符串：abcdestr11 = abcde C++ 运算符和结合性的附录 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"CMake 入门教程之一 Linux 安装 CMake","url":"/posts/65d4f633.html","text":"Linux 安装 CMake3通过软件仓库安装 OpenSSL提示 在 Linux 系统上，安装 CMake3 的时候，一般需要提前安装 OpenSSL，尤其是使用源码编译的方式安装 CMake3 在 Linux 系统上，OpenSSL 通过源码编译安装的教程可以看这里 CentOS/Fedora 1# yum install -y openssl openssl-devel Debian/Ubuntu 1# apt-get -y install zlib1g zlib1g-dev libssl-dev 通过软件仓库安装 CMake3 CentOS/Fedora 12345# 添加EPEL源# yum install epel-release# 安装Cmake3# yum install -y cmake3 本地手动编译安装 CMake3提示 各版本的 CMake3 可以从 GitHub 仓库下载得到 CMake3 使用源码编译安装的方式，适用于绝大多数 Linux 发行版，例如：Debian/Ubuntu。 1234567891011121314151617181920212223242526# 下载文件# wget https://github.com/Kitware/CMake/releases/download/v3.21.0-rc1/cmake-3.21.0-rc1.tar.gz# 解压文件# tar -zxvf cmake-3.21.0-rc1.tar.gz# 进入解压目录# cd cmake-3.21.0-rc1# 构建# ./bootstrap# 编译# make -j4# 安装# make install# 创建软链接# ln -sf /usr/local/bin/cmake /usr/local/bin/cmake3# 查看版本号# cmake3 --version# 或者# cmake --version CMake 命令行编译代码1234567891011121314151617# 进入项目根目录# cd my_project# 创建构建目录# mkdir build# 进入构建目录# cd build# 生成makefile# cmake3 ..# 编译生成可执行文件# make# 运行可执行程序# ./my_project var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ c语言 linux系统编程"},{"title":"解决 Windows 系统使用 NPM 时遇到的各种问题","url":"/posts/b53b9a77.html","text":"pngquant-bin 模块安装失败 错误信息： 1234567891011npm ERR! path E:\\Workspaces_NodeJs\\hexo\\node_modules\\pngquant-binnpm ERR! command failednpm ERR! command C:\\WINDOWS\\system32\\cmd.exe /d /s /c node lib/install.jsnpm ERR! ‼ getaddrinfo ENOENT raw.githubusercontent.comnpm ERR! ‼ pngquant pre-build test failednpm ERR! i compiling from sourcenpm ERR! × ErroE: pngquant failed to build, make sure that libpng-dev is installednpm ERR! at E:\\Workspaces_NodeJs\\hexo\\node_modules\\bin-build\\node_modules\\execa\\index.js:231:11npm ERR! at runMicrotasks (&lt;anonymous&gt;)npm ERR! at processTicksAndRejections (node:internal/process/task_queues:96:5)npm ERR! at async Promise.all (index 0) 解决方法一：使用 系统管理员身份，在 Windows 系统上执行 npm install -g windows-build-tools 命令，安装系统缺失的编译工具，然后执行 npm install 命令安装需要的 NPM 模块 解决方法二（推荐）：使用 CNPM 替代 NPM，然后执行 cnpm install 命令安装需要的 NPM 模块 12# 安装CNPMnpm install -g cnpm --registry=https://registry.npmmirror.com 解决方法三（推荐）：在 Windows 系统上挂载 VPN，然后执行 npm install 命令安装需要的 NPM 模块，这可以从根本上解决国内访问 raw.githubusercontent.com 域名时被墙的问题 解决方法四：更改 Host 文件 C:\\Windows\\System32\\drivers\\etc\\hosts，在文件末尾添加以下内容，解决国内访问 raw.githubusercontent.com 域名时被墙的问题，然后执行 npm install 命令安装需要的 NPM 模块 1199.232.28.133 raw.githubusercontent.com var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"windows系统"},{"title":"Windows 10 系统备份与还原常见错误解决","url":"/posts/490dddd2.html","text":"前言Windows 10 中的备份和还原（Windows 7）作为 Microsoft Windows 组件，继承了 Windows 7 的功能，该功能使您可以备份与恢复文件以及创建系统映像。如果在 Windows 的早期版本中使用 备份 和 还原 来备份文件或创建系统映像，则仍可以在 Windows 10 中恢复这些备份。此外，Windows 10 还包括另一个备份与恢复工具 - 文件历史记录，它只备份文档，音乐，图片，视频和桌面文件夹中文件的版本，以及 PC 上可用的 OneDrive 文件。如果要使用 文件历史记录 备份位于其他位置的其他文件，可以将其移至这些文件夹之一，然后再进行备份。保存备份的两个目标地址支持外部硬盘驱动器（例如 USB 闪存驱动器）和网络位置。 系统备份常见错误错误一错误提示信息无法创建卷影副本，请检查 vss 和 spp 应用程序事件日志更多信息（错误代码：0x81000019） 或者 由于内部错误，备份应用程序无法启动：卷影复制服务组件遇到意外错误（错误代码：0x80042302） 错误解决方案一这个错误可能是由于三方杀毒软件冲突或者一些 Windows 备份相关的服务被禁用导致的，具体解决步骤如下： a) 暂时关闭或卸载第三方杀毒软件 b) 使用快捷键 windows + r，输入 services.msc，打开服务控制台，并检查下列服务是否正常运行。如果服务被禁用，请将其启用，并将启动类型设置为 自动。 12345Volume Shadow Copy (VSS)Remote Procedure Call (RPCSS)COM+ Event System (eventsystem)System Event Notification Service (sens)Microsoft Software Shadow Copy Provider (SWPRV) c) 重启 Windows 10 系统，然后再次尝试执行系统备份 错误解决方案二 a) 使用快捷键 windows + r，输入 msconfig b) 点击 服务 标签卡，勾选 隐藏所有的 Microsoft 服务 ，然后点击全部禁用并应用 c) 点击 启动 标签卡，点击 打开任务管理器 d) 禁用全部开机启动项 e) 重启 Windows 10 系统，然后再次尝试执行系统备份 f) 系统成功备份后，重新启用在上面的步骤中禁用的服务和开机启动项，最后再次重启系统 错误二错误提示信息Windows 备份在源卷上创建共享保护点失败（错误代码：0×8078006B） 错误解决方案这个错误一般是由程序冲突引起的，目前排查出是 腾讯电脑管家 的设置问题导致，具体解决步骤如下： a) 打开 腾讯电脑管家 的 设置中心 b) 找到 实时防护 菜单下面的 其他安全提示，将 开启卷影备份 的勾选去掉 c) 如果上述设置仍然没办法解决问题，建议暂时关闭或卸载 腾讯电脑管家 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"windows系统"},{"title":"Visual Studio 使用命令行编译 C/C++ 程序","url":"/posts/ab3ae9a.html","text":"VS 使用命令行编译单个 C/C++ 源文件在 Windows 系统的开始菜单栏里，找到 Developer Command Prompt for VS xxxx 应用程序，双击运行后，在 Command 窗口内执行以下命令来编单个 C/C++ 源文件。值得一提的是，这里需要将以下命令中的 HelloWorld 字符串替换为本地真正的 C/C++ 源文件的文件名。 12345678910111213141516171819# 查看文件列表&gt; dir2021/10/30 16:05 &lt;DIR&gt; .2021/10/30 16:05 &lt;DIR&gt; ..2021/10/30 22:15 601 HelloWorld.cpp# 编译C/C++源文件（cl后面字符的是小写L不是数字1）&gt; cl HelloWorld.cpp /EHsc# 查看文件列表，发现成功编译后会多了两个文件&gt; dir2021/10/30 16:53 &lt;DIR&gt; .2021/10/30 16:53 &lt;DIR&gt; ..2021/10/30 22:15 601 HelloWorld.cpp2021/10/30 16:53 101,888 HelloWorld.exe2021/10/30 16:53 1,976 HelloWorld.obj# 运行编译后的C/C++程序&gt; HelloWorld 或者 HelloWorld.exe VS 使用命令行编译多个 C/C++ 源文件假设项目里有如下的三个 C/C++ 源文件，分别是 Array.h、Array.cpp、main.cpp，那么编译这几个文件时就可以使用命令：cl main.cpp Array.cpp /EHsc。值得一提的是，编译命令里不需要指定以 .h 作为后缀的文件，只需要指定所有以 .c 或者 .cpp 作为后缀的文件即可。 Array.h 1234567891011121314151617181920212223#pragma once#include &lt;iostream&gt;using namespace std;class Array {public: Array(int length); Array(const Array&amp; array); ~Array();public: void setData(int index, int value); int getData(int index); int length();private: int m_length; int* m_space;}; Array.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041#include \"Array.h\"Array::Array(int length) { cout &lt;&lt; \"有参构造函数被调用\" &lt;&lt; endl; if (length &lt; 0) { length = 0; } this-&gt;m_length = length; this-&gt;m_space = new int[length];}Array::Array(const Array&amp; array) { cout &lt;&lt; \"拷贝构造函数被调用\" &lt;&lt; endl; // 深拷贝，单独分配内存空间 this-&gt;m_length = array.m_length; this-&gt;m_space = new int[array.m_length]; for (int i = 0; i &lt; array.m_length; i++) { this-&gt;m_space[i] = array.m_space[i]; }}Array::~Array() { cout &lt;&lt; \"析构函数被调用\" &lt;&lt; endl; if (this-&gt;m_space != NULL) { delete[] this-&gt;m_space; this-&gt;m_space = NULL; this-&gt;m_length = 0; }}void Array::setData(int index, int value) { this-&gt;m_space[index] = value;}int Array::getData(int index) { return this-&gt;m_space[index];}int Array::length() { return this-&gt;m_length;} main.cpp 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include \"Array.h\"using namespace std;int main() { // 自动调用构造函数初始化数组 Array array1(5); // 数组赋值 for (int i = 0; i &lt; array1.length(); i++) { array1.setData(i, i); } // 打印数组 for (int i = 0; i &lt; array1.length(); i++) { cout &lt;&lt; \"array1[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; array1.getData(i) &lt;&lt; endl; } // 自动调用拷贝构造函数初始化数组（属于深拷贝） Array array2 = array1; // 打印数组 for (int i = 0; i &lt; array2.length(); i++) { cout &lt;&lt; \"array2[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; array2.getData(i) &lt;&lt; endl; } return 0;} 执行命令编译 C/C++ 程序后，控制台输出的日志信息如下： 1234567891011121314&gt; cl main.cpp Array.cpp /EHsc用于 x86 的 Microsoft (R) C/C++ 优化编译器 19.29.30136 版版权所有(C) Microsoft Corporation。保留所有权利。main.cppArray.cpp正在生成代码...Microsoft (R) Incremental Linker Version 14.29.30136.0Copyright (C) Microsoft Corporation. All rights reserved./out:main.exemain.objArray.obj 运行编译后的 C/C++ 程序： 12345678910111213141516&gt; main有参构造函数被调用array1[0] = 0array1[1] = 1array1[2] = 2array1[3] = 3array1[4] = 4拷贝构造函数被调用array2[0] = 0array2[1] = 1array2[2] = 2array2[3] = 3array2[4] = 4析构函数被调用析构函数被调用 参考博客 模仿 Visual Studio - 命令行编译 C/C++ 程序 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ 开发工具"},{"title":"C++ 入门基础之五","url":"/posts/a35089f6.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 浅拷贝与深拷贝 C++ 提供的默认拷贝构造函数，可以完成对象的数据成员值简单的复制（浅拷贝） 对象的数据资源是由指针指向的堆，C++ 提供的默认拷贝构造函数仅作指针值复制（浅拷贝） 浅拷贝问题剖析 问题抛出思考以下的代码为什么会异常终止运行。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include \"string.h\"using namespace std;class Name {private: char *p; int len;public: Name(const char *name) { cout &lt;&lt; \"有参构造函数被调用了\" &lt;&lt; endl; int length = strlen(name); p = (char *) malloc(length + 1); strcpy(p, name); len = length; } ~Name() { cout &lt;&lt; \"析构函数被调用了\" &lt;&lt; endl; if (p != NULL) { free(p); p = NULL; len = 0; } } char *getP() const { return p; } int getLen() const { return len; }};int main() { Name obj1(\"Peter\"); Name obj2 = obj1; // 自动调用C++提供的默认拷贝构造函数，属于浅拷贝 cout &lt;&lt; \"obj1.name: \" &lt;&lt; obj1.getP() &lt;&lt; \", obj1.len: \" &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; \"obj2.name: \" &lt;&lt; obj2.getP() &lt;&lt; \", obj2.len: \" &lt;&lt; obj2.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 1234567有参构造函数被调用了obj1.name: Peter, obj1.len: 5obj2.name: Peter, obj2.len: 5析构函数被调用了析构函数被调用了Process finished with exit code 134 (interrupted by signal 6: SIGABRT) 问题分析由于在上述的代码中，没有自定义拷贝构造函数，使用的是 C++ 编译器提供的默认拷贝构造函数，因此程序异常终止运行。造成程序异常终止运行的根本原因是，C++ 提供的默认拷贝构造函数属于浅拷贝，当程序运行结束之前，在第二次调用上面的析构函数时会出现错误（同一块内存空间被释放了两次），底层的分析图解可以看这里。 问题解决显式编写自定义的拷贝构造函数，通过实现深拷贝（申请新的内存空间）来解决上述的问题，底层的分析图解可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include \"string.h\"using namespace std;class Name {private: char *p; int len;public: Name(const char *name) { cout &lt;&lt; \"有参构造函数被调用了\" &lt;&lt; endl; int length = strlen(name); p = (char *) malloc(length + 1); strcpy(p, name); len = length; } // 深拷贝的实现 Name(const Name &amp;name) { cout &lt;&lt; \"拷贝构造函数被调用了\" &lt;&lt; endl; int length = name.getLen(); p = (char *) malloc(length + 1); strcpy(p, name.getP()); len = length; } ~Name() { cout &lt;&lt; \"析构函数被调用了\" &lt;&lt; endl; if (p != NULL) { free(p); p = NULL; len = 0; } } char *getP() const { return p; } int getLen() const { return len; }};int main() { Name obj1(\"Peter\"); Name obj3 = obj1; // 自动调用自定义的拷贝构造函数（深拷贝） cout &lt;&lt; \"obj1.name: \" &lt;&lt; obj1.getP() &lt;&lt; \", obj1.len: \" &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; \"obj3.name: \" &lt;&lt; obj3.getP() &lt;&lt; \", obj3.len: \" &lt;&lt; obj3.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123456有参构造函数被调用了拷贝构造函数被调用了obj1.name: Peter, obj1.len: 5obj3.name: Peter, obj3.len: 5析构函数被调用了析构函数被调用了 特别注意： 在以下的代码中，obj3 = obj1; 依旧属于浅拷贝（这里不会自动调用拷贝构造函数），最终程序也会异常终止运行。若希望解决该问题，需要重载 C++ 的 = 操作符，这里暂时不展开讨论。 12345678int main() { Name obj1(\"Peter\"); Name obj3(\"Tom\"); obj3 = obj1; // 浅拷贝，不会自动调用拷贝构造函数 cout &lt;&lt; \"obj1.name: \" &lt;&lt; obj1.getP() &lt;&lt; \", obj1.len: \" &lt;&lt; obj1.getLen() &lt;&lt; endl; cout &lt;&lt; \"obj3.name: \" &lt;&lt; obj3.getP() &lt;&lt; \", obj3.len: \" &lt;&lt; obj3.getLen() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12345678有参构造函数被调用了有参构造函数被调用了obj1.name: Peter, obj1.len: 5obj3.name: Peter, obj3.len: 5析构函数被调用了析构函数被调用了Process finished with exit code 134 (interrupted by signal 6: SIGABRT) 对象的动态建立和释放使用类名定义的对象都是静态的（如 Teacher t(30);），在程序运行过程中，对象所占的内存空间是不能随时释放的，只有在程序运行结束之后才会被释放。但有时候用户希望在需要用到对象时才建立对象，在不需要用该对象时就撤销它，释放它所占的内存空间以供别的数据使用，这样可提高内存空间的利用率。在 C++ 中，可以用 new 运算符动态建立对象，用 delete 运算符动态撤销对象。 new 和 delete 介绍在软件开发过程中，常常需要动态地分配和撤销内存空间，例如对动态链表中结点的插入与删除。在 C 语言中是利用库函数 malloc() 和 free() 来分配和撤销内存空间的。C++ 提供了较简便而功能较强的运算符 new 和 delete 来取代 malloc() 和 free() 函数。值得注意的是，new 和 delete 是运算符，不是函数，因此执行效率更高。虽然为了与 C 语言兼容，C++ 仍保留 malloc() 和 free() 函数，但建议用户不要使用 malloc() 和 free() 函数，而是使用 new 和 delete 运算符。 new 和 delete 的基础语法 new 运算符的简单使用例子如下： new int;：开辟一个存放整数的内存空间，返回一个指向该内存空间的地址（即指针） new int(100);：开辟一个存放整数的空间，并指定该整数的初值为 100，返回一个指向该内存空间的地址（即指针） new char[10];：开辟一个存放字符数组（包括 10 个元素）的空间，返回首元素的地址（即指针） new int[5][4];：开辟一个存放二维整型数组（大小为 5*4）的空间，返回首元素的地址（即指针） float *p = new float (3.14159);：开辟一个存放单精度数的空间，并指定该实数的初值为 3.14159，将返回的该空间的地址赋给指针变量 值得注意的是，用 new 分配数组内存空间时不能指定初值，如果由于内存不足等原因而导致无法正常分配内存空间，那么 new 会返回一个空指针 NULL，用户可以根据该指针的值判断内存空间是否分配成功。 new 和 delete 的使用案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;iostream&gt;using namespace std;class Teacher {private: int _age;public: Teacher(int age) { this-&gt;_age = age; cout &lt;&lt; \"构造函数被调用\" &lt;&lt; endl; } ~Teacher() { cout &lt;&lt; \"析构函数被调用\" &lt;&lt; endl; } void setAget(int age) { this-&gt;_age = age; } int getAge() { return this-&gt;_age; }};// C语言分配基础类型void functionA() { int *p = (int *) malloc(sizeof(int)); *p = 3; cout &lt;&lt; \"functionA -&gt; p = \" &lt;&lt; *p &lt;&lt; endl; free(p);}// C++分配基础类型void functionB() { int *a = new int; *a = 3; cout &lt;&lt; \"functionB -&gt; a = \" &lt;&lt; *a &lt;&lt; endl; delete a; int *b = new int(30); cout &lt;&lt; \"functionB -&gt; b = \" &lt;&lt; *b &lt;&lt; endl; delete b;}// C语言分配数组类型void functionC() { char *p = (char *) malloc(sizeof(char) * 3); p[0] = 'a'; p[1] = 'b'; p[2] = 'c'; cout &lt;&lt; \"functionC -&gt; p = \" &lt;&lt; p[0] &lt;&lt; p[1] &lt;&lt; p[2] &lt;&lt; endl; free(p);}// C++分配数组类型void functionD() { char *p = new char[3]; p[0] = 'e'; p[1] = 'f'; p[2] = 'g'; cout &lt;&lt; \"functionD -&gt; p = \" &lt;&lt; p[0] &lt;&lt; p[1] &lt;&lt; p[2] &lt;&lt; endl; delete []p;}// C语言分配对象void functionE() { // 这里不会自动调用类的构造函数和析构函数 Teacher *p = (Teacher *) malloc(sizeof(Teacher)); p-&gt;setAget(33); cout &lt;&lt; \"functionE -&gt; age = \" &lt;&lt; p-&gt;getAge() &lt;&lt; endl; free(p);}// C++分配对象void functionF() { // new和delete会分别自动调用类的构造函数和析构函数 Teacher *p = new Teacher(35); cout &lt;&lt; \"functionF -&gt; age = \" &lt;&lt; p-&gt;getAge() &lt;&lt; endl; delete p;}int main() { functionA(); functionB(); functionC(); functionD(); functionE(); functionF(); return 0;} 程序运行输出的结果如下： 123456789functionA -&gt; p = 3functionB -&gt; a = 3functionB -&gt; b = 30functionC -&gt; p = abcfunctionD -&gt; p = efgfunctionE -&gt; age = 33构造函数被调用functionF -&gt; age = 35析构函数被调用 上面的 Teacher *p = new Teacher(35); 这种写法，是将两个语句（定义指针变量和使用 new 建立新对象）合并为一个语句，并指定初值，在调用对象时，既可以通过对象名，也可以通过指针。在执行 new 运算符时，如果内存空间不足，无法开辟所需的内存空间，目前大多数 C++ 编译器都会返回一个 0 指针值。只要检测返回值是否为 0，就可判断内存空间是否分配成功。ANSI C++ 标准提出，在执行 new 出现故障时，就抛出一个异常，用户可根据异常进行相关处理，但 C++ 标准仍然允许在出现 new 故障时返回 0 指针值。值得注意的是，不同的编译器对 new 故障的处理方法是不同的。当不再需要使用由 new 建立的对象时，可以用 delete 运算符予以释放，此后程序不能再使用该对象。如果用一个指针变量先后指向了不同的动态对象，应注意指针变量的当前指向，以避免释放错了对象。在执行 delete 运算符时，在释放内存空间之前，会自动调用类的析构函数，完成有关善后清理工作。 静态成员变量静态成员变量的概念 静态成员局部于类，它不是对象成员 在类外访问静态成员变量时，可以使用 类名 :: 作为限定词，或通过对象访问 关键字 static 可以用于声明一个类的成员，静态成员提供了一个同类对象的共享机制 将一个类的成员声明为 static 时，这个类无论有多少个对象被创建，这些对象都共享这个 static 成员 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;class Counter {private: // 声明静态成员变量 static int num;public : // 成员函数访问静态成员变量 void setNum(int i) { num = i; } void showNum() { cout &lt;&lt; num &lt;&lt; endl; }};// 定义静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存int Counter::num = 0;int main() { Counter a, b; a.showNum(); b.showNum(); a.setNum(10); a.showNum(); b.showNum(); return 0;} 程序运行输出的结果如下： 1234001010 静态成员变量的使用123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;class Counter {public: int mem; // 公有成员变量 static int smem; // 公有静态成员变量public : Counter(int num) { mem = num; }};// 定义静态成员变量，这里不是简单的变量赋值，更重要的是告诉C++编译器，给静态成员变量分配内存int Counter::smem = 0;int main() { Counter c(5); for (int i = 0; i &lt; 5; i++) { // 访问静态成员变量的方法1（通过类名直接访问） Counter::smem += i; cout &lt;&lt; \"Counter::smem = \"&lt;&lt; Counter::smem &lt;&lt; endl; } // 访问静态成员变量的方法2（通过对象访问） cout &lt;&lt; \"c.smem = \" &lt;&lt; c.smem &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 123456Counter::smem = 0Counter::smem = 1Counter::smem = 3Counter::smem = 6Counter::smem = 10c.smem = 10 静态成员函数静态成员函数的概念 静态成员函数、静态成员变量都属于类的 静态成员函数都是以关键字 static 声明 在类外调用静态成员函数时，可以使用 类名 :: 作为限定词，或通过对象访问 静态成员函数提供不依赖于类数据结构的共同操作，它没有 this 指针，而普通成员函数包含一个指向具体对象的 this 指针 静态成员函数的使用值得一提的是，在静态成员函数中，不能访问普通成员变量和调用普通成员函数。这是因为静态成员函数属于整个类的，它没办法区分普通成员变量和普通成员函数是属于哪个具体的对象；同时在静态成员函数内，不能使用 this 指针。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Counter {private: int num;public: // 声明静态成员函数 static int getNum(Counter *p); static void setNum(int i, Counter *p);};// 定义静态成员函数int Counter::getNum(Counter *p) { return p-&gt;num;}void Counter::setNum(int i, Counter *p) { p-&gt;num = i;}int main() { Counter obj; // 访问静态成员函数的方法1（通过类名直接访问） Counter::setNum(1, &amp;obj); cout &lt;&lt; \"num = \" &lt;&lt; Counter::getNum(&amp;obj) &lt;&lt; endl; // 访问静态成员函数的方法2（通过对象访问） obj.setNum(3, &amp;obj); cout &lt;&lt; \"num = \" &lt;&lt; obj.getNum(&amp;obj) &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12num = 1num = 3 C++ 面向对象模型初探对象模型概述C++ 对象模型可以概括为以下两部分： 对于各种特性支持的底层实现机制 语言中直接支持面向对象程序设计的部分，主要涉及如构造函数、析构函数、虚函数、继承（单继承、多继承、虚继承）、多态等 在 C 语言中，“数据” 和 “处理数据的操作（函数）” 是分开来声明的，也就是说，语言本身并没有支持 “数据和函数” 之间的关联性。在 C++ 中，通过抽象数据类型 ADT（Abstract Data Type），在类中定义数据和函数来实现数据和函数直接的绑定。概括来说，在 C++ 类中有两种成员数据：static、nonstatic，三种成员函数：static、nonstatic、virtual。 属性和函数的处理机制C++ 中的 Class 从面向对象理论出发，将变量（属性）和函数（方法）集中定义在一起，用于描述现实世界中的类。从计算机的角度，程序依然由数据段和代码段构成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;struct S1 { int i; int j; int k;};struct S2 { int i; int j; int k; static int m;};class C1 {public: int i; int j; int k;};class C2 {public: int i; int j; int k; static int m;public: int getK() const { return k; } void setK(int val) { k = val; }};int main() { printf(\"s1:%d \\n\", sizeof(S1)); printf(\"s2:%d \\n\", sizeof(S2)); printf(\"c1:%d \\n\", sizeof(C1)); printf(\"c2:%d \\n\", sizeof(C2)); return 0;} 程序运行输出的结果如下： 1234s1:12s2:12c1:12c2:12 通过上面的案例，可以得知 C++ 类对象中的成员变量和成员函数是分开存储的，C 语言中的内存四区模型仍然有效。C++ 中类的普通成员函数都隐式包含一个指向当前对象的 this 指针。 静态成员变量：存储于全局数据区中 普通成员变量：存储于对象中，与 struct 变量有相同的内存布局和字节对齐方式 成员函数：存储于代码段中 this 指针的使用 值得一提的是，当使用 const 修饰类成员函数时，成员函数不能修改被调用对象的值，这是因为此时 const 本质上修饰的是 this 指针，间接也说明了 const 与 static 关键字不能同时修饰类成员函数，示例代码如下： 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { // _cm = 10; 是错误写法，对象的_cm属性值不能被改变 return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); // 打印结果为8 return 0;} 全局函数与成员函数的使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &lt;iostream&gt;using namespace std;class Test{public: int a; int b;public: Test(int a = 0, int b = 0) { this-&gt;a = a; this-&gt;b = b; } ~Test() { }public: void printT() { cout &lt;&lt; \"a:\" &lt;&lt; a &lt;&lt; \" b: \" &lt;&lt; b &lt;&lt; endl; } Test testAdd(Test&amp; t2) { Test tmp(this-&gt;a + t2.a, this-&gt;b + t2.b); return tmp; } //t1.testAdd2(t2); //返回一个引用，相当于返回自身 //返回t1这个元素，this就是&amp;t1 Test&amp; testAdd2(Test&amp; t2) { this-&gt;a = this-&gt;a + t2.a; this-&gt;b = this-&gt;b + t2.b; return *this; //把 *(&amp;t1) 又回到了 t1元素 }};// 全局函数Test testAdd(Test&amp; t1, Test&amp; t2){ Test tmp; tmp.a = t1.a + t2.a; tmp.b = t1.b + t2.b; return tmp;}// 全局函数void printT(Test* pT){ cout &lt;&lt; \"a:\" &lt;&lt; pT-&gt;a &lt;&lt; \" b: \" &lt;&lt; pT-&gt;b &lt;&lt; endl;}int main(){ Test t1(1, 2); Test t2(3, 4); // 调用全局函数 Test t3; t3 = testAdd(t1, t2); printT(&amp;t3); // 调用成员函数 Test t4 = t1.testAdd(t2); // 将匿名对象直接转化成t4 t4.printT(); Test t5; t5 = t1.testAdd(t2); // 将匿名对象复制给t5 t5.printT(); t1.testAdd2(t2); // 函数内部使用了this指针 t1.printT(); return 0;} 程序运行输出的结果如下： 1234a:4 b: 6a:4 b: 6a:4 b: 6a:4 b: 6 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"Linux 解决 libc.so.6 version GLIBC_2.18 not found 的问题","url":"/posts/15a7083d.html","text":"错误日志信息 1/lib64/libc.so.6: version 'GLIBC_2.18' not found 系统环境 12CentOS Linux release 7.9.2009 (Core)Linux 3.10.0-1160.45.1.el7.x86_64 #1 SMP Wed Oct 13 17:20:51 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 查看当前 GLIBC 的版本 123456789101112131415161718192021# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17 问题分析 通过查看当前 GLIBC 的版本，可以发现目前系统中最高只支持 GLIBC_2.17，当需要安装依赖 GLIBC_2.18 的软件时，就会出现 libc.so.6: version 'GLIBC_2.18' not found 的错误信息。glibc 是 GNU 发布的 libc 库，即 C 运行库。glibc 是 Linux 系统中最底层的 API，几乎其它任何运行库都会依赖于 glibc。值得一提的是，glibc 除了封装了 Linux 操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现。对于 CentOS 这样的系统，为了追求稳定性（这个值得商榷）往往各种库版本都很低，比如 CentOS 6.5 甚至 CentOS 7.0 自带的还是 glibc 2.12, 而 Ubuntu 14.04 自带 glibc2.19。如果升级 glibc 到一个太新的版本，可能会影响 CentOS 的稳定运行，所以不建议随便升级 glibc 的版本。 解决思路 a) 手动编译安装高版本的 gcc b) 在低版本的系统编译自己的软件，前提是自己的软件确实不需要使用新版 GCC 才支持的特性 c) 利用容器技术（如 Docker），在低版本的操作系统内，轻量级的隔离出一个虚拟运行环境，适应自己的软件 编译安装 GCC glibc 的各个版本可以在这里下载。特别注意，在条件允许的情况下，强烈建议在执行下述的 make install 命令之前，全量备份整个 Linux 系统，防止因系统文件意外被破坏，导致系统在启动或运行期间出现崩溃的问题。 1234567891011121314151617181920212223# 下载glibc-2.18# curl -O http://ftp.gnu.org/gnu/glibc/glibc-2.18.tar.gz# 解压文件# tar zxf glibc-2.18.tar.gz# 进入解压目录# cd glibc-2.18# 建立输出目录，用于存放编译时所有产生的中间文件# mkdir build# 进入输出目录# cd build# 执行配置# ../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin --enable-checking=release --enable-languages=c,c++# 编译GCC，指定编译使用的线程数为8，编译耗时较长# make -j8# 安装GCC（切记谨慎执行）# make install 验证 GCC 的版本是否升级成功 如果在下面的输出结果中，出现 GLIBC_2.18，则代表 GCC 的版本升级成功。 12345678910111213141516171819202122# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17GLIBC_2.18 或者查看 ldd 的版本 12345# ldd --versionldd (GNU libc) 2.18Copyright (C) 2013 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 或者查看系统的库文件 123456789# 查看系统的libc.so库文件# ls /usr/lib64/libc-*.so -al-rwxr-xr-x. 1 root root 2156592 10月 14 02:29 /usr/lib64/libc-2.17.so-rwxr-xr-x. 1 root root 10232696 10月 24 14:52 /usr/lib64/libc-2.18.so# 查看系统的libc.so库文件# ls /usr/lib64/libc.so* -al-rw-r--r--. 1 root root 253 10月 24 14:51 /usr/lib64/libc.solrwxrwxrwx. 1 root root 12 10月 24 14:52 /usr/lib64/libc.so.6 -&gt; libc-2.18.so 解决误删 libc.so.6 库文件的问题 在上述的操作中，若误删了 libc.so.6 库文件，会导致系统大多数命令不可用（例如：ls、cp、ln）。此时千万不要随便重启系统，缺少 libc.so.6 库文件很容易导致系统无法正常启动，其次也尽量不要关闭正在运行的终端，因为很多东西还可以补救，建议参考以下步骤重新创建 libc.so.6 库文件。 123456789101112# 查看系统可用的libc库文件# ls /usr/lib64/libc-*.so -al-rwxr-xr-x. 1 root root 2156592 10月 14 02:29 /usr/lib64/libc-2.17.so# 通过系统环境变量LD_PRELOAD导入可用的libc库文件# export LD_PRELOAD=/usr/lib64/libc-2.17.so# 利用可用的libc库文件，创建新的libc.so.6库文件# ln -s -f /usr/lib64/libc-2.17.so /usr/lib64/libc.so.6# 取消设置系统环境变量LD_PRELOAD# unset LD_PRELOAD 参考博客 Linux（CentOS）GLIBC 出错的补救方式 解决 libc.so.6: version ‘GLIBC_2.18’ not found 的问题 Linux/Centos 下 /lib64/libc.so.6: version ‘GLIBC_2.14’ not found var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux"},{"title":"C++ 入门基础之四","url":"/posts/beb2ebb3.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 学习目标 C++ 面向对象的基础模型 C++ 编译器管理类和对象的机制 C++ 编译器对类对象的生命周期管理，包括对象的创建、使用、销毁等 类和对象基本概念 a) 类、对象、成员变量、成员函数 b) 面向对象三大概念：封装、继承、多态 类的封装封装（Encapsulation）： a) 封装，是面向对象程序设计最基本的特性。把数据（属性）和函数（操作）合成一个整体，对数据和函数进行访问控制，这在计算机世界中是用类与对象实现的。 b) 封装，把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。 C++ 中类的封装： 成员变量：C++ 中用于表示类属性的变量 成员函数：C++ 中用于表示类行为的函数 类成员的访问控制在 C++ 中可以给成员变量和成员函数定义访问级别： private：修饰的成员变量和成员函数，只能在类的内部被访问 public：修饰的成员变量和成员函数，可以在类的内部和类的外部被访问 protected：修饰的成员变量和成员函数，可以在派生类（继承的子类）的内部访问，不能在派生类的外部被访问 特别注意：若在类中没有声明访问控制级别的成员变量和成员函数，默认都是 private 访问级别的 基于类成员的访问控制，计算圆形面积的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {private: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; \"请输入圆形的半径：\"; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; \"圆形的面积是：\" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} struct 和 class 的区别struct 和 class 关键字的区别如下： 在用 class 定义类时，所有成员的默认属性为 private 在用 struct 定义类时，所有成员的默认属性为 public 类的声明与类的实现一起写123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {private: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; \"请输入圆形的半径：\"; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; \"圆形的面积是：\" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} 程序运行输出的结果如下： 12请输入圆形的半径：30圆形的面积是：2826 类的声明与类的实现分开写在企业开发中，由于项目结构比较庞大，一般都会将类的声明和类的实现分开写在不同的源文件中。 Teacher.h 头文件，声明了 Teacher 类的成员变量和成员函数；使用 #ifndef、#define、#endif 指令，是为了防止 Teacher.h 头文件被多次引用时 C++ 编译器编译失败，也可以直接使用 #pragma once 指令来替代。 1234567891011121314151617181920#ifndef TEACHER_H#define TEACHER_Hclass Teacher {private: char *_name; int _age;public: const char *getName() const; void setName(char *name); int getAge() const; void setAge(int age);};#endif Teacher.cpp 源文件，实现了在 Teacher.h 头文件中定义的成员函数 1234567891011121314151617181920#include &lt;iostream&gt;#include \"Teacher.h\"using namespace std;const char *Teacher::getName() const { return this-&gt;_name;}void Teacher::setName(char *name) { this-&gt;_name = name;}int Teacher::getAge() const { return this-&gt;_age;}void Teacher::setAge(int age) { this-&gt;_age = age;} Main.cpp 源文件 12345678910111213#include &lt;iostream&gt;#include \"Teacher.h\"using namespace std;int main() { char name[32] = \"Peter\"; Teacher teacher; teacher.setAge(10); teacher.setName(name); cout &lt;&lt; \"age: \" &lt;&lt; teacher.getAge() &lt;&lt; endl; cout &lt;&lt; \"name: \" &lt;&lt; teacher.getName() &lt;&lt; endl;} 程序运行的输出结果如下： 12age: 10name: Peter 对象的构造和析构析构函数析构函数的定义析构函数的定义： C++ 中的类可以定义一个特殊的成员函数来清理对象，这个特殊的成员函数叫做析构函数 析构函数的名称与类的名称是完全相同的，只是在前面加了个波浪号 ~ 作为前缀，它没有任何参数，也没有任何返回类型的声明 析构函数有助于在跳出程序（比如关闭文件、释放内存等）前释放资源 析构函数在对象销毁时会自动被调用 析构函数的调用： C++ 编译器会自动调用析构函数 析构函数的声明12345678910111213141516171819#include &lt;iostream&gt;using namespace std;class Teacher {public: // 析构函数 ~Teacher() { cout &lt;&lt; \"调用析构函数\" &lt;&lt; endl; }};int main() { Teacher teacher; return 0;} 程序运行输出的结果如下： 1调用析构函数 构造函数创建一个对象时，常常需要做某些初始化的工作，例如对数据成员赋初值。必须注意，类的数据成员是不能在声明类时初始化的。为了解决这个问题，C++ 编译器提供了构造函数（Constructor）来处理对象的初始化。构造函数是一种特殊的成员函数，与其他成员函数不同，不需要用户来调用它，而是在建立对象时自动被调用。 构造函数的定义构造函数的定义： C++ 中的类可以定义与类名相同的特殊成员函数，这种与类名相同的成员函数叫做构造函数 构造函数在定义时可以有参数 构造函数没有任何返回类型的声明 构造函数可用于为某些成员变量设置初始值 构造函数的调用： 自动调用：一般情况下 C++ 编译器会自动调用构造函数 手动调用：在一些特定的情况下，需要手工调用构造函数 构造函数的分类构造函数一般分为三类：无参数的构造函数、带参数的构造函数、拷贝构造函数（赋值构造函数）。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class Test {private: int _a; int _b;public: // 无参数的构造函数 Test() { _a = 1; _b = 2; } // 带参数的构造函数 Test(int a, int b) { _a = a; _b = b; } // 拷贝构造函数（赋值构造函数） Test(const Test &amp;obj) { _a = obj._a; _b = obj._b; }}; 默认的构造函数C++ 中有两个特殊的构造函数： 默认无参构造函数：当类中没有定义构造函数时，编译器默认会提供一个无参构造函数，并且其函数体为空 默认拷贝构造函数：当类中没有定义拷贝构造函数时，编译器默认会提供一个拷贝构造函数，用于简单地进行类成员变量的值复制 构造函数的调用方式构造函数的调用方式分为以下三种： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;class Test {private: int _a; int _b;public: Test() { _a = 1; _b = 1; } Test(int a) { _a = a; _b = 3; } Test(int a, int b) { _a = a; _b = b; }public: int getA() const { return _a; } int getB() const { return _b; }};int main() { // 第一种：C++编译器调用有参构造函数(等号法) Test t1 = (1, 2, 3, 4, 5); printf(\"a = %d, b = %d\\n\", t1.getA(), t1.getB()); // 第二种：C++编译器调用有参构造函数(括号法) Test t2(10, 20); printf(\"a = %d, b = %d\\n\", t2.getA(), t2.getB()); // C++编译器调用无参构造函数 Test t0; printf(\"a = %d, b = %d\\n\", t0.getA(), t0.getB()); // 第三种：手动调用构造函数生成一个对象(直接调用构造函数法) Test t3 = Test(100, 200); printf(\"a = %d, b = %d\\n\", t3.getA(), t3.getB()); return 0;} 程序运行输出的结果如下： 1234a = 5, b = 3a = 10, b = 20a = 1, b = 1a = 100, b = 200 拷贝构造函数的调用场景第一种调用场景123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;class Test {private : int _a;public: Test() { cout &lt;&lt; \"无参构造函数自动被调用了\" &lt;&lt; endl; } Test(int a) { _a = a; cout &lt;&lt; \"有参构造函数被调用了\" &lt;&lt; endl; } Test(const Test &amp;obj) { _a = obj._a + 10; cout &lt;&lt; \"拷贝构造函数被调用了\" &lt;&lt; endl; } ~Test() { cout &lt;&lt; \"析构函数被调用了\" &lt;&lt; endl; } int getA() { return _a; }};void functionA() { Test t1(1); Test t0(2); t0 = t1; // 普通的赋值操作，拷贝构造函数不会被调用 Test t2 = t1; // 类的初始化操作(等号法)，拷贝构造函数会被调用 cout &lt;&lt; \"a = \" &lt;&lt; t2.getA() &lt;&lt; endl;}int main() { functionA(); return 0;} 程序运行输出的结果如下： 1234567有参构造函数被调用了有参构造函数被调用了拷贝构造函数被调用了a = 11析构函数被调用了析构函数被调用了析构函数被调用了 第二种调用场景12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;using namespace std;class Test {private : int _a;public: Test() { cout &lt;&lt; \"无参构造函数自动被调用了\" &lt;&lt; endl; } Test(int a) { _a = a; cout &lt;&lt; \"有参构造函数被调用了\" &lt;&lt; endl; } Test(const Test &amp;obj) { _a = obj._a + 10; cout &lt;&lt; \"拷贝构造函数被调用了\" &lt;&lt; endl; } ~Test() { cout &lt;&lt; \"析构函数被调用了\" &lt;&lt; endl; } int getA() { return _a; }};void functionA() { Test t1(3); Test t2(t1); // 类的初始化操作(括号法)，拷贝构造函数会被调用 cout &lt;&lt; \"a = \" &lt;&lt; t2.getA() &lt;&lt; endl;}int main() { functionA(); return 0;} 程序运行输出的结果如下： 12345有参构造函数被调用了拷贝构造函数被调用了a = 13析构函数被调用了析构函数被调用了 第三种调用场景12345678910111213141516171819202122232425262728293031323334353637383940414243#include \"iostream\"using namespace std;class Location {private : int X, Y;public: Location(int xx = 0, int yy = 0) { X = xx; Y = yy; cout &lt;&lt; \"有参构造函数被调用了\" &lt;&lt; endl; } Location(const Location &amp;p) { X = p.X; Y = p.Y; cout &lt;&lt; \"拷贝构造函数被调用了\" &lt;&lt; endl; } ~Location() { cout &lt;&lt; \"析构函数被调用了\" &lt;&lt; endl; } int getX() { return X; } int getY() { return Y; }};void functionA(Location b) { cout &lt;&lt; b.getX() &lt;&lt; \",\" &lt;&lt; b.getY() &lt;&lt; endl;}int main() { Location a(1, 2); functionA(a); // 拷贝构造函数会被调用，这里会使用实参变量（a）初始化形参变量（b），同时会多创建一个Location对象（匿名对象），所以最后析构函数会被调用两次 return 0;} 程序运行输出的结果如下： 12345有参构造函数被调用了拷贝构造函数被调用了1,2析构函数被调用了析构函数被调用了 第四种调用场景1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;using namespace std;class Location {private : int x, y;public: Location(int xx = 0, int yy = 0) { x = xx; y = yy; cout &lt;&lt; \"有参构造函数被调用了\" &lt;&lt; endl; } Location(const Location &amp;p) { x = p.x; y = p.y; cout &lt;&lt; \"拷贝构造函数被调用了\" &lt;&lt; endl; } ~Location() { cout &lt;&lt; \"析构函数被调用了\" &lt;&lt; endl; } int getX() { return x; } int getY() { return y; }};Location functionA() { Location l(1, 2); return l;}int main() { // 匿名对象的去与留，关键是看返回匿名对象时如何接收，一般有以下两种情况： // 若将函数functionA()返回的匿名对象，赋值给另外一个同类型的对象，那么匿名对象会被析构 // 此时有参构造函数和析构函数被调用两次 Location A; A = functionA(); // 若使用函数functionA()的匿名对象，来初始化另外一个同类型的对象，那么匿名对象会直接转成B对象 // 此时有参构造函数与析构函数各被调用一次 // Location B = functionA(); return 0;} 程序运行输出的结果如下： 1234有参构造函数被调用了有参构造函数被调用了析构函数被调用了析构函数被调用了 思考：在上述的代码中，在 main() 函数内直接调用 functionA() 函数时，为什么拷贝构造函数没有被调用呢？是否跟 C++ 编译器的版本有关系呢？ 构造函数的使用规则 当类中没有定义任何一个构造函数时，C++ 编译器会提供默认无参构造函数和默认拷贝构造函数 当类中定义了拷贝构造函数时，C++ 编译器不会提供默认无参构造函数 当类中定义了任意的非拷贝构造函数（即当类中定义了有参构造函数或无参构造函数），C++ 编译器不会提供默认无参构造函数 C++ 提供的默认拷贝构造函数，只负责给类成员变量简单赋值 必要的时候，需要手动编写拷贝构造函数 构造函数和普通成员函数都遵循函数重载规则 构造函数初始化列表初始化列表出现的原因有的时候必须用带有初始化列表的构造函数：（1）没有默认无参构造函数的成员类对象；（2）const 成员或引用类型的成员，必须要通过初始化列表进行初始化，因为这两种对象要在声明后马上初始化，而在构造函数中，做的就是对它们赋值，这样是不被允许的。值得一提的是，构造函数中有着比我们所看见的还要多的细节，构造函数可以调用其它的构造函数来初始化对象中的基类对象和成员对象的构造函数。类的数据成员中的其它类对象，若该成员对象是没有默认无参构造函数，则必须进行显式初始化；因为编译器会隐式调用成员对象的默认无参构造函数，而它又没有默认无参构造函数，则编译器会编译失败。 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class Teacher {private : int _age;public: Teacher(int age) { _age = age; } int getAge() const { return _age; }};class Student {private : int _age; Teacher teacher;public: int getAge() const { return _age; }};int main() { Teacher t(20); Student s; // C++编译器编译不通过 return 0;} 上述示例代码无法通过编译，Student 的类数据成员中有一个 Teacher 类的对象 teacher，创建 Student 类时，要先创建其成员对象 teacher；由于 Teacher 类有一个自定义的有参构造函数，C++ 编译器不会再提供默认无参构造函数，因此 teacher 对象无法被自动创建。使用构造函数初始化列表改写后，正确的示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;class Teacher {private : int _age;public: Teacher(int age) { _age = age; } int getAge() const { return _age; }};class Student {private : int _age; Teacher teacher;public: // 使用构造函数的初始化列表来初始化Teacher类对象 // 这里会自动调用Teacher类的有参构造函数，并将age2作为构造函数的参数传递过去 Student(int age1, int age2) : teacher(age2) { _age = age1; } int getAge() const { return _age; } Teacher getTeacher() { return teacher; }};int main() { Student s(20, 35); cout &lt;&lt; \"student.age: \" &lt;&lt; s.getAge() &lt;&lt; \", teacher.age: \" &lt;&lt; s.getTeacher().getAge() &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1student.age: 20, teacher.age: 35 初始化列表使用的语法规则构造函数初始化列表以一个冒号开始，接着是以逗号分隔的数据成员列表，每个数据成员后面跟一个放在括号中的初始化式。 1234Constructor::Contructor() : m1(v1), m2(v1,v2), m3(v3){} 在下述的示例代码中，两个构造函数的最终效果是一样的。使用初始化列表的构造函数是显式地初始化类的成员；而没有使用初始化列表的构造函数是对类的成员赋值，并没有显式地初始化。 12345678910111213141516171819class A{public: int a; float b; A(): a(0),b(9.9) {} //构造函数初始化列表};class A{public: int a; float b; A() //构造函数内部赋值 { a = 0; b = 9.9; }}; 初始化 const 成员和引用成员构造函数初始化列表是初始化 const 成员和引用成员的唯一方式。因为 const 成员或引用类型的成员只能被初始化，不能对它们赋值。示例代码如下： 12345678910111213141516171819202122232425#include &lt;iostream&gt;using namespace std;class A {private: int i; int &amp;j; const int c;public: // 构造函数初始化列表 A(int x, int y) : c(x), j(y) { i = -1; }};int main() { int m; A a(5, m); // C++编译可以通过 return 0;} 若不通过初始化列表来对 const 成员或引用类型的成员进行初始化，那么缺省情况下，在构造函数被执行之前，对象中的所有成员都已经被它们自己的默认无参构造函数初始化了。由于这两种数据成员要在声明后马上初始化，而在构造函数中，做的就是对它们赋值，这样是不被允许的。示例代码如下： 1234567891011121314151617181920212223#include &lt;iostream&gt;using namespace std;class A {private: int i; int &amp;j; const int c;public: A(int x) { i = -1; c = 5; // C++编译不通过，必须通过初始化列表来初始化 j = x; // C++编译不通过，必须通过初始化列表来初始化 }};int main() { A a(3); return 0;} 当类中某个数据成员本身也是一个类对象时，应该尽量避免使用赋值操作来对该成员进行初始化，示例代码如下： 1234567891011class Person{private: string name;public: Person(string &amp; n) { name = n; }} 虽然这样的构造函数也能得到正确的结果，但这样写效率并不高。当一个 Person 对象创建时，string 类成员对象 name 先会被默认无参构造函数进行初始化，然后在 Person 类的自定义有参构造函数中，它的值又会因赋值操作而再改变一次。这里可以通过初始化列表来显示地对 name 对象进行初始化，这样就可以将前面的两步骤（初始化和赋值）合并成一个步骤了。示例代码如下： 12345678910class Person{private: string name;public: Person(string&amp; n): name(n){ }} 初始化与赋值的区别重点知识点： 初始化：被初始化的对象正在创建 赋值：被赋值的对象已经存在 初始化列表优先于构造函数的执行 成员变量的初始化顺序与声明的顺序相关，与在初始化列表中的顺序无关 在宏观代码上，两者作用相同。对于数组和结构体来说，初始化和赋值的的形式不同。对于数组，可以使用花括号一起初始化，如果赋值的话，就只能单个元素就行；对于结构体，可以使用花括号初始化，否则只能通过 . 来访问变量进行赋值。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;struct MyStruct { int aa; float bb; string cc;};int main() { int a[3] = {1, 2, 3}; int b[3]; b[0] = 1; b[1] = 2; b[2] = 3; MyStruct stu1 = {1, 3.14f, \"hello world\"}; MyStruct stu2; stu2.aa = 1; stu2.bb = 3.14f; stu2.cc = \"we are csdn\"; cout &lt;&lt; stu1.aa &lt;&lt; endl; cout &lt;&lt; stu1.bb &lt;&lt; endl; cout &lt;&lt; stu1.cc &lt;&lt; endl; return 0;} 构造函数和析构函数的调用顺序 当类中有成员变量是其它类的对象时，首先调用成员变量的构造函数，调用顺序与声明顺序相同，之后再调用类自身的构造函数 析构函数的调用顺序与对应的构造函数调用顺序相反 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 入门基础之三","url":"/posts/f26087ad.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 C++ 对 C 语言的函数扩展内联函数什么是内联函数在 C 语言中，使用宏定义函数这种借助编译器的优化技术来减少程序的执行时间，那么在 C++ 中有没有相同的技术或者更好的实现方法呢？答案是有的，那就是内联函数。内联函数作为编译器优化手段的一种技术，在降低程序运行时间上非常有用。C++ 的内联函数是通常与类一起使用。如果一个函数是内联的，那么在编译时，编译器会把该函数的代码副本放置在每个调用该函数的地方。对内联函数进行任何修改，都需要重新编译函数的所有客户端，因为编译器需要重新更换一次所有的代码，否则将会继续使用旧的函数。如果想把一个函数定义为内联函数，则需要在函数名前面放置关键字 inline，在调用函数之前需要对函数进行定义。所有在类中定义的函数都是内联函数，即使没有使用 inline 关键字声明。当内联函数收到编译器的指示时，即可发生内联：编译器将使用函数的定义体来替代函数调用语句，这种替代行为发生在编译阶段而非程序运行阶段。值得一提的是，内联函数仅仅是对编译器的内联建议，编译器是否觉得采取建议取决于函数是否符合内联的有利条件。如何函数体非常大，那么编译器将忽略函数的内联声明，而将内联函数作为普通函数处理。 为什么要使用内联函数有时候我们会写一些功能专一的函数，这些函数的函数体不大，包含了很少的执行语句。例如在计算 1~1000 以内的素数时，我们经常会使用开方操作使运算范围缩小，这时我们会写如下一个函数： 1234int root(int n){ return (int)sqrt((float)n);} 然后求范围内素数的函数可以这样写： 12345678910int prime(int n){ int i; for (i = 2; i &lt;= root(n); i++) { if (n%i == 0) return 0; return 1; }} 当然，把 root 函数放在循环中不是个不明智的选择，但想象一下，在某个程序上下文内必须频繁地调用某个类似 root 的函数，其调用函数的花销会有多大：当遇到普通函数的调用指令时，程序会保存当前函数的执行现场，将函数中的局部变量以及函数地址压入堆栈，然后再将即将调用的新函数加载到内存中，这要经历复制参数值、跳转到所调用函数的内存位置、执行函数代码、存储函数返回值等过程；当函数执行完后，再获取之前正在调用的函数的地址，回去继续执行那个函数，运行时间开销简直太多了。为了解决上述问题，C++ 内联函数提供了替代函数调用的方案，通过 inline 声明，编译器首先在函数调用处使用函数体本身语句替换了函数调用语句，然后编译替换后的代码。因此，通过内联函数，编译器不需要跳转到内存其他地址去执行函数调用，也不需要保留函数调用时的现场数据。 如何使用内联函数12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;// 宏定义函数的声明#define MAXFUNC(x, y) (x &gt; y) ? x : y// 内联函数的声明inline int Max(int x, int y) { return (x &gt; y) ? x : y;}int main() { // 内联函数的调用 cout &lt;&lt; \"Max (20,10): \" &lt;&lt; Max(20, 10) &lt;&lt; endl; cout &lt;&lt; \"Max (0,200): \" &lt;&lt; Max(0, 200) &lt;&lt; endl; cout &lt;&lt; \"Max (100,1010): \" &lt;&lt; Max(100, 1010) &lt;&lt; endl; // 宏定义函数的调用 printf(\"Max (10,30): %d\\n\", MAXFUNC(10, 30)); return 0;} 程序运行的输出结果如下： 1234Max (20,10): 20Max (0,200): 200Max (100,1010): 1010Max (10,30): 30 内联函数的优缺点优点： 它通过避免函数调用所带来的开销来提高程序的运行速度 通过将函数声明为内联，则可以把函数定义放在头文件内 它避免了普通函数调用时的额外开销（压栈、弹栈、跳转、返回） 缺点： 因为代码的扩展，内联函数增大了可执行程序的体积 C++ 内联函数的展开是编译阶段，这就意味着如果内联函数发生了改动，那么就需要重新编译代码 当把内联函数放在头文件中时，它将会使头文件信息变多，不过头文件的使用者不用在意这些细节 有时候内联函数并不受到青睐，比如在嵌入式系统中，嵌入式系统的存储约束可能不允许体积很大的可执行程序运行 内联函数的编译限制C++ 中内联函数编译的限制： 函数体不能过于庞大 不能对函数进行取址操作 不能存在任何形式的循环语句 不能存在过多的条件判断语句 函数的内联声明必须在调用语句之前 编译器对于内联函数的限制并不是绝对的，内联函数相对于普通函数的优势只是省去了函数调用时压栈、弹栈、跳转和返回的开销。因此，当函数体的执行开销远大于压栈、弹栈、跳转和返回所用的开销时，那么内联将变得毫无意义。 什么时候该使用内联函数当程序设计需要时，每个函数都可以声明为 inline，下面列举一些有用的建议： 当对程序执行性能有要求时，那么就可以使用内联函数 当想使用宏定义一个函数时，那就果断使用内联函数来替代 在类内部定义的函数会默认声明为 inline 函数，这有利于类实现细节的隐藏 关键点： 虚函数不允许内联 所有在类中定义的函数都默认声明为 inline 函数，所有不用再显示地去声明 inline 虽然说模板函数放中头文件中，但它们不一定是内联的（不是说定义在头文件中的函数都是内联函数） C++ 编译器会直接将编译后的内联函数体插入到调用的地方，内联函数在最终生成的代码中是没有定义的 内联函数由编译器处理，直接将编译后的内联函数体插入到调用的地方；而宏定义由预处理器处理，只进行简单的文本替换，没有任何编译过程 一些现代的 C++ 编译器提供了扩展语法，能够对函数进行强制内联，例如： g++ 中的 __attribute__((always_inline)) 属性 编译器的内联看起来就像是代码的复制与粘贴，但这与预处理宏是很不同的；宏定义函数是强制的内联展开，可能将会污染所有的命名空间与代码，会为程序的调试带来困难 内联声明只是一种对编译器的建议，编译器是否采用内联措施由编译器自己来决定。现代 C++ 编译器能够进行编译优化，甚至在汇编阶段或链接阶段，一些没有 inline 声明的函数，也可能被编译器内联编译 函数默认参数C++ 中可以在函数声明时为参数提供一个默认值，当函数调用时没有指定这个参数的值，编译器会自动用默认值代替。函数默认参数的使用规则如下： 只有参数列表后面部分的参数才可以提供默认参数值 一旦在一个函数调用中开始使用默认参数值，那么这个参数后的所有参数都必须使用默认参数值 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;void funcA(int x = 3) { printf(\"x: %d\\n\", x);}void funcB(int a, int b, int y = 4, int z = 5) { printf(\"a: %d, b: %d, y: %d, z: %d\\n\", a, b, y, z);}int main() { funcA(); funcA(6); funcB(1, 2); funcB(1, 2, 3, 4); return 0;} 程序运行的输出结果如下： 1234x: 3x: 6a: 1, b: 2, y: 4, z: 5a: 1, b: 2, y: 3, z: 4 函数占位参数函数占位参数只有参数类型声明，而没有参数名声明；一般情况下，在函数体内部无法使用占位参数。 123456789101112#include &lt;iostream&gt;using namespace std;int func(int a, int b, int) { return a + b;}int main() { printf(\"func(1, 2, 3) = %d\\n\", func(1, 2, 3)); return 0;} 程序运行的输出结果如下： 1func(1, 2, 3) = 3 函数默认参数结合函数占位参数 可以将函数默认参数与函数占位参数结合起来使用，其意义在于为以后程序的扩展留下空间，并兼容 C 语言代码中可能出现的不规范写法。 12345678910111213#include &lt;iostream&gt;using namespace std;void func(int a, int b, int = 0) { printf(\"a + b = %d\\n\", a + b);}int main() { func(1, 2); func(1, 2, 3); return 0;} 程序运行的输出结果如下： 12a + b = 3a + b = 3 函数重载函数重载的概念函数重载概念（Function Overload）： 用同一个函数名定义不同的函数 当函数名和不同的参数搭配时函数的含义不同 函数重载至少满足下面的一个条件（函数重载的判断标准）： 参数个数不同 参数类型不同 参数顺序不同 特别注意： 函数的返回值不是函数重载的判断标准 函数重载的使用12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int func(int x) { return x;}int func(int a, int b) { return a + b;}int func(const char *s) { return strlen(s);}int main() { int c = 0; c = func(1); printf(\"c = %d\\n\", c); c = func(1, 2); printf(\"c = %d\\n\", c); c = func(\"12345\"); printf(\"c = %d\\n\", c); return 0;} 程序运行的输出结果如下： 123c = 1c = 3c = 5 函数重载的调用准则编译器调用重载函数的准则： 将所有同名函数作为候选者 尝试寻找可行的候选函数 精确匹配实参 通过默认参数能够匹配实参 通过默认类型转换匹配实参 匹配失败 最终寻找到的可行候选函数不唯一，则出现二义性，编译失败 无法匹配所有候选者，函数未定义，编译失败 函数重载的注意事项： 重载函数的函数类型是不同的 函数重载是发生在一个类中里面的 函数的返回值不能作为函数重载的依据 函数重载是由函数名和参数列表决定的 重载函数在本质上是相互独立的不同函数 函数重载与函数指针当使用重载函数名对函数指针进行赋值时： 根据重载规则挑选与函数指针参数列表一致的候选者 严格匹配候选者的函数类型与函数指针的函数类型 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int func(int x) { return x;}int func(int a, int b) { return a + b;}int func(const char *s) { return strlen(s);}// 第一种写法：声明函数类型typedef int (FUNC)(int a);// 第二种写法：声明函数指针类型typedef int(*PFUNC)(int a, int b);int main() { // 根据上面的第一种写法，定义函数指针类型的变量 FUNC *FUNC = func; int c = FUNC(1); printf(\"c = %d\\n\", c); // 根据上面的第二种写法，定义函数指针类型的变量 PFUNC p = func; int d = p(3, 4); printf(\"d = %d\\n\", d); return 0;} 程序运行的输出结果如下： 12c = 1d = 7 函数重载与函数默认参数当函数重载遇上函数默认参数时，如果代码存在二义性，那么 C++ 编译器会编译失败，示例代码如下： 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;int func(int a, int b, int c = 0) { return a * b * c;}int func(int a, int b) { return a + b;}int func(int a) { return a;}int main() { int c = 0; // c = func(1, 2); // 存在二义性，调用失败，编译不能通过 printf(\"c = %d\\n\", c); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 入门基础之二","url":"/posts/b03c11a0.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 const 关键字const 简介const 是 constant 的缩写，本意是不变的，不易改变的意思。在 C++ 中是用来修饰内置类型变量、自定义对象、成员函数、返回值、函数参数。C++ 的 const 关键字允许指定一个语义约束，编译器会强制实施这个约束，允许程序员告诉编译器某值是保持不变的。如果在编程中确实有某个值保持不变，就应该明确使用 const，这样可以获得编译器的帮助。 1234567891011#include &lt;iostream&gt;using namespace std;int main() { const int a = 7; int *p = (int *) &amp;a; *p = 8; cout &lt;&lt; a &lt;&lt; \" \"&lt;&lt; *p; return 0;} 在上述代码中，对于 const 变量 a，我们取变量的地址并转换赋值给 指向 int 的指针，然后利用 *p = 8; 重新赋值，然后输出查看 a 的值，程序运行的输出结果如下： 17 8 从结果中可以看到，编译器认为 a 的值为一开始定义的 7，所以对 const a 的操作就会产生上面的情况。所以千万不要轻易对 const 变量赋值，这会产生意想不到的行为。C++ 编译器对 const 常量的处理机制是，当碰见常量声明时，往符号表中放入常量；在编译过程中若发现使用常量，则直接以符号表中的值替换，例如在编译过程中若发现对 const 常量使用了 extern 或者 &amp; 操作符，则会给对应的常量单独分配内存空间（兼容 C 语言），这也是上述代码中打印 *p 的值为 8 的原因，点击查看原理分析图。 如果不想让编译器察觉到上面对 const 变量的操作，我们可以在 const 前面加上 volatile 关键字。volatile 关键字跟 const 刚好相反，是易变的，容易改变的意思；所以不会被编译器优化，编译器也就不会改变对 a 变量的操作。 1234567891011#include&lt;iostream&gt;using namespace std;int main() { volatile const int a = 7; int *p = (int *) &amp;a; *p = 8; cout &lt;&lt; a &lt;&lt; \" \" &lt;&lt; *p; return 0;} 程序运行的输出结果如下： 18 8 const 参数传递对于 const 修饰函数参数可以分为三种情况： A：值传递的 const 修饰传递，一般这种情况不需要 const 修饰，因为函数会自动产生临时变量复制实参值。 123456789101112131415#include &lt;iostream&gt;using namespace std;void Cpf(const int a){ cout &lt;&lt; a; // ++a; 是错误写法，a 不能被改变}int main(){ Cpf(8); return 0;} B：当 const 参数为指针时，可以防止指针被意外篡改。 123456789101112131415#include &lt;iostream&gt;using namespace std;void Cpf(int *const a) { cout &lt;&lt; *a &lt;&lt; endl; // a 为 8 *a = 9;}int main() { int a = 8; Cpf(&amp;a); cout &lt;&lt; a &lt;&lt; endl; // a 为 9 return 0;} C：自定义类型的参数传递，需要使用临时对象复制参数，对于临时对象的构造，需要调用拷贝构造函数，比较浪费资源，因此可以采取 const 外加引用传递的方式。并且对于一般的 int、double 等内置类型，不需要采用引用的传递方式。 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); return 0;} 程序运行的输出结果如下： 18 const 函数返回值对于 const 修饰函数的返回值可以分三种情况： A：const 修饰内置类型（如 int、double）的返回值，修饰与不修饰返回值的作用都一样。 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;const int Cmf() { return 1;}int Cpf() { return 0;}int main() { int _m = Cmf(); int _n = Cpf(); cout &lt;&lt; _m &lt;&lt; \" \" &lt;&lt; _n; // 输出结果为：1 0 return 0;} B：const 修饰自定义类型的作为返回值，此时返回的值不能作为左值使用，既不能被赋值，也不能被修改。 C：const 修饰返回的指针或者引用，是否返回一个指向 const 的指针，取决于我们想让用户干什么。 const 修饰指针变量const 修饰指针变量有以下三种情况： A： const 修饰指针指向的内容，则内容为不可变量。 B： const 修饰指针，则指针为不可变量。 C： const 修饰指针和指针指向的内容，则指针和指针指向的内容都为不可变量。 对于 A，则指针指向的内容不可改变，简称左定值，因为 const 位于 * 号的左边。 12345int a = 10;int b = 20;const int *p = &amp;a;p = &amp;b; // 正确写法*p = 10; //错误写法 对于 B， const 指针 p 其指向的内存地址不能够被改变，但其内容可以改变。简称右定向，因为 const 位于 * 号的右边。 12345int a = 8;int * const p = &amp;a;*p = 9; // 正确写法int b = 7;p = &amp;b; // 错误写法 对于 C，则是 A 和 B 合并的结果，即 const p 指向的内容和指向的内存地址都已固定，不可改变。 12int a = 8;const int * const p = &amp;a; 对于 A、B、C 三种情况，根据 const 位于 * 号的位置不同，可以总结三句便于记忆的话： 左定值，右定向，const 修饰不变量。 const 修饰类成员函数const 修饰类成员函数，其目的是防止成员函数修改被调用对象的值，如果我们不想修改一个调用对象的值，所有的成员函数都应当声明为 const 成员函数，此时 const 本质上修饰的是 this 指针。值得一提的是，const 关键字不能与 static 关键字同时使用，因为 static 关键字修饰静态成员函数，而静态成员函数不含有 this 指针，即不能实例化，但 const 成员函数必须关联某一对象实例。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;class Test {private: int _cm;public: Test() {} Test(int _m) : _cm(_m) {} int get_cm() const { // _cm = 10; 是错误写法，对象的_cm属性值不能被改变 return _cm; }};void Cmf(const Test &amp; _tt) { cout &lt;&lt; _tt.get_cm();}int main() { Test t(8); Cmf(t); return 0;} 程序运行的输出结果如下： 18 上面的 int get_cm() const {} 函数用到了 const 成员函数，如果 int get_cm() {} 去掉 const 修饰，则 Cmf 函数传递的 const _tt 即使没有改变对象的值，编译器也认为函数 int get_cm() {} 会改变对象的值，所以我们尽量按照要求将所有的不需要改变对象内容的函数都作为 const 成员函数。下述两种的写法都是合法的，效果都一样，C++ 中一般将 const 写在函数的末尾处。 123456int get_cm() const {}int const get_cm() {} 如果有个成员函数想修改对象中的某一个成员怎么办？这时我们可以使用 mutable 关键字修饰这个成员，mutable 的意思也是易变的，容易改变的意思，被 mutable 关键字修饰的成员可以处于不断变化中，如下面的例子： 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;class Test {public: int _cm; mutable int _ct;public: Test(int _m, int _t) : _cm(_m), _ct(_t) {} void Kf() const { // ++_cm; 错误写法 ++_ct; // 正确写法 }};int main() { Test t(8, 7); t.Kf(); cout &lt;&lt; t._cm &lt;&lt; \" \" &lt;&lt; t._ct &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 18 8 这里在函数 void Kf() const {} 中可以通过 ++_ct; 修改 _ct 的值，但是通过 ++_cm 修改 _cm 则会报错，因为 _cm 没有用 mutable 修饰。 const 和 #define 的区别C++ 中不但可以用 #define 定义常量还可以用 const 定义常量，例如 const int c = 5; ≈ #define c 5，它们的区别如下： 用 #define MAX 255 定义的常量是没有类型的，所给出的是一个立即数，编译器只是把所定义的常量值与所定义的常量的名字联系起来，#define 所定义的宏变量在编译器执行预处理的时候进行替换，在程序中使用到该常量的地方都要进行拷贝替换 用 const float MAX = 255; 定义的常量有类型名字，存放在内存的静态区域中，在程序运行过程中 const 变量只有一个拷贝，而 #define 所定义的宏变量却有多个拷贝，所以宏定义在程序运行过程中所消耗的内存要比 const 变量的大得多 用 #define 定义的常量是不可以用指针变量去指向的，用 const 定义的常量是可以用指针去指向该常量的地址 用 #define 可以定义一些简单的函数，const 是不可以定义函数 编译器处理方式： #define – 在编译器的预处理阶段进行单纯的文本替换 const – 在编译器的编译阶段确定其值 类型检查： #define – 无类型，不进行类型安全检查，可能会产生意想不到的错误 const – 有数据类型，编译时会进行类型与作用域检查 内存空间： #define – 不分配内存，给出的是立即数，有多少次使用就进行多少次替换，在内存中会有多个拷贝，消耗内存大 const – 在静态存储区中分配空间，在程序运行过程中内存中只有一个拷贝 其他方面： 在编译时，编译器通常不为 const 常量分配内存空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。#define 宏替换只作替换，不做计算，不做表达式求解 宏定义的作用范围仅限于当前文件，默认状态下，const 常量只在文件内有效，当多个文件中出现了同名的 const 常量时，等同于在不同文件中分别定义了独立的常量。如果想在多个文件之间共享 const 常量，必须在常量定义之前添加 extern 关键字（在声明和定义时都要添加） C 语言与 C++ 的 const 对比C 语言的 const 变量： C 语言中 const 变量是只读变量，有自己的内存空间 C 语言中，可以通过操作指针的方式来修改 const 变量的值 C++ 的 const 常量： 可能分配内存空间，也可能不分配内存空间 当使用 &amp; 操作符取 const 常量的地址时，会分配内存空间 当 const 常量为全局，并且需要在其它文件中使用，会分配内存空间 当 const int &amp;a = 10;，即 const 修饰引用时，也会分配内存空间 注意：C++ 编译器虽然可能为 const 常量分配内存空间，但不会使用其内存空间中的值，同时是在编译器的编译阶段分配内存空间 引用（普通引用）变量名回顾 变量名实质上是一段连续内存空间的别名，是一个标号（门牌号） 程序中通过变量来申请并命名内存空间 通过变量的名称可以使用内存空间 引用的概念在 C++ 中新增加了引用的概念： a) 引用可以看作一个已定义变量的别名 b) 引用的语法：Type &amp; name = var; c) 引用作为函数参数声明时，不会进行初始化 d) 普通引用在声明时必须用其它的变量进行初始化 123456789101112131415161718#include &lt;iostream&gt;using namespace std;int main() {{ int a = 10; // 编译器分配4个字节的内存空间，a是内存空间的别名 int &amp;b = a; // b就是a的别名，即b引用了a a =11; // 直接赋值 { int *p = &amp;a; *p = 12; printf(\"a %d \\n\",a); } b = 14; printf(\"a:%d b:%d\", a, b); return 0;} 程序运行的输出结果如下： 12a 12a:14 b:14 引用是 C++ 的概念引用属于 C++ 编译器对 C 语言的扩展，下述代码在 C 语言中不能通过编译，这里不要用 C 语言的语法去思考 b = 11。 123456int main() { int a = 0; int &amp;b = a; b = 11; return 0;} 引用作函数参数 普通引用在声明时必须用其它的变量进行初始化，int &amp;a; 这样的写法是错误的（在结构体内声明除外） 引用作为函数参数声明时，不会进行初始化 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;using namespace std;struct Teacher { char name[64]; int age;};// pT是指向t1的指针，这里相当于修改了t1void printfT(Teacher *pT) { cout &lt;&lt; pT-&gt;age &lt;&lt; endl; pT-&gt;age = 23;}// pT是t1的别名，这里相当于修改了t1void printfT2(Teacher &amp; pT) { cout &lt;&lt; pT.age &lt;&lt; endl; pT.age = 33;}// pT和t1的是两个不同的变量，这里只会修改pT变量，不会修改t1变量void printfT3(Teacher pT) { cout &lt;&lt; pT.age &lt;&lt; endl; pT.age = 43;}int main() { Teacher t1; t1.age = 35; // pT是指向t1的指针 printfT(&amp;t1); printf(\"t1.age:%d \\n\", t1.age); // pT是t1的别名 printfT2(t1); printf(\"t1.age:%d \\n\", t1.age); // pT是形参，相当于t1复制一份数据给pT ---&gt; pT = t1 printfT3(t1); printf(\"t1.age:%d \\n\", t1.age); return 0;} 程序运行输出的结果如下： 12345635t1.age:2323t1.age:3333t1.age:33 引用的使用意义 引用作为其它变量的别名而存在，因此在一些场合可以代替指针 引用相对于指针来说，具有更好的可读性和实用性 使用引用和指针，分别实现交换两个数字的 C++ 代码如下： 引用的本质分析 1）引用在 C++ 中的内部实现是一个常指针，Type &amp; name --&gt; Type * const name 2）C++ 编译器在编译过程中，使用常指针作为引用的内部实现，因此引用所占用的内存空间大小与指针相同 3）从使用的角度看，引用会让人误会其只是一个别名，没有自己的内存空间，这是 C++ 为了实用性而做出的细节隐藏 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;void func(int &amp;a) { a = 10;}void func(int *const a) { *a = 15;}int main() { int x = 5; func(x); cout &lt;&lt; x &lt;&lt; endl; // 10 func(&amp;x); cout &lt;&lt; x &lt;&lt; endl; // 15 return 0;} 参考上述代码，函数参数间接赋值（指针方式）成立的三个条件如下： a) 定义两个变量（一个实参一个形参） b) 建立关联，实参取地址传给形参 c) 使用 *a 形参去间接的修改实参的值 引用在实现上，只不过是把间接赋值成立的三个条件的后两步和二为一；当实参传给形参引用的时候，是 C++ 编译器帮程序员自动取了一个实参地址传给了形参引用（常量指针）。当我们使用引用语法的时，不需要关心编译器引用是怎么做的；当我们分析奇怪的语法现象时，我们才去考虑 C++ 编译器是怎么做的。 函数返回值是引用当函数返回值为引用时： 若函数返回的是栈变量（如作用域只在函数体内的变量），不能成为其它引用的初始值，不能作为左值使用 若函数返回的是静态变量或全局变量，可以成为其他引用的初始值，即可作为右值使用，也可作为左值使用 函数返回值是基础类型当引用12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;int getAA1() { int a; a = 10; return a;}int &amp; getAA2() { int a; a = 10; return a;}int * getAA3() { int a; a = 10; return &amp;a;}int main() { int a1 = getAA1(); int a2 = getAA2(); int &amp;a3 = getAA2(); int *a4 = getAA3(); cout &lt;&lt; \"a1 = \" &lt;&lt; a1 &lt;&lt; endl; cout &lt;&lt; \"a2 = \" &lt;&lt; a2 &lt;&lt; endl; cout &lt;&lt; \"a3 = \" &lt;&lt; a3 &lt;&lt; endl; // 这里用引用去接受函数的返回值，结果是不是乱码，关键是看返回的内存空间是不是被编译器回收了 cout &lt;&lt; \"a4 = \" &lt;&lt; *a4 &lt;&lt; endl; // 这里用引用去接受函数的返回值，结果是不是乱码，关键是看返回的内存空间是不是被编译器回收了 return 0;} 程序运行输出的结果如下： 1234a1 = 10a2 = 10a3 = 10 或者 a3 = 乱码a4 = 10 或者 a4 = 乱码 函数返回值是 static 变量当引用值得一提的是，static 关键字修饰变量的时候，变量是一个状态变量。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;using namespace std;int j() { static int a = 10; a++; printf(\"a:%d \\n\", a); return a;}int &amp; j1() { static int a = 10; a++; printf(\"a:%d \\n\", a); return a;}int * j2() { static int a = 15; a++; printf(\"a:%d \\n\", a); return &amp;a;}int main() { // 错误写法，j()的运算结果是一个数值，没有内存地址，不能当左值，类似 11 = 100; // j() = 3; //当被调用的函数当左值的时候，必须返回一个引用 j1() = 100; j1(); *(j2()) = 200; j2(); return 0;} 程序运行输出的结果如下： 1234a:11a:101a:16a:201 函数返回值是形参当引用12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;int g1(int *p) { *p = 100; return *p;}int &amp; g2(int *p) { *p = 100; return *p;}int main() { int a1 = 10; a1 = g2(&amp;a1); int &amp;a2 = g2(&amp;a1); printf(\"a1:%d \\n\", a1); printf(\"a2:%d \\n\", a2); return 0;} 程序运行输出的结果如下： 12a1:100a2:100 函数返回值是非基础类型如果函数返回的引用不是基础类型，而是一个类，那么此时的情况非常复杂，涉及到 copy 构造函数和 = 操作重载的知识内容，这里暂时不展开讨论。 123456789101112#include &lt;iostream&gt;using namespace std;struct Teachar { char name[64]; int age;};struct Teachar &amp; OpTeacher(struct Teachar &amp;t1) {} 指针引用12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;struct Teacher { char name[64]; int age;};// 二级指针作函数参数int getTe(Teacher **myp) { Teacher *p = (Teacher *) malloc(sizeof(Teacher)); if (p == NULL) { return -1; } memset(p, 0, sizeof(Teacher)); p-&gt;age = 33; *myp = p; return 0;}// 指针引用作函数参数int getTe2(Teacher *&amp;myp) { myp = (Teacher *) malloc(sizeof(Teacher)); if (myp == NULL) { return -1; } myp-&gt;age = 34; return 0;}int main() { Teacher *p = NULL; getTe(&amp;p); printf(\"age:%d \\n\", p-&gt;age); Teacher *pp = NULL; getTe2(pp); printf(\"age:%d \\n\", pp-&gt;age); return 0;} 程序运行输出的结果如下： 12age:33age:34 常引用使用变量初始化 const 引用在 C++ 中可以声明 const 引用，例如 const Type &amp; name = var;，其中的 const 引用让变量拥有只读属性。 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int main() { int a = 10; const int &amp;b = a; // b = 11; 是错误写法，这里不能通过引用改变a的值，无法通过编译 // 只能用指针来改变引用的值 int * p = (int*) &amp;b; *p = 11; printf(\"a:%d\\n\", a); printf(\"b:%d\\n\", b); printf(\"&amp;a:%d\\n\", &amp;a); printf(\"&amp;b:%d\\n\", &amp;b); return 0;} 程序运行的输出结果如下： 1234a:11b:11&amp;a:1323872140&amp;b:1323872140 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;struct Teacher { char name[64]; int age;};// const引用让变量(所指内存空间)拥有只读属性void printTe(const Teacher &amp;t) { // t.age = 11; 是错误写法，无法通过编译}// const 修饰指针和指针指向的内容，那么指针指向的内容都不能更改void printTe2(const Teacher *const pt) { // pt-&gt;age = 11; 是错误写法，无法通过编译}int main() { Teacher t1; t1.age = 33; printTe(t1); printTe2(&amp;t1); return 0;} 使用字面量常量初始化 const 引用1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { const int b = 10; printf(\"b:%d\\n\", &amp;b); // int &amp;a = 19; 若不加const关键字，则编译失败 const int &amp;a = 19; printf(\"&amp;a:%d \\n\", &amp;a); return 0;} const 引用综合使用示例12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;int main() { // 普通引用 int a = 10; int &amp;b = a; // 常量引用，让变量拥有只读属性 const int &amp;c = a; // 常量引用的初始化分为以下两种 // 1.用变量初始化常量引用 { int x = 20; const int &amp;y = x; printf(\"y:%d \\n\", y); } // 2.用字面量常量初始化常量引用 { // int &amp;m = 10; // 错误写法，引用是内存空间的别名，字面量10没有内存空间，没有方法做引用 const int &amp;m = 10; } return 0;} const 引用总结 普通引用 int &amp;e = a; 相当于 int * const e = &amp;a; 常引用 const int &amp; e; 相当于 const int * const e; 当使用字面量常量对 const 引用进行初始化时（如 const int &amp;m = 10;），C++ 编译器会为常量值单独分配内存空间，并将引用名作为这段内存空间的别名 使用字面量常量对 const 引用初始化后（如 const int &amp;m = 10;），将生成一个只读变量，但可以使用指针的方式更改变量的值，示例代码如下： 1234567891011#include &lt;iostream&gt;using namespace std;int main() { const int &amp;a = 100; int *p = (int *) &amp;a; *p = 30; cout &lt;&lt; *p &lt;&lt; endl; cout &lt;&lt; a &lt;&lt; endl;} 程序运行的输出结果如下： 123030 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"C++ 入门基础之一","url":"/posts/8bbc3f09.html","text":"大纲 C++ 入门基础之一、C++ 入门基础之二、C++ 入门基础之三 C++ 入门基础之四、C++ 入门基础之五、C++ 入门基础之六 C++ 入门基础之七、C++ 入门基础之八、C++ 入门基础之九 C++ 简介简介： C++ 被认为是一种中级语言，它综合了高级语言和低级语言的特点。 C++ 是 C 的一个超集，事实上，任何合法的 C 程序都是合法的 C++ 程序。 C++ 是一种静态类型的、编译式的、通用的、大小写敏感的、不规则的编程语言，支持过程化编程、面向对象编程和泛型编程。 C++ 是由 Bjarne Stroustrup 于 1979 年在新泽西州美利山贝尔实验室开始设计开发的。C++ 进一步扩充和完善了 C 语言，最初命名为带类的 C，后来在 1983 年更名为 C++。 注意：使用静态类型的编程语言是在编译时执行类型检查，而不是在运行时执行类型检查。 ANSI 标准： ANSI 标准是为了确保 C++ 的便携性 —— 您所编写的代码在 Mac、UNIX、Windows、Alpha 计算机上都能通过编译。由于 ANSI 标准已稳定使用了很长的时间，所有主要的 C++ 编译器的制造商都支持 ANSI 标准。 标准 C++ 的三大组成部分： 核心语言，提供了所有构件块，包括变量、数据类型和常量等。 C++ 标准库，提供了大量的函数，用于操作文件、字符串等。 标准模板库（STL），提供了大量的方法，用于操作数据结构等。 第一个 C++ 程序12345678910111213// 包含C++的头文件#include &lt;iostream&gt;// 使用命名空间 std（标准的命名空间），在这个命名空间中定义了很多 C++ 的标准定义using namespace std;int main() { // cout: 标准输出 // endl: 换行符号，类似 \"\\n\" // &lt;&lt; 左移操作符: 在C++里面，属于功能的改造（增强），即 C++ 语言的操作符重载 cout &lt;&lt; \"hello world\" &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 1hello world 关于 endl 与 \\n 的区别： 在 C++ 中，终端输出换行时，用 cout &lt;&lt; ... &lt;&lt; endl 与 \\n 都可以，但二者有小小的区别，用 endl 时会刷新缓冲区，使得栈中的东西刷新一次；但用 \\n 则不会刷新，它只会换行，栈内的数据没有变化。一般情况，二者的这点区别是很小的，在大型的程序中可能会用到，建议用 endl 来换行。 endl 除了写入 \\n 之外，还会调用 flush 函数来刷新缓冲区，将缓冲区里的数据写入文件或屏幕，若考虑效率则可以直接使用 \\n cout &lt;&lt; endl; 等价于 cout &lt;&lt; '\\n' &lt;&lt; flush; 程序设计方法介绍面向过程的程序设计方法设计思路 面向过程的结构化程序设计方法，自顶向下、逐步求精。采用模块分解与功能抽象，自顶向下、分而治之。 程序结构 按功能划分为若干个基本模块，形成一个树状结构。 各模块间的关系尽可能简单，功能上相对独立；每一模块内部均是由顺序、选择和循环三种基本结构组成。 其模块化实现的具体方法是使用子程序。 优缺点 优点: 有效地将一个较复杂的程序系统设计任务分解成许多易于控制和处理的子任务，便于开发和维护。 缺点: 可重用性差、数据安全性差、难以开发大型软件和图形界面的应用软件 把数据和处理数据的过程分离为相互独立的实体。 当数据结构改变时，所有相关的处理过程都要进行相应的修改。 每一种相对于老问题的新方法都要带来额外的开销。 图形用户界面的应用程序，很难用过程来描述和实现，开发和维护也都很困难。 面向对象的程序设计方法C++ 完全支持面向对象的程序设计，包括面向对象开发的四大特性： 封装、抽象、继承、多态，更多特性如下： 将数据及对数据的操作方法封装在一起，作为一个相互依存、不可分离的整体（对象）。 对同类型对象抽象出其共性，形成类。 类通过一个简单的外部接口，与外界发生关系。 对象与对象之间通过消息进行通信。 面向对象的软件工程概述面向对象的软件工程是面向对象方法在软件工程领域的全面应用，分别包括: 面向对象的分析（OOA） 面向对象的设计（OOD） 面向对象的编程（OOP） 面向对象的测试（OOT） 面向对象的软件维护（OOSM） 面向过程程序设计：数据结构 + 算法，主要用于解决科学计算问题，用户需求简单而固定，其特点和劣势如下： 特点： 分析解决问题所需要的步骤 利用函数实现各个步骤 依次调用函数解决问题 劣势： 软件可重用性差 软件可维护性差 构建的软件无法满足用户需求 面向对象程序设计：由现实世界建立软件模型，将现实世界中的事物直接映射到程序中，可直接满足用户需求，其特点和优势如下： 特点： 直接分析用户需求中涉及的各个实体 在代码中描述现实世界中的实体 在代码中关联各个实体协同工作解决问题 优势： 构建的软件能够适应用户需求的不断变化 直接利用面向过程方法的优势而避开其劣势 计算圆形的面积面向过程的写法1234567891011121314#include &lt;iostream&gt;using namespace std;int main() { double r = 0; // 圆形的半径 double s = 0; // 圆形的面积 cout &lt;&lt; \"请输入圆形的半径：\"; cin &gt;&gt; r; s = 3.14 * r * r; cout &lt;&lt; \"圆形的面积是：\" &lt;&lt; s &lt;&lt; endl; return 0;} 面向对象的写法123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Circle {public: double m_r; // 圆形的半径 double m_s; // 圆形的面积public: void setR(double r) { m_r = r; } double getR() { return m_r; } double getS() { m_s = 3.14 * m_r * m_r; return m_s; }};int main() { double r; cout &lt;&lt; \"请输入圆形的半径：\"; cin &gt;&gt; r; Circle circle; circle.setR(r); cout &lt;&lt; \"圆形的面积是：\" &lt;&lt; circle.getS() &lt;&lt; endl; return 0;} C++ 基础概念命名空间所谓 namespace，是指标识符的各种可见范围。C++ 标准程序库中的所有标识符都被定义于一个名为 std 的 namespace 中。&lt;iostream&gt; 和 &lt;iostream.h&gt; 格式是不一样的，前者没有后缀，实际上在编译器 include 文件夹里面可以看到，二者是两个文件，打开文件就会发现，里面的代码是不一样的。后缀为 .h 的头文件 C++ 标准已经明确提出不再支持了，早些的实现将标准库功能定义在全局命名空间里，即声明在带 .h 后缀的头文件里；C++ 标准为了和 C 区别开，也为了正确使用命名空间，规定头文件不再使用后缀 .h。 &lt;iostream.h&gt; 与 &lt;iostream&gt; 的区别： 当使用 &lt;iostream.h&gt; 时，相当于在 C 中调用库函数，使用的是全局命名空间，也就是早期的 C++ 实现 当使用 &lt;iostream&gt; 的时候，该头文件没有定义在全局命名空间，必须使用 using namespace std; 这样才能正确使用 cout 等关键字 由于 namespace 的概念，使用 C++ 标准程序库的任何标识符时，可以有以下三种写法可选择： 直接指定标识符：例如 std::ostream 而不是 ostream，完整语句为： std::cout &lt;&lt; std::hex &lt;&lt; 3.4 &lt;&lt; std::endl; 使用 using 关键字：using std::cout; using std::endl; using std::cin;，以上语句可以写成 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl; 使用 using namespace std：这种写法是最方便的，例如： using namespace std;，以上语句可以写成 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl; 命名空间 std 内定义的所有标识符都有效（曝光），就好像它们被声明为全局变量一样，那么以上语句就可以这样写 cout &lt;&lt; hex &lt;&lt; 3.4 &lt;&lt; endl;。因为标准库非常的庞大，所以程序员在选择的类的名称或函数名时就很有可能和标准库中的某个名字相同。因此为了避免这种情况所造成的名字冲突，就把标准库中的一切都被放在名字空间 std 中。但这又会带来了一个新问题，无数原有的 C++ 代码都依赖于使用了多年的伪标准库中的功能，它们都是在全局命名空间下的。所以就有了 &lt;iostream.h&gt; 和 &lt;iostream&gt; 等等这样的头文件，一个是为了兼容以前的 C++ 代码，另一个是为了支持新的标准。命名空间 std 封装的是标准程序库的名称，标准程序库为了和以前的头文件区别，一般不加后缀 .h。 命名空间定义及使用语法在 C++ 中，名称（name）可以是符号常量、变量、宏、函数、结构、枚举、类和对象等等。为了避免在大规模程序的设计中，以及在程序员使用各种各样的 C++ 库时，这些标识符的命名发生冲突，标准 C++ 引入了关键字 namespace（命名空间 / 名字空间 / 名称空间 / 名域），这样就可以更好地控制标识符的作用域。std 是 C++ 标准命名空间，C++ 标准程序库中的所有标识符都被定义在 std 中，比如标准库中的类 iostream、vector 等都定义在该命名空间中，使用时要加上 using 声明（如 using namespace std) 或者 using 指示（如 std::string、std::vector&lt;int&gt;）。 C 语言中的命名空间： 标识符之间可能发生冲突 在 C 语言中只有一个全局作用域 C 语言中所有的全局标识符共享同一个作用域 C++ 中的命名空间： 命名空间可以相互嵌套定义 全局作用域也叫默认命名空间 命名空间将全局作用域分成不同的部分 不同命名空间中的标识符可以同名而不会发生冲突 C++ 命名空间定义及使用语法： 命名空间定义的语法：namespace name { … } 命名空间使用的语法：using namespace name; 使用特定命名空间中的变量：using name::variable; 使用默认命名空间中的变量：::variable 默认情况下可以直接使用默认命名空间中的所有标识符 命名空间编程实战1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;using namespace std;// 定义命名空间 NameSpaceAnamespace NameSpaceA { int a = 0;}// 定义命名空间 NameSpaceBnamespace NameSpaceB { int a = 1; // 嵌套定义命名空间 NameSpaceC namespace NameSpaceC { struct Teacher { char name[10]; int age; }; }}int main() { // 声明 std 命名空间后的写法 cout &lt;&lt; \"hello world\" &lt;&lt; endl; // 不声明 std 命名空间后的写法 std::cout &lt;&lt; \"hello world\" &lt;&lt; std::endl; // 声明 NameSpaceA 命名空间 using namespace NameSpaceA; // 使用 NameSpaceC 命名空间中的变量 using NameSpaceB::NameSpaceC::Teacher; printf(\"a = %d\\n\", a); printf(\"a = %d\\n\", NameSpaceB::a); Teacher teacher = {\"Jim\", 20}; printf(\"teacher.age = %d\\n\", teacher.age); printf(\"teacher.name = %s\\n\", teacher.name); return 0;} 程序运行的输出结果如下： 123456hello worldhello worlda = 0a = 1teacher.age = 20teacher.name = Jim C 语言和 C++ 的关系C 语言是在实践的过程中逐步完善起来的，没有深思熟虑的设计过程，使用时存在很多 灰色地带，残留了过多低级语言的特征，直接利用指针进行内存操作，其最终目标是程序执行效率的高效。当面向过程方法论暴露越来越多的缺陷的时候，业界开始考虑在工程项目中引入面向对象的设计方法，而第一个需要解决的问题就是：高效的面向对象语言，并且能够兼容已经存在的代码。C 语言和 C++ 语言的关系如下： C 语言和 C++ 并不是对立的竞争关系 C++ 是 C 语言的加强，是一种更好的 C 语言 C++ 是以 C 语言为基础的，并且完全兼容 C 语言的特性 C 语言 + 面向对象方法论 —&gt; C++ / Objective C C++ 对 C 语言的增强实用性增强C 语言中的变量都必须在作用域开始的位置定义，而 C++ 中更强调语言的 实用性，所有的变量都可以在需要使用时再定义。 1234567int main(int argc, char *argv[]){ int a = 0; printf(\"hello world\\n\"); int b = 13; // C语言编译器中编译报错，但是C++编译器中不会报错 return 0;} 变量检测增强在 C 语言中，重复定义多个同名的全局变量是合法的，但在 C++ 中，不允许定义多个同名的全局变量。C 语言中多个同名的全局变量最终会被链接到全局数据区的同一个地址空间上。 12int g_var;int g_var = 1; // C++直接拒绝这种二义性的做法 struct 类型的增强C 语言的 struct 定义了一组变量的集合，C 编译器并不认为这是一种新的类型，而在 C++ 中的 struct 是一个新类型的定义声明。 123456789101112struct Student{ char name[100]; int age;};int main(int argc, char *argv[]){ Student s1 = {\"wang\", 1}; // C语言编译器编译报错，C++编译器编译通过 struct Student s2 = {\"chen\", 1}; // C语言编译器编译通过 return 0;} register 关键字增强register 是运行速度最快的关键字，其作用是请求编译器尽可能地将变量存在 CPU 内部的寄存器中，而不是通过内存寻址访问，以提高程序运行效率。注意这里是尽可能，不是绝对。首先，register 变量必须是能被 CPU 所接受的类型，这通常意味着 register 变量必须是一个单个的值，并且长度应该小于或者等于整型的长度。不过，有些机器的寄存器也能存放浮点数。C 语言中，register 关键字表示 “请求”（不一定成功）让变量直接放进寄存器中，方便访问，但是在 C 语言中不能取 register 变量的地址。C++ 对 register 进行了增强，C++ 编译器会对频繁被调用的变量主动申请为 register，即使没有用 register 关键字声明，它也会这样做。值得一提的是，C++ 编译器当发现程序中需要对 register 变量取地址时，register 对变量的声明会变得无效。 123456int main(int argc, char *argv[]){ register int a = 0; printf(\"&amp;a = %x\\n\", &amp;a); return 0;} 由于寄存器的数量有限，而且某些寄存器只能接收特定类型的数据（如指针和浮点数），因此真正起作用的 register 修饰符的数目和类型都依赖于实际运行程序的机器，而任何多余的 register 修饰符都将被编译器所忽略。在某些情况下，把变量保存在寄存器中反而会降低程序的运行速度，这因为被占用的寄存器不能再用于其它用途；或者变量被使用的次数不够多，不足以抵消装入和存储变量所带来的额外开销。早期的 C 编译器不会自动把变量保存在寄存器中，除非程序员命令它这样做，这时 register 修饰符是 C 语言的一种很有价值的补充。然而，随着编译程序设计技术的进步，在决定哪些变量应该被存到寄存器中时，现代的 C 编译器能比程序员做出更好的决定。实际上，许多编译器都会忽略 register 修饰符，尽管它完全合法，但它仅仅是暗示而不是命令。 作用域限定运算符作用域限定运算符，用于对当前作用域之外的同名变量进行访问，例如在下面的例子中，可以利用 :: 实现在局部变量 a 的作用域内对全局变量 a 的访问。 1234567891011121314#include &lt;iostream&gt;using namespace std;int a;int main() { float a; a = 3.14; ::a = 6; cout &lt;&lt; \"local variable a = \" &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; \"global variable a = \" &lt;&lt; ::a &lt;&lt; endl; return 0;} 程序运行的输出结果如下： 12local variable a = 3.14global variable a = 6 新增 Bool 类型关键字C++ 在 C 语言的基本类型系统之上增加了 bool 类型关键字，bool 可取的值只有 true 和 false。理论上 bool 变量只占用一个字节，如果多个 bool 变量定义在一起，可能会各占一个 bit（位），这取决于编译器的实现。true 代表真值，编译器内部用 1 来表示，false 代表非真值，编译器内部用 0 来表示。C++ 编译器会在赋值时将非 0 值转换为 true，0 值转换为 false。 1234567int main(int argc, char *argv[]){ int a; bool b = true; printf(\"b = %d, sizeof(b) = %d\\n\", b, sizeof(b)); return 0;} 程序运行的输出结果如下： 1b = 1, sizeof(b) = 1 三目运算符功能增强12345678910int main(int argc, char *argv[]) int a = 10; int b = 20; // 返回一个最小数，并且给最小数赋值成30 // C 语言中三目运算符是一个表达式 ，表达式不可以做左值，而 C++ 则可以 (a &lt; b ? a : b) = 30; printf(\"a = %d, b = %d\\n\", a, b); return 0;} 程序运行的结果如下： 1a = 30, b = 20 使用三目运算符时，C 语言返回变量的值，C++ 是返回变量本身 C 语言中的三目运算符返回的是变量值，不能作为左值使用 C++ 中的三目运算符可直接返回变量本身，因此可以出现在程序的任何地方 特别注意：C++ 中三目运算符可能返回的值中如果有一个是常量值，则不能作为左值使用，例如 (a &lt; b ? 1 : b )= 30; C 语言如何支持类似 C++ 的三目运算特性呢？当左值的条件：要有内存空间，而 C++ 编译器只是帮助程序员取了一个地址而已，C 语言版的写法为：*(a &lt; b ? &amp;a : &amp;b) = 30 所有的变量和函数都必须声明类型 C 语言默认数据类型在 C++ 编译器中是不合法的，C++ 中所有变量和函数必须声明类型。以下代码在 C 语言中能编译通过，但在 C++ 中会编译报错。 1234567891011121314151617f(i){ printf(\"i = %d\\n\", i);}g(){ return 5;}int main(int argc, char *argv[]){ f(10); printf(\"g() = %d\\n\", g(1, 2, 3, 4, 5)); getchar(); return 0;} 在 C 语言中，int f() 表示返回值为 int，接受任意参数的函数 在 C 语言中，int f(void) 表示返回值为 int 的无参函数 在 C++ 中，int f() 和 int f(void) 具有相同的意义，都表示返回值为 int 的无参函数 C++ 更加强调类型，任意的程序元素都必须显示指明类型 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++"},{"title":"VsCode 入门教程之二打造 Markdown 编辑器","url":"/posts/3baa0a8d.html","text":"常用插件文件图标主题 Material Icon Theme，一款非常漂亮的文件图标主题 自动隐藏侧边栏 Auto Hide，支持自动隐藏侧边栏 Markdown 插件Markdown 预览 Markdown Preview Mermaid Support，实时预览 Mermaid 绘图 Markdown Preview Enhanced，支持 Markdown 实时预览等各种强大的功能 Markdown 快捷键 Markdown Shortcuts，支持各种 Markdown 快捷键 Markdown 表格插入 MarkDown Table Format，支持使用快捷键全局格式化 Markdown 表格 Markdown Table，快速插入 Markdown 表格，支持表格自动格式化和自动插入行 Markdown 文档导出 Markdown PDF，Markdown 文档转 PDF 文档 Markdown 语法高亮 Mermaid Markdown Syntax Highlighting，支持 Mermaid 绘图的语法高亮 Markdown 图片粘贴 Markdown QiNiu，支持将粘贴板里的图片上传到七牛图床 Markdown Paste，支持将粘贴板里的图片保存到本地，并将图片的链接自动加入到 Markdown 文档中 Markdown 功能大全 Markdown All in One，提供了许多有用的功能，使得在 VS Code 中编写 Markdown 文档变得更加容易和高效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"VsCode 入门教程之一基础使用","url":"/posts/879c28df.html","text":"常用插件文件图标主题 vscode-icons Material Icon Theme 自动隐藏侧边栏 Auto Hide 自动更新关闭 VsCode 自动更新方法一： 打开菜单 File 中 Preferences 子菜单中选择 Settings 项，搜索 update mode，将其设置为 none，如下图所示： 方法二： 打开 查看（View）菜单，选择 命令面板（Command Palette） 菜单项或者使用（Ctrl + Shift + P）快捷键打开命令面板。 在命令面板中，输入 Preferences: Open Settings (JSON)，打开用户配置 JSON 的编辑界面，添加配置内容 \"update.mode\": \"none\"。 关闭 VsCode 自动更新插件方法一： 打开菜单 File 中 Preferences 子菜单中选择 Settings 项，搜索 Extensions: Auto Update，取消复选框的选中状态，如下图所示： 方法二： 打开 查看（View）菜单，选择 命令面板（Command Palette） 菜单项或者使用（Ctrl + Shift + P）快捷键打开命令面板。 在命令面板中，输入 Preferences: Open Settings (JSON)，打开用户配置 JSON 编辑界面，添加配置内容 \"extensions.autoUpdate\": false。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Linux 安装 VS Code","url":"/posts/d8f0998b.html","text":"前言本文适用于 Debian/Ubuntu、RHEL/Fedora/CentOS、openSUSE/SLE-based、Arch 等 Linux 发行版。 VS Code 安装Debian / Ubuntu 安装软件仓库源和密钥 1234$ wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor &gt; packages.microsoft.gpg$ sudo install -o root -g root -m 644 packages.microsoft.gpg /etc/apt/trusted.gpg.d/$ sudo sh -c 'echo \"deb [arch=amd64,arm64,armhf signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main\" &gt; /etc/apt/sources.list.d/vscode.list'$ rm -f packages.microsoft.gpg 更新安装包缓存，并安装 VS Code 123$ sudo apt install apt-transport-https$ sudo apt update$ sudo apt install code RHEL/Fedora/CentOS 安装软件仓库源和密钥 12$ sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc$ sudo sh -c 'echo -e \"[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc\" &gt; /etc/yum.repos.d/vscode.repo' 更新安装包缓存，并使用 dnf（Fedora 22 及更高版本） 安装 VS Code 12$ sudo dnf check-update$ sudo dnf install code 或者在旧版本的 CentOS 上使用 yum 安装 VS Code 12$ sudo yum check-update$ sudo yum install code 若 VS Code 成功安装后，在系统的应用菜单栏里找不到快捷启动方式，那么可以通过按下 Alt + F2 快捷键，然后输入 r 重启系统界面；然后导航到应用菜单栏：应用程序 –&gt; 编程 –&gt; Visual Studio Code，双击快捷启动方式的图标即可启动 VS Code。 openSUSE/SLE-based 安装软件仓库源和密钥 12$ sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc$ sudo sh -c 'echo -e \"[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ntype=rpm-md\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc\" &gt; /etc/zypp/repos.d/vscode.repo' 更新安装包缓存，并安装 VS Code 12$ sudo zypper refresh$ sudo zypper install code ArchVS Code 有一个社区维护的 Arch 用户存储库包，要从 AUR 获取有关安装的更多信息，请参阅以下 WiKi 条目： 安装 AUR 包。 Snap通过 Snap 安装 VS Code，此安装方式适用于 RHEL 系、Debian 系、 openSUSE 系等大多数主流的 Linux 发行版，Snap 的安装和使用可参考 本站教程。VS Code 成功安装后，Snap 的守护进程将负责在后台自动更新 VS Code，每当有新的更新可用时，都会自动下载并安装最新版本的 VS Code。 12345$ sudo snap install --classic code或者$ sudo snap install --classic code-insiders VS Code 设置字体 下载字体 12$ cd /usr/share/fonts/truetype/$ git clone https://github.com/abertsch/Menlo-for-Powerline.git 刷新字体 1$ fc-cache -f -v 设置字体 或者编辑 VS Code 的 setting.json 配置文件，在其中加入以下配置内容： 1\"editor.fontFamily\": \"'Menlo for Powerline'\" 重启 VS Code，让字体更改生效 VS Code 版本更新VS Code 每月发布一次，可以通过查看发行日志了解何时有新版本可用。如果 VS Code 软件仓库源安装正确，那么 VS Code 应该会与系统上的其他软件包以相同的方式自动更新。值得一提的是，由于受限于手动签名过程和官方用于发布的系统，yum repo 可能会滞后并且无法立即获取到最新版本的 VS Code。 参考资料 Linux 安装 VS Code 官方教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux 开发工具"},{"title":"C++ 开发随笔","url":"/posts/4ca3ab6c.html","text":"构建工具CMake 无法引入第三方库的头文件这里以 GoogleTest 库为例子，讲述 CMake 为什么无法正常引入项目里的第三方库的头文件，其中 GoogleTest 库在项目里的目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869minder├── CMakeLists.txt├── include├── src└── thirdparty └── googletest ├── gmock │ ├── include │ │ └── gmock │ │ ├── gmock-actions.h │ │ ├── gmock-cardinalities.h │ │ ├── gmock-function-mocker.h │ │ ├── gmock-generated-actions.h │ │ ├── gmock-generated-actions.h.pump │ │ ├── gmock-generated-function-mockers.h │ │ ├── gmock-generated-function-mockers.h.pump │ │ ├── gmock-generated-matchers.h │ │ ├── gmock-generated-matchers.h.pump │ │ ├── gmock.h │ │ ├── gmock-matchers.h │ │ ├── gmock-more-actions.h │ │ ├── gmock-more-matchers.h │ │ ├── gmock-nice-strict.h │ │ ├── gmock-spec-builders.h │ │ └── internal │ │ ├── custom │ │ │ ├── gmock-generated-actions.h │ │ │ ├── gmock-generated-actions.h.pump │ │ │ ├── gmock-matchers.h │ │ │ ├── gmock-port.h │ │ │ └── README.md │ │ ├── gmock-internal-utils.h │ │ ├── gmock-port.h │ │ └── gmock-pp.h │ └── lib │ ├── libgmock_main.so │ └── libgmock.so └── gtest ├── include │ └── gtest │ ├── gtest-death-test.h │ ├── gtest.h │ ├── gtest-matchers.h │ ├── gtest-message.h │ ├── gtest-param-test.h │ ├── gtest_pred_impl.h │ ├── gtest-printers.h │ ├── gtest_prod.h │ ├── gtest-spi.h │ ├── gtest-test-part.h │ ├── gtest-typed-test.h │ └── internal │ ├── custom │ │ ├── gtest.h │ │ ├── gtest-port.h │ │ ├── gtest-printers.h │ │ └── README.md │ ├── gtest-death-test-internal.h │ ├── gtest-filepath.h │ ├── gtest-internal.h │ ├── gtest-param-util.h │ ├── gtest-port-arch.h │ ├── gtest-port.h │ ├── gtest-string.h │ ├── gtest-type-util.h │ └── gtest-type-util.h.pump └── lib ├── libgtest_main.so └── libgtest.so 特别注意 在上面的项目结构中，gtest 的头文件所在的目录是 thirdparty/googletest/gtest/include/gtest/，而不是 thirdparty/googletest/gtest/include/。因此在 C++ 源文件中引入 gtest 头文件的正确写法是 #include &lt;gtest/gtest.h&gt;，即头文件的路径是 include 目录下的 gtest/gtest.h。这一点必须注意，否则会经常导致 CMake 无法正常引入第三方库的头文件。简单一句话概况，如果在 C++ 源文件中，头文件的引入方式是 #include &lt;gtest/gtest.h&gt;，那么在项目里的第三方库的 include 目录下必然要有一个 gtest 子目录。 C++ 的示例代码 1234567891011121314#include &lt;iostream&gt;#include &lt;gtest/gtest.h&gt;using namespace std;TEST( COutputPopLimitStrategyTest, PositiveNos ){ EXPECT_EQ(true, true);}int main(int argc, char **argv) { testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();} CMake 的示例配置 123456789101112131415# 定义 GoogleTest 库的目录路径set(PATH_TO_GOOGLE_TEST thirdparty/googletest/gtest)set(PATH_TO_GOOGLE_MOCK thirdparty/googletest/gmock)# 引入 GoogleTest 库的头文件include_directories(${PATH_TO_GOOGLE_TEST}/include ${PATH_TO_GOOGLE_MOCK}/include)# 指定 GoogleTest 动态链接库所在的目录link_directories(${PATH_TO_GOOGLE_TEST}/lib ${PATH_TO_GOOGLE_MOCK}/lib)# 指定编译参数set(CMAKE_CXX_FLAGS \"-lpthread\")# 链接 GoogleTest 的动态链接库target_link_libraries(${PROJECT_NAME} gtest_main.so gtest.so gmock_main.so gmock.so) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ 开发随笔"},{"title":"Hexo NexT 主题渲染 Mermaid 绘图","url":"/posts/e6e0cad5.html","text":"版本说明 Hexo 5.4.0 NexT 8.8.1 NexT 渲染 Mermaid 绘图安装 Hexo 插件在博客的根目录下，执行以下命令安装 hexo-filter-mermaid-diagrams 插件 1$ npm install hexo-filter-mermaid-diagrams --save NexT 启用 Mermaid打开 NexT 主题的 _config.yml 配置文件，找到 mermaid 的配置项，并设置 enable: true，如下所示： 1234567# Mermaid tagmermaid: enable: true # Available themes: default | dark | forest | neutral theme: light: default dark: dark Hexo 重新编译构建执行以下命令，重新执行 Hexo 的编译构建操作，并启动 Hexo-Server 的预览服务，若 Mermaid 的绘图正常显示，则说明 Mermaid 成功被渲染。 1$ hexo clean &amp;&amp; hexo generate &amp;&amp; hexo server Hexo 插件的使用Hexo 插件 hexo-filter-mermaid-diagrams 的官方文档说明可以看这里。 语法说明值得一提的是，有一些 Markdown 的编辑工具，比如在 Cmd Markdown 里，Mermaid 的使用语法是这样的： 但 hexo-filter-mermaid-diagrams 这款插件的使用语法略有不同： sequence、graph TD 等 Mermaid Diagram 的具体类型必须写在第一行的内容里 三个点后面要写的是 mermaid，而不是 sequence、graph TD 等 Mermaid Diagram 的具体类型 使用示例流程图1234567graph TB id1(圆角矩形)--普通线--&gt;id2[矩形]; subgraph 子图 id2==粗线==&gt;id3{菱形} id3-.虚线.-&gt;id4&gt;右向旗帜] id3--无箭头---id5((圆形)) end graph TB id1(圆角矩形)--普通线--&gt;id2[矩形]; subgraph 子图 id2==粗线==&gt;id3{菱形} id3-.虚线.-&gt;id4&gt;右向旗帜] id3--无箭头---id5((圆形)) end 时序图12345678910sequenceDiagramAlice-&gt;&gt;John: Hello John, how are you?loop Healthcheck John-&gt;&gt;John: Fight against hypochondriaendNote right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob : How about you? Bob--&gt;&gt;John : Jolly good! sequenceDiagram Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob : How about you? Bob--&gt;&gt;John : Jolly good! 甘特图12345678ganttsection Section Completed: done, des1, 2014-01-06, 2014-01-08 Active : active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d gantt section Section Completed: done, des1, 2014-01-06, 2014-01-08 Active : active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d 饼图123456pie title Key elements in Product X \"Calcium\" : 42.96 \"Potassium\" : 50.05 \"Magnesium\" : 10.01 \"Iron\" : 5 pie title Key elements in Product X \"Calcium\" : 42.96 \"Potassium\" : 50.05 \"Magnesium\" : 10.01 \"Iron\" : 5 类别图123456789101112131415161718192021classDiagram Animal &lt;|-- Duck Animal &lt;|-- Fish Animal &lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } classDiagram Animal &lt;|-- Duck Animal &lt;|-- Fish Animal &lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } 状态图12345678910111213141516stateDiagram [*]--&gt;Active state Active { [*]--&gt;NumLockOff NumLockOff--&gt;NumLockOn : EvNumLockPressed NumLockOn--&gt;NumLockOff : EvNumLockPressed -- [*]--&gt;CapsLockOff CapsLockOff--&gt;CapsLockOn : EvCapsLockPressed CapsLockOn--&gt;CapsLockOff : EvCapsLockPressed -- [*]--&gt;ScrollLockOff ScrollLockOff--&gt;ScrollLockOn : EvCapsLockPressed ScrollLockOn--&gt;ScrollLockOff : EvCapsLockPressed } stateDiagram [*]--&gt;Active state Active { [*]--&gt;NumLockOff NumLockOff--&gt;NumLockOn : EvNumLockPressed NumLockOn--&gt;NumLockOff : EvNumLockPressed -- [*]--&gt;CapsLockOff CapsLockOff--&gt;CapsLockOn : EvCapsLockPressed CapsLockOn--&gt;CapsLockOff : EvCapsLockPressed -- [*]--&gt;ScrollLockOff ScrollLockOff--&gt;ScrollLockOn : EvCapsLockPressed ScrollLockOn--&gt;ScrollLockOff : EvCapsLockPressed } 实体关系图1234erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses 参考资料 mermaid-js 官方文档 hexo-filter-mermaid-diagrams 插件的官方文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"Shell 编程常用代码块之一","url":"/posts/d9ceba01.html","text":"日志定义日志的颜色123456789101112131415161718192021222324252627282930313233#!/bin/bash_COLORS=${BS_COLORS:-$(tput colors 2&gt;/dev/null || echo 0)}__detect_color_support() { if [ $? -eq 0 ] &amp;&amp; [ \"$_COLORS\" -gt 2 ]; then RC='\\033[1;31m' GC='\\033[1;32m' BC='\\033[1;34m' YC='\\033[1;33m' EC='\\033[0m' else RC=\"\" GC=\"\" BC=\"\" YC=\"\" EC=\"\" fi}__detect_color_supportechoerror() { printf \"${RC} * ERROR${EC}: %s\\\\n\" \"$@\" 1&gt;&amp;2;}echoinfo() { printf \"${GC} * INFO${EC}: %s\\\\n\" \"$@\";}echowarn() { printf \"${YC} * WARN${EC}: %s\\\\n\" \"$@\";}# 使用示例echoinfo \"Hello World\"echowarn \"Hello World\"echoerror \"Hello World\" 常见的条件判断判断目录是否存在123456789#!/bin/bashLOGS_PATH=\"/tmp/logs/blog\"if [ ! -d \"$LOGS_PATH\" ]; then echo \"目录不存在\"else echo \"目录已存在\"fi 判断操作系统类型1234567891011#!/bin/bash_OS_LINUX=\"Linux\"_OS_INFO=`uname -a`if [[ $_OS_INFO =~ $_OS_LINUX ]]then echo \"Linux 操作系统\"else echo \"非 Linux 操作系统\"fi 判断是否为 Root 用户12345#!/bin/bashif [ $UID -ne 0 ]; then echo \"非 Root 用户!\"fi 执行脚本执行指定的 Shell 脚本文件使用 Linux 命令，执行指定的 Shell 脚本文件 1sh date.sh 执行指定的 Shell 脚本内容使用 Linux 命令，执行指定的 Shell 脚本内容 1sh -c \"echo 现在的时间：`date '+%Y-%m-%d %H:%M:%S'`\" 获取 Linux 命令的执行结果1234#!/bin/bashdate_str=$(date)echo $date_str 执行字符串里的 Shell 脚本内容1234#!/bin/bashUPDATE_SYSTEM_DYNAMIC_LIBS=0echo \"### 是否更新系统的动态链接库: `[[ $UPDATE_SYSTEM_DYNAMIC_LIBS -eq 1 ]] &amp;&amp; echo '是' || echo '否'`\" 程序运行状态获取应用的进程数12345678#!/bin/bash# 应用的名称program_name=\"dockerd\"# 精确统计应用正在运行的进程数量count=`ps -aux | grep -w \"$program_name\" | grep -v grep | wc -l`echo $count 获取应用的进程 ID12345678910111213141516#!/bin/bash# 应用的名称program_name=\"dockerd\"# 精确获取应用正在运行的进程ID（应用同时运行了多个实例时，会有多个值，返回数组）process_ids=`ps -aux | grep -w \"$program_name\" | grep -v grep | awk '{print $2}'`# 判断进程ID是否为空if [ ! -n \"$process_ids\" ]; then echo \"$program_name 没有运行\"else # 数组转字符串 process_ids_str=`echo $process_ids` echo \"$program_name 已经有实例正在运行，PID 是 ${process_ids_str/ /, }\" fi 日期处理判断是否为周末1234567#!/bin/bashif [[ $(date +%u) -gt 5 ]]; then echo \"今天是周末\"else echo \"今天不是周末\"fi 判断今天是星期几12345#!/bin/bash# 值的范围是1 ~ 7，其中 1 表示星期一DOW=$(date +%u)echo $DOW 文件处理读取 ini 配置文件提示 ini 配置文件的格式介绍，可以参考这里 ini 配置文件的后缀名不一定必须是 .ini，也可以是 .cfg、.conf 或者是 .txt。 config.ini 配置文件的内容 12345[Server1]ip = 127.0.0.1[Server2]ip = 192.168.1.1 example.sh 脚本的内容 1234567891011function __readINI() { INIFILE=$1; SECTION=$2; ITEM=$3 _readContent=`awk -F '=' '/\\['$SECTION'\\]/{a=1}a==1&amp;&amp;$1~/'$ITEM'/{print $2;exit}' $INIFILE` echo ${_readContent}}_IP1=( $( __readINI config.ini Server1 ip ) )_IP2=( $( __readINI config.ini Server2 ip ) )echo ${_IP1}echo ${_IP2} 脚本执行后输出的结果 12127.0.0.1192.168.1.1 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux系统编程 代码块"},{"title":"MyBatis 源码分析","url":"/posts/9a55ed5d.html","text":"","tags":"在线电子书"},{"title":"C++ 开发知识图谱 (最新)","url":"/posts/87f5b84d.html","text":"C++ 基础知识 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"知识图谱"},{"title":"CSS 开发随笔","url":"/posts/7562a9f6.html","text":"移动端适配隐藏或显示页面内容有些页面内容适合在 PC 端显示，但是不适合在移动端显示（比如盒子过大，遮挡内容）或者在移动端显示毫无意义等，此时可以使用下面的 CSS 代码来实现：PC 端显示，移动端隐藏 1234567&lt;body&gt; &lt;div class=\"wapnone\"&gt;移动端要判断隐藏的内容&lt;/div&gt; &lt;div class=\"tool_cai\"&gt;移动端要判断隐藏的内容&lt;/div&gt; &lt;div class=\"tool_code\"&gt;移动端要判断隐藏的内容&lt;/div&gt; &lt;div class=\"tool_zan\"&gt;移动端要判断隐藏的内容&lt;/div&gt; &lt;div id=\"player\"&gt;移动端要判断隐藏的内容&lt;/div&gt;&lt;/body&gt; 1234567891011121314151617181920/* 调用单个class */@media screen and (max-width: 1221px) { .wapnone { display: none; }}/* 调用多个class */@media screen and (max-width: 1221px) { .tool_cai, .tool_code, .tool_zan { display: none; }}/* 调用id */@media screen and (max-width: 1221px) { #player { display: none; }} 提示 1、1221px 是屏幕的宽度，具体数值可以自行调试 2、max-width: 1221px 表示如果屏幕宽度在 1221 像素以下（移动端），则对应的 CSS 类就会生效 3、同理的，min-width: 1221px，表示如果屏幕宽度在 1221 像素以上（PC 端），则对应的 CSS 类就会生效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端 开发随笔"},{"title":"区块链开发知识图谱 (最新)","url":"/posts/d5d6425c.html","text":"区块链开发技术 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"知识图谱"},{"title":"Python 开发知识图谱 (最新)","url":"/posts/3c42fe19.html","text":"Python 就业方向 Python 开发技术 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"知识图谱"},{"title":"Linux 系统编程之四 C++ 多线程","url":"/posts/841eca80.html","text":"查看 pthread.h 的位置在 Linux 系统里，pthread.h 头文件的位置一般是 /usr/include/pthread.h，可以通过以下命令查看头文件的位置 1# whereis pthread.h 基于 pthread 多线程编程案例代码123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;using namespace std;void printids(const char *s) { pid_t pid = getpid(); pthread_t tid = pthread_self(); printf(\"%s pid %u tid %u (0x%x)\\n\", s, (unsigned int) pid, (unsigned int) tid, (unsigned int) tid);}void *thr_fn(void *args) { printids(\"new thread: \"); return ((void *) 0);}int main() { pthread_t ntid; int err = pthread_create(&amp;ntid, NULL, thr_fn, NULL); if (err != 0) { printf(\"can't create thread: %d\\n\", err); exit(1); } printids(\"main thread: \"); sleep(1); return 0;} 编译代码由于 pthread 不是 Linux 系统默认的库，因此链接时需要使用静态库 libpthread.a。简而言之，在使用 pthread_create() 创建线程，以及调用 pthread_atfork() 函数建立 fork 处理程序时，需要通过 -lpthread 参数链接该库，同时还需要在 C++ 源文件里添加头文件 pthread.h。 提示 为了可以正常编译使用了 pthread 的项目代码，不同构建工具的使用说明如下： 若使用 G++ 编译 C++ 项目，则编译命令的示例如下： 12# 编译代码$ g++ main.cpp -o main -lpthread 若使用 CMake 构建 C++ 项目，则 CMakeLists.txt 配置文件的示例内容如下： 123set(CMAKE_CXX_FLAGS \"-std=c++11 -lpthread\")add_executable(main main.cpp) 程序运行输出的结果如下： 12main thread: pid 6189 tid 342021952 (0x1462d740)new thread: pid 6189 tid 324765440 (0x135b8700) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ linux系统编程"},{"title":"Java 动态编译的实现","url":"/posts/b8943243.html","text":"前言本文主要介绍如何实现 Java 的动态编译，并给出快速入门案例，点击下载完整的案例代码。 快速入门编写接口12345678910package com.clay.domain;/** * @author clay */public interface Store { public void sell();} 12345678910111213package com.clay.domain;/** * @author clay */public class Supermarket implements Store { @Override public void sell() { System.out.println(\"invoke supermarket sell method\"); }} 编写工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package com.clay.loader;import javax.tools.JavaCompiler;import javax.tools.JavaFileObject;import javax.tools.StandardJavaFileManager;import javax.tools.ToolProvider;import java.io.IOException;import java.net.URL;import java.net.URLClassLoader;import java.util.*;/** * 动态加载器 * * @author clay */public class DynamicLoader { /** * 编译参数 */ private List&lt;String&gt; options = new ArrayList&lt;&gt;(); /** * 添加编译参数 * * @param key * @param value * @throws NullPointerException */ public void addOption(String key, String value) throws NullPointerException { if (key == null || key.isEmpty()) { throw new NullPointerException(\"Option key is empty\"); } options.add(key); options.add(value); } /** * 通过Java文件名和其代码，编译得到字节码，返回类名及其对应类的字节码，封装于Map中， * 值得注意的是，平常类中就编译出来的字节码只有一个类，但是考虑到内部类的情况， 会出现很多个类名及其字节码，所以用Map封装方便 * * @param javaName Java文件名，例如Student.java * @param javaCode Java源码 * @return map */ public Map&lt;String, byte[]&gt; compile(String javaName, String javaCode) { JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager stdManager = compiler.getStandardFileManager(null, null, null); try (MemoryJavaFileManager manager = new MemoryJavaFileManager(stdManager)) { JavaFileObject javaFileObject = manager.makeStringSource(javaName, javaCode); JavaCompiler.CompilationTask task = compiler.getTask(null, manager, null, options, null, Arrays.asList(javaFileObject)); if (task.call()) { return manager.getClassBytes(); } } catch (IOException e) { e.printStackTrace(); } return null; } /** * 先根据类名在内存中查找是否已存在该类，若不存在则调用URLClassLoader.defineClass()方法加载该类 * URLClassLoader的具体作用就是将Class文件加载到JVM虚拟机中 */ public static class MemoryClassLoader extends URLClassLoader { private Map&lt;String, byte[]&gt; classBytes = new HashMap&lt;String, byte[]&gt;(); public MemoryClassLoader(Map&lt;String, byte[]&gt; classBytes) { super(new URL[0], MemoryClassLoader.class.getClassLoader()); this.classBytes.putAll(classBytes); } @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { byte[] buf = this.classBytes.get(name); if (buf == null) { return super.findClass(name); } this.classBytes.remove(name); return defineClass(name, buf, 0, buf.length); } }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132package com.clay.loader;import javax.tools.*;import java.io.*;import java.net.URI;import java.nio.CharBuffer;import java.util.HashMap;import java.util.Map;/** * 将编译好的Class文件保存到内存当中，这里的内存也就是Map映射当中 * * @author clay */public final class MemoryJavaFileManager extends ForwardingJavaFileManager { /** * 用于存放Class文件的内存 */ private Map&lt;String, byte[]&gt; classBytes; /** * Java源文件的扩展名 */ private final static String EXT = \".java\"; public MemoryJavaFileManager(JavaFileManager fileManager) { super(fileManager); classBytes = new HashMap&lt;String, byte[]&gt;(); } public Map&lt;String, byte[]&gt; getClassBytes() { return classBytes; } @Override public void close() throws IOException { classBytes = new HashMap&lt;String, byte[]&gt;(); } @Override public void flush() throws IOException { } @Override public JavaFileObject getJavaFileForOutput( JavaFileManager.Location location, String className, JavaFileObject.Kind kind, FileObject sibling) throws IOException { if (kind == JavaFileObject.Kind.CLASS) { return new ClassOutputBuffer(className); } else { return super.getJavaFileForOutput(location, className, kind, sibling); } } public JavaFileObject makeStringSource(String name, String code) { return new StringInputBuffer(name, code); } public static URI toURI(String name) { File file = new File(name); if (file.exists()) { return file.toURI(); } else { try { final StringBuilder newUri = new StringBuilder(); newUri.append(\"mfm:///\"); newUri.append(name.replace('.', '/')); if (name.endsWith(EXT)) { newUri.replace(newUri.length() - EXT.length(), newUri.length(), EXT); } return URI.create(newUri.toString()); } catch (Exception exp) { return URI.create(\"mfm:///com/sun/script/java/java_source\"); } } } /** * 一个文件对象，用来表示从String中获取到的Source，以下内容是按照JDK给出的例子写的 */ private static class StringInputBuffer extends SimpleJavaFileObject { private final String code; /** * @param name 此文件对象表示的编译单元的name * @param code 此文件对象表示的编译单元source的code */ StringInputBuffer(String name, String code) { super(toURI(name), Kind.SOURCE); this.code = code; } @Override public CharBuffer getCharContent(boolean ignoreEncodingErrors) { return CharBuffer.wrap(code); } public Reader openReader() { return new StringReader(code); } } /** * 将Java字节码存储到classBytes映射中的文件对象 */ private class ClassOutputBuffer extends SimpleJavaFileObject { private String name; ClassOutputBuffer(String name) { super(toURI(name), Kind.CLASS); this.name = name; } @Override public OutputStream openOutputStream() { return new FilterOutputStream(new ByteArrayOutputStream()) { @Override public void close() throws IOException { out.close(); ByteArrayOutputStream bos = (ByteArrayOutputStream) out; // 这里可能需要修改 classBytes.put(name, bos.toByteArray()); } }; } }} 编写测试类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.clay.loader;import com.clay.domain.Store;import com.clay.domain.Supermarket;import org.springframework.util.Assert;import java.lang.reflect.Constructor;import java.util.Map;/** * @author clay */public class ProxyUtil { /** * 获取Java代码 * * @return */ public String getJavaCode() { String rt = \"\\r\\n\"; // 这里定义的Java类代码里，建议首行不要带包名，否则容易出现编译失败的问题 String code = \"import com.clay.domain.Store;\" + rt + \"public class Dealer implements Store\" + rt + \"{\" + rt + \"private Store s;\" + rt + \"public Dealer(Store s)\" + rt + \" {\" + \" this.s = s;\" + rt + \" }\" + rt + \"@Override\" + rt + \"public void sell()\" + \" {\" + rt + \"System.out.println(\\\"invoke dealer sell method\\\");\" + rt + \"s.sell();\" + rt + \" }\" + rt + \"}\"; return code; } /** * 动态编译 * * @throws Exception */ public void handle() throws Exception { String javaName = \"Dealer.java\"; // 对Java代码进行编译，并将生成Class文件存放在Map中 DynamicLoader dynamicLoader = new DynamicLoader(); Map&lt;String, byte[]&gt; bytecode = dynamicLoader.compile(javaName, getJavaCode()); // 加载字节码到虚拟机中 DynamicLoader.MemoryClassLoader classLoader = new DynamicLoader.MemoryClassLoader(bytecode); Class&lt;?&gt; clazz = classLoader.loadClass(\"Dealer\"); Assert.notNull(clazz, \"\"); // 通过反射进行调用 Constructor constructor = clazz.getConstructor(Store.class); Store store = (Store) constructor.newInstance(new Supermarket()); store.sell(); }} 123456789101112131415161718192021222324package com.clay;import com.clay.loader.ProxyUtil;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @author clay */@SpringBootApplicationpublic class ProxyApplication { public static void main(String[] args) { SpringApplication.run(ProxyApplication.class, args); try { ProxyUtil util = new ProxyUtil(); util.handle(); } catch (Exception e) { e.printStackTrace(); } }} 程序运行结果12invoke dealer sell methodinvoke supermarket sell method 常见问题动态编译时找不到第三方包的类动态编译 Java 文件时，如果这个 Java 文件引用了第三方 Jar 包里的类，那么程序运行在 IDE 工具时，则可以正常动态编译。如果程序单独运行在 Web 容器（例如 Tomcat），又或者是直接通过 java -jar xxx.jar 的命令行方式运行，那么执行动态编译时，往往就会提示找不到第三方 Jar 包里的 Class 或者 Package，导致无法正常编译生成 Class 文件或者字节码。 解决方案： 方法一：将所依赖到的第三方 Jar 文件，复制到 %JAVA_HOME%\\jre\\lib\\ext 目录下，然后再重启 Web 容器（Tomcat）或者应用，此方法不一定兼容所有 JDK 版本，且未经验证是否有效 方法二：执行动态编译时，添加 -classpath 参数来指定第三方 Jar 包的绝对路径，示例代码如下： 12345678String jars = \"/root/.m2/repository/com/clay/proxy/1.0.0/proxy-1.0.0.jar\";Iterable&lt;String&gt; options = Arrays.asList(\"-encoding\", \"UTF-8\", \"-classpath\", jars);JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();StandardJavaFileManager fileMgr = compiler.getStandardFileManager(null, null, null);Iterable units = fileMgr.getJavaFileObjects(fileName);JavaCompiler.CompilationTask task = compiler.getTask(null, fileMgr, null, options, null, units);result = task.call(); SpringBoot 找不到动态编译后的类在 SpringBoot 应用内执行动态编译时，可以正常生成 Class 文件，但往往无法直接通过 URLClassLoader 类加载 Class 文件来实例化 Java 对象，示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package com.clay.loader;import javax.tools.JavaCompiler;import javax.tools.JavaCompiler.CompilationTask;import javax.tools.StandardJavaFileManager;import javax.tools.ToolProvider;import java.io.File;import java.io.FileWriter;import java.io.IOException;import java.lang.reflect.Constructor;import java.net.URL;import java.net.URLClassLoader;public class ProxyUtil { /** * 生成文件 * * @param path * @return content */ public boolean createFile(String path, String content) { FileWriter fw = null; try { String parentPath = path.substring(0, path.lastIndexOf(\"/\")); File parentFile = new File(parentPath); if (!parentFile.exists()) { parentFile.mkdirs(); } File javaFile = new File(path); if (!javaFile.exists()) { javaFile.createNewFile(); } fw = new FileWriter(javaFile); fw.write(content); fw.flush(); return true; } catch (Exception e) { e.printStackTrace(); } finally { if (fw != null) { try { fw.close(); } catch (IOException e) { e.printStackTrace(); } } } return false; } /** * 动态编译 * * @throws Exception */ public void handle() throws Exception { String rt = \"\\r\\n\"; String outputDir = \"/tmp/jdk/compile/\"; // 这里定义的Java类代码里，建议首行不要带包名，否则容易出现编译失败的问题 String source = \"import com.clay.domain.Store;\" + rt + \"public class Dealer implements Store\" + rt + \"{\" + rt + \"private Store s;\" + rt + \"public Dealer(Store s)\" + rt + \" {\" + \" this.s = s;\" + rt + \" }\" + rt + \"@Override\" + rt + \"public void sell()\" + \" {\" + rt + \"System.out.println(\\\"call dealer sell method\\\");\" + rt + \"s.sell();\" + rt + \" }\" + rt + \"}\"; // Java文件的完整路径 String javaPath = outputDir + \"Dealer.java\"; System.out.println(\"===&gt; java file path: \" + javaPath); // 生成Java文件 createFile(javaPath, source); // 编译Java文件 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager fileMgr = compiler.getStandardFileManager(null, null, null); Iterable units = fileMgr.getJavaFileObjects(javaPath); CompilationTask task = compiler.getTask(null, fileMgr, null, null, null, units); boolean result = task.call(); fileMgr.close(); System.out.println(\"===&gt; compile result: \" + result); String classPath = \"file:/\" + outputDir; System.out.println(\"===&gt; class file path: \" + classPath); // 加载Class文件 URL[] urls = new URL[]{new URL(classPath)}; URLClassLoader ul = new URLClassLoader(urls); Class clazz = ul.loadClass(\"Dealer\"); // 实例化 Constructor ctr = clazz.getConstructor(Store.class); Store s = (Store) ctr.newInstance(new Supermarket()); s.sell(); }} 特别注意：在 SpringBoot 应用内无法正常运行上述代码，即调用 loadClass () 方法的时候会抛出异常 “java.lang.ClassNotFoundException: Dealer” 此时可以尝试使用 Thread.currentThread().getContextClassLoader() 来替代 new URLClassLoader(urls)，具体的实现代码可参考开源项目 dynamic-loader，这里不再累述 开源项目 varcode dynamic-java-compiler dynamic-loader（推荐） 参考博客 动态代理 - 动态生成 Java 文件并编译成 Class 文件 Java 引入 import 其它目录的自定义包或 Java 源文件 将 Java 字符串形式的源代码动态编译，生成 Class 文件并执行 Java 动态编译整个项目，解决 Jar 包找不到的问题 Java Web 项目部署后，动态编译无法找到依赖的 Jar 包 Java Web 项目部署到 Tomcat 后，使用动态编译无法找到相关类的解决方案 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java"},{"title":"VuePress 入门教程之三主题篇","url":"/posts/cf4f7150.html","text":"前言版本说明本文的内容是基于 VuePress 1.x 讲解的，一切内容以 官方文档 为准。 教程大纲 VuePress 入门教程之一 - 基础篇 VuePress 入门教程之二 - Markdown 篇 VuePress 入门教程之三 - 主题篇 VuePress 入门教程之四 - 插件篇 使用主题使用一个主题和使用一个插件的方式几乎一致。 使用来自依赖的主题一个主题可以在以 vuepress-theme-xxx 的形式发布到 NPM，你可以这样使用它： 1234// .vuepress/config.jsmodule.exports = { theme: 'vuepress-theme-xx'} 主题的缩写如果你的主题名以 vuepress-theme- 开头，你可以使用缩写来省略这个前缀： 1234// .vuepress/config.jsmodule.exports = { theme: 'xxx'} 和下面等价： 1234// .vuepress/config.jsmodule.exports = { theme: 'vuepress-theme-xxx'} 这也适用于 Scoped Packages: 1234// .vuepress/config.jsmodule.exports = { theme: '@org/vuepress-theme-xxx', // 或者一个官方主题: '@vuepress/theme-xxx'} 缩写: 1234// .vuepress/config.jsmodule.exports = { theme: '@org/xxx', // 或者一个官方主题: '@vuepress/xxx'} 提示：以 @vuepress/theme- 开头的主题是官方维护的主题 主题的通用配置和插件几乎一样，主题的配置文件 themeEntry 应该导出一个普通的 JavaScript 对象（#1），它也可以是一个返回对象的函数（#2），这个函数接受用户在 siteConfig.themeConfig 为第一个参数、包含编译期上下文的 ctx 对象作为第二个参数。 12345// .vuepress/theme/index.js// #1module.exports = { // ...} 1234567// .vuepress/theme/index.js// #2module.exports = (themeConfig, ctx) =&gt; { return { // ... }} 提示： 你应该能看到 themeEntry 和 themeConfig 的区别，前者是一个主题本身的配置，这些配置由 VuePress 本身提供；而后者则是用户对主题的配置，这些配置选项则由当前使用的主题来实现，如 默认主题配置。 除了本节列出的选项，themeEntry 也支持插件支持的所有 配置选项 和 生命周期。 plugins 类型: Array|Object 默认值: undefined 参考: 插件 &gt; 使用插件 Warning 注意：你一般可能不需要使用下面的这些配置选项，除非你知道你在做什么！ devTemplate 类型: String 默认值: undefined dev 模式下使用的 HTML 模板路径，默认模板见 这里。 ssrTemplate 类型: String 默认值: undefined build 模式下使用的 HTML 模板路径，默认模板见 这里。 参考: Vue SSR Guide &gt; template. extend 类型: String 默认值: undefined 1234// .vuepress/theme/index.jsmodule.exports = { extend: '@vuepress/theme-default'} VuePress 支持一个主题继承于另一个主题。VuePress 将遵循 override 的理念自动帮你解决各种主题属性（如样式、布局组件）的优先级。 参考: 主题继承 例子: @vuepress/theme-vue globalLayout 类型: String 默认值: undefined 1234// .vuepress/theme/index.jsmodule.exports = { globalLayout: '/path/to/your/global/vue/sfc'} 全局布局组件是负责管理全局布局方案的一个组件，VuePress 默认的 globalLayout 会帮你根据 $frontmatter.layout 来渲染不同的布局，所以大部分情况下你不要配置此选项。举例来说，当你想为当前主题设置全局的 header 和 footer 时，你可以这样做： 12345678910111213141516171819202122232425&lt;!-- .vuepress/theme/layouts/GlobalLayout.vue --&gt;&lt;template&gt; &lt;div id=\"global-layout\"&gt; &lt;header&gt;&lt;h1&gt;Header&lt;/h1&gt;&lt;/header&gt; &lt;component :is=\"layout\"/&gt; &lt;footer&gt;&lt;h1&gt;Footer&lt;/h1&gt;&lt;/footer&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { computed: { layout () { if (this.$page.path) { if (this.$frontmatter.layout) { // 你也可以像默认的 globalLayout 一样首先检测 layout 是否存在 return this.$frontmatter.layout } return 'Layout' } return 'NotFound' } }}&lt;/script&gt; 默认主题的配置下述所列的选项仅对 VuePress 的默认主题生效，如果你在使用一个自定义主题，选项可能会有不同。 首页默认的主题提供了一个首页（Homepage）的布局 (用于 这个网站的主页)。想要使用它，需要在你的根级 README.md 的 YAML Front Matter 指定 home: true。以下是一个如何使用的例子： 12345678910111213141516---home: trueheroImage: /hero.pngheroText: Hero 标题tagline: Hero 副标题actionText: 快速上手 →actionLink: /zh/guide/features:- title: 简洁至上 details: 以 Markdown 为中心的项目结构，以最少的配置帮助你专注于写作。- title: Vue驱动 details: 享受 Vue + webpack 的开发体验，在 Markdown 中使用 Vue 组件，同时可以使用 Vue 来开发自定义主题。- title: 高性能 details: VuePress 为每个页面预渲染生成静态的 HTML，同时在页面被加载的时候，将作为 SPA 运行。footer: MIT Licensed | Copyright © 2018-present Evan You--- 你可以将相应的内容设置为 null 来禁用标题和副标题，任何 YAML Front Matter 之后额外的内容将会以普通的 Markdown 被渲染，并插入到 features 的后面。 导航栏导航栏可能包含你的页面标题、多语言切换、搜索框、 导航栏链接、仓库链接，它们均取决于你的配置。 导航栏 Logo你可以通过 themeConfig.logo 增加导航栏 Logo ，Logo 可以被放置在公共文件目录： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { logo: '/assets/img/logo.png', }} 导航栏链接你可以通过 themeConfig.nav 增加一些导航栏链接: 12345678910// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Home', link: '/' }, { text: 'Guide', link: '/guide/' }, { text: 'External', link: 'https://google.com' }, ] }} 外部链接 &lt;a&gt; 标签的特性将默认包含 target=\"_blank\" rel=\"noopener noreferrer\"，你可以提供 target 与 rel，它们将被作为特性被增加到 &lt;a&gt; 标签上： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'External', link: 'https://google.com', target:'_self', rel:'' }, { text: 'Guide', link: '/guide/', target:'_blank' } ] }} 当你提供了一个 items 数组而不是一个单一的 link 时，它将显示为一个 下拉列表 ： 123456789101112131415// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Languages', ariaLabel: 'Language Menu', items: [ { text: 'Chinese', link: '/language/chinese/' }, { text: 'Japanese', link: '/language/japanese/' } ] } ] }} 此外，你还可以通过嵌套的 items 来在 下拉列表 中设置分组： 1234567891011121314// .vuepress/config.jsmodule.exports = { themeConfig: { nav: [ { text: 'Languages', items: [ { text: 'Group1', items: [/* */] }, { text: 'Group2', items: [/* */] } ] } ] }} 禁用导航栏你可以使用 themeConfig.navbar 来禁用所有页面的导航栏： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { navbar: false }} 你也可以通过 YAML Front Matter 来禁用某个指定页面的导航栏： 123---navbar: false--- 侧边栏想要使 侧边栏（Sidebar）生效，需要配置 themeConfig.sidebar，基本的配置，需要一个包含了多个链接的数组： 12345678910// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: [ '/', '/page-a', ['/page-b', 'Explicit link text'] ] }} 你可以省略 .md 拓展名，同时以 / 结尾的路径将会被视为 */README.md，这个链接的文字将会被自动获取到（无论你是声明为页面的第一个 header，还是明确地在 YAML Front Matter 中指定页面的标题）。如果你想要显示地指定链接的文字，使用一个格式为 [link, text] 的数组。 嵌套的标题链接默认情况下，侧边栏会自动地显示由当前页面的标题（headers）组成的链接，并按照页面本身的结构进行嵌套，你可以通过 themeConfig.sidebarDepth 来修改它的行为。默认的深度是 1，它将提取到 h2 的标题，设置成 0 将会禁用标题（headers）链接，同时，最大的深度为 2，它将同时提取 h2 和 h3 标题。 也可以使用 YAML Front Matter 来为某个页面重写此值（优先级最高）： 123---sidebarDepth: 2--- 显示所有页面的标题链接默认情况下，侧边栏只会显示由当前活动页面的标题（headers）组成的链接，你可以将 themeConfig.displayAllHeaders 设置为 true 来显示所有页面的标题链接： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { displayAllHeaders: true // 默认值：false }} 活动的标题链接默认情况下，当用户通过滚动查看页面的不同部分时，嵌套的标题链接和 URL 中的 Hash 值会实时更新，这个行为可以通过以下的配置来禁用： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { activeHeaderLinks: false, // 默认值：true }} 值得一提的是，当你禁用此选项时，此功能的相应脚本将不会被加载，这是我们性能优化的一个小点 侧边栏分组你可以通过使用对象来将侧边栏划分成多个组： 123456789101112131415161718192021// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: [ { title: 'Group 1', // 必要的 path: '/foo/', // 可选的, 标题的跳转链接，应为绝对路径且必须存在 collapsable: false, // 可选的, 默认值是 true, sidebarDepth: 1, // 可选的, 默认值是 1 children: [ '/' ] }, { title: 'Group 2', children: [ /* ... */ ], initialOpenGroupIndex: -1 // 可选的, 默认值是 0 } ] }} 侧边栏的每个子组默认是可折叠的，你可以设置 collapsable: false 来让一个组永远都是展开状态。一个侧边栏的子组配置同时支持 sidebarDepth 字段用于重写默认显示的侧边栏深度 (1)。 嵌套的侧边栏分组也是支持的 多个侧边栏如果你想为不同的页面组来显示不同的侧边栏，首先，将你的页面文件组织成下述的目录结构： 123456789101112.├─ README.md├─ contact.md├─ about.md├─ foo/│&nbsp;&nbsp;├─ README.md│ ├─ one.md│ └─ two.md└─ bar/ ├─ README.md ├─ three.md └─ four.md 接着，遵循以下的侧边栏配置： 12345678910111213141516171819202122232425// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: { '/foo/': [ '', /* /foo/ */ 'one', /* /foo/one.html */ 'two' /* /foo/two.html */ ], '/bar/': [ '', /* /bar/ */ 'three', /* /bar/three.html */ 'four' /* /bar/four.html */ ], // fallback '/': [ '', /* / */ 'contact', /* /contact.html */ 'about' /* /about.html */ ] } }} 注意：确保 fallback 侧边栏被最后定义，VuePress 会按顺序遍历侧边栏配置来寻找匹配的配置 自动生成侧栏如果你希望自动生成一个仅仅包含了当前页面标题（headers）链接的侧边栏，你可以通过 YAML Front Matter 来实现（优先级最高）： 123---sidebar: auto--- 你也可以通过配置来在所有页面中启用它： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { sidebar: 'auto' }} 在 多语言 模式下，你也可以将其应用到某一特定的语言下： 12345678// .vuepress/config.jsmodule.exports = { themeConfig: { '/zh/': { sidebar: 'auto' } }} 注意：自动生成的侧边栏，默认支持多级显示（两级以上） 禁用侧边栏你可以通过 YAML Front Matter 来禁用指定页面的侧边栏： 123---sidebar: false--- 搜索框内置搜索你可以通过设置 themeConfig.search: false 来禁用默认的搜索框，或是通过 themeConfig.searchMaxSuggestions 来调整默认搜索框显示的搜索结果数量： 1234567// .vuepress/config.jsmodule.exports = { themeConfig: { search: false, searchMaxSuggestions: 10 }} 你可以通过在页面的 Front Matter 中设置 tags 来优化搜索结果： 123456---tags: - 配置 - 主题 - 索引--- 你可以通过在页面的 Front Matter 中设置 search 来对单独的页面禁用内置的搜索框： 123---search: false--- 提示： 如果你需要全文搜索，你可以使用 Algolia 搜索 内置搜索只会为页面的标题、h2 、 h3 以及 tags 构建搜索索引 Algolia 搜索如果需要全文搜索，你可以通过 themeConfig.algolia 选项来使用 Algolia 搜索 替换内置的搜索框。要启用 Algolia 搜索，你需要至少提供 apiKey 和 indexName： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { algolia: { apiKey: '&lt;API_KEY&gt;', indexName: '&lt;INDEX_NAME&gt;' } }} 不同于开箱即用的 内置搜索，Algolia 搜索 需要你在使用之前将你的网站提交给它们用于创建索引，更多选项请参考 Algolia DocSearch 的官方文档。 最后更新时间你可以通过 themeConfig.lastUpdated 选项来获取每个文件最后一次 git 提交的 UNIX 时间戳（ms），同时它将以合适的日期格式显示在每一页的底部： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { lastUpdated: 'Last Updated', // string | boolean }} 请注意，themeConfig.lastUpdated 默认是关闭的，如果给定一个字符串，它将会作为前缀显示（默认值是：Last Updated）。由于 lastUpdated 是基于 git 的，所以你只能在一个基于 git 的项目中启用它。此外，由于使用的时间戳来自 git commit，因此它将仅在给定页的第一次提交之后显示，并且仅在该页面后续提交更改时更新。 参考: @vuepress/plugin-last-updated 上 / 下一篇链接上一篇和下一篇文章的链接将会自动地根据当前页面的侧边栏的顺序来获取。 你可以通过 themeConfig.nextLinks 和 themeConfig.prevLinks 来全局禁用它们： 123456789// .vuepress/config.jsmodule.exports = { themeConfig: { // 默认值是 true 。设置为 false 来禁用所有页面的 下一篇 链接 nextLinks: false, // 默认值是 true 。设置为 false 来禁用所有页面的 上一篇 链接 prevLinks: false }} 你也可以使用 YAML Front Matter 来明确地重写或者禁用它们： 1234---prev: ./some-other-pagenext: false--- Git 仓库和编辑链接当你提供了 themeConfig.repo 选项，将会自动在每个页面的导航栏生成生成一个 GitHub 链接，以及在页面的底部生成一个 \"Edit this page\" 链接。 1234567891011121314151617181920212223// .vuepress/config.jsmodule.exports = { themeConfig: { // 假定是 GitHub. 同时也可以是一个完整的 GitLab URL repo: 'vuejs/vuepress', &nbsp; &nbsp;// 自定义仓库链接文字。默认从 `themeConfig.repo` 中自动推断为 &nbsp; &nbsp;// \"GitHub\"/\"GitLab\"/\"Bitbucket\" 其中之一，或是 \"Source\"。 &nbsp; &nbsp;repoLabel: '查看源码', &nbsp; &nbsp;// 以下为可选的编辑链接选项 &nbsp; &nbsp;// 假如你的文档仓库和项目本身不在一个仓库： &nbsp; &nbsp;docsRepo: 'vuejs/vuepress', &nbsp; &nbsp;// 假如文档不是放在仓库的根目录下： &nbsp; &nbsp;docsDir: 'docs', &nbsp; &nbsp;// 假如文档放在一个特定的分支下： &nbsp; &nbsp;docsBranch: 'master', // 默认是 false, 设置为 true 来启用 editLinks: true, // 默认为 \"Edit this page\" editLinkText: '帮助我们改善此页面！' }} 你可以通过 YAML front matter 来禁用指定页面的编辑链接： 123---editLink: false--- 页面滚动你可以通过 themeConfig.smoothScroll 选项来启用页面滚动效果： 123456// .vuepress/config.jsmodule.exports = { themeConfig: { smoothScroll: true }} 自定义页面类（CSS）有时候你可能需要为特定页面添加一个 CSS 类名，以方便针对该页面添加一些专门的 CSS。这种情况下你可以在该页面的 YAML Front Matter 中声明一个 pageClass： 123---pageClass: custom-page-class--- 只能在 .vuepress/styles/index.styl 中编写针对该页面的 CSS ： 12345/* .vuepress/styles/index.styl */.theme-container.custom-page-class { /* 特定页面的 CSS */} 自定义样式应该写在 index.styl 内，该文件可以让你方便地添加或覆盖样式 特定页面的自定义布局默认情况下，每个 *.md 文件将会被渲染在一个 &lt;div class=\"page\"&gt; 容器中，同时还有侧边栏、自动生成的编辑链接，以及上 / 下一篇文章的链接。如果你想要使用一个完全自定义的组件来代替当前的页面（而只保留导航栏），你可以再次使用 YAML Front Matter 来指定这个组件。 123---layout: SpecialLayout--- 这将会为当前的页面渲染 .vuepress/components/SpecialLayout.vue 布局。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"VuePress 入门教程之二 Markdown 篇","url":"/posts/b693c9f4.html","text":"前言版本说明本文的内容是基于 VuePress 1.x 讲解的，一切内容以 官方文档 为准。 教程大纲 VuePress 入门教程之一 - 基础篇 VuePress 入门教程之二 - Markdown 篇 VuePress 入门教程之三 - 主题篇 VuePress 入门教程之四 - 插件篇 Markdown 扩展Header Anchors所有的标题将会自动地应用 anchor 链接，anchor 的渲染可以通过 markdown.anchor 来配置。 链接内部链接网站内部的链接，将会被转换成 &lt;router-link&gt; 用于 SPA 导航。同时，站内的每一个文件夹下的 README.md 或者 index.md 文件都会被自动编译为 index.html，对应的链接将被视为 /。 以如下的文件结构为例： 12345678910.├─ README.md├─ foo│&nbsp;&nbsp;├─ README.md│ ├─ one.md│ └─ two.md└─ bar ├─ README.md ├─ three.md └─ four.md 假设你现在位于 foo/one.md 中： 12345[Home](/) &lt;!-- 跳转到根部的 README.md --&gt;[foo](/foo/) &lt;!-- 跳转到 foo 文件夹的 index.html --&gt;[foo heading](./#heading) &lt;!-- 跳转到 foo/index.html 的特定标题位置 --&gt;[bar - three](../bar/three.md) &lt;!-- 具体文件可以使用 .md 结尾（推荐） --&gt;[bar - four](../bar/four.html) &lt;!-- 也可以用 .html --&gt; 链接的重定向VuePress 支持重定向到干净链接。如果一个链接 /foo 找不到，VuePress 会自行寻找一个可用的 /foo/ 或 /foo.html。反过来，当 /foo/ 或 /foo.html 中的一个找不到时，VuePress 也会尝试寻找另一个。借助这种特性，我们可以通过官方插件 vuepress-plugin-clean-urls 定制你的网站路径。 Tip 注意：无论是否使用了 permalink 和 clean-urls 插件，你的相对路径都应该依赖于当前的文件结构来定义。在上面的例子中，即使你将 /foo/one.md 的路径设为了 /foo/one/，你依然应该通过 ./two.md 来访问 /foo/two.md 页面后缀默认情况下，页面和内部链接是以 .html 后缀生成，可以通过设置 config.markdown.pageSuffix 来自定义它。 外部链接外部的链接将会被自动地设置为 target=\"_blank\" rel=\"noopener noreferrer\": 12- [vuejs.org](https://vuejs.org)- [VuePress on GitHub](https://github.com/vuejs/vuepress) 你可以自定义通过配置 config.markdown.externalLinks 来自定义外部链接的特性。 Front MatterVuePress 提供了对 YAML Front Matter 开箱即用的支持: 1234---title: Blogging Like a Hackerlang: en-US--- 这些数据可以在当前 Markdown 的正文，或者是任意的自定义或主题组件中使用。想了解更多，请移步 Front Matter。 Github 风格的表格输入内容 12345| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 输出效果 Emoji 表情输入内容 1:tada: :100: 输出效果 你可以在这个列表找到所有可用的 Emoji 表情。 文档目录输入内容 1[[toc]] 输出效果 目录（Table of Contents）的渲染可以通过 markdown.toc 选项来配置。 自定义容器 Warning 注意：自定义容器只针对 VuePress 的默认主题有效。 输入内容 123456789101112131415::: tip这是一个提示:::::: warning这是一个警告:::::: danger这是一个危险警告:::::: details这是一个详情块，在 IE / Edge 中不生效::: 输出效果 代码块中的语法高亮VuePress 使用了 Prism 来为 Markdown 中的代码块实现语法高亮。Prism 支持大量的编程语言，你需要做的只是在代码块的开始倒勾中附加一个有效的语言别名： 输入内容 12345678910``` html&lt;ul&gt; &lt;li v-for=\"todo in todos\" :key=\"todo.id\" &gt; {{ todo.text }} &lt;/li&gt;&lt;/ul&gt;``` 输出效果 在 Prism 的网站上查看 合法的语言列表。 代码块中的行高亮输入内容 123456789``` js {4}export default { data () { return { msg: 'Highlighted!' } }}``` 输出效果 除了单行以外，你也可指定多行，行数区间，或是两者都指定。 行数区间：例如 {5-8}, {3-10}, {10-17} 多个单行：例如 {4,7,9} 行数区间与多个单行：例如 {4,7-13,16,23-27,40} 输入内容 12345678910111213``` js{1,4,6-7}export default { // Highlighted data () { return { msg: `Highlighted! This line isn't highlighted, but this and the next 2 are.`, motd: 'VuePress is awesome', lorem: 'ipsum', } }}``` 输出效果 代码块行号显示你可以通过配置来为每个代码块显示行号： 12345module.exports = { markdown: { lineNumbers: true }} 显示效果： 代码块片段导入你可以通过下述的语法，在 Markdown 文件中导入已经存在的其他文件中的代码段： 1&lt;&lt;&lt; @/filepath 它也支持 行高亮，语法如下： 1&lt;&lt;&lt; @/filepath{highlightLines} 输入内容 1&lt;&lt;&lt; @/../@vuepress/markdown/__tests__/fragments/snippet.js{2} 输出效果 Tip 注意：由于代码段的导入将在 Webpack 编译之前执行，因此你无法使用 Webpack 中的路径别名，此处的 @ 默认值是 process.cwd() 为了只导入对应部分的代码，你也可运用 VS Code Region。你可以在文件路径后方的 # 紧接着提供一个自定义的区域名称（预设为 snippet ） 代码文件 1234567891011121314151617181920212223242526272829303132// #region snippetfunction foo () { return ({ dest: '../../vuepress', locales: { '/': { lang: 'en-US', title: 'VuePress', description: 'Vue-powered Static Site Generator' }, '/zh/': { lang: 'zh-CN', title: 'VuePress', description: 'Vue 驱动的静态网站生成器' } }, head: [ ['link', { rel: 'icon', href: `/logo.png` }], ['link', { rel: 'manifest', href: '/manifest.json' }], ['meta', { name: 'theme-color', content: '#3eaf7c' }], ['meta', { name: 'apple-mobile-web-app-capable', content: 'yes' }], ['meta', { name: 'apple-mobile-web-app-status-bar-style', content: 'black' }], ['link', { rel: 'apple-touch-icon', href: `/icons/apple-touch-icon-152x152.png` }], ['link', { rel: 'mask-icon', href: '/icons/safari-pinned-tab.svg', color: '#3eaf7c' }], ['meta', { name: 'msapplication-TileImage', content: '/icons/msapplication-icon-144x144.png' }], ['meta', { name: 'msapplication-TileColor', content: '#000000' }] ] })}// #endregion snippetexport default foo 输入内容 1&lt;&lt;&lt; @/../@vuepress/markdown/__tests__/fragments/snippet-with-region.js#snippet{1} 输出效果 进阶配置VuePress 使用 markdown-it 来渲染 Markdown，上述大多数的拓展也都是通过自定义的插件实现的。想要进一步的话，你可以通过 .vuepress/config.js 的 markdown 选项，来对当前的 markdown-it 实例做一些自定义的配置： 123456789101112module.exports = { markdown: { // markdown-it-anchor 的选项 anchor: { permalink: false }, // markdown-it-toc 的选项 toc: { includeLevel: [1, 2] }, extendMarkdown: md =&gt; { &nbsp; &nbsp; &nbsp;// 使用更多的 markdown-it 插件! md.use(require('markdown-it-xxx')) } }} 在 Markdown 中 使用 Vue浏览器的 API 访问限制当你在开发一个 VuePress 应用时，由于所有的页面在生成静态 HTML 时都需要通过 Node.js 服务端渲染，因此所有的 Vue 相关代码都应当遵循 编写通用代码 的要求。简而言之，请确保只在 beforeMount 或者 mounted 访问浏览器 DOM 的 API。 如果你正在使用，或者需要展示一个对于 SSR 不怎么友好的组件（比如包含了自定义指令），你可以将它们包裹在内置的 &lt;ClientOnly&gt; 组件中： 123&lt;ClientOnly&gt; &lt;NonSSRFriendlyComponent/&gt;&lt;/ClientOnly&gt; 请注意，这并不能解决一些组件或库在导入时就试图访问浏览器 API 的问题 —— 如果需要使用这样的组件或库，你需要在合适的生命周期钩子中动态导入它们： 123456789&lt;script&gt;export default { mounted () { import('./lib-that-access-window-on-import').then(module =&gt; { // use code }) }}&lt;/script&gt; 如果你的模块通过 export default 导出一个 Vue 组件，那么你可以动态注册它： 1234567891011121314151617&lt;template&gt; &lt;component v-if=\"dynamicComponent\" :is=\"dynamicComponent\"&gt;&lt;/component&gt;&lt;/template&gt;&lt;script&gt;export default { data() { return { dynamicComponent: null } }, mounted () { import('./lib-that-access-window-on-import').then(module =&gt; { this.dynamicComponent = module.default }) }}&lt;/script&gt; 参考： Vue.js &gt; 动态组件 模板语法插值每一个 Markdown 文件将首先被编译成 HTML，接着作为一个 Vue 组件传入 vue-loader，这意味着你可以在文本中使用 Vue 风格的插值： 输入内容 1{{ 1 + 1 }} 输出效果 12 指令同样地，也可以使用指令: 输入内容 1&lt;span v-for=\"i in 3\"&gt;{{ i }} &lt;/span&gt; 输出效果 11 2 3 访问网站以及页面的数据编译后的组件没有私有数据，但可以访问 网站的元数据，举例来说： 输入内容 1{{ $page }} 输出效果 12345{ \"path\": \"/using-vue.html\", \"title\": \"Using Vue in Markdown\", \"frontmatter\": {}} Escaping默认情况下，块级 (block) 的代码块将会被自动包裹在 v-pre 中。如果你想要在内联 (inline) 的代码块或者普通文本中显示原始的大括号，或者一些 Vue 特定的语法，你需要使用自定义容器 v-pre 来包裹： 输入内容 123::: v-pre`{{ This will be displayed as-is }}`::: 输出效果 1{{ This will be displayed as-is }} 使用组件正常使用组件所有在 .vuepress/components 中找到的 *.vue 文件将会自动地被注册为全局的异步组件，如： 1234567.└─ .vuepress &nbsp;&nbsp;└─ components ├─ demo-1.vue &nbsp;&nbsp; &nbsp;├─ OtherComponent.vue &nbsp; &nbsp; &nbsp;└─ Foo &nbsp; &nbsp; &nbsp; &nbsp; └─ Bar.vue 你可以直接使用这些组件在任意的 Markdown 文件中（组件名是通过文件名取到的）： 123&lt;demo-1/&gt;&lt;OtherComponent/&gt;&lt;Foo-Bar/&gt; Warning 重要：请确保一个自定义组件的名字包含连接符或者是 PascalCase，否则，它将会被视为一个内联元素，并被包裹在一个 &lt;p&gt; 标签中，这将会导致 HTML 渲染紊乱，因为 HTML 标准规定， &lt;p&gt; 标签中不允许放置任何块级元素。 在标题中使用组件你可以在标题中使用 Vue 组件，但是请留意以下两种方式的不同： Markdown 输出的 HTML 解析后的标题 # text &lt;Tag/&gt; &lt;h1&gt;text &lt;Tag/&gt;&lt;/h1&gt; text # text `&lt;Tag/&gt;` &lt;h1&gt;text &lt;code&gt;&amp;lt;Tag/&amp;gt;&lt;/code&gt;&lt;/h1&gt; text &lt;Tag/&gt; 被 &lt;code&gt; 包装的 HTML 将按原样显示，只有未被包装的 HTML 才会被 Vue 解析。输出的 HTML 由 markdown-it 完成，而解析后的标题由 VuePress 完成，用于侧边栏以及文档的标题。 使用预处理器VuePress 对以下预处理器已经内置相关的 Webpack 配置：sass、scss、less、stylus 和 pug。要使用它们你只需要在项目中安装对应的依赖即可。例如，要使用 sass，需要安装： 1$ yarn add -D sass-loader node-sass 然后你就可以在 Markdown 或是组件中使用如下代码： 1234&lt;style lang=\"sass\"&gt; .title font-size: 20px&lt;/style&gt; 要在组件中使用 &lt;template lang=\"pug\"&gt;，则需要安装 pug 和 pug-plain-loader: 1$ yarn add -D pug pug-plain-loader 需要指出的是，如果你是一个 stylus 用户，你并不需要在你的项目中安装 stylus 和 stylus-loader，因为 VuePress 已经内置了它们。对于那些没有内置的预处理器，除了安装对应的依赖，你还需要 拓展内部的 Webpack 配置。 脚本和样式提升有时，你可以只想在当前页面应用一些 JavaScript 或者 CSS，在这种情况下，你可以直接在 Markdown 文件中使用原生的 &lt;script&gt; 或者 &lt;style&gt; 标签，它们将会从编译后的 HTML 文件中提取出来，并作为生成的 Vue 单文件组件的 &lt;script&gt; 和 &lt;style&gt; 标签。 输入内容 1234567891011121314151617&lt;p class=\"demo\" :class=\"$style.example\"&gt;&lt;/p&gt;&lt;style module&gt;.example { color: #41b883;}&lt;/style&gt;&lt;script&gt;export default { props: ['slot-key'], mounted () { document.querySelector(`.${this.$style.example}`) .textContent = '这个块是被内联的脚本渲染的，样式也采用了内联样式。' }}&lt;/script&gt; 输出效果 内置的组件OutboundLinkOutboundLink 用来表明当前是一个外部链接，在 VuePress 中这个组件会紧跟在每一个外部链接后面。 ClientOnly参考 浏览器的 API 访问限制。 Content Props: pageKey - string, 要渲染的 page 的 hash key, 默认值是当前页面的 key. slotKey - string, 页面的 markdown slot 的 key. 默认值是 default slot. Usage： 指定一个指定页面的特定 slot 用于渲染，当你使用 自定义布局 或者自定义主题时，这将非常有用。 1&lt;Content/&gt; 参考: 全局计算属性 &gt; $page Markdown 插槽 开发主题 &gt; 获取渲染内容 Badge 注意： Badge 只针对 VuePress 的默认主题生效 Props: text - string type - string, 可选值： \"tip\"|\"warning\"|\"error\"，默认值是： \"tip\" vertical - string, 可选值： \"top\"|\"middle\"，默认值是： \"top\" Usage: 你可以在标题中，使用这个组件来为某些 API 添加一些状态。 输入内容 1### Badge &lt;Badge text=\"beta\" type=\"warning\"/&gt; &lt;Badge text=\"默认主题\"/&gt; 输入效果 参考: 在标题中使用组件 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"VuePress 入门教程之一基础篇","url":"/posts/8d13e75d.html","text":"前言版本说明本文的内容是基于 VuePress 1.x 讲解的，一切内容以 官方文档 为准。 教程大纲 VuePress 入门教程之一 - 基础篇 VuePress 入门教程之二 - Markdown 篇 VuePress 入门教程之三 - 主题篇 VuePress 入门教程之四 - 插件篇 静态网站生成器比较Hexo Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其它渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。Hexo 配合它的主题模块，比如 NexT 主题，可以作为非常简洁方便的静态博客系统。 GitBook GitBook 是一个现代的文档平台，团队或个人可以在其上编写产品、API 接口文档以及团队内部知识库。GitBook 改版之后，感觉团队更专注于商业产品而不是开源工具，同时 CLI 工具不再提供了，所以无法实现个性化部署。 Nuxt Nuxt.js 是一个基于 Vue.js 的通用应用框架。通过对客户端 / 服务端基础架构的抽象组织，Nuxt.js 主要关注的是应用的 UI 渲染。Nuxt.js 的目标是创建一个灵活的应用框架，你可以基于它初始化新项目的基础结构代码，或者在已有 Node.js 项目中使用 Nuxt.js。简而言之，Nuxt.js 更像是为构建应用程序而生的，而不是独立的内容静态网站。 Docsify Docsify 是一个动态生成文档网站的工具。不同于 GitBook、Hexo 的地方是它不会生成将 .md 转成 .html 文件，所有转换工作都是在运行时进。Docsify 是基于 Vue，完全的运行时驱动，不需要渲染 HTML，所以对 SEO 不够友好。如果不关注 SEO，安装简单化不想有大量依赖，它是比较好的选择，比如公司或这团队内部的文档系统。 Docute Docute 本质上就是一个 JavaScript 文件，它可以获取 Markdown 文件并将它们呈现为单页面应用。它完全由运行时驱动，因此并不涉及服务端组件，这就意味着没有构建过程。你只需创建一个 HTML 文件和一堆 Markdown 文档，你的网站就差不多完成了！Docute 与 Docsify 基本一样，只是在文件大小和 UI 及不同的使用方式，Docute 官网有其差异的介绍。 VuePress VuePress 实际上是由 Vue、Vue Router 和 Webpack 驱动的单页面应用程序，实现了 GitBook 的功能。VuePress 展示页面与 Docsify 类似，但是与 Docsify 不同的是会预先渲染 HTML。每个 Markdown 文件都使用 markdown-it 编译为 HTML，然后作为 Vue 组件的模板进行处理；这允许你直接在 Markdown 文件中使用 Vue，在需要嵌入动态内容时，这种使用方式非常有用。 Other Jekyll、Typecho、Hugo、Ghost VuePress 介绍VuePress 由两部分组成：第一部分是一个极简静态网站生成器，它包含由 Vue 驱动的主题系统和插件 API，另一个部分是为书写技术文档而优化的默认主题，它的诞生初衷是为了支持 Vue 及其子项目的文档需求。每一个由 VuePress 生成的页面都带有预渲染好的 HTML，也因此具有非常好的加载性能和搜索引擎优化（SEO）。同时，一旦页面被加载，Vue 将接管这些静态内容，并将其转换成一个完整的单页应用（SPA），其他的页面则会只在用户浏览到的时候才按需加载。 工作原理事实上，一个 VuePress 网站是一个由 Vue、Vue Router 和 Webpack 驱动的单页应用。如果你以前使用过 Vue 的话，当你在开发一个自定义主题的时候，你会感受到非常熟悉的开发体验，你甚至可以使用 Vue DevTools 去调试你的自定义主题。在构建时，我们会为应用创建一个服务端渲染（SSR）的版本，然后通过虚拟访问每一条路径来渲染对应的 HTML。这种做法的灵感来源于 Nuxt 的 nuxt generate 命令，以及其他的一些项目，比如 Gatsby。 功能说明内置的 Markdown 拓展 目录 自定义容器 代码块中的行高亮 行号 导入代码段 在 Markdown 中 使用 Vue 模板语法 使用组件 Vue 驱动的自定义主题系统 网站和页面的元数据 内容摘抄 默认主题 Responsive layout 首页 内置的搜索 Algolia 搜索 可定制的 navbar and sidebar 自动生成的 GitHub 链接和页面编辑链接 PWA: 刷新内容的 Popup 最后更新时间 多语言支持 博客主题 文档 在线案例 Plugin 强大的 Plugin API 博客插件 PWA 插件 Google Analytics 插件 … VuePress 快速入门 Warning 前提条件：VuePress 需要 Node.js &gt;= 8.6 下述内容会帮助你从头搭建一个简单的 VuePress 文档，如果你想在一个现有的项目中使用 VuePress 来管理文档，从步骤 3 开始。 创建并进入一个新目录 1$ mkdir vuepress-starter &amp;&amp; cd vuepress-starter 使用你喜欢的包管理器进行初始化 1234$ yarn init# 或者$ npm init 将 VuePress 安装为本地依赖 1234$ yarn add -D vuepress# 或者$ npm install -D vuepress # npm install vuepress --save-dev Warning 注意：官方已经不再推荐全局安装 VuePress，如果你的现有项目依赖了 Webpack 3.x，则推荐使用 Yarn 而不是 NPM 来安装 VuePress。因为在这种情形下，NPM 会生成错误的依赖树 创建第一篇文档 1$ mkdir docs &amp;&amp; echo '# Hello VuePress' &gt; docs/README.md 在 package.json 中添加一些 scripts 这一步骤是可选的，但推荐你完成它。在下文中，会默认这些 scripts 已经被添加。 123456{ \"scripts\": { \"docs:dev\": \"vuepress dev docs\", \"docs:build\": \"vuepress build docs\" }} 在本地启动服务器 1234$ yarn docs:dev# 或者$ npm run docs:dev VuePress 会在 http://127.0.0.1:8080 启动一个热重载的开发服务器，此时你就拥有了一个简单可用的 VuePress 文档。当你的文档逐渐成型的时候，不要忘记 VuePress 的 多语言支持 ，并了解一下如何将你的文档 部署 到任意静态文件服务器上。 目录结构说明 如果 docs 目录做为顶级目录（非 vuepress-starter 的子目录），如下所示： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 那么 package.json 的配置内容需要更改为： 123456{ \"scripts\": { \"build\": \"vuepress build .\", \"dev\": \"vuepress dev .\" }} Shell 脚本的内容则更改为： 1234$ yarn dev# 或者$ npm run dev VuePress 基础概念目录结构VuePress 遵循 “约定优于配置” 的原则，推荐的目录结构如下： 12345678910111213141516171819202122.├── docs│&nbsp;&nbsp; ├── .vuepress _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `components` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `theme` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │ └── Layout.vue│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `public` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `styles` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; ├── index.styl│&nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── palette.styl│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `templates` _(**可选的, 谨慎配置**)_│&nbsp;&nbsp; │&nbsp;&nbsp; │ &nbsp; ├── dev.html│&nbsp;&nbsp; │&nbsp;&nbsp; │ &nbsp; └── ssr.html│&nbsp;&nbsp; │&nbsp;&nbsp; ├── `config.js` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;&nbsp; └── `enhanceApp.js` _(**可选的**)_│&nbsp;&nbsp; │&nbsp;│&nbsp;&nbsp; ├── README.md│&nbsp;&nbsp; ├── guide│&nbsp;&nbsp; │&nbsp;&nbsp; └── README.md│&nbsp;&nbsp; └── config.md│&nbsp;└── package.json Warning 注意：请留意目录名的大写 docs/.vuepress: 用于存放全局的配置、组件、静态资源等。 docs/.vuepress/components: 该目录中的 Vue 组件将会被自动注册为全局组件。 docs/.vuepress/theme: 用于存放本地主题。 docs/.vuepress/styles: 用于存放样式相关的文件。 docs/.vuepress/styles/index.styl: 将会被自动应用的全局样式文件，会生成在最终的 CSS 文件结尾，具有比默认样式更高的优先级。 docs/.vuepress/styles/palette.styl: 用于重写默认颜色常量，或者设置新的 stylus 颜色常量。 docs/.vuepress/public: 静态资源目录。 docs/.vuepress/templates: 存储 HTML 模板文件。 docs/.vuepress/templates/dev.html: 用于开发环境的 HTML 模板文件。 docs/.vuepress/templates/ssr.html: 构建时基于 Vue SSR 的 HTML 模板文件。 docs/.vuepress/config.js: 配置文件的入口文件，也可以是 YML 或 toml。 docs/.vuepress/enhanceApp.js: 客户端应用的增强。 Warning 注意：当你想要去自定义 templates/ssr.html 或 templates/dev.html 时，最好基于 默认的模板文件 来修改，否则可能会导致构建出错 页面路由此处一般把 docs 目录作为 targetDir （参考 命令行接口），下面所有的 “文件的相对路径” 都是相对于 docs 目录的。在项目根目录下的 package.json 中添加如下 scripts ： 123456{ \"scripts\": { \"dev\": \"vuepress dev docs\", \"build\": \"vuepress build docs\" }} 对于上述的目录结构，Vuepress 的默认页面路由地址如下： 文件的相对路径 页面路由地址 /README.md / /guide/README.md /guide/ /config.md /config.html 基本配置配置文件如果没有任何配置，这个网站将会是非常局限的，用户也无法在你的网站上自由导航。为了更好地自定义你的网站，首先需要在你的文档目录下创建一个 .vuepress 目录，所有 VuePress 相关的文件都将会被放在这里，项目结构示例如下： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 一个 VuePress 网站最必要的配置文件是 .vuepress/config.js，它应该导出一个 JavaScript 对象： 1234module.exports = { title: 'Hello VuePress', description: 'Just playing around'} 对于上述的配置，如果你运行起 dev server，你应该能看到一个页面，它包含一个页头，里面包含一个标题和一个搜索框。VuePress 内置了基于 headers 的搜索 —— 它会自动为所有页面的标题、h2 和 h3 构建起一个简单的搜索索引。可参见 配置 来查看所有可配置的选项。 Tip 其他配置格式：你也可以使用 YAML (.vuepress/config.yml) 或是 TOML (.vuepress/config.toml) 格式的配置文件 主题配置一个 VuePress 主题应该负责整个网站的布局和交互细节。在 VuePress 中，目前自带了一个默认的主题（正是你现在所看到的），它是为技术文档而设计的。同时，默认主题提供了一些选项，让你可以去自定义导航栏（navbar）、 侧边栏（sidebar）和 首页（homepage） 等，详情请参见 默认主题配置 ，如果你想开发一个自定义主题，可以参考 自定义主题。 应用级别的配置由于 VuePress 是一个标准的 Vue 应用，你可以通过创建一个 .vuepress/enhanceApp.js 文件来做一些应用级别的配置，当该文件存在的时候，会被导入到应用内部。enhanceApp.js 应该 export default 一个钩子函数，并接受一个包含了一些应用级别属性的对象作为参数。你可以使用这个钩子来安装一些附加的 Vue 插件、注册全局组件，或者增加额外的路由钩子等： 12345678910// 使用异步函数也是可以的export default ({ Vue, // VuePress 正在使用的 Vue 构造函数 options, // 附加到根实例的一些选项 router, // 当前应用的路由实例 siteData, // 站点元数据 isServer // 当前应用配置是处于 服务端渲染 或 客户端}) =&gt; { // ...做一些其他的应用级别的优化} 静态资源相对路径所有的 Markdown 文件都会被 Webpack 编译成 Vue 组件，因此你可以，并且应该更倾向于使用相对路径（Relative URLs）来引用所有的静态资源： 1![An image](./image.png) 同样地，这在 *.vue 文件的模板中一样可以工作，图片将会被 url-loader 和 file-loader 处理，在运行生成静态文件的构建任务时，文件会被复制到正确的位置。 除此之外，你也使用 ~ 前缀来明确地指出这是一个 Webpack 的模块请求，这将允许你通过 Webpack 别名来引用文件或者 NPM 的依赖： 12![Image from alias](~@alias/image.png)![Image from dependency](~some-dependency/image.png) Webpack 的别名可以通过 .vuepress/config.js 中 configureWebpack 来配置，如： 123456789module.exports = { configureWebpack: { resolve: { alias: { '@alias': 'path/to/some/dir' } } }} 公共文件有时，你可能需要提供一个静态资源，但是它们并不直接被你的任何一个 Markdown 文件或者主题组件引用 —— 举例来说，favicons 和 PWA 的图标，在这种情形下，你可以将它们放在 .vuepress/public 中， 它们最终会被复制到生成的静态文件夹中。 基础路径如果你的网站会被部署到一个非根路径，你将需要在 .vuepress/config.js 中设置 base，举例来说，如果你打算将你的网站部署到 https://foo.github.io/bar/，那么 base 的值就应该被设置为 \"/bar/\" (应当总是以斜杠开始，并以斜杠结束)。有了基础路径（Base URL），如果你希望引用一张放在 .vuepress/public 中的图片，你需要使用这样路径：/bar/image.png，然而，一旦某一天你决定去修改 base，这样的路径引用将会显得异常脆弱。为了解决这个问题，VuePress 提供了内置的一个 helper $withBase（它被注入到了 Vue 的原型上），可以帮助你生成正确的路径： 1&lt;img :src=\"$withBase('/foo.png')\" alt=\"foo\"&gt; 值得一提的是，你不仅可以在你的 Vue 组件中使用上述的语法，在 Markdown 文件中亦是如此。最后补充一句，一个 base 路径一旦被设置，它将会自动地作为前缀插入到 .vuepress/config.js 中所有以 / 开始的资源路径中。 多语言支持站点多语言配置要启用 VuePress 的多语言支持，首先需要使用如下的文件结构： 12345678910docs├─ README.md├─ foo.md├─ nested│&nbsp;&nbsp;└─ README.md└─ zh ├─ README.md ├─ foo.md └─ nested &nbsp;&nbsp; └─ README.md 然后，在 .vuepress/config.js 中提供 locales 选项： 12345678910111213141516module.exports = { locales: { // 键名是该语言所属的子路径 // 作为特例，默认语言可以使用 '/' 作为其路径。 '/': { lang: 'en-US', // 将会被设置为 &lt;html&gt; 的 lang 属性 title: 'VuePress', description: 'Vue-powered Static Site Generator' }, '/zh/': { lang: 'zh-CN', title: 'VuePress', description: 'Vue 驱动的静态网站生成器' } }} 如果一个语言没有声明 title 或者 description，VuePress 将会尝试使用配置顶层的对应值。如果每个语言都声明了 title 和 description，则顶层的这两个值可以被省略。 默认主题多语言配置默认主题也内置了多语言支持，可以通过 themeConfig.locales 来配置。该选项接受同样的 { path: config } 格式的值。每个语言除了可以配置一些站点中用到的文字之外，还可以拥有自己的 导航栏 和 侧边栏 配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647module.exports = { locales: { '/': { lang: 'en-US', title: 'VuePress', description: 'Vue-powered Static Site Generator' }, '/zh/': { lang: 'zh-CN', title: 'VuePress', description: 'Vue 驱动的静态网站生成器' } }, themeConfig: { locales: { '/': { selectText: 'Languages', label: 'English', ariaLabel: 'Languages', editLinkText: 'Edit this page on GitHub', algolia: {}, nav: [ {text: 'Nested', link: '/nested/', ariaLabel: 'Nested'} ], sidebar: { '/nested/': [/* ... */] } }, '/zh/': { // 多语言下拉菜单的标题 selectText: '选择语言', // 该语言在下拉菜单中的标签 label: '简体中文', // 编辑链接文字 editLinkText: '在 GitHub 上编辑此页', // 当前 locale 的 algolia docsearch 选项 algolia: {}, nav: [ {text: '嵌套', link: '/zh/nested/'} ], sidebar: { '/zh/nested/': [/* ... */] } } } }} 编译构建 在 config.js 中指定构建的目标目录： 123module.exports = { dest: 'docs/.vuepress/dist'} 通过以下命令编译构建，生成 VuePress 网站所需的静态文件，这样就可以很方便地将 VuePress 文档部署到任意的 Web 服务器 123456789101112131415161718192021# 编译构建$ yarm docs:build# 或者$ npm run docs:build# 成功编译后，会在指定的目录下生成网站的所有静态文件，目录结构如下docs/.vuepress/dist├── 404.html├── assets├── contact├── debug├── en├── faq├── favicon.ico├── guide├── hero.png├── index.html├── logo.png├── manifest.json└── service-worker.js 目录结构说明 如果 docs 目录做为顶级目录，如下所示： 123456.├─ docs│ ├─ README.md│ └─ .vuepress│ └─ config.js└─ package.json 那么 config.js 的配置内容需要更改为： 123module.exports = { dest: '.vuepress/dist'} 编译构建的命令则更改为： 1234$ yarn build# 或者$ npm run build 部署方式GitHub Pages 在 docs/.vuepress/config.js 中设置正确的 base 如果你打算发布到 https://&lt;USERNAME&gt;.github.io/，则可以省略这一步，因为 base 默认即是 \"/\"。 如果你打算发布到 https://&lt;USERNAME&gt;.github.io/&lt;REPO&gt;/（也就是说你的仓库在 https://github.com/&lt;USERNAME&gt;/&lt;REPO&gt;），则将 base 设置为 \"/&lt;REPO&gt;/\"。 在你的项目中，创建一个如下的 deploy.sh 文件（请自行判断去掉对应的注释） 12345678910111213141516171819202122232425#!/usr/bin/env sh# 确保脚本抛出遇到的错误set -e# 生成静态文件npm run docs:build# 进入生成的文件夹cd docs/.vuepress/dist# 如果是发布到自定义域名# echo 'www.example.com' &gt; CNAMEgit initgit add -Agit commit -m 'deploy'# 如果发布到 https://&lt;USERNAME&gt;.github.io## git push -f git@github.com:&lt;USERNAME&gt;/&lt;USERNAME&gt;.github.io.git master# 如果发布到 https://&lt;USERNAME&gt;.github.io/&lt;REPO&gt;## git push -f git@github.com:&lt;USERNAME&gt;/&lt;REPO&gt;.git master:gh-pagescd - 你可以在你的持续集成的设置中，设置在每次 Push 代码时自动运行上述 Shell 脚本 GitHub Pages and Travis CI 在 docs/.vuepress/config.js 中设置正确的 base 如果你打算发布到 https://&lt;USERNAME or GROUP&gt;.github.io/，则可以省略这一步，因为 base 默认即是 \"/\"。 如果你打算发布到 https://&lt;USERNAME or GROUP&gt;.github.io/&lt;REPO&gt;/（也就是说你的仓库在 https://github.com/&lt;USERNAME&gt;/&lt;REPO&gt;），则将 base 设置为 \"/&lt;REPO&gt;/\"。 在项目的根目录创建一个名为 .travis.yml 的文件 在本地执行 yarn 或 npm install 并且提交生成的 lock 文件（即 yarn.lock 或 package-lock.json） 使用 GitHub Pages 部署提供程序模板，并遵循 Travis 文档规范 来编写 .travis.yml 文件 123456789101112131415language: node_jsnode_js: - lts/*install: - yarn install # npm ciscript: - yarn docs:build # npm run docs:builddeploy: provider: pages skip_cleanup: true local_dir: docs/.vuepress/dist github_token: $GITHUB_TOKEN # 在 GitHub 中生成，用于允许 Travis 向你的仓库推送代码。在 Travis 的项目设置页面进行配置，设置为 secure variable keep_history: true on: branch: master var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"初探前端框架 Vue2 之四","url":"/posts/9f128424.html","text":"大纲 初探前端框架 Vue2 之一 初探前端框架 Vue2 之二 初探前端框架 Vue2 之三 初探前端框架 Vue2 之四 Vue CLI 安装CLI 是 Command-Line Interface (命令行界面) 的缩写，俗称脚手架。Vue CLI 是一个由 Vue 官方提供的、快速生成 Vue 工程化项目的工具，可以快速搭建 Vue 开发环境以及创建对应的 Webpack 配置文件。在使用 Vue 开发大型应用时，往往需要考虑代码目录结构、项目结构和部署、热加载、单元测试等事情；如果每个项目都要手动完成这些工作，那无以效率比较低效，所以通常会使用一些脚手架工具来帮助完成这些事情。 版本区别Vue CLI 目前拥有两个版本，分别是 Vue CLI 2 和 Vue CLI 3，两者的区别如下： Vue CLI 3 提供了 vue ui 命令，提供了可视化配置，更加人性化 Vue CLI 3 是基于 Webpack 4 打造，Vue CLI 2 是基于 Webpack 3 打造 Vue CLI 3 的设计原则是 零配置，移除了配置文件根目录下的 build 和 config 等目录 Vue CLI 3 移除了 static 文件夹，新增了 public 文件夹，并且将 index.html 移动到 public 文件夹中 Vue CLI 2 安装12# 全局安装 Vue CLI 2$ npm install vue-cli -g Vue CLI 3 安装12# 全局安装 Vue CLI 3$ npm install @vue-cli -g 由于 Vue CLI 3 和 Vue CLI 2 使用了相同的 vue 命令，若之前安装过 Vue CLI 2，那么 Vue CLI 2 的命令会被覆盖掉。如果安装了 Vue CLI 3 后，仍然需要使用 Vue CLI 2 的 vue init 功能，可以全局安装一个桥接工具，命令如下： 12345# 全局安装桥接工具$ npm install -g @vue/cli-init# 桥接工具安装完成后，`vue init` 命令的运行效果将会跟 `vue-cli@2.x` 的命令相同$ vue init webpack my-project Vue 模块化开发在企业项目开发中，往往是使用脚手架进行模块化开发，因此需要提前安装好 Vue CLI 脚手架。 创建 Vue 项目初始化项目Vue CLI 脚手架使用 webpack 模板初始化一个名为 vue-demo 的 Vue 项目，命令如下： 1$ vue init webpack vue-demo 项目结构 构建项目 启动项目 1$ npm run dev 项目启动后，浏览器打开 http://localhost:8080 即可以访问项目。 打包项目 1$ npm run build Vue 单文件组件Vue 单文件组件由三个部分组成： Template：HTML 模板 Script:vue：Vue 实例配置 Style：CSS 样式 12345678910111213141516171819202122&lt;template&gt; &lt;div class=\"hello\"&gt; &lt;h1&gt;{{ msg }}&lt;/h1&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { name: \"HelloWorld\", data() { return { msg: \"Welcome to Your Vue.js App\", }; },};&lt;/script&gt;&lt;style scoped&gt;h1, h2 { font-weight: normal;}&lt;/style&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"初探前端框架 Vue2 之三","url":"/posts/b6dfff10.html","text":"大纲 初探前端框架 Vue2 之一 初探前端框架 Vue2 之二 初探前端框架 Vue2 之三 初探前端框架 Vue2 之四 监听器（watch）监听器介绍watch 属性可以监听一个值的变化，从而做出相应的反应（渲染）。 监听器使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;ul&gt; &lt;li&gt;西游记：价格 {{xyjPrice}}，数量： &lt;input type=\"number\" v-model=\"xyjNum\"&gt; &lt;/li&gt; &lt;li&gt;水浒传：价格 {{shzPrice}}，数量： &lt;input type=\"number\" v-model=\"shzNum\"&gt; &lt;/li&gt; &lt;li&gt;提示信息：{{msg}}&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { xyjPrice: 56, shzPrice: 47, xyjNum: 1, shzNum: 1, msg: '' }, watch: { // 监听 xyjNum 值的变化 xyjNum(newVal, oldVal) { if (newVal &gt;= 3) { this.msg = '库存不足'; this.xyjNum = 3; } else { this.msg = ''; } } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，当输入的西游记下单数量大于等于 3 时，页面会显示 库存不足 的提示信息。 过滤器（filters）过滤器介绍过滤器不会改变真正的 data，而只是改变渲染的结果，并返回过滤后的内容。在很多不同的业务场景下，过滤器都是有用的，比如尽可能保持 API 响应结果的干净，并在前端处理数据的格式。 提示 过滤器常用来处理文本格式化的操作 过滤器可以用在两个地方：双花括号插值 {{ }} 和 v-bind 指令中 过滤器使用局部过滤器使用局部过滤器注册在当前的 Vue 实例中，只有当前 Vue 实例可以使用。| 管道符号，表示使用后面的过滤器处理前面的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;table border=\"1px\" cellspacing=\"0\" width=\"200px\"&gt; &lt;tr align=\"center\"&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;性别&lt;/th&gt; &lt;/tr&gt; &lt;tr align=\"center\" v-for=\"user in userList\"&gt; &lt;td&gt;{{user.id}}&lt;/td&gt; &lt;td&gt;{{user.name}}&lt;/td&gt; &lt;!-- 使用性别过滤器 --&gt; &lt;td&gt;{{user.gender | genderFilters}}&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { userList: [ { id: 1, name: 'Jack', gender: 1 }, { id: 2, name: 'Amy', gender: 0 } ] }, filters: { // 注册性别过滤器 genderFilters(val) { if (val === 1) { return \"男\"; } else { return \"女\"; } } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，当使用局部定义的性别过滤器后，页面渲染后会显示过滤后得到的性别。 全局过滤器使用全局过滤器注册在全局，可以在当前 Vue 实例之外使用。| 管道符号，表示使用后面的过滤器处理前面的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body style=\"margin: 100px;\"&gt; &lt;div id=\"app\"&gt; &lt;table border=\"1px\" cellspacing=\"0\" width=\"200px\"&gt; &lt;tr align=\"center\"&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;性别&lt;/th&gt; &lt;/tr&gt; &lt;tr align=\"center\" v-for=\"user in userList\"&gt; &lt;td&gt;{{user.id}}&lt;/td&gt; &lt;td&gt;{{user.name}}&lt;/td&gt; &lt;!-- 使用性别过滤器 --&gt; &lt;td&gt;{{user.gender | genderFilters}}&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; // 在创建 Vue 实例之前注册全局过滤器 Vue.filter('genderFilters', function (val) { if (val === 1) { return \"男\"; } else { return \"女\"; } }); let app = new Vue({ el: \"#app\", data: { userList: [ { id: 1, name: 'Jack', gender: 1 }, { id: 2, name: 'Amy', gender: 0 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，当使用全局定义的性别过滤器后，页面渲染后会显示过滤后得到的性别。 计算属性（computed）计算属性介绍若某些渲染结果是基于已有数据实时计算出来的，那么可以利用 Vue 的计算属性（computed）来实现。 计算属性使用123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;ul&gt; &lt;li&gt;西游记：价格 {{xyjPrice}}，数量： &lt;input type=\"number\" v-model=\"xyjNum\"&gt; &lt;/li&gt; &lt;li&gt;水浒传：价格 {{shzPrice}}，数量： &lt;input type=\"number\" v-model=\"shzNum\"&gt; &lt;/li&gt; &lt;li&gt;总价：{{totalPrice}}&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { xyjPrice: 56, shzPrice: 47, xyjNum: 1, shzNum: 1 }, computed: { // 实时计算 totalPrice totalPrice() { return this.xyjPrice * this.xyjNum + this.shzPrice * this.shzNum; } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，只要 totalPrice 依赖的属性发生了变化，就会重新计算 totalPrice 的值。 组件化在大型应用开发的时候，页面可以划分成很多部分。往往不同的页面，也会有相同的部分，例如可能会有相同的头部导航。但是如果每个页面都独自开发，这无疑增加了开发的成本。所以一般会把页面的不同部分拆分成独立的组件，然后在不同页面就可以共享这些组件，避免重复开发。在 Vue 里，所有的 Vue 实例都是组件，通常一个应用会以一棵嵌套的组件树的形式来组织（如下图）。例如，可能会有页头、侧边栏、内容区等组件，每个组件又包含了其它的像导航链接、博文之类的组件。 全局组件通过 Vue 的 component() 函数可以定义一个全局组件，component() 函数的第一个参数是组件名称，第二个参数是组件的参数。 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;!-- 使用已定义的全局组件 --&gt; &lt;counter&gt;&lt;/counter&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; // 在创建 Vue 实例之前，全局注册一个组件 Vue.component(\"counter\", { template: `&lt;button v-on:click=\"count++\"&gt;点击了 {{count}} 次&lt;/button&gt;`, data() { return { count: 1 } } }); let app = new Vue({ el: \"#app\" }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，每点击一次按钮，都会记录显示点击的总次数。 组件其实也是一个 Vue 实例，因此它在定义时也会接收 data、methods、生命周期函数等 与普通 Vue 实例不同的是，组件不会与页面的元素绑定，否则就无法复用了，因此没有 el 属性 由于组件渲染需要 HTML 模板，所以增加了 template 属性，值就是 HTML 模板的内容 全局组件定义完成后，任何 Vue 实例都可以直接在 HTML 中通过组件名称来使用组件 data 必须是一个函数，不再是一个对象，因此每个实例可以维护一份被返回对象的独立的拷贝。否则重复引用同一个组件时，数据会互相影响 局部组件通过 Vue 的 components 属性可以定义一个局部组件，components 就是当前 Vue 实例子组件的集合。特别注意，局部组件只能在当前 Vue 实例中使用。 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;!-- 使用已定义的局部组件 --&gt; &lt;counter&gt;&lt;/counter&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", components: { // 注册局部组件 'counter': { template: `&lt;button v-on:click=\"count++\"&gt;点击了 {{count}} 次&lt;/button&gt;`, data() { return { count: 1 } } } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下，每点击一次按钮，都会记录显示点击的总次数。 组件复用定义好全局组件或局部组件后，在同一个 Vue 实例（页面）中可以任意重复使用多次。 特别注意 注册全局组件或局部组件时，data 必须是一个函数，不再是一个对象，因此每个实例可以维护一份被返回对象的独立的拷贝。否则重复引用同一个组件时，数据会互相影响。 1234567891011121314151617181920212223242526272829303132333435&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;!-- 重复使用已定义的全局组件 --&gt; &lt;counter&gt;&lt;/counter&gt; &lt;counter&gt;&lt;/counter&gt; &lt;counter&gt;&lt;/counter&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; // 在创建 Vue 实例之前，全局注册一个组件 Vue.component(\"counter\", { template: `&lt;button v-on:click=\"count++\"&gt;点击了 {{count}} 次&lt;/button&gt;`, data() { return { count: 1 } } }); let app = new Vue({ el: \"#app\" }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 生命周期和钩子函数每个 Vue 实例在被创建时都要经过一系列的初始化过程：创建实例，装载模板，渲染模板等等。Vue 为生命周期中的每个状态都设置了钩子函数（监听函数）。每当 Vue 实例处于不同的生命周期时，对应的钩子函数就会被触发调用。 生命周期生命周期图示下图展示了 Vue 实例的生命周期。开发者不需要立马弄明白所有的东西，不过随着不断学习和使用，它的参考价值会越来越高。 钩子函数钩子函数介绍 beforeCreated：在使用 Vue 时都要进行实例化，因此该函数就是在 Vue 实例化时调用，也可以将它理解为初始化函数比较方便一点，在 Vue 1.0 版本时，这个函数的名字就是 init created：在创建 Vue 实例之后进行调用 beforeMount：页面加载完成，没有渲染，例如此时页面还是会显示类似 {{name}} 的内容 mounted：可以将它理解为原生 JS 中的 window.onload=function(){}，或许也可以理解为 JQuery 中的 $(document).ready(function(){})，它就是在 DOM 文档渲染完毕之后将要执行的函数，该函数在 Vue 1.0 版本中名字为 compiled，此时页面中的 {{name}} 已被渲染成 张三 beforeDestroy：该函数将在销毁实例前进行调用 destroyed：该函数将在销毁实例后进行调用 beforeUpdate：该函数将在组件更新之前调用 updated：该函数将在组件更新之后调用 钩子函数使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;span id=\"num\"&gt;{{num}}&lt;/span&gt; &lt;button v-on:click=\"num++\"&gt;点赞&lt;/button&gt; &lt;h2&gt; {{name}}，有 {{num}} 个人点赞。 &lt;/h2&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { name: \"张三\", num: 10 }, methods: { show() { return this.name; }, add() { this.num++; } }, beforeCreate() { console.log(\"=========beforeCreate=============\"); console.log(\"数据模型未加载: \" + this.name, this.num); console.log(\"方法未加载: \" + this.show); console.log(\"html 模板未加载: \" + document.getElementById(\"num\")); }, created: function () { console.log(\"=========created=============\"); console.log(\"数据模型已加载: \" + this.name, this.num); console.log(\"方法已加载: \" + this.show()); console.log(\"html 模板已加载: \" + document.getElementById(\"num\")); console.log(\"html 模板未渲染: \" + document.getElementById(\"num\").innerText); }, beforeMount() { console.log(\"=========beforeMount=============\"); console.log(\"html 模板未渲染: \" + document.getElementById(\"num\").innerText); }, mounted() { console.log(\"=========mounted=============\"); console.log(\"html 模板已渲染: \" + document.getElementById(\"num\").innerText); }, beforeUpdate() { console.log(\"=========beforeUpdate=============\"); console.log(\"数据模型已更新: \" + this.num); console.log(\"html 模板未更新: \" + document.getElementById(\"num\").innerText); }, updated() { console.log(\"=========updated=============\"); console.log(\"数据模型已更新: \" + this.num); console.log(\"html 模板已更新: \" + document.getElementById(\"num\").innerText); } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码运行后，浏览器控制台的日志输出如下，在页面中每点赞一次，都会记录显示点赞的总次数。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"初探前端框架 Vue2 之二","url":"/posts/919c7e37.html","text":"大纲 初探前端框架 Vue2 之一 初探前端框架 Vue2 之二 初探前端框架 Vue2 之三 初探前端框架 Vue2 之四 Vue 指令介绍什么是指令 指令（Directives）是带有 v- 前缀的特殊特性 指令特性的预期值是：单个 JavaScript 表达式 指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM（视图）。 插值表达式花括号 格式：{{表达式}} 描述： 花括号 {{ }} 只能写在 HTML 的标签体内 表达式支持 JS 语法，可以调用 JS 内置函数（必须有返回值） 表达式必须有返回结果，例如 1 + 1，没有结果的表达式不允许使用，例如 let a = 1 + 1 是不合法的表达式 可以直接指定 Vue 实例中定义的数据或函数 插值闪烁使用 {{ }} 方式在网速较慢时会出现问题。在数据未加载完成时，页面会显示出原始的 {{ }} 内容，页面加载完毕后才会显示正确的数据，该现象称为 插值闪烁。Chrome 浏览器可以将网速调慢一些（如下图），然后刷新页面，这样就可以重现 插值闪烁 现象。 v-text 和 v-html 指令为了解决 插值闪烁 的问题，可以使用 v-text 和 v-html 指令来替代 {{ }} v-text：将数据输出到标签内部，如果输出的数据有 HTML 代码，会作为普通文本输出 v-html：将数据输出到标签内部，如果输出的数据有 HTML 代码，会被渲染后再输出 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;span v-html=\"code\"&gt;&lt;/span&gt; &lt;br&gt; &lt;span v-text=\"code\"&gt;&lt;/span&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { code: \"&lt;h1&gt;Hello World&lt;/h1&gt;\" } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码运行后的效果如下，即使是网速较低的时候，也不会出现插值闪烁现象；当没有数据时，会显示空白或者默认数据。 v-bind 指令HTML 标签的属性不能使用花括号 {{ }} 的形式来绑定，但可以使用 v-bind 指令给 HTML 标签的属性绑定值；而且在将 v-bind 指令用于 class 和 style 时，Vue 做了专门的增强。 绑定 class使用 v-bind 指令绑定 HTML 标签的 class。 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;span v-bind:class=\"{'active': isActive, 'text-danger': hasError}\"&gt;Hello World&lt;/span&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { isActive: true, hasError: true } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 绑定 style使用 v-bind 指令绑定 HTML 标签的 style。 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;span v-bind:style=\"{'color': fontColor, 'font-size': fontSize}\"&gt;Hello Vue&lt;/span&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { fontColor: 'red', fontSize: '30px' } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 绑定 attribute使用 v-bind 指令绑定 HTML 标签的 attribute（属性）。 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;a v-bind:href=\"link\"&gt;Baidu&lt;/a&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { link: 'https://www.baidu.com' } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 绑定其他任意属性使用 v-bind 指令绑定 HTML 标签的其他任意属性。 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;span v-bind:user=\"userName\"&gt;Hello World&lt;/span&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { userName: 'Jack' } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-bind 指令支持缩写v-bind 指令支持缩写，例如 v-bind:href 可以缩写为 :href。 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;a :href=\"link\"&gt;Baidu&lt;/a&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { link: 'https://www.baidu.com' } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-model 指令v-model 指令介绍上述的 v-text、v-html、v-bind 可以看做是单向绑定，模型变化会引起视图变化（渲染），但是反过来就不行。而 v-model 指令是双向绑定，模型（Model）与视图（View）之间会互相影响。既然是双向绑定，一定是在视图中可以修改数据，这样就限定了视图的 HTML 标签类型。目前 v-model 的可使用标签有： radio：单选框 checkbox：多选框 select：下拉列表 input：单行输入框 textarea：多行文本输入框 components：Vue 中的自定义组件 基本上除了最后一项，其它都是表单的输入项。 v-model 指令使用12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;label&gt;精通的语言：&lt;/label&gt;&lt;br&gt; &lt;input type=\"checkbox\" v-model=\"language\" value=\"java\"&gt; Java&lt;br&gt; &lt;input type=\"checkbox\" v-model=\"language\" value=\"php\"&gt; PHP&lt;br&gt; &lt;input type=\"checkbox\" v-model=\"language\" value=\"c++\"&gt; C++&lt;br&gt; &lt;input type=\"checkbox\" v-model=\"language\" value=\"golang\"&gt; Golang&lt;br&gt; &lt;label&gt;选中的语言：&lt;/label&gt;&lt;br&gt; {{language.join(' , ')}} &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { language: [] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 多个 checkBox 对应一个 Model 时，Model 的类型是一个数组；单个 checkbox 时，Model 的类型是 boolean select 单选对应的值是字符串类型，多选对应的值是数组类型 radio 对应的值是 input 标签的 value 值 text 和 textarea 对应值是字符串类型 代码运行效果 使用 v-model 指令，上述 HTML 代码运行后的效果如下： v-on 指令v-on 指令介绍v-on 指令用于给页面标签绑定事件（如点击事件）。 v-on 指令中可以写 JS 片段，也可以指定在 Vue 实例中定义的函数名称，语法为：v-on:事件名=\"JS 片段或函数名称\" v-on 指令支持缩写，v-on:click='add' 可以缩写为 @click='add' v-on 指令使用12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;button v-on:click=\"number++\"&gt;点赞&lt;/button&gt; &lt;button @click=\"cancel\"&gt;取消点赞&lt;/button&gt; &lt;h2&gt;有 {{number}} 个人点赞&lt;/h2&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: '#app', data: { number: 0 }, methods: { cancel() { if (this.number &gt; 0) { this.number--; } } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-on 指令的事件修饰符事件修饰符介绍为了阻止事件冒泡，在事件处理的代码中调用 event.preventDefault() 或 event.stopPropagation() 是非常常见的需求。尽管可以在函数中轻松实现这一点，但更好的方式是让函数只拥有纯粹的数据逻辑，而不是去处理 DOM 事件细节。为了解决这个问题，Vue 为 v-on 指令提供了事件修饰符，而修饰符是由点开头的指令后缀来表示。 .stop：阻止事件冒泡到父标签 .prevent：阻止默认事件发生 .capture：使用事件捕获模式 .self：只有标签自身触发事件才执行（冒泡或捕获的都不执行） .once：只执行一次 事件修饰符使用123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;div style=\"border: 1px solid red; padding: 20px;\" v-on:click=\"hello\"&gt; 大的 Div &lt;!-- 阻止事件冒泡 --&gt; &lt;div style=\"border: 1px solid blue; padding: 20px;\" v-on:click.stop=\"hello\"&gt; 小的 Div&lt;br /&gt; &lt;!-- 阻止默认事件和事件冒泡 --&gt; &lt;a href=\"http://www.baidu.com\" v-on:click.prevent.stop=\"hello\"&gt;跳转百度&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: '#app', data: { number: 0 }, methods: { hello() { console.log(\"点击了\"); } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-on 指令的按键修饰符按键修饰符介绍在监听键盘事件时，往往需要检查常见的键值。Vue 允许为 v-on 指令在监听键盘事件时添加按键修饰符： 12&lt;!-- 只有在 `keyCode` 是 13 时才调用 `submit()` --&gt;&lt;input v-on:keyup.13=\"submit\"&gt; 由于记住所有的 keyCode 比较困难，所以 Vue 为最常用的按键提供了别名： 12345&lt;!-- 只有在按下回车键时才调用 `submit()` --&gt;&lt;input v-on:keyup.enter=\"submit\"&gt;&lt;!-- 缩写的语法 --&gt;&lt;input @keyup.enter=\"submit\"&gt; 全部的按键别名如下： .enter .tab .delete（捕获” 删除” 和” 退格” 键） .esc .space .up .down .left .right 按键修饰符使用1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;span&gt;输入数字：&lt;/span&gt;&lt;input text=\"text\" v-model=\"number\" v-on:keyup.up=\"number+=2\" v-on:keyup.down=\"number-=2\"&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: '#app', data: { number: 0 } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 组合按键的使用可以用如下修饰符来实现仅在按下相应按键时，才触发鼠标或键盘事件的监听器。 .ctrl .alt .shift 12345&lt;!-- Alt + C --&gt;&lt;input v-on:keyup.alt.67=\"clear\"&gt;&lt;!-- Ctrl + Click --&gt;&lt;div v-on:click.ctrl=\"doSomething\"&gt;Do something&lt;/div&gt; v-for 指令v-for 指令介绍通过遍历数据来渲染页面是非常常见的需求，在 Vue 中可以通过 v-for 指令来实现。 v-for 指令使用遍历数组语法：v-for=\"item in items\" items：要遍历的数组，需要在 Vue 实例的 data 中定义好 item：迭代得到的当前正在遍历的元素 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;ul&gt; &lt;li v-for=\"user in users\"&gt; {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { users: [ { name: '柳岩', gender: '女', age: 23 }, { name: '刘亦菲', gender: '女', age: 28 }, { name: '古力娜扎', gender: '女', age: 26 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： 数组下标若希望在遍历数组时，获取当前数组元素的下标，可以指定第二个参数。 语法：v-for=\"(item, index) in items\" items：要遍历的数组，需要在 Vue 实例的 data 中定义好 item：迭代得到的当前正在遍历的元素 index：迭代到的当前元素的索引，从 0 开始 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;ul&gt; &lt;li v-for=\"(user, index) in users\"&gt; 第 {{index+1}} 个女明星: {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { users: [ { name: '柳岩', gender: '女', age: 23 }, { name: '刘亦菲', gender: '女', age: 28 }, { name: '古力娜扎', gender: '女', age: 26 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： 遍历对象v-for 指令除了可以迭代数组，还可以迭代对象。语法如下： v-for=\"value in object\"，得到的是对象的属性值 v-for=\"(value, key) in object\"，得到的第一个是对象的属性值，第二个是对象的属性名 v-for=\"(value, key, index) in object\"，得到的第一个是对象的属性值，第二个是对象的属性名，第三个是索引（从 0 开始） 1234567891011121314151617181920212223242526272829&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;ul&gt; &lt;li v-for=\"(value, key, index) in user\"&gt; 第 {{index+1}} 个属性: {{key}} - {{value}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { user: { name: '柳岩', gender: '女', age: 23 } } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： 遍历优化遍历数据时，建议都加上 v-bind:key 指令来区分不同的数据（标识每一个元素的唯一特征），这样 Vue 就可以使用” 就地复用” 策略有效地提高渲染效率。 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;ul&gt; &lt;!-- 使用 v-bind 指令指定 key --&gt; &lt;li v-for=\"user in users\" v-bind:key=\"user.id\"&gt; {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { users: [ { id: 1, name: '柳岩', gender: '女', age: 23 }, { id: 2, name: '刘亦菲', gender: '女', age: 28 }, { id: 3, name: '古力娜扎', gender: '女', age: 26 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 若遍历的数据（数组或者对象）没法通过唯一标识来区分时，可以直接使用 index 索引来作为 key。 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;ul&gt; &lt;!-- 使用 v-bind 指令指定 key --&gt; &lt;li v-for=\"(user, index) in users\" v-bind:key=\"index\"&gt; {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { users: [ { name: '柳岩', gender: '女', age: 23 }, { name: '刘亦菲', gender: '女', age: 28 }, { name: '古力娜扎', gender: '女', age: 26 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 最佳实践 如果 items 是普通数组，可以使用 index 作为每个元素的唯一标识 如果 items 是对象数组，可以使用 item.id 作为每个元素的唯一标识 v-if 指令v-if 指令介绍v-if 指令，用于条件判断。当得到结果为 true 时，所在的标签才会被渲染。 v-if 指令使用1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;button v-on:click=\"show = !show\"&gt;切换显示模式&lt;/button&gt; &lt;h1 v-if=\"show\"&gt;Hello World&lt;/h1&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { show: true } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 与 v-for 结合使用当 v-if 和 v-for 指令同时使用时，v-for 指令的优先级更高。也就是说，Vue 会先遍历数据，然后再判断条件。 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;ul&gt; &lt;li v-for=\"(user, index) in users\" v-if=\"user.gender == '女'\"&gt; 第 {{index+1}} 个明星: {{user.name}} - {{user.gender}} - {{user.age}} &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { users: [ { name: '柳岩', gender: '女', age: 23 }, { name: '刘亦菲', gender: '女', age: 28 }, { name: '刘德华', gender: '男', age: 60 } ] } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： v-show 指令v-show 指令介绍v-show 指令，也用于条件判断，当得到结果为 true 时，所在的标签才会被显示。v-show 与 v-if 指令不同的地方在于，当结果为 false 时，v-show 指令是通过添加 CSS 样式 style=\"display: none\" 来隐藏标签内容的。 v-show 指令使用1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;button v-on:click=\"show = !show\"&gt;切换显示模式&lt;/button&gt; &lt;h1 v-show=\"show\"&gt;Hello World&lt;/h1&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { show: true } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-else 与 v-else-if 指令v-else 指令必须紧跟在带 v-if 或者 v-else-if 指令的标签的后面，否则它将不会被识别。 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;button v-on:click=\"random = Math.random()\"&gt;生成随机数&lt;/button&gt; &lt;p&gt;&lt;/p&gt; &lt;h3&gt;{{random}}&lt;/h3&gt; &lt;h2 v-if=\"random &gt;= 0.75\"&gt; &amp;gt;= 0.75 &lt;/h2&gt; &lt;h2 v-else-if=\"random &gt;= 0.5\"&gt; &amp;gt;= 0.5 &lt;/h2&gt; &lt;h2 v-else-if=\"random &gt;= 0.2\"&gt; &amp;gt;= 0.2 &lt;/h2&gt; &lt;h2 v-else&gt; &amp;lt; 0.2 &lt;/h2&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; let app = new Vue({ el: \"#app\", data: { random: 1 } }) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 上述 HTML 代码的运行效果如下： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"初探前端框架 Vue2 之一","url":"/posts/7da7d638.html","text":"大纲 初探前端框架 Vue2 之一 初探前端框架 Vue2 之二 初探前端框架 Vue2 之三 初探前端框架 Vue2 之四 前言MVVM 思想 M：即 Model（模型），包括数据和一些基本操作 V：即 View（视图），页面的渲染结果 VM：即 View-Model，模型与视图间的双向操作（无需开发人员干涉） 在 MVVM 之前，开发人员从后端获取需要的数据模型，然后要通过 DOM 操作 Model 渲染到 View 中。当用户操作视图后，开发人员还需要通过 DOM 获取 View 中的数据，然后同步到 Model 中。而 MVVM 中的 VM 要做的事情就是把 DOM 操作完全封装起来，开发人员不用再关心 Model 和 View 之间是如何互相影响的。这样可以将开发人员从繁琐的 DOM 操作中解放出来，把关注点放在如何操作 Model 上。 一旦 Model 发生了改变，View 上自然就会呈现出来 当用户修改了 View，Model 中的数据也会跟着改变 Vue 简介Vue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与现代化的工具链以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。更多的 Vue 介绍可参考 Vue v2 中文官网、Vue GitHub 项目。 Vue 安装Script 方式安装可以直接下载 Vue 的 JS 文件，然后使用 &lt;script&gt; 标签引入，Vue 会被注册为一个全局变量。 CDN 方式安装12345&lt;!-- 开发环境 --&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt;&lt;!-- 生产环境 --&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10\"&gt;&lt;/script&gt; 若使用了原生 ES Modules，这里也有一个兼容 ES Module 的构建文件： 123&lt;script type=\"module\"&gt; import Vue from 'https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.esm.browser.js'&lt;/script&gt; NPM 方式安装NPM 安装步骤初始化 NodeJs 项目，会自动生成 package.json 和 package-lock.json 文件 1$ npm install -y 给 NodeJs 项目安装 Vue，安装完成后项目下会多出 node_modules 目录 12345# 安装最新版本（适用于开发环境）$ npm install vue# 安装指定版本（适用于生产环境）$ npm install vue@2.7.10 不同构建版本的说明在 NPM 包的 dist 目录你将会找到很多不同的 Vue.js 构建版本。这里列出了它们之间的差别： UMD CommonJS ES Module (基于构建工具使用) ES Module (直接用于浏览器) 完整版 vue.js vue.common.js vue.esm.js vue.esm.browser.js 只包含运行时版 vue.runtime.js vue.runtime.common.js vue.runtime.esm.js - 完整版 (生产环境) vue.min.js - - vue.esm.browser.min.js 只包含运行时版 (生产环境) vue.runtime.min.js - - - 完整版：同时包含编译器和运行时的版本。 编译器：用来将模板字符串编译成为 JavaScript 渲染函数的代码。 运行时：用来创建 Vue 实例、渲染并处理虚拟 DOM 等的代码。基本上就是除去编译器的其它一切。 UMD：UMD 版本可以通过 &lt;script&gt; 标签直接用在浏览器中。CDN 的 https://cdn.jsdelivr.net/npm/vue@2.7.10 默认文件就是运行时 + 编译器的 UMD 版本 (vue.js)。 CommonJS：CommonJS 版本用来配合老的打包工具比如 Browserify 或 Webpack 1。这些打包工具的默认文件 (pkg.main) 是只包含运行时的 CommonJS 版本 (vue.runtime.common.js)。 ES Module：从 2.6 开始 Vue 会提供两个 ES Modules (ESM) 构建文件： 为打包工具提供的 ESM：为诸如 Webpack 2 或 Rollup 提供的现代打包工具。ESM 格式被设计为可以被静态分析，所以打包工具可以利用这一点来进行 tree-shaking 并将用不到的代码排除出最终的包。为这些打包工具提供的默认文件 (pkg.module) 是只有运行时的 ES Module 构建 (vue.runtime.esm.js)。 为浏览器提供的 ESM (2.6+)：用于在现代浏览器中通过 &lt;script type=\"module\"&gt; 直接导入。 Vue 快速入门Vue 简单使用说明 使用 Vue 实例管理 DOM DOM 与数据 / 事件等进行相关绑定 开发者只需要关注数据、事件等处理，无需关心视图如何进行更新 声明式渲染123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Vue&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;h1&gt; Hello {{name}} &lt;/h1&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { name: \"Jack\" } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 首先通过 new Vue() 来创建 Vue 实例 然后 Vue 的构造函数接收一个对象，对象中有一些属性 el：是 element 的缩写，通过 id 选中要渲染的页面标签，在本案例里选中了一个 DIV 标签 data：数据，数据是一个对象，里面有很多自定义的属性，都可以渲染到视图中 name：指定了一个 name 属性 最后在页面的 h1 标签中，通过 {{name}} 的方式，来渲染刚刚定义的 name 属性 代码运行效果 使用 Vue 的声明式渲染，上述 HTML 代码运行后的效果如下，打开浏览器的 JavaScript 控制台，通过执行 app.name='Peter' 来改变模型，将看到视图会相应地更新 单向绑定单向绑定，也就是模型变化会引起视图变化（渲染），但是反过来就不行。 v-bind 指令使用 v-bind 指令绑定 HTML 标签的 attribute（属性） 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;span v-bind:title=\"message\"&gt; 鼠标悬停几秒钟，查看此处动态绑定的提示信息！ &lt;/span&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: '#app', data: { message: '页面加载于 ' + new Date().toLocaleString() } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 双向绑定双向绑定，也就是模型变化会引起视图变化（渲染），反之亦然。 v-model 指令使用 v-model 指令进行双向绑定 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;label&gt;Please input a number: &lt;/label&gt;&lt;input type=\"text\" v-model=\"number\" &gt; &lt;h1&gt; Hello {{name}}, you {{number}} have books&lt;/h1&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { name: \"Jack\", number: \"1\" } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 使用 v-model 指令进行双向绑定，上述 HTML 代码运行后的效果如下，页面上显示的数字会随输入框的内容一起变化 事件绑定v-on 指令使用 v-on 指令绑定点击事件 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;button v-on:click=\"number++\"&gt;Add Books&lt;/button&gt; &lt;h1&gt; Hello {{name}}, you have {{number}} books&lt;/h1&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { name: \"Jack\", number: \"1\" } }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 或者在 Vue 实例中定义方法 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt; &lt;button v-on:click=\"add\"&gt;Add Books&lt;/button&gt; &lt;h1&gt; Hello {{name}}, you have {{number}} books&lt;/h1&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.7.10/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; let app = new Vue({ el: \"#app\", data: { name: \"Jack\", number: \"1\" }, methods: { add () { this.number++; } }, }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 代码运行效果 使用 Vue 的点击事件绑定，上述 HTML 代码运行后的效果如下，点击按钮后，页面上显示的数字会递增 Vue 开发工具VSCode 插件 Vetur - Vue 语法高亮、智能感知、Emmet 等 Vue 3 Snippets - Vue2、Vue3 代码片段快速生成 Chrome 浏览器调试插件应用商店安装访问 Chrome 应用商店（依赖科学上网），然后在搜索框搜索 Vue Devtools，最后直接点击插件进行安装即可。 源码编译安装1234567891011# 下载源码$ git clone https://github.com/vuejs/vue-devtools# 进入源码目录$ cd vue-devtools# 安装依赖$ npm install# 编译打包$ npm run build 编译打包成功后会在 shells 下生成 chrome 文件夹，此文件夹就是用来存放编译打包生成的 Chrome 扩展程序。 打开 Chrome 浏览器 &gt; 更多工具 &gt; 扩展程序 &gt; 打开开发者模式，点击加载已解压的扩展程序，找到刚才生成的 chrome 文件夹，选择 vue-devtools &gt; shells &gt; chrome 放入，安装成功后的截图如下： 插件使用说明Chrome 浏览器打开 Vue 项目的页面后，按下快捷键 F12，点击选择 vue 标签页就可以开始使用插件了 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"Bucket4j 限流入门教程之一","url":"/posts/2885bf23.html","text":"前言限流概述在开发高并发系统时可以用三把利器来保护系统：缓存、降级和限流。缓存的目的是提升系统访问速度和增大系统处理的容量，是抗高并发流量的 “银弹”；而降级是当服务出现问题或者影响到核心流程时，需要暂时将其屏蔽掉，待高峰过去之后或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询等，因此需要有一种手段来限制这些场景的并发 / 请求量，即限流。限流的目的是通过对并发访问 / 请求进行限速或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或友好的展示页）、排队或等待（比如秒杀、评论、下单等场景）、降级（返回兜底数据或默认数据）。主流的中间件都会有单机限流框架，一般支持两种限流模式：控制速率和控制并发。Spring Cloud Zuul 通过第三方扩展 spring-cloud-zuul-ratelimit 也可以支持限流，而 Spring Cloud Gateway 的限流实现可以看这里。常见的限流算法有漏桶和令牌桶，计数器也可以进行粗暴限流实现。对于限流算法，可以参考 Guava 中的 RateLimiter、Bucket4j、RateLimitJ 等项目的具体实现。 Bucket4j 介绍Bucket4j 是基于令牌桶算法的 Java 限流库，它主要用在 3 种场景： 限制比较重工作的速率 限制对 API 的访问速率 将限流作为定时器，例如有些场景限制你对服务提供方的调用速度，因此使用限流器作为定时器，定时按照约定速率调用服务提供方 Spring Boot 整合 Bucket4j本案例主要是简单演示如何在单机 Spring Boot 应用中使用 Bucket4j，使用的缓存组件是 Caffeine（JCache API），点击下载完整的案例代码。特别注意，在企业开发中，若 Spring Boot 应用是以集群的方式部署，则必须采用分布式缓存方案，具体的参考方案如下： Back-end Documentation page Async supported Optimized serialization Thin-client support Hazelcast bucket4j-hazelcast Yes Yes Planned Apache Ignite bucket4j-ignite Yes n/a Yes Inifinispan bucket4j-infinspan Yes Yes No Oracle Coherence bucket4j-coherence Yes Yes No 代码示例添加 Bucket4j + Spring Boot Starter + Caffeine 相关的 Maven 依赖 123456789101112131415161718192021222324252627282930313233343536373839&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.giffing.bucket4j.spring.boot.starter&lt;/groupId&gt; &lt;artifactId&gt;bucket4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;jcache&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.cache&lt;/groupId&gt; &lt;artifactId&gt;cache-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建缓存配置类，并添加 @EnableCaching 注解来启用缓存功能 12345@EnableCaching@Configurationpublic class Bucket4jCacheConfig {} 创建 Controller 类 123456789101112131415161718import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class TestController { @GetMapping(\"hello\") public ResponseEntity&lt;String&gt; hello() { return ResponseEntity.ok(\"Hello World\"); } @GetMapping(\"world\") public ResponseEntity&lt;String&gt; world() { return ResponseEntity.ok(\"Hello World\"); }} 创建主启动类 12345678@SpringBootApplicationpublic class Bucket4jApplication { public static void main(String[] args) { SpringApplication.run(Bucket4jApplication.class, args); }} 创建 application.yml 主配置文件 12345678910111213141516171819202122server: port: 8080spring: application: name: bucket4j-spring-boot-caffeine cache: cache-names: - buckets caffeine: spec: maximumSize=1000000,expireAfterAccess=3600s # 设置了名为buckets的缓存，过期时间为1h，容量为1000000bucket4j: enabled: true filters: - cache-name: buckets url: .* rate-limits: - bandwidths: - capacity: 2 time: 10 unit: seconds # 设置的rate-limits每10秒2个token Bucket4j 配置参数说明如下： bucket4j.enabled=true：启用 Bucket4j 的自动配置 bucket4j.filters.cache-name：从缓存中获取 API 密钥的 Bucket bucket4j.filters.url：表示应用速率限制的路径表达式，.* 表示拦截所有 URL bucket4j.filters.rate-limits.bandwidths：定义 Bucket4j 速率限制参数 代码测试正常请求接口的时候，服务端响应的结果如下： 12345$ curl -v -X GET 'http://127.0.0.1:8080/hello'&lt; HTTP/1.1 200&lt; X-Rate-Limit-Remaining: 1Hello World 当频繁请求接口的时候，服务端会返回 429 的 HTTP 状态码和 JSON 数据 { \"message\": \"Too many requests!\" }，如下所示： 12345$ curl -v -X GET 'http://127.0.0.1:8080/hello'&lt; HTTP/1.1 429&lt; X-Rate-Limit-Retry-After-Seconds: 2{ \"message\": \"Too many requests!\" } 自定义限流响应结果当触发限流条件时，Bucket4j 默认会返回 429 的 HTTP 状态码，同时返回 JSON 数据 { \"message\": \"Too many requests!\" } 给客户端。若需要自定义返回的数据内容，可以配置 http-response-body 参数，如下所示： 1234567891011bucket4j: enabled: true filters: - cache-name: buckets url: .* http-response-body: '{\"code\":429,\"data\":\"\",\"msg\":\"Too many requests!\"}' rate-limits: - bandwidths: - capacity: 2 time: 10 unit: seconds 参考博客 Rate Limiting a Spring API Using Bucket4j var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 java"},{"title":"Java 开发常用代码块之一","url":"/posts/677dbf04.html","text":"网络编程获取 IP 地址12345678910111213141516171819202122232425262728293031323334353637383940import cn.hutool.core.util.StrUtil;import javax.servlet.http.HttpServletRequest;/** * IP地址工具 */public class IPUtils { /** * 获取IP地址 * 如果使用Nginx等反向代理软件，不能通过request.getRemoteAddr()获取IP地址 * 如果使用了多级反向代理的话，X-Forwarded-For的值并不止一个，而是一串IP地址，X-Forwarded-For中第一个非unknown的有效IP字符串，则为真实IP地址 */ public static String getIpAddr(HttpServletRequest request) { String ip = null; try { ip = request.getHeader(\"x-forwarded-for\"); if (StrUtil.isEmpty(ip) || \"unknown\".equalsIgnoreCase(ip)) { ip = request.getHeader(\"Proxy-Client-IP\"); } if (StrUtil.isEmpty(ip) || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) { ip = request.getHeader(\"WL-Proxy-Client-IP\"); } if (StrUtil.isEmpty(ip) || \"unknown\".equalsIgnoreCase(ip)) { ip = request.getHeader(\"HTTP_CLIENT_IP\"); } if (StrUtil.isEmpty(ip) || \"unknown\".equalsIgnoreCase(ip)) { ip = request.getHeader(\"HTTP_X_FORWARDED_FOR\"); } if (StrUtil.isEmpty(ip) || \"unknown\".equalsIgnoreCase(ip)) { ip = request.getRemoteAddr(); } } catch (Exception e) { System.out.println(\"IPUtils ERROR \" + e.getLocalizedMessage()); } return ip; }} 正则表达式解析 URL通过正则表达式，获取 URL 中的协议、域名、端口、URI。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import cn.hutool.core.util.StrUtil;import java.util.HashMap;import java.util.Map;import java.util.regex.Matcher;import java.util.regex.Pattern;public class HttpUtil { public static final String HTTP_PROTOCOL = \"http://\"; public static final String HTTPS_PROTOCOL = \"https://\"; /** * 解析URL（包括协议、域名、端口、URI） * * @param url * @return */ public static Map&lt;String, String&gt; parseUrl(String url) { Map&lt;String, String&gt; map = new HashMap(4); try { Pattern pattern = Pattern.compile(\"(https?://)([^:^/]*)(:\\\\d*)?(.*)?\"); Matcher matcher = pattern.matcher(url); boolean findResult = matcher.find(); if (!findResult) { return map; } String protocol = matcher.group(1); String domain = matcher.group(2); String port = matcher.group(3); String uri = matcher.group(4); if (StrUtil.isBlank(port)) { if (HTTP_PROTOCOL.equals(protocol)) { port = \"80\"; } else if (HTTPS_PROTOCOL.equals(protocol)) { port = \"443\"; } else { port = \"unknown\"; } } else { port = port.replace(\":\", \"\"); } map.put(\"protocol\", protocol); map.put(\"domain\", domain); map.put(\"port\", port); map.put(\"uri\", uri); } catch (Exception e) { e.printStackTrace(); } return map; }} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 代码块"},{"title":"Debian 更换软件源","url":"/posts/f7ed6378.html","text":"Ubuntu 20.4 LTS 更换软件源 更换阿里云软件源 12345678# 备份配置文件# cp /etc/apt/sources.list /etc/apt/sources.list.bak# 清空配置文件内容# echo \"\" &gt; /etc/apt/sources.list# 编辑配置文件，添加以下内容# vi /etc/apt/sources.list 12345678910deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse 使阿里云软件源生效 12# 更新软件索引# apt-get update Debian 9（Stretch）更换软件源 更换阿里云软件源 12345678# 备份配置文件# cp /etc/apt/sources.list /etc/apt/backup.sources.list# 清空配置文件内容# echo \"\" &gt; /etc/apt/sources.list# 编辑配置文件，添加以下内容# vi /etc/apt/sources.list 12345678deb http://mirrors.aliyun.com/debian/ stretch main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch main non-free contribdeb http://mirrors.aliyun.com/debian-security stretch/updates maindeb-src http://mirrors.aliyun.com/debian-security stretch/updates maindeb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch-updates main non-free contribdeb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib 使阿里云软件源生效（必须） 12# 更新软件索引# apt-get update 更新软件和系统（非必须，请谨慎操作） 12345# 升级系统里的所有软件# apt-get upgrade# 升级系统版本# apt-get dist-upgrade 若是构建 Docker 镜像，那么在 Dockerfile 里可以使用以下指令 12345678910111213RUN cp /etc/apt/sources.list /etc/apt/backup.sources.list &amp;&amp; echo \"deb http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb-src http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update \\ &amp;&amp; apt-get -y upgrade \\ &amp;&amp; apt-get -y autoclean &amp;&amp; apt-get -y autoremove Debian 11（Bullseye）更换软件源 更换 163 软件源 12345678# 备份配置文件# cp /etc/apt/sources.list /etc/apt/backup.sources.list# 清空配置文件内容# echo \"\" &gt; /etc/apt/sources.list# 编辑配置文件，添加以下内容# vi /etc/apt/sources.list 12345678deb http://mirrors.163.com/debian/ bullseye main non-free contribdeb http://mirrors.163.com/debian/ bullseye-updates main non-free contribdeb http://mirrors.163.com/debian/ bullseye-backports main non-free contribdeb-src http://mirrors.163.com/debian/ bullseye main non-free contribdeb-src http://mirrors.163.com/debian/ bullseye-updates main non-free contribdeb-src http://mirrors.163.com/debian/ bullseye-backports main non-free contribdeb http://mirrors.ustc.edu.cn/debian-security/ stable-security main non-free contribdeb-src http://mirrors.ustc.edu.cn/debian-security/ stable-security main non-free contrib 使 163 软件源生效（必须） 12# 更新软件索引# apt-get update 更新软件和系统（非必须，请谨慎操作） 12345# 升级系统里的所有软件# apt-get upgrade# 升级系统版本# apt-get dist-upgrade 若是构建 Docker 镜像，那么在 Dockerfile 里可以使用以下指令 12345678910111213RUN cp /etc/apt/sources.list /etc/apt/sources.list.bak \\ &amp;&amp; echo \"deb http://mirrors.163.com/debian/ bullseye main non-free contrib\" &gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb http://mirrors.163.com/debian/ bullseye-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb http://mirrors.163.com/debian/ bullseye-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb-src http://mirrors.163.com/debian/ bullseye main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb-src http://mirrors.163.com/debian/ bullseye-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb-src http://mirrors.163.com/debian/ bullseye-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb http://mirrors.ustc.edu.cn/debian-security/ stable-security main non-free contrib\" &gt;&gt; /etc/apt/sources.list \\ &amp;&amp; echo \"deb-src http://mirrors.ustc.edu.cn/debian-security/ stable-security main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update \\ &amp;&amp; apt-get -y upgrade \\ &amp;&amp; apt-get -y autoclean &amp;&amp; apt-get -y autoremove var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"debian"},{"title":"C 语言开发常用代码块之一","url":"/posts/3b2974c1.html","text":"加载动态库加载动态链接库（.dll）下述示例代码，适用于 Windows 系统的 C 语言开发。 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;windows.h&gt;int main() { HINSTANCE hInstance; // 加载动态链接库 hInstance = LoadLibrary(\"./socketclient.dll\"); if (hInstance == NULL) { printf(\"LoadLibrary() 调用失败, ErrorCode: %d\", GetLastError()); return -1; } // 定义函数类型指针 typedef int (*CltSocketInit)(void** handle); // 调用动态链接库 CltSocketInit cltSocketInit = (CltSocketInit)GetProcAddress(hInstance, \"cltSocketInit\"); if (cltSocketInit != NULL) { void* handle = NULL; int result = cltSocketInit(&amp;handle); printf(\"result = %d\", result); } // 释放动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c语言 代码块"},{"title":"C 语言面向接口编程和多态","url":"/posts/1844a1fe.html","text":"数组指针数组类型的语法C 语言中的数组有自己特定的类型，可以通过 typedef 关键字定义数组类型，语法格式为：typedef type(name)[length];，例如： typedef int(MyIntArray)[3]; typedef char(MyCharArray)[3]; 数组指针类型的语法 数组指针类型用于指向一个数组 可以直接定义数组指针类型：typedef type(*name)[length]; 数组类型与数组指针类型的使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;stdio.h&gt;int main() { // 1. 定义数组类型（会分配内存空间） typedef int(MyArray)[3]; MyArray array; array[0] = 1; array[1] = 2; array[2] = 3; for (int i = 0; i &lt; 3; i++) { printf(\"array[%d] = %d\\n\", i, array[i]); } printf(\"\\n\"); // 2. 定义数组指针类型（不会分配内存空间） typedef int(*MyPointArray)[3]; int a[3]; MyPointArray pointArray; pointArray = &amp;a; // 将数组指针类型指向一个数组 (*pointArray)[0] = 11; (*pointArray)[1] = 22; (*pointArray)[2] = 33; for (int j = 0; j &lt; 3; j++) { printf(\"a[%d] = %d, \", j, a[j]); printf(\"(*pointArray)[%d] = %d\\n\", j, (*pointArray)[j]); } printf(\"\\n\"); // 3. 定义一个数组指针变量（不会分配内存空间） int(*pointArrayVar)[3]; int b[3]; pointArrayVar = &amp;b; // 将数组指针变量指向一个数组 (*pointArrayVar)[0] = 111; (*pointArrayVar)[1] = 222; (*pointArrayVar)[2] = 333; for (int n = 0; n &lt; 3; n++) { printf(\"b[%d] = %d, \", n, b[n]); printf(\"(*pointArrayVar)[%d] = %d\\n\", n, (*pointArrayVar)[n]); }} 程序运行的输出结果如下： 1234567891011array[0] = 1array[1] = 2array[2] = 3a[0] = 11, (*pointArray)[0] = 11a[1] = 22, (*pointArray)[1] = 22a[2] = 33, (*pointArray)[2] = 33b[0] = 111, (*pointArrayVar)[0] = 111b[1] = 222, (*pointArrayVar)[1] = 222b[2] = 333, (*pointArrayVar)[2] = 333 函数指针函数类型的语法C 语言中的函数有自己特定的类型，可以通过 typedef 关键字定义函数类型，语法格式为：typedef type (name)(parameter list);，例如： typedef int (f)(int, int); typedef void (p)(int); 函数指针类型的语法 函数指针类型用于指向一个函数 函数有三大要素：名称、参数、返回值，函数名是函数体的入口地址 可以通过函数类型定义函数指针类型: FuncType* pointer; 也可以直接定义函数指针类型：typedef type (*pointer)(parameter list); pointer：函数指针变量名 type：指向函数的返回值类型 parameter list：指向函数的参数类型列表 函数类型与函数指针类型的使用12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;int add(int a, int b) { return a + b;}int main() { // 1. 定义函数类型 typedef int (MyFuncType)(int a, int b); // 通过函数类型定义函数指针类型 MyFuncType* myFuncType = add; int result = myFuncType(1, 3); printf(\"%d + %d = %d\\n\", 1, 3, result); // 2. 定义一个函数指针类型（不会分配内存空间） typedef int (*MyFuncPointType)(int a, int b); // 加不加上\"&amp;\"符号都是可以的，如果加上了\"&amp;\"符号，可以解决C语言版本的兼容问题 // MyFuncPointType myFuncPointType = &amp;add; MyFuncPointType myFuncPointType = add; int result2 = myFuncPointType(4, 5); printf(\"%d + %d = %d\\n\", 4, 5, result2); // 3. 定义函数指针变量（会分配内存空间） int (*MyFuncPointVar)(int a, int b); MyFuncPointVar = add; int result3 = MyFuncPointVar(7, 9); printf(\"%d + %d = %d\\n\", 7, 9, result3); return 0;} 程序运行的输出结果如下： 1231 + 3 = 44 + 5 = 97 + 9 = 16 函数类型与函数指针作为函数参数函数类型作为函数参数当函数类型做为函数的参数传递给一个被调用函数，被调用函数就可以通过这个函数类型调用外部的函数，这就形成了回调函数。C 语言回调函数的本质是，提前做了一个协议的约定（把函数的参数、函数的返回值类型提前约定）。 1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;// 定义函数类型typedef int (MyFuncType)(int a, int b);int add(int a, int b) { return a + b;}int mult(int a, int b) { return a * b;}// 函数类型作为函数参数int callbackFunc(MyFuncType func) { return func(3, 6);}int main() { // 通过函数类型定义函数指针类型 MyFuncType* myFuncType = NULL; myFuncType = add; int result = callbackFunc(*myFuncType); printf(\"result = %d\\n\", result); myFuncType = mult; int result2 = callbackFunc(*myFuncType); printf(\"result = %d\\n\", result2); return 0;} 程序运行的输出结果如下： 12result = 9result = 18 函数指针作为函数参数当函数指针做为函数的参数传递给一个被调用函数，被调用函数就可以通过这个指针调用外部的函数，这就形成了回调函数。C 语言回调函数的本质是，提前做了一个协议的约定（把函数的参数、函数的返回值类型提前约定）。 a) 将 “函数的调用” 和 “函数的实现” 解耦 b) 可以模拟 C++ 的多态机制（提前布局 VPTR 指针和虚函数表，找虚函数入口地址来实现函数调用） 1234567891011121314151617181920212223242526272829#include &lt;stdio.h&gt;int add(int a, int b) { return a + b;}int mult(int a, int b) { return a * b;}// 函数指针做函数参数int callbackFunc(int (*MyFunc)(int a, int b)) { return MyFunc(3, 4);}int main() { // 定义函数指针变量 int (*myFuncVar)(int a, int b); myFuncVar = add; int result = callbackFunc(myFuncVar); printf(\"result = %d\\n\", result); myFuncVar = mult; int result2 = callbackFunc(myFuncVar); printf(\"result = %d\\n\", result2); return 0;} 程序运行的输出结果如下： 12result = 7result = 12 上述的 add、mult 函数都是写在同一个源文件当中，假如 add 函数是一个库中的函数，此时就只有使用回调了，通过函数指针参数将外部函数地址传入来实现调用。日后如果库里面的 add 函数的代码作了修改，也不必改动函数调用方的代码，就可以正常实现调用，便于程序的维护和升级。 DLL 动态链接库的使用下面将介绍 C/C++ 如何开发和调用一款 Socket 客户端的 DLL 动态链接库，该 DLL 主要实现了 Socket 客户端的初始化、报文发送、报文接收、资源释放等功能，第三方可以直接调用该 DLL 实现 Socket 通信。值得一提的是，本案例并没有真正完整地实现 Socket 客户端的底层代码，更多的是使用伪代码来模拟 Socket 客户端的通信。 运行环境说明这里给出的案例代码和操作步骤，只适用于 Windows 系统的 C/C++ 开发，且依赖 Visual Studio 开发工具，不适用于 Linux 系统的 C/C++ 开发。 DLL 项目的创建新建 DLL 项目 值得一提的是，通过 Visual Studio 创建 DLL（动态链接库）项目，源文件默认的后缀是 .cpp，如果项目使用的是 C 语言，则需要将自动生成的 dllmain.cpp、pch.cpp 的文件名改为 dllmain.c、pch.c。 编写 DLL 代码 创建 socketclient.c 源文件 socketclient.c 源文件的代码如下，其中 __declspec(dllexport) 的作用是将函数导出给 DLL 的调用方 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#include \"pch.h\"#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;// 定义函数指针类型，用于数据加密typedef int (*EncodeData)(unsigned char* in, int inlen, unsigned char* out, int* outlen);// 定义结构体typedef struct _Sck_Handle { char version[16]; char ip[16]; int port; unsigned char* p; int len; char* p2; EncodeData encodeCallback;} Sck_Handle;//客户端初始化__declspec(dllexport)int socketclient_init(void** handle) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL) { ret = -1; printf(\"function socketclient_init() err :%d check params == NULL err \\n\", ret); return ret; } tmpHandle = (Sck_Handle*)malloc(sizeof(Sck_Handle)); if (tmpHandle == NULL) { ret = -2; printf(\"function socketclient_init() err :%d malloc err \\n\", ret); return ret; } memset(tmpHandle, 0, sizeof(Sck_Handle)); strcpy(tmpHandle-&gt;version, \"1.0.0.1\"); strcpy(tmpHandle-&gt;ip, \"192.168.12.12\"); tmpHandle-&gt;port = 8081; //间接赋值 *handle = tmpHandle; return ret;}//客户端报文发送__declspec(dllexport)int socketclient_send(void* handle, unsigned char* buf, int buflen) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || buflen &lt;= 0) { ret = -2; printf(\"function socketclient_send() err :%d (handle == NULL || buf == NULL || buflen &lt;= 0 ) \\n\", ret); return ret; } tmpHandle = (Sck_Handle*)handle; if (tmpHandle-&gt;encodeCallback == NULL) { //明文发送 tmpHandle-&gt;len = buflen; tmpHandle-&gt;p = (unsigned char*)malloc(buflen); if (tmpHandle-&gt;p == NULL) { ret = -2; printf(\"function socketclient_send() err :%d malloc len:%d \\n\", ret, buflen); return ret; } memcpy(tmpHandle-&gt;p, buf, buflen); } else { //加密发送 unsigned char crypdata[4096]; int cryptdatalen = 4096; ret = tmpHandle-&gt;encodeCallback(buf, buflen, crypdata, &amp;cryptdatalen); if (ret != 0) { printf(\"function encodeCallback() err :%d \\n\", ret); return ret; } tmpHandle-&gt;len = cryptdatalen; tmpHandle-&gt;p = (unsigned char*)malloc(cryptdatalen); if (tmpHandle-&gt;p == NULL) { ret = -1; printf(\"function socketclient_send() err :%d malloc len:%d \\n\", ret, cryptdatalen); return ret; } memcpy(tmpHandle-&gt;p, crypdata, cryptdatalen); } return ret;}//客户端报文加密发送__declspec(dllexport)int socketclient_send_encode(void* handle, unsigned char* buf, int buflen, EncodeData encodeCallback) { int ret = 0; unsigned char cryptbuf[4096]; int cryptbuflen = 4096; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || encodeCallback == NULL) { ret = -1; printf(\"function socketclient_send_encode() err :%d (handle == NULL || buf == NULL || encodeCallback == NULL) \\n\", ret); return ret; } // 通过函数指针，执行数据的加密操作 ret = encodeCallback(buf, buflen, cryptbuf, &amp;cryptbuflen); if (ret != 0) { ret = -2; printf(\"function socketclient_send_encode() err :%d check encode_result == 0 err \\n\", ret); return ret; } tmpHandle = (Sck_Handle*)handle; tmpHandle-&gt;len = cryptbuflen; tmpHandle-&gt;p = (unsigned char*)malloc(cryptbuflen); if (tmpHandle-&gt;p == NULL) { ret = -3; printf(\"function socketclient_send_encode() err :%d malloc len:%d \\n\", ret, cryptbuflen); return ret; } //把加密的明文缓存到内存中 memcpy(tmpHandle-&gt;p, cryptbuf, cryptbuflen); return 0;}//客户端报文接收__declspec(dllexport)int socketclient_recv(void* handle, unsigned char* buf, int* buflen) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || buf == NULL || buflen == NULL) { ret = -2; printf(\"function socketclient_recv() err :%d (handle == NULL || buf == NULL || buflen == NULL ) \\n\", ret); return ret; } tmpHandle = (Sck_Handle*)handle; memcpy(buf, tmpHandle-&gt;p, tmpHandle-&gt;len); *buflen = tmpHandle-&gt;len; return ret;}//客户端资源释放__declspec(dllexport)int socketclient_destory(void* handle) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL) { return -1; } tmpHandle = (Sck_Handle*)handle; if (tmpHandle-&gt;p != NULL) { free(tmpHandle-&gt;p); //释放结构体成员域的指针所指向的内存空间 } free(tmpHandle); //释放结构体内存 handle = NULL; return 0;}//设置加密回调函数__declspec(dllexport)int socketclient_set_encode_callback(void* handle, EncodeData encodeCallback) { int ret = 0; Sck_Handle* tmpHandle = NULL; if (handle == NULL || encodeCallback == NULL) { ret = -1; printf(\"function socketclient_set_encode_callback() err :%d check (handle == NULL || encodeCallback == NULL) err \\n\", ret); return ret; } tmpHandle = (Sck_Handle*)handle; tmpHandle-&gt;encodeCallback = encodeCallback; return 0;} 生成 DLL 文件DLL 项目执行编译后，会自动在项目所在的文件夹内生成 .dll 与 .lib 文件，例如 socket-client.dll 与 socket-client.lib。在 VS Studio 的 Developer Command Prompt 命令窗口中，使用 dumpbin /exports socket-client.dll 命令，查看得到 socket-client.dll 动态链接库的详细信息如下： 12345678910111213141516171819202122232425262728293031323334353637Microsoft (R) COFF/PE Dumper Version 14.29.30136.0Copyright (C) Microsoft Corporation. All rights reserved.Dump of file socket-client.dllFile Type: DLL Section contains the following exports for socket-client.dll 00000000 characteristics FFFFFFFF time date stamp 0.00 version 1 ordinal base 6 number of functions 6 number of names ordinal hint RVA name 1 0 00011005 socketclient_destory = @ILT+0(socketclient_destory) 2 1 0001135C socketclient_init = @ILT+855(socketclient_init) 3 2 00011055 socketclient_recv = @ILT+80(socketclient_recv) 4 3 00011195 socketclient_send = @ILT+400(socketclient_send) 5 4 000112E4 socketclient_send_encode = @ILT+735(socketclient_send_encode) 6 5 00011244 socketclient_set_encode_callback = @ILT+575(socketclient_set_encode_callback) Summary 1000 .00cfg 1000 .data 1000 .idata 1000 .msvcjmc 3000 .pdata 4000 .rdata 1000 .reloc 1000 .rsrc 9000 .text 10000 .textbss 案例代码下载 点击下载完整的案例代码 DLL 的两种调用方式DLL 动态调用在本案例中，实现了通过函数指针类型，动态调用 DLL 里的函数，点击下载 使用到的 socket-client.dll 。值得一提的是，日后如果 DLL 里面的函数体代码作了修改，也不必改动函数调用方的代码（如下代码），就可以正常实现函数的调用，这样非常便于程序的维护和升级。特别注意，动态调用 DLL 里的函数时（动态加载 DLL），不需要 .h 和 .lib 文件，只需要 .dll 文件，同时要知道所要调用的函数的参数类型以及返回值类型（用于定义函数指针类型）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;stdio.h&gt;#include &lt;windows.h&gt;// 定义函数指针类型typedef int (*SocketInit)(void** handle);typedef int (*SocketSend)(void* handle, unsigned char* buf, int buflen);typedef int (*SocketRev)(void* handle, unsigned char* buf, int* buflen);typedef int (*SocketDestory)(void* handle);int main() { HINSTANCE hInstance; // 加载DLL动态链接库 hInstance = LoadLibrary(\"./socket-client.dll\"); if (hInstance == NULL) { printf(\"LoadLibrary() 调用失败, ErrorCode: %d\", GetLastError()); return -1; } // 调用DLL动态链接库 SocketInit socketInit = (SocketInit)GetProcAddress(hInstance, \"socketclient_init\"); SocketSend socketSend = (SocketSend)GetProcAddress(hInstance, \"socketclient_send\"); SocketRev socketRev = (SocketRev)GetProcAddress(hInstance, \"socketclient_recv\"); SocketDestory socketDestory = (SocketDestory)GetProcAddress(hInstance, \"socketclient_destory\"); if (socketInit == NULL) { return -1; } unsigned char inbuf[128]; int inbuflen = 128; unsigned char outbuf[4096]; int outbuflen = 4096; void* handle = NULL; int initResult = socketInit(&amp;handle); int sendResult = socketSend(handle, inbuf, inbuflen); int revResult = socketRev(handle, outbuf, &amp;outbuflen); int destoryResult = socketDestory(handle); printf(\"initResult = %d\\n\", initResult); printf(\"sendResult = %d\\n\", sendResult); printf(\"revResult = %d\\n\", revResult); printf(\"destoryResult = %d\\n\", destoryResult); // 释放DLL动态链接库 if (hInstance != NULL) { FreeLibrary(hInstance); } return 0;} 程序运行的输出结果如下： 1234initResult = 0sendResult = 0revResult = 0destoryResult = 0 DLL 静态调用静态调用 DLL 里的函数（静态加载 DLL），需要同时使用 .h、.lib 以及 .dll 文件，具体的操作步骤如下： a) 将 .h、.lib 以及 .dll 文件分别拷贝到项目所在的文件夹内，必须与 .c 源文件处于同一个文件夹 b) 在需要调用 DLL 的 .c 源文件中，通过 #pragma comment(lib \"xxx.lib\") 指令引入 .lib 文件 c) 在需要调用 DLL 的 .c 源文件中，通过 #include \"xxx.h，引入 .h 头文件 d) 正常编写代码，并调用 DLL 里的函数 若使用的开发工具是 Visual Studio，则可以不通过 #pragma comment(lib \"xxx.lib\") 指令引入 .lib 文件。右键项目，选择 属性，导航到 配置属性 -&gt; 链接器 -&gt; 输入 -&gt; 附加依赖项，添加对应的 .lib 文件名即可，如下图所示： .h 头文件里一般定义了 DLL 动态链接库里的函数原型，例如 socket-client.h 头文件的代码如下： 123456789101112131415161718192021#ifndef _INC_MYSOCKETCLIENT_H__#define _INC_MYSOCKETCLIENT_H__#ifdef __cplusplusextern \"C\" {#endif typedef int (*EncodeData)(unsigned char* in, int inlen, unsigned char* out, int* outlen); int socketclient_init(void** handle); int socketclient_send(void* handle, unsigned char* buf, int buflen); int socketclient_recv(void* handle, unsigned char* buf, int* buflen); int socketclient_destory(void* handle); int socketclient_set_encode_callback(void* handle, EncodeData encodeCallback); int socketclient_send_encode(void* handle, unsigned char* buf, int buflen, EncodeData encodeCallback);#ifdef __cplusplus}#endif#endif /* _INC_MYSOCKETCLIENT_H__ */ 静态调用 DLL 里的函数（main.c）的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include \"socket-client.h\"int Hw_Encode(unsigned char* in, int inlen, unsigned char* out, int* outlen) { printf(\"function Hw_Encode() begin ....\\n\"); strcpy((char*)out, \"123456789\"); *outlen = 9; printf(\"function Hw_Encode() end ....\\n\"); return 0;}int Cisco_Encode(unsigned char* in, int inlen, unsigned char* out, int* outlen) { printf(\"function Cisco_Encode() begin ....\\n\"); strcpy((char*)out, \"123456789\"); *outlen = 9; printf(\"function Cisco_Encode() end ....\\n\"); return 0;}int main() { unsigned char in[1024]; int inlen; unsigned char out[1024]; int outlen; void* handle = NULL; int ret = 0; strcpy((char*)in, \"aaaaaaaa\"); inlen = 9; //客户端初始化 ret = socketclient_init(&amp;handle); if (ret != 0) { printf(\"function socketclient_init() err:%d \\n\", ret); goto End; } printf(\"the result of socketclient_init() is %d \\n\", ret); //设置加密回调函数 ret = socketclient_set_encode_callback(handle, Cisco_Encode); if (ret != 0) { printf(\"function socketclient_set_encode_callback() err:%d \\n\", ret); } printf(\"the result of socketclient_set_encode_callback() is %d \\n\", ret); //客户端发送报文 ret = socketclient_send(handle, in, inlen); if (ret != 0) { printf(\"function socketclient_send() err:%d \\n\", ret); goto End; } printf(\"the result of socketclient_send() is %d \\n\", ret); //客户端报文加密发送 ret = socketclient_send_encode(handle, in, inlen, Hw_Encode); if (ret != 0) { printf(\"function socketclient_send_encode() err:%d \\n\", ret); goto End; } printf(\"the result of socketclient_send_encode() is %d \\n\", ret); //客户端接收报文 ret = socketclient_recv(handle, out, &amp;outlen); if (ret != 0) { printf(\"function socketclient_recv() err:%d \\n\", ret); goto End; } printf(\"the result of socketclient_recv() is %d \\n\", ret);End: //客户端释放资源 ret = socketclient_destory(handle); if (ret != 0) { printf(\"function socketclient_destory() err:%d \\n\", ret); } printf(\"the result of socketclient_destory() is %d \\n\", ret); return 0;} 程序运行的输出结果如下： 12345678910the result of socketclient_init() is 0the result of socketclient_set_encode_callback() is 0function Cisco_Encode() begin ....function Cisco_Encode() end ....the result of socketclient_send() is 0function Hw_Encode() begin ....function Hw_Encode() end ....the result of socketclient_send_encode() is 0the result of socketclient_recv() is 0the result of socketclient_destory() is 0 案例代码下载 点击下载完整的案例代码（DLL 静态调用） 参考博客 C++ 动态加载 DLL 和静态加载 DLL，以及 DLL 的编写 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c语言"},{"title":"Spring Cloud Gateway 开发随笔","url":"/posts/a6f0aaf9.html","text":"Gateway 配置路由超时时间配置路由超时配置可以为所有路由配置 HTTP 超时（响应和连接），并为每个特定路由覆盖 HTTP 超时。 全局路由的超时时间配置配置全局 HTTP 超时（响应和连接），需要使用以下两个参数： connect-timeout：必须以毫秒为单位指定连接超时时间 response-timeout：必须指定为 java.time.Duration 123456spring: cloud: gateway: httpclient: connect-timeout: 1000 response-timeout: 5s 每个路由的超时时间配置可以通过路由的 metadata 以下两个参数配置每个路由的超时时间： connect-timeout：必须以毫秒为单位指定连接超时时间 response-timeout：必须以毫秒为单位指定响应超时时间 123456789- id: per_route_timeouts uri: https://example.org predicates: - name: Path args: pattern: /delay/{timeout} metadata: response-timeout: 1000 connect-timeout: 1000 使用 Java DSL 为每个路由配置超时时间123456789101112131415import static org.springframework.cloud.gateway.support.RouteMetadataUtils.CONNECT_TIMEOUT_ATTR;import static org.springframework.cloud.gateway.support.RouteMetadataUtils.RESPONSE_TIMEOUT_ATTR;@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder routeBuilder){ return routeBuilder.routes() .route(\"test1\", r -&gt; { return r.host(\"*.somehost.org\").and().path(\"/somepath\") .filters(f -&gt; f.addRequestHeader(\"header1\", \"header-value-1\")) .uri(\"http://someuri\") .metadata(RESPONSE_TIMEOUT_ATTR, 1000) .metadata(CONNECT_TIMEOUT_ATTR, 1000); }) .build();} Gateway 负载均衡负载均衡失效，响应 503 错误码 版本说明 Spring Boot Spring Cloud Spring Cloud Alibaba 2.6.3 2021.0.1 2021.0.1.0 Gateway 的配置 12345678910111213spring: cloud: nacos: discovery: server-addr: 192.168.56.103:8848 gateway: routes: - id: tmall-product uri: lb://tmall-product predicates: - Path=/api/** filters: - RewritePath=/api(?&lt;segment&gt;/?.*), /tmall-product/$\\{segment} 问题描述 Gateway 使用 Nacos 作为配置中心，基于上述的配置内容，当通过 uri: http://127.0.0.1:9090 去直接调用 tmall-product 服务时，是可以正常调用的，但是使用 uri: lb://tmall-product 时就无法调用服务，Gateway 返回 503 错误码。 解决方案 造成 Gateway 负载均衡失效的原因是，从 Spring Cloud 2020 版本开始，Spring Cloud 弃用了 Ribbon，使用 Spring Cloud Loadbalancer 作为客户端的负载均衡组件；因此 Spring Cloud Alibaba 在 2021 版本的 Nacos 中也移除了 Ribbon 的依赖，最终导致 Gateway 无法通过 lb:// 路由到指定的服务，继而出现了 503 错误码。解决方案是引入 Spring Cloud Loadbalancer 的 Maven 坐标即可： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-loadbalancer&lt;/artifactId&gt;&lt;/dependency&gt; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 开发随笔"},{"title":"OpenFeign 开发随笔","url":"/posts/9becbc39.html","text":"常见错误Request method ‘POST’ not supported 错误信息：在调用 OpenFeign 下面这段代码时，抛出了 Request method 'POST' not supported 的异常 12345678910/** * 服务调用方 */@FeignClient(name = MicroServiceName.WECHAT_SERVICE)public interface WechatSubscribeUserService { @RequestMapping(value = \"/wechat/subscribe/get\", method = RequestMethod.GET) WechatSubscribeUser getSubscribeUser(@RequestBody WechatSubscribeUserVo vo);} 123456789101112131415161718/** * 服务提供方 */@RestController@RequestMapping(\"/wechat/subscribe\")public class WechatSubscribeUserController { @Autowired private WechatSubscribeUserService subscribeUserService; @GetMapping(\"/get\") public WechatSubscribeUser get(WechatSubscribeUserVo vo) { String toOpenId = vo.getToOpenId(); String fromOpenId = vo.getFromOpenId(); return subscribeUserService.getUser(fromOpenId, toOpenId); }} 错误原因：OpenFeign 原生的连接工具默认使用了 JDK 中的 HttpURLConnection 类进行实现，下面这段代码是在 HttpURLConnection 中发现的，所以只要 HTTP 请求里有 Body 体对象，就会强制的把 GET 请求转换成 POST 请求。 1234567891011private synchronized OutputStream getOutputStream0() throws IOException { try { if (!this.doOutput) { throw new ProtocolException(\"cannot write to a URLConnection if doOutput=false - call setDoOutput(true)\"); } else { if (this.method.equals(\"GET\")) { this.method = \"POST\"; } } }} 第一种解决方案：不使用 POJO 对象作为参数，而是传入多个独立的参数，并添加 @RequestParam 注解 12345678910/** * 服务调用方 */@FeignClient(name = MicroServiceName.WECHAT_SERVICE)public interface WechatSubscribeUserService { @RequestMapping(value = \"/wechat/subscribe/get\", method = RequestMethod.GET) WechatSubscribeUser getSubscribeUser(@RequestParam(\"fromOpenId\") String fromOpenId, @RequestParam(\"toOpenId\") String toOpenId);} 第二种解决方案：使用 POJO 对象作为参数，同时添加 @SpringQueryMap 注解 12345678910/** * 服务调用方 */@FeignClient(name = MicroServiceName.WECHAT_SERVICE)public interface WechatSubscribeUserService { @RequestMapping(value = \"/wechat/subscribe/get\", method = RequestMethod.GET) WechatSubscribeUser get(@SpringQueryMap WechatSubscribeUserVo vo);} 提示 Feign 的 @QueryMap 注解支持将 POJO 用作 GET 请求的参数映射，但默认的 @QueryMap 注解与 Spring 不兼容，因为它缺少 value 属性。Spring Cloud OpenFeign 提供了等效的 @SpringQueryMap 注解，用于将 POJO 或 Map 参数映射为查询参数。简而言之，Feign 的 GET 请求无法解析对象参数，如果传参是一个类对象，框架就需要把这个类对象解析成查询参数，但是直接在方法中传参框架不会自动把类对象解析成查询参数。@SpringQueryMap 注解的作用就是把 POJO 解析成 k1=v1&amp;k2=v2 的查询参数格式。 第三种解决方案：使用 Apache HttpClient 或者 OkHttp 替换掉 OpenFeign 原生使用的 HttpURLConnection 连接工具，然后添加 @RequestBody 注解 12345678910/** * 服务调用方 */@FeignClient(name = MicroServiceName.WECHAT_SERVICE)public interface WechatSubscribeUserService { @RequestMapping(value = \"/wechat/subscribe/get\", method = RequestMethod.GET) WechatSubscribeUser getSubscribeUser(@RequestBody WechatSubscribeUserVo vo);} warning笔者尝试使用 Apache HttpClient 或者 OkHttp 替换 OpenFeign 默认使用的 HttpURLConnection，但并没有生效，有兴趣的可以参考这里的 替换教程。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 开发随笔"},{"title":"MySQL 常用命令","url":"/posts/31eec5f6.html","text":"用户管理创建用户创建普通用户，并完全授权访问特定的数据库 12345create user 'clay'@'%' identified by '123456';grant all privileges on mysql_db.* to 'clay'@'%';flush privileges; 删除用户删除用户及权限 1drop user 'clay'@'%'; 创建只读用户创建普通用户，并授予特定数据库的只读权限 123grant select on mysql_db.* to 'clay'@'%' identified by '123456';flush privileges; 权限管理查看用户的所有权限1show grants for 'clay'@'%'; 授权 Root 用户远程登录*.* 代表所有数据库所有权限，'root'@'%' 中的 root 代表用户名，% 代表所有的访问地址，123456 是登录密码 123GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;FLUSH PRIVILEGES; var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"数据库"},{"title":"分布式唯一全局 ID 解决方案之二","url":"/posts/221613dd.html","text":"大纲 分布式唯一全局 ID 解决方案之一 分布式唯一全局 ID 解决方案之二 1、UidGenerator 分布式 ID 生成器1.1、概述UidGenerator 是 Java 实现的，基于 Snowflake 算法的唯一 ID 生成器。UidGenerator 以组件形式工作在应用项目中， 支持自定义 workerId 位数和初始化策略， 从而适用于 Docker 等虚拟化环境下实例自动重启、漂移等场景。在实现上， UidGenerator 通过借用未来时间来解决 sequence 天然存在的并发限制；采用 RingBuffer 来缓存已生成的 UID， 并行化 UID 的生产和消费， 同时对 CacheLine 补齐，避免了由 RingBuffer 带来的硬件级「伪共享」问题。 最终单机 QPS 可达 600 万。依赖 Java8 及以上版本， MySQL (内置 WorkerID 分配器， 启动阶段通过数据库进行分配；如自定义实现，则数据库非必选依赖）。 1.2、结构Snowflake 算法描述：指定机器 &amp; 同一时刻 &amp; 某一并发序列，是唯一的。据此可生成一个 64 bit 的唯一 ID（Long 型），默认采用下图字节分配方式： sign（1bit）：符号位，固定是 0，表示全部 ID 都是正整数 delta seconds (28 bits)：当前时间，相对于时间基点 2016-05-20 的增量值，单位为秒，最多可支持约 8.7 年 worker id (22 bits)：机器 ID，最多可支持约 420w 次机器启动。内置实现为在启动时由数据库分配，默认分配策略为用后即弃，后续可提供复用策略 sequence (13 bits)：每秒下的并发序列，13 bits 可支持每秒 8192 个并发 2、Leaf 分布式 ID 生成系统Leaf 提供了两种方案，分别是 Leaf-segment 和 Leaf-snowflake 方案，前者依赖 MySQL，后者依赖 ZooKeeper。 2.1、Leaf-segment 方案2.1.1、概述Leaf-segment 方案，在使用 MySQL 自增 ID 的方案上，做了如下改变： 原方案每次获取 ID 都得读写一次数据库，造成数据库压力大。改为利用 Proxy Server 批量获取，每次获取一个 segment（step 决定大小）号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力 各个业务不同的 ID 生成需求用 biz_tag 字段来区分，每个 biz-tag 的 ID 获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述复杂的扩容操作，只需要对 biz_tag 分库分表就行 123456789+-------------+--------------+------+-----+-------------------+-----------------------------+| Field | Type | Null | Key | Default | Extra |+-------------+--------------+------+-----+-------------------+-----------------------------+| biz_tag | varchar(128) | NO | PRI | | || max_id | bigint(20) | NO | | 1 | || step | int(11) | NO | | NULL | || desc | varchar(256) | YES | | NULL | || update_time | timestamp | NO | | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |+-------------+--------------+------+-----+-------------------+-----------------------------+ 重要字段说明： biz_tag：用来区分业务 max_id：表示该 biz_tag 目前所被分配的 ID 段的最大值 step：表示每次分配的号段长度。原来获取 ID 每次都需要写数据库，现在只需要把 step 设置得足够大，比如 1000。那么只有当 1000 个号被消耗完了之后才会去重新读写一次数据库，读写数据库的频率从 1 减小到了 1 / step 2.1.2、架构 test_tag 在第一台 Leaf 机器上是 11000 的号段，当这个号段用完时，会去加载另一个长度为 step=1000 的号段，假设另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是 30014000。同时数据库对应的 biz_tag 这条数据的 max_id 会从 3000 被更新成 4000，更新号段的 SQL 语句如下： 1234BeginUPDATE table SET max_id=max_id+step WHERE biz_tag=xxxSELECT tag, max_id, step FROM table WHERE biz_tag=xxxCommit 2.1.3、优缺点优点： Leaf 服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景 ID 是趋势递增的 8 byte 的 64 位数字，满足上述数据库存储的主键要求 可以自定义 max_id 的大小，非常方便业务从原有的 ID 方式上迁移过来 容灾性高，Leaf 服务内部有号段缓存，即使数据库宕机，短时间内 Leaf 仍能正常对外提供服务 缺点： 数据库宕机会造成整个系统不可用 ID 不够随机，能够泄露发号数量的信息，不太安全 TP999 数据波动大，当号段使用完之后，ID 生成的性能瓶颈还是会在更新数据库的 I/O 上，TP999 数据会出现偶尔的尖刺 2.1.4、高可用容灾针对第一个缺点数据库可用性问题，目前采用一主两从的方式，同时分机房部署，Master 和 Slave 之间采用半同步方式同步数据。同时使用 Atlas 数据库中间件（已开源，改名为 DBProxy）做主从切换。当然这种方案在一些情况会退化成异步模式，甚至在非常极端情况下仍然会造成数据不一致的情况，但是出现的概率非常小。如果系统要保证 100% 的数据强一致，可以选择使用 类 Paxos 算法 实现的强一致 MySQL 方案，如 MySQL 5.7 GA 的 MySQL Group Replication，但是运维成本和精力都会相应的增加，根据实际情况选型即可。在美团点评内部，Leaf 服务分 IDC 部署，内部的服务化框架是 MTthrift RPC。服务调用的时候，根据负载均衡算法会优先调用同机房的 Leaf 服务。在该 IDC 内 Leaf 服务不可用的时候才会选择其他机房的 Leaf 服务。同时服务治理平台 OCTO 还提供了针对服务的过载保护、一键截流、动态流量分配等对服务的保护措施。 2.1.5、双 Buffer 优化针对上述第三个缺点，Leaf-segment 做了一些优化，简单的说就是：Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的 ID 下发时间取决于下一次从数据库取回号段的时间，并且在这期间进来的请求也会因为数据库号段没有取回来，导致线程阻塞。如果请求数据库的网络和数据库的性能稳定，这种情况对系统的影响是不大的，但是假如取数据库的时候网络发生抖动，或者数据库发生慢查询就会导致整个系统的响应时间变慢。为此，希望数据库取号段的过程能够做到无阻塞，不需要在数据库取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段。这样做就可以很大程度上的降低系统的 TP999 指标。详细实现如下图所示： 采用双 Buffer 的方式，Leaf 服务内部有两个号段缓存区 segment。当前号段已下发 10% 时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前 segment 接着下发，循环往复 每个 biz-tag 都有消费速度监控，通常推荐 segment 长度设置为服务高峰期发号 QPS 的 600 倍（10 分钟），这样即使数据库宕机，Leaf 仍能持续发号 10-20 分钟不受影响 每次请求来临时都会判断下个号段的状态，从而更新此号段，所以偶尔的网络抖动不会影响下个号段的更新 2.2、Leaf-snowflake 方案2.2.1、概述Leaf-segment 方案可以生成趋势递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，比如竞对在两天中午 12 点分别下单，通过订单 ID 相减就能大致计算出公司一天的订单量，这个是不能忍受的。面对这一问题，美团点评提供了 Leaf-snowflake 方案。 2.2.2、架构Leaf-snowflake 方案完全沿用 SnowFlake 方案的 bit 位设计，即是 1+41+10+12 的方式组装 ID。对于 workerId 的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf 服务规模较大，动手配置成本太高。所以使用 ZooKeeper 持久顺序节点的特性自动对 SnowFlake 节点配置 wokerId。Leaf-snowflake 是按照下面几个步骤启动的： 启动 Leaf-snowflake 服务，连接 ZooKeeper，在 leaf_forever 父节点下检查自己是否已经注册过（是否有该顺序子节点） 如果有注册过直接取回自己的 workerId（ZooKeeper 顺序节点生成的 int 类型 ID），启动服务 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的 workerId 号，启动服务 2.2.3、弱依赖 ZooKeeper除了每次会去 ZooKeeper 拿数据以外，也会在本机文件系统上缓存一个 workerId 文件。当 ZooKeeper 出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖，一定程度上提高了 SLA。 2.2.4、解决时钟回拨问题因为 Leaf-snowflake 方案依赖时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的 ID，因此需要解决时钟回退的问题。Leaf-snowflake 整个启动流程图如下： 1）服务启动时首先检查自己是否写过 ZooKeeper 的 leaf_forever 节点 2）若写过，则用自身系统时间与 leaf_forever/${self} 节点记录时间做比较，若小于 leaf_forever/${self} 时间则认为机器时间发生了大步长回拨，服务启动失败并报警 3）若未写过，证明是新服务节点，直接创建持久节点 leaf_forever/${self} 并写入自身系统时间，接下来综合对比其余 Leaf 节点的系统时间来判断自身系统时间是否准确，具体做法是取 leaf_temporary 下的所有临时节点（所有运行中的 Leaf-snowflake 节点）的服务 IP：Port，然后通过 RPC 请求得到所有节点的系统时间，计算 sum(time) / nodeSize。 4）若 abs (系统时间 - sum (time) /nodeSize ) &lt; 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点 leaf_temporary/${self} 维持租约 5）否则认为本机系统时间发生大步长偏移，启动失败并报警 6）每隔一段时间（3s）上报自身系统时间写入 leaf_forever/${self} 由于强依赖时钟，对时间的要求比较敏感，在机器工作时 NTP 同步也会造成秒级别的回退，建议可以直接关闭 NTP 同步。要么在时钟回拨的时候直接不提供服务直接返回 ERROR_CODE，等时钟追上即可。或者做一层重试，然后上报报警系统，更或者是发现有时钟回拨之后自动摘除本身节点并报警，代码如下： 12345678910111213141516171819202122//发生了回拨，此刻时间小于上次发号时间 if (timestamp &lt; lastTimestamp) { long offset = lastTimestamp - timestamp; if (offset &lt;= 5) { try { //时间偏差大小小于5ms，则等待两倍时间 wait(offset &lt;&lt; 1);//wait timestamp = timeGen(); if (timestamp &lt; lastTimestamp) { //还是小于，抛异常并上报 throwClockBackwardsEx(timestamp); } } catch (InterruptedException e) { throw e; } } else { //throw throwClockBackwardsEx(timestamp); } } //分配ID 3、参考资料 Leaf 官方文档 MySQL 半同步复制 UidGenerator 官方文档 基于美团 Leaf、百度 UidGenerator、SnowFlake 整合的分布式唯一 ID 生成器 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"数据库 分布式"},{"title":"分布式唯一全局 ID 解决方案之一","url":"/posts/b2330a87.html","text":"大纲 分布式唯一全局 ID 解决方案之一 分布式唯一全局 ID 解决方案之二 1、分布式 ID 简介1.1、业务背景在复杂的分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如在美团点评的金融、支付、餐饮、酒店、猫眼电影等产品的系统中数据日渐增长，对数据分库分表后需要有一个唯一 ID 来标识一条数据或消息。具体一点的如订单、骑手、优惠劵也都需要有唯一标识，此时一个能够生成全局唯一 ID 的系统是非常必要的。 1.2、ID 生成规则的硬性要求 全局唯一：不能出现重复的 ID ，既然是唯一标识，这是最基本的要求 单调递增：保证下一个 ID 大于上一个 ID，例如事务版本号、IM 增量信息、排序等特殊需求 趋势递增：在 MySQL 的 InnoDB 存储引擎中使用的是聚集索引，由于多数 RDBMS 使用 BTree 的数据结构来存储索引数据，在主键的选择上面应该尽量使用有序的主键来保证写入性能 信息安全：如果 ID 是连续的，恶意用户的爬取工作就非常容易做了，直接按照顺序下载指定 URL 即可 所以在一些应用场景下，需要 ID 无规则或者不规则，让竞争对手不好猜 上述的全局唯一、单调递增、趋势递增需求分别对应三类不同的业务场景，但单调递增和信息安全这两个需求是互斥的，无法使用同一个方案满足 1.3、ID 生成系统的可用性要求 低延迟：发一个获取分布式 ID 的请求，服务器就要快，极速 高可用：一个获取分布式 ID 的请求，服务器就要在保证 99.999% 成功率的情况下创建一个唯一分布式 ID 高 QPS：假如并发一堆创建分布式 ID 的请求同时杀过来，服务器要顶得住且一下子成功创建 10 万个唯一分布式 ID 2、UUID 生成 ID2.1、概述UUID 按照 OSF 制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片 ID 码和许多可能的数字，并由以下几部分的组成：当前日期和时间、时钟序列、全局唯一的 IEEE 机器识别号。UUID 的标准形式包含 32 个 16 进制的数字，以连字号分为 5 段，形式为 cb6ce510-74fe-4e18-ac3d-05a5c96d3a0f 的 36 个字符。特别注意，基于 MAC 地址生成 UUID 的算法可能会造成 MAC 地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。 2.2、优缺点 优点：性能高，本地生成，没有网络消耗。如果只考虑唯一性，那么可以使用 缺点：无序，长度较长，入库性能差，作为数据库主键时，会导致索引效率下降，空间占用较多 适用场景：只要对存储空间没有苛刻要求的都能够适用，比如各种链路追踪、日志存储等 为什么无序的 UUID 会导致入库性能变差？ 无序：即无法预测 ID 的生成顺序，不能生成递增的有序数字 ID 长度过长：分布式 ID 一般都是作为主键，但是 MySQL 官方推荐主键尽量越短越好，36 个字符长度的 UUID 不是很推荐 B+ 树索引分裂：既然分布式 ID 是主键，然后主键是包含索引的，MySQL 的索引是通过 B+ 树来实现的，每一次新的 UUID 数据的插入，为了查询的优化，都会对索引的底层 B+ 树进行修改。因为 UUID 数据是无序的，所以每一次 UUID 的数据插入都会对主键底层的 B+ 树进行很大的修改，这一点非常不好。插入的 ID 完全无序，不但会导致一些中间节点产生分裂，也会白白的创造出很多的不饱和节点，这样大大的降低了数据库的插入性能 3、数据库自增 ID3.1、概述在分布式应用里，数据库的自增 ID 机制的主要原理是使用：MySQL 数据库自增 ID 和 replace into 来实现的。利用给字段设置 auto_increment 和 auto_increment_offset 来保证 ID 自增，每次业务使用下列 SQL 读写 MySQL 得到 ID。 这里的 replace into 跟 insert 功能类似，不同点在于 replace into 首先会尝试插入数据到表中，如果发现表中已经有此行数据（根据主键或者唯一索引判断），则先删除旧数据，否则直接插入新数据 3.2、优缺点优点： 非常简单，利用现有数据库系统的功能实现，成本小 ID 单调自增，可以实现一些对 ID 有特殊要求的业务 缺点： 生成的是单调递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，否则竞争对手很从容易猜到 分库分表后，同一数据表的自增 ID 容易重复，无法直接使用（可以设置自增步长，但局限性很明显） 强依赖数据库，当数据库异常时整个系统不可用，属于致命问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证，主从切换时的不一致可能会导致重复生成 ID 生成 ID 的性能瓶颈限制在单台 MySQL 的读写性能，如果设计一个单独的数据库来实现分布式应用的数据唯一性，即使使用预生成方案，也会因为事务锁的问题，高并发场景容易出现单点瓶颈 适用场景： 单数据库实例的表 ID（包含主从同步场景），部分按天计数的流水号等，不适用于分库分表场景、全局唯一 ID 场景 数据库的自增 ID 机制为什么不适合作为分布式 ID？ 在高并发的场景下，数据库压力还是很大，每次获取 ID 都得读写一次数据库，非常影响性能，不符合分布式 ID 里面的低延迟和高 QPS 的规则 系统水平扩展比较困难，为了提高 MySQL 的性能，如果要增加 MySQL 数据库该怎么做？ 3.3、MySQL 集群场景在分布式系统中可以多部署几台机器，每台机器设置不同的初始值，且自增步长和机器数相等。比如有 2 台机器，设置自增步长为 2，TicketServer1 的初始值为 1（1，3，5，7，9，11 …）、TicketServer2 的初始值为 2（2，4，6，8，10 …）。如下所示，分别设置两台机器对应的参数，TicketServer1 从 1 开始生成 ID ，TicketServer2 从 2 开始生成 ID ，两台机器每次生成 ID 之后都递增 2。 1234567TicketServer1:auto-increment-increment = 2auto-increment-offset = 1TicketServer2:auto-increment-increment = 2auto-increment-offset = 2 假设要部署 N 台机器，自增步长需设置为 N，每台的初始值依次为 0，1，2 … N-1，那么整个架构就变成了如下图所示： 这种架构貌似能够满足性能的需求，但有以下几个缺点： 数据库压力还是很大，每次获取 ID 都得读写一次数据库，只能靠堆机器来提高性能 ID 没有了单调递增的特性，只能趋势递增，这个缺点对于一般业务需求不是很重要，可以容忍 系统水平扩展比较困难，比如定义好了自增步长和机器台数之后，如果要添加机器该怎么做？假设现在只有一台机器生成 ID 是 1，2，3，4，5（自增步长是 1），这个时候需要扩容机器一台。可以这样做：把第二台机器的初始值设置得比第一台超过很多，比如 14（假设在扩容时间之内第一台不可能发到 14），同时设置自增步长为 2，那么这台机器下发的号码都是 14 以后的偶数。然后摘掉第一台，把 ID 值保留为奇数，比如 7，然后修改第一台的自增步长为 2。让它符合我们定义的号段标准，对于这个例子来说就是让第一台以后只能产生奇数。扩容方案看起来复杂吗？貌似还好，现在想象一下如果线上有 100 台机器，这个时候要扩容该怎么做？简直是噩梦，所以系统水平扩展方案复杂难以实现。 4、基于 Redis 生成全局 ID 策略4.1、概述因为 Redis 是单线程的，天生保证了原子性，可以使用原子操作 INCR 和 INCRBY 来生成分布式唯一 ID 4.2、优缺点优点： 整体吞吐量比数据库方案要高 缺点： Redis 实例或集群宕机后，找回最新的 ID 值有点困难 Redis 单机环境下，存在单点故障问题，导致 ID 生成服务不可用 生成的是单调递增的 ID，同时 ID 是可计算的，不适用于订单 ID 生成场景，否则竞争对手很从容易猜到 适用场景： 比较适合计数场景，如用户访问量，订单流水号（日期 + 流水号）等 4.3、Redis 集群场景通过 Redis 集群来生成唯一 ID 时，需要设置相同的自增步长，且自增步长等于节点数，同时 Key 要求设置相同的有效期，以此来获得更高的吞吐量。假设一个集群中有 5 台 Redis，此时可以初始化每台 Redis 的值分别是 1，2，3，4，5，然后自增步长都是 5，那么各个 Redis 生成的 ID 为： A：1，6，11，16，21 B：2，7，12，17，22 C：3，8，13，18，23 D：4，9，14，19，24 E：5，10，15，20，25 这种方式最大的缺点是复杂性太高，需要严重依赖第三方服务，集群管理繁琐，而且代码配置繁琐。一般来说，越是复杂的方案，越不可靠。 5、SnowFlake（雪花算法）5.1、概述SnowFlake 算法来源于 Twitter，使用 Scala 语言实现，利用 Thrift 框架实现 RPC 接口调用，最初的项目起因是数据库从 MySQL 迁移到 Cassandra，而 Cassandra 没有现成可用的 ID 生成机制，就催生了该算法。SnowFlake 的特性如下： SnowFlake 生成 ID 能够按照时间有序生成 经测试 SnowFlake 每秒能够产生 26 万个自增可排序 ID 分布式系统内不会产生 ID 碰撞（由 datacenter 和 workerId 做区分），并且生成效率较高 SnowFlake 算法生成 ID 的结果是一个 64 bit 大小的整数，刚好为一个 Long 型，转换成字符串后长度最多是 19 5.2、结构SnowFlake 算法的特性是有序、全局唯一、高性能、低延迟（响应时间在 2ms 以内），可在分布式环境（多集群，跨机房）下使用，因此使用 SnowFlake 算法得到的 ID 是分段组成的： 与指定日期的时间差（毫秒级），41 位，够用 69 年 集群 ID + 机器 ID，一共 10 位，包括 5 位 datacenterId 和 5 位 workerId，最多支持 1024 台机器 序列号，12 位，每台机器每毫秒内最多产生 4096 个序列号 1bit：符号位，固定是 0，表示全部 ID 都是正整数 41bit：时间戳（毫秒数时间差），从指定的日期算起，够用 69 年，用 Long 类型表示的时间戳是从 1970-01-01 00:00:00 开始算起的 10bit：机器 ID，有异地部署，多集群的也可以配置，需要线下规划好各地机房，各集群，各实例 ID 的编号 12bit：序列号，前面都相同的话，最多可以支持到 4096 个 5.3、优缺点优点： 可以根据自身业务特性分配 bit 位，非常灵活 毫秒数在高位，自增序列在低位，整个 ID 都是趋势递增的 不依赖数据库等三方系统，以服务的方式部署，稳定性更高，生成 ID 的效率也是非常高，低延迟 缺点： 强依赖机器时钟，如果机器的时钟回拨了，会导致生成重复的 ID 若生成环境中使用了容器化技术，实例的个数随时有变化，那么 SnowFlake 需要一定的改造才能更好地应用到生产环境中 在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步（如时钟回拨），有时候可能会出现不是全局递增的情况（此缺点可认为无所谓，一般分布式 ID 只是要求趋势递增，并不会严格要求递增，90% 的业务需求都只需要趋势递增） 适用场景： 分布式应用环境的数据主键 5.4、Java 版实现Java 版的代码实现来自这里，在企业的项目开发中，一般可以直接使用封装好 SnowFlake 算法的 Java 工具库（如 Hutools 工具库），不再需要自己实现一遍，完整的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * twitter的snowflake算法 -- java实现 * * @author beyond * @date 2016/11/26 */public class SnowFlake { /** * 起始的时间戳 */ private final static long START_STMP = 1480166465631L; /** * 每一部分占用的位数 */ private final static long SEQUENCE_BIT = 12; //序列号占用的位数 private final static long MACHINE_BIT = 5; //机器标识占用的位数 private final static long DATACENTER_BIT = 5;//数据中心占用的位数 /** * 每一部分的最大值 */ private final static long MAX_DATACENTER_NUM = -1L ^ (-1L &lt;&lt; DATACENTER_BIT); private final static long MAX_MACHINE_NUM = -1L ^ (-1L &lt;&lt; MACHINE_BIT); private final static long MAX_SEQUENCE = -1L ^ (-1L &lt;&lt; SEQUENCE_BIT); /** * 每一部分向左的位移 */ private final static long MACHINE_LEFT = SEQUENCE_BIT; private final static long DATACENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private final static long TIMESTMP_LEFT = DATACENTER_LEFT + DATACENTER_BIT; private long datacenterId; //数据中心 private long machineId; //机器标识 private long sequence = 0L; //序列号 private long lastStmp = -1L;//上一次时间戳 public SnowFlake(long datacenterId, long machineId) { if (datacenterId &gt; MAX_DATACENTER_NUM || datacenterId &lt; 0) { throw new IllegalArgumentException(\"datacenterId can't be greater than MAX_DATACENTER_NUM or less than 0\"); } if (machineId &gt; MAX_MACHINE_NUM || machineId &lt; 0) { throw new IllegalArgumentException(\"machineId can't be greater than MAX_MACHINE_NUM or less than 0\"); } this.datacenterId = datacenterId; this.machineId = machineId; } /** * 产生下一个ID * * @return */ public synchronized long nextId() { long currStmp = getNewstmp(); if (currStmp &lt; lastStmp) { throw new RuntimeException(\"Clock moved backwards. Refusing to generate id\"); } if (currStmp == lastStmp) { //相同毫秒内，序列号自增 sequence = (sequence + 1) &amp; MAX_SEQUENCE; //同一毫秒的序列数已经达到最大 if (sequence == 0L) { currStmp = getNextMill(); } } else { //不同毫秒内，序列号置为0 sequence = 0L; } lastStmp = currStmp; return (currStmp - START_STMP) &lt;&lt; TIMESTMP_LEFT //时间戳部分 | datacenterId &lt;&lt; DATACENTER_LEFT //数据中心部分 | machineId &lt;&lt; MACHINE_LEFT //机器标识部分 | sequence; //序列号部分 } private long getNextMill() { long mill = getNewstmp(); while (mill &lt;= lastStmp) { mill = getNewstmp(); } return mill; } private long getNewstmp() { return System.currentTimeMillis(); } public static void main(String[] args) { SnowFlake snowFlake = new SnowFlake(2, 3); for (int i = 0; i &lt; (1 &lt;&lt; 12); i++) { System.out.println(snowFlake.nextId()); } }} 上面的代码基本上通过位移操作，将每段含义的数值，移到相应的位置上。如机器 ID 这里由数据中心 + 机器标识组成，所以，机器标识向左移 12 位，就是它的位置，数据中心的编号向左移 17 位，时间戳的值向左移 22 位，每部分占据自己的位置，各不干涉，由此组成一个完整的 ID 值。 了解 SnowFlake 的基本实现原理，可以通过提前规划好机器标识来实现，但目前的分布式生产环境，借用了多种云计算、容器化技术，实例的个数随时有变化，而且还需要处理服务器实例的时钟回拨问题，固定规划 ID 然后通过配置来使用 SnowFlake 的场景可行性不高。一般是自动启停，增减机器，这样就需要对 SnowFlake 进行一些改造才能更好地应用到生产环境中。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"数据库 分布式"},{"title":"Eureka 开发随笔","url":"/posts/6cbc15f0.html","text":"Eureka 搭建集群，节点均出现在 unavailable-replicas 下 Eureka 搭建高可用集群，启动多个注册中心后，节点均出现在 unavailable-replicas，查阅各类资料和测试，提供的方案如下： eureka.client.serviceUrl.defaultZone 配置项的地址，不能使用 localhost 或者内网/外网 IP，要使用域名，DNS 解析请自行配置，也可以在本机的 /etc/hosts 里映射域名 spring.application.name 要一致（默认不配置也可以） register-with-eureka 设置为 true（默认不配置也可以） 1234eureka: client: register-with-eureka: true fetch-registry: false 配置 eureka.instance.hostname (好像看到过正常情况下 Eureka 会自动拉取设备 Host，但各节点在同一机器下时请务必添加，注意各节点配置自己节点的 Host) 123eureka: instance: hostname: host1 千折腾万折腾还是不好使的时候，请去掉下面这个参数或者改为 false（神坑），未找到官方原因 123eureka: instance: prefer-ip-address: false 个人大概理解了下，prefer-ip-address: true 为不使用主机名来定义注册中心的地址，而使用 IP 地址的形式，而 defaultZone 中是以域名的方式向注册中心注册的（测试了下使用 IP 注册到备份节点不可识别），最终导致分片节点不能识别匹配（IP 地址与域名），而认为分片均处于不可达状态。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 开发随笔"},{"title":"Navicat Premium 15 永久破解教程","url":"/posts/319e35f3.html","text":"前言这篇文章主要介绍 Windows 系统下 Navicat Premium 15 永久破解的教程，亲测永久破解有效！Navicat Premium 是 MySQL、MongoDB、SQL Server、Oracle 和 PostgreSQL 的一体化数据库管理工具，功能非常强大。 准备工作软件版本说明建议 Navicat Premium 15 软件和注册机软件都直接从本站下载，当前本站提供下载的 Navicat Premium 版本是 15.0.26，配套的注册机软件版本是 v5.6，两者都是经过亲测可以永久破解的。这是因为随着时间的推移，从官网下载的最新版 Navicat Premium 15，并不能保证能被 v5.6 版本的注册机永久破解。 下载注册机软件 本站下载地址（推荐）：点击下载 百度网盘地址：点击下载&nbsp; 提取码: mzgp 下载 Navicat Premium 15 软件 官网下载地址：点击下载 本站下载地址（推荐）：点击下载 Navicat Premium 15 破解注意事项 运行注册机软件之前，必须保证断网 运行注册机软件之前，必须关闭所有杀毒软件，包括 360 杀毒、腾讯管家、Windows Defender 等 Navicat Premium 15 安装完成后，不要运行 Navicat 软件，而是直接先运行注册机软件 运行注册机软件时，请选择 Navicat 的版本为 Navicat v15 安装 Navicat Premium 15Navicat Premium 15 下载好后直接安装，此安装步骤比较简单，选择安装位置后全部点击下一步 按钮即可 特别注意： Navicat Premium 15 安装完成后，不要运行 Navicat 软件 破解 Navicat Premium 15第一步破解 Navicat Premium 15 之前，必须保证断网，同时必须关闭所有杀毒软件，例如 360 杀毒、腾讯管家、Windows Defender 等 第二步以管理员身份运行注册机软件，勾选 Backup、Host 和 Navicat v15，然后点击 Patch 按钮，找到 Navicat Premium 15 安装目录下的 navicat.exe，选中并点击打开，Patch 成功后会提示 navicat.exe - x64 -&gt; Cracked，表示 Navicat Premium 15 已被破解 提示：如果 Navicat 安装在默认位置，点击 Patch 按钮后，会直接提示 navicat.exe - x64 -&gt; Cracked，而不再弹窗让你选择特定安装目录下的 navicat.exe 第三步Licenses 项选择 Enterprise，Products 项选择 Premium，Languages 项选择 Simplified Chinese，Resale License 项选择 Site License，然后点击 Generate 按钮，生成许可证密钥 第四步运行 Navicat Premium 15 软件，点击 注册 按钮，或者在主界面的菜单栏导航到：帮助 -&gt; 注册 粘贴上一步生成的许可证密钥到 Navicat Premium 15 的许可证密钥输入框，然后点击 激活 按钮 紧接着点击 手动激活 按钮 点击 手动激活 按钮后，显示的界面如下，该界面会显示 Navicat Premium 15 的 请求码 第五步将上一步 Navicat Premium 15 生成的 请求码 粘贴到注册机软件的 Request Code 输入框中，然后点击 Generate 按钮，生成激活码 最后将注册机软件生成的激活码粘贴到 Navicat Premium 15 的激活码输入框，然后点击 激活 按钮 成功激活后的提示界面如下 也可以在 Navicat Premium 15 主界面的菜单栏导航到：帮助 -&gt; 注册 来查看是否成功激活 常见问题破解失败若破解失败，首先卸载 Navicat Premium 15 软件，然后清理注册表并重启系统，最后再尝试重新安装并破解 Navicat 软件 参考博客 Navicat 的 Linux 版破解工具 Linux 安装 Navicat Premium 15 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Centos 7 安装 R 语言","url":"/posts/a4ef22cd.html","text":"前言 R 官网下载 RStudio 官网下载 RPM 安装 R因为 R 已经由 EPEL 仓库管理，所以使用以下命令安装 R 12345678# 安装EPEL# yum install epel-release# 安装R# yum install R# 查看R的版本# R --version RPM 安装 RStudio从 官网下载 RStudio Desktop 或者 RStudio Server 的 RPM 安装包，然后直接使用以下 RPM 命令安装即可 1# rpm -ivh rstudio-1.4.1106-x86_64.rpm 验证 R 的安装创建 /usr/local/R/demo.R 源文件，写入以下代码 12345x &lt;- c(1,2,5,7,9)y &lt;- c(2,4,7,8,10)plot(x,y)abline(lm(y~x))title(\"回归图表\") 在 R 的交互终端执行以下命令，运行上述的代码，若可以正常显示 回归图表，则说明 R 安装成功 123$ R&gt; setwd(\"/usr/local/R/\")&gt; source(\"demo.R\") R 安装 Package12$ R&gt; install.packages(\"httr\") var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"centos"},{"title":"Hexo Next 8.x 主题添加可切换的暗黑模式","url":"/posts/abf4aee1.html","text":"前言Next 8.x 原生的暗黑模式Next 8.x 主题已经原生支持暗黑模式，只需要在 Next 的 _config.yml 配置文件中，将相应的开关打开即可（如下所示）： 1darkmode: true Next 8.x 主题原生暗黑模式的优缺点： 优点： 配置非常简单 缺点： 缺少切换按钮，默认是根据系统偏好（系统是否处于暗黑模式）来决定是否启用 Next 7.x 自动添加可切换的暗黑模式若读者使用的 Next 版本是 7.x，建议直接安装 hexo-next-darkmode 插件来自动添加可切换的暗黑模式，具体的安装步骤与下面讲述的 Next 8.x 教程一致。 Next 8.x 自动添加可切换的暗黑模式hexo-next-darkmode 插件支持自动添加可切换的暗黑模式，同时支持暗黑模式下的 CSS 样式高度自定义，兼容 Next 7.x 与 8.x 版本。 安装 Hexo 插件安装 hexo-next-darkmode 插件 1$ npm install hexo-next-darkmode --save 配置 Hexo 插件在 Next 主题的 _config.yml 配置文件里添加以下内容 1234567891011121314151617# Darkmode JS# For more information: https://github.com/rqh656418510/hexo-next-darkmode, https://github.com/sandoche/Darkmode.jsdarkmode_js: enable: true bottom: '64px' # default: '32px' right: 'unset' # default: '32px' left: '32px' # default: 'unset' time: '0.5s' # default: '0.3s' mixColor: 'transparent' # default: '#fff' backgroundColor: 'transparent' # default: '#fff' buttonColorDark: '#100f2c' # default: '#100f2c' buttonColorLight: '#fff' # default: '#fff' isActivated: false # default false saveInCookies: true # default: true label: '🌓' # default: '' autoMatchOsTheme: true # default: true libUrl: # Set custom library cdn url for Darkmode.js isActivated: true：默认激活暗黑 / 夜间模式，请始终与 saveInCookies: false、autoMatchOsTheme: false 一起使用；同时需要在 NexT 主题的 _config.yml 配置文件里设置 pjax: true，即启用 Pjax。 关闭原生的暗黑模式确保 Next 原生的 darkmode 选项设置为 false，在 Next 的 _config.yml 配置文件中更改以下内容： 1darkmode: false 暗黑模式 CSS 样式自定义（可选）暗黑模式激活后，hexo-next-darkmode 插件会将 darkmode--activated CSS 类添加到 body 标签，可以利用它覆盖插件默认自带的 CSS 样式（如下所示），这样就可以实现暗黑模式 CSS 样式的高度自定义。更多配置内容介绍可以参考官方文档，实现原理分析可以看这里。 12345678910111213141516171819202122232425262728293031323334353637.darkmode--activated { --body-bg-color: #282828; --content-bg-color: #333; --card-bg-color: #555; --text-color: #ccc; --blockquote-color: #bbb; --link-color: #ccc; --link-hover-color: #eee; --brand-color: #ddd; --brand-hover-color: #ddd; --table-row-odd-bg-color: #282828; --table-row-hover-bg-color: #363636; --menu-item-bg-color: #555; --btn-default-bg: #222; --btn-default-color: #ccc; --btn-default-border-color: #555; --btn-default-hover-bg: #666; --btn-default-hover-color: #ccc; --btn-default-hover-border-color: #666; --highlight-background: #282b2e; --highlight-foreground: #a9b7c6; --highlight-gutter-background: #34393d; --highlight-gutter-foreground: #9ca9b6;}.darkmode--activated img { opacity: 0.75;}.darkmode--activated img:hover { opacity: 0.9;}.darkmode--activated code { color: #69dbdc; background: transparent;} 重新构建生成静态文件Hexo 重新构建生成静态文件后，点击页面上的按钮即可切换暗黑模式，最终演示效果可以看这里。 123$ hexo clean$ hexo g -d Next 8.x 手动添加可切换的暗黑模式关闭原生的暗黑模式确保 Next 原生的 darkmode 选项设置为 false，在 Next 的 _config.yml 配置文件中更改以下内容： 1darkmode: false 添加 JS 库 Darkmode.js下载 darkmode.js 或者直接添加 CDN 配置到 Next 的 themes/next/_vendors.yml 文件末尾，这里采用 CDN 配置的方式（如下所示） 1234darkmode_js: name: darkmode-js version: 1.5.7 file: lib/darkmode-js.min.js 添加 Darkmode.js 的启用开关在 Next 的 _config.yml 配置文件添加以下内容，值得一提的是，这里需要注意缩进，第一个 darkmode_js 是在 vendors 栏目下，第二个 darkmode_js 是一个单独的栏目 123456vendors: # Darkmode.js darkmode_js:darkmode_js: enable: true 配置 JS 库 Darkmode.js编辑 themes/next/layout/_scripts/vendors.njk 文件，将原有的代码删除掉，替换为以下代码即可： 123456789101112131415161718192021222324252627282930313233{%- if theme.canvas_ribbon.enable %} &lt;script size=\"{{ theme.canvas_ribbon.size }}\" alpha=\"{{ theme.canvas_ribbon.alpha }}\" zIndex=\"{{ theme.canvas_ribbon.zIndex }}\" src=\"{{ theme.vendors.canvas_ribbon }}\"&gt;&lt;/script&gt;{%- endif %}{# Customize darkmode.js - Declaration #}{%- if theme.darkmode_js.enable %} &lt;script src=\"{{ theme.vendors.darkmode_js }}\"&gt;&lt;/script&gt;{%- endif %}{%- for name in js_vendors() %} &lt;script src=\"{{ url_for(theme.vendors[name]) }}\"&gt;&lt;/script&gt;{%- endfor %}{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: 'unset', // default: '32px' left: '32px', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: '#fff', // default: '#fff' backgroundColor: '#fff', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: true // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 更改后的源文件就如上所示，其他内容可以根据实际情况自行更改。添加上面的代码后，暗黑模式的切换按钮默认显示在左下角，如果希望切换按钮显示在右下角，可以参考以下代码： 1234567891011121314151617181920{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: '32px', // default: '32px' left: 'unset', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: '#fff', // default: '#fff' backgroundColor: '#fff', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: false // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 暗黑模式 CSS 样式自定义实现原理分析从 Next 8.0 开始，已经原生支持代码块 Dark 主题，直接在 Next 的 _config.xml 文件里配置即可（如下所示）： 123456789codeblock: # Code Highlight theme # All available themes: https://theme-next.js.org/highlight/ theme: light: atelier-forest-light dark: androidstudio prism: light: prism dark: prism-atom-dark 其中 Next 8.3 源文件 themes/next/source/css/_colors.styl 的内容如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465:root { --body-bg-color: $body-bg-color; --content-bg-color: $content-bg-color; --card-bg-color: $card-bg-color; --text-color: $text-color; --blockquote-color: $blockquote-color; --link-color: $link-color; --link-hover-color: $link-hover-color; --brand-color: $brand-color; --brand-hover-color: $brand-hover-color; --table-row-odd-bg-color: $table-row-odd-bg-color; --table-row-hover-bg-color: $table-row-hover-bg-color; --menu-item-bg-color: $menu-item-bg-color; --btn-default-bg: $btn-default-bg; --btn-default-color: $btn-default-color; --btn-default-border-color: $btn-default-border-color; --btn-default-hover-bg: $btn-default-hover-bg; --btn-default-hover-color: $btn-default-hover-color; --btn-default-hover-border-color: $btn-default-hover-border-color; --highlight-background: $highlight-background; --highlight-foreground: $highlight-foreground; --highlight-gutter-background: $highlight-gutter-background; --highlight-gutter-foreground: $highlight-gutter-foreground;}if (hexo-config('darkmode')) { @media (prefers-color-scheme: dark) { :root { --body-bg-color: $body-bg-color-dark; --content-bg-color: $content-bg-color-dark; --card-bg-color: $card-bg-color-dark; --text-color: $text-color-dark; --blockquote-color: $blockquote-color-dark; --link-color: $link-color-dark; --link-hover-color: $link-hover-color-dark; --brand-color: $brand-color-dark; --brand-hover-color: $brand-hover-color-dark; --table-row-odd-bg-color: $table-row-odd-bg-color-dark; --table-row-hover-bg-color: $table-row-hover-bg-color-dark; --menu-item-bg-color: $menu-item-bg-color-dark; --btn-default-bg: $btn-default-bg-dark; --btn-default-color: $btn-default-color-dark; --btn-default-border-color: $btn-default-border-color-dark; --btn-default-hover-bg: $btn-default-hover-bg-dark; --btn-default-hover-color: $btn-default-hover-color-dark; --btn-default-hover-border-color: $btn-default-hover-border-color-dark; --highlight-background: $highlight-background-dark; --highlight-foreground: $highlight-foreground-dark; --highlight-gutter-background: $highlight-gutter-background-dark; --highlight-gutter-foreground: $highlight-gutter-foreground-dark; } img { opacity: .75; &amp;:hover { opacity: .9; } } }} 暗黑模式激活后，Darkmode.js 默认会将 darkmode--activated CSS 类添加到 body 标签，可以利用它覆盖暗黑模式默认的 CSS 样式。换句话说，只要将上面的 themes/next/source/css/_colors.styl 里的 CSS 样式添加到 darkmode--activated CSS 类的下面，就可以实现暗黑模式的 CSS 样式自定义。 实现步骤介绍 第一步：创建 themes/next/source/css/_custom/darkmode.styl 源文件，并将以下内容写入到文件里，code 样式用于控制暗黑模式下的代码块颜色显示 12345678910111213141516171819202122232425262728293031323334353637383940.darkmode--activated{ --body-bg-color: $body-bg-color-dark; --content-bg-color: $content-bg-color-dark; --card-bg-color: $card-bg-color-dark; --text-color: $text-color-dark; --blockquote-color: $blockquote-color-dark; --link-color: $link-color-dark; --link-hover-color: $link-hover-color-dark; --brand-color: $brand-color-dark; --brand-hover-color: $brand-hover-color-dark; --table-row-odd-bg-color: $table-row-odd-bg-color-dark; --table-row-hover-bg-color: $table-row-hover-bg-color-dark; --menu-item-bg-color: $menu-item-bg-color-dark; --btn-default-bg: $btn-default-bg-dark; --btn-default-color: $btn-default-color-dark; --btn-default-border-color: $btn-default-border-color-dark; --btn-default-hover-bg: $btn-default-hover-bg-dark; --btn-default-hover-color: $btn-default-hover-color-dark; --btn-default-hover-border-color: $btn-default-hover-border-color-dark; --highlight-background: $highlight-background-dark; --highlight-foreground: $highlight-foreground-dark; --highlight-gutter-background: $highlight-gutter-background-dark; --highlight-gutter-foreground: $highlight-gutter-foreground-dark; img { opacity: .75; &amp;:hover { opacity: .9; } } code { color: #69dbdc; background: transparent; }} 若添加上述 CSS 样式后，暗黑模式的切换按钮点击无效，那么可以尝试追加以下样式来解决 123button.darkmode-toggle { z-index: 9999;} 第二步：在 themes/next/source/css/main.styl 文件里引入上面创建的 CSS 文件即可 1@import '_custom/darkmode.styl'; 第三步：在 themes/next/layout/_scripts/vendors.njk 里更改 Darkmode.js 的颜色配置（如下所示），其中主要设置 mixColor: 'transparent' 与 backgroundColor: 'transparent'，否则自定义的暗黑模式 CSS 样式无法达到预期的显示效果 12345678910111213141516171819202122232425{# Customize darkmode.js - Declaration #}{%- if theme.darkmode_js.enable %} &lt;script src=\"{{ theme.vendors.darkmode_js }}\"&gt;&lt;/script&gt;{%- endif %}{# Customize darkmode.js - Invokation #}{%- if theme.darkmode_js.enable %}&lt;script&gt;var options = { bottom: '64px', // default: '32px' right: 'unset', // default: '32px' left: '32px', // default: 'unset' time: '0.5s', // default: '0.3s' mixColor: 'transparent', // default: '#fff' backgroundColor: 'transparent', // default: '#fff' buttonColorDark: '#100f2c', // default: '#100f2c' buttonColorLight: '#fff', // default: '#fff' saveInCookies: true, // default: true, label: '🌓', // default: '' autoMatchOsTheme: true // default: true}const darkmode = new Darkmode(options);darkmode.showWidget();&lt;/script&gt;{%- endif %} 重新构建生成静态文件Hexo 重新构建生成静态文件后，点击页面上的按钮即可切换暗黑模式 123$ hexo clean$ hexo g -d 支持评论系统的暗黑模式Waline 评论系统 Waline 评论系统启用暗黑模式 最终演示效果 常见问题评论区留言反馈若暗黑模式无法生效，你可以在下方的评论区留言，或者创建 GitHub Issue。希望你在留言的时候，能提供 NexT 主题的版本 + 博客链接，这样方便博主跟踪并帮你解决问题。 Darkmode.js 详细配置 Darkmode Github Chrome 无法正常显示切换按钮的图标默认的切换按钮图标 label: '🌓' 是 Emoji 表情字符，部分浏览器（如 Chrome）可能会显示为一个方块。解决方法是访问 Chrome 网上应用商店，手动安装 Chromoji 浏览器插件，即可让 Chrome 正常显示 Emoji 表情字符。请确保可以科学上网，否则无法正常访问 Chrome 的网上应用商店。若此方法依旧无法解决该问题，请参考下方评论区中网友 busyops 给出的解决方案，或在评论区留言，笔者会及时回复你。","tags":"静态博客"},{"title":"PyCharm 2021.1 最新专业版激活教程","url":"/posts/cfba1e15.html","text":"前言本文适用于 PyCharm 2021.1 最新专业版的激活，由于 PyCharm 更新到 2021.1 版本后，之前所有的激活方式好像都失效了，所以今天介绍下最新的激活方式。该激活方法适用于 Jetbrains 全家桶任何版本，即使是从官网下载的最新版本，亲测可成功激活。 资源下载 Python 官网下载 PyCharm 官网下载 Jetbrains 激活插件下载（本站） PyCharm 激活更改 Hosts 文件更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com PyCharm 安装与试用下载安装 PyCharm，然后启动 PyCharm 并选择试⽤（Evaluate for free）模式进⼊软件（如下图）。假设软件之前激活过且已失效、正在试用、试用过且已过期，那么必须先删除 PyCharm 的所有配置文件，然后再重新启动软件，PyCharm 配置文件所在的目录如下： 1234567# Windows系统C:\\Documents and Settings\\Administrator\\.PyCharm2021.1\\configC:\\Documents and Settings\\Administrator\\.PyCharm2021.1\\system# Linux/Mac系统~/.config/JetBrains/PyCharm2021.1~/.local/share/JetBrains/PyCharm2021.1 PyCharm 创建或选择项目选择创建项目或者打开已存在的项目 选择好项目路径和 Python 解释器后，点击 create 按钮后，进入 Pycharm 的主界面 PyCharm 激活这里的激活方式就是通过激活插件，让 PyCharm 可以一直试用，本质是重置 PyCharm，最终达到无限次试用 30 天的效果。值得一提的是，此激活方法会彻底重置 PyCharm，任何配置信息都将丢失，和新安装的时候一样。 离线激活方式首先手动下载好 PyCharm 的激活插件，然后启动 PyCharm 后，菜单栏导航到 file -&gt; settings -&gt; Plugins，依次点击 齿轮 -&gt; Install Plugin from Disk...，找到激活插件所在目录，选中本地激活文件 ide-eval-resetter-2.1.13.zip，最后点击 OK 按钮即可 在线激活方式启动 PyCharm 后，菜单栏导航到 file -&gt; settings -&gt; Plugins，依次点击 齿轮 -&gt; Manage Plugin Repositories...，点击 + 添加仓库 URL https://plugins.zhile.io，然后点击 OK 按钮 点击 Plugins -&gt; Maketplace，搜索 IDE Eval Reset 插件，然后点击 Install 按钮进行安装，如果搜索不到对应的插件，请检查网络是否通畅 PyCharm 激活插件配置一般来说，在 IDE 窗口切出去或切回来时（窗口失去 / 得到焦点）会触发事件，检测是否长时间（2 5 天）内没有重置，然后发送通知让你选择重置。也可以手动唤出激活插件的主界面，打开 PyCharm 的主界面，菜单栏导航到 Help -&gt; Eval Reset，弹出如下提示框，其中包括 2 个按钮，1 个勾选项： Reload 按钮：用来刷新界面上的显示信息 Reset 按钮：点击会询问是否重置试用信息并重启 IDE。选择 Yes 则执行重置操作并重启 IDE 生效，选择 No 则什么也不做（此为手动重置方式） Auto reset before per restart 勾选项：如果勾选了，则自勾选后每次重启 / 退出 IDE 时会自动重置试用信息，无需做额外的事情（此为自动重置方式） 常见问题Pycharm 无限重启如果 Pycharm 无限重启，说明之前的激活插件（例如 BetterInterlliJ）没有卸载，请卸载干净再重新激活 PyCharm 激活失败如果之前在 hosts 中添加过 0.0.0.0 account.JetBrains.com 和 0.0.0.0 www.JetBrains.com，请删除掉对应的内容再重新激活 如何更新激活插件 IDE 会自行检测其自身和所安装插件的更新并给予提示，如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新 菜单栏导航到 Check for Updates...，手动检测 IDE 和所安装插件的更新，如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新 插件更新可能会需要重启 IDE 付费插件重置说明市场上付费插件的试用信息也会一并重置，MyBatisCodeHelperPro 插件有两个版本如下，功能完全相同，安装时须看清楚： MyBatisCodeHelperPro (Marketplace Edition)，可重置！ MyBatisCodeHelperPro，不可重置！ 对于某些付费插件（如: Iedis 2, MinBatis）来说，可能需要去除掉 javaagent 配置（如果有）后再重启 IDE： 如果 IDE 没有打开项目，在 Welcome 界面点击菜单： Configure -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的内容 如果 IDE 打开了项目，点击菜单：Help -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的内容 重置需要重启 IDE 才生效 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"构建 Hexo Next 主题的源码","url":"/posts/63112f7b.html","text":"核心源文件布局模板文件 /themes/next/layout/_layout.njk /themes/next/layout/_macro/post.njk 更改 Next 主题的源码NJK 模版文件判断是否为首页1{%- if is_index %} ... {%- endif %} 1{%- if not is_index %} ... {%- endif %} 引入自定义的 NJK 模版文件默认以 /theme/next/layout 为根目录，不需要使用 ../ 符号来引用上级目录中的模版文件 1{{ partial('_partials/_custom/adsense/post-footer-ads.njk') }} 下述这种引入方式只能引入当前目录下（包括子目录）的模版文件，无法使用 ../ 符号来引用上级目录中的模版文件 1{%- include '_custom/adsense/post-footer-ads.njk' -%} NJK 模版文件获取 Hexo 的配置信息获取 Hexo 的配置文件 _config.yml 的内容： 1{%- if config.excerpt_description %} ... {%- endif %} 或者 123456&lt;div style=\"text-align:center\"&gt; &lt;ins class=\"ads\" style=\"display:block\" data-ad-client=\"{{ config.adsense.publisher_id }}\" data-full-width-responsive=\"true\"&gt;&lt;/ins&gt;&lt;/div&gt; NJK 模版文件获取 Next 的配置信息获取 Next 主题的配置文件 /theme/next/_config.yml 的内容： 1{%- if theme.excerpt_description %} ... {%- endif %} 或者 123456&lt;div style=\"text-align:center\"&gt; &lt;ins class=\"ads\" style=\"display:block\" data-ad-client=\"{{ theme.adsense.publisher_id }}\" data-full-width-responsive=\"true\"&gt;&lt;/ins&gt;&lt;/div&gt; NJK 模版文件获取文章的 Meta 信息1{%- if post.description and theme.excerpt_description %} ... {%- endif %} 覆盖 Next 默认的 CSS 样式123.vpreview p { color: #444 !important;} 取消 Next 默认的 CSS 样式123.comments { overflow: unset;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"Python 常用命令","url":"/posts/1e59ef45.html","text":"Pip 管理模块单个更新模块12345678# 列出所有已安装的模块# pip list# 列出所有过期的模块# pip list --outdated# 更新指定的模块# pip install --upgrade requests 批量更新模块12345# 安装更新工具# pip install pip-review# 批量更新模块# pip-review --local --interactive --auto 批量卸载模块12345# 列出所有已安装的模块# pip freeze &gt; py.txt# 卸载所有已安装的模块# pip uninstall -y -r py.txt var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"python"},{"title":"Gateway + Security + OAuth 2.0 + JWT 实现统一的认证授权","url":"/posts/2cb9090c.html","text":"1、前言1.1、OAuth 2.0 介绍 OAuth 2.0 特性与介绍 1.2、OAuth 2.0 与 JWT 的关系 OAuth 2.0 是一种认证授权的协议规范 JWT 是基于 Token 的安全认证协议的实现 OAuth 2.0 的认证服务器签发的 Token 可以使用 JWT 来实现，JWT 轻量且安全。 1.3、基于 OAuth 2.0 认证授权的框架OAuth 的官网提供了很多开发框架，分为服务器端和客户端，其中服务端和客户端都支持的 Java 框架有四个：Apache Oltu、Spring Security OAuth、Restlet Framework、Keycloak。值得一提的是，Keycloak 为现代应用和分布式服务提供了一套完整的认证授权管理开源解决方案，是一个独立的认证授权服务器；主要是基于 OAuth 2.0 协议实现，同时提供了多种语言库，可以很快速地根据业务需求将 Keycloak 集成到企业项目中去使用。 2、Gateway + Security + OAuth 2.0 + Knife4j2.1、认证授权流程 用户携带账号密码通过网关服务请求认证服务 认证通过后，授权服务颁发身份令牌给客户端，并将身份令牌储存在 Redis/MySQL 中 用户携带身份令牌请求资源服务（微服务应用），必经网关服务 网关服务获取客户端带来的令牌和 Redis/MySQL 中的令牌进行比对校验 网关服务校验通过后，转发 HTTP 请求，资源服务（微服务应用）获取到身份令牌，进行身份校验和鉴权，通过后处理系统业务 资源服务（微服务应用）将响应数据返回给客户端 提示 Gateway 校验并解析外部传递过来的身份令牌后，可以获取到用户信息（身份 + 权限），并将用户信息写入到 HTTP Header 里，让后续的微服务可以方便地得到用户信息 2.2、应用架构设计12345├── common 基础模块├── eureka 注册中心模块├── gateway 网关模块，负责校验认证（Token）、请求转发、统一解析用户信息├── shop 业务模块，负责校验认证（Token） 、鉴权└── auth 认证模块，负责用户的Oauth2.0认证授权，基于MySQL存储 认证服务负责认证和授权，网关服务只负责校验认证（Token）、请求转发和统一解析用户信息，业务模块负责校验认证（Token）和鉴权。由于 gateway、shop 模块没有使用 MySQL 存储，暂时无法实现注销 Token 的功能；若两者都引入 MySQL 存储，感觉应用有点重（依赖 ORM 框架，而且可能出现多数据源的场景），或者需要使用 Redis 存储来替代 MySQL 存储。终上所述，如果不考虑提供注销 Token 的功能，该方案还是可以接受的。 2.3、下载案例代码 Gateway + Security + OAuth 2.0 + Knife4j 整合案例代码下载 3、Gateway + Security + OAuth 2.0 + JWT3.1、应用架构设计123├── micro-oauth2-api 受保护的API服务，用户被网关服务鉴权通过后可以访问该服务，不整合Spring Security + Oauth2.0├── micro-oauth2-auth Oauth2.0认证服务，负责对登录用户进行认证授权，整合Spring Security + Oauth2.0，基于Redis存储└── micro-oauth2-gateway 网关服务，负责校验认证（Token）、鉴权和请求转发等，整合Spring Security + Oauth2，基于Redis存储 认证服务负责认证和授权，网关负责校验认证（Token）和鉴权，其他 API 服务则只负责处理自己的业务逻辑。安全相关的逻辑只存在于认证服务和网关服务中，其他 API 服务只是单纯地提供服务而没有任何安全相关逻辑。这种应用架构要求所有 HTTP 请求都必须经过网关服务，同时任何 API 服务都不能暴露在外网，否则会存在极大的安全隐患。 3.2、下载案例代码 Gateway + Security + OAuth 2.0 + JWT 整合案例代码下载 4、延伸内容4.1、Knife4j 整合 OAuth 2.0 Knife4j 整合 OAuth 2.0 4.2、网关是否适合进行认证与鉴权 第一派系：网关不适合进行业务操作，所以做个简单的去 Redis 比较 Token 校验是正确思路，剩下的交给后续的服务做 优点：不用在网关服务引入多余的 Spring Security、ORM 框架 缺点：第二派系的优点 第二派系： 网关用来认证与鉴权，登录蹦不蹦已经不是问题了，毕竟网关宕机，代表系统瘫痪了 优点：权限方面的代码会很好写，控制 URL 即可 缺点：第一派系的优点 第三派系： 网关用来认证与鉴权，但鉴权所需的数据（用户、角色、权限）从 Caffeine + Redis 缓存中加载，而认证授权服务启动时，负责将 MySQL 中权限相关的数据提前加载到 Redis 优点：第一与第二派系的优点 缺点：严重依赖 Redis，一般需要部署维护 Redis 集群，如果 Redis 集群宕机，可能会造成网关鉴权功能不可用或者系统瘫痪 4.3、基于 HTTP Header 传递用户信息的缺点基于 Spring Cloud 的技术体系（RESTful 接口规范），Gateway 校验并解析外部传递过来的 Access Token 后，获取到用户信息（身份 + 权限），同时将用户信息写入到 HTTP Header 里，让后面的业务系统接收到 Gateway 转发过来的请求后，也能从 HTTP Header 里得到相应的用户信息。但这种方式对使用了 RPC 调用的场景不适用，因为在 RPC 调用里，无法从 HTTP Header 获取到任何数据，该问题的讨论可以关注这里。 5、参考博客 API 网关认证授权 OAuth 2.0 的 Java 各类配置与使用场景 FAQ Spring Cloud Gateway + Security + OAuth 2.0 搭建微服务统一认证授权 Spring Cloud Gateway + Security + OAuth 2.0 + JWT 实现微服务统一认证鉴权 Spring Cloud Gateway + Security + OAuth 2.0 + JWT 集成统一认证授权平台下实现注销使 JWT 失效方案 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 oauth"},{"title":"构建 Privoxy、Tor、ExpressVPN 的 Docker 镜像","url":"/posts/3fe8dbc5.html","text":"前言教程目标构建集成了 Privoxy、Tor、ExpressVPN、SpeedTest 服务的 Docker 镜像，支持使用 SpeedTest 测试 ExpressVPN 的连接速度。Docker 镜像构建成功后，可以利用 Privoxy 与 Tor 在 ExpressVPN 的基础上，实现普通代理与匿名代理服务。 项目地址 expressvpn-privoxy-tor 构建镜像Dockerfile 文件Dockerfile 文件的内容如下，核心内容是安装 Privoxy、Tor、ExpressVPN，并指定 Privoxy 与 Tor 的监听端口 123456789101112131415161718192021222324252627FROM debian:bullseye-slimLABEL maintainer=\"benjamin@polkaned.net\"ENV ACTIVATION_CODE CodeENV LOCATION smartARG APP=expressvpn_3.25.0.13-1_amd64.debRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\ wget curl apt-utils apt-transport-https dirmngr ca-certificates expect iproute2 procps libnm0 gnupg2 tor privoxy \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; wget -q \"https://www.expressvpn.works/clients/linux/${APP}\" -O /tmp/${APP} \\ &amp;&amp; dpkg -i /tmp/${APP} \\ &amp;&amp; rm -rf /tmp/*.deb \\ &amp;&amp; apt-get purge -y --auto-remove wget \\ &amp;&amp; sed -i \\ -e 's/#SocksPort 192.168.0.1:9100/SocksPort 0.0.0.0:9050/g' \\ -e 's/#ControlPort 9051/ControlPort 9052/g' \\ /etc/tor/torrc \\ &amp;&amp; sed -i \\ -e 's/listen-address\\s*127.0.0.1:8118/listen-address 0.0.0.0:8118/g' \\ /etc/privoxy/configCOPY entrypoint.sh /tmp/entrypoint.shCOPY expressvpnActivate.sh /tmp/expressvpnActivate.shENTRYPOINT [\"/bin/bash\", \"/tmp/entrypoint.sh\"] Shell 脚本文件entrypoint.sh 文件的内容如下： 12345678910111213#!/usr/bin/bashservice tor startservice privoxy startcp /etc/resolv.conf /tmp/resolv.confsu -c 'umount /etc/resolv.conf'cp /tmp/resolv.conf /etc/resolv.confsed -i 's/DAEMON_ARGS=.*/DAEMON_ARGS=\"\"/' /etc/init.d/expressvpnservice expressvpn restart/usr/bin/expect /tmp/expressvpnActivate.shexpressvpn connect $SERVERexec \"$@\" expressvpnActivate.sh 文件的内容如下： 1234567#!/usr/bin/expectspawn expressvpn activateexpect \"code:\"send \"$env(ACTIVATION_CODE)\\r\"expect \"information.\"send \"n\\r\"expect eof 构建 Docker 镜像由于这里需要从官网下载 ExpressVPN 的安装包，因此构建 Docker 镜像时，必须保证可以科学上网，否则无法正常构建镜像。温馨提示，若无法提供科学上网的条件，可参考这里的方案来解决。 1# docker build --pull --no-cache --rm --force-rm -f Dockerfile -t polkaned/privoxy-tor-expressvpn:latest . 运行容器Docker 运行容器 {% your-activation-code %}：ExpressVPN 的激活码，例如 ACTIVATION_CODE=ABCD1EBGH2IJAL3MNOP4QRS {% LOCATION/ALIAS/COUNTRY %}：ExpressVPN 的连接位置，例如 SERVER=jpyo，若为空值则默认使用 ExpressVPN 的智能位置 1234567891011121314docker run \\ --env=ACTIVATION_CODE={% your-activation-code %} \\ --env=SERVER={% LOCATION/ALIAS/COUNTRY %} \\ --cap-add=NET_ADMIN \\ --device=/dev/net/tun \\ --privileged \\ --detach=true \\ --tty=true \\ -p 9050:9050 \\ -p 9052:9052 \\ -p 8118:8118 \\ --name=expressvpn \\ polkaned/privoxy-tor-expressvpn \\ /bin/bash Docker-Compose 运行容器docker-compose.yml 文件的内容如下： 12345678910111213141516171819202122version: \"3.5\"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 tty: true stdin_open: true command: /bin/bash 若其他容器需要使用 ExpressVPN，那么可以参考以下配置内容： 1234567891011121314151617181920212223242526272829version: \"3.5\"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 tty: true stdin_open: true command: /bin/bash downloader: image: example/downloader container_name: downloader network_mode: service:expressvpn depends_on: - expressvpn 通过 Docker-Compose 创建并启动 Docker 容器 12345# 创建并启动容器# docker-compose up -d# 查看容器的日志信息# docker logs -f --tail 20 expressvpn 测试 Privoxy 与 Tor 代理是否可用12345# 测试Privoxy$ curl -I -x 127.0.0.1:8118 www.google.com# 测试Tor$ curl --socks5 127.0.0.1:9050 www.google.com 进阶配置Privoxy 代理 Tor（可选）若希望 Privoxy 代理 Tor，可以在 /etc/privoxy/config 配置文件的末尾添加以下内容： 1forward-socks5 / 0.0.0.0:9050 . 限制请求来源的 IP（可选）若希望限制访问 Privoxy 代理服务的 IP，即新增 IP 白名单，则可以在 /etc/privoxy/config 配置文件的末尾添加以下内容： 123456# 编辑配置文件，IP需要根据实际情况进行更改# vim /etc/privoxy/configpermit-access 14.215.177.38/26# 重启容器让配置变更生效# docker restart expressvpn 挂载本地配置文件（可选）1）启动 Docker 容器后，分别拷贝一份 Privoxy、Tor 的配置文件到宿主机的本地磁盘 1234567# 创建宿主机本地的配置文件目录# mkdir -p /usr/local/tor# mkdir -p /usr/local/privoxy# 拷贝容器里的配置文件到宿主机的本地磁盘# docker cp expressvpn:/etc/tor/torrc /usr/local/tor/torrc# docker cp expressvpn:/etc/privoxy/config /usr/local/privoxy/config 2）创建 Privoxy 的 user.action 配置文件，用于阻止 Privoxy 指向服务器本身的 IP 和域名，这里请替换为你自己真实服务器的 IP 和域名 12345# 创建文件$ touch /usr/local/privoxy/user.action# 写入以下内容到文件中$ vim /usr/local/privoxy/user.action 12{+block{block ip and domain which point to server itself}}127.0.0.1 3）创建 Privoxy 的 user.filter 配置文件，用于存放 Privoxy 的过滤规则，暂时不需要填写任何内容 1$ touch /usr/local/privoxy/user.filter 4）更改 docker-compose.yml 文件，添加数据卷的配置内容（如下所示） 123456789101112131415161718192021222324252627version: \"3.5\"services: expressvpn: container_name: expressvpn image: polkaned/privoxy-tor-expressvpn:latest privileged: true restart: always environment: - ACTIVATION_CODE={% your-activation-code %} - SERVER={% LOCATION/ALIAS/COUNTRY %} cap_add: - NET_ADMIN devices: - /dev/net/tun ports: - 9050:9050 - 9052:9052 - 8118:8118 volumes: - /usr/local/tor/torrc:/etc/privoxy/torrc - /usr/local/privoxy/config:/etc/privoxy/config - /usr/local/privoxy/user.action:/etc/privoxy/user.action - /usr/local/privoxy/user.filter:/etc/privoxy/user.filter tty: true stdin_open: true command: /bin/bash VPN 管理ExpressVPN 常用管理命令123456789101112131415161718192021# 优化ExpressVPN的配置# docker exec -it expressvpn expressvpn protocol lightway_udp# docker exec -it expressvpn expressvpn preferences set desktop_notifications false# 查看ExpressVP的配置信息# docker exec -it expressvpn expressvpn preferences# 查看ExpressVPN的连接状态# docker exec -it expressvpn expressvpn status# 查看ExpressVPN的可连接地区# docker exec -it expressvpn expressvpn list# 连接VPN（智能连接）# docker exec -it expressvpn expressvpn connect# 连接VPN，并指定连接的地区# docker exec -it expressvpn expressvpn connect jpyo# 断开VPN连接# docker exec -it expressvpn expressvpn disconnect VPN 测速ExpressVPN 使用 SpeedTest 测速若希望测试 ExpressVPN 的连接速度，则可以安装 SpeedTest 来实现，更改后完整的 Dockerfile 如下： 1234567891011121314151617181920212223242526272829FROM debian:bullseye-slimLABEL maintainer=\"benjamin@polkaned.net\"ENV ACTIVATION_CODE CodeENV LOCATION smartARG APP=expressvpn_3.18.1.0-1_amd64.debRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\ wget curl apt-utils apt-transport-https dirmngr ca-certificates expect iproute2 procps libnm0 gnupg2 tor privoxy \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; wget -q \"https://www.expressvpn.works/clients/linux/${APP}\" -O /tmp/${APP} \\ &amp;&amp; dpkg -i /tmp/${APP} \\ &amp;&amp; rm -rf /tmp/*.deb \\ &amp;&amp; apt-get purge -y --auto-remove wget \\ &amp;&amp; sed -i \\ -e 's/#SocksPort 192.168.0.1:9100/SocksPort 0.0.0.0:9050/g' \\ -e 's/#ControlPort 9051/ControlPort 9052/g' \\ /etc/tor/torrc \\ &amp;&amp; sed -i \\ -e 's/listen-address\\s*127.0.0.1:8118/listen-address 0.0.0.0:8118/g' \\ /etc/privoxy/config \\ &amp;&amp; curl -s https://install.speedtest.net/app/cli/install.deb.sh | bash \\ &amp;&amp; apt-get install speedtestCOPY entrypoint.sh /tmp/entrypoint.shCOPY expressvpnActivate.sh /tmp/expressvpnActivate.shENTRYPOINT [\"/bin/bash\", \"/tmp/entrypoint.sh\"] 使用命令行测试 ExpressVPN 的连接速度： 12345# 测速# docker exec -it expressvpn speedtest# 测速，并指定网速的显示单位# docker exec -it expressvpn speedtest -u kB/s SpeedTest 支持显示的网速单位如下： 1234Decimal prefix, bits per second: bps, kbps, Mbps, GbpsDecimal prefix, bytes per second: B/s, kB/s, MB/s, GB/sBinary prefix, bits per second: kibps, Mibps, GibpsBinary prefix, bytes per second: kiB/s, MiB/s, GiB/s 常见问题ExpressVPN 版本更新若日后希望更新 ExpressVPN 的版本，只需要执行以下两步操作即可： 1）更改 Dockerfile 里 ExpressVPN 安装包的文件名 1234FROM debian:bullseye-slim...ARG APP=expressvpn_3.18.1.0-1_amd64.deb... 2）重新构建 Docker 镜像 1# docker build --pull --no-cache --rm --force-rm -f Dockerfile -t polkaned/privoxy-tor-expressvpn:latest . Chrome 浏览器使用 Privoxy 代理若希望 Chrome 浏览器智能切换至 Docker + ExpressVPN + Privoxy/Tor 提供的代理服务（实现国内外流量分流功能），可以安装 SwitchyOmega 浏览器插件来实现，具体使用方式这里不再累述，更多资料可参考以下链接： Proxy SwitchyOmega 的项目地址 Proxy SwitchyOmega 的 Chrome 应用商店安装地址 构建 Docker 镜像时无法科学上网在上面的教程里，必须保证可以科学上网才能正常构建 Docker 镜像。特殊情况下，可能无法提供科学上网的条件，此时可以通过其他途径手动下载 ExpressVPN 最新版本的 Debian/Ubuntu 安装包，并将安装包重命名为 expressvpn_amd64.deb，然后更改上面的 Dockerfile 的内容（如下所示），这样就可以直接构建 Docker 镜像，不再需要依赖科学上网了。 12345678910111213141516171819202122232425FROM debian:bullseye-slimLABEL maintainer=\"benjamin@polkaned.net\"ENV ACTIVATION_CODE CodeENV LOCATION smartCOPY expressvpn_amd64.deb /tmp/expressvpn_amd64.debRUN dpkg -i /tmp/expressvpn_amd64.deb &amp;&amp; rm -rf /tmp/expressvpn_amd64.debRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\ curl apt-utils apt-transport-https dirmngr ca-certificates expect iproute2 procps libnm0 gnupg2 tor privoxy \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; sed -i \\ -e 's/#SocksPort 192.168.0.1:9100/SocksPort 0.0.0.0:9050/g' \\ -e 's/#ControlPort 9051/ControlPort 9052/g' \\ /etc/tor/torrc \\ &amp;&amp; sed -i \\ -e 's/listen-address\\s*127.0.0.1:8118/listen-address 0.0.0.0:8118/g' \\ /etc/privoxy/configCOPY entrypoint.sh /tmp/entrypoint.shCOPY expressvpnActivate.sh /tmp/expressvpnActivate.shENTRYPOINT [\"/bin/bash\", \"/tmp/entrypoint.sh\"] 参考资料 Tor Privoxy ExpressVPN Dockerfiles Docker 安装 Privoxy 代理服务 Centos7 安装 ExpressVPN 客户端 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化 开发工具"},{"title":"Spring Security + OAuth 2.0 + JWT 开发随笔","url":"/posts/894ad1eb.html","text":"JWT 签名与验签公钥与私钥生成使用 JDK 提供的 keytool 工具生成 JKS 密钥库 (Java Key Store)，认证授权服务器会使用私钥对 Token 进行签名，一般将生成的 shop.jks 文件放在 resources 目录下 1keytool -genkey -alias shop -keyalg RSA -keypass 123456 -keystore shop.jks -storepass 123456 根据私钥生成公钥，将其保存在 public.crt 文件中，用于对 Token 进行验签，一般将其放 resources 目录下 1keytool -list -rfc --keystore shop.jks | openssl x509 -inform pem -pubkey -noout 123456789-----BEGIN PUBLIC KEY-----MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtXKXj3JGNJNWVXg4+++4FtNTJre+8kHLdPLwHJJcRw4aV7oMMjI1nesyj75w/kjRZImhbNo0poEu1jj+sDO9UbLUHSy59zoDDMZTYmbkboDEpkFq3ZUhAoLtt5DtAgI8DkOK22RlSxXpcMvkeL8XziFizWf/HatSgAat/SfX+5dH3KX40piPv9kI5YVJz1GyD8xO4dN95tr0Ld7FDmdKJBPWfkM+CMlKRhYqB+sAlaQW5/L3xb3WNftucC/RhdKT8/mmgMsIBhUZOS/1iFnDKuPsEwU5xEQxK9pWX2bWsSkeOgQYJmQa6hiWBuujPUyOs4rICvniopxsW2yyPOFXZQIDAQAB-----END PUBLIC KEY----- 认证授权服务器加载 JKS 秘钥库认证授权服务器加载 JKS 秘钥库，从中获取密钥对（公钥 + 私钥），Java 示例代码如下： 1234567891011/** * 从ClassPath下的密钥库中获取密钥对（公钥+私钥） * * @return */@Beanpublic KeyPair keyPair() { KeyStoreKeyFactory factory = new KeyStoreKeyFactory(new ClassPathResource(\"shop.jks\"), \"123456\".toCharArray()); KeyPair keyPair = factory.getKeyPair(\"shop\", \"123456\".toCharArray()); return keyPair;} 认证授权服务器暴露获取公钥的接口对外暴露 JWK Set URI 接口，让其他应用系统可以获取到公钥 1234567891011121314151617181920@RestController@RequestMapping(\"/oauth\")public class JwkSetController { @Autowired private KeyPair keyPair; /** * 获取公钥 * * @return */ @GetMapping(\"/.well-known/jwks.json\") public Map&lt;String, Object&gt; publicKey() { RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); RSAKey key = new RSAKey.Builder(publicKey).build(); return new JWKSet(key).toJSONObject(); }} 或者通过 KeyPair 来获取公钥 123456789101112131415161718@RestController@RequestMapping(\"/oauth\")public class PublicKeyController { @Autowired private KeyPair keyPair; /** * 获取公钥 * * @return */ @GetMapping(\"/publicKey\") public String publicKey() { return Base64.encode(new String(keyPair.getPublic().getEncoded())); }} 或者直接使用 OAuth 2.0 内置的接口 /oauth/token_key 来获取公钥 12# 下述的\"127.0.0.1:8080\"是认证授权服务器的地址$ curl --request GET 'http://127.0.0.1:8080/oauth/token_key 1234{ \"alg\": \"SHA256withRSA\", \"value\": \"-----BEGIN PUBLIC KEY-----\\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtXKXj3JGNJNWVXg4+++4FtNTJre+8kHLdPLwHJJcRw4aV7oMMjI1nesyj75w/kjRZImhbNo0poEu1jj+sDO9p8n5oYXn3qU8bsmqLa/vttq7Ubi4a5eaoP8ASjoD+dnQ0I7ZdpH/fiiHfriGI4tFziFizWf/HatSgAat/SfX+5dk3KX40piPv9kI5YVJz1GyD8xO4dN9dtr0Ld7FDmdKJBPWfkM+CMlKRhYqB+sAlaQW5/L3xb3WNftucC/RhdKT8/mmgMsIBhUZOS/1iFnDKaPsEwU5xEQxK9pWX2bWsSkeOgQYJmQa6hiWBuujPUyOs4rICvniopxsW2yyPOFXZQIDAQAB\\n-----END PUBLIC KEY-----\"} 资源服务器指定公钥文件的路径在 YML 配置里指定认证授权服务器暴露的 JWK Set URI 接口，以此来获取公钥，值得一提的是，默认情况下 jwk-set-uri 指定的 URL 无法使用 Ribbon 来实现负载均衡访问（除非利用 DNS 的域名解析，即单个域名绑定多个 IP，通过 DNS 服务器做负载均衡） 12345678spring: application: name: gateway-server security: oauth2: resourceserver: jwt: jwk-set-uri: http://127.0.0.1:8080/oauth/.well-known/jwks.json 或者将上面通过 keytool 工具获取到的公钥拷贝到 src/main/resources/public.crt 文件中，然后在 YML 配置里指定公钥文件的路径 12345678spring: application: name: gateway-server security: oauth2: resourceserver: jwt: public-key-location: classpath:public.crt Cannot convert access token to JSON 错误应用启动后，出现 Cannot convert access token to JSON 这个错误，主要是 OAuth 2.0 的资源服务器缺少了加载公钥的配置，解决方法如下： 123456789@Beanpublic JwtAccessTokenConverter accessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); // 获取公钥 String publicKey = getPublicKey(); // 加载公钥 converter.setVerifier(new RsaVerifier(publicKey)); return converter;} 资源服务器加载公钥的完整示例代码如下： 1234567891011121314151617181920212223242526 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.75&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;xom&lt;/groupId&gt; &lt;artifactId&gt;xom&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jdom&lt;/groupId&gt; &lt;artifactId&gt;jdom&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.5.8&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124import cn.hutool.core.io.FileUtil;import cn.hutool.core.util.StrUtil;import com.alibaba.fastjson.JSONObject;import net.sf.json.xml.XMLSerializer;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.autoconfigure.security.oauth2.resource.OAuth2ResourceServerProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.ClassPathResource;import org.springframework.core.io.Resource;import org.springframework.security.jwt.crypto.sign.RsaVerifier;import org.springframework.security.oauth2.provider.token.TokenStore;import org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter;import org.springframework.security.oauth2.provider.token.store.JwtTokenStore;import org.springframework.web.client.RestTemplate;import java.io.BufferedReader;import java.io.InputStreamReader;import java.util.stream.Collectors;/** * OAuth2.0认证的Token配置 */@Configurationpublic class OAuthTokenConfig { /** * 获取公钥的接口地址 */ @Value(\"${spring.security.oauth2.resourceserver.jwt.key-set-uri:}\") private String keySetUri; private OAuth2ResourceServerProperties resourceServerProperties; private static final Logger logger = LoggerFactory.getLogger(OAuthTokenConfig.class); public OAuthTokenConfig(OAuth2ResourceServerProperties resourceServerProperties) { this.resourceServerProperties = resourceServerProperties; } @Bean public TokenStore tokenStore() { return new JwtTokenStore(accessTokenConverter()); } @Bean public JwtAccessTokenConverter accessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); String publicKey = getPublicKey(); converter.setVerifier(new RsaVerifier(publicKey)); logger.info(\"success to load public key\"); return converter; } /** * 通过读取本地文件获取非对称加密公钥 * * @return 公钥 */ private String getPublicKey() { if (StrUtil.isBlank(keySetUri)) { return getKeyFromLocal(); } else { return getKeyFromAuthorizationServer(); } } /** * 通过访问授权服务器获取非对称加密公钥&lt;br&gt; * 这里可以直接使用OAuth2.0内置的接口来获取公钥，Key Set Uri 地址配置示例： http://127.0.0.1:8080/oauth/token_key * * @return 公钥 */ private String getKeyFromAuthorizationServer() { try { XMLSerializer xmlSerializer = new XMLSerializer(); String xmlPubKey = new RestTemplate().getForObject(keySetUri, String.class); String jsonPubKey = xmlSerializer.read(xmlPubKey).toString(); JSONObject json = JSONObject.parseObject(jsonPubKey); return json.get(\"value\").toString(); } catch (Exception e) { logger.error(\"failed to load public key from authorization server: {}\", e.getLocalizedMessage()); } return null; } /** * 获取本地的公钥 * * @return */ private String getKeyFromLocal() { Resource resource = getPublicKeyFile(); try (BufferedReader br = new BufferedReader(new InputStreamReader(resource.getInputStream()))) { return br.lines().collect(Collectors.joining(\"\\n\")); } catch (Exception e) { logger.error(\"failed to load public key from local: {}\", e.getLocalizedMessage()); } return null; } /** * 获取本地的公钥文件 * * @return */ private Resource getPublicKeyFile() { try { // 读取YML配置里指定的本地公钥文件，对应的YML配置如下： // spring.security.oauth2.resourceserver.jwt.public-key-location=public.crt Resource resource = resourceServerProperties.getJwt().getPublicKeyLocation(); if (FileUtil.exist(resource.getFile())) { return resource; } } catch (Exception e) { logger.error(\"failed to read public key file from local: {}\", e.getLocalizedMessage()); } // 读取默认路径下的本地公钥文件 return new ClassPathResource(\"public.crt\"); }} 123456789spring: application: name: provider-service security: oauth2: resourceserver: jwt: # public-key-location: classpath:public.crt # 加载本地的公钥文件 key-set-uri: http://127.0.0.1:8080/oauth/token_key # 从认证授权服务器获取公钥 特别注意：在上述代码中，若在 YML 文件里配置了从认证授权服务器获取公钥，那么必须使用 OAuth 2.0 内置的接口 /oauth/token_key 来获取公钥，同时使用的配置项是 key-set-uri，而不再是 jwk-set-uri OAuth 2.0 资源服务器资源服务器鉴权配置默认情况下，OAuth 2.0 的权限是从 Client 的 scope 中获取，示例代码如下： 123456789101112131415161718192021222324252627282930313233/** * 资源服务器配置 */@Configuration@EnableResourceServerpublic class OAuthResouceServer extends ResourceServerConfigurerAdapter { @Autowired private TokenStore tokenStore; /** * 资源配置 */ @Override public void configure(ResourceServerSecurityConfigurer resources) { resources.resourceId(\"school\") .tokenStore(tokenStore) .stateless(true) .accessDeniedHandler(new CustomAccessDeniedHandler()); } /** * 对HTTP请求鉴权 */ @Override public void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\"/**\").access(\"#oauth2.hasScope('teacher')\") .and().csrf().disable() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS); }} 若权限存在于 authorities 中，需要替代 OAuth2ResourceServerWebSecurityConfiguration 的配置，示例代码如下： 弃用方法安全 通过自定义 Converter 来指定权限，Converter 是函数接口，当前上下问参数为 JWT 对象 获取 JWT 中的 authorities 12345678910111213141516171819@EnableGlobalMethodSecurity(prePostEnabled = true)@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .anyRequest().authenticated() .and() .oauth2ResourceServer().jwt().jwtAuthenticationConverter(jwt -&gt; { Collection&lt;SimpleGrantedAuthority&gt; authorities = ((Collection&lt;String&gt;) jwt.getClaims() .get(\"authorities\")).stream() .map(SimpleGrantedAuthority::new) .collect(Collectors.toSet()); return new JwtAuthenticationToken(jwt, authorities); }); }} 参考博客 Spring Security + OAuth 2.0 之 Resource Server（基于 JWT） 在 Spring Boot 的 YML 配置中使用 jwt.key-uri 替换 jwk.key-set-uri Spring Security Oauth2 添加自定义过滤器和 Oauth2 认证后 API 权限控制 Spring Cloud Oauth2 - Cannot convert access token to JSON 错误解决方法 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 开发随笔 oauth"},{"title":"Hexo Next 主题使用 Waline 评论系统","url":"/posts/ae18fb85.html","text":"前言本教程的内容虽然会持续更新，但一切内容以 Waline 官方文档 为准。 版本说明 软件 版本 描述 linux CentOS 7.9 docker 20.10.5 mysql 5.7.26 node 14.17.3 hexo 5.4.0 next 8.12.1 waline-admin 0.18.0 waline-client 2.5.1 waline-server 1.18.5 Hexo 评论系统选择Hexo 各类评论系统的对比可看这里，之前博客一直使用的评论系统是基于 Github Issue 的 Utterances。由于 Utterances 默认没有 CDN 加速，经常造成页面加载完成后无法正常显示 Utterances 的评论区，而且需用用户登录 Github 账号才能评论，因此打算更换博客的评论系统。国外的 Disqus、Hypercomments 暂时不考虑，国内访问被墙的概率很大。Gitment、Gitalk、Gitter 和 Utterances 一样，访问速度不太稳定，且登录 Github 才能评论，暂时也不考虑。这一波排除下来，剩下的方案只有 Valine、Isso、Waline 或者 自建评论系统。考虑到 Valine 依赖 Leancloud 第三方服务，且需要在 Leancloud 额外部署 Valine Admin 才能实现邮件通知与评论管理等功能，这样一来感觉也不靠谱，万一 Leancloud 以后退出商业市场竞争呢？综合考虑下来，最终选择了 Waline 评论系统，一款从 Valine 衍生的带后端评论系统，支持多种部署方式和数据存储方式，这样就可以省去 自建评论系统 的开发成本，同时也可以尽量少依赖第三方服务，增加日后扩展和维护的自由度。 Hexo 评论系统介绍Valine 评论系统Valine 是一款基于 Leancloud 的快速、简洁且高效的无后端评论系统，用户无需登录即可评论，目前已有 Hexo、Jekyll、Typecho、Hugo、Ghost 等博客程序在使用。由于 Valine 自身不支持邮件通知支持，因此诞生了 Valine Admin 开源项目；一个对 Valine 评论系统的拓展应用，可增强 Valine 的邮件通知功能；基于 Leancloud 的云引擎与云函数，主要实现评论邮件通知、评论管理、自定义邮件通知模板等功能，而且还可以提供邮件 通知博主 和 @ 通知 的功能。 Waline 评论系统Waline 一款从 Valine 衍生的带后端评论系统，可以将 Waline 等价成 With backend Valine，采用 Client/Server 架构并基于 NodeJS 开发。Valine 支持 MarkDown 语法、邮件通知、评论管理、多种部署方式、多种数据存储方式。 Waline 客户端脚本 服务端部署 数据存储 @waline/client Vercel LeanCloud MiniValine CloudBase CloudBase Docker MongoDB 独立部署 MySQL SQLite PostgreSQL Github Waline 支持的功能： 邮件通知 微信通知 QQ 通知 Telegram 通知 Akismet 反垃圾评论 文章统计 多语言 自定义语言支持 登录支持 评论管理 评论删除 其它数据库服务支持（已支持 LeanCloud, MySQL, MongoDB, SQLite, PostgreSQL) 基于 IP 的评论发布频率限制 基于关键词的评论过滤限制 IP 黑名单 重复内容检测 CloudBase 腾讯云开发部署支持 社交登录 AWS, GCP, Azure 部署支持 置顶评论 评论赞踩 Docker 部署 MySQL Server使用 Docker 部署 MySQL，容器管理工具使用 Docker-Compose。 Doker 部署 MySQL在下述的 Docker-Compose 配置里，指定了 MySQL 容器的静态 IP 地址与系统时区，yourPassword 为数据库密码，/usr/local/docker-volumes/mysql/* 是 MySQL 容器各个数据卷目录的路径 1234567891011121314151617181920212223242526272829version: \"3.5\"services: mysql: image: mysql:5.7.26 container_name: waline-mysql restart: always privileged: false environment: TZ: 'Asia/Shanghai' MYSQL_ROOT_PASSWORD: yourPassword ports: - 3306:3306 networks: waline-network: ipv4_address: 172.23.0.3 volumes: - '/usr/local/docker-volumes/mysql/conf:/etc/mysql/conf.d' - '/usr/local/docker-volumes/mysql/data:/var/lib/mysql' - '/usr/local/docker-volumes/mysql/log:/var/log/mysql' command: --default-authentication-plugin=mysql_native_passwordnetworks: waline-network: name: waline-network driver: bridge ipam: config: - subnet: 172.23.0.0/24 MySQL 数据库表初始化创建并启动 MySQL 的 Docker 容器后，导入最新的 waline.sql 脚本来创建好 Waline Server 所需的数据库表，其中相关表的结构如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152CREATE DATABASE waline DEFAULT CHARACTER SET utf8mb4;CREATE TABLE `wl_Comment` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `user_id` int(11) DEFAULT NULL, `comment` text, `insertedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `ip` varchar(100) DEFAULT '', `link` varchar(255) DEFAULT NULL, `mail` varchar(255) DEFAULT NULL, `nick` varchar(255) DEFAULT NULL, `pid` int(11) DEFAULT NULL, `rid` int(11) DEFAULT NULL, `sticky` boolean DEFAULT NULL, `status` varchar(50) NOT NULL DEFAULT '', `like` int(11) DEFAULT NULL, `ua` text, `url` varchar(255) DEFAULT NULL, `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;CREATE TABLE `wl_Counter` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `time` int(11) DEFAULT NULL, `url` varchar(255) NOT NULL DEFAULT '', `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;CREATE TABLE `wl_Users` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `display_name` varchar(255) NOT NULL DEFAULT '', `email` varchar(255) NOT NULL DEFAULT '', `password` varchar(255) NOT NULL DEFAULT '', `type` varchar(50) NOT NULL DEFAULT '', `label` varchar(255) DEFAULT NULL, `url` varchar(255) DEFAULT NULL, `avatar` varchar(255) DEFAULT NULL, `github` varchar(255) DEFAULT NULL, `twitter` varchar(255) DEFAULT NULL, `facebook` varchar(255) DEFAULT NULL, `google` varchar(255) DEFAULT NULL, `weibo` varchar(255) DEFAULT NULL, `qq` varchar(255) DEFAULT NULL, `2fa` varchar(32) DEFAULT NULL, `createdAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, `updatedAt` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; Docker 部署 Waline Server使用 Docker 部署 Waline Server，数据存储方式选择 MySQL，容器管理工具使用 Docker-Compose。 构建 Waline Server 镜像若不希望自己构建 Waline Server 的 Docker 镜像，可以直接使用 Waline 官方的 Docker 镜像，操作步骤如下： 12345678# 拉取最新的代码# git clone https://github.com/lizheming/waline.git# 进入代码目录# cd waline/packages/server/# 构建镜像# docker build -t lizheming/waline -f Dockerfile . 值得一提的是，官方提供的 Dockerfile 默认会使用最新的 Waline Server 代码来构建 Docker 镜像，若希望使用本地的 Waline Server 代码（经过更改的）来构建 Docker 镜像，需要自行更改 Dockerfile 的内容（如下所示）；为了统一使用东八区时区，建议更改系统默认的时区。 12345678910111213141516171819# https://github.com/nodejs/LTSFROM node:lts AS buildWORKDIR /appENV NODE_ENV productionRUN set -eux; \\ # npm config set registry https://registry.npmmirror.com; \\ npm install --production --silent @waline/vercel# use local source codeRUN rm -rf /app/node_modules/@waline/vercel/src/*COPY ./src/ /app/node_modules/@waline/vercel/srcFROM node:lts-buster-slimWORKDIR /appRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeENV TZ Asia/ShanghaiENV NODE_ENV productionCOPY --from=build /app .EXPOSE 8360CMD [\"node\", \"node_modules/@waline/vercel/vanilla.js\"] 提示 若构建 Waline Server 的 Docker 镜像时，一直卡在 NPM 安装模块的过程里，可以更改对应的 Dockerfile（如下所示），使用淘宝的 NPM 源来加速 NPM 模块下载 123456$ vim waline/packages/server/Dockerfile...（省略）npm config set registry https://registry.npmmirror.com; \\npm install --production --silent @waline/vercel...（省略） Docker 部署 Waline Server在上面 MySQL 的 Docker-Compose 配置基础上，指定 Waline Server 容器的静态 IP 地址 与 Waline Server 启动时所需的环境变量 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758version: \"3.5\"services: mysql: image: mysql:5.7.26 container_name: waline-mysql restart: always privileged: false environment: TZ: 'Asia/Shanghai' MYSQL_ROOT_PASSWORD: yourPassword ports: - 3306:3306 networks: waline-network: ipv4_address: 172.23.0.3 volumes: - '/usr/local/docker-volumes/mysql/conf:/etc/mysql/conf.d' - '/usr/local/docker-volumes/mysql/data:/var/lib/mysql' - '/usr/local/docker-volumes/mysql/log:/var/log/mysql' command: --default-authentication-plugin=mysql_native_password waline: container_name: waline image: lizheming/waline:latest restart: always privileged: false depends_on: - mysql ports: - 8360:8360 networks: waline-network: ipv4_address: 172.23.0.4 environment: TZ: \"Asia/Shanghai\" AKISMET_KEY: \"false\" DISABLE_USERAGENT: \"true\" SITE_NAME: \"Your site name\" SECURE_DOMAINS: \"example.cn\" AUTHOR_EMAIL: \"example@qq.com\" SITE_URL: \"https://www.example.cn\" MYSQL_HOST: 172.23.0.3 MYSQL_PORT: 3306 MYSQL_DB: waline MYSQL_PREFIX: wl_ MYSQL_USER: root MYSQL_PASSWORD: yourPassword volumes: - /usr/local/waline/data:/app/datanetworks: waline-network: name: waline-network driver: bridge ipam: config: - subnet: 172.89.0.0/24 Waline Server 的环境变量Waline Server 的 自身环境变量如下： 环境变量名称 必填 默认值 备注 TZ 时区 SITE_URL 站点 URL SITE_NAME 站点名称 AUTHOR_EMAIL 博主邮箱 SECURE_DOMAINS 安全域名配置，支持逗号分隔配置多个域名，配置后非该域名来源的请求会返回 403 状态码，不配置表示允许所有域名来源 IPQPS 60 基于 IP 的评论发布频率限制，单位为秒。默认为 60 秒，设置为 0 不限制 DISABLE_USERAGENT false 是否隐藏评论者的 UA，默认为否 DISABLE_REGION false 是否隐藏评论者的归属地，默认为否 DISABLE_AUTHOR_NOTIFY false 是否禁止新评论通知，默认为否 COMMENT_AUDIT 评论发布审核开关，默认为否，配置后建议在 Placehoder 上提供文案提示 AKISMET_KEY Akismet 反垃圾评论服务的 Key（默认开启，不用请设置为 false，关闭后可以加快评论提交的速度） AVATAR_PROXY https://avatar.75cdn.workers.dev/ 头像的代理地址，设置 false 可以关闭代理 LOGIN 当设置为 LOGIN: 'force' 时，服务端会要求客户端必须登录才能评论；同时 Waline 客户端需要增加 login： force 的配置用于隐藏博客页面上的评论匿名输入框 GRAVATAR_STR https://seccdn.libravatar.org/avatar/{{mail|md5}} Gravatar 头像的地址，基于 Nunjucks 语法 OAUTH_URL https://user.75.team OAuth 第三方登录服务地址，也可以使用 auth 自建 WEBHOOK 评论成功后会向 WEBHOOK 配置的地址发送一条 POST 请求 COMMENT_AUDIT：阅读源代码发现，环境变量中不配置 COMMENT_AUDIT，则默认关闭评论发布的审核功能，只要在环境变量中添加了该属性，无论属性值是什么，都会开启评论发布的审核功能 Waline Server 的 MySQL 环境变量如下： 环境变量名称 必填 默认值 备注 MYSQL_HOST 127.0.0.1 MySQL 服务的地址 MYSQL_PORT 3306 MySQL 服务的端口 MYSQL_DB ✓ MySQL 数据库库名 MYSQL_USER ✓ MySQL 数据库的用户名 MYSQL_PASSWORD ✓ MySQL 数据库的密码 MYSQL_PREFIX wl_ MySQL 数据表的表前缀 MYSQL_CHARSET utf8mb4 MySQL 数据表的字符集 Waline Server 运行测试分别创建并启动 MySQL 与 Waline Server 容器，然后浏览器访问 http://ip:port/ui/register，打开 Waline Server 的 Web 管理界面进行注册，第一个注册的用户会被 Waline Server 识别为系统管理员（博主），成功登录后的界面如下： 若 Waline Server 的 Web 管理界面无法正常访问，可以使用以下命令查看 Docker 容器的日志来定位问题 1# docker logs -f --tail 20 waline Waline Server 配置反向代理Nginx 反向代理配置若使用 Nginx 作为 Waline Server 的反向代理，可参考以下配置内容。 12345678910111213141516171819202122232425262728293031323334353637server { listen 80; listen 443 ssl; server_name www.example.com if ($server_port !~ 443){ rewrite ^(/.*)$ https://$host$1 permanent; } # SSL 证书 ssl_certificate /usr/local/nginx/cert/waline.example.com.crt; ssl_certificate_key /usr/local/nginx/cert/waline.example.com.key; # SSL 性能调优 ssl_session_timeout 10m; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES256-SHA384:AES256-SHA256:RC4:HIGH:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!AESGCM; add_header Strict-Transport-Security 'max-age=31536000'; location / { # 反向代理 proxy_pass http://$server_name; proxy_set_header Host $host:$server_port; proxy_set_header X-NginX-Proxy true; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr; # 缓存 add_header X-Cache $upstream_cache_status; add_header Cache-Control no-cache; expires 12h; }} Nginx 配置跨域访问默认情况下，当在 Waline 服务端的环境变量里添加了 SITE_URL 属性，那么 Nginx 的反向代理不再需要配置跨域，因为 Waline Server 会自动将 SITE_URL 添加到允许跨域的名单里。若 Waline Server 自带的跨域配置不能满足要求，可以参考以下内容自行配置 Nginx 的跨域。 123456789101112131415161718192021222324252627location /comment { # 清除Waline自带的跨域Header proxy_hide_header Access-Control-Allow-Origin; proxy_hide_header Access-Control-Allow-Methods; proxy_hide_header Access-Control-Allow-Headers; proxy_hide_header Access-Control-Allow-Credentials; # 添加自定义的跨域Header add_header 'Access-Control-Allow-Origin' '*' always; add_header 'Access-Control-Allow-Credentials' 'true' always; add_header 'Access-Control-Allow-Methods' 'GET,HEAD,PUT,POST,DELETE,PATCH,OPTIONS' always; add_header 'Access-Control-Allow-Headers' 'Accept,Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Origin' always; # 反向代理 proxy_pass http://$server_name; proxy_set_header Host $host:$server_port; proxy_set_header X-NginX-Proxy true; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr; # 缓存 add_header X-Cache $upstream_cache_status; add_header Cache-Control no-cache; expires 12h;} Next 主题安装 Waline 官方插件安装 Waline 官方插件Waline 官方插件的版本必须与 Next 主题的版本匹配，否则 Waline 官方插件无法正常使用，两者的兼容性说明如下： Next 主题的版本 Waline 官方插件的版本 &lt;= 8.3.0 &lt;= 1.0.8 &gt;= 8.4.0 &gt;= 2.0.0 12345# 进入博客的根目录$ cd /blog-root# 安装Waline插件（默认是最新版本）$ npm install @waline/hexo-next --save 配置 Waline 官方插件更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容，其中 serverURL 是 Waline Server 的访问 URL，需要自行更改该属性的值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# Waline Config File# For more information:# - https://waline.js.org# - https://waline.js.org/reference/component.htmlwaline: # New! Whether enable this plugin enable: true # Waline server address url, you should set this to your own link serverURL: https://waline.vercel.app # Waline library CDN url, you can set this to your preferred CDN # libUrl: https://unpkg.com/@waline/client@v2/dist/waline.js # Waline CSS styles CDN url, you can set this to your preferred CDN cssUrl: https://unpkg.com/@waline/client@v2/dist/waline.css # Custom locales # locale: # placeholder: Welcome to comment # Comment box placeholder # If false, comment count will only be displayed in post page, not in home page commentCount: true # Pageviews count, Note: You should not enable both `waline.pageview` and `leancloud_visitors`. pageview: false # Custom emoji # emoji: # - https://unpkg.com/@waline/emojis@1.0.1/weibo # - https://unpkg.com/@waline/emojis@1.0.1/alus # - https://unpkg.com/@waline/emojis@1.0.1/bilibili # - https://unpkg.com/@waline/emojis@1.0.1/qq # - https://unpkg.com/@waline/emojis@1.0.1/tieba # - https://unpkg.com/@waline/emojis@1.0.1/tw-emoji # Comment infomation, valid meta are nick, mail and link # meta: # - nick # - mail # - link # Set required meta field, e.g.: [nick] | [nick, mail] # requiredMeta: # - nick # Language, available values: en-US, zh-CN, zh-TW, pt-BR, ru-RU, jp-JP # lang: zh-CN # Word limit, no limit when setting to 0 # wordLimit: 0 # Whether enable login, can choose from 'enable', 'disable' and 'force' # login: enable # comment per page # pageSize: 10 更改 Next 主题的样式由于 Next 主题默认对所有图片都添加了 display: block; CSS 样式，这会导致 Waline 的表情包图片独立一行显示，需要往 Next 主题里添加以下自定义样式来解决，例如更改样式文件 themes/next/source/css/_common/scaffolding/base.styl 123.wl-content .vemoji, .wl-content .wl-emoji { display: inline !important;} Hexo 构建失败的解决方法若 Next 主题安装 Waline 官方插件后，执行 hexo g 命令抛出以下异常，这是由于 Hexo 或者 Next 的版本过低导致，此时需要升级 Hexo 或者 Next 的版本 1234567891011121314151617181920212223ERROR Render HTML failed: index.htmlTypeError: Cannot read property 'parent' of null at Function.exports.update (/usr/local/hexo/node_modules/cheerio/lib/parse.js:55:26) at module.exports (/usr/local/hexo/node_modules/cheerio/lib/parse.js:17:11) at Function.exports.load (/usr/local/hexo/node_modules/cheerio/lib/static.js:22:14) at Hexo.hexoMetaGeneratorInject (/usr/local/hexo/node_modules/hexo/lib/plugins/filter/meta_generator.js:8:21) at Hexo.tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo/node_modules/bluebird/js/release/method.js:15:34) at Promise.each.filter (/usr/local/hexo/node_modules/hexo/lib/extend/filter.js:60:50) at tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromiseCtx (/usr/local/hexo/node_modules/bluebird/js/release/promise.js:641:10) at _drainQueueStep (/usr/local/hexo/node_modules/bluebird/js/release/async.js:97:12) at _drainQueue (/usr/local/hexo/node_modules/bluebird/js/release/async.js:86:9) at Async._drainQueues (/usr/local/hexo/node_modules/bluebird/js/release/async.js:102:5) at Immediate.Async.drainQueues [as _onImmediate] (/usr/local/hexo/node_modules/bluebird/js/release/async.js:15:14) at runCallback (timers.js:705:18) at tryOnImmediate (timers.js:676:5) at processImmediate (timers.js:658:5) Waline 第三方插件列表hexo-waline-next hexo-waline-next，一款更强大且适用于 Next 主题的 Waline 插件，支持上传评论图片到七牛图床 hexo-next-darkmode hexo-next-darkmode，一款适用于 Waline 与 Next 主题的暗黑模式切换插件，详细的使用说明请看这里 Waline 进阶配置客户端使用 CDNWaline 客户端若想使用 CDN 加速，只需在 Next 主题的 _config.yml 配置文件中，更改 Waline 官方插件的配置（如下所示）即可。由于 Waline 采用 Client/Server 架构，客户端与服务端的版本一般需要匹配才能正常运行；因此不建议每次自动都获取最新版的客户端文件，而是推荐日后统一更新客户端与服务端的版本。 123456789# 获取最新版本的Walinewaline: libUrl: https://unpkg.com/@waline/client@v2/dist/waline.js cssUrl: https://unpkg.com/@waline/client@v2/dist/waline.css# 获取指定版本的Walinewaline: libUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.js cssUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.css 验证用户注册邮箱用户注册和评论的邮件通知都会用到邮件服务，配置邮件服务相关变量后，用户注册流程会增加邮箱验证码确认相关的操作，用来防止恶意的注册。 环境变量名称 备注 SMTP_SERVICE SMTP 邮件发送服务提供商 SMTP_HOST SMTP 服务器地址，一般可以在邮箱的设置中找到。 SMTP_PORT SMTP 服务器端口，一般可以在邮箱的设置中找到。 SMTP_USER SMTP 邮件发送服务的用户名，一般为登录邮箱。 SMTP_PASS SMTP 邮件发送服务的密码，一般为邮箱登录密码，部分邮箱 (例如 163) 是单独的 SMTP 密码。 SENDER_NAME 自定义发送邮件的发件人 SENDER_EMAIL 自定义发送邮件的发件地址 提示：可以在这里查看支持的邮箱服务商，SMTP_SERVICE 和 (SMTP_HOST、SMTP_PORT）任选其一进行配置即可。如果在邮箱服务商列表中没有对应的 SMTP_SERVICE ，则需要同时配置 SMTP_HOST 和 SMTP_PORT。 客户端配置用户头像Waline 目前使用 Libravatar 来获取评论列表头像。Libravatar 是自由、开放的头像服务，支持联邦托管并与 Gravatar 完全兼容。首先博主或者用户自行使用邮箱登录或注册 Libravatar，然后更改自己的 Libravatar 头像。当在博客评论的时候，留下在 Libravatar 注册时所使用的邮箱即可，或者使用 Waline 客户端提供的登录功能；最后 Waline 会自动根据邮箱地址去 Libravatar 获取用户的头像，当未能从 Libravatar 查询到头像时，将会自动转为从 Gravatar 查询。目前 Waline 非自定义头像有以下 7 种默认值可选： 在 Waline Server 中，通过配置环境变量 GRAVATAR_STR 来指定 Libravatar 头像服务的地址（基于 Nunjucks 语法），这样就可以自定义客户端所使用的用户头像类型，如下所示： 1GRAVATAR_STR: 'https://seccdn.libravatar.org/avatar/{{mail|md5}}?d=robohash' 若 Libravatar 或者 Gravatar 在国内被墙，此时还可以使用 Cravatar 替代。在 Waline Server 中配置以下环境变量，就可以快速切换到 Cravatar，并自定义客户端所使用的用户头像类型： 12AVATAR_PROXY: 'false'GRAVATAR_STR: 'https://cravatar.cn/avatar/{{mail|md5}}?d=robohash' 特别注意 尽管诸如谷歌、QQ 等邮件提供商对电子邮件不区分大小写，但是你仍需要保证 Libravatar 或者 Gravatar 注册的邮箱和填入的邮箱地址对应。虽然全球大部分大型邮件提供商均不对电子邮件用户名区分大小写，但是根据 RFC 5231 的规定，电子邮件是区分大小写的。这意味着邮件提供商可以将 abc@xxx.com 和 ABC@xxx.com 视为不同的账号，而且也的确有邮件提供商这样处理。所以为防止使用此类邮件提供商的用户无法收到邮件或显示错误的头像，Waline 并不会对邮箱进行大小写转换。 服务端配置评论通知当博客有用户发布评论或者用户回复评论时，Waline 支持对博主和回复评论作者进行通知。博主评论通知支持邮件、微信、QQ 与 Telegram，回复评论作者仅支持邮件通知。由于篇幅有限，这里仅介绍邮箱通知的配置，其他的通知方式可参考官方文档。邮件通知需要在环境变量中配置以下属性： AUTHOR_EMAIL：博主邮箱，用来区分发布的评论是否是博主本身发布的。如果是博主发布的则不进行提醒通知。 SMTP_SERVICE：SMTP 邮件发送服务提供商，可以在 这里 查看所有支持的运营商。如果没在列表中的可以自行配置 SMTP_HOST 和 SMTP_PORT。 SMTP_HOST：SMTP 服务器地址，一般可以在邮箱的设置中找到。如果未配置 SMTP_SERVICE 的话该项必填。 SMTP_PORT：SMTP 服务器端口，一般可以在邮箱的设置中找到。如果未配置 SMTP_SERVICE 的话该项必填。 SMTP_USER：SMTP 邮件发送服务的用户名，一般为登录邮箱。 SMTP_PASS：SMTP 邮件发送服务的密码，一般为邮箱登录密码，部分邮箱（例如 163）是单独的 SMTP 密码。 SMTP_SECURE： SMTP 邮件发送加密，默认为 true，设置为 false 则不会加密请求 SITE_NAME：网站名称，用于在消息中显示。 SITE_URL：网站地址，用于在消息中显示。 SENDER_NAME：自定义发送邮件的发件人，选填。 SENDER_EMAIL：自定义发送邮件的发件地址，选填。 MAIL_SUBJECT：评论回复邮件标题自定义 MAIL_TEMPLATE：评论回复邮件内容自定义 MAIL_SUBJECT_ADMIN：新评论通知邮件标题自定义 MAIL_TEMPLATE_ADMIN：新评论通知邮件内容自定义 提示 用户注册和评论的邮件通知都会用到邮件服务 由于国内腾讯云、阿里云默认禁用了 25 端口，若 Waline 的服务端是部署在云服务器上，则需要使用 465 端口，并启用 SSL 邮件加密，最后系统防火墙别忘了开放 465 端口 Waline Client 的其他特性自定义样式Waline 客户端默认提供了一些 CSS 变量，可以很轻松的通过这些变量自定义 Waline 客户端的 CSS 样式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344:root { /* 字体大小 */ --waline-font-size: 16px; /* 常规颜色 */ --waline-white: #fff; --waline-light-grey: #999; --waline-dark-grey: #666; /* 主题色 */ --waline-theme-color: #27ae60; --waline-active-color: #2ecc71; /* 布局颜色 */ --waline-color: #444; --waline-bgcolor: #fff; --waline-bgcolor-light: #f8f8f8; --waline-bgcolor-hover: #f0f0f0; --waline-border-color: #ddd; --waline-disable-bgcolor: #f8f8f8; --waline-disable-color: #bbb; --waline-code-bgcolor: #282c34; /* 特殊颜色 */ --waline-bq-color: #f0f0f0; /* 头像 */ --waline-avatar-size: 3.25rem; --waline-m-avatar-size: calc(var(--waline-avatar-size) * 9 / 13); /* 徽章 */ --waline-badge-color: #3498db; --waline-badge-font-size: 0.775em; /* 信息 */ --waline-info-bgcolor: #f8f8f8; --waline-info-color: #999; --waline-info-font-size: 0.625em; /* 渲染选择 */ --waline-border: 1px solid var(--waline-border-color); --waline-avatar-radius: 50%; --waline-box-shadow: none;} 如果使用了一个大量运用阴影 (box-shadow) 的主题，可以通过修改 --waline-border 和 --waline-box-shadow 来更改 Waline 客户端的阴影样式，如: 12345678910:root { --waline-border: none; --waline-box-shadow: 0 12px 40px rgb(134 151 168 / 25%);}@media (prefers-color-scheme: dark) { body { --waline-box-shadow: 0 12px 40px #0f0e0d; }} 如果上面的 CSS 变量无法满足你对 Waline 样式的定制要求，你可以停止导入 Waline 官方提供的样式，并自己制作 CSS。 自定义表情包 Waline 客户端自定义表情包 启用暗黑模式Waline 客户端默认支持暗黑模式，只需在 Waline 客户端初始化的时候，指定 dark 参数即可 设置 dark: auto 会根据设备颜色模式自动切换 填入 CSS 选择器，则会在对应选择器生效时启用暗黑模式 针对不同的 Hexo 主题，Waline 客户端的配置示例如下： vuepress-theme-hope：它会在 &lt;body&gt; 上添加 theme-dark class 来开启暗黑模式，那么需要将 dark 选项设置为 body.theme-dark Docusaurus：它会在 &lt;html&gt; 上通过设置 data-theme=\"dark\" 开启暗黑模式，那么需要将 dark 选项设置为 'html[data-theme=\"dark\"]' hexo-theme-fluid：它会在 &lt;html&gt; 上通过设置 data-user-color-scheme=\"dark\" 开启暗黑模式，那么需要将 dark 选项设置为 'html[data-user-color-scheme=\"dark\"]' 若 Hexo 使用的是 Next 主题，且是通过插件 hexo-next-darkmode 来自动添加可切换的暗黑模式，那么可以在 Next 主题的 _config.yml 配置文件里添加以下内容来启用 Waline 客户端的暗黑模式 1234waline: enable: true dark: 'body.darkmode--activated' ... 在暗黑模式下，Waline 客户端默认会使用以下样式，若希望自定义暗黑模式的 CSS 样式，直接覆盖以下 CSS 样式即可。 12345678910111213141516171819202122/* 根据用户设置 ↓ */darkmode-selector { /* 常规颜色 */ --waline-white: #000; --waline-light-grey: #666; --waline-dark-grey: #999; /* 布局颜色 */ --waline-color: #888; --waline-bgcolor: #1e1e1e; --waline-bgcolor-light: #272727; --waline-border-color: #333; --waline-disable-bgcolor: #444; --waline-disable-color: #272727; /* 特殊颜色 */ --waline-bq-color: #272727; /* 其他颜色 */ --waline-info-bgcolor: #272727; --waline-info-color: #666;} 提示 Next 主题使用插件 hexo-next-darkmode 来自动添加可切换的暗黑模式，详细的步骤可以参考这篇博客。 Github 社交登录最新版 Waline 增加了登录评论功能，除了普通的账号登录之外，还支持使用第三方社交账号进行直接登录。目前官方支持 Github 社交账号登录，当然默认没有开启 Github 社交账号登录功能，需要做一些配置才能支持。若要增加 Github 账号登录功能，需要配置 Github OAuth 密钥。点击 《Register a new OAuth application》 进入 Github OAuth 应用申请页面，这里需要填入以下几个配置： Application name：应用名称，可以随意，会在用户授权时显示，推荐使用博客名称。 Homepage URL：应用主页地址，可以随意，会在用户授权时显示，推荐使用博客地址。 Appcation description：应用描述，可以随意，会在用户授权时显示，非必填项。 Authorization callback URL：应用的回调地址，登录时需要使用。填入 &lt;serverURL&gt;/oauth/github 其中 &lt;serverURL&gt; 是你的 Waline 服务端地址。 填完后点击 Register application 按钮就成功创建应用了，可以在页面中看到 Client ID。点击 Client secrets 栏右边的 Generate a new client secret 按钮，可以获取到该应用的 Client secrets。 最后按照如下环境变量配置，将上面获取到的密钥（Client secrets）配置进 Waline 服务端的环境变量中，然后重新部署 Waline 服务端后即可使用 Github 登录。 环境变量名称 备注 GITHUB_ID 对应 Github OAuth Application 中的 Client ID GITHUB_SECRET 对应 Github OAuth Application 中的 Client secrets 由于 Github 的 API 调用在国内不太稳定，建议直接使用普通的账号登录 上传图片至七牛图床Waline 客户端内置了图像上传的支持，默认会将图片转换为 Base64 字符串，然后通过 Waline Server 进行存储，例如将图片存储到 MySQL。在 Hexo 的 Next 主题下，若希望使用七牛图床，则可以安装 Waline 的第三方插件 hexo-waline-next 来实现。 12345# 卸载Waline官方插件$ npm uninstall @waline/hexo-next --save# 安装Waline第三方插件（默认是最新版本）$ npm install hexo-waline-next --save 第三方插件 hexo-waline-next 使用了七牛官方的 Qiniu-JavaScript-SDK ，为了安全考虑，默认没有包含 Upload Token 的生成实现，因此 Upload Token 需要通过网络从服务端（自建）获取，服务端代码可以参考七牛服务端 SDK 的文档，插件的配置示例如下： 123456waline: enable: true qiniuDebug: false # print the error message of the picture uploaded by qiniu qiniuDomain: https://qiniu.example.cn # The custom domain for qiniu, e.g https://qiniu.example.cn qiniuTokenUrl: https://api.example.cn/qiniu/sdk/token/upload # The api to get qiniu token, e.g https://api.example.cn/qiniu/sdk/token/upload ... qiniuDomain：七牛的外链域名 qiniuDebug：前端是否输出七牛上传图片的错误信息 qiniuTokenUrl：获取七牛 Upload Token 的接口地址 若希望禁用图片上传的功能，可以使用以下配置内容，适用于 Waline 客户端默认的图片上传和七牛图床上传： 1234waline: enable: true allowUploadImage: false # Allow upload picture ... allowUploadImage：是否允许上传图片，默认值为：true 第三方插件 hexo-waline-next 对七牛 Upload Token 接口返回数据（JSON）的定义如下： 1234{ \"data\": \"tdvdhnpSs2JFt8U9-c9hL74ddWtEj\", \"msg\": \"success\"} 参数名称 类型 实例值 说明 status code Number 200 HTTP 响应状态码，成功返回 200，非法请求来源返回 403，接口调用太频繁返回 429，系统内部出错返回 500 data String tdvdhnpSs2JFt8U9-c9hL74ddWtEj Upload Token 的值 msg String success 消息提示内容 提高七牛 Upload Token 接口的安全性： 全站启用 HTTPS 协议 通过 HTTP Header 的 referer 、 X-Real-IP 、X-Forwarded-For 等来限制请求来源的域名、IP 获取 Upload Token 的接口应该内置限流功能，避免外部恶意频繁调用接口，例如限制每分钟只能调用两次接口 服务端生成 Upload Token 时，应该指定上传策略，例如设置 Token 的有效时间（expires、deadline），具体可参考七牛官方文档一、七牛官方文档二，Java 版服务端的示例代码如下： 1234567891011String bucket = \"bucket name\";String accessKey = \"access key\";String secretKey = \"secret key\";//指定UploadToken的有效时间为10秒long expireSeconds = 10;StringMap putPolicy = new StringMap();Auth auth = Auth.create(accessKey, secretKey);String upToken = auth.uploadToken(bucket, null, expireSeconds, putPolicy);System.out.println(upToken); Waline 开发指南准备工作 使用 Git 克隆项目 1$ git clone https://github.com/lizheming/waline.git 保证 NPM 的版本是 7 Node 14 及以下默认使用 npm@v6，你需要确保自己使用 npm@v7 版本，否则运行或者编译构建 Waline 组件时会出错 12345# 安装最新版的NPM$ npm i -g npm@latest# 查看NPM的版本$ npm -v 安装依赖 123$ cd waline$ npm i 本地开发本地使用以下命令启动 @waline/client，由于 Waline 采用 Client/Server 架构，在调试 client 时，必须配置本地环境变量 SERVERURL 至 waline/packages/client/.env，其中在 waline/packages/client/.env.example 文件里有可参考的配置示例。 1$ npm run client:dev @waline/client 正常启动时，输出的日志信息如下，此时浏览器直接访问 http://127.0.0.1:9000 就可以开始测试本地的 @waline/client 123456789101112131415161718192021222324252627&gt; client:dev&gt; npm run dev --workspace=@waline/client&gt; @waline/client@1.3.3 dev&gt; webpack serve --mode=development --config ./build/webpack.config.js&lt;i&gt; [webpack-dev-server] Project is running at:&lt;i&gt; [webpack-dev-server] Loopback: http://127.0.0.1:9000&lt;i&gt; [webpack-dev-server] On Your Network (IPv4): http://192.168.1.128:9000/&lt;i&gt; [webpack-dev-server] Content not from webpack is served from '/usr/local/waline/packages/client/public' directoryasset Waline.min.js 1010 KiB [emitted] (name: main) 1 related assetasset index.html 967 bytes [emitted]runtime modules 27.1 KiB 13 modulescacheable modules 832 KiB modules by path ./src/ 95.3 KiB 48 modules modules by path ../../node_modules/ 737 KiB modules by path ../../node_modules/webpack-dev-server/client/ 48.9 KiB 12 modules modules by path ../../node_modules/style-loader/dist/runtime/*.js 5.02 KiB 6 modules modules by path ../../node_modules/webpack/hot/*.js 4.3 KiB 4 modules modules by path ../../node_modules/html-entities/lib/*.js 81.3 KiB 4 modules modules by path ../../node_modules/@vue/ 437 KiB 4 modules modules by path ../../node_modules/url/ 37.4 KiB 3 modules modules by path ../../node_modules/querystring/*.js 4.51 KiB ../../node_modules/querystring/index.js 127 bytes [built] [code generated] ../../node_modules/querystring/decode.js 2.34 KiB [built] [code generated] ../../node_modules/querystring/encode.js 2.04 KiB [built] [code generated]webpack 5.50.0 compiled successfully in 3160 ms 如果希望在 Hexo Next 主题里测试本地的 @waline/client，那么可以在 Next 的 _config.yml 配置文件中指定 Waline 插件的 libUrl 参数，配置示例如下： 1234waline: enable: true libUrl: http://127.0.0.1:9000/Waline.min.js # Set custom waline cdn url .... 本地使用以下命令启动 @waline/server，为了使 @waline/server 能在本地正常运行，需要配置必要的本地环境变量至 waline/example/.env，其中在 waline/example/.env.example 文件里有可参考的配置示例。@waline/server 正常启动后，默认的服务器地址是 http://127.0.0.1:9000。 1$ npm run server:dev 编译构建12345678# 构建@waline/admin$ npm run admin:build# 构建@waline/client$ npm run client:build# 或者同时构建@waline/admin与@waline/client$ npm run build Waline 组件编译构建完成后，默认会在 waline/node_modules/@waline 目录下生成对应的文件，目录结构如下： 12345waline/node_modules/@waline├── admin -&gt; ../../packages/admin├── client -&gt; ../../packages/client├── cloudbase -&gt; ../../packages/cloudbase└── vercel -&gt; ../../packages/server 值得一提的是，以 @waline/client 组件为例，编译构建完成后，实际的输出路径是：waline/packages/client/dist Waline 常见问题防止恶意刷评论 Waline 服务端启用评论审核功能 Waline 服务端启用基于 IP 的评论发布频率限制功能 Waline 服务端启用客户端登录后才允许评论的功能，确保服务端的版本大于等于 0.26.0，同时 Waline 的客户端需要增加 login=force 的配置用于隐藏博客页面上的评论匿名输入框 Waline 的服务端如果启用客户端登录后才允许评论的功能，那么还需要在服务端的环境变量里配置邮件服务相关的参数；这是为了防止恶意注册，当配置了邮件服务相关的环境变量后，用户注册流程会增加邮箱验证码确认相关的操作 Waline 发布评论很慢发布评论的时候因为一些特殊原因，例如垃圾邮件检测、评论通知都是串联操作。其中垃圾邮件检测使用的是 Akismet 提供的服务，这块由于调用国外服务可能会造成访问过慢，可以通过 AKISMET_KEY=false 后端环境变量关闭垃圾评论检测功能来定位问题。除了垃圾评论检测服务之外，评论通知中的邮件通知也有可能造成超时，这块建议可以先关闭评论通知再测一下是否是因为该功能导致的过慢。 Github 登录无法管理后台Github 登录后无法管理后台，解决方法可参考 Github Issue：通过 Github 登录无法管理后台 Waline 版本更新流程 更新 MySQL 数据库表结构 更新 Hexo-Waline-Next 插件 更新 Waline Server 的代码，重新构建 Docker 镜像 若在 Next 主题的 _config.yml 文件中，Waline 官方插件的 CDN 配置里有指定 Waline Client 的版本（如下配置），那么还需要更改 Client 的版本号，否则默认会使用最新版的 Waline Client 1234waline: enable: true libUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.js cssUrl: https://unpkg.com/@waline/client@2.0.7/dist/waline.css 提示 由于 Waline 采用 Client/Server 架构，客户端与服务端的版本一般需要匹配才能正常运行。 waline/packages/server/src/controller/index.js 源文件涉及到 Waline Client 版本的定义（最新版本） waline/packages/server/src/middleware/dashboard.js 源文件涉及到 Waline Admin 版本的定义（最新版本） 项目源码 Waline Github Waline DockerHub 参考博客 Waline 官方中文文档 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"C 语言基础之一","url":"/posts/1228be9f.html","text":"语言发展历程机器语言计算机的大脑或者说心脏就是 CPU，它控制着整个计算机的运作。每种 CPU，都有自己的指令系统。这个指令系统，就是该 CPU 的机器语言。机器语言是一组由 0 和 1 系列组成的指令码，这些指令码，是 CPU 制造厂商规定出来的，然后发布出来，要求程序员遵守。要让计算机干活，就得用机器语言（二级制数）去命令它。这样的命令，不是一条两条，而是上百条。不同型号的计算机其机器语言是不相通的，也就是使用某种计算机的机器指令编制的程序，不能在另一种计算机上执行。 汇编语言机器语言编程很令人烦恼，因此终于出现了汇编语言，就是一些标识符取代 0 与 1。汇编语言是一门人类可以比较轻松认识的编程语言。只是这门语言计算机并不认识，所以人类还不能用这门语言命令计算机做事情。所以，有一类专门的程序，既认识机器语言，又认识汇编语言，也就是编译器，将标识符换成 0 与 1，知道怎么把汇编语言翻译成机器语言。 高级语言汇编语言和机器语言都是面向机器的，机器不同，语言也不同。既然有办法让汇编语言翻译成机器语言，难道就不能把其他更人性化的语言翻译成机器语言？1954 年，Fortran 语言出现了，其后相继出现了其他的类似语言。这批语言，使程序员摆脱了计算机硬件的限制，把主要精力放在了程序设计上，不在关注低层的计算机硬件。这类语言，称为高级语言。同样的，高级语言要被计算机执行，也需要一个翻译程序将其翻译成机器语言，这就是编译程序，简称 “编译器”。这类高级语言解决问题的方法是分析出解决问题所需要的步骤，把程序看作是数据被加工的过程。基于这类方法的程序设计语言，成为了面向过程的语言。 语言的层次 语言的进化史 为什么要学习 C 语言C 语言的特点优点： 代码量小 功能强大 编程自由 执行速度快 缺点： 可移植性较差 对平台库依赖较多 写代码实现周期长 过于自由，经验不足易出错 学习 C 语言理由 C 语言的应用领域C 语言的应用极其广泛，从网站后台，到底层操作系统，从多媒体应用到大型网络游戏，均可使用 C 语言来开发： C 语言可以写网站后台程序 C 语言可以专门针对某个领域写出功能强大的程序库 C 语言可以写出大型游戏的引擎 C 语言可以写出另一个语言来，例如：PHP 纯 C 语言开发的 C 语言可以写操作系统和驱动程序，并且一般只能用 C 语言编写 任何设备只要配置了微处理器，就都支持 C 语言。从微波炉到手机，都是由 C 语言技术来推动的 详见：各类语言的应用领域图解分析 第一个 C 语言程序编写代码123456#include &lt;stdio.h&gt;int main(int argc, char *argv[]) { printf(\"Hello World!\\n\"); return 0;} 编译代码 GCC 编译命令常用选项说明 选项 含义 -o 指定生成的输出文件名 -E 只进行预处理 -S 只进行预处理和编译 -c 只进行预处理、编译和汇编 编译代码，生成可以执行文件 1$ gcc hello.c -o hello 运行代码 运行可执行文件 123$ ./helloHello World! 代码分析 #include 头文件包含： #include 的意思是头文件包含，#include &lt;stdio.h&gt; 表示包含 stdio.h 这个头文件 使用 C 语言库函数时，需要提前包含库函数对应的头文件，如这里使用了 printf() 函数，则需要包含 stdio.h 头文件 #include &lt;&gt; 与 #include \"\" 的区别： &lt;&gt; 表示编译器直接按系统指定的目录（/usr/include）检索头文件 \"\" 表示系统先在 \"\" 指定的路径（没写路径则默认使用当前路径）查找头文件，如果找不到，再按系统指定的目录检索 main() 函数 一个完整的 C 语言程序，是由一个、且只能有一个 main() 函数（又称主函数，必须有）和若干个其他函数结合而成（可选） main() 函数是 C 语言程序的入口，程序是从 main() 函数开始执行的 printf() 函数 printf() 是 C 语言库函数，功能是向标准输出设备输出一个字符串 printf() 函数在 stdio.h 头文件里定义 \\n 表示回车换行 return 语句 return 代表函数执行完毕 如果 main() 函数定义的时候前面是 int，那么 return 后面就需要写一个整数 如果 main() 函数定义的时候前面是 void，那么 return 后面什么也不需要写 在 main() 函数中 return 0 代表程序执行成功，return -1 代表程序执行失败 int main() 和 void main() 在 C 语言中都是支持的，但 C++ 只支持 int main() 这种定义方式 system 函数system 函数的定义1234567头文件：#include &lt;stdlib.h&gt;声明：int system(const char *command);功能：在已经运行的程序中执行另外一个外部程序参数：外部可执行程序名字返回值： 成功：不同系统返回值不一样 失败：通常是 -1 system 函数的调用12345678#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char *argv[]) { system(\"ls\"); // Linux 平台 // system(\"calc\"); // Windows 平台 return 0;} system 函数的返回值在 Linux 和 Windows 系统下分别调用 system() 函数，若调用成功返回值是不一样的，若调动失败返回值一般为 -1。C 语言所有的库函数调用，只能保证语法是一致的，但不能保证执行结果是一致的；同样的库函数在不同的操作系统下执行结果可能是一样的，也可能是不一样的。Linux 的发展离不开 POSIX 标准，只要符合这个标准的函数，在不同的系统下执行的结果就可以一致。Unix 和 Linux 很多库函数都是支持 POSIX 标准的，但 Windows 支持的比较差。如果将 Unix 代码移植到 Linux 一般代价很小，如果把 Windows 代码移植到 Unix 或者 Linux 就比较麻烦。 C 语言的编译过程C 语言的编译步骤C 语言编译成可执行程序需要经过以下 4 个步骤，详见 编译流程图。 预处理：宏定义展开、头文件展开、条件编译等，同时将代码中的注释删除，这里并不会检查语法 编译：检查语法，将预处理后文件编译生成汇编文件 汇编：将汇编文件生成目标文件（二进制文件） 链接：C 语言编写的程序是需要依赖各种库的，所以编译之后还需要把库链接到最终的可执行程序中去 GCC 的编译过程GCC 的编译步骤 步骤 命令 1. 预处理 gcc -E hello.c -o hello.i 2. 编译到汇编代码 gcc -S hello.c -o hello.s 3. 汇编到目标代码（二进制文件） gcc -c hello.s -o hello.o 4. 链接，生成可执行文件 gcc hello.o -o hello 值得一提的是，以上四个步骤，可以合成一个步骤，直接编译链接成可执行目标文件，命令是 gcc hello.c -o hello 文件后缀的不同含义 文件后缀 含义 .c C 语言文件 .i 预处理后的 C 语言文件 .s 编译后的汇编文件 .o 编译后的目标文件 查找程序所依赖的动态库12345678# GCC编译$ gcc hello.c -o hello# 查看所依赖的动态库$ ldd hello linux-vdso.so.1 =&gt; (0x00007f152053a000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f151ff4d000) /lib64/ld-linux-x86-64.so.2 (0x00007f152031b000) 在 Windows 系统里，可以使用 Dependency Walker 工具查看程序所依赖的动态库（DLL），如下图所示： VS 中 C 语言嵌套汇编代码在 Visual Studio 中，由于下述代码使用了 eax 寄存器，因此程序需要运行在 32 位（x86）的平台。 12345678910111213141516171819#include &lt;stdio.h&gt;int main() { int a; int b; int c; __asm { mov a, 3 // 3的值放在a对应内存的位置 mov b, 4 // 4的值放在a对应内存的位置 mov eax, a // 把a内存的值放在eax寄存器 add eax, b // eax和b相加，结果放在eax mov c, eax // eax的值放在c中 } printf(\"c = %d\\n\", c); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c语言"},{"title":"Hexo 与 Next 版本升级教程","url":"/posts/d1f06120.html","text":"前言 Next 官方博客 Next 官方教程 - 版本升级 Next 各版本的仓库 年份 版本 仓库 2014 ~ 2017 v5 https://github.com/iissnan/hexo-theme-next 2018 ~ 2019 v6 ~ v7 https://github.com/theme-next/hexo-theme-next 2020 v8 https://github.com/next-theme/hexo-theme-next Next 与 Hexo 版本适配关系 NodeJS 版本升级NodeJS 版本升级不是必须的，可以根据自己的实际情况选择是否升级，首先在 NodeJS 官网下载最新版的二进制安装包，解压后配置系统环境变量即可。 123456789# 配置环境变量# vim /etc/profileexport PATH=$PATH:/usr/local/node-v14.16.1/binNODE_PATH=/usr/local/node-v14.16.1/lib/node_modulesPATH=$PATH:$NODE_PATHexport NODE_PATH PATH# 使配置生效# source /etc/profile Hexo 版本升级笔者是从 Hexo 3.9.0 升级到 Hexo 5.4.0，步骤如下： 全局升级 Hexo 版本若曾经在系统里，直接使用过 hexo 的命令，才需要执行以下升级操作 123456789101112131415# 清理NPM缓存$ npm cache clean -f# 全局安装版本检测、版本升级工具$ npm install -g npm-check$ npm install -g npm-upgrade# 全局检测哪些模块可以升级，这里可以根据打印的提示信息，手动安装最新版本的模块$ npm-check -g# 全局更新模块$ npm update -g# 全局安装或更新Hexo的最新版本$ npm install --global hexo 博客升级 Hexo 版本1234567891011121314151617181920212223# 进入博客的根目录$ cd /blog-root# 检测Hexo哪些模块可以升级$ npm-check# 删除package-lock.json# rm -rf package-lock.json# 更新package.json$ npm-upgrade# 删除整个模块目录，这样可以避免很多坑$ rm -rf node_modules# 更新Hexo的模块$ npm update --save# 若出现依赖的问题，用以下命令检查一下，然后把报错的统一修复一下即可$ npm audix# 或者强制更新$ npm update --save --force 由于新版的 Hexo 一般增加了不少新特性，因此需要使用新版 Hexo 默认的配置模版文件 _config.yml，同时还需要稍微更改旧版的 package.json 配置文件，否则容易出现各种兼容错误 123456# 进入博客的根目录$ cd /blog-root# 备份旧版的配置文件$ mv _config.yml _config.yml.bak$ mv package.json package.json.bak 12345678$ 单独初始化全新的Hexo博客目录$ hexo init hexo-upgrade$ 拷贝新的配置模版文件到博客的根目录$ cp hexo-upgrade/_config.yml /blog-root/_config.yml$ cp hexo-upgrade/package.json /blog-root/package.json# 最后在新的配置模版文件里，重新追加旧版的Hexo配置内容 升级 Next 主题注意事项笔者 从 Next 7.8.0 升级到 Next 8.3.0，值得一提的是，Next 版本升级必须注意以下事项： Next 与 Hexo 的版本必须兼容 必须使用新版 Next 主题的 _config.yml 配置文件，若继续使用 Next 旧版的 _config.yml 配置文件，容易出现各种兼容错误 版本升级12345678910# 进入博客的主题目录$ cd /boot-root/theme# 备份旧版主题的配置$ mv next next-bak# 拉取最新的代码（注意：Next不同版本使用不同的仓库）$ git clone https://github.com/next-theme/hexo-theme-next next# 最后将旧版的Next配置内容追加到Next新版的配置文件中，包括拷贝旧版自定义的样式、布局文件等 本地下载第三方库（可选）在 Next 8.3.0 的 _config.yml 中，新增了 vendors.internal 属性（如下配置）来指定加载本地的第三方库文件，默认存放路径为 themes/next/source/lib；启用后站点就不再需要依赖第三方的 CDN 资源，而是直接使用本地站点的资源文件，这样可以让站点的访问速度更稳定。 1234567891011# It's recommended to use the same version as in `_vendors.yml` to avoid potential problems.# Remember to use the HTTPS protocol of CDN links when you enable HTTPS on your site.vendors: # The CDN provider of NexT internal scripts. # Available values: local | jsdelivr | unpkg | cdnjs # Warning: If you are using the latest master branch of NexT, please set `internal: local` internal: local # The default CDN provider of third-party plugins. # Available values: local | jsdelivr | unpkg | cdnjs # Dependencies for `plugins: local`: https://github.com/next-theme/plugins plugins: local 安装 NexT 插件特别注意 若希望使用本地的第三方库文件，则需要安装 NexT 的 @next-theme/plugins 插件，其中插件的版本必须与 NexT 主题的版本一致。 12# 安装插件$ npm install @next-theme/plugins --save 批量下载第三方库将 themes/next/_vendors.yml 里定义的第三方库文件统一下载下来，并存放在 themes/next/source/lib 目录下，具体步骤如下 临时更改 themes/next/scripts/events/lib/vendors.js 源文件的代码（如下所示），然后执行 hexo g 命令，从输出日志信息中得到批量下载第三方库文件的 curl 命令 将得到的所有 curl 命令保存到 Shell 脚本文件里，然后执行 Shell 脚本文件批量下载第三方库文件到 themes/next/source/lib 目录下 最后还原 themes/next/scripts/events/lib/vendors.js 源文件的代码 1234567891011// 打印下载命令const { name, version, file, alias, unavailable } = value;if (version) { var _path = `https://cdn.jsdelivr.net/npm/${name}@${version}/${file}`; console.log(\"curl \" + _path + \" --create-dirs -o ${DIR}\" + \"/\" + name + \"/\" + file); continue;}const links = { // 省略 ...}; 批量下载 Next 8.3.0 版本所需的第三方库文件的 Shell 脚本文件如下，DIR 是 themes/next/source/lib 目录的绝对路径，请自行更改 123456789101112131415161718192021222324252627282930313233343536#!/bin/shDIR=/usr/local/hexo-develop/themes/next/source/librm -rf ${DIR}/*curl https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js --create-dirs -o ${DIR}/animejs/lib/anime.min.jscurl https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css --create-dirs -o ${DIR}/@fortawesome/fontawesome-free/css/all.min.csscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/components/prism-core.min.js --create-dirs -o ${DIR}/prismjs/components/prism-core.min.jscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/autoloader/prism-autoloader.min.js --create-dirs -o ${DIR}/prismjs/plugins/autoloader/prism-autoloader.min.jscurl https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/line-numbers/prism-line-numbers.min.js --create-dirs -o ${DIR}/prismjs/plugins/line-numbers/prism-line-numbers.min.jscurl https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js --create-dirs -o ${DIR}/mathjax/es5/tex-mml-chtml.jscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css --create-dirs -o ${DIR}/katex/dist/katex.min.csscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/copy-tex.min.js --create-dirs -o ${DIR}/katex/dist/contrib/copy-tex.min.jscurl https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/copy-tex.min.css --create-dirs -o ${DIR}/katex/dist/contrib/copy-tex.min.csscurl https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.4.0/pjax.min.js --create-dirs -o ${DIR}/@next-theme/pjax/pjax.min.jscurl https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js --create-dirs -o ${DIR}/jquery/dist/jquery.min.jscurl https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js --create-dirs -o ${DIR}/@fancyapps/fancybox/dist/jquery.fancybox.min.jscurl https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css --create-dirs -o ${DIR}/@fancyapps/fancybox/dist/jquery.fancybox.min.csscurl https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js --create-dirs -o ${DIR}/medium-zoom/dist/medium-zoom.min.jscurl https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js --create-dirs -o ${DIR}/lozad/dist/lozad.min.jscurl https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js --create-dirs -o ${DIR}/pangu/dist/browser/pangu.min.jscurl https://cdn.jsdelivr.net/npm/quicklink@2.1.0/dist/quicklink.umd.js --create-dirs -o ${DIR}/quicklink/dist/quicklink.umd.jscurl https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqus.js --create-dirs -o ${DIR}/disqusjs/dist/disqus.jscurl https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqusjs.css --create-dirs -o ${DIR}/disqusjs/dist/disqusjs.csscurl https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js --create-dirs -o ${DIR}/gitalk/dist/gitalk.min.jscurl https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css --create-dirs -o ${DIR}/gitalk/dist/gitalk.csscurl https://cdn.jsdelivr.net/npm/firebase@8.3.1/firebase-app.js --create-dirs -o ${DIR}/firebase/firebase-app.jscurl https://cdn.jsdelivr.net/npm/firebase@8.3.1/firebase-firestore.js --create-dirs -o ${DIR}/firebase/firebase-firestore.jscurl https://cdn.jsdelivr.net/npm/algoliasearch@4.8.6/dist/algoliasearch-lite.umd.js --create-dirs -o ${DIR}/algoliasearch/dist/algoliasearch-lite.umd.jscurl https://cdn.jsdelivr.net/npm/instantsearch.js@4.19.0/dist/instantsearch.production.min.js --create-dirs -o ${DIR}/instantsearch.js/dist/instantsearch.production.min.jscurl https://cdn.jsdelivr.net/npm/pdfobject@2.2.5/pdfobject.min.js --create-dirs -o ${DIR}/pdfobject/pdfobject.min.jscurl https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js --create-dirs -o ${DIR}/mermaid/dist/mermaid.min.jscurl https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css --create-dirs -o ${DIR}/animate.css/animate.min.csscurl https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js --create-dirs -o ${DIR}/nprogress/nprogress.jscurl https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.css --create-dirs -o ${DIR}/nprogress/nprogress.csscurl https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js --create-dirs -o ${DIR}/ribbon.js/dist/ribbon.min.js 常见问题问题一完成上述升级操作后，执行 hexo generator 命令后，themes/next/scripts/events/lib/vendors.js 的代码里面抛出以下错误信息： 1234567891011121314151617181920INFO Start processingFATAL { err: TypeError: Cannot read property 'call' of undefined at module.exports (/usr/local/hexo-develop/themes/next/scripts/events/lib/vendors.js:27:25) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/themes/next/scripts/events/index.js:9:27) at Hexo.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/node_modules/bluebird/js/release/method.js:15:34) at /usr/local/hexo-develop/node_modules/hexo/lib/extend/filter.js:67:52 at tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromiseCtx (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:641:10) at _drainQueueStep (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:97:12) at _drainQueue (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:86:9) at Async._drainQueues (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:102:5) at Immediate.Async.drainQueues [as _onImmediate] (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:15:14) at processImmediate (internal/timers.js:461:21) 这一般是 Hexo 的部分模块没有成功更新引起，例如 hexo-util 模块更新失败，最终导致代码不兼容。首先检查 hexo-util 模块的版本，然后可以尝试执行以下命令，强制更新 hexo-util 模块 12345# 进入博客的主题目录$ cd /boot-root/# 强制更新$ npm update --save --force 问题二完成上述升级操作后，执行 hexo generator 命令后，Hexo 会抛出以下错误信息： 123456789101112131415161718192021222324FATAL { err: TypeError: line.matchAll is not a function at res.value.res.value.split.map.line (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:128:26) at Array.map (&lt;anonymous&gt;) at closeTags (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:126:37) at highlight (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:119:10) at highlightUtil (/usr/local/hexo-develop/node_modules/hexo-util/lib/highlight.js:23:16) at data.content.dataContent.replace (/usr/local/hexo-develop/node_modules/hexo/lib/plugins/filter/before_post_render/backtick_code_block.js:92:17) at String.replace (&lt;anonymous&gt;) at Hexo.backtickCodeBlock (/usr/local/hexo-develop/node_modules/hexo/lib/plugins/filter/before_post_render/backtick_code_block.js:19:30) at Hexo.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Hexo.&lt;anonymous&gt; (/usr/local/hexo-develop/node_modules/bluebird/js/release/method.js:15:34) at Promise.each.filter (/usr/local/hexo-develop/node_modules/hexo/lib/extend/filter.js:67:52) at tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Object.gotValue (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:166:18) at Object.gotAccum (/usr/local/hexo-develop/node_modules/bluebird/js/release/reduce.js:155:25) at Object.tryCatcher (/usr/local/hexo-develop/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromise0 (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:649:10) at Promise._settlePromises (/usr/local/hexo-develop/node_modules/bluebird/js/release/promise.js:729:18) at _drainQueueStep (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:93:12) at _drainQueue (/usr/local/hexo-develop/node_modules/bluebird/js/release/async.js:86:9) NodeJS 从 12.0.0 才开始支持函数 String.matchAll()，如果 NodeJS 的版本低于 12.0.0，那么执行 Hexo 的构建命令就会出现上述的错误，解决方法如下： 方法一：将 NodeJs 升级到高于 12.0.0 的版本 方法二：更改 Hexo 的配置文件 _config.yml，禁用 highlight 的功能，这样就可以避免出错，但这将会关闭代码的高亮显示功能 12highlight: enable: false var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"Docker 基于 Gitolite 搭建 Git 服务器","url":"/posts/4da97727.html","text":"前言官方教程 Docker Install Gitolite Centos7 使用 Gitolite 搭建 Git 服务器 镜像数据卷目录 目录 用途 /home/git/repositories 存储实际的 Git 仓库 /etc/ssh 存储 SSH 主机密钥 Docker 安装 Gitolite这里直接使用国外开发者构建好的 Docker 镜像 elsdoerfer/gitolite，不再通过手写 Dockerfile 来构建 Gitolite，具体使用方法如下： 12# 拉取镜像# docker pull elsdoerfer/gitolite:latest var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化 版本控制"},{"title":"ES6 快速入门教程","url":"/posts/259675f9.html","text":"ECMAScriptECMAScript 简介ECMAScript 是一种由 Ecma 国际（前身为欧洲计算机制造商协会，英文名称是 European Computer Manufacturers Association）通过 ECMA-262 标准化的脚本程序设计语言。ECMAScript 是浏览器脚本语言的规范，而 JavaScript 和 JScript 都是 ECMAScript 规范的实现者。 前端发展历程回顾 Web 1.0 时代 最初的网页以 HTML 为主，是纯静态的网页。网页是只读的，信息流只能从服务到客户端单向流通。开发人员只关心页面的样式和内容即可。 Web 2.0 时代 1995 年，网景工程师 Brendan Eich 花了 10 天时间设计了 JavaScript 语言。 1996 年，微软发布了 JScript，其实是 JavaScript 的逆向工程实现。 1996 年 11 月，JavaScript 的创造者 Netscape 公司，决定将 JavaScript 提交给标准化组织 ECMA，希望这种语言能够成为国际标准。 1997 年，ECMA 发布 262 号标准文件（ECMA-262）的第一版，规定了浏览器脚本语言的标准，并将这种语言称为 ECMAScript，这个版本就是 1.0 版。 JavaScript 和 JScript 都是 ECMAScript 规范的实现者，随后各大浏览器厂商纷纷实现了 ECMAScript 规范。 ES6 快速入门ES6 简介ECMAScript 6.0（简称 ES6）是 JavaScript 语言的下一代标准，在 2015 年 6 月正式发布，并且从 ECMAScript 6 开始，开始采用年号来做版本。因此，ECMAScript 2015，也被称为 ECMAScript 6。它的目标，是使得 JavaScript 语言可以用来编写复杂的大型应用程序，成为企业级开发语言。 ECMAScript 每年发布一个新版本，从版本发布的概念上，不同版本的 ECMAScript 可以类比不同版本的 Java JDK（例如 JDK 8、JDK 11、JDK 15）。 变量声明let 声明变量 let 声明的变量有严格的局部作用域，而 var 声明的变量往往会越域 123456{ var a = 1; let b = 2;}console.log(a); // 1console.log(b); // ReferenceError: b is not defined 同一个变量，let 只可以声明一次，而 var 可以声明多次 123456var a = 1;var a = 2;let b = 3;// let b = 4; // 同一个变量声明多次会出现语法错误console.log(a); // 2console.log(b); // 3 let 不存在变量提升，而 var 存在变量提升 12345console.log(a); // undefinedvar a = 1;console.log(y); // ReferenceError: Cannot access 'y' before initializationlet y = 2; const 声明常量 const 用于声明常量，声明后不允许改变常量的值，一旦声明必须初始化，否则会出现语法错误 12const a = 1;a = 2; // Uncaught TypeError: Assignment to constant variable. 解构表达式数组解构1234567891011let arr = [1, 2, 3];// 第一种写法（普通），通过角标获取数组元素let a1 = arr[0];let a2 = arr[1];let a3 = arr[2];console.log(a1, a2, a3); // 1 2 3// 第二种写法（数组解构），b1, b2, b3 将与 arr 数组中的每个位置对应来取值let [b1, b2, b3] = arr;console.log(b1, b2, b3); // 1 2 3 对象解构1234567891011121314151617const person = { name: \"jack\", age: 23}// 第一种写法（普通），通过对象来获取属性值const name1 = person.name;const age1 = person.age;console.log(name1, age1);// 第二种写法（对象解构），对象里面的每个属性和左边对应赋值const {name, age} = person;console.log(name, age);// 第三种写法（对象解构），对象里面的每个属性和左边对应赋值，并使用变量别名const {name:name2, age:age2} = person;console.log(name2, age2); 字符串扩展新 API 函数 includes()：返回布尔值，表示是否找到了参数字符串 startsWith()：返回布尔值，表示参数字符串是否在原字符串的头部 endsWith()：返回布尔值，表示参数字符串是否在原字符串的尾部 12345let str = \"hello world\"; console.log(str.startsWith(\"hello\")); // trueconsole.log(str.endsWith(\"world\")); // trueconsole.log(str.includes(\"e\")); // trueconsole.log(str.includes(\"hello\")); // true 字符串模版模板字符串相当于加强版的字符串，使用反引号 ` 包裹，除了可以作为普通字符串，还可以用来定义多行字符串，也可以在字符串中加入变量和表达式。 定义多行字符串 123456let str = ` &lt;div&gt; &lt;span&gt;Hello World&lt;/span&gt; &lt;/div&gt; `;console.log(str); 字符串中插入变量，变量名写在 ${} 内 1234let name = \"Jack\";let age = 18;let info = `我是${name}, 年龄是${age}岁`;console.log(info); 字符串中插入表达式，${} 内可以放入 JavaScript 表达式，例如函数调用 1234567function fun() { return \"This is a function.\"}// 在字符串中调用函数let str2 = `Return Message : ${fun()}`;console.log(str2); 函数优化函数参数默认值ES6 支持给函数参数设置默认值，语法为 参数名称 = 默认值 123456789101112131415// 在 ES6 之前，无法给一个函数参数设置默认值，只能采用变通的写法function add(a, b) { // 判断 b 是否为空，为空则赋默认值 1 b = b || 1; return a + b;}// 只传递一个参数console.log(add(10)); // 11// ES6 可以这么写，直接给参数设置默认值，如果没有传递就会自动使用默认值function sub(a, b = 1) { return a - b;}// 只传递一个参数console.log(sub(3)); // 2 不定参数不定参数用来表示不确定参数个数，语法为 ... 变量名，由 ... 加上一个具名参数标识符组成。特别注意，具名参数只能放在参数列表的最后，并且有且只能有一个不定参数。 12345function fun(... params) { console.log(params.length);}fun(\"a\", \"b\"); // 2fun(\"a\", \"b\", \"c\", \"d\"); // 4 箭头函数声明单个参数的函数123456789101112131415161718192021// 在 ES6 之前，声明单个参数函数的写法var print = function (param) { console.log(param);};print(\"Hello World\");// 在 ES6 中，声明单个参数函数的写法（第一种）var echo = (param) =&gt; { console.log(param);}echo(\"Hello World\")// 在 ES6 中，声明单个参数函数的写法（第二种），只有一个参数时，可省略括号 ()var output = param =&gt; { console.log(param);}output(\"Hello World\")// 在 ES6 中，声明单个参数函数的写法（第三种），函数体只有一行语句时，可以省略 {}var display = param =&gt; console.log(param);display(\"Hello World\") 声明多个参数的函数12345678910111213141516171819// 在 ES6 之前，声明多个参数函数的写法var sum = function (a, b) { console.log(a + b);}sum(2, 5);// 在 ES6 中，声明多个参数函数的写法（第一种）var sub = (a, b) =&gt; { console.log(a - b);}sub(5, 2);// 在 ES6 中，声明多个参数函数的写法（第二种），函数体只有一行语句时，可以省略 {}var div = (a, b) =&gt; console.log(a / b);div(8, 4);// 在 ES6 中，声明多个参数函数的写法（第三种），函数体只有一行语句时，并且需要返回结果时，可以省略 {}，会自动返回结果var multi = (a, b) =&gt; a * b;console.log(multi(3, 7)); 箭头函数结合解构表达式12345678910111213141516const person = { name: \"jack\", age: 23}// 在 ES6 之前，声明一个对象，将对象作为函数参数，然后在函数体内访问对象属性的写法function printPerson(person){ console.log(\"hello \" + person.name);}printPerson(person);// 在 ES6 中，声明一个对象，将对象作为函数参数，然后在函数体内访问对象属性的写法var echoPerson = ({ name }) =&gt; { console.log(\"hello \" + name);}echoPerson(person); 对象优化新 API 函数ES6 给 Object 对象拓展了许多新的 API 函数，如： keys(obj)：获取对象的所有 key 形成的数组 values(obj)：获取对象的所有 value 形成的数组 entries(obj)：获取对象的所有 key 和 value 形成的二维数组，格式：[[k1,v1], [k2,v2], ...] assign(dest, ...src)：将多个 src 对象的值拷贝到 dest 中（第一层为深拷贝，第二层为浅拷贝）。 1234567const person = { name: \"jack\", age: 25}console.log(Object.keys(person)); // ['name', 'age']console.log(Object.values(person)); // ['jack', 25]console.log(Object.entries(person)); // [Array(2), Array(2)] 1234567const dest = {a : 1};const source1 = {b: 2};const source2 = {c: 3};// Object.assign() 拷贝函数的第一个参数是目标对象，后面的参数都是源对象Object.assign(dest, source1, source2);console.log(dest); // {a:1, b:2, c:3} 声明对象简写12345678910const age = 23;const name = \"Jack\";// 在 ES6 之前，声明对象的写法const person1 = {age: age, name: name};console.log(person1); // {age: 23, name: \"Jack\"}// 在 ES6 中，声明对象时支持简写const person2 = {age, name};console.log(person2); // {age: 23, name: \"Jack\"} 对象的函数属性简写12345678910111213141516171819202122let person = { name: \"Jack\", // 在 ES6 之前，对象的函数属性的写法 eat: function (food) { console.log(this.name + \" eat \" + food); }, // 在 ES6 中，对象的函数属性的第一种写法（箭头函数版本），这里拿不到 this 对象 play1: (toy) =&gt; { console.log(person.name + \" play \" + toy); }, // 在 ES6 中，对象的函数属性的第二种写法（简写版本），这里可以拿到 this 对象 play2 (toy) { console.log(this.name + \" play \" + toy); }}person.eat('apple'); // Jack eat appleperson.play1(\"computer\"); // Jack play computerperson.play2(\"computer\"); // Jack play computer 对象拓展运算符对象拓展运算符 ... 用于取出参数对象所有可遍历的属性，然后拷贝给当前对象。 12345678910// 拷贝对象（深拷贝）let person1 = { name: \"Jack\", age: 23 };let someone = { ...person1 };console.log(someone); // {name: \"Jack\", age: 23}// 合并对象，如果两个对象的属性有重复，后面对象的属性值会覆盖前面对象的属性值let person2 = { age: 15 };let person3 = { name: \"Jack\" };let person4 = { ...person2, ...person3 };console.log(person4); // {age: 15, name:\"Jack\"} map 和 reduce 函数ES6 在数组中新增了 map 和 reduce 函数。 map 函数 语法：arr.map(callback) 描述：map 函数的参数是一个回调函数，将原数组中的所有元素用这个回调函数处理后放入新数组并返回。 12345678let arr = [\"1\", \"23\", \"5\", \"16\"];console.log(arr); // [\"1\", \"23\", \"5\", \"16\"]arr = arr.map(item =&gt; parseInt(item));console.log(arr); // [1, 23, 5, 16]arr = arr.map(item =&gt; item * 2);console.log(arr); // [2, 46, 10, 32] reduce 函数 语法：arr.reduce(callback, [initialValue]) 描述：reduce 函数会为数组中的每一个元素依次执行回调函数，不包括数组中被删除或从未被赋值的元素 callback：处理数组中每个元素的回调函数，包含四个参数 previousValue：上一次调用回调函数返回的值，或者是提供的初始值（initialValue） currentValue：数组中当前被处理的元素 index：当前元素在数组中的索引 array：调用 reduce 函数的数组 initialValue：作为第一次调用 callback 回调函数的初始值（或者上一次回调函数的返回值） 123456789const arr = [1, 20, -5, 3];// 没有初始值console.log(arr.reduce((a, b) =&gt; a + b)); // 19 = 1 + 20 + (-5) + 3console.log(arr.reduce((a, b) =&gt; a * b)); // -300 = 1 * 20 * (-5) * 3// 拥有初始值console.log(arr.reduce((a, b) =&gt; a + b, 1)); // 20 = 1 + 1 + 20 + (-5) + 3console.log(arr.reduce((a, b) =&gt; a * b, 0)); // -0 = 0 * 1 * 20 * (-5) * 3 Promise在 JavaScript 的世界中，所有代码都是单线程执行的。由于这个 “缺陷”，导致 JavaScript 的所有网络操作，浏览器事件，都必须是异步执行。异步执行可以用回调函数实现。一旦有一连串的 Ajax 请求 a，b，c，d … 后面的请求依赖前面的请求结果，就需要层层嵌套。这种缩进和层层嵌套的方式，非常容易造成上下文代码混乱，开发者不得不非常小心翼翼处理内层函数与外层函数的数据，一旦内层函数使用了上层函数的变量，这种混乱程度就会加剧。总之，这种层叠上下文的层层嵌套方式，着实增加了开发的难度。 传统 Ajax 回调使用案例这里将演示传统 Ajax 回调的使用案例，目的是让读者对层层嵌套的代码有一个直观的了解。 需求说明用户登录后，展示该用户的各科成绩。在页面发送三次请求: 1、查询用户，查询成功说明可以登录 2、根据用户的查询结果，查询科目信息 3、根据科目的查询结果，获取科目成绩 后端接口此时后台应该提供三个接口，一个提供用户的查询接口，一个提供科目的查询接口，一个提供各科成绩的查询接口。为了渲染方便，建议最好是响应 JSON 数据。在这里就不编写后台接口了，而是提供三个 JSON 文件，通过直接提供 JSON 数据的方式来模拟后台的接口。 user.json 12345{ \"id\": 1, \"name\": \"zhangsan\", \"password\": \"123456\"} user_corse_1.json 1234{ \"id\": 10, \"name\": \"chinese\"} corse_score_10.json 1234{ \"id\": 100, \"score\": 90} 调用接口在传统的 Jquery Ajax 回调方式中，回调函数层层嵌套，也被称为 回调地狱。 123456789101112131415161718192021222324252627$.ajax({ url: \"mock/user.json\", success(data) { console.log(\"查询到用户:\", data); $.ajax({ url: `mock/user_corse_${data.id}.json`, success(data) { console.log(\"查询到课程:\", data); $.ajax({ url: `mock/corse_score_${data.id}.json`, success(data) { console.log(\"查询到分数:\", data); }, error(error) { console.log(\"出现异常了:\" + error); } }); }, error(error) { console.log(\"出现异常了:\" + error); } }); }, error(error) { console.log(\"出现异常了:\" + error); }}); Promise 语法 基础版的语法 12345678910const promise = new Promise(function (resolve, reject) { // 执行异步操作 let result = true; // 判断异步操作执行的结果 if (result) { resolve(value); // 调用 resolve 函数，代表 Promise 将返回成功的结果 } else { reject(error); // 调用 reject 函数，代表 Promise 将会返回失败结果 }}); 箭头函数版的语法 12345678910const promise = new Promise((resolve, reject) =&gt; { // 执行异步操作 let result = true; // 判断异步操作执行的结果 if (result) { resolve(value); // 调用 resolve 函数，代表 Promise 将返回成功的结果 } else { reject(error); // 调用 reject 函数，代表 Promise 将会返回失败结果 }}); Prmise 处理执行结果如果想要等待异步执行完成后做一些事情，可以通过 Promise 的 then 函数来实现。如果想要处理 Promise 异步执行失败的事件，还可以使用 catch 函数。 12345promise.then(function (value) { // 异步执行成功后的回调}).catch(function (error) { // 异步执行失败后的回调}) Promise 使用案例上述的 Jquery Ajax 回调代码，使用 Promise 改造后如下： 12345678910111213141516171819202122232425262728293031323334new Promise((resolve, reject) =&gt; { $.ajax({ url: \"mock/user.json\", success(data) { console.log(\"查询到用户:\", data); resolve(data.id); }, error(error) { console.log(\"出现异常了:\" + error); } });}).then((userId) =&gt; { return new Promise((resolve, reject) =&gt; { $.ajax({ url: `mock/user_corse_${userId}.json`, success(data) { console.log(\"查询到课程:\", data); resolve(data.id); }, error(error) { console.log(\"出现异常了:\" + error); } }); });}).then((corseId) =&gt; { $.ajax({ url: `mock/corse_score_${corseId}.json`, success(data) { console.log(\"查询到分数:\", data); }, error(error) { console.log(\"出现异常了:\" + error); } });}); Promise 优化处理通常在企业开发中，会把 Promise 封装成通用方法，下述的代码封装了一个通用的 get 请求方法： 1234567891011121314151617181920212223242526272829// 企业开发中，往往会将 get 方法单独放到 common.js 中let get = function (url, data) { return new Promise((resolve, reject) =&gt; { $.ajax({ url: url, type: \"GET\", data: data, success(result) { resolve(result); }, error(error) { reject(error); } }); })}// 使用封装的 get 方法，实现分数查询get(\"mock/user.json\").then((result) =&gt; { console.log(\"查询到用户:\", result); return get(`mock/user_corse_${result.id}.json`);}).then((result) =&gt; { console.log(\"查询到课程:\", result); return get(`mock/corse_score_${result.id}.json`)}).then((result) =&gt; { console.log(\"查询到分数:\", result);}).catch(() =&gt; { console.log(\"出现异常了:\" + error);}); 模块化模块化介绍模块化就是把代码进行拆分，方便重复利用。类似 Java 中的导包操作：要使用一个包，必须先导包。而 JavaScript 中没有包的概念，换来的是模块。模块功能主要由两个指令构成： export 和 import。 export：用于规定模块的对外接口 import：用于导入其他模块提供的功能 export 指令比如定义一个 JavaScript 文件 hello.js，里面有一个对象，可以使用 export 指令将这个对象导出： 1234567const util = { sum (a, b) { return a + b; }}export {util}; 当然，也可以简写为： 12345export const util = { sum (a, b) { return a + b; }} export 指定不仅可以导出对象，一切 JavaScript 变量都可以导出，包括基本类型变量、函数、数组、对象。当要导出多个值时，还可以简写，比如定义 user.js 文件： 123var name = \"jack\"var age = 21export {name, age} 在上面的导出代码中，都明确指定了导出的变量名，这样其它人在导入使用时就必须准确写出变量名，否则就会出错。因此 JavaScript 提供了 default 关键字，可以对导出的变量名进行省略 12345export default { sum (a, b) { return a + b; }} import 指令使用 export 命令定义了模块的对外接口以后，其他 JavaScript 文件就可以通过 import 指令加载这个模块。 1234import util from 'hello.js'// 调用util对象中的属性util.sum(1, 2); 批量导入前面在 user.js 中导出的 name 和 age 变量 123import {name, age} from 'user.js'console.log(name + \" , 今年\" + age + \"岁了\"); 浏览器支持说明上面的代码暂时无法直接在浏览器运行，因为浏览器目前还不支持 ES6 的导入和导出功能。除非借助于第三方工具，将 ES6 的语法进行编译降级到 ES5，比如 Babel 工具。值得一提的是，Babel 是一个工具链，主要用于将 ES6+ 版本的代码转换为向后兼容的 JavaScript 语法，以便能够运行在当前和旧版本的浏览器或其他环境中。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端"},{"title":"Nacos 2.0 发布，性能提升 10 倍","url":"/posts/57722de1.html","text":"前言继 Nacos 1.0 发布以来，Nacos 迅速被成千上万家企业采用，并构建起强大的生态。但是随着用户深入使用，逐渐暴露一些性能问题，因此启动了 Nacos 2.0 的隔代产品设计，时隔半年终于将其全部实现，实测性能提升 10 倍，相信能满足所有用户的性能需求。 Nacos 简介Nacos 是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。它孵化于阿里巴巴，成长于十年双十一的洪峰考验，沉淀了简单易用、稳定可靠、性能卓越的核心竞争力。 Nacos 2.0 架构2021 年 03 月 30 日，Nacos 2.0 正式对外发布。全新的 2.0 架构不仅将性能大幅提升 10 倍，而且内核进行了分层抽象，并且实现插件扩展机制。Nacos 2.0 架构层次如下图，它相比 Nacos 1.X 的最主要变化是： 通信层统一到 gRPC 协议，同时完善了客户端和服务端的流量控制和负载均衡能力，提升的整体吞吐。 将存储和一致性模型做了充分抽象分层，架构更简单清晰，代码更加健壮，性能更加强悍。 设计了可拓展的接口，提升了集成能力，如让用户扩展实现各自的安全机制。 Nacos 2.0 服务发现升级一致性模型Nacos 2.0&nbsp;架构下的服务发现，客户端通过 gRPC，发起注册服务或订阅服务的请求。服务端使用 Client 对象来记录该客户端使用 gRPC 连接发布了哪些服务，又订阅了哪些服务，并将该 Client 进行服务间同步。由于实际的使用习惯是服务到客户端的映射，即服务下有哪些客户端实例；因此 2.0 的服务端会通过构建索引和元数据，快速生成类似 1.X 中的 Service 信息，并将 Service 的数据通过 &nbsp;gRPC Stream 进行推送。 Nacos 2.0 配置管理升级通信机制配置管理之前用 Http1.1 的 Keep Alive 模式 30s 发一个心跳模拟长链接，协议难以理解，内存消耗大，推送性能弱，因此 2.0 通过 gRPC 彻底解决这些问题，内存消耗大量降低。 Nacos 2.0 架构优势 Nacos 2.0 大幅降低了资源消耗，提升吞吐性能，优化客户端和服务端交互，对用户更加友好；虽然可观测性略微下降，但是整体性价比非常高。 Nacos 2.0 项目演进自从 Nacos1.X 版本突破 10000 Star 后，随着用户深入和大规模使用开始逐渐暴露 Nacos1.X 的性能问题，借此 Nacos 开启了 2.0 的发展阶段，全面升级了通信协议、服务一致性模型、插件化支持、支持服务网格生态和多语言生态。 长连接支持Nacos1.x 版本主要基于 HTTP 短连接构建服务注册与发现、配置管理系统。随着用户的服务量级的增大，HTTP 短连接架构暴露了一些问题。为了克服短连接的固有的技术瓶颈，Nacos 社区针对 HTTP 短连接架构进行了一次基于长连接的重构升级。 在 Nacos 1.X 架构中，配置中心的推送功能通过长轮询构建，周期性地由客户端主动发送 HTTP 请求并在发生更新时返回变更内容；而服务注册中心的推送则通过 UDP 推送 + HTTP 定期对账来实现。然而，配置中心的长轮训、服务注册中心的定期对账，都需要周期性地对于服务端进行一次主动建立连接和配置传送，增大服务端的内存开销；随着 Nacos 用户的服务数和配置数规模的增大，服务端的内存泄漏风险也大大增加。为了更好的支撑用户的性能要求，克服 HTTP 短连接架构固有的性能瓶颈，Nacos 社区在阿里巴巴集团内部充分验证的基础上，进行了一次基于长连接的重构升级。长连接时代的 Nacos2.x 在原本 1.x 的架构基础上新增了对 gRPC 长连接模型的支持，同时保留对旧客户端和 OpenAPI 的兼容。 通信层目前通过 gRPC 实现了长连接 RPC 调用和推送能力。升级完成之后，服务变化、配置变更等信息会通过 gRPC 的双向流主动推送给客户端，而客户端只需要针对各个长连接主动发送轻量级的心跳即可。升级后的技术架构极大地减少了服务端处理数据的开销；同时，由于长连接基于可复用 TCP 的机制，也大大降低了网络堵塞的风险。 MCP 及 XDS 协议支持通过对于 MCP 协议及 XDS 协议的支持，目前服务网格生态领域已完全兼容 Nacos，为 Istio 接入 Nacos 注册中心提供零侵入、高性能的微服务以及网关解决方案，帮助用户在使用非 K8S 服务发现的情况下，仍然可以无缝享用服务网格的无侵入式的服务治理策略。 插件化支持在插件化支持方面，Nacos 社区通过为鉴权、配置加解密、多数据源等模块进行了插件化改造，支持用户进行灵活的插件实现和改造。用户可以根据自己的业务需要，通过实现相应的 SPI 接口和 Jar 包的引入，方便地进行自定义的鉴权、加解密、多数据源等附加功能的实现。插件化升级之后，Nacos 充分实现了多种附加功能与核心功能的解耦合，可扩展性大大加强。 多语言支持随着 Nacos 2.0 对于长连接的支持，多语言客户端也迈出了一大步。当前 Golang、Java、Python、C# 等主流语言已完全拥抱 Nacos 2.0，支持通过 gRPC 协议进行高性能服务注册与发现、配置管理；另外，C++、Node.js、PHP 的 2.0 客户端仍在快速迭代开发、生产验证过程中，同时希望更多社区朋友参与进来，共同构建更加完善的 Nacos 多语言生态。 Nacos 2.0 性能提升由于 Nacos 由服务发现和配置管理两大模块构成，业务模型略有差异，因此下面分别介绍一下具体压测指标。 Nacos 2.0 服务发现的性能提升服务发现场景主要关注客户端数，服务数实例数，及服务订阅者数在大规模场景下，服务端在同步，推送及稳定状态时的性能表现。同时还关注在有大量服务在进行上下线时，系统的性能表现。 容量及稳定状态测试 该场景主要关注随着服务规模和客户端实例规模上涨，系统性能表现。 可以看到 2.0.0 版本在 10W 级客户端规模下，能够稳定的支撑，在达到稳定状态后，CPU 的损耗非常低。虽然在最初的大量注册阶段，由于存在瞬时的大量注册和推送，因此有一定的推送超时，但是会在重试后推送成功，不会影响数据一致性。反观 1.X 版本，在 10W、5W 级客户端下，服务端完全处于 Full GC 状态，推送完全失败，集群不可用；在 2W 客户端规模下，虽然服务端运行状态正常，但由于心跳处理不及时，大量服务在摘除和注册阶段反复进行，因此达不到稳定状态，CPU 一直很高。1.2W 客户端规模下，可以稳定运行，但稳态时 CPU 消耗是更大规模下 2.0 的 3 倍以上。 频繁变更测试 该场景主要关注业务大规模发布，服务频繁推送条件下，不同版本的吞吐和失败率。 频繁变更时，2.0 和 1.X 在达到稳定状态后，均能稳定支撑，其中 2.0 由于不再有瞬时的推送风暴，因此推送失败率归 0，而 1.X 的 UDP 推送的不稳定性导致了有极小部分推送出现了超时，需要重试推送。 Nacos 2.0 配置管理的性能提升由于配置是少写多读场景，所以瓶颈主要在单台监听的客户端数量以及配置的推送获取上，因此配置管理的压测性能主要集中于单台服务端的连接容量以及大量推送的比较。 Nacos 2.0 连接容量测试 该场景主要关注不同客户端规模下的系统压力。 Nacos 2.0 最高单机能够支撑 4.2w 个配置客户端连接，在连接建立的阶段，有大量订阅请求需要处理，因此 CPU 消耗较高，但达到稳态后，CPU 的消耗会变得很低，几乎没有消耗。反观 Nacos 1.X，在客户端 6000 时，稳定状态的 CPU 一直很高，且 GC 频繁，主要原因是长轮训是通过 hold 请求来保持连接，每 30s 需要回一次 Response 并且重新发起连接和请求。需要做大量的上下文切换，同时还需要持有所有 Request 和 Response。当规模达到 1.2w 客户端时，已经无法达到稳态，所以无法支撑这个量级的客户端数。 Nacos 2.0 频繁推送测试 该场景关注不同推送规模下的系统表现。 在频繁变更的场景，两个版本都处于 6000 个客户端连接中。明显可以发现 2.0 版本的性能损耗要远低于 1.X 版本。在 3000tps 的推送场景下，优化程度约优化了 3 倍。 Nacos 2.0 性能结论 针对服务发现场景，Nacos 2.0 能够在 10W 级规模下，稳定运行；相比 Nacos 1.X 版本的 1.2W 规模，提升约 10 倍。 针对配置管理场景，Nacos 2.0 单机最高能够支撑 4.2W 个客户端连接；相比 Nacos 1.X，提升了 7 倍，且推送时的性能明显好于 1.X。 Nacos 生态及 2.X 后续规划随着 Nacos 三年的发展，几乎支持了所有的 RPC 框架和微服务生态，并且引领云原生微服务生态发展。 Nacos 是整个微服务生态中非常核心的组件，它可以无缝和 K8s 服务发现体系互通，通过 MCP/XDS 协议与 Istio 通信，将 Nacos 服务下发 Sidecar；同样也可以和 CoreDNS 联合，将 Nacos 服务通过域名模式暴露给下游调用。Nacos 目前已经和各类微服务 RPC 框架融合进行服务发现；另外可以协助高可用框架 Sentinel 进行各类管理规则的控制和下发。 如果只使用 RPC 框架，有时候并不足够简单，因为部分 RPC 框架比如 gRPC 和 Thrift，还需要自行启动 Server 并告知 Client 该调用哪个 IP。这时候就需要和应用框架进行融合，比如 SCA、Dapr 等；当然也可以通过 Envoy Sidecar 来进行流量控制，应用层的 RPC 就不需要知道服务 的 IP 列表了。最后，Nacos 还可以和各类微服务网关打通，实现接入层的分发和微服务调用。 Nacos 生态在阿里的实践目前 Nacos 已经完成了自研、开源、商业化三位一体的建设，阿里内部的钉钉、考拉、饿了么、优酷等业务域已经全部采用云产品 MSE 中的 Nacos 服务，并且与阿里和云原生的技术栈无缝整合。下面以钉钉为例简单做一下介绍。 Nacos 运行在微服务引擎 MSE（全托管的 Nacos 集群）上，进行维护和多集群管理；业务的各类 Dubbo3 或 HSF 服务在启动时，通过 Dubbo3 自身注册到 Nacos 集群中；然后 Nacos 通过 MCP 协议将服务信息同步到 Istio 和 Ingress-Envoy 网关。 用户流量从北向进入集团的 VPC 网络中，先通过一个统一接入 Ingress-Tengine 网关，他可以将域名解析并路由到不同的机房、单元等。本周也同步更新了 Tengine 2.3.3 版本，内核升级到 Nginx Core 1.18.0 ，支持 Dubbo 协议 ，支持 DTLSv1 和 DTLSv1.2，支持 Prometheus 格式，从而提升阿里云微服务生态完整性、安全性、可观测性。 通过统一接入层网关后，用户请求会通过 Ingress-Envoy 微服务网关，转发到对应的微服务中，并进行调用。如果需要调用到其他网络域的服务，会通过 Ingress-Envoy 微服务网关将流量导入到对应的 VPC 网络中，从而打通不同安全域、网络域和业务域的服务。 微服务之间的相互调用，会通过 Envoy Sidecar 或传统的微服务自订阅的方式进行。最终，用户请求在各个微服务的互相调用中，完成后并返回给用户。 Nacos 2.X 的规划Nacos 2.X 将在 2.0 解决性能问题的基础上，通过插件化实现新的功能并改造大量旧功能，使得 Nacos 能够更方便，更易于拓展。 总结Nacos 2.0 作为一个跨代版本，彻底解决了 Nacos 1.X 的性能问题，将性能提升了 10 倍。并且通过抽象和分层让架构更加简单，通过插件化更好的扩展，让 Nacos 能够支持更多场景，融合更广生态。相信 Nacos2.X 在后续版本迭代后，会更加易用，解决更多微服务问题，并向着 Mesh 化进行更深入地探索。 Nacos：https://nacos.io/zh-cn Nacos Github：https://github.com/alibaba/nacos var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Hexo Next 主题详细配置之二","url":"/posts/fef9e726.html","text":"前言官方教程 Next 官方教程 - 常见问题 Next 官方教程 - 内置标签 Next 官方教程 - 第三方服务集成 版本说明本文使用各软件的版本如下： 软件 版本 hexo 3.9.0 hexo-cli 2.0.0 next 7.8 Next 第三方服务集成 百度统计集成 登录 百度统计，定位到站点的代码获取页面 复制 hm.js? 后面那串统计脚本 id，如下图所示 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1baidu_analytics: 'tug63d4s3hlw9lz2hdtfwhtl0rxay' Next 主题自带的百度统计脚本，默认会将博客本地访问记录也统计进去，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/analytics/baidu-analytics.swig 文件，替换为以下内容 1234567891011121314{%- if theme.baidu_analytics %} &lt;script{{ pjax }}&gt; var _hmt = _hmt || []; (function() { var host = window.location.host; if (host.indexOf(\"127.0.0.1\") == -1 &amp;&amp; host.indexOf(\"localhost\") == -1) { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?{{ theme.baidu_analytics }}\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); } })(); &lt;/script&gt;{%- endif %} 谷歌统计集成更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123google_analytics: tracking_id: 'UA-949648306-1' only_pageview: false Next 主题自带的谷歌统计脚本，默认会将博客本地访问记录也统计进去，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/analytics/google-analytics.swig 文件，替换为以下内容 123456789101112131415161718192021222324252627282930313233{%- if theme.google_analytics.tracking_id %} {%- if not theme.google_analytics.only_pageview %} &lt;script async src=\"https://www.googletagmanager.com/gtag/js?id={{ theme.google_analytics.tracking_id }}\"&gt;&lt;/script&gt; &lt;script{{ pjax }}&gt; var host = window.location.host; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} if (host.indexOf(\"127.0.0.1\") == -1 &amp;&amp; host.indexOf(\"localhost\") == -1) { gtag('js', new Date()); gtag('config', '{{ theme.google_analytics.tracking_id }}'); } &lt;/script&gt; {%- endif %} {%- if theme.google_analytics.only_pageview %} &lt;script&gt; function sendPageView() { if (CONFIG.hostname !== location.hostname) return; var uid = localStorage.getItem('uid') || (Math.random() + '.' + Math.random()); localStorage.setItem('uid', uid); navigator.sendBeacon('https://www.google-analytics.com/collect', new URLSearchParams({ v : 1, tid: '{{ theme.google_analytics.tracking_id }}', cid: uid, t : 'pageview', dp : encodeURIComponent(location.pathname) })); } document.addEventListener('pjax:complete', sendPageView); sendPageView(); &lt;/script&gt; {%- endif %}{%- endif %} 百度自动推送集成更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1baidu_push: true Next 主题自带的百度自动推送脚本，默认在本地访问博客时也会自动推送，例如通过 127.0.0.1 或者 localhost 访问博客 更改 themes/next/layout/_third-party/baidu-push.swig 文件，替换为以下内容 123456789101112131415161718{%- if theme.baidu_push %} &lt;script{{ pjax }}&gt; (function() { var host = window.location.host; if (host.indexOf(\"127.0.0.1\") == -1 &amp;&amp; host.indexOf(\"localhost\") == -1) { var bp = document.createElement('script'); var curProtocol = window.location.protocol.split(':')[0]; if (curProtocol === 'https') { bp.src = 'https://zz.bdstatic.com/linksubmit/push.js'; } else { bp.src = 'http://push.zhanzhang.baidu.com/push.js'; } var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(bp, s); } })(); &lt;/script&gt;{%- endif %} Utterances 评论插件集成Utterances 的原理和 Gitment、Gitalk 类似，依赖 Github Issue，但是索取的权限更少。首先在 Github 创建新的仓库，同时为 Utterances 在 Github 上授权，让 Utterances 有权限访问新仓库的 Issue。当然也可以单独指定 Utterances 能够访问的仓库，可见其权限控制做的非常好，具体操作这里不再累述。下面给出的是 Next 安装 Utterances 评论插件的方法与相关配置内容。 12345# 进入博客的根目录$ cd ${blog-root}/# 安装插件$ npm install github:theme-next/hexo-next-utteranc --save 更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容 1234567utteranc: enable: true repo: xxxx/xxxx # Github repo such as :TrumanDu/comments pathname: pathname theme: github-light # theme: github-light, github-dark, github-dark-orange cdn: https://utteranc.es/client.js priority: # If you want to modify priority, please config in **hexo** 配置完成后，每篇文章的底部都会自动新增评论区，效果图如下： Next 使用本地字体由于 Next 默认是调用 Google Fonts API 来设置字体，正如 Next 官方所说的那样，Google Fonts API 并不稳定。对于这种情况，部分解决方案是 Google Fonts API 指向国内的镜像。但这种方式并不稳定，更好的方式是，将字体下载到站点中，再在站点里使用绝对路径的方式引用字体，相关教程如下： Next 官方设置字体教程 Next 主题字体下载与使用本地字体 当字体下载到本地站点后，更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，由于使用了本地字体，不再使用 Google Fonts 的在线字体，因此统一设置 external: false 123456789101112131415161718192021222324252627282930313233font: enable: true # 外链字体库地址，例如 https://fonts.googleapis.com (默认值) host: https://fonts.googleapis.com # 全局字体，应用在 body 元素上 global: external: false family: Lato size: 16px # 站点标题字体 title: external: false family: size: # 页头标题字体 (h1, h2, h3, h4, h5, h6) headings: external: false family: Roboto Slab size: # 文章字体 posts: external: false family: # 代码字体，应用于 code 以及代码块 codes: external: false family: Roboto Mono var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"Centos7 升级 GCC 版本","url":"/posts/4a5f9755.html","text":"前言 本文主要介绍如何在 Centos 7 系统环境下升级 GCC 的版本，适用于部分源码包依赖高版本的 GCC 进行编译的场景。 安装 SCL SCL 可以在不覆盖原有软件包的情况下与其共存，缺点就是仅支持 64 位 SCL 仅支持安装 devtoolset-4（GCC 5.2）（不含）之后的 GCC 版本 1# yum install -y centos-release-scl 安装 GCC 使用以下命令安装 GCC，其中的 9 表示大版本号，默认安装大版本下的最新稳定版本 1# yum install -y devtoolset-9 scl-utils-build 启用 GCC 临时启用：使用以下命令临时启用 GCC，这种方式适用于临时切换系统的 GCC 版本，即开即用，仅在当前 bash 中有效 1# scl enable devtoolset-9 bash 永久启用：使用以下命令永久启用 GCC，这种方式适用于长期使用该版本进行编译，切换 bash 依然有效 1# echo \"source /opt/rh/devtoolset-9/enable\" &gt;&gt; /etc/profile &amp;&amp; souce /etc/profile 查看 GCC 版本 1# gcc --version var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"centos"},{"title":"Hexo Next 主题详细配置之一","url":"/posts/755ff30d.html","text":"前言 Next 官方教程 - 开始使用 Next 官方教程 - 主题配置 Next 官方教程 - 常见问题 Next 安装版本说明本文使用各软件的版本如下： 软件 版本 hexo 3.9.0 hexo-cli 2.0.0 next 7.8 Next 各版本的介绍值得一提的是，Next 不同版本使用的是不同的仓库，各版本的仓库如下： 年份 版本 仓库 2014 ~ 2017 v5 https://github.com/iissnan/hexo-theme-next 2018 ~ 2019 v6 ~ v7 https://github.com/theme-next/hexo-theme-next 2020 v8 https://github.com/next-theme/hexo-theme-next Next 主题与 Hexo 的版本兼容如下： Next 主题安装 7.x 版本克隆整个 Next 仓库，这里使用 Next 7.x 版本 12# 克隆代码（Next不同版本使用不同仓库）$ git clone https://github.com/theme-next/hexo-theme-next themes/next 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1theme: next 日后可以随时使用 Git 更新当前 Next 的版本，并切换到任何带标签的版本，或者切换到最新的 master 或任何其他分支。在大多数情况下，这对用户和开发人员都有用。 123456789101112131415161718# 进入主题目录$ cd themes/next# 查看带标签的版本$ git tag -lv6.0.0v6.0.1v6.0.2…# 切换到特定标签的版本$ git checkout tags/v6.0.1# 重新切换为master分支$ git checkout master# 更新代码$ git pull Next 常规配置PDF 显示Next 默认支持 PDF 自定义标签，使用格式为： {% pdf https://www.example.com/spring.pdf %}。若希望启用 PDF 的支持，需要更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，详见官方文档 1234pdf: enable: true # Default height height: 550px 首页像显示头更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234avatar: url: /images/avatar.png # 头像图片 rounded: true # 头像显示在圆里 rotated: true # 鼠标焦点落在头像时，是否转动头像 菜单显示中文在博客的根目录里，找到 _config.yml 文件，然后设置以下的配置项，值得一提的是，这里的字体是 zh-CN，而不是 zh-Hans 1language: zh-CN 启用文章目录更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456toc: enable: true number: false # 自动添加目录编号 wrap: true # 每行目录字数超长自动换行 expand_all: true # 展开所有级别 max_depth: 5 # 目录的最大深度 启用文章打赏更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容，需要将收款二维码图片放到 themes/next/source/images 文件夹下，或者使用自定义的图片目录路径 12345678reward_settings: enable: true animation: false comment: 坚持原创技术分享，您的支持将鼓励我继续创作！reward: wechatpay: /images/wechatpay.png alipay: /images/alipay.png 添加版权声明更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345creative_commons: license: by-nc-sa # License类型： by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero sidebar: false # 在侧边栏有一个版权的图片链接 post: true # 在每一篇文章末尾自动增加本文作者、本文链接、版权声明信息 language: deed.zh # 点击链接后显示的版权信息的语言 如果需要自定义文章底部版权信息的，可以自行修改 themes/next/layout/_partials/post/post-copyright.swig 模版文件来实现 添加标签页面通过 Hexo 创建一个标签页面 12345# 进入博客的根目录$ cd ${blog-root}/# 创建标签页$ hexo new page tags 创建完标签页后，发现 source 文件夹下会多了 tags/index.md 文件，这个文件是用于显示站点内所有分类标签的，复制以下内容到 tags/index.md 中，必须使用 --- 包裹配置内容，否则配置无效 123456---title: 标签type: \"tags\"comments: falsedate: 2021-04-05 17:13:00--- 若博客有集成评论服务，标签页面也会带有评论，需要关闭的话，请添加字段 comments 并将值设置为 false 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12menu: tags: /tags/ || fa fa-tags 添加网站备案号更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123beian: enable: true icp: '粤ICP备19024664号' 启用不蒜子统计更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345678busuanzi_count: enable: true total_visitors: true total_visitors_icon: fa fa-user total_views: true total_views_icon: fa fa-eye post_views: true post_views_icon: fa fa-eye 首页不显示文章描述摘录Next 主题默认会在首页里将文章描述摘录为前言文本，但在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。 NexT 提供三种方式来控制文章在首页的显示方式，也就是说，在首页显示文章的摘录并显示 阅读全文 按钮，可以更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1excerpt_description: false 建议使用 &lt;!-- more --&gt;，除了可以精确控制需要显示的摘录内容以外，这种方式也可以让 Hexo 中的插件更好的识别 Next 进阶配置启用 PjaxPjax 主要用于加速 Web 页面的切换速度，同时也可以用来解决 Aplayer 音频播发器切换页面后播放出现中断的问题 12345# 进入Next主题的目录$ cd themes/next# 下载资源文件$ git clone https://github.com/theme-next/theme-next-pjax source/lib/pjax 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1pjax: true 启用背景 3D 动画Next 主题默认支持 3D 背景动画，官方配置教程可以看这里，前提是需要下载指定的静态资源文件或者使用 CDN 静态资源文件 12345# 进入Next主题的目录$ cd themes/next# 下载3D资源文件$ git clone https://github.com/theme-next/theme-next-three source/lib/three 或者更改 Next 主题的配置文件 themes/next/_config.yml，通过以下配置内容来指定 CDN 静态资源文件的 URL 12345vendors: three: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js three_waves: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/three-waves.min.js canvas_lines: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/canvas_lines.min.js canvas_sphere: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/canvas_sphere.min.js 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345three: enable: true three_waves: true # 背景3D动画样式一 canvas_lines: false # 背景3D动画样式二 canvas_sphere: false # 背景3D动画样式三 启用图片点击居中预览更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1mediumzoom: true 启用 Canvas Ribbon 背景Next 主题默认支持 Canvas Ribbon 背景，官方配置教程可以看这里，前提是需要下载指定的静态资源文件或者使用 CDN 静态资源文件 12345# 进入Next主题的目录$ cd themes/next# # 下载Canvas资源文件$ git clone https://github.com/theme-next/theme-next-canvas-ribbon source/lib/canvas-ribbon 或者更改 Next 主题的配置文件 themes/next/_config.yml，通过以下配置内容来指定 CDN 静态资源文件的 URL 12vendors: canvas_ribbon: //cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-ribbon@1/canvas-ribbon.js 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345canvas_ribbon: enable: true size: 300 # Ribbon的宽度 alpha: 0.6 # Ribbon的透明度 zIndex: -1 # Ribbon的显示级别 添加页面顶部加载进度条12345# 进入Next主题的目录$ cd themes/next# 克隆代码$ git clone https://github.com/theme-next/theme-next-pace source/lib/pace 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123pace: enable: true theme: minimal 添加页面顶部阅读进度条12345# 进入Next主题的目录$ cd themes/next# 克隆代码$ git clone https://github.com/theme-next/theme-next-reading-progress source/lib/reading_progress 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12345reading_progress: enable: true position: top # 进度条的位置：top | bottom color: \"#37c6c0\" # 进度条的颜色 height: 3px # 进度条的大小 显示侧栏阅读进度百分比更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234back2top: enable: true sidebar: false scrollpercent: true Next 页面样式更改超链接样式打开 CSS 文件 themes/next/source/css/_common/components/post/post.styl，在末尾添加以下 CSS 样式，颜色可自定义，在这里超链接选中状态为橙色，链接样式为蓝色 12345678910.post-body p a{ color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover { color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; }} 代码块高亮样式更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456codeblock: highlight_theme: 'night eighties' # 代码高亮可选样式: normal | night | night eighties | night blue | night bright | solarized | solarized dark | galactic copy_button: enable: true # 启用代码复制按钮 show_result: false # 显示代码复制结果 style: flat # 代码块可选样式: default | flat | mac 文章底部标签样式打开模板文件 themes/next/layout/_macro/post.swig，将以下内容替换掉 123{%- for tag in post.tags.toArray() %} &lt;a href=\"{{ url_for(tag.path) }}\" rel=\"tag\"&gt;{{ tag_indicate }} {{ tag.name }}&lt;/a&gt;{%- endfor %} 替换的内容如下 123{%- for tag in post.tags.toArray() %} &lt;a href=\"{{ url_for(tag.path) }}\" rel=\"tag\"&gt; &lt;i class=\"fa fa-tag\"&gt;&lt;/i&gt; {{ tag.name }}&lt;/a&gt;{%- endfor %} 页面底部添加站点运行时间在 themes/next/layout/_partials/ 目录下创建 runtime.swig 源文件，并添加如下内容 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;div id=\"site-runtime\"&gt; &lt;span class=\"post-meta-item-icon\"&gt; &lt;i class=\"fa fa-clock-o\"&gt;&lt;/i&gt; &lt;/span&gt; &lt;span id=\"runtime\"&gt;&lt;/span&gt;&lt;/div&gt;&lt;script language=\"javascript\"&gt; function isPC() { var userAgentInfo = navigator.userAgent; var agents = [\"Android\", \"iPhone\", \"SymbianOS\", \"Windows Phone\", \"iPad\", \"iPod\"]; for (var i = 0; i &lt; agents.length; i++) { if (userAgentInfo.indexOf(agents[i]) &gt; 0) { return false; } } return true; } function siteTime(openOnPC, start) { window.setTimeout(\"siteTime(openOnPC, start)\", 1000); var seconds = 1000; var minutes = seconds * 60; var hours = minutes * 60; var days = hours * 24; var years = days * 365; {%- if theme.runtime.start %} start = new Date(\"{{ theme.runtime.start }}\"); {%- endif %} var now = new Date(); var year = now.getFullYear(); var month = now.getMonth() + 1; var date = now.getDate(); var hour = now.getHours(); var minute = now.getMinutes(); var second = now.getSeconds(); var diff = now - start; var diffYears = Math.floor(diff / years); var diffDays = Math.floor((diff / days) - diffYears * 365); var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours); var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes); var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds); if (openOnPC) { document.getElementById(\"runtime\").innerHTML = \"Running: \" + diffYears + \" years \" + diffDays + \" days \" + diffHours + \" hours \" + diffMinutes + \" mins \" + diffSeconds + \" secs\"; } else { document.getElementById(\"runtime\").innerHTML = \"Running: \" + diffYears + \"y \" + diffDays + \"d \" + diffHours + \"h \" + diffMinutes + \"m \" + diffSeconds + \"s\"; } } var showOnMobile = {{ theme.runtime.mobile }}; var openOnPC = isPC(); var start = new Date(); siteTime(openOnPC, start); if (!openOnPC &amp;&amp; !showOnMobile) { document.getElementById('site-runtime').style.display = 'none'; }&lt;/script&gt; 编辑源文件 themes/next/layout/_partials/footer.swig，在文件末尾添加如下内容 123{%- if theme.runtime.enable %} {% include 'runtime.swig' %}{%- endif %} 更改 Next 主题的配置文件 themes/next/_config.yml，添加以下内容 12345678910# Site Runtimeruntime: enable: true # The time of the site started running. If not defined, current time of local time zone will be used. # You can specify the time zone by adding the `+HOURS` or `-HOURS` format time zone. # If not specify the time zone, it will use `+0000` as default. # ex: \"2015-06-08 07:24:13 +0800\", `+0800` specify that it is the time in the East Eight Time Zone. start: 2019-11-23 09:00:00 +0800 # Whether to show on the mobile side mobile: false Next 安装常用插件标签云插件 Hexo-Tag-Cloud 12345# 进入博客的根目录$ cd ${blog-root}/# 安装标签云插件$ npm install hexo-tag-cloud --save 更改 Next 主题的源文件 themes/next/layout/_macro/sidebar.swig, 然后在最后添加如下内容 123456789101112{% if site.tags.length &gt; 1 %}&lt;script type=\"text/javascript\" charset=\"utf-8\" src=\"{{ url_for('/js/tagcloud.js') }}\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\" charset=\"utf-8\" src=\"{{ url_for('/js/tagcanvas.js') }}\"&gt;&lt;/script&gt;&lt;div class=\"widget-wrap\"&gt; &lt;h3 class=\"widget-title\"&gt;Tag Cloud&lt;/h3&gt; &lt;div id=\"myCanvasContainer\" class=\"widget tagcloud\"&gt; &lt;canvas width=\"250\" height=\"250\" id=\"resCanvas\" style=\"width:100%\"&gt; {{ list_tags() }} &lt;/canvas&gt; &lt;/div&gt;&lt;/div&gt;{% endif %} hexo-tag-cloud 插件支持自定义标签云的字体、颜色和高亮显示，在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 1234567tag_cloud: textFont: Trebuchet MS, Helvetica # 字体 textColor: '#333' # 字体颜色 textHeight: 25 # 字体大小 outlineColor: '#E2E1D1' maxSpeed: 0.5 # 旋转速度 pauseOnSelected: false # 当选中对应标签时，是否停止转动 完成安装和配置后，可以通过以下命令来进行本地预览，其中 hexo clean 为必须选项 1$ hexo clean &amp;&amp; hexo g &amp;&amp; hexo s 本地搜索插件Next 主题默认支持使用 Hexo-Generator-Searchdb 插件来实现本地搜索，前提是需要手动安装对应的插件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装搜索插件$ npm install hexo-generator-searchdb --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123456search: path: search.xml field: post content: true format: html limit: 1000 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 123456local_search: enable: true trigger: auto top_n_per_article: 1 unescape: false preload: false RSS 订阅插件hexo-generator-feed 插件用于在 public 目录下自动生成 atom.xml 文件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装RSS订阅插件$ npm install hexo-generator-feed --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 1234567feed: limit: 20 type: atom path: atom.xml order_by: -date content_limit: 140 autodiscovery: true 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 12social: RSS: /atom.xml || fa fa-rss 站点地图插件hexo-generator-sitemap 站点地图插件会在 public 目录下自动生成 sitemap.xml 文件 12345# 进入博客的根目录$ cd ${blog-root}/# 安装插件$ npm install hexo-generator-sitemap --save 在博客的根目录里，创建站点地图的模板文件 sitemap_template.xml，将以下内容复制到文件中 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"&gt; {% for post in posts %} &lt;url&gt; &lt;loc&gt;{{ post.permalink | uriencode }}&lt;/loc&gt; {% if post.updated %} &lt;lastmod&gt;{{ post.updated.toISOString() }}&lt;/lastmod&gt; {% elif post.date %} &lt;lastmod&gt;{{ post.date.toISOString() }}&lt;/lastmod&gt; {% endif %} &lt;/url&gt; {% endfor %}&lt;/urlset&gt; 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123sitemap: path: sitemap.xml template: ./sitemap_template.xml 字数与阅读时长统计插件Next 主题默认支持使用 hexo-symbols-count-time 插件来统计文章字数和阅读时长，前提是需要手动安装对应的插件 12345678# 进入博客的根目录$ cd ${blog-root}/# 安装依赖$ npm install eslint --save# 安装插件$ npm install hexo-symbols-count-time --save 在博客的根目录里，找到 _config.yml 文件，然后添加如下的配置项 123456symbols_count_time: time: true # 文章阅读时长 symbols: true # 文章字数统计 total_time: true # 站点总阅读时长 total_symbols: true # 站点总字数统计 exclude_codeblock: true # 排除代码字数统计 更改 Next 主题的配置文件 themes/next/_config.yml，设置以下内容 1234symbols_count_time: separated_meta: false # 是否另起一行显示（即不和发表时间等同一行显示） item_text_post: true # 首页文章统计数量前是否显示文字描述（本文字数、阅读时长） item_text_total: false # 页面底部统计数量前是否显示文字描述（站点总字数、站点阅读时长） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"静态博客"},{"title":"Kubernetes 之二基于二进制方式搭建集群","url":"/posts/ccd6f2d4.html","text":"前言软件环境 软件 版本 安装方式 CentOS 7.9 3.10.0-1160.15.2.el7.x86_64 虚拟机 Docker docker-19.03.9 二进制安装包 Kubernetes 1.19 二进制安装包 Etcd 3.4.9 二进制安装包 集群搭建要求搭建 Kubernetes 集群需要满足以下几个条件： 一台或多台机器，建议操作系统 CentOS 7_x86_64 Master 节点的硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 20GB 或更多 Node 节点的硬件配置：4GB 或更多 RAM，4 个 CPU 或更多 CPU，硬盘 40GB 或更多 系统内可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点 集群中所有机器之间的网络可以互通 禁用 swap 分区 集群服务器规划 Host Name 角色 IP CPU Memory Disk 组件 k8s-master master 192.168.1.109 &gt;= 2C &gt;=2G &gt;=20G kube-apiserver，kube-controller-manager，kube-scheduler，etcd k8s-node1 node 192.168.1.200 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd k8s-node2 node 192.168.1.111 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd k8s-node3 node 192.168.1.112 &gt;= 4C &gt;=4G &gt;=40G kubelet，kube-proxy，docker，etcd Kubernetes 单 Master 集群搭建系统初始化值得一提的是，以下系统初始化操作必须在所有节点上执行一次，包括 Master 节点与 Node 节点。 关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i 's/enforcing/disabled/' /etc/selinux/config 关闭 swap 12345# 临时关闭$ swapoff -a# 永久关闭# sed -i 's/.*swap.*/#&amp;/' /etc/fstab 系统时间同步 12345# 安装时间同步工具# yum install ntpdate -y# 设置时间同步服务器# ntpdate time.windows.com 将桥接的 IPv4 流量传递到 iptables 的链 1234567# 添加路由规则# vim /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1# 配置生效# sysctl --system 设置主机名 1# hostnamectl set-hostname &lt;hostname&gt; 添加 hosts（Master 和各 Node 节点都需要配置） 123456# 添加hosts# vim /etc/hosts192.168.1.109 k8s-master192.168.1.200 k8s-node1192.168.1.111 k8s-node2192.168.1.112 k8s-node3 搭建 Etcd 集群Etcd 是一个分布式键值存储系统，Kubernetes 使用 Etcd 进行数据存储，所以先准备一个 Etcd 系统。为解决 Etcd 单点故障，建议采用集群方式部署，这里使用 3 台机器组建 Etcd 集群，可容忍 1 台机器故障。当然，也可以使用 5 台组建集群，可容忍 2 台机器故障。为了节省机器，这里与 Kubernetes 节点机器复用，也可以独立于 Kubernetes 集群之外部署，只要 api-server 能连接上就行。 CFSSL 生成证书CFSSL 是 CloudFlare 开源的一款 PKI/TLS 工具，包含一个命令行工具和一个用于签名、验证并且捆绑 TLS 证书的 HTTP API 服务，详细使用教程在这里。 安装 CFSSL 12345678910# 二进制方式安装# curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o /usr/local/bin/cfssl# curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o /usr/local/bin/cfssljson# curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o /usr/local/bin/cfssl-certinfo# 文件授权# chmod +x /usr/local/bin/cfssl*# 配置环境变量# export PATH=/usr/local/bin:$PATH 创建 CA 证书的配置文件 1234567891011121314151617181920# cat &lt;&lt; EOF | tee ca-config.json{ \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"www\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } }}EOF 创建 CA 证书签名的配置文件 123456789101112131415161718192021# cat &lt;&lt; EOF | tee ca-csr.json{ \"CN\": \"etcd ca\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"BeiJing\", \"L\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ], \"ca\": { \"expiry\": \"87600h\" }}EOF 创建 Etcd 证书的配置文件，hosts 字段中的 IP 为所有 Etcd 节点的集群内部通信 IP，为了方便后期扩容，可以多写几个预留的 IP。由于这里的 Etcd 集群节点和 Kubernetes 的集群节点共同安装在不同虚拟机内，所以 IP 列表就是 Kubernetes 集群各节点的 IP 集合。 123456789101112131415161718192021222324# cat &lt;&lt; EOF | tee server-csr.json{ \"CN\": \"etcd\", \"hosts\": [ \"192.168.1.109\", \"192.168.1.200\", \"192.168.1.111\", \"192.168.1.112\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"BeiJing\", \"L\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ]}EOF 使用自签 CA 签发 Etcd 证书 12345678910111213# 查看目录文件# lsca-config.json ca-csr.json server-csr.json# 生成CA证书# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -# 生成Etcd证书，\"-profile\" 参数的值必须与 `ca-config.json` 配置文件中的值一致# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server.csr server-csr.json server-key.pem server.pem 部署 Etcd 集群以下操作都是在 Kubernetes 的 Master 节点上执行，完成后会将 Master 节点上生成的所有 Etcd 文件全部拷贝到其他 Node 节点。千万不要在每个 Node 节点都单独执行生成 Etcd 证书的操作，否则 Etcd 集群里的节点可能会因证书不一致而导致集群启动失败。 Master 节点安装 Etcd 服务 1234567891011# 下载安装文件# wget https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz# 创建安装目录# mkdir -p /opt/etcd/{bin,cfg,ssl}# 解压安装文件# tar zxvf etcd-v3.4.9-linux-amd64.tar.gz# 拷贝安装文件# mv etcd-v3.4.9-linux-amd64/{etcd,etcdctl} /opt/etcd/bin/ Master 节点拷贝上面生成的 Etcd 证书 12# 拷贝证书# cp ca.pem ca-key.pem server.pem server-key.pem /opt/etcd/ssl Master 节点创建 Etcd 的配置文件，这里必须根据实际情况更改 Etcd 各节点的 IP、端口、名称 123456789101112131415# 创建Etcd的配置文件# cat &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOF#[Member]ETCD_NAME=\"etcd-1\"ETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\"ETCD_LISTEN_PEER_URLS=\"https://192.168.1.109:2380\"ETCD_LISTEN_CLIENT_URLS=\"https://192.168.1.109:2379\"#[Cluster]ETCD_INITIAL_ADVERTISE_PEER_URLS=\"https://192.168.1.109:2380\"ETCD_ADVERTISE_CLIENT_URLS=\"https://192.168.1.109:2379\"ETCD_INITIAL_CLUSTER=\"etcd-1=https://192.168.1.109:2380,etcd-2=https://192.168.1.200:2380,etcd-3=https://192.168.1.111:2380,etcd-4=https://192.168.1.112:2380\"ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster\"ETCD_INITIAL_CLUSTER_STATE=\"new\"EOF 123456789ETCD_NAME：节点名称，集群中唯一ETCDDATADIR：数据目录路径ETCD_LISTEN_PEER_URLS：集群通信监听地址ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址ETCD_INITIAL_CLUSTER：集群节点地址ETCD_INITIAL_CLUSTER_TOKEN：集群 TokenETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new 是新集群，existing 表示加入已有集群 Master 节点使用 Systemd 管理 Etcd 服务 1234567891011121314151617181920212223242526272829303132# 创建Etcd服务管理的配置文件# cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \\--cert-file=/opt/etcd/ssl/server.pem \\--key-file=/opt/etcd/ssl/server-key.pem \\--peer-cert-file=/opt/etcd/ssl/server.pem \\--peer-key-file=/opt/etcd/ssl/server-key.pem \\--trusted-ca-file=/opt/etcd/ssl/ca.pem \\--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\--logger=zapRestart=alwaysRestartSec=10sLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF# 更新配置# systemctl daemon-reload# 开机自启动# systemctl enable etcd 拷贝 Kubernetes 的 Master 节点里的所有 Etcd 文件到其他 Node 节点，并在各个 Node 节点里分别配置 Etcd 和设置 Etcd 服务开机自启动 12345678910111213141516# 拷贝Etcd的文件到各个Node节点# scp -r /opt/etcd/ root@k8s-node1:/opt/# scp -r /opt/etcd/ root@k8s-node2:/opt/# scp -r /opt/etcd/ root@k8s-node3:/opt/# 拷贝Etcd服务管理的配置文件到各个Node节点# scp /usr/lib/systemd/system/etcd.service root@k8s-node1:/usr/lib/systemd/system/# scp /usr/lib/systemd/system/etcd.service root@k8s-node2:/usr/lib/systemd/system/# scp /usr/lib/systemd/system/etcd.service root@k8s-node3:/usr/lib/systemd/system/# 在各个Node节点里分别编辑Etcd的配置文件，包括更改当前节点的名称和IP# vim /opt/etcd/cfg/etcd.conf# 在各个Node节点里分别设置Etcd服务开机自启动# systemctl daemon-reload# systemctl enable etcd 启动 Etcd 集群在 Etcd 的多个节点里分别执行以下命令来启动 Etcd 集群，值得一提的是，必须在多个 Etcd 节点里同时执行 systemctl start etcd 命令来启动集群，否则单个 Etcd 节点是无法正常启动的 123456789# 启动Etcd# systemctl start etcd# 查看运行状态# systemctl satus etcd# 查看启动日志# journalctl -u etcd# tail -f 200 /var/log/message 若 Etcd 集群启动失败，可以在各个 Etcd 节点里分别执行以下操作来解决 12345678# 关闭Etcd# systemctl stop etcd# 删除数据目录# rm -rf /var/lib/etcd/default.etcd# 重启Etcd# systemctl start etcd 参考博客 Etcd 集群故障处理 K8S 二进制部署高可用集群（Calico 网络方案） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化"},{"title":"Kubernetes 创建 TLS 证书","url":"/posts/58887565.html","text":"前言概述Kubernetes 系统的各组件需要使用 TLS 证书对通信进行加密，本文使用 CloudFlare 的 PKI 工具集 cfssl 来生成 Certificate Authority (CA) 和其它证书，使用证书的组件如下： 组件 证书 etcd ca.pem、kubernetes-key.pem、kubernetes.pem kube-apiserver ca.pem、kubernetes-key.pem、kubernetes.pem kubelet ca.pem kube-proxy ca.pem、kube-proxy-key.pem、kube-proxy.pem kubectl ca.pem、admin-key.pem、admin.pem kube-controller-manager ca-key.pem、ca.pem 用于创建证书的 Json 文件在部署 Kubernetes 集群时创建证书会使用到的 Json 文件，里面包含有 Kubernetes 各组件创建证书时使用到的 Json 文件，目录结构如下，点击下载。 12345678910111213141516├── ca│&nbsp;&nbsp; └── ca-config.json├── etcd│&nbsp;&nbsp; └── server-csr.json├── kube-apiserver│&nbsp;&nbsp; └── server-csr.json├── kube-controller-manager│&nbsp;&nbsp; └── kube-controller-manager-csr.json├── kubectl│&nbsp;&nbsp; └── admin-csr.json├── kubelet│&nbsp;&nbsp; └── kubelet.config.json├── kube-proxy│&nbsp;&nbsp; └── kube-proxy-csr.json└── kube-scheduler └── kube-scheduler-csr.json 特别注意：创建证书的操作都是在 Kubernetes 的 Master 节点上执行，证书只需要创建一次即可，以后向 Kubernetes 集群中添加新节点时，只要将对应的证书拷贝到新节点上即可。千万不要在每个 Node 节点都单独执行生成 Etcd 证书的操作，否则 Etcd 集群里的节点可能会因证书不一致而导致集群启动失败。 安装 CFSSLCFSSL 是 CloudFlare 开源的一款 PKI/TLS 工具，包含一个命令行工具和一个用于签名、验证并且捆绑 TLS 证书的 HTTP API 服务，使用 Go 语言编写。 12345678910# 二进制方式安装# curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o /usr/local/bin/cfssl# curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o /usr/local/bin/cfssljson# curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o /usr/local/bin/cfssl-certinfo# 文件授权# chmod +x /usr/local/bin/cfssl*# 配置环境变量# export PATH=/usr/local/bin:$PATH 创建 CA 证书创建 CA 证书的配置文件 1234567891011121314151617181920# cat &lt;&lt; EOF | tee ca-config.json{ \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"kubernetes\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } }}EOF 123456## 字段说明:expiry : 87600h 表示有效期 10 年；ca-config.json：可以定义多个 profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个 profile；signing：表示该证书可用于签名其它证书；生成的 ca.pem 证书中 CA=TRUE；server auth：表示 client 可以用该 CA 对 server 提供的证书进行验证；client auth：表示 server 可以用该 CA 对 client 提供的证书进行验证； 创建 CA 证书签名的配置文件 123456789101112131415161718192021# cat &lt;&lt; EOF | tee ca-csr.json{ \"CN\": \"kubernetes\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"BeiJing\", \"L\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ], \"ca\": { \"expiry\": \"87600h\" }}EOF 123## 字段说明:\"CN\"：Common Name，kube-apiserver 从证书中提取该字段作为请求的用户名 (User Name)；浏览器使用该字段验证网站是否合法；\"O\"：Organization，kube-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)； 创建 CA 证书和私钥 12345678910# 查看目录下的文件# lsca-config.json ca-csr.json# 生成CA证书和私钥# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem 创建 Server 证书创建用于生成 Server 证书的 Json 配置文件，如果 hosts 字段不为空，则需要指定授权使用该证书的 IP 或域名列表。由于该证书后续被 Etcd 集群和 Kubernetes 集群使用，所以一般分别指定 Etcd 集群、Kubernetes 集群各 Master、Node 节点的主机 IP 和 Kubernetes 服务 IP（通常是 kube-apiserver 指定的 service-cluster-ip-range 网段的第一个 IP，如 10.254.0.1） 123456789101112131415161718192021222324# cat &lt;&lt; EOF | tee server-csr.json{ \"CN\": \"kubernetes\", \"hosts\": [ \"192.168.1.61\", \"192.168.1.62\", \"192.168.1.63\", \"192.168.1.64\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"BeiJing\", \"L\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ]}EOF 创建 Server 证书 1234567891011121314# 查看目录下的文件# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server-csr.json# 创建Server证书，\"-profile\" 参数的值必须与 `ca-config.json` 配置文件中的值一致# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server# 查看生成结果# lsca-config.json ca.csr ca-csr.json ca-key.pem ca.pem server.csr server-csr.json server-key.pem server.pem# 验证证书# cfssl-certinfo -cert server.pem# openssl x509 -noout -text -in server.pem 参考博客 Kubernetes SSL 证书梳理 Kubernetes 创建 TLS 证书和秘钥 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化"},{"title":"Kubernetes 之一特性与 Kubeadm 方式搭建集群","url":"/posts/b728042a.html","text":"Kubernetes 概述Kubernetes 简介Kubernetes 是 Google 开源的一个容器编排引擎，简称 K8s，是用 8 代替 8 个字符 ubernete 而成的缩写。Kubernetes 可用于管理云平台中多个主机上的容器化的应用，支持自动化部署、大规模扩缩容、应用容器化管理。在生产环境中部署一个应用程序时，通常要部署该应用的多个实例以便对应用请求进行负载均衡。Kubernetes 提供了应用部署、规划、更新、维护的一种机制。在 Kubernetes 中，可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要运维人员去进行复杂的手工配置和处理。 各种部署方式的区别传统的应用部署方式是通过插件或脚本来安装应用，这样做的缺点是应用的运行、配置、管理、所有生存周期将与当前操作系统绑定，这样做并不利于应用的升级更新、回滚等操作；当然也可以通过创建虚拟机的方式来实现某些功能，但是虚拟机非常重，并不利于可移植性。新的方式是通过部署容器方式实现，每个容器之间互相隔离，每个容器有自己的文件系统，容器之间进程不会相互影响，能区分计算资源。相对于虚拟机，容器能够快速部署，由于容器与底层设施、机器文件系统解耦的，所以它能在不同云、不同版本操作系统间进行迁移。容器占用资源少、部署快，每个应用可以被打包成一个容器镜像，每个应用与容器间成一对一关系也使容器有更大优势，使用容器可以在 build 或 release 的阶段，为应用创建容器镜像，因为每个应用不需要与其余的应用堆栈组合，也不依赖于生产环境基础结构，这使得从研发到测试、生产能提供一致环境。类似地，容器比虚拟机轻量、更 “透明”，这更便于监控和管理。 Kubernetes 功能介绍 自动装箱：基于容器对应用运行环境的资源配置要求自动部署应用容器 自我修复：当容器运行失败时，会对容器进行重启；当所部署的 Node 节点有问题时，会对容器进行重新部署和重新调度；当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务 水平扩展：通过简单的命令、用户 UI 界面或基于 CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁 服务发现：用户不需使用额外的服务发现机制，就能够基于 Kubernetes 自身能力实现服务发现和负载均衡 滚动更新：可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新 版本回退：可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退 密钥和配置管理：在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署 存储编排：自动实现存储系统挂载及应用，这特别对有状态应用实现数据持久化非常重要；存储系统可以来自于本地目录、网络存储（NFS、Gluster、Ceph 等）、公共云存储服务 批处理：提供一次性任务，定时任务，满足批量数据处理和分析的场景 Kubernetes 架构应用部署架构分类 无中心节点架构：GlusterFS 有中心节点架构：HDFS、K8S Kubernetes 集群架构 Kubernetes 集群架构节点角色 Master（主控节点）：Kubernetes 集群控制节点，负责对集群进行调度管理，接受集群外的用户去集群操作请求。Master 由 API Server、Scheduler、ClusterState Store（ETCD 存储系统）和 Controller MangerServer 组成 Scheduler：节点调度，选择 Node 节点来应用部署 API Server：集群统一入口，以 RESTful 接口将数据交给 ETCD 存储系统 Controller MangerServer：处理集群中的常规后台任务，一个资源对应一个控制器 Node（工作节点）：Kubernetes 集群工作节点，负责运行用户业务应用容器，Node 由 Kubelet、Kube-Proxy 和 ContainerRuntime 组成 Kubelet：负责 Pod 对应的容器的创建、启停管理，与 Master 节点协作，实现集群管理的基本功能 Kube-Proxy：提供 Kubernetes 的通信与负载均衡功能的重要组件 Kubernetes 核心概念 Kubernetes 集群搭建集群搭建方式目前生产环境搭建 Kubernetes 集群主要有以下两种方式： Kubeadm：Kubeadm 是一个 Kubernetes 部署工具，提供 kubeadm init 和 kubeadm join 命令，可用于快速搭建 Kubernetes 集群 二进制包：从 Github 下载发行版的二进制包，手动部署每个组件，组成 Kubernetes 集群。Kubeadm 虽然降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，生产环境推荐使用二进制包搭建 Kubernetes 集群，虽然手动部署比较麻烦，但期间可以学习很多工作原理，也利于后期维护 集群搭建要求搭建 Kubernetes 集群需要满足以下几个条件： 一台或多台机器，建议操作系统 CentOS 7.x86_64 Master 节点的硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 20GB 或更多 Node 节点的硬件配置：4GB 或更多 RAM，4 个 CPU 或更多 CPU，硬盘 40GB 或更多 集群中所有机器之间的网络可以互通 系统内可以访问外网，需要拉取镜像 禁用 swap 分区 集群搭建规划Kubernetes 集群搭建规划分为单 Master 集群和多 Master 集群两种，为了提高集群的高可用性，生产环境一般采用后者的规划方案，如下图所示： Kubeadm 方式搭建单 Master 集群搭建目标-（1）在所有节点上安装 Docker 和 kubeadm-（2）部署 Kubernetes Master-（3）部署容器网络插件-（4）部署 Kubernetes Node，将节点加入 Kubernetes 集群中-（5）部署 Dashboard Web 页面，可视化查看 Kubernetes 资源 软件环境 软件 版本 安装方式 CentOS 7.9 3.10.0-1160.15.2.el7.x86_64 虚拟机 Docker docker-ce-18.06.1.ce-3.el7 YUM Kubelet 1.18.0 YUM Kubeadm 1.18.0 YUM Kubectl 1.18.0 YUM Dashboard 2.0.3 Kubernetes 服务器规划 Host Name 角色 IP CPU Memory Disk k8s-master master 192.168.31.61 &gt;= 2C &gt;=2G &gt;=20G k8s-node1 node 192.168.31.62 &gt;= 4C &gt;=4G &gt;=40G k8s-node2 node 192.168.31.63 &gt;= 4C &gt;=4G &gt;=40G k8s-node3 node 192.168.31.64 &gt;= 4C &gt;=4G &gt;=40G 系统初始化值得一提的是，以下系统初始化操作都必须在所有节点上执行一次，重点包括在所有节点里安装 Docker、Kubelet、Kubeadm。这里要求 Kubelet、Kubeadm、Kubectl 的版本与 Docker 的版本互相匹配（兼容），不建议安装最新版本的 Docker，因为 Kubernetes 对最新版的 Docker 兼容不够及时，容易导致 Kubeadm 方式搭建 Kubernetes 集群失败。 关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i 's/enforcing/disabled/' /etc/selinux/config 关闭 swap 12345# 临时关闭$ swapoff -a# 永久关闭# sed -i 's/.*swap.*/#&amp;/' /etc/fstab 系统时间同步 12345# 安装时间同步工具# yum install ntpdate -y# 设置时间同步服务器# ntpdate time.windows.com 安装 Docker，这是由于 Kubernetes 默认的 CRI（容器运行时）为 Docker 1234567891011121314151617181920212223242526# 添加YUM源# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo# 安装Docker（指定版本号，否则默认安装最新版本）# yum -y install docker-ce-18.06.1.ce-3.el7# 开机自启动Docker# systemctl enable docker# 启动Docker# systemctl start docker# 配置阿里的Docker镜像加速# vim /etc/docker/daemon.json{ \"registry-mirrors\": [\"https://b9pmyelo.mirror.aliyuncs.com\"]}# 重启Docker# systemctl restart docker# 查看Docker的版本# docker --version# 查看Docker的安装信息# docker info 安装 Kubelet、Kubeadm、Kubectl 1234567891011121314151617# 添加YUm源# vim /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg# 安装（指定版本号，否则默认会安装最新版本）# yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0# 开机自启动Kubelet# systemctl enable kubelet# 提示：Kubelet安装完成后不需要手动启动，因为在Node节点成功加入集群之前，Kubelet自身会不断重启（期间会伴随着各种启动错误，这点不用在意） 将桥接的 IPv4 流量传递到 iptables 的链 1234567# 添加路由规则# vim /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1# 配置生效# sysctl --system 设置主机名 1# hostnamectl set-hostname &lt;hostname&gt; 添加 hosts（Master 和各 Node 节点都配置） 123456# 添加hosts# vim /etc/hosts192.168.31.61 k8s-master192.168.31.62 k8s-node1192.168.31.63 k8s-node2192.168.31.64 k8s-node3 部署 Master 节点在 Master 节点执行 Kubeadm 初始化操作，--service-cidr 与 --pod-network-cidr 一般都不需要更改，详细参数说明如下，点击查看详细的安装日志信息 --apiserver-advertise-address：Master 节点的 IP 地址 --kubernetes-version：Kubernetes 的版本号，必须与上面 Kubelet 的版本号一致 --apiserver-advertise-address：一般指定为 Haproxy + Keepalived 的 VIP --image-repository：由于默认拉取镜像地址 k8s.gcr.io 国内无法访问，指定阿里云镜像仓库地址 --pod-network-cidr：指定 Pod Network 的地址范围，由于 Kubernetes 支持多种网络方案，而且不同网络方案对参数有各自要求，设置为 10.244.0.0/16 表示使用 Flannel 网络方案 1234567891011121314151617181920212223242526# 执行初始化# kubeadm init \\--apiserver-advertise-address=192.168.31.61 \\--image-repository registry.aliyuncs.com/google_containers \\--kubernetes-version v1.18.0 \\--service-cidr=10.96.0.0/12 \\--pod-network-cidr=10.244.0.0/16# 当终端打印如下的提示信息，则说明Docker开始拉取镜像，这个过程比较耗时（严重依赖网速）[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'# 初始化完成后，记录下终端最后打印的Kubeadm命令（如下），后续添加Node节点到集群时会使用到### kubeadm join 192.168.1.109:6443 --token jve1cd.3ulp5fqifsptti23 --discovery-token-ca-cert-hash sha256:01229ee179cf13855dbf38bc050b3251928571996d60878f30ce13c08aaa62d5# 查看Docker的镜像列表# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.aliyuncs.com/google_containers/kube-proxy v1.18.0 43940c34f24f 11 months ago 117MBregistry.aliyuncs.com/google_containers/kube-apiserver v1.18.0 74060cea7f70 11 months ago 173MBregistry.aliyuncs.com/google_containers/kube-controller-manager v1.18.0 d3e55153f52f 11 months ago 162MBregistry.aliyuncs.com/google_containers/kube-scheduler v1.18.0 a31f78c7c8ce 11 months ago 95.3MBregistry.aliyuncs.com/google_containers/pause 3.2 80d28bedfe5d 13 months ago 683kBregistry.aliyuncs.com/google_containers/coredns 1.6.7 67da37a9a360 13 months ago 43.8MBregistry.aliyuncs.com/google_containers/etcd 3.4.3-0 303ce5db0e90 16 months ago 288MB 在 Master 节点配置 Kubectl 工具 1234567891011121314151617# 创建目录# mkdir -p $HOME/.kube# 拷贝配置文件# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config# 文件授权# chown $(id -u):$(id -g) $HOME/.kube/config# 查询组件的状态# kubectl get csNAME STATUS MESSAGEERROR etcd-0 Healthy {\"health\":\"true\"}controller-manager Healthy okscheduler Healthy ok# 提示：当上面的 STATUS 结果都为 \"Healthy\"，表示组件处于健康状态，否则需要检查错误，如果排除不了问题，可以使用 \"kubeadm reset\" 命令重置集群后重新初始化 Master 节点安装 Flannel 网络插件查看集群状态，此时的 Master 处于 “NotReady”（未就绪），这是因为集群中尚未安装 Flannel 网络插件，部署完网络插件后状态会自动变为 Ready 1234# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master NotReady master 12m v1.18.0 安装 Flannel 网络插件，若 kubectl apply -f 命令执行后提示网络连接失败，可留意文章后面给出的解决方案 12345678910111213141516# 安装Flannel网络插件# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube\u0002-flannel.yml# 查询Pod组件的状态# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-7ff77c879f-67rjn 1/1 Running 0 4m35scoredns-7ff77c879f-xpq9h 1/1 Running 0 4m35setcd-k8s-master 1/1 Running 0 4m44skube-apiserver-k8s-master 1/1 Running 0 4m44skube-controller-manager-k8s-master 1/1 Running 0 4m44skube-flannel-ds-4jtp4 1/1 Running 0 2m36skube-proxy-8bbhk 1/1 Running 0 4m34skube-scheduler-k8s-master 1/1 Running 0 4m44s# 提示：Flannel 网络插件安装完成后，需要耐心等待一段时间，直到 \"kubectl get pods -n kube-system\" 命令查询到的所有 Pod 组件的状态都为 Running 为止 当 Master 节点处于 Ready 状态，就可以开始将 Node 节点加入集群 1234# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master Ready master 12m v1.18.0 将 Node 节点加入到 Kubernetes 集群在各个 Node 节点里执行以下命令，向 Kubernetes 集群添加新节点，该命令是上述 kubeadm init 命令执行完成后在终端记录下来的 12# 添加Node节点到集群# kubeadm join 192.168.1.109:6443 --token jve1cd.3ulp5fqifsptti23 --discovery-token-ca-cert-hash sha256:01229ee179cf13855dbf38bc050b3251928571996d60878f30ce13c08aaa62d5 测试 Kubernetes 集群功能在 Master 节点执行以下命令，查看集群中所有节点的状态，当它们的状态都为 Ready 时，表示 Kubernetes 集群已经成功搭建起来了。值得一提的是，集群中所有节点的状态变更为 Ready，这需要花较长时间，可能花十几分钟甚至几十分钟 1234567891011121314151617181920212223242526272829303132# 查看集群状态# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master Ready master 9m37s v1.18.0k8s-node1 Ready &lt;none&gt; 2m43s v1.18.0k8s-node2 Ready &lt;none&gt; 11s v1.18.0k8s-node3 Ready &lt;none&gt; 1s v1.18.0# 查询Pod组件的状态# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-7ff77c879f-67rjn 1/1 Running 0 30mcoredns-7ff77c879f-xpq9h 1/1 Running 0 30metcd-k8s-master 1/1 Running 0 30mkube-apiserver-k8s-master 1/1 Running 0 30mkube-controller-manager-k8s-master 1/1 Running 0 30mkube-flannel-ds-4jtp4 1/1 Running 0 28mkube-flannel-ds-6k8sp 1/1 Running 0 23mkube-flannel-ds-bzwrt 1/1 Running 0 23mkube-flannel-ds-rc8vv 1/1 Running 0 23mkube-proxy-8bbhk 1/1 Running 0 30mkube-proxy-9f96v 1/1 Running 0 23mkube-proxy-9j6qh 1/1 Running 0 23mkube-proxy-bqm7t 1/1 Running 0 23mkube-scheduler-k8s-master 1/1 Running 0 30m# 查看集群版本# kubectl version --shortClient Version: v1.18.0Server Version: v1.18.0# 提示：当各节点的 Linux 系统重启后，Kubernetes 集群里对应的组件会自动启动，不需要人为干预 在 Master 节点里创建一个 Nginx 容器，验证 Kubernetes 集群是否正常运行 123456789101112131415161718# 创建Nginx容器# kubectl create deployment nginx --image=nginx# 暴露Nginx的端口# kubectl expose deployment nginx --port=80 --type=NodePort# 查看Pod组件# kubectl get podNAME READY STATUS RESTARTS AGEpod/nginx-f89759699-59cb7 1/1 Running 0 2m1s# 查看Svc# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 48mservice/nginx NodePort 10.102.129.11 &lt;none&gt; 80:32517/TCP 10s# 提示：浏览器访问 \"http://&lt;any_node_ip&gt;:32517\"，若 Ngninx 容器在集群中创建并启动成功，则默认会打开 Nginx 的首页 Kubeadm 部署 Dashboard 可视化插件在 Kubeadm 部署 Dashboard 可视化插件的流程中，以下所有操作都是直接在 Master 节点里执行，后续不再累述。 Dashboard 简介在 Kubernetes 社区中，有一个很受欢迎的 Dashboard 项目，它可以给用户提供一个可视化的 Web 界面来查看当前集群的各种信息。用户可以用 Kubernetes Dashboard 部署容器化的应用、监控应用的状态、执行故障排查任务以及管理 Kubernetes 各种资源。 Dashboard 官方参考文档 Dashboard Github 项目地址 Dashboard 各版本说明，Dashboard 版本与 Kubernetes 版本必须匹配（兼容） Dashboard 部署执行 YAML 文件直接部署 Dashboard，这里的 Kubernetes 1.8 版本对应的 Dashboard 版本为 v2.0.3，两者的版本号必须匹配 12# 部署# kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml 查看 Dashboard 的运行状态，可以看到以 deployment 方式部署，运行了 2 个 Pod 及 2 个 Service 1234567891011# 查看Pod的状态# kubectl -n kubernetes-dashboard get podsNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-6b4884c9d5-wn22s 0/1 ContainerCreating 0 48skubernetes-dashboard-7f99b75bf4-fn956 0/1 ContainerCreating 0 48s# 查看Svc的状态# kubectl -n kubernetes-dashboard get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.96.115.247 &lt;none&gt; 8000/TCP 117skubernetes-dashboard ClusterIP 10.100.88.170 &lt;none&gt; 443/TCP 117s Dashboard 暴露服务这里作为演示，使用 NodePort 方式将 Dashboard 的服务暴露在集群外，指定使用 30443 端口（可自定义） 12345678# 暴露Service# kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard -p '{\"spec\":{\"type\":\"NodePort\",\"ports\":[{\"port\":443,\"targetPort\":8443,\"nodePort\":30443}]}}'# 查看暴露的Service# kubectl -n kubernetes-dashboard get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.96.115.247 &lt;none&gt; 8000/TCP 6m2skubernetes-dashboard NodePort 10.100.88.170 &lt;none&gt; 443:30443/TCP 6m2s 或者下载 YAML 文件，手动更改 Service 部分的端口，并以为 NodePort 方式进行部署 1234567891011121314151617181920212223242526# 下载YAML文件# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml# 更改YAML文件# vim recommended.yaml---kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30443 selector: k8s-app: kubernetes-dashboard---# 更新配置# kubectl apply -f recommended.yaml Dashboard 认证方式登录Dashboard 支持 Kubeconfig 和 Token 两种认证方式，这里选择 Token 认证方式登录，首先执行以下操作创建登录用户 12345# 创建YAML配置文件，复制下面的内容到文件中# vim dashboard-adminuser.yaml# 创建登录用户# kubectl apply -f dashboard-adminuser.yaml YAML 配置文件 dashboard-adminuser.yaml 的完整内容如下，指定了一个名称为 admin-user 的服务账号，并放在 kubernetes-dashboard 命名空间下，并将 cluster-admin 角色绑定到 admin-user 账户，这样 admin-user 账户就有了管理员的权限。默认情况下，Kubeadm 创建集群时已经创建了 cluster-admin 角色，只需直接绑定即可 1234567891011121314151617181920---apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 查看 admin-user 账户的 Token 12# 查看Token# kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}') 使用火狐浏览器打开 https://&lt;any_node_ip&gt;:30443，访问 Dashboard 的登录界面，由于谷歌浏览器会强制使用 HTTPS 协议，这将导致无法访问 Dashboard 的登录页面，因此建议使用火狐浏览器进行访问 将获取到的 Token 复制到登录界面的 Token 输入框中，成功登陆 Dashboard Dashboard 登录超时Dashboard 默认登录超时时间是 15min，可以为 Dashboard 容器增加 --token-ttl 参数来自定义超时时间，配置示例如下： 123456789101112131415# 下载YAML文件# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml# 更改YAML文件# vim recommended.yaml---args: - --auto-generate-certificates - --namespace=kubernetes-dashboard - --token-ttl=43200---# 更新配置# kubectl apply -f recommended.yaml Kubeadm 搭建集群问题总结1[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2 执行 kubeadm init 命令，提示 CPU 核心数少于 2，可以添加命令参数 --ignore-preflight-errors=NumCPU 忽略警告 1[ERROR Swap]: running with swap on is not supported. Please disable swap 执行 kubeadm init 命令，提示启用了 swap 分区，可以添加命令参数 --ignore-preflight-errors 'Swap' 忽略错误 1[WARNING SystemVerification]: this Docker version is not on the list of validated versions: 19.03.1. Latest validated version: 18.09 执行 kubeadm init 命令，提示 Docker 的版本过高，可能与 Kubernetes 的版本不兼容 1The connection to the server raw.githubusercontent.com was refused - did you specify the right host or port? 执行 kubectl apply -f 命令，提示网络链接失败，这是国内无法访问 raw.githubusercontent.com 导致，临时解决方法如下： 在 https://www.ipaddress.com 网站上查询 raw.githubusercontent.com 域名的真实 IP 地址 更改系统的 /etc/hosts 配置文件，添加一行内容 185.199.108.133 raw.githubusercontent.com，将 185.199.108.133 替换为查询到真实的 IP 地址 重新执行 kubectl apply -f 命令即可 参考资料 Kubernetes 部署 Dashboard 可视化插件 Kubeadm 部署单 Master 节点 Kubernetes 集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化"},{"title":"Knife4j 基础使用教程","url":"/posts/e2246230.html","text":"1、前言 Knife4j Github 项目 Knife4j 官方示例代码 Knife4j 官方中文文档 - 最新 Knife4j 官方中文文档 - 旧版 特别注意，若没有特别标注说明，本文默认使用的 Knife4j 版本是 2.x。 1.1、Knife4j 简介Knife4j 是为 Java MVC 框架集成 Swagger 生成 Api 文档的增强解决方案，前身是 swagger-bootstrap-ui，致力于 springfox-swagger 的增强 UI 实现。knife4j 为了契合微服务的架构发展，由于原来 swagger-bootstrap-ui 采用的是后端 Java 代码 + 前端 UI 混合打包的方式，在微服务架构下显的很臃肿，因此项目正式更名为 knife4j，更名后主要专注的方面如下： 后端 Java 代码以及前端 UI 模块进行了分离，在微服务架构下使用更加灵活 提供专注于 Swagger 的增强解决方案，不同于只是单纯增强前端 UI 部分 1.2、Knife4j 模块 模块名称 说明 knife4j 为 Java MVC 框架集成 Swagger 的增强解决方案 knife4j-admin 云端 Swagger 接口文档注册管理中心，集成 gateway 网关对任意微服务文档进行组合集成 knife4j-extension chrome 浏览器的增强 swagger 接口文档 ui, 快速渲染 swagger 资源 knife4j-service 为 swagger 服务的一系列接口服务程序 knife4j-front knife4j-spring-ui 的纯前端静态版本，用于集成非 Java 语言使用 swagger-bootstrap-ui knife4j 的前身，最后发布版本是 1.9.6 1.3、使用 Knife4j 的业务场景若不使用 knife4j 的增强功能，相当于纯粹换了一个 Swagger 的前端界面，这种情况是最简单的，原项目结构下无需作任何变更，可以直接引用 swagger-bootstrap-ui 的最后一个版本 1.9.6 或者使用 knife4j-spring-ui 123456&lt;!-- 旧版本引用 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;`swagger-bootstrap-ui`&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt;&lt;/dependency&gt; 123456&lt;!-- 新版本引用 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-ui&lt;/artifactId&gt; &lt;version&gt;${lastVersion}&lt;/version&gt;&lt;/dependency&gt; 若在 Spring Boot 项目单体架构使用增强功能，knife4j 提供了 starter 供开发者快速使用，该包会引用 knife4j 提供的所有资源，包括前端 UI 和后端的 Jar 包 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 若在 Spring Cloud 的微服务架构下，每个微服务其实并不需要引入前端的 UI 资源，因此在每个微服务的 Spring Boot 项目里，只需引入 knife4j 提供的微服务 starter 即可 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-micro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 最后在 Spring Cloud 的网关聚合文档服务（如 Zuul、Gateway）里，再把前端的 UI 资源引入 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j.version}&lt;/version&gt;&lt;/dependency&gt; 不管是 knife4j 还是 swagger-bootstrap-ui，对外提供的访问地址依然是 http://ip:port/doc.html；同时 swagger-bootstrap-ui 使用的是传统的 Javascript 技术，即 jQuery + DOM 操作，打包后的源码并没有压缩处理，而 knife4j 的前端则采用 Vue。 2、Spring 单体架构2.1、基于 Maven Bom 方式使用 基于 Maven Bom 方式使用 2.2、Spring MVC 框架集成 Knife4j Spring MVC 框架集成 Knife4j 2.3、Spring Boot 框架集成 Knife4j Spring Boot 框架集成 Knife4j 3、Spring Cloud 微服务架构3.1、Spring Cloud Zuul 集成 Knife4j Spring Cloud Zuul 集成 Knife4j 3.2、Spring Cloud Gateway 集成 Knife4j Spring Cloud Gateway 集成 Knife4j 4、微服务聚合实战4.1、Eureka 聚合 Knife4j Eureka 聚合 Knife4j 4.2、Nacos 聚合 Knife4j Nacos 聚合 Knife4j 4.3、Gateway 聚合 Knife4jGateway 聚合 Knife4j 后，若需要对业务模块的的 API 文档接口 /v2/api-doc 添加 Basic 身份认证，则只需在对应的业务模块下的 YML 配置文件里添加以下内容即可： 12345678knife4j: cors: true enable: true # 是否开启增强配置 basic: username: test # Basic认证用户名 password: 987789 # Basic认证密码 enable: true # 开启Basic身份认证 production: false # 是否屏蔽所有Swagger的相关资源，默认是false 若业务模块配置了上述的 Basic 身份认证后，此时访问 Gateway 的聚合文档服务的 Web 界面，会弹出用户名和密码的输入框（如下图） 5、Knife4j 整合 OAuth2.0Knife4j 整合 OAuth2.0 的 Java 代码配置如下，关键在于创建 Docket 对象时，指定 OAuth2.0 的授权模式，包括简化模式 (implicit)、授权码模式 (authorization_code)、密码模式 (password)、客户端模式 (client_credentials)。值得一提的是，无论项目采用 Spring 单体架构还是 Spring Cloud 微服务架构，下面介绍的 Knife4j + OAuth2.0 的整合方式都适用，包括 Gateway + Knife4j + OAuth2.0 整合的项目。 下文提到的 @EnableBeanValidator 注解类的代码如下： 123456789101112import org.springframework.context.annotation.Import;import springfox.bean.validators.configuration.BeanValidatorPluginsConfiguration;import java.lang.annotation.*;@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.TYPE})@Documented@Import(BeanValidatorPluginsConfiguration.class)public @interface EnableBeanValidator {} 手动方式 ★点击展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.ApiKey;import springfox.documentation.service.AuthorizationScope;import springfox.documentation.service.SecurityReference;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.Collections;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(\"com.shop\")) .paths(PathSelectors.any()) .build() // 整合OAuth2.0 .securitySchemes(Collections.singletonList(apiKey())) .securityContexts(Collections.singletonList(securityContext())); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"Knife4j 接口文档\") .description(\"业务接口 API 文档.\") .termsOfServiceUrl(\"\") .version(\"v1.0.0\") .build(); } private ApiKey apiKey() { return new ApiKey(\"Bearer\", \"Authorization\", \"header\"); } /** * Swagger2 认证的安全上下文 * * @return */ private SecurityContext securityContext() { return SecurityContext.builder() .securityReferences(defaultAuth()) .forPaths(PathSelectors.any()) .build(); } /** * 认证方式 * * @return */ private List&lt;SecurityReference&gt; defaultAuth() { AuthorizationScope authorizationScope = new AuthorizationScope(\"web\", \"access_token\"); AuthorizationScope[] authorizationScopes = new AuthorizationScope[1]; authorizationScopes[0] = authorizationScope; return Collections.singletonList(new SecurityReference(\"Bearer\", authorizationScopes)); }} 最终呈现的界面如下，填写提前获取到的 Access Token 即可，如下图所示： 刷新业务接口的调试界面，就会看到参数 Authorization 值已经更新了，如下图所示： 客户端模式 ★点击展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage(\"com.example\")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"Knife4j 接口文档\") .description(\"业务接口 API 文档.\") .termsOfServiceUrl(\"\") .version(\"v1.0.0\") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference(\"oauth2\", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant(\"/**\")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用客户端模式（client_credentials） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); String clientTokenUrl = \"http://127.0.0.1:18010/oauth/token\"; ClientCredentialsGrant clientCredentialsGrant = new ClientCredentialsGrant(clientTokenUrl); grantTypes.add(clientCredentialsGrant); OAuth oAuth = new OAuthBuilder().name(\"oauth2\").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 clientId 以及 clientSecret，然后点击 Authorize 按钮进行授权即可，如下图所示： 密码模式 ★点击展开代码★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage(\"com.example\")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"Knife4j 接口文档\") .description(\"业务接口 API 文档.\") .termsOfServiceUrl(\"\") .version(\"v1.0.0\") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference(\"oauth2\", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant(\"/**\")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用密码模式（password） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); String passwordTokenUrl = \"http://127.0.0.1:18010/oauth/token\"; ResourceOwnerPasswordCredentialsGrant resourceOwnerPasswordCredentialsGrant = new ResourceOwnerPasswordCredentialsGrant(passwordTokenUrl); grantTypes.add(resourceOwnerPasswordCredentialsGrant); OAuth oAuth = new OAuthBuilder().name(\"oauth2\").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 username、password、clientId 以及 clientSecret，然后点击 Authorize 按钮进行授权即可，如下图所示： 授权模式 ★点击展开代码★ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import com.google.common.collect.Lists;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.OAuthBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc;import java.util.ArrayList;import java.util.List;@Configuration@EnableBeanValidator@EnableSwagger2WebMvcpublic class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.basePackage(\"com.example\")) .paths(PathSelectors.any()) .build() .securityContexts(securityContexts()) .securitySchemes(securitySchemes()) .apiInfo(apiInfo()); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"Knife4j 接口文档\") .description(\"业务接口 API 文档.\") .termsOfServiceUrl(\"\") .version(\"v1.0.0\") .build(); } /** * Swagger2 认证的安全上下文 * * @return */ private List&lt;SecurityContext&gt; securityContexts() { List&lt;AuthorizationScope&gt; scopes = new ArrayList&lt;&gt;(); SecurityReference securityReference = new SecurityReference(\"oauth2\", scopes.toArray(new AuthorizationScope[]{})); SecurityContext securityContext = new SecurityContext(Lists.newArrayList(securityReference), PathSelectors.ant(\"/**\")); return Lists.newArrayList(securityContext); } /** * OAuth2.0 的认证方式 * * @return */ private List&lt;SecurityScheme&gt; securitySchemes() { // 使用授权码模式（authorization_code） List&lt;GrantType&gt; grantTypes = new ArrayList&lt;&gt;(); TokenRequestEndpoint tokenRequestEndpoint = new TokenRequestEndpoint(\"http://127.0.0.1:18010/oauth/authorize\", \"client1\", \"secert1\"); TokenEndpoint tokenEndpoint = new TokenEndpoint(\"http://127.0.0.1:18010/oauth/token\", \"access_token\"); AuthorizationCodeGrant authorizationCodeGrant = new AuthorizationCodeGrant(tokenRequestEndpoint, tokenEndpoint); grantTypes.add(authorizationCodeGrant); OAuth oAuth = new OAuthBuilder().name(\"oauth2\").grantTypes(grantTypes).build(); return Lists.newArrayList(oAuth); }} 输入 clientId 及 clientSecret，然后点击 Authorize 按钮，最终跳转授权界面，如下图所示： 选择进行授权，授权完成后就可以直接调试接口了，如下图所示（该图与上述代码不相关，来源于网络）： 简化模式（待补充）6、全局参数设置 Oauth 的 Token除了上面介绍的 Knife4j 自动获取 Access Token 之外，还可以通过 Knife4j 全局参数设置的功能来手动添加 Access Token，可以省去整合 OAuth2.0 的 Java 代码，这里 Access Token 的格式必须是以 bearer + 空格 作为前缀 7、参考文档 Swagger 源码分析 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 java"},{"title":"JWT 基础使用教程","url":"/posts/1b9bb05b.html","text":"JWT 概述JSON Web Token（JWT）是目前最流行的跨域身份验证解决方案。 传统的身份验证 用户向服务器发送用户名和密码 验证服务器后，相关数据（如用户角色，登录时间等）将保存在当前会话中 服务器向用户返回 session_id，Session 信息都会写入到用户的 Cookie 中 用户的每个后续请求都将通过在 Cookie 中取出 session_id 并传递给服务器 服务器收到 session_id 并对比之前保存的数据，确认用户的身份 这种模式最大的问题是，没有分布式架构，无法支持横向扩展。如果使用一个服务器，该模式完全没有问题。但是，如果它是服务器群集或面向服务的跨域体系结构的话，则需要一个统一的 Session 数据库（Redis）来保存会话数据实现共享，如果保存 Session 的数据库（Redis）挂掉，整个认证体系都会挂掉。 JWT 的身份验证JWT 的原则是在服务器身份验证之后，将生成一个 JSON 对象并将其发送给用户。之后，当用户与服务器通信时，客户在请求中带上 JSON 对象，服务器仅依赖于这个 JSON 对象来标识用户。为了防止用户篡改数据，服务器将在生成对象时添加签名。服务器不保存任何会话数据，即服务器变为无状态，使其更容易扩展。具体的身份验证流程如下： 用户发起登录请求，请求认证服务 认证服务成功认证后，生成 JWT 令牌，并将 JWT 令牌写入到用户的 Cookie 用户访问 Web 资源页面，带着 Cookie 到网关服务 网关服务从 Cookie 获取并校验用户的 JWT 令牌，如果 JWT 令牌有效否则放行请求 用户注销登录，请求认证服务，删除用户 Cookie 中的 JWT 令牌 JWT 与 传统身份验证比较JWT 和传统的 Cookie/Session 会话管理相比较有着多方面的优势，因为 Cookie/Session 需要在 Web 服务器的 Session 里存放用户信息，然后通过客户端 Cookie 中存储的 session_id 来获取特定的用户信息，这个过程需要消耗 Web 服务器的内存和对客户端的要求比较严格（必须支持 Cookie），而 JWT 最大的特性在于就是无状态、去中心化，所以 JWT 更适用分布式的场景，不需要在多台服务器做会话同步这种消耗服务器性能的操作。另外 JWT 和 Redis + Token 这两种会话管理方案需要根据项目情况选择，别用了 JWT 还使用 Redis 存储的，因为这种做法对 JWT 来说就是 “伤害不大，但侮辱性极强” 的做法，相当于无视 JWT 的 “无状态” 特性。 JWT 字符串结构JWT 字符串由 Header（头部）、Payload（负载）、Signature（签名）三部分组成： Header: JSON 对象，用来描述 JWT 的元数据，alg 属性表示签名的算法，typ 标识 token 的类型 Payload: JSON 对象，重要部分，除了默认的字段，还可以扩展自定义字段，比如用户 ID、姓名、角色等等 Signature: 对 Header、Payload 这两部分进行签名，认证服务器使用私钥签名，然后在资源服务器使用公钥验签，防止数据被人动了手脚 JWT 签名有对称和非对称两种方式： 对称方式：认证服务器和资源服务器使用同一个密钥进行加签和验签 ，默认算法 HMAC 非对称方式：认证服务器使用私钥加签，资源服务器使用公钥验签，默认算法 RSA 非对称方式相较于对称方式更为安全，因为私钥只有认证服务器知道 JWT 开源库的使用OAuth 2.0 与 JWT 的关系 OAuth 2.0 是一种认证授权的协议规范 JWT 是基于 Token 的安全认证协议的实现 OAuth 2.0 的认证服务器签发的 Token 可以使用 JWT 来实现，JWT 轻量且安全。 Gateway + OAuth 2.0 + JWT 实现统一的认证授权 Gateway + Security + OAuth 2.0 + JWT 实现统一的认证授权 参考博客 nimbus-jose-jwt JWT 库使用介绍 Spring Cloud Gateway + JWT 实现统一的认证授权 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"oauth"},{"title":"JetBrains IDEA 2020.3.2 破解激活教程","url":"/posts/3644bd49.html","text":"最新公告本教程提供的激活码已失效，建议参考这篇博客，使用最新的方式来激活 JetBrains IDEA 2020.3.2 或者更新的版本。 前言本教程适用于 JetBrains IDEA 2020.3.2 以下所有版本（包括 IDEA 2020 全系列），支持将 IDEA 2020.3.2 激活到 2099 年，亲测激活成功！！！ 资源下载 JetBrains IDEA 下载：官网 JetBrains IDEA&nbsp;破解补丁下载：本站 激活步骤第一步更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com 第二步下载安装 JetBrains IDEA，然后启动 IDEA 并选择试⽤（Evaluate for free）模式进⼊软件（如下图），首次启动后的配置项根据自己的需要勾选即可，此步骤不会影响后面破解的过程。假设软件之前已经在试用或者试用过而且过期了，那么可以先删除 IDEA 的所有配置文件，然后再重新启动软件，IDEA 配置文件所在的目录如下： 1234567# Windows系统C:\\Documents and Settings\\Administrator\\.idea-2020.3\\configC:\\Documents and Settings\\Administrator\\.idea-2020.3\\system# Linux/Mac系统~/.config/JetBrains/IntelliJIdea2020.3~/.local/share/JetBrains/IntelliJIdea2020.3 第三步下载并解压破解补丁的压缩文件，得到 BetterIntelliJ.zip 文件和激活 KEY，切记以后不能随意删除或者移动 BetterIntelliJ.zip 文件的位置，否则 IDEA 激活之后还会失效。 第四步JetBrains IDEA 启动后（试用模式），手动选择创建或者打开一个项目，进入到 IDEA 的主界面。在菜单栏导航到：File -&gt; Settings -&gt; Plugins -&gt; Install Plugin From Disk，然后找到 BetterIntelliJ.zip 文件开始安装破解插件。当破解插件安装完成后，手动重启 IDEA 让插件生效，建议检查 IDEA 的进程是否真正关闭了。特别注意，以后不能随意在 IDEA 的插件市场更新 BetterIntelliJ 破解插件的版本，否则 IDEA 的破解激活会失效。 第五步检查破解插件是否安装成功，IDEA 的菜单栏导航到：Help -&gt; Edit Custom Vm Options，如果配置文件末尾出现了一行 -javaagent:/xxxx/BetterIntelliJ-1.16.jar，则说明破解插件安装成功。值得一提的是，在 Linux/Mac 64 位系统环境下，破解插件所用的配置文件的路径为 /${HOME}/.config/JetBrains/IntelliJIdea2020.3/idea64.vmoptions，而不是 IDEA 自身安装目录下的 idea64.vmoptions 配置文件。 破解插件在不同系统平台的正确配置如下： 12345# Windows系统-javaagent:C:\\Users\\Public\\.BetterIntelliJ\\BetterIntelliJ-版本号.jar# Linux/Mac系统-javaagent:${HOME}/.BetterIntelliJ/BetterIntelliJ-版本号.jar 第六步IDEA 的菜单导航到：Help -&gt; Register -&gt; Add New License，将破解补丁压缩文件里的激活 KEY 复制到 IDEA 激活码的输入框里，然后点击 Activate 激活按钮即可，如下图所示： 第七步查看 IDEA 是否破解成功，IDEA 的菜单栏导航到：Help -&gt; About，若出现下图的信息则说明破解成功。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Redisson 分布式锁使用教程","url":"/posts/f838cf2a.html","text":"前言 Redisson 官网 Redisson 官方文档 Redisson GitHub 仓库 Redisson 简介Redisson 是架设在 Redis 基础上的一个 Java 驻内存数据网格（In-Memory Data Grid）。充分地利用了 Redis 键值数据库提供的一系列优势，基于 Java 实用工具包中的常用接口，为使用者提供了一系列具有分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度。同时结合各富特色的分布式服务，更进一步简化了分布式环境中程序相互之间的协作。Redisson 的宗旨是促进使用者对 Redis 的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。值得一提的是，Redisson 底层采用的是 Netty 框架。支持 Redis 2.8 以上版本，支持 Java 1.6+ 以上版本。 Redisson 对象Redis 命令和 Redisson 对象匹配列表请阅读 这里。 Redisson 基础使用Spring 整合 Redisson 引入 Maven 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.19.0&lt;/version&gt;&lt;/dependency&gt; 配置 Redisson 客户端的连接信息，包括 Reids 服务器的地址、密码等内容。 123456789101112131415@Configurationpublic class RedisssonConfig { @Bean(destroyMethod = \"shutdown\") public RedissonClient redissonClient() throws IOException { Config config = new Config(); config.useSingleServer() // 地址 .setAddress(\"redis://127.0.0.1:6379\") // 密码 .setPassword(\"123456\"); return Redisson.create(config); } } 提示 上述的配置方式同样适用于 SpringBoot 项目。 配置完 Redisson 客户端后，在 Java 业务代码里就可以直接注入 RedissonClient 实例对象来使用 Redisson 提供的各种分布式锁了。 可重入锁 (Reentrant Lock)基于 Redis 的 Redisson 分布式可重入锁 RLock 实现了 java.util.concurrent.locks.Lock 接口，同时还提供了异步（Async）、反射式（Reactive）和 RxJava2 标准的接口。众所周知，如果负责储存这个分布式锁的 Redisson 节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson 内部提供了一个监控锁的看门狗，它的作用是在 Redisson 实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是 30 秒钟，也可以通过修改 Config.lockWatchdogTimeout 来另行指定。另外 Redisson 还为加锁的方法提供了 leaseTime 参数来指定加锁的时间，超过这个时间后锁便会自动解开。 直接获取锁，阻塞等待直至获取到锁 12345678910111213141516171819202122232425@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void rLock() throws InterruptedException { // 获取可重入锁 RLock lock = redissonClient.getLock(\"rLock\"); // 阻塞等待，直至获取到锁 lock.lock(); try { System.out.println(\"==&gt; success to get locker\"); Thread.sleep(5000); } catch (Exception e) { e.printStackTrace(); } finally { // 解锁 lock.unlock(); } }} 提示 RLock.lock() 方法加锁后，默认加的锁的有效期是 30 秒。 RLock.lock() 方法加锁后，如果业务耗时超长，Redisson 在业务执行期间会周期性地自动给锁续上新的 30 秒有效期（看门狗机制），不用担心业务执行时间过长，锁自动过期被删掉的问题。 RLock.lock() 方法加锁后，只要加锁的业务运行完成，Redisson 就不会再给当前锁续期，即使不手动解锁，锁默认会在 30 秒内自动删除。 直接获取锁，阻塞等待直至获取到锁，且上锁以后 10 秒自动解锁 12345678910111213141516171819202122232425@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void rLock() throws InterruptedException { // 获取可重入锁 RLock lock = redissonClient.getLock(\"rLock\"); // 阻塞等待，直至获取到锁，且上锁以后10秒自动解锁 lock.lock(10, TimeUnit.SECONDS); try { System.out.println(\"==&gt; success to get locker\"); Thread.sleep(5000); } catch (Exception e) { e.printStackTrace(); } finally { // 解锁 lock.unlock(); } }} 特别注意 调用 RLock.lock(10, TimeUnit.SECONDS) 方法加锁时，设置自动解锁的时间必须大于业务的执行时间。 调用 RLock.lock(10, TimeUnit.SECONDS) 方法加锁时，在锁时间到了以后，即使业务未执行完成，Redisson 也不会给锁续期，也就是看门狗机制此时不会生效。 尝试获取锁，阻塞等待，但不能超过指定的最大等待时间，且上锁以后 10 秒自动解锁 12345678910111213141516171819202122232425@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void rLock() throws InterruptedException { // 获取可重入锁 RLock lock = redissonClient.getLock(\"rLock\"); // 尝试加锁，最多等待100秒，上锁以后10秒自动解锁 boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS); if (res) { try { System.out.println(\"==&gt; success to get locker\"); Thread.sleep(5000); } finally { // 解锁 lock.unlock(); } } }} 特别注意 调用 RLock.tryLock(100, 10, TimeUnit.SECONDS) 方法加锁时，设置自动解锁的时间必须大于业务的执行时间。 调用 RLock.tryLock(100, 10, TimeUnit.SECONDS) 方法加锁时，在锁时间到了以后，即使业务未执行完成，Redisson 也不会给锁续期，也就是看门狗机制此时不会生效。 读写锁 (ReadWriteLock)基于 Redis 的 Redisson 分布式可重入读写锁 RReadWriteLock 实现了 java.util.concurrent.locks.ReadWriteLock 接口，其中读锁和写锁都继承了 RLock 接口。分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。 读写锁的特性 读 + 读：相当于无锁，支持并发读 写 + 读：读操作需要等待写操作完成 读 + 写：写操作需要等待读操作完成 写 + 写：互斥，需要等待对方的锁释放 简而言之，只要有写锁存在，则其他操作都必须阻塞等待 单元测试代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; /** * 缓存（非线程安全） */ public static final Map&lt;String, String&gt; CACHES = new HashMap&lt;&gt;(); /** * 写入数据 */ private String writeValue() { // 获取写锁 RReadWriteLock rwLock = redissonClient.getReadWriteLock(\"rw-lock\"); RLock writeLock = rwLock.writeLock(); String uuid = UUID.randomUUID().toString(); try { // 加写锁 writeLock.lock(); Thread.sleep(8000); CACHES.put(\"uuid\", uuid); System.out.println(\"==&gt; write uuid : \" + uuid); } catch (Exception e) { e.printStackTrace(); } finally { // 解写锁 writeLock.unlock(); } return uuid; } /** * 读取数据 */ private String readValue() { // 获取读锁 RReadWriteLock rwLock = redissonClient.getReadWriteLock(\"rw-lock\"); RLock readLock = rwLock.readLock(); String uuid = null; try { // 加读锁 readLock.lock(); uuid = CACHES.get(\"uuid\"); System.out.println(\"==&gt; read uuid : \" + uuid); } catch (Exception e) { e.printStackTrace(); } finally { // 解读锁 readLock.unlock(); } return uuid; } @Test public void readWriteLock() throws Exception { // 写操作 new Thread(this::writeValue).start(); Thread.sleep(500); // 读操作（会阻塞等待写操作完成才执行） new Thread(this::readValue).start(); System.in.read(); } } 单元测试结果 12==&gt; write uuid : 7d611f3a-2437-413d-b1aa-4041decc344e==&gt; read uuid : 7d611f3a-2437-413d-b1aa-4041decc344e 提示 读锁是一个共享锁，支持并发地执行读操作。 写锁是一个排他锁（互斥锁），可防止并发地执行写操作。 使用读写锁，可以保证读到的数据永远是最新的；只要写锁没有释放掉，那么拥有读锁的操作就会一直阻塞等待，直至写锁被释放。 闭锁 (CountDownLatch)基于 Redis 的 Redisson 分布式闭锁 RCountDownLatch 采用了与 java.util.concurrent.CountDownLatch 相似的接口和用法。闭锁适用于等待一个多线程的操作，也就是等待 N 个线程把所有业务执行完毕后，再处理一个业务。关于闭锁的使用场景，可以想象一下公司的门卫如何等所有员工下班后再关门。公司一共有五名员工，门卫需要等这五名员工下班后，才能关闭大门。 闭锁的使用场景 闭锁可以延迟线程的进度直到其到达终止状态，闭锁可以用来确保某些活动直到其他活动都完成才继续执行： a) 确保某个计算在其需要的所有资源都被初始化之后才继续执行 b) 确保某个服务在其他依赖的所有其他服务都已经启动之后才启动 c) 等待直到某个操作所有参与者都准备就绪再继续执行 单元测试代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; /** * 门卫关门 */ public void lockDoor() { RCountDownLatch countDownLatch = redissonClient.getCountDownLatch(\"countDownLatch\"); // 设置总共有5个员工 countDownLatch.trySetCount(5); try { // 门卫等待所有员工下班 countDownLatch.await(); System.out.println(\"==&gt; 门卫关门成功\"); } catch (InterruptedException e) { e.printStackTrace(); } } /** * 员工下班 */ public void offWork(long num) { RCountDownLatch countDownLatch = redissonClient.getCountDownLatch(\"countDownLatch\"); // 未下班的员工计数减一 countDownLatch.countDown(); System.out.println(\"==&gt; \" + num + \" 号员工下班\"); } @Test public void countDownLatch() throws Exception { // 模拟门卫关门 new Thread(this::lockDoor).start(); Thread.sleep(1000); // 模拟5个员工下班 for (int i = 0; i &lt; 5; i++) { new Thread(() -&gt; { offWork(Thread.currentThread().getId()); }).start(); } System.in.read(); } } 单元测试结果 123456==&gt; 113 号员工下班==&gt; 112 号员工下班==&gt; 114 号员工下班==&gt; 115 号员工下班==&gt; 116 号员工下班==&gt; 门卫关门成功 信号量 (Semaphore)基于 Redis 的 Redisson 的分布式信号量 RSemaphore 采用了与 java.util.concurrent.Semaphore 相似的接口和用法，同时还提供了异步（Async）、反射式（Reactive）和 RxJava2 标准的接口。关于信号量的使用场景，可以想象一下平时停车场如何停车。一共有十辆车准备停车，停车位有五个，当五个停车位满了后，其他车只能等有车位空出来才能停车。可以把停车位比作信号，现在有五个信号，停一次车，用掉一个信号，车离开就是释放一个信号。值得一提的是，RSemaphore 可用于实现分布式限流。RSemaphore 的原理图如下。 单元测试代码 123456789101112131415161718192021222324252627282930313233343536@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void semaphore() throws IOException { // 获取信号量 RSemaphore semaphore = redissonClient.getSemaphore(\"semaphore\"); // 设置许可数量，模拟五个停车位 semaphore.trySetPermits(5); // 创建10个线程，模拟10辆车过来停车 ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.submit(() -&gt; { try { // 占用信号（停车位） semaphore.acquire(); Thread.sleep(1000); System.out.println(\"==&gt; 车辆 \" + Thread.currentThread().getId() + \" 进入停车场\"); } catch (Exception e) { e.printStackTrace(); } finally { // 释放信号（停车位） semaphore.release(); System.out.println(\"==&gt; 车辆 \" + Thread.currentThread().getId() + \" 离开停车场\"); } }); } System.in.read(); } } 单元测试结果 1234567891011121314151617181920==&gt; 车辆 113 进入停车场==&gt; 车辆 110 进入停车场==&gt; 车辆 109 进入停车场==&gt; 车辆 111 进入停车场==&gt; 车辆 108 进入停车场==&gt; 车辆 108 离开停车场==&gt; 车辆 109 离开停车场==&gt; 车辆 110 离开停车场==&gt; 车辆 111 离开停车场==&gt; 车辆 113 离开停车场==&gt; 车辆 112 进入停车场==&gt; 车辆 117 进入停车场==&gt; 车辆 114 进入停车场==&gt; 车辆 116 进入停车场==&gt; 车辆 116 离开停车场==&gt; 车辆 114 离开停车场==&gt; 车辆 112 离开停车场==&gt; 车辆 117 离开停车场==&gt; 车辆 115 进入停车场==&gt; 车辆 115 离开停车场 可过期性信号量 (PermitExpirableSemaphore)基于 Redis 的 Redisson 可过期性信号量 RPermitExpirableSemaphore 是在 RSemaphore 对象的基础上，为每个信号增加了一个过期时间。每个信号可以通过独立的 ID 来辨识，释放时只能通过提交这个 ID 才能释放。它提供了异步（Async）、反射式（Reactive）和 RxJava2 标准的接口。 单元测试代码 12345678910111213141516171819202122232425262728293031323334353637@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void expirableSemaphore() throws IOException { // 获取可过期性信号量 RPermitExpirableSemaphore semaphore = redissonClient.getPermitExpirableSemaphore(\"expirable-semaphore\"); // 设置许可数量，模拟五个停车位 semaphore.trySetPermits(5); // 创建10个线程，模拟10辆车过来停车 for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { // 信号的 ID 标识 String permitId = null; try { // 占用信号量（停车位），有效期只有5秒 permitId = semaphore.acquire(5, TimeUnit.SECONDS); Thread.sleep(1000); System.out.println(\"==&gt; 车辆 \" + Thread.currentThread().getId() + \" 进入停车场\"); } catch (Exception e) { e.printStackTrace(); } finally { // 释放信号量（停车位） semaphore.release(permitId); System.out.println(\"==&gt; 车辆 \" + Thread.currentThread().getId() + \" 离开停车场\"); } }).start(); } System.in.read(); } } 单元测试结果 1234567891011121314151617181920==&gt; 车辆 115 进入停车场==&gt; 车辆 109 进入停车场==&gt; 车辆 112 进入停车场==&gt; 车辆 111 进入停车场==&gt; 车辆 113 进入停车场==&gt; 车辆 113 离开停车场==&gt; 车辆 115 离开停车场==&gt; 车辆 111 离开停车场==&gt; 车辆 109 离开停车场==&gt; 车辆 112 离开停车场==&gt; 车辆 110 进入停车场==&gt; 车辆 114 进入停车场==&gt; 车辆 108 进入停车场==&gt; 车辆 106 进入停车场==&gt; 车辆 114 离开停车场==&gt; 车辆 108 离开停车场==&gt; 车辆 106 离开停车场==&gt; 车辆 110 离开停车场==&gt; 车辆 107 进入停车场==&gt; 车辆 107 离开停车场 SpringBoot 整合 Redisson引入 Maven 依赖12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.19.0&lt;/version&gt;&lt;/dependency&gt; 添加 YML 配置信息 配置 Redis 的连接信息，包括主机地址、端口、密码等信息。 1234567spring: redis: host: 127.0.0.1 port: 6379 password: 123456 database: 0 timeout: 5000 创建 Redission 配置类 创建 Redission 配置类，用于定义 Redission 的客户端。 12345678910111213141516171819202122232425import org.redisson.Redisson;import org.redisson.api.RedissonClient;import org.redisson.config.Config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.data.redis.RedisProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RedisssonConfig { @Autowired private RedisProperties redisProperties; @Bean(destroyMethod = \"shutdown\") public RedissonClient redissonClient() { String password = redisProperties.getPassword(); String url = String.format(\"redis://%s:%s\", redisProperties.getHost() + \"\", redisProperties.getPort() + \"\"); Config config = new Config(); config.useSingleServer().setAddress(url).setPassword(password); return Redisson.create(config); } } 单元测试代码12345678910111213141516171819202122232425@SpringBootTestpublic class RedissonTest { @Autowired private RedissonClient redissonClient; @Test public void rLock() throws InterruptedException { // 获取可重入锁 RLock lock = redissonClient.getLock(\"rLock\"); // 阻塞等待，直至获取到锁 lock.lock(); try { System.out.println(\"==&gt; success to get locker\"); Thread.sleep(5000); } catch (Exception e) { e.printStackTrace(); } finally { // 解锁 lock.unlock(); } }} 参考博客 分布式锁中的王者方案 - Redisson Redis 分布式锁：关于使用 Redlock 算法的官方说明 (中文版) Redis 分布式锁：关于使用 Redlock 算法的官方说明 (英文版) var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 缓存"},{"title":"Redis 分布式锁中 Lua 脚本的使用","url":"/posts/51ce4ef9.html","text":"Lua 简介从 Redis 2.6.0 版本开始，通过内置的 Lua 解释器，可以使用 EVAL 命令对 Lua 脚本进行求值。Redis 使用单个 Lua 解释器去运行所有脚本，并且 Redis 也保证脚本会以原子性 (atomic) 的方式执行。当某个脚本正在运行的时候，不会有其他脚本或 Redis 命令被执行。这和使用 MULTI / EXEC 包围的事务很类似。在其他别的客户端看来，脚本的效果 (effect) 要么是不可见的 (not visible)，要么就是已完成的 (already completed)。在 Lua 脚本中，可以使用 redis.call () 函数来执行 Redis 命令。 Lua 在 Reids 中的使用方式​Redis 中内嵌了 Lua 脚本的解释器，并提供了执行 Lua 脚本的入口 eval 命令，格式为 eval script numkeys key [key ...] arg [arg...]。其中 eval 为命令，script 为执行的命令脚本，numkeys 为脚本中共涉及到的 key 的数量，后续接收若干个 key 的输入和若干个 arg 的输入。​在 Lua 脚本中使用 KEYS[index]， 和 ARGV[index] 来获取实际输入的参数，这有点类似于 SQL 的占位符。另外一层原因由于 Redis 集群的固有模式导致 EVAL 命令在集群中涉及多个 KEY 的操作时，要求所有的 KEY 都在同一个 Hash Solt 上。在集群环境中调用 EVAL 命令，Redis 会对脚本先做一个的校验。KEYS[1] KEYS[2] 是要操作的键，可以指定多个，在 Lua 脚本中可以通过 KEYS[1]、KEYS[2] 获取 Key 的值。特别注意，这些键要在 Redis 中存在，不然就获取不到对应的值。ARGV[1] ARGV[2] 参数在 Lua 脚本中可以通过 ARGV[1]、ARGV[2] 获取值。 Lua 脚本示例 下述的 Lua 脚本可以保证 Redis 删除 Key 这一操作的原子性。该脚本会先判断 Key 是否存在和 Key 的值是否匹配，若满足条件，则会删除对应的 Key。 123456if redis.call(\"get\", KEYS[1]) == ARGV[1]then return redis.call(\"del\", KEYS[1])else return 0end Redis 执行 Lua 脚本的保证Redis 可以保证对一个 Lua 脚本执行的完整性，也就是说一个 Lua 脚本的执行结果只会有成功和失败，且保证在 Redis Server 端同时只会有一个 Lua 脚本在运行，这样就意味着 Lua 脚本中的操作是一个完整的原子操作，不会伴随中间状态和资源竞争，同时也意味着在 Lua 脚本中不适合进行一些耗时较长的操作。由于有以上的保证，使用 Redis 来进行一些复杂的原子操作就再合适不过了，setnx 与 setex 命令的局限性也被 Redis Lua 进行了弥补。Redis 对嵌入的 Lua 做了若干的限制，可以保证脚本不对 Redis 造成破坏。不提供访问系统状态的库，禁止使用 loadfile 函数，禁止带有随机性质的命令或者带有副作用的命令，对随机读命令的结果进行排序，替换 math 原有的 random 方法，不允许定义函数，不允许声明全局变量等。 Lua 脚本调用 Redis 命令在 Lua 脚本中，可以使用 redis.call() 函数调用 Redis 的命令，示例代码如下。redis.call() 函数的返回值就是 Redis 命令的执行结果。Redis 命令的返回值有 5 种类型，redis.call() 函数会将这 5 种类型的返回值转换成对应的 Lua 数据类型。 12345-- Set Keyredis.call('set', 'foo', 'bar')-- Get Keylocal value = redis.call('get', 'foo') Redis 分布式锁实现 分布锁一般需要满足两个条件，一个是加拥有过期时间的锁，一个是高性能解锁 解锁：需要采用 Lua 脚本，必须保证解锁操作的原子性 加锁：可以采用两种方式，但都必须保证加锁操作的原子性 第一种方式：在 Lua 脚本中，分别使用 Redis 命令 setnx 与 setex 设置 Key 和过期时间 第二种方式：直接使用 Redis 命令 set resource-key resource-value nx ex max-lock-time 原子性地设置 Key 和过期时间 思考 为什么不能直接使用 Redis 命令 setnx 与 setex 命令实现加锁操作，而是必须借助 Lua 脚本呢？ 当按照上面的流程图直接使用 Redis 命令 setnx 与 setex 实现加锁操作时，如果在 setnx 和 setex 这两个命令执行中间，万一发生网络抖动或者 Reids 服务器宕机了，那么 Key 将没有设置过期时间，也就是 Key 会永远存在；当后续解锁操作执行失败时，会导致其他请求永远获取不到锁。 由于 setnx 与 setex 命令是分步执行的，那么可以想办法将两步合成一步，将加锁操作放在同一个原子中执行即可： 第一种方案：使用 Lua 脚本，它可以保证 setnx 与 setex 命令执行的原子性 第二种方案：Redis 从 2.6 版本之后支持 setnx、setex 连用，也就是可以直接使用 set resource-key resource-value nx ex max-lock-time 命令实现原子性地加锁 基于 Lua 脚本，使用 setnx 与 setex 命令进行加锁的代码 123456789101112local lockKey = KEYS[1]local lockTime = KEYS[2]local lockValue = KEYS[3]local result_1 = redis.call('SETNX', lockKey, lockValue)if result_1 == 1then local result_2= redis.call('SETEX', lockKey, lockTime, lockValue) return result_2else return 'faild'end 基于 Lua 脚本解锁的代码 123456if redis.call(\"get\", KEYS[1]) == ARGV[1]then return redis.call(\"del\", KEYS[1])else return 0end 提示 在 Spring 项目中，可以直接使用 StringRedisTemplate 实例对象调用 Lua 脚本，只需传入 Lua 脚本的 key 和 arg 参数即可，详细教程请点击 这里。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 缓存"},{"title":"Java 缓存与分布式锁","url":"/posts/150bedf.html","text":"缓存缓存使用为了系统性能的提升，一般都会将部分数据放入缓存中，加快业务服务的处理速度，而数据库则承担数据落盘的工作。 哪些数据适合放入缓存？ 即时性、数据一致性要求不高的数据 访问量大且更新频率不高的数据（读多写少） 比如在电商类应用中，商品分类，商品列表等数据适合缓存，并加一个失效时间 (根据数据更新频率来决定)，后台如果发布一个商品，买家需要 5 分钟后才能看到新的商品，这一般还是可以接受的。 缓存读模式的使用流程图如下 特别注意 在开发中，凡是放入缓存中的数据都应该指定过期时间，使其可以在系统即使没有主动更新数据的情况下，也能自动触发数据加载进缓存的流程。避免出现业务崩溃导致的数据永久不一致问题。 SpringBoot 整合 Redis Maven 引入 SpringBoot 的 Redis Starter 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot 2.0 以后默认使用的 Redis 客户端是 Lettuce，若希望使用 Jedis 作为客户端（不推荐），可以使用以下 Maven 配置信息 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; 堆外内存溢出 对 Lettuce 进行压力测试时，可能会出现 io.netty.util.internal.OutOfDirectMemoryError 的错误，即产生了堆外内存溢出。主要原因是 SpringBoot 2.0 以后默认使用 Lettuce 作为操作 Redis 的客户端，它是基于 Netty 进行网络通信，而由于旧版 Lettuce 自身的 Bug 导致一些使用过的内存没有被及时清理掉，因此最终会出现内存溢出的问题。解决方案有两种：一是升级 Lettuce 的版本，而是使用 Jedis 作为 Redis 的客户端。 配置 Redis 的连接信息，在 application.yml 配置文件中添加以下内容 12345spring: redis: port: 6379 host: 192.168.56.103 password: 123456 简单使用 RedisTemplate 类操作 Redis 12345678910@Autowiredpublic StringRedisTemplate stringRedisTemplate;@Testpublic void testStringRedisTemplate() { ValueOperations&lt;String, String&gt; ops = stringRedisTemplate.opsForValue(); ops.set(\"hello\", \"world_\" + UUID.randomUUID().toString()); String hello = ops.get(\"hello\"); System.out.println(hello);} 缓存失效问题在高并发的业务场景下，缓存失效一般分为几种情况，包括 缓存穿透、缓存雪崩、缓存击穿。 缓存穿透缓存穿透是指查询一个不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，因此没有将这次查询的 Null 结果写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大的时候，数据库可能就会被压垮，要是有人恶意利用不存在的 Key 频繁攻击应用服务，这就存在安全漏洞。为了解决缓存穿透的问题，当数据库查询不到数据时，可以将空结果写入缓存，并设置较短的过期时间。 缓存雪崩缓存雪崩是指在设置缓存时，采用了相同的过期时间，导致大量缓存在某一时刻同时失效，外部请求全部转发到数据库，而数据库由于瞬时压力过重导致雪崩。为了解决缓存雪崩问题，可以在原有的缓存失效时间基础上增加一个随机值，比如 1 ~ 5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，进而很难引发缓存集体失效的事件。 缓存击穿对于一些设置了过期时间的 Key，如果这些 Key 可能会在某些时间点被超高并发地访问，也就是一种非常 热点 的数据。那么在这个时候，需要考虑一个问题，如果这个 Key 在大量请求同时进来前刚好失效，那么所有对这个 Key 的数据查询都会落到数据库，这种现象一般称为 缓存击穿。为了解决缓存击穿的问题，可以通过加锁（分布式锁）来限制对数据库的访问。除了加锁之外，还可以使用 Cananl 数据库中间件来解决缓存击穿问题。` 缓存数据一致性更新缓存数据时，一般有两种模式（统称写模式），分别是 双写模式 与 失效模式，这两种写模式都存在缓存数据一致性问题（即可能会读取到脏数据）。 双写模式双写模式 是指先将数据写入数据库，然后再写入缓存。在 双写模式 下，读到的数据可能会不是最新的（存在延迟），同时还可能会读取到暂时性的脏数据，图解说明如下。值得一提的是，双写模式 属于 最终一致性 的一类。 脏数据问题分析 如上图，线程 A 和 B 都去写数据库，正常情况下应该是，A 先写数据库先写缓存，B 后写数据库后写缓存；但是由于卡顿等原因，导致写缓存 2 在最前，写缓存 1 在后面就出现了不一致，出现了脏数据；但是这是暂时性的脏数据问题，在数据稳定和缓存过期以后，又能得到最新的正确数据。若希望从根本上解决脏数据的问题，可以使用分布式锁（读写锁），也就是写数据库和写缓存这两个操作（两者可以是看做是一个操作）需要获取到锁才能执行，但是加了分布式锁以后，系统的整体性能会下降。另外，也可以使用 Canal 中间件来解决缓存的一致性问题。 失效模式失效模式 是指写完数据库，不用写缓存，而是删除缓存；等有请求进来读数据的时候，发现缓存中没有数据，就会主动查询数据库，并将查询结果放到缓存里面，这也叫 触发主动更新。值得一提的是，失效模式 也存在读取到脏数据的问题，如下图所示。 缓存一致性解决方案总结无论是双写模式还是失效模式，都会导致缓存数据与数据库数据不一致的问题，即多个实例同时更新时会出事，那么怎么办呢？ 缓存数据 + 过期时间的配合使用，也足够解决大部分业务对于缓存的要求。 如果是用户纬度数据 (订单数据、用户数据)，这种数据并发更新的几率非常小，可以不用考虑一致性问题，缓存数据加上过期时间，每隔一段时间自动触发读的主动更新即可。 如果是菜单列表、商品介绍等基础数据，也可以使用 Canal 中间件订阅数据库 binlog 的方式来更新缓存。 通过加分布式锁来保证并发读写的准确性，写 + 写 的时候按顺序排好队执行，读 + 读 则无所谓，所以适合使用分布式读写锁（如果业务不关心脏数据，允许临时的脏数据存在，则可以不使用分布式锁）。 总结 能放入缓存的数据本就不应该是实时性、一致性要求超高的，所以缓存数据的时候加上过期时间，保证每天拿到当前最新的数据即可 遇到实时性、一致性要求高的数据，就应该直接查询数据库，即使效率慢一点。 系统不应该过度设计，否则会增加系统的复杂性。 使用 Canal 解决一致性问题使用 Canal 数据库中间件，可以从根本上解决缓存一致性的问题，但会增加系统的复杂性，整理的工作流程图如下： 本地锁与分布式锁本地锁本地锁，如使用 JDK 的 synchronized 关键字或者 JUC 包下的 Lock 类等。本地锁只能锁住当前的 Java 进程，并不适用于分布式的业务场景。 注意 使用本地锁操作缓存时，需要注意锁的时序问题，即查询数据库与写入缓存这两者必须是原子操作，点击查看详细的图解说明。 分布式锁分布式锁，如使用 Redisson 第三方库提供的各种锁。分布式锁可以简单理解为同时去一个地方 占坑，如果占到，就执行业务逻辑，否则就必须等待，直到占到锁为止。占坑 可以去 Redis，也可以去数据库。等待过程可以是使用自旋的方式。 Redis 分布式锁的实现这里将介绍如何使用 Redis 实现分布式锁，更多内容建议参考 Reids 官方中文文档。 实现命令 set resource-key resource-value nx ex max-lock-time：设置 key 和设置过期时间，属于原子命令 例如： set sku 56a4e5e-a022 nx ex 300，其中的 key 是 sku，value 是 56a4e5e-a022，过期时间是 300 （单位是秒），设置成功会返回 OK，否则返回 Nil 实现流程 核心问题使用 Redis 实现分布式锁，最重要的是锁要有过期时间，不然万一业务代码抛出异常或者 Redis 宕机，Redis 锁将永远得不到释放，进而出现 死锁，导致其他线程一直获取不到资源。为了避免这种情况的发生，就必须保证执行加锁时，设置 Key 与设置过期时间这两者执行的原子性。值得一提的是，在解锁的时候，也必须保证判断 Key 是否存在与删除 Key 这两者执行的原子性。 Redis 实现分布式锁的核心内容 加锁原子性：通过 Redis 自身的 setnxex 命令加锁 解锁原子性：通过 Redis + Lua 脚本实现解锁，不能直接使用 DEL 命令删除锁 执行解锁时，必须确保解锁的是自己加的锁 代码实现 在项目的 resources 目录下创建 lua 目录，并且创建 redisLock.lua 文件，用于保证解锁操作的原子性 123456if redis.call(\"get\", KEYS[1]) == ARGV[1]then return redis.call(\"del\", KEYS[1])else return 0end 提示 更多关于 Redis 分布式锁中 Lua 脚本的使用教程，请点击 这里。 引入 Maven 坐标 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Lua 脚本的配置类 12345678910111213141516171819@Configurationpublic class RedisLuaConfig { @Resource private StringRedisTemplate stringRedisTemplate; /** * 删除锁 */ public boolean deleteLock(String lockKey, String value) { List&lt;String&gt; keyList = Collections.singletonList(lockKey); DefaultRedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(\"lua/redisLock.lua\"))); redisScript.setResultType(Long.class); Long result = stringRedisTemplate.execute(redisScript, keyList, value); return 1 == result; } } Redis 分布式锁的服务类 123456789101112131415161718192021222324@Servicepublic class RedisLockService { @Resource private RedisLuaConfig redisLuaConfig; @Resource private StringRedisTemplate stringRedisTemplate; /** * 加锁（原子操作） */ public boolean lock(String lockKey, String value, long time, TimeUnit timeUnit) { return stringRedisTemplate.opsForValue().setIfAbsent(lockKey, value, time, timeUnit); } /** * 解锁（原子操作） */ public boolean unlock(String lockKey, String value) { return redisLuaConfig.deleteLock(lockKey, value); } } 单元测试 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@SpringBootTestpublic class RedisLockTest { @Autowired private RedisLockService lockService; /** * 加锁/解锁 */ private void reduceSku() throws Exception { // 锁的唯一标识，用于保证解锁的是当前线程自己加的锁 String value = UUID.randomUUID().toString(); // 加锁 + 设置锁的过期时间，必须是原子操作 boolean lock = lockService.lock(\"lock\", value, 10, TimeUnit.SECONDS); if (lock) { System.out.println(\"==&gt; 加锁成功\"); // 模拟业务执行的耗时 TimeUnit.SECONDS.sleep(8); // 解锁，必须满足原子性，通过 Redis + Lua 脚本实现 boolean unlock = lockService.unlock(\"lock\", value); System.out.println(\"==&gt; 解锁\" + (unlock ? \"成功\": \"失败\")); } else { System.out.println(\"==&gt; 加锁失败\"); } } /** * 并发测试 */ @Test public void multiThreadLock() throws Exception { for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { reduceSku(); } catch (Exception e) { e.printStackTrace(); } }).start(); } System.in.read(); } } 测试结果 1234567891011==&gt; 加锁成功==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 加锁失败==&gt; 解锁成功 总结 为了防止持有过期锁的客户端误删现有锁的情况出现，可以使用以下方案改进 a) 不使用固定的字符串作为键的值，而是设置一个不可猜测（如 UUID）的长随机字符串作为口令串（token）。 b) 不使用 DEL 命令来解锁，而是发送一个 Lua 脚本，这个脚本只在客户端传入的值与口令串相匹配时，才对键进行删除。 Redisson 分布式锁的使用上面介绍的方式并不推荐用来实现 Redis 分布式锁。Redis 官方推荐参考 the Redlock algorithm 的实现，因为这种方法只是复杂一点，但是却能保证更好的使用效果。其中，基于 Java 语言开发的分布式锁的框架就是 Redisson。 Redisson 基础使用教程 Redisson 的使用请阅读 Redisson 分布式锁使用教程。 参考博客 Redis set NX EX 命令介绍 Redis 分布式锁中 Lua 脚本的使用 Redis 基于 setnx、setex 连用实现分布式锁 Redis 基于通过 setnxex (互斥锁) 实现分布式锁 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java 缓存"},{"title":"Linux 管理 Crontab 服务","url":"/posts/vbd8mmaf.html","text":"前言 本文主要介绍如何在 Linux 系统上安装和管理 Crontab 服务，适用于 Debian 9、CentOS 7 系统。 Crontab 安装Crontab 安装（CentOS 7）1# yum instal crontabs Crontab 安装（Debian 9）1# apt-get install cron Crontab 服务管理Crontab 服务管理（CentOS 7）1234567891011# 启动Crontab服务# systemctl start crond# 关闭Crontab服务# systemctl stop crond# 重启Crontab服务# systemctl restart crond# 查看Crontab服务的运行状态# systemctl status crond Crontab 服务管理（Debian 9）1234567891011121314151617# 启动Crontab服务# service cron start# 关闭Crontab服务# service cron stop# 重启Crontab服务# service cron restart# 查看Crontab服务的运行状态# service cron status# 或者使用以下命令替代# /etc/init.d/cron stop# /etc/init.d/cron start# /etc/init.d/cron status# /etc/init.d/cron restart Crontab 日志管理Crontab 日志管理（CentOS 7）12# 查看Crontab的日志信息# tail -f -n 10 /var/log/cron Crontab 日志管理（Debian 9）123456789101112131415# 安装rsyslog服务# apt-get install rsyslog# 创建Crontab的日志文件# touch /var/log/cron.log# 开启Crontab的日志记录# vim /etc/rsyslog.confcron.* /var/log/cron.log #取消这行内容的注释即可# 启动rsyslog服务# service rsyslog start# 查看Crontab的日志信息# tail -f -n 10 /var/log/cron.log Crontab 任务管理Crontab 任务管理（CentOS 7）12345678910111213141516171819# 编辑并保存当前用户的计划任务# crontab -e# 查看当前用户的所有计划任务# crontab -l# 提示：以下通过Vim编辑器更改配置文件的方式，不一定能让新增的Crontab计划任务生效# 编辑root用户的计划任务（依赖root用户的权限）# vim /var/spool/cron/root# 查看root用户的计划任务（依赖root用户的权限）# cat /var/spool/cron/root# 编辑www用户的计划任务（依赖root或者www用户的权限）# vim /var/spool/cron/www# 查看www用户的计划任务（依赖root或者www用户的权限）# cat /var/spool/cron/www Crontab 任务管理（Debian 9）12345678910111213141516171819# 编辑并保存当前用户的计划任务# crontab -e# 查看当前用户的所有计划任务# crontab -l# 提示：以下通过Vim编辑器更改配置文件的方式，不一定能让新增的Crontab计划任务生效# 编辑root用户的计划任务（依赖root用户的权限）# vim /var/spool/cron/crontabs/root# 查看root用户的计划任务（依赖root用户的权限）# cat /var/spool/cron/crontabs/root# 编辑www用户的计划任务（依赖root或者www用户的权限）# vim /var/spool/cron/crontabs/www# 查看www用户的计划任务（依赖root或者www用户的权限）# cat /var/spool/cron/crontabs/www Shell 脚本添加 Crontab 计划任务12# 添加系统级的计划任务，依赖root用户的权限，同时需要指定以哪个用户来执行计划任务，此方法适用于绝大多数的Linux发行版# echo \"0 */2 * * * root /usr/bin/python3 /usr/share/python_scripts/mysql-sync.py\" &gt;&gt; /etc/crontab Crontab 的使用命令格式crontab [-u user] file crontab [-u user] [ -e | -l | -r ] -u user：用来设置某个用户的 Crontab 服务 file：命令文件的名称，表示将 file 作为 Crontab 的任务列表文件并载入 Crontab -e：编辑某个用户的 Crontab 配置文件内容。如果不指定用户，则表示编辑当前用户的 Crontab 配置文件 -l：显示某个用户的 Crontab 配置文件内容，如果不指定用户，则表示显示当前用户的 Crontab 配置文件内容 -r：从 /var/spool/cron 目录中删除某个用户的 Crontab 配置文件，如果不指定用户，则默认删除当前用户的 Crontab 配置文件 Crontab 使用格式 第 1 列：分钟 0～59 第 2 列：小时 0～23 第 3 列：日 1～31 第 4 列：月 1～12 第 5 列：星期 0～7 (0 和 7 表示星期天) 第 6 列：需要执行的命令 Crontab 使用案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 每5秒执行一次0/5 * * * * command# 每一小时执行一次0 */1 * * * command# 每天6点执行一次0 6 * * * command# 每天7:50执行一次50 7 * * * command# 每隔45分钟执行一次*/45 * * * * command# 在12月内，每天6点到12点，每隔3个小时0分钟执行一次0 6-12/3 * 12 * command# 每小时的第3和第15分钟执行3,15 * * * * command# 在上午8点到11点的第3和第15分钟执行3,15 8-11 * * * command# 每隔两天的上午8点到11点的第3和第15分钟执行3,15 8-11 */2 * * command# 每周一上午8点到11点的第3和第15分钟执行3,15 8-11 * * 1 command# 每晚的21:30执行30 21 * * * command# 每月1、10、22日的4:45执行45 4 1,10,22 * * command# 每周六、周日的01:10执行10 1 * * 6,0 command# 每天18:00至23:00之间每隔30分钟执行0,30 18-23 * * * command# 每星期六的晚上23:00执行0 23 * * 6 command# 晚上11点到早上7点之间，每隔一小时执行0 23-7 * * * command Docker 构建 Crontab 镜像警告 这里不建议使用 CentOS 镜像，因为 Docker 的官方 CentOS 镜像中没有提供 systemd 服务，虽然有对应的 解决方案，但解决起来稍微复杂了一点 如果基于 CentOS 镜像构建 Crontab 镜像，启动容器时往往会出现错误信息： Failed to get D-Bus connection: Operation not permitted，更多资料可参考 这里 用于构建 Crontab 镜像的 Dockerfile 的内容如下，基于 Debian 9（Stretch）系统 1234567891011121314151617181920212223242526272829303132333435from augurproject/python2-and-3MAINTAINER clay&lt;clay@gmail.com&gt;RUN touch /var/log/cron.logRUN mkdir -p /usr/share/python_scriptsENV workpath /usr/share/python_scriptsWORKDIR $workpathRUN echo \"Asia/Shanghai\" &gt; /etc/timezoneRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN cp /etc/apt/sources.list /etc/apt/backup.sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN echo \"deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib\" &gt;&gt; /etc/apt/sources.listRUN apt-get -y update &amp;&amp; apt-get -y upgradeRUN apt-get -y install cron rsyslog apt-utils net-tools telnet wget curl vimRUN apt-get -y autoclean &amp;&amp; apt-get -y autoremoveRUN sed -i \"s/#cron./cron./g\" /etc/rsyslog.confRUN echo \"0 */2 * * * root /usr/bin/python3 /usr/share/python_scripts/mysql-sync.py\" &gt;&gt; /etc/crontabRUN echo \"59 23 * * * root /usr/bin/python2 /usr/share/python_scripts/mysql-check.py\" &gt;&gt; /etc/crontabCMD service rsyslog start &amp;&amp; service cron start &amp;&amp; tail -f -n 20 /var/log/cron.log 将上面的内容保存到 Dockerfile-Crontab 文件中，然后使用以下命令构建 Crontab 镜像 1# docker build -f Dockerfile-Crontab -t clay/crontab:1.0 . 使用 Docker-Compose 来管理 Crontab 镜像，其中 Docker-Compose 的配置文件内容如下 12345678910version: \"3.5\"services: crontab: image: clay/crontab:1.0 container_name: crontab volumes: - /usr/local/python_scripts:/usr/share/python_scripts restart: always network_mode: bridge 创建并后台启动 Crontab 容器 1# docker-compose up -d Crontab 命令在线生成工具 Crontab Generator 参考资料 Linux 中的 Crontab 定时任务 Crontab 定时任务不执行的一些原因总结 使用 Shell 脚本或命令行添加 Crontab 定时任务 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux"},{"title":"Centos7 安装 ExpressVPN 客户端","url":"/posts/4d31c632.html","text":"前言ExpressVPN 介绍 ExpressVPN 官网 ExpressVPN 的优势 ExpressVPN 支持的路由器型号 ExpressVPN 支持的所有设备类型 ExpressVPN 支持同一个账号最多 5 个设备同时使用 ExpressVPN 如何支持 5 个以上的设备同时使用一个账号 快速入门ExpressVPN 客户端安装在 ExpressVPN 官网下载 Fedora 64-bit 版的客户端，通过命令安装客户端 1# yum install expressvpn-3.4.2.4-1.x86_64.rpm 激活，只需要拷贝 ExpressVPN 的激活码到终端，然后按下回车键即可 1$ expressvpn activate 可以选择通过共享匿名诊断报告来帮助改进 ExpressVPN ，输入 Y 接受，或输入 n 拒绝 如果希望以后不再选择向 ExpressVPN 发送诊断报告，可以运行以下命令 1$ expressvpn preferences set send_diagnostics false ExpressVPN 客户端卸载1# yum remove expressvpn 值得一提的是，如果日后需要更新 ExpressVPN 的客户端，只需要先卸载旧版的客户端，然后再安装新版的客户端即可 ExpressVPN 客户端连接服务器连接 VPN 服务器，如果是第一次连接，ExpressVPN 将使用 “智能位置” 功能来选择服务器位置，这是根据速度和邻近性等因素推荐的。如果不是第一次连接，ExpressVPN 将连接到最近连接过的服务器位置 1$ expressvpn connect 默认情况下，如果成功连接到 VPN 服务器，在系统的通知面板里将看到一条指示 ExpressVPN 已连接的通知 当单个 ExpressVPN 账号超过 5 台设备同时使用时，终端会输出以下错误日志信息 验证是否可以正常连接到 VPN 服务器 1$ curl -I www.google.com 断开 VPN 连接，可使用以下命令 1$ expressvpn disconnect 进阶使用ExpressVPN 网速测试安装并使用 Speedtest CLI 工具来测试 ExpressVPN 的实际连接速度，也可以直接使用 Speedtest 的 Python 版 或者 Speedtest 的网页版进行测试。 123456789101112131415161718# 卸载其他版本的 Speedtest# rpm -qa | grep speedtest | xargs -I {} sudo yum -y remove {}# 安装 Speedtest# curl -s https://install.speedtest.net/app/cli/install.rpm.sh | sudo bash# yum install speedtest# 开始网速测试$ speedtest# 或者指定 Speedtest 的网速显示单位$ speedtest -u kB/s# 提示：Speedtest CLI 支持的单位如下：Decimal prefix, bits per second: bps, kbps, Mbps, GbpsDecimal prefix, bytes per second: B/s, kB/s, MB/s, GB/sBinary prefix, bits per second: kibps, Mibps, GibpsBinary prefix, bytes per second: kiB/s, MiB/s, GiB/s ExpressVPN 客户端常用管理命令12345678# 显示所有推荐的 VPN 服务器位置$ expressvpn list# 显示所有有效的 VPN 服务器位置$ expressvpn list all# 显示最近连接过的三个 VPN 服务器位置$ expressvpn list recent 12345# 连接到智能推荐的 VPN 服务器位置$ expressvpn connect smart# 连接到特定的 VPN 服务器位置$ expressvpn connect \"Hong Kong - 2\" 12345678# 设置 ExpressVPN 使用 TCP 作为 VPN 协议$ expressvpn protocol tcp# 设置 ExpressVPN 使用 UDP 作为 VPN 协议$ expressvpn protocol udp# 设置 ExpressVPN 自动选择 VPN 协议，包括 lightway_udp、tcp、udp 协议$ expressvpn protocol auto 12345# 设置 ExpressVPN 在启动时自动连接到上次连接过的 VPN 服务器位置$ expressvpn autoconnect true# 禁用 ExpressVPN 在启动时自动连接$ expressvpn autoconnect false 12345# 查看 ExpressVPN 当前的连接状态$ expressvpn status# 查看 ExpressVPN 的后台服务状态$ systemctl status expressvpn 12345678# 查看 ExpressVPN 当前的配置信息$ expressvpn preferences# 获取 ExpressVPN 特定的配置信息$ expressvpn preferences get desktop_notifications# 设置 ExpressVPN 特定的配置信息$ expressvpn preferences set desktop_notifications false 12# 查看 ExpressVPN 的命令帮助文档$ man expressvpn ExpressVPN Chrome 浏览器插件安装如果希望使用图形用户界面（GUI）来管理 ExpressVPN 的 Linux 客户端，则可以使用适用于 Chrome 的 ExpressVPN 浏览器插件来实现。在 Chrome 的应用商店里安装 ExpressVPN 插件，然后简单配置 Chrome 浏览器插件即可。特别注意，要使用 Chrome 的浏览器插件，需要确保已下载并激活 ExpressVPN 的 Linux 客户端。 高级使用ExpressVPN 使用建议 建议优先使用速度较快的 lightway_udp 协议，其次才是 tcp、udp 协议 Centos 7 安装 ExpressVPN 的客户端后，默认的 VPN 代理是系统全局代理 由于 ExpressVPN 的客户端是系统全局代理，因此不需要额外的配置就可以直接在 Centos 7 系统内的终端、浏览器使用 VPN 代理 由于 ExpressVPN 的客户端是系统全局代理，因此不需要额外的配置就可以直接让 Centos 7 系统内的所有用户直接使用 VPN 代理，包括终端、浏览器 ExpressVPN 客户端的默认配置项如下： 12345678auto_connect falsedesktop_notifications falsedisable_ipv6 trueforce_vpn_dns truelightway_cipher autonetwork_lock defaultpreferred_protocol autosend_diagnostics true Docker 安装 ExpressVPN 构建 Privoxy、Tor、ExpressVPN 的 Docker 镜像 Linux 实现国内外流量分流ExpressVPN 支持在 Windows、Mac、Android、Router 系统上使用隧道分流功能（即国内外流量分流），但不支持在 Linux 系统上使用隧道分流功能。在 Linux 环境下可以尝试通过 Docker + Privoxy + SwitchyOmega（Chrome 浏览器插件） 来实现隧道分流（如下图），Docker 负责运行 ExpressVPN 的服务，Privoxy 负责网络代理，SwitchyOmega 负责国内外流量分流。值得一提的是，使用该方案之后 ExpressVPN 的 Chrome 浏览器插件就无法正常使用了，此时需要从外部连接到 Docker 容器，然后在终端里使用命令行管理 ExpressVPN 的服务，亲测该方案有效。 官方教程与软件下载ExpressVPN 软件下载 ExpressVPN 的 Linux 客户端 ExpressVPN 的 Chrome 插件 ExpressVPN 的 Android 客户端 ExpressVPN 的 Windows 客户端 ExpressVPN 官方教程 Linux 配置 DNS 服务器 Linux 系统使用 ExpressVPN 路由器系统使用 ExpressVPN Windows 系统使用 ExpressVPN Windows、Mac 系统设置 ExpressVPN 隧道分流 参考资料 ExpressVPN 进阶使用教程 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"centos 开发工具"},{"title":"Spring Cloud Alibaba 综合集成架构演示案例","url":"/posts/7f5a87b2.html","text":"前言Spring Cloud 是一套较为全面的微服务框架集，集成了如服务注册发现、配置中心、消息总线、负载均衡、断路器、API 网关等功能实现。而在网上经常会发现 Spring Cloud 与阿里巴巴的 Dubbo 进行选择对比，这样做其实不是很妥当，前者是一套较为完整的微服务架构方案，而 Dubbo 只是服务治理与 RPC 实现方案。Dubbo 在国内有着非常大的用户群体，但是其周边设施与组件相对来说并不那么完善。很多开发者用户又很希望享受 Spring Cloud 的生态，因此也会有一些 Spring Cloud 与 Dubbo 一起使用的案例与方法出现，但是一直以来大部分 Spring Cloud 整合 Dubbo 的使用方案都不完善，直到 Spring Cloud Alibaba 的出现，才得以解决这样的问题。 问题延伸由于 Feign 是基于 HTTP Restful 的调用，在高并发下的性能不够理想，那么 RPC 方案能否切换为 Dubbo？Spring Cloud 与阿里系的若干组件能否完美集成呢？ 整体系统架构系统架构图 API 网关：系统统一入口，屏蔽架构内部结构，统一安全拦截，采用 Zuul 实现 Application-1：应用 1，模拟应用，提供 HTTP 接口服务给 API 网关调用（Feign） Service-1：微服务 1，模拟微服务，提供 Dubbo 接口服务给 Application-1 调用 Service-2：微服务 2，模拟微服务，提供 Dubbo 接口服务给 Application-1 调用 架构分层 接入层：API 网关 应用层：Application-1 微服务层：Service-1、Service-2 调用流程 所有访问系统的请求都要经过 API 网关，网关转发 HTTP 请求至 Application-1，然后 Application-1 使用 Dubbo 调用 Service-1 完成自身业务，最后 Sevice-1 使用 Dubbo 调用 Service-2 完成自身业务。至此，完成所有组件贯穿。 Application 与 Sevice 的区别 形成 Service 支撑 Application 的整体架构，增加多变的 Application 甚至不需要变动 Service Service 提供了基础服务功能，而 Application 组装基础服务功能，提供给用户直接可用的业务，适合快速迭代开发 Service 服务粒度小、功能基础，不易发生改变，而 Application 提供上游业务功能，紧贴业务需求，容易发生改变 Spring Cloud Alibaba 集成架构演示案例1.0、技术选型Spring Boot、Spring Cloud Zuul、Spring Cloud OpenFeign、Nacos、Dubbo 1.1、版本说明 Zuul 1.3.1 Dubbo 2.7.8 Nacos Server 1.4.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Dubbo 2.2.3.RELEASE Spring Cloud Alibaba Nacos Config 2.1.3.RELEASE Spring Cloud Alibaba Nacos Discovery 2.1.3.RELEASE 本案例中使用的各开源组件的版本如上，其中 Spring Cloud Alibaba Nacos Config 并没有真正发挥配置中心的作用，因为本文为了方便演示，并没有将 bootstrap.yml 配置文件里的部分配置信息发布到 Nacos Server（配置中心 + 注册中心），尤其是 api-gateway 工程里的路由映射配置，点击下载完整的案例代码。 1.2、工程结构采用 Maven 工程结构（如下），为了方便演示，各组件的开发顺序为： service-2 -&gt; service-1 -&gt; application-1 -&gt; api-gateway 123456789alibaba-micro-service-study 整体父工程├── api-gateway API 网关，端口：56010├── application-1 应用 1，端口：56020├── service-1 服务 1 父工程│&nbsp;&nbsp; ├── service-1-api 服务 1 API│&nbsp;&nbsp; ├── service-1-business 服务 1 业务实现，端口：56030└── service-2 服务 2 父工程 ├── service-2-api 服务 2 API └── services-2-business 服务 2 业务实现，端口：56040 1.3、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt;&lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;api-gateway&lt;/module&gt; &lt;module&gt;application-1&lt;/module&gt; &lt;module&gt;service-1&lt;/module&gt; &lt;module&gt;service-2&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-dubbo.version&gt;2.2.3.RELEASE&lt;/spring-cloud-dubbo.version&gt; &lt;spring-cloud-nacos.version&gt;2.1.3.RELEASE&lt;/spring-cloud-nacos.version&gt; &lt;/properties&gt; &lt;!-- 管理依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-dubbo.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 利用传递依赖，公共部分 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.4、创建 Service 2 工程Service 2 工程 的 Maven 配置如下： 1234567891011121314&lt;artifactId&gt;service-2&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;service-2-api&lt;/module&gt; &lt;module&gt;services-2-business&lt;/module&gt;&lt;/modules&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 1.4.1、创建 Service 2 API 工程Service 2 API 工程非常简单，只负责声明服务接口，没有具体的实现，Maven 配置如下： 123456789&lt;artifactId&gt;service-2-api&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 声明服务接口 123456public interface ProviderService { public String add(Integer a, Integer b); public String sub(Integer a, Integer b);} 1.4.2、创建 Service 2 Business 工程引入 service-2-api 依赖，由于需用使用 Dubbo 供 service-1 模块进行远程调用，因此需要引入 spring-cloud-starter-dubbo 依赖 1234567891011121314151617181920212223242526272829&lt;artifactId&gt;services-2-business&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class Service2Application { public static void main(String[] args) { SpringApplication.run(Service2Application.class, args); }} 创建具体的服务接口实现类，添加 @DubboService 注解标记此类的方法暴露为 Dubbo 接口 1234567891011121314151617181920/** * 使用 @DubboService 注解标记此类的方法暴露为Dubbo接口 */@DubboServicepublic class ProviderServiceImpl implements ProviderService { private Logger LOG = LoggerFactory.getLogger(ProviderServiceImpl.class); @Override public String add(Integer a, Integer b) { LOG.info(\"service 2 business invoke\"); return String.valueOf(a + b); } @Override public String sub(Integer a, Integer b) { LOG.info(\"service 2 business invoke\"); return String.valueOf(a - b); }} 添加 bootstrap.yml 配置文件，加入 Dubbo 相关的配置内容 1234567891011121314151617181920212223242526272829303132server: port: ${port:56040} servlet: context‐path: /service2spring: application: name: service2 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: scan: base-packages: com.alibaba.micro.study protocol: name: dubbo port: 20891 registry: address: nacos://127.0.0.1:8848 # 注册中心地址 application: qos-enable: false # Dubbo运维服务是否开启 consumer: check: false # 启动时就否检查依赖的服务 1.5、创建 Service 1 工程Service 1 工程 的 Maven 配置如下： 1234567891011121314&lt;artifactId&gt;service-1&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;service-1-api&lt;/module&gt; &lt;module&gt;service-1-business&lt;/module&gt;&lt;/modules&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 1.5.1、创建 Service 1 API 工程Service 1 API 工程非常简单，只负责声明服务接口，没有具体的实现，Maven 配置如下： 123456789&lt;artifactId&gt;service-1-api&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 声明服务接口 1234public interface ConsumerService { public String add(Integer a, Integer b);} 1.5.2、创建 Service 1 Business 工程引入 service-1-api、service-2-api 依赖，由于需用使用 Dubbo 调用 service-2-business 的服务实现，因此需要引入 spring-cloud-starter-dubbo 依赖 12345678910111213141516171819202122232425262728293031323334&lt;artifactId&gt;service-1-business&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class Service1Application { public static void main(String[] args) { SpringApplication.run(Service1Application.class, args); }} 创建具体的服务接口实现类，添加 @DubboService 注解标记此类的方法暴露为 Dubbo 接口，同时使用 @DubboReference 注解生成接口代理对象，然后通过代理对象进行远程调用 service-2 的服务 1234567891011121314151617181920/** * 使用 @DubboService 注解标记此类的方法暴露为Dubbo接口 */@DubboServicepublic class ConsumerServiceImpl implements ConsumerService { /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ProviderService providerService; private Logger LOG = LoggerFactory.getLogger(ConsumerServiceImpl.class); @Override public String add(Integer a, Integer b) { LOG.info(\"service 1 business invoke\"); return providerService.add(a, b); }} 添加 bootstrap.yml 配置文件，加入 Dubbo 相关的配置内容 1234567891011121314151617181920212223242526272829303132server: port: ${port:56030} servlet: context‐path: /service1spring: application: name: service1 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: scan: base-packages: com.alibaba.micro.study protocol: name: dubbo port: 20881 registry: address: nacos://127.0.0.1:8848 # 注册中心地址 application: qos-enable: false # Dubbo运维服务是否开启 consumer: check: false # 启动时就否检查依赖的服务 1.6、创建 Application 1 工程引入 service-1-api、service-2-api 依赖，由于需要使用 Dubbo 进行远程调用，因此还需要引入 spring-cloud-starter-dubbo 依赖 12345678910111213141516171819202122232425262728293031323334&lt;artifactId&gt;application-1&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-1-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;artifactId&gt;service-2-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ApplicationBootstrap { public static void main(String[] args) { SpringApplication.run(ApplicationBootstrap.class, args); }} 创建 Controller 测试类，暴露供第三方调用的 HTTP API，同时使用 @DubboReference 注解生成接口代理对象，然后通过代理对象进行远程调用 service-1、service-2 的服务 1234567891011121314151617181920212223242526272829@RestControllerpublic class ApplicationController { /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ConsumerService consumerService; /** * 生成接口代理对象，通过代理对象进行远程调用 */ @DubboReference private ProviderService providerService; private Logger LOG = LoggerFactory.getLogger(ApplicationController.class); @GetMapping(\"/add\") public String add(Integer a, Integer b) { LOG.info(\"application invoke\"); return consumerService.add(a, b); } @GetMapping(\"/sub\") public String sub(Integer a, Integer b) { LOG.info(\"application invoke\"); return providerService.sub(a, b); }} 添加 bootstrap.yml 配置文件，特别注意，这里并没有将 appplication-1 的任何 Dubbo 服务注册到 Nacos Server，只是单纯的作为 Dubbo 服务的消费者 1234567891011121314151617181920212223server: port: ${port:56020} servlet: context‐path: /application1spring: application: name: application1 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组dubbo: consumer: check: false # 启动时就否检查依赖的服务 1.7、创建 API 网关工程引入 Maven 依赖，由于使用了 Zuul 作为网关服务，因此需要引入 spring-cloud-starter-netflix-zuul 依赖，同时这里指定 Zuul 通过 Feign 将第三方的 HTTP 请求转发给 application-1 服务，还需要引入 spring-cloud-starter-openfeign 12345678910111213141516171819202122232425262728&lt;artifactId&gt;api-gateway&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;parent&gt; &lt;artifactId&gt;alibaba-micro-service-study&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba.micro.study&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient、@EnableZuulProxy 123456789@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxypublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 添加 bootstrap.yml 配置文件，由于路由的映射规则会经常发生改变，在生产环境中建议将下列 Zuul 相关的配置发布到 Nacos Server（配置中心 + 注册中心）中。为了演示方便，这里直接将 Zuul 的路由配置信息写在 bootstrap.yml 里。 12345678910111213141516171819202122232425server: port: ${port:56010} servlet: context‐path: /api-gatewayspring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 cluster-name: DEFAULT config: server-addr: 127.0.0.1:8848 file-extension: yaml namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 # 开发环境 group: NACOS_MICRO_SERVICE_GROUP # xxx业务组zuul: routes: application1: stripPrefix: false path: /application1/** 或者将 Zuul 的路由规则配置发布到 Nacos Server，而不是直接写在 bootstrap.yml 配置文件中，如下图所示： 1.8、测试应用代码 1）分别启动 service-2、service-1、application-1、api-gateway 应用 2）浏览器访问 http://127.0.0.1:56020/application1/sub?a=6&amp;b=2，若响应结果正确返回，则说明 service-2、application-1 服务运行正常 3）浏览器访问 http://127.0.0.1:56020/application1/add?a=3&amp;b=4，若响应结果正确返回，则说明 service-2、service-1、application-1 服务运行正常 4）浏览器访问 http://127.0.0.1:56010/api-gateway/application1/add?a=3&amp;b=4，若响应结果正确返回，则说明 service-2、service-1、application-1、api-gateway 服务运行正常 Nacos Server 的服务列表如下： 若希望测试各服务多实例的负载均衡调用情况，可以通过 -Dport=xxxxx VM 参数指定不同的端口来启动多个服务实例即可，这里不再累述 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"SpringBoot 读取 YML 配置文件的几种写法","url":"/posts/4c496bc8.html","text":"前言本文主要介绍 SpringBoot 读取 YML 配置文件的几种写法。 第一种写法添加 @Configuration 注解到 Bean 定义类，并使用 @Value 注解指定 YML 配置文件中的 Key。 123456shop: wechat: app-id: '' app-secret: '' encoding-token: '' encoding-aes-key: '' 1234567891011121314151617@Data@Configurationpublic class WechatProperties { @Value(\"${shop.wechat.app-id:}\") private String appId; @Value(\"${shop.wechat.app-secret:}\") private String appSecret; @Value(\"${shop.wechat.encoding-token:}\") private String encodingToken; @Value(\"${shop.wechat.encoding-aes-key:}\") private String encodingAesKey;} 第二种写法添加 @Configuration 和 @ConfigurationProperties 注解到 Bean 定义类，并使用 YML 配置文件中 Key 作为前缀。值得一提的是，这里即使不加 @Value 注解，SpringBoot 也会根据驼峰命名规则自动转换并匹配 Bean 定义类的属性名称。 123456shop: wechat: app-id: '' app-secret: '' encoding-token: '' encoding-aes-key: '' 1234567891011121314@Data@Configuration@ConfigurationProperties(prefix = \"shop.wechat\")public class WechatProperties { private String appId; private String appSecret; private String encodingToken; private String encodingAesKey;} 第三种方式添加 @Configuration 和 @ConfigurationProperties 注解到 Bean 定义类，并使用内部类和 YML 配置文件中 Key 作为前缀。值得一提的是，这里即使不加 @Value 注解，SpringBoot 也会根据驼峰命名规则自动转换并匹配 Bean 定义类的属性名称。 123456789shop: mail: 'example@gmail.com' wechat: app-id: '' app-secret: '' encoding-token: '' encoding-aes-key: '' security: web-allow-others: true 123456789101112131415161718192021222324252627282930@Data@Configuration@ConfigurationProperties(prefix = \"shop\")public class ShopProperties { private String mail; private final Wechat wechat = new Wechat(); private final Security security = new Security(); private static class Wechat { private String appId; private String appSecret; private String encodingToken; private String encodingAesKey; } public static class Security { private boolean webAllowOthers; }} 第四种方式添加 @ConfigurationProperties 和 @NestedConfigurationProperty 注解到 Bean 定义类，并使用 @EnableConfigurationProperties 注解对 Bean 定义类的属性进行绑定 12345678xxl: job: admin: addresses: '' executor: port: 9913 ip: '' address: '' 1234567891011@Data@ConfigurationProperties(prefix = \"xxl.job\")public class XxlJobProperties { @NestedConfigurationProperty private XxlAdminProperties admin = new XxlAdminProperties(); @NestedConfigurationProperty private XxlExecutorProperties executor = new XxlExecutorProperties();} 123456@Datapublic class XxlAdminProperties { private String addresses;} 12345678910@Datapublic class XxlExecutorProperties { private String ip; private Integer port; private String address;} 123456789@SpringBootApplication@EnableConfigurationProperties(XxlJobProperties.class)public class ShopApplication { public static void main(String[] args) { SpringApplication.run(ShopApplication.class, args); }} 参考资料 @ConfigurationProperties 使用详解 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java"},{"title":"不蒜子统计数据更改","url":"/posts/fc73f615.html","text":"前言由于不蒜子统计不对普通用户提供后台管理的功能，当站点的域名更换后，网站以前的所有统计数据都会重置为零。下面将介绍如何使用抓包工具来分析不蒜子统计的 API，进而实现不蒜子统计数据的更改。 Fiddler 下载这里使用了 Fiddler，它是一款流行的抓包工具，可以将网络传输发送与接受的数据包进行截获、重发、编辑、转存等操作。本质上，Fiddler 是通过改写 HTTP 代理，让数据从它那里通过，来监控并且截取到网络数据。 Fiddler 官网下载地址 ：https://www.telerik.com/download/fiddler Fiddler 离线下载地址：https://pan.baidu.com/s/1bpnp3Ef &nbsp;&nbsp;提取码：5skw 抓包分析1）启动 Fiddler 后，打开本地的浏览器访问博客的 URL，此时在 Fiddler 的界面上可以看到有关不蒜子的请求 1https://busuanzi.ibruce.info/busuanzi?jsonpCallback=BusuanziCallback_195655659654 2）观察请求的响应结果，可以发现其中包含了网站访问量的数据，不蒜子统计就是通过这个请求来统计网站的访问量，包括 site_pv、site_uv、page_pv 3）重新发送一条不蒜子请求，右击该请求，选择 Replay –&gt; Reissue Requests 4）查看请求响应的结果，发现 page_pv 和 site_pv 的值都递增了，在网页端查看也确实递增了 5）访客数 site_uv 的值，自然就是通过 Cookie 来实现了 6）Cookie 中有三条数据，尝试删除 busuanziId 后再次发送请求。首先选择 Replay –&gt; Reissue and Edit，在 Raw 选项里删去 Cookie 中的 busuanziId 这条数据，然后点击 Run to Completion 即可发送请求 7）从响应结果可以看到 site_uv 已经加 1 了，同时 page_pv 和 site_pv 也会分别加 1 更改统计数据现在就可以使用 Fiddler 的自动批量发包功能来刷访客数和访问量了，值得一提的是，这里也可以使用 JMeter 来刷统计数据。若刷访客数，则选中修改过 Cookie 的请求，右击选择 Replay –&gt; Reissue Sequentially，输入目标访问人数就可以很快刷上去了 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"爬虫"},{"title":"Seata 入门教程 - 实战篇（电商）","url":"/posts/b0f7bd00.html","text":"上篇 - Seata 入门教程（基础篇） Seata 入门教程 - 基础篇 1、前言 本案例使用的是 Seata 的 AT 模式 由于篇幅有限，本案例只给出各个模块的核心代码和配置，点击下载完整的案例代码（简版） 为了方便演示，本案例只使用 Nacos 作为注册中心，不使用 Nacos 作为配置中心，即使用 file.conf 配置文件来存储 TC（Seata Server）相关的配置信息 最新发布的内容，已追加 TC（Seata Server）整合 Nacos 作为配置中心的教程，点击下载完整的案例代码（配置中心版） 1.1、版本说明 MySQL 5.7 Nacos Server 1.4.0 Seata Server 1.4.0 Springt Boot 2.3.2.RELEASE Spring Cloud Hoxton.SR8 Spring Cloud Alibaba 2.2.3.RELEASE 特别注意：Spring Boot 和 Spring Cloud 以及 Spring Cloud Alibaba 的版本号需要互相对应，否则可能会存在各种问题，具体可以参考官方的版本说明 1.2、案例目标本案例将会创建三个服务，分别是订单服务、库存服务、账户服务，各服务之间的调用流程如下： 1）当用户下单时，调用订单服务创建一个订单，然后通过远程调用（OpenFeign）让库存服务扣减下单商品的库存 2）订单服务再通过远程调用（OpenFeign）让账户服务来扣减用户账户里面的余额 3）最后在订单服务中修改订单状态为已完成 上述操作跨越了三个数据库，有两次远程调用，很明显会有分布式事务的问题，项目的整体结构如下： 12345seata-transaction-demo├── seata-common-api # API模块├── seata-account-service # 账户模块，端口：2002├── seata-storage-service # 库存模块，端口：2000└── seata-order-service # 订单模块，端口：2001 1.3、Seata 分布式交易解决方案 2、准备工作2.1、初始化数据库本案例使用 MySQL 数据库来存储 Seata Server（TC）的全局事务会话信息，因此需要执行 SQL 初始化脚本来创建本案例需要的 Seata 数据库、对应的业务库与业务表。由于 Seata 的 SEATA、AT 模式均需要用到 UNDO_LOG 回滚日志表，因此在每个业务数据库里都要单独创建 UNDO_LOG 回滚日志表，最终所有用到的数据库和业务表如下图所示： 2.2、Nacos 创建命名空间在 Nacos 的控制台创建新的命名空间，后面会将命名空间写在 registry.confg 配置文件中，让 Seata Server 将自身的服务注册到 Nacos 3、配置 Seata Server3.1、创建 file.conffile.conf 是 Seata Server（TC）的配置文件，用于指定 TC 的相关配置，核心配置如下： 123456789101112131415161718192021222324252627service { vgroupMapping.seata-order-service-tx-group = \"default\" vgroupMapping.seata-storage-service-tx-group = \"default\" vgroupMapping.seata-account-service-tx-group = \"default\"}store { mode = \"db\" db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = \"druid\" ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = \"mysql\" driverClassName = \"com.mysql.cj.jdbc.Driver\" url = \"jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false\" user = \"root\" password = \"123456\" minConn = 5 maxConn = 100 globalTable = \"global_table\" branchTable = \"branch_table\" lockTable = \"lock_table\" queryLimit = 100 maxWait = 5000 }} ★file.conf 完整配置★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154transport { # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = \"seata\" compressor = \"none\"}service { vgroupMapping.seata-order-service-tx-group = \"default\" vgroupMapping.seata-storage-service-tx-group = \"default\" vgroupMapping.seata-account-service-tx-group = \"default\" default.grouplist = \"127.0.0.1:8091\" enableDegrade = false disable = false max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false}client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1}## transaction log store, only used in seata-serverstore { ## store mode: file、db、redis mode = \"db\" ## file store property file { ## store location dir dir = \"sessionStore\" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions maxBranchSessionSize = 16384 # globe session size , if exceeded throws exceptions maxGlobalSessionSize = 512 # file buffer size , if exceeded allocate new buffer fileWriteBufferCacheSize = 16384 # when recover batch read size sessionReloadReadSize = 100 # async, sync flushDiskMode = async } ## database store property db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = \"druid\" ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = \"mysql\" driverClassName = \"com.mysql.cj.jdbc.Driver\" url = \"jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false\" user = \"root\" password = \"123456\" minConn = 5 maxConn = 100 globalTable = \"global_table\" branchTable = \"branch_table\" lockTable = \"lock_table\" queryLimit = 100 maxWait = 5000 } ## redis store property redis { host = \"127.0.0.1\" port = \"6379\" password = \"\" database = \"0\" minConn = 1 maxConn = 10 maxTotal = 100 queryLimit = 100 }}lock { ## the lock store mode: local、remote mode = \"remote\" local { ## store locks in user's database } remote { ## store locks in the seata's server }}recovery { #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000}transaction { undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\"}## metrics settingsmetrics { enabled = false registry-type = \"compact\" # multi exporters use comma divided exporter-list = \"prometheus\" exporter-prometheus-port = 9898}support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false }} 3.2、创建 registry.confregistry.conf 用于指定 TC 的注册中心和 TC 的配置文件，这里使用 Nacos 作为注册中心，但 TC 的配置信息直接从 file.conf 配置文件中读取，核心配置如下： 123456789101112131415161718192021registry { type = \"nacos\" nacos { application = \"seata-server\" serverAddr = \"127.0.0.1:8848\" group = \"seata_demo\" namespace = \"ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d\" cluster = \"default\" username = \"\" password = \"\" }}config { type = \"file\" file { name = \"file.conf\" }} ★registry.conf 完整配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos { application = \"seata-server\" serverAddr = \"127.0.0.1:8848\" group = \"seata_demo\" namespace = \"ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d\" cluster = \"default\" username = \"\" password = \"\" } eureka { serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" } redis { serverAddr = \"localhost:6379\" db = 0 password = \"\" cluster = \"default\" timeout = 0 } zk { cluster = \"default\" serverAddr = \"127.0.0.1:2181\" sessionTimeout = 6000 connectTimeout = 2000 username = \"\" password = \"\" } consul { cluster = \"default\" serverAddr = \"127.0.0.1:8500\" } etcd3 { cluster = \"default\" serverAddr = \"http://localhost:2379\" } sofa { serverAddr = \"127.0.0.1:9603\" application = \"default\" region = \"DEFAULT_ZONE\" datacenter = \"DefaultDataCenter\" cluster = \"default\" group = \"SEATA_GROUP\" addressWaitTime = \"3000\" } file { name = \"file.conf\" }}config { # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" nacos { serverAddr = \"127.0.0.1:8848\" namespace = \"\" group = \"SEATA_GROUP\" username = \"\" password = \"\" } consul { serverAddr = \"127.0.0.1:8500\" } apollo { appId = \"seata-server\" apolloMeta = \"http://192.168.1.204:8801\" namespace = \"application\" } zk { serverAddr = \"127.0.0.1:2181\" sessionTimeout = 6000 connectTimeout = 2000 username = \"\" password = \"\" } etcd3 { serverAddr = \"http://localhost:2379\" } file { name = \"file.conf\" }} 3.3、拷贝配置文件 1）将上面的 file.conf、registry.conf 配置文件拷贝到 Seata Server 的 conf 目录下，直接覆盖原有的配置文件即可 2）由于本案例没有使用配置中心，因此还需要将上面的 file.conf 配置文件拷贝到每个 Maven 子工程的 src/main/resource 目录下 4、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，项目整体结构如下： ★父工程的 Maven 配置★ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;groupId&gt;com.seata.study&lt;/groupId&gt;&lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;seata-common-api&lt;/module&gt; &lt;module&gt;seata-order-service&lt;/module&gt; &lt;module&gt;seata-storage-service&lt;/module&gt; &lt;module&gt;seata-account-service&lt;/module&gt;&lt;/modules&gt;&lt;!-- 统一管理版本 --&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;mysql.version&gt;8.0.21&lt;/mysql.version&gt; &lt;spring.cloud.version&gt;Hoxton.SR8&lt;/spring.cloud.version&gt; &lt;spring.boot.version&gt;2.3.2.RELEASE&lt;/spring.boot.version&gt; &lt;spring.cloud.alibaba&gt;2.2.3.RELEASE&lt;/spring.cloud.alibaba&gt; &lt;seata.spring.boot.version&gt;1.4.0&lt;/seata.spring.boot.version&gt; &lt;druid.spring.boot.version&gt;1.2.4&lt;/druid.spring.boot.version&gt; &lt;mybatis.spring.boot.version&gt;2.1.3&lt;/mybatis.spring.boot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--spring boot--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.cloud.alibaba}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${druid.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--log4j--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 5、创建订单工程5.1、创建 pom.xml ★订单工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 5.2、创建 bootstrap.ymlSeata 1.1.0 版本之后客户端已经支持用 YAML 文件替代 xxxx.conf 文件。以下 bootstrap.yml 由于添加了 seata.registry 来配置 Seata Server 所使用的注册中心，因此不再需要拷贝 Seata Server 的 registry.conf 配置文件拷到每个 Maven 子工程的 src/main/resource 目录下。 特别注意：bootstrap.yml 中的 Seata 配置项，必须严格与 Seata Server 的 registry.conf、file.conf 的配置一致，否则会导致应用启动后无法正常连接 Seata Server seata.registry.nacos.group 必须与 Seata Server 的 registry.conf 中的 registry.nacos.group 一致 seata.registry.nacos.namespace 必须与 Seata Server 的 registry.conf 中的 registry.nacos.namespace 一致 seata.registry.nacos.server-addr 必须与 Seata Server 的 registry.conf 中的 registry.nacos.serverAddr 一致 seata.registry.nacos.application 必须与 Seata Server 的 registry.conf 中的 registry.nacos.application 一致 seata.tx-service-group 必须与 Seata Server 的 file.conf 中的 service.vgroupMapping.xxxx = \"default\" 的 xxxx 一致 在 file.conf 里，service.vgroupMapping.xxxx = \"default\" 支持配置多个，对应的就是多个微服务应用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace: ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-order-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2001spring: application: name: seata-order-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_order?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: \"\" password: \"\" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 5.3、注入代理数据源Seata 通过代理数据源的方式实现分支事务，其中 MyBatis 和 JPA 都需要注入 io.seata.rm.datasource.DataSourceProxy, 不同的是，MyBatis 还需要额外注入 org.apache.ibatis.session.SqlSessionFactory。在 Spring Boot Seata Starter 2.2.0.RELEASE 及以后版本，代理数据源的注入 Seata 已经自动实现了，即不需要再手动去配置。若希望 Seata 自动注入代理数据源，需要在工程里的 file.conf 配置文件添加 support.spring.datasource.autoproxy=true，手动实现的方式如下： 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Value(\"${mybatis.type-aliases-package}\") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 5.4、添加全局事务注解在订单创建的入口方法上面添加 @GlobalTransactional 来控制分布式事务，这里使用 OpenFeign 去调用库存服务和账户服务的接口 1234567891011121314151617181920212223242526@Servicepublic class OrderServiceImpl implements OrderService { @Resource private OrderMapper orderMapper; @Resource private AccountClient accountClient; @Resource private StorageClient storageClient; @Override @GlobalTransactional(name = \"create-order\", rollbackFor = Exception.class) public CommonResult createOrder(Order order) { // 创建订单 orderMapper.create(order); // 扣减商品库存 storageClient.decrease(order.getProductId(), order.getCount()); // 扣减账户余额 accountClient.decrease(order.getUserId(), order.getMoney()); //更新订单状态 orderMapper.update(order.getId(), OrderStatus.FINISHED.getValue()); return new CommonResult(); }} 5.5、创建主启动类123456789@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableDiscoveryClient@EnableFeignClientspublic class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); }} 6、创建库存工程6.1、创建 pom.xml ★库存工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 6.2、创建 bootstrap.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace:ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-storage-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2000spring: application: name: seata-storage-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_storage?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: \"\" password: \"\" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 6.3、注入代理数据源 ★代理数据源注入代码★ 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Value(\"${mybatis.type-aliases-package}\") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 6.4、创建业务处理类123456789101112131415161718192021222324252627@Servicepublic class StorageServiceImpl implements StorageService { @Resource private StorageMapper storageMapper; @Override public CommonResult decrease(Long productId, Long count) { Storage storage = storageMapper.findByProduct(productId); Long total = storage.getTotal(); Long used = storage.getUsed(); Long residue = storage.getResidue(); // 校验参数 if (count == null || count &lt;= 0) { return new CommonResult(SystemCode.ERROR_PARAMETER); } // 判断库存是否足够 if (count &gt; residue) { return new CommonResult(SystemCode.STORAGE_NOT_ENOUGH); } // 扣减库存 storage.setUsed(used + count); storage.setResidue(residue - count); storageMapper.update(storage); return new CommonResult(); }} 6.5、创建启动主类123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class StorageApplication { public static void main(String[] args) { SpringApplication.run(StorageApplication.class, args); }} 7、创建账户工程7.1、创建 pom.xml ★账户工程的 Maven 配置★ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;parent&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-transaction-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--seata-common-api--&gt; &lt;dependency&gt; &lt;groupId&gt;com.seata.study&lt;/groupId&gt; &lt;artifactId&gt;seata-common-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;!-- 阿里巴巴已经集成服务间调用X-id的传递，包括FeignClient的重写，如果在之前自定义封装过Feign，注意两者之间的冲突--&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--去除默认依赖的版本--&gt; &lt;exclusion&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 指定Seata的版本，需要与Seata服务端的版本保持一致--&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 7.2、创建 bootstrap.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace:ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-account-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2002spring: application: name: seata-account-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_account?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: \"\" password: \"\" config: type: filefeign: hystrix: enabled: falselogging: level: io: seata: info 7.3、注入代理数据源 ★代理数据源注入代码★ 123456789101112131415161718192021222324252627282930@Configurationpublic class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Value(\"${mybatis.type-aliases-package}\") private String typeAliasesPackage; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); }} 7.4、创建业务处理类这里添加了模拟账户业务处理超时的代码，延时时间为 10 秒。因为 OpenFeign 的默认超时时间为 1 秒，所以当订单服务远程调用账户服务来扣减账户余额时，会抛出请求超时的异常，这时就可以测试全局事务注解 @GlobalTransactional 是否生效了。若 @GlobalTransactional 生效，当订单服务的远程调用抛出请求超时的异常后，账户数据库里对应的账户余额不会被修改；若账户余额被修改了，则说明 @GlobalTransactional 没有生效。 12345678910111213141516171819202122232425262728293031323334@Servicepublic class AccountServiceImpl implements AccountService { @Resource private AccountMapper accountMapper; @Override public CommonResult decrease(Long userId, BigDecimal money) { Account account = accountMapper.findByUser(userId); BigDecimal total = account.getTotal(); BigDecimal used = account.getUsed(); BigDecimal residue = account.getResidue(); // 模拟业务处理超时 try { Thread.sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } // 校验参数 if (money == null || money.compareTo(BigDecimal.ZERO) &lt; 1) { return new CommonResult(SystemCode.ERROR_PARAMETER); } // 判断余额是否足够 if (money.compareTo(residue) == 1) { return new CommonResult(SystemCode.ACCOUNT_NOT_ENOUGH); } // // 扣减余额 account.setUsed(account.getUsed().add(money)); account.setResidue(account.getResidue().subtract(money)); accountMapper.update(account); return new CommonResult(); }} 7.5、创建主启动类123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class AccountApplication { public static void main(String[] args) { SpringApplication.run(AccountApplication.class, args); }} 8、测试项目代码 1）首先启动 MySQL Server、Nacos Server、Seata Server，并按照上文介绍的准备工作进行初始化 2）分别启动 seata-account-service、seata-storage-service、seata-order-service 服务 3）浏览器访问 http://127.0.0.1:8848/nacos 打开 Nacos 的控制台，各服务成功启动后，在 Nacos 的控制台里可以看到有多个服务已注册（如下图） 4）观察不同数据库中的 seata_account.t_account、seata_storage.t_storage 业务表的数据，如下图： 5）浏览器访问 http://127.0.0.1:2001/order/create?userId=1&amp;count=3&amp;money=20&amp;productId=1 调用订单创建接口，由于订单服务远程调用账户服务来扣减账户余额时，抛出了请求超时的异常，因此响应的 500 错误页面显示如下： 6）再观察不同数据库中的 seata_account.t_account、seata_storage.t_storage 业务表的数据是否发生了变更，若数据没有变更，则说明全局事务注解 @GlobalTransactional 生效了，否则注解没有生效 7）创建订单的接口被调用后，可以看到三个应用在控制台输出的日志如下： ★各微服务的日志信息★ 123456789101112################## seata_order 服务的日志 #####################java.net.SocketTimeoutException: Read timed out at java.base/java.net.SocketInputStream.socketRead0(Native Method) ~[na:na] at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140) ~[na:na] at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252) ~[na:na] at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:292) ~[na:na] at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351) ~[na:na] at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:746) ~[na:na] at java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:689) ~[na:na] 123456################## seata_storage 服务的日志 #####################[_RMROLE_1_2_144] i.s.c.r.p.c.RmBranchRollbackProcessor : rm handle branch rollback process:xid=192.168.1.130:8091:86489181212647424,branchId=86489188837892097,branchType=AT,resourceId=jdbc:mysql://127.0.0.1:3306/seata_storage,applicationData=null[_RMROLE_1_2_144] io.seata.rm.AbstractRMHandler : Branch Rollbacking: 192.168.1.130:8091:86489181212647424 86489188837892097 jdbc:mysql://127.0.0.1:3306/seata_storage[_RMROLE_1_2_144] i.s.r.d.undo.AbstractUndoLogManager : xid 192.168.1.130:8091:86489181212647424 branch 86489188837892097, undo_log deleted with GlobalFinished[_RMROLE_1_2_144] io.seata.rm.AbstractRMHandler : Branch Rollbacked result: PhaseTwo_Rollbacked 1234567891011################## seata_account 服务的日志 #####################io.seata.core.exception.RmTransactionException: Response[ TransactionException[Could not found global transaction xid = 192.168.1.130:8091:86489181212647424, may be has finished.] ] at io.seata.rm.AbstractResourceManager.branchRegister(AbstractResourceManager.java:69) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.DefaultResourceManager.branchRegister(DefaultResourceManager.java:96) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.register(ConnectionProxy.java:241) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.processGlobalTransactionCommit(ConnectionProxy.java:219) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.doCommit(ConnectionProxy.java:199) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.lambda$commit$0(ConnectionProxy.java:184) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy$LockRetryPolicy.execute(ConnectionProxy.java:292) ~[seata-all-1.4.0.jar:1.4.0] at io.seata.rm.datasource.ConnectionProxy.commit(ConnectionProxy.java:183) ~[seata-all-1.4.0.jar:1.4.0] 9、Seata Server 整合 Nacos 配置中心在上面的案例中，并没有使用 Nacos 配置中心来存储 TC（Seata Server）相关的配置信息，而是直接使用了 file.conf ，但在生产环境中一般极少采用这种方式。特别注意，当使用 Seata Server 使用 Nacos 作为配置中心后，Seata Server 启动时只需要依赖 registry.conf，即不再需要 file.conf。同时在 Spring Cloud 应用中不再需要依赖任何 file.conf、registry.conf，直接在 bootstrap.yml 里就可以完成 Seata 的所有配置。 9.1、配置 Seata Server 的 registry.conf在 Seata Server 的 registry.conf 里，指定使用配置中心来存储 TC 的相关配置（如下） 12345678910111213141516171819202122232425registry { type = \"nacos\" nacos { application = \"seata-server\" serverAddr = \"127.0.0.1:8848\" group = \"seata_demo\" namespace = \"ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d\" cluster = \"default\" username = \"\" password = \"\" }}config { type = \"nacos\" nacos { serverAddr = \"127.0.0.1:8848\" namespace = \"ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d\" group = \"seata_demo\" username = \"\" password = \"\" }} 9.2、导入配置信息到 Nacos 配置中心Seata 官方提供了将配置信息（file.conf）批量导入到各种主流配置中心的 Shell 脚本，存放路径是在 Seata 源码目录下的 script/config-center 目录（如下） 1234567891011121314script/config-center├── apollo│&nbsp;&nbsp; └── apollo-config.sh├── config.txt├── consul│&nbsp;&nbsp; └── consul-config.sh├── etcd3│&nbsp;&nbsp; └── etcd3-config.sh├── nacos│&nbsp;&nbsp; ├── nacos-config.py│&nbsp;&nbsp; └── nacos-config.sh├── README.md└── zk └── zk-config.sh 其中 config.txt 为通用参数文件，包含了 Seata Server（TC）需要的所有配置信息，需要根据实际情况更改文件里的以下内容： 1234567891011service.vgroupMapping.seata-order-service-tx-group=defaultservice.vgroupMapping.seata-storage-service-tx-group=defaultservice.vgroupMapping.seata-account-service-tx-group=defaultstore.mode=dbstore.db.datasource=druidstore.db.dbType=mysqlstore.db.driverClassName=com.mysql.cj.jdbc.Driverstore.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=falsestore.db.user=rootstore.db.password=123456 通用参数文件 config.txt 更改完成后，执行对应的 Shell 脚本将配置信息写入到配置中心即可。值得一提的是，config.txt 文件必须在 xxxx.sh 的上级目录里，而且 Shell 脚本可以重复执行多次。若使用 Nacos 作为配置中心，执行脚本时可以指定一些启动参数，如 Nacos 的 IP、端口号、命名空间、配置组等，Shell 脚本的具体使用方法可以查看官方说明文档 12# 执行数据导入脚本$ sh nacos-config.sh -h 127.0.0.1 -p 8848 -t ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d -g seata_demo 成功批量导入配置信息到 Nacos 后，控制台会输出如下提示： 1234========================================================================= Complete initialization parameters, total-count:79 , failure-count:0========================================================================= Init nacos config finished, please start seata-server. 访问 Nacos 的控制台，可以看到已经有对应的配置信息（如下）： 9.3、配置 Spring Cloud 项目以订单模块为例，bootstrap.yml 的完整配置如下，此时订单模块的 src/main/resources 目录下不再需要存放 file.conf、registry.conf 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475nacos: # Nacos的地址 server-addr: 127.0.0.1:8848 # Nacos的命名空间 namespace: ee08c2b7-2b41-4e9d-aeae-aae35a8dbd1d # Nacos的配置分组 group: seata_demo # Seata Server的配置 seata: application: seata-server tx-service-group: seata-order-service-tx-group####### 以上是自定义配置中心和注册中心的共同属性，方便其他地方直接引用 #######server: port: 2001spring: application: name: seata-order-service cloud: nacos: discovery: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} config: server-addr: ${nacos.server-addr} prefix: ${spring.application.name} file-extension: yaml namespace: ${nacos.namespace} group: ${nacos.group} # 以下配置内容均可以添加在Nacos配置中心 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata_order?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false username: root password: 123456mybatis: mapperLocations: classpath*:mapper/*.xml type-aliases-package: com.seata.study.domainseata: enabled: true application-id: ${spring.application.name} tx-service-group: ${nacos.seata.tx-service-group} enable-auto-data-source-proxy: false registry: type: nacos nacos: application: ${nacos.seata.application} server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: \"\" password: \"\" config: type: nacos nacos: server-addr: ${nacos.server-addr} namespace: ${nacos.namespace} group: ${nacos.group} username: \"\" password: \"\"feign: hystrix: enabled: falselogging: level: io: seata: info 9.4、代码下载（配置中心版） 点击下载完整的案例代码（配置中心版） 10、参考资料 Spring Cloud 快速集成 Seata 下篇 - Seata 入门教程（中级篇） Seata 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 分布式"},{"title":"Seata 入门教程 - 中级篇","url":"/posts/84d3f3e6.html","text":"1、Seata 整体框架1.1、Seata 概述Seata 是一套一站式分布式事务解决方案，为用户提供了 AT、TCC、SAGA 和 XA 事务模式，致力于提供高性能和简单易用的分布式事务服务。 1.2、Seata 的三大模块Seata 中有三大模块，分别是 TM、RM 和 TC，其中 TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起，TC 作为 Seata 的服务端独立部署。 TC：Transaction Coordinator 事务协调器，维护全局和分支事务的状态，负责协调并驱动全局事务的提交或回滚 TM：Transaction Manager 事务管理器，控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议 RM：Resource Manager 资源管理器，管理分支事务处理的资源，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务 1.3、Seata 的执行流程 TM 开启分布式事务（TM 向 TC 注册全局事务记录） 按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ） TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交 / 回滚分布式事务） TC 汇总事务信息，决定分布式事务是提交还是回滚 TC 通知所有 RM 提交 / 回滚 资源，事务二阶段结束 2、AT 模式2.1、前提 Java 应用，通过 JDBC 访问数据库 基于支持本地 ACID 事务的关系型数据库 2.2、写隔离 一阶段本地事务提交前，需要确保先拿到全局锁 拿不到全局锁 ，不能提交本地事务 拿全局锁的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁 举例说明：两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000 tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的全局锁，本地提交事务释放本地锁。tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。tx2 本地事务提交前，尝试拿该记录的全局锁；tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待全局锁 。 如果 tx1 二阶段全局提交，释放全局锁，tx2 拿到全局锁后提交本地事务 如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支事务的回滚。此时，如果 tx2 仍在等待该数据的全局锁，同时持有本地锁，则 tx1 的分支事务回滚会失败。tx1 的分支事务回滚会一直重试，直到 tx2 的全局锁等锁超时，放弃等待全局锁并回滚本地事务释放本地锁，tx1 的分支事务最终回滚成功。因为整个过程全局锁在 tx1 结束前一直是被 tx1 持有的，所以不会出现脏写的问题。 2.3、读隔离在数据库本地事务隔离级别读已提交（Read Committed）或以上的基础上，Seata（AT 模式）的默认全局隔离级别是读未提交（Read Uncommitted）。如果应用在特定场景下，必需要求全局的读已提交，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。 SELECT FOR UPDATE 语句的执行会申请全局锁，如果全局锁被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到拿到全局锁，即读取的相关数据是已提交的才返回。出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。 2.4、整体机制AT 模式本质是两阶段提交协议（2PC）的演变： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源 二阶段： 提交异步化，非常快速地完成 回滚是通过一阶段的回滚日志进行反向补偿 一阶段： 在一阶段，Seata 会拦截业务 SQL： 1）首先解析 SQL 语义，找到业务 SQL 要更新的业务数据，在业务数据被更新前，将其保存成 before image 2）执行 业务 SQL 更新业务数据，在业务数据更新之后，再将其保存成 after image 3）最后生成行锁 以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性，任何提交的业务数据的更新一定有相应的回滚日志存在 基于这样的机制，分支的本地事务便可以在全局事务的第一阶段提交，并马上释放本地事务锁定的资源；这也是 Seata 和 XA 事务的不同之处，两阶段提交往往对资源的锁定需要持续到第二阶段实际的提交或者回滚操作，而有了回滚日志之后，可以在第一阶段释放对资源的锁定，降低了锁范围，提高效率，即使第二阶段发生异常需要回滚，只需找对 undolog 中对应数据并反解析成 SQL 来达到回滚目的。同时 Seata 通过代理数据源将业务 SQL 的执行解析成 undolog 来与业务数据的更新同时入库，达到了对业务无侵入的效果。 二阶段提交： 二阶段如果是提交的话，因为 业务 SQL 在一阶段已经提交至数据库，所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。 二阶段回滚： 二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的 业务 SQL 来还原业务数据。回滚方式便是用 before image 还原业务数据；但在还原前要首先要校验脏写，对比 数据库当前业务数据 和 after image，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要根据配置策略来做处理（如转人工处理）。 通俗讲： 第一阶段：假如我们现在插入或更新一条数据，根据动态代理它会提取你插入或更新的数据，保存一个原快照，然后再去执行 业务 SQL，再保存一个新快照，生成一个行锁。当你这个业务方法没有执行完，这个锁是不会释放的。最终提交 业务 SQL，业务表和 unlog 表是在同一个本地事务中，也就是要么同时成功，要么同时失败。因为你更新或插入一条数据，unlog 表会记录一些原始数据便于回滚，是 Seata 帮助我们实现了回滚 第二阶段：在这个阶段 Seata 会查看你的日志是否成功，如果成功不会做任何操作，如果失败，它会做一个反向补偿，使用 unlog 表记录一些原数据进行回滚操作 2.5、适用场景与优缺点适用场景： 分布式事务的业务逻辑中仅仅是纯数据库操作，不包含其他中间件的事务逻辑 优点： 改动及代码侵入最小，由 Seata 来负责 Commit 和 Rollback 的自动化提交或回滚操作 缺点： 如果事务中包含缓存存储或发送 MQ 消息等，则不适合使用 多次对数据库操作，以及全局行锁的存在对并发处理性能有影响 为了保证镜像 SQL 的可靠性，需要用户对 SQL 尽量做简化，建议做法：将多条 SQL 语句分解为多个事务中的原子步骤（对应 Seata AT 模式的分支 Branch 概念），如果单条 SQL 语句跨表，也分解成为多个事务中的原子步骤（尽量降低 Seata 存储前 SQL 镜像结果时的风险） 3、TCC 模式3.1、概述该模式由蚂蚁金服贡献，TCC 需要用户根据自己的业务场景实现 Try、Confirm 和 Cancel 三个接口。事务发起方在一阶段执行 Try 操作，在二阶段提交执行 Confirm 操作，二阶段回滚执行 Cancel 操作。TCC 三个接口的描述如下： Try：资源的检测和预留 Confirm：执行的业务操作提交，要求 Try 成功 Confirm 就一定要能成功 Cancel：预留资源释放 一个分布式的全局事务，整体是两阶段提交的模型。全局事务是由若干分支事务组成的，分支事务要满足两阶段提交的模型要求，即需要每个分支事务都具备自己的： 一阶段 prepare 行为 二阶段 commit 或 rollback 行为 3.2、AT 与 TCC 的区别根据两阶段行为模式的不同，可以将分支事务划分为 Automatic (Branch) Transaction Mode 和 Manual (Branch) Transaction Mode。 AT 模式基于支持本地 ACID 事务的关系型数据库： 一阶段 prepare 行为：在本地事务中，一并提交业务数据更新和相应回滚日志记录 二阶段 commit 行为：马上成功结束，自动异步批量清理回滚日志 二阶段 rollback 行为：通过回滚日志，自动生成补偿操作，完成数据回滚 相应的，TCC 模式，不依赖于底层数据资源的事务支持： 一阶段 prepare 行为：调用 自定义 的 prepare 逻辑 二阶段 commit 行为：调用 自定义 的 commit 逻辑 二阶段 rollback 行为：调用 自定义 的 rollback 逻辑 所谓的 Seata TCC 模式，是指支持把自定义的分支事务纳入到全局事务的管理中 3.3、适用场景与优缺点适用场景： 分布式事务的业务逻辑中除了数据库操作外，包含其他中间件事务逻辑 优点： 适合微服务化场景 无 AT 模式的全局行锁，TCC 性能会比 AT 模式高很多 用户可以自己定义业务的补偿逻辑，由业务层保证事务的一致性 缺点： TCC 模式下开发者需要自行实现 Try、Confirm、Cancel 接口，对业务代码有一定的侵入性 需要考虑如何将业务模型拆成 2 阶段，实现成 TCC 的 3 个方法，并且保证 Try 成功 Confirm 就一定能成功，Confirm 失败会不断重试 4、Saga 模式4.1、概述Saga 模式是 Seata 提供的长事务解决方案，该模式主要由蚂蚁金服贡献，在 Saga 模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。 4.2、整体机制目前 Seata 提供的 Saga 模式是基于状态机引擎来实现的，机制是： 1）通过状态图来定义服务调用的流程，并生成 Json 状态语言定义文件 2）状态图中一个节点可以是调用一个服务，节点可以配置它的补偿节点 3）状态图 Json 由状态机引擎驱动执行，当出现异常时状态引擎反向执行已成功节点对应的补偿节点将事务回滚（注意：异常发生时是否进行补偿也可由用户自定义决定） 4）可以实现服务编排需求，支持单项选择、并发、子流程、参数转换、参数映射、服务执行状态判断、异常捕获等功能 4.3、适用场景与优缺点适用场景： 对数据隔离性要求不高，对性能要求高的场景 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口 业务流程长、业务流程多、不需马上返回最终结果，只要保证最终一致性的场景 优点： 补偿逻辑易于实现 一阶段提交本地事务，无锁，高性能 事件驱动架构，参与者可异步执行，高吞吐量 缺点： 不保证隔离性 补偿逻辑需要自行实现 5、XA 模式5.1、前提 支持 XA 事务的数据库 Java 应用，通过 JDBC 访问数据库 5.2、整体机制在 Seata 定义的分布式事务框架内，利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种事务模式。 执行阶段： 可回滚：业务 SQL 操作放在 XA 分支中进行，由资源对 XA 协议的支持来保证可回滚 持久化：XA 分支完成后，执行 XA Prepare，同样，由资源对 XA 协议的支持来保证持久化（即之后任何意外都不会造成无法回滚的情况） 完成阶段： 分支提交：执行 XA 分支的 Commit 分支回滚：执行 XA 分支的 Rollback 5.3、工作机制整体运行机制： XA 模式 运行在 Seata 定义的事务框架内： 执行阶段（E xecute）：XA start/XA end/XA prepare + SQL + 注册分支 完成阶段（F inish）：XA commit/XA rollback 数据源代理： XA 模式需要依赖 XAConnection，获取 XAConnection 两种方式： 方式一：要求开发者配置 XADataSource，给开发者增加了认知负担，需要为 XA 模式专门去学习和使用 XA 数据源，与透明化 XA 编程模型的设计目标相违背 方式二：根据开发者的普通 DataSource 来创建，对开发者比较友好，和 AT 模式使用一样，开发者完全不必关心 XA 层面的任何问题，保持本地编程模型即可 Seata 优先设计实现第二种方式：数据源代理根据普通数据源中获取的普通 JDBC 连接创建出相应的 XAConnection，类比 AT 模式的数据源代理机制（如下）: 但是第二种方法有局限：无法保证兼容的正确性。实际上，这种方法是在做数据库驱动程序要做的事情；不同的厂商、不同版本的数据库驱动实现机制是厂商私有的，Seata 只能保证在充分测试过的驱动程序上是正确的，开发者使用的驱动程序版本差异很可能造成机制的失效，这点在 Oracle 上体现非常明显。 综合考虑，XA 模式的数据源代理设计需要同时支持第一种方式：基于 XA 数据源进行代理，类比 AT 模式的数据源代理机制（如下）： 分支注册： XA Start 需要 Xid 参数，这个 Xid 需要和 Seata 全局事务的 XID 和 BranchId 关联起来，以便由 TC 驱动 XA 分支的提交或回滚。目前 Seata 的 BranchId 是在分支注册过程，由 TC 统一生成的，所以 XA 模式分支注册的时机需要在 XA start 之前。Seata 的 XA 模式将来一个可能的优化方向：把分支注册尽量延后。类似 AT 模式在本地事务提交之前才注册分支，避免分支执行失败情况下，没有意义的分支注册。这个优化方向需要 BranchId 生成机制的变化来配合，即 BranchId 不通过分支注册过程生成，而是生成后再带着 BranchId 去注册分支。 XA 模式的使用： 从编程模型上，XA 模式与 AT 模式保持完全一致，只需要修改数据源代理，即可实现 XA 模式与 AT 模式之间的切换，示例代码如下： 12345678@Bean(\"dataSource\") public DataSource dataSource(DruidDataSource druidDataSource) { // DataSourceProxy for AT mode // return new DataSourceProxy(druidDataSource); // DataSourceProxyXA for XA mode return new DataSourceProxyXA(druidDataSource); } 6、参考文献 Seata 官方文档 - AT 模式 Seata 官方文档 - XA 模式 Seata 官方文档 - TCC 模式 Seata 官方文档 - Saga 模式 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 分布式"},{"title":"Seata 入门教程 - 基础篇","url":"/posts/e8b71fbe.html","text":"前言术语 TX 协议：应用或者应用服务器与事务管理器的接口 XA 协议：全局事务管理器与资源管理器的接口。XA 是由 X/Open 组织提出的分布式事务规范，该规范主要定义了全局事务管理器和局部资源管理器之间的接口，主流的数据库产品都实现了 XA 接口。XA 接口是一个双向的系统接口，在事务管理器以及多个资源管理器之间作为通信桥梁。之所以需要 XA 是因为在分布式系统中从理论上讲两台机器是无法达到一致性状态的，因此引入一个单点进行协调。由全局事务管理器管理和协调的事务可以跨越多个资源和进程。全局事务管理器一般使用 XA 二阶段协议与数据库进行交互。 分布式理论CAP 理论： CAP 定理是由加州大学伯克利分校 Eric Brewer 教授提出来的，他指出 WEB 服务无法同时满足一下三个属性： 一致性 (Consistency)：客户端知道一系列的操作都会同时发生 (生效) 可用性 (Availability)：每个操作都必须以可预期的响应结束 分区容错性 (Partition tolerance)：即使出现单个组件无法可用，操作依然可以完成 具体地讲在分布式系统中，任何数据库设计或者 Web 应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。 BASE 理论： 在分布式系统中，往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？前人已经给我们提出来了另外一个理论，就是 BASE 理论，它是用来对 CAP 定理进行进一步扩充的。BASE 理论指的是： Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 酸碱平衡： ACID 能够保证事务的强一致性，即数据是实时一致的，这在本地事务中是没有问题的。在分布式事务中，强一致性会极大影响分布式系统的性能，因此分布式系统中遵循 BASE 理论即可。但分布式系统的不同业务场景对一致性的要求也不同。如交易场景下，就要求强一致性，此时就需要遵循 ACID 理论，而在注册成功后发送短信验证码等场景下，并不需要实时一致，因此遵循 BASE 理论即可。因此要根据具体业务场景，在 ACID 和 BASE 之间寻求平衡。 分布式事务基础事务事务指的就是一个操作单元，在这个操作单元中的所有操作最终要保持一致的行为，要么所有操都成功，要么所有的操作都被撤销。简单地说，事务提供一种” 要么什么都不做，要么做全套 “机制。 本地事务本地事务其实可以认为是数据库提供的事务机制。说到数据库事务就不得不说，数据库事务中的四大特性（ACID）： A：原子性（Atomicity），一个事务中的所有操作，要么全部完成，要么全部不完成 C：一致性（Consistency），在一个事务执行之前和执行之后数据库都必须处于一致性状态 I：隔离性（Isolation），在并发环境中，当不同的事务同时操作相同的数据时，事务之间互不影响 D：持久性（Durability），指的是只要事务成功结束，它对数据库所做的更新就必须永久的保存下来 数据库事务在实现时会将一次事务涉及的所有操作全部纳入到一个不可分割的执行单元，该执行单元中的所有操作要么都成功，要么都失败，只要其中任一操作执行失败，都将导致整个事务的回滚。 分布式事务分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。一句话概括就是，一次业务操作需要跨多个数据源或者需要跨多个系统进行远程调用，就会产生分布式事务问题。 分布式事务的场景 单体系统访问多个数据库：一个服务需要调用多个数据库实例完成数据的增删改操作 多个微服务访问同一个数据库：多个服务需要调用一个数据库实例完成数据的增删改操作 多个微服务访问多个数据库：多个服务需要调用一个数据库实例完成数据的增删改操作 分布式事务协议两阶段提交协议（2PC）分布式系统的一个难点是如何保证架构下多个节点在进行事务性操作的时候保持一致性。为实现这个目的，二阶段提交算法的成立基于以下假设： 该分布式系统中，存在一个节点作为协调者（Coordinator），其他节点作为参与者（Cohorts），且节点之间可以进行网络通信 所有节点都采用预写式日志，且日志被写入后即被保持在可靠的存储设备上，即使节点损坏不会导致日志数据的消失 所有节点不会永久性损坏，即使损坏后仍然可以恢复 第一阶段（投票阶段）: 协调者节点向所有参与者节点询问是否可以执行提交操作（vote），并开始等待各参与者节点的响应 参与者节点执行询问发起为止的所有事务操作，并将 Undo 信息和 Redo 信息写入日志（注意：若成功这里其实每个参与者已经执行了事务操作） 各参与者节点响应协调者节点发起的询问，如果参与者节点的事务操作实际执行成功，则它返回一个” 同意” 消息；如果参与者节点的事务操作实际执行失败，则它返回一个” 中止” 消息 第二阶段（提交执行阶段）： 当协调者节点从所有参与者节点获得的相应消息都为” 同意” 时： 协调者节点向所有参与者节点发出” 正式提交（Commit）” 的请求 参与者节点正式完成操作，并释放在整个事务期间内占用的资源 参与者节点向协调者节点发送” 完成” 消息 协调者节点受到所有参与者节点反馈的” 完成” 消息后，完成事务 中断事务： 如果任一参与者节点在第一阶段返回的响应消息为” 中止”，或者协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时： 协调者节点向所有参与者节点发出” 回滚操作（Rollback）” 的请求 参与者节点利用之前写入的 Undo 信息执行回滚，并释放在整个事务期间内占用的资源 参与者节点向协调者节点发送” 回滚完成” 消息 协调者节点受到所有参与者节点反馈的” 回滚完成” 消息后，取消事务 特别注意：不管最后结果如何，第二阶段都会结束当前事务 二阶段提交的缺点： 资源阻塞：执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态 参与者发生故障：协调者需要给每个参与者额外指定超时机制，超时后整个事务失败（没有多少容错机制） 协调者发生故障：参与者会一直阻塞下去。需要额外的备机进行容错（这个可以依赖 Paxos 协议实现 HA） 二阶段无法解决的问题：协调者再发出 Commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否已经被提交成功，这有可能导致数据不一致 三阶段提交协议（3PC）与两阶段提交不同的是，三阶段提交有两个改动点： 引入超时机制。同时在协调者和参与者中都引入超时机制 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的 也就是说，除了引入超时机制之外，3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段. CanCommit 阶段： 3PC 的 CanCommit 阶段其实和 2PC 的准备阶段很像。协调者向参与者发送 Commit 请求，参与者如果可以提交就返回 Yes 响应，否则返回 No 响应： 事务询问：协调者向参与者发送 CanCommit 请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应 响应反馈：参与者接到 CanCommit 请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回 Yes 响应，并进入预备状态，否则反馈 No PreCommit 阶段： 协调者根据参与者的反应情况来决定是否可以执行事务的 PreCommit 操作。根据响应情况，有以下两种可能： 假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务的预执行 发送预提交请求：协调者向参与者发送 PreCommit 请求后，并进入 Prepared 阶段 事务预提交：参与者接收到 PreCommit 请求后，会执行事务操作，并将 Undo 和 Redo 信息记录到事务日志中 响应反馈：如果参与者成功的执行了事务操作，则返回 ACK 响应，同时开始等待最终指令 假如有任何一个参与者向协调者发送了 No 响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断 发送中断请求：协调者向所有参与者发送 Abort 请求 中断事务：参与者收到来自协调者的 Abort 请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断 DoCommit 阶段 该阶段进行真正的事务提交，也可以分为以下两种情况： 执行提交： 发送提交请求：协调接收到参与者发送的 ACK 响应，那么它将从预提交状态进入到提交状态，并向所有参与者发送 DoCommit 请求 事务提交：参与者接收到 DoCommit 请求之后，执行正式的事务提交，并在完成事务提交之后释放所有事务资源 响应反馈：事务提交完之后，向协调者发送 ACK 响应 完成事务：协调者接收到所有参与者的 ACK 响应之后，完成事务 中断事务 发送中断请求：协调者向所有参与者发送 Abort 请求 事务回滚：参与者接收到 Abort 请求之后，利用其在阶段二记录的 Undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源 反馈结果：参与者完成事务回滚之后，向协调者发送 ACK 消息 中断事务：协调者接收到参与者反馈的 ACK 消息之后，执行事务的中断 这里协调者如果没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是 ACK 响应，也可能响应超时），那么就会执行中断事务。 分布式事务解决方案全局事务（DTP 模型）全局事务是基于 DTP 模型实现的，DTP 是由 X/Open 组织提出的一种分布式事务模型 ——X/Open Distributed Transaction Processing Reference Model。它规定了要实现分布式事务，需要三种角色： AP: Application 应用系统 (微服务) TM: Transaction Manager 事务管理器 (全局事务管理) RM: Resource Manager 资源管理器 (数据库) 整个事务分成两个阶段： 阶段一：表决阶段，所有参与者都将本事务执行预提交，并将能否成功的信息反馈发给协调者 阶段二：执行阶段，协调者根据所有参与者的反馈，通知所有参与者，步调一致地执行提交或者回滚 优点： 提高了数据一致性的概率，实现成本较低 缺点： 单点问题：事务协调者宕机 同步阻塞：延迟了提交时间，加长了资源阻塞时间 数据不一致：在提交的第二阶段，依然存在 Commit 结果未知的情况，有可能导致数据不一致 TCC（两阶段型、补偿型）TCC 即为 Try Confirm Cancel，它属于补偿型分布式事务。TCC 实现分布式事务一共有三个步骤： Try（尝试待执行的业务）：这个过程并未执行业务，只是完成所有业务的一致性检查，并预留好执行所需的全部资源 Confirm（确认执行业务）：确认执行业务操作，不做任何业务检查，只使用 Try 阶段预留的业务资源。通常情况下，采用 TCC 则认为 Confirm 阶段是不会出错的。即只要 Try 成功，Confirm 就一定成功。若 Confirm 阶段真的出错了，需引入重试机制或人工处理 Cancel（取消待执行的业务）：取消 Try 阶段预留的业务资源。通常情况下，采用 TCC 则认为 Cancel 阶段也是一定成功的。若 Cancel 阶段真的出错了，需引入重试机制或人工处理 TCC 两阶段提交与 XA 两阶段提交的区别： XA 是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁 TCC 是业务层面的分布式事务，最终一致性，不会一直持有资源的锁 TCC 事务的优缺点： 优点：把数据库层的二阶段提交上提到了应用层来实现，规避了数据库层的 2PC 性能低下的问题 缺点：TCC 的 Try、Confirm 和 Cancel 操作功能需业务提供，开发成本高 最大努力通知（定期校对）最大努力通知也被称为定期校对，其实是对第二种解决方案的进一步优化。它引入了本地消息表来记录错误消息，然后加入失败消息的定期校对功能，来进一步保证消息会被下游系统消费。 第一步：消息由系统 A 投递到消息中间件 1）处理业务的同一事务中，向本地消息表中写入一条记录 2）准备专门的消息发送者不断地发送本地消息表中的消息到消息中间件，如果发送失败则重试 第二步：消息由中间件投递到系统 B 1）消息中间件收到消息后负责将该消息同步投递给相应的下游系统，并触发下游系统的任务执行 2）当下游系统处理成功后，向消息中间件反馈确认应答，消息中间件便可以将该条消息删除，从而该事务完成 3）对于投递失败的消息，利用重试机制进行重试，对于重试失败的，写入错误消息表 4）消息中间件需要提供失败消息的查询接口，下游系统会定期查询失败消息，并将其消费 优缺点： 优点： 一种非常经典的实现，实现了最终一致性 缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理，在业界并没有成熟的方案来解决 基于可靠消息服务的分布式事务基于可靠消息服务的方案是通过消息中间件保证上、下游应用数据操作的一致性。假设有 A 和 B 两个系统，分别可以处理任务 A 和任务 B。此时存在一个业务流程，需要将任务 A 和任务 B 在同一个事务中处理，此时就可以使用消息中间件来实现这种分布式事务。 第一步：消息由系统 A 投递到消息中间件 1）在系统 A 处理任务 A 前，首先向消息中间件发送一条消息 2）消息中间件收到后将该条消息持久化，但并不投递。持久化成功后，向 A 回复一个确认应答 3）系统 A 收到确认应答后，则可以开始处理任务 A 4）任务 A 处理完成后，向消息中间件发送 Commit 或者 Rollback 请求。该请求发送完成后，对系统 A 而言，该事务的处理过程就结束了 5）如果消息中间件收到 Commit，则向 B 系统投递消息；如果收到 Rollback，则直接丢弃消息。但是如果消息中间件收不到 Commit 和 Rollback 指令，那么就要依靠” 超时询问机制” 超时询问机制 系统 A 除了实现正常的业务流程外，还需提供一个事务询问的接口，供消息中间件调用。当消息中间件收到发布消息便开始计时，如果到了超时没收到确认指令，就会主动调用系统 A 提供的事务询问接口询问该系统目前的状态。该接口会返回三种结果，中间件根据三种结果做出不同反应： 提交：将该消息投递给系统 B 回滚：直接将消息丢弃 处理中：继续等待 第二步：消息由中间件投递到系统 B 消息中间件向下游系统投递完消息后便进入阻塞等待状态，下游系统便立即进行任务的处理，任务处理完成后便向消息中间件返回应答。 如果消息中间件收到确认应答后便认为该事务处理完毕 如果消息中间件在等待确认应答超时之后就会重新投递，直到下游消费者返回消费成功响应为止。一般消息中间件可以设置消息重试的次数和时间间隔，如果最终还是不能成功投递，则需要手工干预。这里之所以使用人工干预，而不是使用让 Ａ 系统回滚，主要是考虑到整个系统设计的复杂度问题 基于可靠消息服务的分布式事务，前半部分使用异步，注重性能；后半部分使用同步，注重开发成本。 Seata 介绍Seata 简介2019 年 1 月，阿里巴巴中间件团队发起了开源项目 Fescar（Fast &amp; Easy Commit And Rollback），其愿景是让分布式事务的使用像本地事务的使用一样，简单和高效，并逐步解决开发者们遇到的分布式事务方面的所有难题。Fescar 开源后，蚂蚁金服加入 Fescar 社区参与共建，并在 Fescar 0.4.0 版本中贡献了 TCC 模式。为了打造更中立、更开放、生态更加丰富的分布式事务开源社区，经过社区核心成员的投票，决定对 Fescar 进行品牌升级，于 2019 年 5 月 开始更名为 Seata，意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案，为用户提供了 AT、TCC、SAGA 和 XA 事务模式。Seata 融合了阿里巴巴和蚂蚁金服在分布式事务技术上的积累，并沉淀了新零售、云计算和新金融等场景下丰富的实践经验，但要实现适用于所有的分布式事务场景的愿景，仍有很长的路要走。更多介绍可参考：Seata 项目、Seata 官方示例代码、Seata 官网、Seata 官方中文文档 Seata 演进历史 TXC：Taobao Transaction Constructor，阿里巴巴中间件团队自 2014 年起启动该项目，以满足应用程序架构从单一服务变为微服务所导致的分布式事务问题 GTS：Global Transaction Service，2016 年 TXC 作为阿里中间件的产品，更名为 GTS 发布 FESCAR：2019 年开始基于 TXC/GTS 开源 FESCAR SEATA：2019 年 5 月 FESCAR 更名为 SEATA Seata 设计理念Seata 的设计目标是对业务无侵入，因此从业务无侵入的 2PC 方案着手，在传统 2PC 的基础上演进。它把一个分布式事务理解成一个包含了若干分支事务的全局事务。全局事务的职责是协调其下管辖的分支事务达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个关系型数据库的本地事务。 Seata 的三大组件 TC：Transaction Coordinator 事务协调器，维护全局和分支事务的状态，负责协调并驱动全局事务的提交或回滚 TM：Transaction Manager 事务管理器，控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议 RM：Resource Manager 资源管理器，管理分支事务处理的资源，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务 Seata 的执行流程 1）A 服务的 TM 向 TC 申请开启一个全局事务，TC 就会创建一个全局事务并返回一个唯一的 XID 2）A 服务的 RM 向 TC 注册分支事务，并将其纳入 XID 对应全局事务的管辖 3）A 服务执行分支事务，向数据库执行操作 4）A 服务开始远程调用 B 服务，此时 XID 会在微服务的调用链上传播 5）B 服务的 RM 向 TC 注册分支事务，并将其纳入 XID 对应的全局事务的管辖 6）B 服务执行分支事务，向数据库执行操作 7）全局事务调用链处理完毕，TM 根据有无异常向 TC 发起全局事务的提交或者回滚 8）TC 协调其管辖之下的所有分支事务，决定是否回滚 Seata 实现的 2PC 与传统 2PC 的区别 1）架构层次方面：传统 2PC 方案的 RM 实际上是在数据库层，RM 本质上就是数据库自身，通过 XA 协议实现，而 Seata 的 RM 是以 Jar 包的形式作为中间件层部署在应用程序这一侧的 2）两阶段提交方面：传统 2PC 无论第二阶段的决议是 Commit 还是 Rollback，事务性资源的锁都要保持到 Phase2 完成才释放。而 Seata 的做法是在 Phase1 就将本地事务提交，这样就可以省去 Phase2 持锁的时间，整体提高了效率 Seata Server 安装Seata 分 TC、TM 和 RM 三个角色，TC（Server 端）需要单独作为服务端部署，TM 和 RM（Client 端）由业务系统集成（如 Maven、Gradle）。 Seata Server 下载1）Seata Server 的官方下载地址在这里，直接下载已编译好的二进制包（seata-server-1.4.0.tar.gz ），然后解压即可使用 12345# 下载$ wget https://github.com/seata/seata/releases/download/v1.4.0/seata-server-1.4.0.tar.gz# 解压$ tar -xvf seata-server-1.4.0.tar.gz 2）Seata 的初始化资源的官方下载地址在这里，需要下载 Seata 的源代码包（Source code），后面初始化数据库或者配置中心时会用到资源目录里的文件 1234567891011# 下载$ wget https://github.com/seata/seata/archive/v1.4.0.tar.gz# 解压# tar -xvf v1.4.0.tar.gz# 资源目录的结构seata-1.4.0/script├── client├── config-center└── server 资源目录说明如下： server：Server 端数据库脚本及各个容器配置 client：存放 Client 端的 SQL 脚本、参数配置 config-center：各个配置中心参数导入脚本，其中的 config.txt(包含 Server 和 Client，原名为 nacos-config.txt) 为通用参数文件 Seata Server 配置1）将 Seata Server（TC）的存储模式更改为 DB，即使用数据库来存储全局事务会话信息，同时自定义事务组的名称。这里演示使用的数据库为 MySQL，默认支持的数据库类型包括：MySQL、Oracle、PostgreSQL、H2、Oceanbase，其中 service.vgroupMapping 的详细介绍可以看自定义事务组的名称 12345678910111213141516171819202122232425262728# 备份配置文件$ cp seata/conf/file.conf seata/conf/file.conf.bak# 编辑配置文件，更改或者新增以下内容$ vim seata/conf/file.confservice { vgroupMapping.tx_group_test = \"default\" #自定义事务组的名称，若不存在service配置项，直接新增对应的配置内容即可 default.grouplist = \"127.0.0.1:8091\" enableDegrade = false disable = false max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false}store { mode = \"db\" # 存储模式 db { dbType = \"mysql\" # 数据库类型 datasource = \"druid\" # 数据库连接池 driverClassName = \"com.mysql.cj.jdbc.Driver\" # 数据库驱动 url = \"jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=false\" # 数据库连接地址 user = \"mysql\" # 数据库用户名 password = \"mysql\" # 数据库密码 }} 2）初始化 Seata Server（TC）依赖的 MySQL 数据库，用于存储全局事务会话信息，SQL 初始化脚本的位置是 Seata 源码目录下的 script/server/db/mysql.sql。全局事务会话信息由三块内容构成，全局事务 –&gt; 分支事务 –&gt; 全局锁，对应的表分别是 global_table、branch_table、lock_table 12345678910111213141516171819# 创建Seata数据库mysql&gt; create database seata default character set utf8;# 切换数据库mysql&gt; use seata;# 执行SQL初始化脚本mysql&gt; source seata-1.4.0/script/server/db/mysql.sql# 查看数据库表mysql&gt; show tables;+-----------------+| Tables_in_seata |+-----------------+| branch_table || global_table || lock_table |+-----------------+3 rows in set (0.00 sec) 3）指定 Seata Server（TC）依赖的注册中心，这里使用的注册中心是 Nacos。为了演示方便，这里不再使用配置中心来存储 TC 的相关配置，即直接使用本地的 file.conf 配置文件。默认支持的注册中心与配置中心列表如下： 配置中心支持类型：File、Nacos 、Apollo、Zookeeper、Consul、Etcd3 注册中心支持类型：File 、Nacos 、Eureka、Zookeeper、Consul、Etcd3、Sofa、Redis 123456789101112131415161718192021222324252627# 备份配置文件$ cp seata/conf/registry.conf seata/conf/registry.conf.bak# 编辑配置文件，更改或者新增以下内容$ vim seata/conf/registry.confregistry { type = \"nacos\" nacos { application = \"seata-server\" serverAddr = \"127.0.0.1:8848\" group = \"SEATA_GROUP\" namespace = \"\" cluster = \"default\" username = \"\" password = \"\" }}config { type = \"file\" file { name = \"file.conf\" }} Seata Server 启动先将 Seata Server 依赖的数据库、注册中心服务启动了，最后才启动 Seata Server。 1234567891011121314# 创建GC的日志目录$ mkdir seata/logs# 进入bin目录$ cd seata/bin# 执行启动脚本$ sh seata-server.sh# 或者后台启动$ nohup sh seata-server.sh &amp;# 或者指定启动参数$ sh seata-server.sh -h 127.0.0.1 -p 8091 -n 1 启动参数说明如下： -h: 注册到注册中心的 IP -p: Seata Server 的本地监听端口，默认端口是 8091 -m: 全局事务会话信息存储模式，file、db、redis，优先读取启动参数 (Seata-Server 1.3 及以上版本支持 Redis) -n: Server Node，多个 Server 时，需区分各自节点，用于生成不同区间的 transactionId，以免冲突 -e: 多环境配置可以参考这里 特别注意：堆内存建议分配 2G，堆外内存 1G，JVM 的内存参数可以直接在 seata/bin/-server.sh 脚本里调整 Seata Server 成功启动后，在注册中心的服务列表里，可以看到 Seata Server 的服务已经成功注册： Seata Server 配置介绍配置文件说明 conf/file.conf： TC 的配置文件，用于指定 TC 的相关配置。如果使用了配置中心，也可以将 file.conf 里的配置信息写入到配置中心。 conf/registry.conf：用于指定 TC 的注册中心和 TC 的配置文件，默认类型都是 file。如果使用其他注册中心，要求 Seata Server 自身也注册到注册中心。 配置中心使用若在 registry.conf 中指定使用配置中心来存储 TC 的相关配置（如下），即利用配置中心来替代 file.conf 配置文件，那么此时需要手动将 file.conf 里的配置信息添加到配置中心 12345678910111213config { type = \"nacos\" nacos { serverAddr = \"127.0.0.1:8848\" namespace = \"\" group = \"SEATA_GROUP\" username = \"\" password = \"\" } ...} Seata 官方提供了将配置信息批量写入到各种主流配置中心的 Shell 脚本，存放路径是在 Seata 源码目录下的 script/config-center 目录（如下） 1234567891011121314script/config-center├── apollo│&nbsp;&nbsp; └── apollo-config.sh├── config.txt├── consul│&nbsp;&nbsp; └── consul-config.sh├── etcd3│&nbsp;&nbsp; └── etcd3-config.sh├── nacos│&nbsp;&nbsp; ├── nacos-config.py│&nbsp;&nbsp; └── nacos-config.sh├── README.md└── zk └── zk-config.sh 其中 config.txt 为通用参数文件，包含了 Seata Server 需要的所有配置信息，只需执行对应的 Shell 脚本将配置信息写入到配置中心即可。值得一提的是，config.txt 文件必须在 xxxx.sh 的上级目录里；若使用 Nacos 作为配置中心，执行脚本时可以指定一些启动参数，如 Nacos 的 IP、端口号、命名空间、配置组等，Shell 脚本的具体使用方法可以查看 script/config-center/README.md 说明文档。 1$ nacos-config.sh -h 127.0.0.1 -p 8848 -t namespace -g group -u username -w password 成功批量导入配置信息到配置中心后，控制台会输出如下提示： 1234========================================================================= Complete initialization parameters, total-count:79 , failure-count:0========================================================================= Init nacos config finished, please start seata-server. 访问 Nacos 的控制台，可以看到已经有对应的配置信息 配置 TC 的存储模式Seata Server（TC）的存储模式现有 File、DB、Redis 三种（后续将引入 Raft、Mongodb），需要在 file.conf 配置文件中指定（如下） 123456789101112131415161718192021store { mode = \"file\" ## file store property file { ## store location dir dir = \"sessionStore\" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions maxBranchSessionSize = 16384 # globe session size , if exceeded throws exceptions maxGlobalSessionSize = 512 # file buffer size , if exceeded allocate new buffer fileWriteBufferCacheSize = 16384 # when recover batch read size sessionReloadReadSize = 100 # async, sync flushDiskMode = async } ...} 默认存储模式为 File，若使用 File 模式则无需改动任何配置，直接启动即可，每种模式的说明如下： File 模式为单机模式，全局事务会话信息在内存中读写，并持久化为本地文件 root.data，性能较高 DB 模式为高可用模式，全局事务会话信息通过 DB 共享，性能会差一点 Redis 模式在 Seata-Server 1.3 及以上版本开始支持，性能较高，存在事务信息丢失风险，需要配置合适当前场景的 Redis 持久化配置 自定义事务组的名称特别注意，file.conf 中的 service.vgroupMapping 这个配置，在 Spring Cloud 中的值默认是 ${spring.application.name}-fescar-service-group，可以通过指定 application.yml 中的 spring.cloud.alibaba.seata.tx-service-group 这个属性来覆盖；但是必须要和 file.conf 中的 service.vgroupMapping 一致，否则会出现 no available service 'null' found, please make sure registry config correct 的错误，举例说明如下： 123service { vgroupMapping.tx_group_test = \"default\"} 12345spring: cloud: alibaba: seata: tx-service-group: tx_group_test 在上述的配置中，Spring Cloud 中 tx-service-group 的值也必须为 tx_group_test；如果将 vgroupMapping.xxxx 中的 xxxx（Key 值）改为 abcdefg，则 Spring Cloud 中 tx-service-group 的值也必须为 abcdefg，即这两个值必须保持一致 Seata Server 的坑default.grouplist 属性在 Seata Server 的 file.conf 配置文件中，有个 default.grouplist 配置，该配置的使用说明如下： 1）只有在 registry.conf 中配置了 registry.type=file，即注册中心是 File 模式时，该配置才会起作用 2）对应的值可以配置多个，配置多个就需要搭建 Seata Server 集群。由于默认并未提供本地文件的同步功能，所以在 store.mode=file 模式下，这种集群方式的配置会报错；如果 Seata Server 搭建为集群，且 store.mode=db，这样就可以通过 DB 来共享 TC（Seata Server） 集群间的数据 3）当 registry.type=file 时，这个 default.grouplist 才会起作用，但是 File 方式并不能提供一个注册中心的完整功能，比如健康检查机制，实例列表的更新剔出等，建议选择 Nacos 、Eureka、Redis、Zookeeper、Consul、Etcd3、Sofa 作为注册中心 4）registry.type=file 或 config.type=file 的设计初衷，是让开发者在不依赖第三方注册中心或配置中心的前提下，可以通过 File 这种简单的直连快速验证 Seata 服务，达到快速上手的目的 service.vgroup_mapping 属性Seata Server &lt;=1.0 的版本用的是 service.vgroup_mapping，但在新版本里改成了 service.vgroupMapping。若应用启动后无法连接 Seata Server，且抛出了以下异常信息，此时应该注意使用的是不是旧的 service.vgroup_mapping 1no available service 'null' found, please make sure registry config correct 在 file.conf 配置文件中，service.vgroupMapping 支持配置多个： 1234service.vgroupMapping.user-service-group=defaultservice.vgroupMapping.order-service-group=defaultservice.vgroupMapping.account-service-group=defaultservice.vgroupMapping.storage-service-group=default 参考文献 分布式事务解决方案 微服务分布式事务 4 种解决方案实战 大规模 SOA 系统中的分布事务处事（程立） 下篇 - Seata 入门教程（电商实战篇） Seata 入门教程 - 实战篇（电商） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 分布式"},{"title":"Sentinel 入门教程 - 整合篇","url":"/posts/63e3926c.html","text":"前言为了减少开发的复杂度，Sentinel 对大部分的主流框架，例如 Web Servlet、Dubbo、Spring Cloud、gRPC、Spring WebFlux，Reactor 等都做了适配，只需要引入对应的依赖即可方便的整合 Sentinel。如果要实现 Spring Cloud 和 Sentinel 的整合，可以通过引入 Spring Cloud Alibaba Sentinel 来整合 Sentinel。Spring Cloud Alibaba 是阿里巴巴开源的，致力于提供微服务开发的一站式解决方案。Spring Cloud Alibaba 默认为 Sentinel 整合了 Servlet、RestTemplate、FeignClient 和 Spring WebFlux。Sentinel 在 Spring Cloud 生态中，不仅补全了 Hystrix 在 Servlet 和 RestTemplate 这一块空白，而且还完全兼容了 Hystrix 在 FeignClient 中限流降级的用法，并且支持运行时灵活地配置和调整限流降级规则。 Sentinel 整合 Spring Cloud1.0、版本说明本案例使用各开源组件的版本说明如下，点击下载完整的案例代码 Sentinel 1.8.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Sentinel 2.1.3.RELEASE 1.1、引入 Maven 依赖添加 spring-cloud-starter-alibaba-sentinel 依赖 1234567891011121314151617181920212223242526272829303132&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1.2、创建主启动类1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 1.3、创建 Controller 测试类12345678910111213141516171819202122232425262728@RestControllerpublic class TestController { /** * 定义资源 * value：资源名称 * blockHandler：限流处理的方法 * * @return */ @SentinelResource(value = \"Hello\", blockHandler = \"exceptionHandler\") @GetMapping(\"/hello\") public String hello() { // 使用限流规则 return \"Hello Sentinel!\"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return \"系统繁忙，请稍候 ...\"; }} 1.4、配置 Sentinel 控制台在 application.yml 配置文件里，指定 Sentinel 控制台的地址和端口 12345678910server: port: 8080spring: application: name: sentinel-spring-cloud cloud: sentinel: transport: dashboard: 127.0.0.1:9000 1.5、测试代码 1）启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 2）启动 Spring Cloud 应用，浏览器访问 http://127.0.0.1:8080/hello，若响应结果返回 Hello Sentinel!，说明应用启动成功 3）浏览器访问 http://127.0.0.1:9000，打开 Sentinel 控制台，动态添加流控规则，如下图所示： 4）浏览器再次访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，，则说明 Sentinel 的流控规则生效了 Sentinel 整合 OpenFeignSentinel 适配了 OpenFeign 组件，如果想使用，除了引入 spring-cloud-starter-alibaba-sentinel 依赖之外，还需要以下两个步骤： 在配置文件里打开 Sentinel 对 OpenFeign 的支持：feign.sentinel.enabled=true 加入 spring-cloud-starter-openfeign 依赖使 Sentinel starter 中的自动化配置类生效 2.0、版本说明本案例使用各开源组件的版本说明如下，其中服务注册中心使用 Nacos，若改为使用 Eureka，只需要在案例里将 Nacos 相关的配置（Maven 依赖 + YAML 配置）替换掉即可，点击下载完整的案例代码 Sentinel 1.8.0 Nacos Server 1.4.0 Spring Boot 2.1.18.RELEASE Spring Cloud Greenwich.SR6 Spring Cloud Alibaba Sentinel 2.1.3.RELEASE Spring Cloud Alibaba Nacos Config 2.1.3.RELEASE 2.1、案例目标实现 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时的流量控制 2.2、准备工作启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 启动 Nacos Server，并在 Nacos Server 的控制面台里，创建名称为 dev 的命名空间 2.3、创建 Maven 父工程创建 Maven 父工程，配置好工程需要的父级依赖，目的是为了更方便管理与简化配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt; &lt;spring-cloud-starter-nacos.version&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-nacos.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-nacos.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.4、创建 Sentinel Provider 工程引入 Maven 依赖 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，启用服务发现功能，并将服务注册到 Nacos 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Controller 测试类 1234567891011@RestControllerpublic class ProviderController { private Logger LOG = LoggerFactory.getLogger(ProviderController.class); @GetMapping(\"/hello\") public String hello() { LOG.info(\"provider invoke ... \"); return \"Hello Sentinel!\"; }} 创建 application.yml 配置文件，添加 Nacos 注册中心的地址和端口等信息 1234567891011121314server: port: 8080 servlet: context-path: /providerspring: application: name: sentinel-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT 2.5、创建 Sentinel Consumer 工程引入 Maven 依赖，包括 spring-cloud-starter-openfeign、spring-cloud-starter-alibaba-sentinel 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Feign Client 的接口类 123456@FeignClient(value = \"sentinel-provider\", fallback = FallbackService.class)public interface FeignAgent { @GetMapping(\"/provider/hello\") public String hello();} 创建处理限流、降级的回调类 12345678@Componentpublic class FallbackService implements FeignAgent { @Override public String hello() { return \"系统繁忙，请稍候 ...\"; }} 创建主启动类，添加 @EnableDiscoveryClient、@EnableFeignClients 注解 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Controller 测试类 1234567891011121314@RestControllerpublic class ConsumerController { @Autowired private FeignAgent feignAgent; private Logger LOG = LoggerFactory.getLogger(ConsumerController.class); @GetMapping(\"/hello\") public String hello() { LOG.info(\"consumer invoke ... \"); return feignAgent.hello(); }} 创建 application.yml 配置文件，添加 Nacos 注册中心的地址和端口等信息，并启用 Sentinel 对 OpenFeign 的支持 123456789101112131415161718192021server: port: 8082 servlet: context-path: /consumerspring: application: name: sentinel-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT sentinel: transport: dashboard: 127.0.0.1:9000feign: sentinel: enabled: true 2.6、测试代码 1）分别启动 sentinel-consumer、sentinel-provider 应用 2）浏览器访问 http://127.0.0.1:8082/consumer/hello，若响应结果为 Hello Sentinel!，说明两个应用启动成功，同时在 Nacos 的控制台可以看到已经有两个服务注册了，如下图所示： 3）浏览器访问 http://127.0.0.1:9000，打开 Sentinel 的控制台，动态添加流控规则，如下图所示： 特别注意：Sentinel 与 Feign 整合时，流控规则的编写格式为 HTTP请求方式:协议://服务名/请求路径跟参数，例如：GET:http://sentinel-provider/provider/hello 4）浏览器再次访问 http://127.0.0.1:8082/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时，Sentinel 的流控规则生效了 Sentinel 网关限流Sentinel 支持对 Spring Cloud Gateway、Zuul 1.x、Zuul 2.x 等主流的 API Gateway 进行限流。 Sentinel 整合 Gateway从 1.6.0 版本开始，Sentinel 提供了 Spring Cloud Gateway 的适配模块，可以提供两种资源维度的限流： route 维度：即在 Spring 配置文件中配置的路由条目，资源名为对应的 routeId 自定义 API 维度：用户可以利用 Sentinel 提供的 API 来自定义一些 API 分组 3.0、案例说明本案例是在上述 Sentinel 整合 OpenFeign 案例的基础上开发的，注册中心依旧使用 Nacos，其中主要的变化是新创建了 sentinel-gateway 工程，因此下面只给出新增或者更改后的代码和配置，点击下载完整的案例代码。 3.1、案例目标实现 sentinel-gateway 微服务访问 sentinel-consumer 微服务时的流量控制，其中 sentinel-consumer 微服务通过 OpenFeign 访问 sentinel-provider 微服务时的流量控制在上述 Sentinel 整合 OpenFeign 案例已经实现了，完整的调用流程为 sentinel-gateway –&gt; sentinel-consumer –&gt; sentinel-provider。 3.2、准备工作启动 Sentinel 控制台 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 启动 Nacos Server，并在 Nacos Server 的控制面台里，创建名称为 dev 的命名空间 3.3、更改 Maven 父工程添加 spring-cloud-alibaba-sentinel-gateway 依赖 123456789&lt;properties&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt;&lt;/dependency&gt; 3.4、创建 Sentinel Gateway 工程引入 Maven 依赖 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Gateway 的配置类，用于定义被限流或者降级时处理的方法 12345678910111213141516171819@Configurationpublic class GatewayConfiguration { /** * 初始化 */ @PostConstruct public void init() { // 设置被限流或者降级处理时的回调方法 GatewayCallbackManager.setBlockHandler(new BlockRequestHandler() { // 被限流或者降级时处理的方法 @Override public Mono&lt;ServerResponse&gt; handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) { return ServerResponse.status(200).syncBody(\"系统繁忙，请稍后 ...\"); } }); }} 创建主启动类，添加 @EnableDiscoveryClient 注解 12345678@SpringBootApplication@EnableDiscoveryClientpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 application.yml 配置文件，由于这里指定了 context-path，因此在路由规则配置中需要使用 StripPrefix 参数将访问进来的 URL 中的 context-path 截取掉，否则 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，会出现 404 错误 12345678910111213141516171819202122232425server: port: 8083 servlet: context-path: gatewayspring: application: name: sentinel-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 cluster-name: DEFAULT sentinel: transport: dashboard: 127.0.0.1:9000 gateway: routes: - id: sentinel-gateway-route uri: lb://sentinel-consumer predicates: - Path=/${server.servlet.context-path}/consumer/hello/** filters: - StripPrefix=1 若在 application.yml 配置文件里没有配置 context-path，那么路由规则配置可以使用以下的写法： 1234567891011server: port: 8083spring: cloud: gateway: routes: - id: sentinel-gateway-route uri: lb://sentinel-consumer predicates: - Path=/consumer/hello/** 3.5、测试代码 1）分别启动 sentinel-gateway、sentinel-consumer、sentinel-provider 应用 2）浏览器访问 http://127.0.0.1:8083/gateway/consumer/hello，若响应结果为 Hello Sentinel!，说明三个应用启动成功，同时在 Nacos 的控制台可以看到已经有三个服务注册了，如下图所示： 3）这里让 Sentinel 基于 Route 维度进行网关限流，浏览器访问 http://127.0.0.1:9000，打开 Sentinel 的控制台，在 sentinel-gateway 服务里动态添加网关流控规则，其中 API 名称就是 application.yml 配置文件里的路由 ID，如下图所示： 4）浏览器再次访问 http://127.0.0.1:8083/gateway/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，Sentinel 的网关流控规则生效了 3.6、使用自定义 API 进行限流从 1.6.0 版本开始，Sentinel 提供了 Spring Cloud Gateway 的适配模块，可以提供两种资源维度的限流： route 维度：即在 Spring 配置文件中配置的路由条目，资源名为对应的 routeId 自定义 API 维度：用户可以利用 Sentinel 提供的 API 来自定义一些 API 分组 1）在 Sentinel 控制台里，删除所有与 sentinel-gateway 应用相关的网关流控规则 2）在 Sentinel 控制台的菜单栏里找到 sentinel-gatway -&gt; API 管理 -&gt; 新增 API 分组，由于上面在 application.yml 配置文件中指定了 context-path，因此表单里的” 匹配串” 为 /gateway/consumer/hello/**，” 匹配模式” 选择 前缀 3）在 Sentinel 控制台的菜单栏里找到 sentinel-gatway -&gt; 流控规则 -&gt; 新增网关流控规则，在表单里的 “API 类型” 选择 API 分组，”API 名称” 选择刚刚创建的 API 即可 4）浏览器访问 http://127.0.0.1:8083/gateway/consumer/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 sentinel-gateway 微服务访问 sentinel-consumer 微服务时，Sentinel 使用自定义 API 成功对网关进行限流了 参考博客 Sentinel 适配主流框架详解 Sentinel 官方文档中的网关限流 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"HarmonyOS 入门教程之一 HarmonyOS 简介","url":"/posts/658c60f7.html","text":"博客资料 HarmonyOS 官网 HarmonyOS 应用开发官网 HarmonyOS 设备开发官网 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"移动端"},{"title":"Sentinel 入门教程 - 中级篇","url":"/posts/e3c83db6.html","text":"上篇 - Sentinel 入门教程（基础篇） Sentinel 入门教程 - 基础篇 前言1.0、版本说明本文针对 Sentinel 1.8.0 及以上版本编写，特别说明除外。由于 1.8.0 版本对熔断降级特性进行了全新的改进升级，建议使用最新版本以更好地利用熔断降级的能力。 1.1、Sentinel 的控制规则Sentinel 的所有规则都可以在内存态中动态地查询与修改，修改之后立即生效，同时 Sentinel 也提供了相关 API 供开发者来定制自己的规则策略。Sentinel 主要支持以下几种规则： 流量控制规则 熔断降级规则 系统保护规则 来源访问控制规则 动态规则扩展 Sentinel 流量控制实现2.0、流量控制概述流量控制（Flow Control），其原理是监控应用流量的 QPS 或者并发线程数等指标，当达到指定的阀值时对流量进行控制，以避免被瞬间的流量高峰冲垮，从而保障应用的高可用性。FlowSlot 会根据预设的规则，结合 NodeSelectorSlot、ClusterBuilderSlot、StatisticSlot 统计出来的实时信息进行流量控制。限流的直接表现是在执行 Entry nodeA = SphU.entry(resourceName) 的时候抛出 FlowException 异常。FlowException 是 BlockException 的子类，可以捕捉 BlockException 来自定义被限流之后的处理逻辑。 2.1、流量控制策略Sentinel 的流量控制策略主要有两种实现方式： 并发线程数：并发线程数限流用于保护业务线程数不被耗尽 QPS：当 QPS 超过某个阀值的时候，则采取措施进行流量控制 2.2、流量控制规则的属性流量控制规则（FlowRule）包含下面几个重要的属性： count：限流阀值 strategy：调用关系限流策略 resource：资源名，即流控规则的作用对象 grade：限流阀值类型（QPS 或者并发线程数） limitApp：流控针对的调用来源，若为 default 则不区分调用来源 controlBehavior：流量整形的控制效果（直接拒绝、Warm Up、匀速排队） 直接拒绝（RuleConstant.CONTROL_BEHAVIOR_DEFAULT）方式是默认的流量控制方式，当 QPS 超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出 FlowException。这种方式适用于对系统处理能力确切已知的情况下，例如通过压测确定了系统的准确水位时。 Warm Up（RuleConstant.CONTROL_BEHAVIOR_WARM_UP）方式，即预热 / 冷启动方式，在系统长期处于低水位的情况下，当流量突然增加时，会直接把系统拉升到高水位，这可能会瞬间把系统拉跨。通过” 冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。 匀速排队（RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）方式会严格控制请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法，例如阈值 QPS=2 时，每个 500ms 处理一个请求，假设当前有 10 个请求则需要排队处理 5 秒。 特别注意：同一个资源可以同时拥有多个流控规则，Sentinel 检查规则时会依次检查。 2.3、流量控制规则的设置流量控制规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 2.3.1、代码设置以下只给出流量控制的简单示例代码，若需要更详细的流量控制代码示例，可以点这里 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@RestControllerpublic class DegradeController { /** * 资源名称 */ private static final String RESOURCE_NAME = \"Flow\"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = \"exceptionHandler\") @GetMapping(\"/hello\") public String hello() { // 被保护的资源 return \"Hello Sentinel!\"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return \"系统繁忙，请稍候 ...\"; } /** * 当前类的构造方法执行之后执行此方法 */ @PostConstruct public void initFlowRules() { // 创建存放流控规则的集合 List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); // 创建流控规则 FlowRule rule = new FlowRule(); // 定义资源，表示Sentinel会对哪个资源生效 rule.setResource(RESOURCE_NAME); // 定义流控规则的类型 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); // 定义QPS每秒能通过的请求数 rule.setCount(2); // 将流控规则存放在集合中 rules.add(rule); // 加载流控规则 FlowRuleManager.loadRules(rules); }} 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，然后快速多次刷新页面，当每秒的请求数大于 2 时，接口的请求结果为 系统繁忙，请稍候 ...，则说明上面设置的流控规则生效了。 2.3.2、注解属性说明 通过 @SentinelResource 注解的 blockHandler 属性制定具体的限流处理方法 实现处理方法，该方法的传参必须与资源点的传参一样，并且最后必须加上 BlockException 异常参数，同时返回类型也必须一样 2.3.3、Sentinel 控制台动态设置 Sentinel 熔断降级实现3.0、熔断降级概述除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。一个服务常常会调用别的模块，可能是另外的一个远程服务、数据库，或者第三方 API 等。例如，支付的时候，可能需要远程调用银联提供的 API；查询某个商品的价格，可能需要进行数据库查询。然而，这个被依赖服务的稳定性是不能保证的。如果依赖的服务出现了不稳定的情况，请求的响应时间变长，那么调用服务的方法的响应时间也会变长，线程会产生堆积，最终可能耗尽业务自身的线程池，服务本身也变得不可用。 现代微服务架构都是分布式的，由非常多的服务组成。不同服务之间相互调用，组成复杂的调用链路。以上的问题在链路调用中会产生放大的效果。复杂链路上的某一环不稳定，就可能会层层级联，最终导致整个链路都不可用。因此需要对不稳定的弱依赖服务调用进行熔断降级，暂时切断不稳定调用，避免局部不稳定因素导致整体的雪崩。熔断降级作为保护自身的手段，通常在客户端（调用端）进行配置。熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或者异常比例升高），对这个资源的调用进行限制，让请求快速多次失败，避免影响到其他的资源而导致级联故障（服务雪崩）。当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException）。 3.1、熔断降级策略 慢调用比例 (SLOW_REQUEST_RATIO）：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。 异常比例 (ERROR_RATIO）：当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数 (ERROR_COUNT）：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。 特别注意：异常降级仅针对业务异常，对 Sentinel 限流降级本身的异常（BlockException）不生效。 3.2、熔断降级规则的属性熔断降级规则（DegradeRule）包含下面几个重要的属性： 特别注意：同一个资源可以同时拥有多个熔断降级规则。 3.3、熔断降级规则的设置熔断降级规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 3.3.1、代码设置下面将演示如何使用慢调用比例 (SLOW_REQUEST_RATIO）熔断降级规则，点击下载完整的案例代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@RestControllerpublic class DegradeController { private static final String RESOURCE_NAME = \"Degrade\"; private Logger LOG = LoggerFactory.getLogger(DegradeController.class); /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：熔断降级处理的方法 */ @SentinelResource(value = RESOURCE_NAME, fallback = \"exceptionHandler\") @GetMapping(\"/hello\") public String hello() { // 被保护的资源 try { Random random = new Random(); int millis = random.nextInt(10); LOG.info(\"sleep time: \" + millis); // 随机休眠10毫秒以内，模拟接口慢调用 Thread.sleep(millis); } catch (InterruptedException e) { e.printStackTrace(); } return \"hello\"; } /** * 原方法被熔断降级的时候调用此方法 * * @return */ public String exceptionHandler() { LOG.error(\"fallback handler invoke\"); return \"系统繁忙，请稍候 ...\"; } /** * 定义熔断降级规则 */ @PostConstruct public void initDegradeRule() { // 创建存放熔断降级规则的集合 List&lt;DegradeRule&gt; rules = new ArrayList&lt;&gt;(); // 创建熔断降级规则 DegradeRule rule = new DegradeRule(); // 定义资源名称 rule.setResource(RESOURCE_NAME); // 定义熔断降级规则的类型 rule.setGrade(RuleConstant.DEGRADE_GRADE_RT); // 定义降级熔断时间（单位 s） rule.setTimeWindow(5); // 定义慢调用临界RT（超出该值计为慢调用，单位 s） rule.setCount(0.005); // 定义熔断触发的最小请求数 rule.setMinRequestAmount(1); // 定义统计时长（单位为 ms） rule.setStatIntervalMs(1000); // 定义慢调用比例阈值 rule.setSlowRatioThreshold(0.5); // 将熔断降级规则添加到集合中 rules.add(rule); // 加载熔断降级规则 DegradeRuleManager.loadRules(rules); }} 上述定义的慢调用比例熔断降级规则为：调用临界 RT（超出该值计为慢调用）值为 0.005 秒，当 1000 毫秒内请求数量大于 1，且慢调用的比例大于阈值大于 0.5，则熔断降级 5 秒。 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，然后快速多次刷新页面，若输出的日志信息类似下面的内容，则说明上面设置的熔断降级规则生效了。 123456789102020-01-18 22:15:45.705 INFO 61206 --- [nio-8080-exec-1] c.s.study.controller.DegradeController : sleep time: 82020-01-18 22:15:46.585 ERROR 61206 --- [nio-8080-exec-3] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:47.112 ERROR 61206 --- [nio-8080-exec-5] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:48.911 ERROR 61206 --- [nio-8080-exec-7] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:49.505 ERROR 61206 --- [nio-8080-exec-9] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:49.809 ERROR 61206 --- [nio-8080-exec-1] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:51.511 INFO 61206 --- [nio-8080-exec-3] c.s.study.controller.DegradeController : sleep time: 12020-01-18 22:15:51.834 INFO 61206 --- [nio-8080-exec-5] c.s.study.controller.DegradeController : sleep time: 32020-01-18 22:15:52.428 ERROR 61206 --- [nio-8080-exec-7] c.s.study.controller.DegradeController : fallback handler invoke2020-01-18 22:15:52.846 ERROR 61206 --- [nio-8080-exec-9] c.s.study.controller.DegradeController : fallback handler invoke 3.3.2、注解属性说明 3.3.3、Sentinel 控制台动态设置 Sentinel 系统自适应保护实现4.0、系统自适应保护概述在开始之前，先了解一下系统保护的目的： 保证系统不被拖垮 在系统稳定的前提下，保持系统的吞吐量 长期以来，系统保护的思路是根据硬指标，即系统的负载 (load1) 来做系统过载保护。当系统负载高于某个阈值，就禁止或者减少流量的进入；当 load 开始好转，则恢复流量的进入。这个思路给我们带来了不可避免的两个问题： load 是一个 “结果”，如果根据 load 的情况来调节流量的通过率，那么就始终有延迟性。也就意味着通过率的任何调整，都会过一段时间才能看到效果。当前通过率是使 load 恶化的一个动作，那么也至少要过 1 秒之后才能观测到；同理，如果当前通过率调整是让 load 好转的一个动作，也需要 1 秒之后才能继续调整，这样就浪费了系统的处理能力。所以我们看到的曲线，总是会有抖动。 恢复慢。想象一下这样的一个场景（真实），出现了这样一个问题，下游应用不可靠，导致应用 RT 很高，从而 load 到了一个很高的点。过了一段时间之后下游应用恢复了，应用 RT 也相应减少。这个时候，其实应该大幅度增大流量的通过率；但是由于这个时候 load 仍然很高，通过率的恢复仍然不高。 TCP BBR 的思想给了我们一个很大的启发。我们应该根据系统能够处理的请求，和允许进来的请求，来做平衡，而不是根据一个间接的指标（系统 load）来做限流。最终我们追求的目标是在系统不被拖垮的情况下，提高系统的吞吐率，而不是 load 一定要到低于某个阈值。如果我们还是按照固有的思维，超过特定的 load 就禁止流量进入，系统 load 恢复就放开流量，这样做的结果是无论我们怎么调参数，调比例，都是按照果来调节因，都无法取得良好的效果。Sentinel 在系统自适应保护的做法是，用 load1 作为启动自适应保护的因子，而允许通过的流量由处理请求的能力，即请求的响应时间以及当前系统正在处理的请求速率来决定。 4.1、系统自适应保护策略系统保护规则是从应用级别的入口流量进行控制，从单台机器的 Load、CPU 使用率、平均 RT、入口 QPS 和并发线程数等几个维度监控应用指标，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。系统保护规则是应用整体维度的，而不是资源维度的，并且仅对入口流量生效。入口流量指的是进入应用的流量（EntryType.IN），比如 Web 服务或 Dubbo 服务端接收的请求，都属于入口流量。 系统规则支持以策略： Load 自适应（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。 CPU Usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。 平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 4.2、系统自适应保护规则的属性 特别注意：系统自适应保护规则只针对入口资源（EntryType.IN）有效 4.3、系统自适应保护规则的设置系统自适应保护规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 4.3.1、代码设置以下演示的是如何使用 入口 QPS 系统自适应保护规则，点击下载完整的案例代码。 1234567891011121314151617181920212223242526272829303132@RestControllerpublic class SystemProtectController { /** * 定义资源 * EntryType.IN 表示入口资源 * * @return */ @SentinelResource(entryType = EntryType.IN) @GetMapping(\"/hello\") public String hello() { return \"Hello Sentinel!\"; } /** * 定义系统自适应保护规则 */ @PostConstruct public void initSystemRule() { // 创建存放系统自适应保护规则的集合 List&lt;SystemRule&gt; rules = new ArrayList&lt;&gt;(); // 创建系统自适应保护规则 SystemRule rule = new SystemRule(); // 定义入口资源的QPS（每秒允许的最大请求数） rule.setQps(2); // 添加系统自适应保护规则到集合中 rules.add(rule); // 加载系统自适应保护规则 SystemRuleManager.loadRules(rules); }} 程序运行后，当 /hello 接口每秒请求的次数大于 2，则会触发 Sentinel 的系统自适应保护规则，同时会返回 Blocked by Sentinel (flow limiting) 字符串给客户端。 4.3.2、Sentinel 控制台动态设置 Sentinel 来源访问控制实现5.0、来源访问控制概述很多时候需要根据调用来源来判断该次请求是否允许放行，这时候可以使用 Sentinel 的来源访问控制（授权控制、黑白名单控制）的功能。来源访问控制根据资源的请求来源（origin）限制资源是否通过，若配置白名单则只有请求来源位于白名单内时才可通过；若配置黑名单则请求来源位于黑名单时不通过，其余的请求通过。调用方的信息通过 ContextUtil.enter(resourceName, origin) 方法中的 origin 参数传入。特别注意，白名单和黑名单不能同时使用。 5.1、来源访问控制规则的属性来源访问控制规则（AuthorityRule）非常简单，主要有以下配置项： resource：资源名，即流控规则的作用对象。 limitApp：对应的黑名单 / 白名单，不同 origin 用 , 分隔，例如 appA,appB。 strategy：限制模式，AUTHORITY_WHITE 为白名单模式，AUTHORITY_BLACK 为黑名单模式，默认为白名单模式。 5.2、来源访问控制规则的设置来源访问控制规则设置有以下两种方式： 本地代码设置 在 Sentinel 控制台动态设置 5.2.1、代码设置下面将演示如何使用白名单来源访问控制规则，点击下载完整的案例代码。 1234567891011/** * 自定义来源解析器 */ @Component public class RequestOriginParserDefinition implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest httpServletRequest) { return httpServletRequest.getRemoteAddr(); } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@RestControllerpublic class OriginControlController { private static final String RESOURCE_NAME = \"Origin\"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：被限制访问时处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = \"exceptionHandler\") @GetMapping(\"/hello\") public String hello() { return \"Hello Sentinel!\"; } /** * 原方法被限制访问的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { return \"系统繁忙，请稍候 ...\"; } /** * 定义来源访问控制规则（黑名单） */ @PostConstruct public void initBlackRule() { // 创建存放规则的集合 List&lt;AuthorityRule&gt; rules = new ArrayList&lt;&gt;(); // 创建来源访问控制规则 AuthorityRule rule = new AuthorityRule(); // 定义资源名称 rule.setResource(RESOURCE_NAME); // 定义限制模式 rule.setStrategy(RuleConstant.AUTHORITY_BLACK); // 定义请求来源 rule.setLimitApp(\"127.0.0.1\"); // 将规则保存到集合中 rules.add(rule); // 加载规则 AuthorityRuleManager.loadRules(rules); }} 程序运行后，通过浏览器访问 http://127.0.0.1:8080/hello，若响应结果为 系统繁忙，请稍候 ...，则说明上面设置的黑名单来源控制规则生效了。 5.2.2、Sentinel 控制台动态设置 Sentinel 动态规则扩展（持久化规则）Sentinel 的理念是开发者只需要关注资源的定义，当资源定义成功后可以动态增加各种流控降级规则。Sentinel 提供以下几种方式设置规则： 通过 API 直接设置 (loadRules) 通过 DataSource 适配不同数据源修改 手动通过 API 设置比较直观，可以通过以下几个 API 设置不同的规则： 1234FlowRuleManager.loadRules(List&lt;FlowRule&gt; rules); // 设置流控规则DegradeRuleManager.loadRules(List&lt;DegradeRule&gt; rules); // 设置熔断降级规则SystemRuleManager.loadRules(List&lt;SystemRule&gt; rules); // 设置系统自适应保护规则AuthorityRuleManager.loadRules(List&lt;AuthorityRule&gt; rules); // 设置来源访问控制规则 6.0、DataSource 扩展不管是通过 Java 代码还是通过 Sentinel 控制台的方式设置流控降级规则，都属于手动方式，不够灵活。这种方式一般仅用于测试和演示，生产环境一般通过动态规则源的方式来动态管理流控降级规则。上述 loadRules() 方法只接受内存态的规则对象，但更多时候规则存储在文件、数据库或者配置中心当中。Sentinel 的 DataSource 接口提供了对接任意数据源的能力。Sentinel 官方推荐通过控制台设置规则后，将规则推送到统一的规则中心，客户端则实现 ReadableDataSource 接口监听规则中心来实时获取规则配置的变更，流程图如下： DataSource 扩展常见的实现方式有: 拉模式：客户端主动向某个规则管理中心定期轮询拉取规则，这个规则中心可以是 RDBMS、文件，甚至是 VCS 等。这样做的方式是简单，缺点是无法及时获取变更 推模式：规则中心统一推送，客户端通过注册监听器的方式时刻监听变化，比如使用 Nacos、Zookeeper 等配置中心，这种方式有更好的实时性和一致性保证 Sentinel 目前支持以下数据源扩展： Pull-based（拉模式）: 动态文件数据源、Consul、Eureka Push-based（推模式）: ZooKeeper、Apollo、Nacos, etcd、Redis 6.1、使用 ZooKeeper 规则配置（推模式）下面将演示如何使用 ZooKeeper 存放 Sentinel 的流控规则配置数据，使用的是 推模式，各组件的版本如下，点击下载完整的案例代码。 Sentinel 1.8.0 ZooKeeper Server 3.5.5 Spring Boot 2.1.18.RELEASE Sentinel Datasource Zookeeper 1.8.0 Spring Cloud Starter Sentinel 2.1.3.RELEASE 6.1.1、代码示例引入 Maven 依赖，添加 sentinel-datasource-zookeeper 依赖 1234567891011121314151617181920212223242526272829303132333435&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt; &lt;sentinel-datasource-zookeeper.version&gt;1.8.0&lt;/sentinel-datasource-zookeeper.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-zookeeper&lt;/artifactId&gt; &lt;version&gt;${sentinel-datasource-zookeeper.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Sentinel 的 配置类，让 Sentinel 使用 ZooKeeper 作为规则配置数据源 12345678910111213141516171819202122232425@Configurationpublic class SentinelZookeeperConfig { public static final String ZOOKEEPER_ADDRESS = \"127.0.0.1:2181\"; public static final String ZOOKEEPER_PATH = \"/Sentinel/FlowRules\"; /** * Sentinel从Zookeeper加载规则配置数据 */ @PostConstruct public void init() { // 参数一：Zookeeper的地址 // 参数二：Zookeeper中数据的路径 // 参数三：Zookeeper中数据的解析器 ReadableDataSource&lt;String, List&lt;FlowRule&gt;&gt; flowRuleDataSource = new ZookeeperDataSource&lt;&gt;( ZOOKEEPER_ADDRESS, ZOOKEEPER_PATH, source -&gt; JSON.parseObject(source, new TypeReference&lt;List&lt;FlowRule&gt;&gt;() { })); // 加载流控规则 FlowRuleManager.register2Property(flowRuleDataSource.getProperty()); }} 创建 Controller 测试类 123456789101112131415161718192021222324252627282930313233@RestControllerpublic class HelloController { private final static Logger LOG = LoggerFactory.getLogger(HelloController.class); /** * 资源名称 */ public static final String RESOURCE_NAME = \"Hello\"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = \"exceptionHandler\") @GetMapping(\"/hello\") public String hello() { return \"Hello Sentinel!\"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { LOG.info(\"系统繁忙，请稍候 ...\"); return \"系统繁忙，请稍候 ...\"; }} 创建主启动类 1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 创建 application.yml 配置文件，其中 sentinel.transport.dashboard 为非必要配置项；若不需要通过 Sentinel 控制台监控应用，这里可以不配置 sentinel.transport.dashboard，无论是否配置都不会影响应用加载和动态感知 ZooKeeper Server 中的规则配置数据 12345678910server: port: 8080spring: application: name: sentinel-zookeeper-demo cloud: sentinel: transport: dashboard: 127.0.0.1:9000 # 非必要配置项 创建 ZooKeeper 的数据测试类，作用是插入规则配置数据到 ZooKeeper 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@RunWith(SpringRunner.class)@SpringBootTestpublic class ZookeeperConfigSender { private static final int RETRY_TIMES = 3; private static final int SLEEP_TIME = 1000; @Test public void sendData() throws Exception { final String remoteAddress = \"127.0.0.1:2181\"; final String groupId = \"Sentinel\"; final String dataId = \"FlowRules\"; final String rule = \"[\\n\" + \" {\\n\" + \" \\\"resource\\\": \\\"Hello\\\",\\n\" + \" \\\"controlBehavior\\\": 0,\\n\" + \" \\\"count\\\": 2.0,\\n\" + \" \\\"grade\\\": 1,\\n\" + \" \\\"limitApp\\\": \\\"default\\\",\\n\" + \" \\\"strategy\\\": 0\\n\" + \" }\\n\" + \"]\"; CuratorFramework zkClient = CuratorFrameworkFactory.newClient(remoteAddress, new ExponentialBackoffRetry(SLEEP_TIME, RETRY_TIMES)); zkClient.start(); String path = getPath(groupId, dataId); Stat stat = zkClient.checkExists().forPath(path); if (stat == null) { zkClient.create().creatingParentContainersIfNeeded().withMode(CreateMode.PERSISTENT).forPath(path, null); } zkClient.setData().forPath(path, rule.getBytes()); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } zkClient.close(); } private static String getPath(String groupId, String dataId) { String path = \"\"; if (groupId.startsWith(\"/\")) { path += groupId; } else { path += \"/\" + groupId; } if (dataId.startsWith(\"/\")) { path += dataId; } else { path += \"/\" + dataId; } return path; }} 6.1.2、测试代码 1）启动 ZooKeeper Server 2）启动 sentinel-zookeeper-demo 应用，若控制台输出如下日志信息，则说明应用已经成功连接上 ZooKeeper 服务器 1234[localhost:2181)] org.apache.zookeeper.ClientCnxn : Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)[localhost:2181)] org.apache.zookeeper.ClientCnxn : Socket connection established to localhost/127.0.0.1:2181, initiating session[localhost:2181)] org.apache.zookeeper.ClientCnxn : Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000447be50007, negotiated timeout = 40000[ain-EventThread] o.a.c.f.state.ConnectionStateManager : State change: CONNECTED 3）浏览器访问 http://127.0.0.1:8080/hello，快速多次刷新页面，可以发现响应结果会一直返回 Hello Sentinel! 字符串 4）通过 Junit 执行 ZookeeperConfigSender.sendData() 方法，将规则配置数据插入到 ZooKeeper Server 5）通过命令行登录进 ZooKeeper Server 后，执行以下操作，可以观察到 ZooKeeper Server 中有对应的规则配置数据成功插入了 1234567891011[zk: localhost:2181(CONNECTED) 15] get /Sentinel/FlowRules[ { \"resource\": \"Hello\", \"controlBehavior\": 0, \"count\": 2.0, \"grade\": 1, \"limitApp\": \"default\", \"strategy\": 0 }] 6）浏览器再次快速多次访问 http://127.0.0.1:8080/hello，若响应结果为 系统繁忙，请稍候 ...，则说明 Sentinel 成功加载到 ZooKeeper Server 里的规则配置数据，而且是基于 推模式，默认支持监听规则配置的变更 6.2、更多数据源扩展支持Sentinel 默认还支持文件、Nacos、Apollo、Redis 等作为数据源扩展，这里不再累述，具体可以阅读官方文档中的动态规则扩展。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Sentinel 入门教程 - 基础篇","url":"/posts/8facd1ee.html","text":"前言本文针对 Sentinel 1.8.0 及以上版本编写，特别说明除外。由于 1.8.0 版本对熔断降级特性进行了全新的改进升级，建议使用最新版本以更好地利用熔断降级的能力。 流量控制与熔断降级流量控制概述拿旅游景点举个示例，旅游景点通常都会有最大的接待量，不可能无限制的放游客进入，比如故宫每天只卖八万张票，超过八万的游客，无法买票进入，因为如果超过八万人，景点的工作人员可能就忙不过来，过于拥挤的景点也会影响游客的体验和心情，并且还会有安全隐患；只卖 N 张票，这就是一种限流的手段。流量控制在网络传输中是一个常用的概念，它用于调整网络包的发送数据。在网络传输时，任意时间到来的请求往往是随机不可控的，而系统的处理能力是有限的，因此需要根据系统的处理能力对流量进行控制。 熔断降级概述在调用系统的时候，如果调用链路中的某个资源出现了不稳定或者不可用，最终会导致请求发生积压（如下图），而熔断降级就可以解决这个问题。所谓的熔断降级就是当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间过长或者异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其他的资源而导致级联故障（服务雪崩）。 流量控制与熔断降级实现方案Hystrix Hystrix 是由 Netflix 开源的一个针对分布式系统容错处理的开源组件，2011 - 2012 年相继诞生和成熟，在 2018 年 11 月 20 日之后已经停止维护，最后一个正式版本为 1.5.18。Hystrix 单词意为 “豪猪”，浑身有刺保护自己，Hystrix 就是这样一个用来捍卫应用程序健康的利器。进一步说，Hystrix 是一个延迟和容错库，用在隔离远程系统、服务和第三方库，阻止级连故障，在复杂的分布式系统中实现恢复能力，以提高分布式系统的弹性。 Sentinel Sentinel 是阿里巴巴出品的面向分布式服务架构的轻量级流量控制组件，主要以流量为入点，从限流、流量整形、熔断降级、系统负载保护等多个维度来保障微服务的稳定性。 Resilience4j Resilience4j 是一款轻量级，易于使用的容错库，其灵感来自于 Netflix Hystrix，但是专为 Java 8 和函数式编程而设计。轻量级，因为库只使用了 Vavr，它没有任何其他外部依赖下。相比之下，Netflix Hystrix 对 Archaius 具有编译依赖性，Archaius 具有更多的外部库依赖性，例如 Guava 和 Apache Commons Configuration。在 Spring Cloud Greenwich 版中，Spring 官方推荐使用 Resilience4j 替代 Hystrix。 开源实现方案对比附：Sentinel 对比 Hystrix 详解 Sentinel 介绍Sentinel 简介Sentinel 是阿里巴巴出品的面向分布式服务架构的轻量级流量控制组件，主要以流量为入点，从限流、流量整形、熔断降级、系统负载保护等多个维度来保障微服务的稳定性，更多介绍可参考：Sentinel 项目、Sentinel 官方中文文档 Sentinel 历史2012 年，Sentinel 诞生，主要功能为入口流量控制2013 - 2017 年，Sentinel 在阿里巴巴集团内部迅速发展，成为基础技术模块，覆盖了所有的核心场景，Sentinel 也因此积累了大量的流量归整场景以及生产实践2018 年，Sentinel 开源，并持续演进2019 年 Sentinel 朝着多语言扩展的方向不断探索，推出 C++ 原生版本，同时针对 Service Mesh 场景也推出了 Envoy 集群流量控制支持，以解决 Service Mesh 架构下多语言限流的问题2020 年，推出 Sentinel 的 Go 原生版本，继续朝着云原生的方向演进，同时已覆盖微服务、API Gateway 和 Service Mesh 三大板块的核心生态 Sentinel 组成 核心库：主要指 Java 客户端，不依赖任何框架 / 库，能够运行于 Java 7 及以上的版本的运行环境，同时对 Dubbo、Spring Cloud、Spring Cloud Alibaba 等框架也有较好的支持 控制台：控制台主要负责管理推送规则、监控、集群限流分配管理、机器发现等 Sentinel 优势 友好的控制面板，支持实时监控 多种限流。支持 QPS 限流，线程数限流，多种限流策略，如：直接拒绝，冷启动，匀速模式（漏斗） 多种降级模式，支持按平均返回时间降级，按多种异常数降级，按异常比率降级 方便扩展开发，支持 SPI 模式对 chain 进行扩展 支持链路的关联，按链路统计限流，系统保护，热门资源保护等等 Sentinel 特点 丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架 / 库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合，只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel 完备的实时监控：Sentinel 同时提供实时的监控功能。开发者可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况 完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。可以通过实现扩展接口来快速地定制逻辑，例如定制规则管理、适配动态数据源等 Sentinel 开源生态 AHAS Sentinel 控制台AHAS Sentinel 简介AHAS Sentinel 是 Sentinel 的阿里云上版本（商业版），提供企业级的高可用防护服务，包括： 可靠的实时监控和历史秒级监控数据查询，包含 QPS、RT、load、CPU 使用率等指标，支持按照调用类型分类，支持同比 / 环比展示 热力图概览，可以快速定位不稳定的机器 动态规则管理 / 推送，无需自行配置外部数据源 告警中心（触发流控、CPU 利用率高等事件） 全自动托管、高可用的集群流量控制 针对 Istio/Envoy 集群的 Mesh 高可用防护 Nginx 网关流控 AHAS Sentinel 控制台体验这里只是简单使用 AHAS Sentinel 官方提供的 Demo 包接入到 AHAS Sentinel 控制台，若希望将已有的 Sentinel 项目接入到 AHAS Sentinel 控制台，具体可参考 Sentinel 官方文档。 阿里云开通 AHAS 打开 AHAS 产品主页 在页面右上角单击登录 在页面上输入您的阿里云账号和密码，并单击登录 在产品主页上单击申请免费开通，然后在云产品开通页页面上勾选” 我已阅读并同意《应用高可用服务服务协议》”，并单击立即开通 接入新应用 若应用运行在非阿里云 ECS 环境或本地，需要在左上角选择切换公网环境 获取 Demo 包 点击控制台左侧菜单栏的 应用防护，找到 Tab 页面选择 JAVA 语言 -&gt; 体验 Demo，然后根据页面提示下载 Demo 包 启动 Demo 应用 公网和阿里云经典网络环境下，需要额外指定 License 用于身份校验，VPC 专有网络无需配置 License 12# 启动命令$ java -Dahas.namespace=default -Dproject.name=AppName -Dahas.license=xxxxxxxxxxxxx -jar ahas-sentinel-sdk-demo.jar 等待一会，AHAS Sentinel 控制台就会显示相关监控数据 Sentinel 基础Sentinel 基本概念资源 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序自身提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。 规则 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。 Sentinel 设计理念流量控制设计理念Sentinel 流量控制有以下几个角度: 运行指标，例如 QPS、线程池、系统负载等 控制的效果，例如直接限流、冷启动、排队等 资源的调用关系，例如资源的调用链路，资源和资源之间的关系 熔断降级设计理念Sentinel 和 Hystrix 的原则是一致的，即当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间过长或异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联故障。但在限制的手段上，Sentinel 和 Hystrix 采取了完全不一样的方法。Hystrix 通过线程池隔离的方式，来对依赖（在 Sentinel 的概念中对应资源）进行了隔离。这样做的好处是资源和资源之间做到了最彻底的隔离。缺点是除了增加了线程切换的成本（过多的线程池导致线程数目过多），还需要预先给各个资源做线程池大小的分配，并且对于一些使用了 ThreadLocal 的场景来说会有问题（如 Spring 的事务）。Sentinel 对这个问题采取了以下两种手段来解决： 通过并发线程数进行限制 和资源池隔离的方法不同，Sentinel 通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要您预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程数在特定资源上堆积到一定的数量之后，对该资源的新请求就会被拒绝，堆积的线程完成任务后才开始继续接收请求。 针对慢调用和异常对资源进行降级 除了对并发线程数进行控制以外，Sentinel 还可以根据响应时间和异常等不稳定因素来快速对不稳定的调用进行熔断。当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新渐进式地恢复。 系统自适应保护理念Sentinel 同时提供系统维度的自适应保护能力。防止雪崩，是系统防护中重要的一环。当系统负载较高的时候，如果还持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。 Sentinel 流量控制入门案例版本说明本案例使用的 Spring Boot 版本为 2.1.4.RELEASE，Sentinel 版本为 1.8.0，点击下载完整的案例代码。 本地 Sentinel 控制台搭建Sentinel 提供了一个轻量级的开源控制台，它提供机器发现以及健康状况管理、实时监控（单机和集群），规则管理和推送功能 下载 Sentinel 控制台Sentinel 控制台下载有两种方式，一种是直接下载编译好的 Release 版本程序包，另一种是下载 Sentinel 控制台的工程源码，在本地打包后启动，这里采用第一种方式 12# 下载命令$ wget https://github.com/alibaba/Sentinel/releases/download/v1.8.0/sentinel-dashboard-1.8.0.jar 启动 Sentinel 控制台启动 Sentinel 控制台需要依赖 JDK 版本为 1.8 及以上版本，使用以下命令启动控制台： 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 浏览器访问 http://127.0.0.1:9000，默认登录的用户名和密码为：sentinel/sentinel Sentinel 控制台启动参数说明Sentinel 控制台启动时，可配置的 JVM 参数如下： -Dserver.port 指定 Sentinel 控制台监听的端口 -Dproject.name，设置应用在 Sentinel 控制台中显示的名称 -Dcsp.sentinel.dashboard.server 设置应用需要连接到的 Sentinel 控制台的主机地址和端口号 -Dsentinel.dashboard.auth.password=123456 用于指定控制台的登录密码为 123456 -Dsentinel.dashboard.auth.username=sentinel 用于指定控制台的登录用户名为 sentinel -Dserver.servlet.session.timeout=7200 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟 特别注意：Sentinel 控制台启动时，若在 JVM 参数中添加了 -Dproject.name 与 -Dcsp.sentinel.dashboard.server，那么 Sentinel 控制台自身也可以注册到其他 Sentinel 控制台中，Sentinel 控制台甚至可以自己监控自己，启动配置示例如下： 1$ java -Dserver.port=9000 -Dcsp.sentinel.dashboard.server=127.0.0.1:9000 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.0.jar 此时浏览器访问 http://127.0.0.1:9000，可以发现控制台会多出一个 sentinel-dashboard 节点： 构建 Sentinel 本地应用引入 Maven 依赖由于需要将应用接入到 Sentinel 控制台，因此引入了 sentinel-transport-simple-http 依赖 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;sentinel.version&gt;1.8.0&lt;/sentinel.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt; &lt;version&gt;${sentinel.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt; &lt;version&gt;${sentinel.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 添加 Java SDK 代码123456789101112131415161718192021222324252627282930313233343536373839404142@RestControllerpublic class HelloController { /** * 资源名称 */ private static final String RESOURCE_NAME = \"Hello\"; @GetMapping(\"/hello\") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return \"Hello Sentinel!\"; } catch (Exception e) { // 被限流 e.printStackTrace(); return \"系统繁忙，请稍后 ...\"; } } /** * 当前类的构造函数执行之后执行此方法 */ @PostConstruct public void initFlowRules() { // 创建存放流控规则的集合 List&lt;FlowRule&gt; rules = new ArrayList&lt;&gt;(); // 创建流控规则 FlowRule rule = new FlowRule(); // 定义资源，表示Sentinel会对哪个资源生效 rule.setResource(RESOURCE_NAME); // 定义流控规则的类型 rule.setGrade(RuleConstant.FLOW_GRADE_QPS); // 定义QPS每秒能通过的请求数 rule.setCount(2); // 将流控规则存放在集合中 rules.add(rule); // 加载流控规则 FlowRuleManager.loadRules(rules); }} 1234567@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 将应用连接到 Sentinel 控制台若应用程序需要连接到 Sentinel 控制台， Sentinel 提供如下两种常用的配置方式，具体可参考 Sentinel 官方文档中的启动配置项 JVM -D 参数方式 properties 文件方式（1.7.0 版本开始支持） 这里采用添加 JVM 参数的启动方式，即启动应用时加入以下 JVM 参数： -Dproject.name=sentinel-demo，设置本地应用在 Sentinel 控制台中显示的名称 -Dcsp.sentinel.dashboard.server=127.0.0.1:9000，设置应用需要连接到的 Sentinel 控制台的主机地址和端口号 或者将 JVM 参数添加到 IDEA Configuration 里的 VM options 中： 测试代码 1）启动本地的 Sentinel 控制台，命令如下： 1$ java -Dserver.port=9000 -jar sentinel-dashboard-1.8.0.jar 2）在 Spring Boot 应用的 JVM 参数中配置 Sentinel 控制台，然后启动应用，若控制台输出以下日志信息，则说明 Sentinel 加载成功 1234INFO: Sentinel log output type is: fileINFO: Sentinel log charset is: utf-8INFO: Sentinel log base directory is: /root/logs/csp/INFO: Sentinel log name use pid is: false 特别注意：当代码里硬编码了流控规则（即使用 Java API 定义和加载流控规则）时，IDE 的控制台才会在应用启动时输出上面 Sentinel 相关的日志信息 3）浏览器访问 http://127.0.0.:9090，查看 Sentinel 控制台的监控信息；这里需要先手动调用一次 http://127.0.0.1:8080/hello 接口，Sentinel 控制台才会显示监控数据 4）浏览器访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明 Sentinel 的流控规则生效了 动态配置 Sentinel 的流控规则在上述案例中，将 Sentinel 的流控规则硬编码在 Java 代码里，但在实际的企业项目开发中，这种方式不推荐使用。在日常测试和演示中，一般都会在 Sentinel 控制台里动态配置流控规则，因为这样使用起来比较灵活。首先，将上述案例中添加 Sentinel 流控规则的代码注释掉（示例代码如下），然后在 Spring Boot 应用的 JVM 参数中配置 Sentinel 控制台。重新启动应用后，此时打印的启动日志信息不会再有 Sentinel 相关的内容。特别注意，默认情况下通过 Sentinel 控制台动态添加的规则配置是存放在内存里的，即动态添加的规则配置在 Sentinel 控制台应用重启后会失效。 123456789101112131415161718192021@RestControllerpublic class HelloController { /** * 资源名称 */ private static final String RESOURCE_NAME = \"Hello\"; @GetMapping(\"/hello\") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return \"Hello Sentinel!\"; } catch (Exception e) { // 被限流 e.printStackTrace(); return \"系统繁忙，请稍后 ...\"; } }} 浏览器手动调用一次 http://127.0.0.1:8080/hello 接口，然后打开 Sentinel 控制台，动态添加流控规则，表单里的资源名必须与 Java 代码里指定的资源名一致，如下图所示： 浏览器再次访问 http://127.0.0.1:8080/hello，当快速刷新页面时，请求的响应结果变为 系统繁忙，请稍后 ...，则说明动态配置的 Sentinel 流控规则生效了 Sentinel 定义资源的方式资源是 Sentinel 的关键概念，它可以是 Java 应用程序中的任何内容，例如，由应用程序自身提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。使用 Sentinel 来进行资源保护，主要分为两个步骤，包括定义资源和定义规则。先把可能需要保护的资源定义好，之后再配置规则。在编码的时候，只需要考虑这个代码是否需要保护，如果需要保护，就可以将之定义为一个资源。 Sentinel 除了基本的定义资源的方式之外，还有其他定义资源的方式，具体如下： 抛出异常的方式定义资源 返回布尔值方式定义资源 异步调用支持 注解方式定义资源 主流框架的默认适配 版本声明本案例使用的 Spring Boot 版本为 2.1.4.RELEASE，Spring Cloud Alibaba Sentinel 版本为 2.1.3.RELEASE，Sentinel 1.8.0。以下代码，默认都通过 Sentinel 控制台动态配置流控规则来测试，具体不再累述，点击下载完整的案例代码。 添加 Maven 依赖1234567891011121314151617181920212223242526&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud-starter-sentinel&gt;2.1.3.RELEASE&lt;/spring-cloud-starter-sentinel&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-starter-sentinel}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 如果不需要使用注解的方式来定义 Sentinel 资源，一般只需要引入以下两个依赖即可，此时启动应用时需要添加 JVM 参数来连接 Sentinel 控制台。否则需要引入 spring-cloud-starter-alibaba-sentinel 依赖，才能让 @SentinelResource 注解生效。 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt; &lt;version&gt;1.8.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 application.yml12345678910server: port: 8080spring: application: name: sentinel-resource-define-demo cloud: sentinel: transport: dashboard: 127.0.0.1:9000 抛出异常的方式定义资源Sentinel 的 SphU 包含了 try-catch 风格的 API。用这种方式，当资源发生了限流之后就会抛出 BlockException 异常。这个时候可以捕获异常，进行限流之后的逻辑处理，而在上述的入门案例中就使用了此种方式进行定义资源，关键代码如下： 123456789101112131415161718192021@RestControllerpublic class TestController { /** * 资源名称 */ private static final String RESOURCE_NAME = \"Hello\"; @GetMapping(\"/hello\") public String hello() { // 使用流控规则 try (Entry entry = SphU.entry(RESOURCE_NAME)) { // 被保护的资源 return \"Hello Sentinel!\"; } catch (Exception e) { // 被限流 e.printStackTrace(); return \"系统繁忙，请稍后 ...\"; } }} 返回布尔值方式定义资源Sentinel 的 SphO 提供 if-else 风格的 API，用这种方式，当资源发生了限流之后就会返回 false，这个时候可以根据返回值，进行限流之后的逻辑处理。 123456789101112131415161718192021222324252627@RestControllerpublic class TestBooleanController { /** * 资源名称 */ private static final String RESOURCE_NAME = \"Boolean\"; @GetMapping(\"/boolean\") public boolean hello() { // 使用流控规则 if (SphO.entry(RESOURCE_NAME)) { // 被保护的资源 try { System.out.println(\"Hello Sentinel!\"); return true; } finally { // 限流的出口 SphO.exit(); } } else { // 被限流 System.out.println(\"系统繁忙，请稍后 ...\"); return false; } }} 特别注意：SphO.entry() 需要与 SphO.exit() 方法成对出现，否则会导致调用链记录异常，抛出 ErrorEntryFreeException 异常。 异步调用方式定义资源Sentinel 支持异步调用链路的统计，在异步调用中，需要通过 SphU.asyncEntry() 方法定义资源，并在需要异步的回调函数中调用 exit() 方法。 1234567891011/** * @EnableAsync 启用Spring的异步调用支持 */@SpringBootApplication@EnableAsyncpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); }} 1234567891011121314151617@Servicepublic class AsyncService { /** * @Async 表示异步调用方法 */ @Async public void hello() { System.out.println(\"start async method ...\"); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"end async method ...\"); }} 12345678910111213141516171819202122232425262728@RestControllerpublic class TestAsyncController { private static final String RESOURCE_NAME = \"Async\"; @Autowired private AsyncService asyncService; @GetMapping(\"/async\") public void hello() { AsyncEntry asyncEntry = null; try { // 使用流控规则 asyncEntry = SphU.asyncEntry(RESOURCE_NAME); // 被保护的资源 asyncService.hello(); } catch (BlockException e) { // 被限流 e.printStackTrace(); System.out.println(\"系统繁忙，请稍后 ...\"); } finally { if (asyncEntry != null) { // 限流的出口 asyncEntry.exit(); } } }} 注解方式定义资源 通过 @SentinelResource 注解的 blockHandler 属性制定具体的限流处理方法 实现处理方法，该方法的传参必须与资源点的传参一样，并且最后必须加上 BlockException 异常参数，同时返回类型也必须一样 从 1.4.0 版本开始，使用注解的方式定义资源，默认支持自动统计业务异常，无需再手动调用 Tracer.trace(ex) 来记录业务异常 更多注解属性说明，可以看这里 1234567891011121314151617181920212223242526272829303132@RestControllerpublic class TestAnnotationController { /** * 资源名称 */ private static final String RESOURCE_NAME = \"Annotation\"; /** * @return * @SentinelResource 定义资源 * value：资源名称 * blockHandler：限流处理的方法 */ @SentinelResource(value = RESOURCE_NAME, blockHandler = \"exceptionHandler\") @GetMapping(\"/annotation\") public String hello() { // 被保护的资源 return \"Hello Sentinel!\"; } /** * 原方法被限流的时候调用此方法 * * @param e * @return */ public String exceptionHandler(BlockException e) { e.printStackTrace(); return \"系统繁忙，请稍候 ...\"; }} 下篇 - Sentinel 入门教程（中级篇） Sentinel 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Nacos 入门教程 - 服务发现基础篇","url":"/posts/f9da4c12.html","text":"服务发现介绍微服务架构概述为适应企业的业务发展，提高软件研发的生产力，降低软件研发的成本，软件架构也作了升级和优化，将一个独立的系统拆分成若干小的服务，每个小服务运行在不同的进程中，服务与服务之间采用 RESTful、RPC 等协议传输数据，每个服务所拥有的功能具有独立性强的特点，这样的设计就实现了单个服务的高内聚，服务与服务之间的低耦合效果，这些小服务就是微服务，基于这种方法设计的系统架构即微服务架构。微服务架构的优点如下： 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰，代码量较少 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 业务之间松耦合，无论是在开发阶段或者部署阶段，不同的服务都是互相独立的 局部修改容易部署：单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈 按需伸缩：可根据需求，实现细粒度的扩展 只有业务逻辑的代码，不会和 HTML、CSS 或者其他前端页面耦合，目前有两种开发模式：前后端分离、全栈开发 什么是服务发现在微服务架构中，整个系统会按职责能力划分为多个服务，通过服务之间协作来实现业务目标。这样在代码中免不了要进行服务间的远程调用，服务的消费方要调用服务的生产方，为了完成一次请求，消费方需要知道服务生产方的网络位置（IP 地址和端口号）。一般情况下，代码可以通过读取配置文件的方式读取服务生产方网络位置，如下图所示： 看上去很完美，但是仔细考虑以下，此方案对于微服务应用而言行不通。首先，微服务可能是部署在云环境的，服务实例的网络位置或许是动态分配的。另外，每一个服务一般会有多个实例来做负载均衡，由于宕机或升级，服务实例网络地址会经常动态改变。再者，每一个服务也可能应对临时访问压力增加新的服务节点，如下图所示： 基于以上的问题，服务之间如何相互发现？服务如何管理？这就是服务发现的问题了。服务发现就是服务消费方通过服务发现中心智能发现服务提供方，从而进行远程调用的过程，如下图所示： 上图中服务实例本身并不记录服务生产方的网络地址，所有服务实例内部都会包含服务发现客户端。 在每个服务启动时会向服务发现中心上报自己的网络位置，这样在服务发现中心内部会形成一个服务注册表，服务注册表是服务发现的核心部分，是包含所有服务实例的网络地址的数据库 服务发现客户端会定期从服务发现中心同步服务注册表，并缓存在客户端 当需要对某服务进行请求时，服务实例通过该注册表，定位目标服务网络地址。若目标服务存在多个网络地址，则使用负载均衡算法从多个服务实例中选择出一个，然后发出请求。 总结： 在微服务环境中，由于服务运行实例的网络地址是不断动态变化的，服务实例数量的动态变化 ，因此无法使用固定的配置文件来记录服务提供方的网络地址，必须使用动态的服务发现机制用于实现微服务间的相互感知。各服务实例会上报自己的网络地址，这样服务中心就形成了一个完整的服务注册表，各服务实例会通过服务发现中心来获取访问目标服务的网络地址，从而实现服务发现的机制。 服务发现协作流程 服务发现产品对比 Nacos 作为服务发现中心，具备更多的功能支持项，且从长远来看 Nacos 在以后的版本会支持 Spring Cloud + Kubernetes 的组合，填补两者者的鸿沟，在两套体系下可以采用同一套服务发现和配置管理的解决方案，这将大大的简化使用和维护的成本。另外，Nacos 计划实现 Service Mesh，也是未来微服务发展的趋势，更多关于 Nacos 的介绍可以看这里。 Nacos 服务发现管理服务发现数据模型Nacos 在经过阿里内部多年生产经验后提炼出的数据模型，是一种服务 - 集群 - 实例的三层模型，这样基本可以满足服务在所有场景下的数据存储和管理。 命名空间（Namespace） 用于进行租户粒度的配置隔离，命名空间不仅适用于 Nacos 的配置管理，同样适用于服务发现。Namespace 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。 服务 提供给客户端的软件功能，通过预定义接口进行网络访问。 服务名 服务提供方的标识，通过该标识可以唯一确定其指代的服务。 实例 提供一个或多个服务的具有可访问网络地址（IP:Port）的进程，启动一个服务，就产生了一个服务实例。 元信息 Nacos 数据（如配置和服务）描述信息，如服务版本、权重、容灾策略、负载均衡策略、鉴权配置、各种自定义标签 (label），从作用范围来看，分为服务级别的元信息、集群的元信息及实例的元信息 集群 服务实例的集合，服务实例组成一个默认集群，集群可以被进一步按需求划分，划分的单位可以是虚拟集群，相同集群下的实例才能相互感知。 服务发现配置示例应用通过 Namespace、Cluster、Service 的配置，描述了该服务向哪个环境（如开发环境）的哪个集群注册实例 123456789spring: application: name: transaction‐service cloud: nacos: discovery: server‐addr: 127.0.0.1:8848 namespace: a1f8e863‐3117‐48c4‐9dd3‐e9ddc2af90a8 cluster-name: DEFAULT 集群作为实例的隔离，相同集群的实例才能相互感知 namespace、cluster-name 若不填写都将采用默认值，namespace 的默认是 public 命名空间，cluster-name 的默认值为 DEFAULT 集群 服务发现管理功能服务管理 开发者或者运维人员往往需要在服务注册后，通过友好的界面来查看服务的注册情况，包括当前系统注册的所有服务和每个服务的详情。并在有权限控制的情况下，进行服务的一些配置的编辑操作。Nacos 在目前最新版本开放的控制台的服务发现部分，主要就是提供用户一个基本的运维页面，能够查看、编辑当前注册的服务，这些功能集中在 Nacos 控制台的服务管理一级菜单内。 服务列表管理 服务列表帮助用户以统一的视图管理其所有的微服务以及服务健康状态。整体界面布局是左上角有服务的搜索框和搜索按钮，页面中央是服务列表的展示。服务列表主要展示服务名、集群数目、实例数目、健康实例数目和详情按钮五个栏目。 服务流量权重支持及流量保护 Nacos 为用户提供了流量权重控制的能力，同时开放了服务流量的阈值保护，以帮助用户更好的保护服务服务提供者集群不被意外打垮。如下图所示，可以点击实例的 编辑 按钮，修改实例的权重。如果想增加实例的流量，可以将权重调大；如果不想实例接收流量，则可以将权重设为 0。 服务元数据管理 Nacos 提供多个维度的服务元数据的暴露，帮助用户存储自定义的信息。这些信息都是以 K-V 的数据结构存储，在控制台上，会以 JSON 数据格式来展示。类似的，编辑元数据可以通过相同的格式进行。例如服务的元数据编辑，首先点击服务详情页里的 编辑 按钮，然后在元数据输入框输入：{\"version\": 1.0}。 服务优雅上下线 Nacos 还提供服务实例的上下线操作，在服务详情页面，可以点击实例的 上线 或者 下线 按钮，被下线的实例，将不会包含在健康的实例列表里。 Nacos Discovery Spring 入门案例1.0、版本说明在本案例中，Spring 的版本为 5.2.x，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 1.1、添加 Maven 依赖12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.12.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-spring-context&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 1.2、创建 Nacos 配置类通过添加 @EnableNacosDiscovery 注解开启 Nacos Spring 的服务发现功能 1234567891011121314package com.nacos.study.configuration;import com.alibaba.nacos.api.annotation.NacosProperties;import com.alibaba.nacos.spring.context.annotation.discovery.EnableNacosDiscovery;import org.springframework.context.annotation.Configuration;/** * @author clay */@Configuration@EnableNacosDiscovery(globalProperties = @NacosProperties(serverAddr = \"127.0.0.1:8848\"))public class NacosConfiguration {} 1.3、创建 Controller 测试类使用 @NacosInjected 注入 Nacos 的 NamingService 实例，通过该实例获取 Nacos Server 的服务列表 123456789101112131415161718192021222324252627282930package com.nacos.study.controller;import com.alibaba.nacos.api.annotation.NacosInjected;import com.alibaba.nacos.api.exception.NacosException;import com.alibaba.nacos.api.naming.NamingService;import com.alibaba.nacos.api.naming.pojo.Instance;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import java.util.List;/** * @author clay */@Controller@RequestMapping(\"/discovery\")public class DiscoveryController { @NacosInjected private NamingService namingService; @RequestMapping(value = \"/get\", method = RequestMethod.GET) @ResponseBody public List&lt;Instance&gt; get(@RequestParam(defaultValue = \"\") String serviceName) throws NacosException { return namingService.getAllInstances(serviceName); }} 1.4、配置 web.xml12345678910&lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 1.5、配置 dispatcherServlet-servlet.xml1234567&lt;!-- Spring MVC Annotation-Driven --&gt;&lt;mvc:annotation-driven/&gt;&lt;!-- Spring Context Annotation-Driven --&gt;&lt;context:annotation-config/&gt;&lt;context:component-scan base-package=\"com.nacos.study\"/&gt; 1.6、调用 Nacos Open API 注册服务调用 Nacos Open API 注册一个名称为 example 的服务，这里模拟了服务生产者自动注册服务到 Nacos Server。由于注册的服务不是真实存在的，因此服务注册一段时间后，会因 Nacos Server 的健康检查机制而被剔除出服务列表 1$ curl -X PUT 'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=example&amp;ip=127.0.0.1&amp;port=8080' 1.7、测试应用程序 将 Spring Web 应用部署到 Tomcat 服务器 浏览器访问 http://127.0.0.1:8080/discovery/get?serviceName=example，若响应结果如下，则说明程序运行正常 1234567891011121314151617181920[ { \"instanceId\": \"127.0.0.1#8080#DEFAULT#DEFAULT_GROUP@@example\", \"ip\": \"127.0.0.1\", \"port\": 8080, \"weight\": 1.0, \"healthy\": true, \"enabled\": true, \"ephemeral\": true, \"clusterName\": \"DEFAULT\", \"serviceName\": \"DEFAULT_GROUP@@example\", \"metadata\": { }, \"instanceHeartBeatInterval\": 5000, \"instanceHeartBeatTimeOut\": 15000, \"ipDeleteTimeout\": 30000, \"instanceIdGenerator\": \"simple\" }] Nacos Discovery Spring Boot 入门案例2.0、版本说明在本案例中，Spring Boot 的版本为 2.0.3.RELEASE，对应的 Nacos Discovery Spring Boot 的版本为 0.2.7，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 2.1、添加 Maven 依赖特别注意，Nacos Spring Boot Starter 版本 0.2.x.RELEASE 对应的是 Spring Boot 2.x 版本，版本 0.1.x.RELEASE 对应的是 Spring Boot 1.x 版本。 12345678910111213141516171819202122232425&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;nacos-discovery-spring-boot.version&gt;0.2.7&lt;/nacos-discovery-spring-boot.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-discovery-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${nacos-discovery-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.2、创建启动主类1234567@SpringBootApplicationpublic class NacosDiscoveryApplication { public static void main(String[] args) { SpringApplication.run(NacosDiscoveryApplication.class, args); }} 2.3、创建 Controller 测试类使用 @NacosInjected 注入 Nacos 的 NamingService 实例，通过该实例获取 Nacos Server 的服务列表 12345678910111213@Controller@RequestMapping(\"/discovery\")public class DiscoveryController { @NacosInjected private NamingService namingService; @RequestMapping(value = \"/get\", method = RequestMethod.GET) @ResponseBody public List&lt;Instance&gt; get(@RequestParam(defaultValue = \"\") String serviceName) throws NacosException { return namingService.getAllInstances(serviceName); }} 2.4、配置 application.properties在 application.properties 中配置 Nacos Server 的地址 1nacos.discovery.server-addr=127.0.0.1:8848 2.5、调用 Nacos Open API 注册服务调用 Nacos Open API 注册一个名称为 example 的服务，这里模拟了服务生产者自动注册服务到 Nacos Server。由于注册的服务不是真实存在的，因此服务注册一段时间后，会因 Nacos Server 的健康检查机制而被剔除出服务列表 1$ curl -X PUT 'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=example&amp;ip=127.0.0.1&amp;port=8080' 2.6、测试应用程序 启动 Spring Boot 应用 浏览器访问 http://127.0.0.1:8080/discovery/get?serviceName=example，若响应结果如下，则说明程序运行正常 1234567891011121314151617181920[ { \"instanceId\": \"127.0.0.1#8080#DEFAULT#DEFAULT_GROUP@@example\", \"ip\": \"127.0.0.1\", \"port\": 8080, \"weight\": 1.0, \"healthy\": true, \"enabled\": true, \"ephemeral\": true, \"clusterName\": \"DEFAULT\", \"serviceName\": \"DEFAULT_GROUP@@example\", \"metadata\": { }, \"instanceIdGenerator\": \"simple\", \"instanceHeartBeatInterval\": 5000, \"instanceHeartBeatTimeOut\": 15000, \"ipDeleteTimeout\": 30000 }] Nacos Discovery Spring Cloud 入门案例3.0、版本说明在本案例中，Spring Cloud 的版本是 Greenwich.SR6，对应的 Spring Boot 版本是 2.1.18.RELEASE，对应的 Nacos Discovery Spring Cloud 版本为 2.1.3.RELEASE，Nacos Server 的版本为 1.4.0，Nacos 官方版本说明可以看这里，点击下载完整的案例代码。 3.1、创建 Maven 父工程在 Maven 父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下。特别注意，Nacos Spring Cloud Starter 版本 2.1.x.RELEASE 对应的是 Spring Boot 2.1.x 版本，版本 2.0.x.RELEASE 对应的是 Spring Boot 2.0.x 版本，版本 1.5.x.RELEASE 对应的是 Spring Boot 1.5.x 版本，Nacos 官方版本说明可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;nacos-discovery-spring-cloud.version&gt;2.1.3.RELEASE&lt;/nacos-discovery-spring-cloud.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;${nacos-discovery-spring-cloud.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.2、创建 Provider Service 工程创建 Provider Service 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-discovery 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，将服务注册到 Nacos Server 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Controller 测试类 123456789@RestController@RequestMapping(\"/provider\")public class ProviderController { @GetMapping(\"/call\") public String call() { return \"provider invoke\"; }} 在 application.properties 中配置 Nacos Server 的地址 12345678910server: port: 56011spring: application: name: provider-service cloud: nacos: discovery: server-addr: 127.0.0.1:8848 3.3、创建 Consumer Service 工程创建 Consumer Service 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-alibaba-nacos-discovery 依赖，由于需要通过 Feign Client 调用远程服务，因此还需要引入 spring-cloud-starter-openfeign 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建主启动类，添加 @EnableDiscoveryClient 注解，将服务注册到 Nacos Server，同时添加 @EnableFeignClients 注解来启用 Feign Client 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建服务接口类，用于调用 Provider Service 暴露的 API 1234567@FeignClient(\"provider-service\")public interface ProviderClient { @GetMapping(\"/provider/call\") public String call();} 创建 Controller 测试类，因为需要创建一个 API 来供第三方调用 Provider Service 的那个自定义 API 12345678910111213@RestController@RequestMapping(\"/consumer\")public class ConsumerController { @Autowired private ProviderClient providerClient; @GetMapping(\"/call\") public String call() { return \"consumer invoke | \" + providerClient.call(); }} 在 application.properties 中配置 Nacos Server 的地址 12345678910server: port: 56010spring: application: name: consumer-service cloud: nacos: discovery: server-addr: 127.0.0.1:8848 3.4、测试应用程序 1）分别启动 nacos-provider-service、nacos-consumer-service 应用 2）浏览器访问 http://127.0.0.1:56011/provider/call，若响应结果为 provider invoke，则说明 nacos-provider-service 应用运行正常 3）浏览器访问 http://127.0.0.1:56010/consumer/call，若响应结果为 consumer invoke | provider invoke，则说明 nacos-consumer-service 应用运行正常 4）在 Nascos Server 的控制台，可以看到已经有两个服务成功注册了，如下图： 5）若希望测试多实例（Provider）的负载均衡调用情况，可以修改 Provider Service 工程下的 application.properties 配置文件里的 server.port 参数（如下），然后通过 -Dport=xxxxx VM 参数指定不同的端口来启动多个 Provider Service 应用即可 12server: port: ${port:56011} 补充内容Endpoint 支持Endpoint 查看Spring Boot 支持这一点，Nacos Discovery 也可以使用 Endpoint 来暴露信息，先决条件是将依赖 spring-boot-starter-actuator 添加到 pom.xml 文件中，并配置端点的访问策略。 Spring Boot 1.x 中添加端点访问策略的配置 management.security.enabled = false Spring Boot 2.x 中添加端点访问策略的配置 management.endpoints.web.exposure.include = * Spring Boot 1.x 中 Nacos Discovery 端点查看的 URL 是 http://127.0.0.1:18083/nacos_discovery Spring Boot 2.x 中 Nacos Discovery 端点查看的 URL 如下所示，不同 Nacos Discovery 版本可能有所差异 第一种：http://127.0.0.1:18083/actuator/nacosdiscovery 第二种：http://127.0.0.1:18083/actuator/nacos-discovery 值得一提的是，http://127.0.0.1:18083/actuator/nacosdiscovery 的 127.0.0.1:18083 是 Spring Cloud 应用（业务）占用的 IP 和端口 Endpoint 配置示例 引入 Actuator 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置端点的访问策略（Spring Boot 2.x） 12345678management: endpoints: web: exposure: include: \"*\" endpoint: health: show-details: ALWAYS 端点访问策略配置 management.endpoint.health.show-details=ALWAYS：何时显示完整的健康信息，默认为 NEVER 都不展示。可选 WHEN_AUTHORIZED 当经过授权的用户；可选 ALWAYS 总是显示。 management.endpoints.web.exposure.include=*：需要开放的端点，默认值只打开 health 和 info 这两个端点。通过设置 * ，可以开放所有端点（生产环境不建议这样配置）。 Nacos 注册发现原理浅析服务注册Spring Cloud Nacos Discovery 遵循了 Spring Cloud Common 标准，实现了 AutoServiceRegistration、ServiceRegistry、Registration 这三个接口。在 Spring 应用程序的启动阶段，将监视 WebServerInitializedEvent 事件。在初始化 Web 容器后收到 WebServerInitializedEvent 事件时，将触发注册操作，并调用 ServiceRegistry 注册方法以将服务注册到 Nacos Server。 服务发现NacosServerList 实现 com.netflix.loadbalancer.ServerList 接口，并在 @ConditionOnMissingBean 下自动注入它。如果有定制化的需求，可以实现自己的 ServerList。由于 Nacos Discovery Starter 默认集成了 Ribbon ，所以对于使用了 Ribbon 做负载均衡的组件，可以直接使用 Nacos 的服务发现。 Nacos 服务发现常用配置说明 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Nacos 入门教程 - 配置管理高级篇","url":"/posts/cc563108.html","text":"上篇 - Nacos 入门教程 - 配置管理（中级篇） Nacos 入门教程 - 配置管理中级篇 Nacos Server 集群部署模式Nacos Server 支持三种部署模式： 单机模式 - 用于测试和单机试用 集群模式 - 用于生产环境，确保高可用 多集群模式 - 用于多数据中心场景 集群搭建安装 Nacos Server集群环境下，至少需要安装三台以上的 Nacos Server，一般情况下复制三份 Nacos Server 解压后的文件夹即可，分别命名为 nacos-1、nacos-2、nacos-3。 配置 IP 与 端口 若是单机搭建 Nacos Server 集群，则需要更改每台 Nacos Server 目录的 conf 目录下的 application.properties 配置文件，通过 server.port 参数让每台 Nacos Server 使用不同的端口，以此来避免端口冲突。 在生产环境中，若每台 Nacos Sever 都有独立的真实 IP 地址，或者单台 Nacos Server 拥有多块网卡时，则需要在每台 Nacos Server 目录的 conf 目录下的 application.properties 配置文件里通过 nacos.inetutils.ip-address 参数绑定真实的 IP 地址。 12server.port=8848nacos.inetutils.ip-address=192.168.1.124 配置集群配置文件在所有 Nacos Server 目录的 conf 目录下找到 cluster.conf.example 配置文件，将其重命名为 cluster.conf，并将所有 Nacos Server 的 IP 地址以 ip:port 的格式写到配置文件里，配置示例如下： 特别注意：这里的 IP 不能写 127.0.0.1，必须是 Linux 命令 hostname -i 能够识别的 IP 123192.168.1.124:8848 # Nacos Server 1192.168.1.124:8849 # Nacos Server 2192.168.1.124:8850 # Nacos Server 3 配置 MySQL 数据源Nacos Server 默认使用嵌入式数据库（Derby）实现数据的存储，若直接启动多个默认配置下的 Nacos Server 节点，数据存储会存在一致性的问题。为了解决这个问题，Nacos Server 采用了集中存储的方式来支持集群化部署，目前只支持 MySQL 的存储（5.6.5+）。由于前面的教程已经介绍过 Nacos Server 如何配置 MySQL 数据源，这里不再累述。值得一提的是，每台 Nacos Server 都需要单独配置 MySQL 数据源。 集群模式下启动启动 Nacos Server 集群，需要分别在每台 Nacos Server 目录的 bin 目录下执行启动脚本 123$ sh nacos-1/bin/startup.sh$ sh nacos-2/bin/startup.sh$ sh nacos-3/bin/startup.sh 若每台 Nacos Server 在启动时输出以下日志信息，说明 Nacos Server 是以集群模式启动了 12nacos is starting with clusternacos is starting，you can check the /nacos-x/logs/start.out 集群模式下关闭若希望关闭 Nacos Server 集群，同样分别在每台 Nacos Server 目录的 bin 目录下执行关闭脚本即可 123$ sh nacos-1/bin/shutdown.sh$ sh nacos-2/bin/shutdown.sh$ sh nacos-3/bin/shutdown.sh Spring Cloud 配置集群Spring Cloud 配置 Nacos 集群的示例如下： 1234567spring: application: name: service cloud: nacos: config: server-addr: 192.168.1.124:8848,192.168.1.124:8849,192.168.1.124:8850 # 当不使用Nginx作为负载均衡服务时，可以直接填写多个Nacos Server节点的IP 集群启动的失败解决方案若机器不能同时启动三个 Nacos Server 实例，建议检查是否内存不够，此时可以在每台 Nacos Server 目录的 bin 目录下的 startup.sh 启动脚本里适当调整 JVM 的内存参数 12$ vim startup.shJAVA_OPT=\"${JAVA_OPT} -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" 集群部署架构（高可用）多种部署模式 http://ip1:port/openAPI：直连 IP 模式，机器宕机则需要修改 IP 才可以使用 http://VIP:port/openAPI：挂载 VIP 模式，直连 VIP 即可，下面挂载 Server 真实 IP，可读性不好 http://nacos.com:port/openAPI：域名 + VIP 模式，可读性好，而且换 IP 方便，当 Nacos 集群迁移时客户端也无需修改，推荐使用此模式，部署架构图如下图所示： Nginx 反向代理配置在 Nacos Server 的集群启动完毕之后，根据上面的部署架构图所示，还需要提供一个统一的入口给 Spring Cloud 应用访问。简单地说，就是需要为上面启动的的三个 Nacos Server 节点做一个可以为它们实现负载均衡的访问点。这个实现的方式非常多，可以考虑使用 Nginx 来实现，配置示例如下。特别注意，考虑到 Nginx 的高可用性，建议使用 Nginx + Keepalive 来搭建 Nginx 集群。 123456789101112131415upstream nacos { server 192.168.1.124:8848; server 192.168.1.124:8849; server 192.168.1.124:8850;}server { listen 80; server_name nacos.a-hh.cn; location / { proxy_pass http://nacos; }} MySQL 数据库高可用在 Nacos Server 集群模式下，当采用 MySQL 作为外置数据源时，为了确保数据库的高可用性，在生产环境下建议 MySQL 至少使用主备模式，或者采用高可用数据库。可通过修改 ${nacos-home}/conf/application.properties 配置文件，让 Nacos Server 拥有多个数据源，配置示例如下： 1234567spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://192.168.1.1:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.url.1=jdbc:mysql://192.168.1.2:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user=rootdb.password=123456 特别注意：若 MySQL 配置了主从库（主从同步），当主库宕机后，切换到从库，此时切到从库后会导致主库的数据比从库少，即会出现数据不一致的问题。 集群高可用部署架构图 多集群模式Nacos Server 支持 NameServer 路由请求模式，通过它可以设计一个有用的映射规则来控制请求转发到相应的集群，在映射规则中可以按命名空间或租户等分片请求。 多网卡 IP 选择 当本地环境比较复杂的时候，Nacos 服务在启动的时候需要选择运行时使用的 IP 或者网卡。Nacos Server 从多网卡获取 IP 参考了 Spring Cloud 设计，通过 nacos.inetutils 参数，可以指定 Nacos 使用的网卡和 IP 地址，目前支持的配置参数有： ip-address 参数可以直接设置 Nacos 的 IP 1nacos.inetutils.ip-address=10.11.105.155 use-only-site-local-interfaces 参数可以让 Nacos 使用局域网 IP，这个在 Nacos 部署的机器有多网卡时很有用，可以让 Nacos 选择局域网网卡 1nacos.inetutils.use-only-site-local-interfaces=true ignored-interfaces 支持网卡数组，可以让 Nacos 忽略多个网卡 12- nacos.inetutils.ignored-interfaces[0]=eth0- nacos.inetutils.ignored-interfaces[1]=eth1 preferred-networks 参数可以让 Nacos 优先选择匹配的 IP，支持正则匹配和前缀匹配 12nacos.inetutils.preferred-networks[0]=30.5.124.nacos.inetutils.preferred-networks[0]=30.5.124.(25[0-5]|2[0-4]\\\\d|((1d{2})|([1-9]?\\\\d))),30.5.124.(25[0-5]|2[0-4]\\\\d|((1d{2})|([1-9]?\\\\d))) Docker 安装 Nacos Server Docker 安装 Nacos 单机和集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Nacos 入门教程 - 配置管理中级篇","url":"/posts/35766a62.html","text":"上篇 - Nacos 入门教程 - 配置管理（基础篇） Nacos 入门教程 - 配置管理基础篇 Nacos Config Spring 入门案例1.0、版本说明在本案例中，Spring 的版本为 5.2.x，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 1.1、发布配置12345Namespace: publicData ID: nacos_config_spring_demo.propertiesGroup: DEFAULT_GROUP配置格式: Properties配置内容: useLocalCache=true 1.2 、添加 Maven 依赖12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.12.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-spring-context&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 1.3、创建 Nacos 配置类添加 @EnableNacosConfig 注解启用 Nacos Spring 的配置管理服务，其中使用 @NacosPropertySource 加载了 dataId 为 nacos_config_spring_demo.properties 的配置集，并开启自动更新 12345678910111213141516package com.nacos.study.config;import com.alibaba.nacos.api.annotation.NacosProperties;import com.alibaba.nacos.spring.context.annotation.config.EnableNacosConfig;import com.alibaba.nacos.spring.context.annotation.config.NacosPropertySource;import org.springframework.context.annotation.Configuration;/** * @author clay */@Configuration@EnableNacosConfig(globalProperties = @NacosProperties(serverAddr = \"127.0.0.1:8848\"))@NacosPropertySource(dataId = \"nacos_config_spring_demo.properties\", autoRefreshed = true)public class NacosConfiguration {} 1.4、创建 Controller 测试类通过 Nacos 的 @NacosValue 注解设置属性值 123456789101112131415161718192021222324package com.nacos.study.controller;import com.alibaba.nacos.api.config.annotation.NacosValue;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;/** * @author clay */@Controller@RequestMapping(\"/config\")public class ConfigController { @NacosValue(value = \"${useLocalCache:false}\", autoRefreshed = true) private boolean useLocalCache; @ResponseBody @RequestMapping(value = \"/get\", method = RequestMethod.GET) public boolean get() { return useLocalCache; }} 1.5、配置 web.xml12345678910&lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 1.6、配置 dispatcherServlet-servlet.xml1234567&lt;!-- Spring MVC Annotation-Driven --&gt;&lt;mvc:annotation-driven/&gt;&lt;!-- Spring Context Annotation-Driven --&gt;&lt;context:annotation-config/&gt;&lt;context:component-scan base-package=\"com.nacos.study\"/&gt; 1.7、测试应用程序 将 Spring Web 应用部署到 Tomcat 服务器 浏览器访问 http://127.0.0.1:8080/config/get，若响应结果为 true，则说明程序运行正常 Nacos Config Spring Boot 入门案例2.0、版本说明在本案例中，Spring Boot 的版本为 2.0.3.RELEASE，对应的 Nacos Config Spring Boot 的版本为 0.2.7，Nacos Server 的版本为 1.4.0，点击下载完整的案例代码。 2.1、发布配置12345Namespace: publicData ID: nacos_config_springboot_demo.propertiesGroup: DEFAULT_GROUP配置格式: Properties配置内容: useLocalCache=true 2.2、添加 Maven 依赖特别注意，Nacos Spring Boot Starter 版本 0.2.x.RELEASE 对应的是 Spring Boot 2.x 版本，版本 0.1.x.RELEASE 对应的是 Spring Boot 1.x 版本。 123456789101112131415161718192021222324252627282930313233&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;nacos-config-spring-boot.version&gt;0.2.7&lt;/nacos-config-spring-boot.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-actuator&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.3、创建启动主类使用 @NacosPropertySource 加载了 dataId 为 nacos_config_springboot_demo.properties 的配置集，并开启自动更新 12345678@SpringBootApplication@NacosPropertySource(dataId = \"nacos_config_springboot_demo.properties\", autoRefreshed = true)public class NacosConfigApplication { public static void main(String[] args) { SpringApplication.run(NacosConfigApplication.class, args); }} 2.4、创建 Controller 测试类通过 Nacos 的 @NacosValue 注解设置属性值 12345678910111213@Controller@RequestMapping(\"/config\")public class ConfigController { @NacosValue(value = \"${useLocalCache:false}\", autoRefreshed = true) private boolean useLocalCache; @ResponseBody @RequestMapping(value = \"/get\", method = RequestMethod.GET) public boolean get() { return useLocalCache; }} 2.5、配置 application.properties在 application.properties 中配置 Nacos Server 的地址 1nacos.config.server-addr=127.0.0.1:8848 2.6、测试应用程序 启动 Spring Boot 应用 浏览器访问 http://127.0.0.1:8080/config/get，若响应结果为 true，则说明程序运行正常 Nacos Config Spring Cloud 入门案例3.0、版本说明在本案例中，Spring Cloud 的版本是 Greenwich.SR6，对应的 Spring Boot 版本是 2.1.18.RELEASE，对应的 Nacos Config Spring Cloud 版本为 2.1.3.RELEASE，Nacos Server 的版本为 1.4.0，Nacos 官方版本说明可以看这里，点击下载完整的案例代码。 3.1、发布配置第一步：创建名称为 dev 的命名空间 第二步：在 dev 命名空间下新增两项配置，具体的配置内容如下： 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: service-1.yamlGroup: TEST_GROUP配置格式: YAML配置内容: common: name: service-1-config 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: service-2.yamlGroup: TEST_GROUP配置格式: YAML配置内容: common: name: service-2-config 3.2、创建 Maven 父工程在 Maven 父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体配置如下。特别注意，Nacos Spring Cloud Starter 版本 2.1.x.RELEASE 对应的是 Spring Boot 2.1.x 版本，版本 2.0.x.RELEASE 对应的是 Spring Boot 2.0.x 版本，版本 1.5.x.RELEASE 对应的是 Spring Boot 1.5.x 版本，Nacos 官方版本说明可以看这里。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.18.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;spring-cloud.version&gt;Greenwich.SR6&lt;/spring-cloud.version&gt; &lt;nacos-config-spring-cloud.version&gt;2.1.3.RELEASE&lt;/nacos-config-spring-cloud.version&gt;&lt;/properties&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;${nacos-config-spring-cloud.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 特别注意 若使用的 Spring Cloud 是高版本，例如 Spring Cloud 2021.0.1，则还需要引入 spring-cloud-starter-bootstrap 依赖（如下所示），否则 Spring Cloud 无法读取项目中的 bootstrap.yml 配置文件，导致 Maven 引入 Nacos 配置中心后无法生效，详细说明请看 这里。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;&lt;/dependency&gt; 3.3、创建 Service 1 工程创建 Service 1 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Service 1 的主启动类 1234567@SpringBootApplicationpublic class Service1Application { public static void main(String[] args) { SpringApplication.run(Service1Application.class, args); }} 创建 Service 1 的 Controller 测试类，添加 Spring Cloud 原生 @RefreshScope 注解来实现配置自动更新，或者手动通过 ConfigurableApplicationContext.getEnvironment().getProperty() 来实时获取最新的配置信息 12345678910111213@RestController@RequestMapping(\"/config\")@RefreshScopepublic class ConfigController { @Value(\"${common.name}\") private String config2; @GetMapping(\"/get\") public String get() { return config2; }} 添加 Service 1 需要的 bootstrap.yml 配置文件到工程中 12345678910111213server: port: 56010spring: application: name: service-1 cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 group: TEST_GROUP #配置分组 file-extension: yaml #由于当前环境对应的profile为空，这里的Data ID的名称就是application的name加上file-extension，即service-1.yaml 3.4、创建 Service 2 工程创建 Service 2 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Service 2 的主启动类 1234567@SpringBootApplicationpublic class Service2Application { public static void main(String[] args) { SpringApplication.run(Service2Application.class, args); }} 创建 Service 2 的 Controller 测试类，添加 Spring Cloud 原生 @RefreshScope 注解来实现配置自动更新，或者手动通过 ConfigurableApplicationContext.getEnvironment().getProperty() 来实时获取最新的配置信息 1234567891011121314151617181920@RestController@RequestMapping(\"/config\")public class ConfigController { @Value(\"${common.name}\") private String config2; @Autowired private ConfigurableApplicationContext applicationContext; @GetMapping(\"/get\") private String get() { return config2; } @GetMapping(\"/getRealTime\") private String getRealTime() { return applicationContext.getEnvironment().getProperty(\"common.name\"); }} 添加 Service 2 需要的 bootstrap.yml 配置文件到工程中 12345678910111213server: port: 56011spring: application: name: service-2 cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 group: TEST_GROUP #配置分组 file-extension: yaml #由于当前环境对应的profile为空，这里的Data ID的名称就是application的name加上file-extension，即service-2.yaml 3.5、测试应用程序 分别启动 nacos-service-1、nacos-service-2 应用 浏览器访问 http://127.0.0.1:56010/config/get，若响应结果为 service-1-config，则说明 nacos-service-1 应用运行正常 通过 Nacos 的控制台更改 Data ID 为 service-1.yaml 的配置内容，然后再次访问 http://127.0.0.1:56010/config/get，若响应结果发生了变化，则说明 nacos-service-1 应用可以实时感知到 Nacos Server 的配置变更 参考步骤二和步骤三，测试 nacos-service-2 应用即可 Nacos Config Spring Cloud 常用配置配置信息的优先级 若本地配置文件（YML、Properties）和 Nacos 配置中心分别存放了相同的配置信息，Nacos Config Spring Cloud 会优先使用配置中心的配置信息，即配置中心的信息会覆盖本地的配置信息。 常用的配置参数在上面的 bootstrap.yaml 配置文件中，之所以需要配置 spring.application.name，是因为它是构成 Nacos 配置管理 dataId 字段的一部分，在 Nacos Spring Cloud 中，dataId 的完整格式如下： 1${prefix}-${spring.profiles.active}.${file-extension} group 默认为 DEFAULT_GROUP，可以通过 spring.cloud.nacos.config.group 来配置 prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置 namespace 默认为 public 命名空间的 ID，可以通过 spring.cloud.nacos.config.namespace 来配置，这里的值是 Namespace 的 ID file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置，目前只支持 properties 和 yaml 类型 spring.profiles.active 即为当前环境对应的 profile。特别注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式会变成 ${prefix}.${file-extension} 完整的配置参数 配置文件加载顺序若项目中同时存在 bootstrap.yaml 和 application.yml 配置文件，那么 Nacos Config Spring Cloud 的配置信息必须写在 bootstrap.yml 配置文件里，因为 Spring Boot 会优先加载 bootstrap.yml 配置文件。值得一提的是，bootstrap.yml 作用于应用程序上下文的引导阶段，bootstrap.yml 由父 Spring ApplicationContext 加载。 自定义 Data ID 配置自定义扩展 Data ID 配置在日常项目开发中，单个微服务可能拥有多个配置文件，对应的就是 Nacos 中的多个 Data ID（配置集），例如包括全局配置、局部配置等（如下图），而上面的案例只能使用配置单一的 Data ID（配置集），无法满足实际的开发需求。但 Nacos Config Spring CLoud 提供了自定义扩展 Data ID 的配置，以此来解决该问题。在以下案例中，首先通过 Nacos 的控制台新增了全局配置（extension-config-01.yaml）与默认配置（extension-config-02.yaml），然后在 bootstrap.yaml 配置文件中通过 extension-configs 标签来配置多个 Data ID（配置集），点击下载完整的案例代码。 使用场景 发布配置 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: extension-config-01.yamlGroup: GLOBAL_GROUP配置格式: YAML配置内容: common: address: 127.0.0.1 123456Namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18Data ID: extension-config-02.yamlGroup: DEFAULT_GROUP配置格式: YAML配置内容: common: threads: 2000 配置示例 值得一提的是，在旧版 Nacos Config Spring Cloud 中，使用的标签是 ext-config，下标都是从零开始，配置示例如下： 12345678910111213141516171819server: port: 56010spring: application: name: service cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 extension-configs[0]: data-id: extension-config-01.yaml group: GLOBAL_GROUP refresh: true extension-configs[1]: data-id: extension-config-02.yaml group: DEFAULT_GROUP refresh: true 通过 spring.cloud.nacos.config.extension-config[n].data-id 的配置方式来支持多个 Data ID 的配置 通过 spring.cloud.nacos.config.extension-config[n].group 的配置方式自定义 Data ID 所在的组，不配置的话，默认是 DEFAULT_GROUP 通过 spring.cloud.nacos.config.extension-config[n].refresh 的配置方式来控制该 Data ID 在配置变更时，是否支持在应用中可动态刷新，感知到最新的配置值，默认是不支持的 多个 Data ID 同时配置时，优先级关系是 spring.cloud.nacos.config.extension-config[n].data-id 其中 n 的值越大，优先级越高 spring.cloud.nacos.config.extension-config[n].data-id 的值必须带文件扩展名，文件扩展名支持 properties、yaml/yml，此时 spring.cloud.nacos.config.file-extension 的配置参数对自定义扩展配置的 Data ID 文件扩展名没有影响 Java 代码 12345678910111213141516@RestController@RequestMapping(\"/config\")@RefreshScopepublic class ConfigController { @Value((\"${common.address}\")) private String address; @Value(\"${common.threads}\") private String threads; @GetMapping(\"/get\") public String get() { return \"address: \" + address + \" threads: \" + threads; }} 自定义共享 Data ID 配置为了更加清晰地在多个应用间配置共享的 Data ID，可以使用 spring.cloud.nacos.config.shared-dataids 标签来定义 Data ID。值得一提的是，在新版的 Nacos Config Spring Cloud 中，使用的标签升级为 spring.cloud.nacos.config.shared-configs。当使用自定义共享 Data ID 配置的方式时，只能读取到配置分组（Group）为 DEFAULT_GROUP 的 Data ID，如果 Data ID 归属于其他非默认的配置分组（DEFAULT_GROUP），则无法读取对应的配置信息，所以自定义共享 Data ID 配置的方式在实际开发中使用频率较低。 配置示例 12345678910111213server: port: 56010spring: application: name: service cloud: nacos: config: server-addr: 127.0.0.1:8848 #配置中心的地址 namespace: 4bfcbae8-8c37-417d-89e4-d5134e23eb18 #命名空间 shared-dataids: shared-config-01.yaml,shared-config-02.yaml refreshable-dataids: shared-config-01.yaml 通过 spring.cloud.nacos.config.shared-dataids 来支持多个共享 Data ID 的配置，多个之间用逗号隔开 通过 spring.cloud.nacos.config.refreshable-dataids 来支持哪些共享配置的 Data ID 在配置变化时，在应用中是否可动态刷新，感知到最新的配置值，多个 Data ID 之间用逗号隔开。如果没有配置时，默认情况下所有共享配置的 Data ID 都不支持动态刷新 通过 spring.cloud.nacos.config.shared-dataids 来支持多个共享配置的 Data ID 时， 多个共享配置间的优先级关系由配置出现的先后顺序来决定，即后面的优先级要高于前面 通过 spring.cloud.nacos.config.shared-dataids 来配置时，Data ID 必须带文件扩展名，文件扩展名既可支持 properties、yaml/yml，此时 spring.cloud.nacos.config.file-extension 的配置参数对自定义共享配置的 Data ID 文件扩展名没有影响 spring.cloud.nacos.config.refreshable-dataids 配置哪些 Data ID 需要支持动态刷新时，Data ID 的值也必须明确给出文件扩展名 配置加载的优先级新版的 Nacos Config Spring Cloud 目前提供了三种配置能力从 Nacos 拉取相关的配置，具体如下： A: 通过 spring.cloud.nacos.config.shared-configs 支持多个共享 Data ID 的配置 B: 通过 spring.cloud.nacos.config.extension-configs[n].data-id 的方式支持多个扩展 Data ID 的配置 C: 通过内部相关规则（应用名 或者 应用名 + Profile），即 ${prefix}-${spring.profiles.active}.${file-extension} 规则来自动生成相关的 Data ID 配置 当三种方式共同使用时，优先级关系是： A &lt; B &lt; C 完全关闭配置若希望完全关闭 Nacos Config Spring Cloud，可以通过设置 spring.cloud.nacos.config.enabled=false 来关闭。 Nacos Config Spring Cloud 原理浅析自动注入Nacos Config Spring Cloud Starter 实现了 org.springframework.cloud.bootstrap.config.PropertySourceLocator 接口，并将优先级设置成了最高。在 Spring Cloud 应用启动阶段，会主动从 Nacos Server 端获取对应的数据，并将获取到的数据转换成 PropertySource 且注入到 Environment 的 PropertySources 属性中，所以使用 @Value 注解也能直接获取 Nacos Server 端配置的内容。 动态刷新Nacos Config Spring Cloud Starter 默认为所有获取数据成功的 Nacos 的配置项添加了监听功能，在监听到服务端配置发生变化时会实时触发 org.springframework.cloud.context.refresh.ContextRefresher 的 refresh() 方法 。如果需要对 Bean 进行动态刷新，给类添加 @RefreshScope 或 @ConfigurationProperties 注解即可。 补充内容Endpoint 支持Endpoint 信息查看Spring Boot 支持这一点，Nacos Config 也可以使用 Endpoint 来暴露信息。在 Maven 中添加 spring-boot-starter-actuator 依赖，并配置端点的访问策略。 Spring Boot 1.x 中添加端点访问策略的配置 management.security.enabled=false Spring Boot 2.x 中添加端点访问策略的配置 management.endpoints.web.exposure.include=* Spring Boot 1.x 中 Nacos Config 端点查看的 URL 是 http://127.0.0.1:18084/nacos_config Spring Boot 2.x 中 Nacos Config 端点查看的 URL 如下所示，不同 Nacos Config 版本可能有所差异 http://127.0.0.1:18084/actuator/nacosconfig http://127.0.0.1:18084/actuator/nacos-config 值得一提的是，http://127.0.0.1:18084/actuator/nacosconfig 的 127.0.0.1:18084 是 Spring Cloud 应用（业务）占用的 IP 和端口 Endpoint 配置示例 引入 Actuator 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置端点的访问策略（Spring Boot 2.x） 12345678management: endpoints: web: exposure: include: \"*\" endpoint: health: show-details: ALWAYS 端点访问策略配置 management.endpoint.health.show-details=ALWAYS：何时显示完整的健康信息，默认为 NEVER 都不展示。可选 WHEN_AUTHORIZED 当经过授权的用户；可选 ALWAYS 总是显示。 management.endpoints.web.exposure.include=*：需要开放的端点，默认值只打开 health 和 info 这两个端点。通过设置 * ，可以开放所有端点（生产环境不建议这样配置）。 下篇 - Nacos 入门教程 - 配置管理（高级篇） Nacos 入门教程 - 配置管理高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Linux 安装 RTL8812AU 无线 USB 网卡驱动","url":"/posts/e173757f.html","text":"前言 本文主要介绍如何在 Linux 系统里安装 RTL8812AU 无线 USB 网卡驱动，适用于 Debian、Ubuntu 18/19/20、Centos7/8，其中 Linux 的内核版本必须为大于等于 3.10。 检测系统是否正确识别 RTL8812AU 无线网卡 12# lsusb | grep RTL8812AUBus 003 Device 008: ID 0bda:8812 Realtek Semiconductor Corp. RTL8812AU 802.11a/b/g/n/ac 2T2R DB WLAN Adapter Ubuntu 18/19/20 手动安装 RTL8812AU 无线网卡驱动 12# 系统环境Linux Ubuntu-20 5.4.0-42-generic #46-Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux 12345678910111213141516171819# 安装工具软件# apt-get install -y git make# 克隆源码# git clone https://github.com/gnab/rtl8812au.git# 进入源码目录# cd rtl8812au# 编译驱动# make# 安装驱动# cp 8812au.ko /lib/modules/$(uname -r)/kernel/drivers/net/wireless# 更新模块依赖# depmod# 提示：执行完以上步骤后，正常情况下就可以在系统的设置面板里看到 RTL8812AU 无线 USB 网卡搜索到的 WiFi 列表；如果网卡驱动安装后不生效，可以尝试重启系统。 Ubuntu 18/19/20 通过 DKMS 安装 RTL8812AU 无线网卡驱动 当手动安装 RTL8812AU 无线网卡驱动后，如果 Linux 系统的内核版本升级了，那么 RTL8812AU 驱动就会失效，导致需要重新安装驱动才能正常使用无线网卡。为了解决 Linux 系统内核版本升级带来的问题，可以 通过 DKMS 自动重建并安装网卡驱动到新的内核中。值得注意的是，若通过 DKMS 安装网卡驱动，则无需再使用上面的方法手动安装网卡驱动了。 1234567891011121314151617181920# 安装工具软件# apt-get install -y git make build-essential dkms# 克隆源码# git clone https://github.com/gnab/rtl8812au.git# 进入源码目录# cd rtl8812au# 将网卡驱动安装到DKMS（若命令执行出错，请看本文后面给出的解决办法）# make dkms_install# 查看DKMS是否正确安装网卡驱动# dkms status8812au, 4.2.3, 5.4.0-42-generic, x86_64: installed# 配置系统引导时自动加载网卡驱动# echo 8812au | sudo tee -a /etc/modules# 提示：执行完以上步骤后，正常情况下就可以在系统的设置面板里看到 RTL8812AU 无线 USB 网卡搜索到的 WiFi 列表；如果网卡驱动安装后不生效，可以尝试重启系统。 若执行 make dkms_install 命令出现错误 Makefile:1085: *** unterminated call to function 'shell': missing ')'. Stop，此时可以更改 Makefile 的文件内容后，再次执行 make dkms_install 等命令。 123456789101112# 进入源码目录# cd rtl8812au# 查看网卡驱动的版本号# cat include/rtw_version.hdefine DRIVERVERSION \"v4.2.3\"# 编辑Makefile文件，手动指定网卡驱动的具体版本号# vim MakefileDRIVER_VERSION = 4.2.3# 提示：即找到Makefile文件中的 DRIVER_VERSION = $(shell grep \"#define DRIVERVERSION\" include/rtw_version.h | awk '{print $$3}' | tr -d v\\\")，并将其修改为 DRIVER_VERSION = 4.2.3 若需要从 DKMS 中卸载网卡驱动，可以执行以下命令： 12345# 进入源码目录# cd rtl8812au# 通过DKMS卸载网卡驱动# make dkms_remove Centos 7/8 YUM 安装 RTL8812AU 无线网卡驱动 由于亲测在 Centos7 系统环境下，通过上述的方法（手动 + DKMS）安装 RTL8812AU 无线网卡的驱动后，无法使无线网卡正常工作，因此可以通过 YUM 包来安装对应的网卡驱动。 12# 系统环境Linux Centos-7 3.10.0-1160.6.1.el7.x86_64 #1 SMP Tue Nov 17 13:59:11 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux 1234567# 安装网卡驱动# yum install kmod-rtl8812au# 查看网卡驱动是否安装成功（正常情况下，需要将无线USB网卡插到电脑上才会显示具体的驱动信息）# lsmod| grep \"XX\"88XXau 2189305 0cfg80211 710816 1 88XXau 可以使用以下常用的命令来判断 RTL8812AU 无线网卡是否正常工作，当然也可以在系统的设置面板里查看无线网卡的工作状态： 1234567891011# ifconfigwlp0s20u5: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500inet 192.168.0.117 netmask 255.255.255.0 broadcast 192.168.0.255inet6 fe80::bbf5:446d:e3ec:90fd prefixlen 64 scopeid 0x20inet6 2606:a000:810c:9300:9c04:74bc:9909:73d prefixlen 64 scopeid 0x0inet6 2606:a000:810c:9300::6 prefixlen 128 scopeid 0x0ether c4:41:1e:5d:7f:98 txqueuelen 1000 (Ethernet)RX packets 1480 bytes 999935 (976.4 KiB)RX errors 0 dropped 0 overruns 0 frame 0TX packets 1724 bytes 484480 (473.1 KiB)TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 12345678910# iwconfigwlp0s20u5 IEEE 802.11AC ESSID:\"SBG6900AC\" Nickname:\"WIFI@REALTEK\"Mode:Managed Frequency:5.745 GHz Access Point: 5C:E3:0E:96:D7:A0Bit Rate:174 Mb/s Sensitivity:0/0Retry:off RTS thr:off Fragment thr:offEncryption key:------- Security mode:openPower Management:offLink Quality=83/100 Signal level=36/100 Noise level=0/100Rx invalid nwid:0 Rx invalid crypt:0 Rx invalid frag:0Tx excessive retries:0 Invalid misc:0 Missed beacon:0 123# nmcli conNAME UUID TYPE DEVICESBG6900AC fd0097f7-2c89-4a2b-bb8e-a23e5d197ac2 wifi wlp0s20u5 12345# nmcli dev wifiIN-USE SSID MODE CHAN RATE SIGNAL BARS SECURITY TP-LINK_3BC402 Infra 6 270 Mbit/s 47 ▂▄__ -- Tenda_F73CF8 Infra 11 130 Mbit/s 37 ▂▄__ WPA1 WPA2 Tenda_58D840 Infra 10 130 Mbit/s 14 ▂___ WPA1 WPA2 参考资料 https://github.com/gnab/rtl8812au https://github.com/gnab/rtl8812au/issues/208 https://github.com/gnab/rtl8812au/issues/115 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux"},{"title":"Nacos 入门教程 - 配置管理基础篇","url":"/posts/ab6959cb.html","text":"配置中心介绍什么是配置中心在集中式开发时代，配置文件已经基本足够了，因为那时配置的管理通常不会成为一个很大的问题。但是在互联网时代，应用都是分布式系统，部署在 N 台服务器上，想要去线上一台台地重启机器肯定不靠谱，并且维护成本也很高，所以配置中心应运而生。配置中心被用作集中管理不同环境（Dev、Test、Stage、Prod）和不同集群配置，以及在修改配置后将实时动态推送到应用上进行刷新。配置中心应具备的功能如下： Open API 业务无关性 高可用集群 配置生效监控 配合灰度与更新 一致性 K-V 存储 统一配置实时推送 配置全局恢复、备份与历史 主流配置中心对比 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图一 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图二 Nacos 简介Nacos 概述Nacos 是构建以 “服务” 为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施，可以更敏捷和容易地构建、交付和管理微服务平台。Nacos 提供了一组简单易用的特性集，致力于快速实现动态服务发现、服务配置、服务元数据及流量管理。更多资料可参考：Nacos 项目、Nacos 官网、Nacos 官方中文文档、Nacos 官方示例代码、Nacos 官方博客 Nacos 功能动态配置服务 动态配置服务能够以中心化、外部化和动态化的方式管理所有环境的配置。动态配置消除了配置变更时重新部署应用和服务的需要。配置中心化管理让实现无状态服务更简单，也让按需弹性扩展服务更容易。 服务发现与服务健康监测 动态服务发现对以服务为中心的（例如微服务和云原生）应用架构方式非常关键。Nacos 支持 DNS-Based 和 RPC-Based（Dubbo、gRPC） 模式的服务发现。Nacos 也提供实时健康检查，以防止将请求发往不健康的主机或服务实例。借助 Nacos，可以更容易地为服务实现断路器。 动态 DNS 服务 通过支持权重路由，动态 DNS 服务能够轻松实现中间层负载均衡、更灵活的路由策略、流量控制以及简单数据中心内网的简单 DNS 解析服务。动态 DNS 服务还能更容易地实现以 DNS 协议为基础的服务发现，以消除耦合到厂商私有服务发现 API 上的风险。 服务及其元数据管理 Nacos 能从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的 SLA 以及最首要的 metrics 统计数据。 Nacos 特性易于使用 动态配置管理、服务发现和动态的一站式解决方案 20 多种开箱即用的以服务为中心的架构特性 基本符合生产要求的轻量级易用控制台 生产等级 脱胎于历经阿里巴巴 10 年生产验证的内部产品 支持具有数百万服务的大规模场景 具备企业级 SLA 的开源产品 更适应云架构 无缝支持 Kubernetes 和 Spring Cloud 在主流公共云上更容易部署和运行（例如阿里云和 AWS） 多租户和多环境支持 丰富的应用场景 支持限流、大促销预案和异地多活 直接支持或稍作扩展即可支持大量有用的互联网应用场景 流量调度和服务治理 Nacos 生态图如 Nacos 生态图所示，Nacos 无缝支持一些主流的开源生态，包括 Spring Cloud、Apache Dubbo、Dubbo Mesh、gRPC、Kubernetes 、CNCF 等。 Nacos 安装安装 Nacos安装环境准备Nacos 依赖 Java 环境运行，因此需要提前安装并配置 JDK，如果是从源码开始构建并运行 Nacos，还需要为此配置 Maven 环境，Nacos 依赖的软件环境如下： 64 Bit OS，支持 Unix/Linux/Mac/Windows 64 Bit JDK 1.8+ Maven 3.2.x+ Nacos 1.4.0 通过源码编译安装12345678910111213141516171819202122232425262728# 拉取源码$ git clone git@github.com:alibaba/nacos.git# 进入源码目录$ cd nacos# 编译打包$ mvn -Prelease-nacos clean install -U# 或者指定编译时跳过测试$ mvn -Prelease-nacos clean install -U -f pom.xml -Dmaven.test.skip=true# 进入编译后的bin目录$ cd distribution/target/nacos-server-1.4.0/nacos/bin# 单机模式下启动Nacos服务，默认端口为8848，默认使用内置数据源$ sh startup.sh -m standalone# 查看Nacos的进程状态$ ps -aux|grep nacos# 查看Nacos的端口状态$ netstat -anp|grep 8848# 关闭Nacos服务$ sh shutdown.sh# 提示： Nacos启动的日志文件路径为： nacos/distribution/target/nacos-server-1.4.0/nacos/logs/start.out 通过下载二进制包安装Nacos 下载地址点这里，下载后解压即可运行。 12345678910111213141516171819# 解压$ tar -xvf nacos-server-1.4.0.tar.gz# 进入bin目录$ cd nacos/bin# 单机模式下启动Nacos服务，默认端口为8848，默认使用内置数据源$ sh startup.sh -m standalone# 查看Nacos的进程状态$ ps -aux|grep nacos# 查看Nacos的端口状态$ netstat -anp|grep 8848# 关闭Nacos服务$ sh shutdown.sh# 提示： Nacos启动的日志文件路径为： nacos/logs/start.out 访问 Nacos 的 Web 控制台浏览器访问 http://127.0.0.1:8848/nacos，默认登录的用户名和密码为 nacos/nacos。 Open API 配置管理测试Nacos 启动成功后，可通过 Nacos 提供的 HTTP API 验证 Nacos 服务运行是否正常。 123# 新增配置信息到Nacos$ curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=HelloWorld\"true 刷新 Nacos 的 Web 控制台，可以看到刚新增的配置信息如下： 123# 从Nacos获取配置信息$ curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test\"HelloWorld 外部 MySQL 数据库支持（持久化配置）单机模式下 Nacos 默认使用嵌入式数据库 derby 来存储数据，若想使用外部 MySQL 数据库存储 Nacos 的数据，需要进行以下操作： 安装 MySQL 5.6.5+ 下载 Nacos Server 的二进制安装包并解压 创建数据库 nacos_config，执行 SQL 初始化脚本，数据库初始化脚本的路径为：${nacos-home}/conf/nacos-mysql.sql 12345678910111213141516171819202122232425262728# 创建数据库mysql&gt; create database nacos_config default character set utf8;# 切换数据库mysql&gt; use nacos_config;# 执行SQL初始化脚本mysql&gt; source ${nacos-home}/conf/nacos-mysql.sql;# 查看数据库表mysql&gt; show tables;+------------------------+| Tables_in_nacos_config |+------------------------+| config_info || config_info_aggr || config_info_beta || config_info_tag || config_tags_relation || group_capacity || his_config_info || permissions || roles || tenant_capacity || tenant_info || users |+------------------------+12 rows in set (0.00 sec) 修改 ${nacos-home}/conf/application.properties 配置文件，增加支持 MySQL 数据源的配置信息（目前只支持 MySQL），并添加 MySQL 数据库的 URL、用户名、密码，最后重新启动 Nacos 服务即可，配置示例如下： 123456spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://127.0.0.1:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user=rootdb.password=123456 若希望使用 Nacos Server 内置的数据源（嵌入式数据库），可以使用 -p embedded 参数来启动 Nacos Server 1sh startup.sh -p embedded Nacos 配置入门案例第一步：点击新增配置按钮浏览器访问 http://127.0.0.1:8848/nacos，打开 Nacos 的 Web 控制台，并找到菜单 配置管理 &gt; 配置列表，然后点击 新增 按钮： 第二步：新增配置信息在新增配置信息的表单里，填写如下的内容，然后点击 发布 按钮即可。特别注意的是，DataId 默认是以 properties 作为默认的文件扩展名。 第三步：查询配置信息 第四步：调用 Java API 获取 Nacos 的配置信息12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.exception.NacosException;import java.util.Properties;/** * 从Nacos读取配置信息 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException { String serverAddr = \"127.0.0.1:8848\"; String dataId = \"nacos_simple_demo.yaml\"; String group = \"DEFAULT_GROUP\"; Properties properties = new Properties(); properties.put(\"serverAddr\", serverAddr); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); }} 程序运行输出结果如下： 12common: config: something Nacos 配置管理基础Nacos 配置管理模型Nacos 配置管理概念对于 Nacos 的配置管理，是通过 Namespace、Group、Data ID 来定位到一个配置集。 配置项 配置集中包含的一个个配置内容就是配置项。它代表一个具体的可配置的参数与其值域，通常以 key=value 的形式存在。例如经常配置系统的日志输出级别（logLevel=INFO|WARN|ERROR） 就是一个配置项。 配置集（Data ID） 在系统中，一个配置文件通常就是一个配置集，一个配置集可以包含了系统的各种配置信息，例如一个配置集可能包含了数据源、线程池、日志级别等配置项。每个配置集都可以定义一个有意义的名称，就是配置集的 ID，即 Data ID。 配置分组（Group） 配置分组是对配置集进行分组，通过一个有意义的字符串（如 Buy 或 Trade ）来表示，不同的配置分组下可以有相同的配置集（Data ID）。当在 Nacos 上创建一个配置时，如果未填写配置分组的名称，则配置分组的名称默认采用 DEFAULT_GROUP。配置分组的常见场景：可用于区分不同的项目或应用，例如：学生管理系统的配置集可以定义一个 Group 为：STUDENT_GROUP。 命名空间（Namespace） 命名空间可用于进行不同环境的配置隔离。例如可以隔离开发环境、测试环境和生产环境，因为它们的配置可能各不相同，或者是隔离不同的用户，不同的开发人员使用同一个 Nacos 管理各自的配置，可通过 Namespace 隔离。当在 Nacos 上创建一个配置时，如果未填写命名空间的名称，则命名空间的名称默认为 public。不同的命名空间下，可以存在相同名称的配置分组（Group） 或 配置集。 Nacos 配置管理最佳实践Nacos 抽象定义了 Namespace、Group、Data ID 的概念，具体这几个概念代表什么，取决于把它们看成什么，这里推荐一种用法，如下图： Namespace ：代表不同环境，如开发、测试、生产环境 Group：代表某项目，如 XX 医疗项目、XX 电商项目、XX 校园项目 DataId：每个项目下往往有若干个工程，每个配置集（DataId）是一个工程的主配置文件 Namespace 与 Group 的其他最佳实践 除了上面介绍的一种最佳实践方法外，还可以为每个微服务创建自己的 namespace 进行隔离，然后利用 group 来区分 Dev、Beta、Prod 等环境。 Nacos 命名空间管理Namespace 隔离设计Namespace 的设计是 Nacos 基于此做多环境以及多租户（多个用户共同使用 Nacos）数据（配置和服务）隔离的。从一个租户 (用户）的角度来看，如果有多套不同的环境，那么这个时候可以根据指定的环境来创建不同的 Namespace，以此来实现多环境的隔离。例如可能有开发、测试和生产三个不同的环境，那么使用一套 Nacos 集群可以分别建以下三个不同的 Namespace，如下图所示： 从多个租户（用户）的角度来看，每个租户（用户）可能会有自己的 Namespace，每个租户（用户）的配置数据以及注册的服务数据都会归属到自己的 Namespace 下，以此来实现多租户间的数据隔离。例如超级管理员分配了三个租户（用户），分别为张三、李四和王五。分配好了之后，各租户用自己的账户名和密码登录后，创建自己的命名空间。如下图所示： Nacos 创建命名空间第一步：菜单栏选中命名空间，然后点击页面上的新建命名空间按钮 第二步：在表单内填写必要的命名空间信息，然后点击确定按钮提交 第三步：菜单栏选中配置管理 &gt; 配置列表，可以通过 Tab 按钮切换到不同的命名空间，接着就可以在对应的命名空间下新增配置信息 代码示例 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.exception.NacosException;import java.util.Properties;/** * 从Nacos读取特定命名空间下的配置信息 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException { String serverAddr = \"127.0.0.1:8848\"; String namespace = \"7ec71a71-6ee5-4f87-a387-0d29d9e8fe51\"; String group = \"DEFAULT_GROUP\"; String dataId = \"nacos_simple_demo.yaml\"; Properties properties = new Properties(); properties.put(\"serverAddr\", serverAddr); properties.put(\"namespace\", namespace); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); }} Nacos 常见配置管理操作配置集导出勾选若干配置集，点击导出选中的配置按钮，即可自动下载一个压缩包，压缩包内包含了选中配置集所转换的配置文件。 配置集导入点击右上角的导入配置按钮，选择之前导出的配置文件压缩包，可以将压缩包内的文件恢复为 Nacos 配置集。 配置集克隆勾选若干配置集，点击克隆按钮，可以将选中的配置集批量复制到指定的命名空间内。 历史版本Nacos 通过提供配置版本管理及其一键回滚能力，帮助用户改错配置的时候能够快速回滚，降低微服务系统在配置管理上的可用性风险。 监听查询Nacos 提供配置订阅者（即监听者）查询能力，同时提供客户端当前配置的 MD5 校验值，以便帮助用户更好的检查服务器的配置变更是否推送到 Nacos 客户端，其中 Nacos 客户端监听的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839import com.alibaba.nacos.api.NacosFactory;import com.alibaba.nacos.api.config.ConfigService;import com.alibaba.nacos.api.config.listener.Listener;import com.alibaba.nacos.api.exception.NacosException;import java.io.IOException;import java.util.Properties;import java.util.concurrent.Executor;/** * Nacos客户端监听服务器的配置信息是否变更 * @author clay */public class NacosDemoApplicaton { public static void main(String[] args) throws NacosException, IOException { String serverAddr = \"127.0.0.1:8848\"; String group = \"DEFAULT_GROUP\"; String dataId = \"nacos_simple_demo.yaml\"; Properties properties = new Properties(); properties.put(\"serverAddr\", serverAddr); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 1000); System.out.println(content); configService.addListener(dataId, group, new Listener() { @Override public Executor getExecutor() { return null; } @Override public void receiveConfigInfo(String configInfo) { System.out.println(configInfo); } }); System.in.read(); }} 登录管理Nacos 支持简单的登录功能，默认用户名 / 密码为： nacos/nacos， 生成密码 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;version&gt;5.4.1&lt;/version&gt;&lt;/dependency&gt; 1234567891011/** * 由于采用BCrypt加密方法在每次生成密码时会加随机盐，因此生成的密码每次都可能不一样 * @author clay */public class PasswordEncoderUtil { public static void main(String[] args) { String password = new BCryptPasswordEncoder().encode(\"123456\"); System.out.println(password); }} 创建登录用户 当 Nacos 使用 MySQL 数据库存储数据时，可以使用以下 SQL 来创建新用户，其中密码就是上面通过 Java 代码生成的字符串。同理，若需要更改旧用户的登录密码，只需要通过 SQL 更新对应的数据库表数据即可，这里不再累述。 12INSERT INTO users (username, password, enabled) VALUES ('admin','$2a$10$kCRcD31fYzYUhfvCSUqQ9u/IAKbq4yTWi1z3l6kTrKL5exGSNbSUK', TRUE);INSERT INTO roles (username, role) VALUES ('admin', 'ROLE_ADMIN'); 关闭登录功能由于部分公司自己开发控制台，不希望被 Nacos 的安全 Filter 拦截。因此 Nacos 支持定制关闭登录功能，只需要找到配置文件 ${nacos-home}/conf/application.properties，替换以下内容即可，最后重启 Nacos 服务使更改生效。特别注意，以下更改只适合 Nacos 1.2.0 以下的版本。 123456spring.security.enabled=falsemanagement.security=falsesecurity.basic.enabled=falsenacos.security.ignore.urls=/**# nacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/** 下篇 - Nacos 入门教程 - 配置管理（中级篇） Nacos 入门教程 - 配置管理中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Linux 的 .a、.so 和 .o 文件介绍","url":"/posts/7d3e2801.html","text":"var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux系统编程"},{"title":"Spring Cloud Alibaba 新一代微服务解决方案","url":"/posts/97d0a561.html","text":"Spring Cloud Alibaba 是什么Spring Cloud Alibaba 是阿里巴巴提供的微服务开发一站式解决方案，是阿里巴巴开源中间件与 Spring Cloud 体系的融合，Github 项目地址在这里，官方文档在这里。 Spring Cloud 概述提起微服务，不得不提 Spring Cloud 全家桶系列，Spring Cloud 是若干个框架的集合，包括 spring-cloud-config、spring-cloud-bus 等近 20 多个子项目，提供了服务治理、服务网关、智能路由、负载均衡、断路器、监控跟踪、分布式消息队列、配置管理等领域的解决方案。Spring Cloud 通过 Spring Boot 风格的封装，屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、容易部署的分布式系统开发工具包。一般来说，Spring Cloud 包含以下组件，主要以 Netflix 开源项目为主： Spring Cloud Alibaba 概述同 Spring Cloud 一样，Spring Cloud Alibaba 也是一套微服务解决方案，包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。依托 Spring Cloud Alibaba，开发者只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。作为 Spring Cloud 体系下的新实现，Spring Cloud Alibaba 跟官方的组件或其它的第三方实现如 Netflix、Consul、Zookeeper 等对比，具备了更多的功能: Spring Cloud Alibaba 包含的组件下图是 Spring Cloud Alibaba 系列组件，其中包含了阿里开源组件、阿里云商业化组件，以及集成了 Spring Cloud 组件。 Alibaba 开源组件 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 RocketMQ：开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Dubbo：在国内应用非常广泛的一款高性能 Java RPC 框架。 Seata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。 Arthas：开源的 Java 动态追踪工具，基于字节码增强技术，功能非常强大。 Alibaba 商业化组件 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS：阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的云存储服务。 Alibaba Cloud SchedulerX：阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准的定时（基于 Cron 表达式）任务调度服务。 Alibaba 集成 Spring Cloud 组件Spring Cloud Alibaba 作为整套的微服务解决组件，只依靠目前阿里的开源组件是不够的，更多的是集成当前的社区组件，所以 Spring Cloud Alibaba 可以集成 Zuul，OpenFeign 等组件，也支持 Spring Cloud Stream 消息组件。Spring Cloud Alibaba 适配了 Spring Cloud 中 Edgware、Finchley、Greenwich 三个版本的对应版本，具体对应关系如下： Spring Cloud Alibaba 的功能服务注册与发现Spring Cloud Alibaba 基于 Nacos 提供 spring-cloud-alibaba-starter-nacos-discovery 、spring-cloud-alibaba-starter-nacos-config 实现了服务注册与配置管理功能。依靠 @EnableDiscoveryClient 进行服务注册，兼容 RestTemplate 与 OpenFeign 的客户端进行服务调用，同时适配了 Spring Cloud 的服务注册与发现标准，默认集成了 Ribbon 的支持。 支持多协议的服务调用Spring Cloud 默认的服务调用依赖 RestTemplate 或者 OpenFeign 使用 REST 进行调用。使用 @DubboTransported 注解可将底层的 REST 协议无缝切换成 Dubbo RPC 协议，进行 RPC 调用。 123456789@FeignClient(\"dubbo-provider\")@DubboTransported(protocol = \"dubbo\")public interface DubboFeignRestService { @GetMapping(value = \"/param\") String param(@RequestParam(\"param\") String param); @PostMapping(\"/saveB\") String saveB(@RequestParam(\"a\") int a, @RequestParam(\"b\") String b);} 服务限流降级作为稳定性的核心要素之一，服务限流和降级是微服务领域特别重要的一环，Spring Cloud Alibaba 基于 Sentinel，对 Spring 体系内基本所有的客户端和网关进行了适配，默认支持 WebServlet、WebFlux、OpenFeign、RestTemplate、Spring Cloud Gateway、Zuul、Dubbo 和 RocketMQ 限流降级功能的接入。Sentinel 的应用比较简单，只需引入 starter 即可生效，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 微服务消息驱动支持为微服务应用构建消息驱动能力，基于 Spring Cloud Stream 提供 Binder 的新实现：Spring Cloud Stream RocketMQ Binder，也新增了 Spring Cloud Bus 消息总线的新实现： Spring Cloud Bus RocketMQ。 分布式事务使用 Seata 解决微服务场景下面临的分布式事务问题，通过 @GlobalTransactional 注解，在微服务中传递事务上下文，可以对业务零侵入地解决分布式事务问题。 阿里云提供的商业能力通过上面提到的 OSS，SchedulerX 等组件，开发者可以在阿里云上实现对象存储，分布式任务调度等功能。 Spring Cloud Alibaba 的优势阿里巴巴强大的技术输出能力阿里巴巴无疑是国内开源技术领域的最有影响力的公司之一，已经有 Dubbo、Druid，FastJson 等成功的开源组件，再加上阿里不遗余力的推广，社区发展也非常快。 云原生趋势，集成阿里云商业化组件云原生（Cloud Native）是今年技术领域特别热门的一个词，云原生是一种专门针对云上应用而设计的方法，用于构建和部署应用，以充分发挥云计算的优势。Spring Cloud Alibaba 集成了阿里云的商业化组件，可以说天然支持云原生特性。 集成 Dubbo，利用 Dubbo 在微服务领域的超高人气Dubbo 是国内应用最广的分布式服务框架之一，基于 Dubbo 改造的 DubboX 等也有很多公司在使用，Spring Cloud Alibaba 对 Dubbo 做了比较好的集成，可以吸引不少使用 Dubbo 的开发者。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"深入理解 Java 内存模型","url":"/posts/5bbede3c.html","text":"前言本文来源自《深入理解 Java 虚拟机》。 物理硬件和内存首先，在单核电脑中处理的问题要简单得多，对内存和硬件的要求，各种方面的考虑没有在多核的情况下复杂。电脑中，CPU 的运行计算速度是非常快的，而其他硬件比如 IO，网络、内存读取等等，跟 CPU 的速度比起来是差几个数量级的。而不管任何操作，几乎是不可能都在 CPU 中完成而不借助于任何其他硬件操作。所以协调 CPU 和各个硬件之间的速度差异是非常重要的，要不然 CPU 就一直在等待，浪费资源。而在多核中，不仅面临如上问题，还有如果多个核用到了同一个数据，如何保证数据的一致性、正确性等问题，也是必须要解决的。目前基于高速缓存的存储交互很好的解决了 CPU 和内存等其他硬件之间的速度矛盾，多核情况下各个处理器（核）都要遵循一定的诸如 MSI、MESI 等协议来保证内存的各个处理器高速缓存和主内存的数据的一致性。 除了增加高速缓存，为了使处理器内部运算单元尽可能被充分利用，处理器还会对输入的代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在乱序执行之后的结果进行重组，保证结果的正确性，也就是保证结果与顺序执行的结果一致。但是在真正的执行过程中，代码执行的顺序并不一定按照代码的书写顺序来执行，可能和代码的书写顺序不同。 Java 的内存模型Java 内存模型（Java Memory Model，简称 JMM）是 Java 虚拟机规范定义的，用来屏蔽掉 Java 程序在各种不同的硬件和操作系统对内存的访问的差异，这样就可以实现 Java 程序在各种不同的平台上都能达到内存访问的一致性。避免了像 C++ 等直接使用物理硬件和操作系统的内存模型在不同操作系统和硬件平台下表现不同，比如有些 C/C++ 程序可能在 Windows 平台运行正常，而在 Linux 平台却运行有问题。 虽然 Java 程序所有的运行都是在虚拟机中，涉及到的内存等信息都是虚拟机的一部分，但实际也是物理机的，只不过是虚拟机作为最外层的容器统一做了处理。虚拟机的内存模型，以及多线程的场景下与物理机的情况是很相似的，可以类比参考。Java 内存模型的主要目标是定义程序中变量的访问规则。即在虚拟机中将变量存储到主内存或者将变量从主内存取出这样的底层细节。需要注意的是这里的变量跟平时写 Java 程序中的变量不是完全等同的。这里的变量是指实例字段、静态字段、构成数组对象的元素，但是不包括局部变量和方法参数（因为这是线程私有的）。这里可以简单的认为主内存是 Java 虚拟机内存区域中的堆，局部变量和方法参数是在虚拟机栈中定义的。但是在堆中的变量如果在多线程中都使用，就涉及到了堆和不同虚拟机栈中变量的值的一致性问题了。 Java 内存模型的两个重要概念： 主内存：Java 虚拟机规定所有的变量（不是程序中的变量）都必须在主内存中产生，为了方便理解，可以认为是堆区。可以与前面说的物理机的主内存相比，只不过物理机的主内存是整个机器的内存，而虚拟机的主内存是虚拟机内存中的一部分。 工作内存：Java 虚拟机中每个线程都有自己的工作内存，该内存是线程私有的。为了方便理解，可以认为是虚拟机栈，可以与前面说的高速缓存相比。线程的工作内存保存了线程需要的变量在主内存中的副本。虚拟机规定，线程对主内存变量的修改必须在线程的工作内存中进行，不能直接读写主内存中的变量。不同的线程之间也不能相互访问对方的工作内存。如果线程之间需要传递变量的值，必须通过主内存来作为中介进行传递。 特别说明：主内存、工作内存与 Java 内存区域中的 Java 堆、虚拟机栈、方法区并不是一个层次的内存划分。这两者是基本上是没有关系的，上文只是为了便于理解，做的类比。 工作内存与主内存交互物理机高速缓存和主内存之间有交互协议，同样的，Java 内存中线程的工作内存和主内存的交互是由 Java 虚拟机定义了如下的八种操作来完成的，每种操作必须是原子性的（double 和 long 类型在某些平台有例外）。Java 虚拟机中主内存和工作内存交互，本质就是一个变量如何从主内存传输到工作内存中，如何把修改后的变量从工作内存同步回主内存。 lock（锁定）：作用于主内存的变量，一个变量在同一时间只能被一个线程锁定，该操作表示这条线成独占这个变量 unlock（解锁）：作用于主内存的变量，表示这个变量的状态由处于锁定状态被释放，这样其他线程才能对该变量进行锁定 read（读取）：作用于主内存变量，表示把一个主内存变量的值传输到线程的工作内存，以便随后的 load 操作使用 load（载入）：作用于线程的工作内存的变量，表示把 read 操作从主内存中读取的变量的值放到工作内存的变量副本中（副本是相对于主内存的变量而言的） use（使用）：作用于线程的工作内存中的变量，表示把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时就会执行该操作 assign（赋值）：作用于线程的工作内存的变量，表示把执行引擎返回的结果赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的字节码指令时就会执行该操作 store（存储）：作用于线程的工作内存中的变量，把工作内存中的一个变量的值传递给主内存，以便随后的 write 操作使用 write（写入）：作用于主内存的变量，把 store 操作从工作内存中得到的变量的值放入主内存的变量中 如果要把一个变量从主内存传输到工作内存，那就要顺序的执行 read 和 load 操作，如果要把一个变量从工作内存回写到主内存，就要顺序的执行 store 和 write 操作。对于普通变量，虚拟机只是要求顺序的执行，并没有要求连续的执行，所以如下也是正确的。例如两个线程分别从主内存中读取变量 a 和 b 的值，即执行 read a; load a; read b; load b;，此时可能也会出现如下执行顺序 read a; read b; load b; load a;。这八种操作必须是原子的，不可分割的。 针对于 volatile 修饰的变量，会有一些特殊规则，后边会详细列出。 对于上述八种操作，虚拟机也规定了一系列规则，在执行这八种操作的时候必须遵循如下的规则： 不允许 read 和 load、store 和 write 操作之一单独出现，也就是不允许从主内存读取了变量的值但是工作内存不接收的情况，或者不允许从工作内存将变量的值回写到主内存但是主内存不接收的情况 不允许一个线程丢弃最近的 assign 操作，也就是不允许线程在自己的工作线程中修改了变量的值却不同步 / 回写到主内存 不允许一个线程回写没有修改的变量到主内存，也就是如果线程工作内存中变量没有发生过任何 assign 操作，是不允许将该变量的值回写到主内存 变量只能在主内存中产生，不允许在工作内存中直接使用一个未被初始化的变量，也就是没有执行 load 或者 assign 操作，即执行 use、store 之前必须对相同的变量执行了 load、assign 操作 一个变量在同一时刻只能被一个线程对其进行 lock 操作，也就是说一个线程一旦对一个变量加锁后，在该线程没有释放掉锁之前，其他线程是不能对其加锁的，但是同一个线程对一个变量加锁后，可以继续加锁，同时在释放锁的时候释放锁次数必须和加锁次数相同 对变量执行 lock 操作，就会清空工作内存中该变量的值，执行引擎使用这个变量之前，需要重新 load 或者 assign 操作初始化变量的值 不允许对没有 lock 的变量执行 unlock 操作，如果一个变量没有被 lock 操作，那也不能对其执行 unlock 操作，当然一个线程也不能对被其他线程 lock 的变量执行 unlock 操作 对一个变量执行 unlock 之前，必须先把变量同步回主内存中，也就是执行 store 和 write 操作 volatile 变量volatile 变量的特殊规则关键字 volatile 可以说是 Java 虚拟机中提供的最轻量级的同步机制，Java 内存模型对 volatile 专门定义了一些特殊的访问规则。假定 T 表示一个线程，V 和 W 分别表示两个 volatile 修饰的变量，那么在进行 read、load、use、assign、store 和 write 操作的时候需要满足如下规则： 只有当线程 T 对变量 V 执行的前一个动作是 load，线程 T 对变量 V 才能执行 use 动作；同时只有当线程 T 对变量 V 执行的后一个动作是 use 的时候，线程 T 对变量 V 才能执行 load 操作。所以，线程 T 对变量 V 的 use 动作和线程 T 对变量 V 的 read、load 动作相关联，必须是连续一起出现。也就是在线程 T 的工作内存中，每次使用变量 V 之前必须从主内存去重新获取最新的值，用于保证线程 T 能看得见其他线程对变量 V 的最新的修改后的值。 只有当线程 T 对变量 V 执行的前一个动作是 assign 的时候，线程 T 对变量 V 才能执行 store 动作；同时只有当线程 T 对变量 V 执行的后一个动作是 store 的时候，线程 T 对变量 V 才能执行 assign 动作。所以，线程 T 对变量 V 的 assign 操作和线程 T 对变量 V 的 store、write 动作相关联，必须一起连续出现。也即是在线程 T 的工作内存中，每次修改变量 V 之后必须立刻同步回主内存，用于保证线程 T 对变量 V 的修改能立刻被其他线程看到。 假定动作 A 是线程 T 对变量 V 实施的 use 或 assign 动作，动作 F 是和动作 A 相关联的 load 或 store 动作，动作 P 是和动作 F 相对应的对变量 V 的 read 或 write 动作；类似的，假定动作 B 是线程 T 对变量 W 实施的 use 或 assign 动作，动作 G 是和动作 B 相关联的 load 或 store 动作，动作 Q 是和动作 G 相对应的对变量 W 的 read 或 write 动作。如果动作 A 先于 B，那么 P 先于 Q。也就是说在同一个线程内部，被 volatile 修饰的变量不会被指令重排序，保证代码的执行顺序和程序的顺序相同。 总结上面三条规则：前面两条可以概括为：volatile 类型的变量保证对所有线程的可见性。第三条为：volatile 类型的变量禁止了指令重排优化。 volatile 变量禁止指令重排计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排，一般分为以下三种： 单线程环境里面确保程序最终执行结果和代码顺序执行的结果一致。处理器在进行重排序时必须考虑指令之间的数据依赖性。多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测。 普通的变量仅仅会保证在该方法执行的过程中，所有依赖赋值结果的地方都能获取到正确的结果，但不能保证变量赋值的操作顺序和程序代码的顺序一致。因为在一个线程的方法执行过程中无法感知到这一点，这也就是 Java 内存模型中描述的所谓的线程内部表现为串行的语义。也就是在单线程内部，我们看到的或者感知到的结果和代码顺序是一致的；即使代码的执行顺序和代码顺序不一致，但是在需要赋值的时候结果也是正确的，所以看起来就是串行的。但实际结果有可能代码的执行顺序和代码顺序是不一致的，这在多线程代码中就会出现问题。示例代码如下： 12345678910111213141516171819Map configOptions;char[] configText;//volatile类型变量volatile boolean initialized = false;//假设以下代码在线程A中执行//模拟读取配置信息，读取完成后认为是初始化完成configOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText, configOptions);initialized = true;//假设以下代码在线程B中执行//等待initialized为true后，读取配置信息进行操作while ( !initialized) { sleep();}doSomethingWithConfig(); 在上述代码中，如果 initialiezd 是普通变量，没有被 volatile 修饰，那么线程 A 执行的代码的修改初始化完成的结果 initialized = true 就有可能先于之前的三行代码执行，而此时线程 B 发现 initialized 为 true 了，就执行 doSomethingWithConfig() 方法，但是里面的配置信息都是 Null 的，就会出现问题了。如果 initialized 是 volatile 类型变量，保证禁止代码重排序优化，那么就可以保证 initialized = true 执行的时候，前边的三行代码一定执行完成了，那么线程 B 读取的配置文件信息就是正确的。跟其他保证并发安全的工具相比，volatile 的性能确实会好一些。在某些情况下，volatile 的同步机制性能要优于锁（使用 synchronized 关键字或者 Java.util.concurrent 包中的锁）。但是现在由于虚拟机对锁的不断优化和实行的许多消除动作，很难有一个量化的比较；但与自身比较可以确定一个原则：volatile 变量的读操作和普通变量的读操作几乎没有差异，但是写操作会性能差一些，因为要在本地代码中插入许多内存屏障指令来禁止指令重排序，保证处理器不发生代码乱序执行行为。 volatile 变量保证可见性可见性是指当一个线程修改了这个变量的值，新值（修改后的值）对于其他线程来说是立即可以得知的。正如上面的前两条规则规定，volatile 类型的变量每次值被修改了就立即同步回主内存，每次使用时就需要从主内存重新读取值。返回到前面 JMM 对普通变量的规则中，并没有要求这一点，所以普通变量的值是不会立即对所有线程可见的，即普通变量不具备可见性。volatile 变量保证可见性的验证代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 1 验证volatile的可见性 * 1.1 加入int number=0，number变量之前没有添加volatile关键字修饰，不具备可见性 * 1.2 添加了volatile关键字，可以解决可见性问题 */ public class VolatileTest { public static void main(String[] args) { MyData data = new MyData(); new Thread(() - &gt; { System.out.println(Thread.currentThread().getName() + \" thread come in\"); try { TimeUnit.SECONDS.sleep(3); } catch(InterruptedException e) { e.printStackTrace(); } data.setNumber(); System.out.println(Thread.currentThread().getName() + \" thread set number is \" + data.number); }, \"AAA\").start(); while(data.number == 0) { // main线程一直在这里循环等待，直到number的值不再等于零 } System.out.println(Thread.currentThread().getName() + \" thread is over, the number is \" + data.number); } } class MyData { // int number = 0; // volatile可以保证可见性，即可以及时通知其他线程，主内存中的变量值已经被修改 volatile int number = 0; public void setNumber() { this.number = 60; } } 123AAA thread come inAAA thread set number is 60main thread is over, the number is 60 volatile 变量不保证原子性常见误解：volatile 变量对所有线程是立即可见的，所以对 volatile 变量的所有修改（写操作）都立刻能反应到其他线程中。或者换句话说：volatile 变量在各个线程中是一致的，所以基于 volatile 变量的运算在并发下是线程安全的。这个观点的论据是正确的，但是根据论据得出的结论是错误的，并不能得出这样的结论。volatile 的规则，保证了 read、load、use 的顺序和连续性，同理 assign、store、write 也是顺序和连续的。也就是这几个动作是原子性的，但是对变量的修改，或者对变量的运算，却不能保证是原子性的。如果对变量的修改是分为多个步骤的，那么多个线程同时从主内存拿到的值是最新的，但是经过多步运算后回写到主内存的值是有可能存在覆盖情况发生的。volatile 变量不保证原子性的验证代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class VolatileTest{ public static volatile int race = 0; public static void increase() { race++; } private static final int THREADS_COUNT = 20; public static void main(String[] args) { Thread[] threads = new Thread[THREADS_COUNT]; for(int i = 0; i &lt; THREADS_COUNT; i++) { threads[i] = new Thread(new Runnable() { @Override public void run() { for(int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); }} 141078 上述代码就是对 volatile 类型的变量启动了 20 个线程，每个线程对变量执行 1w 次加 1 操作，如果 volatile 变量并发操作没有问题的话，那么结果应该是输出 20w，但是结果运行的时候每次都是小于 20w，这就是因为 race++ 操作不是原子性的（图解），是分多个步骤完成的。假设两个线程 a、b 同时取到了主内存的值是 0，这是没有问题的，在进行 ++ 操作的时候假设线程 a 执行到一半，线程 b 执行完了，这时线程 b 立即同步给了主内存，主内存的值为 1，而线程 a 此时也执行完了，同步给了主内存，此时的值仍然是 1，线程 b 的结果被覆盖掉了。 如果需要解决 volatile 不保证原子性的问题，直接使用 AtomicInteger 这样的原子包装类即可保证原子性。示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class VolatileTest{ public static AtomicInteger race = new AtomicInteger(); public static void increase() { race.getAndIncrement(); } private static final int THREADS_COUNT = 20; public static void main(String[] args) { Thread[] threads = new Thread[THREADS_COUNT]; for(int i = 0; i &lt; THREADS_COUNT; i++) { threads[i] = new Thread(new Runnable() { @Override public void run() { for(int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); }} long 和 double 变量long 和 double 变量的特殊规则Java 内存模型要求对主内存和工作内存交互的八种操作是原子性的，正如上文所讲，对 long 和 double 有一些特殊规则。八种操作中 lock、unlock、read、load、use、assign、store、write 对待 32 位的基本数据类型都是原子操作，对待 long 和 double 这两个 64 位的数据，Java 虚拟机规范对 Java 内存模型的规定中特别定义了一条相对宽松的规则：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行，也就是允许虚拟机不保证对 64 位数据的 read、load、store 和 write 这 4 个动作的操作是原子的。这也就是常说的 long 和 double 的非原子性协定（Nonautomic Treatment of double and long Variables）。 并发内存模型的实质Java 内存模型围绕着并发过程中如何处理原子性、可见性和顺序性这三个特征来设计的。 原子性（Atomicity）： 由 Java 内存模型来直接保证原子性的变量操作包括 read、load、use、assign、store、write 这 6 种操作，虽然存在 long 和 double 的特例，但基本可以忽略不计，目前虚拟机基本都对其实现了原子性。如果需要更大范围的控制，lock 和 unlock 也可以满足需求。lock 和 unlock 虽然没有被虚拟机直接提供给用户使用，但是提供了字节码层次的指令 monitorenter 和 monitorexit 对应这两个操作，对应到 Java 代码就是 synchronized 关键字，因此在 synchronized 块之间的代码都具有原子性。 可见性（Visibility）： 可见性是指一个线程修改了一个变量的值后，其他线程立即可以感知到这个值的修改。正如前面所说，volatile 类型的变量在修改后会立即同步给主内存，在使用的时候会从主内存重新读取，是依赖主内存为中介来保证多线程下变量对其他线程的可见性的。除了 volatile 之外，synchronized 和 final 也可以实现可见性。synchronized 关键字是通过 unlock 之前必须把变量同步回主内存来实现的，final 则是在初始化后就不会更改，所以只要在初始化过程中没有把 this 指针传递出去也能保证对其他线程的可见性。 有序性： 有序性从不同的角度来看是不同的。单纯单线程来看都是有序的，但到了多线程就会跟我们预想的不一样。可以这么说：如果在本线程内部观察，所有操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句说的就是线程内表现为串行的语义，后半句指的是指令重排现象和主内存与工作内存之间同步存在延迟的现象。保证有序性的关键字有 volatile 和 synchronized，其中 volatile 禁止了指令重排序，而 synchronized 则由一个变量在同一时刻只能被一个线程对其进行lock操作来保证。 总结：synchronized 对三种特性都有支持，虽然简单，但是如果无控制地滥用对性能就会产生较大影响。volatile 只支持可见性和有序性（禁止指令重排），不支持原子性 先行发生原则如果 Java 内存模型中所有的有序性都要依靠 volatile 和 synchronized 来实现，那是不是非常繁琐。Java 语言中有一个 “先行发生原则”，是判断数据是否存在竞争、线程是否安全的主要依据。 什么是先行发生原则 先行发生原则是 Java 内存模型中定义的两个操作之间的偏序关系。比如说操作 A 先行发生于操作 B，那么在 B 操作发生之前，A 操作产生的 “影响” 都会被操作 B 感知到。这里的影响是指修改了内存中的共享变量、发送了消息、调用了方法等。 Java 内存模型自带先行发生原则有哪些 程序次序原则：在一个线程内部，按照代码的顺序，书写在前面的先行发生与后边的。或者更准确的说是在控制流顺序前面的先行发生与控制流后面的，而不是代码顺序，因为会有分支、跳转、循环等 管程锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须注意的是对同一个锁，后面是指时间上的后面 volatile变量规则：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的后面是指时间上的先后顺序 线程启动规则：Thread 对象的 start () 方法先行发生与该线程的每个动作。当然如果错误的使用了线程，创建线程后没有执行 start 方法，而是执行 run 方法，那此句话是不成立的，但是如果这样其实也不是线程了 线程终止规则：线程中的所有操作都先行发生与对此线程的终止检测，可以通过 Thread.join () 和 Thread.isAlive () 的返回值等手段检测线程是否已经终止执行 线程中断规则：对线程 interrupt () 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread.interrupted () 方法检测到是否有中断发生 对象终结规则：一个对象的初始化完成先行发生于他的 finalize 方法的执行，也就是初始化方法先行发生于 finalize 方法 传递性规则：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C 在下述的代码中，如果有两个线程 A 和 B，A 先调用 setValue 方法，然后 B 调用 getValue 方法，那么 B 线程执行方法返回的结果是什么？ 123456789private int value = 0;public void setValue(int value) { this.value = value;}public int getValue() { return this.value;} 对照先行发生原则一个一个对比。首先是程序次序规则，这里是多线程，不在一个线程中，不适用；然后是管程锁定规则，这里没有 synchronized，自然不会发生 lock 和 unlock，不适用；后面对于线程启动规则、线程终止规则、线程中断规则也不适用，这里与对象终结规则、传递性规则也没有关系。所以说 B 返回的结果是不确定的，也就是说在多线程环境下该操作不是线程安全的。如何修改呢，一个是对 get、set 方法加入 synchronized 关键字，即可以使用管程锁定规则；要么对 value 加 volatile 修饰，可以使用 volatile 变量规则。 通过上面的例子可知，一个操作时间上先发生并不代表这个操作先行发生，那么一个操作先行发生是不是代表这个操作在时间上先发生？也不是，如下面的例子： 12int i = 2;int j = 1; 在同一个线程内，对 i 的赋值先行发生于对 j 赋值的操作，但是代码重排序优化，也有可能是 j 的赋值先发生，我们无法感知到这一变化。综上所述，时间先后顺序与先行发生原则之间基本没有太大关系。我们衡量并发安全的问题的时候不要受到时间先后顺序的干扰，一切以先行发生原则为准。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java"},{"title":"Visual Studio 之一常用配置与使用","url":"/posts/ec73e38.html","text":"VS 版本说明本文使用的 Visual Studio 版本是 Microsoft Visual Studio Community 2019 版本 16.11.5。 界面操作添加源码目录将源码目录拷贝到 VS 的工程目录下，这时在 VS 的工程目录列表里是看不到新增的目录的，在如下图工具栏中点击图标 显示所有文件，才可以看到新增的目录 这时新增的源码目录还没有真正地加入到 VS 的工程中来，可见新增的文件的图标是红色的 在新增的源码目录上右键选择 包括在项目中，新增的源码目录就会加入到 VS 的工程中 新增的文件的图标最终才会正常显示 添加预处理器定义若项目编译失败，并输出如下的错误日志信息，则可以导航到菜单栏：项目 -&gt; 属性 -&gt; C/C++ -&gt; 预处理器 -&gt; 预处理器定义 -&gt; 编辑，然后加入 _CRT_SECURE_NO_WARNINGS 和 _CRT_NONSTDC_NO_DEPRECATE 即可。 1错误 C4996 'fopen': This function or variable may be unsafe. Consider using fopen_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. 常用快捷键 f9：设置断点 f5：调试运行 ctrl + f5：只运行，不调试 ctrl + shift + b：只编译，不运行 ctrl + k + c：注释代码 ctrl + k + u：取消注释代码 ctrl + k + f：代码格式化 ctrl + shift + f 或者 ctrl + shift + h：全局搜索文件内容 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"搜索中间件面试题之一","url":"/posts/a03f47f2.html","text":"ElasticSearch 和 Solr 的区别两者都是基于 Lucene 搜索服务器开发的，是一款优秀的、高性能的企业级搜索服务器，且都是基于分词技术构建的倒排索引的方式进行查询，区别如下： 当单纯地对已有数据进行检索的时候，Solr 的效率高于 ES 当实时建立索引的时候，Solr 会产生 IO 阻塞，而 ES 则不会，ES 的查询性能高于 Solr 在不断动态添加数据的时候，Solr 的检索效率会变得低下，而 ES 则没什么变化 Solr 利用 ZooKeeper 进行分布式管理，而 ES 自带分布式管理功能，Solr 一般都要部署到 Web 服务器上（如 Tomcat），启动 Tomcat 的时候需要配置 Tomcat 与 Solr 的关联 Solr 支持更多的数据格式（XML、JSON、CSV 等），而 ES 仅支持 JSON 文件格式 Solr 是传统搜索应用的有力解决方案，但是 ES 更适用于新兴的实时搜索应用 Solr 官网提供的功能更多，而 ES 本身更注重核心功能，高级功能一般由第三方插件提供 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"面试"},{"title":"Visual Studio 2019 离线安装","url":"/posts/f201bf82.html","text":"前言本文介绍的是 VS 离线安装，类似 ISO 安装，可以解决因 Internet 连接不可靠或带宽较低，导致 VS 安装失败的问题。其原理是使用命令行创建安装文件的本地缓存，这样就可以实现一次下载多次安装，节省下载安装文件所花的时间。 VS 离线安装步骤一访问 VS 官网，下载 VS 的安装器 vs_community.exe，选择社区版（免费）即可。 步骤二通过命令行，使用 VS 的安装器 vs_community.exe 创建（下载）安装文件的本地缓存，命令行的各个参数说明如下： --lang：指定语言 -add：下载工作负荷组件 --layout：指定本地缓存存放的目录路径 --includeRecommended：下载推荐的组件 -–includeOptional：下载可选的组件，比较占磁盘空间，不建议使用 1vs_community.exe --layout G:\\VisualStudio\\Packages -add Microsoft.VisualStudio.Workload.ManagedDesktop -add Microsoft.VisualStudio.Workload.NativeDesktop -add Microsoft.VisualStudio.Workload.Universal --includeRecommended --lang en-US zh-CN 若是 C++ 开发，一般选择安装 Microsoft.VisualStudio.Workload.ManagedDesktop、Microsoft.VisualStudio.Workload.NativeDesktop、Microsoft.VisualStudio.Workload.Universal 这三大组件即可，分别对应下图中已勾选的组件，VS 的组件列表可以看这里。 步骤三下载完成后，进入上面命令行中 --layout 参数所指定的文件夹下，双击 vs_setup.exe 进行安装 步骤四等待文件提取完成，显示 VS 的安装界面 步骤五选择安装位置，请确保安装位置所在的磁盘有足够的空间，然后点击 安装 按钮开始安装。值得一提的是，这里一般不再需要在安装界面上的 工作负荷、单个组件、语言包 页面里，手动勾选任何内容。 VS 创建 C++ 项目 VS 创建 C++ 项目 VS 各大组件的附录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879Visual Studio 核心编辑器ID： Microsoft.VisualStudio.Workload.CoreEditor说明： Visual Studio 核心 shell 体验，包括语法感知代码编辑、源代码管理和工作项管理。Azure 开发ID： Microsoft.VisualStudio.Workload.Azure说明：用于开发云应用、创建资源以及生成包括 Docker 支持的容器的 Azure SDK、工具和项目。数据存储和处理ID： Microsoft.VisualStudio.Workload.Data说明： 使用 SQL Server、Azure Data Lake 或 Hadoop 连接、开发和测试数据解决方案。数据科学和分析应用程序ID： Microsoft.VisualStudio.Workload.DataScience说明： 用于创建数据科学应用程序的语言和工具（包括 Python、R 和 F#）。.NET 桌面开发ID： Microsoft.VisualStudio.Workload.ManagedDesktop说明： 使用 C#、Visual Basic 和 F# 生成 WPF、Windows 窗体和控制台应用程序。使用 Unity 的游戏开发ID： Microsoft.VisualStudio.Workload.ManagedGame说明： 使用 Unity（功能强大的跨平台开发环境）创建 2D 和 3D 游戏。使用 C++ 的 Linux 开发ID： Microsoft.VisualStudio.Workload.NativeCrossPlat说明： 创建和调试在 Linux 环境中运行的应用程序。使用 C++ 的桌面开发ID： Microsoft.VisualStudio.Workload.NativeDesktop说明：使用 Microsoft C++ 工具集、ATL 或 MFC 生成 Windows 桌面应用程序。使用 C++ 的游戏开发ID： Microsoft.VisualStudio.Workload.NativeGame说明： 以 DirectX、Unreal 或 Cocos2d 为后盾，利用 C++ 的强大功能生成专业游戏。使用 C++ 的移动开发ID： Microsoft.VisualStudio.Workload.NativeMobile说明： 使用 C++ 生成适用于 iOS、Android 或 Windows 的跨平台应用程序。.NET Core 跨平台开发ID： Microsoft.VisualStudio.Workload.NetCoreTools说明： 使用 .NET Core、ASP.NET Core、HTML/JavaScript 和包括 Docker 支持的容器生成跨平台应用程序。使用 .NET 的移动开发ID： Microsoft.VisualStudio.Workload.NetCrossPlat说明： 使用 Xmarin 生成适用于 iOS、Android 或 Windows 的跨平台应用程序。ASP.NET 和 Web 开发ID： Microsoft.VisualStudio.Workload.NetWeb说明： 使用 ASP.NET、ASP.NET Core、HTML/JavaScript 和包括 Docker 支持的容器生成 Web 应用程序。Node.js 开发ID： Microsoft.VisualStudio.Workload.Node说明： 使用 Node.js（事件驱动的异步 JavaScript 运行时）生成可扩展的网络应用程序。Office/SharePoint 开发ID： Microsoft.VisualStudio.Workload.Office说明： 使用 C#、VB 和 JavaScript 创建 Office 和 SharePoint 外接程序、SharePoint 解决方案和 VSTO 外接程序。Python 开发ID： Microsoft.VisualStudio.Workload.Python说明： 适用于 Python 的编辑、调试、交互式开发和源代码管理。通用 Windows 平台开发ID： Microsoft.VisualStudio.Workload.Universal说明： 使用 C#、VB 和 JavaScript 或 C++（可选）创建适用于通用 Windows 平台的应用程序。Visual Studio 扩展开发ID： Microsoft.VisualStudio.Workload.VisualStudioExtension说明： 创建适用于 Visual Studio 的加载项和扩展，包括新命令、代码分析器和工具窗口。使用 JavaScript 的移动开发ID： Microsoft.VisualStudio.Workload.WebCrossPlat说明： 使用用于 Apache Cordova 的工具生成 Android、iOS 和 UWP 应用。Visual Studio 帮助查看器ID: Microsoft.Component.HelpViewer说明：VS 的帮助查看器。 参考资料 Visual Studio 2019 在线安装 VS2019 离线安装方法详解 Visual Studio 2019 脱机安装 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Visual Studio 2019 在线安装","url":"/posts/71979ec9.html","text":"下载 VS 安装器访问 VS 官网，选择社区版（免费）进行下载 安装 VS步骤一直接双击 “vs_community.exe” 运行 VS 安装器 步骤二等待文件提取完成，显示 VS 的安装界面 步骤三根据自己的开发需要，选择对应的工作负荷组件，若是开发 C++，一般勾选下图中的三项即可 步骤四选择单个组件，一般情况下这里不需要手动勾选 步骤五选择语言包，建议选择 “中文（简体）” 和 “英语” 步骤六选择安装位置，请确保安装位置所在的磁盘有足够的空间，然后点击 “安装” 按钮开始安装即可 VS 创建 C++ 项目步骤一运行 VS 的主程序，选择 “创建新项目” 步骤二选择 C++ 的 “空项目”，若没有找到 “空项目”，在语言下拉列表里选择 “C++” 即可 步骤三输入项目名，更改项目的存放路径 步骤四新建 C++ 的源文件 步骤五编写 C++ 代码 123456789#include &lt;iostream&gt;#include &lt;stdlib.h&gt;using namespace std;int main() { cout &lt;&lt; \"Hello World\" &lt;&lt; endl; system(\"pause\");} 步骤六编译运行 C++ 代码 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Docker-K8S 面试题之一","url":"/posts/3b82844a.html","text":"var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"面试"},{"title":"iPhone 破解各种锁的教程","url":"/posts/9ab7ecb5.html","text":"前言本文主要介绍 iPhone 如何破解屏幕锁、停用锁、丢失锁、ID 锁，由于篇幅有限，下面只会给出核心说明、软件下载链接与视频教程链接等，毕竟网上有很多可以参考的资料。其中破解 ID 锁常见有三种方式，包括绕过 ID（跳过 ID 锁登录）、隐藏 ID（将 ID 锁隐藏起来）、删除 ID（将 ID 锁删除掉），为了描述方便下文统一简述为破解 ID 锁。下文是笔者亲身实践的总结内容，2020 年 8 月成功解锁了 iPhone 6SP（iOS 12）、iPhone 8（iOS 13） 的 ID 锁。随着时间的推移，笔者不能保证本文内容（视频教程、软件工具等）可以长期生效，毕竟 iOS 14 已经发布了；而且破解 iPhone 各种锁本来就是攻防之间的较量，破解技术一直在不断地进步，苹果的安全技术也同样不断在完善。 各种锁介绍 丢失锁被失主激活，刷机即可解决 屏幕锁的密码忘记了，刷机即可解决 多次输出错误的屏幕锁密码，导致 iPhone 激活了停用锁，刷机即可解决 IOS 系统开启了 查找我的 iPhone 功能后，即使 ID 锁被激活了，可以使用以下三种方法破解 ID 锁： 方法一、刷机 + 越狱 + 激活 方法二、越狱 + 备份激活凭证 + 刷机 + 越狱 + 激活 + 还原激活凭证 方法三、越狱 + 关闭 查找我的 iPhone 的功能（一般包含了激活凭证的备份与还原） + 刷机，此方法暂时只适用于 IOS 13+ 的系统（不包括从低版本升级到 IOS 13+ 的情况） 特别注意事项： 建议无论是使用哪种方法破解 ID 锁，为了以防万一，都建议先越狱并备份激活凭证 如果实在无法备份激活凭证（例如越狱失败），此时若采用上面的方法一破解 ID 锁后，三网的机子（两网除外）只能当游戏机用了，无法正常使用 Sim 卡的打电话和 4G 网络等功能！！！ 如果 IOS 系统开启了 查找我的 iPhone 功能（ID 锁被激活），那么原系统都必须先越狱，然后备份原系统的激活凭证，再执行其他操作，否则一旦刷机或升级系统后，三网的机子（两网除外）即使激活了系统也无法正常使用 Sim 卡的打电话和 4G 网络等功能，切记！！！ 各种锁破解后的功能介绍1、屏幕锁、停用锁、丢失锁破解后的功能说明如下： 完美全功能，破解后等于没有 ID 锁，相当于官解 2、两网版机子破解 ID 锁后的功能说明如下： Siri iCloud 云同步 重启 / 关机 打电话 / 4G 上网 通知推送 破解网络锁 系统升级还原抹除 3、三网版机子破解 ID 锁后的功能说明如下： Siri iCloud 云同步 重启 / 关机 通知推送 破解网络锁 打电话 / 4G 上网 系统升级还原抹除 越狱Checkra1n 越狱工具Checkra1n 是一款适用于 iPhone 5s ~ iPhone X（A7 - A11 处理器），且 iOS 系统版本为 12.3+ 的越狱工具，支持运行在 Mac、Linux 系统，暂时不支持 Windows 系统。普通的家用电脑（Windows 系统）可以使用 Checkra1n 镜像制作 Linux Live U 盘，然后在 BIOS 里设置从 U 盘启动，这样就可以使用 Linux 系统里的 Checkra1n 工具了。Checkra1n 0.10.2 版本的镜像可以从这里下载，该镜像的原地址和使用教程在这里，支持 U 盘和硬盘启动，硬盘启动教程可以参考博客。如果需要其他版本的 Checkra1n Linux 镜像，可从百度网盘下载，提取码为 erso，具体的使用教程可以看这里，Checkra1n 与 IOS 系统的版本对应关系如下： Checkra1n 0.9.8 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.9.8.1 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.9.8.2 适用 IOS 12.3 ~ IOS 13.3.1 Checkra1n 0.10.1 适用 IOS 12.3 ~ IOS 13.4.1 Checkra1n 0.10.2 适用 IOS 12.3 ~ IOS 13.5 Checkra1n 越狱视频教程 Checkra1n U 盘越狱 iOS 13.6 Checkra1n U 盘越狱 Checkra1n Liunx U 盘 iOS 13 越狱 Checkra1n 越狱 0.9.8~0.1.0.2 共存版 Checkra1n 越狱错误码汇总Checkra1n 官方 issues 可以看这里，中文版的越狱错误汇总可以看这里，常见的错误如下： -26 或者 -31 错误码 不支持在虚拟机内（VMware/VBox）运行 Checkra1n 越狱工具 -77 错误码 解开锁屏 /iPhone 停用界面后，进入系统界面再越狱，这种错误一般在使用 Checkra1n Linux 镜像（U 盘版）时会出现 若锁屏 /iPhone 停用界面无法解开，可以物理安装 Ubuntu 系统或者使用 Ubuntu Live 盘，在 Ubuntu 系统里通过 apt-get 安装 Checkra1n（必须提前执行 apt-get upgrade 命令，否则安装会出现依赖问题），或者在 Checkra1n 官网下载编译好的可执行文件来安装，安装完成后执行越狱操作即可 破解 ID 锁破解 ID 锁视频教程以下视频来源 Youtube 平台，请自备梯子，否则无法正常打开。 苹果手机解锁 - 删除 - 查找我的 iPhone（免费）随意刷机，永久成为你自己的机器 停用的苹果 iPhone 手机 ID 密码忘了，完美绕过 ID 可以打电话上网 4G 一切正常 一个 U 盘就可以绕过苹果 Icloud 激活锁 A7-A11 所有设备 iPhone and ipad bypass icloud 苹果越狱 - 跳过 ID 激活锁 - 直接插 Sim 卡就可以打电话了 - 2020 年 4 月 26 日 FREE CELLULAR FIX for Passcode Locked &amp; Di 苹果越狱 - 跳过 ID 激活锁 - 直接插 SIM 卡就可以打电话了（Windows 版说明）FREE CELLULAR FIX for Passcode Locked &amp; D iCLoud Bypass iOS 12.3-13.6 Sim Card Fix Call And Internet In Window Real Full Untethered Bypass iCloud on iPhone &amp; iPad iOS 12.4.8 - iOS 13.6.1 | Windows Tutorial 运行平台 一、Mac 平台全搞定 二、 Linux 平台全搞定（Debian、Ubuntu） 三、混合平台，可任意组合使用，组合案例如下 刷机：Windows 系统 + 爱思助手 越狱：U 盘 + Checkra1n Linux 镜像 破解 ID 锁：Windows 系统 + iFRPFILE 备份与还原激活凭证：Windows 系统 + Sliver 工具软件破解 ID 锁 Sliver：激活凭证备份与还原 iFRPFILE：系统激活工具（破解 ID 锁） iCloud Bypass：系统激活工具（破解 ID 锁） X-Activator：集成了越狱、破解 ID 锁、修复推送等功能，该软件收费 各种软件下载请自备梯子，否则以下软件可能会下载失败，同时随着时间的推移，工具可能会失效。 Checkra1n 越狱工具：下载地址 iCloud Bypass Windows 版：下载地址 Checkra1n Linux 镜像：下载地址，提取码：erso Sliver Windows 版：下载地址，解压密码：https://t.me/itlj8 Sliver Mac 版：下载地址，访问密码：itlj8，解压密码：https://t.me/itlj8 功能验证 短信是否可用 WiFi 是否可用 2G/4G 网络是否可用 是否可以接听和拨打电话 系统是否正常重启和关机 是否可以通过 APP Store 安装应用 通知推送、iCloud、iTunes、Siri 是否可用 技巧总结判断 IOS 系统的版本若开机后是屏幕锁、停用锁、丢失锁界面，可以通过以下方式区分 IOS 12 和 IOS 13 系统： 静音键：按下静音键，若音量弹窗出现在屏幕中间，那就是 IOS 12 系统，音量弹窗出现在屏幕顶部，那就是 IOS 13 系统 恢复模式：进入恢复模式，如果界面出现了彩色的 iTunes Logo（如图），那就是那就是 IOS 12 系统，如果是全白色的图案（如图），就是 IOS 13 系统 查询 iPhone 的硬件配置在得知 IMEI 码的前提下，可以通过 IMEI 码查询 iPhone 具体的硬件配置信息，例如设备型号、硬盘容量、销售地区等，网上资料很多，这里不再累述。 查询 iPhone 的 ID 锁状态若开机后是屏幕锁、停用锁、丢失锁界面，可通过手机卡托上的 IMEI 序号，到 imeipro 网站（请自备梯子）查询 iPhone 的激活锁是否被激活（即是否开启了 “查找我的 iPhone”）；如果激活锁处于关闭状态（不存在 ID 锁），那么直接刷机就能当正常的 iPhone 手机使用了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"生活随笔"},{"title":"CLion 使用 Meson 构建 C/C++ 项目","url":"/posts/12d66a7e.html","text":"提示 本文适用于 Windows/Linux 系统，包括 Debian/Ubuntu/CentOS/Fedora 等 Linux 发行版。 Meson 入门指南 Meson 入门指南之一 CLion 使用 Meson 构建项目 CLion managing Meson projects Using meson as a build system with clion Working with meson in CLion using compilation db var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Vmware 虚拟机安装黑苹果系统","url":"/posts/3cc999a7.html","text":"准备操作 设置主板的 BIOS，开启硬件虚拟化的支持 Windows 系统环境下，需要关闭虚拟软件 Hyper-V，在 控制面板-程序-添加关闭 Window 功能 里，把 Hyper-V 关闭即可 软件环境 软件 版本 Vmware 15.5.6 Pro Unlocker 3.0.3 操作系统 Windows 10 Vmware 安装 Vmware 官网下载 Vmware 15.5.6 Pro 版本的安装文件，然后直接点击 EXE 文件进行安装即可，完成安装后可以输入下列秘钥进行永久激活。 123456YG5H2-ANZ0H-M8ERY-TXZZZ-YKRV8UG5J2-0ME12-M89WY-NPWXX-WQH88UA5DR-2ZD4H-089FY-6YQ5T-YPRX6GA590-86Y05-4806Y-X4PEE-ZV8E0ZF582-0NW5N-H8D2P-0XZEE-Z22VAYA18K-0WY8P-H85DY-L4NZG-X7RAD Unlocker 安装 由于 Vmware 默认屏蔽了 Mac OS 系统的支持，因此需要使用 Unlocker 工具进行解锁。最新版的 Unlocker 可以从 Github 上下载，由于官方的 Unlocker 会在运行期间到 Vmware 官网下载 com.vmware.fusion.tools.darwin.zip.tar 文件，整个下载过程非常慢。因此建议在 Unlocker 的目录下创建 tools 目录，然后手动下载 com.vmware.fusion.tools.darwin.zip.tar 文件到 tools 目录下，此时还需要更改 Unlocker 的 Python 代码，具体操作可参考文章。最后使用管理员权限运行 win-install.cmd 可执行文件即可，解锁完成后 Vmware 新建虚拟机时即可看到 Apple Mac OS X 的选项（如下图）。 特别注意：Unlocker 须解压在非中文的目录路径下，不同版本的 Vmware 需要用的 Unlocker 版本是不一样的，Vmware 15.5.6 Pro 对应 Unlocker 3.0.3 版本，解锁所需的资源文件如下： Unlocker 3.0.3 代码更改版：百度网盘，提取码: hxh6 com.vmware.fusion.tools.darwin.zip.tar：下载地址，若下载失败可以到这里找到可用的版本（11.1.0），并在 packages 目录里下载该文件 Vmware 安装 Mac OS Vmware14 安装黑苹果 mac ox x 10.13 懒人版教程 虚拟机 Vmware 安装黑苹果 MacOS Sierra 图文教程 Vmware 15.5 虚拟机 MacOS 系统手动安装 Vmware Tools Vmware 11 安装 Mac OS X 10.10 及安装 Mac Vmware Tools 黑苹果 Vmware 安装 AppStore 原版 MacOS Catalina 10.15.1，附 VirtualBox 安装 High Sierra 10.13 教程和升级到 Mojave 10.14.5 安装 Vmware Tools Vmware Tools 可以提高鼠标操作的流畅度、实现全屏显示、文件共享等，当在 Vmware 虚拟机中安装好 Mac OS 后，在 Vmware 软件中点击安装 Vmware Tools 的选项，会弹出提示：无法在更新服务器上找到组件。请联系Vmware技术支持或您的系统管理员。这是因为在 Mac OS 里安装 Vmware Tools 需要用到一个叫 darwin.iso 的文件，可以在 Vmware 官网下载该文件，找到最新的版本号（11.1.0），下载 packge 目录下的 com.vmware.fusion.tools.darwin.zip.tar 文件即可。下载后逐级打开压缩文件，在 payload 目录中可以找到 darwin.iso 文件，将其解压并拷贝到 Vmware 的安装根目录（C:\\Program Files (x86)\\Vmware\\Vmware Workstation）。最后将虚拟机中的 Mac OS 关机，然后在虚拟机的设置中将 CD/DVD 指定为 darwin.iso，启动 Mac OS 后在桌面右边就可以看到 Vmware Tools，直接双击执行安装操作即可。 资源下载 可以从百度网盘上打包下载以下工具，提取码为 a5qr 1234MK-Unlocker-VM15.5.zipVmware Tools linux-Win-Mac .zipVmware Workstation Pro v15.5.6 Lite.rarMacOS Mojave 10.14.5 (18F132)懒人镜像.zip 补充说明 不建议使用 VBox 安装黑苹果系统，因为 VBox 出问题的概率很大 Vmware 安装黑苹果系统的时候，建议直接使用懒人版的 cdr 镜像 Mac OS 原版 dmg 镜像只能安装在 GPT 分区格式的硬盘上，懒人版 cdr 镜像可以安装在 MBR 格式和 GPT 分区格式的硬盘上 Vmware 15.5.6 Pro 里的 Mac OS 在正常情况下可以直接识别到 IPhone 设备，导航到 菜单栏 - 虚拟机 - 可移动设备 就可以看到，如果无法识别，建议在 Windows 系统（宿主机）上安装好 iTunes 再试试 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Meson 入门指南之一","url":"/posts/68d93948.html","text":"相关站点 Meson 官网 Meson 官方文档 Meson GitHub 项目 Meson 介绍Meson 的简介Meson（The Meson Build System）是个项目构建系统，类似的构建系统有 Makefile、CMake、automake …。 Meson 是一个由 Python 实现的开源项目，其思想是，开发人员花费在构建调试上的每一秒都是浪费，同样等待构建过程直到真正开始编译都是不值得的。因此，Meson 的设计目的是在用户友好的同时不损害性能，Meson 提供客户语言（custom language）作为主要工具，用户可以使用它完成项目构建的描述。客户语言的设计目标是简单（simplicity）、清晰（clarity）、简洁（conciseness），其中很多灵感来源于 Python 语言。Meson 的另个一主要设计目的是为现代编程工具提供优秀的支持和最好的实现。这包括一些特性如：单元测试（unit testing）、代码覆盖率报告（code coverage reporting）、头文件预编译（precompiled headers）。用户不需要寻找第三方宏指令（third party macros）或编写 Shell 脚本来实现这些特性，Meson 可以开箱即用。Meson 相比 CMake 来说，不仅仅支持 C/C++，还支持多种编程语言。如今，很多项目都由 CMake 转向到了 Meson，例如 DPDK 和 Mapnik。 Ninja 的简介项目开发中一般将 Meson 和 Ninja 配合使用，Meson 负责构建项目依赖关系，Ninja 负责编译代码。Ninja 是一个轻量的构建系统，主要关注构建的速度。它与其他构建系统的区别主要在于两个方面：一是 Ninja 被设计成需要一个输入文件的形式，这个输入文件则由高级别的构建系统生成；二是 Ninja 被设计成尽可能快速执行构建的工具。 Meson 的特性 支持多种平台，包括 Linux、macOS、Windows、GCC、Clang、Visual Studio 等 支持多种编程语言，包括 C/C++、D、Fortran、Java、Rust 支持在一个非常可读和用户友好的非图灵完整 DSL 中构建定义 支持很多操作系统和裸机进行交叉编译 支持极快的完整和增量构建而优化，而不牺牲正确性 支持与发行版包一起工作的内置多平台依赖提供程序 Meson 的依赖Meson 是依赖 Python 与 Ninja 实现的，依赖的版本如下： Python (version 3.6 or newer) Ninja (version 1.8.2 or newer) Meson 安装Windows 平台 a）在 Meson GitHub Releases 网站下载 Windows 版的安装程序，如 meson-0.60.3-64.msi b）双击 meson-0.60.3-64.msi 安装程序，按默认选项直接安装 Meson c）在系统的 开始菜单栏 里，找到 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx），双击运行后，在 CMD 窗口内执行以下命令查看 Meson 和 Ninja 的版本 12345&gt; meson --version0.60.3&gt; ninja --version1.10.2 Debian/Ubuntu1# apt install -y meson ninja-build Fedora/CentOS12345# yum install -y meson ninja-build# 或者# dnf install -y meson ninja-build 通过 PyPi 安装Meson 可以直接通过 PyPi 安装，但必须确保使用的是 Python3 的 pip，安装命令如下： 1# pip3 install meson ninja 或者使用标准的 Python 命令安装 Meson 12345# 安装meson# python3 -m pip install meson# 安装ninja# python3 -m pip install ninja Meson 运行注意 若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 通过 Mesonn 初始化新的 C/C++ 项目，并使用 Meson 构建项目 1234567891011# 创建一个新目录来保存项目文件$ mkdir meson_project# 进入项目目录$ cd meson_project# 使用Meson初始化并构建一个新的C/C++项目，会自动生成\"meson.build\"配置文件和C/C++源文件$ meson init --name meson_project --build# 项目构建完成后，默认的构建目录是build，可以直接运行构建生成的可执行文件$ build/meson_project 当项目代码发生变更后，可以进入 build 目录重新构建代码 12345# 进入build目录$ cd build# 重新构建代码$ meson compile Meson 项目的顶层目录结构如下 1234meson_project├── build # Meson的构建目录├── meson.build # Meson的配置文件└── meson_project.c # C/C++源文件 Meson 指定编译参数通过 meson configure 命令可以查看 Meson 内置的编译参数、默认值以及可选值 12345# 进入Meson项目的根目录$ cd meson_project# 查看Meson的编译参数$ meson configure Meson 项目可以通过 meson_options.txt 配置文件来增加项目特有的编译参数，如： 1234option('tests', type: 'boolean', value: true, description: 'build unit tests')option('use_hpet', type: 'boolean', value: false, description: 'use HPET timer in EAL') Meson 还支持在生成项目编译配置时，通过 -D 指定编译参数 1234567891011# 进入Meson项目的根目录$ cd meson_project# 指定编译参数，生成输出目录$ meson build -Dprefix=/usr -Dtests=disabled# 进入输出目录$ cd build# 编译代码$ ninja -j8 Meson 打印编译信息通过 --verbose 参数，Messon 和 Ninja 可以打印详细的编译信息，包括编译项目时，执行的所有命令 12345678910# 进入输出目录$ cd build# 编译代码$ meson compile --verbose# 或者# 编译代码$ ninja --verbose Meson 实战应用案例构建可执行项目注意 若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建项目，目录结构如下，点击下载完整的案例代码 123meson_demo├── main.c└── meson.build main.c 的文件内容 123456#include &lt;stdio.h&gt;int main(int argc, char *argv[]) { printf(\"Hello World!\\n\"); return 0;} meson.build 的文件内容 12project('meson_demo', 'c')exe = executable('main', 'main.c') 第二步：构建项目 1234567891011121314# 进入项目目录$ meson_demo# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 运行可执行文件$ ./main Meson 配置文件（meson.build）的说明如下： project('meson_demo', 'c')：指定项目名称和编程语言的类型 exe = executable('main', 'main.c')：指定可执行文件的文件名和入口源文件 构建静态库项目注意 若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建静态库的项目，目录结构如下，点击下载完整的案例代码 12345static_lib_project├── meson.build└── src ├── static_lib.c └── static_lib.h static_lib.h 的文件内容 123456#ifndef _THIRD_LIB_#define _THIRD_LIB_ void info_print(); #endif static_lib.c 的文件内容 1234567#include &lt;stdio.h&gt;#include \"static_lib.h\"void info_print(){ printf(\"hello static library\\n\");} meson.build 的文件内容 12project('static_lib_project', 'c')static_library('static_lib', 'src/static_lib.c') 第二步：构建项目 12345678910111213141516171819202122232425# 进入项目目录$ cd static_lib_project# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 项目成功编译后，会生成静态库文件\"libstatic_lib.a“ $ ls -aldrwxr-xr-x. 6 clay clay 4096 08月 12 21:05 .drwxr-xr-x. 4 clay clay 46 08月 12 10:13 ..-rw-r--r--. 1 clay clay 2972 08月 12 10:13 build.ninja-rw-r--r--. 1 clay clay 430 08月 12 10:13 compile_commands.json-rw-r--r--. 1 clay clay 3564 08月 12 21:05 libstatic_lib.adrwxr-xr-x. 2 clay clay 31 08月 12 21:05 libstatic_lib.a.pdrwxr-xr-x. 2 clay clay 4096 08月 12 10:13 meson-infodrwxr-xr-x. 2 clay clay 26 08月 12 10:13 meson-logsdrwxr-xr-x. 2 clay clay 4096 08月 12 10:13 meson-private-rw-r--r--. 1 clay clay 808 08月 12 21:05 .ninja_deps-rw-r--r--. 1 clay clay 152 08月 12 21:05 .ninja_log Meson 配置文件（meson.build）的说明如下： project('static_lib_project', 'c')：指定项目名称和编程语言的类型 static_library('static_lib', 'src/static_lib.c')：指定静态库文件的文件名和入口源文件 构建加载第三方静态库的可执行项目注意 若使用的是 Windows 平台，则需要在 Visual Studio 开发人员工具（Native Tools Command Prompt for VS xxxx）里执行 Meson 的命令，这是因为 C/C++ 编译器只会在该工具上运行。 第一步：创建静态库的项目，目录结构如下，点击下载完整的案例代码 12345678load_static_lib_project├── meson.build└── src ├── include │&nbsp;&nbsp; └── static_lib.h ├── lib │&nbsp;&nbsp; └── libstatic_lib.a └── main.c static_lib.h 的文件内容 123456#ifndef _THIRD_LIB_#define _THIRD_LIB_ void info_print(); #endif main.c 的文件内容 1234567#include &lt;stdio.h&gt;#include \"static_lib.h\" int main(int argc, char *argv[]) { info_print(); return 0;} meson.build 的文件内容 123project('load_static_lib_project', 'c')libs=meson.get_compiler('c').find_library('static_lib', dirs : join_paths(meson.source_root(),'src/lib'))executable('load_static_lib', 'src/main.c', dependencies : libs, include_directories : 'src/include') 第二步：构建项目 1234567891011121314# 进入项目目录$ cd load_static_lib_project# 生成构建目录，build是构建目录的名称，可以自定义$ meson build # 或者 meson setup build# 进入构建目录$ cd build# 编译项目代码$ ninja# 运行可执行文件$ ./load_static_lib Meson 配置文件（meson.build）的说明如下： 第一行：指定项目名称和编程语言的类型 第二行：指定静态库文件的名称和所在目录的路径，文件名称不需要加”lib” 前缀 第三行：指定可执行文件的文件名、入口源文件、静态库的头文件所在目录的路径 参考博客 Meson 的使用 Meson 构建系统 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ c语言 linux系统编程"},{"title":"天河区珠江新城游玩攻略","url":"/posts/8f9b760f.html","text":"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 请 输 入 阅 读 密 码.","tags":"加密博客"},{"title":"天河区体育西路游玩攻略","url":"/posts/4d9c17ad.html","text":"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 请 输 入 阅 读 密 码.","tags":"加密博客"},{"title":"SpringCloud 面试题之一","url":"/posts/1cdff3b4.html","text":"微服务微服务的概述微服务理论的提出者马丁。福勒（Martin Fowler） 在其博客中详细描述了什么是微服务。微服务强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题 / 提供落地对应服务的一个服务应用；狭意的看，可以看作 Eclipse 里面的一个个微服务工程 / 或者 Module。 微服务架构的概述微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分为一组小服务，每个服务运行在自己的独立进程中，服务间通信采用轻量级通信机制 (通常是基于 HTTP 的 RESTful API)。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。另外，应该尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的编程语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的编程语言来编写服务，也可以使用不同的数据存储技术。 微服务架构的优缺点 优点： 易于开发和维护：一个微服务只会关注一个特定的业务功能，所以它业务清晰，代码量较少 单个微服务启动较快：单个微服务代码量较少，所以启动会比较快 业务之间松耦合，无论是在开发阶段或者部署阶段，不同的服务都是互相独立的 局部修改容易部署：单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈 按需伸缩：可根据需求，实现细粒度的扩展 只有业务逻辑的代码，不会和 HTML、CSS 或者其他前端页面耦合，目前有两种开发模式：前后端分离、全栈开发 缺点： 运维要求高：更多的服务意味着更多的运维投入 技术开发难度高：涉及到网络通信延迟、服务容错、数据一致性、系统集成测试、系统部署依赖、性能监控等 分布式系统固有的复杂性：使用微服务架构的是分布式系统，对于一个分布式系统，系统容错，网络延迟，分布式事务等都会带来巨大的挑战 接口调整成本高：微服务之间通过接口进行通信。如果修改某一个微服务的 API，可能所有使用了该接口的微服务都需要做调整 重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一功能，从而导致代码重复 SpringBoot 与 SpringCloudSpringBoot 与 SpringCloud 的关系 SpringBoot 专注于快速、方便的开发单个微服务个体，SpringCloud 则关注全局的服务治理 SpringCloud 将 SpringBoot 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等集成的服务 SpringBoot 可以离开 SpringCloud 独立使用开发项目，但是 SpringCloud 离不开 SpringBoot，属于依赖的关系 Dubbo 对比 SpringCloudRPC 与 REST 的区别微服务理论的提出者马丁。福勒（Martin Fowler），在其论文中可以发现其定义的服务间通信机制就是 HTTP REST。RPC 的性能比较出众，其最主要的缺陷就是服务提供方和调用方式之间依赖太强，毕竟需要为每一个微服务进行接口的定义，并通过持续集成发布，需要严格的版本控制才不会出现服务提供和调用之间因为版本不同而产生的冲突。而 REST 是轻量级的接口，服务的提供和调用不存在代码之间的耦合，只是通过一个约定进行规范，但也有可能出现文档和接口不一致而导致的服务集成问题，但可以通过 Swagger 工具整合，是代码和文档一体化解决，所以 REST 在分布式环境下比 RPC 更加灵活，这也是为什么当当网的 DubboX 在对 Dubbo 的增强中增加了对 REST 的支持的原因。 Dubbo 与 SpringCloud 的区别 功能 Dubbo SpringCloud 服务注册中心 Zookeeper、Nacos、Redis Spring Cloud Netfix Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-Monitor Spring Boot Admin 熔断器 Sentinel Spring Cloud Netflix Hystrix 服务网关 无 Spring Cloud Netflix Zuul 分布式配置 Nacos Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 信息总线 无 Spring Cloud Bus 最大区别：SpringCloud 抛弃了 Dubbo 的 RPC 通信，采用的是基于 HTTP 的 REST 方式。严格来说这两种技术方案各有优劣。虽然从一定程度上来说，SpringCloud 牺牲了服务调用的性能，但也避免了原生 RPC 带来的问题。而且 REST 相比 RPC 更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更加合适。 定位区别：Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断。而 SpringCloud 诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了 Spirng、SpirngBoot 的优势之上，两个框架在开始目标就不一致，Dubbo 定位为 RPC 框架、SpirngCloud 定位为微服务架构下的一站式解决方案（微服务生态）。作为重启 Dubbo 开源项目的负责人刘军也曾表示，如果非要类比的话，Dubbo 可以类比为 Netfix OSS 技术栈，而 SpringCloud 集成了 Netfix OSS 作为分布式服务治理解决方案，但除此之外 SpringCloud 还提供了包括 config、stream、security 等等分布式问题解决方案。当前由于 RPC 协议、注册中心元数据不匹配等问题，在面临微服务基础框架选型时，Dubbo 与 SpringCloud 只能二选一。Dubbo 日后可能会积极适配到 SpringCloud 生态，比如作为 SpringCloud 的二进制通讯方案来发挥 Dubbo 的性能优势，或者 Dubbo 通过模块化以及对 HTTP 的支持适配到 SpringCloud。 品牌机与组装机的区别：Spring Cloud 的功能很明显比 Dubbo 更加强大，涵盖面更广，而且作为 Spring 的旗舰项目，它也能够与 Spring Framework、Spring Boot、Spring Data、Spring Batch 等其他 Spring 项目完美融合，这些对于微服务而言是至关重要的。使用 Dubbo 构建的微服务架构就像组装电脑，各环节选择自由度很高，但是最终结果很有可能因为一条内存质量不行就点不亮了，总是让人不怎么放心，但是如果使用者是一名高手，那这些都不是问题。而 Spring Cloud 就像品牌机，在 Spring Source 的整合下，做了大量的兼容性测试，保证了机器拥有更高的稳定性，但是如果要在使用非原装组件外的东西，就需要对其基础原理有足够的了解。 社区支持与更新力度的区别：最为重要的是，Dubbo 停止了 5 年左右的更新，虽然 2017.9 重启了。对于技术发展的新需求，需要由开发者自行拓展升级（比如当当网自研了 Dubbox），这对于很多想要采用微服务架构的中小型软件公司，显然是不太合适的。中小型软件公司没有这么强大的技术能力去修改 Dubbo 源码 + 周边的一整套解决方案，并且不是每一个公司都有阿里的大牛 + 真实的线上生产环境测试经修改过源码的框架。 其他组件对比Eureka 对比 ZooKeeper ZooKeeper 保证的是 CP，Eureka 保证的是 AP Eureka 本质上是一个工程，而 ZooKeeper 只是一个进程 ZooKeeper 有 Leader 和 Follower 角色，Eureka 各个节点是平等关系 ZooKeeper 在选举期间注册服务瘫痪，虽然服务最终会恢复，但是选举期间不可用；Eureka 只要有一实例就可以保证服务可用，但查询到的数据可能并不是最新的 ZooKeeper 采用过半数存活原则，Eureka 采用自我保护机制解决分区问题 Eureka 自我保护机制会导致： Eureka 不再从注册列表移除因长时间没收到心跳而应该过期的服务 Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点（高可用） Eureka 在网络稳定的时候，当前实例新的注册信息会被同步到其他节点中（最终一致性） Eureka 可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像 ZooKeeper 一样使得整个注册中心瘫痪 多种主流注册中心的对比 Zuul 对比 Spring Cloud Gateway 常见问答什么是服务熔断、服务降级在复杂的分布式系统中，微服务之间的相互调用，有可能出现各种各样的原因导致服务的阻塞；在高并发场景下，服务的阻塞意味着线程的阻塞，导致当前线程不可用，更严重的会让服务器线程全部阻塞，导致服务器崩溃。由于服务之间的调用关系是同步的，会对整个微服务系统造成服务雪崩。为了解决某个微服务的调用响应时间过长或者不可用进而占用越来越多的系统资源引起的雪崩效应，这就需要进行服务熔断和服务降级处理。服务熔断指的是某个服务出现故障或异常时，起到类似现实世界中的 “保险丝” 的作用，即当某个异常条件被触发就直接熔断整个服务，而不是一直等到此服务超时。简而言之，一旦发生服务雪崩就会熔断整个服务，通过维护一个线程池，当线程达到阈值的时候就启动服务降级，如果其他请求继续访问就直接返回 FallBack 的默认值。 什么是 API 网关API 网关提供 API 全托管服务，丰富的 API 管理功能，辅助企业管理大规模的 API，以降低管理成本和安全风险。其中包括： 协议适配：当对外提供服务时使用 HTTP 协议、内部服务调用时使用 RPC，此时需要协议适配 协议转发：将外部的 HTTP 请求转换为内部的 RPC 请求 安全策略（WAF）：恶意攻击、电商系统或者 O2O 系统的防刷单、Web 爬虫 系统防刷：防刷单、Web 爬虫 流量控制：限流、防 DDOS 攻击 监控日志：API 调用日志 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"面试"},{"title":"Linux 搭建 Redis 高可用集群","url":"/posts/b8e96a9f.html","text":"前言软件环境 软件 版本 CentOS 7.9 Redis 6.0.6 集群节点规划Redis 集群至少一共需要 6 个节点，包括 3 个 Master 节点和 3 个 Slave 节点，且每个 Master 节点对应 1 个 Slave 节点，对应的关系如下： 1 Master –&gt; 1 Slave，Redis 集群需要 6 个节点，如图所示 1 Master –&gt; 2 Slave，Redis 集群需要 9 个节点，以此类推，如图所示 名称 IP 端口 Master 192.168.109 7001 Master 192.168.109 7002 Master 192.168.109 7003 Slave 192.168.109 7004 Slave 192.168.109 7005 Slave 192.168.109 7006 Redis 集群特性Redis 集群的优点无中心架构，分布式提供服务。数据按照 slot 存储分布在多个 Redis 实例上。增加 Slave 做 Standby 数据副本，用于 Failover，使集群快速恢复。实现故障 Auto Failover，节点之间通过 gossip 协议交换状态信息；投票机制完成 Slave 到 Master 角色的提升。支持在线增加或减少节点，降低硬件成本和运维成本，提高系统的扩展性和可用性。 Redis 集群的缺点客户端实现复杂，驱动要求实现 Smart Client，缓存 Slots Mapping 信息并及时更新。目前仅 JedisCluster 相对成熟，异常处理部分还不完善。客户端的不成熟，影响应用的稳定性，提高开发难度。节点会因为某些原因发生阻塞（阻塞时间大于 clutser-node-timeout），被判断为下线。这种 Failover 是没有必要的，Sentinel 模式也存在这种切换场景。 Redis 集群搭建系统初始化12345678# 添加配置一# echo \"net.core.somaxconn = 1024\" &gt;&gt; /etc/sysctl.conf# echo \"vm.overcommit_memory = 1\" &gt;&gt; /etc/sysctl.conf# sysctl -p# 添加配置二# echo \"echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\" &gt;&gt; /etc/rc.local# source /etc/rc.local 创建 Redis 用户12345# 创建redis用户组# groupadd redis# 创建redis用户（不允许远程登录）# useradd -g redis redis -s /bin/false Redis 编译安装Redis 各版本可以从官网下载，这里使用的版本是 6.0.6 1234567891011121314151617181920212223242526272829303132333435363738# 安装依赖# yum install -y centos-release-scl devtoolset-9 scl-utils-build tcl# 临时启用GCC9编译环境# scl enable devtoolset-9 bash# 下载文件# wget http://download.redis.io/releases/redis-6.0.6.tar.gz# 解压文件# tar -xvf redis-6.0.6.tar.gz# 进入解压目录# cd redis-6.0.6# 编译# make# 安装# make install PREFIX=/usr/local/redis# 创建软连接# ln -s /usr/local/redis/bin/redis-benchmark /usr/local/bin/redis-benchmark# ln -s /usr/local/redis/bin/redis-check-aof /usr/local/bin/redis-check-aof# ln -s /usr/local/redis/bin/redis-check-rdb /usr/local/bin/redis-check-rdb# ln -s /usr/local/redis/bin/redis-sentinel /usr/local/bin/redis-sentinel# ln -s /usr/local/redis/bin/redis-server /usr/local/bin/redis-server# ln -s /usr/local/redis/bin/redis-cli /usr/local/bin/redis-cli# 拷贝配置文件# cp redis.conf /usr/local/redis# 创建日志目录# mkdir -p /var/log/redis# 文件授权# chown -R redis:redis /var/log/redis# chown -R redis:redis /usr/local/redis 更改 Redis 的基础配置内容，其中有些配置文件的文件名都包含了端口号，是为了后面方便使用不同的端口号来区分各个节点 1234567891011121314# 更改基础配置# vim /usr/local/redis/redis.confio-threads 2daemonize yes# bind 127.0.0.1protected-mode nomasterauth 123456requirepass 123456dbfilename dump_6379.rdbpidfile /var/run/redis_6379.pidcluster-config-file nodes_6379.confappendfilename \"appendonly_6379.aof\"logfile \"/var/log/redis/redis_6379.log\" 验证 Redis 是否安装成功 12345678910111213141516# 切换Redis用户# su redis# 进入安装目录$ cd /usr/local/redis# 启动Redis$ ./bin/redis-server redis.conf# 查看Redis的运行状态$ ps -aux|grep redis# 关闭Redis$ ./bin/redis-cli127.0.0.1:6379&gt; auth 123456127.0.0.1:6379&gt; shutdown Redis 搭建集群创建 Redis 集群各节点的安装文件，并更改与端口相关的所有配置内容（例如：port、pidfile、dbfilename、logfile、cluster-config-file），同时开启对集群的支持 1234567891011121314151617181920212223242526# 创建集群目录# mkdir -p /usr/local/redis-cluster# 拷贝各节点的安装文件# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7001# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7002# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7003# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7004# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7005# cp -r /usr/local/redis /usr/local/redis-cluster/redis-7006# 更改各节点里与端口相关的所有配置项# sed -i \"s/6379/7001/g\" /usr/local/redis-cluster/redis-7001/redis.conf# sed -i \"s/6379/7002/g\" /usr/local/redis-cluster/redis-7002/redis.conf# sed -i \"s/6379/7003/g\" /usr/local/redis-cluster/redis-7003/redis.conf# sed -i \"s/6379/7004/g\" /usr/local/redis-cluster/redis-7004/redis.conf# sed -i \"s/6379/7005/g\" /usr/local/redis-cluster/redis-7005/redis.conf# sed -i \"s/6379/7006/g\" /usr/local/redis-cluster/redis-7006/redis.conf# 开启各节点对集群的支持# sed -i \"s/# cluster-enabled/cluster-enabled/g\" `find /usr/local/redis-cluster -type f -name \"redis.conf\"`# sed -i \"s/# cluster-config-file/cluster-config-file/g\" `find /usr/local/redis-cluster -type f -name \"redis.conf\"`# sed -i \"s/# cluster-node-timeout/cluster-node-timeout/g\" `find /usr/local/redis-cluster -type f -name \"redis.conf\"`# 文件授权# chown -R redis:redis /usr/local/redis-cluster 拷贝 Redis 的集群管理工具 12345678# 进入Redis的解压目录# cd redis-6.0.6# 拷贝集群管理工具# cp src/redis-trib.rb /usr/local/redis-cluster# 文件授权# chown -R redis:redis /usr/local/redis-cluster/redis-trib.rb 创建 Shell 脚本批量启动 Redis 集群的各个节点 12345678910111213141516171819202122# vim /usr/local/redis-cluster/start-cluster.sh#!/bin/bashREDIS_CLUSTER_HOME=/usr/local/redis-clustercd $REDIS_CLUSTER_HOMEcd redis-7001./bin/redis-server redis.confcd ..cd redis-7002./bin/redis-server redis.confcd ..cd redis-7003./bin/redis-server redis.confcd ..cd redis-7004./bin/redis-server redis.confcd ..cd redis-7005./bin/redis-server redis.confcd ..cd redis-7006./bin/redis-server redis.conf Shell 脚本授权执行 123# 文件授权# chmod +x /usr/local/redis-cluster/start-cluster.sh# chown -R redis:redis /usr/local/redis-cluster/start-cluster.sh Redis 集群设置密码若需要对集群各节点设置密码，那么 requirepass 和 masterauth 都需要同时设置，且两者的密码必须一致，否则发生主从切换时，就会遇到授权问题。值得一提的是，在使用 redis-trib.rb 或者 redis-cli 构建集群的时候，两者设置密码的方式是不一样的，具体如下： redis-trib.rb：如果是使用 redis-trib.rb 工具构建集群，集群构建完成前不要配置密码，集群构建完毕需要执行以下命令逐个节点机器设置密码，不需要重启节点 1234$ redis-cli -c -p 7001config set masterauth 123456config set requirepass 123456config rewrite redis-cli：如果是使用 redis-cli 构建集群，首先需要在集群各节点的 redis.conf 中配置密码，包括 requirepass 和 masterauth，然后在构建集群的命令行里加入 -a password 参数，其中的 password 就是集群各节点的密码 12masterauth 123456requirepass 123456 12345678$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1 Redis 集群构建启动首先执行 Shell 脚本批量启动所有 Redis 节点，切记不能以 Root 用户的身份启动 Redis，否则会造成系统重大安全隐患 123456789101112131415# 切换到Redis用户# su redis# 启动集群节点$ ./usr/local/redis-cluster/start-cluster.sh# 查看各节点的运行状态$ ps -aux|grep redisredis 32641 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7001 [cluster]redis 32649 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7002 [cluster]redis 32657 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7003 [cluster]redis 20814 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7004 [cluster]redis 20822 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7005 [cluster]redis 20830 0.0 0.0 181880 7688 ? Ssl 21:33 0:00 ./bin/redis-server *:7006 [cluster] 使用 redis-trib.rb 工具构建集群时，在 6.0.6 里面会给打印提示，让你使用 redis-cli 命令来构建集群，并提供给你需要使用的命令，使其和 redis-trib.rb 达到一致的效果（这样就可以不用再单独的安装 Ruby），原本使用 redis-trib.rb 的语句如下 1234567$ ./redis-trib.rb create --replicas 1 \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 提供使用的 redis-cli 的语句如下，建议使用 redis-cli 命令来构建 Redis 集群，因为这样就不需要额外安装 Ruby 12345678$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1 可以看出两个语句都差不多，而且语句意思也差不多，--cluster-replicas 1 表示主备的比例关系为 1，即一个主节点对应一个备节点，前三个 ip:port 默认表示主节点，后面的依次为前三个主节点的备节点。在生产环境使用多台服务器搭建 Redis 集群时，为了保证高可用（在任意一台服务器挂了的情况下都不影响 Redis 集群的使用），主备节点不可以部署在同一台服务器上，因为主备节点在同一台服务器上，则备节点也没有太大的意义了，所以要错开对应。当主节点宕机后，备节点可以充当主节点继续工作，使 Redis 集群正常运行。 执行完构建集群的命令后（只需执行一次），Redis 默认罗列出集群的对应关系来让你确定，输入 yes 完成集群创建即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.1.109:7006 to 192.168.1.109:7001Adding replica 192.168.1.109:7003 to 192.168.1.109:7004Adding replica 192.168.1.109:7005 to 192.168.1.109:7002M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) masterM: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) masterM: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots:[5461-10922] (5462 slots) masterS: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 replicates 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 replicates 283abb498445ffd6206f24c451ac0b9fb7129383S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5Can I set the above configuration? (type 'yes' to accept):&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.1.109:7001)M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) master 1 additional replica(s)M: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 slots: (0 slots) slave replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 slots: (0 slots) slave replicates 283abb498445ffd6206f24c451ac0b9fb7129383M: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 slots: (0 slots) slave replicates 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 测试 Redis 集群Redis 客户端登录进某个集群节点，登录时需要指定密码，下面可以看到数据放入的哈希槽为 [12182]，属于 192.168.1.109:7002 所管控的节点，所以就直接跳转到 192.168.1.109:7002 节点来获取刚才放入的数据 12345678$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; set foo hello-&gt; Redirected to slot [12182] located at 192.168.1.109:7002OK192.168.1.109:7002&gt; get foo\"hello\"192.168.1.109:7002&gt; 查看 Redis 当前集群的信息 12345678910111213141516171819202122$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:7cluster_my_epoch:1cluster_stats_messages_ping_sent:3154cluster_stats_messages_pong_sent:3377cluster_stats_messages_fail_sent:4cluster_stats_messages_auth-ack_sent:1cluster_stats_messages_sent:6536cluster_stats_messages_ping_received:3372cluster_stats_messages_pong_received:3154cluster_stats_messages_meet_received:5cluster_stats_messages_auth-req_received:1cluster_stats_messages_received:6532 查看 Redis 特定节点的状态 12345678910111213141516171819202122232425262728293031$ redis-cli --cluster check 192.168.1.109:7003 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.1.109:7003 (cde86683...) -&gt; 0 keys | 5462 slots | 1 slaves.192.168.1.109:7002 (283abb49...) -&gt; 1 keys | 5461 slots | 1 slaves.192.168.1.109:7001 (225e37e5...) -&gt; 0 keys | 5461 slots | 1 slaves.[OK] 1 keys in 3 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.1.109:7003)M: cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005 slots: (0 slots) slave replicates 283abb498445ffd6206f24c451ac0b9fb7129383S: 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004 slots: (0 slots) slave replicates cde86683e2d314fd52cf8708f78935c6648ea3c6M: 283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006 slots: (0 slots) slave replicates 225e37e5bb340467fb58b6f9d14cfb1893bf92d5M: 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001 slots:[0-5460] (5461 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 查看 Redis 所有集群节点的信息 123456789$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster nodes7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004@17004 master - 0 1616460018217 3 connected 5461-10922225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001@17001 myself,master - 0 1616460015000 1 connected 0-5460f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006@17006 slave 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 0 1616460018000 1 connected1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005@17005 slave 283abb498445ffd6206f24c451ac0b9fb7129383 0 1616460016000 2 connected283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002@17002 master - 0 1616460016000 2 connected 10923-16383cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003@17003 slave 7a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 0 1616460017000 3 connected 验证主从切换，从上面的集群信息可以观察到 192.168.1.109:7003 节点是 192.168.1.109:7004 的 Slave 节点，因此可以 Kill 掉 192.168.1.109:7004 Master 节点的进程，然后观察 192.168.1.109:7003 节点会不会选举为新的 Master 节点，若可以则说明主从切换成功，此时 192.168.1.109:7003 节点的日志信息如下： 12345678911970:S 21 Jul 2020 22:48:40.080 * Connecting to MASTER 192.168.1.109:700411970:S 21 Jul 2020 22:48:40.080 * MASTER &lt;-&gt; REPLICA sync started11970:S 21 Jul 2020 22:48:40.081 # Error condition on socket for SYNC: Operation now in progress11970:S 21 Jul 2020 22:48:40.982 # Starting a failover election for epoch 7.11970:S 21 Jul 2020 22:48:40.985 # Failover election won: I'm the new master.11970:S 21 Jul 2020 22:48:40.985 # configEpoch set to 7 after successful failover11970:M 21 Jul 2020 22:48:40.985 * Discarding previously cached master state.11970:M 21 Jul 2020 22:48:40.985 # Setting secondary replication ID to 00c7b21f3980b471d3373792d9d61bedf7e424e6, valid up to offset: 2059. New replication ID is c9f299ab0a8124a56d76e0e8a458135893b4533611970:M 21 Jul 2020 22:48:40.985 # Cluster state changed: ok 最后重新启动 192.168.1.109:7004 节点，可以发现它会变为 192.168.1.109:7003 节点的 Slave 节点 1234567a1229732ada6ae8d8eb51ae7b7cac6242a6f8d4 192.168.1.109:7004@17004 slave cde86683e2d314fd52cf8708f78935c6648ea3c6 0 1616461490000 7 connected225e37e5bb340467fb58b6f9d14cfb1893bf92d5 192.168.1.109:7001@17001 myself,master - 0 1616461492000 1 connected 0-5460f8a5d94e9928ed615514f23ddaabd259134af709 192.168.1.109:7006@17006 slave 225e37e5bb340467fb58b6f9d14cfb1893bf92d5 0 1616461492000 1 connected1f3f441d619ceeac55ae91015a3f46ede37352bb 192.168.1.109:7005@17005 slave 283abb498445ffd6206f24c451ac0b9fb7129383 0 1616461492010 2 connected283abb498445ffd6206f24c451ac0b9fb7129383 192.168.1.109:7002@17002 master - 0 1616461491000 2 connected 10923-16383cde86683e2d314fd52cf8708f78935c6648ea3c6 192.168.1.109:7003@17003 master - 0 1616461493010 7 connected 5461-10922 Redis 集群重建（初始化）若 Redis 集群出现无法正常使用的问题，可以尝试执行以下操作来重建 Redis 集群来解决，下述操作会删除 Redis 的所有 RDB 快照数据，切记先备份好数据再进行操作。 12345678910111213141516171819202122232425# 关闭所有节点服务器上的Redis$ pkill -9 redis# 在所有节点服务器上执行以下命令（切记先备份好Redis的快照数据）$ find /usr/local/redis-cluster -type f -iname \"dump*.rdb\" | xargs rm -rf$ find /usr/local/redis-cluster -type f -iname \"nodes_*.conf\" | xargs rm -rf$ rm -rf /var/log/redis/*# 启动所有节点服务器上的Redis$ ./usr/local/redis-cluster/start-cluster.sh# 执行集群构建操作$ redis-cli -a 123456 --cluster create \\192.168.109:7001 \\192.168.109:7002 \\192.168.109:7003 \\192.168.109:7004 \\192.168.109:7005 \\192.168.109:7006 \\--cluster-replicas 1# 查询集群信息和状态$ redis-cli -c -p 7001 -a 123456127.0.0.1:7001&gt; cluster info127.0.0.1:7001&gt; cluster nodes 参考博客 Redis 6 高可用集群搭建 Redis 两台服务器组集群 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux 缓存"},{"title":"Redis 入门教程之一五大数据类型","url":"/posts/fea85f3.html","text":"系统级命令获取符合规则的键名列表KEYS 命令需要遍历 Redis 中的所有键，当键的数量较多时会严重影响性能，在生产环境中应该禁用该命令。 1KEYS pattern 示例： 12redis&gt; KEYS *1) \"book\" pattern 支持 Glob 风格的通配符格式： 符号 含义 ? 匹配一个字符 * 匹配任意个（包括 0 个）字符 [ ] 匹配括号间的任一字符，可以使用 “-” 符号来表示一个范围，如 a [b-d] 可以匹配 “ab”、”ac”、”ad” \\x 匹配字符 x，用于转义字符，如需要匹配 “?” 就需要使用 \\? 判断一个键是否存在如果键存在则返回整数类型 1，否则返回 0。 1EXISTS key 示例： 12345redis&gt; EXISTS book(integer) 1redis&gt; EXISTS noexists(integer) 0 删除键可以删除一个或多个键，返回值是删除的键的个数。 1DEL key 示例： 12345redis&gt; DEL book(integer) 1redis&gt; DEL noexists(integer) 0 DEL 命令的参数不支持通配符，但可以结合 Linux 的管道和 xargs 命令实现删除所有符合规则的键。比如要删除以 “user:” 开头的键，就可以执行以下命令： 1$ redis-cli KEYS \"user:*\" | xargs redis-cli DEL 另外由于 DEL 命令支持多个键作为参数，所以还可以执行以下命令来达到同样的效果，但是性能更好： 1$ redis-cli DEL `redis-cli KEYS \"user:*\"` 获得键值的数据类型1TYPE key 示例： 12127.0.0.1:6379&gt; type bookstring 清空当前数据库1FLUSHDB [ASYNC] 清空所有数据库1FLUSHALL [ASYNC] 设置过期时间1EXPIRE key seconds 查看剩余存活时间1TTL key 数据类型字符串类型（String）字符串类型是 Redis 中最基础的数据类型，它能存储任何形式的字符串，包括二进制数据。例如存储用户的邮箱、JSON 化的对象甚至是一张图片。一个字符串类型键允许存储的最大容量是 512 MB。字符串类型是其他 4 种数据类型的基础，其他数据类型和字符串类型的差别从某种角度来说只是组织字符串的形式不同。例如，列表类型（List）是以列表的形式组织字符串，而集合类型是以集合的形式组织字符串。 赋值与取值（字符串）123SET key valueGET key 示例： 12345redis&gt; SET book javaOKredis&gt; GET book\"java\" 取值时，当键不存在时，会返回空结果。 递增数字字符串类型可以存储任何形式的字符串，当存储的字符串是整数形式时，Redis 提供了一个实用的命令 INCR，其作用是让当前键值递增 1，并返回递增后的值。 1INCR key 示例： 12345redis&gt; INCR num(integer) 1redis&gt; INCR num(integer) 2 当要操作的键不存在时，会创建该键并设置值为 0，所以第一次递增后的结果为 1。 1234redis&gt; SET foo barredis&gt; INCR foo(error) ERR value is not an integer or out of range 当键值不是整数时，Redis 会提示错误。 增加指定的整数INCRBY 命令与 INCR 命令级别一样，只不过前者可以通过 increment 参数指定一次增加的数值。 1INCRBY key increment 示例： 12345redis&gt; INCRBY bar 2(integer) 2redis&gt; INCRBY bar 3(integer) 5 减少指定的整数DECR 命令与 INCR 命令的用法相同，只不过是让键值递减 1。 1DECR key 示例： 12redis&gt; DECR car(integer) -1 DECRBY 与 INCRBY 命令的用法相同，可以通过 increment 参数指定一次递减的数值。 1DECRBY key increment 示例： 12345redis&gt; DECRBY cat 3(integer) -3redis&gt; DECRBY cat 5(integer) -8 增加指定的浮点数INCRBYFLOAT 命令类似 INCRBY 命令，差别是 INCRBYFLOAT 可以递增一个双精度浮点数。 1INCRBYFLOAT key pattern 示例： 12345redis&gt; INCRBYFLOAT bar 2.7\"2.7\"redis&gt; INCRBYFLOAT bar 5E+4\"50002.69999999999999929\" 向尾部追加值APPEND 的作用是向键值的末尾追加 value。如果键不存在，则会创建该键并设置值为 value，返回值是追加后字符串的总长度。 1APPEND key value 示例： 12345678redis&gt; set key helloOKredis&gt; APPEND key \" world!\"(integer) 12redis&gt; GET key\"hello world!\" 获取字符串长度STRLEN 命令返回键值的长度，如果键不存在则返回 0。 1STRLEN key 示例： 12345678redis&gt; STRLEN key(integer) 12redis&gt; set key 你好OKredis&gt; STRLEN key(integer) 6 同时获取 / 设置多个键值123MGET key [key ...]MSET key value [key value ...] 示例： 123456redis&gt; MSET key1 v1 key2 v2 key3 v3redis&gt; MGET key1 key2 key31) \"v1\"2) \"v2\"3) \"v3\" 位操作位操作命令： 123456789GETBIT key offsetSETBIT key offset valueBITCOUNT key [start] [end]BITOP operation destkey key [key ...]BITPOS key value [start] [end] 一个字节由 8 个二进制位组成，Redis 提供了上述 4 个命令可以直接对二进制位进行操作。为了演示，首先将 foo 键赋值为 bar： 12redis&gt; SET foo bar(integer) 0 bar 的 3 个字母 “b”、”a”、”r” 对应的 ASCII 码分别是 98、97 和 114，转换成二进制后分别为 1100010、1100001、1110010，所以 foo 键中的二进制位结构图如下： GETBIT 命令可以获取一个字符串类型键指定位置的二进制位的值（0 或 1），索引从 0 开始。如果需要获取的二进制位的索引超出了键值的二进制位的实际长度，则默认值为 0。 12345678redis&gt; GETBIT foo 0(integer) 0redis&gt; GETBIT foo 6(integer) 1redis&gt; GETBIT foo 100000(integer) 0 SETBIT 命令可以设置字符串类型键指定位置的二进制位的值，返回值是该位置的旧值。如果要将 foo 键值设置为 aar，那么可以通过位操作将 foo 键的二进制位的索引第 6 位设置为 0，第 7 位设置为 1。 12345678redis&gt; SETBIT foo 6 0(integer) 1redis&gt; SETBIT foo 7 1(integer) 0redis&gt; GET foo\"aar\" 如果要设置的位置超过了键值的二进制的长度，SETBIT 命令会自动将中间的二进制位设置为 0；同理设置一个不存在的键的指定二进制位的值，会自动将前面的位赋值为 0。 12345redis&gt; SETBIT nofoo 10 1(integer) 0redis&gt; GETBIT nofoo 5(integer) 0 BITCOUNT 命令可以获得字符串类型键中值是 1 的二进制位个数，例如： 12345redis&gt; set foo barOKredis&gt; BITCOUNT foo(integer) 10 BITCOUNT 可以通过参数限制统计的字节范围，例如只希望统计前两个字节（即 “fo”），字节范围从 0 开始： 12345redis&gt; set foo barOKredis&gt; BITCOUNT foo 0 1(integer) 6 BITOP 命令可以对多个字符串类型键进行位运算，并将结果存储在 destkey 参数指定的键中。BITOP 命令支持的运算操作有 AND、OR、XOR 和 NOT。例如可以对 bar 和 aar 进行 OR 运算： 1234567891011redis&gt; set foo1 barOKredis&gt; set foo2 aarOKredis&gt; BITOP OR res foo1 foo2(integer) 3redis&gt; GET res\"car\" 具体的位运算过程如下图： BITPOS 命令可以获得指定键的第一个位值是 0 或者 1 的位置。以 “bar” 这个键值为例，如果想获取键值中的第一个二进制位值为 1 的位置（从 0 开始算起），则可以执行： 12345redis&gt; SET foo barOKredis&gt; BITPOS foo 1(integer) 1 对比上面位运算的过程图，正如 BITPOS 命令的执行结果所示，”bar” 中第一个值为 1 的二进制位的位置为 1（同其他命令一样，BITPOS 命令的索引也是从 0 开始算起）。如果希望指定二进制位的查询范围，那么可以使用 BITPOS 命令的第二个和第三个参数，它们分别用来指定要查询的起始字节（从 0 开始算起）和结束字节。特别注意，这里第二个和第三个参数的单位不再是二进制位，而是字节。而返回的结果（位置）是从头开始算起的，与起始字节无关。如果不设置结束字节且键值的所有二进制位都是 1 的时候，则当要查询值为 0 的二进制位的位置时，返回结果会是键值长度的下一个字位的位置，这是因为 Redis 会认为键值长度之后的二进制位都是 0。举个例子，如果想查询第二个字节到第三个字节之间（即 “a” 和 “r”）出现的第一个值为 1 的二进制位的位置，则可以执行： 12345redis&gt; SET foo barOKredis&gt; BITPOS foo 1 1 2(integer) 9 位操作应用举例： 利用位操作命令可以非常紧凑地存储布尔值。比如假设网站的每个用户都有一个递增的整数 ID，如果使用一个字符串类型键配合位操作来记录每个用户的性别（用户 ID 作为索引，二进制位值 1 和 0 表示男性和女性），那么记录 100 万个用户的性别只需占用 100 KB 多的空间，而且由于 GETBIT 和 SETBIT 的时间复杂度都是 O (1)，所以读取二进制位值性能很高。 SETBIT 命令使用注意事项： 使用 SETBIT 命令时，如果当前键的键值长度小于要设置的二进制位的位置时，Redis 会自动分配内存并将键值的当前长度到指定的位置之间的二进制位都设置为 0。此时如果要分配的内存过大，则很可能会造成服务器的暂时阻塞而无法处理同一时间的其他请求。还是举刚才存储网站用户性别的例子，如果这个网站的用户 ID 是从 100000001 开始的，那么会造成 10 多 MB 的浪费，正确的做法是给每个用户的 ID 减去 100000000 再进行存储。 散列类型（Hash）Redis 是采用字典结构以键值对的形式存储数据的，而散列类型（Hash）的键值是一种字典结构，其存储了字段（Field）和字段值的映射，但字段值只能是字符串，不支持其他数据类型，即散列类型不能嵌套其他的数据类型。一个散列类型键可以包含之多 2^32 - 1 个字段。除了散列类型，Redis 的其他数据类型同样不支持数据类型嵌套。比如集合类型的每个元素都只能是字符串，不能是另一个集合或散列表等。散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示对象的属性，而字段值则存储属性值。例如要存储 ID 为 2 的汽车对象，可以分别使用名为 color、name 和 price 的 3 个字段来存储该辆汽车的颜色、名称和价格，具体存储结构图如下： 对比关系数据库中存储的汽车对象： 关系型数据库中，数据是以二维表的形式存储的，这就要求所有的记录都拥有相同的属性，无法单独为某条记录增减属性。如果想为 ID 为 1 的汽车增加生产日期的属性，就需要吧数据表更改为如上图所示的结构。增加一个属性后对于 ID 为 2 和 3 的两条记录而言 data 字段是冗余的。而 Redis 的散列类型则不存在这个问题，上图中描述了汽车对象的存储结构，但是这个结构只是人为的约定，Redis 并不强制要求每个键都依据此结构存储，完全可以自由地为任何键增减字段而不影响其他键。 赋值与取值（散列）赋值与取值命令： 123456789HSET key field valueHGET key fieldHMSET key field value [field value ...]HMGET key field [field ...]HGETALL key 示例： 12345678redis&gt; HSET car price 500(integer) 1redis&gt; HSET car name BMW(integer) 1redis&gt; HGET car name\"BMW\" HSET 命令的方便之处在于不区分新增和更新操作，这意味着修改数据时不用事先判断字段是否存在来决定要执行的是新增操作（inert）还是更新操作（update）。当执行的是新增操作时（即之前字段不存在）HSET 命令会返回 1，当执行的是更新操作时（即之前字段已经存在）HSET 命令会返回 0。更进一步，当键本身不存在时，HSET 命令还会自动创建它。值得注意的是，Redis 中每个键都属于一个明确的数据类型，如通过 HSET 命令建立的键是散列类型，通过 SET 命令建立的键是字符串类型等等。使用一种数据类型的命令操作另一种数据类型的键会提示错误：”ERR Operation against a key holding the wrong kind of value”；但并不是所有命令都如此，比如 SET 命令可以覆盖已经存在的键而不管原来的键是什么类型。 若需要同时设置、获取多个字段的值时，可以使用 HMSET、HMGET 命令： 123456redis&gt; HMSET car2 price 500 name BMWOKredis&gt; HMGET car2 price name1) \"500\"2) \"BMW\" 若想获取键中所有字段和字段值却不知道键中有哪些字段，则应该使用 HGETALL 命令： 12345redis&gt; HGETALL car1) \"price\"2) \"500\"3) \"name\"4) \"BMW\" 判断字段是否存在HEXISTS 命令用来判断一个字段是否存在，如果存在则返回 1，否则返回 0（如果键不存在也会返回 0）。 1HEXISTS key field 示例： 12345678redis&gt; HEXISTS car model(integer) 0redis&gt; HSET car model c200(integer) 1redis&gt; HEXISTS car model(integer) 1 当字段不存在时赋值HSETNX 命令与 HSET 命令类似，区别在于如果字段已经存在，HSETNX 命令将不执行任何操作。HSETNX 命令中的 “NX” 表示 “If Not Exists”（如果不存在），同时 HSETNX 命令是原子操作，不用担心竞态条件，可以用作分布式锁的实现。 1HSETNX key field value 示例： 12345678redis&gt; HSET car model c200(integer) 1redis&gt; HSETNX car model c300(integer) 0redis&gt; HGET car model\"c200\" 增加字段HINCRBY 与 INCR、INCRBY 命令类似，可以使字段值增加指定的整数。散列类型没有 HINCR 命令，但可以通过 HINCRBY key field 1 来实现。 1HINCRBY key field increment 示例： 12345redis&gt; HINCRBY person score 60(integer) 60redis&gt; HGET person score\"60\" 当 persion 键不存在时，HINCRBY 命令会自动建立该键，并设置字段 score 的默认值为 0，然后再执行自增操作，命令的返回结果是增值后的字段值。 删除字段HDEL 命令可以删除一个或多个字段，返回值是被删除的字段个数。 1HDEL key field [field ...] 示例： 12345redis&gt; HDEL car name(integer) 1redis&gt; HDEL car name(integer) 0 只获取字段名或字段值若仅仅需要获取键中所有字段的名称或者字段值，那么可以使用 HKEYS、HVALS 命令： 123HKEYS keyHVALS key 示例： 1234567redis&gt; HKEYS car1) \"price\"2) \"model\"redis&gt; HVALS car1) \"500\"2) \"c200\" 列表类型（List）列表类型（List）可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素，或者获得列表的某一个片段。列表类型内部是使用双向链表（double linked list）实现的，所以向列表两端添加元素的时间复杂度为 O (1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的 10 条记录也是极快的（和从只有 20 个元素的列表中获取头部或尾部的 10 条记录的速度是一样的），不过使用链表的代价是通过索引访问元素比较慢，其元素遍历速度要远慢于数组。这种特性使列表类型能非常快速地完成关系数据库难以应付的场景：如社交网站的新鲜事，用户关心的只是最新的内容，使用列表类型存储，即使新鲜事的总数达到几千万个，获取其中最新的 100 条数据也是极快的。同样因为在两端插入记录的时间复杂度是 O (1)，列表类型也适合用来记录日志，可以保证加入新日志的速度不会受到已有日志数量的影响。与散列类型键最多能容纳的字段数量相同，一个列表类型键最多能容纳 2^32 − 1 个元素。借助列表类型，Redis 还可以作为队列使用。 向列表两端添加元素LPUSH 命令用来向列表左边添加元素，返回值表示添加元素后列表的总长度。 123LPUSH key value [value …]RPUSH key value [value …] 示例： 12345redis&gt; LPUSH numbers 1(integer) 1redis&gt; LPUSH numbers 2 3(integer) 3 当通过 LPUSH 命令往列表中依次添加 “1”、”2“、”3“ 时，numbers 键中的数据如下图所示： 使用 RPUSH 命令向列表右边添加元素的话，其用法和 LPUSH 命令一样： 12redis&gt; RPUSH numbers 0 -1(integer) 3 此时 numbers 键中的数据如下图所示： 从列表两端弹出元素有进有出，LPOP 命令可以从列表左边弹出一个元素。LPOP 命令执行两步操作：第一步是将列表左边的元素从列表中移除，第二步是返回被移除的元素值。 123LPOP keyRPOP key 示例： 12345redis&gt; LPOP numbers\"3\"redis&gt; RPOP numbers\"-1\" 从 numbers 列表左边弹出一个元素（也就是 ”3“），同时列表右边也弹出一个元素（即”-1“），此时 numbers 键中的数据如下图所示： 综合 LPUSH、RPUSH、LPOP、RPOP 命令，可以使用列表类型来模拟栈和队列的操作。如果想把列表当做栈，则搭配使用 LPUSH、LPOP 或 RPUSH、RPOP。如果想当成队列，则搭配使用 LPUSH、RPOP 或 RPUSH、LPOP。 获取列表中元素的个数当键不存在时，LLEN 命令会返回 0。 1LLEN key 示例： 12redis&gt; LLEN numbers(integer) 3 LLEN 命令的功能类似 SQL 语句 SELECT COUNT(*) FROM table_name，但是 LLEN 的时间复杂度为 O (1)，使用时 Redis 会直接读取现成的值，而不需要像部分关系数据库（如使用 InnoDB 存储引擎的 MySQL 表）那样需要遍历一遍数据表来统计条目数量。 获得列表片段LRANGE 命令是列表类型最常用的命令之一，它能够获得列表中的某一片段。LRANGE 命令将返回索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop），Redis 的列表起始索引为 0。LRANGE 命令在取得列表片段时，不会像 LPOP 一样删除该片段。 1LRANGE key start stop 示例： 1234redis&gt; LRANGE numbers 0 21) \"2\"2) \"1\"3) \"0\" LRANGE 命令也支持负索引，表示从右边开始计算序数，如 “-1” 表示最右边第一个元素，”-2” 表示最右边第二个元素，依次类推。显然，LRANGE numbers 0 -1 可以获取列表中的所有元素。 12345678redis&gt; LRANGE numbers 0 -11) \"2\"2) \"1\"3) \"0\"redis&gt; LRANGE numbers -2 -11) \"1\"2) \"0\" 虽然 LRANGE numbers 0 -1 可以获取列表中的所有元素，但存在一些特殊情况如下： 如果 start 的索引位置比 stop 的索引位置靠后，则会返回空列表 如果 stop 大于实际的索引范围，则会返回到列表最右边的元素 删除列表中指定的值1LREM key count value LREM 命令会删除列表中前 count 个值为 value 的元素，返回值是实际删除的元素个数。根据 count 值的不同，LREM 命令的执行方式会略有差异，具体如下： 当 count &gt; 0 时 LREM 命令会从列表左边开始删除前 count 个值为 value 的元素。 当 count &lt; 0 时 LREM 命令会从列表右边开始删除前 |count| 个值为 value 的元素。 当 count = 0 是 LREM 命令会删除所有值为 value 的元素。 示例： 1234567891011121314redis&gt; LRANGE numbers 0 -11) \"2\"2) \"1\"3) \"0\"4) \"2\"# 从右边开始删除第一个值为”2“的元素redis&gt; LREM numbers -1 2(integer) 1redis&gt; LRANGE numbers 0 -11) \"2\"2) \"1\"3) \"0\" 获取与设置指定索引的元素值如果要将列表类型当作数组来用，LINDEX 命令是必不可少的。LINDEX 命令用来返回指定索引的元素，索引从 0 开始。 123LINDEX key indexLSET key index value 示例： 12345678redis&gt; LRANGE numbers 0 -11) \"4\"2) \"3\"3) \"2\"4) \"1\"redis&gt; LINDEX numbers 1\"3\" LSET 是另一个通过索引操作列表的命令，它会将索引为 index 的元素赋值为 value。 1234567891011redis&gt; LRANGE numbers 0 -11) \"4\"2) \"3\"3) \"2\"4) \"1\"redis&gt; LSET numbers 1 10OKredis&gt; LINDEX numbers 1\"10\" 只保留列表指定片段LTRIM 命令可以删除指定索引范围之外的所有元素，其指定列表范围的方法和 LRANGE 命令相同，即保留索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop）。 1LTRIM key start stop 示例： 123456789101112redis&gt; LRANGE numbers 0 -11) \"4\"2) \"3\"3) \"2\"4) \"1\"redis&gt; LTRIM numbers 1 2OKredis&gt; LRANGE numbers 0 -11) \"3\"2) \"2\" LTRIM 命令常和 LPUSH 命令一起使用来限制列表中元素的数量，比如记录日志时希望只保留最近的 100 条日志，则每次加入新元素时调用一次 LTRIM 命令即可： 123LPUSH logs $newLogLTRIM logs 0 99 向列表中插入元素LINSERT 命令首先会在列表中从左到右查找值为 pivot 的元素，然后根据第二个参数是 BEFORE 还是 AFTER 来决定将 value 插入到该元素的前面还是后面，命令的返回值是插入后列表的元素个数。 1LINSERT key BEFORE|AFTER pivot value 示例： 123456789101112131415redis&gt; LRANGE numbers 0 -11) \"4\"2) \"3\"3) \"2\"4) \"1\"redis&gt; LINSERT numbers after 1 0(integer) 5redis&gt; LRANGE numbers 0 -11) \"4\"2) \"3\"3) \"2\"4) \"1\"5) \"0\" 将元素从一个列表转到另一个列表RPOPLPUSH 是个很有意思的命令，从名字就可以看出它的功能：先执行 RPOP 命令再执行 LPUSH 命令。RPOPLPUSH 命令会先从 source 列表类型键的右边弹出一个元素，然后将其加入到 destination 列表类型键的左边，并返回这个元素的值，整个过程是原子的。 1RPOPLPUSH source destination 当把列表类型作为队列使用时，RPOPLPUSH 命令可以很直观地在多个队列中传递数据。当 source 和 destination 相同时，RPOPLPUSH 命令会不断地将队尾的元素移到队首，借助这个特性可以实现一个网站监控系统：使用一个队列存储需要监控的网址，然后监控程序不断地使用 RPOPLPUSH 命令循环取出一个网址来测试可用性。这里使用 RPOPLPUSH 命令的好处在于在程序执行过程中仍然可以不断地向网址列表中加入新网址，而且整个系统容易扩展，允许多个客户端同时处理队列。 列表阻塞操作BLPOP 命令是 LPOP 命令的阻塞版本，当给定列表内没有任何元素可供弹出的时候，Redis 连接将被 BLPOP 命令阻塞，直到等待超时或发现可弹出元素为止。超时参数 timeout 接受一个以秒为单位的数字作为值，设为 0 表示阻塞时间可以无限期延迟。当给定多个 Key 参数时，BLPOP 命令会按参数 Key 的先后顺序依次检查各个列表，弹出第一个非空列表的头元素，并和被弹出元素所属的列表的名字一起，组成结果返回给调用者。如果所有给定 Key 都不存在或包含空列表，那么 BLPOP 命令将阻塞连接直到等待超时，或者有另一个客户端对给定 Key 的任意一个执行 LPUSH 或 RPUSH 命令为止。BRPOP、BRPOPLPUSH 命令与 BLPOP 命令类似，这里不再累述。 12345BLPOP key [key ...] timeoutBRPOP key [key ...] timeoutBRPOPLPUSH source destination timeout 示例：假设现在有 job 、 command 和 request 三个列表，其中 job 不存在， command 和 request 都持有非空列表。 123456789redis&gt; LPUSH command \"update system\"(integer) 1redis&gt; LPUSH request \"visit page\"(integer) 1redis&gt; BLPOP job command request 01) \"command\"2) \"update system...\" 上面的例子中，BLPOP 命令返回的元素来自 command 列表，因为它是按” 查找 job -&gt; 查找 command -&gt; 查找 request “这样的顺序，找到第一个非空列表 command。 集合类型（Set）在集合中的每个元素都是不同的，且没有顺序。一个集合类型键可以存储至多 2^32 - 1 个字符串。集合类型与散列类型的对比如下： 比较内容 集合类型 列表类型 存储内容 至多 2^32 - 1 个字符串 至多 2^32 - 1 个字符串 有序性 否 是 唯一性 是 否 集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等。由于集合类型在 Redis 内部是使用值为空的散列表（Hash Table）实现的，所以这些操作的时间复杂度都是 O (1)。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算。 增加、删除元素SADD 命令用来向集合中增加一个或多个元素，如果键不存在则会自动创建。因为在一个集合中不能有相同的元素，所以如果要加入的元素已经存在于集合中就会忽略这个元素。该命令的返回值是成功加入的元素数量（忽略的元素不计算在内）。 1SADD key member [member …] 示例： 12345redis&gt; SADD letters a(integer) 1redis&gt; SADD letters a b c(integer) 2 SREM 命令用来从集合中删除一个或多个元素，并返回删除成功的个数。 1SREM key member [member …] 示例： 12redis&gt; SREM letters b c(integer) 2 获取集合中的所有元素SMEMBERS 命令会返回集合中的所有元素。 1SMEMBERS key 示例： 123redis&gt; SMEMBERS letters1) \"a\"2) \"b\" 判断元素是否在集合中判断一个元素是否在集合中是一个时间复杂度为 O (1) 的操作，无论集合中有多少个元素，SISMEMBER 命令始终可以极快地返回结果。当值存在时 SISMEMBER 命令返回 1，当值不存在或键不存在时返回 0。 1SISMEMBER key member 示例： 12redis&gt; SISMEMBER letters a(integer) 1 集合间运算集合间运算命令（差集、交集、并集）： 12345SDIFF key [key ...]SINTER key [key ...]SUNION key [key ...] SDIFF 命令用来对多个集合执行差集运算。集合 A 与集合 B 的差集表示为 A−B，代表所有属于 A 且不属于 B 的元素构成的集合。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SDIFF setA setB1) \"1\"redis&gt; SDIFF setB setA1) \"4\" SDIFF 命令自持同时传入多个键，下面的例子中，计算顺序是先计算 setA 与 setB 的差集，再计算结果与 setC 的差集。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SADD setC 2 3(integer) 2redis&gt; SDIFF setA setB setC1) \"1\" SINTER 命令用来对多个集合执行交集运算。集合 A 与集合 B 的交集表示为 A ∩ B，代表所有属于 A 且属于 B 的元素构成的集合。SINTER 同样支持同时传入多个键。 123456789redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SINTER setA setB1) \"2\"2) \"3\" SUNION 命令用来对多个集合执行并集运算。集合 A 与集合 B 的并集表示为 A ∪ B，代表所有属于 A 或者属于 B 的元素构成的集合。SUNION 同样支持同时传入多个键。 1234567891011redis&gt; SADD setA 1 2 3(integer) 3redis&gt; SADD setB 2 3 4(integer) 3redis&gt; SUNION setA setB1) \"1\"2) \"2\"3) \"3\"4) \"4\" 获取集合中元素的个数SCARD 命令用来获得集合中的元素个数。 1SCARD key 示例： 12345678redis&gt; SMEMBERS setA1) \"b\"2) \"d\"3) \"a\"4) \"c\"redis&gt; SCARD setA(integer) 4 进行集合运算并将结果存储12345SDIFFSTORE destination key [key …]SINTERSTORE destination key [key …]SUNIONSTORE destination key [key …] SDIFFSTORE 命令和 SDIFF 命令功能一样，唯一的区别就是前者不会直接返回运算结果，而是将结果存储在 destination 键中。 SDIFFSTORE 命令常用于需要进行多步集合运算的场景中，如需要先计算差集再将结果和其他键计算交集。 SINTERSTORE 、 SUNIONSTORE 命令与 SDIFFSTORE 类似，不再赘述。 随机获得集合中的元素SRANDMEMBER 命令用来随机从集合中获取一个元素，还可以传递 count 参数来一次随机获得多个元素。根据 count 的正负不同，SRANDMEMBER 命令的具体表现也不同： 当 count 为正数时，SRANDMEMBER 会随机从集合里获得 count 个不重复的元素。如果 count 的值大于集合中的元素个数，则 SRANDMEMBER 会返回集合中的全部元素。 当 count 为负数时，SRANDMEMBER 会随机从集合里获得 |count| 个的元素，这些元素有可能相同。 SRANDMEMBER 命令返回的结果并不是非常随机的，根本原因是由集合类型的存储结构（Hash Table）决定的，点击查看详细解释 1SRANDMEMBER key [count] 示例： 123456789101112131415161718192021redis&gt; SMEMBERS setA1) \"b\"2) \"d\"3) \"a\"4) \"c\"redis&gt; SRANDMEMBER setA\"b\"redis&gt; SRANDMEMBER setA 11) \"c\"redis&gt; SRANDMEMBER setA -21) \"c\"2) \"c\"redis&gt; SRANDMEMBER setA 51) \"b\"2) \"a\"3) \"d\"4) \"c\" 从集合中弹出一个元素由于集合类型的元素是无序的，所以 SPOP 命令会从集合中随机选择一个元素弹出。 1SPOP key 示例： 12345678redis&gt; SMEMBERS setA1) \"b\"2) \"d\"3) \"a\"4) \"c\"redis&gt; SPOP setA\"c\" 有序集合类型（Sorted Set）在集合类型的基础上有序集合类型为集合中的每个元素都关联了一个分数，这使得不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能够获得分数最高（或最低）的前 N 个元素、获得指定分数范围内的元素等与分数有关的操作。虽然集合中每个元素都是不同的，但是它们的分数却可以相同。 有序集合类型和列表类型的相同点： 都是有序的 都可以获得某一范围的元素 有序集合类型和列表类型的不同点： 列表类型是通过双向链表实现的，获取靠近两端的数据速度极快，而当元素增多后，访问中间数据的速度会较慢，所以它更加适合实现如 “新鲜事” 或 “日志” 这样很少访问中间元素的应用 有序集合类型是使用散列表（Hash Table）和跳跃表（Skip List）实现的，所以即使读取位于中间部分的数据速度也很快，时间复杂度是 O (log (N)) 列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数） 有序集合要比列表类型更耗费内存 增加元素ZADD 命令用来向有序集合中加入一个元素和该元素的分数，如果该元素已经存在则会用新的分数替换原有的分数。ZADD 命令的返回值是新加入到集合中的元素个数（不包含之前已经存在的元素）。 1ZADD key score member [score member …] 示例： 12345redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZADD scoreboard 80 Peter(integer) 0 分数不仅可以是整数，还支持双精度浮点数，其中 +inf 和 -inf 分别表示正无穷和负无穷。 1234567891011redis&gt; ZADD testboard 17E+307 a(integer) 1redis&gt; ZADD testboard 1.5 b(integer) 1redis&gt; ZADD testboard `+inf`c(integer) 1redis&gt; ZADD testboard `-inf` d(integer) 1 获取元素的分数1ZSCORE key member 示例： 12redis&gt; ZSCORE scoreboard Tom\"89\" 获得排名在某个范围的元素列表ZRANGE 命令会按照元素分数从小到大的顺序返回索引从 start 到 stop 之间的所有元素（包含两端的元素：start、stop）。ZRANGE 命令与 LRANGE 命令十分类似，如索引都是从 0 开始，负数代表从后向前查找（−1 表示最后一个元素）。 123ZRANGE key start stop [WITHSCORES]ZREVRANGE key start stop [WITHSCORES] 示例： 1234567891011redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZRANGE scoreboard 0 21) \"Peter\"2) \"Tom\"3) \"Jim\"redis&gt; ZRANGE scoreboard 1 -11) \"Tom\"2) \"Jim\" 如果需要同时获得元素的分数的话，可以在 ZRANGE 命令的尾部加上 WITHSCORES 参数： 1234567redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES1) \"Peter\"2) \"67\"3) \"Tom\"4) \"89\"5) \"Jim\"6) \"100\" ZRANGE 命令的时间复杂度为 O (log n+m)，其中 n 为有序集合的基数，m 为返回的元素个数。如果两个元素的分数相同，Redis 会按照字典顺序（即 0 &lt; 9 &lt; A &lt; Z &lt; a &lt; z 的顺序）来进行排列。如果元素的值是中文，那么排列顺序取决于中文的编码方式，例如使用 UTF-8 编码时排列顺序如下，可见此时 Redis 依然是按照字典顺序排列这些元素。 12345678redis&gt; ZADD chineseName 0 马华 0 刘墉 0 司马光 0 赵哲(integer) 4redis&gt; ZRANGE chineseName 0 -11) \"\\xe5\\x88\\x98\\xe5\\xa2\\x89\"2) \"\\xe5\\x8f\\xb8\\xe9\\xa9\\xac\\xe5\\x85\\x89\"3) \"\\xe8\\xb5\\xb5\\xe5\\x93\\xb2\"4) \"\\xe9\\xa9\\xac\\xe5\\x8d\\x8e\" ZREVRANGE 命令与 ZRANGE 命令的唯一不同在于 ZREVRANGE 命令是按照元素的分数从大到小的顺序输出结果。 1234567redis&gt; ZREVRANGE scoreboard 0 -1 WITHSCORES1) \"Jim\"2) \"100\"3) \"Tom\"4) \"89\"5) \"Peter\"6) \"67\" 获得指定分数范围的元素ZRANGEBYSCORE 命令参数虽然多，但是都很好理解。该命令按照元素分数从小到大的顺序返回分数在 min 和 max 之间（包含 min 和 max ）的元素。值得注意的是，ZREVRANGEBYSCORE 命令不仅是按照元素分数从大往小的顺序输出结果，而且它的 min 和 max 参数的位置与 ZRANGEBYSCORE 命令是相反的。 123ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] 示例： 123456redis&gt; ZADD scoreboard 89 Tom 67 Peter 100 Jim(integer) 3redis&gt; ZRANGEBYSCORE scoreboard 80 1001) \"Tom\"2) \"Jim\" 如果希望分数范围不包含端点值，可以在分数前加上 “(” 符号。例如，希望返回 80 分到 100 分的数据，可以含 80 分，但不包含 100 分，则命令如下： 12redis&gt; ZRANGEBYSCORE scoreboard 80 (1001) \"Tom\" min 和 max 还支持无穷值，这和 ZADD 命令一样，其中 +inf 和 -inf 分别表示正无穷和负无穷。比如希望得到分数高于 80 分（不包含 80 分）的人的名单，但却不知道最高分是多少，这时候就可以用上 +inf： 123redis&gt; ZRANGEBYSCORE scoreboard (80 +inf1) \"Tom\"2) \"Jim\" LIMIT offset count 与 SQL 中的用法基本相同，即在获得的元素列表的基础上向后偏移 offset 个元素，并且只获取 count 个元素。例如下面的例子中，表示获得分数高于 60 分的，并从第二个人开始的 3 个人： 123456789101112131415161718redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES 1) \"Jerry\" 2) \"56\" 3) \"Peter\" 4) \"67\" 5) \"Yvonne\" 6) \"67\" 7) \"Tom\" 8) \"89\" 9) \"Wendy\"10) \"92\"11) \"Jim\"12) \"100\"redis&gt; ZRANGEBYSCORE scoreboard 60 +inf LIMIT 1 31) \"Yvonne\"2) \"Tom\"3) \"Wendy\" 如果想获取分数低于或等于 100 分的前 3 个人，可以借助 ZREVRANGEBYSCORE 命令实现。ZREVRANGEBYSCORE 命令不仅是按照元素分数从大往小的顺序输出结果，而且它的 min 和 max 参数的位置与 ZRANGEBYSCORE 命令是相反的。 123456789101112131415161718redis&gt; ZREVRANGE scoreboard 0 -1 WITHSCORES 1) \"Jim\" 2) \"100\" 3) \"Wendy\" 4) \"92\" 5) \"Tom\" 6) \"89\" 7) \"Yvonne\" 8) \"67\" 9) \"Peter\"10) \"67\"11) \"Jerry\"12) \"56\"redis&gt; ZREVRANGEBYSCORE scoreboard 100 0 LIMIT 0 31) \"Jim\"2) \"Wendy\"3) \"Tom\" 增减某个元素的分数ZINCRBY 命令可以增加一个元素的分数，返回值是更改后的分数。 1ZINCRBY key increment member 示例： 12345678redis&gt; ZSCORE scoreboard Peter\"67\"redis&gt; ZINCRBY scoreboard 6 Peter\"73\"redis&gt; ZSCORE scoreboard Peter\"73\" increment 也可以是个负数表示减分，例如给 Peter 减 4 分： 12redis&gt; ZINCRBY scoreboard -4 Peter\"69\" 如果指定的元素不存在，Redis 在执行命令前会先建立它并将它的分数值赋为 0，然后再执行增减操作。 获取集合中元素的数量1ZCARD key 示例： 12redis&gt; ZCARD scoreboard(integer) 6 获得指定分数范围内的元素个数ZCOUNT 命令的 min 和 max 参数的特性与 ZRANGEBYSCORE 命令中的一样。 1ZCOUNT key min max 示例： 12345678910111213141516171819redis&gt; ZRANGE scoreboard 0 -1 WITHSCORES 1) \"Jerry\" 2) \"56\" 3) \"Yvonne\" 4) \"67\" 5) \"Peter\" 6) \"69\" 7) \"Tom\" 8) \"89\" 9) \"Wendy\"10) \"92\"11) \"Jim\"12) \"100\"redis&gt; ZCOUNT scoreboard 90 100(integer) 2redis&gt; ZCOUNT scoreboard (80 +inf(integer) 3 删除一个或多个元素ZREM 命令的返回值是成功删除的元素数量（不包含本来就不存在的元素）。 1ZREM key member [member …] 示例： 12345redis&gt; ZREM scoreboard Wendy(integer) 1redis&gt; ZCARD scoreboard(integer) 5 按照排名范围删除元素ZREMRANGEBYRANK 命令按照元素分数从小到大的顺序（即索引 0 表示最小的值）删除处在指定排名范围内的所有元素，并返回删除的元素数量。 1ZREMRANGEBYRANK key start stop 示例： 12345678910redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREMRANGEBYRANK testRem 0 2(integer) 3redis&gt; ZRANGE testRem 0 -11) \"d\"2) \"e\"3) \"f\" 按照分数范围删除元素ZREMRANGEBYSCORE 命令会删除指定分数范围内的所有元素，参数 min 和 max 的特性和 ZRANGEBYSCORE 命令中的一样，返回值是删除的元素数量。 1ZREMRANGEBYSCORE key min max 示例： 123456789101112redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREMRANGEBYSCORE testRem (4 5(integer) 1redis&gt; ZRANGE testRem 0 -11) \"a\"2) \"b\"3) \"c\"4) \"d\"5) \"f\" 获得元素的排名123ZRANK key memberZREVRANK key member ZRANK 命令会按照元素分数从小到大的顺序获得指定的元素的排名（从 0 开始，即分数最小的元素排名为 0）。 12345redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 1redis&gt; ZRANK testRem b(integer) 1 ZREVRANK 命令则与 ZRANK 命令相反，分数最大的元素排名为 0。 12345redis&gt; ZADD testRem 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6redis&gt; ZREVRANK testRem f(integer) 0 计算有序集合的交集ZINTERSTORE 命令用来计算多个有序集合的交集并将结果存储在 destination 键中（同样以有序集合类型存储），返回值为 destination 键中的元素个数，若 destination 键已存在则会被覆盖。其中 destination 键中元素的分数是由 AGGREGATE 参数决定的。 1ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight…]] [AGGREGATE SUM|MIN|MAX] 当 AGGREGATE 是 SUM 时（也就是默认值），destination 键中元素的分数是每个参与计算的集合中该元素分数的和。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) \"a\"2) \"11\"3) \"b\"4) \"22\" 当 AGGREGATE 是 MIN 时，destination 键中元素的分数是每个参与计算的集合中该元素分数的最小值。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2 AGGREGATE MIN(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) \"a\"2) \"1\"3) \"b\"4) \"2\" 当 AGGREGATE 是 MAX 时，destination 键中元素的分数是每个参与计算的集合中该元素分数的最大值。 1234567891011121314redis&gt; ZADD sortedSets1 1 a 2 b(integer) 2redis&gt; ZADD sortedSets2 10 a 20 b(integer) 2redis&gt; ZINTERSTORE sortedSetsResult 2 sortedSets1 sortedSets2 AGGREGATE MAX(integer) 2redis&gt; ZRANGE sortedSetsResult 0 -1 WITHSCORES1) \"a\"2) \"10\"3) \"b\"4) \"20\" 计算有序集合的并集ZUNIONSTORE 命令用于计算集合间的并集，与 ZINTERSTORE 命令的使用方法一样，这里不再累述。 1ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight…]] [AGGREGATE SUM|MIN|MAX] 数据类型使用总结 数据类型 结构存储的值 结构的读写能力 博客系统中的应用 字符串类型 可以是字符串、整数或者浮点数 对整个字符串或字符串的其中一部分执行操作；对整数和浮点数执行自增或者自减操作 （1） 博客文章访问量统计（2）生成自增 ID 散列类型 包含键值对的无序散列表 添加、获取、移除单个键值对；获取所有键值对 （1）存储文章数据（2）存储文章缩略名 列表类型 一个双向链表，链表上的每个节点都包含了一个字符串 从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪（Trim）；读取单个或多个元素；根据值查找或者移除元素 （1）存储文章 ID 列表（2）存储评论列表 集合类型 包含字符串的无序收集器，并且被包含的每个字符串都不可重复 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素 （1）存储文章标签（2）通过标签搜索文章 有序集合类型 字符串成员与浮点数分值之间的有序映射，元素的排列顺序由分值的大小决定 添加、获取、删除单个元素；根据分值范围或者成员来获取元素 （1）实现按点击量排序（2）更改文章发布时间和获得指定时间范围内的文章列表 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"缓存"},{"title":"Nginx + Keepalived 实现双机主备高可用","url":"/posts/503c34e4.html","text":"前言负载均衡的实现 TCP 层实现的负载均衡，例如：LVS（调度性能强悍） 应用层实现的负载均衡，例如：Nginx、Haproxy、Apache (mod_proxy)、Varnish、Squid、Ribbon Keepalived 概述Keepalived 简介 Keepalived 是 Linux 下一个轻量级别的高可用开源解决方案，高可用 (High Avalilability)，其实两种不同的含义：广义来讲，是指整个系统的高可用行，狭义的来讲就是之主机的冗余和接管，它与 HeartBeat RoseHA 实现相同类似的功能，都可以实现服务或者网络的高可用；但是又有差别，HeartBeat 是一个专业的、功能完善的高可用软件，它提供了 HA 软件所需的基本功能，比如：心跳检测、资源接管、检测集群中的服务、在集群节点转移共享 IP 地址的所有者等等。HeartBeat 功能强大，但是部署和使用相对比较麻烦，与 HeartBeat 相比，Keepalived 主要是通过虚拟路由冗余来实现高可用功能，虽然它没有 HeartBeat 功能强大，但是 Keepalived 部署和使用非常的简单，所有配置只需要一个配置文件即可以完成。Keepalived 实现了轻量级的高可用，一般用于前端高可用，且不需要共享存储，一般常用于两个节点的高可用。而 Heartbeat 用于服务的高可用，且需要共享存储，一般用于多节点的高可用。 Keepalived 起初是专为 LVS 设计的，用来管理并监控 LVS 集群系统中各个服务节点的状态，后来又加入了可以实现高可用的 VRRP 功能。因此，Keepalived 除了能够管理 LVS 软件外，还可以实现任意两台主机之间，例如 Master 和 Backup 主机之间的故障转移和自动切换，这个主机可以是普通的不能停机的业务服务器，也可以是 LVS 负载均衡、Nginx 反向代理这样的服务器。Keepalived 软件主要是通过 VRRP 协议实现高可用功能的，VRRP 是 Virtual Router Redundancy Protocol（虚拟路由冗余协议）的缩写，VRRP 出现的目的就是为了解决静态路由的单点故障问题的，它能保证当个别节点宕机时，整个网络可以不间断、稳定地运行。所以，Keepalived 一方面具有配置管理 LVS 的功能，同时还具有对 LVS 下面节点进行健康检查的功能，另一方面也可以实现系统网络服务的高可用功能。 VRRP 协议与工作原理 在现实的网络环境中，主机之间的通信都是通过配置静态路由或者 (默认网关) 来完成的，而主机之间的路由器一旦发生故障，通信就会失效，因此这种通信模式当中，路由器就成了一个单点瓶颈，为了解决这个问题，就引入了 VRRP 协议，它是一种主备模式的协议，通过 VRRP 可以在网络发生故障时透明的进行设备切换而不影响主机之间的数据通信，这其中涉及到两个概念：物理路由器和虚拟路由器。 VRRP 可以将两台或者多台物理路由器设备虚拟成一个虚拟路由，这个虚拟路由器通过虚拟 IP（一个或者多个) 对外提供服务，而在虚拟路由器内部十多个物理路由器协同工作，同一时间只有一台物理路由器对外提供服务，这台物理路由设备被成为：主路由器（Master 角色)，一般情况下 Master 是由选举算法产生，它拥有对外服务的虚拟 IP，提供各种网络功能，如：ARP 请求，ICMP 数据转发等，而且其它的物理路由器不拥有对外的虚拟 IP，也不提供对外网络功能，仅仅接收 MASTER 的 VRRP 状态通告信息，这些路由器被统称为 “BACKUP 的角色”，当主路由器失败时，处于 BACKUP 角色的备份路由器将重新进行选举，产生一个新的主路由器进入 MASTER 角色，继续提供对外服务，整个切换对用户来说是完全透明的。 每个虚拟路由器都有一个唯一的标识号，称为 VRID，一个 VRID 与一组 IP 地址构成一个虚拟路由器，在 VRRP 协议中，所有的报文都是通过 IP 多播方式发送的，而在一个虚拟路由器中，只有处于 Master 角色的路由器会一直发送 VRRP 数据包，处于 BACKUP 角色的路由器只会接受 Master 角色发送过来的报文信息，用来监控 Master 运行状态，一般不会发生 BACKUP 抢占的情况，除非它的优先级更高，而当 MASTER 不可用时，BACKUP 也就无法收到 Master 发过来的信息，于是就认定 Master 出现故障，接着多台 BAKCUP 就会进行选举，优先级最高的 BACKUP 将称为新的 MASTER，这种选举角色切换非常之快（&lt; 1s），因而保证了服务的持续可用性。 Keepalvied 的工作原理 Keepalived 通过 VRRP 实现高可用，作为一个高性能集群软件，它还能实现对集群中服务器运行状态的监控以及故障隔离。Keepalived 工作在 TCP/IP 参考模型的 三层、四层、五层，也就是分别为：网络层，传输层和应用层，根据 TCP、IP 参数模型隔层所能实现的功能，Keepalived 运行机制如下： 在网络层： 运行 4 个重要的协议：互联网络 IP 协议，互联网络可控制报文协议 ICMP、地址转换协议 ARP、反向地址转换协议 RARP，Keepalived 在网络层采用最常见的工作方式是通过 ICMP 协议向服务器集群中的每一个节点发送一个 ICMP 数据包 (有点类似与 Ping 的功能)， 如果某个节点没有返回响应数据包，那么认为该节点发生了故障，Keepalived 将报告这个节点失效，并从服务器集群中剔除故障节点； 在传输层： 提供了两个主要的协议：传输控制协议 TCP 和用户数据协议 UDP，传输控制协议 TCP 可以提供可靠的数据输出服务、 IP 地址和端口，代表 TCP 的一个连接端，要获得 TCP 服务，需要在发送机的一个端口和接收机的一个端口上建立连接，而 Keepalived 在传输层里利用了 TCP 协议的端口连接和扫描技术来判断集群节点的端口是否正常，比如对于常见的 WEB 服务器 80 端口。或者 SSH 服务 22 端口，Keepalived 一旦在传输层探测到这些端口号没有数据响应和数据返回，就认为这些端口发生异常，然后强制将这些端口所对应的节点从服务器集群中剔除掉； 在应用层：可以运行 FTP，TELNET，SMTP，DNS 等各种不同类型的高层协议，Keepalived 的运行方式也更加全面化和复杂化，用户可以通过自定义 Keepalived 工作方式，例如：可以通过编写程序或者脚本来运行 Keepalived，而 Keepalived 将根据用户的设定参数检测各种程序或者服务是否允许正常，如果 Keepalived 的检测结果和用户设定的不一致时，Keepalived 将把对应的服务器从服务器集群中剔除； Keepalived 高可用服务对之间的故障切换转移，是通过 VRRP 来实现的。在 Keepalived 服务工作时，主 Master 节点会不断地向备节点发送（多播的方式）心跳消息，用来告诉备 Backup 节点自己还活着。当主节点发生故障时，就无法发送心跳的消息了，备节点也因此无法继续检测到来自主节点的心跳了。于是就会调用自身的接管程序，接管主节点的 IP 资源和服务。当主节点恢复时，备节点又会释放主节点故障时自身接管的 IP 资源和服务，恢复到原来的备用角色。 Keepalived 的体系结构 简单模块介绍： 1）SchedulerI/OMultiplexer 是一个 I/O 复用分发调度器，它负载安排 Keepalived 所有内部的任务请求 2）Memory Mngt 是一个内存管理机制，这个框架提供了访问内存的一些通用方法 3）Control Plane 是 Keepalived 的控制版面，可以实现对配置文件编译和解析 4）Core componets 这部分主要包含了 5 个部分 a）看门狗 (Watchdog) ：是计算机可靠领域中极为简单又非常有效的检测工具，Keepalived 正是通过它监控 Checkers 和 VRRP 进程的 b）检查者 (Checkers) : 是 Keepalived 最基础、最主要的功能，可以实现对服务器运行状态检测和故障隔离 c）VRRP 模块 (VRRP Stack) : 是 Keepalived 引用 VRRP 功能，可以实现 HA 集群中失败切换功能，负责负载均衡器之间的失败切换 FailOver d）IPVS 模块 (IPVS wrapper) : 是 IPVS 功能的一个实现，IPVSwarrper 模块将可以设置好的 IPVS 规则发送的内核空间并且提供给 IPVS 模块，最终实现 IPVS 模块的负载功能 e）VIP 切换 (Netlink Reflector) ：用来实现高可用集群 Failover 时虚拟 IP (VIP) 的设置和切换 由上图可知，两个子进程都被系统 WatchDog 看管，healthchecker 子进程实现检查各自服务器的健康程度，例如 HTTP、LVS 等等，如果 healthchecker 子进程检查到 MASTER 上服务不可用，就会通知本机上的兄弟 VRRP 子进程，让它删除通告，并且去掉虚拟 IP，转换为 BACKUP 状态 Nginx + Keepalived 搭建高可用集群部署架构图本文采用的是 Nginx + Keepalived 双机主备架构（主从模式），即使用一个 VIP 地址，Nginx 使用 2 台机器，一台做主节点（Master），一台做备节点（Backup），但同时只有一台机器工作，另一台备用机器在主机器不出现故障的时候，处于空闲状态，仅仅用于灾备。 服务器规划 角色 IP 软件 运行环境 Master 节点 192.168.1.163 CentOS 7、Nginx、Keepalived Vbox 虚拟机 Backup 节点 192.168.1.109 CentOS 7、Nginx、Keepalived VBox 虚拟机 准备工作关闭防火墙 12345# 临时关闭# systemctl stop firewalld# 永久关闭# systemctl disable firewalld 关闭 selinux 12345# 临时关闭# setenforce 0# 永久关闭# sed -i 's/enforcing/disabled/' /etc/selinux/config 软件安装要求在 Master 与 Backup 节点上都安装好 Nginx 和 Keepalived，建议使用编译安装的方式。在生产环境中，Nginx 与 Keepalived 也可以安装在不用的物理机器上。 Nginx 编译安装12345# 创建nginx用户组# groupadd nginx# 创建nginx用户（不允许远程登录）# useradd -g nginx nginx -s /bin/false 12# 安装依赖# yum install -y gcc gdb strace gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs patch e2fsprogs-devel krb5-devel libidn libidn-devel openldap-devel nss_ldap openldap-clients openldap-servers libevent-devel libevent uuid-devel uuid openssl openssl-devel pcre pcre-devel 1234567891011121314151617181920212223242526272829303132# 下载# wget http://nginx.org/download/nginx-1.17.1.tar.gz# 解压# tar -xvf nginx-1.17.1.tar.gz# 进入解压目录# cd nginx-1.17.1# 配置./configure \\ --user=nginx \\ --group=nginx \\ --prefix=/usr/local/nginx \\ --with-pcre \\ --with-http_v2_module \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module# 编译安装# make &amp;&amp; make install# 后台启动Nginx# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf# 验证访问Nginx# curl -X GET 127.0.0.1# 查看Nginx的运行状态# ps -aux|grep nginx Keepalived 编译安装12# 安装依赖# yum -y install curl gcc libnl3-devel net-snmp-devel libnl libnl-devel libnfnetlink-devel openssl openssl-devel 1234567891011121314151617181920212223242526272829303132## Keepalived官网下载地址：https://www.keepalived.org/download.html# 下载# wget http://keepalived.org/software/keepalived-2.0.18.tar.gz# 解压# tar -xvf keepalived-2.0.18.tar.gz# 进入解压目录# cd keepalived-2.0.18# 配置# ./configure --prefix=/usr/local/keepalived# 确保 \"./configure\" 命令执行完后，输出的以下支持项都为Yesfwmark socket support : YesUse VRRP Framework : YesUse VRRP VMAC : YesUse VRRP authentication : YesWith ip rules/routes : Yes# 编译安装# make &amp;&amp; make install# 创建存放Keepalived配置文件的目录# mkdir -p /etc/keepalived# 拷贝Keepalived默认的配置文件# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived# 设置Keepalived开机自启动# systemctl enable keepalived.service Keepalived 核心配置在 Makster 和 Backup 节点分别创建检查 Nginx 健康状态的脚本 /etc/keepalived/nginx_check.sh 123456789#!/bin/bashA=`ps -C nginx --no-header | wc -l`if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf sleep 2 if [ `ps -C nginx --no-header | wc -l` -eq 0 ];then killall keepalived fifi 12# 脚本授权执行# chmod +x /etc/keepalived/nginx_check.sh Keepalived 是服务器级别的，只监控服务器，Nginx 宕机了，是没有办法接管的。比如，这里是用 Nginx 做负载均衡分发请求的数据包的，如果 Master 节点的 Keepalived 服务正常运行，而 Nginx 运行异常，那么将会出现 Nginx 负载均衡服务失灵，无法切换到 Nginx 备用的负载均衡器上，后端的 Web 服务器无法收到请求。所以，应该要检测 Nginx 的服务是否正常运行，如果不是正常运行，首先尝试启动 Nginx 的服务；若 Nginx 重启失败，就应该关闭掉该节点上的 Keepalived 的服务，这样才能自动切换到 Keepalived 的 Backup 节点上。 Keepalived 的配置示例如下： 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc # 指定收件人 } # notification_email_from Alexandre.Cassen@firewall.loc # 指定发件人 # smtp_server 192.168.200.1 # SMTP服务器地址 # smtp_connect_timeout 30 # SMTP服务器连接超时时间 router_id LVS_1 # 必填，标识本节点的字符串，在不同的Keepalived服务器里唯一，通常为hostname，但不一定非得是hostname，故障发生时，发邮件通知时会用到 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script \"/etc/keepalived/nginx_check.sh\" # 检测服务健康状态的Shell脚本 interval 2 # 每隔多长时间探测一次 weight -20 # 如果条件成立的话，则权重-20}vrrp_instance VI_1 { # 定义虚拟路由，VI_1为虚拟路由的标示符，可以是自定义名称，允许定义多个虚拟路由 state MASTER # 必填，可以是MASTER或BACKUP，不过当其他节点Keepalived启动时会将Priority比较大的节点选举为MASTER interface enp0s3 # 必填，节点固有IP（非VIP）的网卡，用来发VRRP包做心跳检测 mcast_src_ip 192.168.1.109 # 本机的IP virtual_router_id 51 # 必填，虚拟路由ID，取值在0-255之间，用来区分多个Instance的VRRP组播，同一网段内ID不能重复，主备机器的该值必须为一样 priority 100 # 必填，用来选举Master的，要成为Master那么这个选项的值最好高于其他机器50个点，该项取值范围是1-255(在此范围之外会被识别成默认值100) advert_int 1 # 必填，检查间隔默认为1秒，即1秒进行一次Master选举（可以认为是健康查检时间间隔） authentication { # 必填，认证区域，认证类型有PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位），主备配置必须一样 auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 # 必填，虚拟VIP地址，建议后缀加上\"/24\"，允许有多个 } track_script { # 检测服务健康状态的Shell脚本 chk_nginx }} 在 Makster 节点创建 Keepalived 的主配置文件 /etc/keepalived/keepalived.conf，配置文件的内容如下： 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc } # notification_email_from Alexandre.Cassen@firewall.loc # smtp_server 192.168.200.1 # smtp_connect_timeout 30 router_id LVS_1 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script \"/etc/keepalived/nginx_check.sh\" interval 2 weight -20}vrrp_instance VI_1 { state MASTER interface enp0s3 mcast_src_ip 192.168.1.163 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 } track_script { chk_nginx }} 在 Backup 节点创建 Keepalived 的主配置文件 /etc/keepalived/keepalived.conf，配置文件的内容如下，与 Master 节点的最大参数区别是：router_id LVS_2、state BACKUP、mcast_src_ip 192.168.1.109 1234567891011121314151617181920212223242526272829303132333435363738global_defs { notification_email { # acassen@firewall.loc } # notification_email_from Alexandre.Cassen@firewall.loc # smtp_server 192.168.200.1 # smtp_connect_timeout 30 router_id LVS_2 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script \"/etc/keepalived/nginx_check.sh\" interval 2 weight -20}vrrp_instance VI_1 { state BACKUP interface enp0s3 virtual_router_id 51 mcast_src_ip 192.168.1.109 priority 90 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.186/24 } track_script{ chk_nginx }} 分别在 Master 节点和 Backup 节点启动 Keepalived 的服务 123456789# 启动Keepalived# service keepalived start# 查看运行状态# service keepalived status# 查看启动的日志信息# more /var/log/messages# journalctl -u keepalived 测试虚拟 IPMaster 节点查看虚拟 IP在 Master 节点执行以下命令，查看节点的 IP 状态 1# ip addr 在 Master 节点可以看到已经生成了虚拟 IP 192.168.1.186 Backup 节点查看虚拟 IP在 Backup 节点执行以下命令，查看节点的 IP 状态 1# ip addr 在 Backup 节点默认不会看到生成的虚拟 IP，如果生成那就是 Keepalived 的配置文件出现了错误，即备节点和主节点争用 IP 资源，这个现象叫做 脑裂 使用虚拟 IP 访问 Nginx分别在 Master 节点和 Backup 节点上，验证是否可通过虚拟 IP 访问本地的 Nginx 服务 12345# 确保可以Ping得通虚拟IP# ping 192.168.1.186# 访问Nginx# curl -X GET 192.168.1.186 值得一提的是，建议额外在宿主机上测试是否可以访问 VIP 主备服务器高可用切换关闭 Master 节点的 Keepalived 服务 1# service keepalived stop 查看 Backup 节点是否会生成虚拟 IP 192.168.1.186 重新启动 Master 的 Keepalived 服务，然后查看 Master 和 Backup 的虚拟 IP，此时主节点应该会将虚拟 IP 抢夺回来 1# service keepalived restar Keepalived 脑裂（主备节点均有 VIP）脑裂（split-brain）指在一个高可用（HA）系统中，当联系着的两个节点断开联系时，本来为一个整体的系统，分裂为两个独立节点，这时两个节点开始争抢共享资源，结果会导致系统混乱，数据损坏。对于无状态服务的 HA，无所谓脑裂不脑裂；但对有状态服务（比如 MySQL）的 HA，必须要严格防止脑裂。 脑裂原因一般来说脑裂问题有以下这几种原因： 高可用服务器上开启了 iptables 防火墙，阻止了心跳传消息输 高可用服务器上心跳网卡地址等信息配置不正确，导致发送心跳失败 其他服务配置不当的原因，如心跳方式不同，心跳广播冲突，软件 Bug 等 高可用服务器对之间心跳线链路发生故障，导致无法正常通信，例如：心跳线坏了（包括断了或者老化）、网卡及相关驱动损坏、IP 配置及冲突问题（网卡直连）、心跳线之间的设备故障（网卡及交换机）、仲裁的机器出现问题（采用仲裁的方案） 提示：Keepalived 配置里的同一个 VRRP 实例，如果 virtual_router_id 参数在主备节点上的配置不一致，也会导致出现脑裂现象 脑裂方案在实际生产环境中，可以从以下方面防止脑裂： 同时使用串行电缆和以太网电缆连接、同时使用两条心跳线路，这样一条线路断了，另外一条还是好的，依然能传送心跳消息 当检查脑裂时强行关闭一个心跳节点（这个功能需要特殊设备支持，如 stonith、fence）相当于备节点接收不到心跳消息，通过单独的线路发送关机命令关闭主节点的电源 做好对脑裂的监控报警 解决常见方案： 如果开启防火墙，一定要让心跳消息通过，一般通过允许 IP 段的形式解决 可以拉一条以太网网线或者串口线作为主被节点心跳线路的冗余 开发检测程序通过监控软件检测脑裂 脑裂报警脚本监控报警思路，正常情况下 Keepalived 的 VIP 是挂载在 Master 节点上的，如果在 Backup 节点发现了 VIP，同时还可以 Ping 得通 Master 节点，就触发脑裂报警。这种监控思路是假设在 Keepalived 服务自身不会宕机的基础上的，若 Master 节点上的 Keepalived 服务宕机了，VIP 会正常挂载到 Backup 节点上，同时还是可以 Ping 得通 Master 节点，这种极端情况下就会错误触发脑裂警报。 12345678910111213141516#!/bin/bash# 检查脑裂的脚本，在Backup节点上进行部署VIP=192.168.1.186MASTER_IP=192.168.1.163while truedo ping -c 2 -W 3 $MASTER_IP &amp;&gt;/dev/null if [ $? -eq 0 -a `ip add|grep \"$VIP\"|wc -l` -eq 1 ];then echo \"ha is brain.\" else echo \"ha is ok\" fi sleep 5done Nginx + Keepalived 高可用部署架构方案 双机主备方案：就是上文介绍过的，使用一个 VIP 地址，前端使用 2 台机器，一台做主节点（Master），一台做备节点（Backup），但同时只有一台机器工作，另一台备用机器在主机器不出现故障的时候，永远处于浪费状态，仅仅用于灾备，平时都是空闲着的。 双主热备方案：弥补了双机主备的缺点，使用 2 个 VIP 地址，前端使用 2 台机器，彼此互为主备，同时有两台机器工作。用户访问之后，DNS 轮询选择访问哪个 VIP，当其中一台机器出现故障，两台机器的请求会转移到同一台机器负载。 FAQMaster 节点无法访问虚拟 IPMaster 节点里的 Keepalived 服务配置好 VIP 后，通过 ip addr 可以看到 VIP 已经顺利挂载，但是在 Master 节点内部无法 Ping 通。原因是 keepalived.conf 文件中默认配置了 vrrp_strict，需要把它注释掉，重启 Keepalived 的服务后即可以 Ping 得通。vrrp_strict 参数表示严格遵守 VRRP 协议，下列情况将会阻止 Keepalived 的虚拟 IP 功能： 1）单播邻居 2）没有 VIP 地址 3）在 VRRP 版本 2 中有 IPv6 地址 Backup 节点无法访问虚拟 IP虚拟 IP 的网段要和 Real Server 真实 IP 的网段地址一致，比如 Master 节点与 Backup 节点的 IP 网段为 192.168.171，那么虚拟 IP 必须是 192.168.171.*，否则 Backup 节点无法访问虚拟 IP。 Nginx 服务使用非默认的 80 端口若 Nginx 服务使用非默认的 80 端口，那么在 Keepalived 的配置文件 keepalived.conf 里，只需要正常配置 virtual_ipaddress 参数即可，不需要关心 Nginx 具体使用的是哪个端口，因为默认可以通过 http://vip:port 的地址格式访问 Nginx。 Master 节点与 Backup 节点同时生成了虚拟 IP关闭系统防火墙，让 Master 节点和 Backup 节点可以互相通信，否则会导致主备节点都生成了两个 VIP（脑裂现象）。也可以配置主备节点之间的防火墙协议（如下），开启其他需要通信的 IP 即可： 12345678# 开启VRRP协议# firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --protocol vrrp -j ACCEPT# 或者# firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface em1 --destination 192.168.1.163 --protocol vrrp -j ACCEPT# 重载配置生效# firewall-cmd --reload 商业云服务器对 Keepalived 的支持以阿里云服务器举例，可以使用 HAVIP + VPC（Virtual Private Cloud，虚拟私有云） 来实现 Keepalived，但是普通的 ECS 是不适用的，要求必须使用 VPC 类型的 ECS，而且虚拟 IP 需要另外申请（不支持自建 VIP）。阿里云目前不支持自建 LVS 高可用负载均衡，但有现成的商业产品–负载均衡 SLB 可以选择。值得一提的是，云服务器 ECS 不支持组播和广播，这点需要注意一下。 参考博客 Keepalived 配置文件参数详解 Keepalived 虚拟 VIP 无法访问的问题 Centos 8 开启防火墙后，脑裂的问题解决 基于华为云搭建 Keepalived + Nginx 实验 Nginx 高可用集群解决方案 Nginx + Keepalived Keepalived + Nginx 实现搭建双机主备 + 双主热备 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux web服务器"},{"title":"OpenWrt 设置 IP 地址","url":"/posts/ee7f1a35.html","text":"前言由于路由器的 IP 一般都是 192.168.1.1，当接入了二级路由器时，为了让二级路由器的 IP 不与一级路由器的 IP 冲突，此时一般需要更改二级路由器的 IP 地址，下面将介绍 OpenWrt 如何通过可视化界面和更改配置文件的方式来指定 IP 地址。 查看 OpenWrt 的 IP通过 SSH 连接到 OpenWrt 后，在终端输入 ifconfig 命令，可以看到 OpenWrt 默认的 IP 地址是 192.168.1.1。这里的 SSH 登录账号，一般是 OpenWrt 可视化管理界面的登录账号，用户名一般为 root。 通过配置文件更改 IP编辑配置文件 /etc/config/network，将 192.168.1.1 改为自定义的 IP 地址（例如：192.168.2.1），然后重启路由器即可。 12345678910# vim /etc/config/networkconfig interface 'lan' option ifname 'eth0.1' option force_link '1' option type 'bridge' option proto 'static' option ipaddr '192.168.2.1' option netmask '255.255.255.0' option ip6assign '60' 通过可视化界面更改 IP菜单栏导航到：NetWork -&gt; Interfaces -&gt; LAN -&gt; General Setup，更改 IPv4 address 的 IP 地址，然后点击 保存 &amp; 应用 即可。 补充说明OpenWrt 重启后，通过 ifconfig 命令查询 IP 地址是否成功更改。值得注意的是，当二级路由器的网段更改后，那么通过 DHCP 分配给客户端设备的网段也会随着变更，例如当路由器的 IP 更改为 192.168.2.1，那么客户端设备的网段将更改为 192.168.2，同时 IP 地址为 192.168.2.xxx。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"树莓派"},{"title":"MySQL 索引的使用","url":"/posts/ba389f6e.html","text":"索引介绍索引是一种特殊的文件（InnoDB 数据表上的索引是表空间的一个组成部分），包含了对数据表里所有记录的引用指针。索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。创建索引时，需要确保该索引是应用在 SQL 查询语句的条件 (一般是 WHERE、JOIN 子句的条件)。 索引的类型（四种） FULLTEXT：即为全文索引，目前只有 MyISAM 引擎支持，其可以在 CREATE TABLE，ALTER TABLE，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR、TEXT 列上可以创建全文索引 HASH：由于 HASH 的唯一性及类似键值对的形式，很适合作为索引，HASH 索引可以一次定位，不需要像树形索引那样逐层查找，因此具有极高的效率。但是，这种高效是有条件的，即只在 “=” 和 “in” 条件下才高效，对于范围查询、排序及组合索引仍然效率不高 BTREE：一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口 Root 开始，依次遍历 Node，获取 Leaf，这是 MySQL 里默认和最常用的索引类型 RTREE：在 MySQL 很少使用，仅支持 geometry 数据类型，支持该类型的存储引擎有 MyISAM、BDb、InnoDb、NDb、Archive，相对于 BTREE，RTREE 的优势在于范围查找 索引的种类（五种） 普通索引：仅加速查询（BTREE 类型） 全文索引：对文本的内容进行分词和搜索 唯一索引：加速查询 + 列值唯一（可以有 NULL 值） 主键索引：加速查询 + 列值唯一（不可以有 NULL 值） + 每个表只能有一个主键索引 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并（使用多个单列索引组合搜索） 索引的操作创建索引： 1234567891011--创建普通索引CREATE INDEX index_name ON table_name(col_name);--创建唯一索引CREATE UNIQUE INDEX index_name ON table_name(col_name);--创建普通组合索引CREATE INDEX index_name ON table_name(col_name_1, col_name_2);--创建唯一组合索引CREATE UNIQUE INDEX index_name ON table_name(col_name_1, col_name_2); 通过修改表结构创建索引： 1ALTER TABLE table_name ADD INDEX index_name(col_name); 创建表时直接指定索引： 12345CREATE TABLE table_name ( ID INT NOT NULL, col_name VARCHAR (16) NOT NULL, INDEX index_name(col_name)); 删除索引： 12345--直接删除索引DROP INDEX index_name ON table_name;--修改表结构删除索引ALTER TABLE table_name DROP INDEX index_name; 其它相关命令： 12345678910111213--查看表结构desc table_name;--查看创建表的SQLshow create table table_name;--查看索引show index from&nbsp;table_name;--查看执行时间set profiling = 1;SQL ...show profiles; 索引使用的代价 索引虽然可以大大提高了查询速度，但同时也会降低更新表的速度，如对表进行 INSERT、UPDATE 和 DELETE 操作；因为更新表时，MySQL 不仅要保存数据，还要更新索引文件 建立索引会占用更多的磁盘空间，这是因为需要分配磁盘空间给索引文件，一般情况这个问题不太严重，但如果在一个大表上创建了多种组合索引，索引文件的体积会膨胀得很快 索引适用的场景索引创建的时机一般来说，在 WHERE 和 JOIN 子句中出现的列需要建立索引，但也不完全如此，因为 MySQL 只对 &lt;、&lt;=、=、&gt;、&gt;=、BETWEEN、IN 以及某些时候的 LIKE 才会使用索引。例如下述的 SQL 语句，就需要对 city 和 age 列建立索引，由于 mytable_m 表的 userame 也出现在了 JOIN 子句中，因此也有对它建立索引的必要。 1SELECT t.Name FROM mytable_t LEFT JOIN mytable_m ON t.Name=m.username WHERE m.age=20 AND m.city='郑州' ; 特别注意：上面提到只有某些时候的 LIKE 才需建立索引，因为在以通配符 % 开头作查询时，MySQL 不会使用索引；只有以通配符 % 结尾做查询时，MySQL 才会使用到索引。但有一种情况例外，那就是当触发了覆盖索引（select 的数据列只从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖）的情况下，以通配符 % 开头作查询 MySQL 也会使用索引。例如：如果表里面只有 id 和 username 两个字段且都加了索引，那么 select * like '%username' 查询也是会使用索引的，前提是 select 数据列都加了索引。 哪些字段应该创建索引 增删改非常频繁的字段不适合作为索引 查询中与其他表关联的字段，例如外键应该建立索引 WHERE 和 JOIN 子句中，较频繁作为查询条件的字段应该创建索引 查询中排序（order by）、分组（group by）、统计的字段应该建立索引 唯一性太差的字段不适合创建索引，尽管频繁作为查询条件，例如：性别字段 索引不生效的情况 对于多列索引，如果不是使用的第一部分，则不会使用索引 如果 MySQL 估算使用全表扫描要比使用索引快，则不会使用索引 like 查询，即是以 % 开头的查询不会使用索引，除非 select 数据列都加了索引 如果列类型是字符串，那一定要在条件中将数据使用单引号包起来，否则索引不生效 如果条件中有 or，即使其中有部分条件带索引也不会使用。换言之，必须所有列都建有索引才有效 索引使用注意事项 针对普通查询 避免使用 select * 连表时注意条件类型需一致 创建表时尽量时 char 代替 varchar &nbsp;count (1) 或 count (列) 代替&nbsp;count (*) 使用表连接（JOIN）来代替子查询（Sub-Queries） 针对索引使用 使用组合索引代替多个单列索引（经常使用多个条件查询时） 索引散列值（重复多的值）不适合建索引，例如：性别字段不适合建索引 索引不会包含有 NULL 值的列，只要列中包含有 NULL 值都将不会被包含在索引中，组合索引中只要有一列含有 NULL 值，那么这一列对于此组合索引就是无效的，因此在数据库设计时不要让字段的默认值为 NULL 不要在列上进行运算，例如 select * from users where YEAR(adddate)&lt;2007，将在每个行记录上进行运算，这将导致索引失效而进行全表扫描，因此可以改成 select * from users where adddate&lt;’2007-01-01′ 尽量使用短索引，对串列进行索引，如果可能应该指定一个前缀长度。例如：如果有一个 CHAR (255) 的列，如果在前 10 个或 20 个字符内，多数值是惟一的，那么就不要对整个列进行索引；短索引不仅可以提高查询速度，还可以节省磁盘空间和 I/O 操作 MySQL 5.0 之前，SQL 查询只能使用一个索引，因此如果 WHERE 子句中已经使用了索引的话，那么 order by、group by 中的列是不会使用索引的。因此如果数据库默认排序可以符合要求的情况下，不要使用排序操作，同时尽量使用不包含多个列的排序，如果需要最好给这些列创建组合索引 查看索引的使用效果执行计划Explain + 查询 SQL，用于显示 SQL 执行信息参数，根据参考信息可以进行 SQL 优化或者判断索引是否生效 查看索引的使用情况1show status like '%Handler_read%'; handler_read_key：这个值越高越好，越高表示使用索引查询到的次数越多 handler_read_rnd_next：这个值越高，说明查询效率低效 补充说明MySQL 查询只能使用一个索引？MySQL 5.0 之前，SQL 查询只能使用一个索引，所以要合理使用组合索引，而不是单列索引。与其说是 “数据库查询只能用到一个索引”，倒不如说和全表扫描、只使用一个索引的查询速度比起来，去分析多个索引二叉树更加耗费时间，所以绝大多数情况下数据库都是用一个索引。特别注意：从 MySQL 5.1 开始，引入了索引合并优化技术，对同一个表可以使用多个索引分别进行条件扫描。 1select count(1) from table1 where column1 = 1 and column2 = 'foo' and column3 = 'bar'; 例如上面的语句，当数据库有 N 个索引并且查询中分别都要用上它们的情况下：查询优化器（用于生成执行计划）需要进行 N 次主二叉树查找（这里主二叉树的意思是最外层的索引节点），此时的查找流程大概是：查出第一条 column1 主二叉树等于 1 的值，然后去第二条 column2 主二叉树查出 foo 的值并且当前行的 coumn1 必须等于 1，最后去 column3 主二叉树查找 bar 的值并且 column1 必须等于 1 和 column2 必须等于 foo。如果这样的流程被查询优化器执行一遍，就算不死也半条命了，查询优化器可等不及把以上计划都执行一遍，贪婪算法（最近邻居算法）可不允许这种情况的发生。所以当遇到上面的语句，数据库只要用到第一个筛选列的索引（column1），就会直接去进行表扫描了。所以与其说是数据库只支持一条查询语句只使用一个索引，倒不如说 N 个独立索引同时在一条语句使用的开销比只使用一个索引还要大。最佳推荐是使用 index(column1, column2, column3） 这种组合索引，此组合索引可以把 B+Tree 结构的优势发挥得淋漓尽致。一条主二叉树（column=1），查询到（column=1）节点后基于当前节点进行二级二叉树（column2=foo）的查询，在二级二叉树查询到（column2=foo）后，去三级二叉树（column3=bar）查找，这样查询效率会高跟多。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"数据库"},{"title":"海珠区江南西路游玩攻略","url":"/posts/c7942874.html","text":"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 请 输 入 阅 读 密 码.","tags":"加密博客"},{"title":"JVM 内存结构与 GC 算法","url":"/posts/2f77f23a.html","text":"Java 虚拟机JVM 内存结构JVM 内存结构主要有三大块：栈、堆内存、方法区。堆内存是 JVM 中最大的一块，由新生代和老年代组成，不包括永久代（方法区）；而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间，默认情况下新生代按照 8:1:1 的比例来分配。方法区存储类信息、静态变量、常量、常量池等数据，是线程共享的区域，为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。栈又分为 Java 虚拟机栈和本地方法栈，主要用于方法的执行。 堆内存堆内存（Heap）是 Java 虚拟机所管理内存最大的一块，各个线程之间共享，在虚拟机启动时创建，此区域的唯一目的就是存放实例对象，几乎所有的实例对象都在这里分配内存。堆内存是垃圾收集器（GC）管理的主要区域，因此很多时候被称为 “GC 堆”。由于现在垃圾收集器基本采用分代收集算法，所以堆内存还可以被分为新生代和老年代，而新生代内存又被分成 Eden 空间、From Survivor 空间、To Survivor 空间。Java 虚拟机规范的规定，堆内存可以在物理不连续的内存空间上，只要逻辑上是连续的即可。如果在堆内存中没有足够的内存完成实例分配，并且堆内存也无法再扩展时，将会抛出 OutOfMemoryError 异常。 方法区方法区（Method Area）包含了类信息、静态变量、常量、常量池，是各个线程共享的内存区域。它存储已被虚拟机加载的类信息、静态变量、常量、常量池，即编译器编译后的代码等数据。为了与 Java 堆区分，方法区还有一个别名 Non-Heap （非堆）。对于习惯在 HotSpot 虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为” 永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为 HotSpot 虚拟机的设计团队选择把 GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样” 永久” 存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收 “成绩” 比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。方法区中的常量和静态变量引用的对象，可作为 GC Root。 Java 虚拟机栈Java 虚拟机栈（Java Virtual Machine Stacks），是线程私有的，生命周期和线程相同。每个方法执行的同时，会创建一个栈帧（Stacks Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。方法的执行，对应栈帧在虚拟机中入栈到出栈的过程（一句话总结：创建栈帧执行方法，程序计数器会指向栈顶）。局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、double、long）、对象引用（Reference 类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和 ReturnAddress 类型（指向了一条字节码指令的地址）。其中 64 位长度的 long 和 double 类型的数据会占用 2 个局部变量空间（Slot），其余的数据类型只占用 1 个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。在 Java 虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的 Java 虚拟机都支持动态扩展，只不过 Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。Java 虚拟机栈引用的对象可作为 GC Root。 本地方法栈本地方法栈（Native Method Stack），与 Java 虚拟机栈发挥的作用相似，它们之间的区别不过是 Java 虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则为虚拟机使用的 Native 方法服务。Java 虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如 Sun HotSpot 虚拟机）直接就把本地方法栈和 Java 虚拟机栈合二为一。与 Java 虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常。本地方法栈 Native 方法引用的对象可作为 GC Root。 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器，即保证线程切换后恢复到正确的执行位置。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于 Java 虚拟机的多线程是通过线程切换并获取时间片的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，一般称这类内存区域为 “线程私有” 的内存。如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的是 Natvie 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 异常情况的区域。 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分，用于存放编译期生成的各种字面量和符号引用。这部分内容在类加载后进入方法区的运行时常量池存放。运行时常量池另一个重要特征就是具有动态性。Java 语言并不要求常量一定只有编译期才能产生，运行期间也可以将新的常量放入池中，这种特性被开发人员利用的比较多的就是 String 类的 intern() 方法。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域，但是这部分内存也被频繁的使用，而且也可能导致 OutOfMemoryError 异常。在 JDK1.4 中新加入的 NIO 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式。它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中提高性能，因为避免了 Java 堆和 Native 堆中来回复制数据。值得注意的是，本机的直接内存的分配不会受到 Java 堆大小的限制，但是会受到本机总内存的限制，这可能导致各个内存区域总和大于物理内存的限制，从而导致动态扩展时出现 OutOfMemoryError 异常。 通过参数来控制各区域的内存大小 -Xms，设置堆内存的最小空间大小 -Xmx，设置堆内存的最大空间大小 -XX:NewSize，设置新生代最小空间大小 -XX:MaxNewSize，设置新生代最大空间大小 -XX:PermSize，设置永久代（方法区）最小空间大小 -XX:MaxPermSize，设置永久代（方法区）最大空间大小 -Xss，设置每个线程的堆栈大小 特别注意：JVM 没有提供直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小来间接控制，老年代空间大小 = 堆空间大小 - 新生代大空间大小 JVM 垃圾收集机制如何确定一个对象是否会被回收引用计数算法（Reference Counting）引用计数算法是通过判断对象的引用数量来决定对象是否可以被回收。它的思路是给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加 1；当引用失效时，计数器值就减 1；任何时刻计数器为 0 的对象就是不可能再被使用的。大部分场景下，这个算法都是不错，效率也比较高；但是 Java 虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题；而且对对象赋值时均要维护引用计数器，同时计数器本身也有一定的消耗。 123456789101112131415161718192021222324252627282930/** * 引用计数算法的缺陷 */public class ReferenceCountingGC { public Object instance = null; public static final int _1MB = 1024 * 1024; /** * 占点内存，以便GC日志观看 */ private byte[] bigSize = new byte[2 * _1MB]; public static void main(String[] args) { testGC(); } public static void testGC() { ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = new ReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; //这里发生GC， objA 和 objB能否被回收？ System.gc(); }} 上述代码最后面两句将 objA 和 objB 赋值为 null，也就是说 objA 和 objB 指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为 0，那么垃圾收集器就永远不会回收它们。 可达性分析算法（Reachability Analysis）判断对象的引用链是否可达。它的思路是：通过一系列的称为 “GC Roots” 的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到 GC Roots 没有任何引用链相连（用图论的话来说就是从 GC Roots 到这个对象不可达）时，则证明此对象是不可用的，如图所示： 在 Java 中，可作为 GC Root 的对象包括以下几种： 方法区中常量引用的对象 方法区中类静态属性引用的对象 Java 虚拟机栈（栈帧中的局部变量表）中引用的对象 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象 GC 算法垃圾收集算法主要有：复制算法（Copying）、标记 - 清除算法（Mark-Sweep）、标记 - 整理算法（Mark-Compact）、分代收集算法（Generational Collection）。 标记 - 清除算法“标记 - 清除” 算法是最基础的算法，它分为 “标记” 和” 清除” 两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它有两个不足：一个是效率问题，标记和清除两个过程的效率都不高（两次扫描，耗时严重）；另一个是空间问题，标记清除之后会产生大量的不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存从而不得不提前触发另一次垃圾收集动作。 复制算法 为了解决效率问题，一种称为 “复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这块的内存用完了，就将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 将现有的内存空间分为两快，每次只使用其中一块，在垃圾收集时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾收集。如果系统中的垃圾对象很多，复制算法需要复制的存活对象数量并不会太大。因此在真正需要垃圾收集的时刻，复制算法的效率是很高的。又由于对象在垃圾收集过程中统一被复制到新的内存空间中，因此，可确保回收后的内存空间是没有碎片的。复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活的对象较多，复制的成本也将很高。该算法的缺点是将系统内存折半。 Java 虚拟机的新生代串行垃圾收集器中使用了复制算法的思想。新生代分为 Eden 空间、From Survivor 空间、To Survivor 空间。其中 From Survivor 空间和 To Survivor 空间可以视为用于复制的两块大小相同、地位相等，且可进行角色互换的空间块。From Survivor 和 To Survivor 空间也称为 Survivor 空间，即幸存者空间，用于存放未被回收的对象。在垃圾收集时，Eden 空间中的存活对象会被复制到未使用的 Survivor 空间中（假设是 To Survivor），正在使用的 Survivor 空间（假设是 From） 中的年轻对象也会被复制到 To Survivor 空间中 (大对象或者老年对象会直接进入老年代，如果 To Survivor 空间已满，则对象也会直接进入老年代)。此时，Eden 空间和 From Survivor 空间中的剩余对象就是垃圾对象，可以直接清空，To Survivor 空间则存放此次回收后的存活对象。这种改进的复制算法既保证了空间的连续性，又避免了大量的内存空间浪费。 标记 - 整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。如果不想浪费 50% 的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都 100% 存活的极端情况，所以老年代不能直接选用这种算法。标记整理算法中，标记过程仍然与 “标记 - 清除” 算法一样，但是后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法对于一个大型的系统，当创建的对象和方法变量比较多时，堆内存中的对象也会比较多，如果逐一分析对象是否该回收，那么势必造成效率低下。分代收集算法是基于这样一个事实：不同的对象的生命周期（存活情况）是不一样的，而不同生命周期的对象位于堆内存中不同的区域，因此对堆内存不同区域采用不同的策略进行回收可以提高 JVM 的执行效率。“分代收集”（Generational Collection）算法，根据对象存活周期的不同将内存划分为几块。一般是把 Java 堆分为新生代和老年代，这样既可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用 “标记 - 清除” 或者 “标记 - 整理” 算法来进行回收。 GC 算法对比复制算法： 复制算法执行的速度较快，典型的空间换时间 当对象的存活率很高的时候，不断的复制操作会显得耗时 复制算法很明显的缺点就是浪费内存空间，因为将内存分为两块，一次只能使用一块，这也意味着分的块越大，浪费的内存越多 标记 - 清除算法： 首先是速度慢，因为” 标记 - 清除算法” 在标记阶段需要使用递归的方式从根结点出发，不断寻找可达的对象；而在清除阶段又需要遍历堆内存中的所有对象，查看其是否被标记，然后再清除；并且在程序进行 GC 的时候，JVM 中所有的 Java 程序都要进行暂停，俗称 Stop-The-World，后面会提到。 其次是其最大的缺点，使用这种算法进行清理而得的堆内存的空闲空间一般是不连续的，由于对象实例在堆内存中是随机存储的，所以在清理之后，会产生许多的内存碎片，如果这个时候来了一个很大的对象实例，尽管显示内存还足够，但是已经存不下这个大对象了，内存碎片太多会导致当程序需要为较大对象分配内存时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。再者，这种零散的碎片对于数组的分配也不是很方便。 标记 - 整理算法： 首先这种算法克服了” 标记 - 清除算法” 中会产生内存碎片的缺点，也解决了复制算法中内存减半使用的不足 而其缺点则是速度也不是很快，不仅要遍历标记所有可达结点，还要一个个整理可达存活对象的地址，所以导致其效率不是很高 关于 Stop-The-World在 GC 算法执行的时候，所有正在执行中的 Java 程序都会被挂起（被暂停），只有 Native 方法可以执行，但是也不能和 JVM 进行交互，这样一来似乎整个 Java 世界都停止了，这也就是为什么叫做 Stop-The-World；等到 GC 程序执行完毕后，Java 程序才会重新恢复执行。这个其实很好理解，因为 GC 程序是一个线程，Java 程序也是一个线程，它们操作的堆内存是一片共享的区域，假设一种情况，Java 程序 A 新建了一个对象 object，new Object（）被存放在堆内存，但是很不巧的是，堆内存刚刚执行过复制算法，前一步存活的对象已经被转移到另一块空间了，而 new Object（）就留在了原来的空间，无辜地被清除了。这显然是不可接受的，因为线程不安全。 内存分配策略Java 的自动内存管理，最终可以归结为自动化地解决了两个问题：给对象分配内存、回收分配给对象的内存。对象的内存分配通常是在堆上分配（除此以外还有可能经过 JIT 编译后被拆散为标量类型并间接地在栈上分配），对象主要分配在新生代的 Eden 空间上，如果启动了本地线程分配缓冲，将按线程优先在 TLAB 上分配。少数情况下也可能会直接分配在老年代中，分配的规则并不是固定的，实际取决于垃圾收集器的具体组合以及虚拟机中与内存相关的参数的设置。下面以使用 Serial/Serial Old 收集器，介绍内存分配的策略。 对象优先在 Eden 空间分配大多数情况下，对象在新生代的 Eden 空间中分配，当 Eden 空间没有足够空间进行分配时，虚拟机将发起一次 Minor GC。 大对象直接进入老年代所谓的大对象是指需要大量连续内存空间的 Java 对象，最典型的大对象就是很长的字符串以及数组。大对象对虚拟机的内存分配来说是一个坏消息（尤其是遇到朝生夕灭的 “短命大对象”，写程序时应避免），经常出现大对象容易导致内存还有不少空间时，就提前触发 GC 以获取足够的连续内存空间来安置它们。虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，令大小超过这个设置值的对象直接在老年代分配。这样做的目的是避免在 Eden 空间及两个 Survivor 空间之间发生大量的内存复制（新生代采用复制算法来回收内存）。 长期存活的对象将进入老年代既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这点，虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在 Eden 空间出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 空间容纳的话，将被移动到 Survivor 空间中，并且对象年龄设为 1。对象在 Survivor 空间中每 “熬过” 一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 设置。 动态对象年龄判定为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到 MaxTenuringThreshold 中要求的年龄。 空间分配担保在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续内存空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。如果不成立，则虚拟机会查看 HandlePromotionFailure 的设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续内存空间是否大于历次晋升到老年代对象的平均大小；如果大于，将尝试着进行一次 Minor GC，尽管这次 Minor GC 是有风险的；如果小于或者 HandlePromotionFailure 的设置不允许冒险，那这时也要改为进行一次 Full GC。新生代使用复制算法，但为了内存利用率，只使用其中一个 Survivor 空间来作为轮换备份，因此当出现大量对象在 Minor GC 后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把 Survivor 无法容纳的对象直接进入老年代。与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行 Full GC 来让老年代腾出更多空间。使用平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次 Minor GC 存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了 HandlePromotionFailure 失败，那就只好在失败后重新发起一次 Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将 HandlePromotionFailure 开关打开，避免 Full GC 过于频繁。 GC 的触发条件Minor GC 的触发条件对于 Minor GC，其触发条件非常简单，当新生代的 Eden 空间满时，就将触发一次 Minor GC。 Full GC 的触发条件调用 System.gc ()此方法的调用是建议 JVM 进行 Full GC，虽然只是建议而非一定，但很多情况下它会触发 Full GC，从而增加 Full GC 的频率，也即增加了间歇性停顿的次数。因此强烈建议能不使用此方法就不要使用，让虚拟机自己去管理它的内存，可通过 -XX:+ DisableExplicitGC 来禁止 RMI 调用 System.gc()。 老年代空间不足老年代空间不足的常见场景为大对象直接进入老年代、长期存活的对象进入老年代等，当执行 Full GC 后空间仍然不足，则抛出如下错误： Java.lang.OutOfMemoryError: Java heap space，为避免以上两种状况引起的 Full GC，调优时应尽量做到让对象在 Minor GC 阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。 空间分配担保失败在新生代使用复制算法的 Minor GC，需要老年代的内存空间作担保，如果出现了 HandlePromotionFailure 担保失败，则会触发 Full GC。 JDK 1.7 及以前的永久代空间不足在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些类信息、静态变量、常量、常量池等数据，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation 可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么 JVM 会抛出错误信息 java.lang.OutOfMemoryError: PermGen space，为避免 Permanet Generation 占满造成 Full GC 现象，可采用的方法为增大 Permanet Generation 空间或转为使用 CMS GC。在 JDK 1.8 中用元空间替换了永久代作为方法区的实现，元空间是本地内存，因此减少了一种 Full GC 触发的可能性。 Java 虚拟机规范里，使用方法区作为默认实现 JDK 1.7 及以前，HotSpot 虚拟机中的方法区使用永久代实现 JDK 1.8，HotSpot 虚拟机中的方法区使用元空间实现 Concurrent Mode Failure执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（有时候空间不足是由于 CMS GC 执行时，当前的浮动垃圾过多导致暂时性的空间不足触发 Full GC），便会报 Concurrent Mode Failure 错误，并触发 Full GC。 JVM 垃圾收集器如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。Java 虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的垃圾收集器。下面的图中展示了 7 种作用于不同分代的垃圾收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。 概念理解吞吐量 吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即：吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间） 虚拟机总共运行了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是 99% 并发和并行 这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，它们的解释如下 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个 CPU 核上 Minor GC 和 Full GC 新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快 老年代 GC（Full GC / Major GC）：指发生在老年代的 GC，出现 Full GC 的时候，经常会伴随至少一次的 Minor GC（但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接执行了 Full GC 的策略选择过程）。Full GC 的速度一般会比 Minor GC 慢 10 倍以上 新生代收集器Serial 收集器 Serial 收集器是最基本、发展历史最悠久的收集器，曾经（在 JDK 1.3.1 之前）是虚拟机新生代收集的唯一选择。 特性：这个收集器是一个单线程的收集器，但它的 “单线程” 的意义并不仅仅说明它只会使用一个 CPU 或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束，即会造成 “Stop The World” 现象。 应用场景：Serial 收集器是虚拟机运行在 Client 模式下的默认新生代收集器。 优势：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 ParNew 收集器 特性：ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括 Serial 收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。 应用场景：ParNew 收集器是许多运行在 Server 模式下的虚拟机中首选的新生代收集器。很重要的原因是：除了 Serial 收集器外，目前只有它能与 CMS 收集器配合工作。在 JDK 1.5 时期，HotSpot 推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器 - CMS 收集器，这款收集器是 HotSpot 虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。不幸的是，CMS 作为老年代的收集器，却无法与 JDK 1.4.0 中已经存在的新生代收集器 Parallel Scavenge 配合工作，所以在 JDK 1.5 中使用 CMS 来收集老年代的时候，新生代只能选择 ParNew 或者 Serial 收集器中的一个。 Serial 收集器 VS ParNew 收集器：ParNew 收集器在单 CPU 的环境中绝对不会有比 Serial 收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证可以超越 Serial 收集器。然而，随着可以使用的 CPU 的数量的增加，它对于 GC 时系统资源的有效利用还是很有好处的。它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多的情况下可使用 -XX:ParallerGCThreads 参数设置。 Parallel Scavenge 收集器特性：Parallel Scavenge 收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。 应用场景：停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge 收集器 与 CMS 收集器：Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS 等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标是达到一个可控制的吞吐量（Throughput）。由于与吞吐量关系密切，Parallel Scavenge 收集器也经常称为 “吞吐量优先” 收集器。另外值得注意的一点是，Parallel Scavenge 收集器无法与 CMS 收集器配合使用，所以在 JDK 1.6 推出 Parallel Old 之前，如果新生代选择 Parallel Scavenge 收集器，老年代只有 Serial Old 收集器能与之配合使用。 Parallel Scavenge 收集器 VS ParNew 收集器：Parallel Scavenge 收集器与 ParNew 收集器的一个重要区别是，前者具有 GC 自适应调节策略特性。Parallel Scavenge 收集器除了会显而易见地提供可以精确控制吞吐量的参数，还提供了一个参数 -XX:+UseAdaptiveSizePolicy，这是一个开关参数，打开参数后就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 空间的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为 GC 自适应调节策略（GC Ergonomics）。 老年代收集器Serial Old 收集器 特性：Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程收集器，使用” 标记 - 整理算法”。 应用场景： Client 模式下，Serial Old 收集器的主要意义也是在于给 Client 模式下的虚拟机使用。 Server 模式下，主要有两大用途：一种用途是在 JDK 1.5 以及之前的版本中与 Parallel Scavenge 收集器搭配使用；另一种用途就是作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。 Parallel Old 收集器 特性：Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和 “标记 - 整理” 算法。 应用场景：在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 Parallel Old 配合 Parallel Scavenge：Parallel Old 收集器是在 JDK 1.6 中才开始提供的，在此之前新生代的 Parallel Scavenge 收集器一直处于比较尴尬的状态。因为如果新生代选择了 Parallel Scavenge 收集器，老年代除了 Serial Old 收集器外别无选择（Parallel Scavenge 收集器无法与 CMS 收集器配合使用）。由于老年代 Serial Old 收集器在服务端应用性能上的 “拖累”，使用了 Parallel Scavenge 收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集器（Serial Old）无法充分利用服务器多 CPU 的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有 ParNew 加 CMS 的组合 “给力”。直到 Parallel Old 收集器出现后，“吞吐量优先” 收集器终于有了比较名副其实的应用组合。 CMS 收集器 特性：CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的 Java 应用集中在互联网站或者 B/S 系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS 收集器就非常符合这类应用的需求。 运作流程：CMS 收集器是基于 “标记 - 清除” 算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为以下 4 个步骤。由于在耗时最长的并发标记和并发清除整个过程中，收集器线程都可以与用户线程一起工作，所以从总体上来说，CMS 收集器的内存回收过程是与用户线程一起并发执行的。 初始标记（CMS initial mark）：初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要 “Stop The World” 并发标记（CMS concurrent mark）：并发标记阶段就是进行 GC Roots Tracing 的过程 重新标记（CMS remark）：重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短，仍然需要 “Stop The World” 并发清除（CMS concurrent sweep）：并发清除阶段会清除对象 优点CMS 是一款优秀的收集器，它的主要优点是并发收集、停顿时间短，因此 CMS 收集器也被称为” 并发低停顿收集器”（Concurrent Low Pause Collector）。 缺点： CMS 收集器对 CPU 资源非常敏感，其实面向并发设计的程序都对 CPU 资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说 CPU 资源）而导致应用程序变慢，总吞吐量会降低。CMS 默认启动的回收线程数是（CPU 数量 + 3）/ 4，也就是当 CPU 在 4 个以上时，并发回收时垃圾收集线程不少于 25% 的 CPU 资源，并且随着 CPU 数量的增加而下降。但是当 CPU 不足 4 个（例如 2 个）时，CMS 对用户程序的影响就可能变得很大。 CMS 收集器无法处理浮动垃圾，可能出现 “Concurrent Mode Failure” 失败而导致另一次 Full GC 的产生。由于 CMS 并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再清理掉，这一部分垃圾就称为 “浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此 CMS 收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。要是 CMS 运行期间预留的内存无法满足程序需要，就会出现一次 “Concurrent Mode Failure” 失败，这时虚拟机将启动后备预案：临时启用 Serial Old 收集器来重新进行老年代的垃圾收集（Full GC），这样停顿时间就很长了。 CMS 收集器会产生大量空间碎片，CMS 是一款基于 “标记 - 清除” 算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续内存空间来分配当前对象，导致不得不提前触发一次 Full GC。 G1 收集器 G1（Garbage-First）收集器是当今收集器技术发展最前沿的成果之一，它是一款面向服务端应用的垃圾收集器，HotSpot 开发团队赋予它的使命是（在比较长期的）未来可以替换掉 JDK 1.5 中发布的 CMS 收集器。 特性： 并行与并发：G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个 CPU 来缩短 Stop-The-World 停顿的时间，部分其他收集器需要停顿 Java 线程来执行的 GC 动作，而 G1 收集器仍然可以通过并发的方式让 Java 程序继续执行。 分代收集：与其他收集器一样，分代概念在 G1 中依然得以保留。虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果。 空间整合：与 CMS 的 “标记 - 清除” 算法不同，G1 从整体来看是基于 “标记 - 整理” 算法实现的收集器，从局部（两个 Region 之间）上来看是基于 “复制” 算法实现的，但无论如何，这两种算法都意味着 G1 运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 Full GC。 可预测的停顿：这是 G1 相对于 CMS 的另一大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。 横跨整个堆内存：在 G1 之前的其他收集器进行收集的范围都是单独针对新生代或者老年代，而 G1 不再是这样。使用 G1 收集器时，Java 堆的内存布局就与其他收集器有很大差别，它将整个 Java 堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分 Region（不需要连续）的集合。 建立可预测的时间模型：G1 收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个 Java 堆中进行全区域的垃圾收集。G1 跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region（这也就是 Garbage-First 名称的来由）。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。 避免全堆扫描 - Remembered Set：G1 把 Java 堆分为多个 Region，就是 “化整为零”。但是 Region 不可能是孤立的，一个对象分配在某个 Region 中，可以与整个 Java 堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个 Java 堆才能保证准确性，这显然是对 GC 效率的极大伤害。为了避免全堆扫描的发生，虚拟机为 G1 中每个 Region 维护了一个与之对应的 Remembered Set。虚拟机发现程序在对 Reference 类型的数据进行写操作时，会产生一个 Write Barrier 暂时中断写操作，检查 Reference 引用的对象是否处于不同的 Region 之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是便通过 CardTable 把相关引用信息记录到被引用对象所属的 Region 的 Remembered Set 之中。当进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏。 执行过程： 初始标记（Initial Marking）：初始标记阶段仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的 Region 中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking）：并发标记阶段是从 GC Root 开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking）：最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation）：筛选回收阶段首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java"},{"title":"Puppeteer 入门使用教程","url":"/posts/1a44388b.html","text":"Puppeteer 介绍Puppeteer 是什么Puppeteer 是一个 NodeJs 库，它提供了一个高级 API 来通过 DevTools 协议控制 Chromium 或 Chrome。相比较 Selenium 或是 PhantomJs，它最大的特点就是完全可以在内存中模拟 DOM 操作，即在 V8 引擎中处理而不打开浏览器，而且关键的是该项目是 Chrome 团队在维护，会拥有更好的兼容性和前景，更多资料可参考以下站点：Puppeteer Github、Puppeteer 中文文档、DevTools Protocol 文档、Chromium 命令行启动参数。 Puppeteer 的功能 生成页面的截图和 PDF 自动提交表单，进行 UI 测试，键盘输入等 捕获网站的时间线跟踪，用来帮助分析性能问题 抓取 SPA（单页应用），并生成预渲染内容，即 “SSR”（服务器端渲染） 创建一个最新的自动化测试环境，使用最新的 JavaScript 和浏览器功能，直接在最新版本的 Chrome 中运行测试 测试浏览器扩展，Chrome / Chromium 扩展当前只能在非无头模式下使用，目前还无法测试扩展弹出窗口或内容脚本 Puppeteer VS Puppeteer-Core使用区别自 v1.7.0 以来的 Puppeteer 每个版本都会发布两个包：puppeteer、puppeteer-core，两者的区别如下： puppeteer 是浏览器自动化的产品，安装后它会下载一个最新版本的 Chromium，然后使用 puppeteer-core 驱动工作。作为最终用户产品，puppeteer 支持一堆方便的 PUPPETEER_* 环境变量来调整运行行为 puppeteer-core 是一个库来帮助驱动任何支持 DevTools 协议的东西。puppeteer-core 在安装时不会下载 Chromium，作为一个库，puppeteer-core 完全是通过其编程接口驱动的，并且会忽略所有 PUPPETEER_* 环境变量 使用建议在大多数情况下，可以使用 puppeteer 包，如果是下面这些情况，那可以使用 puppeteer-core： 正在构建使用 DevTools 协议的另一个最终用户产品或库；例如，可以使用 puppeteer-core 构建 PDF 生成器，并编写下载 headless_shell 的自定义 install.js 脚本，而不是使用 Chromium 来节省磁盘空间 正在打包 Puppeteer 用在 Chrome 上的扩展应用或者浏览器中以使用 DevTools 协议，因为下载额外的 Chromium 二进制文件不是必须的 当需要使用 puppeteer-core 时，使用下面这行代码代替原来的引入方式即可： 1const puppeteer = require('puppeteer-core'); Puppeteer 运行环境与安装Puppeteer 运行环境Puppeteer 运行依赖于 NodeJs v6.4.0+，如果要使用 async /await，只有 NodeJs v7.6.0 或更高版本才支持，NodeJs 可以点击这里下载。 Puppeteer 安装Puppeteer 安装的过程默认会执行 install.js 脚本来下载最新版本的 Chromium（请自备梯子），可以使用 --ignore-scripts 参数跳过 Chromium 的下载，也可以通过设置环境变量 PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=1 来跳过下载。 12345# 安装puppeteer$ npm install puppeteer -g --ignore-scripts# 或者使用淘宝镜像源安装puppeteer$ npm install puppeteer -g --ignore-scripts --registry=https://registry.npm.taobao.org 手动下载 Chromium 并解压在本地磁盘，下载可以点击这里（请自备梯子）： Puppeteer 入门案例入门案例初始化项目： 1$ npm init 创建 index.js 文件，代码如下，executablePath 是 Chromium 或者 Chrome 可执行文件的路径： 123456789101112const puppeteer = require('puppeteer');(async () =&gt; { const browser = await puppeteer.launch({ executablePath: '/usr/bin/google-chrome-stable', headless: false }); const page = await browser.newPage(); await page.goto('http://www.baidu.com/'); await page.screenshot({path: 'baidu.png'}); browser.close();})(); 执行 index.js 脚本，运行成功后，会在当前目录下生成网页的截图文件 baidu.png： 1$ node index.js 启动参数Puppeteer Launch 的启动参数如下： executablePath：Chromium 或 Chrome 可执行文件的路径 headless：是否运行在浏览器 headless 模式，true 表示不打开浏览器执行，默认为 true timeout：等待浏览器实例启动的最长时间（以毫秒为单位），默认为 30000，当值为 0 时表示禁用超时 args：传递给浏览器实例的其他参数 Puppeteer 实战Puppeteer 环境变量Puppeteer 的环境变量如下，在使用 puppeteer-core 时，下述环境变量中以 PUPPETEER_* 开头的会被忽略： HTTP_PROXY、HTTPS_PROXY, NO_PROXY - 定义用于下载和运行 Chromium 的 HTTP 代理设置 PUPPETEER_SKIP_CHROMIUM_DOWNLOAD - 请勿在安装步骤中下载绑定的 Chromium PUPPETEER_DOWNLOAD_HOST - 覆盖用于下载 Chromium 的 URL 的主机部分 PUPPETEER_CHROMIUM_REVISION - 在安装步骤中指定一个 puppeteer 使用的特定版本的 Chromium PUPPETEER_EXECUTABLE_PATH - 指定一个 Chrome 或者 Chromium 可执行文件的路径，会被用于 puppeteer.launch Puppeteer 的选择器Puppeteer 中获取元素的方法和浏览器里面的一样，但是获取元素的属性的办法和浏览器不一样，它有一套 API 用来获取界面中的元素，还有一套 API 用来获取元素的属性。 获取元素的操作如下： 12345// Page.$(selector) 获取单个元素，底层是调用的是 document.querySelector()，所以选择器的 selector 格式遵循 CSS 选择器规范let inputElement = await page.$('#search');// Page.$$(selector) 获取一组元素，底层调用的是 document.querySelectorAll()，返回 Promise(Array(ElemetHandle)) 元素数组const links = await page.$$(\"a\"); 获取元素的属性的操作如下： 1234567// Puppeteer 获取元素属性跟平时写 JavaScript 的逻辑有点不一样，按照通常的逻辑，应该是现获取元素，然后再获取元素的属性// Puppeteer 获取元素的 API 最终返回的都是 ElemetHandle 对象，而 ElemetHandle 并没有提供获取元素属性的 API，而 Puppeteer 专门提供了一套获取元素属性的 API，分别是： Page.$eval() 和 Page.$$eval()const href = await page.$eval('#a', ele =&gt; ele.href);const content = await page.$eval('.content', ele =&gt; ele.outerHTML);const value = await page.$eval('input[name=search]', input =&gt; input.value);const textArray = await page.$$eval('#dom', els =&gt; Array.from(els).map(el =&gt; el.textContent)); 常用的元素选择器： 选择器 示例 示例说明 id 选择器 #id 选择匹配 id 的元素，仅存在一个 class 选择器 .class 同时匹配多个 class 元素 属性选择器 div[attr] 匹配具有 attr 的属性，不考虑具体的值 属性选择器 div[attr=‘122‘] 匹配具有 attr 的属性，值为 122 后代选择器 div span 后代选择器，匹配所有 div 后面的 span 标签，div 与 span 之间用空格隔开 子元素选择器 div &gt; span 子元素选择器，匹配 div 后所有的 span 匹配父元素下的第 n 个子元素 div:nth-child(2) 匹配父元素下的第 2 个元素 SegmentFault 模拟登录123456789101112131415161718192021222324252627const puppeteer = require('puppeteer');(async () =&gt; { const browser = await puppeteer.launch({ executablePath: '/usr/bin/google-chrome-stable', headless: false }); const page = await browser.newPage(); page.setJavaScriptEnabled(true); page.setCacheEnabled(true); await page.goto(\"https://segmentfault.com/user/login\", { \"timeout\" : 30000 }); // 选择登录方式 await page.tap(\".login-nav &gt; a[data-mode='password']\"); // 输入用户名 await page.type(\"form[class='password-form'] &gt; div &gt; input[name='username']\", 'admin', {delay:100}); // 输入密码 await page.type(\"form[class='password-form'] &gt; div &gt; input[name='password']\", '123456', {delay:100}); // 点击登录按钮 await page.tap(\"form[class='password-form'] &gt; button[type='submit']\"); // await page.close(); // await browser.close();})(); Puppeteer 结合 Jest 使用Puppeteer 周边的开源项目 jvppeteer，Java 版的 Puppeteer pyppeteer，Python 版的 Puppeteer awesome-puppeteer，Puppeteer 相关的开源项目整理 docker-puppeteer，A minimal Docker image for Puppeteer puppeteer-cluster，Puppeteer Pool, run a cluster of instances in parallel puppeteer-deep，爬取《es6 标准入门》、自动推文到掘金、站点性能分析；高级爬虫、自动化 UI 测试、性能分析的实践案例 puppeteer-recorder，Puppeteer recorder is a Chrome extension that records your browser interactions and generates a Puppeteer script var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"前端 爬虫"},{"title":"SpringCloud 容器化","url":"/posts/fe094f6c.html","text":"前言容器化技术的出现标准化了服务的基础设施，统一了应用的打包分发、部署及操作系统相关类库等，解决了测试及生产部署时环境差异的问题，更方便分析排查问题。对运维来说，由于镜像的不可变性，更容易进行服务部署升级及回滚。另外利用诸如 Kubemetes 之类的容器管理平台，更容易实现一键部署、扩容、缩容等操作，更能将微服务架构、DevOps、不可变基础设施的思想落地下来。本文重点讲述 Spring Cloud 如何使用 Docker 实现容器化。 Java 服务 Docker 化基础镜像选择操作系统层面，可以选择传统的 Centos、Ubuntu 或者轻量级的 Alpine。其中 Ubuntu 16.04 版本的镜像大小约为 113M，压缩后大约 43M；Centos 7 版本的镜像大小约为 199M，压缩后大约为 73M；而 Alpine 3.7 版本镜像大小约为 4.15M，压缩后约为 2M。关于基础镜像的选择，一个是考虑镜像大小，一个是只提供最小的依赖包。关于第二点，不同的服务应用依赖包是不同的，这里不再展开，只从镜像大小角度考虑的话，Alpine 是首选，镜像小，远程推拉镜像的速度快，更为方便，这里建议釆用 Alpine 镜像作为基础镜像。从 Docker 镜像分层缓存的机制来考虑，如果选择了比较大的基础镜像，DockerFile 编写时可以适当分层，然后集中在几台镜像打包机上处理镜像打包及上传，这样可以充分利用打包机镜像分层缓存的机制，减少上传镜像的耗时。但是对于分布式服务的 Docker 部署，目标服务实例部署的机器比较多而且是随机的，就没办法利用这个机制来加快镜像下载速度。 DockerFile 编写选择 Alpine 有个麻烦的地方就是 Alpine 采用的是 musl libc 的 C 标准库，而 Oracle JDK 或 OpenJDK 提供的版本则主要是以 glibc 为主，虽然 OpenJDK 在一些早期版本会放出使用 musl libc 编译好的版本，不过在正式发布的时候，并没有单独的 musl libc 编译版本可以下载，需要自己单独编译，稍微有些不便。因此可以考虑在 Alpine 里加上 glibc，然后添加 glibc 的 JDK 编译版本作为基础镜像。 Alpine + glibc下述的 DockerFile 中，选择 Alpine 3.7 版本，glibc 釆用 Sgerrand 开源的 glibc 安装包，版本为 2.27-r0，该镜像可以作为后面的 JDK 镜像 的基础镜像。 1234567891011121314151617181920FROM alpine:3.7MAINTAINER example &lt;example@gmail.com&gt;RUN apk add --no-cache ca-certificates curl openssl binutils xz tzdata \\ &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ &amp;&amp; echo \"Asia/Shanghai\" &gt; /etc/timezone \\ &amp;&amp; GLIBC_VER=\"2.27-r0\" \\ &amp;&amp; ALPINE_GLIBC_REPO=\"https://github.com/sgerrand/alpine-pkg-glibc/releases/download\" \\ &amp;&amp; curl -Ls ${ALPINE_GLIBC_REPO}/${GLIBC_VER}/glibc-${GLIBC_VER}.apk &gt; /tmp/${GLIBC_VER}.apk \\ &amp;&amp; apk add --allow-untrusted /tmp/${GLIBC_VER}.apk \\ &amp;&amp; curl -Ls https://www.archlinux.org/packages/core/x86_64/gcc-libs/download &gt; /tmp/gcc-libs.tar.xz \\ &amp;&amp; mkdir /tmp/gcc \\ &amp;&amp; tar -xf /tmp/gcc-libs.tar.xz -C /tmp/gcc \\ &amp;&amp; mv /tmp/gcc/usr/lib/libgcc* /tmp/gcc/usr/lib/libstdc++* /usr/glibc-compat/lib \\ &amp;&amp; strip /usr/glibc-compat/lib/libgcc_s.so.* /usr/glibc-compat/lib/libstdc++.so* \\ &amp;&amp; curl -Ls https://www.archlinux.org/packages/core/x86_64/zlib/download &gt; /tmp/libz.tar.xz \\ &amp;&amp; mkdir /tmp/libz \\ &amp;&amp; tar -xf /tmp/libz.tar.xz -C /tmp/libz \\ &amp;&amp; mv /tmp/libz/usr/lib/libz.so* /usr/glibc-compat/lib \\ &amp;&amp; apk del binutils \\ &amp;&amp; rm -rf /tmp/${GLIBC_VER}.apk /tmp/gcc /tmp/gcc-libs.tar.xz /tmp/libz /tmp/libz.tar.xz /var/cache/apk/* 这里有几点需要注意： 由于 Docker 镜像采用的是分层机制，因此安全类库或软件的命令最好在同一行命令中，减少分层，以降低最后镜像的大小 命令中间安装了类库或软件包，需要在同一行命令中删除 apk 的 cache，这样才能有效删除 apk，以减少镜像大小 这里安装了 openssl、curl、xz、tzdata 库，同时把 timezone 改为了 Asia/Shanghai 构建镜像的命令为：docker build -f /usr/local/DockerFile-Alpine-Glibc -t alpine-3.7:glibc-2.27-r0 .，其中 /usr/local/DockerFile-Alpine-Glibc 是 DockerFile 的文件路径 由于构建镜像的过程比较慢，这里给出阿里云上已构建好的镜像（alpine + glibc），可以直接拉取到本地来使用，命令如下： 12# 拉取镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0 Alpine + glibc + JDK8对于 JDK 版本的选择，有 Oracle 的 Hotspot JDK，也有 OpenJDK。对于 Oracle 的 JDK，个人使用及非商业使用是免费的，而对于商业使用来说，需进行企业订阅，在 2019 年 1 月之后才能继续获得 Java SE8 更新。Oracle 已经建议选择不订阅或不继续订阅的公司在订阅结束之前，把 JDK 版本迁移到 OpenJDK，以确保相关应用程序不受影响。下述的 JDK 8 版本釆用 Oracle 的 server-jre-8ul72 版本，而对于 JDK 9、10 及 11 版本，则釆取 OpenJDK 来构建。附上 OpenJDK 的官方下载地址。 123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD server-jre-8u172-linux-x64.tar.gz /opt/RUN chmod +x /opt/jdk1.8.0_172ENV JAVA_HOME=/opt/jdk1.8.0_172ENV PATH=\"$JAVA_HOME/bin:${PATH}\" Alpine + glibc + JDK9123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-9u181_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-9ENV JAVA_HOME=/opt/jdk-9ENV PATH=\"$JAVA_HOME/bin:${PATH}\" Alpine + glibc + JDK10123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-10.0.1_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-10.0.1ENV JAVA_HOME=/opt/jdk-10.0.1ENV PATH=\"$JAVA_HOME/bin:${PATH}\" Alpine + glibc + JDK11123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0MAINTAINER example &lt;example@gmail.com&gt;ADD openjdk-11+28_linux-x64_bin.tar.gz /opt/RUN chmod +x /opt/jdk-11ENV JAVA_HOME=/opt/jdk-11ENV PATH=\"$JAVA_HOME/bin:${PATH}\" 阿里云上有已构建好的不同版本的 JDK 镜像，拉取到本地就可以直接使用： 1234567891011# 基于 Oracle JDK 8 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpine# 基于 OpenJDK 9 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-9u181-alpine# 基于 OpenJDK 10 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-10.0.1-alpine# 基于 OpenJDK 11 构建的镜像# docker pull registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-11-ea19-alpine Maven 构建与发布镜像构建镜像的 Maven 插件主流的几款 Docker 的 Maven 插件： 这里以 Maven 构建为例，选用的是 com.spotify 的插件，其 Maven 的 POM 配置如下。使用 spring-boot-maven-plugin 的 1.4.3 版本，另外设置的镜像前缀为 registry.cn-hangzhou.aliyuncs.com/springcloud-cn，tag 为 $(project.version)， repository（私有仓库地址）为 ${docker.image.prefix}/${project.artifactId}，另外这里还传递了一个 Docker 的 buildArg 为 JAR_FILE，其值为 $(project.build.finalName) .jar。username 与 password 标签是指访问私有仓库的用户名和密码，若不需要身份认证，则可以注释这两个标签。点击下载完整的示例代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;dockerfile.maven.version&gt;1.4.3&lt;/dockerfile.maven.version&gt; &lt;docker.image.prefix&gt;registry.cn-hangzhou.aliyuncs.com/springcloud-cn&lt;/docker.image.prefix&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${dockerfile.maven.version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;skipPush&gt;true&lt;/skipPush&gt; &lt;!-- &lt;username&gt;admin&lt;/username&gt; --&gt; &lt;!-- &lt;password&gt;123456&lt;/password&gt; --&gt; &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;${project.build.finalName}.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Maven 构建镜像的 DockFileMaven 项目的 DockerFile 内容如下，特别注意，DockerFile 需要放在 IDEA 里的某个应用（模块）的根目录下。例如 gateway-server 模块需要打包，并发布构建到 Docker 镜像里，那么 DockerFile 此时应该放在 gateway-server 模块的根目录下，不同的应用（模块）可以拥有自己的 DockerFile。下面的 registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpine 是指私有仓库里已构建好的 JDK 镜像。 123456FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:8u172-jre-alpineARG JAR_FILEENV PROFILE defaultADD target/${JAR_FILE} /opt/app.jarEXPOSE 8080ENTRYPOINT java ${JAVA_OPTS} -Djava.security.egd=file:/dev/./urandom -Duser.timezone=Asia/Shanghai -Dfile.encoding=UTF-8 -Dspring.profiles.active=${PROFILE} -jar /opt/app.jar Maven 打包构建镜像执行下述的 Maven 打包构建命令（跳过单元测试），成功后会在本地构建生成新的 Docker 镜像，如果上面的 POM 配置了 &lt;skipPush&gt;false&lt;/skipPush&gt;，会自动将新的镜像 Push 到私有仓库。 1$ mvn clean package -Dmaven.test.skip=true Maven Push 镜像Maven 手动 Push 镜像到 私有仓库： 12345# 第一种方式：不使用身份认证或者使用POM配置里的私有仓库账号进行Push$ mvn dockerfile:push# 第二种方式：使用指定的私有仓库账号进行Push$ mvn dockerfile:push -Ddockerfile.username=xxx -Ddockerfile.password=xxx Maven 运行镜像执行以下命令运行镜像，实际项目中可以根据项目需要调整对应的 JVM 参数： 1234# docker run -p 8080:8080 --rm \\-e JAVA_OPTS='-server -Xmx1g -Xms1g -XX:MetaspaceSize=64m -verbose:gc -verbose:sizes -XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UnlockDiagnosticVMOptions -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/ -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -Xloggc:/opt/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M -Djava.io.tmpdir=/tmp' \\-e PROFILE='default' \\registry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway:1.0-SNAPSHOT JDK 8+ 的 Docker 资源限制支持JDK 8 &amp;&amp; JDK 9Java 8ul31 及以上版本开始支持了 Docker 的 CPU 和 Memory 限制。对于 CPU 的限制，如果 JVM 没有显式指定 -XX： ParalllelGCThreads 或者 -XX： CICompilerCount，那么 JVM 会使用 Docker 的 CPU 限制。如果 Docker 有指定 CPU Limit，JVM 参数也有指定 -XX： ParalllelGCThreads 或者 -XX： CICompilerCount，那么最终以指定的 JVM 参数为准。对于 Memory 限制，需要加上 -XX： +UnlockExperimentalVMOptions 和 -XX： +UseCGroupMemoryLimitForHeap 才能使得 Xmx 感知 Docker 的 Memory Limit。 JDK 10JDK 10 版本废弃了 UseCGroupMemoryLimitForHeap，同时新引入了新配置 ActiveProcessorCount，可以用来强制指定 CPU 的个数。 JDK 11JDK 11 正式移除 UseCGroupMemoryLimitForHeap，同时新引入 UseContainerSupport 配置，默认为 ture，即默认支持 Docker 的 CPU 及 Memory 限制，也可以设置为 false 来禁用容器支持。 JDK 9+ 镜像优化JDK9 及以上的版本与之前的版本有一个比较大的变动，就是 JDK9 及以上的版本支持模块系统 JPMS，同时 JDK 自身也模块化了，里面的 Modular Run-Time Images 功能特性以及 jlink 工具对于镜像的优化非常有帮助，可根据所需模块来精简 JDK。 Jlink 工具Jlink 工具可以用来将已有的 JDK 按所需模块进行优化，并重新组装成一个自定义的 runtime image，其基本语法如下： jlink [options] --module-path modulepath --add-modules module [,module...] 其中 module-path 参数用于指定需要 Jlink 的 JDK 的 jmods 路径，options 的部分参数说明如下： add-mobules，用来指定所需要的模块名称，比如 java.xml compress，用来指定压缩级别，0 为不压缩，1 为常量字符串共享，2 为 Zip 压缩 no-hreader-files，表示排除掉 header 文件 output，指定输出精简后的 JDK 的文件夹路径 Jlink 使用案例创建对应 Dockerfile，配置内容如下，其中指定了需要依赖的 JDK 模块，目的是通过 Jlink 生成精简的 JDK，点击下载完整的示例代码。 1234567891011121314151617181920212223FROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/java:openjdk-10.0.1-alpine as packager# jlink toolRUN /opt/jdk-10.0.1/bin/jlink \\ --module-path /opt/jdk-10.0.1/jmods \\ --verbose \\ --add-modules java.base,java.logging,java.xml,jdk.unsupported,java.sql,java.desktop,java.management,java.naming,java.instrument,jdk.jstatd,jdk.jcmd,jdk.management \\ --compress 2 \\ --no-header-files \\ --output /opt/jdk-10-jlinked# copy jdk after jlinkFROM registry.cn-hangzhou.aliyuncs.com/springcloud-cn/alpine-3.7:glibc-2.27-r0COPY --from=packager /opt/jdk-10-jlinked /opt/jdk-10.0.1ENV JAVA_HOME=/opt/jdk-10.0.1ENV PATH=$JAVA_HOME/bin:$PATH# add application jarARG JAR_FILEENV PROFILE defaultADD target/${JAR_FILE} /opt/app.jarEXPOSE 8080ENTRYPOINT java ${JAVA_OPTS} -Djava.security.egd=file:/dev/./urandom -Duser.timezone=Asia/Shanghai -Dfile.encoding=UTF-8 -Dspring.profiles.active=${PROFILE} -jar /opt/app.jar 通过 Maven 打包构建镜像： 1$ mvn clean package -Dmaven.test.skip=true 查看镜像的大小，可以发现精简后的 JDK 包括 app.jar，总大小在 100M 以内： 12# docker images |grep gatewaydocker images |grep gatewayregistry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway 1.0-SNAPSHOT 8f0c327e65a4 2 minutes ago 96MB 运行镜像： 1234# docker run -p 8080:8080 --rm \\-e JAVA_OPTS='-server -XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:ActiveProcessorCount=1 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/ -Xlog:age*,gc*=info:file=gc-%p-%t.log:time,tid,tags:filecount=5,filesize=10m -Djava.io.tmpdir=/tmp' \\-e PROFILE='default' \\registry.cn-hangzhou.aliyuncs.com/springcloud-cn/gateway:1.0-SNAPSHOT 查看精简后的 JDK 大小： 12345678910# 连接容器# docker exec -it dreamy_golick /bin/sh# 查看精简后的JDK大小# du -sh /opt/jdk-10.0.1/53.5M /opt/jdk-10.0.1/# 查看应用Jar包的大小# du -sh /opt/app.jar22.2M /opt/app.jar var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务 容器化"},{"title":"ArtiPub 一款开源的一文多发平台","url":"/posts/5987f4b4.html","text":"前言很多优秀的程序员和技术人员喜欢写技术文章和技术博客，通过这样的方式分享传播知识和经验，扩大自己的知名度和影响力，吸引粉丝关注，甚至有些技术博主还通过写文章来获取广告收入，还通过这种方法获得了出版书的机会以及工作机会。因此，写技术文章是一件非常值得投入的事情，帮助了自己，也让大众受益。但是，写技术文章通常也很耗时，特别是一些优质文章，不仅需要旁征博引、构思文章结构、照顾读者受众，还需要做很多前期工作，例如搭建环境、写 Demo 代码、测试代码等等。一篇优质技术文章通常需要 3-6 个小时来完成，可花了很多时间来写文章，最终发布出来的文章得不到很多人的关注是一件相当令人沮丧的事情。因此，优质文章值得获取关注和传播，让更多的技术工作者通过阅读文章获取知识获益。每个技术博主都有自己喜欢的技术媒体平台，例如简书、知乎、掘金、CSDN、微信公众号等等。很多技术博主也喜欢将文章发布在不同的平台上，寻求最大的关注度，同时也防止自己辛辛苦苦写的文章被别人复制粘贴盗版过去。然而，在多个平台上发文是一件麻烦的事情：博主需要同时登陆多个媒体平台，将自己的文章复制一个一个粘贴过去；更麻烦的是，有些平台只支持 Markdown，有些平台只支持富文本，博主需要在这两者之间来回转换，这增加了工作量。一文多发平台 ArtiPub 就解决了这样的问题，下面将介绍开源的一文多发平台 ArtiPub。 ArtiPub 简介ArtiPub（Article Publisher 的简称，意为” 文章发布者”）是一款开源的一文多发平台，可以帮助文章作者将编写好的文章自动发布到简书、掘金、SegmentFault、CSDN、知乎、开源中国等技术媒体平台，传播优质知识，获取最大的曝光度。ArtiPub 安装简单，提供了多种安装方式（Docker、NPM、源码），可以一键安装使用，安装一般只要 5 分钟。ArtiPub 目前支持文章编辑、文章发布、数据统计的功能，后期会加入存量文章导入、数据分析的功能。此外，ArtiPub 日后还会接入更多媒体渠道，真正做到让文章随处可阅。用户使用 ArtiPub 也很简单，只需要在浏览器上打开 ArtiPub 的 Web 界面，将文章以 Markdown 的形式输入到编辑器，然后点击一键发布，等待不到 1 分钟，文章就自动同步到各大技术媒体平台了。此外，文章的阅读、点赞、评论数据还将周期性的被同步回来，让作者可以近实时看到文章的传播情况。 ArtiPub 原理简介ArtiPub 的底层原理并不复杂，简单来说就是利用了爬虫技术将文章发布到各大平台。ArtiPub 的爬虫是用了 Google 开源的自动化测试工具 Puppeteer，这个工具不仅可以获取需要有 ajax 动态内容的数据，还可以来做一些模拟操作，作用类似于 Selenium，但更强大。如何进行登陆操作呢？其实 ArtiPub 是通过 Chrome 插件获取了用户登陆信息（Cookie），将 Cookie 注入到由 Puppeteer 操作的 Chromium 浏览器中，然后浏览器就可以正常登陆网站进行发文操作了。Cookie 是保存在用户自己搭建的 MongoDB 数据库里，不对外暴露，因此很安全。 ArtiPub 的架构示意图如下： 架构原理简介如下： 后端（Backend）是整个架构的中枢，负责给前端交换数据、储存读取数据库、控制爬虫、收集 Cookie 等 Chrome 插件（Chrome Extension）只负责从网站（Sites）获取 Cookie 爬虫（Spiders）被后端控制，负责在网站上发布文章和抓取数据 数据库（MongoDB）负责储存数据（Cookie） 前端（Frontend）是一个 React 应用，基于 Ant Design Pro 改造而来 ArtiPub 支持的平台 掘金 SegmentFault CSDN 简书 知乎 开源中国 今日头条 博客园 微博 百度百家号 51CTO 开发者头条 微信公众号 ArtiPub 与其他平台比较市面上已经存在一文多发的商业平台了，为何还要创建 ArtiPub 呢？或许其他一文多发平台也是一个替代方案，但它们要求用户将自己的账户信息，例如 Cookie 或账号密码上传到对方服务器，这很不安全，一旦平台发生问题，自己的账户信息会遭到泄漏。虽然一般的平台不会恶意操作用户的账户，但如果出现误操作或者黑客攻击，用户的账户信息将遭到泄漏，平台上的财产也可能遭到损坏。ArtiPub 不要求用户上传账户信息，所有账户信息全部保存在用户自己的数据库里，因此规避了这个安全风险。另外，由于 ArtiPub 是基于 JS 开源的，JS 源码也比较易于理解，可扩展性很强，用户如果有其他平台的接入需求，完全可以通过更改源码来实现自己的需求，不用等待平台更新。官方的开发组也将持续开发 ArtiPub，将其打造得更实用和易用。 ArtiPub 安装Docker 安装 ArtiPub 软件依赖 软件版本 Docker 18.03 Docker Compose 1.24.1 通过 Docker，可以免去手动安装 MongoDB 的步骤，这是最推荐的安装方式。使用 Docker 安装 ArtiPub 前，请确保已安装好 Docker 以及 Docker Compose。在项目目录下创建 docker-compose.yml 文件，输入如下内容： 1234567891011121314151617181920version: '3.3'services: app: image: \"tikazyq/artipub:latest\" container_name: \"artipub-server\" environment: MONGO_HOST: \"mongo\" ARTIPUB_API_ADDRESS: \"http://localhost:3000\" # 后端服务的API地址，如果后端服务不是安装在本机，请修改为协议 + 服务器 IP 地址 + 端口号（默认端口为 3000） ports: - \"8000:8000\" # 前端服务 - \"3000:3000\" # 后端服务 depends_on: - mongo mongo: image: mongo:latest container_name: \"artipub-mongo\" restart: always ports: - \"27017:27017\" 由于 ArtiPub 采用了前后端分离的架构，前端使用 Nginx 作为 Web 服务器，如果需要对 Nginx 进行配置（例如配置跨域），此时可以使用数据卷来挂载 Nginx 的配置文件到 ArtiPub 的容器内，ArtiPub 的 Nginx 配置文件路径为：/etc/nginx/conf.d/artipub.conf： 12345678910111213141516171819202122version: '3.3'services: app: image: \"tikazyq/artipub:latest\" container_name: \"artipub-server\" environment: MONGO_HOST: \"mongo\" ARTIPUB_API_ADDRESS: \"http://localhost:3000\" ports: - \"8000:8000\" - \"3000:3000\" depends_on: - mongo mongo: image: mongo:latest container_name: \"artipub-mongo\" restart: always ports: - \"27017:27017\" volumes: - '/usr/local/docker-volumes/artipub/artipub.conf:/etc/nginx/conf.d/artipub.conf' 创建并启动 ArtiPub 的容器，启动完成后在浏览器中访问 http://127.0.0.1:8000，可以看到 Web 管理界面： 12345# 后台启动# docker-compose up -d# 查看输出的日志信息# docker logs artipub-server --tail 100 -f MongoDB 数据库管理命令： 1234567891011# 登录MongoDB# docker exec -it artipub-mongo mongo# 显示所有数据库&gt; show dbs# 切换数据库&gt; use artipub# 查看数据库的所有集合&gt; show collections NPM 包安装 ArtiPub 软件依赖 软件版本 NodeJS 8.12+ MongoDB 3.6+ 123456789101112131415# 提示：通过 NPM 包安装 ArtiPub，需要提前手动安装好 MongoDB# 安装# npm install -g artipub# 或者指定镜像源来安装，加快下载速度# npm install -g artipub --registry=https://registry.npm.taobao.org# 启动# artipub start# 默认会使用 \"127.0.0.1:27017/artipub\" 作为MongoDB的数据库链接，使用如下命令可以配置数据库信息等# artipub -h# 成功启动后，在浏览器中访问 `http://127.0.0.1:8000`，可以看到 Web 管理界面 源码安装 ArtiPub123456789101112131415161718192021222324# 提示：通过源码安装 ArtiPub，需要提前手动安装好 MongoDB# 克隆源码# git clone https://github.com/crawlab-team/artipub# 进入源码目录# cd artipub# 安装# npm install# 配置数据库# vim ./config.js# 配置后端服务的API地址# vim ./src/config/config.ts # 将 apiEndpoint 改成对应的 IP 地址 + 端口。# 启动前端服务# npm run start:frontend# 启动后端服务# npm run start:backend# 成功启动后，在浏览器中访问 `http://127.0.0.1:8000`，可以看到 Web 管理界面 ArtiPub 登录助手的使用ArtiPub 需要依赖登录助手（Chrome 浏览器插件）来获取用户在各个平台的账号信息，因此需要手动安装登录助手插件。ArtiPub 成功启动后，通过 http://127.0.0.1:8000 访问 Web 管理界面，点击页面上的 “登录助手” 菜单项，然后按照以下步骤安装插件： 点击” 下载登陆助手”，保存文件名为 artipub-helper.zip 在 Chrome 浏览器中输入 chrome://extensions，并开启开发者模式（点击右上角） 将下载的登陆助手文件 artipub-helper.zip 拖入浏览器中，浏览器将自动安装插件（如果不能拖拽，请刷新页面后重试） 在使用登陆助手之前，请确保各个平台的账号已经处于登陆状态 浏览器右上角点击安装好的插件图标，点击” 一键获取登陆信息”，插件将获取所有平台的 Cookie 注意：如果 ArtiPub 的后端服务没有部署在本机，请点击浏览器右上角的登录助手里的” 扳手” 按钮，输入后端服务的 IP 地址 + 端口号（默认 3000），然后再获取登陆信息 到” 平台管理” 页面，点击” 更新 Cookie 状态”（需要大约 1 分钟），然后查看 “Cookie 状态”，确保其为” 已导入” 状态 到” 文章管理” 页面，点击” 发布”，选择登陆方式为 “Cookie”，然后发布文章 ArtiPub 界面平台管理界面 文章管理界面 文章发布界面 文章编辑界面 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Atom 编写 Markdown 将图片上传到七牛图床","url":"/posts/410644c5.html","text":"前言 七牛云免费提供 30 天有效期的七牛融合 CDN 测试域名，也支持绑定自定义域名，但要求自定义的域名必须备案 七牛云每月会免费提供 10 GB 存储空间、10 GB 下载流量、10 万次 PUT 请求、100 万次 GET 请求，但免费提供的存储资源只支持 HTTP 协议访问，若需要使用 HTTPS 协议，则需要按流量付费才能够使用 Atom 编写 Markdown 将图片到七牛图床，第一种方法是安装两款插件，分别是：markdown-assistant + qiniu-uploader，不支持上传本地文件到七牛云，只支持将剪贴面板里的图片上传到七牛云，在新版本的 Atom 中存在兼容性问题 Atom 编写 Markdown 将图片到七牛图床，第二种方法直接安装 md-writer-qiniu 插件，该插件是在 markdown-writer 的基础上新增了七牛图片上传的功能，支持上传本地图片到七牛云，支持将剪贴面板里的图片保存到本地或者上传到七牛云 Atom 安装 md-writer-qiniu 插件 12345678910111213# 进入 Atom 本地的插件目录$ cd ~/.atom/packages# 克隆代码，文件夹的名称必须是 markdown-writer ，即需要和 packagename 一致，否则插件无法正常使用$ git clone https://github.com/chenghm123/md-writer-qiniu.git markdown-writer# 进入源码目录$ cd markdown-writer# 安装依赖$ npm install# 重启 Atom md-writer-qiniu 快捷键冲突 md-writer-qiniu 的快捷键默认是 shift-ctrl-i，可能会与 toggle-dev-tools 的快捷键冲突，可以编辑 ~/.atom/keymap.cson 文件，更改 md-writer-qiniu 的快捷键，即下面的 \"shift-ctrl-v\": \"markdown-writer:insert-image\"： 1234567891011121314$ vim ~/.atom/keymap.cson\".platform-linux atom-text-editor:not([mini])\": \"shift-ctrl-K\": \"markdown-writer:insert-link\" \"shift-ctrl-v\": \"markdown-writer:insert-image\" \"shift-ctrl-X\": \"markdown-writer:toggle-taskdone\" \"ctrl-i\": \"markdown-writer:toggle-italic-text\" \"ctrl-b\": \"markdown-writer:toggle-bold-text\" \"ctrl-'\": \"markdown-writer:toggle-code-text\" \"ctrl-h\": \"markdown-writer:toggle-strikethrough-text\" \"ctrl-1\": \"markdown-writer:toggle-h1\" \"ctrl-2\": \"markdown-writer:toggle-h2\" \"ctrl-3\": \"markdown-writer:toggle-h3\" \"ctrl-4\": \"markdown-writer:toggle-h4\" \"ctrl-5\": \"markdown-writer:toggle-h5\" md-writer-qiniu 插件配置 首先注册七牛云的账号，选择” 对象存储” 产品，然后创建存储空间（必须设置为公开访问），接着在 Atom 的插件配置中填写以下内容即可。 Qiniu Bucket 是七牛云存储空间的名称 Qiniu Domain 是七牛云存储空间的域名 AccessKey、SecretKey 即是在七牛云中的 AK、SK 如果希望将剪贴面板里的图片保存到本地目录，需要配置 Hexo 图片的默认保存目录，下述配置是将图片保存在 source/asset/{year}/{month} 本地目录下： md-writer-qiniu 插件的使用 使用快捷方式 shift-ctrl-i 或者 shift-ctrl-v，调出图片上传的界面（如下图），也可以导航到菜单： Packages –&gt; Markdown Writer –&gt; Markup –&gt; Insert Image。在下面的操作完成后，默认按下” 回车键 “，即表示开始上传图片或者保存图片到 Hexo 的图片目录。 第一种使用情况：当剪贴面板里有图片时，如果勾选了 “Save Image To”，则只会将剪贴面板里的图片保存到 Hexo 的图片目录，此时并不会上传到七牛云；若不勾选，则默认会将剪贴面板里的图片上传到七牛云。 第二种使用情况：当剪贴面板里没有图片时，此时点击 “Choose Local Image” 按钮从本地选择图片，若勾选了 ”Copy Image To”，则只会当本地图片保存到 Hexo 的图片目录，此时并不会上传到七牛云；若不勾选，则默认会将本地图片上传到七牛云。 使用总结： 若不勾选 ”Save Image To“或者 “Copy Image To” 选项，默认会将剪贴面板里的图片或者本地图片上传到七牛云 只要勾选了 ”Save Image To“或者 “Copy Image To” 选项，都不会将剪贴面板里的图片或者本地图片上传到七牛云 补充说明 使用上面提到的 md-writer-qiniu 插件将图片上传到七牛云后，默认的图片路径是 {YYYY}/{MM}/{DD}/{HHmmss}{random-string}{extname} 的格式， 该插件不支持自定义七牛云里的图片文件名 若需要自定义七牛云里的图片文件名，可以使用这个分支的 md-writer-qiniu 插件（安装方法和上面的插件一样），支持使用路径前缀（针对七牛云的存储路径）。当在该插件的配置项里不勾选 Qiniu File Random Name 选项时，默认的图片路径是 {keyPrefix}/{YYYY}/{MM}/{title}{extname}，也就是说可以指定 Title 作为七牛云图片的文件名，具体配置如下图： var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Gateway 入门教程 - 中级篇","url":"/posts/802c502f.html","text":"上篇 - Gateway 入门教程（基础篇） Gateway 入门教程 - 基础篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Gateway 基于服务发现的路由规则Gateway 的服务发现路由概述Spring Cloud 对 Zuul 进行封装处理之后，当通过 Zuul 访问后端微服务时，基于服务发现的默认路由规则是：http://zuul_host:zuul_port/微服务在 Eureka 上的 serviceld/**。 Spring Cloud Gateway 在设计的时候考虑了从 Zuul 迁移到 Gateway 的 兼容性和迁移成本等，Gateway 基于服务发现的路由规则和 Zuul 的设计类似，但是也有很大差别。Spring Cloud Gateway 基于服务发现的路由规则，在不同注册中心下其差异如下： 如果把 Gateway 注册到 Consul 上，通过网关转发服务调用，服务名默认小写，不需要做任何处理 如果把 Gateway 注册到 Zookeeper 上，通过网关转发服务调用，服务名默认小写，不需要做任何处理 如果把 Gateway 注册到 Eureka 上，通过网关转发服务调用，访问网关的 URL 是 http://Gateway_HOST:Gateway_PORT/大写的 serviceld/*，其中服务名默认必须是大写，否则会抛 404 错误；如果服务名要用小写访问，可以在属性配置文件里面加 spring.cloud.gateway.discovery.locator.lowerCaseServiceId=true 配置解决 Gateway 服务发现的路由规则案例下面将使用 Eureka 作为注册中心来剖析 Gateway 服务发现的路由规则，其中各个模块的说明如下，由于篇幅有限，这里只给出核心的配置和代码，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-route N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 基于 Spring Cloud Gateway 的网关服务 micro-service-provider 9002 服务提供者 micro-service-consumer 9003 服务消费者 1. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 2. 创建 Micro Service Eureka 工程创建 Micro Service Eureka 的 Maven 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Eureka 的启动主类： 12345678@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 创建 Micro Service Eureka 的 application.yml 配置文件： 123456789101112131415server: port: 9000spring: application: name: eureka-servereureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 3. 创建 Micro Service Gateway 工程创建 Micro Service Gateway 的 Maven 工程，配置工程里的 pom.xml 文件，由于需要将 Gateway 服务注册到 Eureka，因此需要引入 Eureka Client；同时为了避免 Gateway 的依赖冲突，排除引入 spring-webmvc、spring-boot-starter-tomcat： 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Micro Service Gateway 的 application.yml 配置文件，其中 spring.cloud.gateway.discovery.locator.enabled 表示是否与服务发现组件进行结合，通过 serviceId 转发到具体的服务实例，默认为 false，若为 true 则开启基于服务发现的路由规则。spring.cloud.gateway.discovery.locator.lowerCaseServiceId=true 表示当注册中心为 Eureka 时，设置为 true 表示开启用小写的 serviceId 进行基于服务路由的转发。 1234567891011121314151617181920server: port: 9001spring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: trueeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: true 4. 创建 Micro Service Provider 工程创建 Micro Service Provider 的 Maven 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Provider 的启动主类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Micro Service Provider 的测试控制类： 123456789101112@RestController@RequestMapping(\"/provider\")public class ProviderController { @Value(\"${server.port}\") private String port; @GetMapping(\"/sayHello/{name}\") public String sayHello(@PathVariable(\"name\") String name) { return \"from port: \" + port + \", hello \" + name; }} 创建 Micro Service Provider 的 application.yml 配置文件： 1234567891011121314server: port: 9002spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: provider-service-${server.port} prefer-ip-address: true 5. 创建 Micro Service Consumer 工程创建 Micro Service Consumer 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Micro Service Consumer 的启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Micro Service Consumer 的服务调用接口： 123456@FeignClient(\"provider-service\")public interface ProviderService { @RequestMapping(value = \"/provider/sayHello/{name}\", method = RequestMethod.GET) public String sayHello(@PathVariable(\"name\") String name);} 创建 Micro Service Consumer 的测试控制类： 123456789101112@RestController@RequestMapping(\"/consumer\")public class ConsumerController { @Autowired private ProviderService providerService; @GetMapping(\"/sayHello/{name}\") public String sayHello(@PathVariable(\"name\") String name) { return providerService.sayHello(name); }} 创建 Micro Service Consumer 的 application.yml 配置文件： 1234567891011121314server: port: 9003spring: application: name: consumer-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: consumer-service-${server.port} prefer-ip-address: true 6. 测试结果 依次启动 micro-service-eureka、micro-service-gateway、micro-service-provider、micro-service-consumer 应用 访问 http://127.0.0.1:9000/，查看各个服务是否都成功注册到 Eureka 访问 http://127.0.0.1:9001/consumer-service/consumer/sayHello/Peter，查看是否可以成功通过 Gateway 调用 Consumer 的接口 Gateway Filter 和 Global FilterSpring Cloud Gateway 中的 Filter 从接口实现上分为两种：一种是 Gateway Filter，另外一种是 Global Filter。下面将给出这两种 Filter 的自定义使用示例，点击下载完整的案例代码。 Gateway Filter 和 Global Filter 的概述 Gateway Filter： 从 Web Filter 中复制过来的，相当于一个 Filter 过滤器，可以对访问的 URL 过滤，进行横切处理（切面处理），应用场景包括超时处理、安全检查等。 Global Filter： Spring Cloud Gateway 定义了 Global Filter 的接口，可以让开发者自定义实现自己的 Global Filter。顾名思义，Global Filter 是一个全局的 Filter，作用于所有路由。 Gateway Filter 和 Global Filter 的区别从路由的作用范围来看，Global Filter 会被应用到所有的路由上，而 Gateway Filter 则应用到单个路由或者一个分组的路由上。从源码设计来看，Gateway Filter 和 Global Filter 两个接口中定义的方法一样，都是 Mono filter()，唯一的区别就是 Gateway Filter 继承了 ShortcutConfigurable，而 Global Filter 没有任何继承。 自定义 Gateway Filter 案例 创建自定义的 Gateway Filter 1234567891011121314151617181920212223public class CustomGatewayFilter implements GatewayFilter, Ordered { private static final Logger logger = LoggerFactory.getLogger(CustomGatewayFilter.class); private static final String COUNT_START_TIME = \"countProcessTime\"; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { exchange.getAttributes().put(COUNT_START_TIME, System.currentTimeMillis()); return chain.filter(exchange).then( Mono.fromRunnable(() -&gt; { Long startTime = exchange.getAttribute(COUNT_START_TIME); if (startTime != null) { Long countTime = System.currentTimeMillis() - startTime; logger.info(exchange.getRequest().getURI().getRawPath() + \": \" + countTime + \" ms\"); } })); } @Override public int getOrder() { return Ordered.LOWEST_PRECEDENCE; }} 将 Gateway Filter 配置到路由上，由于 Gateway Filter 是作用于单个路由或者一个分组的路由上的，因此这里需要使用 Java 的流式 API 绑定 Gateway Filter 和路由，或者使用 YML 文件的方式配置路由 123456789101112131415@Configurationpublic class CommonConfiguration { @Bean public RouteLocator customGatewayFilter(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path(\"/custom/gateway/filter\") .filters(f -&gt; f.filter(new CustomGatewayFilter())) .uri(\"http://127.0.0.1:9090/provider/sayHello/Jim/\") .order(0) .id(\"custom-gateway-filter\") ) .build(); }} 自定义 Global Filter 案例下面通过简单定义一个名为 CustomGlobalFilter 的全局过滤器，对请求到网关的 URL 进行权限校验，判断请求的 URL 是否为合法请求。全局过滤器处理的逻辑是通过从 Gateway 的 上下文 ServerWebExchange 对象中获取 authToken 对应的值进行判 Null 处理，也可以根据需求定制开发更复杂的校验逻辑。因为 Global Filter 是作用在所有的路由上，因此只需要添加 @Component 注解，将 CustomGlobalFilter 的 Bean 注入进 Spring 的容器内即可。 123456789101112131415161718@Componentpublic class CustomGlobalFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String token = exchange.getRequest().getQueryParams().getFirst(\"authToken\"); if (null == token || token.isEmpty()) { exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); } return chain.filter(exchange); } @Override public int getOrder() { return -400; }} Gateway 实战场景Spring Cloud Gateway 权重路由WeightRoutePredicateFactory 是一个路由断言工厂，在 Spring Cloud Gateway 中可以使用它对 URL 进行权重路由，只需在配置时指定分组和权重值即可。 权重路由的使用场景在开发、测试的时候，或者线上发布、线上服务多版本控制的时候，需要对服务进行权重路由。最常见的使用场景就是一个服务有两个版本：旧版本 V1、新版本 V2。在线上灰度发布的时候，需要通过网关动态实时推送路由权重信息。比如 95% 的流量走服务 V1 版本，5% 的流量走服务 V2 版本。 权重路由案例下面的案例中，Spring Cloud Gateway 会根据权重路由规则，针对特定的服务，把 95% 的请求流量分发给服务的 V1 版本，把剩余 5% 的流量分发给服务的 V2 版本，由此进行权重路由，点击下载完整的案例代码。 创建 Gateway Server 工程里的 pom.xml 配置文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway Server 工程里的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Gateway Server 工程里的 application.yml 配置文件，添加两个针对 /test 路径转发的路由定义配置，这两个路由属于同一个权重分组，权重的分组名称为 group： 12345678910111213141516171819202122232425262728293031323334server: port: 9090spring: application: name: gateway-server cloud: gateway: routes: - id: provider-service-v1 uri: http://127.0.0.1:9091/v1/ predicates: - Path=/test - Weight=group, 95 - id: provider-service-v2 uri: http://127.0.0.1:9091/v2/ predicates: - Path=/test - Weight=group, 5logging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: '*' security: enabled: false 创建 Provider Service 工程里的测试控制器： 12345678910111213@RestControllerpublic class ProviderController { @GetMapping(\"/v1\") public String v1() { return \"version: v1\"; } @GetMapping(\"/v2\") public String v2() { return \"version: v2\"; }} 创建 Provider Service 工程里的启动主类： 1234567@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Provider Service 工程里的 application.yml 配置文件： 123456server: port: 9091spring: application: name: provider-service 测试结果： 依次启动 gateway-server、provider-service 应用 多次访问 http://127.0.0.1:9090/test ，会发现按权重配置返回对应的请求内容 Spring Cloud Gateway 的 HTTPS 使用大型互联网应用的生产环境基本是全站 HTTPS，常规的做法是通过 Nginx 来配置 SSL 证书。如果使用 Spring Cloud Gateway 作为 API 网关，统一管理所有 API 请求的入口和出口，此时 Spring Cloud Gateway 就需要支持 HTTPS。由于 Spring Cloud Gateway 是基于 Spring Boot 2.0 构建的，所以只需要将生成的 HTTPS 证书放到 Spring Cloud Gateway 应用的类路径下面即可。 HTTPS 案例下面将介绍如何在 Spring Cloud Gateway 中使用 HTTPS，其中各个模块的说明如下。由于本案例是基于上面的 “Gateway 服务发现的路由规则案例 “ 改造而来的，因此 micro-service-eureka、micro-service-provider-1、micro-service-provider-2 工程里的配置和代码不再累述，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-https N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 带有 HTTPS 证书的网关服务，使用 HTTPS 协议访问 micro-service-provider-1 9002 服务提供者，使用 HTTP 协议 micro-service-provider-2 9003 服务提供者，使用 HTTP 协议 创建 Micro Service Gateway 工程里的 pom.xml 配置文件： 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 工程里的启动主类： 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 创建 Micro Service Gateway 工程里的 application.yml 配置文件，通过 key-store 指定 HTTPS 证书的路径： 12345678910111213141516171819202122232425262728server: port: 9001 ssl: enabled: true key-alias: spring key-password: spring key-store: classpath:self-signed.jks key-store-type: JKS key-store-provider: SUN key-store-password: springspring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: trueeureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: true 测试结果： 依次启动 micro-service-eureka、micro-service-provider-1、micro-service-provider-2、micro-service-gateway 应用 通过 HTTPS 协议访问 https://127.0.0.1:9001/provider-service/provider/sayHello/Jim，会出现如下的错误： 123456789101112131415161718io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 485454502f312e3120343030200d0a5472616e736665722d456e636f646 ... at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1156) [netty-handler-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1221) [netty-handler-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) ~[netty-codec-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[netty-transport-4.1.25.Final.jar:4.1.25.Final] at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:808) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:408) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:308) ~[netty-transport-native-epoll-4.1.25.Final-linux-x86_64.jar:4.1.25.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) ~[netty-common-4.1.25.Final.jar:4.1.25.Final] at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_102] HTTPS 转 HTTP 的问题上述错误出现的原因是通过 Spring Cloud Gateway 请求进来的协议是 HTTPS，而后端被代理的服务是 HTTP 协议的请求，所以当 Gateway 用 HTTPS 请求转发调用 HTTP 协议的服务时，就会出现 not an SSL/TLS record 的错误。本质上这是一个 Spring Cloud Gateway 将 HTTPS 请求转发调用 HTTP 服务的问题。由于服务的拆分，在微服务的应用集群中会存在很多服务提供者和服务消费者，而这些服务提供者和服务消费者基本都是部署在企业内网中，没必要全部加 HTTPS 进行调用。因此 Spring Cloud Gateway 对外的请求是 HTTPS，对后端代理服务的请求可以是 HTTP。通过 Debug 调试源码分析，LoadBalancerClientFilter.filter() 方法如下： 123456789URI uri = exchange.getRequest().getURI();String overrideScheme = null;if (schemePrefix != null) { overrideScheme = url.getScheme();}URI requestUrl = this.loadBalancer.reconstructURI(new LoadBalancerClientFilter.DelegatingServiceInstance(instance, overrideScheme), uri);log.trace(\"LoadBalancerClientFilter url chosen: \" + requestUrl);exchange.getAttributes().put(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR, requestUrl); 从上面的代码可以看出，LoadBalancer 对 HTTP 请求进行封装，如果从 Spring Cloud Gateway 进来的请求是 HTTPS，它就用 HTTPS 封装，如果是 HTTP 就用 HTTP 封装，而且没有预留 任何扩展修改的接口，只能通过自定义 Global Filter 的方式对其修改。下面介绍两种修改方法，在实践中任选其中一种即可。 官方 Issues 说明 https://github.com/spring-cloud/spring-cloud-gateway/issues/378 https://github.com/spring-cloud/spring-cloud-gateway/issues/160 第一种解决方案在 LoadBalancerClientFilter 执行之前将 HTTPS 修改为 HTTP 协议： 123456789101112131415161718192021222324252627282930313233343536373839@Componentpublic class HttpsToHttpFilter implements GlobalFilter, Ordered { private static final int HTTPS_TO_HTTP_FILTER_ORDER = 10099; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { URI originalUri = exchange.getRequest().getURI(); ServerHttpRequest request = exchange.getRequest(); ServerHttpRequest.Builder mutate = request.mutate(); String forwardedUri = request.getURI().toString(); if (forwardedUri != null &amp;&amp; forwardedUri.startsWith(\"https\")) { try { URI mutatedUri = new URI(\"http\", originalUri.getUserInfo(), originalUri.getHost(), originalUri.getPort(), originalUri.getPath(), originalUri.getQuery(), originalUri.getFragment()); mutate.uri(mutatedUri); } catch (Exception e) { throw new IllegalStateException(e.getMessage(), e); } } ServerHttpRequest build = mutate.build(); return chain.filter(exchange.mutate().request(build).build()); } /** * 由于LoadBalancerClientFilter的order是10100 * 要在LoadBalancerClientFilter执行之前将Https修改为Http，需要设置order为10099 * @return */ @Override public int getOrder() { return HTTPS_TO_HTTP_FILTER_ORDER; }} 第二种解决方案在 LoadBalancerClientFilter 执行之后将 HTTPS 修改为 HTTP，拷贝 RibbonUtils 中的 upgradeconnection 方法来自定义全局过滤器： 12345678910111213141516171819202122232425262728293031323334353637@Componentpublic class HttpSchemeFilter implements GlobalFilter, Ordered { private static final int HTTPS_TO_HTTP_FILTER_ORDER = 10101; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { Object uriObj = exchange.getAttributes().get(GATEWAY_REQUEST_URL_ATTR); if (uriObj != null) { URI uri = (URI) uriObj; uri = this.upgradeConnection(uri, \"http\"); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, uri); } return chain.filter(exchange); } private URI upgradeConnection(URI uri, String scheme) { UriComponentsBuilder uriComponentsBuilder = UriComponentsBuilder.fromUri(uri).scheme(scheme); if (uri.getRawQuery() != null) { // When building the URI, UriComponentsBuilder verify the allowed characters and does not // support the '+' so we replace it for its equivalent '%20'. // See issue https://jira.spring.io/browse/SPR-10172 uriComponentsBuilder.replaceQuery(uri.getRawQuery().replace(\"+\", \"%20\")); } return uriComponentsBuilder.build(true).toUri(); } /** * 由于LoadBalancerClientFilter的order是10100，所以设置HttpSchemeFilter的的order是10101 * 在LoadBalancerClientFilter之后将https修改为http * @return */ @Override public int getOrder() { return HTTPS_TO_HTTP_FILTER_ORDER; }} Spring Cloud Gateway 集成 SwaggerSwagger 是一个可视化 API 测试工具，可以和应用完美融合。通过声明接口注解的方式，可以方便快捷地获取 API 调试界面进行测试。Zuul 可以很方便地与 Swagger 整合在一起，由于 Spring Cloud Finchley 版是基于 Spring Boot 2.0 的，而 Spring Cloud Gateway 的底层是基于 WebFlux 实现的，且经验证，WebFlux 和 Swagger 不兼容。如果按照 Zuul 集成 Swagger 的方式，应用启动的时候会报错。下面将介绍 Spring Cloud Gateway 如何集成 Swagger，其中各个模块的说明如下。由于本案例是基于上面的 “Gateway 服务发现的路由规则案例 “ 改造而来的，因此 micro-service-eureka 工程里的配置和代码不再累述，点击下载完整的案例代码。 模块 端口 说明 micro-service-gateway-swagger N/A 聚合父 Maven 工程 micro-service-eureka 9000 Eureka 注册中心 micro-service-gateway 9001 基于 Spring Cloud Gateway 的网关服务 micro-service-provider-1 9002 服务提供者 micro-service-provider-2 9003 服务提供者 1. 创建 Micro Service Gateway 工程创建 Micro Service Gateway 工程里的 pom.xml 配置文件： 123456789101112131415161718192021222324252627282930313233343536&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 创建 Micro Service Gateway 工程里的 SwaggerProvider 类，因为 Swagger 暂不支持 WebFlux 项目，所以不能在 Gateway 中配置 SwaggerCoufig，需要编写 GatewaySwaggerProvider 实现 SwaggerResourcesProvider 接口，用于获取 SwaggerResources： 12345678910111213141516171819202122232425262728293031323334353637383940/** * @Primary注解的实例优先于其他实例被注入 */@Primary@Componentpublic class GatewaySwaggerProvider implements SwaggerResourcesProvider { private final RouteLocator routeLocator; private final GatewayProperties gatewayProperties; public static final String API_URI = \"/v2/api-docs\"; public GatewaySwaggerProvider(RouteLocator routeLocator, GatewayProperties gatewayProperties) { this.routeLocator = routeLocator; this.gatewayProperties = gatewayProperties; } @Override public List&lt;SwaggerResource&gt; get() { List&lt;SwaggerResource&gt; resources = new ArrayList&lt;&gt;(); List&lt;String&gt; routes = new ArrayList&lt;&gt;(); //取出Spring Cloud Gateway中的route routeLocator.getRoutes().subscribe(route -&gt; routes.add(route.getId())); //结合application.yml中的路由配置，只获取有效的route节点 gatewayProperties.getRoutes().stream().filter(routeDefinition -&gt; routes.contains(routeDefinition.getId())) .forEach(routeDefinition -&gt; routeDefinition.getPredicates().stream() .filter(predicateDefinition -&gt; (\"Path\").equalsIgnoreCase(predicateDefinition.getName())) .forEach(predicateDefinition -&gt; resources.add(swaggerResource(routeDefinition.getId(), predicateDefinition.getArgs().get(NameUtils.GENERATED_NAME_PREFIX + \"0\") .replace(\"/**\", API_URI))))); return resources; } private SwaggerResource swaggerResource(String name, String location) { SwaggerResource swaggerResource = new SwaggerResource(); swaggerResource.setName(name); swaggerResource.setLocation(location); swaggerResource.setSwaggerVersion(\"2.0\"); return swaggerResource; }} 创建 Micro Service Gateway 工程里的 Swagger-Resource 端点，因为没有在 Gateway 中配置 SwaggerConfig，但是运行 Swagger-UI 的时候需要依赖一些接口，所以需要建立相应的 Swagger-Resource 端点： 123456789101112131415161718192021222324252627282930313233@RestController@RequestMapping(\"/swagger-resources\")public class SwaggerHandler { @Autowired(required = false) private SecurityConfiguration securityConfiguration; @Autowired(required = false) private UiConfiguration uiConfiguration; private final SwaggerResourcesProvider swaggerResources; @Autowired public SwaggerHandler(SwaggerResourcesProvider swaggerResources) { this.swaggerResources = swaggerResources; } @GetMapping(\"/configuration/security\") public Mono&lt;ResponseEntity&lt;SecurityConfiguration&gt;&gt; securityConfiguration() { return Mono.just(new ResponseEntity&lt;&gt;( Optional.ofNullable(securityConfiguration).orElse(SecurityConfigurationBuilder.builder().build()), HttpStatus.OK)); } @GetMapping(\"/configuration/ui\") public Mono&lt;ResponseEntity&lt;UiConfiguration&gt;&gt; uiConfiguration() { return Mono.just(new ResponseEntity&lt;&gt;( Optional.ofNullable(uiConfiguration).orElse(UiConfigurationBuilder.builder().build()), HttpStatus.OK)); } @GetMapping(\"\") public Mono&lt;ResponseEntity&gt; swaggerResources() { return Mono.just((new ResponseEntity&lt;&gt;(swaggerResources.get(), HttpStatus.OK))); }} 创建 Micro Service Gateway 工程里的 GwSwaggerHeaderFilter 类，由于在路由规则为 admin/test/{a}/{b} 时，Swagger 界面上会显示为 test/{a}/{b}，缺少了 /admin 这个路由节点。通过 Debug 断点调试发现，Swagger 会根据 X-Forwarded-Prefix 这个 Header 来获取 BasePath，因此需要将它添加到接口路径与 Host 之间才能正常工作。但是 Gateway 在做转发的时候并没有将这个 Header 添加到 Request 上，从而导致接口调试出现 404 错误。为了解决该问题，需要在 Gateway 中编写一个过滤器来添加这个 Header。特别注意，Spring Boot 版本为 2.0.6 以上的可以跳过这一步骤，最新源码里 Spring Boot 修复了该 Bug，已经默认添加上了这个 Header。 1234567891011121314151617181920@Componentpublic class GwSwaggerHeaderFilter extends AbstractGatewayFilterFactory { private static final String HEADER_NAME = \"X-Forwarded-Prefix\"; @Override public GatewayFilter apply(Object config) { return (exchange, chain) -&gt; { ServerHttpRequest request = exchange.getRequest(); String path = request.getURI().getPath(); if (!StringUtils.endsWithIgnoreCase(path, GatewaySwaggerProvider.API_URI)) { return chain.filter(exchange); } String basePath = path.substring(0, path.lastIndexOf(GatewaySwaggerProvider.API_URI)); ServerHttpRequest newRequest = request.mutate().header(HEADER_NAME, basePath).build(); ServerWebExchange newExchange = exchange.mutate().request(newRequest).build(); return chain.filter(newExchange); }; }} 创建 Micro Service Gateway 工程里的 application.yml 配置文件，添加上面编写的 GwSwaggerHeaderFilter 过滤器， URI 指定为 lb://provider-service-1，表示负载均衡到 provider-service-1 服务。由于 Swagger 发出请求 的 URL 都是以 /xxxx 开头，因此需要使用 StripPrefix 过滤器将第一个路由节点（/xxxx）去掉。 12345678910111213141516171819202122232425262728293031323334353637383940414243server: port: 9001spring: application: name: gateway-server cloud: gateway: discovery: locator: enabled: true lower-case-service-id: true routes: - id: provider-service-1 uri: lb://provider-service-1 predicates: - Path=/provider1/** filters: - GwSwaggerHeaderFilter - StripPrefix=1 - id: provider-service-2 uri: lb://provider-service-2 predicates: - Path=/provider2/** filters: - GwSwaggerHeaderFilter - StripPrefix=1eureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: gateway-server-${server.port} prefer-ip-address: truemanagement: endpoints: web: exposure: include: '*' security: enabled: false 2. 创建 Micro Service Provider 1 工程创建 Micro Service Provider 1 工程里的 pom.xml 配置文件： 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 创建 Micro Service Provider 1 工程里的 SwaggerConfig 类： 1234567891011121314151617181920212223@Configuration@EnableSwagger2public class SwaggerConfig { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)) .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"Swagger API\") .description(\"验证 Gateway 集成 Swagger 的效果\") .termsOfServiceUrl(\"\") .version(\"2.0\") .build(); }} 创建 Micro Service Provider 1 工程里的测试控制类： 123456789101112131415@RestController@Api(\"provider-service-1 接口测试\")@RequestMapping(\"/provider1\")public class ProviderOneController { @ApiOperation(value = \"计算+\", notes = \"加法\") @ApiImplicitParams({ @ApiImplicitParam(name = \"a\", value = \"数字a\", required = true, dataType = \"Long\"), @ApiImplicitParam(name = \"b\", value = \"数字b\", required = true, dataType = \"Long\") }) @GetMapping(\"/{a}/{b}\") public String get(@PathVariable Integer a, @PathVariable Integer b) { return \"from provider service 1, the result is: \" + (a + b); }} 创建 Micro Service Provider 1 工程里的 application.xml 配置文件： 1234567891011121314server: port: 9002spring: application: name: provider-service-1eureka: client: service-url: defaultZone: http://127.0.0.1:9000/eureka instance: instance-id: provider-service-1-${server.port} prefer-ip-address: true 3. 创建 Micro Service Provider 2 工程由于 Micro Service Provider 2 工程 与 Micro Service Provider 1 工程里的配置和代码都差不多，这里不再累述。 4. 测试结果 依次启动 micro-service-eureka、micro-service-provider-1、micro-service-provider-2、micro-service-gateway 应用 访问 http://127.0.0.1:9000/，查看各个服务是否都成功注册到 Eureka 访问 http://127.0.0.1:9001/swagger-ui.html，查看 Swagger 的界面是否正常工作，查看截图 在 Swagger 的界面上打开对应的 URL，输入测试数据，验证 Swagger 经过 Gateway 是否可以正常访问 Provider1 和 Provider2 服务的接口，查看截图 Spring Cloud Gateway 限流Gateway 限流概述在开发高并发系统时可以用三把利器来保护系统：缓存、降级和限流。缓存的目的是提升系统访问速度和增大系统处理的容量，是抗高并发流量的 “银弹”；而降级是当服务出现问题或者影响到核心流程时，需要暂时将其屏蔽掉，待高峰过去之后或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询等，因此需要有一种手段来限制这些场景的并发 / 请求量，即限流。限流的目的是通过对并发访问 / 请求进行限速或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或友好的展示页）、排队或等待（比如秒杀、评论、下单等场景）、降级（返回兜底数据或默认数据）。主流的中间件都会有单机限流框架，一般支持两种限流模式：控制速率和控制并发。Spring Cloud Zuul 通过第三方扩展 spring-cloud-zuul-ratelimit 也可以支持限流。Spring Cloud Gateway 是一个 API 网关中间件，网关是所有请求流量的入口；特别是像天猫双十一、双十二等高并发场景下，当流量迅速剧增，网关除了要保护自身之外，还要限流保护后端应用。常见的限流算法有漏桶和令牌桶，计数器也可以进行粗暴限流实现。对于限流算法，可以参考 Guava 中的 RateLimiter、Bucket4j、RateLimitJ 等项目的具体实现。下面将介绍如何基于 Bucket4j、Gateway 内置的限流过滤器工厂（RequestRateLimiterGatewayFilterFactory）、CPU 使用率实现限流，点击下载完整的案例代码。 Gateway 限流方案基于 Bucket4j 实现限流在 Spring Cloud Gateway 中实现限流比较简单，只需要编写一个过滤器就可以。下面介绍在 Spring Cloud Gateway 中使用 Bucket4j 实现限流，由于篇幅有限，只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 123456789&lt;dependency&gt; &lt;groupId&gt;com.github.vladimir-bukhtoyarov&lt;/groupId&gt; &lt;artifactId&gt;bucket4j-core&lt;/artifactId&gt; &lt;version&gt;4.10.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt; 编写自定义过滤器对特定资源进行限流 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 针对客户端IP进行限流 */public class GatewayRateLimitFilterByIp implements GatewayFilter, Ordered { private final Logger log = LoggerFactory.getLogger(GatewayRateLimitFilterByIp.class); /** * 单机网关限流用一个ConcurrentHashMap来存储 bucket， * 如果是分布式集群限流的话，可以采用 Redis等分布式解决方案 */ private static final Map&lt;String, Bucket&gt; LOCAL_CACHE = new ConcurrentHashMap&lt;&gt;(); /** * 令牌桶的最大容量，即能装载令牌的最大数量 */ int capacity; /** * 每次补充令牌的数量 */ int refillTokens; /** * 补充令牌的时间间隔 */ Duration refillDuration; public GatewayRateLimitFilterByIp() { } public GatewayRateLimitFilterByIp(int capacity, int refillTokens, Duration refillDuration) { this.capacity = capacity; this.refillTokens = refillTokens; this.refillDuration = refillDuration; } private Bucket createNewBucket() { Refill refill = Refill.greedy(refillTokens, refillDuration); Bandwidth limit = Bandwidth.classic(capacity, refill); return Bucket4j.builder().addLimit(limit).build(); } @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String ip = exchange.getRequest().getRemoteAddress().getAddress().getHostAddress(); Bucket bucket = LOCAL_CACHE.computeIfAbsent(ip, k -&gt; createNewBucket()); log.info(\"IP:{} ,令牌桶可用的令牌数量:{} \", ip, bucket.getAvailableTokens()); if (bucket.tryConsume(1)) { return chain.filter(exchange); } else { //当可用的令牌数为0时，进行限流，返回429状态码 exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS); return exchange.getResponse().setComplete(); } } @Override public int getOrder() { return -1000; } // 省略Get和Set方法 ...} 通过 Java 流式 API 的方式配置路由规则，其中 http://127.0.0.1:9091/sayHello/peter/ 对应的是后端的服务，这里不再累述 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator rateLimitFilterByIp(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path(\"/rateLimit\") .filters(f -&gt; f.filter(new GatewayRateLimitFilterByIp(10, 1, Duration.ofSeconds(1)))) .uri(\"http://127.0.0.1:9091/sayHello/peter/\") .id(\"ratelimit_route\")) .build(); }} 编写 application.yml 配置文件 123456server: port: 9090spring: application: name: gateway-server 测试结果 启动各个应用后，多次访问 http://127.0.0.1:9090/rateLimit，可以看到控制台输出如下日志信息。当可用的令牌数量为 0 时，Spring Cloud Gateway 中自定义的限流过滤器开始拒绝处理请求，直接返回 429 状态码（因为请求太多，限流返回 429 状态码）。 1234567891011121314c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:10c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:9c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:8c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:7c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:7c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:6c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:5c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:4c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:3c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:2c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:2c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:1c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:0c.s.s.filter.GatewayRateLimitFilterByIp : IP:127.0.0.1 ,令牌桶可用的令牌数量:0 基于 CPU 的使用率进行限流在实际项目应用中对网关进行限流时，需要参考的因素比较多，可能会根据网络请求连接数、请求流量、CPU 使用率、内存使用率等进行流控。可以通过 Spring Boot Actuator 提供的 Metrics 获取当前 CPU 的使用情况，当 CPU 使用率高于某个阈值就开启限流，否则不开启限流。值得一提的是，在 Actuator 1.x 里可以通过 SystemPublicMetrics 来获取 CPU 的使用情况，但是在 Actuator 2.x 里只能通过 MetricsEndpoint 来获取。由于篇幅有限，下面只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 编写自定义过滤器对特定资源进行限流 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 根据CPU的使用率限流 **/@Componentpublic class GatewayRateLimitFilterByCpu implements GatewayFilter, Ordered { @Autowired private MetricsEndpoint metricsEndpoint; private static final double MAX_USAGE = 0.50D; private static final String METRIC_NAME = \"system.cpu.usage\"; private final Logger log = LoggerFactory.getLogger(GatewayRateLimitFilterByCpu.class); @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { //获取网关服务所在机器的CPU使用情况 Double systemCpuUsage = metricsEndpoint.metric(METRIC_NAME, null) .getMeasurements() .stream() .filter(Objects::nonNull) .findFirst() .map(MetricsEndpoint.Sample::getValue) .filter(Double::isFinite) .orElse(0.0D); boolean isOpenRateLimit = systemCpuUsage &gt; MAX_USAGE; log.info(\"system.cpu.usage: {}, isOpenRateLimit:{} \", systemCpuUsage, isOpenRateLimit); if (isOpenRateLimit) { //当CPU的使用超过设置的最大阀值时，则开启限流 exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS); return exchange.getResponse().setComplete(); } else { return chain.filter(exchange); } } @Override public int getOrder() { return 0; }} 通过 Java 流式 API 的方式配置路由规则，其中 http://127.0.0.1:9091/sayHello/peter/ 对应的是后端的服务，这里不再累述 12345678910111213141516@Configurationpublic class CommonConfiguration { @Autowired private GatewayRateLimitFilterByCpu gatewayRateLimitFilterByCpu; @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path(\"/rateLimit\") .filters(f -&gt; f.filter(gatewayRateLimitFilterByCpu)) .uri(\"http://127.0.0.1:9091/sayHello/peter/\") .id(\"rateLimit_route\") ).build(); }} 编写 application.yml 配置文件 1234567891011121314server: port: 9093spring: application: name: gateway-servermanagement: endpoints: web: exposure: include: '*' security: enabled: false 测试结果 i. Linux 系统下执行压测命令 sysbench cpu --cpu-max-prime=20000 --threads=8 --time=60 run 来模拟 CPU 高负载，其中 --threads 是指 CPU 核数，--time 是指运行时间（秒）ii. 访问 http://localhost:9093/actuator/metrics/system.cpu.usage，查看网关服务所在机器的 CPU 使用情况iii. 启动各个应用后，多次访问 http://127.0.0.1:9090/rateLimit，当 CPU 使用率超过 50% 后，Spring Cloud Gateway 中自定义的限流过滤器开始拒绝处理请求，直接返回 429 状态码（因为请求太多，限流返回 429 状态码），控制台输出的日志信息如下： 12345c.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.846045400926432, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8458261370178468, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.844951044863364, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8547458051590282, isOpenRateLimit:truec.s.s.f.GatewayRateLimitFilterByCpu : system.cpu.usage: 0.8486913849509269, isOpenRateLimit:true Gateway 内置的限流过滤器工厂Spring Cloud Gateway 内置了一个名为 RequestRateLimiterGatewayFilterFactory 的过滤器工厂，可以直接用来限流；其底层的实现依赖于 Redis，使用的算法是令牌桶算法。由于篇幅有限，下面只给出 Gateway Server 工程的核心代码和配置。 添加 Maven 依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;/artifactId&gt;&lt;/dependency&gt; 编写 RemoteAddrKeyResolver 类 123456789public class RemoteAddrKeyResolver implements KeyResolver { public static final String BEAN_NAME = \"remoteAddrKeyResolver\"; @Override public Mono&lt;String&gt; resolve(ServerWebExchange exchange) { return Mono.just(exchange.getRequest().getRemoteAddress().getAddress().getHostAddress()); }} 编写 CommonConfiguration 类 12345678@Configurationpublic class CommonConfiguration { @Bean(RemoteAddrKeyResolver.BEAN_NAME) public RemoteAddrKeyResolver remoteAddrKeyResolver() { return new RemoteAddrKeyResolver(); }} 编写 application.yml 配置文件，添加 Gateway 限流相关的配置内容 123456789101112131415161718192021222324252627server: port: 9092spring: application: name: gateway-server redis: host: 172.175.0.3 port: 6379 cloud: gateway: routes: - id: rateLimit_route uri: http://127.0.0.1:9091/sayHello/peter/ order: 0 predicates: - Path=/rateLimit filters: #Filter名称必须是RequestRateLimiter - name: RequestRateLimiter args: #使用SpEL按名称引用bean key-resolver: \"#{@remoteAddrKeyResolver}\" #允许用户每秒处理多少个请求 redis-rate-limiter.replenishRate: 1 #令牌桶的容量，允许在一秒钟内完成的最大请求数 redis-rate-limiter.burstCapacity: 5 测试结果 启动各个应用后，多次访问 http://127.0.0.1:9092/rateLimit，可以发现当请求太过频繁的时候，Spring Cloud Gateway 会直接返回 429 状态码。 基于 Sentinel 实现限流熔断降级 Sentinel 整合 Gateway Spring Cloud Gateway 的动态路由网关中有两个重要的概念，那就是路由配置和路由规则。路由配置是指配置某请求路径路由到指定的目的地址，而路由规则是指匹配到路由配置之后，再根据路由规则进行转发处理。 Spring Cloud Gateway 作为所有请求流量的入口，在实际生产环境中为了保证高可靠和高可用，以及尽量避免重启，需要实现 Spring Cloud Gateway 动态路由配置。Spring Cloud Gateway 提供了两种方法来配置路由规则（Java 流式 API、YML 配置文件），但都是在 Spring Cloud Gateway 启动时将路由配置和规则加载到内存里，无法做到不重启网关应用就可以动态地对路由的配置和规则进行增加、修改和删除操作。Spring Cloud Gateway 的官方文档并没有讲如何进行动态配置，査看 Spring Cloud Gateway 的源码，发现在 org.springframework.cloud.gateway.actuate.GatewayControllerEndpoint 类中提供了动态配置的 Rest 接口，但是需要开启 Gateway 的端点，而且其提供的功能不是很强大。通过参考与 GatewayControllerEndpoint 相关的代码，可以自己编码实现动态路由配置。 基于 Rest API 的动态路由实现（内存版）下面将介绍 Gateway 基于 Rest API 的动态路由实现，为了方便演示，下述示例的路由配置信息默认存储在内存；若需要持久化路由配置信息（如 MySQL 持久化），可以扩展实现 RouteDefinitionRepository 接口，点击下载完整的案例代码。 添加 Maven 依赖 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt;&lt;/dependency&gt; 定义数据传输模型，分别编写 GatewayRouteDefinition、GatewayPredicateDefinition、GatewayFilterDefinition 类 1234567891011121314151617181920212223242526272829303132/** * Gateway的路由定义模型 */public class GatewayRouteDefinition { /** * 路由的Id */ private String id; /** * 路由断言集合配置 */ private List&lt;GatewayPredicateDefinition&gt; predicates = new ArrayList&lt;&gt;(); /** * 路由过滤器集合配置 */ private List&lt;GatewayFilterDefinition&gt; filters = new ArrayList&lt;&gt;(); /** * 路由规则转发的目标uri */ private String uri; /** * 路由执行的顺序 */ private int order = 0; // 省略Get和Set方法 ...} 1234567891011121314151617/** * 路由断言定义模型 */public class GatewayPredicateDefinition { /** * 断言对应的Name */ private String name; /** * 配置的断言规则 */ private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); // 省略Get和Set方法 ...} 1234567891011121314151617/** * 过滤器定义模型 */public class GatewayFilterDefinition { /** * Filter Name */ private String name; /** * 对应的路由规则 */ private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); // 省略Get和Set方法 ...} 编写动态路由的实现类 DynamicRouteServicelmpl，需要实现 ApplicationEventPublisherAware 接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/** * 动态路由实现类 */@Servicepublic class DynamicRouteServiceImpl implements ApplicationEventPublisherAware { private ApplicationEventPublisher publisher; @Autowired private RouteDefinitionWriter routeDefinitionWriter; private static final Logger logger = LoggerFactory.getLogger(DynamicRouteServiceImpl.class); @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) { this.publisher = applicationEventPublisher; } private void notifyChanged() { this.publisher.publishEvent(new RefreshRoutesEvent(this)); } /** * 增加路由 * * @param definition * @return */ public boolean add(RouteDefinition definition) { try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); notifyChanged(); } catch (Exception e) { logger.error(\"add route fail: \" + e.getMessage()); return false; } return true; } /** * 更新路由 * * @param definition * @return */ public boolean update(RouteDefinition definition) { try { // 特别注意，这里一定不能执行subscribe()方法，否则更新逻辑存在Bug this.routeDefinitionWriter.delete(Mono.just(definition.getId())); } catch (Exception e) { logger.error(\"update route fail: \" + e.getMessage()); return false; } try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); notifyChanged(); return true; } catch (Exception e) { logger.error(\"update route fail: \" + e.getMessage()); return false; } } /** * 删除路由 * * @param id * @return */ public boolean delete(String id) { try { this.routeDefinitionWriter.delete(Mono.just(id)).subscribe(); notifyChanged(); return true; } catch (Exception e) { logger.error(\"delete route fail: \" + e.getMessage()); return false; } } /** * 装配路由配置信息 * * @param gwdefinition * @return */ public RouteDefinition assembleRouteDefinition(GatewayRouteDefinition gwdefinition) { RouteDefinition definition = new RouteDefinition(); // ID definition.setId(gwdefinition.getId()); // Predicates List&lt;PredicateDefinition&gt; pdList = new ArrayList&lt;&gt;(); for (GatewayPredicateDefinition gpDefinition : gwdefinition.getPredicates()) { PredicateDefinition predicate = new PredicateDefinition(); predicate.setArgs(gpDefinition.getArgs()); predicate.setName(gpDefinition.getName()); pdList.add(predicate); } definition.setPredicates(pdList); // Filters List&lt;FilterDefinition&gt; fdList = new ArrayList&lt;&gt;(); for (GatewayFilterDefinition gfDefinition : gwdefinition.getFilters()) { FilterDefinition filter = new FilterDefinition(); filter.setArgs(gfDefinition.getArgs()); filter.setName(gfDefinition.getName()); fdList.add(filter); } definition.setFilters(fdList); // URI URI uri = UriComponentsBuilder.fromUriString(gwdefinition.getUri()).build().toUri(); definition.setUri(uri); return definition; }} 编写 Rest 控制器，对外暴露 Rest API 123456789101112131415161718192021222324252627282930313233343536373839404142@RestController@RequestMapping(\"/route\")public class RouteController { @Autowired private DynamicRouteServiceImpl dynamicRouteService; /** * 增加路由 * * @param gwdefinition * @return */ @PostMapping(\"/add\") public String add(@RequestBody GatewayRouteDefinition gwdefinition) { RouteDefinition definition = dynamicRouteService.assembleRouteDefinition(gwdefinition); return this.dynamicRouteService.add(definition) ? \"success\" : \"fail\"; } /** * 删除路由 * * @param id * @return */ @GetMapping(\"/delete/{id}\") public String delete(@PathVariable String id) { return this.dynamicRouteService.delete(id) ? \"success\" : \"fail\"; } /** * 更新路由 * * @param gwdefinition * @return */ @PostMapping(\"/update\") public String update(@RequestBody GatewayRouteDefinition gwdefinition) { RouteDefinition definition = dynamicRouteService.assembleRouteDefinition(gwdefinition); return this.dynamicRouteService.update(definition) ? \"success\" : \"fail\"; }} 编写应用的启动主类 1234567@SpringBootApplicationpublic class GatewayServerApplication { public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} 编写 application.yml 配置文件： 1234567891011121314server: port: 9090spring: application: name: gateway-servermanagement: endpoints: web: exposure: include: '*' security: enabled: false 测试结果 i. 启动 gateway 应用ii. 访问 http://127.0.0.1:9090/actuator/gateway/routes，此时返回的路由信息应该为空 []iii. 通过 Postman 访问 http://127.0.0.1:9090/route/add，发起 Post 请求添加路由配置信息，其中需要提交的 JSON 数据如下： 1234567891011121314{ \"filters\": [], \"id\": \"jd_route\", \"order\": 0, \"predicates\": [ { \"args\": { \"pattern\": \"/jd\" }, \"name\": \"Path\" } ], \"uri\": \"http://www.jd.com\"} iiii. 再次访问 http://127.0.0.1:9090/actuator/gateway/routes，此时应该可以返回上面添加的路由配置信息iiiii. 访问 http://127.0.0.1:9090/jd，发现可以正常跳转到京东商城的首页，说明上面添加的路由配置生效了iiiiii. 通过 Postman 访问 http://127.0.0.1:9090/route/update，发起 Post 请求更改路由配置信息，其中需要提交的 JSON 数据如下： 1234567891011121314{ \"filters\": [], \"id\": \"jd_route\", \"order\": 0, \"predicates\": [ { \"args\": { \"pattern\": \"/jd\" }, \"name\": \"Path\" } ], \"uri\": \"http://www.taobao.com\"} iiiiiii. 访问 http://127.0.0.1:9090/actuator/gateway/routes，可以发现返回的路由配置信息已经被修改了iiiiiiii. 访问 http://127.0.0.1:9090/jd，发现可以成功跳转到淘宝网iiiiiiiii. 通过 Postman 访问 http://127.0.0.1:9090/route/delete/jd_route，发起 Get 请求删除路由配置信息 最后附上 JSON 版的完整路由配置示例 1234567891011121314151617181920212223242526{ \"filters\": [ { \"args\": { \"name\": \"hystrix\", \"fallbackUri\": \"forward:/fallback\" }, \"name\": \"Hystrix\" }, { \"args\": {}, \"name\": \"RateLimit\" } ], \"id\": \"jd_route\", \"order\": 0, \"predicates\": [ { \"args\": { \"pattern\": \"/jd\" }, \"name\": \"Path\" } ], \"uri\": \"http://www.jd.com\"} Gateway 集群下的动态路由实现上面的示例简单地实现了单机 Gateway 的动态路由，单机 Gateway 中的路由配置信息保存在当前实例的内存中，实例重启后会丢失路由配置信息，同时无法做到整个 Gateway 集群的动态路由控制。通过分析 Spring Cloud Gateway 源码可以发现，默认的 RouteDefinitionWriter 实现类是 InMemoryRouteDefinitionRepository。而 RouteDefinitionRepository 继承了 RouteDefinitionWriter，是 Spring Cloud Gateway 官方预留的接口，因此可以通过下面两种方式来实现集群下的动态路由控制：RouteDefinitionWriter 接口和 RouteDefinitionRepository 接口。在这里推荐实现 RouteDefinitionRepository 这个接口，从数据库或者从配置中心获取路由进行动态配置；具体可以参考上面单机版的动态路由实现，在这里不再累述。 参考资料 Spring Cloud Gateway（Greenwich.SR1） 整合 Swagger2 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"日常网站收藏","url":"/posts/16fab331.html","text":"博客 云风的 BLOG 美团官方博客 电影资源 人人电影网 人人电影网（备用） PDF 资源 aibooks Java 菜市场 GitHub PDF 电子书整理 Docker 加速 Docker 的安装包以及周边高速镜像 在线常用开发工具 Tools Fun Json 在线工具 Cron 在线工具 GitHub 开源文档与书籍 书栈网 网站测速、网站优化工具 站长工具 - 网速测试 GTmetrix - 网站速度诊断 Webkaka - 网站速度测试 Webkaka - 网站速度诊断 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"生活随笔"},{"title":"Gateway 入门教程 - 基础篇","url":"/posts/ec48bc77.html","text":"Reactor 与 WebFlux 介绍Reactor 是什么为了应对高并发的服务器端开发，在 2009 年 的时候，微软提出了一个更优雅地实现异步编程的方式 - Reactive Programming，中文名是响应式编程或者叫反应式编程。随后，其它技术也迅速地跟上了脚步，像 ES6 通过 Promise 引入了类似的异步编程方式。Netflix 和 TypeSafe 公司也提供了 RxJava、Scala、Akka 技术，让 Java 平台也有了能够实现响应式编程的框架，现在比较熟知的 Hystrix 就是以 RxJava 为基础开发的。到了 2017 年，虽然已经有不少公司在实践响应式编程，但整体来说应用范围依旧不大，主要原因在于缺少简单易用的技术将响应式编程推广普及，诸如 MVC 框架、HTTP 客户端、数据库技术等整合。终于，在 2017 年 9 月 28 日，Spring 5 正式发布，而 Spring 5 其最大的意义就是将响应式编程技术的普及向前推进一大步。在背后支持 Spring 5 响应式编程的框架正是 Reactor，它是由 Pivotal 公司（开发 Spring 等技术的公司）开发的，实现了 Reactive Programming 思想，符合 Reactive Streams 规范（Reactive Streams 是由 Netflix、TypeSafe、Pivotal 等公司发起的）的一项技术。Reactive 与 Servlet 的技术栈对比图如下： WebFlux 是什么Spring WebFlux 是 Spring 5.0 引入的新的响应式框架，区别于 Spring MVC，它不需要依赖 Servlet API，采用异步非阻塞的架构，底层基于 Reactor 来实现响应式流规范。因此，Spring WebFlux 特别适合应用在 I/O 密集型的服务中，比如微服务网关这样的应用中。在传统的 Web 架构中，比如 Struts2、Spring MVC 等都是基于 Servlet API 与 Servlet 容器基础之上运行的，使用的是同步阻塞式 I/O 模型。但是在 Servlet 3.1 之后有了异步非阻塞的支持，而 Spring WebFlux 采用的就是典型的异步非阻塞架构，它的核心是基于 Reactor 的相关 API 实现。相对于传统的 Web 架构来说，Spring WebFlux 可以运行在诸如 Netty 及支持 Servlet 3.1+ 的容器（Tomcat、Jetty、Undertow）之上，支持异步非阻塞式 I/O 模型 + 函数式编程（依赖 JDK 8）。根据官方的说明，Spring WebFlux 并不能使接口的响应时间缩短，它仅仅能够提升吞吐量和伸缩性。Spring WebFlux 与 传统 Web 架构的对比图如下： 首先需要明确的一点就是，Spring WebFlux 不是 Spring MVC 的替代方案！虽然 Spring WebFlux 也可以运行在 Servlet 容器之上（Servlet 3.1+），但是 Spring WebFlux 主要还是应用在适合使用异步非阻塞模型的业务场景。而 Spring MVC 是同步阻塞的，如果项目在 Spring MVC 框架中大量使用了非同步方案，那么 Spring WebFlux 才是适用，否则使用 Spring MVC 才是首选。在微服务架构中，Spring MVC 和 Spring WebFlux 可以混合使用（不是指在同一个应用内），比如上面已经提到的，对于那些 I/O 密集型服务（如网关）就可以使用 Spring WebFlux 来实现。Spring MVC 和 Spring WebFlux 的对比图如下： Spring WebFlux 默认情况下使用 Netty 作为服务器 Spring WebFlux 暂时不支持 MySQL，支持 Redis、MongoDB、PostgreSQL Spring WebFlux 使用的响应式流并不是用 JDK 9 提供的，而是基于 Reactor 响应式流库 Spring WebFlux 也可以使用 Spring MVC 注解，如 @Controller，方便在两个 Web 框架中自由转换 Spring WebFlux 与 Spring MVC 都可以使用 Tomcat、Jetty、Undertow 等 Servlet 容器（Servlet 3.1+） Spring MVC 因为是使用的同步阻塞式 I/O 模型，更方便开发人员开发和测试代码；一般来说，如果 Spring MVC 能够满足的场景，就尽量不要用 Spring WebFlux Spring Cloud Gateway 介绍Spring Cloud Gateway 是什么Spring Cloud Gateway 是 Spring 官方基于 Spring 5.x、Spring Boot 2.x、Spring WebFlux 和 Reactor 等技术开发的网关，旨在为微服务架构提供简单、有效且统一的 API 路由管理方式。Spring Cloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Netflix Zuul 1.x。在 Spring Boot 2.0 以上版本中，并没有对 Zuul 2.0 以上最新高性能版本进行集成，仍然使用 Zuul 1.x 非 Reactor 模式（基于 Servlet 2.5 阻塞架构）的旧版本。Spring Cloud Gateway 其不仅提供统一的路由方式，并且还基于 Filter 链的方式提供了网关基本的功能，例如：熔断、重试、安全、监控 / 指标、限流等，更多资料可参考：Gateway 官方英文文档。 Spring Cloud Gateway 的核心概念网关提供 API 全托管服务，丰富的 API 管理功能，辅助企业管理大规模的 API，以降低管理成本和安全风险，包括协议适配、协议转发、安全策略（WAF）、防刷、流量、监控日志等功能。一般来说，网关对外暴露的 URL 或者接口信息，统称为路由信息。如果研发过网关中间件，或者使用或了解过 Zuul 的开发者，会知道网关的核心肯定是 Filter 以及 Filter Chain（Filter 责任链）。Spring Cloud Gateway 也具有路由和 Filter 的概念，其中最重要的几个概念如下： 路由（route）：路由是网关最基础的部分，路由信息由一个 ID、一个目的 URL、一组断言工厂和一组 Filter 组成；如果路由断言为真，则说明请求的 URL 和配置的路由匹配。 断言（predicate）：Java 8 中的断言函数，Spring Cloud Gateway 中的断言函数输入类型是 Spring 5.0 框架中的 ServerWebExchange。在 Spring Cloud Gateway 中的断言函数允许开发者去定义匹配来自于 Http Request 中的任何信息，比如请求头和参数等。 过滤器（filter）：一个标准的 Spring Web Filter，在 Spring Cloud Gateway 中的 Filter 分为两种类型，分别是 Gateway Filter 和 Global Filter，过滤器 Filter 将会对请求和响应进行修改处理。 Spring Cloud Gateway 的核心原理Spring Cloud Gateway 的核心处理流程如下图所示，Gateway 的客户端会向 Spring Cloud Gateway 发起请求，请求首先会被 HttpWebHandlerAdapter 进行提取组装成网关的上下文，然后网关的上下文会传递给 DispatcherHandler。这里的 DispatcherHandler 是所有请求的分发处理器，DispatcherHandler 主要负责分发请求到对应的处理器，比如将请求分发到对应 RoutePredicateHandlerMapping（路由断言处理映射器）。路由断言处理映射器主要用于路由的查找，以及找到路由后返回对应的 FilteringWebHandler。FilteringWebHandler 主要负责组装 Filter 链表并调用 Filter 执行一系列的 Filter 处理，然后把请求转到后端对应的代理服务处理，处理完毕之后，将 Response 返回到 Gateway 客户端。在 Filter 链中，通过虚线分割 Filter 的原因是，过滤器可以在转发请求之前处理或者接收到被代理服务的返回结果之后处理。所有的 Pre 类型的 Filter 执行完毕之后，才会转发请求到被代理的服务处理。被代理的服务把所有请求处理完毕之后，才会执行 Post 类型的过滤器。值得一提的是，在配置路由的时候，如果不指定端口的话，HTTP 默认设置端口为 80，HTTPS 默认设置端口为 443，Spring Cloud Gateway 的启动容器目前只支持 Netty。 Spring Cloud Gateway 入门案例1. 版本说明在本文中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外，点击下载完整的案例代码。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下。特别注意，Spring Cloud Gateway 是基于 WebFlux 的，它与 Spring MVC 是不兼容的，如果引用了 spring-boot-starter-web，则需要把 spring-webmvc 排除掉；由于 Spring Cloud Gateway 的启动容器目前只支持 Netty，因此还需要将 spring-boot-starter-tomcat 排除掉。这里也可以引入 spring-boot-starter-webflux 来替代 Spring MVC 的功能，关于 Gateway 的使用，原则上只需要引入 spring-cloud-starter-gateway 即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 3. 创建 Gateway 工程 创建 Gateway 的 Maven 工程，配置工程里的 pom.xml 文件 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway 的配置类，使用 Java 流式 API 自定义 RouteLocator 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 当访问到 http://127.0.0.1:9090/jd 直接跳转到京东商城的首页 return builder.routes() .route(r -&gt; r.path(\"/jd\") .uri(\"http://jd.com:80/\").id(\"jd_route\") ).build(); }} 创建 Gateway 的主控制类 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 Gateway 的 application.yml 配置文件，添加开启端点的配置信息，Spring Cloud Gateway 提供了一个 Gateway Actuator，该 EndPiont 提供了关于 Filter 及 Routes 的信息查询以及指定 Route 信息更新的 Rest API 接口 123456789101112131415161718192021server: port: 9090spring: application: name: gateway-serverlogging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: '*' security: enabled: false 4. 创建 Gateway YML 工程Spring Cloud Gateway 支持两种方式去配置路由信息，上述代码通过 Java 流式 API 自定义 RouteLocator 的方式定义 Spring Cloud Gateway 的路由信息，也可以通过如下 YML 文件的方式配置路由。 创建 Gateway 的 Maven 工程，配置工程里的 pom.xml 文件 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Gateway 的主控制类 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 创建 Gateway 的 application.yml 配置文件 12345678910111213141516171819202122232425262728server: port: 9091spring: application: name: gateway-server cloud: gateway: routes: #当访问到 http://127.0.0.1:9090/baidu 直接跳转到百度的首页 - id: baidu_route uri: http://baidu.com:80/ predicates: - Path=/baidulogging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement: endpoints: web: exposure: include: '*' security: enabled: false 5. 测试结果 分别启动 gateway、gateway-yml 应用 访问 http://127.0.0.1:9090/actuator/gateway/routes，查看返回的所有路由信息，如下图所示： 访问 http://127.0.0.1:9090/jd，查看是否成功跳转到京东商城的首页 访问 http://127.0.0.1:9091/baidu，查看是否成功跳转到百度的首页 Spring Cloud Gateway 的路由断言Spring Cloud Gateway 的路由匹配的功能是以 Spring WebFlux 中的 Handler Mapping 为基础实现的。Spring Cloud Gateway 也是由许多的路由断言工厂组成的，当 Http Request 请求进入 Spring Cloud Gateway 的时候，网关中的路由断言工厂会根据配置的路由规则，对 Http Request 请求进行断言匹配；匹配成功则进行下一步处理，否则断言失败直接返回错误信息。值得一提的是，Spring Cloud Gateway 大多数的路由断言工厂是支持正则表达式匹配的。下面将给出各种路由断言工厂的使用示例，点击下载完整的案例代码。 After 路由断言工厂After 路由断言工厂中会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之后，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 After 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 生成比当前时间早一个小时的UTC时间 ZonedDateTime minusTime = LocalDateTime.now().minusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( \"after_route\", r -&gt; r.after(minusTime).uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 After 路由断言信息：其中的 UTC 时间可以使用 Java 代码生成，例如 ZonedDateTime.now().minusHours(1).format(DateTimeFormatter.ISO_ ZONED_DATE_TIME); 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: after_route uri: http://baidu.com predicates: - After=2019-10-01T21:55:18.146+08:00[Asia/Shanghai] 测试结果： 启动应用，访问 http://127.0.0.1，查看是否成功跳转到百度的首页 更改 UTC 时间为当前时间一个小时后的 UTC 时间，然后再启动应用，访问 http://127.0.0.1，页面会返回 404 错误信息 Before 路由断言工厂Before 路由断言工厂会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之前，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 Before 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { // 生成比当前时间晚一个小时的UTC时间 ZonedDateTime plusTime = LocalDateTime.now().plusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( \"before_route\", r -&gt; r.before(plusTime).uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 Before 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: before_route uri: http://baidu.com predicates: - Before=2019-10-01T21:55:18.146+08:00[Asia/Shanghai] Between 路由断言工厂Between 路由断言工厂会取一个 UTC 时间格式的时间参数，当请求进来的当前时间在配置的 UTC 时间之间，则会成功匹配，否则不能成功匹配。 通过 Java 代码的方式，将 Between 路由断言的配置信息配置到路由里去： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { ZonedDateTime minusTime = LocalDateTime.now().minusHours(1).atZone(ZoneId.systemDefault()); ZonedDateTime plusTime = LocalDateTime.now().plusHours(1).atZone(ZoneId.systemDefault()); return builder.routes() .route( \"between_route\", r -&gt; r.between(minusTime, plusTime).uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 Between 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: between_route uri: http://baidu.com predicates: - Between=2019-11-10T11:11:11.111 08:00[Asia/Shanghai], 2019-11-12T11:11:11.111 08:00[Asia/Shanghai] Cookie 路由断言工厂Cookie 路由断言工厂会取两个参数，分别是 cookie 名称对应的 key 和 value。当请求中携带的 cookie 和 Cookie 断言工厂中配置的 cookie 一致，则路由匹配成功，否则匹配不成功。 通过 Java 代码的方式，将 Cookie 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( \"cookie_route\", r -&gt; r.cookie(\"book\", \"java\").uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 Cookie 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: cookie_route uri: http://baidu.com predicates: - Cookie=book, java 测试结果 启动 gateway-cookie 应用 在 Postman 中将 book=java 添加到 Cookie，然后访问 http://127.0.0.1，查看是否成功跳转到百度的首页 Header 路由断言工厂Header 路由断言工厂用于根据配置的路由 header 信息进行断言匹配路由，匹配成功进行转发，否则不进行转发。 通过 Java 代码的方式，将 Header 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( \"header_route\", r -&gt; r.header(\"X-Request-Id\", \"Peter\").uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 Header 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: header_route uri: http://baidu.com predicates: - Header=X-Request-Id, Peter 测试结果 启动 gateway-header 应用 在 Postman 中将 X-Request-Id=Peter 添加到 Header，然后访问 http://127.0.0.1，查看是否成功跳转到百度的首页 Host 路由断言工厂Host 路由断言工厂根据配置的 Host，对请求中的 Host 进行断言处理，断言成功则进行路由转发，否则不转发。 通过 Java 代码的方式，将 Host 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( \"host_route\", r -&gt; r.host(\"**.study.com\").uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 Host 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: host_route uri: http://baidu.com predicates: - Host=**.study.com 测试结果 编辑系统的 hosts 配置文件，添加域名映射：127.0.0.1 www.study.com 启动 gateway-host 应用 访问 http://www.study.com，查看是否成功跳转到百度的首页 Method 路由断言工厂Method 路由断言工厂会根据路由信息配置的 method 对请求方法是 Get 或者 Post 等进行断言匹配，匹配成功则进行转发，否则处理失败。 通过 Java 代码的方式，将 Method 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( \"method_route\", r -&gt; r.method(\"GET\").uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 Method 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: method_route uri: http://baidu.com predicates: - Method=GET Query 路由断言工厂Query 路由断言工厂会从请求中获取两个参数，将请求中参数和 Query 断言路由中的配置进行匹配，比如 http://127.0.0.1?book=java 中的 book=java 和下面的 r.query(\"book\",\"java\") 配置一致，则转发成功，否则转发失败。 通过 Java 代码的方式，将 Query 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( \"query_route\", r -&gt; r.query(\"book\", \"java\").uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 Query 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: query_route uri: http://baidu.com predicates: - Query=book, java Path 路由断言工厂Path 路由断言工厂接收一个参数，根据 Path 定义好的规则来判断访问的 URI 是否匹配。在下述配置中，如果请求路径为 /blog/detail/，则此路由将匹配；也可以使用表达式，例如 /blog/detail/** 表示匹配 /blog/detail/ 开头的多级 URI。特别注意，下述的 URI 如果不以 / 结尾，那么转发后的 URI 为 http://baidu.com/blog/detail/；若以 / 结尾，转发后的 URI 则为 http://baidu.com/。 通过 Java 代码的方式，将 Path 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( \"path_route\", r -&gt; r.path(\"/blog/detail/\").uri(\"http://baidu.com/\") ) .build(); }} 也可以在 application.yml 文件里配置 Path 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: path_route uri: http://baidu.com/ predicates: - Path=/blog/detail/ Weight 路由断言工厂Weight 路由断言工厂，在 Spring Cloud Gateway 中可以使用它对 URL 进行权重路由，只需在配置时指定分组和权重值即可。下述配置中，添加了两个针对 /test 路径转发的路由定义配置，这两个路由属于同一个权重分组，权重的分组名称为 group。最终的效果是把 /test 接口的 95% 的请求流量分发给服务的 V1 版本，把剩余 5% 的流量分发给服务的 V2 版本，具体的实战案例可参考这里的教程。 12345678910111213141516spring: application: name: gateway-server cloud: gateway: routes: - id: provider-service-v1 uri: http://127.0.0.1:9091/v1/ predicates: - Path=/test - Weight=group, 95 - id: provider-service-v2 uri: http://127.0.0.1:9091/v2/ predicates: - Path=/test - Weight=group, 5 RemoteAddr 路由断言工厂RemoteAddr 路由断言工厂配置一个 IPv4 或 IPv6 网段的字符串或者 IP。当客户端的 IP 地址在网段之内或者和配置的 IP 相同，则成功转发，否则不能转发。例如 192.168.0.1/16 表示一个网段，其中 192.168.0.1 是 IP 地址，16 是子网掩码，当然也可以直接配置一个 IP。 通过 Java 代码的方式，将 RemoteAddr 路由断言的配置信息配置到路由里去： 123456789101112@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route( \"remoteaddr_route\", r -&gt; r.remoteAddr(\"127.0.0.1\").uri(\"http://baidu.com\") ) .build(); }} 也可以在 application.yml 文件里配置 RemoteAddr 路由断言信息： 12345678910spring: application: name: gateway-server cloud: gateway: routes: - id: remoteaddr_route uri: http://baidu.com predicates: - RemoteAddr=127.0.0.1 Spring Cloud Gateway 的内置 FilterSpring Cloud Gateway 中内置很多的路由过滤工厂，当然也可以根据实际应用场景的需要定制自己的路由过滤器工厂。路由过滤器允许以某种方式修改进来的 HTTP 请求或返回的 HTTP 响应。路由过滤器主要作用于需要处理的特定路由，Spring Cloud Gateway 提供了很多种的过滤器工厂，过滤器的实现类将近二十多个。总得来说，可以分为七类：Header、Parameter、Path、Status、Redirect 跳转、Hytrix 熔断和 RateLimiter 限流。下面将介绍 Spring Cloud Gateway 中常用的 Filter 工厂，点击下载完整的案例代码。 AddRequestHeader 过滤器AddRequestHeader 过滤器工厂用于对匹配上的请求加上 Header： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\"add_request_header_route\", r -&gt; r.path(\"/addRequestHeader\") .filters(f -&gt; f.addRequestHeader(\"X-Request-Id\", \"Peter\")) .uri(\"http://127.0.0.1:8080/addRequestHeader/\") ).build(); }} AddRequestParameter 过滤器AddRequestParameter 过滤器作用是对匹配上的请求添加请求参数： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\"add_request_parameter_route\", r -&gt; r.path(\"/addRequestParameter\") .filters(f -&gt; f.addRequestParameter(\"book\", \"java\")) .uri(\"http://127.0.0.1:8080/addRequestParameter/\") ).build(); }} RewritePath 过滤器Spring Cloud Gateway 可以使用 RewritePath 替换 Zuul 的 StripPrefix 功能，而且功能更强大。在 Zuul 中使用如下配置后，所有 /example/xxxx 的请求会转发给 http://example.com/xxxx，同时去除掉了 example 前缀。 123456zuul: routes: example: path: /example/** stripPrefix: true uri: http://example.com Spring Cloud Gateway 实现了类似的功能，使用的是 RewritePath 过滤器工厂。特别注意，下述的 URI 是不以 / 结尾的，否则仅仅会直接跳转到 http://baidu.com。 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\"rewrite_path_route\", r -&gt; r.path(\"/foo/**\") .filters(f -&gt; f.rewritePath(\"/foo/(?&lt;segment&gt;.*)\", \"/$\\\\{segment}\")) .uri(\"http://www.baidu.com\") ).build(); }} 启动对应的应用后，访问 http://127.0.0.1:9092/foo/cache/sethelp/help.html，路由会转发到 http://www.baidu.com/cache/sethelp/help.html，这里相当于把 foo 前缀去掉。 AddResponseHeader 过滤器AddResponseHeader 过滤器工厂的作用是对从网关返回的响应添加 Header： 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\"add_response_header_route\", r -&gt; r.path(\"/addResponseHeader\") .filters(f -&gt; f.addResponseHeader(\"X-Request-Id\", \"Peter\")) .uri(\"http://www.baidu.com/\") ).build(); }} StripPrefix 过滤器StripPrefixGatewayFilterFactory 是一个对针对请求 URL 前缀进行处理的 Filter 工厂，用于去除前缀，而 PrefixPathGatewayFilterFactory 是用于增加前缀。下述的配置，访问 http://127.0.0.1:9093/baidu/test，会跳转到 https://www.baidu.com，即去除了前缀 /baidu/test/。 123456789101112spring: application: name: gateway-server cloud: gateway: routes: - id: baidu_route uri: http://www.baidu.com predicates: - Path=/baidu/test/** filters: - StripPrefix=2 Retry 过滤器网关作为所有请求流量的入口，网关对路由进行协议适配和协议转发处理的过程中，如果出现异常或网络抖动，为了保证后端服务请求的高可用，一般处理方式会对网络请求进行重试，接口必须需要做幂等处理。config.setRetries(2).setStatuses(HttpStatus.INTERNAL_SERVER_ERROR) 表示设置重试次数为两次，当服务调用失败时设置返回的状态码为 500，即服务器内部错误。 12345678910111213@Configurationpublic class CommonConfiguration { @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\"retry_route\", r -&gt; r.path(\"/test/retry\") .filters(f -&gt; f.retry(config -&gt; config.setRetries(2) .setStatuses(HttpStatus.INTERNAL_SERVER_ERROR))) .uri(\"http://127.0.0.1:8080/retry?key=abc&amp;count=2\")) .build(); }} Hystrix 过滤器Hystrix 可以提供熔断、服务降级和快速失败等功能。Spring Cloud Gateway 对 Hystrix 进行集成提供路由层面的服务熔断和降级，最简单的使用场景是当通过 Spring Cloud Gateway 调用后端服务，后端服务一直出现异常、服务不可用的状态。此时为了提高用户体验，就需要对服务降级，返回友好的提示信息给服务消费者，在保护网关自身可用的同时保护后端服务高可用。下面将给出配置示例，由于篇幅有限，只列出核心的配置内容和代码。 工程里的 pom.xml 配置文件，引入 spring-cloud-starter-gateway、spring-cloud-starter-netflix-hystrix 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 工程里的启动主类 1234567@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 工程里的 Fallback 控制器 12345678@RestControllerpublic class FallbackController { @GetMapping(\"/fallback\") public String fallback() { return \"Spring Cloud Gateway Fallback！\"; }} 工程里的 application.xml 配置文件，添加 Hystrix 过滤器相关的配置，并设置 Hystrix 的 fallbackcmd 的超时时间 1234567891011121314151617181920212223spring: application: name: gateway-server cloud: gateway: routes: - id: hystrix_route predicates: - Path=/test/hystrix filters: - name: Hystrix # Hystrix Filter 的名称 args: # Hystrix 配置参数 name: fallbackcmd # HystrixCommand 的名字 fallbackUri: forward:/fallback # fallback 对应的 uri uri: http://127.0.0.1:8080/hystrix?isSleep=falsehystrix: command: fallbackcmd: execution: isolation: thread: timeoutInMilliseconds: 5000 # Hystrix 的 fallbackcmd 的超时时间 下篇 - Gateway 入门教程（中级篇） Gateway 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Consul 入门教程 - 基础篇","url":"/posts/29fe9682.html","text":"Consul 介绍Consul 是什么作为集群系统的灵魂，服务治理框架一直都受架构师的青睐。随着微服务思想的普及，越来越多的服务治理框架如雨后春笋般冒了出来。除了 Eureka，HashiCorp 公司的 Consul 也让诸多架构师青睐有加。Consul 是一个分布式高可用的服务网格（service mesh）解决方案，提供包括服务发现、配置和分段功能在内的全功能控制平面。这些功能中的每一个都可以根据需要单独使用，也可以一起使用以构建完整的服务网格。简单来说，Consul 是一个分布式高可用的系统服务发现与配置工具，它跟 Eureka 的核心功能一样，但略有不同： Consul 使用 Go 语言编写，以 HTTP 方式对外提供服务 Consul 支持多数据中心，这是它的一大特色 Consul 提供了可视化的 Web 界面 Consul 的一致性协议是 CP（Raft） Consul 除了服务发现之外，还有一些别的功能，例如配置功能 Consul 的主要功能Consul 提供了以服务治理为核心的多种功能以满足分布式系统的需要，它可以作为服务治理组件和配置中心。当然，市场上还有很多其他类似功能的优秀框架，Consul 官方提供了对比信息，以便架构师们在做技术选型时可以尽快找到更适合自己的方案。Consul 的主要功能如下，更多介绍可参考：Consul 官网、Consul 项目、Consul 中文教程。 服务发现：有了 Consul，服务可以通过 DNS 或者 HTTP 直接找到它所依赖的服务 健康检查：Consul 提供了健康检查的机制，从简单的服务端是否返回 200 的响应代码到较为复杂的内存使用率是否低于 90% K/V 存储：应用程序可以根据需要使用 Consul 的 Key/Value 存储，Consul 提供了简单易用的 HTTP 接口来满足用户的动态配置、特征标记、协调、Leader 选举等需求 多数据中心：Consul 原生支持多数据中心，这意味着用户不用为了多数据中心自己做抽象 Consul 安装Consul 的安装比较简单，官方提供了二进制可执行文件，可以在官网下载自己感兴趣的版本，安装步骤如下： 将已下载的 consul_l.2.0_linux_amd64.zip 解压到 /opt/consul/ 目录下 添加 consul 到 PATH（环境变量） 执行 consul -v，如果不报错，基本就算安装成功了 Consul 启动Consul 集群默认需要至少三台 Consul 启动，当有多个 Consul 节点启动了，那么它们会自动组成集群。如果只是想本地开发调试，可以使用开发者模式启动，数据默认保存在内存中。 12# 使用开发模式，启动consul$ consul agent -dev Consul 默认是没有 UI 界面的，如果需要展示 UI 界面，可以加上 -ui 参数进行启动，然后通过 http://127.0.0.1:8500 访问 UI 界面： 1$ consul agent -dev -ui Consul 实用接口Consul 对外提供了丰富的 API，有运维人员喜欢的命令行接口，也有开发人员喜欢的 HTTP 接口，常用的接口如下： Consul 管理命令 consul members：查看当前 Consul 集群里所有成员的信息以及它们的状态：存活、离线、启动失败 consul monitor：持续打印当前 Consul 的日志信息，这个命令很有用，因为 Consul 访问量比较大，所以生产环境一般不会保存日志，如果想查看实时日志，可以使用该命令 consul leave：退出集群，一般会使用这个命令而不是直接杀掉 Consul 的进程 Consul 对外服务接口 /v1/agent/members：列出集群内的所有成员及其信息 /v1/status/leader：显示当前集群 leader /v1/catalog/services：显示当前注册的服务 /v1/kv/key：显示当前 Key 对应的 Value Spring Cloud Consul 基础Spring Cloud Consul 介绍Spring Cloud Consul 通过自动配置、对 Spring Environment 绑定和其他惯用的 Spring 模块，为 Spring Boot 应用程序提供了 Consul 集成。只需要一些简单注解，就可以快速启用和配置 Consul，并用它来构建大型分布式系统。Spring Cloud Consul 作为 Spring Cloud 与 Consul 之间的桥梁，对二者都有良好的支持，其特性如下： 服务注册发现，实例可以向 Consul 注册服务，客户端可以使用 Spring Bean 来发现服务提供方 支持 Ribbon 的客户端负载 支持 Zuul 服务网关 分布式配置中心，使用的是 Consul 的 K/V 存储 控制总线，使用的是 Consul Events Spring Cloud Consul 入门案例Spring Cloud Consul 提供了 bus、config、discovery 等模块，项目中可以根据具体的需要选择对应的模块。下面将演示如何使用 config、discovery 模块，点击下载完整的案例代码。 1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Consul Provider 工程创建 Consul Provider 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-discovery，将服务实例注册到 Consul： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Provider 的主启动类，这里可以缺省添加 @EnableDiscoveryClient 注解： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 创建 Consul Provider 的测试控制类，值得注意的是，在不引入 spring-boot-starter-actuator 依赖的情况下，必须手动创建 /actuator/health 接口，这是新版 Spring Cloud Consul 的默认注册健康检查接口，否则 Consul 会认为服务不可用： 12345678910111213141516@RestControllerpublic class ProviderController { @Value(\"${server.port}\") private String port; @GetMapping(\"/actuator/health\") public String health() { return \"SUCCESS\"; } @GetMapping(\"/provider/sayHello\") public String sayHello(String name) { return \"from port \" + port + \": hello \" + name; }} 添加 Consul Provider 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 4. 创建 Consul Consumer 工程创建 Consul Consumer 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-discovery，将服务实例注册到 Consul，同时引入 Feign： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Consumer 的主启动类，这里可以缺省添加 @EnableDiscoveryClient 注解： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); }} 创建 Consul Consumer 的服务接口类，用于调用 Provider 服务： 123456@FeignClient(value = \"consul-provider\")public interface HelloService { @RequestMapping(value = \"/provider/sayHello\", method = RequestMethod.GET) public String sayHello(@RequestParam(\"name\") String name);} 创建 Consul Consumer 的测试控制类，在不引入 spring-boot-starter-actuator 依赖的情况下，必须手动创建 /actuator/health 接口，这是新版 Spring Cloud Consul 的默认注册健康检查接口，否则 Consul 会认为服务不可用： 12345678910111213141516@RestControllerpublic class ConsumerController { @Autowired private HelloService helloService; @GetMapping(\"/actuator/health\") public String health() { return \"SUCCESS\"; } @GetMapping(\"/consumer/sayHello\") public String sayHello(String name) { return helloService.sayHello(name); }} 添加 Consul Consumer 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9002spring: application: name: consul-consumer cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 5. 创建 Consul Config 工程创建 Consul Config 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-consul-config；这里的 Consul Config 工程与上面的 Provider、Consumer 工程没有任何关系，作用是用来单独演示 Consul 的 Config 功能（配置中心）： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Config 的测试控制类： 12345678910111213@RefreshScope@RestController@RequestMapping(\"/config\")public class ConfigController { @Value(\"${foo.bar.name}\") private String name; @GetMapping(\"/getName\") public String getName() { return name; }} 添加 Consul Config 需要的 application.yml 配置文件到工程中： 12345678910server: port: 9003spring: application: name: consul-config cloud: consul: host: 127.0.0.1 # consul 地址 port: 8500 # consul 端口 6. 测试结果 启动本地的 consul 服务器 依次启动 consul-provider、consul-consumer 应用 访问 consul 的管理界面：http://127.0.0.1:8500，如果各个服务的 Health Checks 显示绿色的对勾，即表示服务注册成功，如下图所示： 访问 http://127.0.0.1:9002/consumer/sayHello?name=Peter，如果返回 from port 9001: hello Peter，说明 consul-provider、consul-consumer 应用一切运行成功 访问 http://127.0.0.1:8500/ui/dc1/kv，点击页面上的 create 按钮，在 Key or folder 栏输入 config/consul-config/foo.bar.name，value 栏输入 book，然后点击 save 按钮保存，如下图所示： 启动 consul-config 应用，访问 http://127.0.0.1:9003/config/getName，如果接口返回 book，说明成功访问到 Consul Config 的 Key/Value 存储 Spring Cloud Consul 深入Spring Cloud Consul 模块介绍Spring Cloud Consul 是在 ecwid 的 consul-api 的基础上又封装了一层功能，使其跟现有 Spring Cloud 组件融合，达到开箱即用的目的。围绕着 Consul 的核心功能，Spring Cloud Consul 也提供了相应的功能模块与之匹配，其中 Consul 的事件功能比较弱化，应用比较多的是服务治理和配置功能，各个模块的介绍如下： spring-cloud-consul-binder：对 Consul 的事件功能封装 spring-cloud-consul-config：对 Consul 的配置功能封装 spring-cloud-consul-core：基础配置和健康检查模块 spring-cloud-consul-discovery：对 Consul 服务治理功能封装 Spring Cloud Consul Discovery基础配置服务启动时，会通过 ConsulServiceRegistry.register（） 向 Consul 注册自身的服务。服务注册时，会告诉 Consul 以下信息： ID：服务 ID，默认是服务名 + 端口号 Name：服务名，默认是应用名称 Tags：给服务打的标签，默认是 [secure=false] Address：服务地址，默认是本机 IP Port：服务端口，默认是服务的 Web 端口 Check：健康检查信息，包括 Interval（健康检查间隔）和 HTTP（健康检查地址） 一般情况下，不需要显式提供上述信息，Spring Cloud Consul 会有默认值，但是在一些特殊业务场景中，可能就需要定制上述服务了。Consul Discovery 的常见配置如下： Tags 栏会有一个 secure=false，这个是 Spring Cloud Consul 默认加上的，它取自配置 spring.cloud.consul.discovery.scheme，默认值是 http。如果服务提供的是 https 的服务时，需要配置该值为 https，它的作用是告诉服务消费者调用服务方接口时需要哪种协议。配置示例如下： 1234567891011/** * 自定义健康检测接口 */@RestControllerpublic class ProviderController { @GetMapping(\"/health\") public String health() { return \"SUCCESS\"; }} 1234567891011121314151617server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: prefer-ip-address: true # 优先使用 IP 注册 ip-address: 127.0.0.1 # 若部署在 Docker 中,指定宿主机 IP port: 9001 # 若部署在 Docker 中,指定宿主机端口 health-check-interval: 20s # 健康检查间隔时间为 20s health-check-path: /health # 自定义健康检查路径 tags: ${LANG},test # 指定服务的标签, 用逗号隔开 服务发现案例Spring Cloud Consul 提供了两种方式的服务发现功能：Ribbon 和 DiscoveryClient。如果客户端使用了 Feign 或者 @LoadBalancerd 注解，那么默认使用的是 ConsulServerList 提供的服务发现逻辑。如果客户端只想独立使用服务发现功能，那么可以直接使用 DiscoveryClient。上面提到了使用 Consul 的 Tags 功能将服务分组，下面就用上面说的两种方式分别调用服务提供者的接口，点击下载完整的案例代码，由于篇幅有限，以下只给出核心代码和配置。 1. 创建 Consul Provider Tag One 工程创建 Consul Provider Tag One 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderOneApplication { public static void main(String[] args) { SpringApplication.run(ProviderOneApplication.class, args); }} 创建 Consul Provider Tag One 的测试控制类： 123456789101112131415public class ProviderOneController { @Value(\"${server.port}\") private String port; @GetMapping(\"/actuator/health\") public String health() { return \"SUCCESS\"; } @GetMapping(\"/provider/sayHello/{name}\") public String sayHello(@PathVariable(\"name\") String name) { return \"from port \" + port + \": hello \" + name; }} 创建 Consul Provider Tag One 的 application.yml 配置文件，加入 tags 属性： 123456789101112server: port: 9001spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: tags: tag1 2. 创建 Consul Provider Tag Two 工程创建 Consul Provider Tag Two 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class ProviderTwoApplication { public static void main(String[] args) { SpringApplication.run(ProviderTwoApplication.class, args); }} 创建 Consul Provider Tag Two 的测试控制类： 12345678910111213141516@RestControllerpublic class ProviderTwoController { @Value(\"${server.port}\") private String port; @GetMapping(\"/actuator/health\") public String health() { return \"SUCCESS\"; } @GetMapping(\"/provider/sayHello/{name}\") public String sayHello(@PathVariable(\"name\") String name) { return \"from port \" + port + \": hello \" + name; }} 创建 Consul Provider Tag Two 的 application.yml 配置文件，加入 tags 属性： 123456789101112server: port: 9002spring: application: name: consul-provider cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: tags: tag2 3. 创建 Consul Consumer Ribbon 工程创建 Consul Consumer Ribbon 的主启动类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerRibbonApplication { public static void main(String[] args) { SpringApplication.run(ConsumerRibbonApplication.class, args); }} 创建 Consul Consumer Ribbon 的服务接口类，用于调用 Provider 服务： 123456@FeignClient(\"consul-provider\")public interface ProviderService { @RequestMapping(value = \"/provider/sayHello/{name}\", method = RequestMethod.GET) public String sayHello(@PathVariable(\"name\") String name);} 创建 Consul Consumer Ribbon 的基础配置类，声明 RestTemplate 的 Bean 对象： 123456789@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); }} 创建 Consul Consumer Ribbon 的测试控制类，建立两个 REST 接口，一个通过 Feign 的方式访问 Provider，另一个通过 RestTemplate 的方式访问 Provider： 1234567891011121314151617181920212223242526@RestControllerpublic class ConsumerRibbonController { private static final String URL = \"http://consul-provider\"; @Autowired private RestTemplate restTemplate; @Autowired private ProviderService providerService; @GetMapping(\"/actuator/health\") public String health() { return \"SUCCESS\"; } @GetMapping(\"/consumer/sayHelloOne/{name}\") public String sayHelloOne(@PathVariable(\"name\") String name) { return providerService.sayHello(name); } @GetMapping(\"/consumer/sayHelloTwo/{name}\") public String sayHelloTwo(@PathVariable(\"name\") String name) { return restTemplate.getForObject(URL + \"/provider/sayHello/\" + name, String.class); }} 创建 Consul Consumer Ribbon 的 application.yml 配置文件： 12345678910111213server: port: 9003spring: application: name: consul-consumer-ribbon cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: server-list-query-tags: consul-provider: tag1 # 在调用 consul-provider 服务时，使用 tag1 对应的服务实例 4. 创建 Consul Consumer Discovery Client 工程创建 Consul Consumer Discovery Client 的主启动类： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class DiscoveryClientApplication { public static void main(String[] args) { SpringApplication.run(DiscoveryClientApplication.class, args); }} 创建 Consul Consumer Discovery Client 的测试控制类，使用 DiscoveryClient 注入的方式，手动去 Consul 中获取服务列表；这里需要说明的是，ConsulDiscoveryClient 中不支持根据自定义 Tags 获取服务提供者： 12345678910111213141516@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @GetMapping(\"/actuator/health\") public String health() { return \"SUCCESS\"; } @GetMapping(\"/getServer/{serviceId}\") public List&lt;ServiceInstance&gt; getServer(@PathVariable(\"serviceId\") String serviceId) { return discoveryClient.getInstances(serviceId); }} 创建 Consul Consumer Discovery Client 的 application.yml 配置文件： 12345678910server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 5. 测试结果 启动本地的 Consul 服务器，打开 Consul 的管理界面，查看服务的注册情况，如下图所示： 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-discovery-client、consul-consumer-ribbon 应用 请求 consul-consumer-ribbon 应用的 Feign 接口，访问 http://127.0.0.1:9003/consumer/sayHelloOne/Jim，查看返回的内容是否为 from port 9001: hello Jim 请求 consul-consumer-ribbon 应用的 RestTemplate 接口，访问 http://127.0.0.1:9003/consumer/sayHelloTwo/Peter，查看返回的内容是否为 from port 9001: hello Peter 请求 consul-consumer-discovery-client 应用的接口，访问 http://127.0.0.1:9004/getServer/consul-provider，查看返回的服务提供者信息是否只有 consul-provider 提供者，如下图所示： Spring Cloud Consul Config上面的示例演示了 Spring Cloud Consul Config 获取和刷新配置的简单用法。Spring Cloud Consul Config 与 Consul 是通过 HTTP 进行交互的，那配置刷新是如何做到的呢？另外，示例中只有一条配置，可是实际工作中的配置可能有成百上千条，难道配置信息需要一个个在 Consul 的管理页面中添加吗？ 配置刷新原理Spring Cloud Consul 是通过 HTTP 的方式跟 Consul 交互，那配置是如何实时生效的呢？答案其实很简单，那就是配置并没有实时生效。org.springframework.cloud.consul.config.ConfigWatch 中有一个定时方法 watchConfigKeyValues()，它默认每秒执行一次（可以通过 spring.cloud.consul.config.watch.delay 自定义执行的时间间隔)，去 Consul 中获取最新的配置信息，一旦配置发生改变，Spring 通过 ApplicationEventPublisher 重新刷新配置。Consul Config 组件就是通过这种方式，达到配置 “实时生效” 的目的。那客户端如何得知配置被更新过了呢，答案在 Consul 返回的数据里。Consul 会给每一项配置加一个 consulIndex 属性，类似于版本号，如果配置更新，它就会自增。Spring Cloud Consul Config 就是通过缓存 consulIndex 来判断配置是否发生改变。 高级配置（作为配置中心）Consul 只支持用 K/V 的方式进行配置，那怎么让 Consul 支持同时配置多条的方式呢？难道要给 Consul 增加一个导入功能吗？其实 K/V 不仅可以代表一条配置，还可以代表一个应用的配置，将应用名作为 Key，Value 中用来存放它所有的配置，这样就可以达到同时配置多条的结果。Spring Cloud Consul Config 就是这样，通过将 yml 或者 properties 放在 Value 中来实现配置的批量操作。下面的示例将演示使用 Consul 的配置功能，将整个应用的配置以 yml 的方式存储在 Consul 中，以此实现类似 Spring Cloud Config 的配置中心功能，点击下载完整的案例代码。 创建 Consul Config Customize 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Consul Config Customize 的主启动类： 1234567@SpringBootApplicationpublic class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class, args); }} 创建 Consul Config Customize 的测试控制类： 12345678910111213@RefreshScope@RestController@RequestMapping(\"/config\")public class TestController { @Value(\"${foo.bar.name}\") private String name; @GetMapping(\"/getName\") public String getName() { return name; }} 创建 Consul Config Customize 的 application.yml 配置文件： 12345spring: application: name: consul-config-customize profiles: active: dev 创建 Consul Config Customize 的 bootstrap.yml 配置文件，增加自定义的配置属性： 1234567891011spring: cloud: consul: config: host: 127.0.0.1 # Consul 启动地址 port: 8500 # Consul 启动端口 format: yaml # Consul 中 Value 配置格式为 yaml prefix: configuration # Consul 中配置文件目录为 configuration, 默认为 config default-context: app # 去该目录下查找缺省配置, 默认为 application profile-separator: ':' # profiles配置分隔符, 默认为‘,’ data-key: data # 如果指定配置格式为 yaml 或者 properties, 则需要该值作为key, 默认为 data 测试结果： 启动本地的 Consul 服务器 访问 http://127.0.0.1:8500/ui/dc1/kv 页面，添加 key 为：configuration/consul-config-customize:dev/data，value 为： 12345server: port: 9002foo: bar: name: book-dev 访问 http://127.0.0.1:8500/ui/dc1/kv 页面，添加 key 为：configuration/consul-config-customize:test/data，value 为： 12345server: port: 9003foo: bar: name: book-test 启动 consul-config-customize 应用，查看启动的端口号；访问 http://127.0.0.1:9002/config/getName，查看接口返回的内容 更改 application.yml 中的配置为 spring.profiles.active=test 重新启动 consul-config-customize 应用，查看启动的端口号；访问 http://127.0.0.1:9003/config/getName，查看接口返回的内容 Spring Cloud Consul 功能重写Spring Cloud Consul 提供了很多方便实用的功能，但是面对五花八门的需求，还是希望可以重写它的原有逻辑。 重写 ConsulDiscoveryClient (支持 Tag)ConsulDiscoveryClient 并不支持根据自定义 Tag 获取服务，一般来说，ConsulServerList 和 ConsulDiscoveryClient 虽然面对的需求不同，但是实现的功能都是一样的，那就是根据条件查找服务。可能 Spring 认为 ConsulDiscoveryClient 是为一些框架型的功能准备的，用户完全可以拿到服务列表后自行筛选所需的数据。下面的示例将重写 ConsulDiscoveryClient 的功能，让其支持根据自定义 Tag 获取服务。首先创建三个工程，分别是：consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override，其中前两个工程与上面的服务发现案例里的配置和代码完全一致，这里不再累述，点击下载完整的案例代码。 Consul Consumer Override 工程里的 MyConsulDiscoveryClient 类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class MyConsulDiscoveryClient implements DiscoveryClient { private final ConsulClient client; private final ConsulDiscoveryProperties properties; public MyConsulDiscoveryClient(ConsulClient client, ConsulDiscoveryProperties properties) { this.client = client; this.properties = properties; } @Override public String description() { return \"Spring Cloud Consul Discovery Client\"; } @Override public List&lt;ServiceInstance&gt; getInstances(final String serviceId) { return getInstances(serviceId, QueryParams.DEFAULT); } public List&lt;ServiceInstance&gt; getInstances(final String serviceId, final QueryParams queryParams) { List&lt;ServiceInstance&gt; instances = new ArrayList&lt;&gt;(); addInstancesToList(instances, serviceId, queryParams); return instances; } private void addInstancesToList(List&lt;ServiceInstance&gt; instances, String serviceId, QueryParams queryParams) { String aclToken = properties.getAclToken(); Response&lt;List&lt;HealthService&gt;&gt; services; if (StringUtils.hasText(aclToken)) { // 这里由获取默认tag改为获取指定tag services = client.getHealthServices(serviceId, getTag(serviceId), this.properties.isQueryPassing(), queryParams, aclToken); } else { // 这里由获取默认tag改为获取指定tag services = client.getHealthServices(serviceId, getTag(serviceId), this.properties.isQueryPassing(), queryParams); } for (HealthService service : services.getValue()) { String host = ConsulServerUtils.findHost(service); Map&lt;String, String&gt; metadata = ConsulServerUtils.getMetadata(service); boolean secure = false; if (metadata.containsKey(\"secure\")) { secure = Boolean.parseBoolean(metadata.get(\"secure\")); } instances.add(new DefaultServiceInstance(serviceId, host, service.getService().getPort(), secure, metadata)); } } public List&lt;ServiceInstance&gt; getAllInstances() { List&lt;ServiceInstance&gt; instances = new ArrayList&lt;&gt;(); Response&lt;Map&lt;String, List&lt;String&gt;&gt;&gt; services = client.getCatalogServices(QueryParams.DEFAULT); for (String serviceId : services.getValue().keySet()) { addInstancesToList(instances, serviceId, QueryParams.DEFAULT); } return instances; } @Override public List&lt;String&gt; getServices() { String aclToken = properties.getAclToken(); if (StringUtils.hasText(aclToken)) { return new ArrayList&lt;&gt;(client.getCatalogServices(QueryParams.DEFAULT, aclToken).getValue().keySet()); } else { return new ArrayList&lt;&gt;(client.getCatalogServices(QueryParams.DEFAULT).getValue().keySet()); } } // 获取tag的方法，该方法在 ConsulServerList 中已存在 protected String getTag(String serviceId) { return this.properties.getQueryTagForService(serviceId); }} Consul Consumer Override 工程里的配置类： 123456789@Configurationpublic class CommonConfiguration { @Bean @Order(Ordered.HIGHEST_PRECEDENCE) // 保证优先被Spring加载 public MyConsulDiscoveryClient discoveryClient(ConsulClient client, ConsulDiscoveryProperties properties) { return new MyConsulDiscoveryClient(client, properties); }} Consul Consumer Override 工程里的测试控制类： 12345678910111213141516@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @GetMapping(\"/actuator/health\") public String health() { return \"SUCCESS\"; } @GetMapping(\"/getServer/{serviceId}\") public List&lt;ServiceInstance&gt; getServer(@PathVariable(\"serviceId\") String serviceId) { return discoveryClient.getInstances(serviceId); }} Consul Consumer Override 工程里的 application.yml 配置文件： 12345678910111213server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 discovery: server-list-query-tags: consul-provider: tag1 # 在调用 consul-provider 服务时，使用 tag1 对应的服务实例 测试结果： 启动本地的 Consul 服务器 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override 应用 访问 http://127.0.0.1:9004/getServer/consul-provider，查看接口返回的信息，看看是否只返回了 tag1 对应的服务实例 重写 ConsulServerList原理分析单纯的自定义实现 ServerList 的接口并不能达到重写 ConsulServerList 的目的，是因为 ConsulServerList 的 serviceId 属性为 null 时会导致启动报错。这个 serviceId 属性表示服务提供者的名称，但是却作为 ConsulServerList 的成员变量。由此可以联想到，Spring Cloud Consul 为每个服务提供者都创建了一个 ConsulServerList 实例，这是为了支持 Ribbon 的服务配置个性化。Ribbon 支持对某一个服务单独配置负载，比如负载算法，是否重试等，当然也包括服务发现逻辑，为每一个服务实例化一个服务发现逻辑，可以最大化地将自由交给实现方。特别注意，ConsulServerList 并不是在 Spring 启动的时候初始化，而是在服务调用时通过 Ribbon 进行初始化，具体的初始化流程如下： Feign 通过 serviceId 去 Ribbon 中获取服务端配置 Ribbon 根据 serviceId 去缓存中找是否存在这个名称的 AnnotationConfigApplicationContext 实例，如果有就立即返回；如果没有就创建一个，而创建 AnnotationConfigApplicationContext 的过程，就是 ConsulServerList 初始化的过程 AnnotationConfigApplicationContext 跟 ConsulServerList 是通过 @RibbonClient 注解关联在一起的，具体可以参考 RibbonClientConfigurationRegistrar 源码 所以重写 ConsulServerList 的过程比较麻烦，要么重新写一套类似的 spring-cloud-consul-discovery 源码，要么就从源头的 RibbonClientConfiguration 开始直到 ConsulServerList 均改成自己的实现。 重写示例下面的示例将使用第二种方式重写 ConsulServerList，首先创建三个工程，分别是：consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override，其中前两个工程与上面的服务发现案例里的配置和代码完全一致，这里不再累述，点击下载完整的案例代码。值得一提的是，在 Consul Consumer Override 工程里新增 MyConsulServerList、MyConsulRibbonClientConfiguration、MyRibbonConsulAutoConfiguration 类，需要保证 MyConsulRibbonClientConfiguration 类不能与被 @ConponentScan 修饰的主类放在同一个包或其子包下，否则会导致 IClientConfig 的 Bean 无法注入。 Consul Consumer Override 工程里的 MyConsulServerList 类： 12345678910111213141516171819202122232425262728293031323334public class MyConsulServerList extends AbstractServerList&lt;ConsulServer&gt; { private String serviceId; private final ConsulClient client; private final ConsulDiscoveryProperties properties; private static final Logger logger = LoggerFactory.getLogger(MyConsulServerList.class); public MyConsulServerList(ConsulClient client, ConsulDiscoveryProperties properties) { this.client = client; this.properties = properties; } /** * 打印一句提示 */ private List&lt;ConsulServer&gt; getServers() { if (this.client == null) { return Collections.emptyList(); } logger.info(\"===== 自定义服务发现 =====\"); String tag = getTag(); // null is ok Response&lt;List&lt;HealthService&gt;&gt; response = this.client.getHealthServices( this.serviceId, tag, this.properties.isQueryPassing(), createQueryParamsForClientRequest(), this.properties.getAclToken()); if (response.getValue() == null || response.getValue().isEmpty()) { return Collections.emptyList(); } return transformResponse(response.getValue()); } // 省略其他代码 ....} Consul Consumer Override 工程里的 MyConsulRibbonClientConfiguration 类： 123456789101112131415161718192021222324252627282930313233343536@Configurationpublic class MyConsulRibbonClientConfiguration { @Autowired private ConsulClient client; private String serviceId = \"client\"; protected static final String VALUE_NOT_SET = \"__not__set__\"; protected static final String DEFAULT_NAMESPACE = \"ribbon\"; public MyConsulRibbonClientConfiguration() { } public MyConsulRibbonClientConfiguration(String serviceId) { this.serviceId = serviceId; } /** * 将ServerList生效的实现改为MyServerList * * @param config * @param properties * @return */ @Bean @ConditionalOnMissingBean public ServerList&lt;?&gt; ribbonServerList(IClientConfig config, ConsulDiscoveryProperties properties) { MyConsulServerList serverList = new MyConsulServerList(client, properties); serverList.initWithNiwsConfig(config); return serverList; } // 省略其他代码 ....} Consul Consumer Override 工程里的 MyRibbonConsulAutoConfiguration 类： 12345678910111213/** * 该类主要是将原有入口取代, 因此它的生效逻辑刚好跟 RibbonConsulAutoConfiguration 相反 * 当 spring.cloud.consul.ribbon.enabled 为 false 时, 这里重写的逻辑生效 */@Configuration@ConditionalOnConsulEnabled@ConditionalOnBean(SpringClientFactory.class)@AutoConfigureAfter(RibbonAutoConfiguration.class)@ConditionalOnExpression(\"${spring.cloud.consul.ribbon.enabled:true}==false\")@RibbonClients(defaultConfiguration = MyConsulRibbonClientConfiguration.class)public class MyRibbonConsulAutoConfiguration {} 在 Consul Consumer Override 工程里里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.springcloud.override.consul.MyRibbonConsulAutoConfiguration Consul Consumer Override 工程里的启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerOverrideApplication { public static void main(String[] args) { SpringApplication.run(ConsumerOverrideApplication.class, args); }} Consul Consumer Override 工程里的服务接口类，用于调用 Provider 服务： 123456@FeignClient(\"consul-provider\")public interface ProviderService { @RequestMapping(value = \"/provider/sayHello/{name}\", method = RequestMethod.GET) public String sayHello(@PathVariable(\"name\") String name);} Consul Consumer Override 工程里的测试控制类： 12345678910111213141516171819@RestControllerpublic class TestController { @Autowired private DiscoveryClient discoveryClient; @Autowired private ProviderService providerService; @GetMapping(\"/actuator/health\") public String health() { return \"SUCCESS\"; } @GetMapping(\"/sayHello/{name}\") public String getServer(@PathVariable(\"name\") String name) { return providerService.sayHello(name); }} Consul Consumer Override 工程里的 application.yml 123456789101112server: port: 9004spring: application: name: consul-consumer-discovery-client cloud: consul: host: 127.0.0.1 # consul 启动地址 port: 8500 # consul 启动端口 ribbon: enabled: false # 此处配置很重要,为 true 时走原有逻辑, 为 false 时走重写逻辑 测试结果： 启动本地的 Consul 服务器 依次启动 consul-provider-tag-one、consul-provider-tag-two、consul-consumer-override 应用 访问 http://127.0.0.1:9004/sayHello/Peter，查看接口是否正常返回内容，控制台输出的日志信息如下： 1234c.netflix.loadbalancer.BaseLoadBalancer : Client: consul-provider instantiated a LoadBalancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=consul ...c.n.l.DynamicServerListLoadBalancer : Using serverListUpdater PollingServerListUpdaterc.s.override.consul.MyConsulServerList : ===== 自定义服务发现 =====c.netflix.config.ChainedDynamicProperty : Flipping property: consul-provider.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 多次访问 http://127.0.0.1:9004/sayHello/Peter，通过接口返回的服务方端口号，看看客户端是不是默认以轮询的方式调用服务方的接口 Spring Cloud Consul 的坑异常信息不完整开发者偶尔会遇到 Spring Cloud Consul 打印的异常堆栈中，message 为 null 的情况，导致排查问题异常困难，这是因为 Spring Cloud Consul 对 consul-api 自定义的 OperationException 异常没有做特殊处理导致的。当 Consul 的 HTTP 响应代码为非 200 时，consul-api 会抛出 OperationException；而 Spring Cloud Consul 在调用 consul-api 接口时，有些代码会简单地使用 Exception 捕获异常，然后打印 Log 日志，导致 OperationException 的属性丢失。例如在 ConsulCatalogWatch、ConsulHealthIndicator 中均使用这种处理方式。 consul-api 的兼容问题Consul 在 1.0.0 版本后，将一些接口（/agent/check/pass，/agent/service/deregister）由 GET 方法改成 PUT，这个 bug 在 consul-api 的 1.3.0 版本才得到解决，对应到 Spring Cloud Consul 已经是 2.0.0.M1 版本了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Linux 安装 Robo 3T（Robomongo）","url":"/posts/1f8b78c4.html","text":"相关站点 Robo 3T 官网 Robo 3T 官方下载 Robo 3T Github 项目 Robo 3T Snap Github 项目 介绍 Robo 3T 是一款跨平台的 MongoDB 可视化工具，在管理数据库内容以及数据库代码编辑方面提供一定的开发优化方案，内置一个代码编辑区域，支持将数据库文件放到软件上修改，结合图形化的处理方式，可以将 MongoDB 数据库中的文件转换为分布式的存储方式，提高数据文件编辑和保存效率。Robo 3T 的前身是 Robomongo，在新版本中，可以更加方便地查找数据库对象、利用其中的数据生成器，可以将 Excel 文件的数据导入数据库中保存，对于制作数据文件来说是非常方便的。 安装说明 由于 Robo 3T 是基于 C++ 开发的，为了避免安装过程中可能出现的 GLibc 依赖错误，下面直接通过 Snap 来安装 Robomongo，这样也方便以后管理软件的更新，此安装方式适用于 Centos、Debian、Ubuntu 等 Liinux 发行版。 12345678910111213141516171819202122# 安装# snap install robo3t-snap# 查看安装状态# snap list# 创建快捷方式# vim /usr/share/applications/robo3t.desktop[Desktop Entry]Name=Robo3tComment=Robo 3T (formerly Robomongo) is the free lightweight GUI for MongoDB enthusiasts.Exec=/snap/bin/robo3t-snap %UTerminal=falseType=ApplicationIcon=/var/lib/snapd/snap/robo3t-snap/current/meta/gui/icon.pngCategories=GNOME;GTK;Development;MimeType=text/plain;# 菜单栏导航到：应用程序 --&gt; 编程 --&gt; Robo3t，直接点击快捷方式启动应用，应用启动后的界面截图如下# 或者直接使用命令来启动（使用普通用户权限）$ /snap/bin/robo3t-snap Robo 3T 界面 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux 开发工具"},{"title":"Config 入门教程 - 高级篇","url":"/posts/8a77bec.html","text":"上篇 - Config 入门教程（中级篇） Config 入门教程 - 中级篇 前言版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Config 高可用对于线上的生产环境，通常对其都是有很高的要求，其中高可用是不可或缺的一部分，必须要保证服务是可用状态，才能保证系统更好地运行，这是业务稳定的保证。 Config 客户端高可用对于客户端的高可用，这里的方案主要还是用 File 的形式，本质与 “客户端回退” 的思路大体一致。客户端高可用主要是解决当服务端不可用的情况下，客户端依然可以正常启动。从客户端的角度出发，不是增加配置中心的高可用性，而是降低客户端对配置中心的依赖程度，从而提高整个分布式架构的健壮性。客户端加载配置的高可用流程图如下，点击下载完整的案例代码。 1. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 2. 创建 Config Client HA AutoConfig 工程创建 Config Client HA AutoConfig 工程，配置工程里的 pom.xml 文件： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client HA AutoConfig 工程里的配置属性加载类： 123456789101112131415161718192021222324252627282930@Component@ConfigurationProperties(prefix = ConfigSupportProperties.CONFIG_PREFIX)public class ConfigSupportProperties { public static final String CONFIG_PREFIX = \"spring.cloud.config.backup\"; private final String DEFAULT_FILE_NAME = \"fallback.properties\"; private boolean enable = false; private String fallbackLocation; public boolean isEnable() { return enable; } public void setEnable(boolean enable) { this.enable = enable; } public String getFallbackLocation() { return fallbackLocation; } public void setFallbackLocation(String fallbackLocation) { // 如果只是填写路径， 就添加上一个默认的文件名 if (fallbackLocation.indexOf(\".\") == -1) { this.fallbackLocation = fallbackLocation + DEFAULT_FILE_NAME; return; } this.fallbackLocation = fallbackLocation; }} 创建 Config Client HA AutoConfig 工程里的自动配置类，该类主要的作用是判断 Config Server 端的配置信息是否可用，如果不能用将读取加载本地备份配置文件进行启动。需要注意的是启动顺序的设置，这是因为 Spring Cloud 使用的 PropertySourceBootstrapConfiguration 启动顺序为 private int order = -2147483638，order 的值越小越先加载，所以下述的 orderNum 只要加上一个整数比其大即可： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185@Configuration@EnableConfigurationProperties(ConfigSupportProperties.class)public class ConfigSupportConfiguration implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered { private final Logger LOGGER = LoggerFactory.getLogger(ConfigSupportConfiguration.class); private final Integer orderNum = Ordered.HIGHEST_PRECEDENCE + 11; @Autowired(required = false) private List&lt;PropertySourceLocator&gt; propertySourceLocators = Collections.EMPTY_LIST; @Autowired private ConfigSupportProperties configSupportProperties; @Override public void initialize(ConfigurableApplicationContext configurableApplicationContext) { if (!isHasCloudConfigLocator(this.propertySourceLocators)) { LOGGER.info(\"未启用Config Server管理配置\"); return; } LOGGER.info(\"检查Config Service配置资源\"); ConfigurableEnvironment environment = configurableApplicationContext.getEnvironment(); MutablePropertySources propertySources = environment.getPropertySources(); LOGGER.info(\"加载PropertySources源：\" + propertySources.size() + \"个\"); if (!configSupportProperties.isEnable()) { LOGGER.warn(\"未启用配置备份功能，可使用{}.enable打开\", ConfigSupportProperties.CONFIG_PREFIX); return; } if (isCloudConfigLoaded(propertySources)) { PropertySource cloudConfigSource = getLoadedCloudPropertySource(propertySources); LOGGER.info(\"成功获取ConfigService配置资源\"); Map&lt;String, Object&gt; backupPropertyMap = makeBackupPropertyMap(cloudConfigSource); doBackup(backupPropertyMap, configSupportProperties.getFallbackLocation()); LOGGER.info(\"成功备份ConfigService配置资源\"); } else { LOGGER.error(\"获取ConfigService配置资源失败\"); Properties backupProperty = loadBackupProperty(configSupportProperties.getFallbackLocation()); if (backupProperty != null) { HashMap backupSourceMap = new HashMap&lt;&gt;(backupProperty); PropertySource backupSource = new MapPropertySource(\"backupSource\", backupSourceMap); propertySources.addFirst(backupSource); LOGGER.warn(\"使用备份的配置启动：{}\", configSupportProperties.getFallbackLocation()); } } } @Override public int getOrder() { return orderNum; } /** * 是否启用了Spring Cloud Config获取配置资源 * * @param propertySourceLocators * @return */ private boolean isHasCloudConfigLocator(List&lt;PropertySourceLocator&gt; propertySourceLocators) { for (PropertySourceLocator sourceLocator : propertySourceLocators) { if (sourceLocator instanceof ConfigServicePropertySourceLocator) { return true; } } return false; } /** * 是否启用Cloud Config * * @param propertySources * @return */ private boolean isCloudConfigLoaded(MutablePropertySources propertySources) { if (getLoadedCloudPropertySource(propertySources) == null) { return false; } return true; } /** * 获取加载的Cloud Config配置项 * * @param propertySources * @return */ private PropertySource getLoadedCloudPropertySource(MutablePropertySources propertySources) { if (!propertySources.contains(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME)) { return null; } PropertySource propertySource = propertySources.get(PropertySourceBootstrapConfiguration.BOOTSTRAP_PROPERTY_SOURCE_NAME); if (propertySource instanceof CompositePropertySource) { for (PropertySource&lt;?&gt; source : ((CompositePropertySource) propertySource).getPropertySources()) { if (source.getName().equals(\"configService\")) { return source; } } } return null; } /** * 生成备份的配置数据 * * @param propertySource * @return */ private Map&lt;String, Object&gt; makeBackupPropertyMap(PropertySource propertySource) { Map&lt;String, Object&gt; backupSourceMap = new HashMap&lt;&gt;(); if (propertySource instanceof CompositePropertySource) { CompositePropertySource composite = (CompositePropertySource) propertySource; for (PropertySource&lt;?&gt; source : composite.getPropertySources()) { if (source instanceof MapPropertySource) { MapPropertySource mapSource = (MapPropertySource) source; for (String propertyName : mapSource.getPropertyNames()) { // 前面的配置覆盖后面的配置 if (!backupSourceMap.containsKey(propertyName)) { backupSourceMap.put(propertyName, mapSource.getProperty(propertyName)); } } } } } return backupSourceMap; } /** * 生成备份文件 * * @param backupPropertyMap * @param filePath */ private void doBackup(Map&lt;String, Object&gt; backupPropertyMap, String filePath) { FileSystemResource fileSystemResource = new FileSystemResource(filePath); File backupFile = fileSystemResource.getFile(); try { if (!backupFile.exists()) { backupFile.createNewFile(); } if (!backupFile.canWrite()) { LOGGER.error(\"无法读写文件：{}\", fileSystemResource.getPath()); } Properties properties = new Properties(); Iterator&lt;String&gt; keyIterator = backupPropertyMap.keySet().iterator(); while (keyIterator.hasNext()) { String key = keyIterator.next(); properties.setProperty(key, String.valueOf(backupPropertyMap.get(key))); } FileOutputStream fos = new FileOutputStream(fileSystemResource.getFile()); properties.store(fos, \"Backup Cloud Config\"); } catch (IOException e) { LOGGER.error(\"文件操作失败：{}\", fileSystemResource.getPath()); e.printStackTrace(); } } /** * 加载本地文件 * * @param filePath * @return */ private Properties loadBackupProperty(String filePath) { PropertiesFactoryBean propertiesFactory = new PropertiesFactoryBean(); Properties props = new Properties(); try { FileSystemResource fileSystemResource = new FileSystemResource(filePath); propertiesFactory.setLocation(fileSystemResource); propertiesFactory.afterPropertiesSet(); props = propertiesFactory.getObject(); } catch (IOException e) { e.printStackTrace(); return null; } return props; }} 创建 Config Client HA AutoConfig 工程里 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.config.ConfigSupportConfiguration 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入上面的 config-client-ha-autoconfig： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-ha-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = \"cn.springcloud\")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping(\"/getConfigInfo\") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，enable 表示是否启动加载远程配置信息进行本地备份，fallbackLocation 表示本地备份的路径，也可以是路径加上文件名： 12345678910spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 backup: enable: true fallbackLocation: /tmp/config/config-client-dev/fallback.properties #备份配置文件的路径 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo 后观察返回的配置信息，与此同时查看是否在目录 /tmp/config/config-client-dev/ 下成功创建了备份文件 fallback.properties 关闭 config-server、config-client 应用，然后单独启动 config-client 应用；观察在不启动 config-server 的情况下，config-client 应用是否能正常启动 若 config-client 应用单独启动成功，config-client 应用会先尝试去连接 config-server，当连接失败后，会加载本地的备份文件，此时控制台输出的日志信息如下： 1234567c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://127.0.0.1:8001c.c.c.ConfigServicePropertySourceLocator : Connect Timeout Exception on Url - http://127.0.0.1:8001. Will be trying the next url if availablec.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for \"http://127.0.0.1:8001/config-client/dev/master\": 拒绝连接; nested exception is java.net.ConnectException: 拒绝连接c.s.s.config.ConfigSupportConfiguration : 检查Config Service配置资源c.s.s.config.ConfigSupportConfiguration : 加载PropertySources源：10个c.s.s.config.ConfigSupportConfiguration : 获取ConfigService配置资源失败c.s.s.config.ConfigSupportConfiguration : 使用备份的配置启动：/tmp/config/config-client-dev/fallback.properties Config 服务端高可用Config Server 一样需要在生成环境下保证高可用的，这里将通过结合 Eureka 注册中心的方式搭建 Config Server 的高可用，即通过 Ribbon 的客户端负载均衡选择一个 Config Server 进行连接来获取配置信息，具体的流程如下，点击下载完整的案例代码。对于 Eureka 的高可用这里也不进行详解，详细关于 Eureka 的高可用可参考 Eureka 集群配置。 1. 准备说明本示例用到上面的 “客户端高可用” 示例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，引入 spring-cloud-starter-netflix-eureka-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程的 src/main/resources 目录下： 1234567891011server: port: 7001eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 3. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，由于 Config Sever 需要注册到 Eureka Server，所以需要另外添加 Eureka Client 的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer、@EnableDiscoveryClient 注解： 123456789@EnableConfigServer@EnableDiscoveryClient@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 1234567891011121314151617181920212223server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: mastereureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 4. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，由于 Config Client 需要注册到 Eureka Server，所以需要另外添加 Eureka Client 的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类，增加 @EnableDiscoveryClient 注解： 123456789@EnableDiscoveryClient@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = \"cn.springcloud\")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping(\"/getConfigInfo\") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，这里不再使用 spring.cloud.config.uri 参数直接指向 Config Server 端的连接地址，而是增加了下述三个参数： spring.cloud.config.discovery.enabled：开启 Config Client 的服务发现支持 spring.cloud.config.discovery.service-id：指定 Config Server 端的 serviceId，也就是 Config Server 端的 spring.application.name 参数值 eureka.client.service-url.defaultZone： 指向 Eureka 注册中心的地址 1234567891011121314151617spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 discovery: enabled: true service-id: config-servereureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: config-client-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 5. 测试 通过 maven install 命令将各个应用安装到本地，然后再使用命令行启动各个应用，当然也可以直接在 IDEA、Eclipse 里启动，具体的命令如下： 1234567891011121314# 启动Eurekajava -jar eureka-server-1.0-SNAPSHOT.jar# 启动Config Server（默认端口：8001）java -jar config-server-1.0-SNAPSHOT.jar# 启动Config Serverjava -jar config-server-1.0-SNAPSHOT.jar --server.port=8002# 启动Config Config（默认端口：9001）java -jar config-client-1.0-SNAPSHOT.jar# 启动Config Configjava -jar config-client-1.0-SNAPSHOT.jar --server.port=9002 当两个 Config Client 应用启动完成后，查看控制台输出的日志信息，看看是否已经负载了；如果没有负载到也没关系，可以启动多个 Config Client 实例再试试 浏览器访问 http://127.0.0.1:9001/getConfigInfo、http://127.0.0.1:9002/getConfigInfo，观察是否可以正确返回配置信息 Config 源码解析（待续） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Docker 安装 Consul","url":"/posts/224f5100.html","text":"相关站点 Consul 官方安装教程 Consul Docker 官方安装教程 拉取 Consul 镜像 12345# 拉取最新版本的镜像# docker pull consul:latest# 拉取特定版本的镜像# docker pull consul:1.7.3 Docker 安装 Consul（单机） 1234567# 创建并启动容器，默认是以开发模式启动，数据保存在内存中# docker run -d --name=consul -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3# 查看容器的运行状态# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7c43babcc760 consul:1.7.3 \"docker-entrypoint.s…\" 38 seconds ago Up 37 seconds 8300-8302/tcp, 8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul Docker 安装 Consul（集群） 下面将演示在开发模式下，如何创建拥有 3 个节点的 Consul 集群，数据默认保存在内存中，开发模式下可以直接通过 8500 端口访问 Consul 的 WebUI 界面。 12345678910111213141516171819202122232425262728# 创建并启动第一个节点# docker run -d --name=consul-node1 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3# 查看第一个节点的IP# docker inspect -f='{{.NetworkSettings.IPAddress}}' consul-node1# 创建并启动第二个节点，172.17.0.3是第一个节点的IP# docker run -d --name=consul-node2 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3 agent -dev -join=172.17.0.3# 创建并启动第三个节点，172.17.0.3是第一个节点的IP# docker run -d --name=consul-node3 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.7.3 agent -dev -join=172.17.0.3# 查看容器的运行状态# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1ac5832f79f4 consul:1.7.3 \"docker-entrypoint.s…\" 31 seconds ago Up 30 seconds 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node3533b0f12877a consul:1.7.3 \"docker-entrypoint.s…\" 56 seconds ago Up 55 seconds 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node2d25f90dffa94 consul:1.7.3 \"docker-entrypoint.s…\" 2 minutes ago Up 2 minutes 8300-8302/tcp, 8500-8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp consul-node1# 在第一个容器中运行consul命令来查询集群中的所有成员# docker exec -t consul-node1 consul membersNode Address Status Type Build Protocol DC Segment1ac5832f79f4 172.17.0.5:8301 alive server 1.7.3 2 dc1 &lt;all&gt;533b0f12877a 172.17.0.4:8301 alive server 1.7.3 2 dc1 &lt;all&gt;d25f90dffa94 172.17.0.3:8301 alive server 1.7.3 2 dc1 &lt;all&gt;# 访问web管理界面# 浏览器访问：http://172.17.0.3:8500 Consul 容器的持久化 在开发模式下启动 Consul 容器，数据默认保存在内存中，容器重启后数据会丢失；若想使用 Docker 的数据卷持久化容器里的数据，可以挂载以下目录，如 docker -v /usr/share/consul/data:/consul/data。 /consul/data：Consul 存放数据的目录 /consul/config：Consul 存放配置文件的目录 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化"},{"title":"C++ 基础面试题之一","url":"/posts/c62ca067.html","text":"多态请谈谈对多态的理解 多态的实现效果 多态是在运行期间根据具体对象的类型决定函数调用，同样的调用语句有多种不同的表现形态 多态实现的三个必要条件 有继承、有虚函数（virtual ）的重写、有父类的指针（引用）指向子类对象 多态的 C++ 实现 使用 virtual 关键字，告诉编译器这个函数要支持多态；不是根据指针类型判断如何调用，而是要根据指针所指向的实际对象类型来判断如何调用 多态的理论基础 动态联编 Vs 静态联编，根据实际的对象类型来判断重写函数的调用 多态的重要意义 多态是设计模式的基础，是框架的基石 实现多态的理论基础 函数指针做函数参数 函数指针一般有两种用法（正、反） 多态原理的探究 与面试官展开讨论 谈谈对重写与重载理解 函数重载 必须在同一个类中进行 子类无法重载父类的函数，父类同名函数将被子类的覆盖 重载是在编译期间根据参数类型、个数和顺序决定函数的调用 函数重写 必须发生于父类与子类之间 父类与子类中的函数必须有完全相同的原型 使用 virtual 关键字声明之后，能够产生多态（如果不使用 virtual 关键字声明，那叫重定义） 在父类的构造函数中调用虚函数，能实现多态吗子类的 VPTR 指针是分步完成初始化的，当执行父类的构造函数时，子类 的 VPTR 指针指向父类的虚函数表，当父类的构造函数执行完毕后，会把子类的 VPTR 指针指向子类的虚函数表。因此，在父类的构造函数中调用虚函数，不能实现多态。 分析图解 如图 所示 对象在创建的时，由编译器对 VPTR 指针进行初始化 只有当对象的构造全部完成后，VPTR 指针的指向才能最终确定 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"面试"},{"title":"Config 入门教程 - 中级篇","url":"/posts/f1872086.html","text":"上篇 - Config 入门教程（基础篇） Config 入门教程 - 基础篇 前言版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外。 Config 使用技巧本地参数覆盖远程参数在某些时候需要使用当前系统的环境变量或者是应用本身设置的参数而不是使用远程拉取的参数，此时 Config Client 可以使用如下配置： 官方 Bug 解决方案： https://github.com/spring-cloud/sprmg-cloud-config/issues/651 https://github.com/spring-cloud/spring-cloud-config/issues/359 123456spring: cloud: config: overrideNone: true allowOverride: true overrideSystemProperties: false overrideNone：当 allowOverride 为 true 时，overrideNone 设置为 true，代表外部配置的优先级更低，而且不能覆盖任何已存在的属性源，默认为 false allowOverride：标识 overrideSystemProperties 属性是否启用，默认为 true，设置为 false 表示禁止用户的个性化设置 overrideSystemProperties：用来标识外部配置是否能够覆盖系统属性，默认为 true 服务端 Git 配置详解Git 中 URI 占位符Spring Cloud Config Server 支持占位符的使用，支持 ｛application｝、{profile｝、{label｝，这样的话就可以在配置 uri 的时候，通过占位符使用应用名称来区分应用对应的仓库然后进行使用。下面举例说明 {application} 占位符的使用，点击下载完整的案例代码。 Config Server 的 application.yml 配置文件如下： 123456789101112131415server: port: 9090spring: application: name: config-server cloud: config: server: git: #根据不同的应用，使用不同的Git仓库，这里需要仓库名称和仓库下面的配置文件名称一致才可以 uri: https://gitee.com/peter/{application} username: admin password: admin search-paths: book-config Config Client 的 bootstrap.yml 配置文件如下： 1234567spring: cloud: config: label: master #Git分支的名称 profile: dev #本次访问的配置项 uri: http://localhost:9090 #Config Server的地址 name: spring-cloud-config #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀 使用上面的配置后，Config Client 请求 Config Server 仓库的连接地址的 uri 变成了 https://gitee.com/peter/spring-cloud-config，连接到了 spring-cloud-config 仓库；其中仓库的名称是由 Config Client 的 spring.cloud.config.name 属性指定，请求的配置文件的完整路径是 https://gitee.com/peter/spring-cloud-config/book-config/spring-cloud-config.yml；值得注意的是，这里需要仓库名称和仓库下面的配置文件名称一致才可以。 路径搜索占位符Spring Cloud Config Server 可以使用 searchPaths 参数进行路径的搜索，支持根据路径和路径前缀等方式进行配置文件的获取。 下述配置中的 book-config 表示匹配当前路径下面所有的配置文件信息，book-config* 表示在以 book-config 为前缀的文件夹内搜索所有配置文件。 1234567891011121314server: port: 9090spring: application: name: config-server cloud: config: server: git: uri: https://gitee.com/peter/spring-cloud-config username: admin password: admin search-paths: book-config, book-config* 下述配置中使用占位符的形式进行目录搜索，这样就可以根据不同的项目，对不同的配置文件进行路径搜索，从而很好地划分配置文件。值得注意的是，这里占位符的前后需要加上单引号，否则占位符无法生效。 123456789101112spring: application: name: config-server cloud: config: server: git: #根据不同的应用，搜索不同的目录路径，这里需要目录名称和目录里的配置文件名称一致才可以 uri: https://gitee.com/peter/spring-cloud-config username: admin password: admin search-paths: '{application}' 模式匹配和多个存储库在 application 和 profile 的使用上，Spring Cloud Config Server 还支持更复杂配置模式，可以使用通配符 {application}/{profile} 进行规则匹配，多个规则需要通过逗号分隔。以下配置中的 spring.cloud.config.server.uri 指明了默认的仓库地址，在使用 {application}/{profile} 匹配不上任何一个仓库时，会使用默认的仓库进行匹配来获取信息。对于 spring-cloud-config-simples 匹配的是 spring-cloud-config-simples/*，需要注意的是其仅能匹配应用名称为 spring-cloud-config-simples 的所有 profile 配置；对于 local 的仓库将会匹配所有的应用名以 local 开头的 Profiles。 123456789101112131415spring: cloud: config: server: git: uri: https://gitee.com/peter/spring-cloud-config search-paths: SC-BOOK-CONFIG repos: simple: https://gitee.com/peter/simple special: pattern: special*/dev*,*special*/dev* uri: https://gitee.com/peter/spring-cloud-config-special local: pattern: local* uri: /Users/peter/all_test/spring-cloud-config 关系型数据库的配置中心的实现1. 基于 MySQL 的配置概述Spring Cloud Config Server 默认提供了 JDBC 的方式连接 MySQL 数据库，整体的流程如下图，点击下载完整的案例代码。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 在 MySQL 中执行下述数据库脚本，创建对应的数据库和表，并插入对应的数据： 123456789101112131415161718192021-- 创建数据库create database `spring-cloud-config` default character set utf8;-- 当前数据库use `spring-cloud-config`;-- 创建类型表CREATE TABLE `PROPERTIES` ( `ID` int(11) NOT NULL AUTO_INCREMENT, `KEY` TEXT DEFAULT NULL, `VALUE` TEXT DEFAULT NULL, `APPLICATION` TEXT DEFAULT NULL, `PROFILE` TEXT DEFAULT NULL, `LABLE` TEXT DEFAULT NULL, PRIMARY KEY (`ID`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;-- 插入数据INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES ('3', 'cn.springcloud.config', 'I am the mysql configuration file from dev environment.', 'config-client', 'dev', 'master');INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES ('4', 'cn.springcloud.config', 'I am the mysql configuration file from test environment.', 'config-client', 'test', 'master');INSERT INTO `spring-cloud-config`.`PROPERTIES` (`ID`, `KEY`, `VALUE`, `APPLICATION`, `PROFILE`, `LABLE`) VALUES ('5', 'cn.springcloud.config', 'I am the mysql configuration file from prod environment.', 'config-client', 'prod', 'master'); 添加 Config Server 需要的 application.yml 配置文件到工程中，其中 spring.cloud.config.server.jdbc.sql 是在调用时使用的 SQL，spring.profiles.active=jdbc 表示使用的激活方式是 JDBC，spring.cloud.refresh.refreshable=none 是用来解决 DataSource 循环依赖问题。若项目中需要激活其他 profile，那么可以指定多个，例如 spring.profiles.active=jdbc,dev。 1234567891011121314151617181920212223242526server: port: 8001spring: application: name: config-server cloud: config: server: jdbc: sql: SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application =? AND profile =? AND lable =? label: master refresh: refreshable: none profiles: active: jdbc datasource: url: jdbc:mysql://127.0.0.1:3306/spring-cloud-config?useUnicode=true&amp;characterEncoding=UTF-8 username: root password: 123456 driver-class-name: com.mysql.jdbc.Driverlogging: level: org.springframework.jdbc.core: DEBUG org.springframework.jdbc.core.StatementCreatorUtils: Trace 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 启动 Config Server 应用后，浏览器输入 http://127.0.0.1:8001/config-client/dev/master 访问 Config Server，接口返回的结果如下： 4. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-client 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 MySQL 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = \"cn.springcloud\")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping(\"/getConfigInfo\") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123456server: port: 9090spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 5. 关于配置的刷新问题手动刷新和配置自动刷新对于 DB 环境下是否同时支持呢？对于 DB 操作来说，在自动刷新方面，一般是做了界面化的配置和管理，当成功提交配置到 DB 后，会调用 Config Server 的 Spring Cloud Bus 刷新接口，这样就可以实现和 Git 的 WebHook — 样的提交绑定执行功能。 6. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9090/getConfigInfo，接口会返回 I am the git configuration file from dev environment，说明一切运行正常 非关系型数据库的配置中心的实现基于 MongoDB 的配置概述Spring Cloud Config Server 并没有提供 MongoDB 的存储方式，但是目前 Spring Cloud 已经收录了一个相关的孵化器。整体的流程如下图，由于篇幅有限，下面只给出 Config Server 工程的核心配置和代码，而 Config Client 工程与上面 MySQL 的示例基本上一样，这里不再累述。 Config Server 工程的配置Config Server 工程的 pom.xml 文件，添加 MongoDB 的依赖支持： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server-mongodb&lt;/artifactId&gt; &lt;version&gt;0.0.2.BUILD-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Config Server 的主启动类，添加注解 @EnableMongoConfigServer： 12345678@SpringBootApplication@EnableMongoConfigServerpublic class MongoDbConfigServerApplication { public static void main(String[] args) { SpringApplication.run(MongoDbConfigServerApplication.class, args); }} Config Server 工程里的 application.yml 文件 123456789server: port: 8001spring: application: name: config-server data: mongodb: uri: mongodb://localhost/springcloud MongoDB 中的数据： 1234567891011{ \"label\" : \"master\", \"profile\" : \"dev\", \"source\" : { \"cn\" : { \"springcloud\" : { \"config\" : \"I am the mongdb configuration file from dev environment. I will edit.\" } } }} Config 功能扩展客户端回退客户端的回退机制，可以处理网络中断的情况，或者配置服务因维护而关闭的场景。当启用回退时，客户端适配器将 “缓存” 本地文件系统中的配置属性。要启用回退功能，只需指定存储缓存的位置即可；这个功能也称之为客户端高可用的一部分，也就是在服务端无法连接的情况下，客户端依然是可以用的，点击下载完整的案例代码。 1. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 2. 创建 Config Client Fallback Autoconfig 工程创建 Config Client Fallback Autoconfig 工程，配置工程里的 pom.xml 文件，其中 spring-security-rsa 依赖主要是用于当配置信息中存在敏感信息（如用户名密码）时，对敏感信息加密后再缓存在本地： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-rsa&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client Fallback Autoconfig 工程里的 FallbackableConfigServicePropertySourceLocator 类，主要用来创建本地回退文件，也就是加载远程配置文件后在本地备份一份： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@Order(0)public class FallbackableConfigServicePropertySourceLocator extends ConfigServicePropertySourceLocator { private boolean fallbackEnabled; private String fallbackLocation; @Autowired(required = false) TextEncryptor textEncryptor; public FallbackableConfigServicePropertySourceLocator(ConfigClientProperties defaultProperties, String fallbackLocation) { super(defaultProperties); this.fallbackLocation = fallbackLocation; this.fallbackEnabled = !StringUtils.isEmpty(fallbackLocation); } @Override public PropertySource&lt;?&gt; locate(Environment environment) { PropertySource&lt;?&gt; propertySource = super.locate(environment); if (fallbackEnabled) { if (propertySource != null) { storeLocally(propertySource); } } return propertySource; } private void storeLocally(PropertySource propertySource) { StringBuilder sb = new StringBuilder(); CompositePropertySource source = (CompositePropertySource) propertySource; for (String propertyName : source.getPropertyNames()) { Object value = source.getProperty(propertyName); if (textEncryptor != null) value = \"{cipher}\" + textEncryptor.encrypt(String.valueOf(value)); sb.append(propertyName).append(\"=\").append(value).append(\"\\n\"); } System.out.println(\"file contents : \" + sb.toString()); saveFile(sb.toString()); } private void saveFile(String contents) { BufferedWriter output = null; File file = new File(fallbackLocation + File.separator + ConfigServerBootstrap.FALLBACK_FILE_NAME); try { if (!file.exists()) { file.createNewFile(); } output = new BufferedWriter(new FileWriter(file)); output.write(contents); } catch (IOException e) { e.printStackTrace(); } finally { if (output != null) { try { output.close(); } catch (IOException e) { System.out.print(\"Error\" + e.getMessage()); } } } }} 创建 Config Client Fallback Autoconfig 工程的自动配置类，添加相关注解，使其在 Spring Boot 启动的时候进行加载。其中 spring.cloud.config.fallbackLocation 是指回退配置文件所在的目录路径，file:${spring. cloud.config.fallbackLocation:}/fallback.properties 是指回退配置文件的完整路径： 12345678910111213141516171819202122232425262728293031/** * 客户端自动配置依赖启动 */@Configuration@EnableConfigurationProperties@PropertySource(value = {\"config-client.properties\", \"file:${spring.cloud.config.fallbackLocation:}/fallback.properties\"}, ignoreResourceNotFound = true)public class ConfigServerBootstrap { public static final String FALLBACK_FILE_NAME = \"fallback.properties\"; @Autowired private ConfigurableEnvironment environment; @Value(\"${spring.cloud.config.fallbackLocation:}\") private String fallbackLocation; @Bean public ConfigClientProperties configClientProperties() { ConfigClientProperties clientProperties = new ConfigClientProperties(this.environment); clientProperties.setEnabled(false); return clientProperties; } @Bean public FallbackableConfigServicePropertySourceLocator fallbackableConfigServicePropertySourceLocator() { ConfigClientProperties client = configClientProperties(); FallbackableConfigServicePropertySourceLocator fallbackableConfigServicePropertySourceLocator = new FallbackableConfigServicePropertySourceLocator(client, fallbackLocation); return fallbackableConfigServicePropertySourceLocator; }} 创建 Config Client Fallback Autoconfig 工程里的 /src/main/resources/config-client.properties 配置文件： 1spring.cloud.config.enabled=false 创建 Config Refresh Fallback Autoconfig 工程里 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.fallback.config.ConfigServerBootstrap 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入上面的 config-client-fallback-autoconfig： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-fallback-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = \"cn.springcloud\")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping(\"/getConfigInfo\") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，fallbackLocation 指定了回退文件的路径： 12345678spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 fallbackLocation: /tmp/config/config-client-dev/ #回退文件的路径 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中： 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo 后观察返回的配置信息，与此同时查看是否在目录 /tmp/config/config-client-dev/ 下成功创建了回退文件 fallback.properties 关闭 config-server、config-client 应用，然后单独启动 config-client 应用；观察在不启动 config-server 的情况下，config-client 应用是否能正常启动 若 config-client 应用单独启动成功，config-client 应用会先尝试去连接 config-server，当连接失败后，会加载本地的回退配置文件，此时控制台输出的日志信息如下： 1234c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://127.0.0.1:8001c.c.c.ConfigServicePropertySourceLocator : Connect Timeout Exception on Url - http://127.0.0.1:8001. Will be trying the next url if availablec.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for \"http://127.0.0.1:8001/config-client/dev/master\": 拒绝连接; nested exception is java.net.ConnectException: 拒绝连接c.s.study.ConfigClientApplication : No active profile set, falling back to default profiles: default 客户端的安全认证机制 JWTSpring Cloud Config 客户端支持使用 JWT 身份验证方法代替标准的基本身份验证，这种方式需要对服务端和客户端都要改造，点击下载完整的案例代码，具体的验证步骤如下： 客户端向服务端负载授权的 RestController 发送请求，并且带上用户名和密码 服务端成功验证用户名和密码后，返回 Jwt Token 客户端加载服务端的配置信息，需要在 Header 中带上 Token 令牌进行认证 i. 准备工作本示例用到上面的 “客户端回退” 示例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 ii. 创建 Config Client Jwt 工程创建 Config Client Jwt 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client Jwt 工程的自动配置类，@PostConstruct 注解是执行是在 Servlet 构造函数和 init() 方法执行之间，也就是说在容器启动过程中会创建一个 RestTemplate 对象，将用户名和密码发送到 Config Server 端进行认证；认证成功会返回 Token，如果认证过程中用户名或者是密码错误，则将返回一个 401 认证失败的错误码。其中 ${spring.cloud.config.usemame}、 ${spring.cloud.config.password} 等参数是配置在客户端的，这里需要创建 ConfigServicePropertySourceLocator 这个 Bean 并且自定义一个 RestTemplate 对象需要带上 Token 信息，这就是代码中的 customRestTemplate 方法。还需要定义一个 ClientHttpRequestlnterceptor 接口的实现类，也就是代码中的 GenericRequestHeaderInterceptor 类，主要用于拦截发送到 Config Server 获取配置信息的请求，将 Token 信息添加到 HttpServletRequest 的 Headers 中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112@Configuration@Order(Ordered.LOWEST_PRECEDENCE)public class ConfigClientBootstrapConfiguration { private static Log logger = LogFactory.getLog(ConfigClientBootstrapConfiguration.class); @Value(\"${spring.cloud.config.username}\") private String jwtUserName; @Value(\"${spring.cloud.config.password}\") private String jwtPassword; @Value(\"${spring.cloud.config.endpoint}\") private String jwtEndpoint; private String jwtToken; @Autowired private ConfigurableEnvironment environment; @PostConstruct public void init() { RestTemplate restTemplate = new RestTemplate(); LoginRequest loginBackend = new LoginRequest(); loginBackend.setUsername(jwtUserName); loginBackend.setPassword(jwtPassword); String serviceUrl = jwtEndpoint; Token token; try { token = restTemplate.postForObject(serviceUrl, loginBackend, Token.class); if (token.getToken() == null) { throw new Exception(); } // 设置token setJwtToken(token.getToken()); } catch (Exception e) { e.printStackTrace(); } } public String getJwtToken() { return jwtToken; } public void setJwtToken(String jwtToken) { this.jwtToken = jwtToken; } @Bean public ConfigServicePropertySourceLocator configServicePropertySourceLocator(ConfigClientProperties configClientProperties) { ConfigServicePropertySourceLocator configServicePropertySourceLocator = new ConfigServicePropertySourceLocator(configClientProperties); configServicePropertySourceLocator.setRestTemplate(customRestTemplate()); return configServicePropertySourceLocator; } @Bean public ConfigClientProperties configClientProperties() { ConfigClientProperties clientProperties = new ConfigClientProperties(this.environment); clientProperties.setEnabled(false); return clientProperties; } /** * 自定义restTemplate ，在发送的时候带上token * * @return */ private RestTemplate customRestTemplate() { Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(); headers.put(\"token\", \"Bearer:\" + jwtToken); SimpleClientHttpRequestFactory requestFactory = new SimpleClientHttpRequestFactory(); requestFactory.setReadTimeout((60 * 1000 * 3) + 5000); RestTemplate template = new RestTemplate(requestFactory); if (!headers.isEmpty()) { template.setInterceptors( Arrays.&lt;ClientHttpRequestInterceptor&gt;asList(new GenericRequestHeaderInterceptor(headers))); } return template; } /** * 客户端请求过滤器 */ public static class GenericRequestHeaderInterceptor implements ClientHttpRequestInterceptor { private final Map&lt;String, String&gt; headers; public GenericRequestHeaderInterceptor(Map&lt;String, String&gt; headers) { this.headers = headers; } /** * 请求之前操作的方法 * * @param httpRequest * @param bytes * @param clientHttpRequestExecution * @return * @throws IOException */ @Override public ClientHttpResponse intercept(HttpRequest httpRequest, byte[] bytes, ClientHttpRequestExecution clientHttpRequestExecution) throws IOException { headers.entrySet().stream().forEach(header -&gt; { httpRequest.getHeaders().add(header.getKey(), header.getValue()); }); return clientHttpRequestExecution.execute(httpRequest, bytes); } }} 创建 Config Client Jwt 工程里的实体类，用于传递用户信息： 123456789101112@JsonIgnoreProperties(ignoreUnknown = true)@JsonInclude(JsonInclude.Include.NON_NULL)public class LoginRequest implements Serializable { @JsonProperty private String username; @JsonProperty private String password; //省略getter、setter方法} 123456789@JsonIgnoreProperties(ignoreUnknown = true)@JsonInclude(JsonInclude.Include.NON_NULL)public class Token implements Serializable { @JsonProperty private String token; //省略getter、setter方法} 在 Config Client Jwt 工程里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\com.springcloud.study.config.ConfigClientBootstrapConfiguration iii. 创建 Config Server 工程创建 Config Server 工程，配置工程里的 pom.xml 文件： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt;&lt;/dependency&gt; 创建 Config Server 工程里的 JwtAuthenticationRequest 实体类，用于传递用户名和密码： 12345678910111213141516public class JwtAuthenticationRequest implements Serializable { private String username; private String password; public JwtAuthenticationRequest() { super(); } public JwtAuthenticationRequest(String username, String password) { this.setUsername(username); this.setPassword(password); } //省略getter、setter方法} 创建 Config Server 工程里的 JwtAuthenticationResponse 实体类，用于返回 Token 信息： 12345678910public class JwtAuthenticationResponse implements Serializable { private final String token; public JwtAuthenticationResponse(String token) { this.token = token; } //省略getter、setter方法} 创建 Config Server 工程里的 JwtUser 实体类，用于返回 JWT 用户认证信息： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class JwtUser implements UserDetails { private final String username; private final String password; private final Collection&lt;? extends GrantedAuthority&gt; authorities; public JwtUser(String username, String password, Collection&lt;? extends GrantedAuthority&gt; authorities) { this.username = username; this.password = password; this.authorities = authorities; } @Override public String getUsername() { return username; } @JsonIgnore @Override public boolean isAccountNonExpired() { return true; } @JsonIgnore @Override public boolean isAccountNonLocked() { return true; } @JsonIgnore @Override public boolean isCredentialsNonExpired() { return true; } @JsonIgnore @Override public String getPassword() { return password; } @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() { return authorities; } @Override public boolean isEnabled() { return true; } @Override public String toString() { return \"JwtUser [username=\" + username + \", password=\" + password + \", authorities=\" + authorities + \"]\"; }} 创建 Config Server 工程里的 JWT Token 认证过滤器： 12345678910111213141516171819202122232425262728public class JwtAuthenticationTokenFilter extends UsernamePasswordAuthenticationFilter { @Autowired private UserDetailsService userDetailsService; @Autowired private JwtTokenUtil jwtTokenUtil; private final String tokenHeader = \"token\"; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest httpRequest = (HttpServletRequest) request; String authToken = httpRequest.getHeader(tokenHeader); String username = jwtTokenUtil.getUsernameFromToken(authToken); if (username != null &amp;&amp; SecurityContextHolder.getContext().getAuthentication() == null) { UserDetails userDetails = this.userDetailsService.loadUserByUsername(username); if (jwtTokenUtil.validateToken(authToken, userDetails)) { UsernamePasswordAuthenticationToken auth = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities()); auth.setDetails(new WebAuthenticationDetailsSource().buildDetails(httpRequest)); SecurityContextHolder.getContext().setAuthentication(auth); } } chain.doFilter(request, response); }} 创建 Config Server 工程里的 JWT 工具类，主要用于根据传递过来的用户信息生成 JWT 的 Token，或者是验证请求的 Token 是否合法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104@Componentpublic class JwtTokenUtil implements Serializable { private static final long serialVersionUID = -8652360919584431721L; private static final String CLAIM_KEY_USERNAME = \"sub\"; private static final String CLAIM_KEY_AUDIENCE = \"audience\"; private static final String CLAIM_KEY_CREATED = \"created\"; private static final String AUDIENCE_UNKNOWN = \"unknown\"; private static final String AUDIENCE_WEB = \"web\"; private Key secret = MacProvider.generateKey(); private Long expiration = (long) 120; // 2 minutes /** * 生成token * * @param userDetails * @return */ public String generateToken(JwtUser userDetails) { Map&lt;String, Object&gt; claims = new HashMap&lt;&gt;(); claims.put(CLAIM_KEY_USERNAME, userDetails.getUsername()); claims.put(CLAIM_KEY_AUDIENCE, AUDIENCE_WEB); claims.put(CLAIM_KEY_CREATED, new Date().getTime() / 1000); return generateToken(claims); } /** * jwt 实际生成token * * @param claims * @return */ private String generateToken(Map&lt;String, Object&gt; claims) { return Jwts.builder().setClaims(claims).setExpiration(generateExpirationDate()) .signWith(SignatureAlgorithm.HS512, secret).compact(); } private Date generateExpirationDate() { return new Date(System.currentTimeMillis() + expiration * 1000); } public String getUsernameFromToken(String token) { if (token == null) { return null; } String username; try { final Claims claims = getClaimsFromToken(token); username = claims.getSubject(); } catch (Exception e) { username = null; } return username; } private Claims getClaimsFromToken(String token) { Claims claims; final String tokenClean = token.substring(7); // remove \"Bearer:\" try { claims = Jwts.parser().setSigningKey(secret).parseClaimsJws(tokenClean).getBody(); } catch (Exception e) { claims = null; } return claims; } /** * 校验token的合法性 * * @param token * @param userDetails * @return */ public Boolean validateToken(String token, UserDetails userDetails) { JwtUser user = (JwtUser) userDetails; final String username = getUsernameFromToken(token); return (username.equals(user.getUsername()) &amp;&amp; !isTokenExpired(token)); } private Boolean isTokenExpired(String token) { final Date expiration = getExpirationDateFromToken(token); return expiration.before(new Date()); } public Date getExpirationDateFromToken(String token) { Date expiration; try { final Claims claims = getClaimsFromToken(token); expiration = claims.getExpiration(); } catch (Exception e) { expiration = null; } return expiration; }} 创建 Config Server 工程里的 JWT 认证端点类，主要用于在认证过程中，若认证未能通过直接返回 401 状态码： 123456789@Componentpublic class JwtAuthenticationEntryPoint implements AuthenticationEntryPoint, Serializable { @Override public void commence(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, AuthenticationException e) throws IOException, ServletException { // 没有认证通过将添加401 httpServletResponse.sendError(HttpServletResponse.SC_UNAUTHORIZED, \"Unauthorized\"); }} 创建 Config Server 工程里的账号验证类，主要用于客户端的验证用户名和密码： 12345678910111213141516171819202122232425@Servicepublic class MemberServiceImpl implements UserDetailsService { private static final PasswordEncoder BCRYPT = new BCryptPasswordEncoder(); @Value(\"${spring.security.user.name}\") private String hardcodedUser; @Value(\"${spring.security.user.password}\") private String password; @Override public JwtUser loadUserByUsername(String username) throws UsernameNotFoundException { // 对密码进行加密 String hardcodedPassword = BCRYPT.encode(password); if (username.equals(hardcodedUser) == false) { throw new UsernameNotFoundException(String.format(\"No user found with username '%s'.\", username)); } else { SimpleGrantedAuthority simpleGrantedAuthority = new SimpleGrantedAuthority(\"ROLE_USER\"); List&lt;GrantedAuthority&gt; grantedAuthorityList = new ArrayList&lt;GrantedAuthority&gt;(); grantedAuthorityList.add(simpleGrantedAuthority); return new JwtUser(hardcodedUser, hardcodedPassword, grantedAuthorityList); } }} 创建 Config Server 工程的 WebAuthenticationDetailsSourceImpl 类，用于将传递过来的对象数据封装到 JwtAuthenticationRequest 里面，该类负责将数据封装成 JSON 格式后返回给客户端： 12345678910111213141516171819202122232425@Componentpublic class WebAuthenticationDetailsSourceImpl implements AuthenticationDetailsSource&lt;HttpServletRequest, JwtAuthenticationRequest&gt; { @Override public JwtAuthenticationRequest buildDetails(HttpServletRequest request) { Gson gson = new Gson(); String json = new String(); String output = new String(); BufferedReader br; StringBuffer buffer = new StringBuffer(16384); JwtAuthenticationRequest jwtAuthenticationRequest = new JwtAuthenticationRequest(); try { br = new BufferedReader(new InputStreamReader(request.getInputStream())); while ((output = br.readLine()) != null) { buffer.append(output); } json = buffer.toString(); jwtAuthenticationRequest = gson.fromJson(json, JwtAuthenticationRequest.class); } catch (IOException e) { e.printStackTrace(); } return jwtAuthenticationRequest; }} 创建 Config Server 工程的 AuthenticationRestController 类，主要用于颁发 Token 给客户端： 1234567891011121314151617181920212223242526272829@RestControllerpublic class AuthenticationRestController { @Autowired private AuthenticationManager authenticationManager; @Autowired private JwtTokenUtil jwtTokenUtil; @Autowired private MemberServiceImpl userDetailsService; @Autowired private WebAuthenticationDetailsSourceImpl webAuthenticationDetailsSource; @RequestMapping(value = \"/auth\", method = RequestMethod.POST) public ResponseEntity&lt;?&gt; createAuthenticationToken(HttpServletRequest request) { JwtAuthenticationRequest jwtAuthenticationRequest = webAuthenticationDetailsSource.buildDetails(request); UsernamePasswordAuthenticationToken authToken = new UsernamePasswordAuthenticationToken(jwtAuthenticationRequest.getUsername(), jwtAuthenticationRequest.getPassword()); authToken.setDetails(jwtAuthenticationRequest); Authentication authenticate = authenticationManager.authenticate(authToken); SecurityContextHolder.getContext().setAuthentication(authenticate); JwtUser userDetails = userDetailsService.loadUserByUsername(jwtAuthenticationRequest.getUsername()); final String token = jwtTokenUtil.generateToken(userDetails); return ResponseEntity.ok(new JwtAuthenticationResponse(token)); }} 创建 Config Server 工程的 SecurityConfig 类，主要作用是进行安全认证和 Token 的过滤： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private JwtAuthenticationEntryPoint unAuthorizedHandler; @Autowired private WebAuthenticationDetailsSourceImpl webAuthenticationDetailsSource; @Bean @ConditionalOnMissingBean(AuthenticationManager.class) public UsernamePasswordAuthenticationFilter usernamePasswordAuthenticationFilter(AuthenticationManager authenticationManager) throws Exception { UsernamePasswordAuthenticationFilter usernamePasswordAuthenticationFilter = new UsernamePasswordAuthenticationFilter(); usernamePasswordAuthenticationFilter.setAuthenticationManager(authenticationManager); usernamePasswordAuthenticationFilter.setAuthenticationDetailsSource(webAuthenticationDetailsSource); return usernamePasswordAuthenticationFilter; } @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } @Bean public JwtAuthenticationTokenFilter authenticationTokenFilter() throws Exception { JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter = new JwtAuthenticationTokenFilter(); jwtAuthenticationTokenFilter.setAuthenticationManager(authenticationManager()); jwtAuthenticationTokenFilter.setAuthenticationDetailsSource(webAuthenticationDetailsSource); return jwtAuthenticationTokenFilter; } @Override protected void configure(HttpSecurity httpSecurity) throws Exception { httpSecurity .csrf().disable() .exceptionHandling().authenticationEntryPoint(unAuthorizedHandler) .and() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() .antMatchers(HttpMethod.GET, \"/\").permitAll() .antMatchers(\"/auth/**\").permitAll() .anyRequest().authenticated().and().formLogin() .authenticationDetailsSource(webAuthenticationDetailsSource) .permitAll(); // 添加自定义的jwt安全过滤的filter httpSecurity.addFilterBefore(authenticationTokenFilter(), UsernamePasswordAuthenticationFilter.class); httpSecurity.headers().cacheControl(); }} iiii. 创建 Config Client 工程这里的 Config Client 工程与上面 “客户端回退” 示例中的 Config Client 工程的代码一致，直接拷贝一份即可，这里不再累述。 Config Client 里的 pom.xml 文件，引入上面的 config-client-jwt 依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-client-jwt&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Config Client 里的 application.yml 配置文件： 123spring: application: name: config-client Config Client 里的 bootstrap.yml 配置文件，其中 password 和 username 是 Config Server 端配置需要的认证用户信息，endpoint 是一个 Config Server 访问验证授权的地址： 1234567891011spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 username: admin password: 123456 enabled: false endpoint: http://localhost:8001/auth #指定JWT的认证地址 iiiii. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9090/getConfigInfo，接口会返回 I am the git configuration file from dev environment，说明一切运行正常 config-client 特意填写错误的账号信息，然后重新启动 config-client 应用，观察控制台是否会出现 401 授权失败的错误 下篇 - Config 入门教程（高级篇） Config 入门教程 - 高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Config 入门教程 - 基础篇","url":"/posts/9de3ccde.html","text":"配置中心介绍什么是配置中心在集中式开发时代，配置文件已经基本足够了，因为那时配置的管理通常不会成为一个很大的问题。但是在互联网时代，应用都是分布式系统，部署在 N 台服务器上，想要去线上一台台地重启机器肯定不靠谱，并且维护成本也很高，所以配置中心应运而生。配置中心被用作集中管理不同环境（Dev、Test、Stage、Prod）和不同集群配置，以及在修改配置后将实时动态推送到应用上进行刷新。配置中心应具备的功能如下： Open API 业务无关性 高可用集群 配置生效监控 配合灰度与更新 一致性 K-V 存储 统一配置实时推送 配置全局恢复、备份与历史 主流配置中心对比 Spring Cloud Config、Apollo、Nacos 对比图 Spring Cloud Config、Netflix Archaius、Apollo、Disconf（已停止维护） 对比图 Config 配置中心概述Spring Cloud Config 是一个集中化外部配置的分布式系统，由服务端和客户端组成。它不依赖于注册中心，是一个独立的配置中心。Spring Cloud Config 支持多种存储配置信息的形式，目前主要有 JDBC、Vault、Native、SVN、Git，其中默认为 Git 存储形式，Git 版的工作原理如下图： 配置中心流转与整体支持图 Config 入门案例1. 版本说明在本文中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，特别声明除外，点击下载完整的案例代码。 2. 准备工作由于下面的 Spring Cloud Config 使用 Git 作为存储方式，因此需要提前在 Git 远程仓库（Github、Gitlab）中创建对应的仓库，然后往仓库里 Push 三个配置文件，分别是 config-client-dev.yml、config-client-prod.yml、config-client-test.yml，配置文件的内容如下： 123456server: port: 9001cn: springcloud: config: I am the git configuration file from dev environment 123456server: port: 9002cn: springcloud: config: I am the git configuration file from prod environment 123456server: port: 9003cn: springcloud: config: I am the git configuration file from test environment 3. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 4. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 添加 Config Server 需要的 application.yml 配置文件到工程中，其中 uri 指的是 Git 远程仓库的地址，private_key_file 是指 SSH 公钥文件；若 Git 仓库地址使用的是 HTTPS 协议，此时可以使用 usemame 、password 参数替代掉 private_key_file，两者分别代表 Git 访问的用户名和密码；search-paths 表示搜索特定目录下所有满足条件的配置文件，可以根据需求添加多个目录，目录之间用逗号隔开；label 指的是 Git 仓库的分支名称，如果不写，默认的分支为 master 123456789101112131415server: port: 8001spring: application: name: config-server cloud: config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: master 启动 Config Server 应用后，可以看到控制台会输出如下信息，这里只是截取关键信息，从控制台信息里的 Mapped 中可以看到配置信息和 URL 的映射关系；其中 name 是应用名称，也可以理解成 Git 仓库里配置文件的名称，profile 指的是对应激活的环境名，例如 dev、test、prod 等，label 指的是 Git 的分支 12345678910Mapped \"{[/{name}-{profiles}.yml || /{name}-{profiles}.yaml],methods=[GET]}\"Mapped \"{[/{name}/{profiles:.*[^-].*}],methods=[GET]}\"Mapped \"{[/{name}/{profiles}/{label:.*}],methods=[GET]}\"Mapped \"{[/{label}/{name}-{profiles}.properties],methods=[GET]}\"Mapped \"{[/{name}-{profiles}.json],methods=[GET]}\"Mapped \"{[/{label}/{name}-{profiles}.json],methods=[GET]}\"Mapped \"{[/{label}/{name}-{profiles}.yml || /{label}/{name}-{profiles}.yaml],methods=[GET]}\"Mapped \"{[/{name}/{profile}/**],methods=[GET],params=[useDefaultLabel]}\"Mapped \"{[/{name}/{profile}/{label}/**],methods=[GET]}\"Mapped \"{[/{name}/{profile}/{label}/**],methods=[GET],produces=[application/octet-stream]}\" 通过 http://127.0.0.1:8001/config-client/dev/master 访问 Config Server，接口返回的结果如下 此时观察 Config Server 控制台打印的信息可知，Config Server 会在本地的临时目录下面克隆远程仓库中的配置文件，本地临时目录的路径如下： 1o.s.c.c.s.e.NativeEnvironmentRepository : Adding property source: file:/tmp/config-repo-3558022506897899775/application.yml (document #0) 5. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-config-client 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Client 的主启动类： 1234567@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息： 1234567891011121314@Component@ConfigurationProperties(prefix = \"cn.springcloud\")public class ConfigProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 1234567891011@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping(\"/getConfigInfo\") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中： 123spring: application: name: config-client 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中，这些配置为什么要放在 bootstrap.yml 里，而不放在 application.yml 中呢？这与 Spring Boot 的加载顺序有关，bootstrap.yml 文件会优先于 application.yml 加载，因此会去加载远程的配置文件信息 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 6. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 重启 config-client 应用，再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 刷新配置中心信息Config Client 手动刷新为了不用重启 Congit Client 应用也可以获取到最新的配置信息，下面将讲解在 Congit Client 端如何手动刷新配置信息，点击下载完整的案例代码。 i. 准备工作本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 ii. 创建 Config Server 工程由于本示例是在上面的入门案例的基础上进行改造的，因此 Config Server 工程与上面入门案例中的 Config Server 工程完全一样，只需拷贝一份即可，由于篇幅有限，这里不再累述。 iii. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Config Client 需要的 application.yml 配置文件到工程中，management.endpoints.web.exposure.include=* 表示暴露所有端点，默认情况下只暴露 info、health 端点，management.endpoint.health.show-details=always 表示总是显示详细信息 1234567891011spring: application: name: config-clientmanagement: endpoints: web: exposure: include: \"*\" health: show-details: always 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 往 Config Client 添加安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息。注意，这里的 ConfigProperties 与 ConfigController 类都需要额外添加 @RefreshScope 注解，被 @RefreshScope 注解修饰的 Bean 都是延迟加载的，只有在第一次访问时才会被初始化；刷新 Bean 也是同理，刷新后下次访问会创建一个新的对象 123456789101112131415@Component@RefreshScopepublic class ConfigProperties { @Value(\"${cn.springcloud.config}\") private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 123456789101112@RefreshScope@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping(\"/getConfigInfo\") public String getConfigInfo() { return configProperties.getConfig(); }} iiii. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 通过 Post 请求访问 http://127.0.0.1:9001/actuator/refresh，让 Config Client 刷新配置信息 再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 结合 Spring Cloud Bus 热更新Spring Cloud Config 结合 Spring Cloud Bus 进行刷新的整体流程图如下，当用户更新配置信息时，触发 Git Hook 配置地址的调用，Config Server 接收到 Refresh 请求后，通过 Bus 将消息发送到 Config Client，当 Config Client 接收到消息后会重新发送请求加载配置信息，大体流程就是这样。下面将使用 RabbitMQ 作为消息中间件，由于篇幅有限，这里不再讲解 RabbitMQ 的安装和使用方法，点击下载完整的案例代码。 1. 准备工作本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. 创建 Config Server 工程创建 Config Server 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖，第四个是消息中间件的依赖： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Server 的主启动类，增加 @EnableConfigServer 注解： 12345678@EnableConfigServer@SpringBootApplicationpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 创建 Config Server 的安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 添加 Config Server 需要的 application.yml 配置文件到工程中，其中包括 RabbitMQ 的地址和账号信息，spring.cloud.bus.trace.enabled=true 表示开启消息跟踪： 12345678910111213141516171819202122232425262728293031server: port: 8001spring: application: name: config-server rabbitmq: port: 5672 host: localhost username: admin password: admin cloud: bus: trace: enabled: true config: server: git: uri: git@github.com:xxxxx/spring-cloud-config-study-repo.git search-paths: spring-cloud-config-study-repo/ strictHostKeyChecking: false private_key_file: /root/.ssh/id_rsa.pub label: mastermanagement: endpoints: web: exposure: include: \"*\" health: show-details: always 3. 创建 Config Client 工程创建 Config Client 的 Maven 工程，配置工程里的 pom.xml 文件，第二个依赖是端点的访问依赖，第三个依赖是安全的依赖，第四个是消息中间件的依赖： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 往 Config Client 添加安全配置类，主要作用是关闭端点访问的安全校验： 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} 为了更好地观察拉取到的 Git 上面的配置，这里需要创建一个 Controller 用于访问返回配置信息，同时还需要创建一个实体，用于注入远程配置上的信息；注意，这里的 ConfigProperties 与 ConfigController 类都需要额外添加 @RefreshScope 注解 123456789101112131415@Component@RefreshScopepublic class ConfigProperties { @Value(\"${cn.springcloud.config}\") private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 123456789101112@RefreshScope@RestControllerpublic class ConfigController { @Autowired public ConfigProperties configProperties; @GetMapping(\"/getConfigInfo\") public String getConfigInfo() { return configProperties.getConfig(); }} 添加 Config Client 需要的 application.yml 配置文件到工程中，其中包括 RabbitMQ 的地址和账号信息，spring.cloud.bus.trace.enabled=true 表示开启消息跟踪： 1234567891011121314151617181920spring: application: name: config-client rabbitmq: port: 5672 host: localhost username: admin password: admin cloud: bus: trace: enabled: truemanagement: endpoints: web: exposure: include: \"*\" health: show-details: always 添加 Config Client 需要的 bootstrap.yml 配置文件到工程中： 1234567spring: cloud: config: name: config-client #需要从远程Git仓库读取的配置文件的名称，注意没有\"yml\"文件后缀，可以写多个，通过逗号隔开 profile: dev #本次访问的配置项 label: master #Git分支的名称 uri: http://127.0.0.1:8001 #Config Server的地址 4. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 通过 Post 请求访问 http://127.0.0.1:8001/actuator/bus-refresh，让 Config Server 通过 Spring Cloud Bus 发送消息通知所有 Config Client 刷新配置信息 再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了提示：可以将 Spring Cloud Bus 的刷新地址配置在 WebHooks 上面，这样在 Git 仓库每次有新文件提交（Push）之后，所有 Config Client 都会自动执行刷新的动作 Config Client 自动刷新（任务调度）在有些应用上面，不需要在服务端批量推送消息的时候，客户端本身需要获取参数变化的情况，此时可以使用客户端的自动刷新功能，其原理是使用任务调度执行刷新操作，点击下载完整的案例代码 1. 准备说明本示例用到上面入门案例中 Git 仓库里的配置文件，包括 config-client-dev.yml、config-client-prod.yml、config-client-test.yml。 2. Config Refresh Autoconfig 工程创建 Config Refresh Autoconfig 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Config Refresh Autoconfig 工程里的自动配置类，添加相关注解，使其在 Spring Boot 启动的时候将其加载。在该类中，主要是注入了端点类，通过定时任务和刷新时间，进行配置请求刷新。由于在类中是直接调用了 RefreshEndpoint 的 refresh() 方法，所以对于 F 版的安全机制不需要对端点进行打开也可以，但需要依赖 spring-boot-starter-actuator，否则无法注入 RefreshEndpoint 的 Bean： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@ConditionalOnClass(RefreshEndpoint.class)@ConditionalOnProperty(\"spring.cloud.config.refreshInterval\")@AutoConfigureAfter(RefreshAutoConfiguration.class)@Configurationpublic class ConfigAutoRefreshConfiguration implements SchedulingConfigurer { private static final Logger logger = LoggerFactory.getLogger(ConfigAutoRefreshConfiguration.class); /** * 间隔刷新时间 */ @Value(\"${spring.cloud.config.refreshInterval}\") private long refreshInterval; /** * 刷新的端点 */ @Autowired private RefreshEndpoint refreshEndpoint; @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) { final long interval = getRefreshIntervalInMilliseconds(); logger.info(String.format(\"Scheduling config refresh task with %s second delay\", refreshInterval)); scheduledTaskRegistrar.addFixedDelayTask(new IntervalTask(new Runnable() { @Override public void run() { refreshEndpoint.refresh(); } }, interval, interval)); } /** * 以毫秒为单位返回刷新间隔 * * @return */ private long getRefreshIntervalInMilliseconds() { return refreshInterval * 1000; } /** * 如果没有在上下文中注册，则启用调度程序 */ @ConditionalOnMissingBean(ScheduledAnnotationBeanPostProcessor.class) @EnableScheduling @Configuration protected static class EnableSchedulingConfigProperties { }} 在 Config Refresh Autoconfig 工程里创建 /src/main/resources/META-INF/spring.factories 配置文件，添加上面的自动配置类： 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.springcloud.study.config.ConfigAutoRefreshConfiguration 3. Cofnig Client 工程这里 Cofnig Client 工程的代码基本与上面的 “Config Client 手动刷新” 示例的代码一致，拷贝一份即可，这里不再累述。 Cofnig Client 工程的 pom.xml 文件，引入 config-refresh-autoconfig 依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.springcloud.study&lt;/groupId&gt; &lt;artifactId&gt;config-refresh-autoconfig&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Cofnig Client 工程的 application.yml 文件，refreshInterval: 15 表示每 15 秒刷新一次配置信息： 123456spring: application: name: config-client cloud: config: refreshInterval: 15 4. Cofnig Server 工程这里 Cofnig Server 工程的代码基本与上面的 “Config Client 手动刷新” 示例的代码一致，拷贝一份即可，这里不再累述。 5. 测试结果 依次启动 config-server、config-client 应用 访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment 更改 Git 远程仓库中的 config-client-dev.yml 配置文件，将内容修改为 I am the git configuration file from dev environment updated 等待一段时间后（15 秒），再次访问 http://127.0.0.1:9001/getConfigInfo，接口会返回 I am the git configuration file from dev environment updated，说明配置更新了 下篇 - Config 入门教程（中级篇） Config 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Zuul 入门教程 - 高级篇","url":"/posts/9652d40e.html","text":"上篇 - Zuul 入门教程（中级篇） Zuul 入门教程 - 中级篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，特别声明除外。 Zuul 多层负载痛点场景在 Spring Cloud 微服务架构体系中，所有请求的前门的网关 Zuul 承担着请求转发的主要功能，对后端服务起着举足轻重的作用。当业务体量猛增之后，得益于 Spring Cloud 的横向扩展能力，往往加节点、加机器就可以使得系统支撑性获得大大提升，但是仅仅加服务而不加网关是会有性能瓶颈的，单一 Zuul 节点的处理能力十分有限。因此扩张节点往往是微服务连带 Zuul 一起扩张，一般会部署一个 Zuul 集群来横向扩展微服务应用，然后再在请求上层加一层软负载，通常是使用 Nginx 均分请求到 Zuul 集群（如下图）。此时若其中一台 Zuul 服务挂掉了，由于从 Nginx 到 Zuul 其实是没有什么关联性，如果 Zuul 服务宕掉，Nginx 还是会把请求导向到 Zuul 服务，导致从 Nginx 到这 Zuul 节点的请求会全部失效，在 Nginx 没有采取相关应对措施的情况下，这是十分严重的问题。 解决方案OpenResty 整合了 Nginx 与 Lua，实现了可伸缩的 Web 服务器，内部集成了大量精良的 Lua 库、第三方模块以及多数的依赖项，能够非常快捷地搭建处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。开发者可以使用 Lua 脚本模块与注册中心构建一个服务动态增减的机制，通过 Lua 获取注册中心状态为 UP 的服务，动态地加入到 Nginx 的负载均衡列表中去，由于这种架构模式涉及了不止一个负载均衡器，一般称其为 “多层负载”（如下图）。 目前 Spring Cloud 中国社区针对这一场景开源了相关的 Lua 插件源码，GitHub 地址在这里，核心配置如下。实现原理是使用 Lua 脚本定时根据配置的服务名与 Eureka 地址，去拉取该服务的信息，在 Eureka 里面提供 /eureka/apps/(serviceld) 端点，返回服务的注册信息，所以只需要取用状态为 UP 的服务，将它的地址加入 Nginx 负载列表即可。此项目使得 Nginx 与 Zuul 之间 拥有一个动态感知能力，不用手动配置 Nginx 负载与 Zuul 负载，这样对于应用弹性扩展是极其友好的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455http { #sharing cache area lua_shared_dict dynamic_eureka_balancer 128m; init_worker_by_lua_block { -- init eureka balancer local file = require \"resty.dynamic_eureka_balancer\" local balancer = file:new({dict_name=\"dynamic_eureka_balancer\"}) --eureka server list balancer.set_eureka_service_url({\"127.0.0.1:8888\", \"127.0.0.1:9999\"}) --eureka basic authentication --use this setting if eureka has enabled basic authentication. --note: basic authentication must use BASE64 encryption in `user:password` format --balancer.set_eureka_service_basic_authentication(\"\") --The service name that needs to be monitored balancer.watch_service({\"zuul\", \"client\"}) } upstream springcloud_cn { server 127.0.0.1:666; # Required, because empty upstream block is rejected by nginx (nginx+ can use 'zone' instead) balancer_by_lua_block { --The zuul name that needs to be monitored local service_name = \"zuul\" local file = require \"resty.dynamic_eureka_balancer\" local balancer = file:new({dict_name=\"dynamic_eureka_balancer\"}) --balancer.ip_hash(service_name) --IP Hash LB balancer.round_robin(service_name) --Round Robin LB } } server { listen 80; server_name localhost; location / { proxy_pass http://springcloud_cn/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} Zuul 应用优化概述Zuul（这里指 Zuul1.0 版本，Zuul2.0 版本之后使用了 Netty 的异步非阻塞模型）在给微服务体系带来诸多便利的同时，也饱受着性能的争议，这一切还要从它的底层架构说起。Zuul 是建立在 Servlet 的同步阻塞架构基础上，所以在处理逻辑上面是和线程密不可分的，每一次请求都需要从线程池获取一个线程来维持 I/O 操作，路由转发的时候又需要从 HTTP 客户端获取线程来维持连接，这就会导致一个组件占用两个线程资源的情况。所以，在 Zuul 的使用中，对这部分的优化是很有必要的，一个好的优化体系会使得应用支撑的业务体量更大，也能最大化利用服务器资源。在这里，将对 Zuul 的优化分为以下几个类型： 容器优化：内置容器 Tomcat 与 Undertow 的比较与参数设置 组件优化：内部集成的组件优化，如 Hystrix 线程隔离、Ribbon. HttpClient 与 OkHttp 选择 JVM 参数优化：适用于网关应用的 JVM 参数建议 内部优化：一些内部原生参数，或者内部源码，以一种更恰当的方式重写它们 容器优化关于 Spring Boot 优化的文章，网上有很多，不过大部分都会提到把默认的内嵌容器 Tomcat 替换成 Undertow。其中 Undertow 翻译为” 暗流”，即平静的湖面下暗藏着波涛汹涌，所以 JBoss 公司取其意，为它的轻量级高性能容器命名。Undertow 提供阻塞或基于 XNIO 的非阻塞机制，它的包大小不足 1MB，内嵌模式运行时的堆内存占用只有 4MB 左右。要使用 Undertow ，只需要在配置文件中移除 Tomcat，添加 Undertow 的依赖 即可： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupld&gt;org.springframework.boot&lt;/groupld&gt; &lt;artifactld&gt;spring-boot-starter-tomcat&lt;/artifactld&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupld&gt;org.springframework.boot&lt;/groupld&gt; &lt;artifactld&gt;spring-boot-starter-undertow&lt;/artifactld&gt;&lt;/dependency&gt; Undertow 的主要配置参数如下： 组件优化在 Spring Cloud 微服务体系中，Zuul 是一个容易被忽略优化，但是集成组件最多，功能最强大的组件。Zuul 网关主要用于智能路由，同时也支持认证、区域和内容感知路由，将多个底层服务聚合成统一的对外 API。所以要更好地使用 Zuul，就免不了要对它集成的组件进行优化，使它可以更好地支撑服务集群。 Hystrix 优化由于 Zuul 默认集成了 Hystrix 熔断器，使得网关应用具有弹性、容错的能力。但是如果使用缺省的配置，可能会遇到种种问题，其中最常见的问题就是当启动 Zuul 应用之后，第一次请求往往会失败。根本原因是 Hystrix 默认的超时时间是 1 秒，如果超过这个时间尚未作出响应，将会进入 fallback 代码。由于在处理第一次请求的时候，Zuul 内部要初始化很多类信息，这是十分耗时的，如果这个响应时间超过 1 秒，就会出现请求失败的问题。解决方式有以下两种： 禁用 Hystrix 的超时时间： hystrix.command.default.execution.timeout.enabled=false 加大 Hystrix 的超时时间： hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000 Zuul 中关于 Hystrix 的配置还有一个很重要的点，那就是 Hystrix 的线程隔离模式的选择，包括线程池隔离模式（THREAD）或者信号量隔离模式（SEMAPHORE）。在网关中，对资源的使用是应该受到严格控制的，如果不加限制，会导致资源滥用，在恶劣的线上环境下就容易引起服务雪崩。两种隔离模式对比，如下图所示。 Hystrix 切换隔离模式的配置方式： 1hystrix.command.default.execution.isolation.strategy=Thread | Semaphore Hystrix 隔离模式选择总结，当应用需要与外网交互，由于网络开销比较大与请求比较耗时，这时选用线程隔离策略，可以保证有剩余的容器（Tomcat &amp; Undertow &amp; Jetty）线程可用，而不会由于外部原因使得线程一直处于阻塞或等待状态，可以快速失败返回。但当微服务应用只在内网交互，并且体量比较大，这时使用信号量隔离策略就比较好，因为这类应用的响应通常会非常快（由于在内网），不会占用容器线程太长时间，可以减少线程上下文切换的开销，提高应用运转的效率，也可以起到对请求进行全局限流的作用。 Ribbon 优化这里主要是讲 Ribbon 的超时重试优化，在 Spring Cloud 中有多种发送 HTTP 请求的方式可以与 Zuul 结合，RestTemplate、Ribbon 或者 Feign，但是无论选择哪种，都可能出现请求失败的情况，这在复杂的互联网环境是不可避免的。Zuul 作为一个网关中间件，在出现偶然请求失败时进行适当的重试是十分必要的，重试可以有效地避免一些突发原因引起的请求丢失。Zuul 中的重试机制是配合 Spring Retry 与 Ribbon 来使用的。 在 pom.xml 引入 Spring Retry 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;org.springframework.retry&lt;/groupld&gt; &lt;artifactld&gt;spring-retry&lt;/artifactld&gt;&lt;/dependency&gt; 在 application.yml 里添加重试相关的配置内容： 123456789101112131415161718#Zuul开启重试，D版之后默认为false，需要手动开启zuul: retryable: true#Ribbon的重试机制配置ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true#SpringCloud内部默认已开启负载均衡重试，这里列出来说明这个参数比较重要spring: cloud: loadbalancer: retry: enabled: true 配置当中的 ConnectTimeout 与 ReadTimeou 是当 HTTP 客户端使用 Apache HttpClient 的时候生效的，这个超时时间最终会被设置到 Apache HttpClient 中去。在设置的时候要结合 Hystrix 的超时时间来综合考虑，针对不同的应用场景，设置太小会导致很多请求失败，设置太大会导致熔断功能控制性变差，所以需要经过压力测试得来。Zuul 同时也支持对单个映射规则进行重试 zuul.routes.&lt;route&gt;.retryable=true，需要注意的是，在某些对幂等要求比较高的使用场景下，要慎用重试机制，因为如果没有相关处理的话，出现幂等问题是十分有可能的。 内部优化在官方文档中，Zuul 部分开篇讲了 zuul.max.host.connections 属性拆解成了 zuul.host.maxTotalConnections（服务 HTTP 客户端最大连接数）与 zuul.host.maxPerRouteConnections（每个路由规则 HTTP 客户端最大连接数），默认值分别为 200 与 20，如果使用 Apache HttpClient 的时候这两个配置参数则有效，如果使用 OkHttp 则无效。在 Zuul 中还有一个超时时间，使用 serviceld 映射与 url 映射的设置是不一样的，如果使用 serviceld 映射，ribbon.ReadTimeout 与 ribbon.SocketTimeout 生效；如果使用 url 映射，应该设置 zuul.host.connect-timeout-millis 与 zuul.host.socket-timeout-millis 参数。 Zuul 源码解析（待续） var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Zuul 入门教程 - 中级篇","url":"/posts/6f728f64.html","text":"上篇 - Zuul 入门教程（基础篇） Zuul 入门教程 - 基础篇 前言版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，特别声明除外。 Zuul Filter 链工作原理Zuul 的核心逻辑是由一系列紧密配合工作的 Filter 来实现的，它们能够在进行 HTTP 请求或者响应的时候执行相关操作。可以说，没有 Filter 责任链，就没有如今的 Zuul，更不可能构成功能丰富的” 网关 “，Zuul Filter 的主要特性有以下几点： Filter 的类型：Filter 的类型决定了此 Filter 在 Filter 链中的执行顺序，可能是路由动作发生前，可能是路由动作发生时，可能是路由动作发生后，也可能是路由过程发生异常时 Filter 的执行顺序：同一种类型的 Filter 可以通过 filterOrder() 方法来设定执行顺序，一般会根据业务的执行顺序需求，来设定自定义 Filter 的执行顺序 Filter 的执行条件：Filter 运行所需要的标准或条件 Filter 的执行效果：符合某个 Filter 执行条件，产生的执行效果 Zuul 内部提供了一个动态读取、编译和运行这些 Filter 的机制，Filter 之间不直接通信，在请求线程中会通过 RequestContext 来共享状态，它的内部是用 ThreadLocal 实现的，当然也可以在 Filter 之间使用 ThreadLocal 来收集自己需要的状态或数据。Zuul 中不同类型 Filter 的执行逻辑核心在 com.netflix.zuul.http.ZuulServlet 类中定义，该类相关代码和官方流程图如下所示： 12345678910111213141516171819202122232425262728293031try { this.init((HttpServletRequest)servletRequest, (HttpServletResponse)servletResponse); RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); try { this.preRoute(); } catch (ZuulException var13) { this.error(var13); this.postRoute(); return; } try { this.route(); } catch (ZuulException var12) { this.error(var12); this.postRoute(); return; } try { this.postRoute(); } catch (ZuulException var11) { this.error(var11); }} catch (Throwable var14) { this.error(new ZuulException(var14, 500, \"UNHANDLED_EXCEPTION_\" + var14.getClass().getName()));} finally { RequestContext.getCurrentContext().unset();} 上面的官方流程图有些问题，其中 Post Filter 抛错之后进入 Error Filter，然后再进入 Post Filter 是有失偏颇的。实际上 Post Filter 抛错分两种情况： 在 Post Filter 抛错之前，Pre、Route Filter 没有抛错，此时会进入 ZuulException 的逻辑，打印堆栈信息，然后再返回 status = 500 的 Error 信息 在 Post Filter 抛错之前，Pre、Route Filter 已有抛错，此时不会打印堆栈信息，直接返回 status = 500 的 Error 信息 也就是说，整个责任链流程终点不只是 Post Filter，还可能是 Error Filter，重新整理后的流程图 Filter 的生命周期Zuul 一共有四种不同生命周期的 Filter，分别是： pre：在 Zuul 按照映射规则路由到下级服务之前执行，如果需要对请求进行预处理，比如鉴权、限流等，都应考虑在此类 Filter 里实现 route：这类 Filter 是 Zuul 路由动作的执行者，是 Apache HttpClient 或 Netflix Ribbon 构建和发送原始 HTTP 请求的地方，目前已支持 OkHttp post：这类 Filter 是在源服务返回结果或者异常信息发生后执行的，如果需要对返回信息做一些处理，则在此类 Filter 进行处理 error：在整个生命周期内如果发生异常，则会进入 Error Filter，可做全局异常处理 在实际项目中，往往需要自实现以上类型的 Filter 来对请求链路进行处理，根据业务的需求，选取相应生命周期的 Filter 来达成目的。在 Filter 之间，通过 com.netflix.zuul.context. RequestContext 类来进行通信，内部采用 ThreadLocal 保存每个请求的一些信息，包括请求路由、错误信息、HttpServletRequest、HttpServletResponse，这使得一些操作是十分可靠的，它还扩展了 ConcurrentHashMap，目的是为了在处理过程中保存任何形式的信息。 Zuul 的原生 Filter首先官方文档提到，Zuul Server 如果使用 @EnableZuulProxy 注解搭配 Spring Boot Actuator，会多出两个管控端点，具体配置如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 123456# 暴露所需的端点management: endpoints: web: exposure: include: health, info, routes, filters 端点 /actuator，查看截图 端点 /filters：返回当前 Zuul Server 中所有已注册生效的 Filter，查看截图 端点 /routes：返回当前 Zuul Server 中所有已生成的映射规则，加上 /details 可查看详细信息，查看截图 从端点 /filters 返回的数据可以清楚地看到所有已注册生效的 Filter 信息，包括：Filter 实现类路径、Filter 执行次序、是否被禁用、是否静态。根据返回的内容，将前面的图稍作扩展，即可得到 Zuul 内置 Filter 与生命周期的组合流程图 。 Zuul 内置了各种 Filter（见上表），以上是使用 @EnableZuulProxy 注解后注册的 Filter，如果使用 @EnableZuulServer 将缺少 PreDecorationFilter、RibbonRoutingFilter、SimpleHostRoutingFilter 这些原生 Filter。如果有特殊的业务需求，可以采取替代实现的方式，覆盖掉其原生代码，也可以釆取禁用策略，语法如下：zuul.&lt;SimpleClassName&gt;.&lt;filterType&gt;.disable=true 多级业务处理自定义 Filter在 Zuul 的 Filter 链体系中，可以把一组业务逻辑细分，然后封装到一个个紧密结合的 Filter 中，设置处理顺序，组成一组 Filter 链。这在一些业务场景下十分实用，以致除 Zuul 以外的网关中间件几乎都有类似的实现。在 Zuul 里实现自定义 Filter，只需继承 ZuulFilter 类即可，ZuulFilter 是一个抽象类，需要实现它的以下几个方法： String filterType ()：使用返回值设定 Filter 类型，可以设置为 pre、route、post、error 类型。 int filterOrder ()：使用返回值设定 Filter 执行次序 boolean shouldFilter ()：使用返回值设定该 Filter 是否执行，可以作为开关来使用 Object run ()：Filter 里面的核心执行逻辑，业务处理在此编写 在 Zuul 里自定义 Filter 的示例代码如下： 1234567891011121314151617181920212223242526272829303132import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.exception.ZuulException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.PRE_TYPE;public class FirstPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(FirstPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info(\"==&gt; first custom zuul filter\"); return null; }} 12345678@Configurationpublic class CommonConfiguration { @Bean public FirstPreFilter firstPreFilter() { return new FirstPreFilter(); }} 业务处理实战Zuul 作为一个 “网关” 组件，原始的功能往往不能满足实际业务需求，为了解决这个问题，官方预留了 API，使得开发者能够实现自定义业务处理，加入 Zuul 的逻辑流程。下面模拟一个业务需求，使用 SecondPreFilter 来验证是否传入 a 参数，使用 ThirdPreFilter 来验证是否传入 b 参数，最后在 PostFilter 里边统一处理返回内容，查看流程图 ，点击下载完整的示例代码。 123456789101112131415161718192021222324252627282930313233343536373839404142public class SecondPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(SecondPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 2; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info(\"==&gt; second custom zuul pre filter\"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //从上下文获取HttpServletRequest HttpServletRequest request = context.getRequest(); //从request尝试获取a参数值 String a = request.getParameter(\"a\"); if (null == a) { //对该请求禁止路由，也就是禁止访问下游服务 context.setSendZuulResponse(false); //保存于上下文，作为同类型下游Filter的执行开关 context.set(\"logic-is-success\", false); //设定responseBody供PostFilter使用 context.setResponseBody(\"{\\\"status\\\":500,\\\"message\\\":\\\"param a is null !\\\"}\"); return null; } //设置避免报空异常 context.set(\"logic-is-success\", true); return null; }} 12345678910111213141516171819202122232425262728293031323334353637383940414243public class ThirdPreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(ThirdPreFilter.class); @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 3; } @Override public boolean shouldFilter() { RequestContext context = RequestContext.getCurrentContext(); return (boolean) context.get(\"logic-is-success\"); } @Override public Object run() throws ZuulException { logger.info(\"==&gt; third custom zuul pre filter\"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //从上下文获取HttpServletRequest HttpServletRequest request = context.getRequest(); //从request尝试获取b参数值 String b = request.getParameter(\"b\"); if (null == b) { //对该请求禁止路由，也就是禁止访问下游服务 context.setSendZuulResponse(false); //保存于上下文，作为同类型下游Filter的执行开关，假定后续还有自定义Filter当设置此值 context.set(\"logic-is-success\", false); //设定responseBody供PostFilter使用 context.setResponseBody(\"{\\\"status\\\":500,\\\"message\\\":\\\"param b is null !\\\"}\"); return null; } //设置避免报空异常 context.set(\"logic-is-success\", true); return null; }} 1234567891011121314151617181920212223242526272829303132333435363738public class PostFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(SecondPreFilter.class); @Override public String filterType() { return POST_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { logger.info(\"==&gt; custom zuul post filter\"); //从RequestContext获取上下文 RequestContext context = RequestContext.getCurrentContext(); //处理返回中文乱码 context.getResponse().setCharacterEncoding(\"UTF-8\"); //获取上下文中保存的responseBody String responseBody = context.getResponseBody(); //如果responseBody不为空，则说明流程有异常发生 if (null != responseBody) { //设定返回状态码 context.setResponseStatusCode(500); //替换响应报文 context.setResponseBody(responseBody); } return null; }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 12SecondPreFilter : ==&gt; second custom zuul pre filterSecondPreFilter : ==&gt; custom zuul post filter 访问 http://127.0.0.1:8092/provider/service/provider/add?a=3，日志输出如下： 123SecondPreFilter : ==&gt; second custom zuul pre filterThirdPreFilter : ==&gt; third custom zuul pre filterSecondPreFilter : ==&gt; custom zuul post filter 使用 Groovy 编写 FilterGroovy 语言是基于 JVM 的一门动态语言，它结合了 Python、 Ruby 和 Smalltalk 的许多强大特性，支持无缝引入 Java 代码与 Java 库，常常被用作 Java 的扩展语言来使用。它的语法与 Java 类似，书写起来比 Java 略为简洁，是一门很优秀的语言。Zuul 中提供 Groovy 的编译类 com.netflix.zuul.groovy.GroovyCompiler，结合 com.netflix.zuul.groovy.GroovyFileFilter 类，可以使用 Groovy 来编写自定义的 Filter。也许到这里，很多开发者认为它在 Zuul 中没有存在的必要，但是当得知它可以不用编译（不用打进工程包），可以放在服务器上任意位置，可以任何时候修改由它编写的 Filter，且修改过后还不用重启服务的时候，就会知道它有多实用了。下面使用 Groovy 编写自定义 Filter 作为例子，点击下载完整的示例代码。 首先添加 Groovy 相关的依赖，需要指定 Groovy 的版本来覆盖 SpringBoot 中的 Groovy 版本，建议这里不要使用阿里云的 Maven 仓库，否则会找不到最新版本的 Groovy： 123456789101112&lt;properties&gt; &lt;groovy.version&gt;3.0.3&lt;/groovy.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt; &lt;artifactId&gt;groovy-all&lt;/artifactId&gt; &lt;version&gt;${groovy.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 使用 Groovy 编写自定义 Filter，并将 Groovy 的源码文件 GroovyFilter.groovy 保存在 /tmp/groovy/ 目录下： 1234567891011121314151617181920212223242526272829303132333435363738import com.netflix.zuul.ZuulFilterimport com.netflix.zuul.context.RequestContextimport com.netflix.zuul.exception.ZuulExceptionimport javax.servlet.http.HttpServletRequestimport static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.PRE_TYPEclass GroovyFilter extends ZuulFilter { @Override String filterType() { return PRE_TYPE } @Override int filterOrder() { return 10 } @Override boolean shouldFilter() { return true } @Override Object run() throws ZuulException { println(\"This is Groovy Filter!\") HttpServletRequest request = RequestContext.currentContext.request as HttpServletRequest Iterator headerIt = request.getHeaderNames().iterator() while (headerIt.hasNext()) { String name = (String) headerIt.next() String value = request.getHeader(name) println(\"header: \" + name + \": \" + value) } return null }} 注册 GroovyFilter.groovy： 12345678910111213141516@Componentpublic class GroovyRunner implements CommandLineRunner { @Override public void run(String... args) throws Exception { MonitoringHelper.initMocks(); FilterLoader.getInstance().setCompiler(new GroovyCompiler()); try{ FilterFileManager.setFilenameFilter(new GroovyFileFilter()); // 指定Groovy源码文件的绝对路径，对路径每隔20秒扫描一次 FilterFileManager.init(20, \"/tmp/groovy\"); }catch(Exception e){ throw new RuntimeException(e); } }} 测试： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 123456This is Groovy Filter!header: host: 127.0.0.1:8092header: connection: keep-aliveheader: cache-control: max-age=0header: upgrade-insecure-requests: 1... 将 /tmp/groovy/GroovyFilter.groovy 里的 println(\"This is Groovy Filter!\") 更改为 println(\"This is Groovy Filter Modify!\") 等待 20 秒后，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，日志输出如下： 123456This is Groovy Filter Modify!header: host: 127.0.0.1:8092header: connection: keep-aliveheader: cache-control: max-age=0header: upgrade-insecure-requests: 1... Zuul 权限集成应用权限概述权限，是整个微服务体系乃至软件业永恒的话题，有资源的地方，就有权限约束。以往在构建单体应用的时候，比较流行的方式是使用 Apache Shiro，开发者的印象都是 Apache Shiro 比 Spring Security 上手容易，学习成本相对较小，但是到了 Spring Cloud 这里，面对成千上万的服务，而且服务之间无状态，此时 Apache Shiro 难免显得力不从心，所以 Spring Cloud 没有选择它也是有原因的。在解决方案的选择上面，传统的譬如单点登录（SSO），或者分布式 Session，要么致使权限服务器集中化导致流量臃肿，要么需要实现一套复杂的存储同步机制，都不是最好的解决方案。作为 Spring Cloud 微服务体系流量前门的 Zuul，除去与它特性毫无相关的实现方式，比较好的方式有： 自定义权限认证 Filter由于 Zuul 对请求转发全程的可控性，可以在 Requestcontext 的基础上做任何事情，例如只需要设置一个执行顺序靠前的 Filter，就可以专门对请求的特定内容做权限认证。这种方式的优点是实现灵活度高，可整合已有权限系统，对原始系统微服务化特别友好；缺点是需要开发一套新的逻辑，维护增加成本，而且也会使得调用链路变得紊乱。 OAuth2.0 + JWT 认证OAuth2.0 是业界对于 “授权 - 认证” 比较成熟的面向资源的授权协议。举个例子，除了可以使用本站用户名与密码登录 Spring Cloud 中国社区，还可以使用第三方应用登录，比如：GitHub、QQ 等登录方式。第三方登录功能对用户十分有亲和力，而 Oauth2.0 就是用于定义 Spring Cloud 中国社区与用户之间的那个 “授权层” 的。Oauth2.0 的认证原理图如下，在整个流程中，用户是资源拥有者，其关键还是在于客户端需要资源拥有者的授权，这个过程就相当于键入密码或者是其他第三方登录，触发了这个操作之后，客户端就可以向授权服务器申请 Token，拿到后再携带 Token 到资源所在服务器拉取相应资源。 JWT（JSON Web Token）是一种使用 JSON 格式来规约 Token 或者 Session 的协议。由于传统认证方式免不了会生成一个凭证，这个凭证可以是 Token 或者 Session，保存于服务端或者其他持久化工具中，这样一来，凭证的存取就变得十分麻烦，JWT 的出现打破了这一瓶颈，实现了 “客户端 Session” 的愿景。JWT 通常由三部分组成： Header 头部：指定 JWT 使用的签名算法 Payload 载荷：包含一些自定义与非自定义的认证信息 Signature 签名：将头部与载荷使用 . 连接之后，使用头部的签名算法生成签名信息并拼装到末尾 OAuth2.0 + JWT 的意义就在于，使用 0Auth2.0 协议的思想拉取认证生成 Token，使用 JWT 瞬时保存这个 Token，在客户端与资源端进行对称或非对称加密，使得这个规约具有定时、定量的授权认证功能，从而免去 Token 存储所带来的安全或系统扩展问题。 OAuth2.0 + JWT 实战下面模拟 Zuul 结合 OAuth2.0 + JWT 的实际应用，点击下载完整的示例代码。 编写 zuul-serverzuul-server 中需要做的就是当请求接口时，判断是否登录，如果未登录，则跳转到 auth-server 的登录界面（这里使用的是 Spring Security OAuth 的默认登录界面，也可以重写相关代码定制页面)，登录成功后 auth-server 颁发 jwt token，zuul-server 在访问下游服务时将 jwt token 放入 header 中即可。 zuul-server 的 pom.xml 文件： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件： 123456789101112131415161718192021222324252627282930server: port: 8092spring: application: name: zuul-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-servicesecurity: oauth2: client: access-token-uri: http://127.0.0.1:8091/uaa/oauth/token #令牌端点 user-authorization-uri: http://127.0.0.1:8091/uaa/oauth/authorize #授权端点 client-id: zuul_server #OAuth2客户端ID client-secret: secret #OAuth2客户端密钥 resource: jwt: key-value: springcloud123 #指定密钥，使用对称加密方式，默认算法为HS256 在 zuul-server 里重写 WebSecurityConfigurerAdapter 适配器的 configure(HttpSecurity http) 方法，声明需要鉴权的 URL 信息 1234567891011121314151617@Component@EnableOAuth2Ssopublic class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\"/login\", \"/provider/service/**\") .permitAll() .anyRequest() .authenticated() .and() .csrf() .disable(); }} 编写 auth-serverauth-server 是整个示例的 另一个核心，作为认证授权中心，用于颁发 jwt token 凭证。 auth-server 的 pom.xml 文件： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; auth-server 的 application.xml 文件： 123456789101112131415server: port: 8091 servlet: context-path: /uaaspring: application: name: auth-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 在 auth-server 里编写认证授权服务适配类 OauthConfigruatrion，主要用于指定客户端 ID、密钥，以及权限定义与作用域声明，指定 TokenStore 为 JWT，不同于以往将 TokenStore 指定为 Redis 或是其他持久化工具： 123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableAuthorizationServerpublic class OauthConfigruatrion extends AuthorizationServerConfigurerAdapter { @Autowired private AuthenticationManager authenticationManager; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() .withClient(\"zuul_server\") .secret(\"secret\") .scopes(\"WRIGTH\", \"read\") .autoApprove(true) .authorities(\"WRIGTH_READ\", \"WRIGTH_WRITE\") .authorizedGrantTypes(\"implicit\", \"refresh_token\", \"password\", \"authorization_code\"); } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints .tokenStore(jwtTokenStore()) .tokenEnhancer(jwtTokenConverter()) .authenticationManager(authenticationManager); } @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtTokenConverter()); } @Bean protected JwtAccessTokenConverter jwtTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey(\"springcloud123\"); return converter; }} 在 auth-server 里编写安全配置类 WebSecurityConfiguration，主要声明用户 admin 具有读写权限，用户 guest 具有读权限，passwordEncoder() 用于声明用户名和密码的加密方式，这个功能在 Spring Security 5.0 之前是没有的。 1234567891011121314151617181920212223@Configurationpublic class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Override @Bean(name = BeanIds.AUTHENTICATION_MANAGER) public AuthenticationManager authenticationManager() throws Exception { return super.authenticationManager(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth .inMemoryAuthentication() .withUser(\"guest\").password(\"guest\").authorities(\"WRIGTH_READ\") .and() .withUser(\"admin\").password(\"admin\").authorities(\"WRIGTH_READ\", \"WRIGTH_WRITE\"); } @Bean public static NoOpPasswordEncoder passwordEncoder() { return (NoOpPasswordEncoder) NoOpPasswordEncoder.getInstance(); }} 编写 provider-serviceprovider-service 作为 zuul-server 的下游服务，需要的功能很简单，能够被注册发现，以及能够按照规贝解析 jwt token 即可。 provider-service 的 pom.xml 文件 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; provider-service 的 application.yml 文件： 12345678910111213server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 在 provider-service 里编写配置类 ResourceServerConfiguration： 123456789101112131415161718192021222324252627282930313233@Configuration@EnableResourceServerpublic class ResourceServerConfiguration extends ResourceServerConfigurerAdapter { @Override public void configure(HttpSecurity http) throws Exception { http .csrf().disable() .authorizeRequests() .antMatchers(\"/**\").authenticated() .antMatchers(HttpMethod.GET, \"/test\") .hasAuthority(\"WRIGTH_READ\"); } @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception { resources .resourceId(\"WRIGTH\") .tokenStore(jwtTokenStore()); } @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtTokenConverter()); } @Bean protected JwtAccessTokenConverter jwtTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey(\"springcloud123\"); return converter; }} 在 provider-service 里编写测试类： 1234567891011121314151617@RestControllerpublic class TestController { private static final Logger logger = LoggerFactory.getLogger(TestController.class); @RequestMapping(\"/test\") public String test(HttpServletRequest request) { logger.info(\"----------------header----------------\"); Enumeration headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements()) { String key = (String) headerNames.nextElement(); logger.info(key + \": \" + request.getHeader(key)); } logger.info(\"----------------header----------------\"); return \"hello!\"; }} 测试效果 在测试之前，整个示例的流程图在这里 依次启动 eureka-server、provider-service、auth-server、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/test，由于未授权，该接口会返回需要授权才能访问的提示信息，查看截图 访问 http://127.0.0.1:8092，会自动跳转到 auth-server 的默认登录页面（http://127.0.0.1:8091/uaa/login），输入用户名 admin 与 密码 admin 进行登录，查看截图 再次访问 http://127.0.0.1:8092/provider/service/test，调用接口成功，控制台的日志信息如下： 1234567891011121314151617181920----------------header----------------upgrade-insecure-requests: 1user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9sec-fetch-site: nonesec-fetch-mode: navigatesec-fetch-user: ?1sec-fetch-dest: documentaccept-language: en,zh-CN;q=0.9,zh;q=0.8authorization: bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1ODg2OTE4NzAsInVzZXJfbmFtZSI6ImFkbWluIiwiYXV0aG9yaXRpZXMiOlsiV1JJ ...x-forwarded-host: 127.0.0.1:8092x-forwarded-proto: httpx-forwarded-prefix: /provider/servicex-forwarded-port: 8092x-forwarded-for: 127.0.0.1accept-encoding: gzipcontent-length: 0host: 192.168.1.130:9090connection: Keep-Alive----------------header---------------- Zuul 限流构建一个自我修复型系统一直是各大企业进行架构设计的难点所在，在 Hystrix 中可以通过熔断器来实现，通过某个阈值来对异常流量进行降级处理。其实，除对异常流量进行降级处理之外，也可以做一些其他操作来保护系统免受 “雪崩之灾”，比如：流量 排队、限流、分流等。 限流算法说到限流算法，不自觉就想到了 “漏桶” 与 “令牌桶” 算法。诚然，两种限流的祖师级算法确有其独到之处，其他实现比如滑动时间窗或者三色速率标记法等，其实质还是 “漏桶” 与 “令牌桶” 的变种，要么是将 “漏桶” 容积换成了单位时间，要么是按规则将请求标记颜色进行处理，底层还是 “令牌” 的思想。所以，掌握 “漏桶” 与 “令牌桶” 算法原理，对理解其他限流算法有一定帮助。 漏桶（Leaky Bucket）算法漏桶的原型是一个底部有漏孔的桶，桶上方有一个入水口，水不断地流进桶内，桶下方的漏孔就会以一个相对恒定的速率漏水，在入大于岀的情况下，桶在一段时间之后就会被装满，这时候多余的水就会溢出；而在入小于出的情况下，漏桶则不起任何作用。后来将这个经典模型运用在网络流量整形上面，通过漏桶算法的约束，突发流量可以被整形为一个规整的流量（如图所示）。当请求或者具有一定体量的数据流涌来的时候，在漏桶的作用下，流量被整形，不能满足要求的部分被削减掉。所以，漏桶算法能够强制限定流量速率。注意，在企业应用中，这部分溢出的流量是可以被利用起来的，并非完全丢弃，可以把它们收集到一个队列里面，做流量排队，尽量做到合理利用所有资源。 令牌桶（Token Bucket）算法令牌桶算法和漏桶算法有点不一样，桶里面存放令牌，而令牌又是以一个恒定的速率被加入桶内，可以积压，可以溢出。当数据流涌来时，量化请求用于获取令牌，如果取到令牌则放行，同时桶内丢弃掉这个令牌；如果不能取到令牌，请求则被丢弃（如图所示）。由于令牌桶内可以存在一定数量的令牌，那么就可能存在一定程度的流量突发，这也是决定漏桶算法与令牌桶算法适用于不同应用场景的主要原因。 限流实战在 Zuul 中实现限流最简单的方式是使用自定义 Filter 加上相关限流算法，其中可能会考虑到 Zuul 的多节点部署，因为算法的原因，这时候需要一个 K/V 存储工具（推荐使用 Redis，充分利用 Redis 单线程的特性，可以有效避免多节点带来的一些问题)。当然如果 Zuul 是单节点应用，限流方式的选择就会广得多，完全可以将相关 prefix 放在内存之中，方便又快捷。这里介绍一个开箱即用的工具 spring-cloud-zuul-ratelimit，它是专门针对 Zuul 编写的限流库，提供了以下特性： 多种细粒度策略： 多种粒度临时变量存储方式： 父 Maven 工程的 pom.xml 文件，这里 Spring Cloud 的版本是 Hoxton.SR4，Spring Boot 的版本是 2.2.6.RELEASE，点击下载完整的示例代码。 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; zuul-server 里的 pom.xml 文件： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.marcosbarbero.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul-ratelimit&lt;/artifactId&gt; &lt;version&gt;2.4.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; zuul-server 里的 application.yml 文件： 1234567891011121314151617181920212223242526272829303132333435server: port: 8092spring: application: name: zuul-server redis: host: 172.175.0.3 port: 6379 password:eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-service ratelimit: enabled: true key-prefix: ratelimit repository: REDIS behind-proxy: true #表示代理之后 policy-list: provider-service: #单独细化到服务粒度 - limit: 2 #在一个单位时间窗口（秒）的请求数量 quota: 1 #在一个单位时间窗口（秒）的请求时间限制 refresh-interval: 3 #刷新时间（秒） type: - url #指定url粒度 zuul-server 里的启动主类： 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 多次访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，在时间窗阈值内访问接口时，接口会返回正确信息；一旦超限，后台会抛出 429 异常，接口返回对应的错误信息，查看截图 Zuul 动态路由动态路由概述Zuul 提供了各种映射规则的配置方式，这极大地增加了在构建应用时的选择余地，这些方式称为 “静态路由（Static Routing）”。一般来说，在微服务构建前期就已经按照业务把各种映射关系制定好了，但是在后期迭代过程中，一个复杂的系统难免经历新服务的上线过程，这个时候不能轻易停掉线上某些映射链路；那么问题就来了，Zuul 是在启动的时候将配置文件中的映射规则写入内存，要新建映射规则，只能修改了配置文件之后再重新启动 Zuul 应用。那能不能有一种方法，既能按需修改映射规则，又能使服务免于重启之痛呢？答案是有的，目前有如下两种解决方案实现 “动态路由（Dynamic Routing）”，通常采用第一种方式，这是 Spring Cloud 生态推崇的方式，但是也有它的局限性，有兴趣的读者可以查阅相关资料。 结合 Spring Cloud Config + Bus，动态刷新配置文件，这种方式的好处是不用 Zuul 维护映射规则，可以随时修改，随时生效；唯一不好的地方是需要单独集成一些使用并不频繁的组件，Config 没有可视化界面，维护起规则来也相对麻烦 重写 Zuul 的配置读取方式，釆用事件刷新机制，从数据库读取路由映射规则，此种方式因为基于数据库，可轻松实现管理界面，灵活度较高 动态路由实现原理剖析Zuul 动态路由实现的四个核心类： DiscoveryClientRouteLocator 类中的 locateRoutes() 方法继承自 SimpleRouteLocator 类并重写了规则，该方法主要的功能就是将配置文件中的映射规则信息包装成 LinkedHashMap&lt;String, ZuulRoute&gt;，键是映射路径，值是配置文件的封装类，以往所见的配置映射读取进来就是使用 ZuulRoute 来封装。refiresh() 实现自 RefreshableRouteLocator 接口，添加刷新功能必须要实现此方法，doRefresh() 方法来自 SimpleRouteLocator 类。 SimpleRouteLocator 该类是 DiscoveryClientRouteLocator 的父类，此类基本实现了 RouteLocator 接口，对读取的配置文件信息做一些基本处理，提供了方法 doRefresh() 与 locateRoutes() 供子类实现刷新策略与映射规则加载策略，两个方法都是使用 protected 修饰，是为了让子类不用维护此类一些成员变量就能够实现刷新或者读取路由的功能。 ZuulServerAutoConfiguration 在低版本的 Spring Cloud Zuul 中，这个类叫作 ZuulConfiguration，位于 org.springframework. cloud.netflix.zuul 包中，主要目的是注册各种过滤器、监听器以及其他功能。Zuul 在注册中心新增服务后刷新监听器也是在此注册的，底层是采用 Spring 的 ApplicationListener 来实现。由方法 onApplicationEvent(ApplicationEvent event) 可知，Zuul 会接收 3 种事件通知（ContextRefreshedEvent、RefreshScopeRefreshedEvent、RoutesRefreshedEvent）去刷新路由映射配置信息，此外心跳续约监视器 HeartbeatMonitor 也会触发这个动作。 ZuulHandlerMapping 此类是将本地配置的映射关系映射到远程的过程控制器，与事件刷新相关的代码。类里的 dirty 属性很重要，它是用来控制当前是否需要重新加载映射配置信息的标记，在 Zuul 每次进行路由操作的时候都会检査这个值，如果为 true，就会触发配置信息的重新加载，同时再将其回设为 false。由 setDirty(boolean dirty) 可知，启动刷新动作必须要实现 RefreshableRouteLocator 接口。 原理总结 在构建动态路由的时候，只需要重写 SimpleRouteLocator 类的 locateRoutes() 方法，并且实现 RefreshableRouteLocator 接口的 refresh() 方法，再在内部调用 SimpleRouteLocator 类的 doRefresh() 方法，就可以构建起一个由 Zuul 内部事件触发的自定义动态路由加载器。如果不想使用内部事件触发配置更新操作，改为手动触发，可以重写 onApplicationEvent(ApplicationEvent event) 方法，事实上手动触发的控制性更好。 基于 DB 的动态路由实战下面做一个实战例子，这里的 DB 暂且选用 MySQL，当然也可以选择其他持久化方式，目的是方便，易于管理，实际上选用 MongoDB 也是一种不错的选择，点击下载完整的示例代码。 存储映射规则的数据库表设计： zuul-server 的 pom.xml 文件： 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件，如果需要防止服务侵入，这里可以将 ribbon.eureka.enabled 设置为 false： 12345678910111213141516171819202122server: port: 8092spring: application: name: zuul-server datasource: url: jdbc:mysql://localhost:3306/zuul-test?useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.jdbc.Driver username: root password: 123456eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: trueribbon: eureka: enabled: true 在 zuul-server 里编写 DAO 类，从数据库读取路由配置信息： 12345678910111213141516171819202122@Componentpublic class PropertiesDao { @Autowired private JdbcTemplate jdbcTemplate; private final static String SQL = \"SELECT * FROM zuul_route WHERE enabled = TRUE\"; public Map&lt;String, ZuulProperties.ZuulRoute&gt; getProperties() { Map&lt;String, ZuulProperties.ZuulRoute&gt; routes = new LinkedHashMap&lt;&gt;(); List&lt;ZuulRouteEntity&gt; list = jdbcTemplate.query(SQL, new BeanPropertyRowMapper&lt;&gt;(ZuulRouteEntity.class)); list.forEach(entity -&gt; { if (StringUtils.isEmpty(entity.getPath())) { return; } ZuulProperties.ZuulRoute zuulRoute = new ZuulProperties.ZuulRoute(); BeanUtils.copyProperties(entity, zuulRoute); routes.put(zuulRoute.getPath(), zuulRoute); }); return routes; }} 在 zuul-server 里编写自定义路由配置加载器类，该类是改造的核心类，locateRoutes() 方法从数据库加载配置信息，并且配合 Zuul 内部事件刷新机制，实际上每次心跳续约都会触发路由配置重新加载的操作，如果需要改为手动触发，可参考上面的动态路由实现原理剖析： 12345678910111213141516171819202122232425262728293031323334353637383940public class DynamicZuulRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator { @Autowired private ZuulProperties properties; @Autowired private PropertiesDao propertiesDao; public DynamicZuulRouteLocator(String servletPath, ZuulProperties properties) { super(servletPath, properties); this.properties = properties; } @Override public void refresh() { doRefresh(); } @Override protected Map&lt;String, ZuulRoute&gt; locateRoutes() { LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;&gt;(); routesMap.putAll(super.locateRoutes()); routesMap.putAll(propertiesDao.getProperties()); LinkedHashMap&lt;String, ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); routesMap.forEach((key, value) -&gt; { String path = key; if (!path.startsWith(\"/\")) { path = \"/\" + path; } if (StringUtils.hasText(this.properties.getPrefix())) { path = this.properties.getPrefix() + path; if (!path.startsWith(\"/\")) { path = \"/\" + path; } } values.put(path, value); }); return values; }} 在 zuul-server 编写配置类，让上面的自定义路由配置加载器生效： 123456789101112131415@Configurationpublic class DynamicZuulConfig { @Autowired private ZuulProperties zuulProperties; @Autowired private ServerProperties serverProperties; @Bean public DynamicZuulRouteLocator routeLocator() { DynamicZuulRouteLocator routeLocator = new DynamicZuulRouteLocator(serverProperties.getServlet().getServletPrefix(), zuulProperties); return routeLocator; }} 测试效果： 依次启动 eureka-server、provider-service、zuul-server 应用 访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，查看接口调用的结果 访问 http://127.0.0.1:8092/provider-service/provider/add?b=3，查看接口调用的结果 访问 http://127.0.0.1:8092/baidu，查看是否跳转到百度的首页 Zuul 灰度发布灰度发布概述灰度发布，是指在系统迭代新功能时的一种平滑过渡的上线发布方式。灰度发布是在原有系统的基础上，额外增加一个新版本，这个新版本包含需要待验证的新功能，随后用负载均衡器引入一小部分流量到这个新版本应用，如果整个过程没有出现任何差错，再平滑地把线上系统或服务一步步替换成新版本，至此完成了一次灰度发布。这种发布方式由于可以在用户无感知的情况下完成产品的升级，在许多公司都有较为成熟的解决方案。对于 Spring Cloud 微服务生态来说，粒度一般是一个服务，往往通过使用某些带有特定标记的流量来充当灰度发布过程中的 “小白鼠”，并且目前已经有比较好的开源项目来做这个事情。 灰度发布实战灰度发布有很多种实现方式，这里要讲的是基于 Eureka 元数据（metadata）的一种方式，它的原理是通过获取 Eureka 实例信息，并鉴别元数据的含义，再分别进行路由规则下的负载均衡，点击下载完整的示例代码。 其中在 Eureka 里面，一共有两种元数据： 标准元数据：这种元数据是服务的各种注册信息，比如 IP、端口、服务健康信息、续约信息等，存储于专门为服务开辟的注册表中，用于其他组件取用以实现整个微服务生态 自定义元数据：自定义元数据是使用 eureka.instance.metadata-map.&lt;key&gt;=&lt;value&gt; 来配置的，其内部其实就是维护了一个 Map 来保存自定义元数据信息，可以配置在服务提供者端，随服务一并注册保存在 Eureka 的注册表中，对微服务生态的任何行为都没有影响，除非知道其特定的含义 首先编写 provider-service、provider-service-2、provider-service-3 应用，9090 与 9091 端口运行的是稳定的线上服务，将它们的 host-mark 设置成 running-host，需要上线的灰度服务的端口为 9092，host-mark 为 gray-host，最后要达成的效果是：由于服务名称都为 provider-service，但是在某一个值的作用下，部分请求被分发到 9090 与 9091 实例上，也就是 host-mark 为 running-host 的节点；另一部分则分发到 9092 实例，host-mark 为 gray-host 的节点。 provider-service 的 application.yml 文件： 123456789101112131415server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: running-host provider-service-2 的 application.yml 文件： 123456789101112131415server: port: 9091spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: running-host provider-service-3 的 application.yml 文件： 123456789101112131415server: port: 9092spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true metadata-map: host-mark: gray-host 在 zuul-server 中的 pom.xml 文件里，引入开源项目 ribbon-discovery-filter-spring-cloud-starter，该项目提供了一种基于 metadata 的负载均衡机制： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 在 zuul-server 里创建自定义的过滤器，此过滤器的作用是将 header 里面的 gray-mark 作为指标，如果 gray-mark 等于 enable 的话，就将该请求路由到灰度节点 gray-host，如果不等于或者没有这个指标就路由到其他节点。RibbonFilterContextHolder 是该项目的一个核心类，它定义了基于 metadata 的一种负载均衡机制 123456789101112131415161718192021222324252627282930public class GrayPublishFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER - 1; } @Override public boolean shouldFilter() { RequestContext ctx = RequestContext.getCurrentContext(); return !ctx.containsKey(FORWARD_TO_KEY) &amp;&amp; !ctx.containsKey(SERVICE_ID_KEY); } @Override public Object run() throws ZuulException { HttpServletRequest request = RequestContext.getCurrentContext().getRequest(); String mark = request.getHeader(\"gray-mark\"); if (!StringUtils.isEmpty(mark) &amp;&amp; \"enable\".equals(mark)) { RibbonFilterContextHolder.getCurrentContext().add(\"host-mark\", \"gray-host\"); } else { RibbonFilterContextHolder.getCurrentContext().add(\"host-mark\", \"running-host\"); } return null; }} 在 zuul-server 里创建配置类： 12345678@Configurationpublic class CommonConfiguration { @Bean public GrayPublishFilter grayPublishFilter() { return new GrayPublishFilter(); }} 在 zuul-server 里创建启动主类： 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 测试效果： 依次启动 eureka-server、provider-service、provider-service-2、provider-service-3、zuul-server 应用 header 不加 gray-mark=enable，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，请求只会路由到 9090 与 9091 端口的 provider-service 服务上（默认轮询） header 加上 gray-mark=enable，访问 http://127.0.0.1:8092/provider/service/provider/add?b=3，无论请求多少次，请求都会路由到 9092 端口的 provider-service 服务上 Zuul 文件上传文件上传的场景，很多开发者都会遇到，Zuul 作为一个网关中间件，自然也会面临文件上传的考验。Zuul 的文件上传功能是从 Spring Boot 承袭过来的，所以也需要 Spring Boot 的相关配置，点击下载完整的示例代码。 文件上传实战zuul-server 的 pom.xml 文件，为了上传测试方便，另外引入了 Swagger2： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; zuul-server 的 application.yml 文件： 12345678910111213141516171819202122232425262728293031323334353637383940server: port: 8092spring: application: name: zuul-server servlet: multipart: enabled: true #使用http multipart上传处理 max-file-size: 100MB #设置单个文件的最大长度，默认1M，如不限制配置为-1 max-request-size: 100MB #设置最大的请求文件的大小，默认10M，如不限制配置为-1 file-size-threshold: 1MB #当上传文件达到1MB的时候进行磁盘写入 location: /tmp #上传的临时目录eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truezuul: routes: provider-service: path: /provider/service/** serviceId: provider-service##### 设置Ribbon的超时时间，如果要上传大文件，为避免超时，稍微设大一点ribbon: ConnectTimeout: 3000 ReadTimeout: 30000##### Hystrix默认超时时间为1秒，如果要上传大文件，为避免超时，稍微设大一点hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 30000 在 zuul-server 里编写 Swagger2 的配置类： 123456789101112131415161718@Configuration@EnableSwagger2public class Swagger2Config { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select() .apis(RequestHandlerSelectors.basePackage(\"com.springcloud.study.controller\")) .paths(PathSelectors.any()).build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"Zuul文件上传\") .description(\"Zuul文件上传\") .version(\"1.0\").build(); }} 在 zuul-server 里编写文件上传的测试类： 12345678910111213141516171819@RestController@Api(\"Zuul文件上传\")public class UploadController { public static final String PREFIX_PATH = \"/tmp/upload/\"; private static final Logger logger = LoggerFactory.getLogger(UploadController.class); @PostMapping(\"/upload\") @ApiOperation(\"文件上传接口\") public String upload(@RequestParam(value = \"file\", required = true) MultipartFile file) throws Exception { logger.info(\"==&gt; file size: \" + file.getSize()); byte[] bytes = file.getBytes(); String filePath = PREFIX_PATH + UUID.randomUUID().toString(); File fileToSave = new File(filePath); FileCopyUtils.copy(bytes, fileToSave); return filePath; }} 测试效果： 依次启动 eureka-server、zuul-server 应用 访问 http://127.0.0.1:8092/swagger-ui.html，选择本地文件进行上传即可 文件上传乱码在 Spring Cloud Finchley 之前的版本，上传中文名的文件会出现文件名乱码的情况，上传英文名的文件则不会，这是由于 Zuul 内部默认使用了 Spring MVC 来上传文件，这种方式对中文字符的处理有点不友好。如果要解决这个问题，可以改为使用 Zuul Servlet 来上传文件，当需要上传大文件的时候尤需如此，因为它自带有一个缓冲区。此时只需要在请求路径前加上 /zuul 就可以使用 Zuul Servlet 了，例如：http://127.0.0.1:8092/zuul/upload。 Zuul 实用技巧饥饿加载Zuul 内部默认使用 Ribbon 来调用远程服务，所以由于 Ribbon 的原因，在部署好所有应用组件之后，第一次经过 Zuul 的调用往往会去注册中心读取服务注册表，初始化 Ribbon 负载均衡信息，这是一种懒加载策略，但是这个过程是极其耗时的，尤其是服务过多的时候。为了避免这个问题，可以在启动 Zuul 的时候就饥饿加载应用程序上下文信息；开启饥饿加载只需添加以下配置即可： 1234zuul: ribbon: eager-load: enabled: true 请求体修改在客户端对 Zuul 发送 POST 请求之后，由于某些原因，在请求到下游服务之前，需要对请求体进行修改，常见的是对 form・data 参数的增减，对 application/json 的修改，对请求体做 Uppercase 等。在 Zuul 中可以很好地解决这种需求，只需要新增一个 PRE 类型的 Filter 对请求体进行修改。由于在 Zuul 中有 Filter (FormBodyWrapperFilter) 会对请求体做封装，因此在编写此 Filter 的时候应当把它的执行次序放在该 Filter 之后，为了稳妥起见，把 ModifyRequestEntityFilter 的次序设置为 PRE 类型 Filter 的最后一级。 12345678910111213141516171819202122232425262728293031323334public class ModifyRequestEntityFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER + 1; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); request.getParameterMap(); Map&lt;String, List&lt;String&gt;&gt; requestQueryParams = ctx.getRequestQueryParams(); if (requestQueryParams == null){ requestQueryParams = new HashMap&lt;&gt;(); } //这里添加新增参数的value，注意，只取list的0位 ArrayList&lt;String&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add(\"wwww\"); requestQueryParams.put(\"test\", arrayList); ctx.setRequestQueryParams(requestQueryParams); return null; }} 重试机制在 Spring Cloud 中有多种发送 HTTP 请求的方式可以与 Zuul 结合，RestTemplate、Ribbon 或者 Feign，但是无论选择哪种，都可能出现请求失败的情况，这在复杂的互联网环境是不可避免的。Zuul 作为一个网关中间件，在出现偶然请求失败时进行适当的重试是十分必要的，重试可以有效地避免一些突发原因引起的请求丢失。Zuul 中的重试机制是配合 Spring Retry 与 Ribbon 来使用的。 在 pom.xml 引入 Spring Retry 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;org.springframework.retry&lt;/groupld&gt; &lt;artifactld&gt;spring-retry&lt;/artifactld&gt;&lt;/dependency&gt; 在 application.yml 里添加重试相关的配置内容： 123456789101112131415161718#Zuul开启重试，D版之后默认为false，需要手动开启zuul: retryable: true#Ribbon的重试机制配置ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true#SpringCloud内部默认已开启负载均衡重试，这里列出来说明这个参数比较重要spring: cloud: loadbalancer: retry: enabled: true 配置当中的 ConnectTimeout 与 ReadTimeou 是当 HTTP 客户端使用 Apache HttpClient 的时候生效的，这个超时时间最终会被设置到 Apache HttpClient 中去。在设置的时候要结合 Hystrix 的超时时间来综合考虑，针对不同的应用场景，设置太小会导致很多请求失败，设置太大会导致熔断功能控制性变差，所以需要经过压力测试得来。Zuul 同时也支持对单个映射规则进行重试 zuul.routes.&lt;route&gt;.retryable=true，需要注意的是，在某些对幂等要求比较高的使用场景下，要慎用重试机制，因为如果没有相关处理的话，出现幂等问题是十分有可能的。 Header 传递在 Zuul 中对请求做了一些处理，需要把处理结果发给下游服务，但是又不能影响请求体的原始特性，这个问题该怎么解决好呢？Zuul 提供了一个重要的类 Requestcontext，里面的 addZuulRequestHeader() 方法正好可以用来解决此问题，官方称之为 Header 的传递。 123456789101112131415161718192021222324public class HeaderDeliverFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return PRE_DECORATION_FILTER_ORDER + 1; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { RequestContext context = RequestContext.getCurrentContext(); context.addZuulRequestHeader(\"result\", \"to next service\"); return null; }} 使用 OkHttp 替换 Apache HttpClient在 Spring Cloud 中各个组件之间使用的通信协议都是 HTTP，而 HTTP 客户端使用的是 Apache HttpClient，但是由于其难以扩展等诸多原因，已被许多技术栈弃用。 Square 公司开发的 okhttp 正在逐渐被接受，在 Zuul 中使用 okhttp 替换 Apache HttpClient，首先需要在 pom.xml 中增加 okhttp 的依赖包： 1234&lt;dependency&gt; &lt;groupld&gt;com.squareup.okhttp3&lt;/groupld&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 然后在 application.yml 文件中禁用 HttpClient 并开启 okhttp 即可： 12345ribbon: httpclient: enabled: false okhttp: enabled: true 下篇 - Zuul 入门教程（高级篇） Zuul 入门教程 - 高级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Zuul 入门教程 - 基础篇","url":"/posts/316633c.html","text":"Zuul 介绍Zuul 是什么Zuul 是由 Netflix 孵化的一个致力于 “网关” 解决方案的开源组件，在动态路由、监控、弹性、服务治理以及安全方面起着举足轻重的作用。从 2012 年 3 月以来，陆续发布了 Zuul 1.0 与 Zuul 2.0 版本，后经 Pivotal 公司将 Zuul 1.0 整合到 Spring Cloud 的生态系统中，即现在的 Spring Cloud Zuul。在 Netflix 官方的解释中，Zuul 是从设备和网站到后端应用程序所有请求的前门，为内部服务提供可配置的对外 URL 到服务的映射关系，基于 JVM 的后端路由器。其底层基于 Servlet 实现，本质组件是一系列 Filter 所构成的责任链，并且 Zuul 的逻辑引擎与 Filter 可用其他基于 JVM 的编程语言编写（比如 Groovy）。Zuul 默认集成了 Ribbon、Hystrix，其中 Zuul 2.x 版本改动相较 1.x 比较大，底层使用了 Netty。虽然 Netflix 已经在 2018 年 5 月开源了 Zuul 2.x，但由于 Zuul 2.x 在 Spring Cloud Gateway 孵化之前一直跳票发布，而且 Spring Cloud Gateway 目前已经孵化成功，相较于 Zuul 1.x 在功能以及性能上都有明显的提升。因此在 Spring Boot 2.0 以上版本中，并没有对 Zuul 2.0 以上最新高性能版本进行集成，仍然使用 Zuul 1.x 非 Reactor 模式（基于 Servlet 2.5 阻塞架构）的旧版本。更多介绍可参考：Zuul 项目、Zuul 官方英文教程、Spring Cloud Zuul 官方中文文档 Zuul 的特性主要特性包括：认证和鉴权、压力控制、动态路由、负载削减、静态响应处理、主动流量管理、金丝雀测试 Zuul 1.x 与 Zuul 2.x 对比Zuul 1.x 是一个基于 Servlet 2.5 的同步阻塞 I/O 网关，不支持任何长连接（如 WebSocket）。Zuul 1.x 的设计和 Nginx 比较像，每次 I/O 操作都是从工作线程池中选择一个来执行，请求线程被阻塞到工作线程完成为止；但是差别是 Nginx 是基于 C/C++ 实现，而 Zuul 1.x 是使用 Java 实现，而 JVM 本身会有第一次加载较慢的情况，使得 Zuul 1.x 的性能相对较差。根据官方提供的基准测试，Spring Cloud Gateway 的 RPS（每秒请求数）是 Zuul 1.x 的 1.6 倍，平均延迟是 Zuul 1.x 的一半。 Zuul 2.x 的理念更先进，基于 Netty 的异步非阻塞 I/O 模型，支持长连接。Zuul 2.x 最大的改进就是基于 Netty Server 实现了异步非阻塞 I/O 来接入请求，同时基于 Netty Client 实现了到后端业务服务 API 的请求，这样就可以实现更高的性能、更低的延迟。此外也调整了 Filter 类型，将原来的三个核心 Filter 显式命名为：Inbound Filter、Endpoint Filter 和 Outbound Filter。值得一提的是，Zuul 2.x 与 Spring Cloud Gateway 的性能差不多。Zuul 2.x 的核心功能如下： GZip HTTP/2 Retries Mutual TLS WebSocket/SSE Proxy Protocol Load Balancing Request Passport Request Attempts Status Categories Service Discovery Connection Pooling Origin Concurrency Protection Zuul 入门案例这里的案例将使用到的 Spring Cloud 组件是 Eureka 与 Zuul，另外再使用一个普通服务作为 Zuul 路由的下级服务，来模拟真实开发中的一次路由过程。 1. 版本说明在本文中，默认使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，Zuul 版本是 1.x，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 下游服务工程创建 Provider 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider-service）、注册中心地址与端口号： 12345678910111213server: port: 9090spring: application: name: provider-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping(\"/provider/add\") public String add(Integer a, Integer b, HttpServletRequest request) { return \"From Port: \" + request.getServerPort() + \", Result: \" + (a + b); }} 5. 创建 Zuul Server 工程创建 Zuul Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-client、spring-cloud-starter-netflix-zuul 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Zuul Server 的启动主类，添加注解 @EnableZuulProxy、@EnableDiscoveryClient 123456789@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulServerApplication { public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); }} 在 application.yml 文件中指定服务名称（zuul-server）、注册中心地址与端口号： 1234567891011121314151617181920server: port: 8092spring: application: name: zuul-servereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true#路由映射规则zuul: routes: provider-service: path: /provider/service/** serviceId: provider-service 6. 测试效果 分别启动 eureka-server、provider-service、zuul-server 应用 访问 provider-service 应用：http://127.0.0.1:9090/provider/add?a=3&amp;b=5 方式一：通过 zuul-server 访问 provider-service 应用：http://127.0.0.1:8092/provider-service/provider/add?a=3&amp;b=5，provider-service 为服务实例的名称 方式二：通过 zuul-server 访问 provider-service 应用：http://127.0.0.1:8092/provider/service/provider/add?a=3&amp;b=6，这里使用了路由映射规则 /provider/service/** 若上面通过 zuul-server 访问 provider-service 应用后，都可以正常返回结果，则说明 Zuul 成功发挥了网关的作用提示：若在 Zuul 的配置文件中指定了路由映射规则，当向 Zuul Server 发起请求的时候，Zuul 会去 Eureka 注册中心拉取服务列表，如果发现有指定的路由映射规则，就会按照映射规则路由到相应的服务接口 Zuul 路由配置路由配置简化12345zuul: routes: client-a: path: /client/** serviceId: client-a 上述的配置中，是一个从 /client/** 路由到 client-a 服务的一个映射规则，它可以简化成如下的简单配置，在这种情况下，Zull 会为 client-a 服务添加一个默认的映射规则 /client/** 123zuul: routes: client-a: /client/** 单实例 URL 映射除了路由到服务外，还支持路由到物理笛子，将 serviceId 替换为 url 即可： 12345zuul: routes: client-a: path: /client/** serviceId: http://127.0.0.1:8080 多实例路由映射在默认情况下，Zuul 会使用 Eureka 中集成的负载均衡功能，如果想要使用 Ribbon 的客户端负载均衡功能，就需要指定一个 serviceId，此操作需要禁止 Ribbon 使用 Eureka。提示：Spring Cloud 在 E 版本之后，新增了负载均衡策略的配置： 123456789101112131415zuul: routes: client-a: path: /ribbon/** serviceId: client-aribbon: eureka: enabled: falseclient-a: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule listOfServers: 127.0.0.1:8001,127.0.0.1:8002 Forward 本地跳转在 Zuul 中有时候会做一些逻辑处理，先在网关（Zuul Server）中写好一个接口，如下： 12345678@RestControllerpublic class TestController { @GetMapping(\"/add\") public String add(Integer a, Integer b){ return \"本地跳转: \" + (a + b); }} 如果希望在访问 /provider/service 接口的时候，跳转到上面的 add 方法上来处理，就需要用到 Zuul 的本地跳转，配置如下： 12345zuul: routes: provider-service: path: /provider/service/** url: forward:/add 当访问 http://127.0.0.1:8092/provider/service?a=2&amp;b=3，会跳转到 TestController 类的 add 本地方法 相同路径的加载规则有一种特殊的情况，为一个映射路径指定多个 serviceId 时，那么 Zuul 总是会路由到 YML 配置文件中最后面的那个服务。即在 YML 解释器工作的时候，如果同一个映射路径对应多个服务，按照加载顺序，最后加载的映射规则会把之前的映射规则覆盖掉。 12345678zuul: routes: client-a: path: /client/** serviceId: client-a client-b: path: /client/** serviceId: client-b 路由通配符此外，映射路径 /client/** 之后的 /** 也大有讲究，其还可以配置为 /* 或者 /?，具体规则如下： Zuul 功能配置路由前缀在配置路由规则的时候，可以配置一个统一的代理前缀，下次通过 Zuul 访问后端接口的时候就需要加上这个后缀了。提示，请求路径会变成 /pre/client/add，但实际起作用的是 /client/add，可以使用 stripPrefix=false 来关闭此功能；关闭之后，请求路径是 /pre/client/add，实际起作用的还是 /pre/client/add，一般不推荐使用这个配置。 1234567zuul: prefix: /pre routes: client-a: path: /client/** serviceId: client-a stripPrefix: false 敏感头信息在构建系统的时候，使用 HTTP 的 header 传值是十分方便的，协议的一些认证信息默认也在 header 里，比如 Cookie，或者习惯把基本认证信息通过 BASE64 加密后放在 Authorization 里面，但是如果系统要和外部系统通信，就可能会出现这些信息的泄漏。Zuul 支持在配置文件里面指定敏感头，切断它和下层服务之间的交互，配置如下： 123456zuul: routes: client-a: path: /client/** serviceId: client-a sensitiveHeaders: Cookie,Set-Cookie,Authorization 重定向问题假设客户端通过 Zuul 请求认证服务，认证成功之后重定向到一个欢迎页面，但是发现重定向的这个欢迎页面的 host 变成了这个认证服务的 host，而不是 Zuul 的 host，直接导致了认证服务地址的暴露（如下图），此时可以使用下述配置来解决： 123456zuul: add-host-header: true #解决重定向的header问题 routes: client-a: path: /client/** serviceId: client-a 服务屏蔽与路径屏蔽有时候为了避免某些服务或者路径的侵入，加入 ignored-services 与 ignored-patterns 之后，可以将它们屏蔽掉： 1234567zuul: ignored-services: client-b #忽略的服务，防服务侵入 ignored-patterns: /**/div/** #忽略的接口，屏蔽接口 routes: client-a: path: /client/** serviceId: client-a 下篇 - Zuul 入门教程（中级篇） Zuul 入门教程 - 中级篇 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Hystrix 入门教程 - 基础篇","url":"/posts/2ed0fea6.html","text":"服务雪崩效应服务雪崩概述微服务之间进行 RPC 或者 HTTP 调用时，一般都会设置 调用超时，失败重试等机制来确保服务的成功执行，这看上去很美好，但如果不考虑服务的熔断和限流，它就是造成服务雪崩的元凶。假设有两个访问量比较大的服务 A 和 B，这两个服务分别依赖 C 和 D，其中 C 和 D 服务都依赖 E 服务（如下图），这就是所谓的扇出。A 和 B 不断地调用 C 和 D，处理客户请求和返回需要的数据；当 E 服务不能提供服务的时候，C 和 D 的 超时和重试机制会被执行；由于新的请求不断的产生，会导致 C 和 D 对 E 服务的调用大量的积压，产生大量的调用等待和重试调用，会慢慢耗尽 C 和 D 的系统资源（CPU 或者内存等），然后 C 和 D 服务跟着也 down 掉。A 和 B 服务会重复 C 和 D 的遭遇，导致系统资源耗尽，然后服务也 down 掉了，最终整个服务都不可访问，造成了服务雪崩。 服务雪崩原因分析 访问量的突然激增 硬件故障，如机器宕机，机房断电，光纤被挖断等 数据库存在严重瓶颈，如：长事务、SQL 查询超时等 缓存击穿，导致请求全部落到某个服务，导致服务宕掉 程序有 Bug，导致服务不可用或者运行缓慢，如内存泄漏、线程同步等待等 服务雪崩解决方案 隔离：将不同类型的接口隔离部署，单个类型接口的失败甚至进程池被耗尽了，也不会影响其他接口的正常访问 限流：当发现服务失败数量达到某个阈值，拒绝访问，以此限制更多流量进来，防止过多失败的请求将资源耗尽 熔断：从接口请求连接时就拒绝访问，类似家里用的保险丝，当使用的电器总和超过了电压就熔断保险丝，保护整个区域的电路防止更多的损失 降级：对于简单的展示功能，如果有失败的请求，返回默认值；对于整个站点或客户端，如果服务器负载过高，则将其他非核心业务停掉，以让出更多资源给其他服务使用 熔断与降级的区别熔断与降级的相同点： 最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用 目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃而采用的技术手段 粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改） 自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段 熔断与降级的不同点： 实现方式不太一样，降级具有代码侵入性 (由控制器完成或者自动降级)，熔断一般称为自我熔断 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑 管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 资源隔离的级别 应用级别隔离：线程池隔离、信号量隔离、连接池隔离；Hystrix 实现了前两种，其各自优缺点如下图： 硬件级别隔离：虚拟机、Docker，比如 Docker 的资源隔离和资源限制，其通过 CGroup 来控制容器使用的资源配额，包括 CPU、内存、磁盘 IO、网络 Hystrix 介绍Hystrix 是什么Hystrix 是由 Netflix 开源的一个针对分布式系统容错处理的开源组件，2011 - 2012 年相继诞生和成熟，在 2018 年 11 月 20 日之后已经停止维护，最后一个正式版本为 1.5.18。Hystrix 单词意为 “豪猪”，浑身有刺保护自己，Hystrix 就是这样一个用来捍卫应用程序健康的利器。进一步说，Hystrix 是一个延迟和容错库，用在隔离远程系统、服务和第三方库，阻止级连故障，在复杂的分布式系统中实现恢复能力，以提高分布式系统的弹性。Hystrix 底层大量使用了 RxJava，而 Spring Cloud Hystrix 对 Hystrix 进行了二次封装，将其整合进 Spring Cloud 生态，更多介绍可参考：Hystrix 项目、Hystrix 官方英文教程、Spring Cloud Hystrix 官方中文文档 Hystrix 的设计目标 通过客户端库对延迟和故障进行保护和控制 在一个复杂的分布式系统中停止级联故障 快速失败和迅速恢复 在合理的情况下回退和优雅地降级 开启近实时监控、告警和操作控制 Hystrix 的特性服务熔断熔断机制是应对服务雪崩效应的一种微服务链路保护机制。日常在各种场景下都会接触到熔断这两个字，高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。股票交易中，如果股票指数过高，也会采用熔断机制，暂停股票的交易。同样，在微服务架构中，熔断机制也是起着类似的作用。当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回” 错误” 的响应信息。当检测到该节点微服务调用响应正常后恢复调用链路。在 Spring Cloud 框架里熔断机制通过 Hystrix 实现，Hystrix 会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是 5 秒内 20 次调用失败就会启动熔断机制。服务熔断是在服务端（服务提供者）实现的，Hybstrix 熔断机制的注解是 @HystrixCommand。 服务降级服务压力剧增的时候，根据当前的业务情况及流量对一些服务和页面有策略的降级，缓解服务器的压力，以保证核心任务的进行，同时保证部分甚至大部分请求能得到正确的响应。也就是当前的请求处理不了或者出错了，给一个默认的返回结果。服务降级处理是在客户端（服务消费者）实现的，与服务端（服务提供者）没有关系。 准实时的调用监控Hystrix 除了隔离依赖服务的调用以外，还提供了准实时的调用监控（Hystrix Dashboard）。Hystrix 会持续地记录所有通过 Hystrix 发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求、多少成功、多少失败等。Netflix 通过 hystrix-metrics-event-stream 项目实现了对以上指标的监控，而 Spring Cloud 也提供了 Hystrix Dashboard 的整合，对监控内容转化成可视化界面。 Hystrix 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程创建 Provider 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-hystrix、spring-cloud-starter-netflix-eureka-client 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableHystrix、@EnableDiscoveryClient 123456789@EnableHystrix@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号： 12345678910111213server: port: 8080spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 123456789101112131415161718@RestController@RequestMapping(\"/user\")public class UserController { @GetMapping(\"/getUser\") @HystrixCommand(fallbackMethod = \"defaultUser\") public String getUser(String userName) { if (userName.equals(\"Jim\")) { return \"this is real user\"; } else { throw new RuntimeException(\"user is not exist\"); } } public String defaultUser(String userName) { return \"the user not exist in this system\"; }} 5. 测试 启动 Eureka Server 与 Provider 应用 浏览器访问 http://127.0.0.1:8080/user/getUser?userName=Jim，当用户名为 Jim 时会返回正确的信息 当用户名不为 Jim 时，则会抛出运行时异常，同时 Hystrix 会降级处理返回友好的提示 Hystrix 实战应用Feign 中使用 Hystrix在 Feign 中，默认是自带 Hystrix 功能的，在很老的版本中默认是打开的，从最近的几个版本开始默认被关闭了，因此需要通过配置文件打开它，点击下载完整的案例代码。 在 Provider 源服务工程里，创建用于测试的 Controller 类： 123456789@RestController@RequestMapping(\"/dept\")public class DeptController { @RequestMapping(\"/getDept\") public String getDept(String deptName) { throw new RuntimeException(\"dept is not exist\"); }} 创建 Feign Client 工程，使用 @FeignClient 定义接口，并配置降级回退类： 123456@FeignClient(name = \"PROVIDER\", fallbackFactory = DeptClientFallbackServiceFactory.class)public interface DeptClientService { @RequestMapping(\"/dept/getDept\") public String getDept(@RequestParam(\"deptName\") String deptName);} 在 Feign Client 工程里，创建降级回退类，实现 FallbackFactory 接口： 1234567891011121314@Componentpublic class DeptClientFallbackServiceFactory implements FallbackFactory&lt;DeptClientService&gt; { @Override public DeptClientService create(Throwable throwable) { return new DeptClientService() { @Override public String getDept(String deptName) { return \"the dept not exist in this system, please confirm deptName\"; } }; }} 在 Feign Client 工程里，创建启动主类： 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class FeignClientApplication { public static void main(String[] args) { SpringApplication.run(FeignClientApplication.class, args); }} 在 Feign Client 工程里，创建用于测试的 Controller 类： 123456789101112@RestController@RequestMapping(\"/dept\")public class DeptController { @Autowired private DeptClientService clientService; @GetMapping(\"/get\") public String get(String deptName) { return clientService.getDept(deptName); }} 在 Feign Client 工程里，配置 pom.xml 文件，让 Feign 启用 Hystrix： 1234567891011121314151617server: port: 8082spring: application: name: feign-clienteureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truefeign: hystrix: enabled: true 测试 Feign 使用 Hystrix 的效果： 启动 Eureka Server、Provider 应用 当设置 feign.hystrix.enabled=false 时，启动 Feign-Client 应用，访问 http://127.0.0.1:8082/dept/get?deptName=IT，服务端返回 500 错误页面 当设置 feign.hystrix.enabled=true 时，启动 Feign-Client 应用，访问 http://127.0.0.1:8082/dept/get?deptName=IT ，服务端返回 the dept not exist in this system, please confirm deptName，这时说明 Hystrix 已经产生作用 Hystrix DashboardHystrix Dashboard 仪表盘是根据系统一段时间内发生的请求情况来展示的可视化面板，这些信息是每个 HystrixCommand 执行过程中的信息，这些信息是一个指标集合和具体的系统运行情况。创建 eureka-server、provider-service、feign-client 工程，其中 provider-service 提供了一个接口返回信息。由于 Hystrix 的指标是需要端口进行支撑的，因此 provider-service 工程需要增加 actuator 依赖，并公开 hystrix.stream 端点以便能被访问到，点击下载完整的案例代码。 配置 provider-service 工程里的 pom.xml，加入以下依赖： 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 provider-service 工程里的 application.yml，当 Spring Cloud 的版本高于 Dalston 时，建议确认 management.endpoints.web.exposure.include 包含的有 hystrix.stream 或者直接为 *；否则访问 http://127.0.0.1:8080/actuator/hystrix.stream 时可能会返回 404 错误页面 12345678910111213141516171819server: port: 8080spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: truemanagement: endpoints: web: exposure: include: hystrix.stream 创建 hystrix-dashboard 工程，引入 spring-cloud-starter-netflix-hystrix-dashboard 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 hystrix-dashboard 工程里，创建启动主类，添加 @EnableHystrixDashboard 注解： 12345678@SpringBootApplication@EnableHystrixDashboardpublic class DashboardApplication { public static void main(String[] args) { SpringApplication.run(DashboardApplication.class, args); }} 在 hystrix-dashboard 工程里，添加 application.yml 文件 12server: port: 8000 测试 Hystrix Dashboard 的运行效果： 分别启动 eureka-server、provider-service、feign-client、hystrix-dashboard 应用 访问 Hystrix Dashboard 的首页：http://127.0.0.1:8091/hystrix，查看首页截图 查看 provider-server 应用的监控信息： http://127.0.0.1:8080/actuator/hystrix.stream，目前 Spring Cloud Finchley 版的 SpringBoot 版本是 2.0，所以访问路径需要加上 /actuator，否则会访问不到监控页面，查看监控信息截图 在 Hystrix Dashboard 的首页中，填写 provider-server 应用的监控地址 http://127.0.0.1:8080/actuator/hystrix.stream，点击 Monitor Stream 按钮，跳转到监控图表页面，查看图表页面截图 调用 feigh-client 的接口：http://127.0.0.1:8082/dept/get?deptName=IT，更换不同的 deptName 参数值，观察 Hystrix Dashboard 监控页面上的图表变化 Hystrix Dashboard 各项指标参数的含义： Turbine 聚合 Hystrix上面讲的是单个实例的 Hystrix Dashboard，但在整个系统和集群的情况下不是特别有用，所以需要一种方式来聚合整个集群下的监控状况，Turbine 就是用来聚合所有相关的 hystrix.stream 流的方案，然后在 Hystrix Dashboard 中显示，具体原理如下图： 创建 eureka-server、provider-service-user、provider-service-dept、hystrix-dashboard 工程后，再创建 hystrix-turbine 工程，用来聚合集群里的 hystrix.stream 流。为了学习方便，也可以将 hystrix-turbine 工程整合到 hystrix-dashboard 工程里，点击下载完整的案例代码。 配置 hystrix-turbine 工程里的 pom.xml 文件，由于 Turbine 依赖 Eureka 的服务注册发现，因此需要另外引入 spring-cloud-starter-netflix-eureka-client 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置 hystrix-turbine 工程的 application.yml 文件： 12345678910111213141516171819202122server: port: 8093spring: application: name: turbine-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: trueturbine: aggregator: clusterConfig: default #指定聚合哪些集群，多个使用\",\"分割，默认为default。可使用http://.../turbine.stream?cluster={clusterConfig之一}访问 appConfig: provider-dept,provider-user #配置Eureka中的serviceId列表，表明监控哪些服务 clusterNameExpression: \"'default'\" # 1.当clusterNameExpression: default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default # 2.当clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称 # 3.当clusterNameExpression: metadata['cluster']时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC，则需要配置，同时turbine.aggregator.clusterConfig: ABC 创建 hystrix-turbine 工程里的启动主类，添加 @EnableTurbine 注解后，会自动启用 Eureka Client： 12345678@EnableTurbine@SpringBootApplicationpublic class TurbineApplication { public static void main(String[] args) { SpringApplication.run(TurbineApplication.class, args); }} 测试 Turbine 的运行效果： 分别启动 eureka-server、provider-service-user、provider-service-dept 应用 启动 hystrix-turbine 应用，访问 http://127.0.0.1:8093/turbine.stream，观察是否能获取到集群监控信息 启动 hystrix-dashboard 应用，访问 Hystrix Dashboard 的首页 http://127.0.0.1:8094/hystrix，在页面上填写 hystrix-turbine 应用的监控地址 http://127.0.0.1:8093/turbine.stream，然后点击 Monitor Stream 按钮，跳转到监控图表页面，查看图表页面截图 分别访问 provider-service-user 应用：http://127.0.0.1:8092/user/getUser?userName=Jim、provider-service-dept 应用：http://127.0.0.1:8091/dept/getDept?deptName=IT，观察 Hystrix Dashboard 监控页面上的图表变化 Hystrix 进阶Hystrix 配置说明Hystrix 的配置比较多，具体可以参考：官方英文文档，第三方中文文档 Hystrix 命令注解的区别Hystrix 在使用过程中除了 HystrixCommand 还有 HystrixObservableCommand，这两个命令有很多共同点，如都支持故障和延迟容错、断路器、指标统计，两者的区别如下： HystrixCommand 默认是阻塞式的，可以提供同步和异步两种方式，但 HystrixObservableCommand 是非阻塞式的，默认只能是异步的 HystrixCommand 执行的方法是 run，HystrixObservableCommand 执行的是 construct HystrixCommand 一个实例一次只能发一条数据出去，HystrixObservableCommand 可以发送多条数据 Hystrix 异常机制和处理5 种会被 fallback 截获的情况Hystrix 的异常处理中，有 5 种出错的情况会被 fallback 所截获，从而触发 fallback，这些情况分别是： 有一种异常是不会触发 fallback 的，且不会被计数进入熔断，它是 BAD_REQUEST，会抛出 HystrixBadRequestException，这种异常一般对应的是由非法参数或者一些非系统异常引起的，对于这种异常可以根据响应创建对应的异常进行异常封装或者直接处理。 1234567891011121314151617/** * HystrixBadRequestException 不会触发 fallback */@RestController@RequestMapping(\"/user\")public class UserController { @GetMapping(\"/getUser\") @HystrixCommand(fallbackMethod = \"defaultUser\") public String getUser(String userName) { throw new HystrixBadRequestException(\"HystrixBadRequestException Error\"); } public String defaultUser(String userName) { return \"the user not exist in this system\"; }} 获取 fallback 里的异常信息若想在 @HystrixCommand 里获取异常信息，只需要在方法内指定 Throwable 参数； 123456789101112131415@RestController@RequestMapping(\"/user\")public class UserController { @GetMapping(\"/getUser\") @HystrixCommand(fallbackMethod = \"defaultUser\") public String getUser(String userName) { throw new RuntimeException(\"the user not exist\"); } public String defaultUser(String userName, Throwable throwable) { System.out.println(throwable.getMessage()); return \"the user not exist in this system\"; }} 或者继承 @HystrixCommand 的命令，通过方法来获取异常： 123456789101112131415161718192021222324252627282930@RestControllerpublic class ExceptionController { @GetMapping(\"/getPSFallbackOtherExpcetion\") public String pSFallbackOtherExpcetion(){ String result = new PSFallbackOtherExpcetion().execute(); return result; }}/** * 继承HystrixCommand */public class PSFallbackOtherExpcetion extends HystrixCommand&lt;String&gt;{ public PSFallbackOtherExpcetion() { super(HystrixCommandGroupKey.Factory.asKey(\"GroupOE\")); } @Override protected String run() throws Exception { throw new Exception(\"this command will trigger fallback\"); } @Override protected String getFallback() { System.out.println(getFailedExecutionException().getMessage()); return \"invoke PSFallbackOtherExpcetion fallback method\"; }} 在 Feign Client 中可以用 ErrorDecoder 实现对这类异常的包装，在实际的使用中，很多时候调用接口会抛出这些 400-500 之间的错误，此时可以通过它进行封装： 12345678910111213141516@Componentpublic class FeignErrorDecoder implements feign.codec.ErrorDecoder { @Override public Exception decode(String methodKey, Response response) { try { if (response.status() &gt;= 400 &amp;&amp; response.status() &lt;= 499) { String error = Util.toString(response.body().asReader()); return new HystrixBadRequestException(error); } } catch (IOException e) { System.out.println(e); } return feign.FeignException.errorStatus(methodKey, response); }} fallback 会抛出异常的情况 Hystrix 请求缓存Hystrix 请求缓存是指 Hystrix 在同一个上下文请求中缓存请求结果，它与传统理解的缓存有一定区别；Hystrix 的请求缓存是在同一个请求中进行，在进行第一次调用结束后对结果缓存，然后接下来同参数的请求将会使用第一次缓存的结果，缓存的生命周期只在这一次请求中有效。使用 HystrixCommand 有两种方式，第一次种是继承，第二种是直接注解，缓存也同时支持这两种使用方式。具体使用例子如下，点击下载完整的案例代码。 使用类来开启缓存Hystrix 的缓存是在一次请求内有效，这要求请求要在一个 Hystrix 上下文里，不然在使用缓存的时候 Hystrix 会报一个没有初始化上下文的异常；可以使用 filter 过滤器或者 Interceptor 拦截器进行初始化，下面将使用一个拦截器来举例。使用类的方式很简单，只需要继承 HystrixCommand，然后重写它的 getCacheKey 方法即可，保证对于同一个请求返回同样的键值；对于缓存的清除，则可以调用 HystrixRequestCache 类的 clean 方法即可。 拦截器类： 1234567891011121314151617181920public class CacheContextInterceptor implements HandlerInterceptor { private HystrixRequestContext context; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { this.context = HystrixRequestContext.initializeContext(); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { this.context.shutdown(); }} 创建配置类，用于注册拦截器： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } @Bean public CacheContextInterceptor userContextInterceptor() { return new CacheContextInterceptor(); }} 1234567891011@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurerAdapter { @Autowired CacheContextInterceptor userContextInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(userContextInterceptor); }} 继承 HystrixCommand 类： 12345678910111213141516171819202122232425262728293031323334public class UserCommand extends HystrixCommand&lt;String&gt; { private String userName; private RestTemplate restTemplate; private static final Logger logger = LoggerFactory.getLogger(UserCommand.class); private static final HystrixCommandKey KEY = HystrixCommandKey.Factory.asKey(\"CommandKey\"); public UserCommand(String userName, RestTemplate restTemplate) { super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CacheGroup\")).andCommandKey(KEY)); this.userName = userName; this.restTemplate = restTemplate; } @Override protected String run() throws Exception { String result = restTemplate.getForObject(\"http://PROVIDER/user/getUser?userName={1}\", String.class, this.userName); logger.info(result); return result; } @Override protected String getFallback() { return super.getFallback(); } @Override protected String getCacheKey() { return this.userName; } public static void cleanCache(String userName) { HystrixRequestCache.getInstance(KEY, HystrixConcurrencyStrategyDefault.getInstance()).clear(userName); }} 用于测试的 Controller 类： 123456789101112131415161718192021@RestController@RequestMapping(\"/user\")public class UserController { private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Autowired private RestTemplate restTemplate; @GetMapping(\"/get\") public String get(String userName) { UserCommand commandOne = new UserCommand(userName, restTemplate); commandOne.execute(); logger.info(\"from cache: \" + commandOne.isResponseFromCache()); UserCommand commandTwo = new UserCommand(userName, restTemplate); commandTwo.execute(); logger.info(\"from cache: \" + commandTwo.isResponseFromCache()); return \"cache test finished\"; }} 启动主类： 123456789@EnableHystrix@EnableDiscoveryClient@SpringBootApplicationpublic class CacheApplication { public static void main(String[] args) { SpringApplication.run(CacheApplication.class, args); }} 访问 http://127.0.0.1:8082/user/get?userName=Tom，调用了两次 execute 方法，使用 Hystrix 的默认方法 isResponseFromCache 来判断请求结果是否来自于缓存，从以下输出可以看出第二次请求确实来自于缓存，此时说明 Hystrix 的缓存生效了。 12c.s.study.controller.CacheController : from cache: falsec.s.study.controller.CacheController : from cache: true 使用注解开启缓存Hystrix 提供了注解来使用缓存机制，且更为方便和快捷，使用 @CacheResult 和 @CacheRemove 即可缓存数据和清除缓存。 使用注解缓存数据： 12345678910111213141516@Servicepublic class DeptService { private static final Logger logger = LoggerFactory.getLogger(DeptService.class); @Autowired private RestTemplate restTemplate; @CacheResult @HystrixCommand public String getDept(String deptName) { String result = restTemplate.getForObject(\"http://PROVIDER/dept/getDept?deptName={1}\", String.class, deptName); logger.info(result); return result; }} 用于测试的 Controller 类： 1234567891011121314@RestController@RequestMapping(\"/dept\")public class DeptController { @Autowired private DeptService deptService; @GetMapping(\"/get\") public String get(String deptName) { deptService.getDept(\"IT\"); deptService.getDept(\"IT\"); return \"annotation cache test finished\"; }} 访问 http://127.0.0.1:8082/dept/get?deptName=IT，调用了两次 get 方法，发现只打印了一条数据，说明第二次的请求是从缓存中读取，即 Hystrix 的缓存生效了。 使用注解清除缓存使用 commandKey 参数来指定 HystrixCommand 的 key，在清除缓存时，可以直接附加这个值来清除指定的参数： 1234567891011121314151617181920212223@Servicepublic class DeptService { private static final Logger logger = LoggerFactory.getLogger(DeptService.class); @Autowired private RestTemplate restTemplate; @CacheResult @HystrixCommand(commandKey = \"findDept\") public String findDept(@CacheKey String deptName) { String result = restTemplate.getForObject(\"http://PROVIDER/dept/getDept?deptName={1}\", String.class, deptName); logger.info(result); return result; } @CacheRemove(commandKey = \"findDept\") @HystrixCommand public String updateDept(@CacheKey String deptName) { logger.info(\"delete dept cache\"); return \"update dept success\"; }} 用于测试的 Controller 类： 1234567891011121314151617181920@RestController@RequestMapping(\"/dept\")public class DeptController { @Autowired private DeptService deptService; @GetMapping(\"/find\") public String find(String deptName) { // 调用接口并缓存数据 deptService.findDept(\"IT\"); deptService.findDept(\"IT\"); // 清除缓存 deptService.updateDept(deptName); // 再调用接口 deptService.findDept(\"IT\"); deptService.findDept(\"IT\"); return \"annotation cache test finished\"; }} 访问 http://127.0.0.1:8082/dept/find?deptName=IT，运行结果如下；在没有缓存的情况下，打印了一次，第二次取的是缓存数据，然后清除缓存后又打印了一次，最后一次又从缓存里取数据： 123DeptService : {\"id\":1,\"deptName\":\"IT\"}DeptService : delete dept cacheDeptService : {\"id\":1,\"deptName\":\"IT\"} 缓存使用注意事项Hystrix 常用缓存注解： @CacheResult：使用该注解后结果会被缓存，同时它需要和 @HystrixCommand 注解一起使用，注解参数为 cacheKeyMethod @CacheRemove：清除缓存，需要指定 commandKey，注解参数为 commandKey、cacheKeyMethod @CacheKey：指定请求命令参数，默认使用方法里的所有参数作为 Key，注解参数为 value 一般在查询接口上使用 @CacheResult，在更新、删除接口上使用 @CacheRemove 删除缓存 使用 Hystrix 缓存时有几方面需要注意： 需要使用 @EnableHystrix 注解启用 Hystrix 需要初始化 HystrixRequestContext，无论是使用继承类还是注解的方式来开启缓存 在指定了 HystrixCommand 的 commandKey 后，在 @CacheRemove 也要指定 commandKey Hystrix Request CollapserRequest Collapser 介绍Request Collapser 是 Hystrix 推出的针对多个请求调用单个后端依赖做的一种优化和节约网络开销的方法。引用官方的这张图，当发起 5 个请求时，在请求没有聚合和合并的情况下，是每个请求单独开启一个线程，并开启一个网络链接进行调用，这都会加重应用程序的负担和开销，并占用 Hystrix 的线程连接池。当使用 Collapser 把请求都合并起来时，则只需要一个线程和一个连接的开销，这大大减少了并发和请求执行所需要的线程数和网络连接数，尤其在一个时间段内有非常多请求的情况下能极大地提高资源利用率。特别注意：若使用 Feign 调用的话，目前还不支持 Collapser。具体使用例子如下，点击下载完整的案例代码。 使用注解进行请求合并使用 Request Collapser 也可以通过继承类和注解的形式来实现，下面主要介绍注解的使用方式。 Request Collapser 和 Hystrix 缓存的使用类似，需要实现 Hystrix 上下文的初始化和关闭，这里使用拦截器来实现： 1234567891011121314151617181920public class HystrixContextInterceptor implements HandlerInterceptor { private HystrixRequestContext context; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { this.context = HystrixRequestContext.initializeContext(); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { this.context.shutdown(); }} 创建配置类，用于注册拦截器： 1234567891011121314@Configurationpublic class CommonConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } @Bean public CacheContextInterceptor userContextInterceptor() { return new CacheContextInterceptor(); }} 1234567891011@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurerAdapter { @Autowired CacheContextInterceptor userContextInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(userContextInterceptor); }} 实现一个 Future 异步返回值的方法，在这个方法上配置请求合并的注解，之后外部通过调用这个方法来实现请求的合并。注意：这个方法必须是 Future 异步返回值的，否则无法合并请求。其中 @HystrixCollapser 注解代表开启请求合并，调用该方法时，实际上运行的是 collapsingList 方法，且利用 HystrixProperty 指定 timerDelayInMilliseconds，这属性代表合并多少毫秒（ms）内的请求，如果不配置的话，默认是 10ms。 1234567891011121314151617181920212223242526@Servicepublic class CollapsingService implements ICollapsingService { private static final Logger logger = LoggerFactory.getLogger(CollapsingService.class); @HystrixCollapser(batchMethod = \"collapsingList\", collapserProperties = { @HystrixProperty(name = \"timerDelayInMilliseconds\", value = \"1000\") }) public Future&lt;User&gt; collapsing(Integer id) { return null; } @HystrixCommand public List&lt;User&gt; collapsingList(List&lt;Integer&gt; userParam) { logger.info(\"collapsingList当前线程: \" + Thread.currentThread().getName()); logger.info(\"当前请求参数个数:\" + userParam.size()); List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); for (Integer userNumber : userParam) { User user = new User(); user.setUserName(\"User - \" + userNumber); user.setAge(userNumber); userList.add(user); } return userList; }} 创建接口测试类，在 getUser 接口内连续调用两次 collapsing 方法： 123456789101112131415161718192021222324@RestController@RequestMapping(\"/user\")public class CollapsingController { private static final Logger logger = LoggerFactory.getLogger(CollapsingController.class); @Autowired private ICollapsingService collapsingService; /** * 请求聚合/合并 * * @return * @throws Exception */ @RequestMapping(\"/getUser\") public String getUser() throws Exception { Future&lt;User&gt; user = collapsingService.collapsing(1); Future&lt;User&gt; user2 = collapsingService.collapsing(2); logger.info(user.get().getUserName()); logger.info(user2.get().getUserName()); return \"Success\"; }} 启动主类： 123456789@EnableHystrix@EnableDiscoveryClient@SpringBootApplicationpublic class CollapsingApplication { public static void main(String[] args) { SpringApplication.run(CollapsingApplication.class, args);} 启动应用后访问 http://127.0.0.1:8082/user/getUser，可以看到实际调用了 collapsingList 方法，并打印了当前线程的名称、请求的参数和运行结果，一共合并了两个请求，达到了预期效果： 1234CollapsingService : collapsingList当前线程: hystrix-CollapsingService-1CollapsingService : 当前请求参数个数:2CollapsingController : User - 1CollapsingController : User - 2 使用注解进行请求合并（全局）上面讲了多个请求是如何合并的，但是都是在同一请求（单一线程）中发起的调用，如果两次请求接口都是在不同线程运行的，那么如何合并整个应用中的请求呢？即如何对所有线程请求中的多次服务调用进行合并呢？ @HystrixCollapser 注解的 scope 属性有个两个值，分别是：Request（默认值）、Global。下面的代码中，增加了一个 scope 属性为 Global 的方法： 1234567891011121314151617181920212223242526@Servicepublic class CollapsingService implements ICollapsingService { private static final Logger logger = LoggerFactory.getLogger(CollapsingService.class); @HystrixCollapser(batchMethod = \"collapsingListGlobal\", scope = Scope.GLOBAL, collapserProperties = { @HystrixProperty(name = \"timerDelayInMilliseconds\", value = \"10000\") }) public Future&lt;User&gt; collapsingGlobal(Integer id) { return null; } @HystrixCommand public List&lt;User&gt; collapsingListGlobal(List&lt;Integer&gt; userParam) { logger.info(\"collapsingListGlobal当前线程: \" + Thread.currentThread().getName()); logger.info(\"当前请求参数个数:\" + userParam.size()); List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); for (Integer userNumber : userParam) { User user = new User(); user.setUserName(\"User- \" + userNumber); user.setAge(userNumber); userList.add(user); } return userList; }} 增加一个调用接口来调用上述方法： 123456789101112131415161718192021222324@RestController@RequestMapping(\"/user\")public class CollapsingController { private static final Logger logger = LoggerFactory.getLogger(CollapsingController.class); @Autowired private ICollapsingService collapsingService; /** * 请求聚合/合并,整个应用的 * * @return * @throws Exception */ @RequestMapping(\"/getUserGolbal\") public String getUserGolbal() throws Exception { Future&lt;User&gt; user = collapsingService.collapsingGlobal(1); Future&lt;User&gt; user2 = collapsingService.collapsingGlobal(2); logger.info(user.get().getUserName()); logger.info(user2.get().getUserName()); return \"Success\"; }} 连续访问 http://127.0.0.1:8082/user/getUserGolbal 两次，会发现所有请求都合并在一个线程中；若改为 Request 作用域，Hystrix 则会运行两个线程来分别处理两次请求。 123456CollapsingService : collapsingListGlobal当前线程: hystrix-CollapsingService-10CollapsingService : 当前请求参数个数:4CollapsingController : User- 1CollapsingController : User- 1CollapsingController : User- 2CollapsingController : User- 2 请求合并总结Hystrix Request Collapser 主要用于请求合并的场景，在一个简单的系统中，这种场景可能很少碰到，所以对于请求合并，一般的使用场景是：当在某个时间段内有大量或并发的相同请求时，则适用使用请求合并；而如果在某个时间段内只有很少的请求，且延迟也不高，此时使用请求合并反而会增加复杂度和延迟，因为对于 Collapser 本身，Hystrix 也是需要时间进行批处理的。 Hystrix 线程传递及并发策略Hystrix 线程传递介绍Hystrix 会对请求进行封装，然后管理请求的调用，从而实现断路器等多种功能。Hystrix 提供了两种隔离模式来进行请求的操作，一种是信号量隔离，一种是线程池隔离。如果是信号量，Hystrix 则在请求的时候会获取到一个信号量，如果成功拿到，则继续进行请求，请求在同一个线程中执行完毕。如果是线程池隔离，Hystrix 会把请求放入线程池中执行，这时就有可能产生线程的变化，从而导致线程 1 的上下文数据在线程 2 里不能正常拿到。下面通过一个例子来说明，点击下载完整的案例代码。 Hystrix 线程传递问题重现建立一个 ThreadLocal 来保存用户的信息，通常在微服务里，会把当前请求的上下文数据放入本地线程变量，便于后续使用和销毁： 1234public class HystrixThreadLocal { public static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();} 定义测试接口，打印当前线程的 ID，并利用 ThreadLocal 存放用户信息；为了兼容其他情况，例如在使用 Feign 调用的时候，通常会使用 RequestContextHolder 拿到上下文属性，在此也进行测试一下： 12345678910111213141516171819@RestController@RequestMapping(\"/user\")public class UserController { private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Autowired private UserService userService; @GetMapping(\"/get/{id}\") public String get(@PathVariable(\"id\") Integer id) { HystrixThreadLocal.threadLocal.set(\"userId: \" + id); RequestContextHolder.currentRequestAttributes().setAttribute(\"userId\", \"userId: \" + id, RequestAttributes.SCOPE_REQUEST); logger.info(\"current thread: \" + Thread.currentThread().getId()); logger.info(\"thread local: \" + HystrixThreadLocal.threadLocal.get()); logger.info(\"RequestContextHolder: \" + RequestContextHolder.currentRequestAttributes().getAttribute(\"userId\", RequestAttributes.SCOPE_REQUEST)); return userService.get(id); }} 定义服务类，测试在没有使用线程池隔离模式的情况下，获取用户信息： 123456789101112@Servicepublic class UserService { private static final Logger logger = LoggerFactory.getLogger(UserService.class); public String get(Integer id) { logger.info(\"current thread: \" + Thread.currentThread().getId()); logger.info(\"thread local: \" + HystrixThreadLocal.threadLocal.get()); logger.info(\"RequestContextHolder: \" + RequestContextHolder.currentRequestAttributes().getAttribute(\"userId\", RequestAttributes.SCOPE_REQUEST).toString()); return \"Success\"; }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，可以看到打印的线程 ID 都是一样的，线程变量也是传入 2，请求上下文的持有对象也可以顺利拿到： 1234567UserController : current thread: 59UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 59UserService : thread local: userId: 2UserService : RequestContextHolder: userId: 2 服务类添加 @HystrixCommand 注解，测试在使用线程池隔离模式的情况下，获取用户信息： 12345678910111213@Servicepublic class UserService { private static final Logger logger = LoggerFactory.getLogger(UserService.class); @HystrixCommand public String get(Integer id) { logger.info(\"current thread: \" + Thread.currentThread().getId()); logger.info(\"thread local: \" + HystrixThreadLocal.threadLocal.get()); logger.info(\"RequestContextHolder: \" + RequestContextHolder.currentRequestAttributes().getAttribute(\"userId\", RequestAttributes.SCOPE_REQUEST).toString()); return \"Success\"; }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，会发现进入的线程池 ID 是 57，当达到后台服务的时候，线程 ID 变成 82，说明线程池的隔离已经生效，是重新启动的线程处理请求的，然后线程的变量也丢失了，RequestContextHolder 中也抛出了异常，意思是没有绑定线程变量，至此成功地重现了父子线程数据传递的问题。 1234567UserController : current thread: 57UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 82UserService : thread local: nulljava.lang.IllegalStateException: No thread-bound request found: Hystrix 线程传递问题解决方案解决 Hystrix 的线程传递问题有两种方法： 第一种：修改 Hystrix 的隔离策略，使用信号量隔离，直接修改配置文件即可，但 Hystrix 默认是线程池隔离，加上从真实的项目情况看，大部分都是使用线程池隔离，因此此方案不太推荐，对应属性为：hystrix.command.default.execution.isolation.strategy 第二种：Hystrix 官方推荐的一种方式，就是使用继承 HystrixConcurrencyStrategy 类覆盖 wrapCallable 方法，下面将介绍此方法的使用例子 创建 HystrixThreadCallable 类，该类的构造函数是希望传递 RequestContextHolder 和自定义的 HystrixThreadLocal 对象： 123456789101112131415161718192021222324public class HystrixThreadCallable&lt;S&gt; implements Callable&lt;S&gt; { private final RequestAttributes requestAttributes; private final Callable&lt;S&gt; delegate; private String params; public HystrixThreadCallable(Callable&lt;S&gt; callable, RequestAttributes requestAttributes, String params) { this.delegate = callable; this.requestAttributes = requestAttributes; this.params = params; } @Override public S call() throws Exception { try { RequestContextHolder.setRequestAttributes(requestAttributes); HystrixThreadLocal.threadLocal.set(params); return delegate.call(); } finally { RequestContextHolder.resetRequestAttributes(); HystrixThreadLocal.threadLocal.remove(); } }} 重写 HystrixConcurrencyStrategy 类的 wrapCallable 方法，在执行请求前包装 HystrixThreadCallable 对象，将需要的对象信息设置进去，这样在下一个线程中就可以拿到了： 1234567public class SpringCloudHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy { @Override public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) { return new HystrixThreadCallable&lt;&gt;(callable, RequestContextHolder.getRequestAttributes(), HystrixThreadLocal.threadLocal.get()); }} 配置类： 12345678@Configurationpublic class HystrixThreadContextConfiguration { @Bean public SpringCloudHystrixConcurrencyStrategy springCloudHystrixConcurrencyStrategy() { return new SpringCloudHystrixConcurrencyStrategy(); }} 启动应用后访问 http://127.0.0.1:8082/user/get/2 后，可以发现即使使用了 Hystrix 的线程池隔离模式，不同的线程也能顺利拿到上一个线程传递过来的信息： 1234567UserController : current thread: 59UserController : thread local: userId: 2UserController : RequestContextHolder: userId: 2UserService : current thread: 84UserService : thread local: userId: 2UserService : RequestContextHolder: userId: 2 并发策略共存由于 HystrixPlugins 的 registerConcurrencyStrategy 方法只能被调用一次，即 Hystrix 不允许注册多个 Hystrix 并发策略，不然就会报错，这就导致了无法和其他并发策略一起使用，因此需要将其他并发策略注入进去，达到并存的目的，如 sleuth 的并发策略也是做了同样的事情。具体的做法就是在构造此并发策略时，找到之前已经存在的并发策略，并保留在类的属性中，在调用过程中，返回之前并发策略的相关信息，如请求变量、连接池、阻塞队列；等请求进来时，既不影响之前的并发策略，也可以包装需要的请求信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class SpringCloudHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy { private HystrixConcurrencyStrategy delegateHystrixConcurrencyStrategy; @Override public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) { return new HystrixThreadCallable&lt;&gt;(callable, RequestContextHolder.getRequestAttributes(), HystrixThreadLocal.threadLocal.get()); } public SpringCloudHystrixConcurrencyStrategy() { init(); } private void init() { try { this.delegateHystrixConcurrencyStrategy = HystrixPlugins.getInstance().getConcurrencyStrategy(); if (this.delegateHystrixConcurrencyStrategy instanceof SpringCloudHystrixConcurrencyStrategy) { return; } HystrixCommandExecutionHook commandExecutionHook = HystrixPlugins.getInstance().getCommandExecutionHook(); HystrixEventNotifier eventNotifier = HystrixPlugins.getInstance().getEventNotifier(); HystrixMetricsPublisher metricsPublisher = HystrixPlugins.getInstance().getMetricsPublisher(); HystrixPropertiesStrategy propertiesStrategy = HystrixPlugins.getInstance().getPropertiesStrategy(); HystrixPlugins.reset(); HystrixPlugins.getInstance().registerConcurrencyStrategy(this); HystrixPlugins.getInstance().registerCommandExecutionHook(commandExecutionHook); HystrixPlugins.getInstance().registerEventNotifier(eventNotifier); HystrixPlugins.getInstance().registerMetricsPublisher(metricsPublisher); HystrixPlugins.getInstance().registerPropertiesStrategy(propertiesStrategy); } catch (Exception e) { throw e; } } @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixProperty&lt;Integer&gt; corePoolSize, HystrixProperty&lt;Integer&gt; maximumPoolSize, HystrixProperty&lt;Integer&gt; keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { return this.delegateHystrixConcurrencyStrategy.getThreadPool(threadPoolKey, corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolProperties threadPoolProperties) { return this.delegateHystrixConcurrencyStrategy.getThreadPool(threadPoolKey, threadPoolProperties); } @Override public BlockingQueue&lt;Runnable&gt; getBlockingQueue(int maxQueueSize) { return this.delegateHystrixConcurrencyStrategy.getBlockingQueue(maxQueueSize); } @Override public &lt;T&gt; HystrixRequestVariable&lt;T&gt; getRequestVariable(HystrixRequestVariableLifecycle&lt;T&gt; rv) { return this.delegateHystrixConcurrencyStrategy.getRequestVariable(rv); }} 补充内容Hystrix 的优势Hytrix 支持异步调用，支持线程池级别的隔离 这种方式就是通过 RxJava 进行调用，等待完成后进行异步通知调用，但在 HTTP 这种请求中，主线程还是阻塞在等待中。带来的收益无非就是 Hytrix 能对超时进行控制。但缺点也很明显，如果是每个接口创建一个线程池的话，如果接口过多，机器中会创建大量线程，而在 Java 中，线程是属于轻量级的进程，对应是内核线程，进而造成线程的切换。而线程切换的成本也比较高。再者还需要预先给各个资源做线程池大小的分配，并且对于一些使用了 ThreadLocal 的场景不友好。 Hytrix 支持百分比 + 连续错误比率的条件进行降级 这确实比 Sentinel 单纯的统计异常率，或异常数更精细，技术选型具体根据业务去取舍。正如阿里巴巴自己比较的，Sentinel 侧重于流控，而熔断的话 Hytrix 更灵活和专业的，虽然 Hystrix 已经停止开发了，但一般情况下用 Sentinel 代替 Hytrix 也足够了。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Manjaro 安装图解教程","url":"/posts/eadad846.html","text":"官方桌面环境比较 XFCE 资源占用少，稳定 GNOME 定制性差，资源占用中等 KDE 定制性高，资源占用多，运行比较卡 官方桌面环境图 社区桌面环境图 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"manjaro"},{"title":"OpenFeign 入门教程 - 基础篇","url":"/posts/906bddbc.html","text":"Spring Cloud OpenFeign 介绍Feign 概述在使用 Spring Cloud 开发微服务应用时，各个服务提供者都是以 HTTP 接口的形式对外提供服务，因此在服务消费者调用服务提供者时，底层通过 HTTP Client 的方式访问。此时可以使用 JDK 原生的 URLConnection、Apache 的 HTTP Client、Netty 的异步 HTTP Client 或者 Spring 的 RestTemplate 去实现服务间的调用。但是最方便、最优雅的方式是通过 Feign 进行服务间的调用。Feign 是由 Netflix 开发的一个声明式的 Web Service 客户端，它的出现使开发 Web Service 客户端变得很简单；Feign 同时也是一款声明式、模板化的 HTTP 客户端。更多介绍可参考：Feign 项目、Spring Cloud Feign 官方中文教程 Spring Cloud OpenFeign 概述Spring Cloud OpenFeign 对 Feign 进行了二次封装，使得在 Spring Cloud 中使用 Feign 的时候，可以做到使用 HTTP 请求访问远程服务，就像调用本地方法一样的，开发者完全感知不到这是在调用远程访问，更感知不到在访问 HTTP 请求。Spring Cloud OpenFeign 增强了 Feign 的功能，使 Feign 有限支持 Spring MVC 的注解，如 @RequestMapping 等。OpenFeign 的 @FeignClient 注解可以解析 Spring MVC 的 @RequestMapping 注解下的接口，并通过动态代理的方式产生实现类，在实现类中做负载均衡并调用其他服务，默认集成了 Ribbon 与 Hystrix。更多介绍可参考：Spring Cloud OpenFeign 项目 Spring Cloud OpenFeign 的特性 Feign 最新特性一览图 支持 Hystrix 和 它的 Fallback 支持 HTTP 请求的响应和压缩 支持 Ribbon 的负载均衡客户端 支持可插拔的 HTTP 编码器和解码器 可插拔的注解支持，包括 Feign 注解 和 JAX-RS 注解 Feign 与 Spring Cloud OpenFeign 的选择Spring Cloud F 及 F 版本以上与 Spring Boot 2.0 以上一般使用 OpenFeign，如果从框架结构上看，OpenFeign 就是 2019 年 Feign 停更后出现的版本，也可以说大多数新项目都用 OpenFeign，而 2018 年以前的项目一般使用 Feign，大概可以这样粗率地划分。 Spring Cloud OpenFeign 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码。由于篇幅有限，下文中若没特殊说明，Feign 一般指的就是 Spring Cloud OpenFeign。 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程为了测试 Feign 的 Web 服务客户端的功能，必须要有一个源服务（服务提供者），并且可以选择启动多个实例，在每个实例中需要有一个标识（例如端口）来识别每次的调用是到了不同的服务实例上。这里可以使用一份代码，采取改变端口号的方式启动多次，就能启动多个相同的服务实例。创建 Provider 的 Maven 工程后，由于需要将服务注册到 Eureka Server，工程下的 pom.xml 文件需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号，后面启动多实例只需要修改这里的端口号即可： 12345678910111213server: port: 9090spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping(\"/provider/add\") public String add(Integer a, Integer b, HttpServletRequest request) { return \"From Port: \" + request.getServerPort() + \", Result: \" + (a + b); }} 5. 创建 Feign Client 工程创建 Feign Client 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-openfeign；若是使用旧版的 Spring Cloud，则改为引入 spring-cloud-starter-feign。另外由于需要从 Eureka Server 获取服务列表，即作为 Eureka 客户端，还需要引入 spring-cloud-starter-netflix-eureka-client。 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建启动主类，添加注解 @EnableFeignClients、@EnableDiscoveryClient 123456789@EnableFeignClients@EnableDiscoveryClient@SpringBootApplicationpublic class FeignApplication { public static void main(String[] args){ SpringApplication.run(FeignApplication.class, args); }} 创建服务接口类，用于调用 Provider 源服务： 123456@FeignClient(value = \"PROVIDER\")public interface ProviderClientService { @GetMapping(\"/provider/add\") String add(@RequestParam(\"a\") Integer a, @RequestParam(\"b\") Integer b);} 创建用于测试的 Controller 类，因为需要创建一个 API 来供第三方调用 Provider 源服务的那个自定义 API： 1234567891011@RestControllerpublic class CalculateController { @Autowired private ProviderClientService clientService; @GetMapping(\"/add\") public String add(Integer a, Integer b){ return clientService.add(a, b); }} 在 application.yml 文件中配置端口号、注册中心地址： 12345678910111213server: port: 8080spring: application: name: feign-clienteureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 6. 测试 启动 Eureka Server 后，更改 Provider 源服务的端口号为 9091 与 9092 后分别启动，浏览器访问 http://127.0.0.1:8090，查看 Eureka Server 的界面是否正常显示多个 Provider 源服务 启动 Feign Client 应用，浏览器访问 http://localhost:8080/add?a=3&amp;b=9，若正常返回计算结果，说明整个项目运行成功 提示：由于 Feign 默认集成了 Ribbon（客户端负载均衡），当存在多个服务提供者时，Feign 默认会使用轮询的方式访问源服务，此外 Feign 对服务实例节点的增减也能动态感知 Spring Cloud OpenFeign 基础功能Feign 的工作原理 开发微服务应用时，在主程序入口添加 @EnableFeignClients 注解开启对 Feign Client 扫描加载处理。根据 Feign Client 的开发规范，需要定义接口并添加 @FeignClient 注解。 当程序启动时，会进行包扫描，扫描所有标注了 @FeignClient 注解的类，并将这些信息注入 Spring IOC 容器中。 当定义的 Feign 接口中的方法被调用时，通过 JDK 的代理方式，来生成具体的 RequestTemplate。生成代理时，Feign 会为每个接口方法创建一个 RestTemplate 对象，该对象封装了 HTTP 请求需要的全部信息，如请求参数名、请求方法等信息都在这个过程中确定。 然后由 RestTemplate 生成 Request，接着把 Request 交给 Client 去处理，这里指的 Client 可以是 JDK 原生的 URLConnection、Apache 的 Http Client、也可以是 Okhttp。最后 Client 被封装到 LoadBalanceClient 类中，这个类结合 Ribbon 客户端负载均衡发起服务间的调用。 @FeignClient 注解的属性 name：指定 FeignClient 的名称，如果项目使用了 Ribbon，那么 name 属性会作为微服务的名称，用于服务发现 url：一般用于调试，可以手动指定 @FeignClient 调用的服务地址 decode404：当发生 404 错误时，如果该字段值为 true，会调用 decoder 进行解码，否则抛出 FeignException configuration：Feign 配置类，可以自定义 Feign 的 Encoder、Decoder、LogLevel、Contract fallback：定义容错的处理类，当调用远程接口失败或超时，会调用对应接口的容错逻辑，fallback 指定的类必须实现 @FeignClient 标记的接口 fallbackFactory：工厂类，用于生成 fallback 类示例，通过这个属性可以实现每个接口通用的容错逻辑，减少重复的代码 path：定义当前 FeignClient 的统一前缀 Feign 属性文件配置若希望对单个指定特定名称的 Feign 进行配置，此时可以将 @FeignClient 注解的属性配置写在 application.yml 或者 application.properties，配置示例如下： 12345678910111213141516feign: client: config: feignName: # 需要配置的FeignName connectTimeout: 5000 # 连接超时时间 readTimeout: 5000 # 读超时时间设置 loggerLevel: full # 配置Feign的日志级别 errorDecoder: com.example.SimpleErrorDecoder # Feign的错误解码器 retryer: com.example.SimpleRetryer # 配置重试 requestInterceptors: # 配置拦截器 - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false encoder: com.example.SimpleEncoder # Feign的编码器 decoder: com.example.SimpleDecoder # Feign的解码器 contract: com.example.SimpleContract # Feign的Contract配置 作用于所有 Feign 的配置方式，如果想使用 application.yml 或者 application.properties 来配置所有 Feign，可以使用下述配置： 1234567feign: client: config: default: readTimeout: 5000 loggerLevel: full connectTimeout: 5000 @EnableFeignClients 注解上有个 defaultConfiguration 属性，可以将默认配置统一写在一个配置类中，然后在主程序入口用 defaultConfiguration 来应用配置类，该配置方式同样可以作用于所有 Feign 123456789@SpringBootApplication@EnableDiscoveryClient@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration.class)public class FeignApplication { public static void main(String[] args){ SpringApplication.run(FeignApplication.class, args); }} 特别注意：如果通过 Java 代码的方式配置过 Feign，然后又通过 application.yml 或者 application.properties 属性文件的方式配置 Feign，默认情况下属性文件中 Feign 的配置会覆盖 Java 代码的配置。但是可以通过使用参数 feign.client.default-to-properties=false 来改变 Feign 配置生效的优先级。 Feign Client 开启日志Feign 为每一个 FeignClient 都提供了一个 feign.Logger 实例，可以在配置中开启日志，开启方式比较简单，分为两步。 第一步：在 application.yml 中配置日志输出，默认情况下，记录器的名称是用于创建 Feign 客户端的接口的完整类名，Feign 日志记录仅响应 DEBUG 级别 123logging: level: com.springcloud.study.service.ProviderClientService: debug 第二步：通过 Java 代码的方式配置日志 Bean，可以配置在主程序入口类或者带有 @Configuration 注解的类，作用是通过配置的 Logger.Level 对象告诉 Feign 记录哪些日志内容 1234567891011121314151617@Configurationpublic class FeignServiceConfig { /** * Logger.Level 的具体级别如下： * NONE：不记录任何信息 * BASIC：仅记录请求方法、URL以及响应状态码和执行时间 * HEADERS：除了记录 BASIC级别的信息外，还会记录请求和响应的头信息 * FULL：记录所有请求与响应的明细，包括头信息、请求体、元数据 * * @return */ @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; }} Feign 开启 GZIP 压缩Feign 支持对请求和响应进行 GZIP 压缩，以此提高通信效率，下述内容配置了 Consumer 通过 Feign 到 Provider 的请求与相应的 Gzip 压缩（在服务消费者端配置） 12345678feign: compression: request: enabled: true mime-types: text/xml,application/xml,application/json # 配置压缩支持的MIME TYPE min-request-size: 2048 # 配置压缩数据大小的下限 response: enabled: true # 配置响应GZIP压缩 由于开启 GZIP 压缩后，Feign 之间的调用是通过二进制协议进行传输的，若服务之间的调用结果出现了乱码，此时可以将返回值的类型修改为 ResponseEntity&lt;byte[]&gt;，其中的 Controller 类 与被 @FeignClient 注解标注的接口都要修改 123456@FeignClient(value = \"PROVIDER\")public interface ProviderClientService { @GetMapping(\"/provider/say\") ResponseEntity&lt;byte[]&gt; String say(@RequestParam(\"msg\") String msg);} 1234567891011@RestControllerpublic class CalculateController { @Autowired private ProviderClientService clientService; @GetMapping(\"/say\") public ResponseEntity&lt;byte[]&gt; say(String msg){ return clientService.say(msg); }} 验证压缩效果，首先开启 Feign 的日志输出，然后分别启用 Feign 压缩与关闭 Feign 压缩，观察前后输出的日志信息： 关闭 GZIP 压缩的 Request 12---&gt; GET http://PROVIDER/provider/say?msg=hello HTTP/1.1---&gt; END HTTP (0-byte body) 开启 GZIP 压缩的 Request，增加了 Accept-Encoding: gzip，证明 Request 开启了 GZIP 压缩 1234---&gt; GET http://PROVIDER/provider/say?msg=hello HTTP/1.1Accept-Encoding: gzipAccept-Encoding: deflate---&gt; END HTTP (0-byte body) Feign 的超时设置Feign 的调用分为两层，即 Ribbon 的调用和 Hystrix 的调用；其中高版本的 Feign 默认关闭了 Hystrix，而 Ribbon 默认是启用了。首先根据超时的异常日志信息，判断是 Ribbon 超时 还是 Hystrix 超时导致了异常的发生，然后根据判断结果添加 Ribbon 或者 Hystrix 的超时配置信息即可。例如：下述配置内容是针对 provider 服务添加与 Ribbon 超时相关的配置参数： 1234PROVIDER: ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 Feign 使用注意事项 在 Feign Client 接口中，不支持 GET 方法直接绑定 POJO 等复杂对象 在 Feign Client 接口中，如果使用到 @PathVariable，必须指定其 value 在 Feign Client 接口中，不能使用 @GetMapping 之类的组合注解，只支持使用 @RequestMapping 这类基础注解 @FeignClient 的属性中，serviceId 属性已经失效，推荐使用 name 属性 @FeignClient 的属性中，在老版本的 Spring Cloud 使用 url 属性时，不需要提供 name 属性；但在新版本中里必须提供 name 属性，并且 name、url 属性支持占位符 若需要自定义单个 Feign Client 的配置，此时被 @Configuration 注解标注的类，不允许被 @ComponentScan 注解扫描到，否则将会导致所有的 Feign Client 都会使用该配置 Spring Cloud OpenFeign 实战应用Feign 默认 Client 的替换Feign 在默认情况下使用的是 JDK 原生的 URLConnection 发送 HTTP 请求，没有使用连接池，但是对每个地址都会保持一个长连接，即利用 HTTP 的 persistence connections。开发者可以用 Apache 的 HTTP Client 替换 Feign 原始的 HTTP Client，通过设置连接池、超时时间等对服务之间的调用进行调优。通过查看源码，在类 feign.Client.Default 中可以看到以下代码，默认执行 HTTP 请求的就是 URLConnection。而在类 org.springframework.cloud.openfeign.ribbon.FeignRibbonClientAutoConfiguration 中，可以看到引入了三个类：HttpClientFeignLoadBalancedConfiguration、OkHttpFeignLoadBalancedConfiguration、DefaultFeignLoadBalancedConfiguration，其中可以看到在 DefaultFeignLoadBalancedConfiguration 中，使用的是 feign.Client.Default，即使用了 URLConnection。 1234567public static class Default implements Client { public Response execute(Request request, Options options) throws IOException { HttpURLConnection connection = this.convertAndSend(request, options); return this.convertResponse(connection).toBuilder().request(request).build(); }} 12345678class DefaultFeignLoadBalancedConfiguration { @Bean @ConditionalOnMissingBean public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) { return new LoadBalancerFeignClient(new Default((SSLSocketFactory)null, (HostnameVerifier)null), cachingFactory, clientFactory); }} 使用 HTTP Client 替换替换步骤使用 Apache HTTP Client 替换 Feign 默认的 Client，替换步骤非常简单，只需要在 pom.xml 与 application.yml 分别添加以下配置内容即可： 1234567891011&lt;!-- 引入 HTTP Client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 引入 Feign 对 Http Client 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 123feign: httpclient: enabled: true 常见错误引入 feign-httpclient 出现下述的错误信息。查看源码可知，这是由于 OpenFeign 调用的不是 com.netflix.feign 的 feign-core 包的代码，而是调用了自身的 feign-core 的代码，但自身的 feign-core 包中的 Response 类并没有 create() 方法导致的。 1Caused by: java.lang.NoSuchMethodError: feign.Response.create(ILjava/lang/String;Ljava/util/Map;Lfeign/Response$Body;)Lfeign/Response; 解决方法是改为引入 io.github.openfeign 的 feign-httpclient 包，配置内容如下： 1234567891011&lt;!-- 引入 HTTP Client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 引入 Feign 对 Http Client 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 验证替换在类 HttpClientFeignLoadBalancedConfiguration 上，声明了注解 @ConditionalOnClass(ApacheHttpClient.class)、@ConditionalOnProperty(value = \"feign.httpclient.enabled\", matchIfMissing = true)，即只有在 ApacheHttpClient 类存在且 feign.httpclient.enabled 为 true 时才会启用配置。此时可以在 HttpClientFeignLoadBalancedConfiguration.feignClient() 方法里打上断点（约第 43 行），重新启动项目（切记不要以单元测试的方式启动，否则可能会因缺少配置导致无法进入打断点的代码），可以看到确实进行了 ApacheHttpClient 的声明；再将 feign.httpclient.enabled 设置为 false 后，断点就进不来了，由此可以验证 ApacheHttpClient 替换成功。 使用 Okhttp 替换替换步骤使用 Okhttp 替换 Feign 默认的 Client，同样只需要在 pom.xml 与 application.yml 分别添加以下配置内容 12345&lt;!-- 引入 Feign 对 Okhttp 的支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 123feign: okhttp: enabled: true 参数配置若需要对 Okhttp 进行个性化的参数设置，可参考以下代码，其中 Okhttp 的特性有： 支持 SPDY，可以合并多个到同一个主机的请求 使用连接池技术减少请求的延迟（如果 SPDY 是可用的话） 使用 GZIP 压缩减少传输的数据量 缓存响应结果，避免重复的网络请求 1234567891011121314151617181920@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignOkHttpConfig { @Bean public okhttp3.OkHttpClient okHttpClient(){ return new okhttp3.OkHttpClient.Builder() //设置连接超时 .connectTimeout(60, TimeUnit.SECONDS) //设置读超时 .readTimeout(60, TimeUnit.SECONDS) //设置写超时 .writeTimeout(60,TimeUnit.SECONDS) //是否自动重连 .retryOnConnectionFailure(true) .connectionPool(new ConnectionPool()) //构建OkHttpClient对象 .build(); }} 验证替换在 OkHttpFeignLoadBalancedConfiguration.feignClient() 方法里打断点调试，然后正常启动项目（切记不要以单元测试的方式启动，否则可能会因缺少配置导致无法进入打断点的代码）。 Post 和 Get 的多参数传递多参数传递方案介绍在企业项目的开发过程中，使用 Feign 实现服务与服务之间的调用时，无法避免多参数的传递。众所周知，在 Web 开发中 Spring MVC 是支持 GET 方法直接绑定 POJO 的，但是 Feign 的实现并未覆盖所有 Spring MVC 的功能，目前解决方式很多，最常见的解决方式如下： 将方法参数封装成 Map 传递 通过 Feign 拦截器的方式处理（推荐） 将 POJO 拆散一个个单独的属性放在方法参数里 使用 GET 传递 @RequestBody，但此方式违反了 Restful 规范 多参数传递的示例代码这里主要介绍通过 Feign 拦截器处理的方式，通过实现 Feign 的 RequestInterceptor 中的 aplly 方法，来进行统一拦截转换处理 Feign 中的 GET 方法多参数传递的问题。由于篇幅有限，下面只贴出核心代码，完整的示例代码可以点击这里下载。 为了方便测试服务之间的接口调用，在 Consumer 端（服务消费者）整合 Swagger2， pom.xml 加入以下配置： 1234567891011&lt;!-- Swagger2 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 在 Consumer 端（服务消费者）编写 Feign 拦截器代码，由于 Feign 不支持 GET 方法传 POJO，因此手动将 Json Body 转换为 Query： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@Componentpublic class FeignRequestInterceptor implements RequestInterceptor { @Autowired private ObjectMapper objectMapper; @Override public void apply(RequestTemplate template) { // Feign 不支持 GET 方法传 POJO, 将 Json Body 转换为 Query if (template.method().equals(\"GET\") &amp;&amp; template.body() != null) { try { JsonNode jsonNode = objectMapper.readTree(template.body()); template.body(null); Map&lt;String, Collection&lt;String&gt;&gt; queries = new HashMap&lt;&gt;(); buildQuery(jsonNode, \"\", queries); template.queries(queries); } catch (IOException e) { // 根据实践项目情况处理此处异常 e.printStackTrace(); } } } private void buildQuery(JsonNode jsonNode, String path, Map&lt;String, Collection&lt;String&gt;&gt; queries) { if (!jsonNode.isContainerNode()) { // 叶子节点 if (jsonNode.isNull()) { return; } Collection&lt;String&gt; values = queries.get(path); if (null == values) { values = new ArrayList&lt;&gt;(); queries.put(path, values); } values.add(jsonNode.asText()); return; } if (jsonNode.isArray()) { // 数组节点 Iterator&lt;JsonNode&gt; it = jsonNode.elements(); while (it.hasNext()) { buildQuery(it.next(), path, queries); } } else { Iterator&lt;Map.Entry&lt;String, JsonNode&gt;&gt; it = jsonNode.fields(); while (it.hasNext()) { Map.Entry&lt;String, JsonNode&gt; entry = it.next(); if (StringUtils.hasText(path)) { buildQuery(entry.getValue(), path + \".\" + entry.getKey(), queries); } else { // 根节点 buildQuery(entry.getValue(), entry.getKey(), queries); } } } }} 编写 Consumer 端（服务消费者）的 Feign Client 接口类： 1234567891011121314@FeignClient(name = \"PROVIDER\")public interface UserFeignService { /** * 默认情况下，Feign 不支持 GET 方法传 POJO * @param user * @return */ @RequestMapping(value = \"/user/add\", method = RequestMethod.GET) String addUser(User user); @RequestMapping(value = \"/user/update\", method = RequestMethod.POST) String updateUser(@RequestBody User user);} 使用 Swagger2，并编写 Consumer 端（服务消费者）的 Controller 类，用于调用 Feign Client 进行 GET 或者 POST 多参数传递 123456789101112131415161718192021222324252627282930@RestController@Api(\"用户管理相关接口\")@RequestMapping(\"/user\")public class UserController { @Autowired private UserFeignService userFeignService; /** * 用于演示Feign的Get请求多参数传递 * @param user * @return */ @ApiOperation(\"添加用户的接口\") @RequestMapping(value = \"/add\", method = RequestMethod.GET) public String addUser(@ApiParam(name=\"用户\",required=true) User user){ return userFeignService.addUser(user); } /** * 用于演示Feign的Post请求多参数传递 * @param user * @return */ @ApiOperation(\"更改用户的接口\") @RequestMapping(value = \"/update\", method = RequestMethod.POST) public String updateUser( @RequestBody @ApiParam(name=\"用户\",value=\"传入json格式\",required=true) User user){ return userFeignService.updateUser(user); }} 编写 Provider 端（服务提供者）的 Controller 类，用于接收 Feign Client 的 GET 请求传递过来的 User 对象： 12345678910111213141516@RestController@RequestMapping(\"/user\")public class UserController { @RequestMapping(value = \"/add\", method = RequestMethod.GET) public User addUser(User user) { System.out.println(\"==&gt; add: \" + user.getId() + '-' + user.getName() + \"-\" + user.getAge()); return user; } @RequestMapping(value = \"/update\", method = RequestMethod.POST) public User updateUser(@RequestBody User user) { System.out.println(\"==&gt; update: \" + user.getId() + '-' + user.getName() + \"-\" + user.getAge()); return user; }} 分别启动各个应用后，浏览器访问 http://127.0.0.1:8080/swagger-ui.html，通过 Swagger2 提供的 UI 界面测试对应的接口即可。 Feign 处理文件上传Netflix 开发的 Feign 早先不支持文件上传，后来虽支持但仍有缺陷，需要一次性完整地将文件读到内存再编码发送。在早期的 Spring Cloud 中，Feign 本身是没有文件上传功能的，要想实现文件上传功能，需要自行编写 Encoder 去实现文件上传。后来 Netflix 官方提供了子项目 feign-form，其中实现了文件上传所需的 Encoder。由于篇幅有限，下面只贴出核心代码，完整的示例代码可以点击这里下载。 在 Consumer 端（服务消费者）的 pom.mxl 文件添加以下内容： 1234567891011&lt;!-- Feign 文件上传--&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; 在 Consumer 端（服务消费者）中，指定 Feign Client 处理文件上传的编码器，特别注意：该配置类不能被 @ComponentScan 注解扫描到，否则该配置将应用到所有 Feign Client 1234567891011/** * Feign Client 配置（非全局生效） */@Configurationpublic class FeignMultipartSupportConfig { @Bean public Encoder multipartFormEncoder() { return new SpringFormEncoder(); }} 编写 Consumer 端（服务提供者）的 Feign 文件上传的客户端： 12345678910111213@FeignClient(name = \"PROVIDER\", configuration = FeignMultipartSupportConfig.class)public interface FileUploadFeignService { /*** * produces, consumes必填 * @param file * @return */ @RequestMapping(value = \"/uploadFile\", method = RequestMethod.POST, produces = {MediaType.APPLICATION_JSON_UTF8_VALUE}, consumes = MediaType.MULTIPART_FORM_DATA_VALUE) String fileUpload(@RequestPart(value = \"file\") MultipartFile file);} 使用 Swagger2，并编写 Consumer 端（服务提供者）的 Controller 类，用于上传文件： 1234567891011121314@RestController@Api(value = \"文件上传接口\")@RequestMapping(\"/feign\")public class FeignUploadController { @Autowired private FileUploadFeignService fileUploadFeignService; @ApiOperation(value = \"文件上传\", notes = \"请选择文件上传\") @PostMapping(value = \"/upload\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE) public String imageUpload(@RequestPart(value = \"file\") @ApiParam(value = \"文件上传\", required = true) MultipartFile file) throws Exception { return fileUploadFeignService.fileUpload(file); }} 编写 Provider 端（服务提供者）的 Controller 类，用于接收 Feign Client 上传的文件: 12345678@RestControllerpublic class FeignUploadController { @PostMapping(value = \"/uploadFile\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE) public String fileUploadServer(@RequestPart(value = \"file\") MultipartFile file) throws Exception { return \"file-name: \" + file.getOriginalFilename() + \" file-size: \" + file.getSize(); }} 分别启动各个应用后，浏览器访问 http://127.0.0.1:8080/swagger-ui.html，通过 Swagger2 提供的 UI 界面上传文件即可。 Feign 处理首次请求失败当 Feign 和 Ribbon 整合了 Hystrix 之后，可能会出现首次调用失败的问题。原因是 Hystrix 默认的超时时间是 1 秒，如果超过这个时间尚未作出响应，将会进入 fallback 代码。由于 Bean 的装配以及懒加载机制等，Feign 首次请求都会比较慢，如果这个响应时间超过 1 秒，就会出现请求失败的问题。此时可以采取以下三种方法处理： 使用 Feign 的时候直接关闭 Hystrix（不推荐）： feign.hystrix.enabled=false 禁用 Hystrix 的超时时间： hystrix.command.default.execution.timeout.enabled=false 将 Hystrix 的超时时间改为 5 秒： hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000 Feign 调用传递 Token在进行认证鉴权的时候，不管是 JWT 还是 Spring Security，当使用 Feign 时就会发现外部请求到 A 服务的时候，A 服务是可以拿到 Token 的；然而当 A 服务使用 Feign 调用 B 服务时，Token 就会丢失，从而导致认证失败。解决方法比较简单，可以利用 RequestInterceptor 拦截器，在 Feign 调用的时候，向请求头里面添加需要传递的 Token，示例代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940/** * Feign统一Token拦截器 */@Componentpublic class FeignTokenInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate requestTemplate) { if(null==getHttpServletRequest()){ //此处省略日志记录 return; } //将获取Token对应的值往下面传 requestTemplate.header(\"oauthToken\", getHeaders(getHttpServletRequest()).get(\"oauthToken\")); } private HttpServletRequest getHttpServletRequest() { try { return ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); } catch (Exception e) { return null; } } /** * Feign拦截器拦截请求获取Token对应的值 * @param request * @return */ private Map&lt;String, String&gt; getHeaders(HttpServletRequest request) { Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;(); Enumeration&lt;String&gt; enumeration = request.getHeaderNames(); while (enumeration.hasMoreElements()) { String key = enumeration.nextElement(); String value = request.getHeader(key); map.put(key, value); } return map; }} Feign 返回图片流在使用 Feign 的过程中，可以将图片流转换成字节数组来传递，但是因为 Controller 层不能直接返回 byte，因此需要将 Feign 的返回值修改为 feign.Response 12@RequestMapping(value = \"/createImageCode\")public Response createImageCode(@RequestParam(\"imageKey\") String imageKey); venus-cloud-feign 的使用为了方便在 API 中使用 Feign 替代 RestTemplate 的手动调用，在写 Feign 接口的时候，想用 Spring MVC 注解只在 Feign 接口写一遍，然后实现类实现此接口即可。但是 Spring MVC 不支持实现接口里的方法参数上的注解（支持继承类、方法上的注解），而且在 GET 请求多参数传递的问题上，需要通过拦截器的方式解决。为了解决上述两个问题，Spring Cloud 中国社区对 Spring Cloud Feign 进行了增强，项目名为 venus-cloud-feign，目前只支持 Spring Cloud 的 Finchley 版本，更多使用方式可以参考官方文档，这里不再累述。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"SpringBoot 配置文件数据加密","url":"/posts/252cb266.html","text":"前言SpringBoot 配置文件中的数据库账户、密码等敏感数据不能明文展示，否则代码泄露的话，数据库的数据会被恶意利用。 加密算法 Jasypt Spring Boot 2.x 默认使用的加密算法是 PBEWithMD5AndDES，其中的 IV 生成器是 org.jasypt.iv.NoIvGenerator Jasypt Spring Boot 3.x 默认使用的加密算法是 PBEWITHHMACSHA512ANDAES_256，其中的 IV 生成器是 org.jasypt.iv.RandomIvGenerator 添加 Maven 坐标12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.4&lt;/version&gt;&lt;/dependency&gt; 加密与解密测试测试加密与解密的代码1234567891011121314151617181920212223242526272829303132333435public class EncryptTest { /** * 加密/解密所需的秘钥（盐） */ private final String salt = \"Jasypt@Test\"; /** * 加密 */ @Test public void encrypt() { BasicTextEncryptor textEncryptor = new BasicTextEncryptor(); // 加密所需的秘钥（盐） textEncryptor.setPassword(salt); // 要加密的数据 String password = textEncryptor.encrypt(\"root\"); // 每次生成的密文都不一样 System.out.println(\"encrypt password: \" + password); } /** * 解密 */ @Test public void decrypt() { BasicTextEncryptor textEncryptor = new BasicTextEncryptor(); // 解密所需的秘钥（盐） textEncryptor.setPassword(salt); // 要解密的数据 String password = textEncryptor.decrypt(\"AM7Q/hDyHcuNswbXO02c1w==\"); System.out.println(\"decrypt password: \" + password); } } 值得一提的是，在上述手动调用 Jasypt API 的代码中，BasicTextEncryptor 类使用加密算法是 PBEWithMD5AndDES。若希望使用 PBEWITHHMACSHA512ANDAES_256 加密算法，可以使用 AES256TextEncryptor 类来替代，更多内容请查看 Jasypt 的源码。 测试加密与解密的命令行 命令行加密 1java -cp jasypt-1.9.3.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=\"root\" password=\"Jasypt@Test\" algorithm=PBEWithMD5AndDES ivGeneratorClassName=org.jasypt.iv.NoIvGenerator 命令行解密 1java -cp jasypt-1.9.3.jar org.jasypt.intf.cli.JasyptPBEStringDecryptionCLI input=\"AM7Q/hDyHcuNswbXO02c1w==\" password=\"Jasypt@Test\" algorithm=PBEWithMD5AndDES ivGeneratorClassName=org.jasypt.iv.NoIvGenerator SpringBoot 配置文件测试环境配置解密所需的秘钥（盐）与解密算法，并使用 ENC() 包裹加密后的数据信息，这样 Jasypt 才知道要解密哪些数据。 特别注意 在 SpringBoot 的配置文件中，强烈建议使用 algorithm 与 iv-generator-classname 参数来指定解密算法。这样可以避免在应用启动时，可能由于加解密使用的算法不一致，导致 Jasypt 无法解密配置文件的密文数据。 1234567891011121314# 配置解密所需的秘钥（盐）、解密算法jasypt: encryptor: password: Jasypt@Test algorithm: PBEWithMD5AndDES iv-generator-classname: org.jasypt.iv.NoIvGenerator# 使用加密后的数据信息spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/wcscanner?characterEncoding=utf-8&amp;useSSL=false&amp;allowPublicKeyRetrieval=true username: ENC(bRVJmN0LlgBAIcXSknCTFQ==) password: ENC(u1HCmk1og6N0wvmnewJI2Q==) 生产环境命令行参数方式上面的 YAML 配置方式，虽然数据库的配置信息使用了密文，但还是非常不安全，因为解密的秘钥（盐）暴露在 application.yml 配置文件中。为了防止秘钥（盐）意外泄漏，被恶意反解出密码，可以在应用部署的时候使用命令行参数传入秘钥（盐）。 1java -jar shop.jar --jasypt.encryptor.password=Jasypt@Test --jasypt.encryptor.algorithm=PBEWithMD5AndDES --jasypt.encryptor.iv-generator-classname=org.jasypt.iv.NoIvGenerator Linux 环境变量方式为了方便统一管理秘钥（盐），可以将秘钥添加到 Linux 系统的环境变量里。 编辑配置文件 1vim /etc/profile 在配置文件末尾，添加环境变量（秘钥） 1export JASYPT_PASSWORD=Jasypt@Test 使配置文件生效 1source /etc/profile 运行 SpringBoot 应用 1java -jar shop.jar --jasypt.encryptor.password=${JASYPT_PASSWORD} --jasypt.encryptor.algorithm=PBEWithMD5AndDES --jasypt.encryptor.iv-generator-classname=org.jasypt.iv.NoIvGenerator 常见错误应用启动提示解密失败SpringBoot 应用启动时，提示解密失败，输出下述的错误信息： 1Decryption of Properties failed, make sure encryption/decryption passwords match 这一般是加密与解密时使用的算法不一致导致的，建议检查 SpringBoot 的配置文件，观察是否有使用 algorithm 与 iv-generator-classname 参数来指定加密算法，没有的话就加上去。 12345jasypt: encryptor: password: Jasypt@Test algorithm: PBEWithMD5AndDES iv-generator-classname: org.jasypt.iv.NoIvGenerator JCE 密钥长度限制问题使用 PBEWITHHMACSHA512ANDAES_256 加密算法后，SpringBoot 应用启动时抛出以下异常。这是由于使用了强加密算法，且未在 Java 虚拟机中安装 Java 加密扩展（JCE）无限强度管辖权策略文件，导致在使用 AES、ElGamal 等加密算法时密钥的长度受到了限制。 1A possible cause is you are using strong encryption algorithms and you have not installed the Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files in this Java Virtual Machine 解决办法是下载 JCE 文件到本地虚拟机，JCE 文件可以从下述地址下载，安装教程可看 这里。 JCE 低版本 JCE 8 - 适用于 JDK 8 参考资料 记录 Jasypt 加密解密中遇到的坑 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"java"},{"title":"Ribbon 入门教程 - 基础篇","url":"/posts/76f2eddc.html","text":"Ribbon 介绍Ribbon 是什么Ribbon 是 Netflix 公司开发的一个负载均衡组件，诞生于 2013 年 1 月，一直是 Netflix 活跃度较高的项目，由 Pivotal 公司将其整合进 Spring Cloud 生态。Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具，通过 Spring Cloud 的封装， 可以轻松地将面向服务的 REST 模板请求自动转换成客户端负载均衡的服务调用。 此外，Ribbon 拥有丰富的负载均衡策略、重试机制、支持多协议的异步与响应式模型、容错、缓存与批次处理等功能。Ribbon 虽然只是一个工具类框架，它不像服务注册中心、配置中心、API 网关那样需要独立部署，但是它几乎存在于每一个 Spring Cloud 构建的微服务和基础设施中。 因为微服务间的调用，API 网关的请求转发等内容实际上都是通过 Ribbon 来实现的，Feign、Zuul 已经集成了 Ribbon，更多介绍可参考：Ribbon 项目、Ribbon 官方英文文档、Spring Cloud Ribbon 官方中文文档 Ribbon 与负载均衡负载均衡（Load Balance），即利用特定方式将流量分摊到多个操作单元上的一种手段，它对系统吞吐量与系统处理能力有着质的提升，当今极少企业没有用到负载均衡器或是负载均衡策略。常见的负载均衡实现有 Nginx 与 LVS，且不管它们的使用方式，工作在什么层次，本质还是对流量的疏导。业界对于负载均衡有不少分类，最常见的有软负载与硬负载，代表产品是 Nginx 与 F5；还有一组分类最能体现出 Ribbon 与传统负载均衡的差别，那就是集中式负载均衡与进程内负载均衡。集中式负载均衡指位于因特网与服务提供者之间，并负责把网络请求转发到各个提供单位，这时候 Nginx 与 F5 就可以归为一类，也可以称是服务端负载均衡。进程内负载均衡是指从一个实例库选取一个实例进行流量导入，在微服务的范畴内，实例库一般存储在 Zookeeper、Eureka、Consul、etcd 这样的注册中心，而此时的负载均衡器就是类似 Ribbon 的 IPC（Inter-Process Communication，进程间通信）组件，因此进程内负载均衡也叫做客户端负载均衡。 Ribbon 入门案例1. 版本说明在下面的的教程中，使用的 Spring Cloud 版本是 Finchley.RELEASE，对应的 Spring Boot 版本是 2.0.3，点击下载完整的案例代码 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 利用传递依赖，公共部分 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，需要引入 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程中 1234567891011server: port: 8090eureka: instance: hostname: 127.0.0.1 client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Provider 源服务工程为了测试 Ribbon 的负载均衡功能，必须要有一个源服务（服务提供者），并且可以选择启动多个实例，在每个实例中需要有一个标识（例如端口）来识别每次的调用是到了不同的服务实例上。这里可以使用一份代码，采取改变端口号的方式启动多次，就能启动多个相同的服务实例。创建 Provider 的 Maven 工程后，由于需要将服务注册到 Eureka Server，工程下的 pom.xml 文件需要引入 spring-cloud-starter-netflix-eureka-client 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Provider 的启动主类，添加注解 @EnableDiscoveryClient，将服务注册到 Eureka Server： 12345678@SpringBootApplication@EnableDiscoveryClientpublic class ProviderApplication { public static void main(String[] args){ SpringApplication.run(ProviderApplication.class, args); }} 在 application.yml 文件中指定服务名称（provider）、注册中心地址与端口号，后面启动多实例只需要修改这里的端口号即可： 12345678910111213server: port: 9090spring: application: name: providereureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 创建用于测试的 Controller 类： 12345678@RestControllerpublic class ProviderController { @GetMapping(\"/provider/add\") public String add(Integer a, Integer b, HttpServletRequest request) { return \"From Port: \" + request.getServerPort() + \", Result: \" + (a + b); }} 5. 创建 Ribbon 客户端工程要使用 Ribbon，需要在 pom.xml 文件中引入依赖 spring-cloud-starter-netflix-ribbon，另外由于需要从 Eureka Server 获取服务列表，即作为 Eureka 客户端，还需要引入 spring-cloud-starter-netflix-eureka-client 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建启动主类，添加注解 @EnableDiscoveryClient 12345678@SpringBootApplication@EnableDiscoveryClientpublic class RibbonLoadBalanceApplication { public static void main(String[] args){ SpringApplication.run(RibbonLoadBalanceApplication.class, args); }} 创建统一配置类，声明 RestTemplate 的 Bean，并且添加注解 @LoadBalanced，指定该 RestTemplate 需要使用客户端负载均衡： 123456789@Configurationpublic class CommonConfiguration{ @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); }} 创建用于测试的 Controller 类，因为 Ribbon 客户端需要创建一个 API 来供第三方调用 Provider 源服务的那个自定义 API，这里需要用 RestTemplate 来调用： 123456789101112131415@RestControllerpublic class CalculateController { @Autowired private RestTemplate restTemplate; /** * 这里的\"PROVIDER\"是服务提供者的实例名称的英文大写 */ @GetMapping(\"/add\") public String add(Integer a, Integer b) { String result = restTemplate.getForObject(\"http://PROVIDER/provider/add?a=\" + a + \"&amp;b=\" + b, String.class); return result; }} 在 application.yml 文件中配置端口号、注册中心地址即可： 12345678910111213server: port: 8080spring: application: name: ribbon-loadbalanceeureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true 6. 测试 启动 Eureka Server 后，更改 Provider 源服务的端口号为 9091 与 9092 后分别启动，浏览器访问 http://127.0.0.1:8090，查看 Eureka Server 的界面是否正常显示多个 Provider 源服务 启动 Ribbon 客户端应用，浏览器访问 http://127.0.0.1:8080/add?a=10&amp;b=5，若正常返回计算结果，说明整个项目运行成功 提示：当存在多个服务提供者时，Ribbon 默认会使用轮询的方式访问源服务，此外 Ribbon 对服务实例节点的增减也能动态感知 Ribbon 负载均衡策略内置的七种负载均衡策略Ribbon 按照不同的需求，已经提供 7 种实现了 IRule 接口的实现类，包含了常用的负载均衡策略，默认的策略是轮询策略。内置的策略能够适用大部分负载均衡需求的应用场景，若有更复杂的需求，可以自己实现 IRule 接口。 策略类 命名 描述 实现说明 RandomRule 随机策略 随机选择可用的服务器 在 index 上随机，选择 index 对应位置的服务器 RoundRobinRule 轮询策略 按顺序循环选择服务器 轮询 index，选择 index 对应位置的服务器 RetryRule 重试策略 对选定的负载均衡策略机上重试机制 在一个配置时间段内当选择服务器不成功，则一直尝试使用 subRule 的方式选择一个可用的服务器 BestAvailableRule 最低并发策略 选择一个并发请求量最少的服务器 逐个考察服务器，如果服务器的断路器打开，则忽略，再选择其他并发连接数最低的服务器 AvailabilityFilteringRule 可用过滤策略 过滤掉一直连接失败并被标记为 circuit tipped 的服务器，过滤掉那些高并发连接的服务器（active connections 超过配置的阀值） 使用一个 AvailabilityPredicate 来包含过滤服务器的逻辑，其实就是检查 status 里记录的各个服务器的运行状态 WeightedResponseTimeRule 响应时间加权策略 根据服务器的响应时间分配权重。响应时间越长，权重越低，被选择到的概率越低；响应时间越短，权重越高，被选择到的概率就越高。这个策略很贴切，综合了各种因素，如：网络、磁盘、CPU 等，这些因素都直接影响着响应时间 一个后台线程定期的从 status 里面读取评价响应时间，为每个服务器计算一个权重；其中权重的计算也比较简单，responsetime 减去每个服务器自己平均的 responsetime 就是服务器的权重。当刚开始运行，没有形成 status 时，使用轮询策略选择服务器 ZoneAvoidanceRule 区域权衡策略 综合判断服务器所在区域的性能和服务器的可用性来轮询选择服务器，并且判断一个 Zone 的运行性能是否可用，剔除不可用的 Zone 中的所有服务器 使用 ZoneAvoidancePredicate 和 AvailabilityPredicate 来判断是否选择某个服务器，前一个判断判定一个 zone 的运行性能是否可用，剔除不可用的 zone 的所有服务器，AvailabilityPredicate 则用于过滤掉连接数过多的服务器 全局负载均衡策略的配置使用 Ribbon 的时候若想要全局更改负载均衡策略，此时只需要增加一个配置类，加上之后凡是通过 Ribbon 的请求都会按照配置的策略来进行负载均衡 12345678@Configurationpublic class RuleConfiguration { @Bean public IRule customRule(){ return new RandomRule(); }} 基于注解的自定义策略配置若想针对某一个源服务设置其特有的负载均衡策略，可以通过使用 @RibbonClient 注解来实现。 创建 @AvoidScan 注解类，只有一个空的声明 123public @interface AvoidScan {} 配置类里注入针对 Ribbon 客户端的配置管理器（非必须），添加 @AvoidScan 注解 123456789101112@AvoidScan@Configurationpublic class RuleConfiguration { @Autowired IClientConfig config; @Bean public IRule customRule(IClientConfig config){ return new RandomRule(); }} 启动主类加上 @RibbonClient 注解，配置内容表示对 provider 服务使用的策略是通过 RuleConfiguration 类所配置的。此外这里使用 @ComponentScan 注解的意思是让 Spring 不去扫描被 @AvoidScan 注解标记的配置类，因为这里的策略配置是希望对单个源服务生效的，所以不能应用于全局。若不想使用 @AvoidScan 注解，只要保证 RuleConfiguration 类 不被 @ComponentScan 注解扫描到就行，简单的做法可以将 RuleConfiguration 类不存放在启动主类（RibbonLoadBalanceApplication）所在的包及其子包下。特别注意：无论是在 Java 代码中还是 YML 配置文件中，只要引用到服务名称的地方，都需要使用大写英文字符的服务名称，否则会找不到对应的服务提供者，导致策略的配置不生效 12345678910@SpringBootApplication@EnableDiscoveryClient@RibbonClient(name = \"PROVIDER\", configuration = RuleConfiguration.class)@ComponentScan(excludeFilters = {@ComponentScan.Filter(type = FilterType.ANNOTATION, value = {AvoidScan.class})})public class RibbonLoadBalanceApplication { public static void main(String[] args){ SpringApplication.run(RibbonLoadBalanceApplication.class, args); }} 若想对多个源服务指定对应的负载均衡策略，可以使用 @RibbonClients 注解 123456@RibbonClients(value = { @RibbonClient(name = \"PROVIDER-USER\", configuration = UserRuleConfiguration.class), @RibbonClient(name = \"PROVIDER-DEPT\", configuration = DeptRuleConfiguration.class)})public class RibbonLoadBalanceApplication {} 基于配置文件的自定义策略配置可以使用配置文件来对源服务的负载均衡策略进行配置，其基本语法是 &lt;service name&gt;.ribbon.*，使用它几乎可以不用写注解形式的任何配置代码，下述配置是对 provider 服务使用随机策略 123PROVIDER: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 区域权衡策略的配置Ribbon 默认实现了区域权衡策略，因此可以通过 Eureka 实例的元数据配置来实现区域化的实例配置方案。Ribbon 会优先访问与客户端处于一个 Zone 中的服务端实例，只有当被选中的 Zone 中没有可用的服务端实例的时候才会访问其他 Zone 中的服务端实例。因此通过 zone 属性的定义，将处于不同机房的实例配置成不同的区域值，配合实际部署的物理结构，可以有效地设计出针对区域性故障的容错集群。而实现的方式非常简单，只需在 Eureka 的服务实例的元数据中增加 zone 参考来指定自己所在的区域，下述内容是配置在 Eureka 的服务实例中： 1234eureka: instance: metadata-map: zone: shanghai Ribbon 配置实战Ribbon 超时与重试使用 HTTP 发起请求，免不了遇到极端环境，此时对调用进行时限控制以及时限之后的重试尤为重要。在 Spring Cloud 的 Brixtion 版本中，对于重试机制的实现需要开发者自行扩展实现，而从 Camden SR2 版本开始，Spring Cloud 整合了 Spring Retry 来增加 RestTemplate 的重试能力，只需要通过简单的配置，原来那些通过 RestTemplate 实现的服务访问就会自动根据配置来实现重试机制。注意，Finchley 版中 Ribbon 的重试机制默认是开启的，只需要添加针对超时时间与重试策略的配置即可。下述配置是对 provider 服务配置超时与重试相关参数： 12345678PROVIDER: ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 MaxAutoRetries: 1 #对第一次请求的服务的重试次数 MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务） OkToRetryOnAllOperations: true NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Ribbon 的饥饿加载Ribbon 在进行客户端负载均衡的时候，并不是启动时就加载上下文的，而是在实际请求的时候才去创建，因此这个特性往往会让第一次调用显得疲软乏力，严重的时候会引起调用超时。此时可用通过指定 Ribbon 具体的客户端的名称来开启饥饿加载，即在启动的时候便加载所有配置项的应用程序上下文。 1234ribbon: eager-load: enabled: true clients: PROVIDER-USER, PROVIDER-DEPT, PROVIDER-ORDER 基于配置文件自定义 Ribbon 客户端Ribbon 在 1.2.0 版本之后，支持使用配置文件来定制 Ribbon 客户端，其实质就是使用配置文件来指定一些默认加载类，从而更改 Ribbon 客户端的默认行为方式，并且这种方法的优先级是最高的，优先级高于使用注解 @RibbonClient 指定的配置和 Java 源码中加载的相关 Bean，具体配置规则如下： 下述配置，表示是对 provider 服务使用随机策略 123PROVIDER: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Ribbon 脱离 Eureka 的使用在默认情况下，Ribbon 客户端会从 Eureka 注册中心读取服务注册信息列表，来达到动态负载均衡的目的。若不想从 Eureka 注册中心读取服务注册列表，可以配置 Ribbon 客户端使用指定的源服务地址，让 Ribbon 脱离 Eureka 使用，配置实例如下： 1234567ribbon: eureka: enabled: false #禁用Eureka的功能PROVIDER: ribbon: listOfServers: http://127.0.0.1:7000, http://127.0.0.1:7001 #指定provider服务的服务地址 Ribbon 进阶核心接口 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"Eureka 入门教程 - 基础篇","url":"/posts/be1e11c7.html","text":"Eureka 介绍Eureka 是什么Eureka 是 Netflix 开发的一款基于 HTTP REST 的服务，由 Pivotal 公司将其整合进 Spring Cloud 生态。Netflix 在设计 Eureka 时遵守的是 AP 原则，通常用于服务注册发现、负载均衡和故障转移等，也是 Spring Cloud 中使用的服务注册发现组件。Eureka 采用 C/S 架构，提供了一个基于 Java 的 Client 组件，用来与服务端交互，同时具有一套内置的负载均衡器，可以进行基本的轮询负载均衡。Eureka 从 2012 年 9 月在 Github 上发布 1.1.2 版本以来，至今已经发布了 231 次，最新版本为 2020 年 4 月份发布的 1.9.20 版本。期间有进行 2.x 版本的开发，不过由于各种原因内部已经冻结开发，目前还是以 1.x 版本为主。更多介绍可参考：Eureka 项目、Eureka 官方英文文档、Spring Cloud Eureka 官方中文文档 Eureka 服务治理体系 Eureka 服务的三个角色 服务注册中心：Eureka 提供的服务端，提供服务注册与发现的功能，一般被称作 Eureka-Server； 服务消费者：消费者应用从服务注册中心获取服务列表，从而使消费者可以知道去何处调用其所需要的服务； 服务提供者：提供服务的应用，可以是 Spring Boot 应用，也可以是其他技术平台且遵循 Eureka 通信机制的应用。它将自己提供的服务注册到 Eureka，以供其他应用发现。 Eureka 高可用性Eureka 的高可用性Eureka 的服务注册中心，它和其他服务注册中心一样，支持高可用配置。依托于强一致性提供良好的服务实例可用性，可以应对多种不同的故障场景。Eureka 服务端支持集群模式部署，当集群中有分片发生故障的时候（超过 85% 的服务实例丢失心跳），Eureka 会自动转入自我保护模式。它允许在分片发生故障的时候继续提供服务的发现和注册，当故障恢复时，集群中的其他分片会把各自的状态再次同步回来。集群中的的不同服务注册中心通过异步模式互相复制各自的状态，这也意味着在给定的时间点每个实例关于所有服务的状态可能存在不一致的现象。 Eureka 的自我保护模式默认情况下，如果 Eureka Server 在一定时间内（默认 90 秒）没有接收到某个微服务实例的心跳，Eureka Server 将会注销该实例。但是当网络分区故障发生时，微服务与 Eureka Server 之间无法正常通信，这就可能变得非常危险了。因为微服务本身是健康的，此时本不应该注销这个微服务。Eureka Server 通过 “自我保护模式” 来解决这个问题，当 Eureka Server 节点在短时间内丢失过多客户端时（超过 85% 的服务实例丢失心跳，可能发生了网络分区故障），那么这个节点就会进入自我保护模式。一旦进入该模式，Eureka Server 就会保护服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。当网络故障恢复后，该 Eureka Server 节点会自动退出自我保护模式。自我保护模式是一种对网络异常的安全保护措施，使用自我保护模式，可以让 Eureka 集群更加的健壮、稳定。 在自我保护模式中，Eureka Server 会保护注册表中的信息，不再注销任何服务实例。当它收到的心跳数重新恢复到阀值以上时，该 Eureka Server 节点就会自动退出自我保护模式。它的设计哲学就是宁可保留错误的服务注册信息（健康或不健康的微服务都会保留），也不盲目注销任何可能健康的服务实例。在 Spring Cloud 中，可以使用 eureka.server.enable-self-preservation: false 来禁用自我保护模式。 Eureka 自我保护模式的效果 Eureka 不再从注册列表移除因长时间没收到心跳而应该过期的服务 Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点（高可用） Eureka 在网络稳定的时候，当前实例新的注册信息会被同步到其他节点中（最终一致性） Eureka 可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像 ZooKeeper 一样使得整个注册中心瘫痪 Eureka 的健康检查在 Eureka 中，微服务状态可取值为 DOWN、OUT_OF_SERVICE、UNKNOWN 等，只有 UP 的微服务会被请求。由于 Eureka Server 与 Eureka Client 之间使用心跳机制来确定 Eureka Client 的状态，默认情况下服务器端与客户端的心跳保持正常，应用程序就会始终保持 UP 状态，所以微服务的 UP 并不能完全反应应用程序的状态。Spring Boot Actuator 提供了 /health 端点，该端点可展示应用程序的健康信息，只要将该端点中的健康状态传播到 Eureka Server 就可以了，实现这点很简单，只需为微服务配置如下内容即可。如果需要更细粒度健康检查，可实现 com.netflix.appinfo.HealthCheckHandler 接口，EurekaHealthCheckHandler 已实现了该接口。 12# 开启健康检查（需要添加spring-boot-starter-actuator依赖）eureka.client.healthcheck.enabled = true Eureka 入门案例1. 版本说明以下案例使用了版本较旧的 SpringCloud-Dalston.SR1 + SpringBoot-1.5.9.RELEASE，配置方式跟最新版本的 SpringCloud 有一定的区别 2. 创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324&lt;properties&gt; &lt;springcloud.version&gt;Dalston.SR1&lt;/springcloud.version&gt; &lt;springboot.version&gt;1.5.9.RELEASE&lt;/springboot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${springboot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${springcloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 3. 创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件，只需添加 spring-cloud-starter-eureka-server 即可；若使用最新版本的 SpringCloud，则需要改为添加 spring-cloud-starter-netflix-eureka-server 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类，这里添加相应注解，作为程序的入口： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程的 src/main/resources 目录下： 1234567891011server: port: 7001eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4. 创建 Eureka Client 工程创建 Eureka Client 的 Maven 工程（作为服务提供者），配置工程里的 pom.xml 文件，需要添加以下内容。若使用最新版的 SpringCloud，此时只需要引入 spring-cloud-starter-netflix-eureka-client 依赖 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Client 的启动主类，添加注解 @EnableEurekaClient 12345678@EnableEurekaClient@SpringBootApplicationpublic class DeptProviderApplication { public static void main(String[] args){ SpringApplication.run(DeptProviderApplication.class, args); }} 添加 Eureka Client 需要的 application.yml 配置文件到工程的 src/main/resources 目录下，特别注意：在生产环境（外网）部署 Eureka Server，一定要配置 eureka:instance:prefer-ip-address: true 参数，否则服务消费者无法通过正确的 IP 调用服务提供者的接口 1234567891011121314server: port: 9090spring: application: name: demo-client #需要指定spring.application.name，否则会在 Eureka Server 界面显示为 UNKNOWeureka: client: service-url: defaultZone: http://localhost:7001/eureka instance: instance-id: demo-client-9090 #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 5. 完善注册服务的 info 信息Maven 父级 Pom 工程添加以下配置： 1234567891011121314151617181920&lt;build&gt; &lt;finalName&gt;springcloud-demo&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;delimit&gt;$&lt;/delimit&gt; &lt;/delimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 配置 Eureka Client 工程里的 pom.xml 文件，引入 spring-boot-starter-actuator 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 配置 Eureka Client 工程里的 application.yml 文件，添加以下内容；若 Info 界面不能正确显示 $ 符号替换后的服务信息，可以尝试依次执行 mvn clean 、mvn compile、 mvn install 命令 12345info: app.name: springcloud-demo company.name: www.example.com build.version: $project.version$ build.artifactId: $project.artifactId$ 6. 测试分别启动 eureka-server 及 eureka-client 应用，然后通过浏览器访问 http://127.0.0.1:7001，若正常显示 Eureka Server 的管理界面和服务列表（如下图），则说明一切配置成功。 Eureka 进阶实战Eureka 的服务事件监听Eureka 提供了五种服务监听事件，因为在某些业务场景下，可能需要做一些自定义的扩展；例如某个微服务挂掉了，希望能监听到并给管理员发送邮件通知等。 EurekaServerStartedEvent: Eureka 注册中心启动事件 EurekaRegistryAvailableEvent: Eureka 注册中心可用事件 EurekaInstanceRenewedEvent: 服务实例续约事件 EurekaInstanceCanceledEvent: 服务实例下线事件 EurekaInstanceRegisteredEvent: 服务实例注册事件 Eureka 的 REST APIEureka 提供了 REST API，允许非 Java 语言的其他应用服务通过 HTTP REST 的方式接入 Eureka 的服务发现中，API 列表可参考 Eureka 官方文档的介绍或者下图。 Eureka 开启登录认证配置 Eureka Server 工程里的 pom.xml 文件，引入 spring-cloud-starter-security 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置 Eureka Server 工程里的 application.yml 文件，增加用户名、密码的配置 123456security: basic: enabled: true user: name: admin #Eureka的登录用户名 password: 123456 #Eureka的登录密码 在 Eureka Server 工程里加入 Security 配置类，关闭掉 CSRF，否则 Client 无法连接 Eureka Server 端；若项目中引入了 Actuator，那么还需要放行 Actuator 的请求 12345678910111213@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable() .authorizeRequests() .antMatchers(\"/eureka/**\").permitAll() .antMatchers(\"/actuator/**\").permitAll() .anyRequest().authenticated().and().httpBasic(); }} 配置 Eureka Client 工程里的 application.yml 文件，更改注册中心的地址 1234567891011121314server: port: 9090spring: application: name: demo-clienteureka: client: service-url: defaultZone: http://admin:123456@localhost:7001/eureka instance: instance-id: demo-client-9090 prefer-ip-address: true 分别启动 eureka-server 及 eureka-client 应用，然后通过浏览器访问 http://127.0.0.1:7001，此时会先弹出登录框，输入正确的用户名和密码后才能看到管理页面 Eureka 集群配置假设现有三台 Eureka Server 主机，每台主机的 IP 与端口分别是： 192.168.1.105:8005、192.168.1.106:8006、192.168.1.107:8007 Eureka Server1 配置1234567891011server: port: 8005eureka: instance: hostname: 192.168.1.105 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.106:8006/eureka/,http://192.168.1.107:8007/eureka/ Eureka Server2 配置1234567891011server: port: 8006eureka: instance: hostname: 192.168.1.106 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.107:8007/eureka/ Eureka Server3 配置1234567891011server: port: 8007eureka: instance: hostname: 192.168.1.107 client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.106:8006/eureka/ Eureka Client 集群配置1234567891011121314server: port: 9090spring: application: name: demo-clienteureka: client: service-url: defaultZone: http://192.168.1.105:8005/eureka/,http://192.168.1.106:8006/eureka/,http://192.168.1.107:8007/eureka/ instance: instance-id: demo-client-9090 prefer-ip-address: true 启动三台 Eureka Server，分别访问三台 Eureka Server 的管理界面，若界面上的 DS Replicas 项可以正常显示其他 Eureka Server 节点（如下图），则说明 Eureka 服务器集群配置成功 本地集群搭建的细节说明若三台 Eureka Server 的 IP 都是 127.0.0.1 或者 localhost，彼此只是服务端口不一样；此时建议修改系统的 hosts 文件作相应的域名映射，方便日后访问 Eureka 的服务。当 hosts 文件加入下述配置之后，则可以通过不同的域名访问对应的 Eureka 服务了，如：http://eureka8005.com:8005/eureka/ 123127.0.0.1 eureka8005.com127.0.0.1 eureka8006.com127.0.0.1 eureka8007.com 特别注意：新版的 Eureka 搭建集群时，eureka.client.serviceUrl.defaultZone 配置项的地址，不能使用 localhost 或者内网/外网 IP，必须使用域名，DNS 解析需自行配置，也可以在本机的 /etc/hosts 里映射域名，否则各节点均出现在 unavailable-replicas 下 补充内容CAP 理论CAP 理论的核心是：一个分布式系统不可能同时很好地满足一致性、可用性和分区容错性这三个需求。因此，根据 CAP 理论可以将 NoSQL 数据库分成满足 CA 原则、满足 CP 原则和满足 AP 原则三大类： CA - 单点集群，满足一致性、可用性的系统，通常在可扩展上不太强大 CP - 满足一致性，分区容错性的系统，通常性能不是特别高 AP - 满足可用性、分区容忍性的系统，通常可能对一致性要求低一点 Eureka 对比 ZooKeeper ZooKeeper 保证的是 CP，Eureka 保证的是 AP Eureka 本质上是一个工程，而 ZooKeeper 只是一个进程 ZooKeeper 有 Leader 和 Follower 角色，Eureka 各个节点是平等关系 ZooKeeper 在选举期间注册服务瘫痪，虽然服务最终会恢复，但是选举期间不可用；Eureka 只要有一实例就可以保证服务可用，但查询到的数据可能并不是最新的 ZooKeeper 采用过半数存活原则，Eureka 采用自我保护机制解决分区问题 Netflix 在 AWS 中的 Eureka 部署架构 上图（左边）描述的是 Netflix 在 AWS 中的 Eureka 部署架构，图中的 us-east-1x 指的是不同的 zone。AWS 将服务划分成不同地区（region），每个 region 中又有若干个机房（zone），结构图大致上图（右边）所示，每个 zone 都是一个 Eureka 集群，其中至少有一台 Eureka Server，用来处理 zone failure。在 Eureka 中注册的服务每隔 30s 会向服务端发送一次心跳，用来告知服务端自己是否” 存活”，这个过程就是图中的 renew；如果 renew 操作在重试几次后都没有成功，那这个服务在 90s 之内就会被踢除。需要注意的是，renew 信息和服务注册信息会在多个 zone 间同步，任何一个 zone 中的客户端都可以寻找到任意一个 zone 中注册的服务信息。 两个 @EnableXXXClient 注解的区别 Spring Cloud 提供了 @EnableDiscoveryClient 与 @EnableEurekaClient 注解，其中 @EnableDiscoveryClient 基于 spring-cloud-commons，而 @EnableEurekaClient 基于 spring-cloud-netflix Spring Cloud 的服务注册发现有多种实现（Eureka、Consul、Zookeeper 等），如果选用的注册中心是 Eureka，那么就推荐使用 @EnableEurekaClient，如果是其他的注册中心，那么推荐使用 @EnableDiscoveryClient 特别注意：@EnableEurekaClient 上包含了 @EnableDiscoveryClient，可以说 @EnableEurekaClient 拥有 @EnableDiscoveryClient 的功能，其实 @EnableEurekaClient 就是一种方便使用 Eureka 的注解而已 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"浅谈 Redis 持久化 - RDB 和 AOF 原理","url":"/posts/b9abccfa.html","text":"持久化什么是持久化持久化（Persistence），即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。 持久化的实现方式 快照方式持久化：在某时刻把所有数据进行完整备份，例如：MySQL 的 Dump 方式、Redis 的 RDB 方式 写日志方式持久化：把用户执行的所有写指令（增删改）备份到文件中，还原数据时只需要把备份的所有指令重新执行一遍即可，例如：MySQL 的 Binlog、Redis 的 AOF、Hbase 的 HLog RDBRDB 介绍RDB 持久化方式是在指定的时间间隔内将内存中的数据集快照写入磁盘（point-in-time snapshot）。在默认情况下，Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。在 Redis 运行时，RDB 程序将当前内存中的数据库快照保存到磁盘文件中，在 Redis 重启动时，RDB 程序可以通过载入 RDB 文件来还原数据库的状态。 RDB 工作原理当 Redis 需要保存 dump.rdb 二进制文件时，服务器会执行以下操作。整个过程中，Redis 的主进程不进行任何 I/O 操作，这就确保了极高的性能，使 Redis 可以从写时复制（copy-on-write）机制中获益。 Redis 单独创建（fork）一个子进程 子进程将内存中的数据集写入到一个临时 RDB 文件中 当子进程完成对临时 RDB 文件的写入时，Redis 用临时 RDB 文件替换旧的 RDB 文件，并删除旧的 RDB 文件 RDB 的三种主要触发机制save 命令（同步）save 命令会执行一个同步操作，以 RDB 文件的方式保存所有数据的快照。特别注意，由于 save 命令是同步命令，会占用 Redis 的主进程，若 Redis 的数据量非常大时，save 命令执行速度会非常慢，会阻塞所有客户端的请求。因此很少在生产环境直接使用 save 命令，可以使用 bgsave 命令代替。如果 bgsave 命令的保存数据的子进程发生错误，导致无法备份时，那么用 save 命令保存最新的数据是最后的手段。 bgsave 命令（异步）Redis 使用 Linux 系统的 fock() 生成一个子进程来将数据库数据保存到磁盘，主进程继续提供服务以供客户端调用。如果操作成功，可以通过客户端命令 LASTSAVE 来检查操作结果。 save 命令与 bgsave 命令对比如下，特别注意，shutdown、slave 命令也会触发数据快照的创建 自动生成 RDB 文件除了手动执行 save 和 bgsave 命令实现 RDB 持久化以外，Redis 还提供了自动自动生成 RDB 文件的方式。通过配置文件对 Redis 进行设置，让它在 “N 秒内数据集至少有 M 个改动” 这一条件被满足时，自动进行数据集保存操作。比如说，以下设置会让 Redis 在满足 “60 秒内有至少有 1000 个键被改动” 这一条件时，自动进行数据集保存操作： 1save 60 1000 RDB 相关配置12345678910111213141516171819202122232425# RDB自动持久化规则# 当 900 秒内有至少有 1 个键被改动时，自动进行数据集保存操作save 900 1# 当 300 秒内有至少有 10 个键被改动时，自动进行数据集保存操作save 300 10# 当 60 秒内有至少有 10000 个键被改动时，自动进行数据集保存操作save 60 10000# RDB持久化文件名dbfilename dump-&lt;port&gt;.rdb# 数据持久化文件存储目录dir /var/lib/redis# bgsave发生错误时是否停止写入，通常为yesstop-writes-on-bgsave-error yes# rdb文件是否使用压缩格式rdbcompression yes# 是否对rdb文件进行校验和检验，通常为yesrdbchecksum yes RDB 的优点 RDB 是一个非常紧凑的文件，它保存了某个时间点的数据集，非常适用于数据集的备份，比如可以在每个小时保存一下过去 24 小时内的数据，同时每天保存过去 30 天的数据，这样即使出了问题也可以根据需求恢复到不同版本的数据集，非常适合做冷备 RDB 是一个紧凑的单一文件，很方便传送到另一个远端数据中心或者亚马逊的 S3（可能加密），非常适用于灾难恢复 RDB 在保存 RDB 文件时，父进程唯一需要做的就是 fork 出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他 I/O 操作，所以 RDB 持久化方式可以最大化地提高 Redis 的性能 若需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那么 RDB 方式要比 AOF 方式的数据恢复速度更快 RDB 的缺点 耗时、耗性能：RDB 需要经常 fork 子进程来保存数据集到硬盘上，当数据集比较大的时候，fork 的过程是非常耗时的，可能会导致 Redis 在毫秒级内不能响应客户端的请求。如果数据集巨大并且 CPU 性能不是很好的情况下，这种情况可能会持续数毫秒或者几秒，AOF 也需要 fork，但可以调节重写日志文件的频率来提高数据集的耐久度 不可控、丢失数据：如果希望在 Redis 意外停止工作（例如机房断电）的情况下尽量减少数据的丢失，那么 RDB 不适合这种场景。虽然可以配置不同的 save 时间点（例如每隔 5 分钟且对数据集有 100 个写的操作时进行备份)，但 Redis 要完整的保存整个数据集是一个比较繁重的工作，通常会每隔 5 分钟或者更久做一次完整的保存，万一在 Redis 意外宕机，可能会丢失几分钟的数据。简单来说，最后一次 RDB 持久化后的数据可能会丢失。 AOFAOF 介绍快照功能（RDB）并不是非常耐久（durable），如果 Redis 因为某些原因而造成故障停机，那么服务器将丢失最近写入且仍未保存到快照中的那些数据。 从 1.1 版本开始，Redis 增加了一种完全耐久的持久化方式，那就是 AOF 持久化。AOF 以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来，同时只许追加文件不能改写文件。在配置文件中启用 AOF（如下配置） 后，每当 Redis 执行一个改变数据集的命令时（比如 SET），这个命令就会被追加到 AOF 文件的末尾。这样的话，当 Redis 重新启时，程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。 1appendonly yes AOF 运行原理AOF 运行原理（创建与恢复）如下： AOF 持久化的三种同步策略可以通过配置文件配置 Redis 多久才将命令 fsync 到磁盘一次，Redis 提供了以下三种策略。 always：每次有新命令需要追加到 AOF 文件时就执行一次 fsync 操作，非常慢，也非常安全 everysec：每秒 fsync 一次，速度足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据，推荐（并且也是默认）的配置为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性。 no：从不 fsync，将数据交给操作系统来处理，由操作系统来决定什么时候同步数据，速度更快，但也更不安全 always、everysec、no 三种策略的对比如下： AOF 重写AOF 重写介绍因为 AOF 的运作方式是不断地将命令追加到文件的末尾，所以随着写入命令的不断增加，AOF 文件的体积也会变得越来越大。举个例子，如果对一个计数器调用了 100 次 INCR ，那么仅仅是为了保存这个计数器的当前值，AOF 文件就需要使用 100 条记录（entry）。然而在实际上，只使用一条 SET 命令已经足以保存计数器的当前值了，其余 99 条记录实际上都是多余的。为了处理这种情况， Redis 支持一种有趣的特性，可以在不打断服务客户端的情况下，对 AOF 文件进行重建（rebuild）。执行 bgrewriteaof 命令，Redis 将生成一个新的 AOF 文件，这个文件包含重建当前数据集所需的最少命令。Redis 2.2 需要自己手动执行 bgrewriteaof 命令，而 Redis 2.4 之后则可以通过配置自动触发 AOF 重写。通过 AOF 重写，可以减少磁盘占用量、加速数据恢复，AOF 重写的对比图如下： AOF 重写的实现方式bgrewriteaof 命令 Redis 的 bgrewriteaof 命令用于异步执行一个 AOF（Append Only File）文件重写操作，重写后会创建一个当前 AOF 文件的体积优化版本。即使 bgrewriteaof 命令执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 bgrewriteaof 命令执行成功之前不会被修改。AOF 重写操作由 Redis 自行触发，bgrewriteaof 命令仅仅用于手动触发 AOF 重写操作，整个流程如下： 如果一个子进程是 Redis 通过磁盘快照创建的，那么 AOF 重写将会在 RDB 操作终止后才开始保存，这种情况下 bgrewriteaof 命令依然会返回 OK 状态码。从 Redis 2.6 起，可以通过 info 命令查看 AOF 重写的执行情况 如果正在执行的 AOF 重写操作返回了一个错误，那么 AOF 重写将会在稍后一点的时间重新执行 AOF 重写配置 AOF 重写自动触发的条件 Redis 支持 AOF 重写自动触发机制，无需手动执行 bgrewriteaof 命令，但需要同时满足下面两个条件才会自动触发： aof_current_size &gt; auto-aof-rewrite-min-size (aof_current_size - aof_base_size) * 100 / aof_base_size &gt; auto-aof-rewrite-percentage 12auto-aof-rewrite-min-size 64mbauto-aof-rewrite-percentage 100 假设 Redis 的配置如上，当 AOF 文件的体积大于 64Mb，并且 AOF 文件的体积比上一次重写时的体积大了至少一倍（100%）时，Redis 将执行 bgrewriteaof 命令进行重写。 AOF 重写的流程Redis 首先 fork 子进程，子进程开始将新 AOF 文件的内容写入到临时文件。对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾，这样即使在重写的中途发生宕机，现有的 AOF 文件也还是安全的。当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。最后 Redis 原子地用新 AOF 文件替换旧 AOF 文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 AOF 相关配置1234567891011121314151617181920# 开启AOF持久化方式appendonly yes# AOF持久化文件名appendfilename appendonly-&lt;port&gt;.aof# 每秒把缓冲区的数据同步到磁盘appendfsync everysec# 数据持久化文件存储目录dir /var/lib/redis# 是否在执行重写时不同步数据到AOF文件no-appendfsync-on-rewrite yes# 触发AOF文件执行重写的最小尺寸auto-aof-rewrite-min-size 64mb# 触发AOF文件执行重写的增长率auto-aof-rewrite-percentage 100 AOF 的优点 使用 AOF 会让 Redis 更加耐久：可以使用不同的 fsync 策略：无 fsync、每秒 fsync、每次写的时候 fsync。使用默认的是每秒 fsync 策略，Redis 的性能依然很好（fsync 是由后台子进程进行处理的，主线程会尽力处理客户端请求），一旦出现故障，最多丢失 1 秒的数据 AOF 对日志文件的写入操作采用的是 append 模式，因此在写入过程中即使出现磁盘空间已满、宕机等现象，也不会破坏日志文件中已经存在的内容。而且如果本次操作只是写入了一半数据就出现了系统崩溃问题，也不用担心，在 Redis 下一次启动之前，可以通过 redis-check-aof 工具来修复数据一致性问题 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 文件进行重写，重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生宕机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作 AOF 文件有序地保存了对数据库执行的所有写入操作，这些写入操作以 Redis 协议的格式保存，因此 AOF 文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单。举个例子，如果不小心执行了 FLUSHALL 命令，但只要 AOF 文件未被重写，那么只要停止服务器，移除 AOF 文件末尾的 FLUSHALL 命令，并重启 Redis，就可以将数据集恢复到 FLUSHALL 执行之前的状态 AOF 的缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积，而且 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。AOF 开启后支持写的 QPS 会比 RDB 支持的写的 QPS 低，但在一般情况下，每秒 fsync 的性能依然非常高，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency） 修复错误的 AOF 文件服务器可能在 Redis 正在对 AOF 文件进行写入时宕机，如果宕机造成了 AOF 文件出错（corrupt）， 那么 Redis 在重启时会拒绝载入这个 AOF 文件，从而确保数据的一致性不会被破坏。当发生这种情况时，可以用以下方法来修复出错的 AOF 文件： 为现有的 AOF 文件创建备份文件 使用 Redis 附带的 redis-check-aof 工具，对原来的 AOF 文件进行修复 1$ redis-check-aof --fix 使用 diff -u 命令对比修复后的 AOF 文件和原始的 AOF 备份文件，查看两个文件之间的不同之处，此步骤为可选操作 重启 Redis 服务器，等待服务器载入修复后的 AOF 文件，并进行数据恢复 RDB 和 AOF 对比 如何选择使用哪种持久化方式？ 如果非常关心数据的安全性，但仍然可以承受数分钟以内的数据丢失，那么可以只使用 RDB 持久化 不推荐只使用 AOF 持久化，因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快 如果想达到足以媲美 PostgreSQL 的数据安全性，则应该同时使用两种持久化机制。当同时使用 RDB 和 AOF 两种持久化机制时，那么在 Redis 重启的时候，会优先使用 AOF 来重建数据集，因为 AOF 的数据更加完整 总结，生产环境中推荐同时使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为恢复数据的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，可以使用 RDB 进行快速的数据恢复。 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"缓存"},{"title":"C 语言语法之四数组","url":"/posts/7f62c448.html","text":"数组的概念 在程序设计中，为了处理方便把具有相同类型的若干变量按有序的形式组织起来，这些按序排列的同类数据元素的集合称为数组 数组是具有相同类型的数据组成的有序集合，其中的每一个数据称包含数组元素与数组下标，数组元素是由其所在的位置序号（称数组元素的下标）来区分 在 C 语言中数组属于构造数据类型，一个数组可以分解为多个数组元素，这些数组元素可以是基本数据类型或是构造类型。因此按数组元素的类型不同，数组又可分为数值数组、字符数组、指针数组、结构数组等各种类别 一维数组的定义 一维数组的定义方式为：类型说明符 数组名 [常量表达式]；例如：int a[10]; 表示定义了一个整型数组，数组名为 a，此数组有 10 个元素，10 个元素都是整型变量 数组元素的一般引用形式为：数组名 [下标]，例如：int x = a[0] 一维数组在内存中的存放时，每个数据元素占用的字节数，就是基本数据类型的字节数，具体存放方式如下： 数组使用注意事项 方括号中的常量表达式表示数据元素的个数，也称为数组的长度 数组名是用户定义的数组标识符，书写规则应符合标识符的书写规定 允许在同一个类型说明中，定义多个数组和多个变量，例如：int a,b,c,d,k1[10],k2[20]; 类型说明符是任一种基本数据类型或构造数据类型，对于同一个数组，其所有元素的数据类型都是相同的 数组 a[10]，表示 a 数组有 10 个元素，下标是从 0 开始的，这 10 个元素是 a [0]，a [1] … a [8]，a [9]，按上面的定义，不存在数组元素 a[10] C 语言不允许对数组的大小作动态定义，即数组的大小不依赖于程序运行过程中变量的值，以下代码是错误的： 1234567/********C语言不允许对数组的大小作动态定义，下面的写法是错误的********/int main(){ int n; scanf(\"%d\", &amp;n); int a[n]; return 0;} 数组元素通常也称为下标变量，必须先定义数组，才能使用下标变量；在 C 语言中只能逐个地使用下标变量，而不能一次引用整个数组，例如： 12345678910/********输出有10个元素的数组时，必须使用循环语句逐个输出各下标变量********/int main(){ for(i=0; i&lt;10; i++) { printf(\"%d\", a[i]); } return 0;}// 不能用一个语句输出整个数组，此写法是错误的：printf(\"%d\", a); 定义数组时用到的数组名 [常量表达式] 和引用数组元素时用到的数组名[下标] 是有区别的，例如：int a[10]; 中的 10 是指数组长度，t=a[6]; 是指引用 a 数组中序号为 6 的元素，此时 6 不代表数组长度 一维数组的初始化赋值 数组初始化赋值是指在数组定义时给数组元素赋予初值，数组初始化的过程是在编译阶段进行的，这样可以减少运行间，提高运行效率 数组赋值的方法除了用赋值语句对数组元素逐个赋值外，还可采用初始化赋值和动态赋值的方法 数组初始化赋值的一般形式为：类型说明符 数组名[常量表达式]={值, 值, ……值};，例如：int a［10］= {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; 可以只给一部分数组元素赋值，例如:int a［10］= {0, 1, 2, 3, 4};，表示定义 a 数组有 10 个元素，但花括弧内只提供 5 个初值，这代表只给前面 5 个元素赋初值，后 5 个元素值默认缺省为 0 在对全部数组元素赋初值时，由于数据的个数已经确定，因此可以不指定数组长度，例如：int a［5］= {1, 2, 3, 4, 5}; 可以写成：int a［ ］= {1, 2, 3, 4, 5}; 数组动态赋值的代码示例如下： 12345678910111213141516/********输入五个数，求出最大的数********/int main(){ int i, max=0, a[5]; printf(\"please input five number:\\n\"); setbuf(stdin, NULL); for(i=0; i&lt;=4; i++){ scanf(\"%d\", &amp;a[i]); } for(i=0; i&lt;=4; i++){ if(a[i] &gt; max){ max = a[i]; } } printf(\"max=%d\\n\", max); return 0;} var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c语言"},{"title":"C 语言语法之三循环控制结构","url":"/posts/e2f81b63.html","text":"循环控制结构循环结构循环结构是程序中一种很重要的结构。其特点是，在给定条件成立时，反复执行某程序段，直到条件不成立为止。给定的条件称为循环条件，反复执行的程序段称为循环体。C 语言提供了多种循环语句，可以组成各种不同形式的循环结构，分别是： 用 for 语句 用 while 语句 用 do-while 语句 用 goto 语句和 if 语句构成循环 goto 语句 goto 语句是一种无条件转移语句，与 BASIC 中的 goto 语句相似，goto 语句的使用格式为：goto 语句标号; 其中标号是一个有效的标识符，这个标识符加上一个 : 一起出现在函数内某处，执行 goto 语句后，程序将跳转到该标号处并执行其后的语句。另外标号必须与 goto 语句同处于一个函数中，但可以不在一个循环层中。通常 goto 语句与 if 条件语句连用，当满足某一条件时，程序跳到标号处运行 必须注意，goto 语句通常不建议使用，因为它将使程序层次不清，且不易读，但在多层嵌套退出时，用 goto 语句则比较合理 123456789101112/*******使用goto语句和if语句构成循环*******/int main(){ int i=1,sum=0; loop: if (i&lt;=100) { sum=sum+i; i++; goto loop; } printf(\"%d\\n\",sum);} while 语句 while 语句的一般形式为：while (表达式) 语句，其中表达式是循环条件，语句为循环体。while 语句的语义是：计算表达式的值，当值为真（非 0）时，则执行循环体语句，其执行过程可用下图表示： while 语句中的表达式一般是关系表达或逻辑表达式，只要表达式的值为真 (非 0)，即可继续循环 循环体如包括有一个以上的语句，则必须用 {} 括起来，组成复合语句 注意：如果 while 循环的表达式的值一开始就为 0，则循环语句一次也会被不执行 1234567891011121314151617181920212223242526/*******使用while语句构成循环*******/int main(){ int i=1,sum=0; while(i&lt;=100) { sum=sum+i; i++; } printf(\"%d\\n\",sum);}/*******下面的while循环永远不会退出（死循环）*******/int main(){ int i=1,sum=0; while(i&lt;=100) // ｝ sum=sum+i; i++; // } printf(\"%d\\n\",sum);}// 因为上面的while循环体没有使用{}括起来，i++不属于while循环体内的一部分，导致了死循环的发生 do-while 语句 do-while 语句的一般形式为：do 语句 while(表达式);，这个循环与 while 循环的不同在于，它先执行循环中的语句，然后再判断表达式是否为真，如果为真则继续循环；如果为假，则终止循环。因此，do-while 循环至少要执行一次循环语句 1234567891011/*******使用do-while语句构成循环*******/int main(){ int i=1,sum=0; do { sum=sum+i; i++; } while(i&lt;=100); printf(\"%d\\n\", sum);} for 语句 在 C 语言中，for 语句使用最为灵活，它完全可以取代 while 语句，它的一般形式为：for (表达式 1；表达式 2；表达式 3) 语句 for 语句的执行过程如下： 123451. 先求解表达式12. 求解表达式2，若其值为真（非0），则执行for语句中指定的内嵌语句，然后执行下面第3步；若其值为假（0），则结束循环，转到第5步3. 求解表达式34. 转回上面第2步继续执行5. 循环结束，执行for语句下面的一个语句 for 语句最简单的应用形式也是最容易理解的形式是：for (循环变量赋初值；循环条件；循环变量增量) 语句；其中循环变量赋初值总是一个赋值语句，它用来给循环控制变量赋初值；循环条件是一个关系表达式，它决定什么时候退出循环；循环变量增量，定义循环控制变量每循环一次后按什么方式变化。这三个部分之间用 ; 分开，具体示例如下： 1234for(i=1; i&lt;=100; i++){ sum=sum+i;} for 语句的使用注意事项 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253i. for循环中的“表达式1（循环变量赋初值）”、“表达式2(循环条件)”和“表达式3(循环变量增量)”都是可选择项，即可以缺省，但“；”不能缺省ii. 若三个表达式都省略了，此时 for(;;) 语句相当于 while(1) 语句iii. 省略了“表达式1（循环变量赋初值）”，表示不对循环控制变量赋初值iiii. 可省略“表达式1（循环变量赋初值）”和“表达式3(循环变量增量)”，例如：for(;i&lt;=100;){ sum=sum+i; i++;}iiiii. 省略了“表达式2(循环条件)”，则不做其它处理时便成为死循环，例如：for(i=1;;i++){ sum=sum+i;}iiiiii. 省略了“表达式3(循环变量增量)”，则不对循环控制变量进行操作，这时可在循环体中加入修改循环控制变量的语句，例如：for(i=1;i&lt;=100;){ sum=sum+i; i++;}iiiiiii. 表达式1可以是设置循环变量的初值的赋值表达式，也可以是其他表达式，例如：for(sum=0;i&lt;=100;i++){ sum=sum+i;}iiiiiiii. 表达式1和表达式3可以是一个简单表达式也可以是逗号表达式，例如:for(sum=0,i=1;i&lt;=100;i++){{ sum=sum+i;}或者：for(i=0,j=100;i&lt;=100;i++,j--){ k=i+j;}iiiiiiiii. 表达式2一般是关系表达式或逻辑表达式，但也可是数值表达式或字符表达式，只要其值非零，就会执行循环体，例如：for(i=0;(c=getchar())!='\\n';i+=c){ printf(\"%c\",c);}或者：for(;(c=getchar())!='\\n';){ printf(\"%c\",c);} 四种循环语句的比较 四种循环都可以用来处理同一问题，一般情况下它们可以互相代替，但一般不提倡用 goto 型循环 在 while 循环和 do-while 循环中，都是在 while 后面的括号内指定循环条件，因此为了使循环能正常结束，应在循环体中包含使循环趋于结束的语句 (如 i++，或 i=i+1 等) for 循环可以在表达式 3 中包含使循环趋于结束的操作，甚至可以将循环体中的操作全部放到表达式 3 中，因此 for 语句的功能更强；凡是用 while 循环能完成的功能，for 循环都能实现 用 while 和 do-while 循环时，循环变量初始化的操作应在 while 和 do-while 语句之前完成，而 for 语句可以在表达式 1 中实现循环变量的初始化 while 循环、do-while 循环和 for 循环，都可以用 break 语句跳出循环，用 continue 语句结束本次循环；而对用 goto 语句和 if 语句构成的循环，不能用 break 语句和 continue 语句进行控制 break 语句 break 语句可以用来从循环体内跳出循环体，即提前结束循环，然后接着执行循环下面的语句，一般形式：break; break 语句不能用于循环语句和 switch 语句之外的任何其他语句中 break 语句对 if-else 的条件语句不起作用 在多层循环中，一个 break 语句只向外跳一层 continue 语句 continue 语句的作用是结束本次循环，即跳过循环体中下面尚未执行的语句，接着进行下一次是否执行循环的判定。一般形式：continue; continue 语句和 break 语句的区别是，continue 语句只结束本次循环，而不是终止整个循环的执行；break 语句则是结束整个循环过程，不再判断执行循环的条件是否成立 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c语言"},{"title":"Docker 安装 Privoxy 代理服务","url":"/posts/1b7c9c6f.html","text":"安装环境介绍 环境名称 版本 linux CentOS Linux release 7.7.1908 (Core) docker-ce 19.03.8 docker-compose 1.24.0-rc1 docker image vimagick/privoxy:latest 初始目录结构 目录结构 12345~/fig/privoxy/├── docker-compose.yml└── privoxy/ ├── user.action └── user.filter 文件：docker-compose.yml 123456789101112131415version: \"3.5\"services: privoxy: image: vimagick/privoxy:latest container_name: privoxy ports: - 8118:8118 volumes: - ./privoxy/user.action:/etc/privoxy/user.action - ./privoxy/user.filter:/etc/privoxy/user.filter cap_add: - NET_ADMIN restart: always 文件：user.action，以下的配置内容，作用是阻止 Privoxy 指向服务器本身的 IP 和域名，需要替换为你自己服务器的 IP 和域名。 1234{+block{block ip and domain which point to server itself}}127.0.0.145.32.57.113.example.com 文件：user.filter，该文件用于存放 Privoxy 的过滤规则，暂时不需要填写任何内容。 1 启动 Privoxy 服务12345678910111213141516171819# 进入目标目录# cd ~/fig/privoxy/# 创建并启动容器# docker-compose up -d# 打印日志信息$ docker-compose logs# 若输出的日志信息如下，则说明Privoxy的代理服务启动成功Attaching to privoxyprivoxy | 2020-03-27 22:49:28.383 7f30fa6aed48 Info: Privoxy version 3.0.28privoxy | 2020-03-27 22:49:28.383 7f30fa6aed48 Info: Program name: privoxyprivoxy | 2020-03-27 22:49:28.384 7f30fa6aed48 Info: Loading filter file: /etc/privoxy/default.filterprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading filter file: /etc/privoxy/user.filterprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/match-all.actionprivoxy | 2020-03-27 22:49:28.386 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/default.actionprivoxy | 2020-03-27 22:49:28.389 7f30fa6aed48 Info: Loading actions file: /etc/privoxy/user.actionprivoxy | 2020-03-27 22:49:28.389 7f30fa6aed48 Info: Listening on port 8118 on IP address 0.0.0.0 创建 Privoxy 的主配置文件123456789101112131415161718192021222324# 进入目标目录# cd ~/fig/privoxy# 拷贝容器中的config文件到本地磁盘（前提是容器已正常启动）# docker cp privoxy:/etc/privoxy/config ./privoxy/config# 文件授权# chmod 644 ./privoxy/config# 编辑docker-compose的配置文件，添加以下内容来挂载本地的config文件# vim docker-compose.ymlvolumes: - ./privoxy/config:/etc/privoxy/config# 重启容器让配置变更生效# docker-compose restart# 最终的目录结构~/fig/privoxy/├── docker-compose.yml└── privoxy/ ├── config ├── user.action └── user.filter 限制访问来源（可选步骤）Privoxy 支持 IP 白名单的功能，配置示例如下： 123456789# 进入目标目录# cd ~/fig/privoxy# 编辑config文件，在文件末尾添加一行内容（IP需要根据自己的实际情况进行修改）# vim ./privoxy/configpermit-access 14.215.177.38/26# 重启容器让配置变更生效# docker-compose restart 开放防火墙端口（Centos7）12345678# 开放Privoxy监听的8118端口# firewall-cmd --zone=public --permanent --add-port=8118/tcp# 保存防火墙配置# firewall-cmd --reload# 查看防火墙已开放的端口# firewall-cmd --list-ports 验证代理服务是否可用 在 Docker 容器内验证 123456789101112131415# 执行以下命令，若返回200状态码，则说明代理服务可用# curl -I -x 127.0.0.1:8118 www.baidu.comHTTP/1.1 200 OKAccept-Ranges: bytesCache-Control: private, no-cache, no-store, proxy-revalidate, no-transformConnection: keep-aliveContent-Length: 277Content-Type: text/htmlDate: Fri, 27 Mar 2020 01:39:09 GMTEtag: \"575e1f6f-115\"Last-Modified: Mon, 13 Jun 2016 02:49:08 GMTPragma: no-cacheServer: bfe/1.0.8.18Proxy-Connection: keep-alive 在其他 Linux 系统上验证 1234567891011121314# 执行以下命令，若返回200状态码，则说明代理服务可用# curl -I -x 45.32.57.113:8118 www.baidu.comHTTP/1.1 200 OKAccept-Ranges: bytesCache-Control: private, no-cache, no-store, proxy-revalidate, no-transformConnection: keep-aliveContent-Length: 277Content-Type: text/htmlDate: Fri, 27 Mar 2020 01:40:09 GMTEtag: \"575e1f60-115\"Last-Modified: Mon, 13 Jun 2016 02:50:08 GMTPragma: no-cacheServer: bfe/1.0.8.18Proxy-Connection: keep-alive 常见问题Privoxy 拒绝连接Privoxy 默认绑定的地址 127.0.0.1:8118，如果主机的 hostname 不是 localhost 或者 127.0.0.1，则需要更改 Privoxy 的主配置文件，重新配置 listen-address 参数。 查看 hostname 1# hostname 更改监听地址 1234# 编辑配置文件，更改监听地址# vim /etc/privoxy/configlisten-address yourHostName:8118 重新验证代理 1# curl -I -x yourHostName:8118 www.baidu.com 参考资料 vimagick/privoxy var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"容器化"},{"title":"C 语言语法之二顺序程序与分支结构程序设计","url":"/posts/b27b9a6a.html","text":"赋值语句 注意在变量声明中给变量赋初值和赋值语句的区别，给变量赋初值是变量声明的一部分，赋初值后的变量与其后的其它同类变量之间仍必须用逗号间隔，而赋值语句则必须用分号结尾，例如：int a=5,b,c; 在变量声明中，不允许连续给多个变量赋初值，而赋值语句则允许连续赋值，如 int a=b=c=5; 声明是错误的，正确的写法必须是：int a=5,b=5,c=5; 注意赋值表达式和赋值语句的区别，赋值表达式是一种表达式，它可以出现在任何允许表达式出现的地方，而赋值语句则不能，如 if((x=y+5)&gt;0) z=x; 语句是合法的，if((x=y+5;)&gt;0) z=x; 语句是非法的，因为 x=y+5; 是语句，不能出现在表达式中 putchar 函数与 getchar 函数 使用 putchar 和 getchar 函数前，都必须要用文件包含命令 #include &lt;stdio.h&gt; 或 #include “stdio.h” putchar 函数是字符输出函数，功能是在显示器上输出单个字符，其一般形式为：putchar (字符变量)，如 putchar('A'); getchar 函数的功能是从键盘上输入一个字符，其一般形式为：getchar ()，通常把输入的字符赋予一个字符变量来构成赋值语句，如：char c = getchar(); putch 函数与 getch 函数 getch 函数是一个不回显函数，当用户按下某个字符时，函数自动读取，无需按回车；有的 C 语言命令行程序会用到此函数做游戏，但是这个函数并非标准函数，要注意不同平台的移植性 Windows 系统使用 putch 和 getch 函数，需要引入 ‘conio.h’ 头文件；在使用 getch 函数之前要调用 initscr()，结束时要调用 endwin()，否则会出现不输入字符这个函数也会有返回值的情况 在不同的系统平台，输入回车，getch 函数将返回不同数值，而 getchar 函数统一返回十进制数 10 (即 \\n) Linux 系统不存在 conio.h 头文件，但可以使用 curses 库替代；若在编译的时候不通过，gcc 编译命令需要添加 -l curses 参数来引入 curses 库。Linux 系统下只能使用 getch 函数，而 putch 函数不能使用，因为 curses 库里没有 putch 函数 printf 函数（格式输出函数） printf 函数称为格式输出函数，其关键字最末一个字母 f 即为 “格式”(format) 之意。其功能是按用户指定的格式，把指定的数据显示到显示器屏幕上。该函数是一个标准库函数，它的函数原型在头文件 stdio.h 中，但作为一个特例，不要求在使用 printf 函数之前必须包含 stdio.h 文件，其调用的一般形式为：printf (“格式控制字符串”，输出表列) 其中格式控制字符串用于指定输出格式，格式控制串可由格式字符串和非格式字符串两种组成。格式字符串是以 % 开头的字符串，在 % 后面跟有各种格式字符，以说明输出数据的类型、形式、长度、小数位数等，如：%c 表示按字符型输出，%d 表示按十进制整型输出，%f 表示按小数形式输出单精度实数 1234i. 类型：具体类型如下表所示ii. 长度：长度格式符为h、l两种，h表示按短整型量输出，l表示按长整型量输出iii. 输出最小宽度：用十进制整数来表示输出的最少位数，若实际位数多于定义的宽度，则按实际位数输出，若实际位数少于定义的宽度则补以空格或0iiii. 输出精度：精度格式符以`.`开头，后面跟十进制整数，本项的意义是如果输出数字，则表示小数的位数；如果输出的是字符，则表示输出字符的个数；若实际位数大于所定义的精度数，则截去超过的部分 1234567891011/printf函数使用例子/int a = 15;char d = 'p';int x = 88, y = 89;float b = 123.1234567;double c = 12345678.1234567;printf(\"%c,%c\\n\",x,y); // &gt;&gt; X, Yprintf(\"a=%d,%5d,%o,%x\\n\",a,a,a,a); // &gt;&gt; a=15, 15,17,fprintf(\"b=%f,%lf,%5.4lf,%e\\n\",b,b,b,b); // &gt;&gt; b=123.123459,123.123459,123.1235,1.231235e+02printf(\"c=%lf,%f,%8.4lf\\n\",c,c,c); // &gt;&gt; c=12345678.123457,12345678.123457,12345678.1235printf(\"d=%c,%8c\\n\",d,d); // &gt;&gt; d=p, p scanf 函数（格式输入函数） scanf 函数称为格式输入函数，即按用户指定的格式从键盘上把数据输入到指定的变量之中。该函数是一个标准库函数，它的函数原型在头文件 stdio.h 中，与 printf 函数相同，C 语言也允许在使用 scanf 函数之前不必包含 stdio.h 文件。scanf 函数的一般形式为：scanf (“格式控制字符串”，地址表列)，其中格式控制字符串的作用与 printf 函数相同，如：int a,b; scanf(\"%d%d\",&amp;a,&amp;b);，但不能显示非格式字符串，也就是不能显示提示字符串。地址表列中给出各变量的地址，地址是由地址运算符 &amp; 后跟变量名组成，例如：&amp;a、 &amp;b 分别表示变量 a 和变量 b 的地址 格式控制字符串的一般形式为：%[*][输入数据宽度][长度] 类型，其中有方括号 [ ] 的项为任选项，各项的意义如下：1234i. *符号：用以表示该输入项读入后不赋予相应的变量，即跳过该输入值，例如: scanf(\"%d %*d %d\", &amp;a, &amp;b)，当输入为：1 2 3 时，将把1赋予a，2被跳过，3赋予bi. 宽度：用十进制整数指定输入的宽度(即字符数)，例如：scanf(\"%5d\", &amp;a)，当输入为：12345678，只把12345赋予变量a，其余部分被截去；又如：scanf(\"%4d%4d\", &amp;a, &amp;b)，当输入为：12345678，将把1234赋予a，而把5678赋予biii. 长度：格式符为l和h，h表示输入短整型数据，l表示输入长整型数据（如%ld） 和双精度浮点数（如%lf）iiii. 类型：表示输入数据的类型，其格式符和意义和printf函数相同，如：d表示输入十进制整数 使用 scanf 函数必须注意以下几点：123456i. 若输入的数据与输出的类型不一致时，虽然编译能够通过，但输出结果可能不正确ii. scanf函数中没有精度控制，如：scanf(\"%5.2f\", &amp;a) 是非法的，不能企图用此语句输入小数为2位的实数iii. scanf中要求给出变量地址，如给出变量名则会出错，如 scanf(\"%d\", a) 是非法的，应改为 scanf(\"%d\", &amp;a) 才是合法的iiii. 在输入多个数值数据时，若格式控制串中没有非格式字符作为输入数据之间的间隔，则可用空格、TAB或回车作间隔；C编译器在碰到空格、TAB、回车或非法数据（如对“%d”输入“12A”，A即为非法数据）时，即认为数据输入结束iiiii. 如果格式控制串中有非格式字符，则输入时也要输入该非格式字符，例如：scanf(\"%d,%d,%d\", &amp;a, &amp;b, &amp;c)，其中用非格式符“,”作间隔符，则输入数据应为：5,6,7，又如：scanf(\"a=%d,b=%d,c=%d\", &amp;a, &amp;b, &amp;c)，则输入数据应为：a=5,b=6,c=7iiiiii. 在输入字符数据时，若格式控制串中无非格式字符，则认为所有输入的字符均为有效字符，如：scanf(\"%c%c%c\", &amp;a, &amp;b, &amp;c)，当输入为：d e f，则把'd'赋予a，' '赋予b，'e'赋予c，只有当输入为：def 时，才能把'd'赋于a，'e'赋予b，'f'赋予c。如果在格式控制中加入空格作为间隔，如：scanf(\"%c %c %c\", &amp;a, &amp;b, &amp;c)，则输入时各数据之间可加空格，a、b、c也将会被赋予正确的值 关系运算符及其优先级关系运算符都是双目运算符，其结合性均为左结合，分别是 &lt;、&lt;=、&gt;、&gt;=、==、!=。关系运算符的优先级低于算术运算符，高于赋值运算符。在六个关系运算符中，前四个 &lt;、&lt;=、&gt;、&gt;= 的优先级相同，且高于 ==、!= 的优先级、而 ==、!= 的优先级相同。 关系表达式 关系表达式的一般形式为：表达式 关系运算符 表达式，例如：a+b &gt; c-d、x &gt; 3/2、-i-5*j == k+1。由于表达式也可以又是关系表达式，因此也允许出现嵌套的情况，例如：a &gt; (b&gt;c)、a != (c==d) 关系表达式的值是” 真” 和 “假”，分别使用 “1” 和 “0” 表示，例如：5 &gt; 0 的值为 “真”，即为 1，又如：(a=3) &gt; (b=5) 由于 3 &gt; 5 不成立，故其值为” 假”，即为 0 逻辑运算符及其优先级 C 语言中提供了三种逻辑运算符：&amp;&amp;（与运算）、||（或运算）、!（非运算），其中与运算符 &amp;&amp; 和或运算符 || 均为双目运算符，具有左结合性。非运算符 ! 为单目运算符，具有右结合性。三种逻辑运算符的优先级是如下图（最高处的运算符级别最高） 逻辑运算的值也分为 “真” 和 “假” 两种，用 “1” 和 “0 ” 来表示。其求值规则如下，与运算符 &amp;&amp;： 参与运算的两个量都为真时，结果才为真，否则为假，例如：5&gt;0 &amp;&amp; 4&gt;2，由于 5&gt;0 为真，4&gt;2 也为真，相与的结果也为真。或运算符 ||： 参与运算的两个量只要有一个为真，结果就为真，两个量都为假时，结果为假，例如：5&gt;0 || 5&gt;8 由于 5&gt;0 为真，相或的结果也就为真。非运算符 !： 参与运算量为真时，结果为假，参与运算量为假时，结果为真，例如：!(5&gt;0) 的结果为假 逻辑表达式 逻辑表达式的一般形式为：表达式 逻辑运算符 表达式，其中的表达式可以又是逻辑表达式，从而组成了嵌套的情形。例如：(a &amp;&amp; b) &amp;&amp; c，根据逻辑运算符的左结合性，也可写为：a &amp;&amp; b &amp;&amp; c if 语句if 语句可以构成分支结构，它根据给定的条件进行判断，以决定执行某个分支程序段，C 语言的 if 语句有三种基本形式： 第一种形式为：if (表达式) 语句，其语义是：如果表达式的值为真，则执行其后的语句，否则不执行该语句 第二种形式为: if-else 第三种形式为：if-else-if，前两种形式的 if 语句一般都用于两个分支以下的情况，当有多个分支选择时，可采用 if-else-if 语句 使用 if 语句应注意的问题 为了避免这种二义性，C 语言规定，else 总是与它前面最近的 if 配对 在 if 语句中，条件判断表达式必须用括号括起来，在语句之后必须加分号 在 if 语句的三种形式中，所有的语句应为单个语句，如果要想在满足条件时执行一组（多个）语句，则必须把这一组语句用 {} 括起来组成一个复合语句，但是在 } 之后不能再加分号 在三种形式的 if 语句中，在 if 关键字之后均为表达式，该表达式通常是逻辑表达式或关系表达式，但也可以是其它表达式，如赋值表达式等，甚至也可以是一个变量。例如：if(a=5) 语句、if(b) 语句 都是合法的，只要表达式的值为非 0，即为 “真” 条件运算符与条件表达式 条件运算符为 ? 和 :，它是一个三目运算符，即有三个参与运算的量。由条件运算符组成条件表达式的一般形式为：表达式 1? 表达式 2: 表达式 3，其求值规则为：如果表达式 1 的值为真，则以表达式 2 的值作为条件表达式的值，否则以表达式 3 的值作为整个条件表达式的值 条件表达式通常用于赋值语句之中，例如条件语句：if(a&gt;b) max=a; else max=b;，可用条件表达式改写为 max=(a&gt;b)?a:b;，执行该语句的语义是：如 a&gt;b 为真，则把 a 赋予 max，否则把 b 赋予 max 条件运算符的运算优先级低于关系运算符和算术运算符，但高于赋值符，因此 max=(a&gt;b)?a:b 可以去掉括号而写为 max=a&gt;b?a:b。条件运算符？和：是一对运算符，不能分开单独使用，其结合方向是自右至左 switch 语句 C 语言还提供了另一种用于多分支选择的 switch 语句，其一般形式为： 1234567switch(表达式){ case 常量表达式: 语句1; case 常量表达式: 语句2; ... case 常量表达式: 语句n; default: 语句n+1;} 其语义是计算表达式的值，并逐个与其后的常量表达式值相比较，当表达式的值与某个常量表达式的值相等时，则执行其后的语句，然后不再进行判断，继续执行后面所有 case、default 后的语句（没有使用 break 关键字的时候） 在使用 switch 语句时还应注意以下几点： 12345i. default子句可以省略不用ii. 在case后的各常量表达式的值不能相同，否则会出现错误iii. 在case后，允许有多个语句，可以不用{}括起来，但建议使用{}括起来iiii. 各case和default子句的先后顺序可以变动，而不会影响程序执行结果 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c语言"},{"title":"Spring Boot Admin 集成钉钉群机器人报警通知","url":"/posts/e728f445.html","text":"前言实现流程创建钉钉群机器人后，得到 Webhook 与 Secret。Java 代码 实现 Admin 的 Notifier 接口，当监听到 Admin 服务状态变更后，直接调用 Webhook 发送消息给钉钉群机器人，群成员就可以收到报警消息通知，这个过程与 Github 的 Webhook 实现流程一致。 钉钉官方文档 钉钉官方文档 - 自定义机器人接入 钉钉官方文档 - 自定义机器人接入界面 值得一提的是，本文使用的是钉钉提供的 自定义机器人 接口，而不是 开发企业内部机器人 接口，同时 Webhook 里包含的 access_token 不存在有效期（永久有效），即不需要定时刷新 access_token。 创建钉钉群机器人首先登录钉钉的 PC 版，创建钉钉群机器人，得到钉钉群机器人的 Webhook；在群机器人的安全设置页面，若选择加签名，加签一栏下面还可以获取到 SEC 开头的字符串（签名秘钥）。 Admin 集成钉钉群机器人通知Java 核心代码钉钉群机器人的配置类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Configuration;@Configurationpublic class DingTalkConfig { /** * 是否启用钉钉群机器人通知（默认否） */ @Value(\"${notify.dingtalk.enable:false}\") private boolean robotEnable; /** * 钉钉群机器人所给URL后面的access_token参数值 */ @Value(\"${notify.dingtalk.access-token:}\") private String accessToken; /** * 钉钉群机器人的签名秘钥 */ @Value(\"${notify.dingtalk.sign-secret:}\") private String signSecret; /** * 是否加签名（默认是） */ @Value(\"${notify.dingtalk.enable-signature:true}\") private boolean enableSignature; public boolean isRobotEnable() { return robotEnable; } public String getAccessToken() { return accessToken; } public String getSignSecret() { return signSecret; } public boolean isEnableSignature() { return enableSignature; }} 钉钉群机器人的消息类型枚举类 12345678910111213141516171819202122232425262728293031public enum DingTalkMessageType { TEXT(\"text\", \"文本消息\"), LINK(\"link\", \"链接消息\"), MARK_DOWN(\"markdown\", \"MarkDown消息\"), FEED_CARD(\"feedCard\", \"FeedCard消息\"), ACTION_CARD(\"actionCard\", \"ActionCard消息\"); private String value; private String name; DingTalkMessageType(String value, String name) { this.value = value; this.name = name; } public String getValue() { return value; } public String getName() { return name; }} 钉钉群机器人的常量类 123456789public class DingTalkConstants { public static final String SERVER_URL = \"https://oapi.dingtalk.com\"; public static final String API_SEND_MESSAGE = SERVER_URL + \"/robot/send?access_token=%s\"; public static final String API_SEND_MESSAGE_SIGN = SERVER_URL + \"/robot/send?access_token=%s&amp;timestamp=%s&amp;sign=%s\";} 钉钉群机器人的消息发送类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import cn.hutool.core.codec.Base64;import com.dingtalk.api.DefaultDingTalkClient;import com.dingtalk.api.DingTalkClient;import com.dingtalk.api.request.OapiRobotSendRequest;import com.monitor.notify.config.DingTalkConfig;import com.monitor.notify.constants.DingTalkConstants;import com.monitor.notify.enums.DingTalkMessageType;import com.taobao.api.TaobaoResponse;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.autoconfigure.condition.ConditionalOnExpression;import org.springframework.stereotype.Component;import javax.crypto.Mac;import javax.crypto.spec.SecretKeySpec;import java.net.URLEncoder;/** * 钉钉群机器人消息发送&lt;br&gt; * 每个钉钉群机器人每分钟最多发送20条，如果超过20条，会限流10分钟&lt;br&gt; * 支持多种消息类型，发起POST请求时，必须将字符集编码设置成UTF-8&lt;br&gt; */@Component@ConditionalOnExpression(\"${notify.dingtalk.enable:false}\")public class DingTalkMessageSender { private static final Logger logger = LoggerFactory.getLogger(DingTalkMessageSender.class); private DingTalkConfig dingTalkConfig; public DingTalkMessageSender(DingTalkConfig dingTalkConfig) { this.dingTalkConfig = dingTalkConfig; } /** * 发送文本消息 * * @param msgText 消息内容 * @return */ public boolean sendTextMessage(String msgText) { String logContent = msgText.replace(\" \", \"\").replace(\"\\n\", \"\"); try { logger.info(\"钉钉群机器人发送Text消息： {}\", logContent); DingTalkClient client = new DefaultDingTalkClient(getUrl()); OapiRobotSendRequest.Text text = new OapiRobotSendRequest.Text(); text.setContent(msgText); OapiRobotSendRequest request = new OapiRobotSendRequest(); request.setMsgtype(DingTalkMessageType.TEXT.getValue()); request.setText(text); TaobaoResponse response = client.execute(request); return response.isSuccess(); } catch (Exception e) { logger.error(\"钉钉群机器人发送Text消息失败 : {} : {}\", logContent, e.getLocalizedMessage()); } return false; } /** * 发送Markdown消息 * * @param title 标题 * @param msgText 消息内容 * @return */ public boolean sendMarkdownMessage(String title, String msgText) { String logContent = msgText.replace(\" \", \"\").replace(\"\\n\", \"\"); try { logger.info(\"钉钉群机器人发送Markdown消息： {}\", logContent); DingTalkClient client = new DefaultDingTalkClient(getUrl()); OapiRobotSendRequest.Markdown markdown = new OapiRobotSendRequest.Markdown(); markdown.setTitle(title); markdown.setText(msgText); OapiRobotSendRequest request = new OapiRobotSendRequest(); request.setMsgtype(DingTalkMessageType.MARK_DOWN.getValue()); request.setMarkdown(markdown); TaobaoResponse response = client.execute(request); return response.isSuccess(); } catch (Exception e) { logger.error(\"钉钉群机器人发送Markdown消息失败 : {} : {}\", logContent, e.getLocalizedMessage()); } return false; } /** * 获取URL * * @return * @throws Exception */ private String getUrl() throws Exception { String accessToken = dingTalkConfig.getAccessToken(); if (!dingTalkConfig.isEnableSignature()) { return String.format(DingTalkConstants.API_SEND_MESSAGE, accessToken); } else { Long timestamp = System.currentTimeMillis(); String sign = getSign(timestamp, dingTalkConfig.getSignSecret()); return String.format(DingTalkConstants.API_SEND_MESSAGE_SIGN, accessToken, timestamp, sign); } } /** * 获取签名 * * @param timestamp 时间戳 * @param secret 钉钉群机器人的签名秘钥 * @return * @throws Exception */ private String getSign(Long timestamp, String secret) throws Exception { String stringToSign = timestamp + \"\\n\" + secret; Mac mac = Mac.getInstance(\"HmacSHA256\"); mac.init(new SecretKeySpec(secret.getBytes(\"UTF-8\"), \"HmacSHA256\")); byte[] signData = mac.doFinal(stringToSign.getBytes(\"UTF-8\")); return URLEncoder.encode(new String(Base64.encode(signData)), \"UTF-8\"); }} 消息通知模板类 123456789101112131415161718192021public class MessageTemplate { /** * 默认的监控消息模板 */ public static final String MONITOR_TEXT_TEMPLATE = \"服务名: %s（%s） \\n服务状态: %s（%s） \\n服务 IP: %s \\n发送时间: %s\"; /** * 钉钉群机器人的MarkDown监控消息模板 */ public static final String MONITOR_MARKDOWN_TEMPLATE_DINGTALK = \"**服务名称：**\\n\\n\" + \"%s（%s）\\n\\n\" + \"**服务状态：**\\n\\n\" + \"%s（%s）\\n\\n\" + \"**服务IP：**\\n\\n\" + \"%s\\n\\n\" + \"**发送时间：**\\n\\n\" + \"%s\\n\\n\";} 实现 Admin 的 Notifier 接口来添加钉钉群机器人的消息通知，若需要监听服务的所有事件变更，还可以改为继承 AbstractEventNotifier 类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import de.codecentric.boot.admin.server.domain.entities.Instance;import de.codecentric.boot.admin.server.domain.entities.InstanceRepository;import de.codecentric.boot.admin.server.domain.events.InstanceEvent;import de.codecentric.boot.admin.server.domain.events.InstanceStatusChangedEvent;import de.codecentric.boot.admin.server.notify.AbstractStatusChangeNotifier;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import reactor.core.publisher.Mono;public abstract class CustomNotifier extends AbstractStatusChangeNotifier { private Logger logger = LoggerFactory.getLogger(CustomNotifier.class); protected CustomNotifier(InstanceRepository repository) { super(repository); } @Override protected Mono&lt;Void&gt; doNotify(InstanceEvent event, Instance instance) { return Mono.fromRunnable(() -&gt; { if (event instanceof InstanceStatusChangedEvent) { logger.info(\"Instance {} ({}) is {}\", instance.getRegistration().getName(), event.getInstance(), ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus()); String status = ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus(); switch (status) { // 健康检查没通过 case \"DOWN\": sendMessage(event, instance, \"健康检查没通过\"); break; // 服务下线 case \"OFFLINE\": sendMessage(event, instance, \"服务下线\"); break; // 服务上线 case \"UP\": sendMessage(event, instance, \"服务上线\"); break; // 服务未知状态 case \"UNKNOWN\": sendMessage(event, instance, \"服务出现未知状态\"); break; default: break; } } else { logger.info(\"Instance {} ({}) {}\", instance.getRegistration().getName(), event.getInstance(), event.getType()); } }); } public abstract void sendMessage(InstanceEvent event, Instance instance, String content);} Admin 的服务状态变更钉钉群机器人通知实现类 12345678910111213141516171819202122232425262728293031323334353637383940414243import cn.hutool.core.date.DatePattern;import cn.hutool.core.date.DateUtil;import com.monitor.notify.message.DingTalkMessageSender;import com.monitor.notify.template.MessageTemplate;import de.codecentric.boot.admin.server.domain.entities.Instance;import de.codecentric.boot.admin.server.domain.entities.InstanceRepository;import de.codecentric.boot.admin.server.domain.events.InstanceEvent;import de.codecentric.boot.admin.server.domain.events.InstanceStatusChangedEvent;import org.springframework.boot.autoconfigure.condition.ConditionalOnExpression;import org.springframework.stereotype.Component;import java.util.Date;@Component@ConditionalOnExpression(\"${notify.dingtalk.enable:false}\")public class DingtalkNotifier extends CustomNotifier { private DingTalkMessageSender messageSender; protected DingtalkNotifier(InstanceRepository repository, DingTalkMessageSender messageSender) { super(repository); this.messageSender = messageSender; } /** * 发送钉钉群机器人消息 * * @param event * @param instance * @param content */ @Override public void sendMessage(InstanceEvent event, Instance instance, String content) { String instanceName = instance.getRegistration().getName(); String instanceId = event.getInstance().toString(); String status = ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus(); String serviceUrl = instance.getRegistration().getServiceUrl(); String dateTime = DateUtil.format(new Date(), DatePattern.NORM_DATETIME_MS_PATTERN); String message = String.format(MessageTemplate.MONITOR_MARKDOWN_TEMPLATE_DINGTALK, instanceName, instanceId, status, content, serviceUrl, dateTime); this.messageSender.sendMarkdownMessage(\"监控消息\", message); }} YML 配置内容123456notify: dingtalk: enable: true access-token: xxxxxxxxxxx sign-secret: SECxxxxxxxxxxx enable-signature: true 钉钉的 Java SDK由于钉钉官方没有将钉钉的 SDK 发布到 Maven 仓库，因此需要在钉钉官网手动下载最新版的 SDK，然后发布到 Maven 私有仓库，或者安装在本地的 Maven 仓库，最后在项目的 pom.xml 配置文件里添加以下依赖。 12345&lt;dependency&gt; &lt;groupId&gt;com.dingtalk&lt;/groupId&gt; &lt;artifactId&gt;dingtalk-api-sdk&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 安装钉钉 SDK 到本地 Maven 仓库的命令如下： 1$ mvn install:install-file -Dfile=taobao-sdk-java-auto_1455552377940-20200322.jar -DgroupId=com.dingtalk -DartifactId=dingtalk-api-sdk -Dversion=1.0.0 -Dpackaging=jar 值得一提的是，不同版本的 钉钉 SDK，其 Maven 坐标中的 groupId、artifactId、version 可能会发生变化，此时只需要将上面对应的参数值替换掉即可。 生产环境扩展建议上述给出的是 Spring Boot Admin 集成钉钉群机器人消息通知的 Demo 代码，生产环境下还需要考虑到如下的实际问题： 报警消息重复发送：若 Admin 应用以集群的方式部署，当 A 应用 DOWN 掉后，那么钉钉群成员将会收到多条 A 应用服务状态变更的报警消息 报警消息的持久化：若大量报警消息积压在 Admin 应用里，但还没来得及发送，此时如果 Admin 应用挂掉，那么报警消息将会丢失，建议使用 消息中间件 的持久化特性来解决 报警消息的发送频率：每个钉钉群机器人每分钟最多发送 20 条，如果超过 20 条，会限流 10 分钟；这里建议利用 任务调度线程池 来实现报警消息的调度发送，同时考虑将多条报警消息合并后再发送，以此来解决报警消息发送频率受限制的问题 参考博客 Java 利用钉钉机器人向钉钉群推送消息 Spring Boot Admin 官方集成各类消息通知的源码实现 Spring Boot Admin 2.0.1 集成自定义监控告警 - 钉钉机器人 一个管理异常通知的 Starter，实现了钉钉消息提醒与邮件提醒 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"数据结构与算法之一","url":"/posts/6f42c94c.html","text":"前言 编程四大基础：数据结构与算法、计算机网络、操作系统、设计模式 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"算法与数据结构"},{"title":"You-Get 安装使用与介绍","url":"/posts/4d770034.html","text":"前言 You-Get 是一个基于 Python3 的下载工具，可以很轻松地下载到网络上的视频、图片及音乐资源，默认支持 YouTube、哔哩哔哩、优酷、爱奇艺、腾讯视频等视频网站的下载。下面将介绍在 Linux 系统下如何使用 You-Get，此教程适用于 Centos/Debian/Ubuntu 等 Linux 发行版。 依赖说明 以下是必要的依赖，需要提前单独安装，除非是在 Windows 系统下使用预安装包： Python 3.2+ FFmpeg 1.0+ RTMPDump（可选） 通过 PIP 安装 You-Get 的官方版本通过 PyPI 分发，可从 PyPI 镜像中通过 pip 包管理器安装，务必使用 Python3 的 pip。 1$ pip3 install you-get 软件版本升级 1$ pip3 install --upgrade you-get 下载视频 当观赏到感兴趣的视频，可以使用 --info/-i 参数来查看视频的所有可用画质与格式: 123456789101112131415161718192021222324252627282930$ you-get -i 'https://www.youtube.com/watch?v=jNQXAC9IVRw'site: YouTubetitle: Me at the zoostreams: # Available quality and codecs [ DEFAULT ] _________________________________ - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL] - itag: 18 container: mp4 quality: medium # download-with: you-get --itag=18 [URL] - itag: 5 container: flv quality: small # download-with: you-get --itag=5 [URL] - itag: 36 container: 3gp quality: small # download-with: you-get --itag=36 [URL] - itag: 17 container: 3gp quality: small # download-with: you-get --itag=17 [URL] 标有 DEFAULT 的为默认画质，一般情况下可直接下载，如 YouTube 视频带有字幕，那边字幕将被一同下载，以 SubRip 格式保存： 1234567891011121314$ you-get 'https://www.youtube.com/watch?v=jNQXAC9IVRw'site: YouTubetitle: Me at the zoostream: - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL]Downloading zoo.webm ...100.0% ( 0.5/0.5 MB) ├████████████████████████████████████████┤[1/1] 7 MB/sSaving Me at the zoo.en.srt ...Done. 注意: 批量下载可以使用参数 --playlist 目前，视频格式选择没有大规模铺开，默认选项为最高画质 ffmpeg 为必要依赖，用于下载流式视频以及合并分块视频 (例如 Youku)，以及 YouTube 的 1080p 或更高分辨率的视频 如果不希望 You-Get 合并视频，可以使用 --no-merge/-n 下载其他内容 直接使用 URL 下载图片，此功能为测试性，远未完成；对于类似 Tumblr 和 Blogger 的大图有效，但是没有办法为所有网站建立通用格式。 12345678$ you-get https://stallman.org/rms.jpgSite: stallman.orgTitle: rmsType: JPEG Image (image/jpeg)Size: 0.06 MiB (66482 Bytes)Downloading rms.jpg ...100.0% ( 0.1/0.1 MB) ├████████████████████████████████████████┤[1/1] 127 kB/s 暂停与恢复下载 可以使用 Ctrl+C 暂停下载，临时的 .download 文件将保存于输出目录。下次使用 You-Get 传入相同参数时，下载将从上次继续开始。如果下载已经完成，临时的 .download 扩展名文件将会被删除，此时 You-Get 将忽略下载。可以用 --force/-f 强行重新下载，会覆盖同名文件或临时文件！ 设置输出路径或文件名 使用 --output-dir/-o 设置路径，--output-filename/-O 设置输出文件名： 1$ you-get -o ~/Videos -O zoo.webm 'https://www.youtube.com/watch?v=jNQXAC9IVRw' 提示: 此参数可以帮助使用脚本批量下载于指定目录和文件名 如果原视频标题包含有与系统不兼容的字符，此参数十分有效 代理设置 使用 --http-proxy/-x 为 You-Get 设置 HTTP 代理，同时系统代理 (即系统变量 http_proxy) 会自动生效，使用 --no-proxy 则可以强行关闭代理： 1$ you-get -x 127.0.0.1:8087 'https://www.youtube.com/watch?v=jNQXAC9IVRw' 提示: 如果经常使用代理 (网络封锁了部分网站)，考虑将 You-Get 和 ProxyChains 一同使用，并在命令行中设置 alias you-get=\"proxychains -q you-get\" 对于某些网站 (例如 Youku)，如果你需要下载仅供中国大陆观看的视频，可以使用 --extractor-proxy/-y 单独为解析器设置代理，也可以使用 -y proxy.uku.im:8888 (鸣谢： Unblock Youku 项目) 播放视频 使用 --player/-p 将视频投喂给播放器，例如 mplayer 或者 vlc，而不是下载视频： 1$ you-get -p vlc 'https://www.youtube.com/watch?v=jNQXAC9IVRw' 或者想在浏览器中观看而不希望看广告或评论区: 1$ you-get -p chromium 'https://www.youtube.com/watch?v=jNQXAC9IVRw' 提示：可以使用 -p 开启下载工具，例如 you-get -p uget-gtk 'https://www.youtube.com/watch?v=jNQXAC9IVRw'，虽然有可能不灵。 加载 Cookie 并非所有视频可供任何人观看，如果需要登录才可以观看 (例如会员视频)，那么可能必须将浏览器的 cookie 通过 --cookies/-c 加载入 You-Get，目前支持两种 cookie 格式：Mozilla cookies.sqlite 和 Netscape cookies.txt。 复用解析数据 使用 --url/-u 获得页面所有可下载 URL 列表，使用 --json 参数则可以获得 JSON 格式的数据，目前此功能未定型，JSON 格式未来有可能变化。 哔哩哔哩批量下载脚本 针对哔哩哔哩的视频，若批量下载参数 --playlist 不适用，可以使用以下 Shell 脚本实现批量下载，传入的参数包括：URL、开始集数、结束集数。如果希望同时执行多个下载任务，那么可以使用不同的参数来多次执行脚本，此操作由于频繁访问哔哩哔哩的视频网站，存在 IP 被封的风险（Http 请求返回 403 错误码）。 12#!/bin/shfor i in $(seq $2 $3); do you-get $1$i; done 或者控制每次执行下载任务之前都等待 N 秒（建议 40 &lt;= N &lt;= 60），防止连续多次下载失败时，频繁访问服务器导致 IP 被封： 12#!/bin/shfor i in $(seq $2 $3); do sleep 40 &amp;&amp; you-get $1$i; done Shell 脚本使用示例： 1sh bilibil.sh https://www.bilibili.com/video/av33087749/?p= 1 3 参考资料 You-Get 官方英文使用说明 You-Get 官方中文使用说明 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux"},{"title":"Spring Boot Admin 基础使用教程","url":"/posts/748546b6.html","text":"1、Admin 简介Spring Boot Admin 是一个开源社区项目，用于管理和监控 Spring Boot 应用程序。 应用程序作为 Spring Boot Admin Client 向为 Spring Boot Admin Server 注册（通过 HTTP 协议）或使用 Spring Cloud 注册中心（例如 Eureka、Consul）的服务发现。UI 是的 AngularJs 应用程序，用于展示 Spring Boot Admin Client 的 Actuator 端点上的一些监控数据。Spring Boot Admin 默认提供了如下功能（包括但不限于）： 显示健康状态及详细信息，如 JVM 和内存指标、数据源指标、缓存指标 显示构建信息编号 跟踪并下载日志文件 查看 JVM 系统和环境属性 查看 Spring Boot 配置属性 轻松的日志级别管理 与 JMX-Beans 交互 查看线程转储 查看 Http 跟踪 查看 auditevents 查看 http-endpoints 查看计划任务 查看和删除活动会话（基于 Spring-Session） 查看 Flyway/Liquibase 数据库迁移 下载 heapdump 文件 状态变更通知（支持电子邮件、Slack、Hipchat …） 状态更改的事件日志（非持久性） 特别注意：Spring Boot Admin 默认不支持监控数据的持久化，若对数据的持久化有要求，建议考虑使用 Metrics、CAT、Prometheus + Grafana 等监控平台。 2、Admin 快速入门2.1、版本说明在本文中，使用的 Spring Cloud 版本是 Hoxton.SR1，对应的 Spring Boot 版本是 2.2.2.RELEASE，特别声明除外，点击下载完整的案例代码。 2.2、创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 2.3、创建 Admin Server 工程创建 Admin Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt; 添加 Admin Server 需要的 application.yml 配置文件到工程中： 123456server: port: 9001spring: application: name: admin-server 创建 Admin Server 的主启动类，引入 @EnableAdminServer 注解： 12345678@EnableAdminServer@SpringBootApplicationpublic class AdminServerApplication { public static void main(String[] args) { SpringApplication.run(AdminServerApplication.class, args); }} 2.4、创建 Admin Client 工程创建 Admin Client 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Client 需要的 application.yml 配置文件到工程中，其中 spring.boot.admin.client.url 是 Admin Server 的地址，目的是将 Admin Client 注册到 Admin Server 中，最后暴露 Admin Client 的 Actuator 的所有端口： 123456789101112131415161718192021server: port: 9002spring: application: name: admin-client boot: admin: client: url: http://127.0.0.1:9001 #Spring Boot Admin Server 的地址 instance: prefer-ip: true #将IP注册到Admin Server上，若不配置默认使用机器的主机名，新版本使用的是 \"service-host-type: ip\"management: endpoints: web: exposure: include: \"*\" endpoint: health: show-details: ALWAYS 提示 将微服务应用注册到 Admin Server 上时，若希望使用 IP 地址来替代主机名，Spring Admin 的旧版本（例如 2.3.0）可以使用 prefer-ip: true，而在新版本（例如 2.7.9）里使用的是 service-host-type: ip。 创建 Admin Client 的主启动类： 1234567@SpringBootApplicationpublic class AdminClientApplication { public static void main(String[] args) { SpringApplication.run(AdminClientApplication.class, args); }} 2.5、测试结果 1）依次启动 admin-server、admin-client 应用程序 2）浏览器访问 http://127.0.0.1:9001/，打开 Admin Server 的主界面，如下图所示： 3）点击实例信息链接跳转到详细页面，可以查看实例的详细监控信息，如图所示 3、Admin 在线查看日志文件3.1、配置日志文件Spring Boot Admin 提供了基于 Web 页面的方式实时查看业务服务输出的本地日志（如下图），前提是在业务服务中配置了 logging.file，即在被监控的业务模块的 application.yml 配置文件中增加下面的内容： 12logging: file: /tmp/shop/auth.log 特别注意 上述的配置内容只适用于 Spring Admin 旧版本（例如 2.3.0），而在新版本（例如 2.7.9）里需要改用以下配置内容来指定日志文件的路径，否则 Admin 的控制台界面会提示 Fetching logfile failed 的错误信息。 在线查看日志文件之前，必须确保日志文件不是空白文件，否则 Admin 无法正常读取日志文件的内容，此时请求日志文件的 HTTP 响应状态为 416 Requested range not satisfiable。 123456789101112# 暴露监控端点management: endpoints: web: exposure: include: \"*\" endpoint: health: show-details: ALWAYS logfile: external-file: /tmp/shop/auth.log enabled: true 3.2、源码分析其核心在 LogFileWebEndpointAutoConfiguration 自动配置类上，所以 logging.file.name、logging.file.path、management.endpoint.logfile.external-file 都可以作为开启条件。使用 logging.file.path 配置需要注意，因为默认会读取 spring.log 作为日志文件，而 logging.file.name 则不会。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration( proxyBeanMethods = false)@ConditionalOnAvailableEndpoint( endpoint = LogFileWebEndpoint.class)@EnableConfigurationProperties({LogFileWebEndpointProperties.class})public class LogFileWebEndpointAutoConfiguration { public LogFileWebEndpointAutoConfiguration() { } @Bean @ConditionalOnMissingBean @Conditional({LogFileWebEndpointAutoConfiguration.LogFileCondition.class}) public LogFileWebEndpoint logFileWebEndpoint(ObjectProvider&lt;LogFile&gt; logFile, LogFileWebEndpointProperties properties) { return new LogFileWebEndpoint((LogFile)logFile.getIfAvailable(), properties.getExternalFile()); } private static class LogFileCondition extends SpringBootCondition { private LogFileCondition() { } public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) { Environment environment = context.getEnvironment(); String config = this.getLogFileConfig(environment, \"logging.file.name\", \"logging.file\"); Builder message = ConditionMessage.forCondition(\"Log File\", new Object[0]); if (StringUtils.hasText(config)) { return ConditionOutcome.match(message.found(\"logging.file.name\").items(new Object[]{config})); } else { config = this.getLogFileConfig(environment, \"logging.file.path\", \"logging.path\"); if (StringUtils.hasText(config)) { return ConditionOutcome.match(message.found(\"logging.file.path\").items(new Object[]{config})); } else { config = environment.getProperty(\"management.endpoint.logfile.external-file\"); return StringUtils.hasText(config) ? ConditionOutcome.match(message.found(\"management.endpoint.logfile.external-file\").items(new Object[]{config})) : ConditionOutcome.noMatch(message.didNotFind(\"logging file\").atAll()); } } } private String getLogFileConfig(Environment environment, String configName, String deprecatedConfigName) { String config = environment.resolvePlaceholders(\"${\" + configName + \":}\"); return StringUtils.hasText(config) ? config : environment.resolvePlaceholders(\"${\" + deprecatedConfigName + \":}\"); } }} 另外可以看到 LogFileWebEndpointProperties 这个类，所以 management.endpoint.logfile.externalFile 也是可以作为开启条件 实际上 Spring 在解析 Properties 时会在 Spring 缓存的 Map 中，把 management.endpoint.logfile.external-file 的 Key 转换成 management.endpoint.logfile.externalFile 4、Admin 整合 Eureka 注册中心在上述的快速入门案例里，是直接将 Admin Client 注册到了 Admin Server 中，而企业开发中更多的是将服务注册到注册中心（Eureka、Consul），以下的案例将演示如何整合 Admin 和 Eureka，点击下载完整的案例代码。 4.1、版本说明在本文中，使用的 Spring Cloud 版本是 Hoxton.SR1，对应的 Spring Boot 版本是 2.2.2.RELEASE，特别声明除外，点击下载完整的案例代码。 4.2、创建 Maven 父级 Pom 工程在父工程里面配置好工程需要的父级依赖，目的是为了更方便管理与简化配置，具体 Maven 配置如下： 123456789101112131415161718192021222324252627282930&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!-- 管理依赖 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!--注意：这里需要添加以下配置，否则可能会有各种依赖问题 --&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 4.3、创建 Eureka Server 工程创建 Eureka Server 的 Maven 工程，配置工程里的 pom.xml 文件： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 Eureka Server 的启动主类： 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args){ SpringApplication.run(EurekaServerApplication.class, args); }} 添加 Eureka Server 需要的 application.yml 配置文件到工程： 1234567891011server: port: 9003eureka: instance: hostname: localhost #Eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己 fetch-registry: false #false表示自己就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4.4、创建 Admin Server 工程创建 Admin Server 的 Maven 工程，配置工程里的 pom.xml 文件： 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Server 需要的 application.yml 配置文件到工程中，将 Admin Server 注册到 Eureka 注册中心，并暴露 Admin Server 的 Actuator 的所有端口： 1234567891011121314151617181920212223242526server: port: 9001spring: application: name: admin-servereureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名management: endpoints: web: exposure: include: \"*\" endpoint: health: show-details: ALWAYS 创建 Admin Server 的主启动类，添加 @EnableAdminServer 注解开启监控功能，添加 @EnableDiscoveryClient 注解让 Admin Server 可以发现注册到 Eureka 里的其他服务实例： 123456789@EnableAdminServer@EnableDiscoveryClient@SpringBootApplicationpublic class AdminServerApplication { public static void main(String[] args) { SpringApplication.run(AdminServerApplication.class, args); }} 4.5、创建 Admin Client 工程创建 Admin Client 的 Maven 工程，配置工程里的 pom.xml 文件： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加 Admin Client 需要的 application.yml 配置文件到工程中，将 Admin Client 注册到 Eureka 注册中心，而不是使用上述快速入门案例里的 spring.boot.admin.client.url 将 Admin Client 注册到 Admin Server 中，最后暴露 Admin Client 的 Actuator 的所有端口： 1234567891011121314151617181920212223242526server: port: 9002spring: application: name: admin-clienteureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名management: endpoints: web: exposure: include: \"*\" endpoint: health: show-details: ALWAYS 创建 Admin Client 的主启动类，引入 @EnableDiscoveryClient 注解： 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class AdminClientApplication { public static void main(String[] args) { SpringApplication.run(AdminClientApplication.class, args); }} 4.6、测试结果 1）依次启动 eureka-server、admin-server、admin-client 应用程序 2）浏览器访问 http://127.0.0.1:9001/，打开 Admin Server 的 Web 界面，可以看到有两个服务（如下图所示）： 3）点击实例信息链接跳转到详细页面，可以查看实例的详细监控信息，这里不再累述 5、Admin 整合 Spring Security生产环境中由于考虑到安全问题，一般不允许直接访问 Admin Server 的 Web 界面，建议整合 Admin + Spring Security，为 Admin Server 新增登录界面，点击下载完整的案例代码。 在 Admin Server 工程的 pom.xml 配置文件中引入以下的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 在 Admin Server 工程的 application.yml 中配置 Spring Security 的用户名和密码，同时在服务注册时带上 metadata-map 的信息： 123456789101112131415161718192021222324252627282930313233server: port: 9001spring: application: name: admin-server security: user: name: \"admin\" password: \"admin\"eureka: client: registryFetchIntervalSeconds: 5 service-url: defaultZone: http://127.0.0.1:9003/eureka/ instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health instance-id: ${spring.application.name}-${server.port} #自定义服务名称 prefer-ip-address: true #将IP注册到Eureka Server上，若不配置默认使用机器的主机名 metadata-map: #指定Spring Security的用户名和密码 user.name: ${spring.security.user.name} user.password: ${spring.security.user.password}management: endpoints: web: exposure: include: \"*\" endpoint: health: show-details: ALWAYS 在 Admin Server 工程中创建 Spring Security 的配置类： 12345678910111213141516171819202122232425@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { private final String adminContextPath; public SecurityConfiguration(AdminServerProperties adminServerProperties) { this.adminContextPath = adminServerProperties.getContextPath(); } @Override protected void configure(HttpSecurity http) throws Exception { SavedRequestAwareAuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler(); successHandler.setTargetUrlParameter(\"redirectTo\"); http.authorizeRequests() .antMatchers(adminContextPath + \"/assets/**\").permitAll() .antMatchers(adminContextPath + \"/login\").permitAll() .anyRequest().authenticated() .and() .formLogin().loginPage(adminContextPath + \"/login\").successHandler(successHandler).and() .logout().logoutUrl(adminContextPath + \"/logout\").and() .httpBasic().and() .csrf().disable(); }} 重启 Admin Server 服务，在浏览器上访问 http://127.0.0.1:9001/ 后，页面会被重定向到登录界面，登录的用户名和密码分别为上面配置的 admin 和 admin，界面显示如下： 6、Admin 整合邮箱报警Spring Boot Admin 中可以集成邮箱报警功能，比如服务不健康了、下线了，都可以给指定邮箱发送邮件。集成的步骤非常简单，首先在 Admin Server 中引入以下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt; 在 Admin Server 的 application.yml 配置文件中，添加邮件相关的配置内容，其中 username 与 notify.mail.from 的内容必须一致： 123456789101112spring: mail: port: 25 host: smtp.qq.com username: 158747124@qq.com password: xxxxxxx boot: admin: notify: mail: to: 389723578@qq.com from: 158747124@qq.com 由于国内腾讯云、阿里云默认封了 25 端口，若项目是部署在云服务器，使用上述的配置是无法正常发送邮件的，需要更改为使用 465 端口，并启用 SSL 邮件加密，最后系统防火墙别忘了开放 465 端口，配置示例如下： 12345678910111213141516171819202122232425spring: mail: port: 465 protocol: smtp host: smtp.qq.com username: 158747124@qq.com password: xxxxxxx properties: mail: smtp: auth: true socketFactory: port: 465 class: javax.net.ssl.SSLSocketFactory ssl: enable: true starttls: enable: true required: true boot: admin: notify: mail: to: 389723578@qq.com from: 158747124@qq.com 以上配置，当已注册的服务的状态从 UP 变为 OFFLINE 或其他状态时，Admin Server 会自动将告警邮件发送到对应的邮箱，更多邮箱相关的配置示例如下： 123456789101112131415161718192021222324252627spring.mail.host=smtp.qq.comspring.mail.username=xx@qq.comspring.mail.password=xxxxxxspring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=truespring.mail.properties.mail.smtp.ssl.enable=truespring.mail.properties.mail.smtp.socket.factory.class=javax.net.ssl.SSLSocketFactoryspring.mail.properties.mail.smtp.socket.factory.fallback=falsespring.mail.properties.mail.smtp.port=465spring.mail.properties.mail.transport.protocol=smtp#需要忽略的状态改变通知，逗号分隔,例如不通知离线到上线的状态，则填写为OFFLINE:UP#spring.boot.admin.notify.mail.ignore-changes=#接收通知的邮箱地址，逗号分隔spring.boot.admin.notify.mail.to=yangzhilong@qq.com#需要抄送的邮箱地址，逗号分隔#spring.boot.admin.notify.mail.cc=test1@qq.com#邮件发送者,大部分情况与登录名相同spring.boot.admin.notify.mail.from=${spring.mail.username}#邮件主题，默认是：#{application.name} (#{application.id}) is #{to.status}spring.boot.admin.notify.mail.subject=${spring.profiles.active} profile's #{application.name} (#{application.id}) is #{to.status}#邮件内容，默认是：#{application.name} (#{application.id})\\nstatus changed from #{from.status} to #{to.status}\\n\\n#{application.healthUrl}spring.boot.admin.notify.mail.text=${spring.profiles.active} profile's #{application.name} (#{application.id})\\nstatus changed from #{from.status} to #{to.status}#Comma-delimited list of status changes to be ignored. Format: \"&lt;from-status&gt;:&lt;to-status&gt;\". Wildcards allowed.默认值：\"UNKNOWN:UP\"#spring.boot.admin.notify.mail.ignore-changes= 7、参考资料 Spring Boot 使用 QQ 邮箱发邮件 Spring Boot Admin 在线日志配置 Spring Boot Admin 2.1.0 全攻略 SpringBoot（2.1.1）监控管理及性能调优 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"微服务"},{"title":"C 语言语法之一数据类型与运算符","url":"/posts/168c8788.html","text":"数据类型数据类型概览 常量与变量对于基本数据类型量，按其取值是否可改变又分为常量和变量两种。在程序执行过程中，其值不发生改变的量称为常量，其值可变的量称为变量。它们可与数据类型结合起来分类，例如可分为整型常量、整型变量、浮点常量、浮点变量、字符常量、字符变量、枚举常量、枚举变量。在程序中，常量是可以不经说明而直接引用的，而变量则必须先定义后使用。（整型量包括整型常量、整型变量） 符号常量在 C 语言中，可以用一个标识符来表示一个常量，称之为符号常量。符号常量在使用之前必须先定义，其一般定义形式为：#define 标识符 常量。其中 #define 也是一条预处理命令（预处理命令都以”#” 开头），称为宏定义命令，其功能是把该标识符定义为其后的常量值。一经定义，以后在程序中所有出现该标识符的地方均代之以该常量值。习惯上符号常量的标识符用大写字母，变量标识符用小写字母，以示区别。 整型常量的表示方法整型常量就是整常数，在 C 语言中，使用的整常数有十进制、八进制和十六进制三种： 十进制整常数：十进制整常数没有前缀，其数码为 0～9，以下各数是合法的十进制整常数：237、-568、65535、1627 八进制整常数：八进制整常数必须以 0 开头，即以 0 作为八进制数的前缀，数码取值为 0～7，八进制数通常是无符号数。 以下各数是合法的八进制数： 015 (十进制为 13)、0101 (十进制为 65)、0177777 (十进制为 65535) 十六进制整常数：十六进制整常数的前缀为 0X 或 0x，其数码取值为 09，AF 或 a~f。 以下各数是合法的十六进制整常数： 0X2A (十进制为 42)、0XA0 (十进制为 160)、0XFFFF (十进制为 65535) 整型常数的后缀：在 16 位字长的机器上，基本整型的长度也为 16 位，因此表示的数的范围也是有限定的。十进制无符号整常数的范围为 0～65535，有符号数为 - 32768～+32767。八进制无符号数的表示范围为 0～0177777。十六进制无符号数的表示范围为 0X0～0XFFFF 或 0x0～0xFFFF。如果使用的数超过了上述范围，就必须用长整型数来表示，长整型数是用后缀 “L” 或 “l” 来表示的。 整型变量的分类注意：整型变量占多少个字节，这个跟系统和编译器的规定有关！ 基本型：类型说明符为 int，在内存中占 4 个字节 短整型：类型说明符为 short int 或 short，在内存中占 2 个字节 长整型：类型说明符为 long int 或 long，在内存中占 8 个字节 无符号型：类型说明符为 unsigned，在内存中占 4 个字节 整型变量在内存中的存放形式内存中的整型变量以二进制存储，一个字节 (byte) = 8 位 (bit)。其中数值是以补码表示，正数的补码和原码相同，负数的补码则是将该数的绝对值的二进制形式按位取反再加一。 1234567例如：求-10的补码10的原码： 00001010取反： 11110101再加1，得-10的补码： 11110110提示：第一位是符号位！ 实型常量的表示方法实型也称为浮点型，实型常量也称为实数或者浮点数。在 C 语言中，浮点数只采用十进制表示，其中有二种形式：十进制小数形式、指数形式。标准 C 语言允许浮点数使用后缀，后缀为 “f” 或 “F” 即表示该数为浮点数，如 356f 和 356. 是等价的。 十进制数形式：由数码 0~ 9 和小数点组成，例如 0.0、25.0、5.789、0.13、5.0、300.、-267.8230 等均为合法的实数 (必须有小数点) 指数形式：由十进制数、阶码标志 “e” 或 “E”、阶码 (只能为整数，可以带符号) 组成，其一般形式为：a E n（a 为十进制数，n 为十进制整数），例如 2.1E5 (等于 2.1105)、-2.8E-2 (等于 - 2.810-2)、0.5E7 (等于 0.5*107) 实型变量的分类实型变量分为：单精度（float 型）、双精度（double 型）和长双精度（long double 型）三类。在 Turbo C 中单精度型占 4 个字节（32 位）内存空间，其数值范围为 3.4E-38～3.4E+38，只能提供七位有效数字。双精度型占 8 个字节（64 位）内存空间，其数值范围为 1.7E-308～1.7E+308，可提供 16 位有效数字。 实型变量在内存中的存放形式实型变量一般占 4 个字节 (32 位) 的内存空间，按指数形式存储，实数 3.14159 在内存中的存放形式如下： 小数部分占的位 (bit) 数愈多，数的有效数字愈多，精度愈高 指数部分占的位数愈多，则能表示的数值范围愈大 字符常量字符常量是用单引号括起来的一个字符，例如：’a’、’b’、’=’、’+’、’?’都是合法字符常量。在 C 语言中，字符常量有以下特点： 字符常量只能用单引号括起来，不能用双引号或其它括号 字符常量只能是单个字符，不能是字符串 字符可以是字符集中任意字符，但数字被定义为字符型之后就不能参与数值运算。例如’5’和 5 是不同的，’5’是字符常量，不能参与运算 转义字符转义字符是一种特殊的字符常量，转义字符以反斜线”\" 开头，后面跟一个或几个字符。转义字符具有特定的含义，不同于字符原有的意义，故称 “转义” 字符。例如 printf 函数的格式串中用到的 \\n 就是一个转义字符，其意义是 “回车换行”。转义字符主要用来表示那些用一般字符不便于表示的控制代码。 字符变量字符变量用来存储字符常量，即单个字符。字符变量的类型说明符是 char，字符变量类型定义的格式和书写规则都与整型变量相同。例如：char a, b; 字符变量在内存中的存放形式每个字符变量被会被分配一个字节的内存空间，因此只能存放一个字符。字符值是以 ASCII 码的形式存放在变量的内存单元之中的，如 x 的十进制 ASCII 码是 120，y 的十进制 ASCII 码是 121。若对字符变量 a、b 分别赋予’x’和’y’值：a =‘x’; b = 'y';，实际上是在 a、b 两个单元内存放 120 和 121 的二进制值。 字符串常量字符串常量是由一对双引号括起的字符序列，例如：”CHINA”、”C program” 等都是合法的字符串常量。字符串常量和字符常量是不同的量，它们之间主要有以下区别： 字符常量由单引号括起来，字符串常量由双引号括起来 字符常量只能是单个字符，字符串常量则可以含一个或多个字符 可以把一个字符常量赋予一个字符变量，但不能把一个字符串常量赋予一个字符变量，例如：可以是 char a = ‘a’ 但不能是 char a = “a” 字符常量占一个字节的内存空间，字符串常量占的内存字节数等于字符串的字节数加一，额外增加的一个字节用于存放字符 \\0 (ASCII 码为 0)，这是字符串的结束标志 运算符各类数值型数据之间的混合运算变量的数据类型是可以转换的，转换的方法有两种，一种是自动转换，一种是强制转换。自动转换发生在不同数据类型的量混合运算时，由编译系统自动完成。自动转换遵循以下规则： 若参与运算量的类型不同，则先转换成同一类型，然后进行运算 转换按数据长度增加的方向进行，以保证精度不降低，如 int 型和 long 型运算时，先把 int 量转成 long 型后再进行运算 所有的浮点运算都是以双精度进行的，即使仅含 float 单精度量运算的表达式，也要先转换成 double 型，再作运算 char 型和 short 型参与运算时，必须先转换成 int 型 在赋值运算中，赋值号两边量的数据类型不同时，赋值号右边量的类型将转换为左边量的类型。如果右边量的数据类型长度比左边长时，将丢失一部分数据，这样会降低精度，丢失的部分按四舍五入向前舍入，类型自动转换的规则为：double &lt;- long &lt;- unsigned &lt;- int &lt;- char、short 自动类型转换如果赋值运算符两边的数据类型不相同，系统将自动进行类型转换，即把赋值号右边的类型换成左边的类型，具体规定如下： 实型赋予整型，舍去小数部分 整型赋予实型，数值不变，但将以浮点形式存放，即增加小数部分 (小数部分的值为 0) 字符型赋予整型，由于字符型为一个字节，而整型为四个字节，故将字符的 ASCII 码值放到整型量的低八位中，高八位为 0。整型赋予字符型，只把低八位赋予字符量 强制类型转换强制类型转换是通过类型转换运算来实现的，其一般形式为：(类型说明符) (表达式)，其功能是把表达式的运算结果强制转换成类型说明符所表示的类型。例如： (float) a 表示把 a 转换为浮点型，(int)(x+y) 表示把 x+y 的结果转换为整型，在使用强制转换时应注意以下问题： 类型说明符和表达式都必须加括号 (单个变量可以不加括号)，如把 (int)(x+y) 写成 (int)x+y 则成了把 x 转换成 int 型之后再与 y 相加了 无论是强制转换或是自动转换，都只是为了本次运算的需要而对变量的数据长度进行的临时性转换，而不改变数据说明时对该变量定义的类型 基本的算术运算符 加法运算符 “+”：加法运算符为双目运算符，即应有两个量参与加法运算。如 a+b, 4+8 等，具有右结合性 减法运算符 “-”：减法运算符为双目运算符，但 “-” 也可作负值运算符，此时为单目运算，如 - x, -5 等，具有左结合性 乘法运算符 “*”：双目运算，具有左结合性 除法运算符 “/”：双目运算，具有左结合性，参与运算量均为整型时，结果也为整型，舍去小数部分；如果运算量中有一个是实型，则结果为双精度实型 运算符的优先级与结合性 运算符的优先级：C 语言中，运算符的运算优先级共分为 15 级。1 级最高，15 级最低。在表达式中，优先级较高的先于优先级较低的进行运算。而在一个运算量两侧的运算符优先级相同时，则按运算符的结合性所规定的结合方向处理 运算符的结合性：C 语言中各运算符的结合性分为两种，即左结合性 (自左至右) 和右结合性 (自右至左)。例如算术运算符的结合性是自左至右，即先左后右。如有表达式 x-y+z 则 y 应先与 “-” 号结合，执行 x-y 运算，然后再执行 + z 的运算，这种自左至右的结合方向就称为 “左结合性”。而自右至左的结合方向称为 “右结合性”。 最典型的右结合性运算符是赋值运算符，如 x=y=z，由于 “=” 的右结合性，应先执行 y=z 再执行 x=(y=z) 运算。C 语言运算符中有不少为右结合性，应注意区别，以避免理解错误 运算符优先级与结合性一览表点击查看运算符优先级与结合性一览表，表中可以总结出如下规律： 结合方向只有三个是从右往左，其余都是从左往右 所有双目运算符中只有赋值运算符的结合方向是从右往左 另外两个从右往左结合的运算符也很好记，因为它们很特殊：一个是单目运算符，一个是三目运算符 C 语言中有且只有一个三目运算符 逗号运算符的优先级最低，要记住 对于优先级：算术运算符 &gt; 关系运算符 &gt; 逻辑运算符 &gt; 赋值运算符，逻辑运算符中 “!” 除外 自增、自减运算符 自增 1 运算符：记为 ++，其功能是使变量的值自增 1 自减 1 运算符：记为 --，其功能是使变量值自减 1 自增 1，自减 1 运算符均为单目运算，都具有右结合性，可有以下几种形式：++i，i 自增 1 后再参与其它运算--i，i 自减 1 后再参与其它运算i++，i 参与运算后，i 的值再自增 1i--，i 参与运算后，i 的值再自减 1 1234567int i = 8;printf(\"%d\\n\",++i); // 打印9，此时i=9printf(\"%d\\n\",--i); // 打印8，此时i=8printf(\"%d\\n\",i++); // 打印8，此时i=9printf(\"%d\\n\",i--); // 打印9，此时i=8printf(\"%d\\n\",-i++); // 打印-8，此时i=9printf(\"%d\\n\",-i--); // 打印-9，此时i=8 赋值运算符和赋值表达式 赋值运算符记为 “=”，由 “=” 连接的式子称为赋值表达式，其一般表现形式为： 变量 = 表达式，例如 x = a + b 赋值表达式的功能是计算表达式的值再赋予左边的变量，因此赋值运算符具有右结合性，例如 a=b=c=5 可理解为 a=(b=(c=5)) 复合的赋值运算符 在赋值符 “=” 之前加上其它二目运算符可构成复合赋值符，例如 +=、-=、*=、/=、%=、&lt;&lt;=、&gt;&gt;=、&amp;=、^=、|= 复合赋值符这种写法，十分有利于编译处理，能提高编译效率并产生质量较高的目标代码，例如 a+=5 等价于 a=a+5，r%=p 等价于 r=r%p 本节重点内容 整型变量在内存中的存放形式 实型变量在内存中的存放形式 字符变量在内存中的存放形式 各类数值型数据之间的混合运算 自动类型转换 运算符的优先级与结合性 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c语言"},{"title":"Linux 必要命令摘要","url":"/posts/817c7d82.html","text":"","tags":"在线电子书"},{"title":"Linux 系统编程之三 - 系统常用命令","url":"/posts/2db9f8a1.html","text":"命令格式Linux 命令的格式：command [-options] [parameter1] ... command：命令名称，相应功能的英文单词或单词的缩写 [-options]：选项，可用来对命令进行控制，也可以省略，[] 代表可选 parameter1 ...：命令的参数，可以是零个、一个或者多个 基础命令管道 |管道，也就是一个命令的输出可以通过管道做为另一个命令的输入。简单概括，管道可以理解现实生活中的管子，管子的一头塞东西进去，另一头取出来，这里 | 的左右分为两端，左端塞东西（写），右端取东西（读）。 1$ ls -alh | more 清屏 clearclear 作用为清除终端上的显示（类似于 DOS 的 cls 清屏功能），也可使用快捷键：ctrl + l。 1$ clear 输出重定向 &gt;Linux 允许将命令执行结果重定向到一个文件，本应显示在终端上的内容保存到指定文件中。&gt; 输出重定向会覆盖原来的内容，&gt;&gt; 输出重定向则会将内容追加到文件的尾部。 12345# 覆盖文件内容$ ls &gt; abc.txt# 追加文件内容$ date &gt;&gt; abc.txt 切换工作目录 cd在使用 Unix/Linux 的时候，经常需要更换工作目录，cd 命令可以帮助用户切换工作目录。Linux 所有的目录和文件名都区分大小写。cd 命令后面可跟绝对路径，也可以跟相对路径；如果省略目录，则默认切换到当前用户的主目录。 显示当前路径 pwd使用 pwd 命令可以显示当前的工作目录，该命令很简单，直接输入 pwd 即可，后面不带参数。 查看命令位置 whichwhich 命令可以用来查看特定命令的具体位置。 12# 查看ls命令的位置$ which ls 帮助文档查看帮助文档 manman 是 Linux 提供的一个帮助手册命令，可以查看绝大部分命令、函数的使用说明。该帮助手册分成很多章节（section），使用 man 命令时可以指定不同的章节来浏览不同的内容。各个章节（section）的含义如下： 1．Standard commands（标准命令） 2．System calls（系统调用，如 open,write） 3．Library functions（库函数，如 printf,fopen） 4．Special devices（设备文件的说明，/dev 下各种设备） 5．File formats（文件格式，如 passwd） 6．Games and toys（游戏和娱乐） 7．Miscellaneous（杂项、惯例与协定等，例如 Linux 档案系统、网络协定、ASCII 码；environ 全局变量） 8．Administrative Commands（管理员命令，如 ifconfig） man 命令的使用格式是：man [选项] 命令名称，例如查看 ls 命令的用法可以使用：man 1 ls，其中 1 是数字，代表第 1 个 章节（section）。实际上，一般不用指定第几个章节也可以正常查看，例如 man ls。但是有一种情况除外，假如命令的名称和函数的名称刚好相同（如：printf），它既是命令，也可以是库函数；如果不指定章节号直接使用 man printf，那么它只能查看命令的用法，不能查看函数的用法，因为 man 命令是按照手册的章节号的顺序进行搜索的。man 命令设置了如下的功能键： 查看帮助文档 - -help--help 一般是 Linux 命令自带的选项，但并不是所有命令都自带这个选项，例如以下命令可以查看 ls 命令的帮助文档： 1$ ls --help 文件管理查看文件列表 lsls 是英文单词 list 的简写，其功能为列出目录的内容，是用户最常用的命令之一，它类似于 DOS 系统下的 dir 命令。Linux 文件或者目录名称最长可以有 256 个字符，. 代表当前目录，.. 代表上一级目录，以 . 开头的文件为隐藏文件，需要用 -a 参数才能显示。 与 DOS 系统下的文件操作类似，在 Unix/Linux 系统中，也同样允许使用特殊字符来同时引用多个文件名，这些特殊字符被称为 通配符。 创建目录 mkdir通过 mkdir 命令可以创建一个新的目录，参数 -p 可递归创建目录。需要注意的是，新建目录的名称不能与当前目录中已有的目录或文件同名，并且目录创建者必须对当前目录具有写权限。 123$ mkdir www$ mkdir -p www/nginx/ 删除目录 rmdir可使用 rmdir 命令删除一个目录，但必须离开目录，并且目录必须为空目录，不然会提示删除失败 删除文件 rm可通过 rm 命令删除文件或目录。使用 rm 命令要特别小心，因为文件删除后不能恢复。为了防止文件误删，可以在 rm 命令后使用 -i 参数以逐个确认要删除的文件。结合 -r 参数，可以递归删除非空目录里的所有文件和文件夹。 123$ rm run.log$ rm -rf /www/share/ 拷贝文件 cpcp 命令的功能是将给出的文件或目录复制到另一个文件或目录中，相当于 DOS 下的 copy 命令。 移动文件 mv用户可以使用 mv 命令来移动文件或目录，也可以给文件或目录重命名。 12345678# 文件重命名$ mv run.log runtime.log# 移动文件$ mv /tmp/run.log /usr/local/share/# 移动目录$ mv /tmp/share/ /usr/local/share/ 创建文件 touchtouch 命令用于修改文件或者目录的时间属性，包括存取时间和更改时间，若文件不存在，则会创建一个新的文件。命令格式为： touch [-acfm] [-d&lt;日期时间&gt;] [-r&lt;参考文件或目录&gt;] [-t&lt;日期时间&gt;] [--help] [--version][文件或目录...] -a：更改文件的读取时间记录 -m：更改文件的修改时间记录 -c：假如指定的文件不存在，不会创建新的文件，与 --no-create 的效果一样 -f：可忽略不使用，是为了与其他 Unix 系统的相容性而保留 -r：使用其他文件的时间信息，而不是当前系统时间 -d：设定时间与日期，可以使用各种不同的格式 -t：设定文件的时间信息，格式与 date 命令相同 --no-create：不创建新的文件 12# 修改文件时间属性为当前系统时间$ touch testfile 值得一提的是，使用 touch 命令时，如果指定的文件不存在，则将创建一个新的空白文件。例如，在当前目录下，使用该指令创建一个空白文件 newfile，可以使用如下命令： 1$ touch newfile 建立链接文件 lnLinux 的链接文件类似于 Windows 下的快捷方式，链接文件分为 软链接 和 硬链接: 硬链接：硬链接只能链接普通文件，不能链接目录，命令格式：ln 源文件 链接文件 软链接：软链接不占用磁盘空间，源文件删除则软链接失效，命令格式：ln -s 源文件 链接文件 1$ ln -s /bin/less /usr/local/bin/less 如果没有 -s 选项则代表建立一个硬链接文件，两个文件占用相同大小的硬盘空间，即使删除了源文件，链接文件还是存在，所以 -s 选项是更常见的使用形式。特别注意，如果软链接文件和源文件不在同一个目录，源文件要使用绝对路径，不能使用相对路径。 获取文件类型 fileLinux 系统文件类型不是根据文件扩展名分类的，通过 file 命令可以确认文件的具体类型。 1$ file run.log 文件内容搜索 grepLinux 系统中的 grep 命令是一种强大的文本搜索工具，grep 命令允许对文本文件进行模式查找。如果找到匹配模式，grep 命令会打印包含模式的所有行。grep 命令的格式为 grep [-选项] \"搜索内容\" 文件名。 12345678# 在文件中搜索字符串$ grep \"time\" /tmp/run.log# 在文件中搜索字符串，不区分大小写$ grep -i \"time\" /tmp/run.log# 在文件中搜索字符串，不区分大小写，显示行号$ grep -i -n \"time\" /tmp/run.log 值得一提的是，在 grep 命令中输入字符串参数时，最好使用引号或双引号括起来，例如：grep \"a\" run.log。 计算文件行数或字数 wc 1234567891011 # 统计文件行数 $ wc -l run.log# 统计文件字数$ wc -w run.log# 统计文件字节数$ wc -c run.log# 统计文件字符数$ wc -m run.log 分页显示文件内容 more查看内容时，在信息过长无法在一屏上显示时，会出现快速滚屏，使得用户无法看清文件的内容。此时可以使用 more 命令，每次只显示一页，按下 空格键 可以显示下一页，按下 回车键 可以显示下一行，按下 q 键退出显示，按下 h 键可以获取帮助。 1$ more README.md 查看或者合并文件内容 cat12345# 查看文件内容$ cat 1.log# 合并文件内容$ cat 1.log 2.log &gt; 3.log 文件压缩解压 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"linux系统编程"},{"title":"Windows 系统下 CLion 配置 MinGW","url":"/posts/60b40ee7.html","text":"MinGW 介绍MinGW 的简介MinGW 是 Minimalist GNU on Windows 的缩写。它是一个可自由使用和自由发布的 Windows 特定头文件和使用 GNU 工具集导入库的集合，允许开发者在 Linux 和 Windows 平台生成本地的 Windows 程序而不需要第三方 C 运行时（C Runtime）库。MinGW 实际上是将经典的开源 C 语言编译器 GCC 移植到了 Windows 平台下，并且包含了 Win32API 和 MSYS，因此可以将源代码编译生成 Windows 下的可执行程序，又能如同在 Linux 平台下时，使用一些 Windows 不具备的开发工具。简单一句话概况，MinGW 就是 GCC 的 Windows 版本 。 MinGW 的优势 MinGW 支持最新的 C 语言 标准 MinGW 是开源软件，可以免费使用 MinGW 由一个活跃的开源社区在持续维护，因此不会过时 MinGW 使用 Windows 的 C 语言运行库，因此编译出的程序不需要第三方 DLL ，可以直接在 Windows 下运行 那些著名的开源 IDE 实际只是将 MinGW 封装了起来，使它拥有友好的图形化界面，简化了操作，但内部核心仍然是 MinGW MinGW 是稳定可靠的、持续更新的 C/C++ 编译器，使用它可以免去很多麻烦，不用担心跟不上时代，也不用担心编译器本身有严重漏洞，可以放心的去编写程序。 MinGW 安装管理器下载 MinGW 安装管理器浏览器访问 这里，下载最新版本的 MinGW 安装管理器 mingw-get-setup.exe 安装 MinGW 安装管理器 使用系统管理员权限运行 mingw-get-setup.exe 选择 MinGW 安装管理器的安装位置 开始下载 MinGW 安装管理器，一般来说并不会花费太长时间，在数分钟范围内即可完成 MinGW 组件安装MinGW 安装管理器安装完成后，会在桌面创建一个快捷方式，以后只要双击它就可以启动 MinGW 安装管理器，这样就可以很方便地管理 MinGW 已安装的组件，或者添加安装新的组件 界面介绍一般来说，只需要一些基础组件就可以满足编译 C/C++ 程序的需求，所以选择左侧目录中的第一项 Basic Setup 即可，之后就可以在右侧选择需要的组件了 勾选组件在组件上单击鼠标右键，然后在弹出的右键菜单中单击 Mark for Installation 选项，即可将组件进行标记。在之后的操作完成后，管理器将会自动安装被标记了的组件 选择组件如果只是为了编译 C/C++ 程序，那么只需安装 mingw-developer-toolkit、mingw32-base、mingw32-gcc-g++、msys-base 这 4 个基础组件即可 应用更改在上述所需的 4 个基础组件都已勾选完成后，单击菜单栏上的 Installation 选项，并在弹出的菜单中单击 Apply Changes 选项 确认安装在弹出的确认窗口里，直接单击 Apply 按钮，之后安装管理器就会真正地开始下载和安装 MinGW 了 MinGW 安装管理器会一边下载一边安装 MinGW，这一过程可能会花费很长的时间。由于 MinGW 安装管理器连接的是国外的服务器，这会导致下载速度缓慢，所以需要耐心地等待一段时间 安装完成 检查更新 已安装组件 MinGW 环境变量配置安装目录结构MinGW 安装后，本地磁盘的目录结构如下，默认安装路径是 C:\\MinGW\\ 添加环境变量将 MinGW 安装目录下 bin 目录的路径添加到系统的环境变量中 验证环境变量在打开的命令提示符窗口中，输入 gcc -v ，然后按回车键（Enter），若控制台正确输出 GCC 的版本信息，则说明已正确配置 MinGW 的环境变量 CLion 配置 MinGWCLion 的安装可以参考本站教程：JetBrains-CLion 永久激活 创建 CMake 项目若是 C++ 项目，则选择 C++ Executable，若是 C 语言项目，则选择 C Executable，然后选择项目路径即可 配置工具链进入 CLion 工具链的配置界面，点击左侧的 + 号，环境选择 MinGW 选择 MinGW 的安装路径，一般情况下，设置好 MinGW 的安装路径后，CLion 会自动探测 CMake、Make、C Compiler 和 C++ Compiler 对应的可执行程序，但速度略慢，可等待探测完成，也可手动选择可执行文件 编译程序选中需要编译和运行的 C/C++ 源文件，然后点击 绿色箭头，这就可以编译和运行 C/C++ 程序了，程序成功运行后，会在 CLion 的输出窗口打印运行结果 参考博客 MinGW 安装教程 MinGW 离线安装包下载 Cygwin 和 MinGW 的区别与联系是怎样的 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"JetBrains-CLion 永久激活教程","url":"/posts/c0477083.html","text":"最新公告本文适用于 JetBrains CLion v2019.3/3.1/3.2/3.3 永久激活，若你使用的是更新的版本，建议参考这篇博客，使用最新的方式来破解。 前言JetBrains CLion 是一款专为 C/C++ 开发所设计的跨平台 IDE。本文适用 JetBrains CLion v2019.3/3.1/3.2/3.3 永久激活，附破解补丁和激活码，可以永久激活 Windows、MAC、Linux 下的 CLion！！！网上有激活码的激活方式（更改 hosts），一般都是几个月或者一年，但下面介绍的方法是永久激活，亲测可以激活成功。JetBrains CLion v2019.3.4 以及之后的版本暂时只支持默认的 License Server 激活方式，望周知。 资源下载 JetBrains CLion 下载：官网 JetBrains CLion&nbsp;破解补丁下载：本站 JetBrains CLion&nbsp;破解补丁下载：百度网盘 提取码：u3pe Clione 激活第一步更改 hosts 文件，将 hosts 文件中有关 Jetbrains 的配置行全部删除掉，若没有则请忽略此步骤。Windows 系统的 hosts 文件路径为：C:\\Windows\\System32\\drivers\\etc\\hosts，Linux 和 Mac 系统的 hosts 文件路径为：/etc/hosts，一般情况下只需删除以下两行内容即可： 120.0.0.0 www.jetbrains.com0.0.0.0 account.jetbrains.com 第二步下载安装 JetBrains CLion，然后启动 CLion 并选择试⽤（Evaluate for free）模式进⼊软件（如下图），首次启动后的配置项根据自己的需要勾选，此步骤不会影响后面破解的过程。假设软件之前已经在试用或者试用过而且过期了，那么可以先删除 CLion 的所有配置文件，然后再重新启动软件，CLion 配置文件所在的目录如下： 123456789# Windows系统C:\\Documents and Settings\\Administrator\\.clion-2019.3.3\\configC:\\Documents and Settings\\Administrator\\.clion-2019.3.3\\system# Linux/Mac系统~/.CLion2019.3/config~/.CLion2019.3/system~/.config/JetBrains #此目录仅供参考，勿随便删除~/.local/share/JetBrains #此目录仅供参考，勿随便删除 第三步JetBrains CLion 启动后（试用模式），手动选择创建或者打开一个项目，进入到 CLion 的主界面。然后解压破解补丁压缩包（解压路径不能包含中文字符），将破解补丁文件 jetbrains-key.jar 拖进 CLion 的主界面，根据提示点击 Restart 按钮重启软件（如下图）。 第四步JetBrains CLion 重启完成后，在弹出的 JetbrainsAgent 配置助手对话框中选择对应的激活方式，然后点击安装按钮即可（如下图）。如果是⽆外网环境（银行、公安内网），请在对话框中选择 Activation code 激活方式和勾选 我⽆法访问外网的选项，一般情况下只需要选择 Activation code 激活方式即可。最后根据提示窗口，再次重启 CLion 即可完成所有破解步骤。 第五步查看是否破解成功，CLion 的菜单栏导航到 Help –&gt; About，若出现下图的信息则说明破解成功。 CLion 支持的工具链Windows 平台下，CLion 支持的工具链包括：MinGW、Cygwin、Visual Studio、WSL、Remote Host，其中 MinGW 的使用可以参考本站教程： CLion 配置 MinGW 背后的原理分析（可忽略）注：使用本文提供的破解补丁时，一定要使用上面提到的方法（拖拽破解补丁文件到 CLion 的主界面）来破解 CLion，否则破解会失败。 1234561. 将破解补丁解压目录下的important.txt、jetbrains-key.jar文件拷贝到~/.jetbrains目录~/.jetbrains/important.txt~/.jetbrains/jetbrains-agent-v3.0.3.ed81.6052. 根据操作系统的位数，找到匹配的配置文件~/.CLion2019.3/config/clion.vmoptions或者~/.CLion2019.3/config/clion64.vmoptions，然后在配置文件末尾追加如下一行内容-javaagent:~/.jetbrains/jetbrains-agent-v3.0.3.ed81.605 参考资料 CLion 如何创建并运行 C/C++ 程序 Jetbrains 系列产品 2019.3.3 最新激活方法 CLion 中创建多个 .c 文件不能运行问题及报错问题 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"开发工具"},{"title":"Linux 系统编程之二 GCC、G++ 与 GDB 的使用","url":"/posts/af282851.html","text":"GCCGCC 编译器介绍GCC（GNU Compiler Collection）编译器是 GNU 开源组织发布的 UNIX/Linux 下功能强大、性能优越的编译器，支持跨平台交叉编译，它还可以将 C、C++ 等多种语言编写的源程序编译、链接成可执行文件。而 GDB 是 GNU 推出的功能强大的程序调试器，可以说 GCC 与 GDB 是在 Linux 环境下进行 C/C++ 程序开发不可缺的工具。GCC 可以编译如 C、C++、Object-C、Java、Fortran、Pascal、Modula-3 和 Ada 等多种编程语言，而且 GCC 又是一个多平台编译器，能够在当前 CPU 平台上为多种不同体系架构的硬件平台开发软件，因此尤其适合在嵌入式软件领域的开发和编译。在使用 GCC 编译程序时，编译过程可以被细分为四个阶段：预处理、编译、汇编、链接。 GCC 使用语法介绍 语法：gcc [options] [filenames] 参数 作用 编译示例 示例说明 -o 指定输出可执行程序的名称，默认文件名为”a.out” gcc hello.c -o hello 编译单个源文件 hello.c，指定输出可执行程序的名称为 hello，支持同时编译多个源文件 -E 仅作预处理，不进行编译、汇编和链接 gcc -E hello.c -o hello.i 仅预处理源文件，指定生成中间文件 *.i，此阶段主要处理源文件中的 #ifdef、#include、#define 等预处理命令 -S 只编译到汇编语言，不进行汇编和链接，生成汇编代码 gcc -S hello.c -o hello.s 仅编译到汇编语言，指定生成汇编源文件 *.s -c 只编译、汇编到目标代码，不进行链接，生成目标文件（机器语言） gcc -c hello.s -o hello.o 根据汇编源文件 *.s，指定生成目标文件 *.o，最后根据生成的目标文件，可执行 gcc hello.o -o hello 命令生成可执行程序 -l 指定程序链接哪个静态库或者动态库 -m 表示是数学库，也就是使用 math.h 头文件 gcc hello.c -o hello -lm 编译单个源文件 hello.c，指定输出可执行程序名称为 hello，并指定程序链接到数学库 -I dir 在头文件的搜索路径列表中添加 dir 目录 -L dir 在库文件的搜索路径列表中添加 dir 目录 -O、-O2、-O3 将优化状态打开，该选项不能与”-g” 选项联合使用 -g 在生成的可执行程序中包含标准调试信息 -Wall 在发生警告时取消编译操作，即将警告看作是错误 -pedantic 严格要求代码符合 ANSI/ISO C 标准，若不符合则给出编译警告信息 -w 禁止输出所有警告 -v 打印编译器内部编译各过程的命令行信息和编译器的版本号 GCC 编译单个源文件假设有 hello.c 单个源文件，编译命令如下： gcc hello.c -o hello GCC 编译多个源文件假设有 hello.h、hello.c、main.c 三个源文件，两种编译的方式如下： 一次性编译：gcc hello.c main.c –o hello 多次独立编译（建议加上 -Wall 参数）： gcc -Wall -c main.c -o main.o gcc -Wall -c hello.c -o hello.o gcc -Wall main.o hello.o -o hello GCC 编译生成可执行文件的流程编译流程图 编译详细命令 步骤 命令 1. 预处理 gcc -E hello.c -o hello.i 2. 编译到汇编代码 gcc -S hello.c -o hello.s 3. 汇编到目标代码（机器语言） gcc -c hello.s -o hello.o 4. 链接，生成可执行文件 gcc hello.o -o hello 以上四个步骤，可以合成一个步骤，直接编译链接成可执行目标文件 gcc hello.c -o hello G++G++ 使用语法介绍 语法：g++ [options] [filenames] Make、CMake、Xmake、Automake、Autoconf、Meson 对比 var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i); var isEncrypt = document.getElementById('hexo-blog-encrypt'); var allowMobile = false; if (!isEncrypt && (!isMobile || (isMobile && allowMobile))) { try { var plugin = new ReadmorePlugin(); plugin.init({ \"type\": \"hexo\", \"id\": \"readmore-container\", \"name\": \"全栈技术驿站\", \"blogId\": \"96641-5333172926158-056\", \"qrcode\": \"https://www.techgrow.cn/img/wx_mp_qr.png\", \"keyword\": \"Tech\", \"random\": \"1\", \"height\": \"auto\", \"expires\": \"365\", \"lockToc\": \"yes\", \"interval\": \"30\", \"baseUrl\": \"\" }); } catch(e) { console.warn(\"readmore plugin occurred error: \" + e.name + \" | \" + e.message); } }","tags":"c++ c语言 linux系统编程"},{"title":"OAuth 2.0 特性与介绍","url":"/posts/197facd0.html","text":"前言用户认证与授权 用户认证：当用户去访问我们的系统资源的时候，我们的系统需要验证用户的身份（比如账号和密码认证这是一种方式），如果身份合法则认证通过，颁发相应的免死金牌，如果验证没通过，则提示用户请三思而后行，这就是用户认证 用户授权：用户授权一般是与用户认证相辅相成的，在认证的时候，如果认证通过，我们还会将该用户的权限信息给收集起来，并将相应信息作为依据，封装在认证的 HTTP 响应体中。当用户认证成功后，访问我们系统的某一个模块的时候，该模块是需要判断该用户是否有权访问，如果没有访问该资源的访问权限，用户也只有被拒绝访问，这就是用户授权 单点登录（SSO）单点登录一般常见于分布式应用中，用户只需要登录一次，即认证一次就可访问分布式应用中的所有模块，而不需要每访问一个模块就得去登录认证一次，这样用户嫌麻烦，后端认证逻辑也冗余。 第三方登录（授权码）比如目前互联网运用中的微信登录、微博登录、支付宝登录等，用户通过授权，第三方应用给予我们系统访问他微信相关信息的权限，我们获取后进行注册，使其称为我们系统的注册人员，实现第三方登录。 OAuth 2.0 概述OAuth 2.0 简介OAuth（Open Authorization，开放授权）是为用户资源的授权定义了一个安全、开放及简单的标准，第三方无需知道用户的账号及密码，就可获取到用户的授权信息。OAuth 2.0 是 OAuth 协议的延续版本，但不向后兼容 OAuth 1.0，即完全废止了 OAuth 1.0。值得一提的是，OAuth 2.0 规定了四种获得令牌的方式，可以选择最适合自己的那一种方式向第三方应用颁发令牌，分别包括： 简化模式（implicit） 密码模式（password） 客户端模式（client_credentials） 授权码模式（authorization_code） 特别注意：不管哪一种授权模式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client id）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。 OAuth 2.0 的角色OAuth 2.0 中有以下几个角色（以微信第三方登录为例）： 客户端：这个客户端和 OAuth 2.0 不沾亲带故，可以是任何独立的系统，比如我们自己的某个系统，或者某个 APP 客户端或者是 Web 客户端 资源拥有者：就是指我们的用户，比如微信登录中，在面对微信的数据库时，我们的系统就是无关人员；而登录的用户，在微信的系统中就是该用户信息的资源拥有者，他掌握着是否将他的微信个人信息暴露给我们的系统 认证服务器：在微信登录中，就是用来辨别用户的认证是否正确，是否可以成为该微信用户信息的资源拥有者；该系统由微信系统提供，用于鉴别资源拥有者的身份合法性 资源服务器：守护该微信用户信息的服务器，它掌握着微信的用户信息，我们的客户端最后就是向他发起请求，像面对甲方一样，求着它给我们响应该用户的微信个人信息 OAuth 2.0 实现第三方登录的流程以微信第三方登录为列子，具体的流程如下，点击查看流程图： 首先用户，登录我们的客户端，点击微信登录 我们的客户端请求微信的授权服务器，响应一个二维码给用户，用户扫码后点击同意 微信的授权服务器会对该微信用户进行验证 验证通过后，返回一个询问页面，是否授权给某某系统 用户点击确认，授权服务器就会颁发一个授权码给我们的客户端，并重定向我们的系统 此时我们的客户端获得授权码，根据授权码去微信的认证服务器申请令牌 微信的认证服务器认证通过后，会颁发一个令牌给我们的系统 当我们的系统拿到令牌时，也就是微信登录成功之时 该令牌代表着我们的系统，有权访问该微信用户在微信中的个人信息数据 我们的客户端携带令牌去微信的资源服务器获取该微信用户的个人信息 微信资源服务器校验该令牌的合法性，通过后响应该用户的微信个人信息数据给我们的客户端 OAuth2.0 四种授权方式授权码模式授权码模式（authorization_code）指的是第三方应用先申请一个授权码，然后再用该授权码来获取令牌。这种方式是最常用的流程，安全性也最高，它适用于那些有后端的 Web 应用。授权码通过前端传送，令牌则是储存在后端，而且所有与资源服务器的通信都在后端完成。这样的前后端分离，可以避免令牌泄漏。 第一步，A 网站提供一个链接，用户点击后就会跳转到 B 网站，授权用户数据给 A 网站使用。下面就是 A 网站跳转 B 网站的一个示意链接。 1